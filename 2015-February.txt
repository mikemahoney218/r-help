From ggrothendieck at gmail.com  Sun Feb  1 00:09:08 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 31 Jan 2015 18:09:08 -0500
Subject: [R] Dropping time series observations
In-Reply-To: <CACM6noYs29QAE8zBxhdxn4_W5d6cH+auaPRLhvrUbwLSWW0ZyQ@mail.gmail.com>
References: <CACM6noYs29QAE8zBxhdxn4_W5d6cH+auaPRLhvrUbwLSWW0ZyQ@mail.gmail.com>
Message-ID: <CAP01uRmqq0SCxu0__Bqt2g+xnEqwk5MgrT1kp1-biKvq1DrMJQ@mail.gmail.com>

On Sat, Jan 31, 2015 at 2:16 PM, Mikael Olai Milh?j
<mikaelmilhoj at gmail.com> wrote:
> Hi
>
> Is there an easy way to drop, for instance, the first 4 observation of a
> time series object in R? I have tried to google the answer without any
> luck.
>
> To be more clear:
> Let us say that I have a time seres object x which data from 2000Q1 to
> 2014Q4 but I only want the data from 2001Q1 to 2014Q4.How do I remove the
> first four elements?
>
> By using x[5:?] R no longer recognize it as a ts.object.
>

1.  We could convert it to a zoo series, drop the first 4 and convert back:

For example, using the built in presidents ts series:

library(zoo)
as.ts(tail(as.zoo(presidents), -4))

1a. This would work too:

library(zoo)
as.ts(as.zoo(presidents)[-(1:4)])


2. Using only base R one can use window like this since 4 observations
is one cycle (given that the frequency of the presidents dataset is 4.

window(presidents, start = start(presidents) + 1)

or in terms of 4:

window(presidents, start = start(presidents) + 4 * deltat(presidents))

Here deltat is the time between observations so we want to start 4
deltat's later.




-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jholtman at gmail.com  Sun Feb  1 01:22:49 2015
From: jholtman at gmail.com (jim holtman)
Date: Sat, 31 Jan 2015 19:22:49 -0500
Subject: [R] Melt and Rbind/Rbindlist
In-Reply-To: <CAMx+UYe7Bx+p6evVh7iNqZnL92FZuvVWfT9zBSeC9coQZV4kVQ@mail.gmail.com>
References: <CAMx+UYe7Bx+p6evVh7iNqZnL92FZuvVWfT9zBSeC9coQZV4kVQ@mail.gmail.com>
Message-ID: <CAAxdm-6DUOimQYaGUyAAqsM4frEwmbbK9Nartkf1Zr16P10UBA@mail.gmail.com>

It would have been nice if you had at least supplied a subset (~10 lines)
from a couple of files so we could see what the data looks like and test
out any solution. Since you are using 'data.table', you should probably
also use 'fread' for reading in the data.  Here is a possible approach of
reading the data into a list and then creating a single, large data.table:

-------
myDTs <- lapply(filelist, function(.file) {
  tmp1 <- fread(.file, sep=",")
  tmp2 <- melt(tmp1, id="FIPS")
  tmp2$year <- as.numeric(substr(tmp2$variable,2,5))
  tmp2$month <- as.numeric(substr(tmp2$variable,7,8))
  tmp2$day <- as.numeric(substr(tmp2$variable,10,11))
  tmp2  # return value
})

bigDT <- rbindlist(myDTs)  # rbind all the data.tables together

# then you should be able to do:

mean.temp <- bigDT[, list(temp.mean=lapply(.SD, mean),
       by=c("FIPS","year","month"), .SDcols=c("temp")]




Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, Jan 31, 2015 at 5:57 PM, Shouro Dasgupta <shouro at gmail.com> wrote:

> I have climate data for 20 years for US counties (FIPS) in csv format, each
> file represents one year of data. I have extracted the data and reshaped
> the yearly data files using melt();
>
> for (i in filelist) {
> >   tmp1 <- as.data.table(read.csv(i,header=T, sep=","))
> >   tmp2 <- melt(tmp1, id="FIPS")
> >   tmp2$year <- as.numeric(substr(tmp2$variable,2,5))
> >   tmp2$month <- as.numeric(substr(tmp2$variable,7,8))
> >   tmp2$day <- as.numeric(substr(tmp2$variable,10,11))
> > }
>
>
> Should I *rbind *in the loop here as I have the memory?
> So, the file (i) tmp2 looks like this:
>
> FIPS  temp year month  date
> > 1001 276.7936 2045 1 1/1/2045
> > 1003 276.7936 2045 1 1/1/2045
> > 1005 279.6452 2045 1 1/1/2045
> > 1007 276.7936 2045 1 1/1/2045
> > 1009 272.3748 2045 1 1/1/2045
> > 1011 279.6452 2045 1 1/1/2045
>
>
> My goal is calculate the mean by FIPS code by month/week, however, when I
> use the following code, I get a NULL value.
>
> mean.temp<- for (i in filelist) {tmp2[, list(temp.mean=lapply(.SD, mean),
> > by=c("FIPS","year","month"), .SDcols=c("temp")]}
>
>
> This works fine for individual years but with *for (i in filelist)*. What
> am I doing wrong? Can include a rbind/bindlist in the loop to make a big
> data.frame? Any suggestions will be highly appreciated. Thank you.
>
> Sincerely,
>
> Shouro
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From aebingham2 at gmail.com  Sun Feb  1 03:59:29 2015
From: aebingham2 at gmail.com (Allen Bingham)
Date: Sat, 31 Jan 2015 18:59:29 -0800
Subject: [R] pch size in a legend
In-Reply-To: <CAG6S0Ond5N3A7t1B4M2Cz+3SVkhLjtitEEDNi4esxN7snLYoRQ@mail.gmail.com>
References: <CAG6S0Ond5N3A7t1B4M2Cz+3SVkhLjtitEEDNi4esxN7snLYoRQ@mail.gmail.com>
Message-ID: <025301d03dcb$1917ccf0$4b4766d0$@gmail.com>

Could you provide an example of trying to use pt.cex that "does not do the
job"?

Using pt.cex works fine for me when I've used it (R version 3.1.2 both 32
bit and 64 bit).

Here's some dummy code that demonstrates that the symbol size changes w/o
changing the text size:

   plot(x=c(0,6),y=c(0,6),type="n")
   legend(x="bottomright",title="Legend 1, symbol 2 with
pt.cex=1.25",legend=c("Item 1","Item
2"),pch=c(1,1),pt.cex=c(1,1.25),col=c('black','blue'))
   legend(x="topleft",title="Legend 2, symbol 2 with
pt.cex=1.75",legend=c("Item 1","Item
2"),pch=c(1,1),pt.cex=c(1,1.75),col=c('black','blue'))

see if that works for you?


______________________________________
Allen Bingham
Bingham Statistical Consulting

aebingham2 at gmail.com


-----Original Message-----
From: Ahmed Attia [mailto:ahmedatia80 at gmail.com] 
Sent: Friday, January 30, 2015 1:50 PM
To: r-help
Subject: [R] pch size in a legend

Hi R users,

I would like to adjust the pch size in a legend without changing the text
size, pt.cex does not do the job. R 2.15.2 32 bit.

legend(0,2100, legend=c("2009","2010","2012","2013","2014"),
col = 1,cex=1,lty=NA,pch=c(1,2,6,7,8),lwd=2,bty="n")

Thanks


Ahmed Attia, Ph.D.
Agronomist & Soil Scientist

Post-Doc Research Associate
Texas A&M AgriLife Research-Vernon
ahmed.attia at ag.tamu.edu
Cell phone: 001-979-248-5215


From shouro at gmail.com  Sun Feb  1 10:14:10 2015
From: shouro at gmail.com (Shouro Dasgupta)
Date: Sun, 1 Feb 2015 10:14:10 +0100
Subject: [R] Melt and Rbind/Rbindlist
In-Reply-To: <CAAxdm-6DUOimQYaGUyAAqsM4frEwmbbK9Nartkf1Zr16P10UBA@mail.gmail.com>
References: <CAMx+UYe7Bx+p6evVh7iNqZnL92FZuvVWfT9zBSeC9coQZV4kVQ@mail.gmail.com>
	<CAAxdm-6DUOimQYaGUyAAqsM4frEwmbbK9Nartkf1Zr16P10UBA@mail.gmail.com>
Message-ID: <CAMx+UYfkUxTZx8Lt9PHcFgk017MUrxY6FtJQEhr+4ORJ_U9fEA@mail.gmail.com>

Hello Mr. Holtman,

Thank you very much for your reply and suggestion. This is what each Year's
data looks like;

tmp1 <- structure(list(FIPS = c(1001L, 1003L, 1005L), X2026.01.01.1 =
> c(285.5533142,
>   285.5533142, 286.2481079), X2026.01.01.2 = c(283.4977112, 283.4977112,
>   285.0860291), X2026.01.01.3 = c(281.9733887, 281.9733887, 284.1548767
>   ), X2026.01.01.4 = c(280.0234985, 280.0234985, 282.6075745),
>       X2026.01.01.5 = c(278.7125854, 278.7125854, 281.2553711),
>       X2026.01.01.6 = c(278.5204773, 278.5204773, 280.6148071)), .Names =
> c("FIPS",
>   "X2026.01.01.1", "X2026.01.01.2", "X2026.01.01.3", "X2026.01.01.4",
>   "X2026.01.01.5", "X2026.01.01.6"), class = "data.frame", row.names =
> c(NA,
>   -3L))


The data is in 3-hour blocks for every day by US FIPS code from 2026-2045,
each year's data is in a difference csv. My goal is to to compute max, min,
and mean by week and month. I used the following code to assign week
numbers to the observations;

nweek <- function(x, format="%Y-%m-%d", origin){
>     if(missing(origin)){
>         as.integer(format(strptime(x, format=format), "%W"))
>     }else{
>         x <- as.Date(x, format=format)
>         o <- as.Date(origin, format=format)
>         w <- as.integer(format(strptime(x, format=format), "%w"))
>         2 + as.integer(x - o - w) %/% 7
>     }
> }
>

 Then the following;

for (i in filelist) {
> nweek(tmp2$date)
> }
> for (i in filelist) {
> nweek(dates, origin="2026-01-01")
> }
> for (i in filelist) {
> wkn<-nweek(tmp2$date)
> }


Is this efficient? Thank you so much again. I really appreciate it.

Sincerely,

Shouro

On Sun, Feb 1, 2015 at 1:22 AM, jim holtman <jholtman at gmail.com> wrote:

> It would have been nice if you had at least supplied a subset (~10 lines)
> from a couple of files so we could see what the data looks like and test
> out any solution. Since you are using 'data.table', you should probably
> also use 'fread' for reading in the data.  Here is a possible approach of
> reading the data into a list and then creating a single, large data.table:
>
> -------
> myDTs <- lapply(filelist, function(.file) {
>   tmp1 <- fread(.file, sep=",")
>   tmp2 <- melt(tmp1, id="FIPS")
>   tmp2$year <- as.numeric(substr(tmp2$variable,2,5))
>   tmp2$month <- as.numeric(substr(tmp2$variable,7,8))
>   tmp2$day <- as.numeric(substr(tmp2$variable,10,11))
>   tmp2  # return value
> })
>
> bigDT <- rbindlist(myDTs)  # rbind all the data.tables together
>
> # then you should be able to do:
>
> mean.temp <- bigDT[, list(temp.mean=lapply(.SD, mean),
>        by=c("FIPS","year","month"), .SDcols=c("temp")]
>
>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Sat, Jan 31, 2015 at 5:57 PM, Shouro Dasgupta <shouro at gmail.com> wrote:
>
>> I have climate data for 20 years for US counties (FIPS) in csv format,
>> each
>> file represents one year of data. I have extracted the data and reshaped
>> the yearly data files using melt();
>>
>> for (i in filelist) {
>> >   tmp1 <- as.data.table(read.csv(i,header=T, sep=","))
>> >   tmp2 <- melt(tmp1, id="FIPS")
>> >   tmp2$year <- as.numeric(substr(tmp2$variable,2,5))
>> >   tmp2$month <- as.numeric(substr(tmp2$variable,7,8))
>> >   tmp2$day <- as.numeric(substr(tmp2$variable,10,11))
>> > }
>>
>>
>> Should I *rbind *in the loop here as I have the memory?
>> So, the file (i) tmp2 looks like this:
>>
>> FIPS  temp year month  date
>> > 1001 276.7936 2045 1 1/1/2045
>> > 1003 276.7936 2045 1 1/1/2045
>> > 1005 279.6452 2045 1 1/1/2045
>> > 1007 276.7936 2045 1 1/1/2045
>> > 1009 272.3748 2045 1 1/1/2045
>> > 1011 279.6452 2045 1 1/1/2045
>>
>>
>> My goal is calculate the mean by FIPS code by month/week, however, when I
>> use the following code, I get a NULL value.
>>
>> mean.temp<- for (i in filelist) {tmp2[, list(temp.mean=lapply(.SD, mean),
>> > by=c("FIPS","year","month"), .SDcols=c("temp")]}
>>
>>
>> This works fine for individual years but with *for (i in filelist)*. What
>> am I doing wrong? Can include a rbind/bindlist in the loop to make a big
>> data.frame? Any suggestions will be highly appreciated. Thank you.
>>
>> Sincerely,
>>
>> Shouro
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Feb  1 12:40:02 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 02 Feb 2015 00:40:02 +1300
Subject: [R] aov and Error function
In-Reply-To: <54CC8FA7020000CB0012199E@smtp.medicine.umaryland.edu>
References: <54CBD676.8060203@gmail.com>
	<54CBDCBC.8060803@gmail.com>	<6EAD7151-F375-4090-A660-96F19B5A9E0B@gmail.com>
	<54CC8FA7020000CB0012199E@smtp.medicine.umaryland.edu>
Message-ID: <54CE1092.6080007@auckland.ac.nz>

On 01/02/15 02:17, John Sorkin wrote:
> I am trying to understand the Error function and its use in ANOVA. In
> particular I want to understand the difference between two models
> that differ only with respect to the Error statement:
>
>
> aovsubj <- aov(value~group+time+Error(subject),data=dataRMANOVA)
> and
> aovsubjgroup <- aov(value~group+time+Error(subject/group),data=dataRMANOVA)
>
> You will note that in my data I have two subject identifiers,
> subject and subject2. I am also trying to trying to understand how I
> should identify subjects, within group (i.e. intervention vs.
> control) or within time (0=baseline, 1=post)

Since no-one else seems to have answered you let me point out that your 
first formulation treats subject 1 in the "int" group as being the same
as subject 1 in the "cont" group, and similarly for subject 2 and so on.

The second formulation (subject nested within group) treats subject 1 in 
the "int" group as being *different* from subject 1 in the "cont" group.

If you were using subject2 instead of subject there would (I *think*) be 
no difference between the two formulations.

HTH

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From heyao at nibs.ac.cn  Sun Feb  1 13:53:23 2015
From: heyao at nibs.ac.cn (Yao He)
Date: Sun, 1 Feb 2015 20:53:23 +0800
Subject: [R] Transform a list of multiple to a data.frame which I want
Message-ID: <099CE2DB-7DBE-4DCF-AC21-5513148FD193@nibs.ac.cn>

Dear all:

	I have a list like that,which is a standard str_locate_all() function (stringr package) output:
$K
   start end
$GSEGTCSCSSK
   start end
[1,]     6   6
[2,]     8   8
$GFSTTCPAHVDDLTPEQVLDGDVNELMDVVLHHVPEAK
   start end
[1,]     6   6
$LVECIGQELIFLLPNK
   start end
[1,]     4   4
$NFK
   start end
$HR
   start end
$AYASLFR
   start end

I want to transform this list like that:

ID   start.1  start.2 
K   NA	NA
GSEGTCSCSSK 6 8
GFSTTCPAHVDDLTPEQVLDGDVNELMDVVLHHVPEAK 6 NA
LVECIGQELIFLLPNK 4 NA
NFK NA NA
HR NA NA
AYASLFR NA NA

I have already tried to use t() , lapply() but I think it is hard to handle the NA value and different rows in every matrix 

Thanks in advance


From smartpink111 at yahoo.com  Sun Feb  1 15:55:54 2015
From: smartpink111 at yahoo.com (arun)
Date: Sun, 1 Feb 2015 14:55:54 +0000 (UTC)
Subject: [R] Is there a way to map data from Binary format to Numerical
 numbers?
Message-ID: <1844064480.476456.1422802554771.JavaMail.yahoo@mail.yahoo.com>

Try

indx <- which(!!mat, arr.ind=TRUE)
v1 <-unname(sapply(split(indx[,2], indx[,1]),toString))

cat(paste(v1, collapse="\n"), sep="\n")
1, 2, 3, 6, 7, 8, 9
1, 2, 3, 6, 8, 9
1, 3, 4, 6, 7, 8, 9
1, 8
1, 3, 6, 7, 8, 9
1, 3, 4, 6, 8, 9
1, 3, 5, 9


A.K.

   



Hi,
Is there a way to map data from Binary format to Numerical numbers?

example:
I have text files, where each record consists of several items (9 items)
1, means item appear
0, means item absent

1,1,1,0,0,1,1,1,1
1,1,1,0,0,1,0,1,1
1,0,1,1,0,1,1,1,1
1,0,0,0,0,0,0,1,0
1,0,1,0,0,1,1,1,1
1,0,1,1,0,1,0,1,1
1,0,1,0,1,0,0,0,1


I want transform my data to numerical numbers in ascending order, such that when items is absent, i didn't print it, but keep increase the counter. for example, the above binary format will be: ,
1,2,3,6,7,8,9
1,2,3,6,8,9
1,3,4,6,7,8,9
1,8,
1,3,6,7,8,9
1,3,4,5,7,8
1,3,5,9


From e283851 at trbvm.com  Sun Feb  1 17:26:19 2015
From: e283851 at trbvm.com (JvanDyne)
Date: Sun, 1 Feb 2015 08:26:19 -0800 (PST)
Subject: [R] Regression Overdispersion?
Message-ID: <1422807979944-4702611.post@n4.nabble.com>

I am trying to use Poisson regression to model count data with four
explanatory variables: ratio, ordinal, nominal and dichotomous ? x1, x2, x3
and x4. After playing around with the input for a bit, I have formed ? what
I believe is ? a series of badly fitting models probably due to
overdispersion [1] - e.g. model=glm(y ~ x1 +
x2,family=poisson(link=log),data=data1) - and I was looking for some general
guidance/direction/help/approach to correcting this in R. 

[1] ? I believe this as a. it?s, as I?m sure you?re aware, a possible reason
for poor model fits; b.the following:

tapply(data1$y,data$x2,function(x)c(mean=mean(x),variance=var(x)))

seems to suggest that, whilst variance does appear to be some function of
the mean, there is a consistently large difference between the two 





--
View this message in context: http://r.789695.n4.nabble.com/Regression-Overdispersion-tp4702611.html
Sent from the R help mailing list archive at Nabble.com.


From john.kalb at gmail.com  Sun Feb  1 17:56:00 2015
From: john.kalb at gmail.com (John Kalb)
Date: Sun, 1 Feb 2015 11:56:00 -0500
Subject: [R] How to enable https for R 3.1.2 on windows 8.1
Message-ID: <CAC1VXC6de=3XzNOBmO8gm5CYr65X9NXw=+BpT9kTuxrN-Mm=uw@mail.gmail.com>

I run the code below successfully on Mac and Ubuntu successfully.
When I run on Windows, I get the results shown.  How do I get the code
to work on Windows? I've googled extensively with no success. Thanks
in advance.

require(twitteR)

Loading required package: twitteR
Loading required package: ROAuth
Loading required package: RCurl
Loading required package: bitops
Loading required package: rjson
> cred <- OAuthFactory $ new( consumerKey = my.key, consumerSecret = my.secret, requestURL =' https:// api.twitter.com/ oauth/ request_token', accessURL =' https:// api.twitter.com/ oauth/ access_token', authURL =' https:// api.twitter.com/ oauth/ authorize')
> cred$handshake(cainfo = "C:/users/john/documents/twitter/cacert.pem")
Error in function (type, msg, asError = TRUE)  :
  Protocol " https" not supported or disabled in libcurl

	[[alternative HTML version deleted]]


From dnbarron at gmail.com  Sun Feb  1 19:55:54 2015
From: dnbarron at gmail.com (David Barron)
Date: Sun, 1 Feb 2015 18:55:54 +0000
Subject: [R] Regression Overdispersion?
In-Reply-To: <1422807979944-4702611.post@n4.nabble.com>
References: <1422807979944-4702611.post@n4.nabble.com>
Message-ID: <CAHuze_LcpZV-qw=rCSfGuGqkCcJP0=mhK2_ihBoBB15Jb_Li=w@mail.gmail.com>

There are two straightforward ways of modelling overdispersion:

1) Use glm as in your example but specify family=quasipoisson.
2) Use glm.nb in the MASS package, which fits a negative binomial model.



On 1 February 2015 at 16:26, JvanDyne <e283851 at trbvm.com> wrote:
> I am trying to use Poisson regression to model count data with four
> explanatory variables: ratio, ordinal, nominal and dichotomous ? x1, x2, x3
> and x4. After playing around with the input for a bit, I have formed ? what
> I believe is ? a series of badly fitting models probably due to
> overdispersion [1] - e.g. model=glm(y ~ x1 +
> x2,family=poisson(link=log),data=data1) - and I was looking for some general
> guidance/direction/help/approach to correcting this in R.
>
> [1] ? I believe this as a. it?s, as I?m sure you?re aware, a possible reason
> for poor model fits; b.the following:
>
> tapply(data1$y,data$x2,function(x)c(mean=mean(x),variance=var(x)))
>
> seems to suggest that, whilst variance does appear to be some function of
> the mean, there is a consistently large difference between the two
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Regression-Overdispersion-tp4702611.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Feb  1 19:58:23 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 01 Feb 2015 10:58:23 -0800
Subject: [R] How to enable https for R 3.1.2 on windows 8.1
In-Reply-To: <CAC1VXC6de=3XzNOBmO8gm5CYr65X9NXw=+BpT9kTuxrN-Mm=uw@mail.gmail.com>
References: <CAC1VXC6de=3XzNOBmO8gm5CYr65X9NXw=+BpT9kTuxrN-Mm=uw@mail.gmail.com>
Message-ID: <91C59476-A35C-48F9-A679-DB782CB96F11@dcn.davis.CA.us>

Honestly? Did you try "rcurl https windows" (without the quotes)?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 1, 2015 8:56:00 AM PST, John Kalb <john.kalb at gmail.com> wrote:
>I run the code below successfully on Mac and Ubuntu successfully.
>When I run on Windows, I get the results shown.  How do I get the code
>to work on Windows? I've googled extensively with no success. Thanks
>in advance.
>
>require(twitteR)
>
>Loading required package: twitteR
>Loading required package: ROAuth
>Loading required package: RCurl
>Loading required package: bitops
>Loading required package: rjson
>> cred <- OAuthFactory $ new( consumerKey = my.key, consumerSecret =
>my.secret, requestURL =' https:// api.twitter.com/ oauth/
>request_token', accessURL =' https:// api.twitter.com/ oauth/
>access_token', authURL =' https:// api.twitter.com/ oauth/ authorize')
>> cred$handshake(cainfo = "C:/users/john/documents/twitter/cacert.pem")
>Error in function (type, msg, asError = TRUE)  :
>  Protocol " https" not supported or disabled in libcurl
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ragia11 at hotmail.com  Sun Feb  1 21:05:47 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Sun, 1 Feb 2015 22:05:47 +0200
Subject: [R] save program results and graphs to one  file
Message-ID: <DUB125-W74A585A523EF697C41BF54B33F0@phx.gbl>


Dear group,

I have many plots and numeric results in my R program,  kindly how can I save them all sequently on one file.
thanks in advance
RAI
 		 	   		  
	[[alternative HTML version deleted]]


From rune.haubo at gmail.com  Sun Feb  1 21:23:36 2015
From: rune.haubo at gmail.com (Rune Haubo)
Date: Sun, 1 Feb 2015 21:23:36 +0100
Subject: [R] Regression Overdispersion?
In-Reply-To: <CAHuze_LcpZV-qw=rCSfGuGqkCcJP0=mhK2_ihBoBB15Jb_Li=w@mail.gmail.com>
References: <1422807979944-4702611.post@n4.nabble.com>
	<CAHuze_LcpZV-qw=rCSfGuGqkCcJP0=mhK2_ihBoBB15Jb_Li=w@mail.gmail.com>
Message-ID: <CAG_uk93V7k-6Bd+1jzA7oQKzokcZm7BddE9pq3dMwZGWOP03dQ@mail.gmail.com>

A third, and often preferable, way is to add an observation-level random effect:

library(lme4)
data1$obs <- factor(seq_len(nrow(data1)))
model <- glmer(y ~ x1 + x2 + (1 | obs), family=poisson(link=log), data=data1)

See http://glmm.wikidot.com/faq and search for "individual-level
random effects".

Cheers,
Rune

On 1 February 2015 at 19:55, David Barron <dnbarron at gmail.com> wrote:
> There are two straightforward ways of modelling overdispersion:
>
> 1) Use glm as in your example but specify family=quasipoisson.
> 2) Use glm.nb in the MASS package, which fits a negative binomial model.
>
>
>
> On 1 February 2015 at 16:26, JvanDyne <e283851 at trbvm.com> wrote:
>> I am trying to use Poisson regression to model count data with four
>> explanatory variables: ratio, ordinal, nominal and dichotomous ? x1, x2, x3
>> and x4. After playing around with the input for a bit, I have formed ? what
>> I believe is ? a series of badly fitting models probably due to
>> overdispersion [1] - e.g. model=glm(y ~ x1 +
>> x2,family=poisson(link=log),data=data1) - and I was looking for some general
>> guidance/direction/help/approach to correcting this in R.
>>
>> [1] ? I believe this as a. it?s, as I?m sure you?re aware, a possible reason
>> for poor model fits; b.the following:
>>
>> tapply(data1$y,data$x2,function(x)c(mean=mean(x),variance=var(x)))
>>
>> seems to suggest that, whilst variance does appear to be some function of
>> the mean, there is a consistently large difference between the two
>>
>>
>>
>>
>>
>> --
>> View this message in context: http://r.789695.n4.nabble.com/Regression-Overdispersion-tp4702611.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Feb  1 21:26:38 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 01 Feb 2015 12:26:38 -0800
Subject: [R] save program results and graphs to one  file
In-Reply-To: <DUB125-W74A585A523EF697C41BF54B33F0@phx.gbl>
References: <DUB125-W74A585A523EF697C41BF54B33F0@phx.gbl>
Message-ID: <D07940B7-41AB-4901-A6BE-D1AAD7439631@dcn.davis.CA.us>

In general this depends what you plan to do with those results. I suspect you are looking for something like knitr with rmarkdown (.Rmd files to create HTML or Word) or LaTeX (.Rnw files to create PDF). 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 1, 2015 12:05:47 PM PST, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
>
>Dear group,
>
>I have many plots and numeric results in my R program,  kindly how can
>I save them all sequently on one file.
>thanks in advance
>RAI
> 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Feb  1 22:33:51 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 1 Feb 2015 13:33:51 -0800
Subject: [R] Regression Overdispersion?
In-Reply-To: <1422807979944-4702611.post@n4.nabble.com>
References: <1422807979944-4702611.post@n4.nabble.com>
Message-ID: <69988781-7BB9-4603-83CB-20A756EB53F3@comcast.net>


On Feb 1, 2015, at 8:26 AM, JvanDyne wrote:

> I am trying to use Poisson regression to model count data with four
> explanatory variables: ratio, ordinal, nominal and dichotomous ? x1, x2, x3
> and x4. After playing around with the input for a bit, I have formed ? what
> I believe is ? a series of badly fitting models probably due to
> overdispersion [1] - e.g. model=glm(y ~ x1 +
> x2,family=poisson(link=log),data=data1) - and I was looking for some general
> guidance/direction/help/approach to correcting this in R. 
> 
> [1] ? I believe this as a. it?s, as I?m sure you?re aware, a possible reason
> for poor model fits; b.the following:
> 
> tapply(data1$y,data$x2,function(x)c(mean=mean(x),variance=var(x)))
> 
> seems to suggest that, whilst variance does appear to be some function of
> the mean, there is a consistently large difference between the two 
> 

This is possibly an interesting question, but at the moment it is both off-topic on R and probably deserving of a book chapter as an answer. There are simply no specifics. One place where it would be on-topic and if tightened up with a specific example might prompt interesting and useful answers from a knowledgeable audience would be http://CrossValidated.com .


> 
> Sent from the R help mailing list archive at Nabble.com.

The Nabble "archive" of R-help is neither an archive of any sort since they arbitraily delte postings and not is most certainly not "the" Rhelp archive.

Maybe if I unquote this four line message, then Nabble users will see it, although usually it get s trimmed:

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 

David Winsemius
Alameda, CA, USA


From gunter.berton at gene.com  Sun Feb  1 23:53:36 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 1 Feb 2015 14:53:36 -0800
Subject: [R] save program results and graphs to one file
In-Reply-To: <D07940B7-41AB-4901-A6BE-D1AAD7439631@dcn.davis.CA.us>
References: <DUB125-W74A585A523EF697C41BF54B33F0@phx.gbl>
	<D07940B7-41AB-4901-A6BE-D1AAD7439631@dcn.davis.CA.us>
Message-ID: <CACk-te2wTVx1FXQA=tXFpsxeVM_=zLZ33+1S5=sg0Mhqcj_e5A@mail.gmail.com>

But in addition to what Jeff noted, see ?save and ?save.image

(noting that that the resulting .Rdata file can only be read by R).

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Feb 1, 2015 at 12:26 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> In general this depends what you plan to do with those results. I suspect you are looking for something like knitr with rmarkdown (.Rmd files to create HTML or Word) or LaTeX (.Rnw files to create PDF).
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On February 1, 2015 12:05:47 PM PST, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
>>
>>Dear group,
>>
>>I have many plots and numeric results in my R program,  kindly how can
>>I save them all sequently on one file.
>>thanks in advance
>>RAI
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mbmiller+l at gmail.com  Mon Feb  2 00:09:38 2015
From: mbmiller+l at gmail.com (Mike Miller)
Date: Sun, 1 Feb 2015 17:09:38 -0600
Subject: [R] the less-than-minus gotcha
Message-ID: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>

I've got to remember to use more spaces.  Here's the basic problem:

These are the same:

v< 1
v<1

But these are extremely different:

v< -1
v<-1

This mistake can get you even inside of a function call like this:

> v <- -2:2
> which( v<1 )
[1] 1 2 3
> which( v<-1 )  # oops, I meant v< -1 not v<-1 a HUGE mistake!
Error in which(v <- 1) : argument to 'which' is not logical
> v
[1] 1

It throws an error but not because I just destroyed my data.  R has no way 
of knowing that I didn't intend to overwrite the vector.

This was how it got me:

which( frame$var>4 )   # no problem

which( frame$var<-4 )  # huge problem: frame$var is destroyed

Too late now:  The data in frame$var were all overwritten with 4s.  So the 
data are lost and might not be recoverable.

Maybe the tactic that will save me in the future is to remember to always 
use plenty of spaces:

which( frame$var > 4 )

which( frame$var < -4 )

That also makes the code easier to read.  In a script, I probably would 
have done that, but in an interactive session I can be lazy.

It seems that there are a lot of "R gotcha" pages on the web but quite a 
few of the examples show R behaving exactly like I would want and expect 
(e.g., of course NA + 5 returns NA)...

https://github.com/mikelove/r-gotchas/blob/master/README.md
http://stackoverflow.com/questions/1535021/whats-the-biggest-r-gotcha-youve-run-across
http://www.burns-stat.com/pages/Tutor/R_inferno.pdf
http://biostat.mc.vanderbilt.edu/wiki/Main/LinuxWorkshopRProgramingTipsAndGotchas
http://tim-smith.us/arrgh/

I didn't happen to see my example on any list, but I didn't read them 
thoroughly, so it's probably there.

Mike


From hb at biostat.ucsf.edu  Mon Feb  2 00:51:56 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 1 Feb 2015 15:51:56 -0800
Subject: [R] save program results and graphs to one file
In-Reply-To: <CACk-te2wTVx1FXQA=tXFpsxeVM_=zLZ33+1S5=sg0Mhqcj_e5A@mail.gmail.com>
References: <DUB125-W74A585A523EF697C41BF54B33F0@phx.gbl>
	<D07940B7-41AB-4901-A6BE-D1AAD7439631@dcn.davis.CA.us>
	<CACk-te2wTVx1FXQA=tXFpsxeVM_=zLZ33+1S5=sg0Mhqcj_e5A@mail.gmail.com>
Message-ID: <CAFDcVCQjigDbyfedBOoF7UOBBEqL+N2c7nYqNW7TBoMbUVKoOQ@mail.gmail.com>

If you're happy with outputting to a multi-page PDF, then you can just
set the default graphics device to pdf(), i.e.

> options(device=pdf)

and the start plotting:

> plot(1:10, col=0)
> plot(10:1, col=1)
> plot((1:10)^2, col=2)
> plot((10:1)^2, col=3)

and at the end make sure to close the device:

> dev.off()

(The PDF device was automatically opened with the first plot call -
all other figures are appended to this one.)


This is what happens implicitly when you run a script in a
non-interactive session, e.g.

    Rscript -f myscript.R

That is, in that case you don't have to set the 'device' options (it's
done for you by default) and you don't have to close it at the end,
because that is also done for you by default.

/Henrik



On Sun, Feb 1, 2015 at 2:53 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> But in addition to what Jeff noted, see ?save and ?save.image
>
> (noting that that the resulting .Rdata file can only be read by R).
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sun, Feb 1, 2015 at 12:26 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> In general this depends what you plan to do with those results. I suspect you are looking for something like knitr with rmarkdown (.Rmd files to create HTML or Word) or LaTeX (.Rnw files to create PDF).
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 1, 2015 12:05:47 PM PST, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
>>>
>>>Dear group,
>>>
>>>I have many plots and numeric results in my R program,  kindly how can
>>>I save them all sequently on one file.
>>>thanks in advance
>>>RAI
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Mon Feb  2 02:07:23 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 2 Feb 2015 01:07:23 +0000
Subject: [R] the less-than-minus gotcha
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
Message-ID: <loom.20150202T020546-447@post.gmane.org>

Mike Miller <mbmiller+l <at> gmail.com> writes:

> 
> I've got to remember to use more spaces.  Here's the basic problem:
> 
> These are the same:
> 
> v< 1
> v<1
> 
> But these are extremely different:
> 
> v< -1
> v<-1
> 

This is indeed documented, in passing, in one of the pages you listed:

http://tim-smith.us/arrgh/syntax.html

Whitespace is meaningless, unless it isn't. Some parsing ambiguities 
are resolved by considering whitespace around operators. See and
despair: x<-y (assignment) is parsed differently than x < -y (comparison)!


From steve.taylor at aut.ac.nz  Mon Feb  2 02:26:36 2015
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Mon, 2 Feb 2015 01:26:36 +0000
Subject: [R] the less-than-minus gotcha
In-Reply-To: <loom.20150202T020546-447@post.gmane.org>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
Message-ID: <CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>

All the more reason to use = instead of <-


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Monday, 2 February 2015 2:07p
To: r-help at stat.math.ethz.ch
Subject: Re: [R] the less-than-minus gotcha

Mike Miller <mbmiller+l <at> gmail.com> writes:

> 
> I've got to remember to use more spaces.  Here's the basic problem:
> 
> These are the same:
> 
> v< 1
> v<1
> 
> But these are extremely different:
> 
> v< -1
> v<-1
> 

This is indeed documented, in passing, in one of the pages you listed:

http://tim-smith.us/arrgh/syntax.html

Whitespace is meaningless, unless it isn't. Some parsing ambiguities 
are resolved by considering whitespace around operators. See and
despair: x<-y (assignment) is parsed differently than x < -y (comparison)!

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From kevin.thorpe at utoronto.ca  Mon Feb  2 02:38:16 2015
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Sun, 1 Feb 2015 20:38:16 -0500
Subject: [R] the less-than-minus gotcha
In-Reply-To: <CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
Message-ID: <54CED508.8020904@utoronto.ca>

Using = has it's problems too.

For example,

print(fit <- lm(...))

Assigns the result of the lm call to fit and prints the results. This is 
quite a useful trick actually.

print(fit = lm(...))

Throws an error.

Moral of story, computers do what you tell them, not what you meant.

Kevin

On 02/01/2015 08:26 PM, Steve Taylor wrote:
> All the more reason to use = instead of <-
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: Monday, 2 February 2015 2:07p
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] the less-than-minus gotcha
>
> Mike Miller <mbmiller+l <at> gmail.com> writes:
>
>>
>> I've got to remember to use more spaces.  Here's the basic problem:
>>
>> These are the same:
>>
>> v< 1
>> v<1
>>
>> But these are extremely different:
>>
>> v< -1
>> v<-1
>>
>
> This is indeed documented, in passing, in one of the pages you listed:
>
> http://tim-smith.us/arrgh/syntax.html
>
> Whitespace is meaningless, unless it isn't. Some parsing ambiguities
> are resolved by considering whitespace around operators. See and
> despair: x<-y (assignment) is parsed differently than x < -y (comparison)!
>


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From p_connolly at slingshot.co.nz  Mon Feb  2 04:26:38 2015
From: p_connolly at slingshot.co.nz (p_connolly)
Date: Mon, 02 Feb 2015 16:26:38 +1300
Subject: [R] Boundaries and deldir
Message-ID: <b7eb2bec9297830b473b3126207ef7d2@slingshot.co.nz>

Just what is meant by dummy points as referred to by the help for the
deldir() function?  I understood they indicated the boundary beyond
which triangulation would cease.

I thought I would need the x/y elements (as described in the help file
at the end of the description of the use of the dpl argument) to
describe ad hoc dummy points as way to define a polygon or two as a
boundary.  However, it gives this error:

Error in xd[-drop] : only 0's may be mixed with negative subscripts

Something internal is doing the negative subscripting.
I tried ndx/ndy instead of x/y but it evidently refers only to a
rectangle so not what I need.

Am I barking up the wrong tree altogether?  Is the boundary defined
somewhere else entirely?  I need to get that clear before I am able to 
provide
useful example code.

TIA
Patrick


From petr.pikal at precheza.cz  Mon Feb  2 08:12:01 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 2 Feb 2015 07:12:01 +0000
Subject: [R] Repeat elements of character vector
In-Reply-To: <1609134.DqXR3223AV@ws-ism-knuth.fm.uit.no>
References: <1609134.DqXR3223AV@ws-ism-knuth.fm.uit.no>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1D8AA@SRVEXCHMBX.precheza.cz>

Hi

Just a warning. Do you intend it for naming some objects. If yes do not do it, use list instead. If not, just discard my comment.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Knut
> Hansen
> Sent: Friday, January 30, 2015 2:34 PM
> To: r-help at r-project.org
> Subject: [R] Repeat elements of character vector
>
> I have a vector of several character elements:
> v1 <- c("a", "b", "c")
>
> I want each of these elements to be repeated n times and the number of
> the repetition added as part of the element text, hence rep() will not
> work. For
> n=3 the result would be:
> v2 <- c("a_1", "a_2", "a_3", "b_1", "b_2", "b_3", "c_1", "c_2", "c_3")
>
> Knut Hansen
> knut.hansen at uit.no
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From drjimlemon at gmail.com  Mon Feb  2 10:24:58 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 2 Feb 2015 20:24:58 +1100
Subject: [R] Transform a list of multiple to a data.frame which I want
In-Reply-To: <099CE2DB-7DBE-4DCF-AC21-5513148FD193@nibs.ac.cn>
References: <099CE2DB-7DBE-4DCF-AC21-5513148FD193@nibs.ac.cn>
Message-ID: <CA+8X3fXYkhe_AyULmWzSGsEM4w3xQ6NhaMTaDUhFhi-VOg7bdw@mail.gmail.com>

Hi Yao,
Messy, but this is the closest I can get:

yhlist<-list(K=matrix(0,ncol=2,nrow=0),
 GSEGTCSCSSK=matrix(c(6,8),nrow=2,ncol=2),
 GFSTTCPAHVDDLTPEQVLDGDVNELMDVVLHHVPEAK=matrix(6,ncol=2,nrow=1),
 LVECIGQELIFLLPNK=matrix(6,ncol=2,nrow=1),
 NFK=matrix(0,ncol=2,nrow=0),
 HR=matrix(0,ncol=2,nrow=0),
 AYASLFR=matrix(0,ncol=2,nrow=0))

colnames(yhlist$K)<-c("start","end")
colnames(yhlist$GSEGTCSCSSK)<-c("start","end")
colnames(yhlist$GFSTTCPAHVDDLTPEQVLDGDVNELMDVVLHHVPEAK)<-c("start","end")
colnames(yhlist$LVECIGQELIFLLPNK)<-c("start","end")
colnames(yhlist$NFK)<-c("start","end")
colnames(yhlist$HR)<-c("start","end")
colnames(yhlist$AYASLFR)<-c("start","end")


crunch<-function(x) {
 start.1<-ifelse(dim(x)[1],x[1,1],NA)
 start.2<-ifelse(dim(x)[1]>1,x[2,1],NA)
 return(list(start.1,start.2))
}

crunchlist<-sapply(yhlist,crunch,simplify=TRUE)

ID<-colnames(crunchlist)
colnames(crunchlist)<-NULL

data.frame(ID,
 start.1=unlist(crunchlist[1,]),
 start.2=unlist(crunchlist[2,]))

Jim


On Sun, Feb 1, 2015 at 11:53 PM, Yao He <heyao at nibs.ac.cn> wrote:
> Dear all:
>
>         I have a list like that,which is a standard str_locate_all() function (stringr package) output:
> $K
>    start end
> $GSEGTCSCSSK
>    start end
> [1,]     6   6
> [2,]     8   8
> $GFSTTCPAHVDDLTPEQVLDGDVNELMDVVLHHVPEAK
>    start end
> [1,]     6   6
> $LVECIGQELIFLLPNK
>    start end
> [1,]     4   4
> $NFK
>    start end
> $HR
>    start end
> $AYASLFR
>    start end
>
> I want to transform this list like that:
>
> ID   start.1  start.2
> K   NA  NA
> GSEGTCSCSSK 6 8
> GFSTTCPAHVDDLTPEQVLDGDVNELMDVVLHHVPEAK 6 NA
> LVECIGQELIFLLPNK 4 NA
> NFK NA NA
> HR NA NA
> AYASLFR NA NA
>
> I have already tried to use t() , lapply() but I think it is hard to handle the NA value and different rows in every matrix
>
> Thanks in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Feb  2 10:49:47 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 02 Feb 2015 04:49:47 -0500
Subject: [R] Boundaries and deldir
In-Reply-To: <b7eb2bec9297830b473b3126207ef7d2@slingshot.co.nz>
References: <b7eb2bec9297830b473b3126207ef7d2@slingshot.co.nz>
Message-ID: <54CF483B.5060406@gmail.com>

On 01/02/2015 10:26 PM, p_connolly wrote:
> Just what is meant by dummy points as referred to by the help for the
> deldir() function?  I understood they indicated the boundary beyond
> which triangulation would cease.

You should say what package you're asking about.  deldir() is not a base
R function.

Duncan Murdoch

> 
> I thought I would need the x/y elements (as described in the help file
> at the end of the description of the use of the dpl argument) to
> describe ad hoc dummy points as way to define a polygon or two as a
> boundary.  However, it gives this error:
> 
> Error in xd[-drop] : only 0's may be mixed with negative subscripts
> 
> Something internal is doing the negative subscripting.
> I tried ndx/ndy instead of x/y but it evidently refers only to a
> rectangle so not what I need.
> 
> Am I barking up the wrong tree altogether?  Is the boundary defined
> somewhere else entirely?  I need to get that clear before I am able to 
> provide
> useful example code.
> 
> TIA
> Patrick
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Rangi-Vivek at hcl.com  Mon Feb  2 08:16:35 2015
From: Rangi-Vivek at hcl.com (Vivek Rangi)
Date: Mon, 2 Feb 2015 07:16:35 +0000
Subject: [R] Cross compiling R
Message-ID: <EA073E1BCBDF7C4DB9BAB257D1C1AC5353982FD6@NDA-HCLT-MBS03.hclt.corp.hcl.in>

Hi!

      I am cross compiling R-3.1.2 for Galileo board with the source code. I am able to configure R-3.1.2 without any errors with the following command :

./configure --host=i586-poky-linux-uclibc CC=i586-poky-linux-uclibc-gcc CXX=i586-poky-linux-uclibc-g++ F77=i586-poky-linux-uclibc-gfortran CPPFLAGS=-I/opt/clanton-tiny/1.4.2/sysroots/i586-poky-linux-uclibc/usr/include/ LDFLAGS="-L/opt/clanton-tiny/1.4.2/sysroots/i586-poky-linux-uclibc/usr/lib/ --sysroot=/opt/clanton-tiny/1.4.2/sysroots/i586-poky-linux-uclibc" --prefix=/home/vivek/Smart_Tracker/R/R-3.1.2/vivek --with-readline=no --with-x=no


But when I am cross compiling R, I am getting following error :

i586-poky-linux-uclibc-gcc -std=gnu99 -I../../../../include -DNDEBUG -I../../../include -I../../../../src/include -DHAVE_CONFIG_H -I../../../../src/main -I/opt/clanton-tiny/1.4.2/sysroots/i586-poky-linux-uclibc/usr/include/   -fvisibility=hidden -fpic  -O2 -pipe -g -feliminate-unused-debug-types  -c gramRd.c -o gramRd.o
i586-poky-linux-uclibc-gcc -std=gnu99 -shared -L/opt/clanton-tiny/1.4.2/sysroots/i586-poky-linux-uclibc/usr/lib/ --sysroot=/opt/clanton-tiny/1.4.2/sysroots/i586-poky-linux-uclibc -o tools.so text.o init.o Rmd5.o md5.o signals.o install.o getfmts.o http.o gramLatex.o gramRd.o
make[6]: Entering directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src/library/tools/src'
mkdir -p -- ../../../../library/tools/libs
make[6]: Leaving directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src/library/tools/src'
make[5]: Leaving directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src/library/tools/src'
make[4]: Leaving directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src/library/tools'
../../../bin/R: line 259: /home/vivek/Smart_Tracker/R/R-3.1.2/bin/exec/R: No such file or directory
make[3]: *** [all] Error 127
make[3]: Leaving directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src/library/tools'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src'
make: *** [R] Error 1


"/home/vivek/Smart_Tracker/R/R-3.1.2/bin/exec/R" exits in the system. It seems it generates the "R" executable for the Galileo board and also, it tries to run the executable to generate the base packages for R. Since the "R" executable (/home/vivek/Smart_Tracker/R/R-3.1.2/bin/exec/R) is not for x86 system but for Galileo board, it is not able to execute it and hence the error.  Can somebody guide me as how to cross compile R?

Regards,
Vivek


::DISCLAIMER::
----------------------------------------------------------------------------------------------------------------------------------------------------

The contents of this e-mail and any attachment(s) are confidential and intended for the named recipient(s) only.
E-mail transmission is not guaranteed to be secure or error-free as information could be intercepted, corrupted,
lost, destroyed, arrive late or incomplete, or may contain viruses in transmission. The e mail and its contents
(with or without referred errors) shall therefore not attach any liability on the originator or HCL or its affiliates.
Views or opinions, if any, presented in this email are solely those of the author and may not necessarily reflect the
views or opinions of HCL or its affiliates. Any form of reproduction, dissemination, copying, disclosure, modification,
distribution and / or publication of this message without the prior written consent of authorized representative of
HCL is strictly prohibited. If you have received this email in error please delete it and notify the sender immediately.
Before opening any email and/or attachments, please check them for viruses and other defects.

----------------------------------------------------------------------------------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Feb  2 09:30:31 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 2 Feb 2015 19:30:31 +1100
Subject: [R] save program results and graphs to one file
In-Reply-To: <CAFDcVCQjigDbyfedBOoF7UOBBEqL+N2c7nYqNW7TBoMbUVKoOQ@mail.gmail.com>
References: <DUB125-W74A585A523EF697C41BF54B33F0@phx.gbl>
	<D07940B7-41AB-4901-A6BE-D1AAD7439631@dcn.davis.CA.us>
	<CACk-te2wTVx1FXQA=tXFpsxeVM_=zLZ33+1S5=sg0Mhqcj_e5A@mail.gmail.com>
	<CAFDcVCQjigDbyfedBOoF7UOBBEqL+N2c7nYqNW7TBoMbUVKoOQ@mail.gmail.com>
Message-ID: <CA+8X3fX7paXVCFkaq5TBanOOvkG5wkifM8ywhcYx2h6M0YbPOw@mail.gmail.com>

Hi Ragia,
There are also the R2HTML and prettyR (see htmlize) packages that will
output an R session in HTML format.

Jim


On Mon, Feb 2, 2015 at 10:51 AM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> If you're happy with outputting to a multi-page PDF, then you can just
> set the default graphics device to pdf(), i.e.
>
>> options(device=pdf)
>
> and the start plotting:
>
>> plot(1:10, col=0)
>> plot(10:1, col=1)
>> plot((1:10)^2, col=2)
>> plot((10:1)^2, col=3)
>
> and at the end make sure to close the device:
>
>> dev.off()
>
> (The PDF device was automatically opened with the first plot call -
> all other figures are appended to this one.)
>
>
> This is what happens implicitly when you run a script in a
> non-interactive session, e.g.
>
>     Rscript -f myscript.R
>
> That is, in that case you don't have to set the 'device' options (it's
> done for you by default) and you don't have to close it at the end,
> because that is also done for you by default.
>
> /Henrik
>
>
>
> On Sun, Feb 1, 2015 at 2:53 PM, Bert Gunter <gunter.berton at gene.com> wrote:
>> But in addition to what Jeff noted, see ?save and ?save.image
>>
>> (noting that that the resulting .Rdata file can only be read by R).
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Sun, Feb 1, 2015 at 12:26 PM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us> wrote:
>>> In general this depends what you plan to do with those results. I suspect you are looking for something like knitr with rmarkdown (.Rmd files to create HTML or Word) or LaTeX (.Rnw files to create PDF).
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>                                       Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On February 1, 2015 12:05:47 PM PST, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
>>>>
>>>>Dear group,
>>>>
>>>>I have many plots and numeric results in my R program,  kindly how can
>>>>I save them all sequently on one file.
>>>>thanks in advance
>>>>RAI
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Feb  2 10:28:47 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 2 Feb 2015 20:28:47 +1100
Subject: [R] the less-than-minus gotcha
In-Reply-To: <54CED508.8020904@utoronto.ca>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
	<54CED508.8020904@utoronto.ca>
Message-ID: <CA+8X3fXTfgmhYpC1XSiPGn46A9nnq6=JhK_h9BTJ7Q8fub84HQ@mail.gmail.com>

"Moral of story, computers do what you tell them, not what you meant."

Not only a fortune, but profound wisdom.

Jim


On Mon, Feb 2, 2015 at 12:38 PM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> Using = has it's problems too.
>
> For example,
>
> print(fit <- lm(...))
>
> Assigns the result of the lm call to fit and prints the results. This is
> quite a useful trick actually.
>
> print(fit = lm(...))
>
> Throws an error.
>
> Moral of story, computers do what you tell them, not what you meant.
>
> Kevin
>
> On 02/01/2015 08:26 PM, Steve Taylor wrote:
>>
>> All the more reason to use = instead of <-
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ben Bolker
>> Sent: Monday, 2 February 2015 2:07p
>> To: r-help at stat.math.ethz.ch
>> Subject: Re: [R] the less-than-minus gotcha
>>
>> Mike Miller <mbmiller+l <at> gmail.com> writes:
>>
>>>
>>> I've got to remember to use more spaces.  Here's the basic problem:
>>>
>>> These are the same:
>>>
>>> v< 1
>>> v<1
>>>
>>> But these are extremely different:
>>>
>>> v< -1
>>> v<-1
>>>
>>
>> This is indeed documented, in passing, in one of the pages you listed:
>>
>> http://tim-smith.us/arrgh/syntax.html
>>
>> Whitespace is meaningless, unless it isn't. Some parsing ambiguities
>> are resolved by considering whitespace around operators. See and
>> despair: x<-y (assignment) is parsed differently than x < -y (comparison)!
>>
>
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sergio.fonda99 at gmail.com  Mon Feb  2 12:16:51 2015
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Mon, 2 Feb 2015 12:16:51 +0100
Subject: [R] save program results and graphs to one file
In-Reply-To: <DUB125-W74A585A523EF697C41BF54B33F0@phx.gbl>
References: <DUB125-W74A585A523EF697C41BF54B33F0@phx.gbl>
Message-ID: <CAJRuHor1WGZVMSMk5xyxDNqwTePme73MXzs48sdzKeEJCgut7Q@mail.gmail.com>

With a little effort you could implement Rstudio and try RMD (R Markdown)
it is very proficient, look at
https://support.rstudio.com/hc/en-us/articles/200552086-Using-R-Markdown
Il 01/feb/2015 21:07 "Ragia Ibrahim" <ragia11 at hotmail.com> ha scritto:

>
> Dear group,
>
> I have many plots and numeric results in my R program,  kindly how can I
> save them all sequently on one file.
> thanks in advance
> RAI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Mon Feb  2 12:34:23 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 02 Feb 2015 11:34:23 +0000
Subject: [R] Cross compiling R
In-Reply-To: <EA073E1BCBDF7C4DB9BAB257D1C1AC5353982FD6@NDA-HCLT-MBS03.hclt.corp.hcl.in>
References: <EA073E1BCBDF7C4DB9BAB257D1C1AC5353982FD6@NDA-HCLT-MBS03.hclt.corp.hcl.in>
Message-ID: <54CF60BF.60305@stats.ox.ac.uk>

Cross-building is not supported (building R is more than just compiling 
and needs a working R executable).

And (see the posting guide) this was not the right list for such a question.

On 02/02/2015 07:16, Vivek Rangi wrote:
> Hi!
>
>        I am cross compiling R-3.1.2 for Galileo board with the source code. I am able to configure R-3.1.2 without any errors with the following command :
>
> ./configure --host=i586-poky-linux-uclibc CC=i586-poky-linux-uclibc-gcc CXX=i586-poky-linux-uclibc-g++ F77=i586-poky-linux-uclibc-gfortran CPPFLAGS=-I/opt/clanton-tiny/1.4.2/sysroots/i586-poky-linux-uclibc/usr/include/ LDFLAGS="-L/opt/clanton-tiny/1.4.2/sysroots/i586-poky-linux-uclibc/usr/lib/ --sysroot=/opt/clanton-tiny/1.4.2/sysroots/i586-poky-linux-uclibc" --prefix=/home/vivek/Smart_Tracker/R/R-3.1.2/vivek --with-readline=no --with-x=no
>
>
> But when I am cross compiling R, I am getting following error :
>
> i586-poky-linux-uclibc-gcc -std=gnu99 -I../../../../include -DNDEBUG -I../../../include -I../../../../src/include -DHAVE_CONFIG_H -I../../../../src/main -I/opt/clanton-tiny/1.4.2/sysroots/i586-poky-linux-uclibc/usr/include/   -fvisibility=hidden -fpic  -O2 -pipe -g -feliminate-unused-debug-types  -c gramRd.c -o gramRd.o
> i586-poky-linux-uclibc-gcc -std=gnu99 -shared -L/opt/clanton-tiny/1.4.2/sysroots/i586-poky-linux-uclibc/usr/lib/ --sysroot=/opt/clanton-tiny/1.4.2/sysroots/i586-poky-linux-uclibc -o tools.so text.o init.o Rmd5.o md5.o signals.o install.o getfmts.o http.o gramLatex.o gramRd.o
> make[6]: Entering directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src/library/tools/src'
> mkdir -p -- ../../../../library/tools/libs
> make[6]: Leaving directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src/library/tools/src'
> make[5]: Leaving directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src/library/tools/src'
> make[4]: Leaving directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src/library/tools'
> ../../../bin/R: line 259: /home/vivek/Smart_Tracker/R/R-3.1.2/bin/exec/R: No such file or directory
> make[3]: *** [all] Error 127
> make[3]: Leaving directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src/library/tools'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src/library'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/vivek/Smart_Tracker/R/R-3.1.2/src'
> make: *** [R] Error 1
>
>
> "/home/vivek/Smart_Tracker/R/R-3.1.2/bin/exec/R" exits in the system. It seems it generates the "R" executable for the Galileo board and also, it tries to run the executable to generate the base packages for R. Since the "R" executable (/home/vivek/Smart_Tracker/R/R-3.1.2/bin/exec/R) is not for x86 system but for Galileo board, it is not able to execute it and hence the error.  Can somebody guide me as how to cross compile R?
>
> Regards,
> Vivek


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From r.turner at auckland.ac.nz  Mon Feb  2 12:46:26 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 03 Feb 2015 00:46:26 +1300
Subject: [R] Boundaries and deldir
In-Reply-To: <b7eb2bec9297830b473b3126207ef7d2@slingshot.co.nz>
References: <b7eb2bec9297830b473b3126207ef7d2@slingshot.co.nz>
Message-ID: <54CF6392.1050701@auckland.ac.nz>


On 02/02/15 16:26, p_connolly wrote:

> Just what is meant by dummy points as referred to by the help for the
> deldir() function?  I understood they indicated the boundary beyond
> which triangulation would cease.
>
> I thought I would need the x/y elements (as described in the help file
> at the end of the description of the use of the dpl argument) to
> describe ad hoc dummy points as way to define a polygon or two as a
> boundary.  However, it gives this error:
>
> Error in xd[-drop] : only 0's may be mixed with negative subscripts
>
> Something internal is doing the negative subscripting.
> I tried ndx/ndy instead of x/y but it evidently refers only to a
> rectangle so not what I need.
>
> Am I barking up the wrong tree altogether?  Is the boundary defined
> somewhere else entirely?  I need to get that clear before I am able to
> provide
> useful example code.

The dummy points have nothing to do with any "boundary".  In fact they 
have nothing much to do with anything, really! :-)  They are a hangover 
from the original purpose of deldir which was to assist in a numerical 
integration needed for the maximum likelihood estimation of the 
intensity function of an inhomogeneous Poisson process.  I really should 
get rid of them, but that would require a bit of work and re-writing of 
code and help files, and they do no real harm so I have decided to apply 
the "If it ain't broke don't fix it." principle.

The deldir function creates a Delaunay triangulation/Dirichlet 
tessellation inside a "rectangular window" (denoted by "rw" in the 
argument list).  This is the only boundary invoked or involved.

The function plot.tile.list() will *plot* the Dirichlet tessellation 
"clipped" to a specified polygon.  But that is just for *plotting*.  I 
am not sure that I really understand the idea of a "boundary beyond 
which the triangulation ceases".  The Delaunay triangulation is a finite
structure; its outer boundary is the convex hull of the set of points 
being triangulated.  You cannot confine it to a smaller region without 
losing some of those points.

If you can explain what you really want to do, perhaps I can help.

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From r.turner at auckland.ac.nz  Mon Feb  2 12:58:10 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 3 Feb 2015 00:58:10 +1300
Subject: [R] the less-than-minus gotcha
In-Reply-To: <CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
Message-ID: <54CF6652.8080001@auckland.ac.nz>


On 02/02/15 14:26, Steve Taylor wrote:

> All the more reason to use = instead of <-

Couldn't agree less, Steve. The "<-" should be used for assignment. The 
"=" sign should be reserved for handling function arguments in the 
"name=value" form.  Doing anything else invites confusion and 
occasionally chaos.

Lots of examples have been given in the past involving syntax of the 
form foo(x = y) and foo(x <- y).

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From S.Ellison at LGCGroup.com  Mon Feb  2 13:09:56 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 2 Feb 2015 12:09:56 +0000
Subject: [R] aov and Error function
In-Reply-To: <54CE1092.6080007@auckland.ac.nz>
References: <54CBD676.8060203@gmail.com>	<54CBDCBC.8060803@gmail.com>
	<6EAD7151-F375-4090-A660-96F19B5A9E0B@gmail.com>
	<54CC8FA7020000CB0012199E@smtp.medicine.umaryland.edu>
	<54CE1092.6080007@auckland.ac.nz>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED65EDCB1CB8@GOLD.corp.lgc-group.com>


> > aovsubj <- aov(value~group+time+Error(subject),data=dataRMANOVA)
> > and
> > aovsubjgroup <- aov(value~group+time+Error(subject/group),data=dataRMANOVA)
> >
> Since no-one else seems to have answered you let me point out that your first
> formulation treats subject 1 in the "int" group as being the same as subject 1 in
> the "cont" group, and similarly for subject 2 and so on.
> 
> The second formulation (subject nested within group) treats subject 1 in the
> "int" group as being *different* from subject 1 in the "cont" group.

Yes, but that isn't all, is it? 

subject/group

means group nested in subject, expanding to 
~subject+subject:group.

so Error(subject/group) asks for a subject effect across groups _as well as_ one within groups.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From pdalgd at gmail.com  Mon Feb  2 13:10:46 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 2 Feb 2015 13:10:46 +0100
Subject: [R] the less-than-minus gotcha
In-Reply-To: <CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
Message-ID: <C42FEA71-9C39-415C-931A-85A1D3BF67A2@gmail.com>

I'd rather say that it is good reason to use spaces around operators. Makes the code easier to read too. (_Possible_ to read for some.)

We've probably all done it. I did, once upon a time in S-Plus, on the results of a multi-day simulation study:

> <<nontrivial analysis>>$statistic
[1] -1.28
> sim <- sapply(1:10000, <<simulated nontrivial analysis>>$statistic)
.
. leave running
.
> mean(sim<-1.28) # get empirical p-value
[1] 1.28

??!?...  Uh-oh.....

On 02 Feb 2015, at 02:26 , Steve Taylor <steve.taylor at aut.ac.nz> wrote:

> All the more reason to use = instead of <-
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Mon Feb  2 13:27:30 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 2 Feb 2015 13:27:30 +0100
Subject: [R] aov and Error function
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED65EDCB1CB8@GOLD.corp.lgc-group.com>
References: <54CBD676.8060203@gmail.com>	<54CBDCBC.8060803@gmail.com>
	<6EAD7151-F375-4090-A660-96F19B5A9E0B@gmail.com>
	<54CC8FA7020000CB0012199E@smtp.medicine.umaryland.edu>
	<54CE1092.6080007@auckland.ac.nz>
	<A4E5A0B016B8CB41A485FC629B633CED65EDCB1CB8@GOLD.corp.lgc-group.com>
Message-ID: <250F3CB8-73E6-4488-8A60-47AACB07F64E@gmail.com>


On 02 Feb 2015, at 13:09 , S Ellison <S.Ellison at lgcgroup.com> wrote:

> 
>>> aovsubj <- aov(value~group+time+Error(subject),data=dataRMANOVA)
>>> and
>>> aovsubjgroup <- aov(value~group+time+Error(subject/group),data=dataRMANOVA)
>>> 
>> Since no-one else seems to have answered you let me point out that your first
>> formulation treats subject 1 in the "int" group as being the same as subject 1 in
>> the "cont" group, and similarly for subject 2 and so on.
>> 
>> The second formulation (subject nested within group) treats subject 1 in the
>> "int" group as being *different* from subject 1 in the "cont" group.
> 
> Yes, but that isn't all, is it? 
> 
> subject/group
> 
> means group nested in subject, expanding to 
> ~subject+subject:group.
> 
> so Error(subject/group) asks for a subject effect across groups _as well as_ one within groups.
> 


Or maybe more usefully stated, a group effect within subjects. This could be relevant if each individual goes to two different groups labeled say 1 and 2, but the groups are not related between different subjects (subj.1 attends AA and Boy Scouts, subj 2 School Board and Church, etc.) so there is no main effect of group. In statistics, it is usually the other way around: subjects arbitrarily numbered 1-20 within each group, but no relation between "subj.1" in one group and "subj.2" of the other, in which case ~group + Error(group:subject) makes sense. 


> S Ellison
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any =...{{dropped:24}}


From Ted.Harding at wlandres.net  Mon Feb  2 13:43:55 2015
From: Ted.Harding at wlandres.net (Ted Harding)
Date: Mon, 2 Feb 2015 12:43:55 +0000
Subject: [R] the less-than-minus gotcha
In-Reply-To: <54CF6652.8080001@auckland.ac.nz>
Message-ID: <XFMail.20150202124355.Ted.Harding@wlandres.net>

On 02-Feb-2015 11:58:10 Rolf Turner wrote:
> 
> On 02/02/15 14:26, Steve Taylor wrote:
> 
>> All the more reason to use = instead of <-
> 
> Couldn't agree less, Steve. The "<-" should be used for assignment. The 
> "=" sign should be reserved for handling function arguments in the 
> "name=value" form.  Doing anything else invites confusion and 
> occasionally chaos.
> 
> Lots of examples have been given in the past involving syntax of the 
> form foo(x = y) and foo(x <- y).
> 
> cheers,
> Rolf
> -- 
> Rolf Turner

As well as agreering with Rolf, it should also be said that Steve's
advice "All the more reason to use = instead of <-" is not applicable
in this context, which was:

  which( frame$var>4 )   # no problem
  which( frame$var<-4 )  # huge problem: frame$var is destroyed

There is no place for an "=" here!

What does not seems to have been mentioned so far is that this
kind of thing can be safely wrapped in parentheses:

  which( frame$var>4 )    # no problem oper
  which( frame$var<(-4) ) # [again no problem]

Personally, I'm prone to using parentheses if I have any feeling
that a "gotcha" may be lurking -- not only in the distinction
between "var<-4" and "var< -4", but also to be confident that,
for instance, my intentions are not being over-ridden by operator
precedence rules.

Some people object to code "clutter" from parentheses that could
be more simply replaced (e.g. "var< -4" instead of "var<(-4)"),
but parentheses ensure that it's right and also make it clear
when one reads it.

Best wishes to all,
Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 02-Feb-2015  Time: 12:43:51
This message was sent by XFMail


From kinley_robert at lilly.com  Mon Feb  2 13:47:21 2015
From: kinley_robert at lilly.com (Robert Douglas Kinley)
Date: Mon, 2 Feb 2015 12:47:21 +0000
Subject: [R] the less-than-minus gotcha
In-Reply-To: <54CF6652.8080001@auckland.ac.nz>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
	<54CF6652.8080001@auckland.ac.nz>
Message-ID: <ED7BD6A4158A1E42913C469CE74CA50E1BD2F500@ukdxmllyc301.rf.lilly.com>


Rolf Turner is right on the money about not mixing-up '=' and '<-'

Though this 'gotcha' will always a threat while  '<-'  is the assignment operator.

The old Algol60 syntax of ':=' was less error-prone, but I guess '<-' is too firmly bedded-in to ever change.

Meanwhile, spaces around the assignment operator gives less error-prone and more readable code.

cheers  Bob Kinley  

_____________________________________________

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rolf Turner
Sent: 02 February 2015 11:58
To: Steve Taylor; r-help at stat.math.ethz.ch
Subject: Re: [R] the less-than-minus gotcha


On 02/02/15 14:26, Steve Taylor wrote:

> All the more reason to use = instead of <-

Couldn't agree less, Steve. The "<-" should be used for assignment. The "=" sign should be reserved for handling function arguments in the "name=value" form.  Doing anything else invites confusion and occasionally chaos.

Lots of examples have been given in the past involving syntax of the form foo(x = y) and foo(x <- y).

cheers,

Rolf

--
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rebecca.yuan at bankofamerica.com  Mon Feb  2 14:43:50 2015
From: rebecca.yuan at bankofamerica.com (Yuan, Rebecca)
Date: Mon, 02 Feb 2015 13:43:50 +0000
Subject: [R] Error: OutOfMemoryError (Java): GC overhead limit exceeded
Message-ID: <419EED2318C2164DB95FBB20AA8810D8016CC227@smtp_mail.bankofamerica.com>

Hello all,

When I met this following error message:

Error: OutOfMemoryError (Java): GC overhead limit exceeded

I usually use the following options to overcome the memory limit:

options(java.parameters = "-Xmx1024m") # to reduce the error message "Error: OutOfMemoryError (Java): GC overhead limit exceeded"

However, this seems not working any more, is there any other way to help avoiding the memory error issue in R?

Thanks very much!

Cheers,

Rebecca



20

----------------------------------------------------------------------
This message, and any attachments, is for the intended r...{{dropped:5}}


From jvadams at usgs.gov  Mon Feb  2 14:59:59 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 2 Feb 2015 07:59:59 -0600
Subject: [R] naming rows/columns in 'array of matrices'
In-Reply-To: <54CBD676.8060203@gmail.com>
References: <54CBD676.8060203@gmail.com>
Message-ID: <CAN5YmCH4GSmJLd0exuP2j2CpLP7QxcaWZ0QWmFdu6Mz9Y=zVSA@mail.gmail.com>

In your example, P is a three dimensional array.  You can assign names to
the three dimensions using the dimnames() function.  For example, this
command assigns names to the first two dimensions, but leaves the third
dimension without names.

dimnames(P) <- list(c("live", "dead"), c("live", "dead"), NULL)

Jean

On Fri, Jan 30, 2015 at 1:07 PM, Evan Cooch <evan.cooch at gmail.com> wrote:

> Suppose I have the following situation:
>
> I have an array of 2 matrices, where each matrix is (2x2):
>
> P <- array(0, c(2,2,2))
>
> P[,,1] <- matrix(c(1,2,3,4),2,2,byrow=T);
> P[,,2] <- matrix(c(5,6,7,8),2,2,byrow=T);
>
> I want to label rows and columns of each matrix in the array, such that P
> would look like
>
>
>         live dead
> live      1    2
> dead      3    4
>
> , , 2
>
>         live  dead
>  live     5    6
>  dead     7    8
>
> I've tried 'direct, brute force" approaches like
>
> rownames(P[,,1]) <- c("live","dead")
> colnames(P[,,1]) <- c("live","dead")
>
> (repeated for the second matrix), but this doesn't work.
>
> Since all of the matrices are of the same dimension(s), and since I want
> the same rownames and colnames for each matrix, I'm hoping there is some
> simply magical permutation of lapply (I'm guessing) which will do the trick.
>
>  I'd also be interested in why the 'direct, brute force' approach (above)
> doesn't work, and what does, since I might need to manipulate row/col names
> for individual matrices in the array (if, say, dimensions of the matrices
> were not the same over the array).
>
> Thanks in advance!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Feb  2 15:27:58 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 02 Feb 2015 06:27:58 -0800
Subject: [R] Error: OutOfMemoryError (Java): GC overhead limit exceeded
In-Reply-To: <419EED2318C2164DB95FBB20AA8810D8016CC227@smtp_mail.bankofamerica.com>
References: <419EED2318C2164DB95FBB20AA8810D8016CC227@smtp_mail.bankofamerica.com>
Message-ID: <A1E92A9D-1D43-410C-8D94-992A68A73D1F@dcn.davis.CA.us>

The memory issue is in Java, not R.

You can either be more parsimonious in your use of Java memory (we have no idea what you are doing with it here, so how you do that is up to you), or you can allocate more memory to Java (you may be able to guess how to do that, or read the Java documentation on the X parameter).
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 2, 2015 5:43:50 AM PST, "Yuan, Rebecca" <rebecca.yuan at bankofamerica.com> wrote:
>Hello all,
>
>When I met this following error message:
>
>Error: OutOfMemoryError (Java): GC overhead limit exceeded
>
>I usually use the following options to overcome the memory limit:
>
>options(java.parameters = "-Xmx1024m") # to reduce the error message
>"Error: OutOfMemoryError (Java): GC overhead limit exceeded"
>
>However, this seems not working any more, is there any other way to
>help avoiding the memory error issue in R?
>
>Thanks very much!
>
>Cheers,
>
>Rebecca
>
>
>
>20
>
>----------------------------------------------------------------------
>This message, and any attachments, is for the intended
>r...{{dropped:5}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From roland.pape at uni-oldenburg.de  Mon Feb  2 15:36:38 2015
From: roland.pape at uni-oldenburg.de (Roland Pape)
Date: Mon, 2 Feb 2015 14:36:38 +0000
Subject: [R] (Cross-)validating GLM including factors
Message-ID: <4780FC16AA89574CA36BB63C15DF63A12BA35ABB@mbx05.w2kroot.uni-oldenburg.de>

Dear list,

I would like to validate various GLMs, all of them containing (among others) several factors as predictors. I thought about using cv.glm from the boot package, but necessarily got the error "factor xy has new level z". Is there any function to easily cross validate LMs or GLMs containing factors that I have missed, or any other work around?
- Having in mind that using cross validation on a small data set is not the best solution (I have 50-600 samples, but also three factors with up to 15 levels): Are there any other approaches?

Any help is greatly appreciated!

Roland

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Mon Feb  2 16:09:24 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 2 Feb 2015 15:09:24 +0000
Subject: [R] naming rows/columns in 'array of matrices'
In-Reply-To: <CAN5YmCH4GSmJLd0exuP2j2CpLP7QxcaWZ0QWmFdu6Mz9Y=zVSA@mail.gmail.com>
References: <54CBD676.8060203@gmail.com>
	<CAN5YmCH4GSmJLd0exuP2j2CpLP7QxcaWZ0QWmFdu6Mz9Y=zVSA@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED65EDCB1EA2@GOLD.corp.lgc-group.com>

> >  I'd also be interested in why the 'direct, brute force' approach
> > (above) doesn't work,
Your example was a 3-dimensional array, so 
> rownames(P) <- colnames(P) <- c(live', 'dead') 
would have worked; rownames() and colnames() work on dimnames[1] and dimnames[2].

But 
rownames(P[,,1])
could not have worked, because you were not assigning to the names of P; you were assigning to something (P[,,1]) extracted from P. In effect, you were doing the equivalent of
{P1 <- P[,,1]
rownames(P1) <- c('live', 'dead')
rm(P1)}


> > ... since I might need to manipulate
> > row/col names for individual matrices in the array (if, say,
> > dimensions of the matrices were not the same over the array).
If the dimension are different you will not have an array; you'd have to have a list of matrices. 
You could then use lapply for the one constant dimension size; for example, 

lp <- list(P22 = matrix(ncol=2, nrow=2), P32= matrix(ncol=2, nrow=3))

lapply(lp, function(x, cn=c('live', 'dead')) {colnames(x)<-cn; x})

Other than that, you'd either have to do some careful conditional coding or apply names manually.

S


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From maechler at lynne.stat.math.ethz.ch  Mon Feb  2 16:11:37 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Mon, 2 Feb 2015 16:11:37 +0100
Subject: [R] the less-than-minus gotcha
In-Reply-To: <CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
Message-ID: <21711.37801.439519.676495@stat.math.ethz.ch>


> All the more reason to use = instead of <-

Definitely not!

(As you were told, there are other drawbacks).

R does not have to look like C, it *is* different in many ways.
If you use a decent IDE for R, you get spaces around ' <- ' for
free: Both in ESS and in Rstudio, you can use   "[Alt] -"  
to produce the 4 characters ' <- '

{ [Alt] + "-") is called 'M--' in ESS / emacs which has even
  more options for " <- " and is fully configurable in its key
  bindings anyway. }

The '=' character has many uses in R  and using  ' <- '
for assignment makes the code "more expressive": It makes sense
to highlight the assignment op, but is a bit stupid to
highlight all "=" signs.  Further it can be nicely marked up by
a real "left arrow" by e.g. the listings LaTeX 
'listings' package, or the (oldish) 'a2ps'  GNU software.

Further, assignment is not commutative, and hence, 
there is a corresponding ` -> `  operator,
whereas the '=' is a commutative operator in mathematics, but
not when used as assignment op.

[ yes: "Flame war is on.  I'll stop reading R-help for a while.."
  ;-) ;-) ]


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: Monday, 2 February 2015 2:07p
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] the less-than-minus gotcha

> Mike Miller <mbmiller+l <at> gmail.com> writes:

> > 
> > I've got to remember to use more spaces.  Here's the basic problem:
> > 
> > These are the same:
> > 
> > v< 1
> > v<1
> > 
> > But these are extremely different:
> > 
> > v< -1
> > v<-1
> > 

> This is indeed documented, in passing, in one of the pages you listed:

> http://tim-smith.us/arrgh/syntax.html

> Whitespace is meaningless, unless it isn't. Some parsing ambiguities 
> are resolved by considering whitespace around operators. See and
> despair: x<-y (assignment) is parsed differently than x < -y (comparison)!


From jholtman at gmail.com  Mon Feb  2 16:20:47 2015
From: jholtman at gmail.com (jim holtman)
Date: Mon, 2 Feb 2015 10:20:47 -0500
Subject: [R] Error: OutOfMemoryError (Java): GC overhead limit exceeded
In-Reply-To: <A1E92A9D-1D43-410C-8D94-992A68A73D1F@dcn.davis.CA.us>
References: <419EED2318C2164DB95FBB20AA8810D8016CC227@smtp_mail.bankofamerica.com>
	<A1E92A9D-1D43-410C-8D94-992A68A73D1F@dcn.davis.CA.us>
Message-ID: <CAAxdm-4BiaTV_BmauAmuK_kfpUxSmidd9wM70vO2LwN68mZ1mQ@mail.gmail.com>

On the off-chance, are you using XLConnect or xlsx packages that are using
Java to access the spreadsheets?  If it is XLConnect, are you access the
'.xlsx' style workbooks?  If so, can you try using '.xls' workbooks?  This
is a problem that I have had; the '.xlsx' workbooks take a lot more
resources (CPU and memory) to process.

A little more information like what your sessionInfo is would help a lot in
responding to your problem.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Feb 2, 2015 at 9:27 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> The memory issue is in Java, not R.
>
> You can either be more parsimonious in your use of Java memory (we have no
> idea what you are doing with it here, so how you do that is up to you), or
> you can allocate more memory to Java (you may be able to guess how to do
> that, or read the Java documentation on the X parameter).
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On February 2, 2015 5:43:50 AM PST, "Yuan, Rebecca" <
> rebecca.yuan at bankofamerica.com> wrote:
> >Hello all,
> >
> >When I met this following error message:
> >
> >Error: OutOfMemoryError (Java): GC overhead limit exceeded
> >
> >I usually use the following options to overcome the memory limit:
> >
> >options(java.parameters = "-Xmx1024m") # to reduce the error message
> >"Error: OutOfMemoryError (Java): GC overhead limit exceeded"
> >
> >However, this seems not working any more, is there any other way to
> >help avoiding the memory error issue in R?
> >
> >Thanks very much!
> >
> >Cheers,
> >
> >Rebecca
> >
> >
> >
> >20
> >
> >----------------------------------------------------------------------
> >This message, and any attachments, is for the intended
> >r...{{dropped:5}}
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Mon Feb  2 16:44:16 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 2 Feb 2015 07:44:16 -0800
Subject: [R] (Cross-)validating GLM including factors
In-Reply-To: <4780FC16AA89574CA36BB63C15DF63A12BA35ABB@mbx05.w2kroot.uni-oldenburg.de>
References: <4780FC16AA89574CA36BB63C15DF63A12BA35ABB@mbx05.w2kroot.uni-oldenburg.de>
Message-ID: <CACk-te2ucp8og6q44FYJ99GVY=j7H3SDy_AD9t7v+bC4uOUS6g@mail.gmail.com>

This is not an r-help issue. Post on a statistics list like
stats.stackexchange.com instead for a variety of opinions.*

Cheers,
Bert

*Which will probably be useless given your paucity of data. But that's
just *my* useless opinion.

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Feb 2, 2015 at 6:36 AM, Roland Pape
<roland.pape at uni-oldenburg.de> wrote:
> Dear list,
>
> I would like to validate various GLMs, all of them containing (among others) several factors as predictors. I thought about using cv.glm from the boot package, but necessarily got the error "factor xy has new level z". Is there any function to easily cross validate LMs or GLMs containing factors that I have missed, or any other work around?
> - Having in mind that using cross validation on a small data set is not the best solution (I have 50-600 samples, but also three factors with up to 15 levels): Are there any other approaches?
>
> Any help is greatly appreciated!
>
> Roland
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Feb  2 16:53:08 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 2 Feb 2015 07:53:08 -0800
Subject: [R] Transform a list of multiple to a data.frame which I want
In-Reply-To: <099CE2DB-7DBE-4DCF-AC21-5513148FD193@nibs.ac.cn>
References: <099CE2DB-7DBE-4DCF-AC21-5513148FD193@nibs.ac.cn>
Message-ID: <CAF8bMcb=BbFS+eW=DjJk2GYWek9a6MutVq13JemDn0+cGeuuog@mail.gmail.com>

Does the following work for you.  The only trick is working around the fact
that matrix subscripting does not allow out-of-bounds subscripts but vector
subscripting does.  We do the subscripting in two steps, relying on the
drop=TRUE default in the matrix subscripting operator that converts the
single-
column matrix output to a vector.

> txt <- c("abc", "abcade", "xyz", "abacad")
> sTxt <- str_locate_all(txt, "a")
> lTxt <- lapply(sTxt, function(st)structure(st[,1][1:2],
names=c("start.1", "start.2")))
> names(lTxt) <- txt
> str(lTxt)
List of 4
 $ abc   : Named int [1:2] 1 NA
  ..- attr(*, "names")= chr [1:2] "start.1" "start.2"
 $ abcade: Named int [1:2] 1 4
  ..- attr(*, "names")= chr [1:2] "start.1" "start.2"
 $ xyz   : Named num [1:2] NA NA
  ..- attr(*, "names")= chr [1:2] "start.1" "start.2"
 $ abacad: Named int [1:2] 1 3
  ..- attr(*, "names")= chr [1:2] "start.1" "start.2"


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Feb 1, 2015 at 4:53 AM, Yao He <heyao at nibs.ac.cn> wrote:

> Dear all:
>
>         I have a list like that,which is a standard str_locate_all()
> function (stringr package) output:
> $K
>    start end
> $GSEGTCSCSSK
>    start end
> [1,]     6   6
> [2,]     8   8
> $GFSTTCPAHVDDLTPEQVLDGDVNELMDVVLHHVPEAK
>    start end
> [1,]     6   6
> $LVECIGQELIFLLPNK
>    start end
> [1,]     4   4
> $NFK
>    start end
> $HR
>    start end
> $AYASLFR
>    start end
>
> I want to transform this list like that:
>
> ID   start.1  start.2
> K   NA  NA
> GSEGTCSCSSK 6 8
> GFSTTCPAHVDDLTPEQVLDGDVNELMDVVLHHVPEAK 6 NA
> LVECIGQELIFLLPNK 4 NA
> NFK NA NA
> HR NA NA
> AYASLFR NA NA
>
> I have already tried to use t() , lapply() but I think it is hard to
> handle the NA value and different rows in every matrix
>
> Thanks in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From thomas.worthington at okstate.edu  Mon Feb  2 18:20:00 2015
From: thomas.worthington at okstate.edu (Worthington, Thomas A)
Date: Mon, 2 Feb 2015 17:20:00 +0000
Subject: [R] Multiple Line Widths denextend
Message-ID: <C1A5238848713043B7C18ED38FFEF1F829CF69C3@STWMB01.ad.okstate.edu>

Dear All 

We are using the dendextend package to modify the plot output from a pvclust clustering 

The model is created with 

result <- pvclust(chord.1, method.dist="euclidian", method.hclust="average",nboot=100000)

The plot is then formatted as following 

dend <- as.dendrogram(result)
dend %>%
pvclust_show_signif(result, signif_type = c("au"),alpha=0.05, signif_value = c(4, 1)) %>% set("labels_cex", c(1.5)) %>% set("labels_col", sp_col) %>% 
plot(horiz=TRUE, sub="", xlab="", ylab="",xlim=c(0.31, -0.17), ylim= c(3.5,93))

We are using the pvclust_show_signif function to set the line weight to '4' of pvclust branches with an alpha of less than 0.05. Is it possible to set multiple line weights for different alpha values e.g. lwd = 8 when alpha = 0.05 and lwd = 4 when alpha = 0.1?

Best wishes
Tom 


From eike.petersen at fp-tga.de  Mon Feb  2 14:27:05 2015
From: eike.petersen at fp-tga.de (Eike Petersen)
Date: Mon, 2 Feb 2015 14:27:05 +0100 (CET)
Subject: [R] FFT Normalization Documentation
Message-ID: <1985531401.416848.1422883625463.JavaMail.open-xchange@omgreatgod.store>

Hello everyone,

the docpage for the fft function states:

?Description: Performs the Fast Fourier Transform of an array.?

and

?Arguments ? inverse: if ?TRUE?, the unnormalized inverse transform is computed
(the inverse has a ?+? in the exponent of e, but here, we do _not_ divide by
?1/length(x)?).?

Judging from this, I would expect ?fft(x)? to yield the correct FFT of x, and
?fft(X, inverse = TRUE) / length(X)? to yield the correct inverse FFT of X.

However, it seems to me that actually the result of ?fft(x)? should be scaled by
?1/length(x)?, while ?fft(X, inverse=TRUE)? seems to yield a correct result by
default:

t <- seq(0.001, 1, 0.001)
y <- 1 + sin(2*pi*20*t) + 1.5 * sin(2*pi*30*t)
Y <- fft(y)
dev.new()
plot(abs(Y)) ## Shows peaks at amplitudes 1000, 500 and 750, while they should
be at amplitude 1, 0.5 and 0.75.
y2 <- Re(fft(Y / length(Y), inverse = TRUE))
max(abs(y-y2)) ## The IFFT yields a correctly scaled result by default, if
applied to a correctly scaled FFT.

Did I get something wrong? If not, having spent quite some time figuring this
out, I would like to see the documentation clearly pointing this out. I find the
current text rather confusing.

On another note: I have spent some time working on demo files that showcase some
of the properties of the FFT and their implementation in R. I have done this
primarily for myself, as I keep forgetting how these things work, but I thought
that it might be helpful to others as well. Any hints on where/how I should
publish such a thing?

Kind regards and many thanks in advance,

Eike


From js.huang at protective.com  Mon Feb  2 18:08:42 2015
From: js.huang at protective.com (JS Huang)
Date: Mon, 2 Feb 2015 09:08:42 -0800 (PST)
Subject: [R] help plotting my data
In-Reply-To: <1422728664835-4702583.post@n4.nabble.com>
References: <1422728664835-4702583.post@n4.nabble.com>
Message-ID: <1422896922028-4702679.post@n4.nabble.com>

Hi,

   I hope the following works for you.  The plot is:  Rplot.png
<http://r.789695.n4.nabble.com/file/n4702679/Rplot.png>  

> data <- read.table("rHelp_20150202.txt",header=TRUE)
> order.data <- order(data$counts,decreasing=TRUE)
> order.data
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
25 26 27 28 29
> plot(data$counts ~ factor(data$role,levels=data$role[order.data]))





--
View this message in context: http://r.789695.n4.nabble.com/help-plotting-my-data-tp4702583p4702679.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Mon Feb  2 18:16:09 2015
From: js.huang at protective.com (JS Huang)
Date: Mon, 2 Feb 2015 09:16:09 -0800 (PST)
Subject: [R] Dropping time series observations
In-Reply-To: <CACM6noYs29QAE8zBxhdxn4_W5d6cH+auaPRLhvrUbwLSWW0ZyQ@mail.gmail.com>
References: <CACM6noYs29QAE8zBxhdxn4_W5d6cH+auaPRLhvrUbwLSWW0ZyQ@mail.gmail.com>
Message-ID: <1422897369192-4702680.post@n4.nabble.com>

Hi,

I have a data frame named data and with the statement
data[5:length(data[[1]]),] I can get row 5 to the end of the data.

> data
               role counts
1             Agent    220
2             Theme    169
3           Patient     67
4          Location     41
5       Destination     32
6         Recipient     31
7            Result     29
8        Instrument     27
9            Source     25
10      Experiencer     22
11            Topic     22
12         Stimulus     18
13        Attribute     15
14      Beneficiary     12
15 Initial_Location     12
16         Co-Agent     11
17       Co-Patient     11
18         Co-Theme      9
19             Goal      9
20            Asset      7
21            Cause      6
22         Material      5
23            Value      5
24          Product      4
25        Predicate      3
26       Trajectory      3
27           Extent      2
28             Time      2
29        Reflexive      1
> data[5:length(data[[1]]),]
               role counts
5       Destination     32
6         Recipient     31
7            Result     29
8        Instrument     27
9            Source     25
10      Experiencer     22
11            Topic     22
12         Stimulus     18
13        Attribute     15
14      Beneficiary     12
15 Initial_Location     12
16         Co-Agent     11
17       Co-Patient     11
18         Co-Theme      9
19             Goal      9
20            Asset      7
21            Cause      6
22         Material      5
23            Value      5
24          Product      4
25        Predicate      3
26       Trajectory      3
27           Extent      2
28             Time      2
29        Reflexive      1



--
View this message in context: http://r.789695.n4.nabble.com/Dropping-time-series-observations-tp4702589p4702680.html
Sent from the R help mailing list archive at Nabble.com.


From aolinto.lst at gmail.com  Mon Feb  2 18:56:27 2015
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Mon, 2 Feb 2015 15:56:27 -0200
Subject: [R] using png and identify commands
Message-ID: <CAE8g1gMpQX6bSCBhhPOkFHXmi_XYx3MGAdyf=oHBXdq3-+W+BQ@mail.gmail.com>

Hi R users

I want to save a plot after using the command identify.

I use identify to place labels manually near the points in order to avoid
overlapping lines and numbers.

x<-c(1,2,3,4,5,6)
y<-c(20,30,15,7,25,40)
plot(x,y,type="b",ylim=c(0,45))
identify(x,y,labels=y)

But when I add

png(filename="test.png",width=20,height=20,units="cm",res=300)
x<-c(1,2,3,4,5,6)
y<-c(20,30,15,7,25,40)
plot(x,y,type="b",ylim=c(0,45))
identify(x,y,labels=y)
dev.off()

The plot is saved directly, without the identification of the points.My
question is: how to save the plot only after having labelled the points.

I use R integrated to gedit in UBUNTU Trusty Tahr 64 bits. I'd like to save
the plot using command lines and not GUIs

Thanks for any help. Best regards,

Antonio Olinto

	[[alternative HTML version deleted]]


From rebecca.yuan at bankofamerica.com  Mon Feb  2 19:11:16 2015
From: rebecca.yuan at bankofamerica.com (Yuan, Rebecca)
Date: Mon, 02 Feb 2015 18:11:16 +0000
Subject: [R] Error: OutOfMemoryError (Java): GC overhead limit exceeded
In-Reply-To: <CAAxdm-4BiaTV_BmauAmuK_kfpUxSmidd9wM70vO2LwN68mZ1mQ@mail.gmail.com>
References: <419EED2318C2164DB95FBB20AA8810D8016CC227@smtp_mail.bankofamerica.com>
	<A1E92A9D-1D43-410C-8D94-992A68A73D1F@dcn.davis.CA.us>
	<CAAxdm-4BiaTV_BmauAmuK_kfpUxSmidd9wM70vO2LwN68mZ1mQ@mail.gmail.com>
Message-ID: <419EED2318C2164DB95FBB20AA8810D8016D147B@smtp_mail.bankofamerica.com>

Hello Jim,

I already use ?.xls? for the loading, but still have the memory issue?.

Thanks,

Rebecca


From: jim holtman [mailto:jholtman at gmail.com]
Sent: Monday, February 02, 2015 10:21 AM
To: Jeff Newmiller
Cc: Yuan, Rebecca; R help (r-help at r-project.org)
Subject: Re: [R] Error: OutOfMemoryError (Java): GC overhead limit exceeded

On the off-chance, are you using XLConnect or xlsx packages that are using Java to access the spreadsheets?  If it is XLConnect, are you access the '.xlsx' style workbooks?  If so, can you try using '.xls' workbooks?  This is a problem that I have had; the '.xlsx' workbooks take a lot more resources (CPU and memory) to process.

A little more information like what your sessionInfo is would help a lot in responding to your problem.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Feb 2, 2015 at 9:27 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>> wrote:
The memory issue is in Java, not R.

You can either be more parsimonious in your use of Java memory (we have no idea what you are doing with it here, so how you do that is up to you), or you can allocate more memory to Java (you may be able to guess how to do that, or read the Java documentation on the X parameter).
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On February 2, 2015 5:43:50 AM PST, "Yuan, Rebecca" <rebecca.yuan at bankofamerica.com<mailto:rebecca.yuan at bankofamerica.com>> wrote:
>Hello all,
>
>When I met this following error message:
>
>Error: OutOfMemoryError (Java): GC overhead limit exceeded
>
>I usually use the following options to overcome the memory limit:
>
>options(java.parameters = "-Xmx1024m") # to reduce the error message
>"Error: OutOfMemoryError (Java): GC overhead limit exceeded"
>
>However, this seems not working any more, is there any other way to
>help avoiding the memory error issue in R?
>
>Thanks very much!
>
>Cheers,
>
>Rebecca
>
>
>
>20
>
>----------------------------------------------------------------------
>This message, and any attachments, is for the intended
>r...{{dropped:5}}
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


----------------------------------------------------------------------
This message, and any attachments, is for the intended recipient(s) only, may contain information that is privileged, confidential and/or proprietary and subject to important terms and conditions available at http://www.bankofamerica.com/emaildisclaimer.   If you are not the intended recipient, please delete this message.

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Feb  2 19:22:36 2015
From: jholtman at gmail.com (jim holtman)
Date: Mon, 2 Feb 2015 13:22:36 -0500
Subject: [R] Error: OutOfMemoryError (Java): GC overhead limit exceeded
In-Reply-To: <419EED2318C2164DB95FBB20AA8810D8016D147B@smtp_mail.bankofamerica.com>
References: <419EED2318C2164DB95FBB20AA8810D8016CC227@smtp_mail.bankofamerica.com>
	<A1E92A9D-1D43-410C-8D94-992A68A73D1F@dcn.davis.CA.us>
	<CAAxdm-4BiaTV_BmauAmuK_kfpUxSmidd9wM70vO2LwN68mZ1mQ@mail.gmail.com>
	<419EED2318C2164DB95FBB20AA8810D8016D147B@smtp_mail.bankofamerica.com>
Message-ID: <CAAxdm-5C1hKZkLxPoNPG6F+K0ZVaw2QrpnKQi2CoEBUM9bOKCQ@mail.gmail.com>

How big are the worksheets that you are reading in?  Do you have multiple
ones open at the same time?  Have to tried to use 'xlcFreeMemory' to see if
this helps?  How much RAM to you have on your system?


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Feb 2, 2015 at 1:11 PM, Yuan, Rebecca <
rebecca.yuan at bankofamerica.com> wrote:

>  Hello Jim,
>
>
>
> I already use ?.xls? for the loading, but still have the memory issue?.
>
>
>
> Thanks,
>
>
>
> Rebecca
>
>
>
>
>
> *From:* jim holtman [mailto:jholtman at gmail.com]
> *Sent:* Monday, February 02, 2015 10:21 AM
> *To:* Jeff Newmiller
> *Cc:* Yuan, Rebecca; R help (r-help at r-project.org)
> *Subject:* Re: [R] Error: OutOfMemoryError (Java): GC overhead limit
> exceeded
>
>
>
> On the off-chance, are you using XLConnect or xlsx packages that are using
> Java to access the spreadsheets?  If it is XLConnect, are you access the
> '.xlsx' style workbooks?  If so, can you try using '.xls' workbooks?  This
> is a problem that I have had; the '.xlsx' workbooks take a lot more
> resources (CPU and memory) to process.
>
>
>
> A little more information like what your sessionInfo is would help a lot
> in responding to your problem.
>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
>
> On Mon, Feb 2, 2015 at 9:27 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> The memory issue is in Java, not R.
>
> You can either be more parsimonious in your use of Java memory (we have no
> idea what you are doing with it here, so how you do that is up to you), or
> you can allocate more memory to Java (you may be able to guess how to do
> that, or read the Java documentation on the X parameter).
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On February 2, 2015 5:43:50 AM PST, "Yuan, Rebecca" <
> rebecca.yuan at bankofamerica.com> wrote:
> >Hello all,
> >
> >When I met this following error message:
> >
> >Error: OutOfMemoryError (Java): GC overhead limit exceeded
> >
> >I usually use the following options to overcome the memory limit:
> >
> >options(java.parameters = "-Xmx1024m") # to reduce the error message
> >"Error: OutOfMemoryError (Java): GC overhead limit exceeded"
> >
> >However, this seems not working any more, is there any other way to
> >help avoiding the memory error issue in R?
> >
> >Thanks very much!
> >
> >Cheers,
> >
> >Rebecca
> >
> >
> >
> >20
> >
> >----------------------------------------------------------------------
> >This message, and any attachments, is for the intended
> >r...{{dropped:5}}
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>  ------------------------------
> This message, and any attachments, is for the intended...{{dropped:11}}


From ssefick at gmail.com  Mon Feb  2 19:39:14 2015
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 2 Feb 2015 12:39:14 -0600
Subject: [R] rJava Scientific Linux 6.5 - Can not install
Message-ID: <CADKEMqgttjhCDNthZkmnAcx+Po1R8shr523LRXp8eK7EToJkSw@mail.gmail.com>

Hello all,

I am having a problem with installing rJava on SL 6.5. I am having compile
errors when I try to from CRAN using install.packages("XLConnect", repos="
http://cran.rstudio.com/"). I can provide anything necessary, but I am
unsure what to provide. Thank you for your help in advance.

output of sessionInfo():
R version 3.1.0 Patched (2014-06-15 r65949)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
 [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
 [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
 [7] LC_PAPER=en_US.utf8       LC_NAME=C
 [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] graphics  grDevices utils     datasets  stats     methods   base

other attached packages:
[1] devtools_1.7.0 ggplot2_1.0.0

loaded via a namespace (and not attached):
 [1] colorspace_1.2-4 digest_0.6.8     grid_3.1.0       gtable_0.1.2
 [5] MASS_7.3-37      munsell_0.4.2    plyr_1.8.1       proto_0.3-10
 [9] Rcpp_0.11.4      reshape2_1.4.1   scales_0.2.4     stringr_0.6.2
[13] tools_3.1.0



-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Feb  2 19:50:44 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 02 Feb 2015 10:50:44 -0800
Subject: [R] How to enable https for R 3.1.2 on windows 8.1
In-Reply-To: <CAC1VXC42D=0svuys9GHGwFePsXAozoggHEs_Bkgh_hqu12EhHg@mail.gmail.com>
References: <CAC1VXC6de=3XzNOBmO8gm5CYr65X9NXw=+BpT9kTuxrN-Mm=uw@mail.gmail.com>
	<91C59476-A35C-48F9-A679-DB782CB96F11@dcn.davis.CA.us>
	<CAC1VXC42D=0svuys9GHGwFePsXAozoggHEs_Bkgh_hqu12EhHg@mail.gmail.com>
Message-ID: <D8BFBC3D-ACCC-403B-97C8-2D88DAF374BD@dcn.davis.CA.us>

Cc'd back to the list... I am a bad bet for one-on-one help.

Showing that your libcurl claims to support HTTPS is progress. I think that at this point you should read the last sentence in the curl FAQ 3.21, which I found by searching for "protocol https not supported or disabled in libcurl".

http://curl.haxx.se/docs/faq.html
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 2, 2015 9:21:05 AM PST, John Kalb <john.kalb at gmail.com> wrote:
>Honestly.  I ran the search you suggested and didn't find anything that
>helped.  I did come across the curlVersion function and ran it right
>after
>receiving the error message.  It seems to indicate that https is
>available.  I don't see a way forward.
>
>Error in function (type, msg, asError = TRUE)  :
>  Protocol " https" not supported or disabled in libcurl
>> curlVersion()$protocol
>[1] "dict"   "file"   "ftp"    "ftps"   "gopher" "http"   "https" 
>"imap"
>  "imaps"  "ldap"
>[11] "pop3"   "pop3s"  "rtmp"   "rtsp"   "scp"    "sftp"   "smtp"  
>"smtps"
> "telnet" "tftp"
>
>On Sun, Feb 1, 2015 at 1:58 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Honestly? Did you try "rcurl https windows" (without the quotes)?
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 1, 2015 8:56:00 AM PST, John Kalb <john.kalb at gmail.com>
>wrote:
>> >I run the code below successfully on Mac and Ubuntu successfully.
>> >When I run on Windows, I get the results shown.  How do I get the
>code
>> >to work on Windows? I've googled extensively with no success. Thanks
>> >in advance.
>> >
>> >require(twitteR)
>> >
>> >Loading required package: twitteR
>> >Loading required package: ROAuth
>> >Loading required package: RCurl
>> >Loading required package: bitops
>> >Loading required package: rjson
>> >> cred <- OAuthFactory $ new( consumerKey = my.key, consumerSecret =
>> >my.secret, requestURL =' https:// api.twitter.com/ oauth/
>> >request_token', accessURL =' https:// api.twitter.com/ oauth/
>> >access_token', authURL =' https:// api.twitter.com/ oauth/
>authorize')
>> >> cred$handshake(cainfo =
>"C:/users/john/documents/twitter/cacert.pem")
>> >Error in function (type, msg, asError = TRUE)  :
>> >  Protocol " https" not supported or disabled in libcurl
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From istazahn at gmail.com  Mon Feb  2 19:53:53 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 2 Feb 2015 13:53:53 -0500
Subject: [R] rJava Scientific Linux 6.5 - Can not install
In-Reply-To: <CADKEMqgttjhCDNthZkmnAcx+Po1R8shr523LRXp8eK7EToJkSw@mail.gmail.com>
References: <CADKEMqgttjhCDNthZkmnAcx+Po1R8shr523LRXp8eK7EToJkSw@mail.gmail.com>
Message-ID: <CA+vqiLEMZoUkxM0nj6ogiAYwu81He9=AjQFibs2W86xt+H+ZcQ@mail.gmail.com>

On Mon, Feb 2, 2015 at 1:39 PM, stephen sefick <ssefick at gmail.com> wrote:
> Hello all,
>
> I am having a problem with installing rJava on SL 6.5. I am having compile
> errors when I try to from CRAN using install.packages("XLConnect", repos="
> http://cran.rstudio.com/"). I can provide anything necessary, but I am
> unsure what to provide.

The actual error would be a good start. You can probably solve your
problem by copying the error message into google, but if that doesn't
help you can post it back here.

Best,
Ista

Thank you for your help in advance.
>
> output of sessionInfo():
> R version 3.1.0 Patched (2014-06-15 r65949)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>  [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
>  [7] LC_PAPER=en_US.utf8       LC_NAME=C
>  [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] graphics  grDevices utils     datasets  stats     methods   base
>
> other attached packages:
> [1] devtools_1.7.0 ggplot2_1.0.0
>
> loaded via a namespace (and not attached):
>  [1] colorspace_1.2-4 digest_0.6.8     grid_3.1.0       gtable_0.1.2
>  [5] MASS_7.3-37      munsell_0.4.2    plyr_1.8.1       proto_0.3-10
>  [9] Rcpp_0.11.4      reshape2_1.4.1   scales_0.2.4     stringr_0.6.2
> [13] tools_3.1.0
>
>
>
> --
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Feb  2 19:54:41 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 02 Feb 2015 10:54:41 -0800
Subject: [R] rJava Scientific Linux 6.5 - Can not install
In-Reply-To: <CADKEMqgttjhCDNthZkmnAcx+Po1R8shr523LRXp8eK7EToJkSw@mail.gmail.com>
References: <CADKEMqgttjhCDNthZkmnAcx+Po1R8shr523LRXp8eK7EToJkSw@mail.gmail.com>
Message-ID: <632E20FD-220C-4924-8FA8-AA62EE602FEB@dcn.davis.CA.us>

Don't know anything about SL but have you installed a Java run time independent of R?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 2, 2015 10:39:14 AM PST, stephen sefick <ssefick at gmail.com> wrote:
>Hello all,
>
>I am having a problem with installing rJava on SL 6.5. I am having
>compile
>errors when I try to from CRAN using install.packages("XLConnect",
>repos="
>http://cran.rstudio.com/"). I can provide anything necessary, but I am
>unsure what to provide. Thank you for your help in advance.
>
>output of sessionInfo():
>R version 3.1.0 Patched (2014-06-15 r65949)
>Platform: x86_64-unknown-linux-gnu (64-bit)
>
>locale:
> [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
> [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
> [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
> [7] LC_PAPER=en_US.utf8       LC_NAME=C
> [9] LC_ADDRESS=C              LC_TELEPHONE=C
>[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
>attached base packages:
>[1] graphics  grDevices utils     datasets  stats     methods   base
>
>other attached packages:
>[1] devtools_1.7.0 ggplot2_1.0.0
>
>loaded via a namespace (and not attached):
> [1] colorspace_1.2-4 digest_0.6.8     grid_3.1.0       gtable_0.1.2
> [5] MASS_7.3-37      munsell_0.4.2    plyr_1.8.1       proto_0.3-10
> [9] Rcpp_0.11.4      reshape2_1.4.1   scales_0.2.4     stringr_0.6.2
>[13] tools_3.1.0


From tom at maladmin.com  Mon Feb  2 19:58:23 2015
From: tom at maladmin.com (Tom Wright)
Date: Mon, 02 Feb 2015 13:58:23 -0500
Subject: [R] using png and identify commands
In-Reply-To: <CAE8g1gMpQX6bSCBhhPOkFHXmi_XYx3MGAdyf=oHBXdq3-+W+BQ@mail.gmail.com>
References: <CAE8g1gMpQX6bSCBhhPOkFHXmi_XYx3MGAdyf=oHBXdq3-+W+BQ@mail.gmail.com>
Message-ID: <1422903503.1901.14.camel@maladmin.com>

replacing png(...) and dev.off() with
dev2bitmap('test.png')
seems to work.

On Mon, 2015-02-02 at 15:56 -0200, Antonio Silva wrote:
> Hi R users
> 
> I want to save a plot after using the command identify.
> 
> I use identify to place labels manually near the points in order to avoid
> overlapping lines and numbers.
> 
> x<-c(1,2,3,4,5,6)
> y<-c(20,30,15,7,25,40)
> plot(x,y,type="b",ylim=c(0,45))
> identify(x,y,labels=y)
> 
> But when I add
> 
> png(filename="test.png",width=20,height=20,units="cm",res=300)
> x<-c(1,2,3,4,5,6)
> y<-c(20,30,15,7,25,40)
> plot(x,y,type="b",ylim=c(0,45))
> identify(x,y,labels=y)
> dev.off()
> 
> The plot is saved directly, without the identification of the points.My
> question is: how to save the plot only after having labelled the points.
> 
> I use R integrated to gedit in UBUNTU Trusty Tahr 64 bits. I'd like to save
> the plot using command lines and not GUIs
> 
> Thanks for any help. Best regards,
> 
> Antonio Olinto
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From utz.ryan at gmail.com  Mon Feb  2 19:00:10 2015
From: utz.ryan at gmail.com (utz.ryan)
Date: Mon, 2 Feb 2015 10:00:10 -0800 (PST)
Subject: [R] odbcConnectAccess2007 errors with Access databases on new PC
Message-ID: <CAKJ8KVgwJQFJAqgO=paRTgH7Hz+s2h7f=sUdEchJTUuz3R49Xw@mail.gmail.com>

Hello,

I've connected R to Microsoft Access databases for years now
using odbcConnectAccess2007. I recently got a new computer and R is
absolutely refusing to connect to any Access database with the following
error message:

Warning messages:
1: In odbcDriverConnect(con, ...) :
  [RODBC] ERROR: state IM002, code 0, message [Microsoft][ODBC Driver
Manager] Data source name not found and no default driver specified
2: In odbcDriverConnect(con, ...) : ODBC connection failed

It's definitely not a path name problem-I've checked a dozen times. A few
things online have mentioned something about 32-bit and 64-bit systems
causing problems. I've tried opening both the 64-bit and 32-bit versions of
R with zero luck. My Office is running a 32-bit system.

Is there anything else I can try? I really would hate to lose the ability
to connect R to my Access databases due to some intractable problem.

Thanks,
Ryan

-- 

Ryan Utz, Ph.D.
Aquatic Ecologist/STREON Scientist
National Ecological Observatory Network

Home/Cell: (724) 272-7769
Work: (720) 836-2488




--
View this message in context: http://r.789695.n4.nabble.com/odbcConnectAccess2007-errors-with-Access-databases-on-new-PC-tp4702686.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From charles.santana at gmail.com  Mon Feb  2 20:00:31 2015
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Mon, 2 Feb 2015 20:00:31 +0100
Subject: [R] A good way to debug a c++ library embedded to an R code
Message-ID: <CAH-FEnhqiY0XbBYy_GSu5wm2UfFNcmJ73dS5rZcRPEGwx=TX4w@mail.gmail.com>

Dear all,

I am using R CMD SHLIB to compile a c++ code into a library (.so) and
dyn.load to load this library into a R code. I am facing some problems in
the c++ part that I can not figure out how to solve. Do you recomend any
good way to debug this R + C++ program? If I was programming only in C++ I
would use GDB.

I would much appreciate any help or suggestion!

Best regards,

Charles

-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Mon Feb  2 20:15:30 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 02 Feb 2015 13:15:30 -0600
Subject: [R] odbcConnectAccess2007 errors with Access databases on new PC
In-Reply-To: <CAKJ8KVgwJQFJAqgO=paRTgH7Hz+s2h7f=sUdEchJTUuz3R49Xw@mail.gmail.com>
References: <CAKJ8KVgwJQFJAqgO=paRTgH7Hz+s2h7f=sUdEchJTUuz3R49Xw@mail.gmail.com>
Message-ID: <C0196F83-5810-4159-9543-7B0695867CA2@me.com>

On Feb 2, 2015, at 12:00 PM, utz.ryan <utz.ryan at gmail.com> wrote:
> 
> Hello,
> 
> I've connected R to Microsoft Access databases for years now
> using odbcConnectAccess2007. I recently got a new computer and R is
> absolutely refusing to connect to any Access database with the following
> error message:
> 
> Warning messages:
> 1: In odbcDriverConnect(con, ...) :
>  [RODBC] ERROR: state IM002, code 0, message [Microsoft][ODBC Driver
> Manager] Data source name not found and no default driver specified
> 2: In odbcDriverConnect(con, ...) : ODBC connection failed
> 
> It's definitely not a path name problem-I've checked a dozen times. A few
> things online have mentioned something about 32-bit and 64-bit systems
> causing problems. I've tried opening both the 64-bit and 32-bit versions of
> R with zero luck. My Office is running a 32-bit system.
> 
> Is there anything else I can try? I really would hate to lose the ability
> to connect R to my Access databases due to some intractable problem.
> 
> Thanks,
> Ryan


Take a look at the RODBC vignette:

  vignette("RODBC")

or

  http://cran.r-project.org/web/packages/RODBC/vignettes/RODBC.pdf

and see the footnote (16) at the bottom of page 22 regarding the creation of 32 bit DSNs and the following from page 20:

"32-bit Windows drivers for Access 2007 and Excel 2007 are bundled with Office 2007 but can be installed separately via the installer AccessDatabaseEngine.exe available from http://www.microsoft.com/en-us/download/details.aspx?id=23734."


The entire tool chain needs to be of the same architecture. So 32 bit Office, 32 bit ODBC drivers, 32 bit DSN and 32 bit R.

BTW, as you may be aware, there is a DB SIG list specifically for these types of questions:

  https://stat.ethz.ch/mailman/listinfo/r-sig-db

Regards,

Marc Schwartz


From hb at biostat.ucsf.edu  Mon Feb  2 20:31:49 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 2 Feb 2015 11:31:49 -0800
Subject: [R] using png and identify commands
In-Reply-To: <CAE8g1gMpQX6bSCBhhPOkFHXmi_XYx3MGAdyf=oHBXdq3-+W+BQ@mail.gmail.com>
References: <CAE8g1gMpQX6bSCBhhPOkFHXmi_XYx3MGAdyf=oHBXdq3-+W+BQ@mail.gmail.com>
Message-ID: <CAFDcVCSWyA_qdhLM3tpq6DB8m2UC-dQ79Z2JuLnqqhiSu+LWsQ@mail.gmail.com>

On Mon, Feb 2, 2015 at 9:56 AM, Antonio Silva <aolinto.lst at gmail.com> wrote:
> Hi R users
>
> I want to save a plot after using the command identify.
>
> I use identify to place labels manually near the points in order to avoid
> overlapping lines and numbers.
>
> x<-c(1,2,3,4,5,6)
> y<-c(20,30,15,7,25,40)
> plot(x,y,type="b",ylim=c(0,45))
> identify(x,y,labels=y)
>
> But when I add
>
> png(filename="test.png",width=20,height=20,units="cm",res=300)
> x<-c(1,2,3,4,5,6)
> y<-c(20,30,15,7,25,40)
> plot(x,y,type="b",ylim=c(0,45))
> identify(x,y,labels=y)
> dev.off()
>
> The plot is saved directly, without the identification of the points.My
> question is: how to save the plot only after having labelled the points.

Not that surprising, because identify() needs an "interactive" /
screen device, e.g. From help("identify"): "identify is only supported
on screen devices such as X11, windows and quartz. On other devices
the call will do nothing."

You need to do it in two steps, e.g.

x<-c(1,2,3,4,5,6)
y<-c(20,30,15,7,25,40)
plot(x,y,type="b",ylim=c(0,45))
marks <- identify(x,y,labels=y,pos=TRUE)

png(filename="test.png",width=20,height=20,units="cm",res=300)
plot(x,y,type="b",ylim=c(0,45))
xym <- cbind(x=x[marks$ind], y=y[marks$ind])
points(xym)
text(xym, labels=xym[,"y"], pos=marks$pos)
dev.off()


To make sure you call the exact same plot commands in the two steps,
you can also do:

library("R.devices")

x<-c(1,2,3,4,5,6)
y<-c(20,30,15,7,25,40)

marks <- NULL
devEval(c("x11", "png"), name="test", {
  plot(x,y,type="b",ylim=c(0,45))
  if (is.null(marks)) {
    marks <- identify(x,y,labels=y,pos=TRUE)
  } else {
    xym <- cbind(x=x[marks$ind], y=y[marks$ind])
    points(xym)
    text(xym, labels=xym[,"y"], pos=marks$pos)
  }
})

/Henrik

>
> I use R integrated to gedit in UBUNTU Trusty Tahr 64 bits. I'd like to save
> the plot using command lines and not GUIs
>
> Thanks for any help. Best regards,
>
> Antonio Olinto
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Feb  2 20:50:32 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 2 Feb 2015 11:50:32 -0800
Subject: [R] How to enable https for R 3.1.2 on windows 8.1
In-Reply-To: <D8BFBC3D-ACCC-403B-97C8-2D88DAF374BD@dcn.davis.CA.us>
References: <CAC1VXC6de=3XzNOBmO8gm5CYr65X9NXw=+BpT9kTuxrN-Mm=uw@mail.gmail.com>
	<91C59476-A35C-48F9-A679-DB782CB96F11@dcn.davis.CA.us>
	<CAC1VXC42D=0svuys9GHGwFePsXAozoggHEs_Bkgh_hqu12EhHg@mail.gmail.com>
	<D8BFBC3D-ACCC-403B-97C8-2D88DAF374BD@dcn.davis.CA.us>
Message-ID: <E512165B-ED8F-4326-B960-8918A8B2590F@comcast.net>


On Feb 2, 2015, at 10:50 AM, Jeff Newmiller wrote:

> Cc'd back to the list... I am a bad bet for one-on-one help.
> 
> Showing that your libcurl claims to support HTTPS is progress. I think that at this point you should read the last sentence in the curl FAQ 3.21, which I found by searching for "protocol https not supported or disabled in libcurl".

I have had success accessing https://... urls using the 'downloader' package's `download` function. The ?download page has system-specific details.

-- 
David.
> 
> http://curl.haxx.se/docs/faq.html
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On February 2, 2015 9:21:05 AM PST, John Kalb <john.kalb at gmail.com> wrote:
>> Honestly.  I ran the search you suggested and didn't find anything that
>> helped.  I did come across the curlVersion function and ran it right
>> after
>> receiving the error message.  It seems to indicate that https is
>> available.  I don't see a way forward.
>> 
>> Error in function (type, msg, asError = TRUE)  :
>> Protocol " https" not supported or disabled in libcurl
>>> curlVersion()$protocol
>> [1] "dict"   "file"   "ftp"    "ftps"   "gopher" "http"   "https" 
>> "imap"
>> "imaps"  "ldap"
>> [11] "pop3"   "pop3s"  "rtmp"   "rtsp"   "scp"    "sftp"   "smtp"  
>> "smtps"
>> "telnet" "tftp"
>> 
>> On Sun, Feb 1, 2015 at 1:58 PM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us>
>> wrote:
>> 
>>> Honestly? Did you try "rcurl https windows" (without the quotes)?
>>> 
>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>                                      Live:   OO#.. Dead: OO#.. 
>> Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>> rocks...1k
>>> 
>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On February 1, 2015 8:56:00 AM PST, John Kalb <john.kalb at gmail.com>
>> wrote:
>>>> I run the code below successfully on Mac and Ubuntu successfully.
>>>> When I run on Windows, I get the results shown.  How do I get the
>> code
>>>> to work on Windows? I've googled extensively with no success. Thanks
>>>> in advance.
>>>> 
>>>> require(twitteR)
>>>> 
>>>> Loading required package: twitteR
>>>> Loading required package: ROAuth
>>>> Loading required package: RCurl
>>>> Loading required package: bitops
>>>> Loading required package: rjson
>>>>> cred <- OAuthFactory $ new( consumerKey = my.key, consumerSecret =
>>>> my.secret, requestURL =' https:// api.twitter.com/ oauth/
>>>> request_token', accessURL =' https:// api.twitter.com/ oauth/
>>>> access_token', authURL =' https:// api.twitter.com/ oauth/
>> authorize')
>>>>> cred$handshake(cainfo =
>> "C:/users/john/documents/twitter/cacert.pem")
>>>> Error in function (type, msg, asError = TRUE)  :
>>>> Protocol " https" not supported or disabled in libcurl
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Feb  2 20:50:32 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 2 Feb 2015 11:50:32 -0800
Subject: [R] How to enable https for R 3.1.2 on windows 8.1
In-Reply-To: <D8BFBC3D-ACCC-403B-97C8-2D88DAF374BD@dcn.davis.CA.us>
References: <CAC1VXC6de=3XzNOBmO8gm5CYr65X9NXw=+BpT9kTuxrN-Mm=uw@mail.gmail.com>
	<91C59476-A35C-48F9-A679-DB782CB96F11@dcn.davis.CA.us>
	<CAC1VXC42D=0svuys9GHGwFePsXAozoggHEs_Bkgh_hqu12EhHg@mail.gmail.com>
	<D8BFBC3D-ACCC-403B-97C8-2D88DAF374BD@dcn.davis.CA.us>
Message-ID: <654062B9-3B63-407C-9EAB-0A1E6C55D5A5@comcast.net>


On Feb 2, 2015, at 10:50 AM, Jeff Newmiller wrote:

> Cc'd back to the list... I am a bad bet for one-on-one help.
> 
> Showing that your libcurl claims to support HTTPS is progress. I think that at this point you should read the last sentence in the curl FAQ 3.21, which I found by searching for "protocol https not supported or disabled in libcurl".

I have had success accessing https://... urls using the 'downloader' package's `download` function. The ?download page has system-specific details.

-- 
David.
> 
> http://curl.haxx.se/docs/faq.html
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On February 2, 2015 9:21:05 AM PST, John Kalb <john.kalb at gmail.com> wrote:
>> Honestly.  I ran the search you suggested and didn't find anything that
>> helped.  I did come across the curlVersion function and ran it right
>> after
>> receiving the error message.  It seems to indicate that https is
>> available.  I don't see a way forward.
>> 
>> Error in function (type, msg, asError = TRUE)  :
>> Protocol " https" not supported or disabled in libcurl
>>> curlVersion()$protocol
>> [1] "dict"   "file"   "ftp"    "ftps"   "gopher" "http"   "https" 
>> "imap"
>> "imaps"  "ldap"
>> [11] "pop3"   "pop3s"  "rtmp"   "rtsp"   "scp"    "sftp"   "smtp"  
>> "smtps"
>> "telnet" "tftp"
>> 
>> On Sun, Feb 1, 2015 at 1:58 PM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us>
>> wrote:
>> 
>>> Honestly? Did you try "rcurl https windows" (without the quotes)?
>>> 
>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>                                      Live:   OO#.. Dead: OO#.. 
>> Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>> rocks...1k
>>> 
>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On February 1, 2015 8:56:00 AM PST, John Kalb <john.kalb at gmail.com>
>> wrote:
>>>> I run the code below successfully on Mac and Ubuntu successfully.
>>>> When I run on Windows, I get the results shown.  How do I get the
>> code
>>>> to work on Windows? I've googled extensively with no success. Thanks
>>>> in advance.
>>>> 
>>>> require(twitteR)
>>>> 
>>>> Loading required package: twitteR
>>>> Loading required package: ROAuth
>>>> Loading required package: RCurl
>>>> Loading required package: bitops
>>>> Loading required package: rjson
>>>>> cred <- OAuthFactory $ new( consumerKey = my.key, consumerSecret =
>>>> my.secret, requestURL =' https:// api.twitter.com/ oauth/
>>>> request_token', accessURL =' https:// api.twitter.com/ oauth/
>>>> access_token', authURL =' https:// api.twitter.com/ oauth/
>> authorize')
>>>>> cred$handshake(cainfo =
>> "C:/users/john/documents/twitter/cacert.pem")
>>>> Error in function (type, msg, asError = TRUE)  :
>>>> Protocol " https" not supported or disabled in libcurl
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From john.kalb at gmail.com  Mon Feb  2 20:29:20 2015
From: john.kalb at gmail.com (John Kalb)
Date: Mon, 2 Feb 2015 14:29:20 -0500
Subject: [R] How to enable https for R 3.1.2 on windows 8.1
In-Reply-To: <D8BFBC3D-ACCC-403B-97C8-2D88DAF374BD@dcn.davis.CA.us>
References: <CAC1VXC6de=3XzNOBmO8gm5CYr65X9NXw=+BpT9kTuxrN-Mm=uw@mail.gmail.com>
	<91C59476-A35C-48F9-A679-DB782CB96F11@dcn.davis.CA.us>
	<CAC1VXC42D=0svuys9GHGwFePsXAozoggHEs_Bkgh_hqu12EhHg@mail.gmail.com>
	<D8BFBC3D-ACCC-403B-97C8-2D88DAF374BD@dcn.davis.CA.us>
Message-ID: <CAC1VXC7r0=o-6+9OU-X4ec=Tv_84sFde7vOPKwr84fxwGTnn4w@mail.gmail.com>

Changing urls to remove spaces and replace single quotes with double quotes
resolved the issue.  Apparently windows demands double quotes.

Thanks for your help.

On Mon, Feb 2, 2015 at 1:50 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Cc'd back to the list... I am a bad bet for one-on-one help.
>
> Showing that your libcurl claims to support HTTPS is progress. I think
> that at this point you should read the last sentence in the curl FAQ 3.21,
> which I found by searching for "protocol https not supported or disabled in
> libcurl".
>
> http://curl.haxx.se/docs/faq.html
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On February 2, 2015 9:21:05 AM PST, John Kalb <john.kalb at gmail.com> wrote:
> >Honestly.  I ran the search you suggested and didn't find anything that
> >helped.  I did come across the curlVersion function and ran it right
> >after
> >receiving the error message.  It seems to indicate that https is
> >available.  I don't see a way forward.
> >
> >Error in function (type, msg, asError = TRUE)  :
> >  Protocol " https" not supported or disabled in libcurl
> >> curlVersion()$protocol
> >[1] "dict"   "file"   "ftp"    "ftps"   "gopher" "http"   "https"
> >"imap"
> >  "imaps"  "ldap"
> >[11] "pop3"   "pop3s"  "rtmp"   "rtsp"   "scp"    "sftp"   "smtp"
> >"smtps"
> > "telnet" "tftp"
> >
> >On Sun, Feb 1, 2015 at 1:58 PM, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> Honestly? Did you try "rcurl https windows" (without the quotes)?
> >>
>
> >---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go
> >Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >> Go...
> >>                                       Live:   OO#.. Dead: OO#..
> >Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >rocks...1k
> >>
>
> >---------------------------------------------------------------------------
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On February 1, 2015 8:56:00 AM PST, John Kalb <john.kalb at gmail.com>
> >wrote:
> >> >I run the code below successfully on Mac and Ubuntu successfully.
> >> >When I run on Windows, I get the results shown.  How do I get the
> >code
> >> >to work on Windows? I've googled extensively with no success. Thanks
> >> >in advance.
> >> >
> >> >require(twitteR)
> >> >
> >> >Loading required package: twitteR
> >> >Loading required package: ROAuth
> >> >Loading required package: RCurl
> >> >Loading required package: bitops
> >> >Loading required package: rjson
> >> >> cred <- OAuthFactory $ new( consumerKey = my.key, consumerSecret =
> >> >my.secret, requestURL =' https:// api.twitter.com/ oauth/
> >> >request_token', accessURL =' https:// api.twitter.com/ oauth/
> >> >access_token', authURL =' https:// api.twitter.com/ oauth/
> >authorize')
> >> >> cred$handshake(cainfo =
> >"C:/users/john/documents/twitter/cacert.pem")
> >> >Error in function (type, msg, asError = TRUE)  :
> >> >  Protocol " https" not supported or disabled in libcurl
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
>
>

	[[alternative HTML version deleted]]


From ssefick at gmail.com  Mon Feb  2 21:39:43 2015
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 2 Feb 2015 14:39:43 -0600
Subject: [R] rJava Scientific Linux 6.5 - Can not install
In-Reply-To: <632E20FD-220C-4924-8FA8-AA62EE602FEB@dcn.davis.CA.us>
References: <CADKEMqgttjhCDNthZkmnAcx+Po1R8shr523LRXp8eK7EToJkSw@mail.gmail.com>
	<632E20FD-220C-4924-8FA8-AA62EE602FEB@dcn.davis.CA.us>
Message-ID: <CADKEMqjQBX_zC_ioUrJe+Rxn3T89fHBnGRgKSsTg7Ez1wcsugA@mail.gmail.com>

Included at the end of this message is the full compiler output. I have
installed jre-7 from Oracle; The java-1.7.0-jdk* packages and javacc are
installed. It looks like the archiver, header prep., and compiler are
missing. I can provide anything else that can help solve my problem. I
really appreciate all of the help. Kindest regards.

checking for gcc... gcc -std=gnu99
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc -std=gnu99 accepts -g... yes
checking for gcc -std=gnu99 option to accept ISO C89... none needed
checking how to run the C preprocessor... gcc -std=gnu99 -E
checking for grep that handles long lines and -e... /bin/grep
checking for egrep... /bin/grep -E
checking for ANSI C header files... yes
checking for sys/wait.h that is POSIX.1 compatible... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking for string.h... (cached) yes
checking sys/time.h usability... yes
checking sys/time.h presence... yes
checking for sys/time.h... yes
checking for unistd.h... (cached) yes
checking for an ANSI C-conforming const... yes
checking whether time.h and sys/time.h may both be included... yes
configure: checking whether gcc -std=gnu99 supports static inline...
yes
checking whether setjmp.h is POSIX.1 compatible... yes
checking whether sigsetjmp is declared... yes
checking whether siglongjmp is declared... yes
checking Java support in R... present:
interpreter : '/usr/bin/java'
archiver    : ''
compiler    : ''
header prep.: ''
cpp flags   : '-I/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0.x86_64/jre/../include
-I/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0.x86_64/jre/../include/linux'
java libs   : '-L/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0.x86_64/jre/lib/amd64/server
-ljvm'configure: error: Java Development Kit (JDK) is missing or not
registered in R
Make sure R is configured with full Java support (including JDK). Run
R CMD javareconf
as root to add Java support to R.

If you don't have root privileges, run
R CMD javareconf -e

to set all Java-related variables and then install rJava.



On Mon, Feb 2, 2015 at 12:54 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Don't know anything about SL but have you installed a Java run time
> independent of R?
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On February 2, 2015 10:39:14 AM PST, stephen sefick <ssefick at gmail.com>
> wrote:
> >Hello all,
> >
> >I am having a problem with installing rJava on SL 6.5. I am having
> >compile
> >errors when I try to from CRAN using install.packages("XLConnect",
> >repos="
> >http://cran.rstudio.com/"). I can provide anything necessary, but I am
> >unsure what to provide. Thank you for your help in advance.
> >
> >output of sessionInfo():
> >R version 3.1.0 Patched (2014-06-15 r65949)
> >Platform: x86_64-unknown-linux-gnu (64-bit)
> >
> >locale:
> > [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
> > [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
> > [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
> > [7] LC_PAPER=en_US.utf8       LC_NAME=C
> > [9] LC_ADDRESS=C              LC_TELEPHONE=C
> >[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
> >
> >attached base packages:
> >[1] graphics  grDevices utils     datasets  stats     methods   base
> >
> >other attached packages:
> >[1] devtools_1.7.0 ggplot2_1.0.0
> >
> >loaded via a namespace (and not attached):
> > [1] colorspace_1.2-4 digest_0.6.8     grid_3.1.0       gtable_0.1.2
> > [5] MASS_7.3-37      munsell_0.4.2    plyr_1.8.1       proto_0.3-10
> > [9] Rcpp_0.11.4      reshape2_1.4.1   scales_0.2.4     stringr_0.6.2
> >[13] tools_3.1.0
>
>


-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From tom at maladmin.com  Mon Feb  2 22:00:12 2015
From: tom at maladmin.com (Tom Wright)
Date: Mon, 02 Feb 2015 16:00:12 -0500
Subject: [R] collapse a list of dataframes
Message-ID: <1422910812.1901.29.camel@maladmin.com>

Hi all,

I'm trying to avoid loops (no real reason, just as an exercise).

Given a list:

list(data.frame(a=1:3,b=letters[1:3]),data.frame(x=1:5,b=LETTERS[1:5]))

Is there an easy way to collapse this to a single dataframe

result<-data.frame(a=c(1:3,1:5),b=c(letters[1:3],LETTERS[1:5]))


Thanks


From wangdan412 at gmail.com  Mon Feb  2 22:09:43 2015
From: wangdan412 at gmail.com (dan wang)
Date: Mon, 2 Feb 2015 16:09:43 -0500
Subject: [R] collapse a list of dataframes
In-Reply-To: <1422910812.1901.29.camel@maladmin.com>
References: <1422910812.1901.29.camel@maladmin.com>
Message-ID: <CA+1Z_YsVpErVgndS=LfLRJxB3s43zqDEnbPgV4aZ=ZhEdmmOwg@mail.gmail.com>

How about this,

t <- lapply(a,function(x){colnames(x)=c("A","B");return(x)})
do.call(rbind,t)

On Mon, Feb 2, 2015 at 4:00 PM, Tom Wright <tom at maladmin.com> wrote:

> Hi all,
>
> I'm trying to avoid loops (no real reason, just as an exercise).
>
> Given a list:
>
> list(data.frame(a=1:3,b=letters[1:3]),data.frame(x=1:5,b=LETTERS[1:5]))
>
> Is there an easy way to collapse this to a single dataframe
>
> result<-data.frame(a=c(1:3,1:5),b=c(letters[1:3],LETTERS[1:5]))
>
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tom at maladmin.com  Mon Feb  2 22:15:24 2015
From: tom at maladmin.com (Tom Wright)
Date: Mon, 02 Feb 2015 16:15:24 -0500
Subject: [R] collapse a list of dataframes
In-Reply-To: <CA+1Z_YsVpErVgndS=LfLRJxB3s43zqDEnbPgV4aZ=ZhEdmmOwg@mail.gmail.com>
References: <1422910812.1901.29.camel@maladmin.com>
	<CA+1Z_YsVpErVgndS=LfLRJxB3s43zqDEnbPgV4aZ=ZhEdmmOwg@mail.gmail.com>
Message-ID: <1422911724.1901.30.camel@maladmin.com>

Thanks,
After posting I came across this page:
http://www.r-bloggers.com/concatenating-a-list-of-data-frames/

rbindlist seems to be a pretty good solution.

On Mon, 2015-02-02 at 16:09 -0500, dan wang wrote:
> How about this,
> 
> 
> t <- lapply(a,function(x){colnames(x)=c("A","B");return(x)})
> do.call(rbind,t)
> 
> 
> On Mon, Feb 2, 2015 at 4:00 PM, Tom Wright <tom at maladmin.com> wrote:
>         Hi all,
>         
>         I'm trying to avoid loops (no real reason, just as an
>         exercise).
>         
>         Given a list:
>         
>         list(data.frame(a=1:3,b=letters[1:3]),data.frame(x=1:5,b=LETTERS[1:5]))
>         
>         Is there an easy way to collapse this to a single dataframe
>         
>         result<-data.frame(a=c(1:3,1:5),b=c(letters[1:3],LETTERS[1:5]))
>         
>         
>         Thanks
>         
>         ______________________________________________
>         R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>         see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         and provide commented, minimal, self-contained, reproducible
>         code.
> 
>


From aolinto.lst at gmail.com  Mon Feb  2 22:06:36 2015
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Mon, 2 Feb 2015 19:06:36 -0200
Subject: [R] using png and identify commands
In-Reply-To: <CAFDcVCSWyA_qdhLM3tpq6DB8m2UC-dQ79Z2JuLnqqhiSu+LWsQ@mail.gmail.com>
References: <CAE8g1gMpQX6bSCBhhPOkFHXmi_XYx3MGAdyf=oHBXdq3-+W+BQ@mail.gmail.com>
	<CAFDcVCSWyA_qdhLM3tpq6DB8m2UC-dQ79Z2JuLnqqhiSu+LWsQ@mail.gmail.com>
Message-ID: <CAE8g1gO6HkBbjqiL8Gy2e5Ygsg7GARVmaWC3v_WyM8=EdidjKA@mail.gmail.com>

Thanks Henrik and Tom, job done. Nice solutions.

All the best

Antonio Olinto

2015-02-02 17:31 GMT-02:00 Henrik Bengtsson <hb at biostat.ucsf.edu>:

> On Mon, Feb 2, 2015 at 9:56 AM, Antonio Silva <aolinto.lst at gmail.com>
> wrote:
> > Hi R users
> >
> > I want to save a plot after using the command identify.
> >
> > I use identify to place labels manually near the points in order to avoid
> > overlapping lines and numbers.
> >
> > x<-c(1,2,3,4,5,6)
> > y<-c(20,30,15,7,25,40)
> > plot(x,y,type="b",ylim=c(0,45))
> > identify(x,y,labels=y)
> >
> > But when I add
> >
> > png(filename="test.png",width=20,height=20,units="cm",res=300)
> > x<-c(1,2,3,4,5,6)
> > y<-c(20,30,15,7,25,40)
> > plot(x,y,type="b",ylim=c(0,45))
> > identify(x,y,labels=y)
> > dev.off()
> >
> > The plot is saved directly, without the identification of the points.My
> > question is: how to save the plot only after having labelled the points.
>
> Not that surprising, because identify() needs an "interactive" /
> screen device, e.g. From help("identify"): "identify is only supported
> on screen devices such as X11, windows and quartz. On other devices
> the call will do nothing."
>
> You need to do it in two steps, e.g.
>
> x<-c(1,2,3,4,5,6)
> y<-c(20,30,15,7,25,40)
> plot(x,y,type="b",ylim=c(0,45))
> marks <- identify(x,y,labels=y,pos=TRUE)
>
> png(filename="test.png",width=20,height=20,units="cm",res=300)
> plot(x,y,type="b",ylim=c(0,45))
> xym <- cbind(x=x[marks$ind], y=y[marks$ind])
> points(xym)
> text(xym, labels=xym[,"y"], pos=marks$pos)
> dev.off()
>
>
> To make sure you call the exact same plot commands in the two steps,
> you can also do:
>
> library("R.devices")
>
> x<-c(1,2,3,4,5,6)
> y<-c(20,30,15,7,25,40)
>
> marks <- NULL
> devEval(c("x11", "png"), name="test", {
>   plot(x,y,type="b",ylim=c(0,45))
>   if (is.null(marks)) {
>     marks <- identify(x,y,labels=y,pos=TRUE)
>   } else {
>     xym <- cbind(x=x[marks$ind], y=y[marks$ind])
>     points(xym)
>     text(xym, labels=xym[,"y"], pos=marks$pos)
>   }
> })
>
> /Henrik
>
> >
> > I use R integrated to gedit in UBUNTU Trusty Tahr 64 bits. I'd like to
> save
> > the plot using command lines and not GUIs
> >
> > Thanks for any help. Best regards,
> >
> > Antonio Olinto
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Ant?nio Olinto ?vila da Silva
Bi?logo / Ocean?grafo
Instituto de Pesca (Fisheries Institute)
S?o Paulo, Brasil

	[[alternative HTML version deleted]]


From sunaga at telenet.be  Mon Feb  2 22:11:37 2015
From: sunaga at telenet.be (sunaga at telenet.be)
Date: Mon, 2 Feb 2015 22:11:37 +0100 (CET)
Subject: [R] rtools fstream error
Message-ID: <1940557801.24359068.1422911497949.JavaMail.root@telenet.be>

Hi,

when writing a simple cpp function to be run in R I obtain a compilation error as soon as I include fstream. Any hints of what goes wrong and how to fix it? It's Windows 7 64-bit, R-3.1.2 and Rtools32. An example to recreate the error:

    #include <R.h>
    #include <Rdefines.h>
    #include <fstream>
    using namespace std;
    
    extern "C" SEXP test(SEXP x) {
      SEXP result;
      
      PROTECT(result = allocVector(REALSXP,1));
      REAL(result)[0] = REAL(x)[0]*5;
    
      UNPROTECT(1);
      return result;
    }

Output:

    > R CMD SHLIB test.cpp
    g++ -m64 -I"C:/PROGRA~1/R/R-31~1.2/include" -DNDEBUG     -I"d:/RCompile/CRANpkg/
    extralibs64/local/include"     -O2 -Wall  -mtune=core2 -c test.cpp -o test.o
    In file included from c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/
    ../../../../include/c++/4.6.3/fstream:42:0,
                     from test.cpp:3:
    c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+
    +/4.6.3/bits/codecvt.h:216:45: error: macro "length" passed 4 arguments, but tak
    es just 1
    In file included from c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/
    ../../../../include/c++/4.6.3/fstream:921:0,
                     from test.cpp:3:
    c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+
    +/4.6.3/bits/fstream.tcc:826:60: error: macro "length" passed 4 arguments, but t
    akes just 1
    c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+
    +/4.6.3/bits/fstream.tcc:943:39: error: macro "length" passed 4 arguments, but t
    akes just 1
    In file included from c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/
    ../../../../include/c++/4.6.3/fstream:42:0,
                     from test.cpp:3:
    c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+
    +/4.6.3/bits/codecvt.h:215:7: error: expected ';' at end of member declaration
    c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+
    +/4.6.3/bits/codecvt.h:217:7: error: expected unqualified-id before '{' token
    make: *** [test.o] Error 1 

Thanks,
sunaga


From jdnewmil at dcn.davis.CA.us  Mon Feb  2 22:24:32 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 02 Feb 2015 13:24:32 -0800
Subject: [R] How to enable https for R 3.1.2 on windows 8.1
In-Reply-To: <CAC1VXC7r0=o-6+9OU-X4ec=Tv_84sFde7vOPKwr84fxwGTnn4w@mail.gmail.com>
References: <CAC1VXC6de=3XzNOBmO8gm5CYr65X9NXw=+BpT9kTuxrN-Mm=uw@mail.gmail.com>
	<91C59476-A35C-48F9-A679-DB782CB96F11@dcn.davis.CA.us>
	<CAC1VXC42D=0svuys9GHGwFePsXAozoggHEs_Bkgh_hqu12EhHg@mail.gmail.com>
	<D8BFBC3D-ACCC-403B-97C8-2D88DAF374BD@dcn.davis.CA.us>
	<CAC1VXC7r0=o-6+9OU-X4ec=Tv_84sFde7vOPKwr84fxwGTnn4w@mail.gmail.com>
Message-ID: <4265A30A-FA50-4E83-912A-E67D4763A406@dcn.davis.CA.us>

I am not aware that Windows demands double quotes for anything in R. I think the spaces was the problem.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 2, 2015 11:29:20 AM PST, John Kalb <john.kalb at gmail.com> wrote:
>Changing urls to remove spaces and replace single quotes with double
>quotes
>resolved the issue.  Apparently windows demands double quotes.
>
>Thanks for your help.
>
>On Mon, Feb 2, 2015 at 1:50 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Cc'd back to the list... I am a bad bet for one-on-one help.
>>
>> Showing that your libcurl claims to support HTTPS is progress. I
>think
>> that at this point you should read the last sentence in the curl FAQ
>3.21,
>> which I found by searching for "protocol https not supported or
>disabled in
>> libcurl".
>>
>> http://curl.haxx.se/docs/faq.html
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 2, 2015 9:21:05 AM PST, John Kalb <john.kalb at gmail.com>
>wrote:
>> >Honestly.  I ran the search you suggested and didn't find anything
>that
>> >helped.  I did come across the curlVersion function and ran it right
>> >after
>> >receiving the error message.  It seems to indicate that https is
>> >available.  I don't see a way forward.
>> >
>> >Error in function (type, msg, asError = TRUE)  :
>> >  Protocol " https" not supported or disabled in libcurl
>> >> curlVersion()$protocol
>> >[1] "dict"   "file"   "ftp"    "ftps"   "gopher" "http"   "https"
>> >"imap"
>> >  "imaps"  "ldap"
>> >[11] "pop3"   "pop3s"  "rtmp"   "rtsp"   "scp"    "sftp"   "smtp"
>> >"smtps"
>> > "telnet" "tftp"
>> >
>> >On Sun, Feb 1, 2015 at 1:58 PM, Jeff Newmiller
>> ><jdnewmil at dcn.davis.ca.us>
>> >wrote:
>> >
>> >> Honestly? Did you try "rcurl https windows" (without the quotes)?
>> >>
>>
>>
>>---------------------------------------------------------------------------
>> >> Jeff Newmiller                        The     .....       ..... 
>Go
>> >Live...
>> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live
>> >> Go...
>> >>                                       Live:   OO#.. Dead: OO#..
>> >Playing
>> >> Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>> >> /Software/Embedded Controllers)               .OO#.       .OO#.
>> >rocks...1k
>> >>
>>
>>
>>---------------------------------------------------------------------------
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>> >> On February 1, 2015 8:56:00 AM PST, John Kalb
><john.kalb at gmail.com>
>> >wrote:
>> >> >I run the code below successfully on Mac and Ubuntu successfully.
>> >> >When I run on Windows, I get the results shown.  How do I get the
>> >code
>> >> >to work on Windows? I've googled extensively with no success.
>Thanks
>> >> >in advance.
>> >> >
>> >> >require(twitteR)
>> >> >
>> >> >Loading required package: twitteR
>> >> >Loading required package: ROAuth
>> >> >Loading required package: RCurl
>> >> >Loading required package: bitops
>> >> >Loading required package: rjson
>> >> >> cred <- OAuthFactory $ new( consumerKey = my.key,
>consumerSecret =
>> >> >my.secret, requestURL =' https:// api.twitter.com/ oauth/
>> >> >request_token', accessURL =' https:// api.twitter.com/ oauth/
>> >> >access_token', authURL =' https:// api.twitter.com/ oauth/
>> >authorize')
>> >> >> cred$handshake(cainfo =
>> >"C:/users/john/documents/twitter/cacert.pem")
>> >> >Error in function (type, msg, asError = TRUE)  :
>> >> >  Protocol " https" not supported or disabled in libcurl
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> >______________________________________________
>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >PLEASE do read the posting guide
>> >> >http://www.R-project.org/posting-guide.html
>> >> >and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >>
>>
>>


From wdunlap at tibco.com  Mon Feb  2 22:29:19 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 2 Feb 2015 13:29:19 -0800
Subject: [R] rtools fstream error
In-Reply-To: <1940557801.24359068.1422911497949.JavaMail.root@telenet.be>
References: <1940557801.24359068.1422911497949.JavaMail.root@telenet.be>
Message-ID: <CAF8bMcZB=9xKtcVWuhfR1TcTey3yAkC02py8KDH3Aso0T1Xxig@mail.gmail.com>

Try adding the line
  #define R_NO_REMAP
to the top of your file (before any #include's) so the R
include files don't define length(x).

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Feb 2, 2015 at 1:11 PM, <sunaga at telenet.be> wrote:

> Hi,
>
> when writing a simple cpp function to be run in R I obtain a compilation
> error as soon as I include fstream. Any hints of what goes wrong and how to
> fix it? It's Windows 7 64-bit, R-3.1.2 and Rtools32. An example to recreate
> the error:
>
>     #include <R.h>
>     #include <Rdefines.h>
>     #include <fstream>
>     using namespace std;
>
>     extern "C" SEXP test(SEXP x) {
>       SEXP result;
>
>       PROTECT(result = allocVector(REALSXP,1));
>       REAL(result)[0] = REAL(x)[0]*5;
>
>       UNPROTECT(1);
>       return result;
>     }
>
> Output:
>
>     > R CMD SHLIB test.cpp
>     g++ -m64 -I"C:/PROGRA~1/R/R-31~1.2/include" -DNDEBUG
>  -I"d:/RCompile/CRANpkg/
>     extralibs64/local/include"     -O2 -Wall  -mtune=core2 -c test.cpp -o
> test.o
>     In file included from
> c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/
>     ../../../../include/c++/4.6.3/fstream:42:0,
>                      from test.cpp:3:
>
> c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+
>     +/4.6.3/bits/codecvt.h:216:45: error: macro "length" passed 4
> arguments, but tak
>     es just 1
>     In file included from
> c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/
>     ../../../../include/c++/4.6.3/fstream:921:0,
>                      from test.cpp:3:
>
> c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+
>     +/4.6.3/bits/fstream.tcc:826:60: error: macro "length" passed 4
> arguments, but t
>     akes just 1
>
> c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+
>     +/4.6.3/bits/fstream.tcc:943:39: error: macro "length" passed 4
> arguments, but t
>     akes just 1
>     In file included from
> c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/
>     ../../../../include/c++/4.6.3/fstream:42:0,
>                      from test.cpp:3:
>
> c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+
>     +/4.6.3/bits/codecvt.h:215:7: error: expected ';' at end of member
> declaration
>
> c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+
>     +/4.6.3/bits/codecvt.h:217:7: error: expected unqualified-id before
> '{' token
>     make: *** [test.o] Error 1
>
> Thanks,
> sunaga
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From qkou at umail.iu.edu  Mon Feb  2 22:42:36 2015
From: qkou at umail.iu.edu (Qiang Kou)
Date: Mon, 2 Feb 2015 16:42:36 -0500
Subject: [R] A good way to debug a c++ library embedded to an R code
In-Reply-To: <CAH-FEnhqiY0XbBYy_GSu5wm2UfFNcmJ73dS5rZcRPEGwx=TX4w@mail.gmail.com>
References: <CAH-FEnhqiY0XbBYy_GSu5wm2UfFNcmJ73dS5rZcRPEGwx=TX4w@mail.gmail.com>
Message-ID: <CAJ_LAMAeRc+LSfD4=vPdM1y5r11RX2uCqPtkH4HZvd_dN=TzzQ@mail.gmail.com>

If you are familiar with GDB, you can just start R by "R -d gdb".

Dirk gave a good example on SO, please check the link below:

http://stackoverflow.com/questions/11345537/debugging-line-by-line-of-rcpp-generated-dll-under-windows

Best,

KK

On Mon, Feb 2, 2015 at 2:00 PM, Charles Novaes de Santana <
charles.santana at gmail.com> wrote:

> Dear all,
>
> I am using R CMD SHLIB to compile a c++ code into a library (.so) and
> dyn.load to load this library into a R code. I am facing some problems in
> the c++ part that I can not figure out how to solve. Do you recomend any
> good way to debug this R + C++ program? If I was programming only in C++ I
> would use GDB.
>
> I would much appreciate any help or suggestion!
>
> Best regards,
>
> Charles
>
> --
> Um ax?! :)
>
> --
> Charles Novaes de Santana, PhD
> http://www.imedea.uib-csic.es/~charles
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Qiang Kou
qkou at umail.iu.edu
School of Informatics and Computing, Indiana University

	[[alternative HTML version deleted]]


From sunaga at telenet.be  Mon Feb  2 23:25:02 2015
From: sunaga at telenet.be (sunaga at telenet.be)
Date: Mon, 2 Feb 2015 23:25:02 +0100 (CET)
Subject: [R] rtools fstream error
In-Reply-To: <CAF8bMcZB=9xKtcVWuhfR1TcTey3yAkC02py8KDH3Aso0T1Xxig@mail.gmail.com>
References: <1940557801.24359068.1422911497949.JavaMail.root@telenet.be>
	<CAF8bMcZB=9xKtcVWuhfR1TcTey3yAkC02py8KDH3Aso0T1Xxig@mail.gmail.com>
Message-ID: <1585254127.24415182.1422915902393.JavaMail.root@telenet.be>

Thank you, it worked. 
For completeness, had to add Rf_ in front of allocVector (and possibly any other function from Rdefines.h) 


----- Original Message -----

From: "William Dunlap" <wdunlap at tibco.com> 
To: sunaga at telenet.be 
Cc: r-help at r-project.org 
Sent: Monday, February 2, 2015 10:29:19 PM 
Subject: Re: [R] rtools fstream error 

Try adding the line 
#define R_NO_REMAP 
to the top of your file (before any #include's) so the R 
include files don't define length(x). 

Bill Dunlap 
TIBCO Software 
wdunlap tibco.com 

On Mon, Feb 2, 2015 at 1:11 PM, < sunaga at telenet.be > wrote: 


Hi, 

when writing a simple cpp function to be run in R I obtain a compilation error as soon as I include fstream. Any hints of what goes wrong and how to fix it? It's Windows 7 64-bit, R-3.1.2 and Rtools32. An example to recreate the error: 

#include <R.h> 
#include <Rdefines.h> 
#include <fstream> 
using namespace std; 

extern "C" SEXP test(SEXP x) { 
SEXP result; 

PROTECT(result = allocVector(REALSXP,1)); 
REAL(result)[0] = REAL(x)[0]*5; 

UNPROTECT(1); 
return result; 
} 

Output: 

> R CMD SHLIB test.cpp 
g++ -m64 -I"C:/PROGRA~1/R/R-31~1.2/include" -DNDEBUG -I"d:/RCompile/CRANpkg/ 
extralibs64/local/include" -O2 -Wall -mtune=core2 -c test.cpp -o test.o 
In file included from c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/ 
../../../../include/c++/4.6.3/fstream:42:0, 
from test.cpp:3: 
c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+ 
+/4.6.3/bits/codecvt.h:216:45: error: macro "length" passed 4 arguments, but tak 
es just 1 
In file included from c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/ 
../../../../include/c++/4.6.3/fstream:921:0, 
from test.cpp:3: 
c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+ 
+/4.6.3/bits/fstream.tcc:826:60: error: macro "length" passed 4 arguments, but t 
akes just 1 
c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+ 
+/4.6.3/bits/fstream.tcc:943:39: error: macro "length" passed 4 arguments, but t 
akes just 1 
In file included from c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/ 
../../../../include/c++/4.6.3/fstream:42:0, 
from test.cpp:3: 
c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+ 
+/4.6.3/bits/codecvt.h:215:7: error: expected ';' at end of member declaration 
c:\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c+ 
+/4.6.3/bits/codecvt.h:217:7: error: expected unqualified-id before '{' token 
make: *** [test.o] Error 1 

Thanks, 
sunaga 

______________________________________________ 
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code. 






	[[alternative HTML version deleted]]


From mikaelmilhoj at gmail.com  Mon Feb  2 23:42:40 2015
From: mikaelmilhoj at gmail.com (=?UTF-8?Q?Mikael_Olai_Milh=C3=B8j?=)
Date: Mon, 2 Feb 2015 23:42:40 +0100
Subject: [R] Plot residuals against standard normal distribution
Message-ID: <CACM6noZW5MK2736HTS6_f25ezQE1zNwuCc83WcyaP4jd5w6KeQ@mail.gmail.com>

Hi,

I'm having trouble trying to plot the density of the residuals against the
standard normal distribution N(0,1). (I'm trying to see if my residuals are
well-behaved).

I know hwo to calculate the standardized residuals (I guess that there may
be a simple way using a R function) and then plot this by using the density
function

y<-(model$residuals-mean(model$residuals))/sd(model$residuals)
plot(density(y))

But I don't know how to add the N(0,1) curve. Any suggestions? Thanks in
advance


/Mikael

	[[alternative HTML version deleted]]


From kennethrrr at gmail.com  Tue Feb  3 00:07:06 2015
From: kennethrrr at gmail.com (Kenneth Z)
Date: Mon, 2 Feb 2015 18:07:06 -0500
Subject: [R] Maxent does not work
In-Reply-To: <B635B7F5-CC4F-49E0-A504-700723DFF1F2@gmail.com>
References: <1355330088.98430.YahooMailClassic@web190503.mail.sg3.yahoo.com>
	<813743db-9d8f-4677-b0b7-b1c4a527ddf2@email.android.com>
	<B635B7F5-CC4F-49E0-A504-700723DFF1F2@gmail.com>
Message-ID: <CE63EFA7-1E11-4F20-AB7C-DBD12AB783F6@gmail.com>

Yesterday I installed the most recent R and maxent package, but it stopped working. Even a simple command like
Model <- maxent(matrix(c(1,2,3,4,5,6,7,8), nrow=2, ncol=4),c(1,-1))

will cause a fatal error in R. I am attaching a screenshot to this email.
 Any help will be appreciated.

Best regards,
Ken




> On Dec 12, 2012, at 4:13 PM, Kenneth Z <kennethrrr at gmail.com> wrote:
> 
> I found that the optim() function does not always reach the real minimum. Is it because the solution is trapped at a local minimum?
> 
> Thanks!
> Ken
> 
> 
> 
>> On Dec 12, 2012, at 2:17 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> 
>> ... origin pro?
>> 
>> Then why are you here?
>> 
>> It is not clear from your message that this has anything to do with R.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                     Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> --------------------------------------------------------------------------- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> vishal katoch <vkatoch007 at yahoo.co.in> wrote:
>> 
>>> Hello,
>>> i am working in origin pro,
>>> i want to plot a graph as like a pdf attached but with black and white
>>> lines.
>>> here radial axis varies from 0 to 1. and angular axis from 0 degree to
>>> 60 degree.and third axis which is depend on both radial and axial gives
>>> non intersecting lines.
>>> how can i read the data from plot for replot.
>>> vikas 
>>> 
>>> 
>>> 
>>> 
>>> ------------------------------------------------------------------------
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Tue Feb  3 00:18:13 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 3 Feb 2015 00:18:13 +0100
Subject: [R] Plot residuals against standard normal distribution
In-Reply-To: <CACM6noZW5MK2736HTS6_f25ezQE1zNwuCc83WcyaP4jd5w6KeQ@mail.gmail.com>
References: <CACM6noZW5MK2736HTS6_f25ezQE1zNwuCc83WcyaP4jd5w6KeQ@mail.gmail.com>
Message-ID: <57A1901D-6806-441F-BD72-198BDBDC99AB@gmail.com>


> On 02 Feb 2015, at 23:42 , Mikael Olai Milh?j <mikaelmilhoj at gmail.com> wrote:
> 
> Hi,
> 
> I'm having trouble trying to plot the density of the residuals against the
> standard normal distribution N(0,1). (I'm trying to see if my residuals are
> well-behaved).
> 
> I know hwo to calculate the standardized residuals (I guess that there may
> be a simple way using a R function) and then plot this by using the density
> function
> 
> y<-(model$residuals-mean(model$residuals))/sd(model$residuals)
> plot(density(y))
> 
> But I don't know how to add the N(0,1) curve. Any suggestions? Thanks in
> advance

I'd try

curve(dnorm(x), add=TRUE)

Some diddling of ylim= is usually required. 


I'd usually prefer qqnorm() for normality checks, though; it is pretty hard to assess the tails of density plots.
 
Also notice rstandard(), rstudent().

-pd

> 
> 
> /Mikael
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From p_connolly at slingshot.co.nz  Tue Feb  3 00:18:01 2015
From: p_connolly at slingshot.co.nz (p_connolly)
Date: Tue, 03 Feb 2015 12:18:01 +1300
Subject: [R] Boundaries and deldir
In-Reply-To: <54CF6392.1050701@auckland.ac.nz>
References: <b7eb2bec9297830b473b3126207ef7d2@slingshot.co.nz>
	<54CF6392.1050701@auckland.ac.nz>
Message-ID: <566bf82720cb9ce3f70cb420b281f460@slingshot.co.nz>

On 2015-02-03 00:46, Rolf Turner wrote:

[...]


> The deldir function creates a Delaunay triangulation/Dirichlet
> tessellation inside a "rectangular window" (denoted by "rw" in the
> argument list).  This is the only boundary invoked or involved.
> 
> The function plot.tile.list() will *plot* the Dirichlet tessellation
> "clipped" to a specified polygon.  But that is just for *plotting*.  I
> am not sure that I really understand the idea of a "boundary beyond
> which the triangulation ceases".  The Delaunay triangulation is a
> finite
> structure; its outer boundary is the convex hull of the set of points
> being triangulated.  You cannot confine it to a smaller region without
> losing some of those points.
> 
> If you can explain what you really want to do, perhaps I can help.

This should make it clearer:


Suppose we had trees planted at the following coordinates

x   <- c(2.3,3.0,7.0,1.0,3.0,8.0)
y   <- c(2.3,3.0,2.0,5.0,8.0,9.0)

We can get a plot of the layout and polygons that "belong" to each tree.

del <- deldir(x,y,list(ndx=2,ndy=2),c(0,10,0,10), plotit = TRUE, wl = 
'tess')

The areas of the polygons so drawn can be seen in this dataframe.

del$summary

Apart from those immediately adjacent to the corner (dummy) points,
the areas represent the amount of space the roots could grow at a
uniform rate before encountering a neighbouring tree's roots or a
notional concrete path as described by the dummy triangular points,
shown by this red square:

polygon(y=c(0,0,10,10,0), x=c(0,10, 10, 0, 0), border = "red")

My question relates to the possibility of doing something similar if
the notional path was described by this green polygon:

polygon(y=c(0.5, 1, 1.5, 9.5, 10, 8.5, 0.5),
         x=c(0.5, 8, 9.5, 9, 7, .7, 0.5), border = "green")

Judging by references to 'rw', a rectangular window, I suspect not.


Thanks for the help.

Patrick



> 
> cheers,
> 
> Rolf


From bretschr at xs4all.nl  Tue Feb  3 00:39:27 2015
From: bretschr at xs4all.nl (Franklin Bretschneider)
Date: Tue, 3 Feb 2015 00:39:27 +0100
Subject: [R] FFT Normalization Documentation
In-Reply-To: <1985531401.416848.1422883625463.JavaMail.open-xchange@omgreatgod.store>
References: <1985531401.416848.1422883625463.JavaMail.open-xchange@omgreatgod.store>
Message-ID: <E17505B1-8B48-495B-8532-CE914D86AC33@xs4all.nl>

Dear Eike Petersen,


Re:

> Hello everyone,
> 
> the docpage for the fft function states:
> 
> ?Description: Performs the Fast Fourier Transform of an array.?
> 
> and
> 
> ?Arguments ? inverse: if ?TRUE?, the unnormalized inverse transform is computed
> (the inverse has a ?+? in the exponent of e, but here, we do _not_ divide by
> ?1/length(x)?).?
> 
> Judging from this, I would expect ?fft(x)? to yield the correct FFT of x, and
> ?fft(X, inverse = TRUE) / length(X)? to yield the correct inverse FFT of X.
> 
> However, it seems to me that actually the result of ?fft(x)? should be scaled by
> ?1/length(x)?, while ?fft(X, inverse=TRUE)? seems to yield a correct result by
> default:
> 
> t <- seq(0.001, 1, 0.001)
> y <- 1 + sin(2*pi*20*t) + 1.5 * sin(2*pi*30*t)
> Y <- fft(y)
> dev.new()
> plot(abs(Y)) ## Shows peaks at amplitudes 1000, 500 and 750, while they should
> be at amplitude 1, 0.5 and 0.75.
> y2 <- Re(fft(Y / length(Y), inverse = TRUE))
> max(abs(y-y2)) ## The IFFT yields a correctly scaled result by default, if
> applied to a correctly scaled FFT.
> 
> Did I get something wrong? If not, having spent quite some time figuring this
> out, I would like to see the documentation clearly pointing this out. I find the
> current text rather confusing.
> 
> On another note: I have spent some time working on demo files that showcase some
> of the properties of the FFT and their implementation in R. I have done this
> primarily for myself, as I keep forgetting how these things work, but I thought
> that it might be helpful to others as well. Any hints on where/how I should
> publish such a thing?
> 
> Kind regards and many thanks in advance,
> 
> Eike
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


As far as I know an FFT must be normalized and folded to obtain a spectrum in the form we like, so this would be my version:

#  your time signal:

t <- seq(0.001, 1, 0.001)
y <- 1 + sin(2*pi*20*t) + 1.5 * sin(2*pi*30*t)

# find time and frequency calibration:

n = length(y)
dt = t[2]-t[1]
fNyq = 1/(2*dt)
tmax = max(t)
df = 1/tmax

#  make frequency vector to display as x-values of the spectrum rather than the index.

f = seq(-fNyq, fNyq-df, by=df)

#  make folding mask

mask=rep(c(1, -1),length.out=n)

#  fold the spectrum around the Nyquist frequency; so the DC value (f=0) is in the middle; the - and + max frequency at the ends.

yy = y * mask

#  #  Then do the FFT

YY <- fft(yy)

Plot the amplitude spectrum vector against the freq. vector

plot(f,abs(YY), type='h') 



--------

It would be a good idea to put such an example in the help pages indeed. 
The short example given in the manual isn't of much help for the usual (periodic!) time signals.

Hoping this helps, I remain

With best wishes,

Frank
----






Franklin Bretschneider
Dept of Biology
Utrecht University
bretschr at xs4all.nl


From mehall at blm.gov  Tue Feb  3 01:01:59 2015
From: mehall at blm.gov (Hall, Mark)
Date: Mon, 2 Feb 2015 16:01:59 -0800
Subject: [R] Plot residuals against standard normal distribution
In-Reply-To: <CACM6noZW5MK2736HTS6_f25ezQE1zNwuCc83WcyaP4jd5w6KeQ@mail.gmail.com>
References: <CACM6noZW5MK2736HTS6_f25ezQE1zNwuCc83WcyaP4jd5w6KeQ@mail.gmail.com>
Message-ID: <CANNh0zcEcdsBMYcoNxLGo5n+LZTshJ1f+R74b_LVmk25VknJbQ@mail.gmail.com>

Since you are plotting densities, check out the sm package.  It has been
over a year or so since I've used it, but there was a setting on the
univariate densities to check the data against a normal distribution.

Best, MEH



On Mon, Feb 2, 2015 at 2:42 PM, Mikael Olai Milh?j <mikaelmilhoj at gmail.com>
wrote:

> Hi,
>
> I'm having trouble trying to plot the density of the residuals against the
> standard normal distribution N(0,1). (I'm trying to see if my residuals are
> well-behaved).
>
> I know hwo to calculate the standardized residuals (I guess that there may
> be a simple way using a R function) and then plot this by using the density
> function
>
> y<-(model$residuals-mean(model$residuals))/sd(model$residuals)
> plot(density(y))
>
> But I don't know how to add the N(0,1) curve. Any suggestions? Thanks in
> advance
>
>
> /Mikael
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Mark E. Hall, PhD
Assistant Field Manager, Black Rock Field Office
Winnemucca District Office
775-623-1529.

	[[alternative HTML version deleted]]


From bharatbargujar at gmail.com  Tue Feb  3 01:05:50 2015
From: bharatbargujar at gmail.com (Bharat Bargujar)
Date: Mon, 2 Feb 2015 18:05:50 -0600
Subject: [R] Asymmetric Cost assignment for SVM | Help
Message-ID: <CAF3tJnF0b2qwHP5_rzys326xUBUv+rTjOjkn3pBUL7J+_nObTQ@mail.gmail.com>

Hi Friends,

I want to assign asymmetric cost values at the time training.

For example : For false negative cost should be 10 and for For false
positive it should be 1.

Can some help me with this.


Code:

svmFit <- train(Y ~ .,
                data = train,
                method = "svmRadial",
                preProc = c("center", "scale"),
                cost=5,
                trControl = trainControl(method = "repeatedcv", repeats =
5,classProbs =  TRUE))


So I need a way to force cost of 10 for false negative and 1 for false
positive at time of training.

Regards,
Bharat

	[[alternative HTML version deleted]]


From phaedrusv at gmail.com  Tue Feb  3 01:49:41 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Tue, 03 Feb 2015 00:49:41 +0000
Subject: [R] Updating to R 3.1.1. - impacts on existing packages
Message-ID: <54D01B25.5030405@gmail.com>

Hi list

I've signed up for a Coursera course on exploratory data analysis, and 
the recommendation is to update to R base 3.1.1. I'm currently on 3.0.2.

If I do upgrade, what is the best way for me to upgrade all my packages 
for compatibility? Would this be accomplished through the command:

 > update.packages()

Also, any ideas what percentage of the packages have been updated to 
work with 3.1.1. ? I'm just wanting to do a risk evaluation because I 
don't want to lose access to packages such as ggplot2, sna, statnet, 
FactoMineR, and several others through upgrading.

Thanks for any steers

Sun


From hb at biostat.ucsf.edu  Tue Feb  3 02:17:38 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 2 Feb 2015 17:17:38 -0800
Subject: [R] Updating to R 3.1.1. - impacts on existing packages
In-Reply-To: <54D01B25.5030405@gmail.com>
References: <54D01B25.5030405@gmail.com>
Message-ID: <CAFDcVCTxzDpFLH-WwBC3UBRqdeuzKpKRYGk1xgYSN+xdFKbQQA@mail.gmail.com>

On Mon, Feb 2, 2015 at 4:49 PM, Sun Shine <phaedrusv at gmail.com> wrote:
> Hi list
>
> I've signed up for a Coursera course on exploratory data analysis, and the
> recommendation is to update to R base 3.1.1. I'm currently on 3.0.2.
>
> If I do upgrade, what is the best way for me to upgrade all my packages for
> compatibility? Would this be accomplished through the command:
>
>> update.packages()
>
> Also, any ideas what percentage of the packages have been updated to work
> with 3.1.1. ? I'm just wanting to do a risk evaluation because I don't want
> to lose access to packages such as ggplot2, sna, statnet, FactoMineR, and
> several others through upgrading.

All package on CRAN should be up-to-date (that's almost the definition
of CRAN; if a package is not updated in time it's likely to be
archived due to lack of maintenance).  When in doubt, have a look at
their individual CRAN pages, e.g.
http://cran.r-project.org/package=ggplot2.  Look for the "r-release".

Note that "r-release" always refers to the latest stable official R
release, which currently is R 3.1.2.  You should upgrade to that
version and not 3.1.1.  It's pretty safe to always install the most
recent stable release version of R.  If you're using an old version of
R, like you do, it's more likely that you run into problems in general
than if you use the most recent version.  So, avoid sticking with old
version and make to upgrade whenever a new release come out.

/Henrik

>
> Thanks for any steers
>
> Sun
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Feb  3 02:45:07 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 2 Feb 2015 17:45:07 -0800 (PST)
Subject: [R] Updating to R 3.1.1. - impacts on existing packages
In-Reply-To: <CAFDcVCTxzDpFLH-WwBC3UBRqdeuzKpKRYGk1xgYSN+xdFKbQQA@mail.gmail.com>
References: <54D01B25.5030405@gmail.com>
	<CAFDcVCTxzDpFLH-WwBC3UBRqdeuzKpKRYGk1xgYSN+xdFKbQQA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1502021741000.2397@pedal.dcn.davis.ca.us>

I think you missed the question, Henrik, which was directed at updating 
the local 3.1 library with all of the packages that were in the 3.0 
library.

The usual advice for this is to copy your 3.0 library onto your 3.1 
library (duplicate directory structure) so R knows what packages you want 
to use and then use update packages. In general the copied directories 
will not work directly, but R can update them. Note that some packages are 
dropped due to better support in different packages or lack of maintainer 
activity, so not all packages thus copied may end up usable.

On Mon, 2 Feb 2015, Henrik Bengtsson wrote:

> On Mon, Feb 2, 2015 at 4:49 PM, Sun Shine <phaedrusv at gmail.com> wrote:
>> Hi list
>>
>> I've signed up for a Coursera course on exploratory data analysis, and the
>> recommendation is to update to R base 3.1.1. I'm currently on 3.0.2.
>>
>> If I do upgrade, what is the best way for me to upgrade all my packages for
>> compatibility? Would this be accomplished through the command:
>>
>>> update.packages()
>>
>> Also, any ideas what percentage of the packages have been updated to work
>> with 3.1.1. ? I'm just wanting to do a risk evaluation because I don't want
>> to lose access to packages such as ggplot2, sna, statnet, FactoMineR, and
>> several others through upgrading.
>
> All package on CRAN should be up-to-date (that's almost the definition
> of CRAN; if a package is not updated in time it's likely to be
> archived due to lack of maintenance).  When in doubt, have a look at
> their individual CRAN pages, e.g.
> http://cran.r-project.org/package=ggplot2.  Look for the "r-release".
>
> Note that "r-release" always refers to the latest stable official R
> release, which currently is R 3.1.2.  You should upgrade to that
> version and not 3.1.1.  It's pretty safe to always install the most
> recent stable release version of R.  If you're using an old version of
> R, like you do, it's more likely that you run into problems in general
> than if you use the most recent version.  So, avoid sticking with old
> version and make to upgrade whenever a new release come out.
>
> /Henrik
>
>>
>> Thanks for any steers
>>
>> Sun
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From steve.taylor at aut.ac.nz  Tue Feb  3 02:57:05 2015
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Tue, 3 Feb 2015 01:57:05 +0000
Subject: [R] the less-than-minus gotcha
In-Reply-To: <21711.37801.439519.676495@stat.math.ethz.ch>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>,
	<21711.37801.439519.676495@stat.math.ethz.ch>
Message-ID: <CCE952776B6679469977532BD863C39C9A66DF62@Lewis.autuni.aut.ac.nz>

Responding to several messages in this thread...

> > All the more reason to use = instead of <-
> Definitely not!

Martin and Rolf are right, it's not a reason for that; I wrote that quickly without thinking it through.  An "=" user might be more likely to fall for the gotcha, if not spacing their code nicely.  So the lesson learned from the gotcha is that it's good to space your code nicely, as others have siad, not which assignment symbol to use.

However, I continue to use "=" for assignment on a daily basis without any problems, as I have done for many years.  I remain unconvinced by any and all of these arguments against it in favour of "<-".  People telling me that I "should" use the arrow need better agruments than what I've seen so far.

I find "<-" ugly and "->" useless/pointless, whereas "=" is simpler and also nicely familiar from my experience in other languages.  It doesn't matter to me that "=" is not commutative because I don't need it to be.

> Further it can be nicely marked up by a real "left arrow" 
> by e.g. the listings LaTeX 'listings' package...

Now that's just silly, turning R code into graphical characters that are not part of the R language.

>  foo(x = y) and foo(x <- y)

I'm well aware of this distinction and it never causes me any problems.  The latter is an example of bad (obfuscated) coding, IMHO; it should be done in two lines for clarity as follows:

x = y
foo(x)

> Using = has it's problems too.
Same goes for apostrophes.

Shall we discuss putting "else" at the start of line next?

cheers,
     Steve


From istazahn at gmail.com  Tue Feb  3 03:36:15 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 2 Feb 2015 21:36:15 -0500
Subject: [R] the less-than-minus gotcha
In-Reply-To: <CCE952776B6679469977532BD863C39C9A66DF62@Lewis.autuni.aut.ac.nz>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
	<21711.37801.439519.676495@stat.math.ethz.ch>
	<CCE952776B6679469977532BD863C39C9A66DF62@Lewis.autuni.aut.ac.nz>
Message-ID: <CA+vqiLErAgNz1e5T2cTTbYMz0hEeNEh31o1Ts+P7HB6MrgwsWw@mail.gmail.com>

On Mon, Feb 2, 2015 at 8:57 PM, Steve Taylor <steve.taylor at aut.ac.nz> wrote:
> Responding to several messages in this thread...
>
>> > All the more reason to use = instead of <-
>> Definitely not!
>
> Martin and Rolf are right, it's not a reason for that; I wrote that quickly without thinking it through.  An "=" user might be more likely to fall for the gotcha, if not spacing their code nicely.  So the lesson learned from the gotcha is that it's good to space your code nicely, as others have siad, not which assignment symbol to use.
>
> However, I continue to use "=" for assignment on a daily basis without any problems, as I have done for many years.  I remain unconvinced by any and all of these arguments against it in favour of "<-".  People telling me that I "should" use the arrow need better agruments than what I've seen so far.

Fair enough, but you skipped right past the most important one: it
makes code easier to read. It's very nice to be able to visually scan
through the code and easily see where assignment happens.

>
> I find "<-" ugly and "->" useless/pointless,

I never used it either, until recently when I started using magrittr.
Maybe still pointless, but I find the form
> library(magrittr)
>
> "hello" %>%
+     paste("world,") %>%
+     paste("my name is") %>%
+     paste("Ista") -> hi
> hi
[1] "hello world, my name is Ista"

quite nice.

--Ista

whereas "=" is simpler and also nicely familiar from my experience in
other languages.  It doesn't matter to me that "=" is not commutative
because I don't need it to be.
>
>> Further it can be nicely marked up by a real "left arrow"
>> by e.g. the listings LaTeX 'listings' package...
>
> Now that's just silly, turning R code into graphical characters that are not part of the R language.
>
>>  foo(x = y) and foo(x <- y)
>
> I'm well aware of this distinction and it never causes me any problems.  The latter is an example of bad (obfuscated) coding, IMHO; it should be done in two lines for clarity as follows:
>
> x = y
> foo(x)
>
>> Using = has it's problems too.
> Same goes for apostrophes.
>
> Shall we discuss putting "else" at the start of line next?
>
> cheers,
>      Steve
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From steve.taylor at aut.ac.nz  Tue Feb  3 03:46:57 2015
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Tue, 3 Feb 2015 02:46:57 +0000
Subject: [R] the less-than-minus gotcha
In-Reply-To: <CA+vqiLErAgNz1e5T2cTTbYMz0hEeNEh31o1Ts+P7HB6MrgwsWw@mail.gmail.com>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
	<21711.37801.439519.676495@stat.math.ethz.ch>
	<CCE952776B6679469977532BD863C39C9A66DF62@Lewis.autuni.aut.ac.nz>
	<CA+vqiLErAgNz1e5T2cTTbYMz0hEeNEh31o1Ts+P7HB6MrgwsWw@mail.gmail.com>
Message-ID: <CCE952776B6679469977532BD863C39C9A66F6BC@Lewis.autuni.aut.ac.nz>

I disagree.  Assignments in my code are all lines that look like this:

variable = expression

They are easy to find and easy to read.

-----Original Message-----
From: Ista Zahn [mailto:istazahn at gmail.com] 
Sent: Tuesday, 3 February 2015 3:36p
To: Steve Taylor
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] the less-than-minus gotcha

On Mon, Feb 2, 2015 at 8:57 PM, Steve Taylor <steve.taylor at aut.ac.nz> wrote:
Fair enough, but you skipped right past the most important one: it
makes code easier to read. It's very nice to be able to visually scan
through the code and easily see where assignment happens.


From jdnewmil at dcn.davis.CA.us  Tue Feb  3 03:53:39 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 2 Feb 2015 18:53:39 -0800
Subject: [R] the less-than-minus gotcha
In-Reply-To: <CCE952776B6679469977532BD863C39C9A66DF62@Lewis.autuni.aut.ac.nz>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>,
	<21711.37801.439519.676495@stat.math.ethz.ch>
	<CCE952776B6679469977532BD863C39C9A66DF62@Lewis.autuni.aut.ac.nz>
Message-ID: <B9408055-FF06-49EA-BF95-1FB3BB4496A9@dcn.davis.CA.us>

I did not start out liking <-, but I am quite attached to it now, and even Rcpp feels weird to me now. This may seem like yet another variation on a theme that you don't find compelling, but I find that

f(x=x)

makes sense when scope is considered, but

x=x

on its own is silly. That is why I prefer to reserve = for assigning parameters... I use it to clarify that I am crossing scope boundaries, while <- never does. (<<- is a dangerous animal, though... to be used only locally in nested function definitions).

In my view, this is similar to preferring == from C-derived syntaxes over the overloaded = from, say, Basic. I am sure you can get by with the syntactic overloading, but if you have the option of reducing ambiguity, why not use it?

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 2, 2015 5:57:05 PM PST, Steve Taylor <steve.taylor at aut.ac.nz> wrote:
>Responding to several messages in this thread...
>
>> > All the more reason to use = instead of <-
>> Definitely not!
>
>Martin and Rolf are right, it's not a reason for that; I wrote that
>quickly without thinking it through.  An "=" user might be more likely
>to fall for the gotcha, if not spacing their code nicely.  So the
>lesson learned from the gotcha is that it's good to space your code
>nicely, as others have siad, not which assignment symbol to use.
>
>However, I continue to use "=" for assignment on a daily basis without
>any problems, as I have done for many years.  I remain unconvinced by
>any and all of these arguments against it in favour of "<-".  People
>telling me that I "should" use the arrow need better agruments than
>what I've seen so far.
>
>I find "<-" ugly and "->" useless/pointless, whereas "=" is simpler and
>also nicely familiar from my experience in other languages.  It doesn't
>matter to me that "=" is not commutative because I don't need it to be.
>
>> Further it can be nicely marked up by a real "left arrow" 
>> by e.g. the listings LaTeX 'listings' package...
>
>Now that's just silly, turning R code into graphical characters that
>are not part of the R language.
>
>>  foo(x = y) and foo(x <- y)
>
>I'm well aware of this distinction and it never causes me any problems.
>The latter is an example of bad (obfuscated) coding, IMHO; it should be
>done in two lines for clarity as follows:
>
>x = y
>foo(x)
>
>> Using = has it's problems too.
>Same goes for apostrophes.
>
>Shall we discuss putting "else" at the start of line next?
>
>cheers,
>     Steve
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From steve.taylor at aut.ac.nz  Tue Feb  3 04:11:47 2015
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Tue, 3 Feb 2015 03:11:47 +0000
Subject: [R] the less-than-minus gotcha
In-Reply-To: <B9408055-FF06-49EA-BF95-1FB3BB4496A9@dcn.davis.CA.us>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>,
	<21711.37801.439519.676495@stat.math.ethz.ch>
	<CCE952776B6679469977532BD863C39C9A66DF62@Lewis.autuni.aut.ac.nz>
	<B9408055-FF06-49EA-BF95-1FB3BB4496A9@dcn.davis.CA.us>
Message-ID: <CCE952776B6679469977532BD863C39C9A66F742@Lewis.autuni.aut.ac.nz>

Nobody would write x=x or indeed x<-x; both are silly.  If I found myself writing f(x=x) I might smirk at the coincidence, but it wouldn't bother me.  I certainly wouldn't confuse it with assigning x to itself.

By the way, here's another assignment operator we can use:

`:=` = `<-`  # this is going in my .Rprofile
x := 1


-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Tuesday, 3 February 2015 3:54p
To: Steve Taylor; r-help at stat.math.ethz.ch
Subject: Re: [R] the less-than-minus gotcha

I did not start out liking <-, but I am quite attached to it now, and even Rcpp feels weird to me now. This may seem like yet another variation on a theme that you don't find compelling, but I find that

f(x=x)

makes sense when scope is considered, but

x=x

on its own is silly. That is why I prefer to reserve = for assigning parameters... I use it to clarify that I am crossing scope boundaries, while <- never does. (<<- is a dangerous animal, though... to be used only locally in nested function definitions).

In my view, this is similar to preferring == from C-derived syntaxes over the overloaded = from, say, Basic. I am sure you can get by with the syntactic overloading, but if you have the option of reducing ambiguity, why not use it?

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 2, 2015 5:57:05 PM PST, Steve Taylor <steve.taylor at aut.ac.nz> wrote:
>Responding to several messages in this thread...
>
>> > All the more reason to use = instead of <-
>> Definitely not!
>
>Martin and Rolf are right, it's not a reason for that; I wrote that
>quickly without thinking it through.  An "=" user might be more likely
>to fall for the gotcha, if not spacing their code nicely.  So the
>lesson learned from the gotcha is that it's good to space your code
>nicely, as others have siad, not which assignment symbol to use.
>
>However, I continue to use "=" for assignment on a daily basis without
>any problems, as I have done for many years.  I remain unconvinced by
>any and all of these arguments against it in favour of "<-".  People
>telling me that I "should" use the arrow need better agruments than
>what I've seen so far.
>
>I find "<-" ugly and "->" useless/pointless, whereas "=" is simpler and
>also nicely familiar from my experience in other languages.  It doesn't
>matter to me that "=" is not commutative because I don't need it to be.
>
>> Further it can be nicely marked up by a real "left arrow" 
>> by e.g. the listings LaTeX 'listings' package...
>
>Now that's just silly, turning R code into graphical characters that
>are not part of the R language.
>
>>  foo(x = y) and foo(x <- y)
>
>I'm well aware of this distinction and it never causes me any problems.
>The latter is an example of bad (obfuscated) coding, IMHO; it should be
>done in two lines for clarity as follows:
>
>x = y
>foo(x)
>
>> Using = has it's problems too.
>Same goes for apostrophes.
>
>Shall we discuss putting "else" at the start of line next?
>
>cheers,
>     Steve
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pbruneau at gmail.com  Tue Feb  3 07:09:54 2015
From: pbruneau at gmail.com (Pierrick Bruneau)
Date: Tue, 3 Feb 2015 07:09:54 +0100
Subject: [R] A good way to debug a c++ library embedded to an R code
In-Reply-To: <CAJ_LAMAeRc+LSfD4=vPdM1y5r11RX2uCqPtkH4HZvd_dN=TzzQ@mail.gmail.com>
References: <CAH-FEnhqiY0XbBYy_GSu5wm2UfFNcmJ73dS5rZcRPEGwx=TX4w@mail.gmail.com>
	<CAJ_LAMAeRc+LSfD4=vPdM1y5r11RX2uCqPtkH4HZvd_dN=TzzQ@mail.gmail.com>
Message-ID: <CAF_q7hXxWyeJjq95Nc+_zH=Sh=3uisJ0kmyxC1brzCv6eAFKww@mail.gmail.com>

There's also a section about this in "Writing R extensions":
http://cran.r-project.org/doc/manuals/r-release/R-exts.html#Debugging-compiled-code

Pierrick

On Mon, Feb 2, 2015 at 10:42 PM, Qiang Kou <qkou at umail.iu.edu> wrote:
> If you are familiar with GDB, you can just start R by "R -d gdb".
>
> Dirk gave a good example on SO, please check the link below:
>
> http://stackoverflow.com/questions/11345537/debugging-line-by-line-of-rcpp-generated-dll-under-windows
>
> Best,
>
> KK
>
> On Mon, Feb 2, 2015 at 2:00 PM, Charles Novaes de Santana <
> charles.santana at gmail.com> wrote:
>
>> Dear all,
>>
>> I am using R CMD SHLIB to compile a c++ code into a library (.so) and
>> dyn.load to load this library into a R code. I am facing some problems in
>> the c++ part that I can not figure out how to solve. Do you recomend any
>> good way to debug this R + C++ program? If I was programming only in C++ I
>> would use GDB.
>>
>> I would much appreciate any help or suggestion!
>>
>> Best regards,
>>
>> Charles
>>
>> --
>> Um ax?! :)
>>
>> --
>> Charles Novaes de Santana, PhD
>> http://www.imedea.uib-csic.es/~charles
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Qiang Kou
> qkou at umail.iu.edu
> School of Informatics and Computing, Indiana University
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Lalitha.Kristipati at techmahindra.com  Tue Feb  3 07:14:28 2015
From: Lalitha.Kristipati at techmahindra.com (Lalitha Kristipati)
Date: Tue, 3 Feb 2015 06:14:28 +0000
Subject: [R] New to R
Message-ID: <260d691123fd4f06bb9ed0cff72f05ef@BLREXCHMBX001.TechMahindra.com>

Hi,



In our data we have 10 people with 10 different attributes , we want to rank the people based on the weightage of these attributes.

Suggest the best statistical method to do this.

Does Revolution R solves my problem??



Regards,
Lalitha Kristipati
Associate Software Engineer



============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Feb  3 08:48:02 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 02 Feb 2015 23:48:02 -0800
Subject: [R] New to R
In-Reply-To: <260d691123fd4f06bb9ed0cff72f05ef@BLREXCHMBX001.TechMahindra.com>
References: <260d691123fd4f06bb9ed0cff72f05ef@BLREXCHMBX001.TechMahindra.com>
Message-ID: <1398B4C5-41D5-4D80-9C09-227CB25648F0@dcn.davis.CA.us>

Please don't cross-post to multiple lists. There is a Posting Guide mentioned in the footer that you probably won't see because you are using Nabble. It would have informed you that the R-devel mailing list was for people interested in modifying R, definitely not this topic.

As to your question, Revolution R would probably be overkill, and if you chose to go that route then asking the Revolution R support people for help would be appropriate. This list is for the open source R software that RR builds on.

Your problem  statement suggests you already know the weights... in which case this is a straightforward linear algebra calculation that is trivial in R.

But your question mentions selecting statistics methods, which is not on topic here in the R-help mailing list, since methods are independent of the software used to apply them. If you know what methods you want to apply, and have read the introductory R documentation, then this is an appropriate place to ask for help on how to apply R to your problem. If that is the case, then DO read the Posting Guide and try again with some example data and if possible some sample results you expect to get. We can then show you how to connect the dots using R.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 2, 2015 10:14:28 PM PST, Lalitha Kristipati <Lalitha.Kristipati at techmahindra.com> wrote:
>Hi,
>
>
>
>In our data we have 10 people with 10 different attributes , we want to
>rank the people based on the weightage of these attributes.
>
>Suggest the best statistical method to do this.
>
>Does Revolution R solves my problem??
>
>
>
>Regards,
>Lalitha Kristipati
>Associate Software Engineer
>
>
>
>============================================================================================================================
>Disclaimer:  This message and the information contained herein is
>proprietary and confidential and subject to the Tech Mahindra policy
>statement, you may review the policy at
>http://www.techmahindra.com/Disclaimer.html externally
>http://tim.techmahindra.com/tim/disclaimer.html internally within
>TechMahindra.
>============================================================================================================================
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mbmiller+l at gmail.com  Tue Feb  3 09:40:34 2015
From: mbmiller+l at gmail.com (Mike Miller)
Date: Tue, 3 Feb 2015 02:40:34 -0600
Subject: [R] the less-than-minus gotcha
In-Reply-To: <CCE952776B6679469977532BD863C39C9A66F742@Lewis.autuni.aut.ac.nz>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>,
	<21711.37801.439519.676495@stat.math.ethz.ch>
	<CCE952776B6679469977532BD863C39C9A66DF62@Lewis.autuni.aut.ac.nz>
	<B9408055-FF06-49EA-BF95-1FB3BB4496A9@dcn.davis.CA.us>
	<CCE952776B6679469977532BD863C39C9A66F742@Lewis.autuni.aut.ac.nz>
Message-ID: <alpine.DEB.2.00.1502030226560.2662@taxa.psych.umn.edu>

Kevin Thorpe wrote,

"Moral of story, computers do what you tell them, not what you meant."

But hope springs eternal!  Of course this aphorism explains neatly every 
problem I've ever run across while using a computer.  But maybe someday 
they'll make a computer that undertands *me*!

Peter Dalgaard wrote,

"I'd rather say that it is good reason to use spaces around operators. 
Makes the code easier to read too."

I think that's the real lesson.  I try to do that, but I'll be trying even 
harder now.


If they'd thought of it long ago, S and R could have been written so that 
"<-" had to be followed by a space or an error would result.  That might 
have been a good idea, but it's too late now.  So we just have to not make 
mistakes.  I'm working on it.

Mike


From maechler at lynne.stat.math.ethz.ch  Tue Feb  3 10:42:05 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Tue, 3 Feb 2015 10:42:05 +0100
Subject: [R] the less-than-minus gotcha
In-Reply-To: <CCE952776B6679469977532BD863C39C9A66F742@Lewis.autuni.aut.ac.nz>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
	<21711.37801.439519.676495@stat.math.ethz.ch>
	<CCE952776B6679469977532BD863C39C9A66DF62@Lewis.autuni.aut.ac.nz>
	<B9408055-FF06-49EA-BF95-1FB3BB4496A9@dcn.davis.CA.us>
	<CCE952776B6679469977532BD863C39C9A66F742@Lewis.autuni.aut.ac.nz>
Message-ID: <21712.38893.932511.27841@stat.math.ethz.ch>

>>>>> Steve Taylor <steve.taylor at aut.ac.nz>
>>>>>     on Tue, 3 Feb 2015 03:11:47 +0000 writes:

    > Nobody would write x=x or indeed x<-x; both are silly.  If
    > I found myself writing f(x=x) I might smirk at the
    > coincidence, but it wouldn't bother me.  I certainly
    > wouldn't confuse it with assigning x to itself.  By the
    > way, here's another assignment operator we can use:

    > `:=` = `<-` # this is going in my .Rprofile 
    >  x := 1

I very much agree with you on that last point.

A while ago, about or shortly before when R was created, say ca. 1991-1993,
when S4 was "around the corner", and I was a beta tester for it,
and  '=' was going to be introduced into the S language, 
I had a fervent plea for considering  ":="  as an alternative...
... but was never even replied to IIRC.

The fact that R's parser allows  ':='  is an interesting
historic relict itself.
Before R even got a version number, R did not have packages yet,
there was "kind of a distinction" (don't ask me for details now)
between "base R functions" and "other R objects"
 {If Ross Ihaka reads this, he will cringe I'm sure.. sorry, Ross!}
and all those used :=

The last version that still used this extensively 0.13, is still available
as  R-0.13alpha.tar.gz  (813570 bytes, dated  Nov 7, 1996),
and contains a file src/library/base/median  (note, no 'R'
subdirectory) which looks like this
---------------------------------------------------------------------
median := function(x, na.rm = FALSE) {
	if(na.rm)
		x <- x[!is.na(x)]
	else if(any(is.na(x)))
		return(NA)
	n <- length(x)
	half <- (n + 1)/2
	if(n %% 2 == 1) {
		sort(x, partial = half)[half]
	}
	else {
		sum(sort(x, partial = c(half, half + 1))[c(half, half + 1)])/2
	}
}
---------------------------------------------------------------------

so yes, ":="  had its nice history,  but as it was not accepted
into S  *instead* of '=', it also fell away for R ...

Martin Maechler, 
ETH Zurich  (and R Core team since "prehistory")


    > -----Original Message----- From: Jeff Newmiller
    > [mailto:jdnewmil at dcn.davis.ca.us] Sent: Tuesday, 3
    > February 2015 3:54p To: Steve Taylor;
    > r-help at stat.math.ethz.ch Subject: Re: [R] the
    > less-than-minus gotcha

    > I did not start out liking <-, but I am quite attached to
    > it now, and even Rcpp feels weird to me now. This may seem
    > like yet another variation on a theme that you don't find
    > compelling, but I find that

    > f(x=x)

    > makes sense when scope is considered, but

    > x=x

    > on its own is silly. That is why I prefer to reserve = for
    > assigning parameters... I use it to clarify that I am
    > crossing scope boundaries, while <- never does. (<<- is a
    > dangerous animal, though... to be used only locally in
    > nested function definitions).

    > In my view, this is similar to preferring == from
    > C-derived syntaxes over the overloaded = from, say,
    > Basic. I am sure you can get by with the syntactic
    > overloading, but if you have the option of reducing
    > ambiguity, why not use it?

    > ---------------------------------------------------------------------------
    > Jeff Newmiller The .....  .....  Go Live...
    > DCN:<jdnewmil at dcn.davis.ca.us> Basics: ##.#.  ##.#.  Live
    > Go...  Live: OO#.. Dead: OO#..  Playing Research Engineer
    > (Solar/Batteries O.O#.  #.O#.  with /Software/Embedded
    > Controllers) .OO#.  .OO#.  rocks...1k
    > --------------------------------------------------------------------------- 
    > Sent from my phone. Please excuse my brevity.

    > On February 2, 2015 5:57:05 PM PST, Steve Taylor
    > <steve.taylor at aut.ac.nz> wrote:
    >> Responding to several messages in this thread...
    >> 
    >>> > All the more reason to use = instead of <- Definitely
    >>> not!
    >> 
    >> Martin and Rolf are right, it's not a reason for that; I
    >> wrote that quickly without thinking it through.  An "="
    >> user might be more likely to fall for the gotcha, if not
    >> spacing their code nicely.  So the lesson learned from
    >> the gotcha is that it's good to space your code nicely,
    >> as others have siad, not which assignment symbol to use.
    >> 
    >> However, I continue to use "=" for assignment on a daily
    >> basis without any problems, as I have done for many
    >> years.  I remain unconvinced by any and all of these
    >> arguments against it in favour of "<-".  People telling
    >> me that I "should" use the arrow need better agruments
    >> than what I've seen so far.
    >> 
    >> I find "<-" ugly and "->" useless/pointless, whereas "="
    >> is simpler and also nicely familiar from my experience in
    >> other languages.  It doesn't matter to me that "=" is not
    >> commutative because I don't need it to be.
    >> 
    >>> Further it can be nicely marked up by a real "left
    >>> arrow" by e.g. the listings LaTeX 'listings' package...
    >> 
    >> Now that's just silly, turning R code into graphical
    >> characters that are not part of the R language.
    >> 
    >>> foo(x = y) and foo(x <- y)
    >> 
    >> I'm well aware of this distinction and it never causes me
    >> any problems.  The latter is an example of bad
    >> (obfuscated) coding, IMHO; it should be done in two lines
    >> for clarity as follows:
    >> 
    >> x = y foo(x)
    >> 
    >>> Using = has it's problems too.
    >> Same goes for apostrophes.
    >> 
    >> Shall we discuss putting "else" at the start of line
    >> next?
    >> 
    >> cheers, Steve
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Feb  3 10:15:27 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 3 Feb 2015 20:15:27 +1100
Subject: [R] New to R
In-Reply-To: <1398B4C5-41D5-4D80-9C09-227CB25648F0@dcn.davis.CA.us>
References: <260d691123fd4f06bb9ed0cff72f05ef@BLREXCHMBX001.TechMahindra.com>
	<1398B4C5-41D5-4D80-9C09-227CB25648F0@dcn.davis.CA.us>
Message-ID: <CA+8X3fW6unYg9_tr_fdUjzdO9+K3hMR13paPbkQBv9eJb=xqeA@mail.gmail.com>

Hi Lalitha,
Your description is more like calculating a composite score from the
values observed on ten attributes, which can then be ranked. Perhaps
you want to standardize the observed values to insure that the result
is not dominated by the attribute with the numerically highest
variance. For example:

V1<-rnorm(10,5,5)
Z1<-scale(V1)

You can then combine your ten standardized (Z) scores to form a
composite score and rank your subjects on that.

Jim


On Tue, Feb 3, 2015 at 6:48 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> Please don't cross-post to multiple lists. There is a Posting Guide mentioned in the footer that you probably won't see because you are using Nabble. It would have informed you that the R-devel mailing list was for people interested in modifying R, definitely not this topic.
>
> As to your question, Revolution R would probably be overkill, and if you chose to go that route then asking the Revolution R support people for help would be appropriate. This list is for the open source R software that RR builds on.
>
> Your problem  statement suggests you already know the weights... in which case this is a straightforward linear algebra calculation that is trivial in R.
>
> But your question mentions selecting statistics methods, which is not on topic here in the R-help mailing list, since methods are independent of the software used to apply them. If you know what methods you want to apply, and have read the introductory R documentation, then this is an appropriate place to ask for help on how to apply R to your problem. If that is the case, then DO read the Posting Guide and try again with some example data and if possible some sample results you expect to get. We can then show you how to connect the dots using R.
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On February 2, 2015 10:14:28 PM PST, Lalitha Kristipati <Lalitha.Kristipati at techmahindra.com> wrote:
>>Hi,
>>
>>
>>
>>In our data we have 10 people with 10 different attributes , we want to
>>rank the people based on the weightage of these attributes.
>>
>>Suggest the best statistical method to do this.
>>
>>Does Revolution R solves my problem??
>>
>>
>>
>>Regards,
>>Lalitha Kristipati
>>Associate Software Engineer
>>
>>
>>
>>============================================================================================================================
>>Disclaimer:  This message and the information contained herein is
>>proprietary and confidential and subject to the Tech Mahindra policy
>>statement, you may review the policy at
>>http://www.techmahindra.com/Disclaimer.html externally
>>http://tim.techmahindra.com/tim/disclaimer.html internally within
>>TechMahindra.
>>============================================================================================================================
>>
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From haenlein at escpeurope.eu  Tue Feb  3 12:08:10 2015
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Tue, 3 Feb 2015 12:08:10 +0100
Subject: [R] Teaching materials for R course
Message-ID: <CAOyz9G6hmTukco-8Rwipga1aoKxOLCNw2fryKR71=vvQDm3GgQ@mail.gmail.com>

Dear all,

I am Professor at a business school and I would like to develop a course
about quantitative research using R.

My current plan is that the course should cover (a) an introduction
(assuming that students have never used R before), (b) basic econometric
analysis (e.g., regression, logit) as well as (c) structural equation
modelling.

Are there any textbooks and teaching materials (e.g., PowerPoint slides)
that one of you could recommend for me to have a look at?

Thanks,

Michael

Michael Haenlein
Professor of Marketing
ESCP Europe

	[[alternative HTML version deleted]]


From minorthreatx at hotmail.com  Tue Feb  3 14:09:21 2015
From: minorthreatx at hotmail.com (Kim C.)
Date: Tue, 3 Feb 2015 14:09:21 +0100
Subject: [R] xerror and xstd are missing from cptable of the Rpart package
Message-ID: <DUB126-W4402D7F3E521431E49A29DE3D0@phx.gbl>

Hello all, 
I'm making a decision tree with the rpart package. I want to prune the tree and in many tutorials it says to use cptable. Like so: opt <- which.min(model_rpart$cptable[, "xerror"])
The problem is that when I look up model_rpart$cptable it only show the columns CP, nsplit, rel error. So xerror and xstd are missing. How can this be? 
Model looks like this: model <- rpart(Product~. , data=trainData, control=rpart.control(minsplit=50, cp=0.002, xval=0))

Thank you. 
Kim  		 	   		  
	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Tue Feb  3 14:23:34 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 3 Feb 2015 07:23:34 -0600
Subject: [R] xerror and xstd are missing from cptable of the Rpart
	package
In-Reply-To: <DUB126-W4402D7F3E521431E49A29DE3D0@phx.gbl>
References: <DUB126-W4402D7F3E521431E49A29DE3D0@phx.gbl>
Message-ID: <CAN5YmCGvO_23h5f_J6ce0X4s4o4g7UKtFf5VE-1UBR_L2viPxw@mail.gmail.com>

Kim,

The "x" in "xerror" and "xstd" stands for cross validation.  But you have
specified no cross validations, xval=0.

Try:

model <- rpart(Product ~ ., data=trainData, control=rpart.control(minsplit=50,
cp=0.002))
model$cptable

Jean


On Tue, Feb 3, 2015 at 7:09 AM, Kim C. <minorthreatx at hotmail.com> wrote:

> Hello all,
> I'm making a decision tree with the rpart package. I want to prune the
> tree and in many tutorials it says to use cptable. Like so: opt <-
> which.min(model_rpart$cptable[, "xerror"])
> The problem is that when I look up model_rpart$cptable it only show the
> columns CP, nsplit, rel error. So xerror and xstd are missing. How can this
> be?
> Model looks like this: model <- rpart(Product~. , data=trainData,
> control=rpart.control(minsplit=50, cp=0.002, xval=0))
>
> Thank you.
> Kim
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marc.lavielle at inria.fr  Tue Feb  3 11:39:40 2015
From: marc.lavielle at inria.fr (lavielle)
Date: Tue, 3 Feb 2015 02:39:40 -0800 (PST)
Subject: [R] Error in running pkmodel function in "mlxR" package
In-Reply-To: <1421894078153-4702110.post@n4.nabble.com>
References: <1421894078153-4702110.post@n4.nabble.com>
Message-ID: <1422959980639-4702745.post@n4.nabble.com>

Hi RajPatil

It seems that you are using an old version of mlxLibrary.

You need to install mlxLibrary 1.1.0 from the Lixoft website
http://download.lixoft.com/?software=mlxlibrary

Marc



--
View this message in context: http://r.789695.n4.nabble.com/Error-in-running-pkmodel-function-in-mlxR-package-tp4702110p4702745.html
Sent from the R help mailing list archive at Nabble.com.


From eike.petersen at fp-tga.de  Tue Feb  3 14:48:11 2015
From: eike.petersen at fp-tga.de (Eike Petersen)
Date: Tue, 3 Feb 2015 14:48:11 +0100 (CET)
Subject: [R] FFT Normalization Documentation
In-Reply-To: <E17505B1-8B48-495B-8532-CE914D86AC33@xs4all.nl>
References: <1985531401.416848.1422883625463.JavaMail.open-xchange@omgreatgod.store>
	<E17505B1-8B48-495B-8532-CE914D86AC33@xs4all.nl>
Message-ID: <1357405753.621214.1422971291950.JavaMail.open-xchange@omgreatgod.store>

Dear Frank,
 
thanks a lot for your reply. I was aware of the need for FFT normalization and
folding, but you're making another good point here, stating that there should be
examples on this (folding) in the documentation as it will pose quite an
obstacle for newcomers attempting to practically use the FFT.
 
When writing yesterday's mail, I falsely was under the impression that there is
such a thing as a "correct" normalization of an FFT. In the meantime, I have
come to realize that when considering "real", i.e., physical, signals, there is
no "true" way of normalizing the result of an inverse FFT, since everything
depends on the sampling characterstics and on the properties of the frequency
domain representation of the signal.
 
Just imagine two differently sampled versions of the frequency representation of
some physical signal, both attaining the same number of sample points NFFT, but
different sampling frequencies. There is no way to scale these two signals
coherently, based only on the number of sample points. Assuming Fs1 < Fs2 and
assuming the physical signal to be band-limited with Fband < Fs1, the inverse
transform of the signal sampled at Fs1 will naturally be larger (due to the
larger number of sinces/cosines being summed up in the time signal).
 
When comparing differently sampled versions of the same signal, it might be
desirable to scale the result based on the energy content of the signal, i.e. by
multiplying the signal with the frequency bin width 'fbin = Fs/(NFFT-1)'. So
this is where your calculation of the attained frequencies comes into play! Note
that this is equivalent to calculating the energy in the frequency domain by
integration of a piecewise constant interpolation of the frequency domain FFT
coefficients.
 
I want to repeat my question concerning proposals on where to publish such
considerations for the use of as many R users as possible. Might it be a good
idea to create and propose an official vignette to the FFT function?
 
Kind regards,
Eike

> On February 3, 2015 at 12:39 AM Franklin Bretschneider <bretschr at xs4all.nl>
> wrote:
>
>
> Dear Eike Petersen,
>
>
> Re:
>
> > Hello everyone,
> >
> > the docpage for the fft function states:
> >
> > ?Description: Performs the Fast Fourier Transform of an array.?
> >
> > and
> >
> > ?Arguments ? inverse: if ?TRUE?, the unnormalized inverse transform is
> > computed
> > (the inverse has a ?+? in the exponent of e, but here, we do _not_ divide by
> > ?1/length(x)?).?
> >
> > Judging from this, I would expect ?fft(x)? to yield the correct FFT of x,
> > and
> > ?fft(X, inverse = TRUE) / length(X)? to yield the correct inverse FFT of X.
> >
> > However, it seems to me that actually the result of ?fft(x)? should be
> > scaled by
> > ?1/length(x)?, while ?fft(X, inverse=TRUE)? seems to yield a correct result
> > by
> > default:
> >
> > t <- seq(0.001, 1, 0.001)
> > y <- 1 + sin(2*pi*20*t) + 1.5 * sin(2*pi*30*t)
> > Y <- fft(y)
> > dev.new()
> > plot(abs(Y)) ## Shows peaks at amplitudes 1000, 500 and 750, while they
> > should
> > be at amplitude 1, 0.5 and 0.75.
> > y2 <- Re(fft(Y / length(Y), inverse = TRUE))
> > max(abs(y-y2)) ## The IFFT yields a correctly scaled result by default, if
> > applied to a correctly scaled FFT.
> >
> > Did I get something wrong? If not, having spent quite some time figuring
> > this
> > out, I would like to see the documentation clearly pointing this out. I find
> > the
> > current text rather confusing.
> >
> > On another note: I have spent some time working on demo files that showcase
> > some
> > of the properties of the FFT and their implementation in R. I have done this
> > primarily for myself, as I keep forgetting how these things work, but I
> > thought
> > that it might be helpful to others as well. Any hints on where/how I should
> > publish such a thing?
> >
> > Kind regards and many thanks in advance,
> >
> > Eike
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
> As far as I know an FFT must be normalized and folded to obtain a spectrum in
> the form we like, so this would be my version:
>
> # your time signal:
>
> t <- seq(0.001, 1, 0.001)
> y <- 1 + sin(2*pi*20*t) + 1.5 * sin(2*pi*30*t)
>
> # find time and frequency calibration:
>
> n = length(y)
> dt = t[2]-t[1]
> fNyq = 1/(2*dt)
> tmax = max(t)
> df = 1/tmax
>
> # make frequency vector to display as x-values of the spectrum rather than the
> index.
>
> f = seq(-fNyq, fNyq-df, by=df)
>
> # make folding mask
>
> mask=rep(c(1, -1),length.out=n)
>
> # fold the spectrum around the Nyquist frequency; so the DC value (f=0) is in
> the middle; the - and + max frequency at the ends.
>
> yy = y * mask
>
> # # Then do the FFT
>
> YY <- fft(yy)
>
> Plot the amplitude spectrum vector against the freq. vector
>
> plot(f,abs(YY), type='h')
>
>
>
> --------
>
> It would be a good idea to put such an example in the help pages indeed.
> The short example given in the manual isn't of much help for the usual
> (periodic!) time signals.
>
> Hoping this helps, I remain
>
> With best wishes,
>
> Frank
> ----
>
>
>
>
>
>
> Franklin Bretschneider
> Dept of Biology
> Utrecht University
> bretschr at xs4all.nl
>
>
>
	[[alternative HTML version deleted]]


From ssefick at gmail.com  Tue Feb  3 14:58:08 2015
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 3 Feb 2015 07:58:08 -0600
Subject: [R] rJava Scientific Linux 6.5 - Can not install
In-Reply-To: <CADKEMqjQBX_zC_ioUrJe+Rxn3T89fHBnGRgKSsTg7Ez1wcsugA@mail.gmail.com>
References: <CADKEMqgttjhCDNthZkmnAcx+Po1R8shr523LRXp8eK7EToJkSw@mail.gmail.com>
	<632E20FD-220C-4924-8FA8-AA62EE602FEB@dcn.davis.CA.us>
	<CADKEMqjQBX_zC_ioUrJe+Rxn3T89fHBnGRgKSsTg7Ez1wcsugA@mail.gmail.com>
Message-ID: <CADKEMqgOu0iLTXUbKyE3W_eGXg=BKw1eZrfPyDVxhkW3h0O7iQ@mail.gmail.com>

I have solved the problem. Here are the steps in case this will help
anyone.

1) I downloaded, compiled, and installed latest R sources.
2) made sure I had all of the R development libraries install through
packages manager
3) update java jkd 1.6* to java jkd 1.7*
4) ran sudo R CMD javareconf
JAVA_HOME="/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.75.x86_64/"
5) Ensured all of the fields in the output of 4 were populated
6) in a sudo R session, I ran install.packages("rJava",
library=personal_library)

Stephen


On Mon, Feb 2, 2015 at 2:39 PM, stephen sefick <ssefick at gmail.com> wrote:

> Included at the end of this message is the full compiler output. I have
> installed jre-7 from Oracle; The java-1.7.0-jdk* packages and javacc are
> installed. It looks like the archiver, header prep., and compiler are
> missing. I can provide anything else that can help solve my problem. I
> really appreciate all of the help. Kindest regards.
>
> checking for gcc... gcc -std=gnu99
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc -std=gnu99 accepts -g... yes
> checking for gcc -std=gnu99 option to accept ISO C89... none needed
> checking how to run the C preprocessor... gcc -std=gnu99 -E
> checking for grep that handles long lines and -e... /bin/grep
> checking for egrep... /bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/wait.h that is POSIX.1 compatible... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking for string.h... (cached) yes
> checking sys/time.h usability... yes
> checking sys/time.h presence... yes
> checking for sys/time.h... yes
> checking for unistd.h... (cached) yes
> checking for an ANSI C-conforming const... yes
> checking whether time.h and sys/time.h may both be included... yes
> configure: checking whether gcc -std=gnu99 supports static inline...
> yes
> checking whether setjmp.h is POSIX.1 compatible... yes
> checking whether sigsetjmp is declared... yes
> checking whether siglongjmp is declared... yes
> checking Java support in R... present:
> interpreter : '/usr/bin/java'
> archiver    : ''
> compiler    : ''
> header prep.: ''
> cpp flags   : '-I/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0.x86_64/jre/../include -I/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0.x86_64/jre/../include/linux'
> java libs   : '-L/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0.x86_64/jre/lib/amd64/server -ljvm'configure: error: Java Development Kit (JDK) is missing or not registered in R
> Make sure R is configured with full Java support (including JDK). Run
> R CMD javareconf
> as root to add Java support to R.
>
> If you don't have root privileges, run
> R CMD javareconf -e
>
> to set all Java-related variables and then install rJava.
>
>
>
> On Mon, Feb 2, 2015 at 12:54 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> Don't know anything about SL but have you installed a Java run time
>> independent of R?
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 2, 2015 10:39:14 AM PST, stephen sefick <ssefick at gmail.com>
>> wrote:
>> >Hello all,
>> >
>> >I am having a problem with installing rJava on SL 6.5. I am having
>> >compile
>> >errors when I try to from CRAN using install.packages("XLConnect",
>> >repos="
>> >http://cran.rstudio.com/"). I can provide anything necessary, but I am
>> >unsure what to provide. Thank you for your help in advance.
>> >
>> >output of sessionInfo():
>> >R version 3.1.0 Patched (2014-06-15 r65949)
>> >Platform: x86_64-unknown-linux-gnu (64-bit)
>> >
>> >locale:
>> > [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>> > [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>> > [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
>> > [7] LC_PAPER=en_US.utf8       LC_NAME=C
>> > [9] LC_ADDRESS=C              LC_TELEPHONE=C
>> >[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>> >
>> >attached base packages:
>> >[1] graphics  grDevices utils     datasets  stats     methods   base
>> >
>> >other attached packages:
>> >[1] devtools_1.7.0 ggplot2_1.0.0
>> >
>> >loaded via a namespace (and not attached):
>> > [1] colorspace_1.2-4 digest_0.6.8     grid_3.1.0       gtable_0.1.2
>> > [5] MASS_7.3-37      munsell_0.4.2    plyr_1.8.1       proto_0.3-10
>> > [9] Rcpp_0.11.4      reshape2_1.4.1   scales_0.2.4     stringr_0.6.2
>> >[13] tools_3.1.0
>>
>>
>
>
> --
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>


-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From Keith.Jewell at campdenbri.co.uk  Tue Feb  3 15:43:22 2015
From: Keith.Jewell at campdenbri.co.uk (Keith.Jewell at campdenbri.co.uk)
Date: Tue, 3 Feb 2015 14:43:22 +0000
Subject: [R] rgl::writeWebGL( , prefix = , )
Message-ID: <5F22AFBADFE10342ABECF0281DE9921816B31050@EXCH001.campden.co.uk>

Dear all,

I am using writeWebGL to create an HTML page containing an interactive 3D plot. It works fine with the default prefix="" but fails when I specify a prefix "for different scenes displayed on the same web page" (quoting ?writeWebGL).  I'm sure I'm misreading the help, and would appreciate guidance.

Briefly, it works fine with the default writeWebGL( ,prefix="", ) and the template containing %WebGL%
I have not been able to make it work with any other value of prefix; e.g. writeWebGL( ,prefix="A",) and the template containing %AWebGL%

Here is code illustrating the problem.

First create three templates:
a) Vanilla: copied system.file(file.path("WebGL", "template.html"), package="rgl") to file.path(getwd(), "template.html")

b) First attempt: ?writeWebGL says # "[the template] should contain a single line containing paste("%", prefix, "WebGL%"), e.g. %WebGL% with the default empty prefix"
paste("%", "A", "WebGL%")
# [1] "% A WebGL%"
so file.path(getwd(), "templateA.html") is a copy of (a) replacing %WebGL% with % A WebGL%

c) Second attempt: file.path(getwd(), "templateB.html") is  a copy of (a) replacing %WebGL% with %AWebGL%

then, in R
#-----------
library(rgl)
plot3d(1:5, 1:5, 1:5) # generate rgl scene
#-----------
# a) vanilla
writeWebGL(dir=getwd(), template = file.path(getwd(), "template.html"), prefix="")
# works OK; result opens and works in IE
#----------------
# b) First attempt, my reading of ?writeWebGL
writeWebGL(dir=getwd(), template = file.path(getwd(), "templateA.html"), prefix="A")
# Error in writeWebGL(dir = getwd(), template = file.path(getwd(), "templateA.html"),  :
#                       template ?m://templateA.html? does not contain %AWebGL%
# so it looks as if the help is trivially wrong, it should be paste0
paste0("%", "A", "WebGL%")
# [1] "%AWebGL%"
#----------------
# c) second attempt using %AWebGL%
writeWebGL(dir=getwd(), template = file.path(getwd(), "templateB.html"), prefix="A")
# runs without error in R but IE displays "You must enable Javascript to view this page properly."
#--------------

I don't understand why (c) is different from (a).

Here are the system details:

R version 3.1.0 (2014-04-10)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United Kingdom.1252
[2] LC_CTYPE=English_United Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] grDevices datasets  splines   graphics  stats     tcltk     utils
 [8] tools     methods   base

other attached packages:
[1] knitr_1.8       animation_2.3   rgl_0.95.1158   CBRIutils_1.0
 [5] stringr_0.6.2   svSocket_0.9-55 TinnR_1.0-5     R2HTML_2.3.1
 [9] Hmisc_3.12-2    Formula_1.1-1   survival_2.37-7

loaded via a namespace (and not attached):
[1] cluster_1.15.3  devtools_1.6.1  evaluate_0.5.5  formatR_1.0
[5] grid_3.1.0      highr_0.4       lattice_0.20-29 rpart_4.1-8
[9] svMisc_0.9-70

Internet Explorer 11 Version 11.0.9600.17420

Any advice is welcome.


Keith Jewell - Statistician
Tel: +44 (0)1386 842055
Web:  www.campdenbri.co.uk
Email:  keith.jewell at campdenBRI.co.uk

Campden BRI (Chipping Campden) Limited - part of the Campden BRI group
Station Road ? Chipping Campden ? Gloucestershire ? GL55 6LD ? UK



________________________________

The information in this document and attachments is given after the exercise of all reasonable care and skill in its compilation, preparation and issue, but is provided without liability in its application or use. It may contain privileged information that is exempt from disclosure by law and may be confidential. If you are not the intended recipient you must not copy, distribute or take any action in reliance on it. If you have received this document in error please notify us and delete this message from your system immediately.

Unless otherwise expressly agreed in writing and signed by a duly authorised representative of Campden BRI, all goods & services procured and provided by Campden BRI shall be subject to our relevant Standard Terms and Conditions copies of which are available on request or can be downloaded from our website at http://www.campdenbri.co.uk/campdenbri/terms.php

? In the event of supplying technical services, such services shall be subject to Campden BRI Standard Terms and Conditions of Supply of Goods/Services.

? In the event of supplying training, conferences, seminars and events, such services shall be subject to Campden BRI Standard Terms and Condition for the Supply of Training including Conferences, Seminars and Events.

? In the event of our procurement of goods and services, such goods and services shall be provided subject to Campden BRI Standard Terms and Conditions of Purchase of Goods and/or Services.

Companies (trading) within the Campden BRI Group:
Campden BRI (private company limited by guarantee, registered number 510618)
Campden BRI (Chipping Campden) Limited (private company limited by shares, registered number 3836922)
Campden BRI (Nutfield) (private company limited by guarantee, registered number 2690377)

All companies are registered in England and Wales with the registered office at Station Road, Chipping Campden, Gloucestershire, GL55 6LD.

The Campden BRI Group may monitor e-mail traffic data and also the content of e-mail for the purposes of security and staff training.

____________________________________________________________
This e-mail has been scanned for all viruses by MessageLabs.
____________________________________________________________

From phaedrusv at gmail.com  Tue Feb  3 15:48:59 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Tue, 03 Feb 2015 14:48:59 +0000
Subject: [R] Updating to R 3.1.1. - impacts on existing packages
In-Reply-To: <alpine.BSF.2.00.1502021741000.2397@pedal.dcn.davis.ca.us>
References: <54D01B25.5030405@gmail.com>
	<CAFDcVCTxzDpFLH-WwBC3UBRqdeuzKpKRYGk1xgYSN+xdFKbQQA@mail.gmail.com>
	<alpine.BSF.2.00.1502021741000.2397@pedal.dcn.davis.ca.us>
Message-ID: <54D0DFDB.1060905@gmail.com>

Thanks Jeff/ Henrik

Jeff - that's what I needed: so far the update seems to be painless.

Many thanks

Sun


On 03/02/15 01:45, Jeff Newmiller wrote:
> I think you missed the question, Henrik, which was directed at 
> updating the local 3.1 library with all of the packages that were in 
> the 3.0 library.
>
> The usual advice for this is to copy your 3.0 library onto your 3.1 
> library (duplicate directory structure) so R knows what packages you 
> want to use and then use update packages. In general the copied 
> directories will not work directly, but R can update them. Note that 
> some packages are dropped due to better support in different packages 
> or lack of maintainer activity, so not all packages thus copied may 
> end up usable.
>
> On Mon, 2 Feb 2015, Henrik Bengtsson wrote:
>
>> On Mon, Feb 2, 2015 at 4:49 PM, Sun Shine <phaedrusv at gmail.com> wrote:
>>> Hi list
>>>
>>> I've signed up for a Coursera course on exploratory data analysis, 
>>> and the
>>> recommendation is to update to R base 3.1.1. I'm currently on 3.0.2.
>>>
>>> If I do upgrade, what is the best way for me to upgrade all my 
>>> packages for
>>> compatibility? Would this be accomplished through the command:
>>>
>>>> update.packages()
>>>
>>> Also, any ideas what percentage of the packages have been updated to 
>>> work
>>> with 3.1.1. ? I'm just wanting to do a risk evaluation because I 
>>> don't want
>>> to lose access to packages such as ggplot2, sna, statnet, 
>>> FactoMineR, and
>>> several others through upgrading.
>>
>> All package on CRAN should be up-to-date (that's almost the definition
>> of CRAN; if a package is not updated in time it's likely to be
>> archived due to lack of maintenance).  When in doubt, have a look at
>> their individual CRAN pages, e.g.
>> http://cran.r-project.org/package=ggplot2.  Look for the "r-release".
>>
>> Note that "r-release" always refers to the latest stable official R
>> release, which currently is R 3.1.2.  You should upgrade to that
>> version and not 3.1.1.  It's pretty safe to always install the most
>> recent stable release version of R.  If you're using an old version of
>> R, like you do, it's more likely that you run into problems in general
>> than if you use the most recent version.  So, avoid sticking with old
>> version and make to upgrade whenever a new release come out.
>>
>> /Henrik
>>
>>>
>>> Thanks for any steers
>>>
>>> Sun
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --------------------------------------------------------------------------- 
>
> Jeff Newmiller                        The     .....       ..... Go 
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#. ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#.. Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#. with
> /Software/Embedded Controllers)               .OO#.       .OO#. 
> rocks...1k
> --------------------------------------------------------------------------- 
>
>


From murdoch.duncan at gmail.com  Tue Feb  3 16:14:35 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 03 Feb 2015 10:14:35 -0500
Subject: [R] rgl::writeWebGL( , prefix = , )
In-Reply-To: <5F22AFBADFE10342ABECF0281DE9921816B31050@EXCH001.campden.co.uk>
References: <5F22AFBADFE10342ABECF0281DE9921816B31050@EXCH001.campden.co.uk>
Message-ID: <54D0E5DB.8000005@gmail.com>

On 03/02/2015 9:43 AM, Keith.Jewell at campdenbri.co.uk wrote:
> Dear all,
>
> I am using writeWebGL to create an HTML page containing an interactive 3D plot. It works fine with the default prefix="" but fails when I specify a prefix "for different scenes displayed on the same web page" (quoting ?writeWebGL).  I'm sure I'm misreading the help, and would appreciate guidance.
>
> Briefly, it works fine with the default writeWebGL( ,prefix="", ) and the template containing %WebGL%
> I have not been able to make it work with any other value of prefix; e.g. writeWebGL( ,prefix="A",) and the template containing %AWebGL%
>
> Here is code illustrating the problem.
>
> First create three templates:
> a) Vanilla: copied system.file(file.path("WebGL", "template.html"), package="rgl") to file.path(getwd(), "template.html")
>
> b) First attempt: ?writeWebGL says # "[the template] should contain a single line containing paste("%", prefix, "WebGL%"), e.g. %WebGL% with the default empty prefix"
> paste("%", "A", "WebGL%")
> # [1] "% A WebGL%"
> so file.path(getwd(), "templateA.html") is a copy of (a) replacing %WebGL% with % A WebGL%
>
> c) Second attempt: file.path(getwd(), "templateB.html") is  a copy of (a) replacing %WebGL% with %AWebGL%
>
> then, in R
> #-----------
> library(rgl)
> plot3d(1:5, 1:5, 1:5) # generate rgl scene
> #-----------
> # a) vanilla
> writeWebGL(dir=getwd(), template = file.path(getwd(), "template.html"), prefix="")
> # works OK; result opens and works in IE
> #----------------
> # b) First attempt, my reading of ?writeWebGL
> writeWebGL(dir=getwd(), template = file.path(getwd(), "templateA.html"), prefix="A")
> # Error in writeWebGL(dir = getwd(), template = file.path(getwd(), "templateA.html"),  :
> #                       template ?m://templateA.html? does not contain %AWebGL%
> # so it looks as if the help is trivially wrong, it should be paste0
> paste0("%", "A", "WebGL%")

Yes, that's right.  I'll fix it.

> # [1] "%AWebGL%"
> #----------------
> # c) second attempt using %AWebGL%
> writeWebGL(dir=getwd(), template = file.path(getwd(), "templateB.html"), prefix="A")
> # runs without error in R but IE displays "You must enable Javascript to view this page properly."
> #--------------
>
> I don't understand why (c) is different from (a).

There may be an error in the generated Javascript.  In Firefox, you 
could ask to see the browser console log, and it would report if there 
was an error on the page; sometimes those make the Javascript fail, and 
it falls back to the error message you saw.  I don't know how/if you can 
do that in IE.


>
> Here are the system details:
>
> R version 3.1.0 (2014-04-10)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] grDevices datasets  splines   graphics  stats     tcltk     utils
>   [8] tools     methods   base
>
> other attached packages:
> [1] knitr_1.8       animation_2.3   rgl_0.95.1158   CBRIutils_1.0

That's an old version of rgl; current on CRAN is 0.95.1201. 
<http://cran.r-project.org/src/contrib/rgl_0.95.1201.tar.gz> (CRAN OSX 
currently has an old binary; I don't recommend that you use it.  I don't 
know why they haven't updated to the current one.) r-forge has even 
newer versions, but I'm in the middle of some changes there, so I don't 
recommend using that version right now.

Duncan Murdoch
<http://cran.r-project.org/src/contrib/rgl_0.95.1201.tar.gz>
>   [5] stringr_0.6.2   svSocket_0.9-55 TinnR_1.0-5     R2HTML_2.3.1
>   [9] Hmisc_3.12-2    Formula_1.1-1   survival_2.37-7
>
> loaded via a namespace (and not attached):
> [1] cluster_1.15.3  devtools_1.6.1  evaluate_0.5.5  formatR_1.0
> [5] grid_3.1.0      highr_0.4       lattice_0.20-29 rpart_4.1-8
> [9] svMisc_0.9-70
>
> Internet Explorer 11 Version 11.0.9600.17420
>
> Any advice is welcome.
>
>
> Keith Jewell - Statistician
> Tel: +44 (0)1386 842055
> Web:  www.campdenbri.co.uk
> Email:  keith.jewell at campdenBRI.co.uk
>
> Campden BRI (Chipping Campden) Limited - part of the Campden BRI group
> Station Road ? Chipping Campden ? Gloucestershire ? GL55 6LD ? UK
>
>
>
> ________________________________
>
> The information in this document and attachments is given after the exercise of all reasonable care and skill in its compilation, preparation and issue, but is provided without liability in its application or use. It may contain privileged information that is exempt from disclosure by law and may be confidential. If you are not the intended recipient you must not copy, distribute or take any action in reliance on it. If you have received this document in error please notify us and delete this message from your system immediately.
>
> Unless otherwise expressly agreed in writing and signed by a duly authorised representative of Campden BRI, all goods & services procured and provided by Campden BRI shall be subject to our relevant Standard Terms and Conditions copies of which are available on request or can be downloaded from our website at http://www.campdenbri.co.uk/campdenbri/terms.php
>
> ? In the event of supplying technical services, such services shall be subject to Campden BRI Standard Terms and Conditions of Supply of Goods/Services.
>
> ? In the event of supplying training, conferences, seminars and events, such services shall be subject to Campden BRI Standard Terms and Condition for the Supply of Training including Conferences, Seminars and Events.
>
> ? In the event of our procurement of goods and services, such goods and services shall be provided subject to Campden BRI Standard Terms and Conditions of Purchase of Goods and/or Services.
>
> Companies (trading) within the Campden BRI Group:
> Campden BRI (private company limited by guarantee, registered number 510618)
> Campden BRI (Chipping Campden) Limited (private company limited by shares, registered number 3836922)
> Campden BRI (Nutfield) (private company limited by guarantee, registered number 2690377)
>
> All companies are registered in England and Wales with the registered office at Station Road, Chipping Campden, Gloucestershire, GL55 6LD.
>
> The Campden BRI Group may monitor e-mail traffic data and also the content of e-mail for the purposes of security and staff training.
>
> ____________________________________________________________
> This e-mail has been scanned for all viruses by MessageLabs.
> ____________________________________________________________
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kiotoqq at gmail.com  Tue Feb  3 16:27:09 2015
From: kiotoqq at gmail.com (maggy yan)
Date: Tue, 3 Feb 2015 16:27:09 +0100
Subject: [R] How to tell if there is overdispersion in a GLMM?
Message-ID: <CAK70=f5RdYgFucy3UVMsBLqhJPbU8SJRdqBsgc5-Aq2PtwF01w@mail.gmail.com>

I read something on http://glmm.wikidot.com/faq, under "How can I deal with
overdispersion in GLMMs?":

library(lme4)  ## 1.0-4set.seed(101)
d <- data.frame(y=rpois(1000,lambda=3),x=runif(1000),
            f=factor(sample(1:10,size=1000,replace=TRUE)))
m1 <- glmer(y~x+(1|f),data=d,family=poisson)
overdisp_fun(m1)##        chisq        ratio          rdf            p
## 1026.7780815    1.0298677  997.0000000    0.2497659
library(glmmADMB)  ## 0.7.7
m2 <- glmmadmb(y~x+(1|f),data=d,family="poisson")
overdisp_fun(m2)##        chisq        ratio          rdf            p
## 1026.7585031    1.0298480  997.0000000    0.2499024

In both case, the chisq is > rdf, does it mean there is over dispersion?

thanks for any help

	[[alternative HTML version deleted]]


From Xochitl.Cormon at ifremer.fr  Tue Feb  3 16:59:59 2015
From: Xochitl.Cormon at ifremer.fr (Xochitl CORMON)
Date: Tue, 03 Feb 2015 16:59:59 +0100
Subject: [R]  Problem running stepAIC within a function.
In-Reply-To: <1330784621343-4441487.post@n4.nabble.com>
References: <1330784621343-4441487.post@n4.nabble.com>
Message-ID: <54D0F07F.6030003@ifremer.fr>

I know it is pretty old but it seems that nobody answer this question. I 
ran into similar problem and the work around I found use the assign 
function. Indeed it seems than stepAIC look for the element it needs 
within the global environment. So if you define an object inside a 
function, you need afterwards to assign this object to the global 
environment.

See ?assign

Maybe that can help some people.

-- 

<>< <>< <>< <><

Xochitl CORMON
+33 (0)3 21 99 56 84

Doctorante en ?cologie marine et science halieutique
PhD student in marine ecology and fishery science

<>< <>< <>< <><

IFREMER
Centre Manche Mer du Nord
150 quai Gambetta
62200 Boulogne-sur-Mer

<>< <>< <>< <><


From Keith.Jewell at campdenbri.co.uk  Tue Feb  3 17:15:23 2015
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Tue, 3 Feb 2015 16:15:23 +0000
Subject: [R] rgl::writeWebGL( , prefix = , )
In-Reply-To: <54D0E5DB.8000005@gmail.com>
References: <5F22AFBADFE10342ABECF0281DE9921816B31050@EXCH001.campden.co.uk>
	<54D0E5DB.8000005@gmail.com>
Message-ID: <maqs6m$coq$1@ger.gmane.org>

Thanks Duncan, your suggestions led me to a solution.

Perhaps this could be reflected in the help, but I'll leave that 
decision to you.

It comes down to the template. As well as including a single line for 
each scene containing
   paste("%", prefix, "WebGL%"); e.g. %WebGL% or %AWebGL%
the <body  > tag must contain an onload attribute with an element for 
each scene
   paste0(prefix, "webGLStart();")
e.g. <body onload="webGLStart(); AwebGLStart();">

While I'm suggesting additions to the help, it took me a little while to 
work out that when writing multiple scenes the result from one 
writeWebGL was the template for the next. E.g. in the above example with 
two scenes:

outfile <- writeWebGL(dir=getwd(), template = file.path(getwd(), 
"template.html"), prefix="")
# position to next scene
outfile <- writeWebGL(dir=getwd(), template = outfile, prefix="A")

Thanks for your help (and a really nice package!)

Keith J

On 03/02/2015 15:14, Duncan Murdoch wrote:
> On 03/02/2015 9:43 AM, Keith.Jewell at campdenbri.co.uk wrote:
>> Dear all,
>>
>> I am using writeWebGL to create an HTML page containing an interactive
>> 3D plot. It works fine with the default prefix="" but fails when I
>> specify a prefix "for different scenes displayed on the same web page"
>> (quoting ?writeWebGL).  I'm sure I'm misreading the help, and would
>> appreciate guidance.
>>
>> Briefly, it works fine with the default writeWebGL( ,prefix="", ) and
>> the template containing %WebGL%
>> I have not been able to make it work with any other value of prefix;
>> e.g. writeWebGL( ,prefix="A",) and the template containing %AWebGL%
>>
>> Here is code illustrating the problem.
>>
>> First create three templates:
>> a) Vanilla: copied system.file(file.path("WebGL", "template.html"),
>> package="rgl") to file.path(getwd(), "template.html")
>>
>> b) First attempt: ?writeWebGL says # "[the template] should contain a
>> single line containing paste("%", prefix, "WebGL%"), e.g. %WebGL% with
>> the default empty prefix"
>> paste("%", "A", "WebGL%")
>> # [1] "% A WebGL%"
>> so file.path(getwd(), "templateA.html") is a copy of (a) replacing
>> %WebGL% with % A WebGL%
>>
>> c) Second attempt: file.path(getwd(), "templateB.html") is  a copy of
>> (a) replacing %WebGL% with %AWebGL%
>>
>> then, in R
>> #-----------
>> library(rgl)
>> plot3d(1:5, 1:5, 1:5) # generate rgl scene
>> #-----------
>> # a) vanilla
>> writeWebGL(dir=getwd(), template = file.path(getwd(),
>> "template.html"), prefix="")
>> # works OK; result opens and works in IE
>> #----------------
>> # b) First attempt, my reading of ?writeWebGL
>> writeWebGL(dir=getwd(), template = file.path(getwd(),
>> "templateA.html"), prefix="A")
>> # Error in writeWebGL(dir = getwd(), template = file.path(getwd(),
>> "templateA.html"),  :
>> #                       template ?m://templateA.html? does not contain
>> %AWebGL%
>> # so it looks as if the help is trivially wrong, it should be paste0
>> paste0("%", "A", "WebGL%")
>
> Yes, that's right.  I'll fix it.
>
>> # [1] "%AWebGL%"
>> #----------------
>> # c) second attempt using %AWebGL%
>> writeWebGL(dir=getwd(), template = file.path(getwd(),
>> "templateB.html"), prefix="A")
>> # runs without error in R but IE displays "You must enable Javascript
>> to view this page properly."
>> #--------------
>>
>> I don't understand why (c) is different from (a).
>
> There may be an error in the generated Javascript.  In Firefox, you
> could ask to see the browser console log, and it would report if there
> was an error on the page; sometimes those make the Javascript fail, and
> it falls back to the error message you saw.  I don't know how/if you can
> do that in IE.
>
>
>>
>> Here are the system details:
>>
>> R version 3.1.0 (2014-04-10)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United Kingdom.1252
>> [2] LC_CTYPE=English_United Kingdom.1252
>> [3] LC_MONETARY=English_United Kingdom.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United Kingdom.1252
>>
>> attached base packages:
>> [1] grDevices datasets  splines   graphics  stats     tcltk     utils
>>   [8] tools     methods   base
>>
>> other attached packages:
>> [1] knitr_1.8       animation_2.3   rgl_0.95.1158   CBRIutils_1.0
>
> That's an old version of rgl; current on CRAN is 0.95.1201.
> <http://cran.r-project.org/src/contrib/rgl_0.95.1201.tar.gz> (CRAN OSX
> currently has an old binary; I don't recommend that you use it.  I don't
> know why they haven't updated to the current one.) r-forge has even
> newer versions, but I'm in the middle of some changes there, so I don't
> recommend using that version right now.
>
> Duncan Murdoch
> <http://cran.r-project.org/src/contrib/rgl_0.95.1201.tar.gz>
>>   [5] stringr_0.6.2   svSocket_0.9-55 TinnR_1.0-5     R2HTML_2.3.1
>>   [9] Hmisc_3.12-2    Formula_1.1-1   survival_2.37-7
>>
>> loaded via a namespace (and not attached):
>> [1] cluster_1.15.3  devtools_1.6.1  evaluate_0.5.5  formatR_1.0
>> [5] grid_3.1.0      highr_0.4       lattice_0.20-29 rpart_4.1-8
>> [9] svMisc_0.9-70
>>
>> Internet Explorer 11 Version 11.0.9600.17420
>>
>> Any advice is welcome.
>>
>>
>> Keith Jewell - Statistician
>> Tel: +44 (0)1386 842055
>> Web:  www.campdenbri.co.uk
>> Email:  keith.jewell at campdenBRI.co.uk
>>
>> Campden BRI (Chipping Campden) Limited - part of the Campden BRI group
>> Station Road ? Chipping Campden ? Gloucestershire ? GL55 6LD ? UK


From dwinsemius at comcast.net  Tue Feb  3 18:18:44 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 3 Feb 2015 09:18:44 -0800
Subject: [R] rgl::writeWebGL( , prefix = , )
In-Reply-To: <54D0E5DB.8000005@gmail.com>
References: <5F22AFBADFE10342ABECF0281DE9921816B31050@EXCH001.campden.co.uk>
	<54D0E5DB.8000005@gmail.com>
Message-ID: <834D1017-EDA9-41F4-83DF-A92EED197D53@comcast.net>


On Feb 3, 2015, at 7:14 AM, Duncan Murdoch wrote:

> On 03/02/2015 9:43 AM, Keith.Jewell at campdenbri.co.uk wrote:
>> Dear all,
>> 
>> I am using writeWebGL to create an HTML page containing an interactive 3D plot. It works fine with the default prefix="" but fails when I specify a prefix "for different scenes displayed on the same web page" (quoting ?writeWebGL).  I'm sure I'm misreading the help, and would appreciate guidance.
>> 
>> Briefly, it works fine with the default writeWebGL( ,prefix="", ) and the template containing %WebGL%
>> I have not been able to make it work with any other value of prefix; e.g. writeWebGL( ,prefix="A",) and the template containing %AWebGL%
>> 
>> Here is code illustrating the problem.
>> 
>> First create three templates:
>> a) Vanilla: copied system.file(file.path("WebGL", "template.html"), package="rgl") to file.path(getwd(), "template.html")
>> 
>> b) First attempt: ?writeWebGL says # "[the template] should contain a single line containing paste("%", prefix, "WebGL%"), e.g. %WebGL% with the default empty prefix"
>> paste("%", "A", "WebGL%")
>> # [1] "% A WebGL%"
>> so file.path(getwd(), "templateA.html") is a copy of (a) replacing %WebGL% with % A WebGL%
>> 
>> c) Second attempt: file.path(getwd(), "templateB.html") is  a copy of (a) replacing %WebGL% with %AWebGL%
>> 
>> then, in R
>> #-----------
>> library(rgl)
>> plot3d(1:5, 1:5, 1:5) # generate rgl scene
>> #-----------
>> # a) vanilla
>> writeWebGL(dir=getwd(), template = file.path(getwd(), "template.html"), prefix="")
>> # works OK; result opens and works in IE
>> #----------------
>> # b) First attempt, my reading of ?writeWebGL
>> writeWebGL(dir=getwd(), template = file.path(getwd(), "templateA.html"), prefix="A")
>> # Error in writeWebGL(dir = getwd(), template = file.path(getwd(), "templateA.html"),  :
>> #                       template ?m://templateA.html? does not contain %AWebGL%
>> # so it looks as if the help is trivially wrong, it should be paste0
>> paste0("%", "A", "WebGL%")
> 
> Yes, that's right.  I'll fix it.
> 
>> # [1] "%AWebGL%"
>> #----------------
>> # c) second attempt using %AWebGL%
>> writeWebGL(dir=getwd(), template = file.path(getwd(), "templateB.html"), prefix="A")
>> # runs without error in R but IE displays "You must enable Javascript to view this page properly."
>> #--------------
>> 
>> I don't understand why (c) is different from (a).
> 
> There may be an error in the generated Javascript.  In Firefox, you could ask to see the browser console log, and it would report if there was an error on the page; sometimes those make the Javascript fail, and it falls back to the error message you saw.  I don't know how/if you can do that in IE.
> 
> 
>> 
>> Here are the system details:
>> 
>> R version 3.1.0 (2014-04-10)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>> 
>> locale:
>> [1] LC_COLLATE=English_United Kingdom.1252
>> [2] LC_CTYPE=English_United Kingdom.1252
>> [3] LC_MONETARY=English_United Kingdom.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United Kingdom.1252
>> 
>> attached base packages:
>> [1] grDevices datasets  splines   graphics  stats     tcltk     utils
>>  [8] tools     methods   base
>> 
>> other attached packages:
>> [1] knitr_1.8       animation_2.3   rgl_0.95.1158   CBRIutils_1.0
> 
> That's an old version of rgl; current on CRAN is 0.95.1201. <http://cran.r-project.org/src/contrib/rgl_0.95.1201.tar.gz> (CRAN OSX currently has an old binary; I don't recommend that you use it.  I don't know why they haven't updated to the current one.)

I'm not sure why either, but that newer package does fail compilation on both trunks of the Mac platform. I have version 1098 on my OSX 10.7.5 box (and I'm pretty sure that's the one on my Yosemite-equiped laptop. I just tried compiling from source on the Lion platform with the source at CRAN and it fails there, too. (Sometimes I am able to get packages to compile that report errors on CRAN.)

The first error reported from efforts at installing both 1201 and 1208 versions is:

checking for X... libraries , headers 
checking for glEnd in -lGL... no
configure: error: missing required library GL

-- 
David.


> r-forge has even newer versions, but I'm in the middle of some changes there, so I don't recommend using that version right now.
> 
> Duncan Murdoch
> <http://cran.r-project.org/src/contrib/rgl_0.95.1201.tar.gz>
>>  [5] stringr_0.6.2   svSocket_0.9-55 TinnR_1.0-5     R2HTML_2.3.1
>>  [9] Hmisc_3.12-2    Formula_1.1-1   survival_2.37-7
>> 
>> loaded via a namespace (and not attached):
>> [1] cluster_1.15.3  devtools_1.6.1  evaluate_0.5.5  formatR_1.0
>> [5] grid_3.1.0      highr_0.4       lattice_0.20-29 rpart_4.1-8
>> [9] svMisc_0.9-70
>> 
>> Internet Explorer 11 Version 11.0.9600.17420
>> 
>> Any advice is welcome.
>> 
>> 
>> Keith Jewell - Statistician

snipped footers ---


David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Tue Feb  3 18:32:33 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 3 Feb 2015 12:32:33 -0500
Subject: [R] rgl::writeWebGL( , prefix = , )
In-Reply-To: <maqs6m$coq$1@ger.gmane.org>
References: <5F22AFBADFE10342ABECF0281DE9921816B31050@EXCH001.campden.co.uk>	<54D0E5DB.8000005@gmail.com>
	<maqs6m$coq$1@ger.gmane.org>
Message-ID: <54D10631.4060505@gmail.com>

On 03/02/2015 11:15 AM, Keith Jewell wrote:
> Thanks Duncan, your suggestions led me to a solution.
>
> Perhaps this could be reflected in the help, but I'll leave that
> decision to you.
>
> It comes down to the template. As well as including a single line for
> each scene containing
>     paste("%", prefix, "WebGL%"); e.g. %WebGL% or %AWebGL%
> the <body  > tag must contain an onload attribute with an element for
> each scene
>     paste0(prefix, "webGLStart();")
> e.g. <body onload="webGLStart(); AwebGLStart();">

In the next revision, the %prefix% substitution will be done, so that 
won't need manual editing.
>
> While I'm suggesting additions to the help, it took me a little while to
> work out that when writing multiple scenes the result from one
> writeWebGL was the template for the next. E.g. in the above example with
> two scenes:
>
> outfile <- writeWebGL(dir=getwd(), template = file.path(getwd(),
> "template.html"), prefix="")
> # position to next scene
> outfile <- writeWebGL(dir=getwd(), template = outfile, prefix="A")
>
> Thanks for your help (and a really nice package!)

You should also look at knitr:  recent versions have good support for 
including WebGL output automatically.  You just
need to say that you want the WebGL driver, and it handles the details.  
I've used it with Markdown (that's what the current rgl vignette uses), 
but there are also other input formats that can produce .html output.

Duncan Murdoch

>
> Keith J
>
> On 03/02/2015 15:14, Duncan Murdoch wrote:
> > On 03/02/2015 9:43 AM, Keith.Jewell at campdenbri.co.uk wrote:
> >> Dear all,
> >>
> >> I am using writeWebGL to create an HTML page containing an interactive
> >> 3D plot. It works fine with the default prefix="" but fails when I
> >> specify a prefix "for different scenes displayed on the same web page"
> >> (quoting ?writeWebGL).  I'm sure I'm misreading the help, and would
> >> appreciate guidance.
> >>
> >> Briefly, it works fine with the default writeWebGL( ,prefix="", ) and
> >> the template containing %WebGL%
> >> I have not been able to make it work with any other value of prefix;
> >> e.g. writeWebGL( ,prefix="A",) and the template containing %AWebGL%
> >>
> >> Here is code illustrating the problem.
> >>
> >> First create three templates:
> >> a) Vanilla: copied system.file(file.path("WebGL", "template.html"),
> >> package="rgl") to file.path(getwd(), "template.html")
> >>
> >> b) First attempt: ?writeWebGL says # "[the template] should contain a
> >> single line containing paste("%", prefix, "WebGL%"), e.g. %WebGL% with
> >> the default empty prefix"
> >> paste("%", "A", "WebGL%")
> >> # [1] "% A WebGL%"
> >> so file.path(getwd(), "templateA.html") is a copy of (a) replacing
> >> %WebGL% with % A WebGL%
> >>
> >> c) Second attempt: file.path(getwd(), "templateB.html") is  a copy of
> >> (a) replacing %WebGL% with %AWebGL%
> >>
> >> then, in R
> >> #-----------
> >> library(rgl)
> >> plot3d(1:5, 1:5, 1:5) # generate rgl scene
> >> #-----------
> >> # a) vanilla
> >> writeWebGL(dir=getwd(), template = file.path(getwd(),
> >> "template.html"), prefix="")
> >> # works OK; result opens and works in IE
> >> #----------------
> >> # b) First attempt, my reading of ?writeWebGL
> >> writeWebGL(dir=getwd(), template = file.path(getwd(),
> >> "templateA.html"), prefix="A")
> >> # Error in writeWebGL(dir = getwd(), template = file.path(getwd(),
> >> "templateA.html"),  :
> >> #                       template ?m://templateA.html? does not contain
> >> %AWebGL%
> >> # so it looks as if the help is trivially wrong, it should be paste0
> >> paste0("%", "A", "WebGL%")
> >
> > Yes, that's right.  I'll fix it.
> >
> >> # [1] "%AWebGL%"
> >> #----------------
> >> # c) second attempt using %AWebGL%
> >> writeWebGL(dir=getwd(), template = file.path(getwd(),
> >> "templateB.html"), prefix="A")
> >> # runs without error in R but IE displays "You must enable Javascript
> >> to view this page properly."
> >> #--------------
> >>
> >> I don't understand why (c) is different from (a).
> >
> > There may be an error in the generated Javascript.  In Firefox, you
> > could ask to see the browser console log, and it would report if there
> > was an error on the page; sometimes those make the Javascript fail, and
> > it falls back to the error message you saw.  I don't know how/if you can
> > do that in IE.
> >
> >
> >>
> >> Here are the system details:
> >>
> >> R version 3.1.0 (2014-04-10)
> >> Platform: i386-w64-mingw32/i386 (32-bit)
> >>
> >> locale:
> >> [1] LC_COLLATE=English_United Kingdom.1252
> >> [2] LC_CTYPE=English_United Kingdom.1252
> >> [3] LC_MONETARY=English_United Kingdom.1252
> >> [4] LC_NUMERIC=C
> >> [5] LC_TIME=English_United Kingdom.1252
> >>
> >> attached base packages:
> >> [1] grDevices datasets  splines   graphics  stats     tcltk     utils
> >>   [8] tools     methods   base
> >>
> >> other attached packages:
> >> [1] knitr_1.8       animation_2.3   rgl_0.95.1158   CBRIutils_1.0
> >
> > That's an old version of rgl; current on CRAN is 0.95.1201.
> > <http://cran.r-project.org/src/contrib/rgl_0.95.1201.tar.gz> (CRAN OSX
> > currently has an old binary; I don't recommend that you use it.  I don't
> > know why they haven't updated to the current one.) r-forge has even
> > newer versions, but I'm in the middle of some changes there, so I don't
> > recommend using that version right now.
> >
> > Duncan Murdoch
> > <http://cran.r-project.org/src/contrib/rgl_0.95.1201.tar.gz>
> >>   [5] stringr_0.6.2   svSocket_0.9-55 TinnR_1.0-5     R2HTML_2.3.1
> >>   [9] Hmisc_3.12-2    Formula_1.1-1   survival_2.37-7
> >>
> >> loaded via a namespace (and not attached):
> >> [1] cluster_1.15.3  devtools_1.6.1  evaluate_0.5.5  formatR_1.0
> >> [5] grid_3.1.0      highr_0.4       lattice_0.20-29 rpart_4.1-8
> >> [9] svMisc_0.9-70
> >>
> >> Internet Explorer 11 Version 11.0.9600.17420
> >>
> >> Any advice is welcome.
> >>
> >>
> >> Keith Jewell - Statistician
> >> Tel: +44 (0)1386 842055
> >> Web:  www.campdenbri.co.uk
> >> Email:  keith.jewell at campdenBRI.co.uk
> >>
> >> Campden BRI (Chipping Campden) Limited - part of the Campden BRI group
> >> Station Road ? Chipping Campden ? Gloucestershire ? GL55 6LD ? UK
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue Feb  3 18:42:09 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 03 Feb 2015 12:42:09 -0500
Subject: [R] rgl::writeWebGL( , prefix = , )
In-Reply-To: <834D1017-EDA9-41F4-83DF-A92EED197D53@comcast.net>
References: <5F22AFBADFE10342ABECF0281DE9921816B31050@EXCH001.campden.co.uk>
	<54D0E5DB.8000005@gmail.com>
	<834D1017-EDA9-41F4-83DF-A92EED197D53@comcast.net>
Message-ID: <54D10871.6010105@gmail.com>

On 03/02/2015 12:18 PM, David Winsemius wrote:
> On Feb 3, 2015, at 7:14 AM, Duncan Murdoch wrote:
>
> > On 03/02/2015 9:43 AM, Keith.Jewell at campdenbri.co.uk wrote:
> >> Dear all,
> >>
> >> I am using writeWebGL to create an HTML page containing an interactive 3D plot. It works fine with the default prefix="" but fails when I specify a prefix "for different scenes displayed on the same web page" (quoting ?writeWebGL).  I'm sure I'm misreading the help, and would appreciate guidance.
> >>
> >> Briefly, it works fine with the default writeWebGL( ,prefix="", ) and the template containing %WebGL%
> >> I have not been able to make it work with any other value of prefix; e.g. writeWebGL( ,prefix="A",) and the template containing %AWebGL%
> >>
> >> Here is code illustrating the problem.
> >>
> >> First create three templates:
> >> a) Vanilla: copied system.file(file.path("WebGL", "template.html"), package="rgl") to file.path(getwd(), "template.html")
> >>
> >> b) First attempt: ?writeWebGL says # "[the template] should contain a single line containing paste("%", prefix, "WebGL%"), e.g. %WebGL% with the default empty prefix"
> >> paste("%", "A", "WebGL%")
> >> # [1] "% A WebGL%"
> >> so file.path(getwd(), "templateA.html") is a copy of (a) replacing %WebGL% with % A WebGL%
> >>
> >> c) Second attempt: file.path(getwd(), "templateB.html") is  a copy of (a) replacing %WebGL% with %AWebGL%
> >>
> >> then, in R
> >> #-----------
> >> library(rgl)
> >> plot3d(1:5, 1:5, 1:5) # generate rgl scene
> >> #-----------
> >> # a) vanilla
> >> writeWebGL(dir=getwd(), template = file.path(getwd(), "template.html"), prefix="")
> >> # works OK; result opens and works in IE
> >> #----------------
> >> # b) First attempt, my reading of ?writeWebGL
> >> writeWebGL(dir=getwd(), template = file.path(getwd(), "templateA.html"), prefix="A")
> >> # Error in writeWebGL(dir = getwd(), template = file.path(getwd(), "templateA.html"),  :
> >> #                       template ?m://templateA.html? does not contain %AWebGL%
> >> # so it looks as if the help is trivially wrong, it should be paste0
> >> paste0("%", "A", "WebGL%")
> >
> > Yes, that's right.  I'll fix it.
> >
> >> # [1] "%AWebGL%"
> >> #----------------
> >> # c) second attempt using %AWebGL%
> >> writeWebGL(dir=getwd(), template = file.path(getwd(), "templateB.html"), prefix="A")
> >> # runs without error in R but IE displays "You must enable Javascript to view this page properly."
> >> #--------------
> >>
> >> I don't understand why (c) is different from (a).
> >
> > There may be an error in the generated Javascript.  In Firefox, you could ask to see the browser console log, and it would report if there was an error on the page; sometimes those make the Javascript fail, and it falls back to the error message you saw.  I don't know how/if you can do that in IE.
> >
> >
> >>
> >> Here are the system details:
> >>
> >> R version 3.1.0 (2014-04-10)
> >> Platform: i386-w64-mingw32/i386 (32-bit)
> >>
> >> locale:
> >> [1] LC_COLLATE=English_United Kingdom.1252
> >> [2] LC_CTYPE=English_United Kingdom.1252
> >> [3] LC_MONETARY=English_United Kingdom.1252
> >> [4] LC_NUMERIC=C
> >> [5] LC_TIME=English_United Kingdom.1252
> >>
> >> attached base packages:
> >> [1] grDevices datasets  splines   graphics  stats     tcltk     utils
> >>  [8] tools     methods   base
> >>
> >> other attached packages:
> >> [1] knitr_1.8       animation_2.3   rgl_0.95.1158   CBRIutils_1.0
> >
> > That's an old version of rgl; current on CRAN is 0.95.1201. <http://cran.r-project.org/src/contrib/rgl_0.95.1201.tar.gz> (CRAN OSX currently has an old binary; I don't recommend that you use it.  I don't know why they haven't updated to the current one.)
>
> I'm not sure why either, but that newer package does fail compilation on both trunks of the Mac platform. I have version 1098 on my OSX 10.7.5 box (and I'm pretty sure that's the one on my Yosemite-equiped laptop. I just tried compiling from source on the Lion platform with the source at CRAN and it fails there, too. (Sometimes I am able to get packages to compile that report errors on CRAN.)
>
> The first error reported from efforts at installing both 1201 and 1208 versions is:
>
> checking for X... libraries , headers
> checking for glEnd in -lGL... no
> configure: error: missing required library GL
>
That looks as though it's not finding the OpenGL libraries.  I think the 
usual way to get them on a Mac is to install XQuartz.  rgl doesn't have 
to use X11, but it will (e.g. if you run it from RStudio), and it 
requires the X11 files for compiling.  I haven't experimented a lot with 
systems that don't have XQuartz installed, but I just saw one yesterday 
where even the native OpenGL code (what you get when you run rgl within 
R.app) wouldn't start; after installing XQuartz, it was fixed.

Duncan Murdoch


From johnwasige at gmail.com  Tue Feb  3 19:06:44 2015
From: johnwasige at gmail.com (John Wasige)
Date: Tue, 3 Feb 2015 19:06:44 +0100
Subject: [R] reprojrecting longitude from 0 - 360 to -180 - 180
Message-ID: <CAJgdCD6D08bZS5qa5BPbXsYCH-sGoX1f+6giDw1AGDhadqeCzQ@mail.gmail.com>

Hello r community,

This is to request for help on how to reprojrect longitude from 0 - 360 to
-180 - 180
With the following script below, i get output transformed to something like
rectangle. Is there a better way of doing it?
### script
convert longitude from 0 - 360 to -180 - 180
library(raster)
rst <- raster('D:/prec/b1980p.tif')
rst <- raster(matrix(1:100, ncol=10), 0, 360, -90, 90, crs="+proj=merc")
r2 <- rotate(rst)
r2

Thanks for your help

John

	[[alternative HTML version deleted]]


From e438709 at trbvm.com  Tue Feb  3 18:56:30 2015
From: e438709 at trbvm.com (TMF)
Date: Tue, 3 Feb 2015 09:56:30 -0800 (PST)
Subject: [R] How to check a regression model's fit?
Message-ID: <1422986190284-4702766.post@n4.nabble.com>

as the title says (from an R begginer). Is it also possible that regression,
in a given data's case, just doesn't exist -- for any type of applied
regression modelling? 

Thanks!



--
View this message in context: http://r.789695.n4.nabble.com/How-to-check-a-regression-model-s-fit-tp4702766.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.ca.us  Tue Feb  3 19:08:47 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 3 Feb 2015 10:08:47 -0800 (PST)
Subject: [R] FFT Normalization Documentation
In-Reply-To: <1357405753.621214.1422971291950.JavaMail.open-xchange@omgreatgod.store>
References: <1985531401.416848.1422883625463.JavaMail.open-xchange@omgreatgod.store>
	<E17505B1-8B48-495B-8532-CE914D86AC33@xs4all.nl>
	<1357405753.621214.1422971291950.JavaMail.open-xchange@omgreatgod.store>
Message-ID: <alpine.BSF.2.00.1502030818480.76797@pedal.dcn.davis.ca.us>

Eike: Understanding Discrete Fourier Transform theory is not trivial... 
while a vignette added to the stat package has the potential help a lot of 
users, it is a bit ambitious to try to supplant the extensive published 
material on using and interpreting the DFT (particularly as there is "more 
than one way to do it" and the R fft() function is very typical of fft 
implementations). (Similar arguments could be applied to most of the stat 
package... note the absence of vignettes there.) It might be more 
practical to propose to R-devel some patches to the fft() help file 
references and examples sections. Alternatively, you could write YAB (Yet 
Another Blog) for people to search for.

Frank: While folding is an important concept to know about when 
interpreting DFT results, I think something went rather wrong in your 
example with your "mask" variable since folding applies to f (for forward 
fft) or t (for inverse fft), not to the corresponding magnitudes. In 
addition to that, it is simply not necessary to pre-fold your data before 
applying the fft... the folding is assumed by the math to exist in the 
input outside the input window, and there is nothing you can do to the 
data to affect that assumption. Folding in the output is more visibly 
evident, but presenting it as a symmetric plot is entirely optional and is 
not done in most cases.

FWIW, my take on this example:

# increment of time
dT <- 0.001 # assumed here to be seconds
# number of samples
N <- 1000
# sampled time axis
t <- seq( 1, N ) * dT
# Nyquist frequency
Fnyq <- 0.5/dT
# increment of frequency
dF <- 1 / ( N * dT )
# sampled frequency axis
f <- seq( 0L, N/2-1 ) * dF
# example data, whole number of cycles within the input window!
y <- 1 + sin( 2 * pi * 20 * t ) + 1.5 * sin( 2 * pi * 30 * t )
# Fourier Series scaling
Y <- fft( y ) / length( y )
# double all sinusoidal components, don't look beyond Nyquist frequency
Ymag <- abs( c( Y[ 1 ], 2 * Y[ 2:(N/2) ] ) )
# plot Fourier Series coefficients, note correspondence with equation
plot( f, Ymag, type='h', ylab="Amplitude", xlab="Frequency (Hz)" )
# compute inverse FFT (if original data was real, inverse will be real also)
yr <- fft( Y, inverse = TRUE )
# check real components ... differs by numerical noise
max( Re( yr ) - y )
# check imaginary components ... differs by numerical noise
max( Im( yr ) )

# now try including a frequency component that exceeds Fnyq
# leads to aliasing
y2 <- 1 + sin( 2 * pi * 20 * t ) + 1.5 * sin( 2 * pi * 970 * t )
# Fourier Series scaling
Y2 <- fft( y2 ) / length( y2 )
# double all sinusoidal components, don't look beyond Nyquist frequency
Y2mag <- abs( c( Y2[ 1 ], 2 * Y2[ 2:(N/2) ] ) )
# plot Fourier Series coefficients, note unfortunate similarity to
# previous plot
plot( f, Y2mag, type='h', ylab="Amplitude", xlab="Frequency (Hz)" )
# moral is not to apply fft when significant amplitudes are present above 
# the Nyquist frequency (know your data)

On Tue, 3 Feb 2015, Eike Petersen wrote:

> Dear Frank,
> 
> thanks a lot for your reply. I was aware of the need for FFT normalization and
> folding, but you're making another good point here, stating that there should be
> examples on this (folding) in the documentation as it will pose quite an
> obstacle for newcomers attempting to practically use the FFT.
> 
> When writing yesterday's mail, I falsely was under the impression that there is
> such a thing as a "correct" normalization of an FFT. In the meantime, I have
> come to realize that when considering "real", i.e., physical, signals, there is
> no "true" way of normalizing the result of an inverse FFT, since everything
> depends on the sampling characterstics and on the properties of the frequency
> domain representation of the signal.
> 
> Just imagine two differently sampled versions of the frequency representation of
> some physical signal, both attaining the same number of sample points NFFT, but
> different sampling frequencies. There is no way to scale these two signals
> coherently, based only on the number of sample points. Assuming Fs1 < Fs2 and
> assuming the physical signal to be band-limited with Fband < Fs1, the inverse
> transform of the signal sampled at Fs1 will naturally be larger (due to the
> larger number of sinces/cosines being summed up in the time signal).
> 
> When comparing differently sampled versions of the same signal, it might be
> desirable to scale the result based on the energy content of the signal, i.e. by
> multiplying the signal with the frequency bin width 'fbin = Fs/(NFFT-1)'. So
> this is where your calculation of the attained frequencies comes into play! Note
> that this is equivalent to calculating the energy in the frequency domain by
> integration of a piecewise constant interpolation of the frequency domain FFT
> coefficients.
> 
> I want to repeat my question concerning proposals on where to publish such
> considerations for the use of as many R users as possible. Might it be a good
> idea to create and propose an official vignette to the FFT function?
> 
> Kind regards,
> Eike
>
>> On February 3, 2015 at 12:39 AM Franklin Bretschneider <bretschr at xs4all.nl>
>> wrote:
>>
>>
>> Dear Eike Petersen,
>>
>>
>> Re:
>>
>> > Hello everyone,
>> >
>> > the docpage for the fft function states:
>> >
>> > ?Description: Performs the Fast Fourier Transform of an array.?
>> >
>> > and
>> >
>> > ?Arguments ? inverse: if ?TRUE?, the unnormalized inverse transform is
>> > computed
>> > (the inverse has a ?+? in the exponent of e, but here, we do _not_ divide by
>> > ?1/length(x)?).?
>> >
>> > Judging from this, I would expect ?fft(x)? to yield the correct FFT of x,
>> > and
>> > ?fft(X, inverse = TRUE) / length(X)? to yield the correct inverse FFT of X.
>> >
>> > However, it seems to me that actually the result of ?fft(x)? should be
>> > scaled by
>> > ?1/length(x)?, while ?fft(X, inverse=TRUE)? seems to yield a correct result
>> > by
>> > default:
>> >
>> > t <- seq(0.001, 1, 0.001)
>> > y <- 1 + sin(2*pi*20*t) + 1.5 * sin(2*pi*30*t)
>> > Y <- fft(y)
>> > dev.new()
>> > plot(abs(Y)) ## Shows peaks at amplitudes 1000, 500 and 750, while they
>> > should
>> > be at amplitude 1, 0.5 and 0.75.
>> > y2 <- Re(fft(Y / length(Y), inverse = TRUE))
>> > max(abs(y-y2)) ## The IFFT yields a correctly scaled result by default, if
>> > applied to a correctly scaled FFT.
>> >
>> > Did I get something wrong? If not, having spent quite some time figuring
>> > this
>> > out, I would like to see the documentation clearly pointing this out. I find
>> > the
>> > current text rather confusing.
>> >
>> > On another note: I have spent some time working on demo files that showcase
>> > some
>> > of the properties of the FFT and their implementation in R. I have done this
>> > primarily for myself, as I keep forgetting how these things work, but I
>> > thought
>> > that it might be helpful to others as well. Any hints on where/how I should
>> > publish such a thing?
>> >
>> > Kind regards and many thanks in advance,
>> >
>> > Eike
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> As far as I know an FFT must be normalized and folded to obtain a spectrum in
>> the form we like, so this would be my version:
>>
>> # your time signal:
>>
>> t <- seq(0.001, 1, 0.001)
>> y <- 1 + sin(2*pi*20*t) + 1.5 * sin(2*pi*30*t)
>>
>> # find time and frequency calibration:
>>
>> n = length(y)
>> dt = t[2]-t[1]
>> fNyq = 1/(2*dt)
>> tmax = max(t)
>> df = 1/tmax
>>
>> # make frequency vector to display as x-values of the spectrum rather than the
>> index.
>>
>> f = seq(-fNyq, fNyq-df, by=df)
>>
>> # make folding mask
>>
>> mask=rep(c(1, -1),length.out=n)
>>
>> # fold the spectrum around the Nyquist frequency; so the DC value (f=0) is in
>> the middle; the - and + max frequency at the ends.
>>
>> yy = y * mask
>>
>> # # Then do the FFT
>>
>> YY <- fft(yy)
>>
>> Plot the amplitude spectrum vector against the freq. vector
>>
>> plot(f,abs(YY), type='h')
>>
>>
>>
>> --------
>>
>> It would be a good idea to put such an example in the help pages indeed.
>> The short example given in the manual isn't of much help for the usual
>> (periodic!) time signals.
>>
>> Hoping this helps, I remain
>>
>> With best wishes,
>>
>> Frank
>> ----
>>
>>
>>
>>
>>
>>
>> Franklin Bretschneider
>> Dept of Biology
>> Utrecht University
>> bretschr at xs4all.nl
>>
>>
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Tue Feb  3 19:21:50 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 3 Feb 2015 10:21:50 -0800 (PST)
Subject: [R] How to check a regression model's fit?
In-Reply-To: <1422986190284-4702766.post@n4.nabble.com>
References: <1422986190284-4702766.post@n4.nabble.com>
Message-ID: <alpine.BSF.2.00.1502031011150.76797@pedal.dcn.davis.ca.us>

Many ways... but they all assume you know the background theory, which you 
don't seem to, and which is off-topic here.

Consider reading some help files:

?summary.lm
?plot.lm

Re: regression not existing... the classic case is when your data fit your 
model too perfectly... regression must have some nonzero error in your 
data to work.  (That is a bonus bit of theory to get you started.)
In most real-world cases, you are more likely to encounter a situation 
where your proposed regression model is simply inappropriate for your 
data, and the regression algorithm plows along successfully computing 
garbage.

On Tue, 3 Feb 2015, TMF wrote:

> as the title says (from an R begginer). Is it also possible that regression,
> in a given data's case, just doesn't exist -- for any type of applied
> regression modelling?
>
> Thanks!
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-check-a-regression-model-s-fit-tp4702766.html
> Sent from the R help mailing list archive at Nabble.com.

Note that Nabble is _not_ the R-help mailing list archive, despite its 
claims.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

The above text may not make it to you... which is why Nabble is not the 
R-help mailing list archive.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From mikaelmilhoj at gmail.com  Tue Feb  3 21:13:57 2015
From: mikaelmilhoj at gmail.com (=?UTF-8?Q?Mikael_Olai_Milh=C3=B8j?=)
Date: Tue, 3 Feb 2015 21:13:57 +0100
Subject: [R] Plot residuals against standard normal distribution
In-Reply-To: <57A1901D-6806-441F-BD72-198BDBDC99AB@gmail.com>
References: <CACM6noZW5MK2736HTS6_f25ezQE1zNwuCc83WcyaP4jd5w6KeQ@mail.gmail.com>
	<57A1901D-6806-441F-BD72-198BDBDC99AB@gmail.com>
Message-ID: <CACM6noZOXx-FyQ6e-oSDMyHszzUjHR2Q8O+07qedhxzFpSk3+Q@mail.gmail.com>

Thx - this was exactly what I needed. Yes I also prefer the qqnorm but I
like the distrubution chart as well.
Thx !


/Mikael

On Tue, Feb 3, 2015 at 12:18 AM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> > On 02 Feb 2015, at 23:42 , Mikael Olai Milh?j <mikaelmilhoj at gmail.com>
> wrote:
> >
> > Hi,
> >
> > I'm having trouble trying to plot the density of the residuals against
> the
> > standard normal distribution N(0,1). (I'm trying to see if my residuals
> are
> > well-behaved).
> >
> > I know hwo to calculate the standardized residuals (I guess that there
> may
> > be a simple way using a R function) and then plot this by using the
> density
> > function
> >
> > y<-(model$residuals-mean(model$residuals))/sd(model$residuals)
> > plot(density(y))
> >
> > But I don't know how to add the N(0,1) curve. Any suggestions? Thanks in
> > advance
>
> I'd try
>
> curve(dnorm(x), add=TRUE)
>
> Some diddling of ylim= is usually required.
>
>
> I'd usually prefer qqnorm() for normality checks, though; it is pretty
> hard to assess the tails of density plots.
>
> Also notice rstandard(), rstudent().
>
> -pd
>
> >
> >
> > /Mikael
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From bretschr at xs4all.nl  Tue Feb  3 23:00:26 2015
From: bretschr at xs4all.nl (Franklin Bretschneider)
Date: Tue, 3 Feb 2015 23:00:26 +0100
Subject: [R] FFT Normalization Documentation
In-Reply-To: <alpine.BSF.2.00.1502030818480.76797@pedal.dcn.davis.ca.us>
References: <1985531401.416848.1422883625463.JavaMail.open-xchange@omgreatgod.store>
	<E17505B1-8B48-495B-8532-CE914D86AC33@xs4all.nl>
	<1357405753.621214.1422971291950.JavaMail.open-xchange@omgreatgod.store>
	<alpine.BSF.2.00.1502030818480.76797@pedal.dcn.davis.ca.us>
Message-ID: <9750012F-B6C9-4E69-92DB-CC5BDD49B979@xs4all.nl>

Dear Elke; Jeff,


Re:

> Eike: Understanding Discrete Fourier Transform theory is not trivial... while a vignette added to the stat package has the potential help a lot of users, it is a bit ambitious to try to supplant the extensive published material on using and interpreting the DFT (particularly as there is "more than one way to do it" and the R fft() function is very typical of fft implementations). (Similar arguments could be applied to most of the stat package... note the absence of vignettes there.) It might be more practical to propose to R-devel some patches to the fft() help file references and examples sections. Alternatively, you could write YAB (Yet Another Blog) for people to search for.
> 
> Frank: While folding is an important concept to know about when interpreting DFT results, I think something went rather wrong in your example with your "mask" variable since folding applies to f (for forward fft) or t (for inverse fft), not to the corresponding magnitudes. In addition to that, it is simply not necessary to pre-fold your data before applying the fft... the folding is assumed by the math to exist in the input outside the input window, and there is nothing you can do to the data to affect that assumption. Folding in the output is more visibly evident, but presenting it as a symmetric plot is entirely optional and is not done in most cases.



Maybe I didn't use the proper terminology, but what I called 'folding' is a modification of the input signal used only to present the amplitude spectrum in a convenient way. The FFT ("butterfly algorithm") yields a complex array where the highest frequencies (pos and neg) are in the middle, the lowest (and DC and fNyq) are at the ends. To display this same array with the DC value in the middle, the neg frequencies increasing to the left and the pos frequencies to the right, the trick with the +1/-1 mask is performed. This mask function is in fact a "square wave" at the Nyquist frequency.
In Matlab, it is in a routine called "fftshift", see here:

> 
> Y = fftshift(X) rearranges the outputs of fft, fft2, and fftn by moving the zero-frequency component to the center of the array. It is useful for visualizing a Fourier transform with the zero-frequency component in the middle of the spectrum.
> 

This is from the MathWorks web site:     http://nl.mathworks.com/help/matlab/ref/fftshift.html.

In addition, in my example I forgot to scale the amplitude. This must indeed be divided by n (the number of data points).
So, change my line YY <- fft(yy) into YY <- fft(yy)/n. Now the amplitudes of the spectral line are numerically the same as given in the composition of y.
These values must indeed be regarded with caution, since with real-world signals the energy will most often be spread among several spectral "lines".
Windowing (Hann, Hanning, Blackman etc.) then improves the spectrum, but that's a different story.

Best wishes,


Frank
---




Franklin Bretschneider
Dept of Biology
Utrecht University
bretschr at xs4all.nl


From cjackson at georgiasouthern.edu  Tue Feb  3 23:06:24 2015
From: cjackson at georgiasouthern.edu (CJ Jackson)
Date: Tue, 3 Feb 2015 17:06:24 -0500
Subject: [R] AMBUR package will not build
Message-ID: <CAJwUrv5Hgruehvj0EqwnmAreOrcN8qqnH9yVGvMCEEzqWTGAKg@mail.gmail.com>

I've been trying to build the latest version of the AMBUR package and have
been having problems.  I've noticed a few other packages experiencing build
issues.  The error appears to be on the R-Forge related based on what I've
been researching about issues with building packages.  I think it is a
library issue concerning rgeos.  The error I'm getting in the install.out
file is:

Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object '/home/rforge/lib/R/3.1/rgeos/libs/rgeos.so':
  libgeos-3.3.3.so: cannot open shared object file: No such file or
directory
Error : package ?rgeos? could not be loaded

Any help you can provide will be greatly appreciated.  Thanks!

cj
________________________________
Chester W. Jackson Jr., Ph.D.
Assistant Professor of Geology
Department of Geology & Geography
Georgia Southern University
P.O. Box 8149
Statesboro, GA  30460-8149
cjackson at georgiasouthern.edu

Applied Coastal Research Laboratory
Georgia Southern University
10 Ocean Science Circle
Savannah, GA  31411

	[[alternative HTML version deleted]]


From js.huang at protective.com  Tue Feb  3 21:56:19 2015
From: js.huang at protective.com (JS Huang)
Date: Tue, 3 Feb 2015 12:56:19 -0800 (PST)
Subject: [R] collapse a list of dataframes
In-Reply-To: <1422911724.1901.30.camel@maladmin.com>
References: <1422910812.1901.29.camel@maladmin.com>
	<CA+1Z_YsVpErVgndS=LfLRJxB3s43zqDEnbPgV4aZ=ZhEdmmOwg@mail.gmail.com>
	<1422911724.1901.30.camel@maladmin.com>
Message-ID: <1422996979057-4702773.post@n4.nabble.com>

Hi,

  The following worked.

> data.frame(rbind(as.matrix(data.frame(a=1:3,b=letters[1:3])),as.matrix(data.frame(x=1:5,b=LETTERS[1:5]))))
  a b
1 1 a
2 2 b
3 3 c
4 1 A
5 2 B
6 3 C
7 4 D
8 5 E



--
View this message in context: http://r.789695.n4.nabble.com/collapse-a-list-of-dataframes-tp4702709p4702773.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Tue Feb  3 22:21:01 2015
From: js.huang at protective.com (JS Huang)
Date: Tue, 3 Feb 2015 13:21:01 -0800 (PST)
Subject: [R] Get 10%,
	50% and 90% Quantile of data samples with probability
In-Reply-To: <1422913715619-4702717.post@n4.nabble.com>
References: <1422913715619-4702717.post@n4.nabble.com>
Message-ID: <1422998461987-4702774.post@n4.nabble.com>

Hi,

  For you first task and use your first row of data as an example.  Define a
function named dist to take care of the probability for each group.

> dist <- function(x)
+ {
+  
return(c(rep(x[1],15),rep(x[2],15),rep(x[3],25),rep(x[4],20),rep(x[5],25)))
+ }
> plot(ecdf(dist(c(2,3,2,5.3,7.3))))



--
View this message in context: http://r.789695.n4.nabble.com/Get-10-50-and-90-Quantile-of-data-samples-with-probability-tp4702717p4702774.html
Sent from the R help mailing list archive at Nabble.com.


From wdunlap at tibco.com  Wed Feb  4 00:34:21 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 3 Feb 2015 15:34:21 -0800
Subject: [R] collapse a list of dataframes
In-Reply-To: <1422996979057-4702773.post@n4.nabble.com>
References: <1422910812.1901.29.camel@maladmin.com>
	<CA+1Z_YsVpErVgndS=LfLRJxB3s43zqDEnbPgV4aZ=ZhEdmmOwg@mail.gmail.com>
	<1422911724.1901.30.camel@maladmin.com>
	<1422996979057-4702773.post@n4.nabble.com>
Message-ID: <CAF8bMcZnuGTjfwycLgv+CdJAL8cV2ONss8n2b5acb_vZ8orvdQ@mail.gmail.com>

I don't think that worked as OP would like it too - all columns of the
output
are factors.
>
 data.frame(rbind(as.matrix(data.frame(a=1:3,b=letters[1:3])),as.matrix(data.frame(x=1:5,b=LETTERS[1:5]))))
  a b
1 1 a
2 2 b
3 3 c
4 1 A
5 2 B
6 3 C
7 4 D
8 5 E
> str(.Last.value)
'data.frame':   8 obs. of  2 variables:
 $ a: Factor w/ 5 levels "1","2","3","4",..: 1 2 3 1 2 3 4 5
 $ b: Factor w/ 8 levels "a","A","b","B",..: 1 3 5 2 4 6 7 8

If you want the retain the types of the columns, leave out those as.matrix()
calls (and then there is no need to call data.frame on rbind's output).



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Feb 3, 2015 at 12:56 PM, JS Huang <js.huang at protective.com> wrote:

> Hi,
>
>   The following worked.
>
> >
> data.frame(rbind(as.matrix(data.frame(a=1:3,b=letters[1:3])),as.matrix(data.frame(x=1:5,b=LETTERS[1:5]))))
>   a b
> 1 1 a
> 2 2 b
> 3 3 c
> 4 1 A
> 5 2 B
> 6 3 C
> 7 4 D
> 8 5 E
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/collapse-a-list-of-dataframes-tp4702709p4702773.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Feb  4 00:41:25 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 03 Feb 2015 15:41:25 -0800
Subject: [R] AMBUR package will not build
In-Reply-To: <CAJwUrv5Hgruehvj0EqwnmAreOrcN8qqnH9yVGvMCEEzqWTGAKg@mail.gmail.com>
References: <CAJwUrv5Hgruehvj0EqwnmAreOrcN8qqnH9yVGvMCEEzqWTGAKg@mail.gmail.com>
Message-ID: <1D623F82-486F-465C-8567-E8AFDE5E1DE6@dcn.davis.CA.us>

You may be able to learn something useful from how the maptools package handles that dependency?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 3, 2015 2:06:24 PM PST, CJ Jackson <cjackson at georgiasouthern.edu> wrote:
>I've been trying to build the latest version of the AMBUR package and
>have
>been having problems.  I've noticed a few other packages experiencing
>build
>issues.  The error appears to be on the R-Forge related based on what
>I've
>been researching about issues with building packages.  I think it is a
>library issue concerning rgeos.  The error I'm getting in the
>install.out
>file is:
>
>Error in dyn.load(file, DLLpath = DLLpath, ...) :
>unable to load shared object
>'/home/rforge/lib/R/3.1/rgeos/libs/rgeos.so':
>  libgeos-3.3.3.so: cannot open shared object file: No such file or
>directory
>Error : package ?rgeos? could not be loaded
>
>Any help you can provide will be greatly appreciated.  Thanks!
>
>cj
>________________________________
>Chester W. Jackson Jr., Ph.D.
>Assistant Professor of Geology
>Department of Geology & Geography
>Georgia Southern University
>P.O. Box 8149
>Statesboro, GA  30460-8149
>cjackson at georgiasouthern.edu
>
>Applied Coastal Research Laboratory
>Georgia Southern University
>10 Ocean Science Circle
>Savannah, GA  31411
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Wed Feb  4 01:28:46 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 4 Feb 2015 00:28:46 +0000
Subject: [R] How to tell if there is overdispersion in a GLMM?
References: <CAK70=f5RdYgFucy3UVMsBLqhJPbU8SJRdqBsgc5-Aq2PtwF01w@mail.gmail.com>
Message-ID: <loom.20150204T012536-881@post.gmane.org>

maggy yan <kiotoqq <at> gmail.com> writes:

> 
> I read something on http://glmm.wikidot.com/faq, under "How can I deal with
> overdispersion in GLMMs?":
> 
> library(lme4)  ## 1.0-4set.seed(101)
> d <- data.frame(y=rpois(1000,lambda=3),x=runif(1000),
>             f=factor(sample(1:10,size=1000,replace=TRUE)))
> m1 <- glmer(y~x+(1|f),data=d,family=poisson)
> overdisp_fun(m1)
  ##        chisq        ratio          rdf            p
> ## 1026.7780815    1.0298677  997.0000000    0.2497659
> library(glmmADMB)  ## 0.7.7
> m2 <- glmmadmb(y~x+(1|f),data=d,family="poisson")
> overdisp_fun(m2)   
  ##        chisq        ratio          rdf            p
> ## 1026.7585031    1.0298480  997.0000000    0.2499024
> 
> In both case, the chisq is > rdf, does it mean there is over dispersion?
> 
> thanks for any help
> 

 Off-topic here, but:

  the residual deviance is greater than the residual degrees
of freedom, but only a little bit (3%).  So, technically, there
is overdispersion here, but not more than expected if the underlying
data generating process was not overdispersed
 (p-value = 0.25).  Which is a good thing
because the data are generated from a Poisson distribution, so
the null hypothesis is actually true.


From Shanley.Chong at sswahs.nsw.gov.au  Wed Feb  4 01:56:04 2015
From: Shanley.Chong at sswahs.nsw.gov.au (Shanley Chong)
Date: Wed, 4 Feb 2015 00:56:04 +0000
Subject: [R] R2BayesX
Message-ID: <90AD9DB98926A747B1C82FC2EE31E8A45BE55769@LIVSVEXMBX01.intra.swsahs.nsw.gov.au>

Hi,

I am trying to run STAR logistic/binomial model using R2BayesX . A warning message came up every time when i included a random effect, bs='re', (unstructured spatial effect) into the model. The warning message is : Warning message: running command '"C:/Users/ChongS/Documents/R/win-library/3.1/BayesXsrc/libs/x64/BayesX.exe" C:/Users/ChongS/AppData/Local/Temp/RtmpCW8QY9/bayesx33/bayesx.estim.input.prg' had status 5

The model is fine when i just ran the model using mrf, bs='mrf', (structured spatial effect).

And when i tried to run STAR using family=Gaussian (response is normally distributed) with structured and unstructured spatial effect, it is fine too.

Can anyone please help?

Regards,

Shanley


_____________________________________________________________________ 
This email has been scanned for the Sydney & South Western Sydney Local Health Districts by the MessageLabs Email Security System.
Sydney & South Western Sydney Local Health Districts regularly monitor email and attachments to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.
	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Wed Feb  4 04:15:35 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 04 Feb 2015 03:15:35 +0000
Subject: [R] reprojrecting longitude from 0 - 360 to -180 - 180
References: <CAJgdCD6D08bZS5qa5BPbXsYCH-sGoX1f+6giDw1AGDhadqeCzQ@mail.gmail.com>
Message-ID: <CAAcGz99GS=_z+4WhLW8tuYVbp9CWJCd55Ru9GCq7JfqOQGgMGw@mail.gmail.com>

On Wed Feb 04 2015 at 5:10:02 AM John Wasige <johnwasige at gmail.com> wrote:

> Hello r community,
>
> This is to request for help on how to reprojrect longitude from 0 - 360 to
> -180 - 180
> With the following script below, i get output transformed to something like
> rectangle. Is there a better way of doing it?
> ### script
> convert longitude from 0 - 360 to -180 - 180
> library(raster)
> rst <- raster('D:/prec/b1980p.tif')
>

I'm confused as why you load from file, but then overwrite that result with
the next line below


> rst <- raster(matrix(1:100, ncol=10), 0, 360, -90, 90, crs="+proj=merc")
>

"+proj=merc" is completely incompatible with an extent in longitude and
latitude - merc is Mercator, which is a metre-based projection by default,
with this PROJ.4 string. If you literally mean 0-360 on WGS84 (for example)
then you should use

, crs = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0
+over"

(+over indicates that you cross the dateline, but its use/application is
not seamless)

If you apply the Mercator projection to xmn=0, xmx=360, ymn=-90, ymx=90 you
are specifying a 360 x 180 metre region in the Atlantic ocean. For example

library(raster)
library(rgdal)
## project just the extent of this raster to longlat
projectExtent(rst, "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
+towgs84=0,0,0 +over")
class       : RasterLayer
dimensions  : 10, 10, 100  (nrow, ncol, ncell)
resolution  : 0.0003233935, 0.0001627865  (x, y)
extent      : 0, 0.003233935, -0.0008139325, 0.0008139325  (xmin, xmax,
ymin, ymax)
coord. ref. : +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
+towgs84=0,0,0 +over


r2 <- rotate(rst)
> r2
>
>
The function raster::rotate is intended purely for the longlat case 0,360
modified to -180,180 - it does "work" for other cases but it's not
guaranteed to - and it's not written in a general way for other cases.

Hope that clarifies a few things, also please use the R-Sig-Geo mailing
list for a group more relevant to these topics.

Cheers, Mike.


> Thanks for your help
>
> John
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Feb  4 04:43:25 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 3 Feb 2015 19:43:25 -0800 (PST)
Subject: [R] FFT Normalization Documentation
In-Reply-To: <9750012F-B6C9-4E69-92DB-CC5BDD49B979@xs4all.nl>
References: <1985531401.416848.1422883625463.JavaMail.open-xchange@omgreatgod.store>
	<E17505B1-8B48-495B-8532-CE914D86AC33@xs4all.nl>
	<1357405753.621214.1422971291950.JavaMail.open-xchange@omgreatgod.store>
	<alpine.BSF.2.00.1502030818480.76797@pedal.dcn.davis.ca.us>
	<9750012F-B6C9-4E69-92DB-CC5BDD49B979@xs4all.nl>
Message-ID: <alpine.BSF.2.00.1502031940000.55863@pedal.dcn.davis.ca.us>

I see now the trick... the square wave clarified it for me. It is indeed 
faster than re-arranging the data if putting the zero frequency in the 
middle of the data is your goal.

Since I only do that for the purposes of teaching I probably won't be 
using it, but it may well be an interesting "trick" to put in the 
examples.

On Tue, 3 Feb 2015, Franklin Bretschneider wrote:

> Dear Elke; Jeff,
>
>
> Re:
>
>> Eike: Understanding Discrete Fourier Transform theory is not trivial... while a vignette added to the stat package has the potential help a lot of users, it is a bit ambitious to try to supplant the extensive published material on using and interpreting the DFT (particularly as there is "more than one way to do it" and the R fft() function is very typical of fft implementations). (Similar arguments could be applied to most of the stat package... note the absence of vignettes there.) It might be more practical to propose to R-devel some patches to the fft() help file references and examples sections. Alternatively, you could write YAB (Yet Another Blog) for people to search for.
>>
>> Frank: While folding is an important concept to know about when interpreting DFT results, I think something went rather wrong in your example with your "mask" variable since folding applies to f (for forward fft) or t (for inverse fft), not to the corresponding magnitudes. In addition to that, it is simply not necessary to pre-fold your data before applying the fft... the folding is assumed by the math to exist in the input outside the input window, and there is nothing you can do to the data to affect that assumption. Folding in the output is more visibly evident, but presenting it as a symmetric plot is entirely optional and is not done in most cases.
>
>
>
> Maybe I didn't use the proper terminology, but what I called 'folding' is a modification of the input signal used only to present the amplitude spectrum in a convenient way. The FFT ("butterfly algorithm") yields a complex array where the highest frequencies (pos and neg) are in the middle, the lowest (and DC and fNyq) are at the ends. To display this same array with the DC value in the middle, the neg frequencies increasing to the left and the pos frequencies to the right, the trick with the +1/-1 mask is performed. This mask function is in fact a "square wave" at the Nyquist frequency.
> In Matlab, it is in a routine called "fftshift", see here:
>
>>
>> Y = fftshift(X) rearranges the outputs of fft, fft2, and fftn by moving the zero-frequency component to the center of the array. It is useful for visualizing a Fourier transform with the zero-frequency component in the middle of the spectrum.
>>
>
> This is from the MathWorks web site:     http://nl.mathworks.com/help/matlab/ref/fftshift.html.
>
> In addition, in my example I forgot to scale the amplitude. This must indeed be divided by n (the number of data points).
> So, change my line YY <- fft(yy) into YY <- fft(yy)/n. Now the amplitudes of the spectral line are numerically the same as given in the composition of y.
> These values must indeed be regarded with caution, since with real-world signals the energy will most often be spread among several spectral "lines".
> Windowing (Hann, Hanning, Blackman etc.) then improves the spectrum, but that's a different story.
>
> Best wishes,
>
>
> Frank
> ---
>
>
>
>
> Franklin Bretschneider
> Dept of Biology
> Utrecht University
> bretschr at xs4all.nl
>
>
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From Achim.Zeileis at uibk.ac.at  Wed Feb  4 10:19:56 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Wed, 4 Feb 2015 10:19:56 +0100 (CET)
Subject: [R] R2BayesX
In-Reply-To: <90AD9DB98926A747B1C82FC2EE31E8A45BE55769@LIVSVEXMBX01.intra.swsahs.nsw.gov.au>
References: <90AD9DB98926A747B1C82FC2EE31E8A45BE55769@LIVSVEXMBX01.intra.swsahs.nsw.gov.au>
Message-ID: <alpine.DEB.2.11.1502041018160.2229@paninaro.uibk.ac.at>

Shanley:

> I am trying to run STAR logistic/binomial model using R2BayesX . A 
> warning message came up every time when i included a random effect, 
> bs='re', (unstructured spatial effect) into the model. The warning 
> message is : Warning message: running command 
> '"C:/Users/ChongS/Documents/R/win-library/3.1/BayesXsrc/libs/x64/BayesX.exe" 
> C:/Users/ChongS/AppData/Local/Temp/RtmpCW8QY9/bayesx33/bayesx.estim.input.prg' 
> had status 5

I haven't seen this problem before. Maybe you can provide "commented, 
minimal, self-contained, reproducible code" (as the posting guide asks)?

I'm also cc'ing the package maintainer (Nikolaus Umlauf) as he might be 
able to give more insight.

Best,
Z

> The model is fine when i just ran the model using mrf, bs='mrf', (structured spatial effect).
>
> And when i tried to run STAR using family=Gaussian (response is normally distributed) with structured and unstructured spatial effect, it is fine too.
>
> Can anyone please help?
>
> Regards,
>
> Shanley
>
>
> _____________________________________________________________________
> This email has been scanned for the Sydney & South Western Sydney Local Health Districts by the MessageLabs Email Security System.
> Sydney & South Western Sydney Local Health Districts regularly monitor email and attachments to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From doug.reid at ontario.ca  Wed Feb  4 15:50:07 2015
From: doug.reid at ontario.ca (Reid, Doug (MNRF))
Date: Wed, 4 Feb 2015 14:50:07 +0000
Subject: [R] bargraph.CI and arrows
Message-ID: <DA616A2FCD46844DB2333D0BD00DE545175B3A@CTSPIGDCAPMXS31.cihs.ad.gov.on.ca>

Hello R-Help folks.  I'm fairly new to R and particularly the graphing functions.  The figures I have made look great though and so I want to use it more.
I am using bargraph.CI and have made several charts successfully using raw data.  I have a figure, however that doesn't lend itself to the functions (calculations) in bargraph.CI because it does not present conventional  means and standard errors.  Still I would like the figure to have the same look as others I am presenting so I want to use the same plot function
Selection ratios and associated standard errors were calculated as per Manley et al (2002) to assess cover type preference for some critters.  Selection Ratios were calculated at two scales from a sample of individual animal locations from the population (used points), and an equal number of random locations (available points): 2nd order across the entire area of possible occurrence, and 3rd order within home ranges.
I want to make a grouped bar chart, using these results:

Cover

SR

Order

SE

Water

0.3309

2nd

0.027909

Open Low

0.22865

2nd

0.024847

Treed Low

1.083006

2nd

0.01808

Sparse

1.966667

2nd

0.254225

Deciduous

0.792079

2nd

0.087706

Mixedwood

0.972441

2nd

0.060019

Conifer

2.226475

2nd

0.048635

Disturbance

0.410596

2nd

0.025288

Other

0.125

2nd

0.124985

Water

0.221983

3rd

0.02152

Open Low

0.648352

3rd

0.08363

Treed Low

1.138462

3rd

0.021742

Sparse

0.976744

3rd

0.149728

Deciduous

0.928571

3rd

0.114005

Mixedwood

1.032432

3rd

0.072452

Conifer

1.880137

3rd

0.046046

Disturbance

0.376321

3rd

0.027415

Other

0

3rd

0


Selection Ratio (SR)  is calculated using
Proportion of used points (oi)/proportion of available points (?i)
Standard error for the selection ratio (SE)
s.e = (sqrt((?i*(1-?i)/ n*(oi^2)) where n is the total number of points
These equations do not lend themselves to making the calculations in R, so I am simply trying to plot the results.  Here is my code:
################################################
data <- read.csv("data.csv")
#Specify the order that factors appear in (alphabetical is default)
data$Cover <- ordered (data$Cover, levels = c("Disturbance", "Deciduous", "Mixedwood",
"Conifer", "Sparse", "Treed Low", "Open Low", "Water", "Other"))

#define errors
sem = function(SE) (SE*1)
errors = with(data, tapply(SE, Cover, sem))
errors

#define benchmark value
benchmark <- 1.0

library(sciplot)
library(graphics)

#make default barchart to determine x-coordinates for error bars#
bargraph.CI(Cover, SR, Order, data = data, lc=FALSE, uc=FALSE) ->bpN.out
bpN.out

#make barchart so it looks right#

par(mar = c(10,8,1,1), oma = c(1,1,1,1))
bargraph.CI(Cover, SR, Order, data = data, ylim=c(0,2.5), ylab = "Selection Ratio",
                     cex.names = 1, cex.axis = 1.5, cex.lab = 1.5, las=2, err.width = 0.03, legend=F,
                                axis.lty=1, cex=1.1,lc=FALSE, uc=FALSE)

#Plot benchmark line at SR = 1.0
abline(h=benchmark, lty = "dotdash", lwd=2)

#Plot error bars
for(i in 1:length(bpN.out)){
arrows(bpN.out$xvals[i],means[i],bpN.out$xvals[i],means[i]+errors[i], angle=90, length=.1)
arrows(bpN.out$xvals[i],means[i],bpN.out$xvals[i],means[i]-errors[i], angle=90, length=.1)
}
 ###
Two questions:

1.       Though I have specified lc=FALSE and uc=FALSE when I call for the plot I get a warning for each of the 18 bars produced, I believe because it cannot calculate a confidence interval.  How can I suppress the function within bargrapg.CI that wants to make the calculation? When I call bpN.out I also get the full list of N/A values for the $CI.  Wondering if I can prevent this from happening, or if I need to.

2.       Instead of plotting error bars I get, "Error in means[i] + errors[i] : non-numeric argument to binary operator".  Is there something else I should be doing to get the SE values I have calculated to define the width of the error bars I want to plot?




Thanks for your help!


Douglas E. B. Reid PhD
Boreal Silviculture Reasearch Program Lead
Centre for Northern Forest Ecosystem Research
(807) 343-4008



	[[alternative HTML version deleted]]


From Michael.Laviolette at dhhs.state.nh.us  Wed Feb  4 16:16:55 2015
From: Michael.Laviolette at dhhs.state.nh.us (Michael.Laviolette at dhhs.state.nh.us)
Date: Wed, 4 Feb 2015 10:16:55 -0500
Subject: [R] Flat tables for confidence intervals with "survey" package
Message-ID: <OF352EC5B5.8AFE1E3C-ON85257DE2.004E7851-85257DE2.0053F28B@dhhs.state.nh.us>


I'm preparing some reports for substate regions from BRFSS survey data. I
can get estimates easily enough, but am having problems putting the results
in convenient form. Here's some code using the New Hampshire portion of the
public BRFSS "SMART" data:

library(foreign)
library(survey)
# download and extract http://www.cdc.gov/brfss/smart/2012/CNTY12XPT.zip
nh.smart <- svydesign(ids = ~0, strata = ~X_STSTR, weights = ~X_CNTYWT,
                      data = subset(read.xport("CNTY12.xpt"), X_STATE ==
33))
# using asthma status as example
nh.smart <- update(nh.smart,
  X_ASTHMS1 = factor(X_ASTHMS1, levels = 1:3,
                     labels = c("Current","Former","Never")),
  X_CNTY = factor(X_CNTY, labels = c("Belknap","Carroll","Cheshire","Coos",
                                     "Grafton","Hillsborough","Merrimack",
                                     "Rockingham","Strafford")))
a <- svyby(~X_ASTHMS1, ~X_CNTY, nh.smart, svymean, na.rm = TRUE,
           vartype = "ci")

Is there a convenient way to get a flat table similar to the following? I'm
not having much success with "ftable."

Thanks in advance,
Michael L.

#                    Percent   LCI   UCI
# Belknap   Current     10.4   5.6  15.3
#           Former       1.5   0.4   2.7
#           Never       88.1  83.1  93.0
# Carroll   Current      7.5   4.9  10.1
#           Former       2.9   1.3   4.5
#           Never       89.6  86.5  92.7
# ...


From murdoch.duncan at gmail.com  Wed Feb  4 17:18:15 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 04 Feb 2015 11:18:15 -0500
Subject: [R] Flat tables for confidence intervals with "survey" package
In-Reply-To: <OF352EC5B5.8AFE1E3C-ON85257DE2.004E7851-85257DE2.0053F28B@dhhs.state.nh.us>
References: <OF352EC5B5.8AFE1E3C-ON85257DE2.004E7851-85257DE2.0053F28B@dhhs.state.nh.us>
Message-ID: <54D24647.1080901@gmail.com>

On 04/02/2015 10:16 AM, Michael.Laviolette at dhhs.state.nh.us wrote:
> I'm preparing some reports for substate regions from BRFSS survey data. I
> can get estimates easily enough, but am having problems putting the results
> in convenient form. Here's some code using the New Hampshire portion of the
> public BRFSS "SMART" data:
>
> library(foreign)
> library(survey)
> # download and extract http://www.cdc.gov/brfss/smart/2012/CNTY12XPT.zip
> nh.smart <- svydesign(ids = ~0, strata = ~X_STSTR, weights = ~X_CNTYWT,
>                        data = subset(read.xport("CNTY12.xpt"), X_STATE ==
> 33))
> # using asthma status as example
> nh.smart <- update(nh.smart,
>    X_ASTHMS1 = factor(X_ASTHMS1, levels = 1:3,
>                       labels = c("Current","Former","Never")),
>    X_CNTY = factor(X_CNTY, labels = c("Belknap","Carroll","Cheshire","Coos",
>                                       "Grafton","Hillsborough","Merrimack",
>                                       "Rockingham","Strafford")))
> a <- svyby(~X_ASTHMS1, ~X_CNTY, nh.smart, svymean, na.rm = TRUE,
>             vartype = "ci")
>
> Is there a convenient way to get a flat table similar to the following? I'm
> not having much success with "ftable."
>
> Thanks in advance,
> Michael L.
>
> #                    Percent   LCI   UCI
> # Belknap   Current     10.4   5.6  15.3
> #           Former       1.5   0.4   2.7
> #           Never       88.1  83.1  93.0
> # Carroll   Current      7.5   4.9  10.1
> #           Former       2.9   1.3   4.5
> #           Never       89.6  86.5  92.7
> # ...
>

What do you mean by a "flat table"?  You can get a table that's suitable 
for conversion to LaTeX or HTML (or maybe some other format) from the 
tables package.  I haven't tried this, but I would think the syntax 
would be something like

tabular(Factor(X_CNTY, "County")*Factor(X_ASTHMS1, "Asthma")
                    ~ Percent(denom=Equal(X_CNTY)) +
                       Percent(denom=Equal(X_CNTY), fn=LCI) +
                       Percent(denom=Equal(X_CNTY), fn=UCI), data=nh.smart)

You'll need to write the LCI and UCI functions to compute the confidence 
limits.  I don't know how to extract those from the objects you've got; 
you may need to add an "analysis variable" to the tabular() call to get 
the required inputs.

Duncan Murdoch


From tom at maladmin.com  Wed Feb  4 20:34:42 2015
From: tom at maladmin.com (Tom Wright)
Date: Wed, 4 Feb 2015 14:34:42 -0500
Subject: [R] Still trying to avoid loops
Message-ID: <1423078482.3751.16.camel@maladmin.com>

Given a dataframe:
dat<-data.frame(S=factor(c(rep('a',2),rep('b',1),rep('c',3)),levels=c('b','a','c')),
		D=c(5,1,3,2,3,4))

where S is a subject identifier and D a visit (actually a date in my
real dataset). I would like to generate another column giving the visit
number

R=c(2,1,1,1,2,3)

My current solution uses nested loops and is slow and ugly. I've looked
at by() but can't see how to keep the order of R correct.

Thanks,
Tom


From ruipbarradas at sapo.pt  Wed Feb  4 20:49:05 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 4 Feb 2015 19:49:05 +0000
Subject: [R] Still trying to avoid loops
In-Reply-To: <1423078482.3751.16.camel@maladmin.com>
References: <1423078482.3751.16.camel@maladmin.com>
Message-ID: <54D277B1.2030609@sapo.pt>

Hello,

Aren't the levels of your example wrong? If the levels are 
levels=c('a','b','c'), not c('b', 'a', 'c'), then the following will do 
the job.

unname(unlist(tapply(dat$D, dat$S, order)))


Hope this helps,

Rui Barradas

Em 04-02-2015 19:34, Tom Wright escreveu:
> Given a dataframe:
> dat<-data.frame(S=factor(c(rep('a',2),rep('b',1),rep('c',3)),levels=c('b','a','c')),
> 		D=c(5,1,3,2,3,4))
>
> where S is a subject identifier and D a visit (actually a date in my
> real dataset). I would like to generate another column giving the visit
> number
>
> R=c(2,1,1,1,2,3)
>
> My current solution uses nested loops and is slow and ugly. I've looked
> at by() but can't see how to keep the order of R correct.
>
> Thanks,
> Tom
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tom at maladmin.com  Wed Feb  4 20:50:22 2015
From: tom at maladmin.com (Tom Wright)
Date: Wed, 04 Feb 2015 14:50:22 -0500
Subject: [R] Teaching materials for R course
In-Reply-To: <CAOyz9G6hmTukco-8Rwipga1aoKxOLCNw2fryKR71=vvQDm3GgQ@mail.gmail.com>
References: <CAOyz9G6hmTukco-8Rwipga1aoKxOLCNw2fryKR71=vvQDm3GgQ@mail.gmail.com>
Message-ID: <1423079422.3751.18.camel@maladmin.com>

For the introduction to R I strongly suggest you look at the materials
published by software-carpentry www.software-carpentry.org. The lessons
are all open-source, hosted on github and are under active development.

On Tue, 2015-02-03 at 12:08 +0100, Michael Haenlein wrote:
> Dear all,
> 
> I am Professor at a business school and I would like to develop a course
> about quantitative research using R.
> 
> My current plan is that the course should cover (a) an introduction
> (assuming that students have never used R before), (b) basic econometric
> analysis (e.g., regression, logit) as well as (c) structural equation
> modelling.
> 
> Are there any textbooks and teaching materials (e.g., PowerPoint slides)
> that one of you could recommend for me to have a look at?
> 
> Thanks,
> 
> Michael
> 
> Michael Haenlein
> Professor of Marketing
> ESCP Europe
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Wed Feb  4 21:06:00 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 4 Feb 2015 12:06:00 -0800
Subject: [R] Still trying to avoid loops
In-Reply-To: <54D277B1.2030609@sapo.pt>
References: <1423078482.3751.16.camel@maladmin.com> <54D277B1.2030609@sapo.pt>
Message-ID: <CACk-te3jUsrJz2EEfwhpH0LCXTjpkkdhFdSmJFvznLbT=C2-ug@mail.gmail.com>

tapply() (of which by() is essentially a wrapper) **is** a (disguised)
loop (at the R level, of course).

Cheers,
Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Feb 4, 2015 at 11:49 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Aren't the levels of your example wrong? If the levels are
> levels=c('a','b','c'), not c('b', 'a', 'c'), then the following will do the
> job.
>
> unname(unlist(tapply(dat$D, dat$S, order)))
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 04-02-2015 19:34, Tom Wright escreveu:
>>
>> Given a dataframe:
>>
>> dat<-data.frame(S=factor(c(rep('a',2),rep('b',1),rep('c',3)),levels=c('b','a','c')),
>>                 D=c(5,1,3,2,3,4))
>>
>> where S is a subject identifier and D a visit (actually a date in my
>> real dataset). I would like to generate another column giving the visit
>> number
>>
>> R=c(2,1,1,1,2,3)
>>
>> My current solution uses nested loops and is slow and ugly. I've looked
>> at by() but can't see how to keep the order of R correct.
>>
>> Thanks,
>> Tom
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tom at maladmin.com  Wed Feb  4 21:07:34 2015
From: tom at maladmin.com (Tom Wright)
Date: Wed, 4 Feb 2015 15:07:34 -0500
Subject: [R] Still trying to avoid loops
In-Reply-To: <54D277B1.2030609@sapo.pt>
References: <1423078482.3751.16.camel@maladmin.com> <54D277B1.2030609@sapo.pt>
Message-ID: <1423080454.3751.23.camel@maladmin.com>

Thanks, I was not aware of order().
I did deliberately mess up the order of S. The following example breaks
your solution
dat_2<-data.frame(S=factor(c('a','c','a','b','c','c')),
		  D=c(5,3,1,3,2,4))

which should give the answer c(2,2,1,1,2,3)

Your solution does indicate that sorting the data correctly before
starting might solve the problem.


On Wed, 2015-02-04 at 19:49 +0000, Rui Barradas wrote:
> Hello,
> 
> Aren't the levels of your example wrong? If the levels are 
> levels=c('a','b','c'), not c('b', 'a', 'c'), then the following will do 
> the job.
> 
> unname(unlist(tapply(dat$D, dat$S, order)))
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 04-02-2015 19:34, Tom Wright escreveu:
> > Given a dataframe:
> > dat<-data.frame(S=factor(c('a','b','a','c','c','c',levels=c('b','a','c')),
> > 		D=c(1,5,3,2,3,4))
> >
> > where S is a subject identifier and D a visit (actually a date in my
> > real dataset). I would like to generate another column giving the visit
> > number
> >
> > R=c(2,1,1,1,2,3)
> >
> > My current solution uses nested loops and is slow and ugly. I've looked
> > at by() but can't see how to keep the order of R correct.
> >
> > Thanks,
> > Tom
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From tom at maladmin.com  Wed Feb  4 21:08:27 2015
From: tom at maladmin.com (Tom Wright)
Date: Wed, 4 Feb 2015 15:08:27 -0500
Subject: [R] Still trying to avoid loops
In-Reply-To: <CACk-te3jUsrJz2EEfwhpH0LCXTjpkkdhFdSmJFvznLbT=C2-ug@mail.gmail.com>
References: <1423078482.3751.16.camel@maladmin.com> <54D277B1.2030609@sapo.pt>
	<CACk-te3jUsrJz2EEfwhpH0LCXTjpkkdhFdSmJFvznLbT=C2-ug@mail.gmail.com>
Message-ID: <1423080507.3751.24.camel@maladmin.com>

No problem with disguise, I'm looking for pretty.

On Wed, 2015-02-04 at 12:06 -0800, Bert Gunter wrote:
> tapply() (of which by() is essentially a wrapper) **is** a (disguised)
> loop (at the R level, of course).
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
> 
> 
> 
> 
> On Wed, Feb 4, 2015 at 11:49 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> > Hello,
> >
> > Aren't the levels of your example wrong? If the levels are
> > levels=c('a','b','c'), not c('b', 'a', 'c'), then the following will do the
> > job.
> >
> > unname(unlist(tapply(dat$D, dat$S, order)))
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > Em 04-02-2015 19:34, Tom Wright escreveu:
> >>
> >> Given a dataframe:
> >>
> >> dat<-data.frame(S=factor(c(rep('a',2),rep('b',1),rep('c',3)),levels=c('b','a','c')),
> >>                 D=c(5,1,3,2,3,4))
> >>
> >> where S is a subject identifier and D a visit (actually a date in my
> >> real dataset). I would like to generate another column giving the visit
> >> number
> >>
> >> R=c(2,1,1,1,2,3)
> >>
> >> My current solution uses nested loops and is slow and ugly. I've looked
> >> at by() but can't see how to keep the order of R correct.
> >>
> >> Thanks,
> >> Tom
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From js.huang at protective.com  Wed Feb  4 18:32:01 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 4 Feb 2015 09:32:01 -0800 (PST)
Subject: [R] Get 10%,
	50% and 90% Quantile of data samples with probability
In-Reply-To: <1422998461987-4702774.post@n4.nabble.com>
References: <1422913715619-4702717.post@n4.nabble.com>
	<1422998461987-4702774.post@n4.nabble.com>
Message-ID: <1423071121875-4702792.post@n4.nabble.com>

Hi,

  To complete the last part:

> dist <- function(x)
+ {
+
return(c(rep(x[1],15),rep(x[2],15),rep(x[3],25),rep(x[4],20),rep(x[5],25)))
+ }
> x <- dist(c(2,3,2,5.3,7.3))
> x
  [1] 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 3.0 3.0
3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0
 [29] 3.0 3.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0
2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 5.3
 [57] 5.3 5.3 5.3 5.3 5.3 5.3 5.3 5.3 5.3 5.3 5.3 5.3 5.3 5.3 5.3 5.3 5.3
5.3 5.3 7.3 7.3 7.3 7.3 7.3 7.3 7.3 7.3 7.3
 [85] 7.3 7.3 7.3 7.3 7.3 7.3 7.3 7.3 7.3 7.3 7.3 7.3 7.3 7.3 7.3 7.3
> quantile(x, prob=c(0.1,0.5,0.9))
10% 50% 90% 
2.0 3.0 7.3 



--
View this message in context: http://r.789695.n4.nabble.com/Get-10-50-and-90-Quantile-of-data-samples-with-probability-tp4702717p4702792.html
Sent from the R help mailing list archive at Nabble.com.


From nick.w.jeffery3 at gmail.com  Wed Feb  4 20:42:50 2015
From: nick.w.jeffery3 at gmail.com (Nick Jeffery)
Date: Wed, 4 Feb 2015 14:42:50 -0500
Subject: [R] Removing 99% similar sequence help
Message-ID: <CADUrEESuGXj2G2y4W2nRUP7nsPgJzLAvdM5Ti+1+EqEDATi0OA@mail.gmail.com>

Dear R users,

I am having trouble finding a package and function to remove DNA sequences
from a fasta file that are >99% similar and/or create an output of the
remaining "unique" sequences. I found the uniquefasta function in phytools
but R can't find this function and also doesn't allow me to set the 99%
parameter. This is because I'm building a phylogeny with tons of nearly
identical sequences so I want to reduce the number of individuals.


Thanks for any help and suggestions,
Nick

-- 
Nick Jeffery, PhD Candidate
Integrative Biology
SCIE 1453
University of Guelph
Guelph, Ontario, Canada

	[[alternative HTML version deleted]]


From gforister at gmail.com  Wed Feb  4 20:15:38 2015
From: gforister at gmail.com (Glen Forister)
Date: Wed, 4 Feb 2015 11:15:38 -0800
Subject: [R] Swirl course crashes
Message-ID: <CAND=aS32PTCD+JdNjagfkbYhahmfJDhhO1R-a+4-GfSsFuh+iw@mail.gmail.com>

Is there a way for me to use the Swirl course "Data_Visualization"?  This
is my main reason for learning R, for the plotting ability but can't use
the course.  I've already been through the following (Programming,
Programming Alt, Getting_and_Cleaning_Data).

I get the following
=========================
Would you like to continue with one of these lessons?

1: Data Analysis Data Visualization
2: R Programming Basic Building Blocks
3: No. Let me start something new.

Selection:
| Attemping to load lesson dependencies.
| Package ?openintro? loaded correctly!

| Here is a dot plot created using the variable 'price' from our 'cars'
| data set. As you may notice, the price is reported along the x-axis in
| $1000s, and each point above the axis represents the price of one of
| the 54 cars in our data set.

Error in plot.new() : figure margins too large

| Leaving swirl now. Type swirl() to resume.

=================================
Hopefully, something can be pointed out that I have forgotten.  so far all
the courses have been great.

-- 
Glen Forister
2319 Vernon St.
Roseville, CA  95678

	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Wed Feb  4 21:25:00 2015
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 4 Feb 2015 12:25:00 -0800
Subject: [R] Swirl course crashes
In-Reply-To: <CAND=aS32PTCD+JdNjagfkbYhahmfJDhhO1R-a+4-GfSsFuh+iw@mail.gmail.com>
References: <CAND=aS32PTCD+JdNjagfkbYhahmfJDhhO1R-a+4-GfSsFuh+iw@mail.gmail.com>
Message-ID: <CA+hbrhWtRVqAj-5wuzm8PuiC-dBZejNfnAA65ynZ47SCLLt1Xw@mail.gmail.com>

It's hard to say from your description what the situation is. The error
simply means the plot area is too small for the figure margins to fit. Try
closing the graphics (plot) window before you run the section that causes
the error, or you can try maximizing the plotting window.
You can also contact the course developers and ask them to fix the bug.

HTH,

Peter


On Wed, Feb 4, 2015 at 11:15 AM, Glen Forister <gforister at gmail.com> wrote:

> Is there a way for me to use the Swirl course "Data_Visualization"?  This
> is my main reason for learning R, for the plotting ability but can't use
> the course.  I've already been through the following (Programming,
> Programming Alt, Getting_and_Cleaning_Data).
>
> I get the following
> =========================
> Would you like to continue with one of these lessons?
>
> 1: Data Analysis Data Visualization
> 2: R Programming Basic Building Blocks
> 3: No. Let me start something new.
>
> Selection:
> | Attemping to load lesson dependencies.
> | Package ?openintro? loaded correctly!
>
> | Here is a dot plot created using the variable 'price' from our 'cars'
> | data set. As you may notice, the price is reported along the x-axis in
> | $1000s, and each point above the axis represents the price of one of
> | the 54 cars in our data set.
>
> Error in plot.new() : figure margins too large
>
> | Leaving swirl now. Type swirl() to resume.
>
> =================================
> Hopefully, something can be pointed out that I have forgotten.  so far all
> the courses have been great.
>
> --
> Glen Forister
> 2319 Vernon St.
> Roseville, CA  95678
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Wed Feb  4 21:37:16 2015
From: jholtman at gmail.com (jim holtman)
Date: Wed, 4 Feb 2015 15:37:16 -0500
Subject: [R] Still trying to avoid loops
In-Reply-To: <1423080507.3751.24.camel@maladmin.com>
References: <1423078482.3751.16.camel@maladmin.com> <54D277B1.2030609@sapo.pt>
	<CACk-te3jUsrJz2EEfwhpH0LCXTjpkkdhFdSmJFvznLbT=C2-ug@mail.gmail.com>
	<1423080507.3751.24.camel@maladmin.com>
Message-ID: <CAAxdm-5WY8ZUxP9S48h7bhPt5a7UDUkhE2TtrW2cK64xTQ0kSw@mail.gmail.com>

>
dat<-data.frame(S=factor(c(rep('a',2),rep('b',1),rep('c',3)),levels=c('b','a','c')),
+                 D=c(5,1,3,2,3,4))
> dat
  S D
1 a 5
2 a 1
3 b 3
4 c 2
5 c 3
6 c 4
> dat$visit <- ave(seq(nrow(dat)), dat$S, FUN = seq_along)
> dat
  S D visit
1 a 5     1
2 a 1     2
3 b 3     1
4 c 2     1
5 c 3     2
6 c 4     3



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Feb 4, 2015 at 3:08 PM, Tom Wright <tom at maladmin.com> wrote:

> No problem with disguise, I'm looking for pretty.
>
> On Wed, 2015-02-04 at 12:06 -0800, Bert Gunter wrote:
> > tapply() (of which by() is essentially a wrapper) **is** a (disguised)
> > loop (at the R level, of course).
> >
> > Cheers,
> > Bert
> >
> >
> >
> > Bert Gunter
> > Genentech Nonclinical Biostatistics
> > (650) 467-7374
> >
> > "Data is not information. Information is not knowledge. And knowledge
> > is certainly not wisdom."
> > Clifford Stoll
> >
> >
> >
> >
> > On Wed, Feb 4, 2015 at 11:49 AM, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> > > Hello,
> > >
> > > Aren't the levels of your example wrong? If the levels are
> > > levels=c('a','b','c'), not c('b', 'a', 'c'), then the following will
> do the
> > > job.
> > >
> > > unname(unlist(tapply(dat$D, dat$S, order)))
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > > Em 04-02-2015 19:34, Tom Wright escreveu:
> > >>
> > >> Given a dataframe:
> > >>
> > >>
> dat<-data.frame(S=factor(c(rep('a',2),rep('b',1),rep('c',3)),levels=c('b','a','c')),
> > >>                 D=c(5,1,3,2,3,4))
> > >>
> > >> where S is a subject identifier and D a visit (actually a date in my
> > >> real dataset). I would like to generate another column giving the
> visit
> > >> number
> > >>
> > >> R=c(2,1,1,1,2,3)
> > >>
> > >> My current solution uses nested loops and is slow and ugly. I've
> looked
> > >> at by() but can't see how to keep the order of R correct.
> > >>
> > >> Thanks,
> > >> Tom
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tom at maladmin.com  Wed Feb  4 21:41:30 2015
From: tom at maladmin.com (Tom Wright)
Date: Wed, 4 Feb 2015 15:41:30 -0500
Subject: [R] Still trying to avoid loops
In-Reply-To: <CAAxdm-5WY8ZUxP9S48h7bhPt5a7UDUkhE2TtrW2cK64xTQ0kSw@mail.gmail.com>
References: <1423078482.3751.16.camel@maladmin.com> <54D277B1.2030609@sapo.pt>
	<CACk-te3jUsrJz2EEfwhpH0LCXTjpkkdhFdSmJFvznLbT=C2-ug@mail.gmail.com>
	<1423080507.3751.24.camel@maladmin.com>
	<CAAxdm-5WY8ZUxP9S48h7bhPt5a7UDUkhE2TtrW2cK64xTQ0kSw@mail.gmail.com>
Message-ID: <1423082490.3751.26.camel@maladmin.com>

Sorry Jim,
That messes up on S=='a'. Should be 2,1 not 1,2

Neat answer though and looks like it should be pretty quick after I
apply some sorting.

On Wed, 2015-02-04 at 15:37 -0500, jim holtman wrote:
> >
> dat<-data.frame(S=factor(c(rep('a',2),rep('b',1),rep('c',3)),levels=c('b','a','c')),
> +                 D=c(5,1,3,2,3,4))
> > dat
>   S D
> 1 a 5
> 2 a 1
> 3 b 3
> 4 c 2
> 5 c 3
> 6 c 4
> > dat$visit <- ave(seq(nrow(dat)), dat$S, FUN = seq_along)
> > dat
>   S D visit
> 1 a 5     1
> 2 a 1     2
> 3 b 3     1
> 4 c 2     1
> 5 c 3     2
> 6 c 4     3
> 
> 
> 
> 
> Jim Holtman
> Data Munger Guru
>  
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
> On Wed, Feb 4, 2015 at 3:08 PM, Tom Wright <tom at maladmin.com> wrote:
>         No problem with disguise, I'm looking for pretty.
>         
>         On Wed, 2015-02-04 at 12:06 -0800, Bert Gunter wrote:
>         > tapply() (of which by() is essentially a wrapper) **is** a
>         (disguised)
>         > loop (at the R level, of course).
>         >
>         > Cheers,
>         > Bert
>         >
>         >
>         >
>         > Bert Gunter
>         > Genentech Nonclinical Biostatistics
>         > (650) 467-7374
>         >
>         > "Data is not information. Information is not knowledge. And
>         knowledge
>         > is certainly not wisdom."
>         > Clifford Stoll
>         >
>         >
>         >
>         >
>         > On Wed, Feb 4, 2015 at 11:49 AM, Rui Barradas
>         <ruipbarradas at sapo.pt> wrote:
>         > > Hello,
>         > >
>         > > Aren't the levels of your example wrong? If the levels are
>         > > levels=c('a','b','c'), not c('b', 'a', 'c'), then the
>         following will do the
>         > > job.
>         > >
>         > > unname(unlist(tapply(dat$D, dat$S, order)))
>         > >
>         > >
>         > > Hope this helps,
>         > >
>         > > Rui Barradas
>         > >
>         > > Em 04-02-2015 19:34, Tom Wright escreveu:
>         > >>
>         > >> Given a dataframe:
>         > >>
>         > >>
>         dat<-data.frame(S=factor(c(rep('a',2),rep('b',1),rep('c',3)),levels=c('b','a','c')),
>         > >>                 D=c(5,1,3,2,3,4))
>         > >>
>         > >> where S is a subject identifier and D a visit (actually a
>         date in my
>         > >> real dataset). I would like to generate another column
>         giving the visit
>         > >> number
>         > >>
>         > >> R=c(2,1,1,1,2,3)
>         > >>
>         > >> My current solution uses nested loops and is slow and
>         ugly. I've looked
>         > >> at by() but can't see how to keep the order of R correct.
>         > >>
>         > >> Thanks,
>         > >> Tom
>         > >>
>         > >> ______________________________________________
>         > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>         more, see
>         > >> https://stat.ethz.ch/mailman/listinfo/r-help
>         > >> PLEASE do read the posting guide
>         > >> http://www.R-project.org/posting-guide.html
>         > >> and provide commented, minimal, self-contained,
>         reproducible code.
>         > >>
>         > >
>         > > ______________________________________________
>         > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>         more, see
>         > > https://stat.ethz.ch/mailman/listinfo/r-help
>         > > PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         > > and provide commented, minimal, self-contained,
>         reproducible code.
>         
>         ______________________________________________
>         R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>         see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         and provide commented, minimal, self-contained, reproducible
>         code.
>         
> 
>


From wdunlap at tibco.com  Wed Feb  4 21:49:16 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 4 Feb 2015 12:49:16 -0800
Subject: [R] Still trying to avoid loops
In-Reply-To: <1423080454.3751.23.camel@maladmin.com>
References: <1423078482.3751.16.camel@maladmin.com> <54D277B1.2030609@sapo.pt>
	<1423080454.3751.23.camel@maladmin.com>
Message-ID: <CAF8bMcbAUWxuRQcNZmCuaZW-51g=WFdXCL5YeHrRT2exVyO7ZA@mail.gmail.com>

A useful technique when it is easy to compute a vector from an ordered
data.frame but you need to do it for an unordered one is to compute the
order
vector 'ord', compute the vector from df[ord,], and use df[ord,...] <-
vector
to reorder the vector.  In your case you could do:
  > dat_2<-data.frame(S=factor(c('a','c','a','b','c','c')),
  +                   D=c(5,3,1,3,2,4))
  > ord <- with(dat_2, order(S, D)) # order by subject, break ties by date
  > dat_2$visitNo <- integer(nrow(dat_2)) # will fill this in next
  > dat_2$visitNo[ord] <- with(dat_2[ord,], ave(visitNo, S, FUN=seq_along))
  > dat_2
    S D visitNo
  1 a 5       2
  2 c 3       2
  3 a 1       1
  4 b 3       1
  5 c 2       1
  6 c 4       3

Now this is different from your answer, c(2,2,1,1,2,3).  Which is correct?

You can also do the reordering of the result from the ordered dataset by
subscripting the right hand side with [order(ord)], but I find using [ord]
on left side easier to remember.
  with(dat_2[ord,], ave(visitNo, S, FUN=seq_along))[order(ord)]
  [1] 2 2 1 1 1 3



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Feb 4, 2015 at 12:07 PM, Tom Wright <tom at maladmin.com> wrote:

> Thanks, I was not aware of order().
> I did deliberately mess up the order of S. The following example breaks
> your solution
> dat_2<-data.frame(S=factor(c('a','c','a','b','c','c')),
>                   D=c(5,3,1,3,2,4))
>
> which should give the answer c(2,2,1,1,2,3)
>
> Your solution does indicate that sorting the data correctly before
> starting might solve the problem.
>
>
> On Wed, 2015-02-04 at 19:49 +0000, Rui Barradas wrote:
> > Hello,
> >
> > Aren't the levels of your example wrong? If the levels are
> > levels=c('a','b','c'), not c('b', 'a', 'c'), then the following will do
> > the job.
> >
> > unname(unlist(tapply(dat$D, dat$S, order)))
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > Em 04-02-2015 19:34, Tom Wright escreveu:
> > > Given a dataframe:
> > >
> dat<-data.frame(S=factor(c('a','b','a','c','c','c',levels=c('b','a','c')),
> > >             D=c(1,5,3,2,3,4))
> > >
> > > where S is a subject identifier and D a visit (actually a date in my
> > > real dataset). I would like to generate another column giving the visit
> > > number
> > >
> > > R=c(2,1,1,1,2,3)
> > >
> > > My current solution uses nested loops and is slow and ugly. I've looked
> > > at by() but can't see how to keep the order of R correct.
> > >
> > > Thanks,
> > > Tom
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Feb  4 21:52:07 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 4 Feb 2015 15:52:07 -0500
Subject: [R] Teaching materials for R course
In-Reply-To: <CAOyz9G6hmTukco-8Rwipga1aoKxOLCNw2fryKR71=vvQDm3GgQ@mail.gmail.com>
References: <CAOyz9G6hmTukco-8Rwipga1aoKxOLCNw2fryKR71=vvQDm3GgQ@mail.gmail.com>
Message-ID: <CA+vqiLERKYTheXfpUYEfsRuHSsbNwgaTMpQgydR9bLtnuu+R8w@mail.gmail.com>

I have some materials at http://tutorials.iq.harvard.edu , you're welcome
to use or adapt.
On Feb 3, 2015 6:12 AM, "Michael Haenlein" <haenlein at escpeurope.eu> wrote:

> Dear all,
>
> I am Professor at a business school and I would like to develop a course
> about quantitative research using R.
>
> My current plan is that the course should cover (a) an introduction
> (assuming that students have never used R before), (b) basic econometric
> analysis (e.g., regression, logit) as well as (c) structural equation
> modelling.
>
> Are there any textbooks and teaching materials (e.g., PowerPoint slides)
> that one of you could recommend for me to have a look at?
>
> Thanks,
>
> Michael
>
> Michael Haenlein
> Professor of Marketing
> ESCP Europe
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Feb  4 21:53:57 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 4 Feb 2015 20:53:57 +0000
Subject: [R] Still trying to avoid loops
In-Reply-To: <1423080454.3751.23.camel@maladmin.com>
References: <1423078482.3751.16.camel@maladmin.com>
	<54D277B1.2030609@sapo.pt> <1423080454.3751.23.camel@maladmin.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FCBDA3@mb02.ads.tamu.edu>

How about?

> ave(dat$D, dat$S, FUN=order)
[1] 2 1 1 1 2 3
> ave(dat_2$D, dat_2$S, FUN=order)
[1] 2 2 1 1 1 3

Note, your answer for the second example is incorrect since row 2 (c, 3) and row 5 (c, 2) are both assigned 2.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Tom Wright
Sent: Wednesday, February 4, 2015 2:08 PM
To: Rui Barradas
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Still trying to avoid loops

Thanks, I was not aware of order().
I did deliberately mess up the order of S. The following example breaks
your solution
dat_2<-data.frame(S=factor(c('a','c','a','b','c','c')),
		  D=c(5,3,1,3,2,4))

which should give the answer c(2,2,1,1,2,3)

Your solution does indicate that sorting the data correctly before
starting might solve the problem.


On Wed, 2015-02-04 at 19:49 +0000, Rui Barradas wrote:
> Hello,
> 
> Aren't the levels of your example wrong? If the levels are 
> levels=c('a','b','c'), not c('b', 'a', 'c'), then the following will do
> the job.
> 
> unname(unlist(tapply(dat$D, dat$S, order)))
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 04-02-2015 19:34, Tom Wright escreveu:
> > Given a dataframe:
> > dat<-data.frame(S=factor(c('a','b','a','c','c','c',levels=c('b','a','c')),
> > 		D=c(1,5,3,2,3,4))
> >
> > where S is a subject identifier and D a visit (actually a date in my
> > real dataset). I would like to generate another column giving the visit
> > number
> >
> > R=c(2,1,1,1,2,3)
> >
> > My current solution uses nested loops and is slow and ugly. I've looked
> > at by() but can't see how to keep the order of R correct.
> >
> > Thanks,
> > Tom
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Feb  4 22:04:43 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 4 Feb 2015 13:04:43 -0800
Subject: [R] Still trying to avoid loops
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726FCBDA3@mb02.ads.tamu.edu>
References: <1423078482.3751.16.camel@maladmin.com> <54D277B1.2030609@sapo.pt>
	<1423080454.3751.23.camel@maladmin.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FCBDA3@mb02.ads.tamu.edu>
Message-ID: <CAF8bMca6qxW69M9cUfJcLwyAbFn0ohUsm8XCEPjsjavL7PUikg@mail.gmail.com>

A potential problem with
   ave(dat_2$D, dat_2$S, FUN=order)
is that it will silently give the wrong answer
or give an error if dat_2$D is not numeric.

E.g., if D is a Date vector we get
  > dat_3 <- dat_2[,1:2]
  > dat_3$D <- as.Date(paste0("2015-02-", dat_2$D))
  > with(dat_3, ave(D, S, FUN=order))
  Error in as.Date.numeric(value) : 'origin' must be supplied

Another problem is that it may take a lot more time than
is required if you have a lot of small groups in your data.

Both of those are avoided if you sort the entire dataset first
and 'unsort' the results when putting them into dataset.




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Feb 4, 2015 at 12:53 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> How about?
>
> > ave(dat$D, dat$S, FUN=order)
> [1] 2 1 1 1 2 3
> > ave(dat_2$D, dat_2$S, FUN=order)
> [1] 2 2 1 1 1 3
>
> Note, your answer for the second example is incorrect since row 2 (c, 3)
> and row 5 (c, 2) are both assigned 2.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Tom Wright
> Sent: Wednesday, February 4, 2015 2:08 PM
> To: Rui Barradas
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Still trying to avoid loops
>
> Thanks, I was not aware of order().
> I did deliberately mess up the order of S. The following example breaks
> your solution
> dat_2<-data.frame(S=factor(c('a','c','a','b','c','c')),
>                   D=c(5,3,1,3,2,4))
>
> which should give the answer c(2,2,1,1,2,3)
>
> Your solution does indicate that sorting the data correctly before
> starting might solve the problem.
>
>
> On Wed, 2015-02-04 at 19:49 +0000, Rui Barradas wrote:
> > Hello,
> >
> > Aren't the levels of your example wrong? If the levels are
> > levels=c('a','b','c'), not c('b', 'a', 'c'), then the following will do
> > the job.
> >
> > unname(unlist(tapply(dat$D, dat$S, order)))
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > Em 04-02-2015 19:34, Tom Wright escreveu:
> > > Given a dataframe:
> > >
> dat<-data.frame(S=factor(c('a','b','a','c','c','c',levels=c('b','a','c')),
> > >             D=c(1,5,3,2,3,4))
> > >
> > > where S is a subject identifier and D a visit (actually a date in my
> > > real dataset). I would like to generate another column giving the visit
> > > number
> > >
> > > R=c(2,1,1,1,2,3)
> > >
> > > My current solution uses nested loops and is slow and ugly. I've looked
> > > at by() but can't see how to keep the order of R correct.
> > >
> > > Thanks,
> > > Tom
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Wed Feb  4 22:33:30 2015
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 4 Feb 2015 14:33:30 -0700
Subject: [R] the less-than-minus gotcha
In-Reply-To: <CCE952776B6679469977532BD863C39C9A66DF62@Lewis.autuni.aut.ac.nz>
References: <alpine.DEB.2.00.1502011516550.2662@taxa.psych.umn.edu>
	<loom.20150202T020546-447@post.gmane.org>
	<CCE952776B6679469977532BD863C39C9A66D85F@Lewis.autuni.aut.ac.nz>
	<21711.37801.439519.676495@stat.math.ethz.ch>
	<CCE952776B6679469977532BD863C39C9A66DF62@Lewis.autuni.aut.ac.nz>
Message-ID: <CAFEqCdx7mQs6mh0U2Xv0Qn9PkMmsGAC9RWRHs13=EN7yk5kKhg@mail.gmail.com>

Steve (and any others still paying attention to this thread),

Larry Wall (author of Perl) said something along the lines of:

things that are similar should look similar, things that are different
should look different.

Ironically one of the first places I saw that quote was in a Perl vs.
Python language war and the same quote was being used by both sides.  This
made me think that you can learn a lot about how programmers think by what
they make look similar and what they make look different (and therefore
what they think are similar and different).

In R, I see the assignments:

foo( x <- something )

as assign to the variable x in the current (or calling) environment and

foo( x = something )

as assign to the variable x in the environment created by the function call.

With this distinction only "<-" makes any sense at the top level, but then
I see assigning to the 2 different environments as 2 different things that
should look different.  Using "=" for assignment makes sense if (and only
if) you consider assigning into different environments to be the same (or
at least very similar) thing.


Also you mentioned that

foo( x <- something )

should always be written as:

x <- something
foo(x)

and for many cases I agree, but consider the counter example of:

system.time( out <- longRunningSimulationFunction(n=1e6) )

compared to:

out = longRunningSimulationFunction(n=1e6)
system.time(out)

I would argue that the 1st version is much more useful than the 2nd.


On Mon, Feb 2, 2015 at 6:57 PM, Steve Taylor <steve.taylor at aut.ac.nz> wrote:

> Responding to several messages in this thread...
>
> > > All the more reason to use = instead of <-
> > Definitely not!
>
> Martin and Rolf are right, it's not a reason for that; I wrote that
> quickly without thinking it through.  An "=" user might be more likely to
> fall for the gotcha, if not spacing their code nicely.  So the lesson
> learned from the gotcha is that it's good to space your code nicely, as
> others have siad, not which assignment symbol to use.
>
> However, I continue to use "=" for assignment on a daily basis without any
> problems, as I have done for many years.  I remain unconvinced by any and
> all of these arguments against it in favour of "<-".  People telling me
> that I "should" use the arrow need better agruments than what I've seen so
> far.
>
> I find "<-" ugly and "->" useless/pointless, whereas "=" is simpler and
> also nicely familiar from my experience in other languages.  It doesn't
> matter to me that "=" is not commutative because I don't need it to be.
>
> > Further it can be nicely marked up by a real "left arrow"
> > by e.g. the listings LaTeX 'listings' package...
>
> Now that's just silly, turning R code into graphical characters that are
> not part of the R language.
>
> >  foo(x = y) and foo(x <- y)
>
> I'm well aware of this distinction and it never causes me any problems.
> The latter is an example of bad (obfuscated) coding, IMHO; it should be
> done in two lines for clarity as follows:
>
> x = y
> foo(x)
>
> > Using = has it's problems too.
> Same goes for apostrophes.
>
> Shall we discuss putting "else" at the start of line next?
>
> cheers,
>      Steve
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com

	[[alternative HTML version deleted]]


From Shanley.Chong at sswahs.nsw.gov.au  Wed Feb  4 22:56:57 2015
From: Shanley.Chong at sswahs.nsw.gov.au (Shanley Chong)
Date: Wed, 4 Feb 2015 21:56:57 +0000
Subject: [R] R2BayesX
In-Reply-To: <alpine.DEB.2.11.1502041018160.2229@paninaro.uibk.ac.at>
References: <90AD9DB98926A747B1C82FC2EE31E8A45BE55769@LIVSVEXMBX01.intra.swsahs.nsw.gov.au>
	<alpine.DEB.2.11.1502041018160.2229@paninaro.uibk.ac.at>
Message-ID: <90AD9DB98926A747B1C82FC2EE31E8A45BE558D0@LIVSVEXMBX01.intra.swsahs.nsw.gov.au>

Dear Z and Nikolaus,

Thank you for your help.
Here is my R codes:

>data("MunichBnd")

>N <- length(MunichBnd); n <- N*5
>dat <- data.frame(x1 = runif(n, -3, 3),id = as.factor(rep(names(MunichBnd), length.out = n)))
>dat$sp <- with(dat, sort(runif(N, -2, 2), decreasing = TRUE)[id])
>dat$re_poi <- with(dat, rpois(N, 10)[id])
>dat$y_poi <- with(dat, 1.5 + sin(x1) + sp + re_poi + rpois(n, 10))
>b_poi <- bayesx(y_poi ~ sx(x1) +  sx(id, bs = "mrf", map = MunichBnd) + sx(id, bs = "re"), method = "MCMC", data = dat, family='poisson')

Warning message:
running command '"C:/Users/ChongS/Documents/R/win-library/3.1/BayesXsrc/libs/x64/BayesX.exe" C:/Users/ChongS/AppData/Local/Temp/RtmpqMhw3Z/bayesx/bayesx.estim.input.prg' had status 3

If I run the model using family='gaussian', it doesn't have problem.
b_poi <- bayesx(y_poi ~ sx(x1) +   sx(id, bs = "mrf", map = MunichBnd) +  sx(id, bs = "re"), method = "MCMC", data = dat, family='gaussian')

Kind regards,
Shanley


-----Original Message-----
From: Achim Zeileis [mailto:Achim.Zeileis at uibk.ac.at] 
Sent: Wednesday, 4 February 2015 8:20 PM
To: Shanley Chong
Cc: r-help at r-project.org; Nikolaus.Umlauf at uibk.ac.at
Subject: Re: [R] R2BayesX

Shanley:

> I am trying to run STAR logistic/binomial model using R2BayesX . A 
> warning message came up every time when i included a random effect, 
> bs='re', (unstructured spatial effect) into the model. The warning 
> message is : Warning message: running command 
> '"C:/Users/ChongS/Documents/R/win-library/3.1/BayesXsrc/libs/x64/BayesX.exe"
> C:/Users/ChongS/AppData/Local/Temp/RtmpCW8QY9/bayesx33/bayesx.estim.input.prg' 
> had status 5

I haven't seen this problem before. Maybe you can provide "commented, minimal, self-contained, reproducible code" (as the posting guide asks)?

I'm also cc'ing the package maintainer (Nikolaus Umlauf) as he might be able to give more insight.

Best,
Z

> The model is fine when i just ran the model using mrf, bs='mrf', (structured spatial effect).
>
> And when i tried to run STAR using family=Gaussian (response is normally distributed) with structured and unstructured spatial effect, it is fine too.
>
> Can anyone please help?
>
> Regards,
>
> Shanley
>
>
> _____________________________________________________________________
> This email has been scanned for the Sydney & South Western Sydney Local Health Districts by the MessageLabs Email Security System.
> Sydney & South Western Sydney Local Health Districts regularly monitor email and attachments to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

_____________________________________________________________________
This email has been scanned for the Sydney & South Western Sydney Local Health Districts by the MessageLabs Email Security System.
Sydney & South Western Sydney Local Health Districts regularly monitor email and attachments to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.

_____________________________________________________________________ 
This email has been scanned for the Sydney & South Western Sydney Local Health Districts by the MessageLabs Email Security System.
Sydney & South Western Sydney Local Health Districts regularly monitor email and attachments to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.


From tom at maladmin.com  Wed Feb  4 23:24:10 2015
From: tom at maladmin.com (Tom Wright)
Date: Wed, 4 Feb 2015 17:24:10 -0500
Subject: [R] Still trying to avoid loops
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726FCBDA3@mb02.ads.tamu.edu>
References: <1423078482.3751.16.camel@maladmin.com>
	<54D277B1.2030609@sapo.pt> <1423080454.3751.23.camel@maladmin.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FCBDA3@mb02.ads.tamu.edu>
Message-ID: <1423088650.3751.28.camel@maladmin.com>

Of course you are correct the second answer should be
 c(2,2,1,1,1,3)

Thanks everyone.

On Wed, 2015-02-04 at 20:53 +0000, David L Carlson wrote:
> How about?
> 
> > ave(dat$D, dat$S, FUN=order)
> [1] 2 1 1 1 2 3
> > ave(dat_2$D, dat_2$S, FUN=order)
> [1] 2 2 1 1 1 3
> 
> Note, your answer for the second example is incorrect since row 2 (c, 3) and row 5 (c, 2) are both assigned 2.
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Tom Wright
> Sent: Wednesday, February 4, 2015 2:08 PM
> To: Rui Barradas
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Still trying to avoid loops
> 
> Thanks, I was not aware of order().
> I did deliberately mess up the order of S. The following example breaks
> your solution
> dat_2<-data.frame(S=factor(c('a','c','a','b','c','c')),
> 		  D=c(5,3,1,3,2,4))
> 
> which should give the answer c(2,2,1,1,2,3)
> 
> Your solution does indicate that sorting the data correctly before
> starting might solve the problem.
> 
> 
> On Wed, 2015-02-04 at 19:49 +0000, Rui Barradas wrote:
> > Hello,
> > 
> > Aren't the levels of your example wrong? If the levels are 
> > levels=c('a','b','c'), not c('b', 'a', 'c'), then the following will do 
> > the job.
> > 
> > unname(unlist(tapply(dat$D, dat$S, order)))
> > 
> > 
> > Hope this helps,
> > 
> > Rui Barradas
> > 
> > Em 04-02-2015 19:34, Tom Wright escreveu:
> > > Given a dataframe:
> > > dat<-data.frame(S=factor(c('a','b','a','c','c','c',levels=c('b','a','c')),
> > > 		D=c(1,5,3,2,3,4))
> > >
> > > where S is a subject identifier and D a visit (actually a date in my
> > > real dataset). I would like to generate another column giving the visit
> > > number
> > >
> > > R=c(2,1,1,1,2,3)
> > >
> > > My current solution uses nested loops and is slow and ugly. I've looked
> > > at by() but can't see how to keep the order of R correct.
> > >
> > > Thanks,
> > > Tom
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From amc5981 at gmail.com  Wed Feb  4 23:24:36 2015
From: amc5981 at gmail.com (Alexandra Catena)
Date: Wed, 4 Feb 2015 14:24:36 -0800
Subject: [R] How to download and unzip data in a loop
Message-ID: <CAHpsUFbhAs4LvAADF=dKSgTmyavoHOet6w5AcQD0WQi9TZCxUA@mail.gmail.com>

Hi All,

I need to loop through and download the past 10 years of met data to a
temporary directory.  I then need to unzip it and place it into another
directory.


year = (2005:2015)

for (i in year)
  tmpdir = tempdir()
  file[i] = file.path(tmpdir, sprintf('724927-23285-%4i.gz', i))
  url = sprintf('
ftp://ftp.ncdc.noaa.gov/pub/data/noaa/%4i/724927-23285-%4i.gz', i, i)
  #file = basename(url)
  download.file(url, file[i])
  files = dir(tmpdir, '*.gz', full.names=FALSE)
  read.table(gzfile('files'))



'file' returns 2015 indices with "/tmp/RtmpKvB4Wz/724927-23285-2015.gz"
next to 2015. and files returns 724927-23285-2015.gz.  However, when I try
to unzip the gz file using the last line, it says it cannot open the
connection and the probable reason is that there is no such file or
directory.



Thanks,
Alexandra

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Feb  4 23:35:37 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 4 Feb 2015 14:35:37 -0800
Subject: [R] Removing 99% similar sequence help
In-Reply-To: <CADUrEESuGXj2G2y4W2nRUP7nsPgJzLAvdM5Ti+1+EqEDATi0OA@mail.gmail.com>
References: <CADUrEESuGXj2G2y4W2nRUP7nsPgJzLAvdM5Ti+1+EqEDATi0OA@mail.gmail.com>
Message-ID: <489D314B-62A7-4063-9233-4A805AD47473@comcast.net>


On Feb 4, 2015, at 11:42 AM, Nick Jeffery wrote:

> Dear R users,
> 
> I am having trouble finding a package and function to remove DNA sequences
> from a fasta file that are >99% similar and/or create an output of the
> remaining "unique" sequences. I found the uniquefasta function in phytools
> but R can't find this function and also doesn't allow me to set the 99%
> parameter. This is because I'm building a phylogeny with tons of nearly
> identical sequences so I want to reduce the number of individuals.
> 

R can't find this function ????

I'm guessing this could be a case of FAQ 7.30:
http://127.0.0.1:11553/doc/manual/R-FAQ.html#I-installed-a-package-but-the-functions-are-not-there


> 
> Thanks for any help and suggestions,
> Nick
> 
> -- 
> Nick Jeffery, PhD Candidate
> Integrative Biology
> SCIE 1453
> University of Guelph
> Guelph, Ontario, Canada
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jeroen.ooms at stat.ucla.edu  Thu Feb  5 03:21:41 2015
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Wed, 4 Feb 2015 18:21:41 -0800
Subject: [R] Failure to execute R CMD SHLIB successfully
In-Reply-To: <27C7FF62-F8E0-44C8-8B1A-41A4BDE5748B@plessthan.com>
References: <27C7FF62-F8E0-44C8-8B1A-41A4BDE5748B@plessthan.com>
Message-ID: <CABFfbXsj7v9GSzmOVDW5eFzQBAcg1Zxi1AXE1AQ+q3f=XnEP9A@mail.gmail.com>

On Sat, Jan 31, 2015 at 1:36 PM, Fisher Dennis <fisher at plessthan.com> wrote:

> followed by a series of errors:
> > gcc -m32 -shared -s -static-libgcc -o ../compiled/Windows32.so tmp.def
> ConvertSAS.o CKHashTable.o readstat_convert.o readstat_bits.o readstat_io.o
> readstat_sas.o -Ld:/RCompile/CRANpkg/extralibs64/local/lib/i386
> -Ld:/RCompile/CRANpkg/extralibs64/local/lib
> -LC:/PROGRA~1/R/R-31~1.2/bin/i386 -lR
> > readstat_convert.o:readstat_convert.c:(.text+0x42): undefined reference
> to `_imp__libiconv'
> > readstat_sas.o:readstat_sas.c:(.text+0x10b5): undefined reference to
> `_imp__libiconv_close'
> > readstat_sas.o:readstat_sas.c:(.text+0x1126): undefined reference to
> `_imp__libiconv_open'
> > readstat_sas.o:readstat_sas.c:(.text+0x1808): undefined reference to
> `dprintf'
> > readstat_sas.o:readstat_sas.c:(.text+0x1da1): undefined reference to
> `_imp__libiconv_open'
> > readstat_sas.o:readstat_sas.c:(.text+0x1de4): undefined reference to
> `_imp__libiconv_close'
> > collect2: ld returned 1 exit status
>


The windows build of R includes a special version of iconv (Riconv.dll in
the same dir as R.exe). Therefore if you include iconv.h somewhere, you
also need to link to Riconv.dll in your Makevars.win:

PKG_LIBS= -lRiconv

	[[alternative HTML version deleted]]


From cmora at Dal.Ca  Thu Feb  5 06:59:57 2015
From: cmora at Dal.Ca (Camilo Mora)
Date: Thu, 5 Feb 2015 05:59:57 +0000
Subject: [R] Fastest way to calculate quantile in large data.table
Message-ID: <1423115997730.77925@Dal.Ca>

Hi everyone,

I have a data.table with 200 columns and few million rows and am trying to calculate the .1 and .9 quantiles for each row across all 200 columns.

I have found different ways to do this, all with different performances. The examples I used are below. I wonder whether there is a faster way to do this?

Thanks and best,

Camilo


library(data.table)
v <- data.table(x=runif(10000),x2 = runif(10000),  x3=runif(10000),x4=runif(10000))
v[,Names:=rownames(v)]

#test 1 using .SD but not .SDcols
Sys.time()->StartTEST1
v[,  as.list(quantile(.SD,c(.1,.90),na.rm=TRUE)), by=Names]
Sys.time()->EndTEST1

#test 2 using .SD and .SDcols
Sys.time()->StartTEST2
v[,  as.list(quantile(.SD,c(.1,.90),na.rm=TRUE)), by=Names,.SDcols=1:4]
Sys.time()->EndTEST2

#test 3 using colnames directly. This is the fastest I found
Sys.time()->StartTEST3
v[,  as.list(quantile(c(x ,       x2,        x3,        x4 ),c(.1,.90),na.rm=TRUE)), by=Names]
Sys.time()->EndTEST3

# melting the database and doing quantile by summary. This is the second fastest, which is ironic given that the database has to be melted first
library(reshape2)
Sys.time()->StartTEST4
vs<-melt(v)
vs[,  as.list(quantile(value,c(.1,.90),na.rm=TRUE)), by=Names]
Sys.time()->EndTEST4


EndTEST1-StartTEST1
EndTEST2-StartTEST2
EndTEST3-StartTEST3
EndTEST4-StartTEST4

	[[alternative HTML version deleted]]


From kathryn.lord2000 at gmail.com  Thu Feb  5 08:42:48 2015
From: kathryn.lord2000 at gmail.com (Kathryn Lord)
Date: Thu, 5 Feb 2015 16:42:48 +0900
Subject: [R] how to draw a legend outside of the plot
Message-ID: <CAMFx86yLKLkSvf1d_GO0-C5HHqsFsrypuWCuhK9W=fdVg8OLGA@mail.gmail.com>

Dear R users,

I have three plots, so I tried, for exmple,

par(mfrow=c(2,2))

y1 <- rnorm(100)
y2 <- rnorm(100)
y3<- rnorm(100)

plot(y1);plot(y2);plot(y3)

Here, I'd like to put a legend on the bottom right hand side (empty space).

is it possible?

Thanks for helping,

Kathryn Lord

	[[alternative HTML version deleted]]


From maechler at lynne.stat.math.ethz.ch  Thu Feb  5 09:05:43 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Thu, 5 Feb 2015 09:05:43 +0100
Subject: [R] FFT Normalization Documentation
In-Reply-To: <alpine.BSF.2.00.1502031940000.55863@pedal.dcn.davis.ca.us>
References: <1985531401.416848.1422883625463.JavaMail.open-xchange@omgreatgod.store>
	<E17505B1-8B48-495B-8532-CE914D86AC33@xs4all.nl>
	<1357405753.621214.1422971291950.JavaMail.open-xchange@omgreatgod.store>
	<alpine.BSF.2.00.1502030818480.76797@pedal.dcn.davis.ca.us>
	<9750012F-B6C9-4E69-92DB-CC5BDD49B979@xs4all.nl>
	<alpine.BSF.2.00.1502031940000.55863@pedal.dcn.davis.ca.us>
Message-ID: <21715.9303.692845.854481@stat.math.ethz.ch>

Dear Jeff, Franklin, Eike and other interested parties,

I agree that the help page for fft() deserves a bit more detail;
its source is
  https://svn.r-project.org/R/trunk/src/library/stats/man/fft.Rd

For instance, it has the comment
  %%
  %% Here, we should really have a nice  \deqn{}{} giving the definition
  %% of the DFT !
  %%

and indeed, the example is minimal, depicting in which sense the
fft(*, inverse=TRUE) is the inverse of fft().

Both a definition of the DFT (in LaTeX or directly as \deqn{}{}) which
matches *our* fft(), and an extended commented example (ca 20 lines,
rather than ca 100 lines!) would be welcome additions.
If you are willing to donate a bit of time to the R project,
we (the R users world!) will be happy for extended versions of
the file fft.Rd  either in public, here, or as 'wishlist' bug
report with an attachment if you want -- or by e-mail to me.
You may also chose to discuss an "optimal example" by e-mail
between you, as you've already started to do so, implicitly.

Martin Maechler, ETH Zurich


>>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>>>>     on Tue, 3 Feb 2015 19:43:25 -0800 writes:

    > I see now the trick... the square wave clarified it for
    > me. It is indeed faster than re-arranging the data if
    > putting the zero frequency in the middle of the data is
    > your goal.

    > Since I only do that for the purposes of teaching I
    > probably won't be using it, but it may well be an
    > interesting "trick" to put in the examples.

    > On Tue, 3 Feb 2015, Franklin Bretschneider wrote:

    >> Dear Elke; Jeff,
    >> 
    >> 
    >> Re:
    >> 
    >>> Eike: Understanding Discrete Fourier Transform theory is
    >>> not trivial... while a vignette added to the stat
    >>> package has the potential help a lot of users, it is a
    >>> bit ambitious to try to supplant the extensive published
    >>> material on using and interpreting the DFT (particularly
    >>> as there is "more than one way to do it" and the R fft()
    >>> function is very typical of fft
    >>> implementations). (Similar arguments could be applied to
    >>> most of the stat package... note the absence of
    >>> vignettes there.) It might be more practical to propose
    >>> to R-devel some patches to the fft() help file
    >>> references and examples sections. Alternatively, you
    >>> could write YAB (Yet Another Blog) for people to search
    >>> for.
    >>> 
    >>> Frank: While folding is an important concept to know
    >>> about when interpreting DFT results, I think something
    >>> went rather wrong in your example with your "mask"
    >>> variable since folding applies to f (for forward fft) or
    >>> t (for inverse fft), not to the corresponding
    >>> magnitudes. In addition to that, it is simply not
    >>> necessary to pre-fold your data before applying the
    >>> fft... the folding is assumed by the math to exist in
    >>> the input outside the input window, and there is nothing
    >>> you can do to the data to affect that
    >>> assumption. Folding in the output is more visibly
    >>> evident, but presenting it as a symmetric plot is
    >>> entirely optional and is not done in most cases.
    >> 
    >> 
    >> 
    >> Maybe I didn't use the proper terminology, but what I
    >> called 'folding' is a modification of the input signal
    >> used only to present the amplitude spectrum in a
    >> convenient way. The FFT ("butterfly algorithm") yields a
    >> complex array where the highest frequencies (pos and neg)
    >> are in the middle, the lowest (and DC and fNyq) are at
    >> the ends. To display this same array with the DC value in
    >> the middle, the neg frequencies increasing to the left
    >> and the pos frequencies to the right, the trick with the
    >> +1/-1 mask is performed. This mask function is in fact a
    >> "square wave" at the Nyquist frequency.  In Matlab, it is
    >> in a routine called "fftshift", see here:
    >> 
    >>> 
    >>> Y = fftshift(X) rearranges the outputs of fft, fft2, and
    >>> fftn by moving the zero-frequency component to the
    >>> center of the array. It is useful for visualizing a
    >>> Fourier transform with the zero-frequency component in
    >>> the middle of the spectrum.
    >>> 
    >> 
    >> This is from the MathWorks web site:
    >> http://nl.mathworks.com/help/matlab/ref/fftshift.html.
    >> 
    >> In addition, in my example I forgot to scale the
    >> amplitude. This must indeed be divided by n (the number
    >> of data points).  So, change my line YY <- fft(yy) into
    >> YY <- fft(yy)/n. Now the amplitudes of the spectral line
    >> are numerically the same as given in the composition of
    >> y.  These values must indeed be regarded with caution,
    >> since with real-world signals the energy will most often
    >> be spread among several spectral "lines".  Windowing
    >> (Hann, Hanning, Blackman etc.) then improves the
    >> spectrum, but that's a different story.
    >> 
    >> Best wishes,
    >> 
    >> 
    >> Frank
    >> ---
    >> 
    >> 
    >> 
    >> 
    >> Franklin Bretschneider Dept of Biology Utrecht University
    >> bretschr at xs4all.nl
    >> 
    >> 
    >> 

    > ---------------------------------------------------------------------------
    > Jeff Newmiller The .....  .....  Go Live...
    > DCN:<jdnewmil at dcn.davis.ca.us> Basics: ##.#.  ##.#.  Live
    > Go...  Live: OO#.. Dead: OO#..  Playing Research Engineer
    > (Solar/Batteries O.O#.  #.O#.  with /Software/Embedded
    > Controllers) .OO#.  .OO#.  rocks...1k

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Feb  5 09:37:32 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 5 Feb 2015 19:37:32 +1100
Subject: [R] how to draw a legend outside of the plot
In-Reply-To: <CAMFx86yLKLkSvf1d_GO0-C5HHqsFsrypuWCuhK9W=fdVg8OLGA@mail.gmail.com>
References: <CAMFx86yLKLkSvf1d_GO0-C5HHqsFsrypuWCuhK9W=fdVg8OLGA@mail.gmail.com>
Message-ID: <CA+8X3fVrZw_sPENvVvy15EVxATbdKg0cKe_8VNKLEAvwNOqTyQ@mail.gmail.com>

Hi Kathryn,
Try this at the end of your example:

plot(y3,type="n",axes=FALSE,xlab="",ylab="")
legend(35,1,c("y1","y2","y3"),pch=1:3)

Jim

On Thu, Feb 5, 2015 at 6:42 PM, Kathryn Lord <kathryn.lord2000 at gmail.com> wrote:
> Dear R users,
>
> I have three plots, so I tried, for exmple,
>
> par(mfrow=c(2,2))
>
> y1 <- rnorm(100)
> y2 <- rnorm(100)
> y3<- rnorm(100)
>
> plot(y1);plot(y2);plot(y3)
>
> Here, I'd like to put a legend on the bottom right hand side (empty space).
>
> is it possible?
>
> Thanks for helping,
>
> Kathryn Lord
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Achim.Zeileis at uibk.ac.at  Thu Feb  5 10:00:58 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 5 Feb 2015 10:00:58 +0100 (CET)
Subject: [R] R2BayesX
In-Reply-To: <90AD9DB98926A747B1C82FC2EE31E8A45BE558D0@LIVSVEXMBX01.intra.swsahs.nsw.gov.au>
References: <90AD9DB98926A747B1C82FC2EE31E8A45BE55769@LIVSVEXMBX01.intra.swsahs.nsw.gov.au>
	<alpine.DEB.2.11.1502041018160.2229@paninaro.uibk.ac.at>
	<90AD9DB98926A747B1C82FC2EE31E8A45BE558D0@LIVSVEXMBX01.intra.swsahs.nsw.gov.au>
Message-ID: <alpine.DEB.2.11.1502050958400.20281@paninaro.uibk.ac.at>

Shanley,

thanks for the example.

> Thank you for your help.
> Here is my R codes:
>
>> data("MunichBnd")
>
>> N <- length(MunichBnd); n <- N*5
>> dat <- data.frame(x1 = runif(n, -3, 3),id = as.factor(rep(names(MunichBnd), length.out = n)))
>> dat$sp <- with(dat, sort(runif(N, -2, 2), decreasing = TRUE)[id])
>> dat$re_poi <- with(dat, rpois(N, 10)[id])
>> dat$y_poi <- with(dat, 1.5 + sin(x1) + sp + re_poi + rpois(n, 10))
>> b_poi <- bayesx(y_poi ~ sx(x1) +  sx(id, bs = "mrf", map = MunichBnd) + sx(id, bs = "re"), method = "MCMC", data = dat, family='poisson')
>
> Warning message:
> running command '"C:/Users/ChongS/Documents/R/win-library/3.1/BayesXsrc/libs/x64/BayesX.exe" C:/Users/ChongS/AppData/Local/Temp/RtmpqMhw3Z/bayesx/bayesx.estim.input.prg' had status 3
>
> If I run the model using family='gaussian', it doesn't have problem.
> b_poi <- bayesx(y_poi ~ sx(x1) +   sx(id, bs = "mrf", map = MunichBnd) +  sx(id, bs = "re"), method = "MCMC", data = dat, family='gaussian')

This appears to be a problem in BayesX for combination of bs="re", 
method="MCMC" and family="poisson". If at least one of these is changed, 
everything works. An even simpler example is:

set.seed(1)
d <- data.frame(y = rpois(1000, 5))
d$x <- rep(1:100, each = 10)

Then:

bayesx(y ~ sx(x, bs = "re"), data = d, method = "MCMC", family = "poisson")
## -> problem processing BayesX!

whereas

bayesx(y ~ sx(x),            data = d, method = "MCMC", family = "poisson")
bayesx(y ~ sx(x, bs = "re"), data = d, method = "REML", family = "poisson")
bayesx(y ~ sx(x, bs = "re"), data = d, method = "MCMC", family = "gaussian")

are all ok. Niki has contacted the original BayesX authors who might be 
able to give more insight. For the moment, I would recommend to use 
method="REML".

Best,
Z

> Kind regards,
> Shanley
>
>
> -----Original Message-----
> From: Achim Zeileis [mailto:Achim.Zeileis at uibk.ac.at]
> Sent: Wednesday, 4 February 2015 8:20 PM
> To: Shanley Chong
> Cc: r-help at r-project.org; Nikolaus.Umlauf at uibk.ac.at
> Subject: Re: [R] R2BayesX
>
> Shanley:
>
>> I am trying to run STAR logistic/binomial model using R2BayesX . A
>> warning message came up every time when i included a random effect,
>> bs='re', (unstructured spatial effect) into the model. The warning
>> message is : Warning message: running command
>> '"C:/Users/ChongS/Documents/R/win-library/3.1/BayesXsrc/libs/x64/BayesX.exe"
>> C:/Users/ChongS/AppData/Local/Temp/RtmpCW8QY9/bayesx33/bayesx.estim.input.prg'
>> had status 5
>
> I haven't seen this problem before. Maybe you can provide "commented, minimal, self-contained, reproducible code" (as the posting guide asks)?
>
> I'm also cc'ing the package maintainer (Nikolaus Umlauf) as he might be able to give more insight.
>
> Best,
> Z
>
>> The model is fine when i just ran the model using mrf, bs='mrf', (structured spatial effect).
>>
>> And when i tried to run STAR using family=Gaussian (response is normally distributed) with structured and unstructured spatial effect, it is fine too.
>>
>> Can anyone please help?
>>
>> Regards,
>>
>> Shanley
>>
>>
>> _____________________________________________________________________
>> This email has been scanned for the Sydney & South Western Sydney Local Health Districts by the MessageLabs Email Security System.
>> Sydney & South Western Sydney Local Health Districts regularly monitor email and attachments to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> _____________________________________________________________________
> This email has been scanned for the Sydney & South Western Sydney Local Health Districts by the MessageLabs Email Security System.
> Sydney & South Western Sydney Local Health Districts regularly monitor email and attachments to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.
>
> _____________________________________________________________________
> This email has been scanned for the Sydney & South Western Sydney Local Health Districts by the MessageLabs Email Security System.
> Sydney & South Western Sydney Local Health Districts regularly monitor email and attachments to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From AARTI.MUNJAL at ucdenver.edu  Thu Feb  5 06:32:48 2015
From: AARTI.MUNJAL at ucdenver.edu (Munjal, Aarti)
Date: Thu, 5 Feb 2015 05:32:48 +0000
Subject: [R] ASA John M. Chambers Statistical Software Award - 2015
Message-ID: <D0F84E49.89DA%amunjal@mines.edu>

John M. Chambers Statistical Software Award - 2015

Statistical Computing Section

American Statistical Association


The Statistical Computing Section of the American Statistical Association announces the competition for the John M. Chambers Statistical Software Award. In 1998 the Association for Computing Machinery presented its Software System Award to John Chambers for the design and development of S. Dr. Chambers generously donated his award to the Statistical Computing Section to endow an annual prize for statistical software written by, or in collaboration with, an undergraduate or graduate student. The prize carries with it a cash award of $1000, plus a substantial allowance for travel to the annual Joint Statistical Meetings (JSM) where the award will be presented.


Teams of up to 3 people can participate in the competition, with the cash award being split among team members. The travel allowance will be given to just one individual in the team, who will be presented the award at JSM. To be eligible, the team must have designed and implemented a piece of statistical software. The individual within the team indicated to receive the travel allowance must have begun the development while a student, and must either currently be a student, or have completed all requirements for her/his last degree after January 1, 2014. To apply for the award, teams must provide the following materials:


Current CV's of all team members.


A letter from a faculty mentor at the academic institution of the individual indicated to receive the travel award. The letter should confirm that the individual had substantial participation in the development of the software, certify her/his student status when the software began to be developed (and either the current student status or the date of degree completion), and briefly discuss the importance of the software to statistical practice.


A brief, one to two page description of the software, summarizing what it does, how it does it, and why it is an important contribution. If the team member competing for the travel allowance has continued developing the software after finishing her/his studies, the description should indicate what was developed when the individual was a student and what has been added since.


An installable software package with its source code for use by the award committee. It should be accompanied by enough information to allow the judges to effectively use and evaluate the software (including its design considerations.) This information can be provided in a variety of ways, including but not limited to a user manual (paper or electronic), a paper, a URL, and online help to the system.


All materials must be in English. We prefer that electronic text be submitted in Postscript or PDF. The entries will be judged on a variety of dimensions, including the importance and relevance for statistical practice of the tasks performed by the software, ease of use, clarity of description, elegance and availability for use by the statistical community. Preference will be given to those entries that are grounded in software design rather than calculation. The decision of the award committee is final.


All application materials must be received by 5:00pm EST, Tuesday, February 17, 2015 at the address below. The winner will be announced in May and the award will be given at the 2015 Joint Statistical Meetings.


Chambers Statistical Software Award

c/o Aarti Munjal

Colorado School of Public Health

University of Colorado Denver

aarti.munjal at ucdenver.edu<mailto:aarti.munjal at ucdenver.edu>


	[[alternative HTML version deleted]]


From burnettwesley at gmail.com  Thu Feb  5 04:15:40 2015
From: burnettwesley at gmail.com (Wesley Burnett)
Date: Wed, 4 Feb 2015 22:15:40 -0500
Subject: [R] Rolling window VAR (vector autoregressive) estimation
Message-ID: <ABEF5E28-2E79-4BA5-B2D6-A4765918BA90@gmail.com>

Hi,

I am completely new to R. I have a dataset of several thousand, weekly observations with ten variables. I would like to create a program (algorithm) that does a rolling window VAR regression of window width "w" (for example, a window width of 200 weeks) for all of the variables within the model. The best package I can find to execute VAR regressions seems to be the "vars" package (http://cran.r-project.org/web/packages/vars/index.html). For my algorithm, I would like to retreive certain objects from the class "varest" generated by the "vars" package after a call to "VAR."  More specifically, within each rolling window I'm interested in retreiving a matrix of the variance-covariance residuals and a matrix of the estimated coefficients for the lagged endogenous variables.

There are several examples within this discussion board about estimating rolling window regressions with linear regression models, but I have not been able to find any algorithms for rolling window regressions with a more complicated regression like the vector autoregressive model.

As I have several thousand observations, I would appreciate advise on creating efficient algorithms to execute the rolling window regression for this VAR execution.

Thanks,

Wesley

From laomeng_3 at 163.com  Thu Feb  5 09:20:44 2015
From: laomeng_3 at 163.com (meng)
Date: Thu, 5 Feb 2015 16:20:44 +0800 (CST)
Subject: [R] one sample test
Message-ID: <69542e40.703.14b58d3b64a.Coremail.laomeng_3@163.com>

Hi all:
If I want to test whether the mean of a set of normal distributed data is different from a value(e.g. 0), I can use one sample t test . But if the data is not normal distributed,what kind of method should be used?


Many thanks!


My best.








	[[alternative HTML version deleted]]


From prakashd at hcl.com  Thu Feb  5 07:35:18 2015
From: prakashd at hcl.com (deepu)
Date: Wed, 4 Feb 2015 22:35:18 -0800 (PST)
Subject: [R] Rhive installation problem in Windows RStudio
Message-ID: <1423118118945-4702825.post@n4.nabble.com>

Hi,

I am facing problem in RHive installation in Rstudio Version 0.98.1091 for R
version 3.1.2 on Windows machine.

Warning message : 
> install.packages("RHive")
Warning in install.packages :
  package ?RHive? is not available (for R version 3.1.2)

Please help me its urgent

Thanks
Deepika



--
View this message in context: http://r.789695.n4.nabble.com/Rhive-installation-problem-in-Windows-RStudio-tp4702825.html
Sent from the R help mailing list archive at Nabble.com.


From snowyfox at 163.com  Thu Feb  5 09:01:13 2015
From: snowyfox at 163.com (=?GBK?B?xLrI59Gp?=)
Date: Thu, 5 Feb 2015 16:01:13 +0800 (CST)
Subject: [R] How to unload R.dll successfully by FreeLibrary
Message-ID: <611287c2.a2e6.14b58c1d63e.Coremail.snowyfox@163.com>

hi,
    I've some C++ code which try to load R.dll and execute some R command, then unload R.dll, yet it seems fail to unload it, so second time to call the function hangs since it is trying to Initialize R again(this is not allowed as documented). Anyone can tell me why, thanks.
//the following is my c++ code, used in a Visual Studio 2012 Console Application
#define ORAPI__cdecl
typedefBOOL(ORAPI*PFN_Rf_initEmbeddedR)(int argc, char *argv[]);
typedefvoid(ORAPI*PFN_Rf_endEmbeddedR)(int fatal);


staticvoid_simple_test()
{
#define STR_R_DLL_PATH_T("D:\\R\\R-3.1.2\\bin\\i386\\R.dll")
HMODULEm_hRDll = LoadLibrary(STR_R_DLL_PATH);
if ( m_hRDll )
{
PFN_Rf_initEmbeddedR pfnInit = (PFN_Rf_initEmbeddedR)GetProcAddress(m_hRDll, "Rf_initEmbeddedR");
PFN_Rf_endEmbeddedR pfnEnd = (PFN_Rf_endEmbeddedR)GetProcAddress(m_hRDll, "Rf_endEmbeddedR");


char*szArgs[] = {"REmbeddedPostgres", "--gui=none", "--silent"};
BOOL bRet = pfnInit(_countof(szArgs), szArgs); //call second time, this function will not return
//do something.
pfnEnd(0);
FreeLibrary(m_hRDll); //==> After this, R.dll still in memory, as I can see in Visual Studio 2012, Module window
}
}
//testing code end
int _tmain(int argc, _TCHAR* argv[])
{
_simple_test(); //first time, seems fine.
_simple_test(); //second time, hangs...
//_start_test_OR_Cache();
//_start_test_OR_Cache();
return 0;
}



????????????????????????????
	[[alternative HTML version deleted]]


From kridox at ymail.com  Thu Feb  5 10:30:13 2015
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 5 Feb 2015 18:30:13 +0900
Subject: [R] Rhive installation problem in Windows RStudio
In-Reply-To: <1423118118945-4702825.post@n4.nabble.com>
References: <1423118118945-4702825.post@n4.nabble.com>
Message-ID: <CAAcyNCw03qKvzEdb2ft1YDehMkveQ+Fx4fFkDFdFt2m0U+57cw@mail.gmail.com>

Hello,

This page says that RHive is not available as Windows binaries:
http://cran.r-project.org/web/packages/RHive/index.html

Regards,
Pascal

On Thu, Feb 5, 2015 at 3:35 PM, deepu <prakashd at hcl.com> wrote:
> Hi,
>
> I am facing problem in RHive installation in Rstudio Version 0.98.1091 for R
> version 3.1.2 on Windows machine.
>
> Warning message :
>> install.packages("RHive")
> Warning in install.packages :
>   package ?RHive? is not available (for R version 3.1.2)
>
> Please help me its urgent
>
> Thanks
> Deepika
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Rhive-installation-problem-in-Windows-RStudio-tp4702825.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From ripley at stats.ox.ac.uk  Thu Feb  5 10:57:14 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 05 Feb 2015 09:57:14 +0000
Subject: [R] Rhive installation problem in Windows RStudio
In-Reply-To: <CAAcyNCw03qKvzEdb2ft1YDehMkveQ+Fx4fFkDFdFt2m0U+57cw@mail.gmail.com>
References: <1423118118945-4702825.post@n4.nabble.com>
	<CAAcyNCw03qKvzEdb2ft1YDehMkveQ+Fx4fFkDFdFt2m0U+57cw@mail.gmail.com>
Message-ID: <54D33E7A.3080601@stats.ox.ac.uk>

On 05/02/2015 09:30, Pascal Oettli wrote:
> Hello,
>
> This page says that RHive is not available as Windows binaries:
> http://cran.r-project.org/web/packages/RHive/index.html

and

OS_type: 	unix

explains why it cannot even be installed from the sources.

>
> Regards,
> Pascal
>
> On Thu, Feb 5, 2015 at 3:35 PM, deepu <prakashd at hcl.com> wrote:
>> Hi,
>>
>> I am facing problem in RHive installation in Rstudio Version 0.98.1091 for R
>> version 3.1.2 on Windows machine.
>>
>> Warning message :
>>> install.packages("RHive")
>> Warning in install.packages :
>>    package ?RHive? is not available (for R version 3.1.2)
>>
>> Please help me its urgent
>>
>> Thanks
>> Deepika



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From pdalgd at gmail.com  Thu Feb  5 11:26:01 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 5 Feb 2015 11:26:01 +0100
Subject: [R] one sample test
In-Reply-To: <69542e40.703.14b58d3b64a.Coremail.laomeng_3@163.com>
References: <69542e40.703.14b58d3b64a.Coremail.laomeng_3@163.com>
Message-ID: <ACBC592C-04F3-4494-8F1A-4CC1FEE11225@gmail.com>


On 05 Feb 2015, at 09:20 , meng <laomeng_3 at 163.com> wrote:

> Hi all:
> If I want to test whether the mean of a set of normal distributed data is different from a value(e.g. 0), I can use one sample t test . But if the data is not normal distributed,what kind of method should be used?
> 

Not really an R question is it?

 (stats.stackexchange.com is -----> over there)

Anyways, short answer: If you can assume symmetry under the null hypothesis, there is a one-sample wilcox.test (signed rank test) and a couple of similar tests. If the distribution is not symmetric, first decide if you really mean the mean. If you actually mean median, there's the sign test. If you really do mean the mean, I'd look at the t test supplemented with bootstrap simulations to see whether departure from normality matters much.

> Many thanks!
> 
> 
> My best.
> 
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jholtman at gmail.com  Thu Feb  5 11:30:25 2015
From: jholtman at gmail.com (jim holtman)
Date: Thu, 5 Feb 2015 05:30:25 -0500
Subject: [R] How to download and unzip data in a loop
In-Reply-To: <CAHpsUFbhAs4LvAADF=dKSgTmyavoHOet6w5AcQD0WQi9TZCxUA@mail.gmail.com>
References: <CAHpsUFbhAs4LvAADF=dKSgTmyavoHOet6w5AcQD0WQi9TZCxUA@mail.gmail.com>
Message-ID: <CAAxdm-5ymnW=uaXFsQ-H5--GXFndS4tfa0EPVVJHhcCpKFvgJg@mail.gmail.com>

try taking the quotes off of 'files'


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Feb 4, 2015 at 5:24 PM, Alexandra Catena <amc5981 at gmail.com> wrote:

> Hi All,
>
> I need to loop through and download the past 10 years of met data to a
> temporary directory.  I then need to unzip it and place it into another
> directory.
>
>
> year = (2005:2015)
>
> for (i in year)
>   tmpdir = tempdir()
>   file[i] = file.path(tmpdir, sprintf('724927-23285-%4i.gz', i))
>   url = sprintf('
> ftp://ftp.ncdc.noaa.gov/pub/data/noaa/%4i/724927-23285-%4i.gz', i, i)
>   #file = basename(url)
>   download.file(url, file[i])
>   files = dir(tmpdir, '*.gz', full.names=FALSE)
>   read.table(gzfile('files'))
>
>
>
> 'file' returns 2015 indices with "/tmp/RtmpKvB4Wz/724927-23285-2015.gz"
> next to 2015. and files returns 724927-23285-2015.gz.  However, when I try
> to unzip the gz file using the last line, it says it cannot open the
> connection and the probable reason is that there is no such file or
> directory.
>
>
>
> Thanks,
> Alexandra
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jon.skoien at jrc.ec.europa.eu  Thu Feb  5 12:11:14 2015
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Thu, 05 Feb 2015 12:11:14 +0100
Subject: [R] How to download and unzip data in a loop
In-Reply-To: <CAAxdm-5ymnW=uaXFsQ-H5--GXFndS4tfa0EPVVJHhcCpKFvgJg@mail.gmail.com>
References: <CAHpsUFbhAs4LvAADF=dKSgTmyavoHOet6w5AcQD0WQi9TZCxUA@mail.gmail.com>
	<CAAxdm-5ymnW=uaXFsQ-H5--GXFndS4tfa0EPVVJHhcCpKFvgJg@mail.gmail.com>
Message-ID: <54D34FD2.7040804@jrc.ec.europa.eu>

In addition to following Jim's suggestion, you should probably also use 
full.names = TRUE, otherwise you will try to open a connection to files 
in your current directory, not in tmpdir.
Another thing is that the unzipped files appear irregular with respect 
to columns, so read.table might not work too well.

Jon

On 2/5/2015 11:30 AM, jim holtman wrote:
> try taking the quotes off of 'files'
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Wed, Feb 4, 2015 at 5:24 PM, Alexandra Catena <amc5981 at gmail.com> wrote:
>
>> Hi All,
>>
>> I need to loop through and download the past 10 years of met data to a
>> temporary directory.  I then need to unzip it and place it into another
>> directory.
>>
>>
>> year = (2005:2015)
>>
>> for (i in year)
>>    tmpdir = tempdir()
>>    file[i] = file.path(tmpdir, sprintf('724927-23285-%4i.gz', i))
>>    url = sprintf('
>> ftp://ftp.ncdc.noaa.gov/pub/data/noaa/%4i/724927-23285-%4i.gz', i, i)
>>    #file = basename(url)
>>    download.file(url, file[i])
>>    files = dir(tmpdir, '*.gz', full.names=FALSE)
>>    read.table(gzfile('files'))
>>
>>
>>
>> 'file' returns 2015 indices with "/tmp/RtmpKvB4Wz/724927-23285-2015.gz"
>> next to 2015. and files returns 724927-23285-2015.gz.  However, when I try
>> to unzip the gz file using the last line, it says it cannot open the
>> connection and the probable reason is that there is no such file or
>> directory.
>>
>>
>>
>> Thanks,
>> Alexandra
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Jon Olav Sk?ien
Joint Research Centre - European Commission
Institute for Environment and Sustainability (IES)
Climate Risk Management Unit

Via Fermi 2749, TP 100-01,  I-21027 Ispra (VA), ITALY

jon.skoien at jrc.ec.europa.eu
Tel:  +39 0332 789205

Disclaimer: Views expressed in this email are those of the individual 
and do not necessarily represent official views of the European Commission.


From hkawakat at gmail.com  Thu Feb  5 13:40:28 2015
From: hkawakat at gmail.com (Hiroyuki Kawakatsu)
Date: Thu, 5 Feb 2015 12:40:28 +0000
Subject: [R] FFT Normalization Documentation
Message-ID: <CADBEN2z0VQmWyUODeKdtQiygNg0Dbs1its32bTwMjPTTUQ7FWw@mail.gmail.com>

On 2015-02-05 Martin Maechler wrote:

[...]
> Both a definition of the DFT (in LaTeX or directly as \deqn{}{}) which
> matches *our* fft(), and an extended commented example (ca 20 lines,
> rather than ca 100 lines!) would be welcome additions.
[...]

Here is a previous attempt:

https://stat.ethz.ch/pipermail/r-devel/2008-June/049807.html

It fell on deaf ears so someone could improve on it. I still
google this page when I have to remind myself what fft()
is doing.

h.
-- 
+---
| Hiroyuki Kawakatsu
| Business School, Dublin City University
| Dublin 9, Ireland. Tel +353 (0)1 700 7496


From alaios at yahoo.com  Thu Feb  5 13:57:42 2015
From: alaios at yahoo.com (Alaios)
Date: Thu, 5 Feb 2015 12:57:42 +0000 (UTC)
Subject: [R] save structure to be accesible later
Message-ID: <1316544333.122505.1423141062041.JavaMail.yahoo@mail.yahoo.com>

Dear all,I have a function that returns the following list. At the end I will call my function 1000 times and I want to keep for each of these 1000 "results" (the structure as given below)in an order to be accessible later (Load the 1000 results and access them within a for loop for example)
How should I approach the issue?I would like to thank you for your exampleRegardsAlex
P,S The result of my function



?str(fitcass1)
List of 10
?$ parameters? :'data.frame':?? 2 obs. of? 3 variables:
? ..$ pi?? : num [1:2] 0.833 0.167
? ..$ mu?? : num [1:2] 8828 110000
? ..$ sigma: num [1:2] 18085 1543
?$ se????????? :'data.frame':?? 2 obs. of? 3 variables:
? ..$ pi.se?? : num [1:2] NA NA
? ..$ mu.se?? : num [1:2] NA NA
? ..$ sigma.se: num [1:2] NA NA
?$ distribution: chr "gamma"
?$ constraint? :List of 8
? ..$ conpi?? : chr "NONE"
? ..$ conmu?? : chr "NONE"
? ..$ consigma: chr "NONE"
? ..$ fixpi?? : NULL
? ..$ fixmu?? : NULL
? ..$ fixsigma: NULL
? ..$ cov???? : NULL
? ..$ size??? : NULL
?$ chisq?????? : num 52.4
?$ df????????? : num 5
?$ P?????????? : num 4.57e-10
?$ vmat??????? : num [1:5, 1:5] NA NA NA NA NA NA NA NA NA NA ...
?$ mixdata???? :Classes ?mixdata? and 'data.frame':???? 11 obs. of? 2 variables:
? ..$ X??? : num [1:11] 1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
? ..$ count: int [1:11] 993 137 82 30 21 5 7 14 21 2 ...
?$ usecondit?? : logi FALSE
?- attr(*, "class")= chr "mix"



	[[alternative HTML version deleted]]


From olivier.crouzet at univ-nantes.fr  Thu Feb  5 14:07:57 2015
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Thu, 5 Feb 2015 13:07:57 +0000
Subject: [R] save structure to be accesible later
In-Reply-To: <1316544333.122505.1423141062041.JavaMail.yahoo@mail.yahoo.com>
References: <1316544333.122505.1423141062041.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <818837787-1423141688-cardhu_decombobulator_blackberry.rim.net-1580041060-@b12.c6.bise7.blackberry>

Hi, have a look at save() and load().

You can save part of your workspace to a file (save()) and load it from this file (load()). Of course the file format is R specific (but its specifications are free) You may easily share the file with other R users.

Olivier.

--
Olivier Crouzet
LLING - Laboratoire de Linguistique de Nantes - EA3827
Universit? de Nantes

-----Original Message-----
From: Alaios via R-help <r-help at r-project.org>
Sender: "R-help" <r-help-bounces at r-project.org>Date: Thu, 5 Feb 2015 12:57:42 
To: R-help Mailing List<r-help at r-project.org>
Reply-To: Alaios <alaios at yahoo.com>
Subject: [R] save structure to be accesible later

Dear all,I have a function that returns the following list. At the end I will call my function 1000 times and I want to keep for each of these 1000 "results" (the structure as given below)in an order to be accessible later (Load the 1000 results and access them within a for loop for example)
How should I approach the issue?I would like to thank you for your exampleRegardsAlex
P,S The result of my function



?str(fitcass1)
List of 10
?$ parameters? :'data.frame':?? 2 obs. of? 3 variables:
? ..$ pi?? : num [1:2] 0.833 0.167
? ..$ mu?? : num [1:2] 8828 110000
? ..$ sigma: num [1:2] 18085 1543
?$ se????????? :'data.frame':?? 2 obs. of? 3 variables:
? ..$ pi.se?? : num [1:2] NA NA
? ..$ mu.se?? : num [1:2] NA NA
? ..$ sigma.se: num [1:2] NA NA
?$ distribution: chr "gamma"
?$ constraint? :List of 8
? ..$ conpi?? : chr "NONE"
? ..$ conmu?? : chr "NONE"
? ..$ consigma: chr "NONE"
? ..$ fixpi?? : NULL
? ..$ fixmu?? : NULL
? ..$ fixsigma: NULL
? ..$ cov???? : NULL
? ..$ size??? : NULL
?$ chisq?????? : num 52.4
?$ df????????? : num 5
?$ P?????????? : num 4.57e-10
?$ vmat??????? : num [1:5, 1:5] NA NA NA NA NA NA NA NA NA NA ...
?$ mixdata???? :Classes ?mixdata? and 'data.frame':???? 11 obs. of? 2 variables:
? ..$ X??? : num [1:11] 1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
? ..$ count: int [1:11] 993 137 82 30 21 5 7 14 21 2 ...
?$ usecondit?? : logi FALSE
?- attr(*, "class")= chr "mix"



	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From ivan.calandra at univ-reims.fr  Thu Feb  5 14:41:11 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 05 Feb 2015 14:41:11 +0100
Subject: [R] save structure to be accesible later
In-Reply-To: <818837787-1423141688-cardhu_decombobulator_blackberry.rim.net-1580041060-@b12.c6.bise7.blackberry>
References: <1316544333.122505.1423141062041.JavaMail.yahoo@mail.yahoo.com>
	<818837787-1423141688-cardhu_decombobulator_blackberry.rim.net-1580041060-@b12.c6.bise7.blackberry>
Message-ID: <54D372F7.8030108@univ-reims.fr>

Hi,

I generally prefer using the functions saveObject() and loadObject() 
from the R.utils package. I like that you load directly to an object in 
the R workspace.

HTH,
Ivan

--
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 05/02/15 14:07, Olivier Crouzet a ?crit :
> Hi, have a look at save() and load().
>
> You can save part of your workspace to a file (save()) and load it from this file (load()). Of course the file format is R specific (but its specifications are free) You may easily share the file with other R users.
>
> Olivier.
>
> --
> Olivier Crouzet
> LLING - Laboratoire de Linguistique de Nantes - EA3827
> Universit? de Nantes
>
> -----Original Message-----
> From: Alaios via R-help <r-help at r-project.org>
> Sender: "R-help" <r-help-bounces at r-project.org>Date: Thu, 5 Feb 2015 12:57:42
> To: R-help Mailing List<r-help at r-project.org>
> Reply-To: Alaios <alaios at yahoo.com>
> Subject: [R] save structure to be accesible later
>
> Dear all,I have a function that returns the following list. At the end I will call my function 1000 times and I want to keep for each of these 1000 "results" (the structure as given below)in an order to be accessible later (Load the 1000 results and access them within a for loop for example)
> How should I approach the issue?I would like to thank you for your exampleRegardsAlex
> P,S The result of my function
>
>
>
>   str(fitcass1)
> List of 10
>   $ parameters  :'data.frame':   2 obs. of  3 variables:
>    ..$ pi   : num [1:2] 0.833 0.167
>    ..$ mu   : num [1:2] 8828 110000
>    ..$ sigma: num [1:2] 18085 1543
>   $ se          :'data.frame':   2 obs. of  3 variables:
>    ..$ pi.se   : num [1:2] NA NA
>    ..$ mu.se   : num [1:2] NA NA
>    ..$ sigma.se: num [1:2] NA NA
>   $ distribution: chr "gamma"
>   $ constraint  :List of 8
>    ..$ conpi   : chr "NONE"
>    ..$ conmu   : chr "NONE"
>    ..$ consigma: chr "NONE"
>    ..$ fixpi   : NULL
>    ..$ fixmu   : NULL
>    ..$ fixsigma: NULL
>    ..$ cov     : NULL
>    ..$ size    : NULL
>   $ chisq       : num 52.4
>   $ df          : num 5
>   $ P           : num 4.57e-10
>   $ vmat        : num [1:5, 1:5] NA NA NA NA NA NA NA NA NA NA ...
>   $ mixdata     :Classes ?mixdata? and 'data.frame':     11 obs. of  2 variables:
>    ..$ X    : num [1:11] 1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
>    ..$ count: int [1:11] 993 137 82 30 21 5 7 14 21 2 ...
>   $ usecondit   : logi FALSE
>   - attr(*, "class")= chr "mix"
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maechler at lynne.stat.math.ethz.ch  Thu Feb  5 17:54:40 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Thu, 5 Feb 2015 17:54:40 +0100
Subject: [R] FFT Normalization Documentation
In-Reply-To: <CADBEN2z0VQmWyUODeKdtQiygNg0Dbs1its32bTwMjPTTUQ7FWw@mail.gmail.com>
References: <CADBEN2z0VQmWyUODeKdtQiygNg0Dbs1its32bTwMjPTTUQ7FWw@mail.gmail.com>
Message-ID: <21715.41040.76555.65053@stat.math.ethz.ch>

>>>>> Hiroyuki Kawakatsu <hkawakat at gmail.com>
>>>>>     on Thu, 5 Feb 2015 12:40:28 +0000 writes:

    > On 2015-02-05 Martin Maechler wrote:
    > [...]
    >> Both a definition of the DFT (in LaTeX or directly as \deqn{}{}) which
    >> matches *our* fft(), and an extended commented example (ca 20 lines,
    >> rather than ca 100 lines!) would be welcome additions.
    > [...]

    > Here is a previous attempt:

    > https://stat.ethz.ch/pipermail/r-devel/2008-June/049807.html

    > It fell on deaf ears so someone could improve on it. I still
    > google this page when I have to remind myself what fft()
    > is doing.

"deaf ears" is clearly too strong here (my wife really having 99% deaf ears..),
but indeed, it is a pity that this was completely overlooked and
never taken up.

I'll do so now.
Martin


From rhelpmaillist at 163.com  Thu Feb  5 10:44:45 2015
From: rhelpmaillist at 163.com (PO SU)
Date: Thu, 5 Feb 2015 17:44:45 +0800 (CST)
Subject: [R] Needing help about recosystem package
Message-ID: <6bbfd6c5.ed88.14b5920a156.Coremail.rhelpmaillist@163.com>



Dear expeRt,
? I am using recosystem package which is an wrapper of the LIBMF library,? it implements matrix factorize which needed in latent factor model, but the package only provides ?the predict method, not include matrix P,Q which estimated. I just need the P and Q matrix, so ,if anyone happen to know it ?




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From laomeng_3 at 163.com  Thu Feb  5 15:55:35 2015
From: laomeng_3 at 163.com (meng)
Date: Thu, 5 Feb 2015 22:55:35 +0800 (CST)
Subject: [R] one sample test
In-Reply-To: <ACBC592C-04F3-4494-8F1A-4CC1FEE11225@gmail.com>
References: <69542e40.703.14b58d3b64a.Coremail.laomeng_3@163.com>
	<ACBC592C-04F3-4494-8F1A-4CC1FEE11225@gmail.com>
Message-ID: <6ece156e.970.14b5a3d34d4.Coremail.laomeng_3@163.com>

Very sorry that I ignore the question type.Yest,it's not an R question.
Many thanks for your answer.







--
QQ: 1733768559





At 2015-02-05 18:26:01,"peter dalgaard" <pdalgd at gmail.com> wrote:
>
>On 05 Feb 2015, at 09:20 , meng <laomeng_3 at 163.com> wrote:
>
>> Hi all:
>> If I want to test whether the mean of a set of normal distributed data is different from a value(e.g. 0), I can use one sample t test . But if the data is not normal distributed,what kind of method should be used?
>> 
>
>Not really an R question is it?
>
> (stats.stackexchange.com is -----> over there)
>
>Anyways, short answer: If you can assume symmetry under the null hypothesis, there is a one-sample wilcox.test (signed rank test) and a couple of similar tests. If the distribution is not symmetric, first decide if you really mean the mean. If you actually mean median, there's the sign test. If you really do mean the mean, I'd look at the t test supplemented with bootstrap simulations to see whether departure from normality matters much.
>
>> Many thanks!
>> 
>> 
>> My best.
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>-- 
>Peter Dalgaard, Professor,
>Center for Statistics, Copenhagen Business School
>Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>Phone: (+45)38153501
>Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From daniel.marmander at gmail.com  Thu Feb  5 17:50:07 2015
From: daniel.marmander at gmail.com (Daniel Marmander)
Date: Thu, 5 Feb 2015 16:50:07 +0000
Subject: [R] Creating two autocorrelated and correlated time series
Message-ID: <CAPDJGXBaQ3mF1uMcwkcef-xQYCO3Pr==efuPyk5wnxS+Dr8iLA@mail.gmail.com>

I can create both correlated series and autocorrelated time series with
well defined correlation factors. I am however having trouble creating two
series given fixed autocorrelation for some number of lags in the series
(autocorrelation might differ between the two as well), that also has a
specific correlation between the series.

I have found some help here:
http://stats.stackexchange.com/questions/71211/how-to-generate-normal-random-variable-vector-which-is-spatially-auto-correlated
but I have a hard time implementing it in R, being a R-novice.


Thanks,
Daniel

	[[alternative HTML version deleted]]


From amc5981 at gmail.com  Thu Feb  5 19:03:34 2015
From: amc5981 at gmail.com (Alexandra Catena)
Date: Thu, 5 Feb 2015 10:03:34 -0800
Subject: [R] How to download and unzip data in a loop
In-Reply-To: <54D34FD2.7040804@jrc.ec.europa.eu>
References: <CAHpsUFbhAs4LvAADF=dKSgTmyavoHOet6w5AcQD0WQi9TZCxUA@mail.gmail.com>
	<CAAxdm-5ymnW=uaXFsQ-H5--GXFndS4tfa0EPVVJHhcCpKFvgJg@mail.gmail.com>
	<54D34FD2.7040804@jrc.ec.europa.eu>
Message-ID: <CAHpsUFbTGKn66sb5E-q+Te+34pF8YE6eOMyN-M55BrM=YgMXOQ@mail.gmail.com>

Thank you guys for the response.

I'm trying to download the last ten years of meteorology data from a
weather station in Livermore from the URL:
ftp://ftp.ncdc.noaa.gov/pub/data/noaa/2015/724927-23285-2015.gz
The Livermore station code is 724927-23285.  If I wanted to download data
from 2005, the URL would be:
ftp://ftp.ncdc.noaa.gov/pub/data/noaa/2005/724927-23285-2005.gz

Once I download the data into a temporary file, I want to unzip it and
store it into another directory where I can access it.

Also, why are there 2015 indices instead of just 10 when I'm only looping
through 2005:2015?

Thanks,
Alexandra

On Thu, Feb 5, 2015 at 3:11 AM, Jon Skoien <jon.skoien at jrc.ec.europa.eu>
wrote:

> In addition to following Jim's suggestion, you should probably also use
> full.names = TRUE, otherwise you will try to open a connection to files in
> your current directory, not in tmpdir.
> Another thing is that the unzipped files appear irregular with respect to
> columns, so read.table might not work too well.
>
> Jon
>
>
> On 2/5/2015 11:30 AM, jim holtman wrote:
>
>> try taking the quotes off of 'files'
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Wed, Feb 4, 2015 at 5:24 PM, Alexandra Catena <amc5981 at gmail.com>
>> wrote:
>>
>>  Hi All,
>>>
>>> I need to loop through and download the past 10 years of met data to a
>>> temporary directory.  I then need to unzip it and place it into another
>>> directory.
>>>
>>>
>>> year = (2005:2015)
>>>
>>> for (i in year)
>>>    tmpdir = tempdir()
>>>    file[i] = file.path(tmpdir, sprintf('724927-23285-%4i.gz', i))
>>>    url = sprintf('
>>> ftp://ftp.ncdc.noaa.gov/pub/data/noaa/%4i/724927-23285-%4i.gz', i, i)
>>>    #file = basename(url)
>>>    download.file(url, file[i])
>>>    files = dir(tmpdir, '*.gz', full.names=FALSE)
>>>    read.table(gzfile('files'))
>>>
>>>
>>>
>>> 'file' returns 2015 indices with "/tmp/RtmpKvB4Wz/724927-23285-2015.gz"
>>> next to 2015. and files returns 724927-23285-2015.gz.  However, when I
>>> try
>>> to unzip the gz file using the last line, it says it cannot open the
>>> connection and the probable reason is that there is no such file or
>>> directory.
>>>
>>>
>>>
>>> Thanks,
>>> Alexandra
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Jon Olav Sk?ien
> Joint Research Centre - European Commission
> Institute for Environment and Sustainability (IES)
> Climate Risk Management Unit
>
> Via Fermi 2749, TP 100-01,  I-21027 Ispra (VA), ITALY
>
> jon.skoien at jrc.ec.europa.eu
> Tel:  +39 0332 789205
>
> Disclaimer: Views expressed in this email are those of the individual and
> do not necessarily represent official views of the European Commission.
>
>

	[[alternative HTML version deleted]]


From cmora at Dal.Ca  Thu Feb  5 20:48:34 2015
From: cmora at Dal.Ca (Camilo Mora)
Date: Thu, 5 Feb 2015 19:48:34 +0000
Subject: [R] Fastest way to calculate quantile in large data.table
In-Reply-To: <mailman.1.1423134001.29479.r-help@r-project.org>
References: <mailman.1.1423134001.29479.r-help@r-project.org>
Message-ID: <1423165712783.7455@Dal.Ca>

In total I found 8 different way to calculate quantile in very a large data.table. I share below their performances for future reference. Tests 1, 7 and 8 were the fastest I found.

Best,

Camilo

library(data.table)
v <- data.table(x=runif(10000),x2 = runif(10000),  x3=runif(10000),x4=runif(10000))

#fastest
Sys.time()->StartTEST1
t(v[, apply(v,1,quantile,probs =c(.1,.9,.5),na.rm=TRUE)] )
Sys.time()->EndTEST1

Sys.time()->StartTEST2
v[, quantile(.SD,probs =c(.1,.9,.5)), by = 1:nrow(v)]
Sys.time()->EndTEST2

Sys.time()->StartTEST3
v[, c("L","H","M"):=quantile(.SD,probs =c(.1,.9,.5)), by = 1:nrow(v)]
Sys.time()->EndTEST3
v
v[, c("L","H","M"):=NULL]

v[,Names:=rownames(v)]
setkey(v,Names)

Sys.time()->StartTEST4
v[, c("L","H","M"):=quantile(.SD,probs =c(.1,.9,.5)), by = Names]
Sys.time()->EndTEST4
v
v[, c("L","H","M"):=NULL]


Sys.time()->StartTEST5
v[,  as.list(quantile(.SD,c(.1,.90,.5),na.rm=TRUE)), by=Names]
Sys.time()->EndTEST5


Sys.time()->StartTEST6
v[,  as.list(quantile(.SD,c(.1,.90,.5),na.rm=TRUE)), by=Names,.SDcols=1:4]
Sys.time()->EndTEST6


Sys.time()->StartTEST7
v[,  as.list(quantile(c(x ,       x2,        x3,        x4 ),c(.1,.90,.5),na.rm=TRUE)), by=Names]
Sys.time()->EndTEST7


# melting the database and doing quantily by summary. This is the second fastest, which is ironic given that the database has to be melted first
library(reshape2)
Sys.time()->StartTEST8
vs<-melt(v)
vs[,  as.list(quantile(value,c(.1,.90,.5),na.rm=TRUE)), by=Names]
Sys.time()->EndTEST8


EndTEST1-StartTEST1
EndTEST2-StartTEST2
EndTEST3-StartTEST3
EndTEST4-StartTEST4
EndTEST5-StartTEST5
EndTEST6-StartTEST6
EndTEST7-StartTEST7
EndTEST8-StartTEST8



From lianoglou.steve at gene.com  Thu Feb  5 21:16:05 2015
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Thu, 5 Feb 2015 12:16:05 -0800
Subject: [R] Fastest way to calculate quantile in large data.table
In-Reply-To: <1423165712783.7455@Dal.Ca>
References: <mailman.1.1423134001.29479.r-help@r-project.org>
	<1423165712783.7455@Dal.Ca>
Message-ID: <CAHA9McP0WdEQ1D3FOBxeEOjHtymsD=t9tCuOTttPidn44fVAEA@mail.gmail.com>

Not sure if there is a question in here somewhere?

But if I can point out an observation: if you are doing summary
calculations across the rows like this, my guess is that using a
data.table (data.frame) structure for that will really bite you,
because this operation on a data.table/data.frame is expensive;

  x <- dt[i,]

However it's much faster with a matrix. It doesn't seem like you're
doing anything with this dataset that takes advantage of data.table's
quick grouping/indexing mojo, so why store it in  data.table at all?

Witness:

R> library(data.table)
R> m <- matrix(rnorm(1e6), nrow=10)
R> d <- as.data.table(m)
R> idxs <- sample(1:nrow(m), 500, replace=TRUE)

R> system.time(for (i in idxs) x <- m[i,])
   user  system elapsed
  0.497   0.169   0.670

R> system.time(for (i in idxs) x <- d[i,])
## I killed it after waiting for 14 seconds

-steve

On Thu, Feb 5, 2015 at 11:48 AM, Camilo Mora <cmora at dal.ca> wrote:
> In total I found 8 different way to calculate quantile in very a large data.table. I share below their performances for future reference. Tests 1, 7 and 8 were the fastest I found.
>
> Best,
>
> Camilo
>
> library(data.table)
> v <- data.table(x=runif(10000),x2 = runif(10000),  x3=runif(10000),x4=runif(10000))
>
> #fastest
> Sys.time()->StartTEST1
> t(v[, apply(v,1,quantile,probs =c(.1,.9,.5),na.rm=TRUE)] )
> Sys.time()->EndTEST1
>
> Sys.time()->StartTEST2
> v[, quantile(.SD,probs =c(.1,.9,.5)), by = 1:nrow(v)]
> Sys.time()->EndTEST2
>
> Sys.time()->StartTEST3
> v[, c("L","H","M"):=quantile(.SD,probs =c(.1,.9,.5)), by = 1:nrow(v)]
> Sys.time()->EndTEST3
> v
> v[, c("L","H","M"):=NULL]
>
> v[,Names:=rownames(v)]
> setkey(v,Names)
>
> Sys.time()->StartTEST4
> v[, c("L","H","M"):=quantile(.SD,probs =c(.1,.9,.5)), by = Names]
> Sys.time()->EndTEST4
> v
> v[, c("L","H","M"):=NULL]
>
>
> Sys.time()->StartTEST5
> v[,  as.list(quantile(.SD,c(.1,.90,.5),na.rm=TRUE)), by=Names]
> Sys.time()->EndTEST5
>
>
> Sys.time()->StartTEST6
> v[,  as.list(quantile(.SD,c(.1,.90,.5),na.rm=TRUE)), by=Names,.SDcols=1:4]
> Sys.time()->EndTEST6
>
>
> Sys.time()->StartTEST7
> v[,  as.list(quantile(c(x ,       x2,        x3,        x4 ),c(.1,.90,.5),na.rm=TRUE)), by=Names]
> Sys.time()->EndTEST7
>
>
> # melting the database and doing quantily by summary. This is the second fastest, which is ironic given that the database has to be melted first
> library(reshape2)
> Sys.time()->StartTEST8
> vs<-melt(v)
> vs[,  as.list(quantile(value,c(.1,.90,.5),na.rm=TRUE)), by=Names]
> Sys.time()->EndTEST8
>
>
> EndTEST1-StartTEST1
> EndTEST2-StartTEST2
> EndTEST3-StartTEST3
> EndTEST4-StartTEST4
> EndTEST5-StartTEST5
> EndTEST6-StartTEST6
> EndTEST7-StartTEST7
> EndTEST8-StartTEST8
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Steve Lianoglou
Computational Biologist
Genentech


From jdnewmil at dcn.davis.CA.us  Thu Feb  5 21:16:46 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 05 Feb 2015 12:16:46 -0800
Subject: [R] How to download and unzip data in a loop
In-Reply-To: <CAHpsUFbTGKn66sb5E-q+Te+34pF8YE6eOMyN-M55BrM=YgMXOQ@mail.gmail.com>
References: <CAHpsUFbhAs4LvAADF=dKSgTmyavoHOet6w5AcQD0WQi9TZCxUA@mail.gmail.com>
	<CAAxdm-5ymnW=uaXFsQ-H5--GXFndS4tfa0EPVVJHhcCpKFvgJg@mail.gmail.com>
	<54D34FD2.7040804@jrc.ec.europa.eu>
	<CAHpsUFbTGKn66sb5E-q+Te+34pF8YE6eOMyN-M55BrM=YgMXOQ@mail.gmail.com>
Message-ID: <AE79A2C8-FD7D-4D6E-85DB-17A0E254A4A3@dcn.davis.CA.us>

Dunno. Try posting your current code that fixes the previously mentioned problems, but this time use plain text so the HTML doesn't corrupt it.

Usually you can solve this kind of issue by executing one line at a time and looking at each result to make sure it is what you think it is. You can also wrap it up in a function and set debug mode for that function and then you can single step through it.

One thing that looks wrong is lack or braces surrounding the body of the for loop.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 5, 2015 10:03:34 AM PST, Alexandra Catena <amc5981 at gmail.com> wrote:
>Thank you guys for the response.
>
>I'm trying to download the last ten years of meteorology data from a
>weather station in Livermore from the URL:
>ftp://ftp.ncdc.noaa.gov/pub/data/noaa/2015/724927-23285-2015.gz
>The Livermore station code is 724927-23285.  If I wanted to download
>data
>from 2005, the URL would be:
>ftp://ftp.ncdc.noaa.gov/pub/data/noaa/2005/724927-23285-2005.gz
>
>Once I download the data into a temporary file, I want to unzip it and
>store it into another directory where I can access it.
>
>Also, why are there 2015 indices instead of just 10 when I'm only
>looping
>through 2005:2015?
>
>Thanks,
>Alexandra
>
>On Thu, Feb 5, 2015 at 3:11 AM, Jon Skoien
><jon.skoien at jrc.ec.europa.eu>
>wrote:
>
>> In addition to following Jim's suggestion, you should probably also
>use
>> full.names = TRUE, otherwise you will try to open a connection to
>files in
>> your current directory, not in tmpdir.
>> Another thing is that the unzipped files appear irregular with
>respect to
>> columns, so read.table might not work too well.
>>
>> Jon
>>
>>
>> On 2/5/2015 11:30 AM, jim holtman wrote:
>>
>>> try taking the quotes off of 'files'
>>>
>>>
>>> Jim Holtman
>>> Data Munger Guru
>>>
>>> What is the problem that you are trying to solve?
>>> Tell me what you want to do, not how you want to do it.
>>>
>>> On Wed, Feb 4, 2015 at 5:24 PM, Alexandra Catena <amc5981 at gmail.com>
>>> wrote:
>>>
>>>  Hi All,
>>>>
>>>> I need to loop through and download the past 10 years of met data
>to a
>>>> temporary directory.  I then need to unzip it and place it into
>another
>>>> directory.
>>>>
>>>>
>>>> year = (2005:2015)
>>>>
>>>> for (i in year)
>>>>    tmpdir = tempdir()
>>>>    file[i] = file.path(tmpdir, sprintf('724927-23285-%4i.gz', i))
>>>>    url = sprintf('
>>>> ftp://ftp.ncdc.noaa.gov/pub/data/noaa/%4i/724927-23285-%4i.gz', i,
>i)
>>>>    #file = basename(url)
>>>>    download.file(url, file[i])
>>>>    files = dir(tmpdir, '*.gz', full.names=FALSE)
>>>>    read.table(gzfile('files'))
>>>>
>>>>
>>>>
>>>> 'file' returns 2015 indices with
>"/tmp/RtmpKvB4Wz/724927-23285-2015.gz"
>>>> next to 2015. and files returns 724927-23285-2015.gz.  However,
>when I
>>>> try
>>>> to unzip the gz file using the last line, it says it cannot open
>the
>>>> connection and the probable reason is that there is no such file or
>>>> directory.
>>>>
>>>>
>>>>
>>>> Thanks,
>>>> Alexandra
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> --
>> Jon Olav Sk?ien
>> Joint Research Centre - European Commission
>> Institute for Environment and Sustainability (IES)
>> Climate Risk Management Unit
>>
>> Via Fermi 2749, TP 100-01,  I-21027 Ispra (VA), ITALY
>>
>> jon.skoien at jrc.ec.europa.eu
>> Tel:  +39 0332 789205
>>
>> Disclaimer: Views expressed in this email are those of the individual
>and
>> do not necessarily represent official views of the European
>Commission.
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From btrautman84 at gmail.com  Thu Feb  5 21:08:51 2015
From: btrautman84 at gmail.com (Brian Trautman)
Date: Thu, 5 Feb 2015 12:08:51 -0800
Subject: [R] Fixed Width EBCDIC Files in R
Message-ID: <CAFYnejK5+8ww+zyJwgcu+0f8FiRYbfpqgWc3t62nmRnSsy4S+w@mail.gmail.com>

I'm trying to read some mainframe data encoded as EBCDIC into R, and am at
a loss. I'd like to avoid using an external program to convert the files,
since I'm operating in a corporate environment.

You can find the example files at at the link below, with both ASCII and
EBCDIC versions. Note that there are no linebreaks in the EBCDIC versions
of the file -- instead, I'd be specifying the width of each line manually.
R has the IBM500 encoding available in my environment, which should be the
correct one for these files.

However, when I run the following commands, R seems to fail entirely.  It
loads a single record with garbage characters, regardless of the encoding I
specified.


layout <- read.fwf("EBCDIC_LAYOUT", widths = c(80), fileEncoding='ibm500')

data   <- read.fwf("EBCDIC_ZIPCODE", widths = c(32), fileEncoding='ibm500')


Where might I go from here?

Related -- some of the files I expect to use will be fairly large (1 GB or
so). Preferably, I'd like a solution that scales reasonably well. (I tried
packages like LaF, but they don't have the option to select encoding.)

Thank you very much!


Example files --
https://drive.google.com/open?id=0ByvX1v-WqaaASTdwV2ZYS0pBV00&authuser=0

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Thu Feb  5 22:17:43 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Thu, 5 Feb 2015 22:17:43 +0100
Subject: [R] =?utf-8?q?Rotate_array_by_90=C2=B0?=
Message-ID: <CALJKBv-vrmD9yekk0fHHYV4+0MwZ=Z8Pmr-BJhw0h8CgQzVSzg@mail.gmail.com>

Dear aal,

Is there a way to rotate array or a cube of matrices by Y axis?


MatLab example:

A = cat(3,{'a' 'b' 'c';'d' 'e' 'f';'g' 'h' 'i'},{'j' 'k' 'l';'m' 'n'
'o';'p' 'q' 'r'})

A(:,:,1) =

    'a'    'b'    'c'
    'd'    'e'    'f'
    'g'    'h'    'i'


A(:,:,2) =

    'j'    'k'    'l'
    'm'    'n'    'o'
    'p'    'q'    'r'

Rotate the cell array by 270 degrees.

B = rot90(A,3)

B(:,:,1) =

    'g'    'd'    'a'
    'h'    'e'    'b'
    'i'    'f'    'c'


B(:,:,2) =

    'p'    'm'    'j'
    'q'    'n'    'k'
    'r'    'o'    'l'


karim

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Feb  5 22:18:48 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Feb 2015 13:18:48 -0800
Subject: [R] How to download and unzip data in a loop
In-Reply-To: <CAHpsUFbTGKn66sb5E-q+Te+34pF8YE6eOMyN-M55BrM=YgMXOQ@mail.gmail.com>
References: <CAHpsUFbhAs4LvAADF=dKSgTmyavoHOet6w5AcQD0WQi9TZCxUA@mail.gmail.com>
	<CAAxdm-5ymnW=uaXFsQ-H5--GXFndS4tfa0EPVVJHhcCpKFvgJg@mail.gmail.com>
	<54D34FD2.7040804@jrc.ec.europa.eu>
	<CAHpsUFbTGKn66sb5E-q+Te+34pF8YE6eOMyN-M55BrM=YgMXOQ@mail.gmail.com>
Message-ID: <9AE15237-00B4-45E7-B895-13C214159A21@comcast.net>


On Feb 5, 2015, at 10:03 AM, Alexandra Catena wrote:

> Thank you guys for the response.
> 
> I'm trying to download the last ten years of meteorology data from a
> weather station in Livermore from the URL:
> ftp://ftp.ncdc.noaa.gov/pub/data/noaa/2015/724927-23285-2015.gz
> The Livermore station code is 724927-23285.  If I wanted to download data
> from 2005, the URL would be:
> ftp://ftp.ncdc.noaa.gov/pub/data/noaa/2005/724927-23285-2005.gz
> 
> Once I download the data into a temporary file, I want to unzip it and
> store it into another directory where I can access it.
> 
> Also, why are there 2015 indices instead of just 10 when I'm only looping
> through 2005:2015?

When you assign to file[2005], R fills in the positions from 1 to 2004 with NA's, and then adds to that vector with each further run through the loop.

The quotes around 'files' are preventing evaluation of your (very poorly named) 'files'-object.

The error I get after correcting those semantic errors is:

>   read.table(gzfile(files))
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  : 
  line 1 did not have 17 elements

... thus validating Jon's warning.


> 
> Thanks,
> Alexandra
> 
> On Thu, Feb 5, 2015 at 3:11 AM, Jon Skoien <jon.skoien at jrc.ec.europa.eu>
> wrote:
> 
>> In addition to following Jim's suggestion, you should probably also use
>> full.names = TRUE, otherwise you will try to open a connection to files in
>> your current directory, not in tmpdir.
>> Another thing is that the unzipped files appear irregular with respect to
>> columns, so read.table might not work too well.
>> 
>> Jon
>> 
>> 
>> On 2/5/2015 11:30 AM, jim holtman wrote:
>> 
>>> try taking the quotes off of 'files'
>>> 
>>> 
>>> Jim Holtman
>>> Data Munger Guru
>>> 
>>> What is the problem that you are trying to solve?
>>> Tell me what you want to do, not how you want to do it.
>>> 
>>> On Wed, Feb 4, 2015 at 5:24 PM, Alexandra Catena <amc5981 at gmail.com>
>>> wrote:
>>> 
>>> Hi All,
>>>> 
>>>> I need to loop through and download the past 10 years of met data to a
>>>> temporary directory.  I then need to unzip it and place it into another
>>>> directory.
>>>> 
>>>> 
>>>> year = (2005:2015)
>>>> 
>>>> for (i in year)
>>>>   tmpdir = tempdir()
>>>>   file[i] = file.path(tmpdir, sprintf('724927-23285-%4i.gz', i))
>>>>   url = sprintf('
>>>> ftp://ftp.ncdc.noaa.gov/pub/data/noaa/%4i/724927-23285-%4i.gz', i, i)
>>>>   #file = basename(url)
>>>>   download.file(url, file[i])
>>>>   files = dir(tmpdir, '*.gz', full.names=FALSE)
>>>>   read.table(gzfile('files'))
>>>> 
>>>> 
>>>> 
>>>> 'file' returns 2015 indices with "/tmp/RtmpKvB4Wz/724927-23285-2015.gz"
>>>> next to 2015. and files returns 724927-23285-2015.gz.  However, when I
>>>> try
>>>> to unzip the gz file using the last line, it says it cannot open the
>>>> connection and the probable reason is that there is no such file or
>>>> directory.
>>>> 
>>>> 
>>>> 
>>>> Thanks,
>>>> Alexandra
>>>> 
>>>>         [[alternative HTML version deleted]]
>>>> 
>>>> 


David Winsemius
Alameda, CA, USA


From Shanley.Chong at sswahs.nsw.gov.au  Thu Feb  5 22:35:09 2015
From: Shanley.Chong at sswahs.nsw.gov.au (Shanley Chong)
Date: Thu, 5 Feb 2015 21:35:09 +0000
Subject: [R] R2BayesX
In-Reply-To: <alpine.DEB.2.11.1502050958400.20281@paninaro.uibk.ac.at>
References: <90AD9DB98926A747B1C82FC2EE31E8A45BE55769@LIVSVEXMBX01.intra.swsahs.nsw.gov.au>
	<alpine.DEB.2.11.1502041018160.2229@paninaro.uibk.ac.at>
	<90AD9DB98926A747B1C82FC2EE31E8A45BE558D0@LIVSVEXMBX01.intra.swsahs.nsw.gov.au>
	<alpine.DEB.2.11.1502050958400.20281@paninaro.uibk.ac.at>
Message-ID: <90AD9DB98926A747B1C82FC2EE31E8A45BE56A50@LIVSVEXMBX01.intra.swsahs.nsw.gov.au>

Many thanks Z and Nikolaus! Much appreciated! Have a great weekend!
Kind regards,
Shanley

-----Original Message-----
From: Achim Zeileis [mailto:Achim.Zeileis at uibk.ac.at] 
Sent: Thursday, 5 February 2015 8:01 PM
To: Shanley Chong
Cc: r-help at r-project.org; Nikolaus.Umlauf at uibk.ac.at
Subject: Re: [R] R2BayesX

Shanley,

thanks for the example.

> Thank you for your help.
> Here is my R codes:
>
>> data("MunichBnd")
>
>> N <- length(MunichBnd); n <- N*5
>> dat <- data.frame(x1 = runif(n, -3, 3),id = 
>> as.factor(rep(names(MunichBnd), length.out = n))) dat$sp <- with(dat, 
>> sort(runif(N, -2, 2), decreasing = TRUE)[id]) dat$re_poi <- with(dat, 
>> rpois(N, 10)[id]) dat$y_poi <- with(dat, 1.5 + sin(x1) + sp + re_poi 
>> + rpois(n, 10)) b_poi <- bayesx(y_poi ~ sx(x1) +  sx(id, bs = "mrf", 
>> map = MunichBnd) + sx(id, bs = "re"), method = "MCMC", data = dat, 
>> family='poisson')
>
> Warning message:
> running command 
> '"C:/Users/ChongS/Documents/R/win-library/3.1/BayesXsrc/libs/x64/Bayes
> X.exe" 
> C:/Users/ChongS/AppData/Local/Temp/RtmpqMhw3Z/bayesx/bayesx.estim.inpu
> t.prg' had status 3
>
> If I run the model using family='gaussian', it doesn't have problem.
> b_poi <- bayesx(y_poi ~ sx(x1) +   sx(id, bs = "mrf", map = MunichBnd) +  sx(id, bs = "re"), method = "MCMC", data = dat, family='gaussian')

This appears to be a problem in BayesX for combination of bs="re", method="MCMC" and family="poisson". If at least one of these is changed, everything works. An even simpler example is:

set.seed(1)
d <- data.frame(y = rpois(1000, 5))
d$x <- rep(1:100, each = 10)

Then:

bayesx(y ~ sx(x, bs = "re"), data = d, method = "MCMC", family = "poisson") ## -> problem processing BayesX!

whereas

bayesx(y ~ sx(x),            data = d, method = "MCMC", family = "poisson")
bayesx(y ~ sx(x, bs = "re"), data = d, method = "REML", family = "poisson") bayesx(y ~ sx(x, bs = "re"), data = d, method = "MCMC", family = "gaussian")

are all ok. Niki has contacted the original BayesX authors who might be able to give more insight. For the moment, I would recommend to use method="REML".

Best,
Z

> Kind regards,
> Shanley
>
>
> -----Original Message-----
> From: Achim Zeileis [mailto:Achim.Zeileis at uibk.ac.at]
> Sent: Wednesday, 4 February 2015 8:20 PM
> To: Shanley Chong
> Cc: r-help at r-project.org; Nikolaus.Umlauf at uibk.ac.at
> Subject: Re: [R] R2BayesX
>
> Shanley:
>
>> I am trying to run STAR logistic/binomial model using R2BayesX . A 
>> warning message came up every time when i included a random effect, 
>> bs='re', (unstructured spatial effect) into the model. The warning 
>> message is : Warning message: running command 
>> '"C:/Users/ChongS/Documents/R/win-library/3.1/BayesXsrc/libs/x64/BayesX.exe"
>> C:/Users/ChongS/AppData/Local/Temp/RtmpCW8QY9/bayesx33/bayesx.estim.input.prg'
>> had status 5
>
> I haven't seen this problem before. Maybe you can provide "commented, minimal, self-contained, reproducible code" (as the posting guide asks)?
>
> I'm also cc'ing the package maintainer (Nikolaus Umlauf) as he might be able to give more insight.
>
> Best,
> Z
>
>> The model is fine when i just ran the model using mrf, bs='mrf', (structured spatial effect).
>>
>> And when i tried to run STAR using family=Gaussian (response is normally distributed) with structured and unstructured spatial effect, it is fine too.
>>
>> Can anyone please help?
>>
>> Regards,
>>
>> Shanley
>>
>>
>> _____________________________________________________________________
>> This email has been scanned for the Sydney & South Western Sydney Local Health Districts by the MessageLabs Email Security System.
>> Sydney & South Western Sydney Local Health Districts regularly monitor email and attachments to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> _____________________________________________________________________
> This email has been scanned for the Sydney & South Western Sydney Local Health Districts by the MessageLabs Email Security System.
> Sydney & South Western Sydney Local Health Districts regularly monitor email and attachments to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.
>
> _____________________________________________________________________
> This email has been scanned for the Sydney & South Western Sydney Local Health Districts by the MessageLabs Email Security System.
> Sydney & South Western Sydney Local Health Districts regularly monitor email and attachments to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

_____________________________________________________________________
This email has been scanned for the Sydney & South Western Sydney Local Health Districts by the MessageLabs Email Security System.
Sydney & South Western Sydney Local Health Districts regularly monitor email and attachments to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.

_____________________________________________________________________ 
This email has been scanned for the Sydney & South Western Sydney Local Health Districts by the MessageLabs Email Security System.
Sydney & South Western Sydney Local Health Districts regularly monitor email and attachments to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.


From jdnewmil at dcn.davis.CA.us  Thu Feb  5 23:00:43 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 05 Feb 2015 14:00:43 -0800
Subject: [R] =?utf-8?q?Rotate_array_by_90=C2=B0?=
In-Reply-To: <CALJKBv-vrmD9yekk0fHHYV4+0MwZ=Z8Pmr-BJhw0h8CgQzVSzg@mail.gmail.com>
References: <CALJKBv-vrmD9yekk0fHHYV4+0MwZ=Z8Pmr-BJhw0h8CgQzVSzg@mail.gmail.com>
Message-ID: <FDBC6919-A1B5-42AB-A603-9B35811765C3@dcn.davis.CA.us>

?aperm

aperm(A, c(2,1,3) )[,3:1,]

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 5, 2015 1:17:43 PM PST, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>Dear aal,
>
>Is there a way to rotate array or a cube of matrices by Y axis?
>
>
>MatLab example:
>
>A = cat(3,{'a' 'b' 'c';'d' 'e' 'f';'g' 'h' 'i'},{'j' 'k' 'l';'m' 'n'
>'o';'p' 'q' 'r'})
>
>A(:,:,1) =
>
>    'a'    'b'    'c'
>    'd'    'e'    'f'
>    'g'    'h'    'i'
>
>
>A(:,:,2) =
>
>    'j'    'k'    'l'
>    'm'    'n'    'o'
>    'p'    'q'    'r'
>
>Rotate the cell array by 270 degrees.
>
>B = rot90(A,3)
>
>B(:,:,1) =
>
>    'g'    'd'    'a'
>    'h'    'e'    'b'
>    'i'    'f'    'c'
>
>
>B(:,:,2) =
>
>    'p'    'm'    'j'
>    'q'    'n'    'k'
>    'r'    'o'    'l'
>
>
>karim
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Thu Feb  5 23:06:17 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 5 Feb 2015 16:06:17 -0600
Subject: [R] Fixed Width EBCDIC Files in R
In-Reply-To: <CAFYnejK5+8ww+zyJwgcu+0f8FiRYbfpqgWc3t62nmRnSsy4S+w@mail.gmail.com>
References: <CAFYnejK5+8ww+zyJwgcu+0f8FiRYbfpqgWc3t62nmRnSsy4S+w@mail.gmail.com>
Message-ID: <CAAJSdjggfqHdJOaYuKfRCoKiBSDZ7+50K=8j3g9OGYuEPgAxvg@mail.gmail.com>

On Thu, Feb 5, 2015 at 2:08 PM, Brian Trautman <btrautman84 at gmail.com>
wrote:

> I'm trying to read some mainframe data encoded as EBCDIC into R, and am at
> a loss. I'd like to avoid using an external program to convert the files,
> since I'm operating in a corporate environment.
>
> You can find the example files at at the link below, with both ASCII and
> EBCDIC versions. Note that there are no linebreaks in the EBCDIC versions
> of the file -- instead, I'd be specifying the width of each line manually.
> R has the IBM500 encoding available in my environment, which should be the
> correct one for these files.
>
> However, when I run the following commands, R seems to fail entirely.  It
> loads a single record with garbage characters, regardless of the encoding I
> specified.
>
>
> layout <- read.fwf("EBCDIC_LAYOUT", widths = c(80), fileEncoding='ibm500')
>
> data   <- read.fwf("EBCDIC_ZIPCODE", widths = c(32), fileEncoding='ibm500')
>
>
> Where might I go from here?
>
> Related -- some of the files I expect to use will be fairly large (1 GB or
> so). Preferably, I'd like a solution that scales reasonably well. (I tried
> packages like LaF, but they don't have the option to select encoding.)
>
> Thank you very much!
>
>
> Example files --
> https://drive.google.com/open?id=0ByvX1v-WqaaASTdwV2ZYS0pBV00&authuser=0
>
>
?
I gave this a short try. What killed me (see below) is that your file
EBCDIC_ZIPCODE has embedded NULL characters, \0. My transcript:

> file<-file("EBCDIC_ZIPCODE",encoding="IBM500", raw=TRUE);
> data=read.fwf(file,widths=c(32));
Warning messages:
1: In readLines(file, n = thisblock) :
  line 1 appears to contain an embedded nul
2: In readLines(file, n = thisblock) :
  incomplete final line found on 'EBCDIC_ZIPCODE'
> View(data)

I don't know how to get past the embedded NULL. I'm a UNIX user, so my
thought (not applicable with your restriction of "pure R"), would be to use
"tr" to convert the \0 to spaces, then use the above.?


-- 
He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Feb  5 23:12:17 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 05 Feb 2015 22:12:17 +0000
Subject: [R] =?iso-8859-1?q?Rotate_array_by_90=B0?=
In-Reply-To: <CALJKBv-vrmD9yekk0fHHYV4+0MwZ=Z8Pmr-BJhw0h8CgQzVSzg@mail.gmail.com>
References: <CALJKBv-vrmD9yekk0fHHYV4+0MwZ=Z8Pmr-BJhw0h8CgQzVSzg@mail.gmail.com>
Message-ID: <54D3EAC1.2000900@sapo.pt>

Hello,

Try the following.


rot90 <- function(x, n = 1){
	r90 <- function(x){
		y <- matrix(rep(NA, prod(dim(x))), nrow = nrow(x))
		for(i in seq_len(nrow(x))) y[, i] <- rev(x[i, ])
		y
	}
	for(i in seq_len(n)) x <- r90(x)
	x
}

mat <- matrix(letters[1:9], byrow = TRUE, nrow = 3)

rot90(mat)
rot90(mat, 3)


Hope this helps,

Rui Barradas

Em 05-02-2015 21:17, Karim Mezhoud escreveu:
> Dear aal,
>
> Is there a way to rotate array or a cube of matrices by Y axis?
>
>
> MatLab example:
>
> A = cat(3,{'a' 'b' 'c';'d' 'e' 'f';'g' 'h' 'i'},{'j' 'k' 'l';'m' 'n'
> 'o';'p' 'q' 'r'})
>
> A(:,:,1) =
>
>      'a'    'b'    'c'
>      'd'    'e'    'f'
>      'g'    'h'    'i'
>
>
> A(:,:,2) =
>
>      'j'    'k'    'l'
>      'm'    'n'    'o'
>      'p'    'q'    'r'
>
> Rotate the cell array by 270 degrees.
>
> B = rot90(A,3)
>
> B(:,:,1) =
>
>      'g'    'd'    'a'
>      'h'    'e'    'b'
>      'i'    'f'    'c'
>
>
> B(:,:,2) =
>
>      'p'    'm'    'j'
>      'q'    'n'    'k'
>      'r'    'o'    'l'
>
>
> karim
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kmezhoud at gmail.com  Thu Feb  5 23:14:56 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Thu, 5 Feb 2015 23:14:56 +0100
Subject: [R] =?utf-8?q?Rotate_array_by_90=C2=B0?=
In-Reply-To: <54D3EAC1.2000900@sapo.pt>
References: <CALJKBv-vrmD9yekk0fHHYV4+0MwZ=Z8Pmr-BJhw0h8CgQzVSzg@mail.gmail.com>
	<54D3EAC1.2000900@sapo.pt>
Message-ID: <CALJKBv9xREaLj-xHNzT6GRfRupvvm8Qc5-wgCrgty0cUnHnmwA@mail.gmail.com>

Thanks Jeff and Rui.




On Thu, Feb 5, 2015 at 11:12 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Try the following.
>
>
> rot90 <- function(x, n = 1){
>         r90 <- function(x){
>                 y <- matrix(rep(NA, prod(dim(x))), nrow = nrow(x))
>                 for(i in seq_len(nrow(x))) y[, i] <- rev(x[i, ])
>                 y
>         }
>         for(i in seq_len(n)) x <- r90(x)
>         x
> }
>
> mat <- matrix(letters[1:9], byrow = TRUE, nrow = 3)
>
> rot90(mat)
> rot90(mat, 3)
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 05-02-2015 21:17, Karim Mezhoud escreveu:
>
>> Dear aal,
>>
>> Is there a way to rotate array or a cube of matrices by Y axis?
>>
>>
>> MatLab example:
>>
>> A = cat(3,{'a' 'b' 'c';'d' 'e' 'f';'g' 'h' 'i'},{'j' 'k' 'l';'m' 'n'
>> 'o';'p' 'q' 'r'})
>>
>> A(:,:,1) =
>>
>>      'a'    'b'    'c'
>>      'd'    'e'    'f'
>>      'g'    'h'    'i'
>>
>>
>> A(:,:,2) =
>>
>>      'j'    'k'    'l'
>>      'm'    'n'    'o'
>>      'p'    'q'    'r'
>>
>> Rotate the cell array by 270 degrees.
>>
>> B = rot90(A,3)
>>
>> B(:,:,1) =
>>
>>      'g'    'd'    'a'
>>      'h'    'e'    'b'
>>      'i'    'f'    'c'
>>
>>
>> B(:,:,2) =
>>
>>      'p'    'm'    'j'
>>      'q'    'n'    'k'
>>      'r'    'o'    'l'
>>
>>
>> karim
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From btrautman84 at gmail.com  Thu Feb  5 23:45:33 2015
From: btrautman84 at gmail.com (Brian Trautman)
Date: Thu, 5 Feb 2015 14:45:33 -0800
Subject: [R] Fixed Width EBCDIC Files in R
In-Reply-To: <CAAJSdjggfqHdJOaYuKfRCoKiBSDZ7+50K=8j3g9OGYuEPgAxvg@mail.gmail.com>
References: <CAFYnejK5+8ww+zyJwgcu+0f8FiRYbfpqgWc3t62nmRnSsy4S+w@mail.gmail.com>
	<CAAJSdjggfqHdJOaYuKfRCoKiBSDZ7+50K=8j3g9OGYuEPgAxvg@mail.gmail.com>
Message-ID: <CAFYnejJ6uUVX=R6DhP1_HqpCi=jEmEFnVFwMTut5GxV4t_3EEQ@mail.gmail.com>

First off, thank you very much for taking a look at this.  I didn't know
"raw=TRUE" would be necessary here.

Unfortunately, I'm stuck with the embedded nulls in the source data at this
point.  If worst comes to worst, does R have a way to do something like --

1.  Read the entire file in as raw binary.
2.  Replace all embedded nulls with spaces.
3.  Output the revised file (as binary) somewhere else.

?

I imagine it'd take a big performance penalty, but at least then I proceed
with importing the revised file.

Thanks again!

On Thu, Feb 5, 2015 at 2:06 PM, John McKown <john.archie.mckown at gmail.com>
wrote:

> On Thu, Feb 5, 2015 at 2:08 PM, Brian Trautman <btrautman84 at gmail.com>
> wrote:
>
>> I'm trying to read some mainframe data encoded as EBCDIC into R, and am at
>> a loss. I'd like to avoid using an external program to convert the files,
>> since I'm operating in a corporate environment.
>>
>> You can find the example files at at the link below, with both ASCII and
>> EBCDIC versions. Note that there are no linebreaks in the EBCDIC versions
>> of the file -- instead, I'd be specifying the width of each line manually.
>> R has the IBM500 encoding available in my environment, which should be the
>> correct one for these files.
>>
>> However, when I run the following commands, R seems to fail entirely.  It
>> loads a single record with garbage characters, regardless of the encoding
>> I
>> specified.
>>
>>
>> layout <- read.fwf("EBCDIC_LAYOUT", widths = c(80), fileEncoding='ibm500')
>>
>> data   <- read.fwf("EBCDIC_ZIPCODE", widths = c(32),
>> fileEncoding='ibm500')
>>
>>
>> Where might I go from here?
>>
>> Related -- some of the files I expect to use will be fairly large (1 GB or
>> so). Preferably, I'd like a solution that scales reasonably well. (I tried
>> packages like LaF, but they don't have the option to select encoding.)
>>
>> Thank you very much!
>>
>>
>> Example files --
>> https://drive.google.com/open?id=0ByvX1v-WqaaASTdwV2ZYS0pBV00&authuser=0
>>
>>
> ?
> I gave this a short try. What killed me (see below) is that your file
> EBCDIC_ZIPCODE has embedded NULL characters, \0. My transcript:
>
> > file<-file("EBCDIC_ZIPCODE",encoding="IBM500", raw=TRUE);
> > data=read.fwf(file,widths=c(32));
> Warning messages:
> 1: In readLines(file, n = thisblock) :
>   line 1 appears to contain an embedded nul
> 2: In readLines(file, n = thisblock) :
>   incomplete final line found on 'EBCDIC_ZIPCODE'
> > View(data)
>
> I don't know how to get past the embedded NULL. I'm a UNIX user, so my
> thought (not applicable with your restriction of "pure R"), would be to use
> "tr" to convert the \0 to spaces, then use the above.?
>
>
> --
> He's about as useful as a wax frying pan.
>
> 10 to the 12th power microphones = 1 Megaphone
>
> Maranatha! <><
> John McKown
>

	[[alternative HTML version deleted]]


From js.huang at protective.com  Fri Feb  6 00:00:14 2015
From: js.huang at protective.com (JS Huang)
Date: Thu, 5 Feb 2015 15:00:14 -0800 (PST)
Subject: [R] =?utf-8?q?Rotate_array_by_90=C2=B0?=
In-Reply-To: <CALJKBv-vrmD9yekk0fHHYV4+0MwZ=Z8Pmr-BJhw0h8CgQzVSzg@mail.gmail.com>
References: <CALJKBv-vrmD9yekk0fHHYV4+0MwZ=Z8Pmr-BJhw0h8CgQzVSzg@mail.gmail.com>
Message-ID: <1423177214225-4702870.post@n4.nabble.com>

Hi,

  Here is an implementation.

> rot90
function(a,times=1)
{
  row <- dim(a)[1]
  col <- dim(a)[2]
  dep <- dim(a)[3]
  if (times %% 2 == 1){t <- row; row <- col; col <- t}
  tempA <- array(NA, c(row,col,dep))
  for (i in 1:dep)
  {
    temp <- a[,,i]
    for (j in 1:times)
    {
      temp <- cbind(sapply(1:row,function(x){rev(temp[x,])}))
    }
    tempA[,,i] <- temp
  }
  return(tempA)
}
> A
, , 1

     [,1] [,2] [,3]
[1,] "a"  "b"  "c" 
[2,] "d"  "e"  "f" 
[3,] "g"  "h"  "i" 

, , 2

     [,1] [,2] [,3]
[1,] "j"  "k"  "l" 
[2,] "m"  "n"  "o" 
[3,] "p"  "q"  "r" 

> rot90(A,3)
, , 1

     [,1] [,2] [,3]
[1,] "g"  "d"  "a" 
[2,] "h"  "e"  "b" 
[3,] "i"  "f"  "c" 

, , 2

     [,1] [,2] [,3]
[1,] "p"  "m"  "j" 
[2,] "q"  "n"  "k" 
[3,] "r"  "o"  "l" 




--
View this message in context: http://r.789695.n4.nabble.com/Rotate-array-by-90-tp4702862p4702870.html
Sent from the R help mailing list archive at Nabble.com.


From madhuri.vio at gmail.com  Thu Feb  5 23:36:48 2015
From: madhuri.vio at gmail.com (Madhuri Maddipatla)
Date: Thu, 5 Feb 2015 17:36:48 -0500
Subject: [R] Scraping HTML using R
Message-ID: <CA+whkv_kUt055EHG0xPNviWt+MLzK8xiZKAcUVzEOXi4BcwBPA@mail.gmail.com>

Dear R experts,

My requirement for web scraping in R goes like this.

*Step 1* - All the medical condition from from A-Z are listed in the link
below.

http://www.webmd.com/drugs/index-drugs.aspx?show=conditions

Choose the first condition say Acid Reflux(GERD-...)

*Step 2 *- It lands on the this page

http://www.webmd.com/drugs/condition-1999-Acid%20Reflux%20%20GERD-Gastroesophageal%20Reflux%20Disease%20.aspx?diseaseid=1999&diseasename=Acid+Reflux+(GERD-Gastroesophageal+Reflux+Disease)&source=3

with a list of drugs.

Choose the column user reviews of the first drug say "Nexium Oral"

*Step 3*: Now it lands on the webpage

http://www.webmd.com/drugs/drugreview-20536-Nexium+oral.aspx?drugid=20536&drugname=Nexium+oral

with a list of reviews.
I would like to scrape review information into a tabular format by scraping
the html.
For instance, i would like to fetch the full comment of each review as a
column in a table.
Also it should automatically go to next page and fetch the full comments of
all reviewers.


Please help me in this endeavor and thanks a lot in advance for reading my
mail and expecting response with your experience and expertise.

Also please suggest me the possibility around my stepwise plan and any
advice you would like to give me along with the solution.

High Regards,
*-----------------------------------------------------------------------------------------*
*Madhuri Maddipatla*
*-----------------------------------------------------------------------------------------*

	[[alternative HTML version deleted]]


From lianoglou.steve at gene.com  Fri Feb  6 00:26:00 2015
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Thu, 5 Feb 2015 15:26:00 -0800
Subject: [R] Scraping HTML using R
In-Reply-To: <CA+whkv_kUt055EHG0xPNviWt+MLzK8xiZKAcUVzEOXi4BcwBPA@mail.gmail.com>
References: <CA+whkv_kUt055EHG0xPNviWt+MLzK8xiZKAcUVzEOXi4BcwBPA@mail.gmail.com>
Message-ID: <CAHA9McN6_dQS5u86YOJGsT5nAwfOrfj-7edBiCp2Bf20i5mq0Q@mail.gmail.com>

You want to take a look at rvest:

https://github.com/hadley/rvest

On Thu, Feb 5, 2015 at 2:36 PM, Madhuri Maddipatla
<madhuri.vio at gmail.com> wrote:
> Dear R experts,
>
> My requirement for web scraping in R goes like this.
>
> *Step 1* - All the medical condition from from A-Z are listed in the link
> below.
>
> http://www.webmd.com/drugs/index-drugs.aspx?show=conditions
>
> Choose the first condition say Acid Reflux(GERD-...)
>
> *Step 2 *- It lands on the this page
>
> http://www.webmd.com/drugs/condition-1999-Acid%20Reflux%20%20GERD-Gastroesophageal%20Reflux%20Disease%20.aspx?diseaseid=1999&diseasename=Acid+Reflux+(GERD-Gastroesophageal+Reflux+Disease)&source=3
>
> with a list of drugs.
>
> Choose the column user reviews of the first drug say "Nexium Oral"
>
> *Step 3*: Now it lands on the webpage
>
> http://www.webmd.com/drugs/drugreview-20536-Nexium+oral.aspx?drugid=20536&drugname=Nexium+oral
>
> with a list of reviews.
> I would like to scrape review information into a tabular format by scraping
> the html.
> For instance, i would like to fetch the full comment of each review as a
> column in a table.
> Also it should automatically go to next page and fetch the full comments of
> all reviewers.
>
>
> Please help me in this endeavor and thanks a lot in advance for reading my
> mail and expecting response with your experience and expertise.
>
> Also please suggest me the possibility around my stepwise plan and any
> advice you would like to give me along with the solution.
>
> High Regards,
> *-----------------------------------------------------------------------------------------*
> *Madhuri Maddipatla*
> *-----------------------------------------------------------------------------------------*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Steve Lianoglou
Computational Biologist
Genentech


From chl948 at mail.usask.ca  Fri Feb  6 02:53:07 2015
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Thu, 05 Feb 2015 19:53:07 -0600
Subject: [R] =?windows-1252?q?Rotate_array_by_90=B0?=
In-Reply-To: <CALJKBv-vrmD9yekk0fHHYV4+0MwZ=Z8Pmr-BJhw0h8CgQzVSzg@mail.gmail.com>
References: <CALJKBv-vrmD9yekk0fHHYV4+0MwZ=Z8Pmr-BJhw0h8CgQzVSzg@mail.gmail.com>
Message-ID: <54D41E83.8060004@mail.usask.ca>

 > lapply(1:2, function(x) t(A[rev(1:3),,x]))
[[1]]
      [,1] [,2] [,3]
[1,] "g"  "d"  "a"
[2,] "h"  "e"  "b"
[3,] "i"  "f"  "c"

[[2]]
      [,1] [,2] [,3]
[1,] "p"  "m"  "j"
[2,] "q"  "n"  "k"
[3,] "r"  "o"  "l"

 >

Is this what you are looking for?  I hope this helps.

Chel Hee Lee

On 02/05/2015 03:17 PM, Karim Mezhoud wrote:
> Dear aal,
>
> Is there a way to rotate array or a cube of matrices by Y axis?
>
>
> MatLab example:
>
> A = cat(3,{'a' 'b' 'c';'d' 'e' 'f';'g' 'h' 'i'},{'j' 'k' 'l';'m' 'n'
> 'o';'p' 'q' 'r'})
>
> A(:,:,1) =
>
>      'a'    'b'    'c'
>      'd'    'e'    'f'
>      'g'    'h'    'i'
>
>
> A(:,:,2) =
>
>      'j'    'k'    'l'
>      'm'    'n'    'o'
>      'p'    'q'    'r'
>
> Rotate the cell array by 270 degrees.
>
> B = rot90(A,3)
>
> B(:,:,1) =
>
>      'g'    'd'    'a'
>      'h'    'e'    'b'
>      'i'    'f'    'c'
>
>
> B(:,:,2) =
>
>      'p'    'm'    'j'
>      'q'    'n'    'k'
>      'r'    'o'    'l'
>
>
> karim
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From zwang10 at mtu.edu  Fri Feb  6 03:58:50 2015
From: zwang10 at mtu.edu (Zhenchuan Wang)
Date: Thu, 5 Feb 2015 21:58:50 -0500
Subject: [R] Parallel Computing in R
Message-ID: <CANcdK1Z1WwtiTWcsfjBZGCirq7-s8Xx35-+A9meLUbWm5gNkqg@mail.gmail.com>

I usually need to compute P-values as following:
 1. generate one sample (usually it is a matrix)
 2. apply several methods (I already wrote a subfunction for each method,
and they are independent) to the generated sample to get pvalues.
 3. compare the pvalues.
Since each method mentioned above takes long time (always different length
of time) to compute the pvalue, I am try to computing the pvalues parallel.
I want to assign computation of each method to each cores (I have intel
i7). Do you have any suggestion? I put the four subfunctions together as

    main.fun=function(i,x,y,numper)
    {
    if (i==1) z=cca1(y,x,numper)
    if (i==2) z=2
    if (i==3) z=2
    if (i==4) z=3
    z
    }

Each i indicates ith subfunction.
But I always get

     task 1 failed - "Lapack routine dgesv: system is exactly singular:
U[84,84] = 0"

But when I only run `cca1` function (not using `foreach`), there is no
error.
The `foreach` is like this

    pvalue=foreach(i=1:4,.combine=c,.packages=c("MASS","base")) %dopar%
main.fun(i,x,y,500)

The single computation is like this

    pvalue=cca1(y,x,500)

I also put following in the top lines of my program

    library(foreach)
    library(doSNOW)
    library(MASS)
    cl=makeCluster(4,type="SOCK")
    registerDoSNOW(cl)

**This looks like when I compute the `pvalue` separately not using
`foreach`, there is no error. But when I combine the subfuntions togeter
like `main.fun`, it has error.**

	[[alternative HTML version deleted]]


From kridox at ymail.com  Fri Feb  6 06:51:30 2015
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 6 Feb 2015 14:51:30 +0900
Subject: [R] Parallel Computing in R
In-Reply-To: <CANcdK1Z1WwtiTWcsfjBZGCirq7-s8Xx35-+A9meLUbWm5gNkqg@mail.gmail.com>
References: <CANcdK1Z1WwtiTWcsfjBZGCirq7-s8Xx35-+A9meLUbWm5gNkqg@mail.gmail.com>
Message-ID: <CAAcyNCxvKXb1a=Lf4LCphbbKNSEbS61HcAtvOB+fnCwc36Ky=w@mail.gmail.com>

Hi,

You already asked this here
(http://stackoverflow.com/questions/28357210/parallel-computing-in-r)
and got some comments.

Regards,
Pascal

On Fri, Feb 6, 2015 at 11:58 AM, Zhenchuan Wang <zwang10 at mtu.edu> wrote:
> I usually need to compute P-values as following:
>  1. generate one sample (usually it is a matrix)
>  2. apply several methods (I already wrote a subfunction for each method,
> and they are independent) to the generated sample to get pvalues.
>  3. compare the pvalues.
> Since each method mentioned above takes long time (always different length
> of time) to compute the pvalue, I am try to computing the pvalues parallel.
> I want to assign computation of each method to each cores (I have intel
> i7). Do you have any suggestion? I put the four subfunctions together as
>
>     main.fun=function(i,x,y,numper)
>     {
>     if (i==1) z=cca1(y,x,numper)
>     if (i==2) z=2
>     if (i==3) z=2
>     if (i==4) z=3
>     z
>     }
>
> Each i indicates ith subfunction.
> But I always get
>
>      task 1 failed - "Lapack routine dgesv: system is exactly singular:
> U[84,84] = 0"
>
> But when I only run `cca1` function (not using `foreach`), there is no
> error.
> The `foreach` is like this
>
>     pvalue=foreach(i=1:4,.combine=c,.packages=c("MASS","base")) %dopar%
> main.fun(i,x,y,500)
>
> The single computation is like this
>
>     pvalue=cca1(y,x,500)
>
> I also put following in the top lines of my program
>
>     library(foreach)
>     library(doSNOW)
>     library(MASS)
>     cl=makeCluster(4,type="SOCK")
>     registerDoSNOW(cl)
>
> **This looks like when I compute the `pvalue` separately not using
> `foreach`, there is no error. But when I combine the subfuntions togeter
> like `main.fun`, it has error.**
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From aziz4 at illinois.edu  Fri Feb  6 07:30:07 2015
From: aziz4 at illinois.edu (Aziz, Muhammad Fayez)
Date: Fri, 6 Feb 2015 06:30:07 +0000
Subject: [R] symm parameter of heatmap
Message-ID: <8BB99D4AA51D4A4397817F165A7BD8DD6F0652B6@CHIMBX5.ad.uillinois.edu>

Hi,



What exactly is the difference between using symm=TRUE and symm=FALSE in a heatmap. More elaborately, when symm=FALSE, what does the heatmap plots because it seems like it changes the scale and makes it asymmetric, even if x is symmetric and square.



Additionally, is it possible to view the matrix that the heatmap plots? Here is a sample code I have been testing:



rm(list = ls())

g <- graph.full(5) %du% graph.full(5) %du% graph.full(5)
g <- add.edges(g, c(1,6, 1,11, 6, 11))

adjMatrix=get.adjacency(g, sparse=FALSE)

heatmap3(adjMatrix, Rowv = NA, Colv = NA, symm=FALSE)

windows()
heatmap3(adjMatrix, Rowv = NA, Colv = NA, symm=TRUE)



Thanks,

Fayez

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Feb  6 12:09:46 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 6 Feb 2015 11:09:46 +0000
Subject: [R] suggestion for optimal plotting to show significant differences
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F0E3@SRVEXCHMBX.precheza.cz>

Dear all

I would like to ask for your opinion about possible graphical representation of such data.

> dput(test)
structure(list(item = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A",
"B"), class = "factor"), day = c(0L, 100L, 200L, 300L, 400L,
500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L,
400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L), set = c(1L,
1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
3L, 3L, 3L), value = c(1.08163365169503, 2.61998412608805, 3.07820466606394,
4.44993419381934, 5.29163171545805, 6.29155990999293, -0.123163011367676,
2.07767236834003, 2.32537052874901, 3.09372794501084, 6.65273721166635,
5.92304962329131, 1.50504697705548, 2.66253728086866, 2.63420157418685,
2.78195098580416, 6.47578642973288, 5.89587443775143, 0.848864231485078,
1.27549677119713, 2.19573089053609, 2.45659926134292, 5.15424403414103,
5.4813151140983, 1.25731482647214, 2.09662105167973, 1.75954023316977,
4.81624002288939, 4.65029189325307, 6.39946904227214, 0.944996929887344,
1.74667265331284, 2.42956264345558, 5.17852980415141, 3.5453435965834,
6.9011238437191)), .Names = c("item", "day", "set", "value"), row.names = c(NA,
-36L), class = "data.frame")
>

One option I came with is

library(ggplot2)
p<-ggplot(test, aes(x=day, y=value, colour=item))
p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))

but -
I have more items (around 5-10), and I want to show if the difference between items is or is not significant. The actual development of value with day is usually not linear nor growing steadily and actually I cannot usually evaluate some analytical equation for my data to compare equation parameters.

I thought about boxplots, but there is not many repetitions and actually 5+ boxplots can be quite messy.

I can plot only mean for each set and item but in that case I lose information if the difference is or is not significant.

I appreciate any suggestion.

Best regards
Petr








________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ivan.calandra at univ-reims.fr  Fri Feb  6 12:20:03 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Fri, 06 Feb 2015 12:20:03 +0100
Subject: [R] save structure to be accesible later
In-Reply-To: <582093984.429553.1423210391375.JavaMail.yahoo@mail.yahoo.com>
References: <54D372F7.8030108@univ-reims.fr>
	<582093984.429553.1423210391375.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <54D4A363.7000805@univ-reims.fr>

Hi,

I  think that putting all your objects into one single list would be 
easier, both to handle it and to save it.
To do it, you can create an empty list with 1000 elements before running 
your function and then run your function in a loop (or something 
similar) with the output of each run being saved in one element of the 
big list.

Something like this:
big.list <- vector(mode="list", length=1000)
for (i in 1:1000){
     big.list[[i]] <- your.function(...)
}

I also like to name the elements of my list, especially when the 
structure gets complicated.

And then you just need to save big.list either with save() or with 
R.utils::saveOjbect().

HTH,
Ivan

PS: answer to the list as well, so you have better chance to get better 
answers.

--
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 06/02/15 09:13, Alaios a ?crit :
> Thanks for the answer.Then I guess that your recommendation is to save 
> each of these structures independently and then load those files one 
> by one. I thought it would be easier to build a big list (I am not 
> sure still how to do that) that contains the 1000 results of my 
> function (with their respective sublists) and save that one once at my 
> file.
> What do you think of this option?
>
> Regards
> Alex
>
>
> On Thursday, February 5, 2015 2:43 PM, Ivan Calandra 
> <ivan.calandra at univ-reims.fr> wrote:
>
>
> Hi,
>
> I generally prefer using the functions saveObject() and loadObject()
> from the R.utils package. I like that you load directly to an object in
> the R workspace.
>
> HTH,
> Ivan
>
> --
> Ivan Calandra, ATER
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr <mailto:ivan.calandra at univ-reims.fr>
> https://www.researchgate.net/profile/Ivan_Calandra
>
> Le 05/02/15 14:07, Olivier Crouzet a ?crit :
> > Hi, have a look at save() and load().
> >
> > You can save part of your workspace to a file (save()) and load it 
> from this file (load()). Of course the file format is R specific (but 
> its specifications are free) You may easily share the file with other 
> R users.
> >
> > Olivier.
> >
> > --
> > Olivier Crouzet
> > LLING - Laboratoire de Linguistique de Nantes - EA3827
> > Universit? de Nantes
> >
> > -----Original Message-----
> > From: Alaios via R-help <r-help at r-project.org 
> <mailto:r-help at r-project.org>>
> > Sender: "R-help" <r-help-bounces at r-project.org 
> <mailto:r-help-bounces at r-project.org>>Date: Thu, 5 Feb 2015 12:57:42
> > To: R-help Mailing List<r-help at r-project.org 
> <mailto:r-help at r-project.org>>
> > Reply-To: Alaios <alaios at yahoo.com <mailto:alaios at yahoo.com>>
> > Subject: [R] save structure to be accesible later
> >
> > Dear all,I have a function that returns the following list. At the 
> end I will call my function 1000 times and I want to keep for each of 
> these 1000 "results" (the structure as given below)in an order to be 
> accessible later (Load the 1000 results and access them within a for 
> loop for example)
> > How should I approach the issue?I would like to thank you for your 
> exampleRegardsAlex
> > P,S The result of my function
> >
> >
> >
> >  str(fitcass1)
> > List of 10
> >  $ parameters  :'data.frame':  2 obs. of  3 variables:
> >    ..$ pi  : num [1:2] 0.833 0.167
> >    ..$ mu  : num [1:2] 8828 110000
> >    ..$ sigma: num [1:2] 18085 1543
> >  $ se          :'data.frame':  2 obs. of  3 variables:
> >    ..$ pi.se  : num [1:2] NA NA
> >    ..$ mu.se  : num [1:2] NA NA
> >    ..$ sigma.se: num [1:2] NA NA
> >  $ distribution: chr "gamma"
> >  $ constraint  :List of 8
> >    ..$ conpi  : chr "NONE"
> >    ..$ conmu  : chr "NONE"
> >    ..$ consigma: chr "NONE"
> >    ..$ fixpi  : NULL
> >    ..$ fixmu  : NULL
> >    ..$ fixsigma: NULL
> >    ..$ cov    : NULL
> >    ..$ size    : NULL
> >  $ chisq      : num 52.4
> >  $ df          : num 5
> >  $ P          : num 4.57e-10
> >  $ vmat        : num [1:5, 1:5] NA NA NA NA NA NA NA NA NA NA ...
> >  $ mixdata    :Classes ?mixdata? and 'data.frame':   11 obs. of  2 
> variables:
> >    ..$ X    : num [1:11] 1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 
> 8e+04 9e+04 1e+05 ...
> >    ..$ count: int [1:11] 993 137 82 30 21 5 7 14 21 2 ...
> >  $ usecondit  : logi FALSE
> >  - attr(*, "class")= chr "mix"
> >
> >
> >
> >     [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- 
> To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
>
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- 
> To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>


From N.Hubner at ncmls.ru.nl  Fri Feb  6 16:13:07 2015
From: N.Hubner at ncmls.ru.nl (N.Hubner at ncmls.ru.nl)
Date: Fri, 6 Feb 2015 15:13:07 +0000
Subject: [R] color heatmap according to value ranges
Message-ID: <5FF7898BAD1B4A4A809F4C519026348496093A58@UMCEXMBX11.umcn.nl>

Probably the simplest thing there is, but I can't get it to work:



Example for my data:



a <- c(1,1,1,2,2,2,3,3,3)

b <- c(1,2,3,1,2,3,1,2,3)

c <- c(1,2,3,4,5,6,7,8,9)

df <- data.frame(cbind(a,b,c))



I create a heat map with c being the values:



ggplot(df, aes(df$a, df$b, fill = df$c)) + geom_raster()



problem:

The color coding is automatically a gradient. However, I would like to color in 4 fixed colors dependent on the value in c. For example:



if c<=2 color "darkblue"

if 2<c<=3 color "blue"

if 3<c<=5 color "lightblue"

if c>5 color "white"



In addition I would like to show a legend that illustrates this color coding.



It must be very easy, but I just can't figure it out. Only find commands that make gradients...



Thanks a lot in advance!




______________________________________________

Dr. Nina C. Hubner
scientist quantitative proteomics

Department of Molecular Biology, Radboud University Nijmegen, The Netherlands
e-mail: n.hubner at ncmls.ru.nl
tel: +31-24-3613655

Visiting address:
Department of Molecular Biology, RIMLS, 2nd floor
Geert Grooteplein 26/28
6525 GA Nijmegen
The Netherlands



The Radboud University Medical Centre is listed in the Commercial Register of the Chamber of Commerce under file number 41055629.

	[[alternative HTML version deleted]]


From m.farah at sc.qa  Fri Feb  6 08:42:13 2015
From: m.farah at sc.qa (Mohamed Farah)
Date: Fri, 6 Feb 2015 07:42:13 +0000
Subject: [R] Interpreting a Logit regression result
Message-ID: <4F65A8DF04F22E4EAFF668100818188BA4E127F6@Q2022MPMB01.qatar2022.local>

I have run a logit regression with two categorical variables (with 0 and 1)  as the values. i.e. payment (1) / non-payment(0) on profit (profitable =1, non-profitable=0) on 375 entities. Here is the result from R:



> divgress <-glm(Div~PRFD, family=binomial(link="logit"), data=divs)
> summary(divgress)

Call:
glm(formula = Div ~ PRFD, family = binomial(link = "logit"),
    data = divs)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-1.6765  -0.2626   0.7502   0.7502   2.6017

Coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -3.3499     0.7194  -4.656 3.22e-06 ***
PRFD          4.4738     0.7311   6.119 9.41e-10 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 491.84  on 376  degrees of freedom
Residual deviance: 371.78  on 375  degrees of freedom
AIC: 375.78

Number of Fisher Scoring iterations: 6



My question is that the coefficient of the independent variable (log-odds) at 4.4738  is difficult to interpret. I have obtained the exponent of the coefficient below and as the result of 87.69..   shown below shows, the number is high which makes suspicious that there is something not working right.



> exp(coef(divgress))
(Intercept)        PRFD
 0.03508772 87.69230769
>



The dataset is attached. I appreciate your help.




This email communication is confidential and may be privileged or otherwise protected. It is intended exclusively for those individuals and entities addressed above and any other persons who have been specifically authorised to receive it. You should not copy it or disclose its contents to anyone. If you are not such an intended recipient, please notify us that you have received this email in error. Please then delete the email and any attachments and destroy any copies of it. We regret any inconvenience resulting from erroneous delivery of this message and thank you for your cooperation.
Please note that none of the Supreme Committee for Delivery and Legacy or any of its affiliated entities will have any liability for any incorrect or incomplete transmission of the information contained in this email nor for any delay in its receipt. Emails are not secure and cannot be guaranteed to be error free. Anyone who communicates with us by email is taken to accept these risks. Any views or opinions expressed in this email are solely those of the author and do not necessarily represent those of the Supreme Committee for Delivery and Legacy or any of its affiliated entities. Any logo trademark or other intellectual property forming part of or attached to this email belongs exclusively to the Supreme Committee for Delivery and Legacy. Any unauthorised reproduction copying or other use by you or others is strictly prohibited.

From laomeng_3 at 163.com  Fri Feb  6 12:46:59 2015
From: laomeng_3 at 163.com (meng)
Date: Fri, 6 Feb 2015 19:46:59 +0800 (CST)
Subject: [R] how to draw paired mosaic plot?
Message-ID: <320b5c11.1b0c.14b5eb6e405.Coremail.laomeng_3@163.com>

Hi all:
If there are two numeric variable:x,y, and I can get paired scatter plot by function "pairs".But if x and y are character, and I want to get paired mosaic plot,which function should be used then?


Many thanks!
My best.






--
QQ: 1733768559


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Feb  6 16:52:34 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 06 Feb 2015 10:52:34 -0500
Subject: [R] how to draw paired mosaic plot?
In-Reply-To: <320b5c11.1b0c.14b5eb6e405.Coremail.laomeng_3@163.com>
References: <320b5c11.1b0c.14b5eb6e405.Coremail.laomeng_3@163.com>
Message-ID: <54D4E342.5080606@gmail.com>

On 06/02/2015 6:46 AM, meng wrote:
> Hi all:
> If there are two numeric variable:x,y, and I can get paired scatter plot by function "pairs".But if x and y are character, and I want to get paired mosaic plot,which function should be used then?

Why not pairs, with a custom panel function?  There are examples on the 
help page, though I don't think a mosaic plot is there.

Duncan Murdoch
>
>
> Many thanks!
> My best.
>
>
>
>
>
>
> --
> QQ: 1733768559
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From info at aghmed.fsnet.co.uk  Fri Feb  6 16:58:11 2015
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Fri, 06 Feb 2015 15:58:11 +0000
Subject: [R] Interpreting a Logit regression result
In-Reply-To: <4F65A8DF04F22E4EAFF668100818188BA4E127F6@Q2022MPMB01.qatar2022.local>
References: <4F65A8DF04F22E4EAFF668100818188BA4E127F6@Q2022MPMB01.qatar2022.local>
Message-ID: <54D4E493.9030104@aghmed.fsnet.co.uk>

Dear Mohamed

Your dataset did not make it through, the list strips most attachments.

In my area of application I would be suspicious that such an odds ratio 
was the result of a data error or my misunderstanding of the underlying 
science. You are probably in the best position to judge both of these in 
your area.

Michael


On 06/02/2015 07:42, Mohamed Farah wrote:
> I have run a logit regression with two categorical variables (with 0 and 1)  as the values. i.e. payment (1) / non-payment(0) on profit (profitable =1, non-profitable=0) on 375 entities. Here is the result from R:
>
>
>
>> divgress <-glm(Div~PRFD, family=binomial(link="logit"), data=divs)
>> summary(divgress)
>
> Call:
> glm(formula = Div ~ PRFD, family = binomial(link = "logit"),
>      data = divs)
>
> Deviance Residuals:
>      Min       1Q   Median       3Q      Max
> -1.6765  -0.2626   0.7502   0.7502   2.6017
>
> Coefficients:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -3.3499     0.7194  -4.656 3.22e-06 ***
> PRFD          4.4738     0.7311   6.119 9.41e-10 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> (Dispersion parameter for binomial family taken to be 1)
>
>      Null deviance: 491.84  on 376  degrees of freedom
> Residual deviance: 371.78  on 375  degrees of freedom
> AIC: 375.78
>
> Number of Fisher Scoring iterations: 6
>
>
>
> My question is that the coefficient of the independent variable (log-odds) at 4.4738  is difficult to interpret. I have obtained the exponent of the coefficient below and as the result of 87.69..   shown below shows, the number is high which makes suspicious that there is something not working right.
>
>
>
>> exp(coef(divgress))
> (Intercept)        PRFD
>   0.03508772 87.69230769
>>
>
>
>
> The dataset is attached. I appreciate your help.
>
>
>
>
> This email communication is confidential and may be privileged or otherwise protected. It is intended exclusively for those individuals and entities addressed above and any other persons who have been specifically authorised to receive it. You should not copy it or disclose its contents to anyone. If you are not such an intended recipient, please notify us that you have received this email in error. Please then delete the email and any attachments and destroy any copies of it. We regret any inconvenience resulting from erroneous delivery of this message and thank you for your cooperation.
> Please note that none of the Supreme Committee for Delivery and Legacy or any of its affiliated entities will have any liability for any incorrect or incomplete transmission of the information contained in this email nor for any delay in its receipt. Emails are not secure and cannot be guaranteed to be error free. Anyone who communicates with us by email is taken to accept these risks. Any views or opinions expressed in this email are solely those of the author and do not necessarily represent those of the Supreme Committee for Delivery and Legacy or any of its affiliated entities. Any logo trademark or other intellectual property forming part of or attached to this email belongs exclusively to the Supreme Committee for Delivery and Legacy. Any unauthorised reproduction copying or other use by you or others is strictly prohibited.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5645 / Virus Database: 4281/9067 - Release Date: 02/06/15
>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From pdalgd at gmail.com  Fri Feb  6 17:35:54 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 6 Feb 2015 17:35:54 +0100
Subject: [R] Interpreting a Logit regression result
In-Reply-To: <54D4E493.9030104@aghmed.fsnet.co.uk>
References: <4F65A8DF04F22E4EAFF668100818188BA4E127F6@Q2022MPMB01.qatar2022.local>
	<54D4E493.9030104@aghmed.fsnet.co.uk>
Message-ID: <EBD40660-3A9B-46EF-B01F-1B5A010BE6E1@gmail.com>


On 06 Feb 2015, at 16:58 , Michael Dewey <info at aghmed.fsnet.co.uk> wrote:

> Dear Mohamed
> 
> Your dataset did not make it through, the list strips most attachments.
> 
> In my area of application I would be suspicious that such an odds ratio was the result of a data error or my misunderstanding of the underlying science. You are probably in the best position to judge both of these in your area.
> 

If both variables are binary, a table would be informative:

with(divs, table(Div, PRFD))

The output is roughly consistent with odds 1:30 if PRFD==0 and 3:1 if PRFD==1.  That sounds extreme, but not entirely implausible, depending on field of application.


> Michael
> 
> 
> On 06/02/2015 07:42, Mohamed Farah wrote:
>> I have run a logit regression with two categorical variables (with 0 and 1)  as the values. i.e. payment (1) / non-payment(0) on profit (profitable =1, non-profitable=0) on 375 entities. Here is the result from R:
>> 
>> 
>> 
>>> divgress <-glm(Div~PRFD, family=binomial(link="logit"), data=divs)
>>> summary(divgress)
>> 
>> Call:
>> glm(formula = Div ~ PRFD, family = binomial(link = "logit"),
>>     data = divs)
>> 
>> Deviance Residuals:
>>     Min       1Q   Median       3Q      Max
>> -1.6765  -0.2626   0.7502   0.7502   2.6017
>> 
>> Coefficients:
>>             Estimate Std. Error z value Pr(>|z|)
>> (Intercept)  -3.3499     0.7194  -4.656 3.22e-06 ***
>> PRFD          4.4738     0.7311   6.119 9.41e-10 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> 
>> (Dispersion parameter for binomial family taken to be 1)
>> 
>>     Null deviance: 491.84  on 376  degrees of freedom
>> Residual deviance: 371.78  on 375  degrees of freedom
>> AIC: 375.78
>> 
>> Number of Fisher Scoring iterations: 6
>> 
>> 
>> 
>> My question is that the coefficient of the independent variable (log-odds) at 4.4738  is difficult to interpret. I have obtained the exponent of the coefficient below and as the result of 87.69..   shown below shows, the number is high which makes suspicious that there is something not working right.
>> 
>> 
>> 
>>> exp(coef(divgress))
>> (Intercept)        PRFD
>>  0.03508772 87.69230769
>>> 
>> 
>> 
>> 
>> The dataset is attached. I appreciate your help.
>> 
>> 
>> 
>> 
>> This email communication is confidential and may be privileged or otherwise protected. It is intended exclusively for those individuals and entities addressed above and any other persons who have been specifically authorised to receive it. You should not copy it or disclose its contents to anyone. If you are not such an intended recipient, please notify us that you have received this email in error. Please then delete the email and any attachments and destroy any copies of it. We regret any inconvenience resulting from erroneous delivery of this message and thank you for your cooperation.
>> Please note that none of the Supreme Committee for Delivery and Legacy or any of its affiliated entities will have any liability for any incorrect or incomplete transmission of the information contained in this email nor for any delay in its receipt. Emails are not secure and cannot be guaranteed to be error free. Anyone who communicates with us by email is taken to accept these risks. Any views or opinions expressed in this email are solely those of the author and do not necessarily represent those of the Supreme Committee for Delivery and Legacy or any of its affiliated entities. Any logo trademark or other intellectual property forming part of or attached to this email belongs exclusively to the Supreme Committee for Delivery and Legacy. Any unauthorised reproduction copying or other use by you or others is strictly prohibited.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> -----
>> No virus found in this message.
>> Checked by AVG - www.avg.com
>> Version: 2015.0.5645 / Virus Database: 4281/9067 - Release Date: 02/06/15
>> 
>> 
>> 
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From rmh at temple.edu  Fri Feb  6 18:14:08 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 6 Feb 2015 12:14:08 -0500
Subject: [R] suggestion for optimal plotting to show significant
	differences
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F0E3@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F0E3@SRVEXCHMBX.precheza.cz>
Message-ID: <CAGx1TMCq1jXtuyofWv5nYC2So0RyKDp_734ze6rAQXztaxccnw@mail.gmail.com>

I would try one of these illustrations for starts.
interaction2wt (two-way tables) is designed to be used with aov() for testing.
interaction2wt shows all main effects and all two-way interactions for
many factors.



test <-
structure(list(item = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A",
"B"), class = "factor"), day = c(0L, 100L, 200L, 300L, 400L,
500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L,
400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L), set = c(1L,
1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
3L, 3L, 3L), value = c(1.08163365169503, 2.61998412608805, 3.07820466606394,
4.44993419381934, 5.29163171545805, 6.29155990999293, -0.123163011367676,
2.07767236834003, 2.32537052874901, 3.09372794501084, 6.65273721166635,
5.92304962329131, 1.50504697705548, 2.66253728086866, 2.63420157418685,
2.78195098580416, 6.47578642973288, 5.89587443775143, 0.848864231485078,
1.27549677119713, 2.19573089053609, 2.45659926134292, 5.15424403414103,
5.4813151140983, 1.25731482647214, 2.09662105167973, 1.75954023316977,
4.81624002288939, 4.65029189325307, 6.39946904227214, 0.944996929887344,
1.74667265331284, 2.42956264345558, 5.17852980415141, 3.5453435965834,
6.9011238437191)), .Names = c("item", "day", "set", "value"), row.names = c(NA,
-36L), class = "data.frame")



library(HH)

test$set <- factor(test$set)
test$day <- factor(test$day)
test$item <- factor(test$item)

interaction2wt(value ~ item * day * set, data=test)

test$item.day <- interaction(test$item, test$day)
position(test$item.day) <- outer(c(-10,10), as.numeric(levels(test$day)), `+`)

xyplot(value ~ as.position(item.day) | set, groups=item,
        data=test, horizontal=FALSE, pch=c(17,16),
        xlab="day",
        scales=list(
          x=list(
            alternating=1,
            at=levels(test$day), ## placement of tick labels and marks
            tck=1)),
        key=list(
          text=list(c("A","B"), col=c("blue","red")),
          points=list(pch=c(17, 16), col=c("blue","red")),
       space="top", columns=2, border=TRUE),
       layout=c(3,1))


## see also the examples in
demo(package="HH", bwplot.examples)

On Fri, Feb 6, 2015 at 6:09 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Dear all
>
> I would like to ask for your opinion about possible graphical representation of such data.
>
>> dput(test)
> structure(list(item = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A",
> "B"), class = "factor"), day = c(0L, 100L, 200L, 300L, 400L,
> 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L,
> 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
> 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L), set = c(1L,
> 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
> 3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> 3L, 3L, 3L), value = c(1.08163365169503, 2.61998412608805, 3.07820466606394,
> 4.44993419381934, 5.29163171545805, 6.29155990999293, -0.123163011367676,
> 2.07767236834003, 2.32537052874901, 3.09372794501084, 6.65273721166635,
> 5.92304962329131, 1.50504697705548, 2.66253728086866, 2.63420157418685,
> 2.78195098580416, 6.47578642973288, 5.89587443775143, 0.848864231485078,
> 1.27549677119713, 2.19573089053609, 2.45659926134292, 5.15424403414103,
> 5.4813151140983, 1.25731482647214, 2.09662105167973, 1.75954023316977,
> 4.81624002288939, 4.65029189325307, 6.39946904227214, 0.944996929887344,
> 1.74667265331284, 2.42956264345558, 5.17852980415141, 3.5453435965834,
> 6.9011238437191)), .Names = c("item", "day", "set", "value"), row.names = c(NA,
> -36L), class = "data.frame")
>>
>
> One option I came with is
>
> library(ggplot2)
> p<-ggplot(test, aes(x=day, y=value, colour=item))
> p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))
>
> but -
> I have more items (around 5-10), and I want to show if the difference between items is or is not significant. The actual development of value with day is usually not linear nor growing steadily and actually I cannot usually evaluate some analytical equation for my data to compare equation parameters.
>
> I thought about boxplots, but there is not many repetitions and actually 5+ boxplots can be quite messy.
>
> I can plot only mean for each set and item but in that case I lose information if the difference is or is not significant.
>
> I appreciate any suggestion.
>
> Best regards
> Petr
>
>
>
>
>
>
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From djmuser at gmail.com  Fri Feb  6 18:42:10 2015
From: djmuser at gmail.com (Dennis Murphy)
Date: Fri, 6 Feb 2015 09:42:10 -0800
Subject: [R] color heatmap according to value ranges
In-Reply-To: <5FF7898BAD1B4A4A809F4C519026348496093A58@UMCEXMBX11.umcn.nl>
References: <5FF7898BAD1B4A4A809F4C519026348496093A58@UMCEXMBX11.umcn.nl>
Message-ID: <CADv2QyF=SngE6gTtUN8_8hWumGfho0woow=i+MB-NpDOCpkQEA@mail.gmail.com>

Hi:

You get a gradient for your response variable because it is numeric.
You need to convert it to factor. (Discrete color sets need to be
mapped to discrete variables - a factor is one way to generate a
discrete variable.)  Here is one approach to get what you appear to be
looking for.

DF <- data.frame(a = rep(1:3, each = 3),
                 b = 1:3, d = 1:9)
DF$e <- cut(DF$d, c(0, 2, 3, 5, 10), rightmost = TRUE,
             labels = c("1-2", "2-3", "3-5", ">5"))

library(ggplot2)
ggplot(DF, aes(x = a, y = b, fill = e)) +
   geom_tile() +
   scale_fill_manual(values = c("darkblue", "blue", "lightblue", "white"))

You need a border of some kind around the plot since the right side of
the graph is the same color as the default background. If you're OK
with the default graph above, that's fine. If you want to expand it to
the edges, you need to draw your own border, something like

ggplot(DF, aes(x = a, y = b, fill = e)) +
   geom_tile() +
   scale_fill_manual(values = c("darkblue", "blue", "lightblue", "white")) +
  # eliminate the padding from each scale
   scale_x_continuous(expand = c(0, 0)) +
   scale_y_continuous(expand = c(0, 0)) +
 # draw the border
   theme(panel.border = element_rect(colour = "black", fill = NA))

The problem that remains is an inability to distinguish the legend key
color in the last category from the plot background. The simplest
workaround is to change the color of the last category in the scale
specification - one suggestion is a light gray, but you can always
substitute another color:

ggplot(DF, aes(x = a, y = b, fill = e)) +
   geom_tile() +
   scale_fill_manual(values = c("darkblue", "blue", "lightblue", "grey90")) +
   scale_x_continuous(expand = c(0, 0)) +
   scale_y_continuous(expand = c(0, 0)) +
   theme(panel.border = element_rect(colour = "black", fill = NA))

Dennis

On Fri, Feb 6, 2015 at 7:13 AM,  <N.Hubner at ncmls.ru.nl> wrote:
> Probably the simplest thing there is, but I can't get it to work:
>
>
>
> Example for my data:
>
>
>
> a <- c(1,1,1,2,2,2,3,3,3)
>
> b <- c(1,2,3,1,2,3,1,2,3)
>
> c <- c(1,2,3,4,5,6,7,8,9)
>
> df <- data.frame(cbind(a,b,c))
>
>
>
> I create a heat map with c being the values:
>
>
>
> ggplot(df, aes(df$a, df$b, fill = df$c)) + geom_raster()
>
>
>
> problem:
>
> The color coding is automatically a gradient. However, I would like to color in 4 fixed colors dependent on the value in c. For example:
>
>
>
> if c<=2 color "darkblue"
>
> if 2<c<=3 color "blue"
>
> if 3<c<=5 color "lightblue"
>
> if c>5 color "white"
>
>
>
> In addition I would like to show a legend that illustrates this color coding.
>
>
>
> It must be very easy, but I just can't figure it out. Only find commands that make gradients...
>
>
>
> Thanks a lot in advance!
>
>
>
>
> ______________________________________________
>
> Dr. Nina C. Hubner
> scientist quantitative proteomics
>
> Department of Molecular Biology, Radboud University Nijmegen, The Netherlands
> e-mail: n.hubner at ncmls.ru.nl
> tel: +31-24-3613655
>
> Visiting address:
> Department of Molecular Biology, RIMLS, 2nd floor
> Geert Grooteplein 26/28
> 6525 GA Nijmegen
> The Netherlands
>
>
>
> The Radboud University Medical Centre is listed in the Commercial Register of the Chamber of Commerce under file number 41055629.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hasan.diwan at gmail.com  Fri Feb  6 20:01:16 2015
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Fri, 6 Feb 2015 11:01:16 -0800
Subject: [R] how to draw paired mosaic plot?
In-Reply-To: <320b5c11.1b0c.14b5eb6e405.Coremail.laomeng_3@163.com>
References: <320b5c11.1b0c.14b5eb6e405.Coremail.laomeng_3@163.com>
Message-ID: <CAP+bYWD_+w7CB2RR04aTRehypbP6ws5YYwUR1+8d_z3obS+VLw@mail.gmail.com>

The stats package has a mosaicplot function. Perhaps that would help? -- H

On 6 February 2015 at 03:46, meng <laomeng_3 at 163.com> wrote:

> Hi all:
> If there are two numeric variable:x,y, and I can get paired scatter plot
> by function "pairs".But if x and y are character, and I want to get paired
> mosaic plot,which function should be used then?
>
>
> Many thanks!
> My best.
>
>
>
>
>
>
> --
> QQ: 1733768559
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
OpenPGP: https://hasan.d8u.us/gpg.key
Sent from my mobile device
Envoy? de mon portable

	[[alternative HTML version deleted]]


From aebingham2 at gmail.com  Fri Feb  6 20:51:01 2015
From: aebingham2 at gmail.com (Allen Bingham)
Date: Fri, 6 Feb 2015 11:51:01 -0800
Subject: [R] censored quantile regression
In-Reply-To: <31D7F80A-95EF-4B17-B28D-161912150E53@mcgill.ca>
References: <31D7F80A-95EF-4B17-B28D-161912150E53@mcgill.ca>
Message-ID: <00c601d04246$3ca8e530$b5faaf90$@gmail.com>

Ashley,

Looking at the code for the crq function it appears that with method="Portnoy" the tau value is not passed to the fitting function (crq.fit.por) and that function appears (I didn't delve into the code to make sure of this ...) to calculate the grid of tau values given the nature of the data, formula, etc. ---

--- more telling though is the following snippet I copied from the documentation of the crq function, specifically it states (in part) [I've split apart the pertinent section first]:

   "... Both the Portnoy and Peng-Huang estimators may be unable to compute estimates of 
    the conditional quantile parameters in the upper tail of distribution.


   ... Like the Kaplan-Meier estimator, when censoring is heavy in the upper tail the 
   estimated distribution is defective and quantiles are only estimable on a sub-interval 
   of (0,1). The Peng and Huang estimator can be viewed as a generalization of the Nelson 
   Aalen estimator of the cumulative hazard function, and can be formulated as a variant 
   of the conventional quantile regression dual problem. See Koenker (2008) for further
   details. This paper is available from the package with vignette("crq"). ...  "

... so I'm guessing that using one of the other fitting methods may be get you what you need --- HOWEVER I'm only looking at the underlying code and documentation for same --- I'm completely ignorant of the statistical methods you are trying to implement --- and whether or not one of the other fitting methods is appropriate to your analyses.

Regardless it seems to me (IMHO) that the documentation for the crq function should indicate that the "tau" or alternatively the "taus" supplied to the crq function are only used with a subset of the method values.

Hope this helps-Allen
______________________________________
Allen Bingham
Bingham Statistical Consulting
aebingham2 at gmail.com

This message and any attachments may contain confidential or privileged information and are only for the use of the intended recipient of this message. If you are not the intended recipient, please notify the sender by return email, and delete or destroy this and all copies of this message and all attachments. Any unauthorized disclosure, use, distribution, or reproduction of this message or any attachments without permission from the sender is prohibited and may be unlawful.





-----Original Message-----
From: Ashley Isaac Naimi, Mr [mailto:ashley.naimi at mcgill.ca] 
Sent: Tuesday, January 20, 2015 7:52 AM
To: r-help at r-project.org
Subject: [R] censored quantile regression

Hi there,

I've generated the following data:

library(quantreg)
library(survival)

set.seed(789)
N <- 2000
u <- runif(N)
x1 <- rbinom(N,1,.5)
x2 <- rbinom(N,1,.5)
x1x2<-x1*x2
lambda <- 1 + 1.5*x1 + 1.5*x2 + .5*x1x2
k <- 2
y <- lambda*((-log(1-u))^(1/k));max(y)
c <- runif(N,max=15)
event = as.numeric(y<=c)
mean(event);table(event)
cens <- 1-event
table(cens);mean(cens)
time <-as.matrix(ifelse(event==1,y,c))

St<-Surv(time,event,type="right")

To which I've fit the following censored quantile regression model:

q2 <- crq(St~x1 + x2 + x1x2,tau=.9,method="Portnoy")
summary(q2)

As one can see, I'm interested in the 0.9th quantile. But summary(q2) returns only the 20th to 80th percentiles (by 20). How can I get only the 0.9th quantile (aka the 90th percentile)?? All I actually need is the parameter estimate for the interaction (x1x2) for the 90th percentile. I know how to extract it if I were able to obtain estimates at tau=0.9, but no luck. Even though I request the 90th percentile in crq (i.e., "tau=0.9"), the summary function keeps returning the same set of (unwanted) percentiles (20th, 40th, 60th, 80th).

I?m using R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet?, Platform: x86_64-apple-darwin13.4.0 (64-bit).

Cheers,

Ashley I Naimi

	[[alternative HTML version deleted]]


From m.farah at sc.qa  Fri Feb  6 18:02:48 2015
From: m.farah at sc.qa (Mohamed Farah)
Date: Fri, 6 Feb 2015 17:02:48 +0000
Subject: [R] Interpreting a Logit regression result
In-Reply-To: <54D4E493.9030104@aghmed.fsnet.co.uk>
References: <4F65A8DF04F22E4EAFF668100818188BA4E127F6@Q2022MPMB01.qatar2022.local>,
	<54D4E493.9030104@aghmed.fsnet.co.uk>
Message-ID: <4F65A8DF04F22E4EAFF668100818188BA4E128D0@Q2022MPMB01.qatar2022.local>

Dear Michael,

Thank you for your comment. My difficulty is concerned with the high coefficient of the independent variable. The result I get fro running a logit regression is:
ylog e^x= -3.3499+ X4.4738. Changing the numbers to exponents of e (antilog) to better interpret the results, I get  y = 0.035087863 + 87.68931008 x.

Mohamed

________________________________________
From: Michael Dewey [info at aghmed.fsnet.co.uk]
Sent: Friday, February 06, 2015 6:58 PM
To: Mohamed Farah; r-help at r-project.org
Subject: Re: [R] Interpreting a Logit regression result

Dear Mohamed

Your dataset did not make it through, the list strips most attachments.

In my area of application I would be suspicious that such an odds ratio
was the result of a data error or my misunderstanding of the underlying
science. You are probably in the best position to judge both of these in
your area.

Michael


On 06/02/2015 07:42, Mohamed Farah wrote:
> I have run a logit regression with two categorical variables (with 0 and 1)  as the values. i.e. payment (1) / non-payment(0) on profit (profitable =1, non-profitable=0) on 375 entities. Here is the result from R:
>
>
>
>> divgress <-glm(Div~PRFD, family=binomial(link="logit"), data=divs)
>> summary(divgress)
>
> Call:
> glm(formula = Div ~ PRFD, family = binomial(link = "logit"),
>      data = divs)
>
> Deviance Residuals:
>      Min       1Q   Median       3Q      Max
> -1.6765  -0.2626   0.7502   0.7502   2.6017
>
> Coefficients:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -3.3499     0.7194  -4.656 3.22e-06 ***
> PRFD          4.4738     0.7311   6.119 9.41e-10 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> (Dispersion parameter for binomial family taken to be 1)
>
>      Null deviance: 491.84  on 376  degrees of freedom
> Residual deviance: 371.78  on 375  degrees of freedom
> AIC: 375.78
>
> Number of Fisher Scoring iterations: 6
>
>
>
> My question is that the coefficient of the independent variable (log-odds) at 4.4738  is difficult to interpret. I have obtained the exponent of the coefficient below and as the result of 87.69..   shown below shows, the number is high which makes suspicious that there is something not working right.
>
>
>
>> exp(coef(divgress))
> (Intercept)        PRFD
>   0.03508772 87.69230769
>>
>
>
>
> The dataset is attached. I appreciate your help.
>
>
>
>
> This email communication is confidential and may be privileged or otherwise protected. It is intended exclusively for those individuals and entities addressed above and any other persons who have been specifically authorised to receive it. You should not copy it or disclose its contents to anyone. If you are not such an intended recipient, please notify us that you have received this email in error. Please then delete the email and any attachments and destroy any copies of it. We regret any inconvenience resulting from erroneous delivery of this message and thank you for your cooperation.
> Please note that none of the Supreme Committee for Delivery and Legacy or any of its affiliated entities will have any liability for any incorrect or incomplete transmission of the information contained in this email nor for any delay in its receipt. Emails are not secure and cannot be guaranteed to be error free. Anyone who communicates with us by email is taken to accept these risks. Any views or opinions expressed in this email are solely those of the author and do not necessarily represent those of the Supreme Committee for Delivery and Legacy or any of its affiliated entities. Any logo trademark or other intellectual property forming part of or attached to this email belongs exclusively to the Supreme Committee for Delivery and Legacy. Any unauthorised reproduction copying or other use by you or others is strictly prohibited.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5645 / Virus Database: 4281/9067 - Release Date: 02/06/15
>
>
>

--
Michael
http://www.dewey.myzen.co.uk

This email communication is confidential and may be privileged or otherwise protected. It is intended exclusively for those individuals and entities addressed above and any other persons who have been specifically authorised to receive it. You should not copy it or disclose its contents to anyone. If you are not such an intended recipient, please notify us that you have received this email in error. Please then delete the email and any attachments and destroy any copies of it. We regret any inconvenience resulting from erroneous delivery of this message and thank you for your cooperation.
Please note that none of the Supreme Committee for Delivery and Legacy or any of its affiliated entities will have any liability for any incorrect or incomplete transmission of the information contained in this email nor for any delay in its receipt. Emails are not secure and cannot be guaranteed to be error free. Anyone who communicates with us by email is taken to accept these risks. Any views or opinions expressed in this email are solely those of the author and do not necessarily represent those of the Supreme Committee for Delivery and Legacy or any of its affiliated entities. Any logo trademark or other intellectual property forming part of or attached to this email belongs exclusively to the Supreme Committee for Delivery and Legacy. Any unauthorised reproduction copying or other use by you or others is strictly prohibited.


From m.farah at sc.qa  Fri Feb  6 18:25:26 2015
From: m.farah at sc.qa (Mohamed Farah)
Date: Fri, 6 Feb 2015 17:25:26 +0000
Subject: [R] Interpreting a Logit regression result
In-Reply-To: <EBD40660-3A9B-46EF-B01F-1B5A010BE6E1@gmail.com>
References: <4F65A8DF04F22E4EAFF668100818188BA4E127F6@Q2022MPMB01.qatar2022.local>
	<54D4E493.9030104@aghmed.fsnet.co.uk>,
	<EBD40660-3A9B-46EF-B01F-1B5A010BE6E1@gmail.com>
Message-ID: <4F65A8DF04F22E4EAFF668100818188BA4E128EE@Q2022MPMB01.qatar2022.local>

Peter,

Appreciate the comment. Here is a summary table. Both variables (Profit and dividend with 0=yes & 1=no) are binary as pointed out. I have out of 368 companies of which 342 were profitable and 26 unprofitable. Of the 342, 79 paid no dividends and 263 paid dividends. Of the 26, 25 paid no dividends and 1 paid dividends. The result is 104 dividend payers and 264 payers.





              DIV

Profit
                   0                1   Grand Total

0       25      1       26
1       79      263     342
Grand Total     104     264     368




________________________________________
From: peter dalgaard [pdalgd at gmail.com]
Sent: Friday, February 06, 2015 7:35 PM
To: Michael Dewey
Cc: Mohamed Farah; r-help at r-project.org
Subject: Re: [R] Interpreting a Logit regression result

On 06 Feb 2015, at 16:58 , Michael Dewey <info at aghmed.fsnet.co.uk> wrote:

> Dear Mohamed
>
> Your dataset did not make it through, the list strips most attachments.
>
> In my area of application I would be suspicious that such an odds ratio was the result of a data error or my misunderstanding of the underlying science. You are probably in the best position to judge both of these in your area.
>

If both variables are binary, a table would be informative:

with(divs, table(Div, PRFD))

The output is roughly consistent with odds 1:30 if PRFD==0 and 3:1 if PRFD==1.  That sounds extreme, but not entirely implausible, depending on field of application.


> Michael
>
>
> On 06/02/2015 07:42, Mohamed Farah wrote:
>> I have run a logit regression with two categorical variables (with 0 and 1)  as the values. i.e. payment (1) / non-payment(0) on profit (profitable =1, non-profitable=0) on 375 entities. Here is the result from R:
>>
>>
>>
>>> divgress <-glm(Div~PRFD, family=binomial(link="logit"), data=divs)
>>> summary(divgress)
>>
>> Call:
>> glm(formula = Div ~ PRFD, family = binomial(link = "logit"),
>>     data = divs)
>>
>> Deviance Residuals:
>>     Min       1Q   Median       3Q      Max
>> -1.6765  -0.2626   0.7502   0.7502   2.6017
>>
>> Coefficients:
>>             Estimate Std. Error z value Pr(>|z|)
>> (Intercept)  -3.3499     0.7194  -4.656 3.22e-06 ***
>> PRFD          4.4738     0.7311   6.119 9.41e-10 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> (Dispersion parameter for binomial family taken to be 1)
>>
>>     Null deviance: 491.84  on 376  degrees of freedom
>> Residual deviance: 371.78  on 375  degrees of freedom
>> AIC: 375.78
>>
>> Number of Fisher Scoring iterations: 6
>>
>>
>>
>> My question is that the coefficient of the independent variable (log-odds) at 4.4738  is difficult to interpret. I have obtained the exponent of the coefficient below and as the result of 87.69..   shown below shows, the number is high which makes suspicious that there is something not working right.
>>
>>
>>
>>> exp(coef(divgress))
>> (Intercept)        PRFD
>>  0.03508772 87.69230769
>>>
>>
>>
>>
>> The dataset is attached. I appreciate your help.
>>
>>
>>
>>
>> This email communication is confidential and may be privileged or otherwise protected. It is intended exclusively for those individuals and entities addressed above and any other persons who have been specifically authorised to receive it. You should not copy it or disclose its contents to anyone. If you are not such an intended recipient, please notify us that you have received this email in error. Please then delete the email and any attachments and destroy any copies of it. We regret any inconvenience resulting from erroneous delivery of this message and thank you for your cooperation.
>> Please note that none of the Supreme Committee for Delivery and Legacy or any of its affiliated entities will have any liability for any incorrect or incomplete transmission of the information contained in this email nor for any delay in its receipt. Emails are not secure and cannot be guaranteed to be error free. Anyone who communicates with us by email is taken to accept these risks. Any views or opinions expressed in this email are solely those of the author and do not necessarily represent those of the Supreme Committee for Delivery and Legacy or any of its affiliated entities. Any logo trademark or other intellectual property forming part of or attached to this email belongs exclusively to the Supreme Committee for Delivery and Legacy. Any unauthorised reproduction copying or other use by you or others is strictly prohibited.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> -----
>> No virus found in this message.
>> Checked by AVG - www.avg.com
>> Version: 2015.0.5645 / Virus Database: 4281/9067 - Release Date: 02/06/15
>>
>>
>>
>
> --
> Michael
> http://www.dewey.myzen.co.uk
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


This email communication is confidential and may be privileged or otherwise protected. It is intended exclusively for those individuals and entities addressed above and any other persons who have been specifically authorised to receive it. You should not copy it or disclose its contents to anyone. If you are not such an intended recipient, please notify us that you have received this email in error. Please then delete the email and any attachments and destroy any copies of it. We regret any inconvenience resulting from erroneous delivery of this message and thank you for your cooperation.
Please note that none of the Supreme Committee for Delivery and Legacy or any of its affiliated entities will have any liability for any incorrect or incomplete transmission of the information contained in this email nor for any delay in its receipt. Emails are not secure and cannot be guaranteed to be error free. Anyone who communicates with us by email is taken to accept these risks. Any views or opinions expressed in this email are solely those of the author and do not necessarily represent those of the Supreme Committee for Delivery and Legacy or any of its affiliated entities. Any logo trademark or other intellectual property forming part of or attached to this email belongs exclusively to the Supreme Committee for Delivery and Legacy. Any unauthorised reproduction copying or other use by you or others is strictly prohibited.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Feb  6 22:42:57 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 6 Feb 2015 22:42:57 +0100
Subject: [R] Interpreting a Logit regression result
In-Reply-To: <4F65A8DF04F22E4EAFF668100818188BA4E128EE@Q2022MPMB01.qatar2022.local>
References: <4F65A8DF04F22E4EAFF668100818188BA4E127F6@Q2022MPMB01.qatar2022.local>
	<54D4E493.9030104@aghmed.fsnet.co.uk> <,
	<EBD40660-3A9B-46EF-B01F-1B5A010BE6E1@gmail.com> <>>
	<4F65A8DF04F22E4EAFF668100818188BA4E128EE@Q2022MPMB01.qatar2022.local>
Message-ID: <04D40258-3F11-4323-AACC-C43E542F7856@gmail.com>


> On 06 Feb 2015, at 18:25 , Mohamed Farah <m.farah at sc.qa> wrote:
> 
> Peter,
> 
> Appreciate the comment. Here is a summary table. Both variables (Profit and dividend with 0=yes & 1=no) are binary as pointed out. I have out of 368 companies of which 342 were profitable and 26 unprofitable. Of the 342, 79 paid no dividends and 263 paid dividends. Of the 26, 25 paid no dividends and 1 paid dividends. The result is 104 dividend payers and 264 payers.
>  
>  
>               DIV
> Profit
>            0	            1	Grand Total
> 0	25	1	26
> 1	79	263	342
> Grand Total	104	264	368

This doesn't quite fit with the 376 df for the null deviance in your glm(). However, the OR for that table is 25*263/(79*1) = 83.23, which isn't far off.

However, something is strange. Your glm() output had odds for one group at 0.03508772, but

> 1/29
[1] 0.03448276
> 1/28
[1] 0.03571429

However 

> 2/57
[1] 0.03508772

and the odds for the other group should be 

> .03508772*87.69230769
[1] 3.076923

which is pretty much exactly 40/13

> 40/13
[1] 3.076923

Now, to fit the 376 null df, I'd expect 377 obs total. That fits if the other group is actually 240:78, so that the entire table is

 57   2
 78 240

And, lo and behold:

> x <- rep(0:1, c(59,318))
> y <- rep(c(0,1,0,1),c(57,2,78,240))
> summary(glm(y~x, binomial))

Call:
glm(formula = y ~ x, family = binomial)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.6765  -0.2626   0.7502   0.7502   2.6017  

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -3.3499     0.7194  -4.656 3.22e-06 ***
x             4.4738     0.7311   6.119 9.41e-10 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 491.84  on 376  degrees of freedom
Residual deviance: 371.78  on 375  degrees of freedom
AIC: 375.78





-pd

> 
> 
> 
> 
> ________________________________________
> From: peter dalgaard [pdalgd at gmail.com]
> Sent: Friday, February 06, 2015 7:35 PM
> To: Michael Dewey
> Cc: Mohamed Farah; r-help at r-project.org
> Subject: Re: [R] Interpreting a Logit regression result
> 
> On 06 Feb 2015, at 16:58 , Michael Dewey <info at aghmed.fsnet.co.uk> wrote:
> 
> > Dear Mohamed
> >
> > Your dataset did not make it through, the list strips most attachments.
> >
> > In my area of application I would be suspicious that such an odds ratio was the result of a data error or my misunderstanding of the underlying science. You are probably in the best position to judge both of these in your area.
> >
> 
> If both variables are binary, a table would be informative:
> 
> with(divs, table(Div, PRFD))
> 
> The output is roughly consistent with odds 1:30 if PRFD==0 and 3:1 if PRFD==1.  That sounds extreme, but not entirely implausible, depending on field of application.
> 
> 
> > Michael
> >
> >
> > On 06/02/2015 07:42, Mohamed Farah wrote:
> >> I have run a logit regression with two categorical variables (with 0 and 1)  as the values. i.e. payment (1) / non-payment(0) on profit (profitable =1, non-profitable=0) on 375 entities. Here is the result from R:
> >>
> >>
> >>
> >>> divgress <-glm(Div~PRFD, family=binomial(link="logit"), data=divs)
> >>> summary(divgress)
> >>
> >> Call:
> >> glm(formula = Div ~ PRFD, family = binomial(link = "logit"),
> >>     data = divs)
> >>
> >> Deviance Residuals:
> >>     Min       1Q   Median       3Q      Max
> >> -1.6765  -0.2626   0.7502   0.7502   2.6017
> >>
> >> Coefficients:
> >>             Estimate Std. Error z value Pr(>|z|)
> >> (Intercept)  -3.3499     0.7194  -4.656 3.22e-06 ***
> >> PRFD          4.4738     0.7311   6.119 9.41e-10 ***
> >> ---
> >> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>
> >> (Dispersion parameter for binomial family taken to be 1)
> >>
> >>     Null deviance: 491.84  on 376  degrees of freedom
> >> Residual deviance: 371.78  on 375  degrees of freedom
> >> AIC: 375.78
> >>
> >> Number of Fisher Scoring iterations: 6
> >>
> >>
> >>
> >> My question is that the coefficient of the independent variable (log-odds) at 4.4738  is difficult to interpret. I have obtained the exponent of the coefficient below and as the result of 87.69..   shown below shows, the number is high which makes suspicious that there is something not working right.
> >>
> >>
> >>
> >>> exp(coef(divgress))
> >> (Intercept)        PRFD
> >>  0.03508772 87.69230769
> >>>
> >>
> >>
> >>
> >> The dataset is attached. I appreciate your help.
> >>
> >>
> >>
> >>
> >> This email communication is confidential and may be privileged or otherwise protected. It is intended exclusively for those individuals and entities addressed above and any other persons who have been specifically authorised to receive it. You should not copy it or disclose its contents to anyone. If you are not such an intended recipient, please notify us that you have received this email in error. Please then delete the email and any attachments and destroy any copies of it. We regret any inconvenience resulting from erroneous delivery of this message and thank you for your cooperation.
> >> Please note that none of the Supreme Committee for Delivery and Legacy or any of its affiliated entities will have any liability for any incorrect or incomplete transmission of the information contained in this email nor for any delay in its receipt. Emails are not secure and cannot be guaranteed to be error free. Anyone who communicates with us by email is taken to accept these risks. Any views or opinions expressed in this email are solely those of the author and do not necessarily represent those of the Supreme Committee for Delivery and Legacy or any of its affiliated entities. Any logo trademark or other intellectual property forming part of or attached to this email belongs exclusively to the Supreme Committee for Delivery and Legacy. Any unauthorised reproduction copying or other use by you or others is strictly prohibited.
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >> -----
> >> No virus found in this message.
> >> Checked by AVG - www.avg.com
> >> Version: 2015.0.5645 / Virus Database: 4281/9067 - Release Date: 02/06/15
> >>
> >>
> >>
> >
> > --
> > Michael
> > http://www.dewey.myzen.co.uk
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> This email communication is confidential and may be privileged or otherwise protected. It is intended exclusively for those individuals and entities addressed above and any other persons who have been specifically authorised to receive it. You should not copy it or disclose its contents to anyone. If you are not such an intended recipient, please notify us that you have received this email in error. Please then delete the email and any attachments and destroy any copies of it. We regret any inconvenience resulting from erroneous delivery of this message and thank you for your cooperation.
> Please note that none of the Supreme Committee for Delivery and Legacy or any of its affiliated entities will have any liability for any incorrect or incomplete transmission of the information contained in this email nor for any delay in its receipt. Emails are not secure and cannot be guaranteed to be error free. Anyone who communicates with us by email is taken to accept these risks. Any views or opinions expressed in this email are solely those of the author and do not necessarily represent those of the Supreme Committee for Delivery and Legacy or any of its affiliated entities. Any logo trademark or other intellectual property forming part of or attached to this email belongs exclusively to the Supreme Committee for Delivery and Legacy. Any unauthorised reproduction copying or other use by you or others is strictly prohibited. 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From friendly at yorku.ca  Fri Feb  6 22:47:10 2015
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 06 Feb 2015 16:47:10 -0500
Subject: [R] poor man's scree plot for SVD: multiline labels and total lines
Message-ID: <54D5365E.8080609@yorku.ca>

In the ca package, the summary method gives the following output, as a 
"poor man's scree plot",
showing eigenvalues, their percents, and a character-based scree plot:

# install.packages("ca")
haireye <- margin.table(HairEyeColor, 1:2)
library(ca)
haireye.ca <- ca(haireye)

summary(haireye.ca, rows=FALSE, columns=FALSE)

Principal inertias (eigenvalues):

  dim    value      %   cum%   scree plot
  1      0.208773  89.4  89.4  **********************
  2      0.022227   9.5  98.9  **
  3      0.002598   1.1 100.0
         -------- -----
  Total: 0.233598 100.0

I'd like to enhance this, to something like the following, using 
multiline column labels and also showing the totals,
but the code in ca::print.summary.ca is too obtuse to try to reuse or 
modify.

Singular values and Principal inertias (eigenvalues)

   Singular  Principal  Percents   Cum  Scree plot
   values    inertias

1 0.456916  0.208773     89.4    89.4 ******************************
2 0.149086  0.022227      9.5    98.9 ***
3 0.050975  0.002598      1.1   100.0
             --------     ----
             0.233598    100.0

I made a start, defining a scree.ca function, and an associated print 
method, but I can't figure out how to
print multiline labels and the totals for relevant columns.  Can someone 
help?

Here are my functions:

scree.ca <- function (obj, scree.width=30) {
     values <- obj$sv
     inertia <- values^2
     pct <- 100*inertia/sum(inertia)
     scree <- character(length(pct))
     stars <- round(scree.width * pct / max(pct), 0)
     for (q in 1:length(pct)) {
       s1 <- paste(rep("*", stars[q]), collapse = "")
       s2 <- paste(rep(" ", scree.width - stars[q]), collapse = "")
       scree[q] <- paste(" ", s1, s2, sep = "")
       }
     dat <- data.frame(values, inertia, pct=round(pct,1), 
Cum=round(cumsum(pct),1), scree, stringsAsFactors=FALSE)
     heading <- "Singular values and Principal inertias (eigenvalues)"
     attr(dat,"heading") <- heading
     attr(dat$values, "label") <- "Singular\nvalues"
     attr(dat$inertia, "label") <- "Principal\ninertias"
     attr(dat$pct, "label") <- "Percents"
     class(dat) <- c("scree.ca", "data.frame")
     dat
}

print.scree.ca <- function(x, digits=5, ...) {
   if (!is.null(heading <- attr(x, "heading")))
     {cat(heading, sep = "\n"); cat("\n")}
     print.data.frame(x, digits=digits, ...)
}

And, a test use:

 > sc <- scree.ca(haireye.ca)
 > str(sc)
Classes ?scree.ca? and 'data.frame':    3 obs. of  5 variables:
  $ values : atomic  0.457 0.149 0.051
   ..- attr(*, "label")= chr "Singular\nvalues"
  $ inertia: atomic  0.2088 0.0222 0.0026
   ..- attr(*, "label")= chr "Principal\ninertias"
  $ pct    : atomic  89.4 9.5 1.1
   ..- attr(*, "label")= chr "Percents"
  $ Cum    : num  89.4 98.9 100
  $ scree  : chr  " ******************************" " 
***                           " "                               "
  - attr(*, "heading")= chr "Singular values and Principal inertias 
(eigenvalues)"
 > sc
Singular values and Principal inertias (eigenvalues)

     values   inertia  pct   Cum                           scree
1 0.456916 0.2087727 89.4  89.4  ******************************
2 0.149086 0.0222266  9.5  98.9  ***
3 0.050975 0.0025984  1.1 100.0
 >


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From js.huang at protective.com  Fri Feb  6 22:56:01 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 6 Feb 2015 13:56:01 -0800 (PST)
Subject: [R] Coverage probability for a Poisson parameter
In-Reply-To: <1423258104797-4702906.post@n4.nabble.com>
References: <1422648135557-4702535.post@n4.nabble.com>
	<1422650922280-4702537.post@n4.nabble.com>
	<1422659760512-4702546.post@n4.nabble.com>
	<1422665613143-4702551.post@n4.nabble.com>
	<1423224280484-4702883.post@n4.nabble.com>
	<1423258104797-4702906.post@n4.nabble.com>
Message-ID: <1423259761894-4702909.post@n4.nabble.com>

Hi,

  After some thought, I found the treatment of sample mean equal 0 was not
appropriate.  I modified the function likelihood.ratio.test.Poisson. 
resulting.matrix now has 0.0512 as the average of type I error.

function(lambda, sample.size, significance.level)
{
  reject <- 0
  sample.mean <- mean(rpois(sample.size, lambda))
  if (sample.mean == 0)
  {
    test.statistics <- 2 * sample.size * lambda
  }
  else
  {
    test.statistics <- 2 * sample.size * (lambda - sample.mean + sample.mean
* log(sample.mean / lambda))
  }
  if (test.statistics >= qchisq(1 - significance.level, 1)) {reject <- 1}
else {reject <- 0}
  return(reject)
} 
> for (i in 1:500){
+   resulting.matrix[i,1] <- 0.01 * i
+   resulting.matrix[i,2] <- mean(sapply(1:100,function(x)
likelihood.ratio.test.Poisson(0.01*i,10,0.05)))  
+ }
> mean(resulting.matrix[,2])
[1] 0.05102



--
View this message in context: http://r.789695.n4.nabble.com/Coverage-probability-for-a-Poisson-parameter-tp4702535p4702909.html
Sent from the R help mailing list archive at Nabble.com.


From paulhtremblay at gmail.com  Fri Feb  6 23:37:56 2015
From: paulhtremblay at gmail.com (Paul Tremblay)
Date: Fri, 6 Feb 2015 14:37:56 -0800
Subject: [R] Create a heat map with German postal codes
Message-ID: <CAP5QEc5a1cieS-=wAP4Or5x7rYrpsJ6Q8C+-fEpc+Mff7oR5qQ@mail.gmail.com>

Hi,

I am tasked with making a map of German postal codes for a few major cities
in Germany. Each postal code will have a differnt color, depending on a
metric. For simplicity, let's just use population density.

This is what I have achieved so far for London (which I used as an
example). I have been able to create a base map using the tutorials. I was
able to import a shapefile of postal codes and display that on the map. I
was able to create points on the map.

What I am not able to do is color in each postal code according to density.
The other problem I have is with actually creating a map that zooms in on
the right area. I know you can limit the area with xlim and ylim, but I
can't figure out sensible values for eacy of these parameters.

I have not found a shapefile yet for German postal codes.

Last, should I use worldmaps, or a more recent package such as ggmap or
rworldmap? I have seen that worldmaps is very outdated.

We have commercial software such as Tableau and Map Point (since
discontinued) floating around here. Both of these software automatically
map districts for US and London postal codes. However, I would like to use
an open source solution if for no other reason than these commercial
software might not work for other regions, and R seems better to extend for
special cases.

Thanks!

Paul

	[[alternative HTML version deleted]]


From js.huang at protective.com  Sat Feb  7 00:43:26 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 6 Feb 2015 15:43:26 -0800 (PST)
Subject: [R] Plotting dataset
In-Reply-To: <1423244497898-4702896.post@n4.nabble.com>
References: <1423244497898-4702896.post@n4.nabble.com>
Message-ID: <1423266206295-4702912.post@n4.nabble.com>

Hi,

  Here is my implementation.  Modify the data as follows so that it can be
read with read.table and save as "rHelp_20151206.txt" under working
directory.

female male vowel language 
391 339 i W.Apache 
561 512 e W.Apache 
826 670 a W.Apache 
453 427 o W.Apache 
358 291 i CA.English 
454 406 e CA.English 
991 706 a CA.English 
561 439 o CA.English 
398 324 u CA.English 
334 307 i Ndumbea 
444 361 e Ndumbea 
796 678 a Ndumbea 
542 474 o Ndumbea 
333 311 u Ndumbea 
343 293 i Sele 
520 363 e Sele 
989 809 a Sele 
507 367 o Sele 
357 300 u Sele 

  Then read following the step below to get the plot:
> plot.case <- read.table("rHelp_20150206.txt",header=TRUE)
> language.vowel <- paste(language, vowel, sep="/")
> plot.case <- data.frame(plot.case,language.vowel)
> ggplot(plot.case,aes(x=language.vowel,y=female)) +
> geom_bar(stat="identity",fill="lightblue",color="black") + coord_flip()




--
View this message in context: http://r.789695.n4.nabble.com/Plotting-dataset-tp4702896p4702912.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Sat Feb  7 00:52:37 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 6 Feb 2015 15:52:37 -0800 (PST)
Subject: [R] Plotting dataset
In-Reply-To: <1423244497898-4702896.post@n4.nabble.com>
References: <1423244497898-4702896.post@n4.nabble.com>
Message-ID: <1423266757896-4702913.post@n4.nabble.com>

Hi,

  Forgot to mention that ggplot2 needs to be installed:

> install.packages("ggplot2")
Warning in install.packages :
  downloaded length 227 != reported length 227
trying URL
'http://cran.rstudio.com/bin/windows/contrib/3.1/ggplot2_1.0.0.zip'
Content type 'application/zip' length 2675344 bytes (2.6 Mb)
opened URL
downloaded 2.6 Mb

package ?ggplot2? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\p068244\AppData\Local\Temp\Rtmp4WVORN\downloaded_packages
> library(ggplot2)



--
View this message in context: http://r.789695.n4.nabble.com/Plotting-dataset-tp4702896p4702913.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Sat Feb  7 02:07:57 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 6 Feb 2015 17:07:57 -0800 (PST)
Subject: [R] Making a histogram
In-Reply-To: <1422902093763-4702689.post@n4.nabble.com>
References: <1422646359635-4702534.post@n4.nabble.com>
	<1422678608054-4702561.post@n4.nabble.com>
	<1422725899267-4702579.post@n4.nabble.com>
	<1422902093763-4702689.post@n4.nabble.com>
Message-ID: <1423271277580-4702915.post@n4.nabble.com>

Hi,

  For your error "object 't1971' not found" can be corrected by subsetting. 
t2001 can be done similarly with 2001 replacing 1971.

> t1971 <- data[year==1971,]
> t1971
   VOT year Consonant
1   67 1971         k
2  127 1971         k
3   79 1971         k
4  150 1971         k
5   53 1971         k
6   65 1971         k
7   75 1971         k
8  109 1971         k
9  109 1971         t
10 126 1971         t
11 129 1971         t
12 119 1971         t
13 104 1971         t
14 153 1971         t
15 124 1971         t
16 107 1971         t
17 181 1971         t
18 166 1971         t



--
View this message in context: http://r.789695.n4.nabble.com/Making-a-histogram-tp4702534p4702915.html
Sent from the R help mailing list archive at Nabble.com.


From ashley.naimi at mcgill.ca  Sat Feb  7 05:04:30 2015
From: ashley.naimi at mcgill.ca (Ashley Isaac Naimi, Mr)
Date: Sat, 7 Feb 2015 04:04:30 +0000
Subject: [R] censored quantile regression
In-Reply-To: <00c601d04246$3ca8e530$b5faaf90$@gmail.com>
References: <31D7F80A-95EF-4B17-B28D-161912150E53@mcgill.ca>
	<00c601d04246$3ca8e530$b5faaf90$@gmail.com>
Message-ID: <5470D7E8-8451-4114-BB48-743F1301DC41@mcgill.ca>

Hi Allen,

Thanks for your response. Regarding the issue that Portnoy and PH estimators may not compute parameters in the tail, I believe this is dependent on the amount of censoring (e.g., in the extreme case, if all observations are censored in the upper tail, one cannot obtain estimates in the absence of parametric assumptions). Furthermore, it could not explain the problem I encountered, since other fitting methods did not provide what I needed, nor was able to obtain parameter estimates at the desired quantile (0.9th) in the absence of censoring.

Dr Koenker offered a simple solution, which was to replace the last line with:

summary(q2, taus = 1:9/10)

instead of requesting the desired taus in the crq() function.

Regards,

Ashley

Ashley I Naimi, PhD
Assistant Professor
Department Obstetrics and Gynecology
McGill University
???????????
web: www.ashleyisaacnaimi.com<http://www.ashleyisaacnaimi.com>
email: ashley.naimi at mcgill.ca<mailto:ashley.naimi at mcgill.ca>
phone: 514.574.8946
fax: 514.834.1678
-----------------------

On Feb 6, 2015, at 2:51 PM, Allen Bingham <aebingham2 at gmail.com<mailto:aebingham2 at gmail.com>> wrote:

Ashley,

Looking at the code for the crq function it appears that with method="Portnoy" the tau value is not passed to the fitting function (crq.fit.por) and that function appears (I didn't delve into the code to make sure of this ...) to calculate the grid of tau values given the nature of the data, formula, etc. ---

--- more telling though is the following snippet I copied from the documentation of the crq function, specifically it states (in part) [I've split apart the pertinent section first]:

  "... Both the Portnoy and Peng-Huang estimators may be unable to compute estimates of
   the conditional quantile parameters in the upper tail of distribution.


  ... Like the Kaplan-Meier estimator, when censoring is heavy in the upper tail the
  estimated distribution is defective and quantiles are only estimable on a sub-interval
  of (0,1). The Peng and Huang estimator can be viewed as a generalization of the Nelson
  Aalen estimator of the cumulative hazard function, and can be formulated as a variant
  of the conventional quantile regression dual problem. See Koenker (2008) for further
  details. This paper is available from the package with vignette("crq"). ...  "

... so I'm guessing that using one of the other fitting methods may be get you what you need --- HOWEVER I'm only looking at the underlying code and documentation for same --- I'm completely ignorant of the statistical methods you are trying to implement --- and whether or not one of the other fitting methods is appropriate to your analyses.

Regardless it seems to me (IMHO) that the documentation for the crq function should indicate that the "tau" or alternatively the "taus" supplied to the crq function are only used with a subset of the method values.

Hope this helps-Allen
______________________________________
Allen Bingham
Bingham Statistical Consulting
aebingham2 at gmail.com<mailto:aebingham2 at gmail.com>

This message and any attachments may contain confidential or privileged information and are only for the use of the intended recipient of this message. If you are not the intended recipient, please notify the sender by return email, and delete or destroy this and all copies of this message and all attachments. Any unauthorized disclosure, use, distribution, or reproduction of this message or any attachments without permission from the sender is prohibited and may be unlawful.





-----Original Message-----
From: Ashley Isaac Naimi, Mr [mailto:ashley.naimi at mcgill.ca]
Sent: Tuesday, January 20, 2015 7:52 AM
To: r-help at r-project.org
Subject: [R] censored quantile regression

Hi there,

I've generated the following data:

library(quantreg)
library(survival)

set.seed(789)
N <- 2000
u <- runif(N)
x1 <- rbinom(N,1,.5)
x2 <- rbinom(N,1,.5)
x1x2<-x1*x2
lambda <- 1 + 1.5*x1 + 1.5*x2 + .5*x1x2
k <- 2
y <- lambda*((-log(1-u))^(1/k));max(y)
c <- runif(N,max=15)
event = as.numeric(y<=c)
mean(event);table(event)
cens <- 1-event
table(cens);mean(cens)
time <-as.matrix(ifelse(event==1,y,c))

St<-Surv(time,event,type="right")

To which I've fit the following censored quantile regression model:

q2 <- crq(St~x1 + x2 + x1x2,tau=.9,method="Portnoy")
summary(q2)

As one can see, I'm interested in the 0.9th quantile. But summary(q2) returns only the 20th to 80th percentiles (by 20). How can I get only the 0.9th quantile (aka the 90th percentile)?? All I actually need is the parameter estimate for the interaction (x1x2) for the 90th percentile. I know how to extract it if I were able to obtain estimates at tau=0.9, but no luck. Even though I request the 90th percentile in crq (i.e., "tau=0.9"), the summary function keeps returning the same set of (unwanted) percentiles (20th, 40th, 60th, 80th).

I?m using R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet?, Platform: x86_64-apple-darwin13.4.0 (64-bit).

Cheers,

Ashley I Naimi

[[alternative HTML version deleted]]




	[[alternative HTML version deleted]]


From katharine.miller at noaa.gov  Sat Feb  7 06:16:20 2015
From: katharine.miller at noaa.gov (Katharine Miller - NOAA Federal)
Date: Fri, 6 Feb 2015 20:16:20 -0900
Subject: [R] R Kohonen counts plot from unit classification?
Message-ID: <CACnUi6-Vz1FgvJHge9WNJfVQQXc-mAYe+Ufh_W+vkez4Rkq4LQ@mail.gmail.com>

I am new to the R Kohonen package.  I plotted the counts per cell and then
compared it to the unit.classif. from the som output - but I can't seem to
get it to match up.  Cells that show no counts in the counts plot have 3 or
more data objects assigned to them in the unit. classif.  I can provide the
data if someone can help.

Thanks

	[[alternative HTML version deleted]]


From beverly893 at gmail.com  Sat Feb  7 06:27:30 2015
From: beverly893 at gmail.com (Beverly Nguyen)
Date: Sat, 7 Feb 2015 00:27:30 -0500
Subject: [R] Computing RLE and NUSE Scores
Message-ID: <CAHSKe8oPEELbXLSdb+KTsF5adO6zsWELOmSMQj0sw0EDKKzL4Q@mail.gmail.com>

I am working on a project, and have been given a list of instructions as to
how to analyze microarray data. I am to use the affy and affyPLM packages
from Bioconductor.

I used ReadAffy() to read in my CEL files, then called rma() to normalize
the data. I now that this function returns an ExpressionSet.

I was then told to use the affyPLM package to compute the RLE and NUSE
scores in order to compute the median RLE and NUSE scores for each sample.
However, I am unable to call any of the package's function (fitPLM(),
NUSE(), RLE()) on the normalized data because it is an ExpressionSet.

My question is, how could I utilize the affyPLM package to compute RLE/NUSE
scores on an ExpressionSet, when the functions require the use of an
AffyBatch.
?

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sat Feb  7 06:49:31 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 6 Feb 2015 21:49:31 -0800
Subject: [R] Computing RLE and NUSE Scores
In-Reply-To: <CAHSKe8oPEELbXLSdb+KTsF5adO6zsWELOmSMQj0sw0EDKKzL4Q@mail.gmail.com>
References: <CAHSKe8oPEELbXLSdb+KTsF5adO6zsWELOmSMQj0sw0EDKKzL4Q@mail.gmail.com>
Message-ID: <CACk-te0xaUBLN+kjs1wwKYA=D70S4n4o-6wQFbdAykK+31G08g@mail.gmail.com>

Ask on the BioConductor list, not here.



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Feb 6, 2015 at 9:27 PM, Beverly Nguyen <beverly893 at gmail.com> wrote:
> I am working on a project, and have been given a list of instructions as to
> how to analyze microarray data. I am to use the affy and affyPLM packages
> from Bioconductor.
>
> I used ReadAffy() to read in my CEL files, then called rma() to normalize
> the data. I now that this function returns an ExpressionSet.
>
> I was then told to use the affyPLM package to compute the RLE and NUSE
> scores in order to compute the median RLE and NUSE scores for each sample.
> However, I am unable to call any of the package's function (fitPLM(),
> NUSE(), RLE()) on the normalized data because it is an ExpressionSet.
>
> My question is, how could I utilize the affyPLM package to compute RLE/NUSE
> scores on an ExpressionSet, when the functions require the use of an
> AffyBatch.
> ?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Feb  7 07:00:16 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 7 Feb 2015 17:00:16 +1100
Subject: [R] poor man's scree plot for SVD: multiline labels and total
	lines
In-Reply-To: <54D5365E.8080609@yorku.ca>
References: <54D5365E.8080609@yorku.ca>
Message-ID: <CA+8X3fWP6q_tx2_bpc=4Es2z5-wYHhdnBLA9t2pT+=CPLJJqtg@mail.gmail.com>

Hi Michael,
If you want to hardwire the title line, this may help. Very hacky, but...

print.scree.ca<-function(x,digits=5,...) {
 cat("Singular values and Principal inertias (eigenvalues)\n\n")
 cat(formatC(
  c("Singular","Principal","Percent","Cumulative","Scree plot"),
  width=10),"\n")
 cat(formatC(c("values","inertia"," ","percent"),width=10),"\n\n")
 for(row in 1:dim(x)[1])
  cat(unlist(format(x[row,],digits=digits,width=10,flag="-",format="f")),"\n")
}

Jim


On Sat, Feb 7, 2015 at 8:47 AM, Michael Friendly <friendly at yorku.ca> wrote:
> In the ca package, the summary method gives the following output, as a "poor
> man's scree plot",
> showing eigenvalues, their percents, and a character-based scree plot:
>
> # install.packages("ca")
> haireye <- margin.table(HairEyeColor, 1:2)
> library(ca)
> haireye.ca <- ca(haireye)
>
> summary(haireye.ca, rows=FALSE, columns=FALSE)
>
> Principal inertias (eigenvalues):
>
>  dim    value      %   cum%   scree plot
>  1      0.208773  89.4  89.4  **********************
>  2      0.022227   9.5  98.9  **
>  3      0.002598   1.1 100.0
>         -------- -----
>  Total: 0.233598 100.0
>
> I'd like to enhance this, to something like the following, using multiline
> column labels and also showing the totals,
> but the code in ca::print.summary.ca is too obtuse to try to reuse or
> modify.
>
> Singular values and Principal inertias (eigenvalues)
>
>   Singular  Principal  Percents   Cum  Scree plot
>   values    inertias
>
> 1 0.456916  0.208773     89.4    89.4 ******************************
> 2 0.149086  0.022227      9.5    98.9 ***
> 3 0.050975  0.002598      1.1   100.0
>             --------     ----
>             0.233598    100.0
>
> I made a start, defining a scree.ca function, and an associated print
> method, but I can't figure out how to
> print multiline labels and the totals for relevant columns.  Can someone
> help?
>
> Here are my functions:
>
> scree.ca <- function (obj, scree.width=30) {
>     values <- obj$sv
>     inertia <- values^2
>     pct <- 100*inertia/sum(inertia)
>     scree <- character(length(pct))
>     stars <- round(scree.width * pct / max(pct), 0)
>     for (q in 1:length(pct)) {
>       s1 <- paste(rep("*", stars[q]), collapse = "")
>       s2 <- paste(rep(" ", scree.width - stars[q]), collapse = "")
>       scree[q] <- paste(" ", s1, s2, sep = "")
>       }
>     dat <- data.frame(values, inertia, pct=round(pct,1),
> Cum=round(cumsum(pct),1), scree, stringsAsFactors=FALSE)
>     heading <- "Singular values and Principal inertias (eigenvalues)"
>     attr(dat,"heading") <- heading
>     attr(dat$values, "label") <- "Singular\nvalues"
>     attr(dat$inertia, "label") <- "Principal\ninertias"
>     attr(dat$pct, "label") <- "Percents"
>     class(dat) <- c("scree.ca", "data.frame")
>     dat
> }
>
> print.scree.ca <- function(x, digits=5, ...) {
>   if (!is.null(heading <- attr(x, "heading")))
>     {cat(heading, sep = "\n"); cat("\n")}
>     print.data.frame(x, digits=digits, ...)
> }
>
> And, a test use:
>
>> sc <- scree.ca(haireye.ca)
>> str(sc)
> Classes ?scree.ca? and 'data.frame':    3 obs. of  5 variables:
>  $ values : atomic  0.457 0.149 0.051
>   ..- attr(*, "label")= chr "Singular\nvalues"
>  $ inertia: atomic  0.2088 0.0222 0.0026
>   ..- attr(*, "label")= chr "Principal\ninertias"
>  $ pct    : atomic  89.4 9.5 1.1
>   ..- attr(*, "label")= chr "Percents"
>  $ Cum    : num  89.4 98.9 100
>  $ scree  : chr  " ******************************" " ***
> " "                               "
>  - attr(*, "heading")= chr "Singular values and Principal inertias
> (eigenvalues)"
>> sc
> Singular values and Principal inertias (eigenvalues)
>
>     values   inertia  pct   Cum                           scree
> 1 0.456916 0.2087727 89.4  89.4  ******************************
> 2 0.149086 0.0222266  9.5  98.9  ***
> 3 0.050975 0.0025984  1.1 100.0
>>
>
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Feb  7 07:12:38 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 7 Feb 2015 17:12:38 +1100
Subject: [R] Create a heat map with German postal codes
In-Reply-To: <CAP5QEc5a1cieS-=wAP4Or5x7rYrpsJ6Q8C+-fEpc+Mff7oR5qQ@mail.gmail.com>
References: <CAP5QEc5a1cieS-=wAP4Or5x7rYrpsJ6Q8C+-fEpc+Mff7oR5qQ@mail.gmail.com>
Message-ID: <CA+8X3fXEfQu1oDLXev1WsaAKFQhhCdQ-shBuLUygFTV7RJcM5Q@mail.gmail.com>

Hi Paul,
Have you seen this site?

http://blog.oraylis.de/2010/05/german-map-spatial-data-for-plz-postal-code-regions/

This seems to have the solution you want, and perhaps some useful
stuff about aggregating postal zones. For one off maps, I usually just
look at par("usr") to get the current plot limits and then trial and
eyeball the limits for the area I want.

Jim


On Sat, Feb 7, 2015 at 9:37 AM, Paul Tremblay <paulhtremblay at gmail.com> wrote:
> Hi,
>
> I am tasked with making a map of German postal codes for a few major cities
> in Germany. Each postal code will have a differnt color, depending on a
> metric. For simplicity, let's just use population density.
>
> This is what I have achieved so far for London (which I used as an
> example). I have been able to create a base map using the tutorials. I was
> able to import a shapefile of postal codes and display that on the map. I
> was able to create points on the map.
>
> What I am not able to do is color in each postal code according to density.
> The other problem I have is with actually creating a map that zooms in on
> the right area. I know you can limit the area with xlim and ylim, but I
> can't figure out sensible values for eacy of these parameters.
>
> I have not found a shapefile yet for German postal codes.
>
> Last, should I use worldmaps, or a more recent package such as ggmap or
> rworldmap? I have seen that worldmaps is very outdated.
>
> We have commercial software such as Tableau and Map Point (since
> discontinued) floating around here. Both of these software automatically
> map districts for US and London postal codes. However, I would like to use
> an open source solution if for no other reason than these commercial
> software might not work for other regions, and R seems better to extend for
> special cases.
>
> Thanks!
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mbmiller+l at gmail.com  Sat Feb  7 07:36:21 2015
From: mbmiller+l at gmail.com (Mike Miller)
Date: Sat, 7 Feb 2015 00:36:21 -0600 (CST)
Subject: [R] Plot residuals against standard normal distribution
In-Reply-To: <CACM6noZW5MK2736HTS6_f25ezQE1zNwuCc83WcyaP4jd5w6KeQ@mail.gmail.com>
References: <CACM6noZW5MK2736HTS6_f25ezQE1zNwuCc83WcyaP4jd5w6KeQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.00.1502062212480.29282@taxa.psych.umn.edu>

On Mon, 2 Feb 2015, Mikael Olai Milh?j wrote:

> I'm having trouble trying to plot the density of the residuals against 
> the standard normal distribution N(0,1). (I'm trying to see if my 
> residuals are well-behaved).
>
> I know hwo to calculate the standardized residuals (I guess that there 
> may be a simple way using a R function) and then plot this by using the 
> density function
>
> y<-(model$residuals-mean(model$residuals))/sd(model$residuals)
> plot(density(y))
>
> But I don't know how to add the N(0,1) curve. Any suggestions? Thanks in 
> advance

This isn't good for you?

qqnorm( residuals( model ) )

Residuals usually have a zero mean, but I guess you can center, anyway, 
and if there could be NAs, you will need to deal with them:

res <- residuals( model )

resStd <- ( res - mean( res, na.rm=TRUE ) ) / sd( res, na.rm=TRUE )

qqnorm( resStd )

Another issue is how to make the theoretical quantiles for the normal 
distribution.  There are a few methods:

https://www.statsdirect.com/help/data_preparation/normal_scores.htm

I usually use Blom:

r <- rank( resStd )
c <- 3/8
N <- sum( !is.na( resStd ) )
resNorm <- qnorm( ( r - c ) / ( N - 2*c + 1 ) )
resNorm[ is.nan( resNorm ) ] <- NA

Then you could plot it directly:

plot(resNorm, resStd)

When we use qqnorm() in R, it looks like R is using a Blom method with 
c=1/2 instead of c=3/8.  I believe Blom recommended 3/8 and programs that 
offer Blom normal scores use c=3/8.

Best,
Mike

-- 
Michael B. Miller, Ph.D.
Minnesota Center for Twin and Family Research
Department of Psychology
University of Minnesota
http://scholar.google.com/citations?user=EV_phq4AAAAJ

From laomeng_3 at 163.com  Sat Feb  7 08:29:20 2015
From: laomeng_3 at 163.com (meng)
Date: Sat, 7 Feb 2015 15:29:20 +0800 (CST)
Subject: [R] how to draw paired mosaic plot?
In-Reply-To: <54D4E342.5080606@gmail.com>
References: <320b5c11.1b0c.14b5eb6e405.Coremail.laomeng_3@163.com>
	<54D4E342.5080606@gmail.com>
Message-ID: <69c3c3db.247.14b62f15d66.Coremail.laomeng_3@163.com>

If both x and y are all character, paired scatter plot is a little bit strange I think.






--
QQ: 1733768559





At 2015-02-06 23:52:34,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>On 06/02/2015 6:46 AM, meng wrote:
>> Hi all:
>> If there are two numeric variable:x,y, and I can get paired scatter plot by function "pairs".But if x and y are character, and I want to get paired mosaic plot,which function should be used then?
>
>Why not pairs, with a custom panel function?  There are examples on the 
>help page, though I don't think a mosaic plot is there.
>
>Duncan Murdoch
>>
>>
>> Many thanks!
>> My best.
>>
>>
>>
>>
>>
>>
>> --
>> QQ: 1733768559
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Feb  7 10:04:26 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 7 Feb 2015 20:04:26 +1100
Subject: [R] how to draw paired mosaic plot?
In-Reply-To: <69c3c3db.247.14b62f15d66.Coremail.laomeng_3@163.com>
References: <320b5c11.1b0c.14b5eb6e405.Coremail.laomeng_3@163.com>
	<54D4E342.5080606@gmail.com>
	<69c3c3db.247.14b62f15d66.Coremail.laomeng_3@163.com>
Message-ID: <CA+8X3fWBk4SF6SonhgfGNcL3JBGnb+6n752GVUEx4DJNh6Yd3w@mail.gmail.com>

Hi meng,
It's not too hard to get a mosaic plot of two character variables:

x<-sample(LETTERS[1:3],20,TRUE)
y<-sample(LETTERS[24:26],20,TRUE)
mosaicplot(table(x,y))

If you could tell us how the above is not what you want, perhaps a
better suggestion will appear.

Jim


On Sat, Feb 7, 2015 at 6:29 PM, meng <laomeng_3 at 163.com> wrote:
> If both x and y are all character, paired scatter plot is a little bit strange I think.
>
>
>
>
>
>
> --
> QQ: 1733768559
>
>
>
>
>
> At 2015-02-06 23:52:34,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>On 06/02/2015 6:46 AM, meng wrote:
>>> Hi all:
>>> If there are two numeric variable:x,y, and I can get paired scatter plot by function "pairs".But if x and y are character, and I want to get paired mosaic plot,which function should be used then?
>>
>>Why not pairs, with a custom panel function?  There are examples on the
>>help page, though I don't think a mosaic plot is there.
>>
>>Duncan Murdoch
>>>
>>>
>>> Many thanks!
>>> My best.
>>>
>>>
>>>
>>>
>>>
>>>
>>> --
>>> QQ: 1733768559
>>>
>>>
>>>      [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j.guilbert at auckland.ac.nz  Sat Feb  7 22:57:55 2015
From: j.guilbert at auckland.ac.nz (jgui001)
Date: Sat, 7 Feb 2015 13:57:55 -0800 (PST)
Subject: [R] Superscript in legend without using expression function
Message-ID: <1423346275659-4702929.post@n4.nabble.com>

I am plotting three sets of data on a single graph, and doing around 100+
graphs.
I can use the expression function to superscript the 2 but that seems to
force me to manually put in the R squared values. Is there away around this? 

This code will show what it should look like this but with the 2
superscripted

r1<-c(0.59,0.9,0.6)
plot(1:6)
legend("topleft",
legend=c(paste("G1 r=",r1[1]), paste("G2 r=",r1[2]), paste("G3 r=",r1[3])))



--
View this message in context: http://r.789695.n4.nabble.com/Superscript-in-legend-without-using-expression-function-tp4702929.html
Sent from the R help mailing list archive at Nabble.com.


From laomeng_3 at 163.com  Sat Feb  7 15:50:37 2015
From: laomeng_3 at 163.com (meng)
Date: Sat, 7 Feb 2015 22:50:37 +0800 (CST)
Subject: [R] how to draw paired mosaic plot?
In-Reply-To: <CA+8X3fWBk4SF6SonhgfGNcL3JBGnb+6n752GVUEx4DJNh6Yd3w@mail.gmail.com>
References: <320b5c11.1b0c.14b5eb6e405.Coremail.laomeng_3@163.com>
	<54D4E342.5080606@gmail.com>
	<69c3c3db.247.14b62f15d66.Coremail.laomeng_3@163.com>
	<CA+8X3fWBk4SF6SonhgfGNcL3JBGnb+6n752GVUEx4DJNh6Yd3w@mail.gmail.com>
Message-ID: <65f31ec3.5c1.14b6485618a.Coremail.laomeng_3@163.com>

If there are many character variables,and I want to get the mosaic plot of every pair of each variable,how to do then?


If the variables are numeric, I can use pairs to get paired scatter plot.
But as to the character variables, how to get the "paired mosaic plot"?


Many thanks.





--
QQ: 1733768559





At 2015-02-07 17:04:26,"Jim Lemon" <drjimlemon at gmail.com> wrote:
>Hi meng,
>It's not too hard to get a mosaic plot of two character variables:
>
>x<-sample(LETTERS[1:3],20,TRUE)
>y<-sample(LETTERS[24:26],20,TRUE)
>mosaicplot(table(x,y))
>
>If you could tell us how the above is not what you want, perhaps a
>better suggestion will appear.
>
>Jim
>
>
>On Sat, Feb 7, 2015 at 6:29 PM, meng <laomeng_3 at 163.com> wrote:
>> If both x and y are all character, paired scatter plot is a little bit strange I think.
>>
>>
>>
>>
>>
>>
>> --
>> QQ: 1733768559
>>
>>
>>
>>
>>
>> At 2015-02-06 23:52:34,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>On 06/02/2015 6:46 AM, meng wrote:
>>>> Hi all:
>>>> If there are two numeric variable:x,y, and I can get paired scatter plot by function "pairs".But if x and y are character, and I want to get paired mosaic plot,which function should be used then?
>>>
>>>Why not pairs, with a custom panel function?  There are examples on the
>>>help page, though I don't think a mosaic plot is there.
>>>
>>>Duncan Murdoch
>>>>
>>>>
>>>> Many thanks!
>>>> My best.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> QQ: 1733768559
>>>>
>>>>
>>>>      [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mbmiller+l at gmail.com  Sat Feb  7 22:43:35 2015
From: mbmiller+l at gmail.com (Mike Miller)
Date: Sat, 7 Feb 2015 15:43:35 -0600 (CST)
Subject: [R] Plot residuals against standard normal distribution
In-Reply-To: <alpine.DEB.2.00.1502062212480.29282@taxa.psych.umn.edu>
References: <CACM6noZW5MK2736HTS6_f25ezQE1zNwuCc83WcyaP4jd5w6KeQ@mail.gmail.com>
	<alpine.DEB.2.00.1502062212480.29282@taxa.psych.umn.edu>
Message-ID: <alpine.DEB.2.00.1502071234010.29282@taxa.psych.umn.edu>

On Sat, 7 Feb 2015, Mike Miller wrote:

> res <- residuals( model )
>
> resStd <- ( res - mean( res, na.rm=TRUE ) ) / sd( res, na.rm=TRUE )
>
> Another issue is how to make the theoretical quantiles for the normal 
> distribution.  There are a few methods:
>
> https://www.statsdirect.com/help/data_preparation/normal_scores.htm
>
> I usually use Blom:
>
> r <- rank( resStd )
> c <- 3/8
> N <- sum( !is.na( resStd ) )
> resNorm <- qnorm( ( r - c ) / ( N - 2*c + 1 ) )
> resNorm[ is.nan( resNorm ) ] <- NA
>
> Then you could plot it directly:
>
> plot(resNorm, resStd)
>
> When we use qqnorm() in R, it looks like R is using a Blom method with 
> c=1/2 instead of c=3/8.  I believe Blom recommended 3/8 and programs 
> that offer Blom normal scores use c=3/8.


I don't know if that was off-track because the OP was asking about 
density, but he also was asking about checking the distribution of 
residuals, so maybe this is appropriate.

I should add, if you don't mind using R's c=1/2, you can get the normal 
scores very quickly this way:

resNorm <- qqnorm( residuals( model ), plot.it=FALSE )$x

Apparently, 11 years ago R was using c=3/8 in qqnorm(), so I guess it 
changed.  Nordheim, Clayton and Yandell wrote about it in this document 
dated September 9, 2003:

https://www.stat.wisc.edu/~yandell/st571/R/append8.pdf

It is definitely using c=1/2 today.  I don't know where that is 
documented.

When I do a QQ-plot of uniform p-values, I like to add a confidence region 
with these lmits:

   qb95 <- qbeta(.95,1:N,N+1-(1:N))
   qb05 <- qbeta(.05,1:N,N+1-(1:N))

If we have N observations from a normal distribution with unknown mean and 
variance, can we create some kind of analogous region on a qqnorm() kind 
of plot?  It seems like there should be a way to get at least an 
approximate result using beta and t distributions, probably building on 
the qbeta() code above.

Mike


From r.turner at auckland.ac.nz  Sat Feb  7 23:54:37 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 08 Feb 2015 11:54:37 +1300
Subject: [R] Superscript in legend without using expression function
In-Reply-To: <1423346275659-4702929.post@n4.nabble.com>
References: <1423346275659-4702929.post@n4.nabble.com>
Message-ID: <54D697AD.90302@auckland.ac.nz>

On 08/02/15 10:57, jgui001 wrote:
> I am plotting three sets of data on a single graph, and doing around 100+
> graphs.
> I can use the expression function to superscript the 2 but that seems to
> force me to manually put in the R squared values. Is there away around this?
>
> This code will show what it should look like this but with the 2
> superscripted
>
> r1<-c(0.59,0.9,0.6)
> plot(1:6)
> legend("topleft",
> legend=c(paste("G1 r=",r1[1]), paste("G2 r=",r1[2]), paste("G3 r=",r1[3])))

One way of accomplishing this is:

r1<-c(0.59,0.9,0.6)
l3 <- c(as.expression(bquote(G[1]~~ r^2 == .(r1[1]))),
         as.expression(bquote(G[2]~~ r^2 == .(r1[2]))),
         as.expression(bquote(G[3]~~ r^2 == .(r1[3]))))
plot(1:6)
legend("topleft",legend=l3)

Don't ask me to explain how this works.  I just hammered and hoped till 
the desired results were produced.

There are other ways, I think, some of which may be less prolix. Someone 
else may chime in and suggest a better way, but I think that the 
foregoing does what you want.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From drjimlemon at gmail.com  Sun Feb  8 04:17:37 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 8 Feb 2015 14:17:37 +1100
Subject: [R] how to draw paired mosaic plot?
In-Reply-To: <65f31ec3.5c1.14b6485618a.Coremail.laomeng_3@163.com>
References: <320b5c11.1b0c.14b5eb6e405.Coremail.laomeng_3@163.com>
	<54D4E342.5080606@gmail.com>
	<69c3c3db.247.14b62f15d66.Coremail.laomeng_3@163.com>
	<CA+8X3fWBk4SF6SonhgfGNcL3JBGnb+6n752GVUEx4DJNh6Yd3w@mail.gmail.com>
	<65f31ec3.5c1.14b6485618a.Coremail.laomeng_3@163.com>
Message-ID: <CA+8X3fWmcQZq_v0JhuTJUVDYbhhMcx=qpom8HgFjVFbX2DfCmw@mail.gmail.com>

Hi meng,
A basic display of mosaic plots for all pairs of variables isn't too
difficult, but you will probably want to make this a bit fancier. It
only displays the unique plots, unlike the "pairs" plot. Keep in mind
that "many" variables will mean many plots.

chardf<-data.frame(v1=sample(LETTERS[1:3],20,TRUE),
 v2=sample(LETTERS[4:6],20,TRUE),
 v3=sample(LETTERS[7:9],20,TRUE),
 v4=sample(LETTERS[10:12],20,TRUE))

mosaic_pairs<-function(x,...) {
 if(!is.data.frame(x) && !is.matrix(x))
  stop("x must be a 2D matrix or data frame")
 nvar<-dim(x)[2]
 paircomb<-combn(nvar,2)
 nplots<-dim(paircomb)[2]
 split.screen(figs=c(nvar-1,nvar-1))
 for(i in 1:nplots) {
  screen((paircomb[2,i]-1)+(paircomb[1,i]-1)*(nvar-1))
  maintitle<-
   paste(names(x)[paircomb[1,i]],"by",names(x)[paircomb[2,i]])
  par(mar=c(1,1,3,1))
  mosaicplot(table(x[[paircomb[2,i]]],x[[paircomb[1,i]]]),
   main=maintitle,...)
 }
}

mosaic_pairs(chardf)

Jim


On Sun, Feb 8, 2015 at 1:50 AM, meng <laomeng_3 at 163.com> wrote:
> If there are many character variables,and I want to get the mosaic plot of
> every pair of each variable,how to do then?
>
> If the variables are numeric, I can use pairs to get paired scatter plot.
> But as to the character variables, how to get the "paired mosaic plot"?
>
> Many thanks.
>
>
>
>
> --
> QQ: 1733768559
>
>
>
> At 2015-02-07 17:04:26,"Jim Lemon" <drjimlemon at gmail.com> wrote:
>>Hi meng,
>>It's not too hard to get a mosaic plot of two character variables:
>>
>>x<-sample(LETTERS[1:3],20,TRUE)
>>y<-sample(LETTERS[24:26],20,TRUE)
>>mosaicplot(table(x,y))
>>
>>If you could tell us how the above is not what you want, perhaps a
>>better suggestion will appear.
>>
>>Jim
>>
>>
>>On Sat, Feb 7, 2015 at 6:29 PM, meng <laomeng_3 at 163.com> wrote:
>>> If both x and y are all character, paired scatter plot is a little bit
>>> strange I think.
>>>
>>>
>>>
>>>
>>>
>>>
>>> --
>>> QQ: 1733768559
>>>
>>>
>>>
>>>
>>>
>>> At 2015-02-06 23:52:34,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>>On 06/02/2015 6:46 AM, meng wrote:
>>>>> Hi all:
>>>>> If there are two numeric variable:x,y, and I can get paired scatter
>>>>> plot by function "pairs".But if x and y are character, and I want to get
>>>>> paired mosaic plot,which function should be used then?
>>>>
>>>>Why not pairs, with a custom panel function?  There are examples on the
>>>>help page, though I don't think a mosaic plot is there.
>>>>
>>>>Duncan Murdoch
>>>>>
>>>>>
>>>>> Many thanks!
>>>>> My best.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> QQ: 1733768559
>>>>>
>>>>>
>>>>>      [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From dwinsemius at comcast.net  Sun Feb  8 04:19:04 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 7 Feb 2015 19:19:04 -0800
Subject: [R] Superscript in legend without using expression function
In-Reply-To: <54D697AD.90302@auckland.ac.nz>
References: <1423346275659-4702929.post@n4.nabble.com>
	<54D697AD.90302@auckland.ac.nz>
Message-ID: <28EA2547-EF8B-4A86-97F9-E823940F3B70@comcast.net>


On Feb 7, 2015, at 2:54 PM, Rolf Turner wrote:

> On 08/02/15 10:57, jgui001 wrote:
>> I am plotting three sets of data on a single graph, and doing around 100+
>> graphs.
>> I can use the expression function to superscript the 2 but that seems to
>> force me to manually put in the R squared values. Is there away around this?
>> 
>> This code will show what it should look like this but with the 2
>> superscripted
>> 
>> r1<-c(0.59,0.9,0.6)
>> plot(1:6)
>> legend("topleft",
>> legend=c(paste("G1 r=",r1[1]), paste("G2 r=",r1[2]), paste("G3 r=",r1[3])))
> 
> One way of accomplishing this is:
> 
> r1<-c(0.59,0.9,0.6)
> l3 <- c(as.expression(bquote(G[1]~~ r^2 == .(r1[1]))),
>        as.expression(bquote(G[2]~~ r^2 == .(r1[2]))),
>        as.expression(bquote(G[3]~~ r^2 == .(r1[3]))))
> plot(1:6)
> legend("topleft",legend=l3)

This might be a bit more compact:

r1<-c(0.59,0.9,0.6)
plot(1:6)
legend("topleft",
leg=as.expression(lapply(1:3, function(n) bquote( G*.(n)~r^2==.(r1[n])))))

I didn't see an indication that there were supposed to be subscripted numerals after the "G"'s

Initialy I tried just:

lapply(1:3, function(n) bquote( G*.(n)~r^2==.(r1[n])))

But this didn't have the proper mode, which was solved by wrapping in as.espression thus returning the correctly constructed expression vector:

expression(G * 1L ~ r^2 == 0.59,
           G * 2L ~ r^2 == 0.9,
           G * 3L ~ r^2 == 0.6)

This could also be delivered slightly less economically with this editing of your effort:

as.expression(c( bquote(G[1]~~ r^2 == .(r1[1])),
                 bquote(G[2]~~ r^2 == .(r1[2])),
                 bquote(G[3]~~ r^2 == .(r1[3]))
                )
             )

I'm not sure but I think that expressions can be vectors but I don't think that there are "call vectors", only call lists.


> Don't ask me to explain how this works.  I just hammered and hoped till the desired results were produced.
> 
> There are other ways, I think, some of which may be less prolix. Someone else may chime in and suggest a better way, but I think that the foregoing does what you want.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Rolf Turner
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> Home phone: +64-9-480-4619
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From friendly at yorku.ca  Sun Feb  8 16:01:09 2015
From: friendly at yorku.ca (Michael Friendly)
Date: Sun, 8 Feb 2015 10:01:09 -0500
Subject: [R] how to draw paired mosaic plot?
In-Reply-To: <65f31ec3.5c1.14b6485618a.Coremail.laomeng_3@163.com>
References: <320b5c11.1b0c.14b5eb6e405.Coremail.laomeng_3@163.com>	<54D4E342.5080606@gmail.com>	<69c3c3db.247.14b62f15d66.Coremail.laomeng_3@163.com>	<CA+8X3fWBk4SF6SonhgfGNcL3JBGnb+6n752GVUEx4DJNh6Yd3w@mail.gmail.com>
	<65f31ec3.5c1.14b6485618a.Coremail.laomeng_3@163.com>
Message-ID: <54D77A35.1030108@yorku.ca>

You are looking for the pairs plot for table and other objects in the 
vcd package:

  ?vcd::pairs.table

It allows you to use various panel functions for the diagonal and 
off-diagonal plots

On 2/7/2015 9:50 AM, meng wrote:
> If there are many character variables,and I want to get the mosaic plot of every pair of each variable,how to do then?
>
>
> If the variables are numeric, I can use pairs to get paired scatter plot.
> But as to the character variables, how to get the "paired mosaic plot"?
>
>
> Many thanks.
>
>
>
>
>
> --
> QQ: 1733768559
>
>
>
>
>
> At 2015-02-07 17:04:26,"Jim Lemon" <drjimlemon at gmail.com> wrote:
>> Hi meng,
>> It's not too hard to get a mosaic plot of two character variables:
>>
>> x<-sample(LETTERS[1:3],20,TRUE)
>> y<-sample(LETTERS[24:26],20,TRUE)
>> mosaicplot(table(x,y))
>>
>> If you could tell us how the above is not what you want, perhaps a
>> better suggestion will appear.
>>
>> Jim
>>
>>
>> On Sat, Feb 7, 2015 at 6:29 PM, meng <laomeng_3 at 163.com> wrote:
>>> If both x and y are all character, paired scatter plot is a little bit strange I think.
>>>
>>>
>>>
>>>
>>>
>>>
>>> --
>>> QQ: 1733768559
>>>
>>>
>>>
>>>
>>>
>>> At 2015-02-06 23:52:34,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>> On 06/02/2015 6:46 AM, meng wrote:
>>>>> Hi all:
>>>>> If there are two numeric variable:x,y, and I can get paired scatter plot by function "pairs".But if x and y are character, and I want to get paired mosaic plot,which function should be used then?
>>>>
>>>> Why not pairs, with a custom panel function?  There are examples on the
>>>> help page, though I don't think a mosaic plot is there.
>>>>
>>>> Duncan Murdoch
>>>>>
>>>>>
>>>>> Many thanks!
>>>>> My best.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> QQ: 1733768559
>>>>>
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From friendly at yorku.ca  Sun Feb  8 16:01:09 2015
From: friendly at yorku.ca (Michael Friendly)
Date: Sun, 08 Feb 2015 10:01:09 -0500
Subject: [R] how to draw paired mosaic plot?
In-Reply-To: <65f31ec3.5c1.14b6485618a.Coremail.laomeng_3@163.com>
References: <320b5c11.1b0c.14b5eb6e405.Coremail.laomeng_3@163.com>	<54D4E342.5080606@gmail.com>	<69c3c3db.247.14b62f15d66.Coremail.laomeng_3@163.com>	<CA+8X3fWBk4SF6SonhgfGNcL3JBGnb+6n752GVUEx4DJNh6Yd3w@mail.gmail.com>
	<65f31ec3.5c1.14b6485618a.Coremail.laomeng_3@163.com>
Message-ID: <54D77A35.1030108@yorku.ca>

You are looking for the pairs plot for table and other objects in the 
vcd package:

  ?vcd::pairs.table

It allows you to use various panel functions for the diagonal and 
off-diagonal plots

On 2/7/2015 9:50 AM, meng wrote:
> If there are many character variables,and I want to get the mosaic plot of every pair of each variable,how to do then?
>
>
> If the variables are numeric, I can use pairs to get paired scatter plot.
> But as to the character variables, how to get the "paired mosaic plot"?
>
>
> Many thanks.
>
>
>
>
>
> --
> QQ: 1733768559
>
>
>
>
>
> At 2015-02-07 17:04:26,"Jim Lemon" <drjimlemon at gmail.com> wrote:
>> Hi meng,
>> It's not too hard to get a mosaic plot of two character variables:
>>
>> x<-sample(LETTERS[1:3],20,TRUE)
>> y<-sample(LETTERS[24:26],20,TRUE)
>> mosaicplot(table(x,y))
>>
>> If you could tell us how the above is not what you want, perhaps a
>> better suggestion will appear.
>>
>> Jim
>>
>>
>> On Sat, Feb 7, 2015 at 6:29 PM, meng <laomeng_3 at 163.com> wrote:
>>> If both x and y are all character, paired scatter plot is a little bit strange I think.
>>>
>>>
>>>
>>>
>>>
>>>
>>> --
>>> QQ: 1733768559
>>>
>>>
>>>
>>>
>>>
>>> At 2015-02-06 23:52:34,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>> On 06/02/2015 6:46 AM, meng wrote:
>>>>> Hi all:
>>>>> If there are two numeric variable:x,y, and I can get paired scatter plot by function "pairs".But if x and y are character, and I want to get paired mosaic plot,which function should be used then?
>>>>
>>>> Why not pairs, with a custom panel function?  There are examples on the
>>>> help page, though I don't think a mosaic plot is there.
>>>>
>>>> Duncan Murdoch
>>>>>
>>>>>
>>>>> Many thanks!
>>>>> My best.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> QQ: 1733768559
>>>>>
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From laomeng_3 at 163.com  Sun Feb  8 17:23:57 2015
From: laomeng_3 at 163.com (meng)
Date: Mon, 9 Feb 2015 00:23:57 +0800 (CST)
Subject: [R] how to draw paired mosaic plot?
In-Reply-To: <54D77A35.1030108@yorku.ca>
References: <320b5c11.1b0c.14b5eb6e405.Coremail.laomeng_3@163.com>
	<54D4E342.5080606@gmail.com>
	<69c3c3db.247.14b62f15d66.Coremail.laomeng_3@163.com>
	<CA+8X3fWBk4SF6SonhgfGNcL3JBGnb+6n752GVUEx4DJNh6Yd3w@mail.gmail.com>
	<65f31ec3.5c1.14b6485618a.Coremail.laomeng_3@163.com>
	<54D77A35.1030108@yorku.ca>
Message-ID: <613a4eff.b2c.14b6a012f45.Coremail.laomeng_3@163.com>

Many thanks.





--
QQ: 1733768559





At 2015-02-08 23:01:09,"Michael Friendly" <friendly at yorku.ca> wrote:
>You are looking for the pairs plot for table and other objects in the 
>vcd package:
>
>  ?vcd::pairs.table
>
>It allows you to use various panel functions for the diagonal and 
>off-diagonal plots
>
>On 2/7/2015 9:50 AM, meng wrote:
>> If there are many character variables,and I want to get the mosaic plot of every pair of each variable,how to do then?
>>
>>
>> If the variables are numeric, I can use pairs to get paired scatter plot.
>> But as to the character variables, how to get the "paired mosaic plot"?
>>
>>
>> Many thanks.
>>
>>
>>
>>
>>
>> --
>> QQ: 1733768559
>>
>>
>>
>>
>>
>> At 2015-02-07 17:04:26,"Jim Lemon" <drjimlemon at gmail.com> wrote:
>>> Hi meng,
>>> It's not too hard to get a mosaic plot of two character variables:
>>>
>>> x<-sample(LETTERS[1:3],20,TRUE)
>>> y<-sample(LETTERS[24:26],20,TRUE)
>>> mosaicplot(table(x,y))
>>>
>>> If you could tell us how the above is not what you want, perhaps a
>>> better suggestion will appear.
>>>
>>> Jim
>>>
>>>
>>> On Sat, Feb 7, 2015 at 6:29 PM, meng <laomeng_3 at 163.com> wrote:
>>>> If both x and y are all character, paired scatter plot is a little bit strange I think.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> QQ: 1733768559
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> At 2015-02-06 23:52:34,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>>> On 06/02/2015 6:46 AM, meng wrote:
>>>>>> Hi all:
>>>>>> If there are two numeric variable:x,y, and I can get paired scatter plot by function "pairs".But if x and y are character, and I want to get paired mosaic plot,which function should be used then?
>>>>>
>>>>> Why not pairs, with a custom panel function?  There are examples on the
>>>>> help page, though I don't think a mosaic plot is there.
>>>>>
>>>>> Duncan Murdoch
>>>>>>
>>>>>>
>>>>>> Many thanks!
>>>>>> My best.
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> QQ: 1733768559
>>>>>>
>>>>>>
>>>>>>       [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> 	[[alternative HTML version deleted]]
>>
>
>
>-- 
>Michael Friendly     Email: friendly AT yorku DOT ca
>Professor, Psychology Dept. & Chair, Quantitative Methods
>York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>4700 Keele Street    Web:   http://www.datavis.ca
>Toronto, ONT  M3J 1P3 CANADA

	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Sun Feb  8 18:46:18 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Sun, 8 Feb 2015 17:46:18 +0000
Subject: [R] Unable to use `eval(parse(text))' in  nlme::lme
Message-ID: <1423417571305.5335@jhu.edu>

Hi,

I would like to run lme() on a number of response variables in a dataframe in an automatic manner.  Bu, when I use eval(parse(text=yname)) to denote the LHS of the formula in lme(), I get the following error message:



> require(nlme)



> mod2 <- with(subset(labdata2, Transplant_type!=0 & time >0), lme(eval(parse(text=yname)) ~ time +  as.factor(gvhd), random = ~1|Patient, correlation = corAR1(), method="ML", na.action=na.omit))
Error in model.frame.default(formula = ~Patient + yname + time + gvhd,  :
  variable lengths differ (found for 'yname')

The same usage works well in lme4::lmer without any problems.



It seems that there is a problem in how the formula object is evaluated in lme().  Is there an alternative way to do this?



Thank you,

Ravi

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Feb  8 21:49:41 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 09 Feb 2015 09:49:41 +1300
Subject: [R] Unable to use `eval(parse(text))' in  nlme::lme
In-Reply-To: <1423417571305.5335@jhu.edu>
References: <1423417571305.5335@jhu.edu>
Message-ID: <54D7CBE5.9020002@auckland.ac.nz>

On 09/02/15 06:46, Ravi Varadhan wrote:
> Hi,
>
> I would like to run lme() on a number of response variables in a
> dataframe in an automatic manner.  Bu, when I use
> eval(parse(text=yname)) to denote the LHS of the formula in lme(), I
> get the following error message:
>
>
>
>> require(nlme)
>
>
>
>> mod2 <- with(subset(labdata2, Transplant_type!=0 & time >0),
>> lme(eval(parse(text=yname)) ~ time +  as.factor(gvhd), random =
>> ~1|Patient, correlation = corAR1(), method="ML",
>> na.action=na.omit))
> Error in model.frame.default(formula = ~Patient + yname + time +
> gvhd,  : variable lengths differ (found for 'yname')
>
> The same usage works well in lme4::lmer without any problems.
>
>
>
> It seems that there is a problem in how the formula object is
> evaluated in lme().  Is there an alternative way to do this?

What about trying some'at lahk:

fmla <- as.formula(paste(yname,"~ time + as.factor(gvhd)"))
mod2 <- with(...., lme(fmla, random = ....))

Also you would probably be better off using the data argument rather 
then using with(); this could have some impact on the environment in 
which the formula is evaluated.

Just stabbing in the dark here since you did not provide a reproducible 
example.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From murdoch.duncan at gmail.com  Sun Feb  8 22:14:55 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 08 Feb 2015 16:14:55 -0500
Subject: [R] Unable to use `eval(parse(text))' in  nlme::lme
In-Reply-To: <54D7CBE5.9020002@auckland.ac.nz>
References: <1423417571305.5335@jhu.edu> <54D7CBE5.9020002@auckland.ac.nz>
Message-ID: <54D7D1CF.2010205@gmail.com>

On 08/02/2015 3:49 PM, Rolf Turner wrote:
> On 09/02/15 06:46, Ravi Varadhan wrote:
>> Hi,
>>
>> I would like to run lme() on a number of response variables in a
>> dataframe in an automatic manner.  Bu, when I use
>> eval(parse(text=yname)) to denote the LHS of the formula in lme(), I
>> get the following error message:
>>
>>
>>
>>> require(nlme)
>>
>>
>>
>>> mod2 <- with(subset(labdata2, Transplant_type!=0 & time >0),
>>> lme(eval(parse(text=yname)) ~ time +  as.factor(gvhd), random =
>>> ~1|Patient, correlation = corAR1(), method="ML",
>>> na.action=na.omit))
>> Error in model.frame.default(formula = ~Patient + yname + time +
>> gvhd,  : variable lengths differ (found for 'yname')
>>
>> The same usage works well in lme4::lmer without any problems.
>>
>>
>>
>> It seems that there is a problem in how the formula object is
>> evaluated in lme().  Is there an alternative way to do this?
> 
> What about trying some'at lahk:
> 
> fmla <- as.formula(paste(yname,"~ time + as.factor(gvhd)"))
> mod2 <- with(...., lme(fmla, random = ....))
> 
> Also you would probably be better off using the data argument rather 
> then using with(); this could have some impact on the environment in 
> which the formula is evaluated.

Formulas are a little tricky:  effectively they are evaluated twice.  If
you type something like

y ~ x

(or eval(parse(text="y ~ x")), or as.formula("y ~ x")) then a formula
object is created.  That object remembers the environment in which it
was created, so later when the modelling function uses it, the x and y
variables are evaluated in the original context.

In your example, as.formula() will convert the string to a formula, and
attach the current environment.  So you'd better hope that whatever
variable yname names, as well as time and gvhd, are all available there.

Duncan Murdoch

> 
> Just stabbing in the dark here since you did not provide a reproducible 
> example.
> 
> cheers,
> 
> Rolf Turner
>


From glennmschultz at me.com  Sun Feb  8 22:06:03 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Sun, 08 Feb 2015 21:06:03 +0000 (GMT)
Subject: [R] Package build help
Message-ID: <b3a194a5-fe72-4202-9999-adf41b5a88c0@me.com>

Hello All,

I am in the final stages of building my first package "BondLab" and the check throughs the following warning. ?I think this is namespace thing. ?I have not done anything with the namespace at this point. ?I am turning my attention to the namespace now. ?Am I correct this can be a handled by the namespace?

Thanks,
Glenn

Found the following significant warnings:
? Warning: replacing previous import by ?lubridate::duration? when loading ?BondLab?
? Warning: replacing previous import by ?plyr::here? when loading ?BondLab?

From murdoch.duncan at gmail.com  Mon Feb  9 00:15:45 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 08 Feb 2015 18:15:45 -0500
Subject: [R] Package build help
In-Reply-To: <b3a194a5-fe72-4202-9999-adf41b5a88c0@me.com>
References: <b3a194a5-fe72-4202-9999-adf41b5a88c0@me.com>
Message-ID: <54D7EE21.7030505@gmail.com>

On 08/02/2015 4:06 PM, Glenn Schultz wrote:
> Hello All,
> 
> I am in the final stages of building my first package "BondLab" and the check throughs the following warning.  I think this is namespace thing.  I have not done anything with the namespace at this point.  I am turning my attention to the namespace now.  Am I correct this can be a handled by the namespace?
> 

I would guess you have imported the lubridate and plyr packages, and
also defined your own duration() and here() functions, hiding theirs.

Duncan Murdoch

> Thanks,
> Glenn
> 
> Found the following significant warnings:
>   Warning: replacing previous import by ?lubridate::duration? when loading ?BondLab?
>   Warning: replacing previous import by ?plyr::here? when loading ?BondLab?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Mon Feb  9 01:08:56 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 8 Feb 2015 19:08:56 -0500
Subject: [R] Superscript in legend without using expression function
In-Reply-To: <1423346275659-4702929.post@n4.nabble.com>
References: <1423346275659-4702929.post@n4.nabble.com>
Message-ID: <CAP01uRm8q8ZweJxwQ3BiuvdNQezDwu5hxxaoRhLpj5q=BCgAjw@mail.gmail.com>

On Sat, Feb 7, 2015 at 4:57 PM, jgui001 <j.guilbert at auckland.ac.nz> wrote:
> I am plotting three sets of data on a single graph, and doing around 100+
> graphs.
> I can use the expression function to superscript the 2 but that seems to
> force me to manually put in the R squared values. Is there away around this?
>
> This code will show what it should look like this but with the 2
> superscripted
>
> r1<-c(0.59,0.9,0.6)
> plot(1:6)
> legend("topleft",
> legend=c(paste("G1 r=",r1[1]), paste("G2 r=",r1[2]), paste("G3 r=",r1[3])))

Replace the legend statement with:

leg <- as.list(parse(text = sprintf("G%d~r^2=%.2f", 1:3, r1)))
legend("topleft", legend = leg)



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From roman at gelzhaeuser.net  Sun Feb  8 23:20:34 2015
From: roman at gelzhaeuser.net (RomanGelzhaeuser)
Date: Sun, 8 Feb 2015 14:20:34 -0800 (PST)
Subject: [R] confidence interval for wilcox_test
Message-ID: <1423434034917-4702950.post@n4.nabble.com>

Hello,
When using wilcox_test from coin I got a sample estimator which does not lie
in the confidence interval.(see below) How is that possible? (The
documentation said that both referre to some kind of pseudo median but it
seems to be the same for both the confidence interval and the samplle
estimator)

> wilcox_test(ErgebnisBefragung~V,daten,conf.int=T)

        Asymptotic Wilcoxon Mann-Whitney Rank Sum Test

data:  ErgebnisBefragung by V (Burch, TVT)
Z = -2.0157, p-value = 0.04383
alternative hypothesis: true mu is not equal to 0
95 percent confidence interval:
 -2.056811e-05 -4.179582e-06
sample estimates:
difference in location 
         -3.251934e-05 

> 



--
View this message in context: http://r.789695.n4.nabble.com/confidence-interval-for-wilcox-test-tp4702950.html
Sent from the R help mailing list archive at Nabble.com.


From bbolker at gmail.com  Mon Feb  9 02:16:55 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 Feb 2015 01:16:55 +0000
Subject: [R]
	=?utf-8?q?Unable_to_use_=60eval=28parse=28text=29=29=27_in__n?=
	=?utf-8?q?lme=3A=3Alme?=
References: <1423417571305.5335@jhu.edu>
Message-ID: <loom.20150209T001628-315@post.gmane.org>

Ravi Varadhan <ravi.varadhan <at> jhu.edu> writes:
 
> I would like to run lme() on a number of response variables 
> in a dataframe in an automatic manner.  Bu, when I
> use eval(parse(text=yname)) to denote the LHS of the formula in lme(), 
> I get the following error message:
> 
> > require(nlme)
> 
> > mod2 <- with(subset(labdata2, Transplant_type!=0 & time >0), 
> lme(eval(parse(text=yname)) ~ time + 
> as.factor(gvhd), random = ~1|Patient, correlation = corAR1(), 
> method="ML", na.action=na.omit))
> Error in model.frame.default(formula = ~Patient + yname + time + gvhd,  :
>   variable lengths differ (found for 'yname')
> 
> The same usage works well in lme4::lmer without any problems.
>
> It seems that there is a problem in 
> how the formula object is evaluated in lme().  Is there an alternative way
> to do this?
> 
  
  While I'm pleased that lmer is more robust, I would say that the
safest/most robust way to do this would be:

ff <- reformulate("time","as.factor(gvhd)",response=yname)
dd <- subset(labdata2, Transplant_type!=0 & time >0)
lme(ff, random=~1|Patient, data=dd, ...)


From evan.cooch at gmail.com  Mon Feb  9 01:41:31 2015
From: evan.cooch at gmail.com (Evan Cooch)
Date: Sun, 08 Feb 2015 19:41:31 -0500
Subject: [R] specifying dimensions of a graphic (not the window...)
Message-ID: <54D8023B.9030109@gmail.com>

Greetings --

Graphics newbie (I generally don't use R for graphics, so if the 
question is 'obvious', point that out gently ;-)

I'm trying to use levelplot in the lattice package, to generate what 
I'll call a 'decision table', where optimal decisions (discrete, on the 
interval [0.0,0.5] by increments of 0.1) from a dynamic programming 
problem are plotted as a function of time since the time horizon. The 
'matrix' I'm trying to plot is 100 rows x 10 columns. While using the 
following works, more or less...

rgb.palette <- colorRampPalette(c("red", "green"), space = "rgb")
levelplot(t(results$policy), main="optimal harvest", xlab="time from 
end", ylab="state (N)", col.regions=rgb.palette(6), cuts=6, 
at=seq(0,0.5,0.1))


the rendered figure is waaaaay too narrow. I want to make the 
proportions of the 'levelplot' (what I usually call a 'heat map') square 
(or something else that I specify). I'm used to dedicated graphics 
applications wherew I simply grab the figure and resize it to whatever 
aspect ratio I want. Obviously, with R, I need to invoke some sort of 
command line argument.

In my searches, I've found a fair number of queries/answers about how to 
change the size of the graphics windows, but I could care lerss what the 
graphics window sizing is (presumably, it should adjust to whatever the 
size of the underlying graphic is). I want to 'hard code' the dimensions 
of the graphic itself, not the window it's rendered in.

I'm sure the answer is out there, but I've been unsuccessful at finding 
the magic keywords in my searches.

Thanks in advance.





	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Mon Feb  9 02:13:06 2015
From: evan.cooch at gmail.com (Evan Cooch)
Date: Sun, 08 Feb 2015 20:13:06 -0500
Subject: [R] specifying dimensions of a graphic (not the window...)
In-Reply-To: <54D8023B.9030109@gmail.com>
References: <54D8023B.9030109@gmail.com>
Message-ID: <54D809A2.7050708@gmail.com>


On 2/8/2015 7:41 PM, Evan Cooch wrote:
> Greetings --
>
> Graphics newbie (I generally don't use R for graphics, so if the 
> question is 'obvious', point that out gently ;-)
>
> I'm trying to use levelplot in the lattice package, to generate what 
> I'll call a 'decision table', where optimal decisions (discrete, on 
> the interval [0.0,0.5] by increments of 0.1) from a dynamic 
> programming problem are plotted as a function of time since the time 
> horizon. The 'matrix' I'm trying to plot is 100 rows x 10 columns. 
> While using the following works, more or less...
>
> rgb.palette <- colorRampPalette(c("red", "green"), space = "rgb")
> levelplot(t(results$policy), main="optimal harvest", xlab="time from 
> end", ylab="state (N)", col.regions=rgb.palette(6), cuts=6, 
> at=seq(0,0.5,0.1))
>
>

Sufficient solution to the problem for now -- adding the option 
aspect="fill" fills the window, and if I specify the size of the window, 
then this amounts to the same thing, more or less.

Seems kind of a backward way to do it. I'd have thought setting size of 
the graphic, and then having the window size change dynamically around 
said graphic, would have been more intuitive.




	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Feb  9 06:41:04 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 08 Feb 2015 21:41:04 -0800
Subject: [R] Zero length data block in hexView?
Message-ID: <1CE14B42-C0D1-4F41-8A94-D4F2DEAD2117@dcn.davis.CA.us>

The JPG data format uses something like the "markedBlock" defined in the hexView package, but some of the blocks are just markers with no data. Is there some simple way that I might have missed to explain this concept to hexView so the readFormat function can handle this? I have cobbled together some code to read part of the header but it doesn't parallel the format definition very well.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.


From AARTI.MUNJAL at ucdenver.edu  Sun Feb  8 09:02:36 2015
From: AARTI.MUNJAL at ucdenver.edu (Munjal, Aarti)
Date: Sun, 8 Feb 2015 08:02:36 +0000
Subject: [R] ASA John M. Chambers Statistical Software Award - 2015
Message-ID: <D0FC6601.8AE7%aarti.munjal@ucdenver.edu>

John M. Chambers Statistical Software Award - 2015

Statistical Computing Section

American Statistical Association


The Statistical Computing Section of the American Statistical Association announces the competition for the John M. Chambers Statistical Software Award. In 1998 the Association for Computing Machinery presented its Software System Award to John Chambers for the design and development of S. Dr. Chambers generously donated his award to the Statistical Computing Section to endow an annual prize for statistical software written by, or in collaboration with, an undergraduate or graduate student. The prize carries with it a cash award of $1000, plus a substantial allowance for travel to the annual Joint Statistical Meetings (JSM) where the award will be presented.


Teams of up to 3 people can participate in the competition, with the cash award being split among team members. The travel allowance will be given to just one individual in the team, who will be presented the award at JSM. To be eligible, the team must have designed and implemented a piece of statistical software. The individual within the team indicated to receive the travel allowance must have begun the development while a student, and must either currently be a student, or have completed all requirements for her/his last degree after January 1, 2014. To apply for the award, teams must provide the following materials:


Current CV's of all team members.


A letter from a faculty mentor at the academic institution of the individual indicated to receive the travel award. The letter should confirm that the individual had substantial participation in the development of the software, certify her/his student status when the software began to be developed (and either the current student status or the date of degree completion), and briefly discuss the importance of the software to statistical practice.


A brief, one to two page description of the software, summarizing what it does, how it does it, and why it is an important contribution. If the team member competing for the travel allowance has continued developing the software after finishing her/his studies, the description should indicate what was developed when the individual was a student and what has been added since.


An installable software package with its source code for use by the award committee. It should be accompanied by enough information to allow the judges to effectively use and evaluate the software (including its design considerations.) This information can be provided in a variety of ways, including but not limited to a user manual (paper or electronic), a paper, a URL, and online help to the system.


All materials must be in English. We prefer that electronic text be submitted in Postscript or PDF. The entries will be judged on a variety of dimensions, including the importance and relevance for statistical practice of the tasks performed by the software, ease of use, clarity of description, elegance and availability for use by the statistical community. Preference will be given to those entries that are grounded in software design rather than calculation. The decision of the award committee is final.


All application materials must be received by 5:00pm EST, Tuesday, February 17, 2015 at the address below. The winner will be announced in May and the award will be given at the 2015 Joint Statistical Meetings.


Chambers Statistical Software Award

c/o Aarti Munjal

Colorado School of Public Health

University of Colorado Denver

aarti.munjal at ucdenver.edu<mailto:aarti.munjal at ucdenver.edu>


	[[alternative HTML version deleted]]


From Lalitha.Kristipati at techmahindra.com  Mon Feb  9 11:33:38 2015
From: Lalitha.Kristipati at techmahindra.com (Lalitha Kristipati)
Date: Mon, 9 Feb 2015 10:33:38 +0000
Subject: [R] Database connection query
Message-ID: <9dea606947d54f4c8cbbbe8acf6cc050@BLREXCHMBX001.TechMahindra.com>

Hi,

I would like to know when to use drivers and when to use packages to connect to databases in R

Regards,
Lalitha Kristipati
Associate Software Engineer



============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Feb  9 12:01:02 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 9 Feb 2015 11:01:02 +0000
Subject: [R] suggestion for optimal plotting to show significant
 differences
In-Reply-To: <CAGx1TMCq1jXtuyofWv5nYC2So0RyKDp_734ze6rAQXztaxccnw@mail.gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F0E3@SRVEXCHMBX.precheza.cz>
	<CAGx1TMCq1jXtuyofWv5nYC2So0RyKDp_734ze6rAQXztaxccnw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F3E0@SRVEXCHMBX.precheza.cz>

Hallo Richard.

I tried your suggestion but it seems to be no better than simple ggplot. Let me extend the example a bit to 8 items which is more realistic.

item<-rep(letters[1:8], each=18)
day<-rep((0:5)*100, 24)
set<-rep(rep(1:3, each=6), 8)
test<-data.frame(item, day, set)
set.seed(111)
test$value<-(test$day/100+1)+rnorm(144)
test$value<-test$value+(as.numeric(test$item)*1.3)

Value is increasing during time (day) for each tested subject (item), each item is measured 3 times (set) each day.

Here is some graph
p<-ggplot(test, aes(x=day, y=value, colour=item))
p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))

I can do lm or aov, however I am not sure about proper formula.

fit<-lm(value~day, data=test)
summary(fit)
# this shows that value is increasing with day

fit<-lm(value~day/item, data=test)
summary(fit)
# this suggests that value is decreasing with day (which is wrong)

fit<-lm(value~day*item, data=test)
summary(fit)
# and this tells me that value is increasing with day and items have different intercepts but the same rate of growth (I hope I got it right).

I do not have your book available but I went through help pages.

Your interaction graph is not much better than ggplot.
I can do

interaction2wt(value ~ item * day, data=test)

which probably is closer to actual problem.

The basic problem is that increase of value with days is in fact not linear and actually it can increase in the beginning and then stagnate or it can stagnate in beginning and then increase. I am not aware of any way how to compare time behaviour of different items in such situations if I cannot state some common formula in which case I would use probably nlme.

Thank for your insight, I try to go through it more deeply.

Best regards
Petr


> -----Original Message-----
> From: Richard M. Heiberger [mailto:rmh at temple.edu]
> Sent: Friday, February 06, 2015 6:14 PM
> To: PIKAL Petr
> Cc: r-help at r-project.org
> Subject: Re: [R] suggestion for optimal plotting to show significant
> differences
>
> I would try one of these illustrations for starts.
> interaction2wt (two-way tables) is designed to be used with aov() for
> testing.
> interaction2wt shows all main effects and all two-way interactions for
> many factors.
>
>
>
> test <-
> structure(list(item = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A", "B"), class =
> "factor"), day = c(0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
> 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
> 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
> 300L, 400L, 500L), set = c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
> 2L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
> 2L, 3L, 3L, 3L, 3L, 3L, 3L), value = c(1.08163365169503,
> 2.61998412608805, 3.07820466606394, 4.44993419381934, 5.29163171545805,
> 6.29155990999293, -0.123163011367676, 2.07767236834003,
> 2.32537052874901, 3.09372794501084, 6.65273721166635, 5.92304962329131,
> 1.50504697705548, 2.66253728086866, 2.63420157418685, 2.78195098580416,
> 6.47578642973288, 5.89587443775143, 0.848864231485078,
> 1.27549677119713, 2.19573089053609, 2.45659926134292, 5.15424403414103,
> 5.4813151140983, 1.25731482647214, 2.09662105167973, 1.75954023316977,
> 4.81624002288939, 4.65029189325307, 6.39946904227214,
> 0.944996929887344, 1.74667265331284, 2.42956264345558,
> 5.17852980415141, 3.5453435965834, 6.9011238437191)), .Names =
> c("item", "day", "set", "value"), row.names = c(NA, -36L), class =
> "data.frame")
>
>
>
> library(HH)
>
> test$set <- factor(test$set)
> test$day <- factor(test$day)
> test$item <- factor(test$item)
>
> interaction2wt(value ~ item * day * set, data=test)
>
> test$item.day <- interaction(test$item, test$day)
> position(test$item.day) <- outer(c(-10,10),
> as.numeric(levels(test$day)), `+`)
>
> xyplot(value ~ as.position(item.day) | set, groups=item,
>         data=test, horizontal=FALSE, pch=c(17,16),
>         xlab="day",
>         scales=list(
>           x=list(
>             alternating=1,
>             at=levels(test$day), ## placement of tick labels and marks
>             tck=1)),
>         key=list(
>           text=list(c("A","B"), col=c("blue","red")),
>           points=list(pch=c(17, 16), col=c("blue","red")),
>        space="top", columns=2, border=TRUE),
>        layout=c(3,1))
>
>
> ## see also the examples in
> demo(package="HH", bwplot.examples)
>
> On Fri, Feb 6, 2015 at 6:09 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Dear all
> >
> > I would like to ask for your opinion about possible graphical
> representation of such data.
> >
> >> dput(test)
> > structure(list(item = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A", "B"), class
> =
> > "factor"), day = c(0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
> > 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
> > 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
> > 300L, 400L, 500L), set = c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 2L,
> > 2L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L), value = c(1.08163365169503,
> > 2.61998412608805, 3.07820466606394, 4.44993419381934,
> > 5.29163171545805, 6.29155990999293, -0.123163011367676,
> > 2.07767236834003, 2.32537052874901, 3.09372794501084,
> > 6.65273721166635, 5.92304962329131, 1.50504697705548,
> > 2.66253728086866, 2.63420157418685, 2.78195098580416,
> > 6.47578642973288, 5.89587443775143, 0.848864231485078,
> > 1.27549677119713, 2.19573089053609, 2.45659926134292,
> > 5.15424403414103, 5.4813151140983, 1.25731482647214,
> 2.09662105167973,
> > 1.75954023316977, 4.81624002288939, 4.65029189325307,
> > 6.39946904227214, 0.944996929887344, 1.74667265331284,
> > 2.42956264345558, 5.17852980415141, 3.5453435965834,
> > 6.9011238437191)), .Names = c("item", "day", "set", "value"),
> > row.names = c(NA, -36L), class = "data.frame")
> >>
> >
> > One option I came with is
> >
> > library(ggplot2)
> > p<-ggplot(test, aes(x=day, y=value, colour=item))
> > p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))
> >
> > but -
> > I have more items (around 5-10), and I want to show if the difference
> between items is or is not significant. The actual development of value
> with day is usually not linear nor growing steadily and actually I
> cannot usually evaluate some analytical equation for my data to compare
> equation parameters.
> >
> > I thought about boxplots, but there is not many repetitions and
> actually 5+ boxplots can be quite messy.
> >
> > I can plot only mean for each set and item but in that case I lose
> information if the difference is or is not significant.
> >
> > I appreciate any suggestion.
> >
> > Best regards
> > Petr
> >
> >
> >
> >
> >
> >
> >
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
> jsou ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> ze strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> > The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering
> into a contract in any time, for any reason, and without stating any
> reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer)
> excludes any acceptance of the offer on the part of the recipient
> containing any amendment or variation.
> > - the sender insists on that the respective contract is concluded
> only upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by
> the recipient.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From evgts at aueb.gr  Mon Feb  9 14:14:13 2015
From: evgts at aueb.gr (Evgenia)
Date: Mon, 9 Feb 2015 05:14:13 -0800 (PST)
Subject: [R] Save a plot with a name given as an argument in a function
Message-ID: <1423487653886-4702965.post@n4.nabble.com>

test<-function(data, TitleGraph){


pdf("TitleGraph.pdf",width=7,height=5)
plot(data)
dev.off()
}

test(cars <- c(1, 3, 6, 4, 9),TitleGraph="etc")

My problem is that I  want graph pdf being saved as etc and not as
Titlegraph.pdf




--
View this message in context: http://r.789695.n4.nabble.com/Save-a-plot-with-a-name-given-as-an-argument-in-a-function-tp4702965.html
Sent from the R help mailing list archive at Nabble.com.


From caciquesamurai at gmail.com  Mon Feb  9 14:24:11 2015
From: caciquesamurai at gmail.com (Raoni Rodrigues)
Date: Mon, 9 Feb 2015 11:24:11 -0200
Subject: [R] Donwload youtube videos
Message-ID: <CAGtwFe1=HBX8ayCjo63bnjO+y_XK8rbEdjZ2XafTmT3CudYBvQ@mail.gmail.com>

Hello R-helpers,

It is possible donwload youtube videos with R? I made a google search and
find no options to do that.

Thanks in advanced,

Raoni

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Mon Feb  9 14:30:47 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 09 Feb 2015 07:30:47 -0600
Subject: [R] Database connection query
In-Reply-To: <9dea606947d54f4c8cbbbe8acf6cc050@BLREXCHMBX001.TechMahindra.com>
References: <9dea606947d54f4c8cbbbe8acf6cc050@BLREXCHMBX001.TechMahindra.com>
Message-ID: <AE4784A7-0460-4757-A9D2-49508AB65F56@me.com>


> On Feb 9, 2015, at 4:33 AM, Lalitha Kristipati <Lalitha.Kristipati at techmahindra.com> wrote:
> 
> Hi,
> 
> I would like to know when to use drivers and when to use packages to connect to databases in R
> 
> Regards,
> Lalitha Kristipati
> Associate Software Engineer


In general, you will need both.

There is more information in the R Data Import/Export manual:

  http://cran.r-project.org/doc/manuals/r-release/R-data.html#Relational-databases

and there is a SIG list for R and DB specific subject matter:

  https://stat.ethz.ch/mailman/listinfo/r-sig-db

Regards,

Marc Schwartz


From jorgeivanvelez at gmail.com  Mon Feb  9 14:32:24 2015
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Tue, 10 Feb 2015 00:32:24 +1100
Subject: [R] Save a plot with a name given as an argument in a function
In-Reply-To: <1423487653886-4702965.post@n4.nabble.com>
References: <1423487653886-4702965.post@n4.nabble.com>
Message-ID: <CAKL8G3GcKwOXJudGxZNjZPzNNT+4REsazN9RY4eeq3fR1o45zg@mail.gmail.com>

Hi Evgenia,

Try

test2 <- function(data, TitleGraph){
pdf(paste0(TitleGraph, ".pdf"), width = 7, height = 5)
plot(data)
dev.off()
}

instead.  Take a look at ?paste0 for more information.

HTH,
Jorge.-


On Tue, Feb 10, 2015 at 12:14 AM, Evgenia <evgts at aueb.gr> wrote:

> test<-function(data, TitleGraph){
>
>
> pdf("TitleGraph.pdf",width=7,height=5)
> plot(data)
> dev.off()
> }
>
> test(cars <- c(1, 3, 6, 4, 9),TitleGraph="etc")
>
> My problem is that I  want graph pdf being saved as etc and not as
> Titlegraph.pdf
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Save-a-plot-with-a-name-given-as-an-argument-in-a-function-tp4702965.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From evgts at aueb.gr  Mon Feb  9 14:30:26 2015
From: evgts at aueb.gr (Evgenia)
Date: Mon, 9 Feb 2015 05:30:26 -0800 (PST)
Subject: [R] Save a plot with a name given as an argument in a function
In-Reply-To: <CAKL8G3GcKwOXJudGxZNjZPzNNT+4REsazN9RY4eeq3fR1o45zg@mail.gmail.com>
References: <1423487653886-4702965.post@n4.nabble.com>
	<CAKL8G3GcKwOXJudGxZNjZPzNNT+4REsazN9RY4eeq3fR1o45zg@mail.gmail.com>
Message-ID: <1423488626628-4702969.post@n4.nabble.com>

Thanks alot




--
View this message in context: http://r.789695.n4.nabble.com/Save-a-plot-with-a-name-given-as-an-argument-in-a-function-tp4702965p4702969.html
Sent from the R help mailing list archive at Nabble.com.


From gosia_jl at hotmail.com  Mon Feb  9 15:28:05 2015
From: gosia_jl at hotmail.com (Malgosia Lubczynska)
Date: Mon, 9 Feb 2015 14:28:05 +0000
Subject: [R] NA when trying to calculate AIC value for DLNM
Message-ID: <DUB118-W3855630EDFA3708447E644E5270@phx.gbl>

Dear all,
 
I am trying to run a sensitivity analysis for a DLNM combined with a case crossover design and select the best parameters based on AIC values for different model set-ups.
 
model <- glm(mortality ~ cb.temp + ns(soo, 7*7) + dow, family=quasipoisson(), my.data)
 
where cb.temp is the crossbasis matrix for the exposure (temperature)
 
However, the output for the AIC calculations equals NA.
Does anyone know how to obtain a correct AIC for a DLNM model?
 
Thank you,
Gosia
 
 
 		 	   		  
	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Mon Feb  9 15:44:34 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Mon, 9 Feb 2015 14:44:34 +0000
Subject: [R] Unable to use `eval(parse(text))' in  nlme::lme
Message-ID: <cdf2600432694952baa3f2fe5bac444b@DOM-EB1-2013.win.ad.jhu.edu>

Thanks to Rolf, Duncan, and Ben.

Ben, your suggestion worked (with a minor correction of concatenating the termlabels into a vector).

Here is the solution to those interested.

ff <- reformulate(termlabels=c("time","as.factor(gvhd)"), response=yname, intercept=TRUE)
dd <- subset(labdata2, Transplant_type!=0 & time >0)
lme(ff, random=~1|Patient, data=dd, correlation=corAR1(), na.action=na.omit)

Best,
Ravi

Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
Associate Professor
Department of Oncology
Division of Biostatistics & Bionformatics
Johns Hopkins University
550 N. Broadway
Baltimore, MD 21205
40-502-2619


	[[alternative HTML version deleted]]


From geoffrey_klein at etu.u-bourgogne.fr  Mon Feb  9 16:47:16 2015
From: geoffrey_klein at etu.u-bourgogne.fr (jeff6868)
Date: Mon, 9 Feb 2015 07:47:16 -0800 (PST)
Subject: [R] transpose a data frame according to a specific variable
Message-ID: <1423496836296-4702971.post@n4.nabble.com>

Dear R-users,

I would like to transpose a large data.frame according to a specific column.
Here's a reproductible example, it will be more understandable.

At the moment, my data.frame looks like this example:

DF <- data.frame(id=c("A","A","A","B","B","B","C","C","C"),
Year=c(2001,2002,2003,2002,2003,2004,2000,2001,2002),
Day=c(120,90,54,18,217,68,164,99,48))

I would like it being transformed to this (fake example again, still just
for being understandable):

finalDF <-
data.frame(id=c("A","B","C"),"2000"=c(NA,NA,164),"2001"=c(120,NA,99),
"2002"=c(90,18,48),"2003"=c(54,217,NA),"2004"=c(NA,68,NA))

Any ideas for doing this easily? I haven't found any good answer on the web.

Thanks for the help!




--
View this message in context: http://r.789695.n4.nabble.com/transpose-a-data-frame-according-to-a-specific-variable-tp4702971.html
Sent from the R help mailing list archive at Nabble.com.


From Pascal.Niklaus at ieu.uzh.ch  Mon Feb  9 17:26:40 2015
From: Pascal.Niklaus at ieu.uzh.ch (Pascal A. Niklaus)
Date: Mon, 09 Feb 2015 17:26:40 +0100
Subject: [R] Coordinate or top left corner + offset
Message-ID: <54D8DFC0.20203@ieu.uzh.ch>

Dear all,

I am struggling to add annotations to panels of a series of plots 
arranged on a page.

Basically, I'd like to add letters enumerating the panels 
("a","b","c",...), at a fixed distance from the top left corner of the 
plot's "box".

I succeeded partly with "mtext" (see below), but the "at" option is in 
user coordinates, which makes is difficult to specify a given offset 
from the corner (e.g. 1cm from top and left).

I tried grid's "npc" but these coordinates refer to the entire plot 
instead of the current inner plotting region.

Phrased differently, I'd like to place text (and ideally also be able to 
plot, e.g. a white disc to cover background items) at position 
(top-1cm,left+1cm)

Here is a minimum working example illustrating what I try to achieve:


pdf("example.pdf",width=15,height=15)

m <- rbind( c(0.1,0.9,0.1,0.6),
             c(0.1,0.9,0.6,0.9)
      );

split.screen(m)

screen(1);
par(mar=c(0,0,0,0));
plot(rnorm(10),rnorm(10),xlim=c(-5,5),xaxt="n",yaxt="n");
mtext(quote(bold(a)),side=3,line=-2.5,at=-5,cex=2.5)

screen(2);
par(mar=c(0,0,0,0));
plot(rnorm(10),rnorm(10),xlim=c(-3,3),xaxt="n",yaxt="n");
mtext(quote(bold(a)),side=3,line=-2.5,at=-3,cex=2.5)


close.screen(all.screens=TRUE)

dev.off()


Thanks for your help

Pascal Niklaus


From amado at cambrasabadell.org  Mon Feb  9 17:22:21 2015
From: amado at cambrasabadell.org (=?iso-8859-1?Q?Manel_Amado_Mart=ED?=)
Date: Mon, 9 Feb 2015 16:22:21 +0000
Subject: [R] 16. Database connection query (Lalitha Kristipati)
Message-ID: <DB3PR05MB026759920CBF12C2230167DC6270@DB3PR05MB026.eurprd05.prod.outlook.com>

Hi,

You can read the R Data Import / Export Manual, that comes within the help files for the R Standard. I recommend specially the chapter 4, where you'll found the generical guidelines to connect to databases. At 4.3, RODBC Package, or DBI packages should be right to you.

Regards,

Manel Amado i Mart?
Cap d'Assessoria de Comer? Interior
amado at cambrasabadell.org
Tel. 93 745 12 63 ? Fax 93 745 12 64 
? ? 
Av. Francesc Maci?, 35 ? 08206 Sabadell
Apt. corr. 119 ? www.cambrasabadell.org



-----Missatge original-----
De: R-help [mailto:r-help-bounces at r-project.org] En nom de r-help-request at r-project.org
Enviat: dilluns, 9 / febrer / 2015 12:00
Per a: r-help at r-project.org
Tema: R-help Digest, Vol 144, Issue 9

Send R-help mailing list submissions to
	r-help at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-help
or, via email, send a message with subject or body 'help' to
	r-help-request at r-project.org

You can reach the person managing the list at
	r-help-owner at r-project.org

When replying, please edit your Subject line so it is more specific than "Re: Contents of R-help digest..."


Today's Topics:

   1. Re: how to draw paired mosaic plot? (Michael Friendly)
   2. Re: how to draw paired mosaic plot? (Michael Friendly)
   3. Re: how to draw paired mosaic plot? (meng)
   4. Unable to use `eval(parse(text))' in  nlme::lme (Ravi Varadhan)
   5. Re: Unable to use `eval(parse(text))' in  nlme::lme (Rolf Turner)
   6. Re: Unable to use `eval(parse(text))' in  nlme::lme
      (Duncan Murdoch)
   7. Package build help (Glenn Schultz)
   8. Re: Package build help (Duncan Murdoch)
   9. Re: Superscript in legend without using expression function
      (Gabor Grothendieck)
  10. confidence interval for wilcox_test (RomanGelzhaeuser)
  11. Re: Unable to use `eval(parse(text))' in  nlme::lme (Ben Bolker)
  12. specifying dimensions of a graphic (not the window...)
      (Evan Cooch)
  13. Re: specifying dimensions of a graphic (not the window...)
      (Evan Cooch)
  14. Zero length data block in hexView? (Jeff Newmiller)
  15. ASA John M. Chambers Statistical Software Award - 2015
      (Munjal, Aarti)
  16. Database connection query (Lalitha Kristipati)


----------------------------------------------------------------------

Message: 1
Date: Sun, 8 Feb 2015 10:01:09 -0500
From: Michael Friendly <friendly at yorku.ca>
To: <r-help at stat.math.ethz.ch>
Cc: R help <r-help at r-project.org>
Subject: Re: [R] how to draw paired mosaic plot?
Message-ID: <54D77A35.1030108 at yorku.ca>
Content-Type: text/plain; charset="windows-1252"; format=flowed

You are looking for the pairs plot for table and other objects in the vcd package:

  ?vcd::pairs.table

It allows you to use various panel functions for the diagonal and off-diagonal plots

On 2/7/2015 9:50 AM, meng wrote:
> If there are many character variables,and I want to get the mosaic plot of every pair of each variable,how to do then?
>
>
> If the variables are numeric, I can use pairs to get paired scatter plot.
> But as to the character variables, how to get the "paired mosaic plot"?
>
>
> Many thanks.
>
>
>
>
>
> --
> QQ: 1733768559
>
>
>
>
>
> At 2015-02-07 17:04:26,"Jim Lemon" <drjimlemon at gmail.com> wrote:
>> Hi meng,
>> It's not too hard to get a mosaic plot of two character variables:
>>
>> x<-sample(LETTERS[1:3],20,TRUE)
>> y<-sample(LETTERS[24:26],20,TRUE)
>> mosaicplot(table(x,y))
>>
>> If you could tell us how the above is not what you want, perhaps a 
>> better suggestion will appear.
>>
>> Jim
>>
>>
>> On Sat, Feb 7, 2015 at 6:29 PM, meng <laomeng_3 at 163.com> wrote:
>>> If both x and y are all character, paired scatter plot is a little bit strange I think.
>>>
>>>
>>>
>>>
>>>
>>>
>>> --
>>> QQ: 1733768559
>>>
>>>
>>>
>>>
>>>
>>> At 2015-02-06 23:52:34,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>> On 06/02/2015 6:46 AM, meng wrote:
>>>>> Hi all:
>>>>> If there are two numeric variable:x,y, and I can get paired scatter plot by function "pairs".But if x and y are character, and I want to get paired mosaic plot,which function should be used then?
>>>>
>>>> Why not pairs, with a custom panel function?  There are examples on 
>>>> the help page, though I don't think a mosaic plot is there.
>>>>
>>>> Duncan Murdoch
>>>>>
>>>>>
>>>>> Many thanks!
>>>>> My best.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> QQ: 1733768559
>>>>>
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide 
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA



------------------------------

Message: 2
Date: Sun, 08 Feb 2015 10:01:09 -0500
From: Michael Friendly <friendly at yorku.ca>
To: meng <laomeng_3 at 163.com>, Jim Lemon <drjimlemon at gmail.com>
Cc: R help <r-help at r-project.org>
Subject: Re: [R] how to draw paired mosaic plot?
Message-ID: <54D77A35.1030108 at yorku.ca>
Content-Type: text/plain; charset=windows-1252; format=flowed

You are looking for the pairs plot for table and other objects in the vcd package:

  ?vcd::pairs.table

It allows you to use various panel functions for the diagonal and off-diagonal plots

On 2/7/2015 9:50 AM, meng wrote:
> If there are many character variables,and I want to get the mosaic plot of every pair of each variable,how to do then?
>
>
> If the variables are numeric, I can use pairs to get paired scatter plot.
> But as to the character variables, how to get the "paired mosaic plot"?
>
>
> Many thanks.
>
>
>
>
>
> --
> QQ: 1733768559
>
>
>
>
>
> At 2015-02-07 17:04:26,"Jim Lemon" <drjimlemon at gmail.com> wrote:
>> Hi meng,
>> It's not too hard to get a mosaic plot of two character variables:
>>
>> x<-sample(LETTERS[1:3],20,TRUE)
>> y<-sample(LETTERS[24:26],20,TRUE)
>> mosaicplot(table(x,y))
>>
>> If you could tell us how the above is not what you want, perhaps a 
>> better suggestion will appear.
>>
>> Jim
>>
>>
>> On Sat, Feb 7, 2015 at 6:29 PM, meng <laomeng_3 at 163.com> wrote:
>>> If both x and y are all character, paired scatter plot is a little bit strange I think.
>>>
>>>
>>>
>>>
>>>
>>>
>>> --
>>> QQ: 1733768559
>>>
>>>
>>>
>>>
>>>
>>> At 2015-02-06 23:52:34,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>> On 06/02/2015 6:46 AM, meng wrote:
>>>>> Hi all:
>>>>> If there are two numeric variable:x,y, and I can get paired scatter plot by function "pairs".But if x and y are character, and I want to get paired mosaic plot,which function should be used then?
>>>>
>>>> Why not pairs, with a custom panel function?  There are examples on 
>>>> the help page, though I don't think a mosaic plot is there.
>>>>
>>>> Duncan Murdoch
>>>>>
>>>>>
>>>>> Many thanks!
>>>>> My best.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> QQ: 1733768559
>>>>>
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide 
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA



------------------------------

Message: 3
Date: Mon, 9 Feb 2015 00:23:57 +0800 (CST)
From: meng  <laomeng_3 at 163.com>
To: "Michael Friendly" <friendly at yorku.ca>
Cc: R help <r-help at r-project.org>
Subject: Re: [R] how to draw paired mosaic plot?
Message-ID: <613a4eff.b2c.14b6a012f45.Coremail.laomeng_3 at 163.com>
Content-Type: text/plain; charset="UTF-8"

Many thanks.





--
QQ: 1733768559





At 2015-02-08 23:01:09,"Michael Friendly" <friendly at yorku.ca> wrote:
>You are looking for the pairs plot for table and other objects in the 
>vcd package:
>
>  ?vcd::pairs.table
>
>It allows you to use various panel functions for the diagonal and 
>off-diagonal plots
>
>On 2/7/2015 9:50 AM, meng wrote:
>> If there are many character variables,and I want to get the mosaic plot of every pair of each variable,how to do then?
>>
>>
>> If the variables are numeric, I can use pairs to get paired scatter plot.
>> But as to the character variables, how to get the "paired mosaic plot"?
>>
>>
>> Many thanks.
>>
>>
>>
>>
>>
>> --
>> QQ: 1733768559
>>
>>
>>
>>
>>
>> At 2015-02-07 17:04:26,"Jim Lemon" <drjimlemon at gmail.com> wrote:
>>> Hi meng,
>>> It's not too hard to get a mosaic plot of two character variables:
>>>
>>> x<-sample(LETTERS[1:3],20,TRUE)
>>> y<-sample(LETTERS[24:26],20,TRUE)
>>> mosaicplot(table(x,y))
>>>
>>> If you could tell us how the above is not what you want, perhaps a 
>>> better suggestion will appear.
>>>
>>> Jim
>>>
>>>
>>> On Sat, Feb 7, 2015 at 6:29 PM, meng <laomeng_3 at 163.com> wrote:
>>>> If both x and y are all character, paired scatter plot is a little bit strange I think.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> QQ: 1733768559
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> At 2015-02-06 23:52:34,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>>>> On 06/02/2015 6:46 AM, meng wrote:
>>>>>> Hi all:
>>>>>> If there are two numeric variable:x,y, and I can get paired scatter plot by function "pairs".But if x and y are character, and I want to get paired mosaic plot,which function should be used then?
>>>>>
>>>>> Why not pairs, with a custom panel function?  There are examples 
>>>>> on the help page, though I don't think a mosaic plot is there.
>>>>>
>>>>> Duncan Murdoch
>>>>>>
>>>>>>
>>>>>> Many thanks!
>>>>>> My best.
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> QQ: 1733768559
>>>>>>
>>>>>>
>>>>>>       [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide 
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> 	[[alternative HTML version deleted]]
>>
>
>
>-- 
>Michael Friendly     Email: friendly AT yorku DOT ca
>Professor, Psychology Dept. & Chair, Quantitative Methods
>York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>4700 Keele Street    Web:   http://www.datavis.ca
>Toronto, ONT  M3J 1P3 CANADA

	[[alternative HTML version deleted]]


------------------------------

Message: 4
Date: Sun, 8 Feb 2015 17:46:18 +0000
From: Ravi Varadhan <ravi.varadhan at jhu.edu>
To: R-Help <r-help at r-project.org>
Subject: [R] Unable to use `eval(parse(text))' in  nlme::lme
Message-ID: <1423417571305.5335 at jhu.edu>
Content-Type: text/plain; charset="UTF-8"

Hi,

I would like to run lme() on a number of response variables in a dataframe in an automatic manner.  Bu, when I use eval(parse(text=yname)) to denote the LHS of the formula in lme(), I get the following error message:



> require(nlme)



> mod2 <- with(subset(labdata2, Transplant_type!=0 & time >0), 
> lme(eval(parse(text=yname)) ~ time +  as.factor(gvhd), random = 
> ~1|Patient, correlation = corAR1(), method="ML", na.action=na.omit))
Error in model.frame.default(formula = ~Patient + yname + time + gvhd,  :
  variable lengths differ (found for 'yname')

The same usage works well in lme4::lmer without any problems.



It seems that there is a problem in how the formula object is evaluated in lme().  Is there an alternative way to do this?



Thank you,

Ravi

	[[alternative HTML version deleted]]



------------------------------

Message: 5
Date: Mon, 09 Feb 2015 09:49:41 +1300
From: Rolf Turner <r.turner at auckland.ac.nz>
To: Ravi Varadhan <ravi.varadhan at jhu.edu>, R-Help
	<r-help at r-project.org>
Subject: Re: [R] Unable to use `eval(parse(text))' in  nlme::lme
Message-ID: <54D7CBE5.9020002 at auckland.ac.nz>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

On 09/02/15 06:46, Ravi Varadhan wrote:
> Hi,
>
> I would like to run lme() on a number of response variables in a 
> dataframe in an automatic manner.  Bu, when I use
> eval(parse(text=yname)) to denote the LHS of the formula in lme(), I 
> get the following error message:
>
>
>
>> require(nlme)
>
>
>
>> mod2 <- with(subset(labdata2, Transplant_type!=0 & time >0),
>> lme(eval(parse(text=yname)) ~ time +  as.factor(gvhd), random = 
>> ~1|Patient, correlation = corAR1(), method="ML",
>> na.action=na.omit))
> Error in model.frame.default(formula = ~Patient + yname + time + gvhd, 
> : variable lengths differ (found for 'yname')
>
> The same usage works well in lme4::lmer without any problems.
>
>
>
> It seems that there is a problem in how the formula object is 
> evaluated in lme().  Is there an alternative way to do this?

What about trying some'at lahk:

fmla <- as.formula(paste(yname,"~ time + as.factor(gvhd)"))
mod2 <- with(...., lme(fmla, random = ....))

Also you would probably be better off using the data argument rather then using with(); this could have some impact on the environment in which the formula is evaluated.

Just stabbing in the dark here since you did not provide a reproducible example.

cheers,

Rolf Turner

--
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619



------------------------------

Message: 6
Date: Sun, 08 Feb 2015 16:14:55 -0500
From: Duncan Murdoch <murdoch.duncan at gmail.com>
To: Rolf Turner <r.turner at auckland.ac.nz>,	Ravi Varadhan
	<ravi.varadhan at jhu.edu>, R-Help <r-help at r-project.org>
Subject: Re: [R] Unable to use `eval(parse(text))' in  nlme::lme
Message-ID: <54D7D1CF.2010205 at gmail.com>
Content-Type: text/plain; charset=windows-1252

On 08/02/2015 3:49 PM, Rolf Turner wrote:
> On 09/02/15 06:46, Ravi Varadhan wrote:
>> Hi,
>>
>> I would like to run lme() on a number of response variables in a
>> dataframe in an automatic manner.  Bu, when I use
>> eval(parse(text=yname)) to denote the LHS of the formula in lme(), I
>> get the following error message:
>>
>>
>>
>>> require(nlme)
>>
>>
>>
>>> mod2 <- with(subset(labdata2, Transplant_type!=0 & time >0),
>>> lme(eval(parse(text=yname)) ~ time +  as.factor(gvhd), random =
>>> ~1|Patient, correlation = corAR1(), method="ML",
>>> na.action=na.omit))
>> Error in model.frame.default(formula = ~Patient + yname + time +
>> gvhd,  : variable lengths differ (found for 'yname')
>>
>> The same usage works well in lme4::lmer without any problems.
>>
>>
>>
>> It seems that there is a problem in how the formula object is
>> evaluated in lme().  Is there an alternative way to do this?
> 
> What about trying some'at lahk:
> 
> fmla <- as.formula(paste(yname,"~ time + as.factor(gvhd)"))
> mod2 <- with(...., lme(fmla, random = ....))
> 
> Also you would probably be better off using the data argument rather 
> then using with(); this could have some impact on the environment in 
> which the formula is evaluated.

Formulas are a little tricky:  effectively they are evaluated twice.  If
you type something like

y ~ x

(or eval(parse(text="y ~ x")), or as.formula("y ~ x")) then a formula
object is created.  That object remembers the environment in which it
was created, so later when the modelling function uses it, the x and y
variables are evaluated in the original context.

In your example, as.formula() will convert the string to a formula, and
attach the current environment.  So you'd better hope that whatever
variable yname names, as well as time and gvhd, are all available there.

Duncan Murdoch

> 
> Just stabbing in the dark here since you did not provide a reproducible 
> example.
> 
> cheers,
> 
> Rolf Turner
>



------------------------------

Message: 7
Date: Sun, 08 Feb 2015 21:06:03 +0000 (GMT)
From: Glenn Schultz <glennmschultz at me.com>
To: R Help R <r-help at r-project.org>
Subject: [R] Package build help
Message-ID: <b3a194a5-fe72-4202-9999-adf41b5a88c0 at me.com>
Content-Type: text/plain; charset=windows-1252; format=flowed

Hello All,

I am in the final stages of building my first package "BondLab" and the check throughs the following warning. ?I think this is namespace thing. ?I have not done anything with the namespace at this point. ?I am turning my attention to the namespace now. ?Am I correct this can be a handled by the namespace?

Thanks,
Glenn

Found the following significant warnings:
? Warning: replacing previous import by ?lubridate::duration? when loading ?BondLab?
? Warning: replacing previous import by ?plyr::here? when loading ?BondLab?

------------------------------

Message: 8
Date: Sun, 08 Feb 2015 18:15:45 -0500
From: Duncan Murdoch <murdoch.duncan at gmail.com>
To: Glenn Schultz <glennmschultz at me.com>, R Help R
	<r-help at r-project.org>
Subject: Re: [R] Package build help
Message-ID: <54D7EE21.7030505 at gmail.com>
Content-Type: text/plain; charset=windows-1252

On 08/02/2015 4:06 PM, Glenn Schultz wrote:
> Hello All,
> 
> I am in the final stages of building my first package "BondLab" and the check throughs the following warning.  I think this is namespace thing.  I have not done anything with the namespace at this point.  I am turning my attention to the namespace now.  Am I correct this can be a handled by the namespace?
> 

I would guess you have imported the lubridate and plyr packages, and
also defined your own duration() and here() functions, hiding theirs.

Duncan Murdoch

> Thanks,
> Glenn
> 
> Found the following significant warnings:
>   Warning: replacing previous import by ?lubridate::duration? when loading ?BondLab?
>   Warning: replacing previous import by ?plyr::here? when loading ?BondLab?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



------------------------------

Message: 9
Date: Sun, 8 Feb 2015 19:08:56 -0500
From: Gabor Grothendieck <ggrothendieck at gmail.com>
To: jgui001 <j.guilbert at auckland.ac.nz>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Subject: Re: [R] Superscript in legend without using expression
	function
Message-ID:
	<CAP01uRm8q8ZweJxwQ3BiuvdNQezDwu5hxxaoRhLpj5q=BCgAjw at mail.gmail.com>
Content-Type: text/plain; charset=UTF-8

On Sat, Feb 7, 2015 at 4:57 PM, jgui001 <j.guilbert at auckland.ac.nz> wrote:
> I am plotting three sets of data on a single graph, and doing around 100+
> graphs.
> I can use the expression function to superscript the 2 but that seems to
> force me to manually put in the R squared values. Is there away around this?
>
> This code will show what it should look like this but with the 2
> superscripted
>
> r1<-c(0.59,0.9,0.6)
> plot(1:6)
> legend("topleft",
> legend=c(paste("G1 r=",r1[1]), paste("G2 r=",r1[2]), paste("G3 r=",r1[3])))

Replace the legend statement with:

leg <- as.list(parse(text = sprintf("G%d~r^2=%.2f", 1:3, r1)))
legend("topleft", legend = leg)



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com



------------------------------

Message: 10
Date: Sun, 8 Feb 2015 14:20:34 -0800 (PST)
From: RomanGelzhaeuser <roman at gelzhaeuser.net>
To: r-help at r-project.org
Subject: [R] confidence interval for wilcox_test
Message-ID: <1423434034917-4702950.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

Hello,
When using wilcox_test from coin I got a sample estimator which does not lie
in the confidence interval.(see below) How is that possible? (The
documentation said that both referre to some kind of pseudo median but it
seems to be the same for both the confidence interval and the samplle
estimator)

> wilcox_test(ErgebnisBefragung~V,daten,conf.int=T)

        Asymptotic Wilcoxon Mann-Whitney Rank Sum Test

data:  ErgebnisBefragung by V (Burch, TVT)
Z = -2.0157, p-value = 0.04383
alternative hypothesis: true mu is not equal to 0
95 percent confidence interval:
 -2.056811e-05 -4.179582e-06
sample estimates:
difference in location 
         -3.251934e-05 

> 



--
View this message in context: http://r.789695.n4.nabble.com/confidence-interval-for-wilcox-test-tp4702950.html
Sent from the R help mailing list archive at Nabble.com.



------------------------------

Message: 11
Date: Mon, 9 Feb 2015 01:16:55 +0000
From: Ben Bolker <bbolker at gmail.com>
To: <r-help at stat.math.ethz.ch>
Subject: Re: [R] Unable to use `eval(parse(text))' in  nlme::lme
Message-ID: <loom.20150209T001628-315 at post.gmane.org>
Content-Type: text/plain; charset="us-ascii"

Ravi Varadhan <ravi.varadhan <at> jhu.edu> writes:

> I would like to run lme() on a number of response variables 
> in a dataframe in an automatic manner.  Bu, when I
> use eval(parse(text=yname)) to denote the LHS of the formula in lme(),
> I get the following error message:
> 
> > require(nlme)
> 
> > mod2 <- with(subset(labdata2, Transplant_type!=0 & time >0), 
> lme(eval(parse(text=yname)) ~ time + 
> as.factor(gvhd), random = ~1|Patient, correlation = corAR1(), 
> method="ML", na.action=na.omit))
> Error in model.frame.default(formula = ~Patient + yname + time + gvhd,  :
>   variable lengths differ (found for 'yname')
> 
> The same usage works well in lme4::lmer without any problems.
>
> It seems that there is a problem in 
> how the formula object is evaluated in lme().  Is there an alternative way
> to do this?
> 
  
  While I'm pleased that lmer is more robust, I would say that the
safest/most robust way to do this would be:

ff <- reformulate("time","as.factor(gvhd)",response=yname)
dd <- subset(labdata2, Transplant_type!=0 & time >0)
lme(ff, random=~1|Patient, data=dd, ...)



------------------------------

Message: 12
Date: Sun, 08 Feb 2015 19:41:31 -0500
From: Evan Cooch <evan.cooch at gmail.com>
To: r-help at r-project.org
Subject: [R] specifying dimensions of a graphic (not the window...)
Message-ID: <54D8023B.9030109 at gmail.com>
Content-Type: text/plain; charset="UTF-8"

Greetings --

Graphics newbie (I generally don't use R for graphics, so if the 
question is 'obvious', point that out gently ;-)

I'm trying to use levelplot in the lattice package, to generate what 
I'll call a 'decision table', where optimal decisions (discrete, on the 
interval [0.0,0.5] by increments of 0.1) from a dynamic programming 
problem are plotted as a function of time since the time horizon. The 
'matrix' I'm trying to plot is 100 rows x 10 columns. While using the 
following works, more or less...

rgb.palette <- colorRampPalette(c("red", "green"), space = "rgb")
levelplot(t(results$policy), main="optimal harvest", xlab="time from 
end", ylab="state (N)", col.regions=rgb.palette(6), cuts=6, 
at=seq(0,0.5,0.1))


the rendered figure is waaaaay too narrow. I want to make the 
proportions of the 'levelplot' (what I usually call a 'heat map') square 
(or something else that I specify). I'm used to dedicated graphics 
applications wherew I simply grab the figure and resize it to whatever 
aspect ratio I want. Obviously, with R, I need to invoke some sort of 
command line argument.

In my searches, I've found a fair number of queries/answers about how to 
change the size of the graphics windows, but I could care lerss what the 
graphics window sizing is (presumably, it should adjust to whatever the 
size of the underlying graphic is). I want to 'hard code' the dimensions 
of the graphic itself, not the window it's rendered in.

I'm sure the answer is out there, but I've been unsuccessful at finding 
the magic keywords in my searches.

Thanks in advance.





	[[alternative HTML version deleted]]



------------------------------

Message: 13
Date: Sun, 08 Feb 2015 20:13:06 -0500
From: Evan Cooch <evan.cooch at gmail.com>
To: r-help at r-project.org
Subject: Re: [R] specifying dimensions of a graphic (not the
	window...)
Message-ID: <54D809A2.7050708 at gmail.com>
Content-Type: text/plain; charset="UTF-8"


On 2/8/2015 7:41 PM, Evan Cooch wrote:
> Greetings --
>
> Graphics newbie (I generally don't use R for graphics, so if the 
> question is 'obvious', point that out gently ;-)
>
> I'm trying to use levelplot in the lattice package, to generate what 
> I'll call a 'decision table', where optimal decisions (discrete, on 
> the interval [0.0,0.5] by increments of 0.1) from a dynamic 
> programming problem are plotted as a function of time since the time 
> horizon. The 'matrix' I'm trying to plot is 100 rows x 10 columns. 
> While using the following works, more or less...
>
> rgb.palette <- colorRampPalette(c("red", "green"), space = "rgb")
> levelplot(t(results$policy), main="optimal harvest", xlab="time from
> end", ylab="state (N)", col.regions=rgb.palette(6), cuts=6, 
> at=seq(0,0.5,0.1))
>
>

Sufficient solution to the problem for now -- adding the option 
aspect="fill" fills the window, and if I specify the size of the window,
then this amounts to the same thing, more or less.

Seems kind of a backward way to do it. I'd have thought setting size of 
the graphic, and then having the window size change dynamically around 
said graphic, would have been more intuitive.




	[[alternative HTML version deleted]]



------------------------------

Message: 14
Date: Sun, 08 Feb 2015 21:41:04 -0800
From: Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
To: R-help <r-help at r-project.org>
Cc: paul at stat.auckland.ac.nz
Subject: [R] Zero length data block in hexView?
Message-ID: <1CE14B42-C0D1-4F41-8A94-D4F2DEAD2117 at dcn.davis.CA.us>
Content-Type: text/plain; charset=UTF-8

The JPG data format uses something like the "markedBlock" defined in the hexView package, but some of the blocks are just markers with no data. Is there some simple way that I might have missed to explain this concept to hexView so the readFormat function can handle this? I have cobbled together some code to read part of the header but it doesn't parallel the format definition very well.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.



------------------------------

Message: 15
Date: Sun, 8 Feb 2015 08:02:36 +0000
From: "Munjal, Aarti" <AARTI.MUNJAL at ucdenver.edu>
To: "r-help at r-project.org" <r-help at r-project.org>
Subject: [R] ASA John M. Chambers Statistical Software Award - 2015
Message-ID: <D0FC6601.8AE7%aarti.munjal at ucdenver.edu>
Content-Type: text/plain; charset="UTF-8"

John M. Chambers Statistical Software Award - 2015

Statistical Computing Section

American Statistical Association


The Statistical Computing Section of the American Statistical Association announces the competition for the John M. Chambers Statistical Software Award. In 1998 the Association for Computing Machinery presented its Software System Award to John Chambers for the design and development of S. Dr. Chambers generously donated his award to the Statistical Computing Section to endow an annual prize for statistical software written by, or in collaboration with, an undergraduate or graduate student. The prize carries with it a cash award of $1000, plus a substantial allowance for travel to the annual Joint Statistical Meetings (JSM) where the award will be presented.


Teams of up to 3 people can participate in the competition, with the cash award being split among team members. The travel allowance will be given to just one individual in the team, who will be presented the award at JSM. To be eligible, the team must have designed and implemented a piece of statistical software. The individual within the team indicated to receive the travel allowance must have begun the development while a student, and must either currently be a student, or have completed all requirements for her/his last degree after January 1, 2014. To apply for the award, teams must provide the following materials:


Current CV's of all team members.


A letter from a faculty mentor at the academic institution of the individual indicated to receive the travel award. The letter should confirm that the individual had substantial participation in the development of the software, certify her/his student status when the software began to be developed (and either the current student status or the date of degree completion), and briefly discuss the importance of the software to statistical practice.


A brief, one to two page description of the software, summarizing what it does, how it does it, and why it is an important contribution. If the team member competing for the travel allowance has continued developing the software after finishing her/his studies, the description should indicate what was developed when the individual was a student and what has been added since.


An installable software package with its source code for use by the award committee. It should be accompanied by enough information to allow the judges to effectively use and evaluate the software (including its design considerations.) This information can be provided in a variety of ways, including but not limited to a user manual (paper or electronic), a paper, a URL, and online help to the system.


All materials must be in English. We prefer that electronic text be submitted in Postscript or PDF. The entries will be judged on a variety of dimensions, including the importance and relevance for statistical practice of the tasks performed by the software, ease of use, clarity of description, elegance and availability for use by the statistical community. Preference will be given to those entries that are grounded in software design rather than calculation. The decision of the award committee is final.


All application materials must be received by 5:00pm EST, Tuesday, February 17, 2015 at the address below. The winner will be announced in May and the award will be given at the 2015 Joint Statistical Meetings.


Chambers Statistical Software Award

c/o Aarti Munjal

Colorado School of Public Health

University of Colorado Denver

aarti.munjal at ucdenver.edu<mailto:aarti.munjal at ucdenver.edu>


	[[alternative HTML version deleted]]



------------------------------

Message: 16
Date: Mon, 9 Feb 2015 10:33:38 +0000
From: Lalitha Kristipati <Lalitha.Kristipati at techmahindra.com>
To: "'R-help at r-project.org'" <R-help at r-project.org>
Subject: [R] Database connection query
Message-ID:
	<9dea606947d54f4c8cbbbe8acf6cc050 at BLREXCHMBX001.TechMahindra.com>
Content-Type: text/plain; charset="UTF-8"

Hi,

I would like to know when to use drivers and when to use packages to connect to databases in R

Regards,
Lalitha Kristipati
Associate Software Engineer



============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


	[[alternative HTML version deleted]]



------------------------------

Subject: Digest Footer

_______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

------------------------------

End of R-help Digest, Vol 144, Issue 9


From ripley at stats.ox.ac.uk  Mon Feb  9 18:24:39 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 09 Feb 2015 17:24:39 +0000
Subject: [R] NA when trying to calculate AIC value for DLNM
In-Reply-To: <DUB118-W3855630EDFA3708447E644E5270@phx.gbl>
References: <DUB118-W3855630EDFA3708447E644E5270@phx.gbl>
Message-ID: <54D8ED57.3030803@stats.ox.ac.uk>

On 09/02/2015 14:28, Malgosia Lubczynska wrote:
> Dear all,
>
> I am trying to run a sensitivity analysis for a DLNM combined with a case crossover design and select the best parameters based on AIC values for different model set-ups.
>
> model <- glm(mortality ~ cb.temp + ns(soo, 7*7) + dow, family=quasipoisson(), my.data)
>
> where cb.temp is the crossbasis matrix for the exposure (temperature)
>
> However, the output for the AIC calculations equals NA.
> Does anyone know how to obtain a correct AIC for a DLNM model?

To have an AIC you need to do maximum-likelihood fitting (and have a 
likelihood ...), something a quasi-Poisson fit does not give you.

>
> Thank you,
> Gosia
>
>
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From david at revolutionanalytics.com  Mon Feb  9 18:54:57 2015
From: david at revolutionanalytics.com (David Smith)
Date: Mon, 9 Feb 2015 11:54:57 -0600
Subject: [R] Revolutions blog: January 2015 roundup
Message-ID: <CABgvEC9W2Rc7VZLkYDCLF0dwKiA0-nU7DxeDUdOdAgAizuKrhA@mail.gmail.com>

For more than 6 years, Revolution Analytics staff and guests have
written about R every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of January:

Slides on reproducible data analysis with Revolution R Open and the
checkpoint package: http://bit.ly/16GIEiM

A review of a recent Bay Area R User Group meetup, featuring Hadley
Wickham, Ryan Hafen and Nick Elprin: http://bit.ly/16GICrh

In an article at opensource.com, I explain why now is a great time to
learn R and provide some resources to get started:
http://bit.ly/16GIEiL

Norm Matloff reviews the state of the art in parallel programming with
GPUs in R: http://bit.ly/16GICrg

A tongue-in-cheek R script provides excuses for when your P-values
aren't *quite* significant enough: http://bit.ly/16GIEiK

Microsoft will acquire Revolution Analytics. I explain what this means
for Revolution R users and the R community generally
(http://bit.ly/16GICHu), and review the media coverage
(http://bit.ly/16GICrg).

Joe Rickert reviews the state of R integration with Spark: http://bit.ly/16GICHx

Tufte's classic weather data visualization recreated in R for Dayton,
Chicago and New York City: http://bit.ly/16GIEiP

A new R-based course, Statistical Computing for Biomedical Data
Analytics: http://bit.ly/16GICHy

An introductory tutorial for R, aimed at budding econometricians:
http://bit.ly/16GICHz

Harvard offers a free 5-week online course on R: http://bit.ly/16GICHA

A look at, and some resources for using, R's base graphics
capabilities: http://bit.ly/16GIEiQ

An update to the "R is Hot" whitepaper with new applications and
statistics on R usage: http://bit.ly/16GIEiR

Interactive R notebooks with Domino Data Lab: http://bit.ly/16GIEiS

The dplyr package has been updated with new data manipulation commands
for filters, joins and set operations: http://bit.ly/16GICHC

Kudos to the rapidly-growing BioConductor project, recently featured
in Nature: http://bit.ly/16GIEiT

An online R-based application evaluates your risk of flooding:
http://bit.ly/16GICHB

Twitter releases an R package for anomaly detection in time series:
http://bit.ly/16GICHD

A Revolution Analytics consultant describes how he used R to visualize
soil attributes using the ggmap package: http://bit.ly/16GIEz8

Yihui Xie created a voice-controlled R graphics application:
http://bit.ly/16GICHE

Video of talks by Trevor Hastie (on machine learning) and John
Chambers (reminiscing on his time at Bell Labs): http://bit.ly/16GICHF

The top 10 posts on the Revolutions blog from 2014: http://bit.ly/16GICHG

General interest stories (not related to R) in the past month
included: a comeback for real and virtual pinball
(http://bit.ly/16GIEza), a geometry construction game
(http://bit.ly/16GICHH), a typography game (http://bit.ly/16GICHI),
and a musical 'tribute' to Shia LeBoeuf (http://bit.ly/16GIEzc).

Meeting times for local R user groups (http://bit.ly/eC5YQe) can be
found on the updated R Community Calendar at: http://bit.ly/bb3naW

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com or via Twitter (I'm
@revodavid).

Cheers,
# David

-- 
David M Smith <david at revolutionanalytics.com>
Chief Community Officer, Revolution Analytics
http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Chicago IL, USA)
Twitter: @revodavid


From djmuser at gmail.com  Mon Feb  9 19:10:29 2015
From: djmuser at gmail.com (Dennis Murphy)
Date: Mon, 9 Feb 2015 10:10:29 -0800
Subject: [R] transpose a data frame according to a specific variable
In-Reply-To: <1423496836296-4702971.post@n4.nabble.com>
References: <1423496836296-4702971.post@n4.nabble.com>
Message-ID: <CADv2QyG=gJN1MrZsA+jK8E5ZNq5W5ux0HK3a3cLbJ629CHaQ6g@mail.gmail.com>

One way is to use the reshape2 package:

library(reshape2)
dcast(DF, id ~ Year, value.var = "Day")


Dennis

On Mon, Feb 9, 2015 at 7:47 AM, jeff6868
<geoffrey_klein at etu.u-bourgogne.fr> wrote:
> Dear R-users,
>
> I would like to transpose a large data.frame according to a specific column.
> Here's a reproductible example, it will be more understandable.
>
> At the moment, my data.frame looks like this example:
>
> DF <- data.frame(id=c("A","A","A","B","B","B","C","C","C"),
> Year=c(2001,2002,2003,2002,2003,2004,2000,2001,2002),
> Day=c(120,90,54,18,217,68,164,99,48))
>
> I would like it being transformed to this (fake example again, still just
> for being understandable):
>
> finalDF <-
> data.frame(id=c("A","B","C"),"2000"=c(NA,NA,164),"2001"=c(120,NA,99),
> "2002"=c(90,18,48),"2003"=c(54,217,NA),"2004"=c(NA,68,NA))
>
> Any ideas for doing this easily? I haven't found any good answer on the web.
>
> Thanks for the help!
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/transpose-a-data-frame-according-to-a-specific-variable-tp4702971.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erich.neuwirth at univie.ac.at  Mon Feb  9 19:27:51 2015
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Mon, 9 Feb 2015 19:27:51 +0100
Subject: [R] transpose a data frame according to a specific variable
In-Reply-To: <1423496836296-4702971.post@n4.nabble.com>
References: <1423496836296-4702971.post@n4.nabble.com>
Message-ID: <FEC6700C-4EF4-4B89-A59B-E16DF0CD5DAF@univie.ac.at>


library(tidyr)
spread(DF,Year,Day)




> On 09 Feb 2015, at 16:47, jeff6868 <geoffrey_klein at etu.u-bourgogne.fr> wrote:
> 
> finalDF <-
> data.frame(id=c("A","B","C"),"2000"=c(NA,NA,164),"2001"=c(120,NA,99),
> "2002"=c(90,18,48),"2003"=c(54,217,NA),"2004"=c(NA,68,NA))

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150209/c8d279c3/attachment.bin>

From dcarlson at tamu.edu  Mon Feb  9 21:49:15 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 9 Feb 2015 20:49:15 +0000
Subject: [R] Coordinate or top left corner + offset
In-Reply-To: <54D8DFC0.20203@ieu.uzh.ch>
References: <54D8DFC0.20203@ieu.uzh.ch>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D64FD0F@mb02.ads.tamu.edu>

This is more complicated, but it could be rolled up into a function. Replace your mtext() call with the following:

# Set character expansion size
cx <- 2.5
# Get the plot coordinates and the character size
ur <- par("usr")[c(1, 4)]
chr <- par("cxy")
rect(ur[1]+chr[1]/10, ur[2]-chr[2]*cx, ur[1]+chr[1]*cx, ur[2]-chr[1]/10, 
     border=NA, col="white")
text(ur[1]+chr[1]*cx/2, ur[2]-chr[2]*cx/2, "a", font=2, cex=2.5, col="red")

1) Assign to cx the cex= value that you are using in text().
2) Then get the upper right corner of the plot window and the size of the default character width in user coordinate units.
3) Draw a white rectangle the size of the character you are plotting (in this case cex=2.5). Shrink the left and top edge so that the box around the plot area is not obscured.
4) Plot your character in the center of the box.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Pascal A. Niklaus
Sent: Monday, February 9, 2015 10:27 AM
To: r-help at r-project.org
Subject: [R] Coordinate or top left corner + offset

Dear all,

I am struggling to add annotations to panels of a series of plots 
arranged on a page.

Basically, I'd like to add letters enumerating the panels 
("a","b","c",...), at a fixed distance from the top left corner of the 
plot's "box".

I succeeded partly with "mtext" (see below), but the "at" option is in 
user coordinates, which makes is difficult to specify a given offset 
from the corner (e.g. 1cm from top and left).

I tried grid's "npc" but these coordinates refer to the entire plot 
instead of the current inner plotting region.

Phrased differently, I'd like to place text (and ideally also be able to 
plot, e.g. a white disc to cover background items) at position 
(top-1cm,left+1cm)

Here is a minimum working example illustrating what I try to achieve:


pdf("example.pdf",width=15,height=15)

m <- rbind( c(0.1,0.9,0.1,0.6),
             c(0.1,0.9,0.6,0.9)
      );

split.screen(m)

screen(1);
par(mar=c(0,0,0,0));
plot(rnorm(10),rnorm(10),xlim=c(-5,5),xaxt="n",yaxt="n");
mtext(quote(bold(a)),side=3,line=-2.5,at=-5,cex=2.5)

screen(2);
par(mar=c(0,0,0,0));
plot(rnorm(10),rnorm(10),xlim=c(-3,3),xaxt="n",yaxt="n");
mtext(quote(bold(a)),side=3,line=-2.5,at=-3,cex=2.5)


close.screen(all.screens=TRUE)

dev.off()


Thanks for your help

Pascal Niklaus

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gracedrop.wang at gmail.com  Mon Feb  9 20:44:04 2015
From: gracedrop.wang at gmail.com (ying_chen wang)
Date: Mon, 9 Feb 2015 12:44:04 -0700
Subject: [R] neural network, random forest with survey data
Message-ID: <CAKyHFTbtQ3cPO5WCxe3T4dTaR4T03ZK9g6xG6dtyDAJUf5z03g@mail.gmail.com>

Hi, everyone:

Does anyone know if any statistical packages (such as R) can accommodate
neural network or random forest with survey data?

With survey data, we have to incorporate weight with sampling issue or even
with design effect.

Would appreciate if anyone can help.

Grace

	[[alternative HTML version deleted]]


From karl.fetter at gmail.com  Mon Feb  9 22:32:55 2015
From: karl.fetter at gmail.com (Karl Fetter)
Date: Mon, 9 Feb 2015 16:32:55 -0500
Subject: [R] Variance is different in R vs. Excel?
Message-ID: <CACZQHzwGxfxF-k6hymjXUayHNOpM-U_oT0QXDpdt7xYqBMPx4g@mail.gmail.com>

Hello everyone, I have a simple question. when I use the var() function in
R to find a variance, it differs greatly from the variance found in excel
using the =VAR.S function. Any explanations on what those two functions are
actually doing?

Here is the data and the results:

dat<-matrix(c(402,908,553,522,627,1040,756,679,806,711,713,734,683,790,597,872,476,1026,423,476,419,591,376,640,550,601,588,499,646,693,351,730,632,707,779,838,814,771,533,818),
nrow=20, ncol=2, byrow=T)

var(dat[,1])
#21290.8

var(dat[,2])
#24748.75

#in Excel, the variance of dat[,1] = 44763.91; for dat[,2] = 52034.2

Thanks,

Karl

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Feb  9 22:45:11 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 9 Feb 2015 21:45:11 +0000
Subject: [R] Variance is different in R vs. Excel?
In-Reply-To: <CACZQHzwGxfxF-k6hymjXUayHNOpM-U_oT0QXDpdt7xYqBMPx4g@mail.gmail.com>
References: <CACZQHzwGxfxF-k6hymjXUayHNOpM-U_oT0QXDpdt7xYqBMPx4g@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D64FD77@mb02.ads.tamu.edu>

Time for a new version of Excel? I cannot duplicate your results in Excel 2013.

R:
> apply(dat, 2, var)
[1] 21290.80 24748.75

Excel 2013:
=VAR.S(A2:A21)   =VAR.S(B2:B21)
21290.8          24748.74737

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Karl Fetter
Sent: Monday, February 9, 2015 3:33 PM
To: r-help at r-project.org
Subject: [R] Variance is different in R vs. Excel?

Hello everyone, I have a simple question. when I use the var() function in
R to find a variance, it differs greatly from the variance found in excel
using the =VAR.S function. Any explanations on what those two functions are
actually doing?

Here is the data and the results:

dat<-matrix(c(402,908,553,522,627,1040,756,679,806,711,713,734,683,790,597,872,476,1026,423,476,419,591,376,640,550,601,588,499,646,693,351,730,632,707,779,838,814,771,533,818),
nrow=20, ncol=2, byrow=T)

var(dat[,1])
#21290.8

var(dat[,2])
#24748.75

#in Excel, the variance of dat[,1] = 44763.91; for dat[,2] = 52034.2

Thanks,

Karl

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Ted.Harding at wlandres.net  Mon Feb  9 23:15:48 2015
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Mon, 09 Feb 2015 22:15:48 -0000 (GMT)
Subject: [R] Variance is different in R vs. Excel?
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D64FD77@mb02.ads.tamu.edu>
Message-ID: <XFMail.20150209221548.Ted.Harding@wlandres.net>

[See at end]

On 09-Feb-2015 21:45:11 David L Carlson wrote:
> Time for a new version of Excel? I cannot duplicate your results in Excel
> 2013.
> 
> R:
>> apply(dat, 2, var)
> [1] 21290.80 24748.75
> 
> Excel 2013:
> =VAR.S(A2:A21)   =VAR.S(B2:B21)
> 21290.8          24748.74737
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Karl Fetter
> Sent: Monday, February 9, 2015 3:33 PM
> To: r-help at r-project.org
> Subject: [R] Variance is different in R vs. Excel?
> 
> Hello everyone, I have a simple question. when I use the var() function in
> R to find a variance, it differs greatly from the variance found in excel
> using the =VAR.S function. Any explanations on what those two functions are
> actually doing?
> 
> Here is the data and the results:
> 
> dat<-matrix(c(402,908,553,522,627,1040,756,679,806,711,713,734,683,790,597,872
> ,476,1026,423,476,419,591,376,640,550,601,588,499,646,693,351,730,632,707,779,
> 838,814,771,533,818),
> nrow=20, ncol=2, byrow=T)
> 
> var(dat[,1])
>#21290.8
> 
> var(dat[,2])
>#24748.75
> 
>#in Excel, the variance of dat[,1] = 44763.91; for dat[,2] = 52034.2
> 
> Thanks,
> Karl

I suspect that something has happened to the reading-in of the
data into Excel. (I don't know much about Excel, and that's because
I don't want to ... ).

The ratio of the variances of the two datasets in R is:

  var(dat[,2])/var(dat[,1])
  # [1] 1.162415

while the ratio of th results from Excel is:

  52034.2/44763.91
  # [1] 1.162414

so they are almost identical. 

So it is as if Excel was evaluating the variances for data which
are

  sqrt(44763.91/var(dat[,1]))
  # [1] 1.45
  sqrt(52034.2/var(dat[,2]))
  # [1] 1.449999

times the data used by R. So maybe there's a "nasty" lurking somewhere
in the spreadsheet? (Excel is notorious for planting things invisibly
in its spreadsheets which lead to messed-up results for no apparent
reasion ... ).

Hoping this helps,
Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 09-Feb-2015  Time: 22:15:44
This message was sent by XFMail


From maitra.mbox.ignored at inbox.com  Tue Feb 10 00:39:14 2015
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Mon, 9 Feb 2015 17:39:14 -0600
Subject: [R] Variance is different in R vs. Excel?
In-Reply-To: <XFMail.20150209221548.Ted.Harding@wlandres.net>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D64FD77@mb02.ads.tamu.edu>
	<XFMail.20150209221548.Ted.Harding@wlandres.net>
Message-ID: <20150209173914.bae4d99ebeadafed3515372c@inbox.com>

I suspect that this is the long-documented issue with indeed an entire industry -- and publications -- devoted to finding such errors in Excel. Till the 2013 version, it used to be a favorite HW problem of mine. Basically, Excel uses the "short formula" to calculate the variance and the sd. This "short formula" has numerical issues with larger numbers (though I am surprised at the OP's data because these numbers were not that large). Anyway, the "long formula" which removes the mean from each datapoint, squares and sums is preferred with large numbers. 

Btw, my HW problem for incoming students in my R class would be this:

Consider the following numbers:
100000000000001, 100000000000002, 100000000000001, 100000000000002, 100000000000001,
100000000000002, 100000000000001, 100000000000002, 100000000000001, 100000000000002.

Calculate the variance in Excel (gives pure garbage) and in R.

I got this (or may have adapted it) from the book: Numerical Issues in Statistical Computing for the Social Scientist by M. Altman, J. Gill and M. P. McDonald.

After over 10 years, Excel finally appears to have fixed the issue. gnumeric never had this problem.

Best wishes,
Ranjan


On Mon, 9 Feb 2015 22:15:48 +0000 Ted Harding <Ted.Harding at wlandres.net> wrote:

> [See at end]
> 
> On 09-Feb-2015 21:45:11 David L Carlson wrote:
> > Time for a new version of Excel? I cannot duplicate your results in Excel
> > 2013.
> > 
> > R:
> >> apply(dat, 2, var)
> > [1] 21290.80 24748.75
> > 
> > Excel 2013:
> > =VAR.S(A2:A21)   =VAR.S(B2:B21)
> > 21290.8          24748.74737
> > 
> > -------------------------------------
> > David L Carlson
> > Department of Anthropology
> > Texas A&M University
> > College Station, TX 77840-4352
> > 
> > 
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Karl Fetter
> > Sent: Monday, February 9, 2015 3:33 PM
> > To: r-help at r-project.org
> > Subject: [R] Variance is different in R vs. Excel?
> > 
> > Hello everyone, I have a simple question. when I use the var() function in
> > R to find a variance, it differs greatly from the variance found in excel
> > using the =VAR.S function. Any explanations on what those two functions are
> > actually doing?
> > 
> > Here is the data and the results:
> > 
> > dat<-matrix(c(402,908,553,522,627,1040,756,679,806,711,713,734,683,790,597,872
> > ,476,1026,423,476,419,591,376,640,550,601,588,499,646,693,351,730,632,707,779,
> > 838,814,771,533,818),
> > nrow=20, ncol=2, byrow=T)
> > 
> > var(dat[,1])
> >#21290.8
> > 
> > var(dat[,2])
> >#24748.75
> > 
> >#in Excel, the variance of dat[,1] = 44763.91; for dat[,2] = 52034.2
> > 
> > Thanks,
> > Karl
> 
> I suspect that something has happened to the reading-in of the
> data into Excel. (I don't know much about Excel, and that's because
> I don't want to ... ).
> 
> The ratio of the variances of the two datasets in R is:
> 
>   var(dat[,2])/var(dat[,1])
>   # [1] 1.162415
> 
> while the ratio of th results from Excel is:
> 
>   52034.2/44763.91
>   # [1] 1.162414
> 
> so they are almost identical. 
> 
> So it is as if Excel was evaluating the variances for data which
> are
> 
>   sqrt(44763.91/var(dat[,1]))
>   # [1] 1.45
>   sqrt(52034.2/var(dat[,2]))
>   # [1] 1.449999
> 
> times the data used by R. So maybe there's a "nasty" lurking somewhere
> in the spreadsheet? (Excel is notorious for planting things invisibly
> in its spreadsheets which lead to messed-up results for no apparent
> reasion ... ).
> 
> Hoping this helps,
> Ted.
> 
> -------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> Date: 09-Feb-2015  Time: 22:15:44
> This message was sent by XFMail
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From bbolker at gmail.com  Tue Feb 10 00:42:38 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 9 Feb 2015 23:42:38 +0000
Subject: [R] Coordinate or top left corner + offset
References: <54D8DFC0.20203@ieu.uzh.ch>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D64FD0F@mb02.ads.tamu.edu>
Message-ID: <loom.20150210T004042-986@post.gmane.org>

David L Carlson <dcarlson <at> tamu.edu> writes:

> 
> This is more complicated, but it could be rolled up into a function.
Replace your mtext() call with the following:
> 
> # Set character expansion size
> cx <- 2.5
> # Get the plot coordinates and the character size
> ur <- par("usr")[c(1, 4)]
> chr <- par("cxy")
> rect(ur[1]+chr[1]/10, ur[2]-chr[2]*cx, ur[1]+chr[1]*cx, ur[2]-chr[1]/10, 
>      border=NA, col="white")
> text(ur[1]+chr[1]*cx/2, ur[2]-chr[2]*cx/2, "a", font=2, cex=2.5, col="red")
> 
> 1) Assign to cx the cex= value that you are using in text().
> 2) Then get the upper right corner of the plot window and the size of the
default character width in user
> coordinate units.
> 3) Draw a white rectangle the size of the character you are plotting (in
this case cex=2.5). Shrink the left
> and top edge so that the box around the plot area is not obscured.
> 4) Plot your character in the center of the box.
> 

  There are two more tricks you can use here:

  (1) cheat by using legend()

plot(0:10,0:10)
legend("topleft",legend=NA,title="hello",bty="n")

  (2) use plotrix::corner.label


From aebingham2 at gmail.com  Tue Feb 10 04:02:10 2015
From: aebingham2 at gmail.com (Allen Bingham)
Date: Mon, 9 Feb 2015 19:02:10 -0800
Subject: [R] SAS equivalent for R's signif function?
Message-ID: <000901d044dd$f747e690$e5d7b3b0$@gmail.com>

Probably posting this to the wrong list ... but I'm in the process of
learning R, after many years of using SAS --- so I thought I'd ask this
question here:

     Is there with a function (or macro) in SAS that performs the same
action as R's "signif" function, if so please provide?

Tried to find via a Google search to no success. Doesn't seem to be in the
"R for SAS and SPSS Users" by Robert A. Munchen (first edition is what I
have), or in SAS and R by Ken Kleinman and Nicholas J. Horton (2nd edition)
[although in the latter they do list the R "signif" function on page 61 ...
but don't list a SAS equivalent.

If you have a suggestion for a different list that I might ask this question
(assuming I don't get the answer here), provide that as well.

Thanks-Allen

______________________________________
Allen Bingham
Bingham Statistical Consulting
aebingham2 at gmail.com
LinkedIn Profile: www.linkedin.com/pub/allen-bingham/3b/556/325


From afflorezr at unal.edu.co  Tue Feb 10 03:07:24 2015
From: afflorezr at unal.edu.co (=?UTF-8?Q?Andr=C3=A9s_Felipe_Fl=C3=B3rez_Rivera?=)
Date: Mon, 9 Feb 2015 21:07:24 -0500
Subject: [R] Help
Message-ID: <CAJh2SWwx=ve+jV98_KyWu=eOKwxGDMd==5a64kg1Oenesxg_bQ@mail.gmail.com>

Hi everyone,

I am trying to automate (on a Win7 system) an R script to read data from a
DB2 data base and write it to file, for processing by another system. My
code runs in the R gui perfectly. So I wrote a batch file to call this .r
file and output results to script.out as shown below. When I double click
the batch file everything runs successfully. When I schedule a task to run
the batch file, the R code runs, collects data from DB2 data base, but the
write to file fails every time, only save the header from sql query.

R Code:

library(RJDBC)
library(rJava)
jcc = JDBC("com.ibm.db2.jcc.DB2Driver",".../db2jcc4.jar")
conn = dbConnect(jcc,"xxx",user="xxxx",password="xxxx")
bd1 = dbSendUpdate(conn, "set current schema PRODUCCION")
bd1 = dbSendQuery(conn,
paste("SELECT *
FROM VW_tabla_1"))
dat4<- fetch(bd1, n = -1)
write.csv2(dat4,file = ".../bd1.csv",row.names = F)
dbDisconnect(conn)


batch file code:

\Program Files\R\R-3.0.1\bin\x64\R.exe" CMD BATCH --vanilla --slave
"C:\Users\abg\SkyDrive\Documents\dat.R"


thanks.

	[[alternative HTML version deleted]]


From ssuhanchen at mail.mcut.edu.tw  Tue Feb 10 02:04:49 2015
From: ssuhanchen at mail.mcut.edu.tw (Ssuhanchen)
Date: Mon, 9 Feb 2015 17:04:49 -0800 (PST)
Subject: [R] How to solve this complex equation
Message-ID: <1423530289334-4702997.post@n4.nabble.com>

Hi!

I want to use R to calculate the variable x which is in a complex equation
in below:

 2
 ?[exp(-x/2)*(x^k)/(2^k*k!)]=0.05
k=0

how to solve this equation to get the exact x in R? 

Thank you very much.




--
View this message in context: http://r.789695.n4.nabble.com/How-to-solve-this-complex-equation-tp4702997.html
Sent from the R help mailing list archive at Nabble.com.


From sirchill88 at att.net  Tue Feb 10 04:15:04 2015
From: sirchill88 at att.net (SirChill88)
Date: Mon, 9 Feb 2015 19:15:04 -0800 (PST)
Subject: [R] Latest version of Rtools is incompatible with latest
 version of R !!
In-Reply-To: <700742354.1204935.1421493604367.JavaMail.yahoo@jws10922.mail.sg3.yahoo.com>
References: <1112680892.833523.1421342848030.JavaMail.yahoo@jws10925.mail.sg3.yahoo.com>
	<CAFDcVCS=5do8oEqmfNBxuf9Bagth+TU9DscSF0gW93nQ-nGWoQ@mail.gmail.com>
	<666396155.1039527.1421409318022.JavaMail.yahoo@jws10902.mail.sg3.yahoo.com>
	<54B90263.5090707@gmail.com>
	<CABdHhvH5cd1AOdo8ofqsEAXrjLHSFpfH50w21TPoUR3RsKcOCQ@mail.gmail.com>
	<700742354.1204935.1421493604367.JavaMail.yahoo@jws10922.mail.sg3.yahoo.com>
Message-ID: <1423538104343-4703000.post@n4.nabble.com>

This solved my problem too. Thank you!



--
View this message in context: http://r.789695.n4.nabble.com/Latest-version-of-Rtools-is-incompatible-with-latest-version-of-R-tp4701853p4703000.html
Sent from the R help mailing list archive at Nabble.com.


From plofrano at ezoic.com  Tue Feb 10 01:38:35 2015
From: plofrano at ezoic.com (Piper Lofrano)
Date: Mon, 9 Feb 2015 16:38:35 -0800
Subject: [R] Ezoic and r-project.org
Message-ID: <efab3a7272146899f6f36b84cdb58cec@s.ezoic.com>

Hi there,

Firstly, congrats; r-project.org is an awesome site.  Do you work on it full time or is it a hobby? 

Ezoic is the first Google AdSense certified partner headquartered in the US that helps sites increase AdSense earnings through layout improvement. Have you ever considered testing your site's layout and ad placements? I know it sounds implausible, but testing new layouts of the exact same content can increase your ad income 50-250% and significantly enhance the user experience, which is one of the most important ranking factors! 

Ezoic can help you do this; would it be alright if I sent you some info? 

Cheers,

Piper
www.ezoic.com


From djnordlund at frontier.com  Tue Feb 10 08:05:08 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Mon, 09 Feb 2015 23:05:08 -0800
Subject: [R] SAS equivalent for R's signif function?
In-Reply-To: <000901d044dd$f747e690$e5d7b3b0$@gmail.com>
References: <000901d044dd$f747e690$e5d7b3b0$@gmail.com>
Message-ID: <54D9ADA4.5080102@frontier.com>

On 2/9/2015 7:02 PM, Allen Bingham wrote:
> Probably posting this to the wrong list ... but I'm in the process of
> learning R, after many years of using SAS --- so I thought I'd ask this
> question here:
>
>       Is there with a function (or macro) in SAS that performs the same
> action as R's "signif" function, if so please provide?
>
> Tried to find via a Google search to no success. Doesn't seem to be in the
> "R for SAS and SPSS Users" by Robert A. Munchen (first edition is what I
> have), or in SAS and R by Ken Kleinman and Nicholas J. Horton (2nd edition)
> [although in the latter they do list the R "signif" function on page 61 ...
> but don't list a SAS equivalent.
>
> If you have a suggestion for a different list that I might ask this question
> (assuming I don't get the answer here), provide that as well.
>
> Thanks-Allen
>
> ______________________________________
> Allen Bingham
> Bingham Statistical Consulting
> aebingham2 at gmail.com
> LinkedIn Profile: www.linkedin.com/pub/allen-bingham/3b/556/325
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Yes, this is the wrong list.  Your question is about SAS (that is what 
SAS-L or SAScommunity is about) and this list is about R, and you 
already know what function to use in R.  That said, I searched for "SAS 
round to fixed number of significant digits" and found this link

http://support.sas.com/kb/24/728.html

You could turn this into a function style macro (but it will be ugly). 
If you have a recent enough version of SAS you could use PROC FCMP to 
turn this into a function.

If you are interested contact me offline and I will send you a PROC FCMP 
implementation.


Dan

-- 
Daniel Nordlund
Bothell, WA USA


From r.turner at auckland.ac.nz  Tue Feb 10 09:29:38 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 10 Feb 2015 21:29:38 +1300
Subject: [R] How to solve this complex equation
In-Reply-To: <1423530289334-4702997.post@n4.nabble.com>
References: <1423530289334-4702997.post@n4.nabble.com>
Message-ID: <54D9C172.3090009@auckland.ac.nz>

On 10/02/15 14:04, Ssuhanchen wrote:
> Hi!
>
> I want to use R to calculate the variable x which is in a complex equation
> in below:
>
>   2
>   ?[exp(-x/2)*(x^k)/(2^k*k!)]=0.05
> k=0
>
> how to solve this equation to get the exact x in R?

Is this homework?  Sure looks like it.  Talk to your prof.  Or do a bit 
of work on learning how to use R --- which is presumably the point of 
the exercise.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From S.Ellison at LGCGroup.com  Tue Feb 10 11:39:22 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 10 Feb 2015 10:39:22 +0000
Subject: [R] How to solve this complex equation
In-Reply-To: <1423530289334-4702997.post@n4.nabble.com>
References: <1423530289334-4702997.post@n4.nabble.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED66040D2733@GOLD.corp.lgc-group.com>



> -----Original Message-----
> I want to use R to calculate the variable x which is in a complex equation in
> below:
> 
>  2
>  ?[exp(-x/2)*(x^k)/(2^k*k!)]=0.05
> k=0
> 
> how to solve this equation to get the exact x in R?

For a _numerical_ solution, if f(x) is your function, use uniroot to find a root of (f(x) - 0.05) 
That will normally need you to define a new function g(x) = f(x)-0.05 and apply uniroot to g(x)


S Ellison




*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From Thomas.Chesney at nottingham.ac.uk  Tue Feb 10 11:45:01 2015
From: Thomas.Chesney at nottingham.ac.uk (Thomas Chesney)
Date: Tue, 10 Feb 2015 10:45:01 +0000
Subject: [R] pairwise.t.test
Message-ID: <5EAA21940C65214F9C11DA5FBBC14F0B3AECCDD657@EXCHANGE2.ad.nottingham.ac.uk>

I'm using pairwise.t.test() with 6 groups, but the dataset the 6 groups are in actually contains 24 groups.

When I run the test with all 24 groups the results I'm getting between Group 1 and Group 2 are very different from the results I'm getting between Group 1 and Group 2 when I split off the 6 groups and run the test. When only 6 groups are included the results are highly significant but with all 24 groups the results are insignificant.

I'm not adjusting p.values. The code I'm running is:

res <- pairwise.t.test(dat$Adopt, dat$Group, p.adj="none")

I thought the above code would run exactly the same test on Groups 1 and 2, regardless of how many groups are in the dataset. Can anyone explain what's going on?

Thank you,

Thomas Chesney




This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please send it back to me, and immediately delete it. 

Please do not use, copy or disclose the information contained in this
message or in any attachment.  Any views or opinions expressed by the
author of this email do not necessarily reflect the views of the
University of Nottingham.

This message has been checked for viruses but the contents of an
attachment may still contain software viruses which could damage your
computer system, you are advised to perform your own checks. Email
communications with the University of Nottingham may be monitored as
permitted by UK legislation.


From jdnewmil at dcn.davis.CA.us  Tue Feb 10 12:36:17 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 10 Feb 2015 06:36:17 -0500
Subject: [R] Help
In-Reply-To: <CAJh2SWwx=ve+jV98_KyWu=eOKwxGDMd==5a64kg1Oenesxg_bQ@mail.gmail.com>
References: <CAJh2SWwx=ve+jV98_KyWu=eOKwxGDMd==5a64kg1Oenesxg_bQ@mail.gmail.com>
Message-ID: <09966363-7F89-4440-971B-83E091E25B71@dcn.davis.CA.us>

If it works interactively then as far as this mailing list is concerned it works. Executing in different environments such as a scheduler can affect any program, not just R, and the reasons are due to the operating system, not R.

In general, you should be aware of the configuration and resource requirements of R in general and your script in particular when switching execution environments.  You can learn more about what R depends on by reading the R-admin.pdf file that comes with R. Environment variables such as R_LIBS are common differences found between interactive and scheduled execution.
Another issue is permissions... scheduled execution often runs as a user who has different permissions than your interactive login does... but that is very off topic here.

One strategy you can try is creating a test script that just checks each requirement that you identify and logs what it finds, and then you can change either the way you are running the batch or add commands to the batch that configure things the way your script needs them. When the logs indicate things are set up right, you will know what to do to your actual processing script to make it work.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 9, 2015 9:07:24 PM EST, "Andr?s Felipe Fl?rez Rivera" <afflorezr at unal.edu.co> wrote:
>Hi everyone,
>
>I am trying to automate (on a Win7 system) an R script to read data
>from a
>DB2 data base and write it to file, for processing by another system.
>My
>code runs in the R gui perfectly. So I wrote a batch file to call this
>.r
>file and output results to script.out as shown below. When I double
>click
>the batch file everything runs successfully. When I schedule a task to
>run
>the batch file, the R code runs, collects data from DB2 data base, but
>the
>write to file fails every time, only save the header from sql query.
>
>R Code:
>
>library(RJDBC)
>library(rJava)
>jcc = JDBC("com.ibm.db2.jcc.DB2Driver",".../db2jcc4.jar")
>conn = dbConnect(jcc,"xxx",user="xxxx",password="xxxx")
>bd1 = dbSendUpdate(conn, "set current schema PRODUCCION")
>bd1 = dbSendQuery(conn,
>paste("SELECT *
>FROM VW_tabla_1"))
>dat4<- fetch(bd1, n = -1)
>write.csv2(dat4,file = ".../bd1.csv",row.names = F)
>dbDisconnect(conn)
>
>
>batch file code:
>
>\Program Files\R\R-3.0.1\bin\x64\R.exe" CMD BATCH --vanilla --slave
>"C:\Users\abg\SkyDrive\Documents\dat.R"
>
>
>thanks.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Tue Feb 10 13:05:32 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 10 Feb 2015 13:05:32 +0100
Subject: [R] pairwise.t.test
In-Reply-To: <5EAA21940C65214F9C11DA5FBBC14F0B3AECCDD657@EXCHANGE2.ad.nottingham.ac.uk>
References: <5EAA21940C65214F9C11DA5FBBC14F0B3AECCDD657@EXCHANGE2.ad.nottingham.ac.uk>
Message-ID: <51E7432C-764E-421F-92AE-53F3525C953F@gmail.com>


On 10 Feb 2015, at 11:45 , Thomas Chesney <Thomas.Chesney at nottingham.ac.uk> wrote:

> I'm using pairwise.t.test() with 6 groups, but the dataset the 6 groups are in actually contains 24 groups.
> 
> When I run the test with all 24 groups the results I'm getting between Group 1 and Group 2 are very different from the results I'm getting between Group 1 and Group 2 when I split off the 6 groups and run the test. When only 6 groups are included the results are highly significant but with all 24 groups the results are insignificant.
> 
> I'm not adjusting p.values. The code I'm running is:
> 
> res <- pairwise.t.test(dat$Adopt, dat$Group, p.adj="none")
> 
> I thought the above code would run exactly the same test on Groups 1 and 2, regardless of how many groups are in the dataset. Can anyone explain what's going on?

Check out pool.sd on the help page.

-pd


> 
> Thank you,
> 
> Thomas Chesney
> 
> 
> 
> 
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please send it back to me, and immediately delete it. 
> 
> Please do not use, copy or disclose the information contained in this
> message or in any attachment.  Any views or opinions expressed by the
> author of this email do not necessarily reflect the views of the
> University of Nottingham.
> 
> This message has been checked for viruses but the contents of an
> attachment may still contain software viruses which could damage your
> computer system, you are advised to perform your own checks. Email
> communications with the University of Nottingham may be monitored as
> permitted by UK legislation.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Thomas.Chesney at nottingham.ac.uk  Tue Feb 10 13:18:19 2015
From: Thomas.Chesney at nottingham.ac.uk (Thomas Chesney)
Date: Tue, 10 Feb 2015 12:18:19 +0000
Subject: [R] pairwise.t.test
In-Reply-To: <51E7432C-764E-421F-92AE-53F3525C953F@gmail.com>
References: <5EAA21940C65214F9C11DA5FBBC14F0B3AECCDD657@EXCHANGE2.ad.nottingham.ac.uk>,
	<51E7432C-764E-421F-92AE-53F3525C953F@gmail.com>
Message-ID: <5EAA21940C65214F9C11DA5FBBC14F0B3AECCDD65C@EXCHANGE2.ad.nottingham.ac.uk>

Thank you!
________________________________________
From: peter dalgaard [pdalgd at gmail.com]
Sent: Tuesday, February 10, 2015 12:05 PM
To: Thomas Chesney
Cc: r-help at r-project.org
Subject: Re: [R] pairwise.t.test

On 10 Feb 2015, at 11:45 , Thomas Chesney <Thomas.Chesney at nottingham.ac.uk> wrote:

> I'm using pairwise.t.test() with 6 groups, but the dataset the 6 groups are in actually contains 24 groups.
>
> When I run the test with all 24 groups the results I'm getting between Group 1 and Group 2 are very different from the results I'm getting between Group 1 and Group 2 when I split off the 6 groups and run the test. When only 6 groups are included the results are highly significant but with all 24 groups the results are insignificant.
>
> I'm not adjusting p.values. The code I'm running is:
>
> res <- pairwise.t.test(dat$Adopt, dat$Group, p.adj="none")
>
> I thought the above code would run exactly the same test on Groups 1 and 2, regardless of how many groups are in the dataset. Can anyone explain what's going on?

Check out pool.sd on the help page.

-pd


>
> Thank you,
>
> Thomas Chesney
>
>
>
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please send it back to me, and immediately delete it.
>
> Please do not use, copy or disclose the information contained in this
> message or in any attachment.  Any views or opinions expressed by the
> author of this email do not necessarily reflect the views of the
> University of Nottingham.
>
> This message has been checked for viruses but the contents of an
> attachment may still contain software viruses which could damage your
> computer system, you are advised to perform your own checks. Email
> communications with the University of Nottingham may be monitored as
> permitted by UK legislation.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com












This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please send it back to me, and immediately delete it. 

Please do not use, copy or disclose the information contained in this
message or in any attachment.  Any views or opinions expressed by the
author of this email do not necessarily reflect the views of the
University of Nottingham.

This message has been checked for viruses but the contents of an
attachment may still contain software viruses which could damage your
computer system, you are advised to perform your own checks. Email
communications with the University of Nottingham may be monitored as
permitted by UK legislation.


From kmezhoud at gmail.com  Tue Feb 10 13:37:48 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Tue, 10 Feb 2015 12:37:48 +0000
Subject: [R] Cube of Matrices or list of Matrices
In-Reply-To: <26E70778-E9A5-4C8E-93FA-383E41437489@bigelow.org>
References: <CALJKBv96a1f61fHqcbs84_e_X220BjQkG6u0PkxSCOeFC=fNEw@mail.gmail.com>
	<A05E7F88-637A-4E35-980C-273FEE5F4128@gmail.com>
	<CALJKBv_TugfPsHpixw4+4cjxNw7M5qSQ5vH_Ns0azzS_JuagdA@mail.gmail.com>
	<D27065ED-2EA9-4B99-BB26-21D210326A0D@bigelow.org>
	<CALJKBv9VnPXQnPbp0BUniqvtF+xWCrjLAxU=FUL4AusHdo1WDg@mail.gmail.com>
	<26E70778-E9A5-4C8E-93FA-383E41437489@bigelow.org>
Message-ID: <CALJKBv9JpBwifA8khH8xhq7nj4RLhd7wkiyuB_+U5ojn+9essA@mail.gmail.com>

Thanks Ben, Jeff and Roy,
Here is an example of my data

Disease <- NULL
Diseases <- NULL
ListMatByGene <- NULL
for(i in 1:3){

Disease[[i]] <-matrix(sample(-30:30,25+(5*i)),5+i)
rownames(Disease[[i]]) <- paste0("Sample",1:(5+i))
colnames(Disease[[i]]) <- paste0("Gene",1:5)

D <- paste0("Disease",i)
Diseases[[D]] <- Disease[[i]]
}

getColumn <- function(x, colNum, len = nrow(x)){
    y <- x[,colNum]
    length(y) <- len
    y
}

getMatrices <- function(colNums, dataList = x){
    # the number of rows required
    n <- max(sapply(dataList, nrow))
    lapply(colNums, function(x, dat, n) { # iterate along requested columns
        do.call(cbind, lapply(dat, getColumn,x, len=n)) # iterate along
input data list
    }, dataList, n)
}
G <- paste0("Gene",1:5)
ListMatByGene[G] <- getMatrices(c(1:ncol(Diseases[[1]])),dataList=Diseases)

## get Disease correlation by gene
DiseaseCorrelation <- lapply(ListMatByGene,function(x) cor(x,use="na",
method="spearman"))

##convert the list of Matrices to array
ArrayDiseaseCor <- array(unlist(DiseaseCorrelation), dim =
c(nrow(DiseaseCorrelation[[1]]), ncol(DiseaseCorrelation[[1]]),
length(DiseaseCorrelation)))
dimnames(ArrayDiseaseCor) <- list(names(Diseases), names(Diseases),
colnames(Diseases[[1]]))

FilterDiseaseCor <- apply(ArrayDiseaseCor,MARGIN=c(1,2) ,function(x)
x[abs(x)>0.5])

FilterDiseaseCor

         Disease1   Disease2  Disease3
Disease1 Numeric,5  Numeric,2 -0.9428571
Disease2 Numeric,2  Numeric,5 Numeric,2
Disease3 -0.9428571 Numeric,2 Numeric,5


Question is:
How can get a table as:

D1              D2               Cor       Gene
Disease1    Disease2      -0.94    Gene2
Disease1    Disease2       0.78    Gene4
Disease3    Disease2       0.5      Gene5
...

and
                 Disease1   Disease2      Disease3
Disease1        5                1                0
Disease2        1                 5                3
Disease3        0                  3               5



Thanks
Karim




On Tue, Jan 20, 2015 at 2:11 AM, Ben Tupper <btupper at bigelow.org> wrote:

> Hi,
>
> On Jan 19, 2015, at 5:17 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>
> Thanks Ben.
> I need to learn more about apply. Have you a link or tutorial about apply.
> R documentation is very short.
>
> How can obtain:
> z <- list (Col1, Col2, Col3, Col4......)?
>
>
> This may not be the most efficient way and there certainly is no error
> checking, but you can wrap one lapply within another as shown below.  The
> innermost iterates over your list of input matrices, extracting one column
> specified per list element.  The outer lapply iterates over the various
> column numbers you want to extract.
>
>
> getMatrices <- function(colNums, dataList = x){
>    # the number of rows required
>    n <- max(sapply(dataList, nrow))
>    lapply(colNums, function(x, dat, n) { # iterate along requested columns
>       do.call(cbind, lapply(dat, getColumn,x, len=n)) # iterate along
> input data list
>    }, dataList, n)
> }
>
> getMatrices(c(1,3), dataList = x)
>
> If we are lucky, one of the plyr package users might show us how to do the
> same with a one-liner.
>
>
> There are endless resources online, here are some gems.
>
> http://www.r-project.org/doc/bib/R-books.html
> http://www.rseek.org/
> http://www.burns-stat.com/documents/
> http://www.r-bloggers.com/
>
> Also, I found "Data Manipulation with R" (
> http://www.r-project.org/doc/bib/R-books_bib.html#R:Spector:2008 )
> helpful.
>
> Ben
>
> Thanks
>
>   ?__
>  c/ /'_;~~~~kmezhoud
> (*) \(*)   ?????  ??????
> http://bioinformatics.tn/
>
>
>
> On Mon, Jan 19, 2015 at 8:22 PM, Ben Tupper <btupper at bigelow.org> wrote:
>
>> Hi again,
>>
>> On Jan 19, 2015, at 1:53 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>>
>> Yes Many thanks.
>> That is my request using lapply.
>>
>> do.call(cbind,col1)
>>
>>  converts col1 to matrix but does not fill empty value with NA.
>>
>> Even for
>>
>> matrix(unlist(col1), ncol=5,byrow = FALSE)
>>
>>
>> How can get Matrix class of col1? And fill empty values with NA?
>>
>>
>> Perhaps best is to determine the maximum number of rows required first,
>> then force each subset to have that length.
>>
>> # make a list of matrices, each with nCol columns and differing
>> # number of rows
>> nCol <- 3
>> nRow <- sample(3:10, 5)
>> x <- lapply(nRow, function(x, nc) {matrix(x:(x + nc*x - 1), ncol = nc,
>> nrow = x)}, nCol)
>> x
>>
>> # make a simple function to get a single column from a matrix
>> getColumn <- function(x, colNum, len = nrow(x)) {
>>    y <- x[,colNum]
>>    length(y) <- len
>>    y
>> }
>>
>> # what is the maximum number of rows
>> n <- max(sapply(x, nrow))
>>
>> # use the function to get the column from each matrix
>> col1 <- lapply(x, getColumn, 1, len = n)
>> col1
>>
>> do.call(cbind, col1)
>>       [,1] [,2] [,3] [,4] [,5]
>>  [1,]    3    8    5    7    9
>>  [2,]    4    9    6    8   10
>>  [3,]    5   10    7    9   11
>>  [4,]   NA   11    8   10   12
>>  [5,]   NA   12    9   11   13
>>  [6,]   NA   13   NA   12   14
>>  [7,]   NA   14   NA   13   15
>>  [8,]   NA   15   NA   NA   16
>>  [9,]   NA   NA   NA   NA   17
>>
>> Ben
>>
>> Thanks
>> Karim
>>
>>
>>   ?__
>>  c/ /'_;~~~~kmezhoud
>> (*) \(*)   ?????  ??????
>> http://bioinformatics.tn/
>>
>>
>>
>> On Mon, Jan 19, 2015 at 4:36 PM, Ben Tupper <ben.bighair at gmail.com>
>> wrote:
>>
>>> Hi,
>>>
>>> On Jan 18, 2015, at 4:36 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>>>
>>> > Dear All,
>>> > I am trying to get correlation between  Diseases (80) in columns and
>>> > samples in rows (UNEQUAL) using gene expression (at less
>>> 1000,numeric). For
>>> > this I can use CORREP package with cor.unbalanced function.
>>> >
>>> > But before to get this final matrix I need to load and to store the
>>> > expression of 1000 genes for every Disease (80). Every disease has
>>> > different number of samples (between 50 - 500).
>>> >
>>> > It is possible to get a cube of matrices with equal columns but unequal
>>> > rows? I think NO and I can't use array function.
>>> >
>>> > I am trying to get ? list of matrices having the same number of
>>> columns but
>>> > different number of rows. as
>>> >
>>> > Cubist <- vector("list", 1)
>>> > Cubist$Expression <- vector("list", 1)
>>> >
>>> >
>>> > for (i in 1:80){
>>> >
>>> > matrix <- function(getGeneExpression[i])
>>> > Cubist$Expression[[Disease[i]]] <- matrix
>>> >
>>> > }
>>> >
>>> > At this step I have:
>>> > length(Cubist$Expression)
>>> > #80
>>> > dim(Cubist$Expression$Disease1)
>>> > #526 1000
>>> > dim(Cubist$Expression$Disease2)
>>> > #106  1000
>>> >
>>> > names(Cubist$Expression$Disease1[4])
>>> > #ABD
>>> >
>>> > names(Cubist$Expression$Disease2[4])
>>> > #ABD
>>> >
>>> > Now I need to built the final matrices for every genes (1000) that I
>>> will
>>> > use for CORREP function.
>>> >
>>> > Is there a way to extract directly the first column (first gene) for
>>> all
>>> > Diseases (80)  from Cubist$Expression? or
>>> >
>>>
>>> I don't understand most your question, but the above seems to be
>>> straight forward.  Here's a toy example:
>>>
>>> # make a list of matrices, each with nCol columns and differing
>>> # number of rows, nRow
>>> nCol <- 3
>>> nRow <- sample(3:10, 5)
>>> x <- lapply(nRow, function(x, nc) {matrix(x:(x + nc*x - 1), ncol = nc,
>>> nrow = x)}, nCol)
>>> x
>>>
>>> # make a simple function to get a single column from a matrix
>>> getColumn <- function(x, colNum) {
>>>    return(x[,colNum])
>>> }
>>>
>>> # use the function to get the column from each matrix
>>> col1 <- lapply(x, getColumn, 1)
>>> col1
>>>
>>> Does that help answer this part of your question?  If not, you may need
>>> to create a very small example of your data and post it here using the
>>> head() and dput() functions.
>>>
>>> Ben
>>>
>>>
>>>
>>> > I need to built 1000 matrices with 80 columns and unequal rows?
>>> >
>>> > Cublist$Diseases <- vector("list", 1)
>>> >
>>> > for (k in 1:1000){
>>> > for (i in 1:80){
>>> >
>>> > Cublist$Diseases[[gene[k] ]] <- Cubist$Expression[[Diseases[i] ]][k]
>>> > }
>>> >
>>> > }
>>> >
>>> > This double loops is time consuming...Is there a way to do this faster?
>>> >
>>> > Thanks,
>>> > karim
>>> >  ?__
>>> > c/ /'_;~~~~kmezhoud
>>> > (*) \(*)   ?????  ??????
>>> > http://bioinformatics.tn/
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> <http://www.r-project.org/posting-guide.html>
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>>
>>
>>
>>
>>
>>
>>
>>
>>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From jhernandezcabrera at gmail.com  Tue Feb 10 14:20:22 2015
From: jhernandezcabrera at gmail.com (Juan Andres Hernandez)
Date: Tue, 10 Feb 2015 13:20:22 +0000
Subject: [R] How to F noncentrality parameter
Message-ID: <CAL79i+QZVS22pihcW503ux32ydhvG-zrvBtK+Uh9JZWaoADmeg@mail.gmail.com>

Does anybody know how to calculate noncentrality parameter for a  three way
interaction? It is easy for a two way interaction, but I can't find the way
to do it with a three way. I have been looking for a packages about this,
but it seems that none manages to do this.
Thank's in advance
Juan Hernandez
Spain

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Feb 10 14:55:40 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 10 Feb 2015 13:55:40 +0000
Subject: [R] Coordinate or top left corner + offset
In-Reply-To: <loom.20150210T004042-986@post.gmane.org>
References: <54D8DFC0.20203@ieu.uzh.ch>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D64FD0F@mb02.ads.tamu.edu>
	<loom.20150210T004042-986@post.gmane.org>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D64FF7F@mb02.ads.tamu.edu>

Thanks, I didn't know about corner.label. I started with legend but I couldn't find a way to make the box small enough. It always covered much more of the corner than the letter which could have obscured data points.

David

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Monday, February 9, 2015 5:43 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Coordinate or top left corner + offset

David L Carlson <dcarlson <at> tamu.edu> writes:

> 
> This is more complicated, but it could be rolled up into a function.
Replace your mtext() call with the following:
> 
> # Set character expansion size
> cx <- 2.5
> # Get the plot coordinates and the character size
> ur <- par("usr")[c(1, 4)]
> chr <- par("cxy")
> rect(ur[1]+chr[1]/10, ur[2]-chr[2]*cx, ur[1]+chr[1]*cx, ur[2]-chr[1]/10, 
>      border=NA, col="white")
> text(ur[1]+chr[1]*cx/2, ur[2]-chr[2]*cx/2, "a", font=2, cex=2.5, col="red")
> 
> 1) Assign to cx the cex= value that you are using in text().
> 2) Then get the upper right corner of the plot window and the size of the
default character width in user
> coordinate units.
> 3) Draw a white rectangle the size of the character you are plotting (in
this case cex=2.5). Shrink the left
> and top edge so that the box around the plot area is not obscured.
> 4) Plot your character in the center of the box.
> 

  There are two more tricks you can use here:

  (1) cheat by using legend()

plot(0:10,0:10)
legend("topleft",legend=NA,title="hello",bty="n")

  (2) use plotrix::corner.label

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From riviverma at iisermohali.ac.in  Tue Feb 10 06:41:27 2015
From: riviverma at iisermohali.ac.in (riviverma at iisermohali.ac.in)
Date: Tue, 10 Feb 2015 11:11:27 +0530
Subject: [R] Breaking y- axis using gap.barplot
Message-ID: <f8cedd1be473d5a5e8c6dacfd415dbd7.squirrel@iisermohali.ac.in>

Hello all

I am trying to plot histogram with break in y-axis for my data by
following various posts on R- help but none seems solving my problem. My
data looks like:

> hdata
$breaks
 [1]  0  5 10 15 20 25 30 35 40 45 50

$counts
 [1] 16311   108    24     8     1     3     0     1     6     3

on using: gap.barplot(hdata$counts, gap=c(26,108), xlab="RMSD",
ytics=c(0,25,110), ylab="Frequency", xtics=hdata$breaks)

the plot does not seems correct.

Please help.


From ssuhanchen at mail.mcut.edu.tw  Tue Feb 10 08:55:04 2015
From: ssuhanchen at mail.mcut.edu.tw (Ssuhanchen)
Date: Mon, 9 Feb 2015 23:55:04 -0800 (PST)
Subject: [R] Terminating a program using R
Message-ID: <1423554904740-4703004.post@n4.nabble.com>

Hi

I would like to query that if it is possible for R to terminate a program
such as notepad, word, etc.?
If yes, what kind of function should I use?

Thank you very much.





--
View this message in context: http://r.789695.n4.nabble.com/Terminating-a-program-using-R-tp4703004.html
Sent from the R help mailing list archive at Nabble.com.


From ssuhanchen at mail.mcut.edu.tw  Tue Feb 10 09:31:53 2015
From: ssuhanchen at mail.mcut.edu.tw (Ssuhanchen)
Date: Tue, 10 Feb 2015 00:31:53 -0800 (PST)
Subject: [R] How to solve this complex equation
In-Reply-To: <1423530289334-4702997.post@n4.nabble.com>
References: <1423530289334-4702997.post@n4.nabble.com>
Message-ID: <1423557113583-4703006.post@n4.nabble.com>

no, it is not my homework.
I would like to know if there is relevant function to solve this equation in
R?
Could you please give me a hint or suggestion please.

Thanks!



--
View this message in context: http://r.789695.n4.nabble.com/How-to-solve-this-complex-equation-tp4702997p4703006.html
Sent from the R help mailing list archive at Nabble.com.


From geoffrey_klein at etu.u-bourgogne.fr  Tue Feb 10 10:15:43 2015
From: geoffrey_klein at etu.u-bourgogne.fr (jeff6868)
Date: Tue, 10 Feb 2015 01:15:43 -0800 (PST)
Subject: [R] transpose a data frame according to a specific variable
In-Reply-To: <1423496836296-4702971.post@n4.nabble.com>
References: <1423496836296-4702971.post@n4.nabble.com>
Message-ID: <1423559743310-4703007.post@n4.nabble.com>

Both ways are doing well the job. Nice!
Thanks again!



--
View this message in context: http://r.789695.n4.nabble.com/transpose-a-data-frame-according-to-a-specific-variable-tp4702971p4703007.html
Sent from the R help mailing list archive at Nabble.com.


From t.h.ergon at ibv.uio.no  Tue Feb 10 11:16:57 2015
From: t.h.ergon at ibv.uio.no (=?iso-8859-1?Q?Torbj=F8rn_H=E5kan_Ergon?=)
Date: Tue, 10 Feb 2015 10:16:57 +0000
Subject: [R] confint.merMod(method="boot") {lme4} with user supplied FUN to
 bootMer fails
Message-ID: <9740505af73247b799c636ffec5f25a3@mail-ex11.exprod.uio.no>

Dear list,

I'm trying to supply a summary function to confint.merMod(method="boot") {lme4} but get persistent errors. The following example generates the errors:

> fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
> test = function(fit) fixef(fit)[1]
> test(fm1)
(Intercept) 
   251.4051 
> confint(fm1, method="boot", FUN=test)
Computing bootstrap confidence intervals ...
Error in set.seed(seed) : supplied seed is not a valid integer
> confint(fm1, method="boot", FUN=test, seed=100)
Computing bootstrap confidence intervals ...
Error in if (use.u) NULL else ~0 : 
  argument is not interpretable as logical
> confint(fm1, method="boot", FUN=test, seed=100, use.u = FALSE)
Computing bootstrap confidence intervals ...
Error in match.arg(type) : 'arg' must be NULL or a character vector
> confint(fm1, method="boot", FUN=test, seed=100, use.u = TRUE)
Computing bootstrap confidence intervals ...
Error in match.arg(type) : 'arg' must be NULL or a character vector
>

Any help/hints/ideas?

Cheers,

Torbj?rn


From ssuhanchen at mail.mcut.edu.tw  Tue Feb 10 13:26:45 2015
From: ssuhanchen at mail.mcut.edu.tw (Ssuhanchen)
Date: Tue, 10 Feb 2015 04:26:45 -0800 (PST)
Subject: [R] How to solve this complex equation
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED66040D2733@GOLD.corp.lgc-group.com>
References: <1423530289334-4702997.post@n4.nabble.com>
	<A4E5A0B016B8CB41A485FC629B633CED66040D2733@GOLD.corp.lgc-group.com>
Message-ID: <1423571205292-4703015.post@n4.nabble.com>

Got it! Thanks!
I find a useful function, uniroot.all, in package "rootSolve".
I hope it will also be helpful to everybody.



--
View this message in context: http://r.789695.n4.nabble.com/How-to-solve-this-complex-equation-tp4702997p4703015.html
Sent from the R help mailing list archive at Nabble.com.


From HDoran at air.org  Tue Feb 10 15:25:35 2015
From: HDoran at air.org (Doran, Harold)
Date: Tue, 10 Feb 2015 14:25:35 +0000
Subject: [R] How to solve this complex equation
In-Reply-To: <1423557113583-4703006.post@n4.nabble.com>
References: <1423530289334-4702997.post@n4.nabble.com>
	<1423557113583-4703006.post@n4.nabble.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686CF38916A@DC1VEX10MB001.air.org>

?uniroot

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ssuhanchen
Sent: Tuesday, February 10, 2015 3:32 AM
To: r-help at r-project.org
Subject: Re: [R] How to solve this complex equation

no, it is not my homework.
I would like to know if there is relevant function to solve this equation in R?
Could you please give me a hint or suggestion please.

Thanks!



--
View this message in context: http://r.789695.n4.nabble.com/How-to-solve-this-complex-equation-tp4702997p4703006.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Tue Feb 10 15:28:48 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Feb 2015 14:28:48 +0000
Subject: [R] Terminating a program using R
In-Reply-To: <1423554904740-4703004.post@n4.nabble.com>
References: <1423554904740-4703004.post@n4.nabble.com>
Message-ID: <54DA15A0.9020002@stats.ox.ac.uk>

On 10/02/2015 07:55, Ssuhanchen wrote:
> Hi
>
> I would like to query that if it is possible for R to terminate a program
> such as notepad, word, etc.?
> If yes, what kind of function should I use?

The POSIX way to do this is to use 'kill', so try ??kill in your R 
process or use system() to call your favourite OS utility to do this.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From seth at forestadapt.org  Tue Feb 10 15:30:14 2015
From: seth at forestadapt.org (Seth Bigelow)
Date: Tue, 10 Feb 2015 09:30:14 -0500
Subject: [R] function that calculates using preceding records
Message-ID: <000901d0453e$1602b730$42082590$@org>

Greetings:

 

My dataframe has 4 variables: treecode, year, rw (tree ring width), and d
(tree diameter). The d variable 

only has data for 2014. I wish to calculate earlier diameters by subtracting
each year's growth (rw) from the 

previous year's diameter, by treecode. Can anyone help me with a function or
statement that will do this? 

Sample dataset below: In this example, d in year 2013 for treecode TC149
would be 7.92 = 8.0 - 0.080.

 

"treecode","year","rw","d"

"1","TC149",2014,NA,8

"2","TC149",2013,0.08,NA

"3","TC149",2012,0.125,NA

"4","TC149",2011,0.12,NA

"5","TC149",2010,0.125,NA

"6","TC148",2014,NA,34

"7","TC148",2013,0.3,NA

"8","TC148",2012,0.335,NA

"9","TC148",2011,0.315,NA

"10","TC148",2010,0.455,NA

"11","TC147",2014,NA,55.5

"12","TC147",2013,1.26,NA

"13","TC147",2012,1.115,NA

"14","TC147",2011,1.025,NA

"15","TC147",2010,1.495,NA

"16","TC146",2014,NA,60

"17","TC146",2013,1.75,NA

"18","TC146",2012,1.81,NA

"19","TC146",2011,1.39,NA

"20","TC146",2010,1.94,NA

 

 

Seth W. Bigelow


	[[alternative HTML version deleted]]


From medei.ren at gmail.com  Tue Feb 10 15:52:58 2015
From: medei.ren at gmail.com (Renato Medei)
Date: Tue, 10 Feb 2015 15:52:58 +0100
Subject: [R] Problems with tm package, Removeword and trasformations
Message-ID: <CAJJdUGjYk16JKHd67mj+-QHkNDYA91eoTWxMOc7qC3ppsKM9yw@mail.gmail.com>

Dear all,
I'm sorry but  as all the newbies  I have a lot of problems to solve.
I'm using R 3.1.2 under osx  10.10.2.
I'm working with tm to analyze some tweets and I received some strange
errors when I tried to remove stopwords (See below error 1), to transform
content (See below error 2) and to create document term Matrix (See below
error 3)
Could anyone help me?

Error 1
> tweets = searchTwitter("rimini", n=1000)
> tweets = sapply(tweets, function(x) x$getText())
> tweets_corpus = Corpus(VectorSource(tweets))
> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
> tweets_corpus <- tm_map(tweets_corpus, toSpace,
"(f|ht)tp(s?)://(.*)[.][a-z]+")
> tweets_corpus <- tm_map(tweets_corpus, toSpace, "RT |via ")
> tweets_corpus <- tm_map(tweets_corpus, toSpace, "@[^\\s]+")
> tweets_corpus <- tm_map(tweets_corpus, removeNumbers)
> tweets_corpus <- tm_map(tweets_corpus, removePunctuation)
> tweets_corpus <- tm_map(tweets_corpus, removeWords, c("rimini", "Rimini",
"Riviera", "riviera"))
> tweets_corpus <- tm_map(tweets_corpus, stopwords("italian"))
Warning message:
In mclapply(content(x), FUN, ...) :
  all scheduled cores encountered errors in user code

Error2
> tweets = searchTwitter("rimini", n=1000)
> tweets = sapply(tweets, function(x) x$getText())
> tweets_corpus = Corpus(VectorSource(tweets))
> tweets_corpus
<<VCorpus (documents: 1000, metadata (corpus/indexed): 0/0)>>
> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
> tweets_corpus <- tm_map(tweets_corpus, toSpace,
"(f|ht)tp(s?)://(.*)[.][a-z]+")
> tweets_corpus <- tm_map(tweets_corpus, toSpace, "RT |via ")
> tweets_corpus <- tm_map(tweets_corpus, toSpace, "@[^\\s]+")
> tweets_corpus <- tm_map(tweets_corpus, removeNumbers)
> tweets_corpus <- tm_map(tweets_corpus, removePunctuation)
> tweets_corpus <- tm_map(tweets_corpus, removeWords, c("rimini", "Rimini",
"Riviera", "riviera"))
> tweets_corpus <- tm_map(tweets_corpus, content_transformer(tolower))
Warning message:
In mclapply(content(x), FUN, ...) :
  all scheduled cores encountered errors in user code


Error3

> tweets = searchTwitter("rimini", n=1000)
> tweets = sapply(tweets, function(x) x$getText())
> tweets_corpus = Corpus(VectorSource(tweets))
> tweets_corpus
<<VCorpus (documents: 1000, metadata (corpus/indexed): 0/0)>>
> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
> tweets_corpus <- tm_map(tweets_corpus, toSpace,
"(f|ht)tp(s?)://(.*)[.][a-z]+")
> tweets_corpus <- tm_map(tweets_corpus, toSpace, "RT |via ")
> tweets_corpus <- tm_map(tweets_corpus, toSpace, "@[^\\s]+")
> tweets_corpus <- tm_map(tweets_corpus, removeNumbers)
> tweets_corpus <- tm_map(tweets_corpus, removePunctuation)
> tweets_corpus <- tm_map(tweets_corpus, removeWords, c("rimini", "Rimini",
"Riviera", "riviera"))
> dtm <- DocumentTermMatrix(tweets_corpus)
Errore in simple_triplet_matrix(i = i, j = j, v = as.numeric(v), nrow =
length(allTerms),  :
  'i, j, v' different lengths
Inoltre: Warning messages:
1: In mclapply(unname(content(x)), termFreq, control) :
  all scheduled cores encountered errors in user code
2: In simple_triplet_matrix(i = i, j = j, v = as.numeric(v), nrow =
length(allTerms),  :
  si ? prodotto un NA per coercizione


Thank you for your help

	[[alternative HTML version deleted]]


From aron.lindberg at case.edu  Tue Feb 10 15:46:19 2015
From: aron.lindberg at case.edu (Aron Lindberg)
Date: Tue, 10 Feb 2015 06:46:19 -0800 (PST)
Subject: [R] How to clean up missing values in a list of lists
Message-ID: <1423579579228.abd9eb59@Nodemailer>

Hi,


I?m trying to query the Github API, and I?m running into some data munging issues, so I was hoping someone on the list might advise.


Here?s my code. To run it you need to replace client_id and client_secret with your own authorization information for Github.


library(github)
library(RCurl)
library(httpuv)
library(jsonlite)


# Set up the query
ctx = interactive.login(?client_id?, ?client_secret?)


pull <- function(i){
? get.pull.request.files(owner = ?rails?, repo = ?rails?, id = i, ctx = get.github.context(), per_page=1000)
}


data <- read.csv(getURL(?https://gist.githubusercontent.com/aronlindberg/a3d135a303664046c94a/raw/e42a0734ec4542eccf5f4d5bdeed5afbdd1720e9/pull_ids?), sep = ?\n?)


list <- read.csv(textConnection(data), header = FALSE)


pull_lists <- lapply(list$V1, pull)


get_files <- function(pull_lists){
? sapply(pull_lists$content, ?[[?, ?filename? )
}


file_lists <- lapply(pull_lists, get_files)


Everything works fine until the last command, which generates:


Error in FUN(X[[1L]], ...) : subscript out of bounds


I?ve read here: http://stackoverflow.com/questions/18461499/subscript-out-of-bounds-on-character-vector


which leads me to believe that the reason for the error is that when I run file_lists <- lapply(pull_lists, get_files) some of the entries are missing. However, I cannot figure out how to clean up the data. I have tried something along the lines of:


clean_files <- function(pull_lists){
? pull_lists$content[which(nchar(pull_lists$content)==NULL)]<-NA
}


clean_lists <- lapply(pull_lists, clean_files)


But that simply replaces *every* value with NA (similarly if I change ==NULL to <1, or <2).


How can I make this code work?


Best,
Aron


--?
Aron Lindberg


Doctoral Candidate,?Information Systems
Weatherhead School of Management?
Case Western Reserve University
aronlindberg.github.io
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Feb 10 16:59:36 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 10 Feb 2015 10:59:36 -0500
Subject: [R] Coordinate or top left corner + offset
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D64FF7F@mb02.ads.tamu.edu>
References: <54D8DFC0.20203@ieu.uzh.ch>	<53BF8FB63FAF2E4A9455EF1EE94DA7262D64FD0F@mb02.ads.tamu.edu>
	<loom.20150210T004042-986@post.gmane.org>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D64FF7F@mb02.ads.tamu.edu>
Message-ID: <54DA2AE8.6060703@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-02-10 08:55 AM, David L Carlson wrote:
> Thanks, I didn't know about corner.label. I started with legend but
> I couldn't find a way to make the box small enough. It always
> covered much more of the corner than the letter which could have
> obscured data points.
> 
> David
> 

  Not sure, but setting the background to NA (bg=NA) might? help.


> -----Original Message----- From: R-help 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: Monday, February 9, 2015 5:43 PM To: r-help at stat.math.ethz.ch
>  Subject: Re: [R] Coordinate or top left corner + offset
> 
> David L Carlson <dcarlson <at> tamu.edu> writes:
> 
>> 
>> This is more complicated, but it could be rolled up into a 
>> function.
> Replace your mtext() call with the following:
>> 
>> # Set character expansion size cx <- 2.5 # Get the plot
>> coordinates and the character size ur <- par("usr")[c(1, 4)] chr
>> <- par("cxy") rect(ur[1]+chr[1]/10, ur[2]-chr[2]*cx,
>> ur[1]+chr[1]*cx, ur[2]-chr[1]/10, border=NA, col="white")
>> text(ur[1]+chr[1]*cx/2, ur[2]-chr[2]*cx/2, "a", font=2, cex=2.5,
>> col="red")
>> 
>> 1) Assign to cx the cex= value that you are using in text(). 2) 
>> Then get the upper right corner of the plot window and the size
>> of the
> default character width in user
>> coordinate units. 3) Draw a white rectangle the size of the 
>> character you are plotting (in
> this case cex=2.5). Shrink the left
>> and top edge so that the box around the plot area is not
>> obscured. 4) Plot your character in the center of the box.
>> 
> 
> There are two more tricks you can use here:
> 
> (1) cheat by using legend()
> 
> plot(0:10,0:10) legend("topleft",legend=NA,title="hello",bty="n")
> 
> (2) use plotrix::corner.label
> 
> ___________________________________
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJU2iroAAoJEOCV5YRblxUHV/YIAMn8cmOdQv035AUCYJCPgMl6
DDPztxTUIEsynQWPxyz2f853GnycIrsIkRDwWWKWaiGjsjeYEK2yb3kDpgLMyIca
JusoldnnIXGSwod2Hx8ozJFx2ggTDDyuP7uTkKWlXBTyM90XxVlZvEf8ZrbMSbly
dni6JMLdlUEBaYWvOV8dLuCYBFO1Mv5VXitY3YpoLGM5h3WIEK/6ABTVFBFXI9VH
Hujb1R7680mfY4V0jGmeY2vTdiIGZH6MGkOdLXNZhBwS1zjkBnoPJ6p6UMNVHbt0
DAgiNrfY+asG/NPEVgvvqeLpJ3TJ4xdt22o2ScG2vcbP0Qg6asrfnxqgrUc3vxM=
=94Ln
-----END PGP SIGNATURE-----


From petr.pikal at precheza.cz  Tue Feb 10 17:22:38 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 10 Feb 2015 16:22:38 +0000
Subject: [R] function that calculates using preceding records
In-Reply-To: <000901d0453e$1602b730$42082590$@org>
References: <000901d0453e$1602b730$42082590$@org>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F819@SRVEXCHMBX.precheza.cz>

Hi

I found an extremely ugly code :-)

# first reverse levels of treecode to correspond with order of values in data frame

temp$treecode<-factor(temp$treecode, rev(levels(temp$treecode)))

# add zeroes and values to rw and d

temp$rw[is.na(temp$rw)]<-0
library(zoo)
temp$d<-na.locf(temp$d)

# split your data acording to treecode

temp.l<-split(temp, temp$treecode)

# subtract from d cumulative sum of rw

mat<-sapply(sapply(temp.l, "[", 4), mean)-t(sapply(sapply(temp.l, "[",3), cumsum))

# transpose mat and remove dimension from mat
mat<-t(mat)
dim(mat)<-NULL

Now

temp <- cbind(temp, dsub=mat)

shall put subtracted values in correct order to your object.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Seth
> Bigelow
> Sent: Tuesday, February 10, 2015 3:30 PM
> To: r-help at r-project.org
> Subject: [R] function that calculates using preceding records
>
> Greetings:
>
>
>
> My dataframe has 4 variables: treecode, year, rw (tree ring width), and
> d (tree diameter). The d variable
>
> only has data for 2014. I wish to calculate earlier diameters by
> subtracting each year's growth (rw) from the
>
> previous year's diameter, by treecode. Can anyone help me with a
> function or statement that will do this?
>
> Sample dataset below: In this example, d in year 2013 for treecode
> TC149 would be 7.92 = 8.0 - 0.080.
>
>
>
> "treecode","year","rw","d"
>
> "1","TC149",2014,NA,8
>
> "2","TC149",2013,0.08,NA
>
> "3","TC149",2012,0.125,NA
>
> "4","TC149",2011,0.12,NA
>
> "5","TC149",2010,0.125,NA
>
> "6","TC148",2014,NA,34
>
> "7","TC148",2013,0.3,NA
>
> "8","TC148",2012,0.335,NA
>
> "9","TC148",2011,0.315,NA
>
> "10","TC148",2010,0.455,NA
>
> "11","TC147",2014,NA,55.5
>
> "12","TC147",2013,1.26,NA
>
> "13","TC147",2012,1.115,NA
>
> "14","TC147",2011,1.025,NA
>
> "15","TC147",2010,1.495,NA
>
> "16","TC146",2014,NA,60
>
> "17","TC146",2013,1.75,NA
>
> "18","TC146",2012,1.81,NA
>
> "19","TC146",2011,1.39,NA
>
> "20","TC146",2010,1.94,NA
>
>
>
>
>
> Seth W. Bigelow
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From aebingham2 at gmail.com  Tue Feb 10 18:22:44 2015
From: aebingham2 at gmail.com (Allen Bingham)
Date: Tue, 10 Feb 2015 09:22:44 -0800
Subject: [R] SAS equivalent for R's signif function?
In-Reply-To: <54D9ADA4.5080102@frontier.com>
References: <000901d044dd$f747e690$e5d7b3b0$@gmail.com>
	<54D9ADA4.5080102@frontier.com>
Message-ID: <005201d04556$2ef55b40$8ce011c0$@gmail.com>

Daniel,

Thanks for the link and the advice (vis-?-vis SAS-L ... after 30+ years of
using SAS I should have remembered that one which I used extensively when
learning SAS).

FYI-I'm working on some R code that may eventually need to be ported to SAS
--- and hence the reason for my question --- I don't want to use code in R
that might be too difficult to replicate in SAS.

I'll send you  a separate email about the PROC FCMP implementation you
mentioned.

Thanks again-Allen

-----Original Message-----
From: Daniel Nordlund [mailto:djnordlund at frontier.com] 
Sent: Monday, February 9, 2015 11:05 PM
To: Allen Bingham; r-help at r-project.org
Subject: Re: [R] SAS equivalent for R's signif function?

On 2/9/2015 7:02 PM, Allen Bingham wrote:
> Probably posting this to the wrong list ... but I'm in the process of 
> learning R, after many years of using SAS --- so I thought I'd ask 
> this question here:
>
>       Is there with a function (or macro) in SAS that performs the 
> same action as R's "signif" function, if so please provide?
>
> Tried to find via a Google search to no success. Doesn't seem to be in 
> the "R for SAS and SPSS Users" by Robert A. Munchen (first edition is 
> what I have), or in SAS and R by Ken Kleinman and Nicholas J. Horton 
> (2nd edition) [although in the latter they do list the R "signif" function
on page 61 ...
> but don't list a SAS equivalent.
>
> If you have a suggestion for a different list that I might ask this 
> question (assuming I don't get the answer here), provide that as well.
>
> Thanks-Allen
>
> ______________________________________
> Allen Bingham
> Bingham Statistical Consulting
> aebingham2 at gmail.com
> LinkedIn Profile: www.linkedin.com/pub/allen-bingham/3b/556/325
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Yes, this is the wrong list.  Your question is about SAS (that is what SAS-L
or SAScommunity is about) and this list is about R, and you already know
what function to use in R.  That said, I searched for "SAS round to fixed
number of significant digits" and found this link

http://support.sas.com/kb/24/728.html

You could turn this into a function style macro (but it will be ugly). 
If you have a recent enough version of SAS you could use PROC FCMP to turn
this into a function.

If you are interested contact me offline and I will send you a PROC FCMP
implementation.


Dan

-- 
Daniel Nordlund
Bothell, WA USA


From seth at forestadapt.org  Tue Feb 10 18:59:04 2015
From: seth at forestadapt.org (Seth Bigelow)
Date: Tue, 10 Feb 2015 12:59:04 -0500
Subject: [R] function that calculates using preceding records
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F819@SRVEXCHMBX.precheza.cz>
References: <000901d0453e$1602b730$42082590$@org>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F819@SRVEXCHMBX.precheza.cz>
Message-ID: <000b01d0455b$43f0a810$cbd1f830$@org>

Petr, 

Your code works therefore I pronounce it beautiful.

Many many thanks

--Seth



-----Original Message-----
From: PIKAL Petr [mailto:petr.pikal at precheza.cz] 
Sent: Tuesday, February 10, 2015 11:23 AM
To: Seth Bigelow; r-help at r-project.org
Subject: RE: [R] function that calculates using preceding records

Hi

I found an extremely ugly code :-)

# first reverse levels of treecode to correspond with order of values in data frame

temp$treecode<-factor(temp$treecode, rev(levels(temp$treecode)))

# add zeroes and values to rw and d

temp$rw[is.na(temp$rw)]<-0
library(zoo)
temp$d<-na.locf(temp$d)

# split your data acording to treecode

temp.l<-split(temp, temp$treecode)

# subtract from d cumulative sum of rw

mat<-sapply(sapply(temp.l, "[", 4), mean)-t(sapply(sapply(temp.l, "[",3), cumsum))

# transpose mat and remove dimension from mat
mat<-t(mat)
dim(mat)<-NULL

Now

temp <- cbind(temp, dsub=mat)

shall put subtracted values in correct order to your object.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Seth 
> Bigelow
> Sent: Tuesday, February 10, 2015 3:30 PM
> To: r-help at r-project.org
> Subject: [R] function that calculates using preceding records
>
> Greetings:
>
>
>
> My dataframe has 4 variables: treecode, year, rw (tree ring width), 
> and d (tree diameter). The d variable
>
> only has data for 2014. I wish to calculate earlier diameters by 
> subtracting each year's growth (rw) from the
>
> previous year's diameter, by treecode. Can anyone help me with a 
> function or statement that will do this?
>
> Sample dataset below: In this example, d in year 2013 for treecode
> TC149 would be 7.92 = 8.0 - 0.080.
>
>
>
> "treecode","year","rw","d"
>
> "1","TC149",2014,NA,8
>
> "2","TC149",2013,0.08,NA
>
> "3","TC149",2012,0.125,NA
>
> "4","TC149",2011,0.12,NA
>
> "5","TC149",2010,0.125,NA
>
> "6","TC148",2014,NA,34
>
> "7","TC148",2013,0.3,NA
>
> "8","TC148",2012,0.335,NA
>
> "9","TC148",2011,0.315,NA
>
> "10","TC148",2010,0.455,NA
>
> "11","TC147",2014,NA,55.5
>
> "12","TC147",2013,1.26,NA
>
> "13","TC147",2012,1.115,NA
>
> "14","TC147",2011,1.025,NA
>
> "15","TC147",2010,1.495,NA
>
> "16","TC146",2014,NA,60
>
> "17","TC146",2013,1.75,NA
>
> "18","TC146",2012,1.81,NA
>
> "19","TC146",2011,1.39,NA
>
> "20","TC146",2010,1.94,NA
>
>
>
>
>
> Seth W. Bigelow
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html and provide commented, minimal, self-contained, 
> reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From j.guilbert at auckland.ac.nz  Tue Feb 10 19:00:54 2015
From: j.guilbert at auckland.ac.nz (jgui001)
Date: Tue, 10 Feb 2015 10:00:54 -0800 (PST)
Subject: [R] Superscript in legend without using expression function
In-Reply-To: <54D697AD.90302@auckland.ac.nz>
References: <1423346275659-4702929.post@n4.nabble.com>
	<54D697AD.90302@auckland.ac.nz>
Message-ID: <1423591254238-4703036.post@n4.nabble.com>

Cheers Guys it worked!




--
View this message in context: http://r.789695.n4.nabble.com/Superscript-in-legend-without-using-expression-function-tp4702929p4703036.html
Sent from the R help mailing list archive at Nabble.com.


From laurent.boyer4 at eps.e-i.com  Tue Feb 10 18:41:18 2015
From: laurent.boyer4 at eps.e-i.com (LaurentB)
Date: Tue, 10 Feb 2015 09:41:18 -0800 (PST)
Subject: [R] oracle connection through proxy authentication
Message-ID: <1423590078887-4703034.post@n4.nabble.com>

Hi,

Due to a new company policy, I need to connect to an oracle database throw a
proxy authentication
(http://docs.oracle.com/cd/B19306_01/java.102/b14355/proxya.htm#JJDBC20000)
but I can't find the solution. 

Until now, I used the RODBC package but it seems that this one do not deal
with proxy authentication.

Can someone redirect me to the right path ?

Thanks in advance

Laurent



--
View this message in context: http://r.789695.n4.nabble.com/oracle-connection-through-proxy-authentication-tp4703034.html
Sent from the R help mailing list archive at Nabble.com.


From aebingham2 at gmail.com  Tue Feb 10 20:13:29 2015
From: aebingham2 at gmail.com (Allen Bingham)
Date: Tue, 10 Feb 2015 11:13:29 -0800
Subject: [R] Error: OutOfMemoryError (Java): GC overhead limit exceeded
In-Reply-To: <CAAxdm-5C1hKZkLxPoNPG6F+K0ZVaw2QrpnKQi2CoEBUM9bOKCQ@mail.gmail.com>
References: <419EED2318C2164DB95FBB20AA8810D8016CC227@smtp_mail.bankofamerica.com>	<A1E92A9D-1D43-410C-8D94-992A68A73D1F@dcn.davis.CA.us>	<CAAxdm-4BiaTV_BmauAmuK_kfpUxSmidd9wM70vO2LwN68mZ1mQ@mail.gmail.com>	<419EED2318C2164DB95FBB20AA8810D8016D147B@smtp_mail.bankofamerica.com>
	<CAAxdm-5C1hKZkLxPoNPG6F+K0ZVaw2QrpnKQi2CoEBUM9bOKCQ@mail.gmail.com>
Message-ID: <00d101d04565$a7e12cf0$f7a386d0$@gmail.com>

Rebecca,

An additional issue might be plots, pivot tables, etc. that you might have in separate sheets on the input Excel workbook (if you have those, just make a separate workbook with only the data you need for R in it).

BTW---I've recently been using the following option for similar use of XLConnect:

	options(java.parameters = "-Xmx4g" )

to set it at 4 Gbytes ... but I have lots of memory on my machine (16 Gbytes).

Another issue is that the above setting is for one instance/session of R --- you can't re-issue it with a larger number later in the same session --- you have to quit R first then re-issue with a larger number.

Good luck-Allen
______________________________________
Allen Bingham
Bingham Statistical Consulting
aebingham2 at gmail.com
LinkedIn Profile: www.linkedin.com/pub/allen-bingham/3b/556/325



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of jim holtman
Sent: Monday, February 2, 2015 10:23 AM
To: Yuan, Rebecca
Cc: R help (r-help at r-project.org)
Subject: Re: [R] Error: OutOfMemoryError (Java): GC overhead limit exceeded

How big are the worksheets that you are reading in?  Do you have multiple ones open at the same time?  Have to tried to use 'xlcFreeMemory' to see if this helps?  How much RAM to you have on your system?


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Feb 2, 2015 at 1:11 PM, Yuan, Rebecca < rebecca.yuan at bankofamerica.com> wrote:

>  Hello Jim,
>
>
>
> I already use ?.xls? for the loading, but still have the memory issue?.
>
>
>
> Thanks,
>
>
>
> Rebecca
>
>
>
>
>
> *From:* jim holtman [mailto:jholtman at gmail.com]
> *Sent:* Monday, February 02, 2015 10:21 AM
> *To:* Jeff Newmiller
> *Cc:* Yuan, Rebecca; R help (r-help at r-project.org)
> *Subject:* Re: [R] Error: OutOfMemoryError (Java): GC overhead limit 
> exceeded
>
>
>
> On the off-chance, are you using XLConnect or xlsx packages that are 
> using Java to access the spreadsheets?  If it is XLConnect, are you 
> access the '.xlsx' style workbooks?  If so, can you try using '.xls' 
> workbooks?  This is a problem that I have had; the '.xlsx' workbooks 
> take a lot more resources (CPU and memory) to process.
>
>
>
> A little more information like what your sessionInfo is would help a 
> lot in responding to your problem.
>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
>
> On Mon, Feb 2, 2015 at 9:27 AM, Jeff Newmiller 
> <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> The memory issue is in Java, not R.
>
> You can either be more parsimonious in your use of Java memory (we 
> have no idea what you are doing with it here, so how you do that is up 
> to you), or you can allocate more memory to Java (you may be able to 
> guess how to do that, or read the Java documentation on the X parameter).
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ----------------------------------------------------------------------
> ----- Sent from my phone. Please excuse my brevity.
>
> On February 2, 2015 5:43:50 AM PST, "Yuan, Rebecca" < 
> rebecca.yuan at bankofamerica.com> wrote:
> >Hello all,
> >
> >When I met this following error message:
> >
> >Error: OutOfMemoryError (Java): GC overhead limit exceeded
> >
> >I usually use the following options to overcome the memory limit:
> >
> >options(java.parameters = "-Xmx1024m") # to reduce the error message
> >"Error: OutOfMemoryError (Java): GC overhead limit exceeded"
> >
> >However, this seems not working any more, is there any other way to 
> >help avoiding the memory error issue in R?
> >
> >Thanks very much!
> >
> >Cheers,
> >
> >Rebecca
> >
> >
> >
> >20
> >
> >---------------------------------------------------------------------
> >- This message, and any attachments, is for the intended 
> >r...{{dropped:5}}
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>  ------------------------------
> This message, and any attachments, is for the \ > in...{{dropped:10}}


From amos.elberg at gmail.com  Tue Feb 10 20:08:55 2015
From: amos.elberg at gmail.com (Amos B. Elberg)
Date: Tue, 10 Feb 2015 14:08:55 -0500
Subject: [R] Problems with tm package, Removeword and trasformations
In-Reply-To: <CAJJdUGjYk16JKHd67mj+-QHkNDYA91eoTWxMOc7qC3ppsKM9yw@mail.gmail.com>
References: <CAJJdUGjYk16JKHd67mj+-QHkNDYA91eoTWxMOc7qC3ppsKM9yw@mail.gmail.com>
Message-ID: <BB30168F-F423-4490-80A4-B6F30E8C72E3@gmail.com>

Trying to use t m to analyze tweets, you're going to experience a long stream of issues like the one you found, which generally relate to text formatting. I worked through them over the past few months for a project. If you email me offline I'll try to help and share some example code.


> On Feb 10, 2015, at 9:52 AM, Renato Medei <medei.ren at gmail.com> wrote:
> 
> Dear all,
> I'm sorry but  as all the newbies  I have a lot of problems to solve.
> I'm using R 3.1.2 under osx  10.10.2.
> I'm working with tm to analyze some tweets and I received some strange
> errors when I tried to remove stopwords (See below error 1), to transform
> content (See below error 2) and to create document term Matrix (See below
> error 3)
> Could anyone help me?
> 
> Error 1
>> tweets = searchTwitter("rimini", n=1000)
>> tweets = sapply(tweets, function(x) x$getText())
>> tweets_corpus = Corpus(VectorSource(tweets))
>> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
>> tweets_corpus <- tm_map(tweets_corpus, toSpace,
> "(f|ht)tp(s?)://(.*)[.][a-z]+")
>> tweets_corpus <- tm_map(tweets_corpus, toSpace, "RT |via ")
>> tweets_corpus <- tm_map(tweets_corpus, toSpace, "@[^\\s]+")
>> tweets_corpus <- tm_map(tweets_corpus, removeNumbers)
>> tweets_corpus <- tm_map(tweets_corpus, removePunctuation)
>> tweets_corpus <- tm_map(tweets_corpus, removeWords, c("rimini", "Rimini",
> "Riviera", "riviera"))
>> tweets_corpus <- tm_map(tweets_corpus, stopwords("italian"))
> Warning message:
> In mclapply(content(x), FUN, ...) :
>  all scheduled cores encountered errors in user code
> 
> Error2
>> tweets = searchTwitter("rimini", n=1000)
>> tweets = sapply(tweets, function(x) x$getText())
>> tweets_corpus = Corpus(VectorSource(tweets))
>> tweets_corpus
> <<VCorpus (documents: 1000, metadata (corpus/indexed): 0/0)>>
>> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
>> tweets_corpus <- tm_map(tweets_corpus, toSpace,
> "(f|ht)tp(s?)://(.*)[.][a-z]+")
>> tweets_corpus <- tm_map(tweets_corpus, toSpace, "RT |via ")
>> tweets_corpus <- tm_map(tweets_corpus, toSpace, "@[^\\s]+")
>> tweets_corpus <- tm_map(tweets_corpus, removeNumbers)
>> tweets_corpus <- tm_map(tweets_corpus, removePunctuation)
>> tweets_corpus <- tm_map(tweets_corpus, removeWords, c("rimini", "Rimini",
> "Riviera", "riviera"))
>> tweets_corpus <- tm_map(tweets_corpus, content_transformer(tolower))
> Warning message:
> In mclapply(content(x), FUN, ...) :
>  all scheduled cores encountered errors in user code
> 
> 
> Error3
> 
>> tweets = searchTwitter("rimini", n=1000)
>> tweets = sapply(tweets, function(x) x$getText())
>> tweets_corpus = Corpus(VectorSource(tweets))
>> tweets_corpus
> <<VCorpus (documents: 1000, metadata (corpus/indexed): 0/0)>>
>> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
>> tweets_corpus <- tm_map(tweets_corpus, toSpace,
> "(f|ht)tp(s?)://(.*)[.][a-z]+")
>> tweets_corpus <- tm_map(tweets_corpus, toSpace, "RT |via ")
>> tweets_corpus <- tm_map(tweets_corpus, toSpace, "@[^\\s]+")
>> tweets_corpus <- tm_map(tweets_corpus, removeNumbers)
>> tweets_corpus <- tm_map(tweets_corpus, removePunctuation)
>> tweets_corpus <- tm_map(tweets_corpus, removeWords, c("rimini", "Rimini",
> "Riviera", "riviera"))
>> dtm <- DocumentTermMatrix(tweets_corpus)
> Errore in simple_triplet_matrix(i = i, j = j, v = as.numeric(v), nrow =
> length(allTerms),  :
>  'i, j, v' different lengths
> Inoltre: Warning messages:
> 1: In mclapply(unname(content(x)), termFreq, control) :
>  all scheduled cores encountered errors in user code
> 2: In simple_triplet_matrix(i = i, j = j, v = as.numeric(v), nrow =
> length(allTerms),  :
>  si ? prodotto un NA per coercizione
> 
> 
> Thank you for your help
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Tue Feb 10 20:29:54 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Feb 2015 19:29:54 +0000
Subject: [R] oracle connection through proxy authentication
In-Reply-To: <1423590078887-4703034.post@n4.nabble.com>
References: <1423590078887-4703034.post@n4.nabble.com>
Message-ID: <54DA5C32.8030803@stats.ox.ac.uk>

On 10/02/2015 17:41, LaurentB wrote:
> Hi,
>
> Due to a new company policy, I need to connect to an oracle database throw a
> proxy authentication
> (http://docs.oracle.com/cd/B19306_01/java.102/b14355/proxya.htm#JJDBC20000)
> but I can't find the solution.
>
> Until now, I used the RODBC package but it seems that this one do not deal
> with proxy authentication.
>
> Can someone redirect me to the right path ?

This is not an R-help (nor R nor RODBC, maybe R-sig-db) issue.  Check 
out the documentation for your Oracle ODBC driver, or ask your Oracle 
support.

>
> Thanks in advance
>
> Laurent

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From seth at forestadapt.org  Tue Feb 10 20:44:34 2015
From: seth at forestadapt.org (Seth Bigelow)
Date: Tue, 10 Feb 2015 14:44:34 -0500
Subject: [R] function that calculates using preceding records
In-Reply-To: <CADv2QyFDZtJd_B81Da6ni2K4451HdEk0_=RHz1GYKqeG62_Z9A@mail.gmail.com>
References: <000901d0453e$1602b730$42082590$@org>
	<CADv2QyFDZtJd_B81Da6ni2K4451HdEk0_=RHz1GYKqeG62_Z9A@mail.gmail.com>
Message-ID: <000f01d04569$ffcef420$ff6cdc60$@org>

Aha, this solution is even more elegant than that of the previous suggestion. Thanks for alerting me to the capabilities of plyr!

--Seth

-----Original Message-----
From: Dennis Murphy [mailto:djmuser at gmail.com] 
Sent: Tuesday, February 10, 2015 2:14 PM
To: Seth Bigelow
Subject: Re: [R] function that calculates using preceding records

Hi:

Here's another way. If I understand this correctly, you can get the diameters by setting the NA values in d to zero, taking the cumulative sum of d (within treecode) and then subtracting the result from diam[1]. Since I'm used to doing this type of thing in data manipulation packages, I prefer to write a function to do the work and then run it in concert with plyr::ddply().

Letting DF represent the name of your data frame,

# Function to apply to each subgroup (treecode ID) f <- function(d)
  {
      d <- d[order(-d$year), ]         # order by decreasing year
      d$rw[is.na(d$rw)] <- 0          # set NAs in rw to 0
      d$diam <- d$d[1] - cumsum(d$rw)    # compute past diams
      d                                        # return modified data frame
  }

library(plyr)
# This applies the function f to each sub-data frame defined # by unique values of treecode ddply(DF, .(treecode), f)

   treecode year    rw    d   diam
1     TC146 2014 0.000 60.0 60.000
2     TC146 2013 1.750   NA 58.250
3     TC146 2012 1.810   NA 56.440
4     TC146 2011 1.390   NA 55.050
5     TC146 2010 1.940   NA 53.110
6     TC147 2014 0.000 55.5 55.500
7     TC147 2013 1.260   NA 54.240
8     TC147 2012 1.115   NA 53.125
9     TC147 2011 1.025   NA 52.100
10    TC147 2010 1.495   NA 50.605
11    TC148 2014 0.000 34.0 34.000
12    TC148 2013 0.300   NA 33.700
13    TC148 2012 0.335   NA 33.365
14    TC148 2011 0.315   NA 33.050
15    TC148 2010 0.455   NA 32.595
16    TC149 2014 0.000  8.0  8.000
17    TC149 2013 0.080   NA  7.920
18    TC149 2012 0.125   NA  7.795
19    TC149 2011 0.120   NA  7.675
20    TC149 2010 0.125   NA  7.550


HTH,
Dennis

On Tue, Feb 10, 2015 at 6:30 AM, Seth Bigelow <seth at forestadapt.org> wrote:
> Greetings:
>
>
>
> My dataframe has 4 variables: treecode, year, rw (tree ring width), 
> and d (tree diameter). The d variable
>
> only has data for 2014. I wish to calculate earlier diameters by 
> subtracting each year's growth (rw) from the
>
> previous year's diameter, by treecode. Can anyone help me with a 
> function or statement that will do this?
>
> Sample dataset below: In this example, d in year 2013 for treecode 
> TC149 would be 7.92 = 8.0 - 0.080.
>
>
>
> "treecode","year","rw","d"
>
> "1","TC149",2014,NA,8
>
> "2","TC149",2013,0.08,NA
>
> "3","TC149",2012,0.125,NA
>
> "4","TC149",2011,0.12,NA
>
> "5","TC149",2010,0.125,NA
>
> "6","TC148",2014,NA,34
>
> "7","TC148",2013,0.3,NA
>
> "8","TC148",2012,0.335,NA
>
> "9","TC148",2011,0.315,NA
>
> "10","TC148",2010,0.455,NA
>
> "11","TC147",2014,NA,55.5
>
> "12","TC147",2013,1.26,NA
>
> "13","TC147",2012,1.115,NA
>
> "14","TC147",2011,1.025,NA
>
> "15","TC147",2010,1.495,NA
>
> "16","TC146",2014,NA,60
>
> "17","TC146",2013,1.75,NA
>
> "18","TC146",2012,1.81,NA
>
> "19","TC146",2011,1.39,NA
>
> "20","TC146",2010,1.94,NA
>
>
>
>
>
> Seth W. Bigelow
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Tue Feb 10 21:51:12 2015
From: jholtman at gmail.com (jim holtman)
Date: Tue, 10 Feb 2015 15:51:12 -0500
Subject: [R] Error: OutOfMemoryError (Java): GC overhead limit exceeded
In-Reply-To: <00d101d04565$a7e12cf0$f7a386d0$@gmail.com>
References: <419EED2318C2164DB95FBB20AA8810D8016CC227@smtp_mail.bankofamerica.com>
	<A1E92A9D-1D43-410C-8D94-992A68A73D1F@dcn.davis.CA.us>
	<CAAxdm-4BiaTV_BmauAmuK_kfpUxSmidd9wM70vO2LwN68mZ1mQ@mail.gmail.com>
	<419EED2318C2164DB95FBB20AA8810D8016D147B@smtp_mail.bankofamerica.com>
	<CAAxdm-5C1hKZkLxPoNPG6F+K0ZVaw2QrpnKQi2CoEBUM9bOKCQ@mail.gmail.com>
	<00d101d04565$a7e12cf0$f7a386d0$@gmail.com>
Message-ID: <CAAxdm-4z6Kj_jFcWca8qj1HTWC6v+FJHVY0Wv4_f+2fRD0Y2Rg@mail.gmail.com>

Another to try is the 'openxlsx' package if  you have '.xlsx' files; it
does not read '.xls' files.  It seems to be faster than XLConnect and does
not require Java; it uses Rcpp to access the APIs.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Tue, Feb 10, 2015 at 2:13 PM, Allen Bingham <aebingham2 at gmail.com> wrote:

> Rebecca,
>
> An additional issue might be plots, pivot tables, etc. that you might have
> in separate sheets on the input Excel workbook (if you have those, just
> make a separate workbook with only the data you need for R in it).
>
> BTW---I've recently been using the following option for similar use of
> XLConnect:
>
>         options(java.parameters = "-Xmx4g" )
>
> to set it at 4 Gbytes ... but I have lots of memory on my machine (16
> Gbytes).
>
> Another issue is that the above setting is for one instance/session of R
> --- you can't re-issue it with a larger number later in the same session
> --- you have to quit R first then re-issue with a larger number.
>
> Good luck-Allen
> ______________________________________
> Allen Bingham
> Bingham Statistical Consulting
> aebingham2 at gmail.com
> LinkedIn Profile: www.linkedin.com/pub/allen-bingham/3b/556/325
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of jim
> holtman
> Sent: Monday, February 2, 2015 10:23 AM
> To: Yuan, Rebecca
> Cc: R help (r-help at r-project.org)
> Subject: Re: [R] Error: OutOfMemoryError (Java): GC overhead limit exceeded
>
> How big are the worksheets that you are reading in?  Do you have multiple
> ones open at the same time?  Have to tried to use 'xlcFreeMemory' to see if
> this helps?  How much RAM to you have on your system?
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Mon, Feb 2, 2015 at 1:11 PM, Yuan, Rebecca <
> rebecca.yuan at bankofamerica.com> wrote:
>
> >  Hello Jim,
> >
> >
> >
> > I already use ?.xls? for the loading, but still have the memory issue?.
> >
> >
> >
> > Thanks,
> >
> >
> >
> > Rebecca
> >
> >
> >
> >
> >
> > *From:* jim holtman [mailto:jholtman at gmail.com]
> > *Sent:* Monday, February 02, 2015 10:21 AM
> > *To:* Jeff Newmiller
> > *Cc:* Yuan, Rebecca; R help (r-help at r-project.org)
> > *Subject:* Re: [R] Error: OutOfMemoryError (Java): GC overhead limit
> > exceeded
> >
> >
> >
> > On the off-chance, are you using XLConnect or xlsx packages that are
> > using Java to access the spreadsheets?  If it is XLConnect, are you
> > access the '.xlsx' style workbooks?  If so, can you try using '.xls'
> > workbooks?  This is a problem that I have had; the '.xlsx' workbooks
> > take a lot more resources (CPU and memory) to process.
> >
> >
> >
> > A little more information like what your sessionInfo is would help a
> > lot in responding to your problem.
> >
> >
> >
> > Jim Holtman
> > Data Munger Guru
> >
> > What is the problem that you are trying to solve?
> > Tell me what you want to do, not how you want to do it.
> >
> >
> >
> > On Mon, Feb 2, 2015 at 9:27 AM, Jeff Newmiller
> > <jdnewmil at dcn.davis.ca.us>
> > wrote:
> >
> > The memory issue is in Java, not R.
> >
> > You can either be more parsimonious in your use of Java memory (we
> > have no idea what you are doing with it here, so how you do that is up
> > to you), or you can allocate more memory to Java (you may be able to
> > guess how to do that, or read the Java documentation on the X parameter).
> >
> ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> > Go...
> >                                       Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> > ----------------------------------------------------------------------
> > ----- Sent from my phone. Please excuse my brevity.
> >
> > On February 2, 2015 5:43:50 AM PST, "Yuan, Rebecca" <
> > rebecca.yuan at bankofamerica.com> wrote:
> > >Hello all,
> > >
> > >When I met this following error message:
> > >
> > >Error: OutOfMemoryError (Java): GC overhead limit exceeded
> > >
> > >I usually use the following options to overcome the memory limit:
> > >
> > >options(java.parameters = "-Xmx1024m") # to reduce the error message
> > >"Error: OutOfMemoryError (Java): GC overhead limit exceeded"
> > >
> > >However, this seems not working any more, is there any other way to
> > >help avoiding the memory error issue in R?
> > >
> > >Thanks very much!
> > >
> > >Cheers,
> > >
> > >Rebecca
> > >
> > >
> > >
> > >20
> > >
> > >---------------------------------------------------------------------
> > >- This message, and any attachments, is for the intended
> > >r...{{dropped:5}}
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >  ------------------------------
> > This message, and any attachments, is for the
> > intended...{{dropped:11}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From aron.lindberg at case.edu  Tue Feb 10 22:41:08 2015
From: aron.lindberg at case.edu (Aron Lindberg)
Date: Tue, 10 Feb 2015 13:41:08 -0800 (PST)
Subject: [R] How to clean up missing values in a list of lists
In-Reply-To: <CADv2QyEEd9pu0hOJQL1iOtO09RhMAjJM0-8OPn6MJks7OwG9HQ@mail.gmail.com>
References: <CADv2QyEEd9pu0hOJQL1iOtO09RhMAjJM0-8OPn6MJks7OwG9HQ@mail.gmail.com>
Message-ID: <1423604467258.1ffc2a2e@Nodemailer>

Thanks Dennis!




In the end try worked:





get_files <- function(pull_lists){

? try(sapply(pull_lists$content, "[[", "filename" ))

}




Best,

Aron




--?

Aron Lindberg




Doctoral Candidate,?Information Systems

Weatherhead School of Management?

Case Western Reserve University

aronlindberg.github.io

On Tue, Feb 10, 2015 at 1:22 PM, Dennis Murphy <djmuser at gmail.com> wrote:

> Hi:
> It sounds like you need a condition handler, so look at ?try and
> ?tryCatch for starters. I'd also suggest looking at ?plyr::failwith if
> all you need is a simple error handler. One of the advantages of these
> functions is that they are designed for situations like yours, where
> an lapply() invocation over a list may occasionally result in an
> error, warning or message. The tryCatch() function is the most
> versatile, in that it allows you to define separate handlers for
> errors, warnings, messages and interrupts ; failwith() and try() are
> primarily used for dealing with errors alone.
> More details re these functions can be found here:
> http://adv-r.had.co.nz/Exceptions-Debugging.html
> HTH,
> Dennis
> On Tue, Feb 10, 2015 at 6:46 AM, Aron Lindberg <aron.lindberg at case.edu> wrote:
>> Hi,
>>
>>
>> I?m trying to query the Github API, and I?m running into some data munging issues, so I was hoping someone on the list might advise.
>>
>>
>> Here?s my code. To run it you need to replace client_id and client_secret with your own authorization information for Github.
>>
>>
>> library(github)
>> library(RCurl)
>> library(httpuv)
>> library(jsonlite)
>>
>>
>> # Set up the query
>> ctx = interactive.login(?client_id?, ?client_secret?)
>>
>>
>> pull <- function(i){
>>   get.pull.request.files(owner = ?rails?, repo = ?rails?, id = i, ctx = get.github.context(), per_page=1000)
>> }
>>
>>
>> data <- read.csv(getURL(?https://gist.githubusercontent.com/aronlindberg/a3d135a303664046c94a/raw/e42a0734ec4542eccf5f4d5bdeed5afbdd1720e9/pull_ids?), sep = ?\n?)
>>
>>
>> list <- read.csv(textConnection(data), header = FALSE)
>>
>>
>> pull_lists <- lapply(list$V1, pull)
>>
>>
>> get_files <- function(pull_lists){
>>   sapply(pull_lists$content, ?[[?, ?filename? )
>> }
>>
>>
>> file_lists <- lapply(pull_lists, get_files)
>>
>>
>> Everything works fine until the last command, which generates:
>>
>>
>> Error in FUN(X[[1L]], ...) : subscript out of bounds
>>
>>
>> I?ve read here: http://stackoverflow.com/questions/18461499/subscript-out-of-bounds-on-character-vector
>>
>>
>> which leads me to believe that the reason for the error is that when I run file_lists <- lapply(pull_lists, get_files) some of the entries are missing. However, I cannot figure out how to clean up the data. I have tried something along the lines of:
>>
>>
>> clean_files <- function(pull_lists){
>>   pull_lists$content[which(nchar(pull_lists$content)==NULL)]<-NA
>> }
>>
>>
>> clean_lists <- lapply(pull_lists, clean_files)
>>
>>
>> But that simply replaces *every* value with NA (similarly if I change ==NULL to <1, or <2).
>>
>>
>> How can I make this code work?
>>
>>
>> Best,
>> Aron
>>
>>
>> --
>> Aron Lindberg
>>
>>
>> Doctoral Candidate, Information Systems
>> Weatherhead School of Management
>> Case Western Reserve University
>> aronlindberg.github.io
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From amc5981 at gmail.com  Tue Feb 10 22:45:05 2015
From: amc5981 at gmail.com (Alexandra Catena)
Date: Tue, 10 Feb 2015 13:45:05 -0800
Subject: [R] How to unzip a .gz file
Message-ID: <CAHpsUFa6ECacPe_28Sdq0V9zRyvWUANmeXbgDSoD5S5VKUT7gA@mail.gmail.com>

Hello,

Can someone help me with unzipping a .gz file.  I used:

readLines(gzfile('/home/file.gz'))


I also found that I could use gunzip, but after trying to install it, it
says:

 "package ?gunzip? is not available (for R version 2.15.1)"


Thanks,
Alexandra

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Feb 10 23:05:00 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 11 Feb 2015 09:05:00 +1100
Subject: [R] Breaking y- axis using gap.barplot
In-Reply-To: <f8cedd1be473d5a5e8c6dacfd415dbd7.squirrel@iisermohali.ac.in>
References: <f8cedd1be473d5a5e8c6dacfd415dbd7.squirrel@iisermohali.ac.in>
Message-ID: <CA+8X3fVUs++bQ6889YheX6c03gZ5T1j8y_OwvEp1TMYLEnnXMw@mail.gmail.com>

Hi reviverma,
I think your problem is that you have chosen the wrong gap, as it cuts
out all of the small bars. Try this:

gap.barplot(hdata$counts, gap=c(120,15900), xlab="RMSD",
 ytics=c(0,100,16000,16100,16200,16300),ylab="Frequency",
 xtics=hdata$breaks)

Note that you have one more "breaks" than you do "counts" in your
example - I corrected this.

Jim

On Tue, Feb 10, 2015 at 4:41 PM,  <riviverma at iisermohali.ac.in> wrote:
> Hello all
>
> I am trying to plot histogram with break in y-axis for my data by
> following various posts on R- help but none seems solving my problem. My
> data looks like:
>
>> hdata
> $breaks
>  [1]  0  5 10 15 20 25 30 35 40 45 50
>
> $counts
>  [1] 16311   108    24     8     1     3     0     1     6     3
>
> on using: gap.barplot(hdata$counts, gap=c(26,108), xlab="RMSD",
> ytics=c(0,25,110), ylab="Frequency", xtics=hdata$breaks)
>
> the plot does not seems correct.
>
> Please help.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From clint at ecy.wa.gov  Tue Feb 10 23:06:59 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Tue, 10 Feb 2015 14:06:59 -0800 (PST)
Subject: [R] How to unzip a .gz file
In-Reply-To: <CAHpsUFa6ECacPe_28Sdq0V9zRyvWUANmeXbgDSoD5S5VKUT7gA@mail.gmail.com>
References: <CAHpsUFa6ECacPe_28Sdq0V9zRyvWUANmeXbgDSoD5S5VKUT7gA@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1502101404360.21564@aeolus.ecy.wa.gov>

Alexandra,  Although you may not have control over the installation of R, 
2.15.1 is very old and should be upgraded--the current is 3.1.2

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Tue, 10 Feb 2015, Alexandra Catena wrote:

> Hello,
>
> Can someone help me with unzipping a .gz file.  I used:
>
> readLines(gzfile('/home/file.gz'))
>
>
> I also found that I could use gunzip, but after trying to install it, it
> says:
>
> "package ?gunzip? is not available (for R version 2.15.1)"
>
>
> Thanks,
> Alexandra
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From puetz at mpipsykl.mpg.de  Tue Feb 10 23:10:35 2015
From: puetz at mpipsykl.mpg.de (=?windows-1252?Q?Benno_P=FCtz?=)
Date: Tue, 10 Feb 2015 23:10:35 +0100
Subject: [R] How to unzip a .gz file
In-Reply-To: <CAHpsUFa6ECacPe_28Sdq0V9zRyvWUANmeXbgDSoD5S5VKUT7gA@mail.gmail.com>
References: <CAHpsUFa6ECacPe_28Sdq0V9zRyvWUANmeXbgDSoD5S5VKUT7gA@mail.gmail.com>
Message-ID: <B1161594-7321-40A4-8F11-A8231D6FB3EF@mpipsykl.mpg.de>

readLines (as well as other I/O routines) handles gzip files transparently, you should be able to simply use

	readLines('/home/file.gz?)


Benno

On 10 Feb 2015, at 22:45 , Alexandra Catena <amc5981 at gmail.com> wrote:

> Hello,
> 
> Can someone help me with unzipping a .gz file.  I used:
> 
> readLines(gzfile('/home/file.gz'))
> 
> 
> I also found that I could use gunzip, but after trying to install it, it
> says:
> 
> "package ?gunzip? is not available (for R version 2.15.1)"
> 
> 
> Thanks,
> Alexandra
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From varinsacha at yahoo.fr  Wed Feb 11 00:16:48 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Tue, 10 Feb 2015 23:16:48 +0000 (UTC)
Subject: [R] library(Rcmdr) sh: otool: command not found
Message-ID: <527541485.4226498.1423610208089.JavaMail.yahoo@mail.yahoo.com>

Hi R experts,

I have just updated R and RStudio. I am running OS X 10.6.8

R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin10.8.0 (64-bit)


RStudio Version 0.98.1102 ? ? 2009-2014 RStudio, Inc.
Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/534.59.10 (KHTML, like Gecko)


Everything is ok for installing the Rcmdr package.

install.packages("Rcmdr")
Installing package into ?/Users/Caro/Library/R/3.1/library?
(as ?lib? is unspecified)
essai de l'URL 'http://cran.rstudio.com/bin/macosx/contrib/3.1/Rcmdr_2.1-6.tgz'
Content type 'application/x-gzip' length 5340999 bytes (5.1 Mb)
URL ouverte
==================================================
downloaded 5.1 Mb


The downloaded binary packages are in
/var/folders/V2/V26Pbtc-GsSUTVPWEj6Bdk+++TI/-Tmp-//RtmpgNlyXf/downloaded_packages
> 


But once I write library(Rcmdr), it doesn't work.

library(Rcmdr)
Le chargement a n?cessit? le package : splines
Le chargement a n?cessit? le package : RcmdrMisc
Le chargement a n?cessit? le package : car
Le chargement a n?cessit? le package : sandwich
Error : .onLoad a ?chou? dans loadNamespace() pour 'tcltk', d?tails :
appel : system2("otool", c("-L", shQuote(DLL)), stdout = TRUE)
erreur : erreur lors de l'ex?cution d'une commande
Erreur : le chargement du package ou de l'espace de noms a ?chou? pour ?Rcmdr?
sh: otool: command not found

Has somebody any idea of how I can solve this problem ?

Thanks,


From NordlDJ at dshs.wa.gov  Wed Feb 11 00:32:28 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 10 Feb 2015 23:32:28 +0000
Subject: [R] library(Rcmdr) sh: otool: command not found
In-Reply-To: <527541485.4226498.1423610208089.JavaMail.yahoo@mail.yahoo.com>
References: <527541485.4226498.1423610208089.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276623B09017@WAXMXOLYMB025.WAX.wa.lcl>

Try setting dependencies = TRUE in install.packages()

install.packages("Rcmdr", dependencies = TRUE)


hope this is helpful,

Dan

Daniel J. Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of varin
> sacha
> Sent: Tuesday, February 10, 2015 3:17 PM
> To: r-help at R-project.org
> Subject: [R] library(Rcmdr) sh: otool: command not found
> 
> Hi R experts,
> 
> I have just updated R and RStudio. I am running OS X 10.6.8
> 
> R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
> Copyright (C) 2014 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
> 
> 
> RStudio Version 0.98.1102 ? ? 2009-2014 RStudio, Inc.
> Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/534.59.10
> (KHTML, like Gecko)
> 
> 
> Everything is ok for installing the Rcmdr package.
> 
> install.packages("Rcmdr")
> Installing package into ?/Users/Caro/Library/R/3.1/library?
> (as ?lib? is unspecified)
> essai de l'URL
> 'http://cran.rstudio.com/bin/macosx/contrib/3.1/Rcmdr_2.1-6.tgz'
> Content type 'application/x-gzip' length 5340999 bytes (5.1 Mb)
> URL ouverte
> ==================================================
> downloaded 5.1 Mb
> 
> 
> The downloaded binary packages are in
> /var/folders/V2/V26Pbtc-GsSUTVPWEj6Bdk+++TI/-Tmp-
> //RtmpgNlyXf/downloaded_packages
> >
> 
> 
> But once I write library(Rcmdr), it doesn't work.
> 
> library(Rcmdr)
> Le chargement a n?cessit? le package : splines
> Le chargement a n?cessit? le package : RcmdrMisc
> Le chargement a n?cessit? le package : car
> Le chargement a n?cessit? le package : sandwich
> Error : .onLoad a ?chou? dans loadNamespace() pour 'tcltk', d?tails :
> appel : system2("otool", c("-L", shQuote(DLL)), stdout = TRUE)
> erreur : erreur lors de l'ex?cution d'une commande
> Erreur : le chargement du package ou de l'espace de noms a ?chou? pour
> ?Rcmdr?
> sh: otool: command not found
> 
> Has somebody any idea of how I can solve this problem ?
> 
> Thanks,
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From btrautman84 at gmail.com  Wed Feb 11 00:58:13 2015
From: btrautman84 at gmail.com (Brian Trautman)
Date: Tue, 10 Feb 2015 15:58:13 -0800
Subject: [R] MApply and SubStr
Message-ID: <CAFYnejJ7BOV3j9E53yOy5Y8Buhe_kbioGvodMWpAyNU7tVtSZA@mail.gmail.com>

Hi!

I'm trying to write a custom function that applies SubStr to a string, and
then depending on the arguments, converts the output to a number.

The substring part of my code works fine, but it's not converting the way I
want to --

options('stringsAsFactors'=FALSE)
require(data.table)

substr_typeswitch <- function(x, start, stop, typeto='chr')
{
  tmpvar <- substr(x=x, start=start, stop=stop)
  tmpvar <- switch(typeto, num=as.numeric(tmpvar), tmpvar)
  return(tmpvar)
}
  startpos <- c(01, 03)
  endpos <-   c(02, 04)
  typelist <- c('chr', 'num')

  startdata <- as.data.table(c('aa01', 'bb02'))

  enddata_want <- as.data.table(mapply(substr_typeswitch, startdata,
startpos, endpos, typelist))

If I examine enddata_want --

> str(enddata_want)
Classes ?data.table? and 'data.frame': 2 obs. of  2 variables:
 $ V1: chr  "aa" "bb"
 $ NA: chr  "1" "2"
 - attr(*, ".internal.selfref")=<externalptr>

"1" and "2" are being stored as character, and not as number.

Can anyone help me understand what I'm doing wrong?

Thank you!

	[[alternative HTML version deleted]]


From wyllys at ischool.utexas.edu  Wed Feb 11 01:09:22 2015
From: wyllys at ischool.utexas.edu (Ronald Wyllys)
Date: Tue, 10 Feb 2015 18:09:22 -0600
Subject: [R] Ranjan Maitra's comment "Re: Variance is different in R vs.
	Excel?
In-Reply-To: <mailman.1.1423566002.4267.r-help@r-project.org>
References: <mailman.1.1423566002.4267.r-help@r-project.org>
Message-ID: <54DA9DB2.6090600@ischool.utexas.edu>

FWIW, both Excel 2007 and LibreOffice 4.2 yield the correct variance for 
the numbers in Ranjan Maitra's HW problem for incoming students in R.  
Namely, both these programs yield a sample variance of 0.2777777778 
(rounded to 10 decimal digits).

Ronald Wyllys


On 02/10/2015 05:00 AM, r-help-request at r-project.org wrote:
> ate: Mon, 9 Feb 2015 17:39:14 -0600
> From: Ranjan Maitra<maitra.mbox.ignored at inbox.com>
> To:<r-help at stat.math.ethz.ch>
> Subject: Re: [R] Variance is different in R vs. Excel?
> Message-ID:<20150209173914.bae4d99ebeadafed3515372c at inbox.com>
> Content-Type: text/plain; charset="us-ascii"
>
> I suspect that this is the long-documented issue with indeed an entire industry -- and publications -- devoted to finding such errors in Excel. Till the 2013 version, it used to be a favorite HW problem of mine. Basically, Excel uses the "short formula" to calculate the variance and the sd. This "short formula" has numerical issues with larger numbers (though I am surprised at the OP's data because these numbers were not that large). Anyway, the "long formula" which removes the mean from each datapoint, squares and sums is preferred with large numbers.
>
> Btw, my HW problem for incoming students in my R class would be this:
>
> Consider the following numbers:
> 100000000000001, 100000000000002, 100000000000001, 100000000000002, 100000000000001,
> 100000000000002, 100000000000001, 100000000000002, 100000000000001, 100000000000002.
>
> Calculate the variance in Excel (gives pure garbage) and in R.
>
> I got this (or may have adapted it) from the book: Numerical Issues in Statistical Computing for the Social Scientist by M. Altman, J. Gill and M. P. McDonald.
>
> After over 10 years, Excel finally appears to have fixed the issue. gnumeric never had this problem.
>
> Best wishes,
> Ranjan


From dwinsemius at comcast.net  Wed Feb 11 02:03:24 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 10 Feb 2015 17:03:24 -0800
Subject: [R] MApply and SubStr
In-Reply-To: <CAFYnejJ7BOV3j9E53yOy5Y8Buhe_kbioGvodMWpAyNU7tVtSZA@mail.gmail.com>
References: <CAFYnejJ7BOV3j9E53yOy5Y8Buhe_kbioGvodMWpAyNU7tVtSZA@mail.gmail.com>
Message-ID: <6E7FA71C-5DBB-422A-8285-03D7CE50E267@comcast.net>


On Feb 10, 2015, at 3:58 PM, Brian Trautman wrote:

> Hi!
> 
> I'm trying to write a custom function that applies SubStr to a string, and
> then depending on the arguments, converts the output to a number.
> 
> The substring part of my code works fine, but it's not converting the way I
> want to --
> 
> options('stringsAsFactors'=FALSE)
> require(data.table)
> 
> substr_typeswitch <- function(x, start, stop, typeto='chr')
> {
>  tmpvar <- substr(x=x, start=start, stop=stop)
>  tmpvar <- switch(typeto, num=as.numeric(tmpvar), tmpvar)
>  return(tmpvar)
> }
>  startpos <- c(01, 03)
>  endpos <-   c(02, 04)
>  typelist <- c('chr', 'num')
> 
>  startdata <- as.data.table(c('aa01', 'bb02'))
> 
>  enddata_want <- as.data.table(mapply(substr_typeswitch, startdata,
> startpos, endpos, typelist))
> 
> If I examine enddata_want --
> 
>> str(enddata_want)
> Classes ?data.table? and 'data.frame': 2 obs. of  2 variables:
> $ V1: chr  "aa" "bb"
> $ NA: chr  "1" "2"
> - attr(*, ".internal.selfref")=<externalptr>
> 
> "1" and "2" are being stored as character, and not as number.

It appears from you code that you might be expecting a vector in a dataframe object to have a character mode in the first postition and a numeric mode in the second position. That wouldn't seem to be a reasonable expectation. But maybe you were hoping the chr and num types were to be applied to columns. I was surprised to get something different from as.data.table:

> str(enddata_want)
Classes ?data.table? and 'data.frame':	2 obs. of  2 variables:
 $ V1: Factor w/ 2 levels "aa","bb": 1 2
 $ NA: Factor w/ 2 levels "1","2": 1 2
 - attr(*, ".internal.selfref")=<externalptr> 

The mapply operation made a matrix which forces all values to be the same mode:

> str( mapply(substr_typeswitch, startdata,
+  startpos, endpos, typelist) )
 chr [1:2, 1:2] "aa" "bb" "1" "2"
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:2] "V1" NA

You might have gotten something less homogeneous if you added the SIMPLIFY argument:

> str( mapply(substr_typeswitch, startdata,
+  startpos, endpos, typelist, SIMPLIFY=FALSE) )
List of 2
 $ V1: chr [1:2] "aa" "bb"
 $ NA: num [1:2] 1 2




> 
> Can anyone help me understand what I'm doing wrong?
> 
> Thank you!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From hb at biostat.ucsf.edu  Wed Feb 11 02:11:54 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 10 Feb 2015 17:11:54 -0800
Subject: [R] How to unzip a .gz file
In-Reply-To: <CAHpsUFa6ECacPe_28Sdq0V9zRyvWUANmeXbgDSoD5S5VKUT7gA@mail.gmail.com>
References: <CAHpsUFa6ECacPe_28Sdq0V9zRyvWUANmeXbgDSoD5S5VKUT7gA@mail.gmail.com>
Message-ID: <CAFDcVCS39U0WJufvNhK5SA-S-S8WX+dBTbFx2sPpWZ1QVy6WSg@mail.gmail.com>

Not clear if you need to:

1. decompress /home/file.gz, or
2. read the content of /home/file.gz into R.

For (1) you can use `gunzip` at the command line, or
gunzip("/home/file.gz") of the R.utils package.  For (2), as already
mentioned, R does a good job of reading gzip'ed files "as is".  It may
even be that you don't have to use gzfile().

DEMO:

# Create gzip'ed file
> cat(file="foo.txt", "Hello world!\n")
> R.utils::gzip("foo.txt")

# Read directly from it
> readLines("foo.txt.gz")
[1] "Hello world!"

# Decompress it
> R.utils::gunzip("foo.txt.gz")
> readLines("foo.txt")
[1] "Hello world!"

/Henrik

On Tue, Feb 10, 2015 at 1:45 PM, Alexandra Catena <amc5981 at gmail.com> wrote:
> Hello,
>
> Can someone help me with unzipping a .gz file.  I used:
>
> readLines(gzfile('/home/file.gz'))
>
>
> I also found that I could use gunzip, but after trying to install it, it
> says:
>
>  "package ?gunzip? is not available (for R version 2.15.1)"
>
>
> Thanks,
> Alexandra
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maitra.mbox.ignored at inbox.com  Wed Feb 11 02:39:07 2015
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Tue, 10 Feb 2015 19:39:07 -0600
Subject: [R] Ranjan Maitra's comment "Re: Variance is different in R vs.
 Excel?
In-Reply-To: <54DA9DB2.6090600@ischool.utexas.edu>
References: <mailman.1.1423566002.4267.r-help@r-project.org>
	<54DA9DB2.6090600@ischool.utexas.edu>
Message-ID: <20150210193907.973d0f24cd6b632922aadae4@inbox.com>

Thanks! Interesting! Perhaps there was a patch to Excel later on, because otherwise, this does not explain things. Anyway, regardless, good to know that the long-standing issue has been fixed.

The title of your e-mail post is amusing!

Ranjan

On Tue, 10 Feb 2015 18:09:22 -0600 Ronald Wyllys <wyllys at ischool.utexas.edu> wrote:

> FWIW, both Excel 2007 and LibreOffice 4.2 yield the correct variance for 
> the numbers in Ranjan Maitra's HW problem for incoming students in R.  
> Namely, both these programs yield a sample variance of 0.2777777778 
> (rounded to 10 decimal digits).
> 
> Ronald Wyllys
> 
> 
> On 02/10/2015 05:00 AM, r-help-request at r-project.org wrote:
> > ate: Mon, 9 Feb 2015 17:39:14 -0600
> > From: Ranjan Maitra<maitra.mbox.ignored at inbox.com>
> > To:<r-help at stat.math.ethz.ch>
> > Subject: Re: [R] Variance is different in R vs. Excel?
> > Message-ID:<20150209173914.bae4d99ebeadafed3515372c at inbox.com>
> > Content-Type: text/plain; charset="us-ascii"
> >
> > I suspect that this is the long-documented issue with indeed an entire industry -- and publications -- devoted to finding such errors in Excel. Till the 2013 version, it used to be a favorite HW problem of mine. Basically, Excel uses the "short formula" to calculate the variance and the sd. This "short formula" has numerical issues with larger numbers (though I am surprised at the OP's data because these numbers were not that large). Anyway, the "long formula" which removes the mean from each datapoint, squares and sums is preferred with large numbers.
> >
> > Btw, my HW problem for incoming students in my R class would be this:
> >
> > Consider the following numbers:
> > 100000000000001, 100000000000002, 100000000000001, 100000000000002, 100000000000001,
> > 100000000000002, 100000000000001, 100000000000002, 100000000000001, 100000000000002.
> >
> > Calculate the variance in Excel (gives pure garbage) and in R.
> >
> > I got this (or may have adapted it) from the book: Numerical Issues in Statistical Computing for the Social Scientist by M. Altman, J. Gill and M. P. McDonald.
> >
> > After over 10 years, Excel finally appears to have fixed the issue. gnumeric never had this problem.
> >
> > Best wishes,
> > Ranjan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jfox at mcmaster.ca  Wed Feb 11 03:12:40 2015
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 10 Feb 2015 21:12:40 -0500
Subject: [R] library(Rcmdr) sh: otool: command not found
In-Reply-To: <527541485.4226498.1423610208089.JavaMail.yahoo@mail.yahoo.com>
References: <527541485.4226498.1423610208089.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <006101d045a0$378ac6b0$a6a05410$@mcmaster.ca>

Dear varin sacha,

This problem presumably will also arise if you try to load the tcltk package directly via library(tcltk) and has been discussed before on the R-SIG-Mac email list, for example at <https://stat.ethz.ch/pipermail/r-sig-mac/2014-December/011260.html>. The problem is fixed in the patched version of R 3.1.2 for Mac OS X, available at <http://r.research.att.com/>.

I hope this helps,
 John

-------------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of varin sacha
> Sent: February-10-15 6:17 PM
> To: r-help at R-project.org
> Subject: [R] library(Rcmdr) sh: otool: command not found
> 
> Hi R experts,
> 
> I have just updated R and RStudio. I am running OS X 10.6.8
> 
> R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
> Copyright (C) 2014 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
> 
> 
> RStudio Version 0.98.1102 ? ? 2009-2014 RStudio, Inc.
> Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/534.59.10
> (KHTML, like Gecko)
> 
> 
> Everything is ok for installing the Rcmdr package.
> 
> install.packages("Rcmdr")
> Installing package into ?/Users/Caro/Library/R/3.1/library?
> (as ?lib? is unspecified)
> essai de l'URL 'http://cran.rstudio.com/bin/macosx/contrib/3.1/Rcmdr_2.1-
> 6.tgz'
> Content type 'application/x-gzip' length 5340999 bytes (5.1 Mb) URL ouverte
> ==================================================
> downloaded 5.1 Mb
> 
> 
> The downloaded binary packages are in
> /var/folders/V2/V26Pbtc-GsSUTVPWEj6Bdk+++TI/-Tmp-
> //RtmpgNlyXf/downloaded_packages
> >
> 
> 
> But once I write library(Rcmdr), it doesn't work.
> 
> library(Rcmdr)
> Le chargement a n?cessit? le package : splines Le chargement a n?cessit? le
> package : RcmdrMisc Le chargement a n?cessit? le package : car Le
> chargement a n?cessit? le package : sandwich Error : .onLoad a ?chou? dans
> loadNamespace() pour 'tcltk', d?tails :
> appel : system2("otool", c("-L", shQuote(DLL)), stdout = TRUE) erreur : erreur
> lors de l'ex?cution d'une commande Erreur : le chargement du package ou de
> l'espace de noms a ?chou? pour ?Rcmdr?
> sh: otool: command not found
> 
> Has somebody any idea of how I can solve this problem ?
> 
> Thanks,
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


---
This email has been checked for viruses by Avast antivirus software.
http://www.avast.com


From bbolker at gmail.com  Tue Feb 10 22:59:30 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 10 Feb 2015 21:59:30 +0000
Subject: [R] =?utf-8?b?Y29uZmludC5tZXJNb2QobWV0aG9kPSJib290Iikge2xtZTR9?=
	=?utf-8?q?_with_user_supplied_FUN_to_bootMer_fails?=
References: <9740505af73247b799c636ffec5f25a3@mail-ex11.exprod.uio.no>
Message-ID: <loom.20150210T225200-556@post.gmane.org>

Torbj?rn H?kan Ergon <t.h.ergon <at> ibv.uio.no> writes:

> 
> Dear list,
> 
> I'm trying to supply a summary function to confint.merMod(method="boot")
>  {lme4} but get persistent
> errors. The following example generates the errors:
> 
> > fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
> > test = function(fit) fixef(fit)[1]
> > test(fm1)
> (Intercept) 
>    251.4051 
> > confint(fm1, method="boot", FUN=test)
> Computing bootstrap confidence intervals ...
> Error in set.seed(seed) : supplied seed is not a valid integer
> > confint(fm1, method="boot", FUN=test, seed=100)
> Computing bootstrap confidence intervals ...
> Error in if (use.u) NULL else ~0 : 
>   argument is not interpretable as logical
> > confint(fm1, method="boot", FUN=test, seed=100, use.u = FALSE)
> Computing bootstrap confidence intervals ...
> Error in match.arg(type) : 'arg' must be NULL or a character vector
> > confint(fm1, method="boot", FUN=test, seed=100, use.u = TRUE)
> Computing bootstrap confidence intervals ...
> Error in match.arg(type) : 'arg' must be NULL or a character vector
> >
> 
> Any help/hints/ideas?
> 

 It turns out (not documented!) that you can't use confint.merMod
(at present) with user-specified functions -- when it says ...
are arguments that can be passed through to bootMer, it actually
means "other than FUN or nsim" ...

This should be a reasonable workaround 

bb <- bootMer(fm1, nsim=100, FUN=test)
library("boot")
boot.ci(bb,type="perc")

Future lme4-related questions should probably go to 
r-sig-mixed-models at r-project.org ...

Future lme4-related questions should probably go 
> Cheers,
> 
> Torbj?rn
> 
> 



From cllanospaez at gmail.com  Wed Feb 11 00:26:09 2015
From: cllanospaez at gmail.com (Carolina Llanos)
Date: Wed, 11 Feb 2015 09:26:09 +1000
Subject: [R] Error in xvardef
Message-ID: <CABg0esnngf7UibY0Q5bbRbG=JpmJN_Z_h2t-Zt4=vSk_yrdMxQ@mail.gmail.com>

Dear all,

First of all, thanks for any help.
I am a new R user and I am trying to do some plots using xpose 4.
When I indicate to R to do this, for example:

DATA CHECKOUT MENU
  \main\data checkout

1: Return to previous menu ->
2: Numerically summarize the covariates
3: Histograms of the covariates
4: QQ plots of the covariates
5: Scatterplot matrix of covariates
6: Check dataset
7: Observations vs independent variable

Selection: 7

Then it appears this kind of error:

Error in print(dv.vs.idv(eval(parse(text = ".cur.db")))) :
  error in evaluating the argument 'x' in selecting a method for function
'print': Error in xvardef(v, object) :
  trying to get slot "Prefs" from an object of a basic class ("function")
with no slots

Someone can tell me how to proceed?

Many thanks in advance

Best wishes,

-- 
Carolina Llanos Paez
PharmD, PhD Candidate
School of Pharmacy
The University of Queensland

	[[alternative HTML version deleted]]


From lepolain at stanford.edu  Wed Feb 11 03:39:24 2015
From: lepolain at stanford.edu (Yann le Polain de Waroux)
Date: Tue, 10 Feb 2015 18:39:24 -0800
Subject: [R] Hausman test for Conditional Logit
Message-ID: <54DAC0DC.8060306@stanford.edu>

Dear all,

I am running a conditional logit model on migration choices using the 
"mclogit" package, and I would like to test the independence of 
irrelevant alternatives (IIA), as it is a restrictive assumption of 
those models. The mclogit package does not offer the Hausman test, which 
seems to be the most widespread. The package "mlogit" does, but it 
doesn't deal with conditional logit models. Does anybody know of a 
package, or has a code to do this?

Thanks in advance.

YLP


From js.huang at protective.com  Wed Feb 11 04:28:17 2015
From: js.huang at protective.com (JS Huang)
Date: Tue, 10 Feb 2015 19:28:17 -0800 (PST)
Subject: [R] function that calculates using preceding records
In-Reply-To: <000901d0453e$1602b730$42082590$@org>
References: <000901d0453e$1602b730$42082590$@org>
Message-ID: <1423625297564-4703069.post@n4.nabble.com>

Hi,

  Here is an implementation:

> data <- read.table("tree.txt",header=TRUE,sep=",",stringsAsFactors=FALSE)
> data
   treecode year    rw     d
1     TC149 2014    NA    8 
2     TC149 2013 0.080   NA 
3     TC149 2012 0.125   NA 
4     TC149 2011 0.120   NA 
5     TC149 2010 0.125   NA 
6     TC148 2014    NA   34 
7     TC148 2013 0.300   NA 
8     TC148 2012 0.335   NA 
9     TC148 2011 0.315   NA 
10    TC148 2010 0.455   NA 
11    TC147 2014    NA 55.5 
12    TC147 2013 1.260   NA 
13    TC147 2012 1.115   NA 
14    TC147 2011 1.025   NA 
15    TC147 2010 1.495   NA 
16    TC146 2014    NA   60 
17    TC146 2013 1.750   NA 
18    TC146 2012 1.810   NA 
19    TC146 2011 1.390   NA 
20    TC146 2010 1.940   NA 
> calDiameter <- function(x)
+ {
+   temp <- x
+   for (i in 1:dim(temp)[1])
+   {
+     if (dim(x[x$treecode==temp$treecode[i] & x$year == temp$year[i] - 1  &
!is.na(x$rw),])[1] == 1 & !is.na(temp$d[i]))
+     {
+       temp$d[i] <- as.numeric(temp$d[i]) - as.numeric(x[x$treecode ==
temp$treecode[i] & x$year == temp$year[i] - 1 & !is.na(x$rw), ]$rw[1])
+     }
+   }
+   return(temp)
+ }
> calDiameter(data)
   treecode year    rw     d
1     TC149 2014    NA  7.92
2     TC149 2013 0.080  <NA>
3     TC149 2012 0.125  <NA>
4     TC149 2011 0.120  <NA>
5     TC149 2010 0.125   NA 
6     TC148 2014    NA  33.7
7     TC148 2013 0.300  <NA>
8     TC148 2012 0.335  <NA>
9     TC148 2011 0.315  <NA>
10    TC148 2010 0.455   NA 
11    TC147 2014    NA 54.24
12    TC147 2013 1.260  <NA>
13    TC147 2012 1.115  <NA>
14    TC147 2011 1.025  <NA>
15    TC147 2010 1.495   NA 
16    TC146 2014    NA 58.25
17    TC146 2013 1.750  <NA>
18    TC146 2012 1.810  <NA>
19    TC146 2011 1.390  <NA>
20    TC146 2010 1.940   NA 
There were 12 warnings (use warnings() to see them)



--
View this message in context: http://r.789695.n4.nabble.com/function-that-calculates-using-preceding-records-tp4703024p4703069.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Wed Feb 11 04:47:37 2015
From: js.huang at protective.com (JS Huang)
Date: Tue, 10 Feb 2015 19:47:37 -0800 (PST)
Subject: [R] How to solve this complex equation
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686CF38916A@DC1VEX10MB001.air.org>
References: <1423530289334-4702997.post@n4.nabble.com>
	<1423557113583-4703006.post@n4.nabble.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD686CF38916A@DC1VEX10MB001.air.org>
Message-ID: <1423626457622-4703070.post@n4.nabble.com>

Hi,

  The solution x to the equation is the parmater lambda = x/2 of a Poisson
distribution with probability of 0.05 for the number of occurrence 2 or
fewer.



--
View this message in context: http://r.789695.n4.nabble.com/How-to-solve-this-complex-equation-tp4702997p4703070.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Wed Feb 11 05:14:09 2015
From: js.huang at protective.com (JS Huang)
Date: Tue, 10 Feb 2015 20:14:09 -0800 (PST)
Subject: [R] assignment of categorical variables to matrix/table
In-Reply-To: <1423506526357-4702981.post@n4.nabble.com>
References: <1423506526357-4702981.post@n4.nabble.com>
Message-ID: <1423628049709-4703071.post@n4.nabble.com>

Hi,

  Try this with three category variables.

> A
[1] "Baby"     "Kid"      "Teenager" "Adult"    "Mature"  
> B
[1] "Male"   "Female"
> C
[1] "PST" "MST" "CST" "EST"
> expand.grid(Age=A, Sex=B, Zone=C)
        Age    Sex Zone
1      Baby   Male  PST
2       Kid   Male  PST
3  Teenager   Male  PST
4     Adult   Male  PST
5    Mature   Male  PST
6      Baby Female  PST
7       Kid Female  PST
8  Teenager Female  PST
9     Adult Female  PST
10   Mature Female  PST
11     Baby   Male  MST
12      Kid   Male  MST
13 Teenager   Male  MST
14    Adult   Male  MST
15   Mature   Male  MST
16     Baby Female  MST
17      Kid Female  MST
18 Teenager Female  MST
19    Adult Female  MST
20   Mature Female  MST
21     Baby   Male  CST
22      Kid   Male  CST
23 Teenager   Male  CST
24    Adult   Male  CST
25   Mature   Male  CST
26     Baby Female  CST
27      Kid Female  CST
28 Teenager Female  CST
29    Adult Female  CST
30   Mature Female  CST
31     Baby   Male  EST
32      Kid   Male  EST
33 Teenager   Male  EST
34    Adult   Male  EST
35   Mature   Male  EST
36     Baby Female  EST
37      Kid Female  EST
38 Teenager Female  EST
39    Adult Female  EST
40   Mature Female  EST




--
View this message in context: http://r.789695.n4.nabble.com/assignment-of-categorical-variables-to-matrix-table-tp4702981p4703071.html
Sent from the R help mailing list archive at Nabble.com.


From riviverma at iisermohali.ac.in  Wed Feb 11 07:01:22 2015
From: riviverma at iisermohali.ac.in (riviverma at iisermohali.ac.in)
Date: Wed, 11 Feb 2015 11:31:22 +0530
Subject: [R] Breaking y- axis using gap.barplot
In-Reply-To: <CA+8X3fVUs++bQ6889YheX6c03gZ5T1j8y_OwvEp1TMYLEnnXMw@mail.gmail.com>
References: <f8cedd1be473d5a5e8c6dacfd415dbd7.squirrel@iisermohali.ac.in>
	<CA+8X3fVUs++bQ6889YheX6c03gZ5T1j8y_OwvEp1TMYLEnnXMw@mail.gmail.com>
Message-ID: <2efac8b3e3151b3cfb9102b692119285.squirrel@iisermohali.ac.in>

Thank you for the reply. Can I have a gap starting from 50 instead of 120
so that the values with lower frequency can show up more predominantly?



> Hi reviverma,
> I think your problem is that you have chosen the wrong gap, as it cuts
> out all of the small bars. Try this:
>
> gap.barplot(hdata$counts, gap=c(120,15900), xlab="RMSD",
>  ytics=c(0,100,16000,16100,16200,16300),ylab="Frequency",
>  xtics=hdata$breaks)
>
> Note that you have one more "breaks" than you do "counts" in your
> example - I corrected this.
>
> Jim
>
> On Tue, Feb 10, 2015 at 4:41 PM,  <riviverma at iisermohali.ac.in> wrote:
>> Hello all
>>
>> I am trying to plot histogram with break in y-axis for my data by
>> following various posts on R- help but none seems solving my problem. My
>> data looks like:
>>
>>> hdata
>> $breaks
>>  [1]  0  5 10 15 20 25 30 35 40 45 50
>>
>> $counts
>>  [1] 16311   108    24     8     1     3     0     1     6     3
>>
>> on using: gap.barplot(hdata$counts, gap=c(26,108), xlab="RMSD",
>> ytics=c(0,25,110), ylab="Frequency", xtics=hdata$breaks)
>>
>> the plot does not seems correct.
>>
>> Please help.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From minorthreatx at hotmail.com  Wed Feb 11 09:02:22 2015
From: minorthreatx at hotmail.com (Kim C.)
Date: Wed, 11 Feb 2015 09:02:22 +0100
Subject: [R] How to read this Rpart decision tree?
Message-ID: <DUB126-W84044312488EE3428E3124DE250@phx.gbl>

Hi all, 

In the attachment or this link (http://oi58.tinypic.com/35ic9qc.jpg) you'll find the decision tree I made. I used the Rpart package to make the tree and the rattle package using the fancyRpartPlot to plot it. The data in the tree looks different than about every example I have seen before. I don't understand how I should read it. I want to predict Product (which are productkeys). The variables to predict it contain age, incomegroup, gender, totalchildren, education, occupation, houseownerflag, numberCars.It looks like the upper number is a ProductKey. The "n" is number of observations? And the percentage of the yes/no question below. 

This is the code I used.  

> ss.rpart1 <- rpart(Product ~ ., data=sstrain, control=rpart.control(minbucket=2,minsplit=1, cp=-1))
> spt <- which.min(ss.rpart1$cptable[, "xerror"])
> scp <- ss.rpart1$cptable[opt, "CP"]
> ss.rpart2 <- prune(ss.rpart1, cp=cp)
> fancyRpartPlot(ss.rpart2)

So why does the tree looks so different from the most (for example: http://media.tumblr.com/a9f482ff88b0b9cfaffca7ffd46c6a8e/tumblr_inline_mz7pyuaYJQ1s5wtly.png). This is from Trevor Stephen's TItanic tutorial. The first node show that 62% of 100% doesn't survive. If they were male, only 19% of them were survivors. I find that a lot examples look like that. Why does mine predict per ProductKey and every node it has something else. it doesn't make sense to me. And it doesn't have the two numbers like .62 and .38 but it has n=197e+3. So should I read the first node like "For 100% of the observations of ProductKey 1074, the incomegroup was moderate)"?

Thank you!

Kim


 		 	   		  
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ssrpart2.png
Type: image/png
Size: 64401 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150211/4d0658ed/attachment.png>

From jabbba at gmail.com  Wed Feb 11 12:33:58 2015
From: jabbba at gmail.com (Marco =?ISO-8859-1?B?QmFyYuByYQ==?=)
Date: Wed, 11 Feb 2015 12:33:58 +0100
Subject: [R] Mixed-effects model for pre-post randomization design
Message-ID: <20150211123358.760e26cd@caprica>

DeaR userRs,

I recently read this Liang-Zeger article:

http://sankhya.isical.ac.in/search/62b1/fpaper7.html

in which (among other things) they adopt a random intercept model for
pre-post designed trials, using a conditional likelihood approach
(I didn't think it possible with only two measurements per subject)

I'm trying to figure out (if and) how it is possible to reproduce
straightforwardly their model using R standard mixed model tools, but
I cannot even try to reproduce their work, since they used a
non-available dataset (I found an extract on prof. Diggle's web site
where it is explicitly reported to be "confidential"), so I have to
review a bit of likelihood theory along with some implementation
details.

In the meantime, I wonder if anyone here could point out any related
documentation to me.

Thank you.
Marco.


From therneau at mayo.edu  Wed Feb 11 14:17:40 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 11 Feb 2015 07:17:40 -0600
Subject: [R] How to read this Rpart decision tree
In-Reply-To: <mailman.1.1423652401.20458.r-help@r-project.org>
References: <mailman.1.1423652401.20458.r-help@r-project.org>
Message-ID: <1e7ee5$1kj4j@ironport10.mayo.edu>

First:
    summary(ss.rpart1)
or summary(ss.rpart, file="whatever")

The printout will be quite long since your tree is so large, so the second form may be 
best followed by a perusal of the file with your favorite text editor.  The file name of 
"whatever" above should be something you choose, of course.   This will give you a full 
description of the tree.  Read the first node or two very carefully so that you understand 
what the fit did.
   Plotting routines for trees have to make display choices, since there simply is not 
enough space available to list all the details.  You have a complicated endpoint with at 
least 14 different products.  The predicted value for the each node of the tree is a 
vector of percentages (one per product, adds to one); plots often show only the name of 
the most frequent.  The alive/dead endpoint for the Titanic data is a lot easier to fit 
into a little plotting oval so of course the plotted tree is easier to grasp.

Terry T.



On 02/11/2015 05:00 AM, r-help-request at r-project.org wrote:
> Hi all,
>
> In the attachment or this link (http://oi58.tinypic.com/35ic9qc.jpg) you'll find the decision tree I made. I used the Rpart package to make the tree and the rattle package using the fancyRpartPlot to plot it. The data in the tree looks different than about every example I have seen before. I don't understand how I should read it. I want to predict Product (which are productkeys). The variables to predict it contain age, incomegroup, gender, totalchildren, education, occupation, houseownerflag, numberCars.It looks like the upper number is a ProductKey. The "n" is number of observations? And the percentage of the yes/no question below.
>
> This is the code I used.
>
>> >ss.rpart1 <- rpart(Product ~ ., data=sstrain, control=rpart.control(minbucket=2,minsplit=1, cp=-1))
>> >spt <- which.min(ss.rpart1$cptable[, "xerror"])
>> >scp <- ss.rpart1$cptable[opt, "CP"]
>> >ss.rpart2 <- prune(ss.rpart1, cp=cp)
>> >fancyRpartPlot(ss.rpart2)
> So why does the tree looks so different from the most (for example:http://media.tumblr.com/a9f482ff88b0b9cfaffca7ffd46c6a8e/tumblr_inline_mz7pyuaYJQ1s5wtly.png). This is from Trevor Stephen's TItanic tutorial. The first node show that 62% of 100% doesn't survive. If they were male, only 19% of them were survivors. I find that a lot examples look like that. Why does mine predict per ProductKey and every node it has something else. it doesn't make sense to me. And it doesn't have the two numbers like .62 and .38 but it has n=197e+3. So should I read the first node like "For 100% of the observations of ProductKey 1074, the incomegroup was moderate)"?
>
> Thank you!
>
> Kim


From arnaud.gaboury at gmail.com  Wed Feb 11 14:24:37 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Wed, 11 Feb 2015 14:24:37 +0100
Subject: [R] upgrading issues with Rcpp
Message-ID: <CAK1hC9s8wf4Jox2qx_Y6VLnoh+AhaYkr4bvdEGBuz6ag88DQYA@mail.gmail.com>

gabx at hortensia [R] sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
LC_MONETARY=en_US.UTF-8
 [6] LC_MESSAGES=en_US.UTF-8    LC_PAPER=en_US.UTF-8       LC_NAME=C
               LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] utils base

loaded via a namespace (and not attached):
[1] tools_3.1.2
--------------------------------------------------------------------

gabx at hortensia [R] search()
[1] ".GlobalEnv"    "tools:rstudio" "package:utils" "package:base"
--------------------------------------------------

Now when trying to update Rcpp:

gabx at hortensia [R] install.packages("Rcpp")
.............
Error in unloadNamespace(pkg_name) :
  namespace ?Rcpp? is imported by ?reshape2?, ?plyr?, ?dplyr? so
cannot be unloaded
......................

I can't upgrade my packages because of Rcpp >=0.11.3 needed (running
actually 0.11.2)

What is this namespace imported by  'reshape2?, ?plyr?, ?dplyr? ? How
can I get rid of it and upgrade my packages ?

Thank you for hints
-- 

google.com/+arnaudgabourygabx


From edd at debian.org  Wed Feb 11 14:38:03 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 11 Feb 2015 13:38:03 +0000
Subject: [R] upgrading issues with Rcpp
References: <CAK1hC9s8wf4Jox2qx_Y6VLnoh+AhaYkr4bvdEGBuz6ag88DQYA@mail.gmail.com>
Message-ID: <loom.20150211T143536-889@post.gmane.org>

arnaud gaboury <arnaud.gaboury <at> gmail.com> writes:
> Now when trying to update Rcpp:
> 
> gabx <at> hortensia [R] install.packages("Rcpp")
> .............
> Error in unloadNamespace(pkg_name) :
>   namespace ?Rcpp? is imported by ?reshape2?, ?plyr?, ?dplyr? so
> cannot be unloaded
> ......................
> 
> I can't upgrade my packages because of Rcpp >=0.11.3 needed (running
> actually 0.11.2)
> 
> What is this namespace imported by  'reshape2?, ?plyr?, ?dplyr? ? How
> can I get rid of it and upgrade my packages ?

I'd do 

  $ R --vanilla                  # to ensure nothing is loaded
  > install.packages("Rcpp")     # possibly set a repo

but what I really do is to use scripts update.r, install.r, install2.r, ...
from package littler which makes as this so much easier -- and do it on the 
command-line with "empty" R sessions.

Dirk




From kmezhoud at gmail.com  Wed Feb 11 15:45:05 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 11 Feb 2015 14:45:05 +0000
Subject: [R] =?utf-8?q?Rotate_array_by_90=C2=B0?=
In-Reply-To: <54D41E83.8060004@mail.usask.ca>
References: <CALJKBv-vrmD9yekk0fHHYV4+0MwZ=Z8Pmr-BJhw0h8CgQzVSzg@mail.gmail.com>
	<54D41E83.8060004@mail.usask.ca>
Message-ID: <CALJKBv8PVvYuu6zoS9e59M67CNDbsmxH-bWmnxayxQ0XeKVg=Q@mail.gmail.com>

Thanks Lee and Huang.
That is useful.
Best




On Fri, Feb 6, 2015 at 1:53 AM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:

> > lapply(1:2, function(x) t(A[rev(1:3),,x]))
> [[1]]
>      [,1] [,2] [,3]
> [1,] "g"  "d"  "a"
> [2,] "h"  "e"  "b"
> [3,] "i"  "f"  "c"
>
> [[2]]
>      [,1] [,2] [,3]
> [1,] "p"  "m"  "j"
> [2,] "q"  "n"  "k"
> [3,] "r"  "o"  "l"
>
> >
>
> Is this what you are looking for?  I hope this helps.
>
> Chel Hee Lee
>
>
> On 02/05/2015 03:17 PM, Karim Mezhoud wrote:
>
>> Dear aal,
>>
>> Is there a way to rotate array or a cube of matrices by Y axis?
>>
>>
>> MatLab example:
>>
>> A = cat(3,{'a' 'b' 'c';'d' 'e' 'f';'g' 'h' 'i'},{'j' 'k' 'l';'m' 'n'
>> 'o';'p' 'q' 'r'})
>>
>> A(:,:,1) =
>>
>>      'a'    'b'    'c'
>>      'd'    'e'    'f'
>>      'g'    'h'    'i'
>>
>>
>> A(:,:,2) =
>>
>>      'j'    'k'    'l'
>>      'm'    'n'    'o'
>>      'p'    'q'    'r'
>>
>> Rotate the cell array by 270 degrees.
>>
>> B = rot90(A,3)
>>
>> B(:,:,1) =
>>
>>      'g'    'd'    'a'
>>      'h'    'e'    'b'
>>      'i'    'f'    'c'
>>
>>
>> B(:,:,2) =
>>
>>      'p'    'm'    'j'
>>      'q'    'n'    'k'
>>      'r'    'o'    'l'
>>
>>
>> karim
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From HDoran at air.org  Wed Feb 11 15:45:17 2015
From: HDoran at air.org (Doran, Harold)
Date: Wed, 11 Feb 2015 14:45:17 +0000
Subject: [R] sqldf() difference between R 3.1.2 and 3.0.1
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686CF38A9FF@DC1VEX10MB001.air.org>

I have a function written and tested using R 3.0.1 and sqldf_0.4-7.1 that works perfectly. However, using this same code with R 3.1.2 and sqldf_0.4-10 yields the error below that I am having a difficult time deciphering. Hence, same code behaves differently on different versions of R and sqldf().

Error in sqliteSendQuery(con, statement, bind.data) :
  error in statement: no such column: V1


Reproducible example below as well as complete sessionInfo all provided below.


My function and code using the function are below.

dorReader <- function(dorFile, layout, sepChar = '\n'){
                sepChar <- as.character(sepChar)
                dorFile <- as.character(dorFile)
                layout$type2 <- ifelse(layout$type == 'C', 'character',
                                                                ifelse(layout$type == 'N', 'numeric', 'Date'))
                dor <- file(dorFile)
                attr(dor, "file.format") <- list(sep = sepChar)
                getVars <- paste("select",
               paste("substr(V1, ", layout$Start, ", ",
                     layout$Length, ") '", layout$Variable.Name, "'", collapse = ", "), "from dor")
                dat <- sqldf(getVars)

                classConverter <- function(obj, types){
                                out <- lapply(1:length(obj),FUN = function(i){FUN1 <- switch(types[i],character = as.character,numeric = as.numeric,factor = as.factor, Date = as.character); FUN1(obj[,i])})
                                names(out) <- colnames(obj)
                                as.data.frame(out)
                }
                dat <- classConverter(dat, layout$type2)
                names(dat) <- layout$Variable.Name
                dat
}

### contents of fwf file 'sample.txt'
1234567
1234567
1234567
1234567
1234567
1234567
1234567
1234567

layout <- data.frame("Variable.Name" =c('test1', 'test2'), "Length" = c(3,4), "Start" =c(1,4), "End" = c(3,7), "type" = c('N', 'N'))

tmp <- dorReader('sample.txt', layout)

### SessionInfo where functions behaves as expected
> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252

attached base packages:
[1] tcltk     stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] sqldf_0.4-7.1         RSQLite.extfuns_0.0.1 RSQLite_0.11.4        DBI_0.2-7             gsubfn_0.6-5
[6] proto_0.3-10          MiscPsycho_1.6        statmod_1.4.18

loaded via a namespace (and not attached):
[1] chron_2.3-45 tools_3.0.1




### SessionInfo for version not working
> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] tcltk     stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] sqldf_0.4-10  RSQLite_1.0.0 DBI_0.3.1     gsubfn_0.6-6  proto_0.3-10

loaded via a namespace (and not attached):
[1] chron_2.3-45 tools_3.1.2

	[[alternative HTML version deleted]]


From kennethrrr at gmail.com  Wed Feb 11 15:46:42 2015
From: kennethrrr at gmail.com (Kenneth Z)
Date: Wed, 11 Feb 2015 09:46:42 -0500
Subject: [R] Maxent does not work
In-Reply-To: <CE63EFA7-1E11-4F20-AB7C-DBD12AB783F6@gmail.com>
References: <1355330088.98430.YahooMailClassic@web190503.mail.sg3.yahoo.com>
	<813743db-9d8f-4677-b0b7-b1c4a527ddf2@email.android.com>
	<B635B7F5-CC4F-49E0-A504-700723DFF1F2@gmail.com>
	<CE63EFA7-1E11-4F20-AB7C-DBD12AB783F6@gmail.com>
Message-ID: <C367DEFC-8815-40A1-8BE1-C56A9DA179B1@gmail.com>

Is there any package that can replace maxent for a large number of independent variables?


Thanks,
Ken

Sent from my iPhone



> On Feb 2, 2015, at 6:07 PM, Kenneth Z <kennethrrr at gmail.com> wrote:
> 
> Yesterday I installed the most recent R and maxent package, but it stopped working. Even a simple command like
> Model <- maxent(matrix(c(1,2,3,4,5,6,7,8), nrow=2, ncol=4),c(1,-1))
> 
> will cause a fatal error in R. I am attaching a screenshot to this email.
> Any help will be appreciated.
> 
> Best regards,
> Ken
> 
> 
> 
> 
>> On Dec 12, 2012, at 4:13 PM, Kenneth Z <kennethrrr at gmail.com> wrote:
>> 
>> I found that the optim() function does not always reach the real minimum. Is it because the solution is trapped at a local minimum?
>> 
>> Thanks!
>> Ken
>> 
>> 
>> 
>>> On Dec 12, 2012, at 2:17 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>> 
>>> ... origin pro?
>>> 
>>> Then why are you here?
>>> 
>>> It is not clear from your message that this has anything to do with R.
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>                                    Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>> --------------------------------------------------------------------------- 
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> vishal katoch <vkatoch007 at yahoo.co.in> wrote:
>>> 
>>>> Hello,
>>>> i am working in origin pro,
>>>> i want to plot a graph as like a pdf attached but with black and white
>>>> lines.
>>>> here radial axis varies from 0 to 1. and angular axis from 0 degree to
>>>> 60 degree.and third axis which is depend on both radial and axial gives
>>>> non intersecting lines.
>>>> how can i read the data from plot for replot.
>>>> vikas 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> ------------------------------------------------------------------------
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From mir.salam at uef.fi  Wed Feb 11 15:47:18 2015
From: mir.salam at uef.fi (Mir Salam)
Date: Wed, 11 Feb 2015 14:47:18 +0000
Subject: [R] help in anova
Message-ID: <1423666285303.92712@uef.fi>

Dear all,



I have follwing factors in my data set (G)

names(G)
relative ht, biomass, treatment, variety, soil group

relative height
biomass
treatment (4 levels)- control+lime, control+ash, contaminated soil+lime, contaminated soil+ash
variety (4 levels)- Salix swherinii, Salix mursinifolia, Klara, Karin
soilgroup (2 level)- control and contaminated
if I fit aov function this is ok

anova1<-aov(ht~treatment*variety,data=G)
summary(anova1)
 R- output
                                     Df     Sum Sq    Mean Sq       F value Pr(>F)
treatment                  3        14015     4672             65.021 < 2e-16 ***
variety                        3         5883       1961            27.295 2.95e-12 ***
treatment:variety    9           5474      608             8.465 8.93e-09 ***
Residuals 80 5748 72
---
Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
above I can see my treatment and variety interaction effect
anova3<-aov(ht~treatment*variety*soilgroup,data=G)
 summary(anova3)
R-ouput

                                      Df      Sum Sq    Mean Sq    F value Pr(>F)
treatment                    3        14015      4672          65.021 < 2e-16 ***
variety                          3         5883       1961           27.295 2.95e-12 ***
treatment:variety      9          5474       608             8.465 8.93e-09 ***
soilgroup -missing
treatment:variety:soilgroup - missing
Here, I am missing value of soil group and interation of treatment: variety: soilgroup- Can any one please tell me why?
Thanks for help


Best regards
Salam

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Feb 11 14:39:03 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Feb 2015 13:39:03 +0000
Subject: [R] Mixed-effects model for pre-post randomization design
References: <20150211123358.760e26cd@caprica>
Message-ID: <loom.20150211T143710-370@post.gmane.org>

Marco Barb?ra <jabbba <at> gmail.com> writes:

> 
> DeaR userRs,
> 
> I recently read this Liang-Zeger article:
> 
> http://sankhya.isical.ac.in/search/62b1/fpaper7.html
> 
> in which (among other things) they adopt a random intercept model for
> pre-post designed trials, using a conditional likelihood approach
> (I didn't think it possible with only two measurements per subject)
> 
> I'm trying to figure out (if and) how it is possible to reproduce
> straightforwardly their model using R standard mixed model tools, but
> I cannot even try to reproduce their work, since they used a
> non-available dataset (I found an extract on prof. Diggle's web site
> where it is explicitly reported to be "confidential"), so I have to
> review a bit of likelihood theory along with some implementation
> details.
> 
> In the meantime, I wonder if anyone here could point out any related
> documentation to me.
> 


  This might get more attention on r-sig-mixed-models at r-project.org.
I took a quick look at the paper, but it's not a case where the
answer is immediately obvious.  The paper of reference for lme4
(see http://cran.r-project.org/web/packages/lme4/citation.html )
gives technical details of lme4's implementation, in case that's
useful.



From js.huang at protective.com  Wed Feb 11 14:58:19 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 11 Feb 2015 05:58:19 -0800 (PST)
Subject: [R] plotting this data
In-Reply-To: <1423309672878-4702926.post@n4.nabble.com>
References: <1423309672878-4702926.post@n4.nabble.com>
Message-ID: <1423663099674-4703089.post@n4.nabble.com>

Hi,

  Here is an implementation.  The image is uploaded as Rplot02.png.
> gen <- read.table("geno.txt",header=TRUE)
> gen
  Genotype   E1   E2    E3   E4   E5   E6   E7   E8   E9  E10  E11  E12  E13 
E14  E15   E16  E17  E18
1       G1 0.79 2.11  6.21 0.56 4.06 2.13 5.61 0.20 3.32 3.01 5.12 0.77 0.78
0.62 2.00  5.87 2.50 0.49
2       G2 0.59 0.92 10.11 0.74 4.01 1.12 4.58 0.70 2.61 1.49 4.59 0.20 1.33
0.62 2.67  5.58 2.22 0.93
3       G3 1.18 3.44  4.08 0.50 6.91 4.27 6.87 0.30 4.57 2.88 6.61 0.59 0.97
1.02 1.45  5.32 2.65 2.73
4       G4 2.17 4.46  6.51 0.35 4.80 5.99 5.44 1.20 4.21 3.59 4.89 0.39 2.26
2.05 3.33  8.55 2.10 2.39
5       G5 0.99 4.83  6.71 1.43 5.83 2.95 3.66 0.50 1.54 2.55 5.70 1.83 0.39
1.44 1.66  5.36 1.32 1.19
6       G6 1.57 3.94  7.49 0.61 5.88 2.74 7.22 1.19 4.81 3.72 5.59 0.38 1.36
1.43 3.94  9.15 2.50 2.56
7       G7 2.38 4.74  9.94 1.31 5.74 5.59 9.01 0.70 4.47 3.59 4.85 3.48 2.35
1.23 3.22 11.21 2.89 3.01
8       G8 0.98 2.56 12.02 3.31 5.41 2.03 5.92 0.30 4.39 4.19 6.10 0.39 1.97
0.62 4.93  8.89 3.45 2.95
   E19  E20  E21  E22  E23  E24
1 0.42 0.73 5.66 4.61 3.98 0.32
2 0.40 0.68 4.28 3.89 2.98 1.78
3 1.31 2.63 6.51 5.42 5.43 0.60
4 0.03 1.81 6.05 6.31 6.53 1.94
5 0.08 1.03 5.38 2.45 5.18 0.54
6 0.08 0.68 6.46 6.02 5.28 2.52
7 0.33 0.91 9.15 7.03 6.39 2.13
8 0.01 0.62 8.35 5.71 5.86 0.38
> x <- expand.grid(gen[,1],names(gen)[2:dim(gen)[2]])
> x
    Var1 Var2
1     G1   E1
2     G2   E1
3     G3   E1
4     G4   E1
5     G5   E1
6     G6   E1
7     G7   E1
8     G8   E1
9     G1   E2
10    G2   E2
11    G3   E2
12    G4   E2
13    G5   E2
14    G6   E2
15    G7   E2
16    G8   E2
17    G1   E3
18    G2   E3
19    G3   E3
20    G4   E3
21    G5   E3
22    G6   E3
23    G7   E3
24    G8   E3
25    G1   E4
26    G2   E4
27    G3   E4
28    G4   E4
29    G5   E4
30    G6   E4
31    G7   E4
32    G8   E4
33    G1   E5
34    G2   E5
35    G3   E5
36    G4   E5
37    G5   E5
38    G6   E5
39    G7   E5
40    G8   E5
41    G1   E6
42    G2   E6
43    G3   E6
44    G4   E6
45    G5   E6
46    G6   E6
47    G7   E6
48    G8   E6
49    G1   E7
50    G2   E7
51    G3   E7
52    G4   E7
53    G5   E7
54    G6   E7
55    G7   E7
56    G8   E7
57    G1   E8
58    G2   E8
59    G3   E8
60    G4   E8
61    G5   E8
62    G6   E8
63    G7   E8
64    G8   E8
65    G1   E9
66    G2   E9
67    G3   E9
68    G4   E9
69    G5   E9
70    G6   E9
71    G7   E9
72    G8   E9
73    G1  E10
74    G2  E10
75    G3  E10
76    G4  E10
77    G5  E10
78    G6  E10
79    G7  E10
80    G8  E10
81    G1  E11
82    G2  E11
83    G3  E11
84    G4  E11
85    G5  E11
86    G6  E11
87    G7  E11
88    G8  E11
89    G1  E12
90    G2  E12
91    G3  E12
92    G4  E12
93    G5  E12
94    G6  E12
95    G7  E12
96    G8  E12
97    G1  E13
98    G2  E13
99    G3  E13
100   G4  E13
101   G5  E13
102   G6  E13
103   G7  E13
104   G8  E13
105   G1  E14
106   G2  E14
107   G3  E14
108   G4  E14
109   G5  E14
110   G6  E14
111   G7  E14
112   G8  E14
113   G1  E15
114   G2  E15
115   G3  E15
116   G4  E15
117   G5  E15
118   G6  E15
119   G7  E15
120   G8  E15
121   G1  E16
122   G2  E16
123   G3  E16
124   G4  E16
125   G5  E16
126   G6  E16
127   G7  E16
128   G8  E16
129   G1  E17
130   G2  E17
131   G3  E17
132   G4  E17
133   G5  E17
134   G6  E17
135   G7  E17
136   G8  E17
137   G1  E18
138   G2  E18
139   G3  E18
140   G4  E18
141   G5  E18
142   G6  E18
143   G7  E18
144   G8  E18
145   G1  E19
146   G2  E19
147   G3  E19
148   G4  E19
149   G5  E19
150   G6  E19
151   G7  E19
152   G8  E19
153   G1  E20
154   G2  E20
155   G3  E20
156   G4  E20
157   G5  E20
158   G6  E20
159   G7  E20
160   G8  E20
161   G1  E21
162   G2  E21
163   G3  E21
164   G4  E21
165   G5  E21
166   G6  E21
167   G7  E21
168   G8  E21
169   G1  E22
170   G2  E22
171   G3  E22
172   G4  E22
173   G5  E22
174   G6  E22
175   G7  E22
176   G8  E22
177   G1  E23
178   G2  E23
179   G3  E23
180   G4  E23
181   G5  E23
182   G6  E23
183   G7  E23
184   G8  E23
185   G1  E24
186   G2  E24
187   G3  E24
188   G4  E24
189   G5  E24
190   G6  E24
191   G7  E24
192   G8  E24
> names(gen) <- NULL
> genfinal <- data.frame(x, unlist(gen[,2:dim(gen)[2]]))
> names(genfinal) <- c("Genotype","category","value")
> genfinal$category <- as.numeric(genfinal$category)
> head(genfinal)
  Genotype category value
1       G1        1  0.79
2       G2        1  0.59
3       G3        1  1.18
4       G4        1  2.17
5       G5        1  0.99
6       G6        1  1.57
> library(ggplot2)
> ggplot(genfinal,aes(x=category,y=value,colour=Genotype)) + geom_line()
Rplot02.png <http://r.789695.n4.nabble.com/file/n4703089/Rplot02.png>  



--
View this message in context: http://r.789695.n4.nabble.com/plotting-this-data-tp4702926p4703089.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Wed Feb 11 15:02:50 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 11 Feb 2015 06:02:50 -0800 (PST)
Subject: [R] factor levels > numeric values
In-Reply-To: <CAA1twZRqtMM74_ZpSx+a0TdTivrfiVTd30FwcBN6Wg29BtiLRA@mail.gmail.com>
References: <CAA1twZRqtMM74_ZpSx+a0TdTivrfiVTd30FwcBN6Wg29BtiLRA@mail.gmail.com>
Message-ID: <1423663370971-4703090.post@n4.nabble.com>

Hi,

  Suppose your data frame is called data and the name of the factor column
is named tobeConverted.  I have tried this and it worked.  Hope this helps.

> as.numeric(as.character(data$tobeConverted))



--
View this message in context: http://r.789695.n4.nabble.com/factor-levels-numeric-values-tp4699515p4703090.html
Sent from the R help mailing list archive at Nabble.com.


From varinsacha at yahoo.fr  Wed Feb 11 15:55:29 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Wed, 11 Feb 2015 14:55:29 +0000 (UTC)
Subject: [R] library(Rcmdr) sh: otool: command not found
In-Reply-To: <006101d045a0$378ac6b0$a6a05410$@mcmaster.ca>
References: <006101d045a0$378ac6b0$a6a05410$@mcmaster.ca>
Message-ID: <962707887.3260367.1423666529193.JavaMail.yahoo@mail.yahoo.com>

Dear John,
Dear Dan,

Many thanks for your response. It works perfectly.

Best,


----- Mail original -----
De : John Fox <jfox at mcmaster.ca>
? : 'varin sacha' <varinsacha at yahoo.fr>
Cc : "'r-help at R-project.org'" <r-help at r-project.org>
Envoy? le : Mercredi 11 f?vrier 2015 3h12
Objet : RE: [R] library(Rcmdr) sh: otool: command not found

Dear varin sacha,

This problem presumably will also arise if you try to load the tcltk package directly via library(tcltk) and has been discussed before on the R-SIG-Mac email list, for example at <https://stat.ethz.ch/pipermail/r-sig-mac/2014-December/011260.html>. The problem is fixed in the patched version of R 3.1.2 for Mac OS X, available at <http://r.research.att.com/>.

I hope this helps,
John

-------------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of varin sacha
> Sent: February-10-15 6:17 PM
> To: r-help at R-project.org
> Subject: [R] library(Rcmdr) sh: otool: command not found
>
> Hi R experts,
>
> I have just updated R and RStudio. I am running OS X 10.6.8
>
> R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
> Copyright (C) 2014 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
>
> RStudio Version 0.98.1102 ? ? 2009-2014 RStudio, Inc.
> Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/534.59.10
> (KHTML, like Gecko)
>
>
> Everything is ok for installing the Rcmdr package.
>
> install.packages("Rcmdr")
> Installing package into ?/Users/Caro/Library/R/3.1/library?
> (as ?lib? is unspecified)
> essai de l'URL 'http://cran.rstudio.com/bin/macosx/contrib/3.1/Rcmdr_2.1-
> 6.tgz'
> Content type 'application/x-gzip' length 5340999 bytes (5.1 Mb) URL ouverte
> ==================================================
> downloaded 5.1 Mb
>
>
> The downloaded binary packages are in
> /var/folders/V2/V26Pbtc-GsSUTVPWEj6Bdk+++TI/-Tmp-
> //RtmpgNlyXf/downloaded_packages
> >
>
>
> But once I write library(Rcmdr), it doesn't work.
>
> library(Rcmdr)
> Le chargement a n?cessit? le package : splines Le chargement a n?cessit? le
> package : RcmdrMisc Le chargement a n?cessit? le package : car Le
> chargement a n?cessit? le package : sandwich Error : .onLoad a ?chou? dans
> loadNamespace() pour 'tcltk', d?tails :
> appel : system2("otool", c("-L", shQuote(DLL)), stdout = TRUE) erreur : erreur
> lors de l'ex?cution d'une commande Erreur : le chargement du package ou de
> l'espace de noms a ?chou? pour ?Rcmdr?
> sh: otool: command not found
>
> Has somebody any idea of how I can solve this problem ?
>
> Thanks,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


---
This email has been checked for viruses by Avast antivirus software.
http://www.avast.com


From sarah.goslee at gmail.com  Wed Feb 11 16:03:28 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 11 Feb 2015 10:03:28 -0500
Subject: [R] How to read this Rpart decision tree?
In-Reply-To: <DUB126-W84044312488EE3428E3124DE250@phx.gbl>
References: <DUB126-W84044312488EE3428E3124DE250@phx.gbl>
Message-ID: <CAM_vjumQvGAg+ZimJ37ECMw6R5AetNB8U3ABKsHXBhu5Md=UiA@mail.gmail.com>

Hi Kim

fancyRpartPlot is a front-end to prp, and you can pass it all of the
prp options - it says this in the help for fancyRpartPlot, and that's
about all it says.

So you need to spend some time reading about prp options, and how to
customize your plot to get what you want. There are lots of detailed
resources; here's one to get you started.

http://www.milbo.org/rpart-plot/prp.pdf

Sarah

On Wed, Feb 11, 2015 at 3:02 AM, Kim C. <minorthreatx at hotmail.com> wrote:
> Hi all,
>
> In the attachment or this link (http://oi58.tinypic.com/35ic9qc.jpg) you'll find the decision tree I made. I used the Rpart package to make the tree and the rattle package using the fancyRpartPlot to plot it. The data in the tree looks different than about every example I have seen before. I don't understand how I should read it. I want to predict Product (which are productkeys). The variables to predict it contain age, incomegroup, gender, totalchildren, education, occupation, houseownerflag, numberCars.It looks like the upper number is a ProductKey. The "n" is number of observations? And the percentage of the yes/no question below.
>
> This is the code I used.
>
>> ss.rpart1 <- rpart(Product ~ ., data=sstrain, control=rpart.control(minbucket=2,minsplit=1, cp=-1))
>> spt <- which.min(ss.rpart1$cptable[, "xerror"])
>> scp <- ss.rpart1$cptable[opt, "CP"]
>> ss.rpart2 <- prune(ss.rpart1, cp=cp)
>> fancyRpartPlot(ss.rpart2)
>
> So why does the tree looks so different from the most (for example: http://media.tumblr.com/a9f482ff88b0b9cfaffca7ffd46c6a8e/tumblr_inline_mz7pyuaYJQ1s5wtly.png). This is from Trevor Stephen's TItanic tutorial. The first node show that 62% of 100% doesn't survive. If they were male, only 19% of them were survivors. I find that a lot examples look like that. Why does mine predict per ProductKey and every node it has something else. it doesn't make sense to me. And it doesn't have the two numbers like .62 and .38 but it has n=197e+3. So should I read the first node like "For 100% of the observations of ProductKey 1074, the incomegroup was moderate)"?
>
> Thank you!
>
> Kim
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From ggrothendieck at gmail.com  Wed Feb 11 16:22:10 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 11 Feb 2015 10:22:10 -0500
Subject: [R] sqldf() difference between R 3.1.2 and 3.0.1
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686CF38A9FF@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686CF38A9FF@DC1VEX10MB001.air.org>
Message-ID: <CAP01uR=nkkdAHs0B2dGZrrh879Ar=g2zevfxMSCegi8v+kQWhA@mail.gmail.com>

On Wed, Feb 11, 2015 at 9:45 AM, Doran, Harold <HDoran at air.org> wrote:
> I have a function written and tested using R 3.0.1 and sqldf_0.4-7.1 that works perfectly. However, using this same code with R 3.1.2 and sqldf_0.4-10 yields the error below that I am having a difficult time deciphering. Hence, same code behaves differently on different versions of R and sqldf().
>
> Error in sqliteSendQuery(con, statement, bind.data) :
>   error in statement: no such column: V1
>
>
> Reproducible example below as well as complete sessionInfo all provided below.
>
>
> My function and code using the function are below.
>
> dorReader <- function(dorFile, layout, sepChar = '\n'){
>                 sepChar <- as.character(sepChar)
>                 dorFile <- as.character(dorFile)
>                 layout$type2 <- ifelse(layout$type == 'C', 'character',
>                                                                 ifelse(layout$type == 'N', 'numeric', 'Date'))
>                 dor <- file(dorFile)
>                 attr(dor, "file.format") <- list(sep = sepChar)
>                 getVars <- paste("select",
>                paste("substr(V1, ", layout$Start, ", ",
>                      layout$Length, ") '", layout$Variable.Name, "'", collapse = ", "), "from dor")
>                 dat <- sqldf(getVars)
>
>                 classConverter <- function(obj, types){
>                                 out <- lapply(1:length(obj),FUN = function(i){FUN1 <- switch(types[i],character = as.character,numeric = as.numeric,factor = as.factor, Date = as.character); FUN1(obj[,i])})
>                                 names(out) <- colnames(obj)
>                                 as.data.frame(out)
>                 }
>                 dat <- classConverter(dat, layout$type2)
>                 names(dat) <- layout$Variable.Name
>                 dat
> }
>
> ### contents of fwf file 'sample.txt'
> 1234567
> 1234567
> 1234567
> 1234567
> 1234567
> 1234567
> 1234567
> 1234567
>
> layout <- data.frame("Variable.Name" =c('test1', 'test2'), "Length" = c(3,4), "Start" =c(1,4), "End" = c(3,7), "type" = c('N', 'N'))
>
> tmp <- dorReader('sample.txt', layout)

sqldf is documented to use the sqliteImportFile defaults for
file.format components.  It may be that RSQLite 1.0 has changed the
default for header in sqliteImportFile.

Try replacing your statement that sets file.format with this:

attr(dor, "file.format") <- list(sep = sepChar, header = FALSE)


From HDoran at air.org  Wed Feb 11 16:24:25 2015
From: HDoran at air.org (Doran, Harold)
Date: Wed, 11 Feb 2015 15:24:25 +0000
Subject: [R] sqldf() difference between R 3.1.2 and 3.0.1
In-Reply-To: <CAP01uR=nkkdAHs0B2dGZrrh879Ar=g2zevfxMSCegi8v+kQWhA@mail.gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686CF38A9FF@DC1VEX10MB001.air.org>
	<CAP01uR=nkkdAHs0B2dGZrrh879Ar=g2zevfxMSCegi8v+kQWhA@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686CF38AB3D@DC1VEX10MB001.air.org>

That seems to have worked, both in the new and old version of R. I'll do more unit testing on other files.

Thank you, Gabor.

-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Wednesday, February 11, 2015 10:22 AM
To: Doran, Harold
Cc: r-help at r-project.org
Subject: Re: [R] sqldf() difference between R 3.1.2 and 3.0.1

On Wed, Feb 11, 2015 at 9:45 AM, Doran, Harold <HDoran at air.org> wrote:
> I have a function written and tested using R 3.0.1 and sqldf_0.4-7.1 that works perfectly. However, using this same code with R 3.1.2 and sqldf_0.4-10 yields the error below that I am having a difficult time deciphering. Hence, same code behaves differently on different versions of R and sqldf().
>
> Error in sqliteSendQuery(con, statement, bind.data) :
>   error in statement: no such column: V1
>
>
> Reproducible example below as well as complete sessionInfo all provided below.
>
>
> My function and code using the function are below.
>
> dorReader <- function(dorFile, layout, sepChar = '\n'){
>                 sepChar <- as.character(sepChar)
>                 dorFile <- as.character(dorFile)
>                 layout$type2 <- ifelse(layout$type == 'C', 'character',
>                                                                 ifelse(layout$type == 'N', 'numeric', 'Date'))
>                 dor <- file(dorFile)
>                 attr(dor, "file.format") <- list(sep = sepChar)
>                 getVars <- paste("select",
>                paste("substr(V1, ", layout$Start, ", ",
>                      layout$Length, ") '", layout$Variable.Name, "'", collapse = ", "), "from dor")
>                 dat <- sqldf(getVars)
>
>                 classConverter <- function(obj, types){
>                                 out <- lapply(1:length(obj),FUN = function(i){FUN1 <- switch(types[i],character = as.character,numeric = as.numeric,factor = as.factor, Date = as.character); FUN1(obj[,i])})
>                                 names(out) <- colnames(obj)
>                                 as.data.frame(out)
>                 }
>                 dat <- classConverter(dat, layout$type2)
>                 names(dat) <- layout$Variable.Name
>                 dat
> }
>
> ### contents of fwf file 'sample.txt'
> 1234567
> 1234567
> 1234567
> 1234567
> 1234567
> 1234567
> 1234567
> 1234567
>
> layout <- data.frame("Variable.Name" =c('test1', 'test2'), "Length" = 
> c(3,4), "Start" =c(1,4), "End" = c(3,7), "type" = c('N', 'N'))
>
> tmp <- dorReader('sample.txt', layout)

sqldf is documented to use the sqliteImportFile defaults for file.format components.  It may be that RSQLite 1.0 has changed the default for header in sqliteImportFile.

Try replacing your statement that sets file.format with this:

attr(dor, "file.format") <- list(sep = sepChar, header = FALSE)

From jabbba at gmail.com  Wed Feb 11 16:49:15 2015
From: jabbba at gmail.com (Marco =?ISO-8859-1?B?QmFyYuByYQ==?=)
Date: Wed, 11 Feb 2015 16:49:15 +0100
Subject: [R] help in anova
In-Reply-To: <1423666285303.92712@uef.fi>
References: <1423666285303.92712@uef.fi>
Message-ID: <20150211164915.6037ef50@caprica>

I suspect that your "treatment" levels are perfectly nested inside the
"soilgroup" levels. If this were the case you can either use one of the
factor in your analysis or the other, depending on what you want to
analyze.


Il giorno Wed, 11 Feb 2015 14:47:18 +0000
Mir Salam <mir.salam at uef.fi> ha scritto:

> Dear all,
> 
>


From btrautman84 at gmail.com  Wed Feb 11 16:52:40 2015
From: btrautman84 at gmail.com (Brian Trautman)
Date: Wed, 11 Feb 2015 07:52:40 -0800
Subject: [R] MApply and SubStr
In-Reply-To: <6E7FA71C-5DBB-422A-8285-03D7CE50E267@comcast.net>
References: <CAFYnejJ7BOV3j9E53yOy5Y8Buhe_kbioGvodMWpAyNU7tVtSZA@mail.gmail.com>
	<6E7FA71C-5DBB-422A-8285-03D7CE50E267@comcast.net>
Message-ID: <CAFYnejJFq819OX6jusjTCOa8HyM2myspRDK8BAbUkC0Yb_xpDw@mail.gmail.com>

That's exactly what I wanted, thank you very much!

My intent was to perform the SubStr operation first, and then apply the
types to the columns. I wasn't expecting the two types in the same column.

I appreciate your response!

On Tue, Feb 10, 2015 at 5:03 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Feb 10, 2015, at 3:58 PM, Brian Trautman wrote:
>
> > Hi!
> >
> > I'm trying to write a custom function that applies SubStr to a string,
> and
> > then depending on the arguments, converts the output to a number.
> >
> > The substring part of my code works fine, but it's not converting the
> way I
> > want to --
> >
> > options('stringsAsFactors'=FALSE)
> > require(data.table)
> >
> > substr_typeswitch <- function(x, start, stop, typeto='chr')
> > {
> >  tmpvar <- substr(x=x, start=start, stop=stop)
> >  tmpvar <- switch(typeto, num=as.numeric(tmpvar), tmpvar)
> >  return(tmpvar)
> > }
> >  startpos <- c(01, 03)
> >  endpos <-   c(02, 04)
> >  typelist <- c('chr', 'num')
> >
> >  startdata <- as.data.table(c('aa01', 'bb02'))
> >
> >  enddata_want <- as.data.table(mapply(substr_typeswitch, startdata,
> > startpos, endpos, typelist))
> >
> > If I examine enddata_want --
> >
> >> str(enddata_want)
> > Classes ?data.table? and 'data.frame': 2 obs. of  2 variables:
> > $ V1: chr  "aa" "bb"
> > $ NA: chr  "1" "2"
> > - attr(*, ".internal.selfref")=<externalptr>
> >
> > "1" and "2" are being stored as character, and not as number.
>
> It appears from you code that you might be expecting a vector in a
> dataframe object to have a character mode in the first postition and a
> numeric mode in the second position. That wouldn't seem to be a reasonable
> expectation. But maybe you were hoping the chr and num types were to be
> applied to columns. I was surprised to get something different from
> as.data.table:
>
> > str(enddata_want)
> Classes ?data.table? and 'data.frame':  2 obs. of  2 variables:
>  $ V1: Factor w/ 2 levels "aa","bb": 1 2
>  $ NA: Factor w/ 2 levels "1","2": 1 2
>  - attr(*, ".internal.selfref")=<externalptr>
>
> The mapply operation made a matrix which forces all values to be the same
> mode:
>
> > str( mapply(substr_typeswitch, startdata,
> +  startpos, endpos, typelist) )
>  chr [1:2, 1:2] "aa" "bb" "1" "2"
>  - attr(*, "dimnames")=List of 2
>   ..$ : NULL
>   ..$ : chr [1:2] "V1" NA
>
> You might have gotten something less homogeneous if you added the SIMPLIFY
> argument:
>
> > str( mapply(substr_typeswitch, startdata,
> +  startpos, endpos, typelist, SIMPLIFY=FALSE) )
> List of 2
>  $ V1: chr [1:2] "aa" "bb"
>  $ NA: num [1:2] 1 2
>
>
>
>
> >
> > Can anyone help me understand what I'm doing wrong?
> >
> > Thank you!
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Wed Feb 11 17:11:06 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 11 Feb 2015 16:11:06 +0000
Subject: [R] Extract data from Array to Table
Message-ID: <CALJKBv_0rJa96jePxbwbbdk4zp-tu4Z5JZHrp9QeCnJWc-N_xg@mail.gmail.com>

Dear All,
I am facing the task to extract data from array to table. here an example
of array.

##Get A list of Matrices with unequal rows

Disease <- NULL
Diseases <- NULL
ListMatByGene <- NULL
for(i in 1:3){

Disease[[i]] <-matrix(sample(-30:30,25+(5*
i)),5+i)
rownames(Disease[[i]]) <- paste0("Sample",1:(5+i))
colnames(Disease[[i]]) <- paste0("Gene",1:5)

D <- paste0("Disease",i)
Diseases[[D]] <- Disease[[i]]
}


## get the same Column from all matrices
getColumn <- function(x, colNum, len = nrow(x)){
    y <- x[,colNum]
    length(y) <- len
    y
}

## get Matrices by the same columns of the list of matrices
getMatrices <- function(colNums, dataList = x){
    # the number of rows required
    n <- max(sapply(dataList, nrow))
    lapply(colNums, function(x, dat, n) { # iterate along requested columns
        do.call(cbind, lapply(dat, getColumn,x, len=n)) # iterate along
input data list
    }, dataList, n)
}

## Rotate the list of matrices by 90?
G <- paste0("Gene",1:5)
ListMatByGene[G] <- getMatrices(c(1:ncol(Diseases[[1]])),dataList=Diseases)

## get Disease correlation by gene
DiseaseCorrelation <- lapply(ListMatByGene,function(x) cor(x,use="na",
method="spearman"))

##convert the list of Matrices to array
ArrayDiseaseCor <- array(unlist(DiseaseCorrelation), dim =
c(nrow(DiseaseCorrelation[[1]]), ncol(DiseaseCorrelation[[1]]),
length(DiseaseCorrelation)))
dimnames(ArrayDiseaseCor) <- list(names(Diseases), names(Diseases),
colnames(Diseases[[1]]))

## Select only correlation bigger than 0.5 from the array
FilterDiseaseCor <- apply(ArrayDiseaseCor,MARGIN=c(1,2) ,function(x)
x[abs(x)>0.5])

## Final result
FilterDiseaseCor

         Disease1   Disease2  Disease3
Disease1 Numeric,5  Numeric,2 -0.9428571
Disease2 Numeric,2  Numeric,5 Numeric,2
Disease3 -0.9428571 Numeric,2 Numeric,5


Question is:
How can get a table as:

D1              D2               Cor       Gene
Disease1    Disease2      -0.94    Gene2
Disease1    Disease2       0.78    Gene4
Disease3    Disease2       0.5      Gene5
...

and
                 Disease1   Disease2      Disease3
Disease1        5                1                0
Disease2        1                 5                3
Disease3        0                  3               5

Or in general, How can I extract data from Array to Table?

Thanks
Karim

	[[alternative HTML version deleted]]


From chl948 at mail.usask.ca  Wed Feb 11 17:11:17 2015
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Wed, 11 Feb 2015 10:11:17 -0600
Subject: [R] How to solve this complex equation
In-Reply-To: <54D9C172.3090009@auckland.ac.nz>
References: <1423530289334-4702997.post@n4.nabble.com>
	<54D9C172.3090009@auckland.ac.nz>
Message-ID: <54DB7F25.2060001@mail.usask.ca>

The functional form given in the post written by Ssuhanchen captures my 
eyes.   It is the cumulative distribution function of Poisson when the 
number of counts is less than or equal to 2 with unknown parameter 
mu=x/2.   Since it is a nonlinear function, there may be multiple 
solutions but the solution should be greater than 0 (if I am in the 
right track).   I am assuming this functional form is originated from 
the Poisson.  Under this assumption, one solution is found as below:

 > rt <- uniroot(function(x) ppois(2, lambda=x)-0.05, interval=c(0.5,1), 
extendInt="yes")
Warning messages:
1: In ppois(2, lambda = x) : NaNs produced
2: In ppois(2, lambda = x) : NaNs produced
3: In ppois(2, lambda = x) : NaNs produced
 > ppois(2, lambda=rt$root)
[1] 0.0500001
 > rt$root
[1] 6.295791

Thus, the solution x would be rt$root*2 (Note that I did not try to find 
other solutions).  I hope this helps.

Chel Hee Lee

On 2/10/2015 2:29 AM, Rolf Turner wrote:
> On 10/02/15 14:04, Ssuhanchen wrote:
>> Hi!
>>
>> I want to use R to calculate the variable x which is in a complex 
>> equation
>> in below:
>>
>>   2
>>   ?[exp(-x/2)*(x^k)/(2^k*k!)]=0.05
>> k=0
>>
>> how to solve this equation to get the exact x in R?
>
> Is this homework?  Sure looks like it.  Talk to your prof.  Or do a 
> bit of work on learning how to use R --- which is presumably the point 
> of the exercise.
>
> cheers,
>
> Rolf Turner
>


From caciquesamurai at gmail.com  Wed Feb 11 17:17:47 2015
From: caciquesamurai at gmail.com (Raoni Rodrigues)
Date: Wed, 11 Feb 2015 14:17:47 -0200
Subject: [R] Download internet videos
Message-ID: <CAGtwFe2iFoWBNmPtQ0XGU+19cjb8-mdu4HXucSmjQExOUxR3AA@mail.gmail.com>

Hello R-helpers,

It is possible donwload youtube videos with R? I made a google search and
find no options to do that.

Thanks in advanced,

Raoni

	[[alternative HTML version deleted]]


From wizardchef at gmail.com  Wed Feb 11 17:25:50 2015
From: wizardchef at gmail.com (Ernest Stokely)
Date: Wed, 11 Feb 2015 10:25:50 -0600
Subject: [R] A portfolio return function?
Message-ID: <578A872F-BCB5-4EF6-B27C-32CE2E85C5B0@gmail.com>

For finance applications, I'm surprised that I am unable to find a function to compute the portfolio return (sqrt(t(w) %*% V %*% w)) where w are portfolio weights and V is the cov(returns). The Performance Analytics portfolio return function seems to compute something else.
Ernie


From pdalgd at gmail.com  Wed Feb 11 17:37:50 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 11 Feb 2015 17:37:50 +0100
Subject: [R] How to solve this complex equation
In-Reply-To: <54DB7F25.2060001@mail.usask.ca>
References: <1423530289334-4702997.post@n4.nabble.com>
	<54D9C172.3090009@auckland.ac.nz> <54DB7F25.2060001@mail.usask.ca>
Message-ID: <14637D34-8F28-4B8E-9FB8-CB20969F437F@gmail.com>


On 11 Feb 2015, at 17:11 , Chel Hee Lee <chl948 at mail.usask.ca> wrote:

> The functional form given in the post written by Ssuhanchen captures my eyes.   It is the cumulative distribution function of Poisson when the number of counts is less than or equal to 2 with unknown parameter mu=x/2.   Since it is a nonlinear function, there may be multiple solutions but the solution should be greater than 0 (if I am in the right track).   I am assuming this functional form is originated from the Poisson.  Under this assumption, one solution is found as below:
> 
> > rt <- uniroot(function(x) ppois(2, lambda=x)-0.05, interval=c(0.5,1), extendInt="yes")
> Warning messages:
> 1: In ppois(2, lambda = x) : NaNs produced
> 2: In ppois(2, lambda = x) : NaNs produced
> 3: In ppois(2, lambda = x) : NaNs produced
> > ppois(2, lambda=rt$root)
> [1] 0.0500001
> > rt$root
> [1] 6.295791
> 
> Thus, the solution x would be rt$root*2 (Note that I did not try to find other solutions).  I hope this helps.
> 

Given the Poisson connection, I would pretty strongly expect the solution to be unique. 

Notice also that your rt$root comes out as the upper end of the confidence interval in

> poisson.test(2, alt="l")

	Exact Poisson test

data:  2 time base: 1
number of events = 2, time base = 1, p-value = 0.9197
alternative hypothesis: true event rate is less than 1
95 percent confidence interval:
 0.000000 6.295794
sample estimates:
event rate 
         2 





> Chel Hee Lee
> 
> On 2/10/2015 2:29 AM, Rolf Turner wrote:
>> On 10/02/15 14:04, Ssuhanchen wrote:
>>> Hi!
>>> 
>>> I want to use R to calculate the variable x which is in a complex equation
>>> in below:
>>> 
>>>  2
>>>  ?[exp(-x/2)*(x^k)/(2^k*k!)]=0.05
>>> k=0
>>> 
>>> how to solve this equation to get the exact x in R?
>> 
>> Is this homework?  Sure looks like it.  Talk to your prof.  Or do a bit of work on learning how to use R --- which is presumably the point of the exercise.
>> 
>> cheers,
>> 
>> Rolf Turner
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From chl948 at mail.usask.ca  Wed Feb 11 17:42:32 2015
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Wed, 11 Feb 2015 10:42:32 -0600
Subject: [R] How to solve this complex equation
In-Reply-To: <14637D34-8F28-4B8E-9FB8-CB20969F437F@gmail.com>
References: <1423530289334-4702997.post@n4.nabble.com>
	<54D9C172.3090009@auckland.ac.nz> <54DB7F25.2060001@mail.usask.ca>
	<14637D34-8F28-4B8E-9FB8-CB20969F437F@gmail.com>
Message-ID: <54DB8678.6030405@mail.usask.ca>

A~ha~!!  Thank you, Prof. Peter Dalgaard, so much for your wonderful 
lesson!!!  Learning new things everyday from this R-help mailing list!

Chel Hee Lee

On 2/11/2015 10:37 AM, peter dalgaard wrote:
>
> On 11 Feb 2015, at 17:11 , Chel Hee Lee <chl948 at mail.usask.ca> wrote:
>
>> The functional form given in the post written by Ssuhanchen captures my eyes.   It is the cumulative distribution function of Poisson when the number of counts is less than or equal to 2 with unknown parameter mu=x/2.   Since it is a nonlinear function, there may be multiple solutions but the solution should be greater than 0 (if I am in the right track).   I am assuming this functional form is originated from the Poisson.  Under this assumption, one solution is found as below:
>>
>>> rt <- uniroot(function(x) ppois(2, lambda=x)-0.05, interval=c(0.5,1), extendInt="yes")
>> Warning messages:
>> 1: In ppois(2, lambda = x) : NaNs produced
>> 2: In ppois(2, lambda = x) : NaNs produced
>> 3: In ppois(2, lambda = x) : NaNs produced
>>> ppois(2, lambda=rt$root)
>> [1] 0.0500001
>>> rt$root
>> [1] 6.295791
>>
>> Thus, the solution x would be rt$root*2 (Note that I did not try to find other solutions).  I hope this helps.
>>
>
> Given the Poisson connection, I would pretty strongly expect the solution to be unique.
>
> Notice also that your rt$root comes out as the upper end of the confidence interval in
>
>> poisson.test(2, alt="l")
>
> 	Exact Poisson test
>
> data:  2 time base: 1
> number of events = 2, time base = 1, p-value = 0.9197
> alternative hypothesis: true event rate is less than 1
> 95 percent confidence interval:
>   0.000000 6.295794
> sample estimates:
> event rate
>           2
>
>
>
>
>
>> Chel Hee Lee
>>
>> On 2/10/2015 2:29 AM, Rolf Turner wrote:
>>> On 10/02/15 14:04, Ssuhanchen wrote:
>>>> Hi!
>>>>
>>>> I want to use R to calculate the variable x which is in a complex equation
>>>> in below:
>>>>
>>>>   2
>>>>   ?[exp(-x/2)*(x^k)/(2^k*k!)]=0.05
>>>> k=0
>>>>
>>>> how to solve this equation to get the exact x in R?
>>>
>>> Is this homework?  Sure looks like it.  Talk to your prof.  Or do a bit of work on learning how to use R --- which is presumably the point of the exercise.
>>>
>>> cheers,
>>>
>>> Rolf Turner
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Wed Feb 11 18:26:50 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 11 Feb 2015 12:26:50 -0500
Subject: [R] Download internet videos
In-Reply-To: <CAGtwFe2iFoWBNmPtQ0XGU+19cjb8-mdu4HXucSmjQExOUxR3AA@mail.gmail.com>
References: <CAGtwFe2iFoWBNmPtQ0XGU+19cjb8-mdu4HXucSmjQExOUxR3AA@mail.gmail.com>
Message-ID: <AD53FD42-063F-429E-A6E7-215489BB79FD@dcn.davis.CA.us>

The set of things that R can do is not a subset of the set of things packages may have been written for.

Have at it.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 11, 2015 11:17:47 AM EST, Raoni Rodrigues <caciquesamurai at gmail.com> wrote:
>Hello R-helpers,
>
>It is possible donwload youtube videos with R? I made a google search
>and
>find no options to do that.
>
>Thanks in advanced,
>
>Raoni
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Wed Feb 11 19:28:24 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 11 Feb 2015 12:28:24 -0600
Subject: [R] Package build help
In-Reply-To: <54D7EE21.7030505@gmail.com>
References: <b3a194a5-fe72-4202-9999-adf41b5a88c0@me.com>
	<54D7EE21.7030505@gmail.com>
Message-ID: <CABdHhvHnoFf-PzpGyf_NPCr6Owj_La4oq8dQuZgpL4wbk1p8eA@mail.gmail.com>

On Sun, Feb 8, 2015 at 5:15 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 08/02/2015 4:06 PM, Glenn Schultz wrote:
>> Hello All,
>>
>> I am in the final stages of building my first package "BondLab" and the check throughs the following warning.  I think this is namespace thing.  I have not done anything with the namespace at this point.  I am turning my attention to the namespace now.  Am I correct this can be a handled by the namespace?
>>
>
> I would guess you have imported the lubridate and plyr packages, and
> also defined your own duration() and here() functions, hiding theirs.

You can also see this problem if you have

import(plyr)
import(plyr, here)

etc.

Or with

import(plyr)
import(lubridate)

since I think both provide a here() function.

Hadley

-- 
http://had.co.nz/


From Jonathan.Burns1 at gdit.com  Wed Feb 11 20:03:31 2015
From: Jonathan.Burns1 at gdit.com (Burns, Jonathan (NONUS))
Date: Wed, 11 Feb 2015 19:03:31 +0000
Subject: [R] prediction intervals for robust regression
Message-ID: <7FF112ADD55D2142AB443F2BC619CBB04758E52B@HQ200-EXMBX03.ad.local>

I have created robust regression models using least trimmed squares and MM-regression (using the R package robustbase).

I am now looking to create prediction intervals for the predicted results.  While I have seen some discussion in the literature about confidence intervals on the estimates for robust regression, I haven't had much success in finding out how to create prediction intervals for the results.  I was wondering if anyone would be able to provide some direction on how to create these prediction intervals in the robust regression setting.

Thanks,

Jonathan Burns
Sr. Statistician
General Dynamics Information Technology
Medicare & Medicaid Solutions
One West Pennsylvania Avenue
Baltimore, MD 21204
(410)-842-1594
Jonathan.Burns1 at gdit.com<mailto:Jonathan.Burns1 at gdit.com>
www.gdit.com<http://www.gdit.com/>


	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Wed Feb 11 20:38:12 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 11 Feb 2015 11:38:12 -0800
Subject: [R] prediction intervals for robust regression
In-Reply-To: <7FF112ADD55D2142AB443F2BC619CBB04758E52B@HQ200-EXMBX03.ad.local>
References: <7FF112ADD55D2142AB443F2BC619CBB04758E52B@HQ200-EXMBX03.ad.local>
Message-ID: <CACk-te3b9+B8eg_i+bSOgbHpAyHKEft8vHOHGvi=3z8QRWjCdQ@mail.gmail.com>

Presumably you've checked out:

http://cran.r-project.org/web/views/Robust.html

If you can estimate the variance of parameter estimates, betahat, then
you can estimate the variance of a predicted value, X betahat; add the
estimated variance of individuals to this if that's what you're
looking for (and it's not already available).

Further questions should go to a statistics site like
stats.stackexchange.com, as statistical questions are off topic here.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Feb 11, 2015 at 11:03 AM, Burns, Jonathan (NONUS)
<Jonathan.Burns1 at gdit.com> wrote:
> I have created robust regression models using least trimmed squares and MM-regression (using the R package robustbase).
>
> I am now looking to create prediction intervals for the predicted results.  While I have seen some discussion in the literature about confidence intervals on the estimates for robust regression, I haven't had much success in finding out how to create prediction intervals for the results.  I was wondering if anyone would be able to provide some direction on how to create these prediction intervals in the robust regression setting.
>
> Thanks,
>
> Jonathan Burns
> Sr. Statistician
> General Dynamics Information Technology
> Medicare & Medicaid Solutions
> One West Pennsylvania Avenue
> Baltimore, MD 21204
> (410)-842-1594
> Jonathan.Burns1 at gdit.com<mailto:Jonathan.Burns1 at gdit.com>
> www.gdit.com<http://www.gdit.com/>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Wed Feb 11 20:55:38 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Feb 2015 19:55:38 +0000
Subject: [R] prediction intervals for robust regression
In-Reply-To: <CACk-te3b9+B8eg_i+bSOgbHpAyHKEft8vHOHGvi=3z8QRWjCdQ@mail.gmail.com>
References: <7FF112ADD55D2142AB443F2BC619CBB04758E52B@HQ200-EXMBX03.ad.local>
	<CACk-te3b9+B8eg_i+bSOgbHpAyHKEft8vHOHGvi=3z8QRWjCdQ@mail.gmail.com>
Message-ID: <54DBB3BA.9080704@stats.ox.ac.uk>

On 11/02/2015 19:38, Bert Gunter wrote:
> Presumably you've checked out:
>
> http://cran.r-project.org/web/views/Robust.html
>
> If you can estimate the variance of parameter estimates, betahat, then
> you can estimate the variance of a predicted value, X betahat; add the
> estimated variance of individuals to this if that's what you're
> looking for (and it's not already available).

But that's not too much use without some idea of the error distribution, 
and using robust statistics assumes it is non-normal, long-tailed.  And 
it is unusual to have enough data to estimate the tail behaviour of such 
a distribution.

It might be better to do this with a parametric model with a long-tailed 
error distribution, especially if there is evidence (e.g. from other 
samples) about the latter.

> Further questions should go to a statistics site like
> stats.stackexchange.com, as statistical questions are off topic here.

Agreed.


>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Wed, Feb 11, 2015 at 11:03 AM, Burns, Jonathan (NONUS)
> <Jonathan.Burns1 at gdit.com> wrote:
>> I have created robust regression models using least trimmed squares and MM-regression (using the R package robustbase).
>>
>> I am now looking to create prediction intervals for the predicted results.  While I have seen some discussion in the literature about confidence intervals on the estimates for robust regression, I haven't had much success in finding out how to create prediction intervals for the results.  I was wondering if anyone would be able to provide some direction on how to create these prediction intervals in the robust regression setting.
>>
>> Thanks,
>>
>> Jonathan Burns
>> Sr. Statistician
>> General Dynamics Information Technology
>> Medicare & Medicaid Solutions
>> One West Pennsylvania Avenue
>> Baltimore, MD 21204
>> (410)-842-1594
>> Jonathan.Burns1 at gdit.com<mailto:Jonathan.Burns1 at gdit.com>
>> www.gdit.com<http://www.gdit.com/>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From andreas.nord at biol.lu.se  Wed Feb 11 16:57:15 2015
From: andreas.nord at biol.lu.se (anord)
Date: Wed, 11 Feb 2015 07:57:15 -0800 (PST)
Subject: [R] AR1 covariance structure for lme object and R/SAS differences
 in model output
Message-ID: <1423670235304-4703103.post@n4.nabble.com>

Dear R users, 
We are working on a data set in which we have measured repeatedly a
physiological response variable (y) 
every 20 min for 12 h (time variable; 'x') in subjects ('id') beloning to
one of five groups ('group'; 'A' to 'E'). Data are located at:
https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0

We are interested to model if the response in y differences with time (i.e.
'x') for the two groups. Thus:
require(nlme)
m1<-lme(y~group*x+group*I(x^2),random=~x|id,data=data.df,na.action=na.omit)

But because data are collected repeatedly over short time intervals for each
subject, it seemed prudent to consider an autoregressive covariance
structure. Thus:
m2<-update(m1,~.,corr=corCAR1(form=~x|id))

AIC values indicate the latter (i.e. m2) as more appropriate:
  anova(m1,m2)
#   Model df      AIC      BIC       logLik        Test  L.Ratio     
p-value
#m1     1 19 2155.996 2260.767 -1058.9981                        
#m2     2 20 2021.944 2132.229  -990.9718 1 vs 2 136.0525  <.0001

Fixed effects and test statistics differ between models. A look at marginal
ANOVA tables suggest inference might differ somewhat between models:
  
anova.lme(m1,type="m")
#              numDF denDF  F-value p-value
#(Intercept)      1  1789 63384.80  <.0001
#group             4    45      1.29  0.2893
#x                   1  1789     0.05  0.8226
#I(x^2)            1  1789     4.02  0.0451
#group:x          4  1789     2.61  0.0341
#group:I(x^2)   4  1789     4.37  0.0016

anova.lme(m2,type="m")
#             numDF denDF  F-value p-value
#(Intercept)      1  1789 59395.79  <.0001
#group             4    45      1.33  0.2725
#x                   1  1789     0.04  0.8379
#I(x^2)            1  1789     2.28  0.1312
#group:x          4  1789     2.09  0.0802
#group:I(x^2)   4  1789     2.81  0.0244

Now, this is all well. But: my colleagues have been running the same data
set using PROC MIXED in SAS and come up with substantially different results
when comparing SAS default covariance structure (variance components) and
AR1. Specifically, there is virtually no change in either test statistics or
fitted values when using AR1 instead of Variance Components in SAS, which
fits the observation that AIC values (in SAS) indicate both covariance
structures fit data equally well. 

This is not very satisfactory to me, and I would be interesting to know what
is happening here. Realizing
this might not be the correct forum for this question, I would like to ask
you all if anyone would have any
input as to what is going on here, e.g. am I setting up my model
erroneously, etc.? 

N.b. I have no desire to replicate SAS results, but I would most certainly
be interested to know what could possibly explain  such a large discrepancy
between the two platforms. Any suggestions greatly welcomed.

(Data are located at:
https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0)

With all best wishes,
Andreas






--
View this message in context: http://r.789695.n4.nabble.com/AR1-covariance-structure-for-lme-object-and-R-SAS-differences-in-model-output-tp4703103.html
Sent from the R help mailing list archive at Nabble.com.


From albert.shuxiang.li at gmail.com  Wed Feb 11 16:10:03 2015
From: albert.shuxiang.li at gmail.com (Albert Shuxiang Li)
Date: Wed, 11 Feb 2015 08:10:03 -0700
Subject: [R] Problem Solved: optim fails when using arima
In-Reply-To: <CANko1DK5jpi8U37oHPiYoy=AMTbohh-w0s3v+8z=2hS_BPD8rQ@mail.gmail.com>
References: <CANko1DLjLyka07PDkVZq6bOFhS70Cq2nNEXZjvt8ZJtdXPJPcg@mail.gmail.com>
	<CANko1DJ-4qVF2mE7ztLkwW-tija8uDTfDxKW0gzXKogPhYDQSw@mail.gmail.com>
	<CANko1DK_VEsuy1obWZx=xd4ZS3TG94vSeueE=tW3eWxxQwb_cA@mail.gmail.com>
	<CANko1D+E7KqhuCaRDtLfe-MPRvvL1MJEm+Vb9uombt-Qz-Cqjw@mail.gmail.com>
	<CANko1DK5jpi8U37oHPiYoy=AMTbohh-w0s3v+8z=2hS_BPD8rQ@mail.gmail.com>
Message-ID: <CANko1DKHubongY0zDTNVGXxmvfi8c+D3Z-akykVA5TNkrp7HKA@mail.gmail.com>

I am using arima(x, order=c(p,0,q)) function for my project, which deals
with a set of large differenced time series data, data size varies from
8000 to 70000. I checked their stationarity before applying arima.
Occasionally, arima(x, order=c(p,0,q)) gives me error like following (which
stops script running):

Error in optim(init[mask], armafn, method = optim.method, Hessian = TRUE, :
non-finite finite-difference value [16]

The last [16] would change anyting from 1 to 16. Using argument
method="CSS", or "ML", or default did not help. I am using the newest R
version 3.1.2 for windows 7.

I have done a lot of research on internet for this Error Message, and tried
a lot of suggested solutions too. But the results are negative. Then,
finally, I used following line which solved my problem.

arima(x, order=c(p,0,q), optim.method="Nelder-Mead")

Hope this helps others with similar situations.

Shuxiang Albert Li

	[[alternative HTML version deleted]]


From js.huang at protective.com  Wed Feb 11 19:16:28 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 11 Feb 2015 10:16:28 -0800 (PST)
Subject: [R] $ operator is invalid for atomic vectors
In-Reply-To: <1423674963277-4703112.post@n4.nabble.com>
References: <1423674963277-4703112.post@n4.nabble.com>
Message-ID: <1423678588821-4703114.post@n4.nabble.com>

Hi, 

  If x is a data frame, then x$getmean will try to get the vector named
getmean in x.  You put "()" after x$getmean.  I think r is confused about
it.  It appears that you want to call a function named getmean().



--
View this message in context: http://r.789695.n4.nabble.com/operator-is-invalid-for-atomic-vectors-tp4703112p4703114.html
Sent from the R help mailing list archive at Nabble.com.


From statsdoc at gmail.com  Wed Feb 11 15:53:16 2015
From: statsdoc at gmail.com (Tim Victor)
Date: Wed, 11 Feb 2015 09:53:16 -0500
Subject: [R] read.table with missing data and consecutive delimiters
Message-ID: <CAOTyWwA_CRFykoEuDQ+nQQF8++jmXVoMQF3A-FGU06+jWpjF=w@mail.gmail.com>

All,

Assume we have data in an ASCII file that looks like

Var1$Var2$Var3$Var4
1$2$3$4
2$$5
$$$6

When I execute

read.table( 'test.dat', header=TRUE, sep='$' )

I, of course, receive the following error:

Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
 :
  line 2 did not have 4 elements

When I set fill=TRUE, e.g., read.table( 'test.dat', header=TRUE, sep='$',
fill=TRUE )

I get:

  Var1 Var2 Var3 Var4
1    1    2    3    4
2    2   NA    5   NA
3   NA   NA   NA    6


What I need is

  Var1 Var2 Var3 Var4
1    1    2    3    4
2    2   NA   NA    5
3   NA   NA   NA    6

What am I missing?

Thanks,

Tim

	[[alternative HTML version deleted]]


From RZwick at ETS.ORG  Wed Feb 11 17:58:02 2015
From: RZwick at ETS.ORG (Zwick, Rebecca J)
Date: Wed, 11 Feb 2015 16:58:02 +0000
Subject: [R] Nonlinear integer programming question
Message-ID: <DM2PR07MB97659DD4008F85A31901702D2250@DM2PR07MB976.namprd07.prod.outlook.com>

I am seeking an optimization routine that can deal with the following problem:
Maximize g(x), where x is a vector and g is nonlinear, subject to linear constraints of the form h(x)>0 and m(x)=0 and subject to the constraint that all values of x are 0 or 1.
I can't find a nonlinear optimization program in R that states that it can accommodate 0-1 constraints.
Oddly, Excel's Solver will produce a solution to such problems but (1) I don't trust it and (2) it cannot handle a large number of constraints.
Thanks, all!

Rebecca Zwick  (Santa Barbara, California)
Statistical Analysis, Data Analysis, and Psychometric Research
Educational Testing Service


________________________________

This e-mail and any files transmitted with it may contain privileged or confidential information. It is solely for use by the individual for whom it is intended, even if addressed incorrectly. If you received this e-mail in error, please notify the sender; do not disclose, copy, distribute, or take any action in reliance on the contents of this information; and delete it from your system. Any other use of this e-mail is prohibited.


Thank you for your compliance.

________________________________

	[[alternative HTML version deleted]]


From JSorkin at grecc.umaryland.edu  Wed Feb 11 21:23:00 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Wed, 11 Feb 2015 15:23:00 -0500
Subject: [R] Impute time-series data,
 perhaps with a Kalman filter - do you know of any R code?
In-Reply-To: <1423670235304-4703103.post@n4.nabble.com>
References: <1423670235304-4703103.post@n4.nabble.com>
Message-ID: <54DB73D4020000CB00122CED@smtp.medicine.umaryland.edu>

Does anyone have code that uses a Kalman filter to impute time-series data? If not, do you know of any software that can be used to impute time-series data?
Thank you,
John
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From ruipbarradas at sapo.pt  Wed Feb 11 21:34:22 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 11 Feb 2015 20:34:22 +0000
Subject: [R] read.table with missing data and consecutive delimiters
In-Reply-To: <CAOTyWwA_CRFykoEuDQ+nQQF8++jmXVoMQF3A-FGU06+jWpjF=w@mail.gmail.com>
References: <CAOTyWwA_CRFykoEuDQ+nQQF8++jmXVoMQF3A-FGU06+jWpjF=w@mail.gmail.com>
Message-ID: <54DBBCCE.8030803@sapo.pt>

Hello,

You're missing a dollar sign: 2$$$5, not 2$$5.

Hope this helps,

Rui Barradas

Em 11-02-2015 14:53, Tim Victor escreveu:
> All,
>
> Assume we have data in an ASCII file that looks like
>
> Var1$Var2$Var3$Var4
> 1$2$3$4
> 2$$5
> $$$6
>
> When I execute
>
> read.table( 'test.dat', header=TRUE, sep='$' )
>
> I, of course, receive the following error:
>
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
>   :
>    line 2 did not have 4 elements
>
> When I set fill=TRUE, e.g., read.table( 'test.dat', header=TRUE, sep='$',
> fill=TRUE )
>
> I get:
>
>    Var1 Var2 Var3 Var4
> 1    1    2    3    4
> 2    2   NA    5   NA
> 3   NA   NA   NA    6
>
>
> What I need is
>
>    Var1 Var2 Var3 Var4
> 1    1    2    3    4
> 2    2   NA   NA    5
> 3   NA   NA   NA    6
>
> What am I missing?
>
> Thanks,
>
> Tim
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From olivier.crouzet at univ-nantes.fr  Wed Feb 11 21:53:04 2015
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Wed, 11 Feb 2015 21:53:04 +0100
Subject: [R] Impute time-series data,
 perhaps with a Kalman filter - do you know of any R code?
In-Reply-To: <54DB73D4020000CB00122CED@smtp.medicine.umaryland.edu>
References: <1423670235304-4703103.post@n4.nabble.com>
	<54DB73D4020000CB00122CED@smtp.medicine.umaryland.edu>
Message-ID: <20150211215304.352ef1bfbeb51c4351e6bf86@univ-nantes.fr>

Hi,

searching for "kalman filter R" gives this paper that was published in
JSS. It may help.

@article{Tusell:2010:JSSOBK:v39i02,
  author =	"Fernando Tusell",
  title =	"Kalman Filtering in R",
  journal =	"Journal of Statistical Software",
  volume =	"39",
  number =	"2",
  pages =	"1--27",
  day =  	"1",
  month =	"3",
  year = 	"2011",
  CODEN =	"JSSOBK",
  ISSN = 	"1548-7660",
  bibdate =	"2010-08-17",
  URL =  	"http://www.jstatsoft.org/v39/i02",
  accepted =	"2010-08-17",
  acknowledgement = "",
  keywords =	"",
  submitted =	"2010-01-12",
}

15:23:00 -0500 "John Sorkin" <JSorkin at grecc.umaryland.edu> wrote:

> Does anyone have code that uses a Kalman filter to impute time-series
> data? If not, do you know of any software that can be used to impute
> time-series data? Thank you, John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:28}}


From pdalgd at gmail.com  Wed Feb 11 22:09:49 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 11 Feb 2015 22:09:49 +0100
Subject: [R] AR1 covariance structure for lme object and R/SAS
	differences in model output
In-Reply-To: <1423670235304-4703103.post@n4.nabble.com>
References: <1423670235304-4703103.post@n4.nabble.com>
Message-ID: <D541B235-3F25-45AD-BB1F-82C2099AAA1B@gmail.com>


> On 11 Feb 2015, at 16:57 , anord <andreas.nord at biol.lu.se> wrote:
> 
> Dear R users, 
> We are working on a data set in which we have measured repeatedly a
> physiological response variable (y) 
> every 20 min for 12 h (time variable; 'x') in subjects ('id') beloning to
> one of five groups ('group'; 'A' to 'E'). Data are located at:
> https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0
> 
> We are interested to model if the response in y differences with time (i.e.
> 'x') for the two groups. Thus:
> require(nlme)
> m1<-lme(y~group*x+group*I(x^2),random=~x|id,data=data.df,na.action=na.omit)
> 
> But because data are collected repeatedly over short time intervals for each
> subject, it seemed prudent to consider an autoregressive covariance
> structure. Thus:
> m2<-update(m1,~.,corr=corCAR1(form=~x|id))
> 
> AIC values indicate the latter (i.e. m2) as more appropriate:
>  anova(m1,m2)
> #   Model df      AIC      BIC       logLik        Test  L.Ratio     
> p-value
> #m1     1 19 2155.996 2260.767 -1058.9981                        
> #m2     2 20 2021.944 2132.229  -990.9718 1 vs 2 136.0525  <.0001
> 
> Fixed effects and test statistics differ between models. A look at marginal
> ANOVA tables suggest inference might differ somewhat between models:
> 
> anova.lme(m1,type="m")
> #              numDF denDF  F-value p-value
> #(Intercept)      1  1789 63384.80  <.0001
> #group             4    45      1.29  0.2893
> #x                   1  1789     0.05  0.8226
> #I(x^2)            1  1789     4.02  0.0451
> #group:x          4  1789     2.61  0.0341
> #group:I(x^2)   4  1789     4.37  0.0016
> 
> anova.lme(m2,type="m")
> #             numDF denDF  F-value p-value
> #(Intercept)      1  1789 59395.79  <.0001
> #group             4    45      1.33  0.2725
> #x                   1  1789     0.04  0.8379
> #I(x^2)            1  1789     2.28  0.1312
> #group:x          4  1789     2.09  0.0802
> #group:I(x^2)   4  1789     2.81  0.0244
> 
> Now, this is all well. But: my colleagues have been running the same data
> set using PROC MIXED in SAS and come up with substantially different results
> when comparing SAS default covariance structure (variance components) and
> AR1. Specifically, there is virtually no change in either test statistics or
> fitted values when using AR1 instead of Variance Components in SAS, which
> fits the observation that AIC values (in SAS) indicate both covariance
> structures fit data equally well. 
> 
> This is not very satisfactory to me, and I would be interesting to know what
> is happening here. Realizing
> this might not be the correct forum for this question, I would like to ask
> you all if anyone would have any
> input as to what is going on here, e.g. am I setting up my model
> erroneously, etc.? 
> 
> N.b. I have no desire to replicate SAS results, but I would most certainly
> be interested to know what could possibly explain  such a large discrepancy
> between the two platforms. Any suggestions greatly welcomed.
> 
> (Data are located at:
> https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0)
> 

Hmm, does SAS include a nugget effect perchance? At any rate, showing the SAS output (or some of it) might make it easier for someone to help.

Also, R-sig-ME is a better choice for discussions of mixed effects models.


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From macqueen1 at llnl.gov  Wed Feb 11 22:42:56 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 11 Feb 2015 21:42:56 +0000
Subject: [R] Download internet videos
In-Reply-To: <CAGtwFe2iFoWBNmPtQ0XGU+19cjb8-mdu4HXucSmjQExOUxR3AA@mail.gmail.com>
References: <CAGtwFe2iFoWBNmPtQ0XGU+19cjb8-mdu4HXucSmjQExOUxR3AA@mail.gmail.com>
Message-ID: <D1010BB9.11E68A%macqueen1@llnl.gov>

Hmmm.

Well, a youtube video is a file. Therefore search for "R download file"
and you will find the download.file() function.


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 2/11/15, 8:17 AM, "Raoni Rodrigues" <caciquesamurai at gmail.com> wrote:

>Hello R-helpers,
>
>It is possible donwload youtube videos with R? I made a google search and
>find no options to do that.
>
>Thanks in advanced,
>
>Raoni
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Wed Feb 11 22:53:13 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 11 Feb 2015 16:53:13 -0500
Subject: [R] suggestion for optimal plotting to show significant
	differences
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F3E0@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F0E3@SRVEXCHMBX.precheza.cz>
	<CAGx1TMCq1jXtuyofWv5nYC2So0RyKDp_734ze6rAQXztaxccnw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F3E0@SRVEXCHMBX.precheza.cz>
Message-ID: <CAGx1TMDvvOOukbUfk23GrWQLSnmwr-Ykx6Qj=xYZLWraAfBKxA@mail.gmail.com>

Petr,

My first attempt is to use the simple=TRUE argument to interaction2wt.

Then the bwplots in the item|item panel show the behavior of value over day
for each item.  You get a plot similar to this panel with the growth curve plots
from nlme, for example,
    bwplot(value ~ day | item, data=test, horizontal=FALSE)
I am treating set as a replication and each box is cumulated over the
three sets.

My analysis question is about day.  You have it as numeric.  My
inclination would
be to make day factor.  Then you could model the interaction of day and item.

Rich

On Mon, Feb 9, 2015 at 6:01 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Hallo Richard.
>
> I tried your suggestion but it seems to be no better than simple ggplot. Let me extend the example a bit to 8 items which is more realistic.
>
> item<-rep(letters[1:8], each=18)
> day<-rep((0:5)*100, 24)
> set<-rep(rep(1:3, each=6), 8)
> test<-data.frame(item, day, set)
> set.seed(111)
> test$value<-(test$day/100+1)+rnorm(144)
> test$value<-test$value+(as.numeric(test$item)*1.3)
>
> Value is increasing during time (day) for each tested subject (item), each item is measured 3 times (set) each day.
>
> Here is some graph
> p<-ggplot(test, aes(x=day, y=value, colour=item))
> p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))
>
> I can do lm or aov, however I am not sure about proper formula.
>
> fit<-lm(value~day, data=test)
> summary(fit)
> # this shows that value is increasing with day
>
> fit<-lm(value~day/item, data=test)
> summary(fit)
> # this suggests that value is decreasing with day (which is wrong)
>
> fit<-lm(value~day*item, data=test)
> summary(fit)
> # and this tells me that value is increasing with day and items have different intercepts but the same rate of growth (I hope I got it right).
>
> I do not have your book available but I went through help pages.
>
> Your interaction graph is not much better than ggplot.
> I can do
>
> interaction2wt(value ~ item * day, data=test)
>
> which probably is closer to actual problem.
>
> The basic problem is that increase of value with days is in fact not linear and actually it can increase in the beginning and then stagnate or it can stagnate in beginning and then increase. I am not aware of any way how to compare time behaviour of different items in such situations if I cannot state some common formula in which case I would use probably nlme.
>
> Thank for your insight, I try to go through it more deeply.
>
> Best regards
> Petr
>
>
>> -----Original Message-----
>> From: Richard M. Heiberger [mailto:rmh at temple.edu]
>> Sent: Friday, February 06, 2015 6:14 PM
>> To: PIKAL Petr
>> Cc: r-help at r-project.org
>> Subject: Re: [R] suggestion for optimal plotting to show significant
>> differences
>>
>> I would try one of these illustrations for starts.
>> interaction2wt (two-way tables) is designed to be used with aov() for
>> testing.
>> interaction2wt shows all main effects and all two-way interactions for
>> many factors.
>>
>>
>>
>> test <-
>> structure(list(item = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A", "B"), class =
>> "factor"), day = c(0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
>> 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
>> 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
>> 300L, 400L, 500L), set = c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 3L, 3L, 3L, 3L, 3L, 3L), value = c(1.08163365169503,
>> 2.61998412608805, 3.07820466606394, 4.44993419381934, 5.29163171545805,
>> 6.29155990999293, -0.123163011367676, 2.07767236834003,
>> 2.32537052874901, 3.09372794501084, 6.65273721166635, 5.92304962329131,
>> 1.50504697705548, 2.66253728086866, 2.63420157418685, 2.78195098580416,
>> 6.47578642973288, 5.89587443775143, 0.848864231485078,
>> 1.27549677119713, 2.19573089053609, 2.45659926134292, 5.15424403414103,
>> 5.4813151140983, 1.25731482647214, 2.09662105167973, 1.75954023316977,
>> 4.81624002288939, 4.65029189325307, 6.39946904227214,
>> 0.944996929887344, 1.74667265331284, 2.42956264345558,
>> 5.17852980415141, 3.5453435965834, 6.9011238437191)), .Names =
>> c("item", "day", "set", "value"), row.names = c(NA, -36L), class =
>> "data.frame")
>>
>>
>>
>> library(HH)
>>
>> test$set <- factor(test$set)
>> test$day <- factor(test$day)
>> test$item <- factor(test$item)
>>
>> interaction2wt(value ~ item * day * set, data=test)
>>
>> test$item.day <- interaction(test$item, test$day)
>> position(test$item.day) <- outer(c(-10,10),
>> as.numeric(levels(test$day)), `+`)
>>
>> xyplot(value ~ as.position(item.day) | set, groups=item,
>>         data=test, horizontal=FALSE, pch=c(17,16),
>>         xlab="day",
>>         scales=list(
>>           x=list(
>>             alternating=1,
>>             at=levels(test$day), ## placement of tick labels and marks
>>             tck=1)),
>>         key=list(
>>           text=list(c("A","B"), col=c("blue","red")),
>>           points=list(pch=c(17, 16), col=c("blue","red")),
>>        space="top", columns=2, border=TRUE),
>>        layout=c(3,1))
>>
>>
>> ## see also the examples in
>> demo(package="HH", bwplot.examples)
>>
>> On Fri, Feb 6, 2015 at 6:09 AM, PIKAL Petr <petr.pikal at precheza.cz>
>> wrote:
>> > Dear all
>> >
>> > I would like to ask for your opinion about possible graphical
>> representation of such data.
>> >
>> >> dput(test)
>> > structure(list(item = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A", "B"), class
>> =
>> > "factor"), day = c(0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
>> > 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
>> > 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L, 200L,
>> > 300L, 400L, 500L), set = c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 2L,
>> > 2L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L), value = c(1.08163365169503,
>> > 2.61998412608805, 3.07820466606394, 4.44993419381934,
>> > 5.29163171545805, 6.29155990999293, -0.123163011367676,
>> > 2.07767236834003, 2.32537052874901, 3.09372794501084,
>> > 6.65273721166635, 5.92304962329131, 1.50504697705548,
>> > 2.66253728086866, 2.63420157418685, 2.78195098580416,
>> > 6.47578642973288, 5.89587443775143, 0.848864231485078,
>> > 1.27549677119713, 2.19573089053609, 2.45659926134292,
>> > 5.15424403414103, 5.4813151140983, 1.25731482647214,
>> 2.09662105167973,
>> > 1.75954023316977, 4.81624002288939, 4.65029189325307,
>> > 6.39946904227214, 0.944996929887344, 1.74667265331284,
>> > 2.42956264345558, 5.17852980415141, 3.5453435965834,
>> > 6.9011238437191)), .Names = c("item", "day", "set", "value"),
>> > row.names = c(NA, -36L), class = "data.frame")
>> >>
>> >
>> > One option I came with is
>> >
>> > library(ggplot2)
>> > p<-ggplot(test, aes(x=day, y=value, colour=item))
>> > p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))
>> >
>> > but -
>> > I have more items (around 5-10), and I want to show if the difference
>> between items is or is not significant. The actual development of value
>> with day is usually not linear nor growing steadily and actually I
>> cannot usually evaluate some analytical equation for my data to compare
>> equation parameters.
>> >
>> > I thought about boxplots, but there is not many repetitions and
>> actually 5+ boxplots can be quite messy.
>> >
>> > I can plot only mean for each set and item but in that case I lose
>> information if the difference is or is not significant.
>> >
>> > I appreciate any suggestion.
>> >
>> > Best regards
>> > Petr
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > ________________________________
>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>> jsou ur?eny pouze jeho adres?t?m.
>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>> kopie vyma?te ze sv?ho syst?mu.
>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>> >
>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
>> ze strany p??jemce s dodatkem ?i odchylkou.
>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>> zn?m?.
>> >
>> > This e-mail and any documents attached to it may be confidential and
>> are intended only for its intended recipients.
>> > If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> > If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any
>> manner.
>> > The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>> >
>> > In case that this e-mail forms part of business dealings:
>> > - the sender reserves the right to end negotiations about entering
>> into a contract in any time, for any reason, and without stating any
>> reasoning.
>> > - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer)
>> excludes any acceptance of the offer on the part of the recipient
>> containing any amendment or variation.
>> > - the sender insists on that the respective contract is concluded
>> only upon an express mutual agreement on all its aspects.
>> > - the sender of this e-mail informs that he/she is not authorized to
>> enter into any contracts on behalf of the company except for cases in
>> which he/she is expressly authorized to do so in writing, and such
>> authorization or power of attorney is submitted to the recipient or the
>> person represented by the recipient, or the existence of such
>> authorization is known to the recipient of the person represented by
>> the recipient.
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From Jill.Goldschneider at gridpoint.com  Wed Feb 11 22:30:03 2015
From: Jill.Goldschneider at gridpoint.com (Goldschneider, Jill)
Date: Wed, 11 Feb 2015 16:30:03 -0500
Subject: [R] piecewise regression and lm() question
Message-ID: <39F67496ED54784DB5C8BC6BE9F86F1511EBE2409B@corp-it-exch02.gridpoint.com>

I was playing with some examples of piecewise regression using lm() and have come across a behavior I'm uncertain about.
Below is simple 3-segment dataset.  I compare predicted output of a model created by one call to lm() to that of 3 models created by 3 calls to lm().
In case A and B, the results are the same.  However, in case C the results differ for the middle segment.
Is the output of lm() for case C to be expected or not and if so, why?
Thank you,
Jill

set.seed(133)
y <- c(21:30, rep(15,10), 10:1) + runif(30, -2, 2)
x <- 1:30

# Case A: 3 segments, each fit with a constant value
plot(x, y)
# 3 different lm fits
p.c3 <- c(predict(lm(y[1:10]~1)), predict(lm(y[11:20]~1)), predict(lm(y[21:30]~1)))
lines(x, p.c3, col="red")
# piecewise via lm
p.lm1 <- predict(lm(y ~ I(x<=10) + I(x>10 & x<=20) + I(x>20)))
lines(x, p.lm1, col="blue")
max(abs(p.c3-p.lm1))

# Case B: 3 segments, each fit with a line
plot(x, y)
# 3 different lm fits
p.c3 <- c(predict(lm(y[1:10]~x[1:10])), predict(lm(y[11:20]~x[11:20])), predict(lm(y[21:30]~x[21:30])))
lines(x, p.c3, col="red")
# piecewise via lm
p.lm1 <- predict(lm(y ~ (x<=10)*x + (x>10 & x<=20)*x + (x>20)*x))
lines(x, p.lm1, col="blue")
max(abs(p.c3-p.lm1))

# Cast C: 3 segments - the middle fit with a constant value, the outer by a line
plot(x, y)
# 3 different lm fits
p.c3 <- c(predict(lm(y[1:10]~x[1:10])), predict(lm(y[11:20]~1)), predict(lm(y[21:30]~x[21:30])))
lines(x, p.c3, col="red")
# piecewise via lm
p.lm1 <- predict(lm(y ~ (x<=10)*x + I(x>10 & x<=20) + (x>20)*x))
lines(x, p.lm1, col="blue")
max(abs(p.c3-p.lm1))
## the single call to lm does not have a constant value fit to the middle section
plot(x, p.c3-p.lm1 )



The information contained in this transmission may contain confidential information.  If the reader of this message is not the intended recipient, you are hereby notified that any review, dissemination, distribution or duplication of this communication is strictly prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.


From js.huang at protective.com  Wed Feb 11 22:32:35 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 11 Feb 2015 13:32:35 -0800 (PST)
Subject: [R] Nonlinear integer programming question
In-Reply-To: <DM2PR07MB97659DD4008F85A31901702D2250@DM2PR07MB976.namprd07.prod.outlook.com>
References: <DM2PR07MB97659DD4008F85A31901702D2250@DM2PR07MB976.namprd07.prod.outlook.com>
Message-ID: <1423690355688-4703128.post@n4.nabble.com>

Hi Rebecca,

  It will be very helpful if you can provide a set of specific functions
g(x), h(x) and m(x).



--
View this message in context: http://r.789695.n4.nabble.com/Nonlinear-integer-programming-question-tp4703122p4703128.html
Sent from the R help mailing list archive at Nabble.com.


From bbolker at gmail.com  Wed Feb 11 23:05:43 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Feb 2015 22:05:43 +0000
Subject: [R] AR1 covariance structure for lme object and R/SAS
	differences in model output
References: <1423670235304-4703103.post@n4.nabble.com>
Message-ID: <loom.20150211T223615-986@post.gmane.org>

anord <andreas.nord <at> biol.lu.se> writes:

> 


  [snip snip]

> We are working on a data set in which we have measured repeatedly a
> physiological response variable (y) 
> every 20 min for 12 h (time variable; 'x') in subjects ('id') beloning to
> one of five groups ('group'; 'A' to 'E'). Data are located at:
> https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0
> 
> We are interested to model if the response in y differences 
> with time (i.e.
> 'x') for the two groups. Thus:
> require(nlme)
> m1<-lme(y~group*x+group*I(x^2),random=~x|id,
>   data=data.df,na.action=na.omit)
> 
> But because data are collected repeatedly over 
> short time intervals for each
> subject, it seemed prudent to consider an autoregressive covariance
> structure. Thus:
> m2<-update(m1,~.,corr=corCAR1(form=~x|id))
> 
> AIC values indicate the latter (i.e. m2) as more appropriate:
>   anova(m1,m2)
> #   Model df      AIC      BIC       logLik        Test  L.Ratio     
> p-value
> #m1     1 19 2155.996 2260.767 -1058.9981                        
> #m2     2 20 2021.944 2132.229  -990.9718 1 vs 2 136.0525  <.0001
> 
> Fixed effects and test statistics differ between models.
>  A look at marginal
> ANOVA tables suggest inference might differ somewhat between models:
> 
> anova.lme(m1,type="m")
> #              numDF denDF  F-value p-value
> #(Intercept)      1  1789 63384.80  <.0001
> #group             4    45      1.29  0.2893
> #x                   1  1789     0.05  0.8226
> #I(x^2)            1  1789     4.02  0.0451
> #group:x          4  1789     2.61  0.0341
> #group:I(x^2)   4  1789     4.37  0.0016
> 
> anova.lme(m2,type="m")
> #             numDF denDF  F-value p-value
> #(Intercept)      1  1789 59395.79  <.0001
> #group             4    45      1.33  0.2725
> #x                   1  1789     0.04  0.8379
> #I(x^2)            1  1789     2.28  0.1312
> #group:x          4  1789     2.09  0.0802
> #group:I(x^2)   4  1789     2.81  0.0244
> 
> Now, this is all well. But: my colleagues have been running 
> the same data
> set using PROC MIXED in SAS and come up with 
> substantially different results
> when comparing SAS default covariance structure (variance components) and
> AR1. Specifically, there is virtually no change 
> in either test statistics or
> fitted values when using AR1 instead of Variance Components in SAS, which
> fits the observation that AIC values (in SAS) indicate both covariance
> structures fit data equally well. 
> 
> This is not very satisfactory to me, and I would be 
> interesting to know what
> is happening here. Realizing
> this might not be the correct forum for this question, I would like to ask
> you all if anyone would have any
> input as to what is going on here, e.g. am I setting up my model
> erroneously, etc.? 
> 
> N.b. I have no desire to replicate SAS results, but I would most certainly
> be interested to know what could possibly explain  
> such a large discrepancy
> between the two platforms. Any suggestions greatly welcomed.
> 
> (Data are located at:
> https://www.dropbox.com/s/hf455aev3teb5e0/data.csv?dl=0)

  Could you repost this on r-sig-mixed-models at r-project.org ?

It would be useful to see some of the comparisons (fixed effects,
RE variance-covariance, correlation parameter) between SAS and
R; are they actually fitting the same model?  (e.g., does SAS
allow for covariance between the slope and intercept random effects?)
Maybe they're getting the same estimates but computing df/p-values
in different ways?

  I thought I would try this with orthogonal polynomials in case
some of the fits were unstable ...

data.df <- read.csv2("ar1_data.csv")
library("nlme")
m1 <- lme(y~group*x+group*I(x^2),random=~x|id,
          data=data.df,na.action=na.omit,method="ML")
## use method="ML" so we can compare orthog. and non-orthog. polynomials
m1B <- update(m1,.~group*poly(x,2))
m2 <- update(m1,corr=corCAR1(form=~x|id))
m2B <- update(m1B,corr=corCAR1(form=~x|id))
AIC(m1,m1B,m2,m2B)


From murdoch.duncan at gmail.com  Wed Feb 11 23:13:14 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 11 Feb 2015 17:13:14 -0500
Subject: [R] piecewise regression and lm() question
In-Reply-To: <39F67496ED54784DB5C8BC6BE9F86F1511EBE2409B@corp-it-exch02.gridpoint.com>
References: <39F67496ED54784DB5C8BC6BE9F86F1511EBE2409B@corp-it-exch02.gridpoint.com>
Message-ID: <54DBD3FA.2030902@gmail.com>

On 11/02/2015 4:30 PM, Goldschneider, Jill wrote:
> I was playing with some examples of piecewise regression using lm() and have come across a behavior I'm uncertain about.
> Below is simple 3-segment dataset.  I compare predicted output of a model created by one call to lm() to that of 3 models created by 3 calls to lm().
> In case A and B, the results are the same.  However, in case C the results differ for the middle segment.
> Is the output of lm() for case C to be expected or not and if so, why?

Take a look at the fit value, and you'll see what happened:

> lm(y ~ (x<=10)*x + I(x>10 & x<=20) + (x>20)*x)

Call:
lm(formula = y ~ (x <= 10) * x + I(x > 10 & x <= 20) + (x > 20) *
    x)

Coefficients:
            (Intercept)              x <= 10TRUE
x  I(x > 10 & x <= 20)TRUE
                35.0741                 -15.0733
-0.1644                 -17.7344
             x > 20TRUE            x <= 10TRUE:x             x:x > 20TRUE
                     NA                   1.2397                  -0.9658

The * in a formula means "main effect plus interaction", not
multiplication.  W	hat you want is


lm(y ~ I((x<=10)*x) + I(x>10 & x<=20) + I((x>20)*x))

This doesn't give exactly the same results as the segmented regression,
because it uses the same intercept in all three segments; you might want
to add I(x <= 10) as well if you don't want that.

Duncan Murdoch

> Thank you,
> Jill
> 
> set.seed(133)
> y <- c(21:30, rep(15,10), 10:1) + runif(30, -2, 2)
> x <- 1:30
> 
> # Case A: 3 segments, each fit with a constant value
> plot(x, y)
> # 3 different lm fits
> p.c3 <- c(predict(lm(y[1:10]~1)), predict(lm(y[11:20]~1)), predict(lm(y[21:30]~1)))
> lines(x, p.c3, col="red")
> # piecewise via lm
> p.lm1 <- predict(lm(y ~ I(x<=10) + I(x>10 & x<=20) + I(x>20)))
> lines(x, p.lm1, col="blue")
> max(abs(p.c3-p.lm1))
> 
> # Case B: 3 segments, each fit with a line
> plot(x, y)
> # 3 different lm fits
> p.c3 <- c(predict(lm(y[1:10]~x[1:10])), predict(lm(y[11:20]~x[11:20])), predict(lm(y[21:30]~x[21:30])))
> lines(x, p.c3, col="red")
> # piecewise via lm
> p.lm1 <- predict(lm(y ~ (x<=10)*x + (x>10 & x<=20)*x + (x>20)*x))
> lines(x, p.lm1, col="blue")
> max(abs(p.c3-p.lm1))
> 
> # Cast C: 3 segments - the middle fit with a constant value, the outer by a line
> plot(x, y)
> # 3 different lm fits
> p.c3 <- c(predict(lm(y[1:10]~x[1:10])), predict(lm(y[11:20]~1)), predict(lm(y[21:30]~x[21:30])))
> lines(x, p.c3, col="red")
> # piecewise via lm
> p.lm1 <- predict(lm(y ~ (x<=10)*x + I(x>10 & x<=20) + (x>20)*x))
> lines(x, p.lm1, col="blue")
> max(abs(p.c3-p.lm1))
> ## the single call to lm does not have a constant value fit to the middle section
> plot(x, p.c3-p.lm1 )
> 
> 
> 
> The information contained in this transmission may contain confidential information.  If the reader of this message is not the intended recipient, you are hereby notified that any review, dissemination, distribution or duplication of this communication is strictly prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mckellercran at gmail.com  Wed Feb 11 23:49:45 2015
From: mckellercran at gmail.com (Matthew Keller)
Date: Wed, 11 Feb 2015 15:49:45 -0700
Subject: [R] simple question - mean of a row of a data.frame
Message-ID: <CAB7vCMQkLuA138tvJNbFKrx=k8-rK7wVyGXoGNxwazHjpTB6Yg@mail.gmail.com>

Hi all,

Simple question I should know: I'm unclear on the logic of why the sum of a
row of a data.frame returns a valid sum but the mean of a row of a
data.frame returns NA:

sum(rock[2,])
[1] 10901.05

mean(rock[2,],trim=0)
[1] NA
Warning message:
In mean.default(rock[2, ], trim = 0) :
  argument is not numeric or logical: returning NA

I get that rock[2,] is itself a data.frame of mode list, but why the
inconsistency between functions? How can you figure this out from, e.g.,
?mean
?sum

Thanks in advance,

Matt


-- 
Matthew C Keller
Asst. Professor of Psychology
University of Colorado at Boulder
www.matthewckeller.com

	[[alternative HTML version deleted]]


From kehld at ktk.pte.hu  Thu Feb 12 00:21:42 2015
From: kehld at ktk.pte.hu (=?iso-8859-1?Q?Kehl_D=E1niel?=)
Date: Wed, 11 Feb 2015 23:21:42 +0000
Subject: [R] simple question - mean of a row of a data.frame
In-Reply-To: <CAB7vCMQkLuA138tvJNbFKrx=k8-rK7wVyGXoGNxwazHjpTB6Yg@mail.gmail.com>
References: <CAB7vCMQkLuA138tvJNbFKrx=k8-rK7wVyGXoGNxwazHjpTB6Yg@mail.gmail.com>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D143BC67C@EMAIL.ktkdom.pte.hu>

Hi,

rock[2,] is a data frame and you should not use sum() on a data frame, first google hit for the error message gives

http://stackoverflow.com/questions/19697498/r-beginner-argument-is-not-numeric-or-logical-returning-na

Otherwise I think you should use

?rowSums and ?rowMeans if you have numeric data frames.

HTH,
daniel
________________________________________
Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Matthew Keller [mckellercran at gmail.com]
K?ldve: 2015. febru?r 11. 23:49
To: r help
T?rgy: [R] simple question - mean of a row of a data.frame

Hi all,

Simple question I should know: I'm unclear on the logic of why the sum of a
row of a data.frame returns a valid sum but the mean of a row of a
data.frame returns NA:

sum(rock[2,])
[1] 10901.05

mean(rock[2,],trim=0)
[1] NA
Warning message:
In mean.default(rock[2, ], trim = 0) :
  argument is not numeric or logical: returning NA

I get that rock[2,] is itself a data.frame of mode list, but why the
inconsistency between functions? How can you figure this out from, e.g.,
?mean
?sum

Thanks in advance,

Matt


--
Matthew C Keller
Asst. Professor of Psychology
University of Colorado at Boulder
www.matthewckeller.com

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From brennan.obanion at gmail.com  Thu Feb 12 02:42:58 2015
From: brennan.obanion at gmail.com (Brennan O'Banion)
Date: Wed, 11 Feb 2015 20:42:58 -0500
Subject: [R] Subsetting data with svyglm
Message-ID: <CAMXc+9YgJ0oJYdZ83Fh0teRwanhbyHyV+n2R2=BRRM9VUQSUow@mail.gmail.com>

I am aware that it is possible to specify a subset with a single
logical operator when constructing a model, such as:
svyglm(formula, design=data, subset=variable=="value").

What I can't figure out is how to specify a subset with two or more
logical operators:
svyglm(formula, design=data, subset=variable=="value a"|"value b").

Is it possible to specify a subset in this way using *glm without
having to, in my case, subset the original data, create a survey
design, and then fit a model?


From marcelolaia at gmail.com  Thu Feb 12 03:57:46 2015
From: marcelolaia at gmail.com (Marcelo Laia)
Date: Thu, 12 Feb 2015 00:57:46 -0200
Subject: [R] grofit issues with replicates  - probit or logit or glmm
Message-ID: <20150212025746.GA10943@marcelo>

Hello

I tried use grofit package in our data set. We provide a subset of our
data with X iso, and 4 doses, and insect died was count each day for
long 5 days. We started with Y insects per dishes. When one is dead, it
was counted and removed. Died insect is cumulative in the next days.
i.e. day 1 died 1. day 2 no died, so, day 2 is assigned 1 died (from day
1).

Here is the script:

library(lattice)
library(grofit)
library(repmis)

url.csv <- https://dl.dropboxusercontent.com/u/34009642/cepajabo07_wide_acumulado.csv

data02 <- read.table(url.csv, header=TRUE, sep="\t", dec=",")

head(data02)

timepoints <- 1:5 # 5 days
time <- t(matrix(rep(timepoints, 120), c(5, 120))) # 5 days and 120 experiments
                                                   # (6 iso * 4 doses
                                                   # * 5 rep)
time

TestRun1$drFit
TestRun2$drFit

colData <- c("black", "cyan", "magenta", "blue")

plot(TestRun1$gcFit, opt = "s", colData = colData, colSpline = 1, 
     pch = 1:4, cex = 1)

plot(TestRun2$gcFit, opt = "s", colData = colData, colSpline = 1, 
     pch = 1:4, cex = 1)

plot(TestRun1$drFit$drFittedSplines[[1]], colData = colData, 
     pch = 1:4, cex = 1)

plot(TestRun2$drFit$drFittedSplines[[1]], colData = colData, 
     pch = 1:4, cex = 1)

The problem: grofit didn't deal with replicates and do a curve for each
ones.

Is it a way to get response curve with the replicates?

We are interested in LD50, and dose response curve, and graphs.

Any suggestion is very welcome!

Thank you!

-- 
Marcelo


From jdnewmil at dcn.davis.CA.us  Thu Feb 12 05:49:39 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 11 Feb 2015 23:49:39 -0500
Subject: [R] Subsetting data with svyglm
In-Reply-To: <CAMXc+9YgJ0oJYdZ83Fh0teRwanhbyHyV+n2R2=BRRM9VUQSUow@mail.gmail.com>
References: <CAMXc+9YgJ0oJYdZ83Fh0teRwanhbyHyV+n2R2=BRRM9VUQSUow@mail.gmail.com>
Message-ID: <C345CF9D-2847-4557-A78C-931311F98FD1@dcn.davis.CA.us>

This seems like a fundamental  misunderstanding on your part of how operators, and in particular logical expressions, work in computer languages. Consider some examples:

1+2 has a numeric answer because 1 and 2 are both numeric.
1+"a" has at the very least not a numeric answer because the values on either side of the "+" sign are not both numeric.
TRUE | FALSE  has a logical type of answer because both sides of the logical "or" operator are logical.
However, you are expressing something like
TRUE | "a string" which might mean something but that something generally is not a logical type of answer.

Try
variable=="value a" | variable=="value b"
or
variable %in% c( "value a", "value b" )

You would probably find that the Introduction to R document that comes with R has some enlightening examples in it. You might also find Pat Burns' "The R Inferno" entertaining as well (search for it in your favorite search engine).
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 11, 2015 8:42:58 PM EST, Brennan O'Banion <brennan.obanion at gmail.com> wrote:
>I am aware that it is possible to specify a subset with a single
>logical operator when constructing a model, such as:
>svyglm(formula, design=data, subset=variable=="value").
>
>What I can't figure out is how to specify a subset with two or more
>logical operators:
>svyglm(formula, design=data, subset=variable=="value a"|"value b").
>
>Is it possible to specify a subset in this way using *glm without
>having to, in my case, subset the original data, create a survey
>design, and then fit a model?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Thu Feb 12 06:38:16 2015
From: ajdamico at gmail.com (Anthony Damico)
Date: Thu, 12 Feb 2015 00:38:16 -0500
Subject: [R] Subsetting data with svyglm
In-Reply-To: <C345CF9D-2847-4557-A78C-931311F98FD1@dcn.davis.CA.us>
References: <CAMXc+9YgJ0oJYdZ83Fh0teRwanhbyHyV+n2R2=BRRM9VUQSUow@mail.gmail.com>
	<C345CF9D-2847-4557-A78C-931311F98FD1@dcn.davis.CA.us>
Message-ID: <CAOwvMDyy42cyKFnuVgxZUMVSLvfyYAW8JAsywHqF3cwweSZ9rA@mail.gmail.com>

hi brennan, survey design objects can be subsetted with the same subset()
syntax as data.frame objects, so following jeff's advice maybe you want

svyglm( formula , design = subset( surveydesign , variable %in% c( 'value
a' , 'value b' ) ) )

for some examples of how to construct a survey design with public use data,
see http://github.com/ajdamico/usgsd


On Wed, Feb 11, 2015 at 11:49 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> This seems like a fundamental  misunderstanding on your part of how
> operators, and in particular logical expressions, work in computer
> languages. Consider some examples:
>
> 1+2 has a numeric answer because 1 and 2 are both numeric.
> 1+"a" has at the very least not a numeric answer because the values on
> either side of the "+" sign are not both numeric.
> TRUE | FALSE  has a logical type of answer because both sides of the
> logical "or" operator are logical.
> However, you are expressing something like
> TRUE | "a string" which might mean something but that something generally
> is not a logical type of answer.
>
> Try
> variable=="value a" | variable=="value b"
> or
> variable %in% c( "value a", "value b" )
>
> You would probably find that the Introduction to R document that comes
> with R has some enlightening examples in it. You might also find Pat Burns'
> "The R Inferno" entertaining as well (search for it in your favorite search
> engine).
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On February 11, 2015 8:42:58 PM EST, Brennan O'Banion <
> brennan.obanion at gmail.com> wrote:
> >I am aware that it is possible to specify a subset with a single
> >logical operator when constructing a model, such as:
> >svyglm(formula, design=data, subset=variable=="value").
> >
> >What I can't figure out is how to specify a subset with two or more
> >logical operators:
> >svyglm(formula, design=data, subset=variable=="value a"|"value b").
> >
> >Is it possible to specify a subset in this way using *glm without
> >having to, in my case, subset the original data, create a survey
> >design, and then fit a model?
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sven.templer at gmail.com  Thu Feb 12 09:10:21 2015
From: sven.templer at gmail.com (Sven E. Templer)
Date: Thu, 12 Feb 2015 09:10:21 +0100
Subject: [R] Extract data from Array to Table
In-Reply-To: <CALJKBv_0rJa96jePxbwbbdk4zp-tu4Z5JZHrp9QeCnJWc-N_xg@mail.gmail.com>
References: <CALJKBv_0rJa96jePxbwbbdk4zp-tu4Z5JZHrp9QeCnJWc-N_xg@mail.gmail.com>
Message-ID: <CAHuTOvo0bdp1Yep_qdsEOkmQ-RYoNFF57V-OvqzGc9BhhhvLdA@mail.gmail.com>

Make use of the plyr and reshape2 package (both on CRAN):

library(plyr)
d<-adply(ArrayDiseaseCor, 1:2)
# adply calls function identity by default
d<-melt(d)
d<-subset(d,value>.5)
head(d)

You will have to rename columns, or adjust arguments in melt/adply.
Note: use set.seed before sampling for reproducible code!

Best, S.

On 11 February 2015 at 17:11, Karim Mezhoud <kmezhoud at gmail.com> wrote:
> Dear All,
> I am facing the task to extract data from array to table. here an example
> of array.
>
> ##Get A list of Matrices with unequal rows
>
> Disease <- NULL
> Diseases <- NULL
> ListMatByGene <- NULL
> for(i in 1:3){
>
> Disease[[i]] <-matrix(sample(-30:30,25+(5*
> i)),5+i)
> rownames(Disease[[i]]) <- paste0("Sample",1:(5+i))
> colnames(Disease[[i]]) <- paste0("Gene",1:5)
>
> D <- paste0("Disease",i)
> Diseases[[D]] <- Disease[[i]]
> }
>
>
> ## get the same Column from all matrices
> getColumn <- function(x, colNum, len = nrow(x)){
>     y <- x[,colNum]
>     length(y) <- len
>     y
> }
>
> ## get Matrices by the same columns of the list of matrices
> getMatrices <- function(colNums, dataList = x){
>     # the number of rows required
>     n <- max(sapply(dataList, nrow))
>     lapply(colNums, function(x, dat, n) { # iterate along requested columns
>         do.call(cbind, lapply(dat, getColumn,x, len=n)) # iterate along
> input data list
>     }, dataList, n)
> }
>
> ## Rotate the list of matrices by 90?
> G <- paste0("Gene",1:5)
> ListMatByGene[G] <- getMatrices(c(1:ncol(Diseases[[1]])),dataList=Diseases)
>
> ## get Disease correlation by gene
> DiseaseCorrelation <- lapply(ListMatByGene,function(x) cor(x,use="na",
> method="spearman"))
>
> ##convert the list of Matrices to array
> ArrayDiseaseCor <- array(unlist(DiseaseCorrelation), dim =
> c(nrow(DiseaseCorrelation[[1]]), ncol(DiseaseCorrelation[[1]]),
> length(DiseaseCorrelation)))
> dimnames(ArrayDiseaseCor) <- list(names(Diseases), names(Diseases),
> colnames(Diseases[[1]]))
>
> ## Select only correlation bigger than 0.5 from the array
> FilterDiseaseCor <- apply(ArrayDiseaseCor,MARGIN=c(1,2) ,function(x)
> x[abs(x)>0.5])
>
> ## Final result
> FilterDiseaseCor
>
>          Disease1   Disease2  Disease3
> Disease1 Numeric,5  Numeric,2 -0.9428571
> Disease2 Numeric,2  Numeric,5 Numeric,2
> Disease3 -0.9428571 Numeric,2 Numeric,5
>
>
> Question is:
> How can get a table as:
>
> D1              D2               Cor       Gene
> Disease1    Disease2      -0.94    Gene2
> Disease1    Disease2       0.78    Gene4
> Disease3    Disease2       0.5      Gene5
> ...
>
> and
>                  Disease1   Disease2      Disease3
> Disease1        5                1                0
> Disease2        1                 5                3
> Disease3        0                  3               5
>
> Or in general, How can I extract data from Array to Table?
>
> Thanks
> Karim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sven.templer at gmail.com  Thu Feb 12 09:11:23 2015
From: sven.templer at gmail.com (Sven E. Templer)
Date: Thu, 12 Feb 2015 09:11:23 +0100
Subject: [R] Extract data from Array to Table
In-Reply-To: <CAHuTOvo0bdp1Yep_qdsEOkmQ-RYoNFF57V-OvqzGc9BhhhvLdA@mail.gmail.com>
References: <CALJKBv_0rJa96jePxbwbbdk4zp-tu4Z5JZHrp9QeCnJWc-N_xg@mail.gmail.com>
	<CAHuTOvo0bdp1Yep_qdsEOkmQ-RYoNFF57V-OvqzGc9BhhhvLdA@mail.gmail.com>
Message-ID: <CAHuTOvqW=_3PNbQ=0CWxm_C92btt6uaGBVM0xwsH7zhTETystg@mail.gmail.com>

see inline

On 12 February 2015 at 09:10, Sven E. Templer <sven.templer at gmail.com> wrote:
> Make use of the plyr and reshape2 package (both on CRAN):
>

I forgot:

library(reshape2)

> library(plyr)
> d<-adply(ArrayDiseaseCor, 1:2)
> # adply calls function identity by default
> d<-melt(d)
> d<-subset(d,value>.5)
> head(d)
>
> You will have to rename columns, or adjust arguments in melt/adply.
> Note: use set.seed before sampling for reproducible code!
>
> Best, S.
>
> On 11 February 2015 at 17:11, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>> Dear All,
>> I am facing the task to extract data from array to table. here an example
>> of array.
>>
>> ##Get A list of Matrices with unequal rows
>>
>> Disease <- NULL
>> Diseases <- NULL
>> ListMatByGene <- NULL
>> for(i in 1:3){
>>
>> Disease[[i]] <-matrix(sample(-30:30,25+(5*
>> i)),5+i)
>> rownames(Disease[[i]]) <- paste0("Sample",1:(5+i))
>> colnames(Disease[[i]]) <- paste0("Gene",1:5)
>>
>> D <- paste0("Disease",i)
>> Diseases[[D]] <- Disease[[i]]
>> }
>>
>>
>> ## get the same Column from all matrices
>> getColumn <- function(x, colNum, len = nrow(x)){
>>     y <- x[,colNum]
>>     length(y) <- len
>>     y
>> }
>>
>> ## get Matrices by the same columns of the list of matrices
>> getMatrices <- function(colNums, dataList = x){
>>     # the number of rows required
>>     n <- max(sapply(dataList, nrow))
>>     lapply(colNums, function(x, dat, n) { # iterate along requested columns
>>         do.call(cbind, lapply(dat, getColumn,x, len=n)) # iterate along
>> input data list
>>     }, dataList, n)
>> }
>>
>> ## Rotate the list of matrices by 90?
>> G <- paste0("Gene",1:5)
>> ListMatByGene[G] <- getMatrices(c(1:ncol(Diseases[[1]])),dataList=Diseases)
>>
>> ## get Disease correlation by gene
>> DiseaseCorrelation <- lapply(ListMatByGene,function(x) cor(x,use="na",
>> method="spearman"))
>>
>> ##convert the list of Matrices to array
>> ArrayDiseaseCor <- array(unlist(DiseaseCorrelation), dim =
>> c(nrow(DiseaseCorrelation[[1]]), ncol(DiseaseCorrelation[[1]]),
>> length(DiseaseCorrelation)))
>> dimnames(ArrayDiseaseCor) <- list(names(Diseases), names(Diseases),
>> colnames(Diseases[[1]]))
>>
>> ## Select only correlation bigger than 0.5 from the array
>> FilterDiseaseCor <- apply(ArrayDiseaseCor,MARGIN=c(1,2) ,function(x)
>> x[abs(x)>0.5])
>>
>> ## Final result
>> FilterDiseaseCor
>>
>>          Disease1   Disease2  Disease3
>> Disease1 Numeric,5  Numeric,2 -0.9428571
>> Disease2 Numeric,2  Numeric,5 Numeric,2
>> Disease3 -0.9428571 Numeric,2 Numeric,5
>>
>>
>> Question is:
>> How can get a table as:
>>
>> D1              D2               Cor       Gene
>> Disease1    Disease2      -0.94    Gene2
>> Disease1    Disease2       0.78    Gene4
>> Disease3    Disease2       0.5      Gene5
>> ...
>>
>> and
>>                  Disease1   Disease2      Disease3
>> Disease1        5                1                0
>> Disease2        1                 5                3
>> Disease3        0                  3               5
>>
>> Or in general, How can I extract data from Array to Table?
>>
>> Thanks
>> Karim
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From samarvir1996 at gmail.com  Thu Feb 12 05:57:55 2015
From: samarvir1996 at gmail.com (samarvir singh)
Date: Thu, 12 Feb 2015 10:27:55 +0530
Subject: [R] How to subset data, by sorting names alphabetically.
Message-ID: <CAOpgo6hun+2OnaOMO2JnNRXhE820ftkaNyCTWgWX1gMPrUOatA@mail.gmail.com>

hello,

I am cleaning some large data with 4 million observation and 7 variable.
Of the 7 variables , 1 is name/string

I want to subset data, which have same name

Example-

 Name var1 var2 var3 var4 var5 var6
aa        -       -       -         -     -        -
ab
bd
ac
ad
af
ba
bd
aa
av

i want to sort the data something like this

aa
aa
all aa in a same subset

and all ab in same subset

every column with same name in a subset



thanks in advance.
I am new to R community.
appreciate your help
- Samarvir

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Feb 12 11:14:09 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 12 Feb 2015 21:14:09 +1100
Subject: [R] How to subset data, by sorting names alphabetically.
In-Reply-To: <CAOpgo6hun+2OnaOMO2JnNRXhE820ftkaNyCTWgWX1gMPrUOatA@mail.gmail.com>
References: <CAOpgo6hun+2OnaOMO2JnNRXhE820ftkaNyCTWgWX1gMPrUOatA@mail.gmail.com>
Message-ID: <CA+8X3fXHG2cxtYnTWUA1bGB6Rady5in+zD4-R6GXuC39bL6oTg@mail.gmail.com>

Hi Samarvir,
Assuming that you want to generate a separate data frame for each
value of "Name",

# name of initial data frame is ssdf
for(nameval in unique(ssdf$Name)) assign(nameval,ssdf[ssdf$Name==nameval,])

This will produce as many data frames as there are unique values of
ssdf$Name, each named by the values it contains.

Jim


On Thu, Feb 12, 2015 at 3:57 PM, samarvir singh <samarvir1996 at gmail.com> wrote:
> hello,
>
> I am cleaning some large data with 4 million observation and 7 variable.
> Of the 7 variables , 1 is name/string
>
> I want to subset data, which have same name
>
> Example-
>
>  Name var1 var2 var3 var4 var5 var6
> aa        -       -       -         -     -        -
> ab
> bd
> ac
> ad
> af
> ba
> bd
> aa
> av
>
> i want to sort the data something like this
>
> aa
> aa
> all aa in a same subset
>
> and all ab in same subset
>
> every column with same name in a subset
>
>
>
> thanks in advance.
> I am new to R community.
> appreciate your help
> - Samarvir
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marcelolaia at gmail.com  Thu Feb 12 11:27:46 2015
From: marcelolaia at gmail.com (Marcelo Laia)
Date: Thu, 12 Feb 2015 08:27:46 -0200
Subject: [R] [UPDATE] grofit issues with replicates - probit or logit or
 glmm
In-Reply-To: <20150212025746.GA10943@marcelo>
References: <20150212025746.GA10943@marcelo>
Message-ID: <20150212102746.GB1718@marcelo>

I done a mistake when I paste the script in the message. An update:

url.csv <-
https://dl.dropboxusercontent.com/u/34009642/cepajabo07_wide_acumulado.csv

data02 <- read.table(url.csv, header=TRUE, sep="\t", dec=",")

head(data02)

timepoints <- 1:5 # 5 days
time <- t(matrix(rep(timepoints, 120), c(5, 120))) 
                                    # 5 days and 120 experimentos
                                    # (6 iso * 4 doses
                                    # * 5 rep)
time

MyOpt1 <- grofit.control(smooth.gc = 0.5, parameter = 28, 
interactive = FALSE)

MyOpt2 <- grofit.control(smooth.gc = 0.5, parameter = 28, 
interactive = FALSE, log.x.dr = TRUE)

TestRun1 <- grofit(time, data02, TRUE, MyOpt1)
TestRun2 <- grofit(time, data02, TRUE, MyOpt2)

TestRun1$drFit
TestRun2$drFit

colData <- c("black", "cyan", "magenta", "blue")

plot(TestRun1$gcFit, opt = "s", colData = colData, colSpline = 1, 
pch = 1:4, cex = 1)

plot(TestRun2$gcFit, opt = "s", colData = colData, colSpline = 1, 
pch = 1:4, cex = 1)

plot(TestRun1$drFit$drFittedSplines[[1]], colData = colData, 
pch = 1:4, cex = 1)

plot(TestRun2$drFit$drFittedSplines[[1]], colData = colData, 
pch = 1:4, cex = 1)

Thank you very much!

Marcelo

On 12/02/15 at 12:57am, Marcelo Laia wrote:
> Hello
> 
> I tried use grofit package in our data set. We provide a subset of our
> data with X iso, and 4 doses, and insect died was count each day for
> long 5 days. We started with Y insects per dishes. When one is dead, it
> was counted and removed. Died insect is cumulative in the next days.
> i.e. day 1 died 1. day 2 no died, so, day 2 is assigned 1 died (from day
> 1).
> 
> Here is the script:
> 
> library(lattice)
> library(grofit)
> library(repmis)
> 
> url.csv <- https://dl.dropboxusercontent.com/u/34009642/cepajabo07_wide_acumulado.csv
> 
> data02 <- read.table(url.csv, header=TRUE, sep="\t", dec=",")
> 
> head(data02)
> 
> timepoints <- 1:5 # 5 days
> time <- t(matrix(rep(timepoints, 120), c(5, 120))) # 5 days and 120 experiments
>                                                    # (6 iso * 4 doses
>                                                    # * 5 rep)
> time
> 
> TestRun1$drFit
> TestRun2$drFit
> 
> colData <- c("black", "cyan", "magenta", "blue")
> 
> plot(TestRun1$gcFit, opt = "s", colData = colData, colSpline = 1, 
>      pch = 1:4, cex = 1)
> 
> plot(TestRun2$gcFit, opt = "s", colData = colData, colSpline = 1, 
>      pch = 1:4, cex = 1)
> 
> plot(TestRun1$drFit$drFittedSplines[[1]], colData = colData, 
>      pch = 1:4, cex = 1)
> 
> plot(TestRun2$drFit$drFittedSplines[[1]], colData = colData, 
>      pch = 1:4, cex = 1)
> 
> The problem: grofit didn't deal with replicates and do a curve for each
> ones.
> 
> Is it a way to get response curve with the replicates?
> 
> We are interested in LD50, and dose response curve, and graphs.
> 
> Any suggestion is very welcome!
> 
> Thank you!
> 
> -- 
> Marcelo
> 

--


From arnaud.gaboury at gmail.com  Thu Feb 12 12:15:35 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Thu, 12 Feb 2015 12:15:35 +0100
Subject: [R] apply two functions to column
Message-ID: <CAK1hC9uSUCsdHTHhNn3fkG4AsBZwSZpqFuivvSJo+Kdhqjd-xg@mail.gmail.com>

I am little lost between all the possibilities to apply a function to
a data.frame or data.table.

Here is mine:

structure(list(name = c("poisonivy", "poisonivy", "poisonivy",
"poisonivy", "poisonivy", "poisonivy", "poisonivy", "poisonivy",
"cruzecontrol", "agreenmamba", "agreenmamba", "vairis", "vairis",
"vairis", "vairis", "vairis", "vairis", "xaeth"), text = c("ok",
"need items ?", "i didn't submit pass codes for a long now",
"ok", "<@U03AEKYL4>: what app are you talking about ?", "some testing
with my irc client",
"ha ha sorry", "for me there is no such question", "Lol.",
"<@U03AEKWTL|agreenmamba> uploaded a file:
<https://enlightened.slack.com/files/agreenmamba/F03KGRF3W/screenshot_2015-02-09-14-31-15.png|regarding:
should I stay or should I go?>",
"<@U032FHV3S> <http://youtu.be/oGIFublvDes>", "ok, see you around",
"yeah, I had a procrastination rush so I started to decode a little",
"<http://ingress.com/intel|ingress.com/intel> when you submit passcodes",
"intel", "what is the cooldown time or how does it work...;",
"anybody knows how does \"Passcode circuitry too hot. Wait for cool
down to enter another passcode.\" works?",
"and people told that agent their geocities experience would never
amount to anything (the convo yesterday) "
), ts = c("1423594336.000138", "1423594311.000136", "1423594294.000135",
"1423594258.000133", "1423594244.000131", "1423497058.000127",
"1423497041.000126", "1423478555.000123", "1423494427.000125",
"1423492370.000124", "1423478364.000121", "1423594358.000139",
"1423594329.000137", "1423594264.000134", "1423594251.000132",
"1423592204.000130", "1423592174.000129", "1423150354.000112"
)), .Names = c("name", "text", "ts"), class = c("data.table",
"data.frame"), row.names = c(NA, -18L))

As you can see, it is of class data.frame and data.table.

I need to work on last column "t"s. These are characters and are times
in epoch format. I want to have time in Posix. I must thus do two
things:
- characters to numeric : myData$ts <- as.numeric(myData$ts)
- epoch to Posix : mapply(as.POSIXct, tz = 'GMT', origin =
'1970-01-01', myMerge$ts)

I wonder:
- if I can apply these two functions at the same time
- what will be the fastest way : use dplyr package, or work with
data.table ? My real data will be much more important than the one
posted.

Thank you for advice and hint.

-- 

google.com/+arnaudgabourygabx


From S.Ellison at LGCGroup.com  Thu Feb 12 12:35:19 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 12 Feb 2015 11:35:19 +0000
Subject: [R] Terminating a program using R
In-Reply-To: <1423554904740-4703004.post@n4.nabble.com>
References: <1423554904740-4703004.post@n4.nabble.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED66040D31D7@GOLD.corp.lgc-group.com>

> I would like to query that if it is possible for R to terminate a program such as
> notepad, word, etc.?

pskill from the tools package says it supports the Windows system call
'TerminateProcess'.

You can get a process's ID using the windows command line 'tasklist'.

I got this to work on my text editor process (TextPad) using

pname <- "TextPad.exe"      #Amend to your process name
tl <- system('tasklist', intern=TRUE)       #Get the task list 
pid.line <- tl[grep(pname, tl)]                #Find the row that matches [WARNING - I assumed only one]
pid.char <- gsub(paste("^",pname," *([0-9]+).*", sep=""), "\\1", pid.line) 
                                                               #Extract the PID 
pid <- as.numeric(pid.char)                   #Convert to integer
pskill(pid)                                               #Kill the process


You'll have to tweak that if you have more than one process with the same name, and also to check for nonexistence of an expected process.


S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jdnewmil at dcn.davis.CA.us  Thu Feb 12 12:52:26 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 12 Feb 2015 06:52:26 -0500
Subject: [R] apply two functions to column
In-Reply-To: <CAK1hC9uSUCsdHTHhNn3fkG4AsBZwSZpqFuivvSJo+Kdhqjd-xg@mail.gmail.com>
References: <CAK1hC9uSUCsdHTHhNn3fkG4AsBZwSZpqFuivvSJo+Kdhqjd-xg@mail.gmail.com>
Message-ID: <34B0F3C6-5D69-42A5-94FF-0AF75037D1A3@dcn.davis.CA.us>

You don't need to do these operations in pieces so the mapply is unnecessary. Neither dplyr nor data.table can go faster than (assuming your data frame is called DF):

DF$dtm <- as.POSIXct( as.numeric( DF$ts ), tz="GMT", origin="1970-01-01" )

They can in this case save you from having to retype DF more than once, but in this case even achieving that requires more typing than the above does.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 12, 2015 6:15:35 AM EST, arnaud gaboury <arnaud.gaboury at gmail.com> wrote:
>I am little lost between all the possibilities to apply a function to
>a data.frame or data.table.
>
>Here is mine:
>
>structure(list(name = c("poisonivy", "poisonivy", "poisonivy",
>"poisonivy", "poisonivy", "poisonivy", "poisonivy", "poisonivy",
>"cruzecontrol", "agreenmamba", "agreenmamba", "vairis", "vairis",
>"vairis", "vairis", "vairis", "vairis", "xaeth"), text = c("ok",
>"need items ?", "i didn't submit pass codes for a long now",
>"ok", "<@U03AEKYL4>: what app are you talking about ?", "some testing
>with my irc client",
>"ha ha sorry", "for me there is no such question", "Lol.",
>"<@U03AEKWTL|agreenmamba> uploaded a file:
><https://enlightened.slack.com/files/agreenmamba/F03KGRF3W/screenshot_2015-02-09-14-31-15.png|regarding:
>should I stay or should I go?>",
>"<@U032FHV3S> <http://youtu.be/oGIFublvDes>", "ok, see you around",
>"yeah, I had a procrastination rush so I started to decode a little",
>"<http://ingress.com/intel|ingress.com/intel> when you submit
>passcodes",
>"intel", "what is the cooldown time or how does it work...;",
>"anybody knows how does \"Passcode circuitry too hot. Wait for cool
>down to enter another passcode.\" works?",
>"and people told that agent their geocities experience would never
>amount to anything (the convo yesterday) "
>), ts = c("1423594336.000138", "1423594311.000136",
>"1423594294.000135",
>"1423594258.000133", "1423594244.000131", "1423497058.000127",
>"1423497041.000126", "1423478555.000123", "1423494427.000125",
>"1423492370.000124", "1423478364.000121", "1423594358.000139",
>"1423594329.000137", "1423594264.000134", "1423594251.000132",
>"1423592204.000130", "1423592174.000129", "1423150354.000112"
>)), .Names = c("name", "text", "ts"), class = c("data.table",
>"data.frame"), row.names = c(NA, -18L))
>
>As you can see, it is of class data.frame and data.table.
>
>I need to work on last column "t"s. These are characters and are times
>in epoch format. I want to have time in Posix. I must thus do two
>things:
>- characters to numeric : myData$ts <- as.numeric(myData$ts)
>- epoch to Posix : mapply(as.POSIXct, tz = 'GMT', origin =
>'1970-01-01', myMerge$ts)
>
>I wonder:
>- if I can apply these two functions at the same time
>- what will be the fastest way : use dplyr package, or work with
>data.table ? My real data will be much more important than the one
>posted.
>
>Thank you for advice and hint.


From nashjc at uottawa.ca  Thu Feb 12 12:59:34 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Thu, 12 Feb 2015 06:59:34 -0500
Subject: [R] Problem Solved: optim fails when using arima
In-Reply-To: <mailman.1.1423738801.12325.r-help@r-project.org>
References: <mailman.1.1423738801.12325.r-help@r-project.org>
Message-ID: <54DC95A6.9020702@uottawa.ca>

I would not say it is fully "solved" since in using Nelder-Mead
you did not get the Hessian.

The issue is almost certainly that there is an implicit bound due to
log() or sqrt() where a parameter gets to be near zero and the finite
difference approximation of derivatives steps over the cliff. Probably
some NM steps are doing the same, but returning a large function value
which will allow NM to "work", but possibly make it inefficient.

JN

On 15-02-12 06:00 AM, r-help-request at r-project.org wrote:
> Message: 30
> Date: Wed, 11 Feb 2015 08:10:03 -0700
> From: Albert Shuxiang Li <albert.shuxiang.li at gmail.com>
> To: r-help at r-project.org
> Subject: [R] Problem Solved: optim fails when using arima
> Message-ID:
> 	<CANko1DKHubongY0zDTNVGXxmvfi8c+D3Z-akykVA5TNkrp7HKA at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> I am using arima(x, order=c(p,0,q)) function for my project, which deals
> with a set of large differenced time series data, data size varies from
> 8000 to 70000. I checked their stationarity before applying arima.
> Occasionally, arima(x, order=c(p,0,q)) gives me error like following (which
> stops script running):
> 
> Error in optim(init[mask], armafn, method = optim.method, Hessian = TRUE, :
> non-finite finite-difference value [16]
> 
> The last [16] would change anyting from 1 to 16. Using argument
> method="CSS", or "ML", or default did not help. I am using the newest R
> version 3.1.2 for windows 7.
> 
> I have done a lot of research on internet for this Error Message, and tried
> a lot of suggested solutions too. But the results are negative. Then,
> finally, I used following line which solved my problem.
> 
> arima(x, order=c(p,0,q), optim.method="Nelder-Mead")
> 
> Hope this helps others with similar situations.
> 
> Shuxiang Albert Li
> 
> 	[[alternative HTML version deleted]]


From GLockhar at virginiaaquarium.com  Thu Feb 12 13:56:05 2015
From: GLockhar at virginiaaquarium.com (Gwen G. Lockhart)
Date: Thu, 12 Feb 2015 12:56:05 +0000
Subject: [R] adehabitatHR KD ID and XY assignement
Message-ID: <6283DCD085FC0B4084E8AA65D9A7A1ECFF8B60F2@VBMS0008.vbgov.com>


Hello Everyone...

I am fairly new to R. I would like to use the adehabitatHR package to create kernel density and isopleths from my sea turtle GPS data. I?m running into some issues?

Basically I am having trouble assigning IDs and XY fields within R to create KDs and MCPs.

Thank you in advance for any help!



Gwen Lockhart
GIS Research Specialist
Virginia Aquarium and Marine Science Center Foundation
Division of Research and Conservation
glockhar at virginiaaquarium.com<mailto:glockhar at virginiaaquarium.com>
Desk: 757-385-6486
Cell: 757-748-6757


#loading packages
`library(adehabitatHR)
library(raster)
library(rgdal)
library(maptools)`

#read CSV with UTM xy and ids

    track<-
read.table("T:/GIS/Data/Tracking/state_space_model/20150210_AbHabiatatHRmodel/All_prelim_model_6hr_utm_forage_10A.csv",
   header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)

# Turn track into a SpatialPointsDataFrame sby specifying that the "X" and "Y" columns are the coordinates:
coordinates(track) <- c("X", "Y")
class(track)
plot(track)


#Project into utm:
proj4string(track) <- CRS("+init=epsg:32618")
#read shore;ine file
shore <- readShapeSpatial("C:/Users/gemme001/Desktop/R_state_space/STATES_VA_COAST_UTM.shp", delete_null_obj=TRUE)
plot(shore)
proj4string(shore) <- CRS("+init=epsg:32618")


#Add to list the list with the names "map" and "relocs"
my.homerange.data <- list(map = shore, relocs = track)

#####THIS IS WHERE I AM RUNNING INTO ISSUES#####
#Assign IDs and XY ? the IDs work but coordinates don?t work.  I get the following error: Error in `[.data.frame`(x at data, i, j, ..., drop = FALSE) : undefined columns selected
id<-my.homerange.data$relocs$Name
xy<-(my.homerange.data$relocs["X","Y"]


#Create CP ? this works
cp <- mcp(my.homerange.data$relocs[,1], percent=95)
class(cp)
plot(cp)


#Create KUD.  This doesn?t work.  I get the following:  Error in xy.coords(x, y, xlabel, ylabel, log) : 'x' is a list, but does not have components 'x' and 'y'
kud <- kernelUD(track[,1], h="href")

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Thu Feb 12 15:02:03 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 12 Feb 2015 14:02:03 +0000
Subject: [R] help in anova
In-Reply-To: <1423666285303.92712@uef.fi>
References: <1423666285303.92712@uef.fi>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED66040D3301@GOLD.corp.lgc-group.com>

> R-ouput
> 
>                                       Df      Sum Sq    Mean Sq    F value Pr(>F)
> treatment                    3        14015      4672          65.021 < 2e-16 ***
> variety                          3         5883       1961           27.295 2.95e-12 ***
> treatment:variety      9          5474       608             8.465 8.93e-09 ***
> soilgroup -missing
> treatment:variety:soilgroup - missing
> Here, I am missing value of soil group and interation of treatment: variety:
> soilgroup- Can any one please tell me why?

Do the lines 
> soilgroup -missing
> treatment:variety:soilgroup - missing
Actually appear in your output? If so, I have no idea.

But if the terms are simply absent, one possibility is that soilgroup is completely confounded with an earlier factor in the model and therefore unidentifiable. aov seems fairly tolerant of that in one sense - instead of throwing an error and stopping it tells you what it can identify and leaves out anything it can't.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From michael.eisenring at agroscope.admin.ch  Thu Feb 12 14:56:37 2015
From: michael.eisenring at agroscope.admin.ch (michael.eisenring at agroscope.admin.ch)
Date: Thu, 12 Feb 2015 13:56:37 +0000
Subject: [R] horizontal bar plots for CI visualization
Message-ID: <9EFCA4A987B0494CBFFB5CD071756D0026B3F8C6@WBF-C7002.bk.evdad.admin.ch>

An embedded and charset-unspecified text was scrubbed...
Name: CI_data.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150212/11fadfa9/attachment.txt>

From hyiltiz at gmail.com  Thu Feb 12 15:08:36 2015
From: hyiltiz at gmail.com (=?UTF-8?Q?H=C3=B6rmetjan_Yiltiz?=)
Date: Thu, 12 Feb 2015 22:08:36 +0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
Message-ID: <CAM5FmSMAiDzGJ+D5drPtgUHbM4V1tr6aLJJtdJSkqCmFS5W49w@mail.gmail.com>

Hi all,

I have four factors for a continuous time variable along with its
confidence interval. I would like to produce a publication quality error
bar chart that is clear to understand. For now, I used colors, x axis
position, facets and alpha level to distinguish them.

I would like to overlap each pairs of bars with the same color a bit as a
group, but not overlap each and every bars with each other.

Here is a minimal example:

N = 32
df<- data.frame(gender=gl(2,1,N, c("male","female")),
          direction=gl(2,2,N, c("up","down")),
          condition=gl(4,4,N, c("c1","c2","c3","c4")),
          location=gl(2,16,N, c("east","west")),
          t=rnorm(N, 1, 0.5),
          ci=abs(rnorm(N, 0, 0.2)))
pp <-
  ggplot(df, aes(x=gender, y=t, fill=condition, alpha=direction)) +
  facet_grid(location~.) +
  geom_bar(position=position_dodge(.9), stat="identity", color="black") +
  geom_errorbar(aes(ymin=t-ci, ymax=t+ci),
                width=.2,                    # Width of the error bars
                position=position_dodge(.9)) +
  scale_alpha_discrete(range= c(0.4, 1))
pp



In the attachment, I have added the output figure, while manually editing
the SVG file to make the lower-left group of bars to make them as I wanted.
(The spacing in between each pair is not necessarily required.)


?Best
?
========================
He who is worthy to receive his days and nights is worthy to receive* all
else* from you (and me).
                                                 The Prophet, Gibran Kahlil

From arnaud.gaboury at gmail.com  Thu Feb 12 15:40:31 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Thu, 12 Feb 2015 15:40:31 +0100
Subject: [R] gsub : replace regex pattern with values from another data.frame
Message-ID: <CAK1hC9uk3dinkEwNF1e9ji=2R2PaQZfbbqN==xeU1G-zDvwzAQ@mail.gmail.com>

I have two df (and dt):

df1
structure(list(name = c("poisonivy", "poisonivy", "poisonivy",
"poisonivy", "poisonivy", "poisonivy", "poisonivy", "poisonivy",
"cruzecontrol", "agreenmamba", "agreenmamba", "vairis", "vairis",
"vairis", "vairis", "vairis", "vairis", "xaeth"), text = c("ok",
"need items ?", "i didn't submit pass codes for a long now",
"ok", "<@U03AEKYL4>: what app are you talking about ?", "some testing
with my irc client",
"ha ha sorry", "for me there is no such question", "Lol.",
"<@U03AEKWTL|agreenmamba> uploaded a file:
<https://enlightened.slack.com/files/agreenmamba/F03KGRF3W/screenshot_2015-02-09-14-31-15.png|regarding:
should I stay or should I go?>",
"<@U032FHV3S> <http://youtu.be/oGIFublvDes>", "ok, see you around",
"yeah, I had a procrastination rush so I started to decode a little",
"<http://ingress.com/intel|ingress.com/intel> when you submit passcodes",
"intel", "what is the cooldown time or how does it work...;",
"anybody knows how does \"Passcode circuitry too hot. Wait for cool
down to enter another passcode.\" works?",
"and people told that agent their geocities experience would never
amount to anything (the convo yesterday) "
), ts = c("1423594336.000138", "1423594311.000136", "1423594294.000135",
"1423594258.000133", "1423594244.000131", "1423497058.000127",
"1423497041.000126", "1423478555.000123", "1423494427.000125",
"1423492370.000124", "1423478364.000121", "1423594358.000139",
"1423594329.000137", "1423594264.000134", "1423594251.000132",
"1423592204.000130", "1423592174.000129", "1423150354.000112"
)), .Names = c("name", "text", "ts"), class = c("data.table",
"data.frame"), row.names = c(NA, -18L))

df2
structure(list(id = c("U03KH8Z52", "U02AF1DTJ", "U02AF0ZT8",
"U03AEKWTL", "U02BCJH0G", "U033YA1MS", "U029QMCRR", "U03H139M5",
"U02AET1D0", "U02A6U41Z", "U02B5T4CX", "U02B2QU4R", "U03F0LQ5X",
"U03JNFKLY", "U02ASMBMQ", "U029QLQC7", "U03AEMBQU", "U02B4D3Q1",
"U02AGDC14", "U029A467C", "U02A7NFG6", "U02AESPPL", "U02AQANK7",
"U03ADJDFK", "U03EYR0KB", "U02AW7Q5Q", "U02AE8RKD", "U02FT84BS",
"U02B25M3B", "U03EZDQT7", "U02AECKFF", "U03H2691M", "U02DWTJ5V",
"U02AFTAHH", "U029QQEPM", "U03C51Z42", "U02CAK2CV", "U03AK21DP",
"U03FFN8ED", "U02B23V03", "U029T2143", "U02C1LEEX", "U03AF2QH2",
"U03E0GN0S", "U03AG20R9", "U02AES8S2", "U02AG64S7", "U02B5A0R7",
"U02AS4SLR", "U03C2SG0R", "U03AV7CCW", "U032XPFDU", "U03AUKSSV",
"U02C2A61Y", "U02AESHJQ", "U02BLSKHU", "U02E34WM6", "U03AK6P26",
"U02E6ADRZ", "U03FCDQ50", "U03EW1CC5", "U02BL0DBD", "U02FHQZ6D",
"U02B47T63", "U03H2TTQP", "U03AVP71V", "U03JLV38V", "U02E39HAY",
"U02AE5281", "U032FHV3S", "U03AL2096", "U02ARUG6M", "U02AECRSP",
"U02B42XG4", "U03AFQZNS", "U02AE7H41", "U03G9UNTG", "U02GEQ0E6",
"U02AGLE5A", "U02BQTRC9", "U03H0J6GS", "U02B3D27F", "U02AEKTHV",
"U02C52YN3", "U02E33MUW", "U03AKUT85", "U03B53EHG", "U02FBN38P",
"U03AH3E5W", "U02B5PLE0", "U02AS4RCK", "U03ANE1GZ", "U02E8LZQB",
"U03EPGJ98", "U02E3N220", "U03AEKYL4", "U02AE7HT1", "U02C1RR3G",
"U03JH408J", "U03KL0FKN", "U02B44R92", "U03EURWGX"), name = c("10k_affair",
"1upwuzhere", "4xcss", "agreenmamba", "ait109", "arly69", "azkop13",
"barcik75", "bigolnob", "blackrose", "blink619", "bobaloo23",
"bodger", "bomb", "bootswithdefer", "brandizzle", "bregalad",
"camon", "celticrain", "ch3mical", "checksum", "cocothunder",
"cruxicon", "cruzecontrol", "crystalskunk", "cscheetah", "dabcelin",
"deelicious", "delthanar", "drkaosdk", "droidenl-joe", "dukeceph",
"fillerbunny", "flickohmsford", "flyingg0d", "garaxiel", "goby9",
"gymbal", "hideandseek", "hobojr", "ijackportals", "invalidcharactr",
"itso9", "j0shs", "jarvis", "jc0mm5", "jencyberchic", "jimbobradyson",
"joespr0cket", "jostrander", "jueliet", "karlashi", "khan99",
"kingkonn0r", "krispycridder", "kritickalmass", "lawgiver", "maxcorbett",
"memory556", "meta000x", "minkovsky", "mistylady", "mstephans",
"mstrinity", "nocarryr", "ollietronic", "philistine11", "pickledpickles",
"piercingsbykris", "poisonivy", "raugmor", "remarks999", "rheds77",
"rhinz", "rigiritter", "robbie0017", "rohdef", "ryoziya", "s4n1ty",
"sacredcow133", "samwill", "sgtlemonpepper", "sivan", "spline9",
"starwolf", "stueliueli", "sweetiris", "swift2plunder", "swissphoenix",
"synyck", "test", "therug", "tinja551", "trulyjuan", "twinster",
"vairis", "vinylz3ro", "watervirus", "xaeth", "yagamiyukari",
"zafo", "zexium")), .Names = c("id", "name"), class = c("data.table",
"data.frame"), row.names = c(NA, -102L))

I need to replace this regex pattern in df1 :
(?<=<@)[^|]{9}(?=>|) by its corresponding name from df2.

E.g : if <@U03KH8Z52> is found in df1, then I want to replace it by
the "name" which correspond to this id in df2., in this case
10k_affair

I know of replace an expression with gsub:
gsub('(?<=<@)[^|]{9}(?=>|)', 'toto', df1, perl = T)
but I have no idea how to replace it with value from another df.

Thank you for hints


From petr.pikal at precheza.cz  Thu Feb 12 15:48:12 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 12 Feb 2015 14:48:12 +0000
Subject: [R] suggestion for optimal plotting to show significant
 differences
In-Reply-To: <CAGx1TMDvvOOukbUfk23GrWQLSnmwr-Ykx6Qj=xYZLWraAfBKxA@mail.gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F0E3@SRVEXCHMBX.precheza.cz>
	<CAGx1TMCq1jXtuyofWv5nYC2So0RyKDp_734ze6rAQXztaxccnw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F3E0@SRVEXCHMBX.precheza.cz>
	<CAGx1TMDvvOOukbUfk23GrWQLSnmwr-Ykx6Qj=xYZLWraAfBKxA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FC45@SRVEXCHMBX.precheza.cz>

Hi Rich

> -----Original Message-----
> From: Richard M. Heiberger [mailto:rmh at temple.edu]
> Sent: Wednesday, February 11, 2015 10:53 PM
> To: PIKAL Petr
> Cc: r-help at r-project.org
> Subject: Re: [R] suggestion for optimal plotting to show significant
> differences
>
> Petr,
>
> My first attempt is to use the simple=TRUE argument to interaction2wt.
>
> Then the bwplots in the item|item panel show the behavior of value over
> day for each item.  You get a plot similar to this panel with the
> growth curve plots from nlme, for example,
>     bwplot(value ~ day | item, data=test, horizontal=FALSE) I am
> treating set as a replication and each box is cumulated over the three
> sets.

Yes, that is the point - set is actually replication of result.

>
> My analysis question is about day.  You have it as numeric.  My
> inclination would be to make day factor.  Then you could model the
> interaction of day and item.

Hm. I hoped I can do

fit<-lm(value~day*item, data=test)
summary(fit)

in which case I can compare differences in intercepts and/or slopes for each item.

However I am rather lost in aov

test$dayf <- factor(test$day)

fit1 <- aov(value~item+dayf, data=test)
summary(fit)
fit2 <- aov(value~item/dayf, data=test)
summary(fit)
and
fit3 <- aov(value~item*dayf, data=test)
summary(fit)
which gives bascally the same result as fit2

> anova(fit1, fit2)
Analysis of Variance Table

Model 1: value ~ item + dayf
Model 2: value ~ item/dayf
  Res.Df    RSS Df Sum of Sq      F Pr(>F)
1    131 160.59
2     96 128.60 35    31.993 0.6824 0.8993

TukeyHSD(fit1, which="item")
TukeyHSD(fit2, which="item")

Both models seems to give quite similar results and I am not sure what actually differs in those models. I believe that model2 tests each item within particular day (but I am not sure about it).

However this discussion is probably deviating more to the statistics issue than to R itself.

I just thought that somebody helps me with a method for comparison of item performance in case that relation of value to day is not simple linear (as in my example) and cannot be expressed by some formula (like examples in nlme).

So far the best options are either your bwplot or my ggplots.

p<-ggplot(test, aes(x=day, y=value, colour=item))
p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))

p<-ggplot(test, aes(x=dayf, y=value, colour=item))
p+geom_boxplot()

p<-ggplot(test, aes(x=item, y=value))
p+geom_boxplot()+facet_wrap(~day)

Thank you for your suggestions which directed me to interaction plots which I was not aware of.

Best regards
Petr


>
> Rich
>
> On Mon, Feb 9, 2015 at 6:01 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Hallo Richard.
> >
> > I tried your suggestion but it seems to be no better than simple
> ggplot. Let me extend the example a bit to 8 items which is more
> realistic.
> >
> > item<-rep(letters[1:8], each=18)
> > day<-rep((0:5)*100, 24)
> > set<-rep(rep(1:3, each=6), 8)
> > test<-data.frame(item, day, set)
> > set.seed(111)
> > test$value<-(test$day/100+1)+rnorm(144)
> > test$value<-test$value+(as.numeric(test$item)*1.3)
> >
> > Value is increasing during time (day) for each tested subject (item),
> each item is measured 3 times (set) each day.
> >
> > Here is some graph
> > p<-ggplot(test, aes(x=day, y=value, colour=item))
> > p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))
> >
> > I can do lm or aov, however I am not sure about proper formula.
> >
> > fit<-lm(value~day, data=test)
> > summary(fit)
> > # this shows that value is increasing with day
> >
> > fit<-lm(value~day/item, data=test)
> > summary(fit)
> > # this suggests that value is decreasing with day (which is wrong)
> >
> > fit<-lm(value~day*item, data=test)
> > summary(fit)
> > # and this tells me that value is increasing with day and items have
> different intercepts but the same rate of growth (I hope I got it
> right).
> >
> > I do not have your book available but I went through help pages.
> >
> > Your interaction graph is not much better than ggplot.
> > I can do
> >
> > interaction2wt(value ~ item * day, data=test)
> >
> > which probably is closer to actual problem.
> >
> > The basic problem is that increase of value with days is in fact not
> linear and actually it can increase in the beginning and then stagnate
> or it can stagnate in beginning and then increase. I am not aware of
> any way how to compare time behaviour of different items in such
> situations if I cannot state some common formula in which case I would
> use probably nlme.
> >
> > Thank for your insight, I try to go through it more deeply.
> >
> > Best regards
> > Petr
> >
> >
> >> -----Original Message-----
> >> From: Richard M. Heiberger [mailto:rmh at temple.edu]
> >> Sent: Friday, February 06, 2015 6:14 PM
> >> To: PIKAL Petr
> >> Cc: r-help at r-project.org
> >> Subject: Re: [R] suggestion for optimal plotting to show significant
> >> differences
> >>
> >> I would try one of these illustrations for starts.
> >> interaction2wt (two-way tables) is designed to be used with aov()
> for
> >> testing.
> >> interaction2wt shows all main effects and all two-way interactions
> >> for many factors.
> >>
> >>
> >>
> >> test <-
> >> structure(list(item = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A", "B"), class
> >> = "factor"), day = c(0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L,
> >> 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L,
> >> 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L,
> >> 200L, 300L, 400L, 500L), set = c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L), value = c(1.08163365169503,
> >> 2.61998412608805, 3.07820466606394, 4.44993419381934,
> >> 5.29163171545805, 6.29155990999293, -0.123163011367676,
> >> 2.07767236834003, 2.32537052874901, 3.09372794501084,
> >> 6.65273721166635, 5.92304962329131, 1.50504697705548,
> >> 2.66253728086866, 2.63420157418685, 2.78195098580416,
> >> 6.47578642973288, 5.89587443775143, 0.848864231485078,
> >> 1.27549677119713, 2.19573089053609, 2.45659926134292,
> >> 5.15424403414103, 5.4813151140983, 1.25731482647214,
> >> 2.09662105167973, 1.75954023316977, 4.81624002288939,
> >> 4.65029189325307, 6.39946904227214, 0.944996929887344,
> >> 1.74667265331284, 2.42956264345558, 5.17852980415141,
> >> 3.5453435965834, 6.9011238437191)), .Names = c("item", "day", "set",
> >> "value"), row.names = c(NA, -36L), class =
> >> "data.frame")
> >>
> >>
> >>
> >> library(HH)
> >>
> >> test$set <- factor(test$set)
> >> test$day <- factor(test$day)
> >> test$item <- factor(test$item)
> >>
> >> interaction2wt(value ~ item * day * set, data=test)
> >>
> >> test$item.day <- interaction(test$item, test$day)
> >> position(test$item.day) <- outer(c(-10,10),
> >> as.numeric(levels(test$day)), `+`)
> >>
> >> xyplot(value ~ as.position(item.day) | set, groups=item,
> >>         data=test, horizontal=FALSE, pch=c(17,16),
> >>         xlab="day",
> >>         scales=list(
> >>           x=list(
> >>             alternating=1,
> >>             at=levels(test$day), ## placement of tick labels and
> marks
> >>             tck=1)),
> >>         key=list(
> >>           text=list(c("A","B"), col=c("blue","red")),
> >>           points=list(pch=c(17, 16), col=c("blue","red")),
> >>        space="top", columns=2, border=TRUE),
> >>        layout=c(3,1))
> >>
> >>
> >> ## see also the examples in
> >> demo(package="HH", bwplot.examples)
> >>
> >> On Fri, Feb 6, 2015 at 6:09 AM, PIKAL Petr <petr.pikal at precheza.cz>
> >> wrote:
> >> > Dear all
> >> >
> >> > I would like to ask for your opinion about possible graphical
> >> representation of such data.
> >> >
> >> >> dput(test)
> >> > structure(list(item = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L,
> >> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A", "B"),
> >> > class
> >> =
> >> > "factor"), day = c(0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L,
> >> > 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L,
> 100L,
> >> > 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L,
> 100L,
> >> > 200L, 300L, 400L, 500L), set = c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
> >> > 2L, 2L,
> >> 2L,
> >> > 2L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
> 2L,
> >> > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L), value = c(1.08163365169503,
> >> > 2.61998412608805, 3.07820466606394, 4.44993419381934,
> >> > 5.29163171545805, 6.29155990999293, -0.123163011367676,
> >> > 2.07767236834003, 2.32537052874901, 3.09372794501084,
> >> > 6.65273721166635, 5.92304962329131, 1.50504697705548,
> >> > 2.66253728086866, 2.63420157418685, 2.78195098580416,
> >> > 6.47578642973288, 5.89587443775143, 0.848864231485078,
> >> > 1.27549677119713, 2.19573089053609, 2.45659926134292,
> >> > 5.15424403414103, 5.4813151140983, 1.25731482647214,
> >> 2.09662105167973,
> >> > 1.75954023316977, 4.81624002288939, 4.65029189325307,
> >> > 6.39946904227214, 0.944996929887344, 1.74667265331284,
> >> > 2.42956264345558, 5.17852980415141, 3.5453435965834,
> >> > 6.9011238437191)), .Names = c("item", "day", "set", "value"),
> >> > row.names = c(NA, -36L), class = "data.frame")
> >> >>
> >> >
> >> > One option I came with is
> >> >
> >> > library(ggplot2)
> >> > p<-ggplot(test, aes(x=day, y=value, colour=item))
> >> > p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))
> >> >
> >> > but -
> >> > I have more items (around 5-10), and I want to show if the
> >> > difference
> >> between items is or is not significant. The actual development of
> >> value with day is usually not linear nor growing steadily and
> >> actually I cannot usually evaluate some analytical equation for my
> >> data to compare equation parameters.
> >> >
> >> > I thought about boxplots, but there is not many repetitions and
> >> actually 5+ boxplots can be quite messy.
> >> >
> >> > I can plot only mean for each set and item but in that case I lose
> >> information if the difference is or is not significant.
> >> >
> >> > I appreciate any suggestion.
> >> >
> >> > Best regards
> >> > Petr
> >> >

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From HDoran at air.org  Thu Feb 12 16:07:48 2015
From: HDoran at air.org (Doran, Harold)
Date: Thu, 12 Feb 2015 15:07:48 +0000
Subject: [R] Shiny User Group
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686CF38BBF8@DC1VEX10MB001.air.org>

I found a google user group for shiny, and am curious if there is an SIG as well. Didn't see one in my searches, but looking for an active place to ask questions and share code.

Thanks.

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Thu Feb 12 16:31:59 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 12 Feb 2015 07:31:59 -0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <CAM5FmSMAiDzGJ+D5drPtgUHbM4V1tr6aLJJtdJSkqCmFS5W49w@mail.gmail.com>
Message-ID: <4AD1EDC7C1F.00000299jrkrideau@inbox.com>

I am gettting the error"
Error in rep_len(rep.int(seq_len(n), rep.int(k, n)), length) : 
  object 'N' not found

Also your image did not come through.  Try sending it as a pdf file.

when I try to create 
df<- data.frame(gender=gl(2,1,N, c("male","female")),
          direction=gl(2,2,N, c("up","down")),
          condition=gl(4,4,N, c("c1","c2","c3","c4")),
          location=gl(2,16,N, c("east","west")),
          t=rnorm(N, 1, 0.5),
          ci=abs(rnorm(N, 0, 0.2)))

John Kane
Kingston ON Canada


> -----Original Message-----
> From: hyiltiz at gmail.com
> Sent: Thu, 12 Feb 2015 22:08:36 +0800
> To: r-help at r-project.org
> Subject: [R] ggplot2 shifting bars to only overlap in groups
> 
> Hi all,
> 
> I have four factors for a continuous time variable along with its
> confidence interval. I would like to produce a publication quality error
> bar chart that is clear to understand. For now, I used colors, x axis
> position, facets and alpha level to distinguish them.
> 
> I would like to overlap each pairs of bars with the same color a bit as a
> group, but not overlap each and every bars with each other.
> 
> Here is a minimal example:
> 
> N = 32
> df<- data.frame(gender=gl(2,1,N, c("male","female")),
>           direction=gl(2,2,N, c("up","down")),
>           condition=gl(4,4,N, c("c1","c2","c3","c4")),
>           location=gl(2,16,N, c("east","west")),
>           t=rnorm(N, 1, 0.5),
>           ci=abs(rnorm(N, 0, 0.2)))
> pp <-
>   ggplot(df, aes(x=gender, y=t, fill=condition, alpha=direction)) +
>   facet_grid(location~.) +
>   geom_bar(position=position_dodge(.9), stat="identity", color="black") +
>   geom_errorbar(aes(ymin=t-ci, ymax=t+ci),
>                 width=.2,                    # Width of the error bars
>                 position=position_dodge(.9)) +
>   scale_alpha_discrete(range= c(0.4, 1))
> pp
> 
> 
> 
> In the attachment, I have added the output figure, while manually editing
> the SVG file to make the lower-left group of bars to make them as I
> wanted.
> (The spacing in between each pair is not necessarily required.)
> 
> 
> ?Best
> ?
> ========================
> He who is worthy to receive his days and nights is worthy to receive* all
> else* from you (and me).
>                                                  The Prophet, Gibran
> Kahlil
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Thu Feb 12 16:33:14 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 12 Feb 2015 07:33:14 -0800
Subject: [R] horizontal bar plots for CI visualization
In-Reply-To: <9EFCA4A987B0494CBFFB5CD071756D0026B3F8C6@WBF-C7002.bk.evdad.admin.ch>
Message-ID: <4AD4B99F77F.000002A0jrkrideau@inbox.com>

And?

John Kane
Kingston ON Canada


> -----Original Message-----
> From: michael.eisenring at agroscope.admin.ch
> Sent: Thu, 12 Feb 2015 13:56:37 +0000
> To: r-help at r-project.org
> Subject: [R] horizontal bar plots for CI visualization

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From hyiltiz at gmail.com  Thu Feb 12 16:38:01 2015
From: hyiltiz at gmail.com (=?UTF-8?Q?H=C3=B6rmetjan_Yiltiz?=)
Date: Thu, 12 Feb 2015 23:38:01 +0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <4AD1EDC7C1F.00000299jrkrideau@inbox.com>
References: <CAM5FmSMAiDzGJ+D5drPtgUHbM4V1tr6aLJJtdJSkqCmFS5W49w@mail.gmail.com>
	<4AD1EDC7C1F.00000299jrkrideau@inbox.com>
Message-ID: <CAM5FmSPBv2v23ojBj=zsP4hi8ONhh-rBY2G1UTxX-sBKQVEiFA@mail.gmail.com>

You are most likely simply not running the whole lines of code: note that
the first line is:
N = 32

?Best
?
========================
He who is worthy to receive his days and nights is worthy to receive* all
else* from you (and me).
                                                 The Prophet, Gibran Kahlil


On Thu, Feb 12, 2015 at 11:31 PM, John Kane <jrkrideau at inbox.com> wrote:

> I am gettting the error"
> Error in rep_len(rep.int(seq_len(n), rep.int(k, n)), length) :
>   object 'N' not found
>
> Also your image did not come through.  Try sending it as a pdf file.
>
> when I try to create
> df<- data.frame(gender=gl(2,1,N, c("male","female")),
>           direction=gl(2,2,N, c("up","down")),
>           condition=gl(4,4,N, c("c1","c2","c3","c4")),
>           location=gl(2,16,N, c("east","west")),
>           t=rnorm(N, 1, 0.5),
>           ci=abs(rnorm(N, 0, 0.2)))
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: hyiltiz at gmail.com
> > Sent: Thu, 12 Feb 2015 22:08:36 +0800
> > To: r-help at r-project.org
> > Subject: [R] ggplot2 shifting bars to only overlap in groups
> >
> > Hi all,
> >
> > I have four factors for a continuous time variable along with its
> > confidence interval. I would like to produce a publication quality error
> > bar chart that is clear to understand. For now, I used colors, x axis
> > position, facets and alpha level to distinguish them.
> >
> > I would like to overlap each pairs of bars with the same color a bit as a
> > group, but not overlap each and every bars with each other.
> >
> > Here is a minimal example:
> >
> > N = 32
> > df<- data.frame(gender=gl(2,1,N, c("male","female")),
> >           direction=gl(2,2,N, c("up","down")),
> >           condition=gl(4,4,N, c("c1","c2","c3","c4")),
> >           location=gl(2,16,N, c("east","west")),
> >           t=rnorm(N, 1, 0.5),
> >           ci=abs(rnorm(N, 0, 0.2)))
> > pp <-
> >   ggplot(df, aes(x=gender, y=t, fill=condition, alpha=direction)) +
> >   facet_grid(location~.) +
> >   geom_bar(position=position_dodge(.9), stat="identity", color="black") +
> >   geom_errorbar(aes(ymin=t-ci, ymax=t+ci),
> >                 width=.2,                    # Width of the error bars
> >                 position=position_dodge(.9)) +
> >   scale_alpha_discrete(range= c(0.4, 1))
> > pp
> >
> >
> >
> > In the attachment, I have added the output figure, while manually editing
> > the SVG file to make the lower-left group of bars to make them as I
> > wanted.
> > (The spacing in between each pair is not necessarily required.)
> >
> >
> > ?Best
> > ?
> > ========================
> > He who is worthy to receive his days and nights is worthy to receive* all
> > else* from you (and me).
> >                                                  The Prophet, Gibran
> > Kahlil
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/password-manager
>
>
>

	[[alternative HTML version deleted]]


From jabbba at gmail.com  Thu Feb 12 16:55:38 2015
From: jabbba at gmail.com (Marco =?ISO-8859-1?B?QmFyYuByYQ==?=)
Date: Thu, 12 Feb 2015 16:55:38 +0100
Subject: [R] Mixed-effects model for pre-post randomization design
In-Reply-To: <loom.20150211T143710-370@post.gmane.org>
References: <20150211123358.760e26cd@caprica>
	<loom.20150211T143710-370@post.gmane.org>
Message-ID: <20150212165538.3888d9ed@caprica>

Thank you very much, Ben. Your answer has been very useful.


From info at aghmed.fsnet.co.uk  Thu Feb 12 16:57:48 2015
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 12 Feb 2015 15:57:48 +0000
Subject: [R] horizontal bar plots for CI visualization
In-Reply-To: <9EFCA4A987B0494CBFFB5CD071756D0026B3F8C6@WBF-C7002.bk.evdad.admin.ch>
References: <9EFCA4A987B0494CBFFB5CD071756D0026B3F8C6@WBF-C7002.bk.evdad.admin.ch>
Message-ID: <54DCCD7C.607@aghmed.fsnet.co.uk>



On 12/02/2015 13:56, michael.eisenring at agroscope.admin.ch wrote:

There are a number of options for doing this. You might consider using 
forest plots as provided by one of a number of the meta-analysis 
packages. See the CRAN MetaAnalysis task view for more details.

-- 
Michael
http://www.dewey.myzen.co.uk


From jrkrideau at inbox.com  Thu Feb 12 17:04:40 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 12 Feb 2015 08:04:40 -0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <CAM5FmSPBv2v23ojBj=zsP4hi8ONhh-rBY2G1UTxX-sBKQVEiFA@mail.gmail.com>
References: <cam5fmsmaidzgj+d5drptguhbm4v1tr6aljjtdjskqcmfs5w49w@mail.gmail.com>
	<4ad1edc7c1f.00000299jrkrideau@inbox.com>
Message-ID: <4B1AFADE554.0000031Bjrkrideau@inbox.com>


I'm a bit blind today. I read df as a dput() .

John Kane
Kingston ON Canada

-----Original Message-----
From: hyiltiz at gmail.com
Sent: Thu, 12 Feb 2015 23:38:01 +0800
To: jrkrideau at inbox.com
Subject: Re: [R] ggplot2 shifting bars to only overlap in groups

You are most likely simply not running the whole lines of code: note that the first line is:

N = 32

 Best
?
========================
He who is worthy to receive his days and nights is worthy to receive* all 
else* from you (and me).
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? The Prophet, Gibran Kahlil 

On Thu, Feb 12, 2015 at 11:31 PM, John Kane <jrkrideau at inbox.com> wrote:

	I am gettting the error"
 Error in rep_len(rep.int [http://rep.int](seq_len(n), rep.int [http://rep.int](k, n)), length) :
 ? object 'N' not found

 Also your image did not come through.? Try sending it as a pdf file.

 when I try to create
 df<- data.frame(gender=gl(2,1,N, c("male","female")),
 ? ? ? ? ? direction=gl(2,2,N, c("up","down")),
 ? ? ? ? ? condition=gl(4,4,N, c("c1","c2","c3","c4")),
 ? ? ? ? ? location=gl(2,16,N, c("east","west")),
 ? ? ? ? ? t=rnorm(N, 1, 0.5),
 ? ? ? ? ? ci=abs(rnorm(N, 0, 0.2)))

 John Kane
 Kingston ON Canada

 > -----Original Message-----
 > From: hyiltiz at gmail.com
 > Sent: Thu, 12 Feb 2015 22:08:36 +0800
 > To: r-help at r-project.org
 > Subject: [R] ggplot2 shifting bars to only overlap in groups
 >
 > Hi all,
 >
 > I have four factors for a continuous time variable along with its
 > confidence interval. I would like to produce a publication quality error
 > bar chart that is clear to understand. For now, I used colors, x axis
 > position, facets and alpha level to distinguish them.
 >
 > I would like to overlap each pairs of bars with the same color a bit as a
 > group, but not overlap each and every bars with each other.
 >
 > Here is a minimal example:
 >
 > N = 32
 > df<- data.frame(gender=gl(2,1,N, c("male","female")),
 >? ? ? ? ? ?direction=gl(2,2,N, c("up","down")),
 >? ? ? ? ? ?condition=gl(4,4,N, c("c1","c2","c3","c4")),
 >? ? ? ? ? ?location=gl(2,16,N, c("east","west")),
 >? ? ? ? ? ?t=rnorm(N, 1, 0.5),
 >? ? ? ? ? ?ci=abs(rnorm(N, 0, 0.2)))
 > pp <-
 >? ?ggplot(df, aes(x=gender, y=t, fill=condition, alpha=direction)) +
 >? ?facet_grid(location~.) +
 >? ?geom_bar(position=position_dodge(.9), stat="identity", color="black") +
 >? ?geom_errorbar(aes(ymin=t-ci, ymax=t+ci),
 >? ? ? ? ? ? ? ? ?width=.2,? ? ? ? ? ? ? ? ? ? # Width of the error bars
 >? ? ? ? ? ? ? ? ?position=position_dodge(.9)) +
 >? ?scale_alpha_discrete(range= c(0.4, 1))
 > pp
 >
 >
 >
 > In the attachment, I have added the output figure, while manually editing
 > the SVG file to make the lower-left group of bars to make them as I
 > wanted.
 > (The spacing in between each pair is not necessarily required.)
 >
 >
 > Best
 > ?
 > ========================
 > He who is worthy to receive his days and nights is worthy to receive* all
 > else* from you (and me).
 >? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? The Prophet, Gibran
 > Kahlil

> ______________________________________________
 > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 > PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 > and provide commented, minimal, self-contained, reproducible code.

 ____________________________________________________________
 Can't remember your password? Do you need a strong and secure password?
 Use Password manager! It stores your passwords & protects your account.
 Check it out at http://mysecurelogon.com/password-manager [http://mysecurelogon.com/password-manager]

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From Yan_Li at ibi.com  Thu Feb 12 17:08:37 2015
From: Yan_Li at ibi.com (Li, Yan)
Date: Thu, 12 Feb 2015 11:08:37 -0500
Subject: [R] 32bit R303 calls external C functions
Message-ID: <A29EC196EE32C64389369F6BF03B66C87A8EFEB5C0@IBIUSMBSB.ibi.com>

Dear All,

I build a R package which will need to call external C functions. I registered the C functions in the NAMESPACE file and include 32bit and 64bit dlls in the packages. If I load the package in 64bit R and calls the external C functions, it works fine. However if I load the package in 32bit R and call the external C functions, it either does not work properly or gives back error message saying cannot find the external C functions.

When I built the same package in R2.15.1, there is no such issue.

I checked the update news for R303 and found most .C is replaced by .Call. I modified the code but the package cannot be loaded and R ended abnormally.

Does anyone know if there any difference of 32bit R303 calling external C from 64bitR303? Thank you!

Regards,
Yan

	[[alternative HTML version deleted]]


From JSOrkin at grecc.umaryland.edu  Thu Feb 12 17:22:56 2015
From: JSOrkin at grecc.umaryland.edu (John Sorkin)
Date: Thu, 12 Feb 2015 11:22:56 -0500
Subject: [R] Installing RStudio
In-Reply-To: <54D372F7.8030108@univ-reims.fr>
References: <1316544333.122505.1423141062041.JavaMail.yahoo@mail.yahoo.com>
	<818837787-1423141688-cardhu_decombobulator_blackberry.rim.net-1580041060-@b12.c6.bise7.blackberry>
	<54D372F7.8030108@univ-reims.fr>
Message-ID: <54DC8D10020000CB00122E61@smtp.medicine.umaryland.edu>

Windows 7, 64-bit.
 
I am trying to install RStudio. Before installing RStudio, I installed R 3.1.2. During the installation or R, I installled (as per the default) 32- and 64-bit packages. When I tried to install RStudio, I received the message
R does not appear to be installed. Please install R before using RStudio.
I know R is installed, beacuse I am able to run R.
Can anyone suggest what I can do to get RStudio installed?
Thank you
John
 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From petr.pikal at precheza.cz  Thu Feb 12 17:40:48 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 12 Feb 2015 16:40:48 +0000
Subject: [R] problems with packages installation
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FD21@SRVEXCHMBX.precheza.cz>

Dear all

I just switched to new version

> version
               _
platform       i386-w64-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status         Under development (unstable)
major          3
minor          2.0
year           2015
month          02
day            11
svn rev        67792
language       R
version.string R Under development (unstable) (2015-02-11 r67792)
nickname       Unsuffered Consequences

and started to have problems with installing packages through utils

> setInternet2(TRUE)
> utils:::menuInstallPkgs()
--- Please select a CRAN mirror for use in this session ---
also installing the dependencies ?colorspace?, ?Rcpp?, ?stringr?, ?RColorBrewer?, ?dichromat?, ?munsell?, ?labeling?, ?plyr?, ?digest?, ?gtable?, ?reshape2?, ?scales?, ?proto?

trying URL 'http://cran.at.r-project.org/src/contrib/colorspace_1.2-4.zip'
Error in download.file(url, destfile, method, mode = "wb", ...) :
  cannot open URL 'http://cran.at.r-project.org/src/contrib/colorspace_1.2-4.zip'
In addition: Warning message:
In download.file(url, destfile, method, mode = "wb", ...) :
  cannot open: HTTP status was '404 Not Found'
Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
  download of package ?colorspace? failed
....

Before I start to disturb our IT I just want to know what could be the issue. AFAIK I did not change anything on my PC. In previous R-devel version I used this package installation worked (and still works)

> utils:::menuInstallPkgs()
--- Please select a CRAN mirror for use in this session ---
trying URL 'http://cran.at.r-project.org/bin/windows/contrib/3.2/mice_2.22.zip'
Content type 'application/zip' length 1148843 bytes (1.1 Mb)
opened URL
downloaded 1.1 Mb

package ?mice? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Documents and Settings\PikalP\Local Settings\Temp\RtmpgZuQB3\downloaded_packages

> version
               _
platform       i386-w64-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status         Under development (unstable)
major          3
minor          2.0
year           2014
month          07
day            16
svn rev        66175
language       R
version.string R Under development (unstable) (2014-07-16 r66175)
nickname       Unsuffered Consequences

can you suggest what changed between those 2 R versions what prevents me in convenient installation of packages.

Petr

BTW. I can install packages manually but when there are many dependencies it can be rather tricky.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.CA.us  Thu Feb 12 17:47:29 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 12 Feb 2015 11:47:29 -0500
Subject: [R] Installing RStudio
In-Reply-To: <54DC8D10020000CB00122E61@smtp.medicine.umaryland.edu>
References: <1316544333.122505.1423141062041.JavaMail.yahoo@mail.yahoo.com>
	<818837787-1423141688-cardhu_decombobulator_blackberry.rim.net-1580041060-@b12.c6.bise7.blackberry>
	<54D372F7.8030108@univ-reims.fr>
	<54DC8D10020000CB00122E61@smtp.medicine.umaryland.edu>
Message-ID: <371C7884-0C74-493D-81A7-C09F1547CD3D@dcn.davis.CA.us>

Ah, ask in the RStudio support area?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 12, 2015 11:22:56 AM EST, John Sorkin <JSOrkin at grecc.umaryland.edu> wrote:
>Windows 7, 64-bit.
> 
>I am trying to install RStudio. Before installing RStudio, I installed
>R 3.1.2. During the installation or R, I installled (as per the
>default) 32- and 64-bit packages. When I tried to install RStudio, I
>received the message
>R does not appear to be installed. Please install R before using
>RStudio.
>I know R is installed, beacuse I am able to run R.
>Can anyone suggest what I can do to get RStudio installed?
>Thank you
>John
> 
>John David Sorkin M.D., Ph.D.
>Professor of Medicine
>Chief, Biostatistics and Informatics
>University of Maryland School of Medicine Division of Gerontology and
>Geriatric Medicine
>Baltimore VA Medical Center
>10 North Greene Street
>GRECC (BT/18/GR)
>Baltimore, MD 21201-1524
>(Phone) 410-605-7119
>(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>
>Confidentiality Statement:
>This email message, including any attachments, is for t...{{dropped:12}}


From jdnewmil at dcn.davis.CA.us  Thu Feb 12 18:14:46 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 12 Feb 2015 12:14:46 -0500
Subject: [R] problems with packages installation
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FD21@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FD21@SRVEXCHMBX.precheza.cz>
Message-ID: <7134618E-DDD1-4D77-AC99-3E5844F5438D@dcn.davis.CA.us>

Time to (re)read the Posting Guide... questions about unreleased versions of R are off topic here. Go to R-devel.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 12, 2015 11:40:48 AM EST, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Dear all
>
>I just switched to new version
>
>> version
>               _
>platform       i386-w64-mingw32
>arch           i386
>os             mingw32
>system         i386, mingw32
>status         Under development (unstable)
>major          3
>minor          2.0
>year           2015
>month          02
>day            11
>svn rev        67792
>language       R
>version.string R Under development (unstable) (2015-02-11 r67792)
>nickname       Unsuffered Consequences
>
>and started to have problems with installing packages through utils
>
>> setInternet2(TRUE)
>> utils:::menuInstallPkgs()
>--- Please select a CRAN mirror for use in this session ---
>also installing the dependencies ?colorspace?, ?Rcpp?, ?stringr?,
>?RColorBrewer?, ?dichromat?, ?munsell?, ?labeling?, ?plyr?, ?digest?,
>?gtable?, ?reshape2?, ?scales?, ?proto?
>
>trying URL
>'http://cran.at.r-project.org/src/contrib/colorspace_1.2-4.zip'
>Error in download.file(url, destfile, method, mode = "wb", ...) :
>cannot open URL
>'http://cran.at.r-project.org/src/contrib/colorspace_1.2-4.zip'
>In addition: Warning message:
>In download.file(url, destfile, method, mode = "wb", ...) :
>  cannot open: HTTP status was '404 Not Found'
>Warning in download.packages(pkgs, destdir = tmpd, available =
>available,  :
>  download of package ?colorspace? failed
>....
>
>Before I start to disturb our IT I just want to know what could be the
>issue. AFAIK I did not change anything on my PC. In previous R-devel
>version I used this package installation worked (and still works)
>
>> utils:::menuInstallPkgs()
>--- Please select a CRAN mirror for use in this session ---
>trying URL
>'http://cran.at.r-project.org/bin/windows/contrib/3.2/mice_2.22.zip'
>Content type 'application/zip' length 1148843 bytes (1.1 Mb)
>opened URL
>downloaded 1.1 Mb
>
>package ?mice? successfully unpacked and MD5 sums checked
>
>The downloaded binary packages are in
>C:\Documents and Settings\PikalP\Local
>Settings\Temp\RtmpgZuQB3\downloaded_packages
>
>> version
>               _
>platform       i386-w64-mingw32
>arch           i386
>os             mingw32
>system         i386, mingw32
>status         Under development (unstable)
>major          3
>minor          2.0
>year           2014
>month          07
>day            16
>svn rev        66175
>language       R
>version.string R Under development (unstable) (2014-07-16 r66175)
>nickname       Unsuffered Consequences
>
>can you suggest what changed between those 2 R versions what prevents
>me in convenient installation of packages.
>
>Petr
>
>BTW. I can install packages manually but when there are many
>dependencies it can be rather tricky.
>
>
>________________________________
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
>ze strany p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>zn?m?.
>
>This e-mail and any documents attached to it may be confidential and
>are intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its
>sender. Delete the contents of this e-mail with all attachments and its
>copies from your system.
>If you are not the intended recipient of this e-mail, you are not
>authorized to use, disseminate, copy or disclose this e-mail in any
>manner.
>The sender of this e-mail shall not be liable for any possible damage
>caused by modifications of the e-mail or by delay with transfer of the
>email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into
>a contract in any time, for any reason, and without stating any
>reasoning.
>- if the e-mail contains an offer, the recipient is entitled to
>immediately accept such offer; The sender of this e-mail (offer)
>excludes any acceptance of the offer on the part of the recipient
>containing any amendment or variation.
>- the sender insists on that the respective contract is concluded only
>upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to
>enter into any contracts on behalf of the company except for cases in
>which he/she is expressly authorized to do so in writing, and such
>authorization or power of attorney is submitted to the recipient or the
>person represented by the recipient, or the existence of such
>authorization is known to the recipient of the person represented by
>the recipient.
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Thu Feb 12 18:27:20 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 12 Feb 2015 11:27:20 -0600
Subject: [R] Shiny User Group
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686CF38BBF8@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686CF38BBF8@DC1VEX10MB001.air.org>
Message-ID: <CABdHhvEiMVT+tMcp1fbEMjRAfK2F54k0o50YkJehijB_J2WOag@mail.gmail.com>

Maybe https://groups.google.com/forum/#!forum/shiny-discuss ?

Hadley

On Thu, Feb 12, 2015 at 9:07 AM, Doran, Harold <HDoran at air.org> wrote:
> I found a google user group for shiny, and am curious if there is an SIG as well. Didn't see one in my searches, but looking for an active place to ask questions and share code.
>
> Thanks.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From rmh at temple.edu  Thu Feb 12 18:29:08 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 12 Feb 2015 12:29:08 -0500
Subject: [R] problems with packages installation
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FD21@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FD21@SRVEXCHMBX.precheza.cz>
Message-ID: <CAGx1TMDbsPMt_1vHh-KaBbrfwU5o8zMCDgeY6+F3uORtrX2OsQ@mail.gmail.com>

You should install Rtools first.

Then you will need to use
install.packages(c(A"","B","etc"), type="source", dependencies=TRUE)

Rich

On Thu, Feb 12, 2015 at 11:40 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Dear all
>
> I just switched to new version
>
>> version
>                _
> platform       i386-w64-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status         Under development (unstable)
> major          3
> minor          2.0
> year           2015
> month          02
> day            11
> svn rev        67792
> language       R
> version.string R Under development (unstable) (2015-02-11 r67792)
> nickname       Unsuffered Consequences
>
> and started to have problems with installing packages through utils
>
>> setInternet2(TRUE)
>> utils:::menuInstallPkgs()
> --- Please select a CRAN mirror for use in this session ---
> also installing the dependencies ?colorspace?, ?Rcpp?, ?stringr?, ?RColorBrewer?, ?dichromat?, ?munsell?, ?labeling?, ?plyr?, ?digest?, ?gtable?, ?reshape2?, ?scales?, ?proto?
>
> trying URL 'http://cran.at.r-project.org/src/contrib/colorspace_1.2-4.zip'
> Error in download.file(url, destfile, method, mode = "wb", ...) :
>   cannot open URL 'http://cran.at.r-project.org/src/contrib/colorspace_1.2-4.zip'
> In addition: Warning message:
> In download.file(url, destfile, method, mode = "wb", ...) :
>   cannot open: HTTP status was '404 Not Found'
> Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
>   download of package ?colorspace? failed
> ....
>
> Before I start to disturb our IT I just want to know what could be the issue. AFAIK I did not change anything on my PC. In previous R-devel version I used this package installation worked (and still works)
>
>> utils:::menuInstallPkgs()
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'http://cran.at.r-project.org/bin/windows/contrib/3.2/mice_2.22.zip'
> Content type 'application/zip' length 1148843 bytes (1.1 Mb)
> opened URL
> downloaded 1.1 Mb
>
> package ?mice? successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
>         C:\Documents and Settings\PikalP\Local Settings\Temp\RtmpgZuQB3\downloaded_packages
>
>> version
>                _
> platform       i386-w64-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status         Under development (unstable)
> major          3
> minor          2.0
> year           2014
> month          07
> day            16
> svn rev        66175
> language       R
> version.string R Under development (unstable) (2014-07-16 r66175)
> nickname       Unsuffered Consequences
>
> can you suggest what changed between those 2 R versions what prevents me in convenient installation of packages.
>
> Petr
>
> BTW. I can install packages manually but when there are many dependencies it can be rather tricky.
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maity at math.niu.edu  Thu Feb 12 16:05:13 2015
From: maity at math.niu.edu (arnabkm2007)
Date: Thu, 12 Feb 2015 07:05:13 -0800 (PST)
Subject: [R] Censoring in R2OpenBUGS
Message-ID: <1423753513965-4703160.post@n4.nabble.com>

Hi, 

I am trying to run the following model for OpenBUGS and want to use
R2OpenBUGS package. The model specifies weibull distribution for censored
data. 

  
  weibull.model <- function() 
  { 
    
    for(i in 1:n) 
    { 
      
      exp.alpha[i] ~ dgamma(a.alpha, b.alpha) 
      alpha[i] <- log(exp.alpha[i]) 
      
      linear.part[i] <- alpha[i] + inprod(nu[ ], x[i, ]) 
      lambda[i] <- exp(linear.part[i]) 
      
      time[i] ~ (dweib(shape, lambda[i]) C(censored.time[i], )) 
      
    } 
    
    shape ~ dgamma(a.shape, b.shape) 
    
    for(j in 1:p) 
    { 
      
      beta[j]  ~ dnorm(prior.mean, prior.tau) 
      gamma[j] ~ dbern(pi[j]) 
      pi[j]    ~ dbeta(1, 1) 
      nu[j]   <- beta[j] * gamma[j] 
      
    } 
    
  } 
  


But R is throwing the following error. 

Error: unexpected symbol in: 
"       
      time[i] ~ (dweib(shape, lambda[i]) C" 

Any help regarding this will be appreciated. 

Thanks & Regards, 
Arnab 


Arnab Kumar Maity 
Graduate Teaching Assistant 
Division of Statistics 
Northern Illinois University 
DeKalb, IL 60115 
Email: maity at math.niu.edu 
Ph:     779-777-3428 



--
View this message in context: http://r.789695.n4.nabble.com/Censoring-in-R2OpenBUGS-tp4703160.html
Sent from the R help mailing list archive at Nabble.com.


From michael.eisenring at agroscope.admin.ch  Thu Feb 12 16:50:22 2015
From: michael.eisenring at agroscope.admin.ch (michael.eisenring at agroscope.admin.ch)
Date: Thu, 12 Feb 2015 15:50:22 +0000
Subject: [R] WG: horizontal bar plots for CI visualization
Message-ID: <9EFCA4A987B0494CBFFB5CD071756D0026B3F951@WBF-C7002.bk.evdad.admin.ch>

An embedded and charset-unspecified text was scrubbed...
Name: CI_data.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150212/346aa82f/attachment.txt>

From xavier.chiriboga at unine.ch  Thu Feb 12 17:19:06 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Thu, 12 Feb 2015 16:19:06 +0000
Subject: [R] SIMPLE question
Message-ID: <7B64C8E017B948419F014C915AA6D7342A034EE8@mail-mbx-04.UNINE.CH>

Hi everybody!



I want to do a boxcox transformation, but I got this:



Error: could not find function "boxcox"



What can I do? I am using R studio.



Thanks!!!



Xavier


From bickis at snoopy.usask.ca  Thu Feb 12 17:26:26 2015
From: bickis at snoopy.usask.ca (Professor Bickis)
Date: Thu, 12 Feb 2015 08:26:26 -0800
Subject: [R] Sorting Surv objects
Message-ID: <80DD3A92-AC92-408E-B1A3-10692F406426@snoopy.usask.ca>

It seems that Surv objects do not sort correctly.   This seems to be a bug.  Anyone else found this?

> survival.data
[1] 4+ 3  1+ 2  5+
> class(survival.data)
[1] "Surv"
> sort(survival.data)
[1] 2  1+ 4+ 3  5+

An easy work-around is to define a function sort.Surv

sort.Surv<-function(a){ord<-order(a[,1])
+ a[ord]}

> sort(survival.data)
[1] 1+ 2  3  4+ 5+

I am using R 3.1.2 GUI 1.65 Mavericks build (6833) running under Yosemite.


From maity at math.niu.edu  Thu Feb 12 17:34:23 2015
From: maity at math.niu.edu (ARNAB KR MAITY)
Date: Thu, 12 Feb 2015 10:34:23 -0600
Subject: [R] Installing RStudio
In-Reply-To: <54DC8D10020000CB00122E61@smtp.medicine.umaryland.edu>
References: <1316544333.122505.1423141062041.JavaMail.yahoo@mail.yahoo.com>
	<818837787-1423141688-cardhu_decombobulator_blackberry.rim.net-1580041060-@b12.c6.bise7.blackberry>
	<54D372F7.8030108@univ-reims.fr>
	<54DC8D10020000CB00122E61@smtp.medicine.umaryland.edu>
Message-ID: <CANjU7dm1PUjo-pHkEcYdPupwf9FH7A=myjQeKaGT0y9hGiTfhA@mail.gmail.com>

Dear John,


I think you have to specify the directory of R in the R-studio installation
process. Somehow the installation wizard is unable to find the address of R
in your system.

Thanks & Regards,
Arnab



Arnab Kumar Maity
Graduate Teaching Assistant
Division of Statistics
Northern Illinois University
DeKalb, IL 60115
Email: maity at math.niu.edu
Ph:     779-777-3428

On Thu, Feb 12, 2015 at 10:22 AM, John Sorkin <JSOrkin at grecc.umaryland.edu>
wrote:

> Windows 7, 64-bit.
>
> I am trying to install RStudio. Before installing RStudio, I installed R
> 3.1.2. During the installation or R, I installled (as per the default) 32-
> and 64-bit packages. When I tried to install RStudio, I received the message
> R does not appear to be installed. Please install R before using RStudio.
> I know R is installed, beacuse I am able to run R.
> Can anyone suggest what I can do to get RStudio installed?
> Thank you
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From ruipbarradas at sapo.pt  Thu Feb 12 18:53:48 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 12 Feb 2015 17:53:48 +0000
Subject: [R] SIMPLE question
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A034EE8@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A034EE8@mail-mbx-04.UNINE.CH>
Message-ID: <54DCE8AC.4050406@sapo.pt>

Hello,

Try the following.

install.packages("sos")  #if not yet

Then,

library(sos)
findFn("boxcox")


There are several hits, maybe you could start with package car

Hope this helps,

Rui Barradas

Em 12-02-2015 16:19, CHIRIBOGA Xavier escreveu:
> Hi everybody!
>
>
>
> I want to do a boxcox transformation, but I got this:
>
>
>
> Error: could not find function "boxcox"
>
>
>
> What can I do? I am using R studio.
>
>
>
> Thanks!!!
>
>
>
> Xavier
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Thu Feb 12 19:01:11 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 12 Feb 2015 13:01:11 -0500
Subject: [R] 32bit R303 calls external C functions
In-Reply-To: <A29EC196EE32C64389369F6BF03B66C87A8EFEB5C0@IBIUSMBSB.ibi.com>
References: <A29EC196EE32C64389369F6BF03B66C87A8EFEB5C0@IBIUSMBSB.ibi.com>
Message-ID: <54DCEA67.8050902@gmail.com>

On 12/02/2015 11:08 AM, Li, Yan wrote:
> Dear All,
>
> I build a R package which will need to call external C functions. I registered the C functions in the NAMESPACE file and include 32bit and 64bit dlls in the packages. If I load the package in 64bit R and calls the external C functions, it works fine. However if I load the package in 32bit R and call the external C functions, it either does not work properly or gives back error message saying cannot find the external C functions.
>
> When I built the same package in R2.15.1, there is no such issue.
>
> I checked the update news for R303 and found most .C is replaced by .Call. I modified the code but the package cannot be loaded and R ended abnormally.
>
> Does anyone know if there any difference of 32bit R303 calling external C from 64bitR303? Thank you!

There's no R303; the current version is 3.1.2.  So if you meant 3.0.3, 
I'd suggest upgrading.  If you meant something else, you're probably in 
the wrong place.

For 3.1.2, there are big differences:  32 bit R can't call 64 bit .dlls 
and vice versa.   You can either install the package from source in both 
versions, or arrange to compile both 32 bit and 64 bit dlls, in which 
case both versions can use the binary of the package.

If you've already done all that, then you'll need to give more details, 
e.g. access to the source for the package, to get more specific help.

Duncan Murdoch


From Yan_Li at ibi.com  Thu Feb 12 19:07:02 2015
From: Yan_Li at ibi.com (Li, Yan)
Date: Thu, 12 Feb 2015 13:07:02 -0500
Subject: [R] 32bit R303 calls external C functions
In-Reply-To: <54DCEA67.8050902@gmail.com>
References: <A29EC196EE32C64389369F6BF03B66C87A8EFEB5C0@IBIUSMBSB.ibi.com>
	<54DCEA67.8050902@gmail.com>
Message-ID: <A29EC196EE32C64389369F6BF03B66C87A8EFEB7D3@IBIUSMBSB.ibi.com>

I meant R3.0.3. I need this package working in R3.0.3.

I have 32bit and 64bit dlls both included in the package.


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Thursday, February 12, 2015 1:01 PM
To: Li, Yan; r-help at r-project.org
Subject: Re: [R] 32bit R303 calls external C functions

On 12/02/2015 11:08 AM, Li, Yan wrote:
> Dear All,
>
> I build a R package which will need to call external C functions. I registered the C functions in the NAMESPACE file and include 32bit and 64bit dlls in the packages. If I load the package in 64bit R and calls the external C functions, it works fine. However if I load the package in 32bit R and call the external C functions, it either does not work properly or gives back error message saying cannot find the external C functions.
>
> When I built the same package in R2.15.1, there is no such issue.
>
> I checked the update news for R303 and found most .C is replaced by .Call. I modified the code but the package cannot be loaded and R ended abnormally.
>
> Does anyone know if there any difference of 32bit R303 calling external C from 64bitR303? Thank you!

There's no R303; the current version is 3.1.2.  So if you meant 3.0.3, I'd suggest upgrading.  If you meant something else, you're probably in the wrong place.

For 3.1.2, there are big differences:  32 bit R can't call 64 bit .dlls 
and vice versa.   You can either install the package from source in both 
versions, or arrange to compile both 32 bit and 64 bit dlls, in which case both versions can use the binary of the package.

If you've already done all that, then you'll need to give more details, e.g. access to the source for the package, to get more specific help.

Duncan Murdoch


From arnaud.gaboury at gmail.com  Thu Feb 12 19:12:48 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Thu, 12 Feb 2015 19:12:48 +0100
Subject: [R] gsub : replace regex pattern with values from another
	data.frame
In-Reply-To: <CAK1hC9uk3dinkEwNF1e9ji=2R2PaQZfbbqN==xeU1G-zDvwzAQ@mail.gmail.com>
References: <CAK1hC9uk3dinkEwNF1e9ji=2R2PaQZfbbqN==xeU1G-zDvwzAQ@mail.gmail.com>
Message-ID: <CAK1hC9tbF7O2naKY2n_CK0QvJDDcJgWPD9w289pCJfyK0KwW8g@mail.gmail.com>

On Thu, Feb 12, 2015 at 3:40 PM, arnaud gaboury
<arnaud.gaboury at gmail.com> wrote:
> I have two df (and dt):
>
> df1
> structure(list(name = c("poisonivy", "poisonivy", "poisonivy",
> "poisonivy", "poisonivy", "poisonivy", "poisonivy", "poisonivy",
> "cruzecontrol", "agreenmamba", "agreenmamba", "vairis", "vairis",
> "vairis", "vairis", "vairis", "vairis", "xaeth"), text = c("ok",
> "need items ?", "i didn't submit pass codes for a long now",
> "ok", "<@U03AEKYL4>: what app are you talking about ?", "some testing
> with my irc client",
> "ha ha sorry", "for me there is no such question", "Lol.",
> "<@U03AEKWTL|agreenmamba> uploaded a file:
> <https://enlightened.slack.com/files/agreenmamba/F03KGRF3W/screenshot_2015-02-09-14-31-15.png|regarding:
> should I stay or should I go?>",
> "<@U032FHV3S> <http://youtu.be/oGIFublvDes>", "ok, see you around",
> "yeah, I had a procrastination rush so I started to decode a little",
> "<http://ingress.com/intel|ingress.com/intel> when you submit passcodes",
> "intel", "what is the cooldown time or how does it work...;",
> "anybody knows how does \"Passcode circuitry too hot. Wait for cool
> down to enter another passcode.\" works?",
> "and people told that agent their geocities experience would never
> amount to anything (the convo yesterday) "
> ), ts = c("1423594336.000138", "1423594311.000136", "1423594294.000135",
> "1423594258.000133", "1423594244.000131", "1423497058.000127",
> "1423497041.000126", "1423478555.000123", "1423494427.000125",
> "1423492370.000124", "1423478364.000121", "1423594358.000139",
> "1423594329.000137", "1423594264.000134", "1423594251.000132",
> "1423592204.000130", "1423592174.000129", "1423150354.000112"
> )), .Names = c("name", "text", "ts"), class = c("data.table",
> "data.frame"), row.names = c(NA, -18L))
>
> df2
> structure(list(id = c("U03KH8Z52", "U02AF1DTJ", "U02AF0ZT8",
> "U03AEKWTL", "U02BCJH0G", "U033YA1MS", "U029QMCRR", "U03H139M5",
> "U02AET1D0", "U02A6U41Z", "U02B5T4CX", "U02B2QU4R", "U03F0LQ5X",
> "U03JNFKLY", "U02ASMBMQ", "U029QLQC7", "U03AEMBQU", "U02B4D3Q1",
> "U02AGDC14", "U029A467C", "U02A7NFG6", "U02AESPPL", "U02AQANK7",
> "U03ADJDFK", "U03EYR0KB", "U02AW7Q5Q", "U02AE8RKD", "U02FT84BS",
> "U02B25M3B", "U03EZDQT7", "U02AECKFF", "U03H2691M", "U02DWTJ5V",
> "U02AFTAHH", "U029QQEPM", "U03C51Z42", "U02CAK2CV", "U03AK21DP",
> "U03FFN8ED", "U02B23V03", "U029T2143", "U02C1LEEX", "U03AF2QH2",
> "U03E0GN0S", "U03AG20R9", "U02AES8S2", "U02AG64S7", "U02B5A0R7",
> "U02AS4SLR", "U03C2SG0R", "U03AV7CCW", "U032XPFDU", "U03AUKSSV",
> "U02C2A61Y", "U02AESHJQ", "U02BLSKHU", "U02E34WM6", "U03AK6P26",
> "U02E6ADRZ", "U03FCDQ50", "U03EW1CC5", "U02BL0DBD", "U02FHQZ6D",
> "U02B47T63", "U03H2TTQP", "U03AVP71V", "U03JLV38V", "U02E39HAY",
> "U02AE5281", "U032FHV3S", "U03AL2096", "U02ARUG6M", "U02AECRSP",
> "U02B42XG4", "U03AFQZNS", "U02AE7H41", "U03G9UNTG", "U02GEQ0E6",
> "U02AGLE5A", "U02BQTRC9", "U03H0J6GS", "U02B3D27F", "U02AEKTHV",
> "U02C52YN3", "U02E33MUW", "U03AKUT85", "U03B53EHG", "U02FBN38P",
> "U03AH3E5W", "U02B5PLE0", "U02AS4RCK", "U03ANE1GZ", "U02E8LZQB",
> "U03EPGJ98", "U02E3N220", "U03AEKYL4", "U02AE7HT1", "U02C1RR3G",
> "U03JH408J", "U03KL0FKN", "U02B44R92", "U03EURWGX"), name = c("10k_affair",
> "1upwuzhere", "4xcss", "agreenmamba", "ait109", "arly69", "azkop13",
> "barcik75", "bigolnob", "blackrose", "blink619", "bobaloo23",
> "bodger", "bomb", "bootswithdefer", "brandizzle", "bregalad",
> "camon", "celticrain", "ch3mical", "checksum", "cocothunder",
> "cruxicon", "cruzecontrol", "crystalskunk", "cscheetah", "dabcelin",
> "deelicious", "delthanar", "drkaosdk", "droidenl-joe", "dukeceph",
> "fillerbunny", "flickohmsford", "flyingg0d", "garaxiel", "goby9",
> "gymbal", "hideandseek", "hobojr", "ijackportals", "invalidcharactr",
> "itso9", "j0shs", "jarvis", "jc0mm5", "jencyberchic", "jimbobradyson",
> "joespr0cket", "jostrander", "jueliet", "karlashi", "khan99",
> "kingkonn0r", "krispycridder", "kritickalmass", "lawgiver", "maxcorbett",
> "memory556", "meta000x", "minkovsky", "mistylady", "mstephans",
> "mstrinity", "nocarryr", "ollietronic", "philistine11", "pickledpickles",
> "piercingsbykris", "poisonivy", "raugmor", "remarks999", "rheds77",
> "rhinz", "rigiritter", "robbie0017", "rohdef", "ryoziya", "s4n1ty",
> "sacredcow133", "samwill", "sgtlemonpepper", "sivan", "spline9",
> "starwolf", "stueliueli", "sweetiris", "swift2plunder", "swissphoenix",
> "synyck", "test", "therug", "tinja551", "trulyjuan", "twinster",
> "vairis", "vinylz3ro", "watervirus", "xaeth", "yagamiyukari",
> "zafo", "zexium")), .Names = c("id", "name"), class = c("data.table",
> "data.frame"), row.names = c(NA, -102L))
>
> I need to replace this regex pattern in df1 :
> (?<=<@)[^|]{9}(?=>|) by its corresponding name from df2.
>
> E.g : if <@U03KH8Z52> is found in df1, then I want to replace it by
> the "name" which correspond to this id in df2., in this case
> 10k_affair
>
> I know of replace an expression with gsub:
> gsub('(?<=<@)[^|]{9}(?=>|)', 'toto', df1, perl = T)
> but I have no idea how to replace it with value from another df.
>
> Thank you for hints

I am gathering some pieces of the puzzles.

> regmatches(df1$text,regexpr('(?<=<@)[^|]{9}(?=>|)',df1$text, perl = T))
[1] "U032FHV3S" "U03AEKWTL" "U03AEKYL4"
The above commands extract the needed pattern

df2[grep("U032FHV3S",df2$id),][[2]]
[1] "poisonivy"
The above command returns the name in the same row than the id. I need
more than one name (in my case, I need 3)

Shall I now write a loop and get a list of my needed name ? Pseudo
code would be something like:

for i %in% regmatches(df1$text,regexpr('(?<=<@)[^|]{9}(?=>|)',df1$text,
perl = T))
                 df2[grep("i",df2$id),][[2]]


Thank you for hint about how I shall proceed.

-- 

google.com/+arnaudgabourygabx


From hyiltiz at gmail.com  Thu Feb 12 19:28:17 2015
From: hyiltiz at gmail.com (=?UTF-8?Q?H=C3=B6rmetjan_Yiltiz?=)
Date: Fri, 13 Feb 2015 02:28:17 +0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <4B1AFADE554.0000031Bjrkrideau@inbox.com>
References: <cam5fmsmaidzgj+d5drptguhbm4v1tr6aljjtdjskqcmfs5w49w@mail.gmail.com>
	<4ad1edc7c1f.00000299jrkrideau@inbox.com>
	<CAM5FmSPBv2v23ojBj=zsP4hi8ONhh-rBY2G1UTxX-sBKQVEiFA@mail.gmail.com>
	<4B1AFADE554.0000031Bjrkrideau@inbox.com>
Message-ID: <CAM5FmSM-jucvYY6pZXfsvDUZeK2+GQg8SMti++LxFG3SL0NPQg@mail.gmail.com>

I did not know the SVG file did not come through. I thought SVG should be
able to pass through the filter. Here is a PDF file along with an PNG.
Guess one of them should be able to pass.

???
========================
He who is worthy to receive his days and nights is worthy to receive* all
else* from you (and me).
                                                 The Prophet, Gibran Kahlil


On Fri, Feb 13, 2015 at 12:04 AM, John Kane <jrkrideau at inbox.com> wrote:

>
> I'm a bit blind today. I read df as a dput() .
>
> John Kane
> Kingston ON Canada
>
> -----Original Message-----
> From: hyiltiz at gmail.com
> Sent: Thu, 12 Feb 2015 23:38:01 +0800
> To: jrkrideau at inbox.com
> Subject: Re: [R] ggplot2 shifting bars to only overlap in groups
>
> You are most likely simply not running the whole lines of code: note that
> the first line is:
>
> N = 32
>
>  Best
> ?
> ========================
> He who is worthy to receive his days and nights is worthy to receive* all
> else* from you (and me).
>                                                  The Prophet, Gibran Kahlil
>
> On Thu, Feb 12, 2015 at 11:31 PM, John Kane <jrkrideau at inbox.com> wrote:
>
>         I am gettting the error"
>  Error in rep_len(rep.int [http://rep.int](seq_len(n), rep.int [
> http://rep.int](k, n)), length) :
>    object 'N' not found
>
>  Also your image did not come through.  Try sending it as a pdf file.
>
>  when I try to create
>  df<- data.frame(gender=gl(2,1,N, c("male","female")),
>            direction=gl(2,2,N, c("up","down")),
>            condition=gl(4,4,N, c("c1","c2","c3","c4")),
>            location=gl(2,16,N, c("east","west")),
>            t=rnorm(N, 1, 0.5),
>            ci=abs(rnorm(N, 0, 0.2)))
>
>  John Kane
>  Kingston ON Canada
>
>  > -----Original Message-----
>  > From: hyiltiz at gmail.com
>  > Sent: Thu, 12 Feb 2015 22:08:36 +0800
>  > To: r-help at r-project.org
>  > Subject: [R] ggplot2 shifting bars to only overlap in groups
>  >
>  > Hi all,
>  >
>  > I have four factors for a continuous time variable along with its
>  > confidence interval. I would like to produce a publication quality error
>  > bar chart that is clear to understand. For now, I used colors, x axis
>  > position, facets and alpha level to distinguish them.
>  >
>  > I would like to overlap each pairs of bars with the same color a bit as
> a
>  > group, but not overlap each and every bars with each other.
>  >
>  > Here is a minimal example:
>  >
>  > N = 32
>  > df<- data.frame(gender=gl(2,1,N, c("male","female")),
>  >           direction=gl(2,2,N, c("up","down")),
>  >           condition=gl(4,4,N, c("c1","c2","c3","c4")),
>  >           location=gl(2,16,N, c("east","west")),
>  >           t=rnorm(N, 1, 0.5),
>  >           ci=abs(rnorm(N, 0, 0.2)))
>  > pp <-
>  >   ggplot(df, aes(x=gender, y=t, fill=condition, alpha=direction)) +
>  >   facet_grid(location~.) +
>  >   geom_bar(position=position_dodge(.9), stat="identity", color="black")
> +
>  >   geom_errorbar(aes(ymin=t-ci, ymax=t+ci),
>  >                 width=.2,                    # Width of the error bars
>  >                 position=position_dodge(.9)) +
>  >   scale_alpha_discrete(range= c(0.4, 1))
>  > pp
>  >
>  >
>  >
>  > In the attachment, I have added the output figure, while manually
> editing
>  > the SVG file to make the lower-left group of bars to make them as I
>  > wanted.
>  > (The spacing in between each pair is not necessarily required.)
>  >
>  >
>  > Best
>  > ?
>  > ========================
>  > He who is worthy to receive his days and nights is worthy to receive*
> all
>  > else* from you (and me).
>  >                                                  The Prophet, Gibran
>  > Kahlil
>
> > ______________________________________________
>  > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  > https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help]
>  > PLEASE do read the posting guide
>  > http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html]
>  > and provide commented, minimal, self-contained, reproducible code.
>
>  ____________________________________________________________
>  Can't remember your password? Do you need a strong and secure password?
>  Use Password manager! It stores your passwords & protects your account.
>  Check it out at http://mysecurelogon.com/password-manager [
> http://mysecurelogon.com/password-manager]
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and
> family!
> Visit http://www.inbox.com/photosharing to find out more!
>
>
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: DodgeInGroup.pdf
Type: application/pdf
Size: 27457 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150213/9eecf0a8/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: DodgeInGroup.png
Type: image/png
Size: 31062 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150213/9eecf0a8/attachment.png>

From arnaud.gaboury at gmail.com  Thu Feb 12 19:31:02 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Thu, 12 Feb 2015 19:31:02 +0100
Subject: [R] gsub : replace regex pattern with values from another
	data.frame
In-Reply-To: <CAK1hC9tbF7O2naKY2n_CK0QvJDDcJgWPD9w289pCJfyK0KwW8g@mail.gmail.com>
References: <CAK1hC9uk3dinkEwNF1e9ji=2R2PaQZfbbqN==xeU1G-zDvwzAQ@mail.gmail.com>
	<CAK1hC9tbF7O2naKY2n_CK0QvJDDcJgWPD9w289pCJfyK0KwW8g@mail.gmail.com>
Message-ID: <CAK1hC9tGjXHMj-eKYbCaL1WQPwaghQ6Hx7gZ6HJBoCHxcqmPSg@mail.gmail.com>

On Thu, Feb 12, 2015 at 7:12 PM, arnaud gaboury
<arnaud.gaboury at gmail.com> wrote:
> On Thu, Feb 12, 2015 at 3:40 PM, arnaud gaboury
> <arnaud.gaboury at gmail.com> wrote:
>> I have two df (and dt):
>>
>> df1
>> structure(list(name = c("poisonivy", "poisonivy", "poisonivy",
>> "poisonivy", "poisonivy", "poisonivy", "poisonivy", "poisonivy",
>> "cruzecontrol", "agreenmamba", "agreenmamba", "vairis", "vairis",
>> "vairis", "vairis", "vairis", "vairis", "xaeth"), text = c("ok",
>> "need items ?", "i didn't submit pass codes for a long now",
>> "ok", "<@U03AEKYL4>: what app are you talking about ?", "some testing
>> with my irc client",
>> "ha ha sorry", "for me there is no such question", "Lol.",
>> "<@U03AEKWTL|agreenmamba> uploaded a file:
>> <https://enlightened.slack.com/files/agreenmamba/F03KGRF3W/screenshot_2015-02-09-14-31-15.png|regarding:
>> should I stay or should I go?>",
>> "<@U032FHV3S> <http://youtu.be/oGIFublvDes>", "ok, see you around",
>> "yeah, I had a procrastination rush so I started to decode a little",
>> "<http://ingress.com/intel|ingress.com/intel> when you submit passcodes",
>> "intel", "what is the cooldown time or how does it work...;",
>> "anybody knows how does \"Passcode circuitry too hot. Wait for cool
>> down to enter another passcode.\" works?",
>> "and people told that agent their geocities experience would never
>> amount to anything (the convo yesterday) "
>> ), ts = c("1423594336.000138", "1423594311.000136", "1423594294.000135",
>> "1423594258.000133", "1423594244.000131", "1423497058.000127",
>> "1423497041.000126", "1423478555.000123", "1423494427.000125",
>> "1423492370.000124", "1423478364.000121", "1423594358.000139",
>> "1423594329.000137", "1423594264.000134", "1423594251.000132",
>> "1423592204.000130", "1423592174.000129", "1423150354.000112"
>> )), .Names = c("name", "text", "ts"), class = c("data.table",
>> "data.frame"), row.names = c(NA, -18L))
>>
>> df2
>> structure(list(id = c("U03KH8Z52", "U02AF1DTJ", "U02AF0ZT8",
>> "U03AEKWTL", "U02BCJH0G", "U033YA1MS", "U029QMCRR", "U03H139M5",
>> "U02AET1D0", "U02A6U41Z", "U02B5T4CX", "U02B2QU4R", "U03F0LQ5X",
>> "U03JNFKLY", "U02ASMBMQ", "U029QLQC7", "U03AEMBQU", "U02B4D3Q1",
>> "U02AGDC14", "U029A467C", "U02A7NFG6", "U02AESPPL", "U02AQANK7",
>> "U03ADJDFK", "U03EYR0KB", "U02AW7Q5Q", "U02AE8RKD", "U02FT84BS",
>> "U02B25M3B", "U03EZDQT7", "U02AECKFF", "U03H2691M", "U02DWTJ5V",
>> "U02AFTAHH", "U029QQEPM", "U03C51Z42", "U02CAK2CV", "U03AK21DP",
>> "U03FFN8ED", "U02B23V03", "U029T2143", "U02C1LEEX", "U03AF2QH2",
>> "U03E0GN0S", "U03AG20R9", "U02AES8S2", "U02AG64S7", "U02B5A0R7",
>> "U02AS4SLR", "U03C2SG0R", "U03AV7CCW", "U032XPFDU", "U03AUKSSV",
>> "U02C2A61Y", "U02AESHJQ", "U02BLSKHU", "U02E34WM6", "U03AK6P26",
>> "U02E6ADRZ", "U03FCDQ50", "U03EW1CC5", "U02BL0DBD", "U02FHQZ6D",
>> "U02B47T63", "U03H2TTQP", "U03AVP71V", "U03JLV38V", "U02E39HAY",
>> "U02AE5281", "U032FHV3S", "U03AL2096", "U02ARUG6M", "U02AECRSP",
>> "U02B42XG4", "U03AFQZNS", "U02AE7H41", "U03G9UNTG", "U02GEQ0E6",
>> "U02AGLE5A", "U02BQTRC9", "U03H0J6GS", "U02B3D27F", "U02AEKTHV",
>> "U02C52YN3", "U02E33MUW", "U03AKUT85", "U03B53EHG", "U02FBN38P",
>> "U03AH3E5W", "U02B5PLE0", "U02AS4RCK", "U03ANE1GZ", "U02E8LZQB",
>> "U03EPGJ98", "U02E3N220", "U03AEKYL4", "U02AE7HT1", "U02C1RR3G",
>> "U03JH408J", "U03KL0FKN", "U02B44R92", "U03EURWGX"), name = c("10k_affair",
>> "1upwuzhere", "4xcss", "agreenmamba", "ait109", "arly69", "azkop13",
>> "barcik75", "bigolnob", "blackrose", "blink619", "bobaloo23",
>> "bodger", "bomb", "bootswithdefer", "brandizzle", "bregalad",
>> "camon", "celticrain", "ch3mical", "checksum", "cocothunder",
>> "cruxicon", "cruzecontrol", "crystalskunk", "cscheetah", "dabcelin",
>> "deelicious", "delthanar", "drkaosdk", "droidenl-joe", "dukeceph",
>> "fillerbunny", "flickohmsford", "flyingg0d", "garaxiel", "goby9",
>> "gymbal", "hideandseek", "hobojr", "ijackportals", "invalidcharactr",
>> "itso9", "j0shs", "jarvis", "jc0mm5", "jencyberchic", "jimbobradyson",
>> "joespr0cket", "jostrander", "jueliet", "karlashi", "khan99",
>> "kingkonn0r", "krispycridder", "kritickalmass", "lawgiver", "maxcorbett",
>> "memory556", "meta000x", "minkovsky", "mistylady", "mstephans",
>> "mstrinity", "nocarryr", "ollietronic", "philistine11", "pickledpickles",
>> "piercingsbykris", "poisonivy", "raugmor", "remarks999", "rheds77",
>> "rhinz", "rigiritter", "robbie0017", "rohdef", "ryoziya", "s4n1ty",
>> "sacredcow133", "samwill", "sgtlemonpepper", "sivan", "spline9",
>> "starwolf", "stueliueli", "sweetiris", "swift2plunder", "swissphoenix",
>> "synyck", "test", "therug", "tinja551", "trulyjuan", "twinster",
>> "vairis", "vinylz3ro", "watervirus", "xaeth", "yagamiyukari",
>> "zafo", "zexium")), .Names = c("id", "name"), class = c("data.table",
>> "data.frame"), row.names = c(NA, -102L))
>>
>> I need to replace this regex pattern in df1 :
>> (?<=<@)[^|]{9}(?=>|) by its corresponding name from df2.
>>
>> E.g : if <@U03KH8Z52> is found in df1, then I want to replace it by
>> the "name" which correspond to this id in df2., in this case
>> 10k_affair
>>
>> I know of replace an expression with gsub:
>> gsub('(?<=<@)[^|]{9}(?=>|)', 'toto', df1, perl = T)
>> but I have no idea how to replace it with value from another df.
>>
>> Thank you for hints
>
> I am gathering some pieces of the puzzles.
>
>> regmatches(df1$text,regexpr('(?<=<@)[^|]{9}(?=>|)',df1$text, perl = T))
> [1] "U032FHV3S" "U03AEKWTL" "U03AEKYL4"
> The above commands extract the needed pattern
>
> df2[grep("U032FHV3S",df2$id),][[2]]
> [1] "poisonivy"
> The above command returns the name in the same row than the id. I need
> more than one name (in my case, I need 3)
>
> Shall I now write a loop and get a list of my needed name ? Pseudo
> code would be something like:
>
> for i %in% regmatches(df1$text,regexpr('(?<=<@)[^|]{9}(?=>|)',df1$text,
> perl = T))
>                  df2[grep("i",df2$id),][[2]]
>
>
> Thank you for hint about how I shall proceed.
>

Better approach than a loop:

> extrac <- regmatches(df1$text,regexpr('(?<=<@)[^|]{9}(?=>|)',df1$text, perl = T))
> extrac
[1] "U032FHV3S" "U03AEKWTL" "U03AEKYL4"
> df2[df2$id %in% extrac
          id        name
1: U03AEKWTL agreenmamba
2: U032FHV3S   poisonivy
3: U03AEKYL4      vairis


From ripley at stats.ox.ac.uk  Thu Feb 12 19:57:28 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Feb 2015 18:57:28 +0000
Subject: [R] Sorting Surv objects
In-Reply-To: <80DD3A92-AC92-408E-B1A3-10692F406426@snoopy.usask.ca>
References: <80DD3A92-AC92-408E-B1A3-10692F406426@snoopy.usask.ca>
Message-ID: <54DCF798.2040506@stats.ox.ac.uk>

On 12/02/2015 16:26, Professor Bickis wrote:
> It seems that Surv objects do not sort correctly.   This seems to be a bug.  Anyone else found this?

This is presumably about Surv() from package survival, not mentioned.

There was a bug, corrected in R-devel (and I will port to R-patched
before 3.1.3).

However, sorting censored survival events is a matter of definition (in 
?xtfrm but cross-referenced from ?sort) and the definition chosen is not 
that of lifetimes (as deaths at T sort after those alive at T and so 
lived longer).

>> survival.data
> [1] 4+ 3  1+ 2  5+

Please follow the posting guide and give a reproducible example.

library(survival)
d <- Surv(c(2,1,4,3,5), c(1,0,1,0,1))

 > d
[1] 2  1+ 4  3+ 5
 > sort(d)
[1] 1+ 2  3+ 4  5

in R-devel.  But

 > sort(Surv(c(2,2,4,3,5), c(1,0,1,0,1)))
[1] 2+ 2  3+ 4  5

>> class(survival.data)
> [1] "Surv"
>> sort(survival.data)
> [1] 2  1+ 4+ 3  5+
>
> An easy work-around is to define a function sort.Surv
>
> sort.Surv<-function(a){ord<-order(a[,1])
> + a[ord]}
>
>> sort(survival.data)
> [1] 1+ 2  3  4+ 5+
>
> I am using R 3.1.2 GUI 1.65 Mavericks build (6833) running under Yosemite.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From bickis at snoopy.usask.ca  Thu Feb 12 19:43:37 2015
From: bickis at snoopy.usask.ca (Professor Bickis)
Date: Thu, 12 Feb 2015 10:43:37 -0800
Subject: [R] Sorting Surv objects
Message-ID: <B5A7EA9D-93B9-48D9-A07B-CF0F945B680E@snoopy.usask.ca>

It seems that Surv objects do not sort correctly.   This seems to be a bug.  Anyone else found this?

>survival.data
[1] 4+ 3  1+ 2  5+
>class(survival.data)
[1] "Surv"
>sort(survival.data)
[1] 2  1+ 4+ 3  5+

An easy work-around is to define a function sort.Surv

>sort.Surv<-function(a){ord<-order(a[,1]); a[ord]}
>sort(survival.data)
[1] 1+ 2  3  4+ 5+

I am using R 3.1.2 GUI 1.65 Mavericks build (6833) running under Yosemite.


From js.huang at protective.com  Thu Feb 12 18:45:03 2015
From: js.huang at protective.com (JS Huang)
Date: Thu, 12 Feb 2015 09:45:03 -0800 (PST)
Subject: [R] SIMPLE question
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A034EE8@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A034EE8@mail-mbx-04.UNINE.CH>
Message-ID: <1423763103665-4703180.post@n4.nabble.com>

Hi, 

  Maybe the following link helps.

http://r.789695.n4.nabble.com/box-cox-td4363944.html




--
View this message in context: http://r.789695.n4.nabble.com/SIMPLE-question-tp4703176p4703180.html
Sent from the R help mailing list archive at Nabble.com.


From rbaer at atsu.edu  Thu Feb 12 20:50:55 2015
From: rbaer at atsu.edu (Robert Baer)
Date: Thu, 12 Feb 2015 13:50:55 -0600
Subject: [R] Installing RStudio
In-Reply-To: <54DC8D10020000CB00122E61@smtp.medicine.umaryland.edu>
References: <1316544333.122505.1423141062041.JavaMail.yahoo@mail.yahoo.com>	<818837787-1423141688-cardhu_decombobulator_blackberry.rim.net-1580041060-@b12.c6.bise7.blackberry>	<54D372F7.8030108@univ-reims.fr>
	<54DC8D10020000CB00122E61@smtp.medicine.umaryland.edu>
Message-ID: <54DD041F.1060304@atsu.edu>


On 2/12/2015 10:22 AM, John Sorkin wrote:
> Windows 7, 64-bit.
>   
> I am trying to install RStudio. Before installing RStudio, I installed R 3.1.2. During the installation or R, I installled (as per the default) 32- and 64-bit packages. When I tried to install RStudio, I received the message
> R does not appear to be installed. Please install R before using RStudio.
> I know R is installed, beacuse I am able to run R.
> Can anyone suggest what I can do to get RStudio installed?
> Thank you
> John
>   
Tools > Global opetions > general, and fill in the top box to point the 
top line at the Installed version of R you wish to use. Usually, it will 
do a pretty good job of finding it on its own, but you can always adjust 
you version to suit here.

Rob


> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:18}}


From rmh at temple.edu  Thu Feb 12 21:27:22 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 12 Feb 2015 15:27:22 -0500
Subject: [R] suggestion for optimal plotting to show significant
	differences
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FC45@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F0E3@SRVEXCHMBX.precheza.cz>
	<CAGx1TMCq1jXtuyofWv5nYC2So0RyKDp_734ze6rAQXztaxccnw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F3E0@SRVEXCHMBX.precheza.cz>
	<CAGx1TMDvvOOukbUfk23GrWQLSnmwr-Ykx6Qj=xYZLWraAfBKxA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FC45@SRVEXCHMBX.precheza.cz>
Message-ID: <CAGx1TMA7q1DNoEPkn49-muTf0ZJQMK5sA134aDO9x1gE5Bfkiw@mail.gmail.com>

## The next step is to think of this in the analysis of covariance setting.

## this example is based on

library(HH)

demo("ancova", package="HH", ask=FALSE)

item<-rep(letters[1:8], each=18)
day<-rep((0:5)*100, 24)
set<-rep(rep(1:3, each=6), 8)
test<-data.frame(item, day, set)
set.seed(111)
test$value<-(test$day/100+1)+rnorm(144)
test$value<-test$value+(as.numeric(test$item)*1.3)
test$dayf <- factor(test$day)


Fitalphabeta <- aov(value ~ day, data=test)
AB <- xyplot(value ~ day | item, data=test, layout=c(8,1),
scales=list(alternating=1),
             main="regression, ignoring item\ncommon slope, common intercept") +
               layer(panel.abline(coef(Fitalphabeta)))
AB

Fitalphabeta0 <- aov(value ~ 0 + item, data=test)
AB0 <- xyplot(value ~ day | item, data=test, layout=c(8,1),
scales=list(alternating=1),
              main="anova, ignoring day\nzero slope, variable intercept") +
                layer(panel.abline(a=coef(Fitalphabeta0)[panel.number()], b=0))
AB0

Fitalphaibeta <- aov(value ~ 0 + item + day, data=test)
AiB <- xyplot(value ~ day | item, data=test, layout=c(8,1),
scales=list(alternating=1),
              main="ancova\ncommon slope, variable intercept") +

layer(panel.abline(a=coef(Fitalphaibeta)[panel.number()],
b=rev(coef(Fitalphaibeta))[1]))
AiB

Fitalphaibetaj <- aov(value ~ 0 + item / day, data=test)
AiBj <- xyplot(value ~ day | item, data=test, layout=c(8,1),
scales=list(alternating=1),
               main="ancova with interaction\nvariable slope, variable
intercept") +

layer(panel.abline(a=coef(Fitalphaibetaj)[panel.number()],
b=coef(Fitalphaibetaj)[8 + panel.number()]))
AiBj

## this is very tight on the standard 7x7 plotting surface.
## it will look ok with 10in wide and 7in high
## pdf("AB2x2.pdf", height=7, width=10)
print(AB,   split=c(1, 1, 2, 2), more=TRUE)
print(AB0,  split=c(1, 2, 2, 2), more=TRUE)
print(AiB,  split=c(2, 1, 2, 2), more=TRUE)
print(AiBj, split=c(2, 2, 2, 2), more=FALSE)
## dev.off()

## this arrangement matches the arrangement in demo("ancova")
## this too is very tight on the standard 7x7 plotting surface.
## it will look ok with 10in wide and 10in high
## pdf("AB2x3.pdf", height=10, width=10)
print(AB,   split=c(1, 2, 2, 3), more=TRUE)
print(AB0,  split=c(2, 3, 2, 3), more=TRUE)
print(AiB,  split=c(2, 2, 2, 3), more=TRUE)
print(AiBj, split=c(2, 1, 2, 3), more=FALSE)
## dev.off()


On Thu, Feb 12, 2015 at 9:48 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Hi Rich
>
>> -----Original Message-----
>> From: Richard M. Heiberger [mailto:rmh at temple.edu]
>> Sent: Wednesday, February 11, 2015 10:53 PM
>> To: PIKAL Petr
>> Cc: r-help at r-project.org
>> Subject: Re: [R] suggestion for optimal plotting to show significant
>> differences
>>
>> Petr,
>>
>> My first attempt is to use the simple=TRUE argument to interaction2wt.
>>
>> Then the bwplots in the item|item panel show the behavior of value over
>> day for each item.  You get a plot similar to this panel with the
>> growth curve plots from nlme, for example,
>>     bwplot(value ~ day | item, data=test, horizontal=FALSE) I am
>> treating set as a replication and each box is cumulated over the three
>> sets.
>
> Yes, that is the point - set is actually replication of result.
>
>>
>> My analysis question is about day.  You have it as numeric.  My
>> inclination would be to make day factor.  Then you could model the
>> interaction of day and item.
>
> Hm. I hoped I can do
>
> fit<-lm(value~day*item, data=test)
> summary(fit)
>
> in which case I can compare differences in intercepts and/or slopes for each item.
>
> However I am rather lost in aov
>
> test$dayf <- factor(test$day)
>
> fit1 <- aov(value~item+dayf, data=test)
> summary(fit)
> fit2 <- aov(value~item/dayf, data=test)
> summary(fit)
> and
> fit3 <- aov(value~item*dayf, data=test)
> summary(fit)
> which gives bascally the same result as fit2
>
>> anova(fit1, fit2)
> Analysis of Variance Table
>
> Model 1: value ~ item + dayf
> Model 2: value ~ item/dayf
>   Res.Df    RSS Df Sum of Sq      F Pr(>F)
> 1    131 160.59
> 2     96 128.60 35    31.993 0.6824 0.8993
>
> TukeyHSD(fit1, which="item")
> TukeyHSD(fit2, which="item")
>
> Both models seems to give quite similar results and I am not sure what actually differs in those models. I believe that model2 tests each item within particular day (but I am not sure about it).
>
> However this discussion is probably deviating more to the statistics issue than to R itself.
>
> I just thought that somebody helps me with a method for comparison of item performance in case that relation of value to day is not simple linear (as in my example) and cannot be expressed by some formula (like examples in nlme).
>
> So far the best options are either your bwplot or my ggplots.
>
> p<-ggplot(test, aes(x=day, y=value, colour=item))
> p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))
>
> p<-ggplot(test, aes(x=dayf, y=value, colour=item))
> p+geom_boxplot()
>
> p<-ggplot(test, aes(x=item, y=value))
> p+geom_boxplot()+facet_wrap(~day)
>
> Thank you for your suggestions which directed me to interaction plots which I was not aware of.
>
> Best regards
> Petr
>
>
>>
>> Rich
>>
>> On Mon, Feb 9, 2015 at 6:01 AM, PIKAL Petr <petr.pikal at precheza.cz>
>> wrote:
>> > Hallo Richard.
>> >
>> > I tried your suggestion but it seems to be no better than simple
>> ggplot. Let me extend the example a bit to 8 items which is more
>> realistic.
>> >
>> > item<-rep(letters[1:8], each=18)
>> > day<-rep((0:5)*100, 24)
>> > set<-rep(rep(1:3, each=6), 8)
>> > test<-data.frame(item, day, set)
>> > set.seed(111)
>> > test$value<-(test$day/100+1)+rnorm(144)
>> > test$value<-test$value+(as.numeric(test$item)*1.3)
>> >
>> > Value is increasing during time (day) for each tested subject (item),
>> each item is measured 3 times (set) each day.
>> >
>> > Here is some graph
>> > p<-ggplot(test, aes(x=day, y=value, colour=item))
>> > p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))
>> >
>> > I can do lm or aov, however I am not sure about proper formula.
>> >
>> > fit<-lm(value~day, data=test)
>> > summary(fit)
>> > # this shows that value is increasing with day
>> >
>> > fit<-lm(value~day/item, data=test)
>> > summary(fit)
>> > # this suggests that value is decreasing with day (which is wrong)
>> >
>> > fit<-lm(value~day*item, data=test)
>> > summary(fit)
>> > # and this tells me that value is increasing with day and items have
>> different intercepts but the same rate of growth (I hope I got it
>> right).
>> >
>> > I do not have your book available but I went through help pages.
>> >
>> > Your interaction graph is not much better than ggplot.
>> > I can do
>> >
>> > interaction2wt(value ~ item * day, data=test)
>> >
>> > which probably is closer to actual problem.
>> >
>> > The basic problem is that increase of value with days is in fact not
>> linear and actually it can increase in the beginning and then stagnate
>> or it can stagnate in beginning and then increase. I am not aware of
>> any way how to compare time behaviour of different items in such
>> situations if I cannot state some common formula in which case I would
>> use probably nlme.
>> >
>> > Thank for your insight, I try to go through it more deeply.
>> >
>> > Best regards
>> > Petr
>> >
>> >
>> >> -----Original Message-----
>> >> From: Richard M. Heiberger [mailto:rmh at temple.edu]
>> >> Sent: Friday, February 06, 2015 6:14 PM
>> >> To: PIKAL Petr
>> >> Cc: r-help at r-project.org
>> >> Subject: Re: [R] suggestion for optimal plotting to show significant
>> >> differences
>> >>
>> >> I would try one of these illustrations for starts.
>> >> interaction2wt (two-way tables) is designed to be used with aov()
>> for
>> >> testing.
>> >> interaction2wt shows all main effects and all two-way interactions
>> >> for many factors.
>> >>
>> >>
>> >>
>> >> test <-
>> >> structure(list(item = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L,
>> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A", "B"), class
>> >> = "factor"), day = c(0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L,
>> >> 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L,
>> >> 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L,
>> >> 200L, 300L, 400L, 500L), set = c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>> >> 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
>> >> 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L), value = c(1.08163365169503,
>> >> 2.61998412608805, 3.07820466606394, 4.44993419381934,
>> >> 5.29163171545805, 6.29155990999293, -0.123163011367676,
>> >> 2.07767236834003, 2.32537052874901, 3.09372794501084,
>> >> 6.65273721166635, 5.92304962329131, 1.50504697705548,
>> >> 2.66253728086866, 2.63420157418685, 2.78195098580416,
>> >> 6.47578642973288, 5.89587443775143, 0.848864231485078,
>> >> 1.27549677119713, 2.19573089053609, 2.45659926134292,
>> >> 5.15424403414103, 5.4813151140983, 1.25731482647214,
>> >> 2.09662105167973, 1.75954023316977, 4.81624002288939,
>> >> 4.65029189325307, 6.39946904227214, 0.944996929887344,
>> >> 1.74667265331284, 2.42956264345558, 5.17852980415141,
>> >> 3.5453435965834, 6.9011238437191)), .Names = c("item", "day", "set",
>> >> "value"), row.names = c(NA, -36L), class =
>> >> "data.frame")
>> >>
>> >>
>> >>
>> >> library(HH)
>> >>
>> >> test$set <- factor(test$set)
>> >> test$day <- factor(test$day)
>> >> test$item <- factor(test$item)
>> >>
>> >> interaction2wt(value ~ item * day * set, data=test)
>> >>
>> >> test$item.day <- interaction(test$item, test$day)
>> >> position(test$item.day) <- outer(c(-10,10),
>> >> as.numeric(levels(test$day)), `+`)
>> >>
>> >> xyplot(value ~ as.position(item.day) | set, groups=item,
>> >>         data=test, horizontal=FALSE, pch=c(17,16),
>> >>         xlab="day",
>> >>         scales=list(
>> >>           x=list(
>> >>             alternating=1,
>> >>             at=levels(test$day), ## placement of tick labels and
>> marks
>> >>             tck=1)),
>> >>         key=list(
>> >>           text=list(c("A","B"), col=c("blue","red")),
>> >>           points=list(pch=c(17, 16), col=c("blue","red")),
>> >>        space="top", columns=2, border=TRUE),
>> >>        layout=c(3,1))
>> >>
>> >>
>> >> ## see also the examples in
>> >> demo(package="HH", bwplot.examples)
>> >>
>> >> On Fri, Feb 6, 2015 at 6:09 AM, PIKAL Petr <petr.pikal at precheza.cz>
>> >> wrote:
>> >> > Dear all
>> >> >
>> >> > I would like to ask for your opinion about possible graphical
>> >> representation of such data.
>> >> >
>> >> >> dput(test)
>> >> > structure(list(item = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> >> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L,
>> >> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A", "B"),
>> >> > class
>> >> =
>> >> > "factor"), day = c(0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L,
>> >> > 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L,
>> 100L,
>> >> > 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L,
>> 100L,
>> >> > 200L, 300L, 400L, 500L), set = c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
>> >> > 2L, 2L,
>> >> 2L,
>> >> > 2L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>> 2L,
>> >> > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L), value = c(1.08163365169503,
>> >> > 2.61998412608805, 3.07820466606394, 4.44993419381934,
>> >> > 5.29163171545805, 6.29155990999293, -0.123163011367676,
>> >> > 2.07767236834003, 2.32537052874901, 3.09372794501084,
>> >> > 6.65273721166635, 5.92304962329131, 1.50504697705548,
>> >> > 2.66253728086866, 2.63420157418685, 2.78195098580416,
>> >> > 6.47578642973288, 5.89587443775143, 0.848864231485078,
>> >> > 1.27549677119713, 2.19573089053609, 2.45659926134292,
>> >> > 5.15424403414103, 5.4813151140983, 1.25731482647214,
>> >> 2.09662105167973,
>> >> > 1.75954023316977, 4.81624002288939, 4.65029189325307,
>> >> > 6.39946904227214, 0.944996929887344, 1.74667265331284,
>> >> > 2.42956264345558, 5.17852980415141, 3.5453435965834,
>> >> > 6.9011238437191)), .Names = c("item", "day", "set", "value"),
>> >> > row.names = c(NA, -36L), class = "data.frame")
>> >> >>
>> >> >
>> >> > One option I came with is
>> >> >
>> >> > library(ggplot2)
>> >> > p<-ggplot(test, aes(x=day, y=value, colour=item))
>> >> > p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))
>> >> >
>> >> > but -
>> >> > I have more items (around 5-10), and I want to show if the
>> >> > difference
>> >> between items is or is not significant. The actual development of
>> >> value with day is usually not linear nor growing steadily and
>> >> actually I cannot usually evaluate some analytical equation for my
>> >> data to compare equation parameters.
>> >> >
>> >> > I thought about boxplots, but there is not many repetitions and
>> >> actually 5+ boxplots can be quite messy.
>> >> >
>> >> > I can plot only mean for each set and item but in that case I lose
>> >> information if the difference is or is not significant.
>> >> >
>> >> > I appreciate any suggestion.
>> >> >
>> >> > Best regards
>> >> > Petr
>> >> >
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From macqueen1 at llnl.gov  Thu Feb 12 22:56:59 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 12 Feb 2015 21:56:59 +0000
Subject: [R] read.table with missing data and consecutive delimiters
In-Reply-To: <54DBBCCE.8030803@sapo.pt>
References: <CAOTyWwA_CRFykoEuDQ+nQQF8++jmXVoMQF3A-FGU06+jWpjF=w@mail.gmail.com>
	<54DBBCCE.8030803@sapo.pt>
Message-ID: <D10260DB.11E91E%macqueen1@llnl.gov>

To which I will add, you could have tried

  count.fields('test.dat', sep='$' )

which I expect would have given you 3,3,2,3, and hence a pointer to where
the problem is.

count.fields is mentioned in the "See Also" section of ?read.table

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 2/11/15, 12:34 PM, "Rui Barradas" <ruipbarradas at sapo.pt> wrote:

>Hello,
>
>You're missing a dollar sign: 2$$$5, not 2$$5.
>
>Hope this helps,
>
>Rui Barradas
>
>Em 11-02-2015 14:53, Tim Victor escreveu:
>> All,
>>
>> Assume we have data in an ASCII file that looks like
>>
>> Var1$Var2$Var3$Var4
>> 1$2$3$4
>> 2$$5
>> $$$6
>>
>> When I execute
>>
>> read.table( 'test.dat', header=TRUE, sep='$' )
>>
>> I, of course, receive the following error:
>>
>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines,
>>na.strings,
>>   :
>>    line 2 did not have 4 elements
>>
>> When I set fill=TRUE, e.g., read.table( 'test.dat', header=TRUE,
>>sep='$',
>> fill=TRUE )
>>
>> I get:
>>
>>    Var1 Var2 Var3 Var4
>> 1    1    2    3    4
>> 2    2   NA    5   NA
>> 3   NA   NA   NA    6
>>
>>
>> What I need is
>>
>>    Var1 Var2 Var3 Var4
>> 1    1    2    3    4
>> 2    2   NA   NA    5
>> 3   NA   NA   NA    6
>>
>> What am I missing?
>>
>> Thanks,
>>
>> Tim
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Thu Feb 12 23:04:58 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 12 Feb 2015 23:04:58 +0100
Subject: [R] 32bit R303 calls external C functions
In-Reply-To: <A29EC196EE32C64389369F6BF03B66C87A8EFEB7D3@IBIUSMBSB.ibi.com>
References: <A29EC196EE32C64389369F6BF03B66C87A8EFEB5C0@IBIUSMBSB.ibi.com>	<54DCEA67.8050902@gmail.com>
	<A29EC196EE32C64389369F6BF03B66C87A8EFEB7D3@IBIUSMBSB.ibi.com>
Message-ID: <54DD238A.80105@statistik.tu-dortmund.de>



On 12.02.2015 19:07, Li, Yan wrote:
> I meant R3.0.3. I need this package working in R3.0.3.
>
> I have 32bit and 64bit dlls both included in the package.

So it should be fine. Maybe you compiled it for a different R version or 
on another OS????

Best,
Uwe Ligges


>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Thursday, February 12, 2015 1:01 PM
> To: Li, Yan; r-help at r-project.org
> Subject: Re: [R] 32bit R303 calls external C functions
>
> On 12/02/2015 11:08 AM, Li, Yan wrote:
>> Dear All,
>>
>> I build a R package which will need to call external C functions. I registered the C functions in the NAMESPACE file and include 32bit and 64bit dlls in the packages. If I load the package in 64bit R and calls the external C functions, it works fine. However if I load the package in 32bit R and call the external C functions, it either does not work properly or gives back error message saying cannot find the external C functions.
>>
>> When I built the same package in R2.15.1, there is no such issue.
>>
>> I checked the update news for R303 and found most .C is replaced by .Call. I modified the code but the package cannot be loaded and R ended abnormally.
>>
>> Does anyone know if there any difference of 32bit R303 calling external C from 64bitR303? Thank you!
>
> There's no R303; the current version is 3.1.2.  So if you meant 3.0.3, I'd suggest upgrading.  If you meant something else, you're probably in the wrong place.
>
> For 3.1.2, there are big differences:  32 bit R can't call 64 bit .dlls
> and vice versa.   You can either install the package from source in both
> versions, or arrange to compile both 32 bit and 64 bit dlls, in which case both versions can use the binary of the package.
>
> If you've already done all that, then you'll need to give more details, e.g. access to the source for the package, to get more specific help.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Thu Feb 12 23:07:04 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 12 Feb 2015 23:07:04 +0100
Subject: [R] Censoring in R2OpenBUGS
In-Reply-To: <1423753513965-4703160.post@n4.nabble.com>
References: <1423753513965-4703160.post@n4.nabble.com>
Message-ID: <54DD2408.6050006@statistik.tu-dortmund.de>

On 12.02.2015 16:05, arnabkm2007 wrote:
> Hi,
>
> I am trying to run the following model for OpenBUGS and want to use
> R2OpenBUGS package. The model specifies weibull distribution for censored
> data.
>
>
>    weibull.model <- function()
>    {
>
>      for(i in 1:n)
>      {
>
>        exp.alpha[i] ~ dgamma(a.alpha, b.alpha)
>        alpha[i] <- log(exp.alpha[i])
>
>        linear.part[i] <- alpha[i] + inprod(nu[ ], x[i, ])
>        lambda[i] <- exp(linear.part[i])
>
>        time[i] ~ (dweib(shape, lambda[i]) C(censored.time[i], ))
>
>      }
>
>      shape ~ dgamma(a.shape, b.shape)
>
>      for(j in 1:p)
>      {
>
>        beta[j]  ~ dnorm(prior.mean, prior.tau)
>        gamma[j] ~ dbern(pi[j])
>        pi[j]    ~ dbeta(1, 1)
>        nu[j]   <- beta[j] * gamma[j]
>
>      }
>
>    }
>
>
>
> But R is throwing the following error.
>
> Error: unexpected symbol in:
> "
>        time[i] ~ (dweib(shape, lambda[i]) C"
>
> Any help regarding this will be appreciated.

See ?write.model:

"As a difference, BUGS syntax allows truncation specification like this: 
dnorm(...) I(...) but this is illegal in R. To overcome this 
incompatibility, use dummy operator %_% before I(...): dnorm(...) %_% 
I(...). The dummy operator %_% will be removed before the BUGS code is 
saved."

Best,
Uwe Ligges





> Thanks & Regards,
> Arnab
>
>
> Arnab Kumar Maity
> Graduate Teaching Assistant
> Division of Statistics
> Northern Illinois University
> DeKalb, IL 60115
> Email: maity at math.niu.edu
> Ph:     779-777-3428
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Censoring-in-R2OpenBUGS-tp4703160.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From 538280 at gmail.com  Thu Feb 12 23:20:14 2015
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 12 Feb 2015 15:20:14 -0700
Subject: [R] How to subset data, by sorting names alphabetically.
In-Reply-To: <CA+8X3fXHG2cxtYnTWUA1bGB6Rady5in+zD4-R6GXuC39bL6oTg@mail.gmail.com>
References: <CAOpgo6hun+2OnaOMO2JnNRXhE820ftkaNyCTWgWX1gMPrUOatA@mail.gmail.com>
	<CA+8X3fXHG2cxtYnTWUA1bGB6Rady5in+zD4-R6GXuC39bL6oTg@mail.gmail.com>
Message-ID: <CAFEqCdxDinkYH0NYkmKxLm8-49SUFHyHfG1MCF0K3ZreexMj-Q@mail.gmail.com>

The split function does essentially this, but puts the results into a list
rather than using the dangerous and messy assign function.  The overall
syntax is simpler as well.

On Thu, Feb 12, 2015 at 3:14 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Samarvir,
> Assuming that you want to generate a separate data frame for each
> value of "Name",
>
> # name of initial data frame is ssdf
> for(nameval in unique(ssdf$Name)) assign(nameval,ssdf[ssdf$Name==nameval,])
>
> This will produce as many data frames as there are unique values of
> ssdf$Name, each named by the values it contains.
>
> Jim
>
>
> On Thu, Feb 12, 2015 at 3:57 PM, samarvir singh <samarvir1996 at gmail.com>
> wrote:
> > hello,
> >
> > I am cleaning some large data with 4 million observation and 7 variable.
> > Of the 7 variables , 1 is name/string
> >
> > I want to subset data, which have same name
> >
> > Example-
> >
> >  Name var1 var2 var3 var4 var5 var6
> > aa        -       -       -         -     -        -
> > ab
> > bd
> > ac
> > ad
> > af
> > ba
> > bd
> > aa
> > av
> >
> > i want to sort the data something like this
> >
> > aa
> > aa
> > all aa in a same subset
> >
> > and all ab in same subset
> >
> > every column with same name in a subset
> >
> >
> >
> > thanks in advance.
> > I am new to R community.
> > appreciate your help
> > - Samarvir
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Feb 13 00:32:53 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 12 Feb 2015 23:32:53 +0000
Subject: [R] horizontal bar plots for CI visualization
References: <9EFCA4A987B0494CBFFB5CD071756D0026B3F8C6@WBF-C7002.bk.evdad.admin.ch>
Message-ID: <loom.20150213T003216-557@post.gmane.org>

 <michael.eisenring <at> agroscope.admin.ch> writes:

> 
> 	2.50%	97.50%
> intercept	2978	7966
> glands	1314	3611
> damage	169	6144
> treatment L1	778	6703
> treatment L4	-3899	5125
> Length	-1817	1828
> 

  plotrix::plotCI(..., err="x") 

??


From learoser at gmail.com  Fri Feb 13 00:47:44 2015
From: learoser at gmail.com (Leandro Roser)
Date: Thu, 12 Feb 2015 20:47:44 -0300
Subject: [R] How to subset data, by sorting names alphabetically.
In-Reply-To: <CAFEqCdxDinkYH0NYkmKxLm8-49SUFHyHfG1MCF0K3ZreexMj-Q@mail.gmail.com>
References: <CAOpgo6hun+2OnaOMO2JnNRXhE820ftkaNyCTWgWX1gMPrUOatA@mail.gmail.com>
	<CA+8X3fXHG2cxtYnTWUA1bGB6Rady5in+zD4-R6GXuC39bL6oTg@mail.gmail.com>
	<CAFEqCdxDinkYH0NYkmKxLm8-49SUFHyHfG1MCF0K3ZreexMj-Q@mail.gmail.com>
Message-ID: <CAJkJCp4AGpghzOYTuDRPGhUU2qg7FQ3NEMqjOnt==V-t0NNYdg@mail.gmail.com>

Hi, a solution could be:

# example matrix a:
a <- matrix(1:100, 10, 10)
a[, 1] <- (sample(c("aa","bb" , "ab"), 10,  rep=TRUE))
a <- a[order(a[, 1]), ]  # order the matrix by row = 1


#subsetting a:

lev <- levels(as.factor(a[, 1]))
subs <- list()
for(i in 1:length(lev)) {
subs[[i]]  <- a[a[, 1] %in% lev[i], ]
}

#result:
subs


## an alternative, with column 1 as name of list:

# example matrix a:
a <- matrix(1:100, 10, 10)
a[, 1] <- (sample(c("aa","bb" , "ab"), 10,  rep=TRUE))
a <- a[order(a[, 1]), ]  # order the matrix by row = 1

lev <- levels(as.factor(a[, 1]))
subs <- list()
for(i in 1:length(lev)) {
    subs[[i]]  <- a[a[, 1] %in% lev[i], -1]
}
names(subs) <- lev

#result:
subs

2015-02-12 19:20 GMT-03:00 Greg Snow <538280 at gmail.com>:
> The split function does essentially this, but puts the results into a list
> rather than using the dangerous and messy assign function.  The overall
> syntax is simpler as well.
>
> On Thu, Feb 12, 2015 at 3:14 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Samarvir,
>> Assuming that you want to generate a separate data frame for each
>> value of "Name",
>>
>> # name of initial data frame is ssdf
>> for(nameval in unique(ssdf$Name)) assign(nameval,ssdf[ssdf$Name==nameval,])
>>
>> This will produce as many data frames as there are unique values of
>> ssdf$Name, each named by the values it contains.
>>
>> Jim
>>
>>
>> On Thu, Feb 12, 2015 at 3:57 PM, samarvir singh <samarvir1996 at gmail.com>
>> wrote:
>> > hello,
>> >
>> > I am cleaning some large data with 4 million observation and 7 variable.
>> > Of the 7 variables , 1 is name/string
>> >
>> > I want to subset data, which have same name
>> >
>> > Example-
>> >
>> >  Name var1 var2 var3 var4 var5 var6
>> > aa        -       -       -         -     -        -
>> > ab
>> > bd
>> > ac
>> > ad
>> > af
>> > ba
>> > bd
>> > aa
>> > av
>> >
>> > i want to sort the data something like this
>> >
>> > aa
>> > aa
>> > all aa in a same subset
>> >
>> > and all ab in same subset
>> >
>> > every column with same name in a subset
>> >
>> >
>> >
>> > thanks in advance.
>> > I am new to R community.
>> > appreciate your help
>> > - Samarvir
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Lic. Leandro Gabriel Roser
 Laboratorio de Gen?tica
 Dto. de Ecolog?a, Gen?tica y Evoluci?n,
 F.C.E.N., U.B.A.,
 Ciudad Universitaria, PB II, 4to piso,
 Nu?ez, Cdad. Aut?noma de Buenos Aires,
 Argentina.
 tel ++54 +11 4576-3300 (ext 219)
 fax ++54 +11 4576-3384


From atesh.koul at gmail.com  Fri Feb 13 09:28:31 2015
From: atesh.koul at gmail.com (atesh koul)
Date: Fri, 13 Feb 2015 09:28:31 +0100
Subject: [R] Help with Flexmix- multivariate time series data
Message-ID: <CAHmbE3oFg6hDaLHLoTyREsq=d=HiRbKqCHvq34TkY7gXXjq=Ng@mail.gmail.com>

Hi all,

I am trying to use R package flexmix for data clustering which I find
extremely useful. I would like to know how many clusters could be there in
the data and the assignment of trials to these clusters.

The data are hand kinematics data- 16 variables at 10 discrete time points
for 17 subjects. I am trying to use the FLXMCmvnorm driver for as the data
features are correlated multinomial features (formula - data~time|subject).

However, using the driver, I found out that only the left hand side in the
formula is used. This would remove the time dependence that I am trying to
model. Currently, I am stuck at this point. I would really appreciate if
any one could provide me any help on how in the formula I can include the
time dependence as well.

I would really appreciate help regarding this and would go a long way in
solving my problem. Please let me know if more information about the data
is needed.

Thanks,

Best regards,
Atesh

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Fri Feb 13 11:53:33 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 13 Feb 2015 11:53:33 +0100
Subject: [R] [BUG] or [undocumented] boxplot - horizontal swaps ylim and xlim
Message-ID: <m2mw4iytea.fsf@krugs.de>

When using the function boxplot() together with the argument

,----
| horizontal = TRUE
`----

xlim and ylim become swapped, i.e. ylim refers to the x-axis instead of
the y-axis:

--8<---------------cut here---------------start------------->8---
x <- runif(1000)
boxplot(x)
boxplot(
   x,
   ylim = c(0.2, 0.8)
   )
boxplot(
   x,
   ylim = c(0.2, 0.8),
   horizontal=TRUE
   )
--8<---------------cut here---------------end--------------->8---

This is either a bug or undocumented.

Cheers,

Rainer

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150213/cadfcc43/attachment.bin>

From laurent.franckx at vito.be  Fri Feb 13 11:59:57 2015
From: laurent.franckx at vito.be (Franckx Laurent)
Date: Fri, 13 Feb 2015 10:59:57 +0000
Subject: [R] difference between max in summary table and max function
Message-ID: <3FA7C532AA08284AB2ACA7B0AB56EF8715907C70@vitomail4.vito.local>

Dear all

I have found out that the max in the summary of an integer vector is not always equal to the actual maximum of that vector. For example:


> testrow <- c(1:131509)
> summary(testrow)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
      1   32880   65760   65760   98630  131500
> max(testrow)
[1] 131509

This has occurred both in a Windows and in a Linux environment.

Does this mean that the max value in the summary is only an approximation?

Best regards

Laurent Franckx, PhD
Senior researcher sustainable mobility
VITO NV | Boeretang 200 | 2400 Mol
Tel. ++ 32 14 33 58 22| mob. +32 479 25 59 07 | Skype: laurent.franckx | laurent.franckx at vito.be | Twitter @LaurentFranckx




VITO Disclaimer: http://www.vito.be/e-maildisclaimer


From martyn.byng at nag.co.uk  Fri Feb 13 12:14:38 2015
From: martyn.byng at nag.co.uk (Martyn Byng)
Date: Fri, 13 Feb 2015 11:14:38 +0000
Subject: [R] difference between max in summary table and max function
In-Reply-To: <3FA7C532AA08284AB2ACA7B0AB56EF8715907C70@vitomail4.vito.local>
References: <3FA7C532AA08284AB2ACA7B0AB56EF8715907C70@vitomail4.vito.local>
Message-ID: <AM2PR05MB075593027DD74FFBEA945DD8A1230@AM2PR05MB0755.eurprd05.prod.outlook.com>

Its a formatting thing, try

summary(testrow,digits=20)

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Franckx Laurent
Sent: 13 February 2015 11:00
To: r-help at r-project.org
Subject: [R] difference between max in summary table and max function

Dear all

I have found out that the max in the summary of an integer vector is not always equal to the actual maximum of that vector. For example:


> testrow <- c(1:131509)
> summary(testrow)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
      1   32880   65760   65760   98630  131500
> max(testrow)
[1] 131509

This has occurred both in a Windows and in a Linux environment.

Does this mean that the max value in the summary is only an approximation?

Best regards

Laurent Franckx, PhD
Senior researcher sustainable mobility
VITO NV | Boeretang 200 | 2400 Mol
Tel. ++ 32 14 33 58 22| mob. +32 479 25 59 07 | Skype: laurent.franckx | laurent.franckx at vito.be | Twitter @LaurentFranckx




VITO Disclaimer: http://www.vito.be/e-maildisclaimer

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________________________________________________
This e-mail has been scanned for all viruses by Star.\ _...{{dropped:3}}


From arnaud.gaboury at gmail.com  Fri Feb 13 12:46:56 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Fri, 13 Feb 2015 12:46:56 +0100
Subject: [R] replace values in one df by values from key pairs in another df
Message-ID: <CAK1hC9uKpp=PKmwpthjhDA+byobz_v5h0VC6RCOh3EmyagqwJw@mail.gmail.com>

I have been searching for a while now, but can't put all pieces of the
puzzle together.

Goal : I want to replace all these kinds of patterns <@U032FHV3S> by
this <@agreenmamba>. In a more generic way, it is replacing 'id' by
user 'name'.

I have two df:
The first, 'history', is some message history where I want to do the
replacement. It is a chat history log,
The second one, idName, is a list of id:name. All are unique. This df
rows are exctracted from a bigger one called 'users' this way :
users[users$id %in% ext].


Please find below my two data.frames:
-------------------------------------------------------------------------
history <- structure(list(name = c("xaeth", "agreenmamba", "poisonivy",
"agreenmamba", "cruzecontrol", "poisonivy", "poisonivy", "vairis",
"vairis", "poisonivy"), text = c("and people told that agent their
geocities experience would never amount to anything (the convo
yesterday) ",
"<@U032FHV3S> <http://youtu.be/oGIFublvDes>", "for me there is no such
question",
"<@U03AEKWTL|agreenmamba> uploaded a file:
<https://enlightened.slack.com/files/agreenmamba/F03KGRF3W/screenshot_2015-02-09-14-31-15.png|regarding:
should I stay or should I go?>",
"Lol.", "ha ha sorry", "some testing with my irc client", "anybody
knows how does \"Passcode circuitry too hot. Wait for cool down to
enter another passcode.\" works?",
"what is the cooldown time or how does it work...;", "<@U03AEKYL4>:
what app are you talking about ?"
)), .Names = c("name", "text"), class = c("data.table", "data.frame"
), row.names = c(NA, -10L)
--------------------------------------------------------------
idName <- structure(list(id = c("U03AEKWTL", "U032FHV3S", "U03AEKYL4"),
    name = c("agreenmamba", "poisonivy", "vairis")), .Names = c("id",
"name"), sorted = "name", class = c("data.table", "data.frame"
), row.names = c(NA, -3L))

--------------------------------------------------------------------

1- I can find the pattern to be replaced in history this way :

ext <- regmatches(history$text,regexpr('(?<=<@)[^|]{9}(?=>|)',history$text,
perl = T)
> ext
[1] "U032FHV3S" "U03AEKWTL" "U03AEKYL4"

2- I can select the pairs id:name in my 'users' df:

> idName=users[users$id %in% ext]
          id        name
1: U03AEKWTL agreenmamba
2: U032FHV3S   poisonivy
3: U03AEKYL4      vairis

3-  i can write a loop to make the changes:

> hist.txt <- history$text
> for (i in 1:3){hist.txt <- gsub(ext[i],idName[[2]][i], hist.txt, perl = T)}

But this will not work because of two things:
- 'idName' is not ordered the same way as 'ext'
- if a users speak twice it will leave with with some NA

May you have some hints how to process ?
I was thinking of maybe using sapply(myFun) to my 'history' df where
myFun would be the replacement process.
OR something like with assigning in my env each 'id' to its corresponding 'name'


Thank you for help


From arnaud.gaboury at gmail.com  Fri Feb 13 13:02:53 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Fri, 13 Feb 2015 13:02:53 +0100
Subject: [R] replace values in one df by values from key pairs in
	another df
In-Reply-To: <CAK1hC9uKpp=PKmwpthjhDA+byobz_v5h0VC6RCOh3EmyagqwJw@mail.gmail.com>
References: <CAK1hC9uKpp=PKmwpthjhDA+byobz_v5h0VC6RCOh3EmyagqwJw@mail.gmail.com>
Message-ID: <CAK1hC9s3F7NR4NTeB1HbD4E=pSi13t721_t3pPOjiLoqNgGz5w@mail.gmail.com>

This is the wrong part of my code.

>
>> idName=users[users$id %in% ext]
>           id        name
> 1: U03AEKWTL agreenmamba
> 2: U032FHV3S   poisonivy
> 3: U03AEKYL4      vairis
>

Best is to use:

idNames <- users[pmatch(ext, users$id, duplicates.ok = T)]. This leave
me with an ordered and duplicate entries :

> idNames <- users[pmatch(ext, users$id, duplicates.ok = T)]
          id        name
1: U03AEKYL4      vairis
2: U03AEKYL4      vairis
3: U03AEKWTL agreenmamba
4: U032FHV3S   poisonivy


From petr.pikal at precheza.cz  Fri Feb 13 13:03:46 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 13 Feb 2015 12:03:46 +0000
Subject: [R] problems with packages installation
In-Reply-To: <7134618E-DDD1-4D77-AC99-3E5844F5438D@dcn.davis.CA.us>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FD21@SRVEXCHMBX.precheza.cz>
	<7134618E-DDD1-4D77-AC99-3E5844F5438D@dcn.davis.CA.us>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FE74@SRVEXCHMBX.precheza.cz>

Hi Jeff

Can you be more specific why question about "using" R-devel shall be directed to R-devel help list?

Posting guide tells me:

R-help is intended to be comprehensible to people who want to use R to solve problems but who are not necessarily interested in or knowledgeable about programming. R-devel is intended for questions and discussion about code development in R. Questions likely to prompt discussion unintelligible to non-programmers should go to to R-devel. For example, questions involving C, C++, etc. code should go to R-devel. More general questions involving pure R code and questions likely to be of interest to the large and diverse set of subscribers to R-help should go to R-help.

and

If you are using an old version of R and think it does not work properly, upgrade to the latest version and try that, before posting. If possible, try the current R-patched or R-devel version of R (see the FAQ for details), to see if the problem has already been addressed.

So even Posting guide suggests to poor user not to use obsolete version of R and try R-patched or R-devel.

To be honest - in R-patched (3.1.2)

setInternet2(TRUE)
utils:::menuInstallPkgs()

works without problems and the same applies to R-devel version from June (3.2.0 - 66175) but it throws error in (3.2.0 - 67792).

There is 15814 bug report about Package Installation which is replied by Brian Ripley:

The 'package installer' is the program which installs the Apple package.  If you mean the 'Package Installer' menu item in R.app, there is a known issue (but that is only known to causes failures, not freezes).

I tried Richard's suggestion (thanks Richard) and with small modification (I do not want to install from sources)

install.packages("ggplot2", repos="http://cran.at.r-project.org", dependencies=TRUE)

works as expected, therefore the problem is in **menu driven installation procedure**. Shall I fill a bug report? Or it is already known to R developers?

Best regards
Petr


> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
> Sent: Thursday, February 12, 2015 6:15 PM
> To: PIKAL Petr; r-help at r-project.org
> Subject: Re: [R] problems with packages installation
>
> Time to (re)read the Posting Guide... questions about unreleased
> versions of R are off topic here. Go to R-devel.
> -----------------------------------------------------------------------
> ----
> Jeff Newmiller                        The     .....       .....  Go
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..
> Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> -----------------------------------------------------------------------
> ----
> Sent from my phone. Please excuse my brevity.
>
> On February 12, 2015 11:40:48 AM EST, PIKAL Petr
> <petr.pikal at precheza.cz> wrote:
> >Dear all
> >
> >I just switched to new version
> >
> >> version
> >               _
> >platform       i386-w64-mingw32
> >arch           i386
> >os             mingw32
> >system         i386, mingw32
> >status         Under development (unstable)
> >major          3
> >minor          2.0
> >year           2015
> >month          02
> >day            11
> >svn rev        67792
> >language       R
> >version.string R Under development (unstable) (2015-02-11 r67792)
> >nickname       Unsuffered Consequences
> >
> >and started to have problems with installing packages through utils
> >
> >> setInternet2(TRUE)
> >> utils:::menuInstallPkgs()
> >--- Please select a CRAN mirror for use in this session --- also
> >installing the dependencies ?colorspace?, ?Rcpp?, ?stringr?,
> >?RColorBrewer?, ?dichromat?, ?munsell?, ?labeling?, ?plyr?, ?digest?,
> >?gtable?, ?reshape2?, ?scales?, ?proto?
> >
> >trying URL
> >'http://cran.at.r-project.org/src/contrib/colorspace_1.2-4.zip'
> >Error in download.file(url, destfile, method, mode = "wb", ...) :
> >cannot open URL
> >'http://cran.at.r-project.org/src/contrib/colorspace_1.2-4.zip'
> >In addition: Warning message:
> >In download.file(url, destfile, method, mode = "wb", ...) :
> >  cannot open: HTTP status was '404 Not Found'
> >Warning in download.packages(pkgs, destdir = tmpd, available =
> >available,  :
> >  download of package ?colorspace? failed ....
> >
> >Before I start to disturb our IT I just want to know what could be the
> >issue. AFAIK I did not change anything on my PC. In previous R-devel
> >version I used this package installation worked (and still works)
> >
> >> utils:::menuInstallPkgs()
> >--- Please select a CRAN mirror for use in this session --- trying URL
> >'http://cran.at.r-project.org/bin/windows/contrib/3.2/mice_2.22.zip'
> >Content type 'application/zip' length 1148843 bytes (1.1 Mb) opened
> URL
> >downloaded 1.1 Mb
> >
> >package ?mice? successfully unpacked and MD5 sums checked
> >
> >The downloaded binary packages are in
> >C:\Documents and Settings\PikalP\Local
> >Settings\Temp\RtmpgZuQB3\downloaded_packages
> >
> >> version
> >               _
> >platform       i386-w64-mingw32
> >arch           i386
> >os             mingw32
> >system         i386, mingw32
> >status         Under development (unstable)
> >major          3
> >minor          2.0
> >year           2014
> >month          07
> >day            16
> >svn rev        66175
> >language       R
> >version.string R Under development (unstable) (2014-07-16 r66175)
> >nickname       Unsuffered Consequences
> >
> >can you suggest what changed between those 2 R versions what prevents
> >me in convenient installation of packages.
> >
> >Petr
> >
> >BTW. I can install packages manually but when there are many
> >dependencies it can be rather tricky.
> >
> >

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From S.Ellison at LGCGroup.com  Fri Feb 13 14:30:32 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 13 Feb 2015 13:30:32 +0000
Subject: [R] [BUG] or [undocumented] boxplot - horizontal swaps ylim and
 xlim
In-Reply-To: <m2mw4iytea.fsf@krugs.de>
References: <m2mw4iytea.fsf@krugs.de>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED66043CB213@GOLD.corp.lgc-group.com>

> When using the function boxplot() together with the argument
> | horizontal = TRUE
> xlim and ylim become swapped, i.e. ylim refers to the x-axis instead of the y-
> axis:

It is neither a bug nor undocumented, though the documentation is a not in ?boxplot (because xlim and ylim aren't defined there) and is also tad unclear in the present version.

For boxplot and its methods, xlim and ylim fall into '...', which is (as documented) passed to bxp (see boxplot.default).
?bxp, says:

"pars,...: graphical parameters (etc) can be passed as arguments to this
          function, either as a list ('pars') or normally('...'), see
          the following.  (Those in '...' take precedence over those in
          'pars'.)

          Currently, 'yaxs' and 'ylim' are used 'along the boxplot',
          i.e., vertically, when 'horizontal' is false, and 'xlim'
          horizontally.  'xaxt', 'yaxt', 'las', 'cex.axis', and
          'col.axis' are passed to 'axis', and 'main', 'cex.main',
          'col.main', 'sub', 'cex.sub', 'col.sub', 'xlab', 'ylab',
          'cex.lab', and 'col.lab' are passed to 'title'."

The key phrase is "Currently, 'yaxs' and 'ylim' are used 'along the boxplot',"     

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From petr.pikal at precheza.cz  Fri Feb 13 14:35:55 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 13 Feb 2015 13:35:55 +0000
Subject: [R] suggestion for optimal plotting to show significant
 differences
In-Reply-To: <CAGx1TMA7q1DNoEPkn49-muTf0ZJQMK5sA134aDO9x1gE5Bfkiw@mail.gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F0E3@SRVEXCHMBX.precheza.cz>
	<CAGx1TMCq1jXtuyofWv5nYC2So0RyKDp_734ze6rAQXztaxccnw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1F3E0@SRVEXCHMBX.precheza.cz>
	<CAGx1TMDvvOOukbUfk23GrWQLSnmwr-Ykx6Qj=xYZLWraAfBKxA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FC45@SRVEXCHMBX.precheza.cz>
	<CAGx1TMA7q1DNoEPkn49-muTf0ZJQMK5sA134aDO9x1gE5Bfkiw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FEA0@SRVEXCHMBX.precheza.cz>

Hi Rich

As usual in R one can come to same result by different means. Using lme from nlme

fit<- lme(value ~ day, data=test, random= ~1|item)
ranef(fit)
  (Intercept)
a  -4.8794330
b  -3.5063635
c  -1.7121614
d  -0.2002288
e   0.5118846
f   1.7805122
g   3.4489819
h   4.5568079
fixef(fit)
(Intercept)         day
6.933644464 0.009715795

which is close to the way how "value" was constructed (day coefficient shall be 1)

> mean(apply(ranef(fit), 2,diff))
[1] 1.348034

But AFAIK lme or nlme is applicable only if I can find some suitable model function.

I therefore like your suggestion to treat day as a factor which, if I understand it well, enables me to look at item differences each day and compare if they are or are not important.

Thanks for your insight
Best regards

Petr


> -----Original Message-----
> From: Richard M. Heiberger [mailto:rmh at temple.edu]
> Sent: Thursday, February 12, 2015 9:27 PM
> To: PIKAL Petr
> Cc: r-help at r-project.org
> Subject: Re: [R] suggestion for optimal plotting to show significant
> differences
>
> ## The next step is to think of this in the analysis of covariance
> setting.
>
> ## this example is based on
>
> library(HH)
>
> demo("ancova", package="HH", ask=FALSE)
>
> item<-rep(letters[1:8], each=18)
> day<-rep((0:5)*100, 24)
> set<-rep(rep(1:3, each=6), 8)
> test<-data.frame(item, day, set)
> set.seed(111)
> test$value<-(test$day/100+1)+rnorm(144)
> test$value<-test$value+(as.numeric(test$item)*1.3)
> test$dayf <- factor(test$day)
>
>
> Fitalphabeta <- aov(value ~ day, data=test)
> AB <- xyplot(value ~ day | item, data=test, layout=c(8,1),
> scales=list(alternating=1),
>              main="regression, ignoring item\ncommon slope, common
> intercept") +
>                layer(panel.abline(coef(Fitalphabeta)))
> AB
>
> Fitalphabeta0 <- aov(value ~ 0 + item, data=test)
> AB0 <- xyplot(value ~ day | item, data=test, layout=c(8,1),
> scales=list(alternating=1),
>               main="anova, ignoring day\nzero slope, variable
> intercept") +
>
> layer(panel.abline(a=coef(Fitalphabeta0)[panel.number()], b=0))
> AB0
>
> Fitalphaibeta <- aov(value ~ 0 + item + day, data=test)
> AiB <- xyplot(value ~ day | item, data=test, layout=c(8,1),
> scales=list(alternating=1),
>               main="ancova\ncommon slope, variable intercept") +
>
> layer(panel.abline(a=coef(Fitalphaibeta)[panel.number()],
> b=rev(coef(Fitalphaibeta))[1]))
> AiB
>
> Fitalphaibetaj <- aov(value ~ 0 + item / day, data=test)
> AiBj <- xyplot(value ~ day | item, data=test, layout=c(8,1),
> scales=list(alternating=1),
>                main="ancova with interaction\nvariable slope, variable
> intercept") +
>
> layer(panel.abline(a=coef(Fitalphaibetaj)[panel.number()],
> b=coef(Fitalphaibetaj)[8 + panel.number()]))
> AiBj
>
> ## this is very tight on the standard 7x7 plotting surface.
> ## it will look ok with 10in wide and 7in high
> ## pdf("AB2x2.pdf", height=7, width=10)
> print(AB,   split=c(1, 1, 2, 2), more=TRUE)
> print(AB0,  split=c(1, 2, 2, 2), more=TRUE)
> print(AiB,  split=c(2, 1, 2, 2), more=TRUE)
> print(AiBj, split=c(2, 2, 2, 2), more=FALSE)
> ## dev.off()
>
> ## this arrangement matches the arrangement in demo("ancova")
> ## this too is very tight on the standard 7x7 plotting surface.
> ## it will look ok with 10in wide and 10in high
> ## pdf("AB2x3.pdf", height=10, width=10)
> print(AB,   split=c(1, 2, 2, 3), more=TRUE)
> print(AB0,  split=c(2, 3, 2, 3), more=TRUE)
> print(AiB,  split=c(2, 2, 2, 3), more=TRUE)
> print(AiBj, split=c(2, 1, 2, 3), more=FALSE)
> ## dev.off()
>
>
> On Thu, Feb 12, 2015 at 9:48 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Hi Rich
> >
> >> -----Original Message-----
> >> From: Richard M. Heiberger [mailto:rmh at temple.edu]
> >> Sent: Wednesday, February 11, 2015 10:53 PM
> >> To: PIKAL Petr
> >> Cc: r-help at r-project.org
> >> Subject: Re: [R] suggestion for optimal plotting to show significant
> >> differences
> >>
> >> Petr,
> >>
> >> My first attempt is to use the simple=TRUE argument to
> interaction2wt.
> >>
> >> Then the bwplots in the item|item panel show the behavior of value
> over
> >> day for each item.  You get a plot similar to this panel with the
> >> growth curve plots from nlme, for example,
> >>     bwplot(value ~ day | item, data=test, horizontal=FALSE) I am
> >> treating set as a replication and each box is cumulated over the
> three
> >> sets.
> >
> > Yes, that is the point - set is actually replication of result.
> >
> >>
> >> My analysis question is about day.  You have it as numeric.  My
> >> inclination would be to make day factor.  Then you could model the
> >> interaction of day and item.
> >
> > Hm. I hoped I can do
> >
> > fit<-lm(value~day*item, data=test)
> > summary(fit)
> >
> > in which case I can compare differences in intercepts and/or slopes
> for each item.
> >
> > However I am rather lost in aov
> >
> > test$dayf <- factor(test$day)
> >
> > fit1 <- aov(value~item+dayf, data=test)
> > summary(fit)
> > fit2 <- aov(value~item/dayf, data=test)
> > summary(fit)
> > and
> > fit3 <- aov(value~item*dayf, data=test)
> > summary(fit)
> > which gives bascally the same result as fit2
> >
> >> anova(fit1, fit2)
> > Analysis of Variance Table
> >
> > Model 1: value ~ item + dayf
> > Model 2: value ~ item/dayf
> >   Res.Df    RSS Df Sum of Sq      F Pr(>F)
> > 1    131 160.59
> > 2     96 128.60 35    31.993 0.6824 0.8993
> >
> > TukeyHSD(fit1, which="item")
> > TukeyHSD(fit2, which="item")
> >
> > Both models seems to give quite similar results and I am not sure
> what actually differs in those models. I believe that model2 tests each
> item within particular day (but I am not sure about it).
> >
> > However this discussion is probably deviating more to the statistics
> issue than to R itself.
> >
> > I just thought that somebody helps me with a method for comparison of
> item performance in case that relation of value to day is not simple
> linear (as in my example) and cannot be expressed by some formula (like
> examples in nlme).
> >
> > So far the best options are either your bwplot or my ggplots.
> >
> > p<-ggplot(test, aes(x=day, y=value, colour=item))
> > p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))
> >
> > p<-ggplot(test, aes(x=dayf, y=value, colour=item))
> > p+geom_boxplot()
> >
> > p<-ggplot(test, aes(x=item, y=value))
> > p+geom_boxplot()+facet_wrap(~day)
> >
> > Thank you for your suggestions which directed me to interaction plots
> which I was not aware of.
> >
> > Best regards
> > Petr
> >
> >
> >>
> >> Rich
> >>
> >> On Mon, Feb 9, 2015 at 6:01 AM, PIKAL Petr <petr.pikal at precheza.cz>
> >> wrote:
> >> > Hallo Richard.
> >> >
> >> > I tried your suggestion but it seems to be no better than simple
> >> ggplot. Let me extend the example a bit to 8 items which is more
> >> realistic.
> >> >
> >> > item<-rep(letters[1:8], each=18)
> >> > day<-rep((0:5)*100, 24)
> >> > set<-rep(rep(1:3, each=6), 8)
> >> > test<-data.frame(item, day, set)
> >> > set.seed(111)
> >> > test$value<-(test$day/100+1)+rnorm(144)
> >> > test$value<-test$value+(as.numeric(test$item)*1.3)
> >> >
> >> > Value is increasing during time (day) for each tested subject
> (item),
> >> each item is measured 3 times (set) each day.
> >> >
> >> > Here is some graph
> >> > p<-ggplot(test, aes(x=day, y=value, colour=item))
> >> > p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))
> >> >
> >> > I can do lm or aov, however I am not sure about proper formula.
> >> >
> >> > fit<-lm(value~day, data=test)
> >> > summary(fit)
> >> > # this shows that value is increasing with day
> >> >
> >> > fit<-lm(value~day/item, data=test)
> >> > summary(fit)
> >> > # this suggests that value is decreasing with day (which is wrong)
> >> >
> >> > fit<-lm(value~day*item, data=test)
> >> > summary(fit)
> >> > # and this tells me that value is increasing with day and items
> have
> >> different intercepts but the same rate of growth (I hope I got it
> >> right).
> >> >
> >> > I do not have your book available but I went through help pages.
> >> >
> >> > Your interaction graph is not much better than ggplot.
> >> > I can do
> >> >
> >> > interaction2wt(value ~ item * day, data=test)
> >> >
> >> > which probably is closer to actual problem.
> >> >
> >> > The basic problem is that increase of value with days is in fact
> not
> >> linear and actually it can increase in the beginning and then
> stagnate
> >> or it can stagnate in beginning and then increase. I am not aware of
> >> any way how to compare time behaviour of different items in such
> >> situations if I cannot state some common formula in which case I
> would
> >> use probably nlme.
> >> >
> >> > Thank for your insight, I try to go through it more deeply.
> >> >
> >> > Best regards
> >> > Petr
> >> >
> >> >
> >> >> -----Original Message-----
> >> >> From: Richard M. Heiberger [mailto:rmh at temple.edu]
> >> >> Sent: Friday, February 06, 2015 6:14 PM
> >> >> To: PIKAL Petr
> >> >> Cc: r-help at r-project.org
> >> >> Subject: Re: [R] suggestion for optimal plotting to show
> significant
> >> >> differences
> >> >>
> >> >> I would try one of these illustrations for starts.
> >> >> interaction2wt (two-way tables) is designed to be used with aov()
> >> for
> >> >> testing.
> >> >> interaction2wt shows all main effects and all two-way
> interactions
> >> >> for many factors.
> >> >>
> >> >>
> >> >>
> >> >> test <-
> >> >> structure(list(item = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L,
> >> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L,
> >> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A", "B"),
> class
> >> >> = "factor"), day = c(0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L,
> >> >> 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L,
> 100L,
> >> >> 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L,
> 100L,
> >> >> 200L, 300L, 400L, 500L), set = c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
> 2L,
> >> >> 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
> 2L,
> >> >> 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L), value =
> c(1.08163365169503,
> >> >> 2.61998412608805, 3.07820466606394, 4.44993419381934,
> >> >> 5.29163171545805, 6.29155990999293, -0.123163011367676,
> >> >> 2.07767236834003, 2.32537052874901, 3.09372794501084,
> >> >> 6.65273721166635, 5.92304962329131, 1.50504697705548,
> >> >> 2.66253728086866, 2.63420157418685, 2.78195098580416,
> >> >> 6.47578642973288, 5.89587443775143, 0.848864231485078,
> >> >> 1.27549677119713, 2.19573089053609, 2.45659926134292,
> >> >> 5.15424403414103, 5.4813151140983, 1.25731482647214,
> >> >> 2.09662105167973, 1.75954023316977, 4.81624002288939,
> >> >> 4.65029189325307, 6.39946904227214, 0.944996929887344,
> >> >> 1.74667265331284, 2.42956264345558, 5.17852980415141,
> >> >> 3.5453435965834, 6.9011238437191)), .Names = c("item", "day",
> "set",
> >> >> "value"), row.names = c(NA, -36L), class =
> >> >> "data.frame")
> >> >>
> >> >>
> >> >>
> >> >> library(HH)
> >> >>
> >> >> test$set <- factor(test$set)
> >> >> test$day <- factor(test$day)
> >> >> test$item <- factor(test$item)
> >> >>
> >> >> interaction2wt(value ~ item * day * set, data=test)
> >> >>
> >> >> test$item.day <- interaction(test$item, test$day)
> >> >> position(test$item.day) <- outer(c(-10,10),
> >> >> as.numeric(levels(test$day)), `+`)
> >> >>
> >> >> xyplot(value ~ as.position(item.day) | set, groups=item,
> >> >>         data=test, horizontal=FALSE, pch=c(17,16),
> >> >>         xlab="day",
> >> >>         scales=list(
> >> >>           x=list(
> >> >>             alternating=1,
> >> >>             at=levels(test$day), ## placement of tick labels and
> >> marks
> >> >>             tck=1)),
> >> >>         key=list(
> >> >>           text=list(c("A","B"), col=c("blue","red")),
> >> >>           points=list(pch=c(17, 16), col=c("blue","red")),
> >> >>        space="top", columns=2, border=TRUE),
> >> >>        layout=c(3,1))
> >> >>
> >> >>
> >> >> ## see also the examples in
> >> >> demo(package="HH", bwplot.examples)
> >> >>
> >> >> On Fri, Feb 6, 2015 at 6:09 AM, PIKAL Petr
> <petr.pikal at precheza.cz>
> >> >> wrote:
> >> >> > Dear all
> >> >> >
> >> >> > I would like to ask for your opinion about possible graphical
> >> >> representation of such data.
> >> >> >
> >> >> >> dput(test)
> >> >> > structure(list(item = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L,
> >> >> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L,
> >> >> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("A",
> "B"),
> >> >> > class
> >> >> =
> >> >> > "factor"), day = c(0L, 100L, 200L, 300L, 400L, 500L, 0L, 100L,
> >> >> > 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L,
> >> 100L,
> >> >> > 200L, 300L, 400L, 500L, 0L, 100L, 200L, 300L, 400L, 500L, 0L,
> >> 100L,
> >> >> > 200L, 300L, 400L, 500L), set = c(1L, 1L, 1L, 1L, 1L, 1L, 2L,
> 2L,
> >> >> > 2L, 2L,
> >> >> 2L,
> >> >> > 2L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
> >> 2L,
> >> >> > 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L), value = c(1.08163365169503,
> >> >> > 2.61998412608805, 3.07820466606394, 4.44993419381934,
> >> >> > 5.29163171545805, 6.29155990999293, -0.123163011367676,
> >> >> > 2.07767236834003, 2.32537052874901, 3.09372794501084,
> >> >> > 6.65273721166635, 5.92304962329131, 1.50504697705548,
> >> >> > 2.66253728086866, 2.63420157418685, 2.78195098580416,
> >> >> > 6.47578642973288, 5.89587443775143, 0.848864231485078,
> >> >> > 1.27549677119713, 2.19573089053609, 2.45659926134292,
> >> >> > 5.15424403414103, 5.4813151140983, 1.25731482647214,
> >> >> 2.09662105167973,
> >> >> > 1.75954023316977, 4.81624002288939, 4.65029189325307,
> >> >> > 6.39946904227214, 0.944996929887344, 1.74667265331284,
> >> >> > 2.42956264345558, 5.17852980415141, 3.5453435965834,
> >> >> > 6.9011238437191)), .Names = c("item", "day", "set", "value"),
> >> >> > row.names = c(NA, -36L), class = "data.frame")
> >> >> >>
> >> >> >
> >> >> > One option I came with is
> >> >> >
> >> >> > library(ggplot2)
> >> >> > p<-ggplot(test, aes(x=day, y=value, colour=item))
> >> >> > p+geom_point()+stat_smooth(method="lm", formula= y~poly(x,2))
> >> >> >
> >> >> > but -
> >> >> > I have more items (around 5-10), and I want to show if the
> >> >> > difference
> >> >> between items is or is not significant. The actual development of
> >> >> value with day is usually not linear nor growing steadily and
> >> >> actually I cannot usually evaluate some analytical equation for
> my
> >> >> data to compare equation parameters.
> >> >> >
> >> >> > I thought about boxplots, but there is not many repetitions and
> >> >> actually 5+ boxplots can be quite messy.
> >> >> >
> >> >> > I can plot only mean for each set and item but in that case I
> lose
> >> >> information if the difference is or is not significant.
> >> >> >
> >> >> > I appreciate any suggestion.
> >> >> >
> >> >> > Best regards
> >> >> > Petr
> >> >> >
> >

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From S.Ellison at LGCGroup.com  Fri Feb 13 14:45:34 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 13 Feb 2015 13:45:34 +0000
Subject: [R] SIMPLE question
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A034EE8@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A034EE8@mail-mbx-04.UNINE.CH>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED66043CB230@GOLD.corp.lgc-group.com>

> I want to do a boxcox transformation, but I got this:
> Error: could not find function "boxcox"
> 
> What can I do? 

Well, the recommended 'homework' in the posting guide would be a start.

i) ??boxcox, if you have any packages installed that include something with that functionality.
ii) RSiteSearch("Box-Cox")
iii) Use a search engine to find  'box-cox transform in R'

These would lead you to a number of packages, such as the car package, which include the transform. 

S


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From therneau at mayo.edu  Fri Feb 13 14:53:35 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 13 Feb 2015 07:53:35 -0600
Subject: [R] Sorting Surv objects
In-Reply-To: <mailman.1.1423825202.10875.r-help@r-project.org>
References: <mailman.1.1423825202.10875.r-help@r-project.org>
Message-ID: <1e7ee5$25h4b@ironport10.mayo.edu>

Your work around is not as "easy" looking to me.

Survival times come in multiple flavors: left censored, right censored, interval censored, 
left-truncated and right censored, and multi-state.  Can you give me guidance on how each 
of these should sort?  If a sort method is added to the package it needs to deal with all 
of these.

  Professor Ripley has pointed out that the default action of sort() for right censored 
times, which I agree is reasonable.

Terry Therneau (author of the survival package)


On 02/13/2015 05:00 AM, r-help-request at r-project.org wrote:
> It seems that Surv objects do not sort correctly.   This seems to be a bug.  Anyone else found this?
>
>> >survival.data
> [1] 4+ 3  1+ 2  5+
>> >class(survival.data)
> [1] "Surv"
>> >sort(survival.data)
> [1] 2  1+ 4+ 3  5+
>
> An easy work-around is to define a function sort.Surv


From Rainer at krugs.de  Fri Feb 13 15:03:30 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 13 Feb 2015 15:03:30 +0100
Subject: [R] [BUG] or [undocumented] boxplot - horizontal swaps ylim and
	xlim
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED66043CB213@GOLD.corp.lgc-group.com>
	(S. Ellison's message of "Fri, 13 Feb 2015 13:30:32 +0000")
References: <m2mw4iytea.fsf@krugs.de>
	<A4E5A0B016B8CB41A485FC629B633CED66043CB213@GOLD.corp.lgc-group.com>
Message-ID: <m2iof5zz65.fsf@krugs.de>

S Ellison <S.Ellison at LGCGroup.com> writes:

>> When using the function boxplot() together with the argument
>> | horizontal = TRUE
>> xlim and ylim become swapped, i.e. ylim refers to the x-axis instead of the y-
>> axis:
>
> It is neither a bug nor undocumented, though the documentation is a
> not in ?boxplot (because xlim and ylim aren't defined there) and is
> also tad unclear in the present version.
>
> For boxplot and its methods, xlim and ylim fall into '...', which is
> (as documented) passed to bxp (see boxplot.default).
> ?bxp, says:
>
> "pars,...: graphical parameters (etc) can be passed as arguments to this
>           function, either as a list ('pars') or normally('...'), see
>           the following.  (Those in '...' take precedence over those in
>           'pars'.)
>
>           Currently, 'yaxs' and 'ylim' are used 'along the boxplot',
>           i.e., vertically, when 'horizontal' is false, and 'xlim'
>           horizontally.  'xaxt', 'yaxt', 'las', 'cex.axis', and
>           'col.axis' are passed to 'axis', and 'main', 'cex.main',
>           'col.main', 'sub', 'cex.sub', 'col.sub', 'xlab', 'ylab',
>           'cex.lab', and 'col.lab' are passed to 'title'."
>
> The key phrase is "Currently, 'yaxs' and 'ylim' are used 'along the boxplot',"     

Thanks for clarifying this.

I think this should be mentioned in boxplot as well.

Cheers,

Rainer

>
> S Ellison
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:24}}

From jdnewmil at dcn.davis.CA.us  Fri Feb 13 15:56:21 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 13 Feb 2015 06:56:21 -0800
Subject: [R] problems with packages installation
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FE74@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FD21@SRVEXCHMBX.precheza.cz>
	<7134618E-DDD1-4D77-AC99-3E5844F5438D@dcn.davis.CA.us>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FE74@SRVEXCHMBX.precheza.cz>
Message-ID: <F2AAA457-0CD8-41CB-BAD4-4005F255F441@dcn.davis.CA.us>

I agree that the PG muddies the water a bit on this topic. However, the web page from which you downloaded the patched version warns:

"This is not an official release of R. Please check bugs in this version against the official release before reporting them."

When a new version is under  development, the number of bugs often increases temporarily by quite a bit. Any use you make of a patched or development version is at your own risk, and should be undertaken for two reasons only: to address a  specific problem you are having with the released version, or because you want to help test the unreleased version out of the goodness of your heart (bless you). In either case, chatter about bugs you encounter that are not in the released version belongs on R-devel.

If you can reproduce the problem in a released version, posting on R-help would be more appropriate, but if you are sure it is a bug then filling a report is the right thing to do.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 13, 2015 4:03:46 AM PST, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Hi Jeff
>
>Can you be more specific why question about "using" R-devel shall be
>directed to R-devel help list?
>
>Posting guide tells me:
>
>R-help is intended to be comprehensible to people who want to use R to
>solve problems but who are not necessarily interested in or
>knowledgeable about programming. R-devel is intended for questions and
>discussion about code development in R. Questions likely to prompt
>discussion unintelligible to non-programmers should go to to R-devel.
>For example, questions involving C, C++, etc. code should go to
>R-devel. More general questions involving pure R code and questions
>likely to be of interest to the large and diverse set of subscribers to
>R-help should go to R-help.
>
>and
>
>If you are using an old version of R and think it does not work
>properly, upgrade to the latest version and try that, before posting.
>If possible, try the current R-patched or R-devel version of R (see the
>FAQ for details), to see if the problem has already been addressed.
>
>So even Posting guide suggests to poor user not to use obsolete version
>of R and try R-patched or R-devel.
>
>To be honest - in R-patched (3.1.2)
>
>setInternet2(TRUE)
>utils:::menuInstallPkgs()
>
>works without problems and the same applies to R-devel version from
>June (3.2.0 - 66175) but it throws error in (3.2.0 - 67792).
>
>There is 15814 bug report about Package Installation which is replied
>by Brian Ripley:
>
>The 'package installer' is the program which installs the Apple
>package.  If you mean the 'Package Installer' menu item in R.app, there
>is a known issue (but that is only known to causes failures, not
>freezes).
>
>I tried Richard's suggestion (thanks Richard) and with small
>modification (I do not want to install from sources)
>
>install.packages("ggplot2", repos="http://cran.at.r-project.org",
>dependencies=TRUE)
>
>works as expected, therefore the problem is in **menu driven
>installation procedure**. Shall I fill a bug report? Or it is already
>known to R developers?
>
>Best regards
>Petr
>
>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
>> Sent: Thursday, February 12, 2015 6:15 PM
>> To: PIKAL Petr; r-help at r-project.org
>> Subject: Re: [R] problems with packages installation
>>
>> Time to (re)read the Posting Guide... questions about unreleased
>> versions of R are off topic here. Go to R-devel.
>>
>-----------------------------------------------------------------------
>> ----
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#..
>> Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>-----------------------------------------------------------------------
>> ----
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 12, 2015 11:40:48 AM EST, PIKAL Petr
>> <petr.pikal at precheza.cz> wrote:
>> >Dear all
>> >
>> >I just switched to new version
>> >
>> >> version
>> >               _
>> >platform       i386-w64-mingw32
>> >arch           i386
>> >os             mingw32
>> >system         i386, mingw32
>> >status         Under development (unstable)
>> >major          3
>> >minor          2.0
>> >year           2015
>> >month          02
>> >day            11
>> >svn rev        67792
>> >language       R
>> >version.string R Under development (unstable) (2015-02-11 r67792)
>> >nickname       Unsuffered Consequences
>> >
>> >and started to have problems with installing packages through utils
>> >
>> >> setInternet2(TRUE)
>> >> utils:::menuInstallPkgs()
>> >--- Please select a CRAN mirror for use in this session --- also
>> >installing the dependencies ?colorspace?, ?Rcpp?, ?stringr?,
>> >?RColorBrewer?, ?dichromat?, ?munsell?, ?labeling?, ?plyr?,
>?digest?,
>> >?gtable?, ?reshape2?, ?scales?, ?proto?
>> >
>> >trying URL
>> >'http://cran.at.r-project.org/src/contrib/colorspace_1.2-4.zip'
>> >Error in download.file(url, destfile, method, mode = "wb", ...) :
>> >cannot open URL
>> >'http://cran.at.r-project.org/src/contrib/colorspace_1.2-4.zip'
>> >In addition: Warning message:
>> >In download.file(url, destfile, method, mode = "wb", ...) :
>> >  cannot open: HTTP status was '404 Not Found'
>> >Warning in download.packages(pkgs, destdir = tmpd, available =
>> >available,  :
>> >  download of package ?colorspace? failed ....
>> >
>> >Before I start to disturb our IT I just want to know what could be
>the
>> >issue. AFAIK I did not change anything on my PC. In previous R-devel
>> >version I used this package installation worked (and still works)
>> >
>> >> utils:::menuInstallPkgs()
>> >--- Please select a CRAN mirror for use in this session --- trying
>URL
>> >'http://cran.at.r-project.org/bin/windows/contrib/3.2/mice_2.22.zip'
>> >Content type 'application/zip' length 1148843 bytes (1.1 Mb) opened
>> URL
>> >downloaded 1.1 Mb
>> >
>> >package ?mice? successfully unpacked and MD5 sums checked
>> >
>> >The downloaded binary packages are in
>> >C:\Documents and Settings\PikalP\Local
>> >Settings\Temp\RtmpgZuQB3\downloaded_packages
>> >
>> >> version
>> >               _
>> >platform       i386-w64-mingw32
>> >arch           i386
>> >os             mingw32
>> >system         i386, mingw32
>> >status         Under development (unstable)
>> >major          3
>> >minor          2.0
>> >year           2014
>> >month          07
>> >day            16
>> >svn rev        66175
>> >language       R
>> >version.string R Under development (unstable) (2014-07-16 r66175)
>> >nickname       Unsuffered Consequences
>> >
>> >can you suggest what changed between those 2 R versions what
>prevents
>> >me in convenient installation of packages.
>> >
>> >Petr
>> >
>> >BTW. I can install packages manually but when there are many
>> >dependencies it can be rather tricky.
>> >
>> >
>
>________________________________
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
>ze strany p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>zn?m?.
>
>This e-mail and any documents attached to it may be confidential and
>are intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its
>sender. Delete the contents of this e-mail with all attachments and its
>copies from your system.
>If you are not the intended recipient of this e-mail, you are not
>authorized to use, disseminate, copy or disclose this e-mail in any
>manner.
>The sender of this e-mail shall not be liable for any possible damage
>caused by modifications of the e-mail or by delay with transfer of the
>email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into
>a contract in any time, for any reason, and without stating any
>reasoning.
>- if the e-mail contains an offer, the recipient is entitled to
>immediately accept such offer; The sender of this e-mail (offer)
>excludes any acceptance of the offer on the part of the recipient
>containing any amendment or variation.
>- the sender insists on that the respective contract is concluded only
>upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to
>enter into any contracts on behalf of the company except for cases in
>which he/she is expressly authorized to do so in writing, and such
>authorization or power of attorney is submitted to the recipient or the
>person represented by the recipient, or the existence of such
>authorization is known to the recipient of the person represented by
>the recipient.


From amen.alyaari at Bordeaux.inra.fr  Fri Feb 13 10:59:20 2015
From: amen.alyaari at Bordeaux.inra.fr (Jonsson)
Date: Fri, 13 Feb 2015 01:59:20 -0800 (PST)
Subject: [R] Why I am getting error when writing a function for "optim"?
Message-ID: <1423821560641-4703205.post@n4.nabble.com>

I have three directories where there is inside each of them 5 files.each file
is a matrix lines 500 and columns 300. I want to perform an optimization
using values from three corresponding pixels.Finally I get a matrix of lines
500 and columns 300 for each parameter in my equation:

           y=(ax1+bx2+c)^2+d
reproducible example:

  dat1 <- array(1:60, c(3,5,4));dat2 <- array(rnorm(60), c(3,5,4));
  dat3 <-array(rnorm(60), c(3,5,4))
reorder dimensions

   dat1 <- aperm(dat1, c(3,1,2));dat2 <- aperm(dat2, c(3,1,2));
   dat3 <- aperm(dat2, c(3,1,2))
make array a matrix

  dat1a <- dat1  ; dim(dat1a) <- c(dim(dat1)[1],prod(dim(dat1)[2:3]))
  dat2a <- dat2;  dim(dat2a) <- c(dim(dat2)[1],prod(dim(dat2)[2:3]))
  dat3a <- dat3 ; dim(dat3a) <- c(dim(dat3)[1],prod(dim(dat3)[2:3]))

> fun
function(x1,x2, y) {
  keep <- !(is.na(x) | is.na(x2)| is.na(y))
  if (sum(keep) > 2) { #less than 3 non-NA values?
    temp <- sum((y[keep] - (p[1]*x1[keep]+p[2]*x2[keep]+p[3])^p[4]+p[5])^2)
    res <- optim(rep(NA,5),temp)
  } else {
    res <- c(NA, NA,NA,NA,NA)#five parameters
  }
 res
}
> res <- mapply(fun, x1=as.data.frame(dat1a), x2=as.data.frame(dat2a),
> y=as.data.frame(dat3a)) 
Error in optim(rep(NA, 5), temp) : non-finite value supplied by optim

Any idea please on how to correct my function?



--
View this message in context: http://r.789695.n4.nabble.com/Why-I-am-getting-error-when-writing-a-function-for-optim-tp4703205.html
Sent from the R help mailing list archive at Nabble.com.


From Michael.Langmaack at the-klu.org  Fri Feb 13 11:45:57 2015
From: Michael.Langmaack at the-klu.org (Michael Langmaack)
Date: Fri, 13 Feb 2015 10:45:57 +0000
Subject: [R] How to get the error and error variance after HB using bayesm
Message-ID: <0A511BFF87BC3147B5F91EA884F122FB3FCA72A0@KLU-MAIL-01.KLU.klu>

Hello all,

I have a question concerning bayesian regression in R using the package bayesm (version 2.2-5) by Peter Rossi. I have binary choice data and estimated individual coefficients using the command rhierBinLogit(Data=Data,Mcmc=Mcmc). That worked out properly, conversion plots, histograms, parameter are fine. No a have to compute the errors and the error variance or something like the MSE. But I do not know how to do. I did not find a hint so far. I would be more than happy if anybody can help me. Thanks in advance!

Best regards,
Michael

	[[alternative HTML version deleted]]


From randall.morrisostrom at icloud.com  Fri Feb 13 16:08:58 2015
From: randall.morrisostrom at icloud.com (Randall Morris-Ostrom)
Date: Fri, 13 Feb 2015 09:08:58 -0600
Subject: [R] 2d rotation: vegan?
Message-ID: <4476A2AE-18B8-4516-AFE8-FDB35E3082A2@icloud.com>

I've been working at interpreting the results of a non-metric multidimensional scaling analysis. I have been using metaMDS in the vegan package because one of the benefits is that it also rotates to solution to its principal components. (Eventually I realized that there is no reason why my results would be most interpretable when aligned along the PC, but it was a nice starting point.)

I have been trying to find ways to rotate the resulting plot so I can visualize it differently and look at actual plot positions (as opposed to just rotating the print outs I have been looking at.) I'm able to find lots of suggestions for how to rotate3d plots, but almost nothing for 2d. I have tried using the MDSrotate function in vegan, but really it comes down to the fact that I'm clueless when I try to make sense of the documentation. *somewhat embarrassed*  My goal is basically to rotate the plot and exam the structure as a tool to generate theories about the meaning of the different dimensions (the interpretation of the clusters in my research are crystal clear.)

I generated a little fake data, just so there would be a plot. I've been trying to figure out how to do this as either just a simple scatterplot or using the vegan package.

Thank you for your time,
Randy

Randall Morris-Ostrom J.D., M.S.
Doctoral Candidate in Psychology,
University of St. Thomas
randall.morrisostrom at icloud.com


Sample Code

library(vegan)
set.seed(12345)
x <- rnorm(1:10)
y <- rnorm(1:10)
df <- data.frame(x,y)
d <- dist(df, method = "euclidean")
nmds <- metaMDS(df, distance = "euclidean", k = 2)
plot(nmds)
# or
nmdp <- as.data.frame(nmds$points)
plot(nmdp$MDS1, nmdp$MDS2)
	[[alternative HTML version deleted]]


From js.huang at protective.com  Fri Feb 13 16:59:28 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 13 Feb 2015 07:59:28 -0800 (PST)
Subject: [R] sd, mean with a frequency distribution matrix
In-Reply-To: <1423837352778-4703218.post@n4.nabble.com>
References: <1423837352778-4703218.post@n4.nabble.com>
Message-ID: <1423843168900-4703220.post@n4.nabble.com>

Hi,

  Try this.

> sd(unlist(sapply(1:dim(p)[1],function(i)rep(p[i,1],p[i,2])))) 



--
View this message in context: http://r.789695.n4.nabble.com/sd-mean-with-a-frequency-distribution-matrix-tp4703218p4703220.html
Sent from the R help mailing list archive at Nabble.com.


From S.Ellison at LGCGroup.com  Fri Feb 13 17:59:48 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 13 Feb 2015 16:59:48 +0000
Subject: [R] Why I am getting error when writing a function for "optim"?
In-Reply-To: <1423821560641-4703205.post@n4.nabble.com>
References: <1423821560641-4703205.post@n4.nabble.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED66043CB3EE@GOLD.corp.lgc-group.com>

You don't appear to be supplying a valid parameter set to optim. 

The first argument in optim (par) must be a vector of parameters to optimise; you're passing a vector of NAs. Thise are not finite.

Also, temp is defined as a value and optim will not be able to optimise that. You need to define temp as a function.

S



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jrkrideau at inbox.com  Fri Feb 13 18:41:18 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 13 Feb 2015 09:41:18 -0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <CAM5FmSM-jucvYY6pZXfsvDUZeK2+GQg8SMti++LxFG3SL0NPQg@mail.gmail.com>
References: <cam5fmsmaidzgj+d5drptguhbm4v1tr6aljjtdjskqcmfs5w49w@mail.gmail.com>
	<4ad1edc7c1f.00000299jrkrideau@inbox.com>
	<4b1afade554.0000031bjrkrideau@inbox.com>
	<cam5fmspbv2v23ojbj=zsp4hi8onhh-rby2g1utxx-sbkqveifa@mail.gmail.com>
Message-ID: <5885A05522B.0000053Fjrkrideau@inbox.com>

Both files came through.? The R-help list is picky. For example it will accept cat.txt but not cat.csv.

Now I see what you are after. and I must admit I haven't a clue at the moment. I suspect others who know more about ggplot can help.? If not there is ggplot2 Google Groups that has a lot of knowledge and you might want to post there.? It accepts all kinds of file types. :)

On the other hand, I don't like dynamite plots (what you have) and wondered if it was possible to do something with geom_point() instead.

It was, in a bit of a half-assed way so I'll pass on my raw code. It's ulgy but works. I don't know if I'd call it pub-quality but perhaps it can be tweaked (wrenched? , bludgened?) into something acceptable.

BTW, I changed your data.frame name to dat1.  df is an R function.  Type df and you will see what I mean. I've also converted the data to a dput() file. Not needed as you supplied a perfectly good data set but generally good practice.

Sorry I was not able to be of more help

John Kane
Kingston ON Canada

############Begin code ##############
library(ggplot2)
library(scales)
dat1  <-  structure(list(gender = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L, 
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L), .Label = c("male", "female"
), class = "factor"), direction = structure(c(1L, 1L, 2L, 2L, 
1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 
1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("up", 
"down"), class = "factor"), condition = structure(c(1L, 1L, 1L, 
1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 
1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L), .Label = c("c1", 
"c2", "c3", "c4"), class = "factor"), location = structure(c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("east", 
"west"), class = "factor"), t = c(1.78664348823968, 1.045971213672, 
1.45271943418506, 1.52433880441405, 0.894240903766416, 1.04200421306615, 
0.992602172725307, 1.35686661120166, 1.15664717132331, 1.78519605814623, 
1.3131987417228, 1.23649081362245, 1.33657440193627, 1.39069933103098, 
1.16990353110185, 1.50384132346169, 0.240063246756554, 0.151918103772423, 
1.26918566082989, 1.44462610872269, 0.944676078996681, 0.945358342820427, 
0.68274449456263, 0.983609699924918, 1.06442538569853, 0.917922814494952, 
1.06681054493614, 0.899670881737641, 0.639091165646195, 1.81227533189609, 
1.02711921654525, 2.05244515236416), ci = c(0.199453475099606, 
0.0208699634619525, 0.0267762622040696, 0.0719683008799792, 0.0388022593655329, 
0.0873965412159785, 0.0828671112758008, 0.556676454332325, 0.109726976194332, 
0.237352334670391, 0.202173510668684, 0.104263016807603, 0.0174283081233597, 
0.027601059580507, 0.118300511535772, 0.272210060810133, 0.210343075045509, 
0.010793003362928, 0.241665829872765, 0.387877941848338, 0.230361471258575, 
0.233088662079594, 0.0956745517473407, 0.187969512005399, 0.0041769632082831, 
0.26242665290992, 0.297793257986101, 0.14520541873456, 0.123447338902161, 
0.10109002280374, 0.332925731545975, 0.434868806611465)), .Names = c("gender", 
"direction", "condition", "location", "t", "ci"), row.names = c(NA, 
-32L), class = "data.frame")


dat1$jit <- ifelse( dat1$gender == "male",  1,
        ifelse( dat1$gender == 'female',  2,
          NA) )
dat1$jit  <-  as.numeric(dat1$jit)

dat1$jit  <-  jitter(dat1$jit)

x  <-  "male"
y  <-  "female"############Begin code ##############
ab <-  ggplot(dat1, aes (jit, t)) +
       geom_point(aes(colour = condition)) +
        theme(axis.ticks = element_blank()) +
        scale_x_continuous(breaks=c(1, 2), 
                           labels=c("male", "female"),
                           name="Gender")
ab


bb  <-  ab + facet_grid(location~.)
bb

bc  <-  bb + 
    geom_errorbar(data = dat1, aes(ymin=t-ci, ymax=t+ci,         
                colour = condition),
                  width=.2 )
bc
  

cf  <-  bc + coord_flip()
cf

############End code ###############


John Kane
Kingston ON Canada

-----Original Message-----
From: hyiltiz at gmail.com
Sent: Fri, 13 Feb 2015 02:28:17 +0800
To: jrkrideau at inbox.com
Subject: Re: [R] ggplot2 shifting bars to only overlap in groups

I did not know the SVG file did not come through. I thought SVG should be able to pass through the filter. Here is a PDF file along with an PNG. Guess one of them should be able to pass.

???
========================
He who is worthy to receive his days and nights is worthy to receive* all 
else* from you (and me).
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? The Prophet, Gibran Kahlil 

On Fri, Feb 13, 2015 at 12:04 AM, John Kane <jrkrideau at inbox.com> wrote:

 I'm a bit blind today. I read df as a dput() .

 John Kane
 Kingston ON Canada

 -----Original Message-----
 From: hyiltiz at gmail.com
 Sent: Thu, 12 Feb 2015 23:38:01 +0800
 To: jrkrideau at inbox.com
 Subject: Re: [R] ggplot2 shifting bars to only overlap in groups

 You are most likely simply not running the whole lines of code: note that the first line is:

 N = 32

 ?Best
 ?
 ========================
 He who is worthy to receive his days and nights is worthy to receive* all
 else* from you (and me).
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? The Prophet, Gibran Kahlil

 On Thu, Feb 12, 2015 at 11:31 PM, John Kane <jrkrideau at inbox.com> wrote:

 ? ? ? ? I am gettting the error"
 ?Error in rep_len(rep.int [http://rep.int] [http://rep.int [http://rep.int]](seq_len(n), rep.int [http://rep.int] [http://rep.int [http://rep.int]](k, n)), length) :

?? object 'N' not found

 ?Also your image did not come through.? Try sending it as a pdf file.

 ?when I try to create
 ?df<- data.frame(gender=gl(2,1,N, c("male","female")),
 ?? ? ? ? ? direction=gl(2,2,N, c("up","down")),
 ?? ? ? ? ? condition=gl(4,4,N, c("c1","c2","c3","c4")),
 ?? ? ? ? ? location=gl(2,16,N, c("east","west")),
 ?? ? ? ? ? t=rnorm(N, 1, 0.5),
 ?? ? ? ? ? ci=abs(rnorm(N, 0, 0.2)))

 ?John Kane
 ?Kingston ON Canada

 ?> -----Original Message-----
 ?> From: hyiltiz at gmail.com
 ?> Sent: Thu, 12 Feb 2015 22:08:36 +0800
 ?> To: r-help at r-project.org
 ?> Subject: [R] ggplot2 shifting bars to only overlap in groups
 ?>
 ?> Hi all,
 ?>
 ?> I have four factors for a continuous time variable along with its
 ?> confidence interval. I would like to produce a publication quality error
 ?> bar chart that is clear to understand. For now, I used colors, x axis
 ?> position, facets and alpha level to distinguish them.
 ?>
 ?> I would like to overlap each pairs of bars with the same color a bit as a
 ?> group, but not overlap each and every bars with each other.
 ?>
 ?> Here is a minimal example:
 ?>
 ?> N = 32
 ?> df<- data.frame(gender=gl(2,1,N, c("male","female")),
 ?>? ? ? ? ? ?direction=gl(2,2,N, c("up","down")),
 ?>? ? ? ? ? ?condition=gl(4,4,N, c("c1","c2","c3","c4")),
 ?>? ? ? ? ? ?location=gl(2,16,N, c("east","west")),
 ?>? ? ? ? ? ?t=rnorm(N, 1, 0.5),
 ?>? ? ? ? ? ?ci=abs(rnorm(N, 0, 0.2)))
 ?> pp <-
 ?>? ?ggplot(df, aes(x=gender, y=t, fill=condition, alpha=direction)) +
 ?>? ?facet_grid(location~.) +
 ?>? ?geom_bar(position=position_dodge(.9), stat="identity", color="black") +
 ?>? ?geom_errorbar(aes(ymin=t-ci, ymax=t+ci),
 ?>? ? ? ? ? ? ? ? ?width=.2,? ? ? ? ? ? ? ? ? ? # Width of the error bars
 ?>? ? ? ? ? ? ? ? ?position=position_dodge(.9)) +
 ?>? ?scale_alpha_discrete(range= c(0.4, 1))
 ?> pp
 ?>
 ?>
 ?>
 ?> In the attachment, I have added the output figure, while manually editing
 ?> the SVG file to make the lower-left group of bars to make them as I
 ?> wanted.
 ?> (The spacing in between each pair is not necessarily required.)
 ?>
 ?>
 ?> Best
 ?> ?
 ?> ========================
 ?> He who is worthy to receive his days and nights is worthy to receive* all
 ?> else* from you (and me).
 ?>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? The Prophet, Gibran
 ?> Kahlil

 > ______________________________________________
 ?> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

?> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]]
 ?> PLEASE do read the posting guide
 ?> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]]
 ?> and provide commented, minimal, self-contained, reproducible code.

 ?____________________________________________________________
 ?Can't remember your password? Do you need a strong and secure password?
 ?Use Password manager! It stores your passwords & protects your account.
 ?Check it out at http://mysecurelogon.com/password-manager [http://mysecurelogon.com/password-manager] [http://mysecurelogon.com/password-manager [http://mysecurelogon.com/password-manager]]

 ____________________________________________________________
 FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
 Visit http://www.inbox.com/photosharing [http://www.inbox.com/photosharing] to find out more!

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From maity at math.niu.edu  Fri Feb 13 20:46:27 2015
From: maity at math.niu.edu (ARNAB KR MAITY)
Date: Fri, 13 Feb 2015 13:46:27 -0600
Subject: [R] How to get the error and error variance after HB using
	bayesm
In-Reply-To: <0A511BFF87BC3147B5F91EA884F122FB3FCA72A0@KLU-MAIL-01.KLU.klu>
References: <0A511BFF87BC3147B5F91EA884F122FB3FCA72A0@KLU-MAIL-01.KLU.klu>
Message-ID: <CANjU7d=qxwwy8Z+ndg_Sv1rq_2Zk0sbZZmAvoX2sSnowpb38qw@mail.gmail.com>

Hello Michael,

I have a question here. Does Bayesian paradigm deal with MSE kind of stuff?

Thanks & Regards,
Arnab



Arnab Kumar Maity
Graduate Teaching Assistant
Division of Statistics
Northern Illinois University
DeKalb, IL 60115
Email: maity at math.niu.edu
Ph:     779-777-3428

On Fri, Feb 13, 2015 at 4:45 AM, Michael Langmaack <
Michael.Langmaack at the-klu.org> wrote:

> Hello all,
>
> I have a question concerning bayesian regression in R using the package
> bayesm (version 2.2-5) by Peter Rossi. I have binary choice data and
> estimated individual coefficients using the command
> rhierBinLogit(Data=Data,Mcmc=Mcmc). That worked out properly, conversion
> plots, histograms, parameter are fine. No a have to compute the errors and
> the error variance or something like the MSE. But I do not know how to do.
> I did not find a hint so far. I would be more than happy if anybody can
> help me. Thanks in advance!
>
> Best regards,
> Michael
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From xavier.chiriboga at unine.ch  Fri Feb 13 22:32:31 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Fri, 13 Feb 2015 21:32:31 +0000
Subject: [R] qq-Plot function in version 3.1.2.
Message-ID: <7B64C8E017B948419F014C915AA6D7342A0350BA@mail-mbx-04.UNINE.CH>

Hello! SORRY PROBLEMS WITH FUNCTIONS AGAIN...



I NEED TO RUN A qqPlot ...I TRIED TO INSTALL IT , BUT A WARNING MESSAGE SAID



qqPlot is not available for version 3.1.2.







qqPlot(residuals(anc0),id.method="identify")
Error: could not find function "qqPlot"
> install.packages("qqPlot")
Installing package into ?C:/Users/chiribogax/Documents/R/win-library/3.1?
(as ?lib? is unspecified)
Warning in install.packages :
  package ?qqPlot? is not available (for R version 3.1.2)



WHAT CAN ID DO?



THANK YOU,



Xavier


From sarah.goslee at gmail.com  Fri Feb 13 22:44:56 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 13 Feb 2015 16:44:56 -0500
Subject: [R] qq-Plot function in version 3.1.2.
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A0350BA@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A0350BA@mail-mbx-04.UNINE.CH>
Message-ID: <CAM_vjukx+DvGBcjJ6ZsjGCgK8LLftug3hrt5i+x+mY=RLYX-=w@mail.gmail.com>

Let's see...

You can spell it qqplot.
You can avoid trying to install nonexistent packages with made-up names.
You can learn to use www.rseek.org
You can learn how to undo your caps lock key. ;)

But do try the first one, in the form of
?qqplot

Sarah

On Fri, Feb 13, 2015 at 4:32 PM, CHIRIBOGA Xavier
<xavier.chiriboga at unine.ch> wrote:
> Hello! SORRY PROBLEMS WITH FUNCTIONS AGAIN...
>
>
>
> I NEED TO RUN A qqPlot ...I TRIED TO INSTALL IT , BUT A WARNING MESSAGE SAID
>
>
>
> qqPlot is not available for version 3.1.2.
>
>
>
>
>
>
>
> qqPlot(residuals(anc0),id.method="identify")
> Error: could not find function "qqPlot"
>> install.packages("qqPlot")
> Installing package into ?C:/Users/chiribogax/Documents/R/win-library/3.1?
> (as ?lib? is unspecified)
> Warning in install.packages :
>   package ?qqPlot? is not available (for R version 3.1.2)
>
>
>
> WHAT CAN ID DO?
>
>
>
> THANK YOU,
>
>
>
> Xavier
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.functionaldiversity.org


From spencer.graves at prodsyse.com  Fri Feb 13 22:45:01 2015
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Fri, 13 Feb 2015 13:45:01 -0800
Subject: [R] qq-Plot function in version 3.1.2.
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A0350BA@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A0350BA@mail-mbx-04.UNINE.CH>
Message-ID: <824D40B3-5EF2-4236-8B7B-8ACDDED02954@prodsyse.com>


> On Feb 13, 2015, at 1:32 PM, CHIRIBOGA Xavier <xavier.chiriboga at unine.ch> wrote:
> 
> Hello! SORRY PROBLEMS WITH FUNCTIONS AGAIN...
> 
> 
> 
> I NEED TO RUN A qqPlot ...I TRIED TO INSTALL IT , BUT A WARNING MESSAGE SAID
> 
> 
> 
> qqPlot is not available for version 3.1.2.


	  What do you want?  


	  There is a "qqplot" function in the stats package.  Beyond that, consider the following:  


library(sos)
qqp <- ???qqPlot
# This downloaded 233 links in 96 packages for me just now.  
sum(qqp$Package=='qqPlot') 
# 0 ... i.e., there is no package by that name (and hasn't been one on CRAN, I don't think) 
qqp
# Opens a page in your default browser containing a table, the first entry of which is for a function "qqPlot" in the "EnvStats" package.  


	  Hope this helps.  
	  Spencer 
> 
> 
> qqPlot(residuals(anc0),id.method="identify")
> Error: could not find function "qqPlot"
>> install.packages("qqPlot")
> Installing package into ?C:/Users/chiribogax/Documents/R/win-library/3.1?
> (as ?lib? is unspecified)
> Warning in install.packages :
>  package ?qqPlot? is not available (for R version 3.1.2)
> 
> 
> 
> WHAT CAN ID DO?
> 
> 
> 
> THANK YOU,
> 
> 
> 
> Xavier
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Feb 13 22:56:01 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 13 Feb 2015 13:56:01 -0800
Subject: [R] Unable to use `eval(parse(text))' in nlme::lme
In-Reply-To: <cdf2600432694952baa3f2fe5bac444b@DOM-EB1-2013.win.ad.jhu.edu>
References: <cdf2600432694952baa3f2fe5bac444b@DOM-EB1-2013.win.ad.jhu.edu>
Message-ID: <CAF8bMcbPxuMrzLnkyoSwMoVUjOS=xC+5nLmonLotgZfHmbAmoA@mail.gmail.com>

> ff <- reformulate(termlabels=c("time","as.factor(gvhd)"), response=yname,
intercept=TRUE)

If the right hand side of the formula were more complicated than an
additive list of terms,
say '~ time * as.factor(gvhd)' or the left side were more than a name, say
'log(yname)' you
could use bquote() instead of reformulate.  E.g.,
  > formulaTemplate <- log(.(responseName)) ~ time * as.factor(gvhd)
  > lapply(c("y1","y2","y3"), function(yname)do.call(bquote,
list(formulaTemplate, list(responseName=as.name(yname)))))
  [[1]]
  log(y1) ~ time * as.factor(gvhd)

  [[2]]
  log(y2) ~ time * as.factor(gvhd)

  [[3]]
  log(y3) ~ time * as.factor(gvhd)

I used 'do.call' because bquote does not evaluate its first argument,
but we need to evaluate the name 'formulaTemplate'.  You could avoid that
by putting the template verbatim in the call to bquote, as in
  lapply(c("y1","y2","y3"), function(yname)bquote(log(.(responseName)) ~
time * as.factor(gvhd), list(responseName=as.name(yname))))

I like the do.call method because I can bury it in a function and forget
about it.

bquote() retains the environment of the formula template.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Feb 9, 2015 at 6:44 AM, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:

> Thanks to Rolf, Duncan, and Ben.
>
> Ben, your suggestion worked (with a minor correction of concatenating the
> termlabels into a vector).
>
> Here is the solution to those interested.
>
> ff <- reformulate(termlabels=c("time","as.factor(gvhd)"), response=yname,
> intercept=TRUE)
> dd <- subset(labdata2, Transplant_type!=0 & time >0)
> lme(ff, random=~1|Patient, data=dd, correlation=corAR1(),
> na.action=na.omit)
>
> Best,
> Ravi
>
> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
> Associate Professor
> Department of Oncology
> Division of Biostatistics & Bionformatics
> Johns Hopkins University
> 550 N. Broadway
> Baltimore, MD 21205
> 40-502-2619
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Fri Feb 13 23:25:19 2015
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 13 Feb 2015 17:25:19 -0500
Subject: [R] qq-Plot function in version 3.1.2.
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A0350BA@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A0350BA@mail-mbx-04.UNINE.CH>
Message-ID: <003a01d047db$fa5ad0d0$ef107270$@mcmaster.ca>

Dear Xavier,

Perhaps you mean the qqPlot() function in the car package. If so, you should
install the car package. As well, if anc0 is a linear or generalized linear
model, qqPlot() has a method for plotting studentized residuals and you'd
probably prefer to use that rather than extracting the residuals from the
model.

I hope this helps,
 John

-------------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> CHIRIBOGA Xavier
> Sent: February-13-15 4:33 PM
> To: r-help at r-project.org
> Subject: [R] qq-Plot function in version 3.1.2.
> 
> Hello! SORRY PROBLEMS WITH FUNCTIONS AGAIN...
> 
> 
> 
> I NEED TO RUN A qqPlot ...I TRIED TO INSTALL IT , BUT A WARNING MESSAGE
> SAID
> 
> 
> 
> qqPlot is not available for version 3.1.2.
> 
> 
> 
> 
> 
> 
> 
> qqPlot(residuals(anc0),id.method="identify")
> Error: could not find function "qqPlot"
> > install.packages("qqPlot")
> Installing package into 'C:/Users/chiribogax/Documents/R/win-library/3.1'
> (as 'lib' is unspecified)
> Warning in install.packages :
>   package 'qqPlot' is not available (for R version 3.1.2)
> 
> 
> 
> WHAT CAN ID DO?
> 
> 
> 
> THANK YOU,
> 
> 
> 
> Xavier
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


---
This email has been checked for viruses by Avast antivirus software.
http://www.avast.com


From gunter.berton at gene.com  Fri Feb 13 23:56:06 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 13 Feb 2015 14:56:06 -0800
Subject: [R] How to get the error and error variance after HB using
	bayesm
In-Reply-To: <CANjU7d=qxwwy8Z+ndg_Sv1rq_2Zk0sbZZmAvoX2sSnowpb38qw@mail.gmail.com>
References: <0A511BFF87BC3147B5F91EA884F122FB3FCA72A0@KLU-MAIL-01.KLU.klu>
	<CANjU7d=qxwwy8Z+ndg_Sv1rq_2Zk0sbZZmAvoX2sSnowpb38qw@mail.gmail.com>
Message-ID: <CACk-te0my58Bj_r7qNGNeWws1HWAsv5xb+x0kNJP153rq7evrA@mail.gmail.com>

This is primarily about statistics, not R, and so is off topic here. I
believe you would do better posting on a stats site like
stats.stackexchange.com, where you could engage in a full (and likely
complicated) discussion of the pros and cons of Bayesian regression
vs. standard frequentist approaches.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Feb 13, 2015 at 11:46 AM, ARNAB KR MAITY <maity at math.niu.edu> wrote:
> Hello Michael,
>
> I have a question here. Does Bayesian paradigm deal with MSE kind of stuff?
>
> Thanks & Regards,
> Arnab
>
>
>
> Arnab Kumar Maity
> Graduate Teaching Assistant
> Division of Statistics
> Northern Illinois University
> DeKalb, IL 60115
> Email: maity at math.niu.edu
> Ph:     779-777-3428
>
> On Fri, Feb 13, 2015 at 4:45 AM, Michael Langmaack <
> Michael.Langmaack at the-klu.org> wrote:
>
>> Hello all,
>>
>> I have a question concerning bayesian regression in R using the package
>> bayesm (version 2.2-5) by Peter Rossi. I have binary choice data and
>> estimated individual coefficients using the command
>> rhierBinLogit(Data=Data,Mcmc=Mcmc). That worked out properly, conversion
>> plots, histograms, parameter are fine. No a have to compute the errors and
>> the error variance or something like the MSE. But I do not know how to do.
>> I did not find a hint so far. I would be more than happy if anybody can
>> help me. Thanks in advance!
>>
>> Best regards,
>> Michael
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From JSorkin at grecc.umaryland.edu  Sat Feb 14 00:00:08 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 13 Feb 2015 18:00:08 -0500
Subject: [R] lme: Can not find groupData object in a function could this be
 a scoping problem?
Message-ID: <54DE3BA8020000CB00123199@smtp.medicine.umaryland.edu>

R 3.1.0, RStudio  0.98.95
Windows 7


I have written a function that uses lme:


doit<- function(TS,rho,premean,presd,RxEffect) {
.
.
.
  # Prepare data frames for regression analyses.
  data <- data.frame(group=c(rep("Cont",SS),rep("Exp",SS)),
                   pre=pre,post=post)  
.
.
.
  previous<-data.frame(time=c("pre","post"),cbind(subject=i,group=data[i,"group"],t(data[i,c("pre","post")])))
. 

.
.
  inter<-groupedData(value~as.integer(time)+as.integer(group)+
                     as.integer(time)*as.integer(group)|subject,
                     inner=~group,data=previous)

  print(inter)
  lmeinter<-lme(inter)
.
.
.
}


When I run the code, at the statement,    lmeinter<-lme(inter)  I get a message:
Error in is.data.frame(data) : object 'inter' not found.
Please note that the print statement, print(inter) prints the groupedData object!
The code works fine when it is not in a function, i.e. 


  inter<-groupedData(value~as.integer(time)+as.integer(group)+
                     as.integer(time)*as.integer(group)|subject,
                     inner=~group,data=previous)

  lmeinter<-lme(inter)



runs and has no problem finding inter.


Can someone suggest what I might change to fix the problem? I think I may have a scoping problem but I am not knowledgeable enough to know (1) how to check this and (2) what to do to fix it.


Thanks,
John




John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From JSorkin at grecc.umaryland.edu  Sat Feb 14 00:25:45 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 13 Feb 2015 18:25:45 -0500
Subject: [R] lme: Can not find groupData object in a function could this be
 a scoping problem?
Message-ID: <54DE41A9020000CB001231A3@smtp.medicine.umaryland.edu>

I resolved my program by restating RStudio . . .
Thanks you,
John


R 3.1.0, RStudio  0.98.95
Windows 7

I have written a function that uses lme:

doit<- function(TS,rho,premean,presd,RxEffect) {
.
.
.
  # Prepare data frames for regression analyses.
  data <- data.frame(group=c(rep("Cont",SS),rep("Exp",SS)),
                   pre=pre,post=post)  
.
.
.
  previous<-data.frame(time=c("pre","post"),cbind(subject=i,group=data[i,"group"],t(data[i,c("pre","post")])))
. 

.
.
  inter<-groupedData(value~as.integer(time)+as.integer(group)+
                     as.integer(time)*as.integer(group)|subject,
                     inner=~group,data=previous)

  print(inter)
  lmeinter<-lme(inter)
.
.
.
}

When I run the code, at the statement,    lmeinter<-lme(inter)  I get a message:
Error in is.data.frame(data) : object 'inter' not found.
Please note that the print statement, print(inter) prints the groupedData object!
The code works fine when it is not in a function, i.e. 


  inter<-groupedData(value~as.integer(time)+as.integer(group)+
                     as.integer(time)*as.integer(group)|subject,
                     inner=~group,data=previous)

  lmeinter<-lme(inter)



runs and has no problem finding inter.


Can someone suggest what I might change to fix the problem? I think I may have a scoping problem but I am not knowledgeable enough to know (1) how to check this and (2) what to do to fix it.


Thanks,
John




John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From josh.m.ulrich at gmail.com  Sat Feb 14 05:11:27 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 13 Feb 2015 22:11:27 -0600
Subject: [R] A portfolio return function?
In-Reply-To: <578A872F-BCB5-4EF6-B27C-32CE2E85C5B0@gmail.com>
References: <578A872F-BCB5-4EF6-B27C-32CE2E85C5B0@gmail.com>
Message-ID: <CAPPM_gQT0+YWycpYiLOjevP5VHc_=EH-cPNvwAVARgjuPFkEaw@mail.gmail.com>

Hi Ernie,

You seem confused.  sqrt(t(w) %*% V %*% w) calculates portfolio
volatility, not returns.  You can calculate portfolio volatility with
PerformanceAnalytics::StdDev.

require(PerformanceAnalytics)
data(edhec)

set.seed(21)
w <- runif(ncol(edhec))
w <- w/sum(w)
sqrt(t(w) %*% cov(edhec) %*% w)
StdDev(edhec, weights=w)

You can use PerformanceAnalytics to calculate the total portfolio
return a couple different ways.

w %*% t(Return.cumulative(edhec))
Return.cumulative(Return.portfolio(edhec, w))

Also, R-SIG-Finance is a better place to ask finance-specific
questions.  You'll likely get faster and more complete responses.

Best,
Josh


On Wed, Feb 11, 2015 at 10:25 AM, Ernest Stokely <wizardchef at gmail.com> wrote:
>
> For finance applications, I'm surprised that I am unable to find a function to compute the portfolio return (sqrt(t(w) %*% V %*% w)) where w are portfolio weights and V is the cov(returns). The Performance Analytics portfolio return function seems to compute something else.
> Ernie
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From aebingham2 at gmail.com  Sat Feb 14 08:16:29 2015
From: aebingham2 at gmail.com (Allen Bingham)
Date: Fri, 13 Feb 2015 23:16:29 -0800
Subject: [R] difference between max in summary table and max function
In-Reply-To: <AM2PR05MB075593027DD74FFBEA945DD8A1230@AM2PR05MB0755.eurprd05.prod.outlook.com>
References: <3FA7C532AA08284AB2ACA7B0AB56EF8715907C70@vitomail4.vito.local>
	<AM2PR05MB075593027DD74FFBEA945DD8A1230@AM2PR05MB0755.eurprd05.prod.outlook.com>
Message-ID: <000901d04826$288953b0$799bfb10$@gmail.com>

I thought I'd chime in ... submitting the following:

   ?summary

Provides the following documentation for the default for generalized
argument (other than class="data.frame", "factor", or "matrix"):

   ## Default S3 method:
   summary(object, ..., digits = max(3, getOption("digits")-3))

so passing along the object "testrow" w/o a corresponding argument for
digits ... defaults to digits=4 (assuming your system has the same default
option of digits = 7 that mine does).

... and since later in the documentation it indicates that digits is an:

   integer, used for number formatting with signif()

so noting that all of the values you reported from summary(testrow) all have
4 significant digits (including the Max. of 131500) (excepting the min value
of "1"), summary() is doing what it is documented to do.

... sorry for being pedantic --- but doing so to point out how helpful the
"?" command can be sometimes.

Hope this helps.

______________________________________
Allen Bingham
Bingham Statistical Consulting
aebingham2 at gmail.com
LinkedIn Profile: www.linkedin.com/pub/allen-bingham/3b/556/325





-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Martyn Byng
Sent: Friday, February 13, 2015 3:15 AM
To: Franckx Laurent; r-help at r-project.org
Subject: Re: [R] difference between max in summary table and max function

Its a formatting thing, try

summary(testrow,digits=20)

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Franckx
Laurent
Sent: 13 February 2015 11:00
To: r-help at r-project.org
Subject: [R] difference between max in summary table and max function

Dear all

I have found out that the max in the summary of an integer vector is not
always equal to the actual maximum of that vector. For example:


> testrow <- c(1:131509)
> summary(testrow)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
      1   32880   65760   65760   98630  131500
> max(testrow)
[1] 131509

This has occurred both in a Windows and in a Linux environment.

Does this mean that the max value in the summary is only an approximation?

Best regards

Laurent Franckx, PhD
Senior researcher sustainable mobility
VITO NV | Boeretang 200 | 2400 Mol
Tel. ++ 32 14 33 58 22| mob. +32 479 25 59 07 | Skype: laurent.franckx |
laurent.franckx at vito.be | Twitter @LaurentFranckx




VITO Disclaimer: http://www.vito.be/e-maildisclaimer

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________________________________________________
This e-mail has been scanned for all viruses by Star.\ _...{{dropped:8}}


From celestialxangel at hotmail.com  Fri Feb 13 17:46:32 2015
From: celestialxangel at hotmail.com (ayane)
Date: Fri, 13 Feb 2015 16:46:32 +0000
Subject: [R] How can you validate association rules?
Message-ID: <BLU184-W396F2E724E1C0D8EF66E63BA230@phx.gbl>

Hey everyone, 

I just started learning R and statistics. I made association rules with the apriori algorithm in the arules package. I sorted them and pruned them. But now I want to validate/test them. In supervised learning they use cross validation. In this paper by Patrick O Perry http://arxiv.org/abs/0909.3052 I read it is possible to use cross validation on unsupervised learning methods (such as arules). But since my background in R, statistics and machine learning is weak the paper was quite hard to get through (also I'm not in college, I just finished high school and am preparing to study computer sciencec). 

So my question is, how do you validate your rules? How can you use cross validation to do so? I have my main data set "Orders", it has 2 million records. I used the sample function to make a training data set and a test data set. But what do I do next? Are there other techniques I should know of?

If there are any specific tutorials on this subject, I would also love to learn from them.

Kind regards,
Ayane 		 	   		  
	[[alternative HTML version deleted]]


From javamon at mindspring.com  Fri Feb 13 18:15:31 2015
From: javamon at mindspring.com (Michael Pomeroy)
Date: Fri, 13 Feb 2015 09:15:31 -0800
Subject: [R] Error when I attempt to create a list or a data frame
Message-ID: <54DE3133.9070809@mindspring.com>


When I try to create a list with three classes of objects:  a numeric, 
boolean, and vector of character data:
lst <- list(c(1,2),TRUE,c(?a?,?b?,?c?))

I receive this error:
Error: unexpected input in "lst <- list(c(1,2),TRUE,c(?"

I receive a similar error when I create a data frame with mixed classes 
of objects.

Thanks ahead of time!


From lisike at terpmail.umd.edu  Fri Feb 13 18:17:10 2015
From: lisike at terpmail.umd.edu (Sike Li)
Date: Fri, 13 Feb 2015 12:17:10 -0500
Subject: [R] Use of R for Hypothesis Testing
Message-ID: <CAGjHE10cWta4QybNp=eCQDbSADA+dF5huvVOh3f5OsYEjT4rcw@mail.gmail.com>

Dear Staff
Hello,

I am recently trying to learn some functions of R. How would I use R to do
T-test, confidence interval calculation, chi-square test and ANOVA?

-- 
Thank you
Sike Li (Lydia)

	[[alternative HTML version deleted]]


From bickis at snoopy.usask.ca  Fri Feb 13 18:22:27 2015
From: bickis at snoopy.usask.ca (Professor Bickis)
Date: Fri, 13 Feb 2015 09:22:27 -0800
Subject: [R] Sorting Surv objects
In-Reply-To: <1e7ee5$25h4c@ironport10.mayo.edu>
References: <mailman.1.1423825202.10875.r-help@r-project.org>
	<1e7ee5$25h4c@ironport10.mayo.edu>
Message-ID: <C751FD1F-603E-4D16-8AB4-83CEBB0C92D9@snoopy.usask.ca>

Thanks for the quick response.  

My work-around was suggested as a quick fix for right-censored data, not as a general sort method for censored data.

My concern was that sort does not work on right-censored data as described in the xtfrm documentation.

Mik Bickis

> On Feb 13, 2015, at 05:53 AM, Therneau, Terry M., Ph.D. <therneau at mayo.edu> wrote:
> 
> Your work around is not as "easy" looking to me.
> 
> Survival times come in multiple flavors: left censored, right censored, interval censored, left-truncated and right censored, and multi-state.  Can you give me guidance on how each of these should sort?  If a sort method is added to the package it needs to deal with all of these.
> 
> Professor Ripley has pointed out that the default action of sort() for right censored times, which I agree is reasonable.
> 
> Terry Therneau (author of the survival package)
> 
> 
> On 02/13/2015 05:00 AM, r-help-request at r-project.org wrote:
>> It seems that Surv objects do not sort correctly.   This seems to be a bug.  Anyone else found this?
>> 
>>> >survival.data
>> [1] 4+ 3  1+ 2  5+
>>> >class(survival.data)
>> [1] "Surv"
>>> >sort(survival.data)
>> [1] 2  1+ 4+ 3  5+
>> 
>> An easy work-around is to define a function sort.Surv
> 


From Z.Ahmad at soton.ac.uk  Fri Feb 13 19:46:07 2015
From: Z.Ahmad at soton.ac.uk (Zahoor)
Date: Fri, 13 Feb 2015 10:46:07 -0800 (PST)
Subject: [R] Caleberating weights
Message-ID: <73D843C055DE9B4DB6619C326B5A7C301BBCE4@SRV00049.soton.ac.uk>

Hi,

Suppose I have weights di, I want to calibrate thesis weights

I used the objective function

Obj = Sum( wi/di-1)^2/2   ; where will be the resulting calibrated weights

My calibration constraint is

Sum(wizi) = Z      , Z is pop total    (1)

I need r-code to minimize 'Obj' subject to the constraint (1) to obtain calibrated weights wi

Thanks




--
View this message in context: http://r.789695.n4.nabble.com/Caleberating-weights-tp4703226.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From js.huang at protective.com  Fri Feb 13 22:15:32 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 13 Feb 2015 13:15:32 -0800 (PST)
Subject: [R] Coverage probability for a Poisson parameter
In-Reply-To: <1423853376490-4703227.post@n4.nabble.com>
References: <1422648135557-4702535.post@n4.nabble.com>
	<1422650922280-4702537.post@n4.nabble.com>
	<1422659760512-4702546.post@n4.nabble.com>
	<1422665613143-4702551.post@n4.nabble.com>
	<1423224280484-4702883.post@n4.nabble.com>
	<1423258104797-4702906.post@n4.nabble.com>
	<1423259761894-4702909.post@n4.nabble.com>
	<1423853376490-4703227.post@n4.nabble.com>
Message-ID: <1423862132371-4703230.post@n4.nabble.com>

Hi,

  In your function cover, lambda1 and lambda2 are used but not in the
argument of the function.  I suppose that you need to have lambda1 and
lambda2 in the argument of the function cover, like function(lambda1,
lambda2, n, significance.level).  

  Give it a try.

cover <- function(lambda, n, significance.level)  {
  s1 <- rpois(1,lambda1) 
  s2 <- rpois(1,lambda2) 
  theta <- lambda2/(lambda1+lambda2) 
  s <- s1+s2 
  z <- qnorm(1-0.05/2) 
  k <- z^2 
  pi <- s2/s 
  lower <- (pi+(k/(2*s))-z*sqrt((pi*(1-pi)+(k/4*s))/s))/(1+k/s) 
  upper <- (pi+(k/(2*s))+z*sqrt((pi*(1-pi)+(k/4*s))/s))/(1+k/s) 
  if (theta >= lower & theta <= upper){1} else {0} 
}



--
View this message in context: http://r.789695.n4.nabble.com/Coverage-probability-for-a-Poisson-parameter-tp4702535p4703230.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Fri Feb 13 22:22:29 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 13 Feb 2015 13:22:29 -0800 (PST)
Subject: [R] sd, mean with a frequency distribution matrix
In-Reply-To: <1423843168900-4703220.post@n4.nabble.com>
References: <1423837352778-4703218.post@n4.nabble.com>
	<1423843168900-4703220.post@n4.nabble.com>
Message-ID: <1423862549747-4703231.post@n4.nabble.com>

Or if you want to perform the calculation without using sd:

sqrt((sum(p[,1]^2*p[,2])-(sum(p[,1]*p[,2]))^2/sum(p[,2]))/(sum(p[,2])-1))




--
View this message in context: http://r.789695.n4.nabble.com/sd-mean-with-a-frequency-distribution-matrix-tp4703218p4703231.html
Sent from the R help mailing list archive at Nabble.com.


From dorian.grelli at gmail.com  Fri Feb 13 22:25:10 2015
From: dorian.grelli at gmail.com (dorian_pg)
Date: Fri, 13 Feb 2015 13:25:10 -0800 (PST)
Subject: [R] sd, mean with a frequency distribution matrix
In-Reply-To: <1423862549747-4703231.post@n4.nabble.com>
References: <1423837352778-4703218.post@n4.nabble.com>
	<1423843168900-4703220.post@n4.nabble.com>
	<1423862549747-4703231.post@n4.nabble.com>
Message-ID: <CAG0O-BwaE2ShhU-OpkGTuZEM8ZdtfT+Xm_bvxOgMOLXQj=4_-w@mail.gmail.com>

Thank you, I'll try as soon as possible!
Il 13/Feb/2015 22:28 "JS Huang [via R]" <
ml-node+s789695n4703231h1 at n4.nabble.com> ha scritto:

> Or if you want to perform the calculation without using sd:
>
> sqrt((sum(p[,1]^2*p[,2])-(sum(p[,1]*p[,2]))^2/sum(p[,2]))/(sum(p[,2])-1))
>
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
>
> http://r.789695.n4.nabble.com/sd-mean-with-a-frequency-distribution-matrix-tp4703218p4703231.html
>  To unsubscribe from sd, mean with a frequency distribution matrix, click
> here
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4703218&code=ZG9yaWFuLmdyZWxsaUBnbWFpbC5jb218NDcwMzIxOHwtOTUyODE5MTM5>
> .
> NAML
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://r.789695.n4.nabble.com/sd-mean-with-a-frequency-distribution-matrix-tp4703218p4703232.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From js.huang at protective.com  Fri Feb 13 22:59:57 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 13 Feb 2015 13:59:57 -0800 (PST)
Subject: [R] Coverage probability for a Poisson parameter
In-Reply-To: <1423863924889-4703236.post@n4.nabble.com>
References: <1422648135557-4702535.post@n4.nabble.com>
	<1422650922280-4702537.post@n4.nabble.com>
	<1422659760512-4702546.post@n4.nabble.com>
	<1422665613143-4702551.post@n4.nabble.com>
	<1423224280484-4702883.post@n4.nabble.com>
	<1423258104797-4702906.post@n4.nabble.com>
	<1423259761894-4702909.post@n4.nabble.com>
	<1423853376490-4703227.post@n4.nabble.com>
	<1423862132371-4703230.post@n4.nabble.com>
	<1423863924889-4703236.post@n4.nabble.com>
Message-ID: <1423864797769-4703238.post@n4.nabble.com>

Hi,

  Given the function cover, it's very likely that you will get 0 for both s1
and s1 with small value of lambda1 and lambda2. In that case the sum s will
be 0.  With s being 0, you will have issue with the expression in   pi <-
s2/s and root <- ((s2/s)*(1-s2/s)+k/(4*s))^(1/2).  You need to take care of
the case that s is 0 before proceeding calculating pi and root.

cover <- function(theta, lambda1, lambda2, significance.level)  { 
  s1 <- rpois(1,lambda1) 
  s2 <- rpois(1,lambda2) 
  theta <- lambda2/(lambda1+lambda2) 
  s <- s1+s2 
  z <- qnorm(1-0.05/2) 
  k <- z^2 
  pi <- s2/s 
  root <- ((s2/s)*(1-s2/s)+k/(4*s))^(1/2) 
  low <- (s2+k/2)/(s+k)-((z*sqrt(s))/(s+k))*root 
  hig <- (s2+k/2)/(s+k)+((z*sqrt(s))/(s+k))*root 
  if (theta >= low & theta <= hig){1} else {0} 
} 



--
View this message in context: http://r.789695.n4.nabble.com/Coverage-probability-for-a-Poisson-parameter-tp4702535p4703238.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Sat Feb 14 00:03:30 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 13 Feb 2015 15:03:30 -0800 (PST)
Subject: [R] Genrating Ordinal Responses in R
In-Reply-To: <1423753425714-4703159.post@n4.nabble.com>
References: <1423753425714-4703159.post@n4.nabble.com>
Message-ID: <1423868610293-4703244.post@n4.nabble.com>

Hi,

  Here assume there are four elements in the ordinal set y and take a random
sample of size 10 according to the cumulative distribution given, or
probability distribution p below.


> y <- c(levels = c("First", "Second", "Third", "Fourth"))
> y
 levels1  levels2  levels3  levels4 
 "First" "Second"  "Third" "Fourth" 
> (x <- c(1/9, 1/4, 3/5, 1))
[1] 0.1111111 0.2500000 0.6000000 1.0000000
> p <- c(x[1], x[2]-x[1], x[3]-x[2], x[4]-x[3])
> p
[1] 0.1111111 0.1388889 0.3500000 0.4000000
> sample(y, 10, replace=TRUE, prob=p)
 levels2  levels4  levels4  levels3  levels1  levels3  levels4  levels2 
levels4  levels3 
"Second" "Fourth" "Fourth"  "Third"  "First"  "Third" "Fourth" "Second"
"Fourth"  "Third" 



--
View this message in context: http://r.789695.n4.nabble.com/Genrating-Ordinal-Responses-in-R-tp4703159p4703244.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Sat Feb 14 00:10:25 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 13 Feb 2015 15:10:25 -0800 (PST)
Subject: [R] Caleberating weights
In-Reply-To: <73D843C055DE9B4DB6619C326B5A7C301BBCE4@SRV00049.soton.ac.uk>
References: <73D843C055DE9B4DB6619C326B5A7C301BBCE4@SRV00049.soton.ac.uk>
Message-ID: <1423869025809-4703245.post@n4.nabble.com>

Hi,

  It's not clear what wizi is in the constraint Sum(wizi) = Z.  If you can
provide some data, it may make the problem easier to understand.



--
View this message in context: http://r.789695.n4.nabble.com/Caleberating-weights-tp4703226p4703245.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Sat Feb 14 00:22:24 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 13 Feb 2015 15:22:24 -0800 (PST)
Subject: [R] lme: Can not find groupData object in a function could this
 be a scoping problem?
In-Reply-To: <54DE3BA8020000CB00123199@smtp.medicine.umaryland.edu>
References: <54DE3BA8020000CB00123199@smtp.medicine.umaryland.edu>
Message-ID: <1423869744761-4703247.post@n4.nabble.com>

Hi,

  Unless you defined SS somewhere before you execute "data <-
data.frame(group=c(rep("Cont",SS),rep("Exp",SS)), pre=pre,post=post)", SS is
not assigned.  Maybe it is TS you intended?

doit<- function(TS,rho,premean,presd,RxEffect) { 
. 
. 
. 
  # Prepare data frames for regression analyses. 
  data <- data.frame(group=c(rep("Cont",SS),rep("Exp",SS)), 
                   pre=pre,post=post)   



--
View this message in context: http://r.789695.n4.nabble.com/lme-Can-not-find-groupData-object-in-a-function-could-this-be-a-scoping-problem-tp4703243p4703247.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Sat Feb 14 01:21:26 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 13 Feb 2015 16:21:26 -0800 (PST)
Subject: [R] Coverage probability for a Poisson parameter
In-Reply-To: <1423864797769-4703238.post@n4.nabble.com>
References: <1422650922280-4702537.post@n4.nabble.com>
	<1422659760512-4702546.post@n4.nabble.com>
	<1422665613143-4702551.post@n4.nabble.com>
	<1423224280484-4702883.post@n4.nabble.com>
	<1423258104797-4702906.post@n4.nabble.com>
	<1423259761894-4702909.post@n4.nabble.com>
	<1423853376490-4703227.post@n4.nabble.com>
	<1423862132371-4703230.post@n4.nabble.com>
	<1423863924889-4703236.post@n4.nabble.com>
	<1423864797769-4703238.post@n4.nabble.com>
Message-ID: <1423873286813-4703248.post@n4.nabble.com>

Hi,

  Some suggestion about the arguments of the function defined below.  Since
theta is calculated with the value of lambda1 and lambda2, there is no need
to include theta in the argument.  Or, your function can be defined as
function(lambda1, lambda2, significance.level)

cover <- function(theta, lambda1, lambda2, significance.level)  { 
  s1 <- rpois(1,lambda1) 
  s2 <- rpois(1,lambda2) 
  theta <- lambda2/(lambda1+lambda2) 
  s <- s1+s2 
  z <- qnorm(1-0.05/2) 
  k <- z^2 
  pi <- s2/s 
  root <- ((s2/s)*(1-s2/s)+k/(4*s))^(1/2) 
  low <- (s2+k/2)/(s+k)-((z*sqrt(s))/(s+k))*root 
  hig <- (s2+k/2)/(s+k)+((z*sqrt(s))/(s+k))*root 
  if (theta >= low & theta <= hig){1} else {0} 
} 



--
View this message in context: http://r.789695.n4.nabble.com/Coverage-probability-for-a-Poisson-parameter-tp4702535p4703248.html
Sent from the R help mailing list archive at Nabble.com.


From ligges at statistik.tu-dortmund.de  Sat Feb 14 09:13:37 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 14 Feb 2015 09:13:37 +0100
Subject: [R] Use of R for Hypothesis Testing
In-Reply-To: <CAGjHE10cWta4QybNp=eCQDbSADA+dF5huvVOh3f5OsYEjT4rcw@mail.gmail.com>
References: <CAGjHE10cWta4QybNp=eCQDbSADA+dF5huvVOh3f5OsYEjT4rcw@mail.gmail.com>
Message-ID: <54DF03B1.3080600@statistik.tu-dortmund.de>



On 13.02.2015 18:17, Sike Li wrote:
> Dear Staff

There is no staff, only volunteers who answer messages in their spare time.


> Hello,
>
> I am recently trying to learn some functions of R. How would I use R to do
> T-test, confidence interval calculation, chi-square test and ANOVA?
>

Please re-read the posting guide and start to read basic documentation.

Best,
Uwe Ligges


From ligges at statistik.tu-dortmund.de  Sat Feb 14 09:14:15 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 14 Feb 2015 09:14:15 +0100
Subject: [R] Error when I attempt to create a list or a data frame
In-Reply-To: <54DE3133.9070809@mindspring.com>
References: <54DE3133.9070809@mindspring.com>
Message-ID: <54DF03D7.2060303@statistik.tu-dortmund.de>



On 13.02.2015 18:15, Michael Pomeroy wrote:
>
> When I try to create a list with three classes of objects:  a numeric,
> boolean, and vector of character data:
> lst <- list(c(1,2),TRUE,c(?a?,?b?,?c?))
>
> I receive this error:
> Error: unexpected input in "lst <- list(c(1,2),TRUE,c(?"

Do not use directed quotes.

Best,
Uwe Ligges

>
> I receive a similar error when I create a data frame with mixed classes
> of objects.
>
> Thanks ahead of time!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Feb 14 09:20:49 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 14 Feb 2015 19:20:49 +1100
Subject: [R] Use of R for Hypothesis Testing
In-Reply-To: <CAGjHE10cWta4QybNp=eCQDbSADA+dF5huvVOh3f5OsYEjT4rcw@mail.gmail.com>
References: <CAGjHE10cWta4QybNp=eCQDbSADA+dF5huvVOh3f5OsYEjT4rcw@mail.gmail.com>
Message-ID: <CA+8X3fX+iYfMT3G2wQ6a5NkebmqqcyZoR+_9TXdiK-C_vLjVFA@mail.gmail.com>

Hi Sike,
Start an R session, issue the command "help.start()" and check the
help pages for "t.test", "chisq.test" and "aov" in the "stats"
package.

Jim


On Sat, Feb 14, 2015 at 4:17 AM, Sike Li <lisike at terpmail.umd.edu> wrote:
> Dear Staff
> Hello,
>
> I am recently trying to learn some functions of R. How would I use R to do
> T-test, confidence interval calculation, chi-square test and ANOVA?
>
> --
> Thank you
> Sike Li (Lydia)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hyiltiz at gmail.com  Sat Feb 14 09:32:03 2015
From: hyiltiz at gmail.com (=?UTF-8?Q?H=C3=B6rmetjan_Yiltiz?=)
Date: Sat, 14 Feb 2015 16:32:03 +0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <5885A05522B.0000053Fjrkrideau@inbox.com>
References: <cam5fmsmaidzgj+d5drptguhbm4v1tr6aljjtdjskqcmfs5w49w@mail.gmail.com>
	<4ad1edc7c1f.00000299jrkrideau@inbox.com>
	<4b1afade554.0000031bjrkrideau@inbox.com>
	<cam5fmspbv2v23ojbj=zsp4hi8onhh-rby2g1utxx-sbkqveifa@mail.gmail.com>
	<CAM5FmSM-jucvYY6pZXfsvDUZeK2+GQg8SMti++LxFG3SL0NPQg@mail.gmail.com>
	<5885A05522B.0000053Fjrkrideau@inbox.com>
Message-ID: <CAM5FmSMNOKfT_X+2X5R0=wmkLSNBZxZK3B6fS7T=u-iGXhMj4A@mail.gmail.com>

I think maybe it is possible to first produce a blank axis, and then
splitting the data frame by the value of *direction. *Then add the goem_bar
and goem_errorbar for the blank axis for the first split, then add them for
the second half split. This is actually a slit-apply-combine strategy. It
would be perfect if we could come up with the way to do that using
*d_ply().*

I see where you are at when you are saying geom_point. I have adjusted it a
bit so that the *direction* factor is also labeled out with *linetype*,
simply adding *linetype=direction* in the goem_errorbar function. One
problem for this is normally we use bar charts as a standard for this type
of statistics, and the comparison is visually more easier using bar charts
than the geom_point version.

A question about this, though. What determines the vertical axis value for
the points? I see they are layered so that they do not overlap although a
lot of dots share the same horizontal value: male. Is that handled utterly
by a mechanism that is not relevant with the data, but to produce less
clattered plot?

Thanks so much for your hlep! Here is the code I have tweaked based on
yours, adding the dashed line for direction:

dat1  <-  structure(list(gender = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L,
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L), .Label = c("male", "female"
), class = "factor"), direction = structure(c(1L, 1L, 2L, 2L,
1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L,
1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("up",
"down"), class = "factor"), condition = structure(c(1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 1L, 1L, 1L,
1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L), .Label = c("c1",
"c2", "c3", "c4"), class = "factor"), location = structure(c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label =
c("east",
"west"), class = "factor"), t = c(1.78664348823968, 1.045971213672,
1.45271943418506, 1.52433880441405, 0.894240903766416, 1.04200421306615,
0.992602172725307, 1.35686661120166, 1.15664717132331, 1.78519605814623,
1.3131987417228, 1.23649081362245, 1.33657440193627, 1.39069933103098,
1.16990353110185, 1.50384132346169, 0.240063246756554, 0.151918103772423,
1.26918566082989, 1.44462610872269, 0.944676078996681, 0.945358342820427,
0.68274449456263, 0.983609699924918, 1.06442538569853, 0.917922814494952,
1.06681054493614, 0.899670881737641, 0.639091165646195, 1.81227533189609,
1.02711921654525, 2.05244515236416), ci = c(0.199453475099606,
0.0208699634619525, 0.0267762622040696, 0.0719683008799792,
0.0388022593655329,
0.0873965412159785, 0.0828671112758008, 0.556676454332325,
0.109726976194332,
0.237352334670391, 0.202173510668684, 0.104263016807603, 0.0174283081233597,
0.027601059580507, 0.118300511535772, 0.272210060810133, 0.210343075045509,
0.010793003362928, 0.241665829872765, 0.387877941848338, 0.230361471258575,
0.233088662079594, 0.0956745517473407, 0.187969512005399,
0.0041769632082831,
0.26242665290992, 0.297793257986101, 0.14520541873456, 0.123447338902161,
0.10109002280374, 0.332925731545975, 0.434868806611465)), .Names =
c("gender",
"direction", "condition", "location", "t", "ci"), row.names = c(NA,
-32L), class = "data.frame")


dat1$jit <- ifelse( dat1$gender == "male",  1,
        ifelse( dat1$gender == 'female',  2,
          NA) )
dat1$jit  <-  as.numeric(dat1$jit)

dat1$jit  <-  jitter(dat1$jit)

x  <-  "male"
y  <-  "female"############Begin code ##############
ab <-  ggplot(dat1, aes (jit, t)) +
       geom_point(aes(colour = condition)) +
        theme(axis.ticks = element_blank()) +
        scale_x_continuous(breaks=c(1, 2),
                           labels=c("male", "female"),
                           name="Gender")
ab


bb  <-  ab + facet_grid(location~.)
bb

bc  <-  bb +
    geom_errorbar(data = dat1, aes(ymin=t-ci, ymax=t+ci,
                colour = condition,
                linetype = direction),
                  width=.2 )
bc


cf  <-  bc + coord_flip()
cf

############End code ###############


???
========================
He who is worthy to receive his days and nights is worthy to receive* all
else* from you (and me).
                                                 The Prophet, Gibran Kahlil


On Sat, Feb 14, 2015 at 1:41 AM, John Kane <jrkrideau at inbox.com> wrote:

> Both files came through.  The R-help list is picky. For example it will
> accept cat.txt but not cat.csv.
>
> Now I see what you are after. and I must admit I haven't a clue at the
> moment. I suspect others who know more about ggplot can help.  If not there
> is ggplot2 Google Groups that has a lot of knowledge and you might want to
> post there.  It accepts all kinds of file types. :)
>
> On the other hand, I don't like dynamite plots (what you have) and
> wondered if it was possible to do something with geom_point() instead.
>
> It was, in a bit of a half-assed way so I'll pass on my raw code. It's
> ulgy but works. I don't know if I'd call it pub-quality but perhaps it can
> be tweaked (wrenched? , bludgened?) into something acceptable.
>
> BTW, I changed your data.frame name to dat1.  df is an R function.  Type
> df and you will see what I mean. I've also converted the data to a dput()
> file. Not needed as you supplied a perfectly good data set but generally
> good practice.
>
> Sorry I was not able to be of more help
>
> John Kane
> Kingston ON Canada
>
> ############Begin code ##############
> library(ggplot2)
> library(scales)
> dat1  <-  structure(list(gender = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L,
> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L), .Label = c("male", "female"
> ), class = "factor"), direction = structure(c(1L, 1L, 2L, 2L,
> 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L,
> 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("up",
> "down"), class = "factor"), condition = structure(c(1L, 1L, 1L,
> 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 1L, 1L, 1L,
> 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L), .Label = c("c1",
> "c2", "c3", "c4"), class = "factor"), location = structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label =
> c("east",
> "west"), class = "factor"), t = c(1.78664348823968, 1.045971213672,
> 1.45271943418506, 1.52433880441405, 0.894240903766416, 1.04200421306615,
> 0.992602172725307, 1.35686661120166, 1.15664717132331, 1.78519605814623,
> 1.3131987417228, 1.23649081362245, 1.33657440193627, 1.39069933103098,
> 1.16990353110185, 1.50384132346169, 0.240063246756554, 0.151918103772423,
> 1.26918566082989, 1.44462610872269, 0.944676078996681, 0.945358342820427,
> 0.68274449456263, 0.983609699924918, 1.06442538569853, 0.917922814494952,
> 1.06681054493614, 0.899670881737641, 0.639091165646195, 1.81227533189609,
> 1.02711921654525, 2.05244515236416), ci = c(0.199453475099606,
> 0.0208699634619525, 0.0267762622040696, 0.0719683008799792,
> 0.0388022593655329,
> 0.0873965412159785, 0.0828671112758008, 0.556676454332325,
> 0.109726976194332,
> 0.237352334670391, 0.202173510668684, 0.104263016807603,
> 0.0174283081233597,
> 0.027601059580507, 0.118300511535772, 0.272210060810133, 0.210343075045509,
> 0.010793003362928, 0.241665829872765, 0.387877941848338, 0.230361471258575,
> 0.233088662079594, 0.0956745517473407, 0.187969512005399,
> 0.0041769632082831,
> 0.26242665290992, 0.297793257986101, 0.14520541873456, 0.123447338902161,
> 0.10109002280374, 0.332925731545975, 0.434868806611465)), .Names =
> c("gender",
> "direction", "condition", "location", "t", "ci"), row.names = c(NA,
> -32L), class = "data.frame")
>
>
> dat1$jit <- ifelse( dat1$gender == "male",  1,
>         ifelse( dat1$gender == 'female',  2,
>           NA) )
> dat1$jit  <-  as.numeric(dat1$jit)
>
> dat1$jit  <-  jitter(dat1$jit)
>
> x  <-  "male"
> y  <-  "female"############Begin code ##############
> ab <-  ggplot(dat1, aes (jit, t)) +
>        geom_point(aes(colour = condition)) +
>         theme(axis.ticks = element_blank()) +
>         scale_x_continuous(breaks=c(1, 2),
>                            labels=c("male", "female"),
>                            name="Gender")
> ab
>
>
> bb  <-  ab + facet_grid(location~.)
> bb
>
> bc  <-  bb +
>     geom_errorbar(data = dat1, aes(ymin=t-ci, ymax=t+ci,
>                 colour = condition),
>                   width=.2 )
> bc
>
>
> cf  <-  bc + coord_flip()
> cf
>
> ############End code ###############
>
>
> John Kane
> Kingston ON Canada
>
> -----Original Message-----
> From: hyiltiz at gmail.com
> Sent: Fri, 13 Feb 2015 02:28:17 +0800
> To: jrkrideau at inbox.com
> Subject: Re: [R] ggplot2 shifting bars to only overlap in groups
>
> I did not know the SVG file did not come through. I thought SVG should be
> able to pass through the filter. Here is a PDF file along with an PNG.
> Guess one of them should be able to pass.
>
> ???
> ========================
> He who is worthy to receive his days and nights is worthy to receive* all
> else* from you (and me).
>                                                  The Prophet, Gibran Kahlil
>
> On Fri, Feb 13, 2015 at 12:04 AM, John Kane <jrkrideau at inbox.com> wrote:
>
>  I'm a bit blind today. I read df as a dput() .
>
>  John Kane
>  Kingston ON Canada
>
>  -----Original Message-----
>  From: hyiltiz at gmail.com
>  Sent: Thu, 12 Feb 2015 23:38:01 +0800
>  To: jrkrideau at inbox.com
>  Subject: Re: [R] ggplot2 shifting bars to only overlap in groups
>
>  You are most likely simply not running the whole lines of code: note that
> the first line is:
>
>  N = 32
>
>   Best
>  ?
>  ========================
>  He who is worthy to receive his days and nights is worthy to receive* all
>  else* from you (and me).
>                                                   The Prophet, Gibran
> Kahlil
>
>  On Thu, Feb 12, 2015 at 11:31 PM, John Kane <jrkrideau at inbox.com> wrote:
>
>          I am gettting the error"
>   Error in rep_len(rep.int [http://rep.int] [http://rep.int [
> http://rep.int]](seq_len(n), rep.int [http://rep.int] [http://rep.int [
> http://rep.int]](k, n)), length) :
>
>    object 'N' not found
>
>   Also your image did not come through.  Try sending it as a pdf file.
>
>   when I try to create
>   df<- data.frame(gender=gl(2,1,N, c("male","female")),
>             direction=gl(2,2,N, c("up","down")),
>             condition=gl(4,4,N, c("c1","c2","c3","c4")),
>             location=gl(2,16,N, c("east","west")),
>             t=rnorm(N, 1, 0.5),
>             ci=abs(rnorm(N, 0, 0.2)))
>
>   John Kane
>   Kingston ON Canada
>
>   > -----Original Message-----
>   > From: hyiltiz at gmail.com
>   > Sent: Thu, 12 Feb 2015 22:08:36 +0800
>   > To: r-help at r-project.org
>   > Subject: [R] ggplot2 shifting bars to only overlap in groups
>   >
>   > Hi all,
>   >
>   > I have four factors for a continuous time variable along with its
>   > confidence interval. I would like to produce a publication quality
> error
>   > bar chart that is clear to understand. For now, I used colors, x axis
>   > position, facets and alpha level to distinguish them.
>   >
>   > I would like to overlap each pairs of bars with the same color a bit
> as a
>   > group, but not overlap each and every bars with each other.
>   >
>   > Here is a minimal example:
>   >
>   > N = 32
>   > df<- data.frame(gender=gl(2,1,N, c("male","female")),
>   >           direction=gl(2,2,N, c("up","down")),
>   >           condition=gl(4,4,N, c("c1","c2","c3","c4")),
>   >           location=gl(2,16,N, c("east","west")),
>   >           t=rnorm(N, 1, 0.5),
>   >           ci=abs(rnorm(N, 0, 0.2)))
>   > pp <-
>   >   ggplot(df, aes(x=gender, y=t, fill=condition, alpha=direction)) +
>   >   facet_grid(location~.) +
>   >   geom_bar(position=position_dodge(.9), stat="identity",
> color="black") +
>   >   geom_errorbar(aes(ymin=t-ci, ymax=t+ci),
>   >                 width=.2,                    # Width of the error bars
>   >                 position=position_dodge(.9)) +
>   >   scale_alpha_discrete(range= c(0.4, 1))
>   > pp
>   >
>   >
>   >
>   > In the attachment, I have added the output figure, while manually
> editing
>   > the SVG file to make the lower-left group of bars to make them as I
>   > wanted.
>   > (The spacing in between each pair is not necessarily required.)
>   >
>   >
>   > Best
>   > ?
>   > ========================
>   > He who is worthy to receive his days and nights is worthy to receive*
> all
>   > else* from you (and me).
>   >                                                  The Prophet, Gibran
>   > Kahlil
>
>  > ______________________________________________
>   > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
>  > https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help] [
> https://stat.ethz.ch/mailman/listinfo/r-help [
> https://stat.ethz.ch/mailman/listinfo/r-help]]
>   > PLEASE do read the posting guide
>   > http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html] [
> http://www.R-project.org/posting-guide.html [
> http://www.R-project.org/posting-guide.html]]
>   > and provide commented, minimal, self-contained, reproducible code.
>
>   ____________________________________________________________
>   Can't remember your password? Do you need a strong and secure password?
>   Use Password manager! It stores your passwords & protects your account.
>   Check it out at http://mysecurelogon.com/password-manager [
> http://mysecurelogon.com/password-manager] [
> http://mysecurelogon.com/password-manager [
> http://mysecurelogon.com/password-manager]]
>
>  ____________________________________________________________
>  FREE ONLINE PHOTOSHARING - Share your photos online with your friends and
> family!
>  Visit http://www.inbox.com/photosharing [
> http://www.inbox.com/photosharing] to find out more!
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/manager
>
>
>

	[[alternative HTML version deleted]]


From cute_loomaa at hotmail.com  Sat Feb 14 13:27:58 2015
From: cute_loomaa at hotmail.com (hms Dreams)
Date: Sat, 14 Feb 2015 15:27:58 +0300
Subject: [R] help please >>metro_hastings function
Message-ID: <DUB128-W33F8C85C1DC256BA2F61AD96200@phx.gbl>




Hi :)anybody can help me please I'm trying to use Metro_Hastings (

MHadaptive package)the proplem is:  How can I know the covariance matrix( prop_sigma ) to enter it in Metro_Hastings: 
 mcmc_r=Metro_Hastings(li_func=baysianlog, pars=c(1,1,1), prop_sigma =NULL,par_names=c('alpha','gamma','delta'),data=x ) its gave me an error , I must enter the cov matrix but I don't know how to calculate it, somebody told me to wrote the function without prop_sigma but its also gave me an error what can I do?? Thank you,Sara
 		 	   		  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sat Feb 14 17:21:17 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 14 Feb 2015 08:21:17 -0800
Subject: [R] How can you validate association rules?
In-Reply-To: <BLU184-W396F2E724E1C0D8EF66E63BA230@phx.gbl>
References: <BLU184-W396F2E724E1C0D8EF66E63BA230@phx.gbl>
Message-ID: <CDBEB69B-2101-4B7F-BE05-AAA1107EEC68@dcn.davis.CA.us>

It will help greatly if you can learn to communicate according to the norms of the list. Reading the Posting Guide mentioned at the bottom of this email will help.

1) This mailing list is plain text. If you send HTML email it will get converted and we won't see what you see, which leads to  miscommunication.

2) The topic here is R, not statistics, so be careful not to wander too far off into why algorithms work. There are other forums where that kind of discussion makes sense, such as stats.stackexchange.com. Your question in its current form seems to belong there, though it sounds like you could probably get on topic here with a little work. Have you read the CRAN task view on machine learning? [1]

3) A small, reproducible example expressed in R of what you have achieved is highly recommended [2]. A clear specification of what you want to achieve is also needed. (We could probably make  progress on this question here if you had the example.) If you reference examples in R help files that you have read then you will clarify how far along you are in understanding the use of R.

[1] http://cran.r-project.org/web/views/MachineLearning.html

[2] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 13, 2015 8:46:32 AM PST, ayane <celestialxangel at hotmail.com> wrote:
>Hey everyone, 
>
>I just started learning R and statistics. I made association rules with
>the apriori algorithm in the arules package. I sorted them and pruned
>them. But now I want to validate/test them. In supervised learning they
>use cross validation. In this paper by Patrick O Perry
>http://arxiv.org/abs/0909.3052 I read it is possible to use cross
>validation on unsupervised learning methods (such as arules). But since
>my background in R, statistics and machine learning is weak the paper
>was quite hard to get through (also I'm not in college, I just finished
>high school and am preparing to study computer sciencec). 
>
>So my question is, how do you validate your rules? How can you use
>cross validation to do so? I have my main data set "Orders", it has 2
>million records. I used the sample function to make a training data set
>and a test data set. But what do I do next? Are there other techniques
>I should know of?
>
>If there are any specific tutorials on this subject, I would also love
>to learn from them.
>
>Kind regards,
>Ayane 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sat Feb 14 17:29:23 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 14 Feb 2015 08:29:23 -0800
Subject: [R] help please >>metro_hastings function
In-Reply-To: <DUB128-W33F8C85C1DC256BA2F61AD96200@phx.gbl>
Message-ID: <64778AF3E5D.00000A93jrkrideau@inbox.com>

It looks like you posted in HTML and the result are garbbled. ONly post in plain text. Also it might help to read one or both of these
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: cute_loomaa at hotmail.com
> Sent: Sat, 14 Feb 2015 15:27:58 +0300
> To: r-help at r-project.org
> Subject: [R] help please >>metro_hastings function
> 
> 
> 
> 
> Hi :)anybody can help me please I'm trying to use Metro_Hastings (
> 
> MHadaptive package)the proplem is:  How can I know the covariance matrix(
> prop_sigma ) to enter it in Metro_Hastings:
>  mcmc_r=Metro_Hastings(li_func=baysianlog, pars=c(1,1,1), prop_sigma
> =NULL,par_names=c('alpha','gamma','delta'),data=x ) its gave me an error
> , I must enter the cov matrix but I don't know how to calculate it,
> somebody told me to wrote the function without prop_sigma but its also
> gave me an error what can I do?? Thank you,Sara
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jrkrideau at inbox.com  Sat Feb 14 17:57:57 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 14 Feb 2015 08:57:57 -0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <CAM5FmSMNOKfT_X+2X5R0=wmkLSNBZxZK3B6fS7T=u-iGXhMj4A@mail.gmail.com>
References: <cam5fmsmaidzgj+d5drptguhbm4v1tr6aljjtdjskqcmfs5w49w@mail.gmail.com>
	<cam5fmsm-jucvyy6pzxfsvduzek2+gqg8smti++lxfg3sl0npqg@mail.gmail.com>
	<4b1afade554.0000031bjrkrideau@inbox.com>
	<5885a05522b.0000053fjrkrideau@inbox.com>
	<4ad1edc7c1f.00000299jrkrideau@inbox.com>
	<cam5fmspbv2v23ojbj=zsp4hi8onhh-rby2g1utxx-sbkqveifa@mail.gmail.com>
Message-ID: <64B762AE67C.00000AEBjrkrideau@inbox.com>

John Kane
Kingston ON Canada

-----Original Message-----
From: hyiltiz at gmail.com
Sent: Sat, 14 Feb 2015 16:32:03 +0800
To: jrkrideau at inbox.com
Subject: Re: [R] ggplot2 shifting bars to only overlap in groups

I think maybe it is possible to first produce a blank axis, and then splitting the data frame by the value of _direction. _Then add the goem_bar and goem_errorbar for the blank axis for the first split, then add them for the second half split. This is actually a slit-apply-combine strategy. It would be perfect if we could come up with the way to do that using _d_ply()._
==========================
john: It may be but I think it is beyond my knowledge.  I almost never would use a barchart and I really don't understand them very well.  I'd reccomend taking what you have both in barchart and scatterplot and talking to the real experts in the Google Groups ggplot group. You can get advice from Hadly and the other people who actually wrote the software.
==============================
I see where you are at when you are saying geom_point. I have adjusted it a bit so that the _direction_?factor is also labeled out with _linetype_, simply adding _linetype=direction_?in the goem_errorbar function. One problem for this is normally we use bar charts as a standard for this type of statistics, and the comparison is visually more easier using bar charts than the geom_point version.?
###################
john: Ah yes, I totally missed the up-down distinction.
I am not so sure that  the visual comparison is as informative but yes it is easier.

Perhaps the worst problem is that "...normally we use barcharts..."  Geting around some conventions can be a real &*^%. It's like broken axes and two scales on one graph.  It is accepted even if probably not at all a good idea.
################################
A question about this, though. What determines the vertical axis value for the points? I see they are layered so that they do not overlap although a lot of dots share the same horizontal value: male. Is that handled utterly by a mechanism that is not relevant with the data, but to produce less clattered plot?
########################################
john
Trial and error?  Yes it is the jitter() function. It is a very handy function to handle overlapping or very crowded data points

It took a little tweaking of the data but it seemed to work.

 I was thinking of ikoverlap problem on the way home a couple of nights ago and realised that while I could not jitter a factor I could recode it into a new numeric variable  and jitter that and use it as the x-axis rather than use Gender directly.  

So what I did was create a new variable dat1$jit  and add some jitter.  Then I plotted the data using dat1$jiit rather than dat1$gender and just re-named the Y axis to Gender.  I hope that is an answer to what you asked

See http://sape.inf.usi.ch/quick-reference/ggplot2/geom_jitter for what seems some basic info. Since this is the first time I have ever had an occasion to use them I am not really all that familiar with all the ins and outs 
####################################3
Thanks so much for your hlep! Here is the code I have tweaked based on yours, adding the dashed line for direction:
################################3

I am happy to have been of a little help and it was an interesting exercise.  Good luck with the rest of it and if you get those bars to work please post back here for our other readers to see what was done.

Gook luck
john

dat1 ?<- ?structure(list(gender = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L,

2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,

2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L), .Label = c("male", "female"

), class = "factor"), direction = structure(c(1L, 1L, 2L, 2L,

1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L,

1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("up",

"down"), class = "factor"), condition = structure(c(1L, 1L, 1L,

1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 1L, 1L, 1L,

1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L), .Label = c("c1",

"c2", "c3", "c4"), class = "factor"), location = structure(c(1L,

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("east",

"west"), class = "factor"), t = c(1.78664348823968, 1.045971213672,

1.45271943418506, 1.52433880441405, 0.894240903766416, 1.04200421306615,

0.992602172725307, 1.35686661120166, 1.15664717132331, 1.78519605814623,

1.3131987417228, 1.23649081362245, 1.33657440193627, 1.39069933103098,

1.16990353110185, 1.50384132346169, 0.240063246756554, 0.151918103772423,

1.26918566082989, 1.44462610872269, 0.944676078996681, 0.945358342820427,

0.68274449456263, 0.983609699924918, 1.06442538569853, 0.917922814494952,

1.06681054493614, 0.899670881737641, 0.639091165646195, 1.81227533189609,

1.02711921654525, 2.05244515236416), ci = c(0.199453475099606,

0.0208699634619525, 0.0267762622040696, 0.0719683008799792, 0.0388022593655329,

0.0873965412159785, 0.0828671112758008, 0.556676454332325, 0.109726976194332,

0.237352334670391, 0.202173510668684, 0.104263016807603, 0.0174283081233597,

0.027601059580507, 0.118300511535772, 0.272210060810133, 0.210343075045509,

0.010793003362928, 0.241665829872765, 0.387877941848338, 0.230361471258575,

0.233088662079594, 0.0956745517473407, 0.187969512005399, 0.0041769632082831,

0.26242665290992, 0.297793257986101, 0.14520541873456, 0.123447338902161,

0.10109002280374, 0.332925731545975, 0.434868806611465)), .Names = c("gender",

"direction", "condition", "location", "t", "ci"), row.names = c(NA,

-32L), class = "data.frame")

dat1$jit <- ifelse( dat1$gender == "male", ?1,

? ? ? ? ifelse( dat1$gender == 'female', ?2,

? ? ? ? ? NA) )

dat1$jit ?<- ?as.numeric(dat1$jit)

dat1$jit ?<- ?jitter(dat1$jit)

x ?<- ?"male"

y ?<- ?"female"############Begin code ##############

ab <- ?ggplot(dat1, aes (jit, t)) +

? ? ? ?geom_point(aes(colour = condition)) +

? ? ? ? theme(axis.ticks = element_blank()) +

? ? ? ? scale_x_continuous(breaks=c(1, 2),

? ? ? ? ? ? ? ? ? ? ? ? ? ?labels=c("male", "female"),

? ? ? ? ? ? ? ? ? ? ? ? ? ?name="Gender")

ab

bb ?<- ?ab + facet_grid(location~.)

bb

bc ?<- ?bb +

? ? geom_errorbar(data = dat1, aes(ymin=t-ci, ymax=t+ci,

? ? ? ? ? ? ? ? colour = condition,

? ? ? ? ? ? ? ? linetype = direction),

? ? ? ? ? ? ? ? ? width=.2 )

bc

cf ?<- ?bc + coord_flip()

cf

############End code ###############

???
========================
He who is worthy to receive his days and nights is worthy to receive* all 
else* from you (and me).
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? The Prophet, Gibran Kahlil 

On Sat, Feb 14, 2015 at 1:41 AM, John Kane <jrkrideau at inbox.com> wrote:

	Both files came through.? The R-help list is picky. For example it will accept cat.txt but not cat.csv.

 Now I see what you are after. and I must admit I haven't a clue at the moment. I suspect others who know more about ggplot can help.? If not there is ggplot2 Google Groups that has a lot of knowledge and you might want to post there.? It accepts all kinds of file types. :)

 On the other hand, I don't like dynamite plots (what you have) and wondered if it was possible to do something with geom_point() instead.

 It was, in a bit of a half-assed way so I'll pass on my raw code. It's ulgy but works. I don't know if I'd call it pub-quality but perhaps it can be tweaked (wrenched? , bludgened?) into something acceptable.

 BTW, I changed your data.frame name to dat1.? df is an R function.? Type df and you will see what I mean. I've also converted the data to a dput() file. Not needed as you supplied a perfectly good data set but generally good practice.

 Sorry I was not able to be of more help

 John Kane
 Kingston ON Canada

 ############Begin code ##############
 library(ggplot2)
 library(scales)
 dat1? <-? structure(list(gender = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L,
 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L), .Label = c("male", "female"
 ), class = "factor"), direction = structure(c(1L, 1L, 2L, 2L,
 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L,
 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("up",
 "down"), class = "factor"), condition = structure(c(1L, 1L, 1L,
 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 1L, 1L, 1L,
 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L), .Label = c("c1",
 "c2", "c3", "c4"), class = "factor"), location = structure(c(1L,
 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("east",
 "west"), class = "factor"), t = c(1.78664348823968, 1.045971213672,
 1.45271943418506, 1.52433880441405, 0.894240903766416, 1.04200421306615,
 0.992602172725307, 1.35686661120166, 1.15664717132331, 1.78519605814623,
 1.3131987417228, 1.23649081362245, 1.33657440193627, 1.39069933103098,
 1.16990353110185, 1.50384132346169, 0.240063246756554, 0.151918103772423,
 1.26918566082989, 1.44462610872269, 0.944676078996681, 0.945358342820427,
 0.68274449456263, 0.983609699924918, 1.06442538569853, 0.917922814494952,
 1.06681054493614, 0.899670881737641, 0.639091165646195, 1.81227533189609,
 1.02711921654525, 2.05244515236416), ci = c(0.199453475099606,
 0.0208699634619525, 0.0267762622040696, 0.0719683008799792, 0.0388022593655329,
 0.0873965412159785, 0.0828671112758008, 0.556676454332325, 0.109726976194332,
 0.237352334670391, 0.202173510668684, 0.104263016807603, 0.0174283081233597,
 0.027601059580507, 0.118300511535772, 0.272210060810133, 0.210343075045509,
 0.010793003362928, 0.241665829872765, 0.387877941848338, 0.230361471258575,
 0.233088662079594, 0.0956745517473407, 0.187969512005399, 0.0041769632082831,
 0.26242665290992, 0.297793257986101, 0.14520541873456, 0.123447338902161,
 0.10109002280374, 0.332925731545975, 0.434868806611465)), .Names = c("gender",
 "direction", "condition", "location", "t", "ci"), row.names = c(NA,
 -32L), class = "data.frame")

 dat1$jit <- ifelse( dat1$gender == "male",? 1,
 ? ? ? ? ifelse( dat1$gender == 'female',? 2,
 ? ? ? ? ? NA) )
 dat1$jit? <-? as.numeric(dat1$jit)

 dat1$jit? <-? jitter(dat1$jit)

 x? <-? "male"
 y? <-? "female"############Begin code ##############
 ab <-? ggplot(dat1, aes (jit, t)) +
 ? ? ? ?geom_point(aes(colour = condition)) +
 ? ? ? ? theme(axis.ticks = element_blank()) +
 ? ? ? ? scale_x_continuous(breaks=c(1, 2),
 ? ? ? ? ? ? ? ? ? ? ? ? ? ?labels=c("male", "female"),
 ? ? ? ? ? ? ? ? ? ? ? ? ? ?name="Gender")
 ab

 bb? <-? ab + facet_grid(location~.)
 bb

 bc? <-? bb +
 ? ? geom_errorbar(data = dat1, aes(ymin=t-ci, ymax=t+ci,
 ? ? ? ? ? ? ? ? colour = condition),
 ? ? ? ? ? ? ? ? ? width=.2 )
 bc

 cf? <-? bc + coord_flip()
 cf

 ############End code ###############

 John Kane
 Kingston ON Canada

 -----Original Message-----
 From: hyiltiz at gmail.com

Sent: Fri, 13 Feb 2015 02:28:17 +0800
 To: jrkrideau at inbox.com
 Subject: Re: [R] ggplot2 shifting bars to only overlap in groups

 I did not know the SVG file did not come through. I thought SVG should be able to pass through the filter. Here is a PDF file along with an PNG. Guess one of them should be able to pass.

 ???
 ========================
 He who is worthy to receive his days and nights is worthy to receive* all
 else* from you (and me).
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? The Prophet, Gibran Kahlil

 On Fri, Feb 13, 2015 at 12:04 AM, John Kane <jrkrideau at inbox.com> wrote:

 ?I'm a bit blind today. I read df as a dput() .

 ?John Kane
 ?Kingston ON Canada

 ?-----Original Message-----
 ?From: hyiltiz at gmail.com
 ?Sent: Thu, 12 Feb 2015 23:38:01 +0800
 ?To: jrkrideau at inbox.com
 ?Subject: Re: [R] ggplot2 shifting bars to only overlap in groups

 ?You are most likely simply not running the whole lines of code: note that the first line is:

 ?N = 32

 ??Best
 ??
 ?========================
 ?He who is worthy to receive his days and nights is worthy to receive* all
 ?else* from you (and me).
 ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? The Prophet, Gibran Kahlil

 ?On Thu, Feb 12, 2015 at 11:31 PM, John Kane <jrkrideau at inbox.com> wrote:

 ?? ? ? ? I am gettting the error"

??Error in rep_len(rep.int [http://rep.int] [http://rep.int [http://rep.int]] [http://rep.int [http://rep.int] [http://rep.int [http://rep.int]]](seq_len(n), rep.int [http://rep.int] [http://rep.int [http://rep.int]] [http://rep.int [http://rep.int] [http://rep.int [http://rep.int]]](k, n)), length) :

 ?? object 'N' not found

 ??Also your image did not come through.? Try sending it as a pdf file.

 ??when I try to create
 ??df<- data.frame(gender=gl(2,1,N, c("male","female")),
 ??? ? ? ? ? direction=gl(2,2,N, c("up","down")),
 ??? ? ? ? ? condition=gl(4,4,N, c("c1","c2","c3","c4")),
 ??? ? ? ? ? location=gl(2,16,N, c("east","west")),
 ??? ? ? ? ? t=rnorm(N, 1, 0.5),
 ??? ? ? ? ? ci=abs(rnorm(N, 0, 0.2)))

 ??John Kane
 ??Kingston ON Canada

 ??> -----Original Message-----
 ??> From: hyiltiz at gmail.com
 ??> Sent: Thu, 12 Feb 2015 22:08:36 +0800
 ??> To: r-help at r-project.org
 ??> Subject: [R] ggplot2 shifting bars to only overlap in groups
 ??>
 ??> Hi all,
 ??>
 ??> I have four factors for a continuous time variable along with its
 ??> confidence interval. I would like to produce a publication quality error
 ??> bar chart that is clear to understand. For now, I used colors, x axis
 ??> position, facets and alpha level to distinguish them.
 ??>
 ??> I would like to overlap each pairs of bars with the same color a bit as a
 ??> group, but not overlap each and every bars with each other.
 ??>
 ??> Here is a minimal example:
 ??>
 ??> N = 32
 ??> df<- data.frame(gender=gl(2,1,N, c("male","female")),
 ??>? ? ? ? ? ?direction=gl(2,2,N, c("up","down")),
 ??>? ? ? ? ? ?condition=gl(4,4,N, c("c1","c2","c3","c4")),
 ??>? ? ? ? ? ?location=gl(2,16,N, c("east","west")),
 ??>? ? ? ? ? ?t=rnorm(N, 1, 0.5),
 ??>? ? ? ? ? ?ci=abs(rnorm(N, 0, 0.2)))
 ??> pp <-
 ??>? ?ggplot(df, aes(x=gender, y=t, fill=condition, alpha=direction)) +
 ??>? ?facet_grid(location~.) +
 ??>? ?geom_bar(position=position_dodge(.9), stat="identity", color="black") +
 ??>? ?geom_errorbar(aes(ymin=t-ci, ymax=t+ci),
 ??>? ? ? ? ? ? ? ? ?width=.2,? ? ? ? ? ? ? ? ? ? # Width of the error bars
 ??>? ? ? ? ? ? ? ? ?position=position_dodge(.9)) +
 ??>? ?scale_alpha_discrete(range= c(0.4, 1))
 ??> pp
 ??>
 ??>
 ??>
 ??> In the attachment, I have added the output figure, while manually editing
 ??> the SVG file to make the lower-left group of bars to make them as I
 ??> wanted.
 ??> (The spacing in between each pair is not necessarily required.)
 ??>
 ??>
 ??> Best
 ??> ?
 ??> ========================
 ??> He who is worthy to receive his days and nights is worthy to receive* all
 ??> else* from you (and me).
 ??>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? The Prophet, Gibran
 ??> Kahlil

 ?> ______________________________________________
 ??> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

?> https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help] [https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]]]
 ??> PLEASE do read the posting guide
 ??> http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html] [http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]]]
 ??> and provide commented, minimal, self-contained, reproducible code.

 ??____________________________________________________________
 ??Can't remember your password? Do you need a strong and secure password?
 ??Use Password manager! It stores your passwords & protects your account.
 ??Check it out at http://mysecurelogon.com/password-manager [http://mysecurelogon.com/password-manager] [http://mysecurelogon.com/password-manager [http://mysecurelogon.com/password-manager]] [http://mysecurelogon.com/password-manager [http://mysecurelogon.com/password-manager] [http://mysecurelogon.com/password-manager [http://mysecurelogon.com/password-manager]]]

 ?____________________________________________________________
 ?FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
 ?Visit http://www.inbox.com/photosharing [http://www.inbox.com/photosharing] [http://www.inbox.com/photosharing [http://www.inbox.com/photosharing]] to find out more!

 ____________________________________________________________
 Can't remember your password? Do you need a strong and secure password?
 Use Password manager! It stores your passwords & protects your account.
 Check it out at http://mysecurelogon.com/manager [http://mysecurelogon.com/manager]

____________________________________________________________
Receive Notifications of Incoming Messages
Easily monitor multiple email accounts & access them with a click.
Visit http://www.inbox.com/notifier and check it out!


From jrkrideau at inbox.com  Sat Feb 14 18:08:20 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 14 Feb 2015 09:08:20 -0800
Subject: [R] Use of R for Hypothesis Testing
In-Reply-To: <CAGjHE10cWta4QybNp=eCQDbSADA+dF5huvVOh3f5OsYEjT4rcw@mail.gmail.com>
Message-ID: <64CE968B4C2.00000B02jrkrideau@inbox.com>

There are anumber of good papers and books in pdf format at the 
R site.  Select a CRAN location and you should see an entry for them on the left side of the page. Pick a couple and see if they help.

And for a fun read on introductory statistics in general which should cover everything you wanted to know and more have a look at 
Danial Navarro's downloadable stats book at http://health.adelaide.edu.au/psychology/ccs/teaching/lsr/

John Kane
Kingston ON Canada


> -----Original Message-----
> From: lisike at terpmail.umd.edu
> Sent: Fri, 13 Feb 2015 12:17:10 -0500
> To: r-help at r-project.org
> Subject: [R] Use of R for Hypothesis Testing
> 
> Dear Staff
> Hello,
> 
> I am recently trying to learn some functions of R. How would I use R to
> do
> T-test, confidence interval calculation, chi-square test and ANOVA?
> 
> --
> Thank you
> Sike Li (Lydia)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From lists at revelle.net  Sat Feb 14 18:29:45 2015
From: lists at revelle.net (William Revelle)
Date: Sat, 14 Feb 2015 11:29:45 -0600
Subject: [R] 2d rotation: vegan?
In-Reply-To: <4476A2AE-18B8-4516-AFE8-FDB35E3082A2@icloud.com>
References: <4476A2AE-18B8-4516-AFE8-FDB35E3082A2@icloud.com>
Message-ID: <9BB1C8B4-3AC8-4125-9D49-A840893AFC7E@revelle.net>

Randall,
  You might try the factor.rotate function in the psych package.  That will allow you to ?hand rotate? any solution where (in your example) nmdp is a matrix.

You also could look at the the various rotations available in the GPArotation package.

Bill

> On Feb 13, 2015, at 9:08 AM, Randall Morris-Ostrom <randall.morrisostrom at icloud.com> wrote:
> 
> I've been working at interpreting the results of a non-metric multidimensional scaling analysis. I have been using metaMDS in the vegan package because one of the benefits is that it also rotates to solution to its principal components. (Eventually I realized that there is no reason why my results would be most interpretable when aligned along the PC, but it was a nice starting point.)
> 
> I have been trying to find ways to rotate the resulting plot so I can visualize it differently and look at actual plot positions (as opposed to just rotating the print outs I have been looking at.) I'm able to find lots of suggestions for how to rotate3d plots, but almost nothing for 2d. I have tried using the MDSrotate function in vegan, but really it comes down to the fact that I'm clueless when I try to make sense of the documentation. *somewhat embarrassed*  My goal is basically to rotate the plot and exam the structure as a tool to generate theories about the meaning of the different dimensions (the interpretation of the clusters in my research are crystal clear.)
> 
> I generated a little fake data, just so there would be a plot. I've been trying to figure out how to do this as either just a simple scatterplot or using the vegan package.
> 
> Thank you for your time,
> Randy
> 
> Randall Morris-Ostrom J.D., M.S.
> Doctoral Candidate in Psychology,
> University of St. Thomas
> randall.morrisostrom at icloud.com
> 
> 
> Sample Code
> 
> library(vegan)
> set.seed(12345)
> x <- rnorm(1:10)
> y <- rnorm(1:10)
> df <- data.frame(x,y)
> d <- dist(df, method = "euclidean")
> nmds <- metaMDS(df, distance = "euclidean", k = 2)
> plot(nmds)
> # or
> nmdp <- as.data.frame(nmds$points)
> plot(nmdp$MDS1, nmdp$MDS2)
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

William Revelle		           http://personality-project.org/revelle.html
Professor			           http://personality-project.org
Department of Psychology   http://www.wcas.northwestern.edu/psych/
Northwestern University	   http://www.northwestern.edu/
Use R for psychology             http://personality-project.org/r
It is 3 minutes to midnight	   http://www.thebulletin.org


From kevin.thorpe at utoronto.ca  Sat Feb 14 18:47:32 2015
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Sat, 14 Feb 2015 12:47:32 -0500
Subject: [R] Use of R for Hypothesis Testing
In-Reply-To: <64CE968B4C2.00000B02jrkrideau@inbox.com>
References: <64CE968B4C2.00000B02jrkrideau@inbox.com>
Message-ID: <54DF8A34.7020000@utoronto.ca>

You will only really learn R by reading and trying things yourself. As 
John says, there are many good books out there. Have you read the 
introductory material that comes with R in the help system? I would 
recommend you start the help system and scroll through the list of 
functions contained in the stats package. You will be amazed at what you 
find.

Kevin

On 02/14/2015 12:08 PM, John Kane wrote:
> There are anumber of good papers and books in pdf format at the
> R site.  Select a CRAN location and you should see an entry for them on the left side of the page. Pick a couple and see if they help.
>
> And for a fun read on introductory statistics in general which should cover everything you wanted to know and more have a look at
> Danial Navarro's downloadable stats book at http://health.adelaide.edu.au/psychology/ccs/teaching/lsr/
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: lisike at terpmail.umd.edu
>> Sent: Fri, 13 Feb 2015 12:17:10 -0500
>> To: r-help at r-project.org
>> Subject: [R] Use of R for Hypothesis Testing
>>
>> Dear Staff
>> Hello,
>>
>> I am recently trying to learn some functions of R. How would I use R to
>> do
>> T-test, confidence interval calculation, chi-square test and ANOVA?
>>
>> --
>> Thank you
>> Sike Li (Lydia)
>>
>> 	[[alternative HTML version deleted]]
>>


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From avik at savion.huji.ac.il  Sat Feb 14 17:55:54 2015
From: avik at savion.huji.ac.il (Avraham Kluger)
Date: Sat, 14 Feb 2015 16:55:54 +0000
Subject: [R] Automate multiple meta-analyses
Message-ID: <268119BD809ADB44968F39A7A86398FA01268DE5FD@Pegasus1.hustaff.huji.local>

I have scores of data sets ready for meta-analyses.  I would like to run them as separate meta-analyses because otherwise I will be mixing apples with oranges.  In the code below, I successfully run a single meta-analysis with a moderator.

metacor(rho,N,Study,data=Leadership,comb.fixed=F,prediction=T,byvar=Leadership$Moderator)

To test my idea, I used the variable Moderator to try to produce separate meta analyses with either by or tapply, to no avail.  The closest I got to what I need is the code below.  It does produce separate output for each level of Moderator, but it just replicate the results without separating the data.  That is, I have k=13, and I just get the same k=13 meta-analysis for each level of Moderator.


attach(Leadership)
f<-metacor(rho,N,Study,comb.fixed=F,prediction=T)
by(Leadership,Moderator,function(x) f)

Yours,

Avi Kluger<http://pluto.huji.ac.il/~mskluger/kluger.html>


	[[alternative HTML version deleted]]


From glennmschultz at me.com  Sat Feb 14 18:10:45 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Sat, 14 Feb 2015 17:10:45 +0000 (GMT)
Subject: [R] BondLab Package
Message-ID: <5421a230-2229-40a5-9486-858f72cb7448@me.com>

Hi All,

I am getting closer to finalizing the package. ?Below is all my information; ?Description, namespace, and check from R Studio. ?I know its basically lubridate as well as bond basis function. ?I re-read the section on environments in Advanced R as I was thinking this is environment related. ?I am going over the creating packages documentation now. ?Unfortunately, whatever I am missing is not getting into my coconut. ? Any ideas are appreciated. ?

Here are my last issues: ?
All declared Imports should be used. ?Not sure?what?this is telling me. ?I have the packages in imports
No visible global function defined this seems like it all lubridate related. ?
Here is the pertinent section from check
=================================================
* checking dependencies in R code ... NOTE
Namespaces in Imports field not imported from:
? ?ggplot2? ?grid? ?lubridate? ?methods? ?optimx? ?plyr? ?reshape2?
? ?termstrc?
? All declared Imports should be used.
See the information on DESCRIPTION files in the chapter ?Creating R
packages? of the ?Writing R Extensions? manual.
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... NOTE
BondBasisConversion: no visible global function definition for ?day?
BondBasisConversion: no visible global function definition for ?month?
BondBasisConversion: no visible global function definition for ?year?
Mtg.Scenario : ReturnAnalysis: no visible global function definition
? for ?%m+%?
PrepaymentAssumption: no visible global function definition for ?%m+%?
Schedule: no visible global function definition for ?%m+%?

Here is my description file
=========================================================
Package: BondLab
Type: Package
Title: A package for the analysis of structured products
Version: 0.0.0
Date: 2013-12-08
Author: Glenn Schultz, CFA
Maintainer: Glenn Schultz <glennmschultz at me.com>
Description: The package provides a suite of software utilities for the analysis of Mortgage and Asset Backed securities
LazyLoad: yes
License: GPL(>=3.0)
Imports: termstrc,?
? ? ? ? ? reshape2,?
? ? ? ? ? ggplot2,?
? ? ? ? ? lubridate,?
? ? ? ? ? methods,?
? ? ? ? ? plyr,?
? ? ? ? ? grid,?
? ? ? ? ? optimx
Suggests: knitr,
? ? ? ? ? devtools,
? ? ? ? ? testthat
VignetteBuilder: knitr

Here is my namespace
=============================================================
# Generated by roxygen2 (4.1.0): do not edit by hand

export(CPR.To.SMM)
export(DollarRoll)
export(Effective.Convexity)
export(Effective.Duration)
export(EstimYTM)
export(Mortgage.Monthly.Payment)
export(MortgageCashFlow)
export(PPC.Ramp)
export(PassThroughAnalytics)
export(PassThroughOAS)
export(Rates)
export(Remain.Balance)
export(SMM.To.CPR)
export(SMMVector.To.CPR)
export(Sched.Prin)
export(TimeValue)
export(YTMtoPrice)
export(bondprice)
exportClasses(DollarRoll)
exportClasses(MBSDetails)
exportClasses(MortgageCashFlow)
exportClasses(MortgageOAS)
exportClasses(MortgageTermStructure)
exportClasses(Mtg.Scenario)
exportClasses(PrepaymentAssumption)
exportClasses(Scenario)

==============================================================
Here is my full check
==> devtools::check()

Updating BondLab documentation
Loading BondLab
'/Library/Frameworks/R.framework/Resources/bin/R' --vanilla CMD build ?\
? '/Users/glennschultz/BondLab' --no-resave-data --no-manual?

* checking for file ?/Users/glennschultz/BondLab/DESCRIPTION? ... OK
* preparing ?BondLab?:
* checking DESCRIPTION meta-information ... OK
* installing the package to build vignettes
* creating vignettes ... OK
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* building ?BondLab_0.0.0.tar.gz?

'/Library/Frameworks/R.framework/Resources/bin/R' --vanilla CMD check ?\
? '/var/folders/tv/sq6gmnvs13j8jrhkt87f_zmc0000gn/T//RtmpiHfQ8g/BondLab_0.0.0.tar.gz' ?\
? --timings?

* using log directory ?/Users/glennschultz/BondLab.Rcheck?
* using R version 3.1.2 (2014-10-31)
* using platform: x86_64-apple-darwin13.4.0 (64-bit)
* using session charset: UTF-8
* checking for file ?BondLab/DESCRIPTION? ... OK
* checking extension type ... Package
* this is package ?BondLab? version ?0.0.0?
* checking package namespace information ... OK
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking if there is a namespace ... OK
* checking for executable files ... OK
* checking for hidden files and directories ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking whether package ?BondLab? can be installed ... OK
* checking installed package size ... OK
* checking package directory ... OK
* checking ?build? directory ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... NOTE
Non-standard files/directories found at top level:
? ?BondData? ?Groups? ?PrepaymentModel? ?RAID? ?RDME? ?REMICData?
? ?RatesData? ?Scenario? ?Schedules? ?Tranches? ?WaterFall?
* checking for left-over files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for non-ASCII characters ... OK
* checking R files for syntax errors ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the package can be unloaded cleanly ... OK
* checking whether the namespace can be loaded with stated dependencies ... OK
* checking whether the namespace can be unloaded cleanly ... OK
* checking dependencies in R code ... NOTE
Namespaces in Imports field not imported from:
? ?ggplot2? ?grid? ?lubridate? ?methods? ?optimx? ?plyr? ?reshape2?
? ?termstrc?
? All declared Imports should be used.
See the information on DESCRIPTION files in the chapter ?Creating R
packages? of the ?Writing R Extensions? manual.
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... NOTE
BondBasisConversion: no visible global function definition for ?day?
BondBasisConversion: no visible global function definition for ?month?
BondBasisConversion: no visible global function definition for ?year?
Mtg.Scenario : ReturnAnalysis: no visible global function definition
? for ?%m+%?
PrepaymentAssumption: no visible global function definition for ?%m+%?
Schedule: no visible global function definition for ?%m+%?
* checking Rd files ... OK
* checking Rd metadata ... OK
* checking Rd line widths ... OK
* checking Rd cross-references ... OK
* checking for missing documentation entries ... WARNING
Undocumented code objects:
? ?CPR.To.SMM? ?DollarRoll? ?Effective.Convexity? ?Effective.Duration?
? ?EstimYTM? ?Mortgage.Monthly.Payment? ?MortgageCashFlow? ?PPC.Ramp?
? ?PassThroughAnalytics? ?PassThroughOAS? ?Rates? ?Remain.Balance?
? ?SMM.To.CPR? ?SMMVector.To.CPR? ?Sched.Prin? ?TimeValue? ?YTMtoPrice?
? ?bondprice?
Undocumented S4 classes:
? ?DollarRoll? ?MBSDetails? ?MortgageCashFlow? ?MortgageOAS?
? ?MortgageTermStructure? ?Mtg.Scenario? ?PrepaymentAssumption?
? ?Scenario?
All user-level objects in a package (including S4 classes and methods)
should have documentation entries.
See the chapter ?Writing R documentation files? in the ?Writing R
Extensions? manual.
* checking for code/documentation mismatches ... OK
* checking Rd \usage sections ... OK
* checking Rd contents ... OK
* checking for unstated dependencies in examples ... OK
* checking installed files from ?inst/doc? ... OK
* checking files in ?vignettes? ... OK
* checking examples ... NONE
* checking for unstated dependencies in tests ... OK
* checking tests ...
? Running ?test-all.R? OK
* checking for unstated dependencies in vignettes ...
?OK
* checking package vignettes in ?inst/doc? ... OK
* checking running R code from vignettes ...
? ??BondLab.Rmd? using ?UTF-8? ... OK
?OK
* checking re-building of vignette outputs ... OK
* checking PDF version of manual ... OK
* DONE
WARNING: There was 1 warning.
NOTE: There were 3 notes.
See
? ?/Users/glennschultz/BondLab.Rcheck/00check.log?
for details.



R CMD check succeeded


From cute_loomaa at hotmail.com  Sat Feb 14 18:52:22 2015
From: cute_loomaa at hotmail.com (hms Dreams)
Date: Sat, 14 Feb 2015 20:52:22 +0300
Subject: [R] my code in Metro_Hastings
Message-ID: <DUB128-W2904255A95472EF08048D796200@phx.gbl>

Hi again :)
my code is in the attachment file
the problem I think in the :



mcmc_r=Metro_Hastings(li_func=baysianlog, pars=c(1,1,1),par_names=c('alpha','gamma','delta'),data=x
)


because  I did not write the prop_sigma because I don't know how can I calcalute the covariance matrix.
 
somebody told me to compute the cov without itreation then  add the reasulting cov matrix to metro hasting using itreation
but it also gave me  an error 
 
Can you check my code and correct it please ?? 
 
Thank you,
Sara

 		 	   		  

From ravi.varadhan at jhu.edu  Sat Feb 14 22:29:46 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Sat, 14 Feb 2015 21:29:46 +0000
Subject: [R] Unable to use `eval(parse(text))' in nlme::lme
In-Reply-To: <CAF8bMcbPxuMrzLnkyoSwMoVUjOS=xC+5nLmonLotgZfHmbAmoA@mail.gmail.com>
References: <cdf2600432694952baa3f2fe5bac444b@DOM-EB1-2013.win.ad.jhu.edu>,
	<CAF8bMcbPxuMrzLnkyoSwMoVUjOS=xC+5nLmonLotgZfHmbAmoA@mail.gmail.com>
Message-ID: <1423949388581.15639@jhu.edu>

Yes, this is a very important point. Thank you, Bill.


Best,

Ravi

________________________________
From: William Dunlap <wdunlap at tibco.com>
Sent: Friday, February 13, 2015 4:56 PM
To: Ravi Varadhan
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Unable to use `eval(parse(text))' in nlme::lme

> ff <- reformulate(termlabels=c("time","as.factor(gvhd)"), response=yname, intercept=TRUE)

If the right hand side of the formula were more complicated than an additive list of terms,
say '~ time * as.factor(gvhd)' or the left side were more than a name, say 'log(yname)' you
could use bquote() instead of reformulate.  E.g.,
  > formulaTemplate <- log(.(responseName)) ~ time * as.factor(gvhd)
  > lapply(c("y1","y2","y3"), function(yname)do.call(bquote, list(formulaTemplate, list(responseName=as.name<http://as.name>(yname)))))
  [[1]]
  log(y1) ~ time * as.factor(gvhd)

  [[2]]
  log(y2) ~ time * as.factor(gvhd)

  [[3]]
  log(y3) ~ time * as.factor(gvhd)

I used 'do.call' because bquote does not evaluate its first argument,
but we need to evaluate the name 'formulaTemplate'.  You could avoid that
by putting the template verbatim in the call to bquote, as in
  lapply(c("y1","y2","y3"), function(yname)bquote(log(.(responseName)) ~ time * as.factor(gvhd), list(responseName=as.name<http://as.name>(yname))))

I like the do.call method because I can bury it in a function and forget about it.

bquote() retains the environment of the formula template.


Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Mon, Feb 9, 2015 at 6:44 AM, Ravi Varadhan <ravi.varadhan at jhu.edu<mailto:ravi.varadhan at jhu.edu>> wrote:
Thanks to Rolf, Duncan, and Ben.

Ben, your suggestion worked (with a minor correction of concatenating the termlabels into a vector).

Here is the solution to those interested.

ff <- reformulate(termlabels=c("time","as.factor(gvhd)"), response=yname, intercept=TRUE)
dd <- subset(labdata2, Transplant_type!=0 & time >0)
lme(ff, random=~1|Patient, data=dd, correlation=corAR1(), na.action=na.omit)

Best,
Ravi

Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
Associate Professor
Department of Oncology
Division of Biostatistics & Bionformatics
Johns Hopkins University
550 N. Broadway
Baltimore, MD 21205
40-502-2619


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From yhbrent at yahoo.com  Sat Feb 14 23:06:02 2015
From: yhbrent at yahoo.com (Brent)
Date: Sat, 14 Feb 2015 22:06:02 +0000 (UTC)
Subject: [R] RMySQL works inside function,
 but prints Error output when executed outside a function
Message-ID: <773197136.3300872.1423951562089.JavaMail.yahoo@mail.yahoo.com>

On my computer, if I execute this R code inside the console of Rgui.exe

??? execInsideFunction = function() {
??? ??? dbc = dbcLocal
??? ??? conn <- dbConnect(MySQL(), host = dbc$host, dbname = "xxx", user=dbc$user, password=dbc$password)
??? ??? dbSendQuery(conn, "delete from yyy")
??? ??? dbDisconnect(conn)
??? }
??? execInsideFunction()

It seems to work fine, printing

??? [1] TRUE

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

However, if I copy the body of that function

??? dbc = dbcLocal
??? conn <- dbConnect(MySQL(), host = dbc$host, dbname = "goral", user=dbc$user, password=dbc$password)
??? dbSendQuery(conn, "delete from archive_batches")
??? dbDisconnect(conn)

and paste it the console to execute it, then it prints the Error output

??? Error: evaluation nested too deeply: infinite recursion / options(expressions=)?
??? Error during wrapup: evaluation nested too deeply: infinite recursion / options(expressions=)?

What the heck is happening?!

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

I note that that Error output appears to be bogus: the database action (delete all rows from a table above) is actually carried out.? Indeed, the 2nd line ("Error during wrapup") indicates that the error only occurred later on.

Still, it is disturbing.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Note: I am using Revolution R Open 8.01-Beta 64 bit.

Below is the output when I execute sessionInfo():

??? R version 3.1.2 (2014-10-31)

??? Platform: x86_64-w64-mingw32/x64 (64-bit)

??? locale:
??? [1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United States.1252??? LC_MONETARY=English_United States.1252 LC_NUMERIC=C??? ?????????? LC_TIME=English_United States.1252?? 

??? attached base packages:
??? [1] grDevices datasets? tcltk???? stats???? tools???? utils???? graphics? methods?? base??? 

??? other attached packages:
??? [1] timeDate_3011.99 stringr_0.6.2??? RODBC_1.3-10???? quantmod_0.4-3?? quadprog_1.5-5?? gWidgets_0.0-54? debug_1.3.1????? goralSpeedUp_1.0 RMySQL_0.9-3???? DBI_0.3.1??????? bitops_1.0-6???? caTools_1.17.1?? lattice_0.20-29? TTR_0.22-0?????? xts_0.9-7??????? zoo_1.7-11?????? Rcpp_0.11.3????? mvbutils_2.7.4.1
??? [19] Matrix_1.1-4???? inline_0.3.13? 

??? loaded via a namespace (and not attached):
??? [1] grid_3.1.2



	[[alternative HTML version deleted]]


From maity at math.niu.edu  Sat Feb 14 23:06:00 2015
From: maity at math.niu.edu (arnabkm2007)
Date: Sat, 14 Feb 2015 14:06:00 -0800 (PST)
Subject: [R] Genrating Ordinal Responses in R
In-Reply-To: <1423868610293-4703244.post@n4.nabble.com>
References: <1423753425714-4703159.post@n4.nabble.com>
	<1423868610293-4703244.post@n4.nabble.com>
Message-ID: <CANjU7dmFTg8CrqAKu_3YDZhDgiiLDY_XhNvx5qWf3tBUGbhBSA@mail.gmail.com>

Thank you very much JS Huang. It helps.

Thanks & Regards,
Arnab



Arnab Kumar Maity
Graduate Teaching Assistant
Division of Statistics
Northern Illinois University
DeKalb, IL 60115
Email: maity at math.niu.edu
Ph:     779-777-3428

On Fri, Feb 13, 2015 at 5:03 PM, JS Huang [via R] <
ml-node+s789695n4703244h14 at n4.nabble.com> wrote:

> Hi,
>
>   Here assume there are four elements in the ordinal set y and take a
> random sample of size 10 according to the cumulative distribution given, or
> probability distribution p below.
>
>
> > y <- c(levels = c("First", "Second", "Third", "Fourth"))
> > y
>  levels1  levels2  levels3  levels4
>  "First" "Second"  "Third" "Fourth"
> > (x <- c(1/9, 1/4, 3/5, 1))
> [1] 0.1111111 0.2500000 0.6000000 1.0000000
> > p <- c(x[1], x[2]-x[1], x[3]-x[2], x[4]-x[3])
> > p
> [1] 0.1111111 0.1388889 0.3500000 0.4000000
> > sample(y, 10, replace=TRUE, prob=p)
>  levels2  levels4  levels4  levels3  levels1  levels3  levels4  levels2
>  levels4  levels3
> "Second" "Fourth" "Fourth"  "Third"  "First"  "Third" "Fourth" "Second"
> "Fourth"  "Third"
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
>
> http://r.789695.n4.nabble.com/Genrating-Ordinal-Responses-in-R-tp4703159p4703244.html
>  To unsubscribe from Genrating Ordinal Responses in R, click here
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4703159&code=bWFpdHlAbWF0aC5uaXUuZWR1fDQ3MDMxNTl8MTMwNTA3NDMzMA==>
> .
> NAML
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://r.789695.n4.nabble.com/Genrating-Ordinal-Responses-in-R-tp4703159p4703274.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From RZwick at ETS.ORG  Sun Feb 15 00:53:55 2015
From: RZwick at ETS.ORG (Zwick, Rebecca J)
Date: Sat, 14 Feb 2015 23:53:55 +0000
Subject: [R] Nonlinear integer programming (again)
Message-ID: <BY2PR07MB96554FB90F2F88F21A73DD7D2200@BY2PR07MB965.namprd07.prod.outlook.com>

Another user suggested I elaborate on my previous post, giving specifics of the problem I am trying to solve.  Here they are:



It is a selection problem involving sample weights.  Say we have applicants with test scores x.  The vector y indicates whether the applicant is a member of Group Y, which is relevant to selection.  The vector w contains the sample weights.  The vector z is to contain zeroes and ones indicating which applicants are selected.  I want to maximize the weighted average test score for the selected applicants, [1/(z'w)]*(z'diag(xw'), under the following constraints:



All elements of z are either 0 or 1.

Additional constraints are of the form

a ?  z'w ? b  and   z'diag(yw') ? c,

where a, b, and c are positive constants.



The inequality constraints are linear in z, but the quantity to be maximized is not.

My question is whether there is an R package that can handle this problem.



PREVIOUS POST:

I am seeking an optimization routine that can deal with the following problem:

Maximize g(x), where x is a vector and g is nonlinear, subject to linear constraints of the form h(x)>0 and m(x)=0 and subject to the constraint that all values of x are 0 or 1.

I can't find a nonlinear optimization program in R that states that it can accommodate 0-1 constraints.

Oddly, Excel's Solver will produce a solution to such problems but (1) I don't trust it and (2) it cannot handle a large number of constraints.


Rebecca Zwick  (Santa Barbara, California)
Statistical Analysis, Data Analysis, and Psychometric Research
Educational Testing Service


________________________________

This e-mail and any files transmitted with it may contain privileged or confidential information. It is solely for use by the individual for whom it is intended, even if addressed incorrectly. If you received this e-mail in error, please notify the sender; do not disclose, copy, distribute, or take any action in reliance on the contents of this information; and delete it from your system. Any other use of this e-mail is prohibited.


Thank you for your compliance.

________________________________

	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Sun Feb 15 01:06:14 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Sat, 14 Feb 2015 16:06:14 -0800 (PST)
Subject: [R] Nonlinear integer programming (again)
In-Reply-To: <BY2PR07MB96554FB90F2F88F21A73DD7D2200@BY2PR07MB965.namprd07.prod.outlook.com>
References: <BY2PR07MB96554FB90F2F88F21A73DD7D2200@BY2PR07MB965.namprd07.prod.outlook.com>
Message-ID: <alpine.LNX.2.11.1502141601560.550@localhost>

On Sat, 14 Feb 2015, Zwick, Rebecca J wrote:

> My question is whether there is an R package that can handle this problem.

Rebecca,

   I'm not sure, but have you looked at the Simplex method in the boot()
package?

<http://www.astrostatistics.psu.edu/datasets/R/html/boot/html/simplex.html>

Rich


From kwcg2010 at gmail.com  Sun Feb 15 06:37:59 2015
From: kwcg2010 at gmail.com (KWCG HE)
Date: Sun, 15 Feb 2015 00:37:59 -0500
Subject: [R] [Question] about plot.xts
Message-ID: <CAL+HOiihY+LBHwMi8JhcngHKsDDUVQHiNwuLJmLrs5SP10hxpg@mail.gmail.com>

Hi All,

I am trying to use xts and xtsExtra packages to plot multiple time series
on one plot.
I got two questions about this package.

What's the meaning of "*The following object is masked from ?package:xts?:*"
when load xts and xtsExtra?*  which plot.xts will be available if I local
xts first and then xtsExtra?*

How to draw multiple lines horizontal legend using legend.pars?

Many thanks.


Endeavor

-------------------------------------------------------------------------------------------

R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(xts)
Loading required package: zoo

Attaching package: ?zoo?

The following objects are masked from ?package:base?:

    as.Date, as.Date.numeric

> library(xtsExtra)

Attaching package: ?xtsExtra?

*The following object is masked from ?package:xts?:*

    plot.xts

>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Feb 15 08:08:35 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 14 Feb 2015 23:08:35 -0800
Subject: [R] [Question] about plot.xts
In-Reply-To: <CAL+HOiihY+LBHwMi8JhcngHKsDDUVQHiNwuLJmLrs5SP10hxpg@mail.gmail.com>
References: <CAL+HOiihY+LBHwMi8JhcngHKsDDUVQHiNwuLJmLrs5SP10hxpg@mail.gmail.com>
Message-ID: <89FDAC4E-13FC-4305-B3B8-1A1A458896BD@dcn.davis.CA.us>

It means that xtsExtra has a different version if plot.xts, and that will be the one that gets run when you call that function. If you want to use the one that is defined in xts, you can specify it...

xts::plot.xts(...)

In the future, don't post in HTML, since this is a plain text only list. We don't see the formatting that you see, so don't delude yourself into thinking that we do.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 14, 2015 9:37:59 PM PST, KWCG HE <kwcg2010 at gmail.com> wrote:
>Hi All,
>
>I am trying to use xts and xtsExtra packages to plot multiple time
>series
>on one plot.
>I got two questions about this package.
>
>What's the meaning of "*The following object is masked from
>?package:xts?:*"
>when load xts and xtsExtra?*  which plot.xts will be available if I
>local
>xts first and then xtsExtra?*
>
>How to draw multiple lines horizontal legend using legend.pars?
>
>Many thanks.
>
>
>Endeavor
>
>-------------------------------------------------------------------------------------------
>
>R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
>Copyright (C) 2014 The R Foundation for Statistical Computing
>Platform: x86_64-unknown-linux-gnu (64-bit)
>
>R is free software and comes with ABSOLUTELY NO WARRANTY.
>You are welcome to redistribute it under certain conditions.
>Type 'license()' or 'licence()' for distribution details.
>
>  Natural language support but running in an English locale
>
>R is a collaborative project with many contributors.
>Type 'contributors()' for more information and
>'citation()' on how to cite R or R packages in publications.
>
>Type 'demo()' for some demos, 'help()' for on-line help, or
>'help.start()' for an HTML browser interface to help.
>Type 'q()' to quit R.
>
>> library(xts)
>Loading required package: zoo
>
>Attaching package: ?zoo?
>
>The following objects are masked from ?package:base?:
>
>    as.Date, as.Date.numeric
>
>> library(xtsExtra)
>
>Attaching package: ?xtsExtra?
>
>*The following object is masked from ?package:xts?:*
>
>    plot.xts
>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From phaedrusv at gmail.com  Sun Feb 15 11:20:50 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Sun, 15 Feb 2015 10:20:50 +0000
Subject: [R] Noob question re: writing while loops on one line
Message-ID: <54E07302.1070108@gmail.com>

Hi list

I'm working through some exercises and did a while loop which raised an 
issue for me:

I can write out the while loop so:

 > count <- 0

while(count < 10) {
     print(count)
     count <- count + 1
    }

And this works fine.

Trying to do the same thing all on one line however gives this error:

"Error: unexpected symbol in "while(count < 10) { print(count) count""

My question:

How can one write out a while loop all in one line? Is there a symbol or 
something that I should be including?

Thanks for any suggestions.

Sun


From drjimlemon at gmail.com  Sun Feb 15 11:41:50 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 15 Feb 2015 21:41:50 +1100
Subject: [R] Noob question re: writing while loops on one line
In-Reply-To: <54E07302.1070108@gmail.com>
References: <54E07302.1070108@gmail.com>
Message-ID: <CA+8X3fUs7TT5OeKxCfw_xL8r4zebY0Y4c7ncx8LV=MCkspxsMA@mail.gmail.com>

Hi Sun,
Try including a semicolon.

while(count < 10) { print(count); count<-count+1 }

Jim


On Sun, Feb 15, 2015 at 9:20 PM, Sun Shine <phaedrusv at gmail.com> wrote:
> Hi list
>
> I'm working through some exercises and did a while loop which raised an
> issue for me:
>
> I can write out the while loop so:
>
>> count <- 0
>
> while(count < 10) {
>     print(count)
>     count <- count + 1
>    }
>
> And this works fine.
>
> Trying to do the same thing all on one line however gives this error:
>
> "Error: unexpected symbol in "while(count < 10) { print(count) count""
>
> My question:
>
> How can one write out a while loop all in one line? Is there a symbol or
> something that I should be including?
>
> Thanks for any suggestions.
>
> Sun
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From phaedrusv at gmail.com  Sun Feb 15 11:55:28 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Sun, 15 Feb 2015 10:55:28 +0000
Subject: [R] Noob question re: writing while loops on one line
In-Reply-To: <CA+8X3fUs7TT5OeKxCfw_xL8r4zebY0Y4c7ncx8LV=MCkspxsMA@mail.gmail.com>
References: <54E07302.1070108@gmail.com>
	<CA+8X3fUs7TT5OeKxCfw_xL8r4zebY0Y4c7ncx8LV=MCkspxsMA@mail.gmail.com>
Message-ID: <54E07B20.1070808@gmail.com>

Brilliant Jim - that does the trick!!

I guess then that the semi-colon rule works for any program or function 
that is being written on one line?

Any reason why when writing this out in the RStudio source editor no 
semi-colon is required, but it is when written in the interactive console?

Thanks again

Sun


On 15/02/15 10:41, Jim Lemon wrote:
> Hi Sun,
> Try including a semicolon.
>
> while(count < 10) { print(count); count<-count+1 }
>
> Jim
>
>
> On Sun, Feb 15, 2015 at 9:20 PM, Sun Shine <phaedrusv at gmail.com> wrote:
>> Hi list
>>
>> I'm working through some exercises and did a while loop which raised an
>> issue for me:
>>
>> I can write out the while loop so:
>>
>>> count <- 0
>> while(count < 10) {
>>      print(count)
>>      count <- count + 1
>>     }
>>
>> And this works fine.
>>
>> Trying to do the same thing all on one line however gives this error:
>>
>> "Error: unexpected symbol in "while(count < 10) { print(count) count""
>>
>> My question:
>>
>> How can one write out a while loop all in one line? Is there a symbol or
>> something that I should be including?
>>
>> Thanks for any suggestions.
>>
>> Sun
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jjanue.n at tv3.cat  Sun Feb 15 12:40:39 2015
From: jjanue.n at tv3.cat (Janue Miret, Jofre)
Date: Sun, 15 Feb 2015 11:40:39 +0000
Subject: [R] info markers from plotgoogMaps
Message-ID: <CC0C03B44EA34848831811718D11BBF664E09647@MAILBOX-3.ad-ccrtv.local>

Anyone Knows why doesn't refresh the data  InfoBox (infowindow) from map markers googlempas? There is always the first selection info data.
That's happen since last Friday 13th wiht googlempas from plotGoogleMaps.
There is any solution please?

	[[alternative HTML version deleted]]


From jSmith.Coursera at outlook.com  Sun Feb 15 10:48:56 2015
From: jSmith.Coursera at outlook.com (John Smith)
Date: Sun, 15 Feb 2015 10:48:56 +0100
Subject: [R] Creating Volatile Table in Teradata using RODBC
Message-ID: <COL403-EAS35640835C4F7F830730F66CFD210@phx.gbl>

Hi All

 

I'm trying to use R to create a temporary table in Teradata and then add
rows from data frame into the temporary volatile table in R

Based on the code below (I have changed the SQL slightly), I am able to
create the temporary table in my spool space but when I try add the data
frame mydata to it, R tells me it cannot find the table

My assumption here is that it is looking for the "real" table as opposed to
the temp table in spool space. Can anyone see the problem?

 

# RShowDoc("teradataR", package="teradataR") - Manual

#RShowDoc("RODBC", package="RODBC")

library(RODBC)

library(teradataR)

 

# Import Data From Text File and remove duplicates

mydata = read.table("c:/Users/user/Desktop/ Keys.txt")

mydata.unique = unique(mydata)

 

# Create SQL for Temp Table in Teradata

strSQL.TempTable = "CREATE VOLATILE TABLE TEMP_Keys (keys VARCHAR (39))
UNIQUE PRIMARY INDEX(key) ON COMMIT PRESERVE ROWS;"

 

# Connect To Teradata DB

channel <- odbcConnect('DB')

# Execute Temp Table

sqlQuery(channel, paste(strSQL.TempTable))

 

sqlUpdate(channel, mydata, tablename = "TEMP_Keys", fast = TRUE)

 

 

Any Help would be greatly appreciated

 

KEYWORDS: Volatile, SQL, R, RODBC, teradataR

REF:
http://stackoverflow.com/questions/24740751/error-with-creating-volatile-tab
le-in-teradata

 


	[[alternative HTML version deleted]]


From smartpink111 at yahoo.com  Sun Feb 15 11:44:28 2015
From: smartpink111 at yahoo.com (arun)
Date: Sun, 15 Feb 2015 10:44:28 +0000 (UTC)
Subject: [R] Difference in dates for unique ID
In-Reply-To: <847582382.5777760.1423996546406.JavaMail.yahoo@mail.yahoo.com>
References: <1852813742.3541618.1423694831468.JavaMail.yahoo@mail.yahoo.com>
	<847582382.5777760.1423996546406.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1076377825.5488375.1423997068609.JavaMail.yahoo@mail.yahoo.com>

HI Farnoosh,



Not sure I understand the expected output.  The difference between the first 2 days is "136 days"

May be this helps

   library(data.table)
       dcast.data.table(setDT(df)[, list(Visit=.N, Diff= as.numeric(abs(diff(as.Date(Date, format='%d-%b-%y'))))) ,
         by = ID], ID+Visit~ Diff, value.var='Diff', length)

    ID Visit 136 255 857
     1:  1     2   1   0   0
     2:  2     3   0   1   1





On Wednesday, February 11, 2015 5:47 PM, farnoosh sheikhi <farnoosh_81 at yahoo.com> wrote:



Hi Arun,

I have a data set that look s like below. I wanted to get a difference in dates for each unique ID and record it as a new X and have binary input for each one. 

ID   Date
1        06-Sep-13
1        20-Jan-14
2        06-Mar-12
2        25-Jun-11
2        29-Oct-13



For example for the first two date for ID=1 ( 20-Jan-14 - 06-Sep-13 ~ 121) and I want the data to be like follow:

ID  Visit   121
1       2        1
2       3         0


I really appreciate if you can help me with this. I know I need to write some kind of loop, but I don't know how to think of the logic behind it.
Thanks a lot.



Farnoosh


From maity at math.niu.edu  Sun Feb 15 15:30:38 2015
From: maity at math.niu.edu (arnabkm2007)
Date: Sun, 15 Feb 2015 06:30:38 -0800 (PST)
Subject: [R] Censoring in R2OpenBUGS
In-Reply-To: <54DD2408.6050006@statistik.tu-dortmund.de>
References: <1423753513965-4703160.post@n4.nabble.com>
	<54DD2408.6050006@statistik.tu-dortmund.de>
Message-ID: <CANjU7dm3quOLXrwS0O37yuTvvJs9Atc9=UQit9KGj-8HLTZ=og@mail.gmail.com>

Thank you so much Uwe. It seems working.

Thanks & Regards,
Arnab



Arnab Kumar Maity
Graduate Teaching Assistant
Division of Statistics
Northern Illinois University
DeKalb, IL 60115
Email: maity at math.niu.edu
Ph:     779-777-3428

On Thu, Feb 12, 2015 at 4:02 PM, Uwe Ligges-3 [via R] <
ml-node+s789695n4703197h57 at n4.nabble.com> wrote:

> On 12.02.2015 16:05, arnabkm2007 wrote:
>
> > Hi,
> >
> > I am trying to run the following model for OpenBUGS and want to use
> > R2OpenBUGS package. The model specifies weibull distribution for
> censored
> > data.
> >
> >
> >    weibull.model <- function()
> >    {
> >
> >      for(i in 1:n)
> >      {
> >
> >        exp.alpha[i] ~ dgamma(a.alpha, b.alpha)
> >        alpha[i] <- log(exp.alpha[i])
> >
> >        linear.part[i] <- alpha[i] + inprod(nu[ ], x[i, ])
> >        lambda[i] <- exp(linear.part[i])
> >
> >        time[i] ~ (dweib(shape, lambda[i]) C(censored.time[i], ))
> >
> >      }
> >
> >      shape ~ dgamma(a.shape, b.shape)
> >
> >      for(j in 1:p)
> >      {
> >
> >        beta[j]  ~ dnorm(prior.mean, prior.tau)
> >        gamma[j] ~ dbern(pi[j])
> >        pi[j]    ~ dbeta(1, 1)
> >        nu[j]   <- beta[j] * gamma[j]
> >
> >      }
> >
> >    }
> >
> >
> >
> > But R is throwing the following error.
> >
> > Error: unexpected symbol in:
> > "
> >        time[i] ~ (dweib(shape, lambda[i]) C"
> >
> > Any help regarding this will be appreciated.
>
> See ?write.model:
>
> "As a difference, BUGS syntax allows truncation specification like this:
> dnorm(...) I(...) but this is illegal in R. To overcome this
> incompatibility, use dummy operator %_% before I(...): dnorm(...) %_%
> I(...). The dummy operator %_% will be removed before the BUGS code is
> saved."
>
> Best,
> Uwe Ligges
>
>
>
>
>
> > Thanks & Regards,
> > Arnab
> >
> >
> > Arnab Kumar Maity
> > Graduate Teaching Assistant
> > Division of Statistics
> > Northern Illinois University
> > DeKalb, IL 60115
> > Email: [hidden email]
> <http:///user/SendEmail.jtp?type=node&node=4703197&i=0>
> > Ph:     779-777-3428
> >
> >
> >
> > --
> > View this message in context:
> http://r.789695.n4.nabble.com/Censoring-in-R2OpenBUGS-tp4703160.html
> > Sent from the R help mailing list archive at Nabble.com.
> >
> > ______________________________________________
> > [hidden email] <http:///user/SendEmail.jtp?type=node&node=4703197&i=1>
> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> [hidden email] <http:///user/SendEmail.jtp?type=node&node=4703197&i=2>
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
>
> http://r.789695.n4.nabble.com/Censoring-in-R2OpenBUGS-tp4703160p4703197.html
>  To unsubscribe from Censoring in R2OpenBUGS, click here
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4703160&code=bWFpdHlAbWF0aC5uaXUuZWR1fDQ3MDMxNjB8MTMwNTA3NDMzMA==>
> .
> NAML
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://r.789695.n4.nabble.com/Censoring-in-R2OpenBUGS-tp4703160p4703285.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sun Feb 15 15:53:51 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 15 Feb 2015 06:53:51 -0800
Subject: [R] info markers from plotgoogMaps
In-Reply-To: <CC0C03B44EA34848831811718D11BBF664E09647@MAILBOX-3.ad-ccrtv.local>
Message-ID: <7034A897D7E.00000570jrkrideau@inbox.com>

ttps://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jjanue.n at tv3.cat
> Sent: Sun, 15 Feb 2015 11:40:39 +0000
> To: r-help at r-project.org
> Subject: [R] info markers from plotgoogMaps
> 
> Anyone Knows why doesn't refresh the data  InfoBox (infowindow) from map
> markers googlempas? There is always the first selection info data.
> That's happen since last Friday 13th wiht googlempas from plotGoogleMaps.
> There is any solution please?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jrkrideau at inbox.com  Sun Feb 15 15:59:56 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 15 Feb 2015 06:59:56 -0800
Subject: [R] Noob question re: writing while loops on one line
In-Reply-To: <54E07B20.1070808@gmail.com>
References: <ca+8x3fus7tt5oekxcfw_xl8r4zeby0y4c7ncx8lv=mckspxsma@mail.gmail.com>
	<54e07302.1070108@gmail.com>
Message-ID: <70423CDCDF7.0000057Djrkrideau@inbox.com>

Hi Sun, 
Can you check the code in the one line command in RStudio?

I tied it and got the expected error.  Or to put it another way, it should not have run for you :)

The semi-colon is funtioning as a line return 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: phaedrusv at gmail.com
> Sent: Sun, 15 Feb 2015 10:55:28 +0000
> To: drjimlemon at gmail.com
> Subject: Re: [R] Noob question re: writing while loops on one line
> 
> Brilliant Jim - that does the trick!!
> 
> I guess then that the semi-colon rule works for any program or function
> that is being written on one line?
> 
> Any reason why when writing this out in the RStudio source editor no
> semi-colon is required, but it is when written in the interactive
> console?
> 
> Thanks again
> 
> Sun
> 
> 
> On 15/02/15 10:41, Jim Lemon wrote:
>> Hi Sun,
>> Try including a semicolon.
>> 
>> while(count < 10) { print(count); count<-count+1 }
>> 
>> Jim
>> 
>> 
>> On Sun, Feb 15, 2015 at 9:20 PM, Sun Shine <phaedrusv at gmail.com> wrote:
>>> Hi list
>>> 
>>> I'm working through some exercises and did a while loop which raised an
>>> issue for me:
>>> 
>>> I can write out the while loop so:
>>> 
>>>> count <- 0
>>> while(count < 10) {
>>>      print(count)
>>>      count <- count + 1
>>>     }
>>> 
>>> And this works fine.
>>> 
>>> Trying to do the same thing all on one line however gives this error:
>>> 
>>> "Error: unexpected symbol in "while(count < 10) { print(count) count""
>>> 
>>> My question:
>>> 
>>> How can one write out a while loop all in one line? Is there a symbol
>>> or
>>> something that I should be including?
>>> 
>>> Thanks for any suggestions.
>>> 
>>> Sun
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From phaedrusv at gmail.com  Sun Feb 15 16:08:07 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Sun, 15 Feb 2015 15:08:07 +0000
Subject: [R] Noob question re: writing while loops on one line
In-Reply-To: <70423CDCDF7.0000057Djrkrideau@inbox.com>
References: <ca+8x3fus7tt5oekxcfw_xl8r4zeby0y4c7ncx8lv=mckspxsma@mail.gmail.com>
	<54e07302.1070108@gmail.com>
	<70423CDCDF7.0000057Djrkrideau@inbox.com>
Message-ID: <54E0B657.1080205@gmail.com>

Thanks John: understanding it as a line return makes sense!

Cheers

Sun


On 15/02/15 14:59, John Kane wrote:
> Hi Sun,
> Can you check the code in the one line command in RStudio?
>
> I tied it and got the expected error.  Or to put it another way, it should not have run for you :)
>
> The semi-colon is funtioning as a line return
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: phaedrusv at gmail.com
>> Sent: Sun, 15 Feb 2015 10:55:28 +0000
>> To: drjimlemon at gmail.com
>> Subject: Re: [R] Noob question re: writing while loops on one line
>>
>> Brilliant Jim - that does the trick!!
>>
>> I guess then that the semi-colon rule works for any program or function
>> that is being written on one line?
>>
>> Any reason why when writing this out in the RStudio source editor no
>> semi-colon is required, but it is when written in the interactive
>> console?
>>
>> Thanks again
>>
>> Sun
>>
>>
>> On 15/02/15 10:41, Jim Lemon wrote:
>>> Hi Sun,
>>> Try including a semicolon.
>>>
>>> while(count < 10) { print(count); count<-count+1 }
>>>
>>> Jim
>>>
>>>
>>> On Sun, Feb 15, 2015 at 9:20 PM, Sun Shine <phaedrusv at gmail.com> wrote:
>>>> Hi list
>>>>
>>>> I'm working through some exercises and did a while loop which raised an
>>>> issue for me:
>>>>
>>>> I can write out the while loop so:
>>>>
>>>>> count <- 0
>>>> while(count < 10) {
>>>>       print(count)
>>>>       count <- count + 1
>>>>      }
>>>>
>>>> And this works fine.
>>>>
>>>> Trying to do the same thing all on one line however gives this error:
>>>>
>>>> "Error: unexpected symbol in "while(count < 10) { print(count) count""
>>>>
>>>> My question:
>>>>
>>>> How can one write out a while loop all in one line? Is there a symbol
>>>> or
>>>> something that I should be including?
>>>>
>>>> Thanks for any suggestions.
>>>>
>>>> Sun
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
>
>
>


From jrkrideau at inbox.com  Sun Feb 15 16:09:39 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 15 Feb 2015 07:09:39 -0800
Subject: [R] my code in Metro_Hastings
In-Reply-To: <DUB128-W2904255A95472EF08048D796200@phx.gbl>
Message-ID: <7057F55831B.00000596jrkrideau@inbox.com>

No sign of your code Saral.

Probably the best way to send it is a .txt file. That usually gets through. R-help is very fussy about what types of files it lets through

John Kane
Kingston ON Canada


> -----Original Message-----
> From: cute_loomaa at hotmail.com
> Sent: Sat, 14 Feb 2015 20:52:22 +0300
> To: r-help at r-project.org
> Subject: [R] my code in Metro_Hastings
> 
> Hi again :)
> my code is in the attachment file
> the problem I think in the :
> 
> 
> 
> mcmc_r=Metro_Hastings(li_func=baysianlog,
> pars=c(1,1,1),par_names=c('alpha','gamma','delta'),data=x
> )
> 
> 
> because  I did not write the prop_sigma because I don't know how can I
> calcalute the covariance matrix.
> 
> somebody told me to compute the cov without itreation then  add the
> reasulting cov matrix to metro hasting using itreation
> but it also gave me  an error
> 
> Can you check my code and correct it please ??
> 
> Thank you,
> Sara
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jjanue.n at tv3.cat  Sun Feb 15 16:22:29 2015
From: jjanue.n at tv3.cat (Janue Miret, Jofre)
Date: Sun, 15 Feb 2015 15:22:29 +0000
Subject: [R] info markers from plotgoogMaps
In-Reply-To: <7034A897D7E.00000570jrkrideau@inbox.com>
References: <CC0C03B44EA34848831811718D11BBF664E09647@MAILBOX-3.ad-ccrtv.local>,
	<7034A897D7E.00000570jrkrideau@inbox.com>
Message-ID: <CC0C03B44EA34848831811718D11BBF664E098C5@MAILBOX-3.ad-ccrtv.local>

this is an exemple:

library(plotGoogleMaps)
data(meuse)
coordinates(meuse)<-~x+y # convert to SPDF
proj4string(meuse) <- CRS('+init=epsg:28992')
# Adding Coordinate Referent Sys.
# Create web map of Point data
m<-plotGoogleMaps(meuse,filename='myMap1.htm')



________________________________________
De: John Kane [jrkrideau at inbox.com]
Enviat el: diumenge, 15 / febrer / 2015 15:53
Per a: Janue Miret, Jofre; 'r-help at r-project.org'
Tema: RE: [R] info markers from plotgoogMaps

ttps://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jjanue.n at tv3.cat
> Sent: Sun, 15 Feb 2015 11:40:39 +0000
> To: r-help at r-project.org
> Subject: [R] info markers from plotgoogMaps
>
> Anyone Knows why doesn't refresh the data  InfoBox (infowindow) from map
> markers googlempas? There is always the first selection info data.
> That's happen since last Friday 13th wiht googlempas from plotGoogleMaps.
> There is any solution please?
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
Check it out at http://www.inbox.com/earth




From murdoch.duncan at gmail.com  Sun Feb 15 16:54:05 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 15 Feb 2015 10:54:05 -0500
Subject: [R] Noob question re: writing while loops on one line
In-Reply-To: <54E0B657.1080205@gmail.com>
References: <ca+8x3fus7tt5oekxcfw_xl8r4zeby0y4c7ncx8lv=mckspxsma@mail.gmail.com>	<54e07302.1070108@gmail.com>	<70423CDCDF7.0000057Djrkrideau@inbox.com>
	<54E0B657.1080205@gmail.com>
Message-ID: <54E0C11D.8030406@gmail.com>

On 15/02/2015 10:08 AM, Sun Shine wrote:
> Thanks John: understanding it as a line return makes sense!

But it's not right.  This is one statement, and it returns the value 3:

1 +
2

This is an error:

1 + ; 2

The semicolon is a statement separator, not a line return.

Duncan Murdoch

> 
> Cheers
> 
> Sun
> 
> 
> On 15/02/15 14:59, John Kane wrote:
>> Hi Sun,
>> Can you check the code in the one line command in RStudio?
>>
>> I tied it and got the expected error.  Or to put it another way, it should not have run for you :)
>>
>> The semi-colon is funtioning as a line return
>>
>> John Kane
>> Kingston ON Canada
>>
>>
>>> -----Original Message-----
>>> From: phaedrusv at gmail.com
>>> Sent: Sun, 15 Feb 2015 10:55:28 +0000
>>> To: drjimlemon at gmail.com
>>> Subject: Re: [R] Noob question re: writing while loops on one line
>>>
>>> Brilliant Jim - that does the trick!!
>>>
>>> I guess then that the semi-colon rule works for any program or function
>>> that is being written on one line?
>>>
>>> Any reason why when writing this out in the RStudio source editor no
>>> semi-colon is required, but it is when written in the interactive
>>> console?
>>>
>>> Thanks again
>>>
>>> Sun
>>>
>>>
>>> On 15/02/15 10:41, Jim Lemon wrote:
>>>> Hi Sun,
>>>> Try including a semicolon.
>>>>
>>>> while(count < 10) { print(count); count<-count+1 }
>>>>
>>>> Jim
>>>>
>>>>
>>>> On Sun, Feb 15, 2015 at 9:20 PM, Sun Shine <phaedrusv at gmail.com> wrote:
>>>>> Hi list
>>>>>
>>>>> I'm working through some exercises and did a while loop which raised an
>>>>> issue for me:
>>>>>
>>>>> I can write out the while loop so:
>>>>>
>>>>>> count <- 0
>>>>> while(count < 10) {
>>>>>       print(count)
>>>>>       count <- count + 1
>>>>>      }
>>>>>
>>>>> And this works fine.
>>>>>
>>>>> Trying to do the same thing all on one line however gives this error:
>>>>>
>>>>> "Error: unexpected symbol in "while(count < 10) { print(count) count""
>>>>>
>>>>> My question:
>>>>>
>>>>> How can one write out a while loop all in one line? Is there a symbol
>>>>> or
>>>>> something that I should be including?
>>>>>
>>>>> Thanks for any suggestions.
>>>>>
>>>>> Sun
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ____________________________________________________________
>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
>> Visit http://www.inbox.com/photosharing to find out more!
>>
>>
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From john.archie.mckown at gmail.com  Sun Feb 15 17:20:39 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Sun, 15 Feb 2015 10:20:39 -0600
Subject: [R] Noob question re: writing while loops on one line
In-Reply-To: <54E0C11D.8030406@gmail.com>
References: <ca+8x3fus7tt5oekxcfw_xl8r4zeby0y4c7ncx8lv=mckspxsma@mail.gmail.com>
	<54e07302.1070108@gmail.com>
	<70423CDCDF7.0000057Djrkrideau@inbox.com>
	<54E0B657.1080205@gmail.com> <54E0C11D.8030406@gmail.com>
Message-ID: <CAAJSdjh5Sf1LD43kDsze4Xw_qZqXNs9f=9_FWB-JrWcHxud-Nw@mail.gmail.com>

On Sun, Feb 15, 2015 at 9:54 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 15/02/2015 10:08 AM, Sun Shine wrote:
> > Thanks John: understanding it as a line return makes sense!
>
> But it's not right.  This is one statement, and it returns the value 3:
>
> 1 +
> 2
>
> This is an error:
>
> 1 + ; 2
>
> The semicolon is a statement separator, not a line return.
>

?Technically speaking a semicolon is a statement terminator, not a
statement separator. In the case of the R language, that is a "nit". In the
case of Pascal, it is a big difference.


>
> Duncan Murdoch
>
>
?This is one reason why I _always_ use the semi-colon. It is _never_ really
wrong to do so. It may be _unnecessary_ in some case. It is also why I
always use <- as the assignment operator (well, that and because I like it
from my APL background). If there are two ways to express something, and
one of them is _always_ correct whereas the other _might not_ be correct in
some cases, then I think doing the former is simply "better form". But,
then, I'm anal about other things to. And that doesn't apply to interactive
use. I don't terminate my interactive statements with a semi-colon all the
time. Just most of the time. Of course, I'm a touch typist too and so it is
not really much of a problem for me.?



-- 
He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Feb 15 17:39:22 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 15 Feb 2015 08:39:22 -0800
Subject: [R] Noob question re: writing while loops on one line
In-Reply-To: <CAAJSdjh5Sf1LD43kDsze4Xw_qZqXNs9f=9_FWB-JrWcHxud-Nw@mail.gmail.com>
References: <ca+8x3fus7tt5oekxcfw_xl8r4zeby0y4c7ncx8lv=mckspxsma@mail.gmail.com>
	<54e07302.1070108@gmail.com>
	<70423CDCDF7.0000057Djrkrideau@inbox.com>
	<54E0B657.1080205@gmail.com> <54E0C11D.8030406@gmail.com>
	<CAAJSdjh5Sf1LD43kDsze4Xw_qZqXNs9f=9_FWB-JrWcHxud-Nw@mail.gmail.com>
Message-ID: <362196B3-B269-4D3F-95B8-B3541F0A7860@dcn.davis.CA.us>

Best not to be pedantic, John, unless you are going to be right. Please read section 10.3.5 in the R Language Definition  document. This is R, not C.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 15, 2015 8:20:39 AM PST, John McKown <john.archie.mckown at gmail.com> wrote:
>On Sun, Feb 15, 2015 at 9:54 AM, Duncan Murdoch
><murdoch.duncan at gmail.com>
>wrote:
>
>> On 15/02/2015 10:08 AM, Sun Shine wrote:
>> > Thanks John: understanding it as a line return makes sense!
>>
>> But it's not right.  This is one statement, and it returns the value
>3:
>>
>> 1 +
>> 2
>>
>> This is an error:
>>
>> 1 + ; 2
>>
>> The semicolon is a statement separator, not a line return.
>>
>
>?Technically speaking a semicolon is a statement terminator, not a
>statement separator. In the case of the R language, that is a "nit". In
>the
>case of Pascal, it is a big difference.
>
>
>>
>> Duncan Murdoch
>>
>>
>?This is one reason why I _always_ use the semi-colon. It is _never_
>really
>wrong to do so. It may be _unnecessary_ in some case. It is also why I
>always use <- as the assignment operator (well, that and because I like
>it
>from my APL background). If there are two ways to express something,
>and
>one of them is _always_ correct whereas the other _might not_ be
>correct in
>some cases, then I think doing the former is simply "better form". But,
>then, I'm anal about other things to. And that doesn't apply to
>interactive
>use. I don't terminate my interactive statements with a semi-colon all
>the
>time. Just most of the time. Of course, I'm a touch typist too and so
>it is
>not really much of a problem for me.?
>
>
>
>-- 
>He's about as useful as a wax frying pan.
>
>10 to the 12th power microphones = 1 Megaphone
>
>Maranatha! <><
>John McKown
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sun Feb 15 17:39:31 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 15 Feb 2015 08:39:31 -0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <CAM5FmSMNOKfT_X+2X5R0=wmkLSNBZxZK3B6fS7T=u-iGXhMj4A@mail.gmail.com>
References: <cam5fmsmaidzgj+d5drptguhbm4v1tr6aljjtdjskqcmfs5w49w@mail.gmail.com>
	<cam5fmsm-jucvyy6pzxfsvduzek2+gqg8smti++lxfg3sl0npqg@mail.gmail.com>
	<4b1afade554.0000031bjrkrideau@inbox.com>
	<5885a05522b.0000053fjrkrideau@inbox.com>
	<4ad1edc7c1f.00000299jrkrideau@inbox.com>
	<cam5fmspbv2v23ojbj=zsp4hi8onhh-rby2g1utxx-sbkqveifa@mail.gmail.com>
Message-ID: <7120DBAAD3F.0000064Fjrkrideau@inbox.com>

 I was thinking about this last night and decided to try more facetingi in the scatterplot.  (No data incuded as it is in your post below.)

 I have deleted the rest of our converstions as the mailer is refusing to mail this; the error message makes no sence; and so my best guess is that we have too large a post.

Have a look at this.  I may be predjudiced (well I am) as I do not like bar charts in most instances but I think this gives a better read of the data. It still needs tweaking but anyway.... I don't think the plot needs to be rotated now. I only did it to get a clear view as we had so many data points in only two panels.

John Kane
Kingston ON Canada

######################################

library(ggplot2)
library(scales)

dat1$jit <- ifelse( dat1$gender == "male",  1,
        ifelse( dat1$gender == 'female',  2,
          NA) )
dat1$jit  <-  as.numeric(dat1$jit)
dat1$jit  <-  jitter(dat1$jit)

ab <-  ggplot(dat1, aes (jit, t)) +
       geom_point(aes(colour = condition)) +
       geom_vline(xintercept = 1.5, colour = "grey")  +
        theme(axis.ticks = element_blank()) +
        scale_x_continuous(breaks=c(1, 2), 
                           labels=c("male", "female"),
                           name="Gender")
ab

bb  <-  ab + facet_grid(location~direction)
bb

bc  <-  bb + 
    geom_errorbar(data = dat1, aes(ymin=t-ci, ymax=t+ci,         
                colour = condition),
                  width=.1 )
bc
 
cf  <-  bc + coord_flip()
cf


######################################

-----Original Message-----
From: hyiltiz at gmail.com
Sent: Sat, 14 Feb 2015 16:32:03 +0800
To: jrkrideau at inbox.com
Subject: Re: [R] ggplot2 shifting bars to only overlap in groups

dat1 ?<- ?structure(list(gender = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L,

2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,

2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L), .Label = c("male", "female"

), class = "factor"), direction = structure(c(1L, 1L, 2L, 2L,

1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L,

1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("up",

"down"), class = "factor"), condition = structure(c(1L, 1L, 1L,

1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 1L, 1L, 1L,

1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L), .Label = c("c1",

"c2", "c3", "c4"), class = "factor"), location = structure(c(1L,

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("east",

"west"), class = "factor"), t = c(1.78664348823968, 1.045971213672,

1.45271943418506, 1.52433880441405, 0.894240903766416, 1.04200421306615,

0.992602172725307, 1.35686661120166, 1.15664717132331, 1.78519605814623,

1.3131987417228, 1.23649081362245, 1.33657440193627, 1.39069933103098,

1.16990353110185, 1.50384132346169, 0.240063246756554, 0.151918103772423,

1.26918566082989, 1.44462610872269, 0.944676078996681, 0.945358342820427,

0.68274449456263, 0.983609699924918, 1.06442538569853, 0.917922814494952,

1.06681054493614, 0.899670881737641, 0.639091165646195, 1.81227533189609,

1.02711921654525, 2.05244515236416), ci = c(0.199453475099606,

0.0208699634619525, 0.0267762622040696, 0.0719683008799792, 0.0388022593655329,

0.0873965412159785, 0.0828671112758008, 0.556676454332325, 0.109726976194332,

0.237352334670391, 0.202173510668684, 0.104263016807603, 0.0174283081233597,

0.027601059580507, 0.118300511535772, 0.272210060810133, 0.210343075045509,

0.010793003362928, 0.241665829872765, 0.387877941848338, 0.230361471258575,

0.233088662079594, 0.0956745517473407, 0.187969512005399, 0.0041769632082831,

0.26242665290992, 0.297793257986101, 0.14520541873456, 0.123447338902161,

0.10109002280374, 0.332925731545975, 0.434868806611465)), .Names = c("gender",

"direction", "condition", "location", "t", "ci"), row.names = c(NA,

-32L), class = "data.frame")

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jrkrideau at inbox.com  Sun Feb 15 17:40:51 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 15 Feb 2015 08:40:51 -0800
Subject: [R] Noob question re: writing while loops on one line
In-Reply-To: <CAAJSdjh5Sf1LD43kDsze4Xw_qZqXNs9f=9_FWB-JrWcHxud-Nw@mail.gmail.com>
References: <54e0c11d.8030406@gmail.com>
	<70423cdcdf7.0000057djrkrideau@inbox.com>
	<ca+8x3fus7tt5oekxcfw_xl8r4zeby0y4c7ncx8lv=mckspxsma@mail.gmail.com>
	<54e07302.1070108@gmail.com> <54e0b657.1080205@gmail.com>
Message-ID: <7123CDF5915.00000651jrkrideau@inbox.com>


Mea culpa, mea culpa
John Kane
Kingston ON Canada

-----Original Message-----
From: john.archie.mckown at gmail.com
Sent: Sun, 15 Feb 2015 10:20:39 -0600
To: murdoch.duncan at gmail.com
Subject: Re: [R] Noob question re: writing while loops on one line

On Sun, Feb 15, 2015 at 9:54 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

	On 15/02/2015 10:08 AM, Sun Shine wrote:
 > Thanks John: understanding it as a line return makes sense!

 But it's not right.? This is one statement, and it returns the value 3:

 1 +
 2

 This is an error:

 1 + ; 2

 The semicolon is a statement separator, not a line return.

 Technically speaking a semicolon is a statement terminator, not a statement separator. In the case of the R language, that is a "nit". In the case of Pascal, it is a big difference.

 Duncan Murdoch

 This is one reason why I _always_ use the semi-colon. It is _never_ really wrong to do so. It may be _unnecessary_ in some case. It is also why I always use <- as the assignment operator (well, that and because I like it from my APL background). If there are two ways to express something, and one of them is _always_ correct whereas the other _might not_ be correct in some cases, then I think doing the former is simply "better form". But, then, I'm anal about other things to. And that doesn't apply to interactive use. I don't terminate my interactive statements with a semi-colon all the time. Just most of the time. Of course, I'm a touch typist too and so it is not really much of a problem for me. 

-- 

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From hyiltiz at gmail.com  Sun Feb 15 19:30:09 2015
From: hyiltiz at gmail.com (=?UTF-8?Q?H=C3=B6rmetjan_Yiltiz?=)
Date: Mon, 16 Feb 2015 02:30:09 +0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <7120DBAAD3F.0000064Fjrkrideau@inbox.com>
References: <cam5fmsmaidzgj+d5drptguhbm4v1tr6aljjtdjskqcmfs5w49w@mail.gmail.com>
	<cam5fmsm-jucvyy6pzxfsvduzek2+gqg8smti++lxfg3sl0npqg@mail.gmail.com>
	<4b1afade554.0000031bjrkrideau@inbox.com>
	<5885a05522b.0000053fjrkrideau@inbox.com>
	<4ad1edc7c1f.00000299jrkrideau@inbox.com>
	<cam5fmspbv2v23ojbj=zsp4hi8onhh-rby2g1utxx-sbkqveifa@mail.gmail.com>
	<CAM5FmSMNOKfT_X+2X5R0=wmkLSNBZxZK3B6fS7T=u-iGXhMj4A@mail.gmail.com>
	<7120DBAAD3F.0000064Fjrkrideau@inbox.com>
Message-ID: <CAM5FmSPCz-0h5HbBMFkyMsGg8tCxmOfhiEG_-GTRe9_UyNUAAw@mail.gmail.com>

Thanks so much, John and Dennis (who did not respond in the mailing list
for some reason). I feel quite obliged to keep you thinking about this.

I do agree that not using the bar chart with error bars is a better option.
And since *condition* is an important ordinal factor for me, it would be
much better to have *condition* be positioned at a relative order. Thus,
only color coding it as John's latest solution would not be optimal.

It would have been better with the random data, but with my actual data, it
does seem necessary to do a jitter for the *male* since it got clattered in
the *west*. Here is the actual data along with the solution based on
Dennis' code:

## data

dat1 <-  structure(list(t = c(1.2454860689532, 0.627186899108052,
0.877176019393987,
                       1.26720638917869, 1.16906482219006,
0.889738853288831, 0.852034797572489,
                       1.30007600828822, 1.22896141479778,
0.820236562746995, 0.822197641624559,
                       1.39529772379005, 1.10479557445486,
0.760017179713665, 0.761340230517717,
                       1.11132156961026, 1.30042963441715,
0.811425854755042, 0.979421690403349,
                       1.3297658281305, 1.13377482477157,
0.895243910826397, 0.874181486658082,
                       1.15728885642541, 1.11121780853125,
0.703348405369258, 0.850897112058048,
                       1.14260584106012, 1.09383015337114,
0.911388765620587, 0.84622335453925,
                       1.09847968194129), condition = structure(c(4L, 4L,
4L, 4L, 1L,
                                                                  1L, 1L,
1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 1L,
                                                                  1L, 1L,
1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L), .Label = c("c1",
                                                                  "c2",
"c2", "c4"), class = "factor"), direction = structure(c(1L,
                       1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L,
2L, 2L, 1L,
                       1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L,
2L, 2L), .Label = c("up",
                       "down"), class = "factor"), location =
structure(c(2L, 1L, 2L,
  1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
  1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L), .Label = c("east",
  "west"), class = "factor"), gender = structure(c(2L, 2L, 2L,
  2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
  1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("male",
  "female"), class = "factor"), ci = c(0.0307396796826649,
0.0302954863637637,
0.0400142340797275, 0.0527186825100342, 0.051675810189946,
0.0368383294010065,
0.0404823188495183, 0.0526312391852324, 0.0347332720922338,
0.0354587857740343,
0.0303368490163547, 0.0710445198259065, 0.0229339653012889,
0.0261217906562281,
0.0285673216713352, 0.0351642108247828, 0.0542657646932069,
0.0566816739316165,
0.0481239729953889, 0.0434272572423839, 0.0497366325101659,
0.0342004255233646,
0.0349733697554762, 0.0405364256564456, 0.0478372176424872,
0.0341294939361437,
0.0424566961614424, 0.0463489561778199, 0.0191707406475215,
0.0501106812754005,
0.0321562411182704, 0.0218613299095178)), .Names = c("t", "condition",
"direction", "location", "gender", "ci"), row.names = c(NA, -32L
), class = "data.frame")

pp <- ggplot(dat1, aes(x = condition, y = t, color = gender, linetype =
direction)) +
  geom_errorbar(aes(ymin = t - ci, ymax = t + ci),
                position = position_dodge(width = 0.6), size = 1,
                width = 0.5) +
  geom_point(position = position_dodge(width = 0.6), size = 2.5) +
  facet_wrap(~ location) +
  scale_color_manual(values = c("blue", "darkorange"))+
  theme_bw()+
  scale_y_continuous(breaks=seq(0.6,1.5,0.1))
pp

## EOF

I have also attached the output.

?Best?
?
========================
He who is worthy to receive his days and nights is worthy to receive* all
else* from you (and me).
                                                 The Prophet, Gibran Kahlil
-------------- next part --------------
A non-text attachment was scrubbed...
Name: last.png
Type: image/png
Size: 5512 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150216/3ef5f36c/attachment.png>

From cute_loomaa at hotmail.com  Sun Feb 15 19:47:25 2015
From: cute_loomaa at hotmail.com (hms Dreams)
Date: Sun, 15 Feb 2015 21:47:25 +0300
Subject: [R] Metro_Hastings I wrote my code again
Message-ID: <DUB128-W16878C542F939ECC4DAFEE96210@phx.gbl>


Hi again :)

I wrote my code here:



library("MHadaptive")baysianlog=function (param,data)



        
{  alpha=param[1]

         
gam=param[2]



        
delta=param[3]


         
x=data


           n =length(x)


         
logl=n*log(alpha)+n*log(gam)+n*log(1/delta)+(alpha-1)*sum(log(x))-sum(log(1+(gam)*x^alpha))


       
p=prior(param)


       
return(logl+p) 


}


prior=function(param)


{  
alpha=param[1]


         
gam=param[2]


        
delta=param[3]


prior_alpha=dunif(alpha,min=0,
max=1,log=TRUE)


 prior_gam=dunif(gam,0,1,log=TRUE)  


prior_delta=dunif(delta,0,1,log=TRUE)  


return(prior_alpha+ prior_gam +prior_delta) 


}


 


n=7 ; m=15


alphaB=c();gamB=c();deltaB=c()


for( i 
in 1:m){


alpha=1.8;gam=3;delta=0.8


v= runif(n)


x =delta*((1-v)^(-1/gam)-1)^(1/alpha )


mcmc_r=Metro_Hastings(li_func=baysianlog, pars=c(1,1,1),par_names=c('alpha','gamma','delta'),data=x
)


 


alphaB[i] =mean(mcmc_r $ trac[,1]) 


gamB[i]=
mean(mcmc_r $ trac[,2])


deltaB[i]=
mean(mcmc_r $ trac[,3])


}#end for


#####


The output is:


Error in optim(pars, li_func,
control = list(fnscale = -1), hessian = TRUE,  :


 
non-finite finite-difference value [1]


________________

the problem I think in the :

mcmc_r=Metro_Hastings(li_func=baysianlog, pars=c(1,1,1),par_names=c('alpha','gamma','delta'),data=x )
because  I did not write the prop_sigma because I don't know how can I calcalute the covariance matrix.
 
somebody told me to compute the cov without itreation then  add the reasulting cov matrix to metro hasting using itreation
but it also gave me  an error 
 
 Please anybody can check my code and correct it ,this is the third time I wrote an email  ?? 
 
Thank you,
Sara
 		 	   		  
	[[alternative HTML version deleted]]


From statistics84 at hotmail.com  Sun Feb 15 20:16:51 2015
From: statistics84 at hotmail.com (pari hesabi)
Date: Sun, 15 Feb 2015 19:16:51 +0000
Subject: [R] package GPseq
Message-ID: <DUB125-W1158F0443D35C295FB0F89C6210@phx.gbl>

Hello
I am going to estimate the parameters of generalized Poisson model of Consul. ?I need to use the function: ?generalized -poisson-likelihood(y).
can anybody make me sure what the vector y is? ??
If the amounts of variable is: ?(0,1,2,3) , ?and the vector of observed values is: (1,4,7,3).
Which one is vector (y)?
Thank you


 		 	   		  

From statistics84 at hotmail.com  Sun Feb 15 20:25:50 2015
From: statistics84 at hotmail.com (pari hesabi)
Date: Sun, 15 Feb 2015 19:25:50 +0000
Subject: [R] package GPseq
In-Reply-To: <DUB125-W1158F0443D35C295FB0F89C6210@phx.gbl>
References: <DUB125-W1158F0443D35C295FB0F89C6210@phx.gbl>
Message-ID: <DUB125-W9D63C6B8AFBDEE5125F12C6210@phx.gbl>



----------------------------------------

?Hello
?I am going to estimate the parameters of generalized Poisson model of Consul. I need to use the function: generalized -poisson-likelihood(y).
?can anybody make me sure what the vector y is?
?If the amounts of variable is: (0,1,2,3) , and the vector of observed frequency for each level is: (1,4,7,3).
?Which one is vector (y)?
?Thank you



 		 	   		  

From murdoch.duncan at gmail.com  Sun Feb 15 21:19:16 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 15 Feb 2015 15:19:16 -0500
Subject: [R] Noob question re: writing while loops on one line
In-Reply-To: <CAAJSdjh5Sf1LD43kDsze4Xw_qZqXNs9f=9_FWB-JrWcHxud-Nw@mail.gmail.com>
References: <ca+8x3fus7tt5oekxcfw_xl8r4zeby0y4c7ncx8lv=mckspxsma@mail.gmail.com>	<54e07302.1070108@gmail.com>	<70423CDCDF7.0000057Djrkrideau@inbox.com>	<54E0B657.1080205@gmail.com>	<54E0C11D.8030406@gmail.com>
	<CAAJSdjh5Sf1LD43kDsze4Xw_qZqXNs9f=9_FWB-JrWcHxud-Nw@mail.gmail.com>
Message-ID: <54E0FF44.2070100@gmail.com>

On 15/02/2015 11:20 AM, John McKown wrote:
> On Sun, Feb 15, 2015 at 9:54 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>>wrote:
> 
>     On 15/02/2015 10:08 AM, Sun Shine wrote:
>     > Thanks John: understanding it as a line return makes sense!
> 
>     But it's not right.  This is one statement, and it returns the value 3:
> 
>     1 +
>     2
> 
>     This is an error:
> 
>     1 + ; 2
> 
>     The semicolon is a statement separator, not a line return.
> 
> 
> ?Technically speaking a semicolon is a statement terminator, not a
> statement separator. In the case of the R language, that is a "nit". In
> the case of Pascal, it is a big difference.
>  
> 
> 
>     Duncan Murdoch
> 
> 
> ?This is one reason why I _always_ use the semi-colon. It is _never_
> really wrong to do so. It may be _unnecessary_ in some case. It is also
> why I always use <- as the assignment operator (well, that and because I
> like it from my APL background). If there are two ways to express
> something, and one of them is _always_ correct whereas the other _might
> not_ be correct in some cases, then I think doing the former is simply
> "better form". But, then, I'm anal about other things to. And that
> doesn't apply to interactive use. I don't terminate my interactive
> statements with a semi-colon all the time. Just most of the time. Of
> course, I'm a touch typist too and so it is not really much of a problem
> for me.?

I don't use semicolons unless they are necessary, and I don't like it
when my students do.  For example, you could be misled by code like this:

x = 1;
y = 2;
verylongname = x + y
    + 1;

If this were C, verylongname would end up with the value 4.  If you read
it and only see 3 "terminators", you might think R is the same, but it's
not.  R sees that as 7 different statements:  two on the 1st, 2nd and
4th lines (in each case the second statement is empty), and one
statement on line 3.  So verylongname ends up with the value 3, not 4.

Cues to remind you what language you're using are a good thing.  That's
one reason to use <- (which I always do) instead of =, and not to use
unnecessary semicolons.

Duncan Murdoch

>  
> 
> 
> -- 
> He's about as useful as a wax frying pan.
> 
> 10 to the 12th power microphones = 1 Megaphone
> 
> Maranatha! <><
> John McKown


From john.archie.mckown at gmail.com  Sun Feb 15 21:30:23 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Sun, 15 Feb 2015 14:30:23 -0600
Subject: [R] Noob question re: writing while loops on one line
In-Reply-To: <54E0FF44.2070100@gmail.com>
References: <ca+8x3fus7tt5oekxcfw_xl8r4zeby0y4c7ncx8lv=mckspxsma@mail.gmail.com>
	<54e07302.1070108@gmail.com>
	<70423CDCDF7.0000057Djrkrideau@inbox.com>
	<54E0B657.1080205@gmail.com> <54E0C11D.8030406@gmail.com>
	<CAAJSdjh5Sf1LD43kDsze4Xw_qZqXNs9f=9_FWB-JrWcHxud-Nw@mail.gmail.com>
	<54E0FF44.2070100@gmail.com>
Message-ID: <CAAJSdjgYj3rzRkZ9xzWfYwBMXP5VAMZ3H77n5MgtdbyiZTHjjA@mail.gmail.com>

I guess my C background has messed me up a bit for R. Well, recovering from
APL was worse. I lost all sense of hierarchy of operations.
On Feb 15, 2015 2:19 PM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:

> On 15/02/2015 11:20 AM, John McKown wrote:
> > On Sun, Feb 15, 2015 at 9:54 AM, Duncan Murdoch
> > <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>>wrote:
> >
> >     On 15/02/2015 10:08 AM, Sun Shine wrote:
> >     > Thanks John: understanding it as a line return makes sense!
> >
> >     But it's not right.  This is one statement, and it returns the value
> 3:
> >
> >     1 +
> >     2
> >
> >     This is an error:
> >
> >     1 + ; 2
> >
> >     The semicolon is a statement separator, not a line return.
> >
> >
> > ?Technically speaking a semicolon is a statement terminator, not a
> > statement separator. In the case of the R language, that is a "nit". In
> > the case of Pascal, it is a big difference.
> >
> >
> >
> >     Duncan Murdoch
> >
> >
> > ?This is one reason why I _always_ use the semi-colon. It is _never_
> > really wrong to do so. It may be _unnecessary_ in some case. It is also
> > why I always use <- as the assignment operator (well, that and because I
> > like it from my APL background). If there are two ways to express
> > something, and one of them is _always_ correct whereas the other _might
> > not_ be correct in some cases, then I think doing the former is simply
> > "better form". But, then, I'm anal about other things to. And that
> > doesn't apply to interactive use. I don't terminate my interactive
> > statements with a semi-colon all the time. Just most of the time. Of
> > course, I'm a touch typist too and so it is not really much of a problem
> > for me.?
>
> I don't use semicolons unless they are necessary, and I don't like it
> when my students do.  For example, you could be misled by code like this:
>
> x = 1;
> y = 2;
> verylongname = x + y
>     + 1;
>
> If this were C, verylongname would end up with the value 4.  If you read
> it and only see 3 "terminators", you might think R is the same, but it's
> not.  R sees that as 7 different statements:  two on the 1st, 2nd and
> 4th lines (in each case the second statement is empty), and one
> statement on line 3.  So verylongname ends up with the value 3, not 4.
>
> Cues to remind you what language you're using are a good thing.  That's
> one reason to use <- (which I always do) instead of =, and not to use
> unnecessary semicolons.
>
> Duncan Murdoch
>
> >
> >
> >
> > --
> > He's about as useful as a wax frying pan.
> >
> > 10 to the 12th power microphones = 1 Megaphone
> >
> > Maranatha! <><
> > John McKown
>
>

	[[alternative HTML version deleted]]


From davidm.team at live.com  Sun Feb 15 18:33:32 2015
From: davidm.team at live.com (David Moskowitz)
Date: Sun, 15 Feb 2015 17:33:32 +0000
Subject: [R] =?utf-8?q?Picking_Best_Discriminant_Function_Variables?=
Message-ID: <COL403-EAS374E9EE1BBC62736823F9A483210@phx.gbl>

Is there a way to have the LDA function give me the best 3 (or 4)  predictor variables.  When I put in all the variables, LDA uses all the variables, but I would like to know what would be the 3 (or 4) best to use out all the available variables and the coefficients for those.




Here is the code I am using for Linear Discriminant Function

library("MASS") 



results <- lda(data$V1 ~ data$V2 + data$V3 + data$V4 + data$V5 + data$V6 + data$V7 + data$V8 + data$V9 + data$V10 + data$V11 + data$V12 + data$V13 + data$V14)



Output:

Coefficients of linear discriminants:
                    LD1                   LD2
data$V2 -0.403399781    0.8717930699
data$V3 0.165254596     0.3053797325
data$V4 -0.369075256    2.3458497486
data$V5 0.154797889     -0.1463807654
data$V6 -0.002163496    -0.0004627565
data$V7 0.618052068     -0.0322128171
data$V8 -1.661191235   -0.4919980543
data$V9 -1.495818440   -1.6309537953
data$V10 0.134092628   -0.3070875776
data$V11 0.355055710    0.2532306865
data$V12 -0.818036073    -1.5156344987
data$V13 -1.157559376    0.0511839665
data$V14 -0.002691206    0.0028529846




So in the above example, I would like the LDA to return to me the 3 best predictors out of the 13 available.


Thank you
	[[alternative HTML version deleted]]


From farnoosh_81 at yahoo.com  Sun Feb 15 19:41:12 2015
From: farnoosh_81 at yahoo.com (farnoosh sheikhi)
Date: Sun, 15 Feb 2015 10:41:12 -0800
Subject: [R] Difference in dates for unique ID
In-Reply-To: <1076377825.5488375.1423997068609.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1424025672.99939.YahooMailAndroidMobile@web141705.mail.bf1.yahoo.com>

That's exactly what I was thinking. Thanks tons.

Sent from Yahoo Mail on Android

From:"arun" <smartpink111 at yahoo.com>
Date:Sun, Feb 15, 2015 at 2:47 AM
Subject:Re: Difference in dates for unique ID

HI Farnoosh,



Not sure I understand the expected output.? The difference between the first 2 days is "136 days"

May be this helps

? library(data.table)
? ? ? dcast.data.table(setDT(df)[, list(Visit=.N, Diff= as.numeric(abs(diff(as.Date(Date, format='%d-%b-%y'))))) ,
? ? ? ? by = ID], ID+Visit~ Diff, value.var='Diff', length)

? ? ID Visit 136 255 857
? ? 1:? 1? ? 2? 1? 0? 0
? ? 2:? 2? ? 3? 0? 1? 1







On Wednesday, February 11, 2015 5:47 PM, farnoosh sheikhi <farnoosh_81 at yahoo.com> wrote:



Hi Arun,

I have a data set that look s like below. I wanted to get a difference in dates for each unique ID and record it as a new X and have binary input for each one. 

ID? Date
1? ? ? ? 06-Sep-13
1? ? ? ? 20-Jan-14
2? ? ? ? 06-Mar-12
2? ? ? ? 25-Jun-11
2? ? ? ? 29-Oct-13



For example for the first two date for ID=1 ( 20-Jan-14 - 06-Sep-13 ~ 121) and I want the data to be like follow:

ID? Visit? 121
1? ? ? 2? ? ? ? 1
2? ? ? 3? ? ? ? 0


I really appreciate if you can help me with this. I know I need to write some kind of loop, but I don't know how to think of the logic behind it.
Thanks a lot.



Farnoosh


	[[alternative HTML version deleted]]


From deyraja1 at yahoo.co.in  Sun Feb 15 18:16:15 2015
From: deyraja1 at yahoo.co.in (Raja Dey)
Date: Sun, 15 Feb 2015 17:16:15 +0000 (UTC)
Subject: [R] peer assessment
Message-ID: <1160922960.2802678.1424020575741.JavaMail.yahoo@mail.yahoo.com>

Dear Sir/Madam,I am currently a student of an online course on R Programming offered by JHU. I finished Week assignment. Peer assessment method is not very clear to me. My questions are as follows:
1. Is it compulsory?2. When it will start and what is the due date for peer assessment for each assignment? Is there any guideline?
3. Can I link my local files of week 2 assignment to my github account now?4. Did I miss any peer assessment for week 1?
Looking forward to hearing from you...My best regards,Raja
Raja Dey, Ph. D.UCONN

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Feb 15 22:03:17 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 15 Feb 2015 16:03:17 -0500
Subject: [R] peer assessment
In-Reply-To: <1160922960.2802678.1424020575741.JavaMail.yahoo@mail.yahoo.com>
References: <1160922960.2802678.1424020575741.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <54E10995.20907@gmail.com>

On 15/02/2015 12:16 PM, Raja Dey wrote:
> Dear Sir/Madam,I am currently a student of an online course on R Programming offered by JHU. I finished Week assignment. Peer assessment method is not very clear to me. My questions are as follows:
> 1. Is it compulsory?2. When it will start and what is the due date for peer assessment for each assignment? Is there any guideline?
> 3. Can I link my local files of week 2 assignment to my github account now?4. Did I miss any peer assessment for week 1?
> Looking forward to hearing from you...My best regards,Raja
> Raja Dey, Ph. D.UCONN

You're writing to the wrong place.  You need to write to your course
instructor, we have no idea about your course.

Duncan Murdoch


From arnab_stat at yahoo.com  Mon Feb 16 00:30:42 2015
From: arnab_stat at yahoo.com (ARNAB KR MAITY)
Date: Sun, 15 Feb 2015 23:30:42 +0000 (UTC)
Subject: [R] help please >>metro_hastings function
In-Reply-To: <DUB128-W33F8C85C1DC256BA2F61AD96200@phx.gbl>
References: <DUB128-W33F8C85C1DC256BA2F61AD96200@phx.gbl>
Message-ID: <1548614153.6326869.1424043042517.JavaMail.yahoo@mail.yahoo.com>

Hi,
I have used this function before successfully. I could help you if you could provide your code.
Thanks & Regards,Arnab?
      From: hms Dreams <cute_loomaa at hotmail.com>
 To: "r-help at r-project.org" <r-help at r-project.org> 
 Sent: Saturday, February 14, 2015 6:27 AM
 Subject: [R] help please >>metro_hastings function
   



Hi :)anybody can help me please I'm trying to use Metro_Hastings (

MHadaptive package)the proplem is:? How can I know the covariance matrix( prop_sigma ) to enter it in Metro_Hastings: 
 mcmc_r=Metro_Hastings(li_func=baysianlog, pars=c(1,1,1), prop_sigma =NULL,par_names=c('alpha','gamma','delta'),data=x ) its gave me an error , I must enter the cov matrix but I don't know how to calculate it, somebody told me to wrote the function without prop_sigma but its also gave me an error what can I do?? Thank you,Sara
 ??? ??? ??? ? ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From bingzhang.chen at gmail.com  Mon Feb 16 01:36:17 2015
From: bingzhang.chen at gmail.com (Bingzhang Chen)
Date: Mon, 16 Feb 2015 09:36:17 +0900
Subject: [R] Pass additional arguments to do.call(grid.arrange, plots)
Message-ID: <CAGeKiphVQ2xcqy-Qcpn1nTZJzjNX5aOLE9Kei0O_npH9QBowNQ@mail.gmail.com>

Hi R users,

I have a problem on how to pass an extra argument to do. call:

The example codes are:

#--------------------------------------------
require(ggplot2)
plots = lapply(1:5, function(.x) qplot(1:10,rnorm(10), main=paste("plot",.x)))
require(gridExtra)
do.call(grid.arrange,  plots)
#---------------------------------------------

I want to force the composite figures into 2 rows by adding 'now = 2'
in the function 'grid.arrange'. How can I do it?
I searched on google but could not find a workable solution.

I am working on RStudio 0.98.1102 on OSX Yosemite 10.10.2.
Thanks a lot,
Bingzhang

-- 
Bingzhang Chen
Ph. D.,
State Key Lab of Marine Environmental Science,
College of Oceanography and Environmental Science,
Xiamen University,
Xiamen, Fujian 361005
P. R. China


From robert.wood at adelphigroup.com  Mon Feb 16 00:31:44 2015
From: robert.wood at adelphigroup.com (Rob Wood)
Date: Sun, 15 Feb 2015 15:31:44 -0800 (PST)
Subject: [R] P-value from Matching
Message-ID: <1424043104310-4703309.post@n4.nabble.com>

Hi all,

When using the match command from the matching package, the output reports
the treatment effect, standard error, t-statistic and a p-value. Which test
is used to generate this p-value, or how us it generated?

Thanks,

Rob.



--
View this message in context: http://r.789695.n4.nabble.com/P-value-from-Matching-tp4703309.html
Sent from the R help mailing list archive at Nabble.com.


From sri4mailing at gmail.com  Mon Feb 16 06:03:45 2015
From: sri4mailing at gmail.com (Srikanth Gumma)
Date: Mon, 16 Feb 2015 13:03:45 +0800
Subject: [R] Fwd: Huge memory utilization when using doMC library
In-Reply-To: <mailman.2477.1423641097.3239.r-help@r-project.org>
References: <mailman.2477.1423641097.3239.r-help@r-project.org>
Message-ID: <CACSaa1W-zFD+W-QhEz=4P-9TFCn34iRUmk995FiuZRfLb=x4gA@mail.gmail.com>

Hi,

I'm the administrator of HPC cluster and one of the user reported that their
R job is vary slow. Below is the code that the user provided to me. May I
request your suggestion why the code is so slow and utilizing 100% memory?

I have installed R version 3.1.2 and RJags_3-14.


## data ##
set.seed(2015)
N <- 1000
y.i <- rnorm(N, 10, 0.1)


## set up MCMC ##
mcmc.chains    <- 3
ChainIDs       <- seq(1, mcmc.chains)
mcmc.burnin    <- 2
N.STEPS        <- 2
n.iter.perstep <- 3
mcmc.thin      <- 1

mort.parameters <- c("mu")
mort.data <- list(y.i = y.i, N = N)

jagsStep.dir <- paste0("JAGSoutput/")
dir.create("JAGSoutput/", showWarnings = FALSE)

library(foreach)
library(R2jags)
library(doMC) ## for linux server only
registerDoMC(4)

## start MCMC

foreach(chain = ChainIDs) %dopar% {

   chain*chain

  set.seed(2013 + chain * 1000)
  rnorm(chain)

  mod <- jags(data = mort.data, #inits = mort.inits,
              parameters.to.save = mort.parameters,
              model.file = "test.txt",
              jags.seed = chain,
              n.chains = 1, n.iter = n.iter.perstep + mcmc.burnin,
              n.burnin = mcmc.burnin, n.thin = mcmc.thin, DIC = TRUE)

}#end of chain loop

## the end ##

Thanks in advance.

Regards
Srikanth.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Feb 16 08:37:46 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 15 Feb 2015 23:37:46 -0800
Subject: [R] Pass additional arguments to do.call(grid.arrange, plots)
In-Reply-To: <CAGeKiphVQ2xcqy-Qcpn1nTZJzjNX5aOLE9Kei0O_npH9QBowNQ@mail.gmail.com>
References: <CAGeKiphVQ2xcqy-Qcpn1nTZJzjNX5aOLE9Kei0O_npH9QBowNQ@mail.gmail.com>
Message-ID: <BA91422F-56F1-4782-92AC-76C945FC2823@comcast.net>


On Feb 15, 2015, at 4:36 PM, Bingzhang Chen wrote:

> Hi R users,
> 
> I have a problem on how to pass an extra argument to do. call:
> 
> The example codes are:
> 
> #--------------------------------------------
> require(ggplot2)
> plots = lapply(1:5, function(.x) qplot(1:10,rnorm(10), main=paste("plot",.x)))
> require(gridExtra)
> do.call(grid.arrange,  plots)
> #---------------------------------------------
> 
> I want to force the composite figures into 2 rows by adding 'now = 2'
> in the function 'grid.arrange'. How can I do it?
> I searched on google but could not find a workable solution.

Wouldn't it just be:

do.call(grid.arrange,  c(plots, nrow=2) )

-- David.

> 
> I am working on RStudio 0.98.1102 on OSX Yosemite 10.10.2.
> Thanks a lot,
> Bingzhang
> 
> -- 
> Bingzhang Chen
> Ph. D.,
> State Key Lab of Marine Environmental Science,
> College of Oceanography and Environmental Science,
> Xiamen University,
> Xiamen, Fujian 361005
> P. R. China
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From petr.pikal at precheza.cz  Mon Feb 16 08:49:28 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 16 Feb 2015 07:49:28 +0000
Subject: [R] problems with packages installation
In-Reply-To: <F2AAA457-0CD8-41CB-BAD4-4005F255F441@dcn.davis.CA.us>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FD21@SRVEXCHMBX.precheza.cz>
	<7134618E-DDD1-4D77-AC99-3E5844F5438D@dcn.davis.CA.us>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FE74@SRVEXCHMBX.precheza.cz>
	<F2AAA457-0CD8-41CB-BAD4-4005F255F441@dcn.davis.CA.us>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C20213@SRVEXCHMBX.precheza.cz>

Hi Jeff

> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
> Sent: Friday, February 13, 2015 3:56 PM
> To: PIKAL Petr; r-help at r-project.org
> Cc: Richard M. Heiberger
> Subject: RE: [R] problems with packages installation
>
> I agree that the PG muddies the water a bit on this topic. However, the
> web page from which you downloaded the patched version warns:
>
> "This is not an official release of R. Please check bugs in this
> version against the official release before reporting them."
>
> When a new version is under  development, the number of bugs often
> increases temporarily by quite a bit. Any use you make of a patched or
> development version is at your own risk, and should be undertaken for
> two reasons only: to address a  specific problem you are having with
> the released version, or because you want to help test the unreleased
> version out of the goodness of your heart (bless you). In either case,

Yes, that is why I use devel versions but I was not able to find a bug (yet).

> chatter about bugs you encounter that are not in the released version
> belongs on R-devel.

It was hard to tell what is the problem. It could be that our IT people silently changed a firewall or something, which would prevent package installation from menu. Far too often I am not able to open some web pages e.g. (https://stat.ethz.ch/mailman/listinfo/r-devel) and I do not have power to change it.

However it seems to be that this particular problem is in R menu procedure for installation as I wrote in my previous mail.

>
> If you can reproduce the problem in a released version, posting on R-
> help would be more appropriate, but if you are sure it is a bug then
> filling a report is the right thing to do.

It is hard to reproduce and I believe that the problem is probably already known by R core (I thank them for their marvellous work).

For me it is solved by install.packages function.

Thanks

Best regards
Petr

> -----------------------------------------------------------------------
> ----
> Jeff Newmiller                        The     .....       .....  Go
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..
> Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> -----------------------------------------------------------------------
> ----
> Sent from my phone. Please excuse my brevity.
>
> On February 13, 2015 4:03:46 AM PST, PIKAL Petr
> <petr.pikal at precheza.cz> wrote:
> >Hi Jeff
> >
> >Can you be more specific why question about "using" R-devel shall be
> >directed to R-devel help list?
> >
> >Posting guide tells me:
> >
> >R-help is intended to be comprehensible to people who want to use R to
> >solve problems but who are not necessarily interested in or
> >knowledgeable about programming. R-devel is intended for questions and
> >discussion about code development in R. Questions likely to prompt
> >discussion unintelligible to non-programmers should go to to R-devel.
> >For example, questions involving C, C++, etc. code should go to
> >R-devel. More general questions involving pure R code and questions
> >likely to be of interest to the large and diverse set of subscribers
> to
> >R-help should go to R-help.
> >
> >and
> >
> >If you are using an old version of R and think it does not work
> >properly, upgrade to the latest version and try that, before posting.
> >If possible, try the current R-patched or R-devel version of R (see
> the
> >FAQ for details), to see if the problem has already been addressed.
> >
> >So even Posting guide suggests to poor user not to use obsolete
> version
> >of R and try R-patched or R-devel.
> >
> >To be honest - in R-patched (3.1.2)
> >
> >setInternet2(TRUE)
> >utils:::menuInstallPkgs()
> >
> >works without problems and the same applies to R-devel version from
> >June (3.2.0 - 66175) but it throws error in (3.2.0 - 67792).
> >
> >There is 15814 bug report about Package Installation which is replied
> >by Brian Ripley:
> >
> >The 'package installer' is the program which installs the Apple
> >package.  If you mean the 'Package Installer' menu item in R.app,
> there
> >is a known issue (but that is only known to causes failures, not
> >freezes).
> >
> >I tried Richard's suggestion (thanks Richard) and with small
> >modification (I do not want to install from sources)
> >
> >install.packages("ggplot2", repos="http://cran.at.r-project.org",
> >dependencies=TRUE)
> >
> >works as expected, therefore the problem is in **menu driven
> >installation procedure**. Shall I fill a bug report? Or it is already
> >known to R developers?
> >
> >Best regards
> >Petr
> >
> >
> >> -----Original Message-----
> >> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
> >> Sent: Thursday, February 12, 2015 6:15 PM
> >> To: PIKAL Petr; r-help at r-project.org
> >> Subject: Re: [R] problems with packages installation
> >>
> >> Time to (re)read the Posting Guide... questions about unreleased
> >> versions of R are off topic here. Go to R-devel.
> >>
> >----------------------------------------------------------------------
> -
> >> ----
> >> Jeff Newmiller                        The     .....       .....  Go
> >> Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
> Live
> >> Go...
> >>                                       Live:   OO#.. Dead: OO#..
> >> Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.
> with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >> rocks...1k
> >>
> >----------------------------------------------------------------------
> -
> >> ----
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On February 12, 2015 11:40:48 AM EST, PIKAL Petr
> >> <petr.pikal at precheza.cz> wrote:
> >> >Dear all
> >> >
> >> >I just switched to new version
> >> >
> >> >> version
> >> >               _
> >> >platform       i386-w64-mingw32
> >> >arch           i386
> >> >os             mingw32
> >> >system         i386, mingw32
> >> >status         Under development (unstable)
> >> >major          3
> >> >minor          2.0
> >> >year           2015
> >> >month          02
> >> >day            11
> >> >svn rev        67792
> >> >language       R
> >> >version.string R Under development (unstable) (2015-02-11 r67792)
> >> >nickname       Unsuffered Consequences
> >> >
> >> >and started to have problems with installing packages through utils
> >> >
> >> >> setInternet2(TRUE)
> >> >> utils:::menuInstallPkgs()
> >> >--- Please select a CRAN mirror for use in this session --- also
> >> >installing the dependencies ?colorspace?, ?Rcpp?, ?stringr?,
> >> >?RColorBrewer?, ?dichromat?, ?munsell?, ?labeling?, ?plyr?,
> >?digest?,
> >> >?gtable?, ?reshape2?, ?scales?, ?proto?
> >> >
> >> >trying URL
> >> >'http://cran.at.r-project.org/src/contrib/colorspace_1.2-4.zip'
> >> >Error in download.file(url, destfile, method, mode = "wb", ...) :
> >> >cannot open URL
> >> >'http://cran.at.r-project.org/src/contrib/colorspace_1.2-4.zip'
> >> >In addition: Warning message:
> >> >In download.file(url, destfile, method, mode = "wb", ...) :
> >> >  cannot open: HTTP status was '404 Not Found'
> >> >Warning in download.packages(pkgs, destdir = tmpd, available =
> >> >available,  :
> >> >  download of package ?colorspace? failed ....
> >> >
> >> >Before I start to disturb our IT I just want to know what could be
> >the
> >> >issue. AFAIK I did not change anything on my PC. In previous R-
> devel
> >> >version I used this package installation worked (and still works)
> >> >
> >> >> utils:::menuInstallPkgs()
> >> >--- Please select a CRAN mirror for use in this session --- trying
> >URL
> >> >'http://cran.at.r-
> project.org/bin/windows/contrib/3.2/mice_2.22.zip'
> >> >Content type 'application/zip' length 1148843 bytes (1.1 Mb) opened
> >> URL
> >> >downloaded 1.1 Mb
> >> >
> >> >package ?mice? successfully unpacked and MD5 sums checked
> >> >
> >> >The downloaded binary packages are in C:\Documents and
> >> >Settings\PikalP\Local Settings\Temp\RtmpgZuQB3\downloaded_packages
> >> >
> >> >> version
> >> >               _
> >> >platform       i386-w64-mingw32
> >> >arch           i386
> >> >os             mingw32
> >> >system         i386, mingw32
> >> >status         Under development (unstable)
> >> >major          3
> >> >minor          2.0
> >> >year           2014
> >> >month          07
> >> >day            16
> >> >svn rev        66175
> >> >language       R
> >> >version.string R Under development (unstable) (2014-07-16 r66175)
> >> >nickname       Unsuffered Consequences
> >> >
> >> >can you suggest what changed between those 2 R versions what
> >prevents
> >> >me in convenient installation of packages.
> >> >
> >> >Petr
> >> >
> >> >BTW. I can install packages manually but when there are many
> >> >dependencies it can be rather tricky.
> >> >
> >> >
> >
> >________________________________
> >Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
> jsou
> >ur?eny pouze jeho adres?t?m.
> >Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> >neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> >kopie vyma?te ze sv?ho syst?mu.
> >Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> >email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> >Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> >modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> >V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> >- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> >smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> >- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> >p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> >ze strany p??jemce s dodatkem ?i odchylkou.
> >- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> >v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> >- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> >spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> >zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> >adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> >p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> >zn?m?.
> >
> >This e-mail and any documents attached to it may be confidential and
> >are intended only for its intended recipients.
> >If you received this e-mail by mistake, please immediately inform its
> >sender. Delete the contents of this e-mail with all attachments and
> its
> >copies from your system.
> >If you are not the intended recipient of this e-mail, you are not
> >authorized to use, disseminate, copy or disclose this e-mail in any
> >manner.
> >The sender of this e-mail shall not be liable for any possible damage
> >caused by modifications of the e-mail or by delay with transfer of the
> >email.
> >
> >In case that this e-mail forms part of business dealings:
> >- the sender reserves the right to end negotiations about entering
> into
> >a contract in any time, for any reason, and without stating any
> >reasoning.
> >- if the e-mail contains an offer, the recipient is entitled to
> >immediately accept such offer; The sender of this e-mail (offer)
> >excludes any acceptance of the offer on the part of the recipient
> >containing any amendment or variation.
> >- the sender insists on that the respective contract is concluded only
> >upon an express mutual agreement on all its aspects.
> >- the sender of this e-mail informs that he/she is not authorized to
> >enter into any contracts on behalf of the company except for cases in
> >which he/she is expressly authorized to do so in writing, and such
> >authorization or power of attorney is submitted to the recipient or
> the
> >person represented by the recipient, or the existence of such
> >authorization is known to the recipient of the person represented by
> >the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pnsinha68 at gmail.com  Mon Feb 16 09:01:33 2015
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Mon, 16 Feb 2015 13:31:33 +0530
Subject: [R] Selection/filtering from Data
Message-ID: <CADcgpJeDeuNHPSAFrmU5dtu3Xhe+vPmTEUqkVJOMWb-j09yc4A@mail.gmail.com>

>From a dataset , I want select age >=36 and income>10000. How to do ?
parth


From r.turner at auckland.ac.nz  Mon Feb 16 09:07:20 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 16 Feb 2015 21:07:20 +1300
Subject: [R] Pass additional arguments to do.call(grid.arrange, plots)
In-Reply-To: <CAGeKiphVQ2xcqy-Qcpn1nTZJzjNX5aOLE9Kei0O_npH9QBowNQ@mail.gmail.com>
References: <CAGeKiphVQ2xcqy-Qcpn1nTZJzjNX5aOLE9Kei0O_npH9QBowNQ@mail.gmail.com>
Message-ID: <54E1A538.7010208@auckland.ac.nz>

On 16/02/15 13:36, Bingzhang Chen wrote:
> Hi R users,
>
> I have a problem on how to pass an extra argument to do. call:
>
> The example codes are:
>
> #--------------------------------------------
> require(ggplot2)
> plots = lapply(1:5, function(.x) qplot(1:10,rnorm(10), main=paste("plot",.x)))
> require(gridExtra)
> do.call(grid.arrange,  plots)
> #---------------------------------------------
>
> I want to force the composite figures into 2 rows by adding 'now = 2'

    You mean 'nrow = 2', but I wasn't fooled for an instant! :-)

> in the function 'grid.arrange'. How can I do it?
> I searched on google but could not find a workable solution.
>
> I am working on RStudio 0.98.1102 on OSX Yosemite 10.10.2.

Try:

     do.call(grid.arrange,c(plots,list(nrow=2))

The second argument to do.call() consists of a list constituting the 
arguments to the first argument.  So just append the argument you want 
to use, to this list.  Easy, once you know. :-)

cheers,

Rolf Turner

P. S.  Thank you for providing a clear and reproducible example.

R. T.

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From ripley at stats.ox.ac.uk  Mon Feb 16 09:07:29 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 16 Feb 2015 08:07:29 +0000
Subject: [R] problems with packages installation
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C20213@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FD21@SRVEXCHMBX.precheza.cz>	<7134618E-DDD1-4D77-AC99-3E5844F5438D@dcn.davis.CA.us>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C1FE74@SRVEXCHMBX.precheza.cz>	<F2AAA457-0CD8-41CB-BAD4-4005F255F441@dcn.davis.CA.us>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C20213@SRVEXCHMBX.precheza.cz>
Message-ID: <54E1A541.1050606@stats.ox.ac.uk>

On 16/02/2015 07:49, PIKAL Petr wrote:
> Hi Jeff
>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
>> Sent: Friday, February 13, 2015 3:56 PM
>> To: PIKAL Petr; r-help at r-project.org
>> Cc: Richard M. Heiberger
>> Subject: RE: [R] problems with packages installation
>>
>> I agree that the PG muddies the water a bit on this topic. However, the
>> web page from which you downloaded the patched version warns:
>>
>> "This is not an official release of R. Please check bugs in this
>> version against the official release before reporting them."
>>
>> When a new version is under  development, the number of bugs often
>> increases temporarily by quite a bit. Any use you make of a patched or
>> development version is at your own risk, and should be undertaken for
>> two reasons only: to address a  specific problem you are having with
>> the released version, or because you want to help test the unreleased
>> version out of the goodness of your heart (bless you). In either case,
>
> Yes, that is why I use devel versions but I was not able to find a bug (yet).
>
>> chatter about bugs you encounter that are not in the released version
>> belongs on R-devel.
>
> It was hard to tell what is the problem. It could be that our IT people silently changed a firewall or something, which would prevent package installation from menu. Far too often I am not able to open some web pages e.g. (https://stat.ethz.ch/mailman/listinfo/r-devel) and I do not have power to change it.
>
> However it seems to be that this particular problem is in R menu procedure for installation as I wrote in my previous mail.
>
>>
>> If you can reproduce the problem in a released version, posting on R-
>> help would be more appropriate, but if you are sure it is a bug then
>> filling a report is the right thing to do.
>
> It is hard to reproduce and I believe that the problem is probably already known by R core (I thank them for their marvellous work).

AFAIK it was already fixed in R-devel at the time of posting.

R-devel is 'under development', and at least until it reaches 'alpha' 
status the R-devel list is the place to report problems (if they persist 
for a few days and after checking with the current version).

> For me it is solved by install.packages function.

Actually that is what the menu calls.  The difference is the arguments 
you used (an explicit package rather than NULL for a menu).


>
> Thanks
>
> Best regards
> Petr


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From drjimlemon at gmail.com  Mon Feb 16 09:41:41 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 16 Feb 2015 19:41:41 +1100
Subject: [R] Selection/filtering from Data
In-Reply-To: <CADcgpJeDeuNHPSAFrmU5dtu3Xhe+vPmTEUqkVJOMWb-j09yc4A@mail.gmail.com>
References: <CADcgpJeDeuNHPSAFrmU5dtu3Xhe+vPmTEUqkVJOMWb-j09yc4A@mail.gmail.com>
Message-ID: <CA+8X3fXkoekUdR-D2YTNzkynEKo+=6AjqW5eGzs9=3PjmTormg@mail.gmail.com>

Hi Parth,
Assume that your dataset is in the form of a data frame, named psdf.

psdf<-data.frame(age=sample(0:100,50),income=sample(8000:12000,50))
selectdf<-subset(psdf,age >= 36 & income > 10000)

Jim

On Mon, Feb 16, 2015 at 7:01 PM, Partha Sinha <pnsinha68 at gmail.com> wrote:
> >From a dataset , I want select age >=36 and income>10000. How to do ?
> parth
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rodikgeorgiana at yahoo.com  Mon Feb 16 11:08:15 2015
From: rodikgeorgiana at yahoo.com (Rodica Coderie)
Date: Mon, 16 Feb 2015 10:08:15 +0000 (UTC)
Subject: [R] #library(party) -  Compare predicted results for ctree
Message-ID: <2121663143.1584704.1424081295743.JavaMail.yahoo@mail.yahoo.com>

Hello,

I've created a ctree model called fit using 15 input variables for a factor predicted variable Response (YES/NO).
When I run the following :
table(predict(fit2), training_data$response) 
I get the following result:

     NO   YES 
NO  48694   480 
YES     0     0

It appears that the NO responses are predicted with 100% accuracy and the YES response are predicted with 0% accuracy.

Why is this happening? It's because of my data or it's something in ctree algorithm?

Thanks!
Rodica


From hwborchers at gmail.com  Mon Feb 16 11:12:40 2015
From: hwborchers at gmail.com (Hans W Borchers)
Date: Mon, 16 Feb 2015 11:12:40 +0100
Subject: [R] Nonlinear integer programming (again)
Message-ID: <CAML4n3NxwQJdT--huCOYUwtOWQ0xAA1CYrgDNQKocxiLphRfPw@mail.gmail.com>

Zwick, Rebecca J <RZwick <at> ETS.ORG> writes:

> Oddly, Excel's Solver will produce a solution to such problems but
> (1) I don't trust it and
> (2) it cannot handle a large number of constraints.
> [...]
> My question is whether there is an R package that can handle this problem.


There are not many free integer (nonlinear) programming (IP, INLP)
solvers available. You could send your problem to one of the MINLP
solvers at NEOS:

    http://neos.mcs.anl.gov/neos/solvers/

[See the list of relevant NEOS solvers (commercial and free) on this page:
 http://www.neos-guide.org/content/mixed-integer-nonlinear-programming]

You can also use the 'rneos' package to send your request to one of
these Web services, but most of the time I find it easier to directly
fill the solver template. Please note that you have to format your
problem and data according to the solver's needs, i.e. likely in AMLP
or GAMS syntax.

If you intend to solve such problems more often, I'd suggest to
download one of the commercial solvers with academic licenses (e.g.,
Knitro, Gurobi, ...) and to install a corresponding R package to
access the solver. For more information see the Optimization task
view.

I would *never* trust Excel for these kinds of problems...

By the way, I may not correctly understand your objective, but perhaps
you can formulate it as maximizing a quadratic function (with
constraints).


From Achim.Zeileis at uibk.ac.at  Mon Feb 16 11:17:45 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 16 Feb 2015 11:17:45 +0100 (CET)
Subject: [R] #library(party) -  Compare predicted results for ctree
In-Reply-To: <2121663143.1584704.1424081295743.JavaMail.yahoo@mail.yahoo.com>
References: <2121663143.1584704.1424081295743.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <alpine.DEB.2.11.1502161114490.12191@paninaro.uibk.ac.at>

On Mon, 16 Feb 2015, Rodica Coderie via R-help wrote:

> Hello,
>
> I've created a ctree model called fit using 15 input variables for a factor predicted variable Response (YES/NO).
> When I run the following :
> table(predict(fit2), training_data$response)
> I get the following result:
>
>     NO   YES
> NO  48694   480
> YES     0     0
>
> It appears that the NO responses are predicted with 100% accuracy and 
> the YES response are predicted with 0% accuracy.
>
> Why is this happening? It's because of my data or it's something in 
> ctree algorithm?

Your data has less than 1% of YES observations and I would guess that the 
tree cannot separate these in a way such that majority voting gives a YES 
prediction. You might consider a different cutoff (other than 50%) or 
downsampling the NO observations.

> Thanks!
> Rodica
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From groemping at beuth-hochschule.de  Mon Feb 16 12:37:01 2015
From: groemping at beuth-hochschule.de (=?UTF-8?B?VWxyaWtlIEdyw7ZtcGluZw==?=)
Date: Mon, 16 Feb 2015 12:37:01 +0100
Subject: [R] How do I provide path character string to extdata content?
Message-ID: <54E1D65D.4050505@beuth-hochschule.de>

Dear helpeRs,

I have some png files in the inst/extdata directory of a package (e.g.,
man.png), and I want to provide character strings containing the paths to
these files; of course, these path strings have to depend on the individual
installation. So far, I have written a function that - if called - writes
the correct strings to the global environment, but that is not CRAN
compatible.

Ideally, I want the package namespace to export these text strings. I have
played with .onLoad without luck. I do not have a good understanding of
which hook is for which purpose. How can I go about this?

Best, Ulrike


From Michael.Langmaack at the-klu.org  Mon Feb 16 11:14:29 2015
From: Michael.Langmaack at the-klu.org (Michael Langmaack)
Date: Mon, 16 Feb 2015 10:14:29 +0000
Subject: [R] How to get the error and error variance after HB using
 bayesm
In-Reply-To: <CANjU7d=qxwwy8Z+ndg_Sv1rq_2Zk0sbZZmAvoX2sSnowpb38qw@mail.gmail.com>
References: <0A511BFF87BC3147B5F91EA884F122FB3FCA72A0@KLU-MAIL-01.KLU.klu>
	<CANjU7d=qxwwy8Z+ndg_Sv1rq_2Zk0sbZZmAvoX2sSnowpb38qw@mail.gmail.com>
Message-ID: <0A511BFF87BC3147B5F91EA884F122FB3FCAFB8A@KLU-MAIL-01.KLU.klu>

Hi Arnab,

Actually, I don?t think so as in Bayesian Regression the estimation converges towards the prior distribution and not a point estimate like in the frequentist approach. But I?m not very sure honestly. I used a Bayesian Logit Model in R (bayesm, rhierBinLogit by Rossi) to calculate individual pert-worth. I reviewer asked me to control for error variance as my results highly depend on it. But I do not know how to deal with using the Bayesian approach.

Cheers,
Michael

From: arnabkrmaity at gmail.com [mailto:arnabkrmaity at gmail.com] On Behalf Of ARNAB KR MAITY
Sent: Freitag, 13. Februar 2015 20:46
To: Michael Langmaack
Cc: r-help at r-project.org
Subject: Re: [R] How to get the error and error variance after HB using bayesm

Hello Michael,

I have a question here. Does Bayesian paradigm deal with MSE kind of stuff?

Thanks & Regards,
Arnab



Arnab Kumar Maity
Graduate Teaching Assistant
Division of Statistics
Northern Illinois University
DeKalb, IL 60115
Email: maity at math.niu.edu<mailto:maity at math.niu.edu>
Ph:     779-777-3428

On Fri, Feb 13, 2015 at 4:45 AM, Michael Langmaack <Michael.Langmaack at the-klu.org<mailto:Michael.Langmaack at the-klu.org>> wrote:
Hello all,

I have a question concerning bayesian regression in R using the package bayesm (version 2.2-5) by Peter Rossi. I have binary choice data and estimated individual coefficients using the command rhierBinLogit(Data=Data,Mcmc=Mcmc). That worked out properly, conversion plots, histograms, parameter are fine. No a have to compute the errors and the error variance or something like the MSE. But I do not know how to do. I did not find a hint so far. I would be more than happy if anybody can help me. Thanks in advance!

Best regards,
Michael

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From laurent.franckx at vito.be  Mon Feb 16 13:45:47 2015
From: laurent.franckx at vito.be (Franckx Laurent)
Date: Mon, 16 Feb 2015 12:45:47 +0000
Subject: [R] difference between max in summary table and max function
In-Reply-To: <000901d04826$288953b0$799bfb10$@gmail.com>
References: <3FA7C532AA08284AB2ACA7B0AB56EF8715907C70@vitomail4.vito.local>
	<AM2PR05MB075593027DD74FFBEA945DD8A1230@AM2PR05MB0755.eurprd05.prod.outlook.com>
	<000901d04826$288953b0$799bfb10$@gmail.com>
Message-ID: <3FA7C532AA08284AB2ACA7B0AB56EF8715908765@vitomail4.vito.local>

Thanks for the clarification. The basic error on my side was that I had misunderstood the "digits" option in the summary, I had not understood that even integer numbers might end up being "rounded". Problem is solved now.

-----Original Message-----
From: Allen Bingham [mailto:aebingham2 at gmail.com]
Sent: zaterdag 14 februari 2015 8:16
To: 'Martyn Byng'; r-help at r-project.org
Cc: Franckx Laurent
Subject: RE: [R] difference between max in summary table and max function

I thought I'd chime in ... submitting the following:

   ?summary

Provides the following documentation for the default for generalized argument (other than class="data.frame", "factor", or "matrix"):

   ## Default S3 method:
   summary(object, ..., digits = max(3, getOption("digits")-3))

so passing along the object "testrow" w/o a corresponding argument for digits ... defaults to digits=4 (assuming your system has the same default option of digits = 7 that mine does).

... and since later in the documentation it indicates that digits is an:

   integer, used for number formatting with signif()

so noting that all of the values you reported from summary(testrow) all have
4 significant digits (including the Max. of 131500) (excepting the min value of "1"), summary() is doing what it is documented to do.

... sorry for being pedantic --- but doing so to point out how helpful the "?" command can be sometimes.

Hope this helps.

______________________________________
Allen Bingham
Bingham Statistical Consulting
aebingham2 at gmail.com
LinkedIn Profile: www.linkedin.com/pub/allen-bingham/3b/556/325





-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Martyn Byng
Sent: Friday, February 13, 2015 3:15 AM
To: Franckx Laurent; r-help at r-project.org
Subject: Re: [R] difference between max in summary table and max function

Its a formatting thing, try

summary(testrow,digits=20)

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Franckx Laurent
Sent: 13 February 2015 11:00
To: r-help at r-project.org
Subject: [R] difference between max in summary table and max function

Dear all

I have found out that the max in the summary of an integer vector is not always equal to the actual maximum of that vector. For example:


> testrow <- c(1:131509)
> summary(testrow)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
      1   32880   65760   65760   98630  131500
> max(testrow)
[1] 131509

This has occurred both in a Windows and in a Linux environment.

Does this mean that the max value in the summary is only an approximation?

Best regards

Laurent Franckx, PhD
Senior researcher sustainable mobility
VITO NV | Boeretang 200 | 2400 Mol
Tel. ++ 32 14 33 58 22| mob. +32 479 25 59 07 | Skype: laurent.franckx | laurent.franckx at vito.be | Twitter @LaurentFranckx




VITO Disclaimer: http://www.vito.be/e-maildisclaimer

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________________________________________________
This e-mail has been scanned for all viruses by Star.\ _...{{dropped:11}}


From jrkrideau at inbox.com  Mon Feb 16 14:35:36 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 16 Feb 2015 05:35:36 -0800
Subject: [R] Nonlinear integer programming (again)
In-Reply-To: <BY2PR07MB96554FB90F2F88F21A73DD7D2200@BY2PR07MB965.namprd07.prod.outlook.com>
Message-ID: <7C1868FA740.0000014Cjrkrideau@inbox.com>


You may have good reason to distrust the Excel solver :)

See below

John Kane
Kingston ON Canada


> -----Original Message-----
> From: rzwick at ets.org
> Sent: Sat, 14 Feb 2015 23:53:55 +0000
> To: r-help at r-project.org
> Subject: [R] Nonlinear integer programming (again)
>
> Oddly, Excel's Solver will produce a solution to such problems but (1) I
> don't trust it and (2) it cannot handle a large number of constraints.

From IIRC a discussion on the R-help list but which I forgot to save the link.

"The idea that the Excel solver "has a good reputation for being fast and accurate" does not withstand an examination of the Excel solver's ability to solve the StRD nls test problems. Solver's ability is abysmal. 13 of 27 "answers" have zero accurate digits, and three more have fewer than two accurate digits --and this is after tuning the solver to get a good answer.
...
Excel solver does have the virtue that it will always produce an answer, albeit one with zero accurate digits."
Bruce McCullough

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From ronald.koelpin at gmail.com  Mon Feb 16 14:36:43 2015
From: ronald.koelpin at gmail.com (=?UTF-8?B?Um9uYWxkIEvDtmxwaW4=?=)
Date: Mon, 16 Feb 2015 14:36:43 +0100
Subject: [R] Loop over regression results
Message-ID: <54E1F26B.2030400@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Dear all,

I have a problem when trying to present the results of several
regression. Say I have run several regressions on a dataset and saved
the different results (as in the mini example below). I then want to
loop over the regression results in order so save certain values to a
matrix (in order to put them into a paper or presentation).

Aside from the question of how to access certain information stored by
lm() (or printed by summary()) I can't seem to so loop over lm()
objects -- no matter whether they are stored in a vector or a list.
They are always evaluated immediately when called. I tried quote() or
substitute() but that didn't work either as "Objects of type 'symbol'
cannot be indexed."

In Stata I would simply do something like

forvalues k = 1/3 {
 quietly estimates restore mod`k'
// [...]
}

and I am looking for the R equivalent of that syntax.

Kind regard and thanks

RK


attach(iris)
mod1 <- lm(Sepal.Width ~ Petal.Width, data=iris, subset=Species=="setosa")
mod2 <- lm(Sepal.Width ~ Petal.Width, data=iris,
subset=Species=="versicolor")
mod3 <- lm(Sepal.Width ~ Petal.Width, data=iris,
subset=Species=="virginica")

summary(mod1); summary(mod2); summary(mod3)

mat <- matrix(data=NA, nrow=3, ncol=5,
              dimnames=list(1:3, c("Model", "Intercept", "p(T > |T|)",
"Slope", "R^2")))

mods <- c(mod1, mod2, mod3)

for(k in 1:3)
{
    mod <- mods[k]
    mat[2,k] <- as.numeric(coef(mod))[1]
    mat[3,k] <- as.numeric(coef(mod))[1]
}
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJU4fJnAAoJEKdHe5EUSrVeafwIALerOj+rsZTnbSKOUX6vYpr4
Uqsx0X2g+IgJw0KLdyqnlDmOut4wW6sWExtVgiugo/bkN8g5rDotGAl06d0UYRQV
17aLQqQjI6EGXKV9swwlm2DBphtXCIYUCXnDWUoG4Y2wC/4hDnaLbZ9yJFF1GSjn
+aN/PFf1mPPZLvF1NgMmzLdszP76VYzEgcOcEUfbmB7RU/2WEBLeBYJ8+FD1utPJ
cnh03rSc/0dgvphP8FO47Nj7mbqqhKL76a9oQqJSJiZJoCFCGiDIIgzq7vwGWc4T
9apwC/R3ahciB18yYOSMq7ZkVdQ+OpsqDTodnnIIUZjrVIcn9AI+GE0eq1VdLSE=
=x+gM
-----END PGP SIGNATURE-----


From murdoch.duncan at gmail.com  Mon Feb 16 14:40:21 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 16 Feb 2015 08:40:21 -0500
Subject: [R] How do I provide path character string to extdata content?
In-Reply-To: <54E1D65D.4050505@beuth-hochschule.de>
References: <54E1D65D.4050505@beuth-hochschule.de>
Message-ID: <54E1F345.1040206@gmail.com>

On 16/02/2015 6:37 AM, Ulrike Gr?mping wrote:
> Dear helpeRs,
> 
> I have some png files in the inst/extdata directory of a package (e.g.,
> man.png), and I want to provide character strings containing the paths to
> these files; of course, these path strings have to depend on the individual
> installation. So far, I have written a function that - if called - writes
> the correct strings to the global environment, but that is not CRAN
> compatible.

The system.file() function does this.  For example, if your package
named foo contains inst/fig/man.png, you would use
system.file("fig/man.png", package="foo").

> 
> Ideally, I want the package namespace to export these text strings. I have
> played with .onLoad without luck. I do not have a good understanding of
> which hook is for which purpose. How can I go about this?

Rather than exporting the strings, it's easier to export a function that
produces the strings, e.g.

fig <- function(name) system.file(file.path("fig", name), package="foo")

to be called as

fig("man.png")

Duncan Murdoch


From jrkrideau at inbox.com  Mon Feb 16 14:40:43 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 16 Feb 2015 05:40:43 -0800
Subject: [R] Selection/filtering from Data
In-Reply-To: <CADcgpJeDeuNHPSAFrmU5dtu3Xhe+vPmTEUqkVJOMWb-j09yc4A@mail.gmail.com>
Message-ID: <7C23D3F8AE0.0000015Cjrkrideau@inbox.com>

? subset.  You have most of the command already written

John Kane
Kingston ON Canada


> -----Original Message-----
> From: pnsinha68 at gmail.com
> Sent: Mon, 16 Feb 2015 13:31:33 +0530
> To: r-help at r-project.org
> Subject: [R] Selection/filtering from Data
> 
> >From a dataset , I want select age >=36 and income>10000. How to do ?
> parth
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From pdalgd at gmail.com  Mon Feb 16 14:43:02 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 16 Feb 2015 14:43:02 +0100
Subject: [R] P-value from Matching
In-Reply-To: <1424043104310-4703309.post@n4.nabble.com>
References: <1424043104310-4703309.post@n4.nabble.com>
Message-ID: <D156F6C4-3C03-43AC-8A80-759FBEECA3C1@gmail.com>


On 16 Feb 2015, at 00:31 , Rob Wood <robert.wood at adelphigroup.com> wrote:

> Hi all,
> 
> When using the match command from the matching package, the output reports
> the treatment effect, standard error, t-statistic and a p-value. Which test
> is used to generate this p-value, or how us it generated?
> 


I would assume this information to be available via the references on the help page for Match() (sic) in the Matching (sic) package.

Peter D.

> Thanks,
> 
> Rob.
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/P-value-from-Matching-tp4703309.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jrkrideau at inbox.com  Mon Feb 16 14:59:05 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 16 Feb 2015 05:59:05 -0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <CAM5FmSPCz-0h5HbBMFkyMsGg8tCxmOfhiEG_-GTRe9_UyNUAAw@mail.gmail.com>
References: <cam5fmsmaidzgj+d5drptguhbm4v1tr6aljjtdjskqcmfs5w49w@mail.gmail.com>
	<7120dbaad3f.0000064fjrkrideau@inbox.com>
	<5885a05522b.0000053fjrkrideau@inbox.com>
	<4b1afade554.0000031bjrkrideau@inbox.com>
	<4ad1edc7c1f.00000299jrkrideau@inbox.com>
	<cam5fmsm-jucvyy6pzxfsvduzek2+gqg8smti++lxfg3sl0npqg@mail.gmail.com>
	<cam5fmsmnokft_x+2x5r0=wmklsnbzxzk3b6fs7t=u-igxhmj4a@mail.gmail.com>
	<cam5fmspbv2v23ojbj=zsp4hi8onhh-rby2g1utxx-sbkqveifa@mail.gmail.com>
Message-ID: <7C4CE5173E6.000001A3jrkrideau@inbox.com>

Lovely, a much more elegant solution.  

John Kane
Kingston ON Canada

-----Original Message-----
From: hyiltiz at gmail.com
Sent: Mon, 16 Feb 2015 02:30:09 +0800
To: jrkrideau at inbox.com, djmuser at gmail.com
Subject: Re: [R] ggplot2 shifting bars to only overlap in groups

Thanks so much, John and Dennis (who did not respond in the mailing list for some reason). I feel quite obliged to keep you thinking about this.?

I do agree that not using the bar chart with error bars is a better option. And since *condition* is an important ordinal factor for me, it would be much better to have *condition* be positioned at a relative order. Thus, only color coding it as John's latest solution would not be optimal.?

It would have been better with the random data, but with my actual data, it does seem necessary to do a jitter for the *male* since it got clattered in the *west*. Here is the actual data along with the solution based on Dennis' code:

## data

dat1 <- ?structure(list(t = c(1.2454860689532, 0.627186899108052, 0.877176019393987,?

? ? ? ? ? ? ? ? ? ? ? ?1.26720638917869, 1.16906482219006, 0.889738853288831, 0.852034797572489,?

? ? ? ? ? ? ? ? ? ? ? ?1.30007600828822, 1.22896141479778, 0.820236562746995, 0.822197641624559,?

? ? ? ? ? ? ? ? ? ? ? ?1.39529772379005, 1.10479557445486, 0.760017179713665, 0.761340230517717,?

? ? ? ? ? ? ? ? ? ? ? ?1.11132156961026, 1.30042963441715, 0.811425854755042, 0.979421690403349,?

? ? ? ? ? ? ? ? ? ? ? ?1.3297658281305, 1.13377482477157, 0.895243910826397, 0.874181486658082,?

? ? ? ? ? ? ? ? ? ? ? ?1.15728885642541, 1.11121780853125, 0.703348405369258, 0.850897112058048,?

? ? ? ? ? ? ? ? ? ? ? ?1.14260584106012, 1.09383015337114, 0.911388765620587, 0.84622335453925,?

? ? ? ? ? ? ? ? ? ? ? ?1.09847968194129), condition = structure(c(4L, 4L, 4L, 4L, 1L,?

? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 1L,?

? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L), .Label = c("c1",?

? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? "c2", "c2", "c4"), class = "factor"), direction = structure(c(1L,?

? ? ? ? ? ? ? ? ? ? ? ?1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,?

? ? ? ? ? ? ? ? ? ? ? ?1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("up",?

? ? ? ? ? ? ? ? ? ? ? ?"down"), class = "factor"), location = structure(c(2L, 1L, 2L,?

? 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,?

? 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L), .Label = c("east",?

? "west"), class = "factor"), gender = structure(c(2L, 2L, 2L,?

? 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,?

? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("male",?

? "female"), class = "factor"), ci = c(0.0307396796826649, 0.0302954863637637,?

0.0400142340797275, 0.0527186825100342, 0.051675810189946, 0.0368383294010065,?

0.0404823188495183, 0.0526312391852324, 0.0347332720922338, 0.0354587857740343,?

0.0303368490163547, 0.0710445198259065, 0.0229339653012889, 0.0261217906562281,?

0.0285673216713352, 0.0351642108247828, 0.0542657646932069, 0.0566816739316165,?

0.0481239729953889, 0.0434272572423839, 0.0497366325101659, 0.0342004255233646,?

0.0349733697554762, 0.0405364256564456, 0.0478372176424872, 0.0341294939361437,?

0.0424566961614424, 0.0463489561778199, 0.0191707406475215, 0.0501106812754005,?

0.0321562411182704, 0.0218613299095178)), .Names = c("t", "condition",?

"direction", "location", "gender", "ci"), row.names = c(NA, -32L

), class = "data.frame")

pp <- ggplot(dat1, aes(x = condition, y = t, color = gender, linetype = direction)) +

? geom_errorbar(aes(ymin = t - ci, ymax = t + ci),

? ? ? ? ? ? ? ? position = position_dodge(width = 0.6), size = 1,

? ? ? ? ? ? ? ? width = 0.5) +

? geom_point(position = position_dodge(width = 0.6), size = 2.5) +

? facet_wrap(~ location) +

? scale_color_manual(values = c("blue", "darkorange"))+

? theme_bw()+

? scale_y_continuous(breaks=seq(0.6,1.5,0.1))

pp

## EOF

I have also attached the output.?

 Best 
?
========================
He who is worthy to receive his days and nights is worthy to receive* all 
else* from you (and me).
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? The Prophet, Gibran Kahlil

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From dcarlson at tamu.edu  Mon Feb 16 15:51:39 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 16 Feb 2015 14:51:39 +0000
Subject: [R] Loop over regression results
In-Reply-To: <54E1F26B.2030400@gmail.com>
References: <54E1F26B.2030400@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D652272@mb02.ads.tamu.edu>

In R you would want to combine the results into a list. This could be done when you create the regressions or afterwards. To repeat your example using a list:

data(iris)
taxon <- levels(iris$Species)
mod <- lapply(taxon, function (x) lm(Sepal.Width ~ Petal.Width, 
	data=iris, subset=Species==x))
names(mod) <- taxon
lapply(mod, summary)
coeffs <- do.call(rbind, lapply(mod, coef, "[1"))
coeffs
#             (Intercept) Petal.Width
# setosa        3.222051   0.8371922
# versicolor    1.372863   1.0536478
# virginica     1.694773   0.6314052

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ronald K?lpin
Sent: Monday, February 16, 2015 7:37 AM
To: r-help at r-project.org
Subject: [R] Loop over regression results

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Dear all,

I have a problem when trying to present the results of several
regression. Say I have run several regressions on a dataset and saved
the different results (as in the mini example below). I then want to
loop over the regression results in order so save certain values to a
matrix (in order to put them into a paper or presentation).

Aside from the question of how to access certain information stored by
lm() (or printed by summary()) I can't seem to so loop over lm()
objects -- no matter whether they are stored in a vector or a list.
They are always evaluated immediately when called. I tried quote() or
substitute() but that didn't work either as "Objects of type 'symbol'
cannot be indexed."

In Stata I would simply do something like

forvalues k = 1/3 {
 quietly estimates restore mod`k'
// [...]
}

and I am looking for the R equivalent of that syntax.

Kind regard and thanks

RK


attach(iris)
mod1 <- lm(Sepal.Width ~ Petal.Width, data=iris, subset=Species=="setosa")
mod2 <- lm(Sepal.Width ~ Petal.Width, data=iris,
subset=Species=="versicolor")
mod3 <- lm(Sepal.Width ~ Petal.Width, data=iris,
subset=Species=="virginica")

summary(mod1); summary(mod2); summary(mod3)

mat <- matrix(data=NA, nrow=3, ncol=5,
              dimnames=list(1:3, c("Model", "Intercept", "p(T > |T|)",
"Slope", "R^2")))

mods <- c(mod1, mod2, mod3)

for(k in 1:3)
{
    mod <- mods[k]
    mat[2,k] <- as.numeric(coef(mod))[1]
    mat[3,k] <- as.numeric(coef(mod))[1]
}
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJU4fJnAAoJEKdHe5EUSrVeafwIALerOj+rsZTnbSKOUX6vYpr4
Uqsx0X2g+IgJw0KLdyqnlDmOut4wW6sWExtVgiugo/bkN8g5rDotGAl06d0UYRQV
17aLQqQjI6EGXKV9swwlm2DBphtXCIYUCXnDWUoG4Y2wC/4hDnaLbZ9yJFF1GSjn
+aN/PFf1mPPZLvF1NgMmzLdszP76VYzEgcOcEUfbmB7RU/2WEBLeBYJ8+FD1utPJ
cnh03rSc/0dgvphP8FO47Nj7mbqqhKL76a9oQqJSJiZJoCFCGiDIIgzq7vwGWc4T
9apwC/R3ahciB18yYOSMq7ZkVdQ+OpsqDTodnnIIUZjrVIcn9AI+GE0eq1VdLSE=
=x+gM
-----END PGP SIGNATURE-----

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From kmezhoud at gmail.com  Mon Feb 16 16:09:38 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Mon, 16 Feb 2015 15:09:38 +0000
Subject: [R] compute values by condition in DF by rownames
Message-ID: <CALJKBv892JHjw=XW2bVv1sNq1HuCq_83Jzw+_0rFDaRPiL7hDQ@mail.gmail.com>

Hi All,
how to compute only abs(value) > 0.2 of DF

               X2     gbm_tcga     lusc_tcga ucec_tcga_pub
   gbm_tcga  1.000000000  0.1405371906 -0.1028471639
   gbm_tcga  1.000000000  0.0441343447  0.0135680550
   gbm_tcga  1.000000000 -0.2000397119  0.0389718175
    gbm_tcga  1.000000000  0.1456991556  0.0099470445
    lusc_tcga  0.140537191  1.0000000000  0.1330807083
    lusc_tcga  0.044134345  1.0000000000  0.0620247126
    lusc_tcga -0.200039712  1.0000000000 -0.1302395515
     lusc_tcga  0.145699156  1.0000000000  0.0417966700
     ucec_tcga_pub -0.102847164  0.1330807083  1.0000000000
     ucec_tcga_pub  0.013568055  0.0620247126  1.0000000000
     ucec_tcga_pub  0.038971817 -0.1302395515  1.0000000000
     ucec_tcga_pub  0.009947045  0.0417966700  1.0000000000


and return

X2                     gbm_tcga     lusc_tcga ucec_tcga_pub

gbm_tcga               4                   1                  0
lusc_tcga                1                   4                  0
 ucec_tcga_pub       0                   0                   4

Thanks

 Karim

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Feb 16 16:17:13 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 16 Feb 2015 15:17:13 +0000
Subject: [R] Loop over regression results
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D652272@mb02.ads.tamu.edu>
References: <54E1F26B.2030400@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D652272@mb02.ads.tamu.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6522B1@mb02.ads.tamu.edu>

Or for the slopes and t-values:

> do.call(rbind, lapply(mod, function(x) summary(x)[["coefficients"]][2,]))
            Estimate Std. Error  t value     Pr(>|t|)
setosa     0.8371922  0.5049134 1.658091 1.038211e-01
versicolor 1.0536478  0.1712595 6.152348 1.466661e-07
virginica  0.6314052  0.1428938 4.418702 5.647610e-05

David C

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Monday, February 16, 2015 8:52 AM
To: Ronald K?lpin; r-help at r-project.org
Subject: Re: [R] Loop over regression results

In R you would want to combine the results into a list. This could be done when you create the regressions or afterwards. To repeat your example using a list:

data(iris)
taxon <- levels(iris$Species)
mod <- lapply(taxon, function (x) lm(Sepal.Width ~ Petal.Width, 
	data=iris, subset=Species==x))
names(mod) <- taxon
lapply(mod, summary)
coeffs <- do.call(rbind, lapply(mod, coef, "[1"))
coeffs
#             (Intercept) Petal.Width
# setosa        3.222051   0.8371922
# versicolor    1.372863   1.0536478
# virginica     1.694773   0.6314052

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ronald K?lpin
Sent: Monday, February 16, 2015 7:37 AM
To: r-help at r-project.org
Subject: [R] Loop over regression results

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Dear all,

I have a problem when trying to present the results of several
regression. Say I have run several regressions on a dataset and saved
the different results (as in the mini example below). I then want to
loop over the regression results in order so save certain values to a
matrix (in order to put them into a paper or presentation).

Aside from the question of how to access certain information stored by
lm() (or printed by summary()) I can't seem to so loop over lm()
objects -- no matter whether they are stored in a vector or a list.
They are always evaluated immediately when called. I tried quote() or
substitute() but that didn't work either as "Objects of type 'symbol'
cannot be indexed."

In Stata I would simply do something like

forvalues k = 1/3 {
 quietly estimates restore mod`k'
// [...]
}

and I am looking for the R equivalent of that syntax.

Kind regard and thanks

RK


attach(iris)
mod1 <- lm(Sepal.Width ~ Petal.Width, data=iris, subset=Species=="setosa")
mod2 <- lm(Sepal.Width ~ Petal.Width, data=iris,
subset=Species=="versicolor")
mod3 <- lm(Sepal.Width ~ Petal.Width, data=iris,
subset=Species=="virginica")

summary(mod1); summary(mod2); summary(mod3)

mat <- matrix(data=NA, nrow=3, ncol=5,
              dimnames=list(1:3, c("Model", "Intercept", "p(T > |T|)",
"Slope", "R^2")))

mods <- c(mod1, mod2, mod3)

for(k in 1:3)
{
    mod <- mods[k]
    mat[2,k] <- as.numeric(coef(mod))[1]
    mat[3,k] <- as.numeric(coef(mod))[1]
}
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQEcBAEBAgAGBQJU4fJnAAoJEKdHe5EUSrVeafwIALerOj+rsZTnbSKOUX6vYpr4
Uqsx0X2g+IgJw0KLdyqnlDmOut4wW6sWExtVgiugo/bkN8g5rDotGAl06d0UYRQV
17aLQqQjI6EGXKV9swwlm2DBphtXCIYUCXnDWUoG4Y2wC/4hDnaLbZ9yJFF1GSjn
+aN/PFf1mPPZLvF1NgMmzLdszP76VYzEgcOcEUfbmB7RU/2WEBLeBYJ8+FD1utPJ
cnh03rSc/0dgvphP8FO47Nj7mbqqhKL76a9oQqJSJiZJoCFCGiDIIgzq7vwGWc4T
9apwC/R3ahciB18yYOSMq7ZkVdQ+OpsqDTodnnIIUZjrVIcn9AI+GE0eq1VdLSE=
=x+gM
-----END PGP SIGNATURE-----

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Feb 16 16:27:49 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 16 Feb 2015 15:27:49 +0000
Subject: [R] Picking Best Discriminant Function Variables
In-Reply-To: <COL403-EAS374E9EE1BBC62736823F9A483210@phx.gbl>
References: <COL403-EAS374E9EE1BBC62736823F9A483210@phx.gbl>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6522CC@mb02.ads.tamu.edu>

Look at the function stepclass() in package klaR.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David Moskowitz
Sent: Sunday, February 15, 2015 11:34 AM
To: n omranian via R-help
Subject: [R] Picking Best Discriminant Function Variables

Is there a way to have the LDA function give me the best 3 (or 4)  predictor variables.  When I put in all the variables, LDA uses all the variables, but I would like to know what would be the 3 (or 4) best to use out all the available variables and the coefficients for those.




Here is the code I am using for Linear Discriminant Function

library("MASS") 



results <- lda(data$V1 ~ data$V2 + data$V3 + data$V4 + data$V5 + data$V6 + data$V7 + data$V8 + data$V9 + data$V10 + data$V11 + data$V12 + data$V13 + data$V14)



Output:

Coefficients of linear discriminants:
                    LD1                   LD2
data$V2 -0.403399781    0.8717930699
data$V3 0.165254596     0.3053797325
data$V4 -0.369075256    2.3458497486
data$V5 0.154797889     -0.1463807654
data$V6 -0.002163496    -0.0004627565
data$V7 0.618052068     -0.0322128171
data$V8 -1.661191235   -0.4919980543
data$V9 -1.495818440   -1.6309537953
data$V10 0.134092628   -0.3070875776
data$V11 0.355055710    0.2532306865
data$V12 -0.818036073    -1.5156344987
data$V13 -1.157559376    0.0511839665
data$V14 -0.002691206    0.0028529846




So in the above example, I would like the LDA to return to me the 3 best predictors out of the 13 available.


Thank you
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Feb 16 16:37:09 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 16 Feb 2015 15:37:09 +0000
Subject: [R] compute values by condition in DF by rownames
In-Reply-To: <CALJKBv892JHjw=XW2bVv1sNq1HuCq_83Jzw+_0rFDaRPiL7hDQ@mail.gmail.com>
References: <CALJKBv892JHjw=XW2bVv1sNq1HuCq_83Jzw+_0rFDaRPiL7hDQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C204BE@SRVEXCHMBX.precheza.cz>

I named your data frame temp

> aggregate(temp[,-1], list(temp[,1]), function(x) sum(abs(x)>.2))
        Group.1 gbm_tcga lusc_tcga ucec_tcga_pub
1      gbm_tcga        4         1             0
2     lusc_tcga        1         4             0
3 ucec_tcga_pub        0         0             4

Cheers
Petr



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Karim
> Mezhoud
> Sent: Monday, February 16, 2015 4:10 PM
> To: r-help at r-project.org
> Subject: [R] compute values by condition in DF by rownames
>
> Hi All,
> how to compute only abs(value) > 0.2 of DF
>
>                X2     gbm_tcga     lusc_tcga ucec_tcga_pub
>    gbm_tcga  1.000000000  0.1405371906 -0.1028471639
>    gbm_tcga  1.000000000  0.0441343447  0.0135680550
>    gbm_tcga  1.000000000 -0.2000397119  0.0389718175
>     gbm_tcga  1.000000000  0.1456991556  0.0099470445
>     lusc_tcga  0.140537191  1.0000000000  0.1330807083
>     lusc_tcga  0.044134345  1.0000000000  0.0620247126
>     lusc_tcga -0.200039712  1.0000000000 -0.1302395515
>      lusc_tcga  0.145699156  1.0000000000  0.0417966700
>      ucec_tcga_pub -0.102847164  0.1330807083  1.0000000000
>      ucec_tcga_pub  0.013568055  0.0620247126  1.0000000000
>      ucec_tcga_pub  0.038971817 -0.1302395515  1.0000000000
>      ucec_tcga_pub  0.009947045  0.0417966700  1.0000000000
>
>
> and return
>
> X2                     gbm_tcga     lusc_tcga ucec_tcga_pub
>
> gbm_tcga               4                   1                  0
> lusc_tcga                1                   4                  0
>  ucec_tcga_pub       0                   0                   4
>
> Thanks
>
>  Karim
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From thierry.onkelinx at inbo.be  Mon Feb 16 16:43:23 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 16 Feb 2015 16:43:23 +0100
Subject: [R] Loop over regression results
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6522B1@mb02.ads.tamu.edu>
References: <54E1F26B.2030400@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D652272@mb02.ads.tamu.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6522B1@mb02.ads.tamu.edu>
Message-ID: <CAJuCY5yovv9oL235BJXAVBn+ypOTADLbHohRUYP_jCaUSnsjUw@mail.gmail.com>

Or even easier is you use lmList() from the nlme package

library(nlme)
data(iris)
regression.list <- lmList(Sepal.Width ~ Petal.Width | Species, data = iris)
summary(regression.list)
coef(regression.list)


Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-02-16 16:17 GMT+01:00 David L Carlson <dcarlson at tamu.edu>:

> Or for the slopes and t-values:
>
> > do.call(rbind, lapply(mod, function(x) summary(x)[["coefficients"]][2,]))
>             Estimate Std. Error  t value     Pr(>|t|)
> setosa     0.8371922  0.5049134 1.658091 1.038211e-01
> versicolor 1.0536478  0.1712595 6.152348 1.466661e-07
> virginica  0.6314052  0.1428938 4.418702 5.647610e-05
>
> David C
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L
> Carlson
> Sent: Monday, February 16, 2015 8:52 AM
> To: Ronald K?lpin; r-help at r-project.org
> Subject: Re: [R] Loop over regression results
>
> In R you would want to combine the results into a list. This could be done
> when you create the regressions or afterwards. To repeat your example using
> a list:
>
> data(iris)
> taxon <- levels(iris$Species)
> mod <- lapply(taxon, function (x) lm(Sepal.Width ~ Petal.Width,
>         data=iris, subset=Species==x))
> names(mod) <- taxon
> lapply(mod, summary)
> coeffs <- do.call(rbind, lapply(mod, coef, "[1"))
> coeffs
> #             (Intercept) Petal.Width
> # setosa        3.222051   0.8371922
> # versicolor    1.372863   1.0536478
> # virginica     1.694773   0.6314052
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ronald
> K?lpin
> Sent: Monday, February 16, 2015 7:37 AM
> To: r-help at r-project.org
> Subject: [R] Loop over regression results
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Dear all,
>
> I have a problem when trying to present the results of several
> regression. Say I have run several regressions on a dataset and saved
> the different results (as in the mini example below). I then want to
> loop over the regression results in order so save certain values to a
> matrix (in order to put them into a paper or presentation).
>
> Aside from the question of how to access certain information stored by
> lm() (or printed by summary()) I can't seem to so loop over lm()
> objects -- no matter whether they are stored in a vector or a list.
> They are always evaluated immediately when called. I tried quote() or
> substitute() but that didn't work either as "Objects of type 'symbol'
> cannot be indexed."
>
> In Stata I would simply do something like
>
> forvalues k = 1/3 {
>  quietly estimates restore mod`k'
> // [...]
> }
>
> and I am looking for the R equivalent of that syntax.
>
> Kind regard and thanks
>
> RK
>
>
> attach(iris)
> mod1 <- lm(Sepal.Width ~ Petal.Width, data=iris, subset=Species=="setosa")
> mod2 <- lm(Sepal.Width ~ Petal.Width, data=iris,
> subset=Species=="versicolor")
> mod3 <- lm(Sepal.Width ~ Petal.Width, data=iris,
> subset=Species=="virginica")
>
> summary(mod1); summary(mod2); summary(mod3)
>
> mat <- matrix(data=NA, nrow=3, ncol=5,
>               dimnames=list(1:3, c("Model", "Intercept", "p(T > |T|)",
> "Slope", "R^2")))
>
> mods <- c(mod1, mod2, mod3)
>
> for(k in 1:3)
> {
>     mod <- mods[k]
>     mat[2,k] <- as.numeric(coef(mod))[1]
>     mat[3,k] <- as.numeric(coef(mod))[1]
> }
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1
>
> iQEcBAEBAgAGBQJU4fJnAAoJEKdHe5EUSrVeafwIALerOj+rsZTnbSKOUX6vYpr4
> Uqsx0X2g+IgJw0KLdyqnlDmOut4wW6sWExtVgiugo/bkN8g5rDotGAl06d0UYRQV
> 17aLQqQjI6EGXKV9swwlm2DBphtXCIYUCXnDWUoG4Y2wC/4hDnaLbZ9yJFF1GSjn
> +aN/PFf1mPPZLvF1NgMmzLdszP76VYzEgcOcEUfbmB7RU/2WEBLeBYJ8+FD1utPJ
> cnh03rSc/0dgvphP8FO47Nj7mbqqhKL76a9oQqJSJiZJoCFCGiDIIgzq7vwGWc4T
> 9apwC/R3ahciB18yYOSMq7ZkVdQ+OpsqDTodnnIIUZjrVIcn9AI+GE0eq1VdLSE=
> =x+gM
> -----END PGP SIGNATURE-----
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tring at gvdnet.dk  Mon Feb 16 17:43:51 2015
From: tring at gvdnet.dk (Troels Ring)
Date: Mon, 16 Feb 2015 17:43:51 +0100
Subject: [R] list of  list
Message-ID: <54E21E47.9080702@gvdnet.dk>

Dear friends - this is simple I know but I can figure it out without 
your help.
I have for each of 2195 instances 10 variables measured at specific 
times from 6 to several hundred, so if I just take one of the instances, 
I can make a list of the 10 variables together with their variable 
times. But when I have 2195 such instances I cannot get it how to make a 
list of these individual lists

As a toy example demonstrating mercilessly my problem, if ASL[j] is mean 
to take the list of here 5 entries made in RES[[i]] and I write this 
(ignoring the times) it certainly doesn't work
ASL <- list()
RES <- list()
for (j in 1:5){
for (i in 1:5)
ASL[[j]] <-
  RES[[i]] <- i^j }

All best wishes
Troels Ring
Aalborg, Denmark


From hyiltiz at gmail.com  Mon Feb 16 18:20:06 2015
From: hyiltiz at gmail.com (=?UTF-8?Q?H=C3=B6rmetjan_Yiltiz?=)
Date: Tue, 17 Feb 2015 01:20:06 +0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <7C4CE5173E6.000001A3jrkrideau@inbox.com>
References: <cam5fmsmaidzgj+d5drptguhbm4v1tr6aljjtdjskqcmfs5w49w@mail.gmail.com>
	<7120dbaad3f.0000064fjrkrideau@inbox.com>
	<5885a05522b.0000053fjrkrideau@inbox.com>
	<4b1afade554.0000031bjrkrideau@inbox.com>
	<4ad1edc7c1f.00000299jrkrideau@inbox.com>
	<cam5fmsm-jucvyy6pzxfsvduzek2+gqg8smti++lxfg3sl0npqg@mail.gmail.com>
	<cam5fmsmnokft_x+2x5r0=wmklsnbzxzk3b6fs7t=u-igxhmj4a@mail.gmail.com>
	<cam5fmspbv2v23ojbj=zsp4hi8onhh-rby2g1utxx-sbkqveifa@mail.gmail.com>
	<CAM5FmSPCz-0h5HbBMFkyMsGg8tCxmOfhiEG_-GTRe9_UyNUAAw@mail.gmail.com>
	<7C4CE5173E6.000001A3jrkrideau@inbox.com>
Message-ID: <CAM5FmSN5kxQXf2gSqdYg2CFAQmpBcwSaUy6qDWOJ4K634AbXhA@mail.gmail.com>

Again, I come to think about violin plots which is more informative than
the error bars. But for some reason, the violin in the *west* became way
too slimmer than the *east* one, though the density plot tells me that is
not necessarily the case. I am still trying to figure that out, and that
would be even more irrelevant as long as *shifting bars in gorups*. So
maybe I will come up with another post later when I got the solution.

???
========================
He who is worthy to receive his days and nights is worthy to receive* all
else* from you (and me).
                                                 The Prophet, Gibran Kahlil


On Mon, Feb 16, 2015 at 9:59 PM, John Kane <jrkrideau at inbox.com> wrote:

> Lovely, a much more elegant solution.
>
> John Kane
> Kingston ON Canada
>
> -----Original Message-----
> From: hyiltiz at gmail.com
> Sent: Mon, 16 Feb 2015 02:30:09 +0800
> To: jrkrideau at inbox.com, djmuser at gmail.com
> Subject: Re: [R] ggplot2 shifting bars to only overlap in groups
>
> Thanks so much, John and Dennis (who did not respond in the mailing list
> for some reason). I feel quite obliged to keep you thinking about this.
>
> I do agree that not using the bar chart with error bars is a better
> option. And since *condition* is an important ordinal factor for me, it
> would be much better to have *condition* be positioned at a relative order.
> Thus, only color coding it as John's latest solution would not be optimal.
>
> It would have been better with the random data, but with my actual data,
> it does seem necessary to do a jitter for the *male* since it got clattered
> in the *west*. Here is the actual data along with the solution based on
> Dennis' code:
>
> ## data
>
> dat1 <-  structure(list(t = c(1.2454860689532, 0.627186899108052,
> 0.877176019393987,
>
>                        1.26720638917869, 1.16906482219006,
> 0.889738853288831, 0.852034797572489,
>
>                        1.30007600828822, 1.22896141479778,
> 0.820236562746995, 0.822197641624559,
>
>                        1.39529772379005, 1.10479557445486,
> 0.760017179713665, 0.761340230517717,
>
>                        1.11132156961026, 1.30042963441715,
> 0.811425854755042, 0.979421690403349,
>
>                        1.3297658281305, 1.13377482477157,
> 0.895243910826397, 0.874181486658082,
>
>                        1.15728885642541, 1.11121780853125,
> 0.703348405369258, 0.850897112058048,
>
>                        1.14260584106012, 1.09383015337114,
> 0.911388765620587, 0.84622335453925,
>
>                        1.09847968194129), condition = structure(c(4L, 4L,
> 4L, 4L, 1L,
>
>                                                                   1L, 1L,
> 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 1L,
>
>                                                                   1L, 1L,
> 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L), .Label = c("c1",
>
>                                                                   "c2",
> "c2", "c4"), class = "factor"), direction = structure(c(1L,
>
>                        1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L,
> 2L, 2L, 1L,
>
>                        1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L,
> 2L, 2L), .Label = c("up",
>
>                        "down"), class = "factor"), location =
> structure(c(2L, 1L, 2L,
>
>   1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>
>   1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L), .Label = c("east",
>
>   "west"), class = "factor"), gender = structure(c(2L, 2L, 2L,
>
>   2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
>
>   1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("male",
>
>   "female"), class = "factor"), ci = c(0.0307396796826649,
> 0.0302954863637637,
>
> 0.0400142340797275, 0.0527186825100342, 0.051675810189946,
> 0.0368383294010065,
>
> 0.0404823188495183, 0.0526312391852324, 0.0347332720922338,
> 0.0354587857740343,
>
> 0.0303368490163547, 0.0710445198259065, 0.0229339653012889,
> 0.0261217906562281,
>
> 0.0285673216713352, 0.0351642108247828, 0.0542657646932069,
> 0.0566816739316165,
>
> 0.0481239729953889, 0.0434272572423839, 0.0497366325101659,
> 0.0342004255233646,
>
> 0.0349733697554762, 0.0405364256564456, 0.0478372176424872,
> 0.0341294939361437,
>
> 0.0424566961614424, 0.0463489561778199, 0.0191707406475215,
> 0.0501106812754005,
>
> 0.0321562411182704, 0.0218613299095178)), .Names = c("t", "condition",
>
> "direction", "location", "gender", "ci"), row.names = c(NA, -32L
>
> ), class = "data.frame")
>
> pp <- ggplot(dat1, aes(x = condition, y = t, color = gender, linetype =
> direction)) +
>
>   geom_errorbar(aes(ymin = t - ci, ymax = t + ci),
>
>                 position = position_dodge(width = 0.6), size = 1,
>
>                 width = 0.5) +
>
>   geom_point(position = position_dodge(width = 0.6), size = 2.5) +
>
>   facet_wrap(~ location) +
>
>   scale_color_manual(values = c("blue", "darkorange"))+
>
>   theme_bw()+
>
>   scale_y_continuous(breaks=seq(0.6,1.5,0.1))
>
> pp
>
> ## EOF
>
> I have also attached the output.
>
>  Best
> ?
> ========================
> He who is worthy to receive his days and nights is worthy to receive* all
> else* from you (and me).
>                                                  The Prophet, Gibran Kahlil
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> Check it out at http://www.inbox.com/earth
>
>
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Feb 16 18:28:09 2015
From: jholtman at gmail.com (jim holtman)
Date: Mon, 16 Feb 2015 12:28:09 -0500
Subject: [R] list of list
In-Reply-To: <54E21E47.9080702@gvdnet.dk>
References: <54E21E47.9080702@gvdnet.dk>
Message-ID: <CAAxdm-5z1L3QJjxPTO3UrETRW5Rgh=1BgW9wPM_n5zZ9PsK8LQ@mail.gmail.com>

Is this what you mean:

ASL <- list()
for (j in 1:5){
    RES <- list()
    for (i in 1:5) RES[[i]] <- i ^ j  # create list
    ASL[[j]] <- RES  # store 'list of list'
}


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Feb 16, 2015 at 11:43 AM, Troels Ring <tring at gvdnet.dk> wrote:

> Dear friends - this is simple I know but I can figure it out without your
> help.
> I have for each of 2195 instances 10 variables measured at specific times
> from 6 to several hundred, so if I just take one of the instances, I can
> make a list of the 10 variables together with their variable times. But
> when I have 2195 such instances I cannot get it how to make a list of these
> individual lists
>
> As a toy example demonstrating mercilessly my problem, if ASL[j] is mean
> to take the list of here 5 entries made in RES[[i]] and I write this
> (ignoring the times) it certainly doesn't work
> ASL <- list()
> RES <- list()
> for (j in 1:5){
> for (i in 1:5)
> ASL[[j]] <-
>  RES[[i]] <- i^j }
>
> All best wishes
> Troels Ring
> Aalborg, Denmark
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Feb 16 18:28:55 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 16 Feb 2015 18:28:55 +0100
Subject: [R] list of  list
In-Reply-To: <54E21E47.9080702@gvdnet.dk>
References: <54E21E47.9080702@gvdnet.dk>
Message-ID: <AEF562ED-2224-4DBE-A6EB-39C7CEBAC3F1@gmail.com>


On 16 Feb 2015, at 17:43 , Troels Ring <tring at gvdnet.dk> wrote:

> Dear friends - this is simple I know but I can figure it out without your help.
> I have for each of 2195 instances 10 variables measured at specific times from 6 to several hundred, so if I just take one of the instances, I can make a list of the 10 variables together with their variable times. But when I have 2195 such instances I cannot get it how to make a list of these individual lists
> 
> As a toy example demonstrating mercilessly my problem, if ASL[j] is mean to take the list of here 5 entries made in RES[[i]] and I write this (ignoring the times) it certainly doesn't work
> ASL <- list()
> RES <- list()
> for (j in 1:5){
> for (i in 1:5)
> ASL[[j]] <-
> RES[[i]] <- i^j }

Your description doesn't quite make sense to me, but if you really want ASL to be a list of lists, you want each member to be a list and the (i,j)th item accessed as ASL[[i]][[j]]. So I'd expect to see something like

for (j .... {
	ASL[[j]] <- list()
	for (i ....
		ASL[[j]][[|]] <- ....
}

You also really don't want to start with an empty list and extend it on every iteration. If you need an n-element list, preallocate it using vector(n, mode="list").

If the above doesn't make sense, rephrase the question....


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Mon Feb 16 18:46:02 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 16 Feb 2015 09:46:02 -0800
Subject: [R] list of  list
In-Reply-To: <54E21E47.9080702@gvdnet.dk>
References: <54E21E47.9080702@gvdnet.dk>
Message-ID: <C681CEBF-D4B6-47E5-85C6-28B529444445@dcn.davis.CA.us>

You have two named objects when your goal is to have one that contains five others.

ASL <- vector( "list", 5 )
for (j in 1:5){
  ASL[[j]] <- vector( "list", 5 )
  for (i in 1:5) {
    ASL[[j]][[i]] <- i^j 
  }
}

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 16, 2015 8:43:51 AM PST, Troels Ring <tring at gvdnet.dk> wrote:
>Dear friends - this is simple I know but I can figure it out without 
>your help.
>I have for each of 2195 instances 10 variables measured at specific 
>times from 6 to several hundred, so if I just take one of the
>instances, 
>I can make a list of the 10 variables together with their variable 
>times. But when I have 2195 such instances I cannot get it how to make
>a 
>list of these individual lists
>
>As a toy example demonstrating mercilessly my problem, if ASL[j] is
>mean 
>to take the list of here 5 entries made in RES[[i]] and I write this 
>(ignoring the times) it certainly doesn't work
>ASL <- list()
>RES <- list()
>for (j in 1:5){
>for (i in 1:5)
>ASL[[j]] <-
>  RES[[i]] <- i^j }
>
>All best wishes
>Troels Ring
>Aalborg, Denmark
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From robert.wood at adelphigroup.com  Mon Feb 16 14:47:20 2015
From: robert.wood at adelphigroup.com (Rob Wood)
Date: Mon, 16 Feb 2015 05:47:20 -0800 (PST)
Subject: [R] P-value from Matching
In-Reply-To: <D156F6C4-3C03-43AC-8A80-759FBEECA3C1@gmail.com>
References: <1424043104310-4703309.post@n4.nabble.com>
	<D156F6C4-3C03-43AC-8A80-759FBEECA3C1@gmail.com>
Message-ID: <1424094440234-4703345.post@n4.nabble.com>

Hi Peter,

That was my first port of call before I posted this thread. Unfortunately,
it does not seem to explicitly state which test is used or how the p-value
is calculated.

Thanks,

Rob.



--
View this message in context: http://r.789695.n4.nabble.com/P-value-from-Matching-tp4703309p4703345.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Mon Feb 16 14:24:19 2015
From: js.huang at protective.com (JS Huang)
Date: Mon, 16 Feb 2015 05:24:19 -0800 (PST)
Subject: [R] sd, mean with a frequency distribution matrix
In-Reply-To: <1423907311273-4703259.post@n4.nabble.com>
References: <1423837352778-4703218.post@n4.nabble.com>
	<1423843168900-4703220.post@n4.nabble.com>
	<1423862549747-4703231.post@n4.nabble.com>
	<1423907311273-4703259.post@n4.nabble.com>
Message-ID: <1424093059993-4703338.post@n4.nabble.com>

Hi,

  For the second one,
sqrt((sum(p[,1]^2*p[,2])-(sum(p[,1]*p[,2]))^2/sum(p[,2]))/(sum(p[,2])-1)),
please refer to the following link for an example to explain how it works.

http://www.lboro.ac.uk/media/wwwlboroacuk/content/mlsc/downloads/var_stand_deviat_group.pdf

  For the first one:
sd(unlist(sapply(1:dim(p)[1],function(i)rep(p[i,1],p[i,2])))).\:

sapply(1:dim(p)[1],function(i)rep(p[i,1],p[i,2])) to get all in the first
column of the matrix repeated the number of times in the second column.

After that, make the resulting list to become a vector so that it can be
executed with sd function.

  Here is some illustrative example.
> p
     [,1] [,2]
[1,]   10    3
[2,]   20    4
[3,]   30    5
> sapply(1:dim(p)[1],function(i)rep(p[i,1],p[i,2]))
[[1]]
[1] 10 10 10

[[2]]
[1] 20 20 20 20

[[3]]
[1] 30 30 30 30 30
> unlist(sapply(1:dim(p)[1],function(i)rep(p[i,1],p[i,2])))
 [1] 10 10 10 20 20 20 20 30 30 30 30 30
> sd(unlist(sapply(1:dim(p)[1],function(i)rep(p[i,1],p[i,2]))))
[1] 8.348471




--
View this message in context: http://r.789695.n4.nabble.com/sd-mean-with-a-frequency-distribution-matrix-tp4703218p4703338.html
Sent from the R help mailing list archive at Nabble.com.


From a.mosnier at gmail.com  Mon Feb 16 19:13:43 2015
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Mon, 16 Feb 2015 13:13:43 -0500
Subject: [R] Comparing gam models fitted using ti()
Message-ID: <CANkFkEe7aGZNmZVB0HnoMPdcuAJdXW1x9pQpEk6KKSHWRLdNrA@mail.gmail.com>

Dear R-Help list,

I want to compare gam models including interaction with simpler models.
For interaction models, I used gam(Y~ti(X1) + ti(X2) + ti(X1,X2))
removing the interaction, the models end as Y~ti(X1) + ti(X2)

How those models compare with models with the form Y ~ s(X1) + s(X2)

In my case, the former (i.e. ti() ) have a better AIC value than those with
s().

Should I keep the ti() form or use only the s() form when I have no
interaction ?

Thanks for your help !

Arnaud

	[[alternative HTML version deleted]]


From tring at gvdnet.dk  Mon Feb 16 19:45:12 2015
From: tring at gvdnet.dk (Troels Ring)
Date: Mon, 16 Feb 2015 19:45:12 +0100
Subject: [R] list of  list
In-Reply-To: <C681CEBF-D4B6-47E5-85C6-28B529444445@dcn.davis.CA.us>
References: <54E21E47.9080702@gvdnet.dk>
	<C681CEBF-D4B6-47E5-85C6-28B529444445@dcn.davis.CA.us>
Message-ID: <54E23AB8.40805@gvdnet.dk>

Thanks to Jim, Peter and Jeff who all saw the solution!
Best wishes
Troels

Den 16-02-2015 kl. 18:46 skrev Jeff Newmiller:
> You have two named objects when your goal is to have one that contains five others.
>
> ASL <- vector( "list", 5 )
> for (j in 1:5){
>    ASL[[j]] <- vector( "list", 5 )
>    for (i in 1:5) {
>      ASL[[j]][[i]] <- i^j
>    }
> }
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On February 16, 2015 8:43:51 AM PST, Troels Ring <tring at gvdnet.dk> wrote:
>> Dear friends - this is simple I know but I can figure it out without
>> your help.
>> I have for each of 2195 instances 10 variables measured at specific
>> times from 6 to several hundred, so if I just take one of the
>> instances,
>> I can make a list of the 10 variables together with their variable
>> times. But when I have 2195 such instances I cannot get it how to make
>> a
>> list of these individual lists
>>
>> As a toy example demonstrating mercilessly my problem, if ASL[j] is
>> mean
>> to take the list of here 5 entries made in RES[[i]] and I write this
>> (ignoring the times) it certainly doesn't work
>> ASL <- list()
>> RES <- list()
>> for (j in 1:5){
>> for (i in 1:5)
>> ASL[[j]] <-
>>   RES[[i]] <- i^j }
>>
>> All best wishes
>> Troels Ring
>> Aalborg, Denmark
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gunter.berton at gene.com  Mon Feb 16 19:54:56 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 16 Feb 2015 10:54:56 -0800
Subject: [R] Comparing gam models fitted using ti()
In-Reply-To: <CANkFkEe7aGZNmZVB0HnoMPdcuAJdXW1x9pQpEk6KKSHWRLdNrA@mail.gmail.com>
References: <CANkFkEe7aGZNmZVB0HnoMPdcuAJdXW1x9pQpEk6KKSHWRLdNrA@mail.gmail.com>
Message-ID: <CACk-te3RG5HOgE0be6WXnpjmPDTxRMBNzT=q7zS+6=xSEnvSgA@mail.gmail.com>

I wonder if this might be better asked on a statistical list -- e.g.
stats.stackexchange.com
 -- as this seems to involve complex statistical model comparison
issues, which are normally OT here.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Feb 16, 2015 at 10:13 AM, Arnaud Mosnier <a.mosnier at gmail.com> wrote:
> Dear R-Help list,
>
> I want to compare gam models including interaction with simpler models.
> For interaction models, I used gam(Y~ti(X1) + ti(X2) + ti(X1,X2))
> removing the interaction, the models end as Y~ti(X1) + ti(X2)
>
> How those models compare with models with the form Y ~ s(X1) + s(X2)
>
> In my case, the former (i.e. ti() ) have a better AIC value than those with
> s().
>
> Should I keep the ti() form or use only the s() form when I have no
> interaction ?
>
> Thanks for your help !
>
> Arnaud
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Feb 16 20:17:21 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 16 Feb 2015 11:17:21 -0800
Subject: [R] list of list
In-Reply-To: <C681CEBF-D4B6-47E5-85C6-28B529444445@dcn.davis.CA.us>
References: <54E21E47.9080702@gvdnet.dk>
	<C681CEBF-D4B6-47E5-85C6-28B529444445@dcn.davis.CA.us>
Message-ID: <CAF8bMcZNDgtCjsuoxDUdq+P6kaGCex80QXXneq5K7oS8G8kKDQ@mail.gmail.com>

You can let lapply() do the preallocation and the looping for you with

   ASL <- lapply(1:5, function(j) lapply(1:5, function(i) i^j))

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Feb 16, 2015 at 9:46 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You have two named objects when your goal is to have one that contains
> five others.
>
> ASL <- vector( "list", 5 )
> for (j in 1:5){
>   ASL[[j]] <- vector( "list", 5 )
>   for (i in 1:5) {
>     ASL[[j]][[i]] <- i^j
>   }
> }
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On February 16, 2015 8:43:51 AM PST, Troels Ring <tring at gvdnet.dk> wrote:
> >Dear friends - this is simple I know but I can figure it out without
> >your help.
> >I have for each of 2195 instances 10 variables measured at specific
> >times from 6 to several hundred, so if I just take one of the
> >instances,
> >I can make a list of the 10 variables together with their variable
> >times. But when I have 2195 such instances I cannot get it how to make
> >a
> >list of these individual lists
> >
> >As a toy example demonstrating mercilessly my problem, if ASL[j] is
> >mean
> >to take the list of here 5 entries made in RES[[i]] and I write this
> >(ignoring the times) it certainly doesn't work
> >ASL <- list()
> >RES <- list()
> >for (j in 1:5){
> >for (i in 1:5)
> >ASL[[j]] <-
> >  RES[[i]] <- i^j }
> >
> >All best wishes
> >Troels Ring
> >Aalborg, Denmark
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cute_loomaa at hotmail.com  Mon Feb 16 23:10:06 2015
From: cute_loomaa at hotmail.com (hms Dreams)
Date: Tue, 17 Feb 2015 01:10:06 +0300
Subject: [R] method of moments estimation
Message-ID: <DUB128-W49A2A53842E4AA8E51495B962E0@phx.gbl>

Hi,
I'm trying to use method of moments estimation to estimate 3 unkown paramters delta,k and alpha.
so I had system of 3 non linear equations:
 
1)  [delta^(1/alpha) *gamma (k-(1/alpha)) ]/gamma(k) = xbar
2)  [delta^(2/alpha) *gamma (k-(2/alpha)) ]/gamma(k) = 1/n *sum (x^2)
3)   [delta^(3/alpha) *gamma (k-(3/alpha)) ]/gamma(k) = 1/n *sum (x^3)
where gamma is a gamma function and  n is the sample size 

 How can I solve these system , Is there a package on R can give me MOM ??
 
Thank you ,
Sara 

 
 		 	   		  
	[[alternative HTML version deleted]]


From constanze_fay at yahoo.de  Mon Feb 16 23:25:25 2015
From: constanze_fay at yahoo.de (fay constanze)
Date: Mon, 16 Feb 2015 22:25:25 +0000 (UTC)
Subject: [R] plm function & plm r.squared error
Message-ID: <247687887.8573055.1424125525621.JavaMail.yahoo@mail.yahoo.com>

?
DearGiovanni,Congratulationsfor the?truly helpful?plm package! Being new to R, I have a problem with the plm function for financial markets timeseries data: After having defined a large, unbalanced panel pdata.frame (https://www.dropbox.com/s/2r9t1cu9v65gobk/Database_CN_2004.csv?dl=0)and running a simple OLS model of two variables regressing company returns(Perf) on index returns (PerfIn)synch <-plm (Perf ~ PerfIn , data=pCN04, na.action = na.omit, index=c("Unit", "Week"), model="pooling") I keepreceiving the following error:Error in model.matrix.pFormula(formula, data, rhs =1, model = model,? : ? NA in theindividual index variableIn addition:Warning message:In `[.data.frame`(index, as.numeric(rownames(mf)),) :? NAsintroduced by coercion
There aremuch more NAs in y (Perf) than in x (PerfIn) and I have tried to get rid ofthem with na.omit. Another error I have is with the same model for the r.squaredfunction r.squared(pCN04,model=NULL, Perf ~ PerfIn, type= "ess")Error in tss.default(object, model = model) : ??unused argument (model = model)In addition: Warning message:In mean.default(haty) : argument is not numeric or logical: returning NAMany thanks in advance,your help is very precious to me!Constanze



	[[alternative HTML version deleted]]


From zilefacelvis at yahoo.com  Tue Feb 17 04:53:57 2015
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Tue, 17 Feb 2015 03:53:57 +0000 (UTC)
Subject: [R] split dataframe to several dataframes in R
Message-ID: <775901483.4092478.1424145237717.JavaMail.yahoo@mail.yahoo.com>

Hi All,I have a dataframe called 'means' as shown below:iris1.csv <- iris
iris2.csv <- iris
names <- c("iris1.csv", "iris2.csv")
dat <- mget(names)
lst4 <- lapply(dat, function(x) apply(x[,-5], 2, mean))

# Build the new data frame
means <- as.data.frame(do.call(rbind, lst4))
means$source <- names(lst4)
means
#           Sepal.Length Sepal.Width Petal.Length Petal.Width       isv    source
# iris1.csv     5.843333    3.057333        3.758    1.199333 0.3333333 iris1.csv
# iris2.csv     5.843333    3.057333        3.758    1.199333 0.3333333 iris2.csvQUESTION: How can I split 'means' such that there are two files (dataframes) on my workspace:datframe 1#           Sepal.Length Sepal.Width Petal.Length Petal.Width       isv    
# iris1.csv     5.843333    3.057333        3.758    1.199333 0.3333333dataframe 2:#           Sepal.Length Sepal.Width Petal.Length Petal.Width       isv# iris2.csv     5.843333    3.057333        3.758    1.199333 0.3333333
Many thanks,Asong.
	[[alternative HTML version deleted]]


From putra_autumn86 at yahoo.com  Tue Feb 17 00:59:27 2015
From: putra_autumn86 at yahoo.com (smart hendsome)
Date: Mon, 16 Feb 2015 23:59:27 +0000 (UTC)
Subject: [R] Fitting gamma distribution
Message-ID: <1210973251.4759434.1424131167387.JavaMail.yahoo@mail.yahoo.com>

I'm very new to r-programming. I have rainfall data. I have tried to fit gamma into my data but there is error. Anyone can help me please.
My rainfall data as I uploaded. When I try run the coding:
library(MASS)

KLT1<-read.csv('C:/Users/User/Dropbox/PhD Materials/Coding_PhD_Thesis/Kelantan_Average/K1.csv')

KLT<-KLT1$Amount
fd_g <- fitdistr(KLT, "gamma")
Error in stats::optim(x = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,? : 
? initial value in 'vmmin' is not finite
Anyone can help me? Thanks.




From r.turner at auckland.ac.nz  Tue Feb 17 06:39:12 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 17 Feb 2015 18:39:12 +1300
Subject: [R] Fitting gamma distribution
In-Reply-To: <1210973251.4759434.1424131167387.JavaMail.yahoo@mail.yahoo.com>
References: <1210973251.4759434.1424131167387.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <54E2D400.1010800@auckland.ac.nz>

On 17/02/15 12:59, smart hendsome wrote:
> I'm very new to r-programming. I have rainfall data. I have tried to fit gamma into my data but there is error. Anyone can help me please.
> My rainfall data as I uploaded. When I try run the coding:
> library(MASS)
>
> KLT1<-read.csv('C:/Users/User/Dropbox/PhD Materials/Coding_PhD_Thesis/Kelantan_Average/K1.csv')
>
> KLT<-KLT1$Amount
> fd_g <- fitdistr(KLT, "gamma")
> Error in stats::optim(x = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  :
>    initial value in 'vmmin' is not finite
> Anyone can help me? Thanks.

No.  No one can help.  Not unless you provided a self-contained 
reproducible example as the posting guide requests.

cheers,

Rolf Turner

P. S. I am not sure, but the error may be indicating that your data
begin with a long string of zeros.  (In which case fitting a gamma 
distribution is simply idiotic.)  Rainfall data often contain many 
zeroes.  (There are, contrary to popular belief, many dry days.)

What you *may* want to fit is a mixture of a gamma distribution and a 
point-mass ("atom") at 0.

R. T.

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From aravindjayaramanagri at gmail.com  Tue Feb 17 05:49:55 2015
From: aravindjayaramanagri at gmail.com (Aravind Jayaraman)
Date: Tue, 17 Feb 2015 10:19:55 +0530
Subject: [R] split dataframe to several dataframes in R
In-Reply-To: <775901483.4092478.1424145237717.JavaMail.yahoo@mail.yahoo.com>
References: <775901483.4092478.1424145237717.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+0rMgnvX7mTSLiOjeJ-PLFSqY+_CEu-+z6+HznZVEvUi5Un0A@mail.gmail.com>

Hi,

I think you need not split the data.frame to get the desired result.
You can work with your list lst4 itself.

#Convert the vectors in the list to data.frames.
lst4 <- lapply(lst4, function(x) {as.data.frame(t(iris1.csv))})
#Get the data.frames in the list to the global environment
list2env(lst4 ,.GlobalEnv)

Regards

On 17 February 2015 at 09:23, Zilefac Elvis via R-help
<r-help at r-project.org> wrote:
> Hi All,I have a dataframe called 'means' as shown below:iris1.csv <- iris
> iris2.csv <- iris
> names <- c("iris1.csv", "iris2.csv")
> dat <- mget(names)
> lst4 <- lapply(dat, function(x) apply(x[,-5], 2, mean))
>
> # Build the new data frame
> means <- as.data.frame(do.call(rbind, lst4))
> means$source <- names(lst4)
> means
> #           Sepal.Length Sepal.Width Petal.Length Petal.Width       isv    source
> # iris1.csv     5.843333    3.057333        3.758    1.199333 0.3333333 iris1.csv
> # iris2.csv     5.843333    3.057333        3.758    1.199333 0.3333333 iris2.csvQUESTION: How can I split 'means' such that there are two files (dataframes) on my workspace:datframe 1#           Sepal.Length Sepal.Width Petal.Length Petal.Width       isv
> # iris1.csv     5.843333    3.057333        3.758    1.199333 0.3333333dataframe 2:#           Sepal.Length Sepal.Width Petal.Length Petal.Width       isv# iris2.csv     5.843333    3.057333        3.758    1.199333 0.3333333
> Many thanks,Asong.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
J.Aravind
Scientist
Germplasm Conservation Division
ICAR-National Bureau of Plant Genetic Resources
New Delhi - 110 012


From js.huang at protective.com  Tue Feb 17 05:30:11 2015
From: js.huang at protective.com (JS Huang)
Date: Mon, 16 Feb 2015 20:30:11 -0800 (PST)
Subject: [R] compute values by condition in DF by rownames
In-Reply-To: <CALJKBv892JHjw=XW2bVv1sNq1HuCq_83Jzw+_0rFDaRPiL7hDQ@mail.gmail.com>
References: <CALJKBv892JHjw=XW2bVv1sNq1HuCq_83Jzw+_0rFDaRPiL7hDQ@mail.gmail.com>
Message-ID: <1424147411612-4703374.post@n4.nabble.com>

Hi,

  I hope that someone can provide a better way to implement it.  This is my
implementation.

> data
              X2     gbm_tcga   lusc_tcga ucec_tcga_pub
1       gbm_tcga  1.000000000  0.14053719  -0.102847164
2       gbm_tcga  1.000000000  0.04413434   0.013568055
3       gbm_tcga  1.000000000 -0.20003971   0.038971817
4       gbm_tcga  1.000000000  0.14569916   0.009947045
5      lusc_tcga  0.140537191  1.00000000   0.133080708
6      lusc_tcga  0.044134345  1.00000000   0.062024713
7      lusc_tcga -0.200039712  1.00000000  -0.130239551
8      lusc_tcga  0.145699156  1.00000000   0.041796670
9  ucec_tcga_pub -0.102847164  0.13308071   1.000000000
10 ucec_tcga_pub  0.013568055  0.06202471   1.000000000
11 ucec_tcga_pub  0.038971817 -0.13023955   1.000000000
12 ucec_tcga_pub  0.009947045  0.04179667   1.000000000
> test
function(x)
{
  tempMatrix <- matrix(0,nrow=3,ncol=3)
  lev <- levels(x$X2)
  for (i in 1:length(lev))
  {
    tempMatrix[i,1] = sum(ifelse(abs(x[x$X2==lev[i],2])>0.2,1,0))
    tempMatrix[i,2] = sum(ifelse(abs(x[x$X2==lev[i],3])>0.2,1,0))
    tempMatrix[i,3] = sum(ifelse(abs(x[x$X2==lev[i],4])>0.2,1,0))
  }
  result <- data.frame(lev,tempMatrix)
  names(result) <- c("X2","gbm_tcga","lusc_tcga","tcga_pub")
  return(result)
}
> test(data)
             X2 gbm_tcga lusc_tcga tcga_pub
1      gbm_tcga        4         1        0
2     lusc_tcga        1         4        0
3 ucec_tcga_pub        0         0        4
> 



--
View this message in context: http://r.789695.n4.nabble.com/compute-values-by-condition-in-DF-by-rownames-tp4703351p4703374.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Tue Feb 17 05:41:03 2015
From: js.huang at protective.com (js.huang at protective.com)
Date: Tue, 17 Feb 2015 05:41:03 +0100
Subject: [R] split dataframe to several dataframes in R
Message-ID: <682203320.38728.1424147667520.JavaMail.administrator@mjoe.nabble.com>

<quote author='R help mailing list-2'>
Hi All,I have a dataframe called 'means' as shown below:iris1.csv <- iris
iris2.csv <- iris
names <- c("iris1.csv", "iris2.csv")
dat <- mget(names)
lst4 <- lapply(dat, function(x) apply(x[,-5], 2, mean))

# Build the new data frame
means <- as.data.frame(do.call(rbind, lst4))
means$source <- names(lst4)
means
#           Sepal.Length Sepal.Width Petal.Length Petal.Width       isv   
source
# iris1.csv     5.843333    3.057333        3.758    1.199333 0.3333333
iris1.csv
# iris2.csv     5.843333    3.057333        3.758    1.199333 0.3333333
iris2.csvQUESTION: How can I split 'means' such that there are two files
(dataframes) on my workspace:datframe 1#           Sepal.Length Sepal.Width
Petal.Length Petal.Width       isv    
# iris1.csv     5.843333    3.057333        3.758    1.199333
0.3333333dataframe 2:#           Sepal.Length Sepal.Width Petal.Length
Petal.Width       isv# iris2.csv     5.843333    3.057333        3.758   
1.199333 0.3333333
Many thanks,Asong.
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

</quote>
Quoted from: 
http://r.789695.n4.nabble.com/split-dataframe-to-several-dataframes-in-R-tp4703372.html


_____________________________________
Sent from http://r.789695.n4.nabble.com


From kmezhoud at gmail.com  Tue Feb 17 09:10:24 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Tue, 17 Feb 2015 08:10:24 +0000
Subject: [R] compute values by condition in DF by rownames
In-Reply-To: <1424147411612-4703374.post@n4.nabble.com>
References: <CALJKBv892JHjw=XW2bVv1sNq1HuCq_83Jzw+_0rFDaRPiL7hDQ@mail.gmail.com>
	<1424147411612-4703374.post@n4.nabble.com>
Message-ID: <CALJKBv-qOa+xSJhkSN9Net3Ri=WfHZezg=UVLavbay9XouBw5A@mail.gmail.com>

Thanks JS
I think aggregate function is better.
Karim
Le 17 f?vr. 2015 08:33, "JS Huang" <js.huang at protective.com> a ?crit :

> Hi,
>
>   I hope that someone can provide a better way to implement it.  This is my
> implementation.
>
> > data
>               X2     gbm_tcga   lusc_tcga ucec_tcga_pub
> 1       gbm_tcga  1.000000000  0.14053719  -0.102847164
> 2       gbm_tcga  1.000000000  0.04413434   0.013568055
> 3       gbm_tcga  1.000000000 -0.20003971   0.038971817
> 4       gbm_tcga  1.000000000  0.14569916   0.009947045
> 5      lusc_tcga  0.140537191  1.00000000   0.133080708
> 6      lusc_tcga  0.044134345  1.00000000   0.062024713
> 7      lusc_tcga -0.200039712  1.00000000  -0.130239551
> 8      lusc_tcga  0.145699156  1.00000000   0.041796670
> 9  ucec_tcga_pub -0.102847164  0.13308071   1.000000000
> 10 ucec_tcga_pub  0.013568055  0.06202471   1.000000000
> 11 ucec_tcga_pub  0.038971817 -0.13023955   1.000000000
> 12 ucec_tcga_pub  0.009947045  0.04179667   1.000000000
> > test
> function(x)
> {
>   tempMatrix <- matrix(0,nrow=3,ncol=3)
>   lev <- levels(x$X2)
>   for (i in 1:length(lev))
>   {
>     tempMatrix[i,1] = sum(ifelse(abs(x[x$X2==lev[i],2])>0.2,1,0))
>     tempMatrix[i,2] = sum(ifelse(abs(x[x$X2==lev[i],3])>0.2,1,0))
>     tempMatrix[i,3] = sum(ifelse(abs(x[x$X2==lev[i],4])>0.2,1,0))
>   }
>   result <- data.frame(lev,tempMatrix)
>   names(result) <- c("X2","gbm_tcga","lusc_tcga","tcga_pub")
>   return(result)
> }
> > test(data)
>              X2 gbm_tcga lusc_tcga tcga_pub
> 1      gbm_tcga        4         1        0
> 2     lusc_tcga        1         4        0
> 3 ucec_tcga_pub        0         0        4
> >
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/compute-values-by-condition-in-DF-by-rownames-tp4703351p4703374.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From helios.derosario at ibv.upv.es  Mon Feb 16 23:11:49 2015
From: helios.derosario at ibv.upv.es (Helios de Rosario)
Date: Mon, 16 Feb 2015 23:11:49 +0100
Subject: [R] [R-pkgs] Release of phia 0.2-0
Message-ID: <54E279350200000C00022218@mailhost.biomec.upv.es>

Dear R users,

I want to announce an update of the package "phia", version 0.2-0, now
on CRAN:
<http://cran.r-project.org/web/packages/phia/>

"phia" (Post-Hoc Interaction Analysis) is aimed at the analysis of the
expected values and other terms of in linear, generalized, and mixed
linear models, on the basis of multiple comparisons of factor contrasts,
and is specially suited for the analysis of interaction effects. The
function "testFactors" provides a flexible user interface for defining
combinations of factor levels and covariates, to evaluate and test the
model, using the function "linearHypothesis" from package "car".
"testInteractions" gives a simpler interface to test multiple
comparisons of simple effects, interaction residuals, interaction
contrasts, or user-defined contrasts. "interactionMeans" may be used to
explore the "cell means" of factorial designs, and plot main effects or
first-order interactions.

This update incorporates some minor bug fixes to previous versions, and
a new feature that had long been requested by some package users: the
report of the error associated to the adjusted values calculated by
functions like "interactionMeans". Now the standard errors are printed
together with the adjusted values, and the plot method for interaction
tables adds error bars with the size of such standard errors, or
asymptotic confidence intervals based on such errors.

In addition, I would like to refer the package users to the development
repository in GitHub: <https://github.com/heliosdrm/phia>, where new
contributions, issues/bug reports, and other comments are welcome.

Best regards

Helios De Rosario

biomecanicamente.org
Conoce la actualidad on-line del IBV
______________________________

INSTITUTO DE BIOMEC?NICA DE VALENCIA
Universidad Polit?cnica de Valencia ? Edificio 9C
Camino de Vera s/n ? 46022 VALENCIA (ESPA?A)
Tel. +34 961111170- +34 610567200 ? Fax +34 96 387 91 69
www.ibv.org

Antes de imprimir este e-mail piense bien si es necesario hacerlo.
En cumplimiento de la Ley Org?nica 15/1999 reguladora de la Protecci?n
de Datos de Car?cter Personal, le informamos de que el presente mensaje
contiene informaci?n confidencial, siendo para uso exclusivo del
destinatario arriba indicado. En caso de no ser usted el destinatario
del mismo le informamos que su recepci?n no le autoriza a su divulgaci?n
o reproducci?n por cualquier medio, debiendo destruirlo de inmediato,
rog?ndole lo notifique al remitente.

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From ccampbell at mango-solutions.com  Tue Feb 17 10:33:50 2015
From: ccampbell at mango-solutions.com (Chris Campbell)
Date: Tue, 17 Feb 2015 09:33:50 +0000
Subject: [R] split dataframe to several dataframes in R
In-Reply-To: <775901483.4092478.1424145237717.JavaMail.yahoo@mail.yahoo.com>
References: <775901483.4092478.1424145237717.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <2C2DB2ABEE65DB40B7946E54C71A8C09A130E91C@mexchange.Mango.local>

# Assuming you want to create many data frames, you can use        
# assign to create new objects.         
newDFNames <- unique(means$source)                   
newDFNames                    
# [1] "iris1.csv" "iris2.csv"                     
for (nm in newDFNames) {                    
     assign(x = nm,             
         value = means[means$source == nm, , drop = FALSE],             
         envir = .GlobalEnv)             
}             
             
iris1.csv             
#           Sepal.Length Sepal.Width Petal.Length Petal.Width    source             
# iris1.csv     5.843333    3.057333        3.758    1.199333 iris1.csv             
             
iris2.csv             
#           Sepal.Length Sepal.Width Petal.Length Petal.Width    source              
# iris2.csv     5.843333    3.057333        3.758    1.199333 iris2.csv             
    
# However, it may be that storing your     
# data objects as a single object, such as a list, is more useful.    
    
Chris Campbell, PhD    
  
Tel. +44 (0)1249 705 450?| Mobile. +44 (0) 7929 628 349
www.mango-solutions.com
Mango Solutions
2 Methuen Park, Chippenham, Wiltshire. SN14 OGB UK

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Zilefac Elvis via R-help
Sent: 17 February 2015 03:54
To: R. Help
Subject: [R] split dataframe to several dataframes in R

Hi All,I have a dataframe called 'means' as shown below:iris1.csv <- iris iris2.csv <- iris names <- c("iris1.csv", "iris2.csv") dat <- mget(names)
lst4 <- lapply(dat, function(x) apply(x[,-5], 2, mean))

# Build the new data frame
means <- as.data.frame(do.call(rbind, lst4)) means$source <- names(lst4) means
#           Sepal.Length Sepal.Width Petal.Length Petal.Width       isv    source
# iris1.csv     5.843333    3.057333        3.758    1.199333 0.3333333 iris1.csv
# iris2.csv     5.843333    3.057333        3.758    1.199333 0.3333333 iris2.csvQUESTION: How can I split 'means' such that there are two files (dataframes) on my workspace:datframe 1#           Sepal.Length Sepal.Width Petal.Length Petal.Width       isv    
# iris1.csv     5.843333    3.057333        3.758    1.199333 0.3333333dataframe 2:#           Sepal.Length Sepal.Width Petal.Length Petal.Width       isv# iris2.csv     5.843333    3.057333        3.758    1.199333 0.3333333
Many thanks,Asong.
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

--

LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}


From wht_crl at yahoo.com  Tue Feb 17 10:52:59 2015
From: wht_crl at yahoo.com (carol white)
Date: Tue, 17 Feb 2015 09:52:59 +0000 (UTC)
Subject: [R] view large tables
Message-ID: <145027582.5078239.1424166779827.JavaMail.yahoo@mail.yahoo.com>

what is the best function to view large tables or data frames, scrolling down-up, left-right?
Thanks
c.

	[[alternative HTML version deleted]]


From hhoeflin at gmail.com  Tue Feb 17 12:31:20 2015
From: hhoeflin at gmail.com (Holger Hoefling)
Date: Tue, 17 Feb 2015 12:31:20 +0100
Subject: [R] Different serialization and digest hash value of functions
Message-ID: <CAFDswJuYKTzd2bF=JuSN8z5MCA-QvPjnOt5YLXCC6taFSg0Ozw@mail.gmail.com>

Hi,

I am using hash-values to cache certain results in R. This caching
also depends on the hash-value of the function that is being cached
(calculated using the digest package). I noticed that computations
that should already be cached are recomputed when switching from an
interactive session to a BATCH session. Therefore, I wrote a test
script

library(digest)
testfun <- function() {
    return(NULL)
}
testval <- "testval"
print(digest(testfun))
print(serialize(testfun, connection = NULL))

and executed it once using input-redirection from a file (testFile.R)
and once copying the code into an interactive R session. The
hash-values of the functions differ. As digest internally relies on
serialize, I also checked there and found that digest is not the
reason for the discrepancy. Instead, the serialized value of the
function already differs between the BATCH and inteactive sessions.

I was wondering if someone knows if
1. Is this a feature or a bug?
2. Is there a way to get consistent hash-values for functions between
BATCH and interactive sessions.

The output from the BATCH and interactive runs are below

Thanks

Holger Hoefling

---------------------------------
BATCH run:

$ R --vanilla < testFile.R

R version 3.1.0 (2014-04-10) -- "Spring Dance"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(digest)
> testfun <- function() {
+     return(NULL)
+ }
> print(digest(testfun))
[1] "b03160b9250f0d5b5bcce42bd86d8e56"
> print(serialize(testfun, connection = NULL))
 [1] 58 0a 00 00 00 02 00 03 01 00 00 02 03 00 00 00 04 03 00 00 00 fd 00 00 00
[26] fe 00 00 00 06 00 00 00 01 00 04 00 09 00 00 00 01 7b 00 00 00 02 00 00 00
[51] 06 00 00 00 01 00 04 00 09 00 00 00 06 72 65 74 75 72 6e 00 00 00 02 00 00
[76] 00 fe 00 00 00 fe 00 00 00 fe
>
>

----------------------------------------------
Interactive run:

$ R --vanilla

R version 3.1.0 (2014-04-10) -- "Spring Dance"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(digest)
> testfun <- function() {
+     return(NULL)
+ }
> print(digest(testfun))
[1] "fada482d2894088b079a8e56b7044862"
> print(serialize(testfun, connection = NULL))
  [1] 58 0a 00 00 00 02 00 03 01 00 00 02 03 00 00 00 06 03 00 00 04 02 00 00 00
 [26] 01 00 04 00 09 00 00 00 06 73 72 63 72 65 66 00 00 03 0d 00 00 00 08 00 00
 [51] 00 01 00 00 00 0c 00 00 00 03 00 00 00 01 00 00 00 0c 00 00 00 01 00 00 00
 [76] 01 00 00 00 03 00 00 04 02 00 00 00 01 00 04 00 09 00 00 00 07 73 72 63 66
[101] 69 6c 65 00 00 00 04 00 00 00 00 00 00 00 f2 00 00 04 02 00 00 00 01 00 04
[126] 00 09 00 00 00 05 6c 69 6e 65 73 00 00 00 10 00 00 00 01 00 04 00 09 00 00
[151] 00 2b 74 65 73 74 66 75 6e 20 3c 2d 20 66 75 6e 63 74 69 6f 6e 28 29 20 7b
[176] 0a 20 20 20 20 72 65 74 75 72 6e 28 4e 55 4c 4c 29 0a 7d 0a 00 00 04 02 00
[201] 00 00 01 00 04 00 09 00 00 00 08 66 69 6c 65 6e 61 6d 65 00 00 00 10 00 00
[226] 00 01 00 04 00 09 00 00 00 00 00 00 00 fe 00 00 00 fe 00 00 04 02 00 00 00
[251] 01 00 04 00 09 00 00 00 05 63 6c 61 73 73 00 00 00 10 00 00 00 02 00 04 00
[276] 09 00 00 00 0b 73 72 63 66 69 6c 65 63 6f 70 79 00 04 00 09 00 00 00 07 73
[301] 72 63 66 69 6c 65 00 00 00 fe 00 00 04 02 00 00 06 ff 00 00 00 10 00 00 00
[326] 01 00 04 00 09 00 00 00 06 73 72 63 72 65 66 00 00 00 fe 00 00 00 fe 00 00
[351] 00 fd 00 00 00 fe 00 00 02 06 00 00 04 02 00 00 01 ff 00 00 00 13 00 00 00
[376] 02 00 00 03 0d 00 00 00 08 00 00 00 01 00 00 00 17 00 00 00 01 00 00 00 17
[401] 00 00 00 17 00 00 00 17 00 00 00 01 00 00 00 01 00 00 04 02 00 00 02 ff 00
[426] 00 03 ff 00 00 04 02 00 00 06 ff 00 00 00 10 00 00 00 01 00 04 00 09 00 00
[451] 00 06 73 72 63 72 65 66 00 00 00 fe 00 00 03 0d 00 00 00 08 00 00 00 02 00
[476] 00 00 05 00 00 00 02 00 00 00 10 00 00 00 05 00 00 00 10 00 00 00 02 00 00
[501] 00 02 00 00 04 02 00 00 02 ff 00 00 03 ff 00 00 04 02 00 00 06 ff 00 00 00
[526] 10 00 00 00 01 00 04 00 09 00 00 00 06 73 72 63 72 65 66 00 00 00 fe 00 00
[551] 04 02 00 00 02 ff 00 00 03 ff 00 00 04 02 00 00 00 01 00 04 00 09 00 00 00
[576] 0b 77 68 6f 6c 65 53 72 63 72 65 66 00 00 03 0d 00 00 00 08 00 00 00 01 00
[601] 00 00 00 00 00 00 03 00 00 00 01 00 00 00 00 00 00 00 01 00 00 00 01 00 00
[626] 00 03 00 00 04 02 00 00 02 ff 00 00 03 ff 00 00 04 02 00 00 06 ff 00 00 00
[651] 10 00 00 00 01 00 04 00 09 00 00 00 06 73 72 63 72 65 66 00 00 00 fe 00 00
[676] 00 fe 00 00 00 01 00 04 00 09 00 00 00 01 7b 00 00 00 02 00 00 00 06 00 00
[701] 00 01 00 04 00 09 00 00 00 06 72 65 74 75 72 6e 00 00 00 02 00 00 00 fe 00
[726] 00 00 fe 00 00 00 fe
>


From jholtman at gmail.com  Tue Feb 17 12:50:35 2015
From: jholtman at gmail.com (jim holtman)
Date: Tue, 17 Feb 2015 06:50:35 -0500
Subject: [R] view large tables
In-Reply-To: <145027582.5078239.1424166779827.JavaMail.yahoo@mail.yahoo.com>
References: <145027582.5078239.1424166779827.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-5tTASHpjkg8NdJ-jgj0i2GUOwcsWmWcZcLakTkDbTXHg@mail.gmail.com>

What is 'large'?  have you tried 'View'?


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Tue, Feb 17, 2015 at 4:52 AM, carol white via R-help <
r-help at r-project.org> wrote:

> what is the best function to view large tables or data frames, scrolling
> down-up, left-right?
> Thanks
> c.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Tue Feb 17 12:53:06 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Tue, 17 Feb 2015 11:53:06 +0000
Subject: [R] Circlize package: add text to chord in symmetric matrix
Message-ID: <CALJKBv8tMG217rsx=DLcT3EFKDcEYgi0X0M8hscJd2goEqaYbw@mail.gmail.com>

Dear All

temp matrix describes correlated genes by disease. Can I include which
genes are common between diseases in chord diagram?

> temp
      X1       X2    Disease1    Disease2    Disease3
1  Gene1 Disease1  1.00000000 -0.31428571  0.25714286
2  Gene2 Disease1  1.00000000  0.42857143  0.42857143
3  Gene3 Disease1  1.00000000 -0.60000000 -0.94285714
4  Gene4 Disease1  1.00000000 -0.54285714 -0.37142857
5  Gene5 Disease1  1.00000000  0.02857143  0.31428571
6  Gene1 Disease2 -0.31428571  1.00000000 -0.60000000
7  Gene2 Disease2  0.42857143  1.00000000  0.14285714
8  Gene3 Disease2 -0.60000000  1.00000000  0.71428571
9  Gene4 Disease2 -0.54285714  1.00000000  0.25714286
10 Gene5 Disease2  0.02857143  1.00000000  0.08571429
11 Gene1 Disease3  0.25714286 -0.60000000  1.00000000
12 Gene2 Disease3  0.42857143  0.14285714  1.00000000
13 Gene3 Disease3 -0.94285714  0.71428571  1.00000000
14 Gene4 Disease3 -0.37142857  0.25714286  1.00000000
15 Gene5 Disease3  0.31428571  0.08571429  1.00000000

The aggregation of temp gives:
temp1 <-aggregate(temp[,c(-1,-2)], list(temp[,2]), function(x) sum(x>.2))
rownames(temp1)<-temp1[,1]
temp1 <- temp1[,-1]

> temp1
         Disease1 Disease2 Disease3
Disease1        5        1        3
Disease2        1        5        2
Disease3        3        2        5

##plot chord diagram
chordDiagram(cor(temp1),symmetric = TRUE

Can I include which genes are common between diseases

##Mapping selected gene by disease
> tempGene1
      Disease1 Disease2 Disease3
Gene1        0        0        1
Gene2        0        1        1
Gene3        0        0        0
Gene4        0        0        0
Gene5        0        0        1

L <-apply(tempGene1,2,function(x) x[x==1])

> L
$Disease1
named integer(0)

$Disease2
Gene2
    1

$Disease3
Gene1 Gene2 Gene5
    1     1     1
Thanks
Karim

	[[alternative HTML version deleted]]


From ronald.koelpin at gmail.com  Tue Feb 17 15:25:51 2015
From: ronald.koelpin at gmail.com (=?UTF-8?B?Um9uYWxkIEvDtmxwaW4=?=)
Date: Tue, 17 Feb 2015 15:25:51 +0100
Subject: [R] Loop over regression results
Message-ID: <54E34F6F.7080001@gmail.com>

Thank you David and Thierry, your answers helped a lot!

Kind regards,

RK.


From gunter.berton at gene.com  Tue Feb 17 15:29:09 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 17 Feb 2015 06:29:09 -0800
Subject: [R] split dataframe to several dataframes in R
In-Reply-To: <2C2DB2ABEE65DB40B7946E54C71A8C09A130E91C@mexchange.Mango.local>
References: <775901483.4092478.1424145237717.JavaMail.yahoo@mail.yahoo.com>
	<2C2DB2ABEE65DB40B7946E54C71A8C09A130E91C@mexchange.Mango.local>
Message-ID: <CACk-te3aEoGojdZhT1EOaYoRwdSxujDkbGqU-Y4fS_NfocjqPg@mail.gmail.com>

Inline.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Feb 17, 2015 at 1:33 AM, Chris Campbell
<ccampbell at mango-solutions.com> wrote:
> # Assuming you want to create many data frames, you can use
> # assign to create new objects.

But almost never should..

See ?list and read some tutorials -- Please!

> newDFNames <- unique(means$source)
> newDFNames
> # [1] "iris1.csv" "iris2.csv"
> for (nm in newDFNames) {
>      assign(x = nm,
>          value = means[means$source == nm, , drop = FALSE],
>          envir = .GlobalEnv)
> }
>
> iris1.csv
> #           Sepal.Length Sepal.Width Petal.Length Petal.Width    source
> # iris1.csv     5.843333    3.057333        3.758    1.199333 iris1.csv
>
> iris2.csv
> #           Sepal.Length Sepal.Width Petal.Length Petal.Width    source
> # iris2.csv     5.843333    3.057333        3.758    1.199333 iris2.csv
>
> # However, it may be that storing your
> # data objects as a single object, such as a list, is more useful.
>
> Chris Campbell, PhD
>
> Tel. +44 (0)1249 705 450 | Mobile. +44 (0) 7929 628 349
> www.mango-solutions.com
> Mango Solutions
> 2 Methuen Park, Chippenham, Wiltshire. SN14 OGB UK
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Zilefac Elvis via R-help
> Sent: 17 February 2015 03:54
> To: R. Help
> Subject: [R] split dataframe to several dataframes in R
>
> Hi All,I have a dataframe called 'means' as shown below:iris1.csv <- iris iris2.csv <- iris names <- c("iris1.csv", "iris2.csv") dat <- mget(names)
> lst4 <- lapply(dat, function(x) apply(x[,-5], 2, mean))
>
> # Build the new data frame
> means <- as.data.frame(do.call(rbind, lst4)) means$source <- names(lst4) means
> #           Sepal.Length Sepal.Width Petal.Length Petal.Width       isv    source
> # iris1.csv     5.843333    3.057333        3.758    1.199333 0.3333333 iris1.csv
> # iris2.csv     5.843333    3.057333        3.758    1.199333 0.3333333 iris2.csvQUESTION: How can I split 'means' such that there are two files (dataframes) on my workspace:datframe 1#           Sepal.Length Sepal.Width Petal.Length Petal.Width       isv
> # iris1.csv     5.843333    3.057333        3.758    1.199333 0.3333333dataframe 2:#           Sepal.Length Sepal.Width Petal.Length Petal.Width       isv# iris2.csv     5.843333    3.057333        3.758    1.199333 0.3333333
> Many thanks,Asong.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> --
>
> LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nina.schoenfelder at fernuni-hagen.de  Tue Feb 17 13:18:49 2015
From: nina.schoenfelder at fernuni-hagen.de (=?windows-1252?Q?Nina_Sch=F6nfelder?=)
Date: Tue, 17 Feb 2015 13:18:49 +0100
Subject: [R] plm function & plm r.squared error
In-Reply-To: <mailman.1.1424170801.5001.r-help@r-project.org>
References: <mailman.1.1424170801.5001.r-help@r-project.org>
Message-ID: <54E331A9.6080808@fernuni-hagen.de>

Dear Constanze,

the error message gives you a hint, where the problem might be. The 
first error massage says that you have NAs in your index variables 
"Unit" and "Week". You can check that with the is.na() function. The 
second error message (r.squared) tells you to specify the model, that is 
on which transformation of the data the R-squared has to be computed.  
There is no default. Moreover, you insert a dataframe ("pCN04") instead 
on a plm object in r.squared().

Kind regards

Nina Sch?nfelder

-----
FernUniversit?t in Hagen
Fakult?t f?r Wirtschaftswissenschaft
Lehrstuhl f?r Volkswirtschaftslehre,
insbes. Makro?konomik
58084 Hagen


On 16/02/15 22:25, fay constanze wrote:
> DearGiovanni,Congratulationsfor the?truly helpful?plm package! Being new to R, I have a problem with the plm function for financial markets timeseries data: After having defined a large, unbalanced panel pdata.frame (https://www.dropbox.com/s/2r9t1cu9v65gobk/Database_CN_2004.csv?dl=0)and running a simple OLS model of two variables regressing company returns(Perf) on index returns (PerfIn)synch <-plm (Perf ~ PerfIn , data=pCN04, na.action = na.omit, index=c("Unit", "Week"), model="pooling") I keepreceiving the following error:Error in model.matrix.pFormula(formula, data, rhs =1, model = model,? : ? NA in theindividual index variableIn addition:Warning message:In `[.data.frame`(index, as.numeric(rownames(mf)),) :? NAsintroduced by coercion
> There aremuch more NAs in y (Perf) than in x (PerfIn) and I have tried to get rid ofthem with na.omit. Another error I have is with the same model for the r.squaredfunction r.squared(pCN04,model=NULL, Perf ~ PerfIn, type= "ess")Error in tss.default(object, model = model) : ??unused argument (model = model)In addition: Warning message:In mean.default(haty) : argument is not numeric or logical: returning NAMany thanks in advance,your help is very precious to me!Constanze
>
>


From knut.hansen at uit.no  Tue Feb 17 12:58:53 2015
From: knut.hansen at uit.no (Knut Hansen)
Date: Tue, 17 Feb 2015 12:58:53 +0100
Subject: [R] Substituting elements in vector
Message-ID: <20061976.pLLQpT2cMr@ws-ism-knuth.fm.uit.no>

Dear list,

I have a vector:
my.vector <- c("A", "B", "C", "D", "E", "F", "G")

and two other:
vec1 <- c("p", "q", "r", "s", "t")
vec2 <- c("x", "y", "z")

I want to substitute elements "b" and "e" in my.vector with vectors vec1 and 
vec2 respectively so that the result becomes the vector:
c("A", "p", "q", "r" , "s" , "t", "C" , "D", "x", "y", "z", "F", "G")

The ordering of the elements is important.

Knut Hansen


From angela.smith2071 at hotmail.com  Tue Feb 17 13:40:54 2015
From: angela.smith2071 at hotmail.com (Angela Smith)
Date: Tue, 17 Feb 2015 05:40:54 -0700
Subject: [R] subsamples and regressions for 100 times
Message-ID: <COL129-W11C7C1C2A2959ECE1D22238E2F0@phx.gbl>



Hi R user,
I'm new to R so
my problem is probably pretty simple but I'm stuck:



my data is consist of 2 variables: co2, temp and one
treatment (l_group). The sample size is different among the treatments. so
that, I wanted to make equal sample size among three groups (A,B and C) of the
treatment.

For this one, I used subsamples technique. Using
subsample, each time the data are different among the three groups of the
treatment.

so that I want to run regression (co2~temp) for a 100
subsamples for each group of treatment (100 times subsample). 

it means that I will have 100 regression equations.? Later, I want to compare the slope of the
regression among the three groups. is there simple way to make a loop so that I
can compare it?

Thanks in advance!



Angela

================
Here is the example:

dat<-structure(list(co2 = c(0.15, 0.148, 0.125, 0.145, 0.138, 0.23, 
0.26, 0.35, 0.41, 0.45, 0.39, 0.42, 0.4, 0.43, 0.26, 0.3, 0.34, 
0.141, 0.145, 0.153, 0.151, 0.128, 0.23, 0.26), temp = c(0.0119, 
0.0122, 0.0089, 0.0115, 0.0101, 0.055, 0.097, 0.22, 0.339, 0.397, 
0.257, 0.434, 0.318, 0.395, 0.087, 0.13, 0.154, 0.0107, 0.0112, 
0.0119, 0.012, 0.0092, 0.055, 0.089), L_group = structure(c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label = c("A", "B", "C"), class = "factor")), .Names = c("co2", 
"temp", "L_group"), class = "data.frame", row.names = c(NA, -24L
))

head(dat)
library(sampling)

# strata.sampling -----
strata.sampling <- function(data, group,size, method = NULL) {
?require(sampling)
? if (is.null(method)) method <- "srswor" 
? temp <- data[order(data[[group]]), ]
? ifelse(length(size)> 1,
???????? size <- size,
???????? ifelse(size < 1,
??????????????? size <- round(table(temp[group]) * size),
??????????????? size <- rep(size, times=length(table(temp[group])))))
? strat = strata(temp, stratanames = names(temp[group]),
???????????????? size = size, method = method)
? getdata(temp, strat)
}

#--------------------------------------------------
sub_dat <- strata.sampling(dat, 'L_group', 4)# 
Lmodel_subdata1<-lm(co2~temp, data=subdat)
Lmodel_subdata1#coef

sub_dat2 <- strata.sampling(dat, 'L_group', 4)# 
Lmodel_subdata2<-lm(co2~temp, data=subdat2)
Lmodel_subdata2#coef

and so on.....[for 100 times)

Table<-rbind(Lmodel_subdata1$coef, Lmodel_subdata1$coef, ....)


 		 	   		  

From js.huang at protective.com  Tue Feb 17 14:14:03 2015
From: js.huang at protective.com (JS Huang)
Date: Tue, 17 Feb 2015 05:14:03 -0800 (PST)
Subject: [R] compute values by condition in DF by rownames
In-Reply-To: <CALJKBv-qOa+xSJhkSN9Net3Ri=WfHZezg=UVLavbay9XouBw5A@mail.gmail.com>
References: <CALJKBv892JHjw=XW2bVv1sNq1HuCq_83Jzw+_0rFDaRPiL7hDQ@mail.gmail.com>
	<1424147411612-4703374.post@n4.nabble.com>
	<CALJKBv-qOa+xSJhkSN9Net3Ri=WfHZezg=UVLavbay9XouBw5A@mail.gmail.com>
Message-ID: <1424178843486-4703387.post@n4.nabble.com>

Hi,

  I like the aggregate version.  Here is an implementation with sapply and
apply:

> data
              X2     gbm_tcga   lusc_tcga ucec_tcga_pub
1       gbm_tcga  1.000000000  0.14053719  -0.102847164
2       gbm_tcga  1.000000000  0.04413434   0.013568055
3       gbm_tcga  1.000000000 -0.20003971   0.038971817
4       gbm_tcga  1.000000000  0.14569916   0.009947045
5      lusc_tcga  0.140537191  1.00000000   0.133080708
6      lusc_tcga  0.044134345  1.00000000   0.062024713
7      lusc_tcga -0.200039712  1.00000000  -0.130239551
8      lusc_tcga  0.145699156  1.00000000   0.041796670
9  ucec_tcga_pub -0.102847164  0.13308071   1.000000000
10 ucec_tcga_pub  0.013568055  0.06202471   1.000000000
11 ucec_tcga_pub  0.038971817 -0.13023955   1.000000000
12 ucec_tcga_pub  0.009947045  0.04179667   1.000000000
> sapply(levels(data[,1]),function(x)
> apply(abs(data[as.character(data$X2)==as.character(x),-1])>0.2,2,sum))
              gbm_tcga lusc_tcga ucec_tcga_pub
gbm_tcga             4         1             0
lusc_tcga            1         4             0
ucec_tcga_pub        0         0             4



--
View this message in context: http://r.789695.n4.nabble.com/compute-values-by-condition-in-DF-by-rownames-tp4703351p4703387.html
Sent from the R help mailing list archive at Nabble.com.


From jrzaurin at gmail.com  Tue Feb 17 15:51:09 2015
From: jrzaurin at gmail.com (Javier Rodriguez Zaurin)
Date: Tue, 17 Feb 2015 14:51:09 +0000
Subject: [R] Image processing using R
Message-ID: <CAL4xj4v5YzBbsPNA3c3Kw24Hh74xK9+E-3jqe2-4S-SSV1R8ag@mail.gmail.com>

Hi all,

I am starting an image processing project. Through the project, I am going
to be needing tools/techniques such as SIFT, HOG,
bag-of-visual-words/features etc...

It seems than OpenCv has most of these features. I have found r-opencv here
https://www.openhub.net/p/r-opencv , but from this website it is not clear
to me how to install it (or if it is even possible)

Therefore, I am wondering if there is any package(s) in R well documented,
suited for this project (beyond biOps or EBimage).

I could always do it using OpenCV (or/and PIL) in python, but I am far more
comfortable using R and I would like to complete the project, if possible,
in R.

Thanks in advance for your time.

Javier

	[[alternative HTML version deleted]]


From andreas.nord at biol.lu.se  Tue Feb 17 16:06:36 2015
From: andreas.nord at biol.lu.se (anord)
Date: Tue, 17 Feb 2015 07:06:36 -0800 (PST)
Subject: [R] Autoregressive covariance structure for lme object and
 R/SAS differences in model output
In-Reply-To: <1423670235304-4703103.post@n4.nabble.com>
References: <1423670235304-4703103.post@n4.nabble.com>
Message-ID: <1424185596463-4703396.post@n4.nabble.com>

Thanks for your comments. I hard disk meltdown has slowed me down somewhat,
but I am now back online. 

I have reposted to the ME-list, and requested SAS output from my colleagues.
I will update the thread again as soon I know more.

Thanks,
Andreas



--
View this message in context: http://r.789695.n4.nabble.com/Autoregressive-covariance-structure-for-lme-object-and-R-SAS-differences-in-model-output-tp4703103p4703396.html
Sent from the R help mailing list archive at Nabble.com.


From info at aghmed.fsnet.co.uk  Tue Feb 17 16:51:31 2015
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Tue, 17 Feb 2015 15:51:31 +0000
Subject: [R] subsamples and regressions for 100 times
In-Reply-To: <COL129-W11C7C1C2A2959ECE1D22238E2F0@phx.gbl>
References: <COL129-W11C7C1C2A2959ECE1D22238E2F0@phx.gbl>
Message-ID: <54E36383.1050005@aghmed.fsnet.co.uk>

Comment inline

On 17/02/2015 12:40, Angela Smith wrote:
>
>
> Hi R user,
> I'm new to R so
> my problem is probably pretty simple but I'm stuck:
>
>
>
> my data is consist of 2 variables: co2, temp and one
> treatment (l_group). The sample size is different among the treatments. so
>
> that, I wanted to make equal sample size among three groups (A,B and C) of the
> treatment.
>

Not sure whether that is necessary for regression but you did not tell 
us why you want to do that.

> For this one, I used subsamples technique. Using
> subsample, each time the data are different among the three groups of the
> treatment.
>
> so that I want to run regression (co2~temp) for a 100
> subsamples for each group of treatment (100 times subsample).
>

The usual way to do this is to store the subsamples in a list and then 
write a function and use lapply, say to store your models. You then have 
another list to which you can then apply the extractor function of your 
choice.


> it means that I will have 100 regression equations.  Later, I want to compare the slope of the
> regression among the three groups. is there simple way to make a loop so that I
> can compare it?
>
> Thanks in advance!
>
>
>
> Angela
>
> ================
> Here is the example:
>
> dat<-structure(list(co2 = c(0.15, 0.148, 0.125, 0.145, 0.138, 0.23,
> 0.26, 0.35, 0.41, 0.45, 0.39, 0.42, 0.4, 0.43, 0.26, 0.3, 0.34,
> 0.141, 0.145, 0.153, 0.151, 0.128, 0.23, 0.26), temp = c(0.0119,
> 0.0122, 0.0089, 0.0115, 0.0101, 0.055, 0.097, 0.22, 0.339, 0.397,
> 0.257, 0.434, 0.318, 0.395, 0.087, 0.13, 0.154, 0.0107, 0.0112,
> 0.0119, 0.012, 0.0092, 0.055, 0.089), L_group = structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label = c("A", "B", "C"), class = "factor")), .Names = c("co2",
> "temp", "L_group"), class = "data.frame", row.names = c(NA, -24L
> ))
>
> head(dat)
> library(sampling)
>
> # strata.sampling -----
> strata.sampling <- function(data, group,size, method = NULL) {
>   require(sampling)
>    if (is.null(method)) method <- "srswor"
>    temp <- data[order(data[[group]]), ]
>    ifelse(length(size)> 1,
>           size <- size,
>           ifelse(size < 1,
>                  size <- round(table(temp[group]) * size),
>                  size <- rep(size, times=length(table(temp[group])))))
>    strat = strata(temp, stratanames = names(temp[group]),
>                   size = size, method = method)
>    getdata(temp, strat)
> }
>
> #--------------------------------------------------
> sub_dat <- strata.sampling(dat, 'L_group', 4)#
> Lmodel_subdata1<-lm(co2~temp, data=subdat)
> Lmodel_subdata1#coef
>
> sub_dat2 <- strata.sampling(dat, 'L_group', 4)#
> Lmodel_subdata2<-lm(co2~temp, data=subdat2)
> Lmodel_subdata2#coef
>
> and so on.....[for 100 times)
>
> Table<-rbind(Lmodel_subdata1$coef, Lmodel_subdata1$coef, ....)
>
>
>   		 	   		
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5645 / Virus Database: 4284/9131 - Release Date: 02/17/15
>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From john.posner at MJBIOSTAT.COM  Tue Feb 17 17:19:57 2015
From: john.posner at MJBIOSTAT.COM (John Posner)
Date: Tue, 17 Feb 2015 16:19:57 +0000
Subject: [R] Coding style question
Message-ID: <9E73F88F04AA25408DBB58FB730BA65329B3BBE3@AUSP01DAG0503.collaborationhost.net>

In the course of slicing-and-dicing some data, I had occasion to create a list like this:

list(
    subset(my_dataframe, GR1=="XX1"),
    subset(my_dataframe, GR1=="XX2"),
    subset(my_dataframe, GR1=="YY"),
    subset(my_dataframe, GR1 %in% c("XX1", "XX2")), 
    subset(my_dataframe, GR2=="Remission"),
    subset(my_dataframe, GR2=="Relapse"))

I used %in% only once, because there was only one "compound value" (XX1 or XX2) for subsetting. But then it occurred to me to use %in% everywhere, taking advantage of the fact that a scalar value is the same as a length-1 vector:

list(
    subset(my_dataframe, GR1 %in% "XX1"),
    subset(my_dataframe, GR1 %in% "XX2"),
    subset(my_dataframe, GR1 %in% "YY"),
    subset(my_dataframe, GR1 %in% c("XX1", "XX2")),
    subset(my_dataframe, GR2 %in% "Remission"),
    subset(my_dataframe, GR2 %in% "Relapse"))

It works just fine.  Are there any problems with this style, from the standpoints of correctness, aesthetics, etc.?

-John


From jrkrideau at inbox.com  Tue Feb 17 17:57:36 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 17 Feb 2015 08:57:36 -0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <CAM5FmSN5kxQXf2gSqdYg2CFAQmpBcwSaUy6qDWOJ4K634AbXhA@mail.gmail.com>
References: <cam5fmsmaidzgj+d5drptguhbm4v1tr6aljjtdjskqcmfs5w49w@mail.gmail.com>
	<7120dbaad3f.0000064fjrkrideau@inbox.com>
	<5885a05522b.0000053fjrkrideau@inbox.com>
	<4b1afade554.0000031bjrkrideau@inbox.com>
	<7c4ce5173e6.000001a3jrkrideau@inbox.com>
	<4ad1edc7c1f.00000299jrkrideau@inbox.com>
	<cam5fmsm-jucvyy6pzxfsvduzek2+gqg8smti++lxfg3sl0npqg@mail.gmail.com>
	<cam5fmspcz-0h5hbbmfkymsgg8tcxmofhieg_-gtre9_uynuaaw@mail.gmail.com>
	<cam5fmsmnokft_x+2x5r0=wmklsnbzxzk3b6fs7t=u-igxhmj4a@mail.gmail.com>
	<cam5fmspbv2v23ojbj=zsp4hi8onhh-rby2g1utxx-sbkqveifa@mail.gmail.com>
Message-ID: <8A6E9310A6B.00000375jrkrideau@inbox.com>

I had never thought of violins.? It might be interesting. However , I still think there maybe some use out of the 4-panel approach.? 

What does your vioilin code look like?

Using Denis' code

gg<- ggplot(dat1, aes(x = condition, y = t, color = gender, linetype =
direction)) +
? geom_errorbar(aes(ymin = t - ci, ymax = t + ci),
??????????????? position = position_dodge(width = 0.6), size = 1,
??????????????? width = 0.5) +
? geom_point(position = position_dodge(width = 0.6), size = 2.5) +
? facet_wrap(direction ~ location) +
? scale_color_manual(values = c("blue", "darkorange"))+
? theme_bw()+
? scale_y_continuous(breaks=seq(0.6,1.5,0.1))
gg

John Kane
Kingston ON Canada

-----Original Message-----
From: hyiltiz at gmail.com
Sent: Tue, 17 Feb 2015 01:20:06 +0800
To: jrkrideau at inbox.com
Subject: Re: [R] ggplot2 shifting bars to only overlap in groups

Again, I come to think about violin plots which is more informative than the error bars. But for some reason, the violin in the *west* became way too slimmer than the *east* one, though the density plot tells me that is not necessarily the case. I am still trying to figure that out, and that would be even more irrelevant as long as *shifting bars in gorups*. So maybe I will come up with another post later when I got the solution.

???
========================
He who is worthy to receive his days and nights is worthy to receive* all 
else* from you (and me).
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? The Prophet, Gibran Kahlil 

On Mon, Feb 16, 2015 at 9:59 PM, John Kane <jrkrideau at inbox.com> wrote:

	Lovely, a much more elegant solution.

 John Kane
 Kingston ON Canada

 -----Original Message-----
 From: hyiltiz at gmail.com
 Sent: Mon, 16 Feb 2015 02:30:09 +0800
 To: jrkrideau at inbox.com, djmuser at gmail.com
 Subject: Re: [R] ggplot2 shifting bars to only overlap in groups

Thanks so much, John and Dennis (who did not respond in the mailing list for some reason). I feel quite obliged to keep you thinking about this.?

 I do agree that not using the bar chart with error bars is a better option. And since *condition* is an important ordinal factor for me, it would be much better to have *condition* be positioned at a relative order. Thus, only color coding it as John's latest solution would not be optimal.?

 It would have been better with the random data, but with my actual data, it does seem necessary to do a jitter for the *male* since it got clattered in the *west*. Here is the actual data along with the solution based on Dennis' code:

 ## data

 dat1 <- ?structure(list(t = c(1.2454860689532, 0.627186899108052, 0.877176019393987,?

 ? ? ? ? ? ? ? ? ? ? ? ?1.26720638917869, 1.16906482219006, 0.889738853288831, 0.852034797572489,?

 ? ? ? ? ? ? ? ? ? ? ? ?1.30007600828822, 1.22896141479778, 0.820236562746995, 0.822197641624559,?

 ? ? ? ? ? ? ? ? ? ? ? ?1.39529772379005, 1.10479557445486, 0.760017179713665, 0.761340230517717,?

 ? ? ? ? ? ? ? ? ? ? ? ?1.11132156961026, 1.30042963441715, 0.811425854755042, 0.979421690403349,?

 ? ? ? ? ? ? ? ? ? ? ? ?1.3297658281305, 1.13377482477157, 0.895243910826397, 0.874181486658082,?

 ? ? ? ? ? ? ? ? ? ? ? ?1.15728885642541, 1.11121780853125, 0.703348405369258, 0.850897112058048,?

 ? ? ? ? ? ? ? ? ? ? ? ?1.14260584106012, 1.09383015337114, 0.911388765620587, 0.84622335453925,?

 ? ? ? ? ? ? ? ? ? ? ? ?1.09847968194129), condition = structure(c(4L, 4L, 4L, 4L, 1L,?

 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 1L,?

 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L), .Label = c("c1",?

 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? "c2", "c2", "c4"), class = "factor"), direction = structure(c(1L,?

 ? ? ? ? ? ? ? ? ? ? ? ?1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,?

 ? ? ? ? ? ? ? ? ? ? ? ?1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("up",?

 ? ? ? ? ? ? ? ? ? ? ? ?"down"), class = "factor"), location = structure(c(2L, 1L, 2L,?

 ? 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,?

 ? 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L), .Label = c("east",?

 ? "west"), class = "factor"), gender = structure(c(2L, 2L, 2L,?

 ? 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,?

 ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("male",?

 ? "female"), class = "factor"), ci = c(0.0307396796826649, 0.0302954863637637,?

 0.0400142340797275, 0.0527186825100342, 0.051675810189946, 0.0368383294010065,?

 0.0404823188495183, 0.0526312391852324, 0.0347332720922338, 0.0354587857740343,?

 0.0303368490163547, 0.0710445198259065, 0.0229339653012889, 0.0261217906562281,?

 0.0285673216713352, 0.0351642108247828, 0.0542657646932069, 0.0566816739316165,?

 0.0481239729953889, 0.0434272572423839, 0.0497366325101659, 0.0342004255233646,?

 0.0349733697554762, 0.0405364256564456, 0.0478372176424872, 0.0341294939361437,?

 0.0424566961614424, 0.0463489561778199, 0.0191707406475215, 0.0501106812754005,?

 0.0321562411182704, 0.0218613299095178)), .Names = c("t", "condition",?

 "direction", "location", "gender", "ci"), row.names = c(NA, -32L

 ), class = "data.frame")

 pp <- ggplot(dat1, aes(x = condition, y = t, color = gender, linetype = direction)) +

 ? geom_errorbar(aes(ymin = t - ci, ymax = t + ci),

 ? ? ? ? ? ? ? ? position = position_dodge(width = 0.6), size = 1,

 ? ? ? ? ? ? ? ? width = 0.5) +

 ? geom_point(position = position_dodge(width = 0.6), size = 2.5) +

 ? facet_wrap(~ location) +

 ? scale_color_manual(values = c("blue", "darkorange"))+

 ? theme_bw()+

 ? scale_y_continuous(breaks=seq(0.6,1.5,0.1))

 pp

 ## EOF

 I have also attached the output.?

 ?Best
 ?
 ========================
 He who is worthy to receive his days and nights is worthy to receive* all
 else* from you (and me).
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? The Prophet, Gibran Kahlil

____________________________________________________________
 FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
 Check it out at http://www.inbox.com/earth [http://www.inbox.com/earth]

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From hyiltiz at gmail.com  Tue Feb 17 18:40:17 2015
From: hyiltiz at gmail.com (=?UTF-8?Q?H=C3=B6rmetjan_Yiltiz?=)
Date: Wed, 18 Feb 2015 01:40:17 +0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <8A6E9310A6B.00000375jrkrideau@inbox.com>
References: <cam5fmsmaidzgj+d5drptguhbm4v1tr6aljjtdjskqcmfs5w49w@mail.gmail.com>
	<7120dbaad3f.0000064fjrkrideau@inbox.com>
	<5885a05522b.0000053fjrkrideau@inbox.com>
	<4b1afade554.0000031bjrkrideau@inbox.com>
	<7c4ce5173e6.000001a3jrkrideau@inbox.com>
	<4ad1edc7c1f.00000299jrkrideau@inbox.com>
	<cam5fmsm-jucvyy6pzxfsvduzek2+gqg8smti++lxfg3sl0npqg@mail.gmail.com>
	<cam5fmspcz-0h5hbbmfkymsgg8tcxmofhieg_-gtre9_uynuaaw@mail.gmail.com>
	<cam5fmsmnokft_x+2x5r0=wmklsnbzxzk3b6fs7t=u-igxhmj4a@mail.gmail.com>
	<cam5fmspbv2v23ojbj=zsp4hi8onhh-rby2g1utxx-sbkqveifa@mail.gmail.com>
	<CAM5FmSN5kxQXf2gSqdYg2CFAQmpBcwSaUy6qDWOJ4K634AbXhA@mail.gmail.com>
	<8A6E9310A6B.00000375jrkrideau@inbox.com>
Message-ID: <CAM5FmSN0o8ZxEyOm_8M3tnTyH3wDNRAxvzHh6_XiuskQG6vLyw@mail.gmail.com>

The code is the same as the last one I showed, except I used geom_violin()
instead.

pp <- ggplot(dat1, aes(x = condition, y = t, color = gender, linetype =
direction)) +
  geom_violin() +
  facet_wrap(~ location) +
  scale_color_manual(values = c("blue", "darkorange"))+
  theme_bw()+
  scale_y_continuous(breaks=seq(0.6,1.5,0.1))

And I have attached the resulted violin plot.

One big difference is that in order to plot violin plots, we need the
un-summarized original data in the long format, rather than the summarized
data as we used in the example above. But I am sorry that I can not share
the original data, so in order to plot a whole violin plot, you just need
to simulate out the data as we previously did.

I see that violin plots by ggplot2 does not contain the quantile
information, but it would be nice if it did. Maybe I should just add
another geom_errorbar for that.

???
========================
He who is worthy to receive his days and nights is worthy to receive* all
else* from you (and me).
                                                 The Prophet, Gibran Kahlil


On Wed, Feb 18, 2015 at 12:57 AM, John Kane <jrkrideau at inbox.com> wrote:

> I had never thought of violins.  It might be interesting. However , I
> still think there maybe some use out of the 4-panel approach.
>
> What does your vioilin code look like?
>
> Using Denis' code
>
> gg<- ggplot(dat1, aes(x = condition, y = t, color = gender, linetype =
> direction)) +
>   geom_errorbar(aes(ymin = t - ci, ymax = t + ci),
>                 position = position_dodge(width = 0.6), size = 1,
>                 width = 0.5) +
>   geom_point(position = position_dodge(width = 0.6), size = 2.5) +
>   facet_wrap(direction ~ location) +
>   scale_color_manual(values = c("blue", "darkorange"))+
>   theme_bw()+
>   scale_y_continuous(breaks=seq(0.6,1.5,0.1))
> gg
>
> John Kane
> Kingston ON Canada
>
> -----Original Message-----
> From: hyiltiz at gmail.com
> Sent: Tue, 17 Feb 2015 01:20:06 +0800
> To: jrkrideau at inbox.com
> Subject: Re: [R] ggplot2 shifting bars to only overlap in groups
>
> Again, I come to think about violin plots which is more informative than
> the error bars. But for some reason, the violin in the *west* became way
> too slimmer than the *east* one, though the density plot tells me that is
> not necessarily the case. I am still trying to figure that out, and that
> would be even more irrelevant as long as *shifting bars in gorups*. So
> maybe I will come up with another post later when I got the solution.
>
> ???
> ========================
> He who is worthy to receive his days and nights is worthy to receive* all
> else* from you (and me).
>                                                  The Prophet, Gibran Kahlil
>
> On Mon, Feb 16, 2015 at 9:59 PM, John Kane <jrkrideau at inbox.com> wrote:
>
>         Lovely, a much more elegant solution.
>
>  John Kane
>  Kingston ON Canada
>
>  -----Original Message-----
>  From: hyiltiz at gmail.com
>  Sent: Mon, 16 Feb 2015 02:30:09 +0800
>  To: jrkrideau at inbox.com, djmuser at gmail.com
>  Subject: Re: [R] ggplot2 shifting bars to only overlap in groups
>
> Thanks so much, John and Dennis (who did not respond in the mailing list
> for some reason). I feel quite obliged to keep you thinking about this.
>
>  I do agree that not using the bar chart with error bars is a better
> option. And since *condition* is an important ordinal factor for me, it
> would be much better to have *condition* be positioned at a relative order.
> Thus, only color coding it as John's latest solution would not be optimal.
>
>  It would have been better with the random data, but with my actual data,
> it does seem necessary to do a jitter for the *male* since it got clattered
> in the *west*. Here is the actual data along with the solution based on
> Dennis' code:
>
>  ## data
>
>  dat1 <-  structure(list(t = c(1.2454860689532, 0.627186899108052,
> 0.877176019393987,
>
>                         1.26720638917869, 1.16906482219006,
> 0.889738853288831, 0.852034797572489,
>
>                         1.30007600828822, 1.22896141479778,
> 0.820236562746995, 0.822197641624559,
>
>                         1.39529772379005, 1.10479557445486,
> 0.760017179713665, 0.761340230517717,
>
>                         1.11132156961026, 1.30042963441715,
> 0.811425854755042, 0.979421690403349,
>
>                         1.3297658281305, 1.13377482477157,
> 0.895243910826397, 0.874181486658082,
>
>                         1.15728885642541, 1.11121780853125,
> 0.703348405369258, 0.850897112058048,
>
>                         1.14260584106012, 1.09383015337114,
> 0.911388765620587, 0.84622335453925,
>
>                         1.09847968194129), condition = structure(c(4L, 4L,
> 4L, 4L, 1L,
>
>                                                                    1L, 1L,
> 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 1L,
>
>                                                                    1L, 1L,
> 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L), .Label = c("c1",
>
>                                                                    "c2",
> "c2", "c4"), class = "factor"), direction = structure(c(1L,
>
>                         1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
> 1L, 2L, 2L, 1L,
>
>                         1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
> 1L, 2L, 2L), .Label = c("up",
>
>                         "down"), class = "factor"), location =
> structure(c(2L, 1L, 2L,
>
>    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>
>    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L), .Label = c("east",
>
>    "west"), class = "factor"), gender = structure(c(2L, 2L, 2L,
>
>    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,
>
>    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("male",
>
>    "female"), class = "factor"), ci = c(0.0307396796826649,
> 0.0302954863637637,
>
>  0.0400142340797275, 0.0527186825100342, 0.051675810189946,
> 0.0368383294010065,
>
>  0.0404823188495183, 0.0526312391852324, 0.0347332720922338,
> 0.0354587857740343,
>
>  0.0303368490163547, 0.0710445198259065, 0.0229339653012889,
> 0.0261217906562281,
>
>  0.0285673216713352, 0.0351642108247828, 0.0542657646932069,
> 0.0566816739316165,
>
>  0.0481239729953889, 0.0434272572423839, 0.0497366325101659,
> 0.0342004255233646,
>
>  0.0349733697554762, 0.0405364256564456, 0.0478372176424872,
> 0.0341294939361437,
>
>  0.0424566961614424, 0.0463489561778199, 0.0191707406475215,
> 0.0501106812754005,
>
>  0.0321562411182704, 0.0218613299095178)), .Names = c("t", "condition",
>
>  "direction", "location", "gender", "ci"), row.names = c(NA, -32L
>
>  ), class = "data.frame")
>
>  pp <- ggplot(dat1, aes(x = condition, y = t, color = gender, linetype =
> direction)) +
>
>    geom_errorbar(aes(ymin = t - ci, ymax = t + ci),
>
>                  position = position_dodge(width = 0.6), size = 1,
>
>                  width = 0.5) +
>
>    geom_point(position = position_dodge(width = 0.6), size = 2.5) +
>
>    facet_wrap(~ location) +
>
>    scale_color_manual(values = c("blue", "darkorange"))+
>
>    theme_bw()+
>
>    scale_y_continuous(breaks=seq(0.6,1.5,0.1))
>
>  pp
>
>  ## EOF
>
>  I have also attached the output.
>
>   Best
>  ?
>  ========================
>  He who is worthy to receive his days and nights is worthy to receive* all
>  else* from you (and me).
>                                                   The Prophet, Gibran
> Kahlil
>
> ____________________________________________________________
>  FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>  Check it out at http://www.inbox.com/earth [http://www.inbox.com/earth]
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> Check it out at http://www.inbox.com/earth
>
>
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: violin_masked.pdf
Type: application/pdf
Size: 72861 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150218/5f1d2f3f/attachment.pdf>

From dcarlson at tamu.edu  Tue Feb 17 18:51:30 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 17 Feb 2015 17:51:30 +0000
Subject: [R] subsamples and regressions for 100 times
In-Reply-To: <54E36383.1050005@aghmed.fsnet.co.uk>
References: <COL129-W11C7C1C2A2959ECE1D22238E2F0@phx.gbl>
	<54E36383.1050005@aghmed.fsnet.co.uk>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D653943@mb02.ads.tamu.edu>

Expanding a bit on Michael's answer, you don't need the sampling package for this, just the sample.int() function to draw a random set of integers that you will use to extract rows from each of your groups. The write a function that returns what you want, the regression slopes from each group and use that function with the replicate() function. Your problem is a good way to illustrate the lapply(), sapply(), replicate() family of functions in R:

# Split the data into a list of data frames
datlist <- split(dat, dat$L_group)
# Write a function to draw the sample and perform the regression on each group
slopes <- function(lst) {
	# Get the minimum sample size
	minsize <- min(sapply(lst, nrow))
	# Draw sample (row numbers) of size minsize from each group
	samlist <- lapply(sapply(lst, nrow), sample.int, size=minsize)
	# Extract sample from each group
	samples <- lapply(names(lst), function(x) lst[[x]][samlist[[x]],])
	# Run the regressions for each group and extract the slopes
	results <- sapply(samples, function(x) coef(lm(co2~temp, x))[2])
	# Use the group names to label the slopes
	names(results) <- names(datlist)
	return(results)
}
# You can get a single set of results with
(results <- slopes(datlist))
#         A         B         C 
# 1.0128392 0.2658041 1.3423786

# To get 100 runs
many <- t(replicate(100, slopes(datlist)))
head(many)
#              A         B        C
# [1,] 1.4326103 0.2658041 1.357475
# [2,] 1.4754324 0.2658041 1.309208
# [3,] 0.9838589 0.2658041 1.408987
# [4,] 0.9993144 0.2658041 1.354297
# [5,] 1.0134187 0.2658041 1.397112
# [6,] 1.4922856 0.2658041 1.312531
>

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael Dewey
Sent: Tuesday, February 17, 2015 9:52 AM
To: Angela Smith; r-help at r-project.org
Subject: Re: [R] subsamples and regressions for 100 times

Comment inline

On 17/02/2015 12:40, Angela Smith wrote:
>
>
> Hi R user,
> I'm new to R so
> my problem is probably pretty simple but I'm stuck:
>
>
>
> my data is consist of 2 variables: co2, temp and one
> treatment (l_group). The sample size is different among the treatments. so
>
> that, I wanted to make equal sample size among three groups (A,B and C) of the
> treatment.
>

Not sure whether that is necessary for regression but you did not tell 
us why you want to do that.

> For this one, I used subsamples technique. Using
> subsample, each time the data are different among the three groups of the
> treatment.
>
> so that I want to run regression (co2~temp) for a 100
> subsamples for each group of treatment (100 times subsample).
>

The usual way to do this is to store the subsamples in a list and then 
write a function and use lapply, say to store your models. You then have 
another list to which you can then apply the extractor function of your 
choice.


> it means that I will have 100 regression equations.  Later, I want to compare the slope of the
> regression among the three groups. is there simple way to make a loop so that I
> can compare it?
>
> Thanks in advance!
>
>
>
> Angela
>
> ================
> Here is the example:
>
> dat<-structure(list(co2 = c(0.15, 0.148, 0.125, 0.145, 0.138, 0.23,
> 0.26, 0.35, 0.41, 0.45, 0.39, 0.42, 0.4, 0.43, 0.26, 0.3, 0.34,
> 0.141, 0.145, 0.153, 0.151, 0.128, 0.23, 0.26), temp = c(0.0119,
> 0.0122, 0.0089, 0.0115, 0.0101, 0.055, 0.097, 0.22, 0.339, 0.397,
> 0.257, 0.434, 0.318, 0.395, 0.087, 0.13, 0.154, 0.0107, 0.0112,
> 0.0119, 0.012, 0.0092, 0.055, 0.089), L_group = structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label = c("A", "B", "C"), class = "factor")), .Names = c("co2",
> "temp", "L_group"), class = "data.frame", row.names = c(NA, -24L
> ))
>
> head(dat)
> library(sampling)
>
> # strata.sampling -----
> strata.sampling <- function(data, group,size, method = NULL) {
>   require(sampling)
>    if (is.null(method)) method <- "srswor"
>    temp <- data[order(data[[group]]), ]
>    ifelse(length(size)> 1,
>           size <- size,
>           ifelse(size < 1,
>                  size <- round(table(temp[group]) * size),
>                  size <- rep(size, times=length(table(temp[group])))))
>    strat = strata(temp, stratanames = names(temp[group]),
>                   size = size, method = method)
>    getdata(temp, strat)
> }
>
> #--------------------------------------------------
> sub_dat <- strata.sampling(dat, 'L_group', 4)#
> Lmodel_subdata1<-lm(co2~temp, data=subdat)
> Lmodel_subdata1#coef
>
> sub_dat2 <- strata.sampling(dat, 'L_group', 4)#
> Lmodel_subdata2<-lm(co2~temp, data=subdat2)
> Lmodel_subdata2#coef
>
> and so on.....[for 100 times)
>
> Table<-rbind(Lmodel_subdata1$coef, Lmodel_subdata1$coef, ....)
>
>
>   		 	   		
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5645 / Virus Database: 4284/9131 - Release Date: 02/17/15
>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From zilefacelvis at yahoo.com  Tue Feb 17 18:52:55 2015
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Tue, 17 Feb 2015 17:52:55 +0000 (UTC)
Subject: [R] split dataframe to several dataframes in R
In-Reply-To: <CACk-te3aEoGojdZhT1EOaYoRwdSxujDkbGqU-Y4fS_NfocjqPg@mail.gmail.com>
References: <CACk-te3aEoGojdZhT1EOaYoRwdSxujDkbGqU-Y4fS_NfocjqPg@mail.gmail.com>
Message-ID: <921393212.5070188.1424195575789.JavaMail.yahoo@mail.yahoo.com>

Great! many thanks, Chris and Bert. 

     On Tuesday, February 17, 2015 8:29 AM, Bert Gunter <gunter.berton at gene.com> wrote:
   

 Inline.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Feb 17, 2015 at 1:33 AM, Chris Campbell
<ccampbell at mango-solutions.com> wrote:
> # Assuming you want to create many data frames, you can use
> # assign to create new objects.

But almost never should..

See ?list and read some tutorials -- Please!

> newDFNames <- unique(means$source)
> newDFNames
> # [1] "iris1.csv" "iris2.csv"
> for (nm in newDFNames) {
>? ? ? assign(x = nm,
>? ? ? ? ? value = means[means$source == nm, , drop = FALSE],
>? ? ? ? ? envir = .GlobalEnv)
> }
>
> iris1.csv
> #? ? ? ? ? Sepal.Length Sepal.Width Petal.Length Petal.Width? ? source
> # iris1.csv? ? 5.843333? ? 3.057333? ? ? ? 3.758? ? 1.199333 iris1.csv
>
> iris2.csv
> #? ? ? ? ? Sepal.Length Sepal.Width Petal.Length Petal.Width? ? source
> # iris2.csv? ? 5.843333? ? 3.057333? ? ? ? 3.758? ? 1.199333 iris2.csv
>
> # However, it may be that storing your
> # data objects as a single object, such as a list, is more useful.
>
> Chris Campbell, PhD
>
> Tel. +44 (0)1249 705 450 | Mobile. +44 (0) 7929 628 349
> www.mango-solutions.com
> Mango Solutions
> 2 Methuen Park, Chippenham, Wiltshire. SN14 OGB UK
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Zilefac Elvis via R-help
> Sent: 17 February 2015 03:54
> To: R. Help
> Subject: [R] split dataframe to several dataframes in R
>
> Hi All,I have a dataframe called 'means' as shown below:iris1.csv <- iris iris2.csv <- iris names <- c("iris1.csv", "iris2.csv") dat <- mget(names)
> lst4 <- lapply(dat, function(x) apply(x[,-5], 2, mean))
>
> # Build the new data frame
> means <- as.data.frame(do.call(rbind, lst4)) means$source <- names(lst4) means
> #? ? ? ? ? Sepal.Length Sepal.Width Petal.Length Petal.Width? ? ? isv? ? source
> # iris1.csv? ? 5.843333? ? 3.057333? ? ? ? 3.758? ? 1.199333 0.3333333 iris1.csv
> # iris2.csv? ? 5.843333? ? 3.057333? ? ? ? 3.758? ? 1.199333 0.3333333 iris2.csvQUESTION: How can I split 'means' such that there are two files (dataframes) on my workspace:datframe 1#? ? ? ? ? Sepal.Length Sepal.Width Petal.Length Petal.Width? ? ? isv
> # iris1.csv? ? 5.843333? ? 3.057333? ? ? ? 3.758? ? 1.199333 0.3333333dataframe 2:#? ? ? ? ? Sepal.Length Sepal.Width Petal.Length Petal.Width? ? ? isv# iris2.csv? ? 5.843333? ? 3.057333? ? ? ? 3.758? ? 1.199333 0.3333333
> Many thanks,Asong.
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> --
>
> LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Tue Feb 17 19:28:46 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 17 Feb 2015 19:28:46 +0100
Subject: [R] Substituting elements in vector
In-Reply-To: <20061976.pLLQpT2cMr@ws-ism-knuth.fm.uit.no>
References: <20061976.pLLQpT2cMr@ws-ism-knuth.fm.uit.no>
Message-ID: <313AD543-81CC-4995-85A7-E3B5131A698A@xs4all.nl>


> On 17-02-2015, at 12:58, Knut Hansen <knut.hansen at uit.no> wrote:
> 
> Dear list,
> 
> I have a vector:
> my.vector <- c("A", "B", "C", "D", "E", "F", "G")
> 
> and two other:
> vec1 <- c("p", "q", "r", "s", "t")
> vec2 <- c("x", "y", "z")
> 
> I want to substitute elements "b" and "e" in my.vector with vectors vec1 and 
> vec2 respectively so that the result becomes the vector:
> c("A", "p", "q", "r" , "s" , "t", "C" , "D", "x", "y", "z", "F", "G")
> 
> The ordering of the elements is important.
> 

Something like this perhaps

res <- c("A", "p", "q", "r" , "s" , "t", "C" , "D", "x", "y", "z", "F", "G?)

rem <- function(vec, who, replace){
	kW <- which(vec == who)
	z1 <- append(vec,replace,kW)
	z2 <- z1[ ! z1 %in% vec[kW] ]
	z2
}

x1 <- rem(my.vector,"B",vec1)
x2 <- rem(x1,"E",vec2)
x2
all.equal(x2,res)

Berend


From zilefacelvis at yahoo.com  Tue Feb 17 19:32:35 2015
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Tue, 17 Feb 2015 18:32:35 +0000 (UTC)
Subject: [R] split dataframe to several dataframes in R
In-Reply-To: <CA+0rMgnvX7mTSLiOjeJ-PLFSqY+_CEu-+z6+HznZVEvUi5Un0A@mail.gmail.com>
References: <775901483.4092478.1424145237717.JavaMail.yahoo@mail.yahoo.com>
	<CA+0rMgnvX7mTSLiOjeJ-PLFSqY+_CEu-+z6+HznZVEvUi5Un0A@mail.gmail.com>
Message-ID: <1480980467.5125244.1424197955907.JavaMail.yahoo@mail.yahoo.com>

Great! Thanks, Aravind. 

     On Monday, February 16, 2015 10:50 PM, Aravind Jayaraman <aravindjayaramanagri at gmail.com> wrote:
   

 Hi,

I think you need not split the data.frame to get the desired result.
You can work with your list lst4 itself.

#Convert the vectors in the list to data.frames.
lst4 <- lapply(lst4, function(x) {as.data.frame(t(iris1.csv))})
#Get the data.frames in the list to the global environment
list2env(lst4 ,.GlobalEnv)

Regards

On 17 February 2015 at 09:23, Zilefac Elvis via R-help
<r-help at r-project.org> wrote:
> Hi All,I have a dataframe called 'means' as shown below:iris1.csv <- iris
> iris2.csv <- iris
> names <- c("iris1.csv", "iris2.csv")
> dat <- mget(names)
> lst4 <- lapply(dat, function(x) apply(x[,-5], 2, mean))
>
> # Build the new data frame
> means <- as.data.frame(do.call(rbind, lst4))
> means$source <- names(lst4)
> means
> #? ? ? ? ? Sepal.Length Sepal.Width Petal.Length Petal.Width? ? ? isv? ? source
> # iris1.csv? ? 5.843333? ? 3.057333? ? ? ? 3.758? ? 1.199333 0.3333333 iris1.csv
> # iris2.csv? ? 5.843333? ? 3.057333? ? ? ? 3.758? ? 1.199333 0.3333333 iris2.csvQUESTION: How can I split 'means' such that there are two files (dataframes) on my workspace:datframe 1#? ? ? ? ? Sepal.Length Sepal.Width Petal.Length Petal.Width? ? ? isv
> # iris1.csv? ? 5.843333? ? 3.057333? ? ? ? 3.758? ? 1.199333 0.3333333dataframe 2:#? ? ? ? ? Sepal.Length Sepal.Width Petal.Length Petal.Width? ? ? isv# iris2.csv? ? 5.843333? ? 3.057333? ? ? ? 3.758? ? 1.199333 0.3333333
> Many thanks,Asong.
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
J.Aravind
Scientist
Germplasm Conservation Division
ICAR-National Bureau of Plant Genetic Resources
New Delhi - 110 012

   
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Feb 17 19:42:19 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Feb 2015 13:42:19 -0500
Subject: [R] Coding style question
In-Reply-To: <9E73F88F04AA25408DBB58FB730BA65329B3BBE3@AUSP01DAG0503.collaborationhost.net>
References: <9E73F88F04AA25408DBB58FB730BA65329B3BBE3@AUSP01DAG0503.collaborationhost.net>
Message-ID: <54E38B8B.7060209@gmail.com>

On 17/02/2015 11:19 AM, John Posner wrote:
> In the course of slicing-and-dicing some data, I had occasion to create a list like this:
>
> list(
>      subset(my_dataframe, GR1=="XX1"),
>      subset(my_dataframe, GR1=="XX2"),
>      subset(my_dataframe, GR1=="YY"),
>      subset(my_dataframe, GR1 %in% c("XX1", "XX2")),
>      subset(my_dataframe, GR2=="Remission"),
>      subset(my_dataframe, GR2=="Relapse"))
>
> I used %in% only once, because there was only one "compound value" (XX1 or XX2) for subsetting. But then it occurred to me to use %in% everywhere, taking advantage of the fact that a scalar value is the same as a length-1 vector:
>
> list(
>      subset(my_dataframe, GR1 %in% "XX1"),
>      subset(my_dataframe, GR1 %in% "XX2"),
>      subset(my_dataframe, GR1 %in% "YY"),
>      subset(my_dataframe, GR1 %in% c("XX1", "XX2")),
>      subset(my_dataframe, GR2 %in% "Remission"),
>      subset(my_dataframe, GR2 %in% "Relapse"))
>
> It works just fine.  Are there any problems with this style, from the standpoints of correctness, aesthetics, etc.?

If GR1 or GR2 has a missing value, you get NA from the equality tests, 
but FALSE from the %in% tests.  That won't affect subset (where NA and 
FALSE both result in the omission of the observation), but it might 
affect other code like this.  For example, if you had selected rows 
using a logical index instead of using subset, the NA entries in the 
index would result in NA selections in the data.

Duncan Murdoch


From Shannon.Bros at sjsu.edu  Tue Feb 17 17:59:46 2015
From: Shannon.Bros at sjsu.edu (smb123)
Date: Tue, 17 Feb 2015 08:59:46 -0800 (PST)
Subject: [R] Discrete variables with logistf
Message-ID: <1424192386804-4703403.post@n4.nabble.com>

I am relatively new to R and I would appreciate some advice on how to include
both discrete and continuous predictor variables in a stepwise backward log
likelihood ration logistic regression. I have a model that includes 3
continuous predictor variables (soilmois, grasscov, and ranvar) and one
discrete predictor (grnsqrl) coded as 0 and 1.

The script I used was:
Bdata$grnsqrl <- factor(Bdata$grnsqrl)
fit2 <-logistf(data=Bdata, badger~soilmois+grasscov+ranvar+grnsqrl)
summary(fit2)
backward(fit2)
drop1(fit2)

The model summary works fine but for either backward.logistf or
drop1.logistf give the error:
missing value where TRUE/FALSE needed

Thank you!



--
View this message in context: http://r.789695.n4.nabble.com/Discrete-variables-with-logistf-tp4703403.html
Sent from the R help mailing list archive at Nabble.com.


From amc5981 at gmail.com  Tue Feb 17 19:15:01 2015
From: amc5981 at gmail.com (Alexandra Catena)
Date: Tue, 17 Feb 2015 10:15:01 -0800
Subject: [R] Help with looping
Message-ID: <CAHpsUFaqhWq4urkMfwtC-Xf2xBQd55F=trkxcax1Q0tNi67V4Q@mail.gmail.com>

Hi,

I need help with a for loop and printing data.  I want to loop through a
few years and print the data from each year stacked on top of each other.
For example,

for (i in 2000:2003){
#script for downloading each year
Data = readLines(sprintf('file/%4i,i))
}

It only prints out the data from the last year.  Also, I tried

Data[i] =  readLines(sprintf('file/%4i,i))

but it says:

"number of items to replace is not a multiple of replacement length"

How do I get it to not replace each year of data? I have R version 2.15.1

Thanks,
Alexandra

	[[alternative HTML version deleted]]


From angela.smith2071 at hotmail.com  Tue Feb 17 19:05:26 2015
From: angela.smith2071 at hotmail.com (Angela Smith)
Date: Tue, 17 Feb 2015 11:05:26 -0700
Subject: [R] subsamples and regressions for 100 times
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D653943@mb02.ads.tamu.edu>
References: <COL129-W11C7C1C2A2959ECE1D22238E2F0@phx.gbl>,
	<54E36383.1050005@aghmed.fsnet.co.uk>,
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D653943@mb02.ads.tamu.edu>
Message-ID: <COL129-W55C8C8F214D900DBCA3D588E2F0@phx.gbl>

Dear David and Michael, 
Thank you so much for the code. It helped me to understand in making a loop and perform the analysis. I am really obliged with your help. 
cheers,
AS
=====




> From: dcarlson at tamu.edu
> To: info at aghmed.fsnet.co.uk; angela.smith2071 at hotmail.com; r-help at r-project.org
> Subject: RE: [R] subsamples and regressions for 100 times
> Date: Tue, 17 Feb 2015 17:51:30 +0000
> 
> Expanding a bit on Michael's answer, you don't need the sampling package for this, just the sample.int() function to draw a random set of integers that you will use to extract rows from each of your groups. The write a function that returns what you want, the regression slopes from each group and use that function with the replicate() function. Your problem is a good way to illustrate the lapply(), sapply(), replicate() family of functions in R:
> 
> # Split the data into a list of data frames
> datlist <- split(dat, dat$L_group)
> # Write a function to draw the sample and perform the regression on each group
> slopes <- function(lst) {
> 	# Get the minimum sample size
> 	minsize <- min(sapply(lst, nrow))
> 	# Draw sample (row numbers) of size minsize from each group
> 	samlist <- lapply(sapply(lst, nrow), sample.int, size=minsize)
> 	# Extract sample from each group
> 	samples <- lapply(names(lst), function(x) lst[[x]][samlist[[x]],])
> 	# Run the regressions for each group and extract the slopes
> 	results <- sapply(samples, function(x) coef(lm(co2~temp, x))[2])
> 	# Use the group names to label the slopes
> 	names(results) <- names(datlist)
> 	return(results)
> }
> # You can get a single set of results with
> (results <- slopes(datlist))
> #         A         B         C 
> # 1.0128392 0.2658041 1.3423786
> 
> # To get 100 runs
> many <- t(replicate(100, slopes(datlist)))
> head(many)
> #              A         B        C
> # [1,] 1.4326103 0.2658041 1.357475
> # [2,] 1.4754324 0.2658041 1.309208
> # [3,] 0.9838589 0.2658041 1.408987
> # [4,] 0.9993144 0.2658041 1.354297
> # [5,] 1.0134187 0.2658041 1.397112
> # [6,] 1.4922856 0.2658041 1.312531
> >
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael Dewey
> Sent: Tuesday, February 17, 2015 9:52 AM
> To: Angela Smith; r-help at r-project.org
> Subject: Re: [R] subsamples and regressions for 100 times
> 
> Comment inline
> 
> On 17/02/2015 12:40, Angela Smith wrote:
> >
> >
> > Hi R user,
> > I'm new to R so
> > my problem is probably pretty simple but I'm stuck:
> >
> >
> >
> > my data is consist of 2 variables: co2, temp and one
> > treatment (l_group). The sample size is different among the treatments. so
> >
> > that, I wanted to make equal sample size among three groups (A,B and C) of the
> > treatment.
> >
> 
> Not sure whether that is necessary for regression but you did not tell 
> us why you want to do that.
> 
> > For this one, I used subsamples technique. Using
> > subsample, each time the data are different among the three groups of the
> > treatment.
> >
> > so that I want to run regression (co2~temp) for a 100
> > subsamples for each group of treatment (100 times subsample).
> >
> 
> The usual way to do this is to store the subsamples in a list and then 
> write a function and use lapply, say to store your models. You then have 
> another list to which you can then apply the extractor function of your 
> choice.
> 
> 
> > it means that I will have 100 regression equations.  Later, I want to compare the slope of the
> > regression among the three groups. is there simple way to make a loop so that I
> > can compare it?
> >
> > Thanks in advance!
> >
> >
> >
> > Angela
> >
> > ================
> > Here is the example:
> >
> > dat<-structure(list(co2 = c(0.15, 0.148, 0.125, 0.145, 0.138, 0.23,
> > 0.26, 0.35, 0.41, 0.45, 0.39, 0.42, 0.4, 0.43, 0.26, 0.3, 0.34,
> > 0.141, 0.145, 0.153, 0.151, 0.128, 0.23, 0.26), temp = c(0.0119,
> > 0.0122, 0.0089, 0.0115, 0.0101, 0.055, 0.097, 0.22, 0.339, 0.397,
> > 0.257, 0.434, 0.318, 0.395, 0.087, 0.13, 0.154, 0.0107, 0.0112,
> > 0.0119, 0.012, 0.0092, 0.055, 0.089), L_group = structure(c(1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> > 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label = c("A", "B", "C"), class = "factor")), .Names = c("co2",
> > "temp", "L_group"), class = "data.frame", row.names = c(NA, -24L
> > ))
> >
> > head(dat)
> > library(sampling)
> >
> > # strata.sampling -----
> > strata.sampling <- function(data, group,size, method = NULL) {
> >   require(sampling)
> >    if (is.null(method)) method <- "srswor"
> >    temp <- data[order(data[[group]]), ]
> >    ifelse(length(size)> 1,
> >           size <- size,
> >           ifelse(size < 1,
> >                  size <- round(table(temp[group]) * size),
> >                  size <- rep(size, times=length(table(temp[group])))))
> >    strat = strata(temp, stratanames = names(temp[group]),
> >                   size = size, method = method)
> >    getdata(temp, strat)
> > }
> >
> > #--------------------------------------------------
> > sub_dat <- strata.sampling(dat, 'L_group', 4)#
> > Lmodel_subdata1<-lm(co2~temp, data=subdat)
> > Lmodel_subdata1#coef
> >
> > sub_dat2 <- strata.sampling(dat, 'L_group', 4)#
> > Lmodel_subdata2<-lm(co2~temp, data=subdat2)
> > Lmodel_subdata2#coef
> >
> > and so on.....[for 100 times)
> >
> > Table<-rbind(Lmodel_subdata1$coef, Lmodel_subdata1$coef, ....)
> >
> >
> >   		 	   		
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > -----
> > No virus found in this message.
> > Checked by AVG - www.avg.com
> > Version: 2015.0.5645 / Virus Database: 4284/9131 - Release Date: 02/17/15
> >
> >
> >
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
 		 	   		  
	[[alternative HTML version deleted]]


From jmadinga at yahoo.fr  Tue Feb 17 17:46:34 2015
From: jmadinga at yahoo.fr (Joule Madinga)
Date: Tue, 17 Feb 2015 16:46:34 +0000 (UTC)
Subject: [R] Change error bar length in barplot2
Message-ID: <309400573.684629.1424191594390.JavaMail.yahoo@mail.yahoo.com>

Hi,I'm new to R.I would like to make a barplot of parasite infection prevalence (with 95% confidence interval) by age group.I have 4 parasite species and 5 age-groups and the example by?Marc Schwartz (barplot2) fits very well to my data.However, I would like to plot my own 95%CI (as calculated with my own data) instead of "faked 95%CI" provided in the example.How can I proceed?
Thank you in advance.?Joule?

	[[alternative HTML version deleted]]


From reganjam at msu.edu  Tue Feb 17 18:13:02 2015
From: reganjam at msu.edu (small_Data88)
Date: Tue, 17 Feb 2015 09:13:02 -0800 (PST)
Subject: [R] paste (CTRL + v) not working rgui
In-Reply-To: <BLU142-W483426068947E061A9845EF5C0@phx.gbl>
References: <BLU142-W483426068947E061A9845EF5C0@phx.gbl>
Message-ID: <1424193182452-4703404.post@n4.nabble.com>

Hello, I am sure you have solved this problem, but I just experienced this
same problem. I was able to fix this by closing my current R session and
then reopening a new one. So, close your current R session and then open a
new one and then you should be able to cut,copy,paste, etc :)

I am running R 3.1.1 on a Windows 7 machine.



--
View this message in context: http://r.789695.n4.nabble.com/paste-CTRL-v-not-working-rgui-tp4480645p4703404.html
Sent from the R help mailing list archive at Nabble.com.


From rnieuws at gmail.com  Tue Feb 17 20:41:36 2015
From: rnieuws at gmail.com (=?UTF-8?Q?Andr=C3=A9_de_Boer?=)
Date: Tue, 17 Feb 2015 20:41:36 +0100
Subject: [R] %>%
Message-ID: <CAO06FDdCLViGuwgVUuSTA8uhjz4YtSf-hVNkNW3x+jBbgL9C6w@mail.gmail.com>

Hello,

Where can I find info about the operator %>%?
Never used it but when I search for it I gives no result.

Thanks,
Andr?


From dwinsemius at comcast.net  Tue Feb 17 20:54:40 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 17 Feb 2015 11:54:40 -0800
Subject: [R] Image processing using R
In-Reply-To: <CAL4xj4v5YzBbsPNA3c3Kw24Hh74xK9+E-3jqe2-4S-SSV1R8ag@mail.gmail.com>
References: <CAL4xj4v5YzBbsPNA3c3Kw24Hh74xK9+E-3jqe2-4S-SSV1R8ag@mail.gmail.com>
Message-ID: <1B0DDC8A-7DD8-4A60-A150-6A7D0BF6F38D@comcast.net>


On Feb 17, 2015, at 6:51 AM, Javier Rodriguez Zaurin wrote:

> Hi all,
> 
> I am starting an image processing project. Through the project, I am going
> to be needing tools/techniques such as SIFT, HOG,
> bag-of-visual-words/features etc...
> 
> It seems than OpenCv has most of these features. I have found r-opencv here
> https://www.openhub.net/p/r-opencv , but from this website it is not clear
> to me how to install it (or if it is even possible)

I would think that you would communicate with DavidvonPKU at gmail.com who is doing most of the work. It is described as providing support for the Bioconductor project.  Like you I did not see a package at that website and I also did not see that it was a package on the Bioconductor repository.


> 
> Therefore, I am wondering if there is any package(s) in R well documented,
> suited for this project (beyond biOps or EBimage).
> 
> I could always do it using OpenCV (or/and PIL) in python, but I am far more
> comfortable using R and I would like to complete the project, if possible,
> in R.
> 
> Thanks in advance for your time.
> 
> Javier
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Tue Feb 17 21:42:45 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Feb 2015 15:42:45 -0500
Subject: [R] %>%
In-Reply-To: <CAO06FDdCLViGuwgVUuSTA8uhjz4YtSf-hVNkNW3x+jBbgL9C6w@mail.gmail.com>
References: <CAO06FDdCLViGuwgVUuSTA8uhjz4YtSf-hVNkNW3x+jBbgL9C6w@mail.gmail.com>
Message-ID: <54E3A7C5.2040505@gmail.com>

On 17/02/2015 2:41 PM, Andr? de Boer wrote:
> Hello,
>
> Where can I find info about the operator %>%?
> Never used it but when I search for it I gives no result.

That is a user-defined binary operator.  You need to look in the sources 
that used it to find how it was defined.  (See section 10.2 of the 
Introduction to R for a description of how to define these.)

Duncan Murdoch


From dnbarron at gmail.com  Tue Feb 17 21:44:18 2015
From: dnbarron at gmail.com (David Barron)
Date: Tue, 17 Feb 2015 20:44:18 +0000
Subject: [R] %>%
In-Reply-To: <CAO06FDdCLViGuwgVUuSTA8uhjz4YtSf-hVNkNW3x+jBbgL9C6w@mail.gmail.com>
References: <CAO06FDdCLViGuwgVUuSTA8uhjz4YtSf-hVNkNW3x+jBbgL9C6w@mail.gmail.com>
Message-ID: <CAHuze_+AQY7ssuVmdz2D695nFxshbfhud5jRDD_oaF7un1QNMA@mail.gmail.com>

It's in the magrittr package.

David

On 17 February 2015 at 19:41, Andr? de Boer <rnieuws at gmail.com> wrote:
> Hello,
>
> Where can I find info about the operator %>%?
> Never used it but when I search for it I gives no result.
>
> Thanks,
> Andr?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Tue Feb 17 22:19:43 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 17 Feb 2015 21:19:43 +0000
Subject: [R] %>%
References: <CAO06FDdCLViGuwgVUuSTA8uhjz4YtSf-hVNkNW3x+jBbgL9C6w@mail.gmail.com>
	<CAHuze_+AQY7ssuVmdz2D695nFxshbfhud5jRDD_oaF7un1QNMA@mail.gmail.com>
Message-ID: <loom.20150217T221829-902@post.gmane.org>

David Barron <dnbarron <at> gmail.com> writes:

> 
> It's in the magrittr package.
> 
> David

  It also exists in dplyr.

  (I would guess that it's imported/exported from magrittr.)
  Although I think the documentation in magrittr is a little better.


From erich.neuwirth at univie.ac.at  Tue Feb 17 23:10:16 2015
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Tue, 17 Feb 2015 23:10:16 +0100
Subject: [R] %>%
In-Reply-To: <loom.20150217T221829-902@post.gmane.org>
References: <CAO06FDdCLViGuwgVUuSTA8uhjz4YtSf-hVNkNW3x+jBbgL9C6w@mail.gmail.com>
	<CAHuze_+AQY7ssuVmdz2D695nFxshbfhud5jRDD_oaF7un1QNMA@mail.gmail.com>
	<loom.20150217T221829-902@post.gmane.org>
Message-ID: <C0576650-F58C-4CE4-B06F-529591A3FD0A@univie.ac.at>

AFAIK dplyr imports magrtittr.
So dplyr ses %>% from migrittr, it does not have its own version.


> On Feb 17, 2015, at 22:19, Ben Bolker <bbolker at gmail.com> wrote:
> 
> David Barron <dnbarron <at> gmail.com> writes:
> 
>> 
>> It's in the magrittr package.
>> 
>> David
> 
>  It also exists in dplyr.
> 
>  (I would guess that it's imported/exported from magrittr.)
>  Although I think the documentation in magrittr is a little better.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150217/0987dae3/attachment.bin>

From dopartpj at gmail.com  Tue Feb 17 22:02:09 2015
From: dopartpj at gmail.com (Pam Dopart)
Date: Tue, 17 Feb 2015 16:02:09 -0500
Subject: [R] multiple imputation of longitudinal, time-unstructured data
Message-ID: <CALhmKoH37CdgdRRsA4HwqXr6_EY17R2uYjyVJmyMQHLDYcXVwA@mail.gmail.com>

Hello!

I have a longitudinal dataset of radiation exposures of an occupational
cohort. A percentage of the exposure values are missing and I would like to
multiply impute the missing values (it is one option of several we are
comparing). The data are recorded in long format (one row for each exposure
entry) and there are multiple exposure measurements per worker. However,
the data are time-unstructured (different data collection schedules for
each worker) and unbalanced.

I want to account for the correlation between repeated measurements on the
same worker. However, because of the time-unstructured nature of the
dataset, I am unable to convert my dataset into wide format and impute that
way. I have begun reading about about using multilevel imputation for such
a scenario, but I rather unfamiliar with this approach, including within R.
Is this an appropriate method to investigate?

Any advice on how to get started would be greatly appreciated!

Thank you!

Pam

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Tue Feb 17 23:26:59 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 17 Feb 2015 16:26:59 -0600
Subject: [R] Help with looping
In-Reply-To: <CAHpsUFaqhWq4urkMfwtC-Xf2xBQd55F=trkxcax1Q0tNi67V4Q@mail.gmail.com>
References: <CAHpsUFaqhWq4urkMfwtC-Xf2xBQd55F=trkxcax1Q0tNi67V4Q@mail.gmail.com>
Message-ID: <C554BB50-1475-40ED-95C4-D008822F9FB6@txbiomed.org>

Alexandra,

According to the documentation (?readLines), readLines returns a character vector with one line from the file being read in each element of the vector. You can put the character vector from each file (as represented by a year designation in your example) in a separate list element. You want to count the elements in the list starting at 1 not 2000. The integers from years[i] get converted to strings in sprintf in the code below.

years <- 2000:2003
Data <- list(length(years))

for (i in seq_along(years)){
    #script for downloading each year
    Data[i] = readLines(sprintf('file/%s',years[i]))
}
# Data[1] will have the character vector made up of the lines in 'file/2000'.

Mark

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Feb 17, 2015, at 12:15 PM, Alexandra Catena <amc5981 at gmail.com> wrote:
>
> Hi,
>
> I need help with a for loop and printing data.  I want to loop through a
> few years and print the data from each year stacked on top of each other.
> For example,
>
> for (i in 2000:2003){
> #script for downloading each year
> Data = readLines(sprintf('file/%4i,i))
> }
>
> It only prints out the data from the last year.  Also, I tried
>
> Data[i] =  readLines(sprintf('file/%4i,i))
>
> but it says:
>
> "number of items to replace is not a multiple of replacement length"
>
> How do I get it to not replace each year of data? I have R version 2.15.1
>
> Thanks,
> Alexandra
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.


From msharp at txbiomed.org  Tue Feb 17 23:28:24 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 17 Feb 2015 16:28:24 -0600
Subject: [R] Help with looping
In-Reply-To: <CAHpsUFaqhWq4urkMfwtC-Xf2xBQd55F=trkxcax1Q0tNi67V4Q@mail.gmail.com>
References: <CAHpsUFaqhWq4urkMfwtC-Xf2xBQd55F=trkxcax1Q0tNi67V4Q@mail.gmail.com>
Message-ID: <F173838F-0C76-499A-B460-C10F691C94FB@txbiomed.org>

Alexandra,

According to the documentation (?readLines), readLines returns a character vector with one line from the file being read in each element of the vector. You can put the character vector from each file (as represented by a year designation in your example) in a separate list element. You want to count the elements in the list starting at 1 not 2000. The integers from years[i] get converted to strings in sprintf in the code below.

years <- 2000:2003
Data <- list(length(years))

for (i in seq_along(years)){
   #script for downloading each year
   Data[i] = readLines(sprintf('file/%s',years[i]))
}
# Data[1] will have the character vector made up of the lines in 'file/2000'.

Mark

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Feb 17, 2015, at 12:15 PM, Alexandra Catena <amc5981 at gmail.com> wrote:
>
> Hi,
>
> I need help with a for loop and printing data.  I want to loop through a
> few years and print the data from each year stacked on top of each other.
> For example,
>
> for (i in 2000:2003){
> #script for downloading each year
> Data = readLines(sprintf('file/%4i,i))
> }
>
> It only prints out the data from the last year.  Also, I tried
>
> Data[i] =  readLines(sprintf('file/%4i,i))
>
> but it says:
>
> "number of items to replace is not a multiple of replacement length"
>
> How do I get it to not replace each year of data? I have R version 2.15.1
>
> Thanks,
> Alexandra
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org








NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.


From ruipbarradas at sapo.pt  Tue Feb 17 23:29:16 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 17 Feb 2015 22:29:16 +0000
Subject: [R] Help with looping
In-Reply-To: <CAHpsUFaqhWq4urkMfwtC-Xf2xBQd55F=trkxcax1Q0tNi67V4Q@mail.gmail.com>
References: <CAHpsUFaqhWq4urkMfwtC-Xf2xBQd55F=trkxcax1Q0tNi67V4Q@mail.gmail.com>
Message-ID: <54E3C0BC.4080202@sapo.pt>

Hello,

Try the following.

Data <- lapply(sprintf('file/%4i', 2000:2003), readLines)


This will give you a list with 4 elements, each of which is the contents 
of each file.

Hope this helps,

Rui Barradas

Em 17-02-2015 18:15, Alexandra Catena escreveu:
> Hi,
>
> I need help with a for loop and printing data.  I want to loop through a
> few years and print the data from each year stacked on top of each other.
> For example,
>
> for (i in 2000:2003){
> #script for downloading each year
> Data = readLines(sprintf('file/%4i,i))
> }
>
> It only prints out the data from the last year.  Also, I tried
>
> Data[i] =  readLines(sprintf('file/%4i,i))
>
> but it says:
>
> "number of items to replace is not a multiple of replacement length"
>
> How do I get it to not replace each year of data? I have R version 2.15.1
>
> Thanks,
> Alexandra
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From marc_schwartz at me.com  Tue Feb 17 23:40:34 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 17 Feb 2015 16:40:34 -0600
Subject: [R] Change error bar length in barplot2
In-Reply-To: <309400573.684629.1424191594390.JavaMail.yahoo@mail.yahoo.com>
References: <309400573.684629.1424191594390.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <EF44C9A7-BB85-4A83-83EF-D449FBCADE4F@me.com>

On Feb 17, 2015, at 10:46 AM, Joule Madinga <jmadinga at yahoo.fr> wrote:
> 
> Hi,I'm new to R.I would like to make a barplot of parasite infection prevalence (with 95% confidence interval) by age group.I have 4 parasite species and 5 age-groups and the example by Marc Schwartz (barplot2) fits very well to my data.However, I would like to plot my own 95%CI (as calculated with my own data) instead of "faked 95%CI" provided in the example.How can I proceed?
> Thank you in advance. Joule 


Joule,

Please see my reply to your offlist e-mail to me this morning.

It looks like there was a delay in your post here coming through, perhaps as a result of moderation.

Regards,

Marc Schwartz


From HDoran at air.org  Wed Feb 18 00:03:24 2015
From: HDoran at air.org (Doran, Harold)
Date: Tue, 17 Feb 2015 23:03:24 +0000
Subject: [R] multiple parameter optimization with optim()
Message-ID: <D10931E1.23C0E%hdoran@air.org>

I am trying to generalize a working piece of code for a single parameter to a multiple parameter problem. Reproducible code is below. The parameters to be estimated are a, b, and c. The estimation problem is such that there is one set of a, b, c parameters for each column of the data. Hence, in this sample data with 20 columns, there are 20 a params, 20 b-params, and 20 c-params.

Because I am estimating so many parameters, I am not certain that I have indicated to the function properly the right number of params to estimate and also if I have generated starting values in a sufficient way.

Thanks for any help.
Harold

dat <- replicate(20, sample(c(0,1), 2000, replace = T))
library(stat mod)
qq <- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma = 1)
nds <- qq$nodes
wts <- qq$weights
fn <- function(params){
a <- params[1:ncol(dat)]
b <- params[1:ncol(dat)]
c <- params[1:ncol(dat)]
L <- sapply(1:ncol(dat), function(i) dbinom(dat[,i], 1, c + ((1 - c)/(1 + exp(-1.7 * a * (nds[i] - b)))) * wts[i]))
r1 <- prod(colSums(L * wts))
-log(r1)
}
startVal <- rep(.5, ncol(dat))
opt <- optim(startVal, fn)

	[[alternative HTML version deleted]]


From js.huang at protective.com  Tue Feb 17 23:45:10 2015
From: js.huang at protective.com (JS Huang)
Date: Tue, 17 Feb 2015 14:45:10 -0800 (PST)
Subject: [R] Substituting elements in vector
In-Reply-To: <313AD543-81CC-4995-85A7-E3B5131A698A@xs4all.nl>
References: <20061976.pLLQpT2cMr@ws-ism-knuth.fm.uit.no>
	<313AD543-81CC-4995-85A7-E3B5131A698A@xs4all.nl>
Message-ID: <1424213110498-4703431.post@n4.nabble.com>

Hi,

  Here is an implementation.

> my.vector
[1] "A" "B" "C" "D" "E" "F" "G"
> vec1
[1] "p" "q" "r" "s" "t"
> vec2
[1] "x" "y" "z"
> final <- as.character(unlist(sapply(my.vector,function(x)
> if(x=="B"){vec1}else{if(x=="E"){vec2}else{x}})))
> final
 [1] "A" "p" "q" "r" "s" "t" "C" "D" "x" "y" "z" "F" "G"



--
View this message in context: http://r.789695.n4.nabble.com/Substituting-elements-in-vector-tp4703395p4703431.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Wed Feb 18 00:50:27 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 17 Feb 2015 15:50:27 -0800
Subject: [R] Substituting elements in vector
In-Reply-To: <20061976.pLLQpT2cMr@ws-ism-knuth.fm.uit.no>
References: <20061976.pLLQpT2cMr@ws-ism-knuth.fm.uit.no>
Message-ID: <C45114AA-E5A1-4492-AEC6-8A30C5404E24@comcast.net>


On Feb 17, 2015, at 3:58 AM, Knut Hansen wrote:

> Dear list,
> 
> I have a vector:
> my.vector <- c("A", "B", "C", "D", "E", "F", "G")
> 
> and two other:
> vec1 <- c("p", "q", "r", "s", "t")
> vec2 <- c("x", "y", "z")
> 
> I want to substitute elements "b" and "e" in my.vector with vectors vec1 and 
> vec2 respectively so that the result becomes the vector:
> c("A", "p", "q", "r" , "s" , "t", "C" , "D", "x", "y", "z", "F", "G")

> my.vlist <- setNames(as.list(my.vector),my.vector)
> replist <- list(B=vec1, E=vec2)
> my.vlist[c("B","E")] <- replist
> unlist(my.vlist)
  A  B1  B2  B3  B4  B5   C   D  E1  E2  E3   F   G 
"A" "p" "q" "r" "s" "t" "C" "D" "x" "y" "z" "F" "G" 

Could also have used:

my.vlist[ names(replist) ] <- replist

.... which I think illustrates the value of character indexing of lists for assignment even better.


> The ordering of the elements is important.
> 
> Knut Hansen
> 
> 

David Winsemius
Alameda, CA, USA


From JSorkin at grecc.umaryland.edu  Wed Feb 18 01:18:14 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 17 Feb 2015 19:18:14 -0500
Subject: [R] multiple imputation of longitudinal, time-unstructured data
In-Reply-To: <CALhmKoH37CdgdRRsA4HwqXr6_EY17R2uYjyVJmyMQHLDYcXVwA@mail.gmail.com>
References: <CALhmKoH37CdgdRRsA4HwqXr6_EY17R2uYjyVJmyMQHLDYcXVwA@mail.gmail.com>
Message-ID: <54E393F6020000CB00123752@smtp.medicine.umaryland.edu>

Pam,
Please let me know what you discover. I just started looking at a similar problem. I understand
 that a Kalman filter can sometimes be applied to this problem,
but at this time I don't know how to accomplish this.
John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


>>> Pam Dopart <dopartpj at gmail.com> 2/17/2015 4:02 PM >>>
Hello!

I have a longitudinal dataset of radiation exposures of an occupational
cohort. A percentage of the exposure values are missing and I would like to
multiply impute the missing values (it is one option of several we are
comparing). The data are recorded in long format (one row for each exposure
entry) and there are multiple exposure measurements per worker. However,
the data are time-unstructured (different data collection schedules for
each worker) and unbalanced.

I want to account for the correlation between repeated measurements on the
same worker. However, because of the time-unstructured nature of the
dataset, I am unable to convert my dataset into wide format and impute that
way. I have begun reading about about using multilevel imputation for such
a scenario, but I rather unfamiliar with this approach, including within R.
Is this an appropriate method to investigate?

Any advice on how to get started would be greatly appreciated!

Thank you!

Pam

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From ecacarva at gmail.com  Wed Feb 18 01:24:43 2015
From: ecacarva at gmail.com (Elias Carvalho)
Date: Tue, 17 Feb 2015 22:24:43 -0200
Subject: [R] Bayesian Networks
Message-ID: <CAH8E6UsQEuxtN56+y9YOUHui+Mp2h+ivuHErKz_iubL+9k7RCg@mail.gmail.com>

Has somebody implemented Bayesian Networks in R ?

-- 
Best regards... 8^)

?*A mente que se abre a novas ideias jamais voltar? *
*a seu tamanho original*?  *Albert Einstein*


_____________________________________________
Prof. Elias C?sar Ara?jo de Carvalho
CV: http://lattes.cnpq.br/4248328961021251

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Wed Feb 18 01:02:15 2015
From: hpages at fredhutch.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 17 Feb 2015 16:02:15 -0800
Subject: [R] %>%
In-Reply-To: <C0576650-F58C-4CE4-B06F-529591A3FD0A@univie.ac.at>
References: <CAO06FDdCLViGuwgVUuSTA8uhjz4YtSf-hVNkNW3x+jBbgL9C6w@mail.gmail.com>	<CAHuze_+AQY7ssuVmdz2D695nFxshbfhud5jRDD_oaF7un1QNMA@mail.gmail.com>	<loom.20150217T221829-902@post.gmane.org>
	<C0576650-F58C-4CE4-B06F-529591A3FD0A@univie.ac.at>
Message-ID: <54E3D687.3020007@fredhutch.org>

On 02/17/2015 02:10 PM, Erich Neuwirth wrote:
> AFAIK dplyr imports magrtittr.
> So dplyr ses %>% from migrittr, it does not have its own version.

But it has its own man page so who knows?

H.

>
>
>> On Feb 17, 2015, at 22:19, Ben Bolker <bbolker at gmail.com> wrote:
>>
>> David Barron <dnbarron <at> gmail.com> writes:
>>
>>>
>>> It's in the magrittr package.
>>>
>>> David
>>
>>   It also exists in dplyr.
>>
>>   (I would guess that it's imported/exported from magrittr.)
>>   Although I think the documentation in magrittr is a little better.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From js.huang at protective.com  Wed Feb 18 00:09:44 2015
From: js.huang at protective.com (JS Huang)
Date: Tue, 17 Feb 2015 15:09:44 -0800 (PST)
Subject: [R] Error when I attempt to create a list or a data frame
In-Reply-To: <54DF03D7.2060303@statistik.tu-dortmund.de>
References: <54DE3133.9070809@mindspring.com>
	<54DF03D7.2060303@statistik.tu-dortmund.de>
Message-ID: <1424214584521-4703433.post@n4.nabble.com>

Hi,

  It appears that you used left double quotation marks and right double
quotation marks in your vector for characters.  The first lst assignment is
copied from your post and indicates issues.  I retyped with doulbe quotation
mark and went through fine with the second lst assignment.  Unicode for
double quotation mark is U+0022 and for left double quotation mark U+201C
and right double quotation mark U+201D.  Although they look similar but they
are not the same in unicode.

> lst <- list(c(1,2),TRUE,c(?a?,?b?,?c?)) 
Error: unexpected input in "lst <- list(c(1,2),TRUE,c(?"
> lst <- list(c(1,2),TRUE,c("a","b","c"))
> lst
[[1]]
[1] 1 2

[[2]]
[1] TRUE

[[3]]
[1] "a" "b" "c"




--
View this message in context: http://r.789695.n4.nabble.com/Error-when-I-attempt-to-create-a-list-or-a-data-frame-tp4703251p4703433.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Wed Feb 18 00:35:19 2015
From: js.huang at protective.com (JS Huang)
Date: Tue, 17 Feb 2015 15:35:19 -0800 (PST)
Subject: [R] Re categorizing  components of varaibles
In-Reply-To: <1424209456538-4703424.post@n4.nabble.com>
References: <1424209456538-4703424.post@n4.nabble.com>
Message-ID: <1424216119963-4703434.post@n4.nabble.com>

Hi,

  Here I use the data.frame b as an example to show how it can be
accomplished.  The sixth column of b has values 6 through 996 by an
increment of 10.  The statement
sapply(b[,6],function(x)if(x==6){0}else{if(x==996){2}else{1}}) assigns 0 to
6, 2 to 996 and 1 to the rest in column 6.  In your case you may use

sapply(b[,6],function(x)if(x==24){2}else{if(x==26){3}else{1}})  

(Note: did you forget to assign a value to 25?)

> a <- matrix(1:1000, ncol=10, byrow=TRUE)
> b <- data.frame(a)
> b[,6] <- sapply(b[,6],function(x)if(x==6){0}else{if(x==996){2}else{1}})
> b <- data.frame(a)
> b[,6]
  [1]   6  16  26  36  46  56  66  76  86  96 106 116 126 136 146 156 166
176 186 196 206 216 226 236
 [25] 246 256 266 276 286 296 306 316 326 336 346 356 366 376 386 396 406
416 426 436 446 456 466 476
 [49] 486 496 506 516 526 536 546 556 566 576 586 596 606 616 626 636 646
656 666 676 686 696 706 716
 [73] 726 736 746 756 766 776 786 796 806 816 826 836 846 856 866 876 886
896 906 916 926 936 946 956
 [97] 966 976 986 996
> b[,6] <- sapply(b[,6],function(x)if(x==6){0}else{if(x==996){2}else{1}})
> b[,6]
  [1] 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [50] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [99] 1 2 



--
View this message in context: http://r.789695.n4.nabble.com/Re-categorizing-components-of-varaibles-tp4703424p4703434.html
Sent from the R help mailing list archive at Nabble.com.


From zilefacelvis at yahoo.com  Wed Feb 18 04:46:24 2015
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Wed, 18 Feb 2015 03:46:24 +0000 (UTC)
Subject: [R] Apply t-test on list in R
Message-ID: <2072605676.295192.1424231184985.JavaMail.yahoo@mail.yahoo.com>

I have a list object in R with dataframe names as: 


"pav_DJF_histo.csv"        "pav_DJF_rcp26_2040s.csv" 
"pav_DJF_rcp26_2080s.csv" 
"pav_DJF_rcp45_2040s.csv""pav_DJF_rcp45_2080s.csv" 
"pav_DJF_rcp85_2040s.csv"  "pav_DJF_rcp85_2080s.csv" 



"pav_JJA_histo.csv" 
"pav_JJA_rcp26_2040s.csv"  "pav_JJA_rcp26_2080s.csv" 
"pav_JJA_rcp45_2040s.csv"  "pav_JJA_rcp45_2080s.csv" 
"pav_JJA_rcp85_2040s.csv"    "pav_JJA_rcp85_2080s.csv" 

and so on ... 

I would like to apply a t-test of difference in mean between: 

"pav_DJF_histo.csv" and all dataframes with names having "pav_DJF..." 

the same for 

"pav_JJA_histo.csv" and all dataframes with names having "pav_JJA..." 

and so on... 

There are 84 dataframes in my list. Calculations will be performed as above on all 84 dataframes. 

Thanks for your suggestions. 
Asong. 

Reproducible example for  "pav_DJF_histo.csv" and all dataframes with names having "pav_DJF...". 

Each df has 1 row * 120 columns.  I will like to do element-wise: 

t.test(pav_DJF_histo.csv,all_dataframes) 

structure(list(pav_DJF_histo.csv = structure(list(G100_pav_DJF = 0.0314208328712871, 
G101_pav_DJF = 0.0316052879207921, G102_pav_DJF = 0.0338115233663366, 
G103_pav_DJF = 0.0349753320792079, G104_pav_DJF = 0.0340410627722772, 
G105_pav_DJF = 0.0344961831683168, G106_pav_DJF = 0.0331672699009901, 
G107_pav_DJF = 0.0335578704950495, G108_pav_DJF = 0.0318934661386139, 
G109_pav_DJF = 0.0326319041584158, G110_pav_DJF = 0.0314491928712871, 
G111_pav_DJF = 0.0295078394059406, G112_pav_DJF = 0.0312701207920792, 
G113_pav_DJF = 0.0274926542574257, G114_pav_DJF = 0.0280412045544554, 
G115_pav_DJF = 0.0308147467326733, G116_pav_DJF = 0.0276809968316832, 
G117_pav_DJF = 0.0334523455445545, G118_pav_DJF = 0.0231678550495049, 
G119_pav_DJF = 0.0329736546534653, G120_pav_DJF = 0.0293986465346535, 
GG10_pav_DJF = 0.0272844384158416, GG11_pav_DJF = 0.0250696742574257, 
GG12_pav_DJF = 0.0267913558415842, GG13_pav_DJF = 0.028447095049505, 
GG14_pav_DJF = 0.0258856714851485, GG15_pav_DJF = 0.0284966926732673, 
GG16_pav_DJF = 0.0259450320792079, GG17_pav_DJF = 0.0275422631683168, 
GG18_pav_DJF = 0.0267659001980198, GG19_pav_DJF = 0.0239620502970297, 
GG20_pav_DJF = 0.0235523667326733, GG21_pav_DJF = 0.0280495275247525, 
GG22_pav_DJF = 0.0260046952475248, GG23_pav_DJF = 0.0245813871287129, 
GG24_pav_DJF = 0.0225754382178218, GG25_pav_DJF = 0.0340031586138614, 
GG26_pav_DJF = 0.0281897057425743, GG27_pav_DJF = 0.0290264237623762, 
GG28_pav_DJF = 0.0387512556435644, GG29_pav_DJF = 0.0316748243564356, 
GG30_pav_DJF = 0.0268749459405941, GG31_pav_DJF = 0.0306790738613861, 
GG32_pav_DJF = 0.0265153081188119, GG33_pav_DJF = 0.0287865821782178, 
GG34_pav_DJF = 0.0269848536633663, GG35_pav_DJF = 0.0237527348514851, 
GG36_pav_DJF = 0.0264141081188119, GG37_pav_DJF = 0.0273517104950495, 
GG38_pav_DJF = 0.0299628936633663, GG39_pav_DJF = 0.0275048685148515, 
GG40_pav_DJF = 0.0196275314851485, GG41_pav_DJF = 0.0226415651485149, 
GG42_pav_DJF = 0.0292957691089109, GG43_pav_DJF = 0.0240719154455446, 
GG44_pav_DJF = 0.0264125300990099, GG45_pav_DJF = 0.0245377025742574, 
GG46_pav_DJF = 0.0254801978217822, GG47_pav_DJF = 0.0264283477227723, 
GG48_pav_DJF = 0.0221284198019802, GG49_pav_DJF = 0.0281992881188119, 
GG50_pav_DJF = 0.0251214203960396, GG51_pav_DJF = 0.022804923960396, 
GG52_pav_DJF = 0.0253265572277228, GG53_pav_DJF = 0.0248078140594059, 
GG54_pav_DJF = 0.0229847805940594, GG55_pav_DJF = 0.0245689685148515, 
GG56_pav_DJF = 0.024459103960396, GG57_pav_DJF = 0.0261233461386139, 
GG58_pav_DJF = 0.0248389976237624, GG59_pav_DJF = 0.0238194382178218, 
GG60_pav_DJF = 0.025920022970297, GG61_pav_DJF = 0.0232416265346535, 
GG62_pav_DJF = 0.0254770396039604, GG63_pav_DJF = 0.0248223295049505, 
GG64_pav_DJF = 0.0249457611881188, GG65_pav_DJF = 0.0237617085148515, 
GG66_pav_DJF = 0.023653757029703, GG67_pav_DJF = 0.0225660194059406, 
GG68_pav_DJF = 0.0209042742574257, GG69_pav_DJF = 0.0253348401980198, 
GG70_pav_DJF = 0.0269268635643564, GG71_pav_DJF = 0.0257322499009901, 
GG72_pav_DJF = 0.0261817491089109, GG73_pav_DJF = 0.0267062437623762, 
GG74_pav_DJF = 0.0254928786138614, GG75_pav_DJF = 0.0263220520792079, 
GG76_pav_DJF = 0.0266288738613861, GG77_pav_DJF = 0.0261239605940594, 
GG78_pav_DJF = 0.0239993772277228, GG79_pav_DJF = 0.0158666427722772, 
GG80_pav_DJF = 0.0175424689108911, GG81_pav_DJF = 0.0193922348514851, 
GG82_pav_DJF = 0.0263564615841584, GG83_pav_DJF = 0.0194876946534653, 
GG84_pav_DJF = 0.0253149083168317, GG85_pav_DJF = 0.0250615659405941, 
GG86_pav_DJF = 0.0241572235643564, GG87_pav_DJF = 0.0232231510891089, 
GG88_pav_DJF = 0.027858396039604, GG89_pav_DJF = 0.0271891471287129, 
GG90_pav_DJF = 0.0269782621782178, GG91_pav_DJF = 0.0259993922772277, 
GG92_pav_DJF = 0.0271551689108911, GG93_pav_DJF = 0.0274789423762376, 
GG94_pav_DJF = 0.0246039, GG95_pav_DJF = 0.0314879467326733, 
GG96_pav_DJF = 0.031215642970297, GG97_pav_DJF = 0.0259254443564356, 
GG98_pav_DJF = 0.028124596039604, GG99_pav_DJF = 0.0293694499009901, 
GGG1_pav_DJF = 0.0280423463366337, GGG2_pav_DJF = 0.0266454362376238, 
GGG3_pav_DJF = 0.0262475837623762, GGG4_pav_DJF = 0.0271603285148515, 
GGG5_pav_DJF = 0.026403784950495, GGG6_pav_DJF = 0.026692183960396, 
GGG7_pav_DJF = 0.0281706176237624, GGG8_pav_DJF = 0.0275187194059406, 
GGG9_pav_DJF = 0.0267755964356436), .Names = c("G100_pav_DJF", 
"G101_pav_DJF", "G102_pav_DJF", "G103_pav_DJF", "G104_pav_DJF", 
"G105_pav_DJF", "G106_pav_DJF", "G107_pav_DJF", "G108_pav_DJF", 
"G109_pav_DJF", "G110_pav_DJF", "G111_pav_DJF", "G112_pav_DJF", 
"G113_pav_DJF", "G114_pav_DJF", "G115_pav_DJF", "G116_pav_DJF", 
"G117_pav_DJF", "G118_pav_DJF", "G119_pav_DJF", "G120_pav_DJF", 
"GG10_pav_DJF", "GG11_pav_DJF", "GG12_pav_DJF", "GG13_pav_DJF", 
"GG14_pav_DJF", "GG15_pav_DJF", "GG16_pav_DJF", "GG17_pav_DJF", 
"GG18_pav_DJF", "GG19_pav_DJF", "GG20_pav_DJF", "GG21_pav_DJF", 
"GG22_pav_DJF", "GG23_pav_DJF", "GG24_pav_DJF", "GG25_pav_DJF", 
"GG26_pav_DJF", "GG27_pav_DJF", "GG28_pav_DJF", "GG29_pav_DJF", 
"GG30_pav_DJF", "GG31_pav_DJF", "GG32_pav_DJF", "GG33_pav_DJF", 
"GG34_pav_DJF", "GG35_pav_DJF", "GG36_pav_DJF", "GG37_pav_DJF", 
"GG38_pav_DJF", "GG39_pav_DJF", "GG40_pav_DJF", "GG41_pav_DJF", 
"GG42_pav_DJF", "GG43_pav_DJF", "GG44_pav_DJF", "GG45_pav_DJF", 
"GG46_pav_DJF", "GG47_pav_DJF", "GG48_pav_DJF", "GG49_pav_DJF", 
"GG50_pav_DJF", "GG51_pav_DJF", "GG52_pav_DJF", "GG53_pav_DJF", 
"GG54_pav_DJF", "GG55_pav_DJF", "GG56_pav_DJF", "GG57_pav_DJF", 
"GG58_pav_DJF", "GG59_pav_DJF", "GG60_pav_DJF", "GG61_pav_DJF", 
"GG62_pav_DJF", "GG63_pav_DJF", "GG64_pav_DJF", "GG65_pav_DJF", 
"GG66_pav_DJF", "GG67_pav_DJF", "GG68_pav_DJF", "GG69_pav_DJF", 
"GG70_pav_DJF", "GG71_pav_DJF", "GG72_pav_DJF", "GG73_pav_DJF", 
"GG74_pav_DJF", "GG75_pav_DJF", "GG76_pav_DJF", "GG77_pav_DJF", 
"GG78_pav_DJF", "GG79_pav_DJF", "GG80_pav_DJF", "GG81_pav_DJF", 
"GG82_pav_DJF", "GG83_pav_DJF", "GG84_pav_DJF", "GG85_pav_DJF", 
"GG86_pav_DJF", "GG87_pav_DJF", "GG88_pav_DJF", "GG89_pav_DJF", 
"GG90_pav_DJF", "GG91_pav_DJF", "GG92_pav_DJF", "GG93_pav_DJF", 
"GG94_pav_DJF", "GG95_pav_DJF", "GG96_pav_DJF", "GG97_pav_DJF", 
"GG98_pav_DJF", "GG99_pav_DJF", "GGG1_pav_DJF", "GGG2_pav_DJF", 
"GGG3_pav_DJF", "GGG4_pav_DJF", "GGG5_pav_DJF", "GGG6_pav_DJF", 
"GGG7_pav_DJF", "GGG8_pav_DJF", "GGG9_pav_DJF"), row.names = c(NA, 
-1L), class = "data.frame"), pav_DJF_rcp26_2040s.csv = structure(list( 
G100_pav_DJF = 0.0336921695049505, G101_pav_DJF = 0.0353346894059406, 
G102_pav_DJF = 0.0374039577722772, G103_pav_DJF = 0.0382527494059406, 
G104_pav_DJF = 0.0372147038613861, G105_pav_DJF = 0.036982626039604, 
G106_pav_DJF = 0.0357056598514851, G107_pav_DJF = 0.0367259367326733, 
G108_pav_DJF = 0.0339615762376238, G109_pav_DJF = 0.0352461818316832, 
G110_pav_DJF = 0.0331901645544554, G111_pav_DJF = 0.0327048907425743, 
G112_pav_DJF = 0.0338771433663366, G113_pav_DJF = 0.0304345107425743, 
G114_pav_DJF = 0.0299715592574257, G115_pav_DJF = 0.0323663623267327, 
G116_pav_DJF = 0.0302113144059406, G117_pav_DJF = 0.0348880272772277, 
G118_pav_DJF = 0.0244634474752475, G119_pav_DJF = 0.0356601117821782, 
G120_pav_DJF = 0.0318457833168317, GG10_pav_DJF = 0.0292012213366337, 
GG11_pav_DJF = 0.0276689620792079, GG12_pav_DJF = 0.0293319658910891, 
GG13_pav_DJF = 0.0304862144059406, GG14_pav_DJF = 0.0280408795544554, 
GG15_pav_DJF = 0.0301200932178218, GG16_pav_DJF = 0.0286451583663366, 
GG17_pav_DJF = 0.0300997758415842, GG18_pav_DJF = 0.0288163182673267, 
GG19_pav_DJF = 0.0263369057920792, GG20_pav_DJF = 0.0266477852475248, 
GG21_pav_DJF = 0.0300933431683168, GG22_pav_DJF = 0.0289349790594059, 
GG23_pav_DJF = 0.0268180481683168, GG24_pav_DJF = 0.0244735858415842, 
GG25_pav_DJF = 0.0365696418316832, GG26_pav_DJF = 0.0300007536138614, 
GG27_pav_DJF = 0.0316598915346535, GG28_pav_DJF = 0.0408627464356436, 
GG29_pav_DJF = 0.0336171423762376, GG30_pav_DJF = 0.0293838656930693, 
GG31_pav_DJF = 0.0328603355445545, GG32_pav_DJF = 0.029574533960396, 
GG33_pav_DJF = 0.030923384009901, GG34_pav_DJF = 0.0295480556930693, 
GG35_pav_DJF = 0.0253115618316832, GG36_pav_DJF = 0.0283057747029703, 
GG37_pav_DJF = 0.0302438872277228, GG38_pav_DJF = 0.0321001403465347, 
GG39_pav_DJF = 0.0297127561386139, GG40_pav_DJF = 0.0210915803465347, 
GG41_pav_DJF = 0.0244056779207921, GG42_pav_DJF = 0.0318838803465347, 
GG43_pav_DJF = 0.0262421126237624, GG44_pav_DJF = 0.0286438319306931, 
GG45_pav_DJF = 0.0269299434158416, GG46_pav_DJF = 0.0278216301980198, 
GG47_pav_DJF = 0.0284923436633663, GG48_pav_DJF = 0.024062545, 
GG49_pav_DJF = 0.0297595119306931, GG50_pav_DJF = 0.0267064392079208, 
GG51_pav_DJF = 0.0251601975247525, GG52_pav_DJF = 0.0270363448019802, 
GG53_pav_DJF = 0.027031203960396, GG54_pav_DJF = 0.0253016908415842, 
GG55_pav_DJF = 0.0266129271287129, GG56_pav_DJF = 0.0264486413861386, 
GG57_pav_DJF = 0.0283687212376238, GG58_pav_DJF = 0.0267607587623762, 
GG59_pav_DJF = 0.0258524088118812, GG60_pav_DJF = 0.0284728297029703, 
GG61_pav_DJF = 0.0242683505445545, GG62_pav_DJF = 0.0269807252970297, 
GG63_pav_DJF = 0.0260612163366337, GG64_pav_DJF = 0.0268121706435644, 
GG65_pav_DJF = 0.0254399943069307, GG66_pav_DJF = 0.0256744116831683, 
GG67_pav_DJF = 0.0242163128712871, GG68_pav_DJF = 0.0232865385643564, 
GG69_pav_DJF = 0.027024237970297, GG70_pav_DJF = 0.0280309896039604, 
GG71_pav_DJF = 0.027491227970297, GG72_pav_DJF = 0.0271313031188119, 
GG73_pav_DJF = 0.0286036438118812, GG74_pav_DJF = 0.0282849307920792, 
GG75_pav_DJF = 0.0280740992079208, GG76_pav_DJF = 0.0294208429207921, 
GG77_pav_DJF = 0.0286056740594059, GG78_pav_DJF = 0.0252083457425743, 
GG79_pav_DJF = 0.0171779085148515, GG80_pav_DJF = 0.0187473600495049, 
GG81_pav_DJF = 0.020924249950495, GG82_pav_DJF = 0.0285746283663366, 
GG83_pav_DJF = 0.0212331709405941, GG84_pav_DJF = 0.0275696948019802, 
GG85_pav_DJF = 0.027292552970297, GG86_pav_DJF = 0.0265909641584158, 
GG87_pav_DJF = 0.025798541039604, GG88_pav_DJF = 0.0306168697029703, 
GG89_pav_DJF = 0.0303202963861386, GG90_pav_DJF = 0.0291813004950495, 
GG91_pav_DJF = 0.0280794616831683, GG92_pav_DJF = 0.0299837882673267, 
GG93_pav_DJF = 0.0299919872772277, GG94_pav_DJF = 0.0269039003465347, 
GG95_pav_DJF = 0.0339354712376238, GG96_pav_DJF = 0.0325601980693069, 
GG97_pav_DJF = 0.0285637703465347, GG98_pav_DJF = 0.0313221871782178, 
GG99_pav_DJF = 0.0323324087128713, GGG1_pav_DJF = 0.0298989088118812, 
GGG2_pav_DJF = 0.0290734964356436, GGG3_pav_DJF = 0.0281705633663366, 
GGG4_pav_DJF = 0.0291793695544554, GGG5_pav_DJF = 0.0279056234653465, 
GGG6_pav_DJF = 0.0281455424752475, GGG7_pav_DJF = 0.0309308349009901, 
GGG8_pav_DJF = 0.0294452942574257, GGG9_pav_DJF = 0.0289754272277228), .Names = c("G100_pav_DJF", 
"G101_pav_DJF", "G102_pav_DJF", "G103_pav_DJF", "G104_pav_DJF", 
"G105_pav_DJF", "G106_pav_DJF", "G107_pav_DJF", "G108_pav_DJF", 
"G109_pav_DJF", "G110_pav_DJF", "G111_pav_DJF", "G112_pav_DJF", 
"G113_pav_DJF", "G114_pav_DJF", "G115_pav_DJF", "G116_pav_DJF", 
"G117_pav_DJF", "G118_pav_DJF", "G119_pav_DJF", "G120_pav_DJF", 
"GG10_pav_DJF", "GG11_pav_DJF", "GG12_pav_DJF", "GG13_pav_DJF", 
"GG14_pav_DJF", "GG15_pav_DJF", "GG16_pav_DJF", "GG17_pav_DJF", 
"GG18_pav_DJF", "GG19_pav_DJF", "GG20_pav_DJF", "GG21_pav_DJF", 
"GG22_pav_DJF", "GG23_pav_DJF", "GG24_pav_DJF", "GG25_pav_DJF", 
"GG26_pav_DJF", "GG27_pav_DJF", "GG28_pav_DJF", "GG29_pav_DJF", 
"GG30_pav_DJF", "GG31_pav_DJF", "GG32_pav_DJF", "GG33_pav_DJF", 
"GG34_pav_DJF", "GG35_pav_DJF", "GG36_pav_DJF", "GG37_pav_DJF", 
"GG38_pav_DJF", "GG39_pav_DJF", "GG40_pav_DJF", "GG41_pav_DJF", 
"GG42_pav_DJF", "GG43_pav_DJF", "GG44_pav_DJF", "GG45_pav_DJF", 
"GG46_pav_DJF", "GG47_pav_DJF", "GG48_pav_DJF", "GG49_pav_DJF", 
"GG50_pav_DJF", "GG51_pav_DJF", "GG52_pav_DJF", "GG53_pav_DJF", 
"GG54_pav_DJF", "GG55_pav_DJF", "GG56_pav_DJF", "GG57_pav_DJF", 
"GG58_pav_DJF", "GG59_pav_DJF", "GG60_pav_DJF", "GG61_pav_DJF", 
"GG62_pav_DJF", "GG63_pav_DJF", "GG64_pav_DJF", "GG65_pav_DJF", 
"GG66_pav_DJF", "GG67_pav_DJF", "GG68_pav_DJF", "GG69_pav_DJF", 
"GG70_pav_DJF", "GG71_pav_DJF", "GG72_pav_DJF", "GG73_pav_DJF", 
"GG74_pav_DJF", "GG75_pav_DJF", "GG76_pav_DJF", "GG77_pav_DJF", 
"GG78_pav_DJF", "GG79_pav_DJF", "GG80_pav_DJF", "GG81_pav_DJF", 
"GG82_pav_DJF", "GG83_pav_DJF", "GG84_pav_DJF", "GG85_pav_DJF", 
"GG86_pav_DJF", "GG87_pav_DJF", "GG88_pav_DJF", "GG89_pav_DJF", 
"GG90_pav_DJF", "GG91_pav_DJF", "GG92_pav_DJF", "GG93_pav_DJF", 
"GG94_pav_DJF", "GG95_pav_DJF", "GG96_pav_DJF", "GG97_pav_DJF", 
"GG98_pav_DJF", "GG99_pav_DJF", "GGG1_pav_DJF", "GGG2_pav_DJF", 
"GGG3_pav_DJF", "GGG4_pav_DJF", "GGG5_pav_DJF", "GGG6_pav_DJF", 
"GGG7_pav_DJF", "GGG8_pav_DJF", "GGG9_pav_DJF"), row.names = c(NA, 
-1L), class = "data.frame")), .Names = c("pav_DJF_histo.csv", 
"pav_DJF_rcp26_2040s.csv"))


From tmrsg11 at gmail.com  Wed Feb 18 04:53:44 2015
From: tmrsg11 at gmail.com (C W)
Date: Tue, 17 Feb 2015 22:53:44 -0500
Subject: [R] Numerical stability of eigenvalue and hessian matrix in R
Message-ID: <CAE2FW2kdjK6-0eeQ4w7_7VEk1PsUfiZY31meQVTEwcmZW24bXg@mail.gmail.com>

Hi list,

I am running the following R code, the answer should be zero.  But R gives
a very small negative number, what should I do?

##R code

library(numDeriv)

h_x <- function(x){
   a = x[1]
   b = x[2]
   c = x[3]
   d = x[4]
   (a^2 + c^2 + d^2) * (b^2 + c^2 + d^2)
}

x1 = 10
x2 = 1
x3 = 0
x4 = 10
x = c(x1, x2, x3, x4)
hess.h <- hessian(func = h_x, x)
mat <- h_x(x)*hess.h - grad(h_x, x) %o% grad(h_x, x)

> mat

              [,1]          [,2]          [,3]          [,4]

[1,]  4.059961e-05 -3.038031e-04 -1.307195e-02 -4.080400e+06

[2,] -3.038031e-04  7.920000e+06 -2.663690e-02 -1.600000e+06

[3,] -1.307195e-02 -2.663690e-02  1.216065e+07  1.331894e-02

[4,] -4.080400e+06 -1.600000e+06  1.331894e-02 -7.920000e+06


# A lot of the elements should be zero, for example the first one.  I will
change them manually.

m = ifelse(abs(mat)< 0.1, 0, mat)

eigen(m)$val

[1] 12160648  8103268  1665782 -9769050

> sum(eigen(m)$val[2:4])

[1] -0.0005430793

## End of R code


The last answer above should be zero, but it's appearing as a very small
negative number.  How should I deal with it?

Thanks lots,

Mike

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Wed Feb 18 05:03:20 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 17 Feb 2015 22:03:20 -0600
Subject: [R] %>%
In-Reply-To: <54E3D687.3020007@fredhutch.org>
References: <CAO06FDdCLViGuwgVUuSTA8uhjz4YtSf-hVNkNW3x+jBbgL9C6w@mail.gmail.com>
	<CAHuze_+AQY7ssuVmdz2D695nFxshbfhud5jRDD_oaF7un1QNMA@mail.gmail.com>
	<loom.20150217T221829-902@post.gmane.org>
	<C0576650-F58C-4CE4-B06F-529591A3FD0A@univie.ac.at>
	<54E3D687.3020007@fredhutch.org>
Message-ID: <CABdHhvGNFm8x9DzpPP65cRy-H=g+ixi1d6=_LM0a-4ji2fHjHw@mail.gmail.com>

On Tue, Feb 17, 2015 at 6:02 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
> On 02/17/2015 02:10 PM, Erich Neuwirth wrote:
>>
>> AFAIK dplyr imports magrtittr.
>> So dplyr ses %>% from migrittr, it does not have its own version.
>
> But it has its own man page so who knows?

If you import and re-export a function from another package, you have
to document it, even if it's already documented elsewhere.

Hadley

-- 
http://had.co.nz/


From Peter.Alspach at plantandfood.co.nz  Wed Feb 18 05:59:37 2015
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Wed, 18 Feb 2015 17:59:37 +1300
Subject: [R] Bayesian Networks
In-Reply-To: <CAH8E6UsQEuxtN56+y9YOUHui+Mp2h+ivuHErKz_iubL+9k7RCg@mail.gmail.com>
References: <CAH8E6UsQEuxtN56+y9YOUHui+Mp2h+ivuHErKz_iubL+9k7RCg@mail.gmail.com>
Message-ID: <E41B375B7520DE4A8C60781AC60B754501A8EFE497@AKLEXM01.PFR.CO.NZ>

Tena koe Elias

Googling 'Bayesian Networks in R' brings up several packages, so the answer appears to be 'Yes'.  Whether any of them are relevant to you is another question.

HTH ....

Peter Alspach

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Elias Carvalho
Sent: Wednesday, 18 February 2015 1:25 p.m.
To: r-help at r-project.org
Subject: [R] Bayesian Networks

Has somebody implemented Bayesian Networks in R ?

--
Best regards... 8^)

?*A mente que se abre a novas ideias jamais voltar? * *a seu tamanho original*?  *Albert Einstein*


_____________________________________________
Prof. Elias C?sar Ara?jo de Carvalho
CV: http://lattes.cnpq.br/4248328961021251

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The contents of this e-mail are confidential and may be subject to legal privilege.
 If you are not the intended recipient you must not use, disseminate, distribute or
 reproduce all or any part of this e-mail or attachments.  If you have received this
 e-mail in error, please notify the sender and delete all material pertaining to this
 e-mail.  Any opinion or views expressed in this e-mail are those of the individual
 sender and may not represent those of The New Zealand Institute for Plant and
 Food Research Limited.

From hpages at fredhutch.org  Wed Feb 18 07:00:10 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 17 Feb 2015 22:00:10 -0800
Subject: [R] %>%
In-Reply-To: <CABdHhvGNFm8x9DzpPP65cRy-H=g+ixi1d6=_LM0a-4ji2fHjHw@mail.gmail.com>
References: <CAO06FDdCLViGuwgVUuSTA8uhjz4YtSf-hVNkNW3x+jBbgL9C6w@mail.gmail.com>
	<CAHuze_+AQY7ssuVmdz2D695nFxshbfhud5jRDD_oaF7un1QNMA@mail.gmail.com>
	<loom.20150217T221829-902@post.gmane.org>
	<C0576650-F58C-4CE4-B06F-529591A3FD0A@univie.ac.at>
	<54E3D687.3020007@fredhutch.org>
	<CABdHhvGNFm8x9DzpPP65cRy-H=g+ixi1d6=_LM0a-4ji2fHjHw@mail.gmail.com>
Message-ID: <54E42A6A.2080402@fredhutch.org>

On 02/17/2015 08:03 PM, Hadley Wickham wrote:
> On Tue, Feb 17, 2015 at 6:02 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
>> On 02/17/2015 02:10 PM, Erich Neuwirth wrote:
>>>
>>> AFAIK dplyr imports magrtittr.
>>> So dplyr ses %>% from migrittr, it does not have its own version.
>>
>> But it has its own man page so who knows?
>
> If you import and re-export a function from another package, you have
> to document it, even if it's already documented elsewhere.

Maybe I should have said: But it has its own man page that doesn't make
any mention of the primary man page so who knows?

H.

>
> Hadley
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From brc.khi at gmail.com  Wed Feb 18 05:02:58 2015
From: brc.khi at gmail.com (BRC)
Date: Wed, 18 Feb 2015 09:02:58 +0500
Subject: [R] faisalconjoint
Message-ID: <CAF54Rnp_vAyb+ryQEPvQijJAH1j7xqaQdaxzuK3KFV4zRw-FUw@mail.gmail.com>

I am developing a r package faisalconjoint, when i run R CMD check
--as-cran faisalconjoint, got the following notes.

* using log directory
'D:/r-test-packages/faisalconjoint/faisalconjoint.Rcheck'
* using R version 3.1.2 (2014-10-31)
* using platform: i386-w64-mingw32 (32-bit)
* using session charset: ISO8859-1
* checking for file 'faisalconjoint/DESCRIPTION' ... OK
* checking extension type ... Package
* this is package 'faisalconjoint' version '1.15'
* checking CRAN incoming feasibility ... NOTE
Maintainer: 'Faisal Afzal Siddiqui <brc.khi at gmail.com>'
New submission
Package was archived on CRAN
* checking package namespace information ... OK
* checking package dependencies ... NOTE
  No repository set, so cyclic dependency check skipped
* checking if this is a source package ... OK
* checking if there is a namespace ... OK
* checking for executable files ... OK
* checking for hidden files and directories ... OK
* checking for portable file names ... OK
* checking whether package 'faisalconjoint' can be installed ... OK
* checking installed package size ... OK
* checking package directory ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... NOTE
Non-standard file/directory found at top level:
  'faisalconjoint-manual.pdf'
* checking for left-over files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for non-ASCII characters ... OK
* checking R files for syntax errors ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the package can be unloaded cleanly ... OK
* checking whether the namespace can be loaded with stated dependencies ...
OK
* checking whether the namespace can be unloaded cleanly ... OK
* checking loading without being on the library search path ... OK
* checking dependencies in R code ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... OK
* checking Rd files ... OK
* checking Rd metadata ... OK
* checking Rd line widths ... OK
* checking Rd cross-references ... OK
* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... OK
* checking Rd \usage sections ... OK
* checking Rd contents ... OK
* checking for unstated dependencies in examples ... OK
* checking contents of 'data' directory ... OK
* checking data for non-ASCII characters ... OK
* checking data for ASCII and uncompressed saves ... OK
* checking examples ... OK
* checking PDF version of manual ... OK
* DONE
NOTE: There were 3 notes.

1. No repository set, so cyclic dependency check skipped
2. Non-standard file/directory found at top level:
 'faisalconjoint-manual.pdf'

please advise how I can remove these notes to upload the package.

I will be very thankful to you.

	[[alternative HTML version deleted]]


From js.huang at protective.com  Wed Feb 18 03:29:52 2015
From: js.huang at protective.com (JS Huang)
Date: Tue, 17 Feb 2015 18:29:52 -0800 (PST)
Subject: [R] sd, mean with a frequency distribution matrix
In-Reply-To: <1424093059993-4703338.post@n4.nabble.com>
References: <1423837352778-4703218.post@n4.nabble.com>
	<1423843168900-4703220.post@n4.nabble.com>
	<1423862549747-4703231.post@n4.nabble.com>
	<1423907311273-4703259.post@n4.nabble.com>
	<1424093059993-4703338.post@n4.nabble.com>
Message-ID: <1424226592931-4703441.post@n4.nabble.com>

Hi,

  Just learned another way to calculate sd for a frequency distribution
matrix:

> p <- matrix(c(10,3,20,4,30,5),ncol=2,byrow=TRUE)
> p
     [,1] [,2]
[1,]   10    3
[2,]   20    4
[3,]   30    5
> rep(p[,1],p[,2])
 [1] 10 10 10 20 20 20 20 30 30 30 30 30
> sd(rep(p[,1],p[,2]))
[1] 8.348471



--
View this message in context: http://r.789695.n4.nabble.com/sd-mean-with-a-frequency-distribution-matrix-tp4703218p4703441.html
Sent from the R help mailing list archive at Nabble.com.


From bhh at xs4all.nl  Wed Feb 18 08:47:34 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 18 Feb 2015 08:47:34 +0100
Subject: [R] faisalconjoint
In-Reply-To: <CAF54Rnp_vAyb+ryQEPvQijJAH1j7xqaQdaxzuK3KFV4zRw-FUw@mail.gmail.com>
References: <CAF54Rnp_vAyb+ryQEPvQijJAH1j7xqaQdaxzuK3KFV4zRw-FUw@mail.gmail.com>
Message-ID: <ED731748-4730-416B-8D24-FFD50B143C95@xs4all.nl>


> On 18-02-2015, at 05:02, BRC <brc.khi at gmail.com> wrote:
> 
> I am developing a r package faisalconjoint, when i run R CMD check
> --as-cran faisalconjoint, got the following notes.
> 
> * using log directory
> 'D:/r-test-packages/faisalconjoint/faisalconjoint.Rcheck'
> * using R version 3.1.2 (2014-10-31)
> * using platform: i386-w64-mingw32 (32-bit)
> * using session charset: ISO8859-1
> * checking for file 'faisalconjoint/DESCRIPTION' ... OK
> * checking extension type ... Package
> * this is package 'faisalconjoint' version '1.15'
> * checking CRAN incoming feasibility ... NOTE
> Maintainer: 'Faisal Afzal Siddiqui <brc.khi at gmail.com>'
> New submission
> Package was archived on CRAN
> * checking package namespace information ... OK
> * checking package dependencies ... NOTE
>  No repository set, so cyclic dependency check skipped
> * checking if this is a source package ... OK
> * checking if there is a namespace ... OK
> * checking for executable files ... OK
> * checking for hidden files and directories ... OK
> * checking for portable file names ... OK
> * checking whether package 'faisalconjoint' can be installed ... OK
> * checking installed package size ... OK
> * checking package directory ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... NOTE
> Non-standard file/directory found at top level:
>  'faisalconjoint-manual.pdf'
> * checking for left-over files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies ... OK
> * checking whether the package can be unloaded cleanly ... OK
> * checking whether the namespace can be loaded with stated dependencies ...
> OK
> * checking whether the namespace can be unloaded cleanly ... OK
> * checking loading without being on the library search path ... OK
> * checking dependencies in R code ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... OK
> * checking Rd files ... OK
> * checking Rd metadata ... OK
> * checking Rd line widths ... OK
> * checking Rd cross-references ... OK
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking for unstated dependencies in examples ... OK
> * checking contents of 'data' directory ... OK
> * checking data for non-ASCII characters ... OK
> * checking data for ASCII and uncompressed saves ... OK
> * checking examples ... OK
> * checking PDF version of manual ... OK
> * DONE
> NOTE: There were 3 notes.
> 
> 1. No repository set, so cyclic dependency check skipped

Google for :  ?No repository set, so cyclic dependency check skipped?
and you will see this:

http://stackoverflow.com/questions/23164929/note-in-r-cran-check-no-repository-set-so-cyclic-dependency-check-skipped

> 2. Non-standard file/directory found at top level:
> 'faisalconjoint-manual.pdf?
> 

Obvious: remove file/directory or clean source directory perhaps?
And if you need file/directory then read the "Writing R Extensions? manual.

> please advise how I can remove these notes to upload the package.
> 

AFAIK you can ignore the note about the maintainer.

Berend

> I will be very thankful to you.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Alexander.Herr at csiro.au  Wed Feb 18 10:39:57 2015
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Wed, 18 Feb 2015 09:39:57 +0000
Subject: [R] expressions from dataframe columns
Message-ID: <DE9431576890DA46BC57EA03BC10449B9BD67B89@exmbx06-cdc.nexus.csiro.au>

Hi List,

I am trying to assign a large expression. It has about 140 lines of code, so
of course this is cumbersome:

list('10001'=list(panel=c(PanelOne=944), seltype='Equal'),
'10002'=list(panel=c(PanelOne=454), seltype='Equal'),
'10003'=list(panel=c(PanelOne=1210), seltype='Equal'),
'10004'=list(panel=c(PanelOne=1), seltype='Equal'),
......
''640'=list(panel=c(PanelOne=1), seltype='Equal'))->test

The numbers in the expression come from within a dataframe:
layer          re1
10001       944
10002       454
10003       1210
10004       1
...
640           1

so in theory one should be able to construct this within R with something
like paste and cat. However, all my attempts have swarted me. 

Any  suggestions?

Thanks
Herry

From jjanue.n at tv3.cat  Wed Feb 18 11:59:56 2015
From: jjanue.n at tv3.cat (Janue Miret, Jofre)
Date: Wed, 18 Feb 2015 10:59:56 +0000
Subject: [R] info markers from plotgoogMaps
Message-ID: <CC0C03B44EA34848831811718D11BBF664E0DAB4@MAILBOX-3.ad-ccrtv.local>

Solution: 


http://stackoverflow.com/questions/28447247/change-in-google-maps-api-v3-on-feb-10-2015-breaks-existing-maps-created-using

https://maps.google.com/maps/api/js?sensor=false&v=3.18


________________________________________
De: Janue Miret, Jofre
Enviat el: diumenge, 15 / febrer / 2015 16:22
Per a: John Kane; 'r-help at r-project.org'
Tema: RE: [R] info markers from plotgoogMaps

this is an exemple:

library(plotGoogleMaps)
data(meuse)
coordinates(meuse)<-~x+y # convert to SPDF
proj4string(meuse) <- CRS('+init=epsg:28992')
# Adding Coordinate Referent Sys.
# Create web map of Point data
m<-plotGoogleMaps(meuse,filename='myMap1.htm')



________________________________________
De: John Kane [jrkrideau at inbox.com]
Enviat el: diumenge, 15 / febrer / 2015 15:53
Per a: Janue Miret, Jofre; 'r-help at r-project.org'
Tema: RE: [R] info markers from plotgoogMaps

ttps://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jjanue.n at tv3.cat
> Sent: Sun, 15 Feb 2015 11:40:39 +0000
> To: r-help at r-project.org
> Subject: [R] info markers from plotgoogMaps
>
> Anyone Knows why doesn't refresh the data  InfoBox (infowindow) from map
> markers googlempas? There is always the first selection info data.
> That's happen since last Friday 13th wiht googlempas from plotGoogleMaps.
> There is any solution please?
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
Check it out at http://www.inbox.com/earth




From murdoch.duncan at gmail.com  Wed Feb 18 12:10:57 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 18 Feb 2015 06:10:57 -0500
Subject: [R] %>%
In-Reply-To: <CABdHhvGNFm8x9DzpPP65cRy-H=g+ixi1d6=_LM0a-4ji2fHjHw@mail.gmail.com>
References: <CAO06FDdCLViGuwgVUuSTA8uhjz4YtSf-hVNkNW3x+jBbgL9C6w@mail.gmail.com>	<CAHuze_+AQY7ssuVmdz2D695nFxshbfhud5jRDD_oaF7un1QNMA@mail.gmail.com>	<loom.20150217T221829-902@post.gmane.org>	<C0576650-F58C-4CE4-B06F-529591A3FD0A@univie.ac.at>	<54E3D687.3020007@fredhutch.org>
	<CABdHhvGNFm8x9DzpPP65cRy-H=g+ixi1d6=_LM0a-4ji2fHjHw@mail.gmail.com>
Message-ID: <54E47341.7090409@gmail.com>

On 17/02/2015 11:03 PM, Hadley Wickham wrote:
> On Tue, Feb 17, 2015 at 6:02 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
>> On 02/17/2015 02:10 PM, Erich Neuwirth wrote:
>>>
>>> AFAIK dplyr imports magrtittr.
>>> So dplyr ses %>% from migrittr, it does not have its own version.
>>
>> But it has its own man page so who knows?
> 
> If you import and re-export a function from another package, you have
> to document it, even if it's already documented elsewhere.
> 
> Hadley
> 

The promptImport() function generates boilerplate documentation that
links to the original docs.  (I notice it doesn't escape % properly, so
the generated page for "%>%" wouldn't work; sigh.)

Duncan Murdoch


From nashjc at uottawa.ca  Wed Feb 18 15:07:29 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Wed, 18 Feb 2015 09:07:29 -0500
Subject: [R] multiple parameter optimization with optim()
In-Reply-To: <mailman.1.1424257202.2915.r-help@r-project.org>
References: <mailman.1.1424257202.2915.r-help@r-project.org>
Message-ID: <54E49CA1.1050709@uottawa.ca>

Some observations -- no solution here though:

1) the code is not executable. I tried. Maybe that makes it reproducible!
    Typos such as "stat mod", undefined Q etc.

2) My experience is that any setup with a ?apply approach that doesn't
then check to see that the structure of the data is correct has a high
probability of failure due to mismatch with the optimizer requirements.
It's worth being VERY pedestrian in setting up optimization functions
and checking obsessively that you get what you expect and that there are
no regions you are likely to wander into with divide by 0,
log(negative), etc.

3) optim() is a BAD choice here. I wrote the source for three of the
codes, and the one most appropriate for many parameters (CG) I have been
deprecating for about 30 years. Use Rcgmin or something else
instead.

4) If possible, analytic gradients are needed for CG like codes. You
probably need to dig out some source code for dbinom() to do this, but
your function is not particularly complicated, and doesn't have "if"
statements etc. However, you could test a case using the numDeriv
gradient that is an option for Rcgmin, but it will be painfully slow.
For a one-off computation, that may still be acceptable.

JN

On 15-02-18 06:00 AM, r-help-request at r-project.org wrote:
> Message: 37
> Date: Tue, 17 Feb 2015 23:03:24 +0000
> From: "Doran, Harold" <HDoran at air.org>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] multiple parameter optimization with optim()
> Message-ID: <D10931E1.23C0E%hdoran at air.org>
> Content-Type: text/plain; charset="UTF-8"
> 
> I am trying to generalize a working piece of code for a single parameter to a multiple parameter problem. Reproducible code is below. The parameters to be estimated are a, b, and c. The estimation problem is such that there is one set of a, b, c parameters for each column of the data. Hence, in this sample data with 20 columns, there are 20 a params, 20 b-params, and 20 c-params.
> 
> Because I am estimating so many parameters, I am not certain that I have indicated to the function properly the right number of params to estimate and also if I have generated starting values in a sufficient way.
> 
> Thanks for any help.
> Harold
> 
> dat <- replicate(20, sample(c(0,1), 2000, replace = T))
> library(stat mod)
> qq <- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma = 1)
> nds <- qq$nodes
> wts <- qq$weights
> fn <- function(params){
> a <- params[1:ncol(dat)]
> b <- params[1:ncol(dat)]
> c <- params[1:ncol(dat)]
> L <- sapply(1:ncol(dat), function(i) dbinom(dat[,i], 1, c + ((1 - c)/(1 + exp(-1.7 * a * (nds[i] - b)))) * wts[i]))
> r1 <- prod(colSums(L * wts))
> -log(r1)
> }
> startVal <- rep(.5, ncol(dat))
> opt <- optim(startVal, fn)
> 
> 	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Feb 18 15:36:03 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 18 Feb 2015 14:36:03 +0000
Subject: [R] Numerical stability of eigenvalue and hessian matrix in R
References: <CAE2FW2kdjK6-0eeQ4w7_7VEk1PsUfiZY31meQVTEwcmZW24bXg@mail.gmail.com>
Message-ID: <loom.20150218T152343-943@post.gmane.org>

C W <tmrsg11 <at> gmail.com> writes:

> 
> Hi list,
> 
> I am running the following R code, the answer should be zero.  But R gives
> a very small negative number, what should I do?
> 
> ##R code
> 
library(numDeriv)
 
h_x <- function(x){
   a = x[1]
   b = x[2]
   c = x[3]
   d = x[4]
    (a^2 + c^2 + d^2) * (b^2 + c^2 + d^2)
}

x1 = 10
x2 = 1
x3 = 0
x4 = 10
x = c(x1, x2, x3, x4)
hess.h <- hessian(func = h_x, x)
mat <- h_x(x)*hess.h - grad(h_x, x) %o% grad(h_x, x)

m <- zapsmall(mat)

sum(eigen(m)$val[2:4])

I get a much smaller answer than you do (several orders of magnitude):

[1] 2.421439e-08
    
This is with: 

 R Under development (unstable) (2015-02-11 r67792)
Platform: i686-pc-linux-gnu (32-bit)
Running under: Ubuntu precise (12.04.5 LTS)
numDeriv_2012.9-1

  However, you mostly have to learn to deal with the
inherent imprecision of floating-point calculations.
It's hard to tell without any further context, but there
may be a more numerically stable way to do what you want.

> [1] 12160648  8103268  1665782 -9769050
> 
> > sum(eigen(m)$val[2:4])
> 
> [1] -0.0005430793
> 
> ## End of R code
> 
> The last answer above should be zero, but it's appearing as a very small
> negative number.  How should I deal with it?
> 
> Thanks lots,
> 
> Mike
> 
> 	[[alternative HTML version deleted]]
> 
>


From simon.gingins at unine.ch  Wed Feb 18 10:42:31 2015
From: simon.gingins at unine.ch (Simon Gingins)
Date: Wed, 18 Feb 2015 10:42:31 +0100
Subject: [R] coxphw with categorical explanatory variables
Message-ID: <0DA15236-7C0C-4E8A-93DA-F84A62F098E6@unine.ch>

Dear R helpers,

I am currently trying to analyze data with a cox proportional hazard survival analysis. For one of my datasets, the proportional hazards assumption is violated. Reading the literature, it seems that the weighted version of cox PH (function coxphw() ) is a good alternative in case of non proportional hazards. However, the function coxphw() does not seem to take categorical explanatory variables and I cannot figure out the reason why. Is there a statistical reason for that? Could you help me please?

In a few words, my data represents 6 species of fishes (~16 individuals per species) tested for their reaction towards novel objects. The response variable is the time to approach the novel object (the experiments was stopped after 5 minutes, so the data is right censored) ad the explanatory variable is species identity. When I run a coxph() model in R, it works with no problems (model1 below). If I run the same model but with the coxphw() function instead of the coxph() it gives me an error message (model2 below). If I coerce the explanatory variable into a numeric format, it also works (model3 below). However, I am not sure this last approach is appropriate, as I guess there must be a reason why coxphw() cannot deal with my response variable in the categorical (factor) format. Can anyone explain?


> model1 <- coxph(Surv(time=O1_approach_sec, event=O1_approach) ~ species, data=personew)
> model2 <- coxphw(Surv(time=O1_approach_sec, event=O1_approach) ~ species,  data=personew, AHR=T)
Erreur dans weights[, 1] : indice hors limites
> model3 <- coxphw(Surv(time=O1_approach_sec, event=O1_approach) ~ as.numeric(species),  data=personew, AHR=T)


Best regards

Simon
___________________________
Simon Gingins
PhD student

University of Neuch?tel
Institute of Biology
Department of Behavioural Ecology
Rue Emile-Argand 11
2000 Neuch?tel
Switzerland

Office: +41 32 718 31 09
research: http://www2.unine.ch/ethol/gingins_simon
photos: www.simongingins.com












	[[alternative HTML version deleted]]


From mittal.ashra at yahoo.com  Wed Feb 18 12:44:05 2015
From: mittal.ashra at yahoo.com (Mittal Ashra)
Date: Wed, 18 Feb 2015 11:44:05 +0000 (UTC)
Subject: [R] API request from R
Message-ID: <275519756.3638634.1424259845282.JavaMail.yahoo@mail.yahoo.com>

Dear All,
Apologies for mailing it to the whole crowd. This is Mittal, presently working in a Project where we have build a platform for displaying recommendations and the results are based on the statistical models.?
I have gone through the CRAN repository to look out for an package which converts the R code into an JAVA API and that can be called from the platform. However, did not find any. If anyone can guide me to the right package that will be grateful.?
The packages can be similar to DeployR from Revolution Analytics.
RegardsMittal
	[[alternative HTML version deleted]]


From knut.hansen at uit.no  Wed Feb 18 14:01:33 2015
From: knut.hansen at uit.no (Knut Hansen)
Date: Wed, 18 Feb 2015 14:01:33 +0100
Subject: [R] Substituting elements in vector
In-Reply-To: <C45114AA-E5A1-4492-AEC6-8A30C5404E24@comcast.net>
References: <20061976.pLLQpT2cMr@ws-ism-knuth.fm.uit.no>
	<C45114AA-E5A1-4492-AEC6-8A30C5404E24@comcast.net>
Message-ID: <3683361.BS2OzK0YU8@ws-ism-knuth.fm.uit.no>

Tirsdag 17. februar 2015 15.50.27 skrev David Winsemius:
> On Feb 17, 2015, at 3:58 AM, Knut Hansen wrote:
> > Dear list,
> > 
> > I have a vector:
> > my.vector <- c("A", "B", "C", "D", "E", "F", "G")
> > 
> > and two other:
> > vec1 <- c("p", "q", "r", "s", "t")
> > vec2 <- c("x", "y", "z")
> > 
> > I want to substitute elements "b" and "e" in my.vector with vectors vec1
> > and vec2 respectively so that the result becomes the vector:
> > c("A", "p", "q", "r" , "s" , "t", "C" , "D", "x", "y", "z", "F", "G")
> > 
> > my.vlist <- setNames(as.list(my.vector),my.vector)
> > replist <- list(B=vec1, E=vec2)
> > my.vlist[c("B","E")] <- replist
> > unlist(my.vlist)
> 
>   A  B1  B2  B3  B4  B5   C   D  E1  E2  E3   F   G
> "A" "p" "q" "r" "s" "t" "C" "D" "x" "y" "z" "F" "G"
> 
> Could also have used:
> 
> my.vlist[ names(replist) ] <- replist
> 
> .... which I think illustrates the value of character indexing of lists for
> assignment even better.
> > The ordering of the elements is important.
> > 
> > Knut Hansen
> 
> David Winsemius
> Alameda, CA, USA

Thank you. This was what I was looking for. I was not aware of named lists in 
R, and I was about to write a script in Python to fix this.

Knut Hansen


From js.huang at protective.com  Wed Feb 18 15:13:26 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 18 Feb 2015 06:13:26 -0800 (PST)
Subject: [R] Numerical stability of eigenvalue and hessian matrix in R
In-Reply-To: <CAE2FW2kdjK6-0eeQ4w7_7VEk1PsUfiZY31meQVTEwcmZW24bXg@mail.gmail.com>
References: <CAE2FW2kdjK6-0eeQ4w7_7VEk1PsUfiZY31meQVTEwcmZW24bXg@mail.gmail.com>
Message-ID: <1424268806967-4703456.post@n4.nabble.com>

Hi,

  Since all entries in your hessian matrix and grad vector are integers, I
suggest you execute the following for mat assignment.

> mat <- round(h_x(x),digits=0)*round(hess.h,digits=0) - round(grad(h_x,
> x),digits=0) %o% round(grad(h_x, x),digits=0) 
> mat
         [,1]     [,2]     [,3]     [,4]
[1,]        0        0        0 -4080400
[2,]        0  7920000        0 -1600000
[3,]        0        0 12160400        0
[4,] -4080400 -1600000        0 -7920000



--
View this message in context: http://r.789695.n4.nabble.com/Numerical-stability-of-eigenvalue-and-hessian-matrix-in-R-tp4703443p4703456.html
Sent from the R help mailing list archive at Nabble.com.


From aron.lindberg at case.edu  Wed Feb 18 17:12:12 2015
From: aron.lindberg at case.edu (Aron Lindberg)
Date: Wed, 18 Feb 2015 08:12:12 -0800 (PST)
Subject: [R] How do I know which package is loaded?
Message-ID: <1424275931831.ea036b71@Nodemailer>

Hi All,


In short: what?s a good workflow for forking/rewriting/testing code in packages?


I?m trying to contribute to a package on Github. So I fork it and then clone my forked repo into my desktop, and then I open the files I want to edit in RStudio.


However, to actually test that the code works, I need to load the package from the local version on my machine. I think I can do this using:


library(rgithub, lib.loc = ?/Users/Aron/github/local/rgithub/?)


However, this fails:


Error in library(rgithub, lib.loc = ?/Users/Aron/github/local/?) :
? there is no package called ?rgithub?


Do I need to install the library from the local repo first somehow? How do I do this?


If I got it to work I assume I would be able to run


sessionInfo()


Which would then enable me to see which version of the package is loaded. However, the version number would be the same as the package that I can install using devtools, e.g. devtools::install_github(?cscheid/rgithub?. How can I check whether I have loaded my local development copy or the ?official? copy that I also have on my machine?


In short: what?s a good workflow for forking/rewriting/testing code in packages?


Best,
Aron


--?
Aron Lindberg


Doctoral Candidate,?Information Systems
Weatherhead School of Management?
Case Western Reserve University
aronlindberg.github.io
	[[alternative HTML version deleted]]


From tmrsg11 at gmail.com  Wed Feb 18 17:44:57 2015
From: tmrsg11 at gmail.com (C W)
Date: Wed, 18 Feb 2015 11:44:57 -0500
Subject: [R] Numerical stability of eigenvalue and hessian matrix in R
In-Reply-To: <1424268806967-4703456.post@n4.nabble.com>
References: <CAE2FW2kdjK6-0eeQ4w7_7VEk1PsUfiZY31meQVTEwcmZW24bXg@mail.gmail.com>
	<1424268806967-4703456.post@n4.nabble.com>
Message-ID: <CAE2FW2k1=-9A1CCVmZ_dsX64FhH43wEY-6LeM3Jr6-ki_s9H6A@mail.gmail.com>

Hi Ben and JS,

Thanks for the reply.

I tried using: hessian(func = h_x, x, method = "complex"), it gives zero,
that's good.

# R code

> hess.h <- hessian(func = h_x, x, method = "complex")

> mat <- h_x(x)*hess.h - grad(h_x, x) %o% grad(h_x, x)

> mat

        [,1]    [,2]     [,3]    [,4]

[1,] 2060602       0        0       0

[2,]       0 2060602        0       0

[3,]       0       0 -4039596 -816080

[4,]       0       0  -816080 4039596


But later I do,

> eigen(mat)

$values

[1] -4121204  4121204  2060602  2060602

$vectors

            [,1]        [,2] [,3] [,4]

[1,]  0.00000000  0.00000000    1    0

[2,]  0.00000000  0.00000000    0    1

[3,] -0.99503719  0.09950372    0    0

[4,] -0.09950372 -0.99503719    0    0


And here is the problem,

> eigen(mat)$values[2] == 4121204

[1] FALSE

> eigen(mat)$values[2] - 4121204

[1] -5.494803e-08

Why doesn't the second value equal to 412104?  How do I overcome that?

Thanks,

Mike

On Wed, Feb 18, 2015 at 9:13 AM, JS Huang <js.huang at protective.com> wrote:

> Hi,
>
>   Since all entries in your hessian matrix and grad vector are integers, I
> suggest you execute the following for mat assignment.
>
> > mat <- round(h_x(x),digits=0)*round(hess.h,digits=0) - round(grad(h_x,
> > x),digits=0) %o% round(grad(h_x, x),digits=0)
> > mat
>          [,1]     [,2]     [,3]     [,4]
> [1,]        0        0        0 -4080400
> [2,]        0  7920000        0 -1600000
> [3,]        0        0 12160400        0
> [4,] -4080400 -1600000        0 -7920000
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Numerical-stability-of-eigenvalue-and-hessian-matrix-in-R-tp4703443p4703456.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Feb 18 17:39:20 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 18 Feb 2015 17:39:20 +0100
Subject: [R] How do I know which package is loaded?
In-Reply-To: <1424275931831.ea036b71@Nodemailer>
References: <1424275931831.ea036b71@Nodemailer>
Message-ID: <CAJuCY5w1-CTS62F8=+Txf-WJj=XPhnwO2ipurfajKG5yM521YQ@mail.gmail.com>

Dear Aron,

- Set the build tools in RStudio to build a package (via Tools -> Project
options -> Build tools)
- Use the Build pane to "Build" and then "Check" the package

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-02-18 17:12 GMT+01:00 Aron Lindberg <aron.lindberg at case.edu>:

> Hi All,
>
>
> In short: what?s a good workflow for forking/rewriting/testing code in
> packages?
>
>
> I?m trying to contribute to a package on Github. So I fork it and then
> clone my forked repo into my desktop, and then I open the files I want to
> edit in RStudio.
>
>
> However, to actually test that the code works, I need to load the package
> from the local version on my machine. I think I can do this using:
>
>
> library(rgithub, lib.loc = ?/Users/Aron/github/local/rgithub/?)
>
>
> However, this fails:
>
>
> Error in library(rgithub, lib.loc = ?/Users/Aron/github/local/?) :
>   there is no package called ?rgithub?
>
>
> Do I need to install the library from the local repo first somehow? How do
> I do this?
>
>
> If I got it to work I assume I would be able to run
>
>
> sessionInfo()
>
>
> Which would then enable me to see which version of the package is loaded.
> However, the version number would be the same as the package that I can
> install using devtools, e.g. devtools::install_github(?cscheid/rgithub?.
> How can I check whether I have loaded my local development copy or the
> ?official? copy that I also have on my machine?
>
>
> In short: what?s a good workflow for forking/rewriting/testing code in
> packages?
>
>
> Best,
> Aron
>
>
> --
> Aron Lindberg
>
>
> Doctoral Candidate, Information Systems
> Weatherhead School of Management
> Case Western Reserve University
> aronlindberg.github.io
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Feb 18 17:57:27 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 18 Feb 2015 17:57:27 +0100
Subject: [R] Numerical stability of eigenvalue and hessian matrix in R
In-Reply-To: <CAE2FW2k1=-9A1CCVmZ_dsX64FhH43wEY-6LeM3Jr6-ki_s9H6A@mail.gmail.com>
References: <CAE2FW2kdjK6-0eeQ4w7_7VEk1PsUfiZY31meQVTEwcmZW24bXg@mail.gmail.com>
	<1424268806967-4703456.post@n4.nabble.com>
	<CAE2FW2k1=-9A1CCVmZ_dsX64FhH43wEY-6LeM3Jr6-ki_s9H6A@mail.gmail.com>
Message-ID: <CAJuCY5zEUzNywEeHViwOmtwJVMbB-BKnGhg5bx2xpx4xGXueEA@mail.gmail.com>

Have a look at FAQ 7.31

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-02-18 17:44 GMT+01:00 C W <tmrsg11 at gmail.com>:

> Hi Ben and JS,
>
> Thanks for the reply.
>
> I tried using: hessian(func = h_x, x, method = "complex"), it gives zero,
> that's good.
>
> # R code
>
> > hess.h <- hessian(func = h_x, x, method = "complex")
>
> > mat <- h_x(x)*hess.h - grad(h_x, x) %o% grad(h_x, x)
>
> > mat
>
>         [,1]    [,2]     [,3]    [,4]
>
> [1,] 2060602       0        0       0
>
> [2,]       0 2060602        0       0
>
> [3,]       0       0 -4039596 -816080
>
> [4,]       0       0  -816080 4039596
>
>
> But later I do,
>
> > eigen(mat)
>
> $values
>
> [1] -4121204  4121204  2060602  2060602
>
> $vectors
>
>             [,1]        [,2] [,3] [,4]
>
> [1,]  0.00000000  0.00000000    1    0
>
> [2,]  0.00000000  0.00000000    0    1
>
> [3,] -0.99503719  0.09950372    0    0
>
> [4,] -0.09950372 -0.99503719    0    0
>
>
> And here is the problem,
>
> > eigen(mat)$values[2] == 4121204
>
> [1] FALSE
>
> > eigen(mat)$values[2] - 4121204
>
> [1] -5.494803e-08
>
> Why doesn't the second value equal to 412104?  How do I overcome that?
>
> Thanks,
>
> Mike
>
> On Wed, Feb 18, 2015 at 9:13 AM, JS Huang <js.huang at protective.com> wrote:
>
> > Hi,
> >
> >   Since all entries in your hessian matrix and grad vector are integers,
> I
> > suggest you execute the following for mat assignment.
> >
> > > mat <- round(h_x(x),digits=0)*round(hess.h,digits=0) - round(grad(h_x,
> > > x),digits=0) %o% round(grad(h_x, x),digits=0)
> > > mat
> >          [,1]     [,2]     [,3]     [,4]
> > [1,]        0        0        0 -4080400
> > [2,]        0  7920000        0 -1600000
> > [3,]        0        0 12160400        0
> > [4,] -4080400 -1600000        0 -7920000
> >
> >
> >
> > --
> > View this message in context:
> >
> http://r.789695.n4.nabble.com/Numerical-stability-of-eigenvalue-and-hessian-matrix-in-R-tp4703443p4703456.html
> > Sent from the R help mailing list archive at Nabble.com.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dinesh.mathurs at rhsmith.umd.edu  Wed Feb 18 16:41:22 2015
From: dinesh.mathurs at rhsmith.umd.edu (Dinesh Mathur S)
Date: Wed, 18 Feb 2015 10:41:22 -0500
Subject: [R] Request for Help with Specifying Priors for MCMC Logit
Message-ID: <CAKf0aXAmL06AwzoFsQaDN3vKUfut6VV_-mbmJfcQGDwOauEw-Q@mail.gmail.com>

Hello,

I am working on a research project at the University of Maryland and as
part of this project I am trying to perform a bayesian analysis. I am
facing difficulty specifying priors using the MCMClogit package. My
question is how do we specify a column vector as a prior mean and a square
matrix as a prior precision?

Can you please provide me any document which has examples related to
specifying priors as a column vector?

Your help in this regard is highly appreciated.

Regards,
Dinesh

	[[alternative HTML version deleted]]


From aron.lindberg at case.edu  Wed Feb 18 18:36:55 2015
From: aron.lindberg at case.edu (Aron Lindberg)
Date: Wed, 18 Feb 2015 09:36:55 -0800 (PST)
Subject: [R] How do I know which package is loaded?
In-Reply-To: <CAJuCY5w1-CTS62F8=+Txf-WJj=XPhnwO2ipurfajKG5yM521YQ@mail.gmail.com>
References: <CAJuCY5w1-CTS62F8=+Txf-WJj=XPhnwO2ipurfajKG5yM521YQ@mail.gmail.com>
Message-ID: <1424281015182.7338cd24@Nodemailer>

Thanks! That?s perfect. Key is to load the local github repo into an Rstudio project first.


--?

Aron Lindberg




Doctoral Candidate,?Information Systems

Weatherhead School of Management?

Case Western Reserve University

aronlindberg.github.io

On Wed, Feb 18, 2015 at 11:39 AM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:

> Dear Aron,
> - Set the build tools in RStudio to build a package (via Tools -> Project
> options -> Build tools)
> - Use the Build pane to "Build" and then "Check" the package
> Best regards,
> Thierry
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 2015-02-18 17:12 GMT+01:00 Aron Lindberg <aron.lindberg at case.edu>:
>> Hi All,
>>
>>
>> In short: what?s a good workflow for forking/rewriting/testing code in
>> packages?
>>
>>
>> I?m trying to contribute to a package on Github. So I fork it and then
>> clone my forked repo into my desktop, and then I open the files I want to
>> edit in RStudio.
>>
>>
>> However, to actually test that the code works, I need to load the package
>> from the local version on my machine. I think I can do this using:
>>
>>
>> library(rgithub, lib.loc = ?/Users/Aron/github/local/rgithub/?)
>>
>>
>> However, this fails:
>>
>>
>> Error in library(rgithub, lib.loc = ?/Users/Aron/github/local/?) :
>>   there is no package called ?rgithub?
>>
>>
>> Do I need to install the library from the local repo first somehow? How do
>> I do this?
>>
>>
>> If I got it to work I assume I would be able to run
>>
>>
>> sessionInfo()
>>
>>
>> Which would then enable me to see which version of the package is loaded.
>> However, the version number would be the same as the package that I can
>> install using devtools, e.g. devtools::install_github(?cscheid/rgithub?.
>> How can I check whether I have loaded my local development copy or the
>> ?official? copy that I also have on my machine?
>>
>>
>> In short: what?s a good workflow for forking/rewriting/testing code in
>> packages?
>>
>>
>> Best,
>> Aron
>>
>>
>> --
>> Aron Lindberg
>>
>>
>> Doctoral Candidate, Information Systems
>> Weatherhead School of Management
>> Case Western Reserve University
>> aronlindberg.github.io
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From tring at gvdnet.dk  Wed Feb 18 18:45:07 2015
From: tring at gvdnet.dk (Troels Ring)
Date: Wed, 18 Feb 2015 18:45:07 +0100
Subject: [R] time conversions
Message-ID: <54E4CFA3.5020502@gvdnet.dk>

dear friends - sorry to ask another simple question -
I have dates set up as this:
dates  #[1] 2003-01-21 01:08:00

To handle it I did
as.POSIXlt(dates)  "2003-01-21 01:08:00 CET"

but noticed that during write.table it was apparently better to take it 
further
as.numeric(as.POSIXct(as.POSIXlt(dates))   1043107680

And this works fine for modeling but now I would like to have it back as 
POSIXlt
as.POSIXlt requires an origin, if I'm right.
So how is it done?

Best wishes

Troels Ring
Aalborg
Denmark


From pdalgd at gmail.com  Wed Feb 18 20:14:49 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 18 Feb 2015 20:14:49 +0100
Subject: [R] time conversions
In-Reply-To: <54E4CFA3.5020502@gvdnet.dk>
References: <54E4CFA3.5020502@gvdnet.dk>
Message-ID: <3962241A-9D37-4831-B44D-706E9EBEA772@gmail.com>


> On 18 Feb 2015, at 18:45 , Troels Ring <tring at gvdnet.dk> wrote:
> 
> dear friends - sorry to ask another simple question -
> I have dates set up as this:
> dates  #[1] 2003-01-21 01:08:00
> 
> To handle it I did
> as.POSIXlt(dates)  "2003-01-21 01:08:00 CET"
> 
> but noticed that during write.table it was apparently better to take it further
> as.numeric(as.POSIXct(as.POSIXlt(dates))   1043107680
> 
> And this works fine for modeling but now I would like to have it back as POSIXlt
> as.POSIXlt requires an origin, if I'm right.
> So how is it done?

Like this?

> as.POSIXlt(1043107680, origin='1970-1-1')
[1] "2003-01-21 01:08:00 CET"

(Time zones may require special care, though.)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ruipbarradas at sapo.pt  Wed Feb 18 20:26:19 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 18 Feb 2015 19:26:19 +0000
Subject: [R] time conversions
In-Reply-To: <54E4CFA3.5020502@gvdnet.dk>
References: <54E4CFA3.5020502@gvdnet.dk>
Message-ID: <54E4E75B.8080208@sapo.pt>

Hello,

Try

as.POSIXlt(1043107680, origin = "1970-01-01", tz = "CET")


Hope this helps,

Rui Barradas

Em 18-02-2015 17:45, Troels Ring escreveu:
> dear friends - sorry to ask another simple question -
> I have dates set up as this:
> dates  #[1] 2003-01-21 01:08:00
>
> To handle it I did
> as.POSIXlt(dates)  "2003-01-21 01:08:00 CET"
>
> but noticed that during write.table it was apparently better to take it
> further
> as.numeric(as.POSIXct(as.POSIXlt(dates))   1043107680
>
> And this works fine for modeling but now I would like to have it back as
> POSIXlt
> as.POSIXlt requires an origin, if I'm right.
> So how is it done?
>
> Best wishes
>
> Troels Ring
> Aalborg
> Denmark
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kate.ignatius at gmail.com  Wed Feb 18 21:27:36 2015
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Wed, 18 Feb 2015 15:27:36 -0500
Subject: [R] grepping out columns
Message-ID: <CAE6QMsaephiW24HTTm73gMrHgBRbF1KSe4hBcXHSZ85dA41qrw@mail.gmail.com>

Hi,

I've got a complicated grep problem (or not)...  I currently have a
file with the headings as follows:

DAY
MONTH
YEAR
SA_TUES
SA_MON
SU_WED
CH_TUES
CH_WED
CH_MON
AR_TUES
AR_WED
AR_MON
SA_THUR
SU_FRI
CH_THUR
CH_FRI
AR_THUR
AR_FRI

I want to grep out all columns that have SA at the beginning of their
day including any other information pertaining to that day.
Ultimately I want to end up with:

SA_TUES
SA_MON
CH_TUES
CH_MON
AR_TUES
AR_MON
SA_THUR
CH_THUR
AR_THUR

Is there a way of doing this simply with grep? Or will this need to be
more complicated?

Thanks!

K.


From dwinsemius at comcast.net  Wed Feb 18 21:55:35 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 18 Feb 2015 12:55:35 -0800
Subject: [R] grepping out columns
In-Reply-To: <CAE6QMsaephiW24HTTm73gMrHgBRbF1KSe4hBcXHSZ85dA41qrw@mail.gmail.com>
References: <CAE6QMsaephiW24HTTm73gMrHgBRbF1KSe4hBcXHSZ85dA41qrw@mail.gmail.com>
Message-ID: <D00BA82A-64BD-4EC1-9E0D-A18CAE9C37CA@comcast.net>


On Feb 18, 2015, at 12:27 PM, Kate Ignatius wrote:
> Hi,
> 
> I've got a complicated grep problem (or not)...  I currently have a
> file with the headings as follows:
> 
Lets assume these values are in a character vector named 'dat'.
> SA_TUES
> SA_MON
> SU_WED
> CH_TUES
> CH_WED
> CH_MON
> AR_TUES
> AR_WED
> AR_MON
> SA_THUR
> SU_FRI
> CH_THUR
> CH_FRI
> AR_THUR
> AR_FRI

 sadays <- dat[grep("SA", dat) ]
 sads <- gsub("SA_","",sadays)
 sads
#[1] "TUES" "MON"  "THUR"

 dat[ sapply(sads, grep, dat) ]
#[1] "SA_TUES" "CH_TUES" "AR_TUES" "SA_MON"  "CH_MON"  "AR_MON" 
#[7] "SA_THUR" "CH_THUR" "AR_THUR

-- 
David Winsemius
Alameda, CA, USA


From felasa at gmail.com  Wed Feb 18 22:10:54 2015
From: felasa at gmail.com (Federico Lasa)
Date: Wed, 18 Feb 2015 15:10:54 -0600
Subject: [R] grepping out columns
In-Reply-To: <D00BA82A-64BD-4EC1-9E0D-A18CAE9C37CA@comcast.net>
References: <CAE6QMsaephiW24HTTm73gMrHgBRbF1KSe4hBcXHSZ85dA41qrw@mail.gmail.com>
	<D00BA82A-64BD-4EC1-9E0D-A18CAE9C37CA@comcast.net>
Message-ID: <CAE8W1T13qzzqYdjg6H5752tBZpPt6QZrH9H9e0jkHPytBuueMQ@mail.gmail.com>

David's almost works except it catches the "MONTH" column, just add an
empty metacharacter tho.

c("DAY",
"MONTH",
"YEAR",
"SA_TUES",
"SA_MON",
"SU_WED",
"CH_TUES",
"CH_WED",
"CH_MON",
"AR_TUES",
"AR_WED",
"AR_MON",
"SA_THUR",
"SU_FRI",
"CH_THUR",
"CH_FRI",
"AR_THUR",
"AR_FRI")-> columns

sa_ind <- grep("SA_",columns)
days <- gsub("SA_","", columns[sa_ind])
days <- paste0(days,"$")
selected <- lapply(days, function(x) grep(x,columns))
selected <- sort(unique(unlist(all_ind)))

columns[selected]
[1] "SA_TUES" "SA_MON"  "CH_TUES" "CH_MON"  "AR_TUES" "AR_MON"
"SA_THUR" "CH_THUR" "AR_THUR"

On Wed, Feb 18, 2015 at 2:55 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Feb 18, 2015, at 12:27 PM, Kate Ignatius wrote:
>> Hi,
>>
>> I've got a complicated grep problem (or not)...  I currently have a
>> file with the headings as follows:
>>
> Lets assume these values are in a character vector named 'dat'.
>> SA_TUES
>> SA_MON
>> SU_WED
>> CH_TUES
>> CH_WED
>> CH_MON
>> AR_TUES
>> AR_WED
>> AR_MON
>> SA_THUR
>> SU_FRI
>> CH_THUR
>> CH_FRI
>> AR_THUR
>> AR_FRI
>
>  sadays <- dat[grep("SA", dat) ]
>  sads <- gsub("SA_","",sadays)
>  sads
> #[1] "TUES" "MON"  "THUR"
>
>  dat[ sapply(sads, grep, dat) ]
> #[1] "SA_TUES" "CH_TUES" "AR_TUES" "SA_MON"  "CH_MON"  "AR_MON"
> #[7] "SA_THUR" "CH_THUR" "AR_THUR
>
> --
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Wed Feb 18 22:13:39 2015
From: tmrsg11 at gmail.com (C W)
Date: Wed, 18 Feb 2015 16:13:39 -0500
Subject: [R] Numerical stability of eigenvalue and hessian matrix in R
In-Reply-To: <CAJuCY5zEUzNywEeHViwOmtwJVMbB-BKnGhg5bx2xpx4xGXueEA@mail.gmail.com>
References: <CAE2FW2kdjK6-0eeQ4w7_7VEk1PsUfiZY31meQVTEwcmZW24bXg@mail.gmail.com>
	<1424268806967-4703456.post@n4.nabble.com>
	<CAE2FW2k1=-9A1CCVmZ_dsX64FhH43wEY-6LeM3Jr6-ki_s9H6A@mail.gmail.com>
	<CAJuCY5zEUzNywEeHViwOmtwJVMbB-BKnGhg5bx2xpx4xGXueEA@mail.gmail.com>
Message-ID: <CAE2FW2nXQh1znZeQ5d5GGF0cXPNhTyxk716XYR+aO-wSvcHXog@mail.gmail.com>

Thanks Thierry for the pointer, that's explains the problem.

Is there anything I can do about the matrix instability or numerical
inaccuracy?

Mike

On Wed, Feb 18, 2015 at 11:57 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Have a look at FAQ 7.31
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-02-18 17:44 GMT+01:00 C W <tmrsg11 at gmail.com>:
>
>> Hi Ben and JS,
>>
>> Thanks for the reply.
>>
>> I tried using: hessian(func = h_x, x, method = "complex"), it gives zero,
>> that's good.
>>
>> # R code
>>
>> > hess.h <- hessian(func = h_x, x, method = "complex")
>>
>> > mat <- h_x(x)*hess.h - grad(h_x, x) %o% grad(h_x, x)
>>
>> > mat
>>
>>         [,1]    [,2]     [,3]    [,4]
>>
>> [1,] 2060602       0        0       0
>>
>> [2,]       0 2060602        0       0
>>
>> [3,]       0       0 -4039596 -816080
>>
>> [4,]       0       0  -816080 4039596
>>
>>
>> But later I do,
>>
>> > eigen(mat)
>>
>> $values
>>
>> [1] -4121204  4121204  2060602  2060602
>>
>> $vectors
>>
>>             [,1]        [,2] [,3] [,4]
>>
>> [1,]  0.00000000  0.00000000    1    0
>>
>> [2,]  0.00000000  0.00000000    0    1
>>
>> [3,] -0.99503719  0.09950372    0    0
>>
>> [4,] -0.09950372 -0.99503719    0    0
>>
>>
>> And here is the problem,
>>
>> > eigen(mat)$values[2] == 4121204
>>
>> [1] FALSE
>>
>> > eigen(mat)$values[2] - 4121204
>>
>> [1] -5.494803e-08
>>
>> Why doesn't the second value equal to 412104?  How do I overcome that?
>>
>> Thanks,
>>
>> Mike
>>
>> On Wed, Feb 18, 2015 at 9:13 AM, JS Huang <js.huang at protective.com>
>> wrote:
>>
>> > Hi,
>> >
>> >   Since all entries in your hessian matrix and grad vector are
>> integers, I
>> > suggest you execute the following for mat assignment.
>> >
>> > > mat <- round(h_x(x),digits=0)*round(hess.h,digits=0) - round(grad(h_x,
>> > > x),digits=0) %o% round(grad(h_x, x),digits=0)
>> > > mat
>> >          [,1]     [,2]     [,3]     [,4]
>> > [1,]        0        0        0 -4080400
>> > [2,]        0  7920000        0 -1600000
>> > [3,]        0        0 12160400        0
>> > [4,] -4080400 -1600000        0 -7920000
>> >
>> >
>> >
>> > --
>> > View this message in context:
>> >
>> http://r.789695.n4.nabble.com/Numerical-stability-of-eigenvalue-and-hessian-matrix-in-R-tp4703443p4703456.html
>> > Sent from the R help mailing list archive at Nabble.com.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From tring at gvdnet.dk  Wed Feb 18 22:16:31 2015
From: tring at gvdnet.dk (Troels Ring)
Date: Wed, 18 Feb 2015 22:16:31 +0100
Subject: [R] time conversions
In-Reply-To: <3962241A-9D37-4831-B44D-706E9EBEA772@gmail.com>
References: <54E4CFA3.5020502@gvdnet.dk>
	<3962241A-9D37-4831-B44D-706E9EBEA772@gmail.com>
Message-ID: <54E5012F.10808@gvdnet.dk>

Thanks a lot and thanks to Rui
Troels

Den 18-02-2015 kl. 20:14 skrev peter dalgaard:
>> On 18 Feb 2015, at 18:45 , Troels Ring <tring at gvdnet.dk> wrote:
>>
>> dear friends - sorry to ask another simple question -
>> I have dates set up as this:
>> dates  #[1] 2003-01-21 01:08:00
>>
>> To handle it I did
>> as.POSIXlt(dates)  "2003-01-21 01:08:00 CET"
>>
>> but noticed that during write.table it was apparently better to take it further
>> as.numeric(as.POSIXct(as.POSIXlt(dates))   1043107680
>>
>> And this works fine for modeling but now I would like to have it back as POSIXlt
>> as.POSIXlt requires an origin, if I'm right.
>> So how is it done?
> Like this?
>
>> as.POSIXlt(1043107680, origin='1970-1-1')
> [1] "2003-01-21 01:08:00 CET"
>
> (Time zones may require special care, though.)
>


From jdnewmil at dcn.davis.CA.us  Wed Feb 18 22:41:23 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 18 Feb 2015 13:41:23 -0800
Subject: [R] Numerical stability of eigenvalue and hessian matrix in R
In-Reply-To: <CAE2FW2nXQh1znZeQ5d5GGF0cXPNhTyxk716XYR+aO-wSvcHXog@mail.gmail.com>
References: <CAE2FW2kdjK6-0eeQ4w7_7VEk1PsUfiZY31meQVTEwcmZW24bXg@mail.gmail.com>
	<1424268806967-4703456.post@n4.nabble.com>
	<CAE2FW2k1=-9A1CCVmZ_dsX64FhH43wEY-6LeM3Jr6-ki_s9H6A@mail.gmail.com>
	<CAJuCY5zEUzNywEeHViwOmtwJVMbB-BKnGhg5bx2xpx4xGXueEA@mail.gmail.com>
	<CAE2FW2nXQh1znZeQ5d5GGF0cXPNhTyxk716XYR+aO-wSvcHXog@mail.gmail.com>
Message-ID: <E2DB80DA-C0EB-48E1-A7BD-DA13400EDC31@dcn.davis.CA.us>

This question is getting pretty deep into numerical analysis theory. The usual approach has already been mentioned... don't expect high accuracy in all problems. Your  specific problem could have a special technique somewhere, but don't be surprised if we are not experts in your specific problem as such tricks are not R-specific.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 18, 2015 1:13:39 PM PST, C W <tmrsg11 at gmail.com> wrote:
>Thanks Thierry for the pointer, that's explains the problem.
>
>Is there anything I can do about the matrix instability or numerical
>inaccuracy?
>
>Mike
>
>On Wed, Feb 18, 2015 at 11:57 AM, Thierry Onkelinx
><thierry.onkelinx at inbo.be
>> wrote:
>
>> Have a look at FAQ 7.31
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for
>Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no
>more
>> than asking him to perform a post-mortem examination: he may be able
>to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>not
>> ensure that a reasonable answer can be extracted from a given body of
>data.
>> ~ John Tukey
>>
>> 2015-02-18 17:44 GMT+01:00 C W <tmrsg11 at gmail.com>:
>>
>>> Hi Ben and JS,
>>>
>>> Thanks for the reply.
>>>
>>> I tried using: hessian(func = h_x, x, method = "complex"), it gives
>zero,
>>> that's good.
>>>
>>> # R code
>>>
>>> > hess.h <- hessian(func = h_x, x, method = "complex")
>>>
>>> > mat <- h_x(x)*hess.h - grad(h_x, x) %o% grad(h_x, x)
>>>
>>> > mat
>>>
>>>         [,1]    [,2]     [,3]    [,4]
>>>
>>> [1,] 2060602       0        0       0
>>>
>>> [2,]       0 2060602        0       0
>>>
>>> [3,]       0       0 -4039596 -816080
>>>
>>> [4,]       0       0  -816080 4039596
>>>
>>>
>>> But later I do,
>>>
>>> > eigen(mat)
>>>
>>> $values
>>>
>>> [1] -4121204  4121204  2060602  2060602
>>>
>>> $vectors
>>>
>>>             [,1]        [,2] [,3] [,4]
>>>
>>> [1,]  0.00000000  0.00000000    1    0
>>>
>>> [2,]  0.00000000  0.00000000    0    1
>>>
>>> [3,] -0.99503719  0.09950372    0    0
>>>
>>> [4,] -0.09950372 -0.99503719    0    0
>>>
>>>
>>> And here is the problem,
>>>
>>> > eigen(mat)$values[2] == 4121204
>>>
>>> [1] FALSE
>>>
>>> > eigen(mat)$values[2] - 4121204
>>>
>>> [1] -5.494803e-08
>>>
>>> Why doesn't the second value equal to 412104?  How do I overcome
>that?
>>>
>>> Thanks,
>>>
>>> Mike
>>>
>>> On Wed, Feb 18, 2015 at 9:13 AM, JS Huang <js.huang at protective.com>
>>> wrote:
>>>
>>> > Hi,
>>> >
>>> >   Since all entries in your hessian matrix and grad vector are
>>> integers, I
>>> > suggest you execute the following for mat assignment.
>>> >
>>> > > mat <- round(h_x(x),digits=0)*round(hess.h,digits=0) -
>round(grad(h_x,
>>> > > x),digits=0) %o% round(grad(h_x, x),digits=0)
>>> > > mat
>>> >          [,1]     [,2]     [,3]     [,4]
>>> > [1,]        0        0        0 -4080400
>>> > [2,]        0  7920000        0 -1600000
>>> > [3,]        0        0 12160400        0
>>> > [4,] -4080400 -1600000        0 -7920000
>>> >
>>> >
>>> >
>>> > --
>>> > View this message in context:
>>> >
>>>
>http://r.789695.n4.nabble.com/Numerical-stability-of-eigenvalue-and-hessian-matrix-in-R-tp4703443p4703456.html
>>> > Sent from the R help mailing list archive at Nabble.com.
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Feb 18 22:54:58 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 18 Feb 2015 13:54:58 -0800
Subject: [R] Numerical stability of eigenvalue and hessian matrix in R
In-Reply-To: <CAE2FW2nXQh1znZeQ5d5GGF0cXPNhTyxk716XYR+aO-wSvcHXog@mail.gmail.com>
References: <CAE2FW2kdjK6-0eeQ4w7_7VEk1PsUfiZY31meQVTEwcmZW24bXg@mail.gmail.com>
	<1424268806967-4703456.post@n4.nabble.com>
	<CAE2FW2k1=-9A1CCVmZ_dsX64FhH43wEY-6LeM3Jr6-ki_s9H6A@mail.gmail.com>
	<CAJuCY5zEUzNywEeHViwOmtwJVMbB-BKnGhg5bx2xpx4xGXueEA@mail.gmail.com>
	<CAE2FW2nXQh1znZeQ5d5GGF0cXPNhTyxk716XYR+aO-wSvcHXog@mail.gmail.com>
Message-ID: <FE17396E-4465-40C7-B742-60B17AAED959@comcast.net>


On Feb 18, 2015, at 1:13 PM, C W wrote:

> Thanks Thierry for the pointer, that's explains the problem.
> 
> Is there anything I can do about the matrix instability or numerical
> inaccuracy?

There are matrix methods in the Rmpfr package that support increased precision, but it is implemented with S4 methods. You would probably need to retool the numDeriv functions to use the mpfrMatrix-class.

-- 
david.
> 
> Mike
> 
> On Wed, Feb 18, 2015 at 11:57 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
>> wrote:
> 
>> Have a look at FAQ 7.31
>> 
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> 
>> 2015-02-18 17:44 GMT+01:00 C W <tmrsg11 at gmail.com>:
>> 
>>> Hi Ben and JS,
>>> 
>>> Thanks for the reply.
>>> 
>>> I tried using: hessian(func = h_x, x, method = "complex"), it gives zero,
>>> that's good.
>>> 
>>> # R code
>>> 
>>>> hess.h <- hessian(func = h_x, x, method = "complex")
>>> 
>>>> mat <- h_x(x)*hess.h - grad(h_x, x) %o% grad(h_x, x)
>>> 
>>>> mat
>>> 
>>>        [,1]    [,2]     [,3]    [,4]
>>> 
>>> [1,] 2060602       0        0       0
>>> 
>>> [2,]       0 2060602        0       0
>>> 
>>> [3,]       0       0 -4039596 -816080
>>> 
>>> [4,]       0       0  -816080 4039596
>>> 
>>> 
>>> But later I do,
>>> 
>>>> eigen(mat)
>>> 
>>> $values
>>> 
>>> [1] -4121204  4121204  2060602  2060602
>>> 
>>> $vectors
>>> 
>>>            [,1]        [,2] [,3] [,4]
>>> 
>>> [1,]  0.00000000  0.00000000    1    0
>>> 
>>> [2,]  0.00000000  0.00000000    0    1
>>> 
>>> [3,] -0.99503719  0.09950372    0    0
>>> 
>>> [4,] -0.09950372 -0.99503719    0    0
>>> 
>>> 
>>> And here is the problem,
>>> 
>>>> eigen(mat)$values[2] == 4121204
>>> 
>>> [1] FALSE
>>> 
>>>> eigen(mat)$values[2] - 4121204
>>> 
>>> [1] -5.494803e-08
>>> 
>>> Why doesn't the second value equal to 412104?  How do I overcome that?
>>> 
>>> Thanks,
>>> 
>>> Mike
>>> 
>>> On Wed, Feb 18, 2015 at 9:13 AM, JS Huang <js.huang at protective.com>
>>> wrote:
>>> 
>>>> Hi,
>>>> 
>>>>  Since all entries in your hessian matrix and grad vector are
>>> integers, I
>>>> suggest you execute the following for mat assignment.
>>>> 
>>>>> mat <- round(h_x(x),digits=0)*round(hess.h,digits=0) - round(grad(h_x,
>>>>> x),digits=0) %o% round(grad(h_x, x),digits=0)
>>>>> mat
>>>>         [,1]     [,2]     [,3]     [,4]
>>>> [1,]        0        0        0 -4080400
>>>> [2,]        0  7920000        0 -1600000
>>>> [3,]        0        0 12160400        0
>>>> [4,] -4080400 -1600000        0 -7920000
>>>> 
>>>> 
>>>> 
>>>> --
>>>> View this message in context:
>>>> 
>>> http://r.789695.n4.nabble.com/Numerical-stability-of-eigenvalue-and-hessian-matrix-in-R-tp4703443p4703456.html
>>>> Sent from the R help mailing list archive at Nabble.com.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From spencer.graves at prodsyse.com  Wed Feb 18 23:15:43 2015
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 18 Feb 2015 14:15:43 -0800
Subject: [R] Numerical stability of eigenvalue and hessian matrix in R
In-Reply-To: <FE17396E-4465-40C7-B742-60B17AAED959@comcast.net>
References: <CAE2FW2kdjK6-0eeQ4w7_7VEk1PsUfiZY31meQVTEwcmZW24bXg@mail.gmail.com>
	<1424268806967-4703456.post@n4.nabble.com>
	<CAE2FW2k1=-9A1CCVmZ_dsX64FhH43wEY-6LeM3Jr6-ki_s9H6A@mail.gmail.com>
	<CAJuCY5zEUzNywEeHViwOmtwJVMbB-BKnGhg5bx2xpx4xGXueEA@mail.gmail.com>
	<CAE2FW2nXQh1znZeQ5d5GGF0cXPNhTyxk716XYR+aO-wSvcHXog@mail.gmail.com>
	<FE17396E-4465-40C7-B742-60B17AAED959@comcast.net>
Message-ID: <333E3726-7F08-4C3D-82FD-D97EAEB2F7E8@prodsyse.com>


> On Feb 18, 2015, at 1:54 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> On Feb 18, 2015, at 1:13 PM, C W wrote:
> 
>> Thanks Thierry for the pointer, that's explains the problem.
>> 
>> Is there anything I can do about the matrix instability or numerical
>> inaccuracy?
> 
> There are matrix methods in the Rmpfr package that support increased precision, but it is implemented with S4 methods. You would probably need to retool the numDeriv functions to use the mpfrMatrix-class.


How much numerical precision do you need?  


How important is the difference between 4121204 and (4121204-5.494803e-08)?  


Spencer 

> 
> -- 
> david.
>> 
>> Mike
>> 
>> On Wed, Feb 18, 2015 at 11:57 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
>>> wrote:
>> 
>>> Have a look at FAQ 7.31
>>> 
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>>> 
>>> 2015-02-18 17:44 GMT+01:00 C W <tmrsg11 at gmail.com>:
>>> 
>>>> Hi Ben and JS,
>>>> 
>>>> Thanks for the reply.
>>>> 
>>>> I tried using: hessian(func = h_x, x, method = "complex"), it gives zero,
>>>> that's good.
>>>> 
>>>> # R code
>>>> 
>>>>> hess.h <- hessian(func = h_x, x, method = "complex")
>>>> 
>>>>> mat <- h_x(x)*hess.h - grad(h_x, x) %o% grad(h_x, x)
>>>> 
>>>>> mat
>>>> 
>>>>       [,1]    [,2]     [,3]    [,4]
>>>> 
>>>> [1,] 2060602       0        0       0
>>>> 
>>>> [2,]       0 2060602        0       0
>>>> 
>>>> [3,]       0       0 -4039596 -816080
>>>> 
>>>> [4,]       0       0  -816080 4039596
>>>> 
>>>> 
>>>> But later I do,
>>>> 
>>>>> eigen(mat)
>>>> 
>>>> $values
>>>> 
>>>> [1] -4121204  4121204  2060602  2060602
>>>> 
>>>> $vectors
>>>> 
>>>>           [,1]        [,2] [,3] [,4]
>>>> 
>>>> [1,]  0.00000000  0.00000000    1    0
>>>> 
>>>> [2,]  0.00000000  0.00000000    0    1
>>>> 
>>>> [3,] -0.99503719  0.09950372    0    0
>>>> 
>>>> [4,] -0.09950372 -0.99503719    0    0
>>>> 
>>>> 
>>>> And here is the problem,
>>>> 
>>>>> eigen(mat)$values[2] == 4121204
>>>> 
>>>> [1] FALSE
>>>> 
>>>>> eigen(mat)$values[2] - 4121204
>>>> 
>>>> [1] -5.494803e-08
>>>> 
>>>> Why doesn't the second value equal to 412104?  How do I overcome that?
>>>> 
>>>> Thanks,
>>>> 
>>>> Mike
>>>> 
>>>> On Wed, Feb 18, 2015 at 9:13 AM, JS Huang <js.huang at protective.com>
>>>> wrote:
>>>> 
>>>>> Hi,
>>>>> 
>>>>> Since all entries in your hessian matrix and grad vector are
>>>> integers, I
>>>>> suggest you execute the following for mat assignment.
>>>>> 
>>>>>> mat <- round(h_x(x),digits=0)*round(hess.h,digits=0) - round(grad(h_x,
>>>>>> x),digits=0) %o% round(grad(h_x, x),digits=0)
>>>>>> mat
>>>>>        [,1]     [,2]     [,3]     [,4]
>>>>> [1,]        0        0        0 -4080400
>>>>> [2,]        0  7920000        0 -1600000
>>>>> [3,]        0        0 12160400        0
>>>>> [4,] -4080400 -1600000        0 -7920000
>>>>> 
>>>>> 
>>>>> 
>>>>> --
>>>>> View this message in context:
>>>>> 
>>>> http://r.789695.n4.nabble.com/Numerical-stability-of-eigenvalue-and-hessian-matrix-in-R-tp4703443p4703456.html
>>>>> Sent from the R help mailing list archive at Nabble.com.
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From spencer.graves at prodsyse.com  Wed Feb 18 23:20:57 2015
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 18 Feb 2015 14:20:57 -0800
Subject: [R] Numerical stability of eigenvalue and hessian matrix in R
In-Reply-To: <333E3726-7F08-4C3D-82FD-D97EAEB2F7E8@prodsyse.com>
References: <CAE2FW2kdjK6-0eeQ4w7_7VEk1PsUfiZY31meQVTEwcmZW24bXg@mail.gmail.com>
	<1424268806967-4703456.post@n4.nabble.com>
	<CAE2FW2k1=-9A1CCVmZ_dsX64FhH43wEY-6LeM3Jr6-ki_s9H6A@mail.gmail.com>
	<CAJuCY5zEUzNywEeHViwOmtwJVMbB-BKnGhg5bx2xpx4xGXueEA@mail.gmail.com>
	<CAE2FW2nXQh1znZeQ5d5GGF0cXPNhTyxk716XYR+aO-wSvcHXog@mail.gmail.com>
	<FE17396E-4465-40C7-B742-60B17AAED959@comcast.net>
	<333E3726-7F08-4C3D-82FD-D97EAEB2F7E8@prodsyse.com>
Message-ID: <B35881B9-E01C-4564-B2FC-4D73E036C01F@prodsyse.com>


> On Feb 18, 2015, at 2:15 PM, Spencer Graves <spencer.graves at prodsyse.com> wrote:
> 
> 
>> On Feb 18, 2015, at 1:54 PM, David Winsemius <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
>> 
>> 
>> On Feb 18, 2015, at 1:13 PM, C W wrote:
>> 
>>> Thanks Thierry for the pointer, that's explains the problem.
>>> 
>>> Is there anything I can do about the matrix instability or numerical
>>> inaccuracy?
>> 
>> There are matrix methods in the Rmpfr package that support increased precision, but it is implemented with S4 methods. You would probably need to retool the numDeriv functions to use the mpfrMatrix-class.
> 
> 
> How much numerical precision do you need?  
> 
> 
> How important is the difference between 4121204 and (4121204-5.494803e-08)?  


p.s.  If that difference is important, your best approach might be to use theory with e2 = 4121204 and d = (-5.494803e-08).  That could give you answers ? and insights ? more accurate than any infinite precision arithmetic.   
> 
> 
> Spencer 
> 
>> 
>> -- 
>> david.
>>> 
>>> Mike
>>> 
>>> On Wed, Feb 18, 2015 at 11:57 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
>>>> wrote:
>>> 
>>>> Have a look at FAQ 7.31
>>>> 
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>>>> 
>>>> 2015-02-18 17:44 GMT+01:00 C W <tmrsg11 at gmail.com <mailto:tmrsg11 at gmail.com>>:
>>>> 
>>>>> Hi Ben and JS,
>>>>> 
>>>>> Thanks for the reply.
>>>>> 
>>>>> I tried using: hessian(func = h_x, x, method = "complex"), it gives zero,
>>>>> that's good.
>>>>> 
>>>>> # R code
>>>>> 
>>>>>> hess.h <- hessian(func = h_x, x, method = "complex")
>>>>> 
>>>>>> mat <- h_x(x)*hess.h - grad(h_x, x) %o% grad(h_x, x)
>>>>> 
>>>>>> mat
>>>>> 
>>>>>       [,1]    [,2]     [,3]    [,4]
>>>>> 
>>>>> [1,] 2060602       0        0       0
>>>>> 
>>>>> [2,]       0 2060602        0       0
>>>>> 
>>>>> [3,]       0       0 -4039596 -816080
>>>>> 
>>>>> [4,]       0       0  -816080 4039596
>>>>> 
>>>>> 
>>>>> But later I do,
>>>>> 
>>>>>> eigen(mat)
>>>>> 
>>>>> $values
>>>>> 
>>>>> [1] -4121204  4121204  2060602  2060602
>>>>> 
>>>>> $vectors
>>>>> 
>>>>>           [,1]        [,2] [,3] [,4]
>>>>> 
>>>>> [1,]  0.00000000  0.00000000    1    0
>>>>> 
>>>>> [2,]  0.00000000  0.00000000    0    1
>>>>> 
>>>>> [3,] -0.99503719  0.09950372    0    0
>>>>> 
>>>>> [4,] -0.09950372 -0.99503719    0    0
>>>>> 
>>>>> 
>>>>> And here is the problem,
>>>>> 
>>>>>> eigen(mat)$values[2] == 4121204
>>>>> 
>>>>> [1] FALSE
>>>>> 
>>>>>> eigen(mat)$values[2] - 4121204
>>>>> 
>>>>> [1] -5.494803e-08
>>>>> 
>>>>> Why doesn't the second value equal to 412104?  How do I overcome that?
>>>>> 
>>>>> Thanks,
>>>>> 
>>>>> Mike
>>>>> 
>>>>> On Wed, Feb 18, 2015 at 9:13 AM, JS Huang <js.huang at protective.com <mailto:js.huang at protective.com>>
>>>>> wrote:
>>>>> 
>>>>>> Hi,
>>>>>> 
>>>>>> Since all entries in your hessian matrix and grad vector are
>>>>> integers, I
>>>>>> suggest you execute the following for mat assignment.
>>>>>> 
>>>>>>> mat <- round(h_x(x),digits=0)*round(hess.h,digits=0) - round(grad(h_x,
>>>>>>> x),digits=0) %o% round(grad(h_x, x),digits=0)
>>>>>>> mat
>>>>>>        [,1]     [,2]     [,3]     [,4]
>>>>>> [1,]        0        0        0 -4080400
>>>>>> [2,]        0  7920000        0 -1600000
>>>>>> [3,]        0        0 12160400        0
>>>>>> [4,] -4080400 -1600000        0 -7920000
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> --
>>>>>> View this message in context:
>>>>>> 
>>>>> http://r.789695.n4.nabble.com/Numerical-stability-of-eigenvalue-and-hessian-matrix-in-R-tp4703443p4703456.html <http://r.789695.n4.nabble.com/Numerical-stability-of-eigenvalue-and-hessian-matrix-in-R-tp4703443p4703456.html>
>>>>>> Sent from the R help mailing list archive at Nabble.com.
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>> 
>>>>>       [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
> 


	[[alternative HTML version deleted]]


From evan.kransdorf at gmail.com  Thu Feb 19 02:40:00 2015
From: evan.kransdorf at gmail.com (Evan Kransdorf)
Date: Wed, 18 Feb 2015 18:40:00 -0700
Subject: [R] Help with declaring factors in a function
Message-ID: <CAKZWb7ey0Vwfh73LC6cBBY605vAtZzDGhPyfFKsd1tcwKbhoJA@mail.gmail.com>

Hello,

I am passing a df to a function and then want to declare factors (based on
a vector of column names in the df) for a logistic regression. I am having
trouble - R doesn't seem to recognize the factors as declared in the
function? Below is my code.  Does anyone have any ideas?

MyFunction <- function(x,y,z) {
#x is a data frame
#y is a formula for the regression
#z vector of factors to be declared
    name<-NULL
    temp<-NULL
    for (i in 1 : length(z)) {
        name<-paste0(substitute(x),"$",z[i])
        print(name)
        temp<-eval(parse(text = name))
        temp<-factor(temp)
        print(levels(temp))
    } #for
    model<-glm(y, x, family=binomial(link = "logit"))
    return(model)
} #func

Thanks very much!!!

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Feb 19 03:24:04 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 18 Feb 2015 18:24:04 -0800
Subject: [R] Help with declaring factors in a function
In-Reply-To: <CAKZWb7ey0Vwfh73LC6cBBY605vAtZzDGhPyfFKsd1tcwKbhoJA@mail.gmail.com>
References: <CAKZWb7ey0Vwfh73LC6cBBY605vAtZzDGhPyfFKsd1tcwKbhoJA@mail.gmail.com>
Message-ID: <CAF8bMcah5McS8h+pTKxp3cdJp060x0q7v_-j8bEqB2sfPwJqXg@mail.gmail.com>

You did not put the altered columns back into the data.frame,
so glm() never saw them.  Does the following work?

func <- function(x,y,z) {
#x is a data frame
#y is a formula for the regression
#z vector of names of columns of x to convert to factors
    for (name in z) {
        x[[name]] <- factor(x[[name]])
    }
    glm(y, x, family=binomial(link = "logit"))
}


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Feb 18, 2015 at 5:40 PM, Evan Kransdorf <evan.kransdorf at gmail.com>
wrote:

> Hello,
>
> I am passing a df to a function and then want to declare factors (based on
> a vector of column names in the df) for a logistic regression. I am having
> trouble - R doesn't seem to recognize the factors as declared in the
> function? Below is my code.  Does anyone have any ideas?
>
> MyFunction <- function(x,y,z) {
> #x is a data frame
> #y is a formula for the regression
> #z vector of factors to be declared
>     name<-NULL
>     temp<-NULL
>     for (i in 1 : length(z)) {
>         name<-paste0(substitute(x),"$",z[i])
>         print(name)
>         temp<-eval(parse(text = name))
>         temp<-factor(temp)
>         print(levels(temp))
>     } #for
>     model<-glm(y, x, family=binomial(link = "logit"))
>     return(model)
> } #func
>
> Thanks very much!!!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kate.ignatius at gmail.com  Thu Feb 19 04:33:48 2015
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Wed, 18 Feb 2015 22:33:48 -0500
Subject: [R] grepping out columns
In-Reply-To: <CAE8W1T13qzzqYdjg6H5752tBZpPt6QZrH9H9e0jkHPytBuueMQ@mail.gmail.com>
References: <CAE6QMsaephiW24HTTm73gMrHgBRbF1KSe4hBcXHSZ85dA41qrw@mail.gmail.com>
	<D00BA82A-64BD-4EC1-9E0D-A18CAE9C37CA@comcast.net>
	<CAE8W1T13qzzqYdjg6H5752tBZpPt6QZrH9H9e0jkHPytBuueMQ@mail.gmail.com>
Message-ID: <CAE6QMsaqcQ0LZaH+8sG3LySE=oQKnEUgfn-2wRuXBxNvyFbXdw@mail.gmail.com>

Thanks!  That was helpful.  Although I think there was a typo in the last line:

selected <- sort(unique(unlist(all_ind)))

but I figured it out :)

K.

On Wed, Feb 18, 2015 at 4:10 PM, Federico Lasa <felasa at gmail.com> wrote:
> David's almost works except it catches the "MONTH" column, just add an
> empty metacharacter tho.
>
> c("DAY",
> "MONTH",
> "YEAR",
> "SA_TUES",
> "SA_MON",
> "SU_WED",
> "CH_TUES",
> "CH_WED",
> "CH_MON",
> "AR_TUES",
> "AR_WED",
> "AR_MON",
> "SA_THUR",
> "SU_FRI",
> "CH_THUR",
> "CH_FRI",
> "AR_THUR",
> "AR_FRI")-> columns
>
> sa_ind <- grep("SA_",columns)
> days <- gsub("SA_","", columns[sa_ind])
> days <- paste0(days,"$")
> selected <- lapply(days, function(x) grep(x,columns))
> selected <- sort(unique(unlist(all_ind)))
>
> columns[selected]
> [1] "SA_TUES" "SA_MON"  "CH_TUES" "CH_MON"  "AR_TUES" "AR_MON"
> "SA_THUR" "CH_THUR" "AR_THUR"
>
> On Wed, Feb 18, 2015 at 2:55 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>> On Feb 18, 2015, at 12:27 PM, Kate Ignatius wrote:
>>> Hi,
>>>
>>> I've got a complicated grep problem (or not)...  I currently have a
>>> file with the headings as follows:
>>>
>> Lets assume these values are in a character vector named 'dat'.
>>> SA_TUES
>>> SA_MON
>>> SU_WED
>>> CH_TUES
>>> CH_WED
>>> CH_MON
>>> AR_TUES
>>> AR_WED
>>> AR_MON
>>> SA_THUR
>>> SU_FRI
>>> CH_THUR
>>> CH_FRI
>>> AR_THUR
>>> AR_FRI
>>
>>  sadays <- dat[grep("SA", dat) ]
>>  sads <- gsub("SA_","",sadays)
>>  sads
>> #[1] "TUES" "MON"  "THUR"
>>
>>  dat[ sapply(sads, grep, dat) ]
>> #[1] "SA_TUES" "CH_TUES" "AR_TUES" "SA_MON"  "CH_MON"  "AR_MON"
>> #[7] "SA_THUR" "CH_THUR" "AR_THUR
>>
>> --
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From Merce.CasasPrat at ec.gc.ca  Wed Feb 18 23:06:31 2015
From: Merce.CasasPrat at ec.gc.ca (CasasPrat,Merce [Ontario])
Date: Wed, 18 Feb 2015 17:06:31 -0500
Subject: [R] find a previous command that starts with a certain letter
Message-ID: <EB98C3C1744CDF4F9D31F7ACFC666A9E0A4A51CD@OntExch3.ontario.int.ec.gc.ca>

Hi,

I'm new to R (was using Matlab previously)

Matlab has a very convenient utility that I haven't been able to find in R. When working interactively, you can find a previous command that starts with a certain letter by typing such a letter and then pressing the cursor up key. In R I've seen that, despite the letter you type, when pressing the cursor up key, it goes to the immediately previous command.

So, do you know if there is any way in R to quickly search for previous commands starting with a certain letter?

 

Thanks!!

Merc?

 


	[[alternative HTML version deleted]]


From jsimino at umc.edu  Thu Feb 19 02:05:11 2015
From: jsimino at umc.edu (Jeannette Simino)
Date: Thu, 19 Feb 2015 01:05:11 +0000
Subject: [R] SKAT for survey data
Message-ID: <5F8A9120C26DA94DA4F9690FF3B55924150D2A32@NTExMbx6.ntummc.umsmed.edu>

Hello all!
    Has anyone modified SKAT or another rare variant analysis packages to incorporate a subject's sampling weight?  I am trying to analyze genetic data from a study that chose a) all people from a previous ancillary study; b) those with an atypical diagnosis; and c) a small number of normals. In addition, many of the individuals selected could not or would not complete the measurement process. Fortunately, the weights back to the broader study population were already derived but I have no idea if the regular genetic packages have been extended to this situation.  Thanks so much! Jeannette
Individuals who have received this information in error or are not authorized to receive it must promptly return or dispose of the information and notify the sender. Those individuals are hereby notified that they are strictly prohibited from reviewing, forwarding, printing, copying, distributing or using this information in any way.

	[[alternative HTML version deleted]]


From efisio.solazzo at jrc.ec.europa.eu  Thu Feb 19 09:25:27 2015
From: efisio.solazzo at jrc.ec.europa.eu (efisio solazzo)
Date: Thu, 19 Feb 2015 09:25:27 +0100
Subject: [R] looping multipanel plots to different figures
Message-ID: <54E59DF7.4090102@jrc.ec.europa.eu>

Dear,
cannot find  a way to direct multipanel plots to different figures 
(files) while within a loop.

Say, the loop creates two plots each step: one plot should go to figure 
1 and the other to  figure 2.
Same for the next steps of the loop: the plots should go to figure 1 
and  figure 2 in a multipanel fashion.

I am not sure at which point to open the files and set the multipanel 
parameters...all I can get is two files with all plots overlaid to the 
same position.

Thanks


From pmassicotte at hotmail.com  Thu Feb 19 10:25:49 2015
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Thu, 19 Feb 2015 09:25:49 +0000
Subject: [R] Removing objects except user-defined functions
Message-ID: <COL127-W50CDF552462DE0B823A5EDB32D0@phx.gbl>

Dear R users.

I would like to remove all object from my workspace except the function I have defined. However, is I use rm(list = ls()) everything is cleared. I was thinking to typeof to get information about objects, but I could not get it working right.

Thank in advance,
Phil
 		 	   		  
	[[alternative HTML version deleted]]


From stephane.adamowicz at avignon.inra.fr  Thu Feb 19 10:33:43 2015
From: stephane.adamowicz at avignon.inra.fr (=?iso-8859-1?Q?St=E9phane_Adamowicz?=)
Date: Thu, 19 Feb 2015 10:33:43 +0100
Subject: [R] Removing objects except user-defined functions
In-Reply-To: <COL127-W50CDF552462DE0B823A5EDB32D0@phx.gbl>
References: <COL127-W50CDF552462DE0B823A5EDB32D0@phx.gbl>
Message-ID: <E93D90DB-F648-4867-88FB-CEBEC9D11481@avignon.inra.fr>

There is a function keep() in package gdata for this purpose

Le 19 f?vr. 2015 ? 10:25, philippe massicotte <pmassicotte at hotmail.com> a ?crit :

> Dear R users.
> 
> I would like to remove all object from my workspace except the function I have defined. However, is I use rm(list = ls()) everything is cleared. I was thinking to typeof to get information about objects, but I could not get it working right.
> 
> Thank in advance,
> Phil
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Feb 19 10:36:39 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 19 Feb 2015 20:36:39 +1100
Subject: [R] looping multipanel plots to different figures
In-Reply-To: <54E59DF7.4090102@jrc.ec.europa.eu>
References: <54E59DF7.4090102@jrc.ec.europa.eu>
Message-ID: <CA+8X3fWUoHqPh-rYYYhaBn+yXGkPrcieL9YWfKkhAv8w-nphow@mail.gmail.com>

Hi efisio,
I read this as wanting to start a new graphics device, then set some plot
parameters, display two plots and then close the graphics device at each
iteration of the loop. If so,

plot_filenames<-c("plot1.png","plot2.png","plot3.png")
for(plotfn in plot_filenames) {
 png(plotfn)
 par(mfrow=c(1,2))
 hist(sample(1:5,30,TRUE))
 hist(sample(1:5,30,TRUE))
 dev.off()
}

Jim



On Thu, Feb 19, 2015 at 7:25 PM, efisio solazzo <
efisio.solazzo at jrc.ec.europa.eu> wrote:

> Dear,
> cannot find  a way to direct multipanel plots to different figures (files)
> while within a loop.
>
> Say, the loop creates two plots each step: one plot should go to figure 1
> and the other to  figure 2.
> Same for the next steps of the loop: the plots should go to figure 1 and
> figure 2 in a multipanel fashion.
>
> I am not sure at which point to open the files and set the multipanel
> parameters...all I can get is two files with all plots overlaid to the same
> position.
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From efisio.solazzo at jrc.ec.europa.eu  Thu Feb 19 11:16:42 2015
From: efisio.solazzo at jrc.ec.europa.eu (efisio solazzo)
Date: Thu, 19 Feb 2015 11:16:42 +0100
Subject: [R] looping multipanel plots to different figures
In-Reply-To: <CA+8X3fWUoHqPh-rYYYhaBn+yXGkPrcieL9YWfKkhAv8w-nphow@mail.gmail.com>
References: <54E59DF7.4090102@jrc.ec.europa.eu>
	<CA+8X3fWUoHqPh-rYYYhaBn+yXGkPrcieL9YWfKkhAv8w-nphow@mail.gmail.com>
Message-ID: <54E5B80A.1020106@jrc.ec.europa.eu>

Thanks Jim,
actually I need to keep open two devices at the same time, and within 
the loop access either of them in alternation. In MatLab there is the 
command Figure(#) which keeps track of the open devices and direct the 
output of the plot to whichever of them.

For example:
plot_filenames<-c("plot1.png","plot2.png","plot3.png")
for (i in 1:5) {
  png(plot_filenames[1])
  par(mfrow=c(1,2))
  hist(sample(i:10,30,TRUE)) #???
  png(plot_filenames[2]) #???
  par(mfrow=c(1,2))
  hist(sample(i+1:15,30,TRUE))
  dev.off() #???
}

Hope I've been clear.

Thanks, Efisio
===========================================



On 19/02/2015 10:36, Jim Lemon wrote:
> Hi efisio,
> I read this as wanting to start a new graphics device, then set some 
> plot parameters, display two plots and then close the graphics device 
> at each iteration of the loop. If so,
>
> plot_filenames<-c("plot1.png","plot2.png","plot3.png")
> for(plotfn in plot_filenames) {
>  png(plotfn)
>  par(mfrow=c(1,2))
>  hist(sample(1:5,30,TRUE))
>  hist(sample(1:5,30,TRUE))
>  dev.off()
> }
>
> Jim
>
>
> On Thu, Feb 19, 2015 at 7:25 PM, efisio solazzo 
> <efisio.solazzo at jrc.ec.europa.eu 
> <mailto:efisio.solazzo at jrc.ec.europa.eu>> wrote:
>
>     Dear,
>     cannot find  a way to direct multipanel plots to different figures
>     (files) while within a loop.
>
>     Say, the loop creates two plots each step: one plot should go to
>     figure 1 and the other to  figure 2.
>     Same for the next steps of the loop: the plots should go to figure
>     1 and  figure 2 in a multipanel fashion.
>
>     I am not sure at which point to open the files and set the
>     multipanel parameters...all I can get is two files with all plots
>     overlaid to the same position.
>
>     Thanks
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Efisio SOLAZZO, Ph.D.
European Commission, Joint Research Centre,
Institute for Environment and Sustainability,
TP123, Via E. Fermi, 2749 I-21027 Ispra (VA), Italy
Tel: +390332789944 Fax: +390332785837



	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Feb 19 11:27:46 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 19 Feb 2015 05:27:46 -0500
Subject: [R] find a previous command that starts with a certain letter
In-Reply-To: <EB98C3C1744CDF4F9D31F7ACFC666A9E0A4A51CD@OntExch3.ontario.int.ec.gc.ca>
References: <EB98C3C1744CDF4F9D31F7ACFC666A9E0A4A51CD@OntExch3.ontario.int.ec.gc.ca>
Message-ID: <54E5BAA2.8040508@gmail.com>

On 18/02/2015 5:06 PM, CasasPrat,Merce [Ontario] wrote:
> Hi,
> 
> I'm new to R (was using Matlab previously)
> 
> Matlab has a very convenient utility that I haven't been able to find in R. When working interactively, you can find a previous command that starts with a certain letter by typing such a letter and then pressing the cursor up key. In R I've seen that, despite the letter you type, when pressing the cursor up key, it goes to the immediately previous command.
> 
> So, do you know if there is any way in R to quickly search for previous commands starting with a certain letter?

This depends on what front end you are using.  In the Windows Rgui.exe,
you get what you saw.  In front-ends using readline, you can do it by
hitting Ctrl-R first.  (The Windows command-line interface, Rterm.exe,
uses this, as do many others.)  If you're using some other front-end,
you'll need to read its documentation.

Duncan Murdoch


From drjimlemon at gmail.com  Thu Feb 19 11:45:28 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 19 Feb 2015 21:45:28 +1100
Subject: [R] looping multipanel plots to different figures
In-Reply-To: <54E5B80A.1020106@jrc.ec.europa.eu>
References: <54E59DF7.4090102@jrc.ec.europa.eu>
	<CA+8X3fWUoHqPh-rYYYhaBn+yXGkPrcieL9YWfKkhAv8w-nphow@mail.gmail.com>
	<54E5B80A.1020106@jrc.ec.europa.eu>
Message-ID: <CA+8X3fW23W0CPa1DS_+H=xT6ANJggyU5EZ3HJJ+=RbVQ7oK8wg@mail.gmail.com>

Hi efisio,
Okay, you can switch devices using the dev.* functions in the grDevices
package. If you only have two devices open at one time, this is not too
difficult:

#open both devices
png(...)
par(mfrow=c(1,2))
png(...)
par(mfrow=c(1,2))
hist(...)
dev.set(dev.next())
hist(...)
dev.set(dev.next())
# after end of loop
dev.off()
dev.off()

to switch devices. Remember to shut both down when the loop is complete.

Jim


Jim


On Thu, Feb 19, 2015 at 9:16 PM, efisio solazzo <
efisio.solazzo at jrc.ec.europa.eu> wrote:

>  Thanks Jim,
> actually I need to keep open two devices at the same time, and within the
> loop access either of them in alternation. In MatLab there is the command
> Figure(#) which keeps track of the open devices and direct the output of
> the plot to whichever of them.
>
> For example:
> plot_filenames<-c("plot1.png","plot2.png","plot3.png")
> for (i in 1:5) {
>  png(plot_filenames[1])
>  par(mfrow=c(1,2))
>  hist(sample(i:10,30,TRUE)) #???
>  png(plot_filenames[2]) #???
>  par(mfrow=c(1,2))
>  hist(sample(i+1:15,30,TRUE))
>  dev.off() #???
> }
>
> Hope I've been clear.
>
> Thanks, Efisio
> ===========================================
>
>
>
> On 19/02/2015 10:36, Jim Lemon wrote:
>
> Hi efisio,
> I read this as wanting to start a new graphics device, then set some plot
> parameters, display two plots and then close the graphics device at each
> iteration of the loop. If so,
>
> plot_filenames<-c("plot1.png","plot2.png","plot3.png")
> for(plotfn in plot_filenames) {
>  png(plotfn)
>  par(mfrow=c(1,2))
>  hist(sample(1:5,30,TRUE))
>  hist(sample(1:5,30,TRUE))
>  dev.off()
> }
>
>  Jim
>
>
>
> On Thu, Feb 19, 2015 at 7:25 PM, efisio solazzo <
> efisio.solazzo at jrc.ec.europa.eu> wrote:
>
>> Dear,
>> cannot find  a way to direct multipanel plots to different figures
>> (files) while within a loop.
>>
>> Say, the loop creates two plots each step: one plot should go to figure 1
>> and the other to  figure 2.
>> Same for the next steps of the loop: the plots should go to figure 1 and
>> figure 2 in a multipanel fashion.
>>
>> I am not sure at which point to open the files and set the multipanel
>> parameters...all I can get is two files with all plots overlaid to the same
>> position.
>>
>> Thanks
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Efisio SOLAZZO, Ph.D.
> European Commission, Joint Research Centre,
> Institute for Environment and Sustainability,
> TP123, Via E. Fermi, 2749 I-21027 Ispra (VA), Italy
> Tel: +390332789944 Fax: +390332785837
>
>

	[[alternative HTML version deleted]]


From cute_loomaa at hotmail.com  Thu Feb 19 14:23:04 2015
From: cute_loomaa at hotmail.com (hms Dreams)
Date: Thu, 19 Feb 2015 16:23:04 +0300
Subject: [R] Metro_Hastings
In-Reply-To: <DUB128-W16878C542F939ECC4DAFEE96210@phx.gbl>
References: <DUB128-W16878C542F939ECC4DAFEE96210@phx.gbl>
Message-ID: <DUB128-W8D892537F11BC6279A2BF962D0@phx.gbl>

Any suggestions :(  ??From: cute_loomaa at hotmail.com
To: r-help at r-project.org
Subject: Metro_Hastings I wrote my code again
Date: Sun, 15 Feb 2015 21:47:25 +0300





Hi again :)

I wrote my code here:



library("MHadaptive")
baysianlog=function (param,data)



        
{  alpha=param[1]

         
gam=param[2]



        
delta=param[3]


         
x=data


           n =length(x)


         
logl=n*log(alpha)+n*log(gam)+n*log(1/delta)+(alpha-1)*sum(log(x))-sum(log(1+(gam)*x^alpha))


       
p=prior(param)


       
return(logl+p) 


}


prior=function(param)


{  
alpha=param[1]


         
gam=param[2]


        
delta=param[3]


prior_alpha=dunif(alpha,min=0,
max=1,log=TRUE)


 prior_gam=dunif(gam,0,1,log=TRUE)  


prior_delta=dunif(delta,0,1,log=TRUE)  


return(prior_alpha+ prior_gam +prior_delta) 


}


 


n=7 ; m=15


alphaB=c();gamB=c();deltaB=c()


for( i 
in 1:m){


alpha=1.8;gam=3;delta=0.8


v= runif(n)


x =delta*((1-v)^(-1/gam)-1)^(1/alpha )


mcmc_r=Metro_Hastings(li_func=baysianlog, pars=c(1,1,1),par_names=c('alpha','gamma','delta'),data=x
)


 


alphaB[i] =mean(mcmc_r $ trac[,1]) 


gamB[i]=
mean(mcmc_r $ trac[,2])


deltaB[i]=
mean(mcmc_r $ trac[,3])


}#end for


#####


The output is:


Error in optim(pars, li_func,
control = list(fnscale = -1), hessian = TRUE,  :


 
non-finite finite-difference value [1]


________________

the problem I think in the :

mcmc_r=Metro_Hastings(li_func=baysianlog, pars=c(1,1,1),par_names=c('alpha','gamma','delta'),data=x )
because  I did not write the prop_sigma because I don't know how can I calcalute the covariance matrix.
 
somebody told me to compute the cov without itreation then  add the reasulting cov matrix to metro hasting using itreation
but it also gave me  an error 
 
 Please anybody can check my code and correct it 
 
Thank you,
Sara
 		 	   		   		 	   		  
	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Thu Feb 19 15:06:53 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 19 Feb 2015 14:06:53 +0000
Subject: [R] API request from R
In-Reply-To: <3ee0a0615a3147799567427d547c2899@EX-0-HT0.lancs.local>
References: <3ee0a0615a3147799567427d547c2899@EX-0-HT0.lancs.local>
Message-ID: <CANVKczN4c9AWoGRLdvxsMsUfWQv8Z3ogX_-0qiD9eDw790MBFA@mail.gmail.com>

On Wed, Feb 18, 2015 at 11:44 AM, Mittal Ashra via R-help
<r-help at r-project.org> wrote:
> Dear All,
> Apologies for mailing it to the whole crowd. This is Mittal, presently working in a Project where we have build a platform for displaying recommendations and the results are based on the statistical models.
> I have gone through the CRAN repository to look out for an package which converts the R code into an JAVA API and that can be called from the platform. However, did not find any. If anyone can guide me to the right package that will be grateful.
> The packages can be similar to DeployR from Revolution Analytics.

 I doubt there's anything smart enough to take a set of R functions
and magically create all the necessary Java boilerplate code that
constitutes an implementation of an API in Java (cynics would say Java
was all boilerplate...).

 There's the rJava package, which includes the JRI system for calling
R from Java. Then your java can kick off an R "engine" and do R stuff:

  [boilerplate code deleted]

  Rengine re=new Rengine(args, false, new TextConsole());

  [more deleted boilerplate]

  re.eval("data(iris)",false);

What you would have to do would be to write the Java
functions/methods/classes with the appropriate arguments for your API
and make them call the R code this way.

 I think RCaller is another way of doing this from Java - its not on
CRAN since its not an R package, its a Java library.

Barry


From loris.bennett at fu-berlin.de  Thu Feb 19 11:19:38 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Thu, 19 Feb 2015 11:19:38 +0100
Subject: [R] find a previous command that starts with a certain letter
References: <EB98C3C1744CDF4F9D31F7ACFC666A9E0A4A51CD@OntExch3.ontario.int.ec.gc.ca>
Message-ID: <874mqidwzp.fsf@hornfels.zedat.fu-berlin.de>

"CasasPrat,Merce [Ontario]" <Merce.CasasPrat at ec.gc.ca> writes:

> Hi,
>
> I'm new to R (was using Matlab previously)
>
> Matlab has a very convenient utility that I haven't been able to find
> in R. When working interactively, you can find a previous command that
> starts with a certain letter by typing such a letter and then pressing
> the cursor up key. In R I've seen that, despite the letter you type,
> when pressing the cursor up key, it goes to the immediately previous
> command.
>
> So, do you know if there is any way in R to quickly search for
> previous commands starting with a certain letter?
>
>  
>
> Thanks!!
>
> Merce

You should be able to do

Ctrl-r

(for "reverse search") and then type any part of the command you want.
You can then also do

Ctrl-s

(for "search") to search in the other direction (i.e. towards more
recently entered commands).

These are all functions of the "readline" library, which is also used in
many other programs (such as the "bash" shell).

Cheers,

Loris

-- 
This signature is currently under construction.


From js.huang at protective.com  Thu Feb 19 13:56:16 2015
From: js.huang at protective.com (JS Huang)
Date: Thu, 19 Feb 2015 04:56:16 -0800 (PST)
Subject: [R] About Read in .csv Files with Chinese Characters
In-Reply-To: <1424338641618-4703514.post@n4.nabble.com>
References: <1424338641618-4703514.post@n4.nabble.com>
Message-ID: <1424350576355-4703518.post@n4.nabble.com>

Hi,

  I tried your file in my Windows7 pc.  It worked fine except the display of
the variable name.  

R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

> Hello <- read.csv("Hello.csv");Hello
   gender brand  ??.?
1       m     1   Tom
2       f     2 David
3       f     2 Smith
4       f    NA  Nich
5       f     3  Dick
6       m     1 Shimm
7       m     1   Sam
8       f     4 Sandy
9       m     2 Elvin
10      f     3 Arlin



--
View this message in context: http://r.789695.n4.nabble.com/About-Read-in-csv-Files-with-Chinese-Characters-tp4703514p4703518.html
Sent from the R help mailing list archive at Nabble.com.


From j.kreft at bham.ac.uk  Thu Feb 19 15:47:14 2015
From: j.kreft at bham.ac.uk (Jan-Ulrich Kreft)
Date: Thu, 19 Feb 2015 14:47:14 +0000
Subject: [R] How to analyse nonlinear response to categorical and
 quantitative explanatory variables?
Message-ID: <FE15711A62D32F44BED5A7CB70F00B1648E522DB@EX8.adf.bham.ac.uk>

Dear list

I have data from a collaborator who has used DesignExpert to design the experiment and analyse the data but no longer has access to this software and does not know exactly what the software did and why.

So I?m now trying to analyse the data in R but can't quite decide what to do.

Cell count is the response variable (number of cells attached to a surface per unit area and time interval, so could be Poisson distributed).

This cell count depends on whether the surface was oriented upwards or downwards (categorical - with or against gravity). Some more categorical variables were also studied such as surface material (glass or polycarbonate, symbols g and p in the figure) and position in flow cell (inlet or outlet), but they seem to have no significant effect.

Cell count also depends on a quantitative variable in a nonlinear manner: the flow rate with which the cell suspension was pumped along the surface.

I was wondering which kind of statistical model would be appropriate. I was first thinking ANCOVA but this seems to be a linear model and treating the quantitative explanatory variable as covariate when this is actually of interest. What else could I use?

Attached a figure showing the means of 4 replicates.

Many thanks.

Best wishes,
Jan.

---
Dr Jan-Ulrich Kreft
+44 (0)121 41-48851
School of Biosciences
University of Birmingham, Birmingham, B15 2TT, UK
http://www.tinyurl.com/kreftlab
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Cells_vs_rpm_means2.pdf
Type: application/pdf
Size: 6730 bytes
Desc: Cells_vs_rpm_means2.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150219/79b2834f/attachment.pdf>

From gunter.berton at gene.com  Thu Feb 19 16:55:10 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 19 Feb 2015 07:55:10 -0800
Subject: [R] Fwd: How to analyse nonlinear response to categorical and
 quantitative explanatory variables?
In-Reply-To: <CACk-te3BUtcZL+w=jjzYscADKpgcPmf_Guur5Z_Px5Simazpng@mail.gmail.com>
References: <FE15711A62D32F44BED5A7CB70F00B1648E522DB@EX8.adf.bham.ac.uk>
	<CACk-te3BUtcZL+w=jjzYscADKpgcPmf_Guur5Z_Px5Simazpng@mail.gmail.com>
Message-ID: <CACk-te3VnXg2J0p0v4X-ZTJPW9vx8H7mJZTZcBp-AK-6j=Y4Ww@mail.gmail.com>

Statistical methodology questions are generally off topic here. This
list is about R programming. I suggest you post to a statistics site
like stats.stackexchange.com instead.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Feb 19, 2015 at 6:47 AM, Jan-Ulrich Kreft <j.kreft at bham.ac.uk> wrote:
> Dear list
>
> I have data from a collaborator who has used DesignExpert to design the experiment and analyse the data but no longer has access to this software and does not know exactly what the software did and why.
>
> So I?m now trying to analyse the data in R but can't quite decide what to do.
>
> Cell count is the response variable (number of cells attached to a surface per unit area and time interval, so could be Poisson distributed).
>
> This cell count depends on whether the surface was oriented upwards or downwards (categorical - with or against gravity). Some more categorical variables were also studied such as surface material (glass or polycarbonate, symbols g and p in the figure) and position in flow cell (inlet or outlet), but they seem to have no significant effect.
>
> Cell count also depends on a quantitative variable in a nonlinear manner: the flow rate with which the cell suspension was pumped along the surface.
>
> I was wondering which kind of statistical model would be appropriate. I was first thinking ANCOVA but this seems to be a linear model and treating the quantitative explanatory variable as covariate when this is actually of interest. What else could I use?
>
> Attached a figure showing the means of 4 replicates.
>
> Many thanks.
>
> Best wishes,
> Jan.
>
> ---
> Dr Jan-Ulrich Kreft
> +44 (0)121 41-48851
> School of Biosciences
> University of Birmingham, Birmingham, B15 2TT, UK
> http://www.tinyurl.com/kreftlab
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From varinsacha at yahoo.fr  Thu Feb 19 17:36:54 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Thu, 19 Feb 2015 16:36:54 +0000 (UTC)
Subject: [R] Density plots for Chi-square and F-distribution on my data
Message-ID: <2080856009.3196505.1424363814890.JavaMail.yahoo@mail.yahoo.com>

Dear R-helpers,

I want to compute the density plot (probability plot) of the Chi-square distribution.
My 2 categorical variables are gender (male, female) and colors of the eyes (blue, green and brown).

The sample size n = 100. The proportions are the following :

male and blue eyes : 10%
male and green eyes : 20%
male and brown eyes : 22%
female and blue eyes : 20%
female and green eyes : 13%
female and brown eyes : 15%

There are k-1 df = 6-1= 5

I don't know how to take into consideration the percents here above in my R code here below ?

x <- rchisq(100, 5)
hist(x, prob=TRUE)
curve( dchisq(x, df=5), col='red', add=TRUE)


Second point, I want to do the same, to compute the density plot, but this time for the Fisher distribution. 
My categorical variable is gender again (male, female)
My numerical variable is the mark in Mathematics test (3; 4; 5; 5.5)
The proportions are the following :
male and 3 : 10%
male and 4 : 15%
male and 5 : 10%
male and 5.5 : 15%
female and 3 : 12%
female and 4: 0%
female and 5 : 25%
female and 5.5 : 13%

There are df1=2-1= 1 and df2=8-2= 6

Again, I don't know how to take into consideration the percents here above in my R code here below ?


df(100, 1, 6, log = FALSE)
x <- rf(100, 1, 6)
hist(x, prob=TRUE)
curve( df(x,1,6), col='red', add=TRUE)

Best, 
Thanks for your help.


From varinsacha at yahoo.fr  Thu Feb 19 17:36:54 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Thu, 19 Feb 2015 16:36:54 +0000 (UTC)
Subject: [R] Density plots for Chi-square and F-distribution on my data
Message-ID: <2080856009.3196505.1424363814890.JavaMail.yahoo@mail.yahoo.com>

Dear R-helpers,

I want to compute the density plot (probability plot) of the Chi-square distribution.
My 2 categorical variables are gender (male, female) and colors of the eyes (blue, green and brown).

The sample size n = 100. The proportions are the following :

male and blue eyes : 10%
male and green eyes : 20%
male and brown eyes : 22%
female and blue eyes : 20%
female and green eyes : 13%
female and brown eyes : 15%

There are k-1 df = 6-1= 5

I don't know how to take into consideration the percents here above in my R code here below ?

x <- rchisq(100, 5)
hist(x, prob=TRUE)
curve( dchisq(x, df=5), col='red', add=TRUE)


Second point, I want to do the same, to compute the density plot, but this time for the Fisher distribution. 
My categorical variable is gender again (male, female)
My numerical variable is the mark in Mathematics test (3; 4; 5; 5.5)
The proportions are the following :
male and 3 : 10%
male and 4 : 15%
male and 5 : 10%
male and 5.5 : 15%
female and 3 : 12%
female and 4: 0%
female and 5 : 25%
female and 5.5 : 13%

There are df1=2-1= 1 and df2=8-2= 6

Again, I don't know how to take into consideration the percents here above in my R code here below ?


df(100, 1, 6, log = FALSE)
x <- rf(100, 1, 6)
hist(x, prob=TRUE)
curve( df(x,1,6), col='red', add=TRUE)

Best, 
Thanks for your help.


From gunter.berton at gene.com  Thu Feb 19 17:51:22 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 19 Feb 2015 08:51:22 -0800
Subject: [R] Density plots for Chi-square and F-distribution on my data
In-Reply-To: <2080856009.3196505.1424363814890.JavaMail.yahoo@mail.yahoo.com>
References: <2080856009.3196505.1424363814890.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CACk-te07QAiBkJPwxJ1-dQNGqbCTEbbGOsTJHPDKerz5eA+ayg@mail.gmail.com>

I think you might do well to consult a local statistical expert, as
you appear to be out of your statistical depth here.

Also, is this homework? If so, this is not a homework site (although
posters sometimes get help anyway).

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Feb 19, 2015 at 8:36 AM, varin sacha <varinsacha at yahoo.fr> wrote:
> Dear R-helpers,
>
> I want to compute the density plot (probability plot) of the Chi-square distribution.
> My 2 categorical variables are gender (male, female) and colors of the eyes (blue, green and brown).
>
> The sample size n = 100. The proportions are the following :
>
> male and blue eyes : 10%
> male and green eyes : 20%
> male and brown eyes : 22%
> female and blue eyes : 20%
> female and green eyes : 13%
> female and brown eyes : 15%
>
> There are k-1 df = 6-1= 5
>
> I don't know how to take into consideration the percents here above in my R code here below ?
>
> x <- rchisq(100, 5)
> hist(x, prob=TRUE)
> curve( dchisq(x, df=5), col='red', add=TRUE)
>
>
> Second point, I want to do the same, to compute the density plot, but this time for the Fisher distribution.
> My categorical variable is gender again (male, female)
> My numerical variable is the mark in Mathematics test (3; 4; 5; 5.5)
> The proportions are the following :
> male and 3 : 10%
> male and 4 : 15%
> male and 5 : 10%
> male and 5.5 : 15%
> female and 3 : 12%
> female and 4: 0%
> female and 5 : 25%
> female and 5.5 : 13%
>
> There are df1=2-1= 1 and df2=8-2= 6
>
> Again, I don't know how to take into consideration the percents here above in my R code here below ?
>
>
> df(100, 1, 6, log = FALSE)
> x <- rf(100, 1, 6)
> hist(x, prob=TRUE)
> curve( df(x,1,6), col='red', add=TRUE)
>
> Best,
> Thanks for your help.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From varinsacha at yahoo.fr  Thu Feb 19 18:16:06 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Thu, 19 Feb 2015 17:16:06 +0000 (UTC)
Subject: [R] Density plots for Chi-square and F-distribution on my data
In-Reply-To: <CACk-te07QAiBkJPwxJ1-dQNGqbCTEbbGOsTJHPDKerz5eA+ayg@mail.gmail.com>
References: <CACk-te07QAiBkJPwxJ1-dQNGqbCTEbbGOsTJHPDKerz5eA+ayg@mail.gmail.com>
Message-ID: <1487116517.3281515.1424366166354.JavaMail.yahoo@mail.yahoo.com>

Arg, just been caught !
No, just joking, it is a long time I don't have homework anymore. I keep on giving myself homeworks life long yes this is true. 
Anyways thanks for your response.
Best,




----- Mail original -----
De : Bert Gunter <gunter.berton at gene.com>
? : varin sacha <varinsacha at yahoo.fr>
Cc : "r-help at r-project.org" <r-help at r-project.org>
Envoy? le : Jeudi 19 f?vrier 2015 17h51
Objet : Re: [R] Density plots for Chi-square and F-distribution on my data

I think you might do well to consult a local statistical expert, as
you appear to be out of your statistical depth here.

Also, is this homework? If so, this is not a homework site (although
posters sometimes get help anyway).

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll





On Thu, Feb 19, 2015 at 8:36 AM, varin sacha <varinsacha at yahoo.fr> wrote:
> Dear R-helpers,
>
> I want to compute the density plot (probability plot) of the Chi-square distribution.
> My 2 categorical variables are gender (male, female) and colors of the eyes (blue, green and brown).
>
> The sample size n = 100. The proportions are the following :
>
> male and blue eyes : 10%
> male and green eyes : 20%
> male and brown eyes : 22%
> female and blue eyes : 20%
> female and green eyes : 13%
> female and brown eyes : 15%
>
> There are k-1 df = 6-1= 5
>
> I don't know how to take into consideration the percents here above in my R code here below ?
>
> x <- rchisq(100, 5)
> hist(x, prob=TRUE)
> curve( dchisq(x, df=5), col='red', add=TRUE)
>
>
> Second point, I want to do the same, to compute the density plot, but this time for the Fisher distribution.
> My categorical variable is gender again (male, female)
> My numerical variable is the mark in Mathematics test (3; 4; 5; 5.5)
> The proportions are the following :
> male and 3 : 10%
> male and 4 : 15%
> male and 5 : 10%
> male and 5.5 : 15%
> female and 3 : 12%
> female and 4: 0%
> female and 5 : 25%
> female and 5.5 : 13%
>
> There are df1=2-1= 1 and df2=8-2= 6
>
> Again, I don't know how to take into consideration the percents here above in my R code here below ?
>
>
> df(100, 1, 6, log = FALSE)
> x <- rf(100, 1, 6)
> hist(x, prob=TRUE)
> curve( df(x,1,6), col='red', add=TRUE)
>
> Best,
> Thanks for your help.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Thu Feb 19 19:09:11 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 19 Feb 2015 10:09:11 -0800
Subject: [R] Change error bar length in barplot2
In-Reply-To: <309400573.684629.1424191594390.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <A433E09DB52.00001030jrkrideau@inbox.com>


https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jmadinga at yahoo.fr
> Sent: Tue, 17 Feb 2015 16:46:34 +0000 (UTC)
> To: r-help at r-project.org
> Subject: [R] Change error bar length in barplot2
> 
> Hi,I'm new to R.I would like to make a barplot of parasite infection
> prevalence (with 95% confidence interval) by age group.I have 4 parasite
> species and 5 age-groups and the example by?Marc Schwartz (barplot2) fits
> very well to my data.However, I would like to plot my own 95%CI (as
> calculated with my own data) instead of "faked 95%CI" provided in the
> example.How can I proceed?
> Thank you in advance.?Joule
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From bjpcjp at gmail.com  Thu Feb 19 17:18:04 2015
From: bjpcjp at gmail.com (brian piercy)
Date: Thu, 19 Feb 2015 10:18:04 -0600
Subject: [R] Noob: How to upgrade from 3.0.2 on Ubuntu 14.04 LTS?
Message-ID: <CAHzeQCK-QOHaUd71UTKoZycCZnFCB7J6z-dzogR5Mjz9dzi+pQ@mail.gmail.com>

One of my favorite blogs (AnalyzeCore) uses the dplyr library which fails
in my environment (R 3.0.2.) I've tried upgrading my R package to get
around this issue, to no avail. I know I'm making a simple mistake but
haven't solved it. A simple "$ sudo apt-get install r-base --upgrade"
didn't get the job done.

How do I upgrade R in a Linux distro?

Many thanks,
@brianpiercy

	[[alternative HTML version deleted]]


From tara.dirilgen at ucdconnect.ie  Thu Feb 19 17:43:17 2015
From: tara.dirilgen at ucdconnect.ie (Tara Dirilgen)
Date: Thu, 19 Feb 2015 16:43:17 +0000
Subject: [R] Procrustes
Message-ID: <CABP52_2T+-RazYS9jpK8Lh3Q30JEvvRS5rzF3yvNvGvKPHsMyw@mail.gmail.com>

I have been using R to calculate the significance of Procrustes
correlations. With one series of data, where there are five cases, the
value returned for the correlation coefficient is one although there are
differences as shown by the procrustes error graph. Is there a statistical
reason for this? Similarly, when we look at the cas scores there is not a
systematic relationship between the two series of data.

Thanks

Tara

-- 
Tara Dirilgen
School of Biology & Environmental Science
Science Center West
University College Dublin
Belfield, Dublin 4
IRELAND
tara.dirilgen at ucdconnect.ie

	[[alternative HTML version deleted]]


From simon.tarr at adtrak.co.uk  Thu Feb 19 17:44:46 2015
From: simon.tarr at adtrak.co.uk (Simon Tarr)
Date: Thu, 19 Feb 2015 16:44:46 +0000
Subject: [R] Raster Help
Message-ID: <CAH+=eXAB0vR94SG3=QoYQQYEm6Q2tS9yJeQ1nUbyS12gj=+iPg@mail.gmail.com>

Hello everyone,

I need a little help with some R syntax to complete what (I think) is a
fairly straightforward task- hopefully someone can assist!

I have a raster map of the UK which is split into postcode areas (e.g. DE,
NG, NR etc. 127 postcodes in total).

I have installed the package 'raster' and have successfully plotted the
.img in R. All working and looks correct with the raster.

I also have a comma delimited CSV file containing the same postcodes as the
raster with another column next to it containing revenue for each postcode.

*I was wondering if someone could help me merge/bind the revenue figures
into the correct postcode in the raster so that I can plot revenue per
postcode.*

I feel I should be using cbind and reclassify to do this but I can't be
sure.

Any help would be appreciated. Thanks in advance!

Simon

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Thu Feb 19 19:19:44 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 19 Feb 2015 10:19:44 -0800
Subject: [R] Noob: How to upgrade from 3.0.2 on Ubuntu 14.04 LTS?
In-Reply-To: <CAHzeQCK-QOHaUd71UTKoZycCZnFCB7J6z-dzogR5Mjz9dzi+pQ@mail.gmail.com>
Message-ID: <A44B723784C.00001066jrkrideau@inbox.com>

This worked for me the last time I tried it and I'm running Ubuntu 14.04. (Note to self-time to upgrade to 14.10)

Installing or updating R
 sudo add-apt-repository ppa:marutter/rrutter
 sudo apt-get update
 sudo apt-get install r-base r-base-dev
from http://www.personal.psu.edu/mar36/blogs/the_ubuntu_r_blog/installing-r.html


John Kane
Kingston ON Canada


> -----Original Message-----
> From: bjpcjp at gmail.com
> Sent: Thu, 19 Feb 2015 10:18:04 -0600
> To: r-help at r-project.org
> Subject: [R] Noob: How to upgrade from 3.0.2 on Ubuntu 14.04 LTS?
> 
> One of my favorite blogs (AnalyzeCore) uses the dplyr library which fails
> in my environment (R 3.0.2.) I've tried upgrading my R package to get
> around this issue, to no avail. I know I'm making a simple mistake but
> haven't solved it. A simple "$ sudo apt-get install r-base --upgrade"
> didn't get the job done.
> 
> How do I upgrade R in a Linux distro?
> 
> Many thanks,
> @brianpiercy
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jrkrideau at inbox.com  Thu Feb 19 19:42:54 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 19 Feb 2015 10:42:54 -0800
Subject: [R] ggplot2 shifting bars to only overlap in groups
In-Reply-To: <CAM5FmSN0o8ZxEyOm_8M3tnTyH3wDNRAxvzHh6_XiuskQG6vLyw@mail.gmail.com>
References: <cam5fmsmaidzgj+d5drptguhbm4v1tr6aljjtdjskqcmfs5w49w@mail.gmail.com>
	<7120dbaad3f.0000064fjrkrideau@inbox.com>
	<5885a05522b.0000053fjrkrideau@inbox.com>
	<4b1afade554.0000031bjrkrideau@inbox.com>
	<7c4ce5173e6.000001a3jrkrideau@inbox.com>
	<4ad1edc7c1f.00000299jrkrideau@inbox.com>
	<cam5fmsm-jucvyy6pzxfsvduzek2+gqg8smti++lxfg3sl0npqg@mail.gmail.com>
	<8a6e9310a6b.00000375jrkrideau@inbox.com>
	<cam5fmspcz-0h5hbbmfkymsgg8tcxmofhieg_-gtre9_uynuaaw@mail.gmail.com>
	<cam5fmsmnokft_x+2x5r0=wmklsnbzxzk3b6fs7t=u-igxhmj4a@mail.gmail.com>
	<cam5fmspbv2v23ojbj=zsp4hi8onhh-rby2g1utxx-sbkqveifa@mail.gmail.com>
	<cam5fmsn5kxqxf2gsqdyg2cfaqmpbcwsauy6qdwoj4k634abxha@mail.gmail.com>
Message-ID: <A47F3614119.000010B9jrkrideau@inbox.com>

Ah yes, with the full data set that looks rather good, indeed.  I tried it with the simulated data but there was not enough variation in the data to give any useful indication of what was happening.  

RE the quartile information, I don't know, it might be of use but it also might add to much clutter to the graph. A quick Google search suggest one approach using boxplots http://www.sthda.com/english/wiki/ggplot2-violin-plot-quick-start-guide-r-software-and-data-visualization but that might be overkill and produce too clutterd a graph in your case.  Still it looks nice :)

BTW I don't think you, strictly speaking, meant quantile information when writing about error-bars. My understanding (not good) is that they are not describing the quantiles of a distribution. Rather they are expressing information about the estimated distribution of the mean (or something like that--it's been a long time)


John Kane
Kingston ON Canada

-----Original Message-----
From: hyiltiz at gmail.com
Sent: Wed, 18 Feb 2015 01:40:17 +0800
To: jrkrideau at inbox.com
Subject: Re: [R] ggplot2 shifting bars to only overlap in groups

The code is the same as the last one I showed, except I used geom_violin() instead.

pp <- ggplot(dat1, aes(x = condition, y = t, color = gender, linetype = direction)) +

? geom_violin() +

? facet_wrap(~ location) +

? scale_color_manual(values = c("blue", "darkorange"))+

? theme_bw()+

? scale_y_continuous(breaks=seq(0.6,1.5,0.1))

And I have attached the resulted violin plot.

One big difference is that in order to plot violin plots, we need the un-summarized original data in the long format, rather than the summarized data as we used in the example above. But I am sorry that I can not share the original data, so in order to plot a whole violin plot, you just need to simulate out the data as we previously did.

I see that violin plots by ggplot2 does not contain the quantile information, but it would be nice if it did. Maybe I should just add another geom_errorbar for that.

???
========================
He who is worthy to receive his days and nights is worthy to receive* all 
else* from you (and me).
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? The Prophet, Gibran Kahlil 

On Wed, Feb 18, 2015 at 12:57 AM, John Kane <jrkrideau at inbox.com> wrote:

	I had never thought of violins.? It might be interesting. However , I still think there maybe some use out of the 4-panel approach.?

 What does your vioilin code look like?

 Using Denis' code

 gg<- ggplot(dat1, aes(x = condition, y = t, color = gender, linetype =
 direction)) +
 ? geom_errorbar(aes(ymin = t - ci, ymax = t + ci),
 ??????????????? position = position_dodge(width = 0.6), size = 1,
 ??????????????? width = 0.5) +
 ? geom_point(position = position_dodge(width = 0.6), size = 2.5) +
 ? facet_wrap(direction ~ location) +
 ? scale_color_manual(values = c("blue", "darkorange"))+
 ? theme_bw()+
 ? scale_y_continuous(breaks=seq(0.6,1.5,0.1))
 gg

 John Kane
 Kingston ON Canada

 -----Original Message-----
 From: hyiltiz at gmail.com

Sent: Tue, 17 Feb 2015 01:20:06 +0800
 To: jrkrideau at inbox.com
 Subject: Re: [R] ggplot2 shifting bars to only overlap in groups

 Again, I come to think about violin plots which is more informative than the error bars. But for some reason, the violin in the *west* became way too slimmer than the *east* one, though the density plot tells me that is not necessarily the case. I am still trying to figure that out, and that would be even more irrelevant as long as *shifting bars in gorups*. So maybe I will come up with another post later when I got the solution.

 ???
 ========================
 He who is worthy to receive his days and nights is worthy to receive* all
 else* from you (and me).
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? The Prophet, Gibran Kahlil

 On Mon, Feb 16, 2015 at 9:59 PM, John Kane <jrkrideau at inbox.com> wrote:

 ? ? ? ? Lovely, a much more elegant solution.

 ?John Kane
 ?Kingston ON Canada

 ?-----Original Message-----
 ?From: hyiltiz at gmail.com
 ?Sent: Mon, 16 Feb 2015 02:30:09 +0800
 ?To: jrkrideau at inbox.com, djmuser at gmail.com
 ?Subject: Re: [R] ggplot2 shifting bars to only overlap in groups

 Thanks so much, John and Dennis (who did not respond in the mailing list for some reason). I feel quite obliged to keep you thinking about this.?

 ?I do agree that not using the bar chart with error bars is a better option. And since *condition* is an important ordinal factor for me, it would be much better to have *condition* be positioned at a relative order. Thus, only color coding it as John's latest solution would not be optimal.?

 ?It would have been better with the random data, but with my actual data, it does seem necessary to do a jitter for the *male* since it got clattered in the *west*. Here is the actual data along with the solution based on Dennis' code:

 ?## data

 ?dat1 <- ?structure(list(t = c(1.2454860689532, 0.627186899108052, 0.877176019393987,?

 ?? ? ? ? ? ? ? ? ? ? ? ?1.26720638917869, 1.16906482219006, 0.889738853288831, 0.852034797572489,?

 ?? ? ? ? ? ? ? ? ? ? ? ?1.30007600828822, 1.22896141479778, 0.820236562746995, 0.822197641624559,?

 ?? ? ? ? ? ? ? ? ? ? ? ?1.39529772379005, 1.10479557445486, 0.760017179713665, 0.761340230517717,?

 ?? ? ? ? ? ? ? ? ? ? ? ?1.11132156961026, 1.30042963441715, 0.811425854755042, 0.979421690403349,?

 ?? ? ? ? ? ? ? ? ? ? ? ?1.3297658281305, 1.13377482477157, 0.895243910826397, 0.874181486658082,?

 ?? ? ? ? ? ? ? ? ? ? ? ?1.15728885642541, 1.11121780853125, 0.703348405369258, 0.850897112058048,?

 ?? ? ? ? ? ? ? ? ? ? ? ?1.14260584106012, 1.09383015337114, 0.911388765620587, 0.84622335453925,?

 ?? ? ? ? ? ? ? ? ? ? ? ?1.09847968194129), condition = structure(c(4L, 4L, 4L, 4L, 1L,?

 ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 1L,?

 ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L), .Label = c("c1",?

 ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? "c2", "c2", "c4"), class = "factor"), direction = structure(c(1L,?

 ?? ? ? ? ? ? ? ? ? ? ? ?1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,?

 ?? ? ? ? ? ? ? ? ? ? ? ?1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L), .Label = c("up",?

 ?? ? ? ? ? ? ? ? ? ? ? ?"down"), class = "factor"), location = structure(c(2L, 1L, 2L,?

 ?? 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,?

 ?? 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L), .Label = c("east",?

 ?? "west"), class = "factor"), gender = structure(c(2L, 2L, 2L,?

 ?? 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L,?

 ?? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("male",?

 ?? "female"), class = "factor"), ci = c(0.0307396796826649, 0.0302954863637637,?

 ?0.0400142340797275, 0.0527186825100342, 0.051675810189946, 0.0368383294010065,?

 ?0.0404823188495183, 0.0526312391852324, 0.0347332720922338, 0.0354587857740343,?

 ?0.0303368490163547, 0.0710445198259065, 0.0229339653012889, 0.0261217906562281,?

 ?0.0285673216713352, 0.0351642108247828, 0.0542657646932069, 0.0566816739316165,?

 ?0.0481239729953889, 0.0434272572423839, 0.0497366325101659, 0.0342004255233646,?

 ?0.0349733697554762, 0.0405364256564456, 0.0478372176424872, 0.0341294939361437,?

 ?0.0424566961614424, 0.0463489561778199, 0.0191707406475215, 0.0501106812754005,?

 ?0.0321562411182704, 0.0218613299095178)), .Names = c("t", "condition",?

 ?"direction", "location", "gender", "ci"), row.names = c(NA, -32L

 ?), class = "data.frame")

 ?pp <- ggplot(dat1, aes(x = condition, y = t, color = gender, linetype = direction)) +

 ?? geom_errorbar(aes(ymin = t - ci, ymax = t + ci),

 ?? ? ? ? ? ? ? ? position = position_dodge(width = 0.6), size = 1,

 ?? ? ? ? ? ? ? ? width = 0.5) +

 ?? geom_point(position = position_dodge(width = 0.6), size = 2.5) +

 ?? facet_wrap(~ location) +

 ?? scale_color_manual(values = c("blue", "darkorange"))+

 ?? theme_bw()+

 ?? scale_y_continuous(breaks=seq(0.6,1.5,0.1))

 ?pp

 ?## EOF

 ?I have also attached the output.?

 ??Best
 ??
 ?========================
 ?He who is worthy to receive his days and nights is worthy to receive* all
 ?else* from you (and me).
 ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? The Prophet, Gibran Kahlil

 ____________________________________________________________
 ?FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!

?Check it out at http://www.inbox.com/earth [http://www.inbox.com/earth] [http://www.inbox.com/earth [http://www.inbox.com/earth]]

 ____________________________________________________________
 FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
 Check it out at http://www.inbox.com/earth [http://www.inbox.com/earth]

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From ecnolasco at gmail.com  Thu Feb 19 19:47:03 2015
From: ecnolasco at gmail.com (Erica Cseko Nolasco)
Date: Thu, 19 Feb 2015 15:47:03 -0300
Subject: [R] 'java' had status 1
Message-ID: <CAMbrGjEO3vKGVAaJxS64s-8_BFiMDs2v=WWu+ro=FHLQa+Oigg@mail.gmail.com>

Dear all,

I?m trying to perform a modeling with Maxent, but I keep getting the
Warning message: running command 'java' had status 1.
I reinstalled Java jdk, I raised the memory to 1024, but it still gives me
the same Warning message. I?m testing with the data from
the vignette(topic="Include_MAXENT", package="biomod2").

First I would love to know what does the message means? I couldn't find on
internet or on the source code.
And, what is the solution for it?

Any thoughts?

Thanks in advance

*Erica Csek? Nolasco*
Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
http://lattes.cnpq.br/2117508819823917
Universidade Estadual de Feira de Santana
Avenida Transnordestina s/n, Novo Horizonte
Feira de Santana - BA, Brasil CEP 44.036-900.

Graduate Student in Modeling of Environmental and Earth Sciences
http://lattes.cnpq.br/2117508819823917
Universidade Estadual de Feira de Santana
Transnordestina Ave, Novo Horizonte
Feira de Santana - BA, Brazil 44.036-900.

	[[alternative HTML version deleted]]


From pbruneau at gmail.com  Thu Feb 19 19:49:57 2015
From: pbruneau at gmail.com (Pierrick Bruneau)
Date: Thu, 19 Feb 2015 19:49:57 +0100
Subject: [R] Procrustes
In-Reply-To: <CABP52_2T+-RazYS9jpK8Lh3Q30JEvvRS5rzF3yvNvGvKPHsMyw@mail.gmail.com>
References: <CABP52_2T+-RazYS9jpK8Lh3Q30JEvvRS5rzF3yvNvGvKPHsMyw@mail.gmail.com>
Message-ID: <CAF_q7hXUV9cDkGN3tmh2FCV+9wimRfkPFRFU_iYmRb+WY_CbVg@mail.gmail.com>

Hi Tara,

Providing a simple example script that reproduces your case and using
it to support your question would increase your chances to obtain an
answer.

Best,
Pierrick

On Thu, Feb 19, 2015 at 5:43 PM, Tara Dirilgen
<tara.dirilgen at ucdconnect.ie> wrote:
> I have been using R to calculate the significance of Procrustes
> correlations. With one series of data, where there are five cases, the
> value returned for the correlation coefficient is one although there are
> differences as shown by the procrustes error graph. Is there a statistical
> reason for this? Similarly, when we look at the cas scores there is not a
> systematic relationship between the two series of data.
>
> Thanks
>
> Tara
>
> --
> Tara Dirilgen
> School of Biology & Environmental Science
> Science Center West
> University College Dublin
> Belfield, Dublin 4
> IRELAND
> tara.dirilgen at ucdconnect.ie
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From js.huang at protective.com  Thu Feb 19 19:28:23 2015
From: js.huang at protective.com (JS Huang)
Date: Thu, 19 Feb 2015 10:28:23 -0800 (PST)
Subject: [R] About Read in .csv Files with Chinese Characters
In-Reply-To: <1424353733100-4703520.post@n4.nabble.com>
References: <1424338641618-4703514.post@n4.nabble.com>
	<1424350576355-4703518.post@n4.nabble.com>
	<1424353733100-4703520.post@n4.nabble.com>
Message-ID: <1424370503039-4703538.post@n4.nabble.com>

Hi Nicholas,

  I am not sure how much the following link can help but at least it is
related to your question.

http://r.789695.n4.nabble.com/Reading-Chinese-Language-GB2312-Input-td4647581.html

  Good luck!

JS



--
View this message in context: http://r.789695.n4.nabble.com/About-Read-in-csv-Files-with-Chinese-Characters-tp4703514p4703538.html
Sent from the R help mailing list archive at Nabble.com.


From angela.smith2071 at hotmail.com  Thu Feb 19 20:33:46 2015
From: angela.smith2071 at hotmail.com (Angela Smith)
Date: Thu, 19 Feb 2015 12:33:46 -0700
Subject: [R] how to convert raster images to .kasc format
Message-ID: <COL129-W68470DB483F0054382FD0A8E2D0@phx.gbl>

Hi R user, 
I was trying to convert raster images into *kasc format using "adehabitat" package in R. but I could not convert it. I spent a lot of time but no luck. would you mind to give some hints to convert this example data?. 

I would really appreciate for your help. 
cheers,

AS
#############
example

install.packages("raster")
install.packages("dismo")
install.packages("adehabitat")
library(dismo)
library(adehabitat)
library(raster)

predictors <- stack(list.files(path=paste(system.file(package="dismo"),'/ex', sep=''),pattern='grd', full.names=TRUE ))
predictors
plot(predictors)
test<-getkasc(kasc, predictors)
> test<-getkasc(kasc, predictors)
Error in getkasc(kasc, predictors) : Non convenient data
> 




 		 	   		  
	[[alternative HTML version deleted]]


From aron.lindberg at case.edu  Thu Feb 19 20:45:54 2015
From: aron.lindberg at case.edu (Aron Lindberg)
Date: Thu, 19 Feb 2015 11:45:54 -0800 (PST)
Subject: [R] Subsetting a list of lists using lapply
Message-ID: <1424375154254.274b59b@Nodemailer>

Hi Everyone,


I'm working on a thorny subsetting problem involving list of lists. I've put a dput of the data here:


	https://gist.githubusercontent.com/aronlindberg/b916dee897d051ac5be5/raw/a78cbf873a7e865c3173f943ff6309ea688c653b/dput


I can get one intense of the element I want this way:


	> input[[67]]$content[[1]]$sha
	[1] "58cf43ecdc1beb7e1043e9de612ecc817b090f15"


However, I need to use a lapply function to loop over all of the items of the list. I've tried something like this, but it doesn't work:


	get_shas <- function(input){
	x <- sapply(input, "[[", "content")
	y <- sapply(x, "[[", "sha")
	return(y)
	}


	sha_lists <- lapply(commit_lists, get_shas)


However, this doesn't work. When I run each of the lapply commands "manually" it returns NULL for every list, and when I run the whole apply function it says:?


	Error in FUN(X[[1L]], ...) : subscript out of bounds


I've tried reading the sections on lists and subsetting in Hadley's Advanced R, but I still cannot figure it out. Can anyone help or offer a pointer?


Best,
Aron


--?
Aron Lindberg


Doctoral Candidate,?Information Systems
Weatherhead School of Management?
Case Western Reserve University
aronlindberg.github.io
	[[alternative HTML version deleted]]


From tara.dirilgen at ucdconnect.ie  Thu Feb 19 20:40:05 2015
From: tara.dirilgen at ucdconnect.ie (Tara Dirilgen)
Date: Thu, 19 Feb 2015 19:40:05 +0000
Subject: [R] Procrustes
In-Reply-To: <CABP52_2T+-RazYS9jpK8Lh3Q30JEvvRS5rzF3yvNvGvKPHsMyw@mail.gmail.com>
References: <CABP52_2T+-RazYS9jpK8Lh3Q30JEvvRS5rzF3yvNvGvKPHsMyw@mail.gmail.com>
Message-ID: <CABP52_03t2qUNzG3nnoYVTcJL=QgGXCig7sQCr5K26Eq4JATvQ@mail.gmail.com>

Hi again,

Just to clarify my question from previous email...

Example script:
A <- data[, c(1,2,3,4)]
B <- data[, c(5,6,7,8)]
library(vegan)
vare.proc <- procrustes(A,B, scale=FALSE, symmetric=FALSE)
vare.proc
summary(vare.proc)
plot(vare.proc)
#plot(vare.proc, kind=2)
residuals(vare.proc)
protest(A,B, scores = "sites", permutations = 999)


Data A and B are case scores from PCA's.

*Question*
Protest output-  'Correlation in a symmetric Procrustes rotation' comes out
as 1 for each different data I input. This does not seem correct as the
graphical output suggests otherwise as well the raw case scores show
that there is not a systematic relationship between the two series of data.
I am wondering what the reason for this is.

Thanks & kind regards,

Tara

On 19 February 2015 at 16:43, Tara Dirilgen <tara.dirilgen at ucdconnect.ie>
wrote:

> I have been using R to calculate the significance of Procrustes
> correlations. With one series of data, where there are five cases, the
> value returned for the correlation coefficient is one although there are
> differences as shown by the procrustes error graph. Is there a statistical
> reason for this? Similarly, when we look at the cas scores there is not a
> systematic relationship between the two series of data.
>
> Thanks
>
> Tara
>
> --
> Tara Dirilgen
> School of Biology & Environmental Science
> Science Center West
> University College Dublin
> Belfield, Dublin 4
> IRELAND
> tara.dirilgen at ucdconnect.ie
>



-- 
Tara Dirilgen
School of Biology & Environmental Science
Science Center West
University College Dublin
Belfield, Dublin 4
IRELAND
tara.dirilgen at ucdconnect.ie

	[[alternative HTML version deleted]]


From rbaer at atsu.edu  Thu Feb 19 21:11:01 2015
From: rbaer at atsu.edu (Robert Baer)
Date: Thu, 19 Feb 2015 14:11:01 -0600
Subject: [R] API request from R
In-Reply-To: <CANVKczN4c9AWoGRLdvxsMsUfWQv8Z3ogX_-0qiD9eDw790MBFA@mail.gmail.com>
References: <3ee0a0615a3147799567427d547c2899@EX-0-HT0.lancs.local>
	<CANVKczN4c9AWoGRLdvxsMsUfWQv8Z3ogX_-0qiD9eDw790MBFA@mail.gmail.com>
Message-ID: <54E64355.6090709@atsu.edu>


On 2/19/2015 8:06 AM, Barry Rowlingson wrote:
> On Wed, Feb 18, 2015 at 11:44 AM, Mittal Ashra via R-help
> <r-help at r-project.org> wrote:
>> Dear All,
>> Apologies for mailing it to the whole crowd. This is Mittal, presently working in a Project where we have build a platform for displaying recommendations and the results are based on the statistical models.
>> I have gone through the CRAN repository to look out for an package which converts the R code into an JAVA API and that can be called from the platform. However, did not find any. If anyone can guide me to the right package that will be grateful.
>> The packages can be similar to DeployR from Revolution Analytics.
>   I doubt there's anything smart enough to take a set of R functions
> and magically create all the necessary Java boilerplate code that
> constitutes an implementation of an API in Java (cynics would say Java
> was all boilerplate...).
>
>   There's the rJava package, which includes the JRI system for calling
> R from Java. Then your java can kick off an R "engine" and do R stuff:
I thought rJava called java from R not the other way around.

Description: Low-level interface to Java VM very much like .C/.Call and friends. Allows creation of objects, calling methods and accessing fields.




>
>    [boilerplate code deleted]
>
>    Rengine re=new Rengine(args, false, new TextConsole());
>
>    [more deleted boilerplate]
>
>    re.eval("data(iris)",false);
>
> What you would have to do would be to write the Java
> functions/methods/classes with the appropriate arguments for your API
> and make them call the R code this way.
>
>   I think RCaller is another way of doing this from Java - its not on
> CRAN since its not an R package, its a Java library.
>
> Barry
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 


Robert W. Baer, Ph.D.
Professor of Physiology
Kirksville College of Osteopathic Medicine
A T Still University of Health Sciences
800 W. Jefferson St
Kirksville, MO 63501
rbaer(at)atsu.edu


	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Thu Feb 19 21:26:08 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 19 Feb 2015 20:26:08 +0000
Subject: [R] API request from R
In-Reply-To: <05c3422b58294260b19153d1bc678ca8@EX-0-HT0.lancs.local>
References: <3ee0a0615a3147799567427d547c2899@EX-0-HT0.lancs.local>
	<CANVKczN4c9AWoGRLdvxsMsUfWQv8Z3ogX_-0qiD9eDw790MBFA@mail.gmail.com>
	<05c3422b58294260b19153d1bc678ca8@EX-0-HT0.lancs.local>
Message-ID: <CANVKczNM9BxwE4-2T9yv=GA0041xuZCr17zc6RME6d26xoihFg@mail.gmail.com>

On 19 Feb 2015 20:11, "Robert Baer" <rbaer at atsu.edu> wrote:
>
>
> On 2/19/2015 8:06 AM, Barry Rowlingson wrote:
>>
>> On Wed, Feb 18, 2015 at 11:44 AM, Mittal Ashra via R-help
>> <r-help at r-project.org> wrote:
>>>
>>> Dear All,
>>> Apologies for mailing it to the whole crowd. This is Mittal, presently
working in a Project where we have build a platform for displaying
recommendations and the results are based on the statistical models.
>>> I have gone through the CRAN repository to look out for an package
which converts the R code into an JAVA API and that can be called from the
platform. However, did not find any. If anyone can guide me to the right
package that will be grateful.
>>> The packages can be similar to DeployR from Revolution Analytics.
>>
>>  I doubt there's anything smart enough to take a set of R functions
>> and magically create all the necessary Java boilerplate code that
>> constitutes an implementation of an API in Java (cynics would say Java
>> was all boilerplate...).
>>
>>  There's the rJava package, which includes the JRI system for calling
>> R from Java. Then your java can kick off an R "engine" and do R stuff:
>
> I thought rJava called java from R not the other way around.
>
> Description: Low-level interface to Java VM very much like .C/.Call and
friends. Allows creation of objects, calling methods and accessing fields.
>
>
>

Yes, but it includes the JRI code for calling R from Java. It's in the
package directory with some example Java programme.

>
>>
>>
>>   [boilerplate code deleted]
>>
>>   Rengine re=new Rengine(args, false, new TextConsole());
>>
>>   [more deleted boilerplate]
>>
>>   re.eval("data(iris)",false);
>>
>> What you would have to do would be to write the Java
>> functions/methods/classes with the appropriate arguments for your API
>> and make them call the R code this way.
>>
>>  I think RCaller is another way of doing this from Java - its not on
>> CRAN since its not an R package, its a Java library.
>>
>> Barry
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> --
>
>
> Robert W. Baer, Ph.D.
> Professor of Physiology
> Kirksville College of Osteopathic Medicine
> A T Still University of Health Sciences
> 800 W. Jefferson St
> Kirksville, MO 63501
> rbaer(at)atsu.edu

	[[alternative HTML version deleted]]


From sven.templer at gmail.com  Thu Feb 19 21:37:24 2015
From: sven.templer at gmail.com (Sven E. Templer)
Date: Thu, 19 Feb 2015 21:37:24 +0100
Subject: [R] Raster Help
In-Reply-To: <CAH+=eXAB0vR94SG3=QoYQQYEm6Q2tS9yJeQ1nUbyS12gj=+iPg@mail.gmail.com>
References: <CAH+=eXAB0vR94SG3=QoYQQYEm6Q2tS9yJeQ1nUbyS12gj=+iPg@mail.gmail.com>
Message-ID: <CAHuTOvp5Df_RF3YSkEjCS__=rqt-34MPAwTUk4JJMciGwR8QSg@mail.gmail.com>

Without (example) code it is hard to follow... use ?dput to present
some data (subset).
But if it is data.frames you are dealing with (for sure with read.csv,
but not so sure at all with raster maps), give this a try:

?merge

On 19 February 2015 at 17:44, Simon Tarr <simon.tarr at adtrak.co.uk> wrote:
> Hello everyone,
>
> I need a little help with some R syntax to complete what (I think) is a
> fairly straightforward task- hopefully someone can assist!
>
> I have a raster map of the UK which is split into postcode areas (e.g. DE,
> NG, NR etc. 127 postcodes in total).
>
> I have installed the package 'raster' and have successfully plotted the
> .img in R. All working and looks correct with the raster.
>
> I also have a comma delimited CSV file containing the same postcodes as the
> raster with another column next to it containing revenue for each postcode.
>
> *I was wondering if someone could help me merge/bind the revenue figures
> into the correct postcode in the raster so that I can plot revenue per
> postcode.*
>
> I feel I should be using cbind and reclassify to do this but I can't be
> sure.
>
> Any help would be appreciated. Thanks in advance!
>
> Simon
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From scolon725 at gmail.com  Thu Feb 19 21:13:32 2015
From: scolon725 at gmail.com (Samuel Colon)
Date: Thu, 19 Feb 2015 15:13:32 -0500
Subject: [R] Issue writing correct code for Coursera assignment--performing
	matrix inversion
Message-ID: <CA+sTf8LqS96YVPeKLWp0pFQQHDzO=9Tg8hcdM_vGkJoA6JH_0A@mail.gmail.com>

Hello All,

I'm new to this mailing list, so please let me know if I've committed any
posting faux-pas.

I'm working on an assignment for my Coursera course; please see my code
below in which I have tried to write two functions--to perform the task of
matrix inversion and then caching that data.  My code is below:

makeCacheMatrix <- function(x = matrix()) {

        i <- NULL

        set <- function(y) {

                x <<- y

                i <<- NULL

        }

        get <- function() x

        setinverse <- function(solve) i <<- solve

        getinverse <- function() i

        list(set = set, get = get, setinverse = setinverse,

             getinverse = getinverse)

}



cacheSolve <- function(x, ...) {

        i <- x$getinverse()

        if(!is.null(i)) {

                message("getting cached data")

                return(i)

        }

        data <- i$get()

        i <- solve(data, ...)

        x$setinverse(i)

        i

}

After I create a new matrix, x, and try to run cacheSolve(x), I receive
this error: "attempt to apply non-function."

I'm new to using the <<- operator, so I'm not sure if that's where my error
is?

Can anyone suggest how I can go about debugging the above code?

Thanks very much,

Sam Colon
Coursera Student

	[[alternative HTML version deleted]]


From c.danyluck at gmail.com  Thu Feb 19 21:32:49 2015
From: c.danyluck at gmail.com (Chad Danyluck)
Date: Thu, 19 Feb 2015 15:32:49 -0500
Subject: [R] Averaging column scores when participants vary in number of
	observations
Message-ID: <CA+_f+RFfJftFAcK6ZsW_xAUmk9k_Cwt0H8bNkx5xoy6EYnLf6g@mail.gmail.com>

I have a data set that includes the identity of a number of Video Coders
who scored participants' behaviors in a video. Every participant was scored
once, but some participants were randomly assigned to have their data
scored twice so I could calculate inter-rater reliabilities. I have
completed the reliability analyses and want to use the average score for
participants who had their behavior coded twice. I'd like to create a 'for
loop' or function that allows me to calculate these column means
iteratively because the number of observations is quite large (*N* =
168). Given the organization of the data, with some participants on
multiple rows, I am not sure how to proceed.

The original data looks something like this:

                        Participant ID Video Coder Score
Observation A                  1            Donald       4
Observation B                  1              Tracy       5
Observation C                  2            Donald       6
Observation D                  3                Sam       2
Observation E                  3              Tracy       3
Observation F                  4            Donald       2
Observation G                  4              Tracy       1
Observation H                  5               Sam       8

When the data processing is completed, I would like the new data set to
look like this:

Participant ID   Score
                 1          4.5
                 2            6
                 3          2.5
                 4          1.5
                 5            8

Any tips or suggestions would be appreciated.

Kind regards,

Chad
-- 
Chad M. Danyluck, MA
PhD Candidate, Psychology
University of Toronto



?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Feb 19 22:38:30 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 20 Feb 2015 10:38:30 +1300
Subject: [R] Subsetting a list of lists using lapply
In-Reply-To: <1424375154254.274b59b@Nodemailer>
References: <1424375154254.274b59b@Nodemailer>
Message-ID: <54E657D6.6090305@auckland.ac.nz>

On 20/02/15 08:45, Aron Lindberg wrote:
> Hi Everyone,
>
>
> I'm working on a thorny subsetting problem involving list of lists.

If you think this is "thorny" you ain't seen nothin' yet!

But note that you've got a list of lists of lists ... i.e. the nesting 
is at least 3 deep.

> I've put a dput of the data here:
>
> https://gist.githubusercontent.com/aronlindberg/b916dee897d051ac5be5/raw/a78cbf873a7e865c3173f943ff6309ea688c653b/dput
>

Thank you for creating a reproducible example.

> I can get one intense of the element I want this way:
>
> > input[[67]]$content[[1]]$sha [1]
> "58cf43ecdc1beb7e1043e9de612ecc817b090f15"
>
> However, I need to use a lapply function to loop over all of the
> items of the list. I've tried something like this, but it doesn't
> work:
>
> get_shas <- function(input){ x <- sapply(input, "[[", "content") y <-
> sapply(x, "[[", "sha") return(y) }
>
> sha_lists <- lapply(commit_lists, get_shas)
>
> However, this doesn't work. When I run each of the lapply commands
> "manually" it returns NULL for every list, and when I run the whole
> apply function it says:
>
>
> Error in FUN(X[[1L]], ...) : subscript out of bounds
>
>
> I've tried reading the sections on lists and subsetting in Hadley's
> Advanced R, but I still cannot figure it out. Can anyone help or
> offer a pointer?

At least part of the problem is that for some values of "i" 
input[[i]]$content[[1]] is a list (with an entry named "sha") and 
sometimes it is a character vector.

I don't follow your function get_shas() completely, so I started from 
scratch:

foo <- function (x){
sapply(x,function(y){
             z <- y$content[[1]]
             if(is.list(z)) z$sha else NA
          })
}

I find that foo(input) gives a vector of length 100, 81 entries of which 
are NA.  Entry number 67 at least agrees with what was shown in your email.

HTH

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From NordlDJ at dshs.wa.gov  Thu Feb 19 22:58:55 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 19 Feb 2015 21:58:55 +0000
Subject: [R] Averaging column scores when participants vary in number
	of	observations
In-Reply-To: <CA+_f+RFfJftFAcK6ZsW_xAUmk9k_Cwt0H8bNkx5xoy6EYnLf6g@mail.gmail.com>
References: <CA+_f+RFfJftFAcK6ZsW_xAUmk9k_Cwt0H8bNkx5xoy6EYnLf6g@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276623B0C48B@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Chad
> Danyluck
> Sent: Thursday, February 19, 2015 12:33 PM
> To: r-help at r-project.org
> Subject: Re: [R] Averaging column scores when participants vary in
> number of observations
> 
> I have a data set that includes the identity of a number of Video
> Coders
> who scored participants' behaviors in a video. Every participant was
> scored
> once, but some participants were randomly assigned to have their data
> scored twice so I could calculate inter-rater reliabilities. I have
> completed the reliability analyses and want to use the average score
> for
> participants who had their behavior coded twice. I'd like to create a
> 'for
> loop' or function that allows me to calculate these column means
> iteratively because the number of observations is quite large (*N* =
> 168). Given the organization of the data, with some participants on
> multiple rows, I am not sure how to proceed.
> 
> The original data looks something like this:
> 
>                         Participant ID Video Coder Score
> Observation A                  1            Donald       4
> Observation B                  1              Tracy       5
> Observation C                  2            Donald       6
> Observation D                  3                Sam       2
> Observation E                  3              Tracy       3
> Observation F                  4            Donald       2
> Observation G                  4              Tracy       1
> Observation H                  5               Sam       8
> 
> When the data processing is completed, I would like the new data set to
> look like this:
> 
> Participant ID   Score
>                  1          4.5
>                  2            6
>                  3          2.5
>                  4          1.5
>                  5            8
> 
> Any tips or suggestions would be appreciated.
> 
> Kind regards,
> 
> Chad

How about something like

aggregate(Score ~ Participant_ID, data=rating, mean)


hope this is helpful,

Dan

Daniel J. Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services



From murdoch.duncan at gmail.com  Thu Feb 19 23:06:06 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 19 Feb 2015 17:06:06 -0500
Subject: [R] Issue writing correct code for Coursera
 assignment--performing matrix inversion
In-Reply-To: <CA+sTf8LqS96YVPeKLWp0pFQQHDzO=9Tg8hcdM_vGkJoA6JH_0A@mail.gmail.com>
References: <CA+sTf8LqS96YVPeKLWp0pFQQHDzO=9Tg8hcdM_vGkJoA6JH_0A@mail.gmail.com>
Message-ID: <54E65E4E.7000705@gmail.com>

On 19/02/2015 3:13 PM, Samuel Colon wrote:
> Hello All,
> 
> I'm new to this mailing list, so please let me know if I've committed any
> posting faux-pas.

Yes, you should probably be using the Coursera support resources instead
of this list.

Duncan Murdoch

> 
> I'm working on an assignment for my Coursera course; please see my code
> below in which I have tried to write two functions--to perform the task of
> matrix inversion and then caching that data.  My code is below:
> 
> makeCacheMatrix <- function(x = matrix()) {
> 
>         i <- NULL
> 
>         set <- function(y) {
> 
>                 x <<- y
> 
>                 i <<- NULL
> 
>         }
> 
>         get <- function() x
> 
>         setinverse <- function(solve) i <<- solve
> 
>         getinverse <- function() i
> 
>         list(set = set, get = get, setinverse = setinverse,
> 
>              getinverse = getinverse)
> 
> }
> 
> 
> 
> cacheSolve <- function(x, ...) {
> 
>         i <- x$getinverse()
> 
>         if(!is.null(i)) {
> 
>                 message("getting cached data")
> 
>                 return(i)
> 
>         }
> 
>         data <- i$get()
> 
>         i <- solve(data, ...)
> 
>         x$setinverse(i)
> 
>         i
> 
> }
> 
> After I create a new matrix, x, and try to run cacheSolve(x), I receive
> this error: "attempt to apply non-function."
> 
> I'm new to using the <<- operator, so I'm not sure if that's where my error
> is?
> 
> Can anyone suggest how I can go about debugging the above code?
> 
> Thanks very much,
> 
> Sam Colon
> Coursera Student
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From antoviral at gmail.com  Fri Feb 20 00:13:47 2015
From: antoviral at gmail.com (Antonello Preti)
Date: Fri, 20 Feb 2015 00:13:47 +0100
Subject: [R] package 'corrplot'
Message-ID: <CAPmpGDuGCU_En2K7UzH-CFBHhBFZQqy3X3KUW99ctLQkdLd+TQ@mail.gmail.com>

I'm using the package 'corrplot' for a figure to be used in an academic
article.
The figure must be black-and-white.
I was able to produce a figure with some shades of grey (less than fifty,
admitedly).
However, the legend is still in red color.
I need the legend be in black color.
How can I get rid of the red color in the legend produced by'corrplot'?

Thank you in advance,
Antonello Preti

Here some code for exemplification.


### call the library

library(corrplot)
library(RColorBrewer)

### toy dataset

data(mtcars)

### assign the dataset to a vector

dat <- mtcars

### corrplot with shades of grey

corrplot.mixed(cor(dat), col = rev(brewer.pal(10, "Greys")))
title("\nCollinearity when r > 0.8")

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Feb 20 00:30:36 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 19 Feb 2015 18:30:36 -0500
Subject: [R] package 'corrplot'
In-Reply-To: <CAPmpGDuGCU_En2K7UzH-CFBHhBFZQqy3X3KUW99ctLQkdLd+TQ@mail.gmail.com>
References: <CAPmpGDuGCU_En2K7UzH-CFBHhBFZQqy3X3KUW99ctLQkdLd+TQ@mail.gmail.com>
Message-ID: <54E6721C.7070503@gmail.com>

On 19/02/2015 6:13 PM, Antonello Preti wrote:> I'm using the package
'corrplot' for a figure to be used in an academic
> article.
> The figure must be black-and-white.
> I was able to produce a figure with some shades of grey (less than fifty,
> admitedly).
> However, the legend is still in red color.
> I need the legend be in black color.
> How can I get rid of the red color in the legend produced by'corrplot'?

See the help page ?corrplot.  It appears that the ... argument to
corrplot.mixed can be any of the arguments to corrplot, and tl.col seems
to default to red.

Duncan Murdoch


>
> Thank you in advance,
> Antonello Preti
>
> Here some code for exemplification.
>
>
> ### call the library
>
> library(corrplot)
> library(RColorBrewer)
>
> ### toy dataset
>
> data(mtcars)
>
> ### assign the dataset to a vector
>
> dat <- mtcars
>
> ### corrplot with shades of grey
>
> corrplot.mixed(cor(dat), col = rev(brewer.pal(10, "Greys")))
> title("\nCollinearity when r > 0.8")
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From btyner at gmail.com  Fri Feb 20 00:31:08 2015
From: btyner at gmail.com (B Tyner)
Date: Thu, 19 Feb 2015 18:31:08 -0500
Subject: [R] non-terminal token lacking children from utils::getParseData
Message-ID: <CANauNAKw9-woZ0UM-rEfYgif3s4g_=13tqNU63RmrKAPK=Q1cQ@mail.gmail.com>

Hi,

I have run across a source file for which the return value
of getParseData() includes a record having FALSE for $terminal, yet it is
not the parent of any other tokens. Before I spend time constructing a
reproducible example, I wanted to verify that this is in fact unexpected
behavior (under R 3.1.2)?

Thanks,
Ben

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Feb 20 00:32:14 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Feb 2015 15:32:14 -0800
Subject: [R] package 'corrplot'
In-Reply-To: <CAPmpGDuGCU_En2K7UzH-CFBHhBFZQqy3X3KUW99ctLQkdLd+TQ@mail.gmail.com>
References: <CAPmpGDuGCU_En2K7UzH-CFBHhBFZQqy3X3KUW99ctLQkdLd+TQ@mail.gmail.com>
Message-ID: <5D0798F4-10B5-4801-9452-486E56FF1D90@comcast.net>


On Feb 19, 2015, at 3:13 PM, Antonello Preti wrote:

> I'm using the package 'corrplot' for a figure to be used in an academic
> article.
> The figure must be black-and-white.
> I was able to produce a figure with some shades of grey (less than fifty,
> admitedly).
> However, the legend is still in red color.
> I need the legend be in black color.
> How can I get rid of the red color in the legend produced by'corrplot'?
> 
> Thank you in advance,
> Antonello Preti
> 
> Here some code for exemplification.
> 
> 
> ### call the library
> 
> library(corrplot)
> library(RColorBrewer)
> 
> ### toy dataset
> 
> data(mtcars)
> 
> ### assign the dataset to a vector
> 
> dat <- mtcars
> 
> ### corrplot with shades of grey
> 
> corrplot.mixed(cor(dat), col = rev(brewer.pal(10, "Greys")))

`corrplot.mixed`'s help page says any extra arguments get passed to corrplot, so look at the help page for corrplot where teh tl.col parameter is described:

corrplot.mixed(cor(dat), col = rev(brewer.pal(10, "Greys")), tl.col = "black")


> title("\nCollinearity when r > 0.8")
> 
> 	[[alternative HTML version deleted]]


-- 
David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Fri Feb 20 00:34:21 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 19 Feb 2015 18:34:21 -0500
Subject: [R] non-terminal token lacking children from utils::getParseData
In-Reply-To: <CANauNAKw9-woZ0UM-rEfYgif3s4g_=13tqNU63RmrKAPK=Q1cQ@mail.gmail.com>
References: <CANauNAKw9-woZ0UM-rEfYgif3s4g_=13tqNU63RmrKAPK=Q1cQ@mail.gmail.com>
Message-ID: <54E672FD.90905@gmail.com>

On 19/02/2015 6:31 PM, B Tyner wrote:
> Hi,
> 
> I have run across a source file for which the return value
> of getParseData() includes a record having FALSE for $terminal, yet it is
> not the parent of any other tokens. Before I spend time constructing a
> reproducible example, I wanted to verify that this is in fact unexpected
> behavior (under R 3.1.2)?

Before I spend the time thinking about that, I'd like to see a
reproducible example.

Duncan Murdoch


From btyner at gmail.com  Fri Feb 20 03:03:07 2015
From: btyner at gmail.com (Benjamin Tyner)
Date: Thu, 19 Feb 2015 21:03:07 -0500
Subject: [R] non-terminal token lacking children from utils::getParseData
In-Reply-To: <54E672FD.90905@gmail.com>
References: <CANauNAKw9-woZ0UM-rEfYgif3s4g_=13tqNU63RmrKAPK=Q1cQ@mail.gmail.com>
	<54E672FD.90905@gmail.com>
Message-ID: <54E695DB.8010906@gmail.com>

I tried to reduce the offending portion as best I could to a
more-or-less minimal example (1136 bytes), which can be downloaded via:

    wget https://www.dropbox.com/s/74rgxr5x2aalr99/badstring.R

then once in R,

    > b <- parse(file = "~/badstring.R", keep.source = TRUE)
    > d <- getParseData(b, includeText = FALSE)
    > subset(d, line1 == 2L)
       line1 col1 line2 col2 id parent token terminal
    10     2    5    24    1 10     21  expr    FALSE
    > subset(d, parent == 10)
    [1] line1    col1     line2    col2     id       parent   token   
terminal
    <0 rows> (or 0-length row.names)
   
here is my

    > sessionInfo()
    R version 3.0.2 (2013-09-25)
    Platform: x86_64-pc-linux-gnu (64-bit)
   
    locale:
     [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C             
     [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8   
     [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8  
     [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                
     [9] LC_ADDRESS=C               LC_TELEPHONE=C           
    [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C      
   
    attached base packages:
    [1] stats     graphics  grDevices utils     datasets  methods   base

note that while it says R version 3.0.2 above, I have seen the same
behaviour under version 3.1.2 as well.

Regards
Ben

On 02/19/2015 06:34 PM, Duncan Murdoch wrote:
> On 19/02/2015 6:31 PM, B Tyner wrote:
>> Hi,
>>
>> I have run across a source file for which the return value
>> of getParseData() includes a record having FALSE for $terminal, yet it is
>> not the parent of any other tokens. Before I spend time constructing a
>> reproducible example, I wanted to verify that this is in fact unexpected
>> behavior (under R 3.1.2)?
> Before I spend the time thinking about that, I'd like to see a
> reproducible example.
>
> Duncan Murdoch
>
>



From hb at biostat.ucsf.edu  Fri Feb 20 04:35:55 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 19 Feb 2015 19:35:55 -0800
Subject: [R] Removing objects except user-defined functions
In-Reply-To: <COL127-W50CDF552462DE0B823A5EDB32D0@phx.gbl>
References: <COL127-W50CDF552462DE0B823A5EDB32D0@phx.gbl>
Message-ID: <CAFDcVCQPDZOP69uRMUArcS2-WhdnwspCzpx570ncG=Vymrw1pg@mail.gmail.com>

On Thu, Feb 19, 2015 at 1:25 AM, philippe massicotte
<pmassicotte at hotmail.com> wrote:
> Dear R users.
>
> I would like to remove all object from my workspace except the function I have defined. However, is I use rm(list = ls()) everything is cleared. I was thinking to typeof to get information about objects, but I could not get it working right.

names <- ls(envir=globalenv())
isfun <- sapply(names, FUN=exists, mode="function", envir=globalenv())
names <- names[!isfun]
rm(list=c(names, "names", "isfun"), envir=globalenv())

/Henrik

>
> Thank in advance,
> Phil
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From js.huang at protective.com  Fri Feb 20 02:36:19 2015
From: js.huang at protective.com (JS Huang)
Date: Thu, 19 Feb 2015 17:36:19 -0800 (PST)
Subject: [R] Averaging column scores when participants vary in number of
 observations
In-Reply-To: <CA+_f+RFfJftFAcK6ZsW_xAUmk9k_Cwt0H8bNkx5xoy6EYnLf6g@mail.gmail.com>
References: <CA+_f+RFfJftFAcK6ZsW_xAUmk9k_Cwt0H8bNkx5xoy6EYnLf6g@mail.gmail.com>
Message-ID: <1424396179744-4703561.post@n4.nabble.com>

Hi,

  Another implication:

> data1
  Observation Participant.ID Video.Coder Score
1           A              1      Donald     4
2           B              1       Tracy     5
3           C              2      Donald     6
4           D              3         Sam     2
5           E              3       Tracy     3
6           F              4      Donald     2
7           G              4       Tracy     1
8           H              5         Sam     8
> tapply(data1$Score,data1$Participant.ID,mean)
  1   2   3   4   5 
4.5 6.0 2.5 1.5 8.0 




--
View this message in context: http://r.789695.n4.nabble.com/Re-Averaging-column-scores-when-participants-vary-in-number-of-observations-tp4703549p4703561.html
Sent from the R help mailing list archive at Nabble.com.


From james at crosb.ie  Thu Feb 19 23:28:15 2015
From: james at crosb.ie (jcrosbie)
Date: Thu, 19 Feb 2015 14:28:15 -0800 (PST)
Subject: [R] Custom function causing an error with returning a ggplot object
 and Error in eval(expr, envir, enclos) : object '...' not found
Message-ID: <1424384895551-4703554.post@n4.nabble.com>

I'm trying to create a custom function to return a chart object. This
function seems to be having an error with calculating min/max/etc in the
ggplot object.

If I run the code for the ggplot not inside a custom function it works.

To reproduce this error after I need to clear the memory with (rm(list =
ls())) and reload the function and data.

How can I change my function to work correctly?

Sample data:

Date<-seq(as.Date("2000/1/1"), by = "week", length.out = 53*4)
ThousandBarrelsADay<-sample(1:1000, 53*4, replace=F)
yAxisTitle<-"Thousand Barrels per Day"
titleChart<-"test"
Function call:

p<-LinePlotTestStatsLine(Date, ThousandBarrelsADay, titleChart, yAxisTitle)
Error:

p
Error in eval(expr, envir, enclos) : object 'MinVal' not found

The code for the function:

LinePlotTestStatsLine<- function(xDateValues, yValues, titleChart,
yAxisTitle) {

dfTemp=0
#the sub title outlining the data range
subtitleChart = paste("(Data set from ", min(xDateValues), " to ",
max(xDateValues), ")", sep="")

#create a base dataframe
Week<- as.numeric(str_sub(ISOweek(xDateValues),start=-2))
dfTemp<-data.frame(xDateValues, Week, yValues)
dfTemp<- dfTemp[order(dfTemp$xDateValues),] 





#Summary Stat by week
dfTemp_Out<-describeBy(dfTemp$yValues, dfTemp$Week, mat = TRUE)
colnames(dfTemp_Out)[2]<-"Week"

#get the last year's of data Use 53 weeks because some years have 53 weeks
tempLast53<- tail(dfTemp, 53-length(dfTemp$yValues))
LableDateMinMax<-tempLast53$xDateValues[13]
LableDateMedian<-tempLast53$xDateValues[20]


#Chrate a base table for charting
ChartData1<-join(dfTemp_Out, tempLast53, type="inner")
#make sure the chart table is sorted
ChartData1<- ChartData1[order(ChartData1$xDateValues),] 


#find the max Date
MaxDate<- max(dfTemp$xDateValues)
maxYR<- max(year(dfTemp$xDateValues))

#min, Median, mean & max for hoizontal lines
MinVal<-min(dfTemp$yValues)
rMin<-max(which(dfTemp$yValues== MinVal, arr.ind = TRUE))
MinD<- dfTemp$xDateValues[rMin]

MaxVal<-max(dfTemp$yValues)
rMax<-max(which(dfTemp$yValues== MaxVal, arr.ind = TRUE))
MaxD<- dfTemp$xDateValues[rMax]

#Set the chart data
ChartData1_Plot <-ChartData1[,c("xDateValues","Week","yValues")]
ChartData1_Plot$Statistic<-paste("Past YR at ", MaxDate, sep="")


MedianVal<-median(dfTemp$yValues)
MeanVal<-mean(dfTemp$yValues)
stDev<- sd(dfTemp$yValues)
#ribbon to show one st. Dev. 
Ribbon<-data.frame(ChartData1[,c("xDateValues")])
Ribbon$Lower<-MeanVal-stDev
Ribbon$Higher<-MeanVal+stDev
colnames(Ribbon)<-c("xDateValues", "Lower", "Higher")
Ribbon$mean<-ChartData1$mean


#Set the seasons for charting
#Spring March 20, 2013
dSpring <- as.Date(paste("03/20/",maxYR, sep=""), "%m/%d/%Y")
if (MaxDate<=dSpring) { 
    dSpring <- as.Date(paste("03/20/",maxYR-1, sep=""), "%m/%d/%Y")
}  

#summer June 21, 2013
dSummer<-as.Date(paste("06/21/",maxYR, sep=""), "%m/%d/%Y")
if (MaxDate<=dSummer) { 
    dSummer<- as.Date(paste("06/21/",maxYR-1, sep=""), "%m/%d/%Y")
}  
#Autumn September 22, 2013 
dAutumn<-as.Date(paste("09/23/",maxYR, sep=""), "%m/%d/%Y")
if (MaxDate<=dAutumn) { 
    dAutumn<- as.Date(paste("09/23/",maxYR-1, sep=""), "%m/%d/%Y")
}  

# winter December 21, 2013
dWinter<-as.Date(paste("12/21/",maxYR, sep=""), "%m/%d/%Y")
if (MaxDate<=dWinter) { 
    dWinter<- as.Date(paste("12/21/",maxYR-1, sep=""), "%m/%d/%Y")
}  

ChartData_Plot <- ChartData1_Plot


p1<-ggplot(ChartData_Plot, aes(x=xDateValues,y=yValues))+
    geom_line(aes(group=Statistic, colour=Statistic))+
    scale_color_manual(values=c("black"))+
    geom_ribbon(data=Ribbon, aes(group = 1, y=mean, x=xDateValues,
ymin=Lower, ymax=Higher), alpha=0.1, fill="blue")+
    geom_hline(aes(yintercept=MinVal), color="red", linetype="dashed")+
    geom_hline(aes(yintercept=MaxVal), color="red", linetype="dashed")+
    annotate(geom="text", x = LableDateMinMax, y = MinVal-MaxVal/90, label =
paste("Min as at ", MinD, sep=""), colour = "red", size = 4)+
    annotate(geom="text", x = LableDateMinMax, y = MaxVal+MaxVal/40, label =
paste("Max as at ", MaxD, sep=""), colour = "red", size = 4)+
    geom_hline(aes(yintercept=MedianVal), color="darkgreen",
linetype="dashed")+
    geom_hline(aes(yintercept=MeanVal), color="blue", linetype="dashed")+
    annotate(geom="text", x = LableDateMinMax, y = MeanVal+MaxVal/40, label
= paste("Mean", sep=""), colour = "blue", size = 4)+
    annotate(geom="text", x = LableDateMedian, y = MedianVal+MaxVal/40,
label = paste("Median", sep=""), colour = "darkgreen", size = 4)+
    theme(legend.position="bottom")+
    geom_vline(xintercept = as.numeric(dSpring),colour="darkgrey")+
    geom_vline(xintercept = as.numeric(dSummer),colour="darkgrey")+
    geom_vline(xintercept = as.numeric(dAutumn),colour="darkgrey")+
    geom_vline(xintercept = as.numeric(dWinter),colour="darkgrey")+
    annotate(geom="text", x = c(dWinter+45, dSpring+45, dSummer+45,
dAutumn+45), y = MaxVal+MaxVal/10, label = c("Winter",
                "Spring", "Summer", "Autumn"), colour = "darkgrey",
                size = 4)+
    ggtitle(bquote(atop(.(titleChart), atop(italic(.(subtitleChart)),
""))))+
    labs(x = "")+
    scale_x_date(breaks="4 weeks",labels = date_format("%b-%Y"))+
    scale_y_continuous(labels = comma)+expand_limits(y = 0)+
    theme(axis.text.x  =
element_text(size=10,angle=45,colour="black",vjust=1,hjust=1))+
    labs(y = yAxisTitle)+
    theme(legend.position="none") 




    Footnote<-"Note: Shaded area represents one standard deviation from the
mean"

#p1<-arrangeGrob(p1, sub = textGrob(Footnote, x = 0, hjust = -0.1,
vjust=0.1, gp = gpar(fontface = "italic", fontsize = 10)))




return(p1)
}



--
View this message in context: http://r.789695.n4.nabble.com/Custom-function-causing-an-error-with-returning-a-ggplot-object-and-Error-in-eval-expr-envir-enclos-d-tp4703554.html
Sent from the R help mailing list archive at Nabble.com.


From mittal.ashra at yahoo.com  Fri Feb 20 03:41:58 2015
From: mittal.ashra at yahoo.com (Mittal Ashra)
Date: Fri, 20 Feb 2015 02:41:58 +0000 (UTC)
Subject: [R] API request from R
In-Reply-To: <CANVKczNM9BxwE4-2T9yv=GA0041xuZCr17zc6RME6d26xoihFg@mail.gmail.com>
References: <3ee0a0615a3147799567427d547c2899@EX-0-HT0.lancs.local>
	<CANVKczN4c9AWoGRLdvxsMsUfWQv8Z3ogX_-0qiD9eDw790MBFA@mail.gmail.com>
	<05c3422b58294260b19153d1bc678ca8@EX-0-HT0.lancs.local>
	<CANVKczNM9BxwE4-2T9yv=GA0041xuZCr17zc6RME6d26xoihFg@mail.gmail.com>
Message-ID: <2086523228.1114822.1424400118589.JavaMail.yahoo@mail.yahoo.com>

Dear All
Thanks for the reply.
RegardsMittal 

     On Friday, 20 February 2015 1:56 AM, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
   

 
On 19 Feb 2015 20:11, "Robert Baer" <rbaer at atsu.edu> wrote:
>
>
> On 2/19/2015 8:06 AM, Barry Rowlingson wrote:
>>
>> On Wed, Feb 18, 2015 at 11:44 AM, Mittal Ashra via R-help
>> <r-help at r-project.org> wrote:
>>>
>>> Dear All,
>>> Apologies for mailing it to the whole crowd. This is Mittal, presently working in a Project where we have build a platform for displaying recommendations and the results are based on the statistical models.
>>> I have gone through the CRAN repository to look out for an package which converts the R code into an JAVA API and that can be called from the platform. However, did not find any. If anyone can guide me to the right package that will be grateful.
>>> The packages can be similar to DeployR from Revolution Analytics.
>>
>>? I doubt there's anything smart enough to take a set of R functions
>> and magically create all the necessary Java boilerplate code that
>> constitutes an implementation of an API in Java (cynics would say Java
>> was all boilerplate...).
>>
>>? There's the rJava package, which includes the JRI system for calling
>> R from Java. Then your java can kick off an R "engine" and do R stuff:
>
> I thought rJava called java from R not the other way around.
>
> Description: Low-level interface to Java VM very much like .C/.Call and friends. Allows creation of objects, calling methods and accessing fields.
>
>
>Yes, but it includes the JRI code for calling R from Java. It's in the package directory with some example Java programme.>
>>
>>
>>?? [boilerplate code deleted]
>>
>>?? Rengine re=new Rengine(args, false, new TextConsole());
>>
>>?? [more deleted boilerplate]
>>
>>?? re.eval("data(iris)",false);
>>
>> What you would have to do would be to write the Java
>> functions/methods/classes with the appropriate arguments for your API
>> and make them call the R code this way.
>>
>>? I think RCaller is another way of doing this from Java - its not on
>> CRAN since its not an R package, its a Java library.
>>
>> Barry
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> -- 
>
>
> Robert W. Baer, Ph.D.
> Professor of Physiology
> Kirksville College of Osteopathic Medicine
> A T Still University of Health Sciences
> 800 W. Jefferson St
> Kirksville, MO 63501
> rbaer(at)atsu.edu

   
	[[alternative HTML version deleted]]


From ccberry at ucsd.edu  Fri Feb 20 04:53:04 2015
From: ccberry at ucsd.edu (Charles Berry)
Date: Fri, 20 Feb 2015 03:53:04 +0000
Subject: [R] Subsetting a list of lists using lapply
References: <1424375154254.274b59b@Nodemailer>
Message-ID: <loom.20150220T044432-198@post.gmane.org>

Aron Lindberg <aron.lindberg <at> case.edu> writes:

> 
> Hi Everyone,
> 
> I'm working on a thorny subsetting problem involving list of lists. I've put a 
dput of the data here:
> 
> 	https://gist.githubusercontent.com/aronlindberg/b916dee897d051ac5be5/
raw/a78cbf873a7e865c3173f943ff6309ea688c653b/dput
> 


IIUC, you want the value of every list element that is named "sha" and 
that name will only apply to atomic objects.

If so, this should do it. 

> input <- dget("/tmp/dpt")
> shas <- unlist( input, use.names=FALSE )[ grepl( "sha", names(unlist(input)))]
> input[[67]]$content[[1]]$sha
[1] "58cf43ecdc1beb7e1043e9de612ecc817b090f15"
> which(input[[67]]$content[[1]]$sha == shas )
[1] 194


HTH,

Chuck


From antoviral at gmail.com  Fri Feb 20 13:54:11 2015
From: antoviral at gmail.com (Antonello Preti)
Date: Fri, 20 Feb 2015 13:54:11 +0100
Subject: [R] colours in ggplot2
Message-ID: <CAPmpGDujAcqR8eOnGBTKTNbp-3LV2-0Rv3Qc6nXdDW_Px5w9bw@mail.gmail.com>

Hi, I'm using ggplot2 to make a plot of the regression of a variable x (let
say, levels of depression),
on a variable y (let say, degree of social impairment),
by taking into account a binary factor (having had or not a past admission
to a psychiatric service),
and age of partecipants.

After some search in Internet I produced a code which is satisfying to me.
This site was very helpful: http://editerna.free.fr/wp/?p=266

However, I have a problem: no matter what I try, the figures always include
bluette and pink flamingo colours.
The figure is for an academic article, and I cannot afford the price of
having the plot printed in colours.

I've extracted the structure of the figure, and I understand that the
problem is in the scale_name "hue",
but I cannot figure out how to deal with it.

Any way to override the ggplot2 system of dealing with factors?

Here the codes and the sessionInfo
The code is a bit baroque, but this is the best I was able to do.


Thank you in advance,
Antonello Preti



######## code for exemplification

### the dataset

df <- structure(list(Social_impairment = c(2.83, 3.08, 2.75, 2.08,
2.92, 1.75, 3.5, 2.33, 2.91, 2.5, 3.25, 2.64, 3.25, 2.83, 2.08,
2.25, 2.17, 2.42, 2.58, 2.42, 2.58, 2.42, 3, 3, 2.83, 2.67, 3.58,
1.58, 2.83, 2.83, 2.67, 3.17, 2.42, 1.92, 2.92, 2.5, 2.42, 2.42,
2.58, 2.42, 3.33, 3, 3.17, 2.17, 2.58, 2.67, 2.58, 3.75, 2.5,
2.08, 2.25, 3.25, 3.17, 2.91, 2.08, 2.25, 3.08, 2.91, 3.08, 2.92,
1.83, 2.5, 2.5, 2.83, 2.67, 3.33, 2.83, 3.33, 2.92, 3), Levels_Depression =
c(1.3,
1.71, 3.08, 0.48, 0.51, 0.71, 1.37, 0.2, 1.21, 1.07, 2.8, 1.24,
0.46, 0.97, 0.81, 1.13, 1.58, 3.12, 1.8, 1.54, 1.02, 0.32, 2.63,
1.39, 1.34, 2.37, 2.6, 1.11, 1.59, 2.17, 1.99, 0.59, 0.76, 0.23,
2.22, 1.98, 0.41, 0.32, 0.37, 1.11, 2.29, 0.97, 1.61, 1.27, 1.22,
2.38, 1.28, 1.21, 0.93, 2.3, 0.8, 2.1, 2.86, 2.47, 2.34, 2.67,
0.31, 0.88, 1.84, 0.23, 2.41, 0.56, 2.03, 1.11, 0.12, 2.39, 0.34,
2.08, 1.01, 1.51), Age = c(66, 59, 49, 70, 42, 55, 28, 41, 69,
65, 40, 21, 18, 77, 28, 40, 47, 37, 47, 39, 32, 33, 42, 28, 59,
49, 29, 41, 22, 29, 53, 39, 55, 61, 30, 49, 43, 46, 18, 36, 34,
17, 42, 37, 37, 54, 48, 23, 71, 42, 52, 83, 19, 47, 23, 80, 43,
38, 47, 80, 36, 73, 74, 51, 76, 14, 65, 39, 17, 73), Past_Admissions = c(1,
1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,
1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,
0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,
1, 0, 1, 0, 0, 1)), .Names = c("Social_impairment", "Levels_Depression",
"Age", "Past_Admissions"), row.names = c(NA, 70L), class = "data.frame")

dim(df)
head(df)
str(df)
summary(df)


### call the library

library(ggplot2)


#### the plot


#### Levels_Depression on Social_impairment by Past_Admissions (yes/no)
#### linear model
#### radius of the bubbles proportional to age


#### background elimination

p1 <- ggplot(data = df, aes(x =Levels_Depression, y = Social_impairment,
group = as.factor(Past_Admissions), col = as.factor(Past_Admissions))) +
  geom_point(aes(size = Age)) + geom_smooth(method = "lm") + xlab("Levels
of depression") + ylab("Social impairment") +
  scale_colour_discrete("History of \npast admissions\nto a psychiatric
service", labels = c("No", "Yes"))

p1 + theme(panel.grid.major = element_blank(), panel.grid.minor =
element_blank(),
    panel.background = element_blank(), axis.line = element_line(colour =
"black"))


### change of then axes' ticks

p1 + theme(panel.grid.major = element_blank(), panel.grid.minor =
element_blank(),
    panel.background = element_blank(), axis.line = element_line(colour =
"black"),
    axis.text = element_text(color = "black", size = 12, face = "italic"))


### after saving, dev.off()
###


#### Age on Social_impairment by Past_Admissions (yes/no)
#### linear model
#### radius of the bubbles proportional to Levels_Depression



#### background elimination

p2 <- ggplot(data = df, aes(x =Age , y = Social_impairment, group =
as.factor(Past_Admissions), col = as.factor(Past_Admissions))) +
  geom_point(aes(size = Levels_Depression)) + geom_smooth(method = "lm")
+xlab("Age of participants") + ylab("Social impairment") +
  scale_colour_discrete("History of \npast admissions\nto a psychiatric
service", labels = c("No", "Yes"))

p2 + theme(panel.grid.major = element_blank(), panel.grid.minor =
element_blank(),
    panel.background = element_blank(), axis.line = element_line(colour =
"black"))


### change of then axes' ticks

p2 + theme(panel.grid.major = element_blank(), panel.grid.minor =
element_blank(),
    panel.background = element_blank(), axis.line = element_line(colour =
"black"),
    axis.text = element_text(color = "black", size = 12, face = "italic"))


### after saving, dev.off()
###


########################
#### paired plots
########################

library(gridExtra)

grid.arrange(p1, p2, ncol = 2)



########################
### sessionInfo()
########################

R version 3.0.2 (2013-09-25)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252
[3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C
[5] LC_TIME=Italian_Italy.1252

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] gridExtra_0.9.1 ggplot2_0.9.3.1

loaded via a namespace (and not attached):
 [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.4
gtable_0.1.2
 [5] labeling_0.2       MASS_7.3-33        munsell_0.4.2
plyr_1.8
 [9] proto_0.3-10       RColorBrewer_1.0-5 reshape2_1.2.2
scales_0.2.3
[13] stringr_0.6.2

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Feb 20 14:02:46 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 20 Feb 2015 14:02:46 +0100
Subject: [R] colours in ggplot2
In-Reply-To: <CAPmpGDujAcqR8eOnGBTKTNbp-3LV2-0Rv3Qc6nXdDW_Px5w9bw@mail.gmail.com>
References: <CAPmpGDujAcqR8eOnGBTKTNbp-3LV2-0Rv3Qc6nXdDW_Px5w9bw@mail.gmail.com>
Message-ID: <CAJuCY5xmPax89ek24dzyBwTPDJwubXB1bTJ3d2szTk4HdOoQmg@mail.gmail.com>

Dear Antonello,

You can specify the colours manually with scale_colour_manual(). See
http://docs.ggplot2.org/0.9.3.1/scale_manual.html for some examples. The
last examples uses greys.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-02-20 13:54 GMT+01:00 Antonello Preti <antoviral at gmail.com>:

> Hi, I'm using ggplot2 to make a plot of the regression of a variable x (let
> say, levels of depression),
> on a variable y (let say, degree of social impairment),
> by taking into account a binary factor (having had or not a past admission
> to a psychiatric service),
> and age of partecipants.
>
> After some search in Internet I produced a code which is satisfying to me.
> This site was very helpful: http://editerna.free.fr/wp/?p=266
>
> However, I have a problem: no matter what I try, the figures always include
> bluette and pink flamingo colours.
> The figure is for an academic article, and I cannot afford the price of
> having the plot printed in colours.
>
> I've extracted the structure of the figure, and I understand that the
> problem is in the scale_name "hue",
> but I cannot figure out how to deal with it.
>
> Any way to override the ggplot2 system of dealing with factors?
>
> Here the codes and the sessionInfo
> The code is a bit baroque, but this is the best I was able to do.
>
>
> Thank you in advance,
> Antonello Preti
>
>
>
> ######## code for exemplification
>
> ### the dataset
>
> df <- structure(list(Social_impairment = c(2.83, 3.08, 2.75, 2.08,
> 2.92, 1.75, 3.5, 2.33, 2.91, 2.5, 3.25, 2.64, 3.25, 2.83, 2.08,
> 2.25, 2.17, 2.42, 2.58, 2.42, 2.58, 2.42, 3, 3, 2.83, 2.67, 3.58,
> 1.58, 2.83, 2.83, 2.67, 3.17, 2.42, 1.92, 2.92, 2.5, 2.42, 2.42,
> 2.58, 2.42, 3.33, 3, 3.17, 2.17, 2.58, 2.67, 2.58, 3.75, 2.5,
> 2.08, 2.25, 3.25, 3.17, 2.91, 2.08, 2.25, 3.08, 2.91, 3.08, 2.92,
> 1.83, 2.5, 2.5, 2.83, 2.67, 3.33, 2.83, 3.33, 2.92, 3), Levels_Depression =
> c(1.3,
> 1.71, 3.08, 0.48, 0.51, 0.71, 1.37, 0.2, 1.21, 1.07, 2.8, 1.24,
> 0.46, 0.97, 0.81, 1.13, 1.58, 3.12, 1.8, 1.54, 1.02, 0.32, 2.63,
> 1.39, 1.34, 2.37, 2.6, 1.11, 1.59, 2.17, 1.99, 0.59, 0.76, 0.23,
> 2.22, 1.98, 0.41, 0.32, 0.37, 1.11, 2.29, 0.97, 1.61, 1.27, 1.22,
> 2.38, 1.28, 1.21, 0.93, 2.3, 0.8, 2.1, 2.86, 2.47, 2.34, 2.67,
> 0.31, 0.88, 1.84, 0.23, 2.41, 0.56, 2.03, 1.11, 0.12, 2.39, 0.34,
> 2.08, 1.01, 1.51), Age = c(66, 59, 49, 70, 42, 55, 28, 41, 69,
> 65, 40, 21, 18, 77, 28, 40, 47, 37, 47, 39, 32, 33, 42, 28, 59,
> 49, 29, 41, 22, 29, 53, 39, 55, 61, 30, 49, 43, 46, 18, 36, 34,
> 17, 42, 37, 37, 54, 48, 23, 71, 42, 52, 83, 19, 47, 23, 80, 43,
> 38, 47, 80, 36, 73, 74, 51, 76, 14, 65, 39, 17, 73), Past_Admissions = c(1,
> 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,
> 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,
> 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,
> 1, 0, 1, 0, 0, 1)), .Names = c("Social_impairment", "Levels_Depression",
> "Age", "Past_Admissions"), row.names = c(NA, 70L), class = "data.frame")
>
> dim(df)
> head(df)
> str(df)
> summary(df)
>
>
> ### call the library
>
> library(ggplot2)
>
>
> #### the plot
>
>
> #### Levels_Depression on Social_impairment by Past_Admissions (yes/no)
> #### linear model
> #### radius of the bubbles proportional to age
>
>
> #### background elimination
>
> p1 <- ggplot(data = df, aes(x =Levels_Depression, y = Social_impairment,
> group = as.factor(Past_Admissions), col = as.factor(Past_Admissions))) +
>   geom_point(aes(size = Age)) + geom_smooth(method = "lm") + xlab("Levels
> of depression") + ylab("Social impairment") +
>   scale_colour_discrete("History of \npast admissions\nto a psychiatric
> service", labels = c("No", "Yes"))
>
> p1 + theme(panel.grid.major = element_blank(), panel.grid.minor =
> element_blank(),
>     panel.background = element_blank(), axis.line = element_line(colour =
> "black"))
>
>
> ### change of then axes' ticks
>
> p1 + theme(panel.grid.major = element_blank(), panel.grid.minor =
> element_blank(),
>     panel.background = element_blank(), axis.line = element_line(colour =
> "black"),
>     axis.text = element_text(color = "black", size = 12, face = "italic"))
>
>
> ### after saving, dev.off()
> ###
>
>
> #### Age on Social_impairment by Past_Admissions (yes/no)
> #### linear model
> #### radius of the bubbles proportional to Levels_Depression
>
>
>
> #### background elimination
>
> p2 <- ggplot(data = df, aes(x =Age , y = Social_impairment, group =
> as.factor(Past_Admissions), col = as.factor(Past_Admissions))) +
>   geom_point(aes(size = Levels_Depression)) + geom_smooth(method = "lm")
> +xlab("Age of participants") + ylab("Social impairment") +
>   scale_colour_discrete("History of \npast admissions\nto a psychiatric
> service", labels = c("No", "Yes"))
>
> p2 + theme(panel.grid.major = element_blank(), panel.grid.minor =
> element_blank(),
>     panel.background = element_blank(), axis.line = element_line(colour =
> "black"))
>
>
> ### change of then axes' ticks
>
> p2 + theme(panel.grid.major = element_blank(), panel.grid.minor =
> element_blank(),
>     panel.background = element_blank(), axis.line = element_line(colour =
> "black"),
>     axis.text = element_text(color = "black", size = 12, face = "italic"))
>
>
> ### after saving, dev.off()
> ###
>
>
> ########################
> #### paired plots
> ########################
>
> library(gridExtra)
>
> grid.arrange(p1, p2, ncol = 2)
>
>
>
> ########################
> ### sessionInfo()
> ########################
>
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252
> [3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C
> [5] LC_TIME=Italian_Italy.1252
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets  methods
> [8] base
>
> other attached packages:
> [1] gridExtra_0.9.1 ggplot2_0.9.3.1
>
> loaded via a namespace (and not attached):
>  [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.4
> gtable_0.1.2
>  [5] labeling_0.2       MASS_7.3-33        munsell_0.4.2
> plyr_1.8
>  [9] proto_0.3-10       RColorBrewer_1.0-5 reshape2_1.2.2
> scales_0.2.3
> [13] stringr_0.6.2
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From aron.lindberg at case.edu  Fri Feb 20 14:25:30 2015
From: aron.lindberg at case.edu (Aron Lindberg)
Date: Fri, 20 Feb 2015 05:25:30 -0800
Subject: [R] Subsetting a list of lists using lapply
In-Reply-To: <loom.20150220T044432-198@post.gmane.org>
References: <loom.20150220T044432-198@post.gmane.org>
Message-ID: <1424438729793.fe8ebf0b@Nodemailer>

Thanks Chuck and Rolf.




While Rolf?s code also works on the dput that I actually gave you (a smaller subset of the full dataset), it failed to work on the larger dataset, because there are further exceptions:





input[[i]]$content[[1]] is sometimes a list, sometimes a character vector, and sometimes input[[i]]$content simply returns list().




Chuck?s solution however bypasses this and works on the full dataset (which was 8mb, which is why I didn?t upload it as a gist).




Best,

Aron




--?

Aron Lindberg




Doctoral Candidate,?Information Systems

Weatherhead School of Management?

Case Western Reserve University

aronlindberg.github.io

On Fri, Feb 20, 2015 at 12:44 AM, Charles Berry <ccberry at ucsd.edu> wrote:

> Aron Lindberg <aron.lindberg <at> case.edu> writes:
>> 
>> Hi Everyone,
>> 
>> I'm working on a thorny subsetting problem involving list of lists. I've put a 
> dput of the data here:
>> 
>> 	https://gist.githubusercontent.com/aronlindberg/b916dee897d051ac5be5/
> raw/a78cbf873a7e865c3173f943ff6309ea688c653b/dput
>> 
> IIUC, you want the value of every list element that is named "sha" and 
> that name will only apply to atomic objects.
> If so, this should do it. 
>> input <- dget("/tmp/dpt")
>> shas <- unlist( input, use.names=FALSE )[ grepl( "sha", names(unlist(input)))]
>> input[[67]]$content[[1]]$sha
> [1] "58cf43ecdc1beb7e1043e9de612ecc817b090f15"
>> which(input[[67]]$content[[1]]$sha == shas )
> [1] 194
> HTH,
> Chuck
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From friendly at yorku.ca  Fri Feb 20 14:27:05 2015
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 20 Feb 2015 08:27:05 -0500
Subject: [R] How to analyse nonlinear response to categorical and
 quantitative explanatory variables?
In-Reply-To: <FE15711A62D32F44BED5A7CB70F00B1648E522DB@EX8.adf.bham.ac.uk>
References: <FE15711A62D32F44BED5A7CB70F00B1648E522DB@EX8.adf.bham.ac.uk>
Message-ID: <54E73629.7020108@yorku.ca>

You want to use a generalized linear model of some sort

glm(count ~ flow + gravity + group, data=mydata, family=poisson)

would be a start, however, the effects of flow rate are nonlinear, so 
you might use a natural spline term like ns(flow,5) to allow 
nonlinearity, and there also seem to be interactions in your plot.

library(splines)
glm(count ~ ns(flow,5) * gravity + group, data=mydata, family=poisson)



That might get you started while you look for a statistician to consult 
with.

-Michael



On 2/19/2015 9:47 AM, Jan-Ulrich Kreft wrote:
> Dear list
>
> I have data from a collaborator who has used DesignExpert to design the experiment and analyse the data but no longer has access to this software and does not know exactly what the software did and why.
>
> So I?m now trying to analyse the data in R but can't quite decide what to do.
>
> Cell count is the response variable (number of cells attached to a surface per unit area and time interval, so could be Poisson distributed).
>
> This cell count depends on whether the surface was oriented upwards or downwards (categorical - with or against gravity). Some more categorical variables were also studied such as surface material (glass or polycarbonate, symbols g and p in the figure) and position in flow cell (inlet or outlet), but they seem to have no significant effect.
>
> Cell count also depends on a quantitative variable in a nonlinear manner: the flow rate with which the cell suspension was pumped along the surface.
>
> I was wondering which kind of statistical model would be appropriate. I was first thinking ANCOVA but this seems to be a linear model and treating the quantitative explanatory variable as covariate when this is actually of interest. What else could I use?
>
> Attached a figure showing the means of 4 replicates.
>
> Many thanks.
>
> Best wishes,
> Jan.
>
> ---
> Dr Jan-Ulrich Kreft
> +44 (0)121 41-48851
> School of Biosciences
> University of Birmingham, Birmingham, B15 2TT, UK
> http://www.tinyurl.com/kreftlab
>
>
>


From HDoran at air.org  Fri Feb 20 15:03:26 2015
From: HDoran at air.org (Doran, Harold)
Date: Fri, 20 Feb 2015 14:03:26 +0000
Subject: [R] multiple parameter optimization with optim()
In-Reply-To: <54E49CA1.1050709@uottawa.ca>
References: <mailman.1.1424257202.2915.r-help@r-project.org>
	<54E49CA1.1050709@uottawa.ca>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686CF392B2B@DC1VEX10MB001.air.org>

John et al

Thank you for your advice below. It was sloppy of me not to verify my reproducible code below.  I have tried a few of your suggestions and wrapped the working code into the function below called pl2. The function properly lands on the right model parameters when I use the optim or nlminb (for nlminb I had to increase max iterations). 

The function is enormously slow. At first, I created the object rr1 with two calls to sapply(). This works, but creates an extremely large matrix at each iteration. 

library(statmod)
dat <- replicate(20, sample(c(0,1), 2000, replace = T))
a <- b <- rep(1, 20)
Q <- 10
qq <- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma=1)
nds <- qq$nodes
wts <- qq$weights

rr1 <- sapply(1:nrow(dat), function(j)
                                                sapply(1:Q, function(i)
                                                                exp(sum(dbinom(dat[j,], 1, 1/ (1 + exp(- 1.7 * a * (qq$nodes[i] - b))), log = TRUE))) * qq$weights[i]))

So, I thought to reduce some memory, I would do it this way which is equivalent, doesn't create such a large matrix, but instead uses an explicit loop. Both approaches are still equally as slow. 

rr1 <- numeric(nrow(dat))
for(j in 1:length(rr1)){
		rr1[j] <- sum(sapply(1:Q, 
		function(i) exp(sum(dbinom(dat[j,], 1, 1/ (1 + exp(- 1.7 * a * (nds[i] - b))), log = TRUE))) * wts[i]))
	}

As you noted, my likelihood is not complex; in fact I have another program that uses newton-raphson with the analytic first and second derivatives because they are so easy to find. In that program, the model converges very (very) quickly. My purpose in using numeric differentiation is experiential in some respects and hoping to apply this to problems for which the analytic derivatives might not be so easy to come by.

I think the basic idea here to improve speed is to make a call to the gradient, which I understand to be the vector of first derivatives of my likelihood function, is that right? If that is right, in a multi-parameter problem, I'm not sure how to think about the gradient function. Since I am maximizing w.r.t. a and b (these are the parameters of the model), I would have a vector of first partials for a and another for b. So I conceptually do not understand what the gradient would be in this instance, perhaps some clarification would be helpful.

Below is the working function, which as I noted is enormously slow. Any advice on speed improvements here would be helpful. Thank you

pl2 <- function(dat, Q, startVal = NULL, ...){
                if(!is.null(startVal) && length(startVal) != ncol(dat) ){
                                stop("Length of argument startVal not equal to the number of parameters estimated")
                }             
                if(!is.null(startVal)){
                                startVal <- startVal
                                } else {
                                p <- colMeans(dat)
                                startValA <- rep(1, ncol(dat))
                                startValB <- as.vector(log((1 - p)/p))
                                startVal <- c(startValA,startValB)
                }
                rr1 <- numeric(nrow(dat))
                qq <- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma=1)
	nds <- qq$nodes
	wts <- qq$weights
                dat <- as.matrix(dat)
                fn <- function(params){
                    a <- params[1:20]            
                    b <- params[21:40]         
		for(j in 1:length(rr1)){
		rr1[j] <- sum(sapply(1:Q, 
		function(i) exp(sum(dbinom(dat[j,], 1, 1/ (1 + exp(- 1.7 * a * (nds[i] - b))), log = TRUE))) * wts[i]))
				}
				-sum(log(rr1))
                }             
                #opt <- optim(startVal, fn, method = "BFGS", hessian = TRUE)
                opt <-  nlminb(startVal, fn)
                #opt <- Rcgmin(startVal, fn)
                opt
                #list("coefficients" = opt$par, "LogLik" = -opt$value, "Std.Error" = sqrt(diag(solve(opt$hessian))))
}

dat <- replicate(20, sample(c(0,1), 2000, replace = T))
r2 <- pl2(datat, Q =10)

-----Original Message-----
From: Prof J C Nash (U30A) [mailto:nashjc at uottawa.ca] 
Sent: Wednesday, February 18, 2015 9:07 AM
To: r-help at r-project.org; Doran, Harold
Subject: Re: [R] multiple parameter optimization with optim()

Some observations -- no solution here though:

1) the code is not executable. I tried. Maybe that makes it reproducible!
    Typos such as "stat mod", undefined Q etc.

2) My experience is that any setup with a ?apply approach that doesn't then check to see that the structure of the data is correct has a high probability of failure due to mismatch with the optimizer requirements.
It's worth being VERY pedestrian in setting up optimization functions and checking obsessively that you get what you expect and that there are no regions you are likely to wander into with divide by 0, log(negative), etc.

3) optim() is a BAD choice here. I wrote the source for three of the codes, and the one most appropriate for many parameters (CG) I have been deprecating for about 30 years. Use Rcgmin or something else instead.

4) If possible, analytic gradients are needed for CG like codes. You probably need to dig out some source code for dbinom() to do this, but your function is not particularly complicated, and doesn't have "if"
statements etc. However, you could test a case using the numDeriv gradient that is an option for Rcgmin, but it will be painfully slow.
For a one-off computation, that may still be acceptable.

JN

On 15-02-18 06:00 AM, r-help-request at r-project.org wrote:
> Message: 37
> Date: Tue, 17 Feb 2015 23:03:24 +0000
> From: "Doran, Harold" <HDoran at air.org>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] multiple parameter optimization with optim()
> Message-ID: <D10931E1.23C0E%hdoran at air.org>
> Content-Type: text/plain; charset="UTF-8"
> 
> I am trying to generalize a working piece of code for a single parameter to a multiple parameter problem. Reproducible code is below. The parameters to be estimated are a, b, and c. The estimation problem is such that there is one set of a, b, c parameters for each column of the data. Hence, in this sample data with 20 columns, there are 20 a params, 20 b-params, and 20 c-params.
> 
> Because I am estimating so many parameters, I am not certain that I have indicated to the function properly the right number of params to estimate and also if I have generated starting values in a sufficient way.
> 
> Thanks for any help.
> Harold
> 
> dat <- replicate(20, sample(c(0,1), 2000, replace = T)) library(stat 
> mod) qq <- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma = 1) nds 
> <- qq$nodes wts <- qq$weights fn <- function(params){ a <- 
> params[1:ncol(dat)] b <- params[1:ncol(dat)] c <- params[1:ncol(dat)] 
> L <- sapply(1:ncol(dat), function(i) dbinom(dat[,i], 1, c + ((1 - 
> c)/(1 + exp(-1.7 * a * (nds[i] - b)))) * wts[i]))
> r1 <- prod(colSums(L * wts))
> -log(r1)
> }
> startVal <- rep(.5, ncol(dat))
> opt <- optim(startVal, fn)
> 
> 	[[alternative HTML version deleted]]


From aron.lindberg at case.edu  Fri Feb 20 15:05:40 2015
From: aron.lindberg at case.edu (Aron Lindberg)
Date: Fri, 20 Feb 2015 06:05:40 -0800 (PST)
Subject: [R] "Design patterns" for data munging?
Message-ID: <1424441139026.c37ad314@Nodemailer>

Hi All,


The most difficult challenge that I face in ?learning R? is to do data munging. I have reviewed Hadley?s advanced R programming guide, familiarized myself with data structures, subsetting, plyr, dplyr, tidy, the lapply() family of functions, basic string manipulation and grepping, SQL etc. I?ve also written a few dozens of functions that do basic data munging tasks. Further, I?ve already reviewed things like the Coursera course ?Computing for Data Analysis? - https://www.coursera.org/course/compdata and Data Camp's data.table course.


However, many of the tasks that are commonly solved by the tools mentioned above seem to be mainly applied to datasets with fairly well-structured variables that needs to be transformed and subsetted in various ways - these tasks are often not so difficult.?



Much of my work involves querying APIs, SQL databases or scraping websites, and then assembling lists of various things that can then be transformed into social networks or timestamped sequences of various events etc. Solutions to many tricky problems in this area still seem to imply creative leaps of imagination that I can understand after I see them, but I have trouble seeing how I could ever come up with them independently.


Therefore I ask - what do I need to learn to become better at solving tricky data munging problems?


I realize a common answer may be: solve many data munging problems. I understand that this is a clear factor, however, I?m trying to figure out if there is some more tangible guidance.?


* Is there something like ?design patterns? for data munging??
* Would doing a course in algorithms help? (I?ve reviewed parts of "Guide to Programming and Algorithms Using R" - http://www.springer.com/computer/swe/book/978-1-4471-5327-6 - many of the problems are mathematical and seem far-removed from the kinds of problems that I?m trying to solve)
* Is there something like SelectorGadget (http://selectorgadget.com/) for R objects?
* Could something like OpenRefine (http://openrefine.org/) make these tasks easier?


Best,
Aron

--?
Aron Lindberg


Doctoral Candidate,?Information Systems
Weatherhead School of Management?
Case Western Reserve University
aronlindberg.github.io
	[[alternative HTML version deleted]]


From aron.lindberg at case.edu  Fri Feb 20 15:13:50 2015
From: aron.lindberg at case.edu (Aron Lindberg)
Date: Fri, 20 Feb 2015 06:13:50 -0800
Subject: [R] Subsetting a list of lists using lapply
In-Reply-To: <1424438729793.fe8ebf0b@Nodemailer>
References: <1424438729793.fe8ebf0b@Nodemailer>
Message-ID: <1424441629292.1f9df286@Nodemailer>

Hmm?Chuck?s solution may actually be problematic because there are several entries which at the deepest level are called ?sha?, but that should not be included, such as:





input[[67]]$content[[1]]$commit$tree$sha




and




input[[67]]$content[[1]]$parents[[1]]$sha





it?s only the ?sha? that fit the following subsetting pattern that should be included:





input[[i]]$content[[1]]$sha[1]




It?s getting thornier!




To be fair to Rolf?s solution (which probably can be updated to solve the problem), I?ve posted the complete dput here:

https://gist.githubusercontent.com/aronlindberg/92700c04c88ff112e4f7/raw/0f3cd8468f4dc82267be3cec72d53a7a04f5c449/dput.R







--?

Aron Lindberg




Doctoral Candidate,?Information Systems

Weatherhead School of Management?

Case Western Reserve University

aronlindberg.github.io

On Fri, Feb 20, 2015 at 8:25 AM, Aron Lindberg <aron.lindberg at case.edu>
wrote:

> Thanks Chuck and Rolf.
> While Rolf?s code also works on the dput that I actually gave you (a smaller subset of the full dataset), it failed to work on the larger dataset, because there are further exceptions:
> input[[i]]$content[[1]] is sometimes a list, sometimes a character vector, and sometimes input[[i]]$content simply returns list().
> Chuck?s solution however bypasses this and works on the full dataset (which was 8mb, which is why I didn?t upload it as a gist).
> Best,
> Aron
> --?
> Aron Lindberg
> Doctoral Candidate,?Information Systems
> Weatherhead School of Management?
> Case Western Reserve University
> aronlindberg.github.io
> On Fri, Feb 20, 2015 at 12:44 AM, Charles Berry <ccberry at ucsd.edu> wrote:
>> Aron Lindberg <aron.lindberg <at> case.edu> writes:
>>> 
>>> Hi Everyone,
>>> 
>>> I'm working on a thorny subsetting problem involving list of lists. I've put a 
>> dput of the data here:
>>> 
>>> 	https://gist.githubusercontent.com/aronlindberg/b916dee897d051ac5be5/
>> raw/a78cbf873a7e865c3173f943ff6309ea688c653b/dput
>>> 
>> IIUC, you want the value of every list element that is named "sha" and 
>> that name will only apply to atomic objects.
>> If so, this should do it. 
>>> input <- dget("/tmp/dpt")
>>> shas <- unlist( input, use.names=FALSE )[ grepl( "sha", names(unlist(input)))]
>>> input[[67]]$content[[1]]$sha
>> [1] "58cf43ecdc1beb7e1043e9de612ecc817b090f15"
>>> which(input[[67]]$content[[1]]$sha == shas )
>> [1] 194
>> HTH,
>> Chuck
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Feb 20 15:27:22 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 20 Feb 2015 14:27:22 +0000
Subject: [R] irregular sequence of events
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C20E2E@SRVEXCHMBX.precheza.cz>

Dear all

I know I am missing something obvious but after few hours of trials I ask for some help.

I have some sequence of values (days)
x <- 1:30

and an indication of event start and end day
mimo<-c(5,10, 13,16, 21,27)

or

events <- structure(list(start = c(5, 13, 21), end = c(10, 16, 27)), .Names = c("start",
"end"), row.names = c(NA, -3L), class = "data.frame")

I need to get a factor indicating event

event <- c(rep(NA, 4), rep("A1", 6), rep(NA, 2), rep("A2", 4), rep(NA, 4), rep("A3", 7), rep(NA,3))
factor(event)

In such small example I can do it manually but I have a long vector of dates and would like to use start and end day of events either from mimo vector or from events data frame.

Is there any function which does it automagically? I know I have seen it before but I cannot find it now.

Best regards
Petr

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From sarah.goslee at gmail.com  Fri Feb 20 15:42:10 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 20 Feb 2015 09:42:10 -0500
Subject: [R] irregular sequence of events
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C20E2E@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C20E2E@SRVEXCHMBX.precheza.cz>
Message-ID: <CAM_vjunv+2W3y_U2aAevpdCR5hXu_voN8mBvkqSxEKKyXt6-VQ@mail.gmail.com>

Hi,

On Fri, Feb 20, 2015 at 9:27 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Dear all
>
> I know I am missing something obvious but after few hours of trials I ask for some help.
>
> I have some sequence of values (days)
> x <- 1:30
>
> and an indication of event start and end day
> mimo<-c(5,10, 13,16, 21,27)


> cut(x, mimo)

 [1] <NA>    <NA>    <NA>    <NA>    <NA>    (5,10]  (5,10]  (5,10]  (5,10]

[10] (5,10]  (10,13] (10,13] (10,13] (13,16] (13,16] (13,16] (16,21] (16,21]

[19] (16,21] (16,21] (16,21] (21,27] (21,27] (21,27] (21,27] (21,27] (21,27]

[28] <NA>    <NA>    <NA>

Levels: (5,10] (10,13] (13,16] (16,21] (21,27]


should get you started. You'll need to tweak the arguments to get
exactly what you want,


> or
>
> events <- structure(list(start = c(5, 13, 21), end = c(10, 16, 27)), .Names = c("start",
> "end"), row.names = c(NA, -3L), class = "data.frame")
>
> I need to get a factor indicating event
>
> event <- c(rep(NA, 4), rep("A1", 6), rep(NA, 2), rep("A2", 4), rep(NA, 4), rep("A3", 7), rep(NA,3))
> factor(event)
>
> In such small example I can do it manually but I have a long vector of dates and would like to use start and end day of events either from mimo vector or from events data frame.
>
> Is there any function which does it automagically? I know I have seen it before but I cannot find it now.
>
> Best regards
> Petr
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From thanoon.younis80 at gmail.com  Fri Feb 20 15:48:21 2015
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Fri, 20 Feb 2015 17:48:21 +0300
Subject: [R] problem in R
Message-ID: <CABLo8nHCvUBqdufYY-nB587XiCN_OE4_ysrnn7vKE3jTkMX1jg@mail.gmail.com>

Dear all members

I have the following matrix in R

> thd <- matrix(testJAGSdata$thd, ncol=6, byrow=TRUE)
> head(thd)
     [,1]   [,2]   [,3]   [,4]  [,5] [,6]
[1,] -200 -2.517 -1.245 -0.444 0.848  200
[2,] -200 -1.447 -0.420  0.119  1.245 200
[3,] -200 -1.671 -0.869 -0.194  0.679 200
[4,] -200 -1.642 -0.869 -0.293  0.332 200
[5,] -200 -1.671 -0.827  0.052  0.756 200
[6,] -200 -1.769 -1.098 -0.469  0.255 200
[7,] -200 -1.490 -0.670 -0.082  0.880 200
[8,] -200 -1.933 -0.880 -0.317  1.008 200
[9,] -200  -1.587 -0.624  0.000  1.008 200
[10,] -200 -1.983 -1.348 -0.348  1.045 200
[11,] -200 -1.983 -1.229 -0.247  0.869 200
[12,] -200 -2.262 -1.426  0.037  1.330 200
[13,] -200 -2.371 -1.295 -0.224  0.651 200
[14,] -200 -2.039 -1.112 -0.149  1.169 200
[15,] -200 -2.262 -1.198 -0.309  1.198 200
[16,] -200 -2.176 -1.537 -0.717  0.597 200
[17,] -200 -1.447 -0.786  0.119  1.008 200
[18,] -200 -2.039 -1.769 -0.661  0.642 200

and when i implemented this matrix i found this error


+ > head(thd)
+      [,1]   [,2]   [,3]   [,4]  [,5] [,6]
+ [1,] -200 -2.517 -1.245 -0.444 0.848  200
Error: unexpected numeric constant in:
"     [,1]   [,2]   [,3]   [,4]  [,5] [,6]
[1,] -200 -2.517 -1.245 -0.444 0.848"
> [2,] -200 -1.447 -0.420  0.119  1.245 200
Error: unexpected '[' in "["
> [3,] -200 -1.671 -0.869 -0.194  0.679 200
Error: unexpected '[' in "["
> [4,] -200 -1.642 -0.869 -0.293  0.332 200
Error: unexpected '[' in "["
> [5,] -200 -1.671 -0.827  0.052  0.756 200
Error: unexpected '[' in "["
> [6,] -200 -1.769 -1.098 -0.469  0.255 200
Error: unexpected '[' in "["
> [7,] -200 -1.490 -0.670 -0.082  0.880 200
Error: unexpected '[' in "["
> [8,] -200 -1.933 -0.880 -0.317  1.008 200
Error: unexpected '[' in "["
> [9,] -200  -1.587 -0.624  0.000  1.008 200
Error: unexpected '[' in "["
> [10,] -200 -1.983 -1.348 -0.348  1.045 200
Error: unexpected '[' in "["
> [11,] -200 -1.983 -1.229 -0.247  0.869 200
Error: unexpected '[' in "["
> [12,] -200 -2.262 -1.426  0.037  1.330 200
Error: unexpected '[' in "["
> [13,] -200 -2.371 -1.295 -0.224  0.651 200
Error: unexpected '[' in "["
> [14,] -200 -2.039 -1.112 -0.149  1.169 200
Error: unexpected '[' in "["
> [15,] -200 -2.262 -1.198 -0.309  1.198 200
Error: unexpected '[' in "["
> [16,] -200 -2.176 -1.537 -0.717  0.597 200
Error: unexpected '[' in "["
> [17,] -200 -1.447 -0.786  0.119  1.008 200
Error: unexpected '[' in "["
> [18,] -200 -2.039 -1.769 -0.661  0.642 200
Error: unexpected '[' in "["


Any help would be very appreciated

thanks in advance
-- 
Thanoon Y. Thanoon
PhD Candidate
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Feb 20 16:04:41 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 20 Feb 2015 10:04:41 -0500
Subject: [R] problem in R
In-Reply-To: <CABLo8nHCvUBqdufYY-nB587XiCN_OE4_ysrnn7vKE3jTkMX1jg@mail.gmail.com>
References: <CABLo8nHCvUBqdufYY-nB587XiCN_OE4_ysrnn7vKE3jTkMX1jg@mail.gmail.com>
Message-ID: <CAM_vjunUQVc6d1tcTrRAxH_xaJWspq9+VG5tRguSeUq=W3tyTQ@mail.gmail.com>

Hi,

On Fri, Feb 20, 2015 at 9:48 AM, thanoon younis
<thanoon.younis80 at gmail.com> wrote:
> Dear all members
>
> I have the following matrix in R
>
>> thd <- matrix(testJAGSdata$thd, ncol=6, byrow=TRUE)
>> head(thd)
>      [,1]   [,2]   [,3]   [,4]  [,5] [,6]
> [1,] -200 -2.517 -1.245 -0.444 0.848  200
> [2,] -200 -1.447 -0.420  0.119  1.245 200
> [3,] -200 -1.671 -0.869 -0.194  0.679 200
> [4,] -200 -1.642 -0.869 -0.293  0.332 200
> [5,] -200 -1.671 -0.827  0.052  0.756 200
> [6,] -200 -1.769 -1.098 -0.469  0.255 200
> [7,] -200 -1.490 -0.670 -0.082  0.880 200
> [8,] -200 -1.933 -0.880 -0.317  1.008 200
> [9,] -200  -1.587 -0.624  0.000  1.008 200
> [10,] -200 -1.983 -1.348 -0.348  1.045 200
> [11,] -200 -1.983 -1.229 -0.247  0.869 200
> [12,] -200 -2.262 -1.426  0.037  1.330 200
> [13,] -200 -2.371 -1.295 -0.224  0.651 200
> [14,] -200 -2.039 -1.112 -0.149  1.169 200
> [15,] -200 -2.262 -1.198 -0.309  1.198 200
> [16,] -200 -2.176 -1.537 -0.717  0.597 200
> [17,] -200 -1.447 -0.786  0.119  1.008 200
> [18,] -200 -2.039 -1.769 -0.661  0.642 200

This is not reproducible, so the below are guesses.

> and when i implemented this matrix i found this error

I have no idea what "implemented this matrix" might mean.

>
> + > head(the)

First problem: the + means R expects continuation of a previous line,
because the command is incomplete. So whatever you did BEFORE this
line is wrong.

> +      [,1]   [,2]   [,3]   [,4]  [,5] [,6]
> + [1,] -200 -2.517 -1.245 -0.444 0.848  200
> Error: unexpected numeric constant in:
> "     [,1]   [,2]   [,3]   [,4]  [,5] [,6]
> [1,] -200 -2.517 -1.245 -0.444 0.848"

These and subsequent errors are what you'd get if you pasted the above
R output back into the R console. Why would you do that?

So: check your previous commands.
If you can't find your mistake, respond to the list with a clear
reproducible example.

>> [2,] -200 -1.447 -0.420  0.119  1.245 200
> Error: unexpected '[' in "["
>> [3,] -200 -1.671 -0.869 -0.194  0.679 200
> Error: unexpected '[' in "["
>> [4,] -200 -1.642 -0.869 -0.293  0.332 200
> Error: unexpected '[' in "["
>> [5,] -200 -1.671 -0.827  0.052  0.756 200
> Error: unexpected '[' in "["
>> [6,] -200 -1.769 -1.098 -0.469  0.255 200
> Error: unexpected '[' in "["
>> [7,] -200 -1.490 -0.670 -0.082  0.880 200
> Error: unexpected '[' in "["
>> [8,] -200 -1.933 -0.880 -0.317  1.008 200
> Error: unexpected '[' in "["
>> [9,] -200  -1.587 -0.624  0.000  1.008 200
> Error: unexpected '[' in "["
>> [10,] -200 -1.983 -1.348 -0.348  1.045 200
> Error: unexpected '[' in "["
>> [11,] -200 -1.983 -1.229 -0.247  0.869 200
> Error: unexpected '[' in "["
>> [12,] -200 -2.262 -1.426  0.037  1.330 200
> Error: unexpected '[' in "["
>> [13,] -200 -2.371 -1.295 -0.224  0.651 200
> Error: unexpected '[' in "["
>> [14,] -200 -2.039 -1.112 -0.149  1.169 200
> Error: unexpected '[' in "["
>> [15,] -200 -2.262 -1.198 -0.309  1.198 200
> Error: unexpected '[' in "["
>> [16,] -200 -2.176 -1.537 -0.717  0.597 200
> Error: unexpected '[' in "["
>> [17,] -200 -1.447 -0.786  0.119  1.008 200
> Error: unexpected '[' in "["
>> [18,] -200 -2.039 -1.769 -0.661  0.642 200
> Error: unexpected '[' in "["
>
>
> Any help would be very appreciated
>
> thanks in advance
> --
> Thanoon Y. Thanoon
> PhD Candidate
> Department of Mathematical Sciences
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From gunter.berton at gene.com  Fri Feb 20 16:09:05 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 20 Feb 2015 07:09:05 -0800
Subject: [R] multiple parameter optimization with optim()
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686CF392B2B@DC1VEX10MB001.air.org>
References: <mailman.1.1424257202.2915.r-help@r-project.org>
	<54E49CA1.1050709@uottawa.ca>
	<B08B6AF0CF8CA44F81B9983EEBDCD686CF392B2B@DC1VEX10MB001.air.org>
Message-ID: <CACk-te32OOeuyk9Viqi-sKWFfnZJYoq9uGKg5aoXKSN6sw1nmA@mail.gmail.com>

This is not the proper venue for a discussion of the mathematics of
optimization, no matter that it is interesting. Please take it off
list.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Feb 20, 2015 at 6:03 AM, Doran, Harold <HDoran at air.org> wrote:
> John et al
>
> Thank you for your advice below. It was sloppy of me not to verify my reproducible code below.  I have tried a few of your suggestions and wrapped the working code into the function below called pl2. The function properly lands on the right model parameters when I use the optim or nlminb (for nlminb I had to increase max iterations).
>
> The function is enormously slow. At first, I created the object rr1 with two calls to sapply(). This works, but creates an extremely large matrix at each iteration.
>
> library(statmod)
> dat <- replicate(20, sample(c(0,1), 2000, replace = T))
> a <- b <- rep(1, 20)
> Q <- 10
> qq <- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma=1)
> nds <- qq$nodes
> wts <- qq$weights
>
> rr1 <- sapply(1:nrow(dat), function(j)
>                                                 sapply(1:Q, function(i)
>                                                                 exp(sum(dbinom(dat[j,], 1, 1/ (1 + exp(- 1.7 * a * (qq$nodes[i] - b))), log = TRUE))) * qq$weights[i]))
>
> So, I thought to reduce some memory, I would do it this way which is equivalent, doesn't create such a large matrix, but instead uses an explicit loop. Both approaches are still equally as slow.
>
> rr1 <- numeric(nrow(dat))
> for(j in 1:length(rr1)){
>                 rr1[j] <- sum(sapply(1:Q,
>                 function(i) exp(sum(dbinom(dat[j,], 1, 1/ (1 + exp(- 1.7 * a * (nds[i] - b))), log = TRUE))) * wts[i]))
>         }
>
> As you noted, my likelihood is not complex; in fact I have another program that uses newton-raphson with the analytic first and second derivatives because they are so easy to find. In that program, the model converges very (very) quickly. My purpose in using numeric differentiation is experiential in some respects and hoping to apply this to problems for which the analytic derivatives might not be so easy to come by.
>
> I think the basic idea here to improve speed is to make a call to the gradient, which I understand to be the vector of first derivatives of my likelihood function, is that right? If that is right, in a multi-parameter problem, I'm not sure how to think about the gradient function. Since I am maximizing w.r.t. a and b (these are the parameters of the model), I would have a vector of first partials for a and another for b. So I conceptually do not understand what the gradient would be in this instance, perhaps some clarification would be helpful.
>
> Below is the working function, which as I noted is enormously slow. Any advice on speed improvements here would be helpful. Thank you
>
> pl2 <- function(dat, Q, startVal = NULL, ...){
>                 if(!is.null(startVal) && length(startVal) != ncol(dat) ){
>                                 stop("Length of argument startVal not equal to the number of parameters estimated")
>                 }
>                 if(!is.null(startVal)){
>                                 startVal <- startVal
>                                 } else {
>                                 p <- colMeans(dat)
>                                 startValA <- rep(1, ncol(dat))
>                                 startValB <- as.vector(log((1 - p)/p))
>                                 startVal <- c(startValA,startValB)
>                 }
>                 rr1 <- numeric(nrow(dat))
>                 qq <- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma=1)
>         nds <- qq$nodes
>         wts <- qq$weights
>                 dat <- as.matrix(dat)
>                 fn <- function(params){
>                     a <- params[1:20]
>                     b <- params[21:40]
>                 for(j in 1:length(rr1)){
>                 rr1[j] <- sum(sapply(1:Q,
>                 function(i) exp(sum(dbinom(dat[j,], 1, 1/ (1 + exp(- 1.7 * a * (nds[i] - b))), log = TRUE))) * wts[i]))
>                                 }
>                                 -sum(log(rr1))
>                 }
>                 #opt <- optim(startVal, fn, method = "BFGS", hessian = TRUE)
>                 opt <-  nlminb(startVal, fn)
>                 #opt <- Rcgmin(startVal, fn)
>                 opt
>                 #list("coefficients" = opt$par, "LogLik" = -opt$value, "Std.Error" = sqrt(diag(solve(opt$hessian))))
> }
>
> dat <- replicate(20, sample(c(0,1), 2000, replace = T))
> r2 <- pl2(datat, Q =10)
>
> -----Original Message-----
> From: Prof J C Nash (U30A) [mailto:nashjc at uottawa.ca]
> Sent: Wednesday, February 18, 2015 9:07 AM
> To: r-help at r-project.org; Doran, Harold
> Subject: Re: [R] multiple parameter optimization with optim()
>
> Some observations -- no solution here though:
>
> 1) the code is not executable. I tried. Maybe that makes it reproducible!
>     Typos such as "stat mod", undefined Q etc.
>
> 2) My experience is that any setup with a ?apply approach that doesn't then check to see that the structure of the data is correct has a high probability of failure due to mismatch with the optimizer requirements.
> It's worth being VERY pedestrian in setting up optimization functions and checking obsessively that you get what you expect and that there are no regions you are likely to wander into with divide by 0, log(negative), etc.
>
> 3) optim() is a BAD choice here. I wrote the source for three of the codes, and the one most appropriate for many parameters (CG) I have been deprecating for about 30 years. Use Rcgmin or something else instead.
>
> 4) If possible, analytic gradients are needed for CG like codes. You probably need to dig out some source code for dbinom() to do this, but your function is not particularly complicated, and doesn't have "if"
> statements etc. However, you could test a case using the numDeriv gradient that is an option for Rcgmin, but it will be painfully slow.
> For a one-off computation, that may still be acceptable.
>
> JN
>
> On 15-02-18 06:00 AM, r-help-request at r-project.org wrote:
>> Message: 37
>> Date: Tue, 17 Feb 2015 23:03:24 +0000
>> From: "Doran, Harold" <HDoran at air.org>
>> To: "r-help at r-project.org" <r-help at r-project.org>
>> Subject: [R] multiple parameter optimization with optim()
>> Message-ID: <D10931E1.23C0E%hdoran at air.org>
>> Content-Type: text/plain; charset="UTF-8"
>>
>> I am trying to generalize a working piece of code for a single parameter to a multiple parameter problem. Reproducible code is below. The parameters to be estimated are a, b, and c. The estimation problem is such that there is one set of a, b, c parameters for each column of the data. Hence, in this sample data with 20 columns, there are 20 a params, 20 b-params, and 20 c-params.
>>
>> Because I am estimating so many parameters, I am not certain that I have indicated to the function properly the right number of params to estimate and also if I have generated starting values in a sufficient way.
>>
>> Thanks for any help.
>> Harold
>>
>> dat <- replicate(20, sample(c(0,1), 2000, replace = T)) library(stat
>> mod) qq <- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma = 1) nds
>> <- qq$nodes wts <- qq$weights fn <- function(params){ a <-
>> params[1:ncol(dat)] b <- params[1:ncol(dat)] c <- params[1:ncol(dat)]
>> L <- sapply(1:ncol(dat), function(i) dbinom(dat[,i], 1, c + ((1 -
>> c)/(1 + exp(-1.7 * a * (nds[i] - b)))) * wts[i]))
>> r1 <- prod(colSums(L * wts))
>> -log(r1)
>> }
>> startVal <- rep(.5, ncol(dat))
>> opt <- optim(startVal, fn)
>>
>>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Fri Feb 20 16:10:00 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 20 Feb 2015 07:10:00 -0800
Subject: [R] Subsetting a list of lists using lapply
In-Reply-To: <1424441629292.1f9df286@Nodemailer>
References: <1424438729793.fe8ebf0b@Nodemailer>
	<1424441629292.1f9df286@Nodemailer>
Message-ID: <CACk-te2v=fFuRfWk0Gq_bmcO15kpgvnOBo6MvqVGe=rYVTe7ng@mail.gmail.com>

How can you expect a solution if you cannot specify the problem?

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Feb 20, 2015 at 6:13 AM, Aron Lindberg <aron.lindberg at case.edu> wrote:
> Hmm?Chuck?s solution may actually be problematic because there are several entries which at the deepest level are called ?sha?, but that should not be included, such as:
>
>
>
>
>
> input[[67]]$content[[1]]$commit$tree$sha
>
>
>
>
> and
>
>
>
>
> input[[67]]$content[[1]]$parents[[1]]$sha
>
>
>
>
>
> it?s only the ?sha? that fit the following subsetting pattern that should be included:
>
>
>
>
>
> input[[i]]$content[[1]]$sha[1]
>
>
>
>
> It?s getting thornier!
>
>
>
>
> To be fair to Rolf?s solution (which probably can be updated to solve the problem), I?ve posted the complete dput here:
>
> https://gist.githubusercontent.com/aronlindberg/92700c04c88ff112e4f7/raw/0f3cd8468f4dc82267be3cec72d53a7a04f5c449/dput.R
>
>
>
>
>
>
>
> --
>
> Aron Lindberg
>
>
>
>
> Doctoral Candidate, Information Systems
>
> Weatherhead School of Management
>
> Case Western Reserve University
>
> aronlindberg.github.io
>
> On Fri, Feb 20, 2015 at 8:25 AM, Aron Lindberg <aron.lindberg at case.edu>
> wrote:
>
>> Thanks Chuck and Rolf.
>> While Rolf?s code also works on the dput that I actually gave you (a smaller subset of the full dataset), it failed to work on the larger dataset, because there are further exceptions:
>> input[[i]]$content[[1]] is sometimes a list, sometimes a character vector, and sometimes input[[i]]$content simply returns list().
>> Chuck?s solution however bypasses this and works on the full dataset (which was 8mb, which is why I didn?t upload it as a gist).
>> Best,
>> Aron
>> --
>> Aron Lindberg
>> Doctoral Candidate, Information Systems
>> Weatherhead School of Management
>> Case Western Reserve University
>> aronlindberg.github.io
>> On Fri, Feb 20, 2015 at 12:44 AM, Charles Berry <ccberry at ucsd.edu> wrote:
>>> Aron Lindberg <aron.lindberg <at> case.edu> writes:
>>>>
>>>> Hi Everyone,
>>>>
>>>> I'm working on a thorny subsetting problem involving list of lists. I've put a
>>> dput of the data here:
>>>>
>>>>     https://gist.githubusercontent.com/aronlindberg/b916dee897d051ac5be5/
>>> raw/a78cbf873a7e865c3173f943ff6309ea688c653b/dput
>>>>
>>> IIUC, you want the value of every list element that is named "sha" and
>>> that name will only apply to atomic objects.
>>> If so, this should do it.
>>>> input <- dget("/tmp/dpt")
>>>> shas <- unlist( input, use.names=FALSE )[ grepl( "sha", names(unlist(input)))]
>>>> input[[67]]$content[[1]]$sha
>>> [1] "58cf43ecdc1beb7e1043e9de612ecc817b090f15"
>>>> which(input[[67]]$content[[1]]$sha == shas )
>>> [1] 194
>>> HTH,
>>> Chuck
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Fri Feb 20 16:34:59 2015
From: jholtman at gmail.com (jim holtman)
Date: Fri, 20 Feb 2015 10:34:59 -0500
Subject: [R] irregular sequence of events
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C20E2E@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C20E2E@SRVEXCHMBX.precheza.cz>
Message-ID: <CAAxdm-675ykGwiSR6fEiFvAGR=f6b_ttsc==acXEDhV86zv_DQ@mail.gmail.com>

Here is a solution using the sqldf package:


> require(sqldf)
> timeline <- data.frame(time = 1:30)
> events <- structure(list(start = c(5, 13, 21), end = c(10, 16, 27)), .Names = c("start",
+  "end"), row.names = c(NA, -3L), class = "data.frame")
> # add event number
> events$num <- paste0("A", seq(nrow(events)))
> events
  start end num
1     5  10  A1
2    13  16  A2
3    21  27  A3
>
> sqldf("
+     select t.*, e.num
+         from timeline t
+         left join (
+             select t.*, e.num
+                 from timeline t, events e
+                 where t.time between e.start and e.end) as e
+             on t.time = e.time
+ ")
   time  num
1     1 <NA>
2     2 <NA>
3     3 <NA>
4     4 <NA>
5     5   A1
6     6   A1
7     7   A1
8     8   A1
9     9   A1
10   10   A1
11   11 <NA>
12   12 <NA>
13   13   A2
14   14   A2
15   15   A2
16   16   A2
17   17 <NA>
18   18 <NA>
19   19 <NA>
20   20 <NA>
21   21   A3
22   22   A3
23   23   A3
24   24   A3
25   25   A3
26   26   A3
27   27   A3
28   28 <NA>
29   29 <NA>
30   30 <NA>
>
>
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Feb 20, 2015 at 9:27 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Dear all
>
> I know I am missing something obvious but after few hours of trials I ask for some help.
>
> I have some sequence of values (days)
> x <- 1:30
>
> and an indication of event start and end day
> mimo<-c(5,10, 13,16, 21,27)
>
> or
>
> events <- structure(list(start = c(5, 13, 21), end = c(10, 16, 27)), .Names = c("start",
> "end"), row.names = c(NA, -3L), class = "data.frame")
>
> I need to get a factor indicating event
>
> event <- c(rep(NA, 4), rep("A1", 6), rep(NA, 2), rep("A2", 4), rep(NA, 4), rep("A3", 7), rep(NA,3))
> factor(event)
>
> In such small example I can do it manually but I have a long vector of dates and would like to use start and end day of events either from mimo vector or from events data frame.
>
> Is there any function which does it automagically? I know I have seen it before but I cannot find it now.
>
> Best regards
> Petr
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Fri Feb 20 16:38:24 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 20 Feb 2015 10:38:24 -0500
Subject: [R] problem in R
In-Reply-To: <CABLo8nEOTtACGeWSDEKvynC9+Tb2qs1hywqpp+4ManEs7BqKGQ@mail.gmail.com>
References: <CABLo8nHCvUBqdufYY-nB587XiCN_OE4_ysrnn7vKE3jTkMX1jg@mail.gmail.com>
	<CAM_vjunUQVc6d1tcTrRAxH_xaJWspq9+VG5tRguSeUq=W3tyTQ@mail.gmail.com>
	<CABLo8nEOTtACGeWSDEKvynC9+Tb2qs1hywqpp+4ManEs7BqKGQ@mail.gmail.com>
Message-ID: <CAM_vju=ZUH9cmTbZm4gKbdize=KmU0b0Adewwbi+1XA10XF3=g@mail.gmail.com>

First, please reply to the list, not just me.

On Fri, Feb 20, 2015 at 10:22 AM, thanoon younis
<thanoon.younis80 at gmail.com> wrote:
> thank you very much for your help
>
> actually, my data set like this
>
> #Data Set
> testJAGSdata =  list(N1=200, N2=200, P=18,
>
>    R=structure(
>               .Data=c(8.0, 1.0,1.0, 8.0),
>               .Dim=c(2,2)),
>
> thd <- matrix(testJAGSdata$thd, ncol=6, byrow=TRUE)
>> head(thd)
>      [,1]   [,2]   [,3]   [,4]  [,5] [,6]
> [1,] -200 -2.517 -1.245 -0.444 0.848  200
> [2,] -200 -1.447 -0.420  0.119  1.245 200
> [3,] -200 -1.671 -0.869 -0.194  0.679 200
> [4,] -200 -1.642 -0.869 -0.293  0.332 200
> [5,] -200 -1.671 -0.827  0.052  0.756 200
> [6,] -200 -1.769 -1.098 -0.469  0.255 200
> [7,] -200 -1.490 -0.670 -0.082  0.880 200
> [8,] -200 -1.933 -0.880 -0.317  1.008 200
> [9,] -200  -1.587 -0.624  0.000  1.008 200
> [10,] -200 -1.983 -1.348 -0.348  1.045 200
> [11,] -200 -1.983 -1.229 -0.247  0.869 200
> [12,] -200 -2.262 -1.426  0.037  1.330 200
> [13,] -200 -2.371 -1.295 -0.224  0.651 200
> [14,] -200 -2.039 -1.112 -0.149  1.169 200
> [15,] -200 -2.262 -1.198 -0.309  1.198 200
> [16,] -200 -2.176 -1.537 -0.717  0.597 200
> [17,] -200 -1.447 -0.786  0.119  1.008 200
> [18,] -200 -2.039 -1.769 -0.661  0.642 200
>
>
>> #Data Set
>> testJAGSdata =  list(N1=200, N2=200, P=18,
> +
> +    R=structure(
> +               .Data=c(8.0, 1.0,1.0, 8.0),
> +               .Dim=c(2,2)),
> +
> + thd <- matrix(testJAGSdata$thd, ncol=6, byrow=TRUE)
> + > head(the)

Did you do what I suggested and look at your commands?

R is expecting the rest of whatever your first command is supposed to
do, and it isn't complete. That's what the + prompt is trying to tell
you.

The first command ends with a , and doesn't have enough parentheses -
something is missing there.
After that, you continue trying to paste in R output to the console.

It looks to  me like you are working by copying and pasting from notes
that you don't understand. Maybe going back and rereading an
introduction to R would help you.


> +      [,1]   [,2]   [,3]   [,4]  [,5] [,6]
> + [1,] -200 -2.517 -1.245 -0.444 0.848  200
> Error: unexpected numeric constant in:
> "     [,1]   [,2]   [,3]   [,4]  [,5] [,6]
> [1,] -200 -2.517 -1.245 -0.444 0.848"
>> [2,] -200 -1.447 -0.420  0.119  1.245 200
> Error: unexpected '[' in "["
>> [3,] -200 -1.671 -0.869 -0.194  0.679 200
> Error: unexpected '[' in "["
>> [4,] -200 -1.642 -0.869 -0.293  0.332 200
> Error: unexpected '[' in "["
>> [5,] -200 -1.671 -0.827  0.052  0.756 200
> Error: unexpected '[' in "["
>> [6,] -200 -1.769 -1.098 -0.469  0.255 200
> Error: unexpected '[' in "["
>> [7,] -200 -1.490 -0.670 -0.082  0.880 200
> Error: unexpected '[' in "["
>> [8,] -200 -1.933 -0.880 -0.317  1.008 200
> Error: unexpected '[' in "["
>> [9,] -200  -1.587 -0.624  0.000  1.008 200
> Error: unexpected '[' in "["
>> [10,] -200 -1.983 -1.348 -0.348  1.045 200
> Error: unexpected '[' in "["
>> [11,] -200 -1.983 -1.229 -0.247  0.869 200
> Error: unexpected '[' in "["
>> [12,] -200 -2.262 -1.426  0.037  1.330 200
> Error: unexpected '[' in "["
>> [13,] -200 -2.371 -1.295 -0.224  0.651 200
> Error: unexpected '[' in "["
>> [14,] -200 -2.039 -1.112 -0.149  1.169 200
> Error: unexpected '[' in "["
>> [15,] -200 -2.262 -1.198 -0.309  1.198 200
> Error: unexpected '[' in "["
>> [16,] -200 -2.176 -1.537 -0.717  0.597 200
> Error: unexpected '[' in "["
>> [17,] -200 -1.447 -0.786  0.119  1.008 200
> Error: unexpected '[' in "["
>> [18,] -200 -2.039 -1.769 -0.661  0.642 200
> Error: unexpected '[' in "["
>
>
> Many thanks in advance
>
> On 20 February 2015 at 18:04, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> Hi,
>>
>> On Fri, Feb 20, 2015 at 9:48 AM, thanoon younis
>> <thanoon.younis80 at gmail.com> wrote:
>> > Dear all members
>> >
>> > I have the following matrix in R
>> >
>> >> thd <- matrix(testJAGSdata$thd, ncol=6, byrow=TRUE)
>> >> head(thd)
>> >      [,1]   [,2]   [,3]   [,4]  [,5] [,6]
>> > [1,] -200 -2.517 -1.245 -0.444 0.848  200
>> > [2,] -200 -1.447 -0.420  0.119  1.245 200
>> > [3,] -200 -1.671 -0.869 -0.194  0.679 200
>> > [4,] -200 -1.642 -0.869 -0.293  0.332 200
>> > [5,] -200 -1.671 -0.827  0.052  0.756 200
>> > [6,] -200 -1.769 -1.098 -0.469  0.255 200
>> > [7,] -200 -1.490 -0.670 -0.082  0.880 200
>> > [8,] -200 -1.933 -0.880 -0.317  1.008 200
>> > [9,] -200  -1.587 -0.624  0.000  1.008 200
>> > [10,] -200 -1.983 -1.348 -0.348  1.045 200
>> > [11,] -200 -1.983 -1.229 -0.247  0.869 200
>> > [12,] -200 -2.262 -1.426  0.037  1.330 200
>> > [13,] -200 -2.371 -1.295 -0.224  0.651 200
>> > [14,] -200 -2.039 -1.112 -0.149  1.169 200
>> > [15,] -200 -2.262 -1.198 -0.309  1.198 200
>> > [16,] -200 -2.176 -1.537 -0.717  0.597 200
>> > [17,] -200 -1.447 -0.786  0.119  1.008 200
>> > [18,] -200 -2.039 -1.769 -0.661  0.642 200
>>
>> This is not reproducible, so the below are guesses.
>>
>> > and when i implemented this matrix i found this error
>>
>> I have no idea what "implemented this matrix" might mean.
>>
>> >
>> > + > head(the)
>>
>> First problem: the + means R expects continuation of a previous line,
>> because the command is incomplete. So whatever you did BEFORE this
>> line is wrong.
>>
>> > +      [,1]   [,2]   [,3]   [,4]  [,5] [,6]
>> > + [1,] -200 -2.517 -1.245 -0.444 0.848  200
>> > Error: unexpected numeric constant in:
>> > "     [,1]   [,2]   [,3]   [,4]  [,5] [,6]
>> > [1,] -200 -2.517 -1.245 -0.444 0.848"
>>
>> These and subsequent errors are what you'd get if you pasted the above
>> R output back into the R console. Why would you do that?
>>
>> So: check your previous commands.
>> If you can't find your mistake, respond to the list with a clear
>> reproducible example.
>>
>> >> [2,] -200 -1.447 -0.420  0.119  1.245 200
>> > Error: unexpected '[' in "["
>> >> [3,] -200 -1.671 -0.869 -0.194  0.679 200
>> > Error: unexpected '[' in "["
>> >> [4,] -200 -1.642 -0.869 -0.293  0.332 200
>> > Error: unexpected '[' in "["
>> >> [5,] -200 -1.671 -0.827  0.052  0.756 200
>> > Error: unexpected '[' in "["
>> >> [6,] -200 -1.769 -1.098 -0.469  0.255 200
>> > Error: unexpected '[' in "["
>> >> [7,] -200 -1.490 -0.670 -0.082  0.880 200
>> > Error: unexpected '[' in "["
>> >> [8,] -200 -1.933 -0.880 -0.317  1.008 200
>> > Error: unexpected '[' in "["
>> >> [9,] -200  -1.587 -0.624  0.000  1.008 200
>> > Error: unexpected '[' in "["
>> >> [10,] -200 -1.983 -1.348 -0.348  1.045 200
>> > Error: unexpected '[' in "["
>> >> [11,] -200 -1.983 -1.229 -0.247  0.869 200
>> > Error: unexpected '[' in "["
>> >> [12,] -200 -2.262 -1.426  0.037  1.330 200
>> > Error: unexpected '[' in "["
>> >> [13,] -200 -2.371 -1.295 -0.224  0.651 200
>> > Error: unexpected '[' in "["
>> >> [14,] -200 -2.039 -1.112 -0.149  1.169 200
>> > Error: unexpected '[' in "["
>> >> [15,] -200 -2.262 -1.198 -0.309  1.198 200
>> > Error: unexpected '[' in "["
>> >> [16,] -200 -2.176 -1.537 -0.717  0.597 200
>> > Error: unexpected '[' in "["
>> >> [17,] -200 -1.447 -0.786  0.119  1.008 200
>> > Error: unexpected '[' in "["
>> >> [18,] -200 -2.039 -1.769 -0.661  0.642 200
>> > Error: unexpected '[' in "["
>> >
>> >
>> > Any help would be very appreciated
>> >
-- 
Sarah Goslee
http://www.functionaldiversity.org


From ashenkin at ufl.edu  Fri Feb 20 16:44:41 2015
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Fri, 20 Feb 2015 15:44:41 +0000
Subject: [R] return named list from foreach
Message-ID: <54E75669.4040102@ufl.edu>

Hello all,

I've been trying to figure out how to return a named list from foreach.  
Given that the order of the returned list is guaranteed to be in the 
order in which the object is passed to foreach, list members can be 
named afterwards.  However, I'm wondering if there's a better way to do 
it, perhaps with some sort of combine function?

    library(doParallel)
    library(foreach)

    cl <- makeCluster(4)
    registerDoParallel(cl)

    df = data.frame(nm = letters[11:20], a = 1:10, b=11:20)

    out = foreach(i=1:nrow(df)) %dopar% {
         a = list(j = sqrt(df[i,]$a), k = sqrt(df[i,]$b))
         a
    }

How do I name the elements of "out" using the corresponding values df$nm?

thanks,
allie

	[[alternative HTML version deleted]]


From simon.tarr at adtrak.co.uk  Fri Feb 20 16:45:04 2015
From: simon.tarr at adtrak.co.uk (Simon Tarr)
Date: Fri, 20 Feb 2015 15:45:04 +0000
Subject: [R] Raster Help
In-Reply-To: <CAHuTOvp5Df_RF3YSkEjCS__=rqt-34MPAwTUk4JJMciGwR8QSg@mail.gmail.com>
References: <CAH+=eXAB0vR94SG3=QoYQQYEm6Q2tS9yJeQ1nUbyS12gj=+iPg@mail.gmail.com>
	<CAHuTOvp5Df_RF3YSkEjCS__=rqt-34MPAwTUk4JJMciGwR8QSg@mail.gmail.com>
Message-ID: <CAH+=eXDcX9kYUXsPcCcfHZGxYgHf_p2UMViTvped-FV8URbaeg@mail.gmail.com>

Hi Sven,

Many thanks for the reply and my apologies for not posting any code. So
far, I have been able to write this (but it's very basic and just getting
me to the 'complicated' stage).

setwd("C:\\Users\\simon.tarr\\Documents\\GIS\\Test Data")
require(raster)
require(rgdal)
revenue<-read.table("revenue.csv",header=T,row.names=1,sep=",")
postcodes<-raster("C:\\Users\\simon.tarr\\Documents\\GIS\\Test
Data\\rasters\\postcodes\\postcodes.img")
trim(postcodes)
plot(postcodes)

I have attached a .csv file that contains my revenue data (this is actually
just made up data- I wanted to make sure I could get the mapping to work
before I start handling large quantities of real data).

As I mentioned, the raster contains the same list of postcode names that
appear in the CSV. So I need to somehow 'attach' the revenue figures to
each postcode in the raster and then plot this.

I hope this makes sense and apologies for the loose language...it's the
only way I can think of to describe it.

I'm trying hard to learn R and its syntax but sometimes I get stuck. I
often know what needs to be done but struggle to write the necessary code
to make it happen.

All the best,

Simon

On 19 February 2015 at 20:37, Sven E. Templer <sven.templer at gmail.com>
wrote:

> Without (example) code it is hard to follow... use ?dput to present
> some data (subset).
> But if it is data.frames you are dealing with (for sure with read.csv,
> but not so sure at all with raster maps), give this a try:
>
> ?merge
>
> On 19 February 2015 at 17:44, Simon Tarr <simon.tarr at adtrak.co.uk> wrote:
> > Hello everyone,
> >
> > I need a little help with some R syntax to complete what (I think) is a
> > fairly straightforward task- hopefully someone can assist!
> >
> > I have a raster map of the UK which is split into postcode areas (e.g.
> DE,
> > NG, NR etc. 127 postcodes in total).
> >
> > I have installed the package 'raster' and have successfully plotted the
> > .img in R. All working and looks correct with the raster.
> >
> > I also have a comma delimited CSV file containing the same postcodes as
> the
> > raster with another column next to it containing revenue for each
> postcode.
> >
> > *I was wondering if someone could help me merge/bind the revenue figures
> > into the correct postcode in the raster so that I can plot revenue per
> > postcode.*
> >
> > I feel I should be using cbind and reclassify to do this but I can't be
> > sure.
> >
> > Any help would be appreciated. Thanks in advance!
> >
> > Simon
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From jrkrideau at inbox.com  Fri Feb 20 16:47:54 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 20 Feb 2015 07:47:54 -0800
Subject: [R] Averaging column scores when participants vary in number of
 observations
In-Reply-To: <1424396179744-4703561.post@n4.nabble.com>
References: <ca+_f+rffjftfack6zsw_xaumk9k_cwt0h8bnkx5xoy6eynlf6g@mail.gmail.com>
Message-ID: <AF8AB863E77.00000779jrkrideau@inbox.com>

And just to muddy the waters more here's another way to do it using the handy plyr package where the data.frame is "dat1"

library(plyr)
ddply(dat1, .(Participant.ID), summarize, mean = mean(Score))

John Kane
Kingston ON Canada


> -----Original Message-----
> From: js.huang at protective.com
> Sent: Thu, 19 Feb 2015 17:36:19 -0800 (PST)
> To: r-help at r-project.org
> Subject: Re: [R] Averaging column scores when participants vary in number
> of observations
> 
> Hi,
> 
>   Another implication:
> 
>> data1
>   Observation Participant.ID Video.Coder Score
> 1           A              1      Donald     4
> 2           B              1       Tracy     5
> 3           C              2      Donald     6
> 4           D              3         Sam     2
> 5           E              3       Tracy     3
> 6           F              4      Donald     2
> 7           G              4       Tracy     1
> 8           H              5         Sam     8
>> tapply(data1$Score,data1$Participant.ID,mean)
>   1   2   3   4   5
> 4.5 6.0 2.5 1.5 8.0
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Re-Averaging-column-scores-when-participants-vary-in-number-of-observations-tp4703549p4703561.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Fri Feb 20 17:06:54 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 20 Feb 2015 08:06:54 -0800
Subject: [R] Raster Help
In-Reply-To: <CAH+=eXDcX9kYUXsPcCcfHZGxYgHf_p2UMViTvped-FV8URbaeg@mail.gmail.com>
References: <cah+=exab0vr94sg3=qoyqqyem6q2ts9yjeq1nubys12gj=+ipg@mail.gmail.com>
	<cahutovp5df_rf3yskejcs__=rqt-34mpawtuk4jjmcigwr8qsg@mail.gmail.com>
Message-ID: <AFB52DBE87D.000007BDjrkrideau@inbox.com>

Simon,
You missed a key request from Sven.  He asked for data in dput() format.  This is essential for dealing with many problems.  Do ?dput for info on the function but esssentially it let's the reader see your data exactly as you see it, unfazed buy any special setting the reader may have for reading in data on R. 

Here is a little example of dput output. Just copy and paste into to get the new data.frame "dat".

dat1 <- structure(list(Observation = c("A", "B", "C", "D", "E", "F", 
"G", "H"), Participant.ID = c(1L, 1L, 2L, 3L, 3L, 4L, 4L, 5L), 
    Video.Coder = c("Donald", "Tracy", "Donald", "Sam", "Tracy", 
    "Donald", "Tracy", "Sam"), Score = c(4L, 5L, 6L, 2L, 3L, 
    2L, 1L, 8L)), .Names = c("Observation", "Participant.ID", 
"Video.Coder", "Score"), class = "data.frame", row.names = c(NA, 
-8L))

See these for some hints on asking questions.
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example


John Kane
Kingston ON Canada


> -----Original Message-----
> From: simon.tarr at adtrak.co.uk
> Sent: Fri, 20 Feb 2015 15:45:04 +0000
> To: sven.templer at gmail.com
> Subject: Re: [R] Raster Help
> 
> Hi Sven,
> 
> Many thanks for the reply and my apologies for not posting any code. So
> far, I have been able to write this (but it's very basic and just getting
> me to the 'complicated' stage).
> 
> setwd("C:\\Users\\simon.tarr\\Documents\\GIS\\Test Data")
> require(raster)
> require(rgdal)
> revenue<-read.table("revenue.csv",header=T,row.names=1,sep=",")
> postcodes<-raster("C:\\Users\\simon.tarr\\Documents\\GIS\\Test
> Data\\rasters\\postcodes\\postcodes.img")
> trim(postcodes)
> plot(postcodes)
> 
> I have attached a .csv file that contains my revenue data (this is
> actually
> just made up data- I wanted to make sure I could get the mapping to work
> before I start handling large quantities of real data).
> 
> As I mentioned, the raster contains the same list of postcode names that
> appear in the CSV. So I need to somehow 'attach' the revenue figures to
> each postcode in the raster and then plot this.
> 
> I hope this makes sense and apologies for the loose language...it's the
> only way I can think of to describe it.
> 
> I'm trying hard to learn R and its syntax but sometimes I get stuck. I
> often know what needs to be done but struggle to write the necessary code
> to make it happen.
> 
> All the best,
> 
> Simon
> 
> On 19 February 2015 at 20:37, Sven E. Templer <sven.templer at gmail.com>
> wrote:
> 
>> Without (example) code it is hard to follow... use ?dput to present
>> some data (subset).
>> But if it is data.frames you are dealing with (for sure with read.csv,
>> but not so sure at all with raster maps), give this a try:
>> 
>> ?merge
>> 
>> On 19 February 2015 at 17:44, Simon Tarr <simon.tarr at adtrak.co.uk>
>> wrote:
>>> Hello everyone,
>>> 
>>> I need a little help with some R syntax to complete what (I think) is a
>>> fairly straightforward task- hopefully someone can assist!
>>> 
>>> I have a raster map of the UK which is split into postcode areas (e.g.
>> DE,
>>> NG, NR etc. 127 postcodes in total).
>>> 
>>> I have installed the package 'raster' and have successfully plotted the
>>> .img in R. All working and looks correct with the raster.
>>> 
>>> I also have a comma delimited CSV file containing the same postcodes as
>> the
>>> raster with another column next to it containing revenue for each
>> postcode.
>>> 
>>> *I was wondering if someone could help me merge/bind the revenue
>>> figures
>>> into the correct postcode in the raster so that I can plot revenue per
>>> postcode.*
>>> 
>>> I feel I should be using cbind and reclassify to do this but I can't be
>>> sure.
>>> 
>>> Any help would be appreciated. Thanks in advance!
>>> 
>>> Simon
>>> 
>>>         [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jdnewmil at dcn.davis.CA.us  Fri Feb 20 17:08:30 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 20 Feb 2015 08:08:30 -0800
Subject: [R] return named list from foreach
In-Reply-To: <54E75669.4040102@ufl.edu>
References: <54E75669.4040102@ufl.edu>
Message-ID: <DE7FE54F-9B3D-4092-B020-7CFEDE8D060E@dcn.davis.CA.us>

You cannot do that in one step. Do it right after:

names(out) <- df$nm

Please don't post using HTML format.. it scrambles code, and since we cannot see what you saw it doesn't help in any way.

Also note that "df" is a function in the base stats package... not a good name to use.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 20, 2015 7:44:41 AM PST, Alexander Shenkin <ashenkin at ufl.edu> wrote:
>Hello all,
>
>I've been trying to figure out how to return a named list from foreach.
> 
>Given that the order of the returned list is guaranteed to be in the 
>order in which the object is passed to foreach, list members can be 
>named afterwards.  However, I'm wondering if there's a better way to do
>
>it, perhaps with some sort of combine function?
>
>    library(doParallel)
>    library(foreach)
>
>    cl <- makeCluster(4)
>    registerDoParallel(cl)
>
>    df = data.frame(nm = letters[11:20], a = 1:10, b=11:20)
>
>    out = foreach(i=1:nrow(df)) %dopar% {
>         a = list(j = sqrt(df[i,]$a), k = sqrt(df[i,]$b))
>         a
>    }
>
>How do I name the elements of "out" using the corresponding values
>df$nm?
>
>thanks,
>allie
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From simon.tarr at adtrak.co.uk  Fri Feb 20 17:10:29 2015
From: simon.tarr at adtrak.co.uk (Simon Tarr)
Date: Fri, 20 Feb 2015 16:10:29 +0000
Subject: [R] Raster Help
In-Reply-To: <AFB52DBE87D.000007BDjrkrideau@inbox.com>
References: <cah+=exab0vr94sg3=qoyqqyem6q2ts9yjeq1nubys12gj=+ipg@mail.gmail.com>
	<cahutovp5df_rf3yskejcs__=rqt-34mpawtuk4jjmcigwr8qsg@mail.gmail.com>
	<CAH+=eXDcX9kYUXsPcCcfHZGxYgHf_p2UMViTvped-FV8URbaeg@mail.gmail.com>
	<AFB52DBE87D.000007BDjrkrideau@inbox.com>
Message-ID: <CAH+=eXB48detWWM3tq6Hrt4HuBhStNU2FdwYwVOtE8b0O6yGgw@mail.gmail.com>

Hi John & everyone else,

My apologies for not providing you all with a good reproducible example. I
will get to work on this and reply in due course.

Thanks John for pointing me in the right direction with this.

Regards,

On 20 February 2015 at 16:06, John Kane <jrkrideau at inbox.com> wrote:

> Simon,
> You missed a key request from Sven.  He asked for data in dput() format.
> This is essential for dealing with many problems.  Do ?dput for info on the
> function but esssentially it let's the reader see your data exactly as you
> see it, unfazed buy any special setting the reader may have for reading in
> data on R.
>
> Here is a little example of dput output. Just copy and paste into to get
> the new data.frame "dat".
>
> dat1 <- structure(list(Observation = c("A", "B", "C", "D", "E", "F",
> "G", "H"), Participant.ID = c(1L, 1L, 2L, 3L, 3L, 4L, 4L, 5L),
>     Video.Coder = c("Donald", "Tracy", "Donald", "Sam", "Tracy",
>     "Donald", "Tracy", "Sam"), Score = c(4L, 5L, 6L, 2L, 3L,
>     2L, 1L, 8L)), .Names = c("Observation", "Participant.ID",
> "Video.Coder", "Score"), class = "data.frame", row.names = c(NA,
> -8L))
>
> See these for some hints on asking questions.
> https://github.com/hadley/devtools/wiki/Reproducibility
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: simon.tarr at adtrak.co.uk
> > Sent: Fri, 20 Feb 2015 15:45:04 +0000
> > To: sven.templer at gmail.com
> > Subject: Re: [R] Raster Help
> >
> > Hi Sven,
> >
> > Many thanks for the reply and my apologies for not posting any code. So
> > far, I have been able to write this (but it's very basic and just getting
> > me to the 'complicated' stage).
> >
> > setwd("C:\\Users\\simon.tarr\\Documents\\GIS\\Test Data")
> > require(raster)
> > require(rgdal)
> > revenue<-read.table("revenue.csv",header=T,row.names=1,sep=",")
> > postcodes<-raster("C:\\Users\\simon.tarr\\Documents\\GIS\\Test
> > Data\\rasters\\postcodes\\postcodes.img")
> > trim(postcodes)
> > plot(postcodes)
> >
> > I have attached a .csv file that contains my revenue data (this is
> > actually
> > just made up data- I wanted to make sure I could get the mapping to work
> > before I start handling large quantities of real data).
> >
> > As I mentioned, the raster contains the same list of postcode names that
> > appear in the CSV. So I need to somehow 'attach' the revenue figures to
> > each postcode in the raster and then plot this.
> >
> > I hope this makes sense and apologies for the loose language...it's the
> > only way I can think of to describe it.
> >
> > I'm trying hard to learn R and its syntax but sometimes I get stuck. I
> > often know what needs to be done but struggle to write the necessary code
> > to make it happen.
> >
> > All the best,
> >
> > Simon
> >
> > On 19 February 2015 at 20:37, Sven E. Templer <sven.templer at gmail.com>
> > wrote:
> >
> >> Without (example) code it is hard to follow... use ?dput to present
> >> some data (subset).
> >> But if it is data.frames you are dealing with (for sure with read.csv,
> >> but not so sure at all with raster maps), give this a try:
> >>
> >> ?merge
> >>
> >> On 19 February 2015 at 17:44, Simon Tarr <simon.tarr at adtrak.co.uk>
> >> wrote:
> >>> Hello everyone,
> >>>
> >>> I need a little help with some R syntax to complete what (I think) is a
> >>> fairly straightforward task- hopefully someone can assist!
> >>>
> >>> I have a raster map of the UK which is split into postcode areas (e.g.
> >> DE,
> >>> NG, NR etc. 127 postcodes in total).
> >>>
> >>> I have installed the package 'raster' and have successfully plotted the
> >>> .img in R. All working and looks correct with the raster.
> >>>
> >>> I also have a comma delimited CSV file containing the same postcodes as
> >> the
> >>> raster with another column next to it containing revenue for each
> >> postcode.
> >>>
> >>> *I was wondering if someone could help me merge/bind the revenue
> >>> figures
> >>> into the correct postcode in the raster so that I can plot revenue per
> >>> postcode.*
> >>>
> >>> I feel I should be using cbind and reclassify to do this but I can't be
> >>> sure.
> >>>
> >>> Any help would be appreciated. Thanks in advance!
> >>>
> >>> Simon
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> Check it out at http://www.inbox.com/earth
>
>
>

	[[alternative HTML version deleted]]


From knut.hansen at uit.no  Fri Feb 20 13:18:22 2015
From: knut.hansen at uit.no (Knut Hansen)
Date: Fri, 20 Feb 2015 13:18:22 +0100
Subject: [R] How do I access a specific element of a multi-dimensional list
Message-ID: <9715408.ITo0cTh8Yr@ws-ism-knuth.fm.uit.no>

Dear list,

Let's say I have setup the following list:
a = c(2, 3, 5) 
b = c("aa", "bb", "cc") 
c = c(TRUE, FALSE, TRUE) 

x = list(a, b, c)

I want to access the first second dimension element of each first dimension 
element so that the result is something like:
(2, "aa", TRUE)

In my real life problem the list is about 350 elements in the first dimension 
so the solution must handle that.

Sincerely
Knut Hansen


From sagnik.stats at gmail.com  Fri Feb 20 14:34:56 2015
From: sagnik.stats at gmail.com (sagnik chakravarty)
Date: Fri, 20 Feb 2015 19:04:56 +0530
Subject: [R] Issue:CCC Doesn't Match in R and SAS
Message-ID: <CAMwbFxjxagxjjZwuSPeb=JFZ2+7YXqPOPfsDr7z9o_hpcP+doQ@mail.gmail.com>

Hi,

I was trying to calculate the CCC metric in R with the help of "NbClust"
source code and the available SAS manual for CCC. All the Pseudo-F and
R-square are matching exactly with the SAS output except for the E_R2 and
hence CCC. I have tried and tested in multiple ways but couldn?t get any
explanation for this.

I have attached sample data, initial seed and also the SAS cluster output
in Rdata format which I used for E_R2 and CCC calculation.

FYI, following are the values of E_R2 in SAS and R respectively:

E_R2=0.4630339 (R); but ERSQ=0.3732597284 (SAS)

Could you please help me out with finding what's going wrong in the
background?

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Kindly find below the codes I have used for this:

----------

<SAS>

----------

proc fastclus data=sample_data

maxiter=100 seed=initial_seed maxc=5 outstat=metrics out=output;

Var v1 v2 v3 v4 v5 v6;

run;



----------

<R>

----------

load("C:\\Users\\sagnik\\Desktop\\SAS_cluster.Rdata")



clust.perf.metrics <- function(data, cl) {

  data1 <- as.matrix(data)

  numberObsBefore <- dim(data1)[1]

  data <- na.omit(data1)

  nn <- numberObsAfter <- dim(data)[1]

  pp <- dim(data)[2]

  qq <- max(cl)

  TT <- t(data) %*% data

  sizeEigenTT <- length(eigen(TT)$value)

  eigenValues <- eigen(TT/(nn - 1))$value

  for (i in 1:sizeEigenTT) {

    if (eigenValues[i] < 0) {

      cat(paste("There are only", numberObsAfter, "non-missing observations
out of a possible",

                numberObsBefore, "observations."))

      stop("The TSS matrix is indefinite. There must be too many missing
values. The index cannot be calculated.")

    }

  }



  s1 <- sqrt(eigenValues)

  ss <- rep(1, sizeEigenTT)

  for (i in 1:sizeEigenTT) {

    if (s1[i] != 0)

      ss[i] = s1[i]

  }

  vv <- prod(ss)

  z <- matrix(0, ncol = qq, nrow = nn)

  clX <- as.matrix(cl)

  for (i in 1:nn)

    for (j in 1:qq) {

      z[i, j] == 0

      if (clX[i, 1] == j) z[i, j] = 1

    }

  xbar <- solve(t(z) %*% z) %*% t(z) %*% data

  B <- t(xbar) %*% t(z) %*% z %*% xbar

  W <- TT - B

  R2 <- 1 - (sum(diag(W))/sum(diag(TT)))

  PseudoF <- (sum(diag(B))/(qq-1))/(sum(diag(W))/(nn-qq))



  v1 <- 1

  u1 <- rep(0, pp)

  c1 <- (vv/qq)^(1/pp)

  u1 <- ss/c1

  k1 <- sum((u1 >= 1) == TRUE)

  p1 <- min(k1, qq - 1)



  if (all(p1 > 0, p1 < pp)) {

    for (i in 1:p1) { v1 <- v1 * ss[i]}

    c <- (v1/qq)^(1/p1)

    u <- ss/c

    b1 <- sum(1/(nn + u[1:p1]))

    b2 <- sum(u[(p1 + 1):pp]^2/(nn + u[(p1 + 1):pp]), na.rm = TRUE)

    E_R2 <- 1 - ((b1 + b2)/sum(u^2)) * ((nn - qq)^2/nn) * (1 + (4/nn))

    ccc <- log((1 - E_R2)/(1 - R2)) * (sqrt(nn * p1/2)/((0.001 + E_R2)^1.2))

  } else {

    b1 <- sum(1/(nn + u))

    E_R2 <- 1 - (b1/sum(u^2)) * ((nn - qq)^2/nn) * (1 + 4/nn)

    ccc <- log((1 - E_R2)/(1 - R2)) * (sqrt(nn * pp/2)/((0.001 + E_R2)^1.2))

  }

  results <- list(R_2=R2, PseudoF=PseudoF, CCC = ccc, E_R2=E_R2);
return(results)

}



clust.perf.metrics(output[,1:6],output[,7])

#-----------------------------------------------------------------------------------------------------------------------------------

THANKS IN ADVANCE,

REGARDS,

SAGNIK

From rodmeriwether at gmail.com  Fri Feb 20 16:36:02 2015
From: rodmeriwether at gmail.com (Rod Meriwether)
Date: Fri, 20 Feb 2015 09:36:02 -0600
Subject: [R] Windows7, latest R-Studio, newb,
 how to display 1 column name from a data frame.
Message-ID: <CA+woKD7TxRJ7AeWUt7GLXRjcSrsmjWbLVe=xNyTmL2C02W2+OQ@mail.gmail.com>

I'm supposed to return for class data with the ID and the value.
I'm returning just the correct value. Here's the code and the output.
 nobs <- data.frame()
  files_list <- list.files(directory, full.names=TRUE)
  dat <- data.frame()

  for (i in id){
     dat <- (read.csv(files_list[i]))

 nobs <-  sum(complete.cases(dat))
 print(nobs)

             }
}

The below values are correct, but I dont have the "id" in front of each
sum.
Any help?
 complete("specdata",c(2,4,8,10,12))
[1] 1041
[1] 474
[1] 192
[1] 148
[1] 96

	[[alternative HTML version deleted]]


From trichter at uni-bremen.de  Fri Feb 20 18:33:30 2015
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Fri, 20 Feb 2015 18:33:30 +0100
Subject: [R] Split a dataframe by rownames and/or colnames
Message-ID: <54E76FEA.5070408@uni-bremen.de>

Dear List,

Consider this example

df <- data.frame(matrix(rnorm(9*9), ncol=9))
names(df) <- c("c_1", "d_1", "e_1", "a_p", "b_p", "c_p", "1_o1", "2_o1", 
"3_o1")
row.names(df) <- names(df)


indx <- gsub(".*_", "", names(df))

I can split the dataframe by the index that is given in the column.names 
after the underscore "_".

list2env(
   setNames(
     lapply(split(colnames(df), indx), function(x) df[x]),
     paste('df', sort(unique(indx)), sep="_")),
   envir=.GlobalEnv)

However, i changed my mind and want to do it now by rownames. Exchanging 
colnames with rownames does not work, it gives the exact same output (9 
rows x 3 columns). I could do
as.data.frame(t(df_x),
but maybe that is not elegant.
What would be the solution for splitting the dataframe by rows?

Thank you very much!

-- 
Tim Richter-Heitmann


From jholtman at gmail.com  Fri Feb 20 18:34:32 2015
From: jholtman at gmail.com (jim holtman)
Date: Fri, 20 Feb 2015 12:34:32 -0500
Subject: [R] How do I access a specific element of a multi-dimensional
	list
In-Reply-To: <9715408.ITo0cTh8Yr@ws-ism-knuth.fm.uit.no>
References: <9715408.ITo0cTh8Yr@ws-ism-knuth.fm.uit.no>
Message-ID: <CAAxdm-4rDNYCvys3DzrKeGROvL0DXJao_Oe6aiscER70+gkd=Q@mail.gmail.com>

try this:

> a = c(2, 3, 5)
>  b = c("aa", "bb", "cc")
>  c = c(TRUE, FALSE, TRUE)
>
>  x = list(a, b, c)
> x
[[1]]
[1] 2 3 5
[[2]]
[1] "aa" "bb" "cc"
[[3]]
[1]  TRUE FALSE  TRUE
> sapply(x, '[[', 1)
[1] "2"    "aa"   "TRUE"
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Feb 20, 2015 at 7:18 AM, Knut Hansen <knut.hansen at uit.no> wrote:
> Dear list,
>
> Let's say I have setup the following list:
> a = c(2, 3, 5)
> b = c("aa", "bb", "cc")
> c = c(TRUE, FALSE, TRUE)
>
> x = list(a, b, c)
>
> I want to access the first second dimension element of each first dimension
> element so that the result is something like:
> (2, "aa", TRUE)
>
> In my real life problem the list is about 350 elements in the first dimension
> so the solution must handle that.
>
> Sincerely
> Knut Hansen
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ccberry at ucsd.edu  Fri Feb 20 18:54:58 2015
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Fri, 20 Feb 2015 09:54:58 -0800
Subject: [R] Subsetting a list of lists using lapply
In-Reply-To: <1424441629292.1f9df286@Nodemailer>
References: <1424438729793.fe8ebf0b@Nodemailer>
	<1424441629292.1f9df286@Nodemailer>
Message-ID: <alpine.OSX.2.00.1502200949510.504@charles-berrys-macbook.local>

On Fri, 20 Feb 2015, Aron Lindberg wrote:

> Hmm?Chuck?s solution may actually be problematic because there are several entries which at the deepest level are called ?sha?, but that should not be included, such as:
>
>
>
>
>
> input[[67]]$content[[1]]$commit$tree$sha
>
>
>
>
> and
>
>
>
>
> input[[67]]$content[[1]]$parents[[1]]$sha
>
>
>
>
>
> it?s only the ?sha? that fit the following subsetting pattern that should be included:
>
>
>
>
>
> input[[i]]$content[[1]]$sha[1]
>
>


This should be straightforward. Look at what grepl() is doing.

And look at what names(unlist(input)) yields.

You can either write a regular expression to handle this (perhaps 
"content.sha$") or write other grepl() expressions to select (or get rid 
of) the desired (or unwanted) pattern.

See ?grepl and the page on regular expression referenced there.

HTH,

Chuck

From erinm.hodgess at gmail.com  Fri Feb 20 18:58:28 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 20 Feb 2015 12:58:28 -0500
Subject: [R] trouble with .Rd file
Message-ID: <CACxE24n6jfHsVEs32-cS7Ce_WGDh58xWsb+qu0j-t5RJBJ8nEA@mail.gmail.com>

Hello everyone!

I've been messing with this .Rd file and am having forest/trees problem by
now.

Here is the section of the .Rd file that is the troublemaker:

\usage{
plot.fore4nodate(y, sim, dates, date.fmt = "%Y-%m-%d", gof.leg = FALSE,
gof.digits = 2, legend =  "", leg.cex = 1, bands.col = "lightblue", border
= NA,
tick.tstep = "auto", lab.tstep = "auto", lab.fmt = NULL, main = NULL,
cal.ini = NA,
val.ini = NA, xlab = "Time",  ylab =  "", ylim, col = c("black", "blue"),
type = c("lines", "lines"), cex = c(1.8, 1.8), cex.axis = 1.8, ex.lab = 1.8,
lwd = c(2.5, 2.5), y = 1:2, pch = c(1, 9), cex.main = 2.1, lasa = 1, mt1 =
1.27, ...)
}


Now the error part:

"c:\Progra~1\R\R-3.0.2\bin\x64\Rcmd" build ts1

* checking for file 'ts1/DESCRIPTION' ... OK
* preparing 'ts1':
* checking DESCRIPTION meta-information ... OK
Warning: newline within quoted string at plot.fore4nodate.Rd:10
Error in parse_Rd
("C:/Users/hodgesse/AppData/Local/Temp/Rt....../ts1/man/plot.fore4nodate.RD",
:
  Unexpected end of input in (in " quoted string opened at
plot.fore4nodate.Rd:14.26)
Execution halted


The 14.26 would be at the word dates in the first line of the
plot.fore4nodate line.

This is making me a little nuts.  Actually a lot nuts.

If anyone can see anything, I would really appreciate any suggestions.

Sincerely,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Feb 20 19:03:48 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 20 Feb 2015 13:03:48 -0500
Subject: [R] trouble with .Rd file
In-Reply-To: <CACxE24n6jfHsVEs32-cS7Ce_WGDh58xWsb+qu0j-t5RJBJ8nEA@mail.gmail.com>
References: <CACxE24n6jfHsVEs32-cS7Ce_WGDh58xWsb+qu0j-t5RJBJ8nEA@mail.gmail.com>
Message-ID: <54E77704.6050803@gmail.com>

On 20/02/2015 12:58 PM, Erin Hodgess wrote:
> Hello everyone!
> 
> I've been messing with this .Rd file and am having forest/trees problem by
> now.
> 
> Here is the section of the .Rd file that is the troublemaker:
> 
> \usage{
> plot.fore4nodate(y, sim, dates, date.fmt = "%Y-%m-%d", gof.leg = FALSE,
> gof.digits = 2, legend =  "", leg.cex = 1, bands.col = "lightblue", border
> = NA,
> tick.tstep = "auto", lab.tstep = "auto", lab.fmt = NULL, main = NULL,
> cal.ini = NA,
> val.ini = NA, xlab = "Time",  ylab =  "", ylim, col = c("black", "blue"),
> type = c("lines", "lines"), cex = c(1.8, 1.8), cex.axis = 1.8, ex.lab = 1.8,
> lwd = c(2.5, 2.5), y = 1:2, pch = c(1, 9), cex.main = 2.1, lasa = 1, mt1 =
> 1.27, ...)
> }
> 
> 
> Now the error part:
> 
> "c:\Progra~1\R\R-3.0.2\bin\x64\Rcmd" build ts1
> 
> * checking for file 'ts1/DESCRIPTION' ... OK
> * preparing 'ts1':
> * checking DESCRIPTION meta-information ... OK
> Warning: newline within quoted string at plot.fore4nodate.Rd:10
> Error in parse_Rd
> ("C:/Users/hodgesse/AppData/Local/Temp/Rt....../ts1/man/plot.fore4nodate.RD",
> :
>   Unexpected end of input in (in " quoted string opened at
> plot.fore4nodate.Rd:14.26)
> Execution halted
> 
> 
> The 14.26 would be at the word dates in the first line of the
> plot.fore4nodate line.
> 
> This is making me a little nuts.  Actually a lot nuts.
> 
> If anyone can see anything, I would really appreciate any suggestions.

Generally percent symbols (%) need to be escaped in Rd files.  So the
default value for date.fmt should be entered as "\%Y-\%m-\%d".

Duncan Murdoch


From statistics84 at hotmail.com  Fri Feb 20 19:05:17 2015
From: statistics84 at hotmail.com (pari hesabi)
Date: Fri, 20 Feb 2015 18:05:17 +0000
Subject: [R] Chi-square test
Message-ID: <DUB125-W49E084DC1A66EF094B6C8EC62A0@phx.gbl>

Hello,
If the vector of observed frequencies is: ?f<-c(0,0,0,2,3,6,17,15,21,21,14,10,5,1,5)
and the vector of probability?:p11<-c(7.577864e-06, 1.999541e-04? ,1.833510e-03,? 9.059845e-03, 2.886977e-02, 6.546229e-02 ,1.124083e-01, 1.525880e-01, 1.689712e-01, 1.563522e-01,?? 1.232031e-01, 8.395000e-02, 5.009534e-02, 2.645857e-02,0.0205403)
The sum of the probabilities is equal to one. But when I want to do the the Chi-square test, I get this error: probabilities must sum to one.
Does anybody know the reason?
Best Regards,
pari
 		 	   		  

From bhh at xs4all.nl  Fri Feb 20 19:13:14 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 20 Feb 2015 19:13:14 +0100
Subject: [R] Chi-square test
In-Reply-To: <DUB125-W49E084DC1A66EF094B6C8EC62A0@phx.gbl>
References: <DUB125-W49E084DC1A66EF094B6C8EC62A0@phx.gbl>
Message-ID: <F94F6E3F-46E7-4A1A-A6AB-9E0DA7860268@xs4all.nl>


> On 20-02-2015, at 19:05, pari hesabi <statistics84 at hotmail.com> wrote:
> 
> Hello,
> If the vector of observed frequencies is:  f<-c(0,0,0,2,3,6,17,15,21,21,14,10,5,1,5)
> and the vector of probability :p11<-c(7.577864e-06, 1.999541e-04  ,1.833510e-03,  9.059845e-03, 2.886977e-02, 6.546229e-02 ,1.124083e-01, 1.525880e-01, 1.689712e-01, 1.563522e-01,   1.232031e-01, 8.395000e-02, 5.009534e-02, 2.645857e-02,0.0205403)
> The sum of the probabilities is equal to one. But when I want to do the the Chi-square test, I get this error: probabilities must sum to one.

print  sum(p11)-1

> Does anybody know the reason?

R FAQ 7.31  (http://cran.r-project.org/doc/FAQ/R-FAQ.html)

Berend

> Best Regards,
> pari
> 		 	   		  
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Fri Feb 20 19:25:58 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 20 Feb 2015 10:25:58 -0800
Subject: [R] Split a dataframe by rownames and/or colnames
In-Reply-To: <54E76FEA.5070408@uni-bremen.de>
References: <54E76FEA.5070408@uni-bremen.de>
Message-ID: <CACk-te2g+nLwANgPahDqfTtwwZ_n2taNsnsCWZ-XESDi54htfQ@mail.gmail.com>

I think

?tapply

and friends: ?by ?aggregate  ?ave

is what you want.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Feb 20, 2015 at 9:33 AM, Tim Richter-Heitmann
<trichter at uni-bremen.de> wrote:
> Dear List,
>
> Consider this example
>
> df <- data.frame(matrix(rnorm(9*9), ncol=9))
> names(df) <- c("c_1", "d_1", "e_1", "a_p", "b_p", "c_p", "1_o1", "2_o1",
> "3_o1")
> row.names(df) <- names(df)
>
>
> indx <- gsub(".*_", "", names(df))
>
> I can split the dataframe by the index that is given in the column.names
> after the underscore "_".
>
> list2env(
>   setNames(
>     lapply(split(colnames(df), indx), function(x) df[x]),
>     paste('df', sort(unique(indx)), sep="_")),
>   envir=.GlobalEnv)
>
> However, i changed my mind and want to do it now by rownames. Exchanging
> colnames with rownames does not work, it gives the exact same output (9 rows
> x 3 columns). I could do
> as.data.frame(t(df_x),
> but maybe that is not elegant.
> What would be the solution for splitting the dataframe by rows?
>
> Thank you very much!
>
> --
> Tim Richter-Heitmann
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erinm.hodgess at gmail.com  Fri Feb 20 19:49:10 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 20 Feb 2015 13:49:10 -0500
Subject: [R] trouble with .Rd file
In-Reply-To: <54E77704.6050803@gmail.com>
References: <CACxE24n6jfHsVEs32-cS7Ce_WGDh58xWsb+qu0j-t5RJBJ8nEA@mail.gmail.com>
	<54E77704.6050803@gmail.com>
Message-ID: <CACxE24nGbENKs9tVVs52Eumo3k6zNdEFUQnaUKF6-AbCmO95FQ@mail.gmail.com>

Ah!  Perfect.  Thanks so much!

Sincerely,
Erin


On Fri, Feb 20, 2015 at 1:03 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 20/02/2015 12:58 PM, Erin Hodgess wrote:
> > Hello everyone!
> >
> > I've been messing with this .Rd file and am having forest/trees problem
> by
> > now.
> >
> > Here is the section of the .Rd file that is the troublemaker:
> >
> > \usage{
> > plot.fore4nodate(y, sim, dates, date.fmt = "%Y-%m-%d", gof.leg = FALSE,
> > gof.digits = 2, legend =  "", leg.cex = 1, bands.col = "lightblue",
> border
> > = NA,
> > tick.tstep = "auto", lab.tstep = "auto", lab.fmt = NULL, main = NULL,
> > cal.ini = NA,
> > val.ini = NA, xlab = "Time",  ylab =  "", ylim, col = c("black", "blue"),
> > type = c("lines", "lines"), cex = c(1.8, 1.8), cex.axis = 1.8, ex.lab =
> 1.8,
> > lwd = c(2.5, 2.5), y = 1:2, pch = c(1, 9), cex.main = 2.1, lasa = 1, mt1
> =
> > 1.27, ...)
> > }
> >
> >
> > Now the error part:
> >
> > "c:\Progra~1\R\R-3.0.2\bin\x64\Rcmd" build ts1
> >
> > * checking for file 'ts1/DESCRIPTION' ... OK
> > * preparing 'ts1':
> > * checking DESCRIPTION meta-information ... OK
> > Warning: newline within quoted string at plot.fore4nodate.Rd:10
> > Error in parse_Rd
> >
> ("C:/Users/hodgesse/AppData/Local/Temp/Rt....../ts1/man/plot.fore4nodate.RD",
> > :
> >   Unexpected end of input in (in " quoted string opened at
> > plot.fore4nodate.Rd:14.26)
> > Execution halted
> >
> >
> > The 14.26 would be at the word dates in the first line of the
> > plot.fore4nodate line.
> >
> > This is making me a little nuts.  Actually a lot nuts.
> >
> > If anyone can see anything, I would really appreciate any suggestions.
>
> Generally percent symbols (%) need to be escaped in Rd files.  So the
> default value for date.fmt should be entered as "\%Y-\%m-\%d".
>
> Duncan Murdoch
>
>


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Feb 20 19:53:08 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 20 Feb 2015 18:53:08 +0000
Subject: [R] Chi-square test
In-Reply-To: <F94F6E3F-46E7-4A1A-A6AB-9E0DA7860268@xs4all.nl>
References: <DUB125-W49E084DC1A66EF094B6C8EC62A0@phx.gbl>
	<F94F6E3F-46E7-4A1A-A6AB-9E0DA7860268@xs4all.nl>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6547E6@mb02.ads.tamu.edu>

And probably why chisq.test has the rescale.p= argument. Your second problem with small expected values can be handled with simulate.p.value=.

> chisq.test(f, p=p11)
Error in chisq.test(f, p = p11) : probabilities must sum to 1.
> 1-sum(p11)
[1] 4.3036e-08
> chisq.test(f, p=p11, rescale.p=TRUE)

        Chi-squared test for given probabilities

data:  f
X-squared = 7.6268, df = 14, p-value = 0.9078

Warning message:
In chisq.test(f, p = p11, rescale.p = TRUE) :
  Chi-squared approximation may be incorrect
> chisq.test(f, p=p11, rescale.p=TRUE, simulate.p.value=TRUE)

        Chi-squared test for given probabilities with simulated p-value (based
        on 2000 replicates)

data:  f
X-squared = 7.6268, df = NA, p-value = 0.7996

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Berend Hasselman
Sent: Friday, February 20, 2015 12:13 PM
To: pari hesabi
Cc: r-help at r-project.org
Subject: Re: [R] Chi-square test


> On 20-02-2015, at 19:05, pari hesabi <statistics84 at hotmail.com> wrote:
> 
> Hello,
> If the vector of observed frequencies is:  f<-c(0,0,0,2,3,6,17,15,21,21,14,10,5,1,5)
> and the vector of probability :p11<-c(7.577864e-06, 1.999541e-04  ,1.833510e-03,  9.059845e-03, 2.886977e-02, 6.546229e-02 ,1.124083e-01, 1.525880e-01, 1.689712e-01, 1.563522e-01,   1.232031e-01, 8.395000e-02, 5.009534e-02, 2.645857e-02,0.0205403)
> The sum of the probabilities is equal to one. But when I want to do the the Chi-square test, I get this error: probabilities must sum to one.

print  sum(p11)-1

> Does anybody know the reason?

R FAQ 7.31  (http://cran.r-project.org/doc/FAQ/R-FAQ.html)

Berend

> Best Regards,
> pari
> 		 	   		  
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Feb 20 19:56:01 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 20 Feb 2015 10:56:01 -0800
Subject: [R] Subsetting a list of lists using lapply
In-Reply-To: <1424441629292.1f9df286@Nodemailer>
References: <1424438729793.fe8ebf0b@Nodemailer>
	<1424441629292.1f9df286@Nodemailer>
Message-ID: <554420A1-C653-48D4-8D16-4B388EF137B6@comcast.net>


On Feb 20, 2015, at 6:13 AM, Aron Lindberg wrote:

> Hmm?Chuck?s solution may actually be problematic because there are several entries which at the deepest level are called ?sha?, but that should not be included, such as:
> 
> input[[67]]$content[[1]]$commit$tree$sh
> 
> 
> and
> 
> input[[67]]$content[[1]]$parents[[1]]$sha
> 
> it?s only the ?sha? that fit the following subsetting pattern that should be included:
> 
> 
> input[[i]]$content[[1]]$sha[1]
> 
> 
> It?s getting thornier!
> 
> To be fair to Rolf?s solution (which probably can be updated to solve the problem), I?ve posted the complete dput here:
> 
> https://gist.githubusercontent.com/aronlindberg/92700c04c88ff112e4f7/raw/0f3cd8468f4dc82267be3cec72d53a7a04f5c449/dput.R

I didn't try on the larger example, but this works on the smaller one:

 get_shas <- function(input){
	x <- lapply(input, "[[", "content")
        y <- lapply(x, "[[", 1)   
	z <- lapply(y, function(yy) if( length(names(yy)) && names(yy) =="sha"  ){ yy[["sha"]] })
	}
      sha_lists <- get_shas(input)

It does deliver an entry for every leaf of the input-object which is either the value of "sha" or NA. I think that is not a bad thing because it lets you figure out where the values are coming from.

> 
> -- 
> 
> Aron Lindberg
> 
> 
> 
> 
> Doctoral Candidate, Information Systems
> 
> Weatherhead School of Management 
> 
> Case Western Reserve University
> 
> aronlindberg.github.io
> 
> On Fri, Feb 20, 2015 at 8:25 AM, Aron Lindberg <aron.lindberg at case.edu>
> wrote:
> 
>> Thanks Chuck and Rolf.
>> While Rolf?s code also works on the dput that I actually gave you (a smaller subset of the full dataset), it failed to work on the larger dataset, because there are further exceptions:
>> input[[i]]$content[[1]] is sometimes a list, sometimes a character vector, and sometimes input[[i]]$content simply returns list().
>> Chuck?s solution however bypasses this and works on the full dataset (which was 8mb, which is why I didn?t upload it as a gist).
>> Best,
>> Aron
>> -- 
>> Aron Lindberg
>> Doctoral Candidate, Information Systems
>> Weatherhead School of Management 
>> Case Western Reserve University
>> aronlindberg.github.io
>> On Fri, Feb 20, 2015 at 12:44 AM, Charles Berry <ccberry at ucsd.edu> wrote:
>>> Aron Lindberg <aron.lindberg <at> case.edu> writes:
>>>> 
>>>> Hi Everyone,
>>>> 
>>>> I'm working on a thorny subsetting problem involving list of lists. I've put a 
>>> dput of the data here:
>>>> 
>>>> 	https://gist.githubusercontent.com/aronlindberg/b916dee897d051ac5be5/
>>> raw/a78cbf873a7e865c3173f943ff6309ea688c653b/dput
>>>> 
>>> IIUC, you want the value of every list element that is named "sha" and 
>>> that name will only apply to atomic objects.
>>> If so, this should do it. 
>>>> input <- dget("/tmp/dpt")
>>>> shas <- unlist( input, use.names=FALSE )[ grepl( "sha", names(unlist(input)))]
>>>> input[[67]]$content[[1]]$sha
>>> [1] "58cf43ecdc1beb7e1043e9de612ecc817b090f15"
>>>> which(input[[67]]$content[[1]]$sha == shas )
>>> [1] 194
>>> HTH,
>>> Chuck
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Feb 20 20:15:40 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 20 Feb 2015 11:15:40 -0800
Subject: [R] Chi-square test
In-Reply-To: <DUB125-W49E084DC1A66EF094B6C8EC62A0@phx.gbl>
References: <DUB125-W49E084DC1A66EF094B6C8EC62A0@phx.gbl>
Message-ID: <EF3894AC-7299-4879-8A7B-9A5A53AC43A3@comcast.net>


On Feb 20, 2015, at 10:05 AM, pari hesabi wrote:

> Hello,
> If the vector of observed frequencies is:  f<-c(0,0,0,2,3,6,17,15,21,21,14,10,5,1,5)
> and the vector of probability :p11<-c(7.577864e-06, 1.999541e-04  ,1.833510e-03,  9.059845e-03, 2.886977e-02, 6.546229e-02 ,1.124083e-01, 1.525880e-01, 1.689712e-01, 1.563522e-01,   1.232031e-01, 8.395000e-02, 5.009534e-02, 2.645857e-02,0.0205403)
> The sum of the probabilities is equal to one.

Well, the sum is close to 1.0 but not exact. There's a simple fix:

> sum(p11)==1
[1] FALSE
> sum( p11/sum(p11) )==1
[1] TRUE

>  But when I want to do the the Chi-square test, I get this error: probabilities must sum to one.
> Does anybody know the reason?

Numerical accuracy. See R-FAQ 7.31

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Feb 20 20:36:15 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 20 Feb 2015 11:36:15 -0800
Subject: [R] Split a dataframe by rownames and/or colnames
In-Reply-To: <54E76FEA.5070408@uni-bremen.de>
References: <54E76FEA.5070408@uni-bremen.de>
Message-ID: <30B8B594-E1BC-44AF-8641-7D1049846CD8@comcast.net>


On Feb 20, 2015, at 9:33 AM, Tim Richter-Heitmann wrote:

> Dear List,
> 
> Consider this example
> 
> df <- data.frame(matrix(rnorm(9*9), ncol=9))
> names(df) <- c("c_1", "d_1", "e_1", "a_p", "b_p", "c_p", "1_o1", "2_o1", "3_o1")
> row.names(df) <- names(df)
> 
> 
> indx <- gsub(".*_", "", names(df))
> 
> I can split the dataframe by the index that is given in the column.names after the underscore "_".
> 
> list2env(
>  setNames(
>    lapply(split(colnames(df), indx), function(x) df[x]),
>    paste('df', sort(unique(indx)), sep="_")),
>  envir=.GlobalEnv)
> 

> However, i changed my mind and want to do it now by rownames. Exchanging colnames with rownames does not work, it gives the exact same output (9 rows x 3 columns). I could do
> as.data.frame(t(df_x),
> but maybe that is not elegant.
> What would be the solution for splitting the dataframe by rows?

The split.data.frame method seems to work perfectly well with a rownames-derived index argument:

> split(df, sub(".+_","", rownames(df) ) )
$`1`
      c_1   d_1  e_1   a_p   b_p   c_p  1_o1 2_o1  3_o1
c_1 -0.11 -0.04 1.33 -0.87 -0.16 -0.25 -0.75 0.34  0.14
d_1 -0.62 -0.94 0.80 -0.78 -0.70  0.74  0.11 1.44 -0.33
e_1  0.98 -0.83 0.48  0.19 -0.32 -1.01  1.28 1.04 -2.16

$o1
       c_1   d_1   e_1   a_p   b_p   c_p  1_o1  2_o1  3_o1
1_o1 -0.93 -0.02  0.69 -0.67  1.04  1.04 -1.50 -0.36  0.50
2_o1  0.02 -0.16 -0.09 -1.50 -0.02 -1.04  1.07 -0.45  1.56
3_o1 -1.42  0.88 -0.05  0.85 -1.35  0.21  1.35  0.92 -0.76

$p
      c_1   d_1   e_1   a_p  b_p   c_p  1_o1  2_o1  3_o1
a_p -1.35  0.91 -0.58 -0.63 0.94 -1.13  0.71  0.25  0.82
b_p -0.25 -0.73 -0.41 -1.71 1.28  0.19 -0.35  1.74 -0.93
c_p -0.01 -1.11 -0.12  0.58 1.51  0.03 -0.99 -0.23 -0.03

> 
> Thank you very much!
> 
> -- 
> Tim Richter-Heitmann
> 
-- 

David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Fri Feb 20 21:08:31 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 20 Feb 2015 12:08:31 -0800
Subject: [R] Subsetting a list of lists using lapply
In-Reply-To: <554420A1-C653-48D4-8D16-4B388EF137B6@comcast.net>
References: <1424438729793.fe8ebf0b@Nodemailer>
	<1424441629292.1f9df286@Nodemailer>
	<554420A1-C653-48D4-8D16-4B388EF137B6@comcast.net>
Message-ID: <CAF8bMcY+GP9guT72Cp-_u1HDeF0_p98dVaxOVRWqpXi2Hob2mA@mail.gmail.com>

The elNamed(x, name) function can simplify this code a bit.  The following
gives the same
result as David W's get_shas() for the sample dataset provided:

   get_shas2 <- function (input) {
      lapply(input, function(el) elNamed(elNamed(el, "content")[[1]],
 "sha")[1])
   }

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Feb 20, 2015 at 10:56 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Feb 20, 2015, at 6:13 AM, Aron Lindberg wrote:
>
> > Hmm?Chuck?s solution may actually be problematic because there are
> several entries which at the deepest level are called ?sha?, but that
> should not be included, such as:
> >
> > input[[67]]$content[[1]]$commit$tree$sh
> >
> >
> > and
> >
> > input[[67]]$content[[1]]$parents[[1]]$sha
> >
> > it?s only the ?sha? that fit the following subsetting pattern that
> should be included:
> >
> >
> > input[[i]]$content[[1]]$sha[1]
> >
> >
> > It?s getting thornier!
> >
> > To be fair to Rolf?s solution (which probably can be updated to solve
> the problem), I?ve posted the complete dput here:
> >
> >
> https://gist.githubusercontent.com/aronlindberg/92700c04c88ff112e4f7/raw/0f3cd8468f4dc82267be3cec72d53a7a04f5c449/dput.R
>
> I didn't try on the larger example, but this works on the smaller one:
>
>  get_shas <- function(input){
>         x <- lapply(input, "[[", "content")
>         y <- lapply(x, "[[", 1)
>         z <- lapply(y, function(yy) if( length(names(yy)) && names(yy)
> =="sha"  ){ yy[["sha"]] })
>         }
>       sha_lists <- get_shas(input)
>
> It does deliver an entry for every leaf of the input-object which is
> either the value of "sha" or NA. I think that is not a bad thing because it
> lets you figure out where the values are coming from.
>
> >
> > --
> >
> > Aron Lindberg
> >
> >
> >
> >
> > Doctoral Candidate, Information Systems
> >
> > Weatherhead School of Management
> >
> > Case Western Reserve University
> >
> > aronlindberg.github.io
> >
> > On Fri, Feb 20, 2015 at 8:25 AM, Aron Lindberg <aron.lindberg at case.edu>
> > wrote:
> >
> >> Thanks Chuck and Rolf.
> >> While Rolf?s code also works on the dput that I actually gave you (a
> smaller subset of the full dataset), it failed to work on the larger
> dataset, because there are further exceptions:
> >> input[[i]]$content[[1]] is sometimes a list, sometimes a character
> vector, and sometimes input[[i]]$content simply returns list().
> >> Chuck?s solution however bypasses this and works on the full dataset
> (which was 8mb, which is why I didn?t upload it as a gist).
> >> Best,
> >> Aron
> >> --
> >> Aron Lindberg
> >> Doctoral Candidate, Information Systems
> >> Weatherhead School of Management
> >> Case Western Reserve University
> >> aronlindberg.github.io
> >> On Fri, Feb 20, 2015 at 12:44 AM, Charles Berry <ccberry at ucsd.edu>
> wrote:
> >>> Aron Lindberg <aron.lindberg <at> case.edu> writes:
> >>>>
> >>>> Hi Everyone,
> >>>>
> >>>> I'm working on a thorny subsetting problem involving list of lists.
> I've put a
> >>> dput of the data here:
> >>>>
> >>>>
> https://gist.githubusercontent.com/aronlindberg/b916dee897d051ac5be5/
> >>> raw/a78cbf873a7e865c3173f943ff6309ea688c653b/dput
> >>>>
> >>> IIUC, you want the value of every list element that is named "sha" and
> >>> that name will only apply to atomic objects.
> >>> If so, this should do it.
> >>>> input <- dget("/tmp/dpt")
> >>>> shas <- unlist( input, use.names=FALSE )[ grepl( "sha",
> names(unlist(input)))]
> >>>> input[[67]]$content[[1]]$sha
> >>> [1] "58cf43ecdc1beb7e1043e9de612ecc817b090f15"
> >>>> which(input[[67]]$content[[1]]$sha == shas )
> >>> [1] 194
> >>> HTH,
> >>> Chuck
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Fri Feb 20 22:07:10 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 20 Feb 2015 16:07:10 -0500
Subject: [R] creating a distinct zip file
Message-ID: <CACxE24nCf5aLKeLaiXcJJaKsFCvxUOdZVKEoWONL1k2aiETB0A@mail.gmail.com>

Hello yet again.

I am trying to create a zip file for a friend who has a Windows machine.

He needs to access this via the "local zip file" packages option.

When I use R CMD INSTALL --compile-both, it produces an item in the library
tree (as promised).

However, I would like to have an actual .zip file.

I do know at one time that was possible, not sure if I can still do it.

I did try R CMD INSTALL --force-biarch as well, same result as compile both.

thank you for any suggestions.

Sincerely,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Fri Feb 20 22:30:03 2015
From: jholtman at gmail.com (jim holtman)
Date: Fri, 20 Feb 2015 16:30:03 -0500
Subject: [R] irregular sequence of events
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C20E2E@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C20E2E@SRVEXCHMBX.precheza.cz>
Message-ID: <CAAxdm-6MR_UPGS_9Tg3G=d7b3JX=Rv75TDDkvrz5mh2f2Y_tHg@mail.gmail.com>

A little shorter version of the SQL solution after consulting with my
SQL expert:

 > require(sqldf)
> timeline <- data.frame(time = 1:30)
> events <- structure(list(start = c(5, 13, 21), end = c(10, 16, 27)), .Names = c("start",
+  "end"), row.names = c(NA, -3L), class = "data.frame")
> # add event number
> events$num <- paste0("A", seq(nrow(events)))
> events
  start end num
1     5  10  A1
2    13  16  A2
3    21  27  A3
>
> sqldf("
+     select t.*, e.num
+         from timeline t
+         left join events as e
+         on t.time between e.start and e.end
+ ")
   time  num
1     1 <NA>
2     2 <NA>
3     3 <NA>
4     4 <NA>
5     5   A1
6     6   A1
7     7   A1
8     8   A1
9     9   A1
10   10   A1
11   11 <NA>
12   12 <NA>
13   13   A2
14   14   A2
15   15   A2
16   16   A2
17   17 <NA>
18   18 <NA>
19   19 <NA>
20   20 <NA>
21   21   A3
22   22   A3
23   23   A3
24   24   A3
25   25   A3
26   26   A3
27   27   A3
28   28 <NA>
29   29 <NA>
30   30 <NA>
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Feb 20, 2015 at 9:27 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Dear all
>
> I know I am missing something obvious but after few hours of trials I ask for some help.
>
> I have some sequence of values (days)
> x <- 1:30
>
> and an indication of event start and end day
> mimo<-c(5,10, 13,16, 21,27)
>
> or
>
> events <- structure(list(start = c(5, 13, 21), end = c(10, 16, 27)), .Names = c("start",
> "end"), row.names = c(NA, -3L), class = "data.frame")
>
> I need to get a factor indicating event
>
> event <- c(rep(NA, 4), rep("A1", 6), rep(NA, 2), rep("A2", 4), rep(NA, 4), rep("A3", 7), rep(NA,3))
> factor(event)
>
> In such small example I can do it manually but I have a long vector of dates and would like to use start and end day of events either from mimo vector or from events data frame.
>
> Is there any function which does it automagically? I know I have seen it before but I cannot find it now.
>
> Best regards
> Petr
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sat Feb 21 03:02:09 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 20 Feb 2015 18:02:09 -0800
Subject: [R] creating a distinct zip file
In-Reply-To: <CACxE24nCf5aLKeLaiXcJJaKsFCvxUOdZVKEoWONL1k2aiETB0A@mail.gmail.com>
References: <CACxE24nCf5aLKeLaiXcJJaKsFCvxUOdZVKEoWONL1k2aiETB0A@mail.gmail.com>
Message-ID: <F5B9B158-5098-4EB0-AA86-04001BB92445@dcn.davis.CA.us>

R CMD INSTALL --build packagename
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 20, 2015 1:07:10 PM PST, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>Hello yet again.
>
>I am trying to create a zip file for a friend who has a Windows
>machine.
>
>He needs to access this via the "local zip file" packages option.
>
>When I use R CMD INSTALL --compile-both, it produces an item in the
>library
>tree (as promised).
>
>However, I would like to have an actual .zip file.
>
>I do know at one time that was possible, not sure if I can still do it.
>
>I did try R CMD INSTALL --force-biarch as well, same result as compile
>both.
>
>thank you for any suggestions.
>
>Sincerely,
>Erin


From r.turner at auckland.ac.nz  Sat Feb 21 03:56:34 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 21 Feb 2015 15:56:34 +1300
Subject: [R] creating a distinct zip file
In-Reply-To: <F5B9B158-5098-4EB0-AA86-04001BB92445@dcn.davis.CA.us>
References: <CACxE24nCf5aLKeLaiXcJJaKsFCvxUOdZVKEoWONL1k2aiETB0A@mail.gmail.com>
	<F5B9B158-5098-4EB0-AA86-04001BB92445@dcn.davis.CA.us>
Message-ID: <54E7F3E2.8060407@auckland.ac.nz>

On 21/02/15 15:02, Jeff Newmiller wrote:
> R CMD INSTALL --build packagename

That will create a *.tar.gz file, not a *.zip file.  The latter being
what Erin wanted, if I understand correctly.

I have worked around the problem in the past with a shell script
like unto:

#! /bin/csh
set vnum = `grep Version $pkge/DESCRIPTION | sed -e 's/Version: //'`
R CMD INSTALL -l Lib $pkge >& /dev/null
cd Lib
zip -r -l $pkge.zip $pkge >& /dev/null
mv $pkge.zip ../$pkge"_"$vnum.zip

In the foregoing "pkge" is the name of the package you are trying to 
build.  You will have to have created the "holding library" "Lib" a priori.

There are doubtless (much) better ways of accomplishing this task, but I 
don't know them.

cheers,

Rolf

> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On February 20, 2015 1:07:10 PM PST, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>> Hello yet again.
>>
>> I am trying to create a zip file for a friend who has a Windows
>> machine.
>>
>> He needs to access this via the "local zip file" packages option.
>>
>> When I use R CMD INSTALL --compile-both, it produces an item in the
>> library
>> tree (as promised).
>>
>> However, I would like to have an actual .zip file.
>>
>> I do know at one time that was possible, not sure if I can still do it.
>>
>> I did try R CMD INSTALL --force-biarch as well, same result as compile
>> both.
>>
>> thank you for any suggestions.
>>
>> Sincerely,
>> Erin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From amc5981 at gmail.com  Fri Feb 20 19:55:30 2015
From: amc5981 at gmail.com (Alexandra Catena)
Date: Fri, 20 Feb 2015 10:55:30 -0800
Subject: [R] Replacing 9999 and 999 values with NA
Message-ID: <CAHpsUFYz6iz3uy6TPiTMn1sbbKS3C6pFxxk1XJtNmk=bTJ_O4g@mail.gmail.com>

Hello All,

I have a data frame of two columns for wind.  The first column is for wind
speed and the second wind direction.  I'm trying to replace the 9999 values
in the first column and the 999 values in the second column with NA.  I
tried to use the function ltdl.fix.df but it doesn't seem to do anything.

> ltdl.fix.df(windMV, zero2na = FALSE, coded = 999)

  n = 9432 by p = 4 matrix checked, 0 NA(s) present

  0 factor variable(s) present

  5675 value(s) coded 999 set to NA

  0 -ve value(s) set to +ve half the negative value


I have R version 3.1.1

Thanks,
Alexandra

	[[alternative HTML version deleted]]


From js.huang at protective.com  Fri Feb 20 21:44:58 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 20 Feb 2015 12:44:58 -0800 (PST)
Subject: [R] Simple Histogram
In-Reply-To: <1424463840508-4703615.post@n4.nabble.com>
References: <1424463840508-4703615.post@n4.nabble.com>
Message-ID: <1424465098625-4703616.post@n4.nabble.com>

Hi,

  Your data may look like the following and named speed.txt in working
directory.  Then the cod follows the data.  The graph is attached as
speed.pdf.

Speed
50
52
55
57
58
59
60
61
62
63
64
65
65
65
67
68
68
68
68
69
69
70
71
72
72
72
73
73
73
73
75
76
77
78
79



> speed <- read.table("speed.txt",header=TRUE)
> speed
   Speed
1     50
2     52
3     55
4     57
5     58
6     59
7     60
8     61
9     62
10    63
11    64
12    65
13    65
14    65
15    67
16    68
17    68
18    68
19    68
20    69
21    69
22    70
23    71
24    72
25    72
26    72
27    73
28    73
29    73
30    73
31    75
32    76
33    77
34    78
35    79
> hist(speed$Speed)

Speed.pdf <http://r.789695.n4.nabble.com/file/n4703616/Speed.pdf>  



--
View this message in context: http://r.789695.n4.nabble.com/Simple-Histogram-tp4703615p4703616.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Fri Feb 20 22:52:40 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 20 Feb 2015 13:52:40 -0800 (PST)
Subject: [R] How do I access a specific element of a multi-dimensional
	list
In-Reply-To: <CAAxdm-4rDNYCvys3DzrKeGROvL0DXJao_Oe6aiscER70+gkd=Q@mail.gmail.com>
References: <9715408.ITo0cTh8Yr@ws-ism-knuth.fm.uit.no>
	<CAAxdm-4rDNYCvys3DzrKeGROvL0DXJao_Oe6aiscER70+gkd=Q@mail.gmail.com>
Message-ID: <1424469160485-4703622.post@n4.nabble.com>

Hi,

  Jim's answer is neat.  There is an issue on the result.  All are
characters even though some are numeric or logic.  The following
implementation retains the variable type.

> x
[[1]]
[1] 2 3 5

[[2]]
[1] "aa" "bb" "cc"

[[3]]
[1]  TRUE FALSE  TRUE

> getFirst
function(aList)
{
  result <- list()
  for (i in 1:length(aList))
  {
    result <- c(result, aList[[i]][1])
  }
  return(result)
}
> getFirst(x)
[[1]]
[1] 2

[[2]]
[1] "aa"

[[3]]
[1] TRUE

> 



--
View this message in context: http://r.789695.n4.nabble.com/How-do-I-access-a-specific-element-of-a-multi-dimensional-list-tp4703596p4703622.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Sat Feb 21 00:24:38 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 20 Feb 2015 15:24:38 -0800 (PST)
Subject: [R] irregular sequence of events
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C20E2E@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C20E2E@SRVEXCHMBX.precheza.cz>
Message-ID: <1424474678721-4703624.post@n4.nabble.com>

Hi,

  Herr is one implementation with function named eventList.

> start
[1]  5 13 21
> start
[1]  5 13 21
> end
[1] 10 16 27
> x
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
25 26 27 28 29 30
> eventList
function(start, end, x)
{
  result <- character(0)
  for (i in 1:length(start))
  {
    if (i == 1)
    {
      if (start[i] > 1)
      {
        result <- c(result, rep(NA, start[i] - 1))
      }
      result <- c(result, rep(paste0("A",i), end[i] - start[i] + 1))
    }
    else
    {
      if (start[i] > end[i - 1] + 1)
      {
        result <- c(result, rep(NA, start[i] - end[i - 1] - 1))
      }
      result <- c(result, rep(paste0("A", i), end[i] - start[i] + 1))
    }
  }
  if (end[length(start)] < length(x))
  {
    result <- c(result, rep(NA, length(x) - end[length(start)]))
  }
  return(result)
}
> eventList(start, end, x)
 [1] NA   NA   NA   NA   "A1" "A1" "A1" "A1" "A1" "A1" NA   NA   "A2" "A2"
"A2" "A2" NA   NA   NA  
[20] NA   "A3" "A3" "A3" "A3" "A3" "A3" "A3" NA   NA   NA  
> 



--
View this message in context: http://r.789695.n4.nabble.com/irregular-sequence-of-events-tp4703579p4703624.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Sat Feb 21 04:47:57 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 20 Feb 2015 19:47:57 -0800
Subject: [R] Replacing 9999 and 999 values with NA
In-Reply-To: <CAHpsUFYz6iz3uy6TPiTMn1sbbKS3C6pFxxk1XJtNmk=bTJ_O4g@mail.gmail.com>
References: <CAHpsUFYz6iz3uy6TPiTMn1sbbKS3C6pFxxk1XJtNmk=bTJ_O4g@mail.gmail.com>
Message-ID: <EE82066F-F9C7-417C-8DB0-F4580E7D90D0@dcn.davis.CA.us>

You did not say how you imported the data, but if you used one of the read.table variants (including read.csv) then you can use the na.strings argument as documented in the help file for read.table.

Next time please read the posting guide, as there are some useful tips in there, such as posting using plain text (a setting in your email program) so we don't get garbled info from you, and providing a reproducible example.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 20, 2015 10:55:30 AM PST, Alexandra Catena <amc5981 at gmail.com> wrote:
>Hello All,
>
>I have a data frame of two columns for wind.  The first column is for
>wind
>speed and the second wind direction.  I'm trying to replace the 9999
>values
>in the first column and the 999 values in the second column with NA.  I
>tried to use the function ltdl.fix.df but it doesn't seem to do
>anything.
>
>> ltdl.fix.df(windMV, zero2na = FALSE, coded = 999)
>
>  n = 9432 by p = 4 matrix checked, 0 NA(s) present
>
>  0 factor variable(s) present
>
>  5675 value(s) coded 999 set to NA
>
>  0 -ve value(s) set to +ve half the negative value
>
>
>I have R version 3.1.1
>
>Thanks,
>Alexandra
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rtt at wayne.edu  Sat Feb 21 05:51:07 2015
From: rtt at wayne.edu (R Tagett)
Date: Fri, 20 Feb 2015 23:51:07 -0500 (EST)
Subject: [R] running rcorr (Hmisc) on multiple cores
In-Reply-To: <529898625.73305360.1424491782706.JavaMail.root@wayne.edu>
Message-ID: <1814518453.73307535.1424494267801.JavaMail.root@wayne.edu>


Hello,

I am having trouble generating a correlation matrix on multiple cores.

I have a matrix "myMat" for which I would like to do a Pearson correlation. 
Lets say dim(myMat) is 100 200. I want a 200x200 correlation matrix and corresponding p-value matrix.

I like to use rcorr(myMat) in the Hmisc package, but for larger matrices this command is too time consuming.
I have spent a day playing with mclapply(myMat, rcorr, ...) from the parallel package, trying to distribute the job on multiple cores. But I can't figure it out.

I also tried mclapply( myMat, cor.test, ...), but it runs even more slowly.

Does anyone have any suggestions?

Thanks very much for your help,
Beck


From alex_restrepo at hotmail.com  Sat Feb 21 06:11:45 2015
From: alex_restrepo at hotmail.com (Alex Restrepo)
Date: Fri, 20 Feb 2015 23:11:45 -0600
Subject: [R] Example of Calling a DLL
Message-ID: <COL402-EAS34637944ED5D06B516CA3AA982B0@phx.gbl>

All, 

I'm a newbie to R and am interested in seeing a simple example of calling a 3rd party Visual Studio generated DLL from RStudio.  Does anyone have a simple example which also walks through the preliminary steps of setting up the INCLUDE path and the library path to either a DLL or LIB file ?  I have tried to find an easy example, but thus far has no luck finding an example using Rcpp to communicate to a 3rd party visual studio DLL. 

Many Thanks in Advance, Alex

From wdunlap at tibco.com  Sat Feb 21 07:15:39 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 20 Feb 2015 22:15:39 -0800
Subject: [R] How do I access a specific element of a multi-dimensional
	list
In-Reply-To: <1424469160485-4703622.post@n4.nabble.com>
References: <9715408.ITo0cTh8Yr@ws-ism-knuth.fm.uit.no>
	<CAAxdm-4rDNYCvys3DzrKeGROvL0DXJao_Oe6aiscER70+gkd=Q@mail.gmail.com>
	<1424469160485-4703622.post@n4.nabble.com>
Message-ID: <CAF8bMcaOroqVsAwKzajM-XdYA8yofc_vsMGj0X74=oEB7OTe9w@mail.gmail.com>

Using lapply() where Jim used sapply() would keep the types
right and be a fair bit faster than a solution based on repeatedly
appending to a list (like your getFirst).

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Feb 20, 2015 at 1:52 PM, JS Huang <js.huang at protective.com> wrote:

> Hi,
>
>   Jim's answer is neat.  There is an issue on the result.  All are
> characters even though some are numeric or logic.  The following
> implementation retains the variable type.
>
> > x
> [[1]]
> [1] 2 3 5
>
> [[2]]
> [1] "aa" "bb" "cc"
>
> [[3]]
> [1]  TRUE FALSE  TRUE
>
> > getFirst
> function(aList)
> {
>   result <- list()
>   for (i in 1:length(aList))
>   {
>     result <- c(result, aList[[i]][1])
>   }
>   return(result)
> }
> > getFirst(x)
> [[1]]
> [1] 2
>
> [[2]]
> [1] "aa"
>
> [[3]]
> [1] TRUE
>
> >
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/How-do-I-access-a-specific-element-of-a-multi-dimensional-list-tp4703596p4703622.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sat Feb 21 07:46:22 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 20 Feb 2015 22:46:22 -0800
Subject: [R] Example of Calling a DLL
In-Reply-To: <COL402-EAS34637944ED5D06B516CA3AA982B0@phx.gbl>
References: <COL402-EAS34637944ED5D06B516CA3AA982B0@phx.gbl>
Message-ID: <CD785C33-2DB0-47D8-8E6E-D2A7F3554481@dcn.davis.CA.us>

This is off-topic here (read the posting guide). You would probably proceed most effectively by studying how GCC interacts with VS object code, e.g. [1], and studying the Writing R Extensions manual.

[1] http://stackoverflow.com/questions/8683046/compatibility-of-dll-a-lib-def-between-visualstudio-and-gcc
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 20, 2015 9:11:45 PM PST, Alex Restrepo <alex_restrepo at hotmail.com> wrote:
>All, 
>
>I'm a newbie to R and am interested in seeing a simple example of
>calling a 3rd party Visual Studio generated DLL from RStudio.  Does
>anyone have a simple example which also walks through the preliminary
>steps of setting up the INCLUDE path and the library path to either a
>DLL or LIB file ?  I have tried to find an easy example, but thus far
>has no luck finding an example using Rcpp to communicate to a 3rd party
>visual studio DLL. 
>
>Many Thanks in Advance, Alex
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sat Feb 21 08:31:43 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 20 Feb 2015 23:31:43 -0800
Subject: [R] creating a distinct zip file
In-Reply-To: <54E7F3E2.8060407@auckland.ac.nz>
References: <CACxE24nCf5aLKeLaiXcJJaKsFCvxUOdZVKEoWONL1k2aiETB0A@mail.gmail.com>
	<F5B9B158-5098-4EB0-AA86-04001BB92445@dcn.davis.CA.us>
	<54E7F3E2.8060407@auckland.ac.nz>
Message-ID: <B3DCC138-EC31-4579-B7CB-C15975C2E950@dcn.davis.CA.us>

On Windows it builds a zip file. If you are on Linux, you might [1] need [2].

[1] https://stat.ethz.ch/pipermail/r-help/2005-January/063596.html
[2] http://cran.r-project.org/doc/contributed/cross-build.pdf
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 20, 2015 6:56:34 PM PST, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>On 21/02/15 15:02, Jeff Newmiller wrote:
>> R CMD INSTALL --build packagename
>
>That will create a *.tar.gz file, not a *.zip file.  The latter being
>what Erin wanted, if I understand correctly.
>
>I have worked around the problem in the past with a shell script
>like unto:
>
>#! /bin/csh
>set vnum = `grep Version $pkge/DESCRIPTION | sed -e 's/Version: //'`
>R CMD INSTALL -l Lib $pkge >& /dev/null
>cd Lib
>zip -r -l $pkge.zip $pkge >& /dev/null
>mv $pkge.zip ../$pkge"_"$vnum.zip
>
>In the foregoing "pkge" is the name of the package you are trying to 
>build.  You will have to have created the "holding library" "Lib" a
>priori.
>
>There are doubtless (much) better ways of accomplishing this task, but
>I 
>don't know them.
>
>cheers,
>
>Rolf
>
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                        Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 20, 2015 1:07:10 PM PST, Erin Hodgess
><erinm.hodgess at gmail.com> wrote:
>>> Hello yet again.
>>>
>>> I am trying to create a zip file for a friend who has a Windows
>>> machine.
>>>
>>> He needs to access this via the "local zip file" packages option.
>>>
>>> When I use R CMD INSTALL --compile-both, it produces an item in the
>>> library
>>> tree (as promised).
>>>
>>> However, I would like to have an actual .zip file.
>>>
>>> I do know at one time that was possible, not sure if I can still do
>it.
>>>
>>> I did try R CMD INSTALL --force-biarch as well, same result as
>compile
>>> both.
>>>
>>> thank you for any suggestions.
>>>
>>> Sincerely,
>>> Erin
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From ripley at stats.ox.ac.uk  Sat Feb 21 08:56:01 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 21 Feb 2015 07:56:01 +0000
Subject: [R] creating a distinct zip file
In-Reply-To: <B3DCC138-EC31-4579-B7CB-C15975C2E950@dcn.davis.CA.us>
References: <CACxE24nCf5aLKeLaiXcJJaKsFCvxUOdZVKEoWONL1k2aiETB0A@mail.gmail.com>	<F5B9B158-5098-4EB0-AA86-04001BB92445@dcn.davis.CA.us>	<54E7F3E2.8060407@auckland.ac.nz>
	<B3DCC138-EC31-4579-B7CB-C15975C2E950@dcn.davis.CA.us>
Message-ID: <54E83A11.1020003@stats.ox.ac.uk>

On 21/02/2015 07:31, Jeff Newmiller wrote:
> On Windows it builds a zip file. If you are on Linux, you might [1] need [2].
>
> [1] https://stat.ethz.ch/pipermail/r-help/2005-January/063596.html
> [2] http://cran.r-project.org/doc/contributed/cross-build.pdf

But the first is from 2005 and the second is invalid (it should be
http://cran.r-project.org/doc/contrib/cross-build.pdf and describes R 
1.7.x: what it describes is no longer supported).

For some time you can install a package without compilable sources on 
any R platform.  So the tarball would be all that is needed.  If 
compilation is needed, submit to winbuilder to make  .zip file.

See also
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#How-can-I-get-a-binary-version-of-a-package_003f



> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On February 20, 2015 6:56:34 PM PST, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>> On 21/02/15 15:02, Jeff Newmiller wrote:
>>> R CMD INSTALL --build packagename
>>
>> That will create a *.tar.gz file, not a *.zip file.  The latter being
>> what Erin wanted, if I understand correctly.
>>
>> I have worked around the problem in the past with a shell script
>> like unto:
>>
>> #! /bin/csh
>> set vnum = `grep Version $pkge/DESCRIPTION | sed -e 's/Version: //'`
>> R CMD INSTALL -l Lib $pkge >& /dev/null
>> cd Lib
>> zip -r -l $pkge.zip $pkge >& /dev/null
>> mv $pkge.zip ../$pkge"_"$vnum.zip
>>
>> In the foregoing "pkge" is the name of the package you are trying to
>> build.  You will have to have created the "holding library" "Lib" a
>> priori.
>>
>> There are doubtless (much) better ways of accomplishing this task, but
>> I
>> don't know them.
>>
>> cheers,
>>
>> Rolf
>>
>>>
>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>>                                         Live:   OO#.. Dead: OO#..
>> Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>>
>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On February 20, 2015 1:07:10 PM PST, Erin Hodgess
>> <erinm.hodgess at gmail.com> wrote:
>>>> Hello yet again.
>>>>
>>>> I am trying to create a zip file for a friend who has a Windows
>>>> machine.
>>>>
>>>> He needs to access this via the "local zip file" packages option.
>>>>
>>>> When I use R CMD INSTALL --compile-both, it produces an item in the
>>>> library
>>>> tree (as promised).
>>>>
>>>> However, I would like to have an actual .zip file.
>>>>
>>>> I do know at one time that was possible, not sure if I can still do
>> it.
>>>>
>>>> I did try R CMD INSTALL --force-biarch as well, same result as
>> compile
>>>> both.
>>>>
>>>> thank you for any suggestions.
>>>>
>>>> Sincerely,
>>>> Erin
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From erinm.hodgess at gmail.com  Sat Feb 21 18:01:17 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sat, 21 Feb 2015 12:01:17 -0500
Subject: [R] creating a distinct zip file
In-Reply-To: <54E83A11.1020003@stats.ox.ac.uk>
References: <CACxE24nCf5aLKeLaiXcJJaKsFCvxUOdZVKEoWONL1k2aiETB0A@mail.gmail.com>
	<F5B9B158-5098-4EB0-AA86-04001BB92445@dcn.davis.CA.us>
	<54E7F3E2.8060407@auckland.ac.nz>
	<B3DCC138-EC31-4579-B7CB-C15975C2E950@dcn.davis.CA.us>
	<54E83A11.1020003@stats.ox.ac.uk>
Message-ID: <CACxE24=5s+0tomVYDap6F-hQLk8b00s=eLMSAgZqM54tBMkKBQ@mail.gmail.com>

This is not for CRAN, just for someone else.


It doesn't need to be submitted.

Thanks,
Erin


On Sat, Feb 21, 2015 at 2:56 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk>
wrote:

> On 21/02/2015 07:31, Jeff Newmiller wrote:
>
>> On Windows it builds a zip file. If you are on Linux, you might [1] need
>> [2].
>>
>> [1] https://stat.ethz.ch/pipermail/r-help/2005-January/063596.html
>> [2] http://cran.r-project.org/doc/contributed/cross-build.pdf
>>
>
> But the first is from 2005 and the second is invalid (it should be
> http://cran.r-project.org/doc/contrib/cross-build.pdf and describes R
> 1.7.x: what it describes is no longer supported).
>
> For some time you can install a package without compilable sources on any
> R platform.  So the tarball would be all that is needed.  If compilation is
> needed, submit to winbuilder to make  .zip file.
>
> See also
> http://cran.r-project.org/bin/windows/base/rw-FAQ.html#How-
> can-I-get-a-binary-version-of-a-package_003f
>
>
>
>
>  ------------------------------------------------------------
>> ---------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> ------------------------------------------------------------
>> ---------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 20, 2015 6:56:34 PM PST, Rolf Turner <r.turner at auckland.ac.nz>
>> wrote:
>>
>>> On 21/02/15 15:02, Jeff Newmiller wrote:
>>>
>>>> R CMD INSTALL --build packagename
>>>>
>>>
>>> That will create a *.tar.gz file, not a *.zip file.  The latter being
>>> what Erin wanted, if I understand correctly.
>>>
>>> I have worked around the problem in the past with a shell script
>>> like unto:
>>>
>>> #! /bin/csh
>>> set vnum = `grep Version $pkge/DESCRIPTION | sed -e 's/Version: //'`
>>> R CMD INSTALL -l Lib $pkge >& /dev/null
>>> cd Lib
>>> zip -r -l $pkge.zip $pkge >& /dev/null
>>> mv $pkge.zip ../$pkge"_"$vnum.zip
>>>
>>> In the foregoing "pkge" is the name of the package you are trying to
>>> build.  You will have to have created the "holding library" "Lib" a
>>> priori.
>>>
>>> There are doubtless (much) better ways of accomplishing this task, but
>>> I
>>> don't know them.
>>>
>>> cheers,
>>>
>>> Rolf
>>>
>>>
>>>>  ------------------------------------------------------------
>>> ---------------
>>>
>>>> Jeff Newmiller                        The     .....       .....  Go
>>>>
>>> Live...
>>>
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>>
>>> Go...
>>>
>>>>                                         Live:   OO#.. Dead: OO#..
>>>>
>>> Playing
>>>
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>>
>>> rocks...1k
>>>
>>>>
>>>>  ------------------------------------------------------------
>>> ---------------
>>>
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On February 20, 2015 1:07:10 PM PST, Erin Hodgess
>>>>
>>> <erinm.hodgess at gmail.com> wrote:
>>>
>>>> Hello yet again.
>>>>>
>>>>> I am trying to create a zip file for a friend who has a Windows
>>>>> machine.
>>>>>
>>>>> He needs to access this via the "local zip file" packages option.
>>>>>
>>>>> When I use R CMD INSTALL --compile-both, it produces an item in the
>>>>> library
>>>>> tree (as promised).
>>>>>
>>>>> However, I would like to have an actual .zip file.
>>>>>
>>>>> I do know at one time that was possible, not sure if I can still do
>>>>>
>>>> it.
>>>
>>>>
>>>>> I did try R CMD INSTALL --force-biarch as well, same result as
>>>>>
>>>> compile
>>>
>>>> both.
>>>>>
>>>>> thank you for any suggestions.
>>>>>
>>>>> Sincerely,
>>>>> Erin
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>>
>>> http://www.R-project.org/posting-guide.html
>>>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Feb 21 19:29:38 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 21 Feb 2015 19:29:38 +0100
Subject: [R] creating a distinct zip file
In-Reply-To: <CACxE24=5s+0tomVYDap6F-hQLk8b00s=eLMSAgZqM54tBMkKBQ@mail.gmail.com>
References: <CACxE24nCf5aLKeLaiXcJJaKsFCvxUOdZVKEoWONL1k2aiETB0A@mail.gmail.com>
	<F5B9B158-5098-4EB0-AA86-04001BB92445@dcn.davis.CA.us>
	<54E7F3E2.8060407@auckland.ac.nz>
	<B3DCC138-EC31-4579-B7CB-C15975C2E950@dcn.davis.CA.us>
	<54E83A11.1020003@stats.ox.ac.uk>
	<CACxE24=5s+0tomVYDap6F-hQLk8b00s=eLMSAgZqM54tBMkKBQ@mail.gmail.com>
Message-ID: <FC57914C-BA09-489E-B7CA-372317DE9ACC@gmail.com>


> On 21 Feb 2015, at 18:01 , Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> 
> This is not for CRAN, just for someone else.
> 
> 
> It doesn't need to be submitted.
> 

As I understand it, it doesn't need to be submitted in order to be submitted...

(to CRAN, winbuilder respectively).

Just make sure it satisfies the formal package structure, with yourself in the maintainer field. Check out

http://win-builder.r-project.org

-pd


> Thanks,
> Erin
> 
> 
> On Sat, Feb 21, 2015 at 2:56 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk>
> wrote:
> 
>> On 21/02/2015 07:31, Jeff Newmiller wrote:
>> 
>>> On Windows it builds a zip file. If you are on Linux, you might [1] need
>>> [2].
>>> 
>>> [1] https://stat.ethz.ch/pipermail/r-help/2005-January/063596.html
>>> [2] http://cran.r-project.org/doc/contributed/cross-build.pdf
>>> 
>> 
>> But the first is from 2005 and the second is invalid (it should be
>> http://cran.r-project.org/doc/contrib/cross-build.pdf and describes R
>> 1.7.x: what it describes is no longer supported).
>> 
>> For some time you can install a package without compilable sources on any
>> R platform.  So the tarball would be all that is needed.  If compilation is
>> needed, submit to winbuilder to make  .zip file.
>> 
>> See also
>> http://cran.r-project.org/bin/windows/base/rw-FAQ.html#How-
>> can-I-get-a-binary-version-of-a-package_003f
>> 
>> 
>> 
>> 
>> ------------------------------------------------------------
>>> ---------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>                                       Live:   OO#.. Dead: OO#.. Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>> ------------------------------------------------------------
>>> ---------------
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On February 20, 2015 6:56:34 PM PST, Rolf Turner <r.turner at auckland.ac.nz>
>>> wrote:
>>> 
>>>> On 21/02/15 15:02, Jeff Newmiller wrote:
>>>> 
>>>>> R CMD INSTALL --build packagename
>>>>> 
>>>> 
>>>> That will create a *.tar.gz file, not a *.zip file.  The latter being
>>>> what Erin wanted, if I understand correctly.
>>>> 
>>>> I have worked around the problem in the past with a shell script
>>>> like unto:
>>>> 
>>>> #! /bin/csh
>>>> set vnum = `grep Version $pkge/DESCRIPTION | sed -e 's/Version: //'`
>>>> R CMD INSTALL -l Lib $pkge >& /dev/null
>>>> cd Lib
>>>> zip -r -l $pkge.zip $pkge >& /dev/null
>>>> mv $pkge.zip ../$pkge"_"$vnum.zip
>>>> 
>>>> In the foregoing "pkge" is the name of the package you are trying to
>>>> build.  You will have to have created the "holding library" "Lib" a
>>>> priori.
>>>> 
>>>> There are doubtless (much) better ways of accomplishing this task, but
>>>> I
>>>> don't know them.
>>>> 
>>>> cheers,
>>>> 
>>>> Rolf
>>>> 
>>>> 
>>>>> ------------------------------------------------------------
>>>> ---------------
>>>> 
>>>>> Jeff Newmiller                        The     .....       .....  Go
>>>>> 
>>>> Live...
>>>> 
>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. Live
>>>>> 
>>>> Go...
>>>> 
>>>>>                                        Live:   OO#.. Dead: OO#..
>>>>> 
>>>> Playing
>>>> 
>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#. with
>>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>>> 
>>>> rocks...1k
>>>> 
>>>>> 
>>>>> ------------------------------------------------------------
>>>> ---------------
>>>> 
>>>>> Sent from my phone. Please excuse my brevity.
>>>>> 
>>>>> On February 20, 2015 1:07:10 PM PST, Erin Hodgess
>>>>> 
>>>> <erinm.hodgess at gmail.com> wrote:
>>>> 
>>>>> Hello yet again.
>>>>>> 
>>>>>> I am trying to create a zip file for a friend who has a Windows
>>>>>> machine.
>>>>>> 
>>>>>> He needs to access this via the "local zip file" packages option.
>>>>>> 
>>>>>> When I use R CMD INSTALL --compile-both, it produces an item in the
>>>>>> library
>>>>>> tree (as promised).
>>>>>> 
>>>>>> However, I would like to have an actual .zip file.
>>>>>> 
>>>>>> I do know at one time that was possible, not sure if I can still do
>>>>>> 
>>>>> it.
>>>> 
>>>>> 
>>>>>> I did try R CMD INSTALL --force-biarch as well, same result as
>>>>>> 
>>>>> compile
>>>> 
>>>>> both.
>>>>>> 
>>>>>> thank you for any suggestions.
>>>>>> 
>>>>>> Sincerely,
>>>>>> Erin
>>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> 
>>>> http://www.R-project.org/posting-guide.html
>>>> 
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>> 
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Emeritus Professor of Applied Statistics, University of Oxford
>> 1 South Parks Road, Oxford OX1 3TG, UK
>> 
> 
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From peter.langfelder at gmail.com  Sat Feb 21 19:49:32 2015
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Sat, 21 Feb 2015 10:49:32 -0800
Subject: [R] creating a distinct zip file
In-Reply-To: <54E7F3E2.8060407@auckland.ac.nz>
References: <CACxE24nCf5aLKeLaiXcJJaKsFCvxUOdZVKEoWONL1k2aiETB0A@mail.gmail.com>
	<F5B9B158-5098-4EB0-AA86-04001BB92445@dcn.davis.CA.us>
	<54E7F3E2.8060407@auckland.ac.nz>
Message-ID: <CA+hbrhUV9nRFTX20B2mPg2jEX1QbZ2aVqHkTvQfVWdBvt_qjyA@mail.gmail.com>

On Fri, Feb 20, 2015 at 6:56 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 21/02/15 15:02, Jeff Newmiller wrote:
>>
>> R CMD INSTALL --build packagename
>
>
> That will create a *.tar.gz file, not a *.zip file.  The latter being
> what Erin wanted, if I understand correctly.


It depends on her system (I don't see it specified anywhere). On
Windows, R CMD INSTALL --build packagename produces a compiled .zip
file. On Mac it produces a .tgz. Haven't tried it on Linux.

Peter


From erinm.hodgess at gmail.com  Sat Feb 21 20:47:16 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sat, 21 Feb 2015 14:47:16 -0500
Subject: [R] creating a distinct zip file
In-Reply-To: <CA+hbrhUV9nRFTX20B2mPg2jEX1QbZ2aVqHkTvQfVWdBvt_qjyA@mail.gmail.com>
References: <CACxE24nCf5aLKeLaiXcJJaKsFCvxUOdZVKEoWONL1k2aiETB0A@mail.gmail.com>
	<F5B9B158-5098-4EB0-AA86-04001BB92445@dcn.davis.CA.us>
	<54E7F3E2.8060407@auckland.ac.nz>
	<CA+hbrhUV9nRFTX20B2mPg2jEX1QbZ2aVqHkTvQfVWdBvt_qjyA@mail.gmail.com>
Message-ID: <CACxE24=BB5YcaX4Jdiz8rHd+osYW=_cHUpST6bmdCO_9Dx7A1g@mail.gmail.com>

I have Windows, but the "R CMD INSTALL --build pack" does not produce a
compiled zip.

Thanks,
Erin


On Sat, Feb 21, 2015 at 1:49 PM, Peter Langfelder <
peter.langfelder at gmail.com> wrote:

> On Fri, Feb 20, 2015 at 6:56 PM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> > On 21/02/15 15:02, Jeff Newmiller wrote:
> >>
> >> R CMD INSTALL --build packagename
> >
> >
> > That will create a *.tar.gz file, not a *.zip file.  The latter being
> > what Erin wanted, if I understand correctly.
>
>
> It depends on her system (I don't see it specified anywhere). On
> Windows, R CMD INSTALL --build packagename produces a compiled .zip
> file. On Mac it produces a .tgz. Haven't tried it on Linux.
>
> Peter
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Feb 21 21:40:31 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 21 Feb 2015 15:40:31 -0500
Subject: [R] creating a distinct zip file
In-Reply-To: <CACxE24=BB5YcaX4Jdiz8rHd+osYW=_cHUpST6bmdCO_9Dx7A1g@mail.gmail.com>
References: <CACxE24nCf5aLKeLaiXcJJaKsFCvxUOdZVKEoWONL1k2aiETB0A@mail.gmail.com>	<F5B9B158-5098-4EB0-AA86-04001BB92445@dcn.davis.CA.us>	<54E7F3E2.8060407@auckland.ac.nz>	<CA+hbrhUV9nRFTX20B2mPg2jEX1QbZ2aVqHkTvQfVWdBvt_qjyA@mail.gmail.com>
	<CACxE24=BB5YcaX4Jdiz8rHd+osYW=_cHUpST6bmdCO_9Dx7A1g@mail.gmail.com>
Message-ID: <54E8ED3F.10001@gmail.com>

On 21/02/2015 2:47 PM, Erin Hodgess wrote:
> I have Windows, but the "R CMD INSTALL --build pack" does not produce a
> compiled zip.

What does it do?  Can you show us a transcript?

Duncan Murdoch

> 
> Thanks,
> Erin
> 
> 
> On Sat, Feb 21, 2015 at 1:49 PM, Peter Langfelder <
> peter.langfelder at gmail.com> wrote:
> 
>> On Fri, Feb 20, 2015 at 6:56 PM, Rolf Turner <r.turner at auckland.ac.nz>
>> wrote:
>>> On 21/02/15 15:02, Jeff Newmiller wrote:
>>>>
>>>> R CMD INSTALL --build packagename
>>>
>>>
>>> That will create a *.tar.gz file, not a *.zip file.  The latter being
>>> what Erin wanted, if I understand correctly.
>>
>>
>> It depends on her system (I don't see it specified anywhere). On
>> Windows, R CMD INSTALL --build packagename produces a compiled .zip
>> file. On Mac it produces a .tgz. Haven't tried it on Linux.
>>
>> Peter
>>
> 
> 
>


From jdnewmil at dcn.davis.CA.us  Sat Feb 21 22:07:52 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 21 Feb 2015 13:07:52 -0800
Subject: [R] creating a distinct zip file
In-Reply-To: <CACxE24=BB5YcaX4Jdiz8rHd+osYW=_cHUpST6bmdCO_9Dx7A1g@mail.gmail.com>
References: <CACxE24nCf5aLKeLaiXcJJaKsFCvxUOdZVKEoWONL1k2aiETB0A@mail.gmail.com>
	<F5B9B158-5098-4EB0-AA86-04001BB92445@dcn.davis.CA.us>
	<54E7F3E2.8060407@auckland.ac.nz>
	<CA+hbrhUV9nRFTX20B2mPg2jEX1QbZ2aVqHkTvQfVWdBvt_qjyA@mail.gmail.com>
	<CACxE24=BB5YcaX4Jdiz8rHd+osYW=_cHUpST6bmdCO_9Dx7A1g@mail.gmail.com>
Message-ID: <5D8F631C-F3E3-490B-9DE1-56386D6EE76F@dcn.davis.CA.us>

What is a "compiled zip"? There is a warning against using that term in section 1 of the Writing R Extensions  documentation, along with a discussion of why it is ambiguous at best. Can you read that and clarify your statement?

Since you make this assertion that R  CMD INSTALL --build does not do what you want it to, I am not sure we are speaking of the same kind of file. If we are, then you may not have your system configured correctly.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 21, 2015 11:47:16 AM PST, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>I have Windows, but the "R CMD INSTALL --build pack" does not produce a
>compiled zip.
>
>Thanks,
>Erin
>
>
>On Sat, Feb 21, 2015 at 1:49 PM, Peter Langfelder <
>peter.langfelder at gmail.com> wrote:
>
>> On Fri, Feb 20, 2015 at 6:56 PM, Rolf Turner
><r.turner at auckland.ac.nz>
>> wrote:
>> > On 21/02/15 15:02, Jeff Newmiller wrote:
>> >>
>> >> R CMD INSTALL --build packagename
>> >
>> >
>> > That will create a *.tar.gz file, not a *.zip file.  The latter
>being
>> > what Erin wanted, if I understand correctly.
>>
>>
>> It depends on her system (I don't see it specified anywhere). On
>> Windows, R CMD INSTALL --build packagename produces a compiled .zip
>> file. On Mac it produces a .tgz. Haven't tried it on Linux.
>>
>> Peter
>>


From jthayn at ilstu.edu  Sat Feb 21 22:42:44 2015
From: jthayn at ilstu.edu (Jonathan Thayn)
Date: Sat, 21 Feb 2015 15:42:44 -0600
Subject: [R] Correlation question
Message-ID: <CB58C863-EB51-4F0E-96A6-95D0B27637D3@ilstu.edu>

I recently compared two different approaches to calculating the correlation of two variables, and I cannot explain the different results: 

data(cars)
model <- lm(dist~speed,data=cars)
coef(model)
fitted.right <- model$fitted
fitted.wrong <- -17+5*cars$speed


When using the OLS fitted values, the lines below all return the same R2 value:

1-sum((cars$dist-fitted.right)^2)/sum((cars$dist-mean(cars$dist))^2)
cor(cars$dist,fitted.right)^2
(sum((cars$dist-mean(cars$dist))*(fitted.right-mean(fitted.right)))/(49*sd(cars$dist)*sd(fitted.right)))^2


However, when I use my estimated parameters to find the fitted values, "fitted.wrong", the first equation returns a much lower R2 value, which I would expect since the fit is worse, but the other lines return the same R2 that I get when using the OLS fitted values.

1-sum((cars$dist-fitted.wrong)^2)/sum((cars$dist-mean(cars$dist))^2)
cor(x=cars$dist,y=fitted.wrong)^2
(sum((cars$dist-mean(cars$dist))*(fitted.wrong-mean(fitted.wrong)))/(49*sd(cars$dist)*sd(fitted.wrong)))^2


I'm sure I'm missing something simple, but can someone explain the difference between these two methods of finding R2? Thanks.

Jon
	[[alternative HTML version deleted]]


From kehld at ktk.pte.hu  Sat Feb 21 23:36:45 2015
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?Kehl_D=E1niel?=)
Date: Sat, 21 Feb 2015 22:36:45 +0000
Subject: [R] Correlation question
In-Reply-To: <CB58C863-EB51-4F0E-96A6-95D0B27637D3@ilstu.edu>
References: <CB58C863-EB51-4F0E-96A6-95D0B27637D3@ilstu.edu>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D143D1464@EMAIL.ktkdom.pte.hu>

Hi,

try

cor(fitted.right,fitted.wrong)

should give 1 as both are a linear function of speed! Hence cor(cars$dist,fitted.right)^2 and cor(x=cars$dist,y=fitted.wrong)^2 must be the same.

HTH
d
________________________________________
Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Jonathan Thayn [jthayn at ilstu.edu]
K?ldve: 2015. febru?r 21. 22:42
To: r-help at r-project.org
T?rgy: [R] Correlation question

I recently compared two different approaches to calculating the correlation of two variables, and I cannot explain the different results:

data(cars)
model <- lm(dist~speed,data=cars)
coef(model)
fitted.right <- model$fitted
fitted.wrong <- -17+5*cars$speed


When using the OLS fitted values, the lines below all return the same R2 value:

1-sum((cars$dist-fitted.right)^2)/sum((cars$dist-mean(cars$dist))^2)
cor(cars$dist,fitted.right)^2
(sum((cars$dist-mean(cars$dist))*(fitted.right-mean(fitted.right)))/(49*sd(cars$dist)*sd(fitted.right)))^2


However, when I use my estimated parameters to find the fitted values, "fitted.wrong", the first equation returns a much lower R2 value, which I would expect since the fit is worse, but the other lines return the same R2 that I get when using the OLS fitted values.

1-sum((cars$dist-fitted.wrong)^2)/sum((cars$dist-mean(cars$dist))^2)
cor(x=cars$dist,y=fitted.wrong)^2
(sum((cars$dist-mean(cars$dist))*(fitted.wrong-mean(fitted.wrong)))/(49*sd(cars$dist)*sd(fitted.wrong)))^2


I'm sure I'm missing something simple, but can someone explain the difference between these two methods of finding R2? Thanks.

Jon
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ravi.varadhan at jhu.edu  Sun Feb 22 00:33:38 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Sat, 21 Feb 2015 23:33:38 +0000
Subject: [R] multiple parameter optimization with optim()
Message-ID: <1424561609231.93109@jhu.edu>

Harold,



Obviously the bottleneck is your objective function fn().  I have speeded up your function by a factor of about 2.4 by using `outer' instead of sapply.  I think it can be speeded much more.  I couldn't figure it out without spending a lot of time.  I am sure someone on this list-serv can come up with a cleverer way to program the objective function.



pl3 <- function(dat, Q, startVal = NULL, ...){
                 if(!is.null(startVal) && length(startVal) != ncol(dat) ){
                                 stop("Length of argument startVal not equal to the number of parameters estimated")
                 }
                 if(!is.null(startVal)){
                                 startVal <- startVal
                                 } else {
                                 p <- colMeans(dat)
                                 startValA <- rep(1, ncol(dat))
                                 startValB <- as.vector(log((1 - p)/p))
                                 startVal <- c(startValA,startValB)
                 }
                 rr1 <- rr2 <- numeric(nrow(dat))
                 qq <- gauss.quad.prob(Q, dist = 'normal', mu = 0, sigma=1)
         nds <- qq$nodes
         wts <- qq$weights
         Q <- length(qq$nodes)
                 dat <- as.matrix(dat)
                 fn <- function(params){
                     a <- params[1:20]
                     b <- params[21:40]
                 for(j in 1:length(rr1)){
                 rr1[j] <- sum(wts*exp(colSums(outer(dat[j,], nds, function(x,y) dbinom(x, 1, 1/ (1 + exp(- 1.7 * a * (y - b))), log = TRUE)))))
      }
      -sum(log(rr1))
                  }
                 #opt <- optim(startVal, fn, method = "BFGS", hessian = TRUE)
                 opt <-  nlminb(startVal, fn, control=list(trace=1, rel.tol=1.e-06, iter.max=50))
#                 opt <- spg(startVal, fn)
                 opt
                 #list("coefficients" = opt$par, "LogLik" = -opt$value, "Std.Error" = sqrt(diag(solve(opt$hessian))))
 }



Hope this is helpful,

Ravi

	[[alternative HTML version deleted]]


From jthayn at ilstu.edu  Sun Feb 22 07:01:19 2015
From: jthayn at ilstu.edu (Jonathan Thayn)
Date: Sun, 22 Feb 2015 00:01:19 -0600
Subject: [R] Correlation question
In-Reply-To: <33D76D77E9AC4B438DA38B348ED6890D143D1464@EMAIL.ktkdom.pte.hu>
References: <CB58C863-EB51-4F0E-96A6-95D0B27637D3@ilstu.edu>
	<33D76D77E9AC4B438DA38B348ED6890D143D1464@EMAIL.ktkdom.pte.hu>
Message-ID: <2DAAE620-96D5-4E50-BCEB-DC8B0072E520@ilstu.edu>

Of course! Thank you, I knew I was missing something painfully obvious. Its seems, then, that this line

1-sum((cars$dist-fitted.wrong)^2)/sum((cars$dist-mean(cars$dist))^2)

is finding something other than the traditional correlation. I found this in a lecture introducing correlation, but , now, I'm not sure what it is. It does do a better job of showing that the fitted.wrong variable is not a good prediction of the distance. 



On Feb 21, 2015, at 4:36 PM, Kehl D?niel wrote:

> Hi,
> 
> try
> 
> cor(fitted.right,fitted.wrong)
> 
> should give 1 as both are a linear function of speed! Hence cor(cars$dist,fitted.right)^2 and cor(x=cars$dist,y=fitted.wrong)^2 must be the same.
> 
> HTH
> d
> ________________________________________
> Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Jonathan Thayn [jthayn at ilstu.edu]
> K?ldve: 2015. febru?r 21. 22:42
> To: r-help at r-project.org
> T?rgy: [R] Correlation question
> 
> I recently compared two different approaches to calculating the correlation of two variables, and I cannot explain the different results:
> 
> data(cars)
> model <- lm(dist~speed,data=cars)
> coef(model)
> fitted.right <- model$fitted
> fitted.wrong <- -17+5*cars$speed
> 
> 
> When using the OLS fitted values, the lines below all return the same R2 value:
> 
> 1-sum((cars$dist-fitted.right)^2)/sum((cars$dist-mean(cars$dist))^2)
> cor(cars$dist,fitted.right)^2
> (sum((cars$dist-mean(cars$dist))*(fitted.right-mean(fitted.right)))/(49*sd(cars$dist)*sd(fitted.right)))^2
> 
> 
> However, when I use my estimated parameters to find the fitted values, "fitted.wrong", the first equation returns a much lower R2 value, which I would expect since the fit is worse, but the other lines return the same R2 that I get when using the OLS fitted values.
> 
> 1-sum((cars$dist-fitted.wrong)^2)/sum((cars$dist-mean(cars$dist))^2)
> cor(x=cars$dist,y=fitted.wrong)^2
> (sum((cars$dist-mean(cars$dist))*(fitted.wrong-mean(fitted.wrong)))/(49*sd(cars$dist)*sd(fitted.wrong)))^2
> 
> 
> I'm sure I'm missing something simple, but can someone explain the difference between these two methods of finding R2? Thanks.
> 
> Jon
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ntfredo at gmail.com  Sun Feb 22 07:38:04 2015
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Sun, 22 Feb 2015 09:38:04 +0300
Subject: [R] Replacing 9999 and 999 values with NA
In-Reply-To: <EE82066F-F9C7-417C-8DB0-F4580E7D90D0@dcn.davis.CA.us>
References: <CAHpsUFYz6iz3uy6TPiTMn1sbbKS3C6pFxxk1XJtNmk=bTJ_O4g@mail.gmail.com>
	<EE82066F-F9C7-417C-8DB0-F4580E7D90D0@dcn.davis.CA.us>
Message-ID: <CAGh51gTZNyH41E3FR5cBJVU=2SZZtuF6Jnu=qnTna7dCLegFzg@mail.gmail.com>

If you are reading the data frame using for instance read.csv, you can put
in the argument na.string ="9999".
Another way to do that is data[data ==9999] <- NA.

It should be good to tell us how you are reading your dataset.
On Feb 21, 2015 6:49 AM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:

> You did not say how you imported the data, but if you used one of the
> read.table variants (including read.csv) then you can use the na.strings
> argument as documented in the help file for read.table.
>
> Next time please read the posting guide, as there are some useful tips in
> there, such as posting using plain text (a setting in your email program)
> so we don't get garbled info from you, and providing a reproducible example.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On February 20, 2015 10:55:30 AM PST, Alexandra Catena <amc5981 at gmail.com>
> wrote:
> >Hello All,
> >
> >I have a data frame of two columns for wind.  The first column is for
> >wind
> >speed and the second wind direction.  I'm trying to replace the 9999
> >values
> >in the first column and the 999 values in the second column with NA.  I
> >tried to use the function ltdl.fix.df but it doesn't seem to do
> >anything.
> >
> >> ltdl.fix.df(windMV, zero2na = FALSE, coded = 999)
> >
> >  n = 9432 by p = 4 matrix checked, 0 NA(s) present
> >
> >  0 factor variable(s) present
> >
> >  5675 value(s) coded 999 set to NA
> >
> >  0 -ve value(s) set to +ve half the negative value
> >
> >
> >I have R version 3.1.1
> >
> >Thanks,
> >Alexandra
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From aakrity333tibrewal at gmail.com  Sun Feb 22 09:36:16 2015
From: aakrity333tibrewal at gmail.com (Aakrity Tibrewal)
Date: Sun, 22 Feb 2015 14:06:16 +0530
Subject: [R] Issue wit Package installation and download.file()
Message-ID: <CANafO925yTZ6PD=RwaP0qj5aOrWr1hVsQSidV6w8mUux5Me4WA@mail.gmail.com>

Hello,

I have installed RStudio Version 0.98.1091, R version, R Version 3.1.2, on
my Windows 7 desktop (64 bit). I am using wifi without any proxy server.

Issues:-

1. I am unable to install the packages from CRAN mirror(India). I am
getting the below error:-

*Warning: unable to access index for repository
http://ftp.iitm.ac.in/cran/bin/windows/contrib/3.1
<http://ftp.iitm.ac.in/cran/bin/windows/contrib/3.1>*
*Warning: unable to access index for repository
http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1
<http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1>*
*Warning messages:*
*1: In open.connection(con, "r") :*
*  unable to connect to 'cran.r-project.org <http://cran.r-project.org>' on
port 80.*
*2: package ?devtools? is not available (for R version 3.1.2) *



2. I am unable to download file using method * download.file() *
I get the below error:-

trying URL '
https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'
Error in download.file(url, file) :
  cannot open URL '
https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'
In addition: Warning message:
In download.file(url, file) :
  InternetOpenUrl failed: 'The server name or address could not be resolved'


Action Taken:-
I have execute the following command in Rstudio:-

*Sys.setenv(http_proxy="")*

and I have created the .Reniron file in the home directory that contains
*Sys.setenv(http_proxy="")*


Issue is still the same.
Please help me!

Thanks,
Aakrity

	[[alternative HTML version deleted]]


From f.alimadadi at gmail.com  Sun Feb 22 12:02:35 2015
From: f.alimadadi at gmail.com (Fatemeh a)
Date: Sun, 22 Feb 2015 14:32:35 +0330
Subject: [R] Running command had status 1 in R
Message-ID: <CABzwCXOJPUYd9ouuvg+--J4Y5WUK8GprBhiu7hRSMHmxdPYWfg@mail.gmail.com>

Hi all,

I am running a software which is shinybased within R : it gives me this
error:

Warning: running command 'octave -qf octave/muxMultisliceCommunity.m'
had status 1

I was wondering if anyone could help me where the problem is and what is
the status 1 mean?

my system info : windows 8, octave 3.6.4, R 3.1.2

thank you in advance,
-- 
regards
F..A

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Feb 22 16:46:35 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 22 Feb 2015 15:46:35 +0000
Subject: [R] Running command had status 1 in R
References: <CABzwCXOJPUYd9ouuvg+--J4Y5WUK8GprBhiu7hRSMHmxdPYWfg@mail.gmail.com>
Message-ID: <loom.20150222T164004-657@post.gmane.org>

Fatemeh a <f.alimadadi <at> gmail.com> writes:

> 
> Hi all,
> 
> I am running a software which is shinybased within R : it gives me this
> error:
> 
> Warning: running command 'octave -qf octave/muxMultisliceCommunity.m'
> had status 1
> 
> I was wondering if anyone could help me where the problem is and what is
> the status 1 mean?
> 
> my system info : windows 8, octave 3.6.4, R 3.1.2
> 
> thank you in advance,

  Sure sounds like you're having problems running octave,
presumably via a system() call from within R.
Without more detail, it's impossible to do more than guess.
Is octave in your path?


From dcarlson at tamu.edu  Sun Feb 22 16:49:32 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 22 Feb 2015 15:49:32 +0000
Subject: [R] Correlation question
In-Reply-To: <2DAAE620-96D5-4E50-BCEB-DC8B0072E520@ilstu.edu>
References: <CB58C863-EB51-4F0E-96A6-95D0B27637D3@ilstu.edu>
	<33D76D77E9AC4B438DA38B348ED6890D143D1464@EMAIL.ktkdom.pte.hu>
	<2DAAE620-96D5-4E50-BCEB-DC8B0072E520@ilstu.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D654FA5@mb02.ads.tamu.edu>

As Kehl pointed out, any linear function of the independent variable (speed) will have the same squared correlation with the dependent variable (dist), but only one linear function minimizes the squared deviations between the fitted values and the original values. The equation you are using is only applicable to that function, not to any of the others. In fact, some linear functions will produce negative values:

> fitted.new <- 6*cars$speed
> cor(cbind(fitted.new, fitted.right, fitted.wrong, cars$dist))
             fitted.new fitted.right fitted.wrong          
fitted.new    1.0000000    1.0000000    1.0000000 0.8068949
fitted.right  1.0000000    1.0000000    1.0000000 0.8068949
fitted.wrong  1.0000000    1.0000000    1.0000000 0.8068949
              0.8068949    0.8068949    0.8068949 1.0000000
> 1-sum((cars$dist-fitted.new)^2)/sum((cars$dist-mean(cars$dist))^2)
[1] -3.281849

David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jonathan Thayn
Sent: Sunday, February 22, 2015 12:01 AM
To: Kehl D?niel
Cc: r-help at r-project.org
Subject: Re: [R] Correlation question

Of course! Thank you, I knew I was missing something painfully obvious. Its seems, then, that this line

1-sum((cars$dist-fitted.wrong)^2)/sum((cars$dist-mean(cars$dist))^2)

is finding something other than the traditional correlation. I found this in a lecture introducing correlation, but , now, I'm not sure what it is. It does do a better job of showing that the fitted.wrong variable is not a good prediction of the distance. 



On Feb 21, 2015, at 4:36 PM, Kehl D?niel wrote:

> Hi,
> 
> try
> 
> cor(fitted.right,fitted.wrong)
> 
> should give 1 as both are a linear function of speed! Hence cor(cars$dist,fitted.right)^2 and cor(x=cars$dist,y=fitted.wrong)^2 must be the same.
> 
> HTH
> d
> ________________________________________
> Felad?: R-help [r-help-bounces at r-project.org] ; meghatalmaz&#243;: Jonathan Thayn [jthayn at ilstu.edu]
> K?ldve: 2015. febru?r 21. 22:42
> To: r-help at r-project.org
> T?rgy: [R] Correlation question
> 
> I recently compared two different approaches to calculating the correlation of two variables, and I cannot explain the different results:
> 
> data(cars)
> model <- lm(dist~speed,data=cars)
> coef(model)
> fitted.right <- model$fitted
> fitted.wrong <- -17+5*cars$speed
> 
> 
> When using the OLS fitted values, the lines below all return the same R2 value:
> 
> 1-sum((cars$dist-fitted.right)^2)/sum((cars$dist-mean(cars$dist))^2)
> cor(cars$dist,fitted.right)^2
> (sum((cars$dist-mean(cars$dist))*(fitted.right-mean(fitted.right)))/(49*sd(cars$dist)*sd(fitted.right)))^2
> 
> 
> However, when I use my estimated parameters to find the fitted values, "fitted.wrong", the first equation returns a much lower R2 value, which I would expect since the fit is worse, but the other lines return the same R2 that I get when using the OLS fitted values.
> 
> 1-sum((cars$dist-fitted.wrong)^2)/sum((cars$dist-mean(cars$dist))^2)
> cor(x=cars$dist,y=fitted.wrong)^2
> (sum((cars$dist-mean(cars$dist))*(fitted.wrong-mean(fitted.wrong)))/(49*sd(cars$dist)*sd(fitted.wrong)))^2
> 
> 
> I'm sure I'm missing something simple, but can someone explain the difference between these two methods of finding R2? Thanks.
> 
> Jon
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From avinashbarnwal123 at gmail.com  Sun Feb 22 18:07:26 2015
From: avinashbarnwal123 at gmail.com (avinash barnwal)
Date: Sun, 22 Feb 2015 22:37:26 +0530
Subject: [R] RMySQL Installation Error
Message-ID: <CAP42OZ22gV9PFjA334W5kb-Ene_UxZCer3r1H5vqorZ_OFbGAg@mail.gmail.com>

Hi List,

I am trying to install RMySQL on Windows 7(64 Bit) with R Version 2.15.1 on
RStudio. I have also followed the steps mentioned on the different web
sources and finally drilled down to following steps:

   1. *Installed  MySQL to "C:\Program Files (x86)\MySQL\MySQL Server 5.6?*
   2. *  Added  "MYSQL_HOME" with a value of "C:/Program Files
   (x86)/MySQL/MySQL Server 5.6/"*
   3. *Created the directory "opt" within "C:\Program Files
   (x86)\MySQL\MySQL Server 5.6\lib" and copy-paste "C:\Program Files
   (x86)\MySQL\MySQL Server 5.6\lib\libmysql.lib" to "C:\Program Files
   (x86)\MySQL\MySQL Server 5.6\lib\opt\" and*
   4. *Copy-paste "C:\Program Files\MySQL\MySQL Server
   5.5\lib\libmysql.dll" to "C:\Program Files\R\R-2.15.1\bin\i386\".*

*B   But i am getting following error while executing
install.packages('RMySQL',type='source') command in RStudio.*
      ** preparing package for lazy loading

Error in setClass("MySQLDriver", contains = "DBIDriver", slots = list(Id =
"integer")) :

  unused argument(s) (slots = list(Id = "integer"))

Error : unable to load R code in package 'RMySQL'

ERROR: lazy loading failed for package 'RMySQL'

* removing 'C:/Users/barney/Documents/R/win-library/2.15/RMySQL'

Warning in install.packages :

  running command 'C:/PROGRA~1/R/R-215~1.1/bin/x64/R CMD INSTALL -l
"C:/Users/barney/Documents/R/win-library/2.15"
C:\Users\barney\AppData\Local\Temp\RtmpgJXVPT/downloaded_packages/RMySQL_0.10.1.tar.gz'
had status 1

Warning in install.packages :

  installation of package ?RMySQL? had non-zero exit status.


Request your help in solving the problem.

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Sun Feb 22 19:21:25 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 22 Feb 2015 18:21:25 +0000
Subject: [R] RMySQL Installation Error
In-Reply-To: <CAP42OZ22gV9PFjA334W5kb-Ene_UxZCer3r1H5vqorZ_OFbGAg@mail.gmail.com>
References: <CAP42OZ22gV9PFjA334W5kb-Ene_UxZCer3r1H5vqorZ_OFbGAg@mail.gmail.com>
Message-ID: <54EA1E25.6000108@stats.ox.ac.uk>

On 22/02/2015 17:07, avinash barnwal wrote:
> Hi List,
>
> I am trying to install RMySQL on Windows 7(64 Bit) with R Version 2.15.1 on
> RStudio. I have also followed the steps mentioned on the different web
> sources and finally drilled down to following steps:

Hmm, those are not the correct instructions for the version of RMySQL 
you used.  Undo them and follow the current instructions ....

>
>     1. *Installed  MySQL to "C:\Program Files (x86)\MySQL\MySQL Server 5.6?*
>     2. *  Added  "MYSQL_HOME" with a value of "C:/Program Files
>     (x86)/MySQL/MySQL Server 5.6/"*
>     3. *Created the directory "opt" within "C:\Program Files
>     (x86)\MySQL\MySQL Server 5.6\lib" and copy-paste "C:\Program Files
>     (x86)\MySQL\MySQL Server 5.6\lib\libmysql.lib" to "C:\Program Files
>     (x86)\MySQL\MySQL Server 5.6\lib\opt\" and*
>     4. *Copy-paste "C:\Program Files\MySQL\MySQL Server
>     5.5\lib\libmysql.dll" to "C:\Program Files\R\R-2.15.1\bin\i386\".*
>
> *B   But i am getting following error while executing
> install.packages('RMySQL',type='source') command in RStudio.*
>        ** preparing package for lazy loading
>
> Error in setClass("MySQLDriver", contains = "DBIDriver", slots = list(Id =
> "integer")) :
>
>    unused argument(s) (slots = list(Id = "integer"))
>
> Error : unable to load R code in package 'RMySQL'
>
> ERROR: lazy loading failed for package 'RMySQL'
>
> * removing 'C:/Users/barney/Documents/R/win-library/2.15/RMySQL'
>
> Warning in install.packages :
>
>    running command 'C:/PROGRA~1/R/R-215~1.1/bin/x64/R CMD INSTALL -l
> "C:/Users/barney/Documents/R/win-library/2.15"
> C:\Users\barney\AppData\Local\Temp\RtmpgJXVPT/downloaded_packages/RMySQL_0.10.1.tar.gz'
> had status 1
>
> Warning in install.packages :
>
>    installation of package ?RMySQL? had non-zero exit status.
>
>
> Request your help in solving the problem.


Follow the posting guide.  Your R is very old, and you were asked to 
update before posting.  Most likely that version of RMySQL requires a 
current version of R.

>
> 	[[alternative HTML version deleted]]

Do not do that, as the posting guide required of you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From xavier.chiriboga at unine.ch  Sun Feb 22 19:28:24 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Sun, 22 Feb 2015 18:28:24 +0000
Subject: [R] HELP asin transformation
Message-ID: <7B64C8E017B948419F014C915AA6D7342A03AA9C@mail-mbx-03.UNINE.CH>

Dear all,



I attempted to transform my data using "asin" but a WARNING message appears:



dat1$Abu.tr<-asin(sqrt(dat1$Abundance/100))
Warning message:
In asin(sqrt(dat1$Abundance/100)) : NaNs produced



What does it mean? Is it a problem? How can I solve this?



Thank you!



XAVIER


From jdnewmil at dcn.davis.CA.us  Sun Feb 22 19:41:19 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 22 Feb 2015 10:41:19 -0800
Subject: [R] Issue wit Package installation and download.file()
In-Reply-To: <CANafO925yTZ6PD=RwaP0qj5aOrWr1hVsQSidV6w8mUux5Me4WA@mail.gmail.com>
References: <CANafO925yTZ6PD=RwaP0qj5aOrWr1hVsQSidV6w8mUux5Me4WA@mail.gmail.com>
Message-ID: <B103C3A2-152B-46EC-A558-EB3464FA04C7@dcn.davis.CA.us>

This sounds like  you should read FAQ 2.19.

Next time you post, please read the Posting Guide first. In particular, please use plain text since your HTML-formatted email was messed up on the mailing list.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 22, 2015 12:36:16 AM PST, Aakrity Tibrewal <aakrity333tibrewal at gmail.com> wrote:
>Hello,
>
>I have installed RStudio Version 0.98.1091, R version, R Version 3.1.2,
>on
>my Windows 7 desktop (64 bit). I am using wifi without any proxy
>server.
>
>Issues:-
>
>1. I am unable to install the packages from CRAN mirror(India). I am
>getting the below error:-
>
>*Warning: unable to access index for repository
>http://ftp.iitm.ac.in/cran/bin/windows/contrib/3.1
><http://ftp.iitm.ac.in/cran/bin/windows/contrib/3.1>*
>*Warning: unable to access index for repository
>http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1
><http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1>*
>*Warning messages:*
>*1: In open.connection(con, "r") :*
>*  unable to connect to 'cran.r-project.org
><http://cran.r-project.org>' on
>port 80.*
>*2: package ?devtools? is not available (for R version 3.1.2) *
>
>
>
>2. I am unable to download file using method * download.file() *
>I get the below error:-
>
>trying URL '
>https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'
>Error in download.file(url, file) :
>  cannot open URL '
>https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'
>In addition: Warning message:
>In download.file(url, file) :
>InternetOpenUrl failed: 'The server name or address could not be
>resolved'
>
>
>Action Taken:-
>I have execute the following command in Rstudio:-
>
>*Sys.setenv(http_proxy="")*
>
>and I have created the .Reniron file in the home directory that
>contains
>*Sys.setenv(http_proxy="")*
>
>
>Issue is still the same.
>Please help me!
>
>Thanks,
>Aakrity
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Feb 22 19:43:32 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 22 Feb 2015 10:43:32 -0800
Subject: [R] HELP asin transformation
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A03AA9C@mail-mbx-03.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A03AA9C@mail-mbx-03.UNINE.CH>
Message-ID: <D7D4977B-5E2C-4533-A998-99650D3F67F9@dcn.davis.CA.us>

This is a math question, not an R question. You cannot give numbers to asin that are less than -1 or greater than 1 and get a defined answer.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 22, 2015 10:28:24 AM PST, CHIRIBOGA Xavier <xavier.chiriboga at unine.ch> wrote:
>Dear all,
>
>
>
>I attempted to transform my data using "asin" but a WARNING message
>appears:
>
>
>
>dat1$Abu.tr<-asin(sqrt(dat1$Abundance/100))
>Warning message:
>In asin(sqrt(dat1$Abundance/100)) : NaNs produced
>
>
>
>What does it mean? Is it a problem? How can I solve this?
>
>
>
>Thank you!
>
>
>
>XAVIER
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From avinashbarnwal123 at gmail.com  Sun Feb 22 20:04:35 2015
From: avinashbarnwal123 at gmail.com (avinash barnwal)
Date: Mon, 23 Feb 2015 00:34:35 +0530
Subject: [R] RMySQL Installation Error
In-Reply-To: <54EA1E25.6000108@stats.ox.ac.uk>
References: <CAP42OZ22gV9PFjA334W5kb-Ene_UxZCer3r1H5vqorZ_OFbGAg@mail.gmail.com>
	<54EA1E25.6000108@stats.ox.ac.uk>
Message-ID: <CAP42OZ1nL4DoK3nzUMdX4Q_WunqTBzY3T7L29y6aZ=aJkFJ96g@mail.gmail.com>

Dear Prof Brian,

Thank you for telling the solution and from next time i will follow the
posting guide.

On Sun, Feb 22, 2015 at 11:51 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk>
wrote:

> On 22/02/2015 17:07, avinash barnwal wrote:
>
>> Hi List,
>>
>> I am trying to install RMySQL on Windows 7(64 Bit) with R Version 2.15.1
>> on
>> RStudio. I have also followed the steps mentioned on the different web
>> sources and finally drilled down to following steps:
>>
>
> Hmm, those are not the correct instructions for the version of RMySQL you
> used.  Undo them and follow the current instructions ....
>
>
>>     1. *Installed  MySQL to "C:\Program Files (x86)\MySQL\MySQL Server
>> 5.6?*
>>     2. *  Added  "MYSQL_HOME" with a value of "C:/Program Files
>>     (x86)/MySQL/MySQL Server 5.6/"*
>>     3. *Created the directory "opt" within "C:\Program Files
>>     (x86)\MySQL\MySQL Server 5.6\lib" and copy-paste "C:\Program Files
>>     (x86)\MySQL\MySQL Server 5.6\lib\libmysql.lib" to "C:\Program Files
>>     (x86)\MySQL\MySQL Server 5.6\lib\opt\" and*
>>     4. *Copy-paste "C:\Program Files\MySQL\MySQL Server
>>     5.5\lib\libmysql.dll" to "C:\Program Files\R\R-2.15.1\bin\i386\".*
>>
>> *B   But i am getting following error while executing
>> install.packages('RMySQL',type='source') command in RStudio.*
>>        ** preparing package for lazy loading
>>
>> Error in setClass("MySQLDriver", contains = "DBIDriver", slots = list(Id =
>> "integer")) :
>>
>>    unused argument(s) (slots = list(Id = "integer"))
>>
>> Error : unable to load R code in package 'RMySQL'
>>
>> ERROR: lazy loading failed for package 'RMySQL'
>>
>> * removing 'C:/Users/barney/Documents/R/win-library/2.15/RMySQL'
>>
>> Warning in install.packages :
>>
>>    running command 'C:/PROGRA~1/R/R-215~1.1/bin/x64/R CMD INSTALL -l
>> "C:/Users/barney/Documents/R/win-library/2.15"
>> C:\Users\barney\AppData\Local\Temp\RtmpgJXVPT/downloaded_
>> packages/RMySQL_0.10.1.tar.gz'
>> had status 1
>>
>> Warning in install.packages :
>>
>>    installation of package ?RMySQL? had non-zero exit status.
>>
>>
>> Request your help in solving the problem.
>>
>
>
> Follow the posting guide.  Your R is very old, and you were asked to
> update before posting.  Most likely that version of RMySQL requires a
> current version of R.
>
>
>>         [[alternative HTML version deleted]]
>>
>
> Do not do that, as the posting guide required of you.
>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>



-- 
Avinash Barnwal, M.Sc.
Statistics and Informatics
Department of Mathematics
IIT Kharagpur

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Feb 22 21:08:02 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 22 Feb 2015 20:08:02 +0000
Subject: [R] HELP asin transformation
References: <7B64C8E017B948419F014C915AA6D7342A03AA9C@mail-mbx-03.UNINE.CH>
Message-ID: <loom.20150222T210710-132@post.gmane.org>

CHIRIBOGA Xavier <xavier.chiriboga <at> unine.ch> writes:

> 
> Dear all,
> 
> I attempted to transform my data using "asin" but a WARNING message appears:
> 
> dat1$Abu.tr<-asin(sqrt(dat1$Abundance/100))
> Warning message:
> In asin(sqrt(dat1$Abundance/100)) : NaNs produced
> 
> What does it mean? Is it a problem? How can I solve this?
> 
> Thank you!
> 
> XAVIER

  To follow up on this, try printing

dat1$Abundance[is.na(dat1$Abu.tr)]

to see which values are causing the problem.


From xavier.chiriboga at unine.ch  Sun Feb 22 21:23:41 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Sun, 22 Feb 2015 20:23:41 +0000
Subject: [R] groupedData FUNCTION
Message-ID: <7B64C8E017B948419F014C915AA6D7342A03AAEB@mail-mbx-03.UNINE.CH>

Dear colleagues,



I am trying to use the function "groupedData". However, I got this message:



results<-groupedData(Abundance~Timepoint|Repli,outer=~Soil,data=dat1)
Error: could not find function "groupedData"





I am puttin g all my willingness to learn R but this is really desesperating. One problem over another....



ThANK YOU!


From ruipbarradas at sapo.pt  Sun Feb 22 21:30:54 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 22 Feb 2015 20:30:54 +0000
Subject: [R] groupedData FUNCTION
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A03AAEB@mail-mbx-03.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A03AAEB@mail-mbx-03.UNINE.CH>
Message-ID: <54EA3C7E.3040807@sapo.pt>

Hello,

You are using a function in package nlme. You must first load the 
package in your R session with the following instruction.

library(nlme)

Hope this helps,

Rui Barradas

Em 22-02-2015 20:23, CHIRIBOGA Xavier escreveu:
> Dear colleagues,
>
>
>
> I am trying to use the function "groupedData". However, I got this message:
>
>
>
> results<-groupedData(Abundance~Timepoint|Repli,outer=~Soil,data=dat1)
> Error: could not find function "groupedData"
>
>
>
>
>
> I am puttin g all my willingness to learn R but this is really desesperating. One problem over another....
>
>
>
> ThANK YOU!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Sun Feb 22 22:41:03 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 22 Feb 2015 21:41:03 +0000
Subject: [R] Running command had status 1 in R
In-Reply-To: <loom.20150222T164004-657@post.gmane.org>
References: <CABzwCXOJPUYd9ouuvg+--J4Y5WUK8GprBhiu7hRSMHmxdPYWfg@mail.gmail.com>
	<loom.20150222T164004-657@post.gmane.org>
Message-ID: <54EA4CEF.40004@stats.ox.ac.uk>

On 22/02/2015 15:46, Ben Bolker wrote:
> Fatemeh a <f.alimadadi <at> gmail.com> writes:
>
>>
>> Hi all,
>>
>> I am running a software which is shinybased within R : it gives me this
>> error:
>>
>> Warning: running command 'octave -qf octave/muxMultisliceCommunity.m'
>> had status 1
>>
>> I was wondering if anyone could help me where the problem is and what is
>> the status 1 mean?
>>
>> my system info : windows 8, octave 3.6.4, R 3.1.2
>>
>> thank you in advance,
>
>    Sure sounds like you're having problems running octave,
> presumably via a system() call from within R.
> Without more detail, it's impossible to do more than guess.
> Is octave in your path?

 From the help file for system():

      If ?intern = FALSE?, the return value is an error code (?0? for
      success), given the invisible attribute (so needs to be printed
      explicitly).  If the command could not be run for any reason, the
      value is ?127?.

so not having the command in your path does not give status 1 ....

This is off-topic here: you need to consult the documentation of the 
command you run to see its error codes.  (On Linux 'man octave' does not 
say, although it would be expected to.)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From mmclean at stat.tamu.edu  Sun Feb 22 22:55:34 2015
From: mmclean at stat.tamu.edu (Mathew McLean)
Date: Sun, 22 Feb 2015 15:55:34 -0600
Subject: [R] glm.fit when family argument is not a "family" object
Message-ID: <CA+3KFoPCbFAZf3PgHhpt+HJa1ZSOEw+wP9MtAhEAG1Not9_SxQ@mail.gmail.com>

The documentation for glm/glm.fit indicates that the family argument "can
be a character string naming a family function, a family function or the
result of a call to a family function".

glm.fit(1, 1, family = "gaussian")

## Error: $ operator is invalid for atomic vectors

glm.fit(1, 1, family = gaussian)

?## Error: object of type 'closure' is not subsettable

glm.fit(1, 1, family = gaussian())  # works?, results omitted

sessionInfo()

## R version 3.1.2 Patched (2015-02-20 r67856)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 7 x64 (build 7601) Service Pack 1

## locale:
## [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252
## [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C

## [5] LC_TIME=English_United States.1252

## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base

## loaded via a namespace (and not attached):
## [1] tools_3.1.2


-- 
Mathew W. McLean
Research Assistant Professor
462 Blocker Building
Texas A&M University
www.stat.tamu.edu/~mmclean

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sun Feb 22 23:46:24 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 22 Feb 2015 14:46:24 -0800
Subject: [R] glm.fit when family argument is not a "family" object
In-Reply-To: <CA+3KFoPCbFAZf3PgHhpt+HJa1ZSOEw+wP9MtAhEAG1Not9_SxQ@mail.gmail.com>
References: <CA+3KFoPCbFAZf3PgHhpt+HJa1ZSOEw+wP9MtAhEAG1Not9_SxQ@mail.gmail.com>
Message-ID: <CACk-te348BzFwQEaG_pqTn01coLMr-JdkGTbsk-+ajdGngRpTw@mail.gmail.com>

...
But

glm(1~1, family = gaussian)  ## works. As does family = "gaussian"

(R 3.1.2 )

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Feb 22, 2015 at 1:55 PM, Mathew McLean <mmclean at stat.tamu.edu> wrote:
> The documentation for glm/glm.fit indicates that the family argument "can
> be a character string naming a family function, a family function or the
> result of a call to a family function".
>
> glm.fit(1, 1, family = "gaussian")
>
> ## Error: $ operator is invalid for atomic vectors
>
> glm.fit(1, 1, family = gaussian)
>
> ## Error: object of type 'closure' is not subsettable
>
> glm.fit(1, 1, family = gaussian())  # works, results omitted
>
> sessionInfo()
>
> ## R version 3.1.2 Patched (2015-02-20 r67856)
> ## Platform: x86_64-w64-mingw32/x64 (64-bit)
> ## Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> ## locale:
> ## [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
> ## [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>
> ## [5] LC_TIME=English_United States.1252
>
> ## attached base packages:
> ## [1] stats     graphics  grDevices utils     datasets  methods   base
>
> ## loaded via a namespace (and not attached):
> ## [1] tools_3.1.2
>
>
> --
> Mathew W. McLean
> Research Assistant Professor
> 462 Blocker Building
> Texas A&M University
> www.stat.tamu.edu/~mmclean
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Feb 23 00:11:53 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 22 Feb 2015 15:11:53 -0800
Subject: [R] glm.fit when family argument is not a "family" object
In-Reply-To: <CA+3KFoPCbFAZf3PgHhpt+HJa1ZSOEw+wP9MtAhEAG1Not9_SxQ@mail.gmail.com>
References: <CA+3KFoPCbFAZf3PgHhpt+HJa1ZSOEw+wP9MtAhEAG1Not9_SxQ@mail.gmail.com>
Message-ID: <47D56F42-47C8-4842-9721-3769D710E04A@comcast.net>


On Feb 22, 2015, at 1:55 PM, Mathew McLean wrote:

> The documentation for glm/glm.fit indicates that the family argument "can
> be a character string naming a family function, a family function or the
> result of a call to a family function".
> 
> glm.fit(1, 1, family = "gaussian")
> 
> ## Error: $ operator is invalid for atomic vectors
> 
> glm.fit(1, 1, family = gaussian)
> 
> ?## Error: object of type 'closure' is not subsettable
> 
> glm.fit(1, 1, family = gaussian())  # works?, results omitted

It's fairly easy to find near the top of code in `glm` which lines are responsible for doing the lookup for a family object and to see by comparison that such lookup efforts are not in `glm.fit` Users are advised that `glm.fit` is not generally called directly. I think it was expected that people who were doing so, should be able to figure the situation out rather quickly by looking at the code. You might also have noticed that the Usage parameters for glm and glm.fit are different.

-- 
David.
> 
> sessionInfo()
> 
> ## R version 3.1.2 Patched (2015-02-20 r67856)
> ## Platform: x86_64-w64-mingw32/x64 (64-bit)
> ## Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> ## locale:
> ## [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
> ## [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> 
> ## [5] LC_TIME=English_United States.1252
> 
> ## attached base packages:
> ## [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> ## loaded via a namespace (and not attached):
> ## [1] tools_3.1.2
> 
> 
> -- 
> Mathew W. McLean
> Research Assistant Professor
> 


David Winsemius
Alameda, CA, USA


From c.shultz at live.com  Mon Feb 23 00:17:16 2015
From: c.shultz at live.com (Christopher Shultz)
Date: Sun, 22 Feb 2015 18:17:16 -0500
Subject: [R] Simultaneous Probit-Tobit
Message-ID: <SNT147-W83F53A1EBAD04BEA1258F3E2280@phx.gbl>

Hi: 


            

I am trying to write code to run a simultaneous probit-tobit 
model (Chappell, 1982) in order to quantify the determinants of 
legislator voting behavior. I can't seem to find any background on this.
 I have worked with code for simple logit and probit models, but this is
 a different beast. 

The logic is that this model reduces some of the endogeneity 
associated with a single equation model. As a general overview of the 
structure: http://uploadpie.com/yB5mw


Does anyone know if there is a package or simple way to code this? Thanks in advance! 


     		 	   		  
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Mon Feb 23 00:57:30 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 22 Feb 2015 15:57:30 -0800
Subject: [R] glm.fit when family argument is not a "family" object
In-Reply-To: <47D56F42-47C8-4842-9721-3769D710E04A@comcast.net>
References: <CA+3KFoPCbFAZf3PgHhpt+HJa1ZSOEw+wP9MtAhEAG1Not9_SxQ@mail.gmail.com>
	<47D56F42-47C8-4842-9721-3769D710E04A@comcast.net>
Message-ID: <CACk-te0Jg0KvgHLakC4R_je2zfMZvhpWg9kUN+o8_tQrPSwd5A@mail.gmail.com>

Exactly. Just a matter of fixing the glm.fit Help page.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Feb 22, 2015 at 3:11 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Feb 22, 2015, at 1:55 PM, Mathew McLean wrote:
>
>> The documentation for glm/glm.fit indicates that the family argument "can
>> be a character string naming a family function, a family function or the
>> result of a call to a family function".
>>
>> glm.fit(1, 1, family = "gaussian")
>>
>> ## Error: $ operator is invalid for atomic vectors
>>
>> glm.fit(1, 1, family = gaussian)
>>
>> ## Error: object of type 'closure' is not subsettable
>>
>> glm.fit(1, 1, family = gaussian())  # works, results omitted
>
> It's fairly easy to find near the top of code in `glm` which lines are responsible for doing the lookup for a family object and to see by comparison that such lookup efforts are not in `glm.fit` Users are advised that `glm.fit` is not generally called directly. I think it was expected that people who were doing so, should be able to figure the situation out rather quickly by looking at the code. You might also have noticed that the Usage parameters for glm and glm.fit are different.
>
> --
> David.
>>
>> sessionInfo()
>>
>> ## R version 3.1.2 Patched (2015-02-20 r67856)
>> ## Platform: x86_64-w64-mingw32/x64 (64-bit)
>> ## Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>> ## locale:
>> ## [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252
>> ## [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>
>> ## [5] LC_TIME=English_United States.1252
>>
>> ## attached base packages:
>> ## [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> ## loaded via a namespace (and not attached):
>> ## [1] tools_3.1.2
>>
>>
>> --
>> Mathew W. McLean
>> Research Assistant Professor
>>
>
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Feb 23 01:04:34 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 22 Feb 2015 16:04:34 -0800
Subject: [R] Simultaneous Probit-Tobit
In-Reply-To: <SNT147-W83F53A1EBAD04BEA1258F3E2280@phx.gbl>
References: <SNT147-W83F53A1EBAD04BEA1258F3E2280@phx.gbl>
Message-ID: <E9B16BD8-BCB9-4E78-8939-20080A263900@comcast.net>


On Feb 22, 2015, at 3:17 PM, Christopher Shultz wrote:

> Hi: 
> 
> 
> 
> 
> I am trying to write code to run a simultaneous probit-tobit 
> model (Chappell, 1982) in order to quantify the determinants of 
> legislator voting behavior. I can't seem to find any background on this.
> I have worked with code for simple logit and probit models, but this is
> a different beast. 
> 
> The logic is that this model reduces some of the endogeneity 
> associated with a single equation model. As a general overview of the 
> structure: http://uploadpie.com/yB5mw

I'm pretty much clueless about "endogeneity", but I do know that Therneau uses this as an example in survival::survreg:

# Economists fit a model called `tobit regression', which is a standard
# linear regression with Gaussian errors, and left censored data.
tobinfit <- survreg(Surv(durable, durable>0, type='left') ~ age + quant,
	            data=tobin, dist='gaussian')

> Does anyone know if there is a package or simple way to code this? Thanks in advance! 

When I ask (or am asked) the question: is there code to do X? .... I reach for the sos-package:

install.packages('sos')
library(sos)
findFn("tobit")  # 98 links
findFn("tobit probit")
found 43 matches;  retrieving 3 pages
2 3 
Downloaded 25 links in 11 packages.

>    		 	   		  
> 	[[alternative HTML version deleted]]
> 
Please read the posting guide.

-- 

David Winsemius
Alameda, CA, USA


From daisy.duursma at gmail.com  Mon Feb 23 03:54:32 2015
From: daisy.duursma at gmail.com (Daisy Englert Duursma)
Date: Mon, 23 Feb 2015 13:54:32 +1100
Subject: [R] double if else
Message-ID: <CAFf2dDE4kw0R8WtRnbjv7k9edUdpdMqJ7pgr_Ui0ZOMJZhu8EQ@mail.gmail.com>

Hello,
I need to make a double clause in an if else/ next statement. I wrote a
single one fine but I could not make it work for two statements statements.

Please see the following example:


#Goals
  #1)if size of area is greater than 15000 test that there are a minimum of
nrow() = 30,
    #write those with at least 30 values to list
  #2) if less than 15000, write those with >= 5 rows

# in the following example I should have a list where one has a value of 10
and the other 20.


areaKM <- 7500 #test for 7500 and 30000, at 30000 should have empty list
dat<-data.frame(x=1:30,y=31:60,cellvalue=c(5,6,7,rep(10,10),rep(20,17)))#fake
data
cells<-unique(as.numeric(dat$cellvalue))#find unique cellvalues
pres100km <- list() #empty list

#make loop to find dat$cellsvalue with at least 30 rows or if areaKM is
less than15000  keep cellvalues for those with more than 5 rows.
for (ii in 1:length(cells)){
  subdat<-subset(dat,cellvalue ==cells[ii])
  if (areaKM >- 15000) {
    if (nrow(subdat) < 30) {
      next
    } else {
      pres100km[[ii]]<-cells[ii] #100kmcells >= 30% coverage of 10kmcells
    }
  } else {
    if (nrow(subddat) < 5) {
      next
    } else {
      pres100km[[ii]]<-cells[ii] #100kmcells >= 50% coverage of 10kmcells
    }
  }
}







-- 
Daisy Englert Duursma
Department of Biological Sciences
Room W19F 135
Macquarie University, North Ryde, NSW 2109
Australia

Tel +61 2 9850 1302

	[[alternative HTML version deleted]]


From daisy.duursma at gmail.com  Mon Feb 23 04:35:01 2015
From: daisy.duursma at gmail.com (Daisy Englert Duursma)
Date: Mon, 23 Feb 2015 14:35:01 +1100
Subject: [R] double if else
In-Reply-To: <CAFf2dDE4kw0R8WtRnbjv7k9edUdpdMqJ7pgr_Ui0ZOMJZhu8EQ@mail.gmail.com>
References: <CAFf2dDE4kw0R8WtRnbjv7k9edUdpdMqJ7pgr_Ui0ZOMJZhu8EQ@mail.gmail.com>
Message-ID: <CAFf2dDEZu6DcZ7Y5ia_Nu+bxrTQt+oBdefCSK0c2A+VgB=WSyA@mail.gmail.com>

The corrected version is below. I found an error.


areaKM<-7500 #test for 7500 and 30000

dat<-data.frame(x=1:30,y=31:60,cellvalue=c(5,6,7,rep(10,10),rep(20,17)))#fake
data
cells<-unique(as.numeric(dat$cellvalue))#find unique cellvalues
pres100km <- list() #empty list

for (ii in 1:length(cells)){ #make loop to find 100km cells with at least
30% of 10km cells being within the alpha hull,
  #or if area of alpha hull less that 15000km2 keep all 100km2 cells where
points fall
  subdat<-subset(dat,cellvalue ==cells[ii])
  if (areaKM >= 15000) {
    if (nrow(subdat) < 30) {
      next
    } else {
      pres100km[[ii]]<-cells[ii] #100kmcells >= 30% coverage of 10kmcells
    }
  } else {
    if(nrow(subdat) < 5) {
      next
    } else {
      pres100km[[ii]]<-cells[ii] #more than 5 obs
    }
  }
}



On Mon, Feb 23, 2015 at 1:54 PM, Daisy Englert Duursma <
daisy.duursma at gmail.com> wrote:

> Hello,
> I need to make a double clause in an if else/ next statement. I wrote a
> single one fine but I could not make it work for two statements statements.
>
> Please see the following example:
>
>
> #Goals
>   #1)if size of area is greater than 15000 test that there are a minimum
> of nrow() = 30,
>     #write those with at least 30 values to list
>   #2) if less than 15000, write those with >= 5 rows
>
> # in the following example I should have a list where one has a value of
> 10 and the other 20.
>
>
> areaKM <- 7500 #test for 7500 and 30000, at 30000 should have empty list
> dat<-data.frame(x=1:30,y=31:60,cellvalue=c(5,6,7,rep(10,10),rep(20,17)))#fake
> data
> cells<-unique(as.numeric(dat$cellvalue))#find unique cellvalues
> pres100km <- list() #empty list
>
> #make loop to find dat$cellsvalue with at least 30 rows or if areaKM is
> less than15000  keep cellvalues for those with more than 5 rows.
> for (ii in 1:length(cells)){
>   subdat<-subset(dat,cellvalue ==cells[ii])
>   if (areaKM >- 15000) {
>     if (nrow(subdat) < 30) {
>       next
>     } else {
>       pres100km[[ii]]<-cells[ii] #100kmcells >= 30% coverage of 10kmcells
>     }
>   } else {
>     if (nrow(subddat) < 5) {
>       next
>     } else {
>       pres100km[[ii]]<-cells[ii] #100kmcells >= 50% coverage of 10kmcells
>     }
>   }
> }
>
>
>
>
>
>
>
> --
> Daisy Englert Duursma
> Department of Biological Sciences
> Room W19F 135
> Macquarie University, North Ryde, NSW 2109
> Australia
>
> Tel +61 2 9850 1302
>
>
>


-- 
Daisy Englert Duursma
Department of Biological Sciences
Room W19F 135
Macquarie University, North Ryde, NSW 2109
Australia

Tel +61 2 9850 1302

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Feb 23 08:56:17 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 23 Feb 2015 08:56:17 +0100
Subject: [R] double if else
In-Reply-To: <CAFf2dDEZu6DcZ7Y5ia_Nu+bxrTQt+oBdefCSK0c2A+VgB=WSyA@mail.gmail.com>
References: <CAFf2dDE4kw0R8WtRnbjv7k9edUdpdMqJ7pgr_Ui0ZOMJZhu8EQ@mail.gmail.com>
	<CAFf2dDEZu6DcZ7Y5ia_Nu+bxrTQt+oBdefCSK0c2A+VgB=WSyA@mail.gmail.com>
Message-ID: <CAJuCY5ya1KQ53WCTK2ggTnpDFFuz7K13VfmmXvPNBDoMRKJ0Kw@mail.gmail.com>

Dear Daisy,

You are making things too complicated. There is no need for a loop and a
nested if structure.

areaKM <- 7500
dat <- data.frame(
  x = 1:30,
  y = 31:60,
  cellvalue = c(5, 6 , 7, rep(10, 10), rep(20, 17))
)#fake

if(areaKM > 15000){
  treshold <- 30
} else {
  treshold <- 5
}

n.cells <- table(dat$cellvalue)
names(n.cells)[n.cells >= treshold]

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-02-23 4:35 GMT+01:00 Daisy Englert Duursma <daisy.duursma at gmail.com>:

> The corrected version is below. I found an error.
>
>
> areaKM<-7500 #test for 7500 and 30000
>
>
> dat<-data.frame(x=1:30,y=31:60,cellvalue=c(5,6,7,rep(10,10),rep(20,17)))#fake
> data
> cells<-unique(as.numeric(dat$cellvalue))#find unique cellvalues
> pres100km <- list() #empty list
>
> for (ii in 1:length(cells)){ #make loop to find 100km cells with at least
> 30% of 10km cells being within the alpha hull,
>   #or if area of alpha hull less that 15000km2 keep all 100km2 cells where
> points fall
>   subdat<-subset(dat,cellvalue ==cells[ii])
>   if (areaKM >= 15000) {
>     if (nrow(subdat) < 30) {
>       next
>     } else {
>       pres100km[[ii]]<-cells[ii] #100kmcells >= 30% coverage of 10kmcells
>     }
>   } else {
>     if(nrow(subdat) < 5) {
>       next
>     } else {
>       pres100km[[ii]]<-cells[ii] #more than 5 obs
>     }
>   }
> }
>
>
>
> On Mon, Feb 23, 2015 at 1:54 PM, Daisy Englert Duursma <
> daisy.duursma at gmail.com> wrote:
>
> > Hello,
> > I need to make a double clause in an if else/ next statement. I wrote a
> > single one fine but I could not make it work for two statements
> statements.
> >
> > Please see the following example:
> >
> >
> > #Goals
> >   #1)if size of area is greater than 15000 test that there are a minimum
> > of nrow() = 30,
> >     #write those with at least 30 values to list
> >   #2) if less than 15000, write those with >= 5 rows
> >
> > # in the following example I should have a list where one has a value of
> > 10 and the other 20.
> >
> >
> > areaKM <- 7500 #test for 7500 and 30000, at 30000 should have empty list
> >
> dat<-data.frame(x=1:30,y=31:60,cellvalue=c(5,6,7,rep(10,10),rep(20,17)))#fake
> > data
> > cells<-unique(as.numeric(dat$cellvalue))#find unique cellvalues
> > pres100km <- list() #empty list
> >
> > #make loop to find dat$cellsvalue with at least 30 rows or if areaKM is
> > less than15000  keep cellvalues for those with more than 5 rows.
> > for (ii in 1:length(cells)){
> >   subdat<-subset(dat,cellvalue ==cells[ii])
> >   if (areaKM >- 15000) {
> >     if (nrow(subdat) < 30) {
> >       next
> >     } else {
> >       pres100km[[ii]]<-cells[ii] #100kmcells >= 30% coverage of 10kmcells
> >     }
> >   } else {
> >     if (nrow(subddat) < 5) {
> >       next
> >     } else {
> >       pres100km[[ii]]<-cells[ii] #100kmcells >= 50% coverage of 10kmcells
> >     }
> >   }
> > }
> >
> >
> >
> >
> >
> >
> >
> > --
> > Daisy Englert Duursma
> > Department of Biological Sciences
> > Room W19F 135
> > Macquarie University, North Ryde, NSW 2109
> > Australia
> >
> > Tel +61 2 9850 1302
> >
> >
> >
>
>
> --
> Daisy Englert Duursma
> Department of Biological Sciences
> Room W19F 135
> Macquarie University, North Ryde, NSW 2109
> Australia
>
> Tel +61 2 9850 1302
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Feb 23 11:17:31 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 23 Feb 2015 10:17:31 +0000
Subject: [R] irregular sequence of events
In-Reply-To: <CAM_vjunv+2W3y_U2aAevpdCR5hXu_voN8mBvkqSxEKKyXt6-VQ@mail.gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C20E2E@SRVEXCHMBX.precheza.cz>
	<CAM_vjunv+2W3y_U2aAevpdCR5hXu_voN8mBvkqSxEKKyXt6-VQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C210C7@SRVEXCHMBX.precheza.cz>

Thanks to all who responded.

I like Sarah's solution best, although it did provide only a clue. It just needed a little of tweak to finish with suitable solution. For the record I put here this tweak (it is not fully reproducible but I hope it is understandable and can help others too).

# make a plot
plot(prov$date, prov$fi>0)

# interactively identify starts and ends of some events
mimo <- identify(prov$datum, prov$fi>0)

# make x as a auxiliary variable
x <- 1:nrow(prov)

# factor of events
event <- cut(x, c(liche(mimo)-1, sude(mimo)))

# discard even events
levels(event)[levels(event)%in%sude(levels(event))]<-NA

Here I could change remaining levels to any sequence.

Functions sude and liche are for selecting even and odd values from vector.

> sude
function (x)
{
    indices <- seq(along = x)
    x[indices%%2 == 0]
}

> liche
function (x)
{
    indices <- seq(along = x)
    x[indices%%2 == 1]
}

Thanks again to all who helped me.

Best regards
Petr


> -----Original Message-----
> From: Sarah Goslee [mailto:sarah.goslee at gmail.com]
> Sent: Friday, February 20, 2015 3:42 PM
> To: PIKAL Petr
> Cc: r-help at r-project.org
> Subject: Re: [R] irregular sequence of events
>
> Hi,
>
> On Fri, Feb 20, 2015 at 9:27 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Dear all
> >
> > I know I am missing something obvious but after few hours of trials I
> ask for some help.
> >
> > I have some sequence of values (days)
> > x <- 1:30
> >
> > and an indication of event start and end day mimo<-c(5,10, 13,16,
> > 21,27)
>
>
> > cut(x, mimo)
>
>  [1] <NA>    <NA>    <NA>    <NA>    <NA>    (5,10]  (5,10]  (5,10]
> (5,10]
>
> [10] (5,10]  (10,13] (10,13] (10,13] (13,16] (13,16] (13,16] (16,21]
> (16,21]
>
> [19] (16,21] (16,21] (16,21] (21,27] (21,27] (21,27] (21,27] (21,27]
> (21,27]
>
> [28] <NA>    <NA>    <NA>
>
> Levels: (5,10] (10,13] (13,16] (16,21] (21,27]
>
>
> should get you started. You'll need to tweak the arguments to get
> exactly what you want,
>
>
> > or
> >
> > events <- structure(list(start = c(5, 13, 21), end = c(10, 16, 27)),
> > .Names = c("start", "end"), row.names = c(NA, -3L), class =
> > "data.frame")
> >
> > I need to get a factor indicating event
> >
> > event <- c(rep(NA, 4), rep("A1", 6), rep(NA, 2), rep("A2", 4),
> rep(NA,
> > 4), rep("A3", 7), rep(NA,3))
> > factor(event)
> >
> > In such small example I can do it manually but I have a long vector
> of dates and would like to use start and end day of events either from
> mimo vector or from events data frame.
> >
> > Is there any function which does it automagically? I know I have seen
> it before but I cannot find it now.
> >
> > Best regards
> > Petr
> >
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From gchappi at gmail.com  Mon Feb 23 11:29:30 2015
From: gchappi at gmail.com (Hans-Peter Suter)
Date: Mon, 23 Feb 2015 11:29:30 +0100
Subject: [R] [offtopic] nice R related domains to give away
Message-ID: <CANJoV3MMmxWDWDPZsFOOfsv9FhpPaRzC0CQms9BEzz01Lo=q4g@mail.gmail.com>

Since some years I have the following domains which I don't need any longer
(and in fact never used despite some plans)

  - developr.org
  - editr.org
  - helpr.org

It makes no sense to hoard domains and I plan to give them away for a 'good
cause'. I'd like to have a small fee for the costs but this is not a
precondition. My email: gchappi, and then gmail.com.

Cheers, Hans-Peter

	[[alternative HTML version deleted]]


From Jose.Iparraguirre at ageuk.org.uk  Mon Feb 23 12:44:01 2015
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Mon, 23 Feb 2015 11:44:01 +0000
Subject: [R] colours in ggplot2
In-Reply-To: <CAPmpGDujAcqR8eOnGBTKTNbp-3LV2-0Rv3Qc6nXdDW_Px5w9bw@mail.gmail.com>
References: <CAPmpGDujAcqR8eOnGBTKTNbp-3LV2-0Rv3Qc6nXdDW_Px5w9bw@mail.gmail.com>
Message-ID: <5F8EC5C77B9AE547A8959F690F04C7B243FE5737@AGEPXMB006.uk.age.local>

Dear Antonello,

How about this? Obviously, you can change the background colours for the confidence levels (deprespal) and for the regression lines, etc.
Surely, many in the list can improve on my rough and ready solution.

deprespal=c("#CCCCCC","#999999")
p2 <- ggplot(data = df, aes(x =Levels_Depression, y = Social_impairment, group = as.factor(Past_Admissions),fill = as.factor(Past_Admissions) )) +
    geom_point(aes(size = Age)) + geom_smooth(method = "lm", col="black") + xlab("Levels of depression") + ylab("Social impairment") +
    scale_fill_manual(values=deprespal) +
    scale_colour_discrete("History of \npast admissions\nto a psychiatric service", labels = c("No", "Yes"))
p2

Regards,

Jos?

Prof. Jos? Iparraguirre
Chief Economist
Age UK

Age UK
Tavis House, 1- 6 Tavistock Square
London, WC1H 9NB


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Antonello Preti
Sent: 20 February 2015 12:54
To: r-help at r-project.org
Subject: [R] colours in ggplot2

Hi, I'm using ggplot2 to make a plot of the regression of a variable x (let say, levels of depression), on a variable y (let say, degree of social impairment), by taking into account a binary factor (having had or not a past admission to a psychiatric service), and age of partecipants.

After some search in Internet I produced a code which is satisfying to me.
This site was very helpful: http://editerna.free.fr/wp/?p=266

However, I have a problem: no matter what I try, the figures always include bluette and pink flamingo colours.
The figure is for an academic article, and I cannot afford the price of having the plot printed in colours.

I've extracted the structure of the figure, and I understand that the problem is in the scale_name "hue", but I cannot figure out how to deal with it.

Any way to override the ggplot2 system of dealing with factors?

Here the codes and the sessionInfo
The code is a bit baroque, but this is the best I was able to do.


Thank you in advance,
Antonello Preti



######## code for exemplification

### the dataset

df <- structure(list(Social_impairment = c(2.83, 3.08, 2.75, 2.08, 2.92, 1.75, 3.5, 2.33, 2.91, 2.5, 3.25, 2.64, 3.25, 2.83, 2.08, 2.25, 2.17, 2.42, 2.58, 2.42, 2.58, 2.42, 3, 3, 2.83, 2.67, 3.58, 1.58, 2.83, 2.83, 2.67, 3.17, 2.42, 1.92, 2.92, 2.5, 2.42, 2.42, 2.58, 2.42, 3.33, 3, 3.17, 2.17, 2.58, 2.67, 2.58, 3.75, 2.5, 2.08, 2.25, 3.25, 3.17, 2.91, 2.08, 2.25, 3.08, 2.91, 3.08, 2.92, 1.83, 2.5, 2.5, 2.83, 2.67, 3.33, 2.83, 3.33, 2.92, 3), Levels_Depression = c(1.3, 1.71, 3.08, 0.48, 0.51, 0.71, 1.37, 0.2, 1.21, 1.07, 2.8, 1.24, 0.46, 0.97, 0.81, 1.13, 1.58, 3.12, 1.8, 1.54, 1.02, 0.32, 2.63, 1.39, 1.34, 2.37, 2.6, 1.11, 1.59, 2.17, 1.99, 0.59, 0.76, 0.23, 2.22, 1.98, 0.41, 0.32, 0.37, 1.11, 2.29, 0.97, 1.61, 1.27, 1.22, 2.38, 1.28, 1.21, 0.93, 2.3, 0.8, 2.1, 2.86, 2.47, 2.34, 2.67, 0.31, 0.88, 1.84, 0.23, 2.41, 0.56, 2.03, 1.11, 0.12, 2.39, 0.34, 2.08, 1.01, 1.51), Age = c(66, 59, 49, 70, 42, 55, 28, 41, 69, 65, 40, 21, 18, 77, 28, 40, 47, 37, 47, 39, 32, 33, 42, 28, 59, 49, 29, 41, 22, 29, 53, 39, 55, 61, 30, 49, 43, 46, 18, 36, 34, 17, 42, 37, 37, 54, 48, 23, 71, 42, 52, 83, 19, 47, 23, 80, 43, 38, 47, 80, 36, 73, 74, 51, 76, 14, 65, 39, 17, 73), Past_Admissions = c(1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1)), .Names = c("Social_impairment", "Levels_Depression", "Age", "Past_Admissions"), row.names = c(NA, 70L), class = "data.frame")

dim(df)
head(df)
str(df)
summary(df)


### call the library

library(ggplot2)


#### the plot


#### Levels_Depression on Social_impairment by Past_Admissions (yes/no) #### linear model #### radius of the bubbles proportional to age


#### background elimination

p1 <- ggplot(data = df, aes(x =Levels_Depression, y = Social_impairment, group = as.factor(Past_Admissions), col = as.factor(Past_Admissions))) +
  geom_point(aes(size = Age)) + geom_smooth(method = "lm") + xlab("Levels of depression") + ylab("Social impairment") +
  scale_colour_discrete("History of \npast admissions\nto a psychiatric service", labels = c("No", "Yes"))

p1 + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
    panel.background = element_blank(), axis.line = element_line(colour =
"black"))


### change of then axes' ticks

p1 + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
    panel.background = element_blank(), axis.line = element_line(colour = "black"),
    axis.text = element_text(color = "black", size = 12, face = "italic"))


### after saving, dev.off()
###


#### Age on Social_impairment by Past_Admissions (yes/no) #### linear model #### radius of the bubbles proportional to Levels_Depression



#### background elimination

p2 <- ggplot(data = df, aes(x =Age , y = Social_impairment, group = as.factor(Past_Admissions), col = as.factor(Past_Admissions))) +
  geom_point(aes(size = Levels_Depression)) + geom_smooth(method = "lm")
+xlab("Age of participants") + ylab("Social impairment") +
  scale_colour_discrete("History of \npast admissions\nto a psychiatric service", labels = c("No", "Yes"))

p2 + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
    panel.background = element_blank(), axis.line = element_line(colour =
"black"))


### change of then axes' ticks

p2 + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
    panel.background = element_blank(), axis.line = element_line(colour = "black"),
    axis.text = element_text(color = "black", size = 12, face = "italic"))


### after saving, dev.off()
###


########################
#### paired plots
########################

library(gridExtra)

grid.arrange(p1, p2, ncol = 2)



########################
### sessionInfo()
########################

R version 3.0.2 (2013-09-25)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252 [3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C [5] LC_TIME=Italian_Italy.1252

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] gridExtra_0.9.1 ggplot2_0.9.3.1

loaded via a namespace (and not attached):
 [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.4
gtable_0.1.2
 [5] labeling_0.2       MASS_7.3-33        munsell_0.4.2
plyr_1.8
 [9] proto_0.3-10       RColorBrewer_1.0-5 reshape2_1.2.2
scales_0.2.3
[13] stringr_0.6.2

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Age UK Group

Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798) Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA. 

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited. Age UK Enterprises Limited is authorised and regulated by the Financial Conduct Authority.

Charitable Services are offered through Age UK (the Charity) and commercial products and services are offered by the Charity?s subsidiary companies. The Age UK Group comprises of Age UK, and its subsidiary companies and charities, dedicated to improving the lives of people in later life. Our network includes the three national charities Age Cymru, Age NI and Age Scotland and more than 160 local Age UK charities.

This email and any files transmitted with it are confide...{{dropped:11}}


From trichter at uni-bremen.de  Mon Feb 23 13:03:41 2015
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Mon, 23 Feb 2015 13:03:41 +0100
Subject: [R] Split a dataframe by rownames and/or colnames
In-Reply-To: <30B8B594-E1BC-44AF-8641-7D1049846CD8@comcast.net>
References: <54E76FEA.5070408@uni-bremen.de>
	<30B8B594-E1BC-44AF-8641-7D1049846CD8@comcast.net>
Message-ID: <54EB171D.7020909@uni-bremen.de>

Thank you very much for the line. It was doing the split as suggested.
However, i want to release all the dataframes to the environment (later 
on, for each dataframe, some dozen lines of code will be carried out, 
and i dont know how to do it w lapply or for-looping, so i do it 
separately):

list2env(split(df, sub(".+_","", rownames(df))), envir=.GlobalEnv)

Anyway, the dataframes have now numeric names in some cases, and cannot 
be easily accessed because of it.
How would the line be  altered to add an "df_" for each  of the 
dataframe names resulting from list2env?

Thank you very much!



Thanks, On 20.02.2015 20:36, David Winsemius wrote:
> On Feb 20, 2015, at 9:33 AM, Tim Richter-Heitmann wrote:
>
>> Dear List,
>>
>> Consider this example
>>
>> df <- data.frame(matrix(rnorm(9*9), ncol=9))
>> names(df) <- c("c_1", "d_1", "e_1", "a_p", "b_p", "c_p", "1_o1", "2_o1", "3_o1")
>> row.names(df) <- names(df)
>>
>>
>> indx <- gsub(".*_", "", names(df))
>>
>> I can split the dataframe by the index that is given in the column.names after the underscore "_".
>>
>> list2env(
>>   setNames(
>>     lapply(split(colnames(df), indx), function(x) df[x]),
>>     paste('df', sort(unique(indx)), sep="_")),
>>   envir=.GlobalEnv)
>>
>> However, i changed my mind and want to do it now by rownames. Exchanging colnames with rownames does not work, it gives the exact same output (9 rows x 3 columns). I could do
>> as.data.frame(t(df_x),
>> but maybe that is not elegant.
>> What would be the solution for splitting the dataframe by rows?
> The split.data.frame method seems to work perfectly well with a rownames-derived index argument:
>
>> split(df, sub(".+_","", rownames(df) ) )
> $`1`
>        c_1   d_1  e_1   a_p   b_p   c_p  1_o1 2_o1  3_o1
> c_1 -0.11 -0.04 1.33 -0.87 -0.16 -0.25 -0.75 0.34  0.14
> d_1 -0.62 -0.94 0.80 -0.78 -0.70  0.74  0.11 1.44 -0.33
> e_1  0.98 -0.83 0.48  0.19 -0.32 -1.01  1.28 1.04 -2.16
>
> $o1
>         c_1   d_1   e_1   a_p   b_p   c_p  1_o1  2_o1  3_o1
> 1_o1 -0.93 -0.02  0.69 -0.67  1.04  1.04 -1.50 -0.36  0.50
> 2_o1  0.02 -0.16 -0.09 -1.50 -0.02 -1.04  1.07 -0.45  1.56
> 3_o1 -1.42  0.88 -0.05  0.85 -1.35  0.21  1.35  0.92 -0.76
>
> $p
>        c_1   d_1   e_1   a_p  b_p   c_p  1_o1  2_o1  3_o1
> a_p -1.35  0.91 -0.58 -0.63 0.94 -1.13  0.71  0.25  0.82
> b_p -0.25 -0.73 -0.41 -1.71 1.28  0.19 -0.35  1.74 -0.93
> c_p -0.01 -1.11 -0.12  0.58 1.51  0.03 -0.99 -0.23 -0.03
>
>> Thank you very much!
>>
>> -- 
>> Tim Richter-Heitmann
>>


-- 
Tim Richter-Heitmann (M.Sc.)
PhD Candidate



International Max-Planck Research School for Marine Microbiology
University of Bremen
Microbial Ecophysiology Group (AG Friedrich)
FB02 - Biologie/Chemie
Leobener Stra?e (NW2 A2130)
D-28359 Bremen
Tel.: 0049(0)421 218-63062
Fax: 0049(0)421 218-63069


From sergio.fonda99 at gmail.com  Mon Feb 23 13:12:56 2015
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Mon, 23 Feb 2015 13:12:56 +0100
Subject: [R] Split a dataframe by rownames and/or colnames
In-Reply-To: <54EB171D.7020909@uni-bremen.de>
References: <54E76FEA.5070408@uni-bremen.de>
	<30B8B594-E1BC-44AF-8641-7D1049846CD8@comcast.net>
	<54EB171D.7020909@uni-bremen.de>
Message-ID: <CAJRuHopRAOMa=QTYULcJmjzqq6h7yDpYzAPd7C6JGODooQuTzQ@mail.gmail.com>

Did you try "dplyr" package?
Sergio
Il 23/feb/2015 13:05 "Tim Richter-Heitmann" <trichter at uni-bremen.de> ha
scritto:

> Thank you very much for the line. It was doing the split as suggested.
> However, i want to release all the dataframes to the environment (later
> on, for each dataframe, some dozen lines of code will be carried out, and i
> dont know how to do it w lapply or for-looping, so i do it separately):
>
> list2env(split(df, sub(".+_","", rownames(df))), envir=.GlobalEnv)
>
> Anyway, the dataframes have now numeric names in some cases, and cannot be
> easily accessed because of it.
> How would the line be  altered to add an "df_" for each  of the dataframe
> names resulting from list2env?
>
> Thank you very much!
>
>
>
> Thanks, On 20.02.2015 20:36, David Winsemius wrote:
>
>> On Feb 20, 2015, at 9:33 AM, Tim Richter-Heitmann wrote:
>>
>>  Dear List,
>>>
>>> Consider this example
>>>
>>> df <- data.frame(matrix(rnorm(9*9), ncol=9))
>>> names(df) <- c("c_1", "d_1", "e_1", "a_p", "b_p", "c_p", "1_o1", "2_o1",
>>> "3_o1")
>>> row.names(df) <- names(df)
>>>
>>>
>>> indx <- gsub(".*_", "", names(df))
>>>
>>> I can split the dataframe by the index that is given in the column.names
>>> after the underscore "_".
>>>
>>> list2env(
>>>   setNames(
>>>     lapply(split(colnames(df), indx), function(x) df[x]),
>>>     paste('df', sort(unique(indx)), sep="_")),
>>>   envir=.GlobalEnv)
>>>
>>> However, i changed my mind and want to do it now by rownames. Exchanging
>>> colnames with rownames does not work, it gives the exact same output (9
>>> rows x 3 columns). I could do
>>> as.data.frame(t(df_x),
>>> but maybe that is not elegant.
>>> What would be the solution for splitting the dataframe by rows?
>>>
>> The split.data.frame method seems to work perfectly well with a
>> rownames-derived index argument:
>>
>>  split(df, sub(".+_","", rownames(df) ) )
>>>
>> $`1`
>>        c_1   d_1  e_1   a_p   b_p   c_p  1_o1 2_o1  3_o1
>> c_1 -0.11 -0.04 1.33 -0.87 -0.16 -0.25 -0.75 0.34  0.14
>> d_1 -0.62 -0.94 0.80 -0.78 -0.70  0.74  0.11 1.44 -0.33
>> e_1  0.98 -0.83 0.48  0.19 -0.32 -1.01  1.28 1.04 -2.16
>>
>> $o1
>>         c_1   d_1   e_1   a_p   b_p   c_p  1_o1  2_o1  3_o1
>> 1_o1 -0.93 -0.02  0.69 -0.67  1.04  1.04 -1.50 -0.36  0.50
>> 2_o1  0.02 -0.16 -0.09 -1.50 -0.02 -1.04  1.07 -0.45  1.56
>> 3_o1 -1.42  0.88 -0.05  0.85 -1.35  0.21  1.35  0.92 -0.76
>>
>> $p
>>        c_1   d_1   e_1   a_p  b_p   c_p  1_o1  2_o1  3_o1
>> a_p -1.35  0.91 -0.58 -0.63 0.94 -1.13  0.71  0.25  0.82
>> b_p -0.25 -0.73 -0.41 -1.71 1.28  0.19 -0.35  1.74 -0.93
>> c_p -0.01 -1.11 -0.12  0.58 1.51  0.03 -0.99 -0.23 -0.03
>>
>>  Thank you very much!
>>>
>>> --
>>> Tim Richter-Heitmann
>>>
>>>
>
> --
> Tim Richter-Heitmann (M.Sc.)
> PhD Candidate
>
>
>
> International Max-Planck Research School for Marine Microbiology
> University of Bremen
> Microbial Ecophysiology Group (AG Friedrich)
> FB02 - Biologie/Chemie
> Leobener Stra?e (NW2 A2130)
> D-28359 Bremen
> Tel.: 0049(0)421 218-63062
> Fax: 0049(0)421 218-63069
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From minorthreatx at hotmail.com  Mon Feb 23 15:01:53 2015
From: minorthreatx at hotmail.com (Kim C.)
Date: Mon, 23 Feb 2015 15:01:53 +0100
Subject: [R] Save rules with asRules() from Rattle into dataframe
Message-ID: <DUB126-W6164C45BE54BB387450BBDDE290@phx.gbl>

Hello,?


I use asRules from the Rattle package to make rules of a rpart decision tree: asRules(rpart1). It gives a rule such as (don't mind the data, it's merely testdata):?


?Rule number: 18 [Product=153 cover=3 (1%) prob=0.00]
? ?TotalChildren>=4.5
? ?Education=Bachelors,Partial College,Partial High School
? ?Gender=F
? ?Occupation=Skilled Manual


Then I want to save it so I use: rules <-asRules(rpart1) but it saves it as an integer. When I view "rules" I only see one column of integers. Not the data like the example above. Preferably I would like to have that data in a dataframe.?

The reproducible example can be found here:?

www.mediafire.com/download/8qqzq3qqu2mlmb1/decision+tree+rules+example.RData

The rpart tree is made with this: rpart1 <- rpart(Product ~ ., data=subset5, method="class", control=rpart.control(minbucket=2,minsplit=1, cp=-1))

Hope someone can help me out. Thanks! 		 	   		  

From dialvac-r at yahoo.de  Mon Feb 23 15:06:08 2015
From: dialvac-r at yahoo.de (Alain D.)
Date: Mon, 23 Feb 2015 15:06:08 +0100 (CET)
Subject: [R] convert number back to point separated date
Message-ID: <1550708451.475115.1424700369069.JavaMail.open-xchange@ptangptang.store>

Dear R-List
 
I have a date column formatted dd.mm.yyyy separated by points that was converted
into a number using as.integer(date). Now I wish to convert the number back into
the original date. Something like:
 
date<-as.factor(c("07.12.2010","29.04.2013"))

dd<-as.integer(date)

as.Date(dd, origin="%d.%m.%Y")# does not work
 
Is there a way to convert "dd" back to "date"?
 
Thank you for help!
 
Best wishes
 
Alain
 
	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Feb 23 15:37:04 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 23 Feb 2015 15:37:04 +0100
Subject: [R] convert number back to point separated date
In-Reply-To: <1550708451.475115.1424700369069.JavaMail.open-xchange@ptangptang.store>
References: <1550708451.475115.1424700369069.JavaMail.open-xchange@ptangptang.store>
Message-ID: <AE10D8A9-7095-4774-8026-D2BB79728690@gmail.com>


On 23 Feb 2015, at 15:06 , Alain D. <dialvac-r at yahoo.de> wrote:

> Dear R-List
> 
> I have a date column formatted dd.mm.yyyy separated by points that was converted
> into a number using as.integer(date). Now I wish to convert the number back into
> the original date. Something like:
> 
> date<-as.factor(c("07.12.2010","29.04.2013"))
> 
> dd<-as.integer(date)
> 
> as.Date(dd, origin="%d.%m.%Y")# does not work
> 
> Is there a way to convert "dd" back to "date"?

> dd
[1] 1 2

So, not without referring to the value of `date`, at the very least its factor levels.

> as.Date(levels(date)[dd], format="%d.%m.%Y")
[1] "2010-12-07" "2013-04-29"

which is really not different from 

> as.Date(date, format="%d.%m.%Y")
[1] "2010-12-07" "2013-04-29"


> 
> Thank you for help!
> 
> Best wishes
> 
> Alain
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Mon Feb 23 17:56:54 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 23 Feb 2015 08:56:54 -0800
Subject: [R] Split a dataframe by rownames and/or colnames
In-Reply-To: <54EB171D.7020909@uni-bremen.de>
References: <54E76FEA.5070408@uni-bremen.de>
	<30B8B594-E1BC-44AF-8641-7D1049846CD8@comcast.net>
	<54EB171D.7020909@uni-bremen.de>
Message-ID: <2C8902E9-596D-438C-85E2-634D574820E9@comcast.net>


On Feb 23, 2015, at 4:03 AM, Tim Richter-Heitmann wrote:

> Thank you very much for the line. It was doing the split as suggested.
> However, i want to release all the dataframes to the environment (later on, for each dataframe, some dozen lines of code will be carried out, and i dont know how to do it w lapply or for-looping, so i do it separately):
> 
> list2env(split(df, sub(".+_","", rownames(df))), envir=.GlobalEnv)

Then just:

 list2env( setNames( split(df, sub(".+_","", rownames(df))),
                    make.names( rownames(df) ) )   
          , envir=.GlobalEnv)

-- 
David.
> 
> Anyway, the dataframes have now numeric names in some cases, and cannot be easily accessed because of it.
> How would the line be  altered to add an "df_" for each  of the dataframe names resulting from list2env?
> 
> Thank you very much!
> 
> 
> 
> Thanks, On 20.02.2015 20:36, David Winsemius wrote:
>> On Feb 20, 2015, at 9:33 AM, Tim Richter-Heitmann wrote:
>> 
>>> Dear List,
>>> 
>>> Consider this example
>>> 
>>> df <- data.frame(matrix(rnorm(9*9), ncol=9))
>>> names(df) <- c("c_1", "d_1", "e_1", "a_p", "b_p", "c_p", "1_o1", "2_o1", "3_o1")
>>> row.names(df) <- names(df)
>>> 
>>> 
>>> indx <- gsub(".*_", "", names(df))
>>> 
>>> I can split the dataframe by the index that is given in the column.names after the underscore "_".
>>> 
>>> list2env(
>>>  setNames(
>>>    lapply(split(colnames(df), indx), function(x) df[x]),
>>>    paste('df', sort(unique(indx)), sep="_")),
>>>  envir=.GlobalEnv)
>>> 
>>> However, i changed my mind and want to do it now by rownames. Exchanging colnames with rownames does not work, it gives the exact same output (9 rows x 3 columns). I could do
>>> as.data.frame(t(df_x),
>>> but maybe that is not elegant.
>>> What would be the solution for splitting the dataframe by rows?
>> The split.data.frame method seems to work perfectly well with a rownames-derived index argument:
>> 
>>> split(df, sub(".+_","", rownames(df) ) )
>> $`1`
>>       c_1   d_1  e_1   a_p   b_p   c_p  1_o1 2_o1  3_o1
>> c_1 -0.11 -0.04 1.33 -0.87 -0.16 -0.25 -0.75 0.34  0.14
>> d_1 -0.62 -0.94 0.80 -0.78 -0.70  0.74  0.11 1.44 -0.33
>> e_1  0.98 -0.83 0.48  0.19 -0.32 -1.01  1.28 1.04 -2.16
>> 
>> $o1
>>        c_1   d_1   e_1   a_p   b_p   c_p  1_o1  2_o1  3_o1
>> 1_o1 -0.93 -0.02  0.69 -0.67  1.04  1.04 -1.50 -0.36  0.50
>> 2_o1  0.02 -0.16 -0.09 -1.50 -0.02 -1.04  1.07 -0.45  1.56
>> 3_o1 -1.42  0.88 -0.05  0.85 -1.35  0.21  1.35  0.92 -0.76
>> 
>> $p
>>       c_1   d_1   e_1   a_p  b_p   c_p  1_o1  2_o1  3_o1
>> a_p -1.35  0.91 -0.58 -0.63 0.94 -1.13  0.71  0.25  0.82
>> b_p -0.25 -0.73 -0.41 -1.71 1.28  0.19 -0.35  1.74 -0.93
>> c_p -0.01 -1.11 -0.12  0.58 1.51  0.03 -0.99 -0.23 -0.03
>> 
>>> Thank you very much!
>>> 
>>> -- 
>>> Tim Richter-Heitmann
>>> 
> 
> 
> -- 
> Tim Richter-Heitmann (M.Sc.)
> PhD Candidate
> 
> 
> 
> International Max-Planck Research School for Marine Microbiology
> University of Bremen
> Microbial Ecophysiology Group (AG Friedrich)
> FB02 - Biologie/Chemie
> Leobener Stra?e (NW2 A2130)
> D-28359 Bremen
> Tel.: 0049(0)421 218-63062
> Fax: 0049(0)421 218-63069
> 

David Winsemius
Alameda, CA, USA


From amc5981 at gmail.com  Mon Feb 23 18:49:47 2015
From: amc5981 at gmail.com (Alexandra Catena)
Date: Mon, 23 Feb 2015 09:49:47 -0800
Subject: [R] Replacing 9999 and 999 values with NA
In-Reply-To: <CAGh51gTZNyH41E3FR5cBJVU=2SZZtuF6Jnu=qnTna7dCLegFzg@mail.gmail.com>
References: <CAHpsUFYz6iz3uy6TPiTMn1sbbKS3C6pFxxk1XJtNmk=bTJ_O4g@mail.gmail.com>
	<EE82066F-F9C7-417C-8DB0-F4580E7D90D0@dcn.davis.CA.us>
	<CAGh51gTZNyH41E3FR5cBJVU=2SZZtuF6Jnu=qnTna7dCLegFzg@mail.gmail.com>
Message-ID: <CAHpsUFakmWm+8ns899ij1-NwH1s6e6Z0n5pn5piXV3v+i1joQw@mail.gmail.com>

The command,  data[data ==9999] <- NA, worked! Thank you!

But just in case you wanted to know, I'm downloading the data and
unzipping it through readLines.  I then concatenate two columns ( wind
speed and direction) from the unzipped data through cbind but I make
it into a data frame.

wind = data.frame(cbind(windSpeed,windDirec))


Thanks,
Alexandra

On Sat, Feb 21, 2015 at 10:38 PM, Frederic Ntirenganya
<ntfredo at gmail.com> wrote:
> If you are reading the data frame using for instance read.csv, you can put
> in the argument na.string ="9999".
> Another way to do that is data[data ==9999] <- NA.
>
> It should be good to tell us how you are reading your dataset.
>
> On Feb 21, 2015 6:49 AM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> You did not say how you imported the data, but if you used one of the
>> read.table variants (including read.csv) then you can use the na.strings
>> argument as documented in the help file for read.table.
>>
>> Next time please read the posting guide, as there are some useful tips in
>> there, such as posting using plain text (a setting in your email program) so
>> we don't get garbled info from you, and providing a reproducible example.
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 20, 2015 10:55:30 AM PST, Alexandra Catena <amc5981 at gmail.com>
>> wrote:
>> >Hello All,
>> >
>> >I have a data frame of two columns for wind.  The first column is for
>> >wind
>> >speed and the second wind direction.  I'm trying to replace the 9999
>> >values
>> >in the first column and the 999 values in the second column with NA.  I
>> >tried to use the function ltdl.fix.df but it doesn't seem to do
>> >anything.
>> >
>> >> ltdl.fix.df(windMV, zero2na = FALSE, coded = 999)
>> >
>> >  n = 9432 by p = 4 matrix checked, 0 NA(s) present
>> >
>> >  0 factor variable(s) present
>> >
>> >  5675 value(s) coded 999 set to NA
>> >
>> >  0 -ve value(s) set to +ve half the negative value
>> >
>> >
>> >I have R version 3.1.1
>> >
>> >Thanks,
>> >Alexandra
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From JS.Huang at protective.com  Mon Feb 23 13:47:54 2015
From: JS.Huang at protective.com (Huang, JS)
Date: Mon, 23 Feb 2015 12:47:54 +0000
Subject: [R] How do I access a specific element of a multi-dimensional
 list
In-Reply-To: <CAF8bMcaOroqVsAwKzajM-XdYA8yofc_vsMGj0X74=oEB7OTe9w@mail.gmail.com>
References: <9715408.ITo0cTh8Yr@ws-ism-knuth.fm.uit.no>
	<CAAxdm-4rDNYCvys3DzrKeGROvL0DXJao_Oe6aiscER70+gkd=Q@mail.gmail.com>
	<1424469160485-4703622.post@n4.nabble.com>
	<CAF8bMcaOroqVsAwKzajM-XdYA8yofc_vsMGj0X74=oEB7OTe9w@mail.gmail.com>
Message-ID: <5A753D062E22614F99E148EDA0621F15CC033FBF@PBMSX04W.secure.protective.com>

Bill,

   Thank you for providing the neat and fast solution.

JS Huang
636.536.5635

From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: Saturday, February 21, 2015 12:16 AM
To: Huang, JS
Cc: r-help at r-project.org
Subject: Re: [R] How do I access a specific element of a multi-dimensional list

Using lapply() where Jim used sapply() would keep the types
right and be a fair bit faster than a solution based on repeatedly
appending to a list (like your getFirst).

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Fri, Feb 20, 2015 at 1:52 PM, JS Huang <js.huang at protective.com<mailto:js.huang at protective.com>> wrote:
Hi,

  Jim's answer is neat.  There is an issue on the result.  All are
characters even though some are numeric or logic.  The following
implementation retains the variable type.

> x
[[1]]
[1] 2 3 5

[[2]]
[1] "aa" "bb" "cc"

[[3]]
[1]  TRUE FALSE  TRUE

> getFirst
function(aList)
{
  result <- list()
  for (i in 1:length(aList))
  {
    result <- c(result, aList[[i]][1])
  }
  return(result)
}
> getFirst(x)
[[1]]
[1] 2

[[2]]
[1] "aa"

[[3]]
[1] TRUE

>



--
View this message in context: http://r.789695.n4.nabble.com/How-do-I-access-a-specific-element-of-a-multi-dimensional-list-tp4703596p4703622.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



Confidentiality Notice: This e-mail communication and any
attachments may contain confidential and privileged information for
the use of the designated recipients named above. If you are not
the intended recipient, you are hereby notified that you have
received this communication in error and that any review,
disclosure, dissemination, distribution or copying of it or its
contents is prohibited. If you have received this communication in
error, please notify me immediately by replying to this message and
deleting it from your computer. Thank you.
	[[alternative HTML version deleted]]


From sagnik.stats at gmail.com  Mon Feb 23 13:06:10 2015
From: sagnik.stats at gmail.com (sagnik chakravarty)
Date: Mon, 23 Feb 2015 17:36:10 +0530
Subject: [R] How to Deploy a 'poLCA' Model?
Message-ID: <CAMwbFxh_8mqdgcSeh8mXpCXV4PrUju0hUoqNWK2uj6L8Vind6w@mail.gmail.com>

Hi Drew,

I was working with 'poLCA' to fit latent-class model with covariates
[formula: f=cbind(y1,y2,y3) ~ x1*x2*x3*x4]. The output contains a fit table
with coefficients, t-value, std_error and P-value for different
combinations of the covariates.

Now if I want to deploy this model to a new dataset like we do for any
other model with 'predict' function, how to proceed?

I couldn't find any predict function described in the package
documentation. Kindly help.

Thanks,

-- 
Regards,

SAGNIK CHAKRAVARTY

	[[alternative HTML version deleted]]


From scolwell at uoguelph.ca  Mon Feb 23 19:15:13 2015
From: scolwell at uoguelph.ca (Scott Colwell)
Date: Mon, 23 Feb 2015 10:15:13 -0800 (PST)
Subject: [R] Extracting Factor Pattern Matrix Similar to Proc Factor
Message-ID: <1424715313110-4703704.post@n4.nabble.com>

Hello,

I am fairly new to R and coming from SAS IML. I am rewriting one of my MC
simulations in R and am stuck on extracting a factor pattern matrix as would
be done in IML using Proc Factor.  

I have found the princomp() command and read through the manual but can't
seem to figure out how to save the factor pattern matrix.  I am waiting for
the R for SAS Users book to arrive. What I would use in SAS IML to get at
what I am looking for is:

PROC FACTOR Data=MODELCOV15(TYPE=COV) NOBS=10000 N=16 CORR
OUTSTAT=FAC.FACOUT15;
RUN;

DATA FAC.PATTERN15; SET FAC.FACOUT15;
IF _TYPE_='PATTERN';
DROP _TYPE_ _NAME_;
RUN;

Would any SAS IML to R converts be able to help me with this?

Thanks,

Scott Colwell, PhD




--
View this message in context: http://r.789695.n4.nabble.com/Extracting-Factor-Pattern-Matrix-Similar-to-Proc-Factor-tp4703704.html
Sent from the R help mailing list archive at Nabble.com.


From sarah.goslee at gmail.com  Mon Feb 23 20:39:58 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 23 Feb 2015 14:39:58 -0500
Subject: [R] Replacing 9999 and 999 values with NA
In-Reply-To: <CAHpsUFakmWm+8ns899ij1-NwH1s6e6Z0n5pn5piXV3v+i1joQw@mail.gmail.com>
References: <CAHpsUFYz6iz3uy6TPiTMn1sbbKS3C6pFxxk1XJtNmk=bTJ_O4g@mail.gmail.com>
	<EE82066F-F9C7-417C-8DB0-F4580E7D90D0@dcn.davis.CA.us>
	<CAGh51gTZNyH41E3FR5cBJVU=2SZZtuF6Jnu=qnTna7dCLegFzg@mail.gmail.com>
	<CAHpsUFakmWm+8ns899ij1-NwH1s6e6Z0n5pn5piXV3v+i1joQw@mail.gmail.com>
Message-ID: <CAM_vjumO10XT6XO7SzDXLvyJDa7VN3L4F8fs+dfdOpJzg8GeZA@mail.gmail.com>

Hi,

On Monday, February 23, 2015, Alexandra Catena <amc5981 at gmail.com> wrote:

> The command,  data[data ==9999] <- NA, worked! Thank you!
>
> But just in case you wanted to know, I'm downloading the data and
> unzipping it through readLines.  I then concatenate two columns ( wind
> speed and direction) from the unzipped data through cbind but I make
> it into a data frame.
>
> wind = data.frame(cbind(windSpeed,windDirec))


It's better (shorter, more efficient, avoids coercion problems) to omit the
cbind():

Wind <- data.frame(windSpeed, windDirec)

Sarah



>
>
> Thanks,
> Alexandra
>
> On Sat, Feb 21, 2015 at 10:38 PM, Frederic Ntirenganya
> <ntfredo at gmail.com <javascript:;>> wrote:
> > If you are reading the data frame using for instance read.csv, you can
> put
> > in the argument na.string ="9999".
> > Another way to do that is data[data ==9999] <- NA.
> >
> > It should be good to tell us how you are reading your dataset.
> >
> > On Feb 21, 2015 6:49 AM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us
> <javascript:;>> wrote:
> >>
> >> You did not say how you imported the data, but if you used one of the
> >> read.table variants (including read.csv) then you can use the na.strings
> >> argument as documented in the help file for read.table.
> >>
> >> Next time please read the posting guide, as there are some useful tips
> in
> >> there, such as posting using plain text (a setting in your email
> program) so
> >> we don't get garbled info from you, and providing a reproducible
> example.
> >>
> >>
> ---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go
> >> Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us <javascript:;>>        Basics: ##.#.
>    ##.#.  Live
> >> Go...
> >>                                       Live:   OO#.. Dead: OO#..  Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >> rocks...1k
> >>
> >>
> ---------------------------------------------------------------------------
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On February 20, 2015 10:55:30 AM PST, Alexandra Catena <
> amc5981 at gmail.com <javascript:;>>
> >> wrote:
> >> >Hello All,
> >> >
> >> >I have a data frame of two columns for wind.  The first column is for
> >> >wind
> >> >speed and the second wind direction.  I'm trying to replace the 9999
> >> >values
> >> >in the first column and the 999 values in the second column with NA.  I
> >> >tried to use the function ltdl.fix.df but it doesn't seem to do
> >> >anything.
> >> >
> >> >> ltdl.fix.df(windMV, zero2na = FALSE, coded = 999)
> >> >
> >> >  n = 9432 by p = 4 matrix checked, 0 NA(s) present
> >> >
> >> >  0 factor variable(s) present
> >> >
> >> >  5675 value(s) coded 999 set to NA
> >> >
> >> >  0 -ve value(s) set to +ve half the negative value
> >> >
> >> >
> >> >I have R version 3.1.1
> >> >
> >> >Thanks,
> >> >Alexandra
> >> >
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From john.posner at MJBIOSTAT.COM  Mon Feb 23 20:54:24 2015
From: john.posner at MJBIOSTAT.COM (John Posner)
Date: Mon, 23 Feb 2015 19:54:24 +0000
Subject: [R] dplyr: producing a good old data frame
Message-ID: <9E73F88F04AA25408DBB58FB730BA65329B3C433@AUSP01DAG0503.collaborationhost.net>

I'm using the dplyr package to perform one-row-at-a-time processing of a data frame:

> rnd6 = function() sample(1:300, 6)
> frm = data.frame(AA=rnd6(), BB=rnd6(), CC=rnd6())

> frm
   AA  BB  CC
1 123  50  45
2  12  30 231
3 127 147 100
4 133  32 129
5  66 235  71
6  38 264 261

The interface is nice and straightforward:

> library(dplyr)
> dplyr_result = frm %>% rowwise() %>% do(MM=max(as.numeric(.)))

I've gotten used to the fact that dplyr_result is not a good old "vanilla" data frame. The as.data.frame() function *seems* to do the trick:

> dplyr_result_2 = as.data.frame(dplyr_result)
> dplyr_result_2
   MM
1 123
2 231
3 147
4 133
5 235
6 264

... but there's trouble ahead:

> mean(dplyr_result_2$MM)
[1] NA
Warning message:
In mean.default(dplyr_result_2$MM) :
  argument is not numeric or logical: returning NA

I need to enlist unlist() to get me to my destination:

> mean(unlist(dplyr_result_2$MM))
[1] 188.8333

[NOTE: dplyr's as_data_frame() function does a better job than as.data.frame() of indicating that I was headed for trouble. ]

By contrast, the plyr package's adply() function *does* produce a vanilla data frame:

 > library(plyr)
> plyr_result = adply(frm, .margins=1, function(onerowfrm) max(as.numeric(onerowfrm[1,])))
> mean(plyr_result$V1)
[1] 188.8333

Is there a good reason for dplyr to require the extra processing? My (na?ve ?) recommendation would be to have as_data_frame() produce a vanilla data frame.

Tx,
John


From dcarlson at tamu.edu  Mon Feb 23 21:34:26 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 23 Feb 2015 20:34:26 +0000
Subject: [R] Replacing 9999 and 999 values with NA
References: <CAHpsUFYz6iz3uy6TPiTMn1sbbKS3C6pFxxk1XJtNmk=bTJ_O4g@mail.gmail.com>
	<EE82066F-F9C7-417C-8DB0-F4580E7D90D0@dcn.davis.CA.us>
	<CAGh51gTZNyH41E3FR5cBJVU=2SZZtuF6Jnu=qnTna7dCLegFzg@mail.gmail.com>
	<CAHpsUFakmWm+8ns899ij1-NwH1s6e6Z0n5pn5piXV3v+i1joQw@mail.gmail.com> 
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D655641@mb02.ads.tamu.edu>

Just for the record, you do not need cbind():

wind <- data.frame(windSpeed,windDirec)

Using cbind() does not create a problem as long as the columns are all numeric, but if your data frame contains a mixture of numeric, factor, and character columns, cbind() will mess things up.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alexandra Catena
Sent: Monday, February 23, 2015 11:50 AM
To: Frederic Ntirenganya
Cc: r-help at r-project.org
Subject: Re: [R] Replacing 9999 and 999 values with NA

The command,  data[data ==9999] <- NA, worked! Thank you!

But just in case you wanted to know, I'm downloading the data and
unzipping it through readLines.  I then concatenate two columns ( wind
speed and direction) from the unzipped data through cbind but I make
it into a data frame.

wind = data.frame(cbind(windSpeed,windDirec))


Thanks,
Alexandra

On Sat, Feb 21, 2015 at 10:38 PM, Frederic Ntirenganya
<ntfredo at gmail.com> wrote:
> If you are reading the data frame using for instance read.csv, you can put
> in the argument na.string ="9999".
> Another way to do that is data[data ==9999] <- NA.
>
> It should be good to tell us how you are reading your dataset.
>
> On Feb 21, 2015 6:49 AM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> You did not say how you imported the data, but if you used one of the
>> read.table variants (including read.csv) then you can use the na.strings
>> argument as documented in the help file for read.table.
>>
>> Next time please read the posting guide, as there are some useful tips in
>> there, such as posting using plain text (a setting in your email program) so
>> we don't get garbled info from you, and providing a reproducible example.
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 20, 2015 10:55:30 AM PST, Alexandra Catena <amc5981 at gmail.com>
>> wrote:
>> >Hello All,
>> >
>> >I have a data frame of two columns for wind.  The first column is for
>> >wind
>> >speed and the second wind direction.  I'm trying to replace the 9999
>> >values
>> >in the first column and the 999 values in the second column with NA.  I
>> >tried to use the function ltdl.fix.df but it doesn't seem to do
>> >anything.
>> >
>> >> ltdl.fix.df(windMV, zero2na = FALSE, coded = 999)
>> >
>> >  n = 9432 by p = 4 matrix checked, 0 NA(s) present
>> >
>> >  0 factor variable(s) present
>> >
>> >  5675 value(s) coded 999 set to NA
>> >
>> >  0 -ve value(s) set to +ve half the negative value
>> >
>> >
>> >I have R version 3.1.1
>> >
>> >Thanks,
>> >Alexandra
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ramiro at precisionbioassay.com  Mon Feb 23 21:35:25 2015
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Mon, 23 Feb 2015 20:35:25 +0000
Subject: [R] Not finding superclass in library
Message-ID: <C7338A7EFF31BB4D831BB06C008877897DB9606A@MBX023-W1-CA-2.exch023.domain.local>

Hello,

I have a library that I created that defines a parent class, assayObject.

I created other classes that inherit from it, say assayObjectDemo.  Each one of those classes I wanted to make in its own directory separate from where the assayObject is defined (there are reasons for that).

But now if I do:

library(assayObject)  #<--- where parent object is defined
source("assayObjectDemo.R")

where assayObjectDemo.R is just:

setClass("assayObjectDemo",contains="assayObject")
createDemoAssayObject <- function() {
  df <- data.frame()
  assay<-new(Class="assayObjectDemo")
  assay
}

I get:

Error in reconcilePropertiesAndPrototype(name, slots, prototype, superClasses,  :
  no definition was found for superclass ?assayObject? in the specification of class ?assayObjectDemo?

What can I do?  There are several reasons why I DO NOT want to define assayObjectDemo in the same library as assayObject, but I am not sure what the issue is here.  If I step through the code in an ESS R session it works fine.

Thanks in advance,

Ramiro

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Mon Feb 23 21:41:42 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 24 Feb 2015 09:41:42 +1300
Subject: [R] Not finding superclass in library
In-Reply-To: <C7338A7EFF31BB4D831BB06C008877897DB9606A@MBX023-W1-CA-2.exch023.domain.local>
References: <C7338A7EFF31BB4D831BB06C008877897DB9606A@MBX023-W1-CA-2.exch023.domain.local>
Message-ID: <54EB9086.6090201@auckland.ac.nz>

On 24/02/15 09:35, Ramiro Barrantes wrote:
> Hello,
>
> I have a library that I created  .....

<SNIP>

No you ***DO NOT***.  You have a ***PACKAGE***.  If you cannot even get 
your terminology straight, what hope is there for you?

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From ramiro at precisionbioassay.com  Mon Feb 23 21:53:17 2015
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Mon, 23 Feb 2015 20:53:17 +0000
Subject: [R] Not finding superclass in library
In-Reply-To: <54EB9086.6090201@auckland.ac.nz>
References: <C7338A7EFF31BB4D831BB06C008877897DB9606A@MBX023-W1-CA-2.exch023.domain.local>,
	<54EB9086.6090201@auckland.ac.nz>
Message-ID: <C7338A7EFF31BB4D831BB06C008877897DB96081@MBX023-W1-CA-2.exch023.domain.local>

Thank you for pointing this out.  I had no idea about the distinction but there are some good references on the matter (http://www.r-bloggers.com/packages-v-libraries-in-r/).  I am pasting the corrected version below, any suggestions appreciated:

I have a package that I created that defines a parent class, assayObject.

I created other classes that inherit from it, say assayObjectDemo.  Each one of those classes I wanted to make in its own directory separate from where the assayObject is defined (there are reasons for that).

But now if I do:

library(assayObject)  #<--- where parent object is defined
source("assayObjectDemo.R")

where assayObjectDemo.R is just:

setClass("assayObjectDemo",contains="assayObject")
createDemoAssayObject <- function() {
  df <- data.frame()
  assay<-new(Class="assayObjectDemo")
  assay
}

I get:

Error in reconcilePropertiesAndPrototype(name, slots, prototype, superClasses,  :
  no definition was found for superclass ?assayObject? in the specification of class ?assayObjectDemo?

What can I do?  There are several reasons why I DO NOT want to define assayObjectDemo in the same package as assayObject, but I am not sure what the issue is here.  If I step through the code in an ESS R session it works fine.

Thanks in advance,

Ramiro

________________________________________
From: Rolf Turner [r.turner at auckland.ac.nz]
Sent: Monday, February 23, 2015 3:41 PM
To: Ramiro Barrantes; r-help at r-project.org
Subject: Re: [R] Not finding superclass in library

On 24/02/15 09:35, Ramiro Barrantes wrote:
> Hello,
>
> I have a library that I created  .....

<SNIP>

No you ***DO NOT***.  You have a ***PACKAGE***.  If you cannot even get
your terminology straight, what hope is there for you?

cheers,

Rolf Turner

--
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From Mike.Conklin at gfk.com  Mon Feb 23 22:16:29 2015
From: Mike.Conklin at gfk.com (Conklin, Mike (GfK))
Date: Mon, 23 Feb 2015 22:16:29 +0100
Subject: [R]  Problem installing with devtools
Message-ID: <FB454C9C2759D64BA12708C3073C30BB80F71A808F@NUEW-EXMBCRB1.gfk.com>

I am trying to install the swirl library via devtools with the following results

> devtools::install_github(c("swirldev/swirl", "swirldev/swirlify"))
Installing github repo swirl/master from swirldev
Downloading master.zip from https://github.com/swirldev/swirl/archive/master.zip
Installing package from C:\Users\MIKE~1.CON\AppData\Local\Temp\RtmpOG7HXq/master.zip
Installing swirl
"C:/Program Files/R/R-31~1.1/bin/i386/R" --vanilla CMD INSTALL  \
  "C:\Users\mike.conklin\AppData\Local\Temp\RtmpOG7HXq\devtoolsd1c48a85b74\swirl-master"  \
  --library="C:/Users/mike.conklin/Documents/R/win-library/3.1" --install-tests 

'C:\Program' is not recognized as an internal or external command,
operable program or batch file.
Error: Command failed (1)

The problem appears to be the inability of the script to handle space in the Program Files directory name.  Is there a work around for this?  Do I need to reinstall R in a different directory?


--
W. Michael Conklin
Executive Vice President
Marketing & Data Sciences - North America
GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
mike.conklin at gfk.com 
T +1 763 417 4545 | M +1 612 567 8287 
www.gfk.com 


From jonsleepy at gmail.com  Mon Feb 23 22:25:09 2015
From: jonsleepy at gmail.com (Jon BR)
Date: Mon, 23 Feb 2015 16:25:09 -0500
Subject: [R] Basic data frame manipulation
Message-ID: <CA+d7zeREr7PMtxjVmJDgU44aEPSD=Q--7agkJPYC70+uyoEP3Q@mail.gmail.com>

Hi R-help,
    Although I know that variations of this question are frequently asked,
I searched and haven't found an answer for this specific variant, and
wonder if any of you know this off the top of your head:

df1 <- data.frame(a = 1:5,
                  row.names = letters[1:5]) # letters a to e
df2 <- data.frame(a = 1:5,
                  row.names = letters[3:7]) # letters c to g
df3 <- data.frame(a = 1:5,
                  row.names = letters[c(1,2,3,5,7)]) # letters a, b, c, e,
and g


I would like a command to produce a data frame which contains the same rows
(with rownames) as in df1, with elements in the columns corresponding to
the values present in each of the data frames (if there exists a matching
row; else NA if not present).  This should ideally work even if the rows
are in random order and if not sorted.

The result would look something like this:

df1.a df2.a df3.a
a 1 NA 1
b 2 NA 2
c 3 1 3
d 4 2 NA
e 5 3 4

Thank you in advance for any tips.

Jonathan

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Mon Feb 23 22:33:56 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 23 Feb 2015 16:33:56 -0500
Subject: [R] Basic data frame manipulation
In-Reply-To: <CA+d7zeREr7PMtxjVmJDgU44aEPSD=Q--7agkJPYC70+uyoEP3Q@mail.gmail.com>
References: <CA+d7zeREr7PMtxjVmJDgU44aEPSD=Q--7agkJPYC70+uyoEP3Q@mail.gmail.com>
Message-ID: <CA+vqiLFUDpmwQF9By9wtjfXjToKOcQn=AVBYrTF2dr4kjkVWug@mail.gmail.com>

Something like

tmp <- merge(df1, df2, by = "row.names", all.x = TRUE)
merge(tmp, df3, by.x = "Row.names", by.y = "row.names", all.x = TRUE)

perhaps?



On Mon, Feb 23, 2015 at 4:25 PM, Jon BR <jonsleepy at gmail.com> wrote:
> Hi R-help,
>     Although I know that variations of this question are frequently asked,
> I searched and haven't found an answer for this specific variant, and
> wonder if any of you know this off the top of your head:
>
> df1 <- data.frame(a = 1:5,
>                   row.names = letters[1:5]) # letters a to e
> df2 <- data.frame(a = 1:5,
>                   row.names = letters[3:7]) # letters c to g
> df3 <- data.frame(a = 1:5,
>                   row.names = letters[c(1,2,3,5,7)]) # letters a, b, c, e,
> and g
>
>
> I would like a command to produce a data frame which contains the same rows
> (with rownames) as in df1, with elements in the columns corresponding to
> the values present in each of the data frames (if there exists a matching
> row; else NA if not present).  This should ideally work even if the rows
> are in random order and if not sorted.
>
> The result would look something like this:
>
> df1.a df2.a df3.a
> a 1 NA 1
> b 2 NA 2
> c 3 1 3
> d 4 2 NA
> e 5 3 4
>
> Thank you in advance for any tips.
>
> Jonathan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Feb 23 22:34:34 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 23 Feb 2015 21:34:34 +0000
Subject: [R] Extracting Factor Pattern Matrix Similar to Proc Factor
In-Reply-To: <1424715313110-4703704.post@n4.nabble.com>
References: <1424715313110-4703704.post@n4.nabble.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6556A0@mb02.ads.tamu.edu>

The pattern matrix is easy to compute from the results of princomp(). First we need a reproducible example so we'll use the iris data set (use ?iris for details) that comes with R.

> data(iris)
> iris.pc <- princomp(iris[,-5], cor=TRUE)
> print(iris.pc$loadings, cutoff=0)

Loadings:
             Comp.1 Comp.2 Comp.3 Comp.4
Sepal.Length  0.521 -0.377  0.720  0.261
Sepal.Width  -0.269 -0.923 -0.244 -0.124
Petal.Length  0.580 -0.024 -0.142 -0.801
Petal.Width   0.565 -0.067 -0.634  0.524

               Comp.1 Comp.2 Comp.3 Comp.4
SS loadings      1.00   1.00   1.00   1.00
Proportion Var   0.25   0.25   0.25   0.25
Cumulative Var   0.25   0.50   0.75   1.00

The object iris.pc is a list with 7 elements. One of those, iris.pc$loadings contains the standardized loadings so that the sum of the squared values in each column is 1. The default print method suppresses the printing of small loadings (< .1) so I've set cutoff=0 so we see them all. 

To get the pattern matrix we just need to multiple each of the columns by iris.pc$sdev (the square roots of the eigenvalues):

> iris.pat <- sweep(iris.pc$loadings, 2, iris.pc$sdev, "*")
> print(iris.pat, cutoff=0)

Loadings:
             Comp.1 Comp.2 Comp.3 Comp.4
Sepal.Length  0.890 -0.361  0.276  0.038
Sepal.Width  -0.460 -0.883 -0.094 -0.018
Petal.Length  0.992 -0.023 -0.054 -0.115
Petal.Width   0.965 -0.064 -0.243  0.075

               Comp.1 Comp.2 Comp.3 Comp.4
SS loadings     2.918  0.914  0.147  0.021
Proportion Var  0.730  0.229  0.037  0.005
Cumulative Var  0.730  0.958  0.995  1.000
> iris.pc$sdev^2
    Comp.1     Comp.2     Comp.3     Comp.4 
2.91849782 0.91403047 0.14675688 0.02071484

The sweep() function multiplies each column by its standard deviation. Now the sums of the squared values in each column sum to the eigenvalue. 

Alternatively, you can install the "psych" package which computes the pattern (structure) matrix directly:

> library(psych)
> iris.pca <- principal(iris[,-5], nfactors=4, rotate="none")
> print(iris.pca$Structure, cutoff=0)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Scott Colwell
Sent: Monday, February 23, 2015 12:15 PM
To: r-help at r-project.org
Subject: [R] Extracting Factor Pattern Matrix Similar to Proc Factor

Hello,

I am fairly new to R and coming from SAS IML. I am rewriting one of my MC
simulations in R and am stuck on extracting a factor pattern matrix as would
be done in IML using Proc Factor.  

I have found the princomp() command and read through the manual but can't
seem to figure out how to save the factor pattern matrix.  I am waiting for
the R for SAS Users book to arrive. What I would use in SAS IML to get at
what I am looking for is:

PROC FACTOR Data=MODELCOV15(TYPE=COV) NOBS=10000 N=16 CORR
OUTSTAT=FAC.FACOUT15;
RUN;

DATA FAC.PATTERN15; SET FAC.FACOUT15;
IF _TYPE_='PATTERN';
DROP _TYPE_ _NAME_;
RUN;

Would any SAS IML to R converts be able to help me with this?

Thanks,

Scott Colwell, PhD




--
View this message in context: http://r.789695.n4.nabble.com/Extracting-Factor-Pattern-Matrix-Similar-to-Proc-Factor-tp4703704.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From scolwell at uoguelph.ca  Mon Feb 23 22:33:50 2015
From: scolwell at uoguelph.ca (Scott Colwell)
Date: Mon, 23 Feb 2015 13:33:50 -0800 (PST)
Subject: [R] Extracting Factor Pattern Matrix Similar to Proc Factor
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6556A0@mb02.ads.tamu.edu>
References: <1424715313110-4703704.post@n4.nabble.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6556A0@mb02.ads.tamu.edu>
Message-ID: <1424727230269-4703719.post@n4.nabble.com>

Thanks David. What do you do when the input is a covariance matrix rather
than a dataset?



--
View this message in context: http://r.789695.n4.nabble.com/Extracting-Factor-Pattern-Matrix-Similar-to-Proc-Factor-tp4703704p4703719.html
Sent from the R help mailing list archive at Nabble.com.


From dcarlson at tamu.edu  Mon Feb 23 22:58:43 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 23 Feb 2015 21:58:43 +0000
Subject: [R] Extracting Factor Pattern Matrix Similar to Proc Factor
In-Reply-To: <1424727230269-4703719.post@n4.nabble.com>
References: <1424715313110-4703704.post@n4.nabble.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6556A0@mb02.ads.tamu.edu>
	<1424727230269-4703719.post@n4.nabble.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D655712@mb02.ads.tamu.edu>

Function principal() in psych takes a correlation matrix so use cov2cor() to convert:

library(psych)
iris.pca <- principal(cov2cor(cov(iris[,-5])), nfactors=4, rotate="none")
print(iris.pca$Structure, cutoff=0)

David
-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Scott Colwell
Sent: Monday, February 23, 2015 3:34 PM
To: r-help at r-project.org
Subject: Re: [R] Extracting Factor Pattern Matrix Similar to Proc Factor

Thanks David. What do you do when the input is a covariance matrix rather
than a dataset?



--
View this message in context: http://r.789695.n4.nabble.com/Extracting-Factor-Pattern-Matrix-Similar-to-Proc-Factor-tp4703704p4703719.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From angela.smith2071 at hotmail.com  Tue Feb 24 00:18:59 2015
From: angela.smith2071 at hotmail.com (Angela Smith)
Date: Mon, 23 Feb 2015 16:18:59 -0700
Subject: [R] how to standardize raster image (GeoTiff) in R?
Message-ID: <COL129-W45DDF5C44CED274C3B34058E290@phx.gbl>

Hi R user, 
Would you give me some hints on to standardize the raster image (GeoTiff). I used the following code but did not work. would you give me some hints on it?

#----------------------------------
#code
# center with 'apply()'
center_apply <- function(x) {
    apply(x, 2, function(y) y - mean(y))
}
# import data
im1<-("image1.tif")
im2<-("image2.tif")
image<-stack(im1,im2)

# standardize (a mean of zero and unit variance) of the rasetr images 
st<-center_apply(image)

but it did not work. any suggestions?




 		 	   		  
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Feb 24 00:30:57 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 23 Feb 2015 15:30:57 -0800
Subject: [R] how to standardize raster image (GeoTiff) in R?
In-Reply-To: <COL129-W45DDF5C44CED274C3B34058E290@phx.gbl>
References: <COL129-W45DDF5C44CED274C3B34058E290@phx.gbl>
Message-ID: <CACk-te08Y8JxVW8tE2-QvAfNyV43RCj4W0j5ho00KKFLr2t16w@mail.gmail.com>

Take a look at im1 and im2. You will find that they are just the
quoted names. You have imported nothing.

Have you made any effort to read R's or the GeoTiff's tutorials? --
you appear to not have a clue about how either works. Also  see
?scale, which will do what you appear to want much much faster.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Feb 23, 2015 at 3:18 PM, Angela Smith
<angela.smith2071 at hotmail.com> wrote:
> Hi R user,
> Would you give me some hints on to standardize the raster image (GeoTiff). I used the following code but did not work. would you give me some hints on it?
>
> #----------------------------------
> #code
> # center with 'apply()'
> center_apply <- function(x) {
>     apply(x, 2, function(y) y - mean(y))
> }
> # import data
> im1<-("image1.tif")
> im2<-("image2.tif")
> image<-stack(im1,im2)
>
> # standardize (a mean of zero and unit variance) of the rasetr images
> st<-center_apply(image)
>
> but it did not work. any suggestions?
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at revelle.net  Tue Feb 24 02:03:55 2015
From: lists at revelle.net (William Revelle)
Date: Mon, 23 Feb 2015 19:03:55 -0600
Subject: [R] Extracting Factor Pattern Matrix Similar to Proc Factor
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D655712@mb02.ads.tamu.edu>
References: <1424715313110-4703704.post@n4.nabble.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6556A0@mb02.ads.tamu.edu>
	<1424727230269-4703719.post@n4.nabble.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D655712@mb02.ads.tamu.edu>
Message-ID: <692083CA-AC98-4FC0-8F93-C51000B83F95@revelle.net>

David and Scott,
 principal will also take a covariance matrix (set the cover option to TRUE)


library(psych)
C <- cov(iris[-5])
pc4 <- principal(C,4,covar=TRUE,rotate="none?)

However, in the case of no rotation or orthogonal rotations, the structure matrix and the pattern matrix are identical.

They differ only if you take an oblique solution.
So, 

pc4 #will give you the results 
print(pc4$loadings,cutoff=0) #will give the loadings (pattern)
print(pc4$Structure,cutoff=0)   #will give the structure matrix

If the input is a covariance matrix, and you want to do the analysis on the correlation matrix, principal does that automatically.

C <- cov(iris[-5])
pc4 <- principal(C,4,rotate="none?)
pc4

Bill



> On Feb 23, 2015, at 3:58 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> Function principal() in psych takes a correlation matrix so use cov2cor() to convert:
> 
> library(psych)
> iris.pca <- principal(cov2cor(cov(iris[,-5])), nfactors=4, rotate="none")
> print(iris.pca$Structure, cutoff=0)
> 
> David
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Scott Colwell
> Sent: Monday, February 23, 2015 3:34 PM
> To: r-help at r-project.org
> Subject: Re: [R] Extracting Factor Pattern Matrix Similar to Proc Factor
> 
> Thanks David. What do you do when the input is a covariance matrix rather
> than a dataset?
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Extracting-Factor-Pattern-Matrix-Similar-to-Proc-Factor-tp4703704p4703719.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

William Revelle		           http://personality-project.org/revelle.html
Professor			           http://personality-project.org
Department of Psychology   http://www.wcas.northwestern.edu/psych/
Northwestern University	   http://www.northwestern.edu/
Use R for psychology             http://personality-project.org/r
It is 3 minutes to midnight	   http://www.thebulletin.org


From ccberry at ucsd.edu  Tue Feb 24 04:20:43 2015
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Mon, 23 Feb 2015 19:20:43 -0800
Subject: [R] Not finding superclass in library
In-Reply-To: <C7338A7EFF31BB4D831BB06C008877897DB96081@MBX023-W1-CA-2.exch023.domain.local>
References: <C7338A7EFF31BB4D831BB06C008877897DB9606A@MBX023-W1-CA-2.exch023.domain.local>,
	<54EB9086.6090201@auckland.ac.nz>
	<C7338A7EFF31BB4D831BB06C008877897DB96081@MBX023-W1-CA-2.exch023.domain.local>
Message-ID: <alpine.OSX.2.00.1502231906010.2437@charles-berrys-macbook.local>

On Mon, 23 Feb 2015, Ramiro Barrantes wrote:

> Thank you for pointing this out.  I had no idea about the distinction 
> but there are some good references on the matter 
> (http://www.r-bloggers.com/packages-v-libraries-in-r/).  I am pasting 
> the corrected version below, any suggestions appreciated:

>

> I have a package that I created that defines a parent class, 
> assayObject.

>
> I created other classes that inherit from it, say assayObjectDemo. 
> Each one of those classes I wanted to make in its own directory separate 
> from where the assayObject is defined (there are reasons for that).

>
> But now if I do:
>
> library(assayObject)  #<--- where parent object is defined
> source("assayObjectDemo.R")
>
> where assayObjectDemo.R is just:
>
> setClass("assayObjectDemo",contains="assayObject")
> createDemoAssayObject <- function() {
>  df <- data.frame()
>  assay<-new(Class="assayObjectDemo")
>  assay
> }
>
> I get:
>
> Error in reconcilePropertiesAndPrototype(name, slots, prototype, superClasses,  :
>  no definition was found for superclass ?assayObject? in the specification of class ?assayObjectDemo?
>
> What can I do?


Start with a reproducible example. Here is one:

   library(Matrix)
   tmpf <- tempfile(fileext=".R")
   cat('setClass("MatrixDemo",contains="Matrix")',file=tmpf)
   source(tmpf)
   slotNames("MatrixDemo")

And it produces the expected output without error:

  [1] "Dim"      "Dimnames"

Since this works fine for a widely used package and fails for your
(unspecified) package, I suspect there is a problem with your package.

If I had to guess, I'd say it is a NAMESPACE issue. Be sure your
exportClasses directive is correctly formed per Section 1.5.6
"Namespaces with S4 classes and methods" of R-exts.

r-devel might be a better venue for this discussion.

HTH,

Chuck

From amc5981 at gmail.com  Mon Feb 23 20:13:20 2015
From: amc5981 at gmail.com (Alexandra Catena)
Date: Mon, 23 Feb 2015 11:13:20 -0800
Subject: [R] Error with using windRose function from the open air package
Message-ID: <CAHpsUFbD01RTti81k0YGWhqCqVn570G3Fe5fxFrDjVas4ihPLg@mail.gmail.com>

Hello All,

I have a data frame called windSFO of four columns, wind speed, wind
direction, station number, and date (yyyymmdd).  I downloaded the gz
data from a site online and then unzipped it using readLines. I then
concatenated these four columns from the unzipped data into a
dataframe using cbind.

windSFO = data.frame(cbind(ws,wd,stn,yearSite))

Here are the first four rows as an example:

       ws  wd          stn       yearSite

1      36 290 724940-23234 20090101

2      77 280 724940-23234 20090101

3      72 290 724940-23234 20090101

4      46 290 724940-23234 20090101


I'm trying to make a wind rose using the windRose function but I keep
getting an error that I don't understand. I type in:

windRose(windSFO,ws='ws',wd='wd')

I then get the error:

Error in Summary.factor(c(27L, 35L, 34L, 29L, 28L, 25L, 25L, 24L, 24L,  :
  max not meaningful for factors
In addition: Warning messages:
1: In Ops.factor(mydata[[wd]], 10) : %% not meaningful for factors
2: In Ops.factor(mydata[[wd]], angle) : / not meaningful for factors

Can anyone tell me what this means/what I'm doing wrong?

Also, I have R version 3.1.1

Thank you!
Alexandra


From jdnewmil at dcn.davis.CA.us  Tue Feb 24 06:38:15 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 23 Feb 2015 21:38:15 -0800
Subject: [R] Error with using windRose function from the open air package
In-Reply-To: <CAHpsUFbD01RTti81k0YGWhqCqVn570G3Fe5fxFrDjVas4ihPLg@mail.gmail.com>
References: <CAHpsUFbD01RTti81k0YGWhqCqVn570G3Fe5fxFrDjVas4ihPLg@mail.gmail.com>
Message-ID: <EF6BB307-8933-41D8-BF71-76ABA236E5FE@dcn.davis.CA.us>

I have no magic answer for you, just some suggestions until you can clarify your problem.

Your description of loading one column in at a time is a bit odd... It is much more typical to use one of the read.table variants.

Don't use cbind to make data frames. If you have any non-numeric columns then you will make them all into character or factor columns. That is almost never a good thing. In fact it is probably at the root of your current woes.

windSFO <- data.frame(ws,wd,stn,yearSite)

Learn to use the str function... e.g.

str(windSFO)

Not that we cannot tell how your data are stored given the way you gave supplied it to us. Read about the use of dput (e.g. [1]) and make your example reproducible (what package exactly are you talking about? package names don't have spaces in them).

Note that the Posting Guide directs you to verify that your problem occurs when you use the latest version (3.1.2 at this time). If you want to keep old versions around for some reason, at least install the latest version and verify that your problem happens with it before posting.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 23, 2015 11:13:20 AM PST, Alexandra Catena <amc5981 at gmail.com> wrote:
>Hello All,
>
>I have a data frame called windSFO of four columns, wind speed, wind
>direction, station number, and date (yyyymmdd).  I downloaded the gz
>data from a site online and then unzipped it using readLines. I then
>concatenated these four columns from the unzipped data into a
>dataframe using cbind.
>
>windSFO = data.frame(cbind(ws,wd,stn,yearSite))
>
>Here are the first four rows as an example:
>
>       ws  wd          stn       yearSite
>
>1      36 290 724940-23234 20090101
>
>2      77 280 724940-23234 20090101
>
>3      72 290 724940-23234 20090101
>
>4      46 290 724940-23234 20090101
>
>
>I'm trying to make a wind rose using the windRose function but I keep
>getting an error that I don't understand. I type in:
>
>windRose(windSFO,ws='ws',wd='wd')
>
>I then get the error:
>
>Error in Summary.factor(c(27L, 35L, 34L, 29L, 28L, 25L, 25L, 24L, 24L, 
>:
>  max not meaningful for factors
>In addition: Warning messages:
>1: In Ops.factor(mydata[[wd]], 10) : %% not meaningful for factors
>2: In Ops.factor(mydata[[wd]], angle) : / not meaningful for factors
>
>Can anyone tell me what this means/what I'm doing wrong?
>
>Also, I have R version 3.1.1
>
>Thank you!
>Alexandra
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Feb 24 08:22:44 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 24 Feb 2015 18:22:44 +1100
Subject: [R] Error with using windRose function from the open air package
In-Reply-To: <EF6BB307-8933-41D8-BF71-76ABA236E5FE@dcn.davis.CA.us>
References: <CAHpsUFbD01RTti81k0YGWhqCqVn570G3Fe5fxFrDjVas4ihPLg@mail.gmail.com>
	<EF6BB307-8933-41D8-BF71-76ABA236E5FE@dcn.davis.CA.us>
Message-ID: <CA+8X3fWmqAnWVx_=MTYT4dJrcDU=QR9zb-fXTWX9nDd0i6-J4w@mail.gmail.com>

Hi Alexandra,
As Jeff mentioned, cbind is probably causing the conversion to factors. One
thing I would suggest is keeping the names:

windSFO<-data.frame(ws=ws,wd=wd,stn=stn,yearSite=yearSite)

as it looks like the windRose function expects the names to be there. If
the error persists after using the above, try:

windSFO$ws<-as.numeric(as.character(windSFO$ws))
windSFO$ww<-as.numeric(as.character(windSFO$ww))

Jim


On Tue, Feb 24, 2015 at 4:38 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I have no magic answer for you, just some suggestions until you can
> clarify your problem.
>
> Your description of loading one column in at a time is a bit odd... It is
> much more typical to use one of the read.table variants.
>
> Don't use cbind to make data frames. If you have any non-numeric columns
> then you will make them all into character or factor columns. That is
> almost never a good thing. In fact it is probably at the root of your
> current woes.
>
> windSFO <- data.frame(ws,wd,stn,yearSite)
>
> Learn to use the str function... e.g.
>
> str(windSFO)
>
> Not that we cannot tell how your data are stored given the way you gave
> supplied it to us. Read about the use of dput (e.g. [1]) and make your
> example reproducible (what package exactly are you talking about? package
> names don't have spaces in them).
>
> Note that the Posting Guide directs you to verify that your problem occurs
> when you use the latest version (3.1.2 at this time). If you want to keep
> old versions around for some reason, at least install the latest version
> and verify that your problem happens with it before posting.
>
> [1]
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On February 23, 2015 11:13:20 AM PST, Alexandra Catena <amc5981 at gmail.com>
> wrote:
> >Hello All,
> >
> >I have a data frame called windSFO of four columns, wind speed, wind
> >direction, station number, and date (yyyymmdd).  I downloaded the gz
> >data from a site online and then unzipped it using readLines. I then
> >concatenated these four columns from the unzipped data into a
> >dataframe using cbind.
> >
> >windSFO = data.frame(cbind(ws,wd,stn,yearSite))
> >
> >Here are the first four rows as an example:
> >
> >       ws  wd          stn       yearSite
> >
> >1      36 290 724940-23234 20090101
> >
> >2      77 280 724940-23234 20090101
> >
> >3      72 290 724940-23234 20090101
> >
> >4      46 290 724940-23234 20090101
> >
> >
> >I'm trying to make a wind rose using the windRose function but I keep
> >getting an error that I don't understand. I type in:
> >
> >windRose(windSFO,ws='ws',wd='wd')
> >
> >I then get the error:
> >
> >Error in Summary.factor(c(27L, 35L, 34L, 29L, 28L, 25L, 25L, 24L, 24L,
> >:
> >  max not meaningful for factors
> >In addition: Warning messages:
> >1: In Ops.factor(mydata[[wd]], 10) : %% not meaningful for factors
> >2: In Ops.factor(mydata[[wd]], angle) : / not meaningful for factors
> >
> >Can anyone tell me what this means/what I'm doing wrong?
> >
> >Also, I have R version 3.1.1
> >
> >Thank you!
> >Alexandra
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Tue Feb 24 11:52:44 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 24 Feb 2015 10:52:44 +0000
Subject: [R] Packages not installing on XP
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED66042D9EE7@GOLD.corp.lgc-group.com>

I have an installation problem; on installing MethComp either from repository or local zip file on Win XP (!) I get

Warning: unable to move temporary installation 'C:\Program Files\R\R-3.1.2\library\filefbc44fe1354\MethComp' to ?C:\Program Files\R\R-3.1.2\library\MethComp?
The same occurs with other packages.

The 'obvious' reason for this is that subsequent inspection shows that there is no temporary installation at the location given.

I appreciate that R is not now tested on XP as XP is no longer supported by MS, but since I've yet to switch to Win7+ on this otherwise serviceable small laptop and it'll be a while before I get back to my desktops, I'd appreciate any clues as to what - if anything - I could to do in the mean time to get a working package install.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ripley at stats.ox.ac.uk  Tue Feb 24 13:10:47 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 24 Feb 2015 12:10:47 +0000
Subject: [R] Packages not installing on XP
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED66042D9EE7@GOLD.corp.lgc-group.com>
References: <A4E5A0B016B8CB41A485FC629B633CED66042D9EE7@GOLD.corp.lgc-group.com>
Message-ID: <54EC6A47.3040607@stats.ox.ac.uk>

On 24/02/2015 10:52, S Ellison wrote:
> I have an installation problem; on installing MethComp either from repository or local zip file on Win XP (!) I get
>
> Warning: unable to move temporary installation 'C:\Program Files\R\R-3.1.2\library\filefbc44fe1354\MethComp' to ?C:\Program Files\R\R-3.1.2\library\MethComp?
> The same occurs with other packages.
>
> The 'obvious' reason for this is that subsequent inspection shows that there is no temporary installation at the location given.

But R CMD INSTALL cleaned it up.

> I appreciate that R is not now tested on XP as XP is no longer supported by MS, but since I've yet to switch to Win7+ on this otherwise serviceable small laptop and it'll be a while before I get back to my desktops, I'd appreciate any clues as to what - if anything - I could to do in the mean time to get a working package install.

1) Check the permissions on :\Program Files\R\R-3.1.2\library, or 
perhaps better, use a separate library directory (see the rw-FAQ).

2) Switch off any anti-virus runtime checking.  There is a comment in 
the sources

                 ## Move the new package to the install lib
                 ## To avoid anti-virus interference, wait a little
                 Sys.sleep(0.5)


> S Ellison


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From S.Ellison at LGCGroup.com  Tue Feb 24 14:17:33 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 24 Feb 2015 13:17:33 +0000
Subject: [R] Packages not installing on XP
In-Reply-To: <54EC6A47.3040607@stats.ox.ac.uk>
References: <A4E5A0B016B8CB41A485FC629B633CED66042D9EE7@GOLD.corp.lgc-group.com>,
	<54EC6A47.3040607@stats.ox.ac.uk>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED66042D9EEB@GOLD.corp.lgc-group.com>

> 2) Switch off any anti-virus runtime checking.  
Thanks; that seems to have been it - probably because of a recent Norton update, as previous package installations worked smoothly.

S

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From aurora.gonzalez2 at um.es  Tue Feb 24 12:16:56 2015
From: aurora.gonzalez2 at um.es (AURORA GONZALEZ VIDAL)
Date: Tue, 24 Feb 2015 12:16:56 +0100
Subject: [R] xtable caption knitr
Message-ID: <20150224121656.Horde.rw7cAuvkbL8LfWtYSlAj3g1@webmail.um.es>

Dear all,
I have a problem with the caption option on the xtable function.

Using Rmarkdown, knitr generates correctly a pdf when I write something
like this:

```{r xtable, results="asis"}
library( xtable )
variableName? <- c( "V03_1" )
age <- c( rep(1,10),rep(2,10),rep(3,10) )
gender <- c( rep("m",15), rep("f",15) )

df <- data.frame( age, gender )

t???? <- xtable( df, caption = "hello" )??? ?
print( t, caption.placement = 'top',comment = FALSE ) ?
```

But if I change to

t???? <- xtable(df, caption = variableName)???

wich is what I really want it retuns a pandoc error:

! Missing $ inserted.
<inserted text>
??????????????? $
l.112 \caption{V03_1}

pandoc: Error producing PDF from TeX source
Error: pandoc document conversion failed with error 43

I don't know why because variableName is also a character variable!

Any idea? Thank you very much!


------
Aurora Gonz?lez Vidal

Secci?n Apoyo Estad?stico.
Servicio de Apoyo a la Investigaci?n (SAI).
Vicerrectorado de Investigaci?n.
Universidad de Murcia
Edif. SACE . Campus de Espinardo.
30100 Murcia

@. aurora.gonzalez2 at um.es
T. 868 88 7315
F. 868 88 7302
www.um.es/sai
www.um.es/ae

	[[alternative HTML version deleted]]


From arjarvis.warthog at gmail.com  Tue Feb 24 14:19:27 2015
From: arjarvis.warthog at gmail.com (Warthog)
Date: Tue, 24 Feb 2015 13:19:27 +0000
Subject: [R] Convert windows source package for Mac use
Message-ID: <C9FE7FA3-E1B1-414D-9BA6-035E5701BCE3@gmail.com>

Hi, 
I am on a Mac. 
Is there a way to convert a Windows source package so it can be installed on a Mac?

I have a package in zip form from a friend who runs Windows. 
I THINK that it is in compiled format for Windows. 
The Description says: 
Built: R 3.1.2 x86_64-w64-mingw32....windows 

I tried to convert it to a tgz then Install/Load on Mac R, but I get the error message: 
Error: package 'package' was built for x86_64-w64-mingw32 

I can run Windows on Parallels Desktop, and the original zip format installs and loads OK. 

I'd prefer to run R on my Mac. 
Sorry if this is a stupid question: I read the R-exts and it doesn't say if you can or cannot do this. 

Thanks, 
Alan 
	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Feb 24 14:51:45 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 24 Feb 2015 07:51:45 -0600
Subject: [R] Convert windows source package for Mac use
In-Reply-To: <C9FE7FA3-E1B1-414D-9BA6-035E5701BCE3@gmail.com>
References: <C9FE7FA3-E1B1-414D-9BA6-035E5701BCE3@gmail.com>
Message-ID: <1F126F59-8061-43FD-A70A-D2B2B5DE1243@me.com>


> On Feb 24, 2015, at 7:19 AM, Warthog <arjarvis.warthog at gmail.com> wrote:
> 
> Hi, 
> I am on a Mac. 
> Is there a way to convert a Windows source package so it can be installed on a Mac?
> 
> I have a package in zip form from a friend who runs Windows. 
> I THINK that it is in compiled format for Windows. 
> The Description says: 
> Built: R 3.1.2 x86_64-w64-mingw32....windows 
> 
> I tried to convert it to a tgz then Install/Load on Mac R, but I get the error message: 
> Error: package 'package' was built for x86_64-w64-mingw32 
> 
> I can run Windows on Parallels Desktop, and the original zip format installs and loads OK. 
> 
> I'd prefer to run R on my Mac. 
> Sorry if this is a stupid question: I read the R-exts and it doesn't say if you can or cannot do this. 
> 
> Thanks, 
> Alan 


Hi,

Just as an FYI, there is a Mac specific SIG list:

  https://stat.ethz.ch/mailman/listinfo/r-sig-mac

Next, the Windows .zip file is a *binary*, not source package, specifically compiled for Windows, as you hint at above. If the package contains any C/C++/FORTRAN code, then that code is also compiled for Windows and is not portable.

The source package would/should have a .tar.gz extension and you would want your friend to provide that version of his/her package, presuming that he/she created this package and that it is not otherwise available (eg. from CRAN or a third party location). 

If you can get that version of the package, then you may be able to install it on OS X, using:

  install.packages(PackageFileName, repos = NULL, type = "source")

That presumes that there is no C/C++/FORTRAN code that requires compilation. If so, you would also need to install required development related tools which are referenced in the R FAQ for OSX and the Installation and Admin manual.

Regards,

Marc Schwartz


From dcarlson at tamu.edu  Tue Feb 24 15:00:52 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 24 Feb 2015 14:00:52 +0000
Subject: [R] How to Deploy a 'poLCA' Model?
In-Reply-To: <CAMwbFxh_8mqdgcSeh8mXpCXV4PrUju0hUoqNWK2uj6L8Vind6w@mail.gmail.com>
References: <CAMwbFxh_8mqdgcSeh8mXpCXV4PrUju0hUoqNWK2uj6L8Vind6w@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6558C4@mb02.ads.tamu.edu>

Looking at package poLCA I see functions poLCA.predcell() and poLCA.table(). If these do not do what you want, you will need to be clearer and provide a reproducible example.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of sagnik chakravarty
Sent: Monday, February 23, 2015 6:06 AM
To: drew at votamatic.org
Cc: r-help
Subject: [R] How to Deploy a 'poLCA' Model?

Hi Drew,

I was working with 'poLCA' to fit latent-class model with covariates
[formula: f=cbind(y1,y2,y3) ~ x1*x2*x3*x4]. The output contains a fit table
with coefficients, t-value, std_error and P-value for different
combinations of the covariates.

Now if I want to deploy this model to a new dataset like we do for any
other model with 'predict' function, how to proceed?

I couldn't find any predict function described in the package
documentation. Kindly help.

Thanks,

-- 
Regards,

SAGNIK CHAKRAVARTY

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Tue Feb 24 15:04:14 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 24 Feb 2015 14:04:14 +0000
Subject: [R] Convert windows source package for Mac use
In-Reply-To: <C9FE7FA3-E1B1-414D-9BA6-035E5701BCE3@gmail.com>
References: <C9FE7FA3-E1B1-414D-9BA6-035E5701BCE3@gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED66042D9EEE@GOLD.corp.lgc-group.com>

> Is there a way to convert a Windows source package so it can be installed on a Mac?

The .zip format yo mention is not a source package; it is a compiled binary. 

The _source_ packages are .tar.gz files. Those do not need to be converted for different platforms (provided the package supports different platforms) because R can install from the tar.gz.

If a .zip exists, though, the .tar.gz should too, or if it doesn't (typically because the developer is a local Windows developer and hasn't bothered to create a tar.gz they don't need) the tar.gz can be created more or less trivially using R CMD from the package source code.

The documentation you're looking for on installation is 6.3 of 'R Installation and Administration. For building packages locally from your own R source code, look at 'Writing R Extensions'



S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From info at aghmed.fsnet.co.uk  Tue Feb 24 15:10:18 2015
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Tue, 24 Feb 2015 14:10:18 +0000
Subject: [R] xtable caption knitr
In-Reply-To: <20150224121656.Horde.rw7cAuvkbL8LfWtYSlAj3g1@webmail.um.es>
References: <20150224121656.Horde.rw7cAuvkbL8LfWtYSlAj3g1@webmail.um.es>
Message-ID: <54EC864A.2040708@aghmed.fsnet.co.uk>

Dear Aurora

I suspect the underscore character in your variable name is the problem.


On 24/02/2015 11:16, AURORA GONZALEZ VIDAL wrote:
> Dear all,
> I have a problem with the caption option on the xtable function.
>
> Using Rmarkdown, knitr generates correctly a pdf when I write something
> like this:
>
> ```{r xtable, results="asis"}
> library( xtable )
> variableName  <- c( "V03_1" )
> age <- c( rep(1,10),rep(2,10),rep(3,10) )
> gender <- c( rep("m",15), rep("f",15) )
>
> df <- data.frame( age, gender )
>
> t     <- xtable( df, caption = "hello" )
> print( t, caption.placement = 'top',comment = FALSE )
> ```
>
> But if I change to
>
> t     <- xtable(df, caption = variableName)
>
> wich is what I really want it retuns a pandoc error:
>
> ! Missing $ inserted.
> <inserted text>
>                  $
> l.112 \caption{V03_1}
>
> pandoc: Error producing PDF from TeX source
> Error: pandoc document conversion failed with error 43
>
> I don't know why because variableName is also a character variable!
>
> Any idea? Thank you very much!
>
>
> ------
> Aurora Gonz?lez Vidal
>
> Secci?n Apoyo Estad?stico.
> Servicio de Apoyo a la Investigaci?n (SAI).
> Vicerrectorado de Investigaci?n.
> Universidad de Murcia
> Edif. SACE . Campus de Espinardo.
> 30100 Murcia
>
> @. aurora.gonzalez2 at um.es
> T. 868 88 7315
> F. 868 88 7302
> www.um.es/sai
> www.um.es/ae
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5645 / Virus Database: 4299/9172 - Release Date: 02/24/15
>

-- 
Michael
http://www.dewey.myzen.co.uk


From alaios at yahoo.com  Tue Feb 24 15:52:40 2015
From: alaios at yahoo.com (Alaios)
Date: Tue, 24 Feb 2015 14:52:40 +0000 (UTC)
Subject: [R] Parallel for that does not keep the results
Message-ID: <1696965607.5162560.1424789560251.JavaMail.yahoo@mail.yahoo.com>

Hi all,I am working in a multi core machine and I am trying to make some parallel code to speed up the process.
I have seen already the foreach packet but it looks like that it always combine the results on a list. My case though is simpler since I am plotting and saving in external files, inside the loop, and thus I do not need to keep anything from the loop.My code looks like
??? expandMeanSigmaOn<-expand.grid(1:100,100:200,5:10,5000:6000)
?? for (i in 1:length(expandMeanSigmaOn$Var1)){
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? mean1<-expandMeanSigmaOn$Var1[i]
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? mean2<-expandMeanSigmaOn$Var2[i]
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? sd1<-expandMeanSigmaOn$Var3[i]
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? sd2<-expandMeanSigmaOn$Var4[i]
??? ??? ??? ??? ??? ??? ??? ??? ?? 
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? fitcass1<-mix(mydata,mixparam(c(mean1,mean2),(c(sd1,sd2)),"gamma")))
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? pdf(file=paste(filename,"ON.pdf",sep=""));plot(fitcass1);dev.off() # plotting and saving
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? save(OnFitList,file=paste(filename,"ON.Rdata",sep="")) # plotting and saving
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? }
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? }
?}

as you can see from the code above, given some input values I am trying some fits, which then I am saving the results. Do you think that the foreach packaget would be suitable (since the returning list can grow very large and eat up memory) or should I try some alternative package?
I would like to thank you in advance for your replyRegardsAlex

	[[alternative HTML version deleted]]


From uma at sophie.unam.mx  Tue Feb 24 16:17:07 2015
From: uma at sophie.unam.mx (Ulises M. Alvarez)
Date: Tue, 24 Feb 2015 09:17:07 -0600
Subject: [R] xtable caption knitr
In-Reply-To: <20150224121656.Horde.rw7cAuvkbL8LfWtYSlAj3g1@webmail.um.es>
References: <20150224121656.Horde.rw7cAuvkbL8LfWtYSlAj3g1@webmail.um.es>
Message-ID: <54EC95F3.6090107@sophie.unam.mx>

On 02/24/2015 05:16 AM, AURORA GONZALEZ VIDAL wrote:
> I have a problem with the caption option on the xtable function.
>
> Using Rmarkdown, knitr generates correctly a pdf when I write something
> like this:
>
> ```{r xtable, results="asis"}
> library( xtable )
> variableName  <- c( "V03_1" )
> age <- c( rep(1,10),rep(2,10),rep(3,10) )
> gender <- c( rep("m",15), rep("f",15) )
>
> df <- data.frame( age, gender )
>
> t     <- xtable( df, caption = "hello" )
> print( t, caption.placement = 'top',comment = FALSE )
> ```
>
> But if I change to
>
> t     <- xtable(df, caption = variableName)
>
> wich is what I really want it retuns a pandoc error

Hello:

It is, indeed, the underscore in the variable name. You should define it as:

variableName  <- c("V03\\_1")

And now:

t <- xtable(df, caption = variableName)
print(t, caption.placement = 'top',comment = FALSE)

Will work.

-- 
Ulises M. Alvarez
http://sophie.unam.mx/


From ramiro at precisionbioassay.com  Tue Feb 24 17:34:13 2015
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Tue, 24 Feb 2015 16:34:13 +0000
Subject: [R] Not finding superclass in library
In-Reply-To: <alpine.OSX.2.00.1502231906010.2437@charles-berrys-macbook.local>
References: <C7338A7EFF31BB4D831BB06C008877897DB9606A@MBX023-W1-CA-2.exch023.domain.local>,
	<54EB9086.6090201@auckland.ac.nz>
	<C7338A7EFF31BB4D831BB06C008877897DB96081@MBX023-W1-CA-2.exch023.domain.local>,
	<alpine.OSX.2.00.1502231906010.2437@charles-berrys-macbook.local>
Message-ID: <C7338A7EFF31BB4D831BB06C008877897DB970B4@MBX023-W1-CA-2.exch023.domain.local>

Thank you so much for your help.  Will aim at making a reproducible example next time, maybe if I had done that I would realized that the issue was that I was using Rscript, which does not load the methods library, which was the source of the problem.
________________________________________
From: Charles C. Berry [ccberry at ucsd.edu]
Sent: Monday, February 23, 2015 10:20 PM
To: Ramiro Barrantes
Cc: Rolf Turner; r-help at r-project.org
Subject: Re: Not finding superclass in library

On Mon, 23 Feb 2015, Ramiro Barrantes wrote:

> Thank you for pointing this out.  I had no idea about the distinction
> but there are some good references on the matter
> (http://www.r-bloggers.com/packages-v-libraries-in-r/).  I am pasting
> the corrected version below, any suggestions appreciated:

>

> I have a package that I created that defines a parent class,
> assayObject.

>
> I created other classes that inherit from it, say assayObjectDemo.
> Each one of those classes I wanted to make in its own directory separate
> from where the assayObject is defined (there are reasons for that).

>
> But now if I do:
>
> library(assayObject)  #<--- where parent object is defined
> source("assayObjectDemo.R")
>
> where assayObjectDemo.R is just:
>
> setClass("assayObjectDemo",contains="assayObject")
> createDemoAssayObject <- function() {
>  df <- data.frame()
>  assay<-new(Class="assayObjectDemo")
>  assay
> }
>
> I get:
>
> Error in reconcilePropertiesAndPrototype(name, slots, prototype, superClasses,  :
>  no definition was found for superclass ?assayObject? in the specification of class ?assayObjectDemo?
>
> What can I do?


Start with a reproducible example. Here is one:

   library(Matrix)
   tmpf <- tempfile(fileext=".R")
   cat('setClass("MatrixDemo",contains="Matrix")',file=tmpf)
   source(tmpf)
   slotNames("MatrixDemo")

And it produces the expected output without error:

  [1] "Dim"      "Dimnames"

Since this works fine for a widely used package and fails for your
(unspecified) package, I suspect there is a problem with your package.

If I had to guess, I'd say it is a NAMESPACE issue. Be sure your
exportClasses directive is correctly formed per Section 1.5.6
"Namespaces with S4 classes and methods" of R-exts.

r-devel might be a better venue for this discussion.

HTH,

Chuck


From lnguye9 at uwo.ca  Tue Feb 24 15:11:13 2015
From: lnguye9 at uwo.ca (Linh Nguyen Vaccarello)
Date: Tue, 24 Feb 2015 09:11:13 -0500
Subject: [R]  decimal places
Message-ID: <CAKUGcucFu3UaXH+2pb-JHD+Kh9crDjM1XzTLf5dFYvyO6rKz8g@mail.gmail.com>

I am very new to R and I'm trying to increase my decimal places (from 2 to
4) for this code:

>with(longitudinal, pairwise.wilcox.test(DV, Time,
                                        p.adjust.method="holm",
                                        paired=TRUE))

Right now the output is:

Pairwise comparisons using Wilcoxon signed rank test

data:  DV and Time

    yr15 yr2  yr5
yr2 0.03 -    -
yr5 0.03 0.05 -
yr8 0.03 0.05 0.03

I have tried various codes and they didn't work:
options(digits=4)
with(longitudinal, pairwise.wilcox.test(DV, Time,
                                        p.adjust.method="holm",
                                        paired=TRUE))

> with(longitudinal, pairwise.wilcox.test(DV, Time,
+ p.adjust.method="holm",
+ paired=TRUE),
+ options(digits=4))

> with(longitudinal, pairwise.wilcox.test(DV, Time,
+ p.adjust.method="holm",
+ paired=TRUE,
+ digits=4))

> with(longitudinal, pairwise.wilcox.test(DV, Time,
+ p.adjust.method="holm",
+ paired=TRUE),
+ signif(digits=4))

thanks,
Linh

	[[alternative HTML version deleted]]


From ronflatau at gmail.com  Tue Feb 24 16:32:08 2015
From: ronflatau at gmail.com (Ron Flatau)
Date: Tue, 24 Feb 2015 17:32:08 +0200
Subject: [R] help
Message-ID: <CADzHNWE+wqCT2VhFzU8fn4uEjSjvFRMoNCwDXTDnTTC_R0no4g@mail.gmail.com>

I try to create a dot plot loop for 6 protein, that mean that i want to do
dot plot to 36 pairs of protein in a loop
library(seqinr)
Seq1 <- read.fasta(file ="C:/D.fasta")
Protinename1 <- Seq1[[1]]
Protinename2 <- Seq1[[2]]
Protinename3 <- Seq1[[3]]
Protinename4 <- Seq1[[4]]
Protinename5 <- Seq1[[5]]
Protinename6 <- Seq1[[6]]
dotPlot(Protinename1 , Protinename3)

i have no idea how to create a loop for this script

thank you for your help

	[[alternative HTML version deleted]]


From maechler at lynne.stat.math.ethz.ch  Tue Feb 24 18:09:32 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Tue, 24 Feb 2015 18:09:32 +0100
Subject: [R] Not finding superclass in library
In-Reply-To: <C7338A7EFF31BB4D831BB06C008877897DB970B4@MBX023-W1-CA-2.exch023.domain.local>
References: <C7338A7EFF31BB4D831BB06C008877897DB9606A@MBX023-W1-CA-2.exch023.domain.local>
	<54EB9086.6090201@auckland.ac.nz>
	<C7338A7EFF31BB4D831BB06C008877897DB96081@MBX023-W1-CA-2.exch023.domain.local>
	<alpine.OSX.2.00.1502231906010.2437@charles-berrys-macbook.local>
	<C7338A7EFF31BB4D831BB06C008877897DB970B4@MBX023-W1-CA-2.exch023.domain.local>
Message-ID: <21740.45132.799421.335837@stat.math.ethz.ch>

>>>>> "RB" == Ramiro Barrantes <ramiro at precisionbioassay.com>
>>>>>     on Tue, 24 Feb 2015 16:34:13 +0000 writes:

    RB> Thank you so much for your help.  Will aim at making a
    RB> reproducible example next time, maybe if I had done that
    RB> I would realized that the issue was that I was using
    RB> Rscript, which does not load the methods library, which
    RB> was the source of the problem.

But Ramiro,  you already forgot what you learned from Rolf:

> fortune(161)

(3 times...rrrrgh...) and why do you think the mailing list is called R-*packages* ???????????
Please do
  for(i in 1:20) cat("It's a package!\n")
   -- Martin Maechler (after a newly released *package* has been called *library* three times in its
      announcement on R-packages)
      R-help (March 2006)

> 

=== :-) ===

Martin


From maechler at lynne.stat.math.ethz.ch  Tue Feb 24 18:07:48 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Tue, 24 Feb 2015 18:07:48 +0100
Subject: [R] Not finding superclass in library
In-Reply-To: <54EB9086.6090201@auckland.ac.nz>
References: <C7338A7EFF31BB4D831BB06C008877897DB9606A@MBX023-W1-CA-2.exch023.domain.local>
	<54EB9086.6090201@auckland.ac.nz>
Message-ID: <21740.45028.448694.848130@stat.math.ethz.ch>

>>>>> Rolf Turner <r.turner at auckland.ac.nz>
>>>>>     on Tue, 24 Feb 2015 09:41:42 +1300 writes:

    > On 24/02/15 09:35, Ramiro Barrantes wrote:
    >> Hello,
    >> 
    >> I have a library that I created .....

    > <SNIP>

    > No you ***DO NOT***.  You have a ***PACKAGE***.  If you
    > cannot even get your terminology straight, what hope is
    > there for you?

    > cheers,

    > Rolf Turner

Thank you, Rolf!   "You saved my day" as the say  ;-)

 if(!require("fortunes")) install.packages("fortunes")
 fortune(58)
 fortune(161)

Regards,
Martin


From murdoch.duncan at gmail.com  Tue Feb 24 18:24:14 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 24 Feb 2015 12:24:14 -0500
Subject: [R] decimal places
In-Reply-To: <CAKUGcucFu3UaXH+2pb-JHD+Kh9crDjM1XzTLf5dFYvyO6rKz8g@mail.gmail.com>
References: <CAKUGcucFu3UaXH+2pb-JHD+Kh9crDjM1XzTLf5dFYvyO6rKz8g@mail.gmail.com>
Message-ID: <54ECB3BE.4030000@gmail.com>

On 24/02/2015 9:11 AM, Linh Nguyen Vaccarello wrote:
> I am very new to R and I'm trying to increase my decimal places (from 2 to
> 4) for this code:
> 
>> with(longitudinal, pairwise.wilcox.test(DV, Time,
>                                         p.adjust.method="holm",
>                                         paired=TRUE))
> 
> Right now the output is:
> 
> Pairwise comparisons using Wilcoxon signed rank test
> 
> data:  DV and Time
> 
>     yr15 yr2  yr5
> yr2 0.03 -    -
> yr5 0.03 0.05 -
> yr8 0.03 0.05 0.03

Many functions in R produce objects with a class, and there are special
methods to print many classes.  In the case of pairwise.wilcox.test the
object produced is of class "pairwise.htest".  You can see the code using

stats:::print.pairwise.htest

and you'll see it hard-codes 2 significant digits.  (Which surprises me
a bit, but I guess your p-values are all 0.030 and 0.050.)

You can edit the definition for a temporary change:

print.pairwise.htest <- function (x, digits = 5, ...)
{
    cat("\n\tPairwise comparisons using", x$method, "\n\n")
    cat("data: ", x$data.name, "\n\n")
    pp <- format.pval(x$p.value, digits, na.form = "-")
    attributes(pp) <- attributes(x$p.value)
    print(pp, quote = FALSE, ...)
    cat("\nP value adjustment method:", x$p.adjust.method, "\n")
    invisible(x)
}

Your definition of this method will override the default one, so
defining that function is enough, R will call it for printing.

Duncan Murdoch
> 
> I have tried various codes and they didn't work:
> options(digits=4)
> with(longitudinal, pairwise.wilcox.test(DV, Time,
>                                         p.adjust.method="holm",
>                                         paired=TRUE))
> 
>> with(longitudinal, pairwise.wilcox.test(DV, Time,
> + p.adjust.method="holm",
> + paired=TRUE),
> + options(digits=4))
> 
>> with(longitudinal, pairwise.wilcox.test(DV, Time,
> + p.adjust.method="holm",
> + paired=TRUE,
> + digits=4))
> 
>> with(longitudinal, pairwise.wilcox.test(DV, Time,
> + p.adjust.method="holm",
> + paired=TRUE),
> + signif(digits=4))
> 
> thanks,
> Linh
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jholtman at gmail.com  Tue Feb 24 19:26:51 2015
From: jholtman at gmail.com (jim holtman)
Date: Tue, 24 Feb 2015 13:26:51 -0500
Subject: [R] help
In-Reply-To: <CADzHNWE+wqCT2VhFzU8fn4uEjSjvFRMoNCwDXTDnTTC_R0no4g@mail.gmail.com>
References: <CADzHNWE+wqCT2VhFzU8fn4uEjSjvFRMoNCwDXTDnTTC_R0no4g@mail.gmail.com>
Message-ID: <CAAxdm-7eFUtRE4+oOJV6jujM4Ye0SHsT5yEtsxMBdyDtgiEcnQ@mail.gmail.com>

Where did 36 pairs come from?  6 things taken 2 at a time is 15 pairs.
Here is an example of how it might be done:

library(seqinr)
Seq1 <- read.fasta(file ="C:/D.fasta")
# are you doing each pair so that you have 6 taken 2 at a time for 15 plots?
pairs <- combn(6, 2)  # create the pairings
# now the loop for the plots
for (col in seq(ncol(pairs))){
    dotPlot(Seq1[[pairs[1, col]]], Seq1[[pairs[2, col]]])
}


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Tue, Feb 24, 2015 at 10:32 AM, Ron Flatau <ronflatau at gmail.com> wrote:
> I try to create a dot plot loop for 6 protein, that mean that i want to do
> dot plot to 36 pairs of protein in a loop
> library(seqinr)
> Seq1 <- read.fasta(file ="C:/D.fasta")
> Protinename1 <- Seq1[[1]]
> Protinename2 <- Seq1[[2]]
> Protinename3 <- Seq1[[3]]
> Protinename4 <- Seq1[[4]]
> Protinename5 <- Seq1[[5]]
> Protinename6 <- Seq1[[6]]
> dotPlot(Protinename1 , Protinename3)
>
> i have no idea how to create a loop for this script
>
> thank you for your help
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hennerw at gmail.com  Tue Feb 24 19:24:17 2015
From: hennerw at gmail.com (William Randall Henner)
Date: Tue, 24 Feb 2015 10:24:17 -0800
Subject: [R] Environment error in the car package Anova.lme function
Message-ID: <CAAs9cAy5fos7Wt6E-7Rc7JiXM9Q1eKScb7cUoqgbYUS+Cxwgqw@mail.gmail.com>

When I call the Anova function on a lme object from inside a function
environment I get an error:

Error in eval(expr, envir, enclos) : object 'y' not found


However, if I call the exact same code in the global environment there is
no error. My theory is that for some reason the Anova.lme function always
searches the global environment for variables rather than starting in its
parent environment.

Since the function runs correctly on lmerMod objects, and I typically
prefer lme4 to nlme this is just of academic interest.

#########
# Steps to reproduce the error

# Load Packages
library(car)
library(lme4)
library(nlme)

# Create random data.
Y <- rnorm(50)
X <- rnorm(50)
Subject <- factor(rep(LETTERS[1:5],each=10))

# Define function to fit a MEM and run the ANOVA.
fun <- function(y,x,sub){
  #mod <- lmer(y ~ x +(1 | sub) )
  mod <- lme(y~x,random=~1|sub)
  print('lme model ran successfully.')
  Anova(mod)
  print('Anova function ran successfully.')
}

# Function produces an error message.
fun(Y,X,Subject)

# if run outside of a function, it runs cleanly.
mod <- lme(Y~X,random=~1|Subject)
Anova(mod)

mod1 <- lmer(Y ~ X +(1 | Subject) )
Anova(mod1)

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Feb 24 21:47:56 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 24 Feb 2015 12:47:56 -0800
Subject: [R] Environment error in the car package Anova.lme function
In-Reply-To: <CAAs9cAy5fos7Wt6E-7Rc7JiXM9Q1eKScb7cUoqgbYUS+Cxwgqw@mail.gmail.com>
References: <CAAs9cAy5fos7Wt6E-7Rc7JiXM9Q1eKScb7cUoqgbYUS+Cxwgqw@mail.gmail.com>
Message-ID: <E27F7E20-3754-4AE0-A35D-09B92FCDEECE@comcast.net>


On Feb 24, 2015, at 10:24 AM, William Randall Henner wrote:

> When I call the Anova function on a lme object from inside a function
> environment I get an error:
> 
> Error in eval(expr, envir, enclos) : object 'y' not found
> 
> 
> However, if I call the exact same code in the global environment there is
> no error. My theory is that for some reason the Anova.lme function always
> searches the global environment for variables rather than starting in its
> parent environment.
> 

Regression functions are generally set up to first look for the tokens/symbols that are in the formulae first in that data argument column-names and then in the calling environment.  It's not finding an "x" or a "y" in either of those locations (R being case sensitive). You _should_ try to pass a dataframe with column-names that match the tokens in the formula argument exactly to a `data=` parameter.


> Since the function runs correctly on lmerMod objects, and I typically
> prefer lme4 to nlme this is just of academic interest.
> 
> #########
> # Steps to reproduce the error
> 
> # Load Packages
> library(car)
> library(lme4)
> library(nlme)
> 
> # Create random data.
> Y <- rnorm(50)
> X <- rnorm(50)
> Subject <- factor(rep(LETTERS[1:5],each=10))
> 
> # Define function to fit a MEM and run the ANOVA.
> fun <- function(y,x,sub){
>  #mod <- lmer(y ~ x +(1 | sub) )
>  mod <- lme(y~x,random=~1|sub)
>  print('lme model ran successfully.')
>  Anova(mod)
>  print('Anova function ran successfully.')
> }
> 
> # Function produces an error message.
> fun(Y,X,Subject)
> 
> # if run outside of a function, it runs cleanly.
> mod <- lme(Y~X,random=~1|Subject)
> Anova(mod)
> 
> mod1 <- lmer(Y ~ X +(1 | Subject) )
> Anova(mod1)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From marek.r at lutonsky.net  Tue Feb 24 21:08:40 2015
From: marek.r at lutonsky.net (marekl)
Date: Tue, 24 Feb 2015 12:08:40 -0800 (PST)
Subject: [R] One column listing on wide monitors too
Message-ID: <1424808520722-4703781.post@n4.nabble.com>

Hi,

it is probably very basic question, but I can't get answer still.

R shows listings in more columns on wider monitors. Like on this picture:
http://i.imgur.com/GLF70r9.png

Is there a way to set R to show listings like this, in one column only?

[1] "String 1"
[2] "String 2"
[3] "String 3"
...
[16] "String 16"

Thank you



--
View this message in context: http://r.789695.n4.nabble.com/One-column-listing-on-wide-monitors-too-tp4703781.html
Sent from the R help mailing list archive at Nabble.com.


From eike.petersen at fp-tga.de  Tue Feb 24 22:13:43 2015
From: eike.petersen at fp-tga.de (Eike Petersen)
Date: Tue, 24 Feb 2015 22:13:43 +0100
Subject: [R] R crashes with "Error in UseMethod("depth")" when resizing
 ggplot windows
Message-ID: <54ECE987.9030906@fp-tga.de>

Hello everyone,

Quite frequently I encounter crashes when resizing ggplot windows. The
error message is always as follows:

> Error in UseMethod("depth") :
>  no applicable method for 'depth' applied to an object of class "NULL"
>
> Process R exited abnormally with code 255 at Tue Feb 24 21:51:18 2015

The error seems to occur rather unpredictably when I do several
resizings, e.g. moving a plot window from one monitor to another using
Windows+Arrow Key several times. It only seems to happen when plotting
rather large data frames.

I was about to file this as a ggplot2 issue, but then I realized that I
can't reproduce it using RStudio - normally, I use emacs/ESS (on Windows
7). So maybe this is a bug related to the "plot engine"...? The problem
is that I can't even do a traceback(), since R is crashed.

How should I proceed? Are there any other options to retrieve valuable
debug information?

Kind regards,
Eike


From pdalgd at gmail.com  Tue Feb 24 22:56:09 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 24 Feb 2015 22:56:09 +0100
Subject: [R] decimal places
In-Reply-To: <54ECB3BE.4030000@gmail.com>
References: <CAKUGcucFu3UaXH+2pb-JHD+Kh9crDjM1XzTLf5dFYvyO6rKz8g@mail.gmail.com>
	<54ECB3BE.4030000@gmail.com>
Message-ID: <ED33BB43-55F3-43AE-A14A-77B2C13C7363@gmail.com>


> On 24 Feb 2015, at 18:24 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> stats:::print.pairwise.htest
> 
> and you'll see it hard-codes 2 significant digits.  (Which surprises me
> a bit, but I guess your p-values are all 0.030 and 0.050.)

It was a decade and a half ago, but I think the general idea of the hardcoded value was that by default you want a display as compact as possible, and 2 digits after adjustment for multiple testing should be enough for most. If you want more, just extract the p.value component and print it to whatever precision you need. 


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dcarlson at tamu.edu  Tue Feb 24 22:59:28 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 24 Feb 2015 21:59:28 +0000
Subject: [R] One column listing on wide monitors too
In-Reply-To: <1424808520722-4703781.post@n4.nabble.com>
References: <1424808520722-4703781.post@n4.nabble.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D655B39@mb02.ads.tamu.edu>

Here are several ways:

> a <- paste("String", 1:16)
> a
 [1] "String 1"  "String 2"  "String 3"  "String 4"  "String 5"  "String 6" 
 [7] "String 7"  "String 8"  "String 9"  "String 10" "String 11" "String 12"
[13] "String 13" "String 14" "String 15" "String 16"
> matrix(a, length(a))
      [,1]       
 [1,] "String 1" 
 [2,] "String 2" 
. . .
[15,] "String 15"
[16,] "String 16"
> t(t(a))
      [,1]       
 [1,] "String 1" 
 [2,] "String 2" 
. . . 
[15,] "String 15"
[16,] "String 16"
> b <- a
> dim(b) <- c(16, 1)
> b
      [,1]       
 [1,] "String 1" 
 [2,] "String 2" 
. . .
[15,] "String 15"
[16,] "String 16"
> cat(a, sep="\n") # But no numbering
String 1
String 2
. . .
String 15
String 16

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of marekl
Sent: Tuesday, February 24, 2015 2:09 PM
To: r-help at r-project.org
Subject: [R] One column listing on wide monitors too

Hi,

it is probably very basic question, but I can't get answer still.

R shows listings in more columns on wider monitors. Like on this picture:
http://i.imgur.com/GLF70r9.png

Is there a way to set R to show listings like this, in one column only?

[1] "String 1"
[2] "String 2"
[3] "String 3"
...
[16] "String 16"

Thank you



--
View this message in context: http://r.789695.n4.nabble.com/One-column-listing-on-wide-monitors-too-tp4703781.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Feb 25 00:23:33 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 24 Feb 2015 18:23:33 -0500
Subject: [R] R crashes with "Error in UseMethod("depth")" when resizing
 ggplot windows
In-Reply-To: <54ECE987.9030906@fp-tga.de>
References: <54ECE987.9030906@fp-tga.de>
Message-ID: <54ED07F5.7070004@gmail.com>

On 24/02/2015 4:13 PM, Eike Petersen wrote:
> Hello everyone,
> 
> Quite frequently I encounter crashes when resizing ggplot windows. The
> error message is always as follows:
> 
>> Error in UseMethod("depth") :
>>  no applicable method for 'depth' applied to an object of class "NULL"
>>
>> Process R exited abnormally with code 255 at Tue Feb 24 21:51:18 2015
> 
> The error seems to occur rather unpredictably when I do several
> resizings, e.g. moving a plot window from one monitor to another using
> Windows+Arrow Key several times. It only seems to happen when plotting
> rather large data frames.
> 
> I was about to file this as a ggplot2 issue, but then I realized that I
> can't reproduce it using RStudio - normally, I use emacs/ESS (on Windows
> 7). So maybe this is a bug related to the "plot engine"...? The problem
> is that I can't even do a traceback(), since R is crashed.
> 
> How should I proceed? Are there any other options to retrieve valuable
> debug information?

It's not easy, but you can run R under a debugger, and it will show you
the location of the crash.  As far as I know only gdb supports debugging
R on Windows (there's a copy in the Rtools collection), but perhaps that
will change now that Microsoft has purchased Revolution Analytics.

Duncan Murdoch


From thanoon.younis80 at gmail.com  Wed Feb 25 04:26:59 2015
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Wed, 25 Feb 2015 06:26:59 +0300
Subject: [R] problem in R2JAGS
Message-ID: <CABLo8nG=Xfa4jkenDV8ocgF-yX9qd8bSgXRXaSmO5m0G1T3iPg@mail.gmail.com>

Hi everyone,

I need your help to correct R code using R2JAGS. The problem is when i
defined testJAGSdata which contains on all the data as following


testJAGSdata <- read.bugsdata("bugsdata.R")
bugsdata.R<-read.table("F:/JAGS/bugsdata.R")

i found this error

> testJAGSdata <- read.bugsdata("bugsdata.R")
Error in file(filename, "r") : cannot open the connection
In addition: Warning message:
In file(filename, "r") :
  cannot open file 'bugsdata.R': No such file or directory
> bugsdata.R<-read.table("F:/JAGS/bugsdata.R")
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
 :
  line 2 did not have 3 elements

and

Error in jags(data = testJAGSdata, inits = testJAGSinits, model.file =
"testJAGS.txt",  :
  object 'testJAGSdata' not found

How can i solve this problem? because i think the problem in bugsdata.R but
this file works correctly.

Any help would be highly appreciated

Many thanks in advance



-- 
Thanoon Y. Thanoon
PhD Candidate
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From yanlinlin82 at gmail.com  Wed Feb 25 02:36:10 2015
From: yanlinlin82 at gmail.com (=?UTF-8?B?TGlubGluIFlhbiAo6aKc5p6X5p6XKQ==?=)
Date: Wed, 25 Feb 2015 09:36:10 +0800
Subject: [R] One column listing on wide monitors too
In-Reply-To: <1424808520722-4703781.post@n4.nabble.com>
References: <1424808520722-4703781.post@n4.nabble.com>
Message-ID: <CA+YjnUsATvk8xRUO1iHhKSiqZSVKUZo=57WbFriO9zqoMX7L9Q@mail.gmail.com>

options(width=10)

On Wed, Feb 25, 2015 at 4:08 AM, marekl <marek.r at lutonsky.net> wrote:
> Hi,
>
> it is probably very basic question, but I can't get answer still.
>
> R shows listings in more columns on wider monitors. Like on this picture:
> http://i.imgur.com/GLF70r9.png
>
> Is there a way to set R to show listings like this, in one column only?
>
> [1] "String 1"
> [2] "String 2"
> [3] "String 3"
> ...
> [16] "String 16"
>
> Thank you
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/One-column-listing-on-wide-monitors-too-tp4703781.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From _ at tnhh.net  Wed Feb 25 03:28:26 2015
From: _ at tnhh.net (Huan Truong)
Date: Tue, 24 Feb 2015 20:28:26 -0600
Subject: [R] Getting Rmarkdown to generate custom LaTEX environment
Message-ID: <CAJtgXV0BxrsPfXNnA_YKVqBCmXVvzOLrXfBk4bPq+2cO2izXcw@mail.gmail.com>

Hi all,

I was struggling trying to make my Rmarkdown document to generate

\begin{figure*}

instead of

\begin{figure}

So that the figure spans on two columns (I'm using a custom template).

in my figure. I have read the Rmarkdown Reference Guide, and searched
for it on StackOverflow, and the general idea seems to be that I could
somehow pass the fig.env variable to the figure, but I have tried it
with no success: Something like this still doesn't have any effect
whatsoever on the latex code generated:

```{r test-plot, echo=FALSE, fig.cap = "Test
plot.\\label{fig:test-plot}", fig.env='figure*' }
options(fig.env='figure*')
plot(blah)
```

I know I must have missed something but couldn't figure out what I'm
missing after hours of struggling. Any help is much appreciated.

I have a smaller problem where I want to customize the [htbp] option
of the figure, and facing the same problem.

Cheers,
- Huan.






-- 

Eccentric Graduate Student
Google Talk/Jabber huant at tnhh.net - Website tnhh.net - Phone 1-858-848-ROFL


From pnsinha68 at gmail.com  Wed Feb 25 08:32:58 2015
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Wed, 25 Feb 2015 13:02:58 +0530
Subject: [R] Barplot
Message-ID: <CADcgpJcegW60jg17vR=3cKarZgpSJ+uUM5XdhXZVx7ZjbeeweA@mail.gmail.com>

i want to plot the following data in barplot

Year Gender revenue
2001 M       100
2001 F       150
2002 M        75
2002 F        200
2003 M        150
2003 F         75

I want to compare performance of gender in year wise fashion .
How to do ?

Parth


From marc_grt at yahoo.fr  Wed Feb 25 08:51:20 2015
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 25 Feb 2015 08:51:20 +0100
Subject: [R] HELP asin transformation
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A03AA9C@mail-mbx-03.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A03AA9C@mail-mbx-03.UNINE.CH>
Message-ID: <54ED7EF8.6000000@yahoo.fr>

Le 22/02/2015 19:28, CHIRIBOGA Xavier a ?crit :
> Dear all,
>
>
>
> I attempted to transform my data using "asin" but a WARNING message appears:
>
>
>
> dat1$Abu.tr<-asin(sqrt(dat1$Abundance/100))
> Warning message:
> In asin(sqrt(dat1$Abundance/100)) : NaNs produced
>
>
>
> What does it mean? Is it a problem? How can I solve this?
>
>
>
One or more of your Abundance data is negative, higher than 100 or 
non-finite:

 > asin(seq(from=-2, to=2, by=0.1))
  [1]        NaN        NaN        NaN        NaN        NaN NaN        NaN
  [8]        NaN        NaN        NaN -1.5707963 -1.1197695 -0.9272952 
-0.7753975
[15] -0.6435011 -0.5235988 -0.4115168 -0.3046927 -0.2013579 -0.1001674  
0.0000000
[22]  0.1001674  0.2013579  0.3046927  0.4115168  0.5235988 0.6435011  
0.7753975
[29]  0.9272952  1.1197695  1.5707963        NaN        NaN NaN        NaN
[36]        NaN        NaN        NaN        NaN        NaN NaN
Message d'avis :
In asin(seq(from = -2, to = 2, by = 0.1)) : production de NaN
 > sqrt(seq(from=-2, to=2, by=0.1))
  [1]       NaN       NaN       NaN       NaN       NaN NaN       
NaN       NaN
  [9]       NaN       NaN       NaN       NaN       NaN NaN       
NaN       NaN
[17]       NaN       NaN       NaN       NaN 0.0000000 0.3162278 
0.4472136 0.5477226
[25] 0.6324555 0.7071068 0.7745967 0.8366600 0.8944272 0.9486833 
1.0000000 1.0488088
[33] 1.0954451 1.1401754 1.1832160 1.2247449 1.2649111 1.3038405 
1.3416408 1.3784049
[41] 1.4142136
Message d'avis :
In sqrt(seq(from = -2, to = 2, by = 0.1)) : production de NaN

But take a look at this also about arcsine transformation:
Warton, D.I., Hui, F.K.C., 2011. The arcsine is asinine: the analysis of 
proportions in ecology. Ecology 92, 3-10.

Sincerely,

Marc


From petr.pikal at precheza.cz  Wed Feb 25 08:53:36 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 25 Feb 2015 07:53:36 +0000
Subject: [R] Barplot
In-Reply-To: <CADcgpJcegW60jg17vR=3cKarZgpSJ+uUM5XdhXZVx7ZjbeeweA@mail.gmail.com>
References: <CADcgpJcegW60jg17vR=3cKarZgpSJ+uUM5XdhXZVx7ZjbeeweA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C21672@SRVEXCHMBX.precheza.cz>

Hi

Homework? We do not solve your homeworks here.

barplot(temp$revenue)

and play with col and names.arg together with ?interaction of Year and Gender

Or use ggplot2

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Partha
> Sinha
> Sent: Wednesday, February 25, 2015 8:33 AM
> To: r-help
> Subject: [R] Barplot
>
> i want to plot the following data in barplot
>
> Year Gender revenue
> 2001 M       100
> 2001 F       150
> 2002 M        75
> 2002 F        200
> 2003 M        150
> 2003 F         75
>
> I want to compare performance of gender in year wise fashion .
> How to do ?
>
> Parth
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From marc.girondot at u-psud.fr  Wed Feb 25 08:50:42 2015
From: marc.girondot at u-psud.fr (Marc Girondot)
Date: Wed, 25 Feb 2015 08:50:42 +0100
Subject: [R] HELP asin transformation
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A03AA9C@mail-mbx-03.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A03AA9C@mail-mbx-03.UNINE.CH>
Message-ID: <54ED7ED2.5050108@u-psud.fr>

Le 22/02/2015 19:28, CHIRIBOGA Xavier a ?crit :
> Dear all,
>
>
>
> I attempted to transform my data using "asin" but a WARNING message appears:
>
>
>
> dat1$Abu.tr<-asin(sqrt(dat1$Abundance/100))
> Warning message:
> In asin(sqrt(dat1$Abundance/100)) : NaNs produced
>
>
>
> What does it mean? Is it a problem? How can I solve this?
>
>
>
One or more of your Abundance data is negative, higher than 100 or 
non-finite:

 > asin(seq(from=-2, to=2, by=0.1))
  [1]        NaN        NaN        NaN        NaN        NaN NaN        NaN
  [8]        NaN        NaN        NaN -1.5707963 -1.1197695 -0.9272952 
-0.7753975
[15] -0.6435011 -0.5235988 -0.4115168 -0.3046927 -0.2013579 -0.1001674  
0.0000000
[22]  0.1001674  0.2013579  0.3046927  0.4115168  0.5235988 0.6435011  
0.7753975
[29]  0.9272952  1.1197695  1.5707963        NaN        NaN NaN        NaN
[36]        NaN        NaN        NaN        NaN        NaN NaN
Message d'avis :
In asin(seq(from = -2, to = 2, by = 0.1)) : production de NaN
 > sqrt(seq(from=-2, to=2, by=0.1))
  [1]       NaN       NaN       NaN       NaN       NaN NaN       
NaN       NaN
  [9]       NaN       NaN       NaN       NaN       NaN NaN       
NaN       NaN
[17]       NaN       NaN       NaN       NaN 0.0000000 0.3162278 
0.4472136 0.5477226
[25] 0.6324555 0.7071068 0.7745967 0.8366600 0.8944272 0.9486833 
1.0000000 1.0488088
[33] 1.0954451 1.1401754 1.1832160 1.2247449 1.2649111 1.3038405 
1.3416408 1.3784049
[41] 1.4142136
Message d'avis :
In sqrt(seq(from = -2, to = 2, by = 0.1)) : production de NaN

But take a look at this also about arcsine transformation:
Warton, D.I., Hui, F.K.C., 2011. The arcsine is asinine: the analysis of 
proportions in ecology. Ecology 92, 3-10.

Sincerely,

Marc


From petr.pikal at precheza.cz  Wed Feb 25 09:10:27 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 25 Feb 2015 08:10:27 +0000
Subject: [R] Apply t-test on list in R
In-Reply-To: <2072605676.295192.1424231184985.JavaMail.yahoo@mail.yahoo.com>
References: <2072605676.295192.1424231184985.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C21695@SRVEXCHMBX.precheza.cz>

Hi

I did not seen any answer so I try one.

If you have data frames organised in list I would use a for cycle.

If your list is named mylist something like

result <- list()
k=0
for(i in n:m) {
k=k+1
result[[k]] <- t.test(mylist[[x]], mylist[[i]])
}

where x is a number for the one data frame you want to compare with others and m, n are numbers selecting a range where are located data frames for comparison.

You can use regular expressions to select data frames but it is not my strength.

Cheers
Petr



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Zilefac
> Elvis via R-help
> Sent: Wednesday, February 18, 2015 4:46 AM
> To: R. Help
> Subject: [R] Apply t-test on list in R
>
> I have a list object in R with dataframe names as:
>
>
> "pav_DJF_histo.csv"        "pav_DJF_rcp26_2040s.csv"
> "pav_DJF_rcp26_2080s.csv"
> "pav_DJF_rcp45_2040s.csv""pav_DJF_rcp45_2080s.csv"
> "pav_DJF_rcp85_2040s.csv"  "pav_DJF_rcp85_2080s.csv"
>
>
>
> "pav_JJA_histo.csv"
> "pav_JJA_rcp26_2040s.csv"  "pav_JJA_rcp26_2080s.csv"
> "pav_JJA_rcp45_2040s.csv"  "pav_JJA_rcp45_2080s.csv"
> "pav_JJA_rcp85_2040s.csv"    "pav_JJA_rcp85_2080s.csv"
>
> and so on ...
>
> I would like to apply a t-test of difference in mean between:
>
> "pav_DJF_histo.csv" and all dataframes with names having "pav_DJF..."
>
> the same for
>
> "pav_JJA_histo.csv" and all dataframes with names having "pav_JJA..."
>
> and so on...
>
> There are 84 dataframes in my list. Calculations will be performed as
> above on all 84 dataframes.
>
> Thanks for your suggestions.
> Asong.
>
> Reproducible example for  "pav_DJF_histo.csv" and all dataframes with
> names having "pav_DJF...".
>
> Each df has 1 row * 120 columns.  I will like to do element-wise:
>
> t.test(pav_DJF_histo.csv,all_dataframes)
>
> structure(list(pav_DJF_histo.csv = structure(list(G100_pav_DJF =
> 0.0314208328712871,
> G101_pav_DJF = 0.0316052879207921, G102_pav_DJF = 0.0338115233663366,
> G103_pav_DJF = 0.0349753320792079, G104_pav_DJF = 0.0340410627722772,
> G105_pav_DJF = 0.0344961831683168, G106_pav_DJF = 0.0331672699009901,
> G107_pav_DJF = 0.0335578704950495, G108_pav_DJF = 0.0318934661386139,
> G109_pav_DJF = 0.0326319041584158, G110_pav_DJF = 0.0314491928712871,
> G111_pav_DJF = 0.0295078394059406, G112_pav_DJF = 0.0312701207920792,
> G113_pav_DJF = 0.0274926542574257, G114_pav_DJF = 0.0280412045544554,
> G115_pav_DJF = 0.0308147467326733, G116_pav_DJF = 0.0276809968316832,
> G117_pav_DJF = 0.0334523455445545, G118_pav_DJF = 0.0231678550495049,
> G119_pav_DJF = 0.0329736546534653, G120_pav_DJF = 0.0293986465346535,
> GG10_pav_DJF = 0.0272844384158416, GG11_pav_DJF = 0.0250696742574257,
> GG12_pav_DJF = 0.0267913558415842, GG13_pav_DJF = 0.028447095049505,
> GG14_pav_DJF = 0.0258856714851485, GG15_pav_DJF = 0.0284966926732673,
> GG16_pav_DJF = 0.0259450320792079, GG17_pav_DJF = 0.0275422631683168,
> GG18_pav_DJF = 0.0267659001980198, GG19_pav_DJF = 0.0239620502970297,
> GG20_pav_DJF = 0.0235523667326733, GG21_pav_DJF = 0.0280495275247525,
> GG22_pav_DJF = 0.0260046952475248, GG23_pav_DJF = 0.0245813871287129,
> GG24_pav_DJF = 0.0225754382178218, GG25_pav_DJF = 0.0340031586138614,
> GG26_pav_DJF = 0.0281897057425743, GG27_pav_DJF = 0.0290264237623762,
> GG28_pav_DJF = 0.0387512556435644, GG29_pav_DJF = 0.0316748243564356,
> GG30_pav_DJF = 0.0268749459405941, GG31_pav_DJF = 0.0306790738613861,
> GG32_pav_DJF = 0.0265153081188119, GG33_pav_DJF = 0.0287865821782178,
> GG34_pav_DJF = 0.0269848536633663, GG35_pav_DJF = 0.0237527348514851,
> GG36_pav_DJF = 0.0264141081188119, GG37_pav_DJF = 0.0273517104950495,
> GG38_pav_DJF = 0.0299628936633663, GG39_pav_DJF = 0.0275048685148515,
> GG40_pav_DJF = 0.0196275314851485, GG41_pav_DJF = 0.0226415651485149,
> GG42_pav_DJF = 0.0292957691089109, GG43_pav_DJF = 0.0240719154455446,
> GG44_pav_DJF = 0.0264125300990099, GG45_pav_DJF = 0.0245377025742574,
> GG46_pav_DJF = 0.0254801978217822, GG47_pav_DJF = 0.0264283477227723,
> GG48_pav_DJF = 0.0221284198019802, GG49_pav_DJF = 0.0281992881188119,
> GG50_pav_DJF = 0.0251214203960396, GG51_pav_DJF = 0.022804923960396,
> GG52_pav_DJF = 0.0253265572277228, GG53_pav_DJF = 0.0248078140594059,
> GG54_pav_DJF = 0.0229847805940594, GG55_pav_DJF = 0.0245689685148515,
> GG56_pav_DJF = 0.024459103960396, GG57_pav_DJF = 0.0261233461386139,
> GG58_pav_DJF = 0.0248389976237624, GG59_pav_DJF = 0.0238194382178218,
> GG60_pav_DJF = 0.025920022970297, GG61_pav_DJF = 0.0232416265346535,
> GG62_pav_DJF = 0.0254770396039604, GG63_pav_DJF = 0.0248223295049505,
> GG64_pav_DJF = 0.0249457611881188, GG65_pav_DJF = 0.0237617085148515,
> GG66_pav_DJF = 0.023653757029703, GG67_pav_DJF = 0.0225660194059406,
> GG68_pav_DJF = 0.0209042742574257, GG69_pav_DJF = 0.0253348401980198,
> GG70_pav_DJF = 0.0269268635643564, GG71_pav_DJF = 0.0257322499009901,
> GG72_pav_DJF = 0.0261817491089109, GG73_pav_DJF = 0.0267062437623762,
> GG74_pav_DJF = 0.0254928786138614, GG75_pav_DJF = 0.0263220520792079,
> GG76_pav_DJF = 0.0266288738613861, GG77_pav_DJF = 0.0261239605940594,
> GG78_pav_DJF = 0.0239993772277228, GG79_pav_DJF = 0.0158666427722772,
> GG80_pav_DJF = 0.0175424689108911, GG81_pav_DJF = 0.0193922348514851,
> GG82_pav_DJF = 0.0263564615841584, GG83_pav_DJF = 0.0194876946534653,
> GG84_pav_DJF = 0.0253149083168317, GG85_pav_DJF = 0.0250615659405941,
> GG86_pav_DJF = 0.0241572235643564, GG87_pav_DJF = 0.0232231510891089,
> GG88_pav_DJF = 0.027858396039604, GG89_pav_DJF = 0.0271891471287129,
> GG90_pav_DJF = 0.0269782621782178, GG91_pav_DJF = 0.0259993922772277,
> GG92_pav_DJF = 0.0271551689108911, GG93_pav_DJF = 0.0274789423762376,
> GG94_pav_DJF = 0.0246039, GG95_pav_DJF = 0.0314879467326733,
> GG96_pav_DJF = 0.031215642970297, GG97_pav_DJF = 0.0259254443564356,
> GG98_pav_DJF = 0.028124596039604, GG99_pav_DJF = 0.0293694499009901,
> GGG1_pav_DJF = 0.0280423463366337, GGG2_pav_DJF = 0.0266454362376238,
> GGG3_pav_DJF = 0.0262475837623762, GGG4_pav_DJF = 0.0271603285148515,
> GGG5_pav_DJF = 0.026403784950495, GGG6_pav_DJF = 0.026692183960396,
> GGG7_pav_DJF = 0.0281706176237624, GGG8_pav_DJF = 0.0275187194059406,
> GGG9_pav_DJF = 0.0267755964356436), .Names = c("G100_pav_DJF",
> "G101_pav_DJF", "G102_pav_DJF", "G103_pav_DJF", "G104_pav_DJF",
> "G105_pav_DJF", "G106_pav_DJF", "G107_pav_DJF", "G108_pav_DJF",
> "G109_pav_DJF", "G110_pav_DJF", "G111_pav_DJF", "G112_pav_DJF",
> "G113_pav_DJF", "G114_pav_DJF", "G115_pav_DJF", "G116_pav_DJF",
> "G117_pav_DJF", "G118_pav_DJF", "G119_pav_DJF", "G120_pav_DJF",
> "GG10_pav_DJF", "GG11_pav_DJF", "GG12_pav_DJF", "GG13_pav_DJF",
> "GG14_pav_DJF", "GG15_pav_DJF", "GG16_pav_DJF", "GG17_pav_DJF",
> "GG18_pav_DJF", "GG19_pav_DJF", "GG20_pav_DJF", "GG21_pav_DJF",
> "GG22_pav_DJF", "GG23_pav_DJF", "GG24_pav_DJF", "GG25_pav_DJF",
> "GG26_pav_DJF", "GG27_pav_DJF", "GG28_pav_DJF", "GG29_pav_DJF",
> "GG30_pav_DJF", "GG31_pav_DJF", "GG32_pav_DJF", "GG33_pav_DJF",
> "GG34_pav_DJF", "GG35_pav_DJF", "GG36_pav_DJF", "GG37_pav_DJF",
> "GG38_pav_DJF", "GG39_pav_DJF", "GG40_pav_DJF", "GG41_pav_DJF",
> "GG42_pav_DJF", "GG43_pav_DJF", "GG44_pav_DJF", "GG45_pav_DJF",
> "GG46_pav_DJF", "GG47_pav_DJF", "GG48_pav_DJF", "GG49_pav_DJF",
> "GG50_pav_DJF", "GG51_pav_DJF", "GG52_pav_DJF", "GG53_pav_DJF",
> "GG54_pav_DJF", "GG55_pav_DJF", "GG56_pav_DJF", "GG57_pav_DJF",
> "GG58_pav_DJF", "GG59_pav_DJF", "GG60_pav_DJF", "GG61_pav_DJF",
> "GG62_pav_DJF", "GG63_pav_DJF", "GG64_pav_DJF", "GG65_pav_DJF",
> "GG66_pav_DJF", "GG67_pav_DJF", "GG68_pav_DJF", "GG69_pav_DJF",
> "GG70_pav_DJF", "GG71_pav_DJF", "GG72_pav_DJF", "GG73_pav_DJF",
> "GG74_pav_DJF", "GG75_pav_DJF", "GG76_pav_DJF", "GG77_pav_DJF",
> "GG78_pav_DJF", "GG79_pav_DJF", "GG80_pav_DJF", "GG81_pav_DJF",
> "GG82_pav_DJF", "GG83_pav_DJF", "GG84_pav_DJF", "GG85_pav_DJF",
> "GG86_pav_DJF", "GG87_pav_DJF", "GG88_pav_DJF", "GG89_pav_DJF",
> "GG90_pav_DJF", "GG91_pav_DJF", "GG92_pav_DJF", "GG93_pav_DJF",
> "GG94_pav_DJF", "GG95_pav_DJF", "GG96_pav_DJF", "GG97_pav_DJF",
> "GG98_pav_DJF", "GG99_pav_DJF", "GGG1_pav_DJF", "GGG2_pav_DJF",
> "GGG3_pav_DJF", "GGG4_pav_DJF", "GGG5_pav_DJF", "GGG6_pav_DJF",
> "GGG7_pav_DJF", "GGG8_pav_DJF", "GGG9_pav_DJF"), row.names = c(NA,
> -1L), class = "data.frame"), pav_DJF_rcp26_2040s.csv = structure(list(
> G100_pav_DJF = 0.0336921695049505, G101_pav_DJF = 0.0353346894059406,
> G102_pav_DJF = 0.0374039577722772, G103_pav_DJF = 0.0382527494059406,
> G104_pav_DJF = 0.0372147038613861, G105_pav_DJF = 0.036982626039604,
> G106_pav_DJF = 0.0357056598514851, G107_pav_DJF = 0.0367259367326733,
> G108_pav_DJF = 0.0339615762376238, G109_pav_DJF = 0.0352461818316832,
> G110_pav_DJF = 0.0331901645544554, G111_pav_DJF = 0.0327048907425743,
> G112_pav_DJF = 0.0338771433663366, G113_pav_DJF = 0.0304345107425743,
> G114_pav_DJF = 0.0299715592574257, G115_pav_DJF = 0.0323663623267327,
> G116_pav_DJF = 0.0302113144059406, G117_pav_DJF = 0.0348880272772277,
> G118_pav_DJF = 0.0244634474752475, G119_pav_DJF = 0.0356601117821782,
> G120_pav_DJF = 0.0318457833168317, GG10_pav_DJF = 0.0292012213366337,
> GG11_pav_DJF = 0.0276689620792079, GG12_pav_DJF = 0.0293319658910891,
> GG13_pav_DJF = 0.0304862144059406, GG14_pav_DJF = 0.0280408795544554,
> GG15_pav_DJF = 0.0301200932178218, GG16_pav_DJF = 0.0286451583663366,
> GG17_pav_DJF = 0.0300997758415842, GG18_pav_DJF = 0.0288163182673267,
> GG19_pav_DJF = 0.0263369057920792, GG20_pav_DJF = 0.0266477852475248,
> GG21_pav_DJF = 0.0300933431683168, GG22_pav_DJF = 0.0289349790594059,
> GG23_pav_DJF = 0.0268180481683168, GG24_pav_DJF = 0.0244735858415842,
> GG25_pav_DJF = 0.0365696418316832, GG26_pav_DJF = 0.0300007536138614,
> GG27_pav_DJF = 0.0316598915346535, GG28_pav_DJF = 0.0408627464356436,
> GG29_pav_DJF = 0.0336171423762376, GG30_pav_DJF = 0.0293838656930693,
> GG31_pav_DJF = 0.0328603355445545, GG32_pav_DJF = 0.029574533960396,
> GG33_pav_DJF = 0.030923384009901, GG34_pav_DJF = 0.0295480556930693,
> GG35_pav_DJF = 0.0253115618316832, GG36_pav_DJF = 0.0283057747029703,
> GG37_pav_DJF = 0.0302438872277228, GG38_pav_DJF = 0.0321001403465347,
> GG39_pav_DJF = 0.0297127561386139, GG40_pav_DJF = 0.0210915803465347,
> GG41_pav_DJF = 0.0244056779207921, GG42_pav_DJF = 0.0318838803465347,
> GG43_pav_DJF = 0.0262421126237624, GG44_pav_DJF = 0.0286438319306931,
> GG45_pav_DJF = 0.0269299434158416, GG46_pav_DJF = 0.0278216301980198,
> GG47_pav_DJF = 0.0284923436633663, GG48_pav_DJF = 0.024062545,
> GG49_pav_DJF = 0.0297595119306931, GG50_pav_DJF = 0.0267064392079208,
> GG51_pav_DJF = 0.0251601975247525, GG52_pav_DJF = 0.0270363448019802,
> GG53_pav_DJF = 0.027031203960396, GG54_pav_DJF = 0.0253016908415842,
> GG55_pav_DJF = 0.0266129271287129, GG56_pav_DJF = 0.0264486413861386,
> GG57_pav_DJF = 0.0283687212376238, GG58_pav_DJF = 0.0267607587623762,
> GG59_pav_DJF = 0.0258524088118812, GG60_pav_DJF = 0.0284728297029703,
> GG61_pav_DJF = 0.0242683505445545, GG62_pav_DJF = 0.0269807252970297,
> GG63_pav_DJF = 0.0260612163366337, GG64_pav_DJF = 0.0268121706435644,
> GG65_pav_DJF = 0.0254399943069307, GG66_pav_DJF = 0.0256744116831683,
> GG67_pav_DJF = 0.0242163128712871, GG68_pav_DJF = 0.0232865385643564,
> GG69_pav_DJF = 0.027024237970297, GG70_pav_DJF = 0.0280309896039604,
> GG71_pav_DJF = 0.027491227970297, GG72_pav_DJF = 0.0271313031188119,
> GG73_pav_DJF = 0.0286036438118812, GG74_pav_DJF = 0.0282849307920792,
> GG75_pav_DJF = 0.0280740992079208, GG76_pav_DJF = 0.0294208429207921,
> GG77_pav_DJF = 0.0286056740594059, GG78_pav_DJF = 0.0252083457425743,
> GG79_pav_DJF = 0.0171779085148515, GG80_pav_DJF = 0.0187473600495049,
> GG81_pav_DJF = 0.020924249950495, GG82_pav_DJF = 0.0285746283663366,
> GG83_pav_DJF = 0.0212331709405941, GG84_pav_DJF = 0.0275696948019802,
> GG85_pav_DJF = 0.027292552970297, GG86_pav_DJF = 0.0265909641584158,
> GG87_pav_DJF = 0.025798541039604, GG88_pav_DJF = 0.0306168697029703,
> GG89_pav_DJF = 0.0303202963861386, GG90_pav_DJF = 0.0291813004950495,
> GG91_pav_DJF = 0.0280794616831683, GG92_pav_DJF = 0.0299837882673267,
> GG93_pav_DJF = 0.0299919872772277, GG94_pav_DJF = 0.0269039003465347,
> GG95_pav_DJF = 0.0339354712376238, GG96_pav_DJF = 0.0325601980693069,
> GG97_pav_DJF = 0.0285637703465347, GG98_pav_DJF = 0.0313221871782178,
> GG99_pav_DJF = 0.0323324087128713, GGG1_pav_DJF = 0.0298989088118812,
> GGG2_pav_DJF = 0.0290734964356436, GGG3_pav_DJF = 0.0281705633663366,
> GGG4_pav_DJF = 0.0291793695544554, GGG5_pav_DJF = 0.0279056234653465,
> GGG6_pav_DJF = 0.0281455424752475, GGG7_pav_DJF = 0.0309308349009901,
> GGG8_pav_DJF = 0.0294452942574257, GGG9_pav_DJF = 0.0289754272277228),
> .Names = c("G100_pav_DJF",
> "G101_pav_DJF", "G102_pav_DJF", "G103_pav_DJF", "G104_pav_DJF",
> "G105_pav_DJF", "G106_pav_DJF", "G107_pav_DJF", "G108_pav_DJF",
> "G109_pav_DJF", "G110_pav_DJF", "G111_pav_DJF", "G112_pav_DJF",
> "G113_pav_DJF", "G114_pav_DJF", "G115_pav_DJF", "G116_pav_DJF",
> "G117_pav_DJF", "G118_pav_DJF", "G119_pav_DJF", "G120_pav_DJF",
> "GG10_pav_DJF", "GG11_pav_DJF", "GG12_pav_DJF", "GG13_pav_DJF",
> "GG14_pav_DJF", "GG15_pav_DJF", "GG16_pav_DJF", "GG17_pav_DJF",
> "GG18_pav_DJF", "GG19_pav_DJF", "GG20_pav_DJF", "GG21_pav_DJF",
> "GG22_pav_DJF", "GG23_pav_DJF", "GG24_pav_DJF", "GG25_pav_DJF",
> "GG26_pav_DJF", "GG27_pav_DJF", "GG28_pav_DJF", "GG29_pav_DJF",
> "GG30_pav_DJF", "GG31_pav_DJF", "GG32_pav_DJF", "GG33_pav_DJF",
> "GG34_pav_DJF", "GG35_pav_DJF", "GG36_pav_DJF", "GG37_pav_DJF",
> "GG38_pav_DJF", "GG39_pav_DJF", "GG40_pav_DJF", "GG41_pav_DJF",
> "GG42_pav_DJF", "GG43_pav_DJF", "GG44_pav_DJF", "GG45_pav_DJF",
> "GG46_pav_DJF", "GG47_pav_DJF", "GG48_pav_DJF", "GG49_pav_DJF",
> "GG50_pav_DJF", "GG51_pav_DJF", "GG52_pav_DJF", "GG53_pav_DJF",
> "GG54_pav_DJF", "GG55_pav_DJF", "GG56_pav_DJF", "GG57_pav_DJF",
> "GG58_pav_DJF", "GG59_pav_DJF", "GG60_pav_DJF", "GG61_pav_DJF",
> "GG62_pav_DJF", "GG63_pav_DJF", "GG64_pav_DJF", "GG65_pav_DJF",
> "GG66_pav_DJF", "GG67_pav_DJF", "GG68_pav_DJF", "GG69_pav_DJF",
> "GG70_pav_DJF", "GG71_pav_DJF", "GG72_pav_DJF", "GG73_pav_DJF",
> "GG74_pav_DJF", "GG75_pav_DJF", "GG76_pav_DJF", "GG77_pav_DJF",
> "GG78_pav_DJF", "GG79_pav_DJF", "GG80_pav_DJF", "GG81_pav_DJF",
> "GG82_pav_DJF", "GG83_pav_DJF", "GG84_pav_DJF", "GG85_pav_DJF",
> "GG86_pav_DJF", "GG87_pav_DJF", "GG88_pav_DJF", "GG89_pav_DJF",
> "GG90_pav_DJF", "GG91_pav_DJF", "GG92_pav_DJF", "GG93_pav_DJF",
> "GG94_pav_DJF", "GG95_pav_DJF", "GG96_pav_DJF", "GG97_pav_DJF",
> "GG98_pav_DJF", "GG99_pav_DJF", "GGG1_pav_DJF", "GGG2_pav_DJF",
> "GGG3_pav_DJF", "GGG4_pav_DJF", "GGG5_pav_DJF", "GGG6_pav_DJF",
> "GGG7_pav_DJF", "GGG8_pav_DJF", "GGG9_pav_DJF"), row.names = c(NA,
> -1L), class = "data.frame")), .Names = c("pav_DJF_histo.csv",
> "pav_DJF_rcp26_2040s.csv"))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From alaios at yahoo.com  Wed Feb 25 10:23:34 2015
From: alaios at yahoo.com (Alaios)
Date: Wed, 25 Feb 2015 09:23:34 +0000 (UTC)
Subject: [R] from expand.grid to a list (lapply)
Message-ID: <635136552.3416760.1424856214241.JavaMail.yahoo@mail.yahoo.com>

Hi all,I would like to use an expand.grid functionality that would give me at the end a listso far my code looks like:
?sigma_max_On_seq<-seq(0.05,100,length.out=10000)
mean_max_On_seq<-seq(2,10000),length.out=10000)
expandMeanSigmaOn<-expand.grid(mean_max_On_seq,mean_max_On_seq,sigma_max_On_seq,sigma_max_On_seq)
that gives me at the end all the possible combinations as a data frame.Browse[1]> str((expandMeanSigmaOn))
'data.frame':?? XXX obs. of? 4 variables:
?$ Var1: num? 1 11432 22864 34295 45727 ...
?$ Var2: num? 1 1 1 1 1 1 1 1 1 1 ...
?$ Var3: num? 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 ...
?$ Var4: num? 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 ...
?- attr(*, "out.attrs")=List of 2
? ..$ dim???? : int? 10 10 10 10
? ..$ dimnames:List of 4
? .. ..$ Var1: chr? "Var1=???? 1.00" "Var1= 11432.44" "Var1= 22863.89" "Var1= 34295.33" ...
? .. ..$ Var2: chr? "Var2=???? 1.00" "Var2= 11432.44" "Var2= 22863.89" "Var2= 34295.33" ...
? .. ..$ Var3: chr? "Var3=? 0.05000" "Var3= 31.48065" "Var3= 62.91131" "Var3= 94.34196" ...
? .. ..$ Var4: chr? "Var4=? 0.05000" "Var4= 31.48065" "Var4= 62.91131" "Var4= 94.34196" ...

?but I want to have a list that I would be able to use it as input into a lapply function. The lapply should use then each list entry independently giving as input variables only the current $Var1,$Var2,$Var3,$Var4

How I can convert in R the data.frame into a list?
I would like to thank you in advance for your replyRegardsAlex


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Feb 25 10:39:00 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 25 Feb 2015 10:39:00 +0100
Subject: [R] Getting Rmarkdown to generate custom LaTEX environment
In-Reply-To: <CAJtgXV0BxrsPfXNnA_YKVqBCmXVvzOLrXfBk4bPq+2cO2izXcw@mail.gmail.com>
References: <CAJtgXV0BxrsPfXNnA_YKVqBCmXVvzOLrXfBk4bPq+2cO2izXcw@mail.gmail.com>
Message-ID: <CAJuCY5zDZjdepHhjttgBbrzU5eDQBjViXYj+wH_9SiWp+VXQzw@mail.gmail.com>

Dear Huan,

Markdown doesn't know the concept of figure*. So you can't generate it with
native Markdown markup. If you really need figure*, then the only option in
markdown is to generate the LaTeX code yourself. Note that is will break
conversion to formats that don't handle LaTeX code.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-02-25 3:28 GMT+01:00 Huan Truong <_ at tnhh.net>:

> Hi all,
>
> I was struggling trying to make my Rmarkdown document to generate
>
> \begin{figure*}
>
> instead of
>
> \begin{figure}
>
> So that the figure spans on two columns (I'm using a custom template).
>
> in my figure. I have read the Rmarkdown Reference Guide, and searched
> for it on StackOverflow, and the general idea seems to be that I could
> somehow pass the fig.env variable to the figure, but I have tried it
> with no success: Something like this still doesn't have any effect
> whatsoever on the latex code generated:
>
> ```{r test-plot, echo=FALSE, fig.cap = "Test
> plot.\\label{fig:test-plot}", fig.env='figure*' }
> options(fig.env='figure*')
> plot(blah)
> ```
>
> I know I must have missed something but couldn't figure out what I'm
> missing after hours of struggling. Any help is much appreciated.
>
> I have a smaller problem where I want to customize the [htbp] option
> of the figure, and facing the same problem.
>
> Cheers,
> - Huan.
>
>
>
>
>
>
> --
>
> Eccentric Graduate Student
> Google Talk/Jabber huant at tnhh.net - Website tnhh.net - Phone
> 1-858-848-ROFL
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Gerrit.Eichner at math.uni-giessen.de  Wed Feb 25 11:13:16 2015
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 25 Feb 2015 11:13:16 +0100 (MET)
Subject: [R] from expand.grid to a list (lapply)
In-Reply-To: <635136552.3416760.1424856214241.JavaMail.yahoo@mail.yahoo.com>
References: <635136552.3416760.1424856214241.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <Pine.SOC.4.64.1502251108560.13233@solcom.hrz.uni-giessen.de>

Hie Alaiso,

try to simply apply lapply() to your data frame. It should work w/o any 
further operation since data frames are lists (check with is.list()).

  Hth  --  Gerrit

On Wed, 25 Feb 2015, Alaios via R-help wrote:

> Hi all,I would like to use an expand.grid functionality that would give 
> me at the end a listso far my code looks like:
> ?sigma_max_On_seq<-seq(0.05,100,length.out=10000)
> mean_max_On_seq<-seq(2,10000),length.out=10000)
> expandMeanSigmaOn<-expand.grid(mean_max_On_seq,mean_max_On_seq,sigma_max_On_seq,sigma_max_On_seq)
> that gives me at the end all the possible combinations as a data 
> frame.
> Browse[1]> str((expandMeanSigmaOn))
> 'data.frame':?? XXX obs. of? 4 variables:
> ?$ Var1: num? 1 11432 22864 34295 45727 ...
> ?$ Var2: num? 1 1 1 1 1 1 1 1 1 1 ...
> ?$ Var3: num? 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 ...
> ?$ Var4: num? 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 ...
> ?- attr(*, "out.attrs")=List of 2
> ? ..$ dim???? : int? 10 10 10 10
> ? ..$ dimnames:List of 4
> ? .. ..$ Var1: chr? "Var1=???? 1.00" "Var1= 11432.44" "Var1= 22863.89" "Var1= 34295.33" ...
> ? .. ..$ Var2: chr? "Var2=???? 1.00" "Var2= 11432.44" "Var2= 22863.89" "Var2= 34295.33" ...
> ? .. ..$ Var3: chr? "Var3=? 0.05000" "Var3= 31.48065" "Var3= 62.91131" "Var3= 94.34196" ...
> ? .. ..$ Var4: chr? "Var4=? 0.05000" "Var4= 31.48065" "Var4= 62.91131" "Var4= 94.34196" ...
>
> ?but I want to have a list that I would be able to use it as input into 
> a lapply function. The lapply should use then each list entry 
> independently giving as input variables only the current 
> $Var1,$Var2,$Var3,$Var4
>
> How I can convert in R the data.frame into a list?
> I would like to thank you in advance for your replyRegardsAlex

From highstat at highstat.com  Wed Feb 25 11:15:59 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 25 Feb 2015 10:15:59 +0000
Subject: [R] Stats course: GAM and GAMM in Genoa, Italy
Message-ID: <54EDA0DF.40608@highstat.com>

Apologies for cross-posting


We would like to announce the following statistics course:

Course:   Introduction to GAM and GAMM with R
Location: University of Genoa, Italy
Date:       11 - 15 May 2015.
Price:       425 GBP

Course website: http://www.highstat.com/statscourse.htm
Course flyer: http://www.highstat.com/Courses/Flyer2015_05Genua.pdf


Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From highstat at highstat.com  Wed Feb 25 11:17:19 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 25 Feb 2015 10:17:19 +0000
Subject: [R] Stats course: GAM and GAMM in Genoa, Italy
Message-ID: <54EDA12F.2080202@highstat.com>

Apologies for cross-posting


We would like to announce the following statistics course:

Course:   Introduction to GAM and GAMM with R
Location: University of Genoa, Italy
Date:       11 - 15 May 2015.
Price:       425 GBP

Course website: http://www.highstat.com/statscourse.htm
Course flyer: http://www.highstat.com/Courses/Flyer2015_05Genua.pdf


Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From optionsraghu at gmail.com  Wed Feb 25 14:32:07 2015
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Wed, 25 Feb 2015 13:32:07 +0000
Subject: [R] plotting multiple time series under one panel
Message-ID: <CADgEnDnzm1TOLurSpca2BrV9EnJkAQDS0Mp2VJv13ffoH6OjfQ@mail.gmail.com>

Dear guRus

I have data frame as:
str(voldf)
'data.frame': 130 obs. of  8 variables:
 $ Date: Date, format: "2014-08-01" "2014-08-05" "2014-08-08" ...
 $ kc  : num  0.453 0.424 0.468 0.481 0.485 ...
 $ sb  : num  0.1128 0.123 0.1272 0.1128 0.0949 ...
 $ qc  : num  0.0626 0.0661 0.0777 0.0765 0.0763 ...
 $ c   : num  0.167 0.182 0.183 0.21 0.215 ...
 $ w   : num  0.21 0.271 0.282 0.351 0.345 ...
 $ s   : num  0.249 0.253 0.295 0.332 0.35 ...
 $ ct  : num  0.212 0.22 0.228 0.188 0.181 ...

I am trying to plot multiple line charts for each of the columns and
show them together in the same panel. Is it possible please using
ggplot?

I tried melting dfm=melt(voldf, id.vars="Date") and then plotted this
but it gives me all graphs in one panel which did not help.

Any assistance is greatly appreciated.

Many thx
Raghu


From h.wickham at gmail.com  Wed Feb 25 14:50:53 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 25 Feb 2015 08:50:53 -0500
Subject: [R] dplyr: producing a good old data frame
In-Reply-To: <9E73F88F04AA25408DBB58FB730BA65329B3C433@AUSP01DAG0503.collaborationhost.net>
References: <9E73F88F04AA25408DBB58FB730BA65329B3C433@AUSP01DAG0503.collaborationhost.net>
Message-ID: <CABdHhvEGb8Xai91ze-+m_SgA9--B9XbkoEaD_S9AUUmwufiw=A@mail.gmail.com>

Hi John,

Just printing the result gives a good indication where the problem lies:

> frm %>% rowwise() %>% do(MM=max(as.numeric(.)))
Source: local data frame [6 x 1]
Groups: <by row>

        MM
1 <dbl[1]>
2 <dbl[1]>
3 <dbl[1]>
4 <dbl[1]>
5 <dbl[1]>
6 <dbl[1]>

do() is designed to produce scalars (e.g. a linear model), not
vectors, so it doesn't join the results back into a single vector. You
can either fix this yourself with unlist(), or use tidyr::unnest()
which will also handle vectors with length > 1.

Hadley

On Mon, Feb 23, 2015 at 2:54 PM, John Posner <john.posner at mjbiostat.com> wrote:
> I'm using the dplyr package to perform one-row-at-a-time processing of a data frame:
>
>> rnd6 = function() sample(1:300, 6)
>> frm = data.frame(AA=rnd6(), BB=rnd6(), CC=rnd6())
>
>> frm
>    AA  BB  CC
> 1 123  50  45
> 2  12  30 231
> 3 127 147 100
> 4 133  32 129
> 5  66 235  71
> 6  38 264 261
>
> The interface is nice and straightforward:
>
>> library(dplyr)
>> dplyr_result = frm %>% rowwise() %>% do(MM=max(as.numeric(.)))
>
> I've gotten used to the fact that dplyr_result is not a good old "vanilla" data frame. The as.data.frame() function *seems* to do the trick:
>
>> dplyr_result_2 = as.data.frame(dplyr_result)
>> dplyr_result_2
>    MM
> 1 123
> 2 231
> 3 147
> 4 133
> 5 235
> 6 264
>
> ... but there's trouble ahead:
>
>> mean(dplyr_result_2$MM)
> [1] NA
> Warning message:
> In mean.default(dplyr_result_2$MM) :
>   argument is not numeric or logical: returning NA
>
> I need to enlist unlist() to get me to my destination:
>
>> mean(unlist(dplyr_result_2$MM))
> [1] 188.8333
>
> [NOTE: dplyr's as_data_frame() function does a better job than as.data.frame() of indicating that I was headed for trouble. ]
>
> By contrast, the plyr package's adply() function *does* produce a vanilla data frame:
>
>  > library(plyr)
>> plyr_result = adply(frm, .margins=1, function(onerowfrm) max(as.numeric(onerowfrm[1,])))
>> mean(plyr_result$V1)
> [1] 188.8333
>
> Is there a good reason for dplyr to require the extra processing? My (na?ve ?) recommendation would be to have as_data_frame() produce a vanilla data frame.
>
> Tx,
> John
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From jdnewmil at dcn.davis.CA.us  Wed Feb 25 14:59:39 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 25 Feb 2015 05:59:39 -0800
Subject: [R] plotting multiple time series under one panel
In-Reply-To: <CADgEnDnzm1TOLurSpca2BrV9EnJkAQDS0Mp2VJv13ffoH6OjfQ@mail.gmail.com>
References: <CADgEnDnzm1TOLurSpca2BrV9EnJkAQDS0Mp2VJv13ffoH6OjfQ@mail.gmail.com>
Message-ID: <401A3A88-5716-4218-B94D-9ED6B2223180@dcn.davis.CA.us>

Your request is confusing. You first say "trying to plot ... together in the same panel" and then complain "all graphs in one panel which did not help".
For ggplot at least, melting seems likely to help, so this would really be a good time for you to follow the request included in every message on this list by providing a reproducible example and clarifying what you want as output. You may find [1] helps you with making your example useful.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 25, 2015 5:32:07 AM PST, Raghuraman Ramachandran <optionsraghu at gmail.com> wrote:
>Dear guRus
>
>I have data frame as:
>str(voldf)
>'data.frame': 130 obs. of  8 variables:
> $ Date: Date, format: "2014-08-01" "2014-08-05" "2014-08-08" ...
> $ kc  : num  0.453 0.424 0.468 0.481 0.485 ...
> $ sb  : num  0.1128 0.123 0.1272 0.1128 0.0949 ...
> $ qc  : num  0.0626 0.0661 0.0777 0.0765 0.0763 ...
> $ c   : num  0.167 0.182 0.183 0.21 0.215 ...
> $ w   : num  0.21 0.271 0.282 0.351 0.345 ...
> $ s   : num  0.249 0.253 0.295 0.332 0.35 ...
> $ ct  : num  0.212 0.22 0.228 0.188 0.181 ...
>
>I am trying to plot multiple line charts for each of the columns and
>show them together in the same panel. Is it possible please using
>ggplot?
>
>I tried melting dfm=melt(voldf, id.vars="Date") and then plotted this
>but it gives me all graphs in one panel which did not help.
>
>Any assistance is greatly appreciated.
>
>Many thx
>Raghu
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From zilefacelvis at yahoo.com  Wed Feb 25 16:46:45 2015
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Wed, 25 Feb 2015 15:46:45 +0000 (UTC)
Subject: [R] Apply t-test on list in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C21695@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C21695@SRVEXCHMBX.precheza.cz>
Message-ID: <1720451914.10759381.1424879205902.JavaMail.yahoo@mail.yahoo.com>

Many thanks, Petr.You solved my problem.AT.
	[[alternative HTML version deleted]]


From hrk1366 at gmail.com  Wed Feb 25 14:55:22 2015
From: hrk1366 at gmail.com (hamid-reza kadkhodazadeh)
Date: Wed, 25 Feb 2015 17:25:22 +0330
Subject: [R] use R in a web interface
Message-ID: <CALsy4Az+GKwCuLNiyUZfTkdgd71c_t7ffBYGNWaK1S3EWx=ihw@mail.gmail.com>

hi;

*Is there a possibility to use R in a web interface (asp.net
<http://asp.net>) without the need to install it?*

thanks

	[[alternative HTML version deleted]]


From lingyi.ma at gmail.com  Wed Feb 25 10:08:58 2015
From: lingyi.ma at gmail.com (conglan)
Date: Wed, 25 Feb 2015 01:08:58 -0800 (PST)
Subject: [R] How to avoid two for loops?
Message-ID: <CACB+=LgMiRho_Bdri3V9QaWk-Y-N34V6uymFYwtMxNuBng0JOA@mail.gmail.com>

HI,

I have the following large data set:
the sample is as the following:
  Country  Product   Brand  Year_Month   DisplaySize   OperationSystem
     AE         1           20    201204              1                  1
     AE         5           20    201204              1                  1
     AE         2           28    201204              3                  2
     AE         3           27    201204              1                  1
     AE         1           20    201205              1                  1
     AE         2           28    201205              3                  2
     AE         4           20    201205              1                  2

I want to calculate the extra three columns as the following:
Let's say "20" is own brand
 #The sums of display size produced by competing brand
 #The sums of display size of other products produced by own brand
 #The sums of display size of products of competing firm in the same
operating system

I build up the following codes, apprently two loop takes too long time:

dd<-unique(cl$Year_Month)

fldata<-data.frame(NULL)

for ( i in 1:length(dd)){

  cls<-cl[cl$Year_Month==dd[i],]
  ws<-numeric(0)  #The sums of characteristics of products produced by
competing firms
  ws1<-numeric(0)  #The sums of characteristics of other products produced
by firm
  ws2<-numeric(0) #The sums of characteristics of products of competing
firm in the same operating system


  for (j in 1:dim(cls)[1]){

   wd<-sum(cls[cls$Brand!=cls$Brand[j],]$DISPLAY_SIZE_INCH)
   ws[j]<-wd
   wc<-sum(cls[cls$Brand==cls$Brand[j] & cls$Item_Id!=cls$Item_Id[j]
,]$DISPLAY_SIZE_INCH)
   ws1[j]<-wc
   wf<-sum(cls[cls$Brand!=cls$Brand[j] &
cls$OPERATING_SYST==cls$OPERATING_SYST[j]
,]$DISPLAY_SIZE_INCH)
   ws2[j]<-wf
   }

  cls<-cbind(cls,SumPCf=ws,SumOPf=ws1,SumPCfOp=ws2)
  fldata<-rbind(fldata,cls)

}


how can I avoid two loops and improve the speed of my code??????? any other
solution?


Thanks.

Tammy




--
View this message in context: http://r.789695.n4.nabble.com/How-to-avoid-two-for-loops-tp4703799.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From lingyi.ma at gmail.com  Wed Feb 25 10:14:49 2015
From: lingyi.ma at gmail.com (conglan)
Date: Wed, 25 Feb 2015 01:14:49 -0800 (PST)
Subject: [R] help on improving the efficiency of the codes
Message-ID: <CACB+=Lgh-59roFwSV1RYs+6_ZKVBtO+cjE9HcbGxNp+wRfLAgA@mail.gmail.com>

HI,

I have the following large data set:
the sample is as the following:
  Country  Product   Brand  Year_Month   DisplaySize   OperationSystem
     AE         1           20    201204              1                  1
     AE         5           20    201204              1                  1
     AE         2           28    201204              3                  2
     AE         3           27    201204              1                  1
     AE         1           20    201205              1                  1
     AE         2           28    201205              3                  2
     AE         4           20    201205              1                  2

I want to calculate the extra three columns as the following:
Let's say "20" is own brand
 #The sums of display size produced by competing brand
 #The sums of display size of other products produced by own brand
 #The sums of display size of products of competing firm in the same
operating system

I build up the following codes, apprently two loops takes too long time:

dd<-unique(cl$Year_Month)

fldata<-data.frame(NULL)

for ( i in 1:length(dd)){

  cls<-cl[cl$Year_Month==dd[i],]
  ws<-numeric(0)  #The sums of characteristics of products produced by
competing firms
  ws1<-numeric(0)  #The sums of characteristics of other products produced
by firm
  ws2<-numeric(0) #The sums of characteristics of products of competing firm
in the same operating system


  for (j in 1:dim(cls)[1]){

   wd<-sum(cls[cls$Brand!=cls$Brand[j],]$DISPLAY_SIZE_INCH)
   ws[j]<-wd
   wc<-sum(cls[cls$Brand==cls$Brand[j] & cls$Item_Id!=cls$Item_Id[j]
,]$DISPLAY_SIZE_INCH)
   ws1[j]<-wc
   wf<-sum(cls[cls$Brand!=cls$Brand[j] &
cls$OPERATING_SYST==cls$OPERATING_SYST[j] ,]$DISPLAY_SIZE_INCH)
   ws2[j]<-wf
   }

  cls<-cbind(cls,SumPCf=ws,SumOPf=ws1,SumPCfOp=ws2)
  fldata<-rbind(fldata,cls)

}


how can I avoid two loops and improve the speed of my code??????? any other
solution?


Thanks.

Tammy




--
View this message in context: http://r.789695.n4.nabble.com/help-on-improving-the-efficiency-of-the-codes-tp4703800.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From ilapro at ceh.ac.uk  Wed Feb 25 16:27:13 2015
From: ilapro at ceh.ac.uk (Ilaria Prosdocimi)
Date: Wed, 25 Feb 2015 15:27:13 +0000
Subject: [R] Robust GAM that covers Gaussian Distributions
References: <CAMmHnJ0FvntaEy-XyUQJRv-M6j8tXhNbeCqKxTuq60qp9_xZtw@mail.gmail.com>
	<loom.20130603T121347-492@post.gmane.org>
Message-ID: <loom.20150225T162216-476@post.gmane.org>

Ilaria Prosdocimi <ilapro <at> ceh.ac.uk> writes:

> 
> Christos Giannoulis <cgiannoul <at> gmail.com> writes:
> 
> > 
> > Dear All,
> > 
> > I was looking the r-archives and crantastic...for a package that has 
a
> > robust approach to generalized additive models. I found two packages
> > "robustgam" and "rgam" but their implemented functions
> > cover only binomial and poisson distributions (pls correct me if I 
am
> > wrong).
> > 
> > I would greatly appreciate if anyone could share with us other 
packages or
> > robust approaches of general additive modeling that might have a 
better
> > performance with small data sets (n = 50 -100 records).
> > 
> > Thank you very much all for reading this message. I am hoping and 
looking
> > forward to receiving your reply.
> > 
> > Sincerely,
> > 
> > Christos Giannoulis
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > 
> 
> Indeed, it seems that both the libraries do not allow normal data. I 
think
> you could try to use the code in this page
> (http://www.stat.ubc.ca/~matias/penalised/) for S-estimation. 
> If you want the code for the Croux et al paper
> (http://onlinelibrary.wiley.com/doi/10.1111/j.1541-
0420.2011.01630.x/full)
> just email me (ilapro + ceh.ac.uk) - it seems to be not available 
online
> anymore. This also allow normal data. 
> 
> Best
> 
> Ilaria
> 
> 



For information - in case somebody finds this post again in the future, 
the original files have now been restored in the KULeuven website at 
this address
http://wis.kuleuven.be/stat/stat-inferen/codes 

I have also packaged the code in a R package which can be accessed on 
GitHub (and installed with devtools::install_github) at

https://github.com/ilapros/DoubleRobGam

Best

Ilaria


From ispanyolcom at gmail.com  Wed Feb 25 17:02:17 2015
From: ispanyolcom at gmail.com (=?UTF-8?Q?Temel_=C4=B0spanyolca?=)
Date: Wed, 25 Feb 2015 17:02:17 +0100
Subject: [R] ts converting
Message-ID: <CAMUSX8p+4u2W7cCVw1hxh9gH-+WZt6070cAgDst6uPch_CBdpA@mail.gmail.com>

Hello
I have problem with ts converting process.
You can see my "y. txt" file in annex.

my codes

irpf <- read.table("y.txt", skip = 1, col.names = c(" time", "irpf"))
irpf1 <- ts(irpf[, 2], start = c(1995, 1), frequency = 12)

When I try to draw my data, result is following (annex: Captura)

R is drawing with frequency of my data, I want to see my orijinal datas not
frequencies..

How can I solve this problem ?

Engin YILMAZ
-------------- next part --------------
t	x
Ene	5.157.118
Feb	1.640.434
Mar	1.771.367
Abr	4.339.425
May	1.595.225
Jun	4.262.616
Jul	4.480.272
Ago	1.099.493
Sep	2.737.122
Oct	4.138.730
Nov	3.737.260
Dic	2.738.028
Ene	5.255.295
Feb	2.344.785
Mar	1.697.469
Abr	4.402.688
May	1.849.267
Jun	4.375.478
Jul	4.659.093
Ago	1.252.978
Sep	2.734.342
Oct	4.476.708
Nov	2.912.762
Dic	2.646.501
Ene	6.151.929
Feb	2.231.486
Mar	1.941.450
Abr	4.707.122
May	2.165.805
Jun	4.288.724
Jul	4.889.162
Ago	926.768
Sep	2.951.820
Oct	4.600.427
Nov	3.500.006
Dic	2.958.741
Ene	5.713.000
Feb	2.369.700
Mar	2.238.837
Abr	4.958.825
May	2.245.498
Jun	4.652.451
Jul	5.451.012
Ago	1.237.028
Sep	2.857.877
Oct	5.072.563
Nov	4.099.994
Dic	2.249.299
Ene	5.808.727
Feb	3.435.291
Mar	2.529.938
Abr	4.109.334
May	2.225.966
Jun	4.486.866
Jul	5.302.114
Ago	862.173
Sep	2.900.607
Oct	4.889.150
Nov	3.839.249
Dic	2.681.746
Ene	6.453.588
Feb	2.883.868
Mar	1.747.542
Abr	5.225.238
May	2.521.874
Jun	4.232.929
Jul	5.946.014
Ago	866.815
Sep	3.237.953
Oct	5.308.596
Nov	3.704.780
Dic	2.286.127
Ene	6.735.346
Feb	3.463.647
Mar	2.107.250
Abr	5.677.259
May	2.586.843
Jun	4.606.320
Jul	6.540.543
Ago	1.041.680
Sep	3.686.266
Oct	5.787.148
Nov	4.197.756
Dic	2.907.284
Ene	7.047.683
Feb	3.370.513
Mar	2.189.916
Abr	6.042.124
May	2.685.689
Jun	2.779.718
Jul	9.261.402
Ago	880.442
Sep	4.087.075
Oct	6.434.520
Nov	4.517.555
Dic	3.241.958
Ene	8.626.035
Feb	3.268.740
Mar	2.762.728
Abr	6.126.065
May	2.463.120
Jun	3.663.186
Jul	9.173.791
Ago	491.064
Sep	4.737.953
Oct	6.456.624
Nov	4.307.134
Dic	3.609.288
Ene	7.501.119
Feb	3.396.385
Mar	2.851.582
Abr	6.563.644
May	2.705.053
Jun	3.616.160
Jul	10.132.038
Ago	627.586
Sep	5.156.988
Oct	6.613.205
Nov	4.607.656
Dic	3.814.171
Ene	8.673.681
Feb	3.773.297
Mar	3.263.099
Abr	7.471.964
May	3.248.389
Jun	4.105.863
Jul	11.828.769
Ago	596.400
Sep	5.830.745
Oct	7.531.752
Nov	5.238.272
Dic	3.529.012
Ene	9.258.036
Feb	4.244.429
Mar	3.720.315
Abr	8.320.555
May	3.587.115
Jun	4.756.313
Jul	13.553.364
Ago	673.547
Sep	6.698.792
Oct	8.372.424
Nov	6.193.290
Dic	4.198.391
Ene	10.605.628
Feb	4.762.318
Mar	4.050.648
Abr	9.350.233
May	4.007.639
Jun	5.394.812
Jul	16.362.354
Ago	720.322
Sep	7.506.043
Oct	9.172.656
Nov	7.792.613
Dic	4.585.419
Ene	11.817.575
Feb	5.250.964
Mar	4.757.200
Abr	9.895.991
May	4.629.004
Jun	5.885.394
Jul	13.713.901
Ago	756.780
Sep	7.691.139
Oct	8.720.457
Nov	7.342.566
Dic	4.697.787
Ene	10.799.100
Feb	4.740.448
Mar	4.419.997
Abr	8.721.759
May	4.220.460
Jun	5.530.643
Jul	13.119.321
Ago	752.536
Sep	7.551.029
Oct	8.285.067
Nov	6.190.624
Dic	4.526.848
Ene	10.796.903
Feb	4.698.078
Mar	4.681.757
Abr	9.036.327
May	4.417.603
Jun	5.568.791
Jul	13.649.027
Ago	968.259
Sep	7.769.819
Oct	8.560.711
Nov	6.065.725
Dic	4.888.910
Ene	11.077.001
Feb	4.842.482
Mar	4.638.218
Abr	9.227.948
May	4.400.549
Jun	5.624.199
Jul	13.708.452
Ago	766.156
Sep	7.922.175
Oct	8.617.066
Nov	6.225.138
Dic	5.217.028
Ene	10.400.660
Feb	4.856.074
Mar	4.995.367
Abr	9.212.220
May	4.732.508
Jun	5.838.574
Jul	13.855.333
Ago	828.424
Sep	8.087.786
Oct	8.371.536
Nov	6.176.752
Dic	4.982.287
Ene	9.958.083
Feb	5.004.434
Mar	4.906.317
Abr	8.943.996
May	4.672.730
Jun	5.460.555
Jul	13.990.082
Ago	951.265
Sep	8.249.639
Oct	8.533.574
Nov	6.327.058
Dic	5.173.028
Ene	10.680.354
Feb	5.454.246
Mar	4.985.454
Abr	7.273.210
May	6.645.547
Jun	5.229.402
Jul	14.641.339
Ago	4.836.548
Sep	4.205.516


-------------- next part --------------
A non-text attachment was scrubbed...
Name: Captura.PNG
Type: image/png
Size: 54749 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150225/43ef4a98/attachment.png>

From ccallaghan2013 at fau.edu  Wed Feb 25 17:03:52 2015
From: ccallaghan2013 at fau.edu (Corey Callaghan)
Date: Wed, 25 Feb 2015 08:03:52 -0800 (PST)
Subject: [R] Help with nonlinear least squares regression curve fitting
Message-ID: <1424880232286-4703812.post@n4.nabble.com>

Hi everyone. This is my first post to this forum and I'm hoping someone can
help.

I'm trying to finish up some analysis for my thesis and this is the last
problem I have. I have calculated data for 15 different species of birds;
below is an example of one species and what the data might look like.

I have three a priori nonlinear curves that I want to test each data set
against in order to see which of the three curves has the best fit. (I
suspect the fit won't be that great for any of them in some instances.)

The curves' functions that I want to test are in the code here (hopefully
correctly):

Inverse Quadratic Curve: 
fitmodel <- nls(Area ~ (-a*Year)*(Year + b), data = df, start=list(a=??,
b=??, c=??))

Sigmodial Curve:
fitmodel <- nls(Area~a/(1+exp(-(b+c*Year))), data=df, start=list(a=???,
b=???, c=??))

Double sigmoidal Curve:
fitmodel <- nls(Area~a+2b(1/(1+exp(-abs(-c*Year+d)))-1/2)*sign(-c*Year+d),
data=df, start=list(a=???, b=???, c=???)

My problem is I can't really figure out how to choose the correct starting
values to avoid getting the singular matrix error. Any help as to how to go
about this would be appreciated! Does everything look right? My method is
okay?

If I can get the fits to run I plan on using AIC to select the best curve
for each of the 15 species.

I thank you in advance for your consideration and help on this!
Cheers,
Corey Callaghan


df:
Area	                 Year
104.7181283	1984
32.88026974	1985
56.07395863	1986
191.3422143	1987
233.4661392	1988
57.28317116	1989
201.1273404	1990
34.42570796	1991
165.8962342	1992
58.21905274	1993
114.6643724	1994
342.3461986	1995
184.8877994	1996
94.90509356	1997
45.2026941	1998
68.6196393	1999
575.2440229	2000
519.7557581	2001
904.157509	2002
1107.357517	2003
1682.876061	2004
40.55667824	2005
740.5032604	2006
885.7243469	2007
395.4190968	2008
1031.314519	2009
2597.544987	2010
1316.968695	2011
848.7093901	2012
5076.675075	2013
6132.975491	2014



--
View this message in context: http://r.789695.n4.nabble.com/Help-with-nonlinear-least-squares-regression-curve-fitting-tp4703812.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Wed Feb 25 17:36:49 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 25 Feb 2015 16:36:49 +0000
Subject: [R] How to avoid two for loops?
In-Reply-To: <CACB+=LgMiRho_Bdri3V9QaWk-Y-N34V6uymFYwtMxNuBng0JOA@mail.gmail.com>
References: <CACB+=LgMiRho_Bdri3V9QaWk-Y-N34V6uymFYwtMxNuBng0JOA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C21869@SRVEXCHMBX.precheza.cz>

Hi

It seems to me that it is work for aggregate. Your code is not reproducible so we cannot test it.

> temp<-read.table("clipboard", header=T)
> temp
  Country Product Brand Year_Month DisplaySize OperationSystem
1      AE       1    20     201204           1               1
2      AE       5    20     201204           1               1
3      AE       2    28     201204           3               2
4      AE       3    27     201204           1               1
5      AE       1    20     201205           1               1
6      AE       2    28     201205           3               2
7      AE       4    20     201205           1               2
> aggregate(temp$DisplaySize, list(temp$Brand), sum)
  Group.1 x
1      20 4
2      27 1
3      28 6

> aggregate(temp$DisplaySize, list(temp$Brand, temp$Year_Month), sum)
  Group.1 Group.2 x
1      20  201204 2
2      27  201204 1
3      28  201204 3
4      20  201205 2
5      28  201205 3

More flexible but more complicated is plyr package, which could probably be used too.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of conglan
> Sent: Wednesday, February 25, 2015 10:09 AM
> To: r-help at r-project.org
> Subject: [R] How to avoid two for loops?
>
> HI,
>
> I have the following large data set:
> the sample is as the following:
>   Country  Product   Brand  Year_Month   DisplaySize   OperationSystem
>      AE         1           20    201204              1
> 1
>      AE         5           20    201204              1
> 1
>      AE         2           28    201204              3
> 2
>      AE         3           27    201204              1
> 1
>      AE         1           20    201205              1
> 1
>      AE         2           28    201205              3
> 2
>      AE         4           20    201205              1
> 2
>
> I want to calculate the extra three columns as the following:
> Let's say "20" is own brand
>  #The sums of display size produced by competing brand
>  #The sums of display size of other products produced by own brand
>  #The sums of display size of products of competing firm in the same
> operating system
>
> I build up the following codes, apprently two loop takes too long time:
>
> dd<-unique(cl$Year_Month)
>
> fldata<-data.frame(NULL)
>
> for ( i in 1:length(dd)){
>
>   cls<-cl[cl$Year_Month==dd[i],]
>   ws<-numeric(0)  #The sums of characteristics of products produced by
> competing firms
>   ws1<-numeric(0)  #The sums of characteristics of other products
> produced
> by firm
>   ws2<-numeric(0) #The sums of characteristics of products of competing
> firm in the same operating system
>
>
>   for (j in 1:dim(cls)[1]){
>
>    wd<-sum(cls[cls$Brand!=cls$Brand[j],]$DISPLAY_SIZE_INCH)
>    ws[j]<-wd
>    wc<-sum(cls[cls$Brand==cls$Brand[j] & cls$Item_Id!=cls$Item_Id[j]
> ,]$DISPLAY_SIZE_INCH)
>    ws1[j]<-wc
>    wf<-sum(cls[cls$Brand!=cls$Brand[j] &
> cls$OPERATING_SYST==cls$OPERATING_SYST[j]
> ,]$DISPLAY_SIZE_INCH)
>    ws2[j]<-wf
>    }
>
>   cls<-cbind(cls,SumPCf=ws,SumOPf=ws1,SumPCfOp=ws2)
>   fldata<-rbind(fldata,cls)
>
> }
>
>
> how can I avoid two loops and improve the speed of my code??????? any
> other
> solution?
>
>
> Thanks.
>
> Tammy
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-
> avoid-two-for-loops-tp4703799.html
> Sent from the R help mailing list archive at Nabble.com.
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ivan.calandra at univ-reims.fr  Wed Feb 25 17:44:15 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Wed, 25 Feb 2015 17:44:15 +0100
Subject: [R] How to avoid two for loops?
In-Reply-To: <CACB+=LgMiRho_Bdri3V9QaWk-Y-N34V6uymFYwtMxNuBng0JOA@mail.gmail.com>
References: <CACB+=LgMiRho_Bdri3V9QaWk-Y-N34V6uymFYwtMxNuBng0JOA@mail.gmail.com>
Message-ID: <54EDFBDF.5080205@univ-reims.fr>

Hi Tammy,

I think you're looking for aggregate() or something similar (from 
package plyr for example).

Something along those lines:
aggregate(DisplaySize~Brand, data=cl, FUN=sum)

HTH,
Ivan

--
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 25/02/15 10:08, conglan a ?crit :
> HI,
>
> I have the following large data set:
> the sample is as the following:
>    Country  Product   Brand  Year_Month   DisplaySize   OperationSystem
>       AE         1           20    201204              1                  1
>       AE         5           20    201204              1                  1
>       AE         2           28    201204              3                  2
>       AE         3           27    201204              1                  1
>       AE         1           20    201205              1                  1
>       AE         2           28    201205              3                  2
>       AE         4           20    201205              1                  2
>
> I want to calculate the extra three columns as the following:
> Let's say "20" is own brand
>   #The sums of display size produced by competing brand
>   #The sums of display size of other products produced by own brand
>   #The sums of display size of products of competing firm in the same
> operating system
>
> I build up the following codes, apprently two loop takes too long time:
>
> dd<-unique(cl$Year_Month)
>
> fldata<-data.frame(NULL)
>
> for ( i in 1:length(dd)){
>
>    cls<-cl[cl$Year_Month==dd[i],]
>    ws<-numeric(0)  #The sums of characteristics of products produced by
> competing firms
>    ws1<-numeric(0)  #The sums of characteristics of other products produced
> by firm
>    ws2<-numeric(0) #The sums of characteristics of products of competing
> firm in the same operating system
>
>
>    for (j in 1:dim(cls)[1]){
>
>     wd<-sum(cls[cls$Brand!=cls$Brand[j],]$DISPLAY_SIZE_INCH)
>     ws[j]<-wd
>     wc<-sum(cls[cls$Brand==cls$Brand[j] & cls$Item_Id!=cls$Item_Id[j]
> ,]$DISPLAY_SIZE_INCH)
>     ws1[j]<-wc
>     wf<-sum(cls[cls$Brand!=cls$Brand[j] &
> cls$OPERATING_SYST==cls$OPERATING_SYST[j]
> ,]$DISPLAY_SIZE_INCH)
>     ws2[j]<-wf
>     }
>
>    cls<-cbind(cls,SumPCf=ws,SumOPf=ws1,SumPCfOp=ws2)
>    fldata<-rbind(fldata,cls)
>
> }
>
>
> how can I avoid two loops and improve the speed of my code??????? any other
> solution?
>
>
> Thanks.
>
> Tammy
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-avoid-two-for-loops-tp4703799.html
> Sent from the R help mailing list archive at Nabble.com.
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From NordlDJ at dshs.wa.gov  Wed Feb 25 17:44:00 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Wed, 25 Feb 2015 16:44:00 +0000
Subject: [R] use R in a web interface
In-Reply-To: <CALsy4Az+GKwCuLNiyUZfTkdgd71c_t7ffBYGNWaK1S3EWx=ihw@mail.gmail.com>
References: <CALsy4Az+GKwCuLNiyUZfTkdgd71c_t7ffBYGNWaK1S3EWx=ihw@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276623B1E3CF@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of hamid-
> reza kadkhodazadeh
> Sent: Wednesday, February 25, 2015 5:55 AM
> To: CRAN at r-project.org; r-help at r-project.org
> Subject: [R] use R in a web interface
> 
> hi;
> 
> *Is there a possibility to use R in a web interface (asp.net
> <http://asp.net>) without the need to install it?*
> 
> thanks
> 

Well, somebody has to have R installed where you can access it.  That being said, you might look at RStudio Server to see if that meets your needs.
 
http://www.rstudio.com/products/RStudio/


Dan

Daniel J. Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services



From ivan.calandra at univ-reims.fr  Wed Feb 25 17:46:34 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Wed, 25 Feb 2015 17:46:34 +0100
Subject: [R] help on improving the efficiency of the codes
In-Reply-To: <CACB+=Lgh-59roFwSV1RYs+6_ZKVBtO+cjE9HcbGxNp+wRfLAgA@mail.gmail.com>
References: <CACB+=Lgh-59roFwSV1RYs+6_ZKVBtO+cjE9HcbGxNp+wRfLAgA@mail.gmail.com>
Message-ID: <54EDFC6A.7060607@univ-reims.fr>

By the way, do not post the same topic twice, especially with different 
subject lines! It's counter-productive

--
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 25/02/15 10:14, conglan a ?crit :
> HI,
>
> I have the following large data set:
> the sample is as the following:
>    Country  Product   Brand  Year_Month   DisplaySize   OperationSystem
>       AE         1           20    201204              1                  1
>       AE         5           20    201204              1                  1
>       AE         2           28    201204              3                  2
>       AE         3           27    201204              1                  1
>       AE         1           20    201205              1                  1
>       AE         2           28    201205              3                  2
>       AE         4           20    201205              1                  2
>
> I want to calculate the extra three columns as the following:
> Let's say "20" is own brand
>   #The sums of display size produced by competing brand
>   #The sums of display size of other products produced by own brand
>   #The sums of display size of products of competing firm in the same
> operating system
>
> I build up the following codes, apprently two loops takes too long time:
>
> dd<-unique(cl$Year_Month)
>
> fldata<-data.frame(NULL)
>
> for ( i in 1:length(dd)){
>
>    cls<-cl[cl$Year_Month==dd[i],]
>    ws<-numeric(0)  #The sums of characteristics of products produced by
> competing firms
>    ws1<-numeric(0)  #The sums of characteristics of other products produced
> by firm
>    ws2<-numeric(0) #The sums of characteristics of products of competing firm
> in the same operating system
>
>
>    for (j in 1:dim(cls)[1]){
>
>     wd<-sum(cls[cls$Brand!=cls$Brand[j],]$DISPLAY_SIZE_INCH)
>     ws[j]<-wd
>     wc<-sum(cls[cls$Brand==cls$Brand[j] & cls$Item_Id!=cls$Item_Id[j]
> ,]$DISPLAY_SIZE_INCH)
>     ws1[j]<-wc
>     wf<-sum(cls[cls$Brand!=cls$Brand[j] &
> cls$OPERATING_SYST==cls$OPERATING_SYST[j] ,]$DISPLAY_SIZE_INCH)
>     ws2[j]<-wf
>     }
>
>    cls<-cbind(cls,SumPCf=ws,SumOPf=ws1,SumPCfOp=ws2)
>    fldata<-rbind(fldata,cls)
>
> }
>
>
> how can I avoid two loops and improve the speed of my code??????? any other
> solution?
>
>
> Thanks.
>
> Tammy
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/help-on-improving-the-efficiency-of-the-codes-tp4703800.html
> Sent from the R help mailing list archive at Nabble.com.
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From s.wood at bath.ac.uk  Wed Feb 25 17:54:07 2015
From: s.wood at bath.ac.uk (Simon Wood)
Date: Wed, 25 Feb 2015 16:54:07 +0000
Subject: [R] Robust GAM that covers Gaussian Distributions
In-Reply-To: <loom.20150225T162216-476@post.gmane.org>
References: <CAMmHnJ0FvntaEy-XyUQJRv-M6j8tXhNbeCqKxTuq60qp9_xZtw@mail.gmail.com>	<loom.20130603T121347-492@post.gmane.org>
	<loom.20150225T162216-476@post.gmane.org>
Message-ID: <54EDFE2F.6050000@bath.ac.uk>

The 'scat' (scaled t) family in mgcv does allow for much heavier tails 
than Gaussian, but it may not be robust enough for you.

On 25/02/15 15:27, Ilaria Prosdocimi wrote:
> Ilaria Prosdocimi <ilapro <at> ceh.ac.uk> writes:
>
>>
>> Christos Giannoulis <cgiannoul <at> gmail.com> writes:
>>
>>>
>>> Dear All,
>>>
>>> I was looking the r-archives and crantastic...for a package that has
> a
>>> robust approach to generalized additive models. I found two packages
>>> "robustgam" and "rgam" but their implemented functions
>>> cover only binomial and poisson distributions (pls correct me if I
> am
>>> wrong).
>>>
>>> I would greatly appreciate if anyone could share with us other
> packages or
>>> robust approaches of general additive modeling that might have a
> better
>>> performance with small data sets (n = 50 -100 records).
>>>
>>> Thank you very much all for reading this message. I am hoping and
> looking
>>> forward to receiving your reply.
>>>
>>> Sincerely,
>>>
>>> Christos Giannoulis
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>>
>>
>> Indeed, it seems that both the libraries do not allow normal data. I
> think
>> you could try to use the code in this page
>> (http://www.stat.ubc.ca/~matias/penalised/) for S-estimation.
>> If you want the code for the Croux et al paper
>> (http://onlinelibrary.wiley.com/doi/10.1111/j.1541-
> 0420.2011.01630.x/full)
>> just email me (ilapro + ceh.ac.uk) - it seems to be not available
> online
>> anymore. This also allow normal data.
>>
>> Best
>>
>> Ilaria
>>
>>
>
>
>
> For information - in case somebody finds this post again in the future,
> the original files have now been restored in the KULeuven website at
> this address
> http://wis.kuleuven.be/stat/stat-inferen/codes
>
> I have also packaged the code in a R package which can be accessed on
> GitHub (and installed with devtools::install_github) at
>
> https://github.com/ilapros/DoubleRobGam
>
> Best
>
> Ilaria
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From jdnewmil at dcn.davis.CA.us  Wed Feb 25 17:54:46 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 25 Feb 2015 08:54:46 -0800
Subject: [R] plotting multiple time series under one panel
In-Reply-To: <CADgEnDmkCrVv8O5Ne5pu=WTM7sfFbn38cDEEEhx+JWSYnJ0pYg@mail.gmail.com>
References: <CADgEnDnzm1TOLurSpca2BrV9EnJkAQDS0Mp2VJv13ffoH6OjfQ@mail.gmail.com>
	<401A3A88-5716-4218-B94D-9ED6B2223180@dcn.davis.CA.us>
	<CADgEnDmkCrVv8O5Ne5pu=WTM7sfFbn38cDEEEhx+JWSYnJ0pYg@mail.gmail.com>
Message-ID: <D9217DF5-DD88-490D-B92C-4F244FD400D1@dcn.davis.CA.us>

This is a plain text mailing list, and HTML gets munged on the list. It doesn't help your cause when you don't follow the Posting Guide (or my previous recommendations).

>From the attached image, you do seem to want separate panels/facets. That is accomplished with the facet_wrap function with ggplot. If that tip is not sufficient, then re-read my previous response to guide you in posting a more complete question.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 25, 2015 6:21:14 AM PST, Raghuraman Ramachandran <optionsraghu at gmail.com> wrote:
>Apologies for the mis-communication Jeff.
>
>Here is what I intended to do:
>
>?The above chart is multiple line charts which I obtained by converting
>the
>same dataframe into an xts and then using plot.zoo. But for aesthetics
>I
>wanted to use ggplot2 which might have yielded better colours and
>visuals.
>Can I get something like the above using ggplot2 please?
>
>Cheers
>Raghu
>
>On Wed, Feb 25, 2015 at 1:59 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Your request is confusing. You first say "trying to plot ... together
>in
>> the same panel" and then complain "all graphs in one panel which did
>not
>> help".
>> For ggplot at least, melting seems likely to help, so this would
>really be
>> a good time for you to follow the request included in every message
>on this
>> list by providing a reproducible example and clarifying what you want
>as
>> output. You may find [1] helps you with making your example useful.
>>
>> [1]
>>
>http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 25, 2015 5:32:07 AM PST, Raghuraman Ramachandran <
>> optionsraghu at gmail.com> wrote:
>> >Dear guRus
>> >
>> >I have data frame as:
>> >str(voldf)
>> >'data.frame': 130 obs. of  8 variables:
>> > $ Date: Date, format: "2014-08-01" "2014-08-05" "2014-08-08" ...
>> > $ kc  : num  0.453 0.424 0.468 0.481 0.485 ...
>> > $ sb  : num  0.1128 0.123 0.1272 0.1128 0.0949 ...
>> > $ qc  : num  0.0626 0.0661 0.0777 0.0765 0.0763 ...
>> > $ c   : num  0.167 0.182 0.183 0.21 0.215 ...
>> > $ w   : num  0.21 0.271 0.282 0.351 0.345 ...
>> > $ s   : num  0.249 0.253 0.295 0.332 0.35 ...
>> > $ ct  : num  0.212 0.22 0.228 0.188 0.181 ...
>> >
>> >I am trying to plot multiple line charts for each of the columns and
>> >show them together in the same panel. Is it possible please using
>> >ggplot?
>> >
>> >I tried melting dfm=melt(voldf, id.vars="Date") and then plotted
>this
>> >but it gives me all graphs in one panel which did not help.
>> >
>> >Any assistance is greatly appreciated.
>> >
>> >Many thx
>> >Raghu
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From phaedrusv at gmail.com  Wed Feb 25 18:33:14 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Wed, 25 Feb 2015 17:33:14 +0000
Subject: [R] text miner error: Error in UseMethod("meta", x)
Message-ID: <54EE075A.1020003@gmail.com>

Hi list

I've been working my way through a tutorial on text mining ( 
http://onepager.togaware.com/TextMiningO.pdf ) and all was well until I 
came across this problem using tm (text miner):

++++++++++code+++++++++++++++++++
 > docs <- tm_map(docs, content_transformer(tolower))
Warning messages:
1: In mclapply(x$content[i], function(d) tm_reduce(d, x$lazy$maps)) :
   all scheduled cores encountered errors in user code
2: In mclapply(content(x), FUN, ...) :
   all scheduled cores encountered errors in user code
++++++++++end-code++++++++++++++++

After some searching, it appears the best fix for this problem was to 
pass an explicit lazy=TRUE argument to tm, like this:

 > docs <- tm_map(docs, content_transformer(tolower), lazy=TRUE)

However, a little further on in the tutorial to set up the text matrix, 
a related (?) error was returned:

++++++++++code+++++++++++++++++++
 > dtm <- DocumentTermMatrix(docs)
Error in UseMethod("meta", x) :
   no applicable method for 'meta' applied to an object of class "try-error"
In addition: Warning message:
In mclapply(unname(content(x)), termFreq, control) :
   all scheduled cores encountered errors in user code
++++++++++end-code++++++++++++++++

I tried applying the explicit lazy=TRUE again, but doesn't change 
things. I have gone over the tutorial again and have followed all of the 
steps (including loading the requisite libraries). Moreover, searching 
on the web seems to return several contradictory suggestions and I'm no 
wiser than I was before.

The closest I came to an answer was at Stack Overflow 
http://stackoverflow.com/questions/24771165/r-project-no-applicable-method-for-meta-applied-to-an-object-of-class-charact 
and that answer suggested using the latest tm (v 0.6) and claimed that 
the earlier tolower step was wrong. However, my code used the 
recommended: corpus <- tm_map(corpus, content_transformer(tolower))

Is there anyone on the list who could either sign-post me to a solution 
or assist in debugging this please?

I'm running R version 3.1.2 and tm is 0.6

Many thanks

Sun


From _ at tnhh.net  Wed Feb 25 18:42:09 2015
From: _ at tnhh.net (Huan Truong)
Date: Wed, 25 Feb 2015 11:42:09 -0600
Subject: [R] Getting Rmarkdown to generate custom LaTEX environment
In-Reply-To: <CAJuCY5zDZjdepHhjttgBbrzU5eDQBjViXYj+wH_9SiWp+VXQzw@mail.gmail.com>
References: <CAJtgXV0BxrsPfXNnA_YKVqBCmXVvzOLrXfBk4bPq+2cO2izXcw@mail.gmail.com>
	<CAJuCY5zDZjdepHhjttgBbrzU5eDQBjViXYj+wH_9SiWp+VXQzw@mail.gmail.com>
Message-ID: <CAJtgXV1it5gGzyrbTqVbdCbXDCp5-7AJJUzpkz4KgSYCrEJphA@mail.gmail.com>

Hi Thierry,

Thanks for the quick and informative answer. I understand that
rmarkdown doesn't know the concept of figure*. However, I wonder why
it knows that I could pass fig.cap fine, but not fig.env? Where in the
code of rmarkdown does it take care of that fig.cap handling, so I can
patch it to make it understand fig.env?

- Huan.

On Wed, Feb 25, 2015 at 3:39 AM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
> Dear Huan,
>
> Markdown doesn't know the concept of figure*. So you can't generate it with
> native Markdown markup. If you really need figure*, then the only option in
> markdown is to generate the LaTeX code yourself. Note that is will break
> conversion to formats that don't handle LaTeX code.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more than
> asking him to perform a post-mortem examination: he may be able to say what
> the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-02-25 3:28 GMT+01:00 Huan Truong <_ at tnhh.net>:
>>
>> Hi all,
>>
>> I was struggling trying to make my Rmarkdown document to generate
>>
>> \begin{figure*}
>>
>> instead of
>>
>> \begin{figure}
>>
>> So that the figure spans on two columns (I'm using a custom template).
>>
>> in my figure. I have read the Rmarkdown Reference Guide, and searched
>> for it on StackOverflow, and the general idea seems to be that I could
>> somehow pass the fig.env variable to the figure, but I have tried it
>> with no success: Something like this still doesn't have any effect
>> whatsoever on the latex code generated:
>>
>> ```{r test-plot, echo=FALSE, fig.cap = "Test
>> plot.\\label{fig:test-plot}", fig.env='figure*' }
>> options(fig.env='figure*')
>> plot(blah)
>> ```
>>
>> I know I must have missed something but couldn't figure out what I'm
>> missing after hours of struggling. Any help is much appreciated.
>>
>> I have a smaller problem where I want to customize the [htbp] option
>> of the figure, and facing the same problem.
>>
>> Cheers,
>> - Huan.
>>
>>
>>
>>
>>
>>
>> --
>>
>> Eccentric Graduate Student
>> Google Talk/Jabber huant at tnhh.net - Website tnhh.net - Phone
>> 1-858-848-ROFL
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 

Eccentric Graduate Student
Google Talk/Jabber huant at tnhh.net - Website tnhh.net - Phone 1-858-848-ROFL


From thierry.onkelinx at inbo.be  Wed Feb 25 19:53:36 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 25 Feb 2015 19:53:36 +0100
Subject: [R] Getting Rmarkdown to generate custom LaTEX environment
In-Reply-To: <CAJtgXV1it5gGzyrbTqVbdCbXDCp5-7AJJUzpkz4KgSYCrEJphA@mail.gmail.com>
References: <CAJtgXV0BxrsPfXNnA_YKVqBCmXVvzOLrXfBk4bPq+2cO2izXcw@mail.gmail.com>
	<CAJuCY5zDZjdepHhjttgBbrzU5eDQBjViXYj+wH_9SiWp+VXQzw@mail.gmail.com>
	<CAJtgXV1it5gGzyrbTqVbdCbXDCp5-7AJJUzpkz4KgSYCrEJphA@mail.gmail.com>
Message-ID: <CAJuCY5wsqFOppuU-ag7LAUNaaKt0QFpT3whtnivMbMohngy6cQ@mail.gmail.com>

This has nothing to do with *r*markdown but with the markdown language
itself. Markdown has the concept of a figure caption. Hence fig.cap in
Rmarkdown can work.
Op 25 feb. 2015 18:42 schreef "Huan Truong" <_ at tnhh.net>:

> Hi Thierry,
>
> Thanks for the quick and informative answer. I understand that
> rmarkdown doesn't know the concept of figure*. However, I wonder why
> it knows that I could pass fig.cap fine, but not fig.env? Where in the
> code of rmarkdown does it take care of that fig.cap handling, so I can
> patch it to make it understand fig.env?
>
> - Huan.
>
> On Wed, Feb 25, 2015 at 3:39 AM, Thierry Onkelinx
> <thierry.onkelinx at inbo.be> wrote:
> > Dear Huan,
> >
> > Markdown doesn't know the concept of figure*. So you can't generate it
> with
> > native Markdown markup. If you really need figure*, then the only option
> in
> > markdown is to generate the LaTeX code yourself. Note that is will break
> > conversion to formats that don't handle LaTeX code.
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> than
> > asking him to perform a post-mortem examination: he may be able to say
> what
> > the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> > 2015-02-25 3:28 GMT+01:00 Huan Truong <_ at tnhh.net>:
> >>
> >> Hi all,
> >>
> >> I was struggling trying to make my Rmarkdown document to generate
> >>
> >> \begin{figure*}
> >>
> >> instead of
> >>
> >> \begin{figure}
> >>
> >> So that the figure spans on two columns (I'm using a custom template).
> >>
> >> in my figure. I have read the Rmarkdown Reference Guide, and searched
> >> for it on StackOverflow, and the general idea seems to be that I could
> >> somehow pass the fig.env variable to the figure, but I have tried it
> >> with no success: Something like this still doesn't have any effect
> >> whatsoever on the latex code generated:
> >>
> >> ```{r test-plot, echo=FALSE, fig.cap = "Test
> >> plot.\\label{fig:test-plot}", fig.env='figure*' }
> >> options(fig.env='figure*')
> >> plot(blah)
> >> ```
> >>
> >> I know I must have missed something but couldn't figure out what I'm
> >> missing after hours of struggling. Any help is much appreciated.
> >>
> >> I have a smaller problem where I want to customize the [htbp] option
> >> of the figure, and facing the same problem.
> >>
> >> Cheers,
> >> - Huan.
> >>
> >>
> >>
> >>
> >>
> >>
> >> --
> >>
> >> Eccentric Graduate Student
> >> Google Talk/Jabber huant at tnhh.net - Website tnhh.net - Phone
> >> 1-858-848-ROFL
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
>
> --
>
> Eccentric Graduate Student
> Google Talk/Jabber huant at tnhh.net - Website tnhh.net - Phone
> 1-858-848-ROFL
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Feb 25 20:07:11 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 25 Feb 2015 14:07:11 -0500
Subject: [R] Getting Rmarkdown to generate custom LaTEX environment
In-Reply-To: <CAJuCY5wsqFOppuU-ag7LAUNaaKt0QFpT3whtnivMbMohngy6cQ@mail.gmail.com>
References: <CAJtgXV0BxrsPfXNnA_YKVqBCmXVvzOLrXfBk4bPq+2cO2izXcw@mail.gmail.com>	<CAJuCY5zDZjdepHhjttgBbrzU5eDQBjViXYj+wH_9SiWp+VXQzw@mail.gmail.com>	<CAJtgXV1it5gGzyrbTqVbdCbXDCp5-7AJJUzpkz4KgSYCrEJphA@mail.gmail.com>
	<CAJuCY5wsqFOppuU-ag7LAUNaaKt0QFpT3whtnivMbMohngy6cQ@mail.gmail.com>
Message-ID: <54EE1D5F.9000204@gmail.com>

On 25/02/2015 1:53 PM, Thierry Onkelinx wrote:
> This has nothing to do with *r*markdown but with the markdown language
> itself. Markdown has the concept of a figure caption. Hence fig.cap in
> Rmarkdown can work.

But rmarkdown is based on knitr, which is very flexible.  Presumably it 
is possible (and probably not that hard) to generate code to insert 
native LaTeX automatically.  It might look something like this, with the 
details filled in:

hook_fullpage <- function(before, options, envir) {
   # save the options
   # edit the options to set fig.env, which I think is a knitr concept
   # call the knitr latex hook
   # restore the options
}

knitr::knit_hooks$set(fullpage = hook_fullpage)

Then any chunk where you wanted this kind of inclusion you'd use the 
fullpage=TRUE option, and knitr
would insert a bit of LaTeX code into the middle of your markdown document.

Duncan Murdoch

> Op 25 feb. 2015 18:42 schreef "Huan Truong" <_ at tnhh.net>:
>
> > Hi Thierry,
> >
> > Thanks for the quick and informative answer. I understand that
> > rmarkdown doesn't know the concept of figure*. However, I wonder why
> > it knows that I could pass fig.cap fine, but not fig.env? Where in the
> > code of rmarkdown does it take care of that fig.cap handling, so I can
> > patch it to make it understand fig.env?
> >
> > - Huan.
> >
> > On Wed, Feb 25, 2015 at 3:39 AM, Thierry Onkelinx
> > <thierry.onkelinx at inbo.be> wrote:
> > > Dear Huan,
> > >
> > > Markdown doesn't know the concept of figure*. So you can't generate it
> > with
> > > native Markdown markup. If you really need figure*, then the only option
> > in
> > > markdown is to generate the LaTeX code yourself. Note that is will break
> > > conversion to formats that don't handle LaTeX code.
> > >
> > > Best regards,
> > >
> > > ir. Thierry Onkelinx
> > > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> > and
> > > Forest
> > > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > > Kliniekstraat 25
> > > 1070 Anderlecht
> > > Belgium
> > >
> > > To call in the statistician after the experiment is done may be no more
> > than
> > > asking him to perform a post-mortem examination: he may be able to say
> > what
> > > the experiment died of. ~ Sir Ronald Aylmer Fisher
> > > The plural of anecdote is not data. ~ Roger Brinner
> > > The combination of some data and an aching desire for an answer does not
> > > ensure that a reasonable answer can be extracted from a given body of
> > data.
> > > ~ John Tukey
> > >
> > > 2015-02-25 3:28 GMT+01:00 Huan Truong <_ at tnhh.net>:
> > >>
> > >> Hi all,
> > >>
> > >> I was struggling trying to make my Rmarkdown document to generate
> > >>
> > >> \begin{figure*}
> > >>
> > >> instead of
> > >>
> > >> \begin{figure}
> > >>
> > >> So that the figure spans on two columns (I'm using a custom template).
> > >>
> > >> in my figure. I have read the Rmarkdown Reference Guide, and searched
> > >> for it on StackOverflow, and the general idea seems to be that I could
> > >> somehow pass the fig.env variable to the figure, but I have tried it
> > >> with no success: Something like this still doesn't have any effect
> > >> whatsoever on the latex code generated:
> > >>
> > >> ```{r test-plot, echo=FALSE, fig.cap = "Test
> > >> plot.\\label{fig:test-plot}", fig.env='figure*' }
> > >> options(fig.env='figure*')
> > >> plot(blah)
> > >> ```
> > >>
> > >> I know I must have missed something but couldn't figure out what I'm
> > >> missing after hours of struggling. Any help is much appreciated.
> > >>
> > >> I have a smaller problem where I want to customize the [htbp] option
> > >> of the figure, and facing the same problem.
> > >>
> > >> Cheers,
> > >> - Huan.
> > >>
> > >>
> > >>
> > >>
> > >>
> > >>
> > >> --
> > >>
> > >> Eccentric Graduate Student
> > >> Google Talk/Jabber huant at tnhh.net - Website tnhh.net - Phone
> > >> 1-858-848-ROFL
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> >
> >
> >
> > --
> >
> > Eccentric Graduate Student
> > Google Talk/Jabber huant at tnhh.net - Website tnhh.net - Phone
> > 1-858-848-ROFL
> >
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chiefmurphy at gmail.com  Wed Feb 25 20:50:34 2015
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Wed, 25 Feb 2015 11:50:34 -0800
Subject: [R] Best Mac for R
Message-ID: <CAHgH9_EeBw6ntXmsu8nygYmEraL1G_dN++fP6wqvN9G8TMWWcw@mail.gmail.com>

I am possibly in the market for a new laptop. Predominantly a Windows
user, I owned a macbook pro 10 years ago and am considering going that
route again. Does the standard advice still hold: Get the most
powerful processor (i7), most ram (16GB), and largest internal storage
(512GB), if affordable?
thanks,
dan


From gunter.berton at gene.com  Wed Feb 25 21:10:06 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 25 Feb 2015 12:10:06 -0800
Subject: [R] Best Mac for R
In-Reply-To: <CAHgH9_EeBw6ntXmsu8nygYmEraL1G_dN++fP6wqvN9G8TMWWcw@mail.gmail.com>
References: <CAHgH9_EeBw6ntXmsu8nygYmEraL1G_dN++fP6wqvN9G8TMWWcw@mail.gmail.com>
Message-ID: <CACk-te097ryMaUxXgcayRMDixdt79NnECz+58rpamDb_tpa0TA@mail.gmail.com>

What does this have to do with R?

Does the answer not depend on what you intend to do with your laptop,
e.g the sorts of data you deal with, of which we have no idea?

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Feb 25, 2015 at 11:50 AM, Dan Murphy <chiefmurphy at gmail.com> wrote:
> I am possibly in the market for a new laptop. Predominantly a Windows
> user, I owned a macbook pro 10 years ago and am considering going that
> route again. Does the standard advice still hold: Get the most
> powerful processor (i7), most ram (16GB), and largest internal storage
> (512GB), if affordable?
> thanks,
> dan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msharp at txbiomed.org  Wed Feb 25 21:12:24 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Wed, 25 Feb 2015 14:12:24 -0600
Subject: [R] Best Mac for R
In-Reply-To: <CAHgH9_EeBw6ntXmsu8nygYmEraL1G_dN++fP6wqvN9G8TMWWcw@mail.gmail.com>
References: <CAHgH9_EeBw6ntXmsu8nygYmEraL1G_dN++fP6wqvN9G8TMWWcw@mail.gmail.com>
Message-ID: <88A6155C-9BF4-40CE-A899-3FDE1D6533AC@txbiomed.org>

For what I do, which does not require a lot of parallel work, the high end iMac was faster and much less expensive than the Mac Pro.

Mark
R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On Feb 25, 2015, at 1:50 PM, Dan Murphy <chiefmurphy at gmail.com> wrote:
>
> I am possibly in the market for a new laptop. Predominantly a Windows
> user, I owned a macbook pro 10 years ago and am considering going that
> route again. Does the standard advice still hold: Get the most
> powerful processor (i7), most ram (16GB), and largest internal storage
> (512GB), if affordable?
> thanks,
> dan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.


From A.Robinson at ms.unimelb.edu.au  Wed Feb 25 21:26:50 2015
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 26 Feb 2015 07:26:50 +1100
Subject: [R] Help with nonlinear least squares regression curve fitting
In-Reply-To: <1424880232286-4703812.post@n4.nabble.com>
References: <1424880232286-4703812.post@n4.nabble.com>
Message-ID: <CAHyGmd6rrUC_AOBHRHw7babXnMzrSbi4b7ZJt0vN5LRWVW2HAw@mail.gmail.com>

Finding starting values is a bit of a dark art.  That said, there are steps
you can take, but it may take time.

First, I would scale Year so that it's not in the thousands! Experiment
with subtracting 1980 or so.  For specific advice, see inline.

On Thu, Feb 26, 2015 at 3:03 AM, Corey Callaghan <ccallaghan2013 at fau.edu>
wrote:

> The curves' functions that I want to test are in the code here (hopefully
> correctly):
>
> Inverse Quadratic Curve:
> fitmodel <- nls(Area ~ (-a*Year)*(Year + b), data = df, start=list(a=??,
> b=??, c=??))
>

I would plot the data and a smooth spline, differentiate the curve
function, identify some parameter values somewhere stable, and estimate
some values by eye, or even predict them from the first derivative of the
spline - spline.smooth will do this.

Sigmodial Curve:
> fitmodel <- nls(Area~a/(1+exp(-(b+c*Year))), data=df, start=list(a=???,
> b=???, c=??))
>

I'd use the highest value as a, fit spline as above then invert area at two
times to get b and c.

Double sigmoidal Curve:
> fitmodel <- nls(Area~a+2b(1/(1+exp(-abs(-c*Year+d)))-1/2)*sign(-c*Year+d),
> data=df, start=list(a=???, b=???, c=???)
>

 I'd use min(Area) as a, figure out b from the maximum (I guess 2b+a is the
asymptote), and experiment with two values for year to retrieve c and d
.... uniroot might help?

Cheers

Andrew

-- 
Andrew Robinson
Deputy Director, CEBRA, School of Biosciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: +61-3-8344
4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au
Website: http://www.ms.unimelb.edu.au/~andrewpr

MSME: http://www.crcpress.com/product/isbn/9781439858028
FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
SPuR: http://www.ms.unimelb.edu.au/spuRs/

	[[alternative HTML version deleted]]


From btrautman84 at gmail.com  Wed Feb 25 22:24:38 2015
From: btrautman84 at gmail.com (Brian Trautman)
Date: Wed, 25 Feb 2015 13:24:38 -0800
Subject: [R] Merging Data.Tables on conditions other than equality
Message-ID: <CAFYnejLL_48NiM=5ZS=2MA1RDS+sjZros2Fy08gWPe9V1HNiiQ@mail.gmail.com>

I have two tables that I would like to join together in a way equivalent to
the following SQL.  Note that I'm using a "greater than" statement in my
join, rather than checking for equality.

require(sqldf)
require(data.table)


dt <- data.table(num=c(1, 2, 3, 4, 5, 6), char=c('A', 'A', 'A', 'B', 'B',
'B'))

dt_out_sql <- sqldf('
select dtone.num as num1, dttwo.num as num2, dttwo.char
from dt as dtone INNER join dt as dttwo on
(dtone.char = dttwo.char) and
(dtone.num *>=* dttwo.num)
')

I realize that I can use the below code, but would like to do the merging
and filtering in the same step (my data sets are large enough for
performance/memory concerns to come into play.

dt_out_r <- merge(x=dt, y=dt, by = c('char'), allow.cartesian=TRUE)
dt_out_r <- dt_out_r[num.x >= num.y]

Thank you very much!

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Wed Feb 25 22:40:42 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 25 Feb 2015 16:40:42 -0500
Subject: [R]  .Rd files
Message-ID: <CACxE24nTJFop4hEP03AtBR0NGvPjRu=-BnRQX0sXCT351GRrKg@mail.gmail.com>

Hello there!

When you use package.skeleton, you can put in all of your nice functions,
and the "bones" of the .Rd files are generated, which is fine.

Now if you add another R function after the fact into the package, is there
a quick-and-dirty function to generate an .Rd file, please?

My inclination is to say no, but thought I'd double check.

Thanks,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Wed Feb 25 22:45:08 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 25 Feb 2015 16:45:08 -0500
Subject: [R] .Rd files
In-Reply-To: <CACxE24nTJFop4hEP03AtBR0NGvPjRu=-BnRQX0sXCT351GRrKg@mail.gmail.com>
References: <CACxE24nTJFop4hEP03AtBR0NGvPjRu=-BnRQX0sXCT351GRrKg@mail.gmail.com>
Message-ID: <CACxE24=6ECWnkdKX8ck8MHso_yowzYdZu0fcaWaW_D3mNnTPXg@mail.gmail.com>

Solved:  it's the prompt function.

On Wed, Feb 25, 2015 at 4:40 PM, Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Hello there!
>
> When you use package.skeleton, you can put in all of your nice functions,
> and the "bones" of the .Rd files are generated, which is fine.
>
> Now if you add another R function after the fact into the package, is
> there a quick-and-dirty function to generate an .Rd file, please?
>
> My inclination is to say no, but thought I'd double check.
>
> Thanks,
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From grossm at gmail.com  Wed Feb 25 22:18:58 2015
From: grossm at gmail.com (Matt Gross)
Date: Wed, 25 Feb 2015 13:18:58 -0800
Subject: [R] Processing key_column, begin_date, end_date in R
Message-ID: <CALYoQdoOqXt1qx8=BTGBZPHsKYbRGETBz+vPQ9eQfD1wePjRiA@mail.gmail.com>

Hi,

I am trying to process a large dataset in R.  The dataset contains the
following three columns:

key_column - a unique key identifier
begin_date - the start date of the active period
end_date - the end date of the active period


Example data is here:

key_column,begin_date,end_date
123456,2013-01-01,2014-01-01
123456,2013-07-01,2014-07-01
789102,2012-03-01,2014-03-01
789102,2015-02-01,2016-02-01
789102,2015-02-06,2016-02-06

I want to build a condensed table of key_column and begin_date's and
end_date's.  As you can see in the example data above, some begin and end
date periods overlap with begin_date and end_date pairs for the same
key_column.  In situations where overlap exists I want to have one record
for the key_column with the min(begin_date) and the max(end_date).

Can anyone help me build the commands to process this data in R?

Thanks,
Matt

-- 
Matt Gross
grossm at gmail.com
503.329.4545

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Wed Feb 25 23:53:07 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 25 Feb 2015 23:53:07 +0100
Subject: [R] Best Mac for R
In-Reply-To: <88A6155C-9BF4-40CE-A899-3FDE1D6533AC@txbiomed.org>
References: <CAHgH9_EeBw6ntXmsu8nygYmEraL1G_dN++fP6wqvN9G8TMWWcw@mail.gmail.com>
	<88A6155C-9BF4-40CE-A899-3FDE1D6533AC@txbiomed.org>
Message-ID: <CALJKBv-WXYN31hFXafHX74HCF+9V+-NqbLbAr40LsrWzt9Ey4A@mail.gmail.com>

 Hi,
It is not so efficient to have the most speed processor or biggest RAM. In
general One processor is working at the time.
It is more interesting to work with Linux for multiple multi_thread package
and 64 bit.
I am not sure if turbo boost is working with R.
http://stackoverflow.com/questions/1395309/how-to-make-r-use-all-processors


On Wed, Feb 25, 2015 at 9:12 PM, Mark Sharp <msharp at txbiomed.org> wrote:

> For what I do, which does not require a lot of parallel work, the high end
> iMac was faster and much less expensive than the Mac Pro.
>
> Mark
> R. Mark Sharp, Ph.D.
> msharp at TxBiomed.org
>
>
>
>
>
> > On Feb 25, 2015, at 1:50 PM, Dan Murphy <chiefmurphy at gmail.com> wrote:
> >
> > I am possibly in the market for a new laptop. Predominantly a Windows
> > user, I owned a macbook pro 10 years ago and am considering going that
> > route again. Does the standard advice still hold: Get the most
> > powerful processor (i7), most ram (16GB), and largest internal storage
> > (512GB), if affordable?
> > thanks,
> > dan
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
> NOTICE:  This E-Mail (including attachments) is confidential and may be
> legally privileged.  It is covered by the Electronic Communications Privacy
> Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are
> hereby notified that any retention, dissemination, distribution or copying
> of this communication is strictly prohibited.  Please reply to the sender
> that you have received this message in error, then delete it.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From putra_autumn86 at yahoo.com  Wed Feb 25 23:54:19 2015
From: putra_autumn86 at yahoo.com (smart hendsome)
Date: Wed, 25 Feb 2015 22:54:19 +0000 (UTC)
Subject: [R] Replace the value with 1 and 0
Message-ID: <393318048.85141.1424904859310.JavaMail.yahoo@mail.yahoo.com>

Hi everyone,
I have this kind of rainfall dataset:
?? Year Month Day Amount
1? 1950???? 1?? 1??? 0.0
2? 1950???? 1?? 2?? 35.5
3? 1950???? 1?? 3?? 17.8
4? 1950???? 1?? 4?? 24.5
5? 1950???? 1?? 5?? 12.3
6? 1950???? 1?? 6?? 11.5
7? 1950???? 1?? 7??? 5.7
8? 1950???? 1?? 8?? 13.2
9? 1950???? 1?? 9?? 11.3
10 1950???? 1? 10?? 14.7
11 1950???? 1? 11?? 11.9
12 1950???? 1? 12?? 17.5
13 1950???? 1? 13??? 8.1
14 1950???? 1? 14??? 0.4
15 1950???? 1? 15??? 0.0
16 1950???? 1? 16?? 19.5
17 1950???? 1? 17?? 10.7
18 1950???? 1? 18??? 0.5
19 1950???? 1? 19?? 12.7
20 1950???? 1? 20??? 6.3

I want to set as rain for Amount> 0 and not rain for Amount = 0.? I want to replace the Amount>0 with 1 and Amount equal to zero with 0.? Then I want to count how many rain in that particular month in that year. Anyone can help me?
This is what I want:
 Year Month Day Amount
1? 1950???? 1?? 1?? ? 0
2? 1950???? 1?? 2? ?? 1
3? 1950???? 1?? 3???? 1
4? 1950???? 1?? 4???? 1
5? 1950???? 1?? 5? ?? 1
6? 1950???? 1?? 6???? 1
7? 1950???? 1?? 7?? ? 1
8? 1950???? 1?? 8???? 1
9? 1950???? 1?? 9???? 1
10 1950???? 1? 10??? 1
11 1950???? 1? 11?? ? 1
12 1950???? 1? 12??? 1
13 1950???? 1? 13??? 1
14 1950???? 1? 14??? 1
15 1950???? 1? 15??? 1
16 1950???? 1? 16??? 1
17 1950???? 1? 17??? 1
18 1950???? 1? 18??? 1
19 1950???? 1? 19??? 1
20 1950???? 1? 20??? 1
Then become like this:
 
| 
 | Jan | Feb | Mar | Apr | May | Jun | Jul | Aug | Sep | Oct | Nov | Dec |
| 1950 | 17 | 6 | 23 | 20 | 19 | 9 | 17 | 23 | 18 | 20 | 20 | 17 |
| 1951 | 23 | 19 | 20 | 20 | 19 | 11 | 16 | 20 | 22 | 25 | 25 | 16 |
| 1952 | 15 | 21 | 30 | 24 | 23 | 20 | 16 | 19 | 20 | 19 | 21 | 15 |


Thanks.


	[[alternative HTML version deleted]]


From Peter.Alspach at plantandfood.co.nz  Thu Feb 26 00:26:54 2015
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Thu, 26 Feb 2015 12:26:54 +1300
Subject: [R] Replace the value with 1 and 0
In-Reply-To: <393318048.85141.1424904859310.JavaMail.yahoo@mail.yahoo.com>
References: <393318048.85141.1424904859310.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <E41B375B7520DE4A8C60781AC60B754501BD429CFC@AKLEXM01.PFR.CO.NZ>

Tena koe

Something like:

set.seed(153)
# Create some (unrealistic) rainfall data
yourData <- data.frame(year=rep(1950:1954, each=10), month=rep(rep(1:2, each=5), 5), rain=sample(0:1, 50, replace=TRUE)*round(rnorm(50, 20, 2), 1))
tapply(yourData$rain>0, yourData[,c('year','month')], sum)

will give your final table, but it will need some tidying up.

HTH ....

Peter Alspach


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of smart hendsome
Sent: Thursday, 26 February 2015 11:54 a.m.
To: r-help at r-project.org
Subject: [R] Replace the value with 1 and 0

Hi everyone,
I have this kind of rainfall dataset:
?? Year Month Day Amount
1? 1950???? 1?? 1??? 0.0
2? 1950???? 1?? 2?? 35.5
3? 1950???? 1?? 3?? 17.8
4? 1950???? 1?? 4?? 24.5
5? 1950???? 1?? 5?? 12.3
6? 1950???? 1?? 6?? 11.5
7? 1950???? 1?? 7??? 5.7
8? 1950???? 1?? 8?? 13.2
9? 1950???? 1?? 9?? 11.3
10 1950???? 1? 10?? 14.7
11 1950???? 1? 11?? 11.9
12 1950???? 1? 12?? 17.5
13 1950???? 1? 13??? 8.1
14 1950???? 1? 14??? 0.4
15 1950???? 1? 15??? 0.0
16 1950???? 1? 16?? 19.5
17 1950???? 1? 17?? 10.7
18 1950???? 1? 18??? 0.5
19 1950???? 1? 19?? 12.7
20 1950???? 1? 20??? 6.3

I want to set as rain for Amount> 0 and not rain for Amount = 0.? I want to replace the Amount>0 with 1 and Amount equal to zero with 0.? Then I want to count how many rain in that particular month in that year. Anyone can help me?
This is what I want:
 Year Month Day Amount
1? 1950???? 1?? 1?? ? 0
2? 1950???? 1?? 2? ?? 1
3? 1950???? 1?? 3???? 1
4? 1950???? 1?? 4???? 1
5? 1950???? 1?? 5? ?? 1
6? 1950???? 1?? 6???? 1
7? 1950???? 1?? 7?? ? 1
8? 1950???? 1?? 8???? 1
9? 1950???? 1?? 9???? 1
10 1950???? 1? 10??? 1
11 1950???? 1? 11?? ? 1
12 1950???? 1? 12??? 1
13 1950???? 1? 13??? 1
14 1950???? 1? 14??? 1
15 1950???? 1? 15??? 1
16 1950???? 1? 16??? 1
17 1950???? 1? 17??? 1
18 1950???? 1? 18??? 1
19 1950???? 1? 19??? 1
20 1950???? 1? 20??? 1
Then become like this:
 
| 
 | Jan | Feb | Mar | Apr | May | Jun | Jul | Aug | Sep | Oct | Nov | Dec |
| 1950 | 17 | 6 | 23 | 20 | 19 | 9 | 17 | 23 | 18 | 20 | 20 | 17 |
| 1951 | 23 | 19 | 20 | 20 | 19 | 11 | 16 | 20 | 22 | 25 | 25 | 16 |
| 1952 | 15 | 21 | 30 | 24 | 23 | 20 | 16 | 19 | 20 | 19 | 21 | 15 |


Thanks.


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The contents of this e-mail are confidential and may be subject to legal privilege.
 If you are not the intended recipient you must not use, disseminate, distribute or
 reproduce all or any part of this e-mail or attachments.  If you have received this
 e-mail in error, please notify the sender and delete all material pertaining to this
 e-mail.  Any opinion or views expressed in this e-mail are those of the individual
 sender and may not represent those of The New Zealand Institute for Plant and
 Food Research Limited.

From clint at ecy.wa.gov  Thu Feb 26 00:40:44 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Wed, 25 Feb 2015 15:40:44 -0800 (PST)
Subject: [R] Replace the value with 1 and 0
In-Reply-To: <E41B375B7520DE4A8C60781AC60B754501BD429CFC@AKLEXM01.PFR.CO.NZ>
References: <393318048.85141.1424904859310.JavaMail.yahoo@mail.yahoo.com>
	<E41B375B7520DE4A8C60781AC60B754501BD429CFC@AKLEXM01.PFR.CO.NZ>
Message-ID: <alpine.LRH.2.11.1502251540010.18806@aeolus.ecy.wa.gov>

or:

with(yourData,table(year,month,yourData[["rain"]]>0))

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Thu, 26 Feb 2015, Peter Alspach wrote:

> Tena koe
>
> Something like:
>
> set.seed(153)
> # Create some (unrealistic) rainfall data
> yourData <- data.frame(year=rep(1950:1954, each=10), month=rep(rep(1:2, each=5), 5), rain=sample(0:1, 50, replace=TRUE)*round(rnorm(50, 20, 2), 1))
> tapply(yourData$rain>0, yourData[,c('year','month')], sum)
>
> will give your final table, but it will need some tidying up.
>
> HTH ....
>
> Peter Alspach
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of smart hendsome
> Sent: Thursday, 26 February 2015 11:54 a.m.
> To: r-help at r-project.org
> Subject: [R] Replace the value with 1 and 0
>
> Hi everyone,
> I have this kind of rainfall dataset:
> ?? Year Month Day Amount
> 1? 1950???? 1?? 1??? 0.0
> 2? 1950???? 1?? 2?? 35.5
> 3? 1950???? 1?? 3?? 17.8
> 4? 1950???? 1?? 4?? 24.5
> 5? 1950???? 1?? 5?? 12.3
> 6? 1950???? 1?? 6?? 11.5
> 7? 1950???? 1?? 7??? 5.7
> 8? 1950???? 1?? 8?? 13.2
> 9? 1950???? 1?? 9?? 11.3
> 10 1950???? 1? 10?? 14.7
> 11 1950???? 1? 11?? 11.9
> 12 1950???? 1? 12?? 17.5
> 13 1950???? 1? 13??? 8.1
> 14 1950???? 1? 14??? 0.4
> 15 1950???? 1? 15??? 0.0
> 16 1950???? 1? 16?? 19.5
> 17 1950???? 1? 17?? 10.7
> 18 1950???? 1? 18??? 0.5
> 19 1950???? 1? 19?? 12.7
> 20 1950???? 1? 20??? 6.3
>
> I want to set as rain for Amount> 0 and not rain for Amount = 0.? I want to replace the Amount>0 with 1 and Amount equal to zero with 0.? Then I want to count how many rain in that particular month in that year. Anyone can help me?
> This is what I want:
> Year Month Day Amount
> 1? 1950???? 1?? 1?? ? 0
> 2? 1950???? 1?? 2? ?? 1
> 3? 1950???? 1?? 3???? 1
> 4? 1950???? 1?? 4???? 1
> 5? 1950???? 1?? 5? ?? 1
> 6? 1950???? 1?? 6???? 1
> 7? 1950???? 1?? 7?? ? 1
> 8? 1950???? 1?? 8???? 1
> 9? 1950???? 1?? 9???? 1
> 10 1950???? 1? 10??? 1
> 11 1950???? 1? 11?? ? 1
> 12 1950???? 1? 12??? 1
> 13 1950???? 1? 13??? 1
> 14 1950???? 1? 14??? 1
> 15 1950???? 1? 15??? 1
> 16 1950???? 1? 16??? 1
> 17 1950???? 1? 17??? 1
> 18 1950???? 1? 18??? 1
> 19 1950???? 1? 19??? 1
> 20 1950???? 1? 20??? 1
> Then become like this:
>
> |
> | Jan | Feb | Mar | Apr | May | Jun | Jul | Aug | Sep | Oct | Nov | Dec |
> | 1950 | 17 | 6 | 23 | 20 | 19 | 9 | 17 | 23 | 18 | 20 | 20 | 17 |
> | 1951 | 23 | 19 | 20 | 20 | 19 | 11 | 16 | 20 | 22 | 25 | 25 | 16 |
> | 1952 | 15 | 21 | 30 | 24 | 23 | 20 | 16 | 19 | 20 | 19 | 21 | 15 |
>
>
> Thanks.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> The contents of this e-mail are confidential and may be subject to legal privilege.
> If you are not the intended recipient you must not use, disseminate, distribute or
> reproduce all or any part of this e-mail or attachments.  If you have received this
> e-mail in error, please notify the sender and delete all material pertaining to this
> e-mail.  Any opinion or views expressed in this e-mail are those of the individual
> sender and may not represent those of The New Zealand Institute for Plant and
> Food Research Limited.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From js.huang at protective.com  Thu Feb 26 00:33:29 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 25 Feb 2015 15:33:29 -0800 (PST)
Subject: [R] Replace the value with 1 and 0
In-Reply-To: <393318048.85141.1424904859310.JavaMail.yahoo@mail.yahoo.com>
References: <393318048.85141.1424904859310.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1424907209414-4703840.post@n4.nabble.com>

Hi,

  Here is an implementation.  More data are added.  An extra column hasRain
is added instead of replacing column Amount.

> rain
   Year Month Day Amount
1  1950     1   1    0.0
2  1950     1   2   35.5
3  1950     1   3   17.8
4  1950     1   4   24.5
5  1950     1   5   12.3
6  1950     1   6   11.5
7  1950     1   7    5.7
8  1950     1   8   13.2
9  1950     1   9   11.3
10 1950     1  10   14.7
11 1950     1  11   11.9
12 1950     1  12   17.5
13 1950     1  13    8.1
14 1950     1  14    0.4
15 1950     1  15    0.0
16 1950     1  16   19.5
17 1950     1  17   10.7
18 1950     1  18    0.5
19 1950     1  19   12.7
20 1950     1  20    6.3
21 1950     2   1    0.0
22 1950     2   2   35.5
23 1950     2   3   17.8
24 1950     2   4   24.5
25 1950     2   5   12.3
26 1950     2   6   11.5
27 1950     2   7    5.7
28 1950     2   8   13.2
29 1950     2   9   11.3
30 1950     2  10   14.7
31 1950     2  11   11.9
32 1950     2  12   17.5
33 1950     2  13    8.1
34 1950     2  14    0.4
35 1950     2  15    0.0
36 1950     2  16   19.5
37 1950     2  17   10.7
38 1950     2  18    0.0
39 1950     2  19    0.0
40 1950     2  20    0.0
> rain$hasRain <- ifelse(rain$Amount>0,1,0)
> rain
   Year Month Day Amount hasRain
1  1950     1   1    0.0       0
2  1950     1   2   35.5       1
3  1950     1   3   17.8       1
4  1950     1   4   24.5       1
5  1950     1   5   12.3       1
6  1950     1   6   11.5       1
7  1950     1   7    5.7       1
8  1950     1   8   13.2       1
9  1950     1   9   11.3       1
10 1950     1  10   14.7       1
11 1950     1  11   11.9       1
12 1950     1  12   17.5       1
13 1950     1  13    8.1       1
14 1950     1  14    0.4       1
15 1950     1  15    0.0       0
16 1950     1  16   19.5       1
17 1950     1  17   10.7       1
18 1950     1  18    0.5       1
19 1950     1  19   12.7       1
20 1950     1  20    6.3       1
21 1950     2   1    0.0       0
22 1950     2   2   35.5       1
23 1950     2   3   17.8       1
24 1950     2   4   24.5       1
25 1950     2   5   12.3       1
26 1950     2   6   11.5       1
27 1950     2   7    5.7       1
28 1950     2   8   13.2       1
29 1950     2   9   11.3       1
30 1950     2  10   14.7       1
31 1950     2  11   11.9       1
32 1950     2  12   17.5       1
33 1950     2  13    8.1       1
34 1950     2  14    0.4       1
35 1950     2  15    0.0       0
36 1950     2  16   19.5       1
37 1950     2  17   10.7       1
38 1950     2  18    0.0       0
39 1950     2  19    0.0       0
40 1950     2  20    0.0       0
> tapply(rain$hasRain,list(rain$Year,rain$Month),sum)
      1  2
1950 18 15
> 



--
View this message in context: http://r.789695.n4.nabble.com/Replace-the-value-with-1-and-0-tp4703838p4703840.html
Sent from the R help mailing list archive at Nabble.com.


From zadig_1 at excite.com  Thu Feb 26 02:55:49 2015
From: zadig_1 at excite.com (ce)
Date: Wed, 25 Feb 2015 20:55:49 -0500
Subject: [R] How many digits are there in left of dot of 0.0001 ?
Message-ID: <20150225205549.17338@web005.roc2.bluetie.com>

Dear all,

I would like to count how many digits are there on the left of a the dot of a numeric variable

a=0.0001

thanks


From hasan.diwan at gmail.com  Thu Feb 26 03:26:03 2015
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Wed, 25 Feb 2015 18:26:03 -0800
Subject: [R] How many digits are there in left of dot of 0.0001 ?
In-Reply-To: <20150225205549.17338@web005.roc2.bluetie.com>
References: <20150225205549.17338@web005.roc2.bluetie.com>
Message-ID: <CAP+bYWDHtPj-dPL3ys_z6TJ5o6K_FMhn=SCgZQS2jKGVG_VgMQ@mail.gmail.com>

On 25 February 2015 at 17:55, ce <zadig_1 at excite.com> wrote:

> Dear all,
>
> I would like to count how many digits are there on the left of a the dot
> of a numeric variable
>

Left? An infinite number... What does this have to do with R, though? -- H

>
> a=0.0001
>
> thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
OpenPGP: https://hasan.d8u.us/gpg.key
Sent from my mobile device
Envoy? de mon portable

	[[alternative HTML version deleted]]


From zadig_1 at excite.com  Thu Feb 26 03:43:35 2015
From: zadig_1 at excite.com (ce)
Date: Wed, 25 Feb 2015 21:43:35 -0500
Subject: [R] How many digits are there in left of dot of 0.0001 ?
Message-ID: <20150225214335.7437@web006.roc2.bluetie.com>


Sorry I meant right. I want to do it R of course. result should be 4 naturally. On the left answer I want would be 1 , 

-----Original Message-----
From: "Hasan Diwan" [hasan.diwan at gmail.com]
Date: 02/25/2015 09:28 PM
To: "R Project Help" <r-help at r-project.org>
Subject: Re: [R] How many digits are there in left of dot of 0.0001 ?

On 25 February 2015 at 17:55, ce <zadig_1 at excite.com> wrote:

> Dear all,
>
> I would like to count how many digits are there on the left of a the dot
> of a numeric variable
>

Left? An infinite number... What does this have to do with R, though? -- H

>
> a=0.0001
>
> thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
OpenPGP: https://hasan.d8u.us/gpg.key
Sent from my mobile device
Envoy? de mon portable

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code


From hasan.diwan at gmail.com  Thu Feb 26 03:54:57 2015
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Wed, 25 Feb 2015 18:54:57 -0800
Subject: [R] How many digits are there in left of dot of 0.0001 ?
In-Reply-To: <20150225214335.7437@web006.roc2.bluetie.com>
References: <20150225214335.7437@web006.roc2.bluetie.com>
Message-ID: <CAP+bYWBYaXbPUsekZH_p6_4mwD-EtCGSbp1qBr_PBqGo50BYoA@mail.gmail.com>

Ahh... The exponent of your number in scientific notation, which you can
obtain using:

format(a.number, scientific=TRUE)

Hope that helps.. -- H

On 25 February 2015 at 18:43, ce <zadig_1 at excite.com> wrote:

>
> Sorry I meant right. I want to do it R of course. result should be 4
> naturally. On the left answer I want would be 1 ,
>
> -----Original Message-----
> From: "Hasan Diwan" [hasan.diwan at gmail.com]
> Date: 02/25/2015 09:28 PM
> To: "R Project Help" <r-help at r-project.org>
> Subject: Re: [R] How many digits are there in left of dot of 0.0001 ?
>
> On 25 February 2015 at 17:55, ce <zadig_1 at excite.com> wrote:
>
> > Dear all,
> >
> > I would like to count how many digits are there on the left of a the dot
> > of a numeric variable
> >
>
> Left? An infinite number... What does this have to do with R, though? -- H
>
> >
> > a=0.0001
> >
> > thanks
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> OpenPGP: https://hasan.d8u.us/gpg.key
> Sent from my mobile device
> Envoy? de mon portable
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code
>



-- 
OpenPGP: https://hasan.d8u.us/gpg.key
Sent from my mobile device
Envoy? de mon portable

	[[alternative HTML version deleted]]


From zadig_1 at excite.com  Thu Feb 26 04:14:52 2015
From: zadig_1 at excite.com (ce)
Date: Wed, 25 Feb 2015 22:14:52 -0500
Subject: [R] How many digits are there in left of dot of 0.0001 ?
Message-ID: <20150225221452.31974@web005.roc2.bluetie.com>


No no, I don't want scientific , I want really the number 4 in a variable or cut the 4 out of 1e-04 . I can do it with sub what difficulty is to cut how many characters , one or two 


-----Original Message-----
From: "Hasan Diwan" [hasan.diwan at gmail.com]
Date: 02/25/2015 09:55 PM
To: "ce" <zadig_1 at excite.com>
CC: "R Project Help" <r-help at r-project.org>
Subject: Re: [R] How many digits are there in left of dot of 0.0001 ?

Ahh... The exponent of your number in scientific notation, which you can obtain using:

format(a.number, scientific=TRUE)


Hope that helps.. -- H


On 25 February 2015 at 18:43, ce <zadig_1 at excite.com> wrote:

Sorry I meant right. I want to do it R of course. result should be 4 naturally. On the left answer I want would be 1 ,

-----Original Message-----
From: "Hasan Diwan" [hasan.diwan at gmail.com]
Date: 02/25/2015 09:28 PM
To: "R Project Help" <r-help at r-project.org>
Subject: Re: [R] How many digits are there in left of dot of 0.0001 ?

On 25 February 2015 at 17:55, ce <zadig_1 at excite.com> wrote:

> Dear all,
>
> I would like to count how many digits are there on the left of a the dot
> of a numeric variable
>

Left? An infinite number... What does this have to do with R, though? -- H

>
> a=0.0001
>
> thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



--
OpenPGP: https://hasan.d8u.us/gpg.key
Sent from my mobile device
Envoy? de mon portable



? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code





-- 
OpenPGP: https://hasan.d8u.us/gpg.key
Sent from my mobile device
Envoy? de mon portable


From chiefmurphy at gmail.com  Thu Feb 26 06:26:22 2015
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Wed, 25 Feb 2015 21:26:22 -0800
Subject: [R] Best Mac for R
In-Reply-To: <CALJKBv-WXYN31hFXafHX74HCF+9V+-NqbLbAr40LsrWzt9Ey4A@mail.gmail.com>
References: <CAHgH9_EeBw6ntXmsu8nygYmEraL1G_dN++fP6wqvN9G8TMWWcw@mail.gmail.com>
	<88A6155C-9BF4-40CE-A899-3FDE1D6533AC@txbiomed.org>
	<CALJKBv-WXYN31hFXafHX74HCF+9V+-NqbLbAr40LsrWzt9Ey4A@mail.gmail.com>
Message-ID: <CAHgH9_Fdq=o5dwsBhJkCbVqdXD8jvsGX-EjWTVqUXANGVXG3hw@mail.gmail.com>

Quick responses as usual. Can always count on R-Help! Bert's point
that "it depends" is key, of course. Mark and Karim reminded me that R
does not use all cores natively. Putting those together, an expensive
quad core machine is not necessary for simple package development,
documentation, etc. And for hard core (no pun intended) analysis, a
multi-core machine won't be fully utilized without parallel
implementation of some type. Thanks all for your advice. Just what I
was looking for.
Dan

On Wed, Feb 25, 2015 at 2:53 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
> Hi,
> It is not so efficient to have the most speed processor or biggest RAM. In
> general One processor is working at the time.
> It is more interesting to work with Linux for multiple multi_thread package
> and 64 bit.
> I am not sure if turbo boost is working with R.
> http://stackoverflow.com/questions/1395309/how-to-make-r-use-all-processors
>
>
> On Wed, Feb 25, 2015 at 9:12 PM, Mark Sharp <msharp at txbiomed.org> wrote:
>>
>> For what I do, which does not require a lot of parallel work, the high end
>> iMac was faster and much less expensive than the Mac Pro.
>>
>> Mark
>> R. Mark Sharp, Ph.D.
>> msharp at TxBiomed.org
>>
>>
>>
>>
>>
>> > On Feb 25, 2015, at 1:50 PM, Dan Murphy <chiefmurphy at gmail.com> wrote:
>> >
>> > I am possibly in the market for a new laptop. Predominantly a Windows
>> > user, I owned a macbook pro 10 years ago and am considering going that
>> > route again. Does the standard advice still hold: Get the most
>> > powerful processor (i7), most ram (16GB), and largest internal storage
>> > (512GB), if affordable?
>> > thanks,
>> > dan
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> NOTICE:  This E-Mail (including attachments) is confidential and may be
>> legally privileged.  It is covered by the Electronic Communications Privacy
>> Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are
>> hereby notified that any retention, dissemination, distribution or copying
>> of this communication is strictly prohibited.  Please reply to the sender
>> that you have received this message in error, then delete it.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From js.huang at protective.com  Thu Feb 26 03:52:50 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 25 Feb 2015 18:52:50 -0800 (PST)
Subject: [R] How many digits are there in left of dot of 0.0001 ?
In-Reply-To: <20150225205549.17338@web005.roc2.bluetie.com>
References: <20150225205549.17338@web005.roc2.bluetie.com>
Message-ID: <1424919170407-4703847.post@n4.nabble.com>

Hi,

  I assume you want to know the digit count to the left of decimal point. 
If this is the case, then you may use  trunc(log10(max(1,trunc(abs(a)))))+1
for a numerical variable a.  Count 0.12 as having one digit to the left of
decimal point.

> trunc(log10(max(1,trunc(abs(-100000.99)))))+1
[1] 6
> trunc(log10(max(1,trunc(abs(0)))))+1
[1] 1
> trunc(log10(max(1,trunc(abs(9.999)))))+1
[1] 1
> trunc(log10(max(1,trunc(abs(19.999)))))+1
[1] 2
> trunc(log10(max(1,trunc(abs(-1999.999)))))+1
[1] 4



--
View this message in context: http://r.789695.n4.nabble.com/How-many-digits-are-there-in-left-of-dot-of-0-0001-tp4703842p4703847.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Thu Feb 26 04:31:00 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 25 Feb 2015 19:31:00 -0800 (PST)
Subject: [R] How many digits are there in left of dot of 0.0001 ?
In-Reply-To: <20150225214335.7437@web006.roc2.bluetie.com>
References: <20150225205549.17338@web005.roc2.bluetie.com>
	<20150225214335.7437@web006.roc2.bluetie.com>
Message-ID: <1424921460072-4703849.post@n4.nabble.com>

Hi,

  To get the number of digits to the right of decimal point: 
nchar(format(a,scientific=FALSE))-(trunc(log10(max(1,trunc(abs(a)))))+1) -1.  

  The part (trunc(log10(max(1,trunc(abs(a)))))+1) is the number of digits to
the left of decimal.  At the end, subtract 1 for the decimal point.

  Negative number needs more work.

> options(digits=10)
> a <- 0.0001
> nchar(format(a,scientific=FALSE))-(trunc(log10(max(1,trunc(abs(a)))))+1)
> -1
[1] 4
> a <- 999.123456
> nchar(format(a,scientific=FALSE))-(trunc(log10(max(1,trunc(abs(a)))))+1)
> -1
[1] 6



--
View this message in context: http://r.789695.n4.nabble.com/How-many-digits-are-there-in-left-of-dot-of-0-0001-tp4703842p4703849.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Thu Feb 26 05:18:36 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 25 Feb 2015 20:18:36 -0800 (PST)
Subject: [R] Processing key_column, begin_date, end_date in R
In-Reply-To: <CALYoQdoOqXt1qx8=BTGBZPHsKYbRGETBz+vPQ9eQfD1wePjRiA@mail.gmail.com>
References: <CALYoQdoOqXt1qx8=BTGBZPHsKYbRGETBz+vPQ9eQfD1wePjRiA@mail.gmail.com>
Message-ID: <1424924316788-4703850.post@n4.nabble.com>

Hi,
  
  Here is an implemenation:

> date
  key_column begin_date    end_date
1     123456 2013-01-01 2014-01-01 
2     123456 2013-07-01 2014-07-01 
3     789102 2012-03-01 2014-03-01 
4     789102 2015-02-01 2016-02-01 
5     789102 2015-02-06  2016-02-06
> y <- t(sapply(unique(date$key_column),function(x)
> c(x,min(as.character(date[date$key_column==x,"begin_date"])),max(as.character(date[date$key_column==x,"end_date"])))))
> y
     [,1]     [,2]         [,3]         
[1,] "123456" "2013-01-01" "2014-07-01 "
[2,] "789102" "2012-03-01" "2016-02-06" 
> colnames(y)
NULL
> colnames(y) <- c("key_column","begin_date","end_date")
> y
     key_column begin_date   end_date     
[1,] "123456"   "2013-01-01" "2014-07-01 "
[2,] "789102"   "2012-03-01" "2016-02-06" 



--
View this message in context: http://r.789695.n4.nabble.com/Processing-key-column-begin-date-end-date-in-R-tp4703835p4703850.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Thu Feb 26 06:15:05 2015
From: js.huang at protective.com (JS Huang)
Date: Wed, 25 Feb 2015 21:15:05 -0800 (PST)
Subject: [R] Processing key_column, begin_date, end_date in R
In-Reply-To: <1424924316788-4703850.post@n4.nabble.com>
References: <CALYoQdoOqXt1qx8=BTGBZPHsKYbRGETBz+vPQ9eQfD1wePjRiA@mail.gmail.com>
	<1424924316788-4703850.post@n4.nabble.com>
Message-ID: <1424927705350-4703852.post@n4.nabble.com>

Hi,

  It's not as easy as I originally thought.  Here is a revision with the
function beginEnd to get it done.

> date
  key_column begin_date    end_date
1     123456 2013-01-01 2014-01-01 
2     123456 2013-07-01 2014-07-01 
3     789102 2012-03-01 2014-03-01 
4     789102 2015-02-01 2016-02-01 
5     789102 2015-02-06  2016-02-06
> beginEnd
function()
{
  date[order(date$key_column,date$begin_date),]
  key <- numeric(0)
  begin <- character(0)
  end <- character(0)
  currentKey <- as.numeric(date$key_column[1])
  key <- c(key, currentKey)
  currentBegin <- as.character(date$begin_date[1])
  begin <- c(begin, currentBegin)
  currentEnd <- as.character(date$end_date[1])
  for (i in 2:length(date$key_column))
  {
    if (currentKey == as.numeric(date$key_column[i]))
    {
      if (currentEnd >= as.character(date$begin_date[i]))
      {
        currentEnd <- max(currentEnd, as.character(date$end_date[i]))
      }
      else
      {
        end <- c(end, currentEnd)
        currentKey <- as.numeric(date$key_column[i])
        key <- c(key, currentKey)
        currentBegin <- as.character(date$begin_date[i])
        begin <- c(begin, currentBegin)
        currentEnd <- as.character(date$end_date[i])        
      }
      if (i == length(date$key_column))
      {
        end <- c(end, currentEnd)
      }
    }
    else
    {
      end <- c(end, currentEnd)
      currentKey <- as.numeric(date$key_column[i])
      key <- c(key, currentKey)
      currentBegin <- as.character(date$begin_date[i])
      begin <- c(begin, currentBegin)
      currentEnd <- as.character(date$end_date[i])
      if (i == length(date$key_column))
      {
        end <- list(end, currentEnd)
      }
    }
  }
  result <- cbind(key, begin, end)
  colnames(result) <- c("key.column","begin.date","end.date")
  return(result)
}
> beginEnd()
     key.column begin.date   end.date     
[1,] "123456"   "2013-01-01" "2014-07-01 "
[2,] "789102"   "2012-03-01" "2014-03-01 "
[3,] "789102"   "2015-02-01" "2016-02-06" 




--
View this message in context: http://r.789695.n4.nabble.com/Processing-key-column-begin-date-end-date-in-R-tp4703835p4703852.html
Sent from the R help mailing list archive at Nabble.com.


From annelies.hoebeeck at ugent.Be  Thu Feb 26 09:12:34 2015
From: annelies.hoebeeck at ugent.Be (hnlki)
Date: Thu, 26 Feb 2015 00:12:34 -0800 (PST)
Subject: [R] PEA and APE Tobit
Message-ID: <1424938354172-4703856.post@n4.nabble.com>

Hi,

I estimated a tobit model 
tobit.fit<-tobit(y~x,left=0, right=Inf)  (library "AER")
or
tobit2.fit<-censReg(y~x, left=0, right=Inf) (library"censReg")
I' have estimated the partial effect at the average as:
pea<-(pnorm((colMeans(x)%*%tobit.fit$coef[-1])/tobit.fit$scale))%*%tobit.fitt$coef[-1]
and the average partial effect as:
ape<-
(length(x[,1]))^(-1)*sum(pnorm((x%*%tobit.fit$coef[-1])/tobit.fit$scale))*tobit.fit$coef[-1]

I guess I did something wrong as 
 margEff( tobit2.fit) (library("censReg")
 gives a different result than my partial effect at the average. 

Any ideas about what I did wrong? 
I  did not find the underlying code of margEff. 

Kind regards, 




--
View this message in context: http://r.789695.n4.nabble.com/PEA-and-APE-Tobit-tp4703856.html
Sent from the R help mailing list archive at Nabble.com.


From pdalgd at gmail.com  Thu Feb 26 09:56:03 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 26 Feb 2015 09:56:03 +0100
Subject: [R] Best Mac for R
In-Reply-To: <CAHgH9_Fdq=o5dwsBhJkCbVqdXD8jvsGX-EjWTVqUXANGVXG3hw@mail.gmail.com>
References: <CAHgH9_EeBw6ntXmsu8nygYmEraL1G_dN++fP6wqvN9G8TMWWcw@mail.gmail.com>
	<88A6155C-9BF4-40CE-A899-3FDE1D6533AC@txbiomed.org>
	<CALJKBv-WXYN31hFXafHX74HCF+9V+-NqbLbAr40LsrWzt9Ey4A@mail.gmail.com>
	<CAHgH9_Fdq=o5dwsBhJkCbVqdXD8jvsGX-EjWTVqUXANGVXG3hw@mail.gmail.com>
Message-ID: <99E99865-63C1-42E9-B3F9-68AAB38EF59B@gmail.com>


> On 26 Feb 2015, at 06:26 , Dan Murphy <chiefmurphy at gmail.com> wrote:
> 
> Quick responses as usual. Can always count on R-Help! Bert's point
> that "it depends" is key, of course. Mark and Karim reminded me that R
> does not use all cores natively. Putting those together, an expensive
> quad core machine is not necessary for simple package development,
> documentation, etc. And for hard core (no pun intended) analysis, a
> multi-core machine won't be fully utilized without parallel
> implementation of some type. Thanks all for your advice. Just what I
> was looking for.
> Dan
> 

Notice though, that parallel features _can_ be exploited fairly easily on the multi-CPU Macs (it depends somewhat on whether you need fine-grained parallelism as in fast matrix operations or just "embarrassingly parallel" tasks like simulation studies - the former needs R to be linked against the Accelerate framework).

Also notice that the real Mac experts live on the R-SIG-Mac list and not so much on R-help.

-pd


> On Wed, Feb 25, 2015 at 2:53 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>> Hi,
>> It is not so efficient to have the most speed processor or biggest RAM. In
>> general One processor is working at the time.
>> It is more interesting to work with Linux for multiple multi_thread package
>> and 64 bit.
>> I am not sure if turbo boost is working with R.
>> http://stackoverflow.com/questions/1395309/how-to-make-r-use-all-processors
>> 
>> 
>> On Wed, Feb 25, 2015 at 9:12 PM, Mark Sharp <msharp at txbiomed.org> wrote:
>>> 
>>> For what I do, which does not require a lot of parallel work, the high end
>>> iMac was faster and much less expensive than the Mac Pro.
>>> 
>>> Mark
>>> R. Mark Sharp, Ph.D.
>>> msharp at TxBiomed.org
>>> 
>>> 
>>> 
>>> 
>>> 
>>>> On Feb 25, 2015, at 1:50 PM, Dan Murphy <chiefmurphy at gmail.com> wrote:
>>>> 
>>>> I am possibly in the market for a new laptop. Predominantly a Windows
>>>> user, I owned a macbook pro 10 years ago and am considering going that
>>>> route again. Does the standard advice still hold: Get the most
>>>> powerful processor (i7), most ram (16GB), and largest internal storage
>>>> (512GB), if affordable?
>>>> thanks,
>>>> dan
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> NOTICE:  This E-Mail (including attachments) is confidential and may be
>>> legally privileged.  It is covered by the Electronic Communications Privacy
>>> Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are
>>> hereby notified that any retention, dissemination, distribution or copying
>>> of this communication is strictly prohibited.  Please reply to the sender
>>> that you have received this message in error, then delete it.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From goran.brostrom at umu.se  Thu Feb 26 09:59:03 2015
From: goran.brostrom at umu.se (=?windows-1252?Q?G=F6ran_Brostr=F6m?=)
Date: Thu, 26 Feb 2015 09:59:03 +0100
Subject: [R] Replace the value with 1 and 0
In-Reply-To: <1424907209414-4703840.post@n4.nabble.com>
References: <393318048.85141.1424904859310.JavaMail.yahoo@mail.yahoo.com>
	<1424907209414-4703840.post@n4.nabble.com>
Message-ID: <54EEE057.8040501@umu.se>



On 2015-02-26 00:33, JS Huang wrote:
> Hi,
>
>    Here is an implementation.  More data are added.  An extra column hasRain
> is added instead of replacing column Amount.
>
>> rain
>     Year Month Day Amount
> 1  1950     1   1    0.0
> 2  1950     1   2   35.5
> 3  1950     1   3   17.8
> 4  1950     1   4   24.5
> 5  1950     1   5   12.3
> 6  1950     1   6   11.5
> 7  1950     1   7    5.7
> 8  1950     1   8   13.2
> 9  1950     1   9   11.3
> 10 1950     1  10   14.7
> 11 1950     1  11   11.9
> 12 1950     1  12   17.5
> 13 1950     1  13    8.1
> 14 1950     1  14    0.4
> 15 1950     1  15    0.0
> 16 1950     1  16   19.5
> 17 1950     1  17   10.7
> 18 1950     1  18    0.5
> 19 1950     1  19   12.7
> 20 1950     1  20    6.3
> 21 1950     2   1    0.0
> 22 1950     2   2   35.5
> 23 1950     2   3   17.8
> 24 1950     2   4   24.5
> 25 1950     2   5   12.3
> 26 1950     2   6   11.5
> 27 1950     2   7    5.7
> 28 1950     2   8   13.2
> 29 1950     2   9   11.3
> 30 1950     2  10   14.7
> 31 1950     2  11   11.9
> 32 1950     2  12   17.5
> 33 1950     2  13    8.1
> 34 1950     2  14    0.4
> 35 1950     2  15    0.0
> 36 1950     2  16   19.5
> 37 1950     2  17   10.7
> 38 1950     2  18    0.0
> 39 1950     2  19    0.0
> 40 1950     2  20    0.0
>> rain$hasRain <- ifelse(rain$Amount>0,1,0)

No! Better is

rain$hasRain <- as.numeric(rain$Amount > 0)

See previous discussions about the use of 'ifelse'.

G?ran

>> rain
>     Year Month Day Amount hasRain
> 1  1950     1   1    0.0       0
> 2  1950     1   2   35.5       1
> 3  1950     1   3   17.8       1
> 4  1950     1   4   24.5       1
> 5  1950     1   5   12.3       1
> 6  1950     1   6   11.5       1
> 7  1950     1   7    5.7       1
> 8  1950     1   8   13.2       1
> 9  1950     1   9   11.3       1
> 10 1950     1  10   14.7       1
> 11 1950     1  11   11.9       1
> 12 1950     1  12   17.5       1
> 13 1950     1  13    8.1       1
> 14 1950     1  14    0.4       1
> 15 1950     1  15    0.0       0
> 16 1950     1  16   19.5       1
> 17 1950     1  17   10.7       1
> 18 1950     1  18    0.5       1
> 19 1950     1  19   12.7       1
> 20 1950     1  20    6.3       1
> 21 1950     2   1    0.0       0
> 22 1950     2   2   35.5       1
> 23 1950     2   3   17.8       1
> 24 1950     2   4   24.5       1
> 25 1950     2   5   12.3       1
> 26 1950     2   6   11.5       1
> 27 1950     2   7    5.7       1
> 28 1950     2   8   13.2       1
> 29 1950     2   9   11.3       1
> 30 1950     2  10   14.7       1
> 31 1950     2  11   11.9       1
> 32 1950     2  12   17.5       1
> 33 1950     2  13    8.1       1
> 34 1950     2  14    0.4       1
> 35 1950     2  15    0.0       0
> 36 1950     2  16   19.5       1
> 37 1950     2  17   10.7       1
> 38 1950     2  18    0.0       0
> 39 1950     2  19    0.0       0
> 40 1950     2  20    0.0       0
>> tapply(rain$hasRain,list(rain$Year,rain$Month),sum)
>        1  2
> 1950 18 15
>>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Replace-the-value-with-1-and-0-tp4703838p4703840.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From phaedrusv at gmail.com  Thu Feb 26 10:19:36 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Thu, 26 Feb 2015 09:19:36 +0000
Subject: [R] Solved: Re: text miner error: Error in UseMethod("meta", x)
In-Reply-To: <54EE075A.1020003@gmail.com>
References: <54EE075A.1020003@gmail.com>
Message-ID: <54EEE528.5070607@gmail.com>

Hi list

Closing this one off myself, this is what I did:

The error seems to concern the update of tm to version 0.6: the 
conversion to lower case text should now be:

 > docs <- tm_map(docs, content_transformer(tolower))

Everything else seems to work fine thereafter.

The issue in the tutorial concerns section 3.1. wherein Graham creates a 
function toSpace. This seems to introduce an additional term that tm_map 
and later DocumentTermMatrix do not seem to know how to handle. This is 
probably an incorrect interpretation of what's going on, but the fix 
appears to be to use the above line earlier in the preparation stage.

If anyone has more informed insight, please share.

Cheers

Sun

On 25/02/15 17:33, Sun Shine wrote:
> Hi list
>
> I've been working my way through a tutorial on text mining ( 
> http://onepager.togaware.com/TextMiningO.pdf ) and all was well until 
> I came across this problem using tm (text miner):
>
> ++++++++++code+++++++++++++++++++
> > docs <- tm_map(docs, content_transformer(tolower))
> Warning messages:
> 1: In mclapply(x$content[i], function(d) tm_reduce(d, x$lazy$maps)) :
>   all scheduled cores encountered errors in user code
> 2: In mclapply(content(x), FUN, ...) :
>   all scheduled cores encountered errors in user code
> ++++++++++end-code++++++++++++++++
>
> After some searching, it appears the best fix for this problem was to 
> pass an explicit lazy=TRUE argument to tm, like this:
>
> > docs <- tm_map(docs, content_transformer(tolower), lazy=TRUE)
>
> However, a little further on in the tutorial to set up the text 
> matrix, a related (?) error was returned:
>
> ++++++++++code+++++++++++++++++++
> > dtm <- DocumentTermMatrix(docs)
> Error in UseMethod("meta", x) :
>   no applicable method for 'meta' applied to an object of class 
> "try-error"
> In addition: Warning message:
> In mclapply(unname(content(x)), termFreq, control) :
>   all scheduled cores encountered errors in user code
> ++++++++++end-code++++++++++++++++
>
> I tried applying the explicit lazy=TRUE again, but doesn't change 
> things. I have gone over the tutorial again and have followed all of 
> the steps (including loading the requisite libraries). Moreover, 
> searching on the web seems to return several contradictory suggestions 
> and I'm no wiser than I was before.
>
> The closest I came to an answer was at Stack Overflow 
> http://stackoverflow.com/questions/24771165/r-project-no-applicable-method-for-meta-applied-to-an-object-of-class-charact 
> and that answer suggested using the latest tm (v 0.6) and claimed that 
> the earlier tolower step was wrong. However, my code used the 
> recommended: corpus <- tm_map(corpus, content_transformer(tolower))
>
> Is there anyone on the list who could either sign-post me to a 
> solution or assist in debugging this please?
>
> I'm running R version 3.1.2 and tm is 0.6
>
> Many thanks
>
> Sun
>
>


From pushpa.methekar at ge.com  Thu Feb 26 10:06:03 2015
From: pushpa.methekar at ge.com (Methekar, Pushpa (GE Transportation, Non-GE))
Date: Thu, 26 Feb 2015 09:06:03 +0000
Subject: [R] covert entire dataset to numeric while persuing percentage
	values
Message-ID: <9C74639432B50946BF93B535048331619CEEA9@LONURLNA15.e2k.ad.ge.com>

Hi ,
I am little confused  about how to covert entire dataset to numeric .
As I read data like..
Xelements =read.csv(file. Choose(),header = T, stringsAsFactors=FALSE)
str(xelements )

> str(xelements)
'data.frame':  731 obs. of  4 variables:
$ Engine.Speed     : chr  "rpm" "ES" "rpm" "1049" ...
$ X..NG.by.Energy  : chr  "" "% NG by Energy" "%" "0%" ...
$ Int.Mfld.Temp    : chr  "" "Int Mfld Temp" "?C" "49" ...
$ Cmd.Advance.Angle: chr  "" "Cmd Advance Angle" "?BTDC" "13.8" ...

I have second column as in 0%, 10%,.... In percentage value ,
Whenever I am going to covert whole dataset its showing NA introduced .second column going to become NA.
Converting separately I would be successful .


> xelements$Engine.Speed <- as.numeric(xelements$Engine.Speed)

Warning message:

NAs introduced by coercion

> xelements$X..NG.by.Energy<- as.numeric(sub("%","",xelements$X..NG.by.Energy))/100

Warning message:

NAs introduced by coercion

> xelements$Int.Mfld.Temp<- as.numeric(xelements$Int.Mfld.Temp)

Warning message:

NAs introduced by coercion

> xelements$Cmd.Advance.Angle<- as.numeric(xelements$Cmd.Advance.Angle)

Warning message:

NAs introduced by coercion

But I want to covert whole dataset at a time. I want to write function which will help me to solve this problem  .


xelements <- data.frame(sapply(xelements, function(x) as.numeric(as.character(x))))
sapply(xelements, class)

but it won't be able to covert percentage value  like 10%, 20%....
please do help me if you know the way. Thank you

	[[alternative HTML version deleted]]


From dialvac-r at yahoo.de  Thu Feb 26 11:08:57 2015
From: dialvac-r at yahoo.de (Alain D.)
Date: Thu, 26 Feb 2015 11:08:57 +0100 (CET)
Subject: [R] format selected columns in dataframe as character
Message-ID: <2077440503.1063622.1424945338331.JavaMail.open-xchange@patina.store>

Dear R-List,
 
#I have a df with the first two cols formatted as factor.
 
dfx <- data.frame(
group = c(rep('A', 8), rep('B', 15), rep('C', 6)),
sex = sample(c("M", "F"), size = 29, replace = TRUE),
age = runif(n = 29, min = 18, max = 54))
 
# now I want to format both factor VARs as character
# I tried
 
factor.id<-names(dfx[sapply(dfx,is.factor)])
chr.names<-which(names(dfx)%in% factor.id)
 
dfx[ , chr.names]<-as.character(dfx[ , chr.names])
# which gives me
str(dfx)
'data.frame': 29 obs. of 3 variables: $ group: chr "c(1, 1, 1, 1, 1, 1, 1, 1, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3)" "c(2, 2, 1, 1, 1,
1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2)" "c(1,
1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,
3)" "c(2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1,
1, 1, 2, 2, 2)" ... $ sex : chr "c(2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2,
1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2)" "c(1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3)" "c(2, 2, 1, 1, 1, 1, 2,
1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2)" "c(1, 1, 1,
1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3)"
... $ age : num 38.5 18 33.5 26 22.5 ...
 
#though I was hoping for something like
 
'data.frame': 29 obs. of  3 variables:
$ group: chr  "A" "A" "A" "A" ...
$ sex  : chr  "M" "F" "F" "M" ...
$ age  : num  21.3 35.2 53.8 21 23.6 ...

#What is wrong with my code?
#Thank you for any help

Best wishes 

Alain
 
 
 
	[[alternative HTML version deleted]]


From xavier.chiriboga at unine.ch  Thu Feb 26 11:21:44 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Thu, 26 Feb 2015 10:21:44 +0000
Subject: [R] HELP Tukey
Message-ID: <7B64C8E017B948419F014C915AA6D7342A03E119@mail-mbx-04.UNINE.CH>

Dear all ,



I am trying to do a Tukey comparison, but a message appears:



tuk<-glht(mod0,linfct=mcp(Soil="Tukey"));summary(tuk)
Error: could not find function "glht"



Anyone knows how to fix it?



Thanks a lot!



Xavier


From phaedrusv at gmail.com  Thu Feb 26 11:38:28 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Thu, 26 Feb 2015 10:38:28 +0000
Subject: [R] Rgraphviz and NA indices error
Message-ID: <54EEF7A4.9070105@gmail.com>

Hi list

Can someone help me debug the following please:

Having downloaded and installed the bioconductor packages and Rgraphviz, 
I am attempting to plot a network graph showing the relation among 
chosen words in the corpus of text data.

I first did this:
 > plot(dtm, terms=findFreqTerms(dtm, lowfreq=100) [1:30], 
corThreshold=0.75)

and received the error message:

Error in `[.simple_triplet_matrix`(m, , terms) : NA indices not allowed.


My next step was to remove any NA indices (although to be honest, this 
is more of a stab in the dark because there shouldn't be any NA values 
in the corpus):

 > docsNA <- (docs[!is.na(docs)])

Then redid the DTM with the NA values removed
 > dtmNA <- DocumentTermMatrix(docsNA)

Then re-ran Rgraphviv with the new set
 > plot(dtmNA, terms=findFreqTerms(dtmNA, lowfreq=100) [1:10], 
corThreshold=0.5)

But, still get an error:
Error in `[.simple_triplet_matrix`(m, , terms) : NA indices not allowed.

I have not been successful in finding out why this error persists nor 
what to do about it.

Anyone have any ideas to progress past this issue?

Thanks

Sun


From thierry.onkelinx at inbo.be  Thu Feb 26 11:55:42 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 26 Feb 2015 11:55:42 +0100
Subject: [R] HELP Tukey
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A03E119@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A03E119@mail-mbx-04.UNINE.CH>
Message-ID: <CAJuCY5y=bS8bmswX17eNwZBw3Bq26sH=Dvtu_fkMkjEP5L0WHA@mail.gmail.com>

??glht would tell you that glht is a function from the multcomp package.
You need to load a package before you can use its functions.

library(multcomp)

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-02-26 11:21 GMT+01:00 CHIRIBOGA Xavier <xavier.chiriboga at unine.ch>:

> Dear all ,
>
>
>
> I am trying to do a Tukey comparison, but a message appears:
>
>
>
> tuk<-glht(mod0,linfct=mcp(Soil="Tukey"));summary(tuk)
> Error: could not find function "glht"
>
>
>
> Anyone knows how to fix it?
>
>
>
> Thanks a lot!
>
>
>
> Xavier
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From xavier.chiriboga at unine.ch  Thu Feb 26 12:20:15 2015
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Thu, 26 Feb 2015 11:20:15 +0000
Subject: [R] library(multcomp) does not work for loading Tukey
Message-ID: <7B64C8E017B948419F014C915AA6D7342A040147@mail-mbx-04.UNINE.CH>

Dear colleagues,



For Tukey, I tried to load the function with



library(multcomp) but again a message says:



Error in library(multcomp) : any package called ?multcomp? has been found







Thanks for ur help,

Xavier


From zadig_1 at excite.com  Thu Feb 26 12:22:05 2015
From: zadig_1 at excite.com (ce)
Date: Thu, 26 Feb 2015 06:22:05 -0500
Subject: [R] How many digits are there in left of dot of 0.0001 ?
Message-ID: <20150226062205.28071@web001.roc2.bluetie.com>


yes this is exactly what I want and it works. thanks.

-----Original Message-----
From: "JS Huang" [js.huang at protective.com]
Date: 02/26/2015 03:22 AM
To: r-help at r-project.org
Subject: Re: [R] How many digits are there in left of dot of 0.0001 ?

Hi,

  To get the number of digits to the right of decimal point: 
nchar(format(a,scientific=FALSE))-(trunc(log10(max(1,trunc(abs(a)))))+1) -1.  

  The part (trunc(log10(max(1,trunc(abs(a)))))+1) is the number of digits to
the left of decimal.  At the end, subtract 1 for the decimal point.

  Negative number needs more work.

> options(digits=10)
> a <- 0.0001
> nchar(format(a,scientific=FALSE))-(trunc(log10(max(1,trunc(abs(a)))))+1)
> -1
[1] 4
> a <- 999.123456
> nchar(format(a,scientific=FALSE))-(trunc(log10(max(1,trunc(abs(a)))))+1)
> -1
[1] 6



--
View this message in context: http://r.789695.n4.nabble.com/How-many-digits-are-there-in-left-of-dot-of-0-0001-tp4703842p4703849.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From studerov at gmail.com  Thu Feb 26 13:02:49 2015
From: studerov at gmail.com (David Studer)
Date: Thu, 26 Feb 2015 13:02:49 +0100
Subject: [R] aggregating variables (sum within groups)
Message-ID: <CAA1twZTv=mDitgtCB=V++XRnM7u8+JWiZtSuSnAin_V-LBhzwQ@mail.gmail.com>

Hello everybody!

I have a (probabely very easy) problem. Even though I was looking in
several r-books
I could not find a suitable function to this problem, that's why I hope
that someone here
could help me:

# Sample data:
group<-c("A","A","A","B","B","C","C","C")
var1<-c(1,0,0,1,1,0,NA,1)
var2<-c(0,1,NA,0,1,1,0,0)
testdata<-data.frame(group, var1, var2)

Now, I'd like to generate two aggregated variables:

testdata$x<- ???   should count the sum of var1 within each group (=4)
testdata$y<- ???   should count the sum of var2 within each group (=3)

Therefore I am looking for a function like ave() which does not calculate
the mean value but a sum.

Thank you for any hints!

David

	[[alternative HTML version deleted]]


From ivan.calandra at univ-reims.fr  Thu Feb 26 13:16:44 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 26 Feb 2015 13:16:44 +0100
Subject: [R] aggregating variables (sum within groups)
In-Reply-To: <CAA1twZTv=mDitgtCB=V++XRnM7u8+JWiZtSuSnAin_V-LBhzwQ@mail.gmail.com>
References: <CAA1twZTv=mDitgtCB=V++XRnM7u8+JWiZtSuSnAin_V-LBhzwQ@mail.gmail.com>
Message-ID: <54EF0EAC.80105@univ-reims.fr>

Hi David,

You have your answer in the question:
aggregate()

aggregate(cbind(var1,var2)~group, data=testdata, FUN=sum)

Although I am not sure what you intended to do with "testdata$x<-" as 
the result cannot have the same number of rows than testdata


HTH,
Ivan

--
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 26/02/15 13:02, David Studer a ?crit :
> Hello everybody!
>
> I have a (probabely very easy) problem. Even though I was looking in
> several r-books
> I could not find a suitable function to this problem, that's why I hope
> that someone here
> could help me:
>
> # Sample data:
> group<-c("A","A","A","B","B","C","C","C")
> var1<-c(1,0,0,1,1,0,NA,1)
> var2<-c(0,1,NA,0,1,1,0,0)
> testdata<-data.frame(group, var1, var2)
>
> Now, I'd like to generate two aggregated variables:
>
> testdata$x<- ???   should count the sum of var1 within each group (=4)
> testdata$y<- ???   should count the sum of var2 within each group (=3)
>
> Therefore I am looking for a function like ave() which does not calculate
> the mean value but a sum.
>
> Thank you for any hints!
>
> David
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Thu Feb 26 13:17:49 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 Feb 2015 07:17:49 -0500
Subject: [R] How many digits are there in left of dot of 0.0001 ?
In-Reply-To: <20150225205549.17338@web005.roc2.bluetie.com>
References: <20150225205549.17338@web005.roc2.bluetie.com>
Message-ID: <54EF0EED.3030107@gmail.com>

On 25/02/2015 8:55 PM, ce wrote:
> Dear all,
> 
> I would like to count how many digits are there on the left of a the dot of a numeric variable
> 
> a=0.0001

This will depend on the formatting used.  If default formatting used by
as.character() is fine, then

nchar(sub("^[[:digit:]]*[.]", "", a))

should work. (Note that default formatting is scientific for 0.0001.) If
you want some other formatting, then format first, and pass a character
object, e.g.

chars <- format(a, scientific = FALSE)
nchar(sub("^[[:digit:]]*[.]", "", chars))

Duncan Murdoch


From bran.chri at gmail.com  Thu Feb 26 13:21:37 2015
From: bran.chri at gmail.com (=?UTF-8?Q?Brandst=C3=A4tter_Christian?=)
Date: Thu, 26 Feb 2015 13:21:37 +0100
Subject: [R] aggregating variables (sum within groups)
In-Reply-To: <CAA1twZTv=mDitgtCB=V++XRnM7u8+JWiZtSuSnAin_V-LBhzwQ@mail.gmail.com>
References: <CAA1twZTv=mDitgtCB=V++XRnM7u8+JWiZtSuSnAin_V-LBhzwQ@mail.gmail.com>
Message-ID: <CAALi0vJ5fPMym2TDqT0kd=Lbbm-o9coxYg01DOpwGG8fDwgF6A@mail.gmail.com>

Dear David,

your email is quite confusing. Do you want to get the sum for each group
(A,B,C) or each variable as would be indicated by your result?


sum by group:
aggregate(data=testdata,var1~group,sum)

count by group:
aggregate(data=testdata,var1~group,length)

sum by variable:
sum(na.omit(testdata$var1))

But homework shouldn't be posted on this list.
Best regards
Christian



2015-02-26 13:02 GMT+01:00 David Studer <studerov at gmail.com>:

> Hello everybody!
>
> I have a (probabely very easy) problem. Even though I was looking in
> several r-books
> I could not find a suitable function to this problem, that's why I hope
> that someone here
> could help me:
>
> # Sample data:
> group<-c("A","A","A","B","B","C","C","C")
> var1<-c(1,0,0,1,1,0,NA,1)
> var2<-c(0,1,NA,0,1,1,0,0)
> testdata<-data.frame(group, var1, var2)
>
> Now, I'd like to generate two aggregated variables:
>
> testdata$x<- ???   should count the sum of var1 within each group (=4)
> testdata$y<- ???   should count the sum of var2 within each group (=3)
>
> Therefore I am looking for a function like ave() which does not calculate
> the mean value but a sum.
>
> Thank you for any hints!
>
> David
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nashjc at uottawa.ca  Thu Feb 26 14:07:12 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Thu, 26 Feb 2015 08:07:12 -0500
Subject: [R] Help with nonlinear least squares regression curve fitting
In-Reply-To: <mailman.1.1424948401.22967.r-help@r-project.org>
References: <mailman.1.1424948401.22967.r-help@r-project.org>
Message-ID: <54EF1A80.8000708@uottawa.ca>

Andrew's suggestion for Year is a help, but package nlmrt shows the
problem you are trying to solve is truly one where there is a Jacobian
singularity. (nlmrt produces the Jacobian singular values -- but read
the output carefully because these are placed for compact output as if
they correspond to parameters, which they do not).

Unfortunately, nlmrt tries to use analytic derivatives, and sign() is
not in the derivatives table for the double sigmoid. BTW, your function
has a typo. Do provide reproducible results. Here is what I did using

callaghan.csv:
Area,Year
104.7181283,1984
32.88026974,1985
56.07395863,1986
191.3422143,1987
233.4661392,1988
57.28317116,1989
201.1273404,1990
34.42570796,1991
165.8962342,1992
58.21905274,1993
114.6643724,1994
342.3461986,1995
184.8877994,1996
94.90509356,1997
45.2026941,1998
68.6196393,1999
575.2440229,2000
519.7557581,2001
904.157509,2002
1107.357517,2003
1682.876061,2004
40.55667824,2005
740.5032604,2006
885.7243469,2007
395.4190968,2008
1031.314519,2009
2597.544987,2010
1316.968695,2011
848.7093901,2012
5076.675075,2013
6132.975491,2014

code:
library(nlmrt)
df <- read.csv("callaghan.csv")

fitmodeliq <- nlxb(Area ~ (-a*Year)*(Year + b), data = df,
start=list(a=1,b=1, c=1))

fitmodelsig <- nlxb(Area~a/(1+exp(-(b+c*Year))), data=df,
start=list(a=1,b=1, c=1))

fitmodelds <- nlxb(Area ~
a+2*b*(1/(1+exp(-abs(-c*Year+d)))-1/2)*sign(-c*Year+d), data=df,
start=list(a=1, b=1, c=1))

For information of readers, Duncan Murdoch and I have been working on
nls14 to replace/augment nls(), but we've a way to go yet before this is
ready for CRAN. Collaborators welcome.

John Nash


On 15-02-26 06:00 AM, r-help-request at r-project.org wrote:
> Message: 24
> Date: Thu, 26 Feb 2015 07:26:50 +1100
> From: Andrew Robinson <A.Robinson at ms.unimelb.edu.au>
> To: Corey Callaghan <ccallaghan2013 at fau.edu>
> Cc: "R help \(r-help at r-project.org\)" <r-help at r-project.org>
> Subject: Re: [R] Help with nonlinear least squares regression curve
> 	fitting
> Message-ID:
> 	<CAHyGmd6rrUC_AOBHRHw7babXnMzrSbi4b7ZJt0vN5LRWVW2HAw at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> Finding starting values is a bit of a dark art.  That said, there are steps
> you can take, but it may take time.
> 
> First, I would scale Year so that it's not in the thousands! Experiment
> with subtracting 1980 or so.  For specific advice, see inline.
> 
> On Thu, Feb 26, 2015 at 3:03 AM, Corey Callaghan <ccallaghan2013 at fau.edu>
> wrote:
> 
>> > The curves' functions that I want to test are in the code here (hopefully
>> > correctly):
>> >
>> > Inverse Quadratic Curve:
>> > fitmodel <- nls(Area ~ (-a*Year)*(Year + b), data = df, start=list(a=??,
>> > b=??, c=??))
>> >
> I would plot the data and a smooth spline, differentiate the curve
> function, identify some parameter values somewhere stable, and estimate
> some values by eye, or even predict them from the first derivative of the
> spline - spline.smooth will do this.
> 
> Sigmodial Curve:
>> > fitmodel <- nls(Area~a/(1+exp(-(b+c*Year))), data=df, start=list(a=???,
>> > b=???, c=??))
>> >
> I'd use the highest value as a, fit spline as above then invert area at two
> times to get b and c.
> 
> Double sigmoidal Curve:
>> > fitmodel <- nls(Area~a+2b(1/(1+exp(-abs(-c*Year+d)))-1/2)*sign(-c*Year+d),
>> > data=df, start=list(a=???, b=???, c=???)
>> >
>  I'd use min(Area) as a, figure out b from the maximum (I guess 2b+a is the
> asymptote), and experiment with two values for year to retrieve c and d
> .... uniroot might help?
> 
> Cheers
> 
> Andrew
> 
> -- Andrew Robinson Deputy Director, CEBRA, School of Biosciences Reader
> & Associate Professor in Applied Statistics Tel: (+61) 0403 138 955
> School of Mathematics and Statistics Fax: +61-3-8344 4599 University of
> Melbourne, VIC 3010 Australia Email: a.robinson at ms.unimelb.edu.au
> Website: http://www.ms.unimelb.edu.au/~andrewpr MSME:
> http://www.crcpress.com/product/isbn/9781439858028 FAwR:
> http://www.ms.unimelb.edu.au/~andrewpr/FAwR/ SPuR:
> http://www.ms.unimelb.edu.au/spuRs/ [[alternative HTML version deleted]]


From info at aghmed.fsnet.co.uk  Thu Feb 26 14:13:44 2015
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 26 Feb 2015 13:13:44 +0000
Subject: [R] library(multcomp) does not work for loading Tukey
In-Reply-To: <7B64C8E017B948419F014C915AA6D7342A040147@mail-mbx-04.UNINE.CH>
References: <7B64C8E017B948419F014C915AA6D7342A040147@mail-mbx-04.UNINE.CH>
Message-ID: <54EF1C08.2070506@aghmed.fsnet.co.uk>

Dear Xavier

See below for comments

On 26/02/2015 11:20, CHIRIBOGA Xavier wrote:
> Dear colleagues,
>
>
>
> For Tukey, I tried to load the function with
>
>
>
> library(multcomp) but again a message says:
>
>
>
> Error in library(multcomp) : any package called ?multcomp? has been found
>
>

I suspect you translated this? I would have thought the message in 
English would have been
there is no package called 'multcomp'
which gives you the clue that you should install it first
?install.packages
is your friend

Michael
>
>
>
>
>
> Thanks for ur help,
>
> Xavier
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5645 / Virus Database: 4299/9183 - Release Date: 02/26/15
>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From ronflatau at gmail.com  Thu Feb 26 14:22:59 2015
From: ronflatau at gmail.com (Ron Flatau)
Date: Thu, 26 Feb 2015 15:22:59 +0200
Subject: [R] retrieving protein for swissport
Message-ID: <CADzHNWHB3g3Y8_kwh0dp9WhT_jexJ2SVWgHcZM5S57SzEtZ-FA@mail.gmail.com>

It's possible to retrieve protein for swissport by protein name??

I try using seqinr and query but i didnt find  a way to get all protein
that named Delta 9 acyl CoA desaturase.

If some one have an idea i be glad :P

thank you all

?

	[[alternative HTML version deleted]]


From js.huang at protective.com  Thu Feb 26 13:12:17 2015
From: js.huang at protective.com (JS Huang)
Date: Thu, 26 Feb 2015 04:12:17 -0800 (PST)
Subject: [R] How many digits are there in left of dot of 0.0001 ?
In-Reply-To: <20150226062205.28071@web001.roc2.bluetie.com>
References: <20150225205549.17338@web005.roc2.bluetie.com>
	<20150226062205.28071@web001.roc2.bluetie.com>
Message-ID: <1424952737497-4703872.post@n4.nabble.com>

Hi, 
  
  Some modification to work for both positive and negative number:

nchar(format(*abs*(a),scientific=FALSE))-(trunc(log10(max(1,trunc(abs(a)))))+1)
-1.



--
View this message in context: http://r.789695.n4.nabble.com/How-many-digits-are-there-in-left-of-dot-of-0-0001-tp4703842p4703872.html
Sent from the R help mailing list archive at Nabble.com.


From alaios at yahoo.com  Thu Feb 26 15:27:30 2015
From: alaios at yahoo.com (Alaios)
Date: Thu, 26 Feb 2015 14:27:30 +0000 (UTC)
Subject: [R] Save a list of list and search for values
Message-ID: <1714479608.448965.1424960850362.JavaMail.yahoo@mail.yahoo.com>

Dear all,in my code I am using the mix() function that returns results in a list. The result looks like
List of 10
?$ parameters? :'data.frame':?? 2 obs. of? 3 variables:
? ..$ pi?? : num [1:2] 0.77 0.23
? ..$ mu?? : num [1:2] -7034 162783
? ..$ sigma: num [1:2] 20235 95261
?$ se????????? :'data.frame':?? 2 obs. of? 3 variables:
? ..$ pi.se?? : num [1:2] 0.0423 0.0423
? ..$ mu.se?? : num [1:2] 177 12422
? ..$ sigma.se: num [1:2] 1067 65551
?$ distribution: chr "norm"
?$ constraint? :List of 8
? ..$ conpi?? : chr "NONE"
? ..$ conmu?? : chr "NONE"
? ..$ consigma: chr "NONE"
? ..$ fixpi?? : NULL
? ..$ fixmu?? : NULL
? ..$ fixsigma: NULL
? ..$ cov???? : NULL
? ..$ size??? : NULL
?$ chisq?????? : num 28
?$ df????????? : num 5
?$ P?????????? : num 3.67e-05
?$ vmat??????? : num [1:5, 1:5] 1.79e-03 -3.69e-01 -1.17e+02 2.95e+01 -2.63e+03 ...
?$ mixdata???? :Classes ?mixdata? and 'data.frame':???? 11 obs. of? 2 variables:
? ..$ X??? : num [1:11] 1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
? ..$ count: int [1:11] 993 137 82 30 21 5 7 14 21 2 ...
?$ usecondit?? : logi FALSE
?- attr(*, "class")= chr "mix"

In my code I am trying around 10.000 fit (and each of these fits returns the list above) and I want to keep those in a way that later on I would be able to search inside all the lists.For example I would like to find inside those 10.000 lists which one has the smallest $chisq value. What would be a suitable way to implement that in R? Luckily I am working in a computer with a lot of ram so storing 10.000 lists temporary in memory before saving to disk would not be a problem.
What would you suggest me?
RegardsAlex

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Feb 26 15:30:56 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 26 Feb 2015 06:30:56 -0800
Subject: [R] Processing key_column, begin_date, end_date in R
In-Reply-To: <CALYoQdoOqXt1qx8=BTGBZPHsKYbRGETBz+vPQ9eQfD1wePjRiA@mail.gmail.com>
References: <CALYoQdoOqXt1qx8=BTGBZPHsKYbRGETBz+vPQ9eQfD1wePjRiA@mail.gmail.com>
Message-ID: <32C13E7A-9C58-42E5-86D6-6E0C975E29D4@dcn.davis.CA.us>

Here is another way. Have not tested for large scale efficiency, but if you convert dta to a data.table that might improve things.

library(dplyr)
dta <- read.csv( text=
"key_column,begin_date,end_date
123456,2013-01-01,2014-01-01
123456,2013-07-01,2014-07-01
789102,2012-03-01,2014-03-01
789102,2015-02-01,2016-02-01
789102,2015-02-06,2016-02-06
789102,2015-02-28,2015-03-31
789102,2015-04-30,2015-05-31
", as.is=TRUE)
( dta
%>% mutate( begin_date = as.Date( begin_date ),
end_date = as.Date( end_date ) )
%>% arrange( key_column, begin_date )
) -> dta

mkgp <- function( begin_date, cend ) {
  ix <- c( TRUE, cend[ -length( begin_date ) ] < begin_date[ -1 ] )
  cumsum( ix )
}

result <- ( dta
          %>% group_by( key_column )
          %>% mutate( cend = as.Date( cummax( as.numeric( end_date ) )
                                    , origin="1970-01-01" )
                      , gp = mkgp( begin_date, cend )
                      )
          %>% ungroup
          %>% group_by( key_column, gp )
          %>% summarise(  begin_date = begin_date[ 1 ]
                        , end_date = cend[ length( cend ) ]
                        )
          %>% ungroup
          %>% select( -gp )
          %>% as.data.frame
          )
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 25, 2015 1:18:58 PM PST, Matt Gross <grossm at gmail.com> wrote:
>Hi,
>
>I am trying to process a large dataset in R.  The dataset contains the
>following three columns:
>
>key_column - a unique key identifier
>begin_date - the start date of the active period
>end_date - the end date of the active period
>
>
>Example data is here:
>
>key_column,begin_date,end_date
>123456,2013-01-01,2014-01-01
>123456,2013-07-01,2014-07-01
>789102,2012-03-01,2014-03-01
>789102,2015-02-01,2016-02-01
>789102,2015-02-06,2016-02-06
>
>I want to build a condensed table of key_column and begin_date's and
>end_date's.  As you can see in the example data above, some begin and
>end
>date periods overlap with begin_date and end_date pairs for the same
>key_column.  In situations where overlap exists I want to have one
>record
>for the key_column with the min(begin_date) and the max(end_date).
>
>Can anyone help me build the commands to process this data in R?
>
>Thanks,
>Matt


From jholtman at gmail.com  Thu Feb 26 15:34:49 2015
From: jholtman at gmail.com (jim holtman)
Date: Thu, 26 Feb 2015 09:34:49 -0500
Subject: [R] covert entire dataset to numeric while persuing percentage
	values
In-Reply-To: <9C74639432B50946BF93B535048331619CEEA9@LONURLNA15.e2k.ad.ge.com>
References: <9C74639432B50946BF93B535048331619CEEA9@LONURLNA15.e2k.ad.ge.com>
Message-ID: <CAAxdm-7JxLqdNSOSGsUyqn2oeaXfeApBcpSqPo_tXQZprT3LbA@mail.gmail.com>

It would help a lot if you posted a subset of your data using 'dput'
so that we know what it actually looks like.  You have character data
mixed with numerics, so you will be NAs in some cases.

Conversion of percent to numeric is accomplished with something like this:

> x <- c('12%', '6%', '3.75%')
> # convert to a number
> as.numeric(gsub("%", "", x)) / 100
[1] 0.1200 0.0600 0.0375
>


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Thu, Feb 26, 2015 at 4:06 AM, Methekar, Pushpa (GE Transportation,
Non-GE) <pushpa.methekar at ge.com> wrote:
> Hi ,
> I am little confused  about how to covert entire dataset to numeric .
> As I read data like..
> Xelements =read.csv(file. Choose(),header = T, stringsAsFactors=FALSE)
> str(xelements )
>
>> str(xelements)
> 'data.frame':  731 obs. of  4 variables:
> $ Engine.Speed     : chr  "rpm" "ES" "rpm" "1049" ...
> $ X..NG.by.Energy  : chr  "" "% NG by Energy" "%" "0%" ...
> $ Int.Mfld.Temp    : chr  "" "Int Mfld Temp" "?C" "49" ...
> $ Cmd.Advance.Angle: chr  "" "Cmd Advance Angle" "?BTDC" "13.8" ...
>
> I have second column as in 0%, 10%,.... In percentage value ,
> Whenever I am going to covert whole dataset its showing NA introduced .second column going to become NA.
> Converting separately I would be successful .
>
>
>> xelements$Engine.Speed <- as.numeric(xelements$Engine.Speed)
>
> Warning message:
>
> NAs introduced by coercion
>
>> xelements$X..NG.by.Energy<- as.numeric(sub("%","",xelements$X..NG.by.Energy))/100
>
> Warning message:
>
> NAs introduced by coercion
>
>> xelements$Int.Mfld.Temp<- as.numeric(xelements$Int.Mfld.Temp)
>
> Warning message:
>
> NAs introduced by coercion
>
>> xelements$Cmd.Advance.Angle<- as.numeric(xelements$Cmd.Advance.Angle)
>
> Warning message:
>
> NAs introduced by coercion
>
> But I want to covert whole dataset at a time. I want to write function which will help me to solve this problem  .
>
>
> xelements <- data.frame(sapply(xelements, function(x) as.numeric(as.character(x))))
> sapply(xelements, class)
>
> but it won't be able to covert percentage value  like 10%, 20%....
> please do help me if you know the way. Thank you
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From josestadistico at gmail.com  Thu Feb 26 14:39:29 2015
From: josestadistico at gmail.com (=?UTF-8?Q?Jos=C3=A9_Luis_Aguilar?=)
Date: Thu, 26 Feb 2015 14:39:29 +0100
Subject: [R] twitteR
Message-ID: <CACt-d0gcD=PUKDbCjtpU9v0bhLzfbCL+kfWVxvec_3Pxk52w4g@mail.gmail.com>

Hello,

i need help,  I'm trying to get oauth authorization to get rcredentials
.RData

the code that i use is:

>library(twitteR)
>library(tm)
>library(wordcloud)
>library(RColorBrewer)
>library(RCurl)
>library(ROAuth)

>options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem",
package = "RCurl")))
>u = "
https://raw.github.com/tonybreyal/Blog-Reference-Functions/master/R/bingSearchXScraper/bingSearchXScraper
."
>x = getURL(u, cainfo = system.file("CurlSSL", "cacert.pem", package =
"RCurl"))

>download.file(url="http://curl.haxx.se/ca/cacert.pem",
              destfile="cacert.pem"
>  requestURL <- "https://api.twitter.com/oauth/request_token"
>  accessURL <- "https://api.twitter.com/oauth/access_token"
> authURL <- "https://api.twitter.com/oauth/authorize"

> consumerKey      <- "<< eED.....>>"
> consumerSecret   <- "<< qo.....>>"

>twitCred <- OAuthFactory$new(consumerKey=consumerKey,
                             consumerSecret=consumerSecret,
                             requestURL=reqURL,
                             accessURL=accessURL,
                             authURL=authURL)

)

when Asking for access

> twitCred$handshake(cainfo="cacert.pem")


i receive this message:

ERROR: AUTHORIZATION NO FOUND

Please help me,

thanks a lot!!

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Feb 26 15:39:12 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 Feb 2015 09:39:12 -0500
Subject: [R] Save a list of list and search for values
In-Reply-To: <1714479608.448965.1424960850362.JavaMail.yahoo@mail.yahoo.com>
References: <1714479608.448965.1424960850362.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <54EF3010.3080200@gmail.com>

On 26/02/2015 9:27 AM, Alaios via R-help wrote:
> Dear all,in my code I am using the mix() function that returns results in a list. The result looks like
> List of 10
>   $ parameters  :'data.frame':   2 obs. of  3 variables:
>    ..$ pi   : num [1:2] 0.77 0.23
>    ..$ mu   : num [1:2] -7034 162783
>    ..$ sigma: num [1:2] 20235 95261
>   $ se          :'data.frame':   2 obs. of  3 variables:
>    ..$ pi.se   : num [1:2] 0.0423 0.0423
>    ..$ mu.se   : num [1:2] 177 12422
>    ..$ sigma.se: num [1:2] 1067 65551
>   $ distribution: chr "norm"
>   $ constraint  :List of 8
>    ..$ conpi   : chr "NONE"
>    ..$ conmu   : chr "NONE"
>    ..$ consigma: chr "NONE"
>    ..$ fixpi   : NULL
>    ..$ fixmu   : NULL
>    ..$ fixsigma: NULL
>    ..$ cov     : NULL
>    ..$ size    : NULL
>   $ chisq       : num 28
>   $ df          : num 5
>   $ P           : num 3.67e-05
>   $ vmat        : num [1:5, 1:5] 1.79e-03 -3.69e-01 -1.17e+02 2.95e+01 -2.63e+03 ...
>   $ mixdata     :Classes ?mixdata? and 'data.frame':     11 obs. of  2 variables:
>    ..$ X    : num [1:11] 1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
>    ..$ count: int [1:11] 993 137 82 30 21 5 7 14 21 2 ...
>   $ usecondit   : logi FALSE
>   - attr(*, "class")= chr "mix"
>
> In my code I am trying around 10.000 fit (and each of these fits returns the list above) and I want to keep those in a way that later on I would be able to search inside all the lists.For example I would like to find inside those 10.000 lists which one has the smallest $chisq value. What would be a suitable way to implement that in R? Luckily I am working in a computer with a lot of ram so storing 10.000 lists temporary in memory before saving to disk would not be a problem.
> What would you suggest me?

If all of the lists have the same components, then it would be 
convenient to convert them into a big matrix or dataframe, with one row 
per fit.  It would need to be a dataframe if you include character data 
along with the numbers, but a matrix would be faster, if it's only 
numbers that you need.  You'd use code like this to produce the matrix:

results <- matrix(NA_real_, 10000, ncols = .... however many you keep ....)
for (i in 1:10000) {
   fit <- .... code to get the fit object ....
   results[i,] <- with(fit, c(parameters$pi, parameters$mu, 
parameters$sigma,   ......  fill in the rest ......)
}

Duncan Murdoch


From jholtman at gmail.com  Thu Feb 26 15:39:31 2015
From: jholtman at gmail.com (jim holtman)
Date: Thu, 26 Feb 2015 09:39:31 -0500
Subject: [R] Save a list of list and search for values
In-Reply-To: <1714479608.448965.1424960850362.JavaMail.yahoo@mail.yahoo.com>
References: <1714479608.448965.1424960850362.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-7u++3iUjhOO+iOj7cXsn-_akxM8M1oPqauE+EMBD8Hgw@mail.gmail.com>

You store it as a list of lists and can then use the lapply function
to navigate for values.

result <- lapply(1:10000, function(x){
    mix(param[x])  # whatever your call to 'mix' is with some data
})





Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Thu, Feb 26, 2015 at 9:27 AM, Alaios via R-help <r-help at r-project.org> wrote:
> Dear all,in my code I am using the mix() function that returns results in a list. The result looks like
> List of 10
>  $ parameters  :'data.frame':   2 obs. of  3 variables:
>   ..$ pi   : num [1:2] 0.77 0.23
>   ..$ mu   : num [1:2] -7034 162783
>   ..$ sigma: num [1:2] 20235 95261
>  $ se          :'data.frame':   2 obs. of  3 variables:
>   ..$ pi.se   : num [1:2] 0.0423 0.0423
>   ..$ mu.se   : num [1:2] 177 12422
>   ..$ sigma.se: num [1:2] 1067 65551
>  $ distribution: chr "norm"
>  $ constraint  :List of 8
>   ..$ conpi   : chr "NONE"
>   ..$ conmu   : chr "NONE"
>   ..$ consigma: chr "NONE"
>   ..$ fixpi   : NULL
>   ..$ fixmu   : NULL
>   ..$ fixsigma: NULL
>   ..$ cov     : NULL
>   ..$ size    : NULL
>  $ chisq       : num 28
>  $ df          : num 5
>  $ P           : num 3.67e-05
>  $ vmat        : num [1:5, 1:5] 1.79e-03 -3.69e-01 -1.17e+02 2.95e+01 -2.63e+03 ...
>  $ mixdata     :Classes ?mixdata? and 'data.frame':     11 obs. of  2 variables:
>   ..$ X    : num [1:11] 1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
>   ..$ count: int [1:11] 993 137 82 30 21 5 7 14 21 2 ...
>  $ usecondit   : logi FALSE
>  - attr(*, "class")= chr "mix"
>
> In my code I am trying around 10.000 fit (and each of these fits returns the list above) and I want to keep those in a way that later on I would be able to search inside all the lists.For example I would like to find inside those 10.000 lists which one has the smallest $chisq value. What would be a suitable way to implement that in R? Luckily I am working in a computer with a lot of ram so storing 10.000 lists temporary in memory before saving to disk would not be a problem.
> What would you suggest me?
> RegardsAlex
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From js.huang at protective.com  Thu Feb 26 14:54:26 2015
From: js.huang at protective.com (JS Huang)
Date: Thu, 26 Feb 2015 05:54:26 -0800 (PST)
Subject: [R] format selected columns in dataframe as character
In-Reply-To: <2077440503.1063622.1424945338331.JavaMail.open-xchange@patina.store>
References: <2077440503.1063622.1424945338331.JavaMail.open-xchange@patina.store>
Message-ID: <1424958866252-4703878.post@n4.nabble.com>

Try as.character like the following shows.

> dfx <- data.frame( 
+   group = c(rep('A', 8), rep('B', 15), rep('C', 6)), 
+   sex = sample(c("M", "F"), size = 29, replace = TRUE), 
+   age = runif(n = 29, min = 18, max = 54))
> dfx
   group sex         age
1      A   M 41.35554346
2      A   F 47.73245469
3      A   F 42.97870796
4      A   M 52.51180396
5      A   F 46.72228944
6      A   M 48.64668630
7      A   M 36.07894452
8      A   M 26.96805121
9      B   M 30.67208692
10     B   M 45.09322672
11     B   M 31.86601692
12     B   F 53.28861780
13     B   M 27.74271305
14     B   F 52.05845066
15     B   F 18.94612430
16     B   M 48.66673378
17     B   F 53.07004762
18     B   F 48.15222416
19     B   M 32.17737802
20     B   M 37.02122907
21     B   M 39.31442046
22     B   M 27.90392578
23     B   M 44.70562356
24     C   F 53.43127126
25     C   M 49.85362283
26     C   M 40.40779822
27     C   F 31.41189728
28     C   M 47.49351314
29     C   M 46.34333618
> summary(dfx)
 group  sex         age          
 A: 8   F:10   Min.   :18.94612  
 B:15   M:19   1st Qu.:32.17738  
 C: 6          Median :44.70562  
               Mean   :41.46947  
               3rd Qu.:48.64669  
               Max.   :53.43127  
> dfx$group <- *as.character*(dfx$group)
> summary(dfx)
    group           sex         age          
 Length:29          F:10   Min.   :18.94612  
 Class :character   M:19   1st Qu.:32.17738  
 Mode  :character          Median :44.70562  
                           Mean   :41.46947  
                           3rd Qu.:48.64669  
                           Max.   :53.43127  
> dfx
   group sex         age
1      A   M 41.35554346
2      A   F 47.73245469
3      A   F 42.97870796
4      A   M 52.51180396
5      A   F 46.72228944
6      A   M 48.64668630
7      A   M 36.07894452
8      A   M 26.96805121
9      B   M 30.67208692
10     B   M 45.09322672
11     B   M 31.86601692
12     B   F 53.28861780
13     B   M 27.74271305
14     B   F 52.05845066
15     B   F 18.94612430
16     B   M 48.66673378
17     B   F 53.07004762
18     B   F 48.15222416
19     B   M 32.17737802
20     B   M 37.02122907
21     B   M 39.31442046
22     B   M 27.90392578
23     B   M 44.70562356
24     C   F 53.43127126
25     C   M 49.85362283
26     C   M 40.40779822
27     C   F 31.41189728
28     C   M 47.49351314
29     C   M 46.34333618
> dfx$sex <- *as.character*(dfx$sex)
> summary(dfx)
    group               sex                 age          
 Length:29          Length:29          Min.   :18.94612  
 Class :character   Class :character   1st Qu.:32.17738  
 Mode  :character   Mode  :character   Median :44.70562  
                                       Mean   :41.46947  
                                       3rd Qu.:48.64669  
                                       Max.   :53.43127  
> class(dfx$group)
[1] "character"
> dfx$group
 [1] "A" "A" "A" "A" "A" "A" "A" "A" "B" "B" "B" "B" "B" "B" "B" "B" "B" "B"
"B" "B" "B" "B" "B" "C"
[25] "C" "C" "C" "C" "C"
> class(dfx$sex)
[1] "character"
> dfx$sex
 [1] "M" "F" "F" "M" "F" "M" "M" "M" "M" "M" "M" "F" "M" "F" "F" "M" "F" "F"
"M" "M" "M" "M" "M" "F"
[25] "M" "M" "F" "M" "M"
> 



--
View this message in context: http://r.789695.n4.nabble.com/format-selected-columns-in-dataframe-as-character-tp4703863p4703878.html
Sent from the R help mailing list archive at Nabble.com.


From js.huang at protective.com  Thu Feb 26 15:19:57 2015
From: js.huang at protective.com (JS Huang)
Date: Thu, 26 Feb 2015 06:19:57 -0800 (PST)
Subject: [R] covert entire dataset to numeric while persuing percentage
 values
In-Reply-To: <9C74639432B50946BF93B535048331619CEEA9@LONURLNA15.e2k.ad.ge.com>
References: <9C74639432B50946BF93B535048331619CEEA9@LONURLNA15.e2k.ad.ge.com>
Message-ID: <1424960397737-4703880.post@n4.nabble.com>

The following data.frame x as one column named Percent.

> x
  Percent
1     10%
2     20%
3     30%
> as.numeric(substr(x$Percent,1,nchar(x$Percent)-1))
[1] 10 20 30



--
View this message in context: http://r.789695.n4.nabble.com/covert-entire-dataset-to-numeric-while-persuing-percentage-values-tp4703862p4703880.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Thu Feb 26 16:05:35 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 26 Feb 2015 07:05:35 -0800
Subject: [R] covert entire dataset to numeric while persuing
	percentage	values
In-Reply-To: <9C74639432B50946BF93B535048331619CEEA9@LONURLNA15.e2k.ad.ge.com>
References: <9C74639432B50946BF93B535048331619CEEA9@LONURLNA15.e2k.ad.ge.com>
Message-ID: <593A63EF-B6D3-43AE-A35E-63EEAD722A35@dcn.davis.CA.us>

I think you are getting ahead of yourself.

You use the term "dataset", which is colloquial and not precise. The read.csv function returns a data.frame, in which each column can have its own storage mode ("type"). Most data.frames do not have all columns of the same type... if they were you might consider converting to a matrix, but with different units in each column that would not be a good idea in this case.

>From your str output, I think you need to skip loading the second and third lines of your file in the first place, since it looks like they consist of unit strings. Something like:

fname <- file.choose()
xelements <- read.csv( fname, header=FALSE, skip=3, stringsAsFactors=FALSE)

but this does not get your column names. One way to get those would be:

names( xelements ) <- names( read.csv( fname ) )

As for the percent signs, you can convert those with something like:

xelements$ X..NG.by.Energy <- as.numeric( sub( "%". "", xelements$ X..NG.by.Energy ) )

In the future, please don't post in HTML format, as it just leads to confusion on this plain text mailing list. Read the Posting Guide for other warnings, and let us follow your journey to your problem with a reproducible example. There are various discussions online of what is reproducible.. you might start with [1]. Note that the read.csv function supports a "text" argument that lets you embed a sample of lines from your file into your example so we could troubleshoot your input process better if that is where your problem is.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 26, 2015 1:06:03 AM PST, "Methekar, Pushpa (GE Transportation, Non-GE)" <pushpa.methekar at ge.com> wrote:
>Hi ,
>I am little confused  about how to covert entire dataset to numeric .
>As I read data like..
>Xelements =read.csv(file. Choose(),header = T, stringsAsFactors=FALSE)
>str(xelements )
>
>> str(xelements)
>'data.frame':  731 obs. of  4 variables:
>$ Engine.Speed     : chr  "rpm" "ES" "rpm" "1049" ...
>$ X..NG.by.Energy  : chr  "" "% NG by Energy" "%" "0%" ...
>$ Int.Mfld.Temp    : chr  "" "Int Mfld Temp" "?C" "49" ...
>$ Cmd.Advance.Angle: chr  "" "Cmd Advance Angle" "?BTDC" "13.8" ...
>
>I have second column as in 0%, 10%,.... In percentage value ,
>Whenever I am going to covert whole dataset its showing NA introduced
>.second column going to become NA.
>Converting separately I would be successful .
>
>
>> xelements$Engine.Speed <- as.numeric(xelements$Engine.Speed)
>
>Warning message:
>
>NAs introduced by coercion
>
>> xelements$X..NG.by.Energy<-
>as.numeric(sub("%","",xelements$X..NG.by.Energy))/100
>
>Warning message:
>
>NAs introduced by coercion
>
>> xelements$Int.Mfld.Temp<- as.numeric(xelements$Int.Mfld.Temp)
>
>Warning message:
>
>NAs introduced by coercion
>
>> xelements$Cmd.Advance.Angle<- as.numeric(xelements$Cmd.Advance.Angle)
>
>Warning message:
>
>NAs introduced by coercion
>
>But I want to covert whole dataset at a time. I want to write function
>which will help me to solve this problem  .
>
>
>xelements <- data.frame(sapply(xelements, function(x)
>as.numeric(as.character(x))))
>sapply(xelements, class)
>
>but it won't be able to covert percentage value  like 10%, 20%....
>please do help me if you know the way. Thank you
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Thu Feb 26 16:18:43 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 26 Feb 2015 07:18:43 -0800
Subject: [R] aggregating variables (sum within groups)
In-Reply-To: <CAA1twZTv=mDitgtCB=V++XRnM7u8+JWiZtSuSnAin_V-LBhzwQ@mail.gmail.com>
References: <CAA1twZTv=mDitgtCB=V++XRnM7u8+JWiZtSuSnAin_V-LBhzwQ@mail.gmail.com>
Message-ID: <8043D5E1-CC63-44F0-8B9A-551D39185BFD@dcn.davis.CA.us>

For the record, the ave function in R can apply any function you specify, not just mean. The primary feature of ave is that it does not collapse the rows like aggregate does. Choose among them according to how you want the output to be organized.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 26, 2015 4:02:49 AM PST, David Studer <studerov at gmail.com> wrote:
>Hello everybody!
>
>I have a (probabely very easy) problem. Even though I was looking in
>several r-books
>I could not find a suitable function to this problem, that's why I hope
>that someone here
>could help me:
>
># Sample data:
>group<-c("A","A","A","B","B","C","C","C")
>var1<-c(1,0,0,1,1,0,NA,1)
>var2<-c(0,1,NA,0,1,1,0,0)
>testdata<-data.frame(group, var1, var2)
>
>Now, I'd like to generate two aggregated variables:
>
>testdata$x<- ???   should count the sum of var1 within each group (=4)
>testdata$y<- ???   should count the sum of var2 within each group (=3)
>
>Therefore I am looking for a function like ave() which does not
>calculate
>the mean value but a sum.
>
>Thank you for any hints!
>
>David
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Thu Feb 26 16:23:57 2015
From: jholtman at gmail.com (jim holtman)
Date: Thu, 26 Feb 2015 10:23:57 -0500
Subject: [R] Processing key_column, begin_date, end_date in R
In-Reply-To: <CALYoQdoOqXt1qx8=BTGBZPHsKYbRGETBz+vPQ9eQfD1wePjRiA@mail.gmail.com>
References: <CALYoQdoOqXt1qx8=BTGBZPHsKYbRGETBz+vPQ9eQfD1wePjRiA@mail.gmail.com>
Message-ID: <CAAxdm-48aRqpps21c-nua4Y61-EbCKBDk=R4H-zCmuiNKK3A_w@mail.gmail.com>

here is yet another way:

> dta <- read.csv( text=
+ "key_column,begin_date,end_date
+  123456,2013-01-01,2014-01-01
+  123456,2013-07-01,2014-07-01
+  789102,2012-03-01,2014-03-01
+  789102,2015-02-01,2016-02-01
+  789102,2015-02-06,2016-02-06
+ 789102,2015-02-28,2015-03-31
+  789102,2015-04-30,2015-05-31"
+  , as.is=TRUE)
>
> # check for overlap by sorting into time order and the adding 1 for
> # begin and -1 for end and create cumsum
> # select only resulting entries with begin @ 1 and end @ 0
> dta <- dta %>%
+     mutate(begin_date = as.Date(begin_date)  # convert the times
+         , end_date = as.Date(end_date)
+         ) %>%
+     gather(time, value, -key_column) %>%  # create 'long' data
+     mutate(oper = ifelse(grepl('^b', time), 1, -1)) %>%  # value for begin/end
+     arrange(value) %>%  # sort by time
+     group_by(key_column) %>%  # separate into groups
+     mutate(depth = cumsum(oper)) %>%
+     filter((grepl("^b", time) & depth == 1) |  # filter on begin at 1 and end at 0
+           (grepl("^e", time) & depth == 0)
+           ) %>%
+     ungroup() %>%
+     arrange(key_column, value)
> # now have pairs of lines for the times
> indx <- seq(1, nrow(dta), 2)
> result <- data.frame(key_column = dta$key_column[indx]
+                 , begin_time = dta$value[indx]
+                 , end_time = dta$value[indx + 1L]
+                 , stringsAsFactors = FALSE
+                 )
> result
  key_column begin_time   end_time
1     123456 2013-01-01 2014-07-01
2     789102 2012-03-01 2014-03-01
3     789102 2015-02-01 2016-02-06
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Feb 25, 2015 at 4:18 PM, Matt Gross <grossm at gmail.com> wrote:
> Hi,
>
> I am trying to process a large dataset in R.  The dataset contains the
> following three columns:
>
> key_column - a unique key identifier
> begin_date - the start date of the active period
> end_date - the end date of the active period
>
>
> Example data is here:
>
> key_column,begin_date,end_date
> 123456,2013-01-01,2014-01-01
> 123456,2013-07-01,2014-07-01
> 789102,2012-03-01,2014-03-01
> 789102,2015-02-01,2016-02-01
> 789102,2015-02-06,2016-02-06
>
> I want to build a condensed table of key_column and begin_date's and
> end_date's.  As you can see in the example data above, some begin and end
> date periods overlap with begin_date and end_date pairs for the same
> key_column.  In situations where overlap exists I want to have one record
> for the key_column with the min(begin_date) and the max(end_date).
>
> Can anyone help me build the commands to process this data in R?
>
> Thanks,
> Matt
>
> --
> Matt Gross
> grossm at gmail.com
> 503.329.4545
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mikaelmilhoj at gmail.com  Thu Feb 26 17:02:48 2015
From: mikaelmilhoj at gmail.com (=?UTF-8?Q?Mikael_Olai_Milh=C3=B8j?=)
Date: Thu, 26 Feb 2015 17:02:48 +0100
Subject: [R] Dummy variable in ARIMA
Message-ID: <CACM6noY+DLzN-JgfYZw2ZNUyCotu9SawAqB+QZgTN5-=QAvqpw@mail.gmail.com>

Hi all

I have been searching on the web in vain. I want to include a dummy
variable in my ARIMA model. Let's say that I want to make an AR(1) model
for X including a dummy variable which should be 1 for observation 4,5,6
and zero otherwise (let's say that there is 50 observations in total). How
do I make that?

This does the trick but seems inefficient: dummy<-c(rep(0,3), rep(1,3),
rep(0,44))

Thx in advance

Best regards
/Mikael

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Feb 26 17:05:09 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 26 Feb 2015 16:05:09 +0000
Subject: [R] format selected columns in dataframe as character
In-Reply-To: <2077440503.1063622.1424945338331.JavaMail.open-xchange@patina.store>
References: <2077440503.1063622.1424945338331.JavaMail.open-xchange@patina.store>
Message-ID: <D1148346.120819%macqueen1@llnl.gov>

Of course you could have created them as character vectors in the first
place:

dfx <- data.frame(
  group = c(rep('A', 8), rep('B', 15), rep('C', 6)),
  sex = sample(c("M", "F"), size = 29, replace = TRUE),
  age = runif(n = 29, min = 18, max = 54),
  stringsAsFactors=FALSE
  )


But if that is not possible in your context, then I would suggest this:

for (nm in names(dfx))
   if (is.factor(dfx[[nm]])) dfx[[nm]] <- as.character(dfx[[nm]])

It's clear and simple.



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 2/26/15, 2:08 AM, "Alain D." <dialvac-r at yahoo.de> wrote:

>Dear R-List,
> 
>#I have a df with the first two cols formatted as factor.
> 
>dfx <- data.frame(
>group = c(rep('A', 8), rep('B', 15), rep('C', 6)),
>sex = sample(c("M", "F"), size = 29, replace = TRUE),
>age = runif(n = 29, min = 18, max = 54))
> 
># now I want to format both factor VARs as character
># I tried
> 
>factor.id<-names(dfx[sapply(dfx,is.factor)])
>chr.names<-which(names(dfx)%in% factor.id)
> 
>dfx[ , chr.names]<-as.character(dfx[ , chr.names])
># which gives me
>str(dfx)
>'data.frame': 29 obs. of 3 variables: $ group: chr "c(1, 1, 1, 1, 1, 1,
>1, 1, 2,
>2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3)" "c(2, 2, 1,
>1, 1,
>1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2)"
>"c(1,
>1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,
>3, 3, 3,
>3)" "c(2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1,
>1, 1,
>1, 1, 2, 2, 2)" ... $ sex : chr "c(2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2,
>2, 2,
>1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2)" "c(1, 1, 1, 1, 1, 1, 1, 1, 2,
>2, 2,
>2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3)" "c(2, 2, 1, 1, 1,
>1, 2,
>1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2)" "c(1,
>1, 1,
>1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,
>3, 3)"
>... $ age : num 38.5 18 33.5 26 22.5 ...
> 
>#though I was hoping for something like
> 
>'data.frame': 29 obs. of  3 variables:
>$ group: chr  "A" "A" "A" "A" ...
>$ sex  : chr  "M" "F" "F" "M" ...
>$ age  : num  21.3 35.2 53.8 21 23.6 ...
>
>#What is wrong with my code?
>#Thank you for any help
>
>Best wishes 
>
>Alain
> 
> 
> 
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tea3rd at gmail.com  Thu Feb 26 17:11:54 2015
From: tea3rd at gmail.com (Thomas Adams)
Date: Thu, 26 Feb 2015 21:11:54 +0500
Subject: [R] Best Mac for R
In-Reply-To: <CAHgH9_EeBw6ntXmsu8nygYmEraL1G_dN++fP6wqvN9G8TMWWcw@mail.gmail.com>
References: <CAHgH9_EeBw6ntXmsu8nygYmEraL1G_dN++fP6wqvN9G8TMWWcw@mail.gmail.com>
Message-ID: <CAGxgkWhtnRYMT8T_R1tB2OQRKZBL4j4q+kCNoOUSUWcZi3Y00Q@mail.gmail.com>

Dan,

FWIW, I have basically the system you describe, except a larger HD ? I'm
quite happy, but I'm a biased Mac user, although I love my Ubuntu Linux
machine as well? One can bring any machine to its knees, so there is the
element of expectations. A MacBook Pro stacks up as well or better compared
to a similarly configured windows box. The thing is, IMO, there are at
least two very good virtual machines to run MS-Windows on if the need
arises (as well as Apple's 'Boot Camp') and, I believe, since the core Mac
OS is essentially UNIX/Linux you have all that capability natively as well.

Tom

On Thu, Feb 26, 2015 at 12:50 AM, Dan Murphy <chiefmurphy at gmail.com> wrote:

> I am possibly in the market for a new laptop. Predominantly a Windows
> user, I owned a macbook pro 10 years ago and am considering going that
> route again. Does the standard advice still hold: Get the most
> powerful processor (i7), most ram (16GB), and largest internal storage
> (512GB), if affordable?
> thanks,
> dan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Thu Feb 26 17:17:31 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 26 Feb 2015 08:17:31 -0800
Subject: [R] Dummy variable in ARIMA
In-Reply-To: <CACM6noY+DLzN-JgfYZw2ZNUyCotu9SawAqB+QZgTN5-=QAvqpw@mail.gmail.com>
References: <CACM6noY+DLzN-JgfYZw2ZNUyCotu9SawAqB+QZgTN5-=QAvqpw@mail.gmail.com>
Message-ID: <CACk-te07UHoQyQj0JTBMjyNArpq6UvKP0o49uC4R+263ZjFz5w@mail.gmail.com>

Inline.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Feb 26, 2015 at 8:02 AM, Mikael Olai Milh?j
<mikaelmilhoj at gmail.com> wrote:
> Hi all
>
> I have been searching on the web in vain. I want to include a dummy
> variable in my ARIMA model. Let's say that I want to make an AR(1) model
> for X including a dummy variable which should be 1 for observation 4,5,6
> and zero otherwise (let's say that there is 50 observations in total). How
> do I make that?

You don't, really.

1. Go through an R tutorial so that you understand the concept of
factors and how they are used in R modeling.

2. fact <- factor( (1:50) %in% (4:6))

Cheers,
Bert

>
> This does the trick but seems inefficient: dummy<-c(rep(0,3), rep(1,3),
> rep(0,44))
>
> Thx in advance
>
> Best regards
> /Mikael
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mikaelmilhoj at gmail.com  Thu Feb 26 17:29:26 2015
From: mikaelmilhoj at gmail.com (=?UTF-8?Q?Mikael_Olai_Milh=C3=B8j?=)
Date: Thu, 26 Feb 2015 17:29:26 +0100
Subject: [R] Dummy variable in ARIMA
In-Reply-To: <CACk-te07UHoQyQj0JTBMjyNArpq6UvKP0o49uC4R+263ZjFz5w@mail.gmail.com>
References: <CACM6noY+DLzN-JgfYZw2ZNUyCotu9SawAqB+QZgTN5-=QAvqpw@mail.gmail.com>
	<CACk-te07UHoQyQj0JTBMjyNArpq6UvKP0o49uC4R+263ZjFz5w@mail.gmail.com>
Message-ID: <CACM6noYFLyh-7i78tNTRhETY=1x1aNBDfsgn52m8Vc6zmoUQ2w@mail.gmail.com>

Hi.

First of all, thx. But when using in arima(...xreg=fact,...) then fact
should be a vector and not a factor variable? Maybe I should have been more
clear in my first mail, sorry. Or else I have to dig deeper into factors.


/Mikael

On Thu, Feb 26, 2015 at 5:17 PM, Bert Gunter <gunter.berton at gene.com> wrote:

> Inline.
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Thu, Feb 26, 2015 at 8:02 AM, Mikael Olai Milh?j
> <mikaelmilhoj at gmail.com> wrote:
> > Hi all
> >
> > I have been searching on the web in vain. I want to include a dummy
> > variable in my ARIMA model. Let's say that I want to make an AR(1) model
> > for X including a dummy variable which should be 1 for observation 4,5,6
> > and zero otherwise (let's say that there is 50 observations in total).
> How
> > do I make that?
>
> You don't, really.
>
> 1. Go through an R tutorial so that you understand the concept of
> factors and how they are used in R modeling.
>
> 2. fact <- factor( (1:50) %in% (4:6))
>
> Cheers,
> Bert
>
> >
> > This does the trick but seems inefficient: dummy<-c(rep(0,3), rep(1,3),
> > rep(0,44))
> >
> > Thx in advance
> >
> > Best regards
> > /Mikael
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Feb 26 17:47:11 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 26 Feb 2015 08:47:11 -0800
Subject: [R] aggregating variables (sum within groups)
In-Reply-To: <CAA1twZTv=mDitgtCB=V++XRnM7u8+JWiZtSuSnAin_V-LBhzwQ@mail.gmail.com>
References: <CAA1twZTv=mDitgtCB=V++XRnM7u8+JWiZtSuSnAin_V-LBhzwQ@mail.gmail.com>
Message-ID: <CAF8bMcYVWrcRs494MNsfXY3dY5TkD55YmThwUtgRf32M+jBEcw@mail.gmail.com>

> Even though I was looking in several r-books
> I could not find a suitable function to this problem

Which R books did you look through?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Feb 26, 2015 at 4:02 AM, David Studer <studerov at gmail.com> wrote:

> Hello everybody!
>
> I have a (probabely very easy) problem. Even though I was looking in
> several r-books
> I could not find a suitable function to this problem, that's why I hope
> that someone here
> could help me:
>
> # Sample data:
> group<-c("A","A","A","B","B","C","C","C")
> var1<-c(1,0,0,1,1,0,NA,1)
> var2<-c(0,1,NA,0,1,1,0,0)
> testdata<-data.frame(group, var1, var2)
>
> Now, I'd like to generate two aggregated variables:
>
> testdata$x<- ???   should count the sum of var1 within each group (=4)
> testdata$y<- ???   should count the sum of var2 within each group (=3)
>
> Therefore I am looking for a function like ave() which does not calculate
> the mean value but a sum.
>
> Thank you for any hints!
>
> David
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marongiu.luigi at gmail.com  Thu Feb 26 17:58:35 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Thu, 26 Feb 2015 16:58:35 +0000
Subject: [R] extract file name from a path string
Message-ID: <CAMk+s2RBjhXGx1hgkpUWefatdCi7uUGdVsKKawPj+GR9dsmn5w@mail.gmail.com>

Dear all,
what code should I write in order to extract the file name from a give
path? Let's say that I want to get the file "my file.xls" which is in
the directory/folder "My documents"; since I work both with Windows
and Linux, the paths I am looking at are in the format:

path.windows<-"\\home$\\lm667\\My Documents\\my file.xls"
path.linux<-"/home/My Documents/my file.xls"

I used two words for the file name because sometimes the file names
have multiple words rather than a single one separated by capitals,
"." or "_".
The code should now get the file name, which is included between "\\"
(or "/") and ".xls" but I don't know what regular expression will do
the trick.
Once the file name has been assigned to a vector, it should be easy to
remove it from the path.windows/.linux and obtain a vector with the
path on its own.
Essentially the output should be as follows:

> file.name
[1] "my file.xls"
> path.w
[1] "\\home$\\lm667\\My Documents\\"
> path.l
[1] "/home/My Documents/"

Thank you,
Luigi


From john.archie.mckown at gmail.com  Thu Feb 26 18:04:25 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 26 Feb 2015 11:04:25 -0600
Subject: [R] extract file name from a path string
In-Reply-To: <CAMk+s2RBjhXGx1hgkpUWefatdCi7uUGdVsKKawPj+GR9dsmn5w@mail.gmail.com>
References: <CAMk+s2RBjhXGx1hgkpUWefatdCi7uUGdVsKKawPj+GR9dsmn5w@mail.gmail.com>
Message-ID: <CAAJSdjjQfdVTGvAwMYCnSEXJ085GkqHKSNirioe=5+xhZ6s_mw@mail.gmail.com>

Look at "dirname()" and "basename()". The first would be what you call
the path. The second is the file.name without the path.

On Thu, Feb 26, 2015 at 10:58 AM, Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> Dear all,
> what code should I write in order to extract the file name from a give
> path? Let's say that I want to get the file "my file.xls" which is in
> the directory/folder "My documents"; since I work both with Windows
> and Linux, the paths I am looking at are in the format:
>
> path.windows<-"\\home$\\lm667\\My Documents\\my file.xls"
> path.linux<-"/home/My Documents/my file.xls"
>
> I used two words for the file name because sometimes the file names
> have multiple words rather than a single one separated by capitals,
> "." or "_".
> The code should now get the file name, which is included between "\\"
> (or "/") and ".xls" but I don't know what regular expression will do
> the trick.
> Once the file name has been assigned to a vector, it should be easy to
> remove it from the path.windows/.linux and obtain a vector with the
> path on its own.
> Essentially the output should be as follows:
>
>> file.name
> [1] "my file.xls"
>> path.w
> [1] "\\home$\\lm667\\My Documents\\"
>> path.l
> [1] "/home/My Documents/"
>
> Thank you,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown


From pdalgd at gmail.com  Thu Feb 26 18:27:26 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 26 Feb 2015 18:27:26 +0100
Subject: [R] Dummy variable in ARIMA
In-Reply-To: <CACM6noYFLyh-7i78tNTRhETY=1x1aNBDfsgn52m8Vc6zmoUQ2w@mail.gmail.com>
References: <CACM6noY+DLzN-JgfYZw2ZNUyCotu9SawAqB+QZgTN5-=QAvqpw@mail.gmail.com>
	<CACk-te07UHoQyQj0JTBMjyNArpq6UvKP0o49uC4R+263ZjFz5w@mail.gmail.com>
	<CACM6noYFLyh-7i78tNTRhETY=1x1aNBDfsgn52m8Vc6zmoUQ2w@mail.gmail.com>
Message-ID: <F674FB18-08AA-408D-88D1-911BBF2C1EC2@gmail.com>


> On 26 Feb 2015, at 17:29 , Mikael Olai Milh?j <mikaelmilhoj at gmail.com> wrote:
> 
> Hi.
> 
> First of all, thx. But when using in arima(...xreg=fact,...) then fact
> should be a vector and not a factor variable? Maybe I should have been more
> clear in my first mail, sorry. Or else I have to dig deeper into factors.
> 

You can always do things like as.numeric((1:50) %in% (4:6)), but longer term I think it is more generalizable to play with model.matrix(), i.e. M <- model.matrix(~fact). As far as I recall, arima() will automatically include a constant so you need to say xreg=M[,-1] to get rid of the column of ones.


> 
> /Mikael
> 
> On Thu, Feb 26, 2015 at 5:17 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> 
>> Inline.
>> 
>> Cheers,
>> Bert
>> 
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>> 
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>> 
>> 
>> 
>> 
>> On Thu, Feb 26, 2015 at 8:02 AM, Mikael Olai Milh?j
>> <mikaelmilhoj at gmail.com> wrote:
>>> Hi all
>>> 
>>> I have been searching on the web in vain. I want to include a dummy
>>> variable in my ARIMA model. Let's say that I want to make an AR(1) model
>>> for X including a dummy variable which should be 1 for observation 4,5,6
>>> and zero otherwise (let's say that there is 50 observations in total).
>> How
>>> do I make that?
>> 
>> You don't, really.
>> 
>> 1. Go through an R tutorial so that you understand the concept of
>> factors and how they are used in R modeling.
>> 
>> 2. fact <- factor( (1:50) %in% (4:6))
>> 
>> Cheers,
>> Bert
>> 
>>> 
>>> This does the trick but seems inefficient: dummy<-c(rep(0,3), rep(1,3),
>>> rep(0,44))
>>> 
>>> Thx in advance
>>> 
>>> Best regards
>>> /Mikael
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From gunter.berton at gene.com  Thu Feb 26 18:29:13 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 26 Feb 2015 09:29:13 -0800
Subject: [R] Dummy variable in ARIMA
In-Reply-To: <CACM6noYFLyh-7i78tNTRhETY=1x1aNBDfsgn52m8Vc6zmoUQ2w@mail.gmail.com>
References: <CACM6noY+DLzN-JgfYZw2ZNUyCotu9SawAqB+QZgTN5-=QAvqpw@mail.gmail.com>
	<CACk-te07UHoQyQj0JTBMjyNArpq6UvKP0o49uC4R+263ZjFz5w@mail.gmail.com>
	<CACM6noYFLyh-7i78tNTRhETY=1x1aNBDfsgn52m8Vc6zmoUQ2w@mail.gmail.com>
Message-ID: <CACk-te0fOdsNmqSa=jH1FHhMugBXYBDb0-7NZtH+bxrp1d=BiA@mail.gmail.com>

Dig deeper.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Feb 26, 2015 at 8:29 AM, Mikael Olai Milh?j
<mikaelmilhoj at gmail.com> wrote:
> Hi.
>
> First of all, thx. But when using in arima(...xreg=fact,...) then fact
> should be a vector and not a factor variable? Maybe I should have been more
> clear in my first mail, sorry. Or else I have to dig deeper into factors.
>
>
> /Mikael
>
> On Thu, Feb 26, 2015 at 5:17 PM, Bert Gunter <gunter.berton at gene.com> wrote:
>>
>> Inline.
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Thu, Feb 26, 2015 at 8:02 AM, Mikael Olai Milh?j
>> <mikaelmilhoj at gmail.com> wrote:
>> > Hi all
>> >
>> > I have been searching on the web in vain. I want to include a dummy
>> > variable in my ARIMA model. Let's say that I want to make an AR(1) model
>> > for X including a dummy variable which should be 1 for observation 4,5,6
>> > and zero otherwise (let's say that there is 50 observations in total).
>> > How
>> > do I make that?
>>
>> You don't, really.
>>
>> 1. Go through an R tutorial so that you understand the concept of
>> factors and how they are used in R modeling.
>>
>> 2. fact <- factor( (1:50) %in% (4:6))
>>
>> Cheers,
>> Bert
>>
>> >
>> > This does the trick but seems inefficient: dummy<-c(rep(0,3), rep(1,3),
>> > rep(0,44))
>> >
>> > Thx in advance
>> >
>> > Best regards
>> > /Mikael
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From scolwell at uoguelph.ca  Thu Feb 26 19:29:16 2015
From: scolwell at uoguelph.ca (Scott Colwell)
Date: Thu, 26 Feb 2015 10:29:16 -0800 (PST)
Subject: [R] Extracting Factor Pattern Matrix Similar to Proc Factor
In-Reply-To: <692083CA-AC98-4FC0-8F93-C51000B83F95@revelle.net>
References: <1424715313110-4703704.post@n4.nabble.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6556A0@mb02.ads.tamu.edu>
	<1424727230269-4703719.post@n4.nabble.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D655712@mb02.ads.tamu.edu>
	<692083CA-AC98-4FC0-8F93-C51000B83F95@revelle.net>
Message-ID: <1424975356270-4703904.post@n4.nabble.com>

Thanks everyone



--
View this message in context: http://r.789695.n4.nabble.com/Extracting-Factor-Pattern-Matrix-Similar-to-Proc-Factor-tp4703704p4703904.html
Sent from the R help mailing list archive at Nabble.com.


From scolwell at uoguelph.ca  Thu Feb 26 19:32:02 2015
From: scolwell at uoguelph.ca (Scott Colwell)
Date: Thu, 26 Feb 2015 10:32:02 -0800 (PST)
Subject: [R] Saving Mean Relative Difference from all.equal()
Message-ID: <1424975522410-4703905.post@n4.nabble.com>


Hello,

Does anyone know how to save the numeric value of the "mean relative
difference" when using the all.equal() command?

For example this:

all.equal(cov2cor(ITEMCOV),cor(item.data))

Gives:

[1] "Attributes: < Length mismatch: comparison on first 1 components >"
[2] "Mean relative difference: 0.01523708"   

I'd like to save the value 0.01523708 in a numeric format.

Thanks,




--
View this message in context: http://r.789695.n4.nabble.com/Saving-Mean-Relative-Difference-from-all-equal-tp4703905.html
Sent from the R help mailing list archive at Nabble.com.


From mtoncic at ffri.hr  Thu Feb 26 19:49:17 2015
From: mtoncic at ffri.hr (marKo)
Date: Thu, 26 Feb 2015 19:49:17 +0100
Subject: [R] integrate with vector arguments
Message-ID: <54EF6AAD.5000105@ffri.hr>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I'm a bit stuck.
I have to integrate a series of polynomial functions with vector
arguments.

v1<-c(1:5)
v2<-c(1:5)

f1<-function (x) {v1*x+v2*x^2}

The problem is that integrate(f1, 0, 1) does not work.
I does not, even if a pas the arguments (v1, v2)

f1<-function (x, v1, v2) {v1*x+v2*x^2}

or if i try to vectorize the function

f1<-Vectorize(function(x, v1, v2){v1*x+v2*x^2},
vectorize.args=c("v1", "v2"))

integrate(f1, 0, 1) gives an error:

Error in integrate(f1, 0, 1) :
  evaluation of function gave a result of wrong length

Any help will be greatly appreciated.

Thanks,

Marko

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQIcBAEBAgAGBQJU72qnAAoJEJcj4KySkkQsLAkP/R7DvO0GiZDRrtHgDna/2xj+
XJd8G/gGfe029lVjg+3i6wfKfZ9CoRH+kHEVnT0/SRYcSAeRu3/fys11sjEgVGnl
a/Go167YRYfDkP/OrY4jKtlULySeiGBxNJwKmk1oCidoodk2mejWdPQ61tBj6ozF
sA+Bzoi7Exh2pp88Eks4+Ynz+Toi8Ck1hItV60kP9yOMSBsIPVLw53lGXDfOshzM
zLcFbHM5hyjmt/BQvyaBm3E822YEJgcDQN3nedjQgwThJuEyig2TXHAvyEZcdBWD
H8Py0b5/TBdmxqJQ3EqYyBFmPxeFuhO4ZS22IhP+rqPJ51EZnfqG6DRBHHLqQ9rX
ZnYJN8ryqDVMOrYHn6j3dNd/m7C/YWmrY8gjArv8WxRsX+kX+DAgbRmiw/43BXNG
Y2Jco5dChWBrXQDR3FMoJWBTWjvwgPfP06hnwjrJT1uJZQLPUzhdrIxyHxbhsW0A
UeiRqNiPjE9YpKrFGn9Itg1tXk35yrPrNmmj1nzIzaHejMzT8zf0X2pJAygAYyk3
+mrEgwkB31GOt2mUqqFzDxgDHASaSTPlskviIVJ9klcs7ViWYSy5ARiF4/ptbluE
CTny7dVj/AoXq8dC8TxghOT1QSnPVy7ceb6fCep7LxJDWlFqTEM0LCbL7Ql78yzP
+Em5gaikzPGbJ7uvVKIG
=7J6P
-----END PGP SIGNATURE-----


From HDoran at air.org  Thu Feb 26 20:08:51 2015
From: HDoran at air.org (Doran, Harold)
Date: Thu, 26 Feb 2015 19:08:51 +0000
Subject: [R] Schedule R function/Code to run at specific time
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686CF3AE4B4@DC1VEX10MB001.air.org>

Is there functionality within R proper, without having to revert to the OS, allowing a function or a portion of an R script to be run at a defined time? My google searches haven't provided much other than one at the link below which relies on an OS.

Thanks,
Harold

https://tgmstat.wordpress.com/2013/09/11/schedule-rscript-with-cron/

	[[alternative HTML version deleted]]


From scolwell at uoguelph.ca  Thu Feb 26 20:02:23 2015
From: scolwell at uoguelph.ca (Scott Colwell)
Date: Thu, 26 Feb 2015 11:02:23 -0800 (PST)
Subject: [R] Saving Mean Relative Difference from all.equal()
In-Reply-To: <1424975522410-4703905.post@n4.nabble.com>
References: <1424975522410-4703905.post@n4.nabble.com>
Message-ID: <1424977343790-4703908.post@n4.nabble.com>

I think I have one solution. Not very pretty though. Relies on the text not
changing at all.

as.numeric(gsub("Mean relative difference: ", "",
all.equal(cov2cor(ITEMCOV),cor(item.data))[2]))

Is there a better way?



--
View this message in context: http://r.789695.n4.nabble.com/Saving-Mean-Relative-Difference-from-all-equal-tp4703905p4703908.html
Sent from the R help mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Thu Feb 26 20:20:44 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 Feb 2015 14:20:44 -0500
Subject: [R] Schedule R function/Code to run at specific time
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686CF3AE4B4@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686CF3AE4B4@DC1VEX10MB001.air.org>
Message-ID: <54EF720C.3040203@gmail.com>

On 26/02/2015 2:08 PM, Doran, Harold wrote:
> Is there functionality within R proper, without having to revert to the OS, allowing a function or a portion of an R script to be run at a defined time? My google searches haven't provided much other than one at the link below which relies on an OS.

If you want it to start 1000 seconds from now, use Sys.sleep(1000) as 
your first statement.  You'll have a process sitting there using no CPU 
(but perhaps lots of virtual memory) until the sleeping is done.  Using 
cron is better.

Duncan Murdoch


From macqueen1 at llnl.gov  Thu Feb 26 20:50:51 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 26 Feb 2015 19:50:51 +0000
Subject: [R] Schedule R function/Code to run at specific time
In-Reply-To: <54EF720C.3040203@gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686CF3AE4B4@DC1VEX10MB001.air.org>
	<54EF720C.3040203@gmail.com>
Message-ID: <D114B764.1208B9%macqueen1@llnl.gov>

Everything Duncan said, plus:

A construction like this might do the job

run.at <- as.POSIXct('2015-02-26 13:05')
while(TRUE) {
  if ( trunc(Sys.time(),'min') == run.at) source('whatever-it-is.r')
  Sys.sleep(60)
}


but I wouldn't count on it to be as reliable as cron (or Windows
equivalent).

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 2/26/15, 11:20 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:

>On 26/02/2015 2:08 PM, Doran, Harold wrote:
>> Is there functionality within R proper, without having to revert to the
>>OS, allowing a function or a portion of an R script to be run at a
>>defined time? My google searches haven't provided much other than one at
>>the link below which relies on an OS.
>
>If you want it to start 1000 seconds from now, use Sys.sleep(1000) as
>your first statement.  You'll have a process sitting there using no CPU
>(but perhaps lots of virtual memory) until the sleeping is done.  Using
>cron is better.
>
>Duncan Murdoch
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kate.ignatius at gmail.com  Thu Feb 26 21:23:48 2015
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Thu, 26 Feb 2015 15:23:48 -0500
Subject: [R] Summing certain values within columns that satisfy a certain
	condition
Message-ID: <CAE6QMsbpTgDX=b-tegcahURbSjANQaXtxxoDPxzZER3nUU5ffw@mail.gmail.com>

Hi,

Supposed I had a data frame like so:

A B C D
0 1 0 7
0 2 0 7
0 3 0 7
0 4 0 7
0 1 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 1 5
0 5 1 5
0 4 1 5
0 8 4 7
0 0 3 0
0 0 3 4
0 0 3 4
0 0 0 5
0 2 0 6
0 0 4 0
0 0 4 0
0 0 4 0

For each row, I want to count how many max column values appear to
adventurely get the following outcome, while ignoring zeros and N/As:

A B C D Sum
0 1 0 7 1
0 2 0 7 1
0 3 0 7 1
0 4 0 7 1
0 1 0 0 0
0 0 0 0 0
0 0 0 0 0
0 0 0 0 0
0 0 1 5 0
0 5 1 5 0
0 4 1 5 0
0 8 4 7 3
0 0 3 0 0
0 0 3 4 0
0 0 3 4 0
0 0 0 5 0
0 2 0 6 0
0 0 4 0 1
0 0 4 0 1
0 0 4 0 1

I've used the following code but it doesn't seem to work (my sum
column column is all 1s):

(apply(df,1, function(x)  (sum(x %in% c(pmax(x))))))

Is this code too simple?

Thanks!

K.


From arne.henningsen at gmail.com  Thu Feb 26 22:05:26 2015
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Thu, 26 Feb 2015 22:05:26 +0100
Subject: [R] PEA and APE Tobit
In-Reply-To: <1424938354172-4703856.post@n4.nabble.com>
References: <1424938354172-4703856.post@n4.nabble.com>
Message-ID: <CAMTWbJgecMFUyRkgTe7nFZCMt5+ZN-_heyg1LbKAXRfx0SZpeQ@mail.gmail.com>

Dear Annelies

On 26 February 2015 at 09:12, hnlki <annelies.hoebeeck at ugent.be> wrote:
> I estimated a tobit model
> tobit.fit<-tobit(y~x,left=0, right=Inf)  (library "AER")
> or
> tobit2.fit<-censReg(y~x, left=0, right=Inf) (library"censReg")
> I' have estimated the partial effect at the average as:
> pea<-(pnorm((colMeans(x)%*%tobit.fit$coef[-1])/tobit.fit$scale))%*%tobit.fitt$coef[-1]
> and the average partial effect as:
> ape<-
> (length(x[,1]))^(-1)*sum(pnorm((x%*%tobit.fit$coef[-1])/tobit.fit$scale))*tobit.fit$coef[-1]
>
> I guess I did something wrong as
>  margEff( tobit2.fit) (library("censReg")
>  gives a different result than my partial effect at the average.
>
> Any ideas about what I did wrong?
> I  did not find the underlying code of margEff.

[...]

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please follow the posting guide and provide a self-contained
reproducible example.

Best regards,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name


From pdalgd at gmail.com  Thu Feb 26 22:19:48 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 26 Feb 2015 22:19:48 +0100
Subject: [R] Schedule R function/Code to run at specific time
In-Reply-To: <54EF720C.3040203@gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686CF3AE4B4@DC1VEX10MB001.air.org>
	<54EF720C.3040203@gmail.com>
Message-ID: <0C6762D3-6086-4219-BD7A-5715790B918E@gmail.com>


> On 26 Feb 2015, at 20:20 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 26/02/2015 2:08 PM, Doran, Harold wrote:
>> Is there functionality within R proper, without having to revert to the OS, allowing a function or a portion of an R script to be run at a defined time? My google searches haven't provided much other than one at the link below which relies on an OS.
> 
> If you want it to start 1000 seconds from now, use Sys.sleep(1000) as your first statement.  You'll have a process sitting there using no CPU (but perhaps lots of virtual memory) until the sleeping is done.  Using cron is better.
> 

There are also some asynchronous possibilities using tcltk:

tcl("after", 10000, quote(print("boo")))

Peter D.

> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Thu Feb 26 22:29:27 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 26 Feb 2015 13:29:27 -0800
Subject: [R] Summing certain values within columns that satisfy a
	certain	condition
In-Reply-To: <CAE6QMsbpTgDX=b-tegcahURbSjANQaXtxxoDPxzZER3nUU5ffw@mail.gmail.com>
References: <CAE6QMsbpTgDX=b-tegcahURbSjANQaXtxxoDPxzZER3nUU5ffw@mail.gmail.com>
Message-ID: <D7B0B8F0-7431-4188-95BB-E7F1CBEC0616@dcn.davis.CA.us>

I guess the answer to your question is "yes".

dta <- read.table( text=
"A B C D
0 1 0 7
0 2 0 7
0 3 0 7
0 4 0 7
0 1 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 1 5
0 5 1 5
0 4 1 5
0 8 4 7
0 0 3 0
0 0 3 4
0 0 3 4
0 0 0 5
0 2 0 6
0 0 4 0
0 0 4 0
0 0 4 0
", header=TRUE )
dtacmax <- sapply( dta, max )

followed by

dta$Sum <- apply(dta,1, function(x) (sum(0!=x & x == dtacmax,na.rm=TRUE)))

or

dtam <- as.matrix( dta[,1:4] )
dta$Sum2 <- rowSums( !is.na(dtam) & 0!=dtam & dtam == matrix( dtacmax, ncol=ncol( dtam ), nrow=nrow( dtam ), byrow=TRUE ) )


---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On February 26, 2015 12:23:48 PM PST, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>Hi,
>
>Supposed I had a data frame like so:
>
>A B C D
>0 1 0 7
>0 2 0 7
>0 3 0 7
>0 4 0 7
>0 1 0 0
>0 0 0 0
>0 0 0 0
>0 0 0 0
>0 0 1 5
>0 5 1 5
>0 4 1 5
>0 8 4 7
>0 0 3 0
>0 0 3 4
>0 0 3 4
>0 0 0 5
>0 2 0 6
>0 0 4 0
>0 0 4 0
>0 0 4 0
>
>For each row, I want to count how many max column values appear to
>adventurely get the following outcome, while ignoring zeros and N/As:
>
>A B C D Sum
>0 1 0 7 1
>0 2 0 7 1
>0 3 0 7 1
>0 4 0 7 1
>0 1 0 0 0
>0 0 0 0 0
>0 0 0 0 0
>0 0 0 0 0
>0 0 1 5 0
>0 5 1 5 0
>0 4 1 5 0
>0 8 4 7 3
>0 0 3 0 0
>0 0 3 4 0
>0 0 3 4 0
>0 0 0 5 0
>0 2 0 6 0
>0 0 4 0 1
>0 0 4 0 1
>0 0 4 0 1
>
>I've used the following code but it doesn't seem to work (my sum
>column column is all 1s):
>
>(apply(df,1, function(x)  (sum(x %in% c(pmax(x))))))
>
>Is this code too simple?
>
>Thanks!
>
>K.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From annelies.hoebeeck at ugent.Be  Thu Feb 26 23:28:50 2015
From: annelies.hoebeeck at ugent.Be (hnlki)
Date: Thu, 26 Feb 2015 14:28:50 -0800 (PST)
Subject: [R] PEA and APE Tobit
In-Reply-To: <CAMTWbJgecMFUyRkgTe7nFZCMt5+ZN-_heyg1LbKAXRfx0SZpeQ@mail.gmail.com>
References: <1424938354172-4703856.post@n4.nabble.com>
	<CAMTWbJgecMFUyRkgTe7nFZCMt5+ZN-_heyg1LbKAXRfx0SZpeQ@mail.gmail.com>
Message-ID: <508C64CD-A46A-4D76-B403-F99EA6551C84@ugent.be>

Dear Mr Henningsen,

I have read the posting guide but apparently not well enough.  I didn't find how to include R code in my post. I'll read it again and I'll try to give a clearer example.
Sorry for the inconvenience. 

Kind regards,
Annelies

> Op 26-feb.-2015 om 21:59 heeft Arne Henningsen-3 [via R] <ml-node+s789695n4703915h77 at n4.nabble.com> het volgende geschreven:
> 
> Dear Annelies 
> 
> On 26 February 2015 at 09:12, hnlki <[hidden email]> wrote:
> 
> > I estimated a tobit model 
> > tobit.fit<-tobit(y~x,left=0, right=Inf)  (library "AER") 
> > or 
> > tobit2.fit<-censReg(y~x, left=0, right=Inf) (library"censReg") 
> > I' have estimated the partial effect at the average as: 
> > pea<-(pnorm((colMeans(x)%*%tobit.fit$coef[-1])/tobit.fit$scale))%*%tobit.fitt$coef[-1] 
> > and the average partial effect as: 
> > ape<- 
> > (length(x[,1]))^(-1)*sum(pnorm((x%*%tobit.fit$coef[-1])/tobit.fit$scale))*tobit.fit$coef[-1] 
> > 
> > I guess I did something wrong as 
> >  margEff( tobit2.fit) (library("censReg") 
> >  gives a different result than my partial effect at the average. 
> > 
> > Any ideas about what I did wrong? 
> > I  did not find the underlying code of margEff.
> 
> [...] 
> 
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code. 
> 
> Please follow the posting guide and provide a self-contained 
> reproducible example. 
> 
> Best regards, 
> Arne 
> 
> -- 
> Arne Henningsen 
> http://www.arne-henningsen.name
> 
> ______________________________________________ 
> [hidden email] mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code. 
> 
> 
> If you reply to this email, your message will be added to the discussion below:
> http://r.789695.n4.nabble.com/PEA-and-APE-Tobit-tp4703856p4703915.html
> To unsubscribe from PEA and APE Tobit, click here.
> NAML




--
View this message in context: http://r.789695.n4.nabble.com/PEA-and-APE-Tobit-tp4703856p4703919.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Fri Feb 27 00:24:26 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 26 Feb 2015 18:24:26 -0500
Subject: [R] get_map in ggplot doesn't allow the exact specification of my
	box's corners?
Message-ID: <CAN2xGJaV0xMr8z_kbdcj+BWRgsLrVUjxutXawbNTspQgYjc64w@mail.gmail.com>

Hello!

get_map help says:

location: an address, longitude/latitude pair (in that order), or
left/bottom/right/top bounding box

My code:

library(ggmap)
library(mapproj)

lat_bottom = 52.33  # bottom latitude of Berlin
lat_top    = 52.5   # top latitude of Berlin
lon_left   = 13.0   # left longitude of Berlin
lon_rigth  = 13.95  # right longitude of Berlin

mymap <- get_map(location = c(lon_left,lat_bottom,lon_rigth,lat_top),
source="google")
ggmap(mymap)

Why is it giving me a warning:
Warning: bounding box given to google - spatial extent only approximate.
converting bounding box to center/zoom specification. (experimental)

Does it mean that there is no way for me to create a map with these
exact corners?


Thank you!

-- 
Dimitri Liakhovitski


From hwborchers at gmail.com  Fri Feb 27 04:16:05 2015
From: hwborchers at gmail.com (Hans W Borchers)
Date: Fri, 27 Feb 2015 04:16:05 +0100
Subject: [R] integrate with vector arguments
Message-ID: <CAML4n3MeW1cO=Czz_mv5SDyJdfQvYAJ7eaVDLdO=zeXCBvTacA@mail.gmail.com>

marKo <mtoncic <at> ffri.hr> writes:
>
> I'm a bit stuck.
> I have to integrate a series of polynomial functions with vector
> arguments.
>
> v1<-c(1:5)
> v2<-c(1:5)
>
> f1<-function (x) {v1*x+v2*x^2}
>
> The problem is that integrate(f1, 0, 1) does not work.


The point is not that there are "vector arguments", but that your function
is vector-valued and so the generated error message below rightly says
"evaluation of function gave a result of wrong length".

You could integrate each dimension separately or, e.g., you use quadv()
from package 'pracma' which handles vector-valued functions:

    > v1 <- v2 <- 1:5
    > f1<-function (x) {v1*x+v2*x^2}

    > library(pracma)
    > quadv(f1, 0, 1, tol=1e-10)
    $Q
    [1] 0.8333333 1.6666667 2.5000000 3.3333333 4.1666667

    $fcnt
    [1] 13

    $estim.prec
    [1] 0.0000000003

quadv() employs an adaptive Simpson quadrature where the recursion is
applied to all components at once.


> I does not, even if a pas the arguments (v1, v2)
>
> f1<-function (x, v1, v2) {v1*x+v2*x^2}
>
> or if i try to vectorize the function
>
> f1<-Vectorize(function(x, v1, v2){v1*x+v2*x^2},
> vectorize.args=c("v1", "v2"))
>
> integrate(f1, 0, 1) gives an error:
>
> Error in integrate(f1, 0, 1) :
>   evaluation of function gave a result of wrong length
>
> Any help will be greatly appreciated.
> Thanks,
>
> Marko
>


From dwinsemius at comcast.net  Fri Feb 27 06:26:40 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 27 Feb 2015 00:26:40 -0500
Subject: [R] Saving Mean Relative Difference from all.equal()
In-Reply-To: <1424977343790-4703908.post@n4.nabble.com>
References: <1424975522410-4703905.post@n4.nabble.com>
	<1424977343790-4703908.post@n4.nabble.com>
Message-ID: <C5100D30-F0F9-47AC-A936-8A60EF46DC09@comcast.net>


> On Feb 26, 2015, at 2:02 PM, Scott Colwell <scolwell at uoguelph.ca> wrote:
> 
> I think I have one solution. Not very pretty though. Relies on the text not
> changing at all.
> 
> as.numeric(gsub("Mean relative difference: ", "",
> all.equal(cov2cor(ITEMCOV),cor(item.data))[2]))
> 
> Is there a better way?
> 

`all.equal` is a generic function and it appears you are interested in `all.equal.numeric`. Not sure if it?s ?better? but you could fairly easily hack the all.equal.numeric function to replace this code (near the end of the function code) :

if (is.na(xy) || xy > tolerance) 
        msg <- c(msg, paste("Mean", what, "difference:", format(xy)))

,,, with:

if (is.na(xy) || xy > tolerance) 
        msg <-  xy

(probably best to make it have a different name and not use 'all.equal' to name it.)

When it did that I got this as a result:

> all.EQ( seq(1,2, by=0.1)*10, 10:20)
[1] TRUE
> all.EQ( seq(1,2, by=0.11)*10, 10:20)
[1] "Numeric: lengths (10, 11) differ"
> all.EQ(seq(1,2, by=0.11)*10, 10:19)
[1] 0.03225806

? 


David Winsemius, MD
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Feb 27 06:49:45 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 27 Feb 2015 00:49:45 -0500
Subject: [R] integrate with vector arguments
In-Reply-To: <54EF6AAD.5000105@ffri.hr>
References: <54EF6AAD.5000105@ffri.hr>
Message-ID: <39652188-1C0F-473C-B846-8B0C5BA421C6@comcast.net>


> On Feb 26, 2015, at 1:49 PM, marKo <mtoncic at ffri.hr> wrote:
> 
> v1<-c(1:5)
> v2<-c(1:5)
> 
> f1<-function (x) {v1*x+v2*x^2}
> 
> The problem is that integrate(f1, 0, 1) does not work.
> I does not, even if a pas the arguments (v1, v2)
> 
> f1<-function (x, v1, v2) {v1*x+v2*x^2}
> 
> or if i try to vectorize the function
> 
> f1<-Vectorize(function(x, v1, v2){v1*x+v2*x^2},
> vectorize.args=c("v1", "v2"))
> 
> integrate(f1, 0, 1) gives an error:


> f1<-function (X, Y) integrate( function(x) {X*x+Y*x^2}, 0, 1)$value
> fV<-Vectorize(f1)
> outer( X=v1,Y=v2, FUN= fV)
          [,1]     [,2] [,3]     [,4]     [,5]
[1,] 0.8333333 1.166667  1.5 1.833333 2.166667
[2,] 1.3333333 1.666667  2.0 2.333333 2.666667
[3,] 1.8333333 2.166667  2.5 2.833333 3.166667
[4,] 2.3333333 2.666667  3.0 3.333333 3.666667
[5,] 2.8333333 3.166667  3.5 3.833333 4.166667

? 
David Winsemius, MD
Alameda, CA, USA


From elmoryl at gmail.com  Thu Feb 26 20:03:22 2015
From: elmoryl at gmail.com (Luke Moryl)
Date: Thu, 26 Feb 2015 11:03:22 -0800
Subject: [R] Rscript silent failures with unmatched brackets
Message-ID: <CADNJAi=TivFJB2b8ekBFp+LfykE3JtH1cBwNMHek774LuKouKw@mail.gmail.com>

Hi all,

I?ve noticed that a script with unmatched brackets of any sort will fail
silently in Rscript?neither logging nor any output in the shell indicates
that anything went wrong. Example file to run in Rscript:

sink('/tmp/exampleoutfile')
a <- 0
{
  print(a)

Replacing the ?{? with any other symbol that must be matched (quotes,
parens, etc.) results in the same kind of silent failure. One workaround is
to use

echo "source('myscript.R')" | R --no-save --no-restore

from the command line but that?s a kludge. My apologies if this has been
brought up before, but doing a quick search I didn?t find anything, and to
me this seems like a significant bug.

Thanks & best,
Luke
?

	[[alternative HTML version deleted]]


From dmck at u.washington.edu  Thu Feb 26 22:11:32 2015
From: dmck at u.washington.edu (Don McKenzie)
Date: Thu, 26 Feb 2015 13:11:32 -0800
Subject: [R] Summing certain values within columns that satisfy a
	certain condition
In-Reply-To: <CAE6QMsbpTgDX=b-tegcahURbSjANQaXtxxoDPxzZER3nUU5ffw@mail.gmail.com>
References: <CAE6QMsbpTgDX=b-tegcahURbSjANQaXtxxoDPxzZER3nUU5ffw@mail.gmail.com>
Message-ID: <205DAF49-C849-4A91-9CCC-8D201FCEB020@u.washington.edu>

Kate ? here is a transparent solution (tested but without NA treatment). Doubtless there are cleverer faster ones, which later posters will present.

HTH

# example with four columns and 20 rows
nrows <- 20

A <- sample(c(1:100), nrows, replace=T)
B <- sample(c(1:100), nrows, replace=T)
C <- sample(c(1:100), nrows, replace=T)
D <- sample(c(1:100), nrows, replace=T)

locs <- c(c(1:nrows)[A==max(A)],c(1:nrows)[B==max(B)],c(1:nrows)[C==max(C)],c(1:nrows)[D==max(D)])

mat1 <- matrix(rep(0,4*nrows),nrows,4)
for (i in 1:4)
	mat1[,i][locs[i]] <- 1
SUM <- rowSums(mat1)


> On Feb 26, 2015, at 12:23 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> 
> Hi,
> 
> Supposed I had a data frame like so:
> 
> A B C D
> 0 1 0 7
> 0 2 0 7
> 0 3 0 7
> 0 4 0 7
> 0 1 0 0
> 0 0 0 0
> 0 0 0 0
> 0 0 0 0
> 0 0 1 5
> 0 5 1 5
> 0 4 1 5
> 0 8 4 7
> 0 0 3 0
> 0 0 3 4
> 0 0 3 4
> 0 0 0 5
> 0 2 0 6
> 0 0 4 0
> 0 0 4 0
> 0 0 4 0
> 
> For each row, I want to count how many max column values appear to
> adventurely get the following outcome, while ignoring zeros and N/As:
> 
> A B C D Sum
> 0 1 0 7 1
> 0 2 0 7 1
> 0 3 0 7 1
> 0 4 0 7 1
> 0 1 0 0 0
> 0 0 0 0 0
> 0 0 0 0 0
> 0 0 0 0 0
> 0 0 1 5 0
> 0 5 1 5 0
> 0 4 1 5 0
> 0 8 4 7 3
> 0 0 3 0 0
> 0 0 3 4 0
> 0 0 3 4 0
> 0 0 0 5 0
> 0 2 0 6 0
> 0 0 4 0 1
> 0 0 4 0 1
> 0 0 4 0 1
> 
> I've used the following code but it doesn't seem to work (my sum
> column column is all 1s):
> 
> (apply(df,1, function(x)  (sum(x %in% c(pmax(x))))))
> 
> Is this code too simple?
> 
> Thanks!
> 
> K.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




From grigorios.georgolopoulos at ebc.uu.se  Thu Feb 26 23:21:50 2015
From: grigorios.georgolopoulos at ebc.uu.se (Grigorios Georgolopoulos)
Date: Thu, 26 Feb 2015 23:21:50 +0100
Subject: [R]  lmerTest - difflsmeans: LS means for Post-hoc analysis
Message-ID: <54EF9C7E.3050506@ebc.uu.se>

Dear fellow R users,

I am trying to calculate the difference of the least square means from a 
lmer model which has a pretty much standard form of  Y ~ A*B + (1|C/D)

I am using the difflsmeans command from the lmerTest package but it 
returns the following error line:

Error in as.data.frame.default(VarCorr(model)) :
   cannot coerce class ""VarCorr.merMod"" to a data.frame

I also tried to do it manually but apparently to no avail.

I am using the lme4 v. 1.0-6 package on Linux  (if that helps).

Any suggestions how to override this?



Thanks in advance!
Grigorios

-- 
__________________________________
Grigorios Georgolopoulos
Research Assistant
Animal Ecology
Department of Ecology and Genetics (IEG)
Evolutionary Biology Centre (EBC)
Uppsala University
Norbyv?gen 18d, SE-752 36
Uppsala, Sweden
Email: georgolopoulosggreg at hotmail.com, grigorios.georgolopoulos at ebc.uu.se


From js.huang at protective.com  Fri Feb 27 01:25:56 2015
From: js.huang at protective.com (JS Huang)
Date: Thu, 26 Feb 2015 16:25:56 -0800 (PST)
Subject: [R] integrate with vector arguments
In-Reply-To: <54EF6AAD.5000105@ffri.hr>
References: <54EF6AAD.5000105@ffri.hr>
Message-ID: <1424996756562-4703925.post@n4.nabble.com>

Hi,

  The following works.

> f2
function(z)
{
  f1 <- function(t)
  {
    z*t + z*t^2
  }
  return(f1)
}
> sapply(1:5,function(x)integrate(f2(x),0,1)$value)
[1] 0.8333333333 1.6666666667 2.5000000000 3.3333333333 4.1666666667



--
View this message in context: http://r.789695.n4.nabble.com/integrate-with-vector-arguments-tp4703906p4703925.html
Sent from the R help mailing list archive at Nabble.com.


From macfire at gmail.com  Thu Feb 26 20:40:23 2015
From: macfire at gmail.com (macfire)
Date: Thu, 26 Feb 2015 16:40:23 -0300
Subject: [R] Schedule R function/Code to run at specific time
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686CF3AE4B4@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686CF3AE4B4@DC1VEX10MB001.air.org>
Message-ID: <CAJh2N8DdMb_qVCw-D2+gHmAX+c4_J1wzw9rW7K+rEHbHKpbsgQ@mail.gmail.com>

I have a problem with statistics, I think this forum is not the right
option, but I'm running out resolution to my problem, so I thought I expose
you here so someone could help me.
Realized a certain amount of tests in different groups, this assessment had
different weights, and the groups were formed by the different amount of
people. I thought of calculating the average to see how much each person
contributed to the total amount of the assessment. What I would like to
know if there is another way I use the absolute number and the average for
quantifying group was better.
Table

 Group

Absolute Points

Unit

Average

A

700

35

20

B

500

20

25

C

900

150

6

D

300

10

30

Att..
Mestre. Marcelo Alves Costa
Grupo de Estudo e Pesquisa em Desenvolvimento e Aprendizagem Motora
(GEPEDAM)
Centro Universit?rio Filad?lfia
(43) 9646-1071


2015-02-26 16:08 GMT-03:00 Doran, Harold <HDoran at air.org>:

> Is there functionality within R proper, without having to revert to the
> OS, allowing a function or a portion of an R script to be run at a defined
> time? My google searches haven't provided much other than one at the link
> below which relies on an OS.
>
> Thanks,
> Harold
>
> https://tgmstat.wordpress.com/2013/09/11/schedule-rscript-with-cron/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Feb 27 08:16:31 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 27 Feb 2015 20:16:31 +1300
Subject: [R] Schedule R function/Code to run at specific time
In-Reply-To: <CAJh2N8DdMb_qVCw-D2+gHmAX+c4_J1wzw9rW7K+rEHbHKpbsgQ@mail.gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686CF3AE4B4@DC1VEX10MB001.air.org>
	<CAJh2N8DdMb_qVCw-D2+gHmAX+c4_J1wzw9rW7K+rEHbHKpbsgQ@mail.gmail.com>
Message-ID: <54F019CF.30804@auckland.ac.nz>


What ***on earth does the content of your message have to do with the 
subject line?

Get your <expletive deleted> act together if you want to ask a question 
of this list!!!

cheers,

Rolf Turner


On 27/02/15 08:40, macfire wrote:
> I have a problem with statistics, I think this forum is not the right
> option, but I'm running out resolution to my problem, so I thought I expose
> you here so someone could help me.
> Realized a certain amount of tests in different groups, this assessment had
> different weights, and the groups were formed by the different amount of
> people. I thought of calculating the average to see how much each person
> contributed to the total amount of the assessment. What I would like to
> know if there is another way I use the absolute number and the average for
> quantifying group was better.
> Table
>
>   Group
>
> Absolute Points
>
> Unit
>
> Average
>
> A
>
> 700
>
> 35
>
> 20
>
> B
>
> 500
>
> 20
>
> 25
>
> C
>
> 900
>
> 150
>
> 6
>
> D
>
> 300
>
> 10
>
> 30

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From statistics84 at hotmail.com  Fri Feb 27 08:19:37 2015
From: statistics84 at hotmail.com (pari hesabi)
Date: Fri, 27 Feb 2015 07:19:37 +0000
Subject: [R] mle
Message-ID: <DUB125-W632FA0232A44B42E4F5F4BC6150@phx.gbl>

Hello,
I am going to estimate the parameter of the count model: pr(N=n)= integration{B(x, alpha)-C(x,alpha)} by maximum likelihood estimation.?
n<-c(0,1,2,3) ? and ? F<- (0,3,4,5) are the vectors of values and observed frequency respectively. The function C(x,alpha) is not defined for n=0, but suppose C(x,alpha)=1 when n=0. ?When I want to insert this exception in the following loop, I don't receive reasonable estimate.
pari (alpha){
nloglik<- function(alpha){
B<-function(x,k){........}
C<-function(x,k){........}
A<-function(x){
s<-rep(0,length(x))
s<-s+ C(x,k)?
s<- s+B(x,k)?
}
s
}
d<-0
for (n in seq(along=F)){
?lik<-integrate(A,0,1)$value
d<- d - F[n]*log(lik)}}
d?}
F<-??(0,3,4,5)
n<-length(F)
mle (nloglik, start=list(alpha=alpha)
} ? ??
This program gives the answer when n= 1,2,3. But for n=0 I get error, I have to consider the exception :?C(x,alpha)=1. ?
Does anybody know where I need to put the exception in the program? ( For 'if' loops, I don't get reasonable results)?
I would appreciate any help
Best Regards,??
?? ?

 		 	   		  

From mtoncic at ffri.hr  Fri Feb 27 10:49:26 2015
From: mtoncic at ffri.hr (marKo)
Date: Fri, 27 Feb 2015 10:49:26 +0100
Subject: [R] integrate with vector arguments
In-Reply-To: <39652188-1C0F-473C-B846-8B0C5BA421C6@comcast.net>
References: <54EF6AAD.5000105@ffri.hr>
	<39652188-1C0F-473C-B846-8B0C5BA421C6@comcast.net>
Message-ID: <54F03DA6.2030308@ffri.hr>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Gee. That simple. I knew that!
Thanks a lot.
Essentially, I needed only the diagonal elements.
Easily solved by:

diag(outer( X=v1,Y=v2, FUN= fV)

I am sure that there are simpler options, but that works like a charm.

Thanks a lot.

Cheers,

Marko



On 02/27/2015 06:49 AM, David Winsemius wrote:
> 
>> On Feb 26, 2015, at 1:49 PM, marKo <mtoncic at ffri.hr> wrote:
>>
>> v1<-c(1:5)
>> v2<-c(1:5)
>>
>> f1<-function (x) {v1*x+v2*x^2}
>>
>> The problem is that integrate(f1, 0, 1) does not work.
>> I does not, even if a pas the arguments (v1, v2)
>>
>> f1<-function (x, v1, v2) {v1*x+v2*x^2}
>>
>> or if i try to vectorize the function
>>
>> f1<-Vectorize(function(x, v1, v2){v1*x+v2*x^2},
>> vectorize.args=c("v1", "v2"))
>>
>> integrate(f1, 0, 1) gives an error:
> 
> 
>> f1<-function (X, Y) integrate( function(x) {X*x+Y*x^2}, 0, 1)$value
>> fV<-Vectorize(f1)
>> outer( X=v1,Y=v2, FUN= fV)
>           [,1]     [,2] [,3]     [,4]     [,5]
> [1,] 0.8333333 1.166667  1.5 1.833333 2.166667
> [2,] 1.3333333 1.666667  2.0 2.333333 2.666667
> [3,] 1.8333333 2.166667  2.5 2.833333 3.166667
> [4,] 2.3333333 2.666667  3.0 3.333333 3.666667
> [5,] 2.8333333 3.166667  3.5 3.833333 4.166667
> 
> ? 
> David Winsemius, MD
> Alameda, CA, USA
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQIcBAEBAgAGBQJU8D2hAAoJEJcj4KySkkQsblsQAK2cpOG/qsrXP6vK9Zq3UMkc
6jNQ9PQqvT1H8WyR8rNTY1Bis7npxgNh0avRYOrsRf1D3u9frNjBAhT2v0mMW+Uk
LRvHpER1EnIZhdFcmE7uOUNsaU/IquicVVWAXgVVu2/yUW8nJZ4FQ2wkKDLlTY97
dyNMj5i1r5DWBtfUbCtTiSJz1G16DXiJBsk0Zi1Z9zT71evOh2tIfztv1qSSTOLJ
gjWbpefYThypPq/170+Eqv3BOigjQd1ljeyXVgGrs/vMTX6a9ZL5KDUYsR7QnhmH
ZiHNUTcUpAFb3QGLNVM6ULd7GfzDKgG7rH8JwokYzi/IIsm5aTNfY7dUCGySx+dL
4tOQKe6LjFGIfqPHeZXXs1ErYrIs7L//z+n9ZfHKT0RH7zAoakrzkvFxsBx2LU7z
Wziv3/eMN65WOPFpH2puaUQrandbmpDujuZS0PfGBc5/hrIpeCejm7LfHocck6MT
v+J4o05+a3jMSdZdtbNXv6q5z+tXaEdThKz77VmFwMQWzFto8QFbe5dOKP9EO6Vn
9+u0gSswtE43PXkn3Egj6HmhrTkREc3lnHsh/0E32+g4UsWxVlyLvfCrm9s4zKOZ
fGjIpaUPUp2AkNGAa8BhLqO6LJVaU2/wCvcYIRAbv1Uck2XK9lppKsvFEUuRz9Uk
kPaGAS9OJgsUS8kMVpMf
=v7j4
-----END PGP SIGNATURE-----


From ronflatau at gmail.com  Fri Feb 27 12:19:04 2015
From: ronflatau at gmail.com (Ron Flatau)
Date: Fri, 27 Feb 2015 13:19:04 +0200
Subject: [R] =?utf-8?q?retrieving_protein_for_swissport=E2=80=8F?=
Message-ID: <CADzHNWHWbOL=p8RBiXZntB2HFnERbUiAjNBZPeiCacD6gMZtJQ@mail.gmail.com>

I Try to run this script on order to get all the protein named Delta 9 acyl
CoA desaturase.

library(seqinr)
choosebank("swissprot")
D9aCd <- query("Delta 9 acyl-CoA desaturase","KD=Delta 9 acyl-CoA
desaturase")

Nothing happen....

i be glad to know what i do wrong...

Thnks

	[[alternative HTML version deleted]]


From alaios at yahoo.com  Fri Feb 27 13:58:29 2015
From: alaios at yahoo.com (Alaios)
Date: Fri, 27 Feb 2015 12:58:29 +0000 (UTC)
Subject: [R] Save a list of list and search for values
In-Reply-To: <CAAxdm-7u++3iUjhOO+iOj7cXsn-_akxM8M1oPqauE+EMBD8Hgw@mail.gmail.com>
References: <CAAxdm-7u++3iUjhOO+iOj7cXsn-_akxM8M1oPqauE+EMBD8Hgw@mail.gmail.com>
Message-ID: <1841953896.1103301.1425041909878.JavaMail.yahoo@mail.yahoo.com>

Hi,thanks all for the answer.I am using mclapply to call the lapply many times as needed. My function returns only a value if the fit is succesful.For testing if the fit is sucessfuly my code works like that
fitcass1<-tryCatch(mix(mixdat=mydataOnVector,mixpar=params,dist=distribution),error=function(e) list(e,"Error"))
if (fitcass1[[2]]=="Error"){
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ? print(sprintf("error at fitting gamma distribution with %s periods. Mean %f %f Sd %f %f",flag,mean1,mean2,sd1,sd2))

??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? }else{ 
(code trunctated)... where I do some plots

so at the end of the function the code looks like
if (fitcass1[[2]]!="Error")
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? return(fitcass1)

then I am calling the function above with
keeptheBigListAsJimSuggested<-mclapply(expandMeanSigmaOn_list,callFunctionAbove,mydataOnVector=mydataOnVector,filename=filename,mc.cores=64)

If I am not wrong that would work. I will try later after my code stops executing. 
Any more comments on this?
RegardsAlex

 

     On Thursday, February 26, 2015 3:39 PM, jim holtman <jholtman at gmail.com> wrote:
   

 You store it as a list of lists and can then use the lapply function
to navigate for values.

result <- lapply(1:10000, function(x){
? ? mix(param[x])? # whatever your call to 'mix' is with some data
})





Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Thu, Feb 26, 2015 at 9:27 AM, Alaios via R-help <r-help at r-project.org> wrote:
> Dear all,in my code I am using the mix() function that returns results in a list. The result looks like
> List of 10
>? $ parameters? :'data.frame':? 2 obs. of? 3 variables:
>? ..$ pi? : num [1:2] 0.77 0.23
>? ..$ mu? : num [1:2] -7034 162783
>? ..$ sigma: num [1:2] 20235 95261
>? $ se? ? ? ? ? :'data.frame':? 2 obs. of? 3 variables:
>? ..$ pi.se? : num [1:2] 0.0423 0.0423
>? ..$ mu.se? : num [1:2] 177 12422
>? ..$ sigma.se: num [1:2] 1067 65551
>? $ distribution: chr "norm"
>? $ constraint? :List of 8
>? ..$ conpi? : chr "NONE"
>? ..$ conmu? : chr "NONE"
>? ..$ consigma: chr "NONE"
>? ..$ fixpi? : NULL
>? ..$ fixmu? : NULL
>? ..$ fixsigma: NULL
>? ..$ cov? ? : NULL
>? ..$ size? ? : NULL
>? $ chisq? ? ? : num 28
>? $ df? ? ? ? ? : num 5
>? $ P? ? ? ? ? : num 3.67e-05
>? $ vmat? ? ? ? : num [1:5, 1:5] 1.79e-03 -3.69e-01 -1.17e+02 2.95e+01 -2.63e+03 ...
>? $ mixdata? ? :Classes ?mixdata? and 'data.frame':? ? 11 obs. of? 2 variables:
>? ..$ X? ? : num [1:11] 1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
>? ..$ count: int [1:11] 993 137 82 30 21 5 7 14 21 2 ...
>? $ usecondit? : logi FALSE
>? - attr(*, "class")= chr "mix"
>
> In my code I am trying around 10.000 fit (and each of these fits returns the list above) and I want to keep those in a way that later on I would be able to search inside all the lists.For example I would like to find inside those 10.000 lists which one has the smallest $chisq value. What would be a suitable way to implement that in R? Luckily I am working in a computer with a lot of ram so storing 10.000 lists temporary in memory before saving to disk would not be a problem.
> What would you suggest me?
> RegardsAlex
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From alaios at yahoo.com  Fri Feb 27 14:09:47 2015
From: alaios at yahoo.com (Alaios)
Date: Fri, 27 Feb 2015 13:09:47 +0000 (UTC)
Subject: [R] Save a list of list and search for values
In-Reply-To: <1841953896.1103301.1425041909878.JavaMail.yahoo@mail.yahoo.com>
References: <CAAxdm-7u++3iUjhOO+iOj7cXsn-_akxM8M1oPqauE+EMBD8Hgw@mail.gmail.com>
	<1841953896.1103301.1425041909878.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <2064332027.1099228.1425042587710.JavaMail.yahoo@mail.yahoo.com>

Sorry Jim I forgot to reply on what I am trying to do.I? have many data sets that contain some numbers: I am trying to fit those with a mixture distribution. For that I am using the mix function that returns me back the fitted parameters and the chi square (which is a first performance indicator).After all the fits are completed and gathered on the big list, I would like to see which are the fits with the better chi square numbers and what are their typical numbers. After I see that results I would have to think more on how to proceed
RegardsAlex
 

     On Friday, February 27, 2015 1:58 PM, Alaios <alaios at yahoo.com> wrote:
   

 Hi,thanks all for the answer.I am using mclapply to call the lapply many times as needed. My function returns only a value if the fit is succesful.For testing if the fit is sucessfuly my code works like that
fitcass1<-tryCatch(mix(mixdat=mydataOnVector,mixpar=params,dist=distribution),error=function(e) list(e,"Error"))
if (fitcass1[[2]]=="Error"){
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ? print(sprintf("error at fitting gamma distribution with %s periods. Mean %f %f Sd %f %f",flag,mean1,mean2,sd1,sd2))

??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ??? }else{ 
(code trunctated)... where I do some plots

so at the end of the function the code looks like
if (fitcass1[[2]]!="Error")
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? return(fitcass1)

then I am calling the function above with
keeptheBigListAsJimSuggested<-mclapply(expandMeanSigmaOn_list,callFunctionAbove,mydataOnVector=mydataOnVector,filename=filename,mc.cores=64)

If I am not wrong that would work. I will try later after my code stops executing. 
Any more comments on this?
RegardsAlex

 

     On Thursday, February 26, 2015 3:39 PM, jim holtman <jholtman at gmail.com> wrote:
   

 You store it as a list of lists and can then use the lapply function
to navigate for values.

result <- lapply(1:10000, function(x){
? ? mix(param[x])? # whatever your call to 'mix' is with some data
})





Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Thu, Feb 26, 2015 at 9:27 AM, Alaios via R-help <r-help at r-project.org> wrote:
> Dear all,in my code I am using the mix() function that returns results in a list. The result looks like
> List of 10
>? $ parameters? :'data.frame':? 2 obs. of? 3 variables:
>? ..$ pi? : num [1:2] 0.77 0.23
>? ..$ mu? : num [1:2] -7034 162783
>? ..$ sigma: num [1:2] 20235 95261
>? $ se? ? ? ? ? :'data.frame':? 2 obs. of? 3 variables:
>? ..$ pi.se? : num [1:2] 0.0423 0.0423
>? ..$ mu.se? : num [1:2] 177 12422
>? ..$ sigma.se: num [1:2] 1067 65551
>? $ distribution: chr "norm"
>? $ constraint? :List of 8
>? ..$ conpi? : chr "NONE"
>? ..$ conmu? : chr "NONE"
>? ..$ consigma: chr "NONE"
>? ..$ fixpi? : NULL
>? ..$ fixmu? : NULL
>? ..$ fixsigma: NULL
>? ..$ cov? ? : NULL
>? ..$ size? ? : NULL
>? $ chisq? ? ? : num 28
>? $ df? ? ? ? ? : num 5
>? $ P? ? ? ? ? : num 3.67e-05
>? $ vmat? ? ? ? : num [1:5, 1:5] 1.79e-03 -3.69e-01 -1.17e+02 2.95e+01 -2.63e+03 ...
>? $ mixdata? ? :Classes ?mixdata? and 'data.frame':? ? 11 obs. of? 2 variables:
>? ..$ X? ? : num [1:11] 1e+04 2e+04 3e+04 4e+04 5e+04 6e+04 7e+04 8e+04 9e+04 1e+05 ...
>? ..$ count: int [1:11] 993 137 82 30 21 5 7 14 21 2 ...
>? $ usecondit? : logi FALSE
>? - attr(*, "class")= chr "mix"
>
> In my code I am trying around 10.000 fit (and each of these fits returns the list above) and I want to keep those in a way that later on I would be able to search inside all the lists.For example I would like to find inside those 10.000 lists which one has the smallest $chisq value. What would be a suitable way to implement that in R? Luckily I am working in a computer with a lot of ram so storing 10.000 lists temporary in memory before saving to disk would not be a problem.
> What would you suggest me?
> RegardsAlex
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

    

   
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Feb 27 14:46:27 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 27 Feb 2015 08:46:27 -0500
Subject: [R] integrate with vector arguments
In-Reply-To: <54F03DA6.2030308@ffri.hr>
References: <54EF6AAD.5000105@ffri.hr>
	<39652188-1C0F-473C-B846-8B0C5BA421C6@comcast.net>
	<54F03DA6.2030308@ffri.hr>
Message-ID: <12B9E228-65CD-4BB2-BF00-F25C862413CA@comcast.net>


> On Feb 27, 2015, at 4:49 AM, marKo <mtoncic at ffri.hr> wrote:
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> Gee. That simple. I knew that!
> Thanks a lot.
> Essentially, I needed only the diagonal elements.
> Easily solved by:
> 
> diag(outer( X=v1,Y=v2, FUN= fV)
> 
> I am sure that there are simpler options, but that works like a charm.

If I had understood that you wanted only the values with v1 and v2 paired, then I would have suggested using apply:

> mapply(fV, v1, v2)
[1] 0.8333333 1.6666667 2.5000000 3.3333333 4.1666667

? 
David.
> 
> Thanks a lot.
> 
> Cheers,
> 
> Marko
> 
> 
> 
> On 02/27/2015 06:49 AM, David Winsemius wrote:
>> 
>>> On Feb 26, 2015, at 1:49 PM, marKo <mtoncic at ffri.hr> wrote:
>>> 
>>> v1<-c(1:5)
>>> v2<-c(1:5)
>>> 
>>> f1<-function (x) {v1*x+v2*x^2}
>>> 
>>> The problem is that integrate(f1, 0, 1) does not work.
>>> I does not, even if a pas the arguments (v1, v2)
>>> 
>>> f1<-function (x, v1, v2) {v1*x+v2*x^2}
>>> 
>>> or if i try to vectorize the function
>>> 
>>> f1<-Vectorize(function(x, v1, v2){v1*x+v2*x^2},
>>> vectorize.args=c("v1", "v2"))
>>> 
>>> integrate(f1, 0, 1) gives an error:
>> 
>> 
>>> f1<-function (X, Y) integrate( function(x) {X*x+Y*x^2}, 0, 1)$value
>>> fV<-Vectorize(f1)
>>> outer( X=v1,Y=v2, FUN= fV)
>>          [,1]     [,2] [,3]     [,4]     [,5]
>> [1,] 0.8333333 1.166667  1.5 1.833333 2.166667
>> [2,] 1.3333333 1.666667  2.0 2.333333 2.666667
>> [3,] 1.8333333 2.166667  2.5 2.833333 3.166667
>> [4,] 2.3333333 2.666667  3.0 3.333333 3.666667
>> [5,] 2.8333333 3.166667  3.5 3.833333 4.166667
>> 
>> ? 
>> David Winsemius, MD
>> Alameda, CA, USA
>> 
> 
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1
> 
> iQIcBAEBAgAGBQJU8D2hAAoJEJcj4KySkkQsblsQAK2cpOG/qsrXP6vK9Zq3UMkc
> 6jNQ9PQqvT1H8WyR8rNTY1Bis7npxgNh0avRYOrsRf1D3u9frNjBAhT2v0mMW+Uk
> LRvHpER1EnIZhdFcmE7uOUNsaU/IquicVVWAXgVVu2/yUW8nJZ4FQ2wkKDLlTY97
> dyNMj5i1r5DWBtfUbCtTiSJz1G16DXiJBsk0Zi1Z9zT71evOh2tIfztv1qSSTOLJ
> gjWbpefYThypPq/170+Eqv3BOigjQd1ljeyXVgGrs/vMTX6a9ZL5KDUYsR7QnhmH
> ZiHNUTcUpAFb3QGLNVM6ULd7GfzDKgG7rH8JwokYzi/IIsm5aTNfY7dUCGySx+dL
> 4tOQKe6LjFGIfqPHeZXXs1ErYrIs7L//z+n9ZfHKT0RH7zAoakrzkvFxsBx2LU7z
> Wziv3/eMN65WOPFpH2puaUQrandbmpDujuZS0PfGBc5/hrIpeCejm7LfHocck6MT
> v+J4o05+a3jMSdZdtbNXv6q5z+tXaEdThKz77VmFwMQWzFto8QFbe5dOKP9EO6Vn
> 9+u0gSswtE43PXkn3Egj6HmhrTkREc3lnHsh/0E32+g4UsWxVlyLvfCrm9s4zKOZ
> fGjIpaUPUp2AkNGAa8BhLqO6LJVaU2/wCvcYIRAbv1Uck2XK9lppKsvFEUuRz9Uk
> kPaGAS9OJgsUS8kMVpMf
> =v7j4
> -----END PGP SIGNATURE-----

David Winsemius, MD
Alameda, CA, USA


From mtoncic at ffri.hr  Fri Feb 27 14:49:07 2015
From: mtoncic at ffri.hr (marKo)
Date: Fri, 27 Feb 2015 14:49:07 +0100
Subject: [R] integrate with vector arguments
In-Reply-To: <12B9E228-65CD-4BB2-BF00-F25C862413CA@comcast.net>
References: <54EF6AAD.5000105@ffri.hr>
	<39652188-1C0F-473C-B846-8B0C5BA421C6@comcast.net>
	<54F03DA6.2030308@ffri.hr>
	<12B9E228-65CD-4BB2-BF00-F25C862413CA@comcast.net>
Message-ID: <54F075D3.6090205@ffri.hr>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Yes. That's it.
Thanks, a lot, really.

Marko



On 02/27/2015 02:46 PM, David Winsemius wrote:
> 
>> On Feb 27, 2015, at 4:49 AM, marKo <mtoncic at ffri.hr> wrote:
>> 
> Gee. That simple. I knew that! Thanks a lot. Essentially, I needed
> only the diagonal elements. Easily solved by:
> 
> diag(outer( X=v1,Y=v2, FUN= fV)
> 
> I am sure that there are simpler options, but that works like a
> charm.
> 
>> If I had understood that you wanted only the values with v1 and
>> v2 paired, then I would have suggested using apply:
> 
> mapply(fV, v1, v2)
>> [1] 0.8333333 1.6666667 2.5000000 3.3333333 4.1666667
> 
>> ? David.
> 
> Thanks a lot.
> 
> Cheers,
> 
> Marko
> 
> 
> 
> On 02/27/2015 06:49 AM, David Winsemius wrote:
>>>> 
>>>>> On Feb 26, 2015, at 1:49 PM, marKo <mtoncic at ffri.hr>
>>>>> wrote:
>>>>> 
>>>>> v1<-c(1:5) v2<-c(1:5)
>>>>> 
>>>>> f1<-function (x) {v1*x+v2*x^2}
>>>>> 
>>>>> The problem is that integrate(f1, 0, 1) does not work. I
>>>>> does not, even if a pas the arguments (v1, v2)
>>>>> 
>>>>> f1<-function (x, v1, v2) {v1*x+v2*x^2}
>>>>> 
>>>>> or if i try to vectorize the function
>>>>> 
>>>>> f1<-Vectorize(function(x, v1, v2){v1*x+v2*x^2}, 
>>>>> vectorize.args=c("v1", "v2"))
>>>>> 
>>>>> integrate(f1, 0, 1) gives an error:
>>>> 
>>>> 
>>>>> f1<-function (X, Y) integrate( function(x) {X*x+Y*x^2}, 0,
>>>>> 1)$value fV<-Vectorize(f1) outer( X=v1,Y=v2, FUN= fV)
>>>> [,1]     [,2] [,3]     [,4]     [,5] [1,] 0.8333333 1.166667
>>>> 1.5 1.833333 2.166667 [2,] 1.3333333 1.666667  2.0 2.333333
>>>> 2.666667 [3,] 1.8333333 2.166667  2.5 2.833333 3.166667 [4,]
>>>> 2.3333333 2.666667  3.0 3.333333 3.666667 [5,] 2.8333333
>>>> 3.166667  3.5 3.833333 4.166667
>>>> 
>>>> ? David Winsemius, MD Alameda, CA, USA
>>>> 
> 
> 
> David Winsemius, MD Alameda, CA, USA
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iQIcBAEBAgAGBQJU8HXQAAoJEJcj4KySkkQsDMUP/i2vCLuf21yrMIFotBehOcF8
XpN3gRWAvRAe9Thd4mpIzSj+5woQLJH/Rp8bF2ClXh0HaO3j62fn+RGJeKBEDS0g
gxqkPFapm0ug6qEIYHvguHVLTMuAEWgzU+fpTY955jAwOYvrkHfWJ9XGqfik7R1o
jBfbquq/4kyUqur1iBsHp4RZXkXEUfuk5lLPv03Tl7B6TOift0M/yJf5PAzi0VvY
2jhDpAvSJ6JSjwx+R+xnDkXhkSNMQAoiZuabuwVbD9dqA7T5dxreieAbu+YcUo4E
FF96A6G7gfIgneCdX3i/2i632MjTfDTe1eDB5YYATf5GnmzYB1K0ZH6Egr6sB4/7
/0wvObJHWJfc5qZQpqJyk8mEy54Igm/jko75yaQ7EIHWbDEcm30AyC0b0/7qTels
w2Tie3T4KvnjfSaPSz65AW7ip8bWYy3QpgNTzpQEn1zNjWSJ3lQYOOvWwFhr67YN
axft3nHRpthOUWk5lZgLJ5Nmx0ILB/NxYIh/nj2uUypsYYvvMNqKTg+QRNEICm51
bace0rfvPTl4UaCCrtFtydN7awv8/weRCMqUtSZccxZ9Hvkli6inIWH0WDK9/xg3
HxPgv8BEF9wJtfHa8HWtDEG7pqUT5byhd3UVtxSkH+RYZl9iGu/Vat/a3Ikj+6Lb
i9lIjaTylqlAy//m4S/Q
=EH2y
-----END PGP SIGNATURE-----


From dimitri.liakhovitski at gmail.com  Fri Feb 27 15:04:29 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 27 Feb 2015 09:04:29 -0500
Subject: [R] Why does R replace all row values with NAs
Message-ID: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>

I know how to get the output I need, but I would benefit from an
explanation why R behaves the way it does.

# I have a data frame x:
x = data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
x
# I want to toss rows in x that contain values >=6. But I don't want
to toss my NAs there.

subset(x,c<6) # Works correctly, but removes NAs in c, understand why
x[which(x$c<6),] # Works correctly, but removes NAs in c, understand why
x[-which(x$c>=6),] # output I need

# Here is my question: why does the following line replace the values
of all rows that contain an NA # in x$c with NAs?

x[x$c<6,]  # Leaves rows with c=NA, but makes the whole row an NA. Why???
x[(x$c<6) | is.na(x$c),] # output I need - I have to be super-explicit

Thank you very much!

-- 
Dimitri Liakhovitski


From murdoch.duncan at gmail.com  Fri Feb 27 15:13:45 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 27 Feb 2015 09:13:45 -0500
Subject: [R] Why does R replace all row values with NAs
In-Reply-To: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>
References: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>
Message-ID: <54F07B99.90005@gmail.com>

On 27/02/2015 9:04 AM, Dimitri Liakhovitski wrote:
> I know how to get the output I need, but I would benefit from an
> explanation why R behaves the way it does.
> 
> # I have a data frame x:
> x = data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
> x
> # I want to toss rows in x that contain values >=6. But I don't want
> to toss my NAs there.
> 
> subset(x,c<6) # Works correctly, but removes NAs in c, understand why
> x[which(x$c<6),] # Works correctly, but removes NAs in c, understand why
> x[-which(x$c>=6),] # output I need
> 
> # Here is my question: why does the following line replace the values
> of all rows that contain an NA # in x$c with NAs?
> 
> x[x$c<6,]  # Leaves rows with c=NA, but makes the whole row an NA. Why???
> x[(x$c<6) | is.na(x$c),] # output I need - I have to be super-explicit
> 
> Thank you very much!

Most of your examples (except the ones using which()) are doing logical
indexing.  In logical indexing, TRUE keeps a line, FALSE drops the line,
and NA returns NA.  Since "x$c < 6" is NA if x$c is NA, you get the
third kind of indexing.

Your last example works because in the cases where x$c is NA, it
evaluates NA | TRUE, and that evaluates to TRUE.  In the cases where x$c
is not NA, you get x$c < 6 | FALSE, and that's the same as x$c < 6,
which will be either TRUE or FALSE.

Duncan Murdoch


From dmck at u.washington.edu  Fri Feb 27 07:42:06 2015
From: dmck at u.washington.edu (Don McKenzie)
Date: Thu, 26 Feb 2015 22:42:06 -0800
Subject: [R] Summing certain values within columns that satisfy a
	certain condition
In-Reply-To: <205DAF49-C849-4A91-9CCC-8D201FCEB020@u.washington.edu>
References: <CAE6QMsbpTgDX=b-tegcahURbSjANQaXtxxoDPxzZER3nUU5ffw@mail.gmail.com>
	<205DAF49-C849-4A91-9CCC-8D201FCEB020@u.washington.edu>
Message-ID: <8E06F658-D56C-4ED9-81FA-207918A286C1@u.washington.edu>

Use Jeff?s solution.  This doesn?t account for ties.

> On Feb 26, 2015, at 1:11 PM, Don McKenzie <dmck at u.washington.edu> wrote:
> 
> Kate ? here is a transparent solution (tested but without NA treatment). Doubtless there are cleverer faster ones, which later posters will present.
> 
> HTH
> 
> # example with four columns and 20 rows
> nrows <- 20
> 
> A <- sample(c(1:100), nrows, replace=T)
> B <- sample(c(1:100), nrows, replace=T)
> C <- sample(c(1:100), nrows, replace=T)
> D <- sample(c(1:100), nrows, replace=T)
> 
> locs <- c(c(1:nrows)[A==max(A)],c(1:nrows)[B==max(B)],c(1:nrows)[C==max(C)],c(1:nrows)[D==max(D)])
> 
> mat1 <- matrix(rep(0,4*nrows),nrows,4)
> for (i in 1:4)
> 	mat1[,i][locs[i]] <- 1
> SUM <- rowSums(mat1)
> 
> 
>> On Feb 26, 2015, at 12:23 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>> 
>> Hi,
>> 
>> Supposed I had a data frame like so:
>> 
>> A B C D
>> 0 1 0 7
>> 0 2 0 7
>> 0 3 0 7
>> 0 4 0 7
>> 0 1 0 0
>> 0 0 0 0
>> 0 0 0 0
>> 0 0 0 0
>> 0 0 1 5
>> 0 5 1 5
>> 0 4 1 5
>> 0 8 4 7
>> 0 0 3 0
>> 0 0 3 4
>> 0 0 3 4
>> 0 0 0 5
>> 0 2 0 6
>> 0 0 4 0
>> 0 0 4 0
>> 0 0 4 0
>> 
>> For each row, I want to count how many max column values appear to
>> adventurely get the following outcome, while ignoring zeros and N/As:
>> 
>> A B C D Sum
>> 0 1 0 7 1
>> 0 2 0 7 1
>> 0 3 0 7 1
>> 0 4 0 7 1
>> 0 1 0 0 0
>> 0 0 0 0 0
>> 0 0 0 0 0
>> 0 0 0 0 0
>> 0 0 1 5 0
>> 0 5 1 5 0
>> 0 4 1 5 0
>> 0 8 4 7 3
>> 0 0 3 0 0
>> 0 0 3 4 0
>> 0 0 3 4 0
>> 0 0 0 5 0
>> 0 2 0 6 0
>> 0 0 4 0 1
>> 0 0 4 0 1
>> 0 0 4 0 1
>> 
>> I've used the following code but it doesn't seem to work (my sum
>> column column is all 1s):
>> 
>> (apply(df,1, function(x)  (sum(x %in% c(pmax(x))))))
>> 
>> Is this code too simple?
>> 
>> Thanks!
>> 
>> K.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




From dimitri.liakhovitski at gmail.com  Fri Feb 27 15:49:17 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 27 Feb 2015 09:49:17 -0500
Subject: [R] Why does R replace all row values with NAs
In-Reply-To: <54F07B99.90005@gmail.com>
References: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>
	<54F07B99.90005@gmail.com>
Message-ID: <CAN2xGJYmhkJmndSBVBL3WD+hEBFVKLhUGDDX_oi2WOQt+uDTiQ@mail.gmail.com>

So, Duncan, do I understand you correctly:

When I use x$x<6, R doesn't know if it's TRUE or FALSE, so it returns
a logical value of NA.
When this logical value is applied to a row, the R says: hell, I don't
know if I should keep it or not, so, just in case, I am going to keep
it, but I'll replace all the values in this row with NAs?

On Fri, Feb 27, 2015 at 9:13 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 27/02/2015 9:04 AM, Dimitri Liakhovitski wrote:
>> I know how to get the output I need, but I would benefit from an
>> explanation why R behaves the way it does.
>>
>> # I have a data frame x:
>> x = data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
>> x
>> # I want to toss rows in x that contain values >=6. But I don't want
>> to toss my NAs there.
>>
>> subset(x,c<6) # Works correctly, but removes NAs in c, understand why
>> x[which(x$c<6),] # Works correctly, but removes NAs in c, understand why
>> x[-which(x$c>=6),] # output I need
>>
>> # Here is my question: why does the following line replace the values
>> of all rows that contain an NA # in x$c with NAs?
>>
>> x[x$c<6,]  # Leaves rows with c=NA, but makes the whole row an NA. Why???
>> x[(x$c<6) | is.na(x$c),] # output I need - I have to be super-explicit
>>
>> Thank you very much!
>
> Most of your examples (except the ones using which()) are doing logical
> indexing.  In logical indexing, TRUE keeps a line, FALSE drops the line,
> and NA returns NA.  Since "x$c < 6" is NA if x$c is NA, you get the
> third kind of indexing.
>
> Your last example works because in the cases where x$c is NA, it
> evaluates NA | TRUE, and that evaluates to TRUE.  In the cases where x$c
> is not NA, you get x$c < 6 | FALSE, and that's the same as x$c < 6,
> which will be either TRUE or FALSE.
>
> Duncan Murdoch
>



-- 
Dimitri Liakhovitski


From murdoch.duncan at gmail.com  Fri Feb 27 16:02:02 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 27 Feb 2015 10:02:02 -0500
Subject: [R] Why does R replace all row values with NAs
In-Reply-To: <CAN2xGJYmhkJmndSBVBL3WD+hEBFVKLhUGDDX_oi2WOQt+uDTiQ@mail.gmail.com>
References: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>	<54F07B99.90005@gmail.com>
	<CAN2xGJYmhkJmndSBVBL3WD+hEBFVKLhUGDDX_oi2WOQt+uDTiQ@mail.gmail.com>
Message-ID: <54F086EA.7020800@gmail.com>

On 27/02/2015 9:49 AM, Dimitri Liakhovitski wrote:
> So, Duncan, do I understand you correctly:
> 
> When I use x$x<6, R doesn't know if it's TRUE or FALSE, so it returns
> a logical value of NA.

Yes, when x$x is NA.  (Though I think you meant x$c.)

> When this logical value is applied to a row, the R says: hell, I don't
> know if I should keep it or not, so, just in case, I am going to keep
> it, but I'll replace all the values in this row with NAs?

Yes.  Indexing with a logical NA is probably a mistake, and this is one
way to signal it without actually triggering a warning or error.

BTW, I should have mentioned that the example where you indexed using
-which(x$c>=6) is a bad idea:  if none of the entries were 6 or more,
this would be indexing with an empty vector, and you'd get nothing, not
everything.

Duncan Murdoch


> 
> On Fri, Feb 27, 2015 at 9:13 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 27/02/2015 9:04 AM, Dimitri Liakhovitski wrote:
>>> I know how to get the output I need, but I would benefit from an
>>> explanation why R behaves the way it does.
>>>
>>> # I have a data frame x:
>>> x = data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
>>> x
>>> # I want to toss rows in x that contain values >=6. But I don't want
>>> to toss my NAs there.
>>>
>>> subset(x,c<6) # Works correctly, but removes NAs in c, understand why
>>> x[which(x$c<6),] # Works correctly, but removes NAs in c, understand why
>>> x[-which(x$c>=6),] # output I need
>>>
>>> # Here is my question: why does the following line replace the values
>>> of all rows that contain an NA # in x$c with NAs?
>>>
>>> x[x$c<6,]  # Leaves rows with c=NA, but makes the whole row an NA. Why???
>>> x[(x$c<6) | is.na(x$c),] # output I need - I have to be super-explicit
>>>
>>> Thank you very much!
>>
>> Most of your examples (except the ones using which()) are doing logical
>> indexing.  In logical indexing, TRUE keeps a line, FALSE drops the line,
>> and NA returns NA.  Since "x$c < 6" is NA if x$c is NA, you get the
>> third kind of indexing.
>>
>> Your last example works because in the cases where x$c is NA, it
>> evaluates NA | TRUE, and that evaluates to TRUE.  In the cases where x$c
>> is not NA, you get x$c < 6 | FALSE, and that's the same as x$c < 6,
>> which will be either TRUE or FALSE.
>>
>> Duncan Murdoch
>>
> 
> 
>


From dimitri.liakhovitski at gmail.com  Fri Feb 27 16:27:17 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 27 Feb 2015 10:27:17 -0500
Subject: [R] Why does R replace all row values with NAs
In-Reply-To: <54F086EA.7020800@gmail.com>
References: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>
	<54F07B99.90005@gmail.com>
	<CAN2xGJYmhkJmndSBVBL3WD+hEBFVKLhUGDDX_oi2WOQt+uDTiQ@mail.gmail.com>
	<54F086EA.7020800@gmail.com>
Message-ID: <CAN2xGJauN=swX6P0WHzH+bsEcobCn24_z0pJWr64D5p-UBwVHg@mail.gmail.com>

Thank you very much, Duncan.
All this being said:

What would you say is the most elegant and most safe way to solve such
a seemingly simple task?

Thank you!

On Fri, Feb 27, 2015 at 10:02 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 27/02/2015 9:49 AM, Dimitri Liakhovitski wrote:
>> So, Duncan, do I understand you correctly:
>>
>> When I use x$x<6, R doesn't know if it's TRUE or FALSE, so it returns
>> a logical value of NA.
>
> Yes, when x$x is NA.  (Though I think you meant x$c.)
>
>> When this logical value is applied to a row, the R says: hell, I don't
>> know if I should keep it or not, so, just in case, I am going to keep
>> it, but I'll replace all the values in this row with NAs?
>
> Yes.  Indexing with a logical NA is probably a mistake, and this is one
> way to signal it without actually triggering a warning or error.
>
> BTW, I should have mentioned that the example where you indexed using
> -which(x$c>=6) is a bad idea:  if none of the entries were 6 or more,
> this would be indexing with an empty vector, and you'd get nothing, not
> everything.
>
> Duncan Murdoch
>
>
>>
>> On Fri, Feb 27, 2015 at 9:13 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>> On 27/02/2015 9:04 AM, Dimitri Liakhovitski wrote:
>>>> I know how to get the output I need, but I would benefit from an
>>>> explanation why R behaves the way it does.
>>>>
>>>> # I have a data frame x:
>>>> x = data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
>>>> x
>>>> # I want to toss rows in x that contain values >=6. But I don't want
>>>> to toss my NAs there.
>>>>
>>>> subset(x,c<6) # Works correctly, but removes NAs in c, understand why
>>>> x[which(x$c<6),] # Works correctly, but removes NAs in c, understand why
>>>> x[-which(x$c>=6),] # output I need
>>>>
>>>> # Here is my question: why does the following line replace the values
>>>> of all rows that contain an NA # in x$c with NAs?
>>>>
>>>> x[x$c<6,]  # Leaves rows with c=NA, but makes the whole row an NA. Why???
>>>> x[(x$c<6) | is.na(x$c),] # output I need - I have to be super-explicit
>>>>
>>>> Thank you very much!
>>>
>>> Most of your examples (except the ones using which()) are doing logical
>>> indexing.  In logical indexing, TRUE keeps a line, FALSE drops the line,
>>> and NA returns NA.  Since "x$c < 6" is NA if x$c is NA, you get the
>>> third kind of indexing.
>>>
>>> Your last example works because in the cases where x$c is NA, it
>>> evaluates NA | TRUE, and that evaluates to TRUE.  In the cases where x$c
>>> is not NA, you get x$c < 6 | FALSE, and that's the same as x$c < 6,
>>> which will be either TRUE or FALSE.
>>>
>>> Duncan Murdoch
>>>
>>
>>
>>
>



-- 
Dimitri Liakhovitski


From murdoch.duncan at gmail.com  Fri Feb 27 17:00:46 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 27 Feb 2015 11:00:46 -0500
Subject: [R] Why does R replace all row values with NAs
In-Reply-To: <CAN2xGJauN=swX6P0WHzH+bsEcobCn24_z0pJWr64D5p-UBwVHg@mail.gmail.com>
References: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>	<54F07B99.90005@gmail.com>	<CAN2xGJYmhkJmndSBVBL3WD+hEBFVKLhUGDDX_oi2WOQt+uDTiQ@mail.gmail.com>	<54F086EA.7020800@gmail.com>
	<CAN2xGJauN=swX6P0WHzH+bsEcobCn24_z0pJWr64D5p-UBwVHg@mail.gmail.com>
Message-ID: <54F094AE.10408@gmail.com>

On 27/02/2015 10:27 AM, Dimitri Liakhovitski wrote:
> Thank you very much, Duncan.
> All this being said:
> 
> What would you say is the most elegant and most safe way to solve such
> a seemingly simple task?

If you have NA values, test for them explicitly, e.g. your original

x[(x$c<6) | is.na(x$c),]

I would write it as

x[is.na(x$c) | x$c < 6,]

but that's purely a style difference, I don't think it would affect
execution time (or results).  I like to put the weird case first because
it will remind me that things are more complicated than you might guess.

Duncan Murdoch

> 
> Thank you!
> 
> On Fri, Feb 27, 2015 at 10:02 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 27/02/2015 9:49 AM, Dimitri Liakhovitski wrote:
>>> So, Duncan, do I understand you correctly:
>>>
>>> When I use x$x<6, R doesn't know if it's TRUE or FALSE, so it returns
>>> a logical value of NA.
>>
>> Yes, when x$x is NA.  (Though I think you meant x$c.)
>>
>>> When this logical value is applied to a row, the R says: hell, I don't
>>> know if I should keep it or not, so, just in case, I am going to keep
>>> it, but I'll replace all the values in this row with NAs?
>>
>> Yes.  Indexing with a logical NA is probably a mistake, and this is one
>> way to signal it without actually triggering a warning or error.
>>
>> BTW, I should have mentioned that the example where you indexed using
>> -which(x$c>=6) is a bad idea:  if none of the entries were 6 or more,
>> this would be indexing with an empty vector, and you'd get nothing, not
>> everything.
>>
>> Duncan Murdoch
>>
>>
>>>
>>> On Fri, Feb 27, 2015 at 9:13 AM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>> On 27/02/2015 9:04 AM, Dimitri Liakhovitski wrote:
>>>>> I know how to get the output I need, but I would benefit from an
>>>>> explanation why R behaves the way it does.
>>>>>
>>>>> # I have a data frame x:
>>>>> x = data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
>>>>> x
>>>>> # I want to toss rows in x that contain values >=6. But I don't want
>>>>> to toss my NAs there.
>>>>>
>>>>> subset(x,c<6) # Works correctly, but removes NAs in c, understand why
>>>>> x[which(x$c<6),] # Works correctly, but removes NAs in c, understand why
>>>>> x[-which(x$c>=6),] # output I need
>>>>>
>>>>> # Here is my question: why does the following line replace the values
>>>>> of all rows that contain an NA # in x$c with NAs?
>>>>>
>>>>> x[x$c<6,]  # Leaves rows with c=NA, but makes the whole row an NA. Why???
>>>>> x[(x$c<6) | is.na(x$c),] # output I need - I have to be super-explicit
>>>>>
>>>>> Thank you very much!
>>>>
>>>> Most of your examples (except the ones using which()) are doing logical
>>>> indexing.  In logical indexing, TRUE keeps a line, FALSE drops the line,
>>>> and NA returns NA.  Since "x$c < 6" is NA if x$c is NA, you get the
>>>> third kind of indexing.
>>>>
>>>> Your last example works because in the cases where x$c is NA, it
>>>> evaluates NA | TRUE, and that evaluates to TRUE.  In the cases where x$c
>>>> is not NA, you get x$c < 6 | FALSE, and that's the same as x$c < 6,
>>>> which will be either TRUE or FALSE.
>>>>
>>>> Duncan Murdoch
>>>>
>>>
>>>
>>>
>>
> 
> 
>


From roger.bos at rothschild.com  Fri Feb 27 17:01:39 2015
From: roger.bos at rothschild.com (Bos, Roger)
Date: Fri, 27 Feb 2015 16:01:39 +0000
Subject: [R] Reading in an XLS (really XML) file from website
Message-ID: <0765308CD028654885F30322557308D81EDE1DD3@NYCSM0208.rth.ad.rothschild.com>

All,

I am trying to read the S&P 500 constituents from the iShares website using the following code:

   URL <- "http://www.ishares.com/us/239726/fund-download.dl"
   setInternet2(TRUE)
   download.file(url=URL, destfile="temp.xls")
   out <- readWorksheetFromFile(file="temp.xls", sheet="Holdings", header=TRUE, startRow=13)

R returns the following error:

>    out <- readWorksheetFromFile(file="temp.xls", sheet="Holdings", header=TRUE, startRow=13)
Error: IllegalArgumentException (Java): Your InputStream was neither an OLE2 stream, nor an OOXML stream
In addition: Warning message:
In download.file(url = URL, destfile = "temp.xls") :
  downloaded length 1938303 != reported length 200

Upon further examination this is because the format is really XML.  Is there any way to get XLConnect or any other excel reader to read in an XML file?  I thought XML was for new Excel format.

Barring that, can we read in the file using the XML package? I tried the following code...

   require(XML)
   tmp <- xmlParse(URL)

... but I get this error:

Opening and ending tag mismatch: Style line 14 and Style
Error: 1: Opening and ending tag mismatch: Style line 14 and Style

Thanks in advance for any help or hints,

Roger



***************************************************************
This message and any attachments are for the named person's use only.
This message may contain confidential, proprietary or legally privileged
information. No right to confidential or privileged treatment
of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately
notify the sender by e-mail, delete the message, any attachments and all
copies from your system and destroy any hard copies. You must
not, directly or indirectly, use, disclose, distribute,
print or copy any part of this message or any attachments if you are not
the intended recipient.



From wdunlap at tibco.com  Fri Feb 27 17:04:36 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 27 Feb 2015 08:04:36 -0800
Subject: [R] Why does R replace all row values with NAs
In-Reply-To: <CAN2xGJauN=swX6P0WHzH+bsEcobCn24_z0pJWr64D5p-UBwVHg@mail.gmail.com>
References: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>
	<54F07B99.90005@gmail.com>
	<CAN2xGJYmhkJmndSBVBL3WD+hEBFVKLhUGDDX_oi2WOQt+uDTiQ@mail.gmail.com>
	<54F086EA.7020800@gmail.com>
	<CAN2xGJauN=swX6P0WHzH+bsEcobCn24_z0pJWr64D5p-UBwVHg@mail.gmail.com>
Message-ID: <CAF8bMcYrPtnLpvOfa17ZthjhSkp3L8KbFcy5uMv+sf-m+5X3UA@mail.gmail.com>

You could define functions like
   is.true <- function(x) !is.na(x) & x
   is.false <- function(x) !is.na(x) & !x
and use them in your selections.  E.g.,
  > x <- data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
  > x[is.true(x$c >= 6), ]
      a  b  c
  7   7  8  7
  10 10 11 10


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Feb 27, 2015 at 7:27 AM, Dimitri Liakhovitski <
dimitri.liakhovitski at gmail.com> wrote:

> Thank you very much, Duncan.
> All this being said:
>
> What would you say is the most elegant and most safe way to solve such
> a seemingly simple task?
>
> Thank you!
>
> On Fri, Feb 27, 2015 at 10:02 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> > On 27/02/2015 9:49 AM, Dimitri Liakhovitski wrote:
> >> So, Duncan, do I understand you correctly:
> >>
> >> When I use x$x<6, R doesn't know if it's TRUE or FALSE, so it returns
> >> a logical value of NA.
> >
> > Yes, when x$x is NA.  (Though I think you meant x$c.)
> >
> >> When this logical value is applied to a row, the R says: hell, I don't
> >> know if I should keep it or not, so, just in case, I am going to keep
> >> it, but I'll replace all the values in this row with NAs?
> >
> > Yes.  Indexing with a logical NA is probably a mistake, and this is one
> > way to signal it without actually triggering a warning or error.
> >
> > BTW, I should have mentioned that the example where you indexed using
> > -which(x$c>=6) is a bad idea:  if none of the entries were 6 or more,
> > this would be indexing with an empty vector, and you'd get nothing, not
> > everything.
> >
> > Duncan Murdoch
> >
> >
> >>
> >> On Fri, Feb 27, 2015 at 9:13 AM, Duncan Murdoch
> >> <murdoch.duncan at gmail.com> wrote:
> >>> On 27/02/2015 9:04 AM, Dimitri Liakhovitski wrote:
> >>>> I know how to get the output I need, but I would benefit from an
> >>>> explanation why R behaves the way it does.
> >>>>
> >>>> # I have a data frame x:
> >>>> x = data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
> >>>> x
> >>>> # I want to toss rows in x that contain values >=6. But I don't want
> >>>> to toss my NAs there.
> >>>>
> >>>> subset(x,c<6) # Works correctly, but removes NAs in c, understand why
> >>>> x[which(x$c<6),] # Works correctly, but removes NAs in c, understand
> why
> >>>> x[-which(x$c>=6),] # output I need
> >>>>
> >>>> # Here is my question: why does the following line replace the values
> >>>> of all rows that contain an NA # in x$c with NAs?
> >>>>
> >>>> x[x$c<6,]  # Leaves rows with c=NA, but makes the whole row an NA.
> Why???
> >>>> x[(x$c<6) | is.na(x$c),] # output I need - I have to be
> super-explicit
> >>>>
> >>>> Thank you very much!
> >>>
> >>> Most of your examples (except the ones using which()) are doing logical
> >>> indexing.  In logical indexing, TRUE keeps a line, FALSE drops the
> line,
> >>> and NA returns NA.  Since "x$c < 6" is NA if x$c is NA, you get the
> >>> third kind of indexing.
> >>>
> >>> Your last example works because in the cases where x$c is NA, it
> >>> evaluates NA | TRUE, and that evaluates to TRUE.  In the cases where
> x$c
> >>> is not NA, you get x$c < 6 | FALSE, and that's the same as x$c < 6,
> >>> which will be either TRUE or FALSE.
> >>>
> >>> Duncan Murdoch
> >>>
> >>
> >>
> >>
> >
>
>
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Feb 27 17:07:57 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 27 Feb 2015 16:07:57 +0000
Subject: [R] Summing certain values within columns that satisfy
	a	certain condition
In-Reply-To: <205DAF49-C849-4A91-9CCC-8D201FCEB020@u.washington.edu>
References: <CAE6QMsbpTgDX=b-tegcahURbSjANQaXtxxoDPxzZER3nUU5ffw@mail.gmail.com>
	<205DAF49-C849-4A91-9CCC-8D201FCEB020@u.washington.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6568D5@mb02.ads.tamu.edu>

Here is another approach

> maxv <- apply(df, 2, max) # Get the column maximums
> maxv0 <- ifelse(maxv == 0, -1, maxv) # Replace 0 maximums with -1
> Sum <-  rowSums(sweep(df, 2, maxv0, "=="))
> data.frame(df, Sum)
   A B C D Sum
1  0 1 0 7   1
2  0 2 0 7   1
3  0 3 0 7   1
4  0 4 0 7   1
5  0 1 0 0   0
6  0 0 0 0   0
7  0 0 0 0   0
8  0 0 0 0   0
9  0 0 1 5   0
10 0 5 1 5   0
11 0 4 1 5   0
12 0 8 4 7   3
13 0 0 3 0   0
14 0 0 3 4   0
15 0 0 3 4   0
16 0 0 0 5   0
17 0 2 0 6   0
18 0 0 4 0   1
19 0 0 4 0   1
20 0 0 4 0   1


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Don McKenzie
Sent: Thursday, February 26, 2015 3:12 PM
To: Kate Ignatius
Cc: r-help
Subject: Re: [R] Summing certain values within columns that satisfy a certain condition

Kate ? here is a transparent solution (tested but without NA treatment). Doubtless there are cleverer faster ones, which later posters will present.

HTH

# example with four columns and 20 rows
nrows <- 20

A <- sample(c(1:100), nrows, replace=T)
B <- sample(c(1:100), nrows, replace=T)
C <- sample(c(1:100), nrows, replace=T)
D <- sample(c(1:100), nrows, replace=T)

locs <- c(c(1:nrows)[A==max(A)],c(1:nrows)[B==max(B)],c(1:nrows)[C==max(C)],c(1:nrows)[D==max(D)])

mat1 <- matrix(rep(0,4*nrows),nrows,4)
for (i in 1:4)
	mat1[,i][locs[i]] <- 1
SUM <- rowSums(mat1)


> On Feb 26, 2015, at 12:23 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> 
> Hi,
> 
> Supposed I had a data frame like so:
> 
> A B C D
> 0 1 0 7
> 0 2 0 7
> 0 3 0 7
> 0 4 0 7
> 0 1 0 0
> 0 0 0 0
> 0 0 0 0
> 0 0 0 0
> 0 0 1 5
> 0 5 1 5
> 0 4 1 5
> 0 8 4 7
> 0 0 3 0
> 0 0 3 4
> 0 0 3 4
> 0 0 0 5
> 0 2 0 6
> 0 0 4 0
> 0 0 4 0
> 0 0 4 0
> 
> For each row, I want to count how many max column values appear to
> adventurely get the following outcome, while ignoring zeros and N/As:
> 
> A B C D Sum
> 0 1 0 7 1
> 0 2 0 7 1
> 0 3 0 7 1
> 0 4 0 7 1
> 0 1 0 0 0
> 0 0 0 0 0
> 0 0 0 0 0
> 0 0 0 0 0
> 0 0 1 5 0
> 0 5 1 5 0
> 0 4 1 5 0
> 0 8 4 7 3
> 0 0 3 0 0
> 0 0 3 4 0
> 0 0 3 4 0
> 0 0 0 5 0
> 0 2 0 6 0
> 0 0 4 0 1
> 0 0 4 0 1
> 0 0 4 0 1
> 
> I've used the following code but it doesn't seem to work (my sum
> column column is all 1s):
> 
> (apply(df,1, function(x)  (sum(x %in% c(pmax(x))))))
> 
> Is this code too simple?
> 
> Thanks!
> 
> K.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From dimitri.liakhovitski at gmail.com  Fri Feb 27 17:22:59 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 27 Feb 2015 11:22:59 -0500
Subject: [R] Why does R replace all row values with NAs
In-Reply-To: <CAF8bMcYrPtnLpvOfa17ZthjhSkp3L8KbFcy5uMv+sf-m+5X3UA@mail.gmail.com>
References: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>
	<54F07B99.90005@gmail.com>
	<CAN2xGJYmhkJmndSBVBL3WD+hEBFVKLhUGDDX_oi2WOQt+uDTiQ@mail.gmail.com>
	<54F086EA.7020800@gmail.com>
	<CAN2xGJauN=swX6P0WHzH+bsEcobCn24_z0pJWr64D5p-UBwVHg@mail.gmail.com>
	<CAF8bMcYrPtnLpvOfa17ZthjhSkp3L8KbFcy5uMv+sf-m+5X3UA@mail.gmail.com>
Message-ID: <CAN2xGJaDTcf2XcN37rBjpPBbe_D+S6nvGUVgCn5YTmFGAZ5MeQ@mail.gmail.com>

Thank you very much guys!

On Fri, Feb 27, 2015 at 11:04 AM, William Dunlap <wdunlap at tibco.com> wrote:
> You could define functions like
>    is.true <- function(x) !is.na(x) & x
>    is.false <- function(x) !is.na(x) & !x
> and use them in your selections.  E.g.,
>   > x <- data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
>   > x[is.true(x$c >= 6), ]
>       a  b  c
>   7   7  8  7
>   10 10 11 10
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Feb 27, 2015 at 7:27 AM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>>
>> Thank you very much, Duncan.
>> All this being said:
>>
>> What would you say is the most elegant and most safe way to solve such
>> a seemingly simple task?
>>
>> Thank you!
>>
>> On Fri, Feb 27, 2015 at 10:02 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>> > On 27/02/2015 9:49 AM, Dimitri Liakhovitski wrote:
>> >> So, Duncan, do I understand you correctly:
>> >>
>> >> When I use x$x<6, R doesn't know if it's TRUE or FALSE, so it returns
>> >> a logical value of NA.
>> >
>> > Yes, when x$x is NA.  (Though I think you meant x$c.)
>> >
>> >> When this logical value is applied to a row, the R says: hell, I don't
>> >> know if I should keep it or not, so, just in case, I am going to keep
>> >> it, but I'll replace all the values in this row with NAs?
>> >
>> > Yes.  Indexing with a logical NA is probably a mistake, and this is one
>> > way to signal it without actually triggering a warning or error.
>> >
>> > BTW, I should have mentioned that the example where you indexed using
>> > -which(x$c>=6) is a bad idea:  if none of the entries were 6 or more,
>> > this would be indexing with an empty vector, and you'd get nothing, not
>> > everything.
>> >
>> > Duncan Murdoch
>> >
>> >
>> >>
>> >> On Fri, Feb 27, 2015 at 9:13 AM, Duncan Murdoch
>> >> <murdoch.duncan at gmail.com> wrote:
>> >>> On 27/02/2015 9:04 AM, Dimitri Liakhovitski wrote:
>> >>>> I know how to get the output I need, but I would benefit from an
>> >>>> explanation why R behaves the way it does.
>> >>>>
>> >>>> # I have a data frame x:
>> >>>> x = data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
>> >>>> x
>> >>>> # I want to toss rows in x that contain values >=6. But I don't want
>> >>>> to toss my NAs there.
>> >>>>
>> >>>> subset(x,c<6) # Works correctly, but removes NAs in c, understand why
>> >>>> x[which(x$c<6),] # Works correctly, but removes NAs in c, understand
>> >>>> why
>> >>>> x[-which(x$c>=6),] # output I need
>> >>>>
>> >>>> # Here is my question: why does the following line replace the values
>> >>>> of all rows that contain an NA # in x$c with NAs?
>> >>>>
>> >>>> x[x$c<6,]  # Leaves rows with c=NA, but makes the whole row an NA.
>> >>>> Why???
>> >>>> x[(x$c<6) | is.na(x$c),] # output I need - I have to be
>> >>>> super-explicit
>> >>>>
>> >>>> Thank you very much!
>> >>>
>> >>> Most of your examples (except the ones using which()) are doing
>> >>> logical
>> >>> indexing.  In logical indexing, TRUE keeps a line, FALSE drops the
>> >>> line,
>> >>> and NA returns NA.  Since "x$c < 6" is NA if x$c is NA, you get the
>> >>> third kind of indexing.
>> >>>
>> >>> Your last example works because in the cases where x$c is NA, it
>> >>> evaluates NA | TRUE, and that evaluates to TRUE.  In the cases where
>> >>> x$c
>> >>> is not NA, you get x$c < 6 | FALSE, and that's the same as x$c < 6,
>> >>> which will be either TRUE or FALSE.
>> >>>
>> >>> Duncan Murdoch
>> >>>
>> >>
>> >>
>> >>
>> >
>>
>>
>>
>> --
>> Dimitri Liakhovitski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Dimitri Liakhovitski


From julian.keil at gmail.com  Fri Feb 27 16:28:39 2015
From: julian.keil at gmail.com (Julian Keil)
Date: Fri, 27 Feb 2015 16:28:39 +0100
Subject: [R] Call R from Matlab
Message-ID: <8B4A2E9A-2986-4D49-B3B6-B94DD7024A2F@gmail.com>

Dear all,

I have a Mac, OSX 10.7.5, run R 3.1.2 (2014-10-31) and Matlab R2013a (8.1.0.604).

I try to call R from within Matlab to run a function in Batch mode.
To do this, I followed this example:

From: www.mathworks.com/matlabcentral/newsreader/view_thread/163726

In an m-file you would have:
~~~~~~~~~~~~~~~~~~~~~
data = sum(rand(100), 1);
csvwrite('data.csv', data(:)); % Write as a column
system('R CMD BATCH calc.R outputForDebugging.txt');
testResults = csvread('testResults.csv');
testResultsStruct = struct('W_statistic', testResults(1), 'p_value', testResults(2))
~~~~~~~~~~~~~~~~~~~~~

In the calc.R r-file you would have:
~~~~~~~~~~~~~~~~~~~~~
data <- read.table("data.csv", header = FALSE, sep = ",")
results <- shapiro.test(data$V1)
results2 <- c( results$statistic[["W"]], results$p.value )
write.table(results2, file="testResults.csv", sep = ",", col.names = FALSE, row.names = FALSE, qmethod = "double")
~~~~~~~~~~~~~~~~~~~~~

Now, the R-Part in itself works fine. If I open R and run the calc.R-Script everything works. If I run the calc.R in Batch mode from the terminal, everything works.
However, if I call R from within Matlab using the system command, I get the error:

Error in dyn.load(file, DLLpath = DLLpath, ...) :
  kann shared object '/Library/Frameworks/R.framework/Versions/3.1/Resources/library/stats/libs/stats.so' nicht laden:
  dlopen(/Library/Frameworks/R.framework/Versions/3.1/Resources/library/stats/libs/stats.so, 6): Symbol not found: __gfortran_pow_r8_i4
  Referenced from: /Library/Frameworks/R.framework/Versions/3.1/Resources/lib/libRlapack.dylib
  Expected in: /Applications/MATLAB_R2013a.app/sys/os/maci64/libgfortran.2.dylib
 in /Library/Frameworks/R.framework/Versions/3.1/Resources/lib/libRlapack.dylib
Beim Start - Warnmeldung:
package 'stats' in options("defaultPackages") was not found

It appears that R fails to load some objects. However, I don't understand why this only happens if I call R from Matlab, not when I start R by itself or use the terminal to start R.
I already installed R new, but it did not help.

Can anyone enlighten my on this matter?

Thanks a lot!

Julian


********************
Dr. Julian Keil

AG Multisensorische Integration
Psychiatrische Universit?tsklinik
der Charit? im St. Hedwig-Krankenhaus
Gro?e Hamburger Stra?e 5-11, Raum E 307
10115 Berlin

Telefon: +49-30-2311-1879
Fax:        +49-30-2311-2209
http://psy-ccm.charite.de/forschung/bildgebung/ag_multisensorische_integration

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 495 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150227/b78a5706/attachment.bin>

From btrautman84 at gmail.com  Fri Feb 27 19:18:15 2015
From: btrautman84 at gmail.com (Brian Trautman)
Date: Fri, 27 Feb 2015 10:18:15 -0800
Subject: [R] Variable Column Names and Lists
Message-ID: <CAFYnejKxREWTY_qzXiprerXJWMB7+DTtHLeSmhtDMTc=q_urtw@mail.gmail.com>

This should be a simple question, but I am at my wits end.

dt<-data.table(a=rep(1:10, 26), b=1:260, c=rep(1:2, 130))

sumvar <- 'mysum'
bvar <- 'b'

dt_min <- dt[, list(sumvar = sum(get(bvar))), by=list(a)]
print(dt_min)

I want the function to return two variables, "a" and "mysum".  However, it
instead returns "a" and "sumvar", rather than evaluating "sumvar".

If I try replacing it with "get(sumvar)" or "eval(sumvar)", R just throws
an error.  What am I missing?

     a sumvar
 1:  1   3276
 2:  2   3302
 3:  3   3328
 4:  4   3354
 5:  5   3380
 6:  6   3406
 7:  7   3432
 8:  8   3458
 9:  9   3484
10: 10   3510

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Feb 27 19:37:02 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 27 Feb 2015 10:37:02 -0800
Subject: [R] Call R from Matlab
In-Reply-To: <8B4A2E9A-2986-4D49-B3B6-B94DD7024A2F@gmail.com>
References: <8B4A2E9A-2986-4D49-B3B6-B94DD7024A2F@gmail.com>
Message-ID: <CAF8bMcbAgKNKzH0VHGQ9+ErTK9QGsWhSqBsX1p_s46MWa4SFbQ@mail.gmail.com>

This usually has to do with the caller (Matlab) and the callee (R) being
dynamically lined with different versions of dynamic libraries.  On Linux
I work around this sort of thing by setting LD_LIBRARY_PATH to exactly
what I want when invoking R.  E.g., instead of making the sh command
   /usr/local/bin/R ...
to start R, try something like
   LD_LIBRARY_PATH=/opt/sw/R/R-3.1.2/lib64/R/lib:/usr/local/lib64:/usr/lib
/usr/local/bin/R ...
where the value I give to LD_LIBRARY_PATH comes from calling
Sys.getenv("LD_LIBRARY_PATH") in a stand-alone R session.

I don't know the details of this on Apple's versions of Unix.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Feb 27, 2015 at 7:28 AM, Julian Keil <julian.keil at gmail.com> wrote:

> Dear all,
>
> I have a Mac, OSX 10.7.5, run R 3.1.2 (2014-10-31) and Matlab R2013a
> (8.1.0.604).
>
> I try to call R from within Matlab to run a function in Batch mode.
> To do this, I followed this example:
>
> From: www.mathworks.com/matlabcentral/newsreader/view_thread/163726
>
> In an m-file you would have:
> ~~~~~~~~~~~~~~~~~~~~~
> data = sum(rand(100), 1);
> csvwrite('data.csv', data(:)); % Write as a column
> system('R CMD BATCH calc.R outputForDebugging.txt');
> testResults = csvread('testResults.csv');
> testResultsStruct = struct('W_statistic', testResults(1), 'p_value',
> testResults(2))
> ~~~~~~~~~~~~~~~~~~~~~
>
> In the calc.R r-file you would have:
> ~~~~~~~~~~~~~~~~~~~~~
> data <- read.table("data.csv", header = FALSE, sep = ",")
> results <- shapiro.test(data$V1)
> results2 <- c( results$statistic[["W"]], results$p.value )
> write.table(results2, file="testResults.csv", sep = ",", col.names =
> FALSE, row.names = FALSE, qmethod = "double")
> ~~~~~~~~~~~~~~~~~~~~~
>
> Now, the R-Part in itself works fine. If I open R and run the
> calc.R-Script everything works. If I run the calc.R in Batch mode from the
> terminal, everything works.
> However, if I call R from within Matlab using the system command, I get
> the error:
>
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>   kann shared object
> '/Library/Frameworks/R.framework/Versions/3.1/Resources/library/stats/libs/stats.so'
> nicht laden:
>
> dlopen(/Library/Frameworks/R.framework/Versions/3.1/Resources/library/stats/libs/stats.so,
> 6): Symbol not found: __gfortran_pow_r8_i4
>   Referenced from:
> /Library/Frameworks/R.framework/Versions/3.1/Resources/lib/libRlapack.dylib
>   Expected in:
> /Applications/MATLAB_R2013a.app/sys/os/maci64/libgfortran.2.dylib
>  in
> /Library/Frameworks/R.framework/Versions/3.1/Resources/lib/libRlapack.dylib
> Beim Start - Warnmeldung:
> package 'stats' in options("defaultPackages") was not found
>
> It appears that R fails to load some objects. However, I don't understand
> why this only happens if I call R from Matlab, not when I start R by itself
> or use the terminal to start R.
> I already installed R new, but it did not help.
>
> Can anyone enlighten my on this matter?
>
> Thanks a lot!
>
> Julian
>
>
> ********************
> Dr. Julian Keil
>
> AG Multisensorische Integration
> Psychiatrische Universit?tsklinik
> der Charit? im St. Hedwig-Krankenhaus
> Gro?e Hamburger Stra?e 5-11, Raum E 307
> 10115 Berlin
>
> Telefon: +49-30-2311-1879
> Fax:        +49-30-2311-2209
>
> http://psy-ccm.charite.de/forschung/bildgebung/ag_multisensorische_integration
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Feb 27 19:47:15 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 27 Feb 2015 13:47:15 -0500
Subject: [R] Variable Column Names and Lists
In-Reply-To: <CAFYnejKxREWTY_qzXiprerXJWMB7+DTtHLeSmhtDMTc=q_urtw@mail.gmail.com>
References: <CAFYnejKxREWTY_qzXiprerXJWMB7+DTtHLeSmhtDMTc=q_urtw@mail.gmail.com>
Message-ID: <54F0BBB3.9010905@gmail.com>

On 27/02/2015 1:18 PM, Brian Trautman wrote:
> This should be a simple question, but I am at my wits end.
> 
> dt<-data.table(a=rep(1:10, 26), b=1:260, c=rep(1:2, 130))
> 
> sumvar <- 'mysum'
> bvar <- 'b'
> 
> dt_min <- dt[, list(sumvar = sum(get(bvar))), by=list(a)]
> print(dt_min)
> 
> I want the function to return two variables, "a" and "mysum".  However, it
> instead returns "a" and "sumvar", rather than evaluating "sumvar".
> 
> If I try replacing it with "get(sumvar)" or "eval(sumvar)", R just throws
> an error.  What am I missing?
> 
>      a sumvar
>  1:  1   3276
>  2:  2   3302
>  3:  3   3328
>  4:  4   3354
>  5:  5   3380
>  6:  6   3406
>  7:  7   3432
>  8:  8   3458
>  9:  9   3484
> 10: 10   3510

I don't know the data.table function, but

 list(sumvar = sum(get(bvar)))

will produce a list with one element named sumvar, holding the sum of
values of a variable named 'b'.  If you want that element to be named
'mysum', you could change it at the end, or construct that list as

structure(list(sum(get(bvar))), names=sumvar)

i.e. the full expression would be

dt_min <- dt[, structure(list(sum(get(bvar))), names=sumvar), by=list(a)]

The idea is that structure() produces list(sum(get(bvar))) with
attribute "names" set to the contents of sumvar.

Duncan Murdoch


From optionsraghu at gmail.com  Fri Feb 27 20:04:15 2015
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Fri, 27 Feb 2015 19:04:15 +0000
Subject: [R] Reading in an XLS (really XML) file from website
In-Reply-To: <0765308CD028654885F30322557308D81EDE1DD3@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D81EDE1DD3@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <CADgEnDme6x01ucAOe64UHThyJFUk4=V2SYTx4-=7LQ8cNuFA_w@mail.gmail.com>

This works:
Change the destination directory to suit you.

MyURL1 = "http://www.ishares.com/us/239726/fund-download.dl"
download.file(MyURL1,paste("C:/Data/Rtest1",date1,"r.xls",sep=""),method="wget",quiet=TRUE,mode="wb",
                         extra="--header=\"User-Agent: Mozilla/5.0
(X11; Linux x86_64; rv:30.0) Gecko/20100101 Firefox/30.0\"")

Cheers
Raghu


On Fri, Feb 27, 2015 at 4:01 PM, Bos, Roger <roger.bos at rothschild.com> wrote:
> All,
>
> I am trying to read the S&P 500 constituents from the iShares website using the following code:
>
>    URL <- "http://www.ishares.com/us/239726/fund-download.dl"
>    setInternet2(TRUE)
>    download.file(url=URL, destfile="temp.xls")
>    out <- readWorksheetFromFile(file="temp.xls", sheet="Holdings", header=TRUE, startRow=13)
>
> R returns the following error:
>
>>    out <- readWorksheetFromFile(file="temp.xls", sheet="Holdings", header=TRUE, startRow=13)
> Error: IllegalArgumentException (Java): Your InputStream was neither an OLE2 stream, nor an OOXML stream
> In addition: Warning message:
> In download.file(url = URL, destfile = "temp.xls") :
>   downloaded length 1938303 != reported length 200
>
> Upon further examination this is because the format is really XML.  Is there any way to get XLConnect or any other excel reader to read in an XML file?  I thought XML was for new Excel format.
>
> Barring that, can we read in the file using the XML package? I tried the following code...
>
>    require(XML)
>    tmp <- xmlParse(URL)
>
> ... but I get this error:
>
> Opening and ending tag mismatch: Style line 14 and Style
> Error: 1: Opening and ending tag mismatch: Style line 14 and Style
>
> Thanks in advance for any help or hints,
>
> Roger
>
>
>
> ***************************************************************
> This message and any attachments are for the named person's use only.
> This message may contain confidential, proprietary or legally privileged
> information. No right to confidential or privileged treatment
> of this message is waived or lost by an error in transmission.
> If you have received this message in error, please immediately
> notify the sender by e-mail, delete the message, any attachments and all
> copies from your system and destroy any hard copies. You must
> not, directly or indirectly, use, disclose, distribute,
> print or copy any part of this message or any attachments if you are not
> the intended recipient.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Wade.A.Wall at usace.army.mil  Fri Feb 27 22:32:27 2015
From: Wade.A.Wall at usace.army.mil (Wall, Wade A ERDC-RDE-CERL-IL)
Date: Fri, 27 Feb 2015 21:32:27 +0000
Subject: [R] Using R for agent based modeling
Message-ID: <C1524BE4BF45454293B8DF38FB9B5ECA1B7F3472@MS-EX1VKS.erdc.dren.mil>

Hi all,

I am wanting to model some patch dynamics using raster objects in R and am trying to figure out the best way to do it.

I want to treat each "patch" (pixel, cell, grid) and assign multiple attributes (for example biomass, temperature, precipitation, etc). I know that I can do this using a brick object, but I also want to add a temporal dimension.

What is the best way to do this? The only way I can think right now is to create a brick object with the number of bands equal to the number of attributes and then create a new object at each time step. Is there a better way? (Surely there is).

Most of what I find points to NetLogo, but I am actually trying to move away from the NetLogo environment, though I am not opposed to using it.

Thanks for any pointers in the right direction and sorry for not posting an example.

Wade




	[[alternative HTML version deleted]]


From btrautman84 at gmail.com  Fri Feb 27 22:35:35 2015
From: btrautman84 at gmail.com (Brian Trautman)
Date: Fri, 27 Feb 2015 13:35:35 -0800
Subject: [R] Variable Column Names and Lists
In-Reply-To: <54F0BBB3.9010905@gmail.com>
References: <CAFYnejKxREWTY_qzXiprerXJWMB7+DTtHLeSmhtDMTc=q_urtw@mail.gmail.com>
	<54F0BBB3.9010905@gmail.com>
Message-ID: <CAFYnejKYmzfnf9D8iRj5Qwm=Zmh8zUAsU0nc1VmD52F_iB=wRQ@mail.gmail.com>

This worked perfectly, thank you!

On Fri, Feb 27, 2015 at 10:47 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 27/02/2015 1:18 PM, Brian Trautman wrote:
> > This should be a simple question, but I am at my wits end.
> >
> > dt<-data.table(a=rep(1:10, 26), b=1:260, c=rep(1:2, 130))
> >
> > sumvar <- 'mysum'
> > bvar <- 'b'
> >
> > dt_min <- dt[, list(sumvar = sum(get(bvar))), by=list(a)]
> > print(dt_min)
> >
> > I want the function to return two variables, "a" and "mysum".  However,
> it
> > instead returns "a" and "sumvar", rather than evaluating "sumvar".
> >
> > If I try replacing it with "get(sumvar)" or "eval(sumvar)", R just throws
> > an error.  What am I missing?
> >
> >      a sumvar
> >  1:  1   3276
> >  2:  2   3302
> >  3:  3   3328
> >  4:  4   3354
> >  5:  5   3380
> >  6:  6   3406
> >  7:  7   3432
> >  8:  8   3458
> >  9:  9   3484
> > 10: 10   3510
>
> I don't know the data.table function, but
>
>  list(sumvar = sum(get(bvar)))
>
> will produce a list with one element named sumvar, holding the sum of
> values of a variable named 'b'.  If you want that element to be named
> 'mysum', you could change it at the end, or construct that list as
>
> structure(list(sum(get(bvar))), names=sumvar)
>
> i.e. the full expression would be
>
> dt_min <- dt[, structure(list(sum(get(bvar))), names=sumvar), by=list(a)]
>
> The idea is that structure() produces list(sum(get(bvar))) with
> attribute "names" set to the contents of sumvar.
>
> Duncan Murdoch
>
>

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Fri Feb 27 23:05:49 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 27 Feb 2015 16:05:49 -0600
Subject: [R] Reading in an XLS (really XML) file from website
In-Reply-To: <0765308CD028654885F30322557308D81EDE1DD3@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D81EDE1DD3@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <CAAJSdjh_h_f+pVf+ok0BzsUddHe5pP8W+vTu_JtbA6Y9O9Kubg@mail.gmail.com>

On Fri, Feb 27, 2015 at 10:01 AM, Bos, Roger <roger.bos at rothschild.com>
wrote:

> All,
>
> I am trying to read the S&P 500 constituents from the iShares website
> using the following code:
>
>    URL <- "http://www.ishares.com/us/239726/fund-download.dl"
>    setInternet2(TRUE)
>    download.file(url=URL, destfile="temp.xls")
>    out <- readWorksheetFromFile(file="temp.xls", sheet="Holdings",
> header=TRUE, startRow=13)
>
> R returns the following error:
>
> >    out <- readWorksheetFromFile(file="temp.xls", sheet="Holdings",
> header=TRUE, startRow=13)
> Error: IllegalArgumentException (Java): Your InputStream was neither an
> OLE2 stream, nor an OOXML stream
> In addition: Warning message:
> In download.file(url = URL, destfile = "temp.xls") :
>   downloaded length 1938303 != reported length 200
>
> Upon further examination this is because the format is really XML.  Is
> there any way to get XLConnect or any other excel reader to read in an XML
> file?  I thought XML was for new Excel format.
>
> Barring that, can we read in the file using the XML package? I tried the
> following code...
>
>    require(XML)
>    tmp <- xmlParse(URL)
>
> ... but I get this error:
>
> Opening and ending tag mismatch: Style line 14 and Style
> Error: 1: Opening and ending tag mismatch: Style line 14 and Style
>
> Thanks in advance for any help or hints,
>
> Roger
>
>
?The problem is indeed on line 14 of the file. The contents of that line
are:

</style>

but should be

</ss:style>

That is, the file is malformed. I edited the file to make that change and
saved it. After I did this, I was able to open it as a spreadsheet using
LibreOffice. I did all of this on my home Linux system. I don't have
Windows, and thus no Excel either, available here, so I can't test with
Excel. ?You should be able to download this file as shown by Raghuraman. On
Windows (which I _assume_ you are using since most do), you can edit the
file using Notepad, or Wordpad. I would use Wordpad myself. Notepad is
"iffy" on some things. Save it back, then try readWorksheetFromFile() as
you originally did.


-- 
He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From alrik.thiem at gmail.com  Fri Feb 27 23:19:47 2015
From: alrik.thiem at gmail.com (Alrik Thiem)
Date: Fri, 27 Feb 2015 23:19:47 +0100
Subject: [R] Substring replacement in string
Message-ID: <027d01d052db$7faa3140$7efe93c0$@gmail.com>

Dear R-help list,

I would like to replace all lower-case letters in a string that are not part
of certain fixed expressions. For example, I have the string:

"pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"

Where I would like to replace all lower-case letters that do not belong to
the functions "pmin" and "pmax" by 1 - toupper(...) to get

"pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"

Any ideas on how I could achieve that?

Many thanks and best wishes,

Alrik


********************************
Alrik Thiem
Post-Doctoral Researcher

Department of Philosophy
University of Geneva
Rue de Candolle 2
CH-1211 Geneva

+41 76 527 80 83

http://www.alrik-thiem.net
http://www.compasss.org


From wdunlap at tibco.com  Fri Feb 27 23:39:21 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 27 Feb 2015 14:39:21 -0800
Subject: [R] Substring replacement in string
In-Reply-To: <027d01d052db$7faa3140$7efe93c0$@gmail.com>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>
Message-ID: <CAF8bMcbAmS5=syLgngszdajw7UcqzZF09VkYmujX5HRJRXfQaw@mail.gmail.com>

If your string will always represent an R expression, you could work with
the expression directly with functions like all.names() and substitute().

f <- function (expr)
{
    toReplace <- setdiff(all.names(expr), c("pmin", "pmax"))
    toReplace <- grep(value = TRUE, "[a-z]", toReplace)
    names(toReplace) <- toReplace
    replacementList <- lapply(toReplace, function(name) call("-",
        1, as.name(toupper(name))))
    do.call(substitute, list(expr, replacementList))
}

> In <- quote(pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1)))
> Desired <- quote(pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1,
1 - Z1)))
> all.equal(Desired, f(In))
[1] TRUE





Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Feb 27, 2015 at 2:19 PM, Alrik Thiem <alrik.thiem at gmail.com> wrote:

> Dear R-help list,
>
> I would like to replace all lower-case letters in a string that are not
> part
> of certain fixed expressions. For example, I have the string:
>
> "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
>
> Where I would like to replace all lower-case letters that do not belong to
> the functions "pmin" and "pmax" by 1 - toupper(...) to get
>
> "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"
>
> Any ideas on how I could achieve that?
>
> Many thanks and best wishes,
>
> Alrik
>
>
> ********************************
> Alrik Thiem
> Post-Doctoral Researcher
>
> Department of Philosophy
> University of Geneva
> Rue de Candolle 2
> CH-1211 Geneva
>
> +41 76 527 80 83
>
> http://www.alrik-thiem.net
> http://www.compasss.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdobbins at statistics.com  Sat Feb 28 00:15:25 2015
From: jdobbins at statistics.com (Janet Dobbins)
Date: Fri, 27 Feb 2015 18:15:25 -0500
Subject: [R] Online courses in R from Statistics.com
Message-ID: <CAM7fjqj9zx3yjh2E-axt1noCNRGyt0tC0Uz8v6G3rJ_ux6GE=w@mail.gmail.com>

Perhaps you could circulate this?

*Online courses in R from Statistics.com*
*Basic? programming? courses: *

   - R Programming - Intro 1 <http://www.statistics.com/R-Prog-Intro-1> (Dr.
   Paul Murrell, instructor - core development team for R and author of *R
   Graphics *and *Introduction to Data Technologies*) This course
   introduces the basic concepts in computer programming via R - it is for
   those who have had little or no experience in programming.  Students will
   learn how to get going in R from the beginning, understand file formats and
   basic R syntax, and learn about using text editors to write code.  They
   will learn how to read in files, use symbols and assignments, and iterate
   simple loops.  The course closes with discussion of data structures and
   subsetting.
   - R Programming - Intro 2 <http://www.statistics.com/r-prog-intro-2/> (Mr.
   Joris Mays, instructor - coauthor of *R for Dummies*) This course
   continues the introduction to R programming. Students will learn how R
   works with numeric vectors and special values, and how to deal with special
   values.  They will start working with R to handle text data, and learn
   about regular expressions, dates, classes and generic functions, as well as
   matrices, data frames and lists.

*?Beyond basic programming:?*
For those who have been working and using R - the instructor for both of
these courses is Dr. Olivia Lau from Google.

   - R Programming - Intermediate
   <http://www.statistics.com/r-courses/course-catalog/R-Prog-Interm/> (One
   year of daily R use required before taking this course) This course is
   intended for experienced data analysts looking to unlock the power of R.
   It provides a systematic overview of R as a programming language,
   emphasizing good programming practices and the development of clear,
   concise code.  After completing the course, students should be able to
   manipulate data programmatically using R functions of their own design.
   - R Programming - Advanced
   <http://www.statistics.com/r-courses/r-program-adv/> (Two years of daily
   R use required before taking this course) This course covers key
   concepts for writing advanced R code, emphasizing the design of functional
   and efficient code.  It will set students down the road to mastering the
   intricacies of R.  After completing the course, students should be able to
   read, understand, modify, and create complex functions to perform a variety
   of tasks.





*?Other topic specific courses in R:We have a full curriculum of courses in
R (Graphics in R, Mapping in R, Spatial Analysis in R, more).  This
page groups and describes our R
courses:http://www.statistics.com/r-courses/
<http://www.statistics.com/r-courses/>?All courses include:*

   - Expert instructors who answer questions on a daily basis
   - Work on practical exercises and individualized feedback
   - Class size which allows interaction with instructor and fellow students

We specialize in personal attention and value pricing. Each course lasts 4
weeks and consists of readings, supplemental materials, exercises, and a
private discussion forum with fellow students and the instructor.  There
are no set hours to be online, and we estimate the workload to be about 15
hours per week. This is not a 'MOOC' (massive open online course) --
enrollment is limited, and the instructor will respond to each question
that you ask.?


*Pricing:*
?Depending on how many participants and how many courses you are interested
in, we can offer an institutional rate.  The commercial price for the R
Programming courses ranges between $549/person for the intro courses to
$629/person for the advanced/ topic focused courses.  Each course has a
text requirement which can be viewed under the "requirements" tab of each
course description page.  If you need help with this, just let me know and
I can put a chart together for you.?


-Janet

Janet Dobbins
Vice President of Marketing and Communications


612 N. Jackson St.
Arlington, VA 22201
703.431.3874 - mobile
703.522.5410 - office
703.522.5846 - fax
janet.dobbins1 - skype
jdobbins at statistics.com

Follow us on Facebook
<https://www.facebook.com/pages/statisticscom-The-Institute-for-Statistics-Education/153157148097998>
, Twitter <https://twitter.com/statisticscom>, LinkedIn
<http://www.linkedin.com/company/statistics-com-the-institute-for-statistics-education?trk=hb_tab_compy_id_1737759>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Sat Feb 28 04:27:35 2015
From: hannah.hlx at gmail.com (li li)
Date: Fri, 27 Feb 2015 22:27:35 -0500
Subject: [R] title of r plots
In-Reply-To: <CAHLnndYzBDwkGB10h+hcJU=9i_MnsE1S4hXSjOsUx3+9JPqgKQ@mail.gmail.com>
References: <CAHLnndYzBDwkGB10h+hcJU=9i_MnsE1S4hXSjOsUx3+9JPqgKQ@mail.gmail.com>
Message-ID: <CAHLnndZtc5+tW3CP4x+FY0EahDM3Y1td0k3VrJxQSf1KXmDn=w@mail.gmail.com>

 Hi all,
  I would like to add "-70?C ? 10?C/Ambient"  as the title of my plot.
Could anyone give some help on this?
  Thanks.
   Hanna

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sat Feb 28 05:03:56 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 27 Feb 2015 20:03:56 -0800
Subject: [R] title of r plots
In-Reply-To: <CAHLnndZtc5+tW3CP4x+FY0EahDM3Y1td0k3VrJxQSf1KXmDn=w@mail.gmail.com>
References: <CAHLnndYzBDwkGB10h+hcJU=9i_MnsE1S4hXSjOsUx3+9JPqgKQ@mail.gmail.com>
	<CAHLnndZtc5+tW3CP4x+FY0EahDM3Y1td0k3VrJxQSf1KXmDn=w@mail.gmail.com>
Message-ID: <CAF8bMcYWokT3pK918=bL8sK8SidF4XRyfvzNc0RKyK19ZT7YwQ@mail.gmail.com>

 plot(1,1,main=expression(-70*degree*C%+-%10*degree*C/Ambient))

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Feb 27, 2015 at 7:27 PM, li li <hannah.hlx at gmail.com> wrote:

>  Hi all,
>   I would like to add "-70?C ? 10?C/Ambient"  as the title of my plot.
> Could anyone give some help on this?
>   Thanks.
>    Hanna
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Sat Feb 28 05:52:00 2015
From: hannah.hlx at gmail.com (li li)
Date: Fri, 27 Feb 2015 23:52:00 -0500
Subject: [R] title of r plots
In-Reply-To: <CAF8bMcYWokT3pK918=bL8sK8SidF4XRyfvzNc0RKyK19ZT7YwQ@mail.gmail.com>
References: <CAHLnndYzBDwkGB10h+hcJU=9i_MnsE1S4hXSjOsUx3+9JPqgKQ@mail.gmail.com>
	<CAHLnndZtc5+tW3CP4x+FY0EahDM3Y1td0k3VrJxQSf1KXmDn=w@mail.gmail.com>
	<CAF8bMcYWokT3pK918=bL8sK8SidF4XRyfvzNc0RKyK19ZT7YwQ@mail.gmail.com>
Message-ID: <CAHLnndaJ7iyf0JGNQrY4g61LnDGLvHUFuYHiYUWFB-2WQ1WviQ@mail.gmail.com>

Thanks very much.
Also How do add an empty space when using expression()?
When I do the following, it returns an error message.


plot(1,1,main=expression(-70*degree*C%+-%10*degree*C/Ambient Condition))



   Hanna


2015-02-27 23:03 GMT-05:00 William Dunlap <wdunlap at tibco.com>:

>  plot(1,1,main=expression(-70*degree*C%+-%10*degree*C/Ambient))
>
>  Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>  On Fri, Feb 27, 2015 at 7:27 PM, li li <hannah.hlx at gmail.com> wrote:
>
>>   Hi all,
>>   I would like to add "-70?C ? 10?C/Ambient"  as the title of my plot.
>> Could anyone give some help on this?
>>   Thanks.
>>    Hanna
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From alrik.thiem at gmail.com  Sat Feb 28 08:25:31 2015
From: alrik.thiem at gmail.com (Alrik Thiem)
Date: Sat, 28 Feb 2015 08:25:31 +0100
Subject: [R] Substring replacement in string
In-Reply-To: <CAF8bMcbAmS5=syLgngszdajw7UcqzZF09VkYmujX5HRJRXfQaw@mail.gmail.com>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>
	<CAF8bMcbAmS5=syLgngszdajw7UcqzZF09VkYmujX5HRJRXfQaw@mail.gmail.com>
Message-ID: <001b01d05327$bd343690$379ca3b0$@gmail.com>

Many thanks. Unfortunately, I cannot work directly on these expressions since they?re only created from other strings. Would I first have to transform these strings to unevaluated expressions? 
 
Von: William Dunlap [mailto:wdunlap at tibco.com] 
Gesendet: Freitag, 27. Februar 2015 23:39
An: Alrik Thiem
Cc: r-help at r-project.org
Betreff: Re: [R] Substring replacement in string
 
If your string will always represent an R expression, you could work with
the expression directly with functions like all.names() and substitute().
 
f <- function (expr) 
{
    toReplace <- setdiff(all.names(expr), c("pmin", "pmax"))
    toReplace <- grep(value = TRUE, "[a-z]", toReplace)
    names(toReplace) <- toReplace
    replacementList <- lapply(toReplace, function(name) call("-", 
        1, as.name(toupper(name))))
    do.call(substitute, list(expr, replacementList))
}
 
> In <- quote(pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1)))
> Desired <- quote(pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1)))
> all.equal(Desired, f(In))
[1] TRUE
 
 
 
 


Bill Dunlap
TIBCO Software
wdunlap tibco.com
 
On Fri, Feb 27, 2015 at 2:19 PM, Alrik Thiem <alrik.thiem at gmail.com> wrote:
Dear R-help list,

I would like to replace all lower-case letters in a string that are not part
of certain fixed expressions. For example, I have the string:

"pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"

Where I would like to replace all lower-case letters that do not belong to
the functions "pmin" and "pmax" by 1 - toupper(...) to get

"pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"

Any ideas on how I could achieve that?

Many thanks and best wishes,

Alrik


********************************
Alrik Thiem
Post-Doctoral Researcher

Department of Philosophy
University of Geneva
Rue de Candolle 2
CH-1211 Geneva

+41 76 527 80 83

http://www.alrik-thiem.net
http://www.compasss.org

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Sat Feb 28 13:35:01 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 28 Feb 2015 07:35:01 -0500
Subject: [R] Substring replacement in string
In-Reply-To: <027d01d052db$7faa3140$7efe93c0$@gmail.com>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>
Message-ID: <CAP01uRnAuV7k2aLLK-BorD36tXP_X3Y3Y2jJUov1QmB-v7QqEQ@mail.gmail.com>

On Fri, Feb 27, 2015 at 5:19 PM, Alrik Thiem <alrik.thiem at gmail.com> wrote:
> I would like to replace all lower-case letters in a string that are not part
> of certain fixed expressions. For example, I have the string:
>
> "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
>
> Where I would like to replace all lower-case letters that do not belong to
> the functions "pmin" and "pmax" by 1 - toupper(...) to get
>
> "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"
>

Assuming x is the input string:

gsub("(\\b[a-oq-z][a-z0-9]+)", "1-\\U\\1", x, perl = TRUE)
## [1] "pmin(pmax(pmin(1-X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1-Z1))"



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From pertsou at gmail.com  Sat Feb 28 13:38:50 2015
From: pertsou at gmail.com (Endy BlackEndy)
Date: Sat, 28 Feb 2015 14:38:50 +0200
Subject: [R] Package survMisc
Message-ID: <CAGpBJKQLvgD52xAtkcTEN2yqSSHaM0cSft1uAZOnpKrqbk4u6w@mail.gmail.com>

Hi R users. I have some problems with the package ?survMisc?. When I am
loading it I am getting the following



> library(survMisc)

Loading required package: survival

Loading required package: splines

Loading required package: km.ci

Loading required package: ggplot2

Loading required package: data.table

data.table 1.9.4  For help type: ?data.table

*** NB: by=.EACHI is now explicit. See README to restore previous behaviour.

Loading required package: gridExtra

Loading required package: grid

Loading required package: rpart



Attaching package: ?survMisc?



The following objects are masked from ?package:stats?:



    AIC, BIC, median, quantile



   In the above output I noticed the line with the three stars (*). In
order to restore the data.table in its previous behavior I tried to locate
the README file but I couldn?t.

   I ignored that NB in the previous output and I continue to run the
example given in the above mentioned package for the routine comp(). The
commands and the output are given below.

> ### 2 curves

> data(kidney,package="KMsurv")

> s1 <- survfit(Surv(time=time, event=delta) ~ type, data=kidney )

> comp(s1)

$tne

       t          n          e   n_type=1   e_type=1   n_type=2   e_type=2

 1:  1.5    86         2       43                1
43                1

 2:  3.5    80         2       40                1
40                1

 3:  4.5    72         4       36                2
36                2

 4:  5.5    66         2       33                1
33                1

 5:  8.5    60         4       30                2                  30
           2

 6:  9.5    54         2       27                1
27                1

 7: 10.5   50         2       25                1
25                1

 8: 11.5    44         2       22               1
22                1

 9: 15.5    28         4       14               2
14                2

10: 16.5   26         2       13               1
13                1

11: 18.5   22         2       11               1
  11                1

12: 23.5     8         2        4                 1
4                1

13: 26.5     6         2        3                 1
3                1



$tests

$tests$lrTests

                                                        ChiSq df p

Log-rank                                                0  1 1

Gehan-Breslow (mod~ Wilcoxon)             0  1 1

Tarone-Ware                                          0  1 1

Peto-Peto                                              0  1 1

Mod~ Peto-Peto (Andersen)                    0  1 1

Flem~-Harr~ with p=1, q=1                      0  1 1



$tests$supTests

                                                             Q p

Log-rank                                                 0 1

Gehan-Breslow (mod~ Wilcoxon)              0 1

Tarone-Ware                                           0 1

Peto-Peto                                               0 1

Mod~ Peto-Peto (Andersen)                     0 1

Renyi Flem~-Harr~ with p=1, q=1             0 1



Notice the zeros (0) that corresponds to the test statistics. (To my
opinion those zeros are strongly related to the NB above).

   Next I noticed the following strange, to my opinion, thing.  More
precisely I have written the following
routine


proc<-function(){

 rm(list=ls())

 library(survMisc)

 d<-read.table("C:\\Program
Files\\R\\Data\\Survival\\HosmLem.txt",fill=TRUE,header=TRUE)

 d4<-as.factor(d[,4])

 s<-survfit(Surv(d[,2], d[,5])~d4)

 ctest<-comp(s)$tests

 print(ctest)

}

The data used are those of Hosmer and Lemeshow book on Applied Survival
Analysis. The first rows of this data set follow.

id Time Age Drug Censor    entdate    enddate

  1    5  46    0      1   05/15/1990 10/14/1990

  2    6  35    1      0   09/19/1989 03/20/1990

  3    8  30    1      1   04/21/1991 12/20/1991

  4    3  30    1      1   01/03/1991 04/04/1991

  5   22  36    0      1   09/18/1989 07/19/1991

  6    1  32    1      0    03/18/1991 04/17/1991

When I run the function proc() I am getting the answer

> proc()

Error in Surv(d[, 2], d[, 5]) : object 'd' not found

In contrast when I run the same routine command-by-command I am getting the
following output

$lrTests

                                                         ChiSq df p

Log-rank                                                 0  1 1

Gehan-Breslow (mod~ Wilcoxon)              0  1 1

Tarone-Ware                                           0  1 1

Peto-Peto                                               0  1 1

Mod~ Peto-Peto (Andersen)                     0  1 1

Flem~-Harr~ with p=1, q=1                       0  1 1



$supTests

                                                              Q p

Log-rank                                                  0 1

Gehan-Breslow (mod~ Wilcoxon)               0 1

Tarone-Ware                                            0 1

Peto-Peto                                                0 1

Mod~ Peto-Peto (Andersen)                      0 1

Renyi Flem~-Harr~ with p=1, q=1              0 1

Any assistance will greatly appreciated.

Cheers

Endy

I am using the

R version 3.1.1 (2014-07-10) -- "Sock it to Me"

Copyright (C) 2014 The R Foundation for Statistical Computing

Platform: i386-w64-mingw32/i386 (32-bit)

	[[alternative HTML version deleted]]


From alrik.thiem at gmail.com  Sat Feb 28 14:16:07 2015
From: alrik.thiem at gmail.com (Alrik Thiem)
Date: Sat, 28 Feb 2015 14:16:07 +0100
Subject: [R] Substring replacement in string
In-Reply-To: <CAP01uRnAuV7k2aLLK-BorD36tXP_X3Y3Y2jJUov1QmB-v7QqEQ@mail.gmail.com>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>
	<CAP01uRnAuV7k2aLLK-BorD36tXP_X3Y3Y2jJUov1QmB-v7QqEQ@mail.gmail.com>
Message-ID: <00b301d05358$b743b680$25cb2380$@gmail.com>

Dear Gabor,

Many thanks. Works like a charm, but I can't get it to work with

"pmin(pmax(pmin(a,B),pmin(a,C,d))==Y,pmax(E,e))"

i.e., with strings where there're no integers following the components in the pmin/pmax functions. Could this be generalized to handle both cases?

Best wishes,
Alrik

-----Urspr?ngliche Nachricht-----
Von: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Gesendet: Samstag, 28. Februar 2015 13:35
An: Alrik Thiem
Cc: r-help at r-project.org
Betreff: Re: [R] Substring replacement in string

On Fri, Feb 27, 2015 at 5:19 PM, Alrik Thiem <alrik.thiem at gmail.com> wrote:
> I would like to replace all lower-case letters in a string that are not part
> of certain fixed expressions. For example, I have the string:
>
> "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
>
> Where I would like to replace all lower-case letters that do not belong to
> the functions "pmin" and "pmax" by 1 - toupper(...) to get
>
> "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"
>

Assuming x is the input string:

gsub("(\\b[a-oq-z][a-z0-9]+)", "1-\\U\\1", x, perl = TRUE)
## [1] "pmin(pmax(pmin(1-X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1-Z1))"



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From phaedrusv at gmail.com  Sat Feb 28 14:46:37 2015
From: phaedrusv at gmail.com (Sun Shine)
Date: Sat, 28 Feb 2015 13:46:37 +0000
Subject: [R] Using a text file as a removeWord dictionary in tm_map
Message-ID: <54F1C6BD.5000401@gmail.com>

Hi list

Although this query applies specifically to the tm package, perhaps it's 
something that others might be able to lend a thought to.

Using tm to do some initial text mining, I want to include an external 
(to R) generated dictionary of words that I want removed from the corpus.

I have created a comma separated list of terms in " " marks in a 
stopList.txt plain UTF-8 file. I want to read this into R, so do:

 > stopDict <- read.table('~/path/to/file/stopList.txt', sep=',')

When I want to load it as part of the removeWords function in tm, I do:

 > docs <- tm_map(docs, removeWords, stopDict)

which has no effect. Neither does:

 > docs <- tm_map(docs, removeWords, c(stopDict))

What am I not seeing/ doing?

How do I pass a text file with pre-defined terms to the removeWords 
transform of tm?

Thanks for any ideas.

Cheers

Sun


From info at aghmed.fsnet.co.uk  Sat Feb 28 14:49:51 2015
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sat, 28 Feb 2015 13:49:51 +0000
Subject: [R] Substring replacement in string
In-Reply-To: <00b301d05358$b743b680$25cb2380$@gmail.com>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>	<CAP01uRnAuV7k2aLLK-BorD36tXP_X3Y3Y2jJUov1QmB-v7QqEQ@mail.gmail.com>
	<00b301d05358$b743b680$25cb2380$@gmail.com>
Message-ID: <54F1C77F.50105@aghmed.fsnet.co.uk>

Dear Alrik

This may seem a silly suggestion but why not just define new functions 
PMIN and PMAX to call pmin and pmax. Obviously that does not solve your 
problem if it is more general than your example.

On 28/02/2015 13:16, Alrik Thiem wrote:
> Dear Gabor,
>
> Many thanks. Works like a charm, but I can't get it to work with
>
> "pmin(pmax(pmin(a,B),pmin(a,C,d))==Y,pmax(E,e))"
>
> i.e., with strings where there're no integers following the components in the pmin/pmax functions. Could this be generalized to handle both cases?
>
> Best wishes,
> Alrik
>
> -----Urspr?ngliche Nachricht-----
> Von: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Gesendet: Samstag, 28. Februar 2015 13:35
> An: Alrik Thiem
> Cc: r-help at r-project.org
> Betreff: Re: [R] Substring replacement in string
>
> On Fri, Feb 27, 2015 at 5:19 PM, Alrik Thiem <alrik.thiem at gmail.com> wrote:
>> I would like to replace all lower-case letters in a string that are not part
>> of certain fixed expressions. For example, I have the string:
>>
>> "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
>>
>> Where I would like to replace all lower-case letters that do not belong to
>> the functions "pmin" and "pmax" by 1 - toupper(...) to get
>>
>> "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"
>>
>
> Assuming x is the input string:
>
> gsub("(\\b[a-oq-z][a-z0-9]+)", "1-\\U\\1", x, perl = TRUE)
> ## [1] "pmin(pmax(pmin(1-X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1-Z1))"
>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From alrik.thiem at gmail.com  Sat Feb 28 15:34:24 2015
From: alrik.thiem at gmail.com (Alrik Thiem)
Date: Sat, 28 Feb 2015 15:34:24 +0100
Subject: [R] Substring replacement in string
In-Reply-To: <54F1C77F.50105@aghmed.fsnet.co.uk>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>	<CAP01uRnAuV7k2aLLK-BorD36tXP_X3Y3Y2jJUov1QmB-v7QqEQ@mail.gmail.com>
	<00b301d05358$b743b680$25cb2380$@gmail.com>
	<54F1C77F.50105@aghmed.fsnet.co.uk>
Message-ID: <00b501d05363$a686e370$f394aa50$@gmail.com>

Dear Michael

I'm not sure how you mean this. Maybe a more general description of my problem is helpful for clarifying.

What I have to deal with are truth table output functions that always take, for example, the following form:

Delta <- "(a*B+a*C*d<=>Y)*(E+e)"

I.e. these functions will always have the structure (.*.+.*.+...<=>.)*(.+.), where the dots in the antecedent could be further conjunctions of unspecified complexity. I now need to filter all rows from the truth table that are compatible with this output function. To create the input part of the truth table "tt" for Delta above, I do:

library(QCA) # createMatrix() function is part of this package
Delta.upper <- toupper(Delta)
f.names <- unique(unlist(strsplit(Delta.upper, "[(*+<=>)]")))
f.names <- f.names[f.names != ""]
tt <- data.frame(createMatrix(rep(2, length(f.names))))
dimnames(tt) <- list(as.character(seq(2^length(f.names))), f.names)
tt

> tt
   A B C D Y E
1  0 0 0 0 0 0
2  0 0 0 0 0 1
.  . . . . . .
63 1 1 1 1 1 0
64 1 1 1 1 1 1

I now need to transform Delta into a string of the following form in order to extract the subset of compatible rows from "tt":

"pmin(pmax(pmin(1-tt$A,tt$B),pmin(1-tt$A,tt$C,1-tt$D))==tt$Y,pmax(tt$E,1-tt$E))==TRUE"

With this string, I can then do:

> tt[pmin(pmax(pmin(1-tt$A,tt$B), pmin(1-tt$A,tt$C,1-tt$D))==tt$Y,pmax(tt$E,1-tt$E))==TRUE, ]
   A B C D Y E
1  0 0 0 0 0 0
2  0 0 0 0 0 1
.  . . . . . .
61 1 1 1 1 0 0
62 1 1 1 1 0 1

-----Urspr?ngliche Nachricht-----
Von: Michael Dewey [mailto:info at aghmed.fsnet.co.uk] 
Gesendet: Samstag, 28. Februar 2015 14:50
An: Alrik Thiem
Cc: r-help at r-project.org
Betreff: Re: [R] Substring replacement in string

Dear Alrik

This may seem a silly suggestion but why not just define new functions 
PMIN and PMAX to call pmin and pmax. Obviously that does not solve your 
problem if it is more general than your example.

On 28/02/2015 13:16, Alrik Thiem wrote:
> Dear Gabor,
>
> Many thanks. Works like a charm, but I can't get it to work with
>
> "pmin(pmax(pmin(a,B),pmin(a,C,d))==Y,pmax(E,e))"
>
> i.e., with strings where there're no integers following the components in the pmin/pmax functions. Could this be generalized to handle both cases?
>
> Best wishes,
> Alrik
>
> -----Urspr?ngliche Nachricht-----
> Von: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Gesendet: Samstag, 28. Februar 2015 13:35
> An: Alrik Thiem
> Cc: r-help at r-project.org
> Betreff: Re: [R] Substring replacement in string
>
> On Fri, Feb 27, 2015 at 5:19 PM, Alrik Thiem <alrik.thiem at gmail.com> wrote:
>> I would like to replace all lower-case letters in a string that are not part
>> of certain fixed expressions. For example, I have the string:
>>
>> "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
>>
>> Where I would like to replace all lower-case letters that do not belong to
>> the functions "pmin" and "pmax" by 1 - toupper(...) to get
>>
>> "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"
>>
>
> Assuming x is the input string:
>
> gsub("(\\b[a-oq-z][a-z0-9]+)", "1-\\U\\1", x, perl = TRUE)
> ## [1] "pmin(pmax(pmin(1-X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1-Z1))"
>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From wdunlap at tibco.com  Sat Feb 28 15:46:24 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 28 Feb 2015 06:46:24 -0800
Subject: [R] Substring replacement in string
In-Reply-To: <001b01d05327$bd343690$379ca3b0$@gmail.com>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>
	<CAF8bMcbAmS5=syLgngszdajw7UcqzZF09VkYmujX5HRJRXfQaw@mail.gmail.com>
	<001b01d05327$bd343690$379ca3b0$@gmail.com>
Message-ID: <CAF8bMcb4aNyGMzz5s_T9W4enAEJav6y6F-deRNztjvJghVzA-Q@mail.gmail.com>

  string <- "pmin(1, x)"
  expr <- parse(text=string)[[1]]

will convert the string to an unevaluated language object.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Feb 27, 2015 at 11:25 PM, Alrik Thiem <alrik.thiem at gmail.com> wrote:

> Many thanks. Unfortunately, I cannot work directly on these expressions
> since they?re only created from other strings. Would I first have to
> transform these strings to unevaluated expressions?
>
>
>
> *Von:* William Dunlap [mailto:wdunlap at tibco.com]
> *Gesendet**:* Freitag, 27. Februar 2015 23:39
> *An:* Alrik Thiem
> *Cc:* r-help at r-project.org
> *Betreff:* Re: [R] Substring replacement in string
>
>
>
> If your string will always represent an R expression, you could work with
>
> the expression directly with functions like all.names() and substitute().
>
>
>
> f <- function (expr)
>
> {
>
>     toReplace <- setdiff(all.names(expr), c("pmin", "pmax"))
>
>     toReplace <- grep(value = TRUE, "[a-z]", toReplace)
>
>     names(toReplace) <- toReplace
>
>     replacementList <- lapply(toReplace, function(name) call("-",
>
>         1, as.name(toupper(name))))
>
>     do.call(substitute, list(expr, replacementList))
>
> }
>
>
>
> > In <- quote(pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1)))
>
> > Desired <- quote(pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y,
> pmax(Z1, 1 - Z1)))
>
> > all.equal(Desired, f(In))
>
> [1] TRUE
>
>
>
>
>
>
>
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
>
> On Fri, Feb 27, 2015 at 2:19 PM, Alrik Thiem <alrik.thiem at gmail.com>
> wrote:
>
> Dear R-help list,
>
> I would like to replace all lower-case letters in a string that are not
> part
> of certain fixed expressions. For example, I have the string:
>
> "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
>
> Where I would like to replace all lower-case letters that do not belong to
> the functions "pmin" and "pmax" by 1 - toupper(...) to get
>
> "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"
>
> Any ideas on how I could achieve that?
>
> Many thanks and best wishes,
>
> Alrik
>
>
> ********************************
> Alrik Thiem
> Post-Doctoral Researcher
>
> Department of Philosophy
> University of Geneva
> Rue de Candolle 2
> CH-1211 Geneva
>
> +41 76 527 80 83
>
> http://www.alrik-thiem.net
> http://www.compasss.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sat Feb 28 15:51:30 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 28 Feb 2015 06:51:30 -0800
Subject: [R] title of r plots
In-Reply-To: <CAHLnndaJ7iyf0JGNQrY4g61LnDGLvHUFuYHiYUWFB-2WQ1WviQ@mail.gmail.com>
References: <CAHLnndYzBDwkGB10h+hcJU=9i_MnsE1S4hXSjOsUx3+9JPqgKQ@mail.gmail.com>
	<CAHLnndZtc5+tW3CP4x+FY0EahDM3Y1td0k3VrJxQSf1KXmDn=w@mail.gmail.com>
	<CAF8bMcYWokT3pK918=bL8sK8SidF4XRyfvzNc0RKyK19ZT7YwQ@mail.gmail.com>
	<CAHLnndaJ7iyf0JGNQrY4g61LnDGLvHUFuYHiYUWFB-2WQ1WviQ@mail.gmail.com>
Message-ID: <CAF8bMcZoL_8F=vrx4BE+Y9siy78B-sVBUmScHD4VC56oVvUn2A@mail.gmail.com>

Use help("plotmath") to see all the details - you can use tildes for spaces,
asterisks for no spaces.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Feb 27, 2015 at 8:52 PM, li li <hannah.hlx at gmail.com> wrote:

>
> Thanks very much.
> Also How do add an empty space when using expression()?
> When I do the following, it returns an error message.
>
>
> plot(1,1,main=expression(-70*degree*C%+-%10*degree*C/Ambient Condition))
>
>
>
>    Hanna
>
>
> 2015-02-27 23:03 GMT-05:00 William Dunlap <wdunlap at tibco.com>:
>
>>  plot(1,1,main=expression(-70*degree*C%+-%10*degree*C/Ambient))
>>
>>  Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>  On Fri, Feb 27, 2015 at 7:27 PM, li li <hannah.hlx at gmail.com> wrote:
>>
>>>   Hi all,
>>>   I would like to add "-70?C ? 10?C/Ambient"  as the title of my plot.
>>> Could anyone give some help on this?
>>>   Thanks.
>>>    Hanna
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> <http://www.r-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>

	[[alternative HTML version deleted]]


From info at aghmed.fsnet.co.uk  Sat Feb 28 17:31:12 2015
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sat, 28 Feb 2015 16:31:12 +0000
Subject: [R] Substring replacement in string
In-Reply-To: <00b501d05363$a686e370$f394aa50$@gmail.com>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>	<CAP01uRnAuV7k2aLLK-BorD36tXP_X3Y3Y2jJUov1QmB-v7QqEQ@mail.gmail.com>
	<00b301d05358$b743b680$25cb2380$@gmail.com>
	<54F1C77F.50105@aghmed.fsnet.co.uk>
	<00b501d05363$a686e370$f394aa50$@gmail.com>
Message-ID: <54F1ED50.5020206@aghmed.fsnet.co.uk>

Your original problem statement seemed to me to be one of wanting to 
transform all the lower case identifiers to upper except for pmin and 
pmax. My suggestion was not to bother and transform everything and then 
define PMIN and PMAX.

On 28/02/2015 14:34, Alrik Thiem wrote:
> Dear Michael
>
> I'm not sure how you mean this. Maybe a more general description of my problem is helpful for clarifying.
>
> What I have to deal with are truth table output functions that always take, for example, the following form:
>
> Delta <- "(a*B+a*C*d<=>Y)*(E+e)"
>
> I.e. these functions will always have the structure (.*.+.*.+...<=>.)*(.+.), where the dots in the antecedent could be further conjunctions of unspecified complexity. I now need to filter all rows from the truth table that are compatible with this output function. To create the input part of the truth table "tt" for Delta above, I do:
>
> library(QCA) # createMatrix() function is part of this package
> Delta.upper <- toupper(Delta)
> f.names <- unique(unlist(strsplit(Delta.upper, "[(*+<=>)]")))
> f.names <- f.names[f.names != ""]
> tt <- data.frame(createMatrix(rep(2, length(f.names))))
> dimnames(tt) <- list(as.character(seq(2^length(f.names))), f.names)
> tt
>
>> tt
>     A B C D Y E
> 1  0 0 0 0 0 0
> 2  0 0 0 0 0 1
> .  . . . . . .
> 63 1 1 1 1 1 0
> 64 1 1 1 1 1 1
>
> I now need to transform Delta into a string of the following form in order to extract the subset of compatible rows from "tt":
>
> "pmin(pmax(pmin(1-tt$A,tt$B),pmin(1-tt$A,tt$C,1-tt$D))==tt$Y,pmax(tt$E,1-tt$E))==TRUE"
>
> With this string, I can then do:
>
>> tt[pmin(pmax(pmin(1-tt$A,tt$B), pmin(1-tt$A,tt$C,1-tt$D))==tt$Y,pmax(tt$E,1-tt$E))==TRUE, ]
>     A B C D Y E
> 1  0 0 0 0 0 0
> 2  0 0 0 0 0 1
> .  . . . . . .
> 61 1 1 1 1 0 0
> 62 1 1 1 1 0 1
>
> -----Urspr?ngliche Nachricht-----
> Von: Michael Dewey [mailto:info at aghmed.fsnet.co.uk]
> Gesendet: Samstag, 28. Februar 2015 14:50
> An: Alrik Thiem
> Cc: r-help at r-project.org
> Betreff: Re: [R] Substring replacement in string
>
> Dear Alrik
>
> This may seem a silly suggestion but why not just define new functions
> PMIN and PMAX to call pmin and pmax. Obviously that does not solve your
> problem if it is more general than your example.
>
> On 28/02/2015 13:16, Alrik Thiem wrote:
>> Dear Gabor,
>>
>> Many thanks. Works like a charm, but I can't get it to work with
>>
>> "pmin(pmax(pmin(a,B),pmin(a,C,d))==Y,pmax(E,e))"
>>
>> i.e., with strings where there're no integers following the components in the pmin/pmax functions. Could this be generalized to handle both cases?
>>
>> Best wishes,
>> Alrik
>>
>> -----Urspr?ngliche Nachricht-----
>> Von: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
>> Gesendet: Samstag, 28. Februar 2015 13:35
>> An: Alrik Thiem
>> Cc: r-help at r-project.org
>> Betreff: Re: [R] Substring replacement in string
>>
>> On Fri, Feb 27, 2015 at 5:19 PM, Alrik Thiem <alrik.thiem at gmail.com> wrote:
>>> I would like to replace all lower-case letters in a string that are not part
>>> of certain fixed expressions. For example, I have the string:
>>>
>>> "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
>>>
>>> Where I would like to replace all lower-case letters that do not belong to
>>> the functions "pmin" and "pmax" by 1 - toupper(...) to get
>>>
>>> "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"
>
>>>
>>
>> Assuming x is the input string:
>>
>> gsub("(\\b[a-oq-z][a-z0-9]+)", "1-\\U\\1", x, perl = TRUE)
>> ## [1] "pmin(pmax(pmin(1-X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1-Z1))"
>>
>>
>>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From alrik.thiem at gmail.com  Sat Feb 28 17:38:06 2015
From: alrik.thiem at gmail.com (Alrik Thiem)
Date: Sat, 28 Feb 2015 17:38:06 +0100
Subject: [R] Substring replacement in string
In-Reply-To: <54F1ED50.5020206@aghmed.fsnet.co.uk>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>	<CAP01uRnAuV7k2aLLK-BorD36tXP_X3Y3Y2jJUov1QmB-v7QqEQ@mail.gmail.com>
	<00b301d05358$b743b680$25cb2380$@gmail.com>
	<54F1C77F.50105@aghmed.fsnet.co.uk>
	<00b501d05363$a686e370$f394aa50$@gmail.com>
	<54F1ED50.5020206@aghmed.fsnet.co.uk>
Message-ID: <000001d05374$ef6d16c0$ce474440$@gmail.com>

Ah, I see what you mean. Thanks for suggesting. I'll try.

-----Urspr?ngliche Nachricht-----
Von: Michael Dewey [mailto:info at aghmed.fsnet.co.uk] 
Gesendet: Samstag, 28. Februar 2015 17:31
An: Alrik Thiem
Cc: r-help at r-project.org
Betreff: Re: AW: [R] Substring replacement in string

Your original problem statement seemed to me to be one of wanting to 
transform all the lower case identifiers to upper except for pmin and 
pmax. My suggestion was not to bother and transform everything and then 
define PMIN and PMAX.

On 28/02/2015 14:34, Alrik Thiem wrote:
> Dear Michael
>
> I'm not sure how you mean this. Maybe a more general description of my problem is helpful for clarifying.
>
> What I have to deal with are truth table output functions that always take, for example, the following form:
>
> Delta <- "(a*B+a*C*d<=>Y)*(E+e)"
>
> I.e. these functions will always have the structure (.*.+.*.+...<=>.)*(.+.), where the dots in the antecedent could be further conjunctions of unspecified complexity. I now need to filter all rows from the truth table that are compatible with this output function. To create the input part of the truth table "tt" for Delta above, I do:
>
> library(QCA) # createMatrix() function is part of this package
> Delta.upper <- toupper(Delta)
> f.names <- unique(unlist(strsplit(Delta.upper, "[(*+<=>)]")))
> f.names <- f.names[f.names != ""]
> tt <- data.frame(createMatrix(rep(2, length(f.names))))
> dimnames(tt) <- list(as.character(seq(2^length(f.names))), f.names)
> tt
>
>> tt
>     A B C D Y E
> 1  0 0 0 0 0 0
> 2  0 0 0 0 0 1
> .  . . . . . .
> 63 1 1 1 1 1 0
> 64 1 1 1 1 1 1
>
> I now need to transform Delta into a string of the following form in order to extract the subset of compatible rows from "tt":
>
> "pmin(pmax(pmin(1-tt$A,tt$B),pmin(1-tt$A,tt$C,1-tt$D))==tt$Y,pmax(tt$E,1-tt$E))==TRUE"
>
> With this string, I can then do:
>
>> tt[pmin(pmax(pmin(1-tt$A,tt$B), pmin(1-tt$A,tt$C,1-tt$D))==tt$Y,pmax(tt$E,1-tt$E))==TRUE, ]
>     A B C D Y E
> 1  0 0 0 0 0 0
> 2  0 0 0 0 0 1
> .  . . . . . .
> 61 1 1 1 1 0 0
> 62 1 1 1 1 0 1
>
> -----Urspr?ngliche Nachricht-----
> Von: Michael Dewey [mailto:info at aghmed.fsnet.co.uk]
> Gesendet: Samstag, 28. Februar 2015 14:50
> An: Alrik Thiem
> Cc: r-help at r-project.org
> Betreff: Re: [R] Substring replacement in string
>
> Dear Alrik
>
> This may seem a silly suggestion but why not just define new functions
> PMIN and PMAX to call pmin and pmax. Obviously that does not solve your
> problem if it is more general than your example.
>
> On 28/02/2015 13:16, Alrik Thiem wrote:
>> Dear Gabor,
>>
>> Many thanks. Works like a charm, but I can't get it to work with
>>
>> "pmin(pmax(pmin(a,B),pmin(a,C,d))==Y,pmax(E,e))"
>>
>> i.e., with strings where there're no integers following the components in the pmin/pmax functions. Could this be generalized to handle both cases?
>>
>> Best wishes,
>> Alrik
>>
>> -----Urspr?ngliche Nachricht-----
>> Von: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
>> Gesendet: Samstag, 28. Februar 2015 13:35
>> An: Alrik Thiem
>> Cc: r-help at r-project.org
>> Betreff: Re: [R] Substring replacement in string
>>
>> On Fri, Feb 27, 2015 at 5:19 PM, Alrik Thiem <alrik.thiem at gmail.com> wrote:
>>> I would like to replace all lower-case letters in a string that are not part
>>> of certain fixed expressions. For example, I have the string:
>>>
>>> "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
>>>
>>> Where I would like to replace all lower-case letters that do not belong to
>>> the functions "pmin" and "pmax" by 1 - toupper(...) to get
>>>
>>> "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"
>
>>>
>>
>> Assuming x is the input string:
>>
>> gsub("(\\b[a-oq-z][a-z0-9]+)", "1-\\U\\1", x, perl = TRUE)
>> ## [1] "pmin(pmax(pmin(1-X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1-Z1))"
>>
>>
>>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From js.huang at protective.com  Fri Feb 27 22:09:29 2015
From: js.huang at protective.com (JS Huang)
Date: Fri, 27 Feb 2015 13:09:29 -0800 (PST)
Subject: [R] evaluate logical expressions
In-Reply-To: <1425058626087-4703964.post@n4.nabble.com>
References: <1425058626087-4703964.post@n4.nabble.com>
Message-ID: <1425071369072-4703970.post@n4.nabble.com>

Hi,

  I assume input y to wrapper <- function(y) {function(x) {(y)}} is a
function.  In the statement to assign gfunc[[i]]<-
gsub("(Gene)([[:digit:]])", "x[\\2]", func[[i]]) the mode of
gsub("(Gene)([[:digit:]])", "x[\\2]", func[[i]]) is character.  Is this the
issue?



--
View this message in context: http://r.789695.n4.nabble.com/evaluate-logical-expressions-tp4703964p4703970.html
Sent from the R help mailing list archive at Nabble.com.


From ggrothendieck at gmail.com  Sat Feb 28 19:29:37 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 28 Feb 2015 13:29:37 -0500
Subject: [R] Substring replacement in string
In-Reply-To: <00b301d05358$b743b680$25cb2380$@gmail.com>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>
	<CAP01uRnAuV7k2aLLK-BorD36tXP_X3Y3Y2jJUov1QmB-v7QqEQ@mail.gmail.com>
	<00b301d05358$b743b680$25cb2380$@gmail.com>
Message-ID: <CAP01uRmUux4OYv8u9tc=Or1eCZ1B1UsNXf=rNyPumYYXDYA7CA@mail.gmail.com>

Replace the + (i.e. 1 or more) in the pattern with a * (i.e. 0 or more):

   x <- "pmin(pmax(pmin(a,B),pmin(a,C,d))==Y,pmax(E,e))"

   gsub("(\\b[a-oq-z][a-z0-9]*)", "1-\\U\\1", x, perl = TRUE)

giving:

   [1] "pmin(pmax(pmin(1-A,B),pmin(1-A,C,1-D))==Y,pmax(E,1-E))"

Here is a visualization of the regular expression:

   https://www.debuggex.com/i/5ByOCQS2zIdPEf-f.png


On Sat, Feb 28, 2015 at 8:16 AM, Alrik Thiem <alrik.thiem at gmail.com> wrote:
> Dear Gabor,
>
> Many thanks. Works like a charm, but I can't get it to work with
>
> "pmin(pmax(pmin(a,B),pmin(a,C,d))==Y,pmax(E,e))"
>
> i.e., with strings where there're no integers following the components in the pmin/pmax functions. Could this be generalized to handle both cases?
>
> Best wishes,
> Alrik
>
> -----Urspr?ngliche Nachricht-----
> Von: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Gesendet: Samstag, 28. Februar 2015 13:35
> An: Alrik Thiem
> Cc: r-help at r-project.org
> Betreff: Re: [R] Substring replacement in string
>
> On Fri, Feb 27, 2015 at 5:19 PM, Alrik Thiem <alrik.thiem at gmail.com> wrote:
>> I would like to replace all lower-case letters in a string that are not part
>> of certain fixed expressions. For example, I have the string:
>>
>> "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
>>
>> Where I would like to replace all lower-case letters that do not belong to
>> the functions "pmin" and "pmax" by 1 - toupper(...) to get
>>
>> "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"
>>
>
> Assuming x is the input string:
>
> gsub("(\\b[a-oq-z][a-z0-9]+)", "1-\\U\\1", x, perl = TRUE)
> ## [1] "pmin(pmax(pmin(1-X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1-Z1))"
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From alrik.thiem at gmail.com  Sat Feb 28 19:41:51 2015
From: alrik.thiem at gmail.com (Alrik Thiem)
Date: Sat, 28 Feb 2015 19:41:51 +0100
Subject: [R] Substring replacement in string
In-Reply-To: <CAP01uRmUux4OYv8u9tc=Or1eCZ1B1UsNXf=rNyPumYYXDYA7CA@mail.gmail.com>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>
	<CAP01uRnAuV7k2aLLK-BorD36tXP_X3Y3Y2jJUov1QmB-v7QqEQ@mail.gmail.com>
	<00b301d05358$b743b680$25cb2380$@gmail.com>
	<CAP01uRmUux4OYv8u9tc=Or1eCZ1B1UsNXf=rNyPumYYXDYA7CA@mail.gmail.com>
Message-ID: <000201d05386$384c4530$a8e4cf90$@gmail.com>

Dear Gabor,

That works perfectly! 

Many thanks and best wishes,
Alrik

-----Urspr?ngliche Nachricht-----
Von: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Gesendet: Samstag, 28. Februar 2015 19:30
An: Alrik Thiem
Cc: r-help at r-project.org
Betreff: Re: [R] Substring replacement in string

Replace the + (i.e. 1 or more) in the pattern with a * (i.e. 0 or more):

   x <- "pmin(pmax(pmin(a,B),pmin(a,C,d))==Y,pmax(E,e))"

   gsub("(\\b[a-oq-z][a-z0-9]*)", "1-\\U\\1", x, perl = TRUE)

giving:

   [1] "pmin(pmax(pmin(1-A,B),pmin(1-A,C,1-D))==Y,pmax(E,1-E))"

Here is a visualization of the regular expression:

   https://www.debuggex.com/i/5ByOCQS2zIdPEf-f.png


On Sat, Feb 28, 2015 at 8:16 AM, Alrik Thiem <alrik.thiem at gmail.com> wrote:
> Dear Gabor,
>
> Many thanks. Works like a charm, but I can't get it to work with
>
> "pmin(pmax(pmin(a,B),pmin(a,C,d))==Y,pmax(E,e))"
>
> i.e., with strings where there're no integers following the components in the pmin/pmax functions. Could this be generalized to handle both cases?
>
> Best wishes,
> Alrik
>
> -----Urspr?ngliche Nachricht-----
> Von: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Gesendet: Samstag, 28. Februar 2015 13:35
> An: Alrik Thiem
> Cc: r-help at r-project.org
> Betreff: Re: [R] Substring replacement in string
>
> On Fri, Feb 27, 2015 at 5:19 PM, Alrik Thiem <alrik.thiem at gmail.com> wrote:
>> I would like to replace all lower-case letters in a string that are not part
>> of certain fixed expressions. For example, I have the string:
>>
>> "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
>>
>> Where I would like to replace all lower-case letters that do not belong to
>> the functions "pmin" and "pmax" by 1 - toupper(...) to get
>>
>> "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"
>>
>
> Assuming x is the input string:
>
> gsub("(\\b[a-oq-z][a-z0-9]+)", "1-\\U\\1", x, perl = TRUE)
> ## [1] "pmin(pmax(pmin(1-X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1-Z1))"
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From r.turner at auckland.ac.nz  Sat Feb 28 22:10:20 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 01 Mar 2015 10:10:20 +1300
Subject: [R] Firefox not showing R help.
Message-ID: <54F22EBC.1070400@auckland.ac.nz>


Firefox recently updated itself on my laptop.  Now when I ask for R help 
--- e.g. ?plot --- I just get my home page. And no help. If I do "?plot" 
again after Firefox has opened its window, I just get yet another 
Firefox window, opened to my home page.  (I have my preferences set to

     "When Firefox starts Show my homepage"

--- as I always have had in the past.)

The Firefox that I am currently running is (according Firefox help
--> "About Firefox") is version 36.0.

Can anyone suggest to me how I can get my html R help back?

For what it's worth:  I am using Linux, Fedora 17.  (Yes, I know it's 
elderly, but then so am I. :-) )

Also in case it has any relevance:

>> sessionInfo()
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_NZ.utf8       LC_NUMERIC=C
>  [3] LC_TIME=en_NZ.utf8        LC_COLLATE=en_NZ.utf8
>  [5] LC_MONETARY=en_NZ.utf8    LC_MESSAGES=en_NZ.utf8
>  [7] LC_PAPER=en_NZ.utf8       LC_NAME=C
>  [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_NZ.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] spatstat_1.40-0.064 misc_0.0-16
>
> loaded via a namespace (and not attached):
>  [1] abind_1.4-0     deldir_0.1-7    goftest_1.0-2   grid_3.1.2
>  [5] lattice_0.20-29 Matrix_1.1-4    mgcv_1.8-3      nlme_3.1-118
>  [9] polyclip_1.3-1  tensor_1.5      tools_3.1.2

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From murdoch.duncan at gmail.com  Sat Feb 28 22:59:35 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 28 Feb 2015 16:59:35 -0500
Subject: [R] Firefox not showing R help.
In-Reply-To: <54F22EBC.1070400@auckland.ac.nz>
References: <54F22EBC.1070400@auckland.ac.nz>
Message-ID: <54F23A47.8070700@gmail.com>

On 28/02/2015 4:10 PM, Rolf Turner wrote:
> 
> Firefox recently updated itself on my laptop.  Now when I ask for R help 
> --- e.g. ?plot --- I just get my home page. And no help. If I do "?plot" 
> again after Firefox has opened its window, I just get yet another 
> Firefox window, opened to my home page.  (I have my preferences set to
> 
>      "When Firefox starts Show my homepage"
> 
> --- as I always have had in the past.)

I would guess that browseURL() won't work for any URL.  Is that right?

What does getOption("browser") give you in R?  If it is just a character
string (e.g. "xdg-open" is what I get in Ubuntu), does it work from your
command line, outside of R, e.g. for me that test would be

xdg-open http://www.r-project.org

If that doesn't work, but you can figure out a command line way to open
a particular URL, change getOption("browser") to use that.

Duncan Murdoch

> 
> The Firefox that I am currently running is (according Firefox help
> --> "About Firefox") is version 36.0.
> 
> Can anyone suggest to me how I can get my html R help back?
> 
> For what it's worth:  I am using Linux, Fedora 17.  (Yes, I know it's 
> elderly, but then so am I. :-) )
> 
> Also in case it has any relevance:
> 
>>> sessionInfo()
>> R version 3.1.2 (2014-10-31)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>>  [1] LC_CTYPE=en_NZ.utf8       LC_NUMERIC=C
>>  [3] LC_TIME=en_NZ.utf8        LC_COLLATE=en_NZ.utf8
>>  [5] LC_MONETARY=en_NZ.utf8    LC_MESSAGES=en_NZ.utf8
>>  [7] LC_PAPER=en_NZ.utf8       LC_NAME=C
>>  [9] LC_ADDRESS=C              LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_NZ.utf8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] spatstat_1.40-0.064 misc_0.0-16
>>
>> loaded via a namespace (and not attached):
>>  [1] abind_1.4-0     deldir_0.1-7    goftest_1.0-2   grid_3.1.2
>>  [5] lattice_0.20-29 Matrix_1.1-4    mgcv_1.8-3      nlme_3.1-118
>>  [9] polyclip_1.3-1  tensor_1.5      tools_3.1.2
> 
> cheers,
> 
> Rolf Turner
>


From hpages at fredhutch.org  Sat Feb 28 23:28:52 2015
From: hpages at fredhutch.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Sat, 28 Feb 2015 14:28:52 -0800
Subject: [R] Substring replacement in string
In-Reply-To: <027d01d052db$7faa3140$7efe93c0$@gmail.com>
References: <027d01d052db$7faa3140$7efe93c0$@gmail.com>
Message-ID: <54F24124.8020207@fredhutch.org>

Hi Alrik,

With the Biostrings/IRanges infrastructure (Bioconductor packages), you
can do this with:

   library(Biostrings)
   x0 <- BString("pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, 
z1))")
   donttouch_words <- c("pmin", "pmax")

   ## Extract the substrings to modify (target substrings).
   donttouch_regions <- reduce(do.call("c", lapply(donttouch_words, 
matchPattern, x0)))
   target_regions <- ranges(gaps(donttouch_regions))
   target_substrings <- extractAt(x0, target_regions)

   ## Modify them.
   old <- paste0(letters, collapse="")
   new <- paste0(LETTERS, collapse="")
   target_substrings <- chartr(old, new, target_substrings)

   ## Replace in original string.
   x1 <- replaceAt(x0, target_regions, target_substrings)

Then:

   > x1
     57-letter "BString" instance
   seq: pmin(pmax(pmin(X1, X2), pmin(X3, X4)) == Y, pmax(Z1, Z1))

   > as.character(x1)
   [1] "pmin(pmax(pmin(X1, X2), pmin(X3, X4)) == Y, pmax(Z1, Z1))"

Hope this helps,
H.

On 02/27/2015 02:19 PM, Alrik Thiem wrote:
> Dear R-help list,
>
> I would like to replace all lower-case letters in a string that are not part
> of certain fixed expressions. For example, I have the string:
>
> "pmin(pmax(pmin(x1, X2), pmin(X3, X4)) == Y, pmax(Z1, z1))"
>
> Where I would like to replace all lower-case letters that do not belong to
> the functions "pmin" and "pmax" by 1 - toupper(...) to get
>
> "pmin(pmax(pmin(1 - X1, X2), pmin(X3, X4)) == Y, pmax(Z1, 1 - Z1))"
>
> Any ideas on how I could achieve that?
>
> Many thanks and best wishes,
>
> Alrik
>
>
> ********************************
> Alrik Thiem
> Post-Doctoral Researcher
>
> Department of Philosophy
> University of Geneva
> Rue de Candolle 2
> CH-1211 Geneva
>
> +41 76 527 80 83
>
> http://www.alrik-thiem.net
> http://www.compasss.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From twboiteau at gmail.com  Sat Feb 28 18:07:30 2015
From: twboiteau at gmail.com (tianshu)
Date: Sat, 28 Feb 2015 09:07:30 -0800 (PST)
Subject: [R] scatter plot matrix with multiple trend lines and p values
Message-ID: <CAD3b6KqO=2TrJHBcHdtm_NS9Dg5Un5vQu1uzoJmoDLQCd5dT7Q@mail.gmail.com>

I am trying to create a scatter plot matrix in which the lower panels
contain
scatter plots colored by group with trend lines by group, and the upper
panels contain r and p values. Using pairs() I was able to get close (ie,
scatter plot matrix on bottom with one trend line and correlation
coefficients and p values in the upper panel) but was unable to add two
lines. Using spm() I was able to get the multiple trend lines, but not the
upper
panel statistics. Does anyone know of a way to accomplish this?

My code using pairs:

pairs(~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width, data = iris,
bg=c("red","blue","green")[iris$Species],
pch = 22,
lower.panel  =my_line <- function(x,y,...){
    points(x,y,...)
    abline(a = lm(y ~ x)$coefficients[1] , b = lm(y ~ x)$coefficients[2] ,
...)
},
upper.panel = panel.cor <- function(x, y, digits = 2, cex.cor, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  # correlation coefficient
  r <- cor(x, y)
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste("r= ", txt, sep = "")
  text(0.5, 0.6, txt)

  # p-value calculation
  p <- cor.test(x, y)$p.value
  txt2 <- format(c(p, 0.123456789), digits = digits)[1]
  txt2 <- paste("p= ", txt2, sep = "")
  if(p<0.01) txt2 <- paste("p= ", "<0.01", sep = "")
  text(0.5, 0.4, txt2)
})




--
View this message in context: http://r.789695.n4.nabble.com/scatter-plot-matrix-with-multiple-trend-lines-and-p-values-tp4703996.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From glennmschultz at me.com  Sat Feb 28 18:25:09 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Sat, 28 Feb 2015 17:25:09 +0000 (GMT)
Subject: [R] Lubridate and NameSpace
Message-ID: <81c14e41-059c-481c-83c6-98742e78851b@me.com>

Hello All,

I am working on a package very near completion - roxygenizing it now. ?The namespace imports from lubridate?importFrom(lubridate,"%m+%"). ?The problem is:

Lubridate will not load with bondlab, I have to manually click on lubridate in R Studio to load it
I tried?calling?function using lubridate:::%m+% within my function based on some discussion I found online. ?This is likely the correct idea but I don't think I am calling the function correctly since it does not work in the code when I use the above syntax.
Any suggestions are appreciated>

Best Glenn?

The description file is as follows:?

Package: BondLab
Type: Package
Title: A package for the analysis of structured products
Version: 0.0.0
Date: 2013-12-08
Author: Glenn Schultz, CFA
Maintainer: Glenn Schultz <glennmschultz at me.com>
Description: The package provides a suite of software utilities for the analysis of Mortgage and Asset Backed securities
LazyLoad: yes
License: GPL(>=3.0)
Imports: ?termstrc,?
? ? ? ? ? lubridate,?
? ? ? ? ? methods,?
? ? ? ? ? optimx,
Suggests: knitr,
? ? ? ? ? devtools,
? ? ? ? ? testthat
VignetteBuilder: knitr

The Namespace is as follows:
# Generated by roxygen2 (4.1.0): do not edit by hand

export(CPR.To.SMM)
export(DollarRoll)
export(Effective.Convexity)
export(Effective.Duration)
export(EstimYTM)
export(MakeScenario)
export(Mortgage.Monthly.Payment)
export(MortgageCashFlow)
export(PPC.Ramp)
export(PassThroughAnalytics)
export(PassThroughOAS)
export(Rates)
export(Remain.Balance)
export(SMM.To.CPR)
export(SMMVector.To.CPR)
export(Sched.Prin)
export(TermStructure)
export(TimeValue)
export(bondprice)
import(methods)
import(optimx)
importFrom(lubridate,"%m+%")
importFrom(termstrc,create_cashflows_matrix)
importFrom(termstrc,create_maturities_matrix)
importFrom(termstrc,estim_cs)
importFrom(termstrc,estim_nss)
importFrom(termstrc,forwardrates)
importFrom(termstrc,spotrates)



From hrk1366 at gmail.com  Sat Feb 28 21:29:17 2015
From: hrk1366 at gmail.com (hamid-reza kadkhodazadeh)
Date: Sat, 28 Feb 2015 23:59:17 +0330
Subject: [R] r script in web
Message-ID: <CALsy4AzcEtCKLdEzcON1SakP6FoBbwDz_cras_cfz-qdc5bctQ@mail.gmail.com>

hi
i want to run r script in web without install r on server(my server is
windows).
is it possible?how?

thank you

	[[alternative HTML version deleted]]


