From wolski at molgen.mpg.de  Wed Sep  1 00:11:00 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Wed, 01 Sep 2004 00:11:00 +0200
Subject: [R] Sparse Matrices in R
In-Reply-To: <20040831215205.20730.qmail@web88011.mail.re2.yahoo.com>
References: <20040831215205.20730.qmail@web88011.mail.re2.yahoo.com>
Message-ID: <200409010011000224.004DDF76@mail.math.fu-berlin.de>

Hi!
help.search("sparse matrix")


graph2SparseM(graph)    Coercion methods between graphs and sparse
                        matrices
tripletMatrix-class(Matrix)
                        Class "tripletMatrix" sparse matrices in
                        triplet form
SparseM.hb(SparseM)     Harwell-Boeing Format Sparse Matrices
image,matrix.csr-method(SparseM)
                        Image Plot for Sparse Matrices
etc .....

/E

*********** REPLY SEPARATOR  ***********

On 8/31/2004 at 5:52 PM Danny Heuman wrote:

>>>I have data in i,j,r format, 
>>>
>>>
>>>
>>>where r is the value in location A[i,j] for some imaginary matrix A.
>>>
>>>I need to build this matrix A, but given the sizes of i and j, I believe
>>>that using a sparse format would be most adequate.
>>>
>>>Hopefully this will allow me to perform some basic matrix manipulation
>>>such as multiplication, addition, rowsums,  transpositions, subsetting
>>>etc etc.
>>>
>>>
>>>
>>>Is there any way to achieve this goal in R?
>>>Thanks,
>>> 
>>>Danny
>>>
>>>	[[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin                'v'    
tel: 0049-30-83875219                        /   \       
mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
      wolski at molgen.mpg.de



From Scott.Waichler at pnl.gov  Wed Sep  1 00:27:44 2004
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Tue, 31 Aug 2004 15:27:44 -0700
Subject: [R] Problem with seq.dates in chron
Message-ID: <7E4C06F49D6FEB49BE4B60E5FC92ED7A05F516@pnlmse35.pnl.gov>


I get faulty output from seq.dates() if I specify a length that is too
long.
For example, I ask for 129 months in the following call to the function,
but it returns
131:

> R.version.string
[1] "R version 1.9.1, 2004-06-21"
> startdatetime <- chron(dates="01/01/1995", times="00:00:00")
> beg.month.datetimes <- seq.dates(from=startdatetime, by="months",
length=129)
> beg.month.datetimes
  [1] 01/01/95 02/01/95 03/01/95 04/01/95 05/01/95 06/01/95 07/01/95
08/01/95
  [9] 09/01/95 10/01/95 11/01/95 12/01/95 01/01/96 02/01/96 03/01/96
04/01/96
 [17] 05/01/96 06/01/96 07/01/96 08/01/96 09/01/96 10/01/96 11/01/96
12/01/96
 [25] 01/01/97 02/01/97 03/01/97 04/01/97 05/01/97 06/01/97 07/01/97
08/01/97
 [33] 09/01/97 10/01/97 11/01/97 12/01/97 01/01/98 02/01/98 03/01/98
04/01/98
 [41] 05/01/98 06/01/98 07/01/98 08/01/98 09/01/98 10/01/98 11/01/98
12/01/98
 [49] 01/01/99 02/01/99 03/01/99 04/01/99 05/01/99 06/01/99 07/01/99
08/01/99
 [57] 09/01/99 10/01/99 11/01/99 12/01/99 01/01/00 02/01/00 03/01/00
04/01/00
 [65] 05/01/00 06/01/00 07/01/00 08/01/00 09/01/00 10/01/00 11/01/00
12/01/00
 [73] 01/01/01 02/01/01 03/01/01 04/01/01 05/01/01 06/01/01 07/01/01
08/01/01
 [81] 09/01/01 10/01/01 11/01/01 12/01/01 01/01/02 02/01/02 03/01/02
04/01/02
 [89] 05/01/02 06/01/02 07/01/02 08/01/02 09/01/02 10/01/02 11/01/02
12/01/02
 [97] 01/01/03 02/01/03 03/01/03 04/01/03 05/01/03 06/01/03 07/01/03
08/01/03
[105] 09/01/03 10/01/03 11/01/03 12/01/03 01/01/04 02/01/04 03/01/04
04/01/04
[113] 05/01/04 06/01/04 07/01/04 08/01/04 09/01/04 10/01/04 11/01/04
12/01/04
[121] 01/01/05 02/01/05 03/01/05 04/01/05 05/01/05 06/01/05 07/01/05
08/01/05
[129] 09/01/05 10/01/05 11/01/05
>

Is this a bug, and can it be fixed?

Scott Waichler
Pacific Northwest National Laboratory
scott.waichler<at>pnl.gov



From xma at Arctur.com  Wed Sep  1 01:37:13 2004
From: xma at Arctur.com (Xiao-Jun Ma)
Date: Tue, 31 Aug 2004 16:37:13 -0700
Subject: [R] subselect install problem
Message-ID: <54AB7E948D3B394BAC0B610DB2E606811B4F40@pegasus.arcturus.local>

Trying to install subselect v0.8 on Redhat 7.3 and R 1.8.1 fails (below). Any help is greatly appreciated.

Xiao-Jun


* Installing *source* package 'subselect' ...
** libs
f2c  < anneal.f > anneal.c
   anneal:
Error on line 263: Declaration error for fica: adjustable dimension on non-argument
Error on line 263: Declaration error for valp: adjustable dimension on non-argument
Error on line 263: Declaration error for auxw: adjustable dimension on non-argument
Error on line 263: wr_ardecls:  nonconstant array size
Error on line 263: wr_ardecls:  nonconstant array size
Error on line 263: wr_ardecls:  nonconstant array size
make: *** [anneal.o] Error 1
ERROR: compilation failed for package 'subselect'



From ggrothendieck at myway.com  Wed Sep  1 03:24:42 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 1 Sep 2004 01:24:42 +0000 (UTC)
Subject: [R] Problem with seq.dates in chron
References: <7E4C06F49D6FEB49BE4B60E5FC92ED7A05F516@pnlmse35.pnl.gov>
Message-ID: <loom.20040901T031530-774@post.gmane.org>

Waichler, Scott R <Scott.Waichler <at> pnl.gov> writes:

> I get faulty output from seq.dates() if I specify a length that is too
> long.
> For example, I ask for 129 months in the following call to the function,
> but it returns
> 131:
> 
> > R.version.string
> [1] "R version 1.9.1, 2004-06-21"
> > startdatetime <- chron(dates="01/01/1995", times="00:00:00")
> > beg.month.datetimes <- seq.dates(from=startdatetime, by="months",
> length=129)

If you look at the seq.dates R source, it sets `to' like this:

   to <- from + (length. - 1) * c(1, 7, 31, 366)[i]

where in your case where i is 3 for months.   It then
picks out those days between from and to having the same day 
of the month as the from date (or uses a more complex algorithm if the day 
of the month exceeds 28).  The multiplication by 31 gives an overestimate 
which is OK for a small lengths but overflows to give too many months if
length is too large.  Since we know the error will always be on the
high side, until it is fixed as a workaround you could just subset it:

   seq.dates(from=startdatetime, by="months", length=129)[1:129]

(Perhaps you could forward this to the maintainer of chron.)



From rlyoung at email.arizona.edu  Wed Sep  1 03:27:33 2004
From: rlyoung at email.arizona.edu (Rebecca Young)
Date: Tue, 31 Aug 2004 18:27:33 -0700
Subject: [R] simpleboot, pairs.boot
Message-ID: <1094002053.60ef4ecc59a24@www.email.arizona.edu>

Hi.

I am a new R user trying to obtain bootstrap confidence intervals around vector
correlations of Principal components.

My data is a data frame of eigenvector loadings from PC1 in the columns the rows
are different species.  I want to calculated the vector correlation and
bootstrap confidence intervals for all species pairs.

I have tried using simpleboot as pairs.boot seems to be an easy way of sampling
from two vectors of data.  The function I wrote "veccor" below works outside of
the pairs.boot function.  However in this function it seems to calculate all
1000 vector correlations as -1.

########
veccor
function(x,y) ((sum((x)*(y)))/((sqrt(sum(y^2)))*(sqrt(sum(x^2)))))
x<-as.vector(faVC[1,])
y<-as.vector(faVC[2,])
boot<-pairs.boot(x,y,veccor,1000)
#########

I have also tried using the boot function but only end up sampling from on of my
vectors of data.

Any suggestions would be greatly appriciated!  Thanks!

Best, Becca



From olympiotneto at uol.com.br  Wed Sep  1 06:24:54 2004
From: olympiotneto at uol.com.br (Olympio T. Neto)
Date: Wed, 1 Sep 2004 01:24:54 -0300
Subject: [R] error in mle
Message-ID: <000801c48fdb$a237eb40$9a6262c8@otneto>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040901/1d94b03a/attachment.pl

From jfox at mcmaster.ca  Wed Sep  1 07:02:40 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 1 Sep 2004 01:02:40 -0400
Subject: [R] Rcmdr X11 protocol error message
In-Reply-To: <x2brgr3xqt.fsf@biostat.ku.dk>
Message-ID: <20040901050238.YUGN7925.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Peter and Michael,

I installed Quantian on  a spare machine that I have and observed the same
warning messages that Michael has been reporting. These (and the problem
with help files but not with viewing data sets that Peter reported) occurred
with version 0.9-11 of Rcmdr but not with an earlier version.

Since the code for the Rcmdr package was substantially reworked this summer,
that seems to me a good candidate for the source of these problems, though I
don't see why the changes should be problematic. I'm afraid that I'm
insufficiently familiar with the inner workings of X11 and Tcl/Tk to be much
help in figuring out what's wrong. Everything seems to work fine under
Windows, as far as I can tell.

It occurs to me that if the warning messages are benign, one approach would
be to suppress them. I already intercept warnings and present them in dialog
boxes; I could grep for "X11 protocol error" and simply ignore these. That
doesn't seem to me a good solution, however. It would be better to
understand what's happening.

I'm copying this message to Dirk since he's mentioned that he plans to put
the newer Rcmdr in Quantian. Dirk: Have you tested with Rcmdr 0.9-11?

Thank you.
 John



> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Peter Dalgaard
> Sent: Tuesday, August 31, 2004 2:37 PM
> To: Michael Bibo
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Rcmdr X11 protocol error message
> 
> Michael Bibo <mbibo at qldnet.com.au> writes:
> 
> > John Fox <jfox <at> mcmaster.ca> writes:
> > 
> > > 
> > > Dear Michael,
> > > 
> > > A question: Do you observe these problems with tcltk in 
> general or 
> > > just with the Rcmdr package? Is it possible for you to 
> test a Tcl/Tk 
> > > program outside of R?
> > > 
> > And Peter asked which version of Tcl/Tk.
> > 
> > Apparently my system has version 8.4 installed, specifically:
> > Tcl-8.4.5-3-mdk (tclsh8.4) and Tk-8.4.5-3-mdk (libtk8.4.so).  As I 
> > understand it, these are installed from RPMs on the 
> installation DVD, 
> > and I note that they are mandrake specific.
> > 
> > John - I wasn't sure if I had any other Tcl/Tk applications 
> installed 
> > (it's not always obvious when installing from RPM's).  I have 
> > certainly not encountered these error messages with any other 
> > application.  I quickly downloaded "WISH Supernotepad 1.2.3".  This 
> > application requires Tcl/Tk 8.4 or greater.  There are no graphics 
> > window in this application, but plenty of dialogue boxes.  
> It gave no errors.  Is this an appropriate test?
> > 
> > If this is a mandrake-configuration-specific problem, it may not be 
> > worth spending too much time investigating, as R Commandr 
> still works.  
> > I can always try re-installing Tcl/Tk from source when/if I 
> have time.
> 
> I don't think we have evidence that it's the Tcl 
> installation, although it could be (Google suggests that 
> there have been problems with at least some versions, 
> although most references seem rather old). I can't seem to 
> reproduce the effect with SUSE's tk-8.4.6-28 either. If it is 
> a bug in Rcmdr, then we'd want to find it and you have the 
> only handle on it....
> 
> BTW, sometimes Tk errors allow you to see a trace of the execution.
> Would this happen to be one of those situations?
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: 
> (+45) 35327907
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Wed Sep  1 08:32:26 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Sep 2004 07:32:26 +0100 (BST)
Subject: [R] subselect install problem
In-Reply-To: <54AB7E948D3B394BAC0B610DB2E606811B4F40@pegasus.arcturus.local>
Message-ID: <Pine.LNX.4.44.0409010722010.1656-100000@gannet.stats>

On Tue, 31 Aug 2004, Xiao-Jun Ma wrote:

> Trying to install subselect v0.8 on Redhat 7.3 and R 1.8.1 fails (below). Any help is greatly appreciated.

They are old, but the issue is package subselect.  anneal.f is not written
in Fortran77.  The comments are non-standard, as is the use of dfloat:

              critvalue = vactual/dsqrt(dfloat(nqsi*k))
                                        ^
"anneal.f", Line = 186, Column = 41: ANSI: Intrinsic "DFLOAT" is an 
extension to the Fortran standard.
etc.

BTW, it seems the C++ routines are non-standard, too, since I get many
warnings like

In file included from 
/opt/local/bin/../lib/gcc/i686-pc-linux-gnu/3.4.1/../../../../include/c++/3.4.1/backward/iostream.h:31,
                 from gaussjel.cpp:5:
/opt/local/bin/../lib/gcc/i686-pc-linux-gnu/3.4.1/../../../../include/c++/3.4.1/backward/backward_warning.h:32:2: 
warning: #warning This file includes at
leastone deprecated or antiquated header. Please consider using one of the
32 headers found in section 17.4.1.2 of the C++ standard. Examples include
substituting the <X> header for the <X.h> header for C++ includes, or
<iostream> instead of the deprecated header <iostream.h>. To disable this
warning use -Wno-deprecated.

The solution is to install g77 and use that rather than f2c when you 
update your R (urgent).

> 
> Xiao-Jun
> 
> 
> * Installing *source* package 'subselect' ...
> ** libs
> f2c  < anneal.f > anneal.c
>    anneal:
> Error on line 263: Declaration error for fica: adjustable dimension on non-argument
> Error on line 263: Declaration error for valp: adjustable dimension on non-argument
> Error on line 263: Declaration error for auxw: adjustable dimension on non-argument
> Error on line 263: wr_ardecls:  nonconstant array size
> Error on line 263: wr_ardecls:  nonconstant array size
> Error on line 263: wr_ardecls:  nonconstant array size
> make: *** [anneal.o] Error 1
> ERROR: compilation failed for package 'subselect'

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wuertz at itp.phys.ethz.ch  Wed Sep  1 09:00:50 2004
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Wed, 01 Sep 2004 07:00:50 +0000
Subject: [R] D'agostino test
In-Reply-To: <5.0.2.1.2.20040830180658.00b04bd0@cimrs1.mnhn.fr>
References: <5.0.2.1.2.20040830180658.00b04bd0@cimrs1.mnhn.fr>
Message-ID: <413573A2.5090508@itp.phys.ethz.ch>

Several versions of the D'Agostino Test are implemented in
"fBasics" from Rmetrics beside many other tests for normality.

Diethelm Wuertz
www.Rmetrics.org


Alexandre Bournery wrote:

> Hi, Does anyone know if the D'agostino test is available with R ?
> Alex
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Wed Sep  1 09:02:14 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Sep 2004 08:02:14 +0100 (BST)
Subject: [R] error in mle -- user error reported by optim
In-Reply-To: <000801c48fdb$a237eb40$9a6262c8@otneto>
Message-ID: <Pine.LNX.4.44.0409010754550.3016-100000@gannet.stats>

The error is rather in _your_ log-likelihood: you are going to have to try
much harder to avoid underflow/overflow.

Avoiding log(exp(a1*x1+a2*x2)) would be a start.  You might begin to 
appreciate why R's d*** and p*** functions have a `log.p' argument.

Better starting values would help, probably a lot.  Also read about 
scaling problems in ?optim.

On Wed, 1 Sep 2004, Olympio T. Neto wrote:

> Friends
> 
>     I'm trying fit a survival model by maximum likelihood estimation
> using this function:
> 
> flver=function(a1,a2,b1,b2)
> {
> 
> lver=-(sum(st*log(exp(a1*x1+a2*x2)))+sum(st*log(hheft(exp(b1*x1+b2*x2)*t,f.heft)))
> -(exp(a1*x1+a2*x2)/exp(b1*x1-b2*x2))*sum(-log(1-pheft(exp(b1*x1+b2*x2)*t,f.heft))))
> }
> emv=mle(flver,start=list(a1=0,a2=0,b1=0,b2=0))
> 
> where hheft and pheft are functions defined in polspline package. 
> My variables are:
> t: time
> st: censor 
> x1 and x2: Covariates
> 
> I don't find any estimation because an error occurs:
> 
> Non finite/finite difference value [0].
> 
> Can I treat this error? I try using "SANN" method and this error occurs
> too. There is another alternative?

(Unlikely, given where in the code this occurs.  You haven't even copied 
it correctly!)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From isaia at econ.unito.it  Wed Sep  1 09:26:59 2004
From: isaia at econ.unito.it (E D. Isaia)
Date: Wed, 01 Sep 2004 09:26:59 +0200
Subject: [R] About Factor Analysis
Message-ID: <413579C3.6000805@econ.unito.it>

Hello,

I' doing some simulation on (confirmatory) factor analysis on a 
covariance matrix and I resort to factanal() function, which works fine 
but it performs only the maximum-likelihood method of extracting factors.
I wonder if (and where) I can find a package that performs the principal 
axis factor (PAF) procedure for extracting factors.

Thanks in advance to all, ennio.

Model:	PowerBook5,2
Platform PowerPc G4, 1.25 GHz
OS.type "unix"
GUI "AQUA"
platform powerpc-apple-darwin6.8
arch     powerpc
os       darwin6.8
system   powerpc, darwin6.8
status
major    1
minor    9.1
year     2004
month    06
day      21
language R

-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~ Ennio D. Isaia
~ Dep. of Statistics & Mathematics, University of Torino
~ Piazza Arbarello, 8 - 10128 Torino (Italy)
~ Phone: +39 011 670 57 29 ~~ Fax: +39 011 670 57 83
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From michael.watson at bbsrc.ac.uk  Wed Sep  1 10:12:10 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Wed, 1 Sep 2004 09:12:10 +0100
Subject: [R] Accessing aov p-value
Message-ID: <8975119BCD0AC5419D61A9CF1A923E951746D5@iahce2knas1.iah.bbsrc.reserved>

Hi

I have a data.frame, and want to perform an analysis of variance on each
row.  I am currently using aov() and summary(), but what I want to do is
perform an analysis of variance on each row and then append the F
statistic and the p-value to the end of the row, so I can then use these
to filter the data later on;  and I want to do all this in a for loop.

How can I access the F statistic and the p-value from aov()
programmatically?

Thanks

Mick



From sb at ihe.se  Wed Sep  1 10:21:57 2004
From: sb at ihe.se (Sixten Borg)
Date: Wed, 01 Sep 2004 10:21:57 +0200
Subject: [R] Advice on good programming practice, lexical scope
Message-ID: <s135a2d0.058@gwmail.ihe.se>


In "An Introduction to R" (See R help menu), there is an example of a function 'open.account' that makes use of the lexical scope in R.

I have a set of functions that can be used to output R tables and graphics into a single report document. (I am aware that several tools can do this already).

While reorganizing my code, I realize that I can collect my functions in a list, in the style of 'open.account' above. This will result in a list containing data and operations on those data. The data is for example the file name of the report. This also results in a rather large object instead of a set of rather small functions and a list of data.

Writing a package of these functions (or this object containing functions), would require documentation of each function. The style that I see in the R help is that the functions are not enclosed like this in a list. 

I like the idea of having the functions collected in a single list, but I think the documentation might be messy. 
Any ideas, opinions, anyone?

Thanks in advance,
Sixten.

Example:

myreport <- report(filename="report.rtf")
my.report$add.table(my.data.frame, "Table of ...")
plot(runif(10))
my.report$add.picture("Plot of ...")

or...

r <- report(filename="report.rtf")
r <- add.table(r, my.data.frame, "Table of...")
plot(runit(10))
r <- add.picture(r, "Plot of...")



From ripley at stats.ox.ac.uk  Wed Sep  1 10:24:33 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Sep 2004 09:24:33 +0100 (BST)
Subject: [R] Accessing aov p-value
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E951746D5@iahce2knas1.iah.bbsrc.reserved>
Message-ID: <Pine.LNX.4.44.0409010919340.10218-100000@gannet.stats>

On Wed, 1 Sep 2004, michael watson (IAH-C) wrote:

> I have a data.frame, and want to perform an analysis of variance on each
> row.  

Really?  On one row?  Makes no sense to me!

> I am currently using aov() and summary(), but what I want to do is
> perform an analysis of variance on each row and then append the F
> statistic and the p-value to the end of the row, so I can then use these
> to filter the data later on;  and I want to do all this in a for loop.
> 
> How can I access the F statistic and the p-value from aov()
> programmatically?

They are not there (nor are they printed).  I think you may have meant
from the summary() method for aov, in which case _please_ read the
relevant help page.

Following up example(aov):

summary(npk.aov)[[1]][, 4:5]

is a data frame, with

> print.data.frame(summary(npk.aov)[[1]][, 4:5])
                F value      Pr(>F)
block        4.44666643 0.015938790
N           12.25873421 0.004371812
P            0.54412982 0.474904093
K            6.16568920 0.028795054
N:P          1.37829669 0.263165283
N:K          2.14597201 0.168647879
P:K          0.03119491 0.862752086
Residuals            NA          NA



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bhx2 at mevik.net  Wed Sep  1 10:32:08 2004
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Wed, 01 Sep 2004 10:32:08 +0200
Subject: [R] Sparse Matrices in R
In-Reply-To: <200409010011000224.004DDF76@mail.math.fu-berlin.de>
	(wolski@molgen.mpg.de's
	message of "Wed, 01 Sep 2004 00:11:00 +0200")
References: <20040831215205.20730.qmail@web88011.mail.re2.yahoo.com>
	<200409010011000224.004DDF76@mail.math.fu-berlin.de>
Message-ID: <m03c22tmnr.fsf@bar.nemo-project.org>

"Wolski" <wolski at molgen.mpg.de> writes:

> Hi!
> help.search("sparse matrix")
>
>
> graph2SparseM(graph)    Coercion methods between graphs and sparse
>                         matrices
> tripletMatrix-class(Matrix)
>                         Class "tripletMatrix" sparse matrices in
>                         triplet form
> SparseM.hb(SparseM)     Harwell-Boeing Format Sparse Matrices
> image,matrix.csr-method(SparseM)
>                         Image Plot for Sparse Matrices
> etc .....

Which of course assumes that you already have packages such as
SparseM, Matrix and graph installed on your system.  If you don't,
help.search("sparse matrix") returns no matches.  :-)

-- 
Bj??rn-Helge Mevik



From janpsmit at yahoo.co.uk  Wed Sep  1 10:43:46 2004
From: janpsmit at yahoo.co.uk (=?iso-8859-1?q?Jan=20Smit?=)
Date: Wed, 1 Sep 2004 09:43:46 +0100 (BST)
Subject: [R] Imputing missing values
Message-ID: <20040901084346.82552.qmail@web86908.mail.ukl.yahoo.com>

Dear all, 

Apologies for this beginner's question. I have a
variable Price, which is associated with factors
Season and Crop, each of which have several levels.
The Price variable contains missing values (NA), which
I want to substitute by the mean of the remaining
(non-NA) Price values of the same Season-Crop
combination of levels. 

Price     Crop    Season 
10        Rice    Summer 
12        Rice    Summer 
NA        Rice    Summer 
8         Rice    Winter 
9         Wheat    Summer 

Price[is.na(Price)] gives me the missing values, and
by(Price, list(Crop, Season), mean, na.rm = T) the
values I want to impute. What I've not been able to
figure out, by looking at by and the various
incarnations of apply, is how to do the actual
substitution. 

Any help would be much appreciated. 

Jan Smit



From Wanzare at HCJP.com  Wed Sep  1 11:01:36 2004
From: Wanzare at HCJP.com (Manoj - Hachibushu Capital)
Date: Wed, 1 Sep 2004 18:01:36 +0900
Subject: [R] Imputing missing values
Message-ID: <1CBA12F2D414914989C723D196B287DC26BCF5@jp-svr-ex1.hcjp.com>

How about the following code below?

Price[is.na(price)] = mean(Price[-which(is.na(price))]);

HTH

Manoj


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jan Smit
Sent: Wednesday, September 01, 2004 5:44 PM
To: R-help at stat.math.ethz.ch
Subject: [R] Imputing missing values

Dear all, 

Apologies for this beginner's question. I have a
variable Price, which is associated with factors
Season and Crop, each of which have several levels.
The Price variable contains missing values (NA), which
I want to substitute by the mean of the remaining
(non-NA) Price values of the same Season-Crop
combination of levels. 

Price     Crop    Season 
10        Rice    Summer 
12        Rice    Summer 
NA        Rice    Summer 
8         Rice    Winter 
9         Wheat    Summer 

Price[is.na(Price)] gives me the missing values, and
by(Price, list(Crop, Season), mean, na.rm = T) the
values I want to impute. What I've not been able to
figure out, by looking at by and the various
incarnations of apply, is how to do the actual
substitution. 

Any help would be much appreciated. 

Jan Smit

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From mi2kelgrum at yahoo.com  Wed Sep  1 11:09:12 2004
From: mi2kelgrum at yahoo.com (Mikkel Grum)
Date: Wed, 1 Sep 2004 02:09:12 -0700 (PDT)
Subject: [R] RODBC query on one line
Message-ID: <20040901090912.74594.qmail@web60201.mail.yahoo.com>

Dear R-helpers,

When I use sqlQuery in the package RODBC, I cannot
break the line, but have to write the entire SQL Query
on the same line.  Is this expected behaviour? It is
definitely workable, but makes the queries a slightly
difficult to read and edit.

I'm using R 1.9.1 and RODBC 1.0-4 on Windows Server
2003 and querying a Sybase database.

Best wishes,
Mikkel



From r.alberts at cs.rug.nl  Wed Sep  1 20:15:26 2004
From: r.alberts at cs.rug.nl (Rudi Alberts)
Date: 01 Sep 2004 11:15:26 -0700
Subject: [R] obtaining exact p-values in mixed effects model
Message-ID: <1094062526.4607.17.camel@gbic04>

Hello,

Using a fixed effects linear model (with lm), I can get exact p-values
out of the AVOVA table, even if they are very small, eg. 1.0e-200.

Using lme (linear mixed effects) from the nlme library,
it appears that there is rounding of the p-values to zero, if
the p-value is less than about 1.0e-16. Is there a way we can obtain 
the exact p-values from lme without rounding?


used commands:

library(nlme)
g<-lme(value~factor(fac1)+factor(fac2)+factor(fac1):factor(fac2),data=mydataframe,random=~1|factor(fac3))
ag<-anova(g)


kind regards, R. Alberts



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Sep  1 11:33:17 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 1 Sep 2004 11:33:17 +0200
Subject: [R] Imputing missing values
References: <20040901084346.82552.qmail@web86908.mail.ukl.yahoo.com>
Message-ID: <00cf01c49006$b71f45a0$ad133a86@www.domain>

Hi Jan,

you could try the following:

dat <- data.frame(Price=c(10,12,NA,8,7,9,NA,9,NA),
                  Crop=c(rep("Rise", 5), rep("Wheat", 4)),
                  Season=c(rep("Summer", 3), rep("Winter", 4),
rep("Summer", 2)))
######
dat <- dat[order(dat$Season, dat$Crop),]
dat$Price.imp <- unlist(tapply(dat$Price, list(dat$Crop, dat$Season),
function(x){
  mx <- mean(x, na.rm=TRUE)
  ifelse(is.na(x), mx, x)
  }))

dat

However, you should be careful using this imputation technique since
you don't take into account the extra variability of imputing new
values in your data set. I don't know what analysis are you planning
to do but in any case I would recommend to read some standard
references for missing values, e.g., Little, R. and Rubin, D. (2002).
Statistical Analysis with Missing Data, New York: Wiley.

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Jan Smit" <janpsmit at yahoo.co.uk>
To: <R-help at stat.math.ethz.ch>
Sent: Wednesday, September 01, 2004 10:43 AM
Subject: [R] Imputing missing values


> Dear all,
>
> Apologies for this beginner's question. I have a
> variable Price, which is associated with factors
> Season and Crop, each of which have several levels.
> The Price variable contains missing values (NA), which
> I want to substitute by the mean of the remaining
> (non-NA) Price values of the same Season-Crop
> combination of levels.
>
> Price     Crop    Season
> 10        Rice    Summer
> 12        Rice    Summer
> NA        Rice    Summer
> 8         Rice    Winter
> 9         Wheat    Summer
>
> Price[is.na(Price)] gives me the missing values, and
> by(Price, list(Crop, Season), mean, na.rm = T) the
> values I want to impute. What I've not been able to
> figure out, by looking at by and the various
> incarnations of apply, is how to do the actual
> substitution.
>
> Any help would be much appreciated.
>
> Jan Smit
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ramasamy at cancer.org.uk  Wed Sep  1 11:47:09 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 01 Sep 2004 10:47:09 +0100
Subject: [R] sample size for t-tests
In-Reply-To: <1093977026.4188.34.camel@vpn202001.lif.icnet.uk>
References: <038a01c48f82$ef9b4f70$8800a8c0@BumgarnerLab.local>
	<1093977026.4188.34.camel@vpn202001.lif.icnet.uk>
Message-ID: <1094032029.3057.1.camel@vpn202001.lif.icnet.uk>

Look into the code of power.t.test in the stats package. For example,
the sample size for two-sample t-test, two-tail testing and strict
interpretation of tail probability can be found by solving the following
equation iteratively :

\begin{equation}
 1 - \beta =   \Pr ( t_{v,ncp}^{*} <  t_{v, \alpha/2 } ) 
             + \Pr ( t_{v,ncp}^{*} >  t_{v, 1 - \alpha/2 } )
\end{equation}
                                          
where :

1) $t_{v, \alpha/2}$ is the $\alpha/2$ quantile of a central
t-distribution with $v$ degrees of freedom and $v = n1 + n2 - 2$

2) $t_{v,ncp}^{*}$ follows a non-central t-distribution $v$ degrees of
freedom and non-centrality parameter of $ncp$

3) non-centralitity parameter in 2) estimated by
$ncp =  \delta / ( \sigma  \sqrt{ \frac{1}{n_1} + \frac{1}{n_2} } )$

As usual, $alpha$ and $beta$ represent type I and type II error and
\delta, \sigma represents the desired difference in group means and
variance.

This would be explained in a textbook but none comes to my mind at the
moment. There is an approximate analytical solution based on normality
assumption but the results are very close for large sample sizes. It is
better to use the exact equation as the computations (via uniroot) is
fast anyway. 

Regards, Adai



> On Tue, 2004-08-31 at 18:49, Caimiao Wei wrote:
> > Dear all,
> > 
> > Could any one please tell me the exact formula R uses to calculate the sample size for one-sample and two-sample t-tests? Thanks,
> > 
> > Caimiao
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >



From ahmlatif at yahoo.com  Wed Sep  1 11:47:18 2004
From: ahmlatif at yahoo.com (Mahbub Latif)
Date: Wed, 1 Sep 2004 02:47:18 -0700 (PDT)
Subject: [R] Imputing missing values
In-Reply-To: <20040901084346.82552.qmail@web86908.mail.ukl.yahoo.com>
Message-ID: <20040901094718.72470.qmail@web41201.mail.yahoo.com>

Try this:

newPrice = unlist(sapply(Price, Crop:Season,
  function(x){
    x[is.na(x)]=mean(x,na.rm=T);
    return(x);
  }))  



--- Jan Smit <janpsmit at yahoo.co.uk> wrote:

> Dear all, 
> 
> Apologies for this beginner's question. I have a
> variable Price, which is associated with factors
> Season and Crop, each of which have several levels.
> The Price variable contains missing values (NA),
> which
> I want to substitute by the mean of the remaining
> (non-NA) Price values of the same Season-Crop
> combination of levels. 
> 
> Price     Crop    Season 
> 10        Rice    Summer 
> 12        Rice    Summer 
> NA        Rice    Summer 
> 8         Rice    Winter 
> 9         Wheat    Summer 
> 
> Price[is.na(Price)] gives me the missing values, and
> by(Price, list(Crop, Season), mean, na.rm = T) the
> values I want to impute. What I've not been able to
> figure out, by looking at by and the various
> incarnations of apply, is how to do the actual
> substitution. 
> 
> Any help would be much appreciated. 
> 
> Jan Smit
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Wed Sep  1 11:49:47 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Sep 2004 10:49:47 +0100 (BST)
Subject: [R] RODBC query on one line
In-Reply-To: <20040901090912.74594.qmail@web60201.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0409011048170.10632-100000@gannet.stats>

Not true: you have to submit the query as one element of a character
vector, not the same thing at all.  You *can* use paste() to assemble it.

On Wed, 1 Sep 2004, Mikkel Grum wrote:

> Dear R-helpers,
> 
> When I use sqlQuery in the package RODBC, I cannot
> break the line, but have to write the entire SQL Query
> on the same line.  Is this expected behaviour? It is
> definitely workable, but makes the queries a slightly
> difficult to read and edit.
> 
> I'm using R 1.9.1 and RODBC 1.0-4 on Windows Server
> 2003 and querying a Sybase database.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sdavis2 at mail.nih.gov  Wed Sep  1 12:08:35 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 1 Sep 2004 06:08:35 -0400
Subject: [R] RODBC query on one line
In-Reply-To: <20040901090912.74594.qmail@web60201.mail.yahoo.com>
References: <20040901090912.74594.qmail@web60201.mail.yahoo.com>
Message-ID: <E31D0558-FBFE-11D8-838A-000A95D7BA10@mail.nih.gov>

I often use paste to build up SQL queries into line-sized chunks, but 
this is only a convenience and not required.  It does improve 
readability and maintainability, in my opinion.

Sean

On Sep 1, 2004, at 5:09 AM, Mikkel Grum wrote:

> Dear R-helpers,
>
> When I use sqlQuery in the package RODBC, I cannot
> break the line, but have to write the entire SQL Query
> on the same line.  Is this expected behaviour? It is
> definitely workable, but makes the queries a slightly
> difficult to read and edit.
>
> I'm using R 1.9.1 and RODBC 1.0-4 on Windows Server
> 2003 and querying a Sybase database.
>
> Best wishes,
> Mikkel
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Wed Sep  1 12:02:05 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Sep 2004 12:02:05 +0200
Subject: [R] sample size for t-tests
In-Reply-To: <1094032029.3057.1.camel@vpn202001.lif.icnet.uk>
References: <038a01c48f82$ef9b4f70$8800a8c0@BumgarnerLab.local>
	<1093977026.4188.34.camel@vpn202001.lif.icnet.uk>
	<1094032029.3057.1.camel@vpn202001.lif.icnet.uk>
Message-ID: <x27jrel336.fsf@biostat.ku.dk>

Adaikalavan Ramasamy <ramasamy at cancer.org.uk> writes:

> Look into the code of power.t.test in the stats package. For example,
> the sample size for two-sample t-test, two-tail testing and strict
> interpretation of tail probability can be found by solving the following
> equation iteratively :
> 
> \begin{equation}
>  1 - \beta =   \Pr ( t_{v,ncp}^{*} <  t_{v, \alpha/2 } ) 
>              + \Pr ( t_{v,ncp}^{*} >  t_{v, 1 - \alpha/2 } )
> \end{equation}
>                                           
> where :
> 
> 1) $t_{v, \alpha/2}$ is the $\alpha/2$ quantile of a central
> t-distribution with $v$ degrees of freedom and $v = n1 + n2 - 2$
> 
> 2) $t_{v,ncp}^{*}$ follows a non-central t-distribution $v$ degrees of
> freedom and non-centrality parameter of $ncp$
> 
> 3) non-centralitity parameter in 2) estimated by
> $ncp =  \delta / ( \sigma  \sqrt{ \frac{1}{n_1} + \frac{1}{n_2} } )$
> 
> As usual, $alpha$ and $beta$ represent type I and type II error and
> \delta, \sigma represents the desired difference in group means and
> variance.
> 
> This would be explained in a textbook but none comes to my mind at the
> moment. There is an approximate analytical solution based on normality
> assumption but the results are very close for large sample sizes. It is
> better to use the exact equation as the computations (via uniroot) is
> fast anyway. 

Yep, just a few nits/qualifications: 

- sigma is the standard deviation, not variance

- n1 and n2 are generally set equal in sample size calculations since
  that is known to be optimal (largest power for given n1+n2)

- all the solutions are based on normality assumptions, the analytical
  formulas come out of assuming the variance known in advance (so that
  you can use the normal distribution instead of the t distribution).
  These ignore the uncertainty from having to estimate the variance
  and so give somewhat too small sample sizes.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From h.andersson at nioo.knaw.nl  Wed Sep  1 12:13:13 2004
From: h.andersson at nioo.knaw.nl (Henrik Andersson)
Date: Wed, 01 Sep 2004 12:13:13 +0200
Subject: [R] Accesing the name of an assigned object in a function
Message-ID: <ch47au$1kh$1@sea.gmane.org>

I want to use the name that I assign to an object in the function that 
produces the output, somewhat like below:

stupid.function <- function(input){
	[body]
	cat("Summarized output is ", output$summary, "Full output is 			given 
by typing", assigned.name, "\n")
	}

assigned.name <- stupid.function(whatever)


or another example is a function that sinks the results to a text file 
and names it assigned.name.txt .

I checked the help for function, <-, assign but could not find it, is it 
  possible ?


---------------------------------------------
Henrik Andersson
Netherlands Institute of Ecology -
Centre for Estuarine and Marine Ecology
P.O. Box 140
4400 AC Yerseke
Phone: +31 113 577473
h.andersson at nioo.knaw.nl
http://www.nioo.knaw.nl/ppages/handersson



From nusbj at hotmail.com  Wed Sep  1 12:13:24 2004
From: nusbj at hotmail.com (Z P)
Date: Wed, 01 Sep 2004 18:13:24 +0800
Subject: [R] Optim in R 
Message-ID: <BAY22-F27fGkMJvYqVK0004b37f@hotmail.com>

Dear all,

I recently use the optim function to find the maxima for some likelihood 
function. I have many parameters, more than 12. As the help file mention, 
the default method does not do well in univariate case. How about the 
different method in optim?

I notice the nlm function uses newton method. I have also done the newton 
method by myself, the iteration does not converge due to the difficulty in 
solve the hessian matrix for this large dimension matrix. Is the newton 
method worse than the method supplied in optim? In the mle package, optim is 
used instead of nlm.

For the different methods in optim, they give somewhat quite different 
estimate for some of the parameters. And the most annoying one is that the 
hessian matrix is sometimes not positive definite after the optim gives 
output using method (the default one and BFGS). Shall we admit that we have 
arrived at the maximum point?

For CG and SANN method, they are both very very slow, however, their maximum 
values are usually bigger than the default method.

Is there any suggestion in choosing these methods? I know it is a very hard 
optimazation question, however, I can not find the reference book in optim 
help at the moment. Thank you.

Yours,

Zhen



From lbaring at stochastik.uni-hannover.de  Wed Sep  1 12:20:30 2004
From: lbaring at stochastik.uni-hannover.de (Ludwig Baringhaus)
Date: Wed, 1 Sep 2004 12:20:30 +0200
Subject: [R] D'agostino test
In-Reply-To: <413573A2.5090508@itp.phys.ethz.ch>
References: <5.0.2.1.2.20040830180658.00b04bd0@cimrs1.mnhn.fr>
	<413573A2.5090508@itp.phys.ethz.ch>
Message-ID: <200409011220.31066.lbaring@stochastik.uni-hannover.de>

> Several versions of the D'Agostino Test are implemented in
> "fBasics" from Rmetrics beside many other tests for normality.
Unlike the Shapiro-Wilk or the Anderson-Darling test, the 
D'Agostino test is not an omnibus test for testing the
hypothesis of normality. In fact, D'Agostino's D 
is a suitable test statistic for testing the hypothesis of 
uniformity. See 
Baringhaus and Henze (1990). 
A test for uniformity with unknown limits based on D'Agostino's D. 
Statist. Probab. Lett. 9, 299-304 

L. Baringhaus
Institut fuer Mathematische Stochastik
Universitaet Hannover
Welfengarten 1
30167 Hannover



From cleemputte at hotmail.com  Wed Sep  1 12:25:44 2004
From: cleemputte at hotmail.com (Patrick Van Cleemputte)
Date: Wed, 01 Sep 2004 10:25:44 +0000
Subject: [R] lme: howto specify covariance structure between levels of
	grouping factors 
Message-ID: <BAY24-F186WGvyGp9dn00019c71@hotmail.com>

Dear all,

I am studying the possibility of using the nlme package in R to analyse 
field trials of agricultural crops. I have a problem with the syntax for the 
modelling of variance covariance structures. I can model the within-group 
covariance structure using the correlation argument and the covariance 
structure between different random effects of the same grouping level using 
'random=pdDiag(~effect)|group' but I would like to model the covariance 
structure' between' the different levels of the grouping factor. This is 
necessary because the plants (= grouping factor) we are testing are not 
independant. They are genetically correlated and usually we know this 
correlation. I would therefore also like to specify the exact (not starting) 
values of this 'between subjects correlation'.

Can you tell me if this is possible in R and how the syntax of such a model 
would look like?

thank you in advance,

P.


http://entertainment.msn.be/muziek/musicclub



From ym at climpact.com  Wed Sep  1 12:38:41 2004
From: ym at climpact.com (Yves Magliulo)
Date: 01 Sep 2004 12:38:41 +0200
Subject: [R] obtaining exact p-values in mixed effects model
In-Reply-To: <1094062526.4607.17.camel@gbic04>
References: <1094062526.4607.17.camel@gbic04>
Message-ID: <1094035120.1759.22.camel@new-york.climpact.net>

hi,

>  Is there a way we can obtain 
> the exact p-values from lme without rounding?
use summary instead.



> used commands:
> 
> library(nlme)
> g<-lme(value~factor(fac1)+factor(fac2)+factor(fac1):factor(fac2),data=mydataframe,random=~1|factor(fac3))
> ag<-anova(g)

summary(g)$tTable[,5] will provide the exact p-value 

you can always get the exact value of summary or predict etc... remember
it's not only printing, it's also a list

see ?summary.lme for more info


hope it's help


> kind regards, R. Alberts
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
-- 
------
Yves Magliulo <ym at climpact.com>
R&D Engineer, CLIMPACT

Tel.   : +33 (0) 1 44 27 34 31
Fax.   : +33 (0) 1 44 27 49 96 
Universite Pierre et Marie Curie
Boite 101 - Tour 45 - 5eme etage - Couloir 45/46
4 place Jussieu, 75252 Paris CEDEX 05, France



From Jordi.Molins at drkw.com  Wed Sep  1 12:53:09 2004
From: Jordi.Molins at drkw.com (Molins, Jordi)
Date: Wed, 1 Sep 2004 12:53:09 +0200
Subject: [R] not positive definite D matrix in quadprog
Message-ID: <AA0BBC8742AFFF4583B91782E958CB660FCECF@ibfftce121.de.ad.drkw.net>


Hello to everybody,

I have a quadratic programming problem that I am trying to solve by various
methods. One of them is to use the quadprog package in R.

When I check positive definiteness of the D matrix, I get that one of the
eigenvalues is negative of order 10^(-8). All the others are positive. When
I set this particular eigenvalue to 0.0 and I recheck the eigenvalues in R,
the last eigenvalue is positive of order 10^(-12). I try to use solve.QP,
but I get an error message that matrix D in quadratic function is not
positive definite. For reference, a fully R session is listed below.

Is 10^(-12) too close to 0? i.e., does R consider that with an eigenvalue of
order +10^(-12) the matrix is not positive definite but positive
semidefinite?

In general, has somebody know a way (in R or outside R, maybe in c++) to
solve quadratic programming with  positive semidefinite matrices? 

In particular, my problem is not so hard: given y an n x 1 matrix, and beta
an n x m matrix,  I want to find an  m x 1 matrix x s. t. sum(y - beta *
x)^2 is minimum. The particularity is that I want to impose restrictions on
x: all x components should be between 0 and 1, and there are also
constraints of the type A x = b, where A and b have the necessary dimensions
to ensure consistency.

I have tried with some other packages, and they do not give a correct
solution when the system increases in size (e.g., 24 variables and 9
constraint equations) ... some idea?

thanks!

Jordi

_____________________________


The problem:
 library(MASS)
 library(quadprog)

 D <-
matrix(c(439.5883658,438.8445615,438.1007572,2430.285506,2426.162884,2422.04
0262,44.21800696,44.14261394,
 
438.8445615,438.1020157,437.3594699,2426.173348,2422.057702,2417.942056,44.1
43188,44.06792255,
 
438.1007572,437.3594699,449.6727418,2445.212326,2542.83573,2643.780669,50.19
455336,52.04059805,
 
2430.285506,2426.173348,2445.212326,13491.19467,13614.55046,13737.90625,253.
4897678,255.745654,
 
2426.162884,2422.057702,2542.83573,13614.55046,14687.86142,15923.99043,313.8
180838,336.4239658,
 
2422.040262,2417.942056,2643.780669,13737.90625,15923.99043,19107.7405,410.9
729841,472.5104919,
 
44.21800696,44.143188,50.19455336,253.4897678,313.8180838,410.9729841,9.5462
51262,11.57677661,
 
44.14261394,44.06792255,52.04059805,255.745654,336.4239658,472.5104919,11.57
677661,14.51245153),8,8)

 D.vectors <- eigen(D,only.values=F)$vectors
 D.values <- eigen(D,only.values=F)$values

#the last value is negative
 D.values
[1]  4.609489e+04  2.458166e+03  8.232288e+01  1.961199e+00  5.976441e-01
[6]  2.810968e-01  1.253157e-09 -2.685763e-08

 D.quad <- matrix(0,8,8)
 diag(D.quad) <- D.values

#checking that the eigenvalue decomposition works fine
 D.vectors%*%D.quad%*%ginv(D.vectors)

 D.quad[8,8]
[1] -2.685763e-08
 D.quad[8,8] <- 0.0

#checking; nothing changes too much
D.vectors%*%D.quad%*%ginv(D.vectors)

#now all eigenvalues are positive:
 D.values.new <-
eigen(D.vectors%*%D.quad%*%ginv(D.vectors),only.values=F)$values
 D.values.new
[1] 4.609489e+04 2.458166e+03 8.232288e+01 1.961199e+00 5.976441e-01
[6] 2.810968e-01 1.253140e-09 1.428534e-12

Dmat <- D.vectors%*%D.quad%*%ginv(D.vectors)

dvec <-
-c(-2910.533769,-2905.609008,-3012.223863,-16274.97455,-17222.46423,-18380.6
391,-357.8878464,-379.6371849)

#this ensures that coefficients are positive:
 Amat <- matrix(0,8,8)
 diag(Amat) <- 1
 bvec <- rep(0,8)

#it says D is not positive definite ...
 solve.QP(Dmat,dvec,Amat,bvec=bvec)
Error in solve.QP(Dmat, dvec, Amat, bvec = bvec) : 
        matrix D in quadratic function is not positive definite!


--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From ggrothendieck at myway.com  Wed Sep  1 12:57:00 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 1 Sep 2004 10:57:00 +0000 (UTC)
Subject: [R] Advice on good programming practice, lexical scope
References: <s135a2d0.058@gwmail.ihe.se>
Message-ID: <loom.20040901T120704-365@post.gmane.org>

Sixten Borg <sb <at> ihe.se> writes:

: 
: In "An Introduction to R" (See R help menu), there is an example of a 
function 'open.account' that makes use
: of the lexical scope in R.
: 
: I have a set of functions that can be used to output R tables and graphics 
into a single report document. (I am
: aware that several tools can do this already).
: 
: While reorganizing my code, I realize that I can collect my functions in a 
list, in the style of
: 'open.account' above. This will result in a list containing data and 
operations on those data. The data is
: for example the file name of the report. This also results in a rather large 
object instead of a set of rather
: small functions and a list of data.
: 
: Writing a package of these functions (or this object containing functions), 
would require documentation
: of each function. The style that I see in the R help is that the functions 
are not enclosed like this in a list. 
: 
: I like the idea of having the functions collected in a single list, but I 
think the documentation might be
: messy. 
: Any ideas, opinions, anyone?
: 
: Thanks in advance,
: Sixten.
: 
: Example:
: 
: myreport <- report(filename="report.rtf")
: my.report$add.table(my.data.frame, "Table of ...")
: plot(runif(10))
: my.report$add.picture("Plot of ...")
: 
: or...
: 
: r <- report(filename="report.rtf")
: r <- add.table(r, my.data.frame, "Table of...")
: plot(runit(10))
: r <- add.picture(r, "Plot of...")


Can't say which is better but in terms of the S3 system style
might look at the R2HTML package for an example.  
R2HTML defines a generic function, HTML, and then 
defines specific methods such as HTML.data.frame to produce HTML 
formatted data frames, HTML.list to produce HTML formatted lists, etc.  
The nice thing is that they can all be called in a uniform way using:

   HTML(x)

and HTML will dispatch HTML.data.frame, HTML.list or whatever
depending on the class of x.   Thus you could have a generic
add function

   add <- function(x, ...) UseMethod("add")

and specific methods:

   add.data.frame <- function(x, ...) ...
   add.recordedplot <- function(x, ...) ...

and call them all in a uniform way passing a data.frame or a 
display list of class recordedplot using the add call in each case
but having add dispatch add.data.frame or add.recordedplot
according to the class of the first arugment.  In the following
the first call to add actually invokes add.data.frame (which
you would have previously defined) whereas the second call
to add invokes previously defined add.recordedplot.  The following
assumes the plot device is already open:

   r <- report("filename")
   my.data.frame <- data.frame(a=1:26,b=letters)
   r <- add(r, my.data.frame)
   dev.control(displaylist="enable") # enable display list
   plot(1:10)
   my.plot <- recordPlot() # load displaylist into variable
   r <- add(r, my.plot)



From vicented.canto.ext at juntadeandalucia.es  Wed Sep  1 13:03:31 2004
From: vicented.canto.ext at juntadeandalucia.es (Vicente Canto Casasola)
Date: Wed, 01 Sep 2004 13:03:31 +0200
Subject: [R]  blockwise sums
References: <200409011014.i81A9W3u026250@hypatia.math.ethz.ch>
Message-ID: <4135AC83.4090206@juntadeandalucia.es>

Hi, all!!

 From the help page for 'aggregate':
     Splits the data into subsets, computes summary statistics for
     each, and returns the result in a convenient form.

So here's the solution I found to this problem:

blocksums <- function(x,n)
{
temp <- 1:length(x)-1
temp <- list((temp%/%n)+1)
aggregate(x,by=temp,sum)$x
}

For instance:
blocksums(1:10,3)
[1]  6 15 24 10

Hope this helps!!
Vicente.



From ahenningsen at email.uni-kiel.de  Wed Sep  1 13:14:46 2004
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Wed, 1 Sep 2004 13:14:46 +0200
Subject: [R] Accesing the name of an assigned object in a function
In-Reply-To: <ch47au$1kh$1@sea.gmane.org>
References: <ch47au$1kh$1@sea.gmane.org>
Message-ID: <200409011314.46375.ahenningsen@email.uni-kiel.de>

Hi Hendrik,

if I understand you right, match.call() can help you.

All the best,
Arne

On Wednesday 01 September 2004 12:13, Henrik Andersson wrote:
> I want to use the name that I assign to an object in the function that
> produces the output, somewhat like below:
>
> stupid.function <- function(input){
>  [body]
>  cat("Summarized output is ", output$summary, "Full output is    given
> by typing", assigned.name, "\n")
>  }
>
> assigned.name <- stupid.function(whatever)
>
>
> or another example is a function that sinks the results to a text file
> and names it assigned.name.txt .
>
> I checked the help for function, <-, assign but could not find it, is it
>   possible ?
>
>
> ---------------------------------------------
> Henrik Andersson
> Netherlands Institute of Ecology -
> Centre for Estuarine and Marine Ecology
> P.O. Box 140
> 4400 AC Yerseke
> Phone: +31 113 577473
> h.andersson at nioo.knaw.nl
> http://www.nioo.knaw.nl/ppages/handersson
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From mbibo at qldnet.com.au  Wed Sep  1 13:20:59 2004
From: mbibo at qldnet.com.au (Michael Bibo)
Date: Wed, 01 Sep 2004 21:20:59 +1000
Subject: [R] Rcmdr X11 protocol error message
In-Reply-To: <20040901050238.YUGN7925.tomts25-srv.bellnexxia.net@JohnDesktop8300>
References: <20040901050238.YUGN7925.tomts25-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <4135B09B.7000602@qldnet.com.au>

John Fox wrote:

>Dear Peter and Michael,
>
>I installed Quantian on  a spare machine that I have and observed the same
>warning messages that Michael has been reporting. These (and the problem
>with help files but not with viewing data sets that Peter reported) occurred
>with version 0.9-11 of Rcmdr but not with an earlier version.
>
>Since the code for the Rcmdr package was substantially reworked this summer,
>that seems to me a good candidate for the source of these problems, though I
>don't see why the changes should be problematic. I'm afraid that I'm
>insufficiently familiar with the inner workings of X11 and Tcl/Tk to be much
>help in figuring out what's wrong. Everything seems to work fine under
>Windows, as far as I can tell.
>
>It occurs to me that if the warning messages are benign, one approach would
>be to suppress them. I already intercept warnings and present them in dialog
>boxes; I could grep for "X11 protocol error" and simply ignore these. That
>doesn't seem to me a good solution, however. It would be better to
>understand what's happening.
>
>I'm copying this message to Dirk since he's mentioned that he plans to put
>the newer Rcmdr in Quantian. Dirk: Have you tested with Rcmdr 0.9-11?
>
>Thank you.
> John
>  
>
>  
>
John, Peter and Dirk,

I'm glad I'm not the only one with a handle on it now.  I've already 
exceeded my level of knowledge and skill in both Linux and R.  But I'm 
happy to help track it down, if I can be of assistance.  As I have said 
to John, the major value of Rcmdr to me is to help 'sell' R to others in 
my organisation currently using SPSS, and for this purpose, the Windows 
version at work is working fine.  It is more of an annoyance at home, as 
it doesn't seem to stop anything working.

Peter asked:

BTW, sometimes Tk errors allow you to see a trace of the execution.
Would this happen to be one of those situations?

The short answer is I don't know (see my first line :-)).  There is no 
button on the dialogue box saying 'more details...' or anything that 
obvious.  Is there a log file somewhere on the system or some other way 
to generate such a trace?

I have been experimenting, and the following seem reliable (at least on 
my system):

Error messages don't seem to happen for the first graph generated.  The 
second graph drawn also generates an error dialogue box with the error 
message repeated about 11 times.  The third and subsequent times exactly 
the same graph is generated leads to an error message repeated about 21 
times.  (I don't know if the number of repetitions is meaningful).  Note 
that the graphs are generated and visible when the error messages appear.

Running any analysis that only writes output to the output window (such 
as fitting a regression model) generates the error messages before the 
output is written to the output window.  The output appears when the 
error dialogue box is OK'd.  I guess it's more likely to be responding 
to exiting the dialogue box than writing the output.  But this only 
happens when such error messages have been generated previously in that 
session by creating a (second) graph.

If the diagnostic panel plots for a regression model are called, the 
error messages appear, but this time the plots themselves are not 
visible in the graphics device (it is blank).  When the error messages 
are OK'd, the plots appear in the device.

When exiting Rcmdr, then, and OK'ing the "Exit?" dialogue box, the final 
error messages appear, but again only if they have already been 
generated by a graph call.

I don't know if this will be helpful, but I thought reliable 
observations might give some clues.

Regards,

Michael

michael_bibo at health.qld.gov.au



From ggrothendieck at myway.com  Wed Sep  1 13:34:35 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 1 Sep 2004 11:34:35 +0000 (UTC)
Subject: [R] Advice on good programming practice, lexical scope
References: <s135a2d0.058@gwmail.ihe.se>
	<loom.20040901T120704-365@post.gmane.org>
Message-ID: <loom.20040901T133126-281@post.gmane.org>

Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

: 
: Sixten Borg <sb <at> ihe.se> writes:
: 
: : 
: : In "An Introduction to R" (See R help menu), there is an example of a 
: function 'open.account' that makes use
: : of the lexical scope in R.
: : 
: : I have a set of functions that can be used to output R tables and graphics 
: into a single report document. (I am
: : aware that several tools can do this already).
: : 
: : While reorganizing my code, I realize that I can collect my functions in a 
: list, in the style of
: : 'open.account' above. This will result in a list containing data and 
: operations on those data. The data is
: : for example the file name of the report. This also results in a rather 
large 
: object instead of a set of rather
: : small functions and a list of data.
: : 
: : Writing a package of these functions (or this object containing 
functions), 
: would require documentation
: : of each function. The style that I see in the R help is that the functions 
: are not enclosed like this in a list. 
: : 
: : I like the idea of having the functions collected in a single list, but I 
: think the documentation might be
: : messy. 
: : Any ideas, opinions, anyone?
: : 
: : Thanks in advance,
: : Sixten.
: : 
: : Example:
: : 
: : myreport <- report(filename="report.rtf")
: : my.report$add.table(my.data.frame, "Table of ...")
: : plot(runif(10))
: : my.report$add.picture("Plot of ...")
: : 
: : or...
: : 
: : r <- report(filename="report.rtf")
: : r <- add.table(r, my.data.frame, "Table of...")
: : plot(runit(10))
: : r <- add.picture(r, "Plot of...")
: 
: Can't say which is better but in terms of the S3 system style
: might look at the R2HTML package for an example.  
: R2HTML defines a generic function, HTML, and then 
: defines specific methods such as HTML.data.frame to produce HTML 
: formatted data frames, HTML.list to produce HTML formatted lists, etc.  
: The nice thing is that they can all be called in a uniform way using:
: 
:    HTML(x)
: 
: and HTML will dispatch HTML.data.frame, HTML.list or whatever
: depending on the class of x.   Thus you could have a generic
: add function
: 
:    add <- function(x, ...) UseMethod("add")
: 
: and specific methods:
: 
:    add.data.frame <- function(x, ...) ...
:    add.recordedplot <- function(x, ...) ...
: 
: and call them all in a uniform way passing a data.frame or a 
: display list of class recordedplot using the add call in each case
: but having add dispatch add.data.frame or add.recordedplot
: according to the class of the first arugment.  In the following
: the first call to add actually invokes add.data.frame (which
: you would have previously defined) whereas the second call
: to add invokes previously defined add.recordedplot.  The following
: assumes the plot device is already open:
: 
:    r <- report("filename")
:    my.data.frame <- data.frame(a=1:26,b=letters)
:    r <- add(r, my.data.frame)
:    dev.control(displaylist="enable") # enable display list
:    plot(1:10)
:    my.plot <- recordPlot() # load displaylist into variable
:    r <- add(r, my.plot)

Obviously the above code does not correspond to my discussion
which says that the dispatch occurs based on the FIRST argument to
add.  These should have been:

    r <- report("filename")
    my.data.frame <- data.frame(a=1:26,b=letters)
    r <- add(my.data.frame, r)
    dev.control(displaylist="enable") # enable display list
    plot(1:10)
    my.plot <- recordPlot() # load displaylist into variable
    r <- add(my.plot, r)



From wolski at molgen.mpg.de  Wed Sep  1 13:34:45 2004
From: wolski at molgen.mpg.de (Eryk Wolski)
Date: Wed, 1 Sep 2004 13:34:45 +0200 (MET DST)
Subject: [R] Accesing the name of an assigned object in a function
In-Reply-To: <ch47au$1kh$1@sea.gmane.org>
Message-ID: <Pine.OSF.4.31.0409011334120.30329-100000@harry.molgen.mpg.de>

?assign

/E

On Wed, 1 Sep 2004, Henrik Andersson wrote:

> I want to use the name that I assign to an object in the function that
> produces the output, somewhat like below:
>
> stupid.function <- function(input){
> 	[body]
> 	cat("Summarized output is ", output$summary, "Full output is 			given
> by typing", assigned.name, "\n")
> 	}
>
> assigned.name <- stupid.function(whatever)
>
>
> or another example is a function that sinks the results to a text file
> and names it assigned.name.txt .
>
> I checked the help for function, <-, assign but could not find it, is it
>   possible ?
>
>
> ---------------------------------------------
> Henrik Andersson
> Netherlands Institute of Ecology -
> Centre for Estuarine and Marine Ecology
> P.O. Box 140
> 4400 AC Yerseke
> Phone: +31 113 577473
> h.andersson at nioo.knaw.nl
> http://www.nioo.knaw.nl/ppages/handersson
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From bates at stat.wisc.edu  Wed Sep  1 13:50:07 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 01 Sep 2004 06:50:07 -0500
Subject: [R] degrees of freedom (lme4 and nlme)
In-Reply-To: <20040827145746.13556.qmail@web52710.mail.yahoo.com>
References: <20040827145746.13556.qmail@web52710.mail.yahoo.com>
Message-ID: <4135B76F.5090901@stat.wisc.edu>

Alexandre Galv??o Patriota wrote:
> Hi, I'm having some problems regarding the packages
> lme4 and nlme, more specifically in the denominator
> degrees of freedom. I used data Orthodont for the two
> packages. The commands used are below.
> 
> require(nlme)
> data(Orthodont)
> 
> fm1<-lme(distance~age+ Sex,
> data=Orthodont,random=~1|Subject, method="REML")
> 
> anova(fm1)
> 
>             numDF  DenDF  F-value    p-value
> (Intercept)   1      80   4123.156   <.0001
> age           1      80    114.838   <.0001
> Sex           1      25     9.292    0.0054
> 
> 
> The DenDF for each fixed effect is 80, 80 and 25.
> Using the package lme4:
> 
> require(lme4)
> data(Orthodont)
> 
> fm2<-lme(distance~age+ Sex,
> data=Orthodont,random=~1|Subject, method="REML")
> 
> anova(fm2)
> 
>     numDF  Sum Sq  Mean Sq  DenDF  F-value    p-value
> age  1	   235.356 235.356   105   114.838    <2.2e-16
> Sex  1      19.044  19.044   105    9.292     0.002912
> 
> 
> In this case the DenDF for each fixed effect is 105
> and 105. In this example, the conclusions are still
> the same, but it's not the case with another dataset I
> analyzed.
> I experience the same type of problem when using
> glmmPQL of the MASS package and the GLMM of package
> lme4. Could anyone give me a hint on why the two
> functions are giving incompatible results?
> thank you in advance for your help

The lme4 package is under development and only has a stub for the code 
that calculates the denominator degrees of freedom.

These Wald-type tests using the F and t distributions are approximations 
at best.  In that sense there is no "correct" degrees of freedom.  I 
think the more accurate tests may end up being the restricted likelihood 
ratio tests that Greg Reinsel and his student Mr. Ahn were working on at 
the time of Greg's death.



From mi2kelgrum at yahoo.com  Wed Sep  1 14:00:40 2004
From: mi2kelgrum at yahoo.com (Mikkel Grum)
Date: Wed, 1 Sep 2004 05:00:40 -0700 (PDT)
Subject: [R] RODBC query on one line
In-Reply-To: <E31D0558-FBFE-11D8-838A-000A95D7BA10@mail.nih.gov>
Message-ID: <20040901120040.59522.qmail@web60208.mail.yahoo.com>

Thanks Brian and Sean,

Works well and solves another problem I had: changing
the same condition in a series of related but
different queries, by making only one change in a
variable that is then used in all the queries.

Mikkel

--- Sean Davis <sdavis2 at mail.nih.gov> wrote:

> I often use paste to build up SQL queries into
> line-sized chunks, but 
> this is only a convenience and not required.  It
> does improve 
> readability and maintainability, in my opinion.
> 
> Sean
> 
> On Sep 1, 2004, at 5:09 AM, Mikkel Grum wrote:
> 
> > Dear R-helpers,
> >
> > When I use sqlQuery in the package RODBC, I cannot
> > break the line, but have to write the entire SQL
> Query
> > on the same line.  Is this expected behaviour? It
> is
> > definitely workable, but makes the queries a
> slightly
> > difficult to read and edit.
> >
> > I'm using R 1.9.1 and RODBC 1.0-4 on Windows
> Server
> > 2003 and querying a Sybase database.
> >
> > Best wishes,
> > Mikkel
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
>



From f.harrell at vanderbilt.edu  Wed Sep  1 14:10:54 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Wed, 01 Sep 2004 08:10:54 -0400
Subject: [R] Imputing missing values
In-Reply-To: <00cf01c49006$b71f45a0$ad133a86@www.domain>
References: <20040901084346.82552.qmail@web86908.mail.ukl.yahoo.com>
	<00cf01c49006$b71f45a0$ad133a86@www.domain>
Message-ID: <4135BC4E.9090303@vanderbilt.edu>

Dimitris Rizopoulos wrote:
> Hi Jan,
> 
> you could try the following:
> 
> dat <- data.frame(Price=c(10,12,NA,8,7,9,NA,9,NA),
>                   Crop=c(rep("Rise", 5), rep("Wheat", 4)),
>                   Season=c(rep("Summer", 3), rep("Winter", 4),
> rep("Summer", 2)))
> ######
> dat <- dat[order(dat$Season, dat$Crop),]
> dat$Price.imp <- unlist(tapply(dat$Price, list(dat$Crop, dat$Season),
> function(x){
>   mx <- mean(x, na.rm=TRUE)
>   ifelse(is.na(x), mx, x)
>   }))
> 
> dat
> 
> However, you should be careful using this imputation technique since
> you don't take into account the extra variability of imputing new
> values in your data set. I don't know what analysis are you planning
> to do but in any case I would recommend to read some standard
> references for missing values, e.g., Little, R. and Rubin, D. (2002).
> Statistical Analysis with Missing Data, New York: Wiley.
> 
> I hope this helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Doctoral Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/396887
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message ----- 
> From: "Jan Smit" <janpsmit at yahoo.co.uk>
> To: <R-help at stat.math.ethz.ch>
> Sent: Wednesday, September 01, 2004 10:43 AM
> Subject: [R] Imputing missing values
> 
> 
> 
>>Dear all,
>>
>>Apologies for this beginner's question. I have a
>>variable Price, which is associated with factors
>>Season and Crop, each of which have several levels.
>>The Price variable contains missing values (NA), which
>>I want to substitute by the mean of the remaining
>>(non-NA) Price values of the same Season-Crop
>>combination of levels.
>>
>>Price     Crop    Season
>>10        Rice    Summer
>>12        Rice    Summer
>>NA        Rice    Summer
>>8         Rice    Winter
>>9         Wheat    Summer
>>
>>Price[is.na(Price)] gives me the missing values, and
>>by(Price, list(Crop, Season), mean, na.rm = T) the
>>values I want to impute. What I've not been able to
>>figure out, by looking at by and the various
>>incarnations of apply, is how to do the actual
>>substitution.
>>
>>Any help would be much appreciated.
>>
>>Jan Smit

Or see the impute function in the Hmisc package and more general 
solutions also in Hmisc.


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From harmony at wina.com  Wed Sep  1 14:16:27 2004
From: harmony at wina.com (Harmony Tenney)
Date: Wed, 1 Sep 2004 08:16:27 -0400
Subject: AW: [R] Looking for help in calculating percentiles
Message-ID: <000601c4901d$82348d70$8901a8c0@cstone.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040901/cd664352/attachment.pl

From ligges at statistik.uni-dortmund.de  Wed Sep  1 15:01:00 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 01 Sep 2004 15:01:00 +0200
Subject: AW: [R] Looking for help in calculating percentiles
In-Reply-To: <000601c4901d$82348d70$8901a8c0@cstone.net>
References: <000601c4901d$82348d70$8901a8c0@cstone.net>
Message-ID: <4135C80C.7060402@statistik.uni-dortmund.de>

Harmony Tenney wrote:
> How do I calculate the 95th percentile when I know the 25th, the median and the 75th??

He? You cannot, or do you have some concrete knowledge about the 
distribution? Then you might be able to parameterize the distribution 
(if not too many parameters have to be estimated) by solving equations 
for the other quantiles and calculate the 0.95 percentile from there ...

Uwe Ligges


> Thanks,
> 
> Harmony Tenney
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rn001 at cebas.csic.es  Wed Sep  1 15:15:26 2004
From: rn001 at cebas.csic.es (javier garcia - CEBAS)
Date: Wed, 1 Sep 2004 15:15:26 +0200
Subject: [R] changing default labels of axis in ts plots
Message-ID: <20040901131346.84812A7AC5@cebas.csic.es>

Hi;
I'm in Spain and my locale and tz are the spanish one, and I'm using plot() 
with irregular time series. And I would like to change the default labels in 
x and y axis:

1) The labels of months in the x axis of the plots appear in Spanish -  
c("Enero,"Febrero",...) - and I would like them to appear in English - 
c("January","February",...) - without changing the locale settings of my 
computer.

2) Also, the labels refers to local time and I would like them to appear in 
UTC ("GMT") time.

I've tried, in several ways, to pass the format and timezone "GMT" to the 
plot, with no result.

Could these defaults be changed without a big effort?

Thanks and best regards

Javier G.



From ripley at stats.ox.ac.uk  Wed Sep  1 15:24:23 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Sep 2004 14:24:23 +0100 (BST)
Subject: [R] changing default labels of axis in ts plots
In-Reply-To: <20040901131346.84812A7AC5@cebas.csic.es>
Message-ID: <Pine.LNX.4.44.0409011422160.31261-100000@gannet.stats>

On Wed, 1 Sep 2004, javier garcia - CEBAS wrote:

> Hi;
> I'm in Spain and my locale and tz are the spanish one, and I'm using plot() 
> with irregular time series. And I would like to change the default labels in 
> x and y axis:
> 
> 1) The labels of months in the x axis of the plots appear in Spanish -  
> c("Enero,"Febrero",...) - and I would like them to appear in English - 
> c("January","February",...) - without changing the locale settings of my 
> computer.
> 
> 2) Also, the labels refers to local time and I would like them to appear in 
> UTC ("GMT") time.
> 
> I've tried, in several ways, to pass the format and timezone "GMT" to the 
> plot, with no result.
> 
> Could these defaults be changed without a big effort?

?locales in R, set TZ with Sys.putenv.  Your process does not have to have 
the same settings as `my computer'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MBock at arcadis-us.com  Wed Sep  1 15:39:31 2004
From: MBock at arcadis-us.com (Bock, Michael)
Date: Wed, 1 Sep 2004 07:39:31 -0600
Subject: [R] Multiple dependant proportions and sample size
Message-ID: <0016F5677B1F1D4281EEBC034993595101821120@CORPEXBE1.arcadis-us.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040901/d256b31e/attachment.pl

From mrufino at ipimar.ualg.pt  Wed Sep  1 15:42:30 2004
From: mrufino at ipimar.ualg.pt (Marta Rufino)
Date: Wed, 1 Sep 2004 14:42:30 +0100
Subject: [R] SIMPER-similarity percentage
Message-ID: <022401c49029$87657a50$0b1a0e0a@PORTATILMARTA>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040901/22db6ba9/attachment.pl

From MBock at arcadis-us.com  Wed Sep  1 15:41:56 2004
From: MBock at arcadis-us.com (Bock, Michael)
Date: Wed, 1 Sep 2004 07:41:56 -0600
Subject: [R] Recall: Multiple dependant proportions and sample size
Message-ID: <0016F5677B1F1D4281EEBC034993595101821129@CORPEXBE1.arcadis-us.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040901/873e58af/attachment.pl

From MBock at arcadis-us.com  Wed Sep  1 15:43:20 2004
From: MBock at arcadis-us.com (Bock, Michael)
Date: Wed, 1 Sep 2004 07:43:20 -0600
Subject: [R] Dependant proportions and sample size
Message-ID: <0016F5677B1F1D4281EEBC03499359510182112A@CORPEXBE1.arcadis-us.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040901/84811278/attachment.pl

From jfox at mcmaster.ca  Wed Sep  1 16:00:59 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 1 Sep 2004 10:00:59 -0400
Subject: [R] Rcmdr X11 protocol error message
In-Reply-To: <4135B09B.7000602@qldnet.com.au>
Message-ID: <20040901140058.CGIL19123.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Michael,

I can confirm Michael's observations: no problems until after a graphics
device window is opened. Then increasing numbers of warnings each time
commands are executed from within the Rcmdr. This happens whether the
commands are executed from dialog boxes or from the (upper) script window.
The warnings continue even if the graphics window is closed. Exiting from
the Commander and restarting it (within the name R session) stops the
warnings until another graphics window is opened.

John

> -----Original Message-----
> From: Michael Bibo [mailto:mbibo at qldnet.com.au] 
> Sent: Wednesday, September 01, 2004 6:21 AM
> To: John Fox
> Cc: 'Peter Dalgaard'; r-help at stat.math.ethz.ch; 'Dirk Eddelbuettel'
> Subject: Re: [R] Rcmdr X11 protocol error message
> 
> John Fox wrote:
> 
> >Dear Peter and Michael,
> >
> >I installed Quantian on  a spare machine that I have and 
> observed the 
> >same warning messages that Michael has been reporting. These 
> (and the 
> >problem with help files but not with viewing data sets that Peter 
> >reported) occurred with version 0.9-11 of Rcmdr but not with 
> an earlier version.
> >
> >Since the code for the Rcmdr package was substantially reworked this 
> >summer, that seems to me a good candidate for the source of these 
> >problems, though I don't see why the changes should be 
> problematic. I'm 
> >afraid that I'm insufficiently familiar with the inner 
> workings of X11 
> >and Tcl/Tk to be much help in figuring out what's wrong. Everything 
> >seems to work fine under Windows, as far as I can tell.
> >
> >It occurs to me that if the warning messages are benign, one 
> approach 
> >would be to suppress them. I already intercept warnings and present 
> >them in dialog boxes; I could grep for "X11 protocol error" 
> and simply 
> >ignore these. That doesn't seem to me a good solution, however. It 
> >would be better to understand what's happening.
> >
> >I'm copying this message to Dirk since he's mentioned that 
> he plans to 
> >put the newer Rcmdr in Quantian. Dirk: Have you tested with 
> Rcmdr 0.9-11?
> >
> >Thank you.
> > John
> >  
> >
> >  
> >
> John, Peter and Dirk,
> 
> I'm glad I'm not the only one with a handle on it now.  I've 
> already exceeded my level of knowledge and skill in both 
> Linux and R.  But I'm happy to help track it down, if I can 
> be of assistance.  As I have said to John, the major value of 
> Rcmdr to me is to help 'sell' R to others in my organisation 
> currently using SPSS, and for this purpose, the Windows 
> version at work is working fine.  It is more of an annoyance 
> at home, as it doesn't seem to stop anything working.
> 
> Peter asked:
> 
> BTW, sometimes Tk errors allow you to see a trace of the execution.
> Would this happen to be one of those situations?
> 
> The short answer is I don't know (see my first line :-)).  
> There is no button on the dialogue box saying 'more 
> details...' or anything that obvious.  Is there a log file 
> somewhere on the system or some other way to generate such a trace?
> 
> I have been experimenting, and the following seem reliable 
> (at least on my system):
> 
> Error messages don't seem to happen for the first graph 
> generated.  The second graph drawn also generates an error 
> dialogue box with the error message repeated about 11 times.  
> The third and subsequent times exactly the same graph is 
> generated leads to an error message repeated about 21 times.  
> (I don't know if the number of repetitions is meaningful).  
> Note that the graphs are generated and visible when the error 
> messages appear.
> 
> Running any analysis that only writes output to the output 
> window (such as fitting a regression model) generates the 
> error messages before the output is written to the output 
> window.  The output appears when the error dialogue box is 
> OK'd.  I guess it's more likely to be responding to exiting 
> the dialogue box than writing the output.  But this only 
> happens when such error messages have been generated 
> previously in that session by creating a (second) graph.
> 
> If the diagnostic panel plots for a regression model are 
> called, the error messages appear, but this time the plots 
> themselves are not visible in the graphics device (it is 
> blank).  When the error messages are OK'd, the plots appear 
> in the device.
> 
> When exiting Rcmdr, then, and OK'ing the "Exit?" dialogue 
> box, the final error messages appear, but again only if they 
> have already been generated by a graph call.
> 
> I don't know if this will be helpful, but I thought reliable 
> observations might give some clues.
> 
> Regards,
> 
> Michael
> 
> michael_bibo at health.qld.gov.au
> 
> 
>



From kannan at disi.unige.it  Wed Sep  1 16:38:50 2004
From: kannan at disi.unige.it (Kannnan)
Date: 01 Sep 2004 16:38:50 +0200
Subject: [R] Membership
Message-ID: <1094049530.1028.604.camel@varazze.disi.unige.it>

Dear sir,

I like to change the objective function in 

fanny function(fuzzy clustering) and I like to modify the membership
function in constructing membership grade to objects to the class.


So I kindly request to provide the source code of this fanny function,
it will be very helpful to continue my research, if you would provide
this source code.

Thanking you,

Yours sincerely,
S R Kannan

************************************************************ 
Dr. S R Kannan 
DISI, Universit?  di Genova 
Via Dodecaneso 35, 16146 Genova, Italy 
e-mail kannan at disi.unige.it
       srkannaniitm at mail.com
phone +39-010-353 6707 
      +39-340-710-2149
fax   +39-010-353 6699



From tlumley at u.washington.edu  Wed Sep  1 16:29:05 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 1 Sep 2004 07:29:05 -0700 (PDT)
Subject: [R] Accesing the name of an assigned object in a function
In-Reply-To: <Pine.OSF.4.31.0409011334120.30329-100000@harry.molgen.mpg.de>
References: <Pine.OSF.4.31.0409011334120.30329-100000@harry.molgen.mpg.de>
Message-ID: <Pine.A41.4.58.0409010725240.87396@homer12.u.washington.edu>

On Wed, 1 Sep 2004, Eryk Wolski wrote:

> ?assign

No, this is not going to work.
If Henrik has described his wish correctly, he wants to execute the call

assigned.name <- stupid.function(whatever)

and be able, inside stupid.function, to find out what name the result is
going to be assigned to.  This is, I think, impossible.

If assigned.name is passed as an argument of stupid.function then it is
possible, but assign() isn't necessary.

	-thomas

>
> /E
>
> On Wed, 1 Sep 2004, Henrik Andersson wrote:
>
> > I want to use the name that I assign to an object in the function that
> > produces the output, somewhat like below:
> >
> > stupid.function <- function(input){
> > 	[body]
> > 	cat("Summarized output is ", output$summary, "Full output is 			given
> > by typing", assigned.name, "\n")
> > 	}
> >
> > assigned.name <- stupid.function(whatever)
> >
> >
> > or another example is a function that sinks the results to a text file
> > and names it assigned.name.txt .
> >
> > I checked the help for function, <-, assign but could not find it, is it
> >   possible ?
> >
> >
> > ---------------------------------------------
> > Henrik Andersson
> > Netherlands Institute of Ecology -
> > Centre for Estuarine and Marine Ecology
> > P.O. Box 140
> > 4400 AC Yerseke
> > Phone: +31 113 577473
> > h.andersson at nioo.knaw.nl
> > http://www.nioo.knaw.nl/ppages/handersson
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From michael.watson at bbsrc.ac.uk  Wed Sep  1 16:31:52 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Wed, 1 Sep 2004 15:31:52 +0100
Subject: [R] Unique lists from a list
Message-ID: <8975119BCD0AC5419D61A9CF1A923E951746D7@iahce2knas1.iah.bbsrc.reserved>

Hi

I have a list.  Two of the elements of this list are "Name" and
"Address", both of which are character vectors.  Name and Address are
linked, so that the same "Name" always associates with the same
"Address".

What I want to do is pull out the unique values, as a new list of the
same format (ie two elements of character vectors).  Now I've worked out
that unique(list$Name) will give me a list of the unique names, but how
do I then go and link those to the correct (unique) addresses so I end
up with a new list which is the same format as the rest, but now unique?

Cheers
Mick



From Par.Matsson at farmaci.uu.se  Wed Sep  1 16:48:23 2004
From: Par.Matsson at farmaci.uu.se (=?ISO-8859-1?Q?P=E4r_Matsson?=)
Date: Wed, 01 Sep 2004 16:48:23 +0200
Subject: [R] Tick marks in cloud (lattice)
Message-ID: <4135E137.6080707@farmaci.uu.se>

Hi! Probably a simple question, but I can't get any tick marks in the 3d 
scatterplot I created using the cloud function.

The following works to display the three groups using different symbols:

data(iris)
cloud(Sepal.Length ~ Petal.Length * Petal.Width, data = iris, cex = 1.2, 
groups = Species, pch = c(16,1,1), col = c("black","black","red"), 
subpanel = panel.superpose, screen = list(z = 50, x = -80, y = 0), 
par.settings = par.set)

What should I add in order to get tick marks on the x, y, and z axes? I 
would like to use this for my own data, with tick marks preferably at 
defined positions [in original scale] for each axis.

Thanks for helping a beginner!
/P??r Matsson

-- 
P??r Matsson, M.Sc.
Dept. of Pharmacy
Uppsala University
Box 580
SE-751 23 Uppsala
Sweden

Phone: +46 (0)18 471 43 71
Cell: +46 (0)70 22 99 836
Fax: +46 (0)18 471 43 77
www.farmaci.uu.se
Par.Matsson at farmaci.uu.se



From ripley at stats.ox.ac.uk  Wed Sep  1 16:49:00 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Sep 2004 15:49:00 +0100 (BST)
Subject: [R] Unique lists from a list
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E951746D7@iahce2knas1.iah.bbsrc.reserved>
Message-ID: <Pine.LNX.4.44.0409011544220.32330-100000@gannet.stats>

On Wed, 1 Sep 2004, michael watson (IAH-C) wrote:

> I have a list.  Two of the elements of this list are "Name" and
> "Address", both of which are character vectors.  Name and Address are
> linked, so that the same "Name" always associates with the same
> "Address".
> 
> What I want to do is pull out the unique values, as a new list of the
> same format (ie two elements of character vectors).  Now I've worked out
> that unique(list$Name) will give me a list of the unique names, but how
> do I then go and link those to the correct (unique) addresses so I end
> up with a new list which is the same format as the rest, but now unique?

match, as in match(unique(list$Name), list$name), OR indexing as in

Address <- list$Address
names(Address) <- list$Name
Name <- unique(list$Name)
list(Name, as.vector(Address[Name])

OR choose a better data structure as in

unique(as.data.frame(list))

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From james.holtman at convergys.com  Wed Sep  1 17:01:54 2004
From: james.holtman at convergys.com (james.holtman@convergys.com)
Date: Wed, 1 Sep 2004 11:01:54 -0400
Subject: [R] Unique lists from a list
Message-ID: <OF2DA896F9.C0628D9C-ON85256F02.00527FAE@nd.convergys.com>





Try this:

l.1 <- list(list(name='a', addr='123'),list(name='b', addr='234'),
      list(name='b', addr='234'), list(name='a', addr='123'))  # create a
list


l.names <- unlist(lapply(l.1, '[[', 'name'))  # get the 'name'
l.u <- unique(l.names)  # make unique

new.list <- l.1[match(l.u, l.names)]      # create new list with just one
'name'

__________________________________________________________
James Holtman        "What is the problem you are trying to solve?"
Executive Technical Consultant  --  Office of Technology, Convergys
james.holtman at convergys.com
+1 (513) 723-2929


                                                                                                                                          
                      "michael watson                                                                                                     
                      (IAH-C)"                     To:       <R-help at stat.math.ethz.ch>                                                   
                      <michael.watson at bbsrc        cc:                                                                                    
                      .ac.uk>                      Subject:  [R] Unique lists from a list                                                 
                      Sent by:                                                                                                            
                      r-help-bounces at stat.m                                                                                               
                      ath.ethz.ch                                                                                                         
                                                                                                                                          
                                                                                                                                          
                      09/01/2004 10:31                                                                                                    
                                                                                                                                          
                                                                                                                                          




Hi

I have a list.  Two of the elements of this list are "Name" and
"Address", both of which are character vectors.  Name and Address are
linked, so that the same "Name" always associates with the same
"Address".

What I want to do is pull out the unique values, as a new list of the
same format (ie two elements of character vectors).  Now I've worked out
that unique(list$Name) will give me a list of the unique names, but how
do I then go and link those to the correct (unique) addresses so I end
up with a new list which is the same format as the rest, but now unique?

Cheers
Mick

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Wed Sep  1 16:59:03 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 01 Sep 2004 07:59:03 -0700
Subject: [R] lme: howto specify covariance structure between levels of
	grouping factors
In-Reply-To: <BAY24-F186WGvyGp9dn00019c71@hotmail.com>
References: <BAY24-F186WGvyGp9dn00019c71@hotmail.com>
Message-ID: <4135E3B7.1060602@pdf.com>

      1.  Have you followed "the posting guide! 
http://www.R-project.org/posting-guide.html"?  In many cases, it might 
help you answer your own questions.  If not, it might help you formulate 
a question in a way that might generate more useful replies. 

      2.  Have you studied Pinhiero and  Bates (2000) Mixed Effects 
Models in S and S-Plus (Springer)?  In my opinion, this is an excellent 
book on the subject, and I was not able to use lme effectively until 
after I had studied that book. 

      hope this helps.  spencer graves

Patrick Van Cleemputte wrote:

> Dear all,
>
> I am studying the possibility of using the nlme package in R to 
> analyse field trials of agricultural crops. I have a problem with the 
> syntax for the modelling of variance covariance structures. I can 
> model the within-group covariance structure using the correlation 
> argument and the covariance structure between different random effects 
> of the same grouping level using 'random=pdDiag(~effect)|group' but I 
> would like to model the covariance structure' between' the different 
> levels of the grouping factor. This is necessary because the plants (= 
> grouping factor) we are testing are not independant. They are 
> genetically correlated and usually we know this correlation. I would 
> therefore also like to specify the exact (not starting) values of this 
> 'between subjects correlation'.
>
> Can you tell me if this is possible in R and how the syntax of such a 
> model would look like?
>
> thank you in advance,
>
> P.
>
>
> http://entertainment.msn.be/muziek/musicclub
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html


-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From ramasamy at cancer.org.uk  Wed Sep  1 17:05:53 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 01 Sep 2004 16:05:53 +0100
Subject: [R] Unique lists from a list
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E951746D7@iahce2knas1.iah.bbsrc.reserved>
References: <8975119BCD0AC5419D61A9CF1A923E951746D7@iahce2knas1.iah.bbsrc.reserved>
Message-ID: <1094051153.3152.22.camel@vpn202001.lif.icnet.uk>

name <- c("a", "b", "a", "c", "d", "a", "b")
addr <- c(10, 20, 10, 30, 40, 10, 20)

duplicated(name)
[1] FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE

which(duplicated(name))
[1] 3 6 7

addr[ -which(duplicated(name)) ]
[1] 10 20 30 40

cbind( name, addr) [ -which(duplicated(name)),  ]
     name addr
[1,] "a"  "10"
[2,] "b"  "20"
[3,] "c"  "30"
[4,] "d"  "40"

Make sure that person named "a" always lives in address "10" (i.e.
one-to-one mapping). 


If it is possible for person "a" to have two addresses (e.g. house and
office) "10" and "11", then it might be better to collect both address.
In this case, you can try :

addr2  <- c(10, 20, 11, 30, 40, 12, 21)
tapply(addr2, as.factor(name), function(x) paste(x, collapse=", ") )
           a            b            c            d
"10, 11, 12"     "20, 21"         "30"         "40"

To convert this into a list, use sapply(a, strsplit, split=", ").



On Wed, 2004-09-01 at 15:31, michael watson (IAH-C) wrote:
> Hi
> 
> I have a list.  Two of the elements of this list are "Name" and
> "Address", both of which are character vectors.  Name and Address are
> linked, so that the same "Name" always associates with the same
> "Address".
> 
> What I want to do is pull out the unique values, as a new list of the
> same format (ie two elements of character vectors).  Now I've worked out
> that unique(list$Name) will give me a list of the unique names, but how
> do I then go and link those to the correct (unique) addresses so I end
> up with a new list which is the same format as the rest, but now unique?
> 
> Cheers
> Mick
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From deepayan at stat.wisc.edu  Wed Sep  1 17:09:25 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 01 Sep 2004 10:09:25 -0500
Subject: [R] Tick marks in cloud (lattice)
In-Reply-To: <4135E137.6080707@farmaci.uu.se>
References: <4135E137.6080707@farmaci.uu.se>
Message-ID: <4135E625.1050805@stat.wisc.edu>



P??r Matsson wrote:
> Hi! Probably a simple question, but I can't get any tick marks in the 3d 
> scatterplot I created using the cloud function.
> 
> The following works to display the three groups using different symbols:
> 
> data(iris)
> cloud(Sepal.Length ~ Petal.Length * Petal.Width, data = iris, cex = 1.2, 
> groups = Species, pch = c(16,1,1), col = c("black","black","red"), 
> subpanel = panel.superpose, screen = list(z = 50, x = -80, y = 0), 
> par.settings = par.set)
> 
> What should I add in order to get tick marks on the x, y, and z axes? I 
> would like to use this for my own data, with tick marks preferably at 
> defined positions [in original scale] for each axis.

help(cloud) says:


   scales: describes scales. Can contain lists named x, y and z. Arrows
           are drawn if 'arrows=TRUE', otherwise tick marks with labels
           are drawn. Both can be suppressed by 'draw=FALSE'. Several
           other components that work in the usual 'scales' argument
           also work here (see 'xyplot').


(which I guess could use a bit more work). So you need to add

  scales = list(arrows = FALSE)

to your cloud call. For finer control, you really need to read the entry 
for scales in help(xyplot), after which the following should make sense.

cloud(Sepal.Length ~ Petal.Length * Petal.Width, data = iris,
       scales = list(arrows = F, x = list(at = 3:5)))


Deepayan



From jgoebel at diw.de  Wed Sep  1 17:30:30 2004
From: jgoebel at diw.de (Jan Goebel)
Date: Wed, 1 Sep 2004 17:30:30 +0200
Subject: [R] While installing Hmisc...
In-Reply-To: <20040830113741.25508.qmail@webmail17.rediffmail.com>
References: <20040830113741.25508.qmail@webmail17.rediffmail.com>
Message-ID: <20040901153030.GA32375@diw138134.diw-berlin.de>

I guess that the perl script during the installation of Hmisc
has used all of your available memory.
I had the same problem with my laptop (288MB RAM), using
the console without an X-Server and/or adding some temporary
Swap space could help.

Best

jan 

On Mon, 30 Aug 2004, data Analytics wrote:

> Dear R-Gurus:
> 
> This afternoon I was installing the "Hmisc" package.
> I use R in Linux (Fedora Core 1  (yarrow)) on a Compaq presario with 128 MB RAM laptop. 
> Opening an R session as a root user (superuser), I issued
> 
> install.packages("Hmisc")
> 
> and waited.
> 
> R downloaded the package, installation was going on, and on the standard output I could see that a list of "documentation filenames" being put out. When the list of filenames came to "somers2", the computer hung up for sometime and then started rebooting. 
> 
> I went back to read the manuals (installation guides), and I tried to install Hmisc again and made two attempts to install Hmisc. On both the occassions the laptop started rebooting when the list of "documentation filenames" output was at "somers2". 
> 
> I later found the Hmisc folder in a folder called 00LOCK in 
> my /usr/lib/R/library
> 
> I installed several other packages using the same command "install.packages("packagename")" but till today, never faced any difficulty.
> 
> What may be the issue? Anticipate your wisdom and advice.
> 
> /Arin Basu
>  
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
+-----------------------------------------
 Jan Goebel 
 j g o e b e l @ d i w . d e

 DIW Berlin 
 German Socio-Economic Panel Study (GSOEP) 
 K??nigin-Luise-Str. 5
 D-14195 Berlin -- Germany --
 phone: 49 30 89789-377
+-----------------------------------------



From t.dewez at brgm.fr  Wed Sep  1 17:41:24 2004
From: t.dewez at brgm.fr (Dewez Thomas)
Date: Wed, 1 Sep 2004 17:41:24 +0200 
Subject: [R] coercing a string naming to a variable name and return value
Message-ID: <D965434E9D6BD511AE3500306E01C8BE05DD6951@SRV0015>

Hi all,

I haven't been able to find how to assess a variable who's name is
constructed with paste. The problem is following: In a data frame, there are
12 columns whose title vary only by a digit, all other part being equal. I
would like to compute a operation on a subset these variables and parse them
in turn.

the data frame "basin.param" contains columns called ratio1, ratio2,
ratio3...
in each of these ratios I want to retain only values above 0. This could be
put like this

crit<- which(basin.param$ratio1 > 0)
basin.param$ratio1[crit] + basin.param$val[crit]

OK, so what if I want to increment from ratio1 to ratio3 automatically and
return the value of the variable represented by the string? (does this make
sense?)
# Create the variable name 
for (i in 1:3){
string.variable <- paste("basin.param$ratio", index, sep="")
# What is the instruction to interpret the string.variable value ???
}

Cheers

Thomas
***
Le contenu de cet e-mail et de ses pi??ces jointes est destin...{{dropped}}



From andy_liaw at merck.com  Wed Sep  1 17:48:27 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 1 Sep 2004 11:48:27 -0400
Subject: [R] Membership
Message-ID: <3A822319EB35174CA3714066D590DCD504AF82EB@usrymx25.merck.com>

http://cran.r-project.org/src/contrib/cluster_1.9.6.tar.gz

Andy


> From: Kannnan
> 
> Dear sir,
> 
> I like to change the objective function in 
> 
> fanny function(fuzzy clustering) and I like to modify the membership
> function in constructing membership grade to objects to the class.
> 
> 
> So I kindly request to provide the source code of this fanny function,
> it will be very helpful to continue my research, if you would provide
> this source code.
> 
> Thanking you,
> 
> Yours sincerely,
> S R Kannan
> 
> ************************************************************ 
> Dr. S R Kannan 
> DISI, Universit?? di Genova 
> Via Dodecaneso 35, 16146 Genova, Italy 
> e-mail kannan at disi.unige.it
>        srkannaniitm at mail.com
> phone +39-010-353 6707 
>       +39-340-710-2149
> fax   +39-010-353 6699
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From rpeng at jhsph.edu  Wed Sep  1 17:50:29 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 01 Sep 2004 11:50:29 -0400
Subject: [R] coercing a string naming to a variable name and return value
In-Reply-To: <D965434E9D6BD511AE3500306E01C8BE05DD6951@SRV0015>
References: <D965434E9D6BD511AE3500306E01C8BE05DD6951@SRV0015>
Message-ID: <4135EFC5.1060209@jhsph.edu>

You can use "[[", I think, as in

basin.param[[string.variable]]

or, eqivalently for a data frame

basin.param[, string.variable]

-roger

Dewez Thomas wrote:
> Hi all,
> 
> I haven't been able to find how to assess a variable who's name is
> constructed with paste. The problem is following: In a data frame, there are
> 12 columns whose title vary only by a digit, all other part being equal. I
> would like to compute a operation on a subset these variables and parse them
> in turn.
> 
> the data frame "basin.param" contains columns called ratio1, ratio2,
> ratio3...
> in each of these ratios I want to retain only values above 0. This could be
> put like this
> 
> crit<- which(basin.param$ratio1 > 0)
> basin.param$ratio1[crit] + basin.param$val[crit]
> 
> OK, so what if I want to increment from ratio1 to ratio3 automatically and
> return the value of the variable represented by the string? (does this make
> sense?)
> # Create the variable name 
> for (i in 1:3){
> string.variable <- paste("basin.param$ratio", index, sep="")
> # What is the instruction to interpret the string.variable value ???
> }
> 
> Cheers
> 
> Thomas
> ***
> Le contenu de cet e-mail et de ses pi??ces jointes est destin...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From sundar.dorai-raj at PDF.COM  Wed Sep  1 17:55:22 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 01 Sep 2004 08:55:22 -0700
Subject: [R] coercing a string naming to a variable name and return value
In-Reply-To: <D965434E9D6BD511AE3500306E01C8BE05DD6951@SRV0015>
References: <D965434E9D6BD511AE3500306E01C8BE05DD6951@SRV0015>
Message-ID: <4135F0EA.5040406@pdf.com>



Dewez Thomas wrote:
> Hi all,
> 
> I haven't been able to find how to assess a variable who's name is
> constructed with paste. The problem is following: In a data frame, there are
> 12 columns whose title vary only by a digit, all other part being equal. I
> would like to compute a operation on a subset these variables and parse them
> in turn.
> 
> the data frame "basin.param" contains columns called ratio1, ratio2,
> ratio3...
> in each of these ratios I want to retain only values above 0. This could be
> put like this
> 
> crit<- which(basin.param$ratio1 > 0)
> basin.param$ratio1[crit] + basin.param$val[crit]
> 
> OK, so what if I want to increment from ratio1 to ratio3 automatically and
> return the value of the variable represented by the string? (does this make
> sense?)
> # Create the variable name 
> for (i in 1:3){
> string.variable <- paste("basin.param$ratio", index, sep="")
> # What is the instruction to interpret the string.variable value ???
> }
> 

You're better off using the data.frame names with the "[" operator and 
not the data.frame name itself with the "$" operator. How about:

val <- list()
for(i in 1:3) {
   ratCol <- paste("ratio", i, sep = "")
   ratio.i <- basin.param[, ratCol]
   crit <- ratio.i > 0
   val[[ratCol]] <- ratio.i[crit] + basin.param$val[crit]
}

--sundar



From ggrothendieck at myway.com  Wed Sep  1 17:57:30 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 1 Sep 2004 15:57:30 +0000 (UTC)
Subject: [R] Accesing the name of an assigned object in a function
References: <ch47au$1kh$1@sea.gmane.org>
	<200409011314.46375.ahenningsen@email.uni-kiel.de>
Message-ID: <loom.20040901T173306-490@post.gmane.org>

Arne Henningsen <ahenningsen <at> email.uni-kiel.de> writes:

> 
> Hi Hendrik,
> 
> if I understand you right, match.call() can help you.
> 
> All the best,
> Arne
> 
> On Wednesday 01 September 2004 12:13, Henrik Andersson wrote:
> > I want to use the name that I assign to an object in the function that
> > produces the output, somewhat like below:
> >
> > stupid.function <- function(input){
> >  [body]
> >  cat("Summarized output is ", output$summary, "Full output is    given
> > by typing", assigned.name, "\n")
> >  }
> >
> > assigned.name <- stupid.function(whatever)
> >
> >
> > or another example is a function that sinks the results to a text file
> > and names it assigned.name.txt .
> >
> > I checked the help for function, <-, assign but could not find it, is it
> >   possible ?



As far as I know you are going to have to pass the assigned.name to the
function although there are a number of tricks that can make this a bit
nicer.  For example, run this:

example(lm)

# which has the effect of defining lm.D9 which we will use for our
# examples below.  Using that:

#### 1
set1 <- function(x, value) {
	name <- as.character(substitute(x))
	print(summary(value)$fstatistic)
	cat("That was F and df.  For more info type", name, "\n")
	assign(name, value, parent.frame())
	invisible(value)
}
set1(x, lm.D9)
x
	
# We can make this a bit prettier this way:

#### 2
set2 <- structure(NA,class="set2")
"[<-.set2" <- function(tmp,x,value) {
	name <- as.character(substitute(x))
	print(summary(value)$fstatistic)
	cat("That was F and df.  For more info type", name, "\n")
	assign(name, value, parent.frame())
	tmp
}

# now we can write:
set2[xx] <- lm.D9
xx

# Another strategy might be to use a global variable to store the
# last output from your function:

#### 3
set3 <- function(value) {
	name <- as.character(substitute(x))
	print(summary(value)$fstatistic)
	cat("That was F and df.  For more info type .set3\n")
	assign(".set3", value, .GlobalEnv)
	invisible(value)
}
xxx <- set3(lm.D9)  # or just set3(lm.D9)
.set3



From ramasamy at cancer.org.uk  Wed Sep  1 18:03:51 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 01 Sep 2004 17:03:51 +0100
Subject: [R] coercing a string naming to a variable name and return value
In-Reply-To: <D965434E9D6BD511AE3500306E01C8BE05DD6951@SRV0015>
References: <D965434E9D6BD511AE3500306E01C8BE05DD6951@SRV0015>
Message-ID: <1094054631.3152.28.camel@vpn202001.lif.icnet.uk>

I am not sure if I understand your problem but I think you might be
close to the solution. Perhaps if you changed 'index' in your code to
'i', you might get the answer. Try this :

set.seed(1066)
m <- matrix(rnorm(9), nc=3)
colnames(m) <- paste("ratio", 1:3, sep="")
 m
         ratio1     ratio2    ratio3
[1,] -0.5917632  0.2399853  2.810498
[2,]  0.2926060  0.9197199 -0.977170
[3,] -0.9212630 -0.7864827  1.746278


for(i in 1:3){ 
 name   <- paste("ratio", i, sep="")
 values <- m[ , name]
 cat("Column named", name, "has values", values, "\n") }
}

Column named ratio1 has values -0.5917632 0.2926060 -0.921263
Column named ratio2 has values 0.2399853 0.9197199 -0.7864827
Column named ratio3 has values 2.810498 -0.97717 1.746278


for(i in c(2,3,1)){ 
   cat("Column named", name <- paste("ratio", i, sep=""), 
       "has values", m[ , name], "\n") 
}
Column named ratio2 has values 0.2399853 0.9197199 -0.7864827
Column named ratio3 has values 2.810498 -0.97717 1.746278
Column named ratio1 has values -0.5917632 0.2926060 -0.921263



On Wed, 2004-09-01 at 16:41, Dewez Thomas wrote:
> Hi all,
> 
> I haven't been able to find how to assess a variable who's name is
> constructed with paste. The problem is following: In a data frame, there are
> 12 columns whose title vary only by a digit, all other part being equal. I
> would like to compute a operation on a subset these variables and parse them
> in turn.
> 
> the data frame "basin.param" contains columns called ratio1, ratio2,
> ratio3...
> in each of these ratios I want to retain only values above 0. This could be
> put like this
> 
> crit<- which(basin.param$ratio1 > 0)
> basin.param$ratio1[crit] + basin.param$val[crit]
> 
> OK, so what if I want to increment from ratio1 to ratio3 automatically and
> return the value of the variable represented by the string? (does this make
> sense?)
> # Create the variable name 
> for (i in 1:3){
> string.variable <- paste("basin.param$ratio", index, sep="")
> # What is the instruction to interpret the string.variable value ???
> }
> 
> Cheers
> 
> Thomas
> ***
> Le contenu de cet e-mail et de ses pi??ces jointes est destin...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From wuertz at itp.phys.ethz.ch  Wed Sep  1 19:34:20 2004
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Wed, 01 Sep 2004 17:34:20 +0000
Subject: [R] D'agostino test
In-Reply-To: <200409011220.31066.lbaring@stochastik.uni-hannover.de>
References: <5.0.2.1.2.20040830180658.00b04bd0@cimrs1.mnhn.fr>	<413573A2.5090508@itp.phys.ethz.ch>
	<200409011220.31066.lbaring@stochastik.uni-hannover.de>
Message-ID: <4136081C.603@itp.phys.ethz.ch>

Ludwig Baringhaus wrote:

>>Several versions of the D'Agostino Test are implemented in
>>"fBasics" from Rmetrics beside many other tests for normality
>>    
>>

>Unlike the Shapiro-Wilk or the Anderson-Darling test, the 
>D'Agostino test is not an omnibus test for testing the
>hypothesis of normality. In fact, D'Agostino's D 
>is a suitable test statistic for testing the hypothesis of 
>uniformity. See 
>Baringhaus and Henze (1990). 
>A test for uniformity with unknown limits based on D'Agostino's D. 
>Statist. Probab. Lett. 9, 299-304 
>  
>

So far, my understanding was the following that the D??Agostino(-Pearson) 
omnibus test
analyzes the data to determine skewness and kurtosis. It then calculates 
how far each
of these values differs from the value expected with a Gaussian 
distribution, and
computes a P value from the sum of the squares of these discrepancies. 
Unlike the
Shapiro-Wilk test, this test is not affected if the data contains 
identical values.

This kind of test is implemented in several other software packages 
under the name
"d'Agostino Test".

May be we are talking about different things.

D. Wuertz

PS: Thanks for the reference, I will have a look on it to clarify my 
understanding.

E.g., see also:
R.B. D'Agostino, "Tests for Normal Distribution" in /Goodness-Of-Fit 
Techniques/
E. Seier, "Comparisons of Tests for Univariate Normality"
J.D. McCauley, "Goodness of Fit Tests"
UITS, "Testing for Normality"

>L. Baringhaus
>Institut fuer Mathematische Stochastik
>Universitaet Hannover
>Welfengarten 1
>30167 Hannover
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From Paul.Schwarz at gartner.com  Wed Sep  1 20:44:46 2004
From: Paul.Schwarz at gartner.com (Schwarz,Paul)
Date: Wed, 1 Sep 2004 11:44:46 -0700
Subject: [R] using hist() with tapply()
Message-ID: <A00D32D4F8342C4CB741761ACE09130AE3D2F4@elk.gar.com>

Hi,

I've been passing the hist() function to tapply() to quickly generate histograms based on the list of factors supplied to tapply().  However, I have not figured out how to generate titles for each of the histograms, which paste in the unique values of the list factors as part of the histogram title.  I'm hoping that someone can tell me how to do this.

Thanks for your time and consideration,

-Paul Schwarz



From hodgess at gator.uhd.edu  Wed Sep  1 22:00:06 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Wed, 1 Sep 2004 15:00:06 -0500
Subject: [R] [R/S] strange
Message-ID: <200409012000.i81K06v30965@gator.dt.uh.edu>

Dear R and S People:

I have run across something very strange.  Here is a function that I wrote
for R:

boot1 <- function(y,method="f",p=1) {
n1 <- length(y)
n2 <- n1*p
n3 <- n2 - 1
a <- 0.5*(outer(1:n3,1:n3,function(x,y){n2 - pmax(x,y)}))
return(a)
}

and here is the R output:
> y1
[1] 9 8 7 3 6
> source("boot1.R")
> boot1(y=y1,p=4)
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] [,17] [,18] [,19]
 [1,]  9.5  9.0  8.5  8.0  7.5  7.0  6.5  6.0  5.5   5.0   4.5   4.0   3.5   3.0   2.5   2.0   1.5   1.0   0.5
 [2,]  9.0  9.0  8.5  8.0  7.5  7.0  6.5  6.0  5.5   5.0   4.5   4.0   3.5   3.0   2.5   2.0   1.5   1.0   0.5
 [3,]  8.5  8.5  8.5  8.0  7.5  7.0  6.5  6.0  5.5   5.0   4.5   4.0   3.5   3.0   2.5   2.0   1.5   1.0   0.5
 [4,]  8.0  8.0  8.0  8.0  7.5  7.0  6.5  6.0  5.5   5.0   4.5   4.0   3.5   3.0   2.5   2.0   1.5   1.0   0.5
 [5,]  7.5  7.5  7.5  7.5  7.5  7.0  6.5  6.0  5.5   5.0   4.5   4.0   3.5   3.0   2.5   2.0   1.5   1.0   0.5
 [6,]  7.0  7.0  7.0  7.0  7.0  7.0  6.5  6.0  5.5   5.0   4.5   4.0   3.5   3.0   2.5   2.0   1.5   1.0   0.5
 [7,]  6.5  6.5  6.5  6.5  6.5  6.5  6.5  6.0  5.5   5.0   4.5   4.0   3.5   3.0   2.5   2.0   1.5   1.0   0.5
 [8,]  6.0  6.0  6.0  6.0  6.0  6.0  6.0  6.0  5.5   5.0   4.5   4.0   3.5   3.0   2.5   2.0   1.5   1.0   0.5
 [9,]  5.5  5.5  5.5  5.5  5.5  5.5  5.5  5.5  5.5   5.0   4.5   4.0   3.5   3.0   2.5   2.0   1.5   1.0   0.5
[10,]  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0   5.0   4.5   4.0   3.5   3.0   2.5   2.0   1.5   1.0   0.5
[11,]  4.5  4.5  4.5  4.5  4.5  4.5  4.5  4.5  4.5   4.5   4.5   4.0   3.5   3.0   2.5   2.0   1.5   1.0   0.5
[12,]  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0   4.0   4.0   4.0   3.5   3.0   2.5   2.0   1.5   1.0   0.5
[13,]  3.5  3.5  3.5  3.5  3.5  3.5  3.5  3.5  3.5   3.5   3.5   3.5   3.5   3.0   2.5   2.0   1.5   1.0   0.5
[14,]  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0   3.0   3.0   3.0   3.0   3.0   2.5   2.0   1.5   1.0   0.5
[15,]  2.5  2.5  2.5  2.5  2.5  2.5  2.5  2.5  2.5   2.5   2.5   2.5   2.5   2.5   2.5   2.0   1.5   1.0   0.5
[16,]  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0   2.0   2.0   2.0   2.0   2.0   2.0   2.0   1.5   1.0   0.5
[17,]  1.5  1.5  1.5  1.5  1.5  1.5  1.5  1.5  1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.5   1.0   0.5
[18,]  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   0.5
[19,]  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5
> 
which is as it should be.

Now I tried the same thing in S+
> y1
[1] 9 8 7 3 6
> source("boot1.R")
> boot1(y=y1,p=4)
Problem in FUN(rep(X, length(Y)), rep(Y, each = length(X))): Object "n2" not found 
Use traceback() to see the call stack
> 

I have no idea why it works in R but not in S+.

R 1.9.1 for Windows
S+ Version 6.2 for Windows.
Any help is appreciated!

Is this part of the difference in scoping, please?

Sincerely,
Erin M. Hodgess
Associate Professor
Dept. of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgesse at uhd.edu



From jfox at mcmaster.ca  Wed Sep  1 22:05:18 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 1 Sep 2004 16:05:18 -0400
Subject: [R] Rcmdr X11 protocol error message
In-Reply-To: <4135B09B.7000602@qldnet.com.au>
Message-ID: <20040901200517.KSIS19123.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Michael and Peter,

I've made the following changes to the current development version of the
Rcmdr package (on my web site, at
http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/index.html, but not posted
to CRAN):

(1) The default for the Rcmdr grab.focus option is now set to FALSE for
non-Windows systems.

(2) There's a new report.X11.warnings option, which is set to FALSE by
default; this suppresses these warnings so that they don't appear in Rcmdr
warning dialogs. This just papers over the problem without really solving
it.

I'm not happy with these "solutions," but perhaps they'll help until we
discover the source of the problems. (I tested on my Quantian system.)

Thanks for your help.
 John

> -----Original Message-----
> From: Michael Bibo [mailto:mbibo at qldnet.com.au] 
> Sent: Wednesday, September 01, 2004 6:21 AM
> To: John Fox
> Cc: 'Peter Dalgaard'; r-help at stat.math.ethz.ch; 'Dirk Eddelbuettel'
> Subject: Re: [R] Rcmdr X11 protocol error message
> 
> John Fox wrote:
> 
> >Dear Peter and Michael,
> >
> >I installed Quantian on  a spare machine that I have and 
> observed the 
> >same warning messages that Michael has been reporting. These 
> (and the 
> >problem with help files but not with viewing data sets that Peter 
> >reported) occurred with version 0.9-11 of Rcmdr but not with 
> an earlier version.
> >
> >Since the code for the Rcmdr package was substantially reworked this 
> >summer, that seems to me a good candidate for the source of these 
> >problems, though I don't see why the changes should be 
> problematic. I'm 
> >afraid that I'm insufficiently familiar with the inner 
> workings of X11 
> >and Tcl/Tk to be much help in figuring out what's wrong. Everything 
> >seems to work fine under Windows, as far as I can tell.
> >
> >It occurs to me that if the warning messages are benign, one 
> approach 
> >would be to suppress them. I already intercept warnings and present 
> >them in dialog boxes; I could grep for "X11 protocol error" 
> and simply 
> >ignore these. That doesn't seem to me a good solution, however. It 
> >would be better to understand what's happening.
> >
> >I'm copying this message to Dirk since he's mentioned that 
> he plans to 
> >put the newer Rcmdr in Quantian. Dirk: Have you tested with 
> Rcmdr 0.9-11?
> >
> >Thank you.
> > John
> >  
> >
> >  
> >
> John, Peter and Dirk,
> 
> I'm glad I'm not the only one with a handle on it now.  I've 
> already exceeded my level of knowledge and skill in both 
> Linux and R.  But I'm happy to help track it down, if I can 
> be of assistance.  As I have said to John, the major value of 
> Rcmdr to me is to help 'sell' R to others in my organisation 
> currently using SPSS, and for this purpose, the Windows 
> version at work is working fine.  It is more of an annoyance 
> at home, as it doesn't seem to stop anything working.
> 
> Peter asked:
> 
> BTW, sometimes Tk errors allow you to see a trace of the execution.
> Would this happen to be one of those situations?
> 
> The short answer is I don't know (see my first line :-)).  
> There is no button on the dialogue box saying 'more 
> details...' or anything that obvious.  Is there a log file 
> somewhere on the system or some other way to generate such a trace?
> 
> I have been experimenting, and the following seem reliable 
> (at least on my system):
> 
> Error messages don't seem to happen for the first graph 
> generated.  The second graph drawn also generates an error 
> dialogue box with the error message repeated about 11 times.  
> The third and subsequent times exactly the same graph is 
> generated leads to an error message repeated about 21 times.  
> (I don't know if the number of repetitions is meaningful).  
> Note that the graphs are generated and visible when the error 
> messages appear.
> 
> Running any analysis that only writes output to the output 
> window (such as fitting a regression model) generates the 
> error messages before the output is written to the output 
> window.  The output appears when the error dialogue box is 
> OK'd.  I guess it's more likely to be responding to exiting 
> the dialogue box than writing the output.  But this only 
> happens when such error messages have been generated 
> previously in that session by creating a (second) graph.
> 
> If the diagnostic panel plots for a regression model are 
> called, the error messages appear, but this time the plots 
> themselves are not visible in the graphics device (it is 
> blank).  When the error messages are OK'd, the plots appear 
> in the device.
> 
> When exiting Rcmdr, then, and OK'ing the "Exit?" dialogue 
> box, the final error messages appear, but again only if they 
> have already been generated by a graph call.
> 
> I don't know if this will be helpful, but I thought reliable 
> observations might give some clues.
> 
> Regards,
> 
> Michael
> 
> michael_bibo at health.qld.gov.au
> 
> 
>



From hodgess at gator.uhd.edu  Wed Sep  1 22:12:11 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Wed, 1 Sep 2004 15:12:11 -0500
Subject: [R] [R/S] strange solution
Message-ID: <200409012012.i81KCBX32439@gator.dt.uh.edu>

Dear R and S People:

I ended up using the "assign" command, and things work in S+.

boot1 <- function(y,method="f",p=1) {
n1 <- length(y)
#n2 <- n1*p
assign("n2",n1*p)
n3 <- n2 - 1
a <- 0.5*(outer(1:n3,1:n3,function(x,y){n2 - pmax(x,y)}))
return(a)
}

thanks for listening!


Sincerely,
Erin H
mailto: hodgess at gator.uhd.edu



From spencer.graves at pdf.com  Wed Sep  1 22:39:25 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 01 Sep 2004 13:39:25 -0700
Subject: [R] Re: [S] [R/S] strange solution
In-Reply-To: <200409012012.i81KCHp32446@gator.dt.uh.edu>
References: <200409012012.i81KCHp32446@gator.dt.uh.edu>
Message-ID: <4136337D.9040105@pdf.com>

Hi, Erin: 

      A cleaner way is to pass "n2" to "outer" as a "..." argument, as 
in the following modification of your code: 

boot1 <- function(y,method="f",p=1) {
n1 <- length(y)
n2 <- n1*p
n3 <- n2 - 1
a <- 0.5*(outer(1:n3,1:n3,function(x,y, n2.){n2. - pmax(x,y)}, n2.=n2))
return(a)
}

y1 <- c( 9,  8, 7, 3, 6)

boot1(y=y1,p=4)

      The use of "assign" like this might be called "dirty programming", 
in the sense that any object "n2" in working directory will be 
overwritten without warning by the function "boot1", and then "boot1" 
leaves the "n2" garbage after it's done.  If you aren't aware of this 
side effect, you could get unpredictable problems with any other use of 
"n2" in the working directory. 

      The difference arises because of differences in the way R and 
S-Plus "scope" variable names.  This is described in the "R Language 
Definition" manual;  search for "scope" and "scoping" or do an R Site 
Search for terms like this at "www.r-project.org". 

      Passing the "n2" as an argument as I did in the above code seemed 
to work for me just now in S-Plus 6.2 and R 1.9.1 under Windows 2000. 

      Hope this helps. 
      Spencer Graves

Erin Hodgess wrote:

>Dear R and S People:
>
>I ended up using the "assign" command, and things work in S+.
>
>boot1 <- function(y,method="f",p=1) {
>n1 <- length(y)
>#n2 <- n1*p
>assign("n2",n1*p)
>n3 <- n2 - 1
>a <- 0.5*(outer(1:n3,1:n3,function(x,y){n2 - pmax(x,y)}))
>return(a)
>}
>
>thanks for listening!
>
>
>Sincerely,
>Erin H
>mailto: hodgess at gator.uhd.edu
>
>--------------------------------------------------------------------
>This message was distributed by s-news at lists.biostat.wustl.edu.  To
>...(s-news.. clipped)...

>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From kbartz at loyaltymatrix.com  Wed Sep  1 22:48:50 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Wed, 1 Sep 2004 13:48:50 -0700
Subject: [R] using hist() with tapply()
In-Reply-To: <A00D32D4F8342C4CB741761ACE09130AE3D2F4@elk.gar.com>
Message-ID: <20040901204851.5300740089@omta12.mta.everyone.net>

Hi Paul,

I think lattice's histogram will do what you want, and in a friendlier
manner. Take a look at this example:

require(lattice)
a <- data.frame(draw = as.vector(mapply(rnorm, rep(100, 4), rep(0, 4),
1:4)),
                sd   = factor(paste("sd =", rep(1:4, each = 100))))

Go ahead and examine "a": "draw" contains the aggregate results of random
draws with four different standard deviations, while "sd" tells you which
value of the standard deviation generated the draw. Naturally, I'd want four
histograms as my result. With lattice, I'd do

histogram(~ draw | sd, a)

and get back a sensible result.

Was this what you were looking for?

Kevin

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Schwarz,Paul
Sent: Wednesday, September 01, 2004 11:45 AM
To: r-help at stat.math.ethz.ch
Subject: [R] using hist() with tapply()

Hi,

I've been passing the hist() function to tapply() to quickly generate
histograms based on the list of factors supplied to tapply().  However, I
have not figured out how to generate titles for each of the histograms,
which paste in the unique values of the list factors as part of the
histogram title.  I'm hoping that someone can tell me how to do this.

Thanks for your time and consideration,

-Paul Schwarz

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From sblay at sfu.ca  Wed Sep  1 23:07:01 2004
From: sblay at sfu.ca (S. Blay)
Date: Wed, 1 Sep 2004 14:07:01 -0700
Subject: [R] allocating memory in C, not in R
Message-ID: <20040901210701.GA7158@sfu.ca>

Dear R helpers,

I need to retrieve several vectors of various types from a call 
to .C(), but I don't know their length in advance. 
Is there a way to do this without allocating an excessive amount 
of memory? 
If so, an example would be very helpful.


S. Blay
Department of Statistics and Actuarial Science
Simon Fraser University, Vancouver, British Columbia



From sundar.dorai-raj at PDF.COM  Wed Sep  1 23:11:26 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 01 Sep 2004 14:11:26 -0700
Subject: [R] allocating memory in C, not in R
In-Reply-To: <20040901210701.GA7158@sfu.ca>
References: <20040901210701.GA7158@sfu.ca>
Message-ID: <41363AFE.4050604@pdf.com>



S. Blay wrote:
> Dear R helpers,
> 
> I need to retrieve several vectors of various types from a call 
> to .C(), but I don't know their length in advance. 
> Is there a way to do this without allocating an excessive amount 
> of memory? 
> If so, an example would be very helpful.
> 
> 

You should probably use the .Call interface instead of .C in this case.

--sundar



From ripley at stats.ox.ac.uk  Wed Sep  1 23:16:59 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Sep 2004 22:16:59 +0100 (BST)
Subject: [R] allocating memory in C, not in R
In-Reply-To: <20040901210701.GA7158@sfu.ca>
Message-ID: <Pine.LNX.4.44.0409012214140.11377-100000@gannet.stats>

On Wed, 1 Sep 2004, S. Blay wrote:

> I need to retrieve several vectors of various types from a call 
> to .C(), but I don't know their length in advance. 
> Is there a way to do this without allocating an excessive amount 
> of memory? 
> If so, an example would be very helpful.

It would be very much easier to use .Call rather than .C.

Alternatively, generate and allocate in C on one C call and retrieve on a
second, as rpart does.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Wed Sep  1 23:24:23 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Sep 2004 23:24:23 +0200
Subject: [R] [R/S] strange
In-Reply-To: <200409012000.i81K06v30965@gator.dt.uh.edu>
References: <200409012000.i81K06v30965@gator.dt.uh.edu>
Message-ID: <x2656xlm2g.fsf@biostat.ku.dk>

Erin Hodgess <hodgess at gator.uhd.edu> writes:

> Dear R and S People:
> 
> I have run across something very strange.  Here is a function that I wrote
> for R:
> 
> boot1 <- function(y,method="f",p=1) {
>   n1 <- length(y)
>   n2 <- n1*p
>   n3 <- n2 - 1
>   a <- 0.5*(outer(1:n3,1:n3,function(x,y){n2 - pmax(x,y)}))
>   return(a)
> }
[and it doesn't work in S]

Well, if you didn't understand what lexical scoping was about before,
now is your chance... 

n2 is in the lexical scope of the (unnamed) function that is getting
passed to outer(), because the function is defined in (the environment
of) the call to boot1. Therefor the value of n2 is available inside
that function.

S doesn't have lexical scoping. Instead it has "frame 0" and "frame
1", which can be used as "scratchpads" for routines to scribble pieces
of information on. So a not-quite-so-dirty variant of your solution is
to assign n2 to frame 1, rather than as permanent data. Not the only
solution, obviously.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From vantini at mate.polimi.it  Thu Sep  2 00:58:43 2004
From: vantini at mate.polimi.it (Simone Vantini)
Date: Thu, 2 Sep 2004 00:58:43 +0200 (CEST)
Subject: [R] How to personalize the rpart function: t.default(x)
Message-ID: <25441.81.208.60.192.1094079523.squirrel@webmail.mate.polimi.it>

I'm trying to personalize the rpart function by introducing a
list('init','split','eval') in the argument method. But I receive an error
message:"Error in t.default(x): argument is not a matrix".
Can anyone tell me what the argument of this function is or where this
function appears in the rpart function.Thanks Simone Vantini



From rolf at math.unb.ca  Thu Sep  2 01:18:19 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed, 1 Sep 2004 20:18:19 -0300 (ADT)
Subject: [R] How to personalize the rpart function: t.default(x)
Message-ID: <200409012318.i81NIJow002166@erdos.math.unb.ca>


t is for transpose; look at ?t, ?t.default,
?t.data.frame

Bottom line:  Somewhere in your code you are trying to transpose
something that is not a matrix.  (Or you are passing to an existing
function an object which that function expects to be a matrix, but
isn't.)

			cheers,

				Rolf Turner
				rolf at math.unb.ca



From sblay at sfu.ca  Thu Sep  2 01:41:36 2004
From: sblay at sfu.ca (Sigal Blay)
Date: Wed, 1 Sep 2004 16:41:36 -0700
Subject: [R] allocating memory in C, not in R
In-Reply-To: <Pine.LNX.4.44.0409012214140.11377-100000@gannet.stats>
References: <20040901210701.GA7158@sfu.ca>
	<Pine.LNX.4.44.0409012214140.11377-100000@gannet.stats>
Message-ID: <20040901234136.GB23391@sfu.ca>

Thank you for the fast reply.

Below is a simplified version of my c function that I am 
currenctly using with a .C() call.
The values that has to be returned to R are the three outVectors.
If I need to convert .C to .Call,
How do I do it based on myFunction below?

Thank you for your help.
 

void myFunction(char **argv, int *inputVector, 
  int *RoutVector1, double *RoutVector2, char **RoutVector3) {
    int    *outVector1;
    double *outVector2;
    char   **outVector3;
    int roof = 0;
    roof = calculate_values ( argv[0], 
                              inputVector, 
                              &outVector1,
                              &outVector2, 
                              &outVector3   )

    for(i=0;i<roof;i++) {
        RoutVector1[i] = outVector1[i];    
        RoutVector2[i] = outVector2[i]; 
    }             
    return;
}


On Wed, Sep 01, 2004 at 10:16:59PM +0100, Prof Brian Ripley wrote:
> On Wed, 1 Sep 2004, S. Blay wrote:
> 
> > I need to retrieve several vectors of various types from a call 
> > to .C(), but I don't know their length in advance. 
> > Is there a way to do this without allocating an excessive amount 
> > of memory? 
> > If so, an example would be very helpful.
> 
> It would be very much easier to use .Call rather than .C.
> 
> Alternatively, generate and allocate in C on one C call and retrieve on a
> second, as rpart does.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Thu Sep  2 02:43:37 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 1 Sep 2004 20:43:37 -0400
Subject: [R] How to personalize the rpart function: t.default(x)
Message-ID: <3A822319EB35174CA3714066D590DCD504AF82F3@usrymx25.merck.com>

On top of what Rolf had said, traceback() would help tracking down how the
error happened.

Andy

> From: Rolf Turner
> 
> t is for transpose; look at ?t, ?t.default,
> ?t.data.frame
> 
> Bottom line:  Somewhere in your code you are trying to transpose
> something that is not a matrix.  (Or you are passing to an existing
> function an object which that function expects to be a matrix, but
> isn't.)
> 
> 			cheers,
> 
> 				Rolf Turner
> 				rolf at math.unb.ca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From sundar.dorai-raj at PDF.COM  Thu Sep  2 03:11:37 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 01 Sep 2004 18:11:37 -0700
Subject: [R] allocating memory in C, not in R
In-Reply-To: <20040901234136.GB23391@sfu.ca>
References: <20040901210701.GA7158@sfu.ca>	<Pine.LNX.4.44.0409012214140.11377-100000@gannet.stats>
	<20040901234136.GB23391@sfu.ca>
Message-ID: <41367349.5000708@pdf.com>



Sigal Blay wrote:
> Thank you for the fast reply.
> 
> Below is a simplified version of my c function that I am 
> currenctly using with a .C() call.
> The values that has to be returned to R are the three outVectors.
> If I need to convert .C to .Call,
> How do I do it based on myFunction below?
> 
> Thank you for your help.
>  
> 
> void myFunction(char **argv, int *inputVector, 
>   int *RoutVector1, double *RoutVector2, char **RoutVector3) {
>     int    *outVector1;
>     double *outVector2;
>     char   **outVector3;
>     int roof = 0;
>     roof = calculate_values ( argv[0], 
>                               inputVector, 
>                               &outVector1,
>                               &outVector2, 
>                               &outVector3   )
> 
>     for(i=0;i<roof;i++) {
>         RoutVector1[i] = outVector1[i];    
>         RoutVector2[i] = outVector2[i]; 
>     }             
>     return;
> }
> 
> 

Well, you could read "Writing R Extensions" (Section 4.8). Your function 
will have to change significantly, though. I would create a list within 
the C-function (called "val" below) and populate the RoutVectors with it.

(I can't remember whether you'll need more than #include <R.h>. Again, I 
direct you to the documentation.)

SEXP myFunction(SEXP argv, SEXP inputVector) {
   SEXP val;
   PROTECT(val = allocVector(VECSXP, 3));
   /* some code you'll have to write */
   UNPROTECT(1);
   return val;
}

# in R
RoutVectors <- .Call("myFunction", argv, inputVector)

--sundar

> On Wed, Sep 01, 2004 at 10:16:59PM +0100, Prof Brian Ripley wrote:
> 
>>On Wed, 1 Sep 2004, S. Blay wrote:
>>
>>
>>>I need to retrieve several vectors of various types from a call 
>>>to .C(), but I don't know their length in advance. 
>>>Is there a way to do this without allocating an excessive amount 
>>>of memory? 
>>>If so, an example would be very helpful.
>>
>>It would be very much easier to use .Call rather than .C.
>>
>>Alternatively, generate and allocate in C on one C call and retrieve on a
>>second, as rpart does.
>>
>>-- 
>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>University of Oxford,             Tel:  +44 1865 272861 (self)
>>1 South Parks Road,                     +44 1865 272866 (PA)
>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From hodgess at gator.uhd.edu  Thu Sep  2 04:35:58 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Wed, 1 Sep 2004 21:35:58 -0500
Subject: [R] [R/S] question re solution
Message-ID: <200409020235.i822ZwH13797@gator.dt.uh.edu>

Dear R and S People:

First, thank you to so many people for your help to my problem.

Here is the solution:

a <- 0.5*(outer(1:n3,1:n3,function(x,y,n2.){n2. - pmax(x,y)},n2.=n2))

I have one final pesky question, please:
During my experiments, I tried the following:

a <- 0.5*(outer(1:n3,1:n3,function(x,y,n2.=n2){n2. - pmax(x,y)}))
Why doesn't this work please?

thank you!

Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu



From spencer.graves at pdf.com  Thu Sep  2 04:53:18 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 01 Sep 2004 19:53:18 -0700
Subject: [R] Re: [S] [R/S] question re solution
In-Reply-To: <200409020235.i822ZrB13789@gator.dt.uh.edu>
References: <200409020235.i822ZrB13789@gator.dt.uh.edu>
Message-ID: <41368B1E.1020703@pdf.com>

<see below>

Erin Hodgess wrote:

>Dear R and S People:
>
>First, thank you to so many people for your help to my problem.
>
>Here is the solution:
>
>a <- 0.5*(outer(1:n3,1:n3,function(x,y,n2.){n2. - pmax(x,y)},n2.=n2))
>
>I have one final pesky question, please:
>During my experiments, I tried the following:
>
>a <- 0.5*(outer(1:n3,1:n3,function(x,y,n2.=n2){n2. - pmax(x,y)}))
>  
>
      In S-Plus, the function "outer" can't find "n2".  In the form

outer(1:n3,1:n3,function(x,y,n2.=n2){n2. - pmax(x,y)}), n2.=n2)


      the value of "n2" is passed to "n2." as part of the "..." 
argument.  Someone else mentioned Venables and Ripley (2000) S 
Programming (Springer).  Please see this or some other discussion of the 
"..." argument. 

      hope this helps. 
      spencer graves

>Why doesn't this work please?
>
>thank you!
>
>Sincerely,
>Erin Hodgess
>Associate Professor
>Department of Computer and Mathematical Sciences
>University of Houston - Downtown
>mailto: hodgess at gator.uhd.edu
>--------------------------------------------------------------------
>This message was distributed by s-news at lists.biostat.wustl.edu.  To
>...(s-news.. clipped)...

>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From kjetil at acelerate.com  Wed Sep  1 23:58:59 2004
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Wed, 01 Sep 2004 17:58:59 -0400
Subject: [R] using hist() with tapply()
In-Reply-To: <A00D32D4F8342C4CB741761ACE09130AE3D2F4@elk.gar.com>
References: <A00D32D4F8342C4CB741761ACE09130AE3D2F4@elk.gar.com>
Message-ID: <41364623.6000908@acelerate.com>

Schwarz,Paul wrote:

>Hi,
>
>I've been passing the hist() function to tapply() to quickly generate histograms based on the list of factors supplied to tapply().  However, I have not figured out how to generate titles for each of the histograms, which paste in the unique values of the list factors as part of the histogram title.  I'm hoping that someone can tell me how to do this.
>
>Thanks for your time and consideration,
>
>-Paul Schwarz
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>
I can't see it with talpply, but mapply and split works:

test <- rnorm(1000)
fac <- factor( rep(1:5, 200))
par(mfrow=c(2,3))
mapply(hist, split(test, fac), main=levels(fac))


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra



From Wanzare at HCJP.com  Thu Sep  2 06:26:58 2004
From: Wanzare at HCJP.com (Manoj - Hachibushu Capital)
Date: Thu, 2 Sep 2004 13:26:58 +0900
Subject: [R] Re: [S] [R/S] question re solution
Message-ID: <1CBA12F2D414914989C723D196B287DC26BCF9@jp-svr-ex1.hcjp.com>

> Someone else mentioned Venables and Ripley (2000) S 
> Programming (Springer).  Please see this or some other discussion of
the 
> "..." argument.

The "Introduction to R" (from Cran website) also talks about it. See pg
49 - section 10.4 (was just reading this the other day).

Cheers

Manoj


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Spencer Graves
Sent: Thursday, September 02, 2004 11:53 AM
To: Erin Hodgess
Cc: R-help; s-news at wubios.wustl.edu
Subject: [R] Re: [S] [R/S] question re solution

<see below>

Erin Hodgess wrote:

>Dear R and S People:
>
>First, thank you to so many people for your help to my problem.
>
>Here is the solution:
>
>a <- 0.5*(outer(1:n3,1:n3,function(x,y,n2.){n2. - pmax(x,y)},n2.=n2))
>
>I have one final pesky question, please:
>During my experiments, I tried the following:
>
>a <- 0.5*(outer(1:n3,1:n3,function(x,y,n2.=n2){n2. - pmax(x,y)}))
>  
>
      In S-Plus, the function "outer" can't find "n2".  In the form

outer(1:n3,1:n3,function(x,y,n2.=n2){n2. - pmax(x,y)}), n2.=n2)


      the value of "n2" is passed to "n2." as part of the "..." 
argument.  Someone else mentioned Venables and Ripley (2000) S 
Programming (Springer).  Please see this or some other discussion of the

"..." argument. 

      hope this helps. 
      spencer graves

>Why doesn't this work please?
>
>thank you!
>
>Sincerely,
>Erin Hodgess
>Associate Professor
>Department of Computer and Mathematical Sciences
>University of Houston - Downtown
>mailto: hodgess at gator.uhd.edu
>--------------------------------------------------------------------
>This message was distributed by s-news at lists.biostat.wustl.edu.  To
>...(s-news.. clipped)...

>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Kevin.Wang at maths.anu.edu.au  Thu Sep  2 06:31:10 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Thu, 02 Sep 2004 14:31:10 +1000
Subject: [R] xtable Questions
In-Reply-To: <x2656xlm2g.fsf@biostat.ku.dk>
References: <200409012000.i81K06v30965@gator.dt.uh.edu>
	<x2656xlm2g.fsf@biostat.ku.dk>
Message-ID: <4136A20E.5070009@maths.anu.edu.au>

Hi,

These are two problems I've never seen when I used xtable() before...

R 1.9.1 for Windows XP, xtable version 1.2-3:
   > final.df
               Loci Chr    Marker Position P.values Deviance DF
   1           Idd5   1  D1Mit181     42.6   0.0011   103.21 78
   2     Idd6/19/20   6  D6Mit374     66.7   0.0014   104.29 78
   3          Idd13   2  D2Mit490     64.5   0.0025    97.83 78
   4        Idd8/12  13 D14Mit109       24   0.0244   102.41 78
   5          Idd14  14  D13Mit39      3.3   0.0379    95.92 78
   6  Idd3/10/17/18   3  D3Mit257     49.2    0.068   105.45 78
   7           Idd9   4  D4Mit233     69.9   0.1406   107.13 78
   8          Idd15   5  D5Mit338     43.7   0.2196   107.67 78
   9           Idd7   7  D7Mit101     45.9   0.4608    95.96 78
   10          Idd2   9  D9Mit328     17.5   0.5125   107.25 78
   11          Aire  10 D10Mit198     33.9   0.6457   106.13 78
   12          Idd4  11 D11Mit298     37.2   0.9261   107.47 78
   13         Idd21  18 D18Mit135      9.8   0.9272   107.67 78
   > xtable(final.df,
   +        caption = "Summary for each Locus",
   +        label = "tab:sumLocus")
   Error in x + ifelse(x == 0, 1, 0) : non-numeric argument to binary 
operator
   > is.data.frame(final.df)
   [1] TRUE

final.df is a data frame, but I cannot understand what the error message 
means about "non-numeric argument to binary operator".

The other problem is:
   > one.df
        Loci P.values
   1    Idd5   0.1147
   2   Idd13   0.0085
   3   Idd14    0.002
   4 Idd8.12    0.042
   5    Idd7   0.0114
   > xtable(one.df,
   +        caption = "Fitting without Interactions",
   +        label = "tab:noI")
   tab:noI
   % latex table generated in R 1.9.1 by xtable 1.2-3 package
   % Thu Sep 02 14:22:01 2004
   \begin{table}[ht]
   \begin{center}
   \begin{tabular}{rll}
   \hline
    & Loci & P.values \\
   \hline
   1 &    Idd5 & 0.1147 \\
   2 &   Idd13 & 0.0085 \\
   3 &   Idd14 &  0.002 \\
   4 & Idd8.12 &  0.042 \\
   5 &    Idd7 & 0.0114 \\
   \hline
   \end{tabular}
   \caption{Fitting without Interactions}
   \end{center}
   \end{table}
   > is.data.frame(one.df)
   [1] TRUE

I want to give the resulting LaTeX markup for one.df a label, namely 
"tab:noI", but instead of putting a \label{tab:noI}, it just put 
"tab:noI" at the beginning of the output.

I've tried to completely clear the workspace, delete the .RData and 
start fresh.  But the problems still occur *_*.

Any help would be appreciated!

Kevin

-- 
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From ripley at stats.ox.ac.uk  Thu Sep  2 08:24:51 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Sep 2004 07:24:51 +0100 (BST)
Subject: [R] How to personalize the rpart function: t.default(x)
In-Reply-To: <25441.81.208.60.192.1094079523.squirrel@webmail.mate.polimi.it>
Message-ID: <Pine.LNX.4.44.0409020723390.29759-100000@gannet.stats>

On Thu, 2 Sep 2004, Simone Vantini wrote:

> I'm trying to personalize the rpart function by introducing a
> list('init','split','eval') in the argument method. But I receive an error
> message:"Error in t.default(x): argument is not a matrix".
> Can anyone tell me what the argument of this function is or where this
> function appears in the rpart function.Thanks Simone Vantini

t.default is the default method for the transpose function t() in R 
itself.

Try help!

Description:

     Given a matrix or 'data.frame' 'x', 't' returns the transpose of
     'x'.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Thu Sep  2 09:30:43 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Sep 2004 09:30:43 +0200
Subject: [R] [R/S] question re solution
In-Reply-To: <200409020235.i822ZwH13797@gator.dt.uh.edu>
References: <200409020235.i822ZwH13797@gator.dt.uh.edu>
Message-ID: <x24qmhdt5o.fsf@biostat.ku.dk>

Erin Hodgess <hodgess at gator.uhd.edu> writes:

> a <- 0.5*(outer(1:n3,1:n3,function(x,y,n2.=n2){n2. - pmax(x,y)}))
> Why doesn't this work please?

Because defaults are expressions to be evaluated in the function's
evaluation frame (i.e. the expression could depend on x and y for
instance). When you evaluate the function, it goes looking for n2 --
and you're back to square one, basically. You might use substitute to
poke a precomputed n2 into the function definition, but it isn't
pretty.  

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From NSpeybroeck at itg.be  Thu Sep  2 10:42:24 2004
From: NSpeybroeck at itg.be (Niko Speybroeck)
Date: Thu, 2 Sep 2004 10:42:24 +0200
Subject: [R] glmm
Message-ID: <15550BEC638FF648B46E8B33F55CD98E1130E3@itgsrv014.itg.be>

  
I am trying to use R. My question is if R can calculate a random effect
probit model {e.g. glmm} but including sampling weights. I am desperately
looking for a random effect model but wanted to use it on survey data.
 
Thanks for an answer: Niko Speybroeck.



From dimitris.rizopoulos at med.kuleuven.ac.be  Thu Sep  2 10:51:31 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 2 Sep 2004 10:51:31 +0200
Subject: [R] glmm
References: <15550BEC638FF648B46E8B33F55CD98E1130E3@itgsrv014.itg.be>
Message-ID: <00a701c490ca$0c40e6b0$ad133a86@www.domain>

Hi Niko,

look at functions `GLMM' (package: lme4) and `glmmPQL' (package:
MASS).

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Niko Speybroeck" <NSpeybroeck at itg.be>
To: <R-help at stat.math.ethz.ch>
Sent: Thursday, September 02, 2004 10:42 AM
Subject: [R] glmm


>
> I am trying to use R. My question is if R can calculate a random
effect
> probit model {e.g. glmm} but including sampling weights. I am
desperately
> looking for a random effect model but wanted to use it on survey
data.
>
> Thanks for an answer: Niko Speybroeck.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Jordi.Molins at drkw.com  Thu Sep  2 11:12:47 2004
From: Jordi.Molins at drkw.com (Molins, Jordi)
Date: Thu, 2 Sep 2004 11:12:47 +0200
Subject: [R] cross-correlations
Message-ID: <AA0BBC8742AFFF4583B91782E958CB660FCEE4@ibfftce121.de.ad.drkw.net>


Hello,

I have been looking around in past helps about cross-correlations for a set
of n time series.

Although you can do it by yourself calculating the out-of-the-diagonal terms
in the cross correlation matrix by using pairwise combinations of ccf and
the diagonal terms by using acf, this does not seem a very practical way of
doing things. Does anybody know a function that gives directly the
cross-correlation matrix?

thanks

Jordi



--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From NSpeybroeck at itg.be  Thu Sep  2 11:33:51 2004
From: NSpeybroeck at itg.be (Niko Speybroeck)
Date: Thu, 2 Sep 2004 11:33:51 +0200
Subject: [R] glmm
Message-ID: <15550BEC638FF648B46E8B33F55CD98E1130E6@itgsrv014.itg.be>

Hi Dimitris,
Thanks a lot for the answer! I see that in glmm you can specify "weight=" but
this is according to me corresponding to for example the frequency of a
certain observation and not to an weighing factor because of the sampling
design. Tell me if I'm wrong. Do you have an example with GLMM or glmmPQL, in
which you use sampling (probability) weights? Thanks in advance.
Niko
 

________________________________

Van: Dimitris Rizopoulos [mailto:dimitris.rizopoulos at med.kuleuven.ac.be]
Verzonden: do 2/09/2004 10:51
Aan: Niko Speybroeck
CC: r-help at stat.math.ethz.ch
Onderwerp: Re: [R] glmm



Hi Niko,

look at functions `GLMM' (package: lme4) and `glmmPQL' (package:
MASS).

Best,
Dimitris

----
Dimitris Rizopoulos
Doctoral Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message -----
From: "Niko Speybroeck" <NSpeybroeck at itg.be>
To: <R-help at stat.math.ethz.ch>
Sent: Thursday, September 02, 2004 10:42 AM
Subject: [R] glmm


>
> I am trying to use R. My question is if R can calculate a random
effect
> probit model {e.g. glmm} but including sampling weights. I am
desperately
> looking for a random effect model but wanted to use it on survey
data.
>
> Thanks for an answer: Niko Speybroeck.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Thu Sep  2 11:34:52 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Sep 2004 10:34:52 +0100 (BST)
Subject: [R] cross-correlations
In-Reply-To: <AA0BBC8742AFFF4583B91782E958CB660FCEE4@ibfftce121.de.ad.drkw.net>
Message-ID: <Pine.LNX.4.44.0409021027400.11446-100000@gannet.stats>

On Thu, 2 Sep 2004, Molins, Jordi wrote:

> I have been looking around in past helps about cross-correlations for a set
> of n time series.
> 
> Although you can do it by yourself calculating the out-of-the-diagonal terms
> in the cross correlation matrix by using pairwise combinations of ccf and
> the diagonal terms by using acf, this does not seem a very practical way of
> doing things. Does anybody know a function that gives directly the
> cross-correlation matrix?

acf!  There is even an example in its examples.  (BTW, it is a 3D array,
for you have a matrix at each lag.)

Please do read the posting guide and follow its advice about doing your 
homework.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wang.kevin at gmail.com  Thu Sep  2 12:54:53 2004
From: wang.kevin at gmail.com (Kevin Wang)
Date: Thu, 2 Sep 2004 20:54:53 +1000
Subject: [R] [OT]Example Data for Non-statisticians
Message-ID: <83fa4f4704090203545a99d8c6@mail.gmail.com>

(Sorry for the slightly off topic post)

I'm giving a talk (on data mining) to some non-statisticians (who're
all postgrad students, but a mixture of Science and Commerce majors).

My intention is to show them the importance of statistics when doing
data mining.  What I'm thinking of doing is using, hopefully, two
datasets.  One from scientific area and another that is
commercially-related.  However, it would be nice if the datasets (or
at least one of them) will violate some kind of basic statistical
assumptions (in its raw form anyway) -- hence showing having a basic
statistical knowledge is important.  Also hopefully, I can introduce R
to them (since many of them haven't heard of it yet).

Does anyone have (or know where I can get) such data?  It doesn't have
to be huge,.....

Thanks!

Kevin

-- 
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From Kevin.Wang at maths.anu.edu.au  Thu Sep  2 12:59:16 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Thu, 2 Sep 2004 20:59:16 +1000 (EST)
Subject: [R] Two xtable Questions
Message-ID: <Pine.GSO.4.58.0409022058170.5204@yin>

Hi,

These are two problems I've never seen when I used xtable() before...

R 1.9.1 for Windows XP, xtable version 1.2-3:
  > final.df
              Loci Chr    Marker Position P.values Deviance DF
  1           Idd5   1  D1Mit181     42.6   0.0011   103.21 78
  2     Idd6/19/20   6  D6Mit374     66.7   0.0014   104.29 78
  3          Idd13   2  D2Mit490     64.5   0.0025    97.83 78
  4        Idd8/12  13 D14Mit109       24   0.0244   102.41 78
  5          Idd14  14  D13Mit39      3.3   0.0379    95.92 78
  6  Idd3/10/17/18   3  D3Mit257     49.2    0.068   105.45 78
  7           Idd9   4  D4Mit233     69.9   0.1406   107.13 78
  8          Idd15   5  D5Mit338     43.7   0.2196   107.67 78
  9           Idd7   7  D7Mit101     45.9   0.4608    95.96 78
  10          Idd2   9  D9Mit328     17.5   0.5125   107.25 78
  11          Aire  10 D10Mit198     33.9   0.6457   106.13 78
  12          Idd4  11 D11Mit298     37.2   0.9261   107.47 78
  13         Idd21  18 D18Mit135      9.8   0.9272   107.67 78
  > xtable(final.df,
  +        caption = "Summary for each Locus",
  +        label = "tab:sumLocus")
  Error in x + ifelse(x == 0, 1, 0) : non-numeric argument to binary
operator
  > is.data.frame(final.df)
  [1] TRUE

final.df is a data frame, but I cannot understand what the error message
means about "non-numeric argument to binary operator".

The other problem is:
  > one.df
       Loci P.values
  1    Idd5   0.1147
  2   Idd13   0.0085
  3   Idd14    0.002
  4 Idd8.12    0.042
  5    Idd7   0.0114
  > xtable(one.df,
  +        caption = "Fitting without Interactions",
  +        label = "tab:noI")
  tab:noI
  % latex table generated in R 1.9.1 by xtable 1.2-3 package
  % Thu Sep 02 14:22:01 2004
  \begin{table}[ht]
  \begin{center}
  \begin{tabular}{rll}
  \hline
   & Loci & P.values \\
  \hline
  1 &    Idd5 & 0.1147 \\
  2 &   Idd13 & 0.0085 \\
  3 &   Idd14 &  0.002 \\
  4 & Idd8.12 &  0.042 \\
  5 &    Idd7 & 0.0114 \\
  \hline
  \end{tabular}
  \caption{Fitting without Interactions}
  \end{center}
  \end{table}
  > is.data.frame(one.df)
  [1] TRUE

I want to give the resulting LaTeX markup for one.df a label, namely
"tab:noI", but instead of putting a \label{tab:noI}, it just put "tab:noI"
at the beginning of the output.

I've tried to completely clear the workspace, delete the .RData and start
fresh.  But the problems still occur *_*.

Any help would be appreciated!

Kevin

--------------------------------
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From bjg at hig.se  Thu Sep  2 13:08:54 2004
From: bjg at hig.se (Bin Jiang)
Date: Thu, 02 Sep 2004 13:08:54 +0200
Subject: [R] newsgroup on R
Message-ID: <4136FF46.5060503@hig.se>

HI, I wonder if there is a newsgroup on R available, instead of 
emaillist which I have to receive mails daily.

Cheers.

Bin



From janpsmit at yahoo.co.uk  Thu Sep  2 13:13:23 2004
From: janpsmit at yahoo.co.uk (=?iso-8859-1?q?Jan=20Smit?=)
Date: Thu, 2 Sep 2004 12:13:23 +0100 (BST)
Subject: [R] Imputing missing values
In-Reply-To: <4135BC4E.9090303@vanderbilt.edu>
Message-ID: <20040902111323.97717.qmail@web86906.mail.ukl.yahoo.com>

Many thanks to Dimitris Rizopoulos, Mahbub Latif,
Manoj, and Frank Harrell for their suggestions and
comments. Dimitris' code gave me what I wanted. 

The data pertain to an impact evaluation of 32
irrigation projects. For each project, there is little
variability in the price farmers receive for each of
their crops within the same season, so I think
mean-imputation is reasonably safe. I have downloaded
Hmisc, though, and will have a close look.

Jan Smit

--- Frank E Harrell Jr <f.harrell at vanderbilt.edu>
wrote: 
> Dimitris Rizopoulos wrote:
> > Hi Jan,
> > 
> > you could try the following:
> > 
> > dat <- data.frame(Price=c(10,12,NA,8,7,9,NA,9,NA),
> >                   Crop=c(rep("Rise", 5),
> rep("Wheat", 4)),
> >                   Season=c(rep("Summer", 3),
> rep("Winter", 4),
> > rep("Summer", 2)))
> > ######
> > dat <- dat[order(dat$Season, dat$Crop),]
> > dat$Price.imp <- unlist(tapply(dat$Price,
> list(dat$Crop, dat$Season),
> > function(x){
> >   mx <- mean(x, na.rm=TRUE)
> >   ifelse(is.na(x), mx, x)
> >   }))
> > 
> > dat
> > 
> > However, you should be careful using this
> imputation technique since
> > you don't take into account the extra variability
> of imputing new
> > values in your data set. I don't know what
> analysis are you planning
> > to do but in any case I would recommend to read
> some standard
> > references for missing values, e.g., Little, R.
> and Rubin, D. (2002).
> > Statistical Analysis with Missing Data, New York:
> Wiley.
> > 
> > I hope this helps.
> > 
> > Best,
> > Dimitris
> > 
> > ----
> > Dimitris Rizopoulos
> > Doctoral Student
> > Biostatistical Centre
> > School of Public Health
> > Catholic University of Leuven
> > 
> > Address: Kapucijnenvoer 35, Leuven, Belgium
> > Tel: +32/16/396887
> > Fax: +32/16/337015
> > Web: http://www.med.kuleuven.ac.be/biostat/
> >     
>
http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
> > 
> > 
> > ----- Original Message ----- 
> > From: "Jan Smit" <janpsmit at yahoo.co.uk>
> > To: <R-help at stat.math.ethz.ch>
> > Sent: Wednesday, September 01, 2004 10:43 AM
> > Subject: [R] Imputing missing values
> > 
> > 
> > 
> >>Dear all,
> >>
> >>Apologies for this beginner's question. I have a
> >>variable Price, which is associated with factors
> >>Season and Crop, each of which have several
> levels.
> >>The Price variable contains missing values (NA),
> which
> >>I want to substitute by the mean of the remaining
> >>(non-NA) Price values of the same Season-Crop
> >>combination of levels.
> >>
> >>Price     Crop    Season
> >>10        Rice    Summer
> >>12        Rice    Summer
> >>NA        Rice    Summer
> >>8         Rice    Winter
> >>9         Wheat    Summer
> >>
> >>Price[is.na(Price)] gives me the missing values,
> and
> >>by(Price, list(Crop, Season), mean, na.rm = T) the
> >>values I want to impute. What I've not been able
> to
> >>figure out, by looking at by and the various
> >>incarnations of apply, is how to do the actual
> >>substitution.
> >>
> >>Any help would be much appreciated.
> >>
> >>Jan Smit
> 
> Or see the impute function in the Hmisc package and
> more general 
> solutions also in Hmisc.
> 
> 
> -- 
> Frank E Harrell Jr   Professor and Chair          
> School of Medicine
>                       Department of Biostatistics  
> Vanderbilt University
>



From JonesW at kssg.com  Thu Sep  2 13:36:36 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Thu, 2 Sep 2004 12:36:36 +0100 
Subject: [R] newsgroup on R
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB02BD195A@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040902/033c1552/attachment.pl

From ccleland at optonline.net  Thu Sep  2 13:45:32 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 02 Sep 2004 07:45:32 -0400
Subject: [R] newsgroup on R
In-Reply-To: <4136FF46.5060503@hig.se>
References: <4136FF46.5060503@hig.se>
Message-ID: <413707DC.5070104@optonline.net>

   You can follow the emails on this list via a news server:

http://gmane.org/info.php?group=gmane.comp.lang.r.general

Bin Jiang wrote:
> HI, I wonder if there is a newsgroup on R available, instead of 
> emaillist which I have to receive mails daily.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From bjg at hig.se  Thu Sep  2 13:51:42 2004
From: bjg at hig.se (Bin Jiang)
Date: Thu, 02 Sep 2004 13:51:42 +0200
Subject: [R] newsgroup on R
In-Reply-To: <413707DC.5070104@optonline.net>
References: <4136FF46.5060503@hig.se> <413707DC.5070104@optonline.net>
Message-ID: <4137094E.1090308@hig.se>

HI, by newsgroup, I mean a kind of user forum like MATLABs 
http://newsreader.mathworks.com/WebX?14@@/comp.soft-sys.matlab

where anyone can post a question, without receiving unnecessary emails daily


Chuck Cleland wrote:

>   You can follow the emails on this list via a news server:
>
> http://gmane.org/info.php?group=gmane.comp.lang.r.general
>
> Bin Jiang wrote:
>
>> HI, I wonder if there is a newsgroup on R available, instead of 
>> emaillist which I have to receive mails daily.
>
>



From f.harrell at vanderbilt.edu  Thu Sep  2 14:01:27 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 02 Sep 2004 08:01:27 -0400
Subject: [R] [OT]Example Data for Non-statisticians
In-Reply-To: <83fa4f4704090203545a99d8c6@mail.gmail.com>
References: <83fa4f4704090203545a99d8c6@mail.gmail.com>
Message-ID: <41370B97.3060901@vanderbilt.edu>

Kevin Wang wrote:
> (Sorry for the slightly off topic post)
> 
> I'm giving a talk (on data mining) to some non-statisticians (who're
> all postgrad students, but a mixture of Science and Commerce majors).
> 
> My intention is to show them the importance of statistics when doing
> data mining.  What I'm thinking of doing is using, hopefully, two
> datasets.  One from scientific area and another that is
> commercially-related.  However, it would be nice if the datasets (or
> at least one of them) will violate some kind of basic statistical
> assumptions (in its raw form anyway) -- hence showing having a basic
> statistical knowledge is important.  Also hopefully, I can introduce R
> to them (since many of them haven't heard of it yet).
> 
> Does anyone have (or know where I can get) such data?  It doesn't have
> to be huge,.....
> 
> Thanks!
> 
> Kevin
> 
The titanic3 dataset on our web site - issue 
loadUrl('http://biostat.mc.vanderbilt.edu/twiki/pub/Main/DataSets/titanic3.sav') 
to load( ) it - may fit the bill although the response variable is 
binary.  Assumptions that would be violated in a trivial analysis would 
be additivity of age and passenger class, and perhaps linearity of age. 
  At least it is a dataset that everyone understands already.

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From andy_liaw at merck.com  Thu Sep  2 14:11:02 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 2 Sep 2004 08:11:02 -0400
Subject: [R] newsgroup on R
Message-ID: <3A822319EB35174CA3714066D590DCD504AF82FA@usrymx25.merck.com>

If I'm not mistaken, that's what gmane does.  AFAIK there's not a usenet
group on R, but gmane makes R-help look like one.

Andy

> From: Bin Jiang
> 
> HI, by newsgroup, I mean a kind of user forum like MATLABs 
> http://newsreader.mathworks.com/WebX?14@@/comp.soft-sys.matlab
> 
> where anyone can post a question, without receiving 
> unnecessary emails daily
> 
> 
> Chuck Cleland wrote:
> 
> >   You can follow the emails on this list via a news server:
> >
> > http://gmane.org/info.php?group=gmane.comp.lang.r.general
> >
> > Bin Jiang wrote:
> >
> >> HI, I wonder if there is a newsgroup on R available, instead of 
> >> emaillist which I have to receive mails daily.
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From Kevin.Wang at maths.anu.edu.au  Thu Sep  2 14:26:27 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Thu, 2 Sep 2004 22:26:27 +1000 (EST)
Subject: [R] newsgroup on R
In-Reply-To: <4136FF46.5060503@hig.se>
References: <4136FF46.5060503@hig.se>
Message-ID: <Pine.GSO.4.58.0409022225560.6839@yin>

Hi,

On Thu, 2 Sep 2004, Bin Jiang wrote:

> HI, I wonder if there is a newsgroup on R available, instead of
> emaillist which I have to receive mails daily.

AFAIK the answer is no.  I think this has been brought up and discussed a
few years ago and the idea was kind of...rejected.

Kevin

--------------------------------
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From petzoldt at rcs.urz.tu-dresden.de  Thu Sep  2 14:28:25 2004
From: petzoldt at rcs.urz.tu-dresden.de (Thomas Petzoldt)
Date: Thu, 02 Sep 2004 14:28:25 +0200
Subject: [R] newsgroup on R
In-Reply-To: <4137094E.1090308@hig.se>
References: <4136FF46.5060503@hig.se> <413707DC.5070104@optonline.net>
	<4137094E.1090308@hig.se>
Message-ID: <ch73lb$qku$1@sea.gmane.org>

Bin Jiang wrote:

> HI, by newsgroup, I mean a kind of user forum like MATLABs
> http://newsreader.mathworks.com/WebX?14@@/comp.soft-sys.matlab
>
> where anyone can post a question, without receiving unnecessary emails
> daily

Hi,

gmane.org IS a gateway from and to a newsgroup system in the original
(NNTP) style. You can simply use the gmane web interface or configure
your newsreader program (e.g. Mozilla Thunderbird) and all things should
work perfectly and, what is more important, in a very efficient way.

Furthermore, there are a lot of alternatives: you can get the messages
as weekly digest or you may use the Archives:

https://stat.ethz.ch/pipermail/r-help/

Thomas

BTW: This mail was sent via GMANE.



From michael.watson at bbsrc.ac.uk  Thu Sep  2 15:21:20 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Thu, 2 Sep 2004 14:21:20 +0100
Subject: [R] Problems with heatmap.2
Message-ID: <8975119BCD0AC5419D61A9CF1A923E957C297D@iahce2knas1.iah.bbsrc.reserved>

Hi

When I give the command:

>
heatmap.2(as.matrix(d),Rowv=as.dendrogram(hc.gene),Colv=FALSE,scale="row
",trace="none",col=greenred.colors(79))

The resulting heatmap has re-ordered my columns!  This is time-course
data, and I don't want my columns re-ordered!  Note from the help:

    Rowv: determines if and how the _row_ dendrogram should be
          reordered.  Either a 'dendrogram' or a vector of values used
          to reorder the row dendrogram or 'FALSE' to suppress
          reordering or by default, 'NULL', see _Details_ below.

    Colv: determines if and how the _column_ dendrogram should be
          reordered.  Has the options as the 'Rowv' argument above and
          _additionally_ when 'x' is a square matrix, 'Colv = "Rowv"'
          means that columns should be treated identically to the rows.

I have specifically set "Colv=FALSE" in my command.

Help?  What am I doing wrong?

Cheers
Mick



From sdavis2 at mail.nih.gov  Thu Sep  2 15:38:48 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 2 Sep 2004 09:38:48 -0400
Subject: [R] Problems with heatmap.2
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E957C297D@iahce2knas1.iah.bbsrc.reserved>
References: <8975119BCD0AC5419D61A9CF1A923E957C297D@iahce2knas1.iah.bbsrc.reserved>
Message-ID: <6B7062E4-FCE5-11D8-8E73-000A95D7BA10@mail.nih.gov>

Didn't test this, but I think you probably want to do  
dendrogram="row",Colv=1:n
where n is the number of samples.

Sean

On Sep 2, 2004, at 9:21 AM, michael watson (IAH-C) wrote:

> Hi
>
> When I give the command:
>
>>
> heatmap.2(as.matrix(d),Rowv=as.dendrogram(hc.gene),Colv=FALSE,scale="ro 
> w
> ",trace="none",col=greenred.colors(79))
>
> The resulting heatmap has re-ordered my columns!  This is time-course
> data, and I don't want my columns re-ordered!  Note from the help:
>
>     Rowv: determines if and how the _row_ dendrogram should be
>           reordered.  Either a 'dendrogram' or a vector of values used
>           to reorder the row dendrogram or 'FALSE' to suppress
>           reordering or by default, 'NULL', see _Details_ below.
>
>     Colv: determines if and how the _column_ dendrogram should be
>           reordered.  Has the options as the 'Rowv' argument above and
>           _additionally_ when 'x' is a square matrix, 'Colv = "Rowv"'
>           means that columns should be treated identically to the rows.
>
> I have specifically set "Colv=FALSE" in my command.
>
> Help?  What am I doing wrong?
>
> Cheers
> Mick
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!  
> http://www.R-project.org/posting-guide.html



From h.andersson at nioo.knaw.nl  Thu Sep  2 15:37:03 2004
From: h.andersson at nioo.knaw.nl (Henrik Andersson)
Date: Thu, 02 Sep 2004 15:37:03 +0200
Subject: [R] newsgroup on R
In-Reply-To: <4136FF46.5060503@hig.se>
References: <4136FF46.5060503@hig.se>
Message-ID: <ch77l1$619$1@sea.gmane.org>

Try news.gmane.org

There you'll find gmane.comp.lang.r.general and gmane.emacs.ess.general

/Henrik

Bin Jiang wrote:
> HI, I wonder if there is a newsgroup on R available, instead of 
> emaillist which I have to receive mails daily.
> 
> Cheers.
> 
> Bin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From tlumley at u.washington.edu  Thu Sep  2 16:15:34 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 2 Sep 2004 07:15:34 -0700 (PDT)
Subject: [R] glmm
In-Reply-To: <00a701c490ca$0c40e6b0$ad133a86@www.domain>
References: <15550BEC638FF648B46E8B33F55CD98E1130E3@itgsrv014.itg.be>
	<00a701c490ca$0c40e6b0$ad133a86@www.domain>
Message-ID: <Pine.A41.4.58.0409020712050.130370@homer06.u.washington.edu>

On Thu, 2 Sep 2004, Dimitris Rizopoulos wrote:

> Hi Niko,
>
> look at functions `GLMM' (package: lme4) and `glmmPQL' (package:
> MASS).

Yes, but they don't take sampling weights.

We had this discussion a while back for linear mixed models and no-one had
a really satisfactory solution. In contrast to most simple regression
models, mixed models don't even give the right point estimates when you
use sampling weights and pretend they are precision weights.

I think the best solution that was suggested is to put the weights in the
model as a predictor (unless they depend on variables that shouldn't be in
the model).  As the weights completely describe the biased sampling, this
will give a valid model-based analysis.

For a design-based analysis you are probably out of luck.

	-thomas


>
> Best,
> Dimitris
>
> ----
> Dimitris Rizopoulos
> Doctoral Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
>
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/396887
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
>
>
> ----- Original Message -----
> From: "Niko Speybroeck" <NSpeybroeck at itg.be>
> To: <R-help at stat.math.ethz.ch>
> Sent: Thursday, September 02, 2004 10:42 AM
> Subject: [R] glmm
>
>
> >
> > I am trying to use R. My question is if R can calculate a random
> effect
> > probit model {e.g. glmm} but including sampling weights. I am
> desperately
> > looking for a random effect model but wanted to use it on survey
> data.
> >
> > Thanks for an answer: Niko Speybroeck.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From bro092 at yahoo.com  Thu Sep  2 16:26:31 2004
From: bro092 at yahoo.com (dan roberts)
Date: Thu, 2 Sep 2004 07:26:31 -0700 (PDT)
Subject: [R] trivial question about nested loops
Message-ID: <20040902142631.18543.qmail@web52605.mail.yahoo.com>

Hello,

It's a trivial question but I haven't found a solution in the
full reference manual. How can I make the code below run? Would
an array/matrix solution be faster? Please provide a short
example, if possible.

Thanks in advance,
dan

for (k in 1:5) 
	assign(paste("f",k,sep=""),vector(mode="complex",5))
for (k in 1:5) {
	for(j in 1:5) 
		f[k][[j]] <- sum(d$Y[k]*exp(-1i*j*d$X)) }
Error: Object "f" not found

(I want f[k] to become f1,...,f5; and d$Y[k] should be
d$Y1,...,d$Y5.)



From NSpeybroeck at itg.be  Thu Sep  2 16:27:49 2004
From: NSpeybroeck at itg.be (Niko Speybroeck)
Date: Thu, 2 Sep 2004 16:27:49 +0200
Subject: [R] glmm
Message-ID: <15550BEC638FF648B46E8B33F55CD98E1130EB@itgsrv014.itg.be>

Thanks a lot for you answer Thomas. Do you have a reference which supports
this solution? Can you give an example of a  weight  that depends on
variables that shouldn't be in the model?

________________________________

Van: Thomas Lumley [mailto:tlumley at u.washington.edu]
Verzonden: do 2/09/2004 16:15
Aan: Dimitris Rizopoulos
CC: Niko Speybroeck; r-help at stat.math.ethz.ch
Onderwerp: Re: [R] glmm



On Thu, 2 Sep 2004, Dimitris Rizopoulos wrote:

> Hi Niko,
>
> look at functions `GLMM' (package: lme4) and `glmmPQL' (package:
> MASS).

Yes, but they don't take sampling weights.

We had this discussion a while back for linear mixed models and no-one had
a really satisfactory solution. In contrast to most simple regression
models, mixed models don't even give the right point estimates when you
use sampling weights and pretend they are precision weights.

I think the best solution that was suggested is to put the weights in the
model as a predictor (unless they depend on variables that shouldn't be in
the model).  As the weights completely describe the biased sampling, this
will give a valid model-based analysis.

For a design-based analysis you are probably out of luck.

        -thomas


>
> Best,
> Dimitris
>
> ----
> Dimitris Rizopoulos
> Doctoral Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
>
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/396887
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
>
>
> ----- Original Message -----
> From: "Niko Speybroeck" <NSpeybroeck at itg.be>
> To: <R-help at stat.math.ethz.ch>
> Sent: Thursday, September 02, 2004 10:42 AM
> Subject: [R] glmm
>
>
> >
> > I am trying to use R. My question is if R can calculate a random
> effect
> > probit model {e.g. glmm} but including sampling weights. I am
> desperately
> > looking for a random effect model but wanted to use it on survey
> data.
> >
> > Thanks for an answer: Niko Speybroeck.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>

Thomas Lumley                   Assoc. Professor, Biostatistics
tlumley at u.washington.edu        University of Washington, Seattle



From murdoch at stats.uwo.ca  Thu Sep  2 16:50:19 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 02 Sep 2004 10:50:19 -0400
Subject: [R] trivial question about nested loops
In-Reply-To: <20040902142631.18543.qmail@web52605.mail.yahoo.com>
References: <20040902142631.18543.qmail@web52605.mail.yahoo.com>
Message-ID: <nbcej09smoisl017gt2h8a00tq3boj72r2@4ax.com>

On Thu, 2 Sep 2004 07:26:31 -0700 (PDT), dan roberts
<bro092 at yahoo.com> wrote :

>Hello,
>
>It's a trivial question but I haven't found a solution in the
>full reference manual. How can I make the code below run? 

Probably most easily if f was a list of lists (see solution 1 below).

>Would
>an array/matrix solution be faster? Please provide a short
>example, if possible.

Yes if the problem were bigger; see solution 2 below.  With the 5x5
size, you won't notice any difference.

>
>Thanks in advance,
>dan
>
>for (k in 1:5) 
>	assign(paste("f",k,sep=""),vector(mode="complex",5))
>for (k in 1:5) {
>	for(j in 1:5) 
>		f[k][[j]] <- sum(d$Y[k]*exp(-1i*j*d$X)) }
>Error: Object "f" not found
>
>(I want f[k] to become f1,...,f5; and d$Y[k] should be
>d$Y1,...,d$Y5.)
>

Solution 1:

f <- list()
for (k in 1:5) {
	f[[k]] <- list()
	for(j in 1:5) 
		f[[k]][[j]] <- sum(d$Y[k]*exp(-1i*j*d$X)) 
}
for (k in 1:5) 
	assign(paste("f",k,sep=""),f[[k]])

Solution 2:

f <- matrix( vector(mode="complex", 25), 5, 5)
for (k in 1:5) {
	for(j in 1:5) 
		f[k,j] <- sum(d$Y[k]*exp(-1i*j*d$X)) 
}
for (k in 1:5) 
	assign(paste("f",k,sep=""),f[k,])



From mapdpl at bath.ac.uk  Thu Sep  2 16:56:56 2004
From: mapdpl at bath.ac.uk (Duncan Lee)
Date: Thu, 2 Sep 2004 15:56:56 +0100
Subject: [R] corARMA
Message-ID: <001501c490fd$17382e60$0961268a@mapc0028>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040902/fb538f52/attachment.pl

From RBaskin at ahrq.gov  Thu Sep  2 17:08:35 2004
From: RBaskin at ahrq.gov (Baskin, Robert)
Date: Thu, 2 Sep 2004 11:08:35 -0400 
Subject: [R] glmm
Message-ID: <6BCD3F430455B1418750004BCD27925902926312@exchange2.ahrq.gov>

I believe in the earlier discussion it was Spencer Graves that pointed out
that there is earlier work by DuMouchel using design information but not
weights as predictors.

The reference for the use of design weights as predictors is:
<<<Start insert from earlier email<<<
< 9. Pfeffermann, D. , Skinner, C. J. , Holmes, D. J. , Goldstein, H. , and
Rasbash, J.  (1998), ``Weighting for unequal selection probabilities in
multilevel models (Disc: p41-56)'', Journal of the Royal Statistical
Society, Series B, Methodological, 60 , 23-40 >

which refers back to:
<29. Pfeffermann, D. , and LaVange, L.  (1989), ``Regression models for
stratified multi-stage cluster samples'', Analysis of Complex Surveys,
237-260 >

If you don't like statistical papers, then see section 4.5 of <8. Korn,
Edward Lee , and Graubard, Barry I.  (1999), ``Analysis of health surveys'',
John Wiley & Sons (New York; Chichester) > They explain the idea of using
weights in a model fairly simply.
>>>End insert>>>


In the earlier discussion Thomas Lumley pointed out that this means your
resulting estimates are conditional on the weights - so it's not a good
solution - just the only one published using weights.

I believe there is a Bayesian solution in the vein of Ghosh & Meeden
(1997-Chapman Hall) but it hasn't been published.

And my personal opinion is that before anyone uses design weights they
should read:
http://www-unix.oit.umass.edu/~cluster/ed/outline/c00ed72.PDF

bob



-----Original Message-----
From: Niko Speybroeck [mailto:NSpeybroeck at itg.be] 
Sent: Thursday, September 02, 2004 10:28 AM
To: Thomas Lumley; Dimitris Rizopoulos
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] glmm


Thanks a lot for you answer Thomas. Do you have a reference which supports
this solution? Can you give an example of a  weight  that depends on
variables that shouldn't be in the model?

________________________________

Van: Thomas Lumley [mailto:tlumley at u.washington.edu]
Verzonden: do 2/09/2004 16:15
Aan: Dimitris Rizopoulos
CC: Niko Speybroeck; r-help at stat.math.ethz.ch
Onderwerp: Re: [R] glmm



On Thu, 2 Sep 2004, Dimitris Rizopoulos wrote:

> Hi Niko,
>
> look at functions `GLMM' (package: lme4) and `glmmPQL' (package: 
> MASS).

Yes, but they don't take sampling weights.

We had this discussion a while back for linear mixed models and no-one had a
really satisfactory solution. In contrast to most simple regression models,
mixed models don't even give the right point estimates when you use sampling
weights and pretend they are precision weights.

I think the best solution that was suggested is to put the weights in the
model as a predictor (unless they depend on variables that shouldn't be in
the model).  As the weights completely describe the biased sampling, this
will give a valid model-based analysis.

For a design-based analysis you are probably out of luck.

        -thomas


>
> Best,
> Dimitris
>
> ----
> Dimitris Rizopoulos
> Doctoral Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
>
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/396887
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
>
>
> ----- Original Message -----
> From: "Niko Speybroeck" <NSpeybroeck at itg.be>
> To: <R-help at stat.math.ethz.ch>
> Sent: Thursday, September 02, 2004 10:42 AM
> Subject: [R] glmm
>
>
> >
> > I am trying to use R. My question is if R can calculate a random
> effect
> > probit model {e.g. glmm} but including sampling weights. I am
> desperately
> > looking for a random effect model but wanted to use it on survey
> data.
> >
> > Thanks for an answer: Niko Speybroeck.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>

Thomas Lumley                   Assoc. Professor, Biostatistics
tlumley at u.washington.edu        University of Washington, Seattle

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From tlumley at u.washington.edu  Thu Sep  2 17:54:09 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 2 Sep 2004 08:54:09 -0700 (PDT)
Subject: [R] glmm
In-Reply-To: <15550BEC638FF648B46E8B33F55CD98E1130EB@itgsrv014.itg.be>
References: <15550BEC638FF648B46E8B33F55CD98E1130EB@itgsrv014.itg.be>
Message-ID: <Pine.A41.4.58.0409020844040.198672@homer12.u.washington.edu>

On Thu, 2 Sep 2004, Niko Speybroeck wrote:

> Thanks a lot for you answer Thomas. Do you have a reference which supports
> this solution? Can you give an example of a  weight  that depends on
> variables that shouldn't be in the model?
>

Robert Baskin has answered some of this.

Additional points
1) I don't have a reference, but the argument would be that the design
variables affect the distribution of the outcome only through the weights.
The situation where it might be preferable just to adjust for weights
would be if the weights depended on a lot of variables (eg indicator
variables for fifty states).


2) An example:  suppose you were interested racial differences in heart
disease.  As race has a substantial effect on income and income may well
have a substantial effect on health, you might want to fit models with and
without income.  If the survey weights depend on median income for a
region you would be unable to fit models that did not include income.

This illustrates the  main situation when a variable can be strongly
predictive but you don't want it in your model: when it is in the
hypothesised causal pathway between an exposure you are interested in and
the outcome.  A less interesting situation is when you don't want to use a
variable that is available in your data set because it won't be available
in future data sets.


	-thomas



From rvalliant at survey.umd.edu  Thu Sep  2 18:48:34 2004
From: rvalliant at survey.umd.edu (Richard Valliant)
Date: Thu, 02 Sep 2004 12:48:34 -0400
Subject: [R] Question on survey package
Message-ID: <s13716ac.019@SURVEYGWIA.UMD.EDU>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040902/29dabea4/attachment.pl

From bro092 at yahoo.com  Thu Sep  2 18:52:07 2004
From: bro092 at yahoo.com (dan roberts)
Date: Thu, 2 Sep 2004 09:52:07 -0700 (PDT)
Subject: [R] trivial question about nested loops
In-Reply-To: <nbcej09smoisl017gt2h8a00tq3boj72r2@4ax.com>
Message-ID: <20040902165207.77370.qmail@web52605.mail.yahoo.com>

Duncan,

I tried your solutions and they almost work. The problem seems
to be d$Y[k]. When I run the code with d$Y[k], I get an empty
matrix (all 0s). However, if I replace d$Y[k] with, for example,
d&Y4, then I get a matrix with one of the results I am looking
for. Do you have any idea how I could make d$Y[k] actually pull
the columns from the imported table (d$Y1, d$Y2, ...)?
I tried
sum(paste("d$Y",k,sep="")*exp(-1i*j*d$X)) 
but I got 
Error in paste("d$Y", k, sep = "") * exp(-(0+1i) * j * d$X) : 
        non-numeric argument to binary operator

Thanks,
dan

d <- read.delim('ft.txt', header = TRUE, sep = "\t", quote="\"",
dec=".", fill = TRUE)
n <- 5
f <- matrix(vector(mode="complex",n^2),n,n)
for (k in 1:n) {
	for(j in 1:n) 
		f[k,j] <- sum(d$Y[k]*exp(-1i*j*d$X)) 
}





--- Duncan Murdoch <murdoch at stats.uwo.ca> wrote:

> On Thu, 2 Sep 2004 07:26:31 -0700 (PDT), dan roberts
> <bro092 at yahoo.com> wrote :
> 
> >Hello,
> >
> >It's a trivial question but I haven't found a solution in the
> >full reference manual. How can I make the code below run? 
> 
> Probably most easily if f was a list of lists (see solution 1
> below).
> 
> >Would
> >an array/matrix solution be faster? Please provide a short
> >example, if possible.
> 
> Yes if the problem were bigger; see solution 2 below.  With
> the 5x5
> size, you won't notice any difference.
> 
> >
> >Thanks in advance,
> >dan
> >
> >for (k in 1:5) 
> >	assign(paste("f",k,sep=""),vector(mode="complex",5))
> >for (k in 1:5) {
> >	for(j in 1:5) 
> >		f[k][[j]] <- sum(d$Y[k]*exp(-1i*j*d$X)) }
> >Error: Object "f" not found
> >
> >(I want f[k] to become f1,...,f5; and d$Y[k] should be
> >d$Y1,...,d$Y5.)
> >
> 
> Solution 1:
> 
> f <- list()
> for (k in 1:5) {
> 	f[[k]] <- list()
> 	for(j in 1:5) 
> 		f[[k]][[j]] <- sum(d$Y[k]*exp(-1i*j*d$X)) 
> }
> for (k in 1:5) 
> 	assign(paste("f",k,sep=""),f[[k]])
> 
> Solution 2:
> 
> f <- matrix( vector(mode="complex", 25), 5, 5)
> for (k in 1:5) {
> 	for(j in 1:5) 
> 		f[k,j] <- sum(d$Y[k]*exp(-1i*j*d$X)) 
> }
> for (k in 1:5) 
> 	assign(paste("f",k,sep=""),f[k,])
>



From ggrothendieck at myway.com  Thu Sep  2 19:18:20 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 2 Sep 2004 17:18:20 +0000 (UTC)
Subject: [R] trivial question about nested loops
References: <nbcej09smoisl017gt2h8a00tq3boj72r2@4ax.com>
	<20040902165207.77370.qmail@web52605.mail.yahoo.com>
Message-ID: <loom.20040902T191305-216@post.gmane.org>

dan roberts <bro092 <at> yahoo.com> writes:

: I tried your solutions and they almost work. The problem seems
: to be d$Y[k]. When I run the code with d$Y[k], I get an empty
: matrix (all 0s). However, if I replace d$Y[k] with, for example,
: d&Y4, then I get a matrix with one of the results I am looking
: for. Do you have any idea how I could make d$Y[k] actually pull
: the columns from the imported table (d$Y1, d$Y2, ...)?
: I tried
: sum(paste("d$Y",k,sep="")*exp(-1i*j*d$X)) 
: but I got 
: Error in paste("d$Y", k, sep = "") * exp(-(0+1i) * j * d$X) : 
:         non-numeric argument to binary operator

You need to post your data.  Without that no one can try out their
solution prior to posting.

If d is your data frame include the output of

    dput(d)

in your post.   If there are a large number of rows then just
provide the first few:

    dput(d[1:10,])



From murdoch at stats.uwo.ca  Thu Sep  2 19:20:06 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 02 Sep 2004 13:20:06 -0400
Subject: [R] trivial question about nested loops
In-Reply-To: <20040902165207.77370.qmail@web52605.mail.yahoo.com>
References: <nbcej09smoisl017gt2h8a00tq3boj72r2@4ax.com>
	<20040902165207.77370.qmail@web52605.mail.yahoo.com>
Message-ID: <98lej0hdjlint5arg42d2nv2m0j01utffc@4ax.com>

On Thu, 2 Sep 2004 09:52:07 -0700 (PDT), dan roberts
<bro092 at yahoo.com> wrote:

>Duncan,
>
>I tried your solutions and they almost work. The problem seems
>to be d$Y[k]. When I run the code with d$Y[k], I get an empty
>matrix (all 0s). However, if I replace d$Y[k] with, for example,
>d&Y4, then I get a matrix with one of the results I am looking
>for. Do you have any idea how I could make d$Y[k] actually pull
>the columns from the imported table (d$Y1, d$Y2, ...)?

What is d?  If it's a data.frame or other list, then 

d[[paste("Y",k,sep="")]] would get the Yk column.  If it's a matrix
with named columns

d[,paste("Y",k,sep="")]

would work.

>I tried
>sum(paste("d$Y",k,sep="")*exp(-1i*j*d$X)) 
>but I got 
>Error in paste("d$Y", k, sep = "") * exp(-(0+1i) * j * d$X) : 
>        non-numeric argument to binary operator

It thought you were trying to multiply by the string "d$Y1".  There
are a number of ways to evaluate a string as if it was code, but you
don't really need those.

Duncan Murdoch



From tlumley at u.washington.edu  Thu Sep  2 19:30:55 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 2 Sep 2004 10:30:55 -0700 (PDT)
Subject: [R] Question on survey package
In-Reply-To: <s13716ac.019@SURVEYGWIA.UMD.EDU>
References: <s13716ac.019@SURVEYGWIA.UMD.EDU>
Message-ID: <Pine.A41.4.58.0409020955410.198672@homer12.u.washington.edu>

On Thu, 2 Sep 2004, Richard Valliant wrote:

> Is there a way to use one of the functions in the survey package to get
> a table of estimated percentages (or proportions) and the standard error
> for each?  For example, suppose that AGECODE AND SEX are two factors
> with 5 and 2 levels.
>
> The 5x2 AGECODE x SEX table would have the estimated percentage of
> persons in each cell,
>

The computations can be done easily enough with svymean or svrepmean, but
the layout isn't quite what you want

Example:

library(survey)
data(api)
dclus1<-svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)

> svymean(~interaction(stype,comp.imp),design=dclus1)
                                      mean     SE
interaction(stype, comp.imp)E.No  0.174863 0.0260
interaction(stype, comp.imp)H.No  0.038251 0.0161
interaction(stype, comp.imp)M.No  0.060109 0.0246
interaction(stype, comp.imp)E.Yes 0.612022 0.0417
interaction(stype, comp.imp)H.Yes 0.038251 0.0161
interaction(stype, comp.imp)M.Yes 0.076503 0.0217


Turning this into a 3x2 table with a mean and SE in each cell would take a
bit of work since R doesn't have a very general table layout system.

One approach is

ftable.svystat<-function(x,rownames){

    m<-cbind(coef(x),sqrt(diag(vcov(x))))
    if (is.null(rownames))
        return(as.table(m))

    rowdim<-sapply(rownames,length)

    mm<-array(m,dim=c(rowdim,NCOL(m)),
             dimnames=c(as.list(rownames),
             list(c("coef","SE"))))


    ftable(mm,row.vars=length(rowdim)+0:1)

}

which gives

a <- svymean(~interaction(stype,comp.imp),design=dclus1)
b <- ftable(a,list(c("E","H","M"),c("No","Yes")))

round(b*100,1)
             E    H    M

No  coef  17.5  3.8  6.0
    SE     2.6  1.6  2.5
Yes coef  61.2  3.8  7.7
    SE     4.2  1.6  2.2


or with named dimnames

> b<-ftable(a,list(stype=c("E","H","M"),comp.imp=c("No","Yes")))
> round(b*100,1)
              stype    E    H    M
comp.imp
No       coef       17.5  3.8  6.0
         SE          2.6  1.6  2.5
Yes      coef       61.2  3.8  7.7
         SE          4.2  1.6  2.2



	-thomas



From gunter.berton at gene.com  Thu Sep  2 19:43:02 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 2 Sep 2004 10:43:02 -0700
Subject: [R] trivial question about nested loops
In-Reply-To: <98lej0hdjlint5arg42d2nv2m0j01utffc@4ax.com>
Message-ID: <200409021743.i82Hh2pE010875@volta.gene.com>




> >sum(paste("d$Y",k,sep="")*exp(-1i*j*d$X)) 
> >but I got 
> >Error in : 
> >        non-numeric argument to binary operator
> 
> It thought you were trying to multiply by the string "d$Y1".  There
> are a number of ways to evaluate a string as if it was code, but you
> don't really need those.
> 
> Duncan Murdoch
> 

(Perhaps unnecessary) translation:

In your expression:

paste("d$Y", k, sep = "") * exp(-(0+1i) * j * d$X) 

the paste part to the left of * is (evaluated as) a character string like
'abc': the exp part to the right is (evaluated as)a numeric quantity. It
makes no sense to the "binary operator" * to multiply two such entities
together.

Duncan's remark means that if you want to somehow translate the character
string into a numeric expression that R can understand and do something
with, there are ways to do it (as this is what the "R Evaluator" must do for
anything that one gives it), but it is not necesary to go to such technical
lengths here.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

From v.tron at ed.ac.uk  Thu Sep  2 20:05:49 2004
From: v.tron at ed.ac.uk (Viktor Tron)
Date: Thu, 02 Sep 2004 19:05:49 +0100
Subject: [R] suggestion for a small addition to the R-FAQ 
Message-ID: <opsdpojzs2z5aw2e@postbox.inf.ed.ac.uk>

Dear Kurt and R-ers,

Short: please add info to the faq about how to make sure you have R and how to start up the interpreter (jump to the end)

Long:

I was gonna use the tool called UCS which requires R.
So I wanted to make sure if our university system has it.
I act before I ask so I thought I check if we have R installed.
Now wait. But how?
I knew R was an interpreted language so it must have an interpreter which
I can call on the command prompt to test. But what is it called?
Although I thought it just can't be called 'R', can it, b but tried

$ which R
which: no R in .....

What now? You don't want me to type 'locate R', do you?
I cunningly tried

$ locate /R/ though with no success, but locate might not be up-to-date anyway.

with irrelevant non-hits. I was still not sure, so I thought I will
have a 'quick' look at some online manual to make sure.

I read through
- http://cran.r-project.org/doc/manuals/R-admin.pdf
- http://cran.r-project.org/src/base/INSTALL
- http://cran.r-project.org/src/base/README
- http://cran.r-project.org/doc/FAQ/R-FAQ.html

In the latter I found:

> You can also perform a ?system-wide? installation using make install. By default, this will install to the following directories:${prefix}/bin
> the front-end shell script

by no means will I tell me what it is called :-)

> ${prefix}/man/man1
> the man page

I won't tell you what to 'man' once it is.

${prefix}/lib/R
all the rest (libraries, on-line help system, ...). This is the ?R Home Directory? (R_HOME) of the installed system.

Hurray! This gave me a hint that the library dir will indeed be called R!
I tried to look at all the relevant /lib-s not finding R, but it may still
be under some exotic place.

Finally on page 4 of
http://cran.r-project.org/doc/manuals/R-intro.pdf
(which I was deterred from opening first since it is a 100 page long
manual in pdf format) I found:

2. Start the R program with the command:

  $ R

Great! It is indeed an interpreter and it is called 'R'.
we didn't have it. I installed it.
However trivial such things are, since the FAQ and other mans mention
functions (even for calling help functions) without ever telling how to
make R to interpret them.

All in all may I recommand that you consider including the following
in the R FAQ Basics section:


Q: How can I make sure R is installed on my system:
A: type in
    $ which R
    or
    $ man R


Q: How do I start an interactive R session?
A: type in
    $ R
    For other ways of running R code see the manual by typing
    $ man R

Also I want to send this letter directly to the FAQ maintainer as well
but the FAQ does not contain their mail. (surely I found him with a bit of
extra work :-) May I humbly suggest that 1.5 of the FAQ be supplemented
with Kurt's (or the maintainer's) email address:

> 1.5 Feedback
>
> Feedback is of course most welcome.
> In particular, note that I do not have access to Windows or
> Macintosh systems. Features specific to the Windows and Mac OS X
> ports of R are described in the ?R for Windows FAQ? and the ?R for
> Mac OS X FAQ. If you have information on Macintosh or Windows
> systems that you think should be added to this document, please let
> me know.

Ironically the software that needed R turned out to have a
proper prerequisite tester.


Thanks
Best
Viktor
(I am not a subscriber of the help list)



From rwatersg at yahoo.com  Thu Sep  2 21:33:41 2004
From: rwatersg at yahoo.com (Robert Waters)
Date: Thu, 2 Sep 2004 12:33:41 -0700 (PDT)
Subject: [R] confidence intervals
Message-ID: <20040902193341.1678.qmail@web90103.mail.scd.yahoo.com>

Dear R users;

Im working with lme and Id like to have an idea of how
can I get CI for the predictions made with the model.
Im not a stats guy but, if Im not wrong, the CIs
should be different if Im predicting a new data point
or a new group. Ive been searching through the web and
in help-lists with no luck. I know this topic had been
asked before but without replies. Can anyone give an
idea of where can I found information about this or
how can I get it from R?

Thanks for any hint

RW



From aleid2001 at yahoo.com  Thu Sep  2 20:40:00 2004
From: aleid2001 at yahoo.com (=?iso-8859-1?q?=20?=)
Date: Thu, 2 Sep 2004 19:40:00 +0100 (BST)
Subject: [R] cross random effects and PQL
Message-ID: <20040902184000.4756.qmail@web52802.mail.yahoo.com>

Dear friends,

I have asked last few weeks about cross-random effects
using PQL, but I have not receive any answer because
might my question was not clear.

My question was about analysing the salamander mating
data using PQL. This data contain cross-random effects
for (male) and for (female). 
After opining MASS and nlme pakeges. I wrote this code

sala.glmm <- glmmPQL(fixed=y~WSf*WSM,
random=list(experiment=pdBlocked(list(pdIdent(~randf-1),pdIdent(~randm-1)))),
family=binomial, data=sala.data).

Where
data neame=sala.glmm which contain
 y is response
 wsf is fixed effect
 wsm is fixed effects
 randf  is random effect
 random is random effect
 where randf and randm are crossed.

The data contain three experiments at the same time.
The previous cod is work but it does not give me
accurate result especially for the random effects.

For experiment I wrote this code 

experiment <-
factor(c(rep(1,120),rep(2,120),rep(3,120)))
 because I have three experiments at the same time,
but if I change the experiment to e.g

experiment <- factor(c(rep(1,360)))

is still give answer but is not the right answer. So,
I am accusing my specification of the experiment
(group). If you have any suggestion pleas let me know.

   E-mail:aleid2001 at yahoo.com



From frankeye at cox.net  Thu Sep  2 23:06:56 2004
From: frankeye at cox.net (Frank J. Iannarilli, Jr.)
Date: Thu, 02 Sep 2004 17:06:56 -0400
Subject: [R] Fixes for pls.pcr 0.2.2 plot.mvr("prediction")
Message-ID: <A34FFFCAFD131ED55D4A352F@3048414F223A201B5995433A>

Hi,

I just sent the following bugfixes to author Ron Wehrens, but thought I 
should also make them available here.  This fixes the prediction plots, 
which are currently erroneous.

=======================


I found some bugs in the the plot.mvr() function, in the 
plottype="prediction" section:


1. Needs to set nscreens <- 1 for condition where length(which) = 1 AND 
length(nlv) = 1.  Otherwise, for such condition, the function exits with 
message "Error: Object nscreens not found".  Here is your code snippet, and 
my suggested addition is indicated by ========>>>>>>>>>>:

        if (length(which) > 1) {
            if (length(nlv) > 3) {
                par(ask = TRUE)
                par(mfrow = c(3, 2))
                nScreens <- ceiling(length(nlv)/3)
            }
            else {
                nScreens <- 1
                par(mfrow = c(length(nlv), 2))
            }
        }
        else {
            if (length(nlv) > 1) {
                nrow <- floor(sqrt(length(nlv)))
                mfrow <- c(nrow, ceiling(length(nlv)/nrow))
                par(mfrow = mfrow)
                nScreens <- 1
            }
 ======>>>>>nScreens <- 1
        }


2.  The prediction plots are being drawn based on incorrect indexing of the 
Ypred matrix -- this can be quite misleading :-)  Here is your code 
snippet:  Basically, need to replace all occurrences of
   mvrmodel$training$Ypred[, i, j] or mvrmodel$validat$Ypred[, i, j]
WITH
   mvrmodel$training$Ypred[, i, nlv[j]] or mvrmodel$validat$Ypred[, i, 
nlv[j]]



                for (j in indices) {
                  if (show[1]) {
                    plot(mvrmodel$Y[, i], mvrmodel$training$Ypred[,
                      i, j], xlab = "Measured", ylab = "Predicted",
                      type = "n", xlim = range(mvrmodel$Y[, i],
                        mvrmodel$training$Ypred[, i, j]), ylim = 
range(mvrmodel$Y[,
                        i], mvrmodel$training$Ypred[, i, j]),
                      main = paste("Training data\n", nlv[j],
                        "latent variables"))
                    if (npred > 1)
                      mtext(ynames[i])
                    abline(0, 1, col = "blue")
                    points(mvrmodel$Y[, i], mvrmodel$training$Ypred[,
                      i, j])
                  }
                  if (show[2]) {
                    plot(mvrmodel$Y[, i], mvrmodel$validat$Ypred[,
                      i, j], xlab = "Measured", ylab = "Predicted",
                      type = "n", xlim = range(mvrmodel$Y[, i],
                        mvrmodel$validat$Ypred[, i, j]), ylim = 
range(mvrmodel$Y[,
                        i], mvrmodel$validat$Ypred[, i, j]),
                      main = paste("Cross-validation data\n",
                        nlv[j], "latent variables"))
                    if (npred > 1)
                      mtext(ynames[i])
                    abline(0, 1, col = "blue")
                    points(mvrmodel$Y[, i], mvrmodel$validat$Ypred[,
                      i, j])


Regards,





Frank J. Iannarilli, Jr.  frankeye at cox.net
www.aerodyne.com/cosr/cosr.html



From kimjj at email.arizona.edu  Thu Sep  2 23:46:31 2004
From: kimjj at email.arizona.edu (JongJoo Kim)
Date: Thu, 02 Sep 2004 14:46:31 -0700
Subject: [R] syntex about a nested mixed linear model
Message-ID: <1094161591.15097.186.camel@kimjj.cals.arizona.edu>


I am a novice R user, and have been in trouble to get the right mixed
model syntax in microarray analyses.

There are three factors: Dye(2 levels), Temperature(3 levels) and
Array(3 for each Temperature with a total of 9 arrays). I want to treat
array as random, and to regard array variation different between
Temperatures.

So the model I want to seek is:

Y = Dye + Temp + Dye + Temp*Dye + Array(Temp) + Dye*Array(Temp).

For F tests of Dye and Dye*Temp, then denominator factor is 
Dye*Array(Temp). For F test of Temp, then denominator factor is
Array(Temp).

I wrote this syntax to fit the above model by typing:

R2.0<-lme(dsnx.0 ~ temp+Dye+temp*Dye, random = list(
Dye*Array(Temp)=pdDiag(~-1+temp*Dye),  Arra=pdDiag(~-1+temp) ) ).

But there is syntax error message.
To obtain one solution, I typed

>int.dye<-interaction(Dye,temp:Arra,drop=T)
which created another factor, int.dye for 'Dye*Array(Temp)', and I
typed:

>R2.0<-lme(dsnx.0 ~ temp+Dye+temp*Dye, random = list(
int.dye=pdDiag(~-1+temp*Dye),  Arra=pdDiag(~-1+temp) ) )

It worked but the degree of freedom for int.dye is 12 instead of 6 <=
(2-1)*3*(3-1).

Could you solve the syntax to fit the right model for this nexted mixed
model?
Thanks so much for your guidance.
Jong
-- 
JongJoo Kim, Ph.D.

243 Shantz Building
Department of Animal Science
University of Arizona
Tucson, AZ 85721
Tel) 520-621-9757
Fax) 520-621-9435
kimjj at email.aizona.edu



From sblay at sfu.ca  Fri Sep  3 00:30:04 2004
From: sblay at sfu.ca (Sigal Blay)
Date: Thu, 2 Sep 2004 15:30:04 -0700
Subject: [R] allocating memory in C, not in R
In-Reply-To: <41367349.5000708@pdf.com>
References: <20040901210701.GA7158@sfu.ca>
	<Pine.LNX.4.44.0409012214140.11377-100000@gannet.stats>
	<20040901234136.GB23391@sfu.ca> <41367349.5000708@pdf.com>
Message-ID: <20040902223004.GA10974@sfu.ca>

> >Below is a simplified version of my c function that I am 
> >currenctly using with a .C() call.
> >The values that has to be returned to R are the three outVectors.
> >If I need to convert .C to .Call,
> >How do I do it based on myFunction below?
> >
> >Thank you for your help.
> > 
> >
> >void myFunction(char **argv, int *inputVector, 
> >  int *RoutVector1, double *RoutVector2, char **RoutVector3) {
> >    int    *outVector1;
> >    double *outVector2;
> >    char   **outVector3;
> >    int roof = 0;
> >    roof = calculate_values ( argv[0], 
> >                              inputVector, 
> >                              &outVector1,
> >                              &outVector2, 
> >                              &outVector3   )
> >
> >    for(i=0;i<roof;i++) {
> >        RoutVector1[i] = outVector1[i];    
> >        RoutVector2[i] = outVector2[i]; 
> >    }             
> >    return;
> >}
> >
> >
> 
> Well, you could read "Writing R Extensions" (Section 4.8). Your 
> function will have to change significantly, though. I would 
> create a list within the C-function (called "val" below) and 
> populate the RoutVectors with it.
> 
> (I can't remember whether you'll need more than #include <R.h>. 
> Again, I direct you to the documentation.)
> 
> SEXP myFunction(SEXP argv, SEXP inputVector) {
>   SEXP val;
>   PROTECT(val = allocVector(VECSXP, 3));
>   /* some code you'll have to write */
>   UNPROTECT(1);
>   return val;
> }
> 
> # in R
> RoutVectors <- .Call("myFunction", argv, inputVector)
> 
> --sundar

Thanks Sundar - but how do I return several vector objects of 
different modes wrapped in a list object using .Call?

Sigal



From nleonard at tartarus.uwa.edu.au  Fri Sep  3 04:11:33 2004
From: nleonard at tartarus.uwa.edu.au (Neil Leonard)
Date: Fri, 3 Sep 2004 10:11:33 +0800
Subject: [R] Printing output on Plot
Message-ID: <93FE291E-FD4E-11D8-A40F-003065D5B8EC@tartarus.uwa.edu.au>

Hi,

I'm trying to print the p-values from the output of a CPH test onto a  
Kaplan Meier plot. Can this be done? I only really want the p-values  
from the CPH test to appear but if this can't be done I am willing to  
have the entire CPH output.

This is what I am currently trying: (it doesn't print the CPH output)

plot_KM <- function(field)
{
	library(survival)
	y = length(levels(factor(field)))
	field.KM <- survfit(Surv(age_at_death,death)~field)
	field.CPH <- coxph(Surv(age_at_death,death)~factor(field))
	plot(field.KM,mark.time=FALSE,col=2: 
(y+1),lty=1,main=paste(as.character(substitute(field))," Kaplan-Meier  
Plot"))
	text(1000, .3, paste(as.character(field.CPH)), col="red")
	legend(1000, .5, levels(factor(field)), col=2:(y+1), lty=1)
}


Thanks,
Neil



From maustin at amgen.com  Fri Sep  3 04:53:19 2004
From: maustin at amgen.com (Austin, Matt)
Date: Thu, 2 Sep 2004 19:53:19 -0700 
Subject: [R] Printing output on Plot
Message-ID: <E7D5AB4811D20B489622AABA9C53859101F111F2@teal-exch.amgen.com>

The following example should get you started.


library(survival)
test1 <- list(time=  c(4, 3,1,1,2,2,3),
                status=c(1,NA,1,0,1,1,0),
                x=     c(0, 2,1,1,1,0,0),
                sex=   c(0, 0,0,0,1,1,1))
cpfit <- coxph( Surv(time, status) ~ x + strata(sex), test1)  #stratified
model

cpfit

pval <- paste("P-value: ", round(1 -
pchisq((cpfit$coef/sqrt(diag(cpfit$var)))^2, 1), 3))
plot(survfit(cpfit))
text(par('usr')[1], par('usr')[3] +par('cxy')[2], pval, adj=0)

--Matt

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Neil Leonard
Sent: Thursday, September 02, 2004 19:12 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Printing output on Plot



Hi,

I'm trying to print the p-values from the output of a CPH test onto a  
Kaplan Meier plot. Can this be done? I only really want the p-values  
from the CPH test to appear but if this can't be done I am willing to  
have the entire CPH output.

This is what I am currently trying: (it doesn't print the CPH output)

plot_KM <- function(field)
{
	library(survival)
	y = length(levels(factor(field)))
	field.KM <- survfit(Surv(age_at_death,death)~field)
	field.CPH <- coxph(Surv(age_at_death,death)~factor(field))
	plot(field.KM,mark.time=FALSE,col=2: 
(y+1),lty=1,main=paste(as.character(substitute(field))," Kaplan-Meier  
Plot"))
	text(1000, .3, paste(as.character(field.CPH)), col="red")
	legend(1000, .5, levels(factor(field)), col=2:(y+1), lty=1)
}


Thanks,
Neil

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From wolfram at fischer-zim.ch  Fri Sep  3 09:13:51 2004
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Fri, 3 Sep 2004 09:13:51 +0200
Subject: [R] variable values in plotmath expressions
Message-ID: <20040903071351.GA2671@s1x.local>

I tried:

    t <- "sample text"
    x <- 333

    plot( 1, 1
        , main=expression( main[x1] )
        , xlab=expression( paste( t, xlab[x2] ) )
        , sub=parse( text = paste( "sub[", x, "]" ) )
        )

The displayed labels for ``main'' and ``sub'' are as expected.
But ``xlab'' shows only "t" not "sample text".
How can I insert the string on which ``t'' points?

I tried e.g.:
    , ylab=parse( text = paste( t, "ylab[", x, "]" ) )
but I received an error (as suspected).

Wolfram



From ripley at stats.ox.ac.uk  Fri Sep  3 09:36:47 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Sep 2004 08:36:47 +0100 (BST)
Subject: [R] variable values in plotmath expressions
In-Reply-To: <20040903071351.GA2671@s1x.local>
Message-ID: <Pine.LNX.4.44.0409030828390.6447-100000@gannet.stats>

?substitute, as in

plot(1, 1,
     main = expression(main[x1]),
     xlab = substitute(paste(t, xlab[x2]), list(t=t)),
     sub = parse(text = paste("sub[", x, "]"))
     )

[Why do you think ( needs a space but = does not?  There is a canonical
way to display R code: see `Writing R Extensions' -- please use it.  
Communication is about making life easy for your readers.]

On Fri, 3 Sep 2004, Wolfram Fischer wrote:

> I tried:
> 
>     t <- "sample text"
>     x <- 333
> 
>     plot( 1, 1
>         , main=expression( main[x1] )
>         , xlab=expression( paste( t, xlab[x2] ) )
>         , sub=parse( text = paste( "sub[", x, "]" ) )
>         )
> 
> The displayed labels for ``main'' and ``sub'' are as expected.
> But ``xlab'' shows only "t" not "sample text".
> How can I insert the string on which ``t'' points?
> 
> I tried e.g.:
>     , ylab=parse( text = paste( t, "ylab[", x, "]" ) )
> but I received an error (as suspected).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From thpe at hhbio.wasser.tu-dresden.de  Fri Sep  3 09:45:58 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Fri, 03 Sep 2004 09:45:58 +0200
Subject: [R] variable values in plotmath expressions
In-Reply-To: <20040903071351.GA2671@s1x.local>
References: <20040903071351.GA2671@s1x.local>
Message-ID: <41382136.6060603@hhbio.wasser.tu-dresden.de>

Hello,

the following may work:

t <- "sample text"
x <- 333

plot(1, 1,
   main = expression(main[x1]),
   xlab = substitute(xxx ~ xlab[x2], list(xxx=t)),
   sub  = parse(text = paste("sub[", x, "]"))
)

Some more examples are on the ?substitute help page.


Thomas P.



From wolfram at fischer-zim.ch  Fri Sep  3 10:28:39 2004
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Fri, 3 Sep 2004 10:28:39 +0200
Subject: [R] variable values in plotmath expressions
In-Reply-To: <Pine.LNX.4.44.0409030828390.6447-100000@gannet.stats>
References: <20040903071351.GA2671@s1x.local>
	<Pine.LNX.4.44.0409030828390.6447-100000@gannet.stats>
Message-ID: <20040903082839.GA3003@s1x.local>

Thanks for your help.

On problem is solved now: ``t'' is substituted.
But what to do, if I do not want "x2" as string
but the value of ``x'' as subscript?

I tried the following but it did not help:
   t <- "sample text"
   x <- 333
   ..., xlab = substitute(paste(t, 'xlab[', x, ']'), list(t=t, x=x)),

Wolfram


On Fri, 3 Sep 2004, Prof Brian Ripley wrote:
>
> ?substitute, as in
> 
> plot(1, 1,
>      main = expression(main[x1]),
>      xlab = substitute(paste(t, xlab[x2]), list(t=t)),
>      sub = parse(text = paste("sub[", x, "]"))
>      )
> 
> [Why do you think ( needs a space but = does not?  There is a canonical
> way to display R code: see `Writing R Extensions' -- please use it.  
> Communication is about making life easy for your readers.]
> 
> On Fri, 3 Sep 2004, Wolfram Fischer wrote:
> 
> > I tried:
> > 
> >     t <- "sample text"
> >     x <- 333
> > 
> >     plot( 1, 1
> >         , main=expression( main[x1] )
> >         , xlab=expression( paste( t, xlab[x2] ) )
> >         , sub=parse( text = paste( "sub[", x, "]" ) )
> >         )
> > 
> > The displayed labels for ``main'' and ``sub'' are as expected.
> > But ``xlab'' shows only "t" not "sample text".
> > How can I insert the string on which ``t'' points?
> > 
> > I tried e.g.:
> >     , ylab=parse( text = paste( t, "ylab[", x, "]" ) )
> > but I received an error (as suspected).
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From michael.watson at bbsrc.ac.uk  Fri Sep  3 10:59:54 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Fri, 3 Sep 2004 09:59:54 +0100
Subject: [R] Problems with heatmap.2
Message-ID: <8975119BCD0AC5419D61A9CF1A923E957C2986@iahce2knas1.iah.bbsrc.reserved>

Hi

I'm afraid not!  

 
heatmap.2(as.matrix(d),Rowv=as.dendrogram(hc.gene),Colv=1:4,scale="row",
trace="none",col=greenred.colors(79))

Produces exactly the same results as if "Colv=FALSE" - my columns get
re-ordered (by a dendrogram no less).  Clearly this isn't meant to be
happening.... (by the way, d is NOT a square matrix either)

Cheers

Mick 

-----Original Message-----
From: Sean Davis [mailto:sdavis2 at mail.nih.gov] 
Sent: 02 September 2004 14:39
To: michael watson (IAH-C)
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Problems with heatmap.2


Didn't test this, but I think you probably want to do  
dendrogram="row",Colv=1:n
where n is the number of samples.

Sean

On Sep 2, 2004, at 9:21 AM, michael watson (IAH-C) wrote:

> Hi
>
> When I give the command:
>
>>
> heatmap.2(as.matrix(d),Rowv=as.dendrogram(hc.gene),Colv=FALSE,scale="r
> o
> w
> ",trace="none",col=greenred.colors(79))
>
> The resulting heatmap has re-ordered my columns!  This is time-course 
> data, and I don't want my columns re-ordered!  Note from the help:
>
>     Rowv: determines if and how the _row_ dendrogram should be
>           reordered.  Either a 'dendrogram' or a vector of values used
>           to reorder the row dendrogram or 'FALSE' to suppress
>           reordering or by default, 'NULL', see _Details_ below.
>
>     Colv: determines if and how the _column_ dendrogram should be
>           reordered.  Has the options as the 'Rowv' argument above and
>           _additionally_ when 'x' is a square matrix, 'Colv = "Rowv"'
>           means that columns should be treated identically to the 
> rows.
>
> I have specifically set "Colv=FALSE" in my command.
>
> Help?  What am I doing wrong?
>
> Cheers
> Mick
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From paolo.ariano at unito.it  Fri Sep  3 11:20:51 2004
From: paolo.ariano at unito.it (Paolo Ariano)
Date: Fri, 03 Sep 2004 11:20:51 +0200
Subject: [R] new user and non parametric test
Message-ID: <1094203250.21354.13.camel@emoscion2>

Hi *

i'm trying to do my statistical analysis with R (on a debianGNULinux)
i've installed R and now i'll try to import my data from .xls 

Where to search for non parametric test in R ? 
I'm studing neurons velocity and i've to check if after the perfusion
with a factor x the velocity changes but as my variable is not normally
ditributed i've to try with non parametric test (i think)

thanks
paolo


-- 
Paolo Ariano
Neuroscience PhD Student @ UniTo

Dati prodromi - Alessandra G.  


_____________________________________________________________________
For your security, this mail has been scanned and protected by Inflex



From michael.watson at bbsrc.ac.uk  Fri Sep  3 11:23:50 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Fri, 3 Sep 2004 10:23:50 +0100
Subject: [R] Problems with heatmap.2
Message-ID: <8975119BCD0AC5419D61A9CF1A923E957C2987@iahce2knas1.iah.bbsrc.reserved>

Ploughing on and solving my own problem, I find that setting:

dendrogram="row"

In heatmap.2 swicthes off column ordering.  Except that column ordering
should have been switched off anyway, by Colv=FALSE, shouldn't it?

Oh and "dendrogram" is spelled "dendogram" in the help :-)

Now all I need to know is how to switch off that damn histogram.... :-D

Mick

-----Original Message-----
From: michael watson (IAH-C) 
Sent: 03 September 2004 10:00
To: Sean Davis
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] Problems with heatmap.2


Hi

I'm afraid not!  

 
heatmap.2(as.matrix(d),Rowv=as.dendrogram(hc.gene),Colv=1:4,scale="row",
trace="none",col=greenred.colors(79))

Produces exactly the same results as if "Colv=FALSE" - my columns get
re-ordered (by a dendrogram no less).  Clearly this isn't meant to be
happening.... (by the way, d is NOT a square matrix either)

Cheers

Mick 

-----Original Message-----
From: Sean Davis [mailto:sdavis2 at mail.nih.gov] 
Sent: 02 September 2004 14:39
To: michael watson (IAH-C)
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Problems with heatmap.2


Didn't test this, but I think you probably want to do  
dendrogram="row",Colv=1:n
where n is the number of samples.

Sean

On Sep 2, 2004, at 9:21 AM, michael watson (IAH-C) wrote:

> Hi
>
> When I give the command:
>
>>
> heatmap.2(as.matrix(d),Rowv=as.dendrogram(hc.gene),Colv=FALSE,scale="r
> o
> w
> ",trace="none",col=greenred.colors(79))
>
> The resulting heatmap has re-ordered my columns!  This is time-course
> data, and I don't want my columns re-ordered!  Note from the help:
>
>     Rowv: determines if and how the _row_ dendrogram should be
>           reordered.  Either a 'dendrogram' or a vector of values used
>           to reorder the row dendrogram or 'FALSE' to suppress
>           reordering or by default, 'NULL', see _Details_ below.
>
>     Colv: determines if and how the _column_ dendrogram should be
>           reordered.  Has the options as the 'Rowv' argument above and
>           _additionally_ when 'x' is a square matrix, 'Colv = "Rowv"'
>           means that columns should be treated identically to the
> rows.
>
> I have specifically set "Colv=FALSE" in my command.
>
> Help?  What am I doing wrong?
>
> Cheers
> Mick
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From christoph.lange at tuebingen.mpg.de  Fri Sep  3 11:32:58 2004
From: christoph.lange at tuebingen.mpg.de (Christoph Lange)
Date: Fri, 3 Sep 2004 11:32:58 +0200
Subject: [R] new user and non parametric test
In-Reply-To: <1094203250.21354.13.camel@emoscion2>
References: <1094203250.21354.13.camel@emoscion2>
Message-ID: <20040903093258.GC26665@sesame.kyb.local>

(Reply to Paolo Ariano)

Hi, Paolo!

> i'm trying to do my statistical analysis with R (on a debianGNULinux)
> i've installed R and now i'll try to import my data from .xls 
> 
> Where to search for non parametric test in R ? 
> I'm studing neurons velocity and i've to check if after the perfusion
> with a factor x the velocity changes but as my variable is not normally
> ditributed i've to try with non parametric test (i think)

?wilcox.test
?friedman.test

etc. - it's true. I didn't find an easy way to find certain test in R
either. But e.g.

  apropos("wilcox")

will help.

Furthermore I recommend the book

@Book{siegel88,
  Author         = {Siegel, S. and Castellan, N. J.},
  Title          = {Nonparametric Statistics for the Behavioral Sciences},
  Publisher      = {McGraw-Hill, Inc.},
  Address        = {Singapore},
  year           = 1988,
}

Regards,
  Christoph.

-- 
Christoph Lange
MPI fuer biologische Kybernetik  |Phone: +49-7071-601-607|
Postfach 2169, D-72012 Tuebingen |FAX:   +49-7071-601-616|



From tura at centroin.com.br  Fri Sep  3 12:02:36 2004
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Fri, 03 Sep 2004 07:02:36 -0300
Subject: [R] newsgroup on R
Message-ID: <6.1.2.0.2.20040903070232.03cc4840@centroin.com.br>

At 08:51 02/09/2004, you wrote:

>HI, by newsgroup, I mean a kind of user forum like MATLABs 
>http://newsreader.mathworks.com/WebX?14@@/comp.soft-sys.matlab
>
>where anyone can post a question, without receiving unnecessary emails daily

Hi Bin Jiang!

I visit the url: http://gmane.org/info.php?group=gmane.comp.lang.r.general 
and in this site is possible read and post messages in R-help list without 
recive e-mails dialy.

So is not necessary newsgroups for solve your problem.

Cheers.

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil  

From paolo.ariano at unito.it  Fri Sep  3 12:26:21 2004
From: paolo.ariano at unito.it (Paolo Ariano)
Date: Fri, 03 Sep 2004 12:26:21 +0200
Subject: [R] new user and non parametric test
In-Reply-To: <20040903093258.GC26665@sesame.kyb.local>
References: <1094203250.21354.13.camel@emoscion2><20040903093258.GC26665@sesame.kyb.local>
Message-ID: <1094207180.21354.16.camel@emoscion2>

Il ven, 2004-09-03 alle 11:32, Christoph Lange ha scritto:
> etc. - it's true. I didn't find an easy way to find certain test in R
> either. But e.g.
> 
>   apropos("wilcox")

thanks a lot, i'll seach also for the book here in the biblio, the
simplest way to load an .xls file ? export to txt ?

thanks
paolo
-- 
Paolo Ariano
Neuroscience PhD Student @ UniTo

La liberta' in coppia si dimezza - Paolo A.  


_____________________________________________________________________
For your security, this mail has been scanned and protected by Inflex



From christoph.lange at tuebingen.mpg.de  Fri Sep  3 12:32:12 2004
From: christoph.lange at tuebingen.mpg.de (Christoph Lange)
Date: Fri, 3 Sep 2004 12:32:12 +0200
Subject: [R] new user and non parametric test
In-Reply-To: <1094207180.21354.16.camel@emoscion2>
References: <20040903093258.GC26665@sesame.kyb.local>
	<1094207180.21354.16.camel@emoscion2>
Message-ID: <20040903103212.GF26665@sesame.kyb.local>

(Reply to Paolo Ariano)

Paolo,

> [...]
> thanks a lot, i'll seach also for the book here in the biblio, the
> simplest way to load an .xls file ? export to txt ?

to .cvs and read into R with read.table(...)

-cl

ps. BTW: couln't reply to your address, perhaps you fix the problem
with 'paolo.ariano' being an unknown user @unito.it

-- 
Christoph Lange
MPI fuer biologische Kybernetik  |Phone: +49-7071-601-607|
Postfach 2169, D-72012 Tuebingen |FAX:   +49-7071-601-616|



From henric.nilsson at statisticon.se  Fri Sep  3 13:23:14 2004
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Fri, 03 Sep 2004 13:23:14 +0200
Subject: [R] seq
Message-ID: <6.1.2.0.0.20040903112728.0584e998@10.0.10.66>

Hi everyone,

I've tried the below on R 1.9.1 and the 2004-08-30 builds of R 1.9.1 
Patched and R 2.0.0 on Windows 2000, and the results are consistent.

 > seq(0.5, 0, by = -0.1)
[1] 0.5 0.4 0.3 0.2 0.1 0.0

 > seq(0.7, 0, by = -0.1)
[1]  7.000000e-01  6.000000e-01  5.000000e-01  4.000000e-01  3.000000e-01 
2.000000e-01  1.000000e-01 -1.110223e-16

Is this really the intended behaviour? I ended up using

 > seq(0.7, 0, length = 8)
[1] 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0

which does what I want.

//Henric



From Roger.Bivand at nhh.no  Fri Sep  3 13:41:56 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 3 Sep 2004 13:41:56 +0200 (CEST)
Subject: [R] seq
In-Reply-To: <6.1.2.0.0.20040903112728.0584e998@10.0.10.66>
Message-ID: <Pine.LNX.4.44.0409031338110.2356-100000@reclus.nhh.no>

On Fri, 3 Sep 2004, Henric Nilsson wrote:

> Hi everyone,
> 
> I've tried the below on R 1.9.1 and the 2004-08-30 builds of R 1.9.1 
> Patched and R 2.0.0 on Windows 2000, and the results are consistent.
> 
>  > seq(0.5, 0, by = -0.1)
> [1] 0.5 0.4 0.3 0.2 0.1 0.0
> 
>  > seq(0.7, 0, by = -0.1)
> [1]  7.000000e-01  6.000000e-01  5.000000e-01  4.000000e-01  3.000000e-01 
> 2.000000e-01  1.000000e-01 -1.110223e-16
> 
> Is this really the intended behaviour? I ended up using

Well, you are using a floating point representation in a digital computer, 
so I don't think you should be surprised. Note that the internal 
representation is also modified by the print() functions, so what you see 
when an object is printed is not always exactly what is inside the object.

> 
>  > seq(0.7, 0, length = 8)
> [1] 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0
> 
> which does what I want.
> 
> //Henric
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From wolski at molgen.mpg.de  Fri Sep  3 14:02:24 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 03 Sep 2004 14:02:24 +0200
Subject: [R] seq
In-Reply-To: <6.1.2.0.0.20040903112728.0584e998@10.0.10.66>
References: <6.1.2.0.0.20040903112728.0584e998@10.0.10.66>
Message-ID: <200409031402240644.060ECFBD@mail.math.fu-berlin.de>

Hi!

For IEEE floating point systems
e_mach= 2^-53  ~=  10^-16 in double precision. 

> identical(seq(0.7, 0, by = -0.1),seq(0.7, 0, length = 8))
[1] FALSE
> a<-seq(0.7, 0, by = -0.1)
> b<-seq(0.7, 0, length = 8)
> a==b
[1]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
> (a-b)<10^-16
[1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
> 

Its in the range of machine accuracy (precision).

/Eryk.






*********** REPLY SEPARATOR  ***********

On 9/3/2004 at 1:23 PM Henric Nilsson wrote:

>>>Hi everyone,
>>>
>>>I've tried the below on R 1.9.1 and the 2004-08-30 builds of R 1.9.1 
>>>Patched and R 2.0.0 on Windows 2000, and the results are consistent.
>>>
>>> > seq(0.5, 0, by = -0.1)
>>>[1] 0.5 0.4 0.3 0.2 0.1 0.0
>>>
>>> > seq(0.7, 0, by = -0.1)
>>>[1]  7.000000e-01  6.000000e-01  5.000000e-01  4.000000e-01 
>>>3.000000e-01 
>>>2.000000e-01  1.000000e-01 -1.110223e-16
>>>
>>>Is this really the intended behaviour? I ended up using
>>>
>>> > seq(0.7, 0, length = 8)
>>>[1] 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0
>>>
>>>which does what I want.
>>>
>>>//Henric
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin                'v'    
tel: 0049-30-83875219                        /   \       
mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
      wolski at molgen.mpg.de



From petr.pikal at precheza.cz  Fri Sep  3 14:02:55 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 03 Sep 2004 14:02:55 +0200
Subject: [R] seq
In-Reply-To: <Pine.LNX.4.44.0409031338110.2356-100000@reclus.nhh.no>
References: <6.1.2.0.0.20040903112728.0584e998@10.0.10.66>
Message-ID: <4138798F.6750.A57963@localhost>



On 3 Sep 2004 at 13:41, Roger Bivand wrote:

> On Fri, 3 Sep 2004, Henric Nilsson wrote:
> 
> > Hi everyone,
> > 
> > I've tried the below on R 1.9.1 and the 2004-08-30 builds of R 1.9.1
> > Patched and R 2.0.0 on Windows 2000, and the results are consistent.
> > 
> >  > seq(0.5, 0, by = -0.1)
> > [1] 0.5 0.4 0.3 0.2 0.1 0.0
> > 
> >  > seq(0.7, 0, by = -0.1)
> > [1]  7.000000e-01  6.000000e-01  5.000000e-01  4.000000e-01 
> > 3.000000e-01 2.000000e-01  1.000000e-01 -1.110223e-16
> > 
> > Is this really the intended behaviour? I ended up using
> 
> Well, you are using a floating point representation in a digital
> computer, so I don't think you should be surprised. Note that the
> internal representation is also modified by the print() functions, so
> what you see when an object is printed is not always exactly what is
> inside the object.
> 
> > 
> >  > seq(0.7, 0, length = 8)
> > [1] 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0
> > 
> > which does what I want.

Hi

Are you sure?

> seq(0.7, 0, length = 8)-c(0.7,0.6,0.5,0.4,0.3,0.2,0.1,0)

[1]  0.000000e+00  0.000000e+00  0.000000e+00 -5.551115e-17  
0.000000e+00
[6]  0.000000e+00 -2.775558e-17  0.000000e+00
>

> sum(seq(0.7, 0, length = 8)-c(0.7,0.6,0.5,0.4,0.3,0.2,0.1,0))
[1] -8.326673e-17
> sum(seq(0.7, 0, length = 8)-c(0.7,0.6,0.5,0.4,0.3,0.2,0.1,0))==0
[1] FALSE
>

Cheers
Petr


> > 
> > //Henric
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > 
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School
> of Economics and Business Administration, Breiviksveien 40, N-5045
> Bergen, Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93 e-mail:
> Roger.Bivand at nhh.no
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ripley at stats.ox.ac.uk  Fri Sep  3 14:17:01 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Sep 2004 13:17:01 +0100 (BST)
Subject: [R] seq
In-Reply-To: <Pine.LNX.4.44.0409031338110.2356-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.44.0409031308340.7143-100000@gannet.stats>

On Fri, 3 Sep 2004, Roger Bivand wrote:

> On Fri, 3 Sep 2004, Henric Nilsson wrote:
> 
> > Hi everyone,
> > 
> > I've tried the below on R 1.9.1 and the 2004-08-30 builds of R 1.9.1 
> > Patched and R 2.0.0 on Windows 2000, and the results are consistent.
> > 
> >  > seq(0.5, 0, by = -0.1)
> > [1] 0.5 0.4 0.3 0.2 0.1 0.0
> > 
> >  > seq(0.7, 0, by = -0.1)
> > [1]  7.000000e-01  6.000000e-01  5.000000e-01  4.000000e-01  3.000000e-01 
> > 2.000000e-01  1.000000e-01 -1.110223e-16
> > 
> > Is this really the intended behaviour? I ended up using
> 
> Well, you are using a floating point representation in a digital computer, 
> so I don't think you should be surprised. Note that the internal 
> representation is also modified by the print() functions, so what you see 
> when an object is printed is not always exactly what is inside the object.
> 
> > 
> >  > seq(0.7, 0, length = 8)
> > [1] 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0
> > 
> > which does what I want.

To expand a little, the code is in seq.default.

seq(0.7, 0, by = -0.1) is done by from + (0:n) * by for n=8
seq(0.7, 0, length = 8) is done by  
  c(from, from + (1:(length.out - 2)) * by, to))

so the last value is handled differently.  Since 0.1 cannot be represented 
exactly on a binary computer,

> print(7*0.1, digits=16)
[1] 0.7000000000000001

and you are seeing the result of 0.7 - 7*0.1.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rdiaz at cnio.es  Fri Sep  3 14:21:16 2004
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Fri, 3 Sep 2004 14:21:16 +0200
Subject: [R] SNOW, lexical scoping, and "programming style"
Message-ID: <200409031421.16774.rdiaz@cnio.es>

Dear All,

A programming style and scoping question when using SNOW and clusterApplyLB. 


### The following will not work:
uu <- matrix(rnorm(200 * 1000), ncol = 1000)

fm1 <- function(xmaster, ...) {
    fs1 <- function(dummy, ...) {
           dim(xmaster)
        }
        clusterApplyLB(TheCluster, 1:3, fs1)

}

fm1(uu) ## uu not found


### I can think of three alternatives:

### Use "force"
fm2 <- function(xmaster, ...) {
    force(xmaster)
    fs2 <- function(dummy, ...) {
        dim(xmaster)
    }
    clusterApplyLB(TheCluster, 1:50, fs2)
}

## Export the variable explicitly from inside the function
fs3 <- function(dummy, ...) {
    dim(xmaster.copy)
}
fm3 <- function(xmaster, ...) {
    xmaster.copy <<- xmaster
    clusterExport(TheCluster, "xmaster.copy")
    clusterApplyLB(TheCluster, 1:50, fs3)

}

## Pass the variable as an argument of clusterApplyLB
fs4 <- function(dummy, xpassedalong) {
    dim(xpassedalong)
}
fm4 <- function(xmaster, ...) {
    clusterApplyLB(TheCluster, 1:50, fs4, xmaster)
}




Which/why would be best? 
I dislike using ClusterExport after a "<<-", but this approach ought to be 
advantageous with clusterApplyLB if each slave node is visited repeatedly (if 
in ClusterApplyLB(cl, x, fun, ...), length(x) >> number of nodes) and the 
object is large. (Some limited testing shows that in these cases the fastest 
is option 3, followed by 2, followed by 4).

Thanks,

R.



-- 
Ram??n D??az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol??gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern??ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)



From michael.watson at bbsrc.ac.uk  Fri Sep  3 14:30:36 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Fri, 3 Sep 2004 13:30:36 +0100
Subject: [R] Standard correlation
Message-ID: <8975119BCD0AC5419D61A9CF1A923E957C298E@iahce2knas1.iah.bbsrc.reserved>

Hi

Is there a function for computing the standard correlation coefficient
(not pearson) in R?

Thanks
Mick



From bates at stat.wisc.edu  Fri Sep  3 14:35:39 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 03 Sep 2004 07:35:39 -0500
Subject: [R] confidence intervals
In-Reply-To: <20040902193341.1678.qmail@web90103.mail.scd.yahoo.com>
References: <20040902193341.1678.qmail@web90103.mail.scd.yahoo.com>
Message-ID: <4138651B.4010507@stat.wisc.edu>

Robert Waters wrote:
> Dear R users;
> 
> Im working with lme and Id like to have an idea of how
> can I get CI for the predictions made with the model.
> Im not a stats guy but, if Im not wrong, the CIs
> should be different if Im predicting a new data point
> or a new group. Ive been searching through the web and
> in help-lists with no luck. I know this topic had been
> asked before but without replies. Can anyone give an
> idea of where can I found information about this or
> how can I get it from R?
> 
> Thanks for any hint

That's not currently implemented in lme.  It's on the "To Do" list but 
it is not very close to the top.



From par at wiklund.net  Fri Sep  3 14:41:57 2004
From: par at wiklund.net (Per Wiklund)
Date: Fri, 3 Sep 2004 05:41:57 -0700
Subject: [R] strptime problems
Message-ID: <1f18a01c491b3$667edc60$6ecb010a@mail2world.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040903/8f488566/attachment.pl

From sdrees at sdrees.de  Fri Sep  3 15:03:23 2004
From: sdrees at sdrees.de (Stefan Drees)
Date: Fri, 3 Sep 2004 15:03:23 +0200
Subject: [R] Standard correlation
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E957C298E@iahce2knas1.iah.bbsrc.reserved>
References: <8975119BCD0AC5419D61A9CF1A923E957C298E@iahce2knas1.iah.bbsrc.reserved>
Message-ID: <20040903130323.GA14026@knoten.biz>

On Fri, Sep 03, 2004 at 01:30:36PM +0100 - a wonderful day 
			- michael watson (IAH-C) wrote:
> Is there a function for computing the standard correlation 
> coefficient (not pearson) in R?
help (cor) yields the following in my R 1.9.1 installation:
"""
...
cor(x, y = NULL, use = "all.obs",
          method = c("pearson", "kendall", "spearman"))
...
"""

HTH,
Stefan.
-- 
.o. e-mail: stefan at drees.name, web: www.sdrees.org, +49 700 SDREESDE
..o fingerprint = 516C C4EF 712A B26F 15C9  C7B7 5651 6964 D508 1B56
ooo  stefan drees  -  consulting and lecturing  -  problems to tasks



From henric.nilsson at statisticon.se  Fri Sep  3 15:05:43 2004
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Fri, 03 Sep 2004 15:05:43 +0200
Subject: [R] seq
In-Reply-To: <Pine.LNX.4.44.0409031308340.7143-100000@gannet.stats>
References: <Pine.LNX.4.44.0409031338110.2356-100000@reclus.nhh.no>
	<Pine.LNX.4.44.0409031308340.7143-100000@gannet.stats>
Message-ID: <6.1.2.0.0.20040903143742.058b8fe0@10.0.10.66>

Thanks to all who replied.

I'm not surprised that R uses floating point arithmetics, nor am I 
surprised that an object and it's printed version may differ due to e.g. 
rounding taking place in the print() function.

I am, however, surprised of the fact that seq() prints it's internal 
representation of 0 as 0.0 when `from = 0.5', but as -1.110223e-16 when 
`from = 0.7'.

//Henric


At 13:17 2004-09-03 +0100, you wrote:
>On Fri, 3 Sep 2004, Roger Bivand wrote:
>
> > On Fri, 3 Sep 2004, Henric Nilsson wrote:
> >
> > > Hi everyone,
> > >
> > > I've tried the below on R 1.9.1 and the 2004-08-30 builds of R 1.9.1
> > > Patched and R 2.0.0 on Windows 2000, and the results are consistent.
> > >
> > >  > seq(0.5, 0, by = -0.1)
> > > [1] 0.5 0.4 0.3 0.2 0.1 0.0
> > >
> > >  > seq(0.7, 0, by = -0.1)
> > > 
> [1]  7.000000e-01  6.000000e-01  5.000000e-01  4.000000e-01  3.000000e-01
> > > 2.000000e-01  1.000000e-01 -1.110223e-16
> > >
> > > Is this really the intended behaviour? I ended up using
> >
> > Well, you are using a floating point representation in a digital computer,
> > so I don't think you should be surprised. Note that the internal
> > representation is also modified by the print() functions, so what you see
> > when an object is printed is not always exactly what is inside the object.
> >
> > >
> > >  > seq(0.7, 0, length = 8)
> > > [1] 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0
> > >
> > > which does what I want.
>
>To expand a little, the code is in seq.default.
>
>seq(0.7, 0, by = -0.1) is done by from + (0:n) * by for n=8
>seq(0.7, 0, length = 8) is done by
>   c(from, from + (1:(length.out - 2)) * by, to))
>
>so the last value is handled differently.  Since 0.1 cannot be represented
>exactly on a binary computer,
>
> > print(7*0.1, digits=16)
>[1] 0.7000000000000001
>
>and you are seeing the result of 0.7 - 7*0.1.
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From thpe at hhbio.wasser.tu-dresden.de  Fri Sep  3 15:16:22 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Fri, 03 Sep 2004 15:16:22 +0200
Subject: [R] strptime problems
In-Reply-To: <1f18a01c491b3$667edc60$6ecb010a@mail2world.com>
References: <1f18a01c491b3$667edc60$6ecb010a@mail2world.com>
Message-ID: <41386EA6.2090004@hhbio.wasser.tu-dresden.de>

Per Wiklund wrote:

 >
 > Hi, I'm experiencing a problem with strptime. (R 1.9.1 on a Win2000
 > machine)

[...]

 > strptime(as.character(ccc[[11]]$TradeDateTime[161522]),
 >    "%d-%b-%y:%H:%M:%S")
 > [1] NA

[...]

Hello,

unfortunately, your code does not show what data are in the object ccc, 
so an exact diagnosis is almost impossible. However, I suspect you have 
timezone problems which are common on Windows computers. If you don't 
need timezone calculations I suggest to use the Date class (uppercase 
"D") or the chron package instead of the POSIX classes, see the last 
issue of R-News:

http://cran.r-project.org/doc/Rnews/Rnews_2004-1.pdf

Thomas P.



From michael.watson at bbsrc.ac.uk  Fri Sep  3 15:20:39 2004
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Fri, 3 Sep 2004 14:20:39 +0100
Subject: [R] Standard correlation
Message-ID: <8975119BCD0AC5419D61A9CF1A923E951746E2@iahce2knas1.iah.bbsrc.reserved>

OK I better clarify what I mean as it appears it may not be a standard
test.

The pearson correlation coefficient, in laymans terms, uses the shape of
a curve around that curve's average to compare two curves.  The standard
correlation coefficient measures the shape of a curve around zero, and
uses that to compare the two curves.

Therefore a measure that starts at 1 and increases away from zero, and a
measure that starts at -4 and increases towards zero, will be deamed
similar via pearson's correlation coefficient, and dissimilar via the
standard correlation coefficient.  This is useful when "increase away
from zero" is very different behaviour from "increase towards zero".

There are some descriptions here:

http://ccgb.umn.edu/support/software/gspring/HelpPages/GSUM-120.html
http://www.optimaldesign.com/AMHelp/HowTo/HowToChooseClustParam.htm

-----Original Message-----
From: Stefan Drees [mailto:sdrees at sdrees.de] 
Sent: 03 September 2004 14:03
To: r-help at stat.math.ethz.ch
Cc: michael watson (IAH-C); Stefan Drees
Subject: Re: [R] Standard correlation


On Fri, Sep 03, 2004 at 01:30:36PM +0100 - a wonderful day 
			- michael watson (IAH-C) wrote:
> Is there a function for computing the standard correlation
> coefficient (not pearson) in R?
help (cor) yields the following in my R 1.9.1 installation:
"""
...
cor(x, y = NULL, use = "all.obs",
          method = c("pearson", "kendall", "spearman"))
...
"""

HTH,
Stefan.
-- 
.o. e-mail: stefan at drees.name, web: www.sdrees.org, +49 700 SDREESDE ..o
fingerprint = 516C C4EF 712A B26F 15C9  C7B7 5651 6964 D508 1B56 ooo
stefan drees  -  consulting and lecturing  -  problems to tasks



From ripley at stats.ox.ac.uk  Fri Sep  3 15:26:41 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Sep 2004 14:26:41 +0100 (BST)
Subject: [R] strptime problems
In-Reply-To: <41386EA6.2090004@hhbio.wasser.tu-dresden.de>
Message-ID: <Pine.LNX.4.44.0409031422190.7239-100000@gannet.stats>

I suspect rather a locale problem which Date and chron will also have.

You are looking for an abbreviated month name (%b).  What language is the 
object ccc in?  What language is your computer in?  See the example in
?strptime

     ## read in date info in format 'ddmmmyyyy'
     ## This will give NA(s) in some locales; setting the C locale
     ## as in the commented lines will overcome this on most systems.
     ## lct <- Sys.getlocale("LC_TIME"); Sys.setlocale("LC_TIME", "C")
     x <- c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
     z <- strptime(x, "%d%b%Y")

Looking for English abbreviations in a Norwegian file, for example, will 
not work and give NAs.

On Fri, 3 Sep 2004, Thomas Petzoldt wrote:

> Per Wiklund wrote:
> 
>  >
>  > Hi, I'm experiencing a problem with strptime. (R 1.9.1 on a Win2000
>  > machine)
> 
> [...]
> 
>  > strptime(as.character(ccc[[11]]$TradeDateTime[161522]),
>  >    "%d-%b-%y:%H:%M:%S")
>  > [1] NA
> 
> [...]
> 
> Hello,
> 
> unfortunately, your code does not show what data are in the object ccc, 
> so an exact diagnosis is almost impossible. However, I suspect you have 
> timezone problems which are common on Windows computers. If you don't 
> need timezone calculations I suggest to use the Date class (uppercase 
> "D") or the chron package instead of the POSIX classes, see the last 
> issue of R-News:
> 
> http://cran.r-project.org/doc/Rnews/Rnews_2004-1.pdf
> 
> Thomas P.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tofesi at web.de  Fri Sep  3 15:27:48 2004
From: tofesi at web.de (tofesi@web.de)
Date: Fri, 03 Sep 2004 15:27:48 +0200
Subject: [R] Changing the value of an object's slot in a method
Message-ID: <662197963@web.de>

Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: 7bit
Received-SPF: none (hypatia: domain of tofesi at web.de does not designate permitted sender hosts)
X-Virus-Scanned: by amavisd-new at stat.math.ethz.ch
X-Spam-Checker-Version: SpamAssassin 2.63 (2004-01-11) on hypatia.math.ethz.ch
X-Spam-Level: 
X-Spam-Status: No, hits=0.2 required=5.0 tests=BAYES_50,NO_REAL_NAME autolearn=no version=2.63

Hi all,

I want to modify the value of an object's slot from within a method, as in the example below:

setClass("MyClass", representation(flag="numeric"))
if( !isGeneric("flipFlag") )
    setGeneric("flipFlag", function(object)
               standardGeneric("flipFlag"))
setMethod("flipFlag","MyClass",
          function(object) {

            # flips object at flag from 0 to 1, or from 1 to 0
          })

This should work in a similar way as in other object-oriented languages where it would be written as 'object.flipFlag()'. However, there seems to be a problem with the call-by-value semantics of R, and the updated value is lost on leaving the function.

The following two options are not suitable for our task:
1.) Directly assigning to 'flag' via a method created by 'setReplaceMethod'. The method 'flipFlag' should require no parameters.
2.) Returning a new object, so that the user has to assign the new object to the old variable.

Thanks in advance,
  Tobi.
________________________________________________________________
Verschicken Sie romantische, coole und witzige Bilder per SMS!



From wolski at molgen.mpg.de  Fri Sep  3 15:41:38 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Fri, 03 Sep 2004 15:41:38 +0200
Subject: [R] Standard correlation
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E951746E2@iahce2knas1.iah.bbsrc.reserved>
References: <8975119BCD0AC5419D61A9CF1A923E951746E2@iahce2knas1.iah.bbsrc.reserved>
Message-ID: <200409031541380314.0669A768@mail.math.fu-berlin.de>

Hi!

?scale
?var
?cov

/E



*********** REPLY SEPARATOR  ***********

On 9/3/2004 at 2:20 PM michael watson (IAH-C) wrote:

>>>OK I better clarify what I mean as it appears it may not be a standard
>>>test.
>>>
>>>The pearson correlation coefficient, in laymans terms, uses the shape of
>>>a curve around that curve's average to compare two curves.  The standard
>>>correlation coefficient measures the shape of a curve around zero, and
>>>uses that to compare the two curves.
>>>
>>>Therefore a measure that starts at 1 and increases away from zero, and a
>>>measure that starts at -4 and increases towards zero, will be deamed
>>>similar via pearson's correlation coefficient, and dissimilar via the
>>>standard correlation coefficient.  This is useful when "increase away
>>>from zero" is very different behaviour from "increase towards zero".
>>>
>>>There are some descriptions here:
>>>
>>>http://ccgb.umn.edu/support/software/gspring/HelpPages/GSUM-120.html
>>>http://www.optimaldesign.com/AMHelp/HowTo/HowToChooseClustParam.htm
>>>
>>>-----Original Message-----
>>>From: Stefan Drees [mailto:sdrees at sdrees.de] 
>>>Sent: 03 September 2004 14:03
>>>To: r-help at stat.math.ethz.ch
>>>Cc: michael watson (IAH-C); Stefan Drees
>>>Subject: Re: [R] Standard correlation
>>>
>>>
>>>On Fri, Sep 03, 2004 at 01:30:36PM +0100 - a wonderful day 
>>>			- michael watson (IAH-C) wrote:
>>>> Is there a function for computing the standard correlation
>>>> coefficient (not pearson) in R?
>>>help (cor) yields the following in my R 1.9.1 installation:
>>>"""
>>>...
>>>cor(x, y = NULL, use = "all.obs",
>>>          method = c("pearson", "kendall", "spearman"))
>>>...
>>>"""
>>>
>>>HTH,
>>>Stefan.
>>>-- 
>>>.o. e-mail: stefan at drees.name, web: www.sdrees.org, +49 700 SDREESDE ..o
>>>fingerprint = 516C C4EF 712A B26F 15C9  C7B7 5651 6964 D508 1B56 ooo
>>>stefan drees  -  consulting and lecturing  -  problems to tasks
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin                'v'    
tel: 0049-30-83875219                        /   \       
mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
      wolski at molgen.mpg.de



From B.Rowlingson at lancaster.ac.uk  Fri Sep  3 15:46:36 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 03 Sep 2004 14:46:36 +0100
Subject: [R] seq
In-Reply-To: <6.1.2.0.0.20040903143742.058b8fe0@10.0.10.66>
References: <Pine.LNX.4.44.0409031338110.2356-100000@reclus.nhh.no>	<Pine.LNX.4.44.0409031308340.7143-100000@gannet.stats>
	<6.1.2.0.0.20040903143742.058b8fe0@10.0.10.66>
Message-ID: <413875BC.700@lancaster.ac.uk>

Henric Nilsson wrote:

> I am, however, surprised of the fact that seq() prints it's internal 
> representation of 0 as 0.0 when `from = 0.5', but as -1.110223e-16 when 
> `from = 0.7'.

  These second one isnt a zero!

  > seq(from=0.5,by=-.1,len=6)==0
  [1] FALSE FALSE FALSE FALSE FALSE  TRUE

  - in this case the last element is exactly zero. Internally it will be 
a string of 0 bits or some other representation that means precisely 
zero. Zero. Zilch, nada, zip.

  > seq(from=0.7,by=-.1,len=8)==0
  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE

  - in this case the last element _isnt_ exactly zero. At some point in 
the calculation floating point's lack of precision kicks in, and the 
last element in that seq() will be represented internally by a pattern 
of ones and zeroes that isn't the zero-pattern, but is the pattern for 
-1.110223e-16 instead. Quite where that happens is controlled by the 
mechanism that seq() uses to generate its numbers.

  I find it surprising that people still think that other people get 
surprised by this. Now that people start their programming with 
high-level languages like R, or Perl, or Visual Wotsit, they don't get 
exposed to internals, and think that numbers are just numbers. The idea 
that 0.1 != 1/10 would be surprising.

  Assembly language for everyone, I say....

BSR



From skong at bidmc.harvard.edu  Fri Sep  3 16:14:38 2004
From: skong at bidmc.harvard.edu (Sek Won Kong,M.D)
Date: Fri, 3 Sep 2004 10:14:38 -0400
Subject: [R] 64 bit benefit for dual G5 powermac
In-Reply-To: <200409031003.i83A3Duk007036@hypatia.math.ethz.ch>
Message-ID: <E1C3Eq0-000429-00@smtp02.mrf.mail.rcn.net>

Hi,
Can dual G5 Powermac have benefit of 64 bit in terms of memory and maximum
matrix size? I have read several positive postings on 64 bit machine.
If yes, what will be configure looked like other than { ./configure
--with-blas='-framework vecLib' --with-lapack --with-aqua } ?
Thank you very much for helps in advance.
-SW



From myao at ou.edu  Fri Sep  3 16:14:53 2004
From: myao at ou.edu (Yao, Minghua)
Date: Fri, 3 Sep 2004 09:14:53 -0500
Subject: [R] Different Index behaviors of Array and Matrix
Message-ID: <89944065A099FB4AB1296358DD02877A1FD727@XMAIL.sooner.net.ou.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040903/a759918d/attachment.pl

From roebuck at odin.mdacc.tmc.edu  Fri Sep  3 16:20:56 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Fri, 3 Sep 2004 09:20:56 -0500 (CDT)
Subject: [R] 64 bit benefit for dual G5 powermac
In-Reply-To: <E1C3Eq0-000429-00@smtp02.mrf.mail.rcn.net>
References: <E1C3Eq0-000429-00@smtp02.mrf.mail.rcn.net>
Message-ID: <Pine.OSF.4.58.0409030917550.70196@odin.mdacc.tmc.edu>

On Fri, 3 Sep 2004, Sek Won Kong,M.D wrote:

> Can dual G5 Powermac have benefit of 64 bit in terms of memory and maximum
> matrix size? I have read several positive postings on 64 bit machine.
> If yes, what will be configure looked like other than { ./configure
> --with-blas='-framework vecLib' --with-lapack --with-aqua } ?

I believe most of the 64-bit support you are wanting is to
be delivered in the forthcoming OS X 10.4 (Tiger) release.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From jmoreira at fe.up.pt  Fri Sep  3 16:37:24 2004
From: jmoreira at fe.up.pt (jmoreira@fe.up.pt)
Date: Fri,  3 Sep 2004 15:37:24 +0100
Subject: [R] windowing strategies
Message-ID: <1094222244.413881a4db74b@webmail.fe.up.pt>


Hello to everybody,

Does anyone has implemented a function for evaluating models using windowing 
strategies, such as growing window or sliding window ones?
The aim is to evaluate regression models on a time series data. I do not use 
cross-validation once data sorted in a radom way does not make sense when 
evaluating time series.

Thanks

Joao Moreira



From par at wiklund.net  Fri Sep  3 16:30:59 2004
From: par at wiklund.net (Per Wiklund)
Date: Fri, 3 Sep 2004 07:30:59 -0700
Subject: [R] strptime problems
Message-ID: <21c7f01c491c2$a1d60fe0$70cb010a@mail2world.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040903/4d72fe69/attachment.pl

From ggrothendieck at myway.com  Fri Sep  3 17:20:10 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 3 Sep 2004 15:20:10 +0000 (UTC)
Subject: [R] seq
References: <6.1.2.0.0.20040903112728.0584e998@10.0.10.66>
Message-ID: <loom.20040903T171201-527@post.gmane.org>

Henric Nilsson <henric.nilsson <at> statisticon.se> writes:

> 
> Hi everyone,
> 
> I've tried the below on R 1.9.1 and the 2004-08-30 builds of R 1.9.1 
> Patched and R 2.0.0 on Windows 2000, and the results are consistent.
> 
>  > seq(0.5, 0, by = -0.1)
> [1] 0.5 0.4 0.3 0.2 0.1 0.0
> 
>  > seq(0.7, 0, by = -0.1)
> [1]  7.000000e-01  6.000000e-01  5.000000e-01  4.000000e-01  3.000000e-01 
> 2.000000e-01  1.000000e-01 -1.110223e-16
> 
> Is this really the intended behaviour? I ended up using
> 
>  > seq(0.7, 0, length = 8)
> [1] 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0
> 
> which does what I want.
> 

You could also try (7:0)/10 .  The numerator will be an integer
sequence, which can be performed exactly, so you will have fewer
occasions for floating point representations and their
associated approximations:

   R> class(7:0)
   [1] "integer"
   R> (7:0)/10  # or seq(7,0)/10
   [1] 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0
   R> class((7:0)/10)
   [1] "numeric"



From sokhnacoura at hotmail.com  Fri Sep  3 17:39:19 2004
From: sokhnacoura at hotmail.com (sokhna ndao)
Date: Fri, 03 Sep 2004 17:39:19 +0200
Subject: [R] arima et graphique
Message-ID: <BAY13-F359EXxt5BBBV0001e828@hotmail.com>

bonjour, je rencontre quelques soucis au niveau de l'utilisation des 
fonctions arima.forecast/predict; en effet elles sont dites inconnues alors 
que j'ai bien install?? et charg?? le package "ts". Aussi, j'aimerai savoir 
comment visualiser le graphique des pr??visions avec arima et celui des 
donn??es brutes dans la m??me fen??tre.
Tout en vous souhaitant bonne r??ception de ce mail, je vous remercie 
d'avance.



From sokhnacoura at hotmail.com  Fri Sep  3 17:39:23 2004
From: sokhnacoura at hotmail.com (sokhna ndao)
Date: Fri, 03 Sep 2004 17:39:23 +0200
Subject: [R] arima et graphique
Message-ID: <BAY13-F37jm0nywT3oW000644d3@hotmail.com>

bonjour, je rencontre quelques soucis au niveau de l'utilisation des 
fonctions arima.forecast/predict; en effet elles sont dites inconnues alors 
que j'ai bien install?? et charg?? le package "ts". Aussi, j'aimerai savoir 
comment visualiser le graphique des pr??visions avec arima et celui des 
donn??es brutes dans la m??me fen??tre.
Tout en vous souhaitant bonne r??ception de ce mail, je vous remercie 
d'avance.



From ripley at stats.ox.ac.uk  Fri Sep  3 17:40:24 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Sep 2004 16:40:24 +0100 (BST)
Subject: [R] Different Index behaviors of Array and Matrix
In-Reply-To: <89944065A099FB4AB1296358DD02877A1FD727@XMAIL.sooner.net.ou.edu>
Message-ID: <Pine.LNX.4.44.0409031536480.7598-100000@gannet.stats>

[I will copy a version of this to R-bugs: please be careful when you reply
to only copy to R-bugs a version with a PR number in the subject.]

On Fri, 3 Sep 2004, Yao, Minghua wrote:

>  I found a difference between the indexing of an array and that of a
> matrix when there are NA's in the index array. The screen copy is as
> follows.
>  
> > A <- array(NA, dim=6)
> > A
> [1] NA NA NA NA NA NA

> > idx <- c(1,NA,NA,4,5,6)
> > B <- c(10,20,30,40,50,60)
> > A[idx] <- B
> > A
> [1] 10 NA NA 40 50 60
> > AA <- matrix(NA,6,1)
> > AA
>      [,1]
> [1,]   NA
> [2,]   NA
> [3,]   NA
> [4,]   NA
> [5,]   NA
> [6,]   NA
> > AA[idx,1] <- B
> > AA
>      [,1]
> [1,]   10
> [2,]   NA
> [3,]   NA
> [4,]   20
> [5,]   30
> [6,]   40
> > 
>  In the case of a array, we miss the elements (20 and 30) in B
> corresponding to the NA's in the index array. In the case of a matrix,
> 20 and 30 are assigned to the elements indexed by the indexes following
> the NA's. Is this a reasonable behavior. Thanks in advance for
> explanation.

A is a 1D array but it behaves just like a vector.
Wierder things happen with multi-dimensional arrrays

> A <- array(NA, dim=c(6,1,1))
> A[idx,1,1] <- B
> A
, , 1

     [,1]
[1,]   10
[2,]   NA
[3,]   NA
[4,]   NA
[5,]   NA
[6,]   NA

One problem with what happens for matrices is that

> idx <- c(1,4,5,6)
> AA <- matrix(NA,6,1)
> AA[idx,1] <- B
Error in "[<-"(`*tmp*`, idx, 1, value = B) :
        number of items to replace is not a multiple of replacement length

is an error, so it is not counting the values consistently.

The only discussion I could find (Blue Book p.103, which is also
discussing LHS subscripting) just says

	If a subscript is NA, an NA is returned.

S normally does not use up values when encountering an NA in an index set, 
although it does for logical matrix indexing of data frames.

I can see two possible interpretations.

1) The NA indicates the values was lost after assignment. We don't know
what index the first NA was, so 20 got assigned somewhere.  And as we
don't know where, all the elements had better be NA. However, that is
unless the NA was 0, when no assignment took place any no value was used.

2) The NA indicates the value was lost before assignment, so no assignment 
took place and no value was used.

R does neither of those.  I suspect the correct course of action is to ban 
NAs in subscripted assignments.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Scott.Waichler at pnl.gov  Fri Sep  3 17:42:19 2004
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Fri, 03 Sep 2004 08:42:19 -0700
Subject: [R] Problem with seq.dates in chron
Message-ID: <7E4C06F49D6FEB49BE4B60E5FC92ED7A05F528@pnlmse35.pnl.gov>


I get faulty output from seq.dates() if I specify a length that is too
long.
For example, I ask for 129 months in the following call to the function,
but it returns
131:

> R.version.string
[1] "R version 1.9.1, 2004-06-21"
> startdatetime <- chron(dates="01/01/1995", times="00:00:00")
> beg.month.datetimes <- seq.dates(from=startdatetime, by="months",
length=129)
> beg.month.datetimes
  [1] 01/01/95 02/01/95 03/01/95 04/01/95 05/01/95 06/01/95 07/01/95
08/01/95
  [9] 09/01/95 10/01/95 11/01/95 12/01/95 01/01/96 02/01/96 03/01/96
04/01/96
 [17] 05/01/96 06/01/96 07/01/96 08/01/96 09/01/96 10/01/96 11/01/96
12/01/96
 [25] 01/01/97 02/01/97 03/01/97 04/01/97 05/01/97 06/01/97 07/01/97
08/01/97
 [33] 09/01/97 10/01/97 11/01/97 12/01/97 01/01/98 02/01/98 03/01/98
04/01/98
 [41] 05/01/98 06/01/98 07/01/98 08/01/98 09/01/98 10/01/98 11/01/98
12/01/98
 [49] 01/01/99 02/01/99 03/01/99 04/01/99 05/01/99 06/01/99 07/01/99
08/01/99
 [57] 09/01/99 10/01/99 11/01/99 12/01/99 01/01/00 02/01/00 03/01/00
04/01/00
 [65] 05/01/00 06/01/00 07/01/00 08/01/00 09/01/00 10/01/00 11/01/00
12/01/00
 [73] 01/01/01 02/01/01 03/01/01 04/01/01 05/01/01 06/01/01 07/01/01
08/01/01
 [81] 09/01/01 10/01/01 11/01/01 12/01/01 01/01/02 02/01/02 03/01/02
04/01/02
 [89] 05/01/02 06/01/02 07/01/02 08/01/02 09/01/02 10/01/02 11/01/02
12/01/02
 [97] 01/01/03 02/01/03 03/01/03 04/01/03 05/01/03 06/01/03 07/01/03
08/01/03
[105] 09/01/03 10/01/03 11/01/03 12/01/03 01/01/04 02/01/04 03/01/04
04/01/04
[113] 05/01/04 06/01/04 07/01/04 08/01/04 09/01/04 10/01/04 11/01/04
12/01/04
[121] 01/01/05 02/01/05 03/01/05 04/01/05 05/01/05 06/01/05 07/01/05
08/01/05
[129] 09/01/05 10/01/05 11/01/05
>

Is this a bug, and can it be fixed?

Scott Waichler
Pacific Northwest National Laboratory
scott.waichler<at>pnl.gov



From ggrothendieck at myway.com  Fri Sep  3 17:44:39 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 3 Sep 2004 15:44:39 +0000 (UTC)
Subject: [R] strptime problems
References: <41386EA6.2090004@hhbio.wasser.tu-dresden.de>
	<Pine.LNX.4.44.0409031422190.7239-100000@gannet.stats>
Message-ID: <loom.20040903T172523-233@post.gmane.org>


Prof Brian Ripley <ripley <at> stats.ox.ac.uk> writes:

: 
: I suspect rather a locale problem which Date and chron will also have.


I don't think chron uses locales so it would likely also be a problem
with Date but not with chron.  

In this example, we change the locale to Danish and then display the first
of each of 12 months using chron and Date:

R> lct <- Sys.getlocale("LC_TIME"); Sys.setlocale("LC_TIME", "da")
[1] "Danish_Denmark.1252"

R> chron(paste(1:12,1,2004,sep="/"),out.format="M-D-Y") 
[1] Jan-01-2004 Feb-01-2004 Mar-01-2004 Apr-01-2004 May-01-2004 Jun-01-2004 
Jul-01-2004 Aug-01-2004 Sep-01-2004 Oct-01-2004 Nov-01-2004 Dec-01-2004

R> format(as.Date(.Last.value),"%B-%d-%Y")
 [1] "januar-01-2004"    "februar-01-2004"   "marts-01-2004"     "april-01-
2004"     "maj-01-2004"       "juni-01-2004"      "juli-01-2004"     
 [8] "august-01-2004"    "september-01-2004" "oktober-01-2004"   "november-01-
2004"  "december-01-2004" 

: 
: You are looking for an abbreviated month name (%b).  What language is the 
: object ccc in?  What language is your computer in?  See the example in
: ?strptime
: 
:      ## read in date info in format 'ddmmmyyyy'
:      ## This will give NA(s) in some locales; setting the C locale
:      ## as in the commented lines will overcome this on most systems.
:      ## lct <- Sys.getlocale("LC_TIME"); Sys.setlocale("LC_TIME", "C")
:      x <- c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
:      z <- strptime(x, "%d%b%Y")
: 
: Looking for English abbreviations in a Norwegian file, for example, will 
: not work and give NAs.
: 
: On Fri, 3 Sep 2004, Thomas Petzoldt wrote:
: 
: > Per Wiklund wrote:
: > 
: >  >
: >  > Hi, I'm experiencing a problem with strptime. (R 1.9.1 on a Win2000
: >  > machine)
: > 
: > [...]
: > 
: >  > strptime(as.character(ccc[[11]]$TradeDateTime[161522]),
: >  >    "%d-%b-%y:%H:%M:%S")
: >  > [1] NA
: > 
: > [...]
: > 
: > Hello,
: > 
: > unfortunately, your code does not show what data are in the object ccc, 
: > so an exact diagnosis is almost impossible. However, I suspect you have 
: > timezone problems which are common on Windows computers. If you don't 
: > need timezone calculations I suggest to use the Date class (uppercase 
: > "D") or the chron package instead of the POSIX classes, see the last 
: > issue of R-News:
: > 
: > http://cran.r-project.org/doc/Rnews/Rnews_2004-1.pdf
: > 
: > Thomas P.
:



From sundar.dorai-raj at PDF.COM  Fri Sep  3 17:55:02 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 03 Sep 2004 08:55:02 -0700
Subject: [R] allocating memory in C, not in R
In-Reply-To: <20040902223004.GA10974@sfu.ca>
References: <20040901210701.GA7158@sfu.ca>	<Pine.LNX.4.44.0409012214140.11377-100000@gannet.stats>	<20040901234136.GB23391@sfu.ca>
	<41367349.5000708@pdf.com> <20040902223004.GA10974@sfu.ca>
Message-ID: <413893D6.3060900@pdf.com>

Sigal Blay wrote:

> Thanks Sundar - but how do I return several vector objects of 
> different modes wrapped in a list object using .Call?
> 
> Sigal
> 


Have you looked at the documentation as I suggested? It's there in 
Section 4.8 of "Writing R Extensions". Take a look at the examples for 
"lapply" or look at Rdefines.h and Rinternals.h in the src/include 
directory.

You're lucky I have an already worked example I have used for myself in 
the past which I include below.

/* junk.c */
#include <R.h>
#include <Rdefines.h>

SEXP junk(SEXP n) {
   SEXP *p_b, *p_nm;
   SEXP val, a, b, c, val_nm;
   double *p_a;
   int *p_c;
   int i, len, val_len;
   char *nm[3] = {"numeric", "character", "integer"};
   char *LETTERS[26] = {"A", "B", "C", "D", "E", "F",
                        "G", "H", "I", "J", "K", "L",
                        "M", "N", "O", "P", "Q", "R",
                        "S", "T", "U", "V", "W", "X",
                        "Y", "Z"};
   val_len = 3;
   len = INTEGER_VALUE(n);
   PROTECT(val = allocVector(VECSXP, val_len));
   PROTECT(a = NEW_NUMERIC(len));
   PROTECT(b = NEW_CHARACTER(len));
   PROTECT(c = NEW_INTEGER(len));
   PROTECT(val_nm = NEW_CHARACTER(val_len));
   p_a = NUMERIC_POINTER(a);
   p_b = CHARACTER_POINTER(b);
   p_c = INTEGER_POINTER(c);
   p_nm = CHARACTER_POINTER(val_nm);
   for(i = 0; i < len; i++) {
     p_a[i] = 1/(double)(i + 1);
     p_b[i] = mkChar(LETTERS[i % 26]);
     p_c[i] = i + 1;
   }
   for(i = 0; i < val_len; i++)
     p_nm[i] = mkChar(nm[i]);
   SET_VECTOR_ELT(val, 0, a);
   SET_VECTOR_ELT(val, 1, b);
   SET_VECTOR_ELT(val, 2, c);
   setAttrib(val, R_NamesSymbol, val_nm);
   UNPROTECT(5);
   return val;
}

/* ## in R                                  */
/* dyn.load("junk")                         */
/* junk <- function(n = 1) .Call("junk", n) */
/* junk(4)                                  */


--sundar



From spencer.graves at pdf.com  Fri Sep  3 17:57:54 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 03 Sep 2004 08:57:54 -0700
Subject: [R] confidence intervals
In-Reply-To: <4138651B.4010507@stat.wisc.edu>
References: <20040902193341.1678.qmail@web90103.mail.scd.yahoo.com>
	<4138651B.4010507@stat.wisc.edu>
Message-ID: <41389482.8070008@pdf.com>

Hi, Robert: 

      While it may be difficult to program this in general (as suggested 
by it's position on Doug's "To Do" list), all the pieces should be 
available to support a special script for your specific application.  
What fixed and random model(s) interest you most? 

      hope this helps.  spencer graves

Douglas Bates wrote:

> Robert Waters wrote:
>
>> Dear R users;
>>
>> Im working with lme and Id like to have an idea of how
>> can I get CI for the predictions made with the model.
>> Im not a stats guy but, if Im not wrong, the CIs
>> should be different if Im predicting a new data point
>> or a new group. Ive been searching through the web and
>> in help-lists with no luck. I know this topic had been
>> asked before but without replies. Can anyone give an
>> idea of where can I found information about this or
>> how can I get it from R?
>>
>> Thanks for any hint
>
>
> That's not currently implemented in lme.  It's on the "To Do" list but 
> it is not very close to the top.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html


-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From Ted.Harding at nessie.mcc.ac.uk  Fri Sep  3 14:59:59 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 03 Sep 2004 13:59:59 +0100 (BST)
Subject: [R] seq
In-Reply-To: <6.1.2.0.0.20040903112728.0584e998@10.0.10.66>
Message-ID: <XFMail.040903135959.Ted.Harding@nessie.mcc.ac.uk>

On 03-Sep-04 Henric Nilsson wrote:
> Hi everyone,
> 
> I've tried the below on R 1.9.1 and the 2004-08-30 builds of R 1.9.1 
> Patched and R 2.0.0 on Windows 2000, and the results are consistent.
> 
>  > seq(0.5, 0, by = -0.1)
> [1] 0.5 0.4 0.3 0.2 0.1 0.0
> 
>  > seq(0.7, 0, by = -0.1)
> [1]  7.000000e-01  6.000000e-01  5.000000e-01  4.000000e-01 
> 3.000000e-01 
> 2.000000e-01  1.000000e-01 -1.110223e-16
> 
> Is this really the intended behaviour? I ended up using
> 
>  > seq(0.7, 0, length = 8)
> [1] 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0
> 
> which does what I want.

Hi Henric,
The replies you have already received explain what is going on.
However, what you (and we all) need is a procedure which can
guarantee that what you expect is what you get, For instance,
a test that the 8th element of the "seq" was "==0" would give
the result FALSE.

What I'm in the habit of doing for this sort of thing is on the
lines of

  0.1*seq(5,0, by = -1)
  [1] 0.5 0.4 0.3 0.2 0.1 0.0

or even simply

  0.1*(5:0)
  [1] 0.5 0.4 0.3 0.2 0.1 0.0

The difference is that here the sequence element is working with
integers, which are (provided within bounds) handled exactly in
a digitial computer. Floating point numbers with a fractional
part generally are not, as already explained by others.

Note however the result of

  0.1*(5:0) == 0.3)
  [1] FALSE FALSE FALSE FALSE FALSE FALSE

as opposed to "==0.5", "==0.4", "==0.2", "==0.1" or "==0"!

I hope this helps,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 03-Sep-04                                       Time: 13:59:59
------------------------------ XFMail ------------------------------



From ltorgo at liacc.up.pt  Fri Sep  3 18:59:59 2004
From: ltorgo at liacc.up.pt (Luis Torgo)
Date: Fri, 03 Sep 2004 17:59:59 +0100
Subject: [R] windowing strategies
In-Reply-To: <1094222244.413881a4db74b@webmail.fe.up.pt>
References: <1094222244.413881a4db74b@webmail.fe.up.pt>
Message-ID: <1094230798.3947.121.camel@nassa.niaad.liacc.up.pt>

On Fri, 2004-09-03 at 15:37, jmoreira at fe.up.pt wrote:
> Hello to everybody,
> 
> Does anyone has implemented a function for evaluating models using windowing 
> strategies, such as growing window or sliding window ones?
> The aim is to evaluate regression models on a time series data. I do not use 
> cross-validation once data sorted in a radom way does not make sense when 
> evaluating time series.
> 

I include two functions I've written that I think accomplish what you
want. They return a list with probably too many unnecessary components
for you (they were useful in the context I've used them), so you will
probably want to change that part.

Hope it helps,

Luis Torgo

#===================================================================
# This function allows the execution of sliding window tests using 
# any algorithm.
# Example:
# > p.rt <- sliding.window.testing(exp[1:800,],700,'rpart',learner.pars=list(fk5 ~ .))
# > p.nn <- sliding.window.testing(exp[1:800,],700,'nnet',
#                                  learner.pars=list(fk5 ~ .,size=10,linout=T),
#                                  relearn.step=7)
# Note: This last example only re-learns a new model every 7 cases
#---------------------------------------------------------------------
sliding.window.testing <- function(orig.data, window.size,
                                   learner, learner.pars,
                                   relearn.step=1, test.pos=window.size+1) {
  init.test <- test.pos
  n <- nrow(orig.data)
  preds <- vector()
  while (test.pos <= n) {
    cat('*')
    learner.pars$data <- orig.data[(test.pos-window.size):(test.pos-1),]
    model <- do.call(learner,learner.pars)
    preds <- c(preds,predict(model,orig.data[test.pos:min(n,test.pos+relearn.step-1),]))
    test.pos <- test.pos+relearn.step
  }
  cat('\n')
  list(train.period=c(test.pos-relearn.step-window.size,test.pos-relearn.step-1),
       model.call=list(func=learner,pars=learner.pars),
       model=model,
       test.period=c(init.test,n),
       preds=preds,
       preds.close=NULL,preds.ret=NULL,err.ret=NULL,weigh.preds=NULL)
}

# ======================================================================
# This function allows the execution of growing window tests using any
# algorithm.
# Example:
# > p.rt <- growing.window.testing(exp[1:800,],700,'rpart',learner.pars=list(fk5 ~ .))
# > p.nn <- growing.window.testing(exp[1:800,],700,'nnet',
#                                  learner.pars=list(fk5 ~ .,size=10,linout=T),
#                                  relearn.step=7)
# Note: This last example only re-learns a new model every 7 cases
# ----------------------------------------------------------------------
growing.window.testing <- function(orig.data, 
                                   learner, learner.pars,
                                   relearn.step=1, test.pos) {
  init.test <- test.pos
  n <- nrow(orig.data)
  preds <- vector()
  while (test.pos <= n) {
    cat('*')
    learner.pars$data <- orig.data[1:(test.pos-1),]
    model <- do.call(learner,learner.pars)
    preds <- c(preds,predict(model,orig.data[test.pos:min(n,test.pos+relearn.step-1),]))
    test.pos <- test.pos+relearn.step
  }
  cat('\n')
  list(model.call=list(func=learner,pars=learner.pars),
       model=model,
       test.period=c(init.test,n),
       preds=preds)
}

-- 
Luis Torgo
  FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
  Machine Learning Group           Fax   : (+351) 22 600 36 54
  R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
  4150 PORTO   -  PORTUGAL         WWW   : http://www.liacc.up.pt/~ltorgo



From ripley at stats.ox.ac.uk  Fri Sep  3 17:58:34 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Sep 2004 16:58:34 +0100 (BST)
Subject: [R] arima et graphique
In-Reply-To: <BAY13-F359EXxt5BBBV0001e828@hotmail.com>
Message-ID: <Pine.LNX.4.44.0409031650390.7598-100000@gannet.stats>

The language of the list is English.  R no longer has a package `ts',
so please read the posting guide and FAQ and get a current version of R.

?UKDriverDeaths and MASS/script/ch14.R will show you examples.

On Fri, 3 Sep 2004, sokhna ndao wrote:

> bonjour, je rencontre quelques soucis au niveau de l'utilisation des 
> fonctions arima.forecast/predict; en effet elles sont dites inconnues alors 
> que j'ai bien install?? et charg?? le package "ts". Aussi, j'aimerai savoir 
> comment visualiser le graphique des pr??visions avec arima et celui des 
> donn??es brutes dans la m??me fen??tre.
> Tout en vous souhaitant bonne r??ception de ce mail, je vous remercie 
> d'avance.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at myway.com  Fri Sep  3 18:17:11 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 3 Sep 2004 16:17:11 +0000 (UTC)
Subject: [R] Problem with seq.dates in chron
References: <7E4C06F49D6FEB49BE4B60E5FC92ED7A05F528@pnlmse35.pnl.gov>
Message-ID: <loom.20040903T181515-696@post.gmane.org>


I think we just discussed this 2 days ago:

https://www.stat.math.ethz.ch/pipermail/r-help/2004-September/055323.html




Waichler, Scott R <Scott.Waichler <at> pnl.gov> writes:

: I get faulty output from seq.dates() if I specify a length that is too
: long.
: For example, I ask for 129 months in the following call to the function,
: but it returns
: 131:
: 
: > R.version.string
: [1] "R version 1.9.1, 2004-06-21"
: > startdatetime <- chron(dates="01/01/1995", times="00:00:00")
: > beg.month.datetimes <- seq.dates(from=startdatetime, by="months",
: length=129)
: > beg.month.datetimes
:   [1] 01/01/95 02/01/95 03/01/95 04/01/95 05/01/95 06/01/95 07/01/95
: 08/01/95
:   [9] 09/01/95 10/01/95 11/01/95 12/01/95 01/01/96 02/01/96 03/01/96
: 04/01/96
:  [17] 05/01/96 06/01/96 07/01/96 08/01/96 09/01/96 10/01/96 11/01/96
: 12/01/96
:  [25] 01/01/97 02/01/97 03/01/97 04/01/97 05/01/97 06/01/97 07/01/97
: 08/01/97
:  [33] 09/01/97 10/01/97 11/01/97 12/01/97 01/01/98 02/01/98 03/01/98
: 04/01/98
:  [41] 05/01/98 06/01/98 07/01/98 08/01/98 09/01/98 10/01/98 11/01/98
: 12/01/98
:  [49] 01/01/99 02/01/99 03/01/99 04/01/99 05/01/99 06/01/99 07/01/99
: 08/01/99
:  [57] 09/01/99 10/01/99 11/01/99 12/01/99 01/01/00 02/01/00 03/01/00
: 04/01/00
:  [65] 05/01/00 06/01/00 07/01/00 08/01/00 09/01/00 10/01/00 11/01/00
: 12/01/00
:  [73] 01/01/01 02/01/01 03/01/01 04/01/01 05/01/01 06/01/01 07/01/01
: 08/01/01
:  [81] 09/01/01 10/01/01 11/01/01 12/01/01 01/01/02 02/01/02 03/01/02
: 04/01/02
:  [89] 05/01/02 06/01/02 07/01/02 08/01/02 09/01/02 10/01/02 11/01/02
: 12/01/02
:  [97] 01/01/03 02/01/03 03/01/03 04/01/03 05/01/03 06/01/03 07/01/03
: 08/01/03
: [105] 09/01/03 10/01/03 11/01/03 12/01/03 01/01/04 02/01/04 03/01/04
: 04/01/04
: [113] 05/01/04 06/01/04 07/01/04 08/01/04 09/01/04 10/01/04 11/01/04
: 12/01/04
: [121] 01/01/05 02/01/05 03/01/05 04/01/05 05/01/05 06/01/05 07/01/05
: 08/01/05
: [129] 09/01/05 10/01/05 11/01/05
: >
: 
: Is this a bug, and can it be fixed?



From ripley at stats.ox.ac.uk  Fri Sep  3 18:26:44 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Sep 2004 17:26:44 +0100 (BST)
Subject: [R] Problem with seq.dates in chron
In-Reply-To: <7E4C06F49D6FEB49BE4B60E5FC92ED7A05F528@pnlmse35.pnl.gov>
Message-ID: <Pine.LNX.4.44.0409031721430.8054-100000@gannet.stats>

The following naive calculation in seq.dates explains this:

        to <- from + (length. - 1) * c(1, 7, 31, 366)[i]

It is calculating the end date from 31-day months.

The following is correct (and even readable to those unused to such an
illogical date format) in Dates in base R.

> startdatetime <- as.Date("1995-01-01")
> seq(as.Date("1995-01-01"), by="months", length=129)



On Fri, 3 Sep 2004, Waichler, Scott R wrote:

> 
> I get faulty output from seq.dates() if I specify a length that is too
> long.
> For example, I ask for 129 months in the following call to the function,
> but it returns
> 131:
> 
> > R.version.string
> [1] "R version 1.9.1, 2004-06-21"
> > startdatetime <- chron(dates="01/01/1995", times="00:00:00")
> > beg.month.datetimes <- seq.dates(from=startdatetime, by="months",
> length=129)
> > beg.month.datetimes
>   [1] 01/01/95 02/01/95 03/01/95 04/01/95 05/01/95 06/01/95 07/01/95
> 08/01/95
>   [9] 09/01/95 10/01/95 11/01/95 12/01/95 01/01/96 02/01/96 03/01/96
> 04/01/96
>  [17] 05/01/96 06/01/96 07/01/96 08/01/96 09/01/96 10/01/96 11/01/96
> 12/01/96
>  [25] 01/01/97 02/01/97 03/01/97 04/01/97 05/01/97 06/01/97 07/01/97
> 08/01/97
>  [33] 09/01/97 10/01/97 11/01/97 12/01/97 01/01/98 02/01/98 03/01/98
> 04/01/98
>  [41] 05/01/98 06/01/98 07/01/98 08/01/98 09/01/98 10/01/98 11/01/98
> 12/01/98
>  [49] 01/01/99 02/01/99 03/01/99 04/01/99 05/01/99 06/01/99 07/01/99
> 08/01/99
>  [57] 09/01/99 10/01/99 11/01/99 12/01/99 01/01/00 02/01/00 03/01/00
> 04/01/00
>  [65] 05/01/00 06/01/00 07/01/00 08/01/00 09/01/00 10/01/00 11/01/00
> 12/01/00
>  [73] 01/01/01 02/01/01 03/01/01 04/01/01 05/01/01 06/01/01 07/01/01
> 08/01/01
>  [81] 09/01/01 10/01/01 11/01/01 12/01/01 01/01/02 02/01/02 03/01/02
> 04/01/02
>  [89] 05/01/02 06/01/02 07/01/02 08/01/02 09/01/02 10/01/02 11/01/02
> 12/01/02
>  [97] 01/01/03 02/01/03 03/01/03 04/01/03 05/01/03 06/01/03 07/01/03
> 08/01/03
> [105] 09/01/03 10/01/03 11/01/03 12/01/03 01/01/04 02/01/04 03/01/04
> 04/01/04
> [113] 05/01/04 06/01/04 07/01/04 08/01/04 09/01/04 10/01/04 11/01/04
> 12/01/04
> [121] 01/01/05 02/01/05 03/01/05 04/01/05 05/01/05 06/01/05 07/01/05
> 08/01/05
> [129] 09/01/05 10/01/05 11/01/05
> >
> 
> Is this a bug, and can it be fixed?
> 
> Scott Waichler
> Pacific Northwest National Laboratory
> scott.waichler<at>pnl.gov
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sdavis2 at mail.nih.gov  Fri Sep  3 18:52:16 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 3 Sep 2004 12:52:16 -0400
Subject: [R] windowing strategies
In-Reply-To: <1094230798.3947.121.camel@nassa.niaad.liacc.up.pt>
References: <1094222244.413881a4db74b@webmail.fe.up.pt>
	<1094230798.3947.121.camel@nassa.niaad.liacc.up.pt>
Message-ID: <9CA9FE18-FDC9-11D8-B0B6-000A95D7BA10@mail.nih.gov>

In the gregmisc package, there are the "running" functions.  I think  
there are specific commands for getting subsets of time series, but I  
can't remember them off the top of my head.

Sean

On Sep 3, 2004, at 12:59 PM, Luis Torgo wrote:

> On Fri, 2004-09-03 at 15:37, jmoreira at fe.up.pt wrote:
>> Hello to everybody,
>>
>> Does anyone has implemented a function for evaluating models using  
>> windowing
>> strategies, such as growing window or sliding window ones?
>> The aim is to evaluate regression models on a time series data. I do  
>> not use
>> cross-validation once data sorted in a radom way does not make sense  
>> when
>> evaluating time series.
>>
>
> I include two functions I've written that I think accomplish what you
> want. They return a list with probably too many unnecessary components
> for you (they were useful in the context I've used them), so you will
> probably want to change that part.
>
> Hope it helps,
>
> Luis Torgo
>
> #===================================================================
> # This function allows the execution of sliding window tests using
> # any algorithm.
> # Example:
> # > p.rt <-  
> sliding.window.testing(exp[1:800,],700,'rpart',learner.pars=list(fk5 ~  
> .))
> # > p.nn <- sliding.window.testing(exp[1:800,],700,'nnet',
> #                                  learner.pars=list(fk5 ~  
> .,size=10,linout=T),
> #                                  relearn.step=7)
> # Note: This last example only re-learns a new model every 7 cases
> #---------------------------------------------------------------------
> sliding.window.testing <- function(orig.data, window.size,
>                                    learner, learner.pars,
>                                    relearn.step=1,  
> test.pos=window.size+1) {
>   init.test <- test.pos
>   n <- nrow(orig.data)
>   preds <- vector()
>   while (test.pos <= n) {
>     cat('*')
>     learner.pars$data <-  
> orig.data[(test.pos-window.size):(test.pos-1),]
>     model <- do.call(learner,learner.pars)
>     preds <-  
> c(preds,predict(model,orig.data[test.pos:min(n,test.pos+relearn.step 
> -1),]))
>     test.pos <- test.pos+relearn.step
>   }
>   cat('\n')
>    
> list(train.period=c(test.pos-relearn.step-window.size,test.pos- 
> relearn.step-1),
>        model.call=list(func=learner,pars=learner.pars),
>        model=model,
>        test.period=c(init.test,n),
>        preds=preds,
>        preds.close=NULL,preds.ret=NULL,err.ret=NULL,weigh.preds=NULL)
> }
>
> #  
> ======================================================================
> # This function allows the execution of growing window tests using any
> # algorithm.
> # Example:
> # > p.rt <-  
> growing.window.testing(exp[1:800,],700,'rpart',learner.pars=list(fk5 ~  
> .))
> # > p.nn <- growing.window.testing(exp[1:800,],700,'nnet',
> #                                  learner.pars=list(fk5 ~  
> .,size=10,linout=T),
> #                                  relearn.step=7)
> # Note: This last example only re-learns a new model every 7 cases
> #  
> ----------------------------------------------------------------------
> growing.window.testing <- function(orig.data,
>                                    learner, learner.pars,
>                                    relearn.step=1, test.pos) {
>   init.test <- test.pos
>   n <- nrow(orig.data)
>   preds <- vector()
>   while (test.pos <= n) {
>     cat('*')
>     learner.pars$data <- orig.data[1:(test.pos-1),]
>     model <- do.call(learner,learner.pars)
>     preds <-  
> c(preds,predict(model,orig.data[test.pos:min(n,test.pos+relearn.step 
> -1),]))
>     test.pos <- test.pos+relearn.step
>   }
>   cat('\n')
>   list(model.call=list(func=learner,pars=learner.pars),
>        model=model,
>        test.period=c(init.test,n),
>        preds=preds)
> }
>
> -- 
> Luis Torgo
>   FEP/LIACC, University of Porto   Phone : (+351) 22 607 88 30
>   Machine Learning Group           Fax   : (+351) 22 600 36 54
>   R. Campo Alegre, 823             email : ltorgo at liacc.up.pt
>   4150 PORTO   -  PORTUGAL         WWW   :  
> http://www.liacc.up.pt/~ltorgo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!  
> http://www.R-project.org/posting-guide.html



From ehughes at mrco2.carleton.ca  Fri Sep  3 20:09:28 2004
From: ehughes at mrco2.carleton.ca (Ed Hughes)
Date: Fri, 03 Sep 2004 13:09:28 -0500
Subject: [R] Installation problems on Solaris 2.6
Message-ID: <4.3.1.1.20040903130410.00df4250@134.117.179.14>

I am trying to install R 1.9.1 on a 5-year-old Sun:  here is the
description:

version
Machine hardware:   sun4u
OS version:         5.6
Processor type:     sparc
Hardware:           SUNW,Ultra-4
The following components are installed on your system:
Sun Visual WorkShop C++ 3.0
         Sun WorkShop Compiler C 4.2 
         Sun WorkShop Compiler C++ 4.2 
         Sun WorkShop Tools.h++ 7.0 
         Sun WorkShop Tools.h++ 6.0.4 
         Sun WorkShop Visual 2.0 
         Sun WorkShop IPE 4.0 
         Sun WorkShop CodeManager 2.0 
         Sun WorkShop Distributed Make 2.0 
         Sun WorkShop FileMerge 3.0 
         Sun WorkShop FreezePoint 2.0 
         Sun WorkShop Maketool 2.0 
         Sun WorkShop VersionTool 2.0 
         Sun WorkShop Dbx 4.0 
         Sun WorkShop Performance Analyzer 4.0 
         Sun WorkShop LoopTool 2.1 
         Sun WorkShop LockLint 2.1 
         Sun WorkShop Thread Analyzer 1.2 
         Sun WorkShop XEmacs 20.00 
Sun WorkShop Professional C 3.0
         Sun WorkShop Compiler C 4.2 
         Sun WorkShop IPE 4.0 
         Sun WorkShop Dbx 4.0 
         Sun WorkShop Performance Analyzer 4.0 
         Sun WorkShop IPE 4.0 
Sun WorkShop Compiler FORTRAN 77 4.2 
Sun WorkShop Compiler Fortran 90 1.2 
Sun Performance Library 1.2 

Here are the lines I changed in config.site:
R_PAPERSIZE=letter
CC="cc -xarch=v8plusa"
CFLAGS="-xO3 -dalign"
F77="f90 -xarch=v8plusa"
FFLAGS="-xO3 -dalign"
MAIN_LDFLAGS="-xarch=v8plusa"
LDFLAGS=-L/opt/SUNWspro/lib
CXX="CC -xarch=v8plusa"
CXXFLAGS="-xO3 -dalign"
BLAS_LIBS="-xlic_lib=sunperf"
LAPACK_LIBS="-xlic_lib=sunperf"

The configure step finished apparently OK.  Then the make step failed;
here are the last few lines of the screen log:

CDIR$          NEXT SCALAR
                ^           
cf90-801 f90comp: WARNING DTGEVC, File = dlapack3.f, Line = 21520, Column = 16 
   Unsupported compiler directive.

f90: SunSoft F90 Version 1.0.1.0  (23279289) Thu Sep  2, 2004  15:24:02
f90: COMPILE TIME 103.070000 SECONDS
f90: MAXIMUM FIELD LENGTH 17338406 DECIMAL WORDS
f90: 30323 SOURCE LINES
f90: 0 ERRORS, 6 WARNINGS, 0 OTHER MESSAGES, 0 ANSI
f90: CODE: 5644483 WORDS, DATA: 468584 WORDS
mv .libs/dlapack3.o dlapack3.lo
f90 -xarch=v8  -PIC  -xO3 -dalign -c cmplx.f -o .libs/cmplx.o
f90: Warning: Option -PIC passed to ld, if ld is invoked, ignored otherwise

       DOUBLE COMPLEX   FUNCTION ZLADIV( X, Y )
       ^                                        
cf90-702 f90comp: ERROR $MAIN, File = cmplx.f, Line = 9605, Column = 7 
   Type double complex is not supported with -ep.

f90: SunSoft F90 Version 1.0.1.0  (23279289) Thu Sep  2, 2004  15:25:52
f90: COMPILE TIME 84.880000 SECONDS
f90: MAXIMUM FIELD LENGTH 13488166 DECIMAL WORDS
f90: 19239 SOURCE LINES
f90: 1 ERRORS, 0 WARNINGS, 0 OTHER MESSAGES, 0 ANSI
f90: CODE: 4649293 WORDS, DATA: 145564 WORDS
*** Error code 1
make: Fatal error: Command failed for target `cmplx.lo'
Current working directory /disk4/home4/ehug/newSoft/R-1.9.1/src/modules/lapack
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /disk4/home4/ehug/newSoft/R-1.9.1/src/modules/lapack
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /disk4/home4/ehug/newSoft/R-1.9.1/src/modules
*** Error code 1
make: Fatal error: Command failed for target `R'
Current working directory /disk4/home4/ehug/newSoft/R-1.9.1/src
*** Error code 1
make: Fatal error: Command failed for target `R'


I don't know f90; can anybody tell me what went wrong? 

Following this failure, I tried again with f77, having built a netlib
generic BLAS static library.  This went through the make step seemingly
OK, but on "make check" it failed.  I found that R would start and do 
simple things, but when I tried linear algebra, it gave errors, saying
it couldn't load the Lapack library. 

Any help would be appreciated.

--Ed Hughes



From ggrothendieck at myway.com  Fri Sep  3 19:11:42 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 3 Sep 2004 17:11:42 +0000 (UTC)
Subject: [R] windowing strategies
References: <1094222244.413881a4db74b@webmail.fe.up.pt>
Message-ID: <loom.20040903T190733-660@post.gmane.org>

 <jmoreira <at> fe.up.pt> writes:

: Does anyone has implemented a function for evaluating models using windowing 
: strategies, such as growing window or sliding window ones?
: The aim is to evaluate regression models on a time series data. I do not use 
: cross-validation once data sorted in a radom way does not make sense when 
: evaluating time series.
: 

This has been discussed a number of times before.  See, for example, 
the entire thread that starts with:

   http://tolstoy.newcastle.edu.au/R/help/04/04/1253.html

and from r-sig-finance see:

   https://stat.ethz.ch/pipermail/r-sig-finance/2004q3/000104.html

which mentions a number of existing functions.



From gunter.berton at gene.com  Fri Sep  3 19:17:04 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 3 Sep 2004 10:17:04 -0700
Subject: [R] seq
In-Reply-To: <XFMail.040903135959.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <200409031717.i83HH4bc024432@meitner.gene.com>

> Note however the result of
> 
>   0.1*(5:0) == 0.3)
>   [1] FALSE FALSE FALSE FALSE FALSE FALSE
> 
> as opposed to "==0.5", "==0.4", "==0.2", "==0.1" or "==0"!
> 
> I hope this helps,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 03-Sep-04                                       Time: 13:59:59


At the risk of flailing at a dead and even dessicated horse ...

>From the Help file of identical(), the construction
identical(all.equal(x,y),TRUE) gives the desired test for equality for
finite precision arithmetic. Hence:

 > sapply(.1*(0:5),function(x)identical(all.equal(x,.3),TRUE))

[1] FALSE FALSE FALSE  TRUE FALSE FALSE

which is, presumably, as desired.

Cheers,

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

From vograno at evafunds.com  Fri Sep  3 20:34:48 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Fri, 3 Sep 2004 11:34:48 -0700
Subject: [R] how to debug a sudden exit in non-interactive mode
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A563D937@phost015.EVAFUNDS.intermedia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040903/6ade002a/attachment.pl

From ripley at stats.ox.ac.uk  Fri Sep  3 20:51:10 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Sep 2004 19:51:10 +0100 (BST)
Subject: [R] how to debug a sudden exit in non-interactive mode
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A563D937@phost015.EVAFUNDS.intermedia.net>
Message-ID: <Pine.LNX.4.44.0409031948260.1903-100000@gannet.stats>

If you look in ?debugger, especially right at the end, you will see how to
attempt a post-mortem dump of the frams to a file.  If that gets run (and
this might be a fatal error from C level, but it is not reporting so), you
can reload the dump and use debugger on it.

On Fri, 3 Sep 2004, Vadim Ogranovich wrote:

> Hi,
>  
> I have a piece of R code that calls mgcv::gam. The code runs fine in the
> interactive mode, but terminates R w/o a single message when run
> non-interactively. Though I think I should be able to locate the problem
> by brute force I'd appreciate an advise how to do it more intelligently
> using R debugging tools.
>  
> At this time I only know that it has something to do with me loading my
> custom library, vor, in .Rprofile.
>  
> I use R-1.9.1 on RH7.3.
>  
> Following the posting guide I include an example (note that it may work
> for you fine since you don't have my .Rprofile). 
>  
> This is debug.R file:
> #=============
> dataLength <- 1e3
> y <-rnorm(dataLength)
> x <- rnorm(dataLength)
>  
> library("mgcv")
>  
> cat("before\n")
>   
> xy.gam <- gam(y ~ s(x), knots=list(place.knots(x, 25)), fit=FALSE)
>  
> cat("after\n")
> 
>  
>  
> # Here I run it non-interactively from the shell. Note that the last
> line, cat("after\n"), doesn't get executed. (it does get executed in the
> interactive mode or with --no-init-file)
> ~% R --no-save --no-restore --silent < debug.R
> .First.lib of vor 
> > dataLength <- 1e3
> > y <-rnorm(dataLength)
> > x <- rnorm(dataLength)
> > 
> > library("mgcv")
> This is mgcv 1.0-9 
> > 
> > cat("before\n")
> before
> >   
> > xy.gam <- gam(y ~ s(x), knots=list(place.knots(x, 25)), fit=FALSE)
> ~% 
>  
>  
> Thanks,
> Vadim
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dede01 at codon.nih.gov  Fri Sep  3 21:00:18 2004
From: dede01 at codon.nih.gov (Dede Greenstein)
Date: Fri, 03 Sep 2004 15:00:18 -0400
Subject: [R] contrast/test statements in polynomial mixed model
Message-ID: <5.0.0.25.2.20040903144743.027abe90@nihexchange20.nih.gov>



From jeroschh at ohsu.edu  Fri Sep  3 21:42:06 2004
From: jeroschh at ohsu.edu (Michael Jerosch-Herold)
Date: Fri, 03 Sep 2004 12:42:06 -0700
Subject: [R] image() with color key?
Message-ID: <s13866a7.039@ohsu.edu>

Is there an "easy" way to plot a "color key" next to a color image (with
image() in graphics package)? The color key should also include a
numerical scale, so that the colors can be cross-referenced with image
intensity values. I see that levelplot has a facility for color keys,
but with image it seems less straightforward, i.e. generating a color
key is not an option in image().

Thank you!

Michael Jerosch-Herold



From deepayan at stat.wisc.edu  Fri Sep  3 21:52:26 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 3 Sep 2004 14:52:26 -0500
Subject: [R] image() with color key?
In-Reply-To: <s13866a7.039@ohsu.edu>
References: <s13866a7.039@ohsu.edu>
Message-ID: <200409031452.26183.deepayan@stat.wisc.edu>

On Friday 03 September 2004 14:42, Michael Jerosch-Herold wrote:
> Is there an "easy" way to plot a "color key" next to a color image (with
> image() in graphics package)? The color key should also include a
> numerical scale, so that the colors can be cross-referenced with image
> intensity values. I see that levelplot has a facility for color keys,
> but with image it seems less straightforward, i.e. generating a color
> key is not an option in image().

Does filled.contour() give you what you want?

Deepayan



From p.dalgaard at biostat.ku.dk  Fri Sep  3 22:02:03 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Sep 2004 22:02:03 +0200
Subject: [R] how to debug a sudden exit in non-interactive mode
In-Reply-To: <Pine.LNX.4.44.0409031948260.1903-100000@gannet.stats>
References: <Pine.LNX.4.44.0409031948260.1903-100000@gannet.stats>
Message-ID: <x2llfrce9w.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> If you look in ?debugger, especially right at the end, you will see how to
> attempt a post-mortem dump of the frams to a file.  If that gets run (and
> this might be a fatal error from C level, but it is not reporting so), you
> can reload the dump and use debugger on it.
> 
> On Fri, 3 Sep 2004, Vadim Ogranovich wrote:
[snip]
> > # Here I run it non-interactively from the shell. Note that the last
> > line, cat("after\n"), doesn't get executed. (it does get executed in the
> > interactive mode or with --no-init-file)
> > ~% R --no-save --no-restore --silent < debug.R

Also, with an invocation like that, you can run under the debugger as
follows: 

  $ R -d gdb
  (gdb) run --no-save --no-restore --silent < debug.R

and maybe set a breakpoint in the error handler, or just let it run to
completion and see if it segfaults or something.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From gunter.berton at gene.com  Fri Sep  3 22:20:27 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 3 Sep 2004 13:20:27 -0700
Subject: [R] image() with color key?
In-Reply-To: <200409031452.26183.deepayan@stat.wisc.edu>
Message-ID: <200409032020.i83KKRXg028406@hertz.gene.com>

In some applications, e.g., visualizing the values of the wells in a 96 well
(8 x 12) assay plate, the matrix of results is truly discrete and you want
to visualize it that way. image() does this, but not filled.contour() AFAIK.
If that's correct, the only way I know how to do it is to overlay two plots
(par(new=FALSE)),one for the data and the other for the legend. This is
certainly not trivial, but it's not impossibly hard, either.

I hope I'm wrong on this, though, as I'd welcome an easier way, too.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box

> Does filled.contour() give you what you want?
> 
> Deepayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

From tlumley at u.washington.edu  Fri Sep  3 22:33:06 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 3 Sep 2004 13:33:06 -0700 (PDT)
Subject: [R] image() with color key?
In-Reply-To: <200409032020.i83KKRXg028406@hertz.gene.com>
References: <200409032020.i83KKRXg028406@hertz.gene.com>
Message-ID: <Pine.A41.4.58.0409031332480.109708@homer03.u.washington.edu>

On Fri, 3 Sep 2004, Berton Gunter wrote:

> In some applications, e.g., visualizing the values of the wells in a 96 well
> (8 x 12) assay plate, the matrix of results is truly discrete and you want
> to visualize it that way. image() does this, but not filled.contour() AFAIK.
> If that's correct, the only way I know how to do it is to overlay two plots
> (par(new=FALSE)),one for the data and the other for the legend. This is
> certainly not trivial, but it's not impossibly hard, either.

layout() is probably easier.  That's how filled.contour does it.

	-thomas

>
> I hope I'm wrong on this, though, as I'd welcome an easier way, too.
>
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
>
> > Does filled.contour() give you what you want?
> >
> > Deepayan
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From sdavis2 at mail.nih.gov  Fri Sep  3 22:36:35 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 3 Sep 2004 16:36:35 -0400
Subject: [R] image() with color key?
In-Reply-To: <200409032020.i83KKRXg028406@hertz.gene.com>
References: <200409032020.i83KKRXg028406@hertz.gene.com>
Message-ID: <F2AED57A-FDE8-11D8-B0B6-000A95D7BA10@mail.nih.gov>

Have you looked at the code for the heatmap and heatmap.2 (gregmisc 
package)?  Also, it seems you might be able to do it with grid 
graphics?  Finally, I think there is a colorbar command in the marray 
package available at http://www.bioconductor.org that generated color 
bars for image plots.  A combo of image and colorbar (?maColorBar) in 
grid or something like that may work.

Perhaps the simplest solution would be to use heatmap or heatmap.2 
directly with dendrogram='none'.

Hope this helps.

Sean

On Sep 3, 2004, at 4:20 PM, Berton Gunter wrote:

> In some applications, e.g., visualizing the values of the wells in a 
> 96 well
> (8 x 12) assay plate, the matrix of results is truly discrete and you 
> want
> to visualize it that way. image() does this, but not filled.contour() 
> AFAIK.
> If that's correct, the only way I know how to do it is to overlay two 
> plots
> (par(new=FALSE)),one for the data and the other for the legend. This is
> certainly not trivial, but it's not impossibly hard, either.
>
> I hope I'm wrong on this, though, as I'd welcome an easier way, too.
>
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>
> "The business of the statistician is to catalyze the scientific 
> learning
> process."  - George E. P. Box
>
>> Does filled.contour() give you what you want?
>>
>> Deepayan
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From DAVID.BICKEL at PIONEER.COM  Fri Sep  3 22:54:06 2004
From: DAVID.BICKEL at PIONEER.COM (Bickel, David)
Date: Fri, 3 Sep 2004 15:54:06 -0500
Subject: [R] debugging an S4 method
Message-ID: <5F883C17941B9F4E80E5FA8C9F1C5E0E010FBB01@jhms08.phibred.com>

Does anyone know how to use the equivalent of debug() on an S4 method? I would like R to enter the browser not for the generic function, but for the method of the class that I specify.

Thanks,
David
_____________________________
David Bickel  http://davidbickel.com
Research Scientist
Pioneer Hi-Bred International
Bioinformatics & Exploratory Research
7250 NW 62nd Ave., PO Box 552
Johnston, Iowa 50131-0552
515-334-4739 Tel
515-334-6634 Fax
david.bickel at pioneer.com, bickel at prueba.info



This communication is for use by the intended recipient and ...{{dropped}}



From cdeclercq at nordnet.fr  Fri Sep  3 22:56:31 2004
From: cdeclercq at nordnet.fr (Christophe Declercq)
Date: Fri, 3 Sep 2004 22:56:31 +0200
Subject: [R] image() with color key?
References: <s13866a7.039@ohsu.edu>
Message-ID: <004d01c491f8$82585340$47ed92c3@Famille>

Hi, Michael

Did you try 'image.plot' in the 'fields' package?

Christophe

----- Original Message -----
From: "Michael Jerosch-Herold" <jeroschh at ohsu.edu>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, September 03, 2004 9:42 PM
Subject: [R] image() with color key?


> Is there an "easy" way to plot a "color key" next to a color image (with
> image() in graphics package)? The color key should also include a
> numerical scale, so that the colors can be cross-referenced with image
> intensity values. I see that levelplot has a facility for color keys,
> but with image it seems less straightforward, i.e. generating a color
> key is not an option in image().
>
> Thank you!
>
> Michael Jerosch-Herold
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>
>



From Manuel.A.Morales at williams.edu  Fri Sep  3 23:02:01 2004
From: Manuel.A.Morales at williams.edu (Manuel A. Morales)
Date: Fri, 03 Sep 2004 17:02:01 -0400
Subject: [R] ML vs. REML with gls()
Message-ID: <4138DBC9.4000003@williams.edu>

Hello listmembers,

I've been thinking of using gls in the nlme package to test for serial 
correlation in my data set. I've simulated a sample data set and have 
found a large discrepancy in the results I get when using the default 
method REML vs. ML.

The data set involves a response that is measured twice a day (once for 
each level of a treatment factor). In my simulated data set, I have a 
mean "day effect" but no serial correlation between days, otherwise. 
However, if I include an AR1 structure in my model, I find significant 
evidence of serial correlation when I fit the model using maximum 
likelihood! I don't see the same result when I use restricted maximum 
likelihood. I'm not a statistician, but I'm wondering if this is 
expected. I also realize that this particular example would work well 
with day as a random effect, but then I'm not sure how I would test for 
serial correlation across days. I have Pinheiro and Bate's extremely 
useful book, but I can't seem to find anything that addresses this. I'm 
using R 1.9.1 with version 3.1-50 of nlme.

Thanks very much for any help. I've included my sample code below.

Manuel Morales

#Below I generate a day variable (note two trials per day).
day<-rep(1:25,each=2)
#Below I generate a random "day effect"
day.effect<-c(); for(i in 1:25) {
	tmp<-rnorm(1);
	day.effect<-append(rep(tmp,2),day.effect)}
#Below I randomize the application of the treatment effect w/i days.
trt<-c(); for(i in 1:25) {
	if (rnorm(1)>0) trt<-append(c(0,1),trt)
	else trt<-append(c(1,0),trt)}
#Below I generate the response variable. Trt increases the response.
resp<-trt+day.effect+rnorm(50)

#Below I analyze the data using REML or ML w/ and w/o AR1 errors.
library(nlme)
base.gls<-gls(resp~factor(trt)+factor(day))
ar.gls<-gls(resp~factor(trt)+factor(day),corr=corAR1())
base.gls.ml<-gls(resp~factor(trt)+factor(day),method="ML")
ar.gls.ml<-gls(resp~factor(trt)+factor(day),corr=corAR1(),method="ML")

#Below I compare models using REML or ML
anova(base.gls,ar.gls); anova(base.gls.ml,ar.gls.ml)



From ernesto at ipimar.pt  Sat Sep  4 00:24:42 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Fri, 03 Sep 2004 23:24:42 +0100
Subject: [R] debugging an S4 method
In-Reply-To: <5F883C17941B9F4E80E5FA8C9F1C5E0E010FBB01@jhms08.phibred.com>
References: <5F883C17941B9F4E80E5FA8C9F1C5E0E010FBB01@jhms08.phibred.com>
Message-ID: <1094250282.3730.1.camel@moria.ipimar.pt>

On Fri, 2004-09-03 at 21:54, Bickel, David wrote:
> Does anyone know how to use the equivalent of debug() on an S4 method? I would like R to enter the browser not for the generic function, but for the method of the class that I specify.
> 

There's non (that I know) ... you can insert the command "browser()" in
the middle of your code.

Regards

EJ



From jonathan.nott at jcu.edu.au  Sat Sep  4 05:16:55 2004
From: jonathan.nott at jcu.edu.au (Jonathan Nott)
Date: Sat, 4 Sep 2004 13:16:55 +1000
Subject: [R] tests for non-stationarity
Message-ID: <000a01c4922d$a250bb80$8d75db89@CONGDON.jcu.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040904/843b194a/attachment.pl

From house-ball at yahoo.com.tw  Sat Sep  4 07:10:03 2004
From: house-ball at yahoo.com.tw (=?big5?q?house-ball?=)
Date: Sat, 4 Sep 2004 13:10:03 +0800 (CST)
Subject: [R] R question
Message-ID: <20040904051003.10463.qmail@web16807.mail.tpe.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040904/5b64d92c/attachment.pl

From 0034058 at fudan.edu.cn  Sat Sep  4 09:27:57 2004
From: 0034058 at fudan.edu.cn (ronggui wong)
Date: Sat, 04 Sep 2004 15:27:57 +0800
Subject: [R] what is th diffence among "cat","print"and"format"
Message-ID: <200409041527.57557.0034058@fudan.edu.cn>

what is the differnces?
and when to use each?



From house-ball at yahoo.com.tw  Sat Sep  4 11:51:54 2004
From: house-ball at yahoo.com.tw (=?big5?q?house-ball?=)
Date: Sat, 4 Sep 2004 17:51:54 +0800 (CST)
Subject: [R] R question
Message-ID: <20040904095154.90460.qmail@web16805.mail.tpe.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040904/a44f7183/attachment.pl

From ggrothendieck at myway.com  Sat Sep  4 14:46:59 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 4 Sep 2004 12:46:59 +0000 (UTC)
Subject: [R] what is th diffence among "cat","print"and"format"
References: <200409041527.57557.0034058@fudan.edu.cn>
Message-ID: <loom.20040904T143526-968@post.gmane.org>

ronggui wong <0034058 <at> fudan.edu.cn> writes:

> what is the differnces?
> and when to use each?


I think the main difference is that cat does not know about
objects.  It just unclasses the input (someone can correct
me on this if this is not true), converts each of the
unclassed inputs to character and concatenates and displays
the contatenated result on the standard output or to a file,
if specified. For example, 

	x <- 3
	class(x) <- "myclass"
	cat(x, "\n")
	cat(unclass(x), "\n")  # same

In contrast, print, format and as.character are S3 generics
which look at the class of their first argument and dispatch
a different method depending on which class is.  e.g.

	# using x from above
	print.myclass <- function(x) cat("***", x, "***\n")
	print(x)

The dispatched method will understand how to represent the
object as a character string so that it can display it in
the case of print or return it as a character string in the
case of format and as.character.  as.character is often just
a wrapper around format, e.g. the source for
as.character.Date is:

	as.character.Date <- function(x, ...) format(x, ...)

You can find out which methods are actually available using:

	methods(print)
	methods(format)
	methods(as.character)

The default method is used, e.g. print.default, if there is no 
available method for the class of the object.

If one wants to display a character string with control over
newlines then one typically uses cat.  If one wants to display
an object one uses print or else converts it to a character string
using format or as.character and then display it using cat.

If you just type the name of an object into R then it invokes
the print method for that object.  e.g.

	x   # same as print(x)



From kjetil at acelerate.com  Sat Sep  4 15:04:50 2004
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Sat, 04 Sep 2004 09:04:50 -0400
Subject: [R] tests for non-stationarity
In-Reply-To: <000a01c4922d$a250bb80$8d75db89@CONGDON.jcu.edu.au>
References: <000a01c4922d$a250bb80$8d75db89@CONGDON.jcu.edu.au>
Message-ID: <4139BD72.1010503@acelerate.com>

Jonathan Nott wrote:

>Dear R list members,
>
>Please excuse my ignorance but as a new comer to R I was wondering if anyone knows of any functions in R or Splus that can test a time-series for non-stationarity such as the Pettitt or the Mann-Kendall tests.
>
>Kind regards,
>
>Jon Nott
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>
Install package tseries from CRAn and do
library(help=tseries)

Kjetil Halvorsen

-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra



From kjetil at acelerate.com  Sat Sep  4 14:59:13 2004
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Sat, 04 Sep 2004 08:59:13 -0400
Subject: [R] R question
In-Reply-To: <20040904051003.10463.qmail@web16807.mail.tpe.yahoo.com>
References: <20040904051003.10463.qmail@web16807.mail.tpe.yahoo.com>
Message-ID: <4139BC21.6000301@acelerate.com>

house-ball wrote:

>Hi,
>
>Would you help me solve the following question? Thanks.
>
> 
>
>Question: If I try to set the probability=0.05 and find the approximate x. (The answer should be somewhere between 2.1782 and 2.1783.)
>
>I write about this R program as follows but I don????t know how to get the value of x which is between 2.1782 and 2.1783.
>
>  
>
First, you should probably read "An Introduction to R" which comes with 
your R-installation.
As posed your question is ambiguous, but assuming you mean to say 
"normal distribution", you need
something like

qnorm(0.05)

or if you mean probability in the upper tail

qnorm(0.05, lower.tail=FALSE)

Then read
?qnorm

Kjetil halvorsen

> 
>
>library(mvtnorm)
>
>value<-array(1000)
>
>a<-array(1000)
>
> 
>
>a<-seq(2,3,by=0.001)                   
>
>for(i in 1000)
>
>{
>
> x<-a[i]
>
> value[i]<-2*(pmvnorm(lower=-Inf, upper=-x, mean=0, sigma=1)+
>
>              pmvnorm(lower=c(-x,-Inf),upper=c(x,-x),mean=0,corr=diag(2)*sqrt(0.5)))
>
> if(value[i]-0.05<0.001) 
>
> print(x)
>
>}
>
>
>
>
>---------------------------------

>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra



From mbibo at qldnet.com.au  Sat Sep  4 16:58:32 2004
From: mbibo at qldnet.com.au (Michael Bibo)
Date: Sun, 05 Sep 2004 00:58:32 +1000
Subject: [R] Rcmdr X11 protocol error message
In-Reply-To: <20040901200517.KSIS19123.tomts20-srv.bellnexxia.net@JohnDesktop8300>
References: <20040901200517.KSIS19123.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <4139D818.7090700@qldnet.com.au>

John Fox wrote:

>Dear Michael and Peter,
>
>I've made the following changes to the current development version of the
>Rcmdr package (on my web site, at
>http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/index.html, but not posted
>to CRAN):
>
>(1) The default for the Rcmdr grab.focus option is now set to FALSE for
>non-Windows systems.
>
>(2) There's a new report.X11.warnings option, which is set to FALSE by
>default; this suppresses these warnings so that they don't appear in Rcmdr
>warning dialogs. This just papers over the problem without really solving
>it.
>
>I'm not happy with these "solutions," but perhaps they'll help until we
>discover the source of the problems. (I tested on my Quantian system.)
>
>Thanks for your help.
> John
>
>  
>
Thanks, John.

The commitment of contributors to R and to this list never ceases to 
amaze me!  The temporary solutions will help.
As I have indicated, I am not a programmer, so I can't offer much in 
terms of the underlying Tcl/Tk issues, but I am happy to test anything 
out for you on my system (if you can explain it simply enough for me).
I have another reliable observation with the new version of Rcmdr, which 
I offer only because it might provide a clue as to what's going on:
If you generate a scatterplot for two numerical variables grouped by a 
factor, the plot is drawn, but the dialogue box remains on screen, and 
is unresponsive.  When the graphics device is closed, you get an error 
message: 'Error: No graphics device active'.
If you then try to generate the same scatterplot ungrouped (which 
previously worked fine) you receive a message; 'Warning: display list 
redraw incomplete'.  This only occurs the first time you try to draw the 
ungrouped scatterplot.
Hope it helps.

Peter,
Any hints as to how to generate that trace of the execution you mentioned?

Michael

michael_bibo at health.qld.gov.au



From spencer.graves at pdf.com  Sat Sep  4 18:05:20 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 04 Sep 2004 09:05:20 -0700
Subject: [R] Non-Markovian Behaviour of a Cusum?
Message-ID: <4139E7C0.4050802@pdf.com>

      Can someone help me understand simulations of a one-sided Cusum? 

      Consider the following: 

      Q[i] = max(0, Q[i-1]+z[i]), z[i] ~ N(offset, 1), with Q[0] = FIR 
(fast initial response). 

      With offset < 0, mean{Q[i] for fixed i averaged over many 
simulations} approaches an asymptote as i -> Inf.  In simulations with 
abs(offset) small and FIR close to the asymptote, Q[i] tends initially 
to drop dramatically before starting to climb again to the asymptote.  
Q[i] is not stationary, as I would naively expect. 

      A simple script follows.  I get similar behavior for different 
values of offset in the range (0.01, 0.15);  for larger offsets, Q[i] 
converges to the asymptote so quickly that this behavior can't be seen, 
while for smaller offsets, the convergence is so slow, 500 observations 
is too few to see the behavior.  I've seen this in both S-Plus 6.1 and R 
1.9.1 with apparently independently programmed versions of this with 
different seeds and different random number generators, and I got a hint 
of this behavior in a small sample test in Excel. 

      What am I missing? 
      Thanks,
      spencer graves
##SCRIPT: 
CusumSim <- function(offset=-0.1, FIR=4.5, maxTime=500, nSims=10000){
# Simulate nSims simultaneous Cusums of length maxTime
# Q[i] <- max(0, Q[i-1]+z[i]), z[i] ~ N(offset, 1),
# Q[0] = FIR
# Store only the mean of Q[i] for each i
  Qmean <- rep(NA, maxTime)
  Q <- rep(FIR, nSims)
  for(i in 1:maxTime){
    Q <- pmax(0, Q+rnorm(nSims, mean=offset))
    Qmean[i] <- mean(Q)
  }
  Qmean
}

set.seed(321)
Cus1 <- CusumSim()
plot(Cus1)
# Different simulation, essentially the same behavior
Cus2 <- CusumSim()
plot(Cus1, ylim=range(Cus1, Cus2))
lines(Cus2)

# Different random number generator, same behavior
RNGkind("Wichmann-Hill")
CusWH <- CusumSim()
plot(Cus1, ylim=range(Cus1, Cus2, CusWH))
lines(Cus2)
lines(CusWH, col=2, lty=2, lwd=2)

# Different values for offest, same behavior
Cus.01 <- CusumSim(-.01, FIR=25)
plot(Cus.01)
Cus.15 <- CusumSim(-.15, FIR=3)
plot(Cus.15)
#
-- 

Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From myao at ou.edu  Sat Sep  4 21:25:12 2004
From: myao at ou.edu (Yao, Minghua)
Date: Sat, 4 Sep 2004 14:25:12 -0500
Subject: [R] Append Columns
Message-ID: <89944065A099FB4AB1296358DD02877A1FD72B@XMAIL.sooner.net.ou.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040904/49fe7cbc/attachment.pl

From ihok at hotmail.com  Sun Sep  5 00:27:23 2004
From: ihok at hotmail.com (Jack Tanner)
Date: Sat, 04 Sep 2004 18:27:23 -0400
Subject: [R] rodbc windows doesn't find dsn
Message-ID: <413A414B.5050508@hotmail.com>

Under WinXP, I have a system DSN called foo. It has stored 
username/password information. (I can click Configure in ODBC 
Administrator and then Test Data Source connects to MySQL without me 
re-entering data.)

Using RODBC, I can connect to the same database. But when I do 
odbcConnect("foo"), I get a window that requires me to re-enter 
username/password information. It seems like RODBC is not finding my 
system DSN. Am I doing something wrong?



From concerto1978 at hotmail.com  Sun Sep  5 04:15:44 2004
From: concerto1978 at hotmail.com (Sebastian S)
Date: Sun, 05 Sep 2004 02:15:44 +0000
Subject: [R] Biased calculations from using rmultinom? 
Message-ID: <BAY19-F149cMhtTYDGG00070233@hotmail.com>

Dear R users,

This is a problem that has puzzled me for quite some time, and I wonder if 
anyone could offer me an insight to what is happening?

I generated a multinomial matrix by using 
A<-rmultinom(100,1,c(0.4,0.3,0.2,0.1), and multiply this matrix by a set of 
values say B<-runif(n,100,50). I then calculate var(colSums(A*B)). I was 
able to work out the theoretical mean of var(colSums(A*B)) by using 
fun.var.match.gen below.

I was however not sure, why is there a persistent over estimate from my 
fun.var.match.gen? I have enclosed the tests I have used to demonstrate this 
fact. The difference is very small but very persistent throughout 
simulations. Is there something I have overlooked here?

All comments very welcome!

Sebastian.

#### Functions used:

fun.split.matrix<-
function(object, index)
{
	result <- lapply(split(object, index), function(x, object)
	matrix(x, ncol = ncol(object)), object)
	return(result)
}

fun.var.match.gen<-function(q,n,mean.cost.m,var.cost.m){
	k<-length(q)
	mean.o<-sum(n*q*mean.cost.m)/k

	result<-sum(n*var.cost.m*q+mean.cost.m^2*(n*q*(1-q+n*q))-2*mean.o*n*q*mean.cost.m+mean.o^2)/(k-1)
}


# Test:

p1<-c(10,10,1,8,8,6,10,9,6,5)
p1<-p1/sum(p1)
e<-5
f<-60000

n1<-4
n.rep<-50000
n.gen<-n1*n.rep

A<-fun.runif(n.gen,e,f)

temp1a<-rmultinom(n.gen,1,p1)*A
# Randomly select items to split
sam<-sample(rep(1:n.rep,each=n1))
temp3<-sapply(fun.split.matrix(temp1a,sam),colSums)

junk.vars<-apply(temp3,2,var)
junk.m<-mean(junk.vars)
junk.theo<-fun.var.match.gen(p1,n1,(e+f)/2,(f-e)^2/12)

plot(junk.vars)
abline(h=junk.theo,col=2)
abline(h=junk.m)


http://adsfac.net/link.asp?cc=FXT002.7542.0



From ramasamy at cancer.org.uk  Sun Sep  5 06:08:44 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Sun, 05 Sep 2004 05:08:44 +0100
Subject: [R] Append Columns
In-Reply-To: <89944065A099FB4AB1296358DD02877A1FD72B@XMAIL.sooner.net.ou.edu>
References: <89944065A099FB4AB1296358DD02877A1FD72B@XMAIL.sooner.net.ou.edu>
Message-ID: <1094357324.24897.18.camel@ndmpc255.ndm.ox.ac.uk>

Using append=TRUE in write.table only appends rows (see example below).
You might be interested in a recent tread about appending to save()
 http://tolstoy.newcastle.edu.au/R/help/04/07/1467.html

> write.table( matrix(1:9, 3), file="aaa.txt", sep="\t" )
> write.table( matrix(101:109, 3), file="aaa.txt", sep="\t",        
append=TRUE, col.names=FALSE )
> read.delim(file="aaa.txt", row.names=NULL)
  row.names  X1  X2  X3
1         1   1   4   7
2         2   2   5   8
3         3   3   6   9
4         1 101 104 107
5         2 102 105 108
6         3 103 106 109


Here are some possible solutions :

1) Read in the existing file first then use cbind and writing it back. 

2) If you plan on doing this frequently (as in a loop), transpose your
problem so that you appending rows as above and after the last
iteration, transpose the results.

3) If you have access to unix/linux environments you can try the paste
command.

Regards, Adai









On Sat, 2004-09-04 at 20:25, Yao, Minghua wrote:
> Dear all,
>  
> Can I use "write.table" to append columnns?
>  
> Thanks for any help
>  
> -MY
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From klaus_thul at yahoo.com  Sun Sep  5 16:00:17 2004
From: klaus_thul at yahoo.com (Klaus Thul)
Date: Sun, 5 Sep 2004 16:00:17 +0200
Subject: [R] Question to NLME, ML vs. REML
Message-ID: <200409051600.17320.klaus_thul@yahoo.com>

Dear all,

I am planning to use nlme library for analysis of experiments in semiconductor 
industry. Currently I am using "lm" but plan to move to "lme" to handle 
within wafer / wafer-to-wafer and lot-to-lot variation correctly. 

So far everything is working well, but I have a fundamentel question: 

NLME offers "maximum likelihood" and "restricted maximum likelihood" for 
parameter estimation. ML has the advantage, that likelihood ratios can be 
computed even with changes in model structure. In addition, ML works with the 
stepAIC function from MASS-library which I am currently using for 
model-building.

I am wondering, why REML is the default setting in NLME and therefore somehow 
preferred by the authors. What is the main reason to use REML? 

Maybe I am lacking here statistical knowledge. Any hint, including reference 
to literature would be very helpful.

Best regards,
Klaus Thul



From jean-noel.candau at avignon.inra.fr  Sun Sep  5 10:40:18 2004
From: jean-noel.candau at avignon.inra.fr (Jean-Noel)
Date: Sun, 5 Sep 2004 10:40:18 +0200
Subject: [R] Generalized degrees of freedom and regression trees
Message-ID: <GOENJEALPPDFMBOMCKOJGEDICIAA.jean-noel.candau@avignon.inra.fr>

Has anybody ever implemented in R the "generalized degree of freedom"
proposed by Ye (1998) in JASA 93(441):120-131 ?
I would like to use this method to calculate degrees of freedom of
regression trees.
Thanks in advance.

Jean-Noel Candau
INRA - Unit?? de Recherches Foresti??res M??diterran??ennes
Avenue A. Vivaldi
84000 AVIGNON
Tel: (33) 4 90 13 59 22
Fax: (33) 4 90 13 59 59



From house-ball at yahoo.com.tw  Sun Sep  5 13:21:27 2004
From: house-ball at yahoo.com.tw (=?big5?q?house-ball?=)
Date: Sun, 5 Sep 2004 19:21:27 +0800 (CST)
Subject: [R] R question
Message-ID: <20040905112127.29342.qmail@web16807.mail.tpe.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040905/84b52dd6/attachment.pl

From house-ball at yahoo.com.tw  Sun Sep  5 13:23:30 2004
From: house-ball at yahoo.com.tw (=?big5?q?house-ball?=)
Date: Sun, 5 Sep 2004 19:23:30 +0800 (CST)
Subject: [R] R question
Message-ID: <20040905112330.91311.qmail@web16802.mail.tpe.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040905/e23ed6d1/attachment.pl

From kjetil at acelerate.com  Sun Sep  5 14:12:04 2004
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Sun, 05 Sep 2004 08:12:04 -0400
Subject: [R] R question
In-Reply-To: <20040905112127.29342.qmail@web16807.mail.tpe.yahoo.com>
References: <20040905112127.29342.qmail@web16807.mail.tpe.yahoo.com>
Message-ID: <413B0294.10309@acelerate.com>

house-ball wrote:

Why do you repeat an unclear question fou times? Please read the posting 
guide.
It is not clear what is your problem.

Kjetil halvorsen

>Hi,
>
>Would you help me solve the following question? Thanks.
>
>my program is as follows:
>
>  
>
>>library(mvtnorm)
>>    
>>
>
>  
>
>>value<-pmvnorm(lower=-Inf, upper=-2.178, mean=0, sigma=1)+          pmvnorm(lower=2.178, upper=Inf, mean=0, sigma=1)+   pmvnorm(lower=c(-2.178,-Inf),upper=c(2.178,-2.178),mean=0,corr=diag(2)*sqrt(0.5))+       pmvnorm(lower=c(-2.178,2.178),upper=c(2.178,Inf),mean=0,corr=diag(2)*sqrt(0.5))
>>    
>>
>
>  
>
>>value
>>    
>>
>
>[1] 0.05794736
>
> 
>
>Now if I try to set the probability=0.05 and find the approximate critical value. (The answer should be somewhere between 2.1782 and 2.1783.)
>
>I write about this R program as follows but I don????t know how to get the value of x which is between 2.1782 and 2.1783. Would you check out what????s a problem with my  program ? Thanks.
>
> 
>
>library(mvtnorm)
>
>value<-array(1000)
>
>a<-array(1000)
>
> 
>
>a<-seq(2,3,by=0.001)                   
>
>for(i in 1000)
>
>{
>
> x<-a[i]
>
> value[i]<-2*(pmvnorm(lower=-Inf, upper=-x, mean=0, sigma=1)+
>
>           pmvnorm(lower=c(-x,-Inf),upper=c(x,-x),mean=0,corr=diag(2)*sqrt(0.5)))
>
> if(value[i]-0.05<0.001) 
>
> print(x)
>
>}
>
> 
>
>Chia-Yi
>
>
>
>
>---------------------------------

>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra



From spencer.graves at pdf.com  Sun Sep  5 18:29:15 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 05 Sep 2004 09:29:15 -0700
Subject: [R] Question to NLME, ML vs. REML
In-Reply-To: <200409051600.17320.klaus_thul@yahoo.com>
References: <200409051600.17320.klaus_thul@yahoo.com>
Message-ID: <413B3EDB.9020908@pdf.com>

    Have you read Pinheiro and Bates (2000) Mixed-Effects Models in S 
and S-Plus (Springer)?  I learned a lot from this book and recommend it 
very highly. 

      Probably the most obvious difference is that ML estimates of 
variance components are biased.  The bias is equivalent to estimating 
the variance of a population by dividing the sum of squared deviations 
from the sample mean of N observations by N rather than N-1. 

      To check for other differences, I just did library(mle4) in R 
1.9.1 and ran the example in help("lme") then ran the same lme call with 
method="ML".  The results (see below) show that the parameter estimates 
for the fixed effects are the same for ML as for REML, but the estimates 
of standard errors of those parameters seems to perpetuate the bias 
corrected by REML. 

      If stepAIC works with ML but not with REML, I would use stepAIC 
with ML then reestimate the final model with REML.  However, I would 
also do some simulations to estimate the false positive (Type I) error 
rate.  AIC includes a penalty for the complexity of the model but NOT 
for the number of alternatives considered, and if you present enough 
random alternatives to the procedure, it will find some that are 
statistically significant.  The nlme package contains a function 
"simulate.lme" to facilitate this. 

      hope this helps.  spencer graves

 > library(lme4)
 >      data(bdf)
 >      fm <- lme(langPOST ~ IQ.ver.cen + avg.IQ.ver.cen, data = bdf,
+                random = ~ IQ.ver.cen | schoolNR)
 >      summary(fm)
Linear mixed-effects model fit by REML
Fixed: langPOST ~ IQ.ver.cen + avg.IQ.ver.cen
 Data: bdf
      AIC      BIC    logLik
 15231.87 15272.02 -7608.937

Random effects:
 Groups   Name        Variance Std.Dev. Corr  
 schoolNR (Intercept)  8.07563 2.84177        
          IQ.ver.cen   0.20801 0.45608  -0.642
 Residual             41.34968 6.43037        
# of obs: 2287, groups: schoolNR, 131

Fixed effects:
                 Estimate Std. Error   DF t value  Pr(>|t|)   
(Intercept)    4.0750e+01 2.8808e-01 2284 141.452 < 2.2e-16 ***
IQ.ver.cen     2.4598e+00 8.3638e-02 2284  29.410 < 2.2e-16 ***
avg.IQ.ver.cen 1.4089e+00 3.2374e-01 2284   4.352 1.409e-05 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Correlation of Fixed Effects:
            (Intr) IQ.vr.
IQ.ver.cen  -0.274      
avg.IQ.vr.c  0.029 -0.213
 >      fm.ml <- lme(langPOST ~ IQ.ver.cen + avg.IQ.ver.cen, data = bdf,
+                random = ~ IQ.ver.cen | schoolNR, method="ML")
 >      summary(fm.ml)
Linear mixed-effects model fit by maximum likelihood
Fixed: langPOST ~ IQ.ver.cen + avg.IQ.ver.cen
 Data: bdf
      AIC      BIC    logLik
 15227.53 15267.68 -7606.767

Random effects:
 Groups   Name        Variance Std.Dev. Corr  
 schoolNR (Intercept)  7.91904 2.81408        
          IQ.ver.cen   0.20006 0.44728  -0.652
 Residual             41.35055 6.43044        
# of obs: 2287, groups: schoolNR, 131

Fixed effects:
                 Estimate Std. Error   DF  t value  Pr(>|t|)   
(Intercept)    4.0750e+01 2.8610e-01 2284 142.4342 < 2.2e-16 ***
IQ.ver.cen     2.4589e+00 8.3237e-02 2284  29.5406 < 2.2e-16 ***
avg.IQ.ver.cen 1.4052e+00 3.2168e-01 2284   4.3683 1.308e-05 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Correlation of Fixed Effects:
            (Intr) IQ.vr.
IQ.ver.cen  -0.274      
avg.IQ.vr.c  0.028 -0.214
#######################
Klaus Thul wrote:

>Dear all,
>
>I am planning to use nlme library for analysis of experiments in semiconductor 
>industry. Currently I am using "lm" but plan to move to "lme" to handle 
>within wafer / wafer-to-wafer and lot-to-lot variation correctly. 
>
>So far everything is working well, but I have a fundamentel question: 
>
>NLME offers "maximum likelihood" and "restricted maximum likelihood" for 
>parameter estimation. ML has the advantage, that likelihood ratios can be 
>computed even with changes in model structure. In addition, ML works with the 
>stepAIC function from MASS-library which I am currently using for 
>model-building.
>
>I am wondering, why REML is the default setting in NLME and therefore somehow 
>preferred by the authors. What is the main reason to use REML? 
>
>Maybe I am lacking here statistical knowledge. Any hint, including reference 
>to literature would be very helpful.
>
>Best regards,
>Klaus Thul
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From michelle.bell at yale.edu  Sun Sep  5 21:08:34 2004
From: michelle.bell at yale.edu (Michelle Bell)
Date: Sun, 05 Sep 2004 15:08:34 -0400
Subject: [R] Hawaii in map() function
Message-ID: <5.2.1.1.2.20040905150645.00b033e0@mlb69.mail.yale.edu>

I would like to use the map function for the continental US plus Hawaii, 
but can only find the library files for the continental US. Suggestions?
Thank you.



From cdeclercq at nordnet.fr  Sun Sep  5 22:02:41 2004
From: cdeclercq at nordnet.fr (Christophe Declercq)
Date: Sun, 5 Sep 2004 22:02:41 +0200
Subject: [R] Hawaii in map() function
References: <5.2.1.1.2.20040905150645.00b033e0@mlb69.mail.yale.edu>
Message-ID: <003401c49383$50c6ef30$37ef92c3@Famille>


> From: "Michelle Bell" <michelle.bell at yale.edu>
> To: <r-help at stat.math.ethz.ch>
> Sent: Sunday, September 05, 2004 9:08 PM
> Subject: [R] Hawaii in map() function


> I would like to use the map function for the continental US plus Hawaii, 
> but can only find the library files for the continental US. Suggestions?

You can find Hawaii in the world map database

You could try:

> library(map)
> map("world", c("USA", "Hawaii"))
 
which has perhaps more than what you want, or try something like:

> map("usa", xlim=c(-170,-60), ylim=c(15,55))
> map("world", "Hawaii", add=TRUE)

Christophe



From laura at env.leeds.ac.uk  Mon Sep  6 02:14:40 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Mon, 6 Sep 2004 01:14:40 +0100 (BST)
Subject: [R] Applying function to lots of separate data sets
Message-ID: <Pine.LNX.4.44.0409060103560.13359-100000@gw.env.leeds.ac.uk>

I have a total mental block and can't find my way around this seemingly
simple problem:

I have created a function such that:

my_answer_1=myfuntion(my_input_1)

I am wanting to perform this calculation over a large number of datasets,
but am having real difficulty calling and assigning - i think the problem
les in the fact that I need to paste for call and assign.

this is my best attempt so far..I can't seem to find a way around this...

for(i in 1:50)
eval(parse(text=paste("my_answer_",i,
    "<-myfunction(text=paste("my_input_",i,sep=""))",sep="")))

can someone please point out where i am going wrong?

Thanks in advance..

Laura Quinn
Institute of Atmospheric Science
School of the Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk



From murdoch at stats.uwo.ca  Mon Sep  6 02:21:00 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 05 Sep 2004 20:21:00 -0400
Subject: [R] Applying function to lots of separate data sets
In-Reply-To: <Pine.LNX.4.44.0409060103560.13359-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0409060103560.13359-100000@gw.env.leeds.ac.uk>
Message-ID: <o7bnj0tip2nfm6jrergsijr81suc8r2mhg@4ax.com>

On Mon, 6 Sep 2004 01:14:40 +0100 (BST), Laura Quinn
<laura at env.leeds.ac.uk> wrote:

>I have a total mental block and can't find my way around this seemingly
>simple problem:
>
>I have created a function such that:
>
>my_answer_1=myfuntion(my_input_1)
>
>I am wanting to perform this calculation over a large number of datasets,
>but am having real difficulty calling and assigning - i think the problem
>les in the fact that I need to paste for call and assign.
>
>this is my best attempt so far..I can't seem to find a way around this...
>
>for(i in 1:50)
>eval(parse(text=paste("my_answer_",i,
>    "<-myfunction(text=paste("my_input_",i,sep=""))",sep="")))
>
>can someone please point out where i am going wrong?

Using paste() to construct variable names is overdone.  It's much
better to put all of your data into a list in one object, then just
use lapply() to apply a function to each element of the list.

For examples, see ?lapply.

Duncan Murdoch



From spencer.graves at pdf.com  Mon Sep  6 02:45:11 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 05 Sep 2004 17:45:11 -0700
Subject: [R] Applying function to lots of separate data sets
In-Reply-To: <o7bnj0tip2nfm6jrergsijr81suc8r2mhg@4ax.com>
References: <Pine.LNX.4.44.0409060103560.13359-100000@gw.env.leeds.ac.uk>
	<o7bnj0tip2nfm6jrergsijr81suc8r2mhg@4ax.com>
Message-ID: <413BB317.40509@pdf.com>

      Also, the underscore "_" in a legal character in a name in R 1.9 
but not, I think in previous versions, where "_" translates to "<-".  
Moreover, with at least some versions of ESS / Emacs / XEmacs, "_" is 
translated into "<-" by (X)Emacs before it gets to R.  hope this helps.  
spencer graves

Duncan Murdoch wrote:

>On Mon, 6 Sep 2004 01:14:40 +0100 (BST), Laura Quinn
><laura at env.leeds.ac.uk> wrote:
>
>  
>
>>I have a total mental block and can't find my way around this seemingly
>>simple problem:
>>
>>I have created a function such that:
>>
>>my_answer_1=myfuntion(my_input_1)
>>
>>I am wanting to perform this calculation over a large number of datasets,
>>but am having real difficulty calling and assigning - i think the problem
>>les in the fact that I need to paste for call and assign.
>>
>>this is my best attempt so far..I can't seem to find a way around this...
>>
>>for(i in 1:50)
>>eval(parse(text=paste("my_answer_",i,
>>   "<-myfunction(text=paste("my_input_",i,sep=""))",sep="")))
>>
>>can someone please point out where i am going wrong?
>>    
>>
>
>Using paste() to construct variable names is overdone.  It's much
>better to put all of your data into a list in one object, then just
>use lapply() to apply a function to each element of the list.
>
>For examples, see ?lapply.
>
>Duncan Murdoch
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From laura at env.leeds.ac.uk  Mon Sep  6 03:08:04 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Mon, 6 Sep 2004 02:08:04 +0100 (BST)
Subject: [R] Applying function to lots of separate data sets
In-Reply-To: <o7bnj0tip2nfm6jrergsijr81suc8r2mhg@4ax.com>
Message-ID: <Pine.LNX.4.44.0409060203550.13359-100000@gw.env.leeds.ac.uk>

Thank you - I have followed your advice but it then begs a further
question!

I am wanting to plot elements from within the list, but I don't know how
to subscript down so far, I want to plot values from rows(1:10) within,
for instance, mylist[[20]], for columns (1:5).

how can I define these??

Laura Quinn
Institute of Atmospheric Science
School of the Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk

On Sun, 5 Sep 2004, Duncan Murdoch wrote:

> On Mon, 6 Sep 2004 01:14:40 +0100 (BST), Laura Quinn
> <laura at env.leeds.ac.uk> wrote:
>
> >I have a total mental block and can't find my way around this seemingly
> >simple problem:
> >
> >I have created a function such that:
> >
> >my_answer_1=myfuntion(my_input_1)
> >
> >I am wanting to perform this calculation over a large number of datasets,
> >but am having real difficulty calling and assigning - i think the problem
> >les in the fact that I need to paste for call and assign.
> >
> >this is my best attempt so far..I can't seem to find a way around this...
> >
> >for(i in 1:50)
> >eval(parse(text=paste("my_answer_",i,
> >    "<-myfunction(text=paste("my_input_",i,sep=""))",sep="")))
> >
> >can someone please point out where i am going wrong?
>
> Using paste() to construct variable names is overdone.  It's much
> better to put all of your data into a list in one object, then just
> use lapply() to apply a function to each element of the list.
>
> For examples, see ?lapply.
>
> Duncan Murdoch
>



From laura at env.leeds.ac.uk  Mon Sep  6 03:13:10 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Mon, 6 Sep 2004 02:13:10 +0100 (BST)
Subject: [R] Applying function to lots of separate data sets
In-Reply-To: <o7bnj0tip2nfm6jrergsijr81suc8r2mhg@4ax.com>
Message-ID: <Pine.LNX.4.44.0409060212230.13359-100000@gw.env.leeds.ac.uk>

Aha, apologies...I have just answered my own question - thanks for showing
me the light with lists, lots of time saving ahead!!

Laura

Laura Quinn
Institute of Atmospheric Science
School of the Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk

On Sun, 5 Sep 2004, Duncan Murdoch wrote:

> On Mon, 6 Sep 2004 01:14:40 +0100 (BST), Laura Quinn
> <laura at env.leeds.ac.uk> wrote:
>
> >I have a total mental block and can't find my way around this seemingly
> >simple problem:
> >
> >I have created a function such that:
> >
> >my_answer_1=myfuntion(my_input_1)
> >
> >I am wanting to perform this calculation over a large number of datasets,
> >but am having real difficulty calling and assigning - i think the problem
> >les in the fact that I need to paste for call and assign.
> >
> >this is my best attempt so far..I can't seem to find a way around this...
> >
> >for(i in 1:50)
> >eval(parse(text=paste("my_answer_",i,
> >    "<-myfunction(text=paste("my_input_",i,sep=""))",sep="")))
> >
> >can someone please point out where i am going wrong?
>
> Using paste() to construct variable names is overdone.  It's much
> better to put all of your data into a list in one object, then just
> use lapply() to apply a function to each element of the list.
>
> For examples, see ?lapply.
>
> Duncan Murdoch
>



From jfox at mcmaster.ca  Mon Sep  6 05:53:02 2004
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 5 Sep 2004 23:53:02 -0400
Subject: [R] Rcmdr X11 protocol error message
In-Reply-To: <4139D818.7090700@qldnet.com.au>
Message-ID: <20040906035259.GJHR7925.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Michael, 

> -----Original Message-----
> From: Michael Bibo [mailto:mbibo at qldnet.com.au] 
> Sent: Saturday, September 04, 2004 9:59 AM
> To: John Fox
> Cc: 'Peter Dalgaard'; r-help at stat.math.ethz.ch; 'Dirk Eddelbuettel'
> Subject: Re: [R] Rcmdr X11 protocol error message
> 

 . . .

> I have another reliable observation with the new version of 
> Rcmdr, which I offer only because it might provide a clue as 
> to what's going on:
> If you generate a scatterplot for two numerical variables 
> grouped by a factor, the plot is drawn, but the dialogue box 
> remains on screen, and is unresponsive.  When the graphics 
> device is closed, you get an error
> message: 'Error: No graphics device active'.
> If you then try to generate the same scatterplot ungrouped 
> (which previously worked fine) you receive a message; 
> 'Warning: display list redraw incomplete'.  This only occurs 
> the first time you try to draw the ungrouped scatterplot.
> Hope it helps.
> 

This works fine for me, under both Windows and Quantian. Is it possible that
you forgot to left-click to position the legend for the scatterplot by
groups (at is indicated at the bottom of the Groups dialog box)?

I hope that this helps,
 John

> Peter,
> Any hints as to how to generate that trace of the execution 
> you mentioned?
> 
> Michael
> 
> michael_bibo at health.qld.gov.au
> 
>



From hadasa704 at 012.net.il  Mon Sep  6 09:33:10 2004
From: hadasa704 at 012.net.il (The Michaelson Institute)
Date: Mon, 06 Sep 2004 07:33:10 -0000
Subject: [R] Cox regression for prevalence estimates
Message-ID: <20040906073128.OBYF22312.fep15@doctor1.workgroup>

Hello, I'm an MD working in an eye clinic. I'm learning by myself to use R
for use in my research works and for implementation in a software project.
There are some authors who recomends the use of Cox regression as a
substitute for Logistic regression (<a
href="http://www.biomedcentral.com/1471-2288/3/21.pdf"> Barros AJD, Hirakata
VN. BMCMedical Research Methodology, 2003; 3:21 </a>. The use of Cox
regression permit the estimation of the prevalence rates rather than Odds
ratios obtained by logistic regression analysis. 
Cox regression is used for time-to-event data. To obtain prevalence rates
the time has to be constant. One of the problems of Cox regression is that
the confidence intervals are overestimated. To correct this Barros &
Hirakata recommend the use of robust variance estimates.
How can R be used to calculate the prevalence ratios using Cox regression +
robust variance estimates ?

Thanks for your collaboration,

Tomas Karpati MD
The Michaelson Institute for Rehabilitation of Vision
Hadassah Medical Organization



From s.su at qut.edu.au  Mon Sep  6 09:46:17 2004
From: s.su at qut.edu.au (Steve Su)
Date: Mon, 6 Sep 2004 17:46:17 +1000
Subject: [R] Biased calculations from using rmultinom?
Message-ID: <001201c493e5$97fb01e0$2032b583@qut.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040906/97ff5098/attachment.pl

From christoph.lehmann at gmx.ch  Mon Sep  6 10:52:56 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Mon, 06 Sep 2004 10:52:56 +0200
Subject: [R] locator() in a multi-figure setting using mfrow()
Message-ID: <413C2568.6020007@gmx.ch>

Hi

based on some code from Thomas Petzoldt (see below), I have a question, 
about how to use locator() in a mfrow() multi-figure setting. I am sure 
this should be a kind of problem, which other people face too?

we have 8 matrices each 10x10 fields, plotted as mfrow = c(2,4).

how can I get, using locator(), the correct index of a field of one of 
the 8 matrices? means, I should get 3 values: the matrix I am in (a 
value between 1..8), and the corresponding x and y coordinates (each in 
1..10)

many, thanks for your kind help.

---
opar <- par(mfrow = c(2,4))
slices <- 8
m <- matrix(runif(100),10,10)
my.list <- list()
for (slice in 1:slices) {
     my.list[[slice]] <- m
}

for  (slice in 1:slices) {
     x <- 1*(1:25)
     y <- 1*(1:25)
     z <- my.list[[slice]]
     image(list(x = 0:9, y = 0:9, z = z))
}
par(opar) #restore device parameters


p <- locator(1)
c(round(p$x), round(p$y))
---

how can I get the "correct" location in the sense of a
3d info: (a) which slice (p$slice) (b) p$x (c) p$y

so that it could be used in the sense of:

	my.list[[p$slice]][round(p$x), round(p$y)]


christoph



From armin at xss.de  Mon Sep  6 11:32:38 2004
From: armin at xss.de (Armin Roehrl)
Date: Mon, 06 Sep 2004 11:32:38 +0200
Subject: [R] extRemes; what data is ftcanmax?
Message-ID: <413C2EB6.6030506@xss.de>

Heya,

  sorry, if I ask the obvious, but I did not find it anywhere.

What Prec got measured here? What real-life observation
is behind that data?

----------
library(extRemes)
data(ftcanmax)
ftcanmax
 > data(ftcanmax)
 > ftcanmax
    Year Prec
1   1900  239
2   1901  232
3   1902  434
etc.
-------

Thanks,
  -Armin



From laura at env.leeds.ac.uk  Mon Sep  6 11:36:12 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Mon, 6 Sep 2004 10:36:12 +0100 (BST)
Subject: [R] Problems with png()
Message-ID: <Pine.LNX.4.44.0409061032050.21322-100000@gw.env.leeds.ac.uk>

I am trying to save a series of plots as .png files by using

png(file="myfile.png",bg="transparent")
dev.off()

for each image plot I produce. Unfortunately when I have tried this I am
unable to open the files, and am told they are corrupted.

I have tried to use the jpeg() function but have the same problem. The only way I have managed to
export a graphic successfully is as dev.copy2eps. Aside from producing
unwieldy files, this is also unhelpful as I at m hoping to create a movie of
the images via ImageMagick.

Any suggestions?

Thanks in advance,

Laura Quinn
Institute of Atmospheric Science
School of the Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk



From christoph.lehmann at gmx.ch  Mon Sep  6 11:40:24 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Mon, 06 Sep 2004 11:40:24 +0200
Subject: [R] locator() in a multi-figure setting using mfrow()
In-Reply-To: <413C2568.6020007@gmx.ch>
References: <413C2568.6020007@gmx.ch>
Message-ID: <413C3088.1000707@gmx.ch>


I know, that I can use par(mfg = c(i,u)) to get the correct x,y 
coordinates of one of the 8 matrices/subimages, but how can I get the i 
and the j, means how can I know in which of the 8 images I am clicking in?

thanks

Christoph

Christoph Lehmann wrote:
> Hi
> 
> based on some code from Thomas Petzoldt (see below), I have a question, 
> about how to use locator() in a mfrow() multi-figure setting. I am sure 
> this should be a kind of problem, which other people face too?
> 
> we have 8 matrices each 10x10 fields, plotted as mfrow = c(2,4).
> 
> how can I get, using locator(), the correct index of a field of one of 
> the 8 matrices? means, I should get 3 values: the matrix I am in (a 
> value between 1..8), and the corresponding x and y coordinates (each in 
> 1..10)
> 
> many, thanks for your kind help.
> 
> ---
> opar <- par(mfrow = c(2,4))
> slices <- 8
> m <- matrix(runif(100),10,10)
> my.list <- list()
> for (slice in 1:slices) {
>     my.list[[slice]] <- m
> }
> 
> for  (slice in 1:slices) {
>     x <- 1*(1:25)
>     y <- 1*(1:25)
>     z <- my.list[[slice]]
>     image(list(x = 0:9, y = 0:9, z = z))
> }
> par(opar) #restore device parameters
> 
> 
> p <- locator(1)
> c(round(p$x), round(p$y))
> ---
> 
> how can I get the "correct" location in the sense of a
> 3d info: (a) which slice (p$slice) (b) p$x (c) p$y
> 
> so that it could be used in the sense of:
> 
>     my.list[[p$slice]][round(p$x), round(p$y)]
> 
> 
> christoph
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From pfm401 at lineone.net  Mon Sep  6 11:51:28 2004
From: pfm401 at lineone.net (pfm401@lineone.net)
Date: Mon, 6 Sep 2004 10:51:28 +0100
Subject: [R] rpart problem
Message-ID: <4124B98A000A0D7F@mk-cpfrontend-3.mail.uk.tiscali.com>

Dear all,

I am having some trouble with getting the rpart function to work as expected.
I am trying to use rpart to combine levels of a factor to reduce the number
of levels of that factor. In exploring the code I have noticed that it is
possible for chisq.test to return a statistically significant result whilst
the rpart method returns only the root node (i.e. no split is made). The
following code recreates the issue using simulated data :


# Create a 2 level factor with group 1 probability of success 90% and group
2 60%
tmp1  <- as.factor((runif (1000) <= 0.9))
tmp2  <- as.factor((runif (1000) <= 0.5))
mysuccess <- as.factor(c(tmp1, tmp2)) 
mygroup   <- as.factor(c(rep (1,1000), rep (2,1000)))

table (mysuccess, mygroup)
chisq.test (mysuccess, mygroup)
# p-value = < 2.2e-16

myrpart <- rpart (mysuccess ~ mygroup)
myrpart
# rpart does not provide splits !!



If I change the parameter in the setting of group 2 to 0.3 from 0.6 rpart
does return splits, i.e. change the line 

tmp2  <- as.factor((runif (1000) <= 0.6))

to 

tmp2  <- as.factor((runif (1000) <= 0.3))

rpart does split the nodes, but as the split with 0.6 is highly significant
I would still have expected a split in this case too.

 
I would appreciate any advice as to whether this is a known feature of rpart,
whether I need to change the way my data are stored, or set some of the
control options. I have tested a few of these options with no success.


Thanks,
Paul.


__________________________________________________________________
Get Tiscali Broadband From ??15:99
http://www.tiscali.co.uk/products/broadbandhome/



From ligges at statistik.uni-dortmund.de  Mon Sep  6 11:53:22 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 06 Sep 2004 11:53:22 +0200
Subject: [R] Problems with png()
In-Reply-To: <Pine.LNX.4.44.0409061032050.21322-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0409061032050.21322-100000@gw.env.leeds.ac.uk>
Message-ID: <413C3392.1040001@statistik.uni-dortmund.de>

Laura Quinn wrote:

> I am trying to save a series of plots as .png files by using
> 
> png(file="myfile.png",bg="transparent")
> dev.off()

More details please, we cannot help otherwise.
At least version of R, operating system, and version of libpng, as well 
as the program that told you the file is corrupted ...

Uwe Ligges



> for each image plot I produce. Unfortunately when I have tried this I am
> unable to open the files, and am told they are corrupted.
> 
> I have tried to use the jpeg() function but have the same problem. The only way I have managed to
> export a graphic successfully is as dev.copy2eps. Aside from producing
> unwieldy files, this is also unhelpful as I at m hoping to create a movie of
> the images via ImageMagick.
> 
> Any suggestions?
> 
> Thanks in advance,
> 
> Laura Quinn
> Institute of Atmospheric Science
> School of the Environment
> University of Leeds
> Leeds
> LS2 9JT
> 
> tel: +44 113 343 1596
> fax: +44 113 343 6716
> mail: laura at env.leeds.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From B.Rowlingson at lancaster.ac.uk  Mon Sep  6 11:57:53 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 06 Sep 2004 10:57:53 +0100
Subject: [R] Problems with png()
In-Reply-To: <Pine.LNX.4.44.0409061032050.21322-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0409061032050.21322-100000@gw.env.leeds.ac.uk>
Message-ID: <413C34A1.6070003@lancaster.ac.uk>

Laura Quinn wrote:
> I am trying to save a series of plots as .png files by using
> 
> png(file="myfile.png",bg="transparent")
> dev.off()
> 
> for each image plot I produce. Unfortunately when I have tried this I am
> unable to open the files, and am told they are corrupted.
> 
> I have tried to use the jpeg() function but have the same problem. The only way I have managed to
> export a graphic successfully is as dev.copy2eps. Aside from producing
> unwieldy files, this is also unhelpful as I at m hoping to create a movie of
> the images via ImageMagick.
> 

  This sounds a bit obvious, but are you doing your plot commands 
_between_ the png() call and the dev.off() call?

  Try:

  png(file="foo.png")
  plot(1:10)
  dev.off()

  What version/platform are you using?

Barry



From laura at env.leeds.ac.uk  Mon Sep  6 12:00:06 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Mon, 6 Sep 2004 11:00:06 +0100 (BST)
Subject: [R] Problems with png()
In-Reply-To: <413C3392.1040001@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0409061057150.21322-100000@gw.env.leeds.ac.uk>

Sorry!

Tried to save the .png from both R-1.9.1 and R-1.8.0 to no avail. I am
running R-1.9.1 on SusE 9.0, and R-1.8.0 on Debian.

I have tried to view the images with Gimp and Kview (on both systems), to
no avail.

Laura Quinn
Institute of Atmospheric Science
School of the Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk

On Mon, 6 Sep 2004, Uwe Ligges wrote:

> Laura Quinn wrote:
>
> > I am trying to save a series of plots as .png files by using
> >
> > png(file="myfile.png",bg="transparent")
> > dev.off()
>
> More details please, we cannot help otherwise.
> At least version of R, operating system, and version of libpng, as well
> as the program that told you the file is corrupted ...
>
> Uwe Ligges
>
>
>
> > for each image plot I produce. Unfortunately when I have tried this I am
> > unable to open the files, and am told they are corrupted.
> >
> > I have tried to use the jpeg() function but have the same problem. The only way I have managed to
> > export a graphic successfully is as dev.copy2eps. Aside from producing
> > unwieldy files, this is also unhelpful as I at m hoping to create a movie of
> > the images via ImageMagick.
> >
> > Any suggestions?
> >
> > Thanks in advance,
> >
> > Laura Quinn
> > Institute of Atmospheric Science
> > School of the Environment
> > University of Leeds
> > Leeds
> > LS2 9JT
> >
> > tel: +44 113 343 1596
> > fax: +44 113 343 6716
> > mail: laura at env.leeds.ac.uk
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From laura at env.leeds.ac.uk  Mon Sep  6 12:05:45 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Mon, 6 Sep 2004 11:05:45 +0100 (BST)
Subject: [R] Problems with png()
In-Reply-To: <413C34A1.6070003@lancaster.ac.uk>
Message-ID: <Pine.LNX.4.44.0409061104040.21322-100000@gw.env.leeds.ac.uk>

On Mon, 6 Sep 2004, Barry Rowlingson wrote:

> Laura Quinn wrote:
> > I am trying to save a series of plots as .png files by using
> >
> > png(file="myfile.png",bg="transparent")
> > dev.off()
> >
> > for each image plot I produce. Unfortunately when I have tried this I am
> > unable to open the files, and am told they are corrupted.
> >
> > I have tried to use the jpeg() function but have the same problem. The only way I have managed to
> > export a graphic successfully is as dev.copy2eps. Aside from producing
> > unwieldy files, this is also unhelpful as I at m hoping to create a movie of
> > the images via ImageMagick.
> >
>
>   This sounds a bit obvious, but are you doing your plot commands
> _between_ the png() call and the dev.off() call?
>
>   Try:
>
>   png(file="foo.png")
>   plot(1:10)
>   dev.off()
>
>   What version/platform are you using?

Yes, I have been using the above call to no avail. I'd be suprised if my
libpng wasn't up-to-date on SuSe 9.0, but I'm not sure how to check which
version I have?

Laura


>
> Barry
>
>



From ramasamy at cancer.org.uk  Mon Sep  6 13:17:56 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 06 Sep 2004 12:17:56 +0100
Subject: [R] Problems with png()
In-Reply-To: <Pine.LNX.4.44.0409061104040.21322-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0409061104040.21322-100000@gw.env.leeds.ac.uk>
Message-ID: <1094469476.3476.50.camel@vpn202001.lif.icnet.uk>

Try running the codes on a windows machine just to rule out any
code-related errors.

Also are you running the codes interactively or in the background ?

Regards, Adai


On Mon, 2004-09-06 at 11:05, Laura Quinn wrote:
> On Mon, 6 Sep 2004, Barry Rowlingson wrote:
> 
> > Laura Quinn wrote:
> > > I am trying to save a series of plots as .png files by using
> > >
> > > png(file="myfile.png",bg="transparent")
> > > dev.off()
> > >
> > > for each image plot I produce. Unfortunately when I have tried this I am
> > > unable to open the files, and am told they are corrupted.
> > >
> > > I have tried to use the jpeg() function but have the same problem. The only way I have managed to
> > > export a graphic successfully is as dev.copy2eps. Aside from producing
> > > unwieldy files, this is also unhelpful as I at m hoping to create a movie of
> > > the images via ImageMagick.
> > >
> >
> >   This sounds a bit obvious, but are you doing your plot commands
> > _between_ the png() call and the dev.off() call?
> >
> >   Try:
> >
> >   png(file="foo.png")
> >   plot(1:10)
> >   dev.off()
> >
> >   What version/platform are you using?
> 
> Yes, I have been using the above call to no avail. I'd be suprised if my
> libpng wasn't up-to-date on SuSe 9.0, but I'm not sure how to check which
> version I have?
> 
> Laura
> 
> 
> >
> > Barry
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From thpe at hhbio.wasser.tu-dresden.de  Mon Sep  6 13:30:46 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Mon, 06 Sep 2004 13:30:46 +0200
Subject: [R] Sweave echoing comments (again)
Message-ID: <413C4A66.30008@hhbio.wasser.tu-dresden.de>

Hello,

I try to document some R scripts for my collegues and observed the 
problem, that Sweave strips comment lines away.

As a small example I write in an Rtex file:

\begin{Scode}
## a small example
test() # line comment
\end{Scode}

... the .tex file generated by Sweave only contains:

\begin{Schunk}
\begin{Sinput}
  test()
\end{Sinput}
\end{Schunk}


... and all the comments are lost. Looking into the archives, I found, 
that such a question appeared already some months ago. Are there any 
advances or workarounds doing such things today?

Thank you in advance!

Thomas P.



From laura at env.leeds.ac.uk  Mon Sep  6 14:58:00 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Mon, 6 Sep 2004 13:58:00 +0100 (BST)
Subject: [R] Problems with png()
In-Reply-To: <1094469476.3476.50.camel@vpn202001.lif.icnet.uk>
Message-ID: <Pine.LNX.4.44.0409061357050.5097-100000@env-pc-phd13>

A windows machine?? If you could suggest where I might get my hands on
one...

AFAIK I'm running the code interactively.

Laura Quinn
Institute of Atmospheric Science
School of the Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk

On Mon, 6 Sep 2004, Adaikalavan Ramasamy wrote:

> Try running the codes on a windows machine just to rule out any
> code-related errors.
>
> Also are you running the codes interactively or in the background ?
>
> Regards, Adai
>
>
> On Mon, 2004-09-06 at 11:05, Laura Quinn wrote:
> > On Mon, 6 Sep 2004, Barry Rowlingson wrote:
> >
> > > Laura Quinn wrote:
> > > > I am trying to save a series of plots as .png files by using
> > > >
> > > > png(file="myfile.png",bg="transparent")
> > > > dev.off()
> > > >
> > > > for each image plot I produce. Unfortunately when I have tried this I am
> > > > unable to open the files, and am told they are corrupted.
> > > >
> > > > I have tried to use the jpeg() function but have the same problem. The only way I have managed to
> > > > export a graphic successfully is as dev.copy2eps. Aside from producing
> > > > unwieldy files, this is also unhelpful as I at m hoping to create a movie of
> > > > the images via ImageMagick.
> > > >
> > >
> > >   This sounds a bit obvious, but are you doing your plot commands
> > > _between_ the png() call and the dev.off() call?
> > >
> > >   Try:
> > >
> > >   png(file="foo.png")
> > >   plot(1:10)
> > >   dev.off()
> > >
> > >   What version/platform are you using?
> >
> > Yes, I have been using the above call to no avail. I'd be suprised if my
> > libpng wasn't up-to-date on SuSe 9.0, but I'm not sure how to check which
> > version I have?
> >
> > Laura
> >
> >
> > >
> > > Barry
> > >
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>
>



From ym at climpact.com  Mon Sep  6 15:15:01 2004
From: ym at climpact.com (Yves Magliulo)
Date: 06 Sep 2004 15:15:01 +0200
Subject: [R] Problems with png()
In-Reply-To: <Pine.LNX.4.44.0409061357050.5097-100000@env-pc-phd13>
References: <Pine.LNX.4.44.0409061357050.5097-100000@env-pc-phd13>
Message-ID: <1094476500.12940.8.camel@new-york.climpact.net>

hi, 

here some alternative solution.

1-use postscript function then convert it in png in shell with convert
command (higher resolution)

2-use dev2bitmap(file, type = "png256") many other type available
?dev2bitmap for more info

-- 
------
Yves Magliulo <ym at climpact.com>
R&D Engineer, CLIMPACT

Tel.   : +33 (0) 1 44 27 34 31
Fax.   : +33 (0) 1 44 27 49 96 
Universite Pierre et Marie Curie
Boite 101 - Tour 45 - 5eme etage - Couloir 45/46
4 place Jussieu, 75252 Paris CEDEX 05, France
Le lun 06/09/2004 ?? 14:58, Laura Quinn a ??crit :
> A windows machine?? If you could suggest where I might get my hands on
> one...
> 
> AFAIK I'm running the code interactively.
> 
> Laura Quinn
> Institute of Atmospheric Science
> School of the Environment
> University of Leeds
> Leeds
> LS2 9JT
> 
> tel: +44 113 343 1596
> fax: +44 113 343 6716
> mail: laura at env.leeds.ac.uk
> 
> On Mon, 6 Sep 2004, Adaikalavan Ramasamy wrote:
> 
> > Try running the codes on a windows machine just to rule out any
> > code-related errors.
> >
> > Also are you running the codes interactively or in the background ?
> >
> > Regards, Adai
> >
> >
> > On Mon, 2004-09-06 at 11:05, Laura Quinn wrote:
> > > On Mon, 6 Sep 2004, Barry Rowlingson wrote:
> > >
> > > > Laura Quinn wrote:
> > > > > I am trying to save a series of plots as .png files by using
> > > > >
> > > > > png(file="myfile.png",bg="transparent")
> > > > > dev.off()
> > > > >
> > > > > for each image plot I produce. Unfortunately when I have tried this I am
> > > > > unable to open the files, and am told they are corrupted.
> > > > >
> > > > > I have tried to use the jpeg() function but have the same problem. The only way I have managed to
> > > > > export a graphic successfully is as dev.copy2eps. Aside from producing
> > > > > unwieldy files, this is also unhelpful as I at m hoping to create a movie of
> > > > > the images via ImageMagick.
> > > > >
> > > >
> > > >   This sounds a bit obvious, but are you doing your plot commands
> > > > _between_ the png() call and the dev.off() call?
> > > >
> > > >   Try:
> > > >
> > > >   png(file="foo.png")
> > > >   plot(1:10)
> > > >   dev.off()
> > > >
> > > >   What version/platform are you using?
> > >
> > > Yes, I have been using the above call to no avail. I'd be suprised if my
> > > libpng wasn't up-to-date on SuSe 9.0, but I'm not sure how to check which
> > > version I have?
> > >
> > > Laura
> > >
> > >
> > > >
> > > > Barry
> > > >
> > > >
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > >
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ahenningsen at email.uni-kiel.de  Mon Sep  6 15:28:50 2004
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Mon, 6 Sep 2004 15:28:50 +0200
Subject: [R] Problems with png()
In-Reply-To: <Pine.LNX.4.44.0409061104040.21322-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0409061104040.21322-100000@gw.env.leeds.ac.uk>
Message-ID: <200409061528.50315.ahenningsen@email.uni-kiel.de>

On Monday 06 September 2004 12:05, Laura Quinn wrote:
> On Mon, 6 Sep 2004, Barry Rowlingson wrote:
> > Laura Quinn wrote:
> > > I am trying to save a series of plots as .png files by using
> > >
> > > png(file="myfile.png",bg="transparent")
> > > dev.off()
> > >
> > > for each image plot I produce. Unfortunately when I have tried this I
> > > am unable to open the files, and am told they are corrupted.
> > >
> > > I have tried to use the jpeg() function but have the same problem. The
> > > only way I have managed to export a graphic successfully is as
> > > dev.copy2eps. Aside from producing unwieldy files, this is also
> > > unhelpful as I at m hoping to create a movie of the images via
> > > ImageMagick.
> >
> >   This sounds a bit obvious, but are you doing your plot commands
> > _between_ the png() call and the dev.off() call?
> >
> >   Try:
> >
> >   png(file="foo.png")
> >   plot(1:10)
> >   dev.off()
> >
> >   What version/platform are you using?
>
> Yes, I have been using the above call to no avail. I'd be suprised if my
> libpng wasn't up-to-date on SuSe 9.0, but I'm not sure how to check which
> version I have?

I have also SuSE 9.0 and R-1.9.1, but I have no problems with png(). Did you 
compile R from source or did you install it from a rpm file?

To figure out your version of libpng type on a console:
rpm -qa libpng*

I get:
libpng-devel-1.2.5-194
libpng-1.2.5-194

"libpng-devel" is only necessary if you compile R from source.

You may send me the file foo.png generated by Uwes code. Then, I can try to 
open it - just to eliminate the possibility that your png viewer is broken.

Best wishes,
Arne

> Laura
>
> > Barry
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From ripley at stats.ox.ac.uk  Mon Sep  6 15:47:48 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Sep 2004 14:47:48 +0100 (BST)
Subject: [R] Problems with png()
In-Reply-To: <200409061528.50315.ahenningsen@email.uni-kiel.de>
Message-ID: <Pine.LNX.4.44.0409061446350.2249-100000@gannet.stats>

On Mon, 6 Sep 2004, Arne Henningsen wrote:

> On Monday 06 September 2004 12:05, Laura Quinn wrote:
> > On Mon, 6 Sep 2004, Barry Rowlingson wrote:
> > > Laura Quinn wrote:
> > > > I am trying to save a series of plots as .png files by using
> > > >
> > > > png(file="myfile.png",bg="transparent")
> > > > dev.off()
> > > >
> > > > for each image plot I produce. Unfortunately when I have tried this I
> > > > am unable to open the files, and am told they are corrupted.
> > > >
> > > > I have tried to use the jpeg() function but have the same problem. The
> > > > only way I have managed to export a graphic successfully is as
> > > > dev.copy2eps. Aside from producing unwieldy files, this is also
> > > > unhelpful as I at m hoping to create a movie of the images via
> > > > ImageMagick.
> > >
> > >   This sounds a bit obvious, but are you doing your plot commands
> > > _between_ the png() call and the dev.off() call?
> > >
> > >   Try:
> > >
> > >   png(file="foo.png")
> > >   plot(1:10)
> > >   dev.off()
> > >
> > >   What version/platform are you using?
> >
> > Yes, I have been using the above call to no avail. I'd be suprised if my
> > libpng wasn't up-to-date on SuSe 9.0, but I'm not sure how to check which
> > version I have?
> 
> I have also SuSE 9.0 and R-1.9.1, but I have no problems with png(). Did you 
> compile R from source or did you install it from a rpm file?
> 
> To figure out your version of libpng type on a console:
> rpm -qa libpng*
> 
> I get:
> libpng-devel-1.2.5-194
> libpng-1.2.5-194

There is a security advisory on that version: you should upgrade to 1.2.6.
(It does not affect R, which only write png files.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ramasamy at cancer.org.uk  Mon Sep  6 16:50:01 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 06 Sep 2004 15:50:01 +0100
Subject: [R] substitution in expression
Message-ID: <1094482201.3665.18.camel@vpn202001.lif.icnet.uk>

I have been struggling with this problem for a while and I hope someone
could help me. Or if someone could point me to a section in the manual I
would be grateful.

 x <- "my"
 plot(1:10, main=expression(paste( x, Delta, "values" )))

Q : How do I get the title to say "my (triangle symbol) values" ?


The following trial-and-error produced mainly errors :

 plot(1:10, main=expression(paste( get(x), Delta, "values" ))) 
 plot(1:10, main=expression(paste( substitute(x), Delta, values )))
 plot(1:10, main=expression(paste( deparse(x), Delta, "values" )))
 plot(1:10, main=paste(x, expression(Delta), "values"))
 plot(1:10, main=paste(x, eval(expression(Delta)), "values"))
 plot(1:10, main=paste(x, expression(Delta, "values" )))
 plot(1:10, main=paste(x, expression(paste(Delta, "values" ))))

Many thanks.

Regards, 
-- 
Adaikalavan Ramasamy                    ramasamy at cancer.org.uk
Centre for Statistics in Medicine       http://www.ihs.ox.ac.uk/csm/
Cancer Research UK                      Tel : 01865 226 677
Old Road Campus, Headington, Oxford     Fax : 01865 226 962



From filippobiscarini at anafi.it  Mon Sep  6 16:31:34 2004
From: filippobiscarini at anafi.it (Filippo Biscarini)
Date: Mon, 6 Sep 2004 16:31:34 +0200
Subject: [R] R under Windows vs R under Unix/Linux
Message-ID: <NHBBLJIIHCNEKPHLLJMOEEBMCCAA.filippobiscarini@anafi.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040906/06d3dd72/attachment.pl

From andy_liaw at merck.com  Mon Sep  6 16:59:42 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 6 Sep 2004 10:59:42 -0400
Subject: [R] Problems with png()
Message-ID: <3A822319EB35174CA3714066D590DCD504AF831D@usrymx25.merck.com>

Another obvious thing to check:  See what capabilities() say about png
support.

Andy

> From: Laura Quinn
> 
> Sorry!
> 
> Tried to save the .png from both R-1.9.1 and R-1.8.0 to no avail. I am
> running R-1.9.1 on SusE 9.0, and R-1.8.0 on Debian.
> 
> I have tried to view the images with Gimp and Kview (on both 
> systems), to
> no avail.
> 
> Laura Quinn
> Institute of Atmospheric Science
> School of the Environment
> University of Leeds
> Leeds
> LS2 9JT
> 
> tel: +44 113 343 1596
> fax: +44 113 343 6716
> mail: laura at env.leeds.ac.uk
> 
> On Mon, 6 Sep 2004, Uwe Ligges wrote:
> 
> > Laura Quinn wrote:
> >
> > > I am trying to save a series of plots as .png files by using
> > >
> > > png(file="myfile.png",bg="transparent")
> > > dev.off()
> >
> > More details please, we cannot help otherwise.
> > At least version of R, operating system, and version of 
> libpng, as well
> > as the program that told you the file is corrupted ...
> >
> > Uwe Ligges
> >
> >
> >
> > > for each image plot I produce. Unfortunately when I have 
> tried this I am
> > > unable to open the files, and am told they are corrupted.
> > >
> > > I have tried to use the jpeg() function but have the same 
> problem. The only way I have managed to
> > > export a graphic successfully is as dev.copy2eps. Aside 
> from producing
> > > unwieldy files, this is also unhelpful as I at m hoping to 
> create a movie of
> > > the images via ImageMagick.
> > >
> > > Any suggestions?
> > >
> > > Thanks in advance,
> > >
> > > Laura Quinn
> > > Institute of Atmospheric Science
> > > School of the Environment
> > > University of Leeds
> > > Leeds
> > > LS2 9JT
> > >
> > > tel: +44 113 343 1596
> > > fax: +44 113 343 6716
> > > mail: laura at env.leeds.ac.uk
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> >
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From wolski at molgen.mpg.de  Mon Sep  6 17:01:51 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Mon, 06 Sep 2004 17:01:51 +0200
Subject: [R] substitution in expression
In-Reply-To: <1094482201.3665.18.camel@vpn202001.lif.icnet.uk>
References: <1094482201.3665.18.camel@vpn202001.lif.icnet.uk>
Message-ID: <200409061701510337.01D1B514@mail.math.fu-berlin.de>

Hi!

plot(1:10, main=expression(paste( x," ", Delta, " values" )))

/E



*********** REPLY SEPARATOR  ***********

On 9/6/2004 at 3:50 PM Adaikalavan Ramasamy wrote:

>>>I have been struggling with this problem for a while and I hope
>>>someone
>>>could help me. Or if someone could point me to a section in the manual I
>>>would be grateful.
>>>
>>> x <- "my"
>>> plot(1:10, main=expression(paste( x, Delta, "values" )))
>>>
>>>Q : How do I get the title to say "my (triangle symbol) values" ?
>>>
>>>
>>>The following trial-and-error produced mainly errors :
>>>
>>> plot(1:10, main=expression(paste( get(x), Delta, "values" ))) 
>>> plot(1:10, main=expression(paste( substitute(x), Delta, values )))
>>> plot(1:10, main=expression(paste( deparse(x), Delta, "values" )))
>>> plot(1:10, main=paste(x, expression(Delta), "values"))
>>> plot(1:10, main=paste(x, eval(expression(Delta)), "values"))
>>> plot(1:10, main=paste(x, expression(Delta, "values" )))
>>> plot(1:10, main=paste(x, expression(paste(Delta, "values" ))))
>>>
>>>Many thanks.
>>>
>>>Regards, 
>>>-- 
>>>Adaikalavan Ramasamy                    ramasamy at cancer.org.uk
>>>Centre for Statistics in Medicine       http://www.ihs.ox.ac.uk/csm/
>>>Cancer Research UK                      Tel : 01865 226 677
>>>Old Road Campus, Headington, Oxford     Fax : 01865 226 962
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin                'v'    
tel: 0049-30-83875219                        /   \       
mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
      wolski at molgen.mpg.de



From wolski at molgen.mpg.de  Mon Sep  6 17:07:19 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Mon, 06 Sep 2004 17:07:19 +0200
Subject: [R] substitution in expression
In-Reply-To: <1094482201.3665.18.camel@vpn202001.lif.icnet.uk>
References: <1094482201.3665.18.camel@vpn202001.lif.icnet.uk>
Message-ID: <200409061707190739.01D6B7E6@mail.math.fu-berlin.de>

Hi!

Sorry for the previous mail.
Take a look at parse.

?parse
x<-"my"
plot(1:10, main=parse(text=x))

Eryk.

*********** REPLY SEPARATOR  ***********

On 9/6/2004 at 3:50 PM Adaikalavan Ramasamy wrote:

>>>I have been struggling with this problem for a while and I hope
>>>someone
>>>could help me. Or if someone could point me to a section in the manual I
>>>would be grateful.
>>>
>>> x <- "my"
>>> plot(1:10, main=expression(paste( x, Delta, "values" )))
>>>
>>>Q : How do I get the title to say "my (triangle symbol) values" ?
>>>
>>>
>>>The following trial-and-error produced mainly errors :
>>>
>>> plot(1:10, main=expression(paste( get(x), Delta, "values" ))) 
>>> plot(1:10, main=expression(paste( substitute(x), Delta, values )))
>>> plot(1:10, main=expression(paste( deparse(x), Delta, "values" )))
>>> plot(1:10, main=paste(x, expression(Delta), "values"))
>>> plot(1:10, main=paste(x, eval(expression(Delta)), "values"))
>>> plot(1:10, main=paste(x, expression(Delta, "values" )))
>>> plot(1:10, main=paste(x, expression(paste(Delta, "values" ))))
>>>
>>>Many thanks.
>>>
>>>Regards, 
>>>-- 
>>>Adaikalavan Ramasamy                    ramasamy at cancer.org.uk
>>>Centre for Statistics in Medicine       http://www.ihs.ox.ac.uk/csm/
>>>Cancer Research UK                      Tel : 01865 226 677
>>>Old Road Campus, Headington, Oxford     Fax : 01865 226 962
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin                'v'    
tel: 0049-30-83875219                        /   \       
mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
      wolski at molgen.mpg.de



From ripley at stats.ox.ac.uk  Mon Sep  6 17:08:17 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Sep 2004 16:08:17 +0100 (BST)
Subject: [R] R under Windows vs R under Unix/Linux
In-Reply-To: <NHBBLJIIHCNEKPHLLJMOEEBMCCAA.filippobiscarini@anafi.it>
Message-ID: <Pine.LNX.4.44.0409061606590.19265-100000@gannet.stats>

On Mon, 6 Sep 2004, Filippo Biscarini wrote:

> I would like to know which are the main differences between R under Windos
> and R under Linux/Unix and where I can find, if something exists, some
> materials and infos on line on this topic.

In the FAQs, mentioned in the posting guide we do ask you to read:

> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From thpe at hhbio.wasser.tu-dresden.de  Mon Sep  6 17:14:37 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Mon, 06 Sep 2004 17:14:37 +0200
Subject: [R] substitution in expression
In-Reply-To: <1094482201.3665.18.camel@vpn202001.lif.icnet.uk>
References: <1094482201.3665.18.camel@vpn202001.lif.icnet.uk>
Message-ID: <413C7EDD.4070802@hhbio.wasser.tu-dresden.de>

Adaikalavan Ramasamy wrote:

 > I have been struggling with this problem for a while and I hope someone
 > could help me. Or if someone could point me to a section in the manual I
 > would be grateful.
 >
 >  x <- "my"
 >  plot(1:10, main=expression(paste( x, Delta, "values" )))

Yes, "substitution" is the correct keyword. Try the following:

  x <- "my"
  plot(1:10, main=substitute(x ~ Delta ~ "values", list(x=x)))

BTW: similar problems were explained last week.

Thomas P.



From ligges at statistik.uni-dortmund.de  Mon Sep  6 17:26:21 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 06 Sep 2004 17:26:21 +0200
Subject: [R] substitution in expression
In-Reply-To: <1094482201.3665.18.camel@vpn202001.lif.icnet.uk>
References: <1094482201.3665.18.camel@vpn202001.lif.icnet.uk>
Message-ID: <413C819D.6050901@statistik.uni-dortmund.de>

Adaikalavan Ramasamy wrote:

> I have been struggling with this problem for a while and I hope someone
> could help me. Or if someone could point me to a section in the manual I
> would be grateful.
> 
>  x <- "my"
>  plot(1:10, main=expression(paste( x, Delta, "values" )))
> 
> Q : How do I get the title to say "my (triangle symbol) values" ?


plot(1:10, main = substitute(y * " " * Delta * " values", list(y = x)))

Uwe Ligges



> 
> The following trial-and-error produced mainly errors :
> 
>  plot(1:10, main=expression(paste( get(x), Delta, "values" ))) 
>  plot(1:10, main=expression(paste( substitute(x), Delta, values )))
>  plot(1:10, main=expression(paste( deparse(x), Delta, "values" )))
>  plot(1:10, main=paste(x, expression(Delta), "values"))
>  plot(1:10, main=paste(x, eval(expression(Delta)), "values"))
>  plot(1:10, main=paste(x, expression(Delta, "values" )))
>  plot(1:10, main=paste(x, expression(paste(Delta, "values" ))))
> 
> Many thanks.
> 
> Regards,



From roym at ufl.edu  Mon Sep  6 17:26:41 2004
From: roym at ufl.edu (Manojit Roy)
Date: Mon, 6 Sep 2004 11:26:41 -0400 (EDT)
Subject: [R] A naive lsoda question....
Message-ID: <162049676.1094484401115.JavaMail.osg@osgjas01.cns.ufl.edu>

Hello,

I am an R newbie, trying to use lsoda to solve standard 
Lotka-Volterra competition equations. My question is: how do I 
pass a parameter that varies with time, like say, phix <- 0.7 + 
runif(tmax) in the example below.

# defining function
lotvol <- function(t,n,p){
    x <- n[1]; y <- n[2]
    rx <- p["rx"]; ry <- p["ry"]
    Kx <- p["Kx"]; Ky <- p["Ky"]
    phix <- p["phix"]; phiy <- p["phiy"]
    dx.dt <- rx*x*(1 - x/Kx) - phix*x*y
    dy.dt <- ry*y*(1 - y/Ky) - phiy*x*y
    list(c(dx.dt, dy.dt))
}

# running lsoda
nstart <- c(x=0.5, y=0.5)
parms <- c(rx=1, ry=1, Kx=1, Ky=1, phix=1.2, phiy=0.8)
tmax <- 100
times <- seq(0,tmax)
require(odesolve)
out <- as.data.frame(lsoda(nstart, times, lotvol, parms))

Thanks,
Manojit



From rpeng at jhsph.edu  Mon Sep  6 17:27:12 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 06 Sep 2004 11:27:12 -0400
Subject: [R] substitution in expression
In-Reply-To: <200409061701510337.01D1B514@mail.math.fu-berlin.de>
References: <1094482201.3665.18.camel@vpn202001.lif.icnet.uk>
	<200409061701510337.01D1B514@mail.math.fu-berlin.de>
Message-ID: <413C81D0.9070207@jhsph.edu>

You need substitute(), as in:

x <- "my"
plot(1:10, main = substitute(paste(x, " ", Delta, " values"), list(x = x)))

-roger

Wolski wrote:
> Hi!
> 
> plot(1:10, main=expression(paste( x," ", Delta, " values" )))
> 
> /E
> 
> 
> 
> *********** REPLY SEPARATOR  ***********
> 
> On 9/6/2004 at 3:50 PM Adaikalavan Ramasamy wrote:
> 
> 
>>>>I have been struggling with this problem for a while and I hope
>>>>someone
>>>>could help me. Or if someone could point me to a section in the manual I
>>>>would be grateful.
>>>>
>>>>x <- "my"
>>>>plot(1:10, main=expression(paste( x, Delta, "values" )))
>>>>
>>>>Q : How do I get the title to say "my (triangle symbol) values" ?
>>>>
>>>>
>>>>The following trial-and-error produced mainly errors :
>>>>
>>>>plot(1:10, main=expression(paste( get(x), Delta, "values" ))) 
>>>>plot(1:10, main=expression(paste( substitute(x), Delta, values )))
>>>>plot(1:10, main=expression(paste( deparse(x), Delta, "values" )))
>>>>plot(1:10, main=paste(x, expression(Delta), "values"))
>>>>plot(1:10, main=paste(x, eval(expression(Delta)), "values"))
>>>>plot(1:10, main=paste(x, expression(Delta, "values" )))
>>>>plot(1:10, main=paste(x, expression(paste(Delta, "values" ))))
>>>>
>>>>Many thanks.
>>>>
>>>>Regards, 
>>>>-- 
>>>>Adaikalavan Ramasamy                    ramasamy at cancer.org.uk
>>>>Centre for Statistics in Medicine       http://www.ihs.ox.ac.uk/csm/
>>>>Cancer Research UK                      Tel : 01865 226 677
>>>>Old Road Campus, Headington, Oxford     Fax : 01865 226 962
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> 
> 
> Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
> Ihnestrasse 63-73 14195 Berlin                'v'    
> tel: 0049-30-83875219                        /   \       
> mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
>       wolski at molgen.mpg.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Mon Sep  6 18:36:45 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 06 Sep 2004 17:36:45 +0100
Subject: [R] substitution in expression
In-Reply-To: <413C81D0.9070207@jhsph.edu>
References: <1094482201.3665.18.camel@vpn202001.lif.icnet.uk>
	<200409061701510337.01D1B514@mail.math.fu-berlin.de>
	<413C81D0.9070207@jhsph.edu>
Message-ID: <1094488605.3816.3.camel@vpn202001.lif.icnet.uk>

Thank you all especially to Wolski, Roger Peng, Thomas Petzoldt and Uwe
Ligges !

Substitute with listing the environment was exactly what I needed.


On Mon, 2004-09-06 at 16:27, Roger D. Peng wrote:
> You need substitute(), as in:
> 
> x <- "my"
> plot(1:10, main = substitute(paste(x, " ", Delta, " values"), list(x = x)))
> 
> -roger
> 
> Wolski wrote:
> > Hi!
> > 
> > plot(1:10, main=expression(paste( x," ", Delta, " values" )))
> > 
> > /E
> > 
> > 
> > 
> > *********** REPLY SEPARATOR  ***********
> > 
> > On 9/6/2004 at 3:50 PM Adaikalavan Ramasamy wrote:
> > 
> > 
> >>>>I have been struggling with this problem for a while and I hope
> >>>>someone
> >>>>could help me. Or if someone could point me to a section in the manual I
> >>>>would be grateful.
> >>>>
> >>>>x <- "my"
> >>>>plot(1:10, main=expression(paste( x, Delta, "values" )))
> >>>>
> >>>>Q : How do I get the title to say "my (triangle symbol) values" ?
> >>>>
> >>>>
> >>>>The following trial-and-error produced mainly errors :
> >>>>
> >>>>plot(1:10, main=expression(paste( get(x), Delta, "values" ))) 
> >>>>plot(1:10, main=expression(paste( substitute(x), Delta, values )))
> >>>>plot(1:10, main=expression(paste( deparse(x), Delta, "values" )))
> >>>>plot(1:10, main=paste(x, expression(Delta), "values"))
> >>>>plot(1:10, main=paste(x, eval(expression(Delta)), "values"))
> >>>>plot(1:10, main=paste(x, expression(Delta, "values" )))
> >>>>plot(1:10, main=paste(x, expression(paste(Delta, "values" ))))
> >>>>
> >>>>Many thanks.
> >>>>
> >>>>Regards, 
> >>>>-- 
> >>>>Adaikalavan Ramasamy                    ramasamy at cancer.org.uk
> >>>>Centre for Statistics in Medicine       http://www.ihs.ox.ac.uk/csm/
> >>>>Cancer Research UK                      Tel : 01865 226 677
> >>>>Old Road Campus, Headington, Oxford     Fax : 01865 226 962
> >>>>
> >>>>______________________________________________
> >>>>R-help at stat.math.ethz.ch mailing list
> >>>>https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > 
> > 
> > 
> > 
> > Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
> > Ihnestrasse 63-73 14195 Berlin                'v'    
> > tel: 0049-30-83875219                        /   \       
> > mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski
> >       wolski at molgen.mpg.de
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > 
>



From vantini at mate.polimi.it  Mon Sep  6 20:20:57 2004
From: vantini at mate.polimi.it (Simone Vantini)
Date: Mon, 6 Sep 2004 20:20:57 +0200 (CEST)
Subject: [R] How to personalize the rpart function: t.default(x)
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF82F3@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF82F3@usrymx25.merck.com>
Message-ID: <42918.81.208.60.192.1094494857.squirrel@webmail.mate.polimi.it>

>Thanks a lot!I've found that the matrix argument of the function
>t.default() is init$y. I thought that y and x were the response and the
>predective variables of the data of the node, isn't it?
On top of what Rolf had said, traceback() would help tracking down how
> the error happened.
>
> Andy
>
>> From: Rolf Turner
>>
>> t is for transpose; look at ?t, ?t.default,
>> ?t.data.frame
>>
>> Bottom line:  Somewhere in your code you are trying to transpose
>> something that is not a matrix.  (Or you are passing to an existing
>> function an object which that function expects to be a matrix, but
>> isn't.)
>>
>> 			cheers,
>>
>> 				Rolf Turner
>> 				rolf at math.unb.ca
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>>
>
>
> ------------------------------------------------------------------------------> Notice:  This e-mail message, together with any attachments, contains
> information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station,
> New Jersey, USA 08889), and/or its affiliates (which may be known
> outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD
> and in Japan, as Banyu) that may be confidential, proprietary
> copyrighted and/or legally privileged. It is intended solely for the
> use of the individual or entity named on this message.  If you are not
> the intended recipient, and have received this message in error, please
> notify us immediately by reply e-mail and then delete it from your
> system.
> ------------------------------------------------------------------------------



From vantini at mate.polimi.it  Mon Sep  6 20:21:56 2004
From: vantini at mate.polimi.it (Simone Vantini)
Date: Mon, 6 Sep 2004 20:21:56 +0200 (CEST)
Subject: [R] How to personalize the rpart function: t.default(x)
In-Reply-To: <Pine.LNX.4.44.0409020723390.29759-100000@gannet.stats>
References: <25441.81.208.60.192.1094079523.squirrel@webmail.mate.polimi.it>
	<Pine.LNX.4.44.0409020723390.29759-100000@gannet.stats>
Message-ID: <49008.81.208.60.192.1094494916.squirrel@webmail.mate.polimi.it>

> Thanks a lot!I've found that the matrix argument of the function
> t.default() is init$y. I thought that y and x were the response and the
> predective variables of the data of the node, isn't it?
On Thu, 2 Sep 2004, Simone Vantini wrote:
>
>> I'm trying to personalize the rpart function by introducing a
>> list('init','split','eval') in the argument method. But I receive an
>> error message:"Error in t.default(x): argument is not a matrix".
>> Can anyone tell me what the argument of this function is or where this
>> function appears in the rpart function.Thanks Simone Vantini
>
> t.default is the default method for the transpose function t() in R
> itself.
>
> Try help!
>
> Description:
>
>     Given a matrix or 'data.frame' 'x', 't' returns the transpose of
>     'x'.
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gavin.simpson at ucl.ac.uk  Mon Sep  6 20:18:49 2004
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 06 Sep 2004 19:18:49 +0100
Subject: [R] Error when running configure on xeon with r-1-9-patched
Message-ID: <413CAA09.3070409@ucl.ac.uk>

Dear list,

I'm having a problem configuring R-1-9-patched on a Intel Xeon machine 
running Fedora Core 2. I used svn to checkout the source, altered 
config.site to add some optimisation flags to match the Fedora rpm on 
CRAN (the flags work fine on two other P3 or P4 machines I've compiled R 
on).

./configure fails with:

<snip>
checking for long double... yes
checking size of long double... 12
checking whether we can compute C Make dependencies... yes, using gcc -MM
checking whether gcc supports -c -o FILE.lo... yes
checking how to get verbose linking output from g77... -v
checking for Fortran libraries of g77...  -L/usr/local/lib 
-L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3 
-L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../.. -lfrtbegin -lg2c -lm 
-lgcc_s -lieee
checking for dummy main to link with Fortran libraries... unknown
configure: error: linking to Fortran libraries from C fails
See `config.log' for more details.

I think this is the relevant part of the log, but I heavn't copied the 
lengthy section on the variables etc that come at the end of the 
config.log file:

| #define SIZEOF_INT 4
| #define INT_32_BITS 1
| #define SIZEOF_LONG 4
| #define SIZEOF_LONG_LONG 8
| #define SIZEOF_LONG_DOUBLE 12
| /* end confdefs.h.  */
| #define F77_DUMMY_MAIN _main
| #ifdef F77_DUMMY_MAIN
|
| #  ifdef __cplusplus
|      extern "C"
| #  endif
|    int F77_DUMMY_MAIN() { return 1; }
|
| #endif
| int
| main ()
| {
|
|   ;
|   return 0;
| }
configure:25321: result: unknown
configure:25341: error: linking to Fortran libraries from C fails
See `config.log' for more details.

I guess I missed some software package or something - although I checked 
that I had all the dependancies list for the Fedora 2 rpm. As I don't 
really understand the specifics of what has gone wrong here could 
someone enlighten me as to my mistake?

Many thanks in advance,

Gavin

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From petzoldt at rcs.urz.tu-dresden.de  Mon Sep  6 21:08:26 2004
From: petzoldt at rcs.urz.tu-dresden.de (Thomas Petzoldt)
Date: Mon, 06 Sep 2004 21:08:26 +0200
Subject: [R] A naive lsoda question....
In-Reply-To: <162049676.1094484401115.JavaMail.osg@osgjas01.cns.ufl.edu>
References: <162049676.1094484401115.JavaMail.osg@osgjas01.cns.ufl.edu>
Message-ID: <413CB5AA.1040803@rcs.urz.tu-dresden.de>

Manojit Roy wrote:
> Hello,
> 
> I am an R newbie, trying to use lsoda to solve standard Lotka-Volterra 
> competition equations. My question is: how do I pass a parameter that 
> varies with time, like say, phix <- 0.7 + runif(tmax) in the example below.

Hello,

the simplest and most pragmatic way to implement such non-autonomous 
systems is to define a global variable, e.g. phix.t and to refer to it 
in the model function via its index (see below) or via approx. If you 
want a more sophisticated solution, don't hesitate to ask me again.

Hope it helps

Thomas P.



lotvol <- function(t,n,p){
    x <- n[1]; y <- n[2]
    rx <- p["rx"]; ry <- p["ry"]
    Kx <- p["Kx"]; Ky <- p["Ky"]

    phix <- phix.t[floor(t+1)]

    phiy <- p["phiy"]

    dx.dt <- rx*x*(1 - x/Kx) - phix*x*y
    dy.dt <- ry*y*(1 - y/Ky) - phiy*x*y
    list(c(dx.dt, dy.dt))
}

# running lsoda
nstart <- c(x=0.5, y=0.5)
parms <- c(rx=1, ry=1, Kx=1, Ky=1, phix=1.2, phiy=0.8)
tmax <- 100
times <- seq(0, tmax)

phix.t <- 0.7 + runif(tmax)

require(odesolve)
out <- as.data.frame(lsoda(nstart, times, lotvol, parms))



From ripley at stats.ox.ac.uk  Mon Sep  6 22:50:46 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Sep 2004 21:50:46 +0100 (BST)
Subject: [R] rpart problem
In-Reply-To: <4124B98A000A0D7F@mk-cpfrontend-3.mail.uk.tiscali.com>
Message-ID: <Pine.LNX.4.44.0409062147410.19583-100000@gannet.stats>

I think you are confusing the purpose of rpart, which is prediction.
You want to predict `mysuccess'.

One group has 90% success, so the best prediction is `success'.
The other group has 60% success, so the best prediction is `success'.

So there is no point in splitting into groups.  Replace 60% by 30% and the 
best prediction for group 2 changes.

If this is not now obvious, please read up on tree-based methods.

On Mon, 6 Sep 2004 pfm401 at lineone.net wrote:

> Dear all,
> 
> I am having some trouble with getting the rpart function to work as expected.
> I am trying to use rpart to combine levels of a factor to reduce the number
> of levels of that factor. In exploring the code I have noticed that it is
> possible for chisq.test to return a statistically significant result whilst
> the rpart method returns only the root node (i.e. no split is made). The
> following code recreates the issue using simulated data :
> 
> 
> # Create a 2 level factor with group 1 probability of success 90% and group
> 2 60%
> tmp1  <- as.factor((runif (1000) <= 0.9))
> tmp2  <- as.factor((runif (1000) <= 0.5))

Is 0.5 a typo?

> mysuccess <- as.factor(c(tmp1, tmp2)) 
> mygroup   <- as.factor(c(rep (1,1000), rep (2,1000)))
> 
> table (mysuccess, mygroup)
> chisq.test (mysuccess, mygroup)
> # p-value = < 2.2e-16
> 
> myrpart <- rpart (mysuccess ~ mygroup)
> myrpart
> # rpart does not provide splits !!
> 
> 
> 
> If I change the parameter in the setting of group 2 to 0.3 from 0.6 rpart
> does return splits, i.e. change the line 
> 
> tmp2  <- as.factor((runif (1000) <= 0.6))
> 
> to 
> 
> tmp2  <- as.factor((runif (1000) <= 0.3))
> 
> rpart does split the nodes, but as the split with 0.6 is highly significant
> I would still have expected a split in this case too.
> 
>  
> I would appreciate any advice as to whether this is a known feature of rpart,
> whether I need to change the way my data are stored, or set some of the
> control options. I have tested a few of these options with no success.

Testing cp < 0 will have an effect.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Sep  6 22:55:23 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Sep 2004 21:55:23 +0100 (BST)
Subject: [R] Error when running configure on xeon with r-1-9-patched
In-Reply-To: <413CAA09.3070409@ucl.ac.uk>
Message-ID: <Pine.LNX.4.44.0409062152110.19583-100000@gannet.stats>

Is libg2c.so in your library path?  That's one common problem.

On Mon, 6 Sep 2004, Gavin Simpson wrote:

> Dear list,
> 
> I'm having a problem configuring R-1-9-patched on a Intel Xeon machine 
> running Fedora Core 2. I used svn to checkout the source, altered 
> config.site to add some optimisation flags to match the Fedora rpm on 
> CRAN (the flags work fine on two other P3 or P4 machines I've compiled R 
> on).

(Configure does not know about P3 vs P4 vs Xeon.)

> ./configure fails with:
> 
> <snip>
> checking for long double... yes
> checking size of long double... 12
> checking whether we can compute C Make dependencies... yes, using gcc -MM
> checking whether gcc supports -c -o FILE.lo... yes
> checking how to get verbose linking output from g77... -v
> checking for Fortran libraries of g77...  -L/usr/local/lib 
> -L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3 
> -L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../.. -lfrtbegin -lg2c -lm 
> -lgcc_s -lieee
> checking for dummy main to link with Fortran libraries... unknown
> configure: error: linking to Fortran libraries from C fails
> See `config.log' for more details.
> 
> I think this is the relevant part of the log, but I heavn't copied the 
> lengthy section on the variables etc that come at the end of the 
> config.log file:

The bit above on how this was linked may be relevant.


> | #define SIZEOF_INT 4
> | #define INT_32_BITS 1
> | #define SIZEOF_LONG 4
> | #define SIZEOF_LONG_LONG 8
> | #define SIZEOF_LONG_DOUBLE 12
> | /* end confdefs.h.  */
> | #define F77_DUMMY_MAIN _main
> | #ifdef F77_DUMMY_MAIN
> |
> | #  ifdef __cplusplus
> |      extern "C"
> | #  endif
> |    int F77_DUMMY_MAIN() { return 1; }
> |
> | #endif
> | int
> | main ()
> | {
> |
> |   ;
> |   return 0;
> | }
> configure:25321: result: unknown
> configure:25341: error: linking to Fortran libraries from C fails
> See `config.log' for more details.
> 
> I guess I missed some software package or something - although I checked 
> that I had all the dependancies list for the Fedora 2 rpm. As I don't 
> really understand the specifics of what has gone wrong here could 
> someone enlighten me as to my mistake?
> 
> Many thanks in advance,
> 
> Gavin
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jz7 at duke.edu  Mon Sep  6 23:54:03 2004
From: jz7 at duke.edu (jz7@duke.edu)
Date: Mon, 6 Sep 2004 17:54:03 -0400 (EDT)
Subject: [R] how to add error bar to the data in R?
Message-ID: <Pine.GSO.4.58.0409061750550.214@godzilla.acpub.duke.edu>

Dear all,

Does anyone knwo how to add error bar to the data point in a simple
xyplot? Right now, I have a .dat file including both the data points and
their standard deviation and read it in R. I tried function arrows(). But
it didn't gave me any arrows.

Thanks for the help!

Jeny



From matmsh at yahoo.com  Tue Sep  7 00:11:03 2004
From: matmsh at yahoo.com (=?iso-8859-1?q?Shing=20Hing=20Man?=)
Date: Mon, 6 Sep 2004 23:11:03 +0100 (BST)
Subject: [R] How the residuals are calculated in a fitted ARCH(1) model.
Message-ID: <20040906221103.38075.qmail@web52405.mail.yahoo.com>

I have used garch in package tseries to fit an ARCH(1)
model
   X_{t} = sigma_{t} e_{t}, where e_{t} ~ N(0,1)
   sigma_{t}^2 = b0 + b1*X_{t-1}^2 
 
to a set of data.


Can anyone please tell me  how the residuals are
calculated.
At first I thought the residuals are the usual
residuals
when  we do linear regression X_{t}^2 on X_{t-1}^2.  

Thanks in advance for your assistance !




=====
Home page :
  http://uk.geocities.com/matmsh/index.html



From ggrothendieck at myway.com  Tue Sep  7 00:20:26 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 6 Sep 2004 22:20:26 +0000 (UTC)
Subject: [R] how to add error bar to the data in R?
References: <Pine.GSO.4.58.0409061750550.214@godzilla.acpub.duke.edu>
Message-ID: <loom.20040907T001851-321@post.gmane.org>

 <jz7 <at> duke.edu> writes:

: Does anyone knwo how to add error bar to the data point in a simple
: xyplot? Right now, I have a .dat file including both the data points and
: their standard deviation and read it in R. I tried function arrows(). But
: it didn't gave me any arrows.

See errbar in package Hmisc and plotCI in package gregmisc.



From deepayan at stat.wisc.edu  Tue Sep  7 01:02:04 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Mon, 6 Sep 2004 18:02:04 -0500
Subject: [R] how to add error bar to the data in R?
In-Reply-To: <Pine.GSO.4.58.0409061750550.214@godzilla.acpub.duke.edu>
References: <Pine.GSO.4.58.0409061750550.214@godzilla.acpub.duke.edu>
Message-ID: <200409061802.04080.deepayan@stat.wisc.edu>

On Monday 06 September 2004 16:54, jz7 at duke.edu wrote:
> Dear all,
>
> Does anyone knwo how to add error bar to the data point in a simple
> xyplot? Right now, I have a .dat file including both the data points
> and their standard deviation and read it in R. I tried function
> arrows(). But it didn't gave me any arrows.

If you are talking about xyplot in the lattice package, you need to use 
larrows instead of arrows. e.g. your call might look like

xyplot(y ~ x, data, sd = data$sd,
       panel = function(x, y, subscripts, sd, ...) {
           larrows(x, y - 2 * sd[subscripts],
                   x, y + 2 * sd[subscripts],
                   angle = 90, code = 3, ...)
           panel.xyplot(x, y, ...)
       })

Alternatively, you could use xYplot in the Hmisc package.

Deepayan



From mentus at gmx.de  Tue Sep  7 05:01:49 2004
From: mentus at gmx.de (Fernando Henrique Ferraz P. da Rosa)
Date: Tue, 7 Sep 2004 00:01:49 -0300
Subject: [R] Contrast matrices for nested factors
Message-ID: <20040907030149.GA25350@ime.usp.br>

        Hi, I'd like to know if it's possible to specify different
contrast matrices in lm() for a factor that is nested within another one. This
is useful when we have a model where the nested factor has a different
number of levels, depending on the main factor.

        Let me illustrate with an example to make it clearer. Consider
the following data set:

        set.seed(1)
        y <- rnorm(14)
        a <- factor(c(rep(1,7),rep(2,3),rep(3,4)))
        b <- factor(c(1,1,1,2,2,3,3,1,1,2,1,1,2,2))
        k <- factor(c(1,2,3,1,2,1,2,1,2,1,1,2,1,2))
        internal <- data.frame(y,a,b,k)

        Where y is an arbitrary response, a is a main factor, b is a
factor nested within a, and k is the replicate number. It is easy to see
that depending on the level of a, b has different numbers of levels. For
instance, when a = 1, we have that b might assume values 1, 2 or 3,
while a = 2 or 3, b might assume only 1 or 2.

        I'd like then to use contrasts summing to 0, so I issue:

        z <- lm(y ~ a + a/b,data=internal,contrasts=list(a=contr.sum,
b=contr.sum))

        The problem is, the design matrix is not quite what I expected.
What happens is, instead of using a different contrast matrix for each
level of a where b is nested, it's using the same contrast matrix for
every b, namely:

        > contr.sum(3)
  [,1] [,2]
1    1    0
2    0    1
3   -1   -1

        So, when a=1, the columns of the design matrix are as expected.
It sums to 0, because there are levels of b 1, 2 and 3, when a=1. But,
when a=2 or a=3, the same contrast matrix is being used, and then, the
factor effects do not sum to 0. That's obviously because there are no
 values for b equal 3, when a != 1, and then the coding that gets done is
 '0' or '1'.

        The design matrix lm() is creating is:

> model.matrix(z)
   (Intercept) a1 a2 a1:b1 a2:b1 a3:b1 a1:b2 a2:b2 a3:b2
1            1  1  0     1     0     0     0     0     0
2            1  1  0     1     0     0     0     0     0
3            1  1  0     1     0     0     0     0     0
4            1  1  0     0     0     0     1     0     0
5            1  1  0     0     0     0     1     0     0
6            1  1  0    -1     0     0    -1     0     0
7            1  1  0    -1     0     0    -1     0     0
8            1  0  1     0     1     0     0     0     0
9            1  0  1     0     1     0     0     0     0
10           1  0  1     0     0     0     0     1     0
11           1 -1 -1     0     0     1     0     0     0
12           1 -1 -1     0     0     1     0     0     0
13           1 -1 -1     0     0     0     0     0     1
14           1 -1 -1     0     0     0     0     0     1


        What I would like to use is:

   (Intercept) a1 a2 a1:b1 a2:b1 a3:b1 a1:b2    
1            1  1  0     1     0     0     0 0 0
2            1  1  0     1     0     0     0 0 0
3            1  1  0     1     0     0     0 0 0
4            1  1  0     0     0     0     1 0 0
5            1  1  0     0     0     0     1 0 0
6            1  1  0    -1     0     0    -1 0 0
7            1  1  0    -1     0     0    -1 0 0
8            1  0  1     0     1     0     0 0 0
9            1  0  1     0     1     0     0 0 0
10           1  0  1     0    -1     0     0 0 0
11           1 -1 -1     0     0     1     0 0 0
12           1 -1 -1     0     0     1     0 0 0
13           1 -1 -1     0     0    -1     0 0 0
14           1 -1 -1     0     0    -1     0 0 0

        (notice that in the second matrix all collumns sum to 0, in the
first they don't).


        Thank you,

--
Fernando Henrique Ferraz P. da Rosa
http://www.ime.usp.br/~feferraz



From plummer at iarc.fr  Tue Sep  7 10:31:31 2004
From: plummer at iarc.fr (Martyn Plummer)
Date: Tue, 07 Sep 2004 10:31:31 +0200
Subject: [R] Error when running configure on xeon with r-1-9-patched
In-Reply-To: <413CAA09.3070409@ucl.ac.uk>
References: <413CAA09.3070409@ucl.ac.uk>
Message-ID: <1094545890.2837.2.camel@nemo>

On Mon, 2004-09-06 at 20:18, Gavin Simpson wrote:
> Dear list,
> 
> I'm having a problem configuring R-1-9-patched on a Intel Xeon machine 
> running Fedora Core 2. I used svn to checkout the source, altered 
> config.site to add some optimisation flags to match the Fedora rpm on 
> CRAN (the flags work fine on two other P3 or P4 machines I've compiled R 
> on).
> 
> ./configure fails with:
> 
> <snip>
> checking for long double... yes
> checking size of long double... 12
> checking whether we can compute C Make dependencies... yes, using gcc -MM
> checking whether gcc supports -c -o FILE.lo... yes
> checking how to get verbose linking output from g77... -v
> checking for Fortran libraries of g77...  -L/usr/local/lib 
> -L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3 
> -L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../.. -lfrtbegin -lg2c -lm 
> -lgcc_s -lieee
> checking for dummy main to link with Fortran libraries... unknown
> configure: error: linking to Fortran libraries from C fails
> See `config.log' for more details.
> 
> I think this is the relevant part of the log, but I heavn't copied the 
> lengthy section on the variables etc that come at the end of the 
> config.log file:
> 
> | #define SIZEOF_INT 4
> | #define INT_32_BITS 1
> | #define SIZEOF_LONG 4
> | #define SIZEOF_LONG_LONG 8
> | #define SIZEOF_LONG_DOUBLE 12
> | /* end confdefs.h.  */
> | #define F77_DUMMY_MAIN _main
> | #ifdef F77_DUMMY_MAIN
> |
> | #  ifdef __cplusplus
> |      extern "C"
> | #  endif
> |    int F77_DUMMY_MAIN() { return 1; }
> |
> | #endif
> | int
> | main ()
> | {
> |
> |   ;
> |   return 0;
> | }
> configure:25321: result: unknown
> configure:25341: error: linking to Fortran libraries from C fails
> See `config.log' for more details.
> 
> I guess I missed some software package or something - although I checked 
> that I had all the dependancies list for the Fedora 2 rpm. As I don't 
> really understand the specifics of what has gone wrong here could 
> someone enlighten me as to my mistake?

If you are building R, you need not just the dependencies of the RPM,
but all the packages listed under BuildRequires in the spec file, namely

gcc-c++, gcc-g77, tetex-latex, texinfo, tcl, tk
libpng-devel, libjpeg-devel, readline-devel
XFree86-devel libtermcap-devel
tcl-devel tk-devel

Make sure you have these installed.
Martyn



From mrufino at ipimar.ualg.pt  Tue Sep  7 11:08:07 2004
From: mrufino at ipimar.ualg.pt (Marta Rufino)
Date: Tue, 7 Sep 2004 10:08:07 +0100
Subject: [R] how to add error bar to the data in R?
References: <Pine.GSO.4.58.0409061750550.214@godzilla.acpub.duke.edu>
Message-ID: <002101c494ba$30f88dc0$0b1a0e0a@PORTATILMARTA>


Hello,

Use the function xYplot from hmisc package
cheers,
Marta



From rksh at soc.soton.ac.uk  Tue Sep  7 11:17:21 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Tue, 7 Sep 2004 10:17:21 +0100
Subject: [R] noncommutative addition: NA+NaN != NaN+NA
Message-ID: <a06002006bd632c519514@[139.166.242.29]>


Hi guys.

Check this out:

>  NaN +NA
[1] NaN
>  NA + NaN
[1] NA

I thought "+" was commutative by definition.   What's going on?

>  R.version
          _
platform powerpc-apple-darwin6.8
arch     powerpc
os       darwin6.8
system   powerpc, darwin6.8
status
major    1
minor    9.0
year     2004
month    04
day      12
language R
>

(Both give NA under linux, so it looks like a version-specific issue).


-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From ripley at stats.ox.ac.uk  Tue Sep  7 11:47:50 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 7 Sep 2004 10:47:50 +0100 (BST)
Subject: [R] noncommutative addition: NA+NaN != NaN+NA
In-Reply-To: <a06002006bd632c519514@[139.166.242.29]>
Message-ID: <Pine.LNX.4.44.0409071041090.11956-100000@gannet.stats>

On Tue, 7 Sep 2004, Robin Hankin wrote:

> Check this out:

I am unable to reproduce it on any of the 7 different systems I checked
(Solaris, Linux, Windows with various compilers).

> >  NaN +NA
> [1] NaN
> >  NA + NaN
> [1] NA
> 
> I thought "+" was commutative by definition.   What's going on?

It is clearly not under your compiler/OS.  We could add a configure test 
for broken systems and fix it in arithmetic.c but it hardly seems 
worthwhile.

> >  R.version
>           _
> platform powerpc-apple-darwin6.8
> arch     powerpc
> os       darwin6.8
> system   powerpc, darwin6.8
> status
> major    1
> minor    9.0
> year     2004
> month    04
> day      12
> language R
> >
> 
> (Both give NA under linux, so it looks like a version-specific issue).

Linux on that hardware?  It might be a chip issue.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jarioksa at sun3.oulu.fi  Tue Sep  7 12:28:11 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 07 Sep 2004 13:28:11 +0300
Subject: [R] noncommutative addition: NA+NaN != NaN+NA
In-Reply-To: <Pine.LNX.4.44.0409071041090.11956-100000@gannet.stats>
References: <Pine.LNX.4.44.0409071041090.11956-100000@gannet.stats>
Message-ID: <1094552890.6039.11.camel@biol102145.oulu.fi>

On Tue, 2004-09-07 at 12:47, Prof Brian Ripley wrote:
> On Tue, 7 Sep 2004, Robin Hankin wrote:
> 
> > Check this out:
> 
> I am unable to reproduce it on any of the 7 different systems I checked
> (Solaris, Linux, Windows with various compilers).
> 
> > >  NaN +NA
> > [1] NaN
> > >  NA + NaN
> > [1] NA
> > 
> > I thought "+" was commutative by definition.   What's going on?
> 
> > platform powerpc-apple-darwin6.8
> > arch     powerpc
> > os       darwin6.8
> > system   powerpc, darwin6.8
> > status
> > (Both give NA under linux, so it looks like a version-specific issue).
> 
> Linux on that hardware?  It might be a chip issue.

I tried this in Linux on Mac iBook G4, and the results were the same:
NaN+NA was NaN, just like in MacOS X version.  So it looks like a "chip
issue". However, the RPM built from the src.rpm packages at CRAN failed
in some checks in Linux/iBook. 

cheers, jari oksanen
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From rksh at soc.soton.ac.uk  Tue Sep  7 12:29:51 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Tue, 7 Sep 2004 11:29:51 +0100
Subject: [R] noncommutative addition: NA+NaN != NaN+NA
In-Reply-To: <Pine.LNX.4.44.0409071041090.11956-100000@gannet.stats>
References: <Pine.LNX.4.44.0409071041090.11956-100000@gannet.stats>
Message-ID: <a06002008bd633c13468e@[139.166.242.29]>

Dear Professor Ripley

thank you for your reply.

>
>>  >  NaN +NA
>>  [1] NaN
>>  >  NA + NaN
>>  [1] NA
>>
>>  I thought "+" was commutative by definition.   What's going on?
>
>It is clearly not under your compiler/OS.  We could add a configure test
>for broken systems and fix it in arithmetic.c but it hardly seems
>worthwhile.

[snip]

>  > (Both give NA under linux, so it looks like a version-specific issue).
>
>Linux on that hardware?  It might be a chip issue.


Sorry, that should read "Both give NA under linux on an i686 system, 
RedHat Linux 2.4.18"

In any event, "+" appears to be associative (which is what I was 
interested in).

best wishes

rksh


-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From gavin.simpson at ucl.ac.uk  Tue Sep  7 13:29:04 2004
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 07 Sep 2004 12:29:04 +0100
Subject: [R] Error when running configure on xeon with r-1-9-patched
In-Reply-To: <Pine.LNX.4.44.0409062152110.19583-100000@gannet.stats>
References: <Pine.LNX.4.44.0409062152110.19583-100000@gannet.stats>
Message-ID: <413D9B80.5060508@ucl.ac.uk>

Prof Brian Ripley wrote:
> Is libg2c.so in your library path?  That's one common problem.

Many thanks for your reply Prof. Ripley. How can I check what my library 
path is?

cat /etc/ld.so.conf gives

include ld.so.conf.d/*.conf
/usr/X11R6/lib
/usr/lib/qt-3.3/lib
/usr/local/lib

and I don't have LD_LIBRARY_PATH set. libg2c.so is in 
/usr/lib/gcc-lib/i386-redhat-linux/3.3.3 and libg2c.so.0 and 
libg2c.so.0.0.0 both link from /usr/lib to libg2c.so in 
/usr/lib/gcc-lib/i386-redhat-linux/3.3.3. This is the same setup as the 
other Fedora boxes I have compiled R on.

> On Mon, 6 Sep 2004, Gavin Simpson wrote:
> 
> 
>>Dear list,
>>
>>I'm having a problem configuring R-1-9-patched on a Intel Xeon machine 
>>running Fedora Core 2. I used svn to checkout the source, altered 
>>config.site to add some optimisation flags to match the Fedora rpm on 
>>CRAN (the flags work fine on two other P3 or P4 machines I've compiled R 
>>on).
> 
> 
> (Configure does not know about P3 vs P4 vs Xeon.)
> 
<snip>

The full section of the config log relating to this error is appended below.

Many thanks,

Gavin

##excerpt from config.log##

configure:25282: gcc -o conftest -D__NO_MATH_INLINES -mieee-fp -O2 -g 
-pipe -march=i386 -mcpu=i686 -I/usr/local/include -L/usr/local/lib 
conftest.c -lreadline -ldl -lncurses -lm   -L/usr/local/lib 
-L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3 
-L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../.. -lfrtbegin -lg2c -lm 
-lgcc_s -lieee >&5
/usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../../libieee.a(.data+0x0): 
multiple definition of `_LIB_VERSION'
/usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../../libieee.a(.data+0x0): 
first defined here
collect2: ld returned 1 exit status
configure:25288: $? = 1
configure: failed program was:
| /* confdefs.h.  */
|
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "1.9.1"
| #define PACKAGE_STRING "R 1.9.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "1.9.1"
| #define R_PLATFORM "i686-pc-linux-gnu"
| #define R_CPU "i686"
| #define R_VENDOR "pc"
| #define R_OS "linux-gnu"
| #define Unix 1
| #ifdef __cplusplus
| extern "C" void std::exit (int) throw (); using std::exit;
| #endif
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_DLFCN_H 1
| #define HAVE_LIBM 1
| #define HAVE_LIBNCURSES 1
| #define HAVE_LIBDL 1
| #define HAVE_LIBREADLINE 1
| #define STDC_HEADERS 1
| #define TIME_WITH_SYS_TIME 1
| #define HAVE_DIRENT_H 1
| #define HAVE_SYS_WAIT_H 1
| #define HAVE_ARPA_INET_H 1
| #define HAVE_DLFCN_H 1
| #define HAVE_ELF_H 1
| #define HAVE_FCNTL_H 1
| #define HAVE_FPU_CONTROL_H 1
| #define HAVE_GRP_H 1
| #define HAVE_IEEE754_H 1
| #define HAVE_LOCALE_H 1
| #define HAVE_NETDB_H 1
| #define HAVE_NETINET_IN_H 1
| #define HAVE_PWD_H 1
| #define HAVE_READLINE_HISTORY_H 1
| #define HAVE_READLINE_READLINE_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_SYS_PARAM_H 1
| #define HAVE_SYS_SELECT_H 1
| #define HAVE_SYS_SOCKET_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_SYS_TIME_H 1
| #define HAVE_SYS_TIMES_H 1
| #define HAVE_SYS_UTSNAME_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE_WCHAR_H 1
| #define HAVE_ERRNO_H 1
| #define HAVE_STDARG_H 1
| #define HAVE_STRING_H 1
| #define HAVE_POSIX_SETJMP 1
| #define HAVE_GLIBC2 1
| #define RETSIGTYPE void
| #define SOCKLEN_T socklen_t
| #define SIZEOF_INT 4
| #define INT_32_BITS 1
| #define SIZEOF_LONG 4
| #define SIZEOF_LONG_LONG 8
| #define SIZEOF_LONG_DOUBLE 12
| /* end confdefs.h.  */
| #define F77_DUMMY_MAIN _main
| #ifdef F77_DUMMY_MAIN
|
| #  ifdef __cplusplus
|      extern "C"
| #  endif
|    int F77_DUMMY_MAIN() { return 1; }
|
| #endif
| int
| main ()
| {
|
|   ;
|   return 0;
| }
configure:25321: result: unknown
configure:25341: error: linking to Fortran libraries from C fails
See `config.log' for more details.

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From p.dalgaard at biostat.ku.dk  Tue Sep  7 13:45:15 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 07 Sep 2004 13:45:15 +0200
Subject: [R] noncommutative addition: NA+NaN != NaN+NA
In-Reply-To: <a06002008bd633c13468e@[139.166.242.29]>
References: <Pine.LNX.4.44.0409071041090.11956-100000@gannet.stats>
	<a06002008bd633c13468e@[139.166.242.29]>
Message-ID: <x2fz5u716c.fsf@biostat.ku.dk>

Robin Hankin <rksh at soc.soton.ac.uk> writes:

> Dear Professor Ripley
> 
> thank you for your reply.
> 
> >
> >>  >  NaN +NA
> >>  [1] NaN
> >>  >  NA + NaN
> >>  [1] NA
> >>
> >>  I thought "+" was commutative by definition.   What's going on?
> >
> >It is clearly not under your compiler/OS.  We could add a configure test
> >for broken systems and fix it in arithmetic.c but it hardly seems
> >worthwhile.

Didn't we do this discussion before? AFAIR, the thing is that IEEE
specifies that NaN + whatever == whatever + NaN == NaN, but NaN is
only specified a bit pattern in the first couple of bytes. R uses a
special value in the lower bytes (1954 -- BTW, when *is* Ross'
birthday?) to signal the NA, but we can't really expect that chip
makers do what we hope they'd do with that part of the value. I think
we resolved that specific checking for this issue would be too much of
a performance killer, especially since R generally treats NaN as NA
anyway. 

> [snip]
> 
> >  > (Both give NA under linux, so it looks like a version-specific issue).
> >
> >Linux on that hardware?  It might be a chip issue.
> 
> 
> Sorry, that should read "Both give NA under linux on an i686 system,
> RedHat Linux 2.4.18"
> 
> In any event, "+" appears to be associative (which is what I was
> interested in).

Eh? That is something that is almost certainly not true for FP
arithmetic, e.g. 

> (1 + 1e-16) + 1e-16 == 1 + (1e-16 + 1e-16)
[1] FALSE


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From gregory_r_warnes at groton.pfizer.com  Tue Sep  7 13:46:27 2004
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Tue, 7 Sep 2004 07:46:27 -0400 
Subject: [R] how to add error bar to the data in R?
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20C521B34@groexmb02.pfizer.com>


Alternatively, use the plotCI() function from the gregmisc package.

-G

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
To: jz7 at duke.edu
Cc: r-help at stat.math.ethz.ch
Sent: 9/7/04 5:08 AM
Subject: Re: [R] how to add error bar to the data in R?


Hello,

Use the function xYplot from hmisc package
cheers,
Marta

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From p.dalgaard at biostat.ku.dk  Tue Sep  7 14:01:44 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 07 Sep 2004 14:01:44 +0200
Subject: [R] Error when running configure on xeon with r-1-9-patched
In-Reply-To: <413D9B80.5060508@ucl.ac.uk>
References: <Pine.LNX.4.44.0409062152110.19583-100000@gannet.stats>
	<413D9B80.5060508@ucl.ac.uk>
Message-ID: <x27jr670ev.fsf@biostat.ku.dk>

Gavin Simpson <gavin.simpson at ucl.ac.uk> writes:

> configure:25282: gcc -o conftest -D__NO_MATH_INLINES -mieee-fp -O2 -g
> -pipe -march=i386 -mcpu=i686 -I/usr/local/include -L/usr/local/lib
> conftest.c -lreadline -ldl -lncurses -lm   -L/usr/local/lib
> -L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3
> -L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../.. -lfrtbegin -lg2c
> -lm -lgcc_s -lieee >&5
> /usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../../libieee.a(.data+0x0):
> multiple definition of `_LIB_VERSION'
> /usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../../libieee.a(.data+0x0):
> first defined here

I think this means that you're linking the same library twice. Did you
put the -lieee in there yourself? (via config.site, e.g.).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Tue Sep  7 14:12:07 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 7 Sep 2004 13:12:07 +0100 (BST)
Subject: [R] Error when running configure on xeon with r-1-9-patched
In-Reply-To: <413D9B80.5060508@ucl.ac.uk>
Message-ID: <Pine.LNX.4.44.0409071310110.17192-100000@gannet.stats>

On Tue, 7 Sep 2004, Gavin Simpson wrote:

> Prof Brian Ripley wrote:
> > Is libg2c.so in your library path?  That's one common problem.
> 
> Many thanks for your reply Prof. Ripley. How can I check what my library 
> path is?
> 
> cat /etc/ld.so.conf gives
> 
> include ld.so.conf.d/*.conf
> /usr/X11R6/lib
> /usr/lib/qt-3.3/lib
> /usr/local/lib

That's it, plus /usr/lib.  (It is not usual to have /usr/local/lib there,
so it's worht checking nothing strange is lurking there.)

> and I don't have LD_LIBRARY_PATH set. libg2c.so is in 
> /usr/lib/gcc-lib/i386-redhat-linux/3.3.3 and libg2c.so.0 and 
> libg2c.so.0.0.0 both link from /usr/lib to libg2c.so in 
> /usr/lib/gcc-lib/i386-redhat-linux/3.3.3. This is the same setup as the 
> other Fedora boxes I have compiled R on.

So seems OK.  

> > On Mon, 6 Sep 2004, Gavin Simpson wrote:
> > 
> > 
> >>Dear list,
> >>
> >>I'm having a problem configuring R-1-9-patched on a Intel Xeon machine 
> >>running Fedora Core 2. I used svn to checkout the source, altered 
> >>config.site to add some optimisation flags to match the Fedora rpm on 
> >>CRAN (the flags work fine on two other P3 or P4 machines I've compiled R 
> >>on).
> > 
> > 
> > (Configure does not know about P3 vs P4 vs Xeon.)
> > 
> <snip>
> 
> The full section of the config log relating to this error is appended below.
> 
> Many thanks,
> 
> Gavin
> 
> ##excerpt from config.log##
> 
> configure:25282: gcc -o conftest -D__NO_MATH_INLINES -mieee-fp -O2 -g 
> -pipe -march=i386 -mcpu=i686 -I/usr/local/include -L/usr/local/lib 
> conftest.c -lreadline -ldl -lncurses -lm   -L/usr/local/lib 
> -L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3 
> -L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../.. -lfrtbegin -lg2c -lm 
> -lgcc_s -lieee >&5
> /usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../../libieee.a(.data+0x0): 
> multiple definition of `_LIB_VERSION'
> /usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../../libieee.a(.data+0x0): 
> first defined here
> collect2: ld returned 1 exit status
> configure:25288: $? = 1
> configure: failed program was:
> | /* confdefs.h.  */
> |
> | #define PACKAGE_NAME "R"
> | #define PACKAGE_TARNAME "R"
> | #define PACKAGE_VERSION "1.9.1"
> | #define PACKAGE_STRING "R 1.9.1"
> | #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
> | #define PACKAGE "R"
> | #define VERSION "1.9.1"
> | #define R_PLATFORM "i686-pc-linux-gnu"
> | #define R_CPU "i686"
> | #define R_VENDOR "pc"
> | #define R_OS "linux-gnu"
> | #define Unix 1
> | #ifdef __cplusplus
> | extern "C" void std::exit (int) throw (); using std::exit;
> | #endif
> | #define STDC_HEADERS 1
> | #define HAVE_SYS_TYPES_H 1
> | #define HAVE_SYS_STAT_H 1
> | #define HAVE_STDLIB_H 1
> | #define HAVE_STRING_H 1
> | #define HAVE_MEMORY_H 1
> | #define HAVE_STRINGS_H 1
> | #define HAVE_INTTYPES_H 1
> | #define HAVE_STDINT_H 1
> | #define HAVE_UNISTD_H 1
> | #define HAVE_DLFCN_H 1
> | #define HAVE_LIBM 1
> | #define HAVE_LIBNCURSES 1
> | #define HAVE_LIBDL 1
> | #define HAVE_LIBREADLINE 1
> | #define STDC_HEADERS 1
> | #define TIME_WITH_SYS_TIME 1
> | #define HAVE_DIRENT_H 1
> | #define HAVE_SYS_WAIT_H 1
> | #define HAVE_ARPA_INET_H 1
> | #define HAVE_DLFCN_H 1
> | #define HAVE_ELF_H 1
> | #define HAVE_FCNTL_H 1
> | #define HAVE_FPU_CONTROL_H 1
> | #define HAVE_GRP_H 1
> | #define HAVE_IEEE754_H 1
> | #define HAVE_LOCALE_H 1
> | #define HAVE_NETDB_H 1
> | #define HAVE_NETINET_IN_H 1
> | #define HAVE_PWD_H 1
> | #define HAVE_READLINE_HISTORY_H 1
> | #define HAVE_READLINE_READLINE_H 1
> | #define HAVE_STRINGS_H 1
> | #define HAVE_SYS_PARAM_H 1
> | #define HAVE_SYS_SELECT_H 1
> | #define HAVE_SYS_SOCKET_H 1
> | #define HAVE_SYS_STAT_H 1
> | #define HAVE_SYS_TIME_H 1
> | #define HAVE_SYS_TIMES_H 1
> | #define HAVE_SYS_UTSNAME_H 1
> | #define HAVE_UNISTD_H 1
> | #define HAVE_WCHAR_H 1
> | #define HAVE_ERRNO_H 1
> | #define HAVE_STDARG_H 1
> | #define HAVE_STRING_H 1
> | #define HAVE_POSIX_SETJMP 1
> | #define HAVE_GLIBC2 1
> | #define RETSIGTYPE void
> | #define SOCKLEN_T socklen_t
> | #define SIZEOF_INT 4
> | #define INT_32_BITS 1
> | #define SIZEOF_LONG 4
> | #define SIZEOF_LONG_LONG 8
> | #define SIZEOF_LONG_DOUBLE 12
> | /* end confdefs.h.  */
> | #define F77_DUMMY_MAIN _main
> | #ifdef F77_DUMMY_MAIN
> |
> | #  ifdef __cplusplus
> |      extern "C"
> | #  endif
> |    int F77_DUMMY_MAIN() { return 1; }
> |
> | #endif
> | int
> | main ()
> | {
> |
> |   ;
> |   return 0;
> | }
> configure:25321: result: unknown
> configure:25341: error: linking to Fortran libraries from C fails
> See `config.log' for more details.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tura at centroin.com.br  Tue Sep  7 14:14:45 2004
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Tue, 07 Sep 2004 09:14:45 -0300
Subject: [R] Cox regression for prevalence estimates
In-Reply-To: <20040906073128.OBYF22312.fep15@doctor1.workgroup>
References: <20040906073128.OBYF22312.fep15@doctor1.workgroup>
Message-ID: <6.1.2.0.2.20040907091047.038486a0@centroin.com.br>

At , The Michaelson Institute wrote:
>How can R be used to calculate the prevalence ratios using Cox regression +
>robust variance estimates ?

Well,

In Design package have a command: cph
This command have a option "robsut" with default=FALSE, but in help is write:
" ... robust if TRUE a robust variance estimate is returned. ..."

I think that is your response...


bye

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil 

From ripley at stats.ox.ac.uk  Tue Sep  7 14:22:35 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 7 Sep 2004 13:22:35 +0100 (BST)
Subject: [R] noncommutative addition: NA+NaN != NaN+NA
In-Reply-To: <x2fz5u716c.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0409071312550.17192-100000@gannet.stats>

On 7 Sep 2004, Peter Dalgaard wrote:

> Robin Hankin <rksh at soc.soton.ac.uk> writes:
> 
> > Dear Professor Ripley
> > 
> > thank you for your reply.
> > 
> > >
> > >>  >  NaN +NA
> > >>  [1] NaN
> > >>  >  NA + NaN
> > >>  [1] NA
> > >>
> > >>  I thought "+" was commutative by definition.   What's going on?
> > >
> > >It is clearly not under your compiler/OS.  We could add a configure test
> > >for broken systems and fix it in arithmetic.c but it hardly seems
> > >worthwhile.
> 
> Didn't we do this discussion before? 

Certainly over NA vs 0+NA, as in this excerpt from reg-tests-1.R

## matching NAs on Solaris (MM 2002-08-02)
# x <- as.double(NA)
# identical(x + 0, x)
# stopifnot(match(x + 0, x, 0) == 1)
## match failed on Solaris with some compiler settings
## NA+0 is not guaranteed to be NA: could be NaN


> AFAIR, the thing is that IEEE
> specifies that NaN + whatever == whatever + NaN == NaN, but NaN is
> only specified a bit pattern in the first couple of bytes. R uses a
> special value in the lower bytes (1954 -- BTW, when *is* Ross'
> birthday?) to signal the NA, but we can't really expect that chip
> makers do what we hope they'd do with that part of the value. I think
> we resolved that specific checking for this issue would be too much of
> a performance killer, especially since R generally treats NaN as NA
> anyway. 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From f.harrell at vanderbilt.edu  Tue Sep  7 14:27:34 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 07 Sep 2004 08:27:34 -0400
Subject: [R] Cox regression for prevalence estimates
In-Reply-To: <6.1.2.0.2.20040907091047.038486a0@centroin.com.br>
References: <20040906073128.OBYF22312.fep15@doctor1.workgroup>
	<6.1.2.0.2.20040907091047.038486a0@centroin.com.br>
Message-ID: <413DA936.1030106@vanderbilt.edu>

Bernardo Rangel Tura wrote:
> At , The Michaelson Institute wrote:
> 
>> How can R be used to calculate the prevalence ratios using Cox 
>> regression +
>> robust variance estimates ?
> 
> 
> Well,
> 
> In Design package have a command: cph
> This command have a option "robsut" with default=FALSE, but in help is 
> write:
> " ... robust if TRUE a robust variance estimate is returned. ..."
> 
> I think that is your response...
> 
> 
> bye
> 
> Bernardo Rangel Tura, MD, MSc
> National Institute of Cardiology Laranjeiras
> Rio de Janeiro Brazil

No, robust is an option to coxph, not cph.  cph uses 'after the fit' 
correction using the robcov or bootcov functions in Design.


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From gavin.simpson at ucl.ac.uk  Tue Sep  7 14:31:36 2004
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 07 Sep 2004 13:31:36 +0100
Subject: [R] Error when running configure on xeon with r-1-9-patched
In-Reply-To: <x27jr670ev.fsf@biostat.ku.dk>
References: <Pine.LNX.4.44.0409062152110.19583-100000@gannet.stats>	<413D9B80.5060508@ucl.ac.uk>
	<x27jr670ev.fsf@biostat.ku.dk>
Message-ID: <413DAA28.3050804@ucl.ac.uk>

Peter Dalgaard wrote:
> Gavin Simpson <gavin.simpson at ucl.ac.uk> writes:
> 
> 
>>configure:25282: gcc -o conftest -D__NO_MATH_INLINES -mieee-fp -O2 -g
>>-pipe -march=i386 -mcpu=i686 -I/usr/local/include -L/usr/local/lib
>>conftest.c -lreadline -ldl -lncurses -lm   -L/usr/local/lib
>>-L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3
>>-L/usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../.. -lfrtbegin -lg2c
>>-lm -lgcc_s -lieee >&5
>>/usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../../libieee.a(.data+0x0):
>>multiple definition of `_LIB_VERSION'
>>/usr/lib/gcc-lib/i386-redhat-linux/3.3.3/../../../libieee.a(.data+0x0):
>>first defined here
> 
> 
> I think this means that you're linking the same library twice. Did you
> put the -lieee in there yourself? (via config.site, e.g.).
> 

Hi Peter,

Yep, that's it. Copied far too many flags from one machine's configure 
output into the config.site file on the new machine - that'll teach me 
to do things in a hurry and late in the day! Removing the duplicated 
flags allows configure to work now.

Thanks to Peter, Prof. Ripley and Martyn for their help solving my 
error. As always it is much appreciated.

Gav

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From tura at centroin.com.br  Tue Sep  7 15:11:32 2004
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Tue, 07 Sep 2004 10:11:32 -0300
Subject: [R] Cox regression for prevalence estimates
Message-ID: <6.1.2.0.2.20040907101126.03857eb0@centroin.com.br>

At 09:27 07/09/2004, you wrote:

>Bernardo Rangel Tura wrote:
>>At , The Michaelson Institute wrote:
>>
>>>How can R be used to calculate the prevalence ratios using Cox regression +
>>>robust variance estimates ?
>>
>>Well,
>>In Design package have a command: cph
>>This command have a option "robsut" with default=FALSE, but in help is write:
>>" ... robust if TRUE a robust variance estimate is returned. ..."
>>I think that is your response...
>>
>>bye
>>Bernardo Rangel Tura, MD, MSc
>>National Institute of Cardiology Laranjeiras
>>Rio de Janeiro Brazil
>
>No, robust is an option to coxph, not cph.  cph uses 'after the fit' 
>correction using the robcov or bootcov functions in Design.
>
>
>--
>Frank E Harrell Jr   Professor and Chair           School of Medicine
>                      Department of Biostatistics   Vanderbilt University

Sorry Frank!
I made a digitation mistake, but I think yours package answers the Tomas 
Karpati?s need.


Thanks in advance

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil  

From laura at env.leeds.ac.uk  Tue Sep  7 16:37:12 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Tue, 7 Sep 2004 15:37:12 +0100 (BST)
Subject: [R] Further png() question
Message-ID: <Pine.LNX.4.44.0409071533560.11916-100000@gw.env.leeds.ac.uk>

Ok, I have reinstalled R-1.9.0 and this appears to have fixed the
problems I was having with png(). However, I have a further question
regarding png()

Is it possible to pass a par() argument to the png() command? I am
wanting to produce 4 plots per object, which I normally acheive on an X
window by par(mfrow=c(1,4)). I have tried calling a new plot and setting
par in this way but this has no bearing when I call png().

Any suggestions?

Thanks in advance,

Laura Quinn
Institute of Atmospheric Science
School of Earth and Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk



From tura at centroin.com.br  Tue Sep  7 16:38:30 2004
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Tue, 07 Sep 2004 11:38:30 -0300
Subject: [R] noncommutative addition: NA+NaN != NaN+NA
Message-ID: <6.1.2.0.2.20040907113817.03854d40@centroin.com.br>

At 06:17 07/09/2004, you wrote:


>Hi guys.
>
>Check this out:
>
>>  NaN +NA
>[1] NaN
>>  NA + NaN
>[1] NA
>
>I thought "+" was commutative by definition.   What's going on?

In my version, both cases is NA:

 >  NaN +NA
[1] NA
 > NA + NaN
[1] NA
 >
R.version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.1
year     2004
month    06
day      21
language R




Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil  

From sdavis2 at mail.nih.gov  Tue Sep  7 16:46:07 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 7 Sep 2004 10:46:07 -0400
Subject: [R] Further png() question
In-Reply-To: <Pine.LNX.4.44.0409071533560.11916-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0409071533560.11916-100000@gw.env.leeds.ac.uk>
Message-ID: <A6BD9154-00DC-11D9-90DB-000A95D7BA10@mail.nih.gov>

Are you calling png before your par command--I think you should.

 > png (file='filename')
 > par(mfrow=c(1,4))
 > plot(1:10)
 > plot(1:10)
 > plot(1:10)
 > plot(1:10)
 > dev.off()

See if that works for you.

Sean

On Sep 7, 2004, at 10:37 AM, Laura Quinn wrote:

> Ok, I have reinstalled R-1.9.0 and this appears to have fixed the
> problems I was having with png(). However, I have a further question
> regarding png()
>
> Is it possible to pass a par() argument to the png() command? I am
> wanting to produce 4 plots per object, which I normally acheive on an X
> window by par(mfrow=c(1,4)). I have tried calling a new plot and 
> setting
> par in this way but this has no bearing when I call png().
>
> Any suggestions?
>
> Thanks in advance,
>
> Laura Quinn
> Institute of Atmospheric Science
> School of Earth and Environment
> University of Leeds
> Leeds
> LS2 9JT
>
> tel: +44 113 343 1596
> fax: +44 113 343 6716
> mail: laura at env.leeds.ac.uk
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From jmc at research.bell-labs.com  Tue Sep  7 16:46:20 2004
From: jmc at research.bell-labs.com (John Chambers)
Date: Tue, 07 Sep 2004 10:46:20 -0400
Subject: [R] debugging an S4 method
References: <5F883C17941B9F4E80E5FA8C9F1C5E0E010FBB01@jhms08.phibred.com>
Message-ID: <413DC9BC.23DA5EB3@research.bell-labs.com>

"Bickel, David" wrote:
> 
> Does anyone know how to use the equivalent of debug() on an S4 method? I would like R to enter the browser not for the generic function, but for the method of the class that I specify.

This is what the trace() function does, if you supply the signature=
argument set to the class or combination of classes for which you want
to examine the selected method.

Typically, a call would be of the form:

trace("myFun", signature="myClass", browser, exit=browser)

which would call the browser on entry to the "myClass" method and again
before exiting.  See ?trace for details.

(There are a few bug fixes and added features in the upcoming 2.0.0
version).

> 
> Thanks,
> David
> _____________________________
> David Bickel  http://davidbickel.com
> Research Scientist
> Pioneer Hi-Bred International
> Bioinformatics & Exploratory Research
> 7250 NW 62nd Ave., PO Box 552
> Johnston, Iowa 50131-0552
> 515-334-4739 Tel
> 515-334-6634 Fax
> david.bickel at pioneer.com, bickel at prueba.info
> 
> This communication is for use by the intended recipient and ...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
John M. Chambers                  jmc at bell-labs.com
Bell Labs, Lucent Technologies    office: (908)582-2681
700 Mountain Avenue, Room 2C-282  fax:    (908)582-3340
Murray Hill, NJ  07974            web: http://www.cs.bell-labs.com/~jmc



From ligges at statistik.uni-dortmund.de  Tue Sep  7 16:48:02 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 07 Sep 2004 16:48:02 +0200
Subject: [R] Further png() question
In-Reply-To: <Pine.LNX.4.44.0409071533560.11916-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0409071533560.11916-100000@gw.env.leeds.ac.uk>
Message-ID: <413DCA22.4020804@statistik.uni-dortmund.de>

Laura Quinn wrote:

> Ok, I have reinstalled R-1.9.0 and this appears to have fixed the
> problems I was having with png(). However, I have a further question
> regarding png()
> 
> Is it possible to pass a par() argument to the png() command? I am
> wanting to produce 4 plots per object, which I normally acheive on an X
> window by par(mfrow=c(1,4)). I have tried calling a new plot and setting
> par in this way but this has no bearing when I call png().

You have to call par() after png() rather than before:

png("test.png")
par(mfrow=c(1,4))
replicate(4, plot(1:10))
dev.off()

Uwe Ligges



> Any suggestions?
> 
> Thanks in advance,
> 
> Laura Quinn
> Institute of Atmospheric Science
> School of Earth and Environment
> University of Leeds
> Leeds
> LS2 9JT
> 
> tel: +44 113 343 1596
> fax: +44 113 343 6716
> mail: laura at env.leeds.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From partha_bagchi at hgsi.com  Tue Sep  7 16:49:02 2004
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Tue, 7 Sep 2004 10:49:02 -0400
Subject: [R] Further png() question
Message-ID: <OFC9C44516.B7DF2740-ON85256F08.005146BD-85256F08.00516533@hgsi.com>

The following is not a problem in R 1.9.1:

> png(file = "test.png")
> par(mfrow = c(2,2))
> plot(c(1:10))
> plot(c(1:10))
> plot(c(1:10))
> plot(c(1:10))
> dev.off()
null device 
          1 
>

Have you tried that?

HTH,
Partha





Laura Quinn <laura at env.leeds.ac.uk>
Sent by: r-help-bounces at stat.math.ethz.ch
09/07/2004 10:37 AM

 
        To:     r-help at stat.math.ethz.ch
        cc: 
        Subject:        [R] Further png() question


Ok, I have reinstalled R-1.9.0 and this appears to have fixed the
problems I was having with png(). However, I have a further question
regarding png()

Is it possible to pass a par() argument to the png() command? I am
wanting to produce 4 plots per object, which I normally acheive on an X
window by par(mfrow=c(1,4)). I have tried calling a new plot and setting
par in this way but this has no bearing when I call png().

Any suggestions?

Thanks in advance,

Laura Quinn
Institute of Atmospheric Science
School of Earth and Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Tue Sep  7 16:59:09 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 7 Sep 2004 10:59:09 -0400
Subject: [R] Further png() question
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8324@usrymx25.merck.com>

Insert the par() call after png().  par() is device-specific.

Andy

> From: Laura Quinn
> 
> Ok, I have reinstalled R-1.9.0 and this appears to have fixed the
> problems I was having with png(). However, I have a further question
> regarding png()
> 
> Is it possible to pass a par() argument to the png() command? I am
> wanting to produce 4 plots per object, which I normally 
> acheive on an X
> window by par(mfrow=c(1,4)). I have tried calling a new plot 
> and setting
> par in this way but this has no bearing when I call png().
> 
> Any suggestions?
> 
> Thanks in advance,
> 
> Laura Quinn
> Institute of Atmospheric Science
> School of Earth and Environment
> University of Leeds
> Leeds
> LS2 9JT
> 
> tel: +44 113 343 1596
> fax: +44 113 343 6716
> mail: laura at env.leeds.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From petr.pikal at precheza.cz  Tue Sep  7 17:01:18 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 07 Sep 2004 17:01:18 +0200
Subject: [R] Further png() question
In-Reply-To: <Pine.LNX.4.44.0409071533560.11916-100000@gw.env.leeds.ac.uk>
Message-ID: <413DE95E.20550.1FCDA0D@localhost>



On 7 Sep 2004 at 15:37, Laura Quinn wrote:

> Ok, I have reinstalled R-1.9.0 and this appears to have fixed the
> problems I was having with png(). However, I have a further question
> regarding png()
> 
> Is it possible to pass a par() argument to the png() command? I am
> wanting to produce 4 plots per object, which I normally acheive on an
> X window by par(mfrow=c(1,4)). I have tried calling a new plot and
> setting par in this way but this has no bearing when I call png().

Hi

png("myplot.png", 800,800)
par(mfrow=c(1,4))
for (i in 1:4) boxplot(rnorm(10)*i)
dev.off()

seems to work or seems to produce 4 graphs on 1 png device. Is 
this what you want?

Cheers
Petr




> 
> Any suggestions?
> 
> Thanks in advance,
> 
> Laura Quinn
> Institute of Atmospheric Science
> School of Earth and Environment
> University of Leeds
> Leeds
> LS2 9JT
> 
> tel: +44 113 343 1596
> fax: +44 113 343 6716
> mail: laura at env.leeds.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From laura at env.leeds.ac.uk  Tue Sep  7 17:03:10 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Tue, 7 Sep 2004 16:03:10 +0100 (BST)
Subject: [R] Further png() question
In-Reply-To: <413DE95E.20550.1FCDA0D@localhost>
Message-ID: <Pine.LNX.4.44.0409071602450.11916-100000@gw.env.leeds.ac.uk>

Thanks all! It appears I just had the par in the wrong place in my loop.


Laura Quinn
Institute of Atmospheric Science
School of Earth and Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk

On Tue, 7 Sep 2004, Petr Pikal wrote:

>
>
> On 7 Sep 2004 at 15:37, Laura Quinn wrote:
>
> > Ok, I have reinstalled R-1.9.0 and this appears to have fixed the
> > problems I was having with png(). However, I have a further question
> > regarding png()
> >
> > Is it possible to pass a par() argument to the png() command? I am
> > wanting to produce 4 plots per object, which I normally acheive on an
> > X window by par(mfrow=c(1,4)). I have tried calling a new plot and
> > setting par in this way but this has no bearing when I call png().
>
> Hi
>
> png("myplot.png", 800,800)
> par(mfrow=c(1,4))
> for (i in 1:4) boxplot(rnorm(10)*i)
> dev.off()
>
> seems to work or seems to produce 4 graphs on 1 png device. Is
> this what you want?
>
> Cheers
> Petr
>
>
>
>
> >
> > Any suggestions?
> >
> > Thanks in advance,
> >
> > Laura Quinn
> > Institute of Atmospheric Science
> > School of Earth and Environment
> > University of Leeds
> > Leeds
> > LS2 9JT
> >
> > tel: +44 113 343 1596
> > fax: +44 113 343 6716
> > mail: laura at env.leeds.ac.uk
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
>
> Petr Pikal
> petr.pikal at precheza.cz
>
>
>



From ripley at stats.ox.ac.uk  Tue Sep  7 17:16:28 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 7 Sep 2004 16:16:28 +0100 (BST)
Subject: [R] rodbc windows doesn't find dsn
In-Reply-To: <413A414B.5050508@hotmail.com>
Message-ID: <Pine.LNX.4.44.0409071609050.27491-100000@gannet.stats>

On Sat, 4 Sep 2004, Jack Tanner wrote:

> Under WinXP, I have a system DSN called foo. It has stored 
> username/password information. (I can click Configure in ODBC 
> Administrator and then Test Data Source connects to MySQL without me 
> re-entering data.)
> 
> Using RODBC, I can connect to the same database. But when I do 
> odbcConnect("foo"), I get a window that requires me to re-enter 
> username/password information. It seems like RODBC is not finding my 
> system DSN. Am I doing something wrong?

Well, we don't know what you are doing!  RODBC does work with system DSNs,
but did you try odbcDriverConnect?  Let me read the help page for you 

     'odbcConnect' establishes a connection to the dsn, and
     'odbcDriverConnect' allows a more flexible specification via a
     connection string.  'odbcConnect' uses the connection string
     '"DSN=dsn;UID=uid;PWD=pwd"'. 

so what did you enter for uid/pwd?

As the posting guide asks, *read the documentation* before posting.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Tue Sep  7 18:11:04 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 7 Sep 2004 09:11:04 -0700 (PDT)
Subject: [R] Cox regression for prevalence estimates
In-Reply-To: <20040906073128.OBYF22312.fep15@doctor1.workgroup>
References: <20040906073128.OBYF22312.fep15@doctor1.workgroup>
Message-ID: <Pine.A41.4.58.0409070910310.278038@homer08.u.washington.edu>


robust standard errors are available from coxph with the option
robust=TRUE.

	-thomas

On 6 xxx -1, The Michaelson Institute wrote:

> Hello, I'm an MD working in an eye clinic. I'm learning by myself to use R
> for use in my research works and for implementation in a software project.
> There are some authors who recomends the use of Cox regression as a
> substitute for Logistic regression (<a
> href="http://www.biomedcentral.com/1471-2288/3/21.pdf"> Barros AJD, Hirakata
> VN. BMCMedical Research Methodology, 2003; 3:21 </a>. The use of Cox
> regression permit the estimation of the prevalence rates rather than Odds
> ratios obtained by logistic regression analysis.
> Cox regression is used for time-to-event data. To obtain prevalence rates
> the time has to be constant. One of the problems of Cox regression is that
> the confidence intervals are overestimated. To correct this Barros &
> Hirakata recommend the use of robust variance estimates.
> How can R be used to calculate the prevalence ratios using Cox regression +
> robust variance estimates ?
>
> Thanks for your collaboration,
>
> Tomas Karpati MD
> The Michaelson Institute for Rehabilitation of Vision
> Hadassah Medical Organization
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From sdavis2 at mail.nih.gov  Tue Sep  7 19:00:56 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 7 Sep 2004 13:00:56 -0400
Subject: [R] gridBase and heatmap
Message-ID: <7BED9330-00EF-11D9-90DB-000A95D7BA10@mail.nih.gov>

I would like to use gridBase to place four separate heatmaps (actually,  
a stripped-down heatmap.2 from ght gregmisc package that contains only  
the "image" part) into four different viewports.  I can get the  
placement correct, but I keep 'losing' the previous plot.  Any  
suggestions?

Here is some quick example code trying to put a heatmap into the left  
viewport and then put a second one into the upper right.

Thanks in advance for insight....

Sean

 > pushViewport(viewport(layout = grid.layout(1, 3, widths =  
unit(rep(1,3), c("null", "cm", "null")))))
viewport[GRID.VP.177]
 > pushViewport(viewport(layout.pos.col=1))
viewport[GRID.VP.178]
 > par(omi=gridOMI(),new=T)
 > my.heatmap(eb$coefficients[(clsum[,1]>1) & (clsum[,2]>1) &  
(clsum[,3]==0),],breaks=c(seq(-2.5,-0.6,0.1), 
-0.1,0.10,seq(0.6,2.5,0.1)),dendrogram="none",Colv=c(9:12,5:8,1: 
4),labRow=rep('',520),margin=c(10,5),colsep=c(4,8),trace="none",density. 
info="none",col=greenred.colors(40),key=F)
 > popViewport()
viewport[GRID.VP.177]
 > pushViewport(viewport(layout.pos.col=3))
viewport[GRID.VP.179]
 > pushViewport(viewport(layout = grid.layout(3, 1, heights =  
unit(rep(1,3), c("null", "null", "null")))))
viewport[GRID.VP.180]
 > pushViewport(viewport(layout.pos.row=1))
viewport[GRID.VP.181]
 > par(omi=gridOMI(),new=T)
 > my.heatmap(eb$coefficients[(clsum[,1]>1) & (clsum[,2]>1) &  
(clsum[,3]==0),][tmp[505:520],],breaks=c(seq(-2.5,-0.6,0.1), 
-0.1,0.10,seq(0.6,2.5,0.1)),dendrogram="none",labRow=sapply(getSYMBOL(as 
.character(rownames(eb$coefficients[(clsum[,1]>1) & (clsum[,2]>1) &  
(clsum[,3]==0),])),'BrafPkg')[tmp[505:520]],function(x)  
{ifelse(is.na(x),"EST",x)}),Colv=c(9:12,5:8,1: 
4),margin=c(10,5),colsep=c(4,8),trace="none",density.info="none",col=gre 
enred.colors(40),key=F)



From dede01 at codon.nih.gov  Tue Sep  7 19:05:32 2004
From: dede01 at codon.nih.gov (Dede Greenstein)
Date: Tue, 07 Sep 2004 13:05:32 -0400
Subject: [R] contrast/test statements in polynomial mixed model
Message-ID: <5.0.0.25.2.20040907130504.027a8eb0@nihexchange20.nih.gov>

Hello


I am having some trouble figuring out how to write contrast/test syntax for 
the following mixed model regression  y ~ group*age  + group*age^2 random 
=~1|ID

(i have centered the age variable & there are only 2 groups)

the contrast i am trying to construct should compare the overall shape of 
the 2 groups -- in SAS,  this does the trick  -- test 'group difference in 
shape' age_squared*group1 -1; age_cent*group 1 -1

Suggestions would be greatly appreciated

Thanks in advance

Dede Greenstein



From kbartz at loyaltymatrix.com  Tue Sep  7 19:14:43 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Tue, 7 Sep 2004 10:14:43 -0700
Subject: [R] gridBase and heatmap
In-Reply-To: <7BED9330-00EF-11D9-90DB-000A95D7BA10@mail.nih.gov>
Message-ID: <20040907171444.62A0240167@omta18.mta.everyone.net>

The problem is that most base plotting functions first wipe the graphics
device clean. To do what you want, you need to use par(new = T) liberally
between plots. Does that work for you?

Kevin

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Sean Davis
Sent: Tuesday, September 07, 2004 10:01 AM
To: r-help
Subject: [R] gridBase and heatmap

I would like to use gridBase to place four separate heatmaps (actually,  
a stripped-down heatmap.2 from ght gregmisc package that contains only  
the "image" part) into four different viewports.  I can get the  
placement correct, but I keep 'losing' the previous plot.  Any  
suggestions?

Here is some quick example code trying to put a heatmap into the left  
viewport and then put a second one into the upper right.

Thanks in advance for insight....

Sean

 > pushViewport(viewport(layout = grid.layout(1, 3, widths =  
unit(rep(1,3), c("null", "cm", "null")))))
viewport[GRID.VP.177]
 > pushViewport(viewport(layout.pos.col=1))
viewport[GRID.VP.178]
 > par(omi=gridOMI(),new=T)
 > my.heatmap(eb$coefficients[(clsum[,1]>1) & (clsum[,2]>1) &  
(clsum[,3]==0),],breaks=c(seq(-2.5,-0.6,0.1), 
-0.1,0.10,seq(0.6,2.5,0.1)),dendrogram="none",Colv=c(9:12,5:8,1: 
4),labRow=rep('',520),margin=c(10,5),colsep=c(4,8),trace="none",density. 
info="none",col=greenred.colors(40),key=F)
 > popViewport()
viewport[GRID.VP.177]
 > pushViewport(viewport(layout.pos.col=3))
viewport[GRID.VP.179]
 > pushViewport(viewport(layout = grid.layout(3, 1, heights =  
unit(rep(1,3), c("null", "null", "null")))))
viewport[GRID.VP.180]
 > pushViewport(viewport(layout.pos.row=1))
viewport[GRID.VP.181]
 > par(omi=gridOMI(),new=T)
 > my.heatmap(eb$coefficients[(clsum[,1]>1) & (clsum[,2]>1) &  
(clsum[,3]==0),][tmp[505:520],],breaks=c(seq(-2.5,-0.6,0.1), 
-0.1,0.10,seq(0.6,2.5,0.1)),dendrogram="none",labRow=sapply(getSYMBOL(as 
.character(rownames(eb$coefficients[(clsum[,1]>1) & (clsum[,2]>1) &  
(clsum[,3]==0),])),'BrafPkg')[tmp[505:520]],function(x)  
{ifelse(is.na(x),"EST",x)}),Colv=c(9:12,5:8,1: 
4),margin=c(10,5),colsep=c(4,8),trace="none",density.info="none",col=gre 
enred.colors(40),key=F)

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From sdavis2 at mail.nih.gov  Tue Sep  7 19:19:13 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 7 Sep 2004 13:19:13 -0400
Subject: [R] gridBase and heatmap
In-Reply-To: <20040907171444.62A0240167@omta18.mta.everyone.net>
References: <20040907171444.62A0240167@omta18.mta.everyone.net>
Message-ID: <09D17CB0-00F2-11D9-90DB-000A95D7BA10@mail.nih.gov>

Kevin,

Thanks for the advice.  However, I was pretty careful to include a  
par(new=T) [see below].

Sean



On Sep 7, 2004, at 1:14 PM, Kevin Bartz wrote:

> The problem is that most base plotting functions first wipe the  
> graphics
> device clean. To do what you want, you need to use par(new = T)  
> liberally
> between plots. Does that work for you?
>
> Kevin
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Sean Davis
> Sent: Tuesday, September 07, 2004 10:01 AM
> To: r-help
> Subject: [R] gridBase and heatmap
>
> I would like to use gridBase to place four separate heatmaps (actually,
> a stripped-down heatmap.2 from ght gregmisc package that contains only
> the "image" part) into four different viewports.  I can get the
> placement correct, but I keep 'losing' the previous plot.  Any
> suggestions?
>
> Here is some quick example code trying to put a heatmap into the left
> viewport and then put a second one into the upper right.
>
> Thanks in advance for insight....
>
> Sean
>
>> pushViewport(viewport(layout = grid.layout(1, 3, widths =
> unit(rep(1,3), c("null", "cm", "null")))))
> viewport[GRID.VP.177]
>> pushViewport(viewport(layout.pos.col=1))
> viewport[GRID.VP.178]
>> par(omi=gridOMI(),new=T)
>> my.heatmap(eb$coefficients[(clsum[,1]>1) & (clsum[,2]>1) &
> (clsum[,3]==0),],breaks=c(seq(-2.5,-0.6,0.1),
> -0.1,0.10,seq(0.6,2.5,0.1)),dendrogram="none",Colv=c(9:12,5:8,1:
> 4),labRow=rep('',520),margin=c(10,5),colsep=c(4,8),trace="none",density 
> .
> info="none",col=greenred.colors(40),key=F)
>> popViewport()
> viewport[GRID.VP.177]
>> pushViewport(viewport(layout.pos.col=3))
> viewport[GRID.VP.179]
>> pushViewport(viewport(layout = grid.layout(3, 1, heights =
> unit(rep(1,3), c("null", "null", "null")))))
> viewport[GRID.VP.180]
>> pushViewport(viewport(layout.pos.row=1))
> viewport[GRID.VP.181]
>> par(omi=gridOMI(),new=T)
>> my.heatmap(eb$coefficients[(clsum[,1]>1) & (clsum[,2]>1) &
> (clsum[,3]==0),][tmp[505:520],],breaks=c(seq(-2.5,-0.6,0.1),
> -0.1,0.10,seq(0.6,2.5,0.1)),dendrogram="none",labRow=sapply(getSYMBOL(a 
> s
> .character(rownames(eb$coefficients[(clsum[,1]>1) & (clsum[,2]>1) &
> (clsum[,3]==0),])),'BrafPkg')[tmp[505:520]],function(x)
> {ifelse(is.na(x),"EST",x)}),Colv=c(9:12,5:8,1:
> 4),margin=c(10,5),colsep=c(4,8),trace="none",density.info="none",col=gr 
> e
> enred.colors(40),key=F)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From rxg218 at psu.edu  Tue Sep  7 19:52:29 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Tue, 07 Sep 2004 13:52:29 -0400
Subject: [R] using text on the x axis ticks rather than numbers
Message-ID: <1094579549.8808.35.camel@blue.chem.psu.edu>

Hello,
  is there a way in which I can use text labels rather than numbers on
the x axis ticks? I basically have a vector of (say) 8 points and I want
to plot these sequentially. Thus the x axis would have ticks at 1 .. 8.
Rather than having the labels 1 .. 8 I would like to have some arbitrary
text labels.

Ideally I would like the labels to be rotated (say at 45 degrees) so
that they don't overlap with each other.

Is this possible?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Breadth-first search is the bulldozer of science.
-- Randy Goebel



From wolski at molgen.mpg.de  Tue Sep  7 20:57:40 2004
From: wolski at molgen.mpg.de (Eryk Wolski)
Date: Tue, 7 Sep 2004 20:57:40 +0200 (MET DST)
Subject: [R] using text on the x axis ticks rather than numbers
In-Reply-To: <1094579549.8808.35.camel@blue.chem.psu.edu>
Message-ID: <Pine.OSF.4.31.0409072056180.15243-100000@harry.molgen.mpg.de>

Hi!
first supress axis drawing with param axes=FALSE in your plot function.
The use axis function to add your axes.
?axis

/E

On Tue, 7 Sep 2004, Rajarshi Guha wrote:

> Hello,
>   is there a way in which I can use text labels rather than numbers on
> the x axis ticks? I basically have a vector of (say) 8 points and I want
> to plot these sequentially. Thus the x axis would have ticks at 1 .. 8.
> Rather than having the labels 1 .. 8 I would like to have some arbitrary
> text labels.
>
> Ideally I would like the labels to be rotated (say at 45 degrees) so
> that they don't overlap with each other.
>
> Is this possible?
>
> Thanks,
>
> -------------------------------------------------------------------
> Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
> GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
> -------------------------------------------------------------------
> Breadth-first search is the bulldozer of science.
> -- Randy Goebel
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From MSchwartz at MedAnalytics.com  Tue Sep  7 21:01:24 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Tue, 07 Sep 2004 14:01:24 -0500
Subject: [R] using text on the x axis ticks rather than numbers
In-Reply-To: <1094579549.8808.35.camel@blue.chem.psu.edu>
References: <1094579549.8808.35.camel@blue.chem.psu.edu>
Message-ID: <1094583683.4384.28.camel@localhost.localdomain>

On Tue, 2004-09-07 at 12:52, Rajarshi Guha wrote:
> Hello,
>   is there a way in which I can use text labels rather than numbers on
> the x axis ticks? I basically have a vector of (say) 8 points and I want
> to plot these sequentially. Thus the x axis would have ticks at 1 .. 8.
> Rather than having the labels 1 .. 8 I would like to have some arbitrary
> text labels.
> 
> Ideally I would like the labels to be rotated (say at 45 degrees) so
> that they don't overlap with each other.
> 
> Is this possible?
> 
> Thanks,


Here is an example. For the axis labels, you need to use text() and not
mtext() as the latter does not allow for text rotation:

# Set margins to make room for x axis labels
par(mar = c(7, 4, 4, 2) + 0.1)

# Create plot with no x axis and no x axis label
plot(1:8, xaxt = "n",  xlab = "")

# Set up x axis with tick marks alone
axis(1, labels = FALSE)

# Create arbitrary text
labels <- paste("arbitrary text", 1:8, sep = " ")

# plot x axis labels using:
# par("usr")[3] - 0.25 as the vertical placement
# srt = 45 as text rotation angle
# adj = 1 to place right end of text at tick mark
# xpd = TRUE to allow for text outside the plot region
text(1:8, par("usr")[1] - 0.25, srt = 45, adj = 1,
     labels = labels, xpd = TRUE)

# plot x axis label at line 6 (of 7)
mtext(1, text = "X Axis Label", line = 6)


You can adjust the value of the '0.25' offset as required to move the x
axis labels up or down relative to the x axis.

HTH,

Marc Schwartz



From sblay at sfu.ca  Tue Sep  7 21:46:55 2004
From: sblay at sfu.ca (S Blay)
Date: Tue, 7 Sep 2004 12:46:55 -0700
Subject: [R] C function name garbled
Message-ID: <20040907194655.GA26789@sfu.ca>

I wrote an R wrapper function (phylpro) around a C function 
(Rphylpro).
The first time I'm running my function, it runs with no errors.
The second time I'm trying to run it, I get an error message 
with the first argument to .Call garbled.

Set up:
> dyn.load("Phylpro.so")
> source("phylpro.R")
> WinHalfWidth<-30
> permReps<-10
> breaks<-c(548, 735, 832)

First call to phylpro succeeds:
> b<-phylpro("simulinfile", breaks, WinHalfWidth, permReps)
>

Second call to phylpro fails:
> b<-phylpro("simulinfile", breaks, WinHalfWidth, permReps)
Error in .Call("PSg\bBh\b", input_file = 
as.character(input_file), breaks = as.integer(breaks),  : 
        .Call function name not in load table

Check if my C function name is in load table: 
> is.loaded("Rphylpro")
[1] TRUE


Any ideas?
Thanks for your help,

S. Blay
Department of Statistics and Actuarial Science
Simon Fraser University, Vancouver, British Columbia



From machud at intellektik.informatik.tu-darmstadt.de  Tue Sep  7 22:26:09 2004
From: machud at intellektik.informatik.tu-darmstadt.de (Marco Chiarandini)
Date: Tue, 7 Sep 2004 22:26:09 +0200 (CEST)
Subject: [R] Multiple comparisons in a non parametric case
Message-ID: <Pine.LNX.4.58.0409072156100.1624@kika.intellektik.informatik.tu-darmstadt.de>

Dear all,

I am conducting a full factorial analysis. I have one factor consisting
in algorithms, which I consider my treatments, and another factor made
of the problems I want to solve. For each problem I obtain a response
variable which is stochastic. I replicate the measure of this response
value 10 times.

When I apply ANOVA the assumptions do not hold, hence I must rely on non
parametric tests.

By transforming the response data in ranks, the Friedman test tells me
that there is statistical significance in the difference of the sum of
ranks of at least one of the treatments.

I would like now to produce a plot for the multiple comparisons similar
to the Least Significant Difference or the Tukey's Honest Significant
Difference used in ANOVA. Since I am in the non parametric case I can
not use these methods.

Instead, I compare graphically individual treatments by plotting the sum
of ranks of each treatment togehter with the 95% confidence interval. To
compute the interval I use the Friedman test as suggested by Conover in
"Practical Nonparametric statistics".

I obtain something like this:

Treat. A                |-+-|
Treat. B              |-+-|
Treat. C                   |-+-|
Treat. D           |-+-|

The intervals have all the same spread because the number of
replications was the same for all experimental units.


I would like to know if someone in the list had a similar experience and
if what I am doing is correct. In alternative also a reference to
another list which could better fit my request is welcome.


Thank you for the help,

Marco



--
Marco Chiarandini, Fachgebiet Intellektik, Fachbereich Informatik,
Technische Universit??t Darmstadt, Hochschulstra??e 10,
D-64289 Darmstadt - Germany, Office: S2/02 Raum E317
Tel: +49 (0)6151 16-6802 Fax: +49 (0)6151 16-5326
email: machud at intellektik.informatik.tu-darmstadt.de
web page: http://www.intellektik.informatik.tu-darmstadt.de/~machud



From murdoch at stats.uwo.ca  Tue Sep  7 22:57:57 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 07 Sep 2004 16:57:57 -0400
Subject: [R] C function name garbled
In-Reply-To: <20040907194655.GA26789@sfu.ca>
References: <20040907194655.GA26789@sfu.ca>
Message-ID: <928sj0drasjhio3u5fkn4q7mnvr0dfr2p9@4ax.com>

On Tue, 7 Sep 2004 12:46:55 -0700, S Blay <sblay at sfu.ca> wrote :

>I wrote an R wrapper function (phylpro) around a C function 
>(Rphylpro).
>The first time I'm running my function, it runs with no errors.
>The second time I'm trying to run it, I get an error message 
>with the first argument to .Call garbled.
>
>Set up:
>> dyn.load("Phylpro.so")
>> source("phylpro.R")
>> WinHalfWidth<-30
>> permReps<-10
>> breaks<-c(548, 735, 832)
>
>First call to phylpro succeeds:
>> b<-phylpro("simulinfile", breaks, WinHalfWidth, permReps)
>>
>
>Second call to phylpro fails:
>> b<-phylpro("simulinfile", breaks, WinHalfWidth, permReps)
>Error in .Call("PSg\bBh\b", input_file = 
>as.character(input_file), breaks = as.integer(breaks),  : 
>        .Call function name not in load table
>
>Check if my C function name is in load table: 
>> is.loaded("Rphylpro")
>[1] TRUE
>
>
>Any ideas?

It looks to me as though your function is doing something to mess up
R's internal data.  I'd try commenting out the whole body of the
function, then adding it back gradually to find which part causes the
trouble.

Duncan Murdoch



From ramasamy at cancer.org.uk  Tue Sep  7 23:04:29 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 07 Sep 2004 22:04:29 +0100
Subject: [R] using text on the x axis ticks rather than numbers
In-Reply-To: <1094583683.4384.28.camel@localhost.localdomain>
References: <1094579549.8808.35.camel@blue.chem.psu.edu>
	<1094583683.4384.28.camel@localhost.localdomain>
Message-ID: <1094591069.3499.6.camel@localhost.localdomain>

Out of curiosity, why is srt not respected in mtext ? See examples below

plot(1:10, xaxt="n"); 
par(srt=45)
mtext( paste("Point", LETTERS[1:10]), side=1, at=1:10 )

plot(1:10, xaxt="n"); 
mtext( paste("Point", LETTERS[1:10]), side=1, at=1:10, srt=45 )


It would be nice to have 'srt' as an argument in mtext in future.

Regards, Adai



On Tue, 2004-09-07 at 20:01, Marc Schwartz wrote:
> On Tue, 2004-09-07 at 12:52, Rajarshi Guha wrote:
> > Hello,
> >   is there a way in which I can use text labels rather than numbers on
> > the x axis ticks? I basically have a vector of (say) 8 points and I want
> > to plot these sequentially. Thus the x axis would have ticks at 1 .. 8.
> > Rather than having the labels 1 .. 8 I would like to have some arbitrary
> > text labels.
> > 
> > Ideally I would like the labels to be rotated (say at 45 degrees) so
> > that they don't overlap with each other.
> > 
> > Is this possible?
> > 
> > Thanks,
> 
> 
> Here is an example. For the axis labels, you need to use text() and not
> mtext() as the latter does not allow for text rotation:
> 
> # Set margins to make room for x axis labels
> par(mar = c(7, 4, 4, 2) + 0.1)
> 
> # Create plot with no x axis and no x axis label
> plot(1:8, xaxt = "n",  xlab = "")
> 
> # Set up x axis with tick marks alone
> axis(1, labels = FALSE)
> 
> # Create arbitrary text
> labels <- paste("arbitrary text", 1:8, sep = " ")
> 
> # plot x axis labels using:
> # par("usr")[3] - 0.25 as the vertical placement
> # srt = 45 as text rotation angle
> # adj = 1 to place right end of text at tick mark
> # xpd = TRUE to allow for text outside the plot region
> text(1:8, par("usr")[1] - 0.25, srt = 45, adj = 1,
>      labels = labels, xpd = TRUE)
> 
> # plot x axis label at line 6 (of 7)
> mtext(1, text = "X Axis Label", line = 6)
> 
> 
> You can adjust the value of the '0.25' offset as required to move the x
> axis labels up or down relative to the x axis.
> 
> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Tue Sep  7 23:33:46 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 7 Sep 2004 22:33:46 +0100 (BST)
Subject: [R] using text on the x axis ticks rather than numbers
In-Reply-To: <1094591069.3499.6.camel@localhost.localdomain>
Message-ID: <Pine.GSO.4.31.0409072220370.16358-100000@toucan.stats>

On Tue, 7 Sep 2004, Adaikalavan Ramasamy wrote:

> Out of curiosity, why is srt not respected in mtext ? See examples below

It doesn't make a lot of sense.  mtext is about putting text on >m<argin
lines, and even the ability to have text perpendicular to the axis (via
las) is rather awkward to interpret (and the interpretation will be
changed in 2.0.0).  If you are going to rotate text you need to able to
specify a point of rotation and that's much easier via text.

> It would be nice to have 'srt' as an argument in mtext in future.

You haven't been listening to the discussions pre-2.0.0 on the semantics
of `adj' (and now padj as well) in mtext.  Experts seem to find it hard to
keep even the two current cases (parallel and perpendicular) clear in
their minds.

BTW, if you want to use srt with mtext(at=) you can always use S ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rolf at math.unb.ca  Wed Sep  8 00:16:30 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 7 Sep 2004 19:16:30 -0300 (ADT)
Subject: [R] Multiple comparisons in a non parametric case
Message-ID: <200409072216.i87MGUwf010767@erdos.math.unb.ca>

It looks to me like what you are doing is trying to judge
significance of differences by non-overlap of single-sample
confidence intervals.  While this is appealing, it's not quite
right.

I just looked into my copy of Applied Nonparametric Statistics
(second ed.) by Wayne W. Daniel (Duxbury, 1990) but that
only deals with the situation where there is a single replicate
per block-treatment combination (whereas you have 10 reps)
and block-treatment interaction is assumed to be non-existent.

The method that Daniel prescribes in this simple setting seems to be
no more than applying the Bonferroni method of multiple comparisons.
(Daniel does not say; his book is very much a cook-book.)  So you
might simply try Bonferroni --- i.e. do all k-choose-2 pairwise
comparisons between treatments (using the appropriate 2 sample method
for each comparison) doing each comparison at the alpha/k-choose-2
significance level.  Where k = the number of treatments = 4 in your
case.  This method is not going to be super-powerful but it is
sometimes surprizing how well Bonferroni stacks up against more
``sophisticated'' methods.

Daniel gives a reference to ``Nonparametric Statistical Methods'' by
Myles Hollander and Douglas A. Wolfe, New York, Wiley, 1973, for ``an
alternative multiple comparisons formula''.  I don't have this book,
and don't know what direction Hollander and Wolfe ride off in, but it
***might*** be worth trying to get your hands on it and see.

Finally --- in what way are the assumptions of Anova violated?  The
conventional wisdom is that Anova is actually quite robust to
non-normality.  Particularly when the sample size is large --- and 10
reps per treatment combination is pretty good.  Heteroskedasticity is
more of a worry, but it's not so much of a worry when the design is
nicely balanced.  As yours is.  And finally-finally --- have you
tried transforming your data to make them a bit more normal and/or
homoskedastic?

I hope this is some help.

				cheers,

					Rolf Turner
					rolf at math.unb.ca

Marco Chiarandini wrote:

> I am conducting a full factorial analysis. I have one factor
> consisting in algorithms, which I consider my treatments, and another
> factor made of the problems I want to solve. For each problem I
> obtain a response variable which is stochastic. I replicate the
> measure of this response value 10 times.
> 
> When I apply ANOVA the assumptions do not hold, hence I must rely on
> non parametric tests.
> 
> By transforming the response data in ranks, the Friedman test tells
> me that there is statistical significance in the difference of the
> sum of ranks of at least one of the treatments.
> 
> I would like now to produce a plot for the multiple comparisons
> similar to the Least Significant Difference or the Tukey's Honest
> Significant Difference used in ANOVA. Since I am in the non
> parametric case I can not use these methods.
> 
> Instead, I compare graphically individual treatments by plotting the
> sum of ranks of each treatment togehter with the 95% confidence
> interval. To compute the interval I use the Friedman test as
> suggested by Conover in "Practical Nonparametric statistics".
> 
> I obtain something like this:
> 
> Treat. A                |-+-|
> Treat. B              |-+-|
> Treat. C                   |-+-|
> Treat. D           |-+-|
> 
> The intervals have all the same spread because the number of
> replications was the same for all experimental units.
> 
> I would like to know if someone in the list had a similar experience
> and if what I am doing is correct. In alternative also a reference to
> another list which could better fit my request is welcome.



From spencer.graves at pdf.com  Wed Sep  8 01:16:21 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 07 Sep 2004 16:16:21 -0700
Subject: [R] Multiple comparisons in a non parametric case
In-Reply-To: <200409072216.i87MGUwf010767@erdos.math.unb.ca>
References: <200409072216.i87MGUwf010767@erdos.math.unb.ca>
Message-ID: <413E4145.6020504@pdf.com>

      Great summary, Rolf. 

      Just one minor issue that recently bit me:  In a data mining 
application with hundred of p-values, people want to make subtle 
distinctions based on extremely small p-values.  In such applications, 
even a modest amount of skewness (to say nothing of outliers) might have 
a surprising (and not necessarily monotonic) impact on p-values. 

      Best Wishes,
      Spencer Graves

Rolf Turner wrote:

>It looks to me like what you are doing is trying to judge
>significance of differences by non-overlap of single-sample
>confidence intervals.  While this is appealing, it's not quite
>right.
>
>I just looked into my copy of Applied Nonparametric Statistics
>(second ed.) by Wayne W. Daniel (Duxbury, 1990) but that
>only deals with the situation where there is a single replicate
>per block-treatment combination (whereas you have 10 reps)
>and block-treatment interaction is assumed to be non-existent.
>
>The method that Daniel prescribes in this simple setting seems to be
>no more than applying the Bonferroni method of multiple comparisons.
>(Daniel does not say; his book is very much a cook-book.)  So you
>might simply try Bonferroni --- i.e. do all k-choose-2 pairwise
>comparisons between treatments (using the appropriate 2 sample method
>for each comparison) doing each comparison at the alpha/k-choose-2
>significance level.  Where k = the number of treatments = 4 in your
>case.  This method is not going to be super-powerful but it is
>sometimes surprizing how well Bonferroni stacks up against more
>``sophisticated'' methods.
>
>Daniel gives a reference to ``Nonparametric Statistical Methods'' by
>Myles Hollander and Douglas A. Wolfe, New York, Wiley, 1973, for ``an
>alternative multiple comparisons formula''.  I don't have this book,
>and don't know what direction Hollander and Wolfe ride off in, but it
>***might*** be worth trying to get your hands on it and see.
>
>Finally --- in what way are the assumptions of Anova violated?  The
>conventional wisdom is that Anova is actually quite robust to
>non-normality.  Particularly when the sample size is large --- and 10
>reps per treatment combination is pretty good.  Heteroskedasticity is
>more of a worry, but it's not so much of a worry when the design is
>nicely balanced.  As yours is.  And finally-finally --- have you
>tried transforming your data to make them a bit more normal and/or
>homoskedastic?
>
>I hope this is some help.
>
>				cheers,
>
>					Rolf Turner
>					rolf at math.unb.ca
>
>Marco Chiarandini wrote:
>
>  
>
>>I am conducting a full factorial analysis. I have one factor
>>consisting in algorithms, which I consider my treatments, and another
>>factor made of the problems I want to solve. For each problem I
>>obtain a response variable which is stochastic. I replicate the
>>measure of this response value 10 times.
>>
>>When I apply ANOVA the assumptions do not hold, hence I must rely on
>>non parametric tests.
>>
>>By transforming the response data in ranks, the Friedman test tells
>>me that there is statistical significance in the difference of the
>>sum of ranks of at least one of the treatments.
>>
>>I would like now to produce a plot for the multiple comparisons
>>similar to the Least Significant Difference or the Tukey's Honest
>>Significant Difference used in ANOVA. Since I am in the non
>>parametric case I can not use these methods.
>>
>>Instead, I compare graphically individual treatments by plotting the
>>sum of ranks of each treatment togehter with the 95% confidence
>>interval. To compute the interval I use the Friedman test as
>>suggested by Conover in "Practical Nonparametric statistics".
>>
>>I obtain something like this:
>>
>>Treat. A                |-+-|
>>Treat. B              |-+-|
>>Treat. C                   |-+-|
>>Treat. D           |-+-|
>>
>>The intervals have all the same spread because the number of
>>replications was the same for all experimental units.
>>
>>I would like to know if someone in the list had a similar experience
>>and if what I am doing is correct. In alternative also a reference to
>>another list which could better fit my request is welcome.
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From pwlepp at pmgm2.stanford.edu  Wed Sep  8 01:26:01 2004
From: pwlepp at pmgm2.stanford.edu (Paul Lepp)
Date: Tue, 7 Sep 2004 16:26:01 -0700
Subject: [R] heatmap help
Message-ID: <DEEEIJAKFKHHOHEFAAEIEEAKCKAA.pwlepp@cmgm.stanford.edu>

Dear R wizards,
	Hopeful someone can help me with what I believe is a pretty simple task.  I
pretty new to R so some (much) of the obvious escapes me. How do I get a
distance matrix into heatmap?  What do I tell distfun if what I'm trying to
map is already an ordered distance matrix?  I tried >heatmap(x,
distfun=as.dist(x)) where x is the distance matrix but R gave me an error.
Thanks in advance for any help.

Paul Lepp

 `-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.
   `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`
     >==/        >==/        >==/        >==/        >==/
   ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,
,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'
Paul Lepp, Ph.D.                       Stanford School of Medicine

VAPAHCS, 154T                   Dept. of Microbiology & Immunology
3801 Miranda Ave                               Stanford University
Palo Alto, CA 94304                                   Stanford, CA
(650) 493-5000 x66762		               fax: (650) 852-3291
http://cmgm.stanford.edu/~pwlepp          pwlepp at cmgm.stanford.edu



From andy_liaw at merck.com  Wed Sep  8 01:36:12 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 7 Sep 2004 19:36:12 -0400
Subject: [R] heatmap help
Message-ID: <3A822319EB35174CA3714066D590DCD504AF832B@usrymx25.merck.com>

I believe you want to pass the (symmetric) matrix as is, rather than wrapped
in as.dist().  E.g.,

x <- as.matrix(dist(matrix(rnorm(100), 20, 5)))
heatmap(x, symm=TRUE, scale="none")

HTH,
Andy

> From: Paul Lepp
> 
> Dear R wizards,
> 	Hopeful someone can help me with what I believe is a 
> pretty simple task.  I
> pretty new to R so some (much) of the obvious escapes me. How 
> do I get a
> distance matrix into heatmap?  What do I tell distfun if what 
> I'm trying to
> map is already an ordered distance matrix?  I tried >heatmap(x,
> distfun=as.dist(x)) where x is the distance matrix but R gave 
> me an error.
> Thanks in advance for any help.
> 
> Paul Lepp
> 
>  `-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.
>    `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`
>      >==/        >==/        >==/        >==/        >==/
>    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,
> ,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'
> Paul Lepp, Ph.D.                       Stanford School of Medicine
> 
> VAPAHCS, 154T                   Dept. of Microbiology & Immunology
> 3801 Miranda Ave                               Stanford University
> Palo Alto, CA 94304                                   Stanford, CA
> (650) 493-5000 x66762		               fax: (650) 852-3291
> http://cmgm.stanford.edu/~pwlepp          pwlepp at cmgm.stanford.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From andy_liaw at merck.com  Wed Sep  8 01:52:43 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 7 Sep 2004 19:52:43 -0400
Subject: [R] heatmap help
Message-ID: <3A822319EB35174CA3714066D590DCD504AF832D@usrymx25.merck.com>

Sorry.  I think you need the argument distfun=as.dist.  E.g.,

heatmap(x, distfun=as.dist, symm=TRUE, scale="none")

Andy

> From: Liaw, Andy
> 
> I believe you want to pass the (symmetric) matrix as is, 
> rather than wrapped
> in as.dist().  E.g.,
> 
> x <- as.matrix(dist(matrix(rnorm(100), 20, 5)))
> heatmap(x, symm=TRUE, scale="none")
> 
> HTH,
> Andy
> 
> > From: Paul Lepp
> > 
> > Dear R wizards,
> > 	Hopeful someone can help me with what I believe is a 
> > pretty simple task.  I
> > pretty new to R so some (much) of the obvious escapes me. How 
> > do I get a
> > distance matrix into heatmap?  What do I tell distfun if what 
> > I'm trying to
> > map is already an ordered distance matrix?  I tried >heatmap(x,
> > distfun=as.dist(x)) where x is the distance matrix but R gave 
> > me an error.
> > Thanks in advance for any help.
> > 
> > Paul Lepp
> > 
> >  `-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.
> >    `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`
> >      >==/        >==/        >==/        >==/        >==/
> >    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,
> > ,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'
> > Paul Lepp, Ph.D.                       Stanford School of Medicine
> > 
> > VAPAHCS, 154T                   Dept. of Microbiology & Immunology
> > 3801 Miranda Ave                               Stanford University
> > Palo Alto, CA 94304                                   Stanford, CA
> > (650) 493-5000 x66762		               fax: 
> (650) 852-3291
> > http://cmgm.stanford.edu/~pwlepp          pwlepp at cmgm.stanford.edu
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> --------------------------------------------------------------
> ----------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New Jersey, USA 08889), and/or its 
> affiliates (which may be known outside the United States as 
> Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
> Banyu) that may be confidential, proprietary copyrighted 
> and/or legally privileged. It is intended solely for the use 
> of the individual or entity named on this message.  If you 
> are not the intended recipient, and have received this 
> message in error, please notify us immediately by reply 
> e-mail and then delete it from your system.
> --------------------------------------------------------------
> ----------------
>



From rlyoung at email.arizona.edu  Wed Sep  8 02:16:34 2004
From: rlyoung at email.arizona.edu (Rebecca Young)
Date: Tue,  7 Sep 2004 17:16:34 -0700
Subject: [R] pairwise comparisons
Message-ID: <1094602594.54b1beda8a6fc@www.email.arizona.edu>

Hello,

I am a new R user.  I am trying to calculate vector correlations for all
pairwise comparisons in my data frame without repeats.  I am familiar with the
expand.grid function, but this includes repeats.  Is there a way to use
expand.grid and eliminate repeats?  Or is there another function that can be
used to do this?

Thank you.
Rebecca


--
Rebecca Young
Graduate Student
Ecology & Evolutionary Biology, Badyaev Lab
University of Arizona
1041 E Lowell
Tucson, AZ 85721-0088
Office: 425BSW
rlyoung at email.arizona.edu
(520) 621-4005



From xmeng at capitalbio.com  Wed Sep  8 02:41:49 2004
From: xmeng at capitalbio.com (=?gb2312?B?w8/QwA==?=)
Date: Wed, 08 Sep 2004 08:41:49 +0800
Subject: [R] a little question about R
Message-ID: <294604109.32291@capitalbio.com>

Hello,sir: Here's a little question about R which needs your help.Thanks in advance. 
If I wanna make a sequence just like a,b,c,d (In other words,a vector consists of 4 characters :a,b,c,d ).How can I do it in a shortcut manner? Yes,I can do it as following: c("a","b","c","d") and the result is:[1] "a" "b" "c" "d".
But I remember there's a shortcut manner to do the same thing,something like 
c("a":"d").But the system said:"Error in "a":"d" : NA/NaN argument" So I wonder the correct method to do it(I remember the expression is very similar with
c("a":"d")). Thanks from the bottom of my heart. My best regards!



From rpeng at jhsph.edu  Wed Sep  8 02:36:56 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 07 Sep 2004 20:36:56 -0400
Subject: [R] pairwise comparisons
In-Reply-To: <1094602594.54b1beda8a6fc@www.email.arizona.edu>
References: <1094602594.54b1beda8a6fc@www.email.arizona.edu>
Message-ID: <413E5428.8010607@jhsph.edu>

Are you talking about repeated rows?  Does unique() do what you want?

-roger

Rebecca Young wrote:

> Hello,
> 
> I am a new R user.  I am trying to calculate vector correlations for all
> pairwise comparisons in my data frame without repeats.  I am familiar with the
> expand.grid function, but this includes repeats.  Is there a way to use
> expand.grid and eliminate repeats?  Or is there another function that can be
> used to do this?
> 
> Thank you.
> Rebecca
> 
> 
> --
> Rebecca Young
> Graduate Student
> Ecology & Evolutionary Biology, Badyaev Lab
> University of Arizona
> 1041 E Lowell
> Tucson, AZ 85721-0088
> Office: 425BSW
> rlyoung at email.arizona.edu
> (520) 621-4005
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jfox at mcmaster.ca  Wed Sep  8 02:38:27 2004
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 7 Sep 2004 20:38:27 -0400
Subject: [R] a little question about R
In-Reply-To: <294604109.32291@capitalbio.com>
Message-ID: <20040908003828.JBCA4758.tomts13-srv.bellnexxia.net@JohnDesktop8300>

You can use letters[1:4].

I hope that this helps,
 John 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of ??
> Sent: Tuesday, September 07, 2004 7:42 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] a little question about R
> 
> Hello,sir: Here's a little question about R which needs your 
> help.Thanks in advance. 
> If I wanna make a sequence just like a,b,c,d (In other 
> words,a vector consists of 4 characters :a,b,c,d ).How can I 
> do it in a shortcut manner? Yes,I can do it as following: 
> c("a","b","c","d") and the result is:[1] "a" "b" "c" "d".
> But I remember there's a shortcut manner to do the same 
> thing,something like c("a":"d").But the system said:"Error in 
> "a":"d" : NA/NaN argument" So I wonder the correct method to 
> do it(I remember the expression is very similar with 
> c("a":"d")). Thanks from the bottom of my heart. My best regards!
>



From rpeng at jhsph.edu  Wed Sep  8 02:41:41 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 07 Sep 2004 20:41:41 -0400
Subject: [R] a little question about R
In-Reply-To: <294604109.32291@capitalbio.com>
References: <294604109.32291@capitalbio.com>
Message-ID: <413E5545.1030404@jhsph.edu>

Try

letters[1:4]

-roger

?????? wrote:

> Hello,sir: Here's a little question about R which needs your help.Thanks in advance. 
> If I wanna make a sequence just like a,b,c,d (In other words,a vector consists of 4 characters :a,b,c,d ).How can I do it in a shortcut manner? Yes,I can do it as following: c("a","b","c","d") and the result is:[1] "a" "b" "c" "d".
> But I remember there's a shortcut manner to do the same thing,something like 
> c("a":"d").But the system said:"Error in "a":"d" : NA/NaN argument" So I wonder the correct method to do it(I remember the expression is very similar with
> c("a":"d")). Thanks from the bottom of my heart. My best regards!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From matthew_wiener at merck.com  Wed Sep  8 02:42:16 2004
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Tue, 7 Sep 2004 20:42:16 -0400
Subject: [R] a little question about R
Message-ID: <45AAE6FD142DCB43A38C00A11FF5DF3E02225F43@uswsmx03.merck.com>

letters[1;4]
LETTERS[1:4] for capitals.

Hope this helps,

Matt Wiener

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of xmeng at capitalbio.com
Sent: Tuesday, September 07, 2004 8:42 PM
To: r-help at stat.math.ethz.ch
Subject: [R] a little question about R


Hello,sir: Here's a little question about R which needs your help.Thanks in
advance. 
If I wanna make a sequence just like a,b,c,d (In other words,a vector
consists of 4 characters :a,b,c,d ).How can I do it in a shortcut manner?
Yes,I can do it as following: c("a","b","c","d") and the result is:[1] "a"
"b" "c" "d".
But I remember there's a shortcut manner to do the same thing,something like

c("a":"d").But the system said:"Error in "a":"d" : NA/NaN argument" So I
wonder the correct method to do it(I remember the expression is very similar
with
c("a":"d")). Thanks from the bottom of my heart. My best regards!

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From astephen at efs.mq.edu.au  Wed Sep  8 02:45:50 2004
From: astephen at efs.mq.edu.au (Alec Stephenson)
Date: Wed, 08 Sep 2004 10:45:50 +1000
Subject: [R] a little question about R
Message-ID: <s13ee2fc.088@137.111.64.49>

letters[1:4]



Alec Stephenson                                               
Department of Statistics
Macquarie University
NSW 2109, Australia 

>>> " $(A????????" <xmeng at capitalbio.com> 09/08/04 10:41am >>>
Hello,sir: Here's a little question about R which needs your help.Thanks in advance. 
If I wanna make a sequence just like a,b,c,d (In other words,a vector consists of 4 characters :a,b,c,d ).How can I do it in a shortcut manner? Yes,I can do it as following: c("a","b","c","d") and the result is:[1] "a" "b" "c" "d".
But I remember there's a shortcut manner to do the same thing,something like 
c("a":"d").But the system said:"Error in "a":"d" : NA/NaN argument" So I wonder the correct method to do it(I remember the expression is very similar with
c("a":"d")). Thanks from the bottom of my heart. My best regards!

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Kevin.Wang at maths.anu.edu.au  Wed Sep  8 02:43:51 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Wed, 8 Sep 2004 10:43:51 +1000 (EST)
Subject: [R] a little question about R
In-Reply-To: <294604109.32291@capitalbio.com>
References: <294604109.32291@capitalbio.com>
Message-ID: <Pine.GSO.4.58.0409081043370.19874@yin>

Hi,

On Wed, 8 Sep 2004, [gb2312] ÃÏÐÀ wrote:

> Hello,sir: Here's a little question about R which needs your help.Thanks in advance.
> If I wanna make a sequence just like a,b,c,d (In other words,a vector consists of 4 characters :a,b,c,d ).How can I do it in a shortcut manner? Yes,I can do it as following: c("a","b","c","d") and the result is:[1] "a" "b" "c" "d".
> But I remember there's a shortcut manner to do the same thing,something like

How about
  letters[1:4]
>

--------------------------------
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From xmeng at capitalbio.com  Wed Sep  8 03:11:20 2004
From: xmeng at capitalbio.com (=?gb2312?B?w8/QwA==?=)
Date: Wed, 08 Sep 2004 09:11:20 +0800
Subject: [R] Thanks
Message-ID: <294605880.01183@capitalbio.com>

Thanks a lot for your timely rely.
I still wonder whether I can use "a":"d" instead of 1:4.
I remember I fulfill it successfully according to the guidance of some materials on R,but fail to find it now.
Thanks again!



From sblay at sfu.ca  Wed Sep  8 03:49:56 2004
From: sblay at sfu.ca (Sigal Blay)
Date: Tue, 7 Sep 2004 18:49:56 -0700
Subject: [R] C function name garbled
In-Reply-To: <928sj0drasjhio3u5fkn4q7mnvr0dfr2p9@4ax.com>
References: <20040907194655.GA26789@sfu.ca>
	<928sj0drasjhio3u5fkn4q7mnvr0dfr2p9@4ax.com>
Message-ID: <20040908014956.GA17542@sfu.ca>

On Tue, Sep 07, 2004 at 04:57:57PM -0400, Duncan Murdoch wrote:
> On Tue, 7 Sep 2004 12:46:55 -0700, S Blay <sblay at sfu.ca> wrote :
> 
> >I wrote an R wrapper function (phylpro) around a C function 
> >(Rphylpro).
> >The first time I'm running my function, it runs with no errors.
> >The second time I'm trying to run it, I get an error message 
> >with the first argument to .Call garbled.
> >
> >Set up:
> >> dyn.load("Phylpro.so")
> >> source("phylpro.R")
> >> WinHalfWidth<-30
> >> permReps<-10
> >> breaks<-c(548, 735, 832)
> >
> >First call to phylpro succeeds:
> >> b<-phylpro("simulinfile", breaks, WinHalfWidth, permReps)
> >>
> >
> >Second call to phylpro fails:
> >> b<-phylpro("simulinfile", breaks, WinHalfWidth, permReps)
> >Error in .Call("PSg\bBh\b", input_file = 
> >as.character(input_file), breaks = as.integer(breaks),  : 
> >        .Call function name not in load table
> >
> >Check if my C function name is in load table: 
> >> is.loaded("Rphylpro")
> >[1] TRUE
> >
> >
> >Any ideas?
> 
> It looks to me as though your function is doing something to mess up
> R's internal data.  I'd try commenting out the whole body of the
> function, then adding it back gradually to find which part causes the
> trouble.
> 
> Duncan Murdoch

I followed your advice - looks like I need some kind of a cast 
when I assign the values of a C vector to an R vector. I think.

Below is an example of something that doesn't work - 
Can someone give me a hand? 
(In the real function, there are also integer and Character 
string C vectors...) 
Thanks.

#include <R.h>
#include <Rdefines.h>

SEXP myfunc() {
    double *corrs; 
    corrs[0]=3.0;
    SEXP Rcorrs; 
    double *pRcorrs;
    PROTECT(Rcorrs = NEW_NUMERIC(1));
    pRcorrs = NUMERIC_POINTER(Rcorrs);
    pRcorrs[0] = corrs[0];

    UNPROTECT(1); 
    return(R_NilValue);
}

/*
 dyn.load("myfunc.so")
 func<-function().Call("myfunc")
 func()
*/

Run it once, it's ok:
>  func() 
NULL

Run it twice, not ok:
>  func() 
Error in .Call(NULL) : function name must be a string (of length 1)



From jg_liao at yahoo.com  Wed Sep  8 04:04:27 2004
From: jg_liao at yahoo.com (Jason Liao)
Date: Tue, 7 Sep 2004 19:04:27 -0700 (PDT)
Subject: [R] 64 bit R slower than 32 bit R on Sun Sparc Solaris?
Message-ID: <20040908020427.85049.qmail@web53708.mail.yahoo.com>

Hello, everyone! I guess no one is still using R on Sun Sparc these
days. But our department has a (pretty new) two-CPU Sun server. We
recently compiled R as a 64 bit application and expected a performance
boost. But it runs 25-30% slower than the 32 bit version of R. Anyone
knows why this is so? Thanks!

Jason


=====
Jason Liao, http://www.geocities.com/jg_liao
Dept. of Biostatistics, http://www2.umdnj.edu/bmtrxweb
University of Medicine and Dentistry of New Jersey
phone 732-235-5429, School of Public Health office
phone 732-235-8611, Cancer Institute of New Jersey office
moble phone 908-720-4205



From rpeng at jhsph.edu  Wed Sep  8 04:44:54 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 07 Sep 2004 22:44:54 -0400
Subject: [R] 64 bit R slower than 32 bit R on Sun Sparc Solaris?
In-Reply-To: <20040908020427.85049.qmail@web53708.mail.yahoo.com>
References: <20040908020427.85049.qmail@web53708.mail.yahoo.com>
Message-ID: <413E7226.507@jhsph.edu>

Are you using an optimized BLAS for both builds?  That's one possibility.  Also, 
64-bit builds use up more memory initially since the pointers are bigger.  I've 
tried both 64-bit and 32-bit builds on Sparc/Solaris and haven't seen any slowdown.

-roger

Jason Liao wrote:

> Hello, everyone! I guess no one is still using R on Sun Sparc these
> days. But our department has a (pretty new) two-CPU Sun server. We
> recently compiled R as a 64 bit application and expected a performance
> boost. But it runs 25-30% slower than the 32 bit version of R. Anyone
> knows why this is so? Thanks!
> 
> Jason
> 
> 
> =====
> Jason Liao, http://www.geocities.com/jg_liao
> Dept. of Biostatistics, http://www2.umdnj.edu/bmtrxweb
> University of Medicine and Dentistry of New Jersey
> phone 732-235-5429, School of Public Health office
> phone 732-235-8611, Cancer Institute of New Jersey office
> moble phone 908-720-4205
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From kathy.deriemer at stanford.edu  Wed Sep  8 04:52:42 2004
From: kathy.deriemer at stanford.edu (Kathy DeRiemer)
Date: Tue, 07 Sep 2004 19:52:42 -0700
Subject: [R] download of 1.9.1
Message-ID: <5.1.1.5.2.20040907194929.024e57f0@molepi.stanford.edu>

Hi there,

I downloaded version 1.9.1 WinZip file, 9.367 bytes ( so I can update my R 
and use the vcd package) but cannot get the download from your Web site to 
unzip and install.  So silly!

The error message is :" Error reading header after processing 0 
entries."  I tried downloading from 3 different URLs, all yielding the same 
message when I try to unzip and install the file.

Could you please let me know what the problem is, including operator error 
on my end.  Thank you



From Kevin.Wang at maths.anu.edu.au  Wed Sep  8 05:03:56 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Wed, 8 Sep 2004 13:03:56 +1000 (EST)
Subject: [R] download of 1.9.1
In-Reply-To: <5.1.1.5.2.20040907194929.024e57f0@molepi.stanford.edu>
References: <5.1.1.5.2.20040907194929.024e57f0@molepi.stanford.edu>
Message-ID: <Pine.GSO.4.58.0409081302440.114@yin>

Hi,

On Tue, 7 Sep 2004, Kathy DeRiemer wrote:

> Hi there,
>
> I downloaded version 1.9.1 WinZip file, 9.367 bytes ( so I can update my R

Ummmm....it doesn't sound right, 9 bytes????

> and use the vcd package) but cannot get the download from your Web site to
> unzip and install.  So silly!
>
> The error message is :" Error reading header after processing 0
> entries."  I tried downloading from 3 different URLs, all yielding the same
> message when I try to unzip and install the file.

Well, since you mentioned WinZip I'm assuming you are using R under
Windows.  IN which case why don't you update the package from Rgui using
the menu?  See the FAQ...

Cheers,

Kevin

--------------------------------
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From ggrothendieck at myway.com  Wed Sep  8 05:13:24 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 8 Sep 2004 03:13:24 +0000 (UTC)
Subject: [R] Thanks
References: <294605880.01183@capitalbio.com>
Message-ID: <loom.20040908T050559-606@post.gmane.org>

?????? <xmeng <at> capitalbio.com> writes:

: Thanks a lot for your timely rely.
: I still wonder whether I can use "a":"d" instead of 1:4.
: I remember I fulfill it successfully according to the guidance of some 
materials on R,but fail to find it now.

You could define your own seq function and operator:

R> "%:%" <- seq.character <- function(x,y) letters[letters >= x & letters <= y]
R> seq("a", "d")
[1] "a" "b" "c" "d"
R> "a" %:% "d"
[1] "a" "b" "c" "d"



From ggrothendieck at myway.com  Wed Sep  8 05:24:09 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 8 Sep 2004 03:24:09 +0000 (UTC)
Subject: [R] Thanks
References: <294605880.01183@capitalbio.com>
	<loom.20040908T050559-606@post.gmane.org>
Message-ID: <loom.20040908T052212-174@post.gmane.org>

Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

: 
: ?????? <xmeng <at> capitalbio.com> writes:
: 
: : Thanks a lot for your timely rely.
: : I still wonder whether I can use "a":"d" instead of 1:4.
: : I remember I fulfill it successfully according to the guidance of some 
: materials on R,but fail to find it now.
: 
: You could define your own seq function and operator:
: 
: R> "%:%" <- seq.character <- function(x,y) letters[letters >= x & letters <= 
y]
: R> seq("a", "d")
: [1] "a" "b" "c" "d"
: R> "a" %:% "d"
: [1] "a" "b" "c" "d"

And just as a follow up to my own post, if you want to make this a bit more
general you might use ascii in place of letters where ascii is defined in:

http://www.r-project.org/nocvs/mail/r-help/2002/0952.html



From andy_liaw at merck.com  Wed Sep  8 05:24:01 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 7 Sep 2004 23:24:01 -0400
Subject: [R] Thanks
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8333@usrymx25.merck.com>

A small drawback to Gabor's proposal:

> "aa" %:% "dd"
[1] "b" "c" "d"
> "00" %:% "99"
character(0)

Defining it as a seq() method for characters is probably not a terribly good
idea, as one should expect it to work for any character vectors as input.
(One can argue that the function worked as `expected', I suppose...)

Best,
Andy

> From: Gabor Grothendieck
> 
> ?? <xmeng <at> capitalbio.com> writes:
> 
> : Thanks a lot for your timely rely.
> : I still wonder whether I can use "a":"d" instead of 1:4.
> : I remember I fulfill it successfully according to the 
> guidance of some 
> materials on R,but fail to find it now.
> 
> You could define your own seq function and operator:
> 
> R> "%:%" <- seq.character <- function(x,y) letters[letters >= 
> x & letters <= y]
> R> seq("a", "d")
> [1] "a" "b" "c" "d"
> R> "a" %:% "d"
> [1] "a" "b" "c" "d"
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ripley at stats.ox.ac.uk  Wed Sep  8 08:15:34 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Sep 2004 07:15:34 +0100 (BST)
Subject: [R] Thanks
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF8333@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.44.0409080713110.26351-100000@gannet.stats>

On Tue, 7 Sep 2004, Liaw, Andy wrote:

> A small drawback to Gabor's proposal:
> 
> > "aa" %:% "dd"
> [1] "b" "c" "d"
> > "00" %:% "99"
> character(0)
> 
> Defining it as a seq() method for characters is probably not a terribly good
> idea, as one should expect it to work for any character vectors as input.
> (One can argue that the function worked as `expected', I suppose...)

Another drawback: the order of characters is locale-dependent. letters and
LETTERS are an Anglophone's view of what happens (or happened, probably)  
in Roman.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Sep  8 08:27:15 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Sep 2004 07:27:15 +0100 (BST)
Subject: [R] C function name garbled
In-Reply-To: <20040908014956.GA17542@sfu.ca>
Message-ID: <Pine.LNX.4.44.0409080718070.26351-100000@gannet.stats>

On Tue, 7 Sep 2004, Sigal Blay wrote:

> On Tue, Sep 07, 2004 at 04:57:57PM -0400, Duncan Murdoch wrote:
> > On Tue, 7 Sep 2004 12:46:55 -0700, S Blay <sblay at sfu.ca> wrote :
> > 
> > >I wrote an R wrapper function (phylpro) around a C function 
> > >(Rphylpro).
> > >The first time I'm running my function, it runs with no errors.
> > >The second time I'm trying to run it, I get an error message 
> > >with the first argument to .Call garbled.
> > >
> > >Set up:
> > >> dyn.load("Phylpro.so")
> > >> source("phylpro.R")
> > >> WinHalfWidth<-30
> > >> permReps<-10
> > >> breaks<-c(548, 735, 832)
> > >
> > >First call to phylpro succeeds:
> > >> b<-phylpro("simulinfile", breaks, WinHalfWidth, permReps)
> > >>
> > >
> > >Second call to phylpro fails:
> > >> b<-phylpro("simulinfile", breaks, WinHalfWidth, permReps)
> > >Error in .Call("PSg\bBh\b", input_file = 
> > >as.character(input_file), breaks = as.integer(breaks),  : 
> > >        .Call function name not in load table
> > >
> > >Check if my C function name is in load table: 
> > >> is.loaded("Rphylpro")
> > >[1] TRUE
> > >
> > >
> > >Any ideas?
> > 
> > It looks to me as though your function is doing something to mess up
> > R's internal data.  I'd try commenting out the whole body of the
> > function, then adding it back gradually to find which part causes the
> > trouble.
> > 
> > Duncan Murdoch
> 
> I followed your advice - looks like I need some kind of a cast 
> when I assign the values of a C vector to an R vector. I think.

No, but your C is writing places it should not.

> Below is an example of something that doesn't work - 
> Can someone give me a hand? 
> (In the real function, there are also integer and Character 
> string C vectors...) 
> Thanks.
> 
> #include <R.h>
> #include <Rdefines.h>
> 
> SEXP myfunc() {
>     double *corrs; 
>     corrs[0]=3.0;

You have never assigned storage for corrs[0], so that is getting put 
somewhere random.  It is also illegal C to have an assignment in the 
middle of the declarations.  Try compiling your C with warnings, for 
example -Wall -pedantic under gcc.

>     SEXP Rcorrs; 
>     double *pRcorrs;
>     PROTECT(Rcorrs = NEW_NUMERIC(1));
>     pRcorrs = NUMERIC_POINTER(Rcorrs);
>     pRcorrs[0] = corrs[0];
> 
>     UNPROTECT(1); 
>     return(R_NilValue);
> }
> 
> /*
>  dyn.load("myfunc.so")
>  func<-function().Call("myfunc")
>  func()
> */
> 
> Run it once, it's ok:
> >  func() 
> NULL
> 
> Run it twice, not ok:
> >  func() 
> Error in .Call(NULL) : function name must be a string (of length 1)

This is not an R issue.  Time for a C course, I believe.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Sep  8 08:36:24 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Sep 2004 07:36:24 +0100 (BST)
Subject: [R] 64 bit R slower than 32 bit R on Sun Sparc Solaris?
In-Reply-To: <413E7226.507@jhsph.edu>
Message-ID: <Pine.LNX.4.44.0409080727360.26351-100000@gannet.stats>

On Tue, 7 Sep 2004, Roger D. Peng wrote:

> Are you using an optimized BLAS for both builds?  That's one
> possibility.  Also, 64-bit builds use up more memory initially since the
> pointers are bigger.  I've tried both 64-bit and 32-bit builds on
> Sparc/Solaris and haven't seen any slowdown.

It uses more memory at all times and so gc() takes longer.  There *is* a
slowdown, for example 90 vs 80 secs for a run of R-devel's stats-Ex.R (for
either Sun's Forte 7 or gcc 3.4.1 compilers).  But `25-30% slower' is
unexpected and needs investigation.

The only difference between 32-bit and 64-bit versions of R on Solaris 
will be the size of the pointers and (probably) less efficient PIC code.
There is no reason to expect a performance boost with 64-bit applications: 
they have to do more work and are only worthwhile if you need the address 
space (in memory or also on disc as 64-bit applications use large files 
natively).


> Jason Liao wrote:
> 
> > Hello, everyone! I guess no one is still using R on Sun Sparc these
> > days. But our department has a (pretty new) two-CPU Sun server. We
> > recently compiled R as a 64 bit application and expected a performance
> > boost. But it runs 25-30% slower than the 32 bit version of R. Anyone
> > knows why this is so? Thanks!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From xmeng at capitalbio.com  Wed Sep  8 03:11:20 2004
From: xmeng at capitalbio.com (=?gb2312?B?w8/QwA==?=)
Date: Wed, 8 Sep 2004 01:11:20 -0000
Subject: [R] Thanks
Message-ID: <294605880.01183@capitalbio.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040908/ee88c584/attachment.pl

From Kevin.Wang at maths.anu.edu.au  Wed Sep  8 02:43:51 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Wed, 8 Sep 2004 00:43:51 -0000
Subject: [R] a little question about R
Message-ID: <Pine.GSO.4.58.0409081043370.19874@yin>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040908/e2aa3f1c/attachment.pl

From p.dalgaard at biostat.ku.dk  Wed Sep  8 10:02:16 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 Sep 2004 10:02:16 +0200
Subject: [R] download of 1.9.1
In-Reply-To: <Pine.GSO.4.58.0409081302440.114@yin>
References: <5.1.1.5.2.20040907194929.024e57f0@molepi.stanford.edu>
	<Pine.GSO.4.58.0409081302440.114@yin>
Message-ID: <x2hdq989yv.fsf@biostat.ku.dk>

Kevin Wang <Kevin.Wang at maths.anu.edu.au> writes:

> Hi,
> 
> On Tue, 7 Sep 2004, Kathy DeRiemer wrote:
> 
> > Hi there,
> >
> > I downloaded version 1.9.1 WinZip file, 9.367 bytes ( so I can update my R
> 
> Ummmm....it doesn't sound right, 9 bytes????

Or 9K ? Still not making sense. The windows install file is rw1091.exe
(not ZIP) and 21180K. Or did you mean a package. If so, which one?

First get the right file...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From sblay at sfu.ca  Wed Sep  8 03:49:56 2004
From: sblay at sfu.ca (Sigal Blay)
Date: Wed, 8 Sep 2004 01:49:56 -0000
Subject: [R] C function name garbled
Message-ID: <20040908014956.GA17542@sfu.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040908/a885e130/attachment.pl

From ripley at stats.ox.ac.uk  Wed Sep  8 10:21:31 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Sep 2004 09:21:31 +0100 (BST)
Subject: [R] download of 1.9.1
In-Reply-To: <x2hdq989yv.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0409080917540.7672-100000@gannet.stats>

On 8 Sep 2004, Peter Dalgaard wrote:

> Kevin Wang <Kevin.Wang at maths.anu.edu.au> writes:
> > On Tue, 7 Sep 2004, Kathy DeRiemer wrote:
> > > I downloaded version 1.9.1 WinZip file, 9.367 bytes (so I can update my R
> > 
> > Ummmm....it doesn't sound right, 9 bytes????
> 
> Or 9K ? Still not making sense. 

R-1.9.1.tgz will be associated with WinZip on Windows if that program is 
installed.  And it is 9,367Kb.

> The windows install file is rw1091.exe
> (not ZIP) and 21180K. Or did you mean a package. If so, which one?
> 
> First get the right file...

Indeed.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jg_liao at yahoo.com  Wed Sep  8 04:04:27 2004
From: jg_liao at yahoo.com (Jason Liao)
Date: Wed, 8 Sep 2004 02:04:27 -0000
Subject: [R] 64 bit R slower than 32 bit R on Sun Sparc Solaris?
Message-ID: <20040908020427.85049.qmail@web53708.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040908/678f6cdd/attachment.pl

From mrufino at ipimar.ualg.pt  Wed Sep  8 11:22:11 2004
From: mrufino at ipimar.ualg.pt (Marta Rufino)
Date: Wed, 8 Sep 2004 10:22:11 +0100
Subject: [R] heatmap help
References: <DEEEIJAKFKHHOHEFAAEIEEAKCKAA.pwlepp@cmgm.stanford.edu>
Message-ID: <010301c49585$5279f5d0$0b1a0e0a@PORTATILMARTA>

Hello,


I was just doing heatmaps myself ;-) and I had the same problem. It would be
nice to have such an example in the help file because it is not clear (thank
you).
you use (for example... this is my case, which I am doing the distance
matrix using vegdist function with Bray curtis similarity):

heatmap(matrix, scale="none", distfun=function(m) vegdist(m, method="bray"),
hclustfun=function(m) hclust(m, method="average"), col=
grey(seq(0.8,0,l=5)))

or you can put directly the distance matrix that you may want, but I found
it worst. To have the right labels on I found that the best way would be to
have them in the matrix directely, because if we put it after it does not
work well...

I have been having difficulties in producing the scale that I want and doing
the correct legend...
I found an email with a function (image.scale()), but it does not work
entirely well.
How can I define the values I want in the scale, for example, use red for 1
g, blue for 2 g, etc...
Is there a simpler way of doing the legend?

thank you very much,
Marta


> Dear R wizards,
> Hopeful someone can help me with what I believe is a pretty simple task.
I
> pretty new to R so some (much) of the obvious escapes me. How do I get a
> distance matrix into heatmap?  What do I tell distfun if what I'm trying
to
> map is already an ordered distance matrix?  I tried >heatmap(x,
> distfun=as.dist(x)) where x is the distance matrix but R gave me an error.
> Thanks in advance for any help.
>
> Paul Lepp
>
>  `-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.
>    `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`
>      >==/        >==/        >==/        >==/        >==/
>    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,
> ,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'
> Paul Lepp, Ph.D.                       Stanford School of Medicine
>
> VAPAHCS, 154T                   Dept. of Microbiology & Immunology
> 3801 Miranda Ave                               Stanford University
> Palo Alto, CA 94304                                   Stanford, CA
> (650) 493-5000 x66762                fax: (650) 852-3291
> http://cmgm.stanford.edu/~pwlepp          pwlepp at cmgm.stanford.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From machud at intellektik.informatik.tu-darmstadt.de  Wed Sep  8 11:18:48 2004
From: machud at intellektik.informatik.tu-darmstadt.de (Marco Chiarandini)
Date: Wed, 8 Sep 2004 11:18:48 +0200 (CEST)
Subject: [R] Multiple comparisons in a non parametric case
In-Reply-To: <200409072216.i87MGUwf010767@erdos.math.unb.ca>
References: <200409072216.i87MGUwf010767@erdos.math.unb.ca>
Message-ID: <Pine.LNX.4.58.0409081031240.1624@kika.intellektik.informatik.tu-darmstadt.de>

Thanks Rolf and Thomas,


> It looks to me like what you are doing is trying to judge
> significance of differences by non-overlap of single-sample
> confidence intervals.  While this is appealing, it's not quite
> right.


Yes, this is what I am trying to do. Apparently, when the replicates are
the same for each experimental unit and the experiment is balanced the
CI should be the same for all sample-pairs, therefore it is somehow like
having single sample CI.


> I just looked into my copy of Applied Nonparametric Statistics
> (second ed.) by Wayne W. Daniel (Duxbury, 1990) but that
> only deals with the situation where there is a single replicate
> per block-treatment combination (whereas you have 10 reps)
> and block-treatment interaction is assumed to be non-existent.


The problems (or instances of problems) are my blocking factor. But this
factor has significant interaction in the ANOVA model.


> The method that Daniel prescribes in this simple setting seems to be
> no more than applying the Bonferroni method of multiple comparisons.
> (Daniel does not say; his book is very much a cook-book.)  So you
> might simply try Bonferroni --- i.e. do all k-choose-2 pairwise
> comparisons between treatments (using the appropriate 2 sample method
> for each comparison) doing each comparison at the alpha/k-choose-2
> significance level.  Where k = the number of treatments = 4 in your
> case.  This method is not going to be super-powerful but it is
> sometimes surprizing how well Bonferroni stacks up against more
> ``sophisticated'' methods.


I knew about Bonferroni. But I am confused. I have actually two
references: Conover "Practical Nonparametric statistics" (page 371) and
Sheskin "Handbook and Nonparmetric statistical procedures" (page
675). Both these books deal with multiple comparison when the Friedman
test would be appropriate. But the formula given are different and the
CI I obtain are also different.

Sheskin, citing various sources (among them Daniel 1990), uses a formula
with the normal distribution z and adjust the alfa value according to
Bonferroni (strangely no sample statistic appears in the formula).
Conover (which is also a good reference) uses a formula with Student't
distribution but does not adjust alfa either in the example he provides
where 4 treatments are pairwise compared.

The CI I obtain are much smaller if I use the Conover procedure than the
Sheskin's. And this happens in spite of the p-adjustment in Sheskin.
Smaller CI are for me nicer because I can distinguish better differences
But the a factor of 3 between them let me doubt I can really use
Conover.

Which is your opinion?


Thansk again for the help,

Ragards,

	Marco




--
Marco Chiarandini, Fachgebiet Intellektik, Fachbereich Informatik,
Technische Universit??t Darmstadt, Hochschulstra??e 10,
D-64289 Darmstadt - Germany, Office: S2/02 Raum E317
Tel: +49 (0)6151 16-6802 Fax: +49 (0)6151 16-5326
email: machud at intellektik.informatik.tu-darmstadt.de
web page: http://www.intellektik.informatik.tu-darmstadt.de/~machud



From mrufino at ipimar.ualg.pt  Wed Sep  8 12:06:38 2004
From: mrufino at ipimar.ualg.pt (Marta Rufino)
Date: Wed, 8 Sep 2004 11:06:38 +0100
Subject: [R] plot.dendrogram
Message-ID: <01ed01c4958c$3c41c5c0$0b1a0e0a@PORTATILMARTA>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040908/cd65d84b/attachment.pl

From jg_liao at yahoo.com  Wed Sep  8 13:48:26 2004
From: jg_liao at yahoo.com (Jason Liao)
Date: Wed, 8 Sep 2004 04:48:26 -0700 (PDT)
Subject: [R] 64 bit R slower than 32 bit R on Sun Sparc Solaris?
In-Reply-To: <Pine.LNX.4.44.0409080727360.26351-100000@gannet.stats>
Message-ID: <20040908114826.36591.qmail@web53708.mail.yahoo.com>

Thank you very much, Profs. Ripley and Peng! It corrected a big
misconception in my mind. 

By the way, does the Sun Forte 7 compiler produce faster R than the GCC
3.4.1 compiler (which we use)?

Jason

--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On Tue, 7 Sep 2004, Roger D. Peng wrote:
> 
> > Are you using an optimized BLAS for both builds?  That's one
> > possibility.  Also, 64-bit builds use up more memory initially
> since the
> > pointers are bigger.  I've tried both 64-bit and 32-bit builds on
> > Sparc/Solaris and haven't seen any slowdown.
> 
> It uses more memory at all times and so gc() takes longer.  There
> *is* a
> slowdown, for example 90 vs 80 secs for a run of R-devel's stats-Ex.R
> (for
> either Sun's Forte 7 or gcc 3.4.1 compilers).  But `25-30% slower' is
> unexpected and needs investigation.
> 
> The only difference between 32-bit and 64-bit versions of R on
> Solaris 
> will be the size of the pointers and (probably) less efficient PIC
> code.
> There is no reason to expect a performance boost with 64-bit
> applications: 
> they have to do more work and are only worthwhile if you need the
> address 
> space (in memory or also on disc as 64-bit applications use large
> files 
> natively).
> 
> 
> > Jason Liao wrote:
> > 
> > > Hello, everyone! I guess no one is still using R on Sun Sparc
> these
> > > days. But our department has a (pretty new) two-CPU Sun server.
> We
> > > recently compiled R as a 64 bit application and expected a
> performance
> > > boost. But it runs 25-30% slower than the 32 bit version of R.
> Anyone
> > > knows why this is so? Thanks!
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 


=====
Jason Liao, http://www.geocities.com/jg_liao
Dept. of Biostatistics, http://www2.umdnj.edu/bmtrxweb
University of Medicine and Dentistry of New Jersey
phone 732-235-5429, School of Public Health office
phone 732-235-8611, Cancer Institute of New Jersey office
moble phone 908-720-4205



From ripley at stats.ox.ac.uk  Wed Sep  8 14:10:57 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Sep 2004 13:10:57 +0100 (BST)
Subject: [R] 64 bit R slower than 32 bit R on Sun Sparc Solaris?
In-Reply-To: <20040908114826.36591.qmail@web53708.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0409081307330.13451-100000@gannet.stats>

On Wed, 8 Sep 2004, Jason Liao wrote:

> Thank you very much, Profs. Ripley and Peng! It corrected a big
> misconception in my mind. 
> 
> By the way, does the Sun Forte 7 compiler produce faster R than the GCC
> 3.4.1 compiler (which we use)?

Not in my experience, although libsunperf helps a lot on some problems
(but ATLAS seems competitive).  I mainly use Forte 7 to test the validity 
of source code: gcc is far too generous, especially as is compiles `GNU 
Fortran' not ISO Fortran.

> 
> Jason
> 
> --- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> 
> > On Tue, 7 Sep 2004, Roger D. Peng wrote:
> > 
> > > Are you using an optimized BLAS for both builds?  That's one
> > > possibility.  Also, 64-bit builds use up more memory initially
> > since the
> > > pointers are bigger.  I've tried both 64-bit and 32-bit builds on
> > > Sparc/Solaris and haven't seen any slowdown.
> > 
> > It uses more memory at all times and so gc() takes longer.  There
> > *is* a
> > slowdown, for example 90 vs 80 secs for a run of R-devel's stats-Ex.R
> > (for
> > either Sun's Forte 7 or gcc 3.4.1 compilers).  But `25-30% slower' is
> > unexpected and needs investigation.
> > 
> > The only difference between 32-bit and 64-bit versions of R on
> > Solaris 
> > will be the size of the pointers and (probably) less efficient PIC
> > code.
> > There is no reason to expect a performance boost with 64-bit
> > applications: 
> > they have to do more work and are only worthwhile if you need the
> > address 
> > space (in memory or also on disc as 64-bit applications use large
> > files 
> > natively).
> > 
> > 
> > > Jason Liao wrote:
> > > 
> > > > Hello, everyone! I guess no one is still using R on Sun Sparc
> > these
> > > > days. But our department has a (pretty new) two-CPU Sun server.
> > We
> > > > recently compiled R as a 64 bit application and expected a
> > performance
> > > > boost. But it runs 25-30% slower than the 32 bit version of R.
> > Anyone
> > > > knows why this is so? Thanks!
> > 
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > 
> > 
> 
> 
> =====
> Jason Liao, http://www.geocities.com/jg_liao
> Dept. of Biostatistics, http://www2.umdnj.edu/bmtrxweb
> University of Medicine and Dentistry of New Jersey
> phone 732-235-5429, School of Public Health office
> phone 732-235-8611, Cancer Institute of New Jersey office
> moble phone 908-720-4205
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From paul.hussein at jrc.it  Wed Sep  8 14:33:39 2004
From: paul.hussein at jrc.it (Paul Hussein)
Date: Wed, 8 Sep 2004 14:33:39 +0200
Subject: [R] Contract for an R and Stats specialist
Message-ID: <OOEEIMPPLBBAGFEHHFBEEELMCEAA.paul.hussein@jrc.it>

Hi all,

We have a genuine requirement for 

Statistical Programmer with experience and knowledge of:

.     R programming, and

.     Oracle data base


This is to work on an a short term project for a research centre in italy.



If anyone would like further information, please feel free to email me.


Regards

Paul.



From HDoran at air.org  Wed Sep  8 14:59:47 2004
From: HDoran at air.org (Doran, Harold)
Date: Wed, 8 Sep 2004 08:59:47 -0400
Subject: [R] isoMDS
Message-ID: <88EAF3512A55DF46B06B1954AEF73F74053F9673@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040908/91f606cf/attachment.pl

From petertait at sympatico.ca  Wed Sep  8 15:46:21 2004
From: petertait at sympatico.ca (petertait@sympatico.ca)
Date: Wed, 8 Sep 2004 9:46:21 -0400
Subject: [R] Case-Cohort Analysis
Message-ID: <20040908134621.RTYI11007.tomts14-srv.bellnexxia.net@mxmta.bellnexxia.net>

Hi All,
I am in the middle of doing an analysis of a Case-Cohort design. I had three questions about the analysis: 

a) Does any one know of some public code for developing the patient risk sets (indexed by failure time) or is there a better way to organize the data? 

b) I was planning to use the Barlow weighting method. Has this or any other weighting method (Prentice, Self-Prentice) been implemented in R?

c) Is matching a good thing to do or can the variables that would be used for matching just be adjusted for in the cox regression (is there a reference for this because I can??t find one)?  If matching is a good thing to do are there any R packages that contain matching functions?

Thanks for your help.
Peter Tait



From ramasamy at cancer.org.uk  Wed Sep  8 15:49:07 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 08 Sep 2004 14:49:07 +0100
Subject: [R] plot.dendrogram
In-Reply-To: <01ed01c4958c$3c41c5c0$0b1a0e0a@PORTATILMARTA>
References: <01ed01c4958c$3c41c5c0$0b1a0e0a@PORTATILMARTA>
Message-ID: <1094651346.3040.60.camel@vpn202001.lif.icnet.uk>

Try setting something like "cex=0.5" in the plot. It works for at least
hclust. Here is a quick example using hclust to show how you can get
away with set the colours.

data(USArrests)
hc <- hclust(dist(USArrests), "ave")

plot(hc, hang=-1, cex=0.5)
labels <- rownames(USArrests)[ hc$order]; n <- length(labels)
mtext(labels, side=1, at=1:n, las=2, col=1:n, cex=0.5, line=0)

If you want to get rid of the double labelling (which is useful for
checking), then set "labels=FALSE" in the plot().


The trick now becomes how to generalise this to other dendrogram and
when "hang=-1" is not the case. 

My initial though was to look into plot.hclust to see how the coordinate
for label placement was calculated and replace it with text(...,
col=col.label). But it appears that this is done with a ".Internal"
function and I have not learned how to read/edit this yet.




On Wed, 2004-09-08 at 11:06, Marta Rufino wrote:
> Dear R-users,
> 
> I would like to change the labels size and format in the node ends of a dendrogram, how can I do it?
> How can I use different symbols/colors in each node ends ?
> 
> 
> I manage to do it with plot.cluster, but heat map uses plot.dendrogram.
> 
> 
> Can anyone help me please?
> thank you
> Marta
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Wed Sep  8 15:57:52 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Sep 2004 14:57:52 +0100 (BST)
Subject: [R] isoMDS
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F74053F9673@dc1ex2.air.org>
Message-ID: <Pine.LNX.4.44.0409081453030.22688-100000@gannet.stats>

On Wed, 8 Sep 2004, Doran, Harold wrote:

> 1)	Can isoMDS work only with dissimilarities? Or, is there a way
> that it can perform the analysis on the similarity matrix as I have
> described it?

Yes.  The method, as well as the function in package MASS.  All other 
MDS packages are doing a conversion, probably without telling you how.

> 2)	If I cannot perform the analysis on the similarity matrix, how
> can I turn this matrix into a dissimilarity matrix necessary? I am less
> familiar with this matrix and how it would be constructed?

Normally similarities are in the range [0,1], and people use D = 1 - S or
sqrt(1-S). (Which does not matter for isoMDS since it only uses ranks of
dissimilarities, apart from finding the starting configuration.)  See the
references on the help page for isoMDS.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From stefan.albrecht at allianz.com  Wed Sep  8 16:06:52 2004
From: stefan.albrecht at allianz.com (stefan.albrecht@allianz.com)
Date: Wed, 8 Sep 2004 16:06:52 +0200
Subject: [R] Stefan Albrecht/HV/Finanzen/Allianz-Sach ist
 =?iso-8859-1?q?au=DF?=
 =?iso-8859-1?q?er_Haus=2E_=3A_R-help_Digest=2C_Vol_19=2C_Issue_8?=
Message-ID: <OF318477C0.E69FB5AD-ONC1256F09.004D88A9@inside.allianz.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040908/f28c458f/attachment.pl

From rksh at soc.soton.ac.uk  Wed Sep  8 16:08:09 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Wed, 8 Sep 2004 15:08:09 +0100
Subject: [R] do.call("[", ...) question
Message-ID: <a06002001bd64c1e41a9b@[139.166.242.29]>

Hi again everyone

I have an arbitrarily dimensional array "a" and a list "jj" of length
length(dim(a)).    The elements of jj are vectors of indexes.

How do I use do.call() to extract a[ jj[[1]], jj[[2]], jj[[3]], ...] ?


Toy example follows:

a <- matrix(1:30,5,6)
jj <- list(5:1,6:1)

I want the following

  a[ jj[[1]],jj[[2]] ]

How do I do this?



OBAttempts:

do.call("[",list(a,jj))
do.call("[",c(a,jj))
do.call("[",list(a,unlist(jj)))


Of course, the one that works is

do.call("[",list(a,jj[[1]],jj[[2]]))

but I don't know how long jj is apriori so this won't do.
-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Sep  8 16:25:53 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 8 Sep 2004 16:25:53 +0200
Subject: [R] do.call("[", ...) question
References: <a06002001bd64c1e41a9b@[139.166.242.29]>
Message-ID: <000901c495af$bf96e810$b2133a86@www.domain>

Hi Robin,

you could try the following:

lis <- lapply(seq(1, length(dim(a))+1), function(x,a.,jj.) if(x==1) a.
else jj.[[x-1]] ,a.=a, jj.=jj)
do.call("[",lis)

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm/

----- Original Message ----- 
From: "Robin Hankin" <rksh at soc.soton.ac.uk>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, September 08, 2004 4:08 PM
Subject: [R] do.call("[", ...) question


> Hi again everyone
>
> I have an arbitrarily dimensional array "a" and a list "jj" of
length
> length(dim(a)).    The elements of jj are vectors of indexes.
>
> How do I use do.call() to extract a[ jj[[1]], jj[[2]], jj[[3]], ...]
?
>
>
> Toy example follows:
>
> a <- matrix(1:30,5,6)
> jj <- list(5:1,6:1)
>
> I want the following
>
>   a[ jj[[1]],jj[[2]] ]
>
> How do I do this?
>
>
>
> OBAttempts:
>
> do.call("[",list(a,jj))
> do.call("[",c(a,jj))
> do.call("[",list(a,unlist(jj)))
>
>
> Of course, the one that works is
>
> do.call("[",list(a,jj[[1]],jj[[2]]))
>
> but I don't know how long jj is apriori so this won't do.
> -- 
> Robin Hankin
> Uncertainty Analyst
> Southampton Oceanography Centre
> SO14 3ZH
> tel +44(0)23-8059-7743
> initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam
precaution)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From HankeA at mar.dfo-mpo.gc.ca  Wed Sep  8 16:35:51 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Wed, 08 Sep 2004 11:35:51 -0300
Subject: [R] isoMDS
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE124A1C@msgmarsta01.bio.dfo.ca>

Distances cannot always be constructed from similarities. This can be done
only if the matrix of similarities is nonnegative definite. With the
nonnegative definite condition, and with the maximum similarity scaled so
that s_ii=1, d_ik=(2*(1-s_ik))^-.5

Check out the vegan package.
Alex

-----Original Message-----
From: Doran, Harold [mailto:HDoran at air.org] 
Sent: September 8, 2004 10:00 AM
To: r-help at stat.math.ethz.ch
Cc: Doran, Harold
Subject: [R] isoMDS


Dear List:

I have a question regarding an MDS procedure that I am accustomed to
using. I have searched around the archives a bit and the help doc and
still need a little assistance. The package isoMDS is what I need to
perform the non-metric scaling, but I am working with similarity
matrices, not dissimilarities. The question may end up being resolved
simply.

Here is a bit of substantive background. I am working on a technique
where individuals organize items based on how similar they perceive the
items to be. For example, assume there are 10 items. Person 1 might
group items 1,2,3,4,5 in group 1 and the others in group 2. I then turn
this grouping into a binomial similarity matrix. The following is a
sample matrix for Person 1 based on this hypothetical grouping. The off
diagonals are the similar items with the 1's representing similarities. 
  a b c d e f g h i j
a 1 1 1 1 1 0 0 0 0 0
b 1 1 1 1 1 0 0 0 0 0
c 1 1 1 1 1 0 0 0 0 0
d 1 1 1 1 1 0 0 0 0 0
e 1 1 1 1 1 0 0 0 0 0
f 0 0 0 0 0 1 1 1 1 1
g 0 0 0 0 0 1 1 1 1 1
h 0 0 0 0 0 1 1 1 1 1
i 0 0 0 0 0 1 1 1 1 1
j 0 0 0 0 0 1 1 1 1 1


Each of these individual matrices are summed over individuals. So, in
this summed matrix diagonal elements represent the total number of
participants and the off-diagonals represent the number of times an item
was viewed as being similar by members of the group (obviously the
matrix is symmetric below the diagonal). So, a "4" in row 'a' column 'c'
means that these items were viewed as being similar by 4 people. A
sample total matrix is at the bottom of this email describing the
perceived similarities of 10 items across 4 individuals.

It is this total matrix that I end up working with in the MDS. I have
previously worked in systat where I run the MDS and specify the matrix
as a similarity matrix. I then take the resulting data from the MDS and
perform a k-means cluster analysis to identify which items belong to a
particular cluster, centroids, etc.

So, here are my questions. 

1)	Can isoMDS work only with dissimilarities? Or, is there a way
that it can perform the analysis on the similarity matrix as I have
described it?
2)	If I cannot perform the analysis on the similarity matrix, how
can I turn this matrix into a dissimilarity matrix necessary? I am less
familiar with this matrix and how it would be constructed?

Thanks for any help offered,

Harold 


  a b c d e f g h i j
a 4 2 4 3 3 2 0 0 0 0
b 2 4 2 3 1 0 2 2 2 2
c 4 2 4 3 3 2 0 0 0 0
d 3 3 3 4 2 1 1 1 1 1
e 3 1 3 2 4 3 1 1 1 1
f 2 0 2 1 3 4 2 2 2 2
g 0 2 0 1 1 2 4 4 4 4
h 0 2 0 1 1 2 4 4 4 4
i 0 2 0 1 1 2 4 4 4 4
j 0 2 0 1 1 2 4 4 4 4

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Wed Sep  8 16:44:49 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 Sep 2004 16:44:49 +0200
Subject: [R] do.call("[", ...) question
In-Reply-To: <a06002001bd64c1e41a9b@[139.166.242.29]>
References: <a06002001bd64c1e41a9b@[139.166.242.29]>
Message-ID: <x2u0u87rby.fsf@biostat.ku.dk>

Robin Hankin <rksh at soc.soton.ac.uk> writes:

> Hi again everyone
> 
> I have an arbitrarily dimensional array "a" and a list "jj" of length
> length(dim(a)).    The elements of jj are vectors of indexes.
> 
> How do I use do.call() to extract a[ jj[[1]], jj[[2]], jj[[3]], ...] ?
> 
> 
> Toy example follows:
> 
> a <- matrix(1:30,5,6)
> jj <- list(5:1,6:1)
> 
> I want the following
> 
>   a[ jj[[1]],jj[[2]] ]
> 
> How do I do this?
> 
> 
> 
> OBAttempts:
> 
> do.call("[",list(a,jj))
> do.call("[",c(a,jj))
> do.call("[",list(a,unlist(jj)))
> 
> 
> Of course, the one that works is
> 
> do.call("[",list(a,jj[[1]],jj[[2]]))
> 
> but I don't know how long jj is apriori so this won't do.


do.call("[",c(list(a),jj))


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Wed Sep  8 16:58:01 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Sep 2004 15:58:01 +0100 (BST)
Subject: [R] isoMDS
In-Reply-To: <E37EEC6DE3A0C5439B7E7B07406C24AE124A1C@msgmarsta01.bio.dfo.ca>
Message-ID: <Pine.LNX.4.44.0409081557280.22757-100000@gannet.stats>

On Wed, 8 Sep 2004, Hanke, Alex wrote:

> Distances cannot always be constructed from similarities. This can be done
> only if the matrix of similarities is nonnegative definite. With the
> nonnegative definite condition, and with the maximum similarity scaled so
> that s_ii=1, d_ik=(2*(1-s_ik))^-.5

But isoMDDS works with dissimilarities not distances.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wolski at molgen.mpg.de  Wed Sep  8 17:46:51 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Wed, 08 Sep 2004 17:46:51 +0200
Subject: [R] Sweave echoing comments (again)
In-Reply-To: <413C4A66.30008@hhbio.wasser.tu-dresden.de>
References: <413C4A66.30008@hhbio.wasser.tu-dresden.de>
Message-ID: <200409081746510955.0C476E9B@mail.math.fu-berlin.de>

Hi!

I observed it also. There are cases where it is not desirable. It will be quite helpfull, if possible, to have a parameter that allows one to switch of removing the #comments. 

/E

*********** REPLY SEPARATOR  ***********

On 9/6/2004 at 1:30 PM Thomas Petzoldt wrote:

>>>Hello,
>>>
>>>I try to document some R scripts for my collegues and observed the 
>>>problem, that Sweave strips comment lines away.
>>>
>>>As a small example I write in an Rtex file:
>>>
>>>\begin{Scode}
>>>## a small example
>>>test() # line comment
>>>\end{Scode}
>>>
>>>... the .tex file generated by Sweave only contains:
>>>
>>>\begin{Schunk}
>>>\begin{Sinput}
>>>  test()
>>>\end{Sinput}
>>>\end{Schunk}
>>>
>>>
>>>... and all the comments are lost. Looking into the archives, I found, 
>>>that such a question appeared already some months ago. Are there any 
>>>advances or workarounds doing such things today?
>>>
>>>Thank you in advance!
>>>
>>>Thomas P.
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin                'v'    
tel: 0049-30-83875219                        /   \       
mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
      wolski at molgen.mpg.de



From HankeA at mar.dfo-mpo.gc.ca  Wed Sep  8 18:08:42 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Wed, 08 Sep 2004 13:08:42 -0300
Subject: [R] isoMDS
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE124A1E@msgmarsta01.bio.dfo.ca>

I don't understand.
If isoMDS does not work with distances, why does the help for isoMDS
indicate that the "Data are assumed to be dissimilarities or relative
distances" ? 
Equally confusing is the loose use of the terms dissimilarities and
distances in the literature. As you point out in your book "Distances are
often called disimilarities". 

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: September 8, 2004 11:58 AM
To: Hanke, Alex
Cc: 'Doran, Harold'; 'r-help at stat.math.ethz.ch'
Subject: RE: [R] isoMDS


On Wed, 8 Sep 2004, Hanke, Alex wrote:

> Distances cannot always be constructed from similarities. This can be done
> only if the matrix of similarities is nonnegative definite. With the
> nonnegative definite condition, and with the maximum similarity scaled so
> that s_ii=1, d_ik=(2*(1-s_ik))^-.5

But isoMDDS works with dissimilarities not distances.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From adele at math.usu.edu  Wed Sep  8 18:20:15 2004
From: adele at math.usu.edu (Adele Cutler)
Date: Wed, 8 Sep 2004 10:20:15 -0600
Subject: [R] local linear embedding
Message-ID: <PKEMLPIILHFCOEGLMKBLGEBLCNAA.adele@math.usu.edu>


Is anyone working on interfacing local linear embedding (Saul and Roweis) to
R?

The only mention I found was in the article "Dimension Reduction for Data
Mapping" (Edwards and Oman) in RNews 3/3.

Adele



From kbartz at loyaltymatrix.com  Wed Sep  8 18:25:29 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Wed, 8 Sep 2004 09:25:29 -0700
Subject: [R] do.call("[", ...) question
In-Reply-To: <a06002001bd64c1e41a9b@[139.166.242.29]>
Message-ID: <20040908162530.40E84400B1@omta14.mta.everyone.net>

This worked very well for me:

do.call("[", c(list(a), jj))

What about you?

Kevin

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Robin Hankin
Sent: Wednesday, September 08, 2004 7:08 AM
To: r-help at stat.math.ethz.ch
Subject: [R] do.call("[", ...) question

Hi again everyone

I have an arbitrarily dimensional array "a" and a list "jj" of length
length(dim(a)).    The elements of jj are vectors of indexes.

How do I use do.call() to extract a[ jj[[1]], jj[[2]], jj[[3]], ...] ?


Toy example follows:

a <- matrix(1:30,5,6)
jj <- list(5:1,6:1)

I want the following

  a[ jj[[1]],jj[[2]] ]

How do I do this?



OBAttempts:

do.call("[",list(a,jj))
do.call("[",c(a,jj))
do.call("[",list(a,unlist(jj)))


Of course, the one that works is

do.call("[",list(a,jj[[1]],jj[[2]]))

but I don't know how long jj is apriori so this won't do.
-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Wed Sep  8 19:03:15 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 8 Sep 2004 13:03:15 -0400
Subject: [R] local linear embedding
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8341@usrymx25.merck.com>

Hi Adele,

The Matlab code at http://www.cs.toronto.edu/~roweis/lle/code/lle.m seems
fairly straightforward to translate to R, so that would be the first thing
I'd try.  However, one can obviously use better algorithms for sub-tasks
within that code, e.g., for finding k-NNs.

Best,
Andy

> From: Adele Cutler
> 
> Is anyone working on interfacing local linear embedding (Saul 
> and Roweis) to
> R?
> 
> The only mention I found was in the article "Dimension 
> Reduction for Data
> Mapping" (Edwards and Oman) in RNews 3/3.
> 
> Adele
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From elynchabeth at hotmail.com  Wed Sep  8 19:54:47 2004
From: elynchabeth at hotmail.com (Elizabeth Lynch)
Date: Wed, 08 Sep 2004 13:54:47 -0400
Subject: [R] degrees of freedom (lme4 and nlme)
Message-ID: <BAY2-F6IDk4JdxVHYEu00005f8f@hotmail.com>

Hi,

I'm looking for pointers/references on calculating den DF's for fixed 
effects when using crossed random effects. Also, is there an implementation 
of simulate.lme that I could use in lme4?

Thanks,

Elizabeth Lynch

Douglas Bates wrote:
>Alexandre Galvão Patriota wrote:
>
>>Hi, I'm having some problems regarding the packages
>>lme4 and nlme, more specifically in the denominator
>>degrees of freedom. <SNIP>
>
>
>The lme4 package is under development and only has a stub for the code that 
>calculates the denominator degrees of freedom.
>
>These Wald-type tests using the F and t distributions are approximations at 
>best.  In that sense there is no "correct" degrees of freedom.  I think the 
>more accurate tests may end up being the restricted likelihood ratio tests 
>that Greg Reinsel and his student Mr. Ahn were working on at the time of 
>Greg's death.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html





From ihok at hotmail.com  Wed Sep  8 20:01:29 2004
From: ihok at hotmail.com (Jack Tanner)
Date: Wed, 08 Sep 2004 14:01:29 -0400
Subject: [R] rodbc windows doesn't find dsn
In-Reply-To: <Pine.LNX.4.44.0409071609050.27491-100000@gannet.stats>
References: <Pine.LNX.4.44.0409071609050.27491-100000@gannet.stats>
Message-ID: <413F48F9.2030509@hotmail.com>

Prof Brian Ripley wrote:
> Well, we don't know what you are doing!  RODBC does work with system DSNs,
> but did you try odbcDriverConnect?  Let me read the help page for you 

odbcDriverConnect("DSN=foo") works, but odbcConnect("foo") fails as
described earlier. Is this as intended?

This seems weird, because odbcConnect("foo") works under Linux for
connecting to the same database (using the same version of the MySQL
ODBC driver, and unixODBC, but a user DSN).



From pwlepp at pmgm2.stanford.edu  Wed Sep  8 20:06:33 2004
From: pwlepp at pmgm2.stanford.edu (Paul Lepp)
Date: Wed, 8 Sep 2004 11:06:33 -0700
Subject: [R] heatmap help
In-Reply-To: <010301c49585$5279f5d0$0b1a0e0a@PORTATILMARTA>
Message-ID: <DEEEIJAKFKHHOHEFAAEIOEANCKAA.pwlepp@cmgm.stanford.edu>

Thanks Marta (and Andy).  Between the two of you I think I got the result I
was looking for.  I ended up doing the following:

heatmap(x, distfun=function(x) as.dist(x))

Thanks again.

> -----Original Message-----
> From: Marta Rufino [mailto:mrufino at ipimar.ualg.pt]
> Sent: Wednesday, September 08, 2004 2:22 AM
> To: pwlepp at pmgm2.Stanford.EDU
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] heatmap help
>
>
> Hello,
>
>
> I was just doing heatmaps myself ;-) and I had the same problem.
> It would be
> nice to have such an example in the help file because it is not
> clear (thank
> you).
> you use (for example... this is my case, which I am doing the distance
> matrix using vegdist function with Bray curtis similarity):
>
> heatmap(matrix, scale="none", distfun=function(m) vegdist(m,
> method="bray"),
> hclustfun=function(m) hclust(m, method="average"), col=
> grey(seq(0.8,0,l=5)))
>
> or you can put directly the distance matrix that you may want, but I found
> it worst. To have the right labels on I found that the best way
> would be to
> have them in the matrix directely, because if we put it after it does not
> work well...
>
> I have been having difficulties in producing the scale that I
> want and doing
> the correct legend...
> I found an email with a function (image.scale()), but it does not work
> entirely well.
> How can I define the values I want in the scale, for example, use
> red for 1
> g, blue for 2 g, etc...
> Is there a simpler way of doing the legend?
>
> thank you very much,
> Marta
>
>
> > Dear R wizards,
> > Hopeful someone can help me with what I believe is a pretty simple task.
> I
> > pretty new to R so some (much) of the obvious escapes me. How do I get a
> > distance matrix into heatmap?  What do I tell distfun if what I'm trying
> to
> > map is already an ordered distance matrix?  I tried >heatmap(x,
> > distfun=as.dist(x)) where x is the distance matrix but R gave
> me an error.
> > Thanks in advance for any help.
> >
> > Paul Lepp
> >
> >  `-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.
> >    `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`
> >      >==/        >==/        >==/        >==/        >==/
> >    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,
> > ,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'
> > Paul Lepp, Ph.D.                       Stanford School of Medicine
> >
> > VAPAHCS, 154T                   Dept. of Microbiology & Immunology
> > 3801 Miranda Ave                               Stanford University
> > Palo Alto, CA 94304                                   Stanford, CA
> > (650) 493-5000 x66762                fax: (650) 852-3291
> > http://cmgm.stanford.edu/~pwlepp          pwlepp at cmgm.stanford.edu
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
>



From h.wickham at gmail.com  Wed Sep  8 20:25:34 2004
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 8 Sep 2004 13:25:34 -0500
Subject: [R] Installing packages on OS X
Message-ID: <f8e6ff0504090811251dbd6ca5@mail.gmail.com>

On my computer, it seems that (binary?) packages installed through the
GUI in RAqua are not used available to the command line version of R,
while (source) packages installed with R CMD INSTALL are available to
both.  This is a problem when I run R CMD CHECK on a package that I am
creating that depends on packages I have installed through the gui.

Is this a problem with my installation of R, or a known limitation?
(there is no mention of this in the Mac OS X faq, however, the entire
section entitled "Installing packages" is blank).

Thanks,

Hadley



From HDoran at air.org  Wed Sep  8 20:31:19 2004
From: HDoran at air.org (Doran, Harold)
Date: Wed, 8 Sep 2004 14:31:19 -0400
Subject: [R] isoMDS
Message-ID: <88EAF3512A55DF46B06B1954AEF73F74053F98C6@dc1ex2.air.org>

Thank you. Quick clarification. isoMDS only works with dissimilarities.
Converting my similarity matrix into the dissimilarity matrix is done as
(from an email I found on the archives)

> d<- max(tt)-tt

Where tt is the similarity matrix. With this, I tried isoMDS as follows:

> tt.mds<-isoMDS(d)

and I get the following error message. 

Error in isoMDS(d) : An initial configuration must be supplied with
NA/Infs in d. I was a little confused on exactly how to specify this
initial config. So, from here I ran cmdscale on d as

> d.mds<-cmdscale(d)

which seemed to work fine and produce reasonable results. I was able to
take the coordinates and run them through a k-means cluster and the
results seemed to correctly match the grouping structure I created for
this sample analysis.

Cmdscale is for metric scaling, but it seemed to produce the results
correctly. 

So, did I correctly convert the similarity matrix to the dissimilarity
matrix? Second, should I have used cmdscale rather than isoMDS as I have
done? Or, is there a way to specify the initial configuration that I
have not done correctly.

Again, many thanks.

Harold

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Wednesday, September 08, 2004 9:58 AM
To: Doran, Harold
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] isoMDS

On Wed, 8 Sep 2004, Doran, Harold wrote:

> 1)	Can isoMDS work only with dissimilarities? Or, is there a way
> that it can perform the analysis on the similarity matrix as I have
> described it?

Yes.  The method, as well as the function in package MASS.  All other 
MDS packages are doing a conversion, probably without telling you how.

> 2)	If I cannot perform the analysis on the similarity matrix, how
> can I turn this matrix into a dissimilarity matrix necessary? I am
less
> familiar with this matrix and how it would be constructed?

Normally similarities are in the range [0,1], and people use D = 1 - S
or
sqrt(1-S). (Which does not matter for isoMDS since it only uses ranks of
dissimilarities, apart from finding the starting configuration.)  See
the
references on the help page for isoMDS.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ehughes at mrco2.carleton.ca  Wed Sep  8 21:45:33 2004
From: ehughes at mrco2.carleton.ca (Ed Hughes)
Date: Wed, 08 Sep 2004 14:45:33 -0500
Subject: [R] Problems loading Lapack library
Message-ID: <4.3.1.1.20040908144353.00df46a0@134.117.179.14>

I have just installed R 1.9.1 on an old Sun Sparc
with the following specs:
version
Machine hardware:   sun4u
OS version:         5.6
Processor type:     sparc
Hardware:           SUNW,Ultra-4
The following components are installed on your system:
Sun Visual WorkShop C++ 3.0
         Sun WorkShop Compiler C 4.2 
         Sun WorkShop Compiler C++ 4.2 
         Sun WorkShop Tools.h++ 7.0 
         Sun WorkShop Tools.h++ 6.0.4 
         Sun WorkShop Visual 2.0 
         Sun WorkShop IPE 4.0 
         Sun WorkShop CodeManager 2.0 
         Sun WorkShop Distributed Make 2.0 
         Sun WorkShop FileMerge 3.0 
         Sun WorkShop FreezePoint 2.0 
         Sun WorkShop Maketool 2.0 
         Sun WorkShop VersionTool 2.0 
         Sun WorkShop Dbx 4.0 
         Sun WorkShop Performance Analyzer 4.0 
         Sun WorkShop LoopTool 2.1 
         Sun WorkShop LockLint 2.1 
         Sun WorkShop Thread Analyzer 1.2 
         Sun WorkShop XEmacs 20.00 
Sun WorkShop Professional C 3.0
         Sun WorkShop Compiler C 4.2 
         Sun WorkShop IPE 4.0 
         Sun WorkShop Dbx 4.0 
         Sun WorkShop Performance Analyzer 4.0 
         Sun WorkShop IPE 4.0 
Sun WorkShop Compiler FORTRAN 77 4.2 
Sun WorkShop Compiler Fortran 90 1.2 
Sun Performance Library 1.2 

Here are the lines I changed in config.site:

R_PAPERSIZE=letter
CC="cc -xarch=v8plusa"
CFLAGS="-xO3 -dalign"
F77="f90 -xarch=v8plusa"
FFLAGS="-xO3 -dalign"
MAIN_LDFLAGS="-xarch=v8plusa"
LDFLAGS="-L/opt/SUNWspro/lib -L/usr/local/lib"
CXX="CC -xarch=v8plusa"
CXXFLAGS="-xO3 -dalign"
BLAS_LIBS="-xlic_lib=sunperf"
LAPACK_LIBS="-xlic_lib=sunperf"

The configure and make steps finished apparently normally,
but "make check" failed.  I found that R would start, and
do elementary things, but anything involving linear algebra
failed:  for example, I tried the "lm-tests.R" file in the
tests directory, with the following result:

  . . . . . . 

Type 'q()' to quit R.

 > source("tests/lm-tests.R")
Error in La.chol2inv(x, size) : lapack routines cannot be loaded
In addition: Warning message: 
unable to load shared library "/disk4/home4/ehug/newSoft/R-1.9.1/modules/lapack.so":
   ld.so.1: /disk4/home4/ehug/newSoft/R-1.9.1/bin/R.bin: fatal: relocation 
   error: file /disk4/home4/ehug/newSoft/R-1.9.1/bin/libRlapack.so: symbol d_sign: 
   referenced symbol not found 

I don't think "d_sign" is a symbol in Lapack.  Similar things happen 
with any attempt to use functions that involve Lapack.  
Can anyone give me some clues about what's happening?  Any help
would be appreciated.



From gregory_r_warnes at groton.pfizer.com  Wed Sep  8 20:42:24 2004
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Wed, 8 Sep 2004 14:42:24 -0400 
Subject: [R] Contrast matrices for nested factors
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20C521B6F@groexmb02.pfizer.com>

You should be able to get the behavior you want using the fit.glh()  (short
for fit general linear hypothesis) function from the gregmisc/gmodels
package.

-G

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of 
> Fernando Henrique
> Ferraz P. da Rosa
> Sent: Monday, September 06, 2004 11:02 PM
> To: r-help
> Subject: [R] Contrast matrices for nested factors
> 
> 
>         Hi, I'd like to know if it's possible to specify different
> contrast matrices in lm() for a factor that is nested within 
> another one. This
> is useful when we have a model where the nested factor has a different
> number of levels, depending on the main factor.
> 
>         Let me illustrate with an example to make it clearer. Consider
> the following data set:
> 
>         set.seed(1)
>         y <- rnorm(14)
>         a <- factor(c(rep(1,7),rep(2,3),rep(3,4)))
>         b <- factor(c(1,1,1,2,2,3,3,1,1,2,1,1,2,2))
>         k <- factor(c(1,2,3,1,2,1,2,1,2,1,1,2,1,2))
>         internal <- data.frame(y,a,b,k)
> 
>         Where y is an arbitrary response, a is a main factor, b is a
> factor nested within a, and k is the replicate number. It is 
> easy to see
> that depending on the level of a, b has different numbers of 
> levels. For
> instance, when a = 1, we have that b might assume values 1, 2 or 3,
> while a = 2 or 3, b might assume only 1 or 2.
> 
>         I'd like then to use contrasts summing to 0, so I issue:
> 
>         z <- lm(y ~ a + a/b,data=internal,contrasts=list(a=contr.sum,
> b=contr.sum))
> 
>         The problem is, the design matrix is not quite what I 
> expected.
> What happens is, instead of using a different contrast matrix for each
> level of a where b is nested, it's using the same contrast matrix for
> every b, namely:
> 
>         > contr.sum(3)
>   [,1] [,2]
> 1    1    0
> 2    0    1
> 3   -1   -1
> 
>         So, when a=1, the columns of the design matrix are as 
> expected.
> It sums to 0, because there are levels of b 1, 2 and 3, when a=1. But,
> when a=2 or a=3, the same contrast matrix is being used, and then, the
> factor effects do not sum to 0. That's obviously because there are no
>  values for b equal 3, when a != 1, and then the coding that 
> gets done is
>  '0' or '1'.
> 
>         The design matrix lm() is creating is:
> 
> > model.matrix(z)
>    (Intercept) a1 a2 a1:b1 a2:b1 a3:b1 a1:b2 a2:b2 a3:b2
> 1            1  1  0     1     0     0     0     0     0
> 2            1  1  0     1     0     0     0     0     0
> 3            1  1  0     1     0     0     0     0     0
> 4            1  1  0     0     0     0     1     0     0
> 5            1  1  0     0     0     0     1     0     0
> 6            1  1  0    -1     0     0    -1     0     0
> 7            1  1  0    -1     0     0    -1     0     0
> 8            1  0  1     0     1     0     0     0     0
> 9            1  0  1     0     1     0     0     0     0
> 10           1  0  1     0     0     0     0     1     0
> 11           1 -1 -1     0     0     1     0     0     0
> 12           1 -1 -1     0     0     1     0     0     0
> 13           1 -1 -1     0     0     0     0     0     1
> 14           1 -1 -1     0     0     0     0     0     1
> 
> 
>         What I would like to use is:
> 
>    (Intercept) a1 a2 a1:b1 a2:b1 a3:b1 a1:b2    
> 1            1  1  0     1     0     0     0 0 0
> 2            1  1  0     1     0     0     0 0 0
> 3            1  1  0     1     0     0     0 0 0
> 4            1  1  0     0     0     0     1 0 0
> 5            1  1  0     0     0     0     1 0 0
> 6            1  1  0    -1     0     0    -1 0 0
> 7            1  1  0    -1     0     0    -1 0 0
> 8            1  0  1     0     1     0     0 0 0
> 9            1  0  1     0     1     0     0 0 0
> 10           1  0  1     0    -1     0     0 0 0
> 11           1 -1 -1     0     0     1     0 0 0
> 12           1 -1 -1     0     0     1     0 0 0
> 13           1 -1 -1     0     0    -1     0 0 0
> 14           1 -1 -1     0     0    -1     0 0 0
> 
>         (notice that in the second matrix all collumns sum to 
> 0, in the
> first they don't).
> 
> 
>         Thank you,
> 
> --
> Fernando Henrique Ferraz P. da Rosa
> http://www.ime.usp.br/~feferraz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From ripley at stats.ox.ac.uk  Wed Sep  8 21:07:02 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Sep 2004 20:07:02 +0100 (BST)
Subject: [R] Problems loading Lapack library
In-Reply-To: <4.3.1.1.20040908144353.00df46a0@134.117.179.14>
Message-ID: <Pine.LNX.4.44.0409082001490.25249-100000@gannet.stats>

Haven't you sent this before?

d_sign is part of the Fortran runtime support.  Since you are running 
sunperf, you should not have been building libRlapack at all.

Please don't try to outsmart R, but let it decide what configuration to
try.  Once that works, feel free to try to improve it.  My guess is that
your use of sunperf (and *PLEASE* read what the R-admin manual says about
LAPACK_LIBS) is the problem, probably because such an ancient sunperf is
broken (I never managed to get it to work prior to SunPro 6).


On Wed, 8 Sep 2004, Ed Hughes wrote:

> I have just installed R 1.9.1 on an old Sun Sparc
> with the following specs:
> version
> Machine hardware:   sun4u
> OS version:         5.6
> Processor type:     sparc
> Hardware:           SUNW,Ultra-4
> The following components are installed on your system:
> Sun Visual WorkShop C++ 3.0
>          Sun WorkShop Compiler C 4.2 
>          Sun WorkShop Compiler C++ 4.2 
>          Sun WorkShop Tools.h++ 7.0 
>          Sun WorkShop Tools.h++ 6.0.4 
>          Sun WorkShop Visual 2.0 
>          Sun WorkShop IPE 4.0 
>          Sun WorkShop CodeManager 2.0 
>          Sun WorkShop Distributed Make 2.0 
>          Sun WorkShop FileMerge 3.0 
>          Sun WorkShop FreezePoint 2.0 
>          Sun WorkShop Maketool 2.0 
>          Sun WorkShop VersionTool 2.0 
>          Sun WorkShop Dbx 4.0 
>          Sun WorkShop Performance Analyzer 4.0 
>          Sun WorkShop LoopTool 2.1 
>          Sun WorkShop LockLint 2.1 
>          Sun WorkShop Thread Analyzer 1.2 
>          Sun WorkShop XEmacs 20.00 
> Sun WorkShop Professional C 3.0
>          Sun WorkShop Compiler C 4.2 
>          Sun WorkShop IPE 4.0 
>          Sun WorkShop Dbx 4.0 
>          Sun WorkShop Performance Analyzer 4.0 
>          Sun WorkShop IPE 4.0 
> Sun WorkShop Compiler FORTRAN 77 4.2 
> Sun WorkShop Compiler Fortran 90 1.2 
> Sun Performance Library 1.2 
> 
> Here are the lines I changed in config.site:
> 
> R_PAPERSIZE=letter
> CC="cc -xarch=v8plusa"
> CFLAGS="-xO3 -dalign"
> F77="f90 -xarch=v8plusa"
> FFLAGS="-xO3 -dalign"
> MAIN_LDFLAGS="-xarch=v8plusa"
> LDFLAGS="-L/opt/SUNWspro/lib -L/usr/local/lib"
> CXX="CC -xarch=v8plusa"
> CXXFLAGS="-xO3 -dalign"
> BLAS_LIBS="-xlic_lib=sunperf"
> LAPACK_LIBS="-xlic_lib=sunperf"
> 
> The configure and make steps finished apparently normally,
> but "make check" failed.  I found that R would start, and
> do elementary things, but anything involving linear algebra
> failed:  for example, I tried the "lm-tests.R" file in the
> tests directory, with the following result:
> 
>   . . . . . . 
> 
> Type 'q()' to quit R.
> 
>  > source("tests/lm-tests.R")
> Error in La.chol2inv(x, size) : lapack routines cannot be loaded
> In addition: Warning message: 
> unable to load shared library "/disk4/home4/ehug/newSoft/R-1.9.1/modules/lapack.so":
>    ld.so.1: /disk4/home4/ehug/newSoft/R-1.9.1/bin/R.bin: fatal: relocation 
>    error: file /disk4/home4/ehug/newSoft/R-1.9.1/bin/libRlapack.so: symbol d_sign: 
>    referenced symbol not found 
> 
> I don't think "d_sign" is a symbol in Lapack.  Similar things happen 
> with any attempt to use functions that involve Lapack.  
> Can anyone give me some clues about what's happening?  Any help
> would be appreciated.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From erich.neuwirth at univie.ac.at  Wed Sep  8 21:52:26 2004
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Wed, 08 Sep 2004 21:52:26 +0200
Subject: [R] factor always have type integer
Message-ID: <413F62FA.7070204@univie.ac.at>

typeof applied to a factor always seems to return "integer",
independently of the type of the levels.
This has a strange side effect.
When a variable is "imported" into a data frame,
its type changes.
character variables automatically are converted
to factors when imported into data frames.

Here is an example:

 > v1<-1:3
 > v2<-c("a","b","c")
 > df<-data.frame(v1,v2)
 > typeof(v2)
[1] "character"
 > typeof(df$v2)
[1] "integer"

It is somewhat surprising that
the types of v2 and df$v2 are different.

the answer is to do
levels(df$v2)[df$v2]
but that is somewhat involved.

Should the types not be identical, and typeof applied to factors
return the type of the levels?


-- 
Erich Neuwirth, Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-38624 Fax: +43-1-4277-9386



From andy_liaw at merck.com  Wed Sep  8 22:00:10 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 8 Sep 2004 16:00:10 -0400
Subject: [R] factor always have type integer
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8348@usrymx25.merck.com>

?data.frame says:

Details:

     A data frame is a list of variables of the same length with unique
     row names, given class '"data.frame"'.

     'data.frame' converts each of its arguments to a data frame by
     calling 'as.data.frame(optional=TRUE)'.  As that is a generic
     function, methods can be written to change the behaviour of
     arguments according to their classes: R comes with many such
     methods. Character variables passed to 'data.frame' are converted
     to factor columns unless protected by 'I'.  ...

(Note that last sentence.)  I believe that answers your question.

Best,
Andy  

> From: Erich Neuwirth
> 
> typeof applied to a factor always seems to return "integer",
> independently of the type of the levels.
> This has a strange side effect.
> When a variable is "imported" into a data frame,
> its type changes.
> character variables automatically are converted
> to factors when imported into data frames.
> 
> Here is an example:
> 
>  > v1<-1:3
>  > v2<-c("a","b","c")
>  > df<-data.frame(v1,v2)
>  > typeof(v2)
> [1] "character"
>  > typeof(df$v2)
> [1] "integer"
> 
> It is somewhat surprising that
> the types of v2 and df$v2 are different.
> 
> the answer is to do
> levels(df$v2)[df$v2]
> but that is somewhat involved.
> 
> Should the types not be identical, and typeof applied to factors
> return the type of the levels?
> 
> 
> -- 
> Erich Neuwirth, Computer Supported Didactics Working Group
> Visit our SunSITE at http://sunsite.univie.ac.at
> Phone: +43-1-4277-38624 Fax: +43-1-4277-9386
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From rpeng at jhsph.edu  Wed Sep  8 22:11:51 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 08 Sep 2004 16:11:51 -0400
Subject: [R] factor always have type integer
In-Reply-To: <413F62FA.7070204@univie.ac.at>
References: <413F62FA.7070204@univie.ac.at>
Message-ID: <413F6787.3040706@jhsph.edu>

In some cases it makes sense to store "character" variables as factors 
(integers with labels) since this can take up much less memory.  If 
you really want to store `v2' as character, just do

data.frame(v1, I(v2))

-roger

Erich Neuwirth wrote:
> typeof applied to a factor always seems to return "integer",
> independently of the type of the levels.
> This has a strange side effect.
> When a variable is "imported" into a data frame,
> its type changes.
> character variables automatically are converted
> to factors when imported into data frames.
> 
> Here is an example:
> 
>  > v1<-1:3
>  > v2<-c("a","b","c")
>  > df<-data.frame(v1,v2)
>  > typeof(v2)
> [1] "character"
>  > typeof(df$v2)
> [1] "integer"
> 
> It is somewhat surprising that
> the types of v2 and df$v2 are different.
> 
> the answer is to do
> levels(df$v2)[df$v2]
> but that is somewhat involved.
> 
> Should the types not be identical, and typeof applied to factors
> return the type of the levels?
> 
>



From elvis at xlsolutions-corp.com  Wed Sep  8 22:15:55 2004
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Wed,  8 Sep 2004 13:15:55 -0700
Subject: [R] R/S-plus Course***In Princeton & Boston,
	***R/Splus Fundamentals and Programming Techniques,
	september - October, 2004 
Message-ID: <20040908201555.29378.qmail@webmail07.mesa1.secureserver.net>

R/S-plus Course***In Princeton & Boston,***R/Splus Fundamentals 
and Programming Techniques, september - October, 2004

XLSolutions Corporation (www.xlsolutions-corp.com) is proud to 
announce  2-day "R/S-plus Fundamentals and Programming 
Techniques".

****Princeton,NJ ---------------------------- September 30th - October
1st
****Boston, MA   ---------------------------- October 14th-15th


Reserve your seat now at the early bird rates! Payment due AFTER 
the class.


Course Description:
This two-day beginner to intermediate R/S-plus course focuses on a 
broad spectrum of topics, from reading raw data to a comparison of R 
and S. We will learn the essentials of data manipulation, graphical 
visualization and R/S-plus programming. We will explore statistical 
data analysis tools,including graphics with data sets. How to enhance 
your plots. We will perform basic statistics and fit linear regression

models. Participants are encouraged to bring data for interactive 
sessions


With the following outline:
- An Overview of R and S
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)


Email us for group discounts.
Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578
Visit us: www.xlsolutions-corp.com/training.htm
Please let us know if you and your colleagues are interested in this 
classto take advantage of group discount. Register now to secure your 
seat! Interested in R/Splus Advanced course? email us.


Cheers,
Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com
elvis at xlsolutions-corp.com



From ripley at stats.ox.ac.uk  Wed Sep  8 22:44:56 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Sep 2004 21:44:56 +0100 (BST)
Subject: [R] factor always have type integer
In-Reply-To: <413F62FA.7070204@univie.ac.at>
Message-ID: <Pine.LNX.4.44.0409082132200.25458-100000@gannet.stats>

On Wed, 8 Sep 2004, Erich Neuwirth wrote:

> typeof applied to a factor always seems to return "integer",
> independently of the type of the levels.

typeof is telling you the internal structure. From ?factor

     'factor' returns an object of class '"factor"' which has a set of
     integer codes the length of 'x' with a '"levels"' attribute of
     mode 'character'. 

(Despite that, we don't enforce this and people have managed to create 
factors with non-integer numeric codes.)

Now ?typeof says

     'typeof' determines the (R internal) type or storage mode of any
     object

and that is the "integer" as the codes are stored in an INTSXP.

BTW, factors were an internal type long ago, and were one of the two
unnamed types which appear in output from memory.profile().

> This has a strange side effect.

It's a very well documented feature of data.frame, as others have 
pointed out.

> When a variable is "imported" into a data frame,
> its type changes.
> character variables automatically are converted
> to factors when imported into data frames.
> 
> Here is an example:
> 
>  > v1<-1:3
>  > v2<-c("a","b","c")
>  > df<-data.frame(v1,v2)
>  > typeof(v2)
> [1] "character"
>  > typeof(df$v2)
> [1] "integer"
> 
> It is somewhat surprising that
> the types of v2 and df$v2 are different.
> 
> the answer is to do
> levels(df$v2)[df$v2]
> but that is somewhat involved.
> 
> Should the types not be identical, and typeof applied to factors
> return the type of the levels?
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wanr at ucalgary.ca  Wed Sep  8 23:23:32 2004
From: wanr at ucalgary.ca (wanr@ucalgary.ca)
Date: Wed, 08 Sep 2004 15:23:32 -0600
Subject: [R] How to draw an observation uniformly from a given dataset?
Message-ID: <200409082123.i88LNWD22869@smtp2.ucalgary.ca>

Hi all,

I have two questions stated below:

1. How to draw an observation uniformly from a given data?

For example, I have a dataset (or dataframe) with 10 observations (with a 
set of variables) and I want to "uniformly" select an observation from this 
given dataset, that is, the probability of selecting each observation is 
1/10. 

2. How to do this "combinations"?

source vector = (1,2)
the length of the target vector = 3

My expected outputs should be: 
111, 112, 121, 122, 211, 212, 221, 222.

However, the output from the function of combinations() is only 111, 112, 
122, 222. I can not even use the function permutations() because the length 
of the target vector is larger than the lengthe of the source vector.
Could anybody tell me how to get my expected results? 

Thank you in advance.

Rui



From drf5n at maplepark.com  Wed Sep  8 23:32:40 2004
From: drf5n at maplepark.com (David Forrest)
Date: Wed, 8 Sep 2004 16:32:40 -0500 (CDT)
Subject: [R] How to draw an observation uniformly from a given dataset?
In-Reply-To: <200409082123.i88LNWD22869@smtp2.ucalgary.ca>
References: <200409082123.i88LNWD22869@smtp2.ucalgary.ca>
Message-ID: <Pine.LNX.4.58.0409081631280.451@maplepark.com>

On Wed, 8 Sep 2004 wanr at ucalgary.ca wrote:

> Hi all,
>
> I have two questions stated below:
>
> 1. How to draw an observation uniformly from a given data?
>
> For example, I have a dataset (or dataframe) with 10 observations (with a
> set of variables) and I want to "uniformly" select an observation from this
> given dataset, that is, the probability of selecting each observation is
> 1/10.

sample(1:10,3,replace=TRUE)

>
> 2. How to do this "combinations"?
>
> source vector = (1,2)
> the length of the target vector = 3
>
> My expected outputs should be:
> 111, 112, 121, 122, 211, 212, 221, 222.

sample(c(1,2),3,replace=TRUE)

Dave
-- 
 Dave Forrest
 drf at vims.edu                                    (804)684-7900w
 drf5n at maplepark.com                             (804)642-0662h
                                   http://maplepark.com/~drf5n/



From rpeng at jhsph.edu  Wed Sep  8 23:35:52 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 08 Sep 2004 17:35:52 -0400
Subject: [R] How to draw an observation uniformly from a given dataset?
In-Reply-To: <200409082123.i88LNWD22869@smtp2.ucalgary.ca>
References: <200409082123.i88LNWD22869@smtp2.ucalgary.ca>
Message-ID: <413F7B38.6090008@jhsph.edu>

wanr at ucalgary.ca wrote:
> Hi all,
> 
> I have two questions stated below:
> 
> 1. How to draw an observation uniformly from a given data?
> 
> For example, I have a dataset (or dataframe) with 10 observations (with a 
> set of variables) and I want to "uniformly" select an observation from this 
> given dataset, that is, the probability of selecting each observation is 
> 1/10. 

Sample the indices, as in

idx <- sample(1:10, 1)
data[idx, ]

> 2. How to do this "combinations"?
> 
> source vector = (1,2)
> the length of the target vector = 3
> 
> My expected outputs should be: 
> 111, 112, 121, 122, 211, 212, 221, 222.
> 
> However, the output from the function of combinations() is only 111, 112, 
> 122, 222. I can not even use the function permutations() because the length 
> of the target vector is larger than the lengthe of the source vector.
> Could anybody tell me how to get my expected results? 
> 
> Thank you in advance.
> 
> Rui
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From wantia at ifi.unizh.ch  Wed Sep  8 23:48:07 2004
From: wantia at ifi.unizh.ch (Jan Wantia)
Date: Wed, 08 Sep 2004 23:48:07 +0200
Subject: [R] cbind in a loop
In-Reply-To: <Pine.LNX.4.44.0409082132200.25458-100000@gannet.stats>
References: <Pine.LNX.4.44.0409082132200.25458-100000@gannet.stats>
Message-ID: <413F7E17.3050801@ifi.unizh.ch>

Dear all,

I have a problem with adding columns to a data structure, using 'cbind':

I create an array, to which I want to cbind one new colum for every 
iteration of a loop.  Without the loop, the code works and looks like this:

 > Min<- array(0,c(129,0))
 > Min

  [1,]
  [2,]
  [3,]
  [4,]
  etc..

 >  file <- paste("Path\\to\\file\\Run_1", sep="")
 >  Tabelle <- read.table(file, sep=";", skip = 8)
 >  cbind(Min, Tabelle[,(which.min(Tabelle[129,]))])
        [,1]
  [1,] 25.45
  [2,] 25.33
  [3,] 25.76
  [4,] 25.40
  [5,] 24.39
  etc.

However, with the loop the result is the following:

 > for(i in 1:2){
+ file <- paste("Path\\to\\file\\Run_",i, sep="")
+ Tabelle <- read.table(file, sep=";", skip = 8)
+ cbind(Min, Tabelle[,(which.min(Tabelle[129,]))])
+ }
 > Min

  [1,]
  [2,]
  [3,]
  [4,]
  [5,]
  [6,]
...
I suppose the solution is very easy, but I just do not find it.
(I am using R 1.9.1 on windows XP)

Thanks in advance!
Jan



From erich.neuwirth at univie.ac.at  Wed Sep  8 23:54:23 2004
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Wed, 08 Sep 2004 23:54:23 +0200
Subject: [R] factor always have type integer
In-Reply-To: <Pine.LNX.4.44.0409082132200.25458-100000@gannet.stats>
References: <Pine.LNX.4.44.0409082132200.25458-100000@gannet.stats>
Message-ID: <413F7F8F.5080309@univie.ac.at>

The function I need is
valtype<-function(x)
	typeof(ifelse(is.factor(x),levels(x),x))

It is easy enough to write.
Are there any other special cases where the values
and the storage mode differ?

The background for all this is that I am transferring data
from R to Excel with VBA and I have to handle numbers
and strings differently. So I need to check for the type
of values I will get returned before I do the transfer.

Therefore, I would like to know if there are other types of variables
(besides factors) which give a misunderstandable answer about the type 
of their values when asked typeof.




Prof Brian Ripley wrote:

> On Wed, 8 Sep 2004, Erich Neuwirth wrote:
> 
> 
>>typeof applied to a factor always seems to return "integer",
>>independently of the type of the levels.
> 
> 
> typeof is telling you the internal structure. From ?factor
> 
>      'factor' returns an object of class '"factor"' which has a set of
>      integer codes the length of 'x' with a '"levels"' attribute of
>      mode 'character'. 
> 
> (Despite that, we don't enforce this and people have managed to create 
> factors with non-integer numeric codes.)
> 
> Now ?typeof says
> 
>      'typeof' determines the (R internal) type or storage mode of any
>      object
> 
> and that is the "integer" as the codes are stored in an INTSXP.
> 
> BTW, factors were an internal type long ago, and were one of the two
> unnamed types which appear in output from memory.profile().
> 
> 
>>This has a strange side effect.
> 
> 
> It's a very well documented feature of data.frame, as others have 
> pointed out.
> 
> 
>>When a variable is "imported" into a data frame,
>>its type changes.
>>character variables automatically are converted
>>to factors when imported into data frames.
>>
>>Here is an example:
>>
>> > v1<-1:3
>> > v2<-c("a","b","c")
>> > df<-data.frame(v1,v2)
>> > typeof(v2)
>>[1] "character"
>> > typeof(df$v2)
>>[1] "integer"
>>
>>It is somewhat surprising that
>>the types of v2 and df$v2 are different.
>>
>>the answer is to do
>>levels(df$v2)[df$v2]
>>but that is somewhat involved.
>>
>>Should the types not be identical, and typeof applied to factors
>>return the type of the levels?
>>
>>
>>
> 
> 


-- 
Erich Neuwirth, Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-38624 Fax: +43-1-4277-9386



From sundar.dorai-raj at PDF.COM  Wed Sep  8 23:55:55 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 08 Sep 2004 16:55:55 -0500
Subject: [R] cbind in a loop
In-Reply-To: <413F7E17.3050801@ifi.unizh.ch>
References: <Pine.LNX.4.44.0409082132200.25458-100000@gannet.stats>
	<413F7E17.3050801@ifi.unizh.ch>
Message-ID: <413F7FEB.50105@pdf.com>



Jan Wantia wrote:

> Dear all,
> 
> I have a problem with adding columns to a data structure, using 'cbind':
> 
> I create an array, to which I want to cbind one new colum for every 
> iteration of a loop.  Without the loop, the code works and looks like this:
> 
>  > Min<- array(0,c(129,0))
>  > Min
> 
>  [1,]
>  [2,]
>  [3,]
>  [4,]
>  etc..
> 
>  >  file <- paste("Path\\to\\file\\Run_1", sep="")
>  >  Tabelle <- read.table(file, sep=";", skip = 8)
>  >  cbind(Min, Tabelle[,(which.min(Tabelle[129,]))])
>        [,1]
>  [1,] 25.45
>  [2,] 25.33
>  [3,] 25.76
>  [4,] 25.40
>  [5,] 24.39
>  etc.
> 
> However, with the loop the result is the following:
> 
>  > for(i in 1:2){
> + file <- paste("Path\\to\\file\\Run_",i, sep="")
> + Tabelle <- read.table(file, sep=";", skip = 8)
> + cbind(Min, Tabelle[,(which.min(Tabelle[129,]))])

You probably want

Min <- cbind(Min, Tabelle[,(which.min(Tabelle[129,]))])

Also, read the posting guide which will tell you the following:

"For new subjects, compose a new message and include the 
'r-help at lists.R-project.org' (or 'r-devel at lists.R-project.org') address 
specifically. (Replying to an existing post and then changing the 
subject messes up the threading in the archives and in many people's 
mail readers.)"

--sundar



From wanr at ucalgary.ca  Thu Sep  9 00:00:50 2004
From: wanr at ucalgary.ca (wanr@ucalgary.ca)
Date: Wed, 08 Sep 2004 16:00:50 -0600
Subject: [R] How to do this "combination" ?
Message-ID: <200409082200.i88M0oD03226@smtp2.ucalgary.ca>

Thanks David first.

Probably, David misunderstood my points.

source vector = (1,2)
the length of the target vector = 3

My expected "complete" outputs should be:
111, 112, 121, 122, 211, 212, 221, 222.

sample(c(1,2),3,replace=TRUE) just gives me one "randomly sampled" 
combination at a time. However, I need the whole list displayed above at a 
time.

Rui



From gregory_r_warnes at groton.pfizer.com  Thu Sep  9 00:04:48 2004
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Wed, 8 Sep 2004 18:04:48 -0400 
Subject: [R] confidence intervals
Message-ID: <D7A3CFD7825BD6119B880002A58F06C20C521B7A@groexmb02.pfizer.com>


You should be able to make small modifications to the ci.lme function
provided in the gregmisc/gmodels package.

-Greg

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Spencer Graves
> Sent: Friday, September 03, 2004 11:58 AM
> To: bates at wisc.edu
> Cc: Robert Waters; r-help at stat.math.ethz.ch
> Subject: Re: [R] confidence intervals
> 
> 
> Hi, Robert: 
> 
>       While it may be difficult to program this in general 
> (as suggested 
> by it's position on Doug's "To Do" list), all the pieces should be 
> available to support a special script for your specific application.  
> What fixed and random model(s) interest you most? 
> 
>       hope this helps.  spencer graves
> 
> Douglas Bates wrote:
> 
> > Robert Waters wrote:
> >
> >> Dear R users;
> >>
> >> Im working with lme and Id like to have an idea of how
> >> can I get CI for the predictions made with the model.
> >> Im not a stats guy but, if Im not wrong, the CIs
> >> should be different if Im predicting a new data point
> >> or a new group. Ive been searching through the web and
> >> in help-lists with no luck. I know this topic had been
> >> asked before but without replies. Can anyone give an
> >> idea of where can I found information about this or
> >> how can I get it from R?
> >>
> >> Thanks for any hint
> >
> >
> > That's not currently implemented in lme.  It's on the "To 
> Do" list but 
> > it is not very close to the top.
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> 
> -- 
> Spencer Graves, PhD, Senior Development Engineer
> O:  (408)938-4420;  mobile:  (408)655-4567
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From andy_liaw at merck.com  Thu Sep  9 00:18:36 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 8 Sep 2004 18:18:36 -0400
Subject: [R] How to do this "combination" ?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF834A@usrymx25.merck.com>

Try:

> m <- as.matrix(expand.grid(1:2, 1:2, 1:2))
> x <- m[,1] * 100 + m[,2] * 10 + m[,3]
> x
  1   2   3   4   5   6   7   8 
111 211 121 221 112 212 122 222 

Note that if the `source vector' is not 1:k for some integer k, you need to
coerce the output of expand.grid, as that returns a data frame of factors.

Andy

> From: wanr at ucalgary.ca
> 
> Thanks David first.
> 
> Probably, David misunderstood my points.
> 
> source vector = (1,2)
> the length of the target vector = 3
> 
> My expected "complete" outputs should be:
> 111, 112, 121, 122, 211, 212, 221, 222.
> 
> sample(c(1,2),3,replace=TRUE) just gives me one "randomly sampled" 
> combination at a time. However, I need the whole list 
> displayed above at a 
> time.
> 
> Rui
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From gunter.berton at gene.com  Thu Sep  9 00:30:31 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 8 Sep 2004 15:30:31 -0700
Subject: [R] factor always have type integer
In-Reply-To: <413F7F8F.5080309@univie.ac.at>
Message-ID: <200409082230.i88MUVJI005105@meitner.gene.com>

> Therefore, I would like to know if there are other types of variables
> (besides factors) which give a misunderstandable answer about 
> the type 
> of their values when asked typeof.

Your question is a bit combative, don't you think? R performs as documented,
so I think your characterization is inaccurate and certainly unfair, as
software is not required to do what one expects, only what is promised.

I'm not sure what you mean by "misunderstandable" (which I don't believe is
a word, btw). In fact, within R, because of S3 or S4 print/show methods
there is no necessity at all that what is printed out on the screen has
anything to do with what "typeof" will give.?print will give some details
for S3 methods ?show for S4 methods,(provided the class package and
associated Help files are loaded). So in that sense, there are an infinite
number of "variables" (i.e. objects) where there is disagreement.

In the sense that you ask (reading in a rectangular array?) please read
?data.frame and ?ead.table carefully. But it surely must depend on exactly
how you are "importing" the data -- i.e., what R function you are using to
do this. One thing to beware of: how missing data (blanks) in the Excel data
or missing value codes like "NA" or "N/A" are handled. For example,
read.table() will correctly interpret blanks in a text file given the
correct number of field/delimiter specifications; but entries like "N/A" in
a numeric field will be interpreted as characters, so that the numeric field
will be converted to characters and then to factor unless you invoke the
as.is=TRUE parameter (by which you can avoid your suggested ifelse
construction, btw). Thus your typeof() invocation would give integer on what
started off as a floating point column in Excel.

So attention to detail and the software documentation is required! IMHO R's
documentation is excellent, and truly remarkable given that it is an all
volunteer effort. Please take advantage of it.


-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

From erich.neuwirth at univie.ac.at  Thu Sep  9 00:36:08 2004
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Thu, 09 Sep 2004 00:36:08 +0200
Subject: [R] factor always have type integer
In-Reply-To: <Pine.LNX.4.44.0409082132200.25458-100000@gannet.stats>
References: <Pine.LNX.4.44.0409082132200.25458-100000@gannet.stats>
Message-ID: <413F8958.6040204@univie.ac.at>

The simple answer to my problem (are the values of a vector
numeric or not) is is.numeric, and that is enough for
what I need right now.
But this way I do not get an answer discriminating between
integers and and doubles. What is the canonical way of getting the
type of the values of a vector?
Is there a better way than
valtype<-function(x)
     typeof(ifelse(is.factor(x),levels(x),x))



-- 
Erich Neuwirth, Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-38624 Fax: +43-1-4277-9386



From Jason.Niggley.2009 at marshall.usc.edu  Thu Sep  9 00:48:09 2004
From: Jason.Niggley.2009 at marshall.usc.edu (Niggley, Jason)
Date: Wed, 8 Sep 2004 15:48:09 -0700
Subject: [R] Problem installing R
Message-ID: <CF3D4422131DD411885D00508BC75F470E4F025D@msbmail01.marshall.usc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040908/b6620d9b/attachment.pl

From wanr at ucalgary.ca  Thu Sep  9 00:51:30 2004
From: wanr at ucalgary.ca (wanr@ucalgary.ca)
Date: Wed, 08 Sep 2004 16:51:30 -0600
Subject: [R] How to do this "combination"?
Message-ID: <200409082251.i88MpUG14309@smtp1.ucalgary.ca>

Hi all,

source vector = (1,2)
the length of the target vector = 3
 
My expected "complete" output should be:
111, 112, 121, 122, 211, 212, 221, 222 (they are Not numerical numbers, they 
are equivalent to abc and aab etc.).

Not perfect solutions suggested by others so far: 
 
solution1: sample(c(1,2),3,replace=TRUE) just gives me one "randomly 
sampled" combination at a time. However, I need the whole list displayed 
above at a time.

solution2: as.matrix(expand.grid(1:2, 1:2, 1:2)) almost implements what I 
need. 

However, in my case, the length of the target vector is not fixed in 
advance. For example, the output might be 11111, 11112, and etc coming from 
the source vector (1,2).

Thanks in advance.

Rui



From erich.neuwirth at univie.ac.at  Thu Sep  9 01:26:22 2004
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Thu, 09 Sep 2004 01:26:22 +0200
Subject: [R] How to do this "combination" ?
In-Reply-To: <200409082200.i88M0oD03226@smtp2.ucalgary.ca>
References: <200409082200.i88M0oD03226@smtp2.ucalgary.ca>
Message-ID: <413F951E.6010704@univie.ac.at>

combinat<-function(els,len){
if (len==1) (return(as.character(els)))
else return(as.vector(t(outer(combinat(els,len-1),as.character(els),
     function(x,y)paste(x,y,sep="")))))
}

combinat(1:2,3)
does what you want



wanr at ucalgary.ca wrote:

> Thanks David first.
> 
> Probably, David misunderstood my points.
> 
> source vector = (1,2)
> the length of the target vector = 3
> 
> My expected "complete" outputs should be:
> 111, 112, 121, 122, 211, 212, 221, 222.
> 
> sample(c(1,2),3,replace=TRUE) just gives me one "randomly sampled" 
> combination at a time. However, I need the whole list displayed above at a 
> time.
> 
> Rui
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Erich Neuwirth, Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-38624 Fax: +43-1-4277-9386



From andy_liaw at merck.com  Thu Sep  9 01:32:54 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 8 Sep 2004 19:32:54 -0400
Subject: [R] How to do this "combination"?
Message-ID: <3A822319EB35174CA3714066D590DCD504AF834D@usrymx25.merck.com>

> n <- 2
> p <- 5
> m <- do.call("expand.grid", data.frame(matrix(rep(1:n, p), n, p)))
> do.call("paste", c(m, sep=""))
 [1] "11111" "21111" "12111" "22111" "11211" "21211" "12211" "22211" "11121"
"21121"
[11] "12121" "22121" "11221" "21221" "12221" "22221" "11112" "21112" "12112"
"22112"
[21] "11212" "21212" "12212" "22212" "11122" "21122" "12122" "22122" "11222"
"21222"
[31] "12222" "22222"


Please give _all_ the details up front, instead of waiting for people to
guess them.

Andy

> From: wanr at ucalgary.ca
> 
> Hi all,
> 
> source vector = (1,2)
> the length of the target vector = 3
>  
> My expected "complete" output should be:
> 111, 112, 121, 122, 211, 212, 221, 222 (they are Not 
> numerical numbers, they 
> are equivalent to abc and aab etc.).
> 
> Not perfect solutions suggested by others so far: 
>  
> solution1: sample(c(1,2),3,replace=TRUE) just gives me one "randomly 
> sampled" combination at a time. However, I need the whole 
> list displayed 
> above at a time.
> 
> solution2: as.matrix(expand.grid(1:2, 1:2, 1:2)) almost 
> implements what I 
> need. 
> 
> However, in my case, the length of the target vector is not fixed in 
> advance. For example, the output might be 11111, 11112, and 
> etc coming from 
> the source vector (1,2).
> 
> Thanks in advance.
> 
> Rui
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From loren71 at email.com  Thu Sep  9 02:50:30 2004
From: loren71 at email.com (Loren Grimes)
Date: Wed, 08 Sep 2004 19:50:30 -0500
Subject: [R] howto load functions?
Message-ID: <20040909005030.26A3C4BDA8@ws1-1.us4.outblaze.com>

I realize that this is pretty basic, and I should be able to figure this out: but, how do I write a function [with a text editor] and then load it into an interactive R session?  

Thanks
-- 
___________________________________________________________
Sign-up for Ads Free at Mail.com
http://promo.mail.com/adsfreejump.htm



From Kevin.Wang at maths.anu.edu.au  Thu Sep  9 02:57:33 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Thu, 09 Sep 2004 10:57:33 +1000
Subject: [R] howto load functions?
In-Reply-To: <20040909005030.26A3C4BDA8@ws1-1.us4.outblaze.com>
References: <20040909005030.26A3C4BDA8@ws1-1.us4.outblaze.com>
Message-ID: <413FAA7D.8030809@maths.anu.edu.au>

Hi,

Loren Grimes wrote:
> I realize that this is pretty basic, and I should be able to figure this out: but, how do I write a function [with a text editor] and then load it into an interactive R session?  
> 
> Thanks

Try ?source

HTH,

Kevin

-- 
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From kjetil at acelerate.com  Thu Sep  9 03:53:23 2004
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Wed, 08 Sep 2004 21:53:23 -0400
Subject: [R] isoMDS
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F74053F98C6@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F74053F98C6@dc1ex2.air.org>
Message-ID: <413FB793.5010902@acelerate.com>

Doran, Harold wrote:

>Thank you. Quick clarification. isoMDS only works with dissimilarities.
>Converting my similarity matrix into the dissimilarity matrix is done as
>(from an email I found on the archives)
>
>  
>
>>d<- max(tt)-tt
>>    
>>
>
>  
>
Mardia, kent & Bibby defines the "standard transformation" from a 
similarity matrix to a dissimilarity
(distance) matrix by

d_rs <-  sqrt( c_rr -2*c_rs + c_ss)

where c_rs are the similarities. This assures the diagonal of the 
dissimilarity matrix to be zero.
You could try that.

Kjetil halvorsen


>Where tt is the similarity matrix. With this, I tried isoMDS as follows:
>
>  
>
>>tt.mds<-isoMDS(d)
>>    
>>
>
>and I get the following error message. 
>
>Error in isoMDS(d) : An initial configuration must be supplied with
>NA/Infs in d. I was a little confused on exactly how to specify this
>initial config. So, from here I ran cmdscale on d as
>
>  
>
>>d.mds<-cmdscale(d)
>>    
>>
>
>which seemed to work fine and produce reasonable results. I was able to
>take the coordinates and run them through a k-means cluster and the
>results seemed to correctly match the grouping structure I created for
>this sample analysis.
>
>Cmdscale is for metric scaling, but it seemed to produce the results
>correctly. 
>
>So, did I correctly convert the similarity matrix to the dissimilarity
>matrix? Second, should I have used cmdscale rather than isoMDS as I have
>done? Or, is there a way to specify the initial configuration that I
>have not done correctly.
>
>Again, many thanks.
>
>Harold
>
>-----Original Message-----
>From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
>Sent: Wednesday, September 08, 2004 9:58 AM
>To: Doran, Harold
>Cc: r-help at stat.math.ethz.ch
>Subject: Re: [R] isoMDS
>
>On Wed, 8 Sep 2004, Doran, Harold wrote:
>
>  
>
>>1)	Can isoMDS work only with dissimilarities? Or, is there a way
>>that it can perform the analysis on the similarity matrix as I have
>>described it?
>>    
>>
>
>Yes.  The method, as well as the function in package MASS.  All other 
>MDS packages are doing a conversion, probably without telling you how.
>
>  
>
>>2)	If I cannot perform the analysis on the similarity matrix, how
>>can I turn this matrix into a dissimilarity matrix necessary? I am
>>    
>>
>less
>  
>
>>familiar with this matrix and how it would be constructed?
>>    
>>
>
>Normally similarities are in the range [0,1], and people use D = 1 - S
>or
>sqrt(1-S). (Which does not matter for isoMDS since it only uses ranks of
>dissimilarities, apart from finding the starting configuration.)  See
>the
>references on the help page for isoMDS.
>
>  
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra



From Leon.Barmuta at utas.edu.au  Thu Sep  9 06:18:49 2004
From: Leon.Barmuta at utas.edu.au (Leon Barmuta)
Date: Thu, 09 Sep 2004 14:18:49 +1000
Subject: [R] Skipping panels in Lattice
Message-ID: <6.1.2.0.2.20040909140332.0291c350@postoffice.sandybay.utas.edu.au>

Dear all,

I wish to generate a lattice boxplot which skips an empty cell in a design. 
I have trawled r-help, scruitinized xyplot(lattice) help page, and merrily 
reproduced examples of using skip from a couple of previous r-help queries 
and the example given in Pinheiro & Bates. But I must be missing something...

Here's an example (running R 1.9.1 on Win2k):

# generate some data

df1 <- data.frame(expand.grid(obsnum=seq(1, 15, 1), faca=c("A1", "A2", "A3"),
     facb=c("B1","B2", "B3", "B4"), facc=c("C1","C2")), dv=rpois(15*3*4*2,10))

# now get rid of the cell B4 & C1 to simulate a missing treatment combination

df2 <- df1[df1$facb !="B4" | df1$facc !="C1", ]

# plain vanilla lattice plot generates an empty panel corresponding to the 
empty cell

plot1 <- bwplot( dv ~ faca | facb*facc, data=df2)
plot1

# now try to skip the empty panel
# turn plot history on so that the separate pages can be recalled

plot2 <- update(plot1, skip=c(rep(F, 3), T, rep(F, 4)))
plot2

and the 4th panel position of the bottom row is skipped, BUT the B4&C1 cell 
is shunted to the top left of row 1 and the last panel of plot1 is now 
moved to page 2. Messing with layout= doesn't help, neither does 
substituting NA for the values of the missing cell (instead of cutting it 
out of the data frame). I also get the same behaviour for stripplot and 
dotplot too.

Apologies if I've missed a previous solution to this during my searches of 
the archive.

Regards,

Leon Barmuta
School of Zoology & TAFI, University of Tasmania, Australia.



From ggrothendieck at myway.com  Thu Sep  9 06:24:57 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 9 Sep 2004 04:24:57 +0000 (UTC)
Subject: [R] How to do this "combination"?
References: <200409082251.i88MpUG14309@smtp1.ucalgary.ca>
Message-ID: <loom.20040909T061924-571@post.gmane.org>

 <wanr <at> ucalgary.ca> writes:

: source vector = (1,2)
: the length of the target vector = 3
:  
: solution2: as.matrix(expand.grid(1:2, 1:2, 1:2)) almost implements what I 
: need. 
: 
: However, in my case, the length of the target vector is not fixed in 
: advance. For example, the output might be 11111, 11112, and etc coming from 
: the source vector (1,2).

If the only problem with that solution is that the length is not a parameter
then you could use this variation of it:

   as.matrix(do.call("expand.grid", rep(list(1:2),3)))



From deepayan at stat.wisc.edu  Thu Sep  9 06:45:10 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 8 Sep 2004 23:45:10 -0500
Subject: [R] Skipping panels in Lattice
In-Reply-To: <6.1.2.0.2.20040909140332.0291c350@postoffice.sandybay.utas.edu.au>
References: <6.1.2.0.2.20040909140332.0291c350@postoffice.sandybay.utas.edu.au>
Message-ID: <200409082345.11030.deepayan@stat.wisc.edu>

On Wednesday 08 September 2004 23:18, Leon Barmuta wrote:
> Dear all,
>
> I wish to generate a lattice boxplot which skips an empty cell in a
> design. I have trawled r-help, scruitinized xyplot(lattice) help
> page, and merrily reproduced examples of using skip from a couple of
> previous r-help queries and the example given in Pinheiro & Bates.
> But I must be missing something...
>
> Here's an example (running R 1.9.1 on Win2k):
>
> # generate some data
>
> df1 <- data.frame(expand.grid(obsnum=seq(1, 15, 1), faca=c("A1",
> "A2", "A3"), facb=c("B1","B2", "B3", "B4"), facc=c("C1","C2")),
> dv=rpois(15*3*4*2,10))
>
> # now get rid of the cell B4 & C1 to simulate a missing treatment
> combination
>
> df2 <- df1[df1$facb !="B4" | df1$facc !="C1", ]
>
> # plain vanilla lattice plot generates an empty panel corresponding
> to the empty cell
>
> plot1 <- bwplot( dv ~ faca | facb*facc, data=df2)
> plot1
>
> # now try to skip the empty panel

What exactly do you mean by that? Do you want the strips and and panel 
boundary for that panel not to be shown? There's no way of doing that 
as long as you have 2 different conditioning variables. The plot here 
is like a matrix, you cannot remove one element from it, you have to 
remove a whole column or a whole row.

The best suggestion I can give you is to use the interaction facc:facb 
as your conditioning variable. bwplot would see this as a single factor 
(so the array structure is lost, and you just have a vector of plots), 
and it will simply drop the unused combination:

plot1 <- bwplot( dv ~ faca | facc:facb, data=df2, layout = c(4, 2))
plot1

plot2 <- update(plot1, skip=c(rep(F, 3), T, rep(F, 4)))
plot2

Deepayan

> # turn plot history on so that the separate pages can be recalled
>
> plot2 <- update(plot1, skip=c(rep(F, 3), T, rep(F, 4)))
> plot2
>
> and the 4th panel position of the bottom row is skipped, BUT the
> B4&C1 cell is shunted to the top left of row 1 and the last panel of
> plot1 is now moved to page 2. Messing with layout= doesn't help,
> neither does substituting NA for the values of the missing cell
> (instead of cutting it out of the data frame). I also get the same
> behaviour for stripplot and dotplot too.
>
> Apologies if I've missed a previous solution to this during my
> searches of the archive.
>
> Regards,
>
> Leon Barmuta
> School of Zoology & TAFI, University of Tasmania, Australia.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Thu Sep  9 06:51:04 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 9 Sep 2004 04:51:04 +0000 (UTC)
Subject: [R] factor always have type integer
References: <413F62FA.7070204@univie.ac.at> <413F6787.3040706@jhsph.edu>
Message-ID: <loom.20040909T064241-398@post.gmane.org>


Note that I(v2) stores v2 as type character but not as class character.  
For example,

R> DF <- data.frame(x = c("a", "b"), y = I(c("a", "b")), z = I(c("a", "b")))
R> class(DF$z) <- "character"

R> sapply(DF, typeof) # y and z do have the same type
          x           y           z 
  "integer" "character" "character" 

R> sapply(DF, class)  # but the 3 columns have different classes
          x           y           z 
   "factor"      "AsIs" "character" 

 



Roger D. Peng <rpeng <at> jhsph.edu> writes:

: 
: In some cases it makes sense to store "character" variables as factors 
: (integers with labels) since this can take up much less memory.  If 
: you really want to store `v2' as character, just do
: 
: data.frame(v1, I(v2))
: 
: -roger
: 
: Erich Neuwirth wrote:
: > typeof applied to a factor always seems to return "integer",
: > independently of the type of the levels.
: > This has a strange side effect.
: > When a variable is "imported" into a data frame,
: > its type changes.
: > character variables automatically are converted
: > to factors when imported into data frames.
: > 
: > Here is an example:
: > 
: >  > v1<-1:3
: >  > v2<-c("a","b","c")
: >  > df<-data.frame(v1,v2)
: >  > typeof(v2)
: > [1] "character"
: >  > typeof(df$v2)
: > [1] "integer"
: > 
: > It is somewhat surprising that
: > the types of v2 and df$v2 are different.
: > 
: > the answer is to do
: > levels(df$v2)[df$v2]
: > but that is somewhat involved.
: > 
: > Should the types not be identical, and typeof applied to factors
: > return the type of the levels?



From ripley at stats.ox.ac.uk  Thu Sep  9 08:06:00 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Sep 2004 07:06:00 +0100 (BST)
Subject: [R] factor always have type integer
In-Reply-To: <413F7F8F.5080309@univie.ac.at>
Message-ID: <Pine.LNX.4.44.0409090703350.26276-100000@gannet.stats>

On Wed, 8 Sep 2004, Erich Neuwirth wrote:

> The function I need is
> valtype<-function(x)
> 	typeof(ifelse(is.factor(x),levels(x),x))
> 
> It is easy enough to write.
> Are there any other special cases where the values
> and the storage mode differ?

All classed objects are more than the internal type recorded by typeof().

> The background for all this is that I am transferring data
> from R to Excel with VBA and I have to handle numbers
> and strings differently. So I need to check for the type
> of values I will get returned before I do the transfer.
> 
> Therefore, I would like to know if there are other types of variables
> (besides factors) which give a misunderstandable answer about the type 
> of their values when asked typeof.

All of them.  Some people are capable of misunderstanding anything!

I believe you should be using class() not typeof().

> Prof Brian Ripley wrote:
> 
> > On Wed, 8 Sep 2004, Erich Neuwirth wrote:
> > 
> > 
> >>typeof applied to a factor always seems to return "integer",
> >>independently of the type of the levels.
> > 
> > 
> > typeof is telling you the internal structure. From ?factor
> > 
> >      'factor' returns an object of class '"factor"' which has a set of
> >      integer codes the length of 'x' with a '"levels"' attribute of
> >      mode 'character'. 
> > 
> > (Despite that, we don't enforce this and people have managed to create 
> > factors with non-integer numeric codes.)
> > 
> > Now ?typeof says
> > 
> >      'typeof' determines the (R internal) type or storage mode of any
> >      object
> > 
> > and that is the "integer" as the codes are stored in an INTSXP.
> > 
> > BTW, factors were an internal type long ago, and were one of the two
> > unnamed types which appear in output from memory.profile().
> > 
> > 
> >>This has a strange side effect.
> > 
> > 
> > It's a very well documented feature of data.frame, as others have 
> > pointed out.
> > 
> > 
> >>When a variable is "imported" into a data frame,
> >>its type changes.
> >>character variables automatically are converted
> >>to factors when imported into data frames.
> >>
> >>Here is an example:
> >>
> >> > v1<-1:3
> >> > v2<-c("a","b","c")
> >> > df<-data.frame(v1,v2)
> >> > typeof(v2)
> >>[1] "character"
> >> > typeof(df$v2)
> >>[1] "integer"
> >>
> >>It is somewhat surprising that
> >>the types of v2 and df$v2 are different.
> >>
> >>the answer is to do
> >>levels(df$v2)[df$v2]
> >>but that is somewhat involved.
> >>
> >>Should the types not be identical, and typeof applied to factors
> >>return the type of the levels?
> >>
> >>
> >>
> > 
> > 
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Sep  9 08:14:29 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Sep 2004 07:14:29 +0100 (BST)
Subject: [R] factor always have type integer
In-Reply-To: <413F8958.6040204@univie.ac.at>
Message-ID: <Pine.LNX.4.44.0409090707010.26276-100000@gannet.stats>

On Thu, 9 Sep 2004, Erich Neuwirth wrote:

> The simple answer to my problem (are the values of a vector
> numeric or not) is is.numeric, and that is enough for
> what I need right now.
> But this way I do not get an answer discriminating between
> integers and and doubles. What is the canonical way of getting the
> type of the values of a vector?
> Is there a better way than
> valtype<-function(x)
>      typeof(ifelse(is.factor(x),levels(x),x))

PLEASE do your homework as the posting guide asks.

1) A factor is not a vector: try is.vector on one.

2) levels(x) is not the `values' of an factor object.  To transfer it to 
VBA you need to coerce it to character -- at that *is* in the FAQ.

3) Once you know you have a vector, typeof() will tell you which of the 
7 types it is.  (logical, integer, double, complex, character, raw, list) 
But you need to test first.  Most R objects are not vectors, or not just 
vectors.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From hadasa704 at 012.net.il  Thu Sep  9 08:20:40 2004
From: hadasa704 at 012.net.il (The Michaelson Institute)
Date: Thu, 09 Sep 2004 06:20:40 -0000
Subject: [R] Cox regression for prevalence estimates
Message-ID: <20040909062038.VLLO4400.fep4@doctor1.workgroup>

Thnks to Prof. Frank E Harrell Jr , Prof. Bernardo Rangel Tura, and Prof. 
Thomas Lumley for their response.

Tomas Karpati (MD)
The Michaelson Institute for the prevention of Blindness
Hadassah Medical Org.
email: hadasa704 at 012.net.il
Phone: +972-2-6256458, fax: +972-2-6232895


On Tue, 07 Sep 2004 10:11:32 -0300, you wrote:
>At 09:27 07/09/2004, you wrote:
>
>>Bernardo Rangel Tura wrote:
>>>At , The Michaelson Institute wrote:
>>>
>>>>How can R be used to calculate the prevalence ratios using Cox regression +
>>>>robust variance estimates ?
>>>
>>>Well,
>>>In Design package have a command: cph
>>>This command have a option "robsut" with default=FALSE, but in help is write:
>>>" ... robust if TRUE a robust variance estimate is returned. ..."
>>>I think that is your response...
>>>
>>>bye
>>>Bernardo Rangel Tura, MD, MSc
>>>National Institute of Cardiology Laranjeiras
>>>Rio de Janeiro Brazil
>>
>>No, robust is an option to coxph, not cph.  cph uses 'after the fit' 
>>correction using the robcov or bootcov functions in Design.
>>
>>
>>--
>>Frank E Harrell Jr   Professor and Chair           School of Medicine
>>                      Department of Biostatistics   Vanderbilt University
>
>Sorry Frank!
>I made a digitation mistake, but I think yours package answers the Tomas 
>Karpati´s need.
>
>
>Thanks in advance
>
>Bernardo Rangel Tura, MD, MSc
>National Institute of Cardiology Laranjeiras
>Rio de Janeiro Brazil  
>



From ripley at stats.ox.ac.uk  Thu Sep  9 08:19:27 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Sep 2004 07:19:27 +0100 (BST)
Subject: [R] Problem installing R
In-Reply-To: <CF3D4422131DD411885D00508BC75F470E4F025D@msbmail01.marshall.usc.edu>
Message-ID: <Pine.LNX.4.44.0409090715570.26276-100000@gannet.stats>

On Wed, 8 Sep 2004, Niggley, Jason wrote:

> As I am installing R for windows, I get the following error:
> 
> "C:\ProgramFiles\R\rw1091\library\stats\chtml\stats.chm

Is that really not Program Files?

> An error occurred while trying to copy a file:
> 
> The source file is corrupted."
> 
> Can you help me?

Please go back to the page you got the installer from, note what it says
about md5sums, and check them.  I suspect you will find you have a
corrupted download and need to download again, possibly using a better 
download program.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Wanzare at HCJP.com  Thu Sep  9 08:29:11 2004
From: Wanzare at HCJP.com (Manoj - Hachibushu Capital)
Date: Thu, 9 Sep 2004 15:29:11 +0900
Subject: [R] Evaluating R function in C code
Message-ID: <1CBA12F2D414914989C723D196B287DC055690@jp-svr-ex1.hcjp.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040909/220d2a30/attachment.pl

From jarioksa at sun3.oulu.fi  Thu Sep  9 10:26:30 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 09 Sep 2004 11:26:30 +0300
Subject: [R] isoMDS
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F74053F98C6@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F74053F98C6@dc1ex2.air.org>
Message-ID: <1094718389.10353.10.camel@biol102145.oulu.fi>

On Wed, 2004-09-08 at 21:31, Doran, Harold wrote:
> Thank you. Quick clarification. isoMDS only works with dissimilarities.
> Converting my similarity matrix into the dissimilarity matrix is done as
> (from an email I found on the archives)
> 
> > d<- max(tt)-tt
> 
> Where tt is the similarity matrix. With this, I tried isoMDS as follows:
> 
> > tt.mds<-isoMDS(d)
> 
> and I get the following error message. 
> 
> Error in isoMDS(d) : An initial configuration must be supplied with
> NA/Infs in d. I was a little confused on exactly how to specify this
> initial config. So, from here I ran cmdscale on d as
> 
This error message is quite informative: you have either missing or
non-finite entries in your data. The only surprising thing here is that
cmdscale works: it should fail, too. Are you sure that you haven't done
anything with your data matrix in between, like changed it from matrix
to a dist object? If the Inf/NaN/NA values are on the diagonal, they
will magically disappear with as.dist. Anyway, if you're able to get a
metric scaling result, you can manually feed that into isoMDS for the
initial configuration, and  avoid the check. See ?isoMDS.

> > d.mds<-cmdscale(d)
> 
> which seemed to work fine and produce reasonable results. I was able to
> take the coordinates and run them through a k-means cluster and the
> results seemed to correctly match the grouping structure I created for
> this sample analysis.
> 
> Cmdscale is for metric scaling, but it seemed to produce the results
> correctly. 
> 
> So, did I correctly convert the similarity matrix to the dissimilarity
> matrix? Second, should I have used cmdscale rather than isoMDS as I have
> done? Or, is there a way to specify the initial configuration that I
> have not done correctly.

If you don't know whether you should use isoMDS or cmdscale, you
probably should use cmdscale. If you know, things are different.
Probably isoMDS gives you `better'(TM) results, but it is more
complicated to handle.

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From jarioksa at sun3.oulu.fi  Thu Sep  9 10:37:10 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 09 Sep 2004 11:37:10 +0300
Subject: [R] isoMDS
In-Reply-To: <413FB793.5010902@acelerate.com>
References: <88EAF3512A55DF46B06B1954AEF73F74053F98C6@dc1ex2.air.org>
	<413FB793.5010902@acelerate.com>
Message-ID: <1094719030.10353.22.camel@biol102145.oulu.fi>

On Thu, 2004-09-09 at 04:53, Kjetil Brinchmann Halvorsen wrote:

> >
> Mardia, kent & Bibby defines the "standard transformation" from a 
> similarity matrix to a dissimilarity
> (distance) matrix by
> 
> d_rs <-  sqrt( c_rr -2*c_rs + c_ss)
> 
> where c_rs are the similarities. This assures the diagonal of the 
> dissimilarity matrix to be zero.
> You could try that.
> 
In R notation, this would be

sim2dist <- function(x) 
             as.dist(sqrt(outer(diag(x), diag(x), "+") - 2*x))

Mardia, Kent & Bibby indeed passingly say that this is a `standard
transformation' (page 403). However, it is really a canonical way only
if diagonal elements in similarity matrix are sums of squares, and
off-diagonal elements are cross products. In that case the `standard
transformation' gives you Euclidean distances (or if you have
variances/covariances or ones/correlations it gives you something
similar). However, it is no standard if your similarities are something
else, and cannot be transformed into Euclidean distances.

However, in isoMDS this *may* not matter, since NMDS uses only rank
order of dissimilarities, and any transformation giving dissimilarities
in the same rank order *may* give similar results. The statement was
conditions ("may"), since isoMDS uses cmdscale for the starting
configuration, and cmdscale will give different results with different
transformations. So isoMDS may stop in different (local) optima. Setting
`tol' parameter low enough in isoMDS (see ?isoMDS) helped in a couple of
cases I tried, and the results were practically identical with different
transformations. So it doesn't matter too much how you change your
similarities to dissimilarities, since isoMDS indeed treats them as
dissimilarities (but cmdscale treats them as distances).

cheers, jari oksanen
-- 
J.Oksanen, Oulu, Finland.
"Object-oriented programming is an exceptionally bad idea which could
only have originated in California." E. Dijkstra



From christian.ritter at shell.com  Thu Sep  9 10:58:27 2004
From: christian.ritter at shell.com (Ritter, Christian C MCIL-CTANL/S)
Date: Thu, 9 Sep 2004 10:58:27 +0200
Subject: [R] Handling the windows clipboard/32KB limit
Message-ID: <156CDC8CCFD1894295D2907F16337A48B2AD51@bru-s-006.europe.shell.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040909/70589115/attachment.pl

From jarioksa at sun3.oulu.fi  Thu Sep  9 11:16:48 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 09 Sep 2004 12:16:48 +0300
Subject: [R] Installing packages on OS X
In-Reply-To: <f8e6ff0504090811251dbd6ca5@mail.gmail.com>
References: <f8e6ff0504090811251dbd6ca5@mail.gmail.com>
Message-ID: <1094721408.10353.29.camel@biol102145.oulu.fi>

On Wed, 2004-09-08 at 21:25, hadley wickham wrote:
> On my computer, it seems that (binary?) packages installed through the
> GUI in RAqua are not used available to the command line version of R,
> while (source) packages installed with R CMD INSTALL are available to
> both.  This is a problem when I run R CMD CHECK on a package that I am
> creating that depends on packages I have installed through the gui.
> 
> Is this a problem with my installation of R, or a known limitation?
> (there is no mention of this in the Mac OS X faq, however, the entire
> section entitled "Installing packages" is blank).
> 
It is in some other FAQ... Unfortunately, I don't have a Mac available
now, so I can't check. However, seek for "environmental variables" and
"setting library paths" in some other R FAQ or R
Administration/Installation guide. There will you find a description of
things you should do. It is just as crystal clear as unix man pages:
everything is clear *after* you know what is said there, but you may
have hard time noticing this clarity.

I solved this problem some months ago after a long search among the
official documentation. So it is documented, but well hidden.

I may have a look at a machine where I solved this in the evening
(UTC+3), if you won't get solution before that.

cheers, jari oksanen
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From ihok at hotmail.com  Thu Sep  9 11:30:02 2004
From: ihok at hotmail.com (Jack Tanner)
Date: Thu, 09 Sep 2004 05:30:02 -0400
Subject: [R] rodbc windows doesn't find dsn
In-Reply-To: <Pine.LNX.4.44.0409071609050.27491-100000@gannet.stats>
References: <Pine.LNX.4.44.0409071609050.27491-100000@gannet.stats>
Message-ID: <4140229A.9010108@hotmail.com>

Prof Brian Ripley wrote:
>      'odbcConnect' establishes a connection to the dsn, and
>      'odbcDriverConnect' allows a more flexible specification via a
>      connection string.  'odbcConnect' uses the connection string
>      '"DSN=dsn;UID=uid;PWD=pwd"'. 

The point here seems to be that odbcConnect is meant to provide a useful 
default, and odbcDriverConnect allows one to override that default. 
Could somebody shed some light on why '"DSN=dsn;UID=;PWD="' is 
considered a more useful default than '"DSN=dsn;"'?



From mrufino at ipimar.ualg.pt  Thu Sep  9 11:33:24 2004
From: mrufino at ipimar.ualg.pt (Marta Rufino)
Date: Thu, 9 Sep 2004 10:33:24 +0100
Subject: [R] filling patterns in image and examples
Message-ID: <007b01c49650$0dbe4560$0b1a0e0a@PORTATILMARTA>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040909/d3b8a916/attachment.pl

From jacques.veslot at cirad.fr  Thu Sep  9 12:38:13 2004
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Thu, 9 Sep 2004 14:38:13 +0400
Subject: [R] Indexing dataframe
Message-ID: <HHEDKBCGCMDOHEDELFBCGECBCCAA.jacques.veslot@cirad.fr>

I am sorry to ask such question, but I can't find a solution...

I have a dataframe 'd2004' and I want to remove two columns:
'd2004$concentration' and 'd2004$stade".

I could do it just as follows:

> names(d2004)

 [1] "Localite"       "Date"           "parcelle"       "maille"
"presence.plant" "concentration"  "stade.culture"
 [8] "stade"          "Trou"           "Horizon"        "Profondeur"

> d2004 <- d2004[, -c(6, 8)]

but I'd like to use column names (to avoid finding column numbers each
time).

I cannot find an easy way to operate...

I wonder why that works:
> d2004[, "concentration"]

and this don't:
> d2004 <- d2004[, -c("concentration", "stade")]

Thanks...

Jacques VESLOT / CIRAD



From ripley at stats.ox.ac.uk  Thu Sep  9 12:41:12 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Sep 2004 11:41:12 +0100 (BST)
Subject: [R] Handling the windows clipboard/32KB limit
In-Reply-To: <156CDC8CCFD1894295D2907F16337A48B2AD51@bru-s-006.europe.shell.com>
Message-ID: <Pine.LNX.4.44.0409091125270.1182-100000@gannet.stats>

On Thu, 9 Sep 2004, Ritter, Christian C MCIL-CTANL/S wrote:

> (R 1.9.1; Windows 2000;)
> 
> I'm just comparing ease of use, speed, etc for methods of transferring
> data frames in the Excel, MySQL, R triangle. It turns out that going
> from Excel to R (when doing this carefully). Using the clipboard is
> actually quite fast and efficient (2 seconds for transferring 120 000
> cells on a common desktop computer as compared to much longer for going
> the RODBC route, maybe also substantially longer using the R(D)COM
> route). Other advantage: Relatively flexible handling of missing values
> from Excel which may be "empty", "#N/A", etc. 

You clearly haven't looked at RODBC carefully as that has equally flexible 
handling.

> So I thought I would also look at ways of going back via the clipboard.
> There I'm hitting a funny snag. The documentation explains that there is
> a 32KB limit on writing to the clipboard. This may make sense as a
> default, but does it make sense as a hard restriction?

I guess you are talking about using file="clipboard" in a connection, but
there is also writeClipboard, whose documentation does not mention a 
limit.

My Windows documentation says there is a 32Kb limit on the size of an 
text object put on the clipboard, and I believe that is the case for
Windows 95/98/ME at least.  So a hard restriction makes sense.

> Any ideas of getting around this limitation (besides cumbersome R-code
> buffering/breaking up the frame to send into small pieces to be
> collected and assembled in Excel?

R is Open Source, so this is an opportunity for you to experiment, test on 
various versions of Windows and contribute a patch back to the R project.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From thpe at hhbio.wasser.tu-dresden.de  Thu Sep  9 12:56:09 2004
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Thu, 09 Sep 2004 12:56:09 +0200
Subject: [R] Indexing dataframe
In-Reply-To: <HHEDKBCGCMDOHEDELFBCGECBCCAA.jacques.veslot@cirad.fr>
References: <HHEDKBCGCMDOHEDELFBCGECBCCAA.jacques.veslot@cirad.fr>
Message-ID: <414036C9.3060906@hhbio.wasser.tu-dresden.de>

Jacques VESLOT wrote:

> I am sorry to ask such question, but I can't find a solution...
> 
> I have a dataframe 'd2004' and I want to remove two columns:
> 'd2004$concentration' and 'd2004$stade".

d2004$concentration <- NULL
d2004$stade         <- NULL

Hope it helps!

Thomas P.



From Matthias.Templ at statistik.gv.at  Thu Sep  9 13:00:17 2004
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Thu, 9 Sep 2004 13:00:17 +0200
Subject: AW: [R] Indexing dataframe
Message-ID: <83536658864BC243BE3C06D7E936ABD501BE190B@xchg1.statistik.gv.at>

Hi,

Use
Newdata <- subset(d2004, select=-c(concentration,stade))

See ?subset for details

Best,
Matthias

> -----Urspr??ngliche Nachricht-----
> Von: Jacques VESLOT [mailto:jacques.veslot at cirad.fr] 
> Gesendet: Donnerstag, 09. September 2004 12:38
> An: r-help at stat.math.ethz.ch
> Betreff: [R] Indexing dataframe
> 
> 
> I am sorry to ask such question, but I can't find a solution...
> 
> I have a dataframe 'd2004' and I want to remove two columns: 
> 'd2004$concentration' and 'd2004$stade".
> 
> I could do it just as follows:
> 
> > names(d2004)
> 
>  [1] "Localite"       "Date"           "parcelle"       "maille"
> "presence.plant" "concentration"  "stade.culture"
>  [8] "stade"          "Trou"           "Horizon"        "Profondeur"
> 
> > d2004 <- d2004[, -c(6, 8)]
> 
> but I'd like to use column names (to avoid finding column 
> numbers each time).
> 
> I cannot find an easy way to operate...
> 
> I wonder why that works:
> > d2004[, "concentration"]
> 
> and this don't:
> > d2004 <- d2004[, -c("concentration", "stade")]
> 
> Thanks...
> 
> Jacques VESLOT / CIRAD
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read 
> the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Thu Sep  9 13:22:49 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Sep 2004 12:22:49 +0100 (BST)
Subject: [R] Installing packages on OS X
In-Reply-To: <1094721408.10353.29.camel@biol102145.oulu.fi>
Message-ID: <Pine.LNX.4.44.0409091219070.1413-100000@gannet.stats>

Here's my guess:

R CMD INSTALL installs to .Library, and does not look at R_LIBS unless set 
in its environment.

install.packages() installs at .libPaths()[1], and uses all the library 
trees available.  So if you have R_LIBS set in ~/.Renviron (as I have), or 
.libPaths() set in .Rprofile or elsewhere, you need to set R_LIBS in your 
shell before calling R CMD check (l/case).

On 9 Sep 2004, Jari Oksanen wrote:

> On Wed, 2004-09-08 at 21:25, hadley wickham wrote:
> > On my computer, it seems that (binary?) packages installed through the
> > GUI in RAqua are not used available to the command line version of R,
> > while (source) packages installed with R CMD INSTALL are available to
> > both.  This is a problem when I run R CMD CHECK on a package that I am
> > creating that depends on packages I have installed through the gui.
> > 
> > Is this a problem with my installation of R, or a known limitation?
> > (there is no mention of this in the Mac OS X faq, however, the entire
> > section entitled "Installing packages" is blank).
> > 
> It is in some other FAQ... Unfortunately, I don't have a Mac available
> now, so I can't check. However, seek for "environmental variables" and
> "setting library paths" in some other R FAQ or R
> Administration/Installation guide. There will you find a description of
> things you should do. It is just as crystal clear as unix man pages:
> everything is clear *after* you know what is said there, but you may
> have hard time noticing this clarity.
> 
> I solved this problem some months ago after a long search among the
> official documentation. So it is documented, but well hidden.
> 
> I may have a look at a machine where I solved this in the evening
> (UTC+3), if you won't get solution before that.
> 
> cheers, jari oksanen
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From HDoran at air.org  Thu Sep  9 13:25:45 2004
From: HDoran at air.org (Doran, Harold)
Date: Thu, 9 Sep 2004 07:25:45 -0400
Subject: [R] isoMDS
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7404044D1B@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040909/e24802ca/attachment.pl

From rdiaz at cnio.es  Thu Sep  9 13:37:18 2004
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Thu, 9 Sep 2004 13:37:18 +0200
Subject: [R] degrees of freedom (lme4 and nlme)
In-Reply-To: <BAY2-F6IDk4JdxVHYEu00005f8f@hotmail.com>
References: <BAY2-F6IDk4JdxVHYEu00005f8f@hotmail.com>
Message-ID: <200409091337.18860.rdiaz@cnio.es>

Dear Elizabeth,

When I looked for this a couple of years ago, I found DF's to be discussed in 
the book by Pinheiro & Bates "Mixed effects models for S and S-Plus", as well 
as the documentation for SAS's PROC MIXED (I believe that the discussion on 
df's on the SAS "manual" was more complete than on the "SAS system for mixed 
models book" ---and I think html versions of the manuals for v 8 of SAS can 
be found on the web). I do not remember specifically, though, whether this 
discussions mentioned explicitly DFs for fixed effects with crossed random 
effects (I do not have the references here now).

Best,

R.

On Wednesday 08 September 2004 19:54, Elizabeth Lynch wrote:
> Hi,
>
> I'm looking for pointers/references on calculating den DF's for fixed
> effects when using crossed random effects. Also, is there an implementation
> of simulate.lme that I could use in lme4?
>
> Thanks,
>
> Elizabeth Lynch
>
> Douglas Bates wrote:
> >Alexandre Galv??o Patriota wrote:
> >>Hi, I'm having some problems regarding the packages
> >>lme4 and nlme, more specifically in the denominator
> >>degrees of freedom. <SNIP>
> >
> >The lme4 package is under development and only has a stub for the code
> > that calculates the denominator degrees of freedom.
> >
> >These Wald-type tests using the F and t distributions are approximations
> > at best.  In that sense there is no "correct" degrees of freedom.  I
> > think the more accurate tests may end up being the restricted likelihood
> > ratio tests that Greg Reinsel and his student Mr. Ahn were working on at
> > the time of Greg's death.
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> >http://www.R-project.org/posting-guide.html
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Ram??n D??az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol??gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern??ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)



From jarioksa at sun3.oulu.fi  Thu Sep  9 13:56:14 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 09 Sep 2004 14:56:14 +0300
Subject: [R] isoMDS
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7404044D1B@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F7404044D1B@dc1ex2.air.org>
Message-ID: <1094730974.10353.42.camel@biol102145.oulu.fi>

On Thu, 2004-09-09 at 14:25, Doran, Harold wrote:
> Thank you. I use the same matrix on cmdscale as I did with isoMDS. I
> have reproduced my steps below for clarification if this happens to
> shed any light.
<--- snip --->

Doran,

Your data clarified things. It seems to me now, that your data are not a
a matrix but a data.frame. A problem for an ordinary user is that
data.frames and matrices look identical, but that's only surface: you
shouldn't be shallow but look deep in their souls to see that they are
compeletely different, and therefore isoMDS fails. At least isoMDS gives
just that error for a data.frame, but cmdscale casts data.frame to a
matrix therefore it works.

So the following should work (worked when I tied):

tt <- as.matrix(tt)
isoMDS(tt)

(and you could down to a dist object with tt <- as.dist(tt) which seems
to handle data.frames directly, too).

Then you will still need to avoid the complaint about zero-distances
among points. This means that you have some identical points in your
data, and isoMDS does not like them. This issue was discussed here in
April, 2004 (and many other times). Search archives for the subject
"question on isoMDS".

cheers, jari oksanen
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From HankeA at mar.dfo-mpo.gc.ca  Thu Sep  9 14:02:49 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Thu, 09 Sep 2004 09:02:49 -0300
Subject: [R] isoMDS
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE124A20@msgmarsta01.bio.dfo.ca>

I get the following message:
Error in isoMDS(tt) : zero or negative distance between objects 1 and 2
This makes sense since a and b are identical in their relationship to c to
h. 
Drop row 1 and col 1 and you get
> isoMDS(tt[2:8,2:8])
initial  value 14.971992 
iter   5 value 8.027815
iter  10 value 4.433377
iter  15 value 3.496364
iter  20 value 3.346726
final  value 3.233738 
converged
$points
           [,1]       [,2]
[1,] -2.3143653 -0.1259226
[2,] -0.3205746 -1.1534662
[3,] -2.8641922 -0.1182906
[4,]  0.7753674  0.1497328
[5,] -0.5705552  1.2416843
[6,]  2.2305175 -0.6995917
[7,]  3.0638025  0.7058540

$stress
[1] 3.233738

Does this help?

-----Original Message-----
From: Doran, Harold [mailto:HDoran at air.org] 
Sent: September 9, 2004 8:26 AM
To: Jari Oksanen
Cc: Doran, Harold; Prof Brian Ripley; R-News
Subject: RE: [R] isoMDS


Thank you. I use the same matrix on cmdscale as I did with isoMDS. I have
reproduced my steps below for clarification if this happens to shed any
light.
 
Here is the original total matrix (see opening thread if you care how this
is created)
 
  a b c d e f g h
a 4 4 2 4 1 2 0 0
b 4 4 2 4 1 2 0 0
c 2 2 4 2 3 2 2 1
d 4 4 2 4 1 2 0 0
e 1 1 3 1 4 3 3 2
f 2 2 2 2 3 4 2 1
g 0 0 2 0 3 2 4 3
h 0 0 1 0 2 1 3 4
 
So, there are 8 items. This matrix indicates that items 1,2, and 4 were
always grouped together (or viewed as being similar by individuals). I
transformed this using 
 
tt<-max(t)-t
 
which results in
  a b c d e f g h
a 0 0 2 0 3 2 4 4
b 0 0 2 0 3 2 4 4
c 2 2 0 2 1 2 2 3
d 0 0 2 0 3 2 4 4
e 3 3 1 3 0 1 1 2
f 2 2 2 2 1 0 2 3
g 4 4 2 4 1 2 0 1
h 4 4 3 4 2 3 1 0
 
When I run isoMDS on this new matrix, it tells me to specify the initial
config because of the NA/INFs/ But when I perform cmdscale on this same
matrix I end up with the following results,
 
> bt<-cmdscale(tt);bt
 
         [,1]       [,2]
a -1.79268634 -0.2662750
b -1.79268634 -0.2662750
c -0.02635497  0.5798934
d -1.79268634 -0.2662750
e  1.08978620  0.6265313
f -0.02635497  0.5798934
g  2.20852966  0.2828937
h  2.13245309 -1.2703869
 
The results suggest that items 1,2, and 4 have similar locations as is
expected. Also items 3 and 6 have similar locations as would also be
expected. So, my results seem to have been replicated correctly using
cmdscale. 
 
I've tried to specify an initial config using isoMDS in a few ways without
success, so I am surely doing something wrong. So far, I have tried the
following:
 
> ll<-isoMDS(tt, y=cmdscale(tt))
 
which tells me "zero or negative distance between objects 1 and 2"
 
> ll<-isoMDS(tt, y=cmdscale(tt, k=2))
 
 
Again, thanks,
 
Harold
 
 

	-----Original Message----- 
	From: Jari Oksanen [mailto:jarioksa at sun3.oulu.fi] 
	Sent: Thu 9/9/2004 4:26 AM 
	To: Doran, Harold 
	Cc: Prof Brian Ripley; R-News 
	Subject: RE: [R] isoMDS
	
	

	On Wed, 2004-09-08 at 21:31, Doran, Harold wrote:
	> Thank you. Quick clarification. isoMDS only works with
dissimilarities.
	> Converting my similarity matrix into the dissimilarity matrix is
done as
	> (from an email I found on the archives)
	>
	> > d<- max(tt)-tt
	>
	> Where tt is the similarity matrix. With this, I tried isoMDS as
follows:
	>
	> > tt.mds<-isoMDS(d)
	>
	> and I get the following error message.
	>
	> Error in isoMDS(d) : An initial configuration must be supplied
with
	> NA/Infs in d. I was a little confused on exactly how to specify
this
	> initial config. So, from here I ran cmdscale on d as
	>
	This error message is quite informative: you have either missing or
	non-finite entries in your data. The only surprising thing here is
that
	cmdscale works: it should fail, too. Are you sure that you haven't
done
	anything with your data matrix in between, like changed it from
matrix
	to a dist object? If the Inf/NaN/NA values are on the diagonal, they
	will magically disappear with as.dist. Anyway, if you're able to get
a
	metric scaling result, you can manually feed that into isoMDS for
the
	initial configuration, and  avoid the check. See ?isoMDS.
	
	> > d.mds<-cmdscale(d)
	>
	> which seemed to work fine and produce reasonable results. I was
able to
	> take the coordinates and run them through a k-means cluster and
the
	> results seemed to correctly match the grouping structure I created
for
	> this sample analysis.
	>
	> Cmdscale is for metric scaling, but it seemed to produce the
results
	> correctly.
	>
	> So, did I correctly convert the similarity matrix to the
dissimilarity
	> matrix? Second, should I have used cmdscale rather than isoMDS as
I have
	> done? Or, is there a way to specify the initial configuration that
I
	> have not done correctly.
	
	If you don't know whether you should use isoMDS or cmdscale, you
	probably should use cmdscale. If you know, things are different.
	Probably isoMDS gives you `better'(TM) results, but it is more
	complicated to handle.
	
	cheers, jari oksanen
	--
	Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
	Ph. +358 8 5531526, cell +358 40 5136529, fax +358 8 5531061
	email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/
	
	


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From msvika at mscc.huji.ac.il  Thu Sep  9 15:46:00 2004
From: msvika at mscc.huji.ac.il (Vicky Landsman)
Date: Thu, 9 Sep 2004 15:46:00 +0200
Subject: [R] Adding GSL library path to SHLIB 
Message-ID: <002001c49673$57dccc70$9200a8c0@Home3>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040909/6ef8f039/attachment.pl

From christian.ritter at shell.com  Thu Sep  9 14:47:59 2004
From: christian.ritter at shell.com (Ritter, Christian C MCIL-CTANL/S)
Date: Thu, 9 Sep 2004 14:47:59 +0200
Subject: [R] Handling the windows clipboard/32KB limit
Message-ID: <156CDC8CCFD1894295D2907F16337A48B2AD53@bru-s-006.europe.shell.com>

Thanks Brian for the hint. 

Indeed, writeClipboard does not suffer from the 32KB limit. Here is a line which can put large quantities of data on the clipboard:
writeClipboard(gsub("NA","\#N/A",apply(Alldata,1,paste,collapse="\t")))
this can then be pasted either manually or via a VBA macro into a spreadsheet. 

Here is some more info for R/Excel junkies:
===========================================
VBA example using RExcel to pass the command:
Sub FetchDataframe(Dfname As String, TargetRange As Range)
    Dim commandString As String
    commandString = "writeClipboard(c(paste(colnames(" & Dfname & "),collapse='\t'),gsub('NA','\#N/A',apply(" & Dfname & ",1,paste,collapse='\t'))))"
    Call RRun(commandString)
    TargetRange.PasteSpecial
End Sub
Again, the time for 
	FetchDataframe "Alldata",Range("Sheet1!$A$1") 
on about 120000 cells is on the order of two or three seconds. I looked at scaling. For 360000 (mixed type) cells, the required time was on the order of 15 seconds. 

I also looked at putting data from Excel to R: Here things scale even better. Using the code:
Sub PutDataframe(Dfname As String, TargetRange As Range)
    Dim commandString As String
    commandString = Dfname & "<-read.table(file=file(description='clipboard'),sep='\t',na.strings=c('#N/A',''),header=TRUE,comment.char=';')"
    TargetRange.Copy
    Call RRun(commandString)
End Sub
the transfer 
	PutDataframe "Alldata",Range("Alldata")
took 7 seconds for 360000 (mixed type) cells.  	

As Brian points out: Obviously, RODBC is more flexible for selecting, cleaning, etc. But in my experience it is a bit slow when dealing with Excel as a data source (via dsn<-odbcConnectExcel("Myfile.xls"). I redid my 120000 cell example using Alldata<-sqlFetch(dsn,"Alldata") and needed about 80 seconds. Now, this is not the fault of RODBC but probably of starting and using the jet data engine within Windows. 
Moreover, in particular, if the workbook Myfile.xls is actually open wile odbc is working on it, there may be memory or performance leaks (probably unrelated to RODBC). If I retrieve the same data frame (from Excel) several times, (either opening and closing the connection every time or opening it once and fetching several times) the retrieval times can become much slower as a go. At some time there may be "waiting for an OLE action to complete messages".

RExcel/R(D)COM gives a third possibility with probably much more flexibility/safety than my crude clipboard method and we are currently working hard at increasing its speed. Currently, we are at about 20 seconds for the 120000 cell example.

In summary, what strikes me about the clipboard approach is its speed and the size of objects which can be moved between Excel and R. Some fine tuning will be needed to deal with exceptions. 



-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Thursday, 09 September, 2004 12:41 PM
To: Ritter, Christian C MCIL-CTANL/S
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Handling the windows clipboard/32KB limit


On Thu, 9 Sep 2004, Ritter, Christian C MCIL-CTANL/S wrote:

> (R 1.9.1; Windows 2000;)
> 
> I'm just comparing ease of use, speed, etc for methods of transferring
> data frames in the Excel, MySQL, R triangle. It turns out that going
> from Excel to R (when doing this carefully). Using the clipboard is
> actually quite fast and efficient (2 seconds for transferring 120 000
> cells on a common desktop computer as compared to much longer for going
> the RODBC route, maybe also substantially longer using the R(D)COM
> route). Other advantage: Relatively flexible handling of missing values
> from Excel which may be "empty", "#N/A", etc. 

You clearly haven't looked at RODBC carefully as that has equally flexible 
handling.

> So I thought I would also look at ways of going back via the clipboard.
> There I'm hitting a funny snag. The documentation explains that there is
> a 32KB limit on writing to the clipboard. This may make sense as a
> default, but does it make sense as a hard restriction?

I guess you are talking about using file="clipboard" in a connection, but
there is also writeClipboard, whose documentation does not mention a 
limit.

My Windows documentation says there is a 32Kb limit on the size of an 
text object put on the clipboard, and I believe that is the case for
Windows 95/98/ME at least.  So a hard restriction makes sense.

> Any ideas of getting around this limitation (besides cumbersome R-code
> buffering/breaking up the frame to send into small pieces to be
> collected and assembled in Excel?

R is Open Source, so this is an opportunity for you to experiment, test on 
various versions of Windows and contribute a patch back to the R project.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From christoph.lehmann at gmx.ch  Thu Sep  9 15:07:08 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Thu, 09 Sep 2004 15:07:08 +0200
Subject: [R] locator() in a multi-figure setting using mfrow(): SOLVED
In-Reply-To: <413C3088.1000707@gmx.ch>
References: <413C2568.6020007@gmx.ch> <413C3088.1000707@gmx.ch>
Message-ID: <4140557C.3030206@gmx.ch>

thanks to some great hints by Paul Murrel I could solve it: here we are 
with one solution (code needs to be cleaned and simplified, but maybe 
one can understand it)

#######
## create a multifigure setting
nr <- 4
nc <- 2
opar <- par(mfrow = c(nr, nc))
slices <- 8
m <- matrix(runif(100),10,10)
my.list <- list()
for (slice in 1:slices) {
     my.list[[slice]] <- m
}

for  (slice in 1:slices) {
     x <- 1*(1:25)
     y <- 1*(1:25)
     z <- my.list[[slice]]
     image(list(x = 0:9, y = 0:9, z = z))
}
########
my.get.coord <- function() {
par(mfg = c(1,1)) #locator() shall be relative to the first plot out
# of the eight plots totally
my.loc <-locator(1) #location, not in inches
my.plot.region <- par("usr") #extremes of plotting region
#(in plot units, not inches)
my.plot.region.x <- my.plot.region[2] - my.plot.region[1]
my.plot.region.y <- my.plot.region[4] - my.plot.region[3]
my.loc.inch.x <- (my.loc$x + 0.5)/my.plot.region.x * (par("pin")[1]) 
#par("pin") #current plot dimension in inches
#relative to the plotting-region bottom left corner, not the axis c(0,0) 
point
my.loc.inch.y <- (my.loc$y + 0.5)/my.plot.region.y * (par("pin")[2])

## search the plot we are in with locator(1)
my.plot.inch.x <- par("pin")[1] + par("mai")[2] + par("mai")[4] #plot.x 
+ left & right margin
par("fin")[1]
my.plot.inch.y <- par("pin")[2] + par("mai")[1] + par("mai")[3] #plot.y 
+ bottom & top margin
par("fin")[2]

pos.rel.x <- (my.loc.inch.x / par("fin")[1] - floor(my.loc.inch.x / 
par("fin")[1])) *
      par("fin")[1] / par("pin")[1] * (par("usr")[2] - par("usr")[1]) - 0.5
      #inches from left bottom corner in target plot region (c(0,0)
      # is plot-region bottom-left corner, not the axis c(0,0) point
pos.rel.y <- (my.loc.inch.y / par("fin")[2] - floor(my.loc.inch.y / 
par("fin")[2])) *
      par("fin")[2] / par("pin")[2] * (par("usr")[4] - par("usr")[3]) - 0.5
      #inches from left bottom corner in target plot

fig.coord.x <- ceiling(my.loc.inch.x / par("fin")[1])
fig.coord.y <- 1 +(-1) *ceiling(my.loc.inch.y / par("fin")[2])
# cat("figure-coord x: ", fig.coord.x,"\n")
# cat("figure-coord y: ", fig.coord.y,"\n")
cat("we are in figure: ", fig.coord.y * nc + fig.coord.x, "\n")
cat("coordinates of the identified point x: ", round(pos.rel.x),"\n")
cat("coordinates of the identified point y: ", round(pos.rel.y),"\n")
}

########
my.get.coord()


Christoph



From ripley at stats.ox.ac.uk  Thu Sep  9 15:17:12 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Sep 2004 14:17:12 +0100 (BST)
Subject: [R] Adding GSL library path to SHLIB 
In-Reply-To: <002001c49673$57dccc70$9200a8c0@Home3>
Message-ID: <Pine.LNX.4.44.0409091407320.1142-100000@gannet.stats>

On Thu, 9 Sep 2004, Vicky Landsman wrote:

> Dear R-list people, 

> I asked a similar question a few hours before. I will try to be more
> specific.  We like to add the GSL library to the file SHLIB in order to
> make it possible to run the C code using GSL functions from R.  We read

Read where?  It's incorrect information and only used for Fortran linking.

> that the path to the libgsl.a should be added to the line shlib_libadd='
> ' in the file SHLIB but it does not work on our system. Dyn.load fails
> with error "referenced symbol <symbolname> not found". What is wrong?  
> We will much appreciate any help on this.
> 
> We are using R-1.9.1 on Unix. 

You should have a file called Makevars in the directory from which 
you are doing the building, defining PKG_LIBS, maybe

PKG_LIBS="-L/path/to/libgsl -lgsl"

in the same way as you would for a package: see `Writing R Extensions'.
I don't think that is documented anywere, though.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From falaise at web.de  Thu Sep  9 15:24:31 2004
From: falaise at web.de (Ute)
Date: Thu, 09 Sep 2004 15:24:31 +0200
Subject: [R] tree architecture in Random Forest
Message-ID: <4140598F.5060504@web.de>

Hello,

I'm doing classification with random Forest using numeric predictor 
variables. I would like to know a detail in the tree architecture: to 
which side of a node data are sent if , for the split variable, their 
value is higer than the split point?

best regards,

Ute M??ller



From andy_liaw at merck.com  Thu Sep  9 15:30:58 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 9 Sep 2004 09:30:58 -0400
Subject: [R] tree architecture in Random Forest
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8358@usrymx25.merck.com>

> From: Ute
> 
> Hello,
> 
> I'm doing classification with random Forest using numeric predictor 
> variables. I would like to know a detail in the tree architecture: to 
> which side of a node data are sent if , for the split variable, their 
> value is higer than the split point?

The right, as one would usually draw a real line...

Andy

 
> best regards,
> 
> Ute M??ller
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From James_A_Rogers at groton.pfizer.com  Thu Sep  9 15:43:24 2004
From: James_A_Rogers at groton.pfizer.com (Rogers, James A [PGRD Groton])
Date: Thu, 9 Sep 2004 09:43:24 -0400 
Subject: [R] confidence intervals
Message-ID: <C735670CCC69D61193DA0002A58EE9900D7F53E9@groexmb07.pfizer.com>


Robert, 

I have this quick hack to obtain approximate "Shewhart" prediction intervals
for variance component models fit with lme (to nitpick slightly,
"confidence" intervals have the interpretation of containing parameters,
while "prediction" and "tolerance" intervals have the interpretation of
containing future observations or statistics). 

Back of the envelope documentation: the only argument that probably needs
explaining is the "reps" argument to shewhart(). If your model is, e.g.

fixed = Y ~ 1, random = ~ 1 | Batch

then specify reps = c(1, 1) if you want to predict a single future
observation from a single future batch, reps = c(1, 2) if you want to
predict the mean of two future observations from a single future batch, reps
= c(2, 2) if you want to predict the mean of 4 observations spread evenly
over 2 future batches, ...

Leave mult.check = 1, unless you want to do a Bonferroni correction. 

HTH, 

Jim Rogers


valStats2 <- 
function (x, fixed, random, ...) 
{
    mod <- lme(fixed = fixed, data = x, random = random, ...)
    mn <- fixef(mod)
    vc <- VarCorr(mod)
    err <- "Expecting only random intercept terms and a single fixed
intercept.\n"
    if (length(mn) > 1 || ncol(vc) > 2) 
        stop(err)
    rn <- rownames(vc)
    skip <- regexpr("=", rn) > 0
    if (!any(skip)) 
        vnms <- attr(vc, "title")
    else vnms <- grep("=", rn, value = TRUE)
    vc <- vc[!skip, ]
    vnms <- trim(sub("=.*", "", vnms))
    vnms <- c(vnms, "Residual")
    vnms <- paste("V", vnms, sep = ".")
    vars <- as.numeric(vc[, "Variance"])
    stats <- c(mn, vars)
    names(stats) <- c("Intercept", vnms)
    stats
}

shewhart <- 
function (x, meancol = "Intercept", varcols = grep("^V\\.", names(x), value
= TRUE), reps = c(1, 1), alpha = 0.02, mult.check = 1) 
{
    mn <- x[[meancol]]
    vr <- as.matrix(x[varcols])
    totvar <- vr %*% (1/reps)
    totsd <- sqrt(totvar)
    LL.mean <- mn + qnorm(alpha/2/mult.check) * totsd
    UL.mean <- mn + qnorm(1 - alpha/2/mult.check) * totsd
    out <- data.frame(V.Total = totvar, LL.mean = LL.mean, UL.mean =
UL.mean)
    out
}


### Example, where x is your data.frame:

foo <- valStats2(x, fixed = Y ~ 1, random = ~ 1|Batch)
foo <- as.data.frame(t(as.matrix(foo)))
data.frame(foo, shewhart(foo))



> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Spencer Graves
> Sent: Friday, September 03, 2004 11:58 AM
> To: bates at wisc.edu
> Cc: Robert Waters; r-help at stat.math.ethz.ch
> Subject: Re: [R] confidence intervals
> 
> 
> Hi, Robert: 
> 
>       While it may be difficult to program this in general 
> (as suggested 
> by it's position on Doug's "To Do" list), all the pieces should be 
> available to support a special script for your specific application.  
> What fixed and random model(s) interest you most? 
> 
>       hope this helps.  spencer graves
> 
> Douglas Bates wrote:
> 
> > Robert Waters wrote:
> >
> >> Dear R users;
> >>
> >> Im working with lme and Id like to have an idea of how
> >> can I get CI for the predictions made with the model.
> >> Im not a stats guy but, if Im not wrong, the CIs
> >> should be different if Im predicting a new data point
> >> or a new group. Ive been searching through the web and
> >> in help-lists with no luck. I know this topic had been
> >> asked before but without replies. Can anyone give an
> >> idea of where can I found information about this or
> >> how can I get it from R?
> >>
> >> Thanks for any hint
> >
> >
> > That's not currently implemented in lme.  It's on the "To 
> Do" list but 
> > it is not very close to the top.
> >




LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From gilal at md.huji.ac.il  Thu Sep  9 16:03:07 2004
From: gilal at md.huji.ac.il (Gila Lithwick)
Date: Thu, 09 Sep 2004 17:03:07 +0300
Subject: [R] kolmogorov-smirnov for discrete ordinal scale data
Message-ID: <4140629B.3030400@md.huji.ac.il>

Hi,

I was wondering whether there is an implementation of the 
Kolmogorov-Smirnov goodness of fit test for discrete, ordinal scale data 
in R - I've only managed to find the test for continuous data.

Thanks!
Gila



From riskpro_jw at hotmail.com  Thu Sep  9 16:17:56 2004
From: riskpro_jw at hotmail.com (J W)
Date: Thu, 09 Sep 2004 09:17:56 -0500
Subject: [R] Copulas
Message-ID: <BAY18-F40EFTLm4GzCl0001e176@hotmail.com>

Is anyone already in the process of developing copula estimation methods or 
porting Prof. Rene Carmona's EVANESCE 
(http://www.orfe.princeton.edu/~rcarmona/SVbook/svbook.html)?

JW



From HankeA at mar.dfo-mpo.gc.ca  Thu Sep  9 16:42:28 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Thu, 09 Sep 2004 11:42:28 -0300
Subject: [R] kolmogorov-smirnov for discrete ordinal scale data
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE124A22@msgmarsta01.bio.dfo.ca>

Hi
I think the answer is no. However, I have written a script that implements
the test described in "Testing for shifts in the Vertical Distribution of
Plankton using a robust Kolmogorov-Smirnov like Statistic" by Smith, Beet
and Solow (1998). The test has the properties you are looking for. If this
sounds helpful let me know.
Alex

-----Original Message-----
From: Gila Lithwick [mailto:gilal at md.huji.ac.il] 
Sent: September 9, 2004 11:03 AM
To: r-help at stat.math.ethz.ch
Subject: [R] kolmogorov-smirnov for discrete ordinal scale data


Hi,

I was wondering whether there is an implementation of the 
Kolmogorov-Smirnov goodness of fit test for discrete, ordinal scale data 
in R - I've only managed to find the test for continuous data.

Thanks!
Gila

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From rrsilva at ib.usp.br  Thu Sep  9 17:17:44 2004
From: rrsilva at ib.usp.br (=?iso-8859-1?q?Rog=E9rio_Rosa_da_Silva?=)
Date: Thu, 9 Sep 2004 12:17:44 -0300
Subject: [R] discriminant analysis
Message-ID: <200409091217.44417.rrsilva@ib.usp.br>

Dear all,

I'm having difficulty getting the procedure for discriminant analysis. How can 
I specify the forward or backward stepwise analyses of variables into the 
model? I'm using lda in MASS and discrimin (ade4). I run R version 1.9.1.

Thanks,

Rog??rio



From msvika at mscc.huji.ac.il  Thu Sep  9 18:18:11 2004
From: msvika at mscc.huji.ac.il (Vicky Landsman)
Date: Thu, 9 Sep 2004 18:18:11 +0200
Subject: [R] Adding GSL library path to SHLIB 
References: <Pine.LNX.4.44.0409091407320.1142-100000@gannet.stats>
Message-ID: <006801c49688$9a538520$9200a8c0@Home3>

Dear Prof. Ripley,
We read the archive thread
http://maths.newcastle.edu.au/~rking/R/help/02b/0547.html
Thank you for your help, we will try to create the Makevars file.
Vicky.



----- Original Message ----- 
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Vicky Landsman" <msvika at mscc.huji.ac.il>
Cc: "r-help" <r-help at stat.math.ethz.ch>; <leonid at cc.huji.ac.il>
Sent: Thursday, September 09, 2004 3:17 PM
Subject: Re: [R] Adding GSL library path to SHLIB


> On Thu, 9 Sep 2004, Vicky Landsman wrote:
>
> > Dear R-list people,
>
> > I asked a similar question a few hours before. I will try to be more
> > specific.  We like to add the GSL library to the file SHLIB in order to
> > make it possible to run the C code using GSL functions from R.  We read
>
> Read where?  It's incorrect information and only used for Fortran linking.
>
> > that the path to the libgsl.a should be added to the line shlib_libadd='
> > ' in the file SHLIB but it does not work on our system. Dyn.load fails
> > with error "referenced symbol <symbolname> not found". What is wrong?
> > We will much appreciate any help on this.
> >
> > We are using R-1.9.1 on Unix.
>
> You should have a file called Makevars in the directory from which
> you are doing the building, defining PKG_LIBS, maybe
>
> PKG_LIBS="-L/path/to/libgsl -lgsl"
>
> in the same way as you would for a package: see `Writing R Extensions'.
> I don't think that is documented anywere, though.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>



From laurent.buffat at it-omics.com  Thu Sep  9 17:19:36 2004
From: laurent.buffat at it-omics.com (Laurent Buffat)
Date: Thu, 9 Sep 2004 17:19:36 +0200
Subject: [R] SJava, Client X11
Message-ID: <20040909151937.F3E9793EE@heart.itomics.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040909/d0ffe91d/attachment.pl

From Whit.Armstrong at tudor.com  Thu Sep  9 18:01:56 2004
From: Whit.Armstrong at tudor.com (Whit Armstrong)
Date: Thu, 9 Sep 2004 12:01:56 -0400 
Subject: [R] scoping rules
Message-ID: <7669F018DC9DD711AEC500065B3D5ABF02CAD450@tudor.com>

Can someone help me with this simple example?

sq <- function() {
	y <- x^2
	y
}

myfunc <- function() {
	x <- 10
	sq()
}

myfunc()


executing the above in R yields:
> myfunc()
Error in sq() : Object "x" not found

I understand that R's scoping rules cause it to look for "x" in the
environment in which "sq" was defined (the global environment in this case).
But in this case "x" is defined inside the calling function, not the
environment in which "sq" was defined.

Is there a way to tell R to look in the calling function for "x" ?

I have tried the following variants of "eval" such as
eval(sq(),parent.frame()) with no success.

Thanks for your help.

Regards,
Whit

> R.Version()
$platform
[1] "i386-pc-mingw32"

$arch
[1] "i386"

$os
[1] "mingw32"

$system
[1] "i386, mingw32"

$status
[1] ""

$major
[1] "1"

$minor
[1] "9.1"

$year
[1] "2004"

$month
[1] "06"

$day
[1] "21"

$language
[1] "R"

>



From ripley at stats.ox.ac.uk  Thu Sep  9 18:17:32 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Sep 2004 17:17:32 +0100 (BST)
Subject: [R] Adding GSL library path to SHLIB 
In-Reply-To: <006801c49688$9a538520$9200a8c0@Home3>
Message-ID: <Pine.LNX.4.44.0409091717040.1477-100000@gannet.stats>

On Thu, 9 Sep 2004, Vicky Landsman wrote:

> Dear Prof. Ripley,
> We read the archive thread
> http://maths.newcastle.edu.au/~rking/R/help/02b/0547.html

Things have changed in 2 years in R ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at myway.com  Thu Sep  9 18:28:17 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 9 Sep 2004 16:28:17 +0000 (UTC)
Subject: [R] scoping rules
References: <7669F018DC9DD711AEC500065B3D5ABF02CAD450@tudor.com>
Message-ID: <loom.20040909T182242-842@post.gmane.org>

Whit Armstrong <Whit.Armstrong <at> tudor.com> writes:

: 
: Can someone help me with this simple example?
: 
: sq <- function() {
: 	y <- x^2
: 	y
: }
: 
: myfunc <- function() {
: 	x <- 10
: 	sq()
: }
: 
: myfunc()
: 
: executing the above in R yields:
: > myfunc()
: Error in sq() : Object "x" not found
: 
: I understand that R's scoping rules cause it to look for "x" in the
: environment in which "sq" was defined (the global environment in this case).
: But in this case "x" is defined inside the calling function, not the
: environment in which "sq" was defined.
: 
: Is there a way to tell R to look in the calling function for "x" ?
: 
: I have tried the following variants of "eval" such as
: eval(sq(),parent.frame()) with no success.
: 



Here are two approaches:

1. have myfunc change sq's environment to the current environment:

sq <- function() { y <- x^2; y }
myfunc <- function() { x <- 10; environment(sq) <- environment(); sq() }
myfunc()

2. modify sq itself to get x from the parent frame.  We use get in
the example below but you could alternately replace get(...) with
eval.parent(substitute(x)) if you prefer to use eval:

sq <- function() { y <- get("x", parent.frame())^2; y }
myfunc <- function() { x <- 10; sq() }
myfunc()



From msvika at mscc.huji.ac.il  Thu Sep  9 19:32:56 2004
From: msvika at mscc.huji.ac.il (Vicky Landsman)
Date: Thu, 9 Sep 2004 19:32:56 +0200
Subject: [R] Dyn.load of sharing object with GSL library 
Message-ID: <007c01c49693$0b6edbb0$9200a8c0@Home3>

Following the recommendation of Prof. Ripley, I have created the Makevars
file with the line:
PKG_LIBS="-L/usr/lib/libm -lm -L/usr/local/lib/libgsl -lgsl -L/usr/local/lib
/libgslcblas -lgslcblas"
in the working directory.
Now I have the code file Example3.c which computes the Bessel function value
(the example is taken from the GSL reference book).
I am running:
R CMD SHLIB Example3.c
and all looks good.
The dyn.load("Example3.so") fails with the following error message:

Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
"/fs/users1/guest/msvika/PhD/R_04/Example3.so":
  ld.so.1: /usr/local/sbin/R-1.9/R-1.9.1/bin/R.bin: fatal: relocation error:
file /fs/users1/guest/msvika/PhD/R_04/Example3.so: symbol gsl_sf_bessel_J0:
referenced symbol not found

What is wrong?
Much thanks, Vicky.

----- Original Message ----- 
From: "Vicky Landsman" <msvika at mscc.huji.ac.il>
To: "r-help" <r-help at stat.math.ethz.ch>
Sent: Thursday, September 09, 2004 6:18 PM
Subject: Re: [R] Adding GSL library path to SHLIB


> Dear Prof. Ripley,
> We read the archive thread
> http://maths.newcastle.edu.au/~rking/R/help/02b/0547.html
> Thank you for your help, we will try to create the Makevars file.
> Vicky.
>
>
>
> ----- Original Message ----- 
> From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
> To: "Vicky Landsman" <msvika at mscc.huji.ac.il>
> Cc: "r-help" <r-help at stat.math.ethz.ch>; <leonid at cc.huji.ac.il>
> Sent: Thursday, September 09, 2004 3:17 PM
> Subject: Re: [R] Adding GSL library path to SHLIB
>
>
> > On Thu, 9 Sep 2004, Vicky Landsman wrote:
> >
> > > Dear R-list people,
> >
> > > I asked a similar question a few hours before. I will try to be more
> > > specific.  We like to add the GSL library to the file SHLIB in order
to
> > > make it possible to run the C code using GSL functions from R.  We
read
> >
> > Read where?  It's incorrect information and only used for Fortran
linking.
> >
> > > that the path to the libgsl.a should be added to the line
shlib_libadd='
> > > ' in the file SHLIB but it does not work on our system. Dyn.load fails
> > > with error "referenced symbol <symbolname> not found". What is wrong?
> > > We will much appreciate any help on this.
> > >
> > > We are using R-1.9.1 on Unix.
> >
> > You should have a file called Makevars in the directory from which
> > you are doing the building, defining PKG_LIBS, maybe
> >
> > PKG_LIBS="-L/path/to/libgsl -lgsl"
> >
> > in the same way as you would for a package: see `Writing R Extensions'.
> > I don't think that is documented anywere, though.
> >
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From h.wickham at gmail.com  Thu Sep  9 18:41:01 2004
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 9 Sep 2004 11:41:01 -0500
Subject: [R] Installing packages on OS X
In-Reply-To: <Pine.LNX.4.44.0409091219070.1413-100000@gannet.stats>
References: <1094721408.10353.29.camel@biol102145.oulu.fi>
	<Pine.LNX.4.44.0409091219070.1413-100000@gannet.stats>
Message-ID: <f8e6ff0504090909414315e5a0@mail.gmail.com>

Thanks to you both.  Setting R_LIBS='~/Library/R/library/' in
~/.Renviron did the trick.

Thanks,

Hadley



From gunter.berton at gene.com  Thu Sep  9 18:49:59 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 9 Sep 2004 09:49:59 -0700
Subject: [R] Proposal for New R List: Criticism? Comments?
Message-ID: <200409091649.i89Gnxof019985@ohm.gene.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040909/9a6ec698/attachment.pl

From ripley at stats.ox.ac.uk  Thu Sep  9 19:02:30 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Sep 2004 18:02:30 +0100 (BST)
Subject: [R] Dyn.load of sharing object with GSL library 
In-Reply-To: <007c01c49693$0b6edbb0$9200a8c0@Home3>
Message-ID: <Pine.LNX.4.44.0409091757260.1605-100000@gannet.stats>

On Thu, 9 Sep 2004, Vicky Landsman wrote:

> Following the recommendation of Prof. Ripley, I have created the Makevars
> file with the line:
> PKG_LIBS="-L/usr/lib/libm -lm -L/usr/local/lib/libgsl -lgsl -L/usr/local/lib
> /libgslcblas -lgslcblas"
> in the working directory.

No, that's not what I recommended. -L/path/to/libgsl would probably be
-L/usr/local/lib if libgsl is in /usr/local/lib.  And why do you want -lm?

Please consult your unstated OS's documentation for ld.

> Now I have the code file Example3.c which computes the Bessel function value
> (the example is taken from the GSL reference book).
> I am running:
> R CMD SHLIB Example3.c

Pleae show us exactly what you get here.

> and all looks good.
> The dyn.load("Example3.so") fails with the following error message:
> 
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>         unable to load shared library
> "/fs/users1/guest/msvika/PhD/R_04/Example3.so":
>   ld.so.1: /usr/local/sbin/R-1.9/R-1.9.1/bin/R.bin: fatal: relocation error:
> file /fs/users1/guest/msvika/PhD/R_04/Example3.so: symbol gsl_sf_bessel_J0:
> referenced symbol not found

Try ldd /fs/users1/guest/msvika/PhD/R_04/Example3.so and get a local
expert to interpret it for you.

You will need anything you had in -L in PKG_LIBS in your library run path
as well.  You may need e.g.

export LD_LIBRARY_PATH=:${LD_LIBRARY_PATH}:/usr/local/lib

and please check with a local expert about this.

> What is wrong?
> Much thanks, Vicky.
> 
> ----- Original Message ----- 
> From: "Vicky Landsman" <msvika at mscc.huji.ac.il>
> To: "r-help" <r-help at stat.math.ethz.ch>
> Sent: Thursday, September 09, 2004 6:18 PM
> Subject: Re: [R] Adding GSL library path to SHLIB
> 
> 
> > Dear Prof. Ripley,
> > We read the archive thread
> > http://maths.newcastle.edu.au/~rking/R/help/02b/0547.html
> > Thank you for your help, we will try to create the Makevars file.
> > Vicky.
> >
> >
> >
> > ----- Original Message ----- 
> > From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
> > To: "Vicky Landsman" <msvika at mscc.huji.ac.il>
> > Cc: "r-help" <r-help at stat.math.ethz.ch>; <leonid at cc.huji.ac.il>
> > Sent: Thursday, September 09, 2004 3:17 PM
> > Subject: Re: [R] Adding GSL library path to SHLIB
> >
> >
> > > On Thu, 9 Sep 2004, Vicky Landsman wrote:
> > >
> > > > Dear R-list people,
> > >
> > > > I asked a similar question a few hours before. I will try to be more
> > > > specific.  We like to add the GSL library to the file SHLIB in order
> to
> > > > make it possible to run the C code using GSL functions from R.  We
> read
> > >
> > > Read where?  It's incorrect information and only used for Fortran
> linking.
> > >
> > > > that the path to the libgsl.a should be added to the line
> shlib_libadd='
> > > > ' in the file SHLIB but it does not work on our system. Dyn.load fails
> > > > with error "referenced symbol <symbolname> not found". What is wrong?
> > > > We will much appreciate any help on this.
> > > >
> > > > We are using R-1.9.1 on Unix.
> > >
> > > You should have a file called Makevars in the directory from which
> > > you are doing the building, defining PKG_LIBS, maybe
> > >
> > > PKG_LIBS="-L/path/to/libgsl -lgsl"
> > >
> > > in the same way as you would for a package: see `Writing R Extensions'.
> > > I don't think that is documented anywere, though.
> > >
> > > -- 
> > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > > University of Oxford,             Tel:  +44 1865 272861 (self)
> > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > >
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From HankeA at mar.dfo-mpo.gc.ca  Thu Sep  9 18:56:23 2004
From: HankeA at mar.dfo-mpo.gc.ca (Hanke, Alex)
Date: Thu, 09 Sep 2004 13:56:23 -0300
Subject: [R] Skipping panels in Lattice
Message-ID: <E37EEC6DE3A0C5439B7E7B07406C24AE124A25@msgmarsta01.bio.dfo.ca>

I have the same problem. As far as I can see, the only thing you can do is :

attach(df2)
group=paste(facb,facc,sep=" ")
bwplot( dv ~ faca | factor(group))

Alex

-----Original Message-----
From: Leon Barmuta [mailto:Leon.Barmuta at utas.edu.au] 
Sent: September 9, 2004 1:19 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Skipping panels in Lattice


Dear all,

I wish to generate a lattice boxplot which skips an empty cell in a design. 
I have trawled r-help, scruitinized xyplot(lattice) help page, and merrily 
reproduced examples of using skip from a couple of previous r-help queries 
and the example given in Pinheiro & Bates. But I must be missing
something...

Here's an example (running R 1.9.1 on Win2k):

# generate some data

df1 <- data.frame(expand.grid(obsnum=seq(1, 15, 1), faca=c("A1", "A2",
"A3"),
     facb=c("B1","B2", "B3", "B4"), facc=c("C1","C2")),
dv=rpois(15*3*4*2,10))

# now get rid of the cell B4 & C1 to simulate a missing treatment
combination

df2 <- df1[df1$facb !="B4" | df1$facc !="C1", ]

# plain vanilla lattice plot generates an empty panel corresponding to the 
empty cell

plot1 <- bwplot( dv ~ faca | facb*facc, data=df2)
plot1

# now try to skip the empty panel
# turn plot history on so that the separate pages can be recalled

plot2 <- update(plot1, skip=c(rep(F, 3), T, rep(F, 4)))
plot2

and the 4th panel position of the bottom row is skipped, BUT the B4&C1 cell 
is shunted to the top left of row 1 and the last panel of plot1 is now 
moved to page 2. Messing with layout= doesn't help, neither does 
substituting NA for the values of the missing cell (instead of cutting it 
out of the data frame). I also get the same behaviour for stripplot and 
dotplot too.

Apologies if I've missed a previous solution to this during my searches of 
the archive.

Regards,

Leon Barmuta
School of Zoology & TAFI, University of Tasmania, Australia.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From baron at psych.upenn.edu  Thu Sep  9 19:04:11 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 9 Sep 2004 13:04:11 -0400
Subject: [R] Proposal for New R List: Criticism? Comments?
In-Reply-To: <200409091649.i89Gnxof019985@ohm.gene.com>
References: <200409091649.i89Gnxof019985@ohm.gene.com>
Message-ID: <20040909170411.GB3434@psych>

I think that a lot of posts on r-help are exactly of the form you
suggest: "How do I do X?"  Answer: "Use Y."  (Or maybe, "Use Y.
And next time RTFM."  But so what.  The answer is still there.)

Often, when the answer is not of that form, the question is
unclear.  In other cases, the questioner is apparently asking for
general statistical advice, rather than which package to use.

In sum, I don't think the new list is needed.  I do not want to
archive it.  I think that, if a questioner fails to find an
answer because the terms he would use do not happen to be indexed
in help.search(), etc., then he has the option of using my search
engine as a fallback, where it is likely that someone else has
used his favored terms.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
R search page: http://finzi.psych.upenn.edu/



From eugenedalt at yahoo.com  Thu Sep  9 19:29:04 2004
From: eugenedalt at yahoo.com (eugene dalt)
Date: Thu, 9 Sep 2004 10:29:04 -0700 (PDT)
Subject: [R] R course in Princeton and Boston
In-Reply-To: <loom.20040909T182242-842@post.gmane.org>
Message-ID: <20040909172904.37425.qmail@web10909.mail.yahoo.com>

Anyone saved the upcoming R course announcement 
for Princeton and Boston?  Please email me...

Thanks
Eugene.



From msvika at mscc.huji.ac.il  Thu Sep  9 20:38:22 2004
From: msvika at mscc.huji.ac.il (Vicky Landsman)
Date: Thu, 9 Sep 2004 20:38:22 +0200
Subject: [R] Dyn.load of sharing object with GSL library 
References: <Pine.LNX.4.44.0409091757260.1605-100000@gannet.stats>
Message-ID: <009e01c4969c$2f251340$9200a8c0@Home3>

Dear Prof. Ripley,
The GSL reference book explains that lm should be added as well (as far as I
understand, and this is what I saw when I run the file in C in a standard
way). No matter, with lm and without, I get the same picture.
Here is what I get after R CMD SHLIB Example3.c

make: Warning: File `Makevars' has modification time 3.4e+03 s in the future
gcc -I/usr/local/sbin/R-1.9/R-1.9.1/include  -I/usr/local/include   -fPIC  -
g -O2 -c Example3.c -o Example3.o
gcc -G -L/usr/local/lib -o Example3.so Example3.o
-L/usr/local/lib/ -lgsl  -L/usr/local/lib/ -lgslcblas"
make: warning:  Clock skew detected.  Your build may be incomplete.

Running ldd line as you stated, I get the following:
        libc.so.1 =>     /usr/lib/libc.so.1
        libdl.so.1 =>    /usr/lib/libdl.so.1
        /usr/platform/SUNW,Sun-Fire-280R/lib/libc_psr.so.1

Sorry for my ignorance in UNIX, where should I run the line
export LD_LIBRARY_PATH=:${LD_LIBRARY_PATH}:/usr/local/lib ?

Vicky.


> On Thu, 9 Sep 2004, Vicky Landsman wrote:
>
> > Following the recommendation of Prof. Ripley, I have created the
Makevars
> > file with the line:
> >
PKG_LIBS="-L/usr/lib/libm -lm -L/usr/local/lib/libgsl -lgsl -L/usr/local/lib
> > /libgslcblas -lgslcblas"
> > in the working directory.
>
> No, that's not what I recommended. -L/path/to/libgsl would probably be
> -L/usr/local/lib if libgsl is in /usr/local/lib.  And why do you want -lm?
>
> Please consult your unstated OS's documentation for ld.
>
> > Now I have the code file Example3.c which computes the Bessel function
value
> > (the example is taken from the GSL reference book).
> > I am running:
> > R CMD SHLIB Example3.c
>


> > and all looks good.
> > The dyn.load("Example3.so") fails with the following error message:
> >
> > Error in dyn.load(x, as.logical(local), as.logical(now)) :
> >         unable to load shared library
> > "/fs/users1/guest/msvika/PhD/R_04/Example3.so":
> >   ld.so.1: /usr/local/sbin/R-1.9/R-1.9.1/bin/R.bin: fatal: relocation
error:
> > file /fs/users1/guest/msvika/PhD/R_04/Example3.so: symbol
gsl_sf_bessel_J0:
> > referenced symbol not found
>
> Try ldd /fs/users1/guest/msvika/PhD/R_04/Example3.so and get a local
> expert to interpret it for you.
>
> You will need anything you had in -L in PKG_LIBS in your library run path
> as well.  You may need e.g.
>
> export LD_LIBRARY_PATH=:${LD_LIBRARY_PATH}:/usr/local/lib
>
> and please check with a local expert about this.
>
> > What is wrong?
> > Much thanks, Vicky.
> >
> > ----- Original Message ----- 
> > From: "Vicky Landsman" <msvika at mscc.huji.ac.il>
> > To: "r-help" <r-help at stat.math.ethz.ch>
> > Sent: Thursday, September 09, 2004 6:18 PM
> > Subject: Re: [R] Adding GSL library path to SHLIB
> >
> >
> > > Dear Prof. Ripley,
> > > We read the archive thread
> > > http://maths.newcastle.edu.au/~rking/R/help/02b/0547.html
> > > Thank you for your help, we will try to create the Makevars file.
> > > Vicky.
> > >
> > >
> > >
> > > ----- Original Message ----- 
> > > From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
> > > To: "Vicky Landsman" <msvika at mscc.huji.ac.il>
> > > Cc: "r-help" <r-help at stat.math.ethz.ch>; <leonid at cc.huji.ac.il>
> > > Sent: Thursday, September 09, 2004 3:17 PM
> > > Subject: Re: [R] Adding GSL library path to SHLIB
> > >
> > >
> > > > On Thu, 9 Sep 2004, Vicky Landsman wrote:
> > > >
> > > > > Dear R-list people,
> > > >
> > > > > I asked a similar question a few hours before. I will try to be
more
> > > > > specific.  We like to add the GSL library to the file SHLIB in
order
> > to
> > > > > make it possible to run the C code using GSL functions from R.  We
> > read
> > > >
> > > > Read where?  It's incorrect information and only used for Fortran
> > linking.
> > > >
> > > > > that the path to the libgsl.a should be added to the line
> > shlib_libadd='
> > > > > ' in the file SHLIB but it does not work on our system. Dyn.load
fails
> > > > > with error "referenced symbol <symbolname> not found". What is
wrong?
> > > > > We will much appreciate any help on this.
> > > > >
> > > > > We are using R-1.9.1 on Unix.
> > > >
> > > > You should have a file called Makevars in the directory from which
> > > > you are doing the building, defining PKG_LIBS, maybe
> > > >
> > > > PKG_LIBS="-L/path/to/libgsl -lgsl"
> > > >
> > > > in the same way as you would for a package: see `Writing R
Extensions'.
> > > > I don't think that is documented anywere, though.
> > > >
> > > > -- 
> > > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > > > University of Oxford,             Tel:  +44 1865 272861 (self)
> > > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > > >
> > > >
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> >
> >
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>



From h.wickham at gmail.com  Thu Sep  9 19:48:15 2004
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 9 Sep 2004 12:48:15 -0500
Subject: [R] Confused about loading other packages from a package
Message-ID: <f8e6ff0504090910483e4aa5b3@mail.gmail.com>

In my package, I create a new method for plot with the following signature:

setMethod("plot", signature(x="marrayNorm", y="formula"), plot.ma)

where marrayNorm is a class defined in the marray package.   After
building and installing my package, I get the following warnings when
I load my package (with library(maVis)):

Warning messages: 
1: In the method signature for function "plot", class "marrayRaw" has
no current definition in: matchSignature(signature, fdef, where)
2: In the method signature for function "plot", class "marrayRaw" has
no current definition in: matchSignature(signature, fdef, where)

(but everything appears to work ok regardless).  I have tried
require(marray) both inside and outside of the .onLoad method.

I presume this is a caused by some difference in require depending on
whether or not it is within a package or not, as simply source()ing
the code gives no errors.  What should I do?  Ignore the warnings (or
turn them off somehow?) or use a different method of loading marray?
I'm also a bit confused about what is best practice for calling
methods in other packages - use namespace:::, use require, use
library, use the depends field in DESCRIPTION, so any advice here
would also be appreciated.

Thanks for you help,

Hadley



From roebuck at odin.mdacc.tmc.edu  Thu Sep  9 19:52:01 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Thu, 9 Sep 2004 12:52:01 -0500 (CDT)
Subject: [R] Dyn.load of sharing object with GSL library 
In-Reply-To: <007c01c49693$0b6edbb0$9200a8c0@Home3>
References: <007c01c49693$0b6edbb0$9200a8c0@Home3>
Message-ID: <Pine.OSF.4.58.0409091213120.478686@odin.mdacc.tmc.edu>

On Thu, 9 Sep 2004, Vicky Landsman wrote:

> Following the recommendation of Prof. Ripley, I have created the Makevars
> file with the line:
> PKG_LIBS="-L/usr/lib/libm -lm -L/usr/local/lib/libgsl -lgsl -L/usr/local/lib
> /libgslcblas -lgslcblas"
> in the working directory.

That should probably look like this instead:

  PKG_LIBS="-L/usr/local/lib -lgsl -lgslcblas -lm"

The math library (-lm) should not be necessary here but I left it in
case it's needed by your [unspecified] OS for some reason.

> Now I have the code file Example3.c which computes the Bessel function value
> (the example is taken from the GSL reference book).
> I am running:
> R CMD SHLIB Example3.c
> and all looks good.

Shared library linkage often allows symbols to remain undefined
until runtime by design. As such, there would be no error message.

> The dyn.load("Example3.so") fails with the following error message:
>
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>         unable to load shared library
> "/fs/users1/guest/msvika/PhD/R_04/Example3.so":
>   ld.so.1: /usr/local/sbin/R-1.9/R-1.9.1/bin/R.bin: fatal: relocation error:
> file /fs/users1/guest/msvika/PhD/R_04/Example3.so: symbol gsl_sf_bessel_J0:
> referenced symbol not found

You may need the following environment variable set prior to
running R. It would be best added to your .profile.

  $ export LD_LIBRARY_PATH=$HOME/lib:/usr/local/lib:/usr/dt/lib:/usr/lib

And why in the world is your R installation located in a
directory for system binaries? Perhaps it would be better
located as '/usr/local/R-1.9.1' or '/opt/R-1.9.1' instead.


----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From rpeng at jhsph.edu  Thu Sep  9 19:55:53 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 09 Sep 2004 13:55:53 -0400
Subject: [R] Confused about loading other packages from a package
In-Reply-To: <f8e6ff0504090910483e4aa5b3@mail.gmail.com>
References: <f8e6ff0504090910483e4aa5b3@mail.gmail.com>
Message-ID: <41409929.3030402@jhsph.edu>

In R 2.0.0-to-be I think putting marray in the Depends: field will 
solve your problem.  Otherwise, you might want to import the 
"marrayNorm" class in your NAMESPACE file.

-roger

hadley wickham wrote:
> In my package, I create a new method for plot with the following signature:
> 
> setMethod("plot", signature(x="marrayNorm", y="formula"), plot.ma)
> 
> where marrayNorm is a class defined in the marray package.   After
> building and installing my package, I get the following warnings when
> I load my package (with library(maVis)):
> 
> Warning messages: 
> 1: In the method signature for function "plot", class "marrayRaw" has
> no current definition in: matchSignature(signature, fdef, where)
> 2: In the method signature for function "plot", class "marrayRaw" has
> no current definition in: matchSignature(signature, fdef, where)
> 
> (but everything appears to work ok regardless).  I have tried
> require(marray) both inside and outside of the .onLoad method.
> 
> I presume this is a caused by some difference in require depending on
> whether or not it is within a package or not, as simply source()ing
> the code gives no errors.  What should I do?  Ignore the warnings (or
> turn them off somehow?) or use a different method of loading marray?
> I'm also a bit confused about what is best practice for calling
> methods in other packages - use namespace:::, use require, use
> library, use the depends field in DESCRIPTION, so any advice here
> would also be appreciated.
> 
> Thanks for you help,
> 
> Hadley
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Thu Sep  9 19:57:55 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 09 Sep 2004 13:57:55 -0400
Subject: [R] scoping rules
In-Reply-To: <7669F018DC9DD711AEC500065B3D5ABF02CAD450@tudor.com>
References: <7669F018DC9DD711AEC500065B3D5ABF02CAD450@tudor.com>
Message-ID: <9a61k0lru05c2b222q4babfrv74acb108b@4ax.com>

On Thu, 9 Sep 2004 12:01:56 -0400 , Whit Armstrong
<Whit.Armstrong at tudor.com> wrote :

>Can someone help me with this simple example?
>
>sq <- function() {
>	y <- x^2
>	y
>}
>
>myfunc <- function() {
>	x <- 10
>	sq()
>}
>
>myfunc()
>
>
>executing the above in R yields:
>> myfunc()
>Error in sq() : Object "x" not found
>
>I understand that R's scoping rules cause it to look for "x" in the
>environment in which "sq" was defined (the global environment in this case).
>But in this case "x" is defined inside the calling function, not the
>environment in which "sq" was defined.
>
>Is there a way to tell R to look in the calling function for "x" ?

The easiest (and best) is to pass x as an argument to sq.

Duncan Murdoch



From ripley at stats.ox.ac.uk  Thu Sep  9 20:03:20 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Sep 2004 19:03:20 +0100 (BST)
Subject: [R] Dyn.load of sharing object with GSL library 
In-Reply-To: <009e01c4969c$2f251340$9200a8c0@Home3>
Message-ID: <Pine.LNX.4.44.0409091902050.3175-100000@gannet.stats>

On Thu, 9 Sep 2004, Vicky Landsman wrote:

> Dear Prof. Ripley,
> The GSL reference book explains that lm should be added as well (as far as I
> understand, and this is what I saw when I run the file in C in a standard
> way). No matter, with lm and without, I get the same picture.
> Here is what I get after R CMD SHLIB Example3.c
> 
> make: Warning: File `Makevars' has modification time 3.4e+03 s in the future
> gcc -I/usr/local/sbin/R-1.9/R-1.9.1/include  -I/usr/local/include   -fPIC  -
> g -O2 -c Example3.c -o Example3.o
> gcc -G -L/usr/local/lib -o Example3.so Example3.o
> -L/usr/local/lib/ -lgsl  -L/usr/local/lib/ -lgslcblas"
> make: warning:  Clock skew detected.  Your build may be incomplete.
> 
> Running ldd line as you stated, I get the following:
>         libc.so.1 =>     /usr/lib/libc.so.1
>         libdl.so.1 =>    /usr/lib/libdl.so.1
>         /usr/platform/SUNW,Sun-Fire-280R/lib/libc_psr.so.1

Looks OK, and no reference to lm.

> Sorry for my ignorance in UNIX, where should I run the line
> export LD_LIBRARY_PATH=:${LD_LIBRARY_PATH}:/usr/local/lib ?

As I asked, ask a local expert.

> 
> Vicky.
> 
> 
> > On Thu, 9 Sep 2004, Vicky Landsman wrote:
> >
> > > Following the recommendation of Prof. Ripley, I have created the
> Makevars
> > > file with the line:
> > >
> PKG_LIBS="-L/usr/lib/libm -lm -L/usr/local/lib/libgsl -lgsl -L/usr/local/lib
> > > /libgslcblas -lgslcblas"
> > > in the working directory.
> >
> > No, that's not what I recommended. -L/path/to/libgsl would probably be
> > -L/usr/local/lib if libgsl is in /usr/local/lib.  And why do you want -lm?
> >
> > Please consult your unstated OS's documentation for ld.
> >
> > > Now I have the code file Example3.c which computes the Bessel function
> value
> > > (the example is taken from the GSL reference book).
> > > I am running:
> > > R CMD SHLIB Example3.c
> >
> 
> 
> > > and all looks good.
> > > The dyn.load("Example3.so") fails with the following error message:
> > >
> > > Error in dyn.load(x, as.logical(local), as.logical(now)) :
> > >         unable to load shared library
> > > "/fs/users1/guest/msvika/PhD/R_04/Example3.so":
> > >   ld.so.1: /usr/local/sbin/R-1.9/R-1.9.1/bin/R.bin: fatal: relocation
> error:
> > > file /fs/users1/guest/msvika/PhD/R_04/Example3.so: symbol
> gsl_sf_bessel_J0:
> > > referenced symbol not found
> >
> > Try ldd /fs/users1/guest/msvika/PhD/R_04/Example3.so and get a local
> > expert to interpret it for you.
> >
> > You will need anything you had in -L in PKG_LIBS in your library run path
> > as well.  You may need e.g.
> >
> > export LD_LIBRARY_PATH=:${LD_LIBRARY_PATH}:/usr/local/lib
> >
> > and please check with a local expert about this.
> >
> > > What is wrong?
> > > Much thanks, Vicky.
> > >
> > > ----- Original Message ----- 
> > > From: "Vicky Landsman" <msvika at mscc.huji.ac.il>
> > > To: "r-help" <r-help at stat.math.ethz.ch>
> > > Sent: Thursday, September 09, 2004 6:18 PM
> > > Subject: Re: [R] Adding GSL library path to SHLIB
> > >
> > >
> > > > Dear Prof. Ripley,
> > > > We read the archive thread
> > > > http://maths.newcastle.edu.au/~rking/R/help/02b/0547.html
> > > > Thank you for your help, we will try to create the Makevars file.
> > > > Vicky.
> > > >
> > > >
> > > >
> > > > ----- Original Message ----- 
> > > > From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
> > > > To: "Vicky Landsman" <msvika at mscc.huji.ac.il>
> > > > Cc: "r-help" <r-help at stat.math.ethz.ch>; <leonid at cc.huji.ac.il>
> > > > Sent: Thursday, September 09, 2004 3:17 PM
> > > > Subject: Re: [R] Adding GSL library path to SHLIB
> > > >
> > > >
> > > > > On Thu, 9 Sep 2004, Vicky Landsman wrote:
> > > > >
> > > > > > Dear R-list people,
> > > > >
> > > > > > I asked a similar question a few hours before. I will try to be
> more
> > > > > > specific.  We like to add the GSL library to the file SHLIB in
> order
> > > to
> > > > > > make it possible to run the C code using GSL functions from R.  We
> > > read
> > > > >
> > > > > Read where?  It's incorrect information and only used for Fortran
> > > linking.
> > > > >
> > > > > > that the path to the libgsl.a should be added to the line
> > > shlib_libadd='
> > > > > > ' in the file SHLIB but it does not work on our system. Dyn.load
> fails
> > > > > > with error "referenced symbol <symbolname> not found". What is
> wrong?
> > > > > > We will much appreciate any help on this.
> > > > > >
> > > > > > We are using R-1.9.1 on Unix.
> > > > >
> > > > > You should have a file called Makevars in the directory from which
> > > > > you are doing the building, defining PKG_LIBS, maybe
> > > > >
> > > > > PKG_LIBS="-L/path/to/libgsl -lgsl"
> > > > >
> > > > > in the same way as you would for a package: see `Writing R
> Extensions'.
> > > > > I don't think that is documented anywere, though.
> > > > >
> > > > > -- 
> > > > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > > > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > > > > University of Oxford,             Tel:  +44 1865 272861 (self)
> > > > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > > > >
> > > > >
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > > >
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> > >
> > >
> >
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Thu Sep  9 20:16:18 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 09 Sep 2004 11:16:18 -0700
Subject: [R] R/S-plus Course***In Princeton & Boston,
	***R/Splus Fundamentals
	and Programming Techniques,	september - October, 2004
In-Reply-To: <20040908201555.29378.qmail@webmail07.mesa1.secureserver.net>
References: <20040908201555.29378.qmail@webmail07.mesa1.secureserver.net>
Message-ID: <41409DF2.9020202@pdf.com>



elvis at xlsolutions-corp.com wrote:

>R/S-plus Course***In Princeton & Boston,***R/Splus Fundamentals 
>and Programming Techniques, september - October, 2004
>
>XLSolutions Corporation (www.xlsolutions-corp.com) is proud to 
>announce  2-day "R/S-plus Fundamentals and Programming 
>Techniques".
>
>****Princeton,NJ ---------------------------- September 30th - October
>1st
>****Boston, MA   ---------------------------- October 14th-15th
>
>
>Reserve your seat now at the early bird rates! Payment due AFTER 
>the class.
>
>
>Course Description:
>This two-day beginner to intermediate R/S-plus course focuses on a 
>broad spectrum of topics, from reading raw data to a comparison of R 
>and S. We will learn the essentials of data manipulation, graphical 
>visualization and R/S-plus programming. We will explore statistical 
>data analysis tools,including graphics with data sets. How to enhance 
>your plots. We will perform basic statistics and fit linear regression
>
>models. Participants are encouraged to bring data for interactive 
>sessions
>
>
>With the following outline:
>- An Overview of R and S
>- Data Manipulation and Graphics
>- Using Lattice Graphics
>- A Comparison of R and S-Plus
>- How can R Complement SAS?
>- Writing Functions
>- Avoiding Loops
>- Vectorization
>- Statistical Modeling
>- Project Management
>- Techniques for Effective use of R and S
>- Enhancing Plots
>- Using High-level Plotting Functions
>- Building and Distributing Packages (libraries)
>
>
>Email us for group discounts.
>Email Sue Turner: sue at xlsolutions-corp.com
>Phone: 206-686-1578
>Visit us: www.xlsolutions-corp.com/training.htm
>Please let us know if you and your colleagues are interested in this 
>classto take advantage of group discount. Register now to secure your 
>seat! Interested in R/Splus Advanced course? email us.
>
>
>Cheers,
>Elvis Miller, PhD
>Manager Training.
>XLSolutions Corporation
>206 686 1578
>www.xlsolutions-corp.com
>elvis at xlsolutions-corp.com
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From h.wickham at gmail.com  Thu Sep  9 21:01:52 2004
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 9 Sep 2004 14:01:52 -0500
Subject: [R] Confused about loading other packages from a package
In-Reply-To: <41409929.3030402@jhsph.edu>
References: <f8e6ff0504090910483e4aa5b3@mail.gmail.com>
	<41409929.3030402@jhsph.edu>
Message-ID: <f8e6ff0504090912012ac21504@mail.gmail.com>

Unfortunately, marrayClasses doesn't seem to have a namespace:

> library(maVis)
Error in loadNamespace(imp[[1]], c(lib.loc, .libPaths()), keep.source) : 
        package 'marrayClasses' does not have a name space
Error in library(maVis) : package/namespace load failed

Any other ideas?

Hadley



From lisawang at uhnres.utoronto.ca  Thu Sep  9 21:12:05 2004
From: lisawang at uhnres.utoronto.ca (Lisa Wang)
Date: Thu, 09 Sep 2004 15:12:05 -0400
Subject: [R] Blom's approximation to rankits?
Message-ID: <4140AB05.27DC7609@uhnres.utoronto.ca>

Hello,

My name is Lisa and I'm a statistician at Princess Margare Hospital. I
wonder if there is any function in R that calculate the Normal rankits
based on Blom's approximation?

Thank you very much

Lisa Wang Msc.
Princess Margaret hospital
Toronto, Ca



From ripley at stats.ox.ac.uk  Thu Sep  9 21:12:16 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Sep 2004 20:12:16 +0100 (BST)
Subject: [R] Confused about loading other packages from a package
In-Reply-To: <f8e6ff0504090912012ac21504@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0409092009030.3322-100000@gannet.stats>

On Thu, 9 Sep 2004, hadley wickham wrote:

> Unfortunately, marrayClasses doesn't seem to have a namespace:
> 
> > library(maVis)
> Error in loadNamespace(imp[[1]], c(lib.loc, .libPaths()), keep.source) : 
>         package 'marrayClasses' does not have a name space
> Error in library(maVis) : package/namespace load failed
> 
> Any other ideas?

Roger's other one is the best one: use pre-2.0.0 and have 
Depends: marrayClasses in your DESCRIPTION file.

Having require(marrayClasses) in install.R in your package may work, 
although you may need it in R_PROFILE.R as well.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lisawang at uhnres.utoronto.ca  Thu Sep  9 21:31:59 2004
From: lisawang at uhnres.utoronto.ca (Lisa Wang)
Date: Thu, 09 Sep 2004 15:31:59 -0400
Subject: [R] GEE model
Message-ID: <4140AFAF.B7E36F42@uhnres.utoronto.ca>

Hello there,


My name is Lisa and I'm doing analysis using genelized linear model-GEE
model because I have some repeated measurements on the same patients (in
a bilateral eye disease case). It would be very appreciated if you could
shed some light on what function to use in R.

Thank you very much

Lisa Wang Msc.

Toronto,Ca



From wolski at molgen.mpg.de  Thu Sep  9 21:47:10 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 09 Sep 2004 21:47:10 +0200
Subject: [R] GEE model
In-Reply-To: <4140AFAF.B7E36F42@uhnres.utoronto.ca>
References: <4140AFAF.B7E36F42@uhnres.utoronto.ca>
Message-ID: <200409092147100119.0233390F@mail.math.fu-berlin.de>

Hi!

There is a package
geepack
on cran which my gues does what you ask for.

If you have a fast internet connection install all packages
under linux
install.packages(CRAN.packages()[,1])
to installs all of them

Under windows you can use the menu Packages.
And then you can use
help.search("GEE")

/E


*********** REPLY SEPARATOR  ***********

On 9/9/2004 at 3:31 PM Lisa Wang wrote:

>>>Hello there,
>>>
>>>
>>>My name is Lisa and I'm doing analysis using genelized linear model-GEE
>>>model because I have some repeated measurements on the same patients (in
>>>a bilateral eye disease case). It would be very appreciated if you could
>>>shed some light on what function to use in R.
>>>
>>>Thank you very much
>>>
>>>Lisa Wang Msc.
>>>
>>>Toronto,Ca
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin                'v'    
tel: 0049-30-83875219                        /   \       
mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
      wolski at molgen.mpg.de



From bwheeler at echip.com  Thu Sep  9 22:01:39 2004
From: bwheeler at echip.com (Bob Wheeler)
Date: Thu, 09 Sep 2004 16:01:39 -0400
Subject: [R] Blom's approximation to rankits?
References: <4140AB05.27DC7609@uhnres.utoronto.ca>
Message-ID: <4140B6A3.5080206@echip.com>


You need not use Blom's approximations. Exact values to several decimal 
places are given by normOrder() in SuppDists.


Lisa Wang wrote:
> Hello,
> 
> My name is Lisa and I'm a statistician at Princess Margare Hospital. I
> wonder if there is any function in R that calculate the Normal rankits
> based on Blom's approximation?
> 
> Thank you very much
> 
> Lisa Wang Msc.
> Princess Margaret hospital
> Toronto, Ca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Bob Wheeler --- http://www.bobwheeler.com/
         ECHIP, Inc. ---
Randomness comes in bunches.



From wanr at ucalgary.ca  Thu Sep  9 22:13:42 2004
From: wanr at ucalgary.ca (wanr@ucalgary.ca)
Date: Thu, 09 Sep 2004 14:13:42 -0600
Subject: [R] How to plot the estimated age-specific cumulative risk function?
Message-ID: <200409092013.i89KDiD10935@smtp2.ucalgary.ca>

The hypothetical data is displayed as follows.

ID   Age1   cens1     Age2        cens2
1     81       0       85             1
2     42       1       48             0
3     37       1       55             0
4     54       0       56             0
5     35       0       37             0
6     38       0       38             1
7     29       0       30             0
8     40       0       40             1

where Age1 is the event time for a disease;
cens1 is the censor variable for the disease (1=hold the disease);
Age2 is the event time for death (in years);
cens2 is the censor variable for death (1=died).

First, I might use surv.obj <- survfit(); then I could get estimated 
cumulative risk function (cdf) by 1 - surv.obj$surv. 

However, it is tedious to plot this cdf in usual way. My question is whether 
there exit some specific functions to plot this cdf easily and whether I can 
set the horizontal axis as individul's age.

I am a beginner in survival analysis and I might not state my questions 
clear enough. Thanks for your understanding and help in advance.

Rui



From HDoran at air.org  Thu Sep  9 22:17:12 2004
From: HDoran at air.org (Doran, Harold)
Date: Thu, 9 Sep 2004 16:17:12 -0400
Subject: [R] Rslides.sty
Message-ID: <88EAF3512A55DF46B06B1954AEF73F74055C0E40@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040909/c3d7f107/attachment.pl

From bitwrit at ozemail.com.au  Thu Sep  9 23:20:35 2004
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Fri, 10 Sep 2004 07:20:35 +1000
Subject: [R] Proposal for New R List: Criticism? Comments?
Message-ID: <20040909210937.VNGG21843.smta03.mail.ozemail.net@there>

The number of help requests that could be answered by either:

1) A full text search of package INDEX files

or

2) A full text search of package documentation files

is certainly large. Professor Baron's search engine does this very well. Some 
time ago, I wrote a Tck-Tk program to perform this sort of search, so that I 
could enter any word and get a list of all files in the R documentation that 
contained that word. In general, it is about as comprehensive as the UPenn 
search engine. However, neither of these are on the CRAN site. It does not 
seem difficult to program such a search on CRAN, so that someone seeking a 
package dealing with, say, "goodness of fit" could enter it and have an HTML 
page served with a list of links to documentation files that contain that 
phrase. A lot easier than working one's way through the 350+ packages listed 
or attempting to divine what each package contains from their often whimsical 
names.

Yes, I would be happy to have a try.

Jim



From andy_liaw at merck.com  Fri Sep 10 00:19:16 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 9 Sep 2004 18:19:16 -0400
Subject: [R] Dyn.load of sharing object with GSL library
Message-ID: <3A822319EB35174CA3714066D590DCD504AF836D@usrymx25.merck.com>

As Prof. Ripley said, twice already: seek local expert help.  If you don't
know who that is, start with the person that setup your user account on that
machine.  Such system-specific problem is much easier to resolve that way,
instead of having others on the list guessing.

Andy

> From: Vicky Landsman
> 
> Dear Prof. Ripley,
> The GSL reference book explains that lm should be added as 
> well (as far as I
> understand, and this is what I saw when I run the file in C 
> in a standard
> way). No matter, with lm and without, I get the same picture.
> Here is what I get after R CMD SHLIB Example3.c
> 
> make: Warning: File `Makevars' has modification time 3.4e+03 
> s in the future
> gcc -I/usr/local/sbin/R-1.9/R-1.9.1/include  
> -I/usr/local/include   -fPIC  -
> g -O2 -c Example3.c -o Example3.o
> gcc -G -L/usr/local/lib -o Example3.so Example3.o
> -L/usr/local/lib/ -lgsl  -L/usr/local/lib/ -lgslcblas"
> make: warning:  Clock skew detected.  Your build may be incomplete.
> 
> Running ldd line as you stated, I get the following:
>         libc.so.1 =>     /usr/lib/libc.so.1
>         libdl.so.1 =>    /usr/lib/libdl.so.1
>         /usr/platform/SUNW,Sun-Fire-280R/lib/libc_psr.so.1
> 
> Sorry for my ignorance in UNIX, where should I run the line
> export LD_LIBRARY_PATH=:${LD_LIBRARY_PATH}:/usr/local/lib ?
> 
> Vicky.
> 
> 
> > On Thu, 9 Sep 2004, Vicky Landsman wrote:
> >
> > > Following the recommendation of Prof. Ripley, I have created the
> Makevars
> > > file with the line:
> > >
> PKG_LIBS="-L/usr/lib/libm -lm -L/usr/local/lib/libgsl -lgsl 
> -L/usr/local/lib
> > > /libgslcblas -lgslcblas"
> > > in the working directory.
> >
> > No, that's not what I recommended. -L/path/to/libgsl would 
> probably be
> > -L/usr/local/lib if libgsl is in /usr/local/lib.  And why 
> do you want -lm?
> >
> > Please consult your unstated OS's documentation for ld.
> >
> > > Now I have the code file Example3.c which computes the 
> Bessel function
> value
> > > (the example is taken from the GSL reference book).
> > > I am running:
> > > R CMD SHLIB Example3.c
> >
> 
> 
> > > and all looks good.
> > > The dyn.load("Example3.so") fails with the following 
> error message:
> > >
> > > Error in dyn.load(x, as.logical(local), as.logical(now)) :
> > >         unable to load shared library
> > > "/fs/users1/guest/msvika/PhD/R_04/Example3.so":
> > >   ld.so.1: /usr/local/sbin/R-1.9/R-1.9.1/bin/R.bin: 
> fatal: relocation
> error:
> > > file /fs/users1/guest/msvika/PhD/R_04/Example3.so: symbol
> gsl_sf_bessel_J0:
> > > referenced symbol not found
> >
> > Try ldd /fs/users1/guest/msvika/PhD/R_04/Example3.so and get a local
> > expert to interpret it for you.
> >
> > You will need anything you had in -L in PKG_LIBS in your 
> library run path
> > as well.  You may need e.g.
> >
> > export LD_LIBRARY_PATH=:${LD_LIBRARY_PATH}:/usr/local/lib
> >
> > and please check with a local expert about this.
> >
> > > What is wrong?
> > > Much thanks, Vicky.
> > >
> > > ----- Original Message ----- 
> > > From: "Vicky Landsman" <msvika at mscc.huji.ac.il>
> > > To: "r-help" <r-help at stat.math.ethz.ch>
> > > Sent: Thursday, September 09, 2004 6:18 PM
> > > Subject: Re: [R] Adding GSL library path to SHLIB
> > >
> > >
> > > > Dear Prof. Ripley,
> > > > We read the archive thread
> > > > http://maths.newcastle.edu.au/~rking/R/help/02b/0547.html
> > > > Thank you for your help, we will try to create the 
> Makevars file.
> > > > Vicky.
> > > >
> > > >
> > > >
> > > > ----- Original Message ----- 
> > > > From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
> > > > To: "Vicky Landsman" <msvika at mscc.huji.ac.il>
> > > > Cc: "r-help" <r-help at stat.math.ethz.ch>; <leonid at cc.huji.ac.il>
> > > > Sent: Thursday, September 09, 2004 3:17 PM
> > > > Subject: Re: [R] Adding GSL library path to SHLIB
> > > >
> > > >
> > > > > On Thu, 9 Sep 2004, Vicky Landsman wrote:
> > > > >
> > > > > > Dear R-list people,
> > > > >
> > > > > > I asked a similar question a few hours before. I 
> will try to be
> more
> > > > > > specific.  We like to add the GSL library to the 
> file SHLIB in
> order
> > > to
> > > > > > make it possible to run the C code using GSL 
> functions from R.  We
> > > read
> > > > >
> > > > > Read where?  It's incorrect information and only used 
> for Fortran
> > > linking.
> > > > >
> > > > > > that the path to the libgsl.a should be added to the line
> > > shlib_libadd='
> > > > > > ' in the file SHLIB but it does not work on our 
> system. Dyn.load
> fails
> > > > > > with error "referenced symbol <symbolname> not 
> found". What is
> wrong?
> > > > > > We will much appreciate any help on this.
> > > > > >
> > > > > > We are using R-1.9.1 on Unix.
> > > > >
> > > > > You should have a file called Makevars in the 
> directory from which
> > > > > you are doing the building, defining PKG_LIBS, maybe
> > > > >
> > > > > PKG_LIBS="-L/path/to/libgsl -lgsl"
> > > > >
> > > > > in the same way as you would for a package: see `Writing R
> Extensions'.
> > > > > I don't think that is documented anywere, though.
> > > > >
> > > > > -- 
> > > > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > > > Professor of Applied Statistics,  
> http://www.stats.ox.ac.uk/~ripley/
> > > > > University of 
> Oxford,             Tel:  +44 1865 272861 (self)
> > > > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > > > >
> > > > >
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > > >
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> > >
> > >
> >
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From nair at sdsc.edu  Fri Sep 10 01:43:51 2004
From: nair at sdsc.edu (T. Murlidharan Nair)
Date: Thu, 09 Sep 2004 16:43:51 -0700
Subject: [R] RDA file
Message-ID: <4140EAB7.6090406@sdsc.edu>

What is an RDA file ? I was trying to work through a turorial on cluster 
analysis using R and bioconductor.
The data files in the library are stored as RDA files. Its part of the 
golubEsets library.  
Cheers ../Murli



From nair at sdsc.edu  Fri Sep 10 02:04:12 2004
From: nair at sdsc.edu (T. Murlidharan Nair)
Date: Thu, 09 Sep 2004 17:04:12 -0700
Subject: [R] swiss.x
Message-ID: <4140EF7C.6050804@sdsc.edu>

Is the swiss data set in R the same as S dataset swiss.x .
I was trying out some clustering by doing the following that I got from
Venables and Ripley's book.

h<-hclus(dist(swiss.x), method= "connected")
plclust(h)
cutree(h,3)
plclust(clorder(h,cutree(h,3)))

I tried swiss instead of swiss.x, it doesnot seem happy.
Thanks ../Murli



From mstrivens at houston.rr.com  Fri Sep 10 02:26:18 2004
From: mstrivens at houston.rr.com (Mark Strivens)
Date: Thu, 9 Sep 2004 19:26:18 -0500
Subject: [R] R conversion
Message-ID: <021301c496cc$ca5b1c80$f7d4f218@your939tqgi62r>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040909/d5fc40cb/attachment.pl

From tvictor at dolphin.upenn.edu  Fri Sep 10 02:40:43 2004
From: tvictor at dolphin.upenn.edu (Timothy W. Victor)
Date: Thu, 09 Sep 2004 20:40:43 -0400
Subject: [R] Efficient Cartesian product of data.frames
Message-ID: <4140F80B.3070902@dolphin.upenn.edu>

Hello List,

I am looking for efficient code to produce the Cartesian product of two 
or more data.frames. I'd like to be able to do this without resorting to 
looping. I have searched the FAQ, web, etc without luck. That being 
said, the help page for merge says that the function can produce what 
I'm looking for if the by vectors are of zero length. Would someone be 
so kind as to provide me with a quick example of exactly how to do this?

Cheers,

Tim Victor



From jfox at mcmaster.ca  Fri Sep 10 02:57:07 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 9 Sep 2004 20:57:07 -0400
Subject: [R] R conversion
In-Reply-To: <021301c496cc$ca5b1c80$f7d4f218@your939tqgi62r>
Message-ID: <20040910005708.TOZK19123.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Mark,

See ?factanal for a factor-analysis function, in the standard stats package
(though factanal does ML factor analysis and not principal axes). Note that
help.search("factor analysis") turns this up.

With respect to your last question, it's not possible to know the source of
the difference without knowing what the difference is. A guess is that
specifying proportion=0.9 in SAS causes the program to use communality
estimates rather than 1's on the diagonal of the correlation matrix.

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mark Strivens
> Sent: Thursday, September 09, 2004 7:26 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] R conversion
> 
> I am a newcomer to R trying to convert a SAS program to R.
> Does anyone know if there is a functional equivalent of the 
> SAS 'Factor' procedure?
> 
> For example in SAS:
> 
> proc factor DATA=cor method=principal rotate=varimax 
> proportion=0.9 scree
> 
> where 'cor' is a correlation matrix (as in the R 'cor' function)
> 
> This should get you a list of eigen values as well as a 
> factor pattern matrix.
> 
> Also why when I use the 'eigen' function in R does it seem to 
> give a subtly different answer to the eigen values generated 
> by the above program?
> 
> Many thanks for any help
> 
> Mark Strivens



From jfox at mcmaster.ca  Fri Sep 10 03:01:29 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 9 Sep 2004 21:01:29 -0400
Subject: [R] Proposal for New R List: Criticism? Comments?
In-Reply-To: <200409091649.i89Gnxof019985@ohm.gene.com>
Message-ID: <20040910010130.VXMT4758.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Bert,

I believe that you've identified an important issue -- and one that's
occasionally been discussed on this list previously -- but I'm not sure that
another email list is a good solution. Some method of indexing functions in
packages that would allow people to more easily locate them (e.g.,
author-supplied [i.e., not simply standard] keywords for each public object
in a package) seems to me a more promising approach.

Regards,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Berton Gunter
> Sent: Thursday, September 09, 2004 11:50 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Proposal for New R List: Criticism? Comments?
> 
> Folks:
>  
> I would like to propose a new R list, tentatively labeled 
> r-contents. I wish to briefly explain the purpose and format 
> here and solicit public comments, pro or con, so feel free to 
> criticize or suggest a better name and other improvements or 
> alternatives.
>  
> R presently consists of a suite of about a dozen core 
> recommended packages and several hundred contributed packages 
> comprising thousands -- perhaps tens of thousands -- of 
> functions. Hopefully, this will continue to grow rapidly. No 
> one can possibly keep track of all of this, and it is 
> therefore a daunting task for someone seeking specific 
> functionality to find it, especially when they are relatively 
> new to R. 
>  
> Of course, R and CRAN (and Google and ...)  have various 
> search capabilities that help, but these are essentially 
> keyword-based and so require the searcher to guess search 
> terms that are at least reasonably close to function names 
> and keywords. A lot of the time this works, but it can be 
> tedious; some of the time one guesses wrong, and it doesn't work.
>  
> S-Plus and much other software addresses this by providing a 
> semantically-based Contents Index (or something like it) in 
> their Help functionality. I find this quite useful, but 
> creating and maintaining such an index seems to me to be 
> extremely labor intensive, fraught with its own issues (what 
> heading should I look under?), and, I think, not a good fit 
> to the spirit and dynamics of R anyway.
>  
> Not surprisingly, as a result, many of the questions 
> addressed to r-help are of the form: "I want to do such and 
> such. How do I do it?" While this certainly gives answers, I 
> think the breadth of r-help and its etiquette and posting 
> conventions result in an abruptness to many of our replies 
> ("Read the posting guide! Read the Help files and do what 
> they say!") that discourages many users -- especially casual 
> ones -- from posting questions, and thus may thus discourage 
> use of R. Clearly, if true, this is not a good thing; on the 
> other hand, I think that given r-help's purpose and 
> practices, many of these abrupt replies may well be 
> appropriate (I'm a curmudgeon at heart!).
>  
> Hence, there is a mismatch between user needs and r-help 
> services. To address this mismatch, I would like to propose a 
> new list, r-contents, to essentially serve the same purpose 
> as the S-Plus Contents index. Hence, it would serve as a 
> place for users to post queries ** only ** of the form: "I 
> want to do such and such. How do I do it?" and receive 
> answers that would all be **single phrases ** of the form 
> "package suchandsuch" or "?suchandsuchfunction." No further 
> explanations regarding usage would be provided, though users 
> would be free to follow up answers with private questions to 
> the responder, although there should be no expectation of any 
> response. Queries could be framed with as much or as little 
> supporting detail as desired, with the obvious consequence 
> that a more clearly framed question would be more likely to 
> get a (better) response. No other posting conventions (aside 
> from the usual ones regarding civility and adherence to
> topic) would be expected.
>  
> My hope is that such a list would both reduce unnecessary 
> traffic on r-help and satisfy a genuine need in a less 
> threatening way. I can certainly see downsides (I often learn 
> a lot from "How can I do this?" queries), but I think, on 
> balance, this approach might be useful. So I would like to 
> subject the idea to public scrutiny and criticism, as well as 
> the opportunity for improvement from suggested modifications 
> or alternatives. If it's useful, this will be recognized; if 
> it's not and/or no one is interested, that, too, will be made 
> manifest. I would be especially grateful for the opinions of 
> casual users or newbies, either publicly or privately.
>  
> Cheers,
>  
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>



From andy_liaw at merck.com  Fri Sep 10 03:02:08 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 9 Sep 2004 21:02:08 -0400
Subject: [R] RDA file
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8371@usrymx25.merck.com>

See ?save and ?load.

Andy

> From: T. Murlidharan Nair
> 
> What is an RDA file ? I was trying to work through a turorial 
> on cluster 
> analysis using R and bioconductor.
> The data files in the library are stored as RDA files. Its 
> part of the 
> golubEsets library.  
> Cheers ../Murli
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From mstrivens at houston.rr.com  Fri Sep 10 04:52:21 2004
From: mstrivens at houston.rr.com (Mark Strivens)
Date: Thu, 9 Sep 2004 21:52:21 -0500
Subject: [R] R conversion
References: <20040910005708.TOZK19123.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <026901c496e1$3205deb0$f7d4f218@your939tqgi62r>

Thanks John for the post - I had found factanal
However factanal it seems you have specify the number of factors to be
fitted
up front, whereas with the SAS procedure you don't - this is apparently
important
to the analysis!

Perhaps I could emulate this function by breaking it down using factor
extraction by principal component analysis and the doing the varimax
rotation second? If that makes
any sense?



From ramasamy at cancer.org.uk  Fri Sep 10 04:54:44 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 10 Sep 2004 03:54:44 +0100
Subject: [R] Proposal for New R List: Criticism? Comments?
In-Reply-To: <20040910010130.VXMT4758.tomts13-srv.bellnexxia.net@JohnDesktop8300>
References: <20040910010130.VXMT4758.tomts13-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <1094784884.3512.46.camel@localhost.localdomain>

There is another issue to be considered. Currently you need to have the
relevant packages installed before help.search() bring it up. My work
around this is to install all available packages just in case the
function I need is nestled in some non-standard packages. I also update
them rather frequently. This is clearly unattractive to some, especially
busy system administrators.

For some suggestions to this problem, see my posting at
   https://stat.ethz.ch/pipermail/r-devel/2004-June/029763.html

Regards, Adai



On Fri, 2004-09-10 at 02:01, John Fox wrote:
> Dear Bert,
> 
> I believe that you've identified an important issue -- and one that's
> occasionally been discussed on this list previously -- but I'm not sure that
> another email list is a good solution. Some method of indexing functions in
> packages that would allow people to more easily locate them (e.g.,
> author-supplied [i.e., not simply standard] keywords for each public object
> in a package) seems to me a more promising approach.
> 
> Regards,
>  John
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Berton Gunter
> > Sent: Thursday, September 09, 2004 11:50 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Proposal for New R List: Criticism? Comments?
> > 
> > Folks:
> >  
> > I would like to propose a new R list, tentatively labeled 
> > r-contents. I wish to briefly explain the purpose and format 
> > here and solicit public comments, pro or con, so feel free to 
> > criticize or suggest a better name and other improvements or 
> > alternatives.
> >  
> > R presently consists of a suite of about a dozen core 
> > recommended packages and several hundred contributed packages 
> > comprising thousands -- perhaps tens of thousands -- of 
> > functions. Hopefully, this will continue to grow rapidly. No 
> > one can possibly keep track of all of this, and it is 
> > therefore a daunting task for someone seeking specific 
> > functionality to find it, especially when they are relatively 
> > new to R. 
> >  
> > Of course, R and CRAN (and Google and ...)  have various 
> > search capabilities that help, but these are essentially 
> > keyword-based and so require the searcher to guess search 
> > terms that are at least reasonably close to function names 
> > and keywords. A lot of the time this works, but it can be 
> > tedious; some of the time one guesses wrong, and it doesn't work.
> >  
> > S-Plus and much other software addresses this by providing a 
> > semantically-based Contents Index (or something like it) in 
> > their Help functionality. I find this quite useful, but 
> > creating and maintaining such an index seems to me to be 
> > extremely labor intensive, fraught with its own issues (what 
> > heading should I look under?), and, I think, not a good fit 
> > to the spirit and dynamics of R anyway.
> >  
> > Not surprisingly, as a result, many of the questions 
> > addressed to r-help are of the form: "I want to do such and 
> > such. How do I do it?" While this certainly gives answers, I 
> > think the breadth of r-help and its etiquette and posting 
> > conventions result in an abruptness to many of our replies 
> > ("Read the posting guide! Read the Help files and do what 
> > they say!") that discourages many users -- especially casual 
> > ones -- from posting questions, and thus may thus discourage 
> > use of R. Clearly, if true, this is not a good thing; on the 
> > other hand, I think that given r-help's purpose and 
> > practices, many of these abrupt replies may well be 
> > appropriate (I'm a curmudgeon at heart!).
> >  
> > Hence, there is a mismatch between user needs and r-help 
> > services. To address this mismatch, I would like to propose a 
> > new list, r-contents, to essentially serve the same purpose 
> > as the S-Plus Contents index. Hence, it would serve as a 
> > place for users to post queries ** only ** of the form: "I 
> > want to do such and such. How do I do it?" and receive 
> > answers that would all be **single phrases ** of the form 
> > "package suchandsuch" or "?suchandsuchfunction." No further 
> > explanations regarding usage would be provided, though users 
> > would be free to follow up answers with private questions to 
> > the responder, although there should be no expectation of any 
> > response. Queries could be framed with as much or as little 
> > supporting detail as desired, with the obvious consequence 
> > that a more clearly framed question would be more likely to 
> > get a (better) response. No other posting conventions (aside 
> > from the usual ones regarding civility and adherence to
> > topic) would be expected.
> >  
> > My hope is that such a list would both reduce unnecessary 
> > traffic on r-help and satisfy a genuine need in a less 
> > threatening way. I can certainly see downsides (I often learn 
> > a lot from "How can I do this?" queries), but I think, on 
> > balance, this approach might be useful. So I would like to 
> > subject the idea to public scrutiny and criticism, as well as 
> > the opportunity for improvement from suggested modifications 
> > or alternatives. If it's useful, this will be recognized; if 
> > it's not and/or no one is interested, that, too, will be made 
> > manifest. I would be especially grateful for the opinions of 
> > casual users or newbies, either publicly or privately.
> >  
> > Cheers,
> >  
> > -- Bert Gunter
> > Genentech Non-Clinical Statistics
> > South San Francisco, CA
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From nair at uhura.sdsc.edu  Fri Sep 10 05:56:46 2004
From: nair at uhura.sdsc.edu (Murli Nair)
Date: Thu, 09 Sep 2004 20:56:46 -0700
Subject: [R] converting to data frame
Message-ID: <414125FE.3030709@imap.sdsc.edu>

Is there a method that converts a csv file to a data frame ?
M



From ggrothendieck at myway.com  Fri Sep 10 06:08:28 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 10 Sep 2004 04:08:28 +0000 (UTC)
Subject: [R] Efficient Cartesian product of data.frames
References: <4140F80B.3070902@dolphin.upenn.edu>
Message-ID: <loom.20040910T025447-254@post.gmane.org>

Timothy W. Victor <tvictor <at> dolphin.upenn.edu> writes:

> I am looking for efficient code to produce the Cartesian product of two 
> or more data.frames. 


First create some test data consisting of a list of n=2 data frames.

   data(iris)
   L <- list(iris1 = iris[1:3,1:2], iris2 = iris[1:3,3:4])

Now calculate the cartesian product of the row indices, grid,
and, in the second line, cbind together the corresponding rows:

   grid <- expand.grid(1:nrow(L[[1]]), 1:nrow(L[[2]]))
   cbind(L[[1]][grid[,1],], L[[2]][grid[,2],])

Now generalize that to n >= 2 data frames:

   grid <- do.call("expand.grid", lapply(L, function(x) 1:nrow(x)))
   do.call("cbind", lapply(seq(L), function(i)L[[i]][grid[,i],]))



From ripley at stats.ox.ac.uk  Fri Sep 10 07:32:38 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 10 Sep 2004 06:32:38 +0100 (BST)
Subject: [R] swiss.x
In-Reply-To: <4140EF7C.6050804@sdsc.edu>
Message-ID: <Pine.LNX.4.44.0409100628530.14055-100000@gannet.stats>

On Thu, 9 Sep 2004, T. Murlidharan Nair wrote:

> Is the swiss data set in R the same as S dataset swiss.x .

If that is meant to be a question, no.

> I was trying out some clustering by doing the following that I got from
> Venables and Ripley's book.

Not from the current edition, p. 317.

> h<-hclus(dist(swiss.x), method= "connected")
> plclust(h)
> cutree(h,3)
> plclust(clorder(h,cutree(h,3)))
> 
> I tried swiss instead of swiss.x, it doesnot seem happy.

If you want to use our book with R, please use the 2002 edition that
covers R. In the MASS package you will find R versions of the scripts for
(one of our books), as documented in the book and the book's website.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Sep 10 07:36:34 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 10 Sep 2004 06:36:34 +0100 (BST)
Subject: [R] converting to data frame
In-Reply-To: <414125FE.3030709@imap.sdsc.edu>
Message-ID: <Pine.LNX.4.44.0409100634230.14055-100000@gannet.stats>

On Thu, 9 Sep 2004, Murli Nair wrote:

> Is there a method that converts a csv file to a data frame ?

There are R _functions_, if that is what you are asking.  ("method" is 
a technical term in R.)  

Try help.search("csv"), which gives me one entry.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wuertz at itp.phys.ethz.ch  Fri Sep 10 09:19:18 2004
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Fri, 10 Sep 2004 07:19:18 +0000
Subject: [R] Copulas
In-Reply-To: <BAY18-F40EFTLm4GzCl0001e176@hotmail.com>
References: <BAY18-F40EFTLm4GzCl0001e176@hotmail.com>
Message-ID: <41415576.8000701@itp.phys.ethz.ch>

I have written a copula package for Rmetrics.

It covers the contents from Evanesce, but it is build in a little bit
different way. When testing is finished it will become part of
Rmetrics / fExtremes in the near future.

DiethelmWuertz


J W wrote:

> Is anyone already in the process of developing copula estimation 
> methods or porting Prof. Rene Carmona's EVANESCE 
> (http://www.orfe.princeton.edu/~rcarmona/SVbook/svbook.html)?
>
> JW
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From msvika at mscc.huji.ac.il  Fri Sep 10 10:34:04 2004
From: msvika at mscc.huji.ac.il (Victoria Landsman)
Date: Fri, 10 Sep 2004 10:34:04 +0200
Subject: [R] Dyn.load of sharing object with GSL library 
References: <Pine.LNX.4.44.0409091757260.1605-100000@gannet.stats>
Message-ID: <012901c49710$eeae7ca0$8600a8c0@home2>

Dear R-list,
1) thanks to all who tried to help me in solving my problem and especially
to Prof. Ripley for his prompt replies. My problem was not in the library
path but in the Makevars file. The main lesson is: don't use the quotes in
Makevars as I studied from
http://www.r-project.org/nocvs/mail/r-help/2002/0467.html.
The appropriate line in the Makevars file should be
PKG_LIBS=-L/usr/local/lib/ -lgsl  -lgslcblas
(no quotes).

2) I see that our  /usr/local/lib  directory does not contain libgsl.so file
but only libgsl.a and libgsl.la. May it be a sign of some problem or it is
usual?

I am using R-1.9.1 on Sun Solaris.
Much thanks again, Vicky.



----- Original Message -----
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Vicky Landsman" <msvika at mscc.huji.ac.il>
Cc: "r-help" <r-help at stat.math.ethz.ch>
Sent: Thursday, September 09, 2004 7:02 PM
Subject: Re: [R] Dyn.load of sharing object with GSL library


> On Thu, 9 Sep 2004, Vicky Landsman wrote:
>
> > Following the recommendation of Prof. Ripley, I have created the
Makevars
> > file with the line:
> >
PKG_LIBS="-L/usr/lib/libm -lm -L/usr/local/lib/libgsl -lgsl -L/usr/local/lib
> > /libgslcblas -lgslcblas"
> > in the working directory.
>
> No, that's not what I recommended. -L/path/to/libgsl would probably be
> -L/usr/local/lib if libgsl is in /usr/local/lib.  And why do you want -lm?
>
> Please consult your unstated OS's documentation for ld.
>
> > Now I have the code file Example3.c which computes the Bessel function
value
> > (the example is taken from the GSL reference book).
> > I am running:
> > R CMD SHLIB Example3.c
>
> Pleae show us exactly what you get here.
>
> > and all looks good.
> > The dyn.load("Example3.so") fails with the following error message:
> >
> > Error in dyn.load(x, as.logical(local), as.logical(now)) :
> >         unable to load shared library
> > "/fs/users1/guest/msvika/PhD/R_04/Example3.so":
> >   ld.so.1: /usr/local/sbin/R-1.9/R-1.9.1/bin/R.bin: fatal: relocation
error:
> > file /fs/users1/guest/msvika/PhD/R_04/Example3.so: symbol
gsl_sf_bessel_J0:
> > referenced symbol not found
>
> Try ldd /fs/users1/guest/msvika/PhD/R_04/Example3.so and get a local
> expert to interpret it for you.
>
> You will need anything you had in -L in PKG_LIBS in your library run path
> as well.  You may need e.g.
>
> export LD_LIBRARY_PATH=:${LD_LIBRARY_PATH}:/usr/local/lib
>
> and please check with a local expert about this.
>
> > What is wrong?
> > Much thanks, Vicky.
> >
> > ----- Original Message -----
> > From: "Vicky Landsman" <msvika at mscc.huji.ac.il>
> > To: "r-help" <r-help at stat.math.ethz.ch>
> > Sent: Thursday, September 09, 2004 6:18 PM
> > Subject: Re: [R] Adding GSL library path to SHLIB
> >
> >
> > > Dear Prof. Ripley,
> > > We read the archive thread
> > > http://maths.newcastle.edu.au/~rking/R/help/02b/0547.html
> > > Thank you for your help, we will try to create the Makevars file.
> > > Vicky.
> > >
> > >
> > >
> > > ----- Original Message -----
> > > From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
> > > To: "Vicky Landsman" <msvika at mscc.huji.ac.il>
> > > Cc: "r-help" <r-help at stat.math.ethz.ch>; <leonid at cc.huji.ac.il>
> > > Sent: Thursday, September 09, 2004 3:17 PM
> > > Subject: Re: [R] Adding GSL library path to SHLIB
> > >
> > >
> > > > On Thu, 9 Sep 2004, Vicky Landsman wrote:
> > > >
> > > > > Dear R-list people,
> > > >
> > > > > I asked a similar question a few hours before. I will try to be
more
> > > > > specific.  We like to add the GSL library to the file SHLIB in
order
> > to
> > > > > make it possible to run the C code using GSL functions from R.  We
> > read
> > > >
> > > > Read where?  It's incorrect information and only used for Fortran
> > linking.
> > > >
> > > > > that the path to the libgsl.a should be added to the line
> > shlib_libadd='
> > > > > ' in the file SHLIB but it does not work on our system. Dyn.load
fails
> > > > > with error "referenced symbol <symbolname> not found". What is
wrong?
> > > > > We will much appreciate any help on this.
> > > > >
> > > > > We are using R-1.9.1 on Unix.
> > > >
> > > > You should have a file called Makevars in the directory from which
> > > > you are doing the building, defining PKG_LIBS, maybe
> > > >
> > > > PKG_LIBS="-L/path/to/libgsl -lgsl"
> > > >
> > > > in the same way as you would for a package: see `Writing R
Extensions'.
> > > > I don't think that is documented anywere, though.
> > > >
> > > > --
> > > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > > > University of Oxford,             Tel:  +44 1865 272861 (self)
> > > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > > >
> > > >
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From vito_ricci at yahoo.com  Fri Sep 10 11:03:21 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Fri, 10 Sep 2004 11:03:21 +0200 (CEST)
Subject: [R] converting to data frame
Message-ID: <20040910090321.65645.qmail@web41201.mail.yahoo.com>

Hi,

see  ? read.csv  and use read.csv() to read the csv
file, after convert as a data.frame see: 

? as.data.frame

it forces into a data.frame;

e.g. you've the data csv file: data.csv

mydata<-read.csv('C:/data.csv')
mydf<-as.data.frame(mydata) ## data as dataframe

bye
Vito



Is there a method that converts a csv file to a data
frame ?
M

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml


		
___________________________________

http://it.seriea.fantasysports.yahoo.com/



From baron at psych.upenn.edu  Fri Sep 10 11:11:40 2004
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Fri, 10 Sep 2004 05:11:40 -0400
Subject: [R] Proposal for New R List: Criticism? Comments?
In-Reply-To: <1094784884.3512.46.camel@localhost.localdomain>
References: <20040910010130.VXMT4758.tomts13-srv.bellnexxia.net@JohnDesktop8300>
	<1094784884.3512.46.camel@localhost.localdomain>
Message-ID: <20040910091140.GA5396@psych>

On 09/10/04 03:54, Adaikalavan Ramasamy wrote:
>There is another issue to be considered. Currently you need to have the
>relevant packages installed before help.search() bring it up. My work
>around this is to install all available packages just in case the
>function I need is nestled in some non-standard packages. I also update
>them rather frequently.

I do this too, at my search site (where "frequently"=monthly) and
you can search functions only, and use Boolean search expressions
and phrases.

But right now the entire set of packages takes about 885 meg (if
I'm reading du correctly), which is less than my very modest
collection of digital photos, and a tiny fraction of a 3-year-old
standard hard disk.  In other words, it is no big deal to install
all the packages if you have your own computer.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
R search page: http://finzi.psych.upenn.edu/



From p.dalgaard at biostat.ku.dk  Fri Sep 10 11:29:57 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Sep 2004 11:29:57 +0200
Subject: [R] converting to data frame
In-Reply-To: <20040910090321.65645.qmail@web41201.mail.yahoo.com>
References: <20040910090321.65645.qmail@web41201.mail.yahoo.com>
Message-ID: <x2656mbhey.fsf@biostat.ku.dk>

Vito Ricci <vito_ricci at yahoo.com> writes:

> Hi,
> 
> see  ? read.csv  and use read.csv() to read the csv
> file, after convert as a data.frame see: 
> 
> ? as.data.frame
> 
> it forces into a data.frame;
> 
> e.g. you've the data csv file: data.csv
> 
> mydata<-read.csv('C:/data.csv')
> mydf<-as.data.frame(mydata) ## data as dataframe

Eh? The return value from read.csv() *is* a data frame! 

Notice, by the way, that you need read.csv2() in locales which use
comma as decimal separator.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Fri Sep 10 12:26:27 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 10 Sep 2004 11:26:27 +0100 (BST)
Subject: [R] Proposal for New R List: Criticism? Comments?
In-Reply-To: <20040910091140.GA5396@psych>
Message-ID: <Pine.LNX.4.44.0409101113450.19494-100000@gannet.stats>

On Fri, 10 Sep 2004, Jonathan Baron wrote:

> On 09/10/04 03:54, Adaikalavan Ramasamy wrote:
> >There is another issue to be considered. Currently you need to have the
> >relevant packages installed before help.search() bring it up. My work
> >around this is to install all available packages just in case the
> >function I need is nestled in some non-standard packages. I also update
> >them rather frequently.
> 
> I do this too, at my search site (where "frequently"=monthly) and
> you can search functions only, and use Boolean search expressions
> and phrases.
> 
> But right now the entire set of packages takes about 885 meg (if
> I'm reading du correctly), which is less than my very modest
> collection of digital photos, and a tiny fraction of a 3-year-old
> standard hard disk.  In other words, it is no big deal to install
> all the packages if you have your own computer.

I am seeing about 520Mb for all base + CRAN packages under 1.9.1, and it 
will be rather less under 2.0.0 as more parts are stored compressed.
BioC is a lot larger.

It is however, a BIG deal to install *all* the packages and am I currently 
10 short since they depend on other software that I do not have a licence 
for or will not compile (and there are three others I cannot reinstall 
using current gcc).  On AMD64 and Solaris there are several others, and
something like 20 do not install on Windows.  (I could use --install-fake 
as the CRAN checks do, but I have the almost complete set installed to 
test R changes, not test packages.)

So I do see some merit in having a full-text search for R help available
at some URL, as Jonathan has kindly provided.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From nusbj at hotmail.com  Fri Sep 10 12:44:55 2004
From: nusbj at hotmail.com (Zhen Pang)
Date: Fri, 10 Sep 2004 18:44:55 +0800
Subject: [R] GEE model
Message-ID: <BAY22-F39Vbj2ltpNeb000395cc@hotmail.com>

try geepack


>From: Lisa Wang <lisawang at uhnres.utoronto.ca>
>To: R-Help <r-help at stat.math.ethz.ch>
>Subject: [R] GEE model
>Date: Thu, 09 Sep 2004 15:31:59 -0400
>
>Hello there,
>
>
>My name is Lisa and I'm doing analysis using genelized linear model-GEE
>model because I have some repeated measurements on the same patients (in
>a bilateral eye disease case). It would be very appreciated if you could
>shed some light on what function to use in R.
>
>Thank you very much
>
>Lisa Wang Msc.
>
>Toronto,Ca
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From sibert at hawaii.edu  Fri Sep 10 13:30:04 2004
From: sibert at hawaii.edu (John Sibert)
Date: Fri, 10 Sep 2004 07:30:04 -0400
Subject: [R] ccf question
Message-ID: <6.1.1.1.2.20040910072425.035c91a8@mail.hawaii.edu>

Can someone please verify the interpretation of lag in the ccf function in 
the ts package.
Suppose ccf(x,y).
Do negative lags indicate that the events in x precede the events in y and 
positive lags indicate that events in y precede events in x?
Thanks,
John


____________________________________

John Sibert, Manager
Pelagic Fisheries Research Program
University of Hawaii at Manoa
1000 Pope Road, MSB 313
Honolulu, HI 96822
United States

Phone: (808) 956-4109
Fax: (808) 956-4104
____________________________________

Washington DC
Phone: (202) 861 2363
Fax: (202) 861 4767
____________________________________

PFRP Web Site:   http://www.soest.hawaii.edu/PFRP/
email:  sibert at hawaii.edu



From day at upci.pitt.edu  Fri Sep 10 14:30:14 2004
From: day at upci.pitt.edu (Day, Roger)
Date: Fri, 10 Sep 2004 08:30:14 -0400
Subject: [R] loading Sjava
Message-ID: <3D0B2434377E984E9C85CAA316F8B18309C6B5@nsabpmail>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040910/375075f4/attachment.pl

From jfox at mcmaster.ca  Fri Sep 10 14:44:57 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 10 Sep 2004 08:44:57 -0400
Subject: [R] R conversion
In-Reply-To: <026901c496e1$3205deb0$f7d4f218@your939tqgi62r>
Message-ID: <20040910124457.BSMC18869.tomts5-srv.bellnexxia.net@JohnDesktop8300>

Dear Mark, 

> -----Original Message-----
> From: Mark Strivens [mailto:mstrivens at houston.rr.com] 
> Sent: Thursday, September 09, 2004 9:52 PM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] R conversion
> 
> Thanks John for the post - I had found factanal However 
> factanal it seems you have specify the number of factors to 
> be fitted up front, whereas with the SAS procedure you don't 
> - this is apparently important to the analysis!
> 

With ML factor analysis, you can test how many factors are required.

> Perhaps I could emulate this function by breaking it down 
> using factor extraction by principal component analysis and 
> the doing the varimax rotation second? If that makes any sense?
> 

Yes -- it shouldn't be hard to write your own PA factor-analysis function,
if that's what you prefer. For principal-components analysis, see ?princomp
and ?prcomp [which are turned up by help.search("principal components"), by
the way].

Regards,
 John



From ripley at stats.ox.ac.uk  Fri Sep 10 15:03:56 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 10 Sep 2004 14:03:56 +0100 (BST)
Subject: [R] loading Sjava
In-Reply-To: <3D0B2434377E984E9C85CAA316F8B18309C6B5@nsabpmail>
Message-ID: <Pine.LNX.4.44.0409101353410.21306-100000@gannet.stats>

On Fri, 10 Sep 2004, Day, Roger wrote:

> I'm excited about SJava, and I'ld love to get it working, but can't get
> past loading the package.
>  
> .First.lib fails on this statement:
>  
> > library.dynam("SJava", "SJava", "C:/PROGRA~1/R/rw1091/library")
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
>         unable to load shared library
> "C:/PROGRA~1/R/rw1091/library/SJava/libs/SJava.dll":
>   LoadLibrary failure:  The specified module could not be found.
> 
>  
> Actually, SJava.dll is present there.

But who said `SJava.dll' was the `specified module'?  Hint: it is most
likely not, but also you are trying to load a DLL built under R 1.6.2 into
R 1.9.1 and that is likely to result in such a message.

> Advice????

Read the documentation, especially before posting as the posting guide 
asks.

> I'm using XP.  
> Obtained the package from http://www.stats.ox.ac.uk/pub/bdr/SJava/ .

Do learn to read ReadMe's!  That one says

    SJava_0.65a.tar.gz      modified sources
    SJava.zip               build under R1.6.2

    The sources here will build under R 1.6.x and R-devel (1.7.0-to-be).

    To install:

    Sjava.zip -- unzip in ...\rw1062\library.

and note, not rw1091.

That was a private area, and I have deleted it.  There is a version of 
SJava in the public area http://www.stats.ox.ac.uk/pub/RWin, but do 
practice assiduously your new-found skills at reading ReadMe files.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kjetil at acelerate.com  Fri Sep 10 15:17:25 2004
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Fri, 10 Sep 2004 09:17:25 -0400
Subject: [R] ccf question
In-Reply-To: <6.1.1.1.2.20040910072425.035c91a8@mail.hawaii.edu>
References: <6.1.1.1.2.20040910072425.035c91a8@mail.hawaii.edu>
Message-ID: <4141A965.2010008@acelerate.com>

John Sibert wrote:

> Can someone please verify the interpretation of lag in the ccf 
> function in the ts package.
> Suppose ccf(x,y).
> Do negative lags indicate that the events in x precede the events in y 
> and positive lags indicate that events in y precede events in x?
> Thanks,
> John
>
>
This you ncan answer for yourself by doing
x <- rnorm(200)
ccf(x, lag(x), na.action=na.omit)


and seing the value 1 at lag 1.

Kjetil halvorsen
 

> ____________________________________
>
> John Sibert, Manager
> Pelagic Fisheries Research Program
> University of Hawaii at Manoa
> 1000 Pope Road, MSB 313
> Honolulu, HI 96822
> United States
>
> Phone: (808) 956-4109
> Fax: (808) 956-4104
> ____________________________________
>
> Washington DC
> Phone: (202) 861 2363
> Fax: (202) 861 4767
> ____________________________________
>
> PFRP Web Site:   http://www.soest.hawaii.edu/PFRP/
> email:  sibert at hawaii.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra



From day at upci.pitt.edu  Fri Sep 10 15:56:01 2004
From: day at upci.pitt.edu (Day, Roger)
Date: Fri, 10 Sep 2004 09:56:01 -0400
Subject: [R] loading Sjava
Message-ID: <3D0B2434377E984E9C85CAA316F8B1831B9472@nsabpmail>

Apparently further explanation is in order,
to correct some misimpressions.

I was not aware that I was intruding on a private space.
I was directed to the quoted URL for Sjava by the omegahat website,
www.omegahat.org/RSJava,
which states "Currently, it is advisable to get the binary from Brian
Ripley's Web site"  where the link is provided.  
After a "refresh", I see that the page still says that.

I had indeed read three "readme"s in the SJava distribution, as well as
two
different FAQs (one on the web and one in the distribution,
and some of the documentation for usage.  
I did not read the "readme" in "examples", putting that off, I think
reasonably.  
I have not found the "readme" which you mention.  
The page www.omegathat.org/RSJava/FAQ.html states "you will need version
1.2.0".

My message mentioned R.dll because the FAQ discusses a problem if the
installed
version of R was not compiled as a shareable library.  When I found 
R.dll I concluded that that problem is probably not applicable here.
It's not 
true that I concluded that R.dll was the "module" referred to.
If 1.6.2 is needed, as you suggest, I do not know yet if I will need 
to compile it with the flag "--enable-R-shlib" mentioned in the FAQ in
reference
to R.dll.  If anyone already has a 1.6.2 build in binary, I would
appreciate it.

I do appreciate your help, Professor, and will pursue your suggestion
vis a vis 1.6.2.  Moderation of the pejoratives would be nice. 

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Friday, September 10, 2004 9:04 AM
To: Day, Roger
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] loading Sjava


On Fri, 10 Sep 2004, Day, Roger wrote:

> I'm excited about SJava, and I'ld love to get it working, but can't 
> get past loading the package.
>  
> .First.lib fails on this statement:
>  
> > library.dynam("SJava", "SJava", "C:/PROGRA~1/R/rw1091/library")
> Error in dyn.load(x, as.logical(local), as.logical(now)) : 
>         unable to load shared library
> "C:/PROGRA~1/R/rw1091/library/SJava/libs/SJava.dll":
>   LoadLibrary failure:  The specified module could not be found.
> 
>  
> Actually, SJava.dll is present there.

But who said `SJava.dll' was the `specified module'?  Hint: it is most
likely not, but also you are trying to load a DLL built under R 1.6.2
into R 1.9.1 and that is likely to result in such a message.

> Advice????

Read the documentation, especially before posting as the posting guide 
asks.

> I'm using XP.
> Obtained the package from http://www.stats.ox.ac.uk/pub/bdr/SJava/ .

Do learn to read ReadMe's!  That one says

    SJava_0.65a.tar.gz      modified sources
    SJava.zip               build under R1.6.2

    The sources here will build under R 1.6.x and R-devel (1.7.0-to-be).

    To install:

    Sjava.zip -- unzip in ...\rw1062\library.

and note, not rw1091.

That was a private area, and I have deleted it.  There is a version of 
SJava in the public area http://www.stats.ox.ac.uk/pub/RWin, but do 
practice assiduously your new-found skills at reading ReadMe files.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kimai at Princeton.Edu  Fri Sep 10 16:54:19 2004
From: kimai at Princeton.Edu (Kosuke Imai)
Date: Fri, 10 Sep 2004 10:54:19 -0400 (EDT)
Subject: [R] random seed
Message-ID: <Pine.LNX.4.44.0409101049220.32241-100000@wws-6qcbw21.Princeton.EDU>

Hi,
  I have a R wrapper function that calls my C code via .C(). In my C code,
I have been calling GetRNGstate() (and PutRNGstate()) once at the
beginning (and the end) of the code. However, if I generate a random
number within the R wrapper function (say via runif()), then my C code
produces the exactly same numbers. If I don't generate a random number 
within the wrapper, it works fine. I wonder if there is something I need 
to do in order to prevent this problem. Any help would be appreciated.
Best,
Kosuke

---------------------------------------------------------
Kosuke Imai               Office: Corwin Hall 041
Assistant Professor       Phone: 609-258-6601 
Department of Politics    eFax:  973-556-1929
Princeton University      Email: kimai at Princeton.Edu
Princeton, NJ 08544-1012  http://www.princeton.edu/~kimai



From jfox at mcmaster.ca  Fri Sep 10 16:56:51 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 10 Sep 2004 10:56:51 -0400
Subject: [R] Proposal for New R List: Criticism? Comments?
In-Reply-To: <Pine.LNX.4.44.0409101113450.19494-100000@gannet.stats>
Message-ID: <20040910145652.KSBB19123.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Brian et al.,

Jonathan's search site is excellent -- I use it frequently -- and for some
reason new users seem unaware of help.search(), which, despite the fact that
it searches only in installed packages, I also find very useful.

A couple of comments, however: First, if help pages from all packages were
available at a central location -- e.g., at CRAN -- help.search() could have
an option to search that location. Second, I still feel that it would be
useful to provide some other way of searching the space of all available
functions. One idea, which I mentioned in an earlier message on this thread,
would be a keyword system (again, different from the current set of standard
keywords). The keywords could be accessed by help.search() and also compiled
into an index.

Regards,
 John

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Friday, September 10, 2004 5:26 AM
> To: Jonathan Baron
> Cc: Adaikalavan Ramasamy; John Fox; R-help; 'Berton Gunter'
> Subject: Re: [R] Proposal for New R List: Criticism? Comments?
> 
> On Fri, 10 Sep 2004, Jonathan Baron wrote:
> 
> > On 09/10/04 03:54, Adaikalavan Ramasamy wrote:
> > >There is another issue to be considered. Currently you 
> need to have 
> > >the relevant packages installed before help.search() bring 
> it up. My 
> > >work around this is to install all available packages just in case 
> > >the function I need is nestled in some non-standard 
> packages. I also 
> > >update them rather frequently.
> > 
> > I do this too, at my search site (where 
> "frequently"=monthly) and you 
> > can search functions only, and use Boolean search expressions and 
> > phrases.
> > 
> > But right now the entire set of packages takes about 885 
> meg (if I'm 
> > reading du correctly), which is less than my very modest 
> collection of 
> > digital photos, and a tiny fraction of a 3-year-old standard hard 
> > disk.  In other words, it is no big deal to install all the 
> packages 
> > if you have your own computer.
> 
> I am seeing about 520Mb for all base + CRAN packages under 
> 1.9.1, and it will be rather less under 2.0.0 as more parts 
> are stored compressed.
> BioC is a lot larger.
> 
> It is however, a BIG deal to install *all* the packages and 
> am I currently 10 short since they depend on other software 
> that I do not have a licence for or will not compile (and 
> there are three others I cannot reinstall using current gcc). 
>  On AMD64 and Solaris there are several others, and something 
> like 20 do not install on Windows.  (I could use 
> --install-fake as the CRAN checks do, but I have the almost 
> complete set installed to test R changes, not test packages.)
> 
> So I do see some merit in having a full-text search for R 
> help available at some URL, as Jonathan has kindly provided.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From martyn.sherriff at kcl.ac.uk  Fri Sep 10 17:24:01 2004
From: martyn.sherriff at kcl.ac.uk (Martyn Sherriff)
Date: Fri, 10 Sep 2004 16:24:01 +0100
Subject: [R] Re: Bangdiwala
Message-ID: <20040910152126.JQKX21130.mta05-svc.ntlworld.com@Hex>

I am new to R and would be grateful if somebody could tell me how to access
the Bangdiwala statistic after an agreement plot.
Thanks,
Martyn

Dr. Martyn Sherriff
Senior Lecturer, Dental Biomaterials Science,
GKT Dental Institute,
Floor 17, Guy's Tower,
London Bridge, London SE1 9RT
e-mail: martyn.sherriff at kcl.ac.uk
Tel. +44(0)-2071-881822
Fax. +44(0)-2071-881823 
Departmental Home Page: http://tinyurl.com/2eotw
Personal Home Page: http://tinyurl.com/kgkd
Youth Rugby: www.fullerians.demon.co.uk
"The difference between winners and losers is that winners tell the jokes
and the losers talk about the run of the ball." 
"It's not over until the fat man whistles."



From sundar.dorai-raj at PDF.COM  Fri Sep 10 17:34:51 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Fri, 10 Sep 2004 10:34:51 -0500
Subject: [R] Re: Bangdiwala
In-Reply-To: <20040910152126.JQKX21130.mta05-svc.ntlworld.com@Hex>
References: <20040910152126.JQKX21130.mta05-svc.ntlworld.com@Hex>
Message-ID: <4141C99B.6090808@pdf.com>



Martyn Sherriff wrote:

> I am new to R and would be grateful if somebody could tell me how to access
> the Bangdiwala statistic after an agreement plot.
> Thanks,
> Martyn
> 

Martyn,
   Since you didn't say so, I have to guess you are using package:vcd? 
If so, then ?agreementplot says:

<quote>
Value

Invisibly returned, a list with components

Bangdiwala 	the unweighted agreement strength statistic
Bangdiwala.Weighted 	the weighted statistic
weights 	the weigtht vector used.
</quote>

So you should be able to do the following:

library(vcd)
data(SexualFun)
ap <- agreementplot(t(SexualFun))

ap$Bangdiwala

(Please read the posting guide.)

--sundar



From gunter.berton at gene.com  Fri Sep 10 17:40:47 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 10 Sep 2004 08:40:47 -0700
Subject: [R] Proposal for New R List: Criticism? Comments?
In-Reply-To: <20040910145652.KSBB19123.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <200409101540.i8AFelLG028224@volta.gene.com>

My thanks to all who commented, both publicly and privately. There seems to
be some agreement that some sort of better "indexing" system (for want of a
better term) to help users find the functionality they need is desirable,
but very little support for my proposal. So be it -- the vox populii has
spoken!

However, I hope that the discussion may yet catalyze some further thought
and ultimately useful improvements or changes in what is currently
available, whether in R, on CRAN, or from individual web sites like Jonathan
Baron's.

Again, my thanks to all for your ideas. 

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

From rossini at blindglobe.net  Fri Sep 10 19:00:18 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 10 Sep 2004 10:00:18 -0700
Subject: [R] Proposal for New R List: Criticism? Comments?
In-Reply-To: <200409101540.i8AFelLG028224@volta.gene.com> (Berton Gunter's
	message of "Fri, 10 Sep 2004 08:40:47 -0700")
References: <200409101540.i8AFelLG028224@volta.gene.com>
Message-ID: <85acvy6ov1.fsf@servant.blindglobe.net>


If you think it would be useful, and that it would help you and your
colleagues (and maybe others), why not see if Genentech would provide
some support for prototyping your idea?  Then if it works (i.e. proof
of usefulness), I'm sure someone would be willing to keep it running.

best,
-tony


Berton Gunter <gunter.berton at gene.com> writes:

> My thanks to all who commented, both publicly and privately. There seems to
> be some agreement that some sort of better "indexing" system (for want of a
> better term) to help users find the functionality they need is desirable,
> but very little support for my proposal. So be it -- the vox populii has
> spoken!
>
> However, I hope that the discussion may yet catalyze some further thought
> and ultimately useful improvements or changes in what is currently
> available, whether in R, on CRAN, or from individual web sites like Jonathan
> Baron's.
>
> Again, my thanks to all for your ideas. 
>
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>  
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
>  
>  
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From ramasamy at cancer.org.uk  Fri Sep 10 19:10:43 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 10 Sep 2004 18:10:43 +0100
Subject: [R] Proposal for New R List: Criticism? Comments?
In-Reply-To: <20040910091140.GA5396@psych>
References: <20040910010130.VXMT4758.tomts13-srv.bellnexxia.net@JohnDesktop8300>
	<1094784884.3512.46.camel@localhost.localdomain>
	<20040910091140.GA5396@psych>
Message-ID: <1094836242.2977.10.camel@ndmpc126.ihs.ox.ac.uk>

Just finished updating and installing new packages from CRAN and
BioConductor (including annotation data) and am happy to say that my R
has just exceeded the 1 GB mark.



On Fri, 2004-09-10 at 10:11, Jonathan Baron wrote:
> On 09/10/04 03:54, Adaikalavan Ramasamy wrote:
> >There is another issue to be considered. Currently you need to have the
> >relevant packages installed before help.search() bring it up. My work
> >around this is to install all available packages just in case the
> >function I need is nestled in some non-standard packages. I also update
> >them rather frequently.
> 
> I do this too, at my search site (where "frequently"=monthly) and
> you can search functions only, and use Boolean search expressions
> and phrases.
> 
> But right now the entire set of packages takes about 885 meg (if
> I'm reading du correctly), which is less than my very modest
> collection of digital photos, and a tiny fraction of a 3-year-old
> standard hard disk.  In other words, it is no big deal to install
> all the packages if you have your own computer.
> 
> Jon



From wanr at ucalgary.ca  Fri Sep 10 21:31:55 2004
From: wanr at ucalgary.ca (wanr@ucalgary.ca)
Date: Fri, 10 Sep 2004 13:31:55 -0600
Subject: [R] How to obtain a 95% envelope for the estimated cumulative risk
	function from bootstrap samples
Message-ID: <200409101931.i8AJVtD20143@smtp2.ucalgary.ca>

Hi all,

The hypothetical data is displayed as follows.

ID   time   status     
1     81       0 
2     42       1
3     37       1
4     54       0
5     35       0
6     38       1
7     29       0
8     40       0

Question 1: How to obtain a 95% envelope for the estimated cumulative risk 
function from bootstrap samples? I guess the output of this step consists of 
the envelope and the estimated cumulative risk function.

Question2: bootstrap process will be repeated for n times; then the average 
cumulative risk function was estimated  as the median of the n empirical 
cumulative risk functions. My question is how to plot this so called Average 
Risk Function vs. time easily instead of using lines() and points() to draw 
the above step function?

Thanks in advance.


Rui



From wanr at ucalgary.ca  Fri Sep 10 21:38:13 2004
From: wanr at ucalgary.ca (wanr@ucalgary.ca)
Date: Fri, 10 Sep 2004 13:38:13 -0600
Subject: [R] How to obtain a 95% envelope for the estimated cumulative risk
	function from bootstrap samples
Message-ID: <200409101938.i8AJcDD21641@smtp2.ucalgary.ca>

Hi all,

I am trying to replicate the results from a paper. The problems are in the 
setting of survival analysis.

The hypothetical data is displayed as follows.

ID   time   status     
1     81       0 
2     42       1
3     37       1
4     54       0
5     35       0
6     38       1
7     29       0
8     40       0

Question 1: How to obtain a 95% envelope for the estimated cumulative risk 
function from bootstrap samples? I guess the output of this step consists of 
the envelope and the estimated cumulative risk function.

Question2: bootstrap process will be repeated for n times; then the average 
cumulative risk function was estimated  as the median of the n empirical 
cumulative risk functions. My question is how to plot this so called Average 
Risk Function vs. time easily instead of using lines() and points() to draw 
the above step function?

Thanks in advance.


Rui



From shitao at hotmail.com  Fri Sep 10 23:06:58 2004
From: shitao at hotmail.com (Tao Shi)
Date: Fri, 10 Sep 2004 21:06:58 +0000
Subject: [R] hclust, centroid
Message-ID: <BAY22-F38xUJyvf6pDL00038c12@hotmail.com>

Does anyone know how hclust (stats) calculates centroid linkage if only a 
distance matrix can be used as the input?

...Tao



From drf5n at maplepark.com  Sat Sep 11 01:29:32 2004
From: drf5n at maplepark.com (David Forrest)
Date: Fri, 10 Sep 2004 18:29:32 -0500 (CDT)
Subject: [R] Plotting irregular grid as image or persp
In-Reply-To: <1093698182.413082867b0b4@www-auth.cs.wisc.edu>
References: <Pine.LNX.4.58.0408271527040.558@maplepark.com>
	<1093662667.412ff7cb848a8@www-auth.cs.wisc.edu>
	<Pine.LNX.4.58.0408272347020.558@maplepark.com>
	<1093698182.413082867b0b4@www-auth.cs.wisc.edu>
Message-ID: <Pine.LNX.4.58.0409101813570.451@maplepark.com>

Thanks Deepanyan,


On Sat, 28 Aug 2004, Deepayan Sarkar wrote:
...
> Yes, I think rgl would be the right tool for this. Even apart from the 3d
> acceleration issues, one of the problems with getting this in R would be that R
> doesn't do raster graphics, and I don't think hidden surface algorithms are
> very easy to implement in the R model.
...
> >
> >   library(ncdf)
> > #  library(rgl)
> >   teapot<-open.ncdf("teapot.nc")
> >    # wget http://www.maplepark.com/~drf5n/extras/teapot.nc
> >   edges<-get.var.ncdf(teapot,"tris")
> >   vertices<-get.var.ncdf(teapot,"locations")
> >
> >   xy<-vertices[c(1,2),] # this would be cooler with ?persp's trans3d
> >
> >   plot(1:2,xlim=range(unlist(xy[1,])), ylim=range(xy[2,]),type='n')
> >   apply(edges,2,function(x){polygon(t(xy[,x]))})
>
> I was playing around with this yesterday and got something similar (but more
> general). I didn't send it to you because I wasn't sure if that's what you
> wanted. Of course, I'm more familiar with the lattice version of trans3d, so it
> uses that. There are 2 versions, one using grid, one with base graphics.
>
> As I said, there are glitches due to faulty drawing order of the triangles.
> Shading is also possible (as implemented in wireframe), but those calculations
> are done in C code, so it would take a bit longer to carry over.
>
>
> library(grid)
> library(lattice)
>
>
> plotMesh.grid <-
>     function(l, z, rot.mat, dist = 0.1)
>     ## rot.mat: 4x4 transformation matrix
>     ## dist: controls perspective, 0 = none
> {
>     x <- ltransform3dto3d(l[,z], rot.mat, dist = dist)
>     id <- seq(length = ncol(x) / 3)
>     ord <- order(x[3, id * 3] + x[3, id * 3 - 1] +
>                  x[3, id * 3 - 2])
>     grid.newpage()
>     xscale <- range(x[1,])
>     yscale <- range(x[2,])
>     md <- max(diff(xscale), diff(yscale))
>     pushViewport(viewport(w = 0.9 * diff(xscale) / md,
>                           h = 0.9 * diff(yscale) / md,
>                           xscale = xscale,
>                           yscale = yscale))
>     id <-
>         as.vector(outer(1:3, (id[ord]-1) * 3, "+"))
>     grid.polygon(x = x[1,id],
>                  y = x[2,id],
>                  default.units = "native",
>                  gp = gpar(fill = "gray"),
>                  id = rep(id[ord], each = 3))
> }
>
>
>
> plotMesh.base <-
>     function(l, z, rot.mat, dist = 0.1, subset = TRUE)
>     ## rot.mat: 4x4 transformation matrix
>     ## dist: controls perspective, 0 = none
> {
>     x <- ltransform3dto3d(l[,z], rot.mat, dist = dist)
>     id <- seq(length = ncol(x) / 3)
>     ord <- order(x[3, id * 3] + x[3, id * 3 - 1] +
>                  x[3, id * 3 - 2])
>     xscale <- range(x[1,])
>     yscale <- range(x[2,])
>     plot(xscale, yscale, type = "n")
>     x <- cbind(x, NA)
>     id <-
>         as.vector(rbind(outer(1:3, (id[ord]-1) * 3, "+"),
>                         ncol(x)))
>     polygon(x = x[1,id],
>             y = x[2,id],
>             col = "gray")
> }
>
>
> rot.mat <- ltransform3dMatrix(list(y = -30, x = 40))
> plotMesh.grid(l, z, rot.mat, dist = 0)
> plotMesh.base(l, z, rot.mat, dist = 0)

Those are nice -- I did want a varying color however, and needed to
separate the calls to polygon:

 plotMesh.base<-function(vertices,edges,col,rot.mat=diag(4),dist=0.1,...){
  ## rot.mat a 4x4 homogeneous transformation matrix
  ## dist: controls perpective per lattice::ltransform3dto3d

  # rotate
  vertices<-ltransform3dto3d(vertices,rot.mat,dist)
    xscale <- range(vertices[1,])
    yscale <- range(vertices[2,])
    plot(xscale, yscale, type = "n")

  # find rough plot order

  ord<-order(apply(edges,2,function(x){sum(vertices[3,x])}))

  if (length(col) == 1){
    sapply(ord,function(x){
      polygon(vertices[1,edges[,x]],vertices[2,edges[,x]],col=col,...)})
  } else {
    sapply(ord,function(x){
      polygon(vertices[1,edges[,x]],vertices[2,edges[,x]],col=col[x],...)})
  }
  invisible(ord)
 }

rot.mat <- ltransform3dMatrix(list(z=45,y=30)) #;rot.mat

plotMesh.base(l,z,rot.mat=rot.mat,col=rainbow(dim(z)[2]),lty=0)


and the resultant image is:

   http://www.maplepark.com/~drf5n/images/teapot2.png


I posted some really rough notes at
http://www.maplepark.com/~drf5n/cgi-bin/wiki.cgi?RMeshVisualization

Dave
-- 
 Dave Forrest
 drf at vims.edu                                    (804)684-7900w
 drf5n at maplepark.com                             (804)642-0662h
                                   http://maplepark.com/~drf5n/



From irena.komprej at telemach.net  Sat Sep 11 11:18:39 2004
From: irena.komprej at telemach.net (Irena Komprej)
Date: Sat, 11 Sep 2004 09:18:39 -0000
Subject: [R] Cancor
Message-ID: <000101bd165b$7bef3070$0300a8c0@JJ.cable.amis.net>

Dear R's!
I am strugling with cancor procedure in R. I cannot figure out the
meaning of xcoef and of yxcoef.
Are these:
1. standardized coefficients
2. structural coefficients
3. something else?

I have tried to simulate canonical correlation analysis by checking the
eigenstructure of the expression:

Sigma_xx %*% Sigma_xy %*% Sigma_yy %*% t(Sigma_xy).

The resulting eigenvalues were the same as the squared values of
cancor$cor. I have normalized the resulting eigenvectors, the a's with

sqrt(a'%*%Sigma_xx%*%t(a)), and similarly the b's with
sqrt(b'%*%Sigma_yy%*%t(b)).

The results differed considerably from xcoef and ycoef of the cancor.

I thought then, maybe these coefficients are structural coefficients and
therefore I multiplied them, the a's with
a%*%Sigma_xx, and the b's with
b%*%Sigma_yy,

but the results are nevertheless far from those of the cancor. Now, I
really don't know any more, how to interpret the xcoef and ycoef.
I am thanking you in advance.

Irena Komprej
(an R enthusiast as of last year)



From irena.komprej at telemach.net  Sat Sep 11 05:45:07 2004
From: irena.komprej at telemach.net (Irena Komprej)
Date: Sat, 11 Sep 2004 05:45:07 +0200
Subject: [R] Cancor
Message-ID: <000b01c497b1$bb755150$0300a8c0@JJ.cable.amis.net>

Dear R's!
I am strugling with cancor procedure in R. I cannot figure out the
meaning of xcoef and of yxcoef.
Are these:
1. standardized coefficients
2. structural coefficients
3. something else?

I have tried to simulate canonical correlation analysis by checking the
eigenstructure of the expression:

Sigma_xx %*% Sigma_xy %*% Sigma_yy %*% t(Sigma_xy).

The resulting eigenvalues were the same as the squared values of
cancor$cor. I have normalized the resulting eigenvectors, the a's with

sqrt(a'%*%Sigma_xx%*%t(a)), and similarly the b's with
sqrt(b'%*%Sigma_yy%*%t(b)).

The results differed considerably from xcoef and ycoef of the cancor.

I thought then, maybe these coefficients are structural coefficients and
therefore I multiplied them, the a's with
a%*%Sigma_xx, and the b's with
b%*%Sigma_yy,

but the results are nevertheless far from those of the cancor. Now, I
really don't know any more, how to interpret the xcoef and ycoef.
I am thanking you in advance.

Irena Komprej
(an R enthusiast as of last year)



From assuncao.senra at portugalmail.com  Sat Sep 11 15:22:13 2004
From: assuncao.senra at portugalmail.com (assuncao.senra@portugalmail.com)
Date: Sat, 11 Sep 2004 14:22:13 +0100
Subject: [R] help in building a function
Message-ID: <1094908933.4142fc05bdda8@webmail2.portugalmail.pt>

hello,
i'm new in writting functions in R. I read the R-help manuals but still 
couldn't get it right.
The problem is: 
I have data on 16 categorical variables for 335 individuals. the data are 
lines for individuals and columns for variables.
I want to calculate the correlation between two variables using a formula 
given by Agresti for ordinal categorical variables.
I have to calcule the value for each pair of variables and save the result in 
a vector...
I wrote the following code

X<-as.matrix(X)

n=335
for (i in 1:15){
for (j in i+1:16){
Tab<-table(X[,i],X[,j])
u<-1:nrow(Tab)
v<-1:ncol(Tab)

ml<-margin.table(Tab,1)
mc<-margin.table(Tab,2)

r1<-u*Tab
r2<-sum(v*t(r1))

r3<-sum(u*ml)*(sum(v*mc)/n

r5<-sum((v^2)*mc)-((sum(v*mc))^2)/n

r4<-sum((u^2)*ml)-((sum(u*ml))^2)/n
r<-(r2-r3)/sqrt(r4*r5)

r
m=(n-1)*r^2
}
}
The correlation is r.I have a result, but there is a warning regarding r5 
about sintax.
Plus, it doesn??t perform the loops and I don't know how to save the results in 
a vector.
thanks for any help

Assun????o



__________________________________________________________



From matt at overlook.homelinux.net  Sat Sep 11 15:39:20 2004
From: matt at overlook.homelinux.net (Matthew Wilson)
Date: Sat, 11 Sep 2004 13:39:20 +0000
Subject: [R] SAS to R migration questions
Message-ID: <20040911133920.GA29444@mwilson.umlcoop.net>

Hi,


I'd like to get away from SAS, but I don't really know R well enough at
this point to know if it would be good for this project.  I tried to
describe the essence of the project below without getting bogged down in
details.

It starts when I receive a data flat file.  There's lots of columns, but
the relevant ones are:

    custid  (customer ID number)
    saledt  (date of sale)
    salepx  (sale price)


Step 1:

I read in this data into a SAS dataset.  Some of these flat files hold
several gigabytes of data.  SAS allows indexes to be created on columns
which really speeds up queries. 

I read the R import/export doc and it suggested using databases for
really big datasets.  I figured I'd probably use perl or python to read
the file and convert it to either an R .tab file or to load the data
into a SQL database for the big files (Postgres or MySQL, since I'm
trying to go 100% open source with this).



Step 2:

In the data, I'll usually find one row per sale, but occasionally, a
sale will be entered incorrectly at first, then later reversed, then a
third line will show the correct sale data:

    custid      saledt      salepx
    111         8/1/2004    $75
    111         9/1/2004    $50
    112         10/1/2004   $30
    112         10/1/2004   ($30)
    112         10/1/2004   $20

The fourth line reverses the third line by showing a negative charge for
the same customer ID and sale date, and the last line is the correct
line.  I want to compress all those adjustments and reversals lines out
of the data, so the outgoing data would look like this:

    custid      saledt      salepx
    111         8/1/2004    $75
    111         9/1/2004    $50
    112         10/1/2004   $20

In SAS, I use a proc summary step in SAS to accomplish this:

    proc summary data=d1;
        class custid saledt;
        var salepx;
        output out=d2 sum=;
    run;

This is where I need help:  how to do this step in R?


Step 3:

I print a list of number of sales per customer ID, ranking the customer
IDs from most to least.  I use a SAS proc freq step for this:

    proc freq data=d2 order=freq;
        tables custid;
    run;

and the output would look like this:

    custid      freq
    111         2
    112         1


Again, I have no idea how to do step 3 in R.  


Thanks in advance!  All help is welcome.  Is this kind of work what R is
good at?


-- 
My public key:
gpg --recv-keys --keyserver www.mandrakesecure.net 0x8D10BFD5



From nusbj at hotmail.com  Sat Sep 11 16:10:50 2004
From: nusbj at hotmail.com (Zhen Pang)
Date: Sat, 11 Sep 2004 22:10:50 +0800
Subject: [R] help in building a function
Message-ID: <BAY22-F24x28eMept8g000453a1@hotmail.com>




>From: assuncao.senra at portugalmail.com
>To: R help <r-help at stat.math.ethz.ch>
>Subject: [R] help in building a function
>Date: Sat, 11 Sep 2004 14:22:13 +0100
>
>hello,
>i'm new in writting functions in R. I read the R-help manuals but still
>couldn't get it right.
>The problem is:
>I have data on 16 categorical variables for 335 individuals. the data are
>lines for individuals and columns for variables.
>I want to calculate the correlation between two variables using a formula
>given by Agresti for ordinal categorical variables.
>I have to calcule the value for each pair of variables and save the result 
>in
>a vector...
>I wrote the following code
>
>X<-as.matrix(X)
>
>n=335
>for (i in 1:15){
>for (j in i+1:16){

note i+1:16 stands for i+(1:16)

>Tab<-table(X[,i],X[,j])
>u<-1:nrow(Tab)
>v<-1:ncol(Tab)
>
>ml<-margin.table(Tab,1)
>mc<-margin.table(Tab,2)
>
>r1<-u*Tab
>r2<-sum(v*t(r1))

t is useless here, also you did not use t at other place

>
>r3<-sum(u*ml)*(sum(v*mc)/n
>
>r5<-sum((v^2)*mc)-((sum(v*mc))^2)/n
>
>r4<-sum((u^2)*ml)-((sum(u*ml))^2)/n
>r<-(r2-r3)/sqrt(r4*r5)
>
>r
>m=(n-1)*r^2
>}
>}
>The correlation is r.I have a result, but there is a warning regarding r5
>about sintax.
>Plus, it doesn´t perform the loops and I don't know how to save the results 
>in
>a vector.
>thanks for any help
>
>Assunção
>
>
>
>__________________________________________________________
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Sat Sep 11 17:18:09 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 11 Sep 2004 17:18:09 +0200
Subject: [R] help in building a function
In-Reply-To: <BAY22-F24x28eMept8g000453a1@hotmail.com>
References: <BAY22-F24x28eMept8g000453a1@hotmail.com>
Message-ID: <41431731.2030401@statistik.uni-dortmund.de>

Zhen Pang wrote:

> 
> 
> 
>> From: assuncao.senra at portugalmail.com
>> To: R help <r-help at stat.math.ethz.ch>
>> Subject: [R] help in building a function
>> Date: Sat, 11 Sep 2004 14:22:13 +0100
>>
>> hello,
>> i'm new in writting functions in R. I read the R-help manuals but still
>> couldn't get it right.
>> The problem is:
>> I have data on 16 categorical variables for 335 individuals. the data are
>> lines for individuals and columns for variables.
>> I want to calculate the correlation between two variables using a formula
>> given by Agresti for ordinal categorical variables.
>> I have to calcule the value for each pair of variables and save the 
>> result in
>> a vector...
>> I wrote the following code
>>
>> X<-as.matrix(X)
>>
>> n=335
>> for (i in 1:15){
>> for (j in i+1:16){
> 
> 
> note i+1:16 stands for i+(1:16)
> 
>> Tab<-table(X[,i],X[,j])
>> u<-1:nrow(Tab)
>> v<-1:ncol(Tab)
>>
>> ml<-margin.table(Tab,1)
>> mc<-margin.table(Tab,2)
>>
>> r1<-u*Tab
>> r2<-sum(v*t(r1))
> 
> 
> t is useless here, also you did not use t at other place
> 
>>
>> r3<-sum(u*ml)*(sum(v*mc)/n
           ^    ^ ^   ^    ^ = 5, but 5%%2 ....
The syntax error is above: Please count the parentheses!

Please try to debug yourself. R has the tools to make it pretty easy!
As a first step, execute your function line by line, for example ... (as 
you always should do during development).

Uwe Ligges


>> r5<-sum((v^2)*mc)-((sum(v*mc))^2)/n
>>
>> r4<-sum((u^2)*ml)-((sum(u*ml))^2)/n
>> r<-(r2-r3)/sqrt(r4*r5)
>>
>> r
>> m=(n-1)*r^2
>> }
>> }
>> The correlation is r.I have a result, but there is a warning regarding r5
>> about sintax.
>> Plus, it doesn??t perform the loops and I don't know how to save the 
>> results in
>> a vector.
>> thanks for any help
>>
>> Assun????o
>>
>>
>>
>> __________________________________________________________
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From h.wickham at gmail.com  Sun Sep 12 00:18:03 2004
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 11 Sep 2004 17:18:03 -0500
Subject: [R] Confused about loading other packages from a package
In-Reply-To: <Pine.LNX.4.44.0409092009030.3322-100000@gannet.stats>
References: <f8e6ff0504090912012ac21504@mail.gmail.com>
	<Pine.LNX.4.44.0409092009030.3322-100000@gannet.stats>
Message-ID: <f8e6ff050409111518dece400@mail.gmail.com>

> Roger's other one is the best one: use pre-2.0.0 and have
> Depends: marrayClasses in your DESCRIPTION file.
> 
> Having require(marrayClasses) in install.R in your package may work,
> although you may need it in R_PROFILE.R as well.


Adding require(marrayClasses) to install.R stops the error appearing
when loading the package, but now I get the error when installing the
package.  If I add it to R_PROFILE.R as well, the package won't
install with the following error:

...
** save image
Error: syntax error
Execution halted
ERROR: execution of package source for 'maVis' failed

Any more ideas?

Thanks,

Hadley



From flatman at swing.be  Sun Sep 12 11:45:11 2004
From: flatman at swing.be (Flatman)
Date: Sun, 12 Sep 2004 11:45:11 +0200
Subject: [R] fBasics
Message-ID: <7097605C-04A0-11D9-A845-000D932DCBE4@swing.be>

hello !

I'm trying to follow some examples in fBasics ...

the routine needs a 'fields' function but doesn't find it :
here's the code :

library(fBasics)
library(fSeries)

symbol="AOLA"

"ymd2cymd" <- function(x) {
          # Transfor Date:
          output <- is.character(x)
          x <- as.integer(as.character(x))
          x <- (19+cumsum(1-sign(c(1,diff(x))))/2)*1000000 + x
          if(output) x <- as.character(x)
          # Return result:
  x }


file=paste(symbol,".csv",sep="")
query=paste("s=",symbol,"&d=7&e=22&f=2004&g=d&a=7&b=8&c=2000",sep="")
STOCK =  
yahooImport(save=TRUE,file=file,source="http://ichart.yahoo.com/ 
table.csv?",query=query)
FULLTABLE <- matrix  
(data=scan(file=file,what="",skip=1,sep=","),byrow=T,ncol=7)

PRIJZEN <- c(as.real(FULLTABLE[,2]))

namesFULLTABLE <- fields(scan(file=file,n=1,what="",sep="\n"))

                                          ^^^^^ <- here happens the  
error !

FULLTABLE[,1] <-  
ymd2cymd(rev(dates(FULLTABLE[,1],format="d-mon- 
y",out.format="ymd",century=2000)))
FULLTABLE <- data.frame(FULLTABLE)
names(FULLTABLE) <- namesFULLTABLE
for( i in 2:length(namesFULLTABLE) ) FULLTABLE[,i] <- rev(FULLTABLE[,i])
write.table(FULLTABLE,file=file, dinnames.write="colnames")


can someone help ?
thanks in advance



From christoph.lehmann at gmx.ch  Sun Sep 12 14:12:37 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Sun, 12 Sep 2004 14:12:37 +0200
Subject: [R] Variable Importance in pls: R or B? (and in glpls?)
Message-ID: <41443D35.8090606@gmx.ch>

Dear R-users, dear Ron

I use pls from the pls.pcr package for classification. Since I need to 
know which variables are most influential onto the classification 
performance, what criteria shall I look at:

a) B, the array of regression coefficients for a certain model (means a 
certain number of latent variables) (and: squared or absolute values?)

OR

b) the weight matrix RR (or R in the De Jong publication; in Ding & 
Gentleman this is the P Matrix and called 'loadings')? (and again: 
squared or absolute values?)



and what about glpls (glpls1a) ?
shall I look at the 'coefficients' (regression coefficients)?

Thanks for clarification

Christoph



From laura at env.leeds.ac.uk  Sun Sep 12 17:10:04 2004
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Sun, 12 Sep 2004 16:10:04 +0100 (BST)
Subject: [R] boxplot() from list
Message-ID: <Pine.LNX.4.44.0409121601440.7614-100000@gw.env.leeds.ac.uk>

I have a list containing 48 objects (each with 30 rows and 4 columns, all
numeric), and wish to produce 4 boxplot series (with 48 plots in each) ,
one for each column of each object.

Basically I want a boxplot from boxplot(mylist[[]][,i])

for i in 1:4. It seems that I can create a boxplot of length 48 from the
entire list, but I don't seem able to subscript to return 4 boxplots from
the list - I have also tried to create 4 new lists (one for each column of
each object) by using variations on the following, but none seems to work:

newlist<-oldlist[,1]
newlist<-oldlist[[]][,1]
newlist<-oldlist[[]][,$colone]

can anyone please offer some insight??

Thanks in advance,

Laura Quinn
Institute of Atmospheric Science
School of Earth and Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk



From MSchwartz at MedAnalytics.com  Sun Sep 12 18:31:59 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Sun, 12 Sep 2004 11:31:59 -0500
Subject: [R] boxplot() from list
In-Reply-To: <Pine.LNX.4.44.0409121601440.7614-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0409121601440.7614-100000@gw.env.leeds.ac.uk>
Message-ID: <1095006719.21973.21.camel@localhost.localdomain>

On Sun, 2004-09-12 at 10:10, Laura Quinn wrote:
> I have a list containing 48 objects (each with 30 rows and 4 columns, all
> numeric), and wish to produce 4 boxplot series (with 48 plots in each) ,
> one for each column of each object.
> 
> Basically I want a boxplot from boxplot(mylist[[]][,i])
> 
> for i in 1:4. It seems that I can create a boxplot of length 48 from the
> entire list, but I don't seem able to subscript to return 4 boxplots from
> the list - I have also tried to create 4 new lists (one for each column of
> each object) by using variations on the following, but none seems to work:
> 
> newlist<-oldlist[,1]
> newlist<-oldlist[[]][,1]
> newlist<-oldlist[[]][,$colone]
> 
> can anyone please offer some insight??
> 
> Thanks in advance,


For each individual boxplot, you could do something like:

boxplot(data.frame(sapply(mylist, function(x) x[, 1])))

adjusting the index (1) for each of the four columns in your list
matrices. 

You can then adjust the additional arguments to boxplot() as you
require.

See ?sapply for more information on accessing list member elements and
returning a vector or matrix.

HTH,

Marc Schwartz



From jfox at mcmaster.ca  Sun Sep 12 18:34:06 2004
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 12 Sep 2004 12:34:06 -0400
Subject: [R] boxplot() from list
In-Reply-To: <Pine.LNX.4.44.0409121601440.7614-100000@gw.env.leeds.ac.uk>
Message-ID: <20040912163406.YDKC15743.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Laura,

You don't say what kind of "objects" are in the list, but suppose that they
are matrices; here's a scaled-down example using 3 list elements:

M1 <- matrix(rnorm(30*4), 48, 4)
M2 <- matrix(rnorm(30*4), 48, 4)
M3 <- matrix(rnorm(30*4), 48, 4)
L <- list(M1=M1, M2=M2, M3=M3)

par(mfrow=c(3, 4))
lapply(L, function(x) apply(x, 2, boxplot))

I hope that this helps,
 John 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Laura Quinn
> Sent: Sunday, September 12, 2004 10:10 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] boxplot() from list
> 
> I have a list containing 48 objects (each with 30 rows and 4 
> columns, all numeric), and wish to produce 4 boxplot series 
> (with 48 plots in each) , one for each column of each object.
> 
> Basically I want a boxplot from boxplot(mylist[[]][,i])
> 
> for i in 1:4. It seems that I can create a boxplot of length 
> 48 from the entire list, but I don't seem able to subscript 
> to return 4 boxplots from the list - I have also tried to 
> create 4 new lists (one for each column of each object) by 
> using variations on the following, but none seems to work:
> 
> newlist<-oldlist[,1]
> newlist<-oldlist[[]][,1]
> newlist<-oldlist[[]][,$colone]
> 
> can anyone please offer some insight??
> 
> Thanks in advance,
> 
> Laura Quinn
> Institute of Atmospheric Science
> School of Earth and Environment
> University of Leeds
> Leeds
> LS2 9JT



From ripley at stats.ox.ac.uk  Sun Sep 12 18:42:05 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 12 Sep 2004 17:42:05 +0100 (BST)
Subject: [R] boxplot() from list
In-Reply-To: <1095006719.21973.21.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.44.0409121737350.18439-100000@gannet.stats>

On Sun, 12 Sep 2004, Marc Schwartz wrote:

> On Sun, 2004-09-12 at 10:10, Laura Quinn wrote:
> > I have a list containing 48 objects (each with 30 rows and 4 columns, all
> > numeric), and wish to produce 4 boxplot series (with 48 plots in each) ,
> > one for each column of each object.
> > 
> > Basically I want a boxplot from boxplot(mylist[[]][,i])
> > 
> > for i in 1:4. It seems that I can create a boxplot of length 48 from the
> > entire list, but I don't seem able to subscript to return 4 boxplots from
> > the list - I have also tried to create 4 new lists (one for each column of
> > each object) by using variations on the following, but none seems to work:
> > 
> > newlist<-oldlist[,1]
> > newlist<-oldlist[[]][,1]
> > newlist<-oldlist[[]][,$colone]
> > 
> > can anyone please offer some insight??
> > 
> > Thanks in advance,
> 
> 
> For each individual boxplot, you could do something like:
> 
> boxplot(data.frame(sapply(mylist, function(x) x[, 1])))
> 
> adjusting the index (1) for each of the four columns in your list
> matrices. 
> 
> You can then adjust the additional arguments to boxplot() as you
> require.
> 
> See ?sapply for more information on accessing list member elements and
> returning a vector or matrix.

I think that is overly complex, as boxplot accepts a list.  I had tested
(but decided not to send)

mylist <- vector("list", 48)
for(i in 1:48) mylist[[i]] <- matrix(rnorm(30*4), 30) 

for (J in 1:4) boxplot(lapply(mylist, function(x, j) x[, j], j = J))


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at MedAnalytics.com  Sun Sep 12 19:01:18 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Sun, 12 Sep 2004 12:01:18 -0500
Subject: [R] boxplot() from list
In-Reply-To: <Pine.LNX.4.44.0409121737350.18439-100000@gannet.stats>
References: <Pine.LNX.4.44.0409121737350.18439-100000@gannet.stats>
Message-ID: <1095008478.21973.36.camel@localhost.localdomain>

On Sun, 2004-09-12 at 11:42, Prof Brian Ripley wrote:
> On Sun, 12 Sep 2004, Marc Schwartz wrote:
> 
> > On Sun, 2004-09-12 at 10:10, Laura Quinn wrote:
> > > I have a list containing 48 objects (each with 30 rows and 4 columns, all
> > > numeric), and wish to produce 4 boxplot series (with 48 plots in each) ,
> > > one for each column of each object.
> > > 
> > > Basically I want a boxplot from boxplot(mylist[[]][,i])
> > > 
> > > for i in 1:4. It seems that I can create a boxplot of length 48 from the
> > > entire list, but I don't seem able to subscript to return 4 boxplots from
> > > the list - I have also tried to create 4 new lists (one for each column of
> > > each object) by using variations on the following, but none seems to work:
> > > 
> > > newlist<-oldlist[,1]
> > > newlist<-oldlist[[]][,1]
> > > newlist<-oldlist[[]][,$colone]
> > > 
> > > can anyone please offer some insight??
> > > 
> > > Thanks in advance,
> > 
> > 
> > For each individual boxplot, you could do something like:
> > 
> > boxplot(data.frame(sapply(mylist, function(x) x[, 1])))
> > 
> > adjusting the index (1) for each of the four columns in your list
> > matrices. 
> > 
> > You can then adjust the additional arguments to boxplot() as you
> > require.
> > 
> > See ?sapply for more information on accessing list member elements and
> > returning a vector or matrix.
> 
> I think that is overly complex, as boxplot accepts a list.  I had tested
> (but decided not to send)
> 
> mylist <- vector("list", 48)
> for(i in 1:48) mylist[[i]] <- matrix(rnorm(30*4), 30) 
> 
> for (J in 1:4) boxplot(lapply(mylist, function(x, j) x[, j], j = J))


Fair enough. I did not want to presume that the remaining arguments to
boxplot might be the same for each plot. Though one could also put those
into an appropriate structure and still do the loop.

Also, if using the display, one would probably want to set par(ask =
TRUE), lest the four plots flash by in rapid sequence.

Marc



From tpapp at Princeton.EDU  Sun Sep 12 19:50:21 2004
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Sun, 12 Sep 2004 13:50:21 -0400
Subject: [R] can't get the quartz window to the background
Message-ID: <20040912175021.GA822@tpapp>

Dear List,

I have switched from Linux to OS X, and I find the R interface there
really nice.  I am using Emacs+ESS, and the quartz device.

My only problem is that

1. I can't move the quartz window, whenever I go above it I see a
   spinning rainbow circle (AFAIK that means "I am busy" or "can't
   touch me" in OS X)

2. Once something gets in front of it, I cannot raise it any more.

3. I don't see it when I cycle the windows with Alt-Tab

I am sure that I am missing something, read the manual and searched
the archives, but found no solution to this.  That might be because I
am really new to OS X.

Thanks,

Tamas



From tpapp at Princeton.EDU  Sun Sep 12 20:03:28 2004
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Sun, 12 Sep 2004 14:03:28 -0400
Subject: [R] can't get the quartz window to the foreground (was:
	background)
In-Reply-To: <20040912175021.GA822@tpapp>
References: <20040912175021.GA822@tpapp>
Message-ID: <20040912180328.GA847@tpapp>

On Sun, Sep 12, 2004 at 01:50:21PM -0400, Tamas K Papp wrote:
> 1. I can't move the quartz window, whenever I go above it I see a
>    spinning rainbow circle (AFAIK that means "I am busy" or "can't
>    touch me" in OS X)
> 
> 2. Once something gets in front of it, I cannot raise it any more.
> 
> 3. I don't see it when I cycle the windows with Alt-Tab

Sorry, misleading subject.  My problem is that I can't get it to the
_foreground_.

Tamas



From ggrothendieck at myway.com  Sun Sep 12 20:04:22 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 12 Sep 2004 18:04:22 +0000 (UTC)
Subject: [R] Cancor
References: <000b01c497b1$bb755150$0300a8c0@JJ.cable.amis.net>
Message-ID: <loom.20040912T192559-238@post.gmane.org>

Irena Komprej <irena.komprej <at> telemach.net> writes:

> 
> I am strugling with cancor procedure in R. I cannot figure out the
> meaning of xcoef and of yxcoef.
> Are these:
> 1. standardized coefficients
> 2. structural coefficients
> 3. something else?
> 


Look at the examples at the bottom of ?cancor from which its evident
xcoef is such that x %*% cxy$xcoef are the canonical variables.  (More
at the end of this post.)


> I have tried to simulate canonical correlation analysis by checking the
> eigenstructure of the expression:
> 
> Sigma_xx %*% Sigma_xy %*% Sigma_yy %*% t(Sigma_xy).
> 
> The resulting eigenvalues were the same as the squared values of
> cancor$cor. I have normalized the resulting eigenvectors, the a's with
> 
> sqrt(a'%*%Sigma_xx%*%t(a)), and similarly the b's with
> sqrt(b'%*%Sigma_yy%*%t(b)).
> 
> The results differed considerably from xcoef and ycoef of the cancor.

Run the example in the help page to get some data and some
output:

   set.seed(1)
   example(cancor)

# Also, define isqrt as the inverse square root of a postive def matrix

   isqrt <- function(x) {
      e <- eigen(x)
      stopifnot( all(e$values > 0) )
      e$vectors %*% diag(1/sqrt(e$values)) %*% solve(e$vectors)
    }

# we can reconstruct the canonical correlations and xcoef 
# in the way you presumably intended like this:

   z <- svd(cov(x,y) %*% solve(var(y), cov(y,x)) %*% solve(var(x)))
   sqrt(z$d)  # canonical correlations
   isqrt((nrow(x)-1)*var(x)) %*% z$u    # xcoef 

Another thing you can do is to type

   cancor

at the R prompt to view its source and see how it works using
the QR decomposition.



From hack at ffos.hr  Sun Sep 12 20:28:24 2004
From: hack at ffos.hr (Branimir K. Hackenberger)
Date: Sun, 12 Sep 2004 20:28:24 +0200
Subject: [R] calculating error
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA/KN/oP+2mk+FvuiZg1iX78KAAAAQAAAALZqbJXmcn0GiLquV3njdAAEAAAAA@knjiga.pedos.hr>


Could anybody explain this results?

>sin(2*pi)           
-2.449213e-16         #should be zero


>(10^16)*sin(log2(4)*pi)
-2.449213             #should be zero too


and explain what to do to correct this events?

Thanks!!!


Branimir K. Hackenberger



From deepayan at stat.wisc.edu  Sun Sep 12 20:42:48 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun, 12 Sep 2004 13:42:48 -0500
Subject: [R] calculating error
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA/KN/oP+2mk+FvuiZg1iX78KAAAAQAAAALZqbJXmcn0GiLquV3njdAAEAAAAA@knjiga.pedos.hr>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA/KN/oP+2mk+FvuiZg1iX78KAAAAQAAAALZqbJXmcn0GiLquV3njdAAEAAAAA@knjiga.pedos.hr>
Message-ID: <200409121342.48736.deepayan@stat.wisc.edu>

On Sunday 12 September 2004 13:28, Branimir K. Hackenberger wrote:
> Could anybody explain this results?
>
> >sin(2*pi)
>
> -2.449213e-16         #should be zero

It is, in the sense that 

> all.equal(sin(2*pi), 0)
[1] TRUE


> >(10^16)*sin(log2(4)*pi)
>
> -2.449213             #should be zero too
>
>
> and explain what to do to correct this events?

For starters, you need to invent and then use an infinite precision 
computer where the variable 'pi' is really the ratio between the 
circumference and radius of a circle, and not just a finite precision 
approximation of it. Good luck trying :-)

Deepayan



From ggrothendieck at myway.com  Sun Sep 12 21:48:00 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 12 Sep 2004 19:48:00 +0000 (UTC)
Subject: [R] calculating error
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAA/KN/oP+2mk+FvuiZg1iX78KAAAAQAAAALZqbJXmcn0GiLquV3njdAAEAAAAA@knjiga.pedos.hr>
Message-ID: <loom.20040912T211743-133@post.gmane.org>

Branimir K. Hackenberger <hack <at> ffos.hr> writes:

: 
: Could anybody explain this results?
: 
: >sin(2*pi)           
: -2.449213e-16         #should be zero
: 
: 
: >(10^16)*sin(log2(4)*pi)
: -2.449213             #should be zero too
: 
: 
: and explain what to do to correct this events?

Someone else has already explained why this is.

In terms of what you can do, in general, you have to keep
finite precision in mind when performing computer calculations
using floating point representations.

Sometimes there are tricks.  If you know that the result or
an intermediate result will be integer then if the error 
is sufficiently small you can round it at that point:

R> round(sin(2*pi))
[1] 0

R> (10^16)*round(sin(log2(4)*pi))
[1] 0

If exact arithmetic is required you may need to use a symbolic
mathematics package capable of exact arithmetic.  There are both 
free, e.g. yacas, and commercial ones, e.g. mathematica, maple.  
For example, in yacas:

In> Sin(2*Pi);
Out> 0;
In> (10^16)*Sin(IntLog(4,2)*Pi)
Out> 0;



From spencer.graves at pdf.com  Sun Sep 12 21:55:59 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 12 Sep 2004 12:55:59 -0700
Subject: [R] SAS to R migration questions
In-Reply-To: <20040911133920.GA29444@mwilson.umlcoop.net>
References: <20040911133920.GA29444@mwilson.umlcoop.net>
Message-ID: <4144A9CF.5000601@pdf.com>

      I copied your data into Excel and saved it as *.txt.  From within 
R, the following commands produced for me the result cited in your email 
below: 

salesData <- read.table("R-qn.txt", header=TRUE,
                        sep="\t", as.is=TRUE)
sapply(salesData, class)# check class of columns of salesData
reversal <- regexpr("\\(", salesData$salepx)
rev <- which(reversal>0)
salesData[-c(rev, rev-1),]

      If "R-qn.txt" contained gigabytes, R might die in "read.table".  
For that, you will need to process the data base in smaller pieces.  The 
"R Data Import/Export" manual [available, e.g., via help.start() from 
within R] discusses various ways of interacting direction with 
relational databases, etc. 

      hope this helps.  spencer graves

Matthew Wilson wrote:

>Hi,
>
>
>I'd like to get away from SAS, but I don't really know R well enough at
>this point to know if it would be good for this project.  I tried to
>describe the essence of the project below without getting bogged down in
>details.
>
>It starts when I receive a data flat file.  There's lots of columns, but
>the relevant ones are:
>
>    custid  (customer ID number)
>    saledt  (date of sale)
>    salepx  (sale price)
>
>
>Step 1:
>
>I read in this data into a SAS dataset.  Some of these flat files hold
>several gigabytes of data.  SAS allows indexes to be created on columns
>which really speeds up queries. 
>
>I read the R import/export doc and it suggested using databases for
>really big datasets.  I figured I'd probably use perl or python to read
>the file and convert it to either an R .tab file or to load the data
>into a SQL database for the big files (Postgres or MySQL, since I'm
>trying to go 100% open source with this).
>
>
>
>Step 2:
>
>In the data, I'll usually find one row per sale, but occasionally, a
>sale will be entered incorrectly at first, then later reversed, then a
>third line will show the correct sale data:
>
>    custid      saledt      salepx
>    111         8/1/2004    $75
>    111         9/1/2004    $50
>    112         10/1/2004   $30
>    112         10/1/2004   ($30)
>    112         10/1/2004   $20
>
>The fourth line reverses the third line by showing a negative charge for
>the same customer ID and sale date, and the last line is the correct
>line.  I want to compress all those adjustments and reversals lines out
>of the data, so the outgoing data would look like this:
>
>    custid      saledt      salepx
>    111         8/1/2004    $75
>    111         9/1/2004    $50
>    112         10/1/2004   $20
>
>In SAS, I use a proc summary step in SAS to accomplish this:
>
>    proc summary data=d1;
>        class custid saledt;
>        var salepx;
>        output out=d2 sum=;
>    run;
>
>This is where I need help:  how to do this step in R?
>
>
>Step 3:
>
>I print a list of number of sales per customer ID, ranking the customer
>IDs from most to least.  I use a SAS proc freq step for this:
>
>    proc freq data=d2 order=freq;
>        tables custid;
>    run;
>
>and the output would look like this:
>
>    custid      freq
>    111         2
>    112         1
>
>
>Again, I have no idea how to do step 3 in R.  
>
>
>Thanks in advance!  All help is welcome.  Is this kind of work what R is
>good at?
>
>
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From nair at uhura.sdsc.edu  Sun Sep 12 22:17:01 2004
From: nair at uhura.sdsc.edu (Murli Nair)
Date: Sun, 12 Sep 2004 13:17:01 -0700
Subject: [R] mahalanobis distance
Message-ID: <4144AEBD.4050605@imap.sdsc.edu>

Is there a function that calculate the mahalanobis distance in R .
The dist function calculates "euclidean"', '"maximum"', '"manhattan"', 
'"canberra"',
'"binary"' or '"minkowski"'.
Thanks ../Murli



From andy_liaw at merck.com  Sun Sep 12 22:29:36 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 12 Sep 2004 16:29:36 -0400
Subject: [R] mahalanobis distance
Message-ID: <3A822319EB35174CA3714066D590DCD504AF837C@usrymx25.merck.com>

See (surprising enough) ?mahalanobis...

Andy

> From: Murli Nair
> 
> Is there a function that calculate the mahalanobis distance in R .
> The dist function calculates "euclidean"', '"maximum"', 
> '"manhattan"', 
> '"canberra"',
> '"binary"' or '"minkowski"'.
> Thanks ../Murli
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From jfox at mcmaster.ca  Sun Sep 12 22:33:21 2004
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 12 Sep 2004 16:33:21 -0400
Subject: [R] mahalanobis distance
In-Reply-To: <4144AEBD.4050605@imap.sdsc.edu>
Message-ID: <20040912203322.ULJT14082.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear Murli,

Try ?mahalanobis, which, by the way, is turned up by
help.search("mahalanobis").

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Murli Nair
> Sent: Sunday, September 12, 2004 3:17 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] mahalanobis distance
> 
> Is there a function that calculate the mahalanobis distance in R .
> The dist function calculates "euclidean"', '"maximum"', 
> '"manhattan"', '"canberra"', '"binary"' or '"minkowski"'.
> Thanks ../Murli



From mentus at gmx.de  Sun Sep 12 23:06:39 2004
From: mentus at gmx.de (Fernando Henrique Ferraz P. da Rosa)
Date: Sun, 12 Sep 2004 18:06:39 -0300
Subject: [R] SAS to R migration questions
In-Reply-To: <20040911133920.GA29444@mwilson.umlcoop.net>
References: <20040911133920.GA29444@mwilson.umlcoop.net>
Message-ID: <20040912210638.GA18678@ime.usp.br>

Matthew Wilson writes:
> (...)
> Step 3:
> 
> I print a list of number of sales per customer ID, ranking the customer
> IDs from most to least.  I use a SAS proc freq step for this:
> 
>     proc freq data=d2 order=freq;
>         tables custid;
>     run;
> 
> and the output would look like this:
> 
>     custid      freq
>     111         2
>     112         1
> 
> 
> Again, I have no idea how to do step 3 in R.  

        Provided that you are going to work with this data stored in a
SQL database, it'll probably be more efficient to do this sort of
manipulation directly in SQL. Anyways, the following lines of code in R
will do what you described:

cust <- c(111,111,112)
cc <- data.frame(t(sapply(unique(cust),function(level,vec) {
c(custid=level,freq=sum(vec==level)) },cust))) 
cc[order(cc$freq,decreasing=T),]


Cheers,

--
Fernando Henrique Ferraz P. da Rosa
http://www.ime.usp.br/~feferraz



From mentus at gmx.de  Sun Sep 12 23:24:58 2004
From: mentus at gmx.de (Fernando Henrique Ferraz P. da Rosa)
Date: Sun, 12 Sep 2004 18:24:58 -0300
Subject: [R] SAS to R migration questions
In-Reply-To: <20040912210638.GA18678@ime.usp.br>
References: <20040911133920.GA29444@mwilson.umlcoop.net>
	<20040912210638.GA18678@ime.usp.br>
Message-ID: <20040912212458.GA18977@ime.usp.br>

Fernando Henrique Ferraz P. da Rosa writes:
> cust <- c(111,111,112)
> cc <- data.frame(t(sapply(unique(cust),function(level,vec) {
> c(custid=level,freq=sum(vec==level)) },cust))) 
> cc[order(cc$freq,decreasing=T),]

        An even simpler solution:
 
        cc <- data.frame(table(cust))
        cc[order(cc$Freq,decreasing=T),]


--
Fernando Henrique Ferraz P. da Rosa
http://www.ime.usp.br/~feferraz



From vantini at mate.polimi.it  Mon Sep 13 00:13:23 2004
From: vantini at mate.polimi.it (Simone Vantini)
Date: Mon, 13 Sep 2004 00:13:23 +0200 (CEST)
Subject: [R] How to personalize principal components analysis
Message-ID: <62169.81.208.60.192.1095027203.squirrel@webmail.mate.polimi.it>

Hallo!
Does anybody know if it is possible to choose the function to be maximazed
in the principal components analysis?Thanks
Simone Vantini



From james.holtman at convergys.com  Mon Sep 13 00:39:48 2004
From: james.holtman at convergys.com (james.holtman@convergys.com)
Date: Sun, 12 Sep 2004 18:39:48 -0400
Subject: [R] calculating error
Message-ID: <OF24DDAFCB.B849973B-ON85256F0D.007C3630@nd.convergys.com>





This is in the FAQs.  It has to do with representation of floating point
numbers.  You can not represent 'pi' exactlly in the 53 bits of precision
in floating point.  If you notice, 2^-53 is 1.1e-16 which indicates the
'roundoff' is in the least significant bit of the precision; this is to be
expected with floating point numbers.
__________________________________________________________
James Holtman        "What is the problem you are trying to solve?"
Executive Technical Consultant  --  Office of Technology, Convergys
james.holtman at convergys.com
+1 (513) 723-2929


                                                                                                                                           
                      "Branimir K.                                                                                                         
                      Hackenberger"                To:       <r-help at stat.math.ethz.ch>                                                    
                      <hack at ffos.hr>               cc:                                                                                     
                      Sent by:                     Subject:  [R] calculating error                                                         
                      r-help-bounces at stat.m                                                                                                
                      ath.ethz.ch                                                                                                          
                                                                                                                                           
                                                                                                                                           
                      09/12/2004 14:28                                                                                                     
                                                                                                                                           
                                                                                                                                           





Could anybody explain this results?

>sin(2*pi)
-2.449213e-16         #should be zero


>(10^16)*sin(log2(4)*pi)
-2.449213             #should be zero too


and explain what to do to correct this events?

Thanks!!!


Branimir K. Hackenberger

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From umalvarez at fata.unam.mx  Mon Sep 13 00:59:58 2004
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Sun, 12 Sep 2004 17:59:58 -0500 (CDT)
Subject: [R] can't get the quartz window to the background
In-Reply-To: <20040912175021.GA822@tpapp>
Message-ID: <Pine.LNX.4.44.0409121754440.13312-100000@athena.fata.unam.mx>

Hello!

The Quartz device only works well when is launched from  R.app. You may 
launch an X Dev (the default when not in R.app) or use R.app. However if 
neither one is a choice, you may use dev.copy() or dev.copy2eps() to save 
your graph.

Regards.


On Sun, 12 Sep 2004, Tamas K Papp wrote:

> Dear List,
> 
> I have switched from Linux to OS X, and I find the R interface there
> really nice.  I am using Emacs+ESS, and the quartz device.
> 
> My only problem is that
> 
> 1. I can't move the quartz window, whenever I go above it I see a
>    spinning rainbow circle (AFAIK that means "I am busy" or "can't
>    touch me" in OS X)
> 
> 2. Once something gets in front of it, I cannot raise it any more.
> 
> 3. I don't see it when I cycle the windows with Alt-Tab
> 
> I am sure that I am missing something, read the manual and searched
> the archives, but found no solution to this.  That might be because I
> am really new to OS X.
> 
> Thanks,
> 
> Tamas
> 



-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
-u-m-a-l-v-a-r-e-z- at -f-a-t-a- dot -u-n-a-m- dot -m-x-



From horebeek at cimat.mx  Mon Sep 13 01:20:29 2004
From: horebeek at cimat.mx (J. Van Horebeek)
Date: Sun, 12 Sep 2004 18:20:29 -0500 (CDT)
Subject: [R] Controling a tcl/tk slider
Message-ID: <Pine.LNX.4.58.0409121754430.708@leonidas.cimat.mx>


Hi,

Is there any command  in R that drags a tcl/tk slider to a 
particular position (value)?

  thanks in advance,

     Johan Van Horebeek



From damian.betebenner at bc.edu  Mon Sep 13 01:44:30 2004
From: damian.betebenner at bc.edu (Damian Betebenner)
Date: Sun, 12 Sep 2004 19:44:30 -0400
Subject: [R] Discrepency between R and MlwiN
Message-ID: <web-1436022@be3.bc.edu>

When playing around fitting unconditional growth models using R and MlwiN today, I produced two different sets of estimates that I can't reconcile and wondered if anyone here has an idea:

The data is two-level repeated measures data with measures nested within child. There are two measures per child. I've fit an unconditional growth model as in Singer and Willet (2003) that allows for variable intercepts
and slopes.

The R code for the analysis is:

model.uncgrowth.2lev <- lme(math ~ grade, mathdata, random=~grade|studentid)

The fixed effects estimates for the intercept and slope are the same between MlwiN and R. It's the random
effects estimates that differ. In particular, the residual error variance is ZERO using MlwiN and significantly
non-zero using R. It appears that MlwiN perfectly fits lines to each of the two data points supplied for each
student and R does not. The two program yield the same results when the covariate grade is treated as a fixed effect. Also, I used REML on both R and MlwiN.

Anyone have any idea how to explain this descrpency?


Damian Betebenner
Boston College
Chestnut Hill, MA 02467



From jfox at mcmaster.ca  Mon Sep 13 03:03:50 2004
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 12 Sep 2004 21:03:50 -0400
Subject: [R] Controling a tcl/tk slider
In-Reply-To: <Pine.LNX.4.58.0409121754430.708@leonidas.cimat.mx>
Message-ID: <20040913010351.JUAN29920.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Johan,

If I understand you correctly, you want to change the position of the slider
without directly moving the "thumb." If so, you can simply change the value
of the variable associated with the slider; for example:

    top <- tktoplevel()
    Var <- tclVar("5")
    slider <- tkscale(top, from=1, to=10, showvalue=TRUE,
      variable=Var, resolution=1, orient="horizontal")
    tkgrid(slider)

    tclvalue(Var) <- "1"

I hope that this helps,
 John 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of J. Van Horebeek
> Sent: Sunday, September 12, 2004 6:20 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Controling a tcl/tk slider
> 
> 
> Hi,
> 
> Is there any command  in R that drags a tcl/tk slider to a 
> particular position (value)?
> 
>   thanks in advance,
> 
>      Johan Van Horebeek



From cjgb at wanadoo.es  Mon Sep 13 00:17:46 2004
From: cjgb at wanadoo.es (Carlos Javier Gil Bellosta)
Date: Mon, 13 Sep 2004 00:17:46 +0200
Subject: [R] write.table performance: an alternative?
Message-ID: <4144CB0A.4090502@wanadoo.es>

Dear R's,

I have been using R lately to perform some statistical analysis and, 
based on them, simulations to be exported in flat text files to other 
programs. These text files are nowadays of about 30MB in size, but they 
could finally be of up to 300MB.

Writing these files with either write.table or write.matrix was 
desperately slow and the bottleneck of the whole process. Besides, the 
it took too much memory and sometimes I experienced heavy paging. So I 
decided to find a better way to export my R tables. Since they contained 
floating numbers only, in order to avoid the internal transformation 
into character values (both write.table and write.matrix seem to be 
doing it), compiling

//////////////////////////     Program Start  //////////////////////////

#include <stdio.h>
#include <stdlib.h>

void salidaOptimizada(int* l_fila, int* n_columnas, double* 
vector_resultados){

       int i;
       int j;

       FILE* f = fopen("datosPorPeriodo.dat", "w");

       for(i=0; i < *n_columnas; i++){
               for(j=0; j < *l_fila; j++){
                       fprintf(f, " %3f", *vector_resultados);
                       vector_resultados++;
               }
               fprintf(f, "\n");
       }

       fclose(f);

}

////////////////////// Program End ////////////////////

as a shared library and linking it to my code, and invoking it with the 
.C function would do the trick for me. The performance gains were 
enormous respect to write.table().

So I decided to look for a greater degree of generality and wrote a 
simple C function (enclosed at the end of the message) that would accept 
character, integer and floating point values. It can be tested, for 
instance, running both

/////////////// Program Start /////////////////

a1 <- rnorm(1000000)
a2 <- floor(a1)
a3 <- as.character(1:1000000)
a <- data.frame(a1, a2, a3)
Rprof()

write.table(a, "salidaNoOptimizada.dat")

Rprof(NULL)
summaryRprof()

////////////////////// Program End /////////////////

and

///////////////////// Program Start /////////////////

dyn.load("liboptio.so")
a1 <- rnorm(1000000)
a2 <- floor(a1)
a3 <- as.character(1:1000000)
a <- data.frame(a1, a2, a3)
Rprof()

borrar <- .C("escribir", as.integer(1000000), as.character("dic"), 
as.integer(3), as.double(a[,1]), as.integer(a[,2]), as.character(a[,3]))

Rprof(NULL)
rm(borrar)
summaryRprof()

//////////////////// Program End ///////////////////

to compare the performance (given that the program below is compiled as 
a shared library under the libopio.so name).

Now, my question:

Is this interesting/useful at all for anybody other then myself? Have I 
done something silly (I know too little about both C and R) and wasted 
an afternoon? Or would it be worth trying to improve the code to improve 
generality and wrapping it in some R code so as to make the function 
invocation a bit more transparent and automatic?

Sincerely,

Carlos J. Gil Bellosta

///////////////////// Program Start /////////////////

#include <stdio.h>
#include <stdlib.h>
#include <stdarg.h>

void escribir(int* n_lin, char** tipo, int* n, ...){

   int i, j;
   va_list lista;

   FILE* f = fopen("salidaPrueba", "w");
   for(i = 0; i < *n_lin; i++){
         char *pAchar = *tipo;

       va_start(lista, *n);
             for(j = 0; j < *n; j++){
                 if(*pAchar == 'd'){
               fprintf(f, " %f", *(va_arg(lista, double*) + i));
           } else

           if(*pAchar == 'i'){
               fprintf(f, " %d", *(va_arg(lista, int*) + i));
           } else
                     if(*pAchar == 'c'){
               fprintf(f, " %s", *(va_arg(lista, char**) + i));
           } else
               fprintf(f, "mierda %c", *pAchar);
                     pAchar++;                  }

       fprintf(f, "\n");
       va_end(lista);          }

   fclose(f);
}

///////////////////// Program End /////////////////



From alan.simpson at robertsresearch.com.au  Mon Sep 13 06:03:47 2004
From: alan.simpson at robertsresearch.com.au (Alan Simpson)
Date: Mon, 13 Sep 2004 14:03:47 +1000
Subject: [R] pairwise deletion of missing cases in lm
Message-ID: <BC4231C30D143F43BFD514168020196935DA04@lurch>

Does anybody know if there is some sort of "pairwise" option for handling
missing cases in lm and computing the relevant statistics?

I would be much obliged if anyone could help...

Regards

Alan Simpson
Roberts Research Group



From wanr at ucalgary.ca  Mon Sep 13 08:23:15 2004
From: wanr at ucalgary.ca (wanr@ucalgary.ca)
Date: Mon, 13 Sep 2004 00:23:15 -0600
Subject: [R] How to bootstrap Kaplan-Miere estimator with 95% envelope
Message-ID: <200409130623.i8D6NFG00916@smtp1.ucalgary.ca>

Hi all,

Given a typical right-censoring data which contains a time variable and a 
censoring indicator. How do we bootstrap samples to obtain a 95% envelope 
for the estimated cumulative hazard function?

Thanks in advance.

Rui



From ripley at stats.ox.ac.uk  Mon Sep 13 08:23:56 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Sep 2004 07:23:56 +0100 (BST)
Subject: [R] How to personalize principal components analysis
In-Reply-To: <62169.81.208.60.192.1095027203.squirrel@webmail.mate.polimi.it>
Message-ID: <Pine.LNX.4.44.0409130720510.11324-100000@gannet.stats>

On Mon, 13 Sep 2004, Simone Vantini wrote:

> Hallo!
> Does anybody know if it is possible to choose the function to be maximazed
> in the principal components analysis?Thanks

Principal components analysis is defined by a series of properties.  Two 
are

1) Maximize the variance of the projection onto a kD subspace

2) Minimize the sum of squares of the distances from points to their 
projections onto a kD subspace.

So the criteria are what defines PCA.  Please consult the references in 
e.g. ?princomp.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wanr at ucalgary.ca  Mon Sep 13 08:26:05 2004
From: wanr at ucalgary.ca (wanr@ucalgary.ca)
Date: Mon, 13 Sep 2004 00:26:05 -0600
Subject: [R] How to obtain a 95% envelope for the estimated cumulaitve
	hazard function via bootstrap?
Message-ID: <200409130626.i8D6Q5D22705@smtp2.ucalgary.ca>

Hi all,

Given a typical right-censoring data which contains a time variable and a 
censoring indicator. How do we bootstrap samples to obtain a 95% envelope 
for the estimated cumulative hazard function?

Rui



From ripley at stats.ox.ac.uk  Mon Sep 13 08:34:34 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Sep 2004 07:34:34 +0100 (BST)
Subject: [R] Discrepency between R and MlwiN
In-Reply-To: <web-1436022@be3.bc.edu>
Message-ID: <Pine.LNX.4.44.0409130725200.11324-100000@gannet.stats>

On Sun, 12 Sep 2004, Damian Betebenner wrote:

> When playing around fitting unconditional growth models using R and MlwiN today, I produced two different sets of estimates that I can't reconcile and wondered if anyone here has an idea:
> 
> The data is two-level repeated measures data with measures nested within child. There are two measures per child. I've fit an unconditional growth model as in Singer and Willet (2003) that allows for variable intercepts
> and slopes.
> 
> The R code for the analysis is:
> 
> model.uncgrowth.2lev <- lme(math ~ grade, mathdata, random=~grade|studentid)
> 
> The fixed effects estimates for the intercept and slope are the same
> between MlwiN and R. It's the random effects estimates that differ. In
> particular, the residual error variance is ZERO using MlwiN and
> significantly non-zero using R. It appears that MlwiN perfectly fits
> lines to each of the two data points supplied for each student and R
> does not. The two program yield the same results when the covariate
> grade is treated as a fixed effect. Also, I used REML on both R and
> MlwiN.
> 
> Anyone have any idea how to explain this descrpency?

Are there always two points per student?  If so, your model is not
identifiable (in so far as I understand what you are doing) and there is
an infinite set of parameters which give the same restricted likelihood.
Please check if the latter is the case for the two sets of results.

For each student you have a random intercept, a random slope and 
measurement error at each point.  That's 4 random variables to explain 2 
observations.

In short, you appear to have chosen a model that overfits.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rksh at soc.soton.ac.uk  Mon Sep 13 08:58:51 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Mon, 13 Sep 2004 07:58:51 +0100
Subject: [R] do.call("dim<-" , ... )
Message-ID: <a06002009bd6af532275b@[139.166.242.29]>

  OK guys

another problem.  I have a 3D array "x" with dim(x)=c(a,a,b^2)
and I want to rearrange the elements of x to make a matrix "y"
with dimensions c(a*b,a*b).  Neither a nor b is known in advance.

I want the "n-th" a*a submatrix of y to be x[,,n] (where 1 <= n <=
b^2).  Needless to say, this has gotta be vectorized!

Toy example with a=2, b=3 follows:


Given:
x <- array(1:36,c(2,2,9))


I require:
y <- matrix(as.integer(c(
           1, 2, 5, 6, 9,10,
           3, 4, 7, 8,11,12,
          13,14,17,18,21,22,
          15,16,19,20,23,24,
          25,26,29,30,33,34,
          27,28,31,32,35,36
       )),6,6)

So
identical(x[,,1] , y[1:2,1:2])
identical(x[,,2] , y[3:4,1:2])
[snip]
identical(x[,,9] , y[5:6,5:6])

all return TRUE.

OBattempts:

(i)
dim(x) <- c(4,9);x <- t(x) ; dim(x) <- c(6,6) ; y <- x

(ii)
y <- aperm(x,c(2,1,3)) ; dim(y) <- c(6,6)

Any genius out there with some ideas?


-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From wolfram at fischer-zim.ch  Mon Sep 13 09:34:15 2004
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Mon, 13 Sep 2004 09:34:15 +0200
Subject: [R] Adding ranks to a repeatedly ragged array
Message-ID: <20040913073415.GA2340@s1x.local>

How can I add an extra column containing the rank
to a ragged array indexed by more than one grouping
factors?

E.g. with the barley dataset: 
How can I to add an additional column ``rank''
containing the rank of the ``yield'' of
the different varieties in relation to the indices
``year'' and ``site'' to the barley dataframe?

I achieved to calculate the ranks with:
	rank.lists <-
	with( barley, tapply( yield, list( site=site, year=year ), rank ) )
but I do not manage to merge this result
to the original dataframe ``barley''.

Thanks!

Wolfram



From ripley at stats.ox.ac.uk  Mon Sep 13 10:10:16 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Sep 2004 09:10:16 +0100 (BST)
Subject: [R] permuting dimensions (was do.call("dim<-" , ... ))
In-Reply-To: <a06002009bd6af532275b@[139.166.242.29]>
Message-ID: <Pine.LNX.4.44.0409130901090.15189-100000@gannet.stats>

What has this to do with the original subject line?  Replacement functions
are not intended to be used directly, and certainly not in do.call.

See ?aperm, as in

xx <- x
dim(xx) <- c(2,2,3,3)
xx <- aperm(xx, c(1,3,2,4))
dim(xx) <- c(6, 6)
xx

as required.

BTW, you have a broken package `magic' on CRAN: please do us the courtesy
of fixing it so we don't continually have to look at it in tests. See

http://cran.r-project.org/src/contrib/checkSummary.html


On Mon, 13 Sep 2004, Robin Hankin wrote:

>   OK guys
> 
> another problem.  I have a 3D array "x" with dim(x)=c(a,a,b^2)
> and I want to rearrange the elements of x to make a matrix "y"
> with dimensions c(a*b,a*b).  Neither a nor b is known in advance.
> 
> I want the "n-th" a*a submatrix of y to be x[,,n] (where 1 <= n <=
> b^2).  Needless to say, this has gotta be vectorized!
> 
> Toy example with a=2, b=3 follows:
> 
> 
> Given:
> x <- array(1:36,c(2,2,9))
> 
> 
> I require:
> y <- matrix(as.integer(c(
>            1, 2, 5, 6, 9,10,
>            3, 4, 7, 8,11,12,
>           13,14,17,18,21,22,
>           15,16,19,20,23,24,
>           25,26,29,30,33,34,
>           27,28,31,32,35,36
>        )),6,6)
> 
> So
> identical(x[,,1] , y[1:2,1:2])
> identical(x[,,2] , y[3:4,1:2])
> [snip]
> identical(x[,,9] , y[5:6,5:6])
> 
> all return TRUE.
> 
> OBattempts:
> 
> (i)
> dim(x) <- c(4,9);x <- t(x) ; dim(x) <- c(6,6) ; y <- x
> 
> (ii)
> y <- aperm(x,c(2,1,3)) ; dim(y) <- c(6,6)
> 
> Any genius out there with some ideas?
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From R.Wehrens at science.ru.nl  Mon Sep 13 10:26:45 2004
From: R.Wehrens at science.ru.nl (Ron Wehrens)
Date: Mon, 13 Sep 2004 10:26:45 +0200
Subject: [R] Re: Variable Importance in pls: R or B? (and in glpls?)
In-Reply-To: <41443D35.8090606@gmx.ch>
References: <41443D35.8090606@gmx.ch>
Message-ID: <200409131026.45727.R.Wehrens@science.ru.nl>

On Sunday 12 September 2004 14:12, Christoph Lehmann wrote:
> Dear R-users, dear Ron
>
> I use pls from the pls.pcr package for classification. Since I need to
> know which variables are most influential onto the classification
> performance, what criteria shall I look at:
>
> a) B, the array of regression coefficients for a certain model (means a
> certain number of latent variables) (and: squared or absolute values?)

The regression coefficients give the most direct information on which 
variables influence the classification, although you must be careful with the 
interpretation if the variables are correlated. So it is the absolute 
magitude that is important; why would you look at the squared values?

>
> OR
>
> b) the weight matrix RR (or R in the De Jong publication; in Ding &
> Gentleman this is the P Matrix and called 'loadings')? (and again:
> squared or absolute values?)
>
The object that is returned contains X and Y loadings (which are _not_ equal 
to te RR matrix, btw); these are mainly used for interpretation. The 
regression coefficients give information on your complete model; the loadings 
on individual components of the model.

Ron

>
>
> and what about glpls (glpls1a) ?
> shall I look at the 'coefficients' (regression coefficients)?
>
> Thanks for clarification
>
> Christoph

-- 
Ron Wehrens            
Institute for Molecules and Materials, Analytical Chemistry
Radboud University	Email: R.Wehrens at science.ru.nl
Toernooiveld 1		http://www.science.ru.nl/cac
6525 ED Nijmegen	Tel: +31 24 365 2053
The Netherlands		Fax: +31 24 365 2653



From ripley at stats.ox.ac.uk  Mon Sep 13 10:24:46 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Sep 2004 09:24:46 +0100 (BST)
Subject: [R] Adding ranks to a repeatedly ragged array
In-Reply-To: <20040913073415.GA2340@s1x.local>
Message-ID: <Pine.LNX.4.44.0409130911240.15189-100000@gannet.stats>

What do you mean by `a repeatedly ragged array': you haven't defined it?

There is no dataset `barley' in vanilla R.  Which one did you mean?
There is a data frame in package lattice, but that is neither an array nor 
ragged.

If that is what you want, rank.lists will be a list matrix.  The easiest
thing to do is to find out the corresponding row numbers and assign there.

pos <- with(barley, tapply(1:120, list(site=site, year=year), na.pass))
barley[unlist(pos), "ranks"] <- unlist(rank.lists)


On Mon, 13 Sep 2004, Wolfram Fischer wrote:

> How can I add an extra column containing the rank
> to a ragged array indexed by more than one grouping
> factors?
> 
> E.g. with the barley dataset: 
> How can I to add an additional column ``rank''
> containing the rank of the ``yield'' of
> the different varieties in relation to the indices
> ``year'' and ``site'' to the barley dataframe?
> 
> I achieved to calculate the ranks with:
> 	rank.lists <-
> 	with( barley, tapply( yield, list( site=site, year=year ), rank ) )
> but I do not manage to merge this result
> to the original dataframe ``barley''.

> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Please do as that asks, including reading its references.  We should not 
have to guess at the meaning of your subject line, where you got a dataset 
from etc.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From vito.muggeo at giustizia.it  Mon Sep 13 11:35:58 2004
From: vito.muggeo at giustizia.it (Vito Muggeo)
Date: Mon, 13 Sep 2004 11:35:58 +0200
Subject: [R] an integration question
Message-ID: <00eb01c49975$16535580$5c13070a@PROCGEN>

Dear all,
I'm stuck on a problem concerning integration..Results from the analytical
expression and numerical approximation (as returned by integrate()) do not
match.
It probably depends on some error of mine, so apologizes for this off-topic
question.

I'm interested in computing the integral of f where:
f<-function(x){exp(-3-.2*pmin(x-7.5,0))}
x<-seq(0,15,length=50)
plot(x, f(x),type="l")

Using the integrate() function, I get reasonable results
a<-sapply(x, function(xx)integrate(f,0,xx)[[1]])
plot(x, a,type="l")

Using analytical expression, the primitive of f is (or should be..)
F<-function(x){exp(-3-.2*pmin(x-7.5,0))/(-.2*I(x<7.5))}
plot(x,(F(x)-F(0)), type="l")

The problem is that for x>7.5 the denominator (-.2*I(x<7.5)) is zero and
then the primitive function F(.) goes to infinity. On the other hand
integrate() provides finite (as it should be, I believe) output. For x<7.5
everything works.

> F(10)-F(0)
[1] -Inf
..
> integrate(f,0,10)
0.9911831 with absolute error < 1.1e-14
>
> F(5)-F(0)
[1] 0.7052258
..
> integrate(f,0,5)
0.7052258 with absolute error < 7.8e-15

Hence I think there is an error in the expression of H(.), but I can not
figure out where it is..Please can anyone help me? I would like to get an
analytical expression for F.

Many thanks,

vito



From pbrouilly at gphy.campus.univ-poitiers.fr  Mon Sep 13 11:23:36 2004
From: pbrouilly at gphy.campus.univ-poitiers.fr (pbrouilly@gphy.campus.univ-poitiers.fr)
Date: Mon, 13 Sep 2004 11:23:36 +0200
Subject: [R] R and perl on solaris
Message-ID: <1095067416.414567185708c@gphy.campus.univ-poitiers.fr>

Dear all,

I am developing a GUI in perl-Tk and I would use R engine to make some analysis
and some plots.
I have seen that the package RSPerl allows R from perl exchanges but this
package is developed on and for intel based computers. 
When I try to install the package on solaris I have some errors

has somebody already used RSPerl on solaris ?

Many thanks,

Patrick



From Friedrich.Leisch at tuwien.ac.at  Mon Sep 13 12:01:32 2004
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Mon, 13 Sep 2004 12:01:32 +0200
Subject: [Rd] Re: [R] Sweave echoing comments (again)
In-Reply-To: <200409081746510955.0C476E9B@mail.math.fu-berlin.de>
References: <413C4A66.30008@hhbio.wasser.tu-dresden.de>
	<200409081746510955.0C476E9B@mail.math.fu-berlin.de>
Message-ID: <16709.28668.343269.139090@galadriel.ci.tuwien.ac.at>

>>>>> On Wed, 08 Sep 2004 17:46:51 +0200,
>>>>> Wolski  (W) wrote:

  > Hi!
  > I observed it also. There are cases where it is not desirable. It
  > will be quite helpfull, if possible, to have a parameter that
  > allows one to switch of removing the #comments.

The problem is that the parser does not keep the comments, and I need
to parse & deparse the source in order to know when expressions are
complete, such that I can insert the ourtput in the right places.

Currently there is no way of keepng the comments in Sweave code
chunks.

Best,
Fritz

PS: I am promising a workaround for quite some time now, but haven't
had the time to code that yet, so don't hold your breath.



From laurent.buffat at it-omics.com  Mon Sep 13 12:09:30 2004
From: laurent.buffat at it-omics.com (laurent buffat)
Date: Mon, 13 Sep 2004 12:09:30 +0200
Subject: [R] SJava, Client X11
In-Reply-To: <20040909151937.F3E9793EE@heart.itomics.local>
Message-ID: <20040913100930.2D39B93EE@heart.itomics.local>


Hi everyone,

I have not received any response on my question, probably because I don't
give sufficient information, but unfortunately, I don't have more
information on my problem.

So I have a simple question:

Does anyone success on running the SJava examples with an X11 client
console?

Thanks for your help.

Laurent



-----Message d'origine-----
De : r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] De la part de Laurent Buffat
Envoy?? : jeudi 9 septembre 2004 17:20
?? : r-help at stat.math.ethz.ch
Objet : [R] SJava, Client X11

Hi,

 

I have installed the SJava package (see http://www.omegahat.org/RSJava/ )
without any problem.

 

I was able to run the examples (see
http://www.omegahat.org/RSJava/examples/index.html )

from R, on my "R Linux server" and directly on the display of the server,

 

But, if I run theses examples on an "X11 client", under Linux or windows,
with a "correct configuration" of the X11 client

(export DISPLAY=machine:0.0 on Linux for example), I have a "scratch" of the
R session without any messages ....

 

For example:

 

> library(SJava)

> .JavaInit()

> source("DynamicButtonCallback.R")

 

Run perfectly on the server, with a creation of a button on the display.

 

But the same instructions, on the X11 client, create the button and
immediately crash the R session and destroy the button.

 

Any Ideas?

 

Thanks for your help.

 

Laurent  

 


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Mon Sep 13 12:18:18 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Sep 2004 12:18:18 +0200
Subject: [R] Discrepency between R and MlwiN
In-Reply-To: <Pine.LNX.4.44.0409130725200.11324-100000@gannet.stats>
References: <Pine.LNX.4.44.0409130725200.11324-100000@gannet.stats>
Message-ID: <x2sm9mpj4l.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Sun, 12 Sep 2004, Damian Betebenner wrote:
> 
> > When playing around fitting unconditional growth models using R and MlwiN today, I produced two different sets of estimates that I can't reconcile and wondered if anyone here has an idea:
> > 
> > The data is two-level repeated measures data with measures nested within child. There are two measures per child. I've fit an unconditional growth model as in Singer and Willet (2003) that allows for variable intercepts
> > and slopes.
....
> Are there always two points per student?  If so, your model is not
> identifiable (in so far as I understand what you are doing) and there is
> an infinite set of parameters which give the same restricted likelihood.
> Please check if the latter is the case for the two sets of results.
> 
> For each student you have a random intercept, a random slope and 
> measurement error at each point.  That's 4 random variables to explain 2 
> observations.

Actually, I don't think that's necessarily a problem (more r.v.'s than
observations), is it?. However, assuming that the two points are the
same for each student, you have an empirical covariance matrix (3
values) and explain it using the variance of A, and B, and the
covariance between them, *and* the residual error, i.e. four
parameters, and that surely is a problem.

> In short, you appear to have chosen a model that overfits.

Yup. And the current lme() algorithm is not very good at detecting
such singularities, although it should be apparent from the covariance
matrix of the random-effects parameters.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Mon Sep 13 12:37:01 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Sep 2004 11:37:01 +0100 (BST)
Subject: [R] SJava, Client X11
In-Reply-To: <20040913100930.2D39B93EE@heart.itomics.local>
Message-ID: <Pine.LNX.4.44.0409131132420.15725-100000@gannet.stats>

This is *R* help, and you are asking about an *Omegahat* package, and 
indeed about debugging your local installation.

In theory Omegahat has its own mailing lists.  But to answer your 
question:

> Does anyone success on running the SJava examples with an X11 client
> console?

Yes, I have done so in 2003.  This is an issue about how you set up Java,
and it is often very slow indeed.  It is really is not an appropriate
question for R-help: it is not about R nor about an R package.


On Mon, 13 Sep 2004, laurent buffat wrote:

> 
> Hi everyone,
> 
> I have not received any response on my question, probably because I don't
> give sufficient information, but unfortunately, I don't have more
> information on my problem.
> 
> So I have a simple question:
> 
> Does anyone success on running the SJava examples with an X11 client
> console?
> 
> Thanks for your help.
> 
> Laurent
> 
> 
> 
> -----Message d'origine-----
> De : r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] De la part de Laurent Buffat
> Envoy?? : jeudi 9 septembre 2004 17:20
> ?? : r-help at stat.math.ethz.ch
> Objet : [R] SJava, Client X11
> 
> Hi,
> 
>  
> 
> I have installed the SJava package (see http://www.omegahat.org/RSJava/ )
> without any problem.
> 
>  
> 
> I was able to run the examples (see
> http://www.omegahat.org/RSJava/examples/index.html )
> 
> from R, on my "R Linux server" and directly on the display of the server,
> 
>  
> 
> But, if I run theses examples on an "X11 client", under Linux or windows,
> with a "correct configuration" of the X11 client
> 
> (export DISPLAY=machine:0.0 on Linux for example), I have a "scratch" of the
> R session without any messages ....
> 
>  
> 
> For example:
> 
>  
> 
> > library(SJava)
> 
> > .JavaInit()
> 
> > source("DynamicButtonCallback.R")
> 
>  
> 
> Run perfectly on the server, with a creation of a button on the display.
> 
>  
> 
> But the same instructions, on the X11 client, create the button and
> immediately crash the R session and destroy the button.
> 
>  
> 
> Any Ideas?
> 
>  
> 
> Thanks for your help.
> 
>  
> 
> Laurent  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sdavis2 at mail.nih.gov  Mon Sep 13 12:58:13 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 13 Sep 2004 06:58:13 -0400
Subject: [R] R and perl on solaris
References: <1095067416.414567185708c@gphy.campus.univ-poitiers.fr>
Message-ID: <003701c49980$93f16170$04653744@WATSON>

Patrick,

This isn't answering your question, but there are other ways to go about
this problem.  See

http://tolstoy.newcastle.edu.au/R/help/04/05/0952.html

for instance....

Further searching might bring more hits.

Sean
----- Original Message -----
From: <pbrouilly at gphy.campus.univ-poitiers.fr>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, September 13, 2004 5:23 AM
Subject: [R] R and perl on solaris


> Dear all,
>
> I am developing a GUI in perl-Tk and I would use R engine to make some
analysis
> and some plots.
> I have seen that the package RSPerl allows R from perl exchanges but this
> package is developed on and for intel based computers.
> When I try to install the package on solaris I have some errors
>
> has somebody already used RSPerl on solaris ?
>
> Many thanks,
>
> Patrick
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From f.harrell at vanderbilt.edu  Mon Sep 13 13:18:14 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Mon, 13 Sep 2004 07:18:14 -0400
Subject: [R] How to bootstrap Kaplan-Miere estimator with 95% envelope
In-Reply-To: <200409130623.i8D6NFG00916@smtp1.ucalgary.ca>
References: <200409130623.i8D6NFG00916@smtp1.ucalgary.ca>
Message-ID: <414581F6.1000509@vanderbilt.edu>

wanr at ucalgary.ca wrote:
> Hi all,
> 
> Given a typical right-censoring data which contains a time variable and a 
> censoring indicator. How do we bootstrap samples to obtain a 95% envelope 
> for the estimated cumulative hazard function?
> 
> Thanks in advance.
> 
> Rui

bootkm in the Hmisc package does not compute confidence intervals for 
the whole curve, only for one time point or one quantile of survival 
time, but it shows how to bootstrap K-M quickly using survfit.km in the 
survival package.

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From irena.komprej at telemach.net  Mon Sep 13 13:30:22 2004
From: irena.komprej at telemach.net (Irena Komprej)
Date: Mon, 13 Sep 2004 13:30:22 +0200
Subject: [R] Cancor 
Message-ID: <010901c49985$0f68e810$0300a8c0@JJ.cable.amis.net>

Dear Gabor,
thank you for your answer, but I am still a little confused because the
values of the xcoef and ycoef are so small. It is true, that I receive
very similar results to the cancor,  if I use the proposed formula with

 z <- svd(cov(x,y) %*% solve(var(y), cov(y,x)) %*% solve(var(x)))
   sqrt(z$d)  # canonical correlations
   isqrt((nrow(x)-1)*var(x)) %*% z$u    # xcoef

But, why do I need the nrow(x)-1)* in isqrt()?
In the literature, if you use the proposed calculation, the a's are
calculated as z$u %*% isqrt(var(x)).

I have this problem, because I need structural coefficients to calculate
Redundancy measure and according to literature, they are calculated as
a's%*%var(x).
The coefficients from cancor are so small that my redundancy measure iz
almost zero, despite the high correlation coefficient.

I have, on the other hand, calculated correlation between x and their
corresponding canonical variables as:
cor(x, x%*%xcoef)
and results were good.

Can I use these results as structural correlations in Redundancy measure
calculation?

Thank you again and best regards

Irena Komprej

________________________________________________________________
Irena Komprej <irena.komprej <at> telemach.net> writes:

>
> I am strugling with cancor procedure in R. I cannot figure out the
> meaning of xcoef and of yxcoef.
> Are these:
> 1. standardized coefficients
> 2. structural coefficients
> 3. something else?
>


Look at the examples at the bottom of ?cancor from which its evident
xcoef is such that x %*% cxy$xcoef are the canonical variables.  (More
at the end of this post.)


> I have tried to simulate canonical correlation analysis by checking
the
> eigenstructure of the expression:
>
> Sigma_xx %*% Sigma_xy %*% Sigma_yy %*% t(Sigma_xy).
>
> The resulting eigenvalues were the same as the squared values of
> cancor$cor. I have normalized the resulting eigenvectors, the a's with
>
> sqrt(a'%*%Sigma_xx%*%t(a)), and similarly the b's with
> sqrt(b'%*%Sigma_yy%*%t(b)).
>
> The results differed considerably from xcoef and ycoef of the cancor.

Run the example in the help page to get some data and some
output:

   set.seed(1)
   example(cancor)

# Also, define isqrt as the inverse square root of a postive def matrix

   isqrt <- function(x) {
      e <- eigen(x)
      stopifnot( all(e$values > 0) )
      e$vectors %*% diag(1/sqrt(e$values)) %*% solve(e$vectors)
    }

# we can reconstruct the canonical correlations and xcoef
# in the way you presumably intended like this:

   z <- svd(cov(x,y) %*% solve(var(y), cov(y,x)) %*% solve(var(x)))
   sqrt(z$d)  # canonical correlations
   isqrt((nrow(x)-1)*var(x)) %*% z$u    # xcoef

Another thing you can do is to type

   cancor

at the R prompt to view its source and see how it works using
the QR decomposition.



From jfox at mcmaster.ca  Mon Sep 13 13:33:35 2004
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 13 Sep 2004 07:33:35 -0400
Subject: [R] pairwise deletion of missing cases in lm
In-Reply-To: <BC4231C30D143F43BFD514168020196935DA04@lurch>
Message-ID: <20040913113336.ELHA25796.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Alan,

I believe that the short answer is "no," since lm() requires a complete data
set. Flexibility is provided by your ability to write your own na.action
function, but that won't cover this case. Moreover, pairwise deletion of
missing data is probably ill-advised.

On the other hand, it shouldn't be hard to write a function that computes
regressions using pairwise deletion, starting with a covariance matrix
returned by cov().

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Alan Simpson
> Sent: Sunday, September 12, 2004 11:04 PM
> To: 'r-help at lists.R-project.org'
> Subject: [R] pairwise deletion of missing cases in lm
> 
> Does anybody know if there is some sort of "pairwise" option 
> for handling missing cases in lm and computing the relevant 
> statistics?
> 
> I would be much obliged if anyone could help...
> 
> Regards
> 
> Alan Simpson
> Roberts Research Group
>



From tlumley at u.washington.edu  Mon Sep 13 13:43:24 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 13 Sep 2004 04:43:24 -0700 (PDT)
Subject: [R] Case-Cohort Analysis
In-Reply-To: <20040908134621.RTYI11007.tomts14-srv.bellnexxia.net@mxmta.bellnexxia.net>
References: <20040908134621.RTYI11007.tomts14-srv.bellnexxia.net@mxmta.bellnexxia.net>
Message-ID: <Pine.A41.4.61.0409130442180.176162@homer08.u.washington.edu>

On Wed, 8 Sep 2004 petertait at sympatico.ca wrote:

> Hi All, I am in the middle of doing an analysis of a Case-Cohort design. 
> I had three questions about the analysis:

I would suggest Mayo Clinic tech report #62
http://www.mayo.edu/hsr/techrpt.html
62: Computing the Cox Model for Case Cohort Designs
Prentice proposed a case-cohort design as an efficient  subsampling 
mechanism for survival studies. Several other  authors have expanded on 
these ideas to create a family of  related sampling plans, along with 
estimators for the  covariate effects. We describe how to obtain the 
proposed  parameter estimates and their variance estimates using  standard 
software packages, with SAS and S-Plus as  particular examples.

 	-thomas


>
> a) Does any one know of some public code for developing the patient risk sets (indexed by failure time) or is there a better way to organize the data?
>
> b) I was planning to use the Barlow weighting method. Has this or any other weighting method (Prentice, Self-Prentice) been implemented in R?
>
> c) Is matching a good thing to do or can the variables that would be used for matching just be adjusted for in the cox regression (is there a reference for this because I can?t find one)?  If matching is a good thing to do are there any R packages that contain matching functions?
>
> Thanks for your help.
> Peter Tait
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From tlumley at u.washington.edu  Mon Sep 13 13:56:37 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 13 Sep 2004 04:56:37 -0700 (PDT)
Subject: [R] scoping rules
In-Reply-To: <7669F018DC9DD711AEC500065B3D5ABF02CAD450@tudor.com>
References: <7669F018DC9DD711AEC500065B3D5ABF02CAD450@tudor.com>
Message-ID: <Pine.A41.4.61.0409130443320.176162@homer08.u.washington.edu>

On Thu, 9 Sep 2004, Whit Armstrong wrote:

> Can someone help me with this simple example?
>
> sq <- function() {
> 	y <- x^2
> 	y
> }
>
> myfunc <- function() {
> 	x <- 10
> 	sq()
> }
>
> myfunc()
>
>
> executing the above in R yields:
>> myfunc()
> Error in sq() : Object "x" not found
>
> I understand that R's scoping rules cause it to look for "x" in the
> environment in which "sq" was defined (the global environment in this case).
> But in this case "x" is defined inside the calling function, not the
> environment in which "sq" was defined.
>
> Is there a way to tell R to look in the calling function for "x" ?

yes, but you almost certainllyy don't want to.

In a real example you would want to either

1/ Pass x as an argument (most likely)
2/ Define sq() inside myfunc()
3/ define myfunc() inside sq()
4/ Pass the name of x as an argument (eg quote(x) or ~x)

While you can fake dynamic scope in R, there is no point in doing it with 
a variable whose name is hard-coded.

The only reason to allow access to a non-local variable x with a fixed 
name is to preserve its value across calls to the function, but with 
dynamic scope the "x" may be a completely different variable each time.


 	-thomas



From ggrothendieck at myway.com  Mon Sep 13 14:00:11 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 13 Sep 2004 12:00:11 +0000 (UTC)
Subject: [R] Cancor
References: <010901c49985$0f68e810$0300a8c0@JJ.cable.amis.net>
Message-ID: <loom.20040913T135151-909@post.gmane.org>

Irena Komprej <irena.komprej <at> telemach.net> writes:

: thank you for your answer, but I am still a little confused because the
: values of the xcoef and ycoef are so small. It is true, that I receive
: very similar results to the cancor,  if I use the proposed formula with
: 
:  z <- svd(cov(x,y) %*% solve(var(y), cov(y,x)) %*% solve(var(x)))
:    sqrt(z$d)  # canonical correlations
:    isqrt((nrow(x)-1)*var(x)) %*% z$u    # xcoef
: 
: But, why do I need the nrow(x)-1)* in isqrt()?

I don't think the scaling really matters.  If you want to define
the scaling so that the canonical variables have identity variance
matrix or other scaling you can rescale.  I chose the above
scaling since the objective was to give the same result as
cancor.

If the values we calculate above are slightly different than cancor's
I would go with cancor since it uses the QR decomposition which is
presumably more stable numerically than what we have above.

Don't know about the rest of your questions.


: 
: >
: > I am strugling with cancor procedure in R. I cannot figure out the
: > meaning of xcoef and of yxcoef.
: > Are these:
: > 1. standardized coefficients
: > 2. structural coefficients
: > 3. something else?
: >
: 
: Look at the examples at the bottom of ?cancor from which its evident
: xcoef is such that x %*% cxy$xcoef are the canonical variables.  (More
: at the end of this post.)
: 
: > I have tried to simulate canonical correlation analysis by checking
: the
: > eigenstructure of the expression:
: >
: > Sigma_xx %*% Sigma_xy %*% Sigma_yy %*% t(Sigma_xy).
: >
: > The resulting eigenvalues were the same as the squared values of
: > cancor$cor. I have normalized the resulting eigenvectors, the a's with
: >
: > sqrt(a'%*%Sigma_xx%*%t(a)), and similarly the b's with
: > sqrt(b'%*%Sigma_yy%*%t(b)).
: >
: > The results differed considerably from xcoef and ycoef of the cancor.
: 
: Run the example in the help page to get some data and some
: output:
: 
:    set.seed(1)
:    example(cancor)
: 
: # Also, define isqrt as the inverse square root of a postive def matrix
: 
:    isqrt <- function(x) {
:       e <- eigen(x)
:       stopifnot( all(e$values > 0) )
:       e$vectors %*% diag(1/sqrt(e$values)) %*% solve(e$vectors)
:     }
: 
: # we can reconstruct the canonical correlations and xcoef
: # in the way you presumably intended like this:
: 
:    z <- svd(cov(x,y) %*% solve(var(y), cov(y,x)) %*% solve(var(x)))
:    sqrt(z$d)  # canonical correlations
:    isqrt((nrow(x)-1)*var(x)) %*% z$u    # xcoef
: 
: Another thing you can do is to type
: 
:    cancor
: 
: at the R prompt to view its source and see how it works using
: the QR decomposition.
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://stat.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From christian.hoffmann at wsl.ch  Mon Sep 13 14:05:48 2004
From: christian.hoffmann at wsl.ch (Christian Hoffmann)
Date: Mon, 13 Sep 2004 14:05:48 +0200
Subject: [R] *.Rd: line breaks incorrect (?) \examples
Message-ID: <41458D1C.4020801@wsl.ch>

Hi all,

I am using

R, Version 1.9.1 alpha (2004-05-25), ISBN 3-900051-00-3

on

SunOS fluke 5.9 Generic_117171-02 sun4u sparc SUNW,Sun-Fire-480R

Version: sparc-sun-solaris2.9
arch = sparc
os = solaris2.9
system = sparc, solaris2.9
status = alpha
major = 1
minor = 9.1
year = 2004
month = 05
day = 25
language = R
Search Path:
  .GlobalEnv, package:methods, package:stats, package:graphics, 
package:utils, package:lattice, package:CWHtool, package:CWHplot, 
package:CWHstring, package:CWHprint, package:CWHmath, Autoloads, 
package:base

In the guide to writing packages I did not find warnings concerning the 
following:

- long lines in \examples{} and \author{} are not folded (broken) in the 
resulting *.ps.

- If I want to write a comment in \examples{} using #, like:
   \examples{
   executable stuff  # comment   \emph{}  \code{\link{}}
   }
   then \emph{} and \code{\link{}} are transformed into a queer sequence 
of characters.   Question: where are \emph{}  \code{\link{}} allowed?

- More general: Where are TeX constructs allowed? $x_{nn}
- Where are TeX constructs mandatory?

- Why are pck.Rcheck/pck-manual.aux, .dvi, and .log generated by runnung 
R CMD build etc., but not pck.Rcheck/pck-manual.ps?    However, 
pck.Rcheck/pck-Examples *is* generated.

Thank you for considering
Christian
-- 
Dr.sc.math.Christian W. Hoffmann, 
http://www.wsl.ch/staff/christian.hoffmann
Mathematics + Statistical Computing   e-mail: christian.hoffmann at wsl.ch
Swiss Federal Research Institute WSL  Tel: ++41-44-73922-   -77  (office)
CH-8903 Birmensdorf, Switzerland             -11(exchange), -15  (fax)



From rksh at soc.soton.ac.uk  Mon Sep 13 14:39:03 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Mon, 13 Sep 2004 13:39:03 +0100
Subject: [R] Rd files with "%" (was: permuting dimensions)
Message-ID: <a06002001bd6b44bedd34@[139.166.242.29]>


Professor Ripley

thanks for this.   Very much appreciated.

The original subject line reflected my late-night conviction
that the answer might involve passing a strange list to do.call().

Anyway, package magic is broken (only in R-devel, I might add)  because I have
a function called "%eq%".

R-2.0.0  CMD check is stopping (I think) because it interprets  the 
"%" as a control character.

Does anyone have a best-practice  example of a package  that includes a
function like "%eq%" that I could modify?  In particular, how do I get
\usage{m1 %eq% m2}  and \examples{..}  to work nicely?


best wishes


rksh


>
>
>
>>What has this to do with the original subject line?  Replacement functions
>>are not intended to be used directly, and certainly not in do.call.
>>
>>See ?aperm, as in
>>
>>xx <- x
>>dim(xx) <- c(2,2,3,3)
>>xx <- aperm(xx, c(1,3,2,4))
>>dim(xx) <- c(6, 6)
>>xx
>>
>>as required.
>>
>>BTW, you have a broken package `magic' on CRAN: please do us the courtesy
>>of fixing it so we don't continually have to look at it in tests. See
>>
>>http://cran.r-project.org/src/contrib/checkSummary.html

-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From fws4 at cdrh.fda.gov  Mon Sep 13 14:40:15 2004
From: fws4 at cdrh.fda.gov (Frank Samuelson)
Date: Mon, 13 Sep 2004 08:40:15 -0400
Subject: [R] Spare some CPU cycles for testing lme?
Message-ID: <ci44e3$96d$1@sea.gmane.org>

If anyone has a few extra CPU cycles to spare,
I'd appreciate it if you could verify a problem that I
have encountered.  Run the code
below and tell me if it crashes your R before
completion.

library(lme4)
data(bdf)
dump<-sapply( 1:50000, function(i) {
     fm <- lme(langPOST ~ IQ.ver.cen + avg.IQ.ver.cen, data = bdf,
               random = ~ IQ.ver.cen | schoolNR);
     cat("  ",i,"\r")
     0
})

The above code simply reruns the example from the
lme help page a large number of times and returns a bunch
of 0's, so you'll need to have the lme4 and Matrix
packages installed.  It might take a while to complete,
but you can always nice it and let it run.

I'm attempting to bootstrap lme() from the lme4 package,
but it causes a
segfault after a couple hundred iterations.  This happens on
my Linux x86 RedHat 7.3, 8.0, 9.0, FC1 systems w/ 1.9.1
and devel 2.0.0 (not all possible combinations actually
tested.)
I've communicated w/ Douglas Bates about this and he
doesn't appear to have the problem.

Thanks for any help.

-Frank



From ripley at stats.ox.ac.uk  Mon Sep 13 14:50:30 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Sep 2004 13:50:30 +0100 (BST)
Subject: [R] *.Rd: line breaks incorrect (?) \examples
In-Reply-To: <41458D1C.4020801@wsl.ch>
Message-ID: <Pine.LNX.4.44.0409131345560.16077-100000@gannet.stats>

On Mon, 13 Sep 2004, Christian Hoffmann wrote:

> Hi all,
> 
> I am using
> 
> R, Version 1.9.1 alpha (2004-05-25), ISBN 3-900051-00-3

Oh, please use a released version or 2.0.0 alpha.

[...]

> In the guide to writing packages I did not find warnings concerning the 
> following:
> 
> - long lines in \examples{} and \author{} are not folded (broken) in the 

\examples is *verbatim* as it says.

I don't think this is correct about \author.

> resulting *.ps.
> 
> - If I want to write a comment in \examples{} using #, like:
>    \examples{
>    executable stuff  # comment   \emph{}  \code{\link{}}
>    }
>    then \emph{} and \code{\link{}} are transformed into a queer sequence 
> of characters.   Question: where are \emph{}  \code{\link{}} allowed?

Outside *verbatim* environments.

> - More general: Where are TeX constructs allowed? $x_{nn}
> - Where are TeX constructs mandatory?

Inside the first argument of \eqn and \deqn only.

> - Why are pck.Rcheck/pck-manual.aux, .dvi, and .log generated by runnung 
> R CMD build etc., but not pck.Rcheck/pck-manual.ps?    However, 

They are not.  They *are* generated by R CMD check, as that checks the 
latex help files.  If you want a .ps manual for a package use R CMD RD2dvi
and then run the appropriate dvi-to-ps command on your system (R does not 
know about such commands).

> pck.Rcheck/pck-Examples *is* generated.

Well, the examples are run.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Mon Sep 13 14:58:03 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 13 Sep 2004 08:58:03 -0400
Subject: [R] Rd files with "%" (was: permuting dimensions)
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8380@usrymx25.merck.com>

I suppose the source for ?"%in%" in base would be a good place to look:

========================
\name{match}
\alias{match}
\alias{\%in\%}
[...]
\usage{
match(x, table, nomatch = NA, incomparables = FALSE)

x \%in\% table
}
[...]
\details{
  \code{\%in\%} is currently defined as \cr
  \code{"\%in\%" <- function(x, table) match(x, table, nomatch = 0) > 0}

[...]
\examples{
[...]
1:10 \%in\% c(1,3,5,9)
sstr <- c("c","ab","B","bba","c","@","bla","a","Ba","\%")
sstr[sstr \%in\% c(letters,LETTERS)]

"\%w/o\%" <- function(x,y) x[!x \%in\% y] #--  x without y
(1:10) \%w/o\% c(3,7,12)
}
[...]

Andy



> From: Robin Hankin
> 
> Professor Ripley
> 
> thanks for this.   Very much appreciated.
> 
> The original subject line reflected my late-night conviction
> that the answer might involve passing a strange list to do.call().
> 
> Anyway, package magic is broken (only in R-devel, I might 
> add)  because I have
> a function called "%eq%".
> 
> R-2.0.0  CMD check is stopping (I think) because it interprets  the 
> "%" as a control character.
> 
> Does anyone have a best-practice  example of a package  that 
> includes a
> function like "%eq%" that I could modify?  In particular, how do I get
> \usage{m1 %eq% m2}  and \examples{..}  to work nicely?
> 
> 
> best wishes
> 
> 
> rksh
> 
> 
> >
> >
> >
> >>What has this to do with the original subject line?  
> Replacement functions
> >>are not intended to be used directly, and certainly not in do.call.
> >>
> >>See ?aperm, as in
> >>
> >>xx <- x
> >>dim(xx) <- c(2,2,3,3)
> >>xx <- aperm(xx, c(1,3,2,4))
> >>dim(xx) <- c(6, 6)
> >>xx
> >>
> >>as required.
> >>
> >>BTW, you have a broken package `magic' on CRAN: please do 
> us the courtesy
> >>of fixing it so we don't continually have to look at it in 
> tests. See
> >>
> >>http://cran.r-project.org/src/contrib/checkSummary.html
> 
> -- 
> Robin Hankin
> Uncertainty Analyst
> Southampton Oceanography Centre
> SO14 3ZH
> tel +44(0)23-8059-7743
> initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam 
> precaution)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From pardelle at yahoo.fr  Mon Sep 13 15:22:09 2004
From: pardelle at yahoo.fr (=?iso-8859-1?q?bournery=20alexandre?=)
Date: Mon, 13 Sep 2004 15:22:09 +0200 (CEST)
Subject: [R] Mixture Analysis
Message-ID: <20040913132209.33991.qmail@web25201.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040913/370e9563/attachment.pl

From max.marinucci at ya.com  Mon Sep 13 15:42:50 2004
From: max.marinucci at ya.com (max.marinucci)
Date: Mon, 13 Sep 2004 15:42:50 +0200
Subject: [R] Mixture Analysis
Message-ID: <002501c49997$91680000$1b567cd9@maxmad9rubu4nk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040913/8a27fd86/attachment.pl

From rolf at math.unb.ca  Mon Sep 13 16:03:21 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 13 Sep 2004 11:03:21 -0300 (ADT)
Subject: [R] Mixture Analysis
Message-ID: <200409131403.i8DE3Lkx017315@erdos.math.unb.ca>


Massimiliano Marinucci wrote:

> as far I know you can estimate mixture regression models with the
> flexmix package

	See also the package ``mixreg'' on CRAN.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From james.holtman at convergys.com  Mon Sep 13 16:13:34 2004
From: james.holtman at convergys.com (james.holtman@convergys.com)
Date: Mon, 13 Sep 2004 10:13:34 -0400
Subject: [R] Spare some CPU cycles for testing lme?
Message-ID: <OF54B185C0.04715309-ON85256F0E.004DED38@nd.convergys.com>





I tried out your example and it abended.

It ran through 22472 times and ended with an error message that the
instruction at 0x77f5b2ab could not reference location 0x00000028.

> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.1
year     2004
month    06
day      21
language R

HTH
__________________________________________________________
James Holtman        "What is the problem you are trying to solve?"
Executive Technical Consultant  --  Office of Technology, Convergys
james.holtman at convergys.com
+1 (513) 723-2929


                                                                                                                                           
                      Frank Samuelson                                                                                                      
                      <fws4 at cdrh.fda.gov>          To:       r-help at stat.math.ethz.ch                                                      
                      Sent by:                     cc:                                                                                     
                      r-help-bounces at stat.m        Subject:  [R] Spare some CPU cycles for testing lme?                                    
                      ath.ethz.ch                                                                                                          
                                                                                                                                           
                                                                                                                                           
                      09/13/2004 08:40                                                                                                     
                                                                                                                                           
                                                                                                                                           




If anyone has a few extra CPU cycles to spare,
I'd appreciate it if you could verify a problem that I
have encountered.  Run the code
below and tell me if it crashes your R before
completion.

library(lme4)
data(bdf)
dump<-sapply( 1:50000, function(i) {
     fm <- lme(langPOST ~ IQ.ver.cen + avg.IQ.ver.cen, data = bdf,
               random = ~ IQ.ver.cen | schoolNR);
     cat("  ",i,"\r")
     0
})

The above code simply reruns the example from the
lme help page a large number of times and returns a bunch
of 0's, so you'll need to have the lme4 and Matrix
packages installed.  It might take a while to complete,
but you can always nice it and let it run.

I'm attempting to bootstrap lme() from the lme4 package,
but it causes a
segfault after a couple hundred iterations.  This happens on
my Linux x86 RedHat 7.3, 8.0, 9.0, FC1 systems w/ 1.9.1
and devel 2.0.0 (not all possible combinations actually
tested.)
I've communicated w/ Douglas Bates about this and he
doesn't appear to have the problem.

Thanks for any help.

-Frank

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From max.marinucci at ya.com  Mon Sep 13 16:14:53 2004
From: max.marinucci at ya.com (max.marinucci)
Date: Mon, 13 Sep 2004 16:14:53 +0200
Subject: [R] Mixture Analysis
References: <200409131403.i8DE3Lkx017315@erdos.math.unb.ca>
Message-ID: <005501c4999c$0a98f200$1b567cd9@maxmad9rubu4nk>

Dear Rolf
this is a good new! Thanks for your effort for making the mixreg package
available on CRAN.
Cheers
Max

----- Original Message -----
From: "Rolf Turner" <rolf at math.unb.ca>
To: <max.marinucci at ya.com>; <pardelle at yahoo.fr>
Cc: <r-help at stat.math.ethz.ch>
Sent: Monday, September 13, 2004 4:03 PM
Subject: Re: [R] Mixture Analysis


>
> Massimiliano Marinucci wrote:
>
> > as far I know you can estimate mixture regression models with the
> > flexmix package
>
> See also the package ``mixreg'' on CRAN.
>
> cheers,
>
> Rolf Turner
> rolf at math.unb.ca
>



From MSchwartz at MedAnalytics.com  Mon Sep 13 16:31:03 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Mon, 13 Sep 2004 09:31:03 -0500
Subject: [R] Spare some CPU cycles for testing lme?
In-Reply-To: <ci44e3$96d$1@sea.gmane.org>
References: <ci44e3$96d$1@sea.gmane.org>
Message-ID: <1095085863.2322.40.camel@localhost.localdomain>

On Mon, 2004-09-13 at 07:40, Frank Samuelson wrote:
> If anyone has a few extra CPU cycles to spare,
> I'd appreciate it if you could verify a problem that I
> have encountered.  Run the code
> below and tell me if it crashes your R before
> completion.
> 
> library(lme4)
> data(bdf)
> dump<-sapply( 1:50000, function(i) {
>      fm <- lme(langPOST ~ IQ.ver.cen + avg.IQ.ver.cen, data = bdf,
>                random = ~ IQ.ver.cen | schoolNR);
>      cat("  ",i,"\r")
>      0
> })
> 
> The above code simply reruns the example from the
> lme help page a large number of times and returns a bunch
> of 0's, so you'll need to have the lme4 and Matrix
> packages installed.  It might take a while to complete,
> but you can always nice it and let it run.
> 
> I'm attempting to bootstrap lme() from the lme4 package,
> but it causes a
> segfault after a couple hundred iterations.  This happens on
> my Linux x86 RedHat 7.3, 8.0, 9.0, FC1 systems w/ 1.9.1
> and devel 2.0.0 (not all possible combinations actually
> tested.)
> I've communicated w/ Douglas Bates about this and he
> doesn't appear to have the problem.
> 
> Thanks for any help.
> 
> -Frank
> 

Replicated here on FC 2 running:

Version 1.9.1 Patched (2004-09-07)

The backtrace from gdb follows. It would probably make sense to move
this thread to r-devel. As you can see, it got through 10,546 runs
before segfaulting.

cc: to Doug.

HTH,

Marc Schwartz


> dump<-sapply( 1:50000, function(i) {
+      fm <- lme(langPOST ~ IQ.ver.cen + avg.IQ.ver.cen, data = bdf,
+                random = ~ IQ.ver.cen | schoolNR);
+      cat("  ",i,"\r")
+      0
+ })
   10546
Program received signal SIGSEGV, Segmentation fault.
0x00982242 in _int_free () from /lib/tls/libc.so.6
(gdb) bt
#0  0x00982242 in _int_free () from /lib/tls/libc.so.6
#1  0x0098373b in free () from /lib/tls/libc.so.6
#2  0x080c4003 in ReleaseLargeFreeVectors () at memory.c:695
#3  0x080c5999 in RunGenCollect (size_needed=1144) at memory.c:1282
#4  0x080c7084 in R_gc_internal (size_needed=1144) at memory.c:1933
#5  0x080c6b67 in Rf_allocVector (type=16, length=2287) at memory.c:1788
#6  0x0809b6b1 in Rf_duplicate (s=0xbed5d40) at duplicate.c:150
#7  0x0809b335 in Rf_duplicate (s=0xb64a3bc) at duplicate.c:100
#8  0x0809b517 in Rf_duplicate (s=0xbed15a8) at duplicate.c:142
#9  0x0809b777 in Rf_duplicate (s=0xb3f6048) at duplicate.c:137
#10 0x080a796d in EnsureLocal (symbol=0x9719f38, rho=0xb64c2b8) at
eval.c:765
#11 0x080a8691 in evalseq (expr=0x9719f38, rho=0xb64c2b8, forcelocal=1,
tmploc=0xb64a340) at eval.c:1135
#12 0x080a8847 in applydefine (call=0x97f9818, op=0x9705264,
args=0x97f9834, rho=0xb64c2b8) at eval.c:1199
#13 0x080a7055 in Rf_eval (e=0x97f9818, rho=0xb64c2b8) at eval.c:375
#14 0x080a8436 in do_begin (call=0x97f97fc, op=0x9705168,
args=0x97f97e0, rho=0xb64c2b8) at eval.c:1046
#15 0x080a7055 in Rf_eval (e=0x97f97fc, rho=0xb64c2b8) at eval.c:375
#16 0x080a7055 in Rf_eval (e=0x97f9bdc, rho=0xb64c2b8) at eval.c:375
#17 0x080a8436 in do_begin (call=0x97f4ac8, op=0x9705168,
args=0x97f9bc0, rho=0xb64c2b8) at eval.c:1046
#18 0x080a7055 in Rf_eval (e=0x97f4ac8, rho=0xb64c2b8) at eval.c:375
#19 0x080a7301 in Rf_applyClosure (call=0xb64c130, op=0x97f9a8c,
arglist=0xb64c050, rho=0xb65989c,
    suppliedenv=0xb64c0f8) at eval.c:566
#20 0x080cd2fb in applyMethod (call=0xb64c130, op=0x97f9a8c,
args=0xb64c050, rho=0xb65989c, newrho=0xb64c0f8)
    at objects.c:119
#21 0x080cd985 in Rf_usemethod (generic=0x81a1f2b "[", obj=0xb3ebbc0,
call=0x9a668f0, args=0xb64c050,
    rho=0xb65989c, callrho=0xb65989c, defrho=0x96f6338, ans=0xfef58728)
at objects.c:326
#22 0x080a994d in Rf_DispatchOrEval (call=0x9a668f0, op=0x9705050,
generic=0x81a1f2b "[", args=0xb64bffc,
    rho=0xb65989c, ans=0xfef58728, dropmissing=0, argsevald=1) at
eval.c:1719
#23 0x0811d5aa in do_subset (call=0x9a668f0, op=0x9705050,
args=0x9a66944, rho=0xb65989c) at subset.c:504
#24 0x080a7055 in Rf_eval (e=0x9a668f0, rho=0xb65989c) at eval.c:375
#25 0x080a8bc3 in do_set (call=0x9a66880, op=0x9705264, args=0x9a668b8,
rho=0xb65989c) at eval.c:1271
#26 0x080a7055 in Rf_eval (e=0x9a66880, rho=0xb65989c) at eval.c:375
---Type <return> to continue, or q <return> to quit---
#27 0x080a8436 in do_begin (call=0x9a67184, op=0x9705168,
args=0x9a66864, rho=0xb65989c) at eval.c:1046
#28 0x080a7055 in Rf_eval (e=0x9a67184, rho=0xb65989c) at eval.c:375
#29 0x080a7055 in Rf_eval (e=0x9a66c44, rho=0xb65989c) at eval.c:375
#30 0x080a8436 in do_begin (call=0x9a66b10, op=0x9705168,
args=0x9a66c28, rho=0xb65989c) at eval.c:1046
#31 0x080a7055 in Rf_eval (e=0x9a66b10, rho=0xb65989c) at eval.c:375
#32 0x080a7301 in Rf_applyClosure (call=0xb659730, op=0x9a67900,
arglist=0xb65a558, rho=0xb65966c,
    suppliedenv=0xb6596f8) at eval.c:566
#33 0x080cd2fb in applyMethod (call=0xb659730, op=0x9a67900,
args=0xb65a558, rho=0xb65966c, newrho=0xb6596f8)
    at objects.c:119
#34 0x080cd985 in Rf_usemethod (generic=0x9b1f300 "model.matrix",
obj=0xb415a64, call=0x9a6783c,
    args=0x96f6338, rho=0xb65966c, callrho=0xb415bb4, defrho=0xa038100,
ans=0xfef59288) at objects.c:326
#35 0x080cdd45 in do_usemethod (call=0x9a6783c, op=0x9713ca8,
args=0x9a67874, env=0xb65966c) at objects.c:389
#36 0x080a7055 in Rf_eval (e=0x9a6783c, rho=0xb65966c) at eval.c:375
#37 0x080a7301 in Rf_applyClosure (call=0xa9e8b04, op=0x9a677cc,
arglist=0xb65a558, rho=0xb415bb4,
    suppliedenv=0x96f6338) at eval.c:566
#38 0x080a6e60 in Rf_eval (e=0xa9e8b04, rho=0xb415bb4) at eval.c:410
#39 0x080a6d8b in Rf_eval (e=0xb65a328, rho=0xb65a408) at eval.c:354
#40 0x080a6d8b in Rf_eval (e=0xb65a4b0, rho=0xb65a408) at eval.c:354
#41 0x0806c791 in do_bind (call=0x9733fb8, op=0x9707e44, args=0xb65a4cc,
env=0xb65a408) at bind.c:877
#42 0x080cd029 in do_internal (call=0xa20, op=0x9706418, args=0x9733fd4,
env=0xb65a408) at names.c:1057
#43 0x080a7055 in Rf_eval (e=0x9733f2c, rho=0xb65a408) at eval.c:375
#44 0x080a8436 in do_begin (call=0x9734060, op=0x9705168,
args=0x9733f10, rho=0xb65a408) at eval.c:1046
#45 0x080a7055 in Rf_eval (e=0x9734060, rho=0xb65a408) at eval.c:375
#46 0x080a7301 in Rf_applyClosure (call=0xa9e8acc, op=0x9733e30,
arglist=0xb65a344, rho=0xb415bb4,
    suppliedenv=0x96f6338) at eval.c:566
#47 0x080a6e60 in Rf_eval (e=0xa9e8acc, rho=0xb415bb4) at eval.c:410
#48 0x080a8d8a in Rf_evalList (el=0xa9e8ab0, rho=0xb415bb4) at
eval.c:1360
#49 0x080a6f7d in Rf_eval (e=0xa9e8a94, rho=0xb415bb4) at eval.c:396
#50 0x080a8d8a in Rf_evalList (el=0xa9e8a78, rho=0xb415bb4) at
eval.c:1360
#51 0x080a97c0 in Rf_DispatchOrEval (call=0xa9e9868, op=0x9706788,
generic=0x8181b21 "c", args=0xa9e9884,
    rho=0xb415bb4, ans=0xfef5a278, dropmissing=1, argsevald=0) at
eval.c:1735
---Type <return> to continue, or q <return> to quit---
#52 0x0806be69 in do_c (call=0xa9e9868, op=0x9706788, args=0xa9e9884,
env=0xb415bb4) at bind.c:562
#53 0x080a7055 in Rf_eval (e=0xa9e9868, rho=0xb415bb4) at eval.c:375
#54 0x080a8bc3 in do_set (call=0xa9e9814, op=0x9705264, args=0xa9e9830,
rho=0xb415bb4) at eval.c:1271
#55 0x080a7055 in Rf_eval (e=0xa9e9814, rho=0xb415bb4) at eval.c:375
#56 0x080a8436 in do_begin (call=0xa9e9d28, op=0x9705168,
args=0xa9e97f8, rho=0xb415bb4) at eval.c:1046
#57 0x080a7055 in Rf_eval (e=0xa9e9d28, rho=0xb415bb4) at eval.c:375
#58 0x080a755d in R_execClosure (call=0xb4167f0, op=0xae393ac,
arglist=0xb4162a4, rho=0xb631a38,
    newrho=0xb415bb4) at eval.c:651
#59 0x080a7813 in R_execMethod (op=0xae393ac, rho=0xb41649c) at
eval.c:753
#60 0x00f86763 in R_standardGeneric (fname=0xacd6c40, ev=0xb41649c,
fdef=0xb41657c)
    at methods_list_dispatch.c:610
#61 0x080cf6dc in do_standardGeneric (call=0xacd89d8, op=0x9713c00,
args=0xb41657c, env=0xb41649c)
    at objects.c:982
#62 0x080a6fe3 in Rf_eval (e=0xacd89d8, rho=0xb41649c) at eval.c:398
#63 0x080a7301 in Rf_applyClosure (call=0xb4167f0, op=0xaca9a34,
arglist=0xb4162a4, rho=0xb631a38,
    suppliedenv=0x96f6338) at eval.c:566
#64 0x080a6e60 in Rf_eval (e=0xb4167f0, rho=0xb631a38) at eval.c:410
#65 0x080a948c in do_eval (call=0x98a581c, op=0x97100c8, args=0xb416138,
rho=0xb4160e4) at eval.c:1541
#66 0x080cd029 in do_internal (call=0x2f00, op=0x9706418,
args=0xb416138, env=0xb4160e4) at names.c:1057
#67 0x080a7055 in Rf_eval (e=0x98a5790, rho=0xb4160e4) at eval.c:375
#68 0x080a7301 in Rf_applyClosure (call=0xa9ecfd8, op=0x98a6644,
arglist=0xb41603c, rho=0xb4179c0,
    suppliedenv=0x96f6338) at eval.c:566
#69 0x080a6e60 in Rf_eval (e=0xa9ecfd8, rho=0xb4179c0) at eval.c:410
#70 0x080a8d8a in Rf_evalList (el=0xa9ecfbc, rho=0xb4179c0) at
eval.c:1360
#71 0x080a6f7d in Rf_eval (e=0xa9ecf84, rho=0xb4179c0) at eval.c:396
#72 0x080a8436 in do_begin (call=0xa9ecd54, op=0x9705168,
args=0xa9ecf68, rho=0xb4179c0) at eval.c:1046
#73 0x080a7055 in Rf_eval (e=0xa9ecd54, rho=0xb4179c0) at eval.c:375
#74 0x080a755d in R_execClosure (call=0xb41889c, op=0xae39770,
arglist=0xb418094, rho=0xb631a38,
    newrho=0xb4179c0) at eval.c:651
#75 0x080a7813 in R_execMethod (op=0xae39770, rho=0xb41828c) at
eval.c:753
#76 0x00f86763 in R_standardGeneric (fname=0xacd6c40, ev=0xb41828c,
fdef=0xb418388)
---Type <return> to continue, or q <return> to quit---
    at methods_list_dispatch.c:610
#77 0x080cf6dc in do_standardGeneric (call=0xacd89d8, op=0x9713c00,
args=0xb418388, env=0xb41828c)
    at objects.c:982
#78 0x080a6fe3 in Rf_eval (e=0xacd89d8, rho=0xb41828c) at eval.c:398
#79 0x080a7301 in Rf_applyClosure (call=0xb41889c, op=0xaca9a34,
arglist=0xb418094, rho=0xb631a38,
    suppliedenv=0x96f6338) at eval.c:566
#80 0x080a6e60 in Rf_eval (e=0xb41889c, rho=0xb631a38) at eval.c:410
#81 0x080a948c in do_eval (call=0x98a581c, op=0x97100c8, args=0xb417f28,
rho=0xb418e68) at eval.c:1541
#82 0x080cd029 in do_internal (call=0x2f00, op=0x9706418,
args=0xb417f28, env=0xb418e68) at names.c:1057
#83 0x080a7055 in Rf_eval (e=0x98a5790, rho=0xb418e68) at eval.c:375
#84 0x080a7301 in Rf_applyClosure (call=0xa9dd984, op=0x98a6644,
arglist=0xb418dc0, rho=0xb631498,
    suppliedenv=0x96f6338) at eval.c:566
#85 0x080a6e60 in Rf_eval (e=0xa9dd984, rho=0xb631498) at eval.c:410
#86 0x080a8d8a in Rf_evalList (el=0xa9dd968, rho=0xb631498) at
eval.c:1360
#87 0x080a6f7d in Rf_eval (e=0xa9dd930, rho=0xb631498) at eval.c:396
#88 0x080a8436 in do_begin (call=0xa9de368, op=0x9705168,
args=0xa9dd914, rho=0xb631498) at eval.c:1046
#89 0x080a7055 in Rf_eval (e=0xa9de368, rho=0xb631498) at eval.c:375
#90 0x080a755d in R_execClosure (call=0xafc54a0, op=0xae3994c,
arglist=0xb631a8c, rho=0xb631a38,
    newrho=0xb631498) at eval.c:651
#91 0x080a7813 in R_execMethod (op=0xae3994c, rho=0xb631c84) at
eval.c:753
#92 0x00f86763 in R_standardGeneric (fname=0xacd6c40, ev=0xb631c84,
fdef=0xb630dd0)
    at methods_list_dispatch.c:610
#93 0x080cf6dc in do_standardGeneric (call=0xacd89d8, op=0x9713c00,
args=0xb630dd0, env=0xb631c84)
    at objects.c:982
#94 0x080a6fe3 in Rf_eval (e=0xacd89d8, rho=0xb631c84) at eval.c:398
#95 0x080a7301 in Rf_applyClosure (call=0xafc54a0, op=0xaca9a34,
arglist=0xb631a8c, rho=0xb631a38,
    suppliedenv=0x96f6338) at eval.c:566
#96 0x080a6e60 in Rf_eval (e=0xafc54a0, rho=0xb631a38) at eval.c:410
#97 0x080a8bc3 in do_set (call=0xafc54f4, op=0x9705264, args=0xafc54d8,
rho=0xb631a38) at eval.c:1271
#98 0x080a7055 in Rf_eval (e=0xafc54f4, rho=0xb631a38) at eval.c:375
#99 0x080a8436 in do_begin (call=0xafc5510, op=0x9705168,
args=0xafc552c, rho=0xb631a38) at eval.c:1046
---Type <return> to continue, or q <return> to quit---
#100 0x080a7055 in Rf_eval (e=0xafc5510, rho=0xb631a38) at eval.c:375
#101 0x080a7301 in Rf_applyClosure (call=0xafc5280, op=0xafc5a50,
arglist=0xb631a00, rho=0xafc4c28,
    suppliedenv=0x96f6338) at eval.c:566
#102 0x080a6e60 in Rf_eval (e=0xafc5280, rho=0xafc4c28) at eval.c:410
#103 0x0805f297 in do_lapply (call=0x990c12c, op=0x9711180, args=0x2933,
rho=0xafc4c28) at apply.c:60
#104 0x080cd029 in do_internal (call=0x3480, op=0x9706418,
args=0x990c19c, env=0xafc4c28) at names.c:1057
#105 0x080a7055 in Rf_eval (e=0x990c0a0, rho=0xafc4c28) at eval.c:375
#106 0x080a8bc3 in do_set (call=0x990c04c, op=0x9705264, args=0x990c068,
rho=0xafc4c28) at eval.c:1271
#107 0x080a7055 in Rf_eval (e=0x990c04c, rho=0xafc4c28) at eval.c:375
#108 0x080a8436 in do_begin (call=0x990c43c, op=0x9705168,
args=0x990c030, rho=0xafc4c28) at eval.c:1046
#109 0x080a7055 in Rf_eval (e=0x990c43c, rho=0xafc4c28) at eval.c:375
#110 0x080a7301 in Rf_applyClosure (call=0x99f649c, op=0x990ccb4,
arglist=0xafc4b80, rho=0xafc591c,
    suppliedenv=0x96f6338) at eval.c:566
#111 0x080a6e60 in Rf_eval (e=0x99f649c, rho=0xafc591c) at eval.c:410
#112 0x080a8bc3 in do_set (call=0x99f6448, op=0x9705264, args=0x99f6464,
rho=0xafc591c) at eval.c:1271
#113 0x080a7055 in Rf_eval (e=0x99f6448, rho=0xafc591c) at eval.c:375
#114 0x080a8436 in do_begin (call=0x99f56e4, op=0x9705168,
args=0x99f642c, rho=0xafc591c) at eval.c:1046
#115 0x080a7055 in Rf_eval (e=0x99f56e4, rho=0xafc591c) at eval.c:375
#116 0x080a7301 in Rf_applyClosure (call=0xafc5778, op=0x99f6e1c,
arglist=0xafc583c, rho=0x9716e0c,
    suppliedenv=0x96f6338) at eval.c:566
#117 0x080a6e60 in Rf_eval (e=0xafc5778, rho=0x9716e0c) at eval.c:410
#118 0x080a8bc3 in do_set (call=0xafc57cc, op=0x9705264, args=0xafc57b0,
rho=0x9716e0c) at eval.c:1271
#119 0x080a7055 in Rf_eval (e=0xafc57cc, rho=0x9716e0c) at eval.c:375
#120 0x080c1ba7 in Rf_ReplIteration (rho=0x9716e0c,
savestack=-1070969512, browselevel=0, state=0xfef5dd40)
    at main.c:250
#121 0x080c1d4f in R_ReplConsole (rho=0x9716e0c, savestack=0,
browselevel=0) at main.c:298
#122 0x080c25d3 in run_Rmainloop () at main.c:656
#123 0x0812478c in main (ac=1, av=0xfef5e254) at system.c:99

end of backtrace.



From mandevip at uaslp.mx  Mon Sep 13 16:57:51 2004
From: mandevip at uaslp.mx (Peter B. Mandeville)
Date: Mon, 13 Sep 2004 09:57:51 -0500
Subject: [R] lmList for glm
Message-ID: <003301c499a2$0abb3850$2609e094@uaslpja8gmj09a>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040913/fa9cc3c6/attachment.pl

From pardelle at yahoo.fr  Mon Sep 13 17:00:02 2004
From: pardelle at yahoo.fr (=?iso-8859-1?q?bournery=20alexandre?=)
Date: Mon, 13 Sep 2004 17:00:02 +0200 (CEST)
Subject: [R] Smoothing using the kernel distribution
Message-ID: <20040913150002.91578.qmail@web25209.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040913/8f01e75f/attachment.pl

From pardelle at yahoo.fr  Mon Sep 13 17:02:48 2004
From: pardelle at yahoo.fr (=?iso-8859-1?q?bournery=20alexandre?=)
Date: Mon, 13 Sep 2004 17:02:48 +0200 (CEST)
Subject: [R] Smoothing using the kernel distribution
Message-ID: <20040913150248.11910.qmail@web25207.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040913/020d90a5/attachment.pl

From bates at stat.wisc.edu  Mon Sep 13 17:03:24 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 13 Sep 2004 10:03:24 -0500
Subject: [R] Spare some CPU cycles for testing lme?
In-Reply-To: <1095085863.2322.40.camel@localhost.localdomain>
References: <ci44e3$96d$1@sea.gmane.org>
	<1095085863.2322.40.camel@localhost.localdomain>
Message-ID: <4145B6BC.1060004@stat.wisc.edu>

Marc Schwartz wrote:
> On Mon, 2004-09-13 at 07:40, Frank Samuelson wrote:
> 
>>If anyone has a few extra CPU cycles to spare,
>>I'd appreciate it if you could verify a problem that I
>>have encountered.  Run the code
>>below and tell me if it crashes your R before
>>completion.
>>
>>library(lme4)
>>data(bdf)
>>dump<-sapply( 1:50000, function(i) {
>>     fm <- lme(langPOST ~ IQ.ver.cen + avg.IQ.ver.cen, data = bdf,
>>               random = ~ IQ.ver.cen | schoolNR);
>>     cat("  ",i,"\r")
>>     0
>>})
>>
>>The above code simply reruns the example from the
>>lme help page a large number of times and returns a bunch
>>of 0's, so you'll need to have the lme4 and Matrix
>>packages installed.  It might take a while to complete,
>>but you can always nice it and let it run.
>>
>>I'm attempting to bootstrap lme() from the lme4 package,
>>but it causes a
>>segfault after a couple hundred iterations.  This happens on
>>my Linux x86 RedHat 7.3, 8.0, 9.0, FC1 systems w/ 1.9.1
>>and devel 2.0.0 (not all possible combinations actually
>>tested.)
>>I've communicated w/ Douglas Bates about this and he
>>doesn't appear to have the problem.
>>
>>Thanks for any help.
>>
>>-Frank
>>
> 
> 
> Replicated here on FC 2 running:
> 
> Version 1.9.1 Patched (2004-09-07)
> 
> The backtrace from gdb follows. It would probably make sense to move
> this thread to r-devel. As you can see, it got through 10,546 runs
> before segfaulting.
> 
> cc: to Doug.
> 
> HTH,
> 
> Marc Schwartz
> 
> 
> 
>>dump<-sapply( 1:50000, function(i) {
> 
> +      fm <- lme(langPOST ~ IQ.ver.cen + avg.IQ.ver.cen, data = bdf,
> +                random = ~ IQ.ver.cen | schoolNR);
> +      cat("  ",i,"\r")
> +      0
> + })
>    10546
> Program received signal SIGSEGV, Segmentation fault.
> 0x00982242 in _int_free () from /lib/tls/libc.so.6
> (gdb) bt
> #0  0x00982242 in _int_free () from /lib/tls/libc.so.6
> #1  0x0098373b in free () from /lib/tls/libc.so.6
> #2  0x080c4003 in ReleaseLargeFreeVectors () at memory.c:695
> #3  0x080c5999 in RunGenCollect (size_needed=1144) at memory.c:1282
> #4  0x080c7084 in R_gc_internal (size_needed=1144) at memory.c:1933
> #5  0x080c6b67 in Rf_allocVector (type=16, length=2287) at memory.c:1788
> #6  0x0809b6b1 in Rf_duplicate (s=0xbed5d40) at duplicate.c:150
> #7  0x0809b335 in Rf_duplicate (s=0xb64a3bc) at duplicate.c:100
> #8  0x0809b517 in Rf_duplicate (s=0xbed15a8) at duplicate.c:142
> #9  0x0809b777 in Rf_duplicate (s=0xb3f6048) at duplicate.c:137
> #10 0x080a796d in EnsureLocal (symbol=0x9719f38, rho=0xb64c2b8) at
> eval.c:765
> #11 0x080a8691 in evalseq (expr=0x9719f38, rho=0xb64c2b8, forcelocal=1,
> tmploc=0xb64a340) at eval.c:1135
> #12 0x080a8847 in applydefine (call=0x97f9818, op=0x9705264,
> args=0x97f9834, rho=0xb64c2b8) at eval.c:1199
> #13 0x080a7055 in Rf_eval (e=0x97f9818, rho=0xb64c2b8) at eval.c:375
> #14 0x080a8436 in do_begin (call=0x97f97fc, op=0x9705168,
> args=0x97f97e0, rho=0xb64c2b8) at eval.c:1046
> #15 0x080a7055 in Rf_eval (e=0x97f97fc, rho=0xb64c2b8) at eval.c:375
> #16 0x080a7055 in Rf_eval (e=0x97f9bdc, rho=0xb64c2b8) at eval.c:375
> #17 0x080a8436 in do_begin (call=0x97f4ac8, op=0x9705168,
> args=0x97f9bc0, rho=0xb64c2b8) at eval.c:1046
> #18 0x080a7055 in Rf_eval (e=0x97f4ac8, rho=0xb64c2b8) at eval.c:375
> #19 0x080a7301 in Rf_applyClosure (call=0xb64c130, op=0x97f9a8c,
> arglist=0xb64c050, rho=0xb65989c,
>     suppliedenv=0xb64c0f8) at eval.c:566
> #20 0x080cd2fb in applyMethod (call=0xb64c130, op=0x97f9a8c,
> args=0xb64c050, rho=0xb65989c, newrho=0xb64c0f8)
>     at objects.c:119
> #21 0x080cd985 in Rf_usemethod (generic=0x81a1f2b "[", obj=0xb3ebbc0,
> call=0x9a668f0, args=0xb64c050,
>     rho=0xb65989c, callrho=0xb65989c, defrho=0x96f6338, ans=0xfef58728)
> at objects.c:326
> #22 0x080a994d in Rf_DispatchOrEval (call=0x9a668f0, op=0x9705050,
> generic=0x81a1f2b "[", args=0xb64bffc,
>     rho=0xb65989c, ans=0xfef58728, dropmissing=0, argsevald=1) at
> eval.c:1719
> #23 0x0811d5aa in do_subset (call=0x9a668f0, op=0x9705050,
> args=0x9a66944, rho=0xb65989c) at subset.c:504
> #24 0x080a7055 in Rf_eval (e=0x9a668f0, rho=0xb65989c) at eval.c:375
> #25 0x080a8bc3 in do_set (call=0x9a66880, op=0x9705264, args=0x9a668b8,
> rho=0xb65989c) at eval.c:1271
> #26 0x080a7055 in Rf_eval (e=0x9a66880, rho=0xb65989c) at eval.c:375
> ---Type <return> to continue, or q <return> to quit---
> #27 0x080a8436 in do_begin (call=0x9a67184, op=0x9705168,
> args=0x9a66864, rho=0xb65989c) at eval.c:1046
> #28 0x080a7055 in Rf_eval (e=0x9a67184, rho=0xb65989c) at eval.c:375
> #29 0x080a7055 in Rf_eval (e=0x9a66c44, rho=0xb65989c) at eval.c:375
> #30 0x080a8436 in do_begin (call=0x9a66b10, op=0x9705168,
> args=0x9a66c28, rho=0xb65989c) at eval.c:1046
> #31 0x080a7055 in Rf_eval (e=0x9a66b10, rho=0xb65989c) at eval.c:375
> #32 0x080a7301 in Rf_applyClosure (call=0xb659730, op=0x9a67900,
> arglist=0xb65a558, rho=0xb65966c,
>     suppliedenv=0xb6596f8) at eval.c:566
> #33 0x080cd2fb in applyMethod (call=0xb659730, op=0x9a67900,
> args=0xb65a558, rho=0xb65966c, newrho=0xb6596f8)
>     at objects.c:119
> #34 0x080cd985 in Rf_usemethod (generic=0x9b1f300 "model.matrix",
> obj=0xb415a64, call=0x9a6783c,
>     args=0x96f6338, rho=0xb65966c, callrho=0xb415bb4, defrho=0xa038100,
> ans=0xfef59288) at objects.c:326
> #35 0x080cdd45 in do_usemethod (call=0x9a6783c, op=0x9713ca8,
> args=0x9a67874, env=0xb65966c) at objects.c:389
> #36 0x080a7055 in Rf_eval (e=0x9a6783c, rho=0xb65966c) at eval.c:375
> #37 0x080a7301 in Rf_applyClosure (call=0xa9e8b04, op=0x9a677cc,
> arglist=0xb65a558, rho=0xb415bb4,
>     suppliedenv=0x96f6338) at eval.c:566
> #38 0x080a6e60 in Rf_eval (e=0xa9e8b04, rho=0xb415bb4) at eval.c:410
> #39 0x080a6d8b in Rf_eval (e=0xb65a328, rho=0xb65a408) at eval.c:354
> #40 0x080a6d8b in Rf_eval (e=0xb65a4b0, rho=0xb65a408) at eval.c:354
> #41 0x0806c791 in do_bind (call=0x9733fb8, op=0x9707e44, args=0xb65a4cc,
> env=0xb65a408) at bind.c:877
> #42 0x080cd029 in do_internal (call=0xa20, op=0x9706418, args=0x9733fd4,
> env=0xb65a408) at names.c:1057
> #43 0x080a7055 in Rf_eval (e=0x9733f2c, rho=0xb65a408) at eval.c:375
> #44 0x080a8436 in do_begin (call=0x9734060, op=0x9705168,
> args=0x9733f10, rho=0xb65a408) at eval.c:1046
> #45 0x080a7055 in Rf_eval (e=0x9734060, rho=0xb65a408) at eval.c:375
> #46 0x080a7301 in Rf_applyClosure (call=0xa9e8acc, op=0x9733e30,
> arglist=0xb65a344, rho=0xb415bb4,
>     suppliedenv=0x96f6338) at eval.c:566
> #47 0x080a6e60 in Rf_eval (e=0xa9e8acc, rho=0xb415bb4) at eval.c:410
> #48 0x080a8d8a in Rf_evalList (el=0xa9e8ab0, rho=0xb415bb4) at
> eval.c:1360
> #49 0x080a6f7d in Rf_eval (e=0xa9e8a94, rho=0xb415bb4) at eval.c:396
> #50 0x080a8d8a in Rf_evalList (el=0xa9e8a78, rho=0xb415bb4) at
> eval.c:1360
> #51 0x080a97c0 in Rf_DispatchOrEval (call=0xa9e9868, op=0x9706788,
> generic=0x8181b21 "c", args=0xa9e9884,
>     rho=0xb415bb4, ans=0xfef5a278, dropmissing=1, argsevald=0) at
> eval.c:1735
> ---Type <return> to continue, or q <return> to quit---
> #52 0x0806be69 in do_c (call=0xa9e9868, op=0x9706788, args=0xa9e9884,
> env=0xb415bb4) at bind.c:562
> #53 0x080a7055 in Rf_eval (e=0xa9e9868, rho=0xb415bb4) at eval.c:375
> #54 0x080a8bc3 in do_set (call=0xa9e9814, op=0x9705264, args=0xa9e9830,
> rho=0xb415bb4) at eval.c:1271
> #55 0x080a7055 in Rf_eval (e=0xa9e9814, rho=0xb415bb4) at eval.c:375
> #56 0x080a8436 in do_begin (call=0xa9e9d28, op=0x9705168,
> args=0xa9e97f8, rho=0xb415bb4) at eval.c:1046
> #57 0x080a7055 in Rf_eval (e=0xa9e9d28, rho=0xb415bb4) at eval.c:375
> #58 0x080a755d in R_execClosure (call=0xb4167f0, op=0xae393ac,
> arglist=0xb4162a4, rho=0xb631a38,
>     newrho=0xb415bb4) at eval.c:651
> #59 0x080a7813 in R_execMethod (op=0xae393ac, rho=0xb41649c) at
> eval.c:753
> #60 0x00f86763 in R_standardGeneric (fname=0xacd6c40, ev=0xb41649c,
> fdef=0xb41657c)
>     at methods_list_dispatch.c:610
> #61 0x080cf6dc in do_standardGeneric (call=0xacd89d8, op=0x9713c00,
> args=0xb41657c, env=0xb41649c)
>     at objects.c:982
> #62 0x080a6fe3 in Rf_eval (e=0xacd89d8, rho=0xb41649c) at eval.c:398
> #63 0x080a7301 in Rf_applyClosure (call=0xb4167f0, op=0xaca9a34,
> arglist=0xb4162a4, rho=0xb631a38,
>     suppliedenv=0x96f6338) at eval.c:566
> #64 0x080a6e60 in Rf_eval (e=0xb4167f0, rho=0xb631a38) at eval.c:410
> #65 0x080a948c in do_eval (call=0x98a581c, op=0x97100c8, args=0xb416138,
> rho=0xb4160e4) at eval.c:1541
> #66 0x080cd029 in do_internal (call=0x2f00, op=0x9706418,
> args=0xb416138, env=0xb4160e4) at names.c:1057
> #67 0x080a7055 in Rf_eval (e=0x98a5790, rho=0xb4160e4) at eval.c:375
> #68 0x080a7301 in Rf_applyClosure (call=0xa9ecfd8, op=0x98a6644,
> arglist=0xb41603c, rho=0xb4179c0,
>     suppliedenv=0x96f6338) at eval.c:566
> #69 0x080a6e60 in Rf_eval (e=0xa9ecfd8, rho=0xb4179c0) at eval.c:410
> #70 0x080a8d8a in Rf_evalList (el=0xa9ecfbc, rho=0xb4179c0) at
> eval.c:1360
> #71 0x080a6f7d in Rf_eval (e=0xa9ecf84, rho=0xb4179c0) at eval.c:396
> #72 0x080a8436 in do_begin (call=0xa9ecd54, op=0x9705168,
> args=0xa9ecf68, rho=0xb4179c0) at eval.c:1046
> #73 0x080a7055 in Rf_eval (e=0xa9ecd54, rho=0xb4179c0) at eval.c:375
> #74 0x080a755d in R_execClosure (call=0xb41889c, op=0xae39770,
> arglist=0xb418094, rho=0xb631a38,
>     newrho=0xb4179c0) at eval.c:651
> #75 0x080a7813 in R_execMethod (op=0xae39770, rho=0xb41828c) at
> eval.c:753
> #76 0x00f86763 in R_standardGeneric (fname=0xacd6c40, ev=0xb41828c,
> fdef=0xb418388)
> ---Type <return> to continue, or q <return> to quit---
>     at methods_list_dispatch.c:610
> #77 0x080cf6dc in do_standardGeneric (call=0xacd89d8, op=0x9713c00,
> args=0xb418388, env=0xb41828c)
>     at objects.c:982
> #78 0x080a6fe3 in Rf_eval (e=0xacd89d8, rho=0xb41828c) at eval.c:398
> #79 0x080a7301 in Rf_applyClosure (call=0xb41889c, op=0xaca9a34,
> arglist=0xb418094, rho=0xb631a38,
>     suppliedenv=0x96f6338) at eval.c:566
> #80 0x080a6e60 in Rf_eval (e=0xb41889c, rho=0xb631a38) at eval.c:410
> #81 0x080a948c in do_eval (call=0x98a581c, op=0x97100c8, args=0xb417f28,
> rho=0xb418e68) at eval.c:1541
> #82 0x080cd029 in do_internal (call=0x2f00, op=0x9706418,
> args=0xb417f28, env=0xb418e68) at names.c:1057
> #83 0x080a7055 in Rf_eval (e=0x98a5790, rho=0xb418e68) at eval.c:375
> #84 0x080a7301 in Rf_applyClosure (call=0xa9dd984, op=0x98a6644,
> arglist=0xb418dc0, rho=0xb631498,
>     suppliedenv=0x96f6338) at eval.c:566
> #85 0x080a6e60 in Rf_eval (e=0xa9dd984, rho=0xb631498) at eval.c:410
> #86 0x080a8d8a in Rf_evalList (el=0xa9dd968, rho=0xb631498) at
> eval.c:1360
> #87 0x080a6f7d in Rf_eval (e=0xa9dd930, rho=0xb631498) at eval.c:396
> #88 0x080a8436 in do_begin (call=0xa9de368, op=0x9705168,
> args=0xa9dd914, rho=0xb631498) at eval.c:1046
> #89 0x080a7055 in Rf_eval (e=0xa9de368, rho=0xb631498) at eval.c:375
> #90 0x080a755d in R_execClosure (call=0xafc54a0, op=0xae3994c,
> arglist=0xb631a8c, rho=0xb631a38,
>     newrho=0xb631498) at eval.c:651
> #91 0x080a7813 in R_execMethod (op=0xae3994c, rho=0xb631c84) at
> eval.c:753
> #92 0x00f86763 in R_standardGeneric (fname=0xacd6c40, ev=0xb631c84,
> fdef=0xb630dd0)
>     at methods_list_dispatch.c:610
> #93 0x080cf6dc in do_standardGeneric (call=0xacd89d8, op=0x9713c00,
> args=0xb630dd0, env=0xb631c84)
>     at objects.c:982
> #94 0x080a6fe3 in Rf_eval (e=0xacd89d8, rho=0xb631c84) at eval.c:398
> #95 0x080a7301 in Rf_applyClosure (call=0xafc54a0, op=0xaca9a34,
> arglist=0xb631a8c, rho=0xb631a38,
>     suppliedenv=0x96f6338) at eval.c:566
> #96 0x080a6e60 in Rf_eval (e=0xafc54a0, rho=0xb631a38) at eval.c:410
> #97 0x080a8bc3 in do_set (call=0xafc54f4, op=0x9705264, args=0xafc54d8,
> rho=0xb631a38) at eval.c:1271
> #98 0x080a7055 in Rf_eval (e=0xafc54f4, rho=0xb631a38) at eval.c:375
> #99 0x080a8436 in do_begin (call=0xafc5510, op=0x9705168,
> args=0xafc552c, rho=0xb631a38) at eval.c:1046
> ---Type <return> to continue, or q <return> to quit---
> #100 0x080a7055 in Rf_eval (e=0xafc5510, rho=0xb631a38) at eval.c:375
> #101 0x080a7301 in Rf_applyClosure (call=0xafc5280, op=0xafc5a50,
> arglist=0xb631a00, rho=0xafc4c28,
>     suppliedenv=0x96f6338) at eval.c:566
> #102 0x080a6e60 in Rf_eval (e=0xafc5280, rho=0xafc4c28) at eval.c:410
> #103 0x0805f297 in do_lapply (call=0x990c12c, op=0x9711180, args=0x2933,
> rho=0xafc4c28) at apply.c:60
> #104 0x080cd029 in do_internal (call=0x3480, op=0x9706418,
> args=0x990c19c, env=0xafc4c28) at names.c:1057
> #105 0x080a7055 in Rf_eval (e=0x990c0a0, rho=0xafc4c28) at eval.c:375
> #106 0x080a8bc3 in do_set (call=0x990c04c, op=0x9705264, args=0x990c068,
> rho=0xafc4c28) at eval.c:1271
> #107 0x080a7055 in Rf_eval (e=0x990c04c, rho=0xafc4c28) at eval.c:375
> #108 0x080a8436 in do_begin (call=0x990c43c, op=0x9705168,
> args=0x990c030, rho=0xafc4c28) at eval.c:1046
> #109 0x080a7055 in Rf_eval (e=0x990c43c, rho=0xafc4c28) at eval.c:375
> #110 0x080a7301 in Rf_applyClosure (call=0x99f649c, op=0x990ccb4,
> arglist=0xafc4b80, rho=0xafc591c,
>     suppliedenv=0x96f6338) at eval.c:566
> #111 0x080a6e60 in Rf_eval (e=0x99f649c, rho=0xafc591c) at eval.c:410
> #112 0x080a8bc3 in do_set (call=0x99f6448, op=0x9705264, args=0x99f6464,
> rho=0xafc591c) at eval.c:1271
> #113 0x080a7055 in Rf_eval (e=0x99f6448, rho=0xafc591c) at eval.c:375
> #114 0x080a8436 in do_begin (call=0x99f56e4, op=0x9705168,
> args=0x99f642c, rho=0xafc591c) at eval.c:1046
> #115 0x080a7055 in Rf_eval (e=0x99f56e4, rho=0xafc591c) at eval.c:375
> #116 0x080a7301 in Rf_applyClosure (call=0xafc5778, op=0x99f6e1c,
> arglist=0xafc583c, rho=0x9716e0c,
>     suppliedenv=0x96f6338) at eval.c:566
> #117 0x080a6e60 in Rf_eval (e=0xafc5778, rho=0x9716e0c) at eval.c:410
> #118 0x080a8bc3 in do_set (call=0xafc57cc, op=0x9705264, args=0xafc57b0,
> rho=0x9716e0c) at eval.c:1271
> #119 0x080a7055 in Rf_eval (e=0xafc57cc, rho=0x9716e0c) at eval.c:375
> #120 0x080c1ba7 in Rf_ReplIteration (rho=0x9716e0c,
> savestack=-1070969512, browselevel=0, state=0xfef5dd40)
>     at main.c:250
> #121 0x080c1d4f in R_ReplConsole (rho=0x9716e0c, savestack=0,
> browselevel=0) at main.c:298
> #122 0x080c25d3 in run_Rmainloop () at main.c:656
> #123 0x0812478c in main (ac=1, av=0xfef5e254) at system.c:99
> 
> end of backtrace.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

As Frank said, I have been unable to get this example to segfault on a 
Debian system.  It definitely looks like memory problems so I would 
suggest running it with gctorture set.  However, you should use a 
machine that you won't need for several days :-)



From bournery at mnhn.fr  Mon Sep 13 17:05:57 2004
From: bournery at mnhn.fr (Alexandre Bournery)
Date: Mon, 13 Sep 2004 17:05:57 +0200
Subject: [R] Kernel distribution
Message-ID: <5.0.2.1.2.20040913170427.00b4ff10@cimrs1.mnhn.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040913/d1e3e72a/attachment.pl

From msylvest at uclink.berkeley.edu  Mon Sep 13 17:34:03 2004
From: msylvest at uclink.berkeley.edu (Matthew David Sylvester)
Date: Mon, 13 Sep 2004 08:34:03 -0700
Subject: [R] bagplot()
Message-ID: <web-1865915@calmail-be1.berkeley.edu>

Hello, 
I saw a little discussion about this in the archives, but it was unclear to me whether someone had 
submitted a port to R of the Splus bagplot() function.  If so, does anyone know where I could get 
it?  Thanks.
Best,
Matt



From ripley at stats.ox.ac.uk  Mon Sep 13 17:36:45 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Sep 2004 16:36:45 +0100 (BST)
Subject: [R] Smoothing using the kernel distribution
In-Reply-To: <20040913150248.11910.qmail@web25207.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.44.0409131635450.19598-100000@gannet.stats>

Since you have now asked this three times:

Yes, yes, yes.  R comes with a pacakge called KernSmooth, for example.

On Mon, 13 Sep 2004, bournery alexandre wrote:

> Does anyone can tell me if R sofware can be used for the smoothing using
> the kernel distribution ?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Sep 13 17:49:31 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Sep 2004 16:49:31 +0100 (BST)
Subject: [R] bagplot()
In-Reply-To: <web-1865915@calmail-be1.berkeley.edu>
Message-ID: <Pine.LNX.4.44.0409131645200.19598-100000@gannet.stats>

There is no bagplot function in S-PLUS.

There is one by Rousseeuw et al for S at

http://www.agoras.ua.ac.be/Locdept.htm

and a reply in the archives about the problems of porting at:

http://maths.newcastle.edu.au/~rking/R/help/03b/4916.html

My guess is that like several other cases, R porting has exposed bugs in
the original code.

On Mon, 13 Sep 2004, Matthew David Sylvester wrote:

> I saw a little discussion about this in the archives, but it was unclear
> to me whether someone had submitted a port to R of the Splus bagplot()
> function.  If so, does anyone know where I could get it?  Thanks.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gunter.berton at gene.com  Mon Sep 13 18:13:34 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 13 Sep 2004 09:13:34 -0700
Subject: [R] Variable Importance in pls: R or B? (and in glpls?)
In-Reply-To: <41443D35.8090606@gmx.ch>
Message-ID: <200409131613.i8DGDYlY026746@volta.gene.com>

Christoph:

I noted that there were not a great number of people leaping to reply. One
reason, I suspect, is that there's really NO GOOD ANSWER to this question.
First, there is a huge literature on this -- it's related to variable
selection in regression and shrinkage estimates, but, in general,
parsimonious model building; second, as Ron Wehrens already noted, when
variables are correlated -- which could have as much to do with the vagaries
of the sampling as to real physical causality -- the whole notion of
"variable importance" is problematic. Fact is, **any** attempt to rank the
contributions of particular variables to PLS components from undesigned data
(the usual case) is fraught with hazard. For that reason, it is perhaps best
to view pls as merely a way of developing a good predictor, not as a way to
uncover causal relationships. I know this is often unsatisfying to
scientists trying to build parsimonious mechanistic models (= physical
theories), especially as there is quite often little likelihood that the
data are representative of any underlying population and therefore capable
of predicting anything, but it is the statistical reality.

For a more informed, more interesting, and more eloquent discussion of these
and related issues, you might look up Leo Breiman's writings on his web site
and his way of trying to assess "variable importance" in his Random Forest
methodology, which is available in the package randomForest on CRAN. (I make
no claim about the effectiveness of this approach -- only that it is clearly
different way of approaching the issue that clearly reveals the dilemmas).

Cheers,

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Christoph Lehmann
> Sent: Sunday, September 12, 2004 5:13 AM
> To: Ron Wehrens; r-help at stat.math.ethz.ch
> Subject: [R] Variable Importance in pls: R or B? (and in glpls?)
> 
> Dear R-users, dear Ron
> 
> I use pls from the pls.pcr package for classification. Since 
> I need to 
> know which variables are most influential onto the classification 
> performance, what criteria shall I look at:
> 
> a) B, the array of regression coefficients for a certain 
> model (means a 
> certain number of latent variables) (and: squared or absolute values?)
> 
> OR
> 
> b) the weight matrix RR (or R in the De Jong publication; in Ding & 
> Gentleman this is the P Matrix and called 'loadings')? (and again: 
> squared or absolute values?)
> 
> 
> 
> and what about glpls (glpls1a) ?
> shall I look at the 'coefficients' (regression coefficients)?
> 
> Thanks for clarification
> 
> Christoph
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

From ramasamy at cancer.org.uk  Mon Sep 13 18:18:32 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 13 Sep 2004 17:18:32 +0100
Subject: [R] Kernel distribution
In-Reply-To: <5.0.2.1.2.20040913170427.00b4ff10@cimrs1.mnhn.fr>
References: <5.0.2.1.2.20040913170427.00b4ff10@cimrs1.mnhn.fr>
Message-ID: <1095092312.3070.24.camel@vpn202001.lif.icnet.uk>

See ?density or try help.search("kernel")


On Mon, 2004-09-13 at 16:05, Alexandre Bournery wrote:
> Hello,
> 
> Does anyone could tell me if R sofware can be used for smoothing, using the 
> kernel distribution ?
> I will appreciate
> Alex
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From xiangli at gila-fw.bioengr.uic.edu  Mon Sep 13 18:26:02 2004
From: xiangli at gila-fw.bioengr.uic.edu (xiang li)
Date: Mon, 13 Sep 2004 11:26:02 -0500 (CDT)
Subject: [R] How to show the symbol of Angstrom ?
Message-ID: <Pine.LNX.4.44.0409131121150.705-100000@gila-fw.bioengr.uic.edu>

Also, I am wondering if there is any source where the expressions of 
many symbols are collected.
Thanks you very much!!!

Li, Xiang(Sean)



From andy_liaw at merck.com  Mon Sep 13 18:34:05 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 13 Sep 2004 12:34:05 -0400
Subject: [R] bagplot()
Message-ID: <3A822319EB35174CA3714066D590DCD504AF838B@usrymx25.merck.com>

There's now a vioplot package on CRAN, if that's what you're looking for.

Andy

> From: Matthew David Sylvester
> 
> Hello, 
> I saw a little discussion about this in the archives, but it 
> was unclear to me whether someone had 
> submitted a port to R of the Splus bagplot() function.  If 
> so, does anyone know where I could get 
> it?  Thanks.
> Best,
> Matt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From igual at mat.uji.es  Mon Sep 13 18:57:33 2004
From: igual at mat.uji.es (Fuensanta Saura Igual)
Date: Mon, 13 Sep 2004 18:57:33 +0200
Subject: [R] R-help
Message-ID: <1095094653.4145d17dc133d@webmail.uji.es>



Dear all,
Does anyone know how to read files with .dbf extension?

Thanks for your time.



From spencer.graves at pdf.com  Mon Sep 13 19:00:19 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 13 Sep 2004 10:00:19 -0700
Subject: [R] an integration question
In-Reply-To: <00eb01c49975$16535580$5c13070a@PROCGEN>
References: <00eb01c49975$16535580$5c13070a@PROCGEN>
Message-ID: <4145D223.9050404@pdf.com>

      I'm not certain what you mean by "primitive", but for x <= 7.5, by 
my computation, the integral is 5*exp(-1.5)*(1-exp(-0.2*x)).  For x = 
7.5, this is  0.8667155, which is exactly what I got from "integrate".  
For x > 7.5, the integral is this constant plus exp(-3)*(x-7.5). 

      hope this helps.  spencer graves

Vito Muggeo wrote:

>Dear all,
>I'm stuck on a problem concerning integration..Results from the analytical
>expression and numerical approximation (as returned by integrate()) do not
>match.
>It probably depends on some error of mine, so apologizes for this off-topic
>question.
>
>I'm interested in computing the integral of f where:
>f<-function(x){exp(-3-.2*pmin(x-7.5,0))}
>x<-seq(0,15,length=50)
>plot(x, f(x),type="l")
>
>Using the integrate() function, I get reasonable results
>a<-sapply(x, function(xx)integrate(f,0,xx)[[1]])
>plot(x, a,type="l")
>
>Using analytical expression, the primitive of f is (or should be..)
>F<-function(x){exp(-3-.2*pmin(x-7.5,0))/(-.2*I(x<7.5))}
>plot(x,(F(x)-F(0)), type="l")
>
>The problem is that for x>7.5 the denominator (-.2*I(x<7.5)) is zero and
>then the primitive function F(.) goes to infinity. On the other hand
>integrate() provides finite (as it should be, I believe) output. For x<7.5
>everything works.
>
>  
>
>>F(10)-F(0)
>>    
>>
>[1] -Inf
>..
>  
>
>>integrate(f,0,10)
>>    
>>
>0.9911831 with absolute error < 1.1e-14
>  
>
>>F(5)-F(0)
>>    
>>
>[1] 0.7052258
>..
>  
>
>>integrate(f,0,5)
>>    
>>
>0.7052258 with absolute error < 7.8e-15
>
>Hence I think there is an error in the expression of H(.), but I can not
>figure out where it is..Please can anyone help me? I would like to get an
>analytical expression for F.
>
>Many thanks,
>
>vito
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From spencer.graves at pdf.com  Mon Sep 13 19:16:24 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 13 Sep 2004 10:16:24 -0700
Subject: [R] R-help
In-Reply-To: <1095094653.4145d17dc133d@webmail.uji.es>
References: <1095094653.4145d17dc133d@webmail.uji.es>
Message-ID: <4145D5E8.4000308@pdf.com>

      Did you do a search at "www.r-project.org" -> "R site search"?  
Searching for ".dbf" there just now exposed a "read.shape" function in 
the maptools package. 

      hope this helps. 
p.s.  Did you read the posting guide! 
"http://www.R-project.org/posting-guide.html"?  Tips provided there may 
help you answer questions like this for yourself.  Failing that, they 
may also help you formulate your questions so you are more likely to get 
useful replies.  Buena suerte.

Fuensanta Saura Igual wrote:

>Dear all,
>Does anyone know how to read files with .dbf extension?
>
>Thanks for your time.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From spencer.graves at pdf.com  Mon Sep 13 19:27:26 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 13 Sep 2004 10:27:26 -0700
Subject: [R] lmList for glm
In-Reply-To: <003301c499a2$0abb3850$2609e094@uaslpja8gmj09a>
References: <003301c499a2$0abb3850$2609e094@uaslpja8gmj09a>
Message-ID: <4145D87E.1040605@pdf.com>

      Have you looked at GLMM in package lme4? 

      hope this helps.  spencer graves
p.s.  Have you read the posting guide! 
"http://www.R-project.org/posting-guide.html"?  It might help you get 
answers to questions like this for yourself quicker than waiting for 
this list to reply.  It may also increase the likelihood that questions 
you do post here get useful answers. 

Peter B. Mandeville wrote:

>Greetings all,
>
>Is there a way to do the equivalent of a lmList (fit separate models for each subject) in the package nlme for a glm? 
>
>Thank you very much,
>
>Peter B.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From ramasamy at cancer.org.uk  Mon Sep 13 19:35:27 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 13 Sep 2004 18:35:27 +0100
Subject: [R] calculating memory usage
Message-ID: <1095096926.3070.118.camel@vpn202001.lif.icnet.uk>

I am comparing two different algorithms in terms of speed and memory
usage. I can calculate the processing time with proc.time() as follows
but am not sure how to calculate the memory usage.

   ptm <- proc.time()
   x <- rnorm(1000000)
   proc.time() - ptm

I would like to be within R itself since I will test the algorithm
several hundred times and in batch mode. So manually looking up 'top'
may not be feasible. help.seach("memory") suggests memory.profile and gc
but I am not sure how to use these.

Sorry if this is a basic question. Thank you.

Regards, Adai



From ripley at stats.ox.ac.uk  Mon Sep 13 19:41:01 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Sep 2004 18:41:01 +0100 (BST)
Subject: [R] R-help
In-Reply-To: <4145D5E8.4000308@pdf.com>
Message-ID: <Pine.LNX.4.44.0409131836090.22630-100000@gannet.stats>

I believe .dbf files are more commonly DBase files, in which case see 
package RODBC.

On Mon, 13 Sep 2004, Spencer Graves wrote:

>       Did you do a search at "www.r-project.org" -> "R site search"?  
> Searching for ".dbf" there just now exposed a "read.shape" function in 
> the maptools package. 
> 
>       hope this helps. 
> p.s.  Did you read the posting guide! 
> "http://www.R-project.org/posting-guide.html"?  Tips provided there may 
> help you answer questions like this for yourself.  Failing that, they 
> may also help you formulate your questions so you are more likely to get 
> useful replies.  Buena suerte.
> 
> Fuensanta Saura Igual wrote:
> 
> >Dear all,
> >Does anyone know how to read files with .dbf extension?
> >
> >Thanks for your time.
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >  
> >
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Sep 13 19:47:28 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Sep 2004 18:47:28 +0100 (BST)
Subject: [R] calculating memory usage
In-Reply-To: <1095096926.3070.118.camel@vpn202001.lif.icnet.uk>
Message-ID: <Pine.LNX.4.44.0409131843580.22630-100000@gannet.stats>

On Mon, 13 Sep 2004, Adaikalavan Ramasamy wrote:

> I am comparing two different algorithms in terms of speed and memory
> usage. I can calculate the processing time with proc.time() as follows
> but am not sure how to calculate the memory usage.
> 
>    ptm <- proc.time()
>    x <- rnorm(1000000)
>    proc.time() - ptm

Hmm ... see ?system.time!

> I would like to be within R itself since I will test the algorithm
> several hundred times and in batch mode. So manually looking up 'top'
> may not be feasible. help.seach("memory") suggests memory.profile and gc
> but I am not sure how to use these.

I don't think you can.  You can find out how much memory R is using NOW, 
but not the peak memory usage during a calculation.  Nor is that 
particularly relevant, as it depends on what was gone on before, the word 
length of the platform and the garbage collection settings.

On Windows, starting in a clean session, calling gc() and memory.size(), 
then calling your code and memory.size(max=TRUE) will give you a fair 
idea, but `top' indicates some Unix-alike.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gavin.simpson at ucl.ac.uk  Mon Sep 13 19:47:22 2004
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 13 Sep 2004 18:47:22 +0100
Subject: [R] generalized eigenvalues - porting code using eig() from Matlab
 to R
Message-ID: <4145DD2A.7010405@ucl.ac.uk>

Dear list,

I am porting some Matlab routines to R. I am looking for the equivalent 
function in R for the Matlab function eig(), such that eig(A, B) 
<quote>produces a diagonal matrix D of generalized eigenvalues and a 
full matrix V whose columns are the corresponding eigenvectors so that 
A*V = B*V*D</quote>[1].

More specifically, I want to find the eigenvalues and eigenvectors of 
eig(ZKZt, diag(K1)) where:

ZKZt
              [,1]          [,2]         [,3]          [,4]
[1,]  0.024326360 -0.0087060425 -0.029307513 -0.0131484613
[2,] -0.001316161  0.0028641451  0.003249924  0.0003892546
[3,] -0.016591044  0.0061132182  0.021493284  0.0083083670
[4,] -0.006419155 -0.0002713207  0.004564305  0.0044508397

and

diag(K1)
           [,1]      [,2]      [,3]      [,4]
[1,] 0.2307692 0.0000000 0.0000000 0.0000000
[2,] 0.0000000 0.2307692 0.0000000 0.0000000
[3,] 0.0000000 0.0000000 0.3076923 0.0000000
[4,] 0.0000000 0.0000000 0.0000000 0.2307692

How would I go about doing this in R?

Thanks in advance,

Gavin

[1] 
http://www.mathworks.com/access/helpdesk/help/techdoc/ref/eig.html?cmdname=eig
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From rossini at blindglobe.net  Mon Sep 13 20:06:07 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 13 Sep 2004 11:06:07 -0700
Subject: [R] SJava, Client X11
In-Reply-To: <Pine.LNX.4.44.0409131132420.15725-100000@gannet.stats> (Brian
	Ripley's message of "Mon, 13 Sep 2004 11:37:01 +0100 (BST)")
References: <Pine.LNX.4.44.0409131132420.15725-100000@gannet.stats>
Message-ID: <85fz5m6o34.fsf@servant.blindglobe.net>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> In theory Omegahat has its own mailing lists. 

Possibly not in practice.  I can't remember which machine (ETH or
UWisc) they were once located on, either.  I'm sure someone will let
me know, preferably in public, so that we can know where to direct
folks.  I unsubscribed from them a while back because of the level of
spam originating from them at the point.

   http://www.omegahat.org/mailman/listinfo 

reports:

  Mailman CGI error!!!

   The Mailman CGI wrapper encountered a fatal error. This entry is
  being stored in your syslog: 
  Group mismatch error.  Mailman expected the CGI
  wrapper script to be executed as group "nobody", but
  the system's web server executed the CGI script as
  group "apache".  Try tweaking the web server to run the
  script as group "nobody", or re-run configure, 
  providing the command line option `--with-cgi-gid=apache'.

Nor is there any up-to-date contact information on the homepage, or on
the first few that I looked at.  It really needs an update.

(and I'm posting here, since I couldn't resubscribe to the lists in
the first place).  Perhaps someone in the large core group of Omegahat
developers could update the site?

best,
-tony

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From ripley at stats.ox.ac.uk  Mon Sep 13 20:37:56 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Sep 2004 19:37:56 +0100 (BST)
Subject: [R] generalized eigenvalues - porting code using eig() from
	Matlab to R
In-Reply-To: <4145DD2A.7010405@ucl.ac.uk>
Message-ID: <Pine.LNX.4.44.0409131935030.22746-100000@gannet.stats>

On Mon, 13 Sep 2004, Gavin Simpson wrote:

> I am porting some Matlab routines to R. I am looking for the equivalent 
> function in R for the Matlab function eig(), such that eig(A, B) 
> <quote>produces a diagonal matrix D of generalized eigenvalues and a 
> full matrix V whose columns are the corresponding eigenvectors so that 
> A*V = B*V*D</quote>[1].

So they are eigenvalues/vectors of B^{-1}A provided B is invertible, as in
your example.

> More specifically, I want to find the eigenvalues and eigenvectors of 
> eig(ZKZt, diag(K1)) where:

...

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From davidr at rhotrading.com  Mon Sep 13 21:45:32 2004
From: davidr at rhotrading.com (davidr@rhotrading.com)
Date: Mon, 13 Sep 2004 14:45:32 -0500
Subject: [R] Can I find the datetime an object was last assigned to/saved?
Message-ID: <12AE52872B5C5348BE5CF47C707FF53A326EFF@rhosvr02.rhotrading.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040913/1acd177d/attachment.pl

From fws4 at cdrh.fda.gov  Mon Sep 13 22:11:33 2004
From: fws4 at cdrh.fda.gov (Frank Samuelson)
Date: Mon, 13 Sep 2004 16:11:33 -0400
Subject: [R] .Random.seed in R-devel
Message-ID: <ci4us5$ral$1@sea.gmane.org>

I'm running R-2.0.0 (yesterday's snapshot)in its own
directory, and everything
works great, except:

 >    .Random.seed
Error: Object ".Random.seed" not found

Does 2.0.0 not use .Random.seed for saving, etc,
like it says in the help page?

Thanks for any help.

-Frank



From andy_liaw at merck.com  Mon Sep 13 22:18:45 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 13 Sep 2004 16:18:45 -0400
Subject: [R] .Random.seed in R-devel
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8394@usrymx25.merck.com>

Is this from a clean session, before set.seed() or any generator is called?
Both S-PLUS and R, I believe, do the same thing: .Random.seed only exists
_after_ set.seed() or some generator is called.

Andy

> From: Frank Samuelson
> 
> I'm running R-2.0.0 (yesterday's snapshot)in its own
> directory, and everything
> works great, except:
> 
>  >    .Random.seed
> Error: Object ".Random.seed" not found
> 
> Does 2.0.0 not use .Random.seed for saving, etc,
> like it says in the help page?
> 
> Thanks for any help.
> 
> -Frank
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ripley at stats.ox.ac.uk  Mon Sep 13 22:21:28 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Sep 2004 21:21:28 +0100 (BST)
Subject: [R] .Random.seed in R-devel
In-Reply-To: <ci4us5$ral$1@sea.gmane.org>
Message-ID: <Pine.LNX.4.44.0409132118250.30054-100000@gannet.stats>

On Mon, 13 Sep 2004, Frank Samuelson wrote:

> I'm running R-2.0.0 (yesterday's snapshot)in its own
> directory, and everything
> works great, except:
> 
>  >    .Random.seed
> Error: Object ".Random.seed" not found
> 
> Does 2.0.0 not use .Random.seed for saving, etc,
> like it says in the help page?

`Like it says on the help page'!

     Initially, there is no seed;  a new one is created from the
     current time when one is required.  Hence, different sessions will
     give different simulation results, by default.

      '.Random.seed' is an integer vector, containing the random number
     generator (RNG) *state* for random number generation in R.  It can
     be saved and restored, but should not be altered by the user.

So .Random.seed does not exist until the state does.  It will after 
runif(1).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Mon Sep 13 22:22:13 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Sep 2004 22:22:13 +0200
Subject: [R] .Random.seed in R-devel
In-Reply-To: <ci4us5$ral$1@sea.gmane.org>
References: <ci4us5$ral$1@sea.gmane.org>
Message-ID: <x2acvtkjgq.fsf@biostat.ku.dk>

Frank Samuelson <fws4 at cdrh.fda.gov> writes:

> I'm running R-2.0.0 (yesterday's snapshot)in its own
> directory, and everything
> works great, except:
> 
>  >    .Random.seed
> Error: Object ".Random.seed" not found
> 
> Does 2.0.0 not use .Random.seed for saving, etc,
> like it says in the help page?
> 
> Thanks for any help.

Did you check that in any other version of R?

[pd at titmouse pd]$ R --vanilla

R : Copyright 2004, The R Foundation for Statistical Computing
Version 1.9.1  (2004-06-21), ISBN 3-900051-00-3
....
> .Random.seed
Error: Object ".Random.seed" not found

Hint: Not set until needed...
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From besweez at gmail.com  Mon Sep 13 22:33:23 2004
From: besweez at gmail.com (Bryan Tseng)
Date: Mon, 13 Sep 2004 16:33:23 -0400
Subject: [R] R in Linux Redhat 9.0
Message-ID: <c38a6c40409131333318f7d0d@mail.gmail.com>

Hi, my name is Bryan and I just installed R on my Redhat 9.0. I
imported the key from the net as directed, and tested the integreity
of the rpm package- it was fine. I then went ahead and installed the
i386.rpm package and the installation was carried to completion.

However, now I have a hard time finding and opening R, which I just
installed. Does someone know what's going on? I'm a relatively new
user to linux, but I don't think I did anything wrong in term of
installing the software. But I don't know.

Thank you for your help, I really appreciate it.

Bryan



From fws4 at cdrh.fda.gov  Mon Sep 13 22:39:08 2004
From: fws4 at cdrh.fda.gov (Frank Samuelson)
Date: Mon, 13 Sep 2004 16:39:08 -0400
Subject: [R] .Random.seed in R-devel
In-Reply-To: <Pine.LNX.4.44.0409132118250.30054-100000@gannet.stats>
References: <ci4us5$ral$1@sea.gmane.org>
	<Pine.LNX.4.44.0409132118250.30054-100000@gannet.stats>
Message-ID: <ci50fr$vpo$1@sea.gmane.org>

Oh.  I guess I had a different definition of
"when one is required" than the help page. :)

Thanks.


Prof Brian Ripley wrote:
> 
> `Like it says on the help page'!
> 
>      Initially, there is no seed;  a new one is created from the
>      current time when one is required.  Hence, different sessions will
>      give different simulation results, by default.
> 
> So .Random.seed does not exist until the state does.  It will after 
> runif(1).
>



From fws4 at cdrh.fda.gov  Mon Sep 13 22:46:12 2004
From: fws4 at cdrh.fda.gov (Frank Samuelson)
Date: Mon, 13 Sep 2004 16:46:12 -0400
Subject: [R] R in Linux Redhat 9.0
In-Reply-To: <c38a6c40409131333318f7d0d@mail.gmail.com>
References: <c38a6c40409131333318f7d0d@mail.gmail.com>
Message-ID: <ci50t3$uf$1@sea.gmane.org>

rpm -ql R
should show you your installed files.

Did you try typing "R"?


Bryan Tseng wrote:
> Hi, my name is Bryan and I just installed R on my Redhat 9.0. I
> imported the key from the net as directed, and tested the integreity
> of the rpm package- it was fine. I then went ahead and installed the
> i386.rpm package and the installation was carried to completion.
> 
> However, now I have a hard time finding and opening R, which I just
> installed. Does someone know what's going on? I'm a relatively new
> user to linux, but I don't think I did anything wrong in term of
> installing the software. But I don't know.
> 
> Thank you for your help, I really appreciate it.
> 
> Bryan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From umalvarez at fata.unam.mx  Mon Sep 13 22:56:20 2004
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Mon, 13 Sep 2004 15:56:20 -0500 (CDT)
Subject: [R] R in Linux Redhat 9.0
In-Reply-To: <c38a6c40409131333318f7d0d@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0409131555110.17178-100000@athena.fata.unam.mx>

Hi!

Just open a terminal and type 'R'.

Read the R-Intro will help you a lot.

Regards.

On Mon, 13 Sep 2004, Bryan Tseng wrote:

> Hi, my name is Bryan and I just installed R on my Redhat 9.0. I
> imported the key from the net as directed, and tested the integreity
> of the rpm package- it was fine. I then went ahead and installed the
> i386.rpm package and the installation was carried to completion.
> 
> However, now I have a hard time finding and opening R, which I just
> installed. Does someone know what's going on? I'm a relatively new
> user to linux, but I don't think I did anything wrong in term of
> installing the software. But I don't know.
> 
> Thank you for your help, I really appreciate it.
> 
> Bryan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
u-m-a-l-v-a-r-e-z AT f-a-t-a DOT u-n-a-m DOT m-x



From shuangge at biostat.wisc.edu  Mon Sep 13 23:03:57 2004
From: shuangge at biostat.wisc.edu (Shuangge Ma)
Date: Mon, 13 Sep 2004 16:03:57 -0500 (CDT)
Subject: [R] maximization subject to constaint
Message-ID: <Pine.GSO.4.58.0409131559560.25120@altair.biostat.wisc.edu>

Hello:
I have been trying to program the following maximization problem and would
definitely welcome some help.

the target function: sum_{i} f(alpha, beta'X_{i}),
                     where alpha and beta are unknown d-dim parameter,
                     f is a known function an X_{i} are i.i.d. r.v.
I need to maximize the above sum, under the constaint that:
                     beta'X_{i}+alpha<=1, for i=1,...,n.

For one dimension, it is kind of trivial. What should I do with high
dimensional alpha and beta?  Thanks for your time,

Shuangge Ma, Ph.D.



From christof.bigler at colorado.edu  Tue Sep 14 01:47:06 2004
From: christof.bigler at colorado.edu (Christof Bigler)
Date: Mon, 13 Sep 2004 17:47:06 -0600
Subject: [R] Measures of association for ordinal data
Message-ID: <381978A5-05DF-11D9-B59C-000A27D7D440@colorado.edu>

In a classification problem with ordinal data (classes 1 - 4), I used 
multidimensional optimization to maximize gamma (Goodman's measure of 
association) between observations and predictions. This resulted in the 
following frequency table (rows = observations, columns = predictions):

	     1         2        3        4      sum
   1      16993    1    4854    27    21875
   2       1308     0    1691   120    3119
   3       1427     1    4587   434    6449
   4        289      0    1965   593    2847
sum   20017   2   13097  1174

Predictions for class 1 are fairly good, however, classes 2 and 4 are 
underrepresented and class 3 is overrepresented, as shown by the 
marginal sums.
Is there any measure of association implemented in R that takes into 
account the prevalence of certain classes?

Thanks for your help!

Christof



From tpapp at Princeton.EDU  Tue Sep 14 01:47:23 2004
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Mon, 13 Sep 2004 19:47:23 -0400
Subject: [R] Spare some CPU cycles for testing lme?
In-Reply-To: <ci44e3$96d$1@sea.gmane.org>
References: <ci44e3$96d$1@sea.gmane.org>
Message-ID: <20040913234723.GA1702@tpapp>

On Mon, Sep 13, 2004 at 08:40:15AM -0400, Frank Samuelson wrote:

> If anyone has a few extra CPU cycles to spare,
> I'd appreciate it if you could verify a problem that I
> have encountered.  Run the code
> below and tell me if it crashes your R before
> completion.
> 
> library(lme4)
> data(bdf)
> dump<-sapply( 1:50000, function(i) {
>     fm <- lme(langPOST ~ IQ.ver.cen + avg.IQ.ver.cen, data = bdf,
>               random = ~ IQ.ver.cen | schoolNR);
>     cat("  ",i,"\r")
>     0
> })

Hi,

It ran smoothly on my installation.

> version  
         _                      
platform powerpc-apple-darwin6.8
arch     powerpc                
os       darwin6.8              
system   powerpc, darwin6.8     
status                          
major    1                      
minor    9.1                    
year     2004                   
month    06                     
day      21                     
language R                      

Typical lines from top (if it helps anything; around 45-50k
iterations):

1225 R.bin       90.7%  2:55:12   1    62  1164  71.7M+ 13.7M  66.6M+  228M+
1225 R.bin       78.6%  3:18:27   1    62  1606  81.3M+ 13.7M  75.5M+  234M+

Best,

Tamas



From Toby.Patterson at csiro.au  Tue Sep 14 02:29:31 2004
From: Toby.Patterson at csiro.au (Toby.Patterson@csiro.au)
Date: Tue, 14 Sep 2004 10:29:31 +1000
Subject: [R] R CMD SHLIB setup problem...
Message-ID: <C4178DC99E08604EA5E2BDB989F09380025D0CCF@extas2-hba.tas.csiro.au>

All, 
When I try and compile a shared library (on WinXP) I get the following
error:  

E:\data\proj>R CMD SHLIB toy_dll.c
Makevars:1: *** missing separator.  Stop.

Has someone else had this error and fixed it? 

This code compiles and works fine on Linux (fedora core 2). Everything
was working fine under R1.8.1 but I've broken something when I upgraded
to R1.9.1. 

So I am assuming something weird has happened in the windows paths etc.
If anyone has some tips as to where to look I'd be extremely grateful.
I've been through the path and environment variables etc many times but
can't see where the error is. Though I realize it's likely to be staring
me in the face...

Thanks 

Toby 

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    9.1            
year     2004           
month    06             
day      21             
language R



From p.murrell at auckland.ac.nz  Tue Sep 14 02:39:32 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 14 Sep 2004 12:39:32 +1200
Subject: [R] How to show the symbol of Angstrom ?
References: <Pine.LNX.4.44.0409131121150.705-100000@gila-fw.bioengr.uic.edu>
Message-ID: <41463DC4.1090202@stat.auckland.ac.nz>

Hi


xiang li wrote:
> Also, I am wondering if there is any source where the expressions of 
> many symbols are collected.
> Thanks you very much!!!


(Assuming you mean draw the angstrom symbol on a plot ...)

There are several ways:

(i) Specify the character code in octal.  Assuming ISO Latin 1 encoding, 
something like ...
   plot(1, type="n")
   text(1, 1, "\305")
... or ...
   grid.newpage()
   grid.text("\305")
... should work.  That should be ok on default setups for Windows and 
Unix.  On the Mac it might have to be "\201" (untested)  See, e.g., 
http://czyborra.com/charsets/iso8859.html#ISO-8859-1 (Unix)
http://www.microsoft.com/typography/unicode/1252.gif (Windows)
http://kodeks.uni-bamberg.de/Computer/CodePages/MacStd.htm (Mac)
for other standard "symbols".

(ii) Use a mathematical expression.  This won't look as good because the 
ring and the A are not a single coherent glyph, but it should work 
"everywhere" ...
   plot(1, type="n")
   text(1, 1, expression(ring(A)))
... or ...
   grid.newpage()
   grid.text(expression(ring(A)))
... demo(plotmath) shows the range of things you can do with this approach.

(iii) Use a hershey font (again, should work on all platforms and 
encodings) ...
   plot(1, type="n")
   text(1, 1, "\\oA", vfont=c("sans serif", "plain"))
... or ...
   grid.newpage()
   grid.text("\\oA", gp=gpar(fontfamily="HersheySans"))
... demo(Hershey) shows the symbols available with this approach.

Hope that helps.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From murdoch at stats.uwo.ca  Tue Sep 14 02:58:28 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 13 Sep 2004 20:58:28 -0400
Subject: [R] R CMD SHLIB setup problem...
In-Reply-To: <C4178DC99E08604EA5E2BDB989F09380025D0CCF@extas2-hba.tas.csiro.au>
References: <C4178DC99E08604EA5E2BDB989F09380025D0CCF@extas2-hba.tas.csiro.au>
Message-ID: <ocgck0lp6nuqnj5a7khchle4gr79tj1fdt@4ax.com>

On Tue, 14 Sep 2004 10:29:31 +1000, <Toby.Patterson at csiro.au> wrote:

>All, 
>When I try and compile a shared library (on WinXP) I get the following
>error:  
>
>E:\data\proj>R CMD SHLIB toy_dll.c
>Makevars:1: *** missing separator.  Stop.
>
>Has someone else had this error and fixed it? 

Haven't had the error, but the usual suspects are:

 - You're getting the wrong make.  Follow the readme.packages
instructions for setting up your path, and make sure "make --version"
tells you you're running GNU Make.

 - Something has messed up your Makevars file.  Does it look normal in
a reasonable text editor?

Duncan Murdoch



From tpapp at Princeton.EDU  Tue Sep 14 03:17:50 2004
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Mon, 13 Sep 2004 21:17:50 -0400
Subject: [R] as.integer(TRUE)
Message-ID: <20040914011750.GA1848@tpapp>

The fact that as.integer(TRUE) is 1 (and that for FALSE, it gives
zero) is a really nice feature, eg when constructing piecewise
functions (for example, as in -x*(x<0)+x*(x>=0)) and for many other
things.

Since I haven't found a reference about this, I just wanted to ask
whether this is officialy part of the language or just a side effect
(ie I want to know whether it is here to stay and if it is prudent to
use this).

Thanks

Tamas



From Toby.Patterson at csiro.au  Tue Sep 14 03:26:28 2004
From: Toby.Patterson at csiro.au (Toby.Patterson@csiro.au)
Date: Tue, 14 Sep 2004 11:26:28 +1000
Subject: [R] R CMD SHLIB setup problem...
Message-ID: <C4178DC99E08604EA5E2BDB989F09380025D0CD0@extas2-hba.tas.csiro.au>

I've compared my Makevars to someone else's and we both have the same
thing:

CFLAGS+= -I$(RHOME)/src/gnuwin32/graphapp

So I assume this is correct? (And the compiler is definitely GNU make). 

When I tried to recompile another bit of C code I got the following
error:

make: *** No rule to make target `C:/PROGRA~1/R/rw1081/src/include/R.h',
needed by `filter_norm.o'.
 Stop.

So it looks like its looking for the R 1.8.1 versions of R.h. I just
can't work out why. I've dumped SET to a file and checked that nothing
on the path or any of the environment variables point to the old
directory. It all looks OK to me. 

As far as I am aware nothing here uses the windows registry so I am
assuming there shouldn't be any problems there.  

Cheers 
T. 

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
Sent: Tuesday, September 14, 2004 10:58 AM
To: Patterson, Toby (Marine, Hobart)
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] R CMD SHLIB setup problem...

On Tue, 14 Sep 2004 10:29:31 +1000, <Toby.Patterson at csiro.au> wrote:

>All, 
>When I try and compile a shared library (on WinXP) I get the following
>error:  
>
>E:\data\proj>R CMD SHLIB toy_dll.c
>Makevars:1: *** missing separator.  Stop.
>
>Has someone else had this error and fixed it? 

Haven't had the error, but the usual suspects are:

 - You're getting the wrong make.  Follow the readme.packages
instructions for setting up your path, and make sure "make --version"
tells you you're running GNU Make.

 - Something has messed up your Makevars file.  Does it look normal in
a reasonable text editor?

Duncan Murdoch



From tpapp at Princeton.EDU  Tue Sep 14 04:37:40 2004
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Mon, 13 Sep 2004 22:37:40 -0400
Subject: [R] drawing on axes
Message-ID: <20040914023740.GA1998@tpapp>

Hi,

I would like to make certain portions of axis lines thicker (as Tufte
suggests).  How can I draw on axes?  I only need a couple of line
segments on the left and bottom one.

Thanks

Tamas



From fchamu at gmail.com  Tue Sep 14 06:06:40 2004
From: fchamu at gmail.com (Francisco Chamu)
Date: Tue, 14 Sep 2004 00:06:40 -0400
Subject: [R] Signs of loadings from princomp on Windows
Message-ID: <ce17a70f04091321067574fb33@mail.gmail.com>

I start a clean session of R 1.9.1 on Windows and I run the following code:

> library(MASS)
> data(painters)
> pca.painters <- princomp(painters[ ,1:4])
> loadings(pca.painters)

Loadings:
            Comp.1 Comp.2 Comp.3 Comp.4
Composition  0.484 -0.376  0.784 -0.101
Drawing      0.424  0.187 -0.280 -0.841
Colour      -0.381 -0.845 -0.211 -0.310
Expression   0.664 -0.330 -0.513  0.432

               Comp.1 Comp.2 Comp.3 Comp.4
SS loadings      1.00   1.00   1.00   1.00
Proportion Var   0.25   0.25   0.25   0.25
Cumulative Var   0.25   0.50   0.75   1.00
> 

However, if I rerun the same analysis, the loadings of the first 
component have the opposite sign (see below), why is that?  I have
read the note
in the princomp help that says

    "The signs of the columns of the loadings and scores are arbitrary,
     and so may differ between different programs for PCA, and even
     between different builds of R."
     
However, I still would expect the same signs for two runs in the same session.

> pca.painters <- princomp(painters[ ,1:4])
> loadings(pca.painters)

Loadings:
            Comp.1 Comp.2 Comp.3 Comp.4
Composition -0.484 -0.376  0.784 -0.101
Drawing     -0.424  0.187 -0.280 -0.841
Colour       0.381 -0.845 -0.211 -0.310
Expression  -0.664 -0.330 -0.513  0.432

               Comp.1 Comp.2 Comp.3 Comp.4
SS loadings      1.00   1.00   1.00   1.00
Proportion Var   0.25   0.25   0.25   0.25
Cumulative Var   0.25   0.50   0.75   1.00
> 
> R.version 
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    9.1            
year     2004           
month    06             
day      21             
language R              
> 

BTW, I have tried the same in R 1.9.1 on Debian and I can't reproduce
what I see
on Windows.  In fact all the runs give the same as the second run on Windows.

-Francisco



From Lorenz.Gygax at fat.admin.ch  Tue Sep 14 07:42:22 2004
From: Lorenz.Gygax at fat.admin.ch (Lorenz.Gygax@fat.admin.ch)
Date: Tue, 14 Sep 2004 07:42:22 +0200
Subject: [R] drawing on axes
Message-ID: <BF74FADD4B44554CA7E53D0B5242CD6A01FC6148@evd-s7014.evd.admin.ch>


> I would like to make certain portions of axis lines thicker (as Tufte
> suggests).  How can I draw on axes?  I only need a couple of line
> segments on the left and bottom one.

How about:

plot (1, 1, xlim= c (-10, 10), bty= 'n')
axis (1, at= c (-10, -5), labels= FALSE, tick= T, lwd= 5, tck= 0)
axis (1, at= c (0, 3), labels= FALSE, tick= T, lwd= 5, tck= 0)
axis (2, at= c (0.8, 1), labels= FALSE, tick= T, lwd= 5, tck= 0)

Cheers, Lorenz
- 
Lorenz Gygax
Tel: +41 (0)52 368 33 84 / lorenz.gygax at fat.admin.ch      
Centre for proper housing of ruminants and pigs
Swiss Federal Veterinary Office



From prophecy at corpranet.net  Tue Sep 14 13:25:03 2004
From: prophecy at corpranet.net (Justace Clutter)
Date: Tue, 14 Sep 2004 06:25:03 -0500
Subject: [R] Excel TDIST and TINV
Message-ID: <1095161103.10080.3.camel@localhost>

Hello all...

	I am really new to statistics and I am trying to figure out a way to
apply Chauvenet's criterion using the t-distribution on a set of numbers
in perl.  I was unable to find a TDIST and TINV function for perl.  I am
getting these functions from Excel.  So, I figured that I would install
R and call it from perl, overkill for what I need I know.  I am having a
hard time figuring out how to mimick the Excel TDIST and TINV functions
in R.  Can somebody give me a hand with this?  Thanks in advance.

-- 
Justace Clutter <prophecy at corpranet.net>



From ripley at stats.ox.ac.uk  Tue Sep 14 08:10:50 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Sep 2004 07:10:50 +0100 (BST)
Subject: [R] Signs of loadings from princomp on Windows
In-Reply-To: <ce17a70f04091321067574fb33@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0409140709500.8690-100000@gannet.stats>

I get the second set each time, on Windows, using the build from CRAN.
Which BLAS are you using?

On Tue, 14 Sep 2004, Francisco Chamu wrote:

> I start a clean session of R 1.9.1 on Windows and I run the following code:
> 
> > library(MASS)
> > data(painters)
> > pca.painters <- princomp(painters[ ,1:4])
> > loadings(pca.painters)
> 
> Loadings:
>             Comp.1 Comp.2 Comp.3 Comp.4
> Composition  0.484 -0.376  0.784 -0.101
> Drawing      0.424  0.187 -0.280 -0.841
> Colour      -0.381 -0.845 -0.211 -0.310
> Expression   0.664 -0.330 -0.513  0.432
> 
>                Comp.1 Comp.2 Comp.3 Comp.4
> SS loadings      1.00   1.00   1.00   1.00
> Proportion Var   0.25   0.25   0.25   0.25
> Cumulative Var   0.25   0.50   0.75   1.00
> > 
> 
> However, if I rerun the same analysis, the loadings of the first 
> component have the opposite sign (see below), why is that?  I have
> read the note
> in the princomp help that says
> 
>     "The signs of the columns of the loadings and scores are arbitrary,
>      and so may differ between different programs for PCA, and even
>      between different builds of R."
>      
> However, I still would expect the same signs for two runs in the same session.
> 
> > pca.painters <- princomp(painters[ ,1:4])
> > loadings(pca.painters)
> 
> Loadings:
>             Comp.1 Comp.2 Comp.3 Comp.4
> Composition -0.484 -0.376  0.784 -0.101
> Drawing     -0.424  0.187 -0.280 -0.841
> Colour       0.381 -0.845 -0.211 -0.310
> Expression  -0.664 -0.330 -0.513  0.432
> 
>                Comp.1 Comp.2 Comp.3 Comp.4
> SS loadings      1.00   1.00   1.00   1.00
> Proportion Var   0.25   0.25   0.25   0.25
> Cumulative Var   0.25   0.50   0.75   1.00
> > 
> > R.version 
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    9.1            
> year     2004           
> month    06             
> day      21             
> language R              
> > 
> 
> BTW, I have tried the same in R 1.9.1 on Debian and I can't reproduce
> what I see
> on Windows.  In fact all the runs give the same as the second run on Windows.
> 
> -Francisco
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Sep 14 08:15:51 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Sep 2004 07:15:51 +0100 (BST)
Subject: [R] as.integer(TRUE)
In-Reply-To: <20040914011750.GA1848@tpapp>
Message-ID: <Pine.LNX.4.44.0409140711010.8690-100000@gannet.stats>

On Mon, 13 Sep 2004, Tamas K Papp wrote:

> The fact that as.integer(TRUE) is 1 (and that for FALSE, it gives
> zero) is a really nice feature, eg when constructing piecewise
> functions (for example, as in -x*(x<0)+x*(x>=0)) and for many other
> things.
> 
> Since I haven't found a reference about this, I just wanted to ask
> whether this is officialy part of the language or just a side effect
> (ie I want to know whether it is here to stay and if it is prudent to
> use this).

Well, you are actually using as.numeric(TRUE) there.  That is documented 
to be 1 (and as.numeric(FALSE) to be 0), in the Blue Book p.100.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Tue Sep 14 08:18:34 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Sep 2004 08:18:34 +0200
Subject: [R] Spare some CPU cycles for testing lme?
In-Reply-To: <20040913234723.GA1702@tpapp>
References: <ci44e3$96d$1@sea.gmane.org> <20040913234723.GA1702@tpapp>
Message-ID: <x2brg9jrut.fsf@biostat.ku.dk>

Tamas K Papp <tpapp at princeton.edu> writes:

> On Mon, Sep 13, 2004 at 08:40:15AM -0400, Frank Samuelson wrote:
> 
> > If anyone has a few extra CPU cycles to spare,
> > I'd appreciate it if you could verify a problem that I
> > have encountered.  Run the code
> > below and tell me if it crashes your R before
> > completion.
> > 
> > library(lme4)
> > data(bdf)
> > dump<-sapply( 1:50000, function(i) {
> >     fm <- lme(langPOST ~ IQ.ver.cen + avg.IQ.ver.cen, data = bdf,
> >               random = ~ IQ.ver.cen | schoolNR);
> >     cat("  ",i,"\r")
> >     0
> > })
> 
> Hi,
> 
> It ran smoothly on my installation.
> 
> > version  
>          _                      
> platform powerpc-apple-darwin6.8

Ditto (SuSE 9.1)

platform x86_64-unknown-linux-gnu
arch     x86_64
os       linux-gnu
system   x86_64, linux-gnu
status   Under development (unstable)
major    2
minor    0.0
year     2004
month    09
day      13
language R


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Tue Sep 14 08:21:38 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Sep 2004 07:21:38 +0100 (BST)
Subject: [R] Excel TDIST and TINV
In-Reply-To: <1095161103.10080.3.camel@localhost>
Message-ID: <Pine.LNX.4.44.0409140716380.8690-100000@gannet.stats>

We are hardly likely to know what those are in Excel.  Possibly pt and qt, 
but see help.search("Student t distribution") for where to look for what R 
provides.

I also do not know what Chauvenet's criterion has to do with Student's t, 
and

http://www.me.umn.edu/education/courses/me8337/chauvenet.txt

states that the latter would be incorrect.


On Tue, 14 Sep 2004, Justace Clutter wrote:

> Hello all...
> 
> 	I am really new to statistics and I am trying to figure out a way to
> apply Chauvenet's criterion using the t-distribution on a set of numbers
> in perl.  I was unable to find a TDIST and TINV function for perl.  I am
> getting these functions from Excel.  So, I figured that I would install
> R and call it from perl, overkill for what I need I know.  I am having a
> hard time figuring out how to mimick the Excel TDIST and TINV functions
> in R.  Can somebody give me a hand with this?  Thanks in advance.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Tue Sep 14 08:34:13 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Sep 2004 08:34:13 +0200
Subject: [R] as.integer(TRUE)
In-Reply-To: <20040914011750.GA1848@tpapp>
References: <20040914011750.GA1848@tpapp>
Message-ID: <x27jqxjr4q.fsf@biostat.ku.dk>

Tamas K Papp <tpapp at princeton.edu> writes:

> The fact that as.integer(TRUE) is 1 (and that for FALSE, it gives
> zero) is a really nice feature, eg when constructing piecewise
> functions (for example, as in -x*(x<0)+x*(x>=0)) and for many other
> things.
> 
> Since I haven't found a reference about this, I just wanted to ask
> whether this is officialy part of the language or just a side effect
> (ie I want to know whether it is here to stay and if it is prudent to
> use this).

I can't find it in the official docs either, but I'm pretty sure that
it is blue book material, and that noone intends to change it.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From pzanis at geol.uoa.gr  Tue Sep 14 08:46:21 2004
From: pzanis at geol.uoa.gr (Prodromos Zanis)
Date: Tue, 14 Sep 2004 09:46:21 +0300
Subject: [R] memory allocation error message
Message-ID: <002701c49a26$8c2c6150$0200a8c0@elassa1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040914/24830faf/attachment.pl

From p.dalgaard at biostat.ku.dk  Tue Sep 14 08:57:28 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Sep 2004 08:57:28 +0200
Subject: [R] memory allocation error message
In-Reply-To: <002701c49a26$8c2c6150$0200a8c0@elassa1>
References: <002701c49a26$8c2c6150$0200a8c0@elassa1>
Message-ID: <x2r7p55odj.fsf@biostat.ku.dk>

"Prodromos Zanis" <pzanis at geol.uoa.gr> writes:

> Dear all
> 
> I use the library(netCDF) to read in NCEP data. The file I want to
> read has size 113 Mb. When i try to read it I get the following
> message:
> 
> Error: cannot allocate vector of size 221080 Kb
> In addition: Warning message: 
> Reached total allocation of 255Mb: see help(memory.size) 
> 
> I get a similar message when I try to read a file with 256 Mb in a
> PC with 2 GigaByte RAM.
> 
> Is there something that I can do to handle this problem of reading
> big netCDF files with R-project.

Did you read help(memory.size)? and follow instructions therein?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Tue Sep 14 09:01:10 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 14 Sep 2004 09:01:10 +0200
Subject: [R] memory allocation error message
In-Reply-To: <002701c49a26$8c2c6150$0200a8c0@elassa1>
References: <002701c49a26$8c2c6150$0200a8c0@elassa1>
Message-ID: <41469736.6070304@statistik.uni-dortmund.de>

Prodromos Zanis wrote:

> Dear all
> 
> I use the library(netCDF) to read in NCEP data. The file I want to read has size 113 Mb.
> When i try to read it I get the following message:
> 
> Error: cannot allocate vector of size 221080 Kb
> In addition: Warning message: 
> Reached total allocation of 255Mb: see help(memory.size) 

So this is an R version < 1.9.0 !

1. Please upgrade.
2. Please read ?Memory and learn how to increase the maximum amount of 
memory consumed by R under Windows.

Uwe Ligges



> I get a similar message when I try to read a file with 256 Mb in a PC with 2 GigaByte RAM.
> 
> Is there something that I can do to handle this problem of reading big netCDF files with R-project.
> 
> I look forward for your help.
> 
> Prodromos Zanis
> 
> 
> ****************************************************
> Dr. Prodromos Zanis
> Research Centre for Atmospheric Physics and Climatology 
> Academy of Athens
> 3rd September 131, Athens 11251, Greece
> Tel. +30 210 8832048
> Fax: +30 210 8832048
> e-mail: pzanis at geol.uoa.gr
> Web address: http://users.auth.gr/~zanis/
> *****************************************************
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Sep 14 09:03:41 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 14 Sep 2004 09:03:41 +0200
Subject: [R] Can I find the datetime an object was last assigned to/saved?
In-Reply-To: <12AE52872B5C5348BE5CF47C707FF53A326EFF@rhosvr02.rhotrading.com>
References: <12AE52872B5C5348BE5CF47C707FF53A326EFF@rhosvr02.rhotrading.com>
Message-ID: <414697CD.6070301@statistik.uni-dortmund.de>

davidr at rhotrading.com wrote:

> I'm using v 1.9.1 under Windoz XP.
> 
> Can I do the equivalent of "ls -l" on my R objects? R's "ls()" lists
> only the names.

For example ll() in package gregmisc.

Uwe Ligges

> Thanks!
> 
>  
> 
> David L. Reiner
> 
>  
> 
> Rho Trading
> 
> 440 S. LaSalle St -- Suite 620
> 
> Chicago  IL  60605
> 
>  
> 
> 312-362-4963 (voice)
> 
> 312-362-4941 (fax)
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Tue Sep 14 09:11:58 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Sep 2004 08:11:58 +0100 (BST)
Subject: [R] memory allocation error message
In-Reply-To: <x2r7p55odj.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0409140807190.8982-100000@gannet.stats>

On 14 Sep 2004, Peter Dalgaard wrote:

> "Prodromos Zanis" <pzanis at geol.uoa.gr> writes:
> 
> > Dear all
> > 
> > I use the library(netCDF) to read in NCEP data. The file I want to
> > read has size 113 Mb. When i try to read it I get the following
> > message:
> > 
> > Error: cannot allocate vector of size 221080 Kb
> > In addition: Warning message: 
> > Reached total allocation of 255Mb: see help(memory.size) 
> > 
> > I get a similar message when I try to read a file with 256 Mb in a
> > PC with 2 GigaByte RAM.
> > 
> > Is there something that I can do to handle this problem of reading
> > big netCDF files with R-project.
> 
> Did you read help(memory.size)? and follow instructions therein?

Also, netCDF has been withdrawn from CRAN, and you might want to use ncdf 
or RNetCDF instead.  (Windows ports of both are available now: see the 
ReadMe on the CRAN windows contrib area.)

If the message really was similar you are using R < 1.6.0 and need to 
upgrade.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Sep 14 09:16:38 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Sep 2004 08:16:38 +0100 (BST)
Subject: [R] Can I find the datetime an object was last assigned to/saved?
In-Reply-To: <414697CD.6070301@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0409140812530.8982-100000@gannet.stats>

On Tue, 14 Sep 2004, Uwe Ligges wrote:

> davidr at rhotrading.com wrote:
> 
> > I'm using v 1.9.1 under Windoz XP.
> > 
> > Can I do the equivalent of "ls -l" on my R objects? R's "ls()" lists
> > only the names.
> 
> For example ll() in package gregmisc.

But that does not give datetimes, since they are not recorded.

It also needs a warning on object sizes, which had it credited its use of 
object.size you would have been able to find.  Would the maintainer please

1) Give credit where credit is due and add a \seealso, and
2) Include an appropriate warning.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Tue Sep 14 09:27:51 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 14 Sep 2004 09:27:51 +0200
Subject: [R] Can I find the datetime an object was last assigned to/saved?
In-Reply-To: <Pine.LNX.4.44.0409140812530.8982-100000@gannet.stats>
References: <Pine.LNX.4.44.0409140812530.8982-100000@gannet.stats>
Message-ID: <41469D77.2020107@statistik.uni-dortmund.de>

Prof Brian Ripley wrote:

> On Tue, 14 Sep 2004, Uwe Ligges wrote:
> 
> 
>>davidr at rhotrading.com wrote:
>>
>>
>>>I'm using v 1.9.1 under Windoz XP.
>>>
>>>Can I do the equivalent of "ls -l" on my R objects? R's "ls()" lists
>>>only the names.
>>
>>For example ll() in package gregmisc.
> 
> 
> But that does not give datetimes, since they are not recorded.

Ups, sorry. Forgot the subject line while reading the body ...

Uwe

> It also needs a warning on object sizes, which had it credited its use of 
> object.size you would have been able to find.  Would the maintainer please
> 
> 1) Give credit where credit is due and add a \seealso, and
> 2) Include an appropriate warning.
>



From ggrothendieck at myway.com  Tue Sep 14 09:43:09 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 14 Sep 2004 07:43:09 +0000 (UTC)
Subject: [R] Can I find the datetime an object was last assigned to/saved?
References: <12AE52872B5C5348BE5CF47C707FF53A326EFF@rhosvr02.rhotrading.com>
Message-ID: <loom.20040914T094124-385@post.gmane.org>

 <davidr <at> rhotrading.com> writes:

> I'm using v 1.9.1 under Windoz XP.
> 
> Can I do the equivalent of "ls -l" on my R objects? R's "ls()" lists
> only the names.

Check out this thread where it was previously discussed:

http://tolstoy.newcastle.edu.au/R/help/04/05/0207.html



From kzgloylduylt at cjftqb.rx-factory.com  Tue Sep 14 11:10:16 2004
From: kzgloylduylt at cjftqb.rx-factory.com (Elbert Purcell)
Date: Tue, 14 Sep 2004 10:10:16 +0100
Subject: [R] anathema fbi evolution
Message-ID: <39EB29BB.22304@rx-factory.com>

Dear,

Pharma manufacturers figure they can charge a small fortune.

Buy overseas and stop getting ripped off.
Paste http://rx-factory.com/ into your address bar to recieve more information

No more notifications
http://rx-factory.com/u

Elbert Purcell
kzgloylduylt at cjftqb.rx-factory.com



From nedluk at yahoo.it  Tue Sep 14 10:44:20 2004
From: nedluk at yahoo.it (=?iso-8859-1?q?michele=20lux?=)
Date: Tue, 14 Sep 2004 10:44:20 +0200 (CEST)
Subject: [R] erase columns
Message-ID: <20040914084420.4770.qmail@web13622.mail.yahoo.com>

Can somebody remember me which is the command to erase
columns from a data frame?
Thanks Michele


		
___________________________________

http://it.seriea.fantasysports.yahoo.com/



From Rau at demogr.mpg.de  Tue Sep 14 10:59:40 2004
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Tue, 14 Sep 2004 10:59:40 +0200
Subject: [R] erase columns
Message-ID: <3699CDBC4ED5D511BE6400306E1C0D81030A0CCD@hermes.demogr.mpg.de>

Hi, 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of michele lux
Sent: Dienstag, 14. September 2004 10:44
To: r-help at r-project.org
Subject: [R] erase columns

Can somebody remember me which is the command to erase
columns from a data frame?
Thanks Michele

I hope the following code-piece helps what you are looking for:

mydf <- as.data.frame(matrix(runif(100),ncol=5))

### if you want to erase the third column, do:
mydf <- mydf[,-3]


mydf2 <- as.data.frame(matrix(runif(100),ncol=20))

### if you want to erase the first, third and twentieth column, do:
mydf2 <- mydf2[,-c(1,5,20)]

Ciao,
Roland


+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From tlumley at u.washington.edu  Tue Sep 14 11:01:56 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 14 Sep 2004 02:01:56 -0700 (PDT)
Subject: [R] maximization subject to constaint
In-Reply-To: <Pine.GSO.4.58.0409131559560.25120@altair.biostat.wisc.edu>
References: <Pine.GSO.4.58.0409131559560.25120@altair.biostat.wisc.edu>
Message-ID: <Pine.A41.4.61.0409140200080.21960@homer09.u.washington.edu>

On Mon, 13 Sep 2004, Shuangge Ma wrote:

constrOptim() will do this, but it isn't a particularly efficient 
algorithm when the number of constraints is large.

 	-thomas


> Hello:
> I have been trying to program the following maximization problem and would
> definitely welcome some help.
>
> the target function: sum_{i} f(alpha, beta'X_{i}),
>                     where alpha and beta are unknown d-dim parameter,
>                     f is a known function an X_{i} are i.i.d. r.v.
> I need to maximize the above sum, under the constaint that:
>                     beta'X_{i}+alpha<=1, for i=1,...,n.
>
> For one dimension, it is kind of trivial. What should I do with high
> dimensional alpha and beta?  Thanks for your time,
>
> Shuangge Ma, Ph.D.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From wolski at molgen.mpg.de  Tue Sep 14 11:05:42 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Tue, 14 Sep 2004 11:05:42 +0200
Subject: [R] erase columns
In-Reply-To: <20040914084420.4770.qmail@web13622.mail.yahoo.com>
References: <20040914084420.4770.qmail@web13622.mail.yahoo.com>
Message-ID: <200409141105420805.059A730C@mail.math.fu-berlin.de>

?subset

/E
*********** REPLY SEPARATOR  ***********

On 9/14/2004 at 10:44 AM michele lux wrote:

>>>Can somebody remember me which is the command to erase
>>>columns from a data frame?
>>>Thanks Michele
>>>
>>>
>>>		
>>>___________________________________
>>>
>>>http://it.seriea.fantasysports.yahoo.com/
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin                'v'    
tel: 0049-30-83875219                        /   \       
mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
      wolski at molgen.mpg.de



From Per.Torang at ebc.uu.se  Tue Sep 14 11:06:56 2004
From: Per.Torang at ebc.uu.se (Per =?iso-8859-1?b?VG9y5G5n?=)
Date: Tue, 14 Sep 2004 11:06:56 +0200
Subject: [R] glmmPQL and random factors
Message-ID: <1095152816.4146b4b04fb6e@webmail.uu.se>

Hello!

I have tested the effect of two treatments on fruit set, i.e. fruits per plant. 
The treatments had two levels each giving four different treatment 
combinations. Forty separated plots were subjected to one of the treatment 
combinations so each combination was replicated ten times. I intend to analyze 
my data using the glmmPQL procedure in the following way.

glmmPQL(Fruit.set~Treat1*Treat2+offset(log10(No.flowers)), random=~1|Plot, 
family=poisson, data=....)

Plot is supposed to be nested in (Treat1*Treat2).
Is this analysis suitable? Moreover, what is the meaning of typing 
random=~1|Plot compared to random=~Treat1*Treat2|Plot?

Cheers
Per Tor??ng
per.torang at ebc.uu.se



From paolo.ariano at unito.it  Tue Sep 14 12:02:24 2004
From: paolo.ariano at unito.it (Paolo Ariano)
Date: Tue, 14 Sep 2004 12:02:24 +0200
Subject: [R] R post-hoc and GUI
Message-ID: <1095156143.18012.4.camel@emoscion2>

Hi *
i've done my anova anlysis but now i need post-hoc test, are these
included in R ?

I've a Big problem, working with people that don't like to use
command-line software (but prefer something like openoffice) does
someone is trying to do a usable GUI for R ? i'm reading something on R
commander SciView and others but all seem to be beta. I'd like to make
possible to make anova and post-hoc more simple to my collegues ;)

thanks
paolo
-- 
Paolo Ariano
Neuroscience PhD Student @ UniTo

Una non esclude l'altra ed entrambe non escludono
i soldi - Paolo A.  


_____________________________________________________________________
For your security, this mail has been scanned and protected by Inflex



From rksh at soc.soton.ac.uk  Tue Sep 14 12:06:09 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Tue, 14 Sep 2004 11:06:09 +0100
Subject: [R] R-2.0.0 CMD check .  and datasets
Message-ID: <a06002003bd6c69b01b0a@[139.166.242.29]>

Hello everyone

I'm having a little difficulty with R-2.0.0 CMD check.  My field is 
Bayesian calibration of computer models.

The problem is  that I have a large collection of toy datasets, that 
in R-1.9.1 were specified with lines
like this:

x.toy <- 1:6
y.toy <- computer.model(x.toy)
z.toy <- reality(x.toy)

in file ./data/toys.R ; functions computer.model() and reality() are 
defined in ./R/calibrator.R.

[In this application,  the (toy) functions computer.model() and 
reality() are the objects of inference, as
per the standard Bayesian approach.  The functions are nonrandom in 
that they are deterministic but
random in the Bayesian sense.  Thus y.toy and z.toy are observations 
of (random) functions].

In the Real World, one would have access to x.toy, y.toy, and z.toy 
but not (of course) computer.model()
or reality().  These functions should never be seen or referred to 
because they are Unknown.

So, in many of the code examples, I use  things like 
"some.function(y.toy, z.toy)" . . . and  I need
y.toy and z.toy to be consistent between different functions.

I think R-2.0.0 sources ./data/toys.R *before* the files in ./R/   ; 
and this throws an error in
R2 CMD check, because the functions are not found.

What is best practice to generate this kind of toy dataset?



-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From ozric at web.de  Tue Sep 14 12:11:11 2004
From: ozric at web.de (Christian Schulz)
Date: Tue, 14 Sep 2004 12:11:11 +0200
Subject: [R] R post-hoc and GUI
In-Reply-To: <1095156143.18012.4.camel@emoscion2>
References: <1095156143.18012.4.camel@emoscion2>
Message-ID: <200409141211.11973.ozric@web.de>

Perhaps the package Rcmdr is a compromise for the 
people don't like command-line  software.

christian


Am Dienstag, 14. September 2004 12:02 schrieb Paolo Ariano:
> Hi *
> i've done my anova anlysis but now i need post-hoc test, are these
> included in R ?
>
> I've a Big problem, working with people that don't like to use
> command-line software (but prefer something like openoffice) does
> someone is trying to do a usable GUI for R ? i'm reading something on R
> commander SciView and others but all seem to be beta. I'd like to make
> possible to make anova and post-hoc more simple to my collegues ;)
>
> thanks
> paolo



From ripley at stats.ox.ac.uk  Tue Sep 14 12:26:04 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Sep 2004 11:26:04 +0100 (BST)
Subject: [R] R post-hoc and GUI
In-Reply-To: <1095156143.18012.4.camel@emoscion2>
Message-ID: <Pine.LNX.4.44.0409141123220.29156-100000@gannet.stats>

On Tue, 14 Sep 2004, Paolo Ariano wrote:

> i've done my anova anlysis but now i need post-hoc test, are these
> included in R ?

Yes, in function TukeyHSD and in package multcomp for example.  There are
worked examples in the MASS scripts.

> I've a Big problem, working with people that don't like to use
> command-line software (but prefer something like openoffice) does
> someone is trying to do a usable GUI for R ? i'm reading something on R
> commander SciView and others but all seem to be beta. I'd like to make
> possible to make anova and post-hoc more simple to my collegues ;)

That's your choice, but have you looked at package Rcmdr?  You cna extend 
its menus if you want to.

BTW, I guess you are working on Windows, but have not told us what OS, 
even. Please read the posting guide.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rossini at blindglobe.net  Tue Sep 14 12:48:51 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue, 14 Sep 2004 03:48:51 -0700
Subject: [R] R post-hoc and GUI
In-Reply-To: <200409141211.11973.ozric@web.de> (Christian Schulz's message
	of "Tue, 14 Sep 2004 12:11:11 +0200")
References: <1095156143.18012.4.camel@emoscion2>
	<200409141211.11973.ozric@web.de>
Message-ID: <85wtyxjfcc.fsf@servant.blindglobe.net>



More importantly -- if you are looking for something "not beta", you
need to be very careful.  "beta" quality is in the eyes of the
claimer, and it isn't uniform.  

In fact, while you could wrap up a usable GUI for your specific needs,
it might be less of a waste of time to write simple functions and
spend the time with training.

Why, I can imagine that the arguments about GUIs would waste more time
than would be spent creating a cheatsheet and the functions/scripts to
simplify everything.

Of course, your situation might differ.

best,
-tony



Christian Schulz <ozric at web.de> writes:

> Perhaps the package Rcmdr is a compromise for the 
> people don't like command-line  software.
>
> christian
>
>
> Am Dienstag, 14. September 2004 12:02 schrieb Paolo Ariano:
>> Hi *
>> i've done my anova anlysis but now i need post-hoc test, are these
>> included in R ?
>>
>> I've a Big problem, working with people that don't like to use
>> command-line software (but prefer something like openoffice) does
>> someone is trying to do a usable GUI for R ? i'm reading something on R
>> commander SciView and others but all seem to be beta. I'd like to make
>> possible to make anova and post-hoc more simple to my collegues ;)
>>
>> thanks
>> paolo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From tom_woody at swissinfo.org  Tue Sep 14 08:55:51 2004
From: tom_woody at swissinfo.org (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Tue, 14 Sep 2004 08:55:51 +0200
Subject: [R] Spare some CPU cycles for testing lme?
In-Reply-To: <ci44e3$96d$1@sea.gmane.org>
References: <ci44e3$96d$1@sea.gmane.org>
Message-ID: <414695F7.1020308@swissinfo.org>

Hello,

Frank Samuelson schrieb:

> If anyone has a few extra CPU cycles to spare,
> I'd appreciate it if you could verify a problem that I
> have encountered.  Run the code
> below and tell me if it crashes your R before
> completion.
>
> library(lme4)
> data(bdf)
> dump<-sapply( 1:50000, function(i) {
>     fm <- lme(langPOST ~ IQ.ver.cen + avg.IQ.ver.cen, data = bdf,
>               random = ~ IQ.ver.cen | schoolNR);
>     cat("  ",i,"\r")
>     0
> })
>
>
I also tested your code by using R-1.91 under Debian Sid. After hundreds 
of iterations it ended up with the already noticed "segmentation fault"

HTH

Thomas



From tom_woody at swissinfo.org  Tue Sep 14 10:47:18 2004
From: tom_woody at swissinfo.org (=?ISO-8859-15?Q?Thomas_Sch=F6nhoff?=)
Date: Tue, 14 Sep 2004 10:47:18 +0200
Subject: [R] Howto enlarge fonts size in R- Graphics?
Message-ID: <4146B016.1090002@swissinfo.org>

Hi,

I am fairly new to GNU R !
At the moment I am doing an intensive learning on the basics of GNU 
R-1.91, especially graphics like plots and alike,  by reading the 
introductory docs!
Well, except some occasional glitches (X11 output errors) everything 
seems to be fine, thanks to developers for this fine program!
But there is a slight problem with the size of fonts in graphics, i.e. 
its very hard form me to read labels of variables in plots or other 
graphical representations! (yes, I am little short sighted)
How may I mainpulate/enlarge the fonts size in graphics from within GNU R ?

Thanks for your time

Thomas



System: GNU/Linux (Debian Sid)
GNU R: 1.91



From daniel.hoppe at univie.ac.at  Tue Sep 14 13:49:17 2004
From: daniel.hoppe at univie.ac.at (Daniel Hoppe)
Date: Tue, 14 Sep 2004 13:49:17 +0200
Subject: [R] Howto enlarge fonts size in R- Graphics?
In-Reply-To: <4146B016.1090002@swissinfo.org>
Message-ID: <000901c49a50$e096d8e0$82b98283@DH>

Hi Thomas!

Try ?par at the R prompt, there you will get all the necessary
information to change the appearance of graphics.

Daniel

--
Daniel Hoppe
Department of Marketing
University of Vienna
Bruenner Strasse 72
1210 Vienna
Austria 


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Thomas 
> Sch??nhoff
> Sent: Tuesday, September 14, 2004 10:47 AM
> To: R User-Liste
> Subject: [R] Howto enlarge fonts size in R- Graphics?
> 
> 
> Hi,
> 
> I am fairly new to GNU R !
> At the moment I am doing an intensive learning on the basics of GNU 
> R-1.91, especially graphics like plots and alike,  by reading the 
> introductory docs!
> Well, except some occasional glitches (X11 output errors) everything 
> seems to be fine, thanks to developers for this fine program! 
> But there is a slight problem with the size of fonts in 
> graphics, i.e. 
> its very hard form me to read labels of variables in plots or other 
> graphical representations! (yes, I am little short sighted)
> How may I mainpulate/enlarge the fonts size in graphics from 
> within GNU R ?
> 
> Thanks for your time
> 
> Thomas
> 
> 
> 
> System: GNU/Linux (Debian Sid)
> GNU R: 1.91
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read 
> the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Tue Sep 14 13:53:41 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 14 Sep 2004 13:53:41 +0200
Subject: [R] Howto enlarge fonts size in R- Graphics?
In-Reply-To: <4146B016.1090002@swissinfo.org>
References: <4146B016.1090002@swissinfo.org>
Message-ID: <4146DBC5.1050304@statistik.uni-dortmund.de>

Thomas Sch??nhoff wrote:

> Hi,
> 
> I am fairly new to GNU R !
> At the moment I am doing an intensive learning on the basics of GNU 
> R-1.91, especially graphics like plots and alike,  by reading the 
> introductory docs!
> Well, except some occasional glitches (X11 output errors) everything 
> seems to be fine, thanks to developers for this fine program!
> But there is a slight problem with the size of fonts in graphics, i.e. 
> its very hard form me to read labels of variables in plots or other 
> graphical representations! (yes, I am little short sighted)
> How may I mainpulate/enlarge the fonts size in graphics from within GNU R ?

See ?plot, ?plot.default and ?par, in particular look out for all 
arguments containing the letters "cex" ....

Uwe Ligges

BTW: It is called R-1.9.1




> Thanks for your time
> 
> Thomas
> 
> 
> 
> System: GNU/Linux (Debian Sid)
> GNU R: 1.91
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Tue Sep 14 13:58:57 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Sep 2004 12:58:57 +0100 (BST)
Subject: [R] Howto enlarge fonts size in R- Graphics?
In-Reply-To: <4146B016.1090002@swissinfo.org>
Message-ID: <Pine.LNX.4.44.0409141254310.3365-100000@gannet.stats>

The X11 device has an argument `pointsize' (which may well mean pixel size
in a particular implementation of X11, as my laptop for example has width,
height and pointsize all much smaller than specified):  just increase it.

The advice to look at ?par is incorrect if you want to scale everything, 
as I think you do.

If you want auto-launched windows to have a larger font, you need to write 
a wrapper to X11 and set options(device=wrapper_name).

On Tue, 14 Sep 2004, [ISO-8859-15] Thomas Sch??nhoff wrote:

> I am fairly new to GNU R !
> At the moment I am doing an intensive learning on the basics of GNU 
> R-1.91, especially graphics like plots and alike,  by reading the 
> introductory docs!
> Well, except some occasional glitches (X11 output errors) everything 
> seems to be fine, thanks to developers for this fine program!
> But there is a slight problem with the size of fonts in graphics, i.e. 
> its very hard form me to read labels of variables in plots or other 
> graphical representations! (yes, I am little short sighted)
> How may I mainpulate/enlarge the fonts size in graphics from within GNU R ?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rolf at math.unb.ca  Tue Sep 14 14:00:34 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 14 Sep 2004 09:00:34 -0300 (ADT)
Subject: [R] Excel TDIST and TINV
Message-ID: <200409141200.i8EC0Y9X008786@erdos.math.unb.ca>


Brian Ripley wrote:

> We are hardly likely to know what those are in Excel.  Possibly pt
> and qt, but see help.search("Student t distribution") for where to
> look for what R provides.
> 
> I also do not know what Chauvenet's criterion has to do with
> Student's t, and
> 
> http://www.me.umn.edu/education/courses/me8337/chauvenet.txt
> 
> states that the latter would be incorrect.

See also

	http://www.stat.uiowa.edu/~jcryer/JSMTalk2001.pdf

for insight into the ``wisdom'' of using Excel in the first place.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From ripley at stats.ox.ac.uk  Tue Sep 14 14:09:55 2004
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Tue, 14 Sep 2004 13:09:55 +0100 (GMT Daylight Time)
Subject: [R] Spare some CPU cycles for testing lme?
In-Reply-To: <ci44e3$96d$1@sea.gmane.org>
References: <ci44e3$96d$1@sea.gmane.org>
Message-ID: <Pine.WNT.4.58.0409141303110.2744@auk>

As others have said, this needs tools not CPU cycles: gctorture or valgrind.

Valgrind found (after a few seconds and on the first pass)

==23057== Invalid read of size 4
==23057==    at 0x3CF4E645: ssc_symbolic_permute (Mutils.c:373)
==23057==    by 0x3CF5BF75: ssclme_create (ssclme.c:168)
==23057==    by 0x80AF5E8: do_dotcall
(/users/ripley/R/svn/R-devel/src/main/dotcode.c:640)
==23057==    by 0x80CFA84: Rf_eval
(/users/ripley/R/svn/R-devel/src/main/eval.c:399)
==23057==  Address 0x3C7F3BD0 is 4 bytes before a block of size 524 alloc'd
==23057==    at 0x3C01CB56: calloc (in
/opt/local/lib/valgrind/vgpreload_memcheck.so)
==23057==    by 0x80F9EBE: R_chk_calloc
(/users/ripley/R/svn/R-devel/src/main/memory.c:2151)
==23057==    by 0x3CF4E515: ssc_symbolic_permute (Mutils.c:352)
==23057==    by 0x3CF5BF75: ssclme_create (ssclme.c:168)
==23057==
==23057== Use of uninitialised value of size 8
==23057==    at 0x80C0137: Rf_duplicate
(/users/ripley/R/svn/R-devel/src/main/duplicate.c:160)
==23057==    by 0x80BFA85: Rf_duplicate
(/users/ripley/R/svn/R-devel/src/main/duplicate.c:101)
==23057==    by 0x80BFEB3: Rf_duplicate
(/users/ripley/R/svn/R-devel/src/main/duplicate.c:154)
==23057==    by 0x816ED96: do_subset2_dflt
(/users/ripley/R/svn/R-devel/src/main/subset.c:816)
==23057==
==23057== Conditional jump or move depends on uninitialised value(s)
==23057==    at 0x3CF62229: ssclme_fitted (ssclme.c:1587)
==23057==    by 0x80AF646: do_dotcall
(/users/ripley/R/svn/R-devel/src/main/dotcode.c:646)
==23057==    by 0x80CFA84: Rf_eval
(/users/ripley/R/svn/R-devel/src/main/eval.c:399)
==23057==    by 0x80D1D80: do_set
(/users/ripley/R/svn/R-devel/src/main/eval.c:1280)

which is pretty definitive evidence of a problem (possibly 2) in the code.

I strongly recommend valgrind (http://valgrind.kde.org/) if you are using
x86 Linux.  It has found quite a few errors in R and in certain packages
recently.  The only thing to watch is that optimized BLASes will probably
crash it.


On Mon, 13 Sep 2004, Frank Samuelson wrote:

> If anyone has a few extra CPU cycles to spare,
> I'd appreciate it if you could verify a problem that I
> have encountered.  Run the code
> below and tell me if it crashes your R before
> completion.
>
> library(lme4)
> data(bdf)
> dump<-sapply( 1:50000, function(i) {
>      fm <- lme(langPOST ~ IQ.ver.cen + avg.IQ.ver.cen, data = bdf,
>                random = ~ IQ.ver.cen | schoolNR);
>      cat("  ",i,"\r")
>      0
> })
>
> The above code simply reruns the example from the
> lme help page a large number of times and returns a bunch
> of 0's, so you'll need to have the lme4 and Matrix
> packages installed.  It might take a while to complete,
> but you can always nice it and let it run.
>
> I'm attempting to bootstrap lme() from the lme4 package,
> but it causes a
> segfault after a couple hundred iterations.  This happens on
> my Linux x86 RedHat 7.3, 8.0, 9.0, FC1 systems w/ 1.9.1
> and devel 2.0.0 (not all possible combinations actually
> tested.)
> I've communicated w/ Douglas Bates about this and he
> doesn't appear to have the problem.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From paolo.ariano at unito.it  Tue Sep 14 14:17:06 2004
From: paolo.ariano at unito.it (Paolo Ariano)
Date: Tue, 14 Sep 2004 14:17:06 +0200
Subject: [R] R post-hoc and GUI
In-Reply-To: <Pine.LNX.4.44.0409141123220.29156-100000@gannet.stats>
References: <Pine.LNX.4.44.0409141123220.29156-100000@gannet.stats>
Message-ID: <1095164225.18253.3.camel@emoscion2>

Il mar, 2004-09-14 alle 12:26, Prof Brian Ripley ha scritto:
> BTW, I guess you are working on Windows, but have not told us what OS, 
> even. Please read the posting guide.

sorry, i use DebianGNU/Linux and my collegues windows

thanks
paolo
-- 
Paolo Ariano
Neuroscience PhD Student @ UniTo

Una non esclude l'altra ed entrambe non escludono
i soldi - Paolo A.  


_____________________________________________________________________
For your security, this mail has been scanned and protected by Inflex



From p.dalgaard at biostat.ku.dk  Tue Sep 14 14:22:08 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Sep 2004 14:22:08 +0200
Subject: [R] Howto enlarge fonts size in R- Graphics?
In-Reply-To: <Pine.LNX.4.44.0409141254310.3365-100000@gannet.stats>
References: <Pine.LNX.4.44.0409141254310.3365-100000@gannet.stats>
Message-ID: <x2wtyxkplb.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> The X11 device has an argument `pointsize' (which may well mean pixel size
> in a particular implementation of X11, as my laptop for example has width,
> height and pointsize all much smaller than specified):  just increase it.
> 
> The advice to look at ?par is incorrect if you want to scale everything, 
> as I think you do.
> 
> If you want auto-launched windows to have a larger font, you need to write 
> a wrapper to X11 and set options(device=wrapper_name).

Also, check out the dpi settings for your display (xdpyinfo). If this
is set lower than the physical reality, then pointsizes are
overestimated (so fonts are smaller than they should be). How to
change it is left as an exercise....

BTW, it's 1.9.1, 1.91 is not in the plans (and wouldn't be for the
next forty years or so). 
 
> On Tue, 14 Sep 2004, [ISO-8859-15] Thomas Sch??nhoff wrote:
> 
> > I am fairly new to GNU R !
> > At the moment I am doing an intensive learning on the basics of GNU 
> > R-1.91, especially graphics like plots and alike,  by reading the 
> > introductory docs!
> > Well, except some occasional glitches (X11 output errors) everything 
> > seems to be fine, thanks to developers for this fine program!
> > But there is a slight problem with the size of fonts in graphics, i.e. 
> > its very hard form me to read labels of variables in plots or other 
> > graphical representations! (yes, I am little short sighted)
> > How may I mainpulate/enlarge the fonts size in graphics from within GNU R ?
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From mbianchi at thamesriver.co.uk  Tue Sep 14 15:08:25 2004
From: mbianchi at thamesriver.co.uk (Marco Bianchi)
Date: Tue, 14 Sep 2004 14:08:25 +0100
Subject: [R] overwriting a line in existing .csv file with new data
Message-ID: <BD08AC4C0714C840ABAA62415CAE9780420E69@TRC-EXVS01.thamesriver.co.uk>

Dear R-users,

I have a data matrix with 20 rows and 10 columns which is stored in the hard drive as .csv file called c:\DataFile.csv and a 10 elements vector called xVec.

I would like to be able to copy and paste the information contained in xVec into (say) the 2nd row of DataFile.csv

Obviously, one way of doing this would be to read the matrix using read.csv() command, implement the copy and paste manipulation and save the new matrix again using write.table(). However, has anyone used an alternative method which does not require use of the read.csv() command?

Regards
Marco Bianchi




________________________________________________________________________
This e-mail has been scanned for all viruses by Star. The\ s...{{dropped}}



From bates at stat.wisc.edu  Tue Sep 14 15:18:30 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 14 Sep 2004 08:18:30 -0500
Subject: [R] Spare some CPU cycles for testing lme?
In-Reply-To: <Pine.WNT.4.58.0409141303110.2744@auk>
References: <ci44e3$96d$1@sea.gmane.org> <Pine.WNT.4.58.0409141303110.2744@auk>
Message-ID: <4146EFA6.9080809@stat.wisc.edu>

Prof Brian D Ripley wrote:
> As others have said, this needs tools not CPU cycles: gctorture or valgrind.
> 
> Valgrind found (after a few seconds and on the first pass)
> 
> ==23057== Invalid read of size 4
> ==23057==    at 0x3CF4E645: ssc_symbolic_permute (Mutils.c:373)
> ==23057==    by 0x3CF5BF75: ssclme_create (ssclme.c:168)
> ==23057==    by 0x80AF5E8: do_dotcall
> (/users/ripley/R/svn/R-devel/src/main/dotcode.c:640)
> ==23057==    by 0x80CFA84: Rf_eval
> (/users/ripley/R/svn/R-devel/src/main/eval.c:399)
> ==23057==  Address 0x3C7F3BD0 is 4 bytes before a block of size 524 alloc'd
> ==23057==    at 0x3C01CB56: calloc (in
> /opt/local/lib/valgrind/vgpreload_memcheck.so)
> ==23057==    by 0x80F9EBE: R_chk_calloc
> (/users/ripley/R/svn/R-devel/src/main/memory.c:2151)
> ==23057==    by 0x3CF4E515: ssc_symbolic_permute (Mutils.c:352)
> ==23057==    by 0x3CF5BF75: ssclme_create (ssclme.c:168)
> ==23057==
> ==23057== Use of uninitialised value of size 8
> ==23057==    at 0x80C0137: Rf_duplicate
> (/users/ripley/R/svn/R-devel/src/main/duplicate.c:160)
> ==23057==    by 0x80BFA85: Rf_duplicate
> (/users/ripley/R/svn/R-devel/src/main/duplicate.c:101)
> ==23057==    by 0x80BFEB3: Rf_duplicate
> (/users/ripley/R/svn/R-devel/src/main/duplicate.c:154)
> ==23057==    by 0x816ED96: do_subset2_dflt
> (/users/ripley/R/svn/R-devel/src/main/subset.c:816)
> ==23057==
> ==23057== Conditional jump or move depends on uninitialised value(s)
> ==23057==    at 0x3CF62229: ssclme_fitted (ssclme.c:1587)
> ==23057==    by 0x80AF646: do_dotcall
> (/users/ripley/R/svn/R-devel/src/main/dotcode.c:646)
> ==23057==    by 0x80CFA84: Rf_eval
> (/users/ripley/R/svn/R-devel/src/main/eval.c:399)
> ==23057==    by 0x80D1D80: do_set
> (/users/ripley/R/svn/R-devel/src/main/eval.c:1280)
> 
> which is pretty definitive evidence of a problem (possibly 2) in the code.
> 
> I strongly recommend valgrind (http://valgrind.kde.org/) if you are using
> x86 Linux.  It has found quite a few errors in R and in certain packages
> recently.  The only thing to watch is that optimized BLASes will probably
> crash it.
> 

You're right.  I had (at least) two thinko's in that code.  The problems 
show up in the lme4 package but the errors in the C code are in the 
Matrix package.  I will upload a repaired version of the Matrix package.



From ramasamy at cancer.org.uk  Tue Sep 14 16:00:59 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 14 Sep 2004 15:00:59 +0100
Subject: [R] calculating memory usage
In-Reply-To: <Pine.LNX.4.44.0409131843580.22630-100000@gannet.stats>
References: <Pine.LNX.4.44.0409131843580.22630-100000@gannet.stats>
Message-ID: <1095170459.3043.85.camel@ndmpc126.ihs.ox.ac.uk>

Many thanks to Prof. Ripley. The problem is that memory.profile does not
exist in *nix environment and there is probably a very good reason why.

I was reading help(Memory) and in the Details section :
     You can find out the current memory consumption (the heap and cons
     cells used as numbers and megabytes) by typing 'gc()' at the R
     prompt.

AFAICS, Ncells is the fixed memory used by the underlying R and Vcells
is the variable part and depends on the calculations. 

Would I be able to say that the generating 10 million random numbers
requires approximately 73.4 Mb (= 26.3 + 80.5 - 26.3 - 7.1) of memory ?
I double checked this against memory.size() in Windows and they seem to
agree. Thank you.

> gc()
         used (Mb) gc trigger (Mb)
Ncells 456262 12.2     984024 26.3
Vcells 122697  1.0     929195  7.1
> 
> x <- rnorm(10000000)
> gc()
           used (Mb) gc trigger (Mb)
Ncells   456274 12.2     984024 26.3
Vcells 10123014 77.3   10538396 80.5




On Mon, 2004-09-13 at 18:47, Prof Brian Ripley wrote:
> On Mon, 13 Sep 2004, Adaikalavan Ramasamy wrote:
> 
> > I am comparing two different algorithms in terms of speed and memory
> > usage. I can calculate the processing time with proc.time() as follows
> > but am not sure how to calculate the memory usage.
> > 
> >    ptm <- proc.time()
> >    x <- rnorm(1000000)
> >    proc.time() - ptm
> 
> Hmm ... see ?system.time!
> 
> > I would like to be within R itself since I will test the algorithm
> > several hundred times and in batch mode. So manually looking up 'top'
> > may not be feasible. help.seach("memory") suggests memory.profile and gc
> > but I am not sure how to use these.
> 
> I don't think you can.  You can find out how much memory R is using NOW, 
> but not the peak memory usage during a calculation.  Nor is that 
> particularly relevant, as it depends on what was gone on before, the word 
> length of the platform and the garbage collection settings.
> 
> On Windows, starting in a clean session, calling gc() and memory.size(), 
> then calling your code and memory.size(max=TRUE) will give you a fair 
> idea, but `top' indicates some Unix-alike.



From ripley at stats.ox.ac.uk  Tue Sep 14 16:06:27 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Sep 2004 15:06:27 +0100 (BST)
Subject: [R] calculating memory usage
In-Reply-To: <1095170459.3043.85.camel@ndmpc126.ihs.ox.ac.uk>
Message-ID: <Pine.LNX.4.44.0409141503240.29576-100000@gannet.stats>

On Tue, 14 Sep 2004, Adaikalavan Ramasamy wrote:

> Many thanks to Prof. Ripley. The problem is that memory.profile does not
> exist in *nix environment and there is probably a very good reason why.

memory.size?

> 
> I was reading help(Memory) and in the Details section :
>      You can find out the current memory consumption (the heap and cons
>      cells used as numbers and megabytes) by typing 'gc()' at the R
>      prompt.
> 
> AFAICS, Ncells is the fixed memory used by the underlying R and Vcells
> is the variable part and depends on the calculations. 
> 
> Would I be able to say that the generating 10 million random numbers
> requires approximately 73.4 Mb (= 26.3 + 80.5 - 26.3 - 7.1) of memory ?
> I double checked this against memory.size() in Windows and they seem to
> agree. Thank you.

No, only that storing 10 million numbers requires 77.3 - 1.0Mb, and

> object.size(x)/1024^2
[1] 76.29397


> > gc()
>          used (Mb) gc trigger (Mb)
> Ncells 456262 12.2     984024 26.3
> Vcells 122697  1.0     929195  7.1
> > 
> > x <- rnorm(10000000)
> > gc()
>            used (Mb) gc trigger (Mb)
> Ncells   456274 12.2     984024 26.3
> Vcells 10123014 77.3   10538396 80.5
> 
> 
> 
> 
> On Mon, 2004-09-13 at 18:47, Prof Brian Ripley wrote:
> > On Mon, 13 Sep 2004, Adaikalavan Ramasamy wrote:
> > 
> > > I am comparing two different algorithms in terms of speed and memory
> > > usage. I can calculate the processing time with proc.time() as follows
> > > but am not sure how to calculate the memory usage.
> > > 
> > >    ptm <- proc.time()
> > >    x <- rnorm(1000000)
> > >    proc.time() - ptm
> > 
> > Hmm ... see ?system.time!
> > 
> > > I would like to be within R itself since I will test the algorithm
> > > several hundred times and in batch mode. So manually looking up 'top'
> > > may not be feasible. help.seach("memory") suggests memory.profile and gc
> > > but I am not sure how to use these.
> > 
> > I don't think you can.  You can find out how much memory R is using NOW, 
> > but not the peak memory usage during a calculation.  Nor is that 
> > particularly relevant, as it depends on what was gone on before, the word 
> > length of the platform and the garbage collection settings.
> > 
> > On Windows, starting in a clean session, calling gc() and memory.size(), 
> > then calling your code and memory.size(max=TRUE) will give you a fair 
> > idea, but `top' indicates some Unix-alike.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rpeng at jhsph.edu  Tue Sep 14 16:10:27 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 14 Sep 2004 10:10:27 -0400
Subject: [R] calculating memory usage
In-Reply-To: <1095096926.3070.118.camel@vpn202001.lif.icnet.uk>
References: <1095096926.3070.118.camel@vpn202001.lif.icnet.uk>
Message-ID: <4146FBD3.9010906@jhsph.edu>

If you only have simple objects in your function, you might be able to 
use a function like

totalMem <- function()  {
   sum(sapply(ls(all = TRUE), function(x) object.size(get(x)))) / 2^20
}

which should give you a rough idea of the memory usage (in MB) in the 
current environment.

-roger

Adaikalavan Ramasamy wrote:
> I am comparing two different algorithms in terms of speed and memory
> usage. I can calculate the processing time with proc.time() as follows
> but am not sure how to calculate the memory usage.
> 
>    ptm <- proc.time()
>    x <- rnorm(1000000)
>    proc.time() - ptm
> 
> I would like to be within R itself since I will test the algorithm
> several hundred times and in batch mode. So manually looking up 'top'
> may not be feasible. help.seach("memory") suggests memory.profile and gc
> but I am not sure how to use these.
> 
> Sorry if this is a basic question. Thank you.
> 
> Regards, Adai
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jzhang at jimmy.harvard.edu  Tue Sep 14 16:11:15 2004
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Tue, 14 Sep 2004 10:11:15 -0400 (EDT)
Subject: [R] Re: datalist
Message-ID: <200409141411.KAA29345@blaise.dfci.harvard.edu>

Hi,

The following is a cut/paste from http://developer.r-project.org/200update.txt:

...

3) When a package is installed, all the data sets are loaded to see
   what they produce.  If this is undesirable (because they are
   enormous, or depend on other packages that need to be installed
   later, ...), add a `datalist' file to the data subdirectory as
   described in `Writing R Extensions'.

...



I only saw a mentioning of 00Index in the description about the data 
subdirectory in Writing R Extensions/Package Subdirectories. Could someone point 
me to the right place or tell me what a 'datalist' file is supposed to be? 


Thanks.


JZ



From rpeng at jhsph.edu  Tue Sep 14 16:48:10 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 14 Sep 2004 10:48:10 -0400
Subject: [R] Getting the argument list within a function
Message-ID: <414704AA.5050304@jhsph.edu>

Is there a way of getting the argument list of a function from within 
that function?  For example, something like

f <- function(x, y = 3) {
	fargs <- getFunctionArgList()
	print(fargs)  ## Should be `alist(x, y = 3)'
}

Thanks,

-roger



From jgentry at jimmy.harvard.edu  Tue Sep 14 16:57:40 2004
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Tue, 14 Sep 2004 10:57:40 -0400 (EDT)
Subject: [R] Getting the argument list within a function
In-Reply-To: <414704AA.5050304@jhsph.edu>
Message-ID: <Pine.SOL.4.20.0409141057320.17461-100000@santiam.dfci.harvard.edu>

> Is there a way of getting the argument list of a function from within 
> that function?  For example, something like

Would formals() work for you here?



From rpeng at jhsph.edu  Tue Sep 14 16:58:44 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 14 Sep 2004 10:58:44 -0400
Subject: [R] Getting the argument list within a function
In-Reply-To: <Pine.SOL.4.20.0409141057320.17461-100000@santiam.dfci.harvard.edu>
References: <Pine.SOL.4.20.0409141057320.17461-100000@santiam.dfci.harvard.edu>
Message-ID: <41470724.7010105@jhsph.edu>

Ergh, yes, that's exactly it.  I didn't realize you could use it in 
that way.

Thanks,

-roger

Jeff Gentry wrote:
>>Is there a way of getting the argument list of a function from within 
>>that function?  For example, something like
> 
> 
> Would formals() work for you here?
> 
>



From andy_liaw at merck.com  Tue Sep 14 17:00:41 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 14 Sep 2004 11:00:41 -0400
Subject: [R] Getting the argument list within a function
Message-ID: <3A822319EB35174CA3714066D590DCD504AF83A4@usrymx25.merck.com>

Is formals() what you're looking for?

Andy

> From: Roger D. Peng
> 
> Is there a way of getting the argument list of a function from within 
> that function?  For example, something like
> 
> f <- function(x, y = 3) {
> 	fargs <- getFunctionArgList()
> 	print(fargs)  ## Should be `alist(x, y = 3)'
> }
> 
> Thanks,
> 
> -roger
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From p.dalgaard at biostat.ku.dk  Tue Sep 14 17:04:23 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Sep 2004 17:04:23 +0200
Subject: [R] Getting the argument list within a function
In-Reply-To: <414704AA.5050304@jhsph.edu>
References: <414704AA.5050304@jhsph.edu>
Message-ID: <x2oek8lwnc.fsf@biostat.ku.dk>

"Roger D. Peng" <rpeng at jhsph.edu> writes:

> Is there a way of getting the argument list of a function from within
> that function?  For example, something like
> 
> f <- function(x, y = 3) {
> 	fargs <- getFunctionArgList()
> 	print(fargs)  ## Should be `alist(x, y = 3)'
> }


> f
function(x, y = 3) {
  fargs <- formals(sys.function())
  print(fargs)  ## Should be equivalent to `alist(x=, y = 3)'
}

(Notice a couple of fine points...)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ggrothendieck at myway.com  Tue Sep 14 17:05:23 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 14 Sep 2004 15:05:23 +0000 (UTC)
Subject: [R] erase columns
References: <20040914084420.4770.qmail@web13622.mail.yahoo.com>
Message-ID: <loom.20040914T165618-948@post.gmane.org>

michele lux <nedluk <at> yahoo.it> writes:

> Can somebody remember me which is the command to erase
> columns from a data frame?

To delete a single column assign NULL to it.  That works
because a data frame is a list and that works for lists.
Here are three examples of deleting column 5, the Species 
column, from the iris data set:

   data(iris)
   iris[,5] <- NULL  

   data(iris)
   iris$Species <- NULL

   data(iris)
   iris[,"Species"] <- NULL



From xiangli at gila-fw.bioengr.uic.edu  Tue Sep 14 17:10:06 2004
From: xiangli at gila-fw.bioengr.uic.edu (xiang li)
Date: Tue, 14 Sep 2004 10:10:06 -0500 (CDT)
Subject: [R] How to show the symbol of Angstrom ?
In-Reply-To: <41463DC4.1090202@stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0409141009310.8049-100000@gila-fw.bioengr.uic.edu>

Paul, Thank you very much! They all works!
Sean

On Tue, 14 Sep 2004, Paul Murrell wrote:

> Hi
> 
> 
> xiang li wrote:
> > Also, I am wondering if there is any source where the expressions of 
> > many symbols are collected.
> > Thanks you very much!!!
> 
> 
> (Assuming you mean draw the angstrom symbol on a plot ...)
> 
> There are several ways:
> 
> (i) Specify the character code in octal.  Assuming ISO Latin 1 encoding, 
> something like ...
>    plot(1, type="n")
>    text(1, 1, "\305")
> ... or ...
>    grid.newpage()
>    grid.text("\305")
> ... should work.  That should be ok on default setups for Windows and 
> Unix.  On the Mac it might have to be "\201" (untested)  See, e.g., 
> http://czyborra.com/charsets/iso8859.html#ISO-8859-1 (Unix)
> http://www.microsoft.com/typography/unicode/1252.gif (Windows)
> http://kodeks.uni-bamberg.de/Computer/CodePages/MacStd.htm (Mac)
> for other standard "symbols".
> 
> (ii) Use a mathematical expression.  This won't look as good because the 
> ring and the A are not a single coherent glyph, but it should work 
> "everywhere" ...
>    plot(1, type="n")
>    text(1, 1, expression(ring(A)))
> ... or ...
>    grid.newpage()
>    grid.text(expression(ring(A)))
> ... demo(plotmath) shows the range of things you can do with this approach.
> 
> (iii) Use a hershey font (again, should work on all platforms and 
> encodings) ...
>    plot(1, type="n")
>    text(1, 1, "\\oA", vfont=c("sans serif", "plain"))
> ... or ...
>    grid.newpage()
>    grid.text("\\oA", gp=gpar(fontfamily="HersheySans"))
> ... demo(Hershey) shows the symbols available with this approach.
> 
> Hope that helps.
> 
> Paul
> 

-- 


Li, Xiang (Sean)                      | xiangli at gila.bioengr.uic.edu
Dept of Bioengineering, SEO, MC 063   | ph:   (312) 355-2520
University of Illinois at Chicago     | fax:  (312) 996-5921 
Chicago, IL  60607-7052, USA          |



From tom_woody at swissinfo.org  Tue Sep 14 17:30:17 2004
From: tom_woody at swissinfo.org (=?ISO-8859-15?Q?Thomas_Sch=F6nhoff?=)
Date: Tue, 14 Sep 2004 17:30:17 +0200
Subject: [R] Howto enlarge fonts size in R- Graphics?
In-Reply-To: <4146DBC5.1050304@statistik.uni-dortmund.de>
References: <4146B016.1090002@swissinfo.org>
	<4146DBC5.1050304@statistik.uni-dortmund.de>
Message-ID: <41470E89.3030708@swissinfo.org>

Hello,

> Thomas Sch??nhoff wrote:

Well, thanks, I'll have a look at your advices.....

regards
Thomas



From maechler at stat.math.ethz.ch  Tue Sep 14 17:44:17 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 14 Sep 2004 17:44:17 +0200
Subject: [R] Re: datalist
In-Reply-To: <200409141411.KAA29345@blaise.dfci.harvard.edu>
References: <200409141411.KAA29345@blaise.dfci.harvard.edu>
Message-ID: <16711.4561.975406.121629@gargle.gargle.HOWL>

>>>>> "John" == John Zhang <jzhang at jimmy.harvard.edu>
>>>>>     on Tue, 14 Sep 2004 10:11:15 -0400 (EDT) writes:

    John> Hi,
    John> The following is a cut/paste from http://developer.r-project.org/200update.txt:

    John> ...

    John> 3) When a package is installed, all the data sets are loaded to see
    John> what they produce.  If this is undesirable (because they are
    John> enormous, or depend on other packages that need to be installed
    John> later, ...), add a `datalist' file to the data subdirectory as
    John> described in `Writing R Extensions'.

    John> ...



    John> I only saw a mentioning of 00Index in the description
    John> about the data subdirectory in Writing R
    John> Extensions/Package Subdirectories. Could someone point
    John> me to the right place or tell me what a 'datalist'
    John> file is supposed to be?

You need "Writing R Extensions" from 'R-devel' aka  "2.0.0 unstable".
The manuals of the UN-released versions of R, are typically
available from www.R-project.org, [Documentation] -> "Help pages"
which points to http://stat.ethz.ch/R-manual/

But for the sake of it, here is the entry for 'datalist' 
(found very quickly in Emacs Info):

   If your data files are enormous you can speed up installation
   by providing a file `datalist' in the `data' subdirectory.
   This should have one line per topic that `data()' will find,
   in the format `foo' if `data(foo)' provides `foo', or `foo:
   bar bah' if `data(foo)' provides `bar' and `bah'.

Regards,
Martin



From smestrella at juno.com  Tue Sep 14 17:56:38 2004
From: smestrella at juno.com (smestrella@juno.com)
Date: Tue, 14 Sep 2004 15:56:38 GMT
Subject: [R] date library and boxplots
Message-ID: <20040914.085712.17147.813423@webmail20.lax.untd.com>


Hello,

I have been trying to use the date library (mdy.date) to create notched boxplots, but have not been successful.  Can anybody help with the code for this command?

Thank you,
Stephanie



From ctsolomon at wisc.edu  Tue Sep 14 18:07:09 2004
From: ctsolomon at wisc.edu (Chris Solomon)
Date: Tue, 14 Sep 2004 11:07:09 -0500
Subject: [R] repeated measures and covariance structures
Message-ID: <000201c49a74$e396ef20$883e5c90@limnology.wisc.edu>

Hello-

I'm trying to do some repeated measures ANOVAs. In the past, using SAS,
I have used the framework outlined in Littell et al.'s "SAS System for
Mixed Models", using the REPEATED statement in PROC MIXED to model
variation across time within an experimental unit. SAS allows you to
specify different within-unit covariance structures (e.g., compound
symmetric, AR(1), etc.) to determine the best model.

I'm having trouble figuring out how to do a similar analysis in R. While
'lme' will let you choose the class of correlation structure to use, it
seems to require that you specify this structure rather than using the
data to estimate the covariance matrix. For example, it seems that to
specify 'corAR1' as the correlation structure, you have to pick a value
for rho, the autoregressive parameter.

So, my question: is there a way to tell 'lme' what sort of covariance
structure you'd like to model, and then let the function estimate the
covariances? Or, alternatively, is there a better way to go about this
sort of repeated measures analysis in R? I've exhausted my available R
resources and done a pretty good search of the help archives without
finding a clear answer.

Thanks much!
Chris



*******
Chris Solomon
Center for Limnology
Univ. of Wisconsin
Phone: (608) 263-2465



From sundar.dorai-raj at PDF.COM  Tue Sep 14 18:15:46 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Tue, 14 Sep 2004 11:15:46 -0500
Subject: [R] reshaping some data
Message-ID: <41471932.3090808@pdf.com>

Hi all,
   I have a data.frame with the following colnames pattern:

x1 y11 x2 y21 y22 y23 x3 y31 y32 ...

I.e. I have an x followed by a few y's. What I would like to do is turn 
this wide format into a tall format with two columns: "x", "y". The 
structure is that xi needs to be associated with yij (e.g. x1 should 
next to y11 and y12, x2 should be next to y21, y22, and y23, etc.).

  x   y
x1 y11
x2 y21
x2 y22
x2 y23
x3 y31
x3 y32
...

I have looked at ?reshape but I didn't see how it could work with this 
structure. I have a solution using nested for loops (see below), but 
it's slow and not very efficient. I would like to find a vectorised 
solution that would achieve the same thing.

Now, for an example:

x <- data.frame(x1 =  1: 5, y11 =  1: 5,
                 x2 =  6:10, y21 =  6:10, y22 = 11:15,
                 x3 = 11:15, y31 = 16:20,
                 x4 = 16:20, y41 = 21:25, y42 = 26:30, y43 = 31:35)
# which are the x columns
nmx <- grep("^x", names(x))
# which are the y columns
nmy <- grep("^y", names(x))
# grab y values
y <- unlist(x[nmy])
# reserve some space for the x's
z <- vector("numeric", length(y))
# a loop counter
k <- 0
n <- nrow(x)
seq.n <- seq(n)
# determine how many times to repeat the x's
repy <- diff(c(nmx, length(names(x)) + 1)) - 1
for(i in seq(along = nmx)) {
   for(j in seq(repy[i])) {
     # store the x values in the appropriate z indices
     z[seq.n + k * n] <- x[, nmx[i]]
     # move to next block in z
     k <- k + 1
   }
}
data.frame(x = z, y = y, row.names = NULL)



From fchamu at gmail.com  Tue Sep 14 18:18:42 2004
From: fchamu at gmail.com (Francisco Chamu)
Date: Tue, 14 Sep 2004 12:18:42 -0400
Subject: [R] Signs of loadings from princomp on Windows
In-Reply-To: <41468FC5.2030904@statistik.uni-dortmund.de>
References: <Pine.LNX.4.44.0409140709500.8690-100000@gannet.stats>
	<41468FC5.2030904@statistik.uni-dortmund.de>
Message-ID: <ce17a70f0409140918408afa9e@mail.gmail.com>

I have run this on both Windows 2000 and XP.  All I did was install
the binaries from CRAN so I think I am using the standard Rblas.dll.

To reproduce what I see you must run the code at the beginning of the
R session.  After the second run, all subsequent runs give the same
result as the second set.

Thanks,
Francisco


On Tue, 14 Sep 2004 08:29:25 +0200, Uwe Ligges
<ligges at statistik.uni-dortmund.de> wrote:
> Prof Brian Ripley wrote:
> > I get the second set each time, on Windows, using the build from CRAN.
> > Which BLAS are you using?
> 
> 
> Works also well for me with a self compiled R-1.9.1 (both with standard
> Rblas as well as with the Rblas.dll for Athlon CPU from CRAN).
> Is this a NT-based version of Windows (NT, 2k, XP)?
> 
> Uwe
> 
> 
> 
> 
> > On Tue, 14 Sep 2004, Francisco Chamu wrote:
> >
> >
> >>I start a clean session of R 1.9.1 on Windows and I run the following code:
> >>
> >>
> >>>library(MASS)
> >>>data(painters)
> >>>pca.painters <- princomp(painters[ ,1:4])
> >>>loadings(pca.painters)
> >>
> >>Loadings:
> >>            Comp.1 Comp.2 Comp.3 Comp.4
> >>Composition  0.484 -0.376  0.784 -0.101
> >>Drawing      0.424  0.187 -0.280 -0.841
> >>Colour      -0.381 -0.845 -0.211 -0.310
> >>Expression   0.664 -0.330 -0.513  0.432
> >>
> >>               Comp.1 Comp.2 Comp.3 Comp.4
> >>SS loadings      1.00   1.00   1.00   1.00
> >>Proportion Var   0.25   0.25   0.25   0.25
> >>Cumulative Var   0.25   0.50   0.75   1.00
> >>
> >>However, if I rerun the same analysis, the loadings of the first
> >>component have the opposite sign (see below), why is that?  I have
> >>read the note
> >>in the princomp help that says
> >>
> >>    "The signs of the columns of the loadings and scores are arbitrary,
> >>     and so may differ between different programs for PCA, and even
> >>     between different builds of R."
> >>
> >>However, I still would expect the same signs for two runs in the same session.
> >>
> >>
> >>>pca.painters <- princomp(painters[ ,1:4])
> >>>loadings(pca.painters)
> >>
> >>Loadings:
> >>            Comp.1 Comp.2 Comp.3 Comp.4
> >>Composition -0.484 -0.376  0.784 -0.101
> >>Drawing     -0.424  0.187 -0.280 -0.841
> >>Colour       0.381 -0.845 -0.211 -0.310
> >>Expression  -0.664 -0.330 -0.513  0.432
> >>
> >>               Comp.1 Comp.2 Comp.3 Comp.4
> >>SS loadings      1.00   1.00   1.00   1.00
> >>Proportion Var   0.25   0.25   0.25   0.25
> >>Cumulative Var   0.25   0.50   0.75   1.00
> >>
> >>>R.version
> >>
> >>         _
> >>platform i386-pc-mingw32
> >>arch     i386
> >>os       mingw32
> >>system   i386, mingw32
> >>status
> >>major    1
> >>minor    9.1
> >>year     2004
> >>month    06
> >>day      21
> >>language R
> >>
> >>BTW, I have tried the same in R 1.9.1 on Debian and I can't reproduce
> >>what I see
> >>on Windows.  In fact all the runs give the same as the second run on Windows.
> >>
> >>-Francisco
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >>
> >>
> >
> >
> 
>



From HDoran at air.org  Tue Sep 14 18:18:42 2004
From: HDoran at air.org (Doran, Harold)
Date: Tue, 14 Sep 2004 12:18:42 -0400
Subject: [R] repeated measures and covariance structures
Message-ID: <88EAF3512A55DF46B06B1954AEF73F74055C1857@dc1ex2.air.org>

Yes. Try something akin to

> fm1<- lme(y~time, data, random=~time|ID)

> fm2<-update(fm1, correlation=corAR1(form~time|ID) 

You can then use anova(fm1,fm2) to compare.

Harold

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Chris Solomon
Sent: Tuesday, September 14, 2004 12:07 PM
To: R-help at stat.math.ethz.ch
Subject: [R] repeated measures and covariance structures

Hello-

I'm trying to do some repeated measures ANOVAs. In the past, using SAS,
I have used the framework outlined in Littell et al.'s "SAS System for
Mixed Models", using the REPEATED statement in PROC MIXED to model
variation across time within an experimental unit. SAS allows you to
specify different within-unit covariance structures (e.g., compound
symmetric, AR(1), etc.) to determine the best model.

I'm having trouble figuring out how to do a similar analysis in R. While
'lme' will let you choose the class of correlation structure to use, it
seems to require that you specify this structure rather than using the
data to estimate the covariance matrix. For example, it seems that to
specify 'corAR1' as the correlation structure, you have to pick a value
for rho, the autoregressive parameter.

So, my question: is there a way to tell 'lme' what sort of covariance
structure you'd like to model, and then let the function estimate the
covariances? Or, alternatively, is there a better way to go about this
sort of repeated measures analysis in R? I've exhausted my available R
resources and done a pretty good search of the help archives without
finding a clear answer.

Thanks much!
Chris



*******
Chris Solomon
Center for Limnology
Univ. of Wisconsin
Phone: (608) 263-2465

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Tue Sep 14 18:25:18 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Sep 2004 17:25:18 +0100 (BST)
Subject: [R] Signs of loadings from princomp on Windows
In-Reply-To: <ce17a70f0409140918408afa9e@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0409141723310.13336-100000@gannet.stats>

On Tue, 14 Sep 2004, Francisco Chamu wrote:

> I have run this on both Windows 2000 and XP.  All I did was install
> the binaries from CRAN so I think I am using the standard Rblas.dll.
> 
> To reproduce what I see you must run the code at the beginning of the
> R session.  

We did, as you said `start a clean session'.

I think to reproduce what you see we have to be using your account on your 
computer.

> After the second run, all subsequent runs give the same
> result as the second set.
> 
> Thanks,
> Francisco
> 
> 
> On Tue, 14 Sep 2004 08:29:25 +0200, Uwe Ligges
> <ligges at statistik.uni-dortmund.de> wrote:
> > Prof Brian Ripley wrote:
> > > I get the second set each time, on Windows, using the build from CRAN.
> > > Which BLAS are you using?
> > 
> > 
> > Works also well for me with a self compiled R-1.9.1 (both with standard
> > Rblas as well as with the Rblas.dll for Athlon CPU from CRAN).
> > Is this a NT-based version of Windows (NT, 2k, XP)?
> > 
> > Uwe
> > 
> > 
> > 
> > 
> > > On Tue, 14 Sep 2004, Francisco Chamu wrote:
> > >
> > >
> > >>I start a clean session of R 1.9.1 on Windows and I run the following code:
> > >>
> > >>
> > >>>library(MASS)
> > >>>data(painters)
> > >>>pca.painters <- princomp(painters[ ,1:4])
> > >>>loadings(pca.painters)
> > >>
> > >>Loadings:
> > >>            Comp.1 Comp.2 Comp.3 Comp.4
> > >>Composition  0.484 -0.376  0.784 -0.101
> > >>Drawing      0.424  0.187 -0.280 -0.841
> > >>Colour      -0.381 -0.845 -0.211 -0.310
> > >>Expression   0.664 -0.330 -0.513  0.432
> > >>
> > >>               Comp.1 Comp.2 Comp.3 Comp.4
> > >>SS loadings      1.00   1.00   1.00   1.00
> > >>Proportion Var   0.25   0.25   0.25   0.25
> > >>Cumulative Var   0.25   0.50   0.75   1.00
> > >>
> > >>However, if I rerun the same analysis, the loadings of the first
> > >>component have the opposite sign (see below), why is that?  I have
> > >>read the note
> > >>in the princomp help that says
> > >>
> > >>    "The signs of the columns of the loadings and scores are arbitrary,
> > >>     and so may differ between different programs for PCA, and even
> > >>     between different builds of R."
> > >>
> > >>However, I still would expect the same signs for two runs in the same session.
> > >>
> > >>
> > >>>pca.painters <- princomp(painters[ ,1:4])
> > >>>loadings(pca.painters)
> > >>
> > >>Loadings:
> > >>            Comp.1 Comp.2 Comp.3 Comp.4
> > >>Composition -0.484 -0.376  0.784 -0.101
> > >>Drawing     -0.424  0.187 -0.280 -0.841
> > >>Colour       0.381 -0.845 -0.211 -0.310
> > >>Expression  -0.664 -0.330 -0.513  0.432
> > >>
> > >>               Comp.1 Comp.2 Comp.3 Comp.4
> > >>SS loadings      1.00   1.00   1.00   1.00
> > >>Proportion Var   0.25   0.25   0.25   0.25
> > >>Cumulative Var   0.25   0.50   0.75   1.00
> > >>
> > >>>R.version
> > >>
> > >>         _
> > >>platform i386-pc-mingw32
> > >>arch     i386
> > >>os       mingw32
> > >>system   i386, mingw32
> > >>status
> > >>major    1
> > >>minor    9.1
> > >>year     2004
> > >>month    06
> > >>day      21
> > >>language R
> > >>
> > >>BTW, I have tried the same in R 1.9.1 on Debian and I can't reproduce
> > >>what I see
> > >>on Windows.  In fact all the runs give the same as the second run on Windows.
> > >>
> > >>-Francisco
> > >>
> > >>______________________________________________
> > >>R-help at stat.math.ethz.ch mailing list
> > >>https://stat.ethz.ch/mailman/listinfo/r-help
> > >>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > >>
> > >>
> > >
> > >
> > 
> >
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Sep 14 18:30:01 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Sep 2004 17:30:01 +0100 (BST)
Subject: [R] repeated measures and covariance structures
In-Reply-To: <000201c49a74$e396ef20$883e5c90@limnology.wisc.edu>
Message-ID: <Pine.LNX.4.44.0409141725290.13336-100000@gannet.stats>

On Tue, 14 Sep 2004, Chris Solomon wrote:

> Hello-
> 
> I'm trying to do some repeated measures ANOVAs. In the past, using SAS,
> I have used the framework outlined in Littell et al.'s "SAS System for
> Mixed Models", using the REPEATED statement in PROC MIXED to model
> variation across time within an experimental unit. SAS allows you to
> specify different within-unit covariance structures (e.g., compound
> symmetric, AR(1), etc.) to determine the best model.
> 
> I'm having trouble figuring out how to do a similar analysis in R. While
> 'lme' will let you choose the class of correlation structure to use, it
> seems to require that you specify this structure rather than using the
> data to estimate the covariance matrix. For example, it seems that to
> specify 'corAR1' as the correlation structure, you have to pick a value
> for rho, the autoregressive parameter.

Why does `it seems'? Your information is incorrect.

> So, my question: is there a way to tell 'lme' what sort of covariance
> structure you'd like to model, and then let the function estimate the
> covariances? 

That is the default.  Take a look at the examples in Venables & Ripley or 
Pinheiro & Bates (as recommended in the posting guide and the FAQ).

> Or, alternatively, is there a better way to go about this
> sort of repeated measures analysis in R? I've exhausted my available R
> resources and done a pretty good search of the help archives without
> finding a clear answer.

Did you look at the references in the FAQ?

> Chris Solomon
> Center for Limnology
> Univ. of Wisconsin

You do know where the maintainer of the nlme package works, don't you?
I am sure your University library has a copy or two of Pinheiro & Bates!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fm3a004 at math.uni-hamburg.de  Tue Sep 14 18:30:43 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Tue, 14 Sep 2004 18:30:43 +0200 (MEST)
Subject: [R] repeated measures and covariance structures
In-Reply-To: <000201c49a74$e396ef20$883e5c90@limnology.wisc.edu>
Message-ID: <Pine.GSO.3.95q.1040914182323.5908E-100000@sun35.math.uni-hamburg.de>

Hello Chris,

as far as I know from the Pinheiro and Bates book "Mixed-Effects Models in S
and S-PLUS", the autoregressive parameter has to be specified only as
initial value for the estimation. That is, the parameter will be estimated,
but the result may depend on the prespecified value. You do not need to
specify it. Then, 0 is used as initial value and this may work well (as in
the example in Pinheiro and Bates, p. 241 f.).

Christian

PS: Have you been at a workshop on model selection near Munich in Nov. 2002?
I suspect that I know who you are but I am not sure.

On Tue, 14 Sep 2004, Chris Solomon wrote:

> Hello-
> 
> I'm trying to do some repeated measures ANOVAs. In the past, using SAS,
> I have used the framework outlined in Littell et al.'s "SAS System for
> Mixed Models", using the REPEATED statement in PROC MIXED to model
> variation across time within an experimental unit. SAS allows you to
> specify different within-unit covariance structures (e.g., compound
> symmetric, AR(1), etc.) to determine the best model.
> 
> I'm having trouble figuring out how to do a similar analysis in R. While
> 'lme' will let you choose the class of correlation structure to use, it
> seems to require that you specify this structure rather than using the
> data to estimate the covariance matrix. For example, it seems that to
> specify 'corAR1' as the correlation structure, you have to pick a value
> for rho, the autoregressive parameter.
> 
> So, my question: is there a way to tell 'lme' what sort of covariance
> structure you'd like to model, and then let the function estimate the
> covariances? Or, alternatively, is there a better way to go about this
> sort of repeated measures analysis in R? I've exhausted my available R
> resources and done a pretty good search of the help archives without
> finding a clear answer.
> 
> Thanks much!
> Chris
> 
> 
> 
> *******
> Chris Solomon
> Center for Limnology
> Univ. of Wisconsin
> Phone: (608) 263-2465
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From sundar.dorai-raj at PDF.COM  Tue Sep 14 18:30:37 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Tue, 14 Sep 2004 11:30:37 -0500
Subject: [R] Signs of loadings from princomp on Windows
In-Reply-To: <ce17a70f0409140918408afa9e@mail.gmail.com>
References: <Pine.LNX.4.44.0409140709500.8690-100000@gannet.stats>	<41468FC5.2030904@statistik.uni-dortmund.de>
	<ce17a70f0409140918408afa9e@mail.gmail.com>
Message-ID: <41471CAD.3090708@pdf.com>

Hi all,
I was able to replicate Francisco's observation. I'm using R-1.9.1 
installed from binaries on Windows 2000 Pro.

[Previously saved workspace restored]

 > library(MASS)
 > data(painters)
 > pca.painters <- princomp(painters[ ,1:4])
 > loadings(pca.painters)

Loadings:
             Comp.1 Comp.2 Comp.3 Comp.4
Composition  0.484 -0.376  0.784 -0.101
Drawing      0.424  0.187 -0.280 -0.841
Colour      -0.381 -0.845 -0.211 -0.310
Expression   0.664 -0.330 -0.513  0.432

                Comp.1 Comp.2 Comp.3 Comp.4
SS loadings      1.00   1.00   1.00   1.00
Proportion Var   0.25   0.25   0.25   0.25
Cumulative Var   0.25   0.50   0.75   1.00
 > pca.painters <- princomp(painters[ ,1:4])
 > loadings(pca.painters)

Loadings:
             Comp.1 Comp.2 Comp.3 Comp.4
Composition -0.484 -0.376  0.784 -0.101
Drawing     -0.424  0.187 -0.280 -0.841
Colour       0.381 -0.845 -0.211 -0.310
Expression  -0.664 -0.330 -0.513  0.432

                Comp.1 Comp.2 Comp.3 Comp.4
SS loadings      1.00   1.00   1.00   1.00
Proportion Var   0.25   0.25   0.25   0.25
Cumulative Var   0.25   0.50   0.75   1.00
 > R.version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.1
year     2004
month    06
day      21
language R

Francisco Chamu wrote:

> I have run this on both Windows 2000 and XP.  All I did was install
> the binaries from CRAN so I think I am using the standard Rblas.dll.
> 
> To reproduce what I see you must run the code at the beginning of the
> R session.  After the second run, all subsequent runs give the same
> result as the second set.
> 
> Thanks,
> Francisco
> 
> 
> On Tue, 14 Sep 2004 08:29:25 +0200, Uwe Ligges
> <ligges at statistik.uni-dortmund.de> wrote:
> 
>>Prof Brian Ripley wrote:
>>
>>>I get the second set each time, on Windows, using the build from CRAN.
>>>Which BLAS are you using?
>>
>>
>>Works also well for me with a self compiled R-1.9.1 (both with standard
>>Rblas as well as with the Rblas.dll for Athlon CPU from CRAN).
>>Is this a NT-based version of Windows (NT, 2k, XP)?
>>
>>Uwe
>>
>>
>>
>>
>>
>>>On Tue, 14 Sep 2004, Francisco Chamu wrote:
>>>
>>>
>>>
>>>>I start a clean session of R 1.9.1 on Windows and I run the following code:
>>>>
>>>>
>>>>
>>>>>library(MASS)
>>>>>data(painters)
>>>>>pca.painters <- princomp(painters[ ,1:4])
>>>>>loadings(pca.painters)
>>>>
>>>>Loadings:
>>>>           Comp.1 Comp.2 Comp.3 Comp.4
>>>>Composition  0.484 -0.376  0.784 -0.101
>>>>Drawing      0.424  0.187 -0.280 -0.841
>>>>Colour      -0.381 -0.845 -0.211 -0.310
>>>>Expression   0.664 -0.330 -0.513  0.432
>>>>
>>>>              Comp.1 Comp.2 Comp.3 Comp.4
>>>>SS loadings      1.00   1.00   1.00   1.00
>>>>Proportion Var   0.25   0.25   0.25   0.25
>>>>Cumulative Var   0.25   0.50   0.75   1.00
>>>>
>>>>However, if I rerun the same analysis, the loadings of the first
>>>>component have the opposite sign (see below), why is that?  I have
>>>>read the note
>>>>in the princomp help that says
>>>>
>>>>   "The signs of the columns of the loadings and scores are arbitrary,
>>>>    and so may differ between different programs for PCA, and even
>>>>    between different builds of R."
>>>>
>>>>However, I still would expect the same signs for two runs in the same session.
>>>>
>>>>
>>>>
>>>>>pca.painters <- princomp(painters[ ,1:4])
>>>>>loadings(pca.painters)
>>>>
>>>>Loadings:
>>>>           Comp.1 Comp.2 Comp.3 Comp.4
>>>>Composition -0.484 -0.376  0.784 -0.101
>>>>Drawing     -0.424  0.187 -0.280 -0.841
>>>>Colour       0.381 -0.845 -0.211 -0.310
>>>>Expression  -0.664 -0.330 -0.513  0.432
>>>>
>>>>              Comp.1 Comp.2 Comp.3 Comp.4
>>>>SS loadings      1.00   1.00   1.00   1.00
>>>>Proportion Var   0.25   0.25   0.25   0.25
>>>>Cumulative Var   0.25   0.50   0.75   1.00
>>>>
>>>>
>>>>>R.version
>>>>
>>>>        _
>>>>platform i386-pc-mingw32
>>>>arch     i386
>>>>os       mingw32
>>>>system   i386, mingw32
>>>>status
>>>>major    1
>>>>minor    9.1
>>>>year     2004
>>>>month    06
>>>>day      21
>>>>language R
>>>>
>>>>BTW, I have tried the same in R 1.9.1 on Debian and I can't reproduce
>>>>what I see
>>>>on Windows.  In fact all the runs give the same as the second run on Windows.
>>>>
>>>>-Francisco
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>>
>>>>
>>>
>>>
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From gunter.berton at gene.com  Tue Sep 14 18:45:04 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 14 Sep 2004 09:45:04 -0700
Subject: [R] reshaping some data
In-Reply-To: <41471932.3090808@pdf.com>
Message-ID: <200409141645.i8EGj5KT029520@faraday.gene.com>

Sundar:

As I understand it, you can easily create an index variable (a pointer,
actually) that will pick out the y columns in order:

z<-yourdataframe
y<-as.vector(z[,indexvar])

So if you could cbind() the x's, you'd be all set.

Again, assuming I understand correctly, the x column you want is:

x<-z[,-indexvar] ## still a frame/matrix
nvec<-seq(length=ncol(x))
x<-as.vector(x[,rep(nvec,times=nvec)])

HTH -- and even if I got it wrong, it was fun, so thanks.

-- Bert

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Sundar 
> Dorai-Raj
> Sent: Tuesday, September 14, 2004 9:16 AM
> To: R-help
> Subject: [R] reshaping some data
> 
> Hi all,
>    I have a data.frame with the following colnames pattern:
> 
> x1 y11 x2 y21 y22 y23 x3 y31 y32 ...
> 
> I.e. I have an x followed by a few y's. What I would like to 
> do is turn 
> this wide format into a tall format with two columns: "x", "y". The 
> structure is that xi needs to be associated with yij (e.g. x1 should 
> next to y11 and y12, x2 should be next to y21, y22, and y23, etc.).
> 
>   x   y
> x1 y11
> x2 y21
> x2 y22
> x2 y23
> x3 y31
> x3 y32
> ...
> 
> I have looked at ?reshape but I didn't see how it could work 
> with this 
> structure. I have a solution using nested for loops (see below), but 
> it's slow and not very efficient. I would like to find a vectorised 
> solution that would achieve the same thing.
> 
> Now, for an example:
> 
> x <- data.frame(x1 =  1: 5, y11 =  1: 5,
>                  x2 =  6:10, y21 =  6:10, y22 = 11:15,
>                  x3 = 11:15, y31 = 16:20,
>                  x4 = 16:20, y41 = 21:25, y42 = 26:30, y43 = 31:35)
> # which are the x columns
> nmx <- grep("^x", names(x))
> # which are the y columns
> nmy <- grep("^y", names(x))
> # grab y values
> y <- unlist(x[nmy])
> # reserve some space for the x's
> z <- vector("numeric", length(y))
> # a loop counter
> k <- 0
> n <- nrow(x)
> seq.n <- seq(n)
> # determine how many times to repeat the x's
> repy <- diff(c(nmx, length(names(x)) + 1)) - 1
> for(i in seq(along = nmx)) {
>    for(j in seq(repy[i])) {
>      # store the x values in the appropriate z indices
>      z[seq.n + k * n] <- x[, nmx[i]]
>      # move to next block in z
>      k <- k + 1
>    }
> }
> data.frame(x = z, y = y, row.names = NULL)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

From Scott.Waichler at pnl.gov  Tue Sep 14 18:44:26 2004
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Tue, 14 Sep 2004 09:44:26 -0700
Subject: [R] Separation between tick marks and tick labels in lattice
Message-ID: <7E4C06F49D6FEB49BE4B60E5FC92ED7A96D112@pnlmse35.pnl.gov>


I can't find a way to control the distance between tick marks and tick
labels
in lattice.  In a stripplot I'm making these components are too close.
I don't
see anything like base graphics mgp in the scales list.

Thanks for your help,
Scott Waichler
Pacific Northwest National Laboratory
Richland, Washington, USA
scott.waichler at pnl.gov



From andy_liaw at merck.com  Tue Sep 14 18:55:32 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 14 Sep 2004 12:55:32 -0400
Subject: [R] Signs of loadings from princomp on Windows
Message-ID: <3A822319EB35174CA3714066D590DCD504AF83A9@usrymx25.merck.com>

Ditto here, although not from a fresh session.  Also 1.9.1 binary from CRAN,
on WinXPPro:

> library(MASS)
> data(painters)
> pca.painters <- princomp(painters[ ,1:4])
> loadings(pca.painters)

Loadings:
            Comp.1 Comp.2 Comp.3 Comp.4
Composition  0.484 -0.376  0.784 -0.101
Drawing      0.424  0.187 -0.280 -0.841
Colour      -0.381 -0.845 -0.211 -0.310
Expression   0.664 -0.330 -0.513  0.432

               Comp.1 Comp.2 Comp.3 Comp.4
SS loadings      1.00   1.00   1.00   1.00
Proportion Var   0.25   0.25   0.25   0.25
Cumulative Var   0.25   0.50   0.75   1.00
> pca.painters <- princomp(painters[ ,1:4])
> loadings(pca.painters)

Loadings:
            Comp.1 Comp.2 Comp.3 Comp.4
Composition -0.484 -0.376  0.784 -0.101
Drawing     -0.424  0.187 -0.280 -0.841
Colour       0.381 -0.845 -0.211 -0.310
Expression  -0.664 -0.330 -0.513  0.432

               Comp.1 Comp.2 Comp.3 Comp.4
SS loadings      1.00   1.00   1.00   1.00
Proportion Var   0.25   0.25   0.25   0.25
Cumulative Var   0.25   0.50   0.75   1.00

Andy

> From: Sundar Dorai-Raj
> 
> Hi all,
> I was able to replicate Francisco's observation. I'm using R-1.9.1 
> installed from binaries on Windows 2000 Pro.
> 
> [Previously saved workspace restored]
> 
>  > library(MASS)
>  > data(painters)
>  > pca.painters <- princomp(painters[ ,1:4])
>  > loadings(pca.painters)
> 
> Loadings:
>              Comp.1 Comp.2 Comp.3 Comp.4
> Composition  0.484 -0.376  0.784 -0.101
> Drawing      0.424  0.187 -0.280 -0.841
> Colour      -0.381 -0.845 -0.211 -0.310
> Expression   0.664 -0.330 -0.513  0.432
> 
>                 Comp.1 Comp.2 Comp.3 Comp.4
> SS loadings      1.00   1.00   1.00   1.00
> Proportion Var   0.25   0.25   0.25   0.25
> Cumulative Var   0.25   0.50   0.75   1.00
>  > pca.painters <- princomp(painters[ ,1:4])
>  > loadings(pca.painters)
> 
> Loadings:
>              Comp.1 Comp.2 Comp.3 Comp.4
> Composition -0.484 -0.376  0.784 -0.101
> Drawing     -0.424  0.187 -0.280 -0.841
> Colour       0.381 -0.845 -0.211 -0.310
> Expression  -0.664 -0.330 -0.513  0.432
> 
>                 Comp.1 Comp.2 Comp.3 Comp.4
> SS loadings      1.00   1.00   1.00   1.00
> Proportion Var   0.25   0.25   0.25   0.25
> Cumulative Var   0.25   0.50   0.75   1.00
>  > R.version
>           _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R
> 
> Francisco Chamu wrote:
> 
> > I have run this on both Windows 2000 and XP.  All I did was install
> > the binaries from CRAN so I think I am using the standard Rblas.dll.
> > 
> > To reproduce what I see you must run the code at the 
> beginning of the
> > R session.  After the second run, all subsequent runs give the same
> > result as the second set.
> > 
> > Thanks,
> > Francisco
> > 
> > 
> > On Tue, 14 Sep 2004 08:29:25 +0200, Uwe Ligges
> > <ligges at statistik.uni-dortmund.de> wrote:
> > 
> >>Prof Brian Ripley wrote:
> >>
> >>>I get the second set each time, on Windows, using the 
> build from CRAN.
> >>>Which BLAS are you using?
> >>
> >>
> >>Works also well for me with a self compiled R-1.9.1 (both 
> with standard
> >>Rblas as well as with the Rblas.dll for Athlon CPU from CRAN).
> >>Is this a NT-based version of Windows (NT, 2k, XP)?
> >>
> >>Uwe
> >>
> >>
> >>
> >>
> >>
> >>>On Tue, 14 Sep 2004, Francisco Chamu wrote:
> >>>
> >>>
> >>>
> >>>>I start a clean session of R 1.9.1 on Windows and I run 
> the following code:
> >>>>
> >>>>
> >>>>
> >>>>>library(MASS)
> >>>>>data(painters)
> >>>>>pca.painters <- princomp(painters[ ,1:4])
> >>>>>loadings(pca.painters)
> >>>>
> >>>>Loadings:
> >>>>           Comp.1 Comp.2 Comp.3 Comp.4
> >>>>Composition  0.484 -0.376  0.784 -0.101
> >>>>Drawing      0.424  0.187 -0.280 -0.841
> >>>>Colour      -0.381 -0.845 -0.211 -0.310
> >>>>Expression   0.664 -0.330 -0.513  0.432
> >>>>
> >>>>              Comp.1 Comp.2 Comp.3 Comp.4
> >>>>SS loadings      1.00   1.00   1.00   1.00
> >>>>Proportion Var   0.25   0.25   0.25   0.25
> >>>>Cumulative Var   0.25   0.50   0.75   1.00
> >>>>
> >>>>However, if I rerun the same analysis, the loadings of the first
> >>>>component have the opposite sign (see below), why is that?  I have
> >>>>read the note
> >>>>in the princomp help that says
> >>>>
> >>>>   "The signs of the columns of the loadings and scores 
> are arbitrary,
> >>>>    and so may differ between different programs for PCA, and even
> >>>>    between different builds of R."
> >>>>
> >>>>However, I still would expect the same signs for two runs 
> in the same session.
> >>>>
> >>>>
> >>>>
> >>>>>pca.painters <- princomp(painters[ ,1:4])
> >>>>>loadings(pca.painters)
> >>>>
> >>>>Loadings:
> >>>>           Comp.1 Comp.2 Comp.3 Comp.4
> >>>>Composition -0.484 -0.376  0.784 -0.101
> >>>>Drawing     -0.424  0.187 -0.280 -0.841
> >>>>Colour       0.381 -0.845 -0.211 -0.310
> >>>>Expression  -0.664 -0.330 -0.513  0.432
> >>>>
> >>>>              Comp.1 Comp.2 Comp.3 Comp.4
> >>>>SS loadings      1.00   1.00   1.00   1.00
> >>>>Proportion Var   0.25   0.25   0.25   0.25
> >>>>Cumulative Var   0.25   0.50   0.75   1.00
> >>>>
> >>>>
> >>>>>R.version
> >>>>
> >>>>        _
> >>>>platform i386-pc-mingw32
> >>>>arch     i386
> >>>>os       mingw32
> >>>>system   i386, mingw32
> >>>>status
> >>>>major    1
> >>>>minor    9.1
> >>>>year     2004
> >>>>month    06
> >>>>day      21
> >>>>language R
> >>>>
> >>>>BTW, I have tried the same in R 1.9.1 on Debian and I 
> can't reproduce
> >>>>what I see
> >>>>on Windows.  In fact all the runs give the same as the 
> second run on Windows.
> >>>>
> >>>>-Francisco
> >>>>
> >>>>______________________________________________
> >>>>R-help at stat.math.ethz.ch mailing list
> >>>>https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >>>>
> >>>>
> >>>
> >>>
> 
> >>
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From tplate at blackmesacapital.com  Tue Sep 14 19:04:29 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Tue, 14 Sep 2004 11:04:29 -0600
Subject: [R] Signs of loadings from princomp on Windows
In-Reply-To: <Pine.LNX.4.44.0409141723310.13336-100000@gannet.stats>
References: <ce17a70f0409140918408afa9e@mail.gmail.com>
	<Pine.LNX.4.44.0409141723310.13336-100000@gannet.stats>
Message-ID: <6.1.0.6.2.20040914105042.05a86cb0@mailhost.blackmesacapital.com>

FWIW, I see the same behavior as Francisco on my Windows machine (also an 
installation of the windows binary without trying to install any special 
BLAS libraries):

 > library(MASS)
 > data(painters)
 > pca.painters <- princomp(painters[ ,1:4])
 > loadings(pca.painters)

Loadings:
             Comp.1 Comp.2 Comp.3 Comp.4
Composition  0.484 -0.376  0.784 -0.101
Drawing      0.424  0.187 -0.280 -0.841
Colour      -0.381 -0.845 -0.211 -0.310
Expression   0.664 -0.330 -0.513  0.432

                Comp.1 Comp.2 Comp.3 Comp.4
SS loadings      1.00   1.00   1.00   1.00
Proportion Var   0.25   0.25   0.25   0.25
Cumulative Var   0.25   0.50   0.75   1.00
 > pca.painters <- princomp(painters[ ,1:4])
 > loadings(pca.painters)

Loadings:
             Comp.1 Comp.2 Comp.3 Comp.4
Composition -0.484 -0.376  0.784 -0.101
Drawing     -0.424  0.187 -0.280 -0.841
Colour       0.381 -0.845 -0.211 -0.310
Expression  -0.664 -0.330 -0.513  0.432

                Comp.1 Comp.2 Comp.3 Comp.4
SS loadings      1.00   1.00   1.00   1.00
Proportion Var   0.25   0.25   0.25   0.25
Cumulative Var   0.25   0.50   0.75   1.00
 > R.version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.1
year     2004
month    06
day      21
language R
 >

My machine is a dual-processor hp xw8000.

I also get the same results with R 2.0.0 dev as in
 > R.version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status   Under development (unstable)
major    2
minor    0.0
year     2004
month    09
day      13
language R
 >

-- Tony Plate

At Tuesday 10:25 AM 9/14/2004, Prof Brian Ripley wrote:
>On Tue, 14 Sep 2004, Francisco Chamu wrote:
>
> > I have run this on both Windows 2000 and XP.  All I did was install
> > the binaries from CRAN so I think I am using the standard Rblas.dll.
> >
> > To reproduce what I see you must run the code at the beginning of the
> > R session.
>
>We did, as you said `start a clean session'.
>
>I think to reproduce what you see we have to be using your account on your
>computer.
>
> > After the second run, all subsequent runs give the same
> > result as the second set.
> >
> > Thanks,
> > Francisco
> >
> >
> > On Tue, 14 Sep 2004 08:29:25 +0200, Uwe Ligges
> > <ligges at statistik.uni-dortmund.de> wrote:
> > > Prof Brian Ripley wrote:
> > > > I get the second set each time, on Windows, using the build from CRAN.
> > > > Which BLAS are you using?
> > >
> > >
> > > Works also well for me with a self compiled R-1.9.1 (both with standard
> > > Rblas as well as with the Rblas.dll for Athlon CPU from CRAN).
> > > Is this a NT-based version of Windows (NT, 2k, XP)?
> > >
> > > Uwe
> > >
> > >
> > >
> > >
> > > > On Tue, 14 Sep 2004, Francisco Chamu wrote:
> > > >
> > > >
> > > >>I start a clean session of R 1.9.1 on Windows and I run the 
> following code:
> > > >>
> > > >>
> > > >>>library(MASS)
> > > >>>data(painters)
> > > >>>pca.painters <- princomp(painters[ ,1:4])
> > > >>>loadings(pca.painters)
> > > >>
> > > >>Loadings:
> > > >>            Comp.1 Comp.2 Comp.3 Comp.4
> > > >>Composition  0.484 -0.376  0.784 -0.101
> > > >>Drawing      0.424  0.187 -0.280 -0.841
> > > >>Colour      -0.381 -0.845 -0.211 -0.310
> > > >>Expression   0.664 -0.330 -0.513  0.432
> > > >>
> > > >>               Comp.1 Comp.2 Comp.3 Comp.4
> > > >>SS loadings      1.00   1.00   1.00   1.00
> > > >>Proportion Var   0.25   0.25   0.25   0.25
> > > >>Cumulative Var   0.25   0.50   0.75   1.00
> > > >>
> > > >>However, if I rerun the same analysis, the loadings of the first
> > > >>component have the opposite sign (see below), why is that?  I have
> > > >>read the note
> > > >>in the princomp help that says
> > > >>
> > > >>    "The signs of the columns of the loadings and scores are arbitrary,
> > > >>     and so may differ between different programs for PCA, and even
> > > >>     between different builds of R."
> > > >>
> > > >>However, I still would expect the same signs for two runs in the 
> same session.
> > > >>
> > > >>
> > > >>>pca.painters <- princomp(painters[ ,1:4])
> > > >>>loadings(pca.painters)
> > > >>
> > > >>Loadings:
> > > >>            Comp.1 Comp.2 Comp.3 Comp.4
> > > >>Composition -0.484 -0.376  0.784 -0.101
> > > >>Drawing     -0.424  0.187 -0.280 -0.841
> > > >>Colour       0.381 -0.845 -0.211 -0.310
> > > >>Expression  -0.664 -0.330 -0.513  0.432
> > > >>
> > > >>               Comp.1 Comp.2 Comp.3 Comp.4
> > > >>SS loadings      1.00   1.00   1.00   1.00
> > > >>Proportion Var   0.25   0.25   0.25   0.25
> > > >>Cumulative Var   0.25   0.50   0.75   1.00
> > > >>
> > > >>>R.version
> > > >>
> > > >>         _
> > > >>platform i386-pc-mingw32
> > > >>arch     i386
> > > >>os       mingw32
> > > >>system   i386, mingw32
> > > >>status
> > > >>major    1
> > > >>minor    9.1
> > > >>year     2004
> > > >>month    06
> > > >>day      21
> > > >>language R
> > > >>
> > > >>BTW, I have tried the same in R 1.9.1 on Debian and I can't reproduce
> > > >>what I see
> > > >>on Windows.  In fact all the runs give the same as the second run 
> on Windows.
> > > >>
> > > >>-Francisco
> > > >>
> > > >>______________________________________________
> > > >>R-help at stat.math.ethz.ch mailing list
> > > >>https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> > > >>
> > > >>
> > > >
> > > >
> > >
> > >
> >
> >
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From s-plus at wiwi.uni-bielefeld.de  Tue Sep 14 19:07:59 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Tue, 14 Sep 2004 19:07:59 +0200
Subject: [R] reshaping some data
References: <41471932.3090808@pdf.com>
Message-ID: <4147256F.9080409@wiwi.uni-bielefeld.de>

Try:

x <- data.frame(x1 =  1: 5, y11 =  1: 5,
                x2 =  6:10, y21 =  6:10, y22 = 11:15,
                x3 = 11:15, y31 = 16:20,
                x4 = 16:20, y41 = 21:25, y42 = 26:30, y43 = 31:35)

df.names<-names(x)
ynames<-df.names[grep("y",df.names)]
xnames<-substring(sub("y","x",ynames),1,2)
cbind(unlist(x[,xnames]),unlist(x[,ynames]))

Peter

Sundar Dorai-Raj wrote:

> Hi all,
>   I have a data.frame with the following colnames pattern:
>
> x1 y11 x2 y21 y22 y23 x3 y31 y32 ...
>
> I.e. I have an x followed by a few y's. What I would like to do is 
> turn this wide format into a tall format with two columns: "x", "y". 
> The structure is that xi needs to be associated with yij (e.g. x1 
> should next to y11 and y12, x2 should be next to y21, y22, and y23, 
> etc.).
>
>  x   y
> x1 y11
> x2 y21
> x2 y22
> x2 y23
> x3 y31
> x3 y32
> ...
>
> I have looked at ?reshape but I didn't see how it could work with this 
> structure. I have a solution using nested for loops (see below), but 
> it's slow and not very efficient. I would like to find a vectorised 
> solution that would achieve the same thing.
>
> Now, for an example:
>
> x <- data.frame(x1 =  1: 5, y11 =  1: 5,
>                 x2 =  6:10, y21 =  6:10, y22 = 11:15,
>                 x3 = 11:15, y31 = 16:20,
>                 x4 = 16:20, y41 = 21:25, y42 = 26:30, y43 = 31:35)
> # which are the x columns
> nmx <- grep("^x", names(x))
> # which are the y columns
> nmy <- grep("^y", names(x))
> # grab y values
> y <- unlist(x[nmy])
> # reserve some space for the x's
> z <- vector("numeric", length(y))
> # a loop counter
> k <- 0
> n <- nrow(x)
> seq.n <- seq(n)
> # determine how many times to repeat the x's
> repy <- diff(c(nmx, length(names(x)) + 1)) - 1
> for(i in seq(along = nmx)) {
>   for(j in seq(repy[i])) {
>     # store the x values in the appropriate z indices
>     z[seq.n + k * n] <- x[, nmx[i]]
>     # move to next block in z
>     k <- k + 1
>   }
> }
> data.frame(x = z, y = y, row.names = NULL)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From sundar.dorai-raj at PDF.COM  Tue Sep 14 19:13:48 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Tue, 14 Sep 2004 12:13:48 -0500
Subject: [R] reshaping some data
In-Reply-To: <200409141645.i8EGj5KT029520@faraday.gene.com>
References: <200409141645.i8EGj5KT029520@faraday.gene.com>
Message-ID: <414726CC.7040202@pdf.com>

Bert,
   Coming up with "nvec" was what I was missing. Modifying your solution 
slightly, here's what I ended up with:

z <- x[, nmx]
nvec <- seq(length(nmx))
z <- unlist(z[, rep(nvec, repy)])
z2 <- data.frame(x = z, y = y, row.names = NULL)

Thanks again,

--sundar

Berton Gunter wrote:

> Sundar:
> 
> As I understand it, you can easily create an index variable (a pointer,
> actually) that will pick out the y columns in order:
> 
> z<-yourdataframe
> y<-as.vector(z[,indexvar])
> 
> So if you could cbind() the x's, you'd be all set.
> 
> Again, assuming I understand correctly, the x column you want is:
> 
> x<-z[,-indexvar] ## still a frame/matrix
> nvec<-seq(length=ncol(x))
> x<-as.vector(x[,rep(nvec,times=nvec)])
> 
> HTH -- and even if I got it wrong, it was fun, so thanks.
> 
> -- Bert
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>  
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
>  
>  
> 
> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Sundar 
>>Dorai-Raj
>>Sent: Tuesday, September 14, 2004 9:16 AM
>>To: R-help
>>Subject: [R] reshaping some data
>>
>>Hi all,
>>   I have a data.frame with the following colnames pattern:
>>
>>x1 y11 x2 y21 y22 y23 x3 y31 y32 ...
>>
>>I.e. I have an x followed by a few y's. What I would like to 
>>do is turn 
>>this wide format into a tall format with two columns: "x", "y". The 
>>structure is that xi needs to be associated with yij (e.g. x1 should 
>>next to y11 and y12, x2 should be next to y21, y22, and y23, etc.).
>>
>>  x   y
>>x1 y11
>>x2 y21
>>x2 y22
>>x2 y23
>>x3 y31
>>x3 y32
>>...
>>
>>I have looked at ?reshape but I didn't see how it could work 
>>with this 
>>structure. I have a solution using nested for loops (see below), but 
>>it's slow and not very efficient. I would like to find a vectorised 
>>solution that would achieve the same thing.
>>
>>Now, for an example:
>>
>>x <- data.frame(x1 =  1: 5, y11 =  1: 5,
>>                 x2 =  6:10, y21 =  6:10, y22 = 11:15,
>>                 x3 = 11:15, y31 = 16:20,
>>                 x4 = 16:20, y41 = 21:25, y42 = 26:30, y43 = 31:35)
>># which are the x columns
>>nmx <- grep("^x", names(x))
>># which are the y columns
>>nmy <- grep("^y", names(x))
>># grab y values
>>y <- unlist(x[nmy])
>># reserve some space for the x's
>>z <- vector("numeric", length(y))
>># a loop counter
>>k <- 0
>>n <- nrow(x)
>>seq.n <- seq(n)
>># determine how many times to repeat the x's
>>repy <- diff(c(nmx, length(names(x)) + 1)) - 1
>>for(i in seq(along = nmx)) {
>>   for(j in seq(repy[i])) {
>>     # store the x values in the appropriate z indices
>>     z[seq.n + k * n] <- x[, nmx[i]]
>>     # move to next block in z
>>     k <- k + 1
>>   }
>>}
>>data.frame(x = z, y = y, row.names = NULL)
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
>>
>>------------------------------------------------------------------------
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Tue Sep 14 19:56:19 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 14 Sep 2004 17:56:19 +0000 (UTC)
Subject: [R] reshaping some data
References: <41471932.3090808@pdf.com>
Message-ID: <loom.20040914T195124-876@post.gmane.org>


Try this:

is.x <- substr(colnames(x),1,1) == "x"   # TRUE if col name starts with x
x. <- unlist(rep(x[,is.x], diff(which(c(is.x,TRUE)))-1))   # repeat x cols
names(x.) <- NULL
y. <- unlist(x[,!is.x])
DF <- data.frame(x = x., y = y., row.names = NULL)



Sundar Dorai-Raj <sundar.dorai-raj <at> PDF.COM> writes:

: 
: Hi all,
:    I have a data.frame with the following colnames pattern:
: 
: x1 y11 x2 y21 y22 y23 x3 y31 y32 ...
: 
: I.e. I have an x followed by a few y's. What I would like to do is turn 
: this wide format into a tall format with two columns: "x", "y". The 
: structure is that xi needs to be associated with yij (e.g. x1 should 
: next to y11 and y12, x2 should be next to y21, y22, and y23, etc.).
: 
:   x   y
: x1 y11
: x2 y21
: x2 y22
: x2 y23
: x3 y31
: x3 y32
: ...
: 
: I have looked at ?reshape but I didn't see how it could work with this 
: structure. I have a solution using nested for loops (see below), but 
: it's slow and not very efficient. I would like to find a vectorised 
: solution that would achieve the same thing.
: 
: Now, for an example:
: 
: x <- data.frame(x1 =  1: 5, y11 =  1: 5,
:                  x2 =  6:10, y21 =  6:10, y22 = 11:15,
:                  x3 = 11:15, y31 = 16:20,
:                  x4 = 16:20, y41 = 21:25, y42 = 26:30, y43 = 31:35)
: # which are the x columns
: nmx <- grep("^x", names(x))
: # which are the y columns
: nmy <- grep("^y", names(x))
: # grab y values
: y <- unlist(x[nmy])
: # reserve some space for the x's
: z <- vector("numeric", length(y))
: # a loop counter
: k <- 0
: n <- nrow(x)
: seq.n <- seq(n)
: # determine how many times to repeat the x's
: repy <- diff(c(nmx, length(names(x)) + 1)) - 1
: for(i in seq(along = nmx)) {
:    for(j in seq(repy[i])) {
:      # store the x values in the appropriate z indices
:      z[seq.n + k * n] <- x[, nmx[i]]
:      # move to next block in z
:      k <- k + 1
:    }
: }
: data.frame(x = z, y = y, row.names = NULL)



From deepayan at stat.wisc.edu  Tue Sep 14 21:12:15 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 14 Sep 2004 14:12:15 -0500
Subject: [R] Separation between tick marks and tick labels in lattice
In-Reply-To: <7E4C06F49D6FEB49BE4B60E5FC92ED7A96D112@pnlmse35.pnl.gov>
References: <7E4C06F49D6FEB49BE4B60E5FC92ED7A96D112@pnlmse35.pnl.gov>
Message-ID: <200409141412.15886.deepayan@stat.wisc.edu>

On Tuesday 14 September 2004 11:44, Waichler, Scott R wrote:
> I can't find a way to control the distance between tick marks and tick
> labels
> in lattice.  In a stripplot I'm making these components are too close.
> I don't
> see anything like base graphics mgp in the scales list.

There's none in the released version. There is a way in the r-devel version 
version, not via scales, but by the settings, e.g. something like

trellis.par.set(axis.components  = list(left = list(pad1 = 3)))

Deepayan



From LLessner at uamail.albany.edu  Tue Sep 14 21:13:01 2004
From: LLessner at uamail.albany.edu (Lawrence Lessner)
Date: Tue, 14 Sep 2004 15:13:01 -0400
Subject: [R] A question please
Message-ID: <606EB32565100B4DB32CB3423FACD310A58293@email2.albany.edu>

Hi Does R have a proceedure/software for capture recapture?  Thank you.
Lawrence Lessner
Please respond to LLessner at nycap.rr.com



From spencer.graves at pdf.com  Tue Sep 14 21:49:43 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 14 Sep 2004 12:49:43 -0700
Subject: [R] A question please
In-Reply-To: <606EB32565100B4DB32CB3423FACD310A58293@email2.albany.edu>
References: <606EB32565100B4DB32CB3423FACD310A58293@email2.albany.edu>
Message-ID: <41474B57.3020308@pdf.com>

      At "www.r-project.org" -> search -> "R site search", I just got 11 
hits for "capture-recapture".  Did you try this?  They may not all be 
relevant, but I suspect that some of them might be. 
     
      hope this helps.  spencer graves

Lawrence Lessner wrote:

>Hi Does R have a proceedure/software for capture recapture?  Thank you.
>Lawrence Lessner
>Please respond to LLessner at nycap.rr.com
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From jeff.laake at noaa.gov  Tue Sep 14 21:57:41 2004
From: jeff.laake at noaa.gov (Jeff Laake)
Date: Tue, 14 Sep 2004 12:57:41 -0700
Subject: [R] A question please 
In-Reply-To: <606EB32565100B4DB32CB3423FACD310A58293@email2.albany.edu>
References: <606EB32565100B4DB32CB3423FACD310A58293@email2.albany.edu>
Message-ID: <41474D35.4070400@noaa.gov>

Lawrence-

Are you familiar with the computer software MARK 
(http://www.cnr.colostate.edu/~gwhite/mark/mark.htm)?
It is a very complete package for analysis of capture-recapture data.  I 
have written an interface to MARK in R but it isn't ready for 
distribution. I'm presently in the process of creating the R help files 
and turning it into an R package. No promises on when I'll be done 
though. Currently my R interface does not support all of the models nor 
capabilities in MARK.  It is an evolving package. I developed it for my 
own use to be able to use the formula and design matrix capabilities in 
R to more easily develop models in MARK. I'm a little hesitant to send 
this message because I'm not looking to provide package support.    You 
may also want to be aware of the package WISP for R written by Walter 
Zucchini and David Borchers as a companion to his book on abundance 
estimation. See http://www.ruwpa.st-and.ac.uk/estimating.abundance/WiSP/

I'd be interested in hearing of other responses that you receive.

--jeff

Lawrence Lessner wrote:

> Hi Does R have a proceedure/software for capture recapture?  Thank you.
> Lawrence Lessner
> Please respond to LLessner at nycap.rr.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at myway.com  Tue Sep 14 21:58:31 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 14 Sep 2004 19:58:31 +0000 (UTC)
Subject: [R] reshaping some data
References: <41471932.3090808@pdf.com>
	<loom.20040914T195124-876@post.gmane.org>
Message-ID: <loom.20040914T215425-249@post.gmane.org>


Here is another variation.  It uses LOCF which is last
observation carried forward -- a function which takes a
logical vector and for each element provides the index of
the last TRUE value.  The version of LOCF here assumes
that the first element of the argument is TRUE which
happens to be the case here.

LOCF <- function(L) which(L)[cumsum(L}]

is.x <- substr(colnames(x),1,1) == "x"
x. <- unlist(x[,LOCF(is.x)[!is.x]])
names(x.) <- NULL
data.frame(x = x., y = unlist(x[,!is.x]), row.names = NULL) 


I found Peter's solution particularly clever.  Note that it
depends on the y colnames having the same first digit as the
corresponding x colnames; however they need not be in any
specific order, whereas the solution above and my previous 
one below depend on the y names being immediately after the 
x names but do not depend on the detailed content of the names.  
In the present case both these assumptions appear to hold
but in different situations one or the other of these assumptions
might be preferable.



Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

: 
: Try this:
: 
: is.x <- substr(colnames(x),1,1) == "x"   # TRUE if col name starts with x
: x. <- unlist(rep(x[,is.x], diff(which(c(is.x,TRUE)))-1))   # repeat x cols
: names(x.) <- NULL
: y. <- unlist(x[,!is.x])
: DF <- data.frame(x = x., y = y., row.names = NULL)
: 
: Sundar Dorai-Raj <sundar.dorai-raj <at> PDF.COM> writes:
: 
: : 
: : Hi all,
: :    I have a data.frame with the following colnames pattern:
: : 
: : x1 y11 x2 y21 y22 y23 x3 y31 y32 ...
: : 
: : I.e. I have an x followed by a few y's. What I would like to do is turn 
: : this wide format into a tall format with two columns: "x", "y". The 
: : structure is that xi needs to be associated with yij (e.g. x1 should 
: : next to y11 and y12, x2 should be next to y21, y22, and y23, etc.).
: : 
: :   x   y
: : x1 y11
: : x2 y21
: : x2 y22
: : x2 y23
: : x3 y31
: : x3 y32
: : ...
: : 
: : I have looked at ?reshape but I didn't see how it could work with this 
: : structure. I have a solution using nested for loops (see below), but 
: : it's slow and not very efficient. I would like to find a vectorised 
: : solution that would achieve the same thing.
: : 
: : Now, for an example:
: : 
: : x <- data.frame(x1 =  1: 5, y11 =  1: 5,
: :                  x2 =  6:10, y21 =  6:10, y22 = 11:15,
: :                  x3 = 11:15, y31 = 16:20,
: :                  x4 = 16:20, y41 = 21:25, y42 = 26:30, y43 = 31:35)
: : # which are the x columns
: : nmx <- grep("^x", names(x))
: : # which are the y columns
: : nmy <- grep("^y", names(x))
: : # grab y values
: : y <- unlist(x[nmy])
: : # reserve some space for the x's
: : z <- vector("numeric", length(y))
: : # a loop counter
: : k <- 0
: : n <- nrow(x)
: : seq.n <- seq(n)
: : # determine how many times to repeat the x's
: : repy <- diff(c(nmx, length(names(x)) + 1)) - 1
: : for(i in seq(along = nmx)) {
: :    for(j in seq(repy[i])) {
: :      # store the x values in the appropriate z indices
: :      z[seq.n + k * n] <- x[, nmx[i]]
: :      # move to next block in z
: :      k <- k + 1
: :    }
: : }
: : data.frame(x = z, y = y, row.names = NULL)
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://stat.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From christoph.lehmann at gmx.ch  Tue Sep 14 22:09:27 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Tue, 14 Sep 2004 22:09:27 +0200
Subject: [R] memory problem under windows
Message-ID: <41474FF7.9060302@gmx.ch>

I have (still) some memory problems, when trying to allocate a huge array:

WinXP pro, with 2G RAM

I start R by calling:	

Rgui.exe --max-mem-size=2Gb (as pointed out in R for windows FAQ)

R.Version(): i386-pc-mingw32, 9.1, 21.6.2004

## and here the problem
x.dim <- 46
y.dim <- 58
slices <- 40
volumes <- 1040
a <- rep(0, x.dim * y.dim * slices * volumes)
dim(a) <- c(x.dim, y.dim, slices, volumes)

gives me: "Error: cannot allocate vector of size 850425 Kb"

even though

memory.limit(size = NA)
yields 	2147483648

and

memory.size()
gives 905838768

so why is that and what can I do against it?

Many thanks for your kind help

Cheers

Christoph

-- 
Christoph Lehmann                            Phone:  ++41 31 930 93 83
Department of Psychiatric Neurophysiology    Mobile: ++41 76 570 28 00
University Hospital of Clinical Psychiatry   Fax:    ++41 31 930 99 61
Waldau                                            lehmann at puk.unibe.ch
CH-3000 Bern 60         http://www.puk.unibe.ch/cl/pn_ni_cv_cl_03.html



From jmacdon at med.umich.edu  Tue Sep 14 22:26:15 2004
From: jmacdon at med.umich.edu (James W. MacDonald)
Date: Tue, 14 Sep 2004 16:26:15 -0400
Subject: [R] memory problem under windows
In-Reply-To: <41474FF7.9060302@gmx.ch>
References: <41474FF7.9060302@gmx.ch>
Message-ID: <414753E7.1050604@med.umich.edu>

Christoph Lehmann wrote:
> I have (still) some memory problems, when trying to allocate a huge array:
> 
> WinXP pro, with 2G RAM
> 
> I start R by calling:   
> 
> Rgui.exe --max-mem-size=2Gb (as pointed out in R for windows FAQ)

Not sure that it actually says to use 2Gb there. You might try 
--max-mem-size=2000M, which seems to work better for me.

HTH,

Jim




-- 
James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109



From ripley at stats.ox.ac.uk  Tue Sep 14 22:29:20 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Sep 2004 21:29:20 +0100 (BST)
Subject: [R] memory problem under windows
In-Reply-To: <41474FF7.9060302@gmx.ch>
Message-ID: <Pine.LNX.4.44.0409142120080.30679-100000@gannet.stats>

Did you read the *rest* of what the rw-FAQ says?

  Be aware though that Windows has (in most versions) a maximum amount of
  user virtual memory of 2Gb, and parts of this can be reserved by 
  processes but not used. The version of the memory manager used from R
  1.9.0 allocates large objects in their own memory areas and so is better
  able to make use of fragmented virtual memory than that used previously.

  R can be compiled to use a different memory manager which might be
  better at using large amounts of memory, but is substantially slower
  (making R several times slower on some tasks).

So, it tells you about memory fragmentation, and it tells you about making 
R aware of large-memory versions of Windows and that an alternative memory 
manager can be used.  If you actually tried those, the posting guide asks 
you to indicate it, so I presume you did not.

Also, take seriously the idea of using a more capable operating system 
that is better able to manage 2Gb of RAM.


On Tue, 14 Sep 2004, Christoph Lehmann wrote:

> I have (still) some memory problems, when trying to allocate a huge array:
> 
> WinXP pro, with 2G RAM
> 
> I start R by calling:	
> 
> Rgui.exe --max-mem-size=2Gb (as pointed out in R for windows FAQ)
> 
> R.Version(): i386-pc-mingw32, 9.1, 21.6.2004
> 
> ## and here the problem
> x.dim <- 46
> y.dim <- 58
> slices <- 40
> volumes <- 1040
> a <- rep(0, x.dim * y.dim * slices * volumes)
> dim(a) <- c(x.dim, y.dim, slices, volumes)
> 
> gives me: "Error: cannot allocate vector of size 850425 Kb"
> 
> even though
> 
> memory.limit(size = NA)
> yields 	2147483648
> 
> and
> 
> memory.size()
> gives 905838768
> 
> so why is that and what can I do against it?
> 
> Many thanks for your kind help
> 
> Cheers
> 
> Christoph
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MROBERTS at ers.usda.gov  Wed Sep 15 00:35:18 2004
From: MROBERTS at ers.usda.gov (Michael Roberts)
Date: Tue, 14 Sep 2004 18:35:18 -0400
Subject: [R] rolling n-step predictions for ARIMA models
Message-ID: <s1473a46.071@email.ers.usda.gov>

Hello:

I would like to generate rolling, multiperiod forecasts from an 
estimated ARIMA model, but the function predict.Arima seems 
only to generate forecasts from the last observation in the data 
set.  To implement this, I was looking for an argument like 
'newdata=' in predict.lm.  

I can write some code that does this for my particular problem,
but might there exist a package/function that does this that I 
cannot find?

Thanks,
-Michael




Michael J. Roberts

Resource Economics Division
Production, Management, and Technology
USDA-ERS
(202) 694-5557 (phone)
(202) 694-5775 (fax)



From valeria.edefonti at uni-bocconi.it  Wed Sep 15 01:40:39 2004
From: valeria.edefonti at uni-bocconi.it (Valeria Edefonti)
Date: Tue, 14 Sep 2004 19:40:39 -0400
Subject: [R] pairs correlations colors
Message-ID: <7BF46702-06A7-11D9-AEA1-00039303A6C4@uni-bocconi.it>

I have the following problem.
I want to use pairs function and get a matrix of scatterplots with the  
correlations in the upper panel and the ordinary scatterplots in the  
lower panel.
Moreover, I want to have points colored in five differet ways in the  
lower panel, because I have five subgroups.
In order to do that I tried to combine examples on pairs function help.
I got a colored matrix using hints on iris dataset.
I got a black and white matrix with correlations using function  
panel.cor, exactly as it is in the example.
Unfortunately, the line:

jpeg(filename="/home/valeria/Thesis/lung/fig/scatterplotcolnames.jpg")
pairs(aggiunta[,1: 
6],labels=c("ALCAM","ITGB5","MSN","CSTB","DHCR24","TRIM29"), main =  
"Scatterplots selected genes",pch=21,
bg = c("red", "green3", "blue",  
"brown","orange")[aggiunta[,7]],upper.panel=panel.cor)
dev.off()

doesn't allow me to get the desidered matrix with colors and  
correlations.
I also tried to create a function panel.col for the lower.panel:

## put colors on the lower panels
      panel.col <- function(datiepheno)
      {
         usr <- par("usr"); on.exit(par(usr))
         par(bg = c("red", "green3", "blue",  
"brown","orange")[datiepheno[,7]],pch=21, usr = c(0, 1, 0, 1))
     }

but it doesn't work as well.
Any idea?
I hope I'll be precise but not too much precise!
Thank you very much
Valeria



From jc at or.psychology.dal.ca  Wed Sep 15 01:56:10 2004
From: jc at or.psychology.dal.ca (John Christie)
Date: Tue, 14 Sep 2004 20:56:10 -0300
Subject: [R] Spare some CPU cycles for testing lme?
In-Reply-To: <20040913234723.GA1702@tpapp>
References: <ci44e3$96d$1@sea.gmane.org> <20040913234723.GA1702@tpapp>
Message-ID: <A734A930-06A9-11D9-A124-000D93AEDA56@or.psychology.dal.ca>


On Sep 13, 2004, at 8:47 PM, Tamas K Papp wrote:

> It ran smoothly on my installation.
>
>> version
>          _
> platform powerpc-apple-darwin6.8
> arch     powerpc
> os       darwin6.8
> system   powerpc, darwin6.8
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R
>
> Typical lines from top (if it helps anything; around 45-50k
> iterations):
>
> 1225 R.bin       90.7%  2:55:12   1    62  1164  71.7M+ 13.7M  66.6M+  
> 228M+
> 1225 R.bin       78.6%  3:18:27   1    62  1606  81.3M+ 13.7M  75.5M+  
> 234M+

I can confirm this.  same installation



From tpapp at Princeton.EDU  Wed Sep 15 02:19:44 2004
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Tue, 14 Sep 2004 20:19:44 -0400
Subject: [R] getting started on Bayesian analysis
Message-ID: <20040915001944.GA1086@tpapp>

I am an economist who decided it's high time that I learned some
Bayesian statistics.  I am following An Introduction to Modern
Bayesian Econometrics by T. Lancaster.

The book recommends using BUGS, but I wonder if there are any
alternatives which are free software and fully integrated to R (which
I have been using for more than two years for numerical computations.)
I would like to learn what R packages (or other software)
statisticians use for Bayesian analysis to R, if there are viable
alternatives to BUGS, etc.

A couple of references to relevant packages, books or online tutorials
would help me a lot.

Thanks

Tamas



From mhall at berkeley.edu  Wed Sep 15 02:27:20 2004
From: mhall at berkeley.edu (HALL, MARK E)
Date: Tue, 14 Sep 2004 17:27:20 -0700
Subject: [R] getting started on Bayesian analysis
In-Reply-To: <20040915001944.GA1086@tpapp>
Message-ID: <web-1916144@calmail-be1.berkeley.edu>

  I've found 
  
Bayesian Methods: A Social and Behavioral Sciences Approach
by Jeff Gill 

useful as an introduction.  The examples are written in R and S with generalized scripts for doing 
a variety of problems.  (Though I never got change-point analysis to successfully in R.)

Best, Mark Hall


Mark Hall
Archaeological Research Facility
UC Berkeley



From Lorenz.Gygax at fat.admin.ch  Wed Sep 15 07:23:21 2004
From: Lorenz.Gygax at fat.admin.ch (Lorenz.Gygax@fat.admin.ch)
Date: Wed, 15 Sep 2004 07:23:21 +0200
Subject: FW: [R] glmmPQL and random factors
Message-ID: <BF74FADD4B44554CA7E53D0B5242CD6A01FC614E@evd-s7014.evd.admin.ch>


I have just realised that I sent this to Per only. For those interested on
the list:

-----Original Message-----
From: Gygax Lorenz FAT 
Sent: Tuesday, September 14, 2004 4:35 PM
To: 'Per Tor??ng'
Subject: RE: [R] glmmPQL and random factors

Hi Per,

> glmmPQL(Fruit.set~Treat1*Treat2+offset(log10(No.flowers)), 
> random=~1|Plot, family=poisson, data=...)
> 
> Plot is supposed to be nested in (Treat1*Treat2).
> Is this analysis suitable?

As far as I understand the methods and with my experience using such
analyses, I would say that the model is ok the way you specified it.

glmmPQL (and the underlying lme) is so intelligent (a thousand thanks to the
developpers!) as to recognise if the treatments are fixed per plot, i.e.
only one level of the two treatments appears in each plot. The denominator
degrees of freedom in the anova table are adjusted automatically. I.e. your
denominator df should  be the number of plots minus five, the number of dfs
you need for the fixed effects (Treat1, Treat2, the interaction, the
covariate and the one df you always loose from the total of observations).

> Moreover, what is the meaning of typing 
> random=~1|Plot compared to random=~Treat1*Treat2|Plot?

The first version means, that the intercept / overall mean can vary from
plot to plot. I.e. each plot may have another mean due to the fact that it
grows somewhere else in addition to the differing treatments.

The second version tries to model a difference in reaction to treatment 1
and 2 for each of the plots (which does not make sense in your case as each
plot is only subjected to one kind of treatment).

In a crossed design, i.e. if you could have treated your plants individually
and had all treatment combinations in each of the plots, the first version
implies that all the plots react in the same consistent way to the
treatments. I.e. that the general level of each plot may be different, but
the differences due to treatment are the same in each plot, the reaction of
the plots are shifted but have the same shape (this is the same as saying
that you only consider main effects of treatment and plot).

The second version allows to estimate the reactions for each plot, i.e. in
addition to a general shift, the treatments may have (slightly) different
effects in each plot. This is the same as saying that you consider
interactions between your fixed and random effects. See also the terrific
book by Pinheiro & Bates (Mixed Effects Modelling in S and S-Plus, Springer,
2000).

Cheers, Lorenz
- 
Lorenz Gygax
Tel: +41 (0)52 368 33 84 / lorenz.gygax at fat.admin.ch      
Centre for proper housing of ruminants and pigs
Swiss Federal Veterinary Office



From patrick.giraudoux at univ-fcomte.fr  Wed Sep 15 07:49:08 2004
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Wed, 15 Sep 2004 07:49:08 +0200
Subject: [R] cluster analysis and null hypothesis testing
Message-ID: <003c01c49ae7$bb452410$87cb0d50@PC728329681112>

Hi,

I am wondering if a Monte Carlo method (or equivalent) exist permitting to test the randomness of a cluster analysis (eg got by
hclust(). I went through the package "fpc" (maybe too superficially) but dit not find such method.

Thanks for any hint,

Patrick Giraudoux



From jarioksa at sun3.oulu.fi  Wed Sep 15 09:40:52 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 15 Sep 2004 10:40:52 +0300
Subject: [R] getting started on Bayesian analysis
In-Reply-To: <web-1916144@calmail-be1.berkeley.edu>
References: <web-1916144@calmail-be1.berkeley.edu>
Message-ID: <1095234051.14727.21.camel@biol102145.oulu.fi>

On Wed, 2004-09-15 at 03:27, HALL, MARK E wrote:
>   I've found 
>   
> Bayesian Methods: A Social and Behavioral Sciences Approach
> by Jeff Gill 
> 
> useful as an introduction.  The examples are written in R and S with generalized scripts for doing 
> a variety of problems.  (Though I never got change-point analysis to successfully in R.)
> 
Change point analysis? I haven't seen the book, but I read lecture
handouts of one Bayesian course over here in Finland (Antti Penttinen,
Jyv??skyl??), and translated his example to R during one (rare) warm
summer day in a garden. So do you mean this (binary case):

> source("/mnt/flash/cb.update.R")
> cb.update
function (y, A=1, B=1, C=1, D=1, N=1200, burnin=200)
{
    n <- length(y)
    lambda <- numeric(N)
    mu <- numeric(N)
    k <- numeric(N)
    lambda[1] <- A/(A+B)
    mu[1] <- C/(C+D)
    k[1] <- n/2
    sn <- sum(y)
 
    for (i in 2:N) {
        kold <- k[i-1]
        sk <- sum(y[1:kold])
        lambda[i] <- rbeta(1, A+sk, B + kold - sk)
        mu[i] <- rbeta(1, C + sn - sk, D + n - sn + sk - kold  )
        knew <- sample(n-1, 1)
        sknew <- sum(y[1:knew])
        r <- (sknew - sk) *
            (log(lambda[i])-log(mu[i]))-(knew-kold)*(lambda[i]-mu[i])
        if(min(0,r) > log(runif(1))) k[i] <- knew
        else k[i] <- k[i-1]
    }
    out <- cbind(lambda, mu, k)
    out[(burnin+1):N, ]
}
> y <- c(rbinom(60, 1, 0.8), rbinom(40, 1, 0.3))
> uh <- cb.update(y, N=5200)
> colMeans(uh)
    lambda         mu          k
 0.8189303  0.4169367 59.0770000
> mean(y[1:60])
[1] 0.7833333
> mean(y[41:100])
[1] 0.45
> plot(density(uh[,1]))
> plot(density(uh[,2]))
> plot(table(uh[,3]), type="h")

This was off-topic. So something about business: isn't the (Win)BUGS
author working with a R port?

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From bob.ohara at helsinki.fi  Wed Sep 15 10:02:15 2004
From: bob.ohara at helsinki.fi (Anon.)
Date: Wed, 15 Sep 2004 11:02:15 +0300
Subject: [R] getting started on Bayesian analysis
References: <web-1916144@calmail-be1.berkeley.edu>
	<1095234051.14727.21.camel@biol102145.oulu.fi>
Message-ID: <4147F707.8040805@helsinki.fi>

Jari Oksanen wrote:
> On Wed, 2004-09-15 at 03:27, HALL, MARK E wrote:
> 
>>  I've found 
>>  
>>Bayesian Methods: A Social and Behavioral Sciences Approach
>>by Jeff Gill 
>>
>>useful as an introduction.  The examples are written in R and S with generalized scripts for doing 
>>a variety of problems.  (Though I never got change-point analysis to successfully in R.)
>>
> 
> Change point analysis? I haven't seen the book, but I read lecture
> handouts of one Bayesian course over here in Finland (Antti Penttinen,
> Jyv??skyl??), and translated his example to R during one (rare) warm
> summer day in a garden. So do you mean this (binary case):
> 
> 
<snip>
> 
> 
> This was off-topic. So something about business: isn't the (Win)BUGS
> author working with a R port?
> 
Yes, he is, and he's got it working in Windows.  But if anyone wants to 
discuss how R does memory management with Andrew, he'll be all ears.

In the mean time, there is the R2WinBUGS package on CRAN for you to enjoy.

Bob

-- 
Bob O'Hara

Dept. of Mathematics and Statistics
P.O. Box 68 (Gustaf H??llstr??min katu 2b)
FIN-00014 University of Helsinki
Finland

Telephone: +358-9-191 51479
Mobile: +358 50 599 0540
Fax:  +358-9-191 51400
WWW:  http://www.RNI.Helsinki.FI/~boh/
Journal of Negative Results - EEB: http://www.jnr-eeb.org



From irena.komprej at telemach.net  Wed Sep 15 10:14:37 2004
From: irena.komprej at telemach.net (Irena Komprej)
Date: Wed, 15 Sep 2004 08:14:37 -0000
Subject: [R] Cancor
Message-ID: <002101bd164e$661f0110$0300a8c0@JJ.cable.amis.net>

Dear Gabor,
thank you for your answer related to the normalization of cancor
coefficients. If you want to interpret the coefficients in terms of
variables' contributions to canonical variables, loadings, redundancy
measure, etc. ,  you have to normalize the results so that the canonical
variables have identity variance matrix. Multiplying cancor coefficients
xcoef and ycoef by as.numeric(sqrt(nrow(x)-1)) does the job.
(I sometimes miss such information in the R help.)
Best regards,
Irena Komprej



From beat.huggler at rmf.ch  Wed Sep 15 10:24:34 2004
From: beat.huggler at rmf.ch (beat.huggler@rmf.ch)
Date: Wed, 15 Sep 2004 09:24:34 +0100
Subject: [R] Bessel function
Message-ID: <2533D4FDDD12204CB8500DD3729B7595056A7FB9@MISQEXMB01.maninvestments.ad.man.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040915/0fed5a37/attachment.pl

From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Sep 15 10:34:46 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 15 Sep 2004 10:34:46 +0200
Subject: [R] Bessel function
References: <2533D4FDDD12204CB8500DD3729B7595056A7FB9@MISQEXMB01.maninvestments.ad.man.com>
Message-ID: <009501c49afe$db7c8cc0$b2133a86@www.domain>

Hi Beat,

take a look at this link, http://www.statsci.org/s/besseli0.html for
the modified Bessel function.

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: <beat.huggler at rmf.ch>
To: <R-help at stat.math.ethz.ch>
Sent: Wednesday, September 15, 2004 10:24 AM
Subject: [R] Bessel function


>
>
>  Dear all
>
> Currently, I'm implementing the generalized hyperbolic distribution
into
> Splus. Unfortunately the Bessel function is not implemented in
Splus. In
> R the Bessel function does exist but it is an internal function and
I'm
> not able to look at the code.
>
> Is there any possibility to see the code of the Bessel function in R
or
> does anybody has an implementation of the Bessel function in Splus?
>
> Thanks a lot for your help.
>
> Beat
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Wed Sep 15 10:39:31 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 15 Sep 2004 09:39:31 +0100 (BST)
Subject: [R] Cancor
In-Reply-To: <002101bd164e$661f0110$0300a8c0@JJ.cable.amis.net>
Message-ID: <Pine.LNX.4.44.0409150935060.4320-100000@gannet.stats>

On (she claimed) Thu, 1 Jan 1998, Irena Komprej wrote:

> Dear Gabor,

This is R-help, not `Gabor', although you keep sending mail addressed to
`Gabor' to this list.

> thank you for your answer related to the normalization of cancor
> coefficients. If you want to interpret the coefficients in terms of
> variables' contributions to canonical variables, loadings, redundancy
> measure, etc. ,  you have to normalize the results so that the canonical
> variables have identity variance matrix. Multiplying cancor coefficients
> xcoef and ycoef by as.numeric(sqrt(nrow(x)-1)) does the job.
> (I sometimes miss such information in the R help.)

I think you miss it in the references given on the R help pages.  Please
do read them.  (Any good book will tell you that the scaling of canonical 
variates is arbitrary.)

Please also ask your local IT advisors to set your computer to a 
sensible time: the world is 6.7 years ahead of you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Sep 15 10:41:24 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 15 Sep 2004 09:41:24 +0100 (BST)
Subject: [R] Bessel function
In-Reply-To: <2533D4FDDD12204CB8500DD3729B7595056A7FB9@MISQEXMB01.maninvestments.ad.man.com>
Message-ID: <Pine.LNX.4.44.0409150939450.4320-100000@gannet.stats>

On Wed, 15 Sep 2004 beat.huggler at rmf.ch wrote:

> Currently, I'm implementing the generalized hyperbolic distribution into
> Splus. Unfortunately the Bessel function is not implemented in Splus. In
> R the Bessel function does exist but it is an internal function and I'm
> not able to look at the code.
> 
> Is there any possibility to see the code of the Bessel function in R or

Of course.  It *is* in the sources.  What stops you looking at the 
sources?  (Where they are is in the FAQ, for example.)

BTW, there are four Bessel functions in R, and others do exist.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From t.dewez at brgm.fr  Wed Sep 15 11:03:24 2004
From: t.dewez at brgm.fr (Dewez Thomas)
Date: Wed, 15 Sep 2004 11:03:24 +0200
Subject: [R] testing goodness of fit of linear model
Message-ID: <D965434E9D6BD511AE3500306E01C8BE05DD6991@SRV0015>

Dear R-users,

I've been reading a bunch of things on linear models but cannot quite find a
clear answer. How can one determine whether a linear model is significant or
not?

For background info, I am modelling the response of topographic slope to the
distance of a catchment's outlet. Some guys have shown that if there is a
significant fit to a linear model, one can deduce the dynamic state of the
basin, that is, whether erosion is as strong as rock uplift, erosion is
smaller than rock uplift, or erosion is greater than rock uplift. I am thus
to test 4 situations:

Situation 1: a linear model is inappropriate for describing the data, the
scatter is too large, and thus a linear model is unfit to explain the data.

Situation 2: the linear model of the kind "y = b0 + b1 * x" is fit to
describe the data, ie data points lie close to a straight line.

Situation 2a: the relationship between slope and distance is significantly
positive
Situation 2b: the relationship between slope and distance is significantly
null (ie data is clustered around a line with b1 non-significantly different
from 0)
Situation 2c: the relationship between slope and distance is significantly
negative

I am confused as to what test I should use for discriminating these
situations.

The glm offers an indication about the significance of regression
parameters. So in the case where b1 is significantly different from 0 (p
value <=0.05 for a test where H0: b1=0; H1: b1 != 0), it is straightforward.
But I don't know how to discriminate between situation 1 and situation 2 (ie
whether a linear model is significant).

Any suggestion are welcome

Cheers,

Thomas
***
Le contenu de cet e-mail et de ses pi??ces jointes est destin...{{dropped}}



From rksh at soc.soton.ac.uk  Wed Sep 15 11:16:52 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Wed, 15 Sep 2004 10:16:52 +0100
Subject: [R] Bessel function
In-Reply-To: <2533D4FDDD12204CB8500DD3729B7595056A7FB9@MISQEXMB01.maninvestments.ad.man
	.com>
References: <2533D4FDDD12204CB8500DD3729B7595056A7FB9@MISQEXMB01.maninvestments.ad.man
	.com>
Message-ID: <a0600200cbd6db8a19d22@[139.166.242.29]>

Hi

you might find package(hyperbolicDist) interesting.

best wishes

rksh


>  Dear all
>
>Currently, I'm implementing the generalized hyperbolic distribution into
>Splus. Unfortunately the Bessel function is not implemented in Splus. In
>R the Bessel function does exist but it is an internal function and I'm
>not able to look at the code.
>
>Is there any possibility to see the code of the Bessel function in R or
>does anybody has an implementation of the Bessel function in Splus?
>
>Thanks a lot for your help.
>
>Beat
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From rksh at soc.soton.ac.uk  Wed Sep 15 11:22:03 2004
From: rksh at soc.soton.ac.uk (Robin Hankin)
Date: Wed, 15 Sep 2004 10:22:03 +0100
Subject: [R] Bessel function
In-Reply-To: <2533D4FDDD12204CB8500DD3729B7595056A7FB9@MISQEXMB01.maninvestments.ad.man
	.com>
References: <2533D4FDDD12204CB8500DD3729B7595056A7FB9@MISQEXMB01.maninvestments.ad.man
	.com>
Message-ID: <a06002015bd6dba03f024@[139.166.242.29]>

Hi

you might find package(hyperbolicDist) interesting.

best wishes

robin


>  Dear all
>
>Currently, I'm implementing the generalized hyperbolic distribution into
>Splus. Unfortunately the Bessel function is not implemented in Splus. In
>R the Bessel function does exist but it is an internal function and I'm
>not able to look at the code.
>
>Is there any possibility to see the code of the Bessel function in R or
>does anybody has an implementation of the Bessel function in Splus?
>
>Thanks a lot for your help.
>
>Beat
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Robin Hankin
Uncertainty Analyst
Southampton Oceanography Centre
SO14 3ZH
tel +44(0)23-8059-7743
initialDOTsurname at soc.soton.ac.uk (edit in obvious way; spam precaution)



From tom_woody at web.de  Wed Sep 15 12:01:06 2004
From: tom_woody at web.de (=?ISO-8859-15?Q?Thomas_Sch=F6nhoff?=)
Date: Wed, 15 Sep 2004 12:01:06 +0200
Subject: [R] loading error of the Rcmdr library on Debian Sid
Message-ID: <414812E2.5030603@web.de>

Hello,

I just tried to get Rcmdr package working, resulting in:


----------------------------------------------------------------------
 > library(Rcmdr)
Loading required package: tcltk
Loading required package: lattice
Loading required package: foreign
Loading required package: abind
Loading required package: lmtest
Loading required package: multcomp
Loading required package: relimp
Loading required package: effects
Loading required package: rgl
Error in dyn.load(x, as.logical(local), as.logical(now)) :
         unable to load shared library 
"/usr/lib/R/site-library/rgl/libs/rgl.so":
   libnvidia-tls.so.1: cannot handle TLS data
Error in .C(symbol.C("rgl_quit"), success = FALSE, PACKAGE = "rgl") :
         C function name not in DLL for package rgl
Loading required package: mgcv
This is mgcv 1.1-1
Loading required package: car
Error: Missing packages: rgl
Error: .onLoad failed in loadNamespace
Error in library(Rcmdr) : package/namespace load failed

Missing rgl-package ?


-----------------------------------------------------------------------


thomas> dpkg -l |grep r-

r-cran-abind   1.1.0-1
r-cran-car     1.0.13-1
r-cran-foreign 0.7-1
r-cran-lattice 0.9.16-1
r-cran-mgcv    1.1.1.1-1
r-cran-rgl     0.64.13-1
r-cran-relimp  0.8.4-1
r-cran-rcmdr   0.9.11-1
r-cran-lmtest  0.9.6-2
r-cran-effects 1.0.5-1
r-cran-multcom 0.4.7-1
r-cran-mvtnorm 0.6.8-1


amongst other R related (basic and specific) packages.


Am I still missing some required packages to run RCommander smoothly?


My system:

Debian Sid (unstable)
GNU R 1.9.1
Xfree 4.3

Anyone else noticed this on Debian Sid whilst trying to run the R 
Commander !? So far I didn't find a related bug report for Linux. Maybe 
this is a Debian related problem, I really have no clue at the moment.

Regards
Thomas



From ozric at web.de  Wed Sep 15 12:31:14 2004
From: ozric at web.de (Christian Schulz)
Date: Wed, 15 Sep 2004 12:31:14 +0200
Subject: [R] loading error of the Rcmdr library on Debian Sid
In-Reply-To: <414812E2.5030603@web.de>
References: <414812E2.5030603@web.de>
Message-ID: <200409151231.15065.ozric@web.de>

Hi,

it seems you have to install the rgl package and this demand 
the gl4 java lib what is necessary, too. 

http://www.jausoft.com/products/gl4java/gl4java_install.html

christian


Am Mittwoch, 15. September 2004 12:01 schrieb Thomas Sch??nhoff:
> Hello,
>
> I just tried to get Rcmdr package working, resulting in:
>
>
> ----------------------------------------------------------------------
>
>  > library(Rcmdr)
>
> Loading required package: tcltk
> Loading required package: lattice
> Loading required package: foreign
> Loading required package: abind
> Loading required package: lmtest
> Loading required package: multcomp
> Loading required package: relimp
> Loading required package: effects
> Loading required package: rgl
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>          unable to load shared library
> "/usr/lib/R/site-library/rgl/libs/rgl.so":
>    libnvidia-tls.so.1: cannot handle TLS data
> Error in .C(symbol.C("rgl_quit"), success = FALSE, PACKAGE = "rgl") :
>          C function name not in DLL for package rgl
> Loading required package: mgcv
> This is mgcv 1.1-1
> Loading required package: car
> Error: Missing packages: rgl
> Error: .onLoad failed in loadNamespace
> Error in library(Rcmdr) : package/namespace load failed
>
> Missing rgl-package ?
>
>
> -----------------------------------------------------------------------
>
>
> thomas> dpkg -l |grep r-
>
> r-cran-abind   1.1.0-1
> r-cran-car     1.0.13-1
> r-cran-foreign 0.7-1
> r-cran-lattice 0.9.16-1
> r-cran-mgcv    1.1.1.1-1
> r-cran-rgl     0.64.13-1
> r-cran-relimp  0.8.4-1
> r-cran-rcmdr   0.9.11-1
> r-cran-lmtest  0.9.6-2
> r-cran-effects 1.0.5-1
> r-cran-multcom 0.4.7-1
> r-cran-mvtnorm 0.6.8-1
>
>
> amongst other R related (basic and specific) packages.
>
>
> Am I still missing some required packages to run RCommander smoothly?
>
>
> My system:
>
> Debian Sid (unstable)
> GNU R 1.9.1
> Xfree 4.3
>
> Anyone else noticed this on Debian Sid whilst trying to run the R
> Commander !? So far I didn't find a related bug report for Linux. Maybe
> this is a Debian related problem, I really have no clue at the moment.
>
> Regards
> Thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From tom_woody at swissinfo.org  Wed Sep 15 13:07:31 2004
From: tom_woody at swissinfo.org (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Wed, 15 Sep 2004 13:07:31 +0200
Subject: [R] loading error of the Rcmdr library on Debian Sid
In-Reply-To: <200409151231.15065.ozric@web.de>
References: <414812E2.5030603@web.de> <200409151231.15065.ozric@web.de>
Message-ID: <41482273.7030205@swissinfo.org>

Hello Christian,

Christian Schulz schrieb:

>Hi,
>
>it seems you have to install the rgl package and this demand 
>the gl4 java lib what is necessary, too. 
>
>http://www.jausoft.com/products/gl4java/gl4java_install.html
>  
>

Seems like that this dependency is missing in the r-cran-rgl package!? 
So I am going to write a bug report to the debian maintainer!

Thanks

Thomas



From brian.macnamee at gmail.com  Wed Sep 15 13:36:15 2004
From: brian.macnamee at gmail.com (Brian Mac Namee)
Date: Wed, 15 Sep 2004 12:36:15 +0100
Subject: [R] Density Estimation
Message-ID: <af2aa6640409150436722aa40c@mail.gmail.com>

Hi there,

Sorry if this is a rather loing post. I have a simple list of single
feature data points from which I would like to generate a probability
that an unseen point comes from the same distribution. To do this I am
trying to estimate the probability density of the list of points and
use this to generate a probability for the new unseen points. I have
managed to use the R density function to generate the density estimate
but have not been able to do anything with this - i.e. generate a
rpobability that a new point comes from the same distribution. Is
there a function to do this, or am I way off the mark using the
density function at all?

Thanks in advance,

Brian.



From HDoran at air.org  Wed Sep 15 14:49:28 2004
From: HDoran at air.org (Doran, Harold)
Date: Wed, 15 Sep 2004 08:49:28 -0400
Subject: [R] Read.fwf
Message-ID: <88EAF3512A55DF46B06B1954AEF73F74055C1A78@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040915/6075b26f/attachment.pl

From vito_ricci at yahoo.com  Wed Sep 15 14:53:14 2004
From: vito_ricci at yahoo.com (=?iso-8859-1?q?Vito=20Ricci?=)
Date: Wed, 15 Sep 2004 14:53:14 +0200 (CEST)
Subject: [R] Density Estimation
Message-ID: <20040915125314.28640.qmail@web41204.mail.yahoo.com>

Dear Brian,

I can suggest you to use density() function to get an
estimate of the pdf you're finding (I believe it's
unknown). Then you can plot the point you got by
density() using plot(). In this way you have a graphic
representation of you unknown pdf. According its shape
and helping by the graphic you could try to understand
what kind of pdf it would be (normal, gamma, weibul,
etc.)
After you can estimate parameters of pdf using your
data with LS or ML methods.
Then you can calculate the goodness of fit for each
model of pdf and use the best one.

I hope I get you a little help.

Cordially
Vito Ricci

brian.macnamee at gmail.com  wrote:

Hi there,

Sorry if this is a rather loing post. I have a simple
list of single
feature data points from which I would like to
generate a probability
that an unseen point comes from the same distribution.
To do this I am
trying to estimate the probability density of the list
of points and
use this to generate a probability for the new unseen
points. I have
managed to use the R density function to generate the
density estimate
but have not been able to do anything with this - i.e.
generate a
rpobability that a new point comes from the same
distribution. Is
there a function to do this, or am I way off the mark
using the
density function at all?

Thanks in advance,

Brian.

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml


		
___________________________________

http://it.seriea.fantasysports.yahoo.com/



From ccleland at optonline.net  Wed Sep 15 14:59:57 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 15 Sep 2004 08:59:57 -0400
Subject: [R] Read.fwf
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F74055C1A78@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F74055C1A78@dc1ex2.air.org>
Message-ID: <41483CCD.9080409@optonline.net>

   You can use rep() in specifying the widths argument to avoid typing 
all those ones.  For example:

read.fwf(file="c:\\mydata.dat", widths = c(rep(1,80), 5, 4, 6))

hope this helps,

Chuck

Doran, Harold wrote:
> I have a fixed width file with variables of varying width. The help is
> pretty transparent for this feature, but I can't seem to figure out how
> I can make effective use of the package with my data.
> 
> In my dataset, the first 80 columns are of width 1 followed by other
> variables with width larger than 1.
> 
> I think the correct way to do this, by brute force, would be
> 
>>read.fwf(dataset, 1,1,1,...,1,5,...).
> 
> I'm sure I do not need to actually enter 80 "1"s, correct? How might I
> do this more effectively?


-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ligges at statistik.uni-dortmund.de  Wed Sep 15 15:11:21 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 15 Sep 2004 15:11:21 +0200
Subject: [R] Read.fwf
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F74055C1A78@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F74055C1A78@dc1ex2.air.org>
Message-ID: <41483F79.6030102@statistik.uni-dortmund.de>

Doran, Harold wrote:

> Dear List
> 
> I have a fixed width file with variables of varying width. The help is
> pretty transparent for this feature, but I can't seem to figure out how
> I can make effective use of the package with my data.
> 
> In my dataset, the first 80 columns are of width 1 followed by other
> variables with width larger than 1.
> 
> I think the correct way to do this, by brute force, would be
> 
> 
>>read.fwf(dataset, 1,1,1,...,1,5,...).
> 
> 
> I'm sure I do not need to actually enter 80 "1"s, correct? How might I
> do this more effectively?

?read.fwf:

"widths  integer vector, giving the widths of the fixed-width fields (of 
one line)."

Hence:
read.fwf(dataset, c(rep(1, 80), 5, ...))

Uwe Ligges




> Harold
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rvaradha at jhsph.edu  Wed Sep 15 15:09:57 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Wed, 15 Sep 2004 09:09:57 -0400
Subject: [R] Bessel function
Message-ID: <E619BDBD99B4F74D9DCA32F43BE926714C748C@XCH-VN02.sph.ad.jhsph.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040915/fd257967/attachment.pl

From jens_hainmueller at ksg05.harvard.edu  Wed Sep 15 15:24:53 2004
From: jens_hainmueller at ksg05.harvard.edu (Jens Hainmueller)
Date: Wed, 15 Sep 2004 09:24:53 -0400
Subject: [R] control of font size & colour for title, subtitles, axis,
	and tick marks  in LATTICE graph
Message-ID: <HCECJPLNNGBBJIOJMJJAOEGDCJAA.jens_hainmueller@ksg05.harvard.edu>

Hi,

I very much appreciate any help on this "fine tuning" problem in a lattice
graph (I am new to LATTICE and could not find an example in the help files
that worked for me. My apologies if I missed it there).

I am running the following box plots to compare conditional distributions of
x at different levels of y under two treatment conditions ID=1 (upper
panel ) & ID=0 (lower panel of the plot).

bwplot(HF.ELECYEAR ~ stparvotech | ID ,
	data=data, aspect=1,
	layout=c(1,2),
            xlab="Changes in Party Vote Shares",
	xlim=(-20:20),
            ylab="Periods Following Last Federal Election",
            main="Divided Government",
	panel = function(x,y)
		{
		panel.bwplot(x,y)
		panel.abline(v=0, col="red")
		}
	)

How can I:
1. Control the font size of the main title, the panel titles, the axis, and
the tick marks? The usual cex.main=1/3, cex.xlab etc. do not work.
2. Change the color of the boxes where the panel titles (ID=1 & ID=0) are
located?

Thank you very much.

Best,
Jens



From ligges at statistik.uni-dortmund.de  Wed Sep 15 15:31:34 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 15 Sep 2004 15:31:34 +0200
Subject: [R] pairs correlations colors
In-Reply-To: <7BF46702-06A7-11D9-AEA1-00039303A6C4@uni-bocconi.it>
References: <7BF46702-06A7-11D9-AEA1-00039303A6C4@uni-bocconi.it>
Message-ID: <41484436.4000702@statistik.uni-dortmund.de>

Valeria Edefonti wrote:

> I have the following problem.
> I want to use pairs function and get a matrix of scatterplots with the  
> correlations in the upper panel and the ordinary scatterplots in the  
> lower panel.
> Moreover, I want to have points colored in five differet ways in the  
> lower panel, because I have five subgroups.
> In order to do that I tried to combine examples on pairs function help.
> I got a colored matrix using hints on iris dataset.
> I got a black and white matrix with correlations using function  
> panel.cor, exactly as it is in the example.
> Unfortunately, the line:
> 
> jpeg(filename="/home/valeria/Thesis/lung/fig/scatterplotcolnames.jpg")
> pairs(aggiunta[,1: 
> 6],labels=c("ALCAM","ITGB5","MSN","CSTB","DHCR24","TRIM29"), main =  
> "Scatterplots selected genes",pch=21,
> bg = c("red", "green3", "blue",  
> "brown","orange")[aggiunta[,7]],upper.panel=panel.cor)
> dev.off()
> 
> doesn't allow me to get the desidered matrix with colors and  correlations.
> I also tried to create a function panel.col for the lower.panel:
> 
> ## put colors on the lower panels
>      panel.col <- function(datiepheno)
>      {
>         usr <- par("usr"); on.exit(par(usr))
>         par(bg = c("red", "green3", "blue",  
> "brown","orange")[datiepheno[,7]],pch=21, usr = c(0, 1, 0, 1))
>     }
> 
> but it doesn't work as well.
> Any idea?
> I hope I'll be precise but not too much precise!
> Thank you very much
> Valeria


Looks like there was no answer yet:
Please specify am example with data available in R, so that we can 
reproduce your example. This will save much time for those people who 
are going to help.
Rearranging your examples with data we do not have available requires 
quite a lot of effort.

What I guess is that you are going to specify

lower.panel = function(x, y)
   points(x, y,
     col = sapply(aggiunta[,7], switch, "1"="red", "2"="green3", .....))


Uwe Ligges





> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From rossini at blindglobe.net  Wed Sep 15 15:36:13 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 15 Sep 2004 06:36:13 -0700
Subject: [R] loading error of the Rcmdr library on Debian Sid
In-Reply-To: <414812E2.5030603@web.de> (Thomas Sch's message of "Wed, 15 Sep
	2004 12:01:06 +0200")
References: <414812E2.5030603@web.de>
Message-ID: <85vfefslgy.fsf@servant.blindglobe.net>


You can apt-get RGL in sid.  

Thomas Sch??nhoff <tom_woody at web.de> writes:

> Hello,
>
> I just tried to get Rcmdr package working, resulting in:
>
>
> ----------------------------------------------------------------------
>  > library(Rcmdr)
> Loading required package: tcltk
> Loading required package: lattice
> Loading required package: foreign
> Loading required package: abind
> Loading required package: lmtest
> Loading required package: multcomp
> Loading required package: relimp
> Loading required package: effects
> Loading required package: rgl
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>          unable to load shared library
>          "/usr/lib/R/site-library/rgl/libs/rgl.so":
>    libnvidia-tls.so.1: cannot handle TLS data
> Error in .C(symbol.C("rgl_quit"), success = FALSE, PACKAGE = "rgl") :
>          C function name not in DLL for package rgl
> Loading required package: mgcv
> This is mgcv 1.1-1
> Loading required package: car
> Error: Missing packages: rgl
> Error: .onLoad failed in loadNamespace
> Error in library(Rcmdr) : package/namespace load failed
>
> Missing rgl-package ?
>
>
> -----------------------------------------------------------------------
>
>
> thomas> dpkg -l |grep r-
>
> r-cran-abind   1.1.0-1
> r-cran-car     1.0.13-1
> r-cran-foreign 0.7-1
> r-cran-lattice 0.9.16-1
> r-cran-mgcv    1.1.1.1-1
> r-cran-rgl     0.64.13-1
> r-cran-relimp  0.8.4-1
> r-cran-rcmdr   0.9.11-1
> r-cran-lmtest  0.9.6-2
> r-cran-effects 1.0.5-1
> r-cran-multcom 0.4.7-1
> r-cran-mvtnorm 0.6.8-1
>
>
> amongst other R related (basic and specific) packages.
>
>
> Am I still missing some required packages to run RCommander smoothly?
>
>
> My system:
>
> Debian Sid (unstable)
> GNU R 1.9.1
> Xfree 4.3
>
> Anyone else noticed this on Debian Sid whilst trying to run the R
> Commander !? So far I didn't find a related bug report for
> Linux. Maybe this is a Debian related problem, I really have no clue
> at the moment.
>
> Regards
> Thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From kahra at mpsgr.it  Wed Sep 15 15:48:23 2004
From: kahra at mpsgr.it (Kahra Hannu)
Date: Wed, 15 Sep 2004 15:48:23 +0200
Subject: [R] Bessel function
Message-ID: <C9FC71F7E9356F40AFE2ACC2099DE147149699@MAILSERVER-B.mpsgr.it>

>Currently, I'm implementing the generalized hyperbolic distribution into
>Splus. Unfortunately the Bessel function is not implemented in Splus. In
>R the Bessel function does exist but it is an internal function and I'm
>not able to look at the code.

>Is there any possibility to see the code of the Bessel function in R or
>does anybody has an implementation of the Bessel function in Splus?

Have a look at Press-Teukolsky-Vetterling-Flannery: Numerical Recipes in C, Cambridge University Press, Chapter 6 (2nd edition). I guess you are looking for modified Bessel functions (see, 6.6).


Hannu Kahra 
Progetti Speciali 
Monte Paschi Asset Management SGR S.p.A. 
Via San Vittore, 37
IT-20123 Milano, Italia 

Tel.: +39 02 43828 754 
Mobile: +39 333 876 1558 
Fax: +39 02 43828 247 
E-mail: kahra at mpsgr.it 
Web: www.mpsam.it



From bwheeler at echip.com  Wed Sep 15 15:54:47 2004
From: bwheeler at echip.com (Bob Wheeler)
Date: Wed, 15 Sep 2004 09:54:47 -0400
Subject: [R] Density Estimation
References: <af2aa6640409150436722aa40c@mail.gmail.com>
Message-ID: <414849A7.90402@echip.com>

Try fitting it with a Johnson function -- see SuppDists. If you can fit 
it you will then be able to use the functions in SuppDists just as you 
can for any other distribution supported by R.

Brian Mac Namee wrote:
> Hi there,
> 
> Sorry if this is a rather loing post. I have a simple list of single
> feature data points from which I would like to generate a probability
> that an unseen point comes from the same distribution. To do this I am
> trying to estimate the probability density of the list of points and
> use this to generate a probability for the new unseen points. I have
> managed to use the R density function to generate the density estimate
> but have not been able to do anything with this - i.e. generate a
> rpobability that a new point comes from the same distribution. Is
> there a function to do this, or am I way off the mark using the
> density function at all?
> 
> Thanks in advance,
> 
> Brian.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Bob Wheeler --- http://www.bobwheeler.com/
         ECHIP, Inc. ---
Randomness comes in bunches.



From andy_liaw at merck.com  Wed Sep 15 15:57:11 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 15 Sep 2004 09:57:11 -0400
Subject: [R] Read.fwf
Message-ID: <3A822319EB35174CA3714066D590DCD504AF83BD@usrymx25.merck.com>

It might help to read that help file again:

> d <- paste(c(rep(0, 80), 11111), collapse="")
> d
[1]
"000000000000000000000000000000000000000000000000000000000000000000000000000
0000011111"
> f <- file("try.dat", "w")
> writeLines(d, f)
> writeLines(d, f)
> writeLines(d, f)
> close(f)
> fw <- c(rep(1, 80), 5)
> x <- read.fwf("try.dat", fw)
> x
  V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 V21
V22
1  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   0   0
0
2  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   0   0
0
3  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   0   0
0
  V23 V24 V25 V26 V27 V28 V29 V30 V31 V32 V33 V34 V35 V36 V37 V38 V39 V40
V41 V42
1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
0   0
2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
0   0
3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
0   0
  V43 V44 V45 V46 V47 V48 V49 V50 V51 V52 V53 V54 V55 V56 V57 V58 V59 V60
V61 V62
1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
0   0
2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
0   0
3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
0   0
  V63 V64 V65 V66 V67 V68 V69 V70 V71 V72 V73 V74 V75 V76 V77 V78 V79 V80
V81
1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
11111
2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
11111
3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
11111

Andy
 

> From: Doran, Harold
> 
> Dear List
> 
> I have a fixed width file with variables of varying width. The help is
> pretty transparent for this feature, but I can't seem to 
> figure out how
> I can make effective use of the package with my data.
> 
> In my dataset, the first 80 columns are of width 1 followed by other
> variables with width larger than 1.
> 
> I think the correct way to do this, by brute force, would be
> 
> > read.fwf(dataset, 1,1,1,...,1,5,...).
> 
> I'm sure I do not need to actually enter 80 "1"s, correct? How might I
> do this more effectively?
> 
> Harold
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From wolski at molgen.mpg.de  Wed Sep 15 16:00:05 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Wed, 15 Sep 2004 16:00:05 +0200
Subject: [R] Density Estimation
In-Reply-To: <af2aa6640409150436722aa40c@mail.gmail.com>
References: <af2aa6640409150436722aa40c@mail.gmail.com>
Message-ID: <200409151600050666.0BCE3437@mail.math.fu-berlin.de>

Hi!

The function density returns you a object of class density.
This object has an x and an y attribute which you can access by x y,
Hi!

Use approx and runif.

eg.:

dd<-density(rnorm(100,3,5))
plot(dd)

Using the function ?approx you can compute the density value for any x.
#the x is a dummy here.
mydist<-function(x,dd)
{
	
	while(1)
	{
		tmp <- runif(1,min=min(dd$x),max=max(dd$x))
		lev <- approx(dd$x,dd$y,tmp)$y
		if(runif(1,c(0,1)) <= lev)
		{
			return(tmp)
		}
	}
}

x <- 0
mydist(x,dd)

res<-rep(0,500)
res<-sapply(res,mydist,dd)
lines(density(res),col=2)


/E.



*********** REPLY SEPARATOR  ***********

On 9/15/2004 at 12:36 PM Brian Mac Namee wrote:

>>>Hi there,
>>>
>>>Sorry if this is a rather loing post. I have a simple list of single
>>>feature data points from which I would like to generate a probability
>>>that an unseen point comes from the same distribution. To do this I am
>>>trying to estimate the probability density of the list of points and
>>>use this to generate a probability for the new unseen points. I have
>>>managed to use the R density function to generate the density estimate
>>>but have not been able to do anything with this - i.e. generate a
>>>rpobability that a new point comes from the same distribution. Is
>>>there a function to do this, or am I way off the mark using the
>>>density function at all?
>>>
>>>Thanks in advance,
>>>
>>>Brian.
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin                'v'    
tel: 0049-30-83875219                        /   \       
mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
      wolski at molgen.mpg.de



From tom_woody at swissinfo.org  Wed Sep 15 16:01:22 2004
From: tom_woody at swissinfo.org (=?ISO-8859-15?Q?Thomas_Sch=F6nhoff?=)
Date: Wed, 15 Sep 2004 16:01:22 +0200
Subject: [R] loading error of the Rcmdr library on Debian Sid
In-Reply-To: <85vfefslgy.fsf@servant.blindglobe.net>
References: <414812E2.5030603@web.de> <85vfefslgy.fsf@servant.blindglobe.net>
Message-ID: <41484B32.5080606@swissinfo.org>

Hello,

A.J. Rossini schrieb:
> You can apt-get RGL in sid.  

An apt-cache search or (Synaptic search) RGL gives me r-cran-rgl 
0.64.13-1. This package is already installed!

regards
Thomas



From rxg218 at psu.edu  Wed Sep 15 16:12:53 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Wed, 15 Sep 2004 10:12:53 -0400
Subject: [R] fractal dimension of an image
Message-ID: <1095257573.6546.21.camel@blue.chem.psu.edu>

Hello, I have a problem that I think can be solved in R but I'm not sure
how to tie things together.

I have a digital image of a crystal growth in 2 dimensions. And my aim
is to calculate the fractal dimension of the crystal. I was planning to
use the box counting method.

So I need to read in the image in R (for which I can use the pixmap or
rimage packages) and then draw a grid over at a series of resolutions
and for each grid, count how many cells of the grid are occupied by the
crystal. Since the image can be converted to grayscale, I figured that
specifying an intensity threshold would allow me to differentiate
between crystal and surrounding solution.

I know this can be done in Matlab, but since I'm more comfortable in R
can it be done in R? I found the fdim package but that calculates the
dimension for a data.frame - but I'm not sure whether this would be
feasible for my image.

Any pointers would be appreciated
-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
So the Zen master asked the hot-dog vendor, 
"Can you make me one with everything?"
- TauZero on Slashdot



From Ted.Harding at nessie.mcc.ac.uk  Wed Sep 15 16:07:33 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 15 Sep 2004 15:07:33 +0100 (BST)
Subject: [R] Density Estimation
In-Reply-To: <af2aa6640409150436722aa40c@mail.gmail.com>
Message-ID: <XFMail.040915150733.Ted.Harding@nessie.mcc.ac.uk>

On 15-Sep-04 Brian Mac Namee wrote:
> Sorry if this is a rather loing post. I have a simple list of single
> feature data points from which I would like to generate a probability
> that an unseen point comes from the same distribution. To do this I am
> trying to estimate the probability density of the list of points and
> use this to generate a probability for the new unseen points. I have
> managed to use the R density function to generate the density estimate
> but have not been able to do anything with this - i.e. generate a
> rpobability that a new point comes from the same distribution. Is
> there a function to do this, or am I way off the mark using the
> density function at all?

It's not clear what you're really after, but it looks as though you
may be wanting to sample from the distribution estimated by 'density'.

A possible approach, which you could refine, is exemplified by

  x<-rnorm(1000)
  d<-density(x,n=4096)
  y<-sample(d$x,size=1000,prob=d$y)

Check performance with

  hist(y)

Looks OK to me! See "?density" and "?sample".

On an alternative interpretation, perhaps you want to first estimate
the density based on data you already have, and then when you have
got further data (but these would then be "seen" and not "unseen")
come to a judgement about whether these new points are compatible
with coming from the distributikon you have estimated.

A possible approach to this question (again susceptible to refinement)
would be as follows.

1. Use a fine-grained grid for 'density', i.e. a large value for "n".

2. Replace each of the points in the new data by the nearest point
   in this grid. Call these values z1, z2, ... , zk corresponding
   to index values i1, i2, ... , ik in d$x.

3. Evaluate the probability P(z1,...,zk) from the density as the
   product of d$y[i] where i<-c(i1,...,ik).
   Better still, evaluated the logarithm of this. Call the result L.

4. Now simulate a large number of draws of k values from d on the
   lines of sample(d$x,size=k,prob=d$y) as above, and evaluate L
   for each  of these. Where is the value of L from (3) situated in
   the distribution of these values of L from (4)? If (say) only
   1 per cent of the simulated values of L from "d" are less than
   the value of L from (3), then you have a basis for a test that
   your new data did not come from the distribution you have estimated
   from your old data, in that the new data are from the low-density
   part of the estimated distribution.

There are of course alternative ways to view this question. The
value of "k" is relevant. In particular, if "k" is small (say 3
or 4) then the suggestion in (4) is probably the best way to
approach it. However, if "k" is large then you can use a test on
the lines of Kolmogorov-Smirnov with the reference distribution
estimated as the cumulative distribution of d$y and the distribution
being tested as the empirical cumulative distribution of your new
data.

Even sharper focus is available if you are in a position to make
a paramatric model for your data, but your description does not
suggest that this is the case.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 15-Sep-04                                       Time: 15:07:33
------------------------------ XFMail ------------------------------



From deepayan at stat.wisc.edu  Wed Sep 15 16:47:15 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 15 Sep 2004 09:47:15 -0500
Subject: [R] control of font size & colour for title, subtitles, axis,
	and tick marks  in LATTICE graph
In-Reply-To: <HCECJPLNNGBBJIOJMJJAOEGDCJAA.jens_hainmueller@ksg05.harvard.edu>
References: <HCECJPLNNGBBJIOJMJJAOEGDCJAA.jens_hainmueller@ksg05.harvard.edu>
Message-ID: <200409150947.15667.deepayan@stat.wisc.edu>

On Wednesday 15 September 2004 08:24, Jens Hainmueller wrote:
> Hi,
>
> I very much appreciate any help on this "fine tuning" problem in a
> lattice graph (I am new to LATTICE and could not find an example in
> the help files that worked for me. My apologies if I missed it
> there).

Well, if the examples were to cover all possible uses, there would be so 
many that they would become practically useless as reference. You are 
also expected to read the documentation. At least for your first 
question, the solution is described pretty much where you would expect 
it to be (see below).

> I am running the following box plots to compare conditional
> distributions of x at different levels of y under two treatment
> conditions ID=1 (upper panel ) & ID=0 (lower panel of the plot).
>
> bwplot(HF.ELECYEAR ~ stparvotech | ID ,
>  data=data, aspect=1,
>  layout=c(1,2),
>             xlab="Changes in Party Vote Shares",
>  xlim=(-20:20),
>             ylab="Periods Following Last Federal Election",
>             main="Divided Government",
>  panel = function(x,y)
>   {
>   panel.bwplot(x,y)
>   panel.abline(v=0, col="red")
>   }
>  )
>
> How can I:
> 1. Control the font size of the main title, the panel titles, the
> axis, and the tick marks? The usual cex.main=1/3, cex.xlab etc. do
> not work. 

Why do you expect them to? In help(bwplot), the entry for 'main' says:

    main: character string or expression or list describing main title
          to be placed on top of each page. Defaults to 'NULL'. Can be
          a character string or expression, or a list with components
          'label, cex, col, font'. The 'label' tag can be omitted if it
          is the first element of the list. Expressions are treated as
          specification of LaTeX-like markup as in 'plotmath'

which suggests that 

    main = list(label = "Divided Government", cex = 1/3)

is what you want. 


> 2. Change the color of the boxes where the panel titles 
> (ID=1 & ID=0) are located?

See help(strip.default). You need to use something like

strip = function(..., bg) strip.default(..., bg = "white")

(The next version of lattice will have a slightly easier way to do this, 
along with an example.)

All this can also be done by changing the settings globally (see 
help(trellis.par.get)), but that's probably not what you want.

Hope that helps,

Deepayan



From ivo_welch-rstat8783 at mailblocks.com  Wed Sep 15 16:53:56 2004
From: ivo_welch-rstat8783 at mailblocks.com (ivo_welch-rstat8783@mailblocks.com)
Date: Wed, 15 Sep 2004 07:53:56 -0700
Subject: [R] adding observations to lm for fast recursive residuals?
In-Reply-To: <200409151010.i8FA7BNw030381@hypatia.math.ethz.ch>
References: <200409151010.i8FA7BNw030381@hypatia.math.ethz.ch>
Message-ID: <200409151453.i8FErv0w032711@hypatia.math.ethz.ch>


dear R community:  i have been looking but failed to find the 
following:  is there a function in R that updates a plain OLS lm() 
model with one additional observation, so that I can write a function 
that computes recursive residuals *quickly*?

PS: (I looked at package strucchange, but if I am not mistaken, the 
recresid function there takes longer than iterating over the models 
fresh from start to end.)  I know the two functions do not do the same 
thing, but the main part (OLS) is the same:
   > handrecurse.test <- function( y, x ) { z<- rep(NA, T); for (i in 
2:T)  { z[i] <- coef(lm(y[1:i] ~ x[1:i]))[2]; }; return(z); }
  > system.time(handrecurse.test(y,x))
    [1] 0.69 0.00 0.70 0.00 0.00
  > system.time(length(recresid( y~x )))
     [1] 1.44 0.07 1.59 0.00 0.00

pointers appreciated.  regards, /iaw

---
ivo welch



From rkoenker at uiuc.edu  Wed Sep 15 17:07:17 2004
From: rkoenker at uiuc.edu (roger koenker)
Date: Wed, 15 Sep 2004 10:07:17 -0500
Subject: [R] adding observations to lm for fast recursive residuals?
In-Reply-To: <200409151453.i8FErv0w032711@hypatia.math.ethz.ch>
References: <200409151010.i8FA7BNw030381@hypatia.math.ethz.ch>
	<200409151453.i8FErv0w032711@hypatia.math.ethz.ch>
Message-ID: <EF2EEF66-0728-11D9-A545-000A95A7E3AA@uiuc.edu>

In my quantreg package there is a function called lm.fit.recursive() 
that, as the .Rd file
says:

Description:

      This function fits a linear model by recursive least squares.  It
      is a utility routine for the 'khmaladzize' function of the
      quantile regression package.

Usage:

      lm.fit.recursive(X, y, int=TRUE)

Arguments:

        X: Design Matrix

        y: Response Variable

      int: if TRUE then append intercept to X

Value:

      return p by n matrix of fitted parameters, where p. The ith column
      gives the solution up to "time" i.

It is written in fortran so it should be reasonably quick.

HTH

url:	www.econ.uiuc.edu/~roger        	Roger Koenker
email	rkoenker at uiuc.edu			Department of Economics
vox: 	217-333-4558				University of Illinois
fax:   	217-244-6678				Champaign, IL 61820

On Sep 15, 2004, at 9:53 AM, <ivo_welch-rstat8783 at mailblocks.com> wrote:

>
> dear R community:  i have been looking but failed to find the 
> following:  is there a function in R that updates a plain OLS lm() 
> model with one additional observation, so that I can write a function 
> that computes recursive residuals *quickly*?
>
> PS: (I looked at package strucchange, but if I am not mistaken, the 
> recresid function there takes longer than iterating over the models 
> fresh from start to end.)  I know the two functions do not do the same 
> thing, but the main part (OLS) is the same:
>   > handrecurse.test <- function( y, x ) { z<- rep(NA, T); for (i in 
> 2:T)  { z[i] <- coef(lm(y[1:i] ~ x[1:i]))[2]; }; return(z); }
>  > system.time(handrecurse.test(y,x))
>    [1] 0.69 0.00 0.70 0.00 0.00
>  > system.time(length(recresid( y~x )))
>     [1] 1.44 0.07 1.59 0.00 0.00
>
> pointers appreciated.  regards, /iaw
>
> ---
> ivo welch
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From pgilbert at bank-banque-canada.ca  Wed Sep 15 17:33:14 2004
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 15 Sep 2004 11:33:14 -0400
Subject: [R] rolling n-step predictions for ARIMA models
In-Reply-To: <s1473a46.071@email.ers.usda.gov>
References: <s1473a46.071@email.ers.usda.gov>
Message-ID: <414860BA.3030900@bank-banque-canada.ca>

There are functions in the dse bundle that do this. (See 
featherForecasts and horizonForecasts.) You might look through the 
users' guide to get an idea if they are exactly what you want.

Paul Gilbert

Michael Roberts wrote:

>Hello:
>
>I would like to generate rolling, multiperiod forecasts from an 
>estimated ARIMA model, but the function predict.Arima seems 
>only to generate forecasts from the last observation in the data 
>set.  To implement this, I was looking for an argument like 
>'newdata=' in predict.lm.  
>
>I can write some code that does this for my particular problem,
>but might there exist a package/function that does this that I 
>cannot find?
>
>Thanks,
>-Michael
>
>
>
>
>Michael J. Roberts
>
>Resource Economics Division
>Production, Management, and Technology
>USDA-ERS
>(202) 694-5557 (phone)
>(202) 694-5775 (fax)
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From ripley at stats.ox.ac.uk  Wed Sep 15 17:38:17 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 15 Sep 2004 16:38:17 +0100 (BST)
Subject: [R] [R-pkgs] RODBC 1.1-1
Message-ID: <Pine.LNX.4.44.0409151632150.17035-100000@gannet.stats>

The first non-maintenance update of RODBC since January 2003 is now on 
CRAN and will soon propagate to mirrors.  From the ChangeLog:

        * Select the decimal point from Sys.localeconv.

        * Add an external reference and finalizer so open channels get
          closed at the end of the session or when there is no R object
          referring to them.

        * There is no longer a restriction to 16 channels.

        * Add NAMESPACE.

        * odbcConnect{Access,Dbase,Excel} allow a missing file name
          (and will bring up a dialog box to search for it).

        * odbcGetInfo returns more information in a 8-element character
          vector (based on an idea of Matthew Dowle).

        * The C code calls SQLExecuteDirect rather than SQLExecute and
          does not call SQLCloseCursor, based on a problem report from
          Matthew Dowle using MS SQLServer.  Repeated calls to
          sqlGetResults now work.

        * New function sqlFetchMore.

        * Table names in Access with embedded spaces are mapped to the
          [name space] form which Access requires.

        * Table creation no longer removes _ from column names.

        * New functions get/setSqlTypeInfo and the typeInfo argument to
          sqlSave allow users to specify the mapping from R types to DBMS
          datatypes.  sqlSave also allows the specification of DBMS
          datatypes by column.

        * It is now possible to write more than 255 chars to a field with
          sqlSave and sqlUpdate.

        * Dates and timestamps are now read as 'Date' and 'POSIXct'
          columns by sqlGetResults (unless as.is = TRUE for the column).

I have been able to test SQL Server reasonably extensively this time 
around, as well as MySQL, PostgreSQL, Access, Excel and SQLite.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From fm3a004 at math.uni-hamburg.de  Wed Sep 15 18:09:18 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Wed, 15 Sep 2004 18:09:18 +0200 (MEST)
Subject: [R] cluster analysis and null hypothesis testing
In-Reply-To: <003c01c49ae7$bb452410$87cb0d50@PC728329681112>
Message-ID: <Pine.GSO.3.95q.1040915175136.13438A-100000@sun35.math.uni-hamburg.de>

Hi,

testing the "randomness of a cluster analysis" is not a well defined
problem, because it depends crucially on your null model. In fpc, there is
nothing like this. Function prabtest in package prabclus performs such a
test, but this is for a particular data structure, namely presence-absence
data in biogeography. 

In principle, a Monte Carlo test can be constructed (and thus implemented in
R) as follows:

1) You need a null model H_0, from which you generate data.
2) You need a test statistic T.
3) Compute T on your data (call it T_0).
4) Repeat k times:
 a) Generate data from H_0
 b) Compute T on the generated data.
5) The p-value is (K+1)/(k+1), where K is the number of generated datasets
   for which T<=T_0 (given that "T small" indicates the tendency of
   clustering). 

Standard choices for H_0 will be a normal or uniform distribution. (In
prabtest, it is a complicated distribution on presence-absence data.)
There are lots of possible choices of T. prabtest uses the ratio between  
the 25% smallest distances in the dataset and the 25% largest distances.
This should be reasonable in fairly general settings. For a discussion of
this and alternative choices (and references on them), you may take a look
into 

C. Hennig and B. Hausdorf:  Distance-based parametric bootstrap tests for
clustering of species ranges,  Computational
Statistics and Data Analysis 45 (2004), 875-896.

A preprint of this can be obtained from my web page.

If you want to test the significance of a solution from a particular cluster
analysis method, you should think about choosing T so that it is somehow
connected to the method. (In the Hennig and Hausdorf paper, there are for
example two alternatives discussed that are connected to Single Linkage.)

Best,
Christian 

On Wed, 15 Sep 2004, Patrick Giraudoux wrote:

> Hi,
> 
> I am wondering if a Monte Carlo method (or equivalent) exist permitting to test the randomness of a cluster analysis (eg got by
> hclust(). I went through the package "fpc" (maybe too superficially) but dit not find such method.
> 
> Thanks for any hint,
> 
> Patrick Giraudoux
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From spencer.graves at pdf.com  Wed Sep 15 18:27:28 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 15 Sep 2004 09:27:28 -0700
Subject: [R] fractal dimension of an image
In-Reply-To: <1095257573.6546.21.camel@blue.chem.psu.edu>
References: <1095257573.6546.21.camel@blue.chem.psu.edu>
Message-ID: <41486D70.2010206@pdf.com>

      From "www.r-project.org" -> search -> "R site search" -> "fractal 
dimension", I got 17 hits, the third of which discussed package 
RandomFields, which includes a function "fractal".  Are you familiar 
with this? 

      hope this helps. 
      spencer graves
p.s.  Have you read the posting guide! 
"http://www.R-project.org/posting-guide.html"? 

Rajarshi Guha wrote:

>Hello, I have a problem that I think can be solved in R but I'm not sure
>how to tie things together.
>
>I have a digital image of a crystal growth in 2 dimensions. And my aim
>is to calculate the fractal dimension of the crystal. I was planning to
>use the box counting method.
>
>So I need to read in the image in R (for which I can use the pixmap or
>rimage packages) and then draw a grid over at a series of resolutions
>and for each grid, count how many cells of the grid are occupied by the
>crystal. Since the image can be converted to grayscale, I figured that
>specifying an intensity threshold would allow me to differentiate
>between crystal and surrounding solution.
>
>I know this can be done in Matlab, but since I'm more comfortable in R
>can it be done in R? I found the fdim package but that calculates the
>dimension for a data.frame - but I'm not sure whether this would be
>feasible for my image.
>
>Any pointers would be appreciated
>-------------------------------------------------------------------
>Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
>GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
>-------------------------------------------------------------------
>So the Zen master asked the hot-dog vendor, 
>"Can you make me one with everything?"
>- TauZero on Slashdot
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From pwlepp at pmgm2.stanford.edu  Wed Sep 15 19:03:00 2004
From: pwlepp at pmgm2.stanford.edu (Paul Lepp)
Date: Wed, 15 Sep 2004 10:03:00 -0700
Subject: [R] heatmap2
Message-ID: <DEEEIJAKFKHHOHEFAAEIIECGCKAA.pwlepp@cmgm.stanford.edu>

Can anybody tell me where to find a copy of heatmap2?  I've seen it in my
travels across the web but didn't bookmark it and can't find it again.
Thanks in advance.

Paul

 `-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.
   `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`
     >==/        >==/        >==/        >==/        >==/
   ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,
,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'
Paul Lepp, Ph.D.                       Stanford School of Medicine

VAPAHCS, 154T                   Dept. of Microbiology & Immunology
3801 Miranda Ave                               Stanford University
Palo Alto, CA 94304                                   Stanford, CA
(650) 493-5000 x66762		               fax: (650) 852-3291
http://cmgm.stanford.edu/~pwlepp          pwlepp at cmgm.stanford.edu



From sdavis2 at mail.nih.gov  Wed Sep 15 19:09:08 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 15 Sep 2004 13:09:08 -0400
Subject: [R] heatmap2
In-Reply-To: <DEEEIJAKFKHHOHEFAAEIIECGCKAA.pwlepp@cmgm.stanford.edu>
References: <DEEEIJAKFKHHOHEFAAEIIECGCKAA.pwlepp@cmgm.stanford.edu>
Message-ID: <F50D7C6C-0739-11D9-A552-000A95D7BA10@mail.nih.gov>

Paul,

It is called heatmap.2 and it is in the gregmisc package.

Sean

On Sep 15, 2004, at 1:03 PM, Paul Lepp wrote:

> Can anybody tell me where to find a copy of heatmap2?  I've seen it in 
> my
> travels across the web but didn't bookmark it and can't find it again.
> Thanks in advance.
>
> Paul
>
>  `-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.   ,-;"`-:-.
>    `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`,'=/     `=`
>> ==/        >==/        >==/        >==/        >==/
>    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,-<=`.    ,=,
> ,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'   `-=_,-'-'
> Paul Lepp, Ph.D.                       Stanford School of Medicine
>
> VAPAHCS, 154T                   Dept. of Microbiology & Immunology
> 3801 Miranda Ave                               Stanford University
> Palo Alto, CA 94304                                   Stanford, CA
> (650) 493-5000 x66762		               fax: (650) 852-3291
> http://cmgm.stanford.edu/~pwlepp          pwlepp at cmgm.stanford.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From rbonneau at systemsbiology.org  Wed Sep 15 19:16:40 2004
From: rbonneau at systemsbiology.org (Richard Bonneau)
Date: Wed, 15 Sep 2004 10:16:40 -0700
Subject: [R] lomb periodogram package
Message-ID: <020A2BE0-073B-11D9-BBBC-000A95AFB68E@systemsbiology.org>


Hi,

Does anyone know the name of the package that
includes a function for computing the lomb periodogram on irregular
spaced ts data? I saw the package once ~ 1 month ago but cannot
find it now ...

,
Rich



From aorchid at mac.com  Wed Sep 15 19:29:28 2004
From: aorchid at mac.com (Aric Gregson)
Date: Wed, 15 Sep 2004 13:29:28 -0400
Subject: [R] Problem installing source packages on OS X
Message-ID: <r02010300-1035-CC62CA14073C11D98641000A959B3D22@[134.192.145.80]>

I am attempting to install the Hmisc, rreport and Design packages, but
am not able to do so. I am running R v1.9.1 on Mac OS 10.3.5. 

I have tried installation using both the GUI version of R and also
running R from sudo in a terminal session. In the terminal I receive the
following error:

* Installing *source* package 'Design' ...
** libs
g77   -fno-common  -g -O2 -c lrmfit.f -o lrmfit.o
make: g77: Command not found
make: *** [lrmfit.o] Error 127
ERROR: compilation failed for package 'Design'
** Removing
'/Library/Frameworks/R.framework/Versions/1.9.1/Resources/library/Design
'

I get the same error for Hmisc (rreport is not on CRAN). It looks like
it is trying to use g77 to compile the source package. How can I change
the default compiler? Will this solve the problem? I cannot find a
binary version of either package.

thanks,

aric



From jari.oksanen at oulu.fi  Wed Sep 15 19:42:17 2004
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Wed, 15 Sep 2004 20:42:17 +0300
Subject: [R] Problem installing source packages on OS X
In-Reply-To: <r02010300-1035-CC62CA14073C11D98641000A959B3D22@[134.192.145.80]>
References: <r02010300-1035-CC62CA14073C11D98641000A959B3D22@[134.192.145.80]>
Message-ID: <963078B0-073E-11D9-BA78-000A95C76CA8@oulu.fi>


On 15 Sep 2004, at 20:29, Aric Gregson wrote:

> I am attempting to install the Hmisc, rreport and Design packages, but
> am not able to do so. I am running R v1.9.1 on Mac OS 10.3.5.
>
> I get the same error for Hmisc (rreport is not on CRAN). It looks like
> it is trying to use g77 to compile the source package. How can I change
> the default compiler? Will this solve the problem? I cannot find a
> binary version of either package.
>
R is trying to build a Fortran program, and it needs a Fortran 
compiler. Fortran compiler does not ship with MacOS X, but you got to 
get one. See the MacOS FAQ for R. If I remember correctly, it tells you 
to go http://hpc.sourceforge.net/ for the compiler.

Normally I wouldn't remember addresses like this, but just today I had 
to make a visit there: I had installed g77 using fink, and that puts 
its stuff into /sw instead of /usr/local. Some R routines had hardcoded 
the g77 path to /usr/local/bin/g77 and so building a package failed in 
the false claim of missing g77 (yeah, it was in the path).

cheers, jari oksanen
--
Jari Oksanen, Oulu, Finland



From tpapp at Princeton.EDU  Wed Sep 15 20:01:08 2004
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Wed, 15 Sep 2004 14:01:08 -0400
Subject: [R] BUGS and OS X
Message-ID: <20040915180108.GA949@dynamic-oit-vapornet-b-104>

Is there a way of running BUGS on OS X (from R)?  I only see Windows
versions on their website.

If not, what are the alternatives for Bayesian analysis?

Thanks,

Tamas



From cstrato at aon.at  Wed Sep 15 20:15:08 2004
From: cstrato at aon.at (cstrato)
Date: Wed, 15 Sep 2004 20:15:08 +0200
Subject: [R] Bessel function
In-Reply-To: <E619BDBD99B4F74D9DCA32F43BE926714C748C@XCH-VN02.sph.ad.jhsph.edu>
References: <E619BDBD99B4F74D9DCA32F43BE926714C748C@XCH-VN02.sph.ad.jhsph.edu>
Message-ID: <414886AC.3080902@aon.at>

You can find C++ source code for Bessel function and similar
functions for example here:
http://root.cern.ch/root/htmldoc/src/TMath.cxx.html

Hope this helps

Best regards
Christian
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
C.h.r.i.s.t.i.a.n. .S.t.r.a.t.o.w.a
V.i.e.n.n.a.         .A.u.s.t.r.i.a
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-

Ravi Varadhan wrote:
> Dear Beat,
>  
> You might also want to look at the book by Zang and Jin -  Computation of Special Functions, John Wiley.  They have Fortran sources for all the special functions covered in there.
>  
> Ravi.
>  
> Ravi Varadhan, Ph.D.
> Assistant Professor,  The Center on Aging and Health
> Division of Geriatric Medicine and Gerontology,
> Johns Hopkins University,
> 2024 E. Monument Street, Suite 2-700
> Baltimore, MD 21205.
> (410) 502 - 7806.
> 
> ________________________________
> 
> From: r-help-bounces at stat.math.ethz.ch on behalf of beat.huggler at rmf.ch
> Sent: Wed 9/15/2004 4:24 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] Bessel function
> 
> 
> 
> 
> 
>  Dear all
> 
> Currently, I'm implementing the generalized hyperbolic distribution into
> Splus. Unfortunately the Bessel function is not implemented in Splus. In
> R the Bessel function does exist but it is an internal function and I'm
> not able to look at the code.
> 
> Is there any possibility to see the code of the Bessel function in R or
> does anybody has an implementation of the Bessel function in Splus?
> 
> Thanks a lot for your help.
> 
> Beat
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From rolf at math.unb.ca  Wed Sep 15 20:28:32 2004
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed, 15 Sep 2004 15:28:32 -0300 (ADT)
Subject: [R] Slightly off-topic --- distribution name.
Message-ID: <200409151828.i8FISWNP003653@erdos.math.unb.ca>


I've built R functions to ``effect'' a particular distribution, and
would like to find out if that distribution is already ``known'' by
an existing name.  (I.e. suppose it were called the ``Melvin''
distribution --- I've built dmelvin, pmelvin, qmelvin, and rmelvin as
it were, but I need a real name to substitute for melvin.)

The distribution is really just a toy --- but it provides a nice (and
``non-obviouse'') example of a two parameter distribution where both
the moment and maximum likelihood equations for the parameter
estimators are readily solvable, but at the same time are
``interesting''.  So it's good for exercises in an intro math-stats
course.

The distribution is simply that of the ***difference*** of two
independent exponential variates, with different parameters.

I.e.  X = U - V  where U ~ exp(beta) and V ~ exp(alpha) (where
E(U) = beta, E(V) = alpha).

This makes the distribution of X something like an asymetric Laplace
distribution, with its mode at 0.  (One could shift the mode too, but
that would add a third parameter, which would be de trop.)

Anyhow:  Is this a ``known'' distribution?  Does it have a name?
(I've never seen it mentioned in any of the intro math-stat books
that I've looked into.) If not, can anyone suggest a good name for
it?  (Don't be rude now!)

				cheers,

					Rolf Turner
					rolf at math.unb.ca

P. S.  To save you putting pen to paper and working it out,
       the density function is

               { exp(x/alpha)/(alpha + beta) for x <= 0
	f(x) = {
               { exp(-x/beta)/(alpha + beta) for x >= 0

       The mean and variance are mu = beta - alpha and
       sigma^2 = alpha^2 + beta^2 respectfully. :-)



From tpapp at Princeton.EDU  Wed Sep 15 20:29:07 2004
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Wed, 15 Sep 2004 14:29:07 -0400
Subject: [R] BUGS and OS X
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF83C6@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF83C6@usrymx25.merck.com>
Message-ID: <20040915182907.GA1065@dynamic-oit-vapornet-b-104>

On Wed, Sep 15, 2004 at 02:21:18PM -0400, Liaw, Andy wrote:
> That's more of a question for the BUGS developers.  BUGS is not open source,
> so whatever binary is provided, that's all you can use.  If I'm not
> mistaken, WinBUGS is the only version under development.

I found something called JAGS, and I am still exploring it.  It
appears to be an open-source BUGS replacement, thought with
limitations.

I was asking what software people would recommend for the same
functionality, not a drop-in replacement.  I am just baffled by the
bewildering array of R packages, and would be so happy if somebody
told me what THEY use for Bayesian analysis, so I could read the docs
and get started.  MCMC? Boa? etc.  Suggestions on how experienced
users do bayesian analysis in R would be welcome.

Thanks,

Tamas



From rossini at blindglobe.net  Wed Sep 15 20:38:08 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 15 Sep 2004 11:38:08 -0700
Subject: [R] Slightly off-topic --- distribution name.
In-Reply-To: <200409151828.i8FISWNP003653@erdos.math.unb.ca> (Rolf Turner's
	message of "Wed, 15 Sep 2004 15:28:32 -0300 (ADT)")
References: <200409151828.i8FISWNP003653@erdos.math.unb.ca>
Message-ID: <85acvr74z3.fsf@servant.blindglobe.net>


Have you checked Johnson and Kotz?  That's the obvious place to start
looking for distributions beyond the usual.

Rolf Turner <rolf at math.unb.ca> writes:

> I've built R functions to ``effect'' a particular distribution, and
> would like to find out if that distribution is already ``known'' by
> an existing name.  (I.e. suppose it were called the ``Melvin''
> distribution --- I've built dmelvin, pmelvin, qmelvin, and rmelvin as
> it were, but I need a real name to substitute for melvin.)
>
> The distribution is really just a toy --- but it provides a nice (and
> ``non-obviouse'') example of a two parameter distribution where both
> the moment and maximum likelihood equations for the parameter
> estimators are readily solvable, but at the same time are
> ``interesting''.  So it's good for exercises in an intro math-stats
> course.
>
> The distribution is simply that of the ***difference*** of two
> independent exponential variates, with different parameters.
>
> I.e.  X = U - V  where U ~ exp(beta) and V ~ exp(alpha) (where
> E(U) = beta, E(V) = alpha).
>
> This makes the distribution of X something like an asymetric Laplace
> distribution, with its mode at 0.  (One could shift the mode too, but
> that would add a third parameter, which would be de trop.)
>
> Anyhow:  Is this a ``known'' distribution?  Does it have a name?
> (I've never seen it mentioned in any of the intro math-stat books
> that I've looked into.) If not, can anyone suggest a good name for
> it?  (Don't be rude now!)
>
> 				cheers,
>
> 					Rolf Turner
> 					rolf at math.unb.ca
>
> P. S.  To save you putting pen to paper and working it out,
>        the density function is
>
>                { exp(x/alpha)/(alpha + beta) for x <= 0
> 	f(x) = {
>                { exp(-x/beta)/(alpha + beta) for x >= 0
>
>        The mean and variance are mu = beta - alpha and
>        sigma^2 = alpha^2 + beta^2 respectfully. :-)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From dave at kanecap.com  Wed Sep 15 20:44:53 2004
From: dave at kanecap.com (David Kane)
Date: Wed, 15 Sep 2004 14:44:53 -0400
Subject: [R] replacing NA's with 0 in a dataframe for specified columns
Message-ID: <16712.36261.523390.852026@gargle.gargle.HOWL>

I know that there must be a cool way of doing this, but I can't think
of it. Let's say I have an dataframe with NA's.

> x <- data.frame(a = c(0,1,2,NA), b = c(0,NA,1,2), c = c(NA, 0, 1, 2))
> x
   a  b  c
1  0  0 NA
2  1 NA  0
3  2  1  1
4 NA  2  2
> 

I know it is easy to replace all the NA's with zeroes.

> x[is.na(x)] <- 0
> x
  a b c
1 0 0 0
2 1 0 0
3 2 1 1
4 0 2 2
> 

But how do I do this for just columns a and c, leaving the NA in
column b alone?

Thanks,

Dave Kane

> R.version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    9.1              
year     2004             
month    06               
day      21               
language R                
>



From efg at stowers-institute.org  Wed Sep 15 20:40:41 2004
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Wed, 15 Sep 2004 13:40:41 -0500
Subject: [R] lomb periodogram package
References: <020A2BE0-073B-11D9-BBBC-000A95AFB68E@systemsbiology.org>
Message-ID: <cia2be$h8s$1@sea.gmane.org>

> Does anyone know the name of the package that
> includes a function for computing the lomb periodogram on irregular
> spaced ts data? I saw the package once ~ 1 month ago but cannot
> find it now ...

I have a LombScargleLibrary.R file that I will be talking about at CAMDA '04
in November:

Searching for Periodic Microarray Expression Patterns Using Lomb-Scargle
Periodograms
http://research.stowers-institute.org/efg/2004/CAMDA/

I'll get the file online by the time of the conference on Nov 10:
http://www.camda.duke.edu/camda04

I could E-mail you the preliminary version before then if you'd like.  Just
drop me an E-mail.

efg
Earl F. Glynn
Scientific Programmer
Bioinformatics Department
Stowers Institute for Medical Research



From rossini at blindglobe.net  Wed Sep 15 20:50:42 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 15 Sep 2004 11:50:42 -0700
Subject: [R] [R-pkgs] Announcing snowFT 0.1
In-Reply-To: <Pine.LNX.4.53.0409150923480.7383@sdhcp24.stat.washington.edu>
	(Hana
	Sevcikova's message of "Wed, 15 Sep 2004 09:59:54 -0700 (PDT)")
References: <85mzzrwmrl.fsf@servant.blindglobe.net>
	<Pine.LNX.4.53.0409150923480.7383@sdhcp24.stat.washington.edu>
Message-ID: <85wtyv5ptp.fsf_-_@servant.blindglobe.net>


Parallel programming with snowFT

Our package snowFT is now available at CRAN. It is an extention of the
package snow, which adds fault tolerance (in the sense of recomputing
computational units when hardware/network failures occur on compute
nodes) and a tighter notion of reproducibility for computations
running on clusters.  It additionally provides tools for flexible
management of cluster size as well as computation transparency.

snowFT is written by Hana Sevcikova and Tony Rossini.

(this tool currently requires rpvm for the SNOW backend, though we are
exploring the possibility of extensions for the Rmpi backend.  It is
unlikely that these extensions will be implemented for the socket
backend.

best,
-tony



-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From spencer.graves at pdf.com  Wed Sep 15 21:01:25 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 15 Sep 2004 12:01:25 -0700
Subject: [R] replacing NA's with 0 in a dataframe for specified columns
In-Reply-To: <16712.36261.523390.852026@gargle.gargle.HOWL>
References: <16712.36261.523390.852026@gargle.gargle.HOWL>
Message-ID: <41489185.9030600@pdf.com>

Have you considered the following: 

 > x <- data.frame(a = c(0,1,2,NA), b = c(0,NA,1,2), c = c(NA, 0, 1, 2))
 > x$a[is.na(x$a)] <- 0
 > x$c[is.na(x$c)] <- 0
 > x
  a  b c
1 0  0 0
2 1 NA 0
3 2  1 1
4 0  2 2

      hope this helps.  spencer graves

David Kane wrote:

>I know that there must be a cool way of doing this, but I can't think
>of it. Let's say I have an dataframe with NA's.
>
>  
>
>>x <- data.frame(a = c(0,1,2,NA), b = c(0,NA,1,2), c = c(NA, 0, 1, 2))
>>x
>>    
>>
>   a  b  c
>1  0  0 NA
>2  1 NA  0
>3  2  1  1
>4 NA  2  2
>  
>
>
>I know it is easy to replace all the NA's with zeroes.
>
>  
>
>>x[is.na(x)] <- 0
>>x
>>    
>>
>  a b c
>1 0 0 0
>2 1 0 0
>3 2 1 1
>4 0 2 2
>  
>
>
>But how do I do this for just columns a and c, leaving the NA in
>column b alone?
>
>Thanks,
>
>Dave Kane
>
>  
>
>>R.version
>>    
>>
>         _                
>platform i686-pc-linux-gnu
>arch     i686             
>os       linux-gnu        
>system   i686, linux-gnu  
>status                    
>major    1                
>minor    9.1              
>year     2004             
>month    06               
>day      21               
>language R                
>  
>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From cmoffet at nwrc.ars.usda.gov  Wed Sep 15 21:05:14 2004
From: cmoffet at nwrc.ars.usda.gov (Corey Moffet)
Date: Wed, 15 Sep 2004 13:05:14 -0600
Subject: [R] replacing NA's with 0 in a dataframe for specified
  columns
In-Reply-To: <16712.36261.523390.852026@gargle.gargle.HOWL>
Message-ID: <3.0.6.32.20040915130514.00f90620@pxms.nwrc.ars.usda.gov>

try:

x[is.na(x$a) | is.na(x$c),] <- 0

At 02:44 PM 9/15/2004 -0400, David Kane wrote:
>I know that there must be a cool way of doing this, but I can't think
>of it. Let's say I have an dataframe with NA's.
>
>> x <- data.frame(a = c(0,1,2,NA), b = c(0,NA,1,2), c = c(NA, 0, 1, 2))
>> x
>   a  b  c
>1  0  0 NA
>2  1 NA  0
>3  2  1  1
>4 NA  2  2
>> 
>
>I know it is easy to replace all the NA's with zeroes.
>
>> x[is.na(x)] <- 0
>> x
>  a b c
>1 0 0 0
>2 1 0 0
>3 2 1 1
>4 0 2 2
>> 
>
>But how do I do this for just columns a and c, leaving the NA in
>column b alone?
>
>Thanks,
>
>Dave Kane
>
>> R.version
>         _                
>platform i686-pc-linux-gnu
>arch     i686             
>os       linux-gnu        
>system   i686, linux-gnu  
>status                    
>major    1                
>minor    9.1              
>year     2004             
>month    06               
>day      21               
>language R                
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
With best wishes and kind regards I am

Sincerely,

Corey A. Moffet
Rangeland Scientist

##################################################################
                                            ####		     
USDA-ARS                                        #		     
Northwest Watershed Research Center             #		     
800 Park Blvd, Plaza IV, Suite 105          ###########   ####    
Boise, ID 83712-7716                       #    #      # #        
Voice: (208) 422-0718                      #    #  ####   ####    
FAX:   (208) 334-1502                      #    # #           #   
                                            ####   ###########    
##################################################################



From gunter.berton at gene.com  Wed Sep 15 21:11:49 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 15 Sep 2004 12:11:49 -0700
Subject: [R] replacing NA's with 0 in a dataframe for specified columns
In-Reply-To: <41489185.9030600@pdf.com>
Message-ID: <200409151911.i8FJBnqh002552@ohm.gene.com>


But Spencer's solution would require looping to generalize to a large
numbers of columns.

In fact, you've given the answer already in your post:

xsub<-x[,somecols]
xsub[is.na(xsub)]<-0
x[,somecols]<-xsub

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Spencer Graves
> Sent: Wednesday, September 15, 2004 12:01 PM
> To: David Kane
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] replacing NA's with 0 in a dataframe for 
> specified columns
> 
> Have you considered the following: 
> 
>  > x <- data.frame(a = c(0,1,2,NA), b = c(0,NA,1,2), c = 
> c(NA, 0, 1, 2))
>  > x$a[is.na(x$a)] <- 0
>  > x$c[is.na(x$c)] <- 0
>  > x
>   a  b c
> 1 0  0 0
> 2 1 NA 0
> 3 2  1 1
> 4 0  2 2
> 
>       hope this helps.  spencer graves
> 
> David Kane wrote:
> 
> >I know that there must be a cool way of doing this, but I can't think
> >of it. Let's say I have an dataframe with NA's.
> >
> >  
> >
> >>x <- data.frame(a = c(0,1,2,NA), b = c(0,NA,1,2), c = c(NA, 
> 0, 1, 2))
> >>x
> >>    
> >>
> >   a  b  c
> >1  0  0 NA
> >2  1 NA  0
> >3  2  1  1
> >4 NA  2  2
> >  
> >
> >
> >I know it is easy to replace all the NA's with zeroes.
> >
> >  
> >
> >>x[is.na(x)] <- 0
> >>x
> >>    
> >>
> >  a b c
> >1 0 0 0
> >2 1 0 0
> >3 2 1 1
> >4 0 2 2
> >  
> >
> >
> >But how do I do this for just columns a and c, leaving the NA in
> >column b alone?
> >
> >Thanks,
> >
> >Dave Kane
> >
> >  
> >
> >>R.version
> >>    
> >>
> >         _                
> >platform i686-pc-linux-gnu
> >arch     i686             
> >os       linux-gnu        
> >system   i686, linux-gnu  
> >status                    
> >major    1                
> >minor    9.1              
> >year     2004             
> >month    06               
> >day      21               
> >language R                
> >  
> >
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >  
> >
> 
> -- 
> Spencer Graves, PhD, Senior Development Engineer
> O:  (408)938-4420;  mobile:  (408)655-4567
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

From jfox at mcmaster.ca  Wed Sep 15 21:12:19 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 15 Sep 2004 15:12:19 -0400
Subject: [R] replacing NA's with 0 in a dataframe for specified
 columns
In-Reply-To: <16712.36261.523390.852026@gargle.gargle.HOWL>
Message-ID: <web-64938038@cgpsrv2.cis.mcmaster.ca>

Dear David,

How about the following?

cols <- c(1,3)
x[,cols][is.na(x[,cols])] <- 0

I hope that this helps,
 John

On Wed, 15 Sep 2004 14:44:53 -0400
 David Kane <dave at kanecap.com> wrote:
> I know that there must be a cool way of doing this, but I can't think
> of it. Let's say I have an dataframe with NA's.
> 
> > x <- data.frame(a = c(0,1,2,NA), b = c(0,NA,1,2), c = c(NA, 0, 1,
> 2))
> > x
>    a  b  c
> 1  0  0 NA
> 2  1 NA  0
> 3  2  1  1
> 4 NA  2  2
> > 
> 
> I know it is easy to replace all the NA's with zeroes.
> 
> > x[is.na(x)] <- 0
> > x
>   a b c
> 1 0 0 0
> 2 1 0 0
> 3 2 1 1
> 4 0 2 2
> > 
> 
> But how do I do this for just columns a and c, leaving the NA in
> column b alone?
> 
> Thanks,
> 
> Dave Kane
> 
> > R.version
>          _                
> platform i686-pc-linux-gnu
> arch     i686             
> os       linux-gnu        
> system   i686, linux-gnu  
> status                    
> major    1                
> minor    9.1              
> year     2004             
> month    06               
> day      21               
> language R                
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From ccleland at optonline.net  Wed Sep 15 21:12:26 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 15 Sep 2004 15:12:26 -0400
Subject: [R] replacing NA's with 0 in a dataframe for specified columns
In-Reply-To: <16712.36261.523390.852026@gargle.gargle.HOWL>
References: <16712.36261.523390.852026@gargle.gargle.HOWL>
Message-ID: <4148941A.4080001@optonline.net>

mydata <- data.frame(a = c(0,1,2,NA), b = c(0,NA,1,2), c = c(NA, 0, 1, 2))

mydata
    a  b  c
1  0  0 NA
2  1 NA  0
3  2  1  1
4 NA  2  2

mydata[,c("a", "c")] <-
apply(mydata[,c("a","c")], 2, function(x){replace(x, is.na(x), 0)})

mydata
   a  b c
1 0  0 0
2 1 NA 0
3 2  1 1
4 0  2 2

David Kane wrote:
> I know that there must be a cool way of doing this, but I can't think
> of it. Let's say I have an dataframe with NA's.
> 
> 
>>x <- data.frame(a = c(0,1,2,NA), b = c(0,NA,1,2), c = c(NA, 0, 1, 2))
>>x
> 
>    a  b  c
> 1  0  0 NA
> 2  1 NA  0
> 3  2  1  1
> 4 NA  2  2
> 
> 
> I know it is easy to replace all the NA's with zeroes.
> 
> 
>>x[is.na(x)] <- 0
>>x
> 
>   a b c
> 1 0 0 0
> 2 1 0 0
> 3 2 1 1
> 4 0 2 2
> 
> 
> But how do I do this for just columns a and c, leaving the NA in
> column b alone?
> 
> Thanks,
> 
> Dave Kane
> 
> 
>>R.version
> 
>          _                
> platform i686-pc-linux-gnu
> arch     i686             
> os       linux-gnu        
> system   i686, linux-gnu  
> status                    
> major    1                
> minor    9.1              
> year     2004             
> month    06               
> day      21               
> language R                
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From jfox at mcmaster.ca  Wed Sep 15 21:16:25 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 15 Sep 2004 15:16:25 -0400
Subject: [R] replacing NA's with 0 in a dataframe for specified
  columns
In-Reply-To: <3.0.6.32.20040915130514.00f90620@pxms.nwrc.ars.usda.gov>
Message-ID: <web-64938796@cgpsrv2.cis.mcmaster.ca>

Dear Corey,

I'm afraid that this will entirely zero out any row with an NA in
column "a" or "c".

John

On Wed, 15 Sep 2004 13:05:14 -0600
 Corey Moffet <cmoffet at nwrc.ars.usda.gov> wrote:
> try:
> 
> x[is.na(x$a) | is.na(x$c),] <- 0
> 
> At 02:44 PM 9/15/2004 -0400, David Kane wrote:
> >I know that there must be a cool way of doing this, but I can't
> think
> >of it. Let's say I have an dataframe with NA's.
> >
> >> x <- data.frame(a = c(0,1,2,NA), b = c(0,NA,1,2), c = c(NA, 0, 1,
> 2))
> >> x
> >   a  b  c
> >1  0  0 NA
> >2  1 NA  0
> >3  2  1  1
> >4 NA  2  2
> >> 
> >
> >I know it is easy to replace all the NA's with zeroes.
> >
> >> x[is.na(x)] <- 0
> >> x
> >  a b c
> >1 0 0 0
> >2 1 0 0
> >3 2 1 1
> >4 0 2 2
> >> 
> >
> >But how do I do this for just columns a and c, leaving the NA in
> >column b alone?
> >
> >Thanks,
> >
> >Dave Kane
> >
> >> R.version
> >         _                
> >platform i686-pc-linux-gnu
> >arch     i686             
> >os       linux-gnu        
> >system   i686, linux-gnu  
> >status                    
> >major    1                
> >minor    9.1              
> >year     2004             
> >month    06               
> >day      21               
> >language R                
> >>
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> With best wishes and kind regards I am
> 
> Sincerely,
> 
> Corey A. Moffet
> Rangeland Scientist
> 
> ##################################################################
>                                             ####		     
> USDA-ARS                                        #		     
> Northwest Watershed Research Center             #		     
> 800 Park Blvd, Plaza IV, Suite 105          ###########   ####    
> Boise, ID 83712-7716                       #    #      # #        
> Voice: (208) 422-0718                      #    #  ####   ####    
> FAX:   (208) 334-1502                      #    # #           #   
>                                             ####   ###########    
> ##################################################################
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From roebuck at odin.mdacc.tmc.edu  Wed Sep 15 22:20:24 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Wed, 15 Sep 2004 15:20:24 -0500 (CDT)
Subject: [R] Splitting vector into individual elements
Message-ID: <Pine.OSF.4.58.0409151433320.393815@odin.mdacc.tmc.edu>

Is there a means to split a vector into its individual
elements without going the brute-force route for arguments
to a predefined function call?

    offred.rgb <- c(1, 0, 0) * 0.60;

    ## Brute force style
    offred.col <- rgb(offred.rgb[1],
                      offred.rgb[2],
                      offred.rgb[3],
                      names = "offred")
    ## Desired style
    offred.col <- rgb(silver.bullet(offred.rgb),
                      names = "offred")

Neither of my attempts gets it right.

    silver.bullet.try1 <- function(x) {
        expr <- cat(x, sep = ",")
        return(parse(text = expr))
    }

    silver.bullet.try2 <- function(x) {
        expr <- expression(cat(x, sep = ","))
        return(eval(expr))
    }

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From ggrothendieck at myway.com  Wed Sep 15 22:20:41 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 15 Sep 2004 20:20:41 +0000 (UTC)
Subject: [R] replacing NA's with 0 in a dataframe for specified columns
References: <16712.36261.523390.852026@gargle.gargle.HOWL>
Message-ID: <loom.20040915T220931-311@post.gmane.org>


The col funtion can be helpful here.  We want to satisfy two conditions: 

	1. the element is an NA
	2. the element lies in one of the specified columns

The first two lines below calculate logical vectors for these two,
respectively, and the last line assigns 0 to those elements.

	isna <- is.na(x)
	iscol <- col(isna) %in% c(1,3)
	x[isna & iscol] <- 0

To specify the columns by name rather than number first
calculate their column numbers and then proceed as before.
That is, replace the second line by:

	cols <- match(c("a", "c"), colnames(x))
        iscol <- col(isna) %in% cols





David Kane <dave <at> kanecap.com> writes:

: 
: I know that there must be a cool way of doing this, but I can't think
: of it. Let's say I have an dataframe with NA's.
: 
: > x <- data.frame(a = c(0,1,2,NA), b = c(0,NA,1,2), c = c(NA, 0, 1, 2))
: > x
:    a  b  c
: 1  0  0 NA
: 2  1 NA  0
: 3  2  1  1
: 4 NA  2  2
: > 
: 
: I know it is easy to replace all the NA's with zeroes.
: 
: > x[is.na(x)] <- 0
: > x
:   a b c
: 1 0 0 0
: 2 1 0 0
: 3 2 1 1
: 4 0 2 2
: > 
: 
: But how do I do this for just columns a and c, leaving the NA in
: column b alone?
: 
: Thanks,
: 
: Dave Kane
: 
: > R.version
:          _                
: platform i686-pc-linux-gnu
: arch     i686             
: os       linux-gnu        
: system   i686, linux-gnu  
: status                    
: major    1                
: minor    9.1              
: year     2004             
: month    06               
: day      21               
: language R                
: >
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://stat.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From andy_liaw at merck.com  Wed Sep 15 22:29:11 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 15 Sep 2004 16:29:11 -0400
Subject: [R] Splitting vector into individual elements
Message-ID: <3A822319EB35174CA3714066D590DCD504AF83C9@usrymx25.merck.com>

do.call() is good for this, I believe:

> offred.rgb <- c(1, 0, 0) * 0.60
> offred.col <- do.call("rgb", c(as.list(offred.rgb), names="offred"))
> offred.col
[1] "#990000"

HTH,
Andy

> From: Paul Roebuck
> 
> Is there a means to split a vector into its individual
> elements without going the brute-force route for arguments
> to a predefined function call?
> 
>     offred.rgb <- c(1, 0, 0) * 0.60;
> 
>     ## Brute force style
>     offred.col <- rgb(offred.rgb[1],
>                       offred.rgb[2],
>                       offred.rgb[3],
>                       names = "offred")
>     ## Desired style
>     offred.col <- rgb(silver.bullet(offred.rgb),
>                       names = "offred")
> 
> Neither of my attempts gets it right.
> 
>     silver.bullet.try1 <- function(x) {
>         expr <- cat(x, sep = ",")
>         return(parse(text = expr))
>     }
> 
>     silver.bullet.try2 <- function(x) {
>         expr <- expression(cat(x, sep = ","))
>         return(eval(expr))
>     }
> 
> ----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From spencer.graves at pdf.com  Wed Sep 15 22:35:24 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 15 Sep 2004 13:35:24 -0700
Subject: [R] Splitting vector into individual elements
In-Reply-To: <Pine.OSF.4.58.0409151433320.393815@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0409151433320.393815@odin.mdacc.tmc.edu>
Message-ID: <4148A78C.6070802@pdf.com>

      Have you considered "do.call": 

 > do.call("rgb", as.list((1:3)/10))
[1] "#1A334C"

same as: 
 > rgb(.1, .2, .3)
[1] "#1A334C"

      Hope this helps.  spencer graves

Paul Roebuck wrote:

>Is there a means to split a vector into its individual
>elements without going the brute-force route for arguments
>to a predefined function call?
>
>    offred.rgb <- c(1, 0, 0) * 0.60;
>
>    ## Brute force style
>    offred.col <- rgb(offred.rgb[1],
>                      offred.rgb[2],
>                      offred.rgb[3],
>                      names = "offred")
>    ## Desired style
>    offred.col <- rgb(silver.bullet(offred.rgb),
>                      names = "offred")
>
>Neither of my attempts gets it right.
>
>    silver.bullet.try1 <- function(x) {
>        expr <- cat(x, sep = ",")
>        return(parse(text = expr))
>    }
>
>    silver.bullet.try2 <- function(x) {
>        expr <- expression(cat(x, sep = ","))
>        return(eval(expr))
>    }
>
>----------------------------------------------------------
>SIGSIG -- signature too long (core dumped)
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From jonathan_lees at unc.edu  Wed Sep 15 22:42:47 2004
From: jonathan_lees at unc.edu (Jonathan M. Lees)
Date: Wed, 15 Sep 2004 16:42:47 -0400
Subject: [R] RWAVE axis notation
Message-ID: <4148A947.4020804@unc.edu>

I am using Rwave wavelets and I need better axis notation.

Does anyone have code similar to
matlab's

centfreq
 
or

scale2frq

functions that turn a scale for a wavelet transform into
a good looking scale to plot on my wavelet transfoms?

I am using the rwave package to investigate
seismic signals from an exploding volcano.


Jonathan Lees

-- 
==========================================
Prof. Jonathan M. Lees
Department of Geological Sciences
CB #3315, Mitchell Hall
University of North Carolina
Chapel Hill, NC  27599-3315
(919) 962-0695
FAX (919) 966-4519

jonathan_lees at unc.edu
http://www.unc.edu/~leesj



From ggrothendieck at myway.com  Wed Sep 15 22:49:55 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 15 Sep 2004 20:49:55 +0000 (UTC)
Subject: [R] Splitting vector into individual elements
References: <Pine.OSF.4.58.0409151433320.393815@odin.mdacc.tmc.edu>
Message-ID: <loom.20040915T224839-122@post.gmane.org>

Paul Roebuck <roebuck <at> odin.mdacc.tmc.edu> writes:
 
: Is there a means to split a vector into its individual
: elements without going the brute-force route for arguments
: to a predefined function call?
: 
:     offred.rgb <- c(1, 0, 0) * 0.60;
: 
:     ## Brute force style
:     offred.col <- rgb(offred.rgb[1],
:                       offred.rgb[2],
:                       offred.rgb[3],
:                       names = "offred")
:     ## Desired style
:     offred.col <- rgb(silver.bullet(offred.rgb),
:                       names = "offred")


See:

http://maths.newcastle.edu.au/~rking/R/help/03a/7417.html



From jfox at mcmaster.ca  Wed Sep 15 22:40:51 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 15 Sep 2004 16:40:51 -0400
Subject: [R] Splitting vector into individual elements
In-Reply-To: <Pine.OSF.4.58.0409151433320.393815@odin.mdacc.tmc.edu>
Message-ID: <web-64958285@cgpsrv2.cis.mcmaster.ca>

Dear Paul,

How about do.call("rgb", as.list(offred.rgb)) ?

I hope that this helps,
 John

On Wed, 15 Sep 2004 15:20:24 -0500 (CDT)
 Paul Roebuck <roebuck at odin.mdacc.tmc.edu> wrote:
> Is there a means to split a vector into its individual
> elements without going the brute-force route for arguments
> to a predefined function call?
> 
>     offred.rgb <- c(1, 0, 0) * 0.60;
> 
>     ## Brute force style
>     offred.col <- rgb(offred.rgb[1],
>                       offred.rgb[2],
>                       offred.rgb[3],
>                       names = "offred")
>     ## Desired style
>     offred.col <- rgb(silver.bullet(offred.rgb),
>                       names = "offred")
> 
> Neither of my attempts gets it right.
> 
>     silver.bullet.try1 <- function(x) {
>         expr <- cat(x, sep = ",")
>         return(parse(text = expr))
>     }
> 
>     silver.bullet.try2 <- function(x) {
>         expr <- expression(cat(x, sep = ","))
>         return(eval(expr))
>     }
> 
> ----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From p.dalgaard at biostat.ku.dk  Wed Sep 15 23:05:38 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 15 Sep 2004 23:05:38 +0200
Subject: [R] Splitting vector into individual elements
In-Reply-To: <Pine.OSF.4.58.0409151433320.393815@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0409151433320.393815@odin.mdacc.tmc.edu>
Message-ID: <x2d60n6y59.fsf@biostat.ku.dk>

Paul Roebuck <roebuck at odin.mdacc.tmc.edu> writes:

> Is there a means to split a vector into its individual
> elements without going the brute-force route for arguments
> to a predefined function call?
> 
>     offred.rgb <- c(1, 0, 0) * 0.60;
> 
>     ## Brute force style
>     offred.col <- rgb(offred.rgb[1],
>                       offred.rgb[2],
>                       offred.rgb[3],
>                       names = "offred")
>     ## Desired style
>     offred.col <- rgb(silver.bullet(offred.rgb),
>                       names = "offred")

The closest is probably this:

offred.col <- do.call("rgb", c(as.list(offred.rgb), 
                               list(names="offred")))

(ever read/seen The Handmaid's Tale, btw?)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rxg218 at psu.edu  Wed Sep 15 23:10:54 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Wed, 15 Sep 2004 17:10:54 -0400
Subject: [R] efficient submatrix extraction
Message-ID: <1095282653.7884.6.camel@blue.chem.psu.edu>

Hi,
  I have a matrix of say 1024x1024 and I want to look at it in chunks.
That is I'd like to divide into a series of submatrices of order 2x2.

| 1 2 3 4 5 6 7 8 ... |
| 1 2 3 4 5 6 7 8 ... |
| 1 2 3 4 5 6 7 8 ... |
| 1 2 3 4 5 6 7 8 ... |
...

So the first submatrix would be

| 1 2 |
| 1 2 |

the second one would be

| 3 4 |
| 3 4 |

and so on. That is I want the matrix to be evenly divided into 2x2
submatrices. Now I'm also doing this subdivision into 4x4, 8x8 ...
256x256 submatrices.

Currently I'm using loops and I'm sure there is a mroe efficient way to
do it:

    m <- matrix(runif(1024*1024), nrow=1024)
    boxsize <- 2^(1:8)

    for (b in boxsize) {
        bcount <- 0
        bstart <- seq(1,1024, by=b)
        for (x in bstart) {
            for (y in bstart) {
                xend <- x + b - 1
                yend <- y + b - 1
                if (length(which( m[ x:xend, y:yend ] > 0.7)) > 0) {
                    bcount <- bcount + 1
                }
            }
        }
    }

Is there any way to vectorize the two inner loops?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
The way to love anything is to realize that it might be lost.



From roebuck at odin.mdacc.tmc.edu  Wed Sep 15 23:30:17 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Wed, 15 Sep 2004 16:30:17 -0500 (CDT)
Subject: [R] Splitting vector into individual elements
In-Reply-To: <x2d60n6y59.fsf@biostat.ku.dk>
References: <Pine.OSF.4.58.0409151433320.393815@odin.mdacc.tmc.edu>
	<x2d60n6y59.fsf@biostat.ku.dk>
Message-ID: <Pine.OSF.4.58.0409151610040.399090@odin.mdacc.tmc.edu>

On Wed, 15 Sep 2004, Peter Dalgaard wrote:

> Paul Roebuck <roebuck at odin.mdacc.tmc.edu> writes:
>
> > Is there a means to split a vector into its individual
> > elements without going the brute-force route for arguments
> > to a predefined function call?
> >
> >     offred.rgb <- c(1, 0, 0) * 0.60;
> >
> >     ## Brute force style
> >     offred.col <- rgb(offred.rgb[1],
> >                       offred.rgb[2],
> >                       offred.rgb[3],
> >                       names = "offred")
> >     ## Desired style
> >     offred.col <- rgb(silver.bullet(offred.rgb),
> >                       names = "offred")
>
> The closest is probably this:
>
> offred.col <- do.call("rgb", c(as.list(offred.rgb),
>                                list(names="offred")))
>

Everyone offered 'do.call' as the solution. While that
works, is it to say that there is no means of expanding
the expression as an argument to the original function?

> (ever read/seen The Handmaid's Tale, btw?)
>

Not yet. Though renaming my sample variable 'off.red.col'
would avoid future confusion with oppressed handmaids.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From tplate at blackmesacapital.com  Wed Sep 15 23:33:27 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Wed, 15 Sep 2004 15:33:27 -0600
Subject: [R] efficient submatrix extraction
In-Reply-To: <1095282653.7884.6.camel@blue.chem.psu.edu>
References: <1095282653.7884.6.camel@blue.chem.psu.edu>
Message-ID: <6.1.0.6.2.20040915152745.05b11258@mailhost.blackmesacapital.com>

I think you should be able to do something with reassigning the "dim" 
attribute, and then using apply(), something along the lines of the 
following (which doesn't do your computation on the data in the subarrays, 
but merely illustrates how to create and access them):

 > x <- matrix(1:64,ncol=8)
 > x
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
[1,]    1    9   17   25   33   41   49   57
[2,]    2   10   18   26   34   42   50   58
[3,]    3   11   19   27   35   43   51   59
[4,]    4   12   20   28   36   44   52   60
[5,]    5   13   21   29   37   45   53   61
[6,]    6   14   22   30   38   46   54   62
[7,]    7   15   23   31   39   47   55   63
[8,]    8   16   24   32   40   48   56   64
 > x2 <- x
 > dim(x2) <- c(2,4,2,4)
 > x2[,1,,1]
      [,1] [,2]
[1,]    1    9
[2,]    2   10
 > x2[,2,,1]
      [,1] [,2]
[1,]    3   11
[2,]    4   12
 > x2[,1,,2]
      [,1] [,2]
[1,]   17   25
[2,]   18   26
 > x4 <- x
 > dim(x4) <- c(4,2,4,2)
 > x4[,1,,1]
      [,1] [,2] [,3] [,4]
[1,]    1    9   17   25
[2,]    2   10   18   26
[3,]    3   11   19   27
[4,]    4   12   20   28
 > invisible(apply(x4, c(2,4), print))
      [,1] [,2] [,3] [,4]
[1,]    1    9   17   25
[2,]    2   10   18   26
[3,]    3   11   19   27
[4,]    4   12   20   28
      [,1] [,2] [,3] [,4]
[1,]    5   13   21   29
[2,]    6   14   22   30
[3,]    7   15   23   31
[4,]    8   16   24   32
      [,1] [,2] [,3] [,4]
[1,]   33   41   49   57
[2,]   34   42   50   58
[3,]   35   43   51   59
[4,]   36   44   52   60
      [,1] [,2] [,3] [,4]
[1,]   37   45   53   61
[2,]   38   46   54   62
[3,]   39   47   55   63
[4,]   40   48   56   64
 >

hope this helps,

Tony Plate

At Wednesday 03:10 PM 9/15/2004, Rajarshi Guha wrote:
>Hi,
>   I have a matrix of say 1024x1024 and I want to look at it in chunks.
>That is I'd like to divide into a series of submatrices of order 2x2.
>
>| 1 2 3 4 5 6 7 8 ... |
>| 1 2 3 4 5 6 7 8 ... |
>| 1 2 3 4 5 6 7 8 ... |
>| 1 2 3 4 5 6 7 8 ... |
>...
>
>So the first submatrix would be
>
>| 1 2 |
>| 1 2 |
>
>the second one would be
>
>| 3 4 |
>| 3 4 |
>
>and so on. That is I want the matrix to be evenly divided into 2x2
>submatrices. Now I'm also doing this subdivision into 4x4, 8x8 ...
>256x256 submatrices.
>
>Currently I'm using loops and I'm sure there is a mroe efficient way to
>do it:
>
>     m <- matrix(runif(1024*1024), nrow=1024)
>     boxsize <- 2^(1:8)
>
>     for (b in boxsize) {
>         bcount <- 0
>         bstart <- seq(1,1024, by=b)
>         for (x in bstart) {
>             for (y in bstart) {
>                 xend <- x + b - 1
>                 yend <- y + b - 1
>                 if (length(which( m[ x:xend, y:yend ] > 0.7)) > 0) {
>                     bcount <- bcount + 1
>                 }
>             }
>         }
>     }
>
>Is there any way to vectorize the two inner loops?
>
>Thanks,
>
>-------------------------------------------------------------------
>Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
>GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
>-------------------------------------------------------------------
>The way to love anything is to realize that it might be lost.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Wed Sep 15 23:46:56 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 15 Sep 2004 17:46:56 -0400
Subject: [R] Splitting vector into individual elements
Message-ID: <3A822319EB35174CA3714066D590DCD504AF83CB@usrymx25.merck.com>

> From: Paul Roebuck
> 
> On Wed, 15 Sep 2004, Peter Dalgaard wrote:
> 
> > Paul Roebuck <roebuck at odin.mdacc.tmc.edu> writes:
> >
> > > Is there a means to split a vector into its individual
> > > elements without going the brute-force route for arguments
> > > to a predefined function call?
> > >
> > >     offred.rgb <- c(1, 0, 0) * 0.60;
> > >
> > >     ## Brute force style
> > >     offred.col <- rgb(offred.rgb[1],
> > >                       offred.rgb[2],
> > >                       offred.rgb[3],
> > >                       names = "offred")
> > >     ## Desired style
> > >     offred.col <- rgb(silver.bullet(offred.rgb),
> > >                       names = "offred")
> >
> > The closest is probably this:
> >
> > offred.col <- do.call("rgb", c(as.list(offred.rgb),
> >                                list(names="offred")))
> 
> Everyone offered 'do.call' as the solution. While that
> works, is it to say that there is no means of expanding
> the expression as an argument to the original function?

What would be the point?  That's what do.call() does for you internally.

Andy
 
> > (ever read/seen The Handmaid's Tale, btw?)
> >
> 
> Not yet. Though renaming my sample variable 'off.red.col'
> would avoid future confusion with oppressed handmaids.
> 
> ----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From p.dalgaard at biostat.ku.dk  Wed Sep 15 23:51:29 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 15 Sep 2004 23:51:29 +0200
Subject: [R] Splitting vector into individual elements
In-Reply-To: <Pine.OSF.4.58.0409151610040.399090@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0409151433320.393815@odin.mdacc.tmc.edu>
	<x2d60n6y59.fsf@biostat.ku.dk>
	<Pine.OSF.4.58.0409151610040.399090@odin.mdacc.tmc.edu>
Message-ID: <x24qlz6w0u.fsf@biostat.ku.dk>

Paul Roebuck <roebuck at odin.mdacc.tmc.edu> writes:

> Everyone offered 'do.call' as the solution. While that
> works, is it to say that there is no means of expanding
> the expression as an argument to the original function?

Not really. You need an explicit expansion of the argument to a list
somehow, and there's no silver bullet that can convert one function
argument to several. There are solutions without do.call, like

> offred.rgb <- c(1, 0, 0) * 0.60
> x <- quote(rgb(.,.,.,names="offred"))
> x[2:4] <- as.list(offred.rgb)
> eval(x)
   offred
"#990000"

but you might find it difficult to explain how it works a year later....


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From andy_liaw at merck.com  Wed Sep 15 23:54:18 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 15 Sep 2004 17:54:18 -0400
Subject: [R] Splitting vector into individual elements
Message-ID: <3A822319EB35174CA3714066D590DCD504AF83CC@usrymx25.merck.com>

> From: Liaw, Andy
> 
> > From: Paul Roebuck
> > 
> > On Wed, 15 Sep 2004, Peter Dalgaard wrote:
> > 
> > > Paul Roebuck <roebuck at odin.mdacc.tmc.edu> writes:
> > >
> > > > Is there a means to split a vector into its individual
> > > > elements without going the brute-force route for arguments
> > > > to a predefined function call?
> > > >
> > > >     offred.rgb <- c(1, 0, 0) * 0.60;
> > > >
> > > >     ## Brute force style
> > > >     offred.col <- rgb(offred.rgb[1],
> > > >                       offred.rgb[2],
> > > >                       offred.rgb[3],
> > > >                       names = "offred")
> > > >     ## Desired style
> > > >     offred.col <- rgb(silver.bullet(offred.rgb),
> > > >                       names = "offred")
> > >
> > > The closest is probably this:
> > >
> > > offred.col <- do.call("rgb", c(as.list(offred.rgb),
> > >                                list(names="offred")))
> > 
> > Everyone offered 'do.call' as the solution. While that
> > works, is it to say that there is no means of expanding
> > the expression as an argument to the original function?
> 
> What would be the point?  That's what do.call() does for you 
> internally.

Is this what you're after?

> toCall <- c(as.name("rgb"), as.list(offred.rgb), names="offred")
> toCall
[[1]]
rgb

[[2]]
[1] 0.6

[[3]]
[1] 0

[[4]]
[1] 0

$names
[1] "offred"

> toCall <- as.call(toCall)
> toCall
rgb(0.6, 0, 0, names = "offred")
> eval(toCall)
[1] "#990000"

Andy
 
> Andy
>  
> > > (ever read/seen The Handmaid's Tale, btw?)
> > >
> > 
> > Not yet. Though renaming my sample variable 'off.red.col'
> > would avoid future confusion with oppressed handmaids.
> > 
> > ----------------------------------------------------------
> > SIGSIG -- signature too long (core dumped)
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> --------------------------------------------------------------
> ----------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New Jersey, USA 08889), and/or its 
> affiliates (which may be known outside the United States as 
> Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
> Banyu) that may be confidential, proprietary copyrighted 
> and/or legally privileged. It is intended solely for the use 
> of the individual or entity named on this message.  If you 
> are not the intended recipient, and have received this 
> message in error, please notify us immediately by reply 
> e-mail and then delete it from your system.
> --------------------------------------------------------------
> ----------------
>



From d.scott at auckland.ac.nz  Thu Sep 16 00:00:26 2004
From: d.scott at auckland.ac.nz (David Scott)
Date: Thu, 16 Sep 2004 10:00:26 +1200 (NZST)
Subject: [R] Slightly off-topic --- distribution name.
In-Reply-To: <200409151828.i8FISWNP003653@erdos.math.unb.ca>
References: <200409151828.i8FISWNP003653@erdos.math.unb.ca>
Message-ID: <Pine.LNX.4.61.0409160958020.9095@hydra.stat.auckland.ac.nz>


I believe this is the skew-Laplace distribution, although the skew-Laplace 
does allow for the location of the mode of the distribution to vary.

Have a look at the function dskewlap in HyperbolicDist. The help on that 
function gives a reference to a paper by Feiller et al which describes the 
distribution.


David Scott




On Wed, 15 Sep 2004, Rolf Turner wrote:

>
> I've built R functions to ``effect'' a particular distribution, and
> would like to find out if that distribution is already ``known'' by
> an existing name.  (I.e. suppose it were called the ``Melvin''
> distribution --- I've built dmelvin, pmelvin, qmelvin, and rmelvin as
> it were, but I need a real name to substitute for melvin.)
>
> The distribution is really just a toy --- but it provides a nice (and
> ``non-obviouse'') example of a two parameter distribution where both
> the moment and maximum likelihood equations for the parameter
> estimators are readily solvable, but at the same time are
> ``interesting''.  So it's good for exercises in an intro math-stats
> course.
>
> The distribution is simply that of the ***difference*** of two
> independent exponential variates, with different parameters.
>
> I.e.  X = U - V  where U ~ exp(beta) and V ~ exp(alpha) (where
> E(U) = beta, E(V) = alpha).
>
> This makes the distribution of X something like an asymetric Laplace
> distribution, with its mode at 0.  (One could shift the mode too, but
> that would add a third parameter, which would be de trop.)
>
> Anyhow:  Is this a ``known'' distribution?  Does it have a name?
> (I've never seen it mentioned in any of the intro math-stat books
> that I've looked into.) If not, can anyone suggest a good name for
> it?  (Don't be rude now!)
>
> 				cheers,
>
> 					Rolf Turner
> 					rolf at math.unb.ca
>
> P. S.  To save you putting pen to paper and working it out,
>       the density function is
>
>               { exp(x/alpha)/(alpha + beta) for x <= 0
> 	f(x) = {
>               { exp(-x/beta)/(alpha + beta) for x >= 0
>
>       The mean and variance are mu = beta - alpha and
>       sigma^2 = alpha^2 + beta^2 respectfully. :-)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
 		The University of Auckland, PB 92019
 		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz


Graduate Officer, Department of Statistics



From ggrothendieck at myway.com  Thu Sep 16 00:10:20 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 15 Sep 2004 22:10:20 +0000 (UTC)
Subject: [R] Splitting vector into individual elements
References: <Pine.OSF.4.58.0409151433320.393815@odin.mdacc.tmc.edu>
	<x2d60n6y59.fsf@biostat.ku.dk>
	<Pine.OSF.4.58.0409151610040.399090@odin.mdacc.tmc.edu>
Message-ID: <loom.20040916T000641-722@post.gmane.org>

Paul Roebuck <roebuck <at> odin.mdacc.tmc.edu> writes:

: 
: On Wed, 15 Sep 2004, Peter Dalgaard wrote:
: 
: > Paul Roebuck <roebuck <at> odin.mdacc.tmc.edu> writes:
: >
: > > Is there a means to split a vector into its individual
: > > elements without going the brute-force route for arguments
: > > to a predefined function call?
: > >
: > >     offred.rgb <- c(1, 0, 0) * 0.60;
: > >
: > >     ## Brute force style
: > >     offred.col <- rgb(offred.rgb[1],
: > >                       offred.rgb[2],
: > >                       offred.rgb[3],
: > >                       names = "offred")
: > >     ## Desired style
: > >     offred.col <- rgb(silver.bullet(offred.rgb),
: > >                       names = "offred")
: >
: > The closest is probably this:
: >
: > offred.col <- do.call("rgb", c(as.list(offred.rgb),
: >                                list(names="offred")))
: >
: 
: Everyone offered 'do.call' as the solution. While that
: works, is it to say that there is no means of expanding
: the expression as an argument to the original function?

This is not a true answer to the question of expanding a list
into arguments without using do.call but it does allow you to 
carry out either syntax in this particular case using S3
dispatch:

R> silver.bullet <- as.list
R> rgb <- function(x, ...) UseMethod("rgb")
R> rgb.list <- function(x, ...) rgb(x[[1]],x[[2]],x[[3]],...)
R> rgb.default <- graphics::rgb

R> offred.rgb <- c(1, 0, 0) * 0.60;
R> # original syntax
R> rgb(offred.rgb[1], offred.rgb[2], offred.rgb[3], names = "offred")
   offred 
"#990000" 
R> # list syntax
R> rgb(silver.bullet(offred.rgb), names = "offred")
   offred 
"#990000"



From spencer.graves at pdf.com  Thu Sep 16 00:05:59 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 15 Sep 2004 15:05:59 -0700
Subject: [R] Splitting vector into individual elements
In-Reply-To: <x24qlz6w0u.fsf@biostat.ku.dk>
References: <Pine.OSF.4.58.0409151433320.393815@odin.mdacc.tmc.edu>	<x2d60n6y59.fsf@biostat.ku.dk>	<Pine.OSF.4.58.0409151610040.399090@odin.mdacc.tmc.edu>
	<x24qlz6w0u.fsf@biostat.ku.dk>
Message-ID: <4148BCC7.7030402@pdf.com>

Slightly more transparent but arguably uglier: 

 > offred.rgb <- c(1, 0, 0) * 0.60
 > ofr <- paste(offred.rgb, collapse=",")
 > ofr. <- paste("rgb(", ofr, ',names="offred")')
 > ofr.
[1] "rgb( 0.6,0,0 ,names=\"offred\")"
 > eval(parse(text=ofr.))
   offred
"#990000"
 >
      As long as I can remember "eval(parse(text=", this is for me the 
most transparent and works for constructing virtually any R command. 
 
      hope this helps.  spencer graves

Peter Dalgaard wrote:

>Paul Roebuck <roebuck at odin.mdacc.tmc.edu> writes:
>
>  
>
>>Everyone offered 'do.call' as the solution. While that
>>works, is it to say that there is no means of expanding
>>the expression as an argument to the original function?
>>    
>>
>
>Not really. You need an explicit expansion of the argument to a list
>somehow, and there's no silver bullet that can convert one function
>argument to several. There are solutions without do.call, like
>
>  
>
>>offred.rgb <- c(1, 0, 0) * 0.60
>>x <- quote(rgb(.,.,.,names="offred"))
>>x[2:4] <- as.list(offred.rgb)
>>eval(x)
>>    
>>
>   offred
>"#990000"
>
>but you might find it difficult to explain how it works a year later....
>
>
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From fchamu at gmail.com  Thu Sep 16 01:07:01 2004
From: fchamu at gmail.com (Francisco Chamu)
Date: Wed, 15 Sep 2004 19:07:01 -0400
Subject: [R] Signs of loadings from princomp on Windows
In-Reply-To: <6.1.0.6.2.20040914105042.05a86cb0@mailhost.blackmesacapital.com>
References: <ce17a70f0409140918408afa9e@mail.gmail.com>
	<Pine.LNX.4.44.0409141723310.13336-100000@gannet.stats>
	<6.1.0.6.2.20040914105042.05a86cb0@mailhost.blackmesacapital.com>
Message-ID: <ce17a70f04091516073d5e12ef@mail.gmail.com>

I am sorry to insist, but we have three other people that were able to
reproduce the behavior I mentioned.  I have also installed R 1.9.1
from the CRAN binaries on a different Windows machine and again I see
the differents signs as mentioned before.  What would be causing the
difference?

-Francisco


On Tue, 14 Sep 2004 11:04:29 -0600, Tony Plate
<tplate at blackmesacapital.com> wrote:
> FWIW, I see the same behavior as Francisco on my Windows machine (also an
> installation of the windows binary without trying to install any special
> BLAS libraries):
> 
>  > library(MASS)
>  > data(painters)
>  > pca.painters <- princomp(painters[ ,1:4])
>  > loadings(pca.painters)
> 
> Loadings:
>              Comp.1 Comp.2 Comp.3 Comp.4
> Composition  0.484 -0.376  0.784 -0.101
> Drawing      0.424  0.187 -0.280 -0.841
> Colour      -0.381 -0.845 -0.211 -0.310
> Expression   0.664 -0.330 -0.513  0.432
> 
>                 Comp.1 Comp.2 Comp.3 Comp.4
> SS loadings      1.00   1.00   1.00   1.00
> Proportion Var   0.25   0.25   0.25   0.25
> Cumulative Var   0.25   0.50   0.75   1.00
>  > pca.painters <- princomp(painters[ ,1:4])
>  > loadings(pca.painters)
> 
> Loadings:
>              Comp.1 Comp.2 Comp.3 Comp.4
> Composition -0.484 -0.376  0.784 -0.101
> Drawing     -0.424  0.187 -0.280 -0.841
> Colour       0.381 -0.845 -0.211 -0.310
> Expression  -0.664 -0.330 -0.513  0.432
> 
>                 Comp.1 Comp.2 Comp.3 Comp.4
> SS loadings      1.00   1.00   1.00   1.00
> Proportion Var   0.25   0.25   0.25   0.25
> Cumulative Var   0.25   0.50   0.75   1.00
>  > R.version
>           _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R
>  >
> 
> My machine is a dual-processor hp xw8000.
> 
> I also get the same results with R 2.0.0 dev as in
>  > R.version
>           _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status   Under development (unstable)
> major    2
> minor    0.0
> year     2004
> month    09
> day      13
> language R
>  >
> 
> -- Tony Plate
> 
> 
> 
> At Tuesday 10:25 AM 9/14/2004, Prof Brian Ripley wrote:
> >On Tue, 14 Sep 2004, Francisco Chamu wrote:
> >
> > > I have run this on both Windows 2000 and XP.  All I did was install
> > > the binaries from CRAN so I think I am using the standard Rblas.dll.
> > >
> > > To reproduce what I see you must run the code at the beginning of the
> > > R session.
> >
> >We did, as you said `start a clean session'.
> >
> >I think to reproduce what you see we have to be using your account on your
> >computer.
> >
> > > After the second run, all subsequent runs give the same
> > > result as the second set.
> > >
> > > Thanks,
> > > Francisco
> > >
> > >
> > > On Tue, 14 Sep 2004 08:29:25 +0200, Uwe Ligges
> > > <ligges at statistik.uni-dortmund.de> wrote:
> > > > Prof Brian Ripley wrote:
> > > > > I get the second set each time, on Windows, using the build from CRAN.
> > > > > Which BLAS are you using?
> > > >
> > > >
> > > > Works also well for me with a self compiled R-1.9.1 (both with standard
> > > > Rblas as well as with the Rblas.dll for Athlon CPU from CRAN).
> > > > Is this a NT-based version of Windows (NT, 2k, XP)?
> > > >
> > > > Uwe
> > > >
> > > >
> > > >
> > > >
> > > > > On Tue, 14 Sep 2004, Francisco Chamu wrote:
> > > > >
> > > > >
> > > > >>I start a clean session of R 1.9.1 on Windows and I run the
> > following code:
> > > > >>
> > > > >>
> > > > >>>library(MASS)
> > > > >>>data(painters)
> > > > >>>pca.painters <- princomp(painters[ ,1:4])
> > > > >>>loadings(pca.painters)
> > > > >>
> > > > >>Loadings:
> > > > >>            Comp.1 Comp.2 Comp.3 Comp.4
> > > > >>Composition  0.484 -0.376  0.784 -0.101
> > > > >>Drawing      0.424  0.187 -0.280 -0.841
> > > > >>Colour      -0.381 -0.845 -0.211 -0.310
> > > > >>Expression   0.664 -0.330 -0.513  0.432
> > > > >>
> > > > >>               Comp.1 Comp.2 Comp.3 Comp.4
> > > > >>SS loadings      1.00   1.00   1.00   1.00
> > > > >>Proportion Var   0.25   0.25   0.25   0.25
> > > > >>Cumulative Var   0.25   0.50   0.75   1.00
> > > > >>
> > > > >>However, if I rerun the same analysis, the loadings of the first
> > > > >>component have the opposite sign (see below), why is that?  I have
> > > > >>read the note
> > > > >>in the princomp help that says
> > > > >>
> > > > >>    "The signs of the columns of the loadings and scores are arbitrary,
> > > > >>     and so may differ between different programs for PCA, and even
> > > > >>     between different builds of R."
> > > > >>
> > > > >>However, I still would expect the same signs for two runs in the
> > same session.
> > > > >>
> > > > >>
> > > > >>>pca.painters <- princomp(painters[ ,1:4])
> > > > >>>loadings(pca.painters)
> > > > >>
> > > > >>Loadings:
> > > > >>            Comp.1 Comp.2 Comp.3 Comp.4
> > > > >>Composition -0.484 -0.376  0.784 -0.101
> > > > >>Drawing     -0.424  0.187 -0.280 -0.841
> > > > >>Colour       0.381 -0.845 -0.211 -0.310
> > > > >>Expression  -0.664 -0.330 -0.513  0.432
> > > > >>
> > > > >>               Comp.1 Comp.2 Comp.3 Comp.4
> > > > >>SS loadings      1.00   1.00   1.00   1.00
> > > > >>Proportion Var   0.25   0.25   0.25   0.25
> > > > >>Cumulative Var   0.25   0.50   0.75   1.00
> > > > >>
> > > > >>>R.version
> > > > >>
> > > > >>         _
> > > > >>platform i386-pc-mingw32
> > > > >>arch     i386
> > > > >>os       mingw32
> > > > >>system   i386, mingw32
> > > > >>status
> > > > >>major    1
> > > > >>minor    9.1
> > > > >>year     2004
> > > > >>month    06
> > > > >>day      21
> > > > >>language R
> > > > >>
> > > > >>BTW, I have tried the same in R 1.9.1 on Debian and I can't reproduce
> > > > >>what I see
> > > > >>on Windows.  In fact all the runs give the same as the second run
> > on Windows.
> > > > >>
> > > > >>-Francisco
> > > > >>
> > > > >>______________________________________________
> > > > >>R-help at stat.math.ethz.ch mailing list
> > > > >>https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >>PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > > > >>
> > > > >>
> > > > >
> > > > >
> > > >
> > > >
> > >
> > >
> >
> >--
> >Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >University of Oxford,             Tel:  +44 1865 272861 (self)
> >1 South Parks Road,                     +44 1865 272866 (PA)
> >Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >______________________________________________
> 
> 
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From yshao at wadsworth.org  Thu Sep 16 01:28:35 2004
From: yshao at wadsworth.org (Yu Shao)
Date: Wed, 15 Sep 2004 19:28:35 -0400 (EDT)
Subject: [R] Cross-validation for Linear Discrimitant Analysis
Message-ID: <Pine.GSO.4.58.0409151904070.18329@bioquad>

Hello:

I am new to R and statistics and I have two questions.

First I need help to interpret the cross-validation result from the R
linear discriminant analysis function "lda". I did the following:

lda (group ~ Var1 + Var2, CV=T)

where "CV=T" tells the lda to do cross-validation. The output of lda are
the posterior probabilities among other things, but I can't find an error
term (like delta returned by cv.glm). My question is how to get such an
error term from the output? Can I just simply calculate the prediction
accuracy using the posterior probabilities from the cross-validation, and
use that to measure the quality of the model?

Another question is more basic: how to determine if a lda model is
significant? (There is no p-value.) Thanks,

Yu Shao

Wadsworth Research Center
Department of Health of New York State
Albany, NY 12208



From tplate at blackmesacapital.com  Thu Sep 16 01:38:11 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Wed, 15 Sep 2004 17:38:11 -0600
Subject: [R] Signs of loadings from princomp on Windows
In-Reply-To: <ce17a70f04091516073d5e12ef@mail.gmail.com>
References: <ce17a70f0409140918408afa9e@mail.gmail.com>
	<Pine.LNX.4.44.0409141723310.13336-100000@gannet.stats>
	<6.1.0.6.2.20040914105042.05a86cb0@mailhost.blackmesacapital.com>
	<ce17a70f04091516073d5e12ef@mail.gmail.com>
Message-ID: <6.1.0.6.2.20040915173048.05b0e810@mailhost.blackmesacapital.com>

You could investigate this yourself by looking at the code of princomp (try 
getAnywhere("princomp.default")).  I'd suggest making a file that in-lines 
the body of princomp.default into the commands you had below.  See if you 
still get the difference.  (I'd be surprised if you didn't).  Then try 
commenting out lines the second pass through the commands produces the same 
results as the first.  The very last thing you commented out might help to 
answer your question "What would be causing the
difference?"  (The fact that various people chimed in to say they could 
reproduce the behavior that bothered you, but didn't bother dig deeper 
suggests it didn't bother them that much, which further suggests that you 
are the person most motivated by this and thus the best candidate for 
investigating it further...)

-- Tony Plate

At Wednesday 05:07 PM 9/15/2004, Francisco Chamu wrote:
>I am sorry to insist, but we have three other people that were able to
>reproduce the behavior I mentioned.  I have also installed R 1.9.1
>from the CRAN binaries on a different Windows machine and again I see
>the differents signs as mentioned before.  What would be causing the
>difference?
>
>-Francisco
>
>
>On Tue, 14 Sep 2004 11:04:29 -0600, Tony Plate
><tplate at blackmesacapital.com> wrote:
> > FWIW, I see the same behavior as Francisco on my Windows machine (also an
> > installation of the windows binary without trying to install any special
> > BLAS libraries):
> >
> >  > library(MASS)
> >  > data(painters)
> >  > pca.painters <- princomp(painters[ ,1:4])
> >  > loadings(pca.painters)
> >
> > Loadings:
> >              Comp.1 Comp.2 Comp.3 Comp.4
> > Composition  0.484 -0.376  0.784 -0.101
> > Drawing      0.424  0.187 -0.280 -0.841
> > Colour      -0.381 -0.845 -0.211 -0.310
> > Expression   0.664 -0.330 -0.513  0.432
> >
> >                 Comp.1 Comp.2 Comp.3 Comp.4
> > SS loadings      1.00   1.00   1.00   1.00
> > Proportion Var   0.25   0.25   0.25   0.25
> > Cumulative Var   0.25   0.50   0.75   1.00
> >  > pca.painters <- princomp(painters[ ,1:4])
> >  > loadings(pca.painters)
> >
> > Loadings:
> >              Comp.1 Comp.2 Comp.3 Comp.4
> > Composition -0.484 -0.376  0.784 -0.101
> > Drawing     -0.424  0.187 -0.280 -0.841
> > Colour       0.381 -0.845 -0.211 -0.310
> > Expression  -0.664 -0.330 -0.513  0.432
> >
> >                 Comp.1 Comp.2 Comp.3 Comp.4
> > SS loadings      1.00   1.00   1.00   1.00
> > Proportion Var   0.25   0.25   0.25   0.25
> > Cumulative Var   0.25   0.50   0.75   1.00
> >  > R.version
> >           _
> > platform i386-pc-mingw32
> > arch     i386
> > os       mingw32
> > system   i386, mingw32
> > status
> > major    1
> > minor    9.1
> > year     2004
> > month    06
> > day      21
> > language R
> >  >
> >
> > My machine is a dual-processor hp xw8000.
> >
> > I also get the same results with R 2.0.0 dev as in
> >  > R.version
> >           _
> > platform i386-pc-mingw32
> > arch     i386
> > os       mingw32
> > system   i386, mingw32
> > status   Under development (unstable)
> > major    2
> > minor    0.0
> > year     2004
> > month    09
> > day      13
> > language R
> >  >
> >
> > -- Tony Plate
> >
> >
> >
> > At Tuesday 10:25 AM 9/14/2004, Prof Brian Ripley wrote:
> > >On Tue, 14 Sep 2004, Francisco Chamu wrote:
> > >
> > > > I have run this on both Windows 2000 and XP.  All I did was install
> > > > the binaries from CRAN so I think I am using the standard Rblas.dll.
> > > >
> > > > To reproduce what I see you must run the code at the beginning of the
> > > > R session.
> > >
> > >We did, as you said `start a clean session'.
> > >
> > >I think to reproduce what you see we have to be using your account on your
> > >computer.
> > >
> > > > After the second run, all subsequent runs give the same
> > > > result as the second set.
> > > >
> > > > Thanks,
> > > > Francisco
> > > >
> > > >
> > > > On Tue, 14 Sep 2004 08:29:25 +0200, Uwe Ligges
> > > > <ligges at statistik.uni-dortmund.de> wrote:
> > > > > Prof Brian Ripley wrote:
> > > > > > I get the second set each time, on Windows, using the build 
> from CRAN.
> > > > > > Which BLAS are you using?
> > > > >
> > > > >
> > > > > Works also well for me with a self compiled R-1.9.1 (both with 
> standard
> > > > > Rblas as well as with the Rblas.dll for Athlon CPU from CRAN).
> > > > > Is this a NT-based version of Windows (NT, 2k, XP)?
> > > > >
> > > > > Uwe
> > > > >
> > > > >
> > > > >
> > > > >
> > > > > > On Tue, 14 Sep 2004, Francisco Chamu wrote:
> > > > > >
> > > > > >
> > > > > >>I start a clean session of R 1.9.1 on Windows and I run the
> > > following code:
> > > > > >>
> > > > > >>
> > > > > >>>library(MASS)
> > > > > >>>data(painters)
> > > > > >>>pca.painters <- princomp(painters[ ,1:4])
> > > > > >>>loadings(pca.painters)
> > > > > >>
> > > > > >>Loadings:
> > > > > >>            Comp.1 Comp.2 Comp.3 Comp.4
> > > > > >>Composition  0.484 -0.376  0.784 -0.101
> > > > > >>Drawing      0.424  0.187 -0.280 -0.841
> > > > > >>Colour      -0.381 -0.845 -0.211 -0.310
> > > > > >>Expression   0.664 -0.330 -0.513  0.432
> > > > > >>
> > > > > >>               Comp.1 Comp.2 Comp.3 Comp.4
> > > > > >>SS loadings      1.00   1.00   1.00   1.00
> > > > > >>Proportion Var   0.25   0.25   0.25   0.25
> > > > > >>Cumulative Var   0.25   0.50   0.75   1.00
> > > > > >>
> > > > > >>However, if I rerun the same analysis, the loadings of the first
> > > > > >>component have the opposite sign (see below), why is that?  I have
> > > > > >>read the note
> > > > > >>in the princomp help that says
> > > > > >>
> > > > > >>    "The signs of the columns of the loadings and scores are 
> arbitrary,
> > > > > >>     and so may differ between different programs for PCA, and even
> > > > > >>     between different builds of R."
> > > > > >>
> > > > > >>However, I still would expect the same signs for two runs in the
> > > same session.
> > > > > >>
> > > > > >>
> > > > > >>>pca.painters <- princomp(painters[ ,1:4])
> > > > > >>>loadings(pca.painters)
> > > > > >>
> > > > > >>Loadings:
> > > > > >>            Comp.1 Comp.2 Comp.3 Comp.4
> > > > > >>Composition -0.484 -0.376  0.784 -0.101
> > > > > >>Drawing     -0.424  0.187 -0.280 -0.841
> > > > > >>Colour       0.381 -0.845 -0.211 -0.310
> > > > > >>Expression  -0.664 -0.330 -0.513  0.432
> > > > > >>
> > > > > >>               Comp.1 Comp.2 Comp.3 Comp.4
> > > > > >>SS loadings      1.00   1.00   1.00   1.00
> > > > > >>Proportion Var   0.25   0.25   0.25   0.25
> > > > > >>Cumulative Var   0.25   0.50   0.75   1.00
> > > > > >>
> > > > > >>>R.version
> > > > > >>
> > > > > >>         _
> > > > > >>platform i386-pc-mingw32
> > > > > >>arch     i386
> > > > > >>os       mingw32
> > > > > >>system   i386, mingw32
> > > > > >>status
> > > > > >>major    1
> > > > > >>minor    9.1
> > > > > >>year     2004
> > > > > >>month    06
> > > > > >>day      21
> > > > > >>language R
> > > > > >>
> > > > > >>BTW, I have tried the same in R 1.9.1 on Debian and I can't 
> reproduce
> > > > > >>what I see
> > > > > >>on Windows.  In fact all the runs give the same as the second run
> > > on Windows.
> > > > > >>
> > > > > >>-Francisco
> > > > > >>
> > > > > >>______________________________________________
> > > > > >>R-help at stat.math.ethz.ch mailing list
> > > > > >>https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > >>PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > > > > >>
> > > > > >>
> > > > > >
> > > > > >
> > > > >
> > > > >
> > > >
> > > >
> > >
> > >--
> > >Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > >Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > >University of Oxford,             Tel:  +44 1865 272861 (self)
> > >1 South Parks Road,                     +44 1865 272866 (PA)
> > >Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > >
> > >______________________________________________
> >
> >
> > >R-help at stat.math.ethz.ch mailing list
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> >
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sean_incali at yahoo.com  Thu Sep 16 02:19:41 2004
From: sean_incali at yahoo.com (sean kim)
Date: Wed, 15 Sep 2004 17:19:41 -0700 (PDT)
Subject: [R] Newbie q.  need some help understanding this code.
Message-ID: <20040916001941.49302.qmail@web60503.mail.yahoo.com>

dear all. 

Would someone be kind and willing to explain the code
below for a person who has never used R?  ( that is if
one has enough time and inclination) 

It implements gillepsie's stochastic algorithm for
Lotka Volterra model. 

What would help me tremendously is to see the
breakdown of the line by line code into plain english.


thanks for any insights or other comments. 

sean 



library(stepfun)

lv <- function(N=1000,cvec=c(1,0.005,0.6),x=c(50,100))
{
        m<-length(cvec)
        n<-length(x)
        xmat<-matrix(nrow=N+1,ncol=n)
        tvec<-vector("numeric",N)
        h<-vector("numeric",m)
        t<-0
        xmat[1,]<-x
        for (i in 1:N) {
                h[1]<-cvec[1]*x[1]
                h[2]<-cvec[2]*x[1]*x[2]
                h[3]<-cvec[3]*x[2]
                h0=sum(h)
                tp<-rexp(1,h0)
                t<-t+tp
                u<-runif(1,0,1)
                if ( u < h[1]/h0 ) {
                        x[1] <- x[1]+1
                } else if ( u < (h[1]+h[2])/h0 ) {
                        x[1] <- x[1]-1
                        x[2] <- x[2]+1
                } else {
                        x[2] <- x[2]-1
                }
                xmat[i+1,]<-x
                tvec[i]<-t
        }
       
list(stepfun(tvec,xmat[,1]),stepfun(tvec,xmat[,2]))
}



results <- lv(N=10000)


op<-par(mfrow=c(2,1))
plot(results[[1]],do.points=True)
plot(results[[2]],do.points=False)
par(op)



From Kevin.Wang at maths.anu.edu.au  Thu Sep 16 02:34:49 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Thu, 16 Sep 2004 10:34:49 +1000
Subject: [R] Newbie q.  need some help understanding this code.
In-Reply-To: <20040916001941.49302.qmail@web60503.mail.yahoo.com>
References: <20040916001941.49302.qmail@web60503.mail.yahoo.com>
Message-ID: <4148DFA9.4090909@maths.anu.edu.au>

Hi,

sean kim wrote:

> thanks for any insights or other comments. 

I would suggest that you run the code line by line, to see what it does 
yourself.  It is the best way to learn!

> library(stepfun)

This just loads the package "stepfun".

> lv <- function(N=1000,cvec=c(1,0.005,0.6),x=c(50,100))
> {

Declaration of a function named lv, where N, cvec and x are the 
parameters/arguments with default values.

>         m<-length(cvec)

m is a new variable, with in this case is just a number, the length of 
the vector cvec.  In this case, 3.

>         n<-length(x)

Ditto.

>         xmat<-matrix(nrow=N+1,ncol=n)

Generate a matrix with N + 1 (1001) rows and  n columns.

>         tvec<-vector("numeric",N)
>         h<-vector("numeric",m)

Generating two vectors.

>         t<-0
>         xmat[1,]<-x

Assign x to the first row of the xmat matrix.

>         for (i in 1:N) {
>                 h[1]<-cvec[1]*x[1]

The first element in cvec and x, multiply them together and the result 
becomes the first element of h.

>                 h[2]<-cvec[2]*x[1]*x[2]
>                 h[3]<-cvec[3]*x[2]

Ditto.

>                 h0=sum(h)

Get the sum of h.

>                 tp<-rexp(1,h0)

Generating an exponential random number with a rate of h0.

>                 t<-t+tp
>                 u<-runif(1,0,1)

Generating a uniform random number, [0, 1]

>                 if ( u < h[1]/h0 ) {
>                         x[1] <- x[1]+1

If the uniform random number, u, is smaller than h[1]/h0 then do...

otherwise do the following...

>                 } else if ( u < (h[1]+h[2])/h0 ) {
>                         x[1] <- x[1]-1
>                         x[2] <- x[2]+1
>                 } else {
>                         x[2] <- x[2]-1
>                 }
>                 xmat[i+1,]<-x

Increment to the next row.

>                 tvec[i]<-t
>         }
>        
> list(stepfun(tvec,xmat[,1]),stepfun(tvec,xmat[,2]))
> }

Put things together into a list.

Again, check these line by line and you'll have a better understanding!

Kev


-- 
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From ggrothendieck at myway.com  Thu Sep 16 03:16:51 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 16 Sep 2004 01:16:51 +0000 (UTC)
Subject: [R] Splitting vector into individual elements
References: <Pine.OSF.4.58.0409151433320.393815@odin.mdacc.tmc.edu>
	<x2d60n6y59.fsf@biostat.ku.dk>
	<Pine.OSF.4.58.0409151610040.399090@odin.mdacc.tmc.edu>
	<loom.20040916T000641-722@post.gmane.org>
Message-ID: <loom.20040916T031457-252@post.gmane.org>

Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

: 
: Paul Roebuck <roebuck <at> odin.mdacc.tmc.edu> writes:
: 
: : 
: : On Wed, 15 Sep 2004, Peter Dalgaard wrote:
: : 
: : > Paul Roebuck <roebuck <at> odin.mdacc.tmc.edu> writes:
: : >
: : > > Is there a means to split a vector into its individual
: : > > elements without going the brute-force route for arguments
: : > > to a predefined function call?
: : > >
: : > >     offred.rgb <- c(1, 0, 0) * 0.60;
: : > >
: : > >     ## Brute force style
: : > >     offred.col <- rgb(offred.rgb[1],
: : > >                       offred.rgb[2],
: : > >                       offred.rgb[3],
: : > >                       names = "offred")
: : > >     ## Desired style
: : > >     offred.col <- rgb(silver.bullet(offred.rgb),
: : > >                       names = "offred")
: : >
: : > The closest is probably this:
: : >
: : > offred.col <- do.call("rgb", c(as.list(offred.rgb),
: : >                                list(names="offred")))
: : >
: : 
: : Everyone offered 'do.call' as the solution. While that
: : works, is it to say that there is no means of expanding
: : the expression as an argument to the original function?
: 
: This is not a true answer to the question of expanding a list
: into arguments without using do.call but it does allow you to 
: carry out either syntax in this particular case using S3
: dispatch:
: 
: R> silver.bullet <- as.list
: R> rgb <- function(x, ...) UseMethod("rgb")
: R> rgb.list <- function(x, ...) rgb(x[[1]],x[[2]],x[[3]],...)
: R> rgb.default <- graphics::rgb
: 
: R> offred.rgb <- c(1, 0, 0) * 0.60;
: R> # original syntax
: R> rgb(offred.rgb[1], offred.rgb[2], offred.rgb[3], names = "offred")
:    offred 
: "#990000" 
: R> # list syntax
: R> rgb(silver.bullet(offred.rgb), names = "offred")
:    offred 
: "#990000"

Here is a second, different approach.  

Again, it is not exactly what you are asking for since silver.bullet,
here called flatten.args, is applied to the function rather than the
argument in question and operates on all arguments, not just one but
I think its closer in spirit to your query than my previous solution:

flatten.args <- function(f)
	function(...) {
		L <- list()
		for(i in list(...)) L <- c(L, unlist(i))
		do.call(as.character(substitute(f)), L)
	}

flatten.args(rgb)(0.6 * c(1,0,0), name = "offred")



From ripley at stats.ox.ac.uk  Thu Sep 16 06:50:41 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Sep 2004 05:50:41 +0100 (BST)
Subject: [R] Cross-validation for Linear Discrimitant Analysis
In-Reply-To: <Pine.GSO.4.58.0409151904070.18329@bioquad>
Message-ID: <Pine.LNX.4.44.0409160534381.11488-100000@gannet.stats>

On Wed, 15 Sep 2004, Yu Shao wrote:

> I am new to R and statistics and I have two questions.

Perhaps then you need to start by explaining why you are using LDA.
Please take a good look at the posting guide.

> First I need help to interpret the cross-validation result from the R
> linear discriminant analysis function "lda". 

You mean Professor Ripley's function lda in package MASS, I guess.

> I did the following:
> 
> lda (group ~ Var1 + Var2, CV=T)

R allows you to use meaningful names, so please do so.

> where "CV=T" tells the lda to do cross-validation. The output of lda are
> the posterior probabilities among other things, but I can't find an error
> term (like delta returned by cv.glm). My question is how to get such an
> error term from the output? Can I just simply calculate the prediction
> accuracy using the posterior probabilities from the cross-validation, and
> use that to measure the quality of the model?

cv.glm as in Dr Canty's package boot?  If you are trying to predict
classifications, LDA is not the right tool, and LOO CV probably is not
either.  There is no unique definition of `error term' (true for cv.glm as
well), and people have written whole books about how to assess
classifiers.  LDA is about `discrimination' not `allocation' in the jargon 
used ca 1960.

> Another question is more basic: how to determine if a lda model is
> significant? (There is no p-value.) Thanks,

Please do read the references on the ?lda page.  It's not a useful
question, as LDA is about discriminating between populations and makes the
unrealistic assumption of multivariate normality.  (Analogously for linear
regression, there are ways to test if that is (statistically)
`significant', but knowledgable users almost never do so.)

Perhaps more realistic advice is to suggest you seek some statistical 
consultancy.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Kevin.Wang at maths.anu.edu.au  Thu Sep 16 07:16:38 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Thu, 16 Sep 2004 15:16:38 +1000
Subject: [R] sapply() with cat()
In-Reply-To: <4148DFA9.4090909@maths.anu.edu.au>
References: <20040916001941.49302.qmail@web60503.mail.yahoo.com>
	<4148DFA9.4090909@maths.anu.edu.au>
Message-ID: <414921B6.4070506@maths.anu.edu.au>

Hi,

Suppose I've got a data frame:
   > inter.df
       V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12
   1  3.3  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
   2  0.0 0.1  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
   3  1.0 0.9 0.2  NA  NA  NA  NA  NA  NA  NA  NA  NA
   4  1.6 0.0 2.9 0.7  NA  NA  NA  NA  NA  NA  NA  NA
   5  0.0 0.1 2.9 0.1 0.1  NA  NA  NA  NA  NA  NA  NA
   6  2.4 1.0 0.6 0.4 1.9 0.1  NA  NA  NA  NA  NA  NA
   7  2.8 1.4 1.2 7.5 0.0 0.0 4.2  NA  NA  NA  NA  NA
   8  0.3 3.1 0.8 3.7 5.7 0.0 0.8 0.0  NA  NA  NA  NA
   9  0.1 2.9 0.3 1.3 0.2 0.2 0.5 1.4 0.9  NA  NA  NA
   10 0.8 2.6 0.0 0.0 0.1 4.1 0.8 4.3 0.6 2.2  NA  NA
   11 0.0 4.0 0.0 0.3 0.5 0.9 0.0 1.5 0.2 0.7 0.8  NA
   12 0.6 0.8 0.3 0.0 0.2 1.2 0.0 0.8 1.5 0.9 0.4   0
   >
   > foo <- function(x) {
   +   ifelse(x > 3.8, NA, x)
   + }
   > sapply(inter.df, foo)
          V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12
    [1,] 3.3  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
    [2,] 0.0 0.1  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
    [3,] 1.0 0.9 0.2  NA  NA  NA  NA  NA  NA  NA  NA  NA
    [4,] 1.6 0.0 2.9 0.7  NA  NA  NA  NA  NA  NA  NA  NA
    [5,] 0.0 0.1 2.9 0.1 0.1  NA  NA  NA  NA  NA  NA  NA
    [6,] 2.4 1.0 0.6 0.4 1.9 0.1  NA  NA  NA  NA  NA  NA
    [7,] 2.8 1.4 1.2  NA 0.0 0.0  NA  NA  NA  NA  NA  NA
    [8,] 0.3 3.1 0.8 3.7  NA 0.0 0.8 0.0  NA  NA  NA  NA
    [9,] 0.1 2.9 0.3 1.3 0.2 0.2 0.5 1.4 0.9  NA  NA  NA
   [10,] 0.8 2.6 0.0 0.0 0.1  NA 0.8  NA 0.6 2.2  NA  NA
   [11,] 0.0  NA 0.0 0.3 0.5 0.9 0.0 1.5 0.2 0.7 0.8  NA
   [12,] 0.6 0.8 0.3 0.0 0.2 1.2 0.0 0.8 1.5 0.9 0.4   0

Up to here, sapply() does what I want, replacing values that are greater 
than 3.8 to NA, as per my foo() function.  But...

   > goo <- function(x) {
   +   ifelse(x > 3.8, cat("\\textbf{", x, "}", sep = ""), x)
   + }
   > sapply(inter.df, goo)
   \textbf{NA0.10.900.111.43.12.92.640.8}Error in "[<-"(`*tmp*`, test, 
value = rep(yes, length.out = length(ans))[test]) :
           incompatible types

If instead whenever I get a value that's greater than 3.8 I want to 
change it what goo() does, e.g. the value 4.0 should become:
   \textbf{4.0}
but I got the above error.

What I'm intending is to then pass the inter.df (with the \textbf{} 
markups) into xtable() so the values will be bolded in the resulting 
LaTeX table (as so far, I cannot see how I can achieve bolding only 
certain numbers with xtable() alone).

Any suggestions will be welcome!

Kevin

-- 
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From ripley at stats.ox.ac.uk  Thu Sep 16 07:37:50 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Sep 2004 06:37:50 +0100 (BST)
Subject: [R] sapply() with cat()
In-Reply-To: <414921B6.4070506@maths.anu.edu.au>
Message-ID: <Pine.LNX.4.44.0409160635460.9075-100000@gannet.stats>

On Thu, 16 Sep 2004, Kevin Wang wrote:

> Hi,
> 
> Suppose I've got a data frame:
>    > inter.df
>        V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12
>    1  3.3  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
>    2  0.0 0.1  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
>    3  1.0 0.9 0.2  NA  NA  NA  NA  NA  NA  NA  NA  NA
>    4  1.6 0.0 2.9 0.7  NA  NA  NA  NA  NA  NA  NA  NA
>    5  0.0 0.1 2.9 0.1 0.1  NA  NA  NA  NA  NA  NA  NA
>    6  2.4 1.0 0.6 0.4 1.9 0.1  NA  NA  NA  NA  NA  NA
>    7  2.8 1.4 1.2 7.5 0.0 0.0 4.2  NA  NA  NA  NA  NA
>    8  0.3 3.1 0.8 3.7 5.7 0.0 0.8 0.0  NA  NA  NA  NA
>    9  0.1 2.9 0.3 1.3 0.2 0.2 0.5 1.4 0.9  NA  NA  NA
>    10 0.8 2.6 0.0 0.0 0.1 4.1 0.8 4.3 0.6 2.2  NA  NA
>    11 0.0 4.0 0.0 0.3 0.5 0.9 0.0 1.5 0.2 0.7 0.8  NA
>    12 0.6 0.8 0.3 0.0 0.2 1.2 0.0 0.8 1.5 0.9 0.4   0
>    >
>    > foo <- function(x) {
>    +   ifelse(x > 3.8, NA, x)
>    + }
>    > sapply(inter.df, foo)
>           V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12
>     [1,] 3.3  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
>     [2,] 0.0 0.1  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
>     [3,] 1.0 0.9 0.2  NA  NA  NA  NA  NA  NA  NA  NA  NA
>     [4,] 1.6 0.0 2.9 0.7  NA  NA  NA  NA  NA  NA  NA  NA
>     [5,] 0.0 0.1 2.9 0.1 0.1  NA  NA  NA  NA  NA  NA  NA
>     [6,] 2.4 1.0 0.6 0.4 1.9 0.1  NA  NA  NA  NA  NA  NA
>     [7,] 2.8 1.4 1.2  NA 0.0 0.0  NA  NA  NA  NA  NA  NA
>     [8,] 0.3 3.1 0.8 3.7  NA 0.0 0.8 0.0  NA  NA  NA  NA
>     [9,] 0.1 2.9 0.3 1.3 0.2 0.2 0.5 1.4 0.9  NA  NA  NA
>    [10,] 0.8 2.6 0.0 0.0 0.1  NA 0.8  NA 0.6 2.2  NA  NA
>    [11,] 0.0  NA 0.0 0.3 0.5 0.9 0.0 1.5 0.2 0.7 0.8  NA
>    [12,] 0.6 0.8 0.3 0.0 0.2 1.2 0.0 0.8 1.5 0.9 0.4   0
> 
> Up to here, sapply() does what I want, replacing values that are greater 
> than 3.8 to NA, as per my foo() function.  But...
> 
>    > goo <- function(x) {
>    +   ifelse(x > 3.8, cat("\\textbf{", x, "}", sep = ""), x)
>    + }
>    > sapply(inter.df, goo)
>    \textbf{NA0.10.900.111.43.12.92.640.8}Error in "[<-"(`*tmp*`, test, 
> value = rep(yes, length.out = length(ans))[test]) :
>            incompatible types
> 
> If instead whenever I get a value that's greater than 3.8 I want to 
> change it what goo() does, e.g. the value 4.0 should become:
>    \textbf{4.0}
> but I got the above error.

cat writes to connection (here stdout) and then returns NULL.  I think you 
meant to use paste():

goo <- function(x)ifelse(x > 3.8, paste("\\textbf{", x, "}", sep = ""), x)

works.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at myway.com  Thu Sep 16 07:52:45 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 16 Sep 2004 05:52:45 +0000 (UTC)
Subject: [R] sapply() with cat()
References: <414921B6.4070506@maths.anu.edu.au>
	<Pine.LNX.4.44.0409160635460.9075-100000@gannet.stats>
Message-ID: <loom.20040916T074943-778@post.gmane.org>

Prof Brian Ripley <ripley <at> stats.ox.ac.uk> writes:

: 
: On Thu, 16 Sep 2004, Kevin Wang wrote:
: 
: > Hi,
: > 
: > Suppose I've got a data frame:
: >    > inter.df
: >        V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12
: >    1  3.3  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
: >    2  0.0 0.1  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
: >    3  1.0 0.9 0.2  NA  NA  NA  NA  NA  NA  NA  NA  NA
: >    4  1.6 0.0 2.9 0.7  NA  NA  NA  NA  NA  NA  NA  NA
: >    5  0.0 0.1 2.9 0.1 0.1  NA  NA  NA  NA  NA  NA  NA
: >    6  2.4 1.0 0.6 0.4 1.9 0.1  NA  NA  NA  NA  NA  NA
: >    7  2.8 1.4 1.2 7.5 0.0 0.0 4.2  NA  NA  NA  NA  NA
: >    8  0.3 3.1 0.8 3.7 5.7 0.0 0.8 0.0  NA  NA  NA  NA
: >    9  0.1 2.9 0.3 1.3 0.2 0.2 0.5 1.4 0.9  NA  NA  NA
: >    10 0.8 2.6 0.0 0.0 0.1 4.1 0.8 4.3 0.6 2.2  NA  NA
: >    11 0.0 4.0 0.0 0.3 0.5 0.9 0.0 1.5 0.2 0.7 0.8  NA
: >    12 0.6 0.8 0.3 0.0 0.2 1.2 0.0 0.8 1.5 0.9 0.4   0
: >    >
: >    > foo <- function(x) {
: >    +   ifelse(x > 3.8, NA, x)
: >    + }
: >    > sapply(inter.df, foo)
: >           V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12
: >     [1,] 3.3  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
: >     [2,] 0.0 0.1  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
: >     [3,] 1.0 0.9 0.2  NA  NA  NA  NA  NA  NA  NA  NA  NA
: >     [4,] 1.6 0.0 2.9 0.7  NA  NA  NA  NA  NA  NA  NA  NA
: >     [5,] 0.0 0.1 2.9 0.1 0.1  NA  NA  NA  NA  NA  NA  NA
: >     [6,] 2.4 1.0 0.6 0.4 1.9 0.1  NA  NA  NA  NA  NA  NA
: >     [7,] 2.8 1.4 1.2  NA 0.0 0.0  NA  NA  NA  NA  NA  NA
: >     [8,] 0.3 3.1 0.8 3.7  NA 0.0 0.8 0.0  NA  NA  NA  NA
: >     [9,] 0.1 2.9 0.3 1.3 0.2 0.2 0.5 1.4 0.9  NA  NA  NA
: >    [10,] 0.8 2.6 0.0 0.0 0.1  NA 0.8  NA 0.6 2.2  NA  NA
: >    [11,] 0.0  NA 0.0 0.3 0.5 0.9 0.0 1.5 0.2 0.7 0.8  NA
: >    [12,] 0.6 0.8 0.3 0.0 0.2 1.2 0.0 0.8 1.5 0.9 0.4   0
: > 
: > Up to here, sapply() does what I want, replacing values that are greater 
: > than 3.8 to NA, as per my foo() function.  But...
: > 
: >    > goo <- function(x) {
: >    +   ifelse(x > 3.8, cat("\\textbf{", x, "}", sep = ""), x)
: >    + }
: >    > sapply(inter.df, goo)
: >    \textbf{NA0.10.900.111.43.12.92.640.8}Error in "[<-"(`*tmp*`, test, 
: > value = rep(yes, length.out = length(ans))[test]) :
: >            incompatible types
: > 
: > If instead whenever I get a value that's greater than 3.8 I want to 
: > change it what goo() does, e.g. the value 4.0 should become:
: >    \textbf{4.0}
: > but I got the above error.
: 
: cat writes to connection (here stdout) and then returns NULL.  I think you 
: meant to use paste():
: 
: goo <- function(x)ifelse(x > 3.8, paste("\\textbf{", x, "}", sep = ""), x)
: 
: works.
: 


Also, if you convert your data frame to a matrix you won't need sapply:

   inter.mat <- as.matrix(inter.df)
   ifelse(inter.mat > 3.8, 
      paste("\\textbf{", inter.mat, "}", sep = ""), 
      inter.mat)



From p.dalgaard at biostat.ku.dk  Thu Sep 16 08:53:11 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Sep 2004 08:53:11 +0200
Subject: [R] Signs of loadings from princomp on Windows
In-Reply-To: <6.1.0.6.2.20040915173048.05b0e810@mailhost.blackmesacapital.com>
References: <ce17a70f0409140918408afa9e@mail.gmail.com>
	<Pine.LNX.4.44.0409141723310.13336-100000@gannet.stats>
	<6.1.0.6.2.20040914105042.05a86cb0@mailhost.blackmesacapital.com>
	<ce17a70f04091516073d5e12ef@mail.gmail.com>
	<6.1.0.6.2.20040915173048.05b0e810@mailhost.blackmesacapital.com>
Message-ID: <x2llfazovc.fsf@biostat.ku.dk>

Tony Plate <tplate at blackmesacapital.com> writes:

> difference?"  (The fact that various people chimed in to say they
> could reproduce the behavior that bothered you, but didn't bother dig
> deeper suggests it didn't bother them that much, which further
> suggests that you are the person most motivated by this and thus the
> best candidate for investigating it further...)

It could be well worth finding though. It's most likely a reliance on
uninitialized memory (the only other explanation I can think of is if
something is tampering with the FPU control word). That may be mostly
harmless if the algorithm converges - the sign is not well defined
anyway - but we have recently fixed a couple of bugs where the
occasional injection of NaN or Inf values caused real trouble.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From jarioksa at sun3.oulu.fi  Thu Sep 16 09:10:19 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 16 Sep 2004 10:10:19 +0300
Subject: [R] BUGS and OS X
Message-ID: <1095318618.21333.10.camel@biol102145.oulu.fi>

On Wed, 2004-09-15 at 21:29, Tamas K Papp wrote:
> On Wed, Sep 15, 2004 at 02:21:18PM -0400, Liaw, Andy wrote:
> > That's more of a question for the BUGS developers.  BUGS is not open
source,
> > so whatever binary is provided, that's all you can use.  If I'm not
> > mistaken, WinBUGS is the only version under development.
> 
> I found something called JAGS, and I am still exploring it.  It
> appears to be an open-source BUGS replacement, thought with
> limitations.
> 
MacOS X is a kind of unix (where the emphasis is on the "kind of"), so
you can get and compile any source code developed for unix -- with some
luck. One alternative is Bassist available at
http://www.cs.helsinki.fi/research/fdk/bassist/. I just tried and found
out that you can compile and install it in MacOS X in the usual way
(./configure && make && sudo make install). That's all I can say about
it. It may not be easiest to use. The current version seems to be a bit
oldish and not quite complete, but somebody claimed that they may start
developing Bassist again. Actually, Bob O'Hara (who usually calls
himself "Anon." in this list) should know more, and hopefully this
message will prompt him to tell us, too.

> I was asking what software people would recommend for the same
> functionality, not a drop-in replacement.  I am just baffled by the
> bewildering array of R packages, and would be so happy if somebody
> told me what THEY use for Bayesian analysis, so I could read the docs
> and get started.  MCMC? Boa? etc.  Suggestions on how experienced
> users do bayesian analysis in R would be welcome.
> 
You need a guru to guide you. That's the holy tradition in Bayesianism.

cheers, jari oksanen
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From jarioksa at sun3.oulu.fi  Thu Sep 16 09:31:51 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 16 Sep 2004 10:31:51 +0300
Subject: [R] Signs of loadings from princomp on Windows
In-Reply-To: <6.1.0.6.2.20040915173048.05b0e810@mailhost.blackmesacapital.com>
References: <ce17a70f0409140918408afa9e@mail.gmail.com>
	<Pine.LNX.4.44.0409141723310.13336-100000@gannet.stats>
	<6.1.0.6.2.20040914105042.05a86cb0@mailhost.blackmesacapital.com>
	<ce17a70f04091516073d5e12ef@mail.gmail.com>
	<6.1.0.6.2.20040915173048.05b0e810@mailhost.blackmesacapital.com>
Message-ID: <1095319910.21333.28.camel@biol102145.oulu.fi>

On Thu, 2004-09-16 at 02:38, Tony Plate wrote:
> You could investigate this yourself by looking at the code of princomp (try 
> getAnywhere("princomp.default")).  I'd suggest making a file that in-lines 
> the body of princomp.default into the commands you had below.  See if you 
> still get the difference.  (I'd be surprised if you didn't).  Then try 
> commenting out lines the second pass through the commands produces the same 
> results as the first.  The very last thing you commented out might help to 
> answer your question "What would be causing the
> difference?"  (The fact that various people chimed in to say they could 
> reproduce the behavior that bothered you, but didn't bother dig deeper 
> suggests it didn't bother them that much, which further suggests that you 
> are the person most motivated by this and thus the best candidate for 
> investigating it further...)
> 
People were not too bothered, since the sign of the eigenvector is not
well defined in PCA: vectors x and -x are equal. Have you compared
absolute values? Do they differ much (more than, say 1e-6)? If they
differ too much for you, this could be a symptom of some other problems,
so it may be worth investigating in machines where you get this thing
(others can do nothing). Since the princomp.default is difficult to find
(either getAnywhere("princomp.default") or stats:::princomp -- I hate
this information hiding), and its code is winding, I'd suggest you
concentrate studying line:

sol <- eigen(cv, symmetric=TRUE)

where you get the cv with

cv <- cov.wt(x)$cov * (1 - 1/nrow(x))

and x is your data matrix. If cv remains unchanged from time to time,
but there is a change in signs of sol$vectors, then you have localised
your problem. If it's not there, then the rest of the princomp.default
code is worth investigating. If it's in the eigen, then it dives deep
into Fortran, and that may be all you can say. (If your covariance
matrices change with repeated calculations, then the problem is deeper).

However, sign doesn't matter if there are 
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From ripley at stats.ox.ac.uk  Thu Sep 16 09:45:35 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Sep 2004 08:45:35 +0100 (BST)
Subject: [R] Signs of loadings from princomp on Windows
In-Reply-To: <x2llfazovc.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0409160834080.10744-100000@gannet.stats>

On 16 Sep 2004, Peter Dalgaard wrote:

> Tony Plate <tplate at blackmesacapital.com> writes:
> 
> > difference?"  (The fact that various people chimed in to say they
> > could reproduce the behavior that bothered you, but didn't bother dig
> > deeper suggests it didn't bother them that much, which further
> > suggests that you are the person most motivated by this and thus the
> > best candidate for investigating it further...)
> 
> It could be well worth finding though. It's most likely a reliance on
> uninitialized memory (the only other explanation I can think of is if
> something is tampering with the FPU control word). That may be mostly
> harmless if the algorithm converges - the sign is not well defined
> anyway - but we have recently fixed a couple of bugs where the
> occasional injection of NaN or Inf values caused real trouble.

valgrind found nothing, though, so the uninitialized memory is probably
not in R.

I suspect a problem with the version of msvcrt.dll in use (and probably
related to use of the full FPU precision in R).

And I do think the OP is making a very big deal out of something that is 
documented on the help page.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Thu Sep 16 10:25:45 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 16 Sep 2004 10:25:45 +0200
Subject: [R] Bessel function
In-Reply-To: <414886AC.3080902@aon.at>
References: <E619BDBD99B4F74D9DCA32F43BE926714C748C@XCH-VN02.sph.ad.jhsph.edu>
	<414886AC.3080902@aon.at>
Message-ID: <16713.19977.484630.402491@gargle.gargle.HOWL>

>>>>> "Christian" == Christian Stratova <cstrato at aon.at>
>>>>>     on Wed, 15 Sep 2004 20:15:08 +0200 writes:

    Christian> You can find C++ source code for Bessel function and similar
    Christian> functions for example here:
    Christian> http://root.cern.ch/root/htmldoc/src/TMath.cxx.html

but as Prof Ripley has said much earlier in this thread :

Why don't you use the C version from R's source?  R is Open Source !!

R's version (of the *four* most common Bessel functions) stems
from the  Netlib "Specfun" collection, 
was ported to C by me and has been slightly fixed more than once
AFAIR.


    Christian> Hope this helps

    Christian> Best regards
    Christian> Christian
    Christian> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-
    Christian> C.h.r.i.s.t.i.a.n. .S.t.r.a.t.o.w.a
    Christian> V.i.e.n.n.a.         .A.u.s.t.r.i.a
    Christian> -.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-

    Christian> Ravi Varadhan wrote:
    >> Dear Beat,
    >> 
    >> You might also want to look at the book by Zang and Jin -  Computation of Special Functions, John Wiley.  They have Fortran sources for all the special functions covered in there.
    >> 
    >> Ravi.
    >> 
    >> Ravi Varadhan, Ph.D.
    >> Assistant Professor,  The Center on Aging and Health
    >> Division of Geriatric Medicine and Gerontology,
    >> Johns Hopkins University,
    >> 2024 E. Monument Street, Suite 2-700
    >> Baltimore, MD 21205.
    >> (410) 502 - 7806.
    >> 
    >> ________________________________
    >> 
    >> From: r-help-bounces at stat.math.ethz.ch on behalf of beat.huggler at rmf.ch
    >> Sent: Wed 9/15/2004 4:24 AM
    >> To: R-help at stat.math.ethz.ch
    >> Subject: [R] Bessel function
    >> 
    >> 
    >> 
    >> 
    >> 
    >> Dear all
    >> 
    >> Currently, I'm implementing the generalized hyperbolic distribution into
    >> Splus. Unfortunately the Bessel function is not implemented in Splus. In
    >> R the Bessel function does exist but it is an internal function and I'm
    >> not able to look at the code.
    >> 
    >> Is there any possibility to see the code of the Bessel function in R or
    >> does anybody has an implementation of the Bessel function in Splus?
    >> 
    >> Thanks a lot for your help.
    >> 
    >> Beat



From vdepalma at deloitte.it  Thu Sep 16 10:22:51 2004
From: vdepalma at deloitte.it (De Palma, Valeria (IT - Milano))
Date: Thu, 16 Sep 2004 10:22:51 +0200
Subject: [R] Use of R libraries in C or C++
Message-ID: <6F07AA950948D043A58F7FC8D8DE03EC04C33F59@itave0411.atrema.deloitte.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040916/ebe7dad8/attachment.pl

From ripley at stats.ox.ac.uk  Thu Sep 16 10:47:44 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Sep 2004 09:47:44 +0100 (BST)
Subject: [R] Use of R libraries in C or C++
In-Reply-To: <6F07AA950948D043A58F7FC8D8DE03EC04C33F59@itave0411.atrema.deloitte.com>
Message-ID: <Pine.LNX.4.44.0409160946540.16608-100000@gannet.stats>

On Thu, 16 Sep 2004, De Palma, Valeria (IT - Milano) wrote:

> 
> 	Hi all,
> 	is it possible to use R libraries in a software built on C or C++?
> 	Hope someone can help me,
> 	Valeria

Look in src/nmath/standalone/README for details of how to use the libRmath 
library.

Or did you mean R *packages*?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From s-plus at wiwi.uni-bielefeld.de  Thu Sep 16 10:56:38 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Thu, 16 Sep 2004 10:56:38 +0200
Subject: [R] efficient submatrix extraction
References: <1095282653.7884.6.camel@blue.chem.psu.edu>
Message-ID: <41495546.60301@wiwi.uni-bielefeld.de>

there are two main ideas to improve the efficiency:

1. the comparison with the limit can be done at first
2. a matrix with boxsize*boxsize rows can be defined so that
   you can apply function "apply" without using inner loops

<<*>>=
# parameters
size<-1024; limit<-0.7
# some data
set.seed(17); data<-runif(size^2)
m<-matrix(data,size,size)
bcount.vec<-NULL
m<-m>limit
for (boxsize in 2^(1:8)) {
  # inner loop:
  m<-array(m,c(boxsize,size/boxsize,size))
  m<-aperm(m,c(1,3,2))
  m<-matrix(m,nrow=boxsize*boxsize)
  bcount.vec<-c(bcount.vec,sum(apply(m,2,max)))
}
bcount<-sum(bcount.vec)
print(bcount.vec)
print(bcount)

@
output-start
[1] 199099  65306  16384   4096   1024    256     64     16
[1] 286245
output-end

Some remarks on your code:
The first expression in your outer loop is setting bcount to 0.
In the inner loops bcount is incremented.
But the outer loop sets bcount to the value 0 again!?
What do you want to count?

Peter

Rajarshi Guha wrote:

>Hi,
>  I have a matrix of say 1024x1024 and I want to look at it in chunks.
>That is I'd like to divide into a series of submatrices of order 2x2.
>
>| 1 2 3 4 5 6 7 8 ... |
>| 1 2 3 4 5 6 7 8 ... |
>| 1 2 3 4 5 6 7 8 ... |
>| 1 2 3 4 5 6 7 8 ... |
>...
>
>So the first submatrix would be
>
>| 1 2 |
>| 1 2 |
>
>the second one would be
>
>| 3 4 |
>| 3 4 |
>
>and so on. That is I want the matrix to be evenly divided into 2x2
>submatrices. Now I'm also doing this subdivision into 4x4, 8x8 ...
>256x256 submatrices.
>
>Currently I'm using loops and I'm sure there is a mroe efficient way to
>do it:
>
>    m <- matrix(runif(1024*1024), nrow=1024)
>    boxsize <- 2^(1:8)
>
>    for (b in boxsize) {
>        bcount <- 0
>        bstart <- seq(1,1024, by=b)
>        for (x in bstart) {
>            for (y in bstart) {
>                xend <- x + b - 1
>                yend <- y + b - 1
>                if (length(which( m[ x:xend, y:yend ] > 0.7)) > 0) {
>                    bcount <- bcount + 1
>                }
>            }
>        }
>    }
>
>Is there any way to vectorize the two inner loops?
>
>Thanks,
>
>-------------------------------------------------------------------
>Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
>GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
>-------------------------------------------------------------------
>The way to love anything is to realize that it might be lost.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From odyn at email.si  Thu Sep 16 11:29:18 2004
From: odyn at email.si (=?ISO-8859-2?Q?Andrej_Udu=E8?=)
Date: Thu, 16 Sep 2004 11:29:18 +0200
Subject: [R] newbie needs help using R as solver
Message-ID: <41495CEE.4080802@email.si>

Greetings
I'm a total newbie in R and I'm trying to make a comparisson of Excel 
and R in the fields of:
- optimisation modeling (using solver)
-  decision trees
-  simulation modeling
as described in Winston, Wayne L.:  Practical Management Science.
for optimisation modeling in Excel I would normaly use solver. In R 
however I can't seem to be able to find the solution. I've narrowed it 
down to optim, optimize functions (I might be totaly wrong), but I can't 
figure out how to set the conditions. I've read something about nlm 
model but I can't find the anwser (examples are not easy enough for me).
what I wanna do is solve this simple task:
a+b =< 500000
c+d  =< 500000
g  >= 0,25*c+d
a+b+c+d+g =< 1000000
a, b, c, d, g => 0

I would very much appreciate any help in this matter. I need to locate 
the appropriate function for the task and figure out how to write this 
formulas. I'd also be very thankfull for any help (links) to simple 
examples of decision trees and/or simulation.
   
    Andrej Udu??



From JonesW at kssg.com  Thu Sep 16 11:44:35 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Thu, 16 Sep 2004 10:44:35 +0100
Subject: [R] newbie needs help using R as solver
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB02FEF95A@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040916/026cf3b6/attachment.pl

From ripley at stats.ox.ac.uk  Thu Sep 16 11:53:15 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Sep 2004 10:53:15 +0100 (BST)
Subject: [R] newbie needs help using R as solver
In-Reply-To: <41495CEE.4080802@email.si>
Message-ID: <Pine.LNX.4.44.0409161046180.18273-100000@gannet.stats>

The problem you describe is usually called `linear programming'.
On my system I get 

> help.search("linear programming")

Help files with alias or concept or title matching 'linear
programming' using fuzzy matching:

solveLP(linprog)        solve Linear Programming / Optimization
                        problems
lp.object(lpSolve)      LP (linear programming) object
print.simplex(boot)     Print Solution to Linear Programming Problem
simplex(boot)           Simplex Method for Linear Programming Problems
simplex.object(boot)    Linear Programming Solution Objects

so that's three packages to look into.

On Thu, 16 Sep 2004, [ISO-8859-2] Andrej Udu?? wrote:

> Greetings
> I'm a total newbie in R and I'm trying to make a comparisson of Excel 
> and R in the fields of:

Unless you are a `total newbie' in Excel, is that not inevitably an unfair 
comparison?  I suspect almost all readers of this list would never have 
guessed to use `solver' for linear programming.

> - optimisation modeling (using solver)
> -  decision trees
> -  simulation modeling
> as described in Winston, Wayne L.:  Practical Management Science.
> for optimisation modeling in Excel I would normaly use solver. In R 
> however I can't seem to be able to find the solution. I've narrowed it 
> down to optim, optimize functions (I might be totaly wrong), but I can't 
> figure out how to set the conditions. I've read something about nlm 
> model but I can't find the anwser (examples are not easy enough for me).
> what I wanna do is solve this simple task:
> a+b =< 500000
> c+d  =< 500000
> g  >= 0,25*c+d
> a+b+c+d+g =< 1000000
> a, b, c, d, g => 0
> 
> I would very much appreciate any help in this matter. I need to locate 
> the appropriate function for the task and figure out how to write this 
> formulas. I'd also be very thankfull for any help (links) to simple 
> examples of decision trees and/or simulation.

Simple examples of decision trees: many of the R/S books listed in the 
FAQ.

`Simulation' has several different meanings, so you need to be more 
explicit.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bob.ohara at helsinki.fi  Thu Sep 16 11:56:29 2004
From: bob.ohara at helsinki.fi (Anon.)
Date: Thu, 16 Sep 2004 12:56:29 +0300
Subject: [R] BUGS and OS X
In-Reply-To: <1095318618.21333.10.camel@biol102145.oulu.fi>
References: <1095318618.21333.10.camel@biol102145.oulu.fi>
Message-ID: <4149634D.1070903@helsinki.fi>

Jari Oksanen wrote:

>On Wed, 2004-09-15 at 21:29, Tamas K Papp wrote:
>  
>
>>On Wed, Sep 15, 2004 at 02:21:18PM -0400, Liaw, Andy wrote:
>>    
>>
>>>That's more of a question for the BUGS developers.  BUGS is not open
>>>      
>>>
>source,
>  
>
>>>so whatever binary is provided, that's all you can use.  If I'm not
>>>mistaken, WinBUGS is the only version under development.
>>>      
>>>
>>I found something called JAGS, and I am still exploring it.  It
>>appears to be an open-source BUGS replacement, thought with
>>limitations.
>>
>>    
>>
>MacOS X is a kind of unix (where the emphasis is on the "kind of"), so
>you can get and compile any source code developed for unix -- with some
>luck. One alternative is Bassist available at
>http://www.cs.helsinki.fi/research/fdk/bassist/. I just tried and found
>out that you can compile and install it in MacOS X in the usual way
>(./configure && make && sudo make install). That's all I can say about
>it. It may not be easiest to use. The current version seems to be a bit
>oldish and not quite complete, but somebody claimed that they may start
>developing Bassist again. Actually, Bob O'Hara (who usually calls
>himself "Anon." in this list) should know more, and hopefully this
>message will prompt him to tell us, too.
>
>  
>
I don't think Andrew has even tried installing WinBUGS it on a Mac 
(first problem: find a Mac).

I haven't heard about any plans to develop BASSIST further, but as it's 
open source, someone else could take it up.  The BASSIST language is 
very BUGS-like, so shouldn't be a big problem to learn.

To answer Ramon about BUGS and R, be patient: I think an announcement 
will come soon, and I'd rather not pre-empt that.

We're drifting away from R, so can I suggest either ending this, 
sticking to R, or shifting it to the WinBUGS list?  That's probably a 
better forum for getting feedback on Bayesian stuff anyway.

Oh, and Jari, are you likely to submit your R: opas ekologielle to CRAN 
at any time?  Hint, hint.

Bob

-- 
Bob O'Hara
Department of Mathematics and Statistics
P.O. Box 68 (Gustaf H??llstr??min katu 2b)
FIN-00014 University of Helsinki
Finland

Telephone: +358-9-191 51479
Mobile: +358 50 599 0540
Fax:  +358-9-191 51400
WWW:  http://www.RNI.Helsinki.FI/~boh/
Journal of Negative Results - EEB: www.jnr-eeb.org



From vito_ricci at yahoo.com  Thu Sep 16 12:00:10 2004
From: vito_ricci at yahoo.com (Vito Ricci)
Date: Thu, 16 Sep 2004 12:00:10 +0200 (CEST)
Subject: [R] newbie needs help using R as solver
Message-ID: <20040916100010.67511.qmail@web41204.mail.yahoo.com>

Hi,

it a LP problem. It's not just a function to optimize
(in this way optim() and optimize() are not usefull),
but a linear system grouping sever
equations/dis-equations.
See package linprog and boot.

See these link about LP:

http://www.ece.northwestern.edu/OTC/
http://www.isye.gatech.edu/~spyros/LP/LP.html
http://www.faqs.org/faqs/linear-programming-faq/

best
Vito

Greetings
I'm a total newbie in R and I'm trying to make a
comparisson of Excel 
and R in the fields of:
- optimisation modeling (using solver)
-  decision trees
-  simulation modeling
as described in Winston, Wayne L.:  Practical
Management Science.
for optimisation modeling in Excel I would normaly use
solver. In R 
however I can't seem to be able to find the solution.
I've narrowed it 
down to optim, optimize functions (I might be totaly
wrong), but I can't 
figure out how to set the conditions. I've read
something about nlm 
model but I can't find the anwser (examples are not
easy enough for me).
what I wanna do is solve this simple task:
a+b =< 500000
c+d  =< 500000
g  >= 0,25*c+d
a+b+c+d+g =< 1000000
a, b, c, d, g => 0

I would very much appreciate any help in this matter.
I need to locate 
the appropriate function for the task and figure out
how to write this 
formulas. I'd also be very thankfull for any help
(links) to simple 
examples of decision trees and/or simulation.
   
    Andrej Udu&#269;

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml


		
___________________________________

http://it.seriea.fantasysports.yahoo.com/



From plummer at iarc.fr  Thu Sep 16 13:00:15 2004
From: plummer at iarc.fr (Martyn Plummer)
Date: Thu, 16 Sep 2004 13:00:15 +0200
Subject: [R] getting started on Bayesian analysis
In-Reply-To: <20040915001944.GA1086@tpapp>
References: <20040915001944.GA1086@tpapp>
Message-ID: <1095332415.3149.8.camel@nemo>

On Wed, 2004-09-15 at 02:19, Tamas K Papp wrote:
> I am an economist who decided it's high time that I learned some
> Bayesian statistics.  I am following An Introduction to Modern
> Bayesian Econometrics by T. Lancaster.
> 
> The book recommends using BUGS, but I wonder if there are any
> alternatives which are free software and fully integrated to R (which
> I have been using for more than two years for numerical computations.)
> I would like to learn what R packages (or other software)
> statisticians use for Bayesian analysis to R, if there are viable
> alternatives to BUGS, etc.

Bayesian analysis in R is relatively underdeveloped. However, Greg
Warnes recently decided to get everyone involved with MCMC in R talking
to each other.  The current state of the art can be seen here:

http://research.warnes.net/Members/warnes/R-MCMC/

All I can say is "watch this space" for future developments.
Martyn



From plummer at iarc.fr  Thu Sep 16 13:02:40 2004
From: plummer at iarc.fr (Martyn Plummer)
Date: Thu, 16 Sep 2004 13:02:40 +0200
Subject: [R] BUGS and OS X
In-Reply-To: <20040915182907.GA1065@dynamic-oit-vapornet-b-104>
References: <3A822319EB35174CA3714066D590DCD504AF83C6@usrymx25.merck.com>
	<20040915182907.GA1065@dynamic-oit-vapornet-b-104>
Message-ID: <1095332560.3149.11.camel@nemo>

On Wed, 2004-09-15 at 20:29, Tamas K Papp wrote:
> On Wed, Sep 15, 2004 at 02:21:18PM -0400, Liaw, Andy wrote:
> > That's more of a question for the BUGS developers.  BUGS is not open source,
> > so whatever binary is provided, that's all you can use.  If I'm not
> > mistaken, WinBUGS is the only version under development.
> 
> I found something called JAGS, and I am still exploring it.  It
> appears to be an open-source BUGS replacement, thought with
> limitations.

Version 0.65 of JAGS runs on MacOs X, thanks to Christopher Jackson. 
The new manual contains instructions on compilation.

Martyn



From agustin.perez at umh.es  Thu Sep 16 13:33:13 2004
From: agustin.perez at umh.es (Perez Martin, Agustin)
Date: Thu, 16 Sep 2004 13:33:13 +0200
Subject: [R] Indexing lists
Message-ID: <79C6D1A4DD5E7B46B663C43C002123651458DC@mailer-e071.umh.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040916/b615a48f/attachment.pl

From sdavis2 at mail.nih.gov  Thu Sep 16 13:43:01 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 16 Sep 2004 07:43:01 -0400
Subject: [R] Indexing lists
In-Reply-To: <79C6D1A4DD5E7B46B663C43C002123651458DC@mailer-e071.umh.es>
References: <79C6D1A4DD5E7B46B663C43C002123651458DC@mailer-e071.umh.es>
Message-ID: <9063B752-07D5-11D9-ABE6-000A95D7BA10@mail.nih.gov>

Maybe not the best solution, but something like:

lapply(mylist,function(x) 
{return(list(FirstCol=mylist[,1],FirstRow=mylist[1,]))})

In any case, look at ?lapply

Sean

On Sep 16, 2004, at 7:33 AM, Perez Martin, Agustin wrote:

> DeaR useRs:
>
> I have a list with 500 elements, in each other there are data.frames 
> and I
> want to take the first row and the first column of each elements of my 
> list
> since the first to the 500-th.
>
> Thanks and excuse my bad English.
>
> ---
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Thu Sep 16 13:51:35 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Sep 2004 13:51:35 +0200
Subject: [R] Indexing lists
In-Reply-To: <79C6D1A4DD5E7B46B663C43C002123651458DC@mailer-e071.umh.es>
References: <79C6D1A4DD5E7B46B663C43C002123651458DC@mailer-e071.umh.es>
Message-ID: <x2r7p2ph2w.fsf@biostat.ku.dk>

"Perez Martin, Agustin" <agustin.perez at umh.es> writes:

> DeaR useRs:
>  
> I have a list with 500 elements, in each other there are data.frames and I
> want to take the first row and the first column of each elements of my list
> since the first to the 500-th.
>  
> Thanks and excuse my bad English.

Possibly (if I catch your drift...)

lapply(yourlist,"[",1,1)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Thu Sep 16 13:57:51 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Sep 2004 13:57:51 +0200
Subject: [R] Indexing lists
In-Reply-To: <9063B752-07D5-11D9-ABE6-000A95D7BA10@mail.nih.gov>
References: <79C6D1A4DD5E7B46B663C43C002123651458DC@mailer-e071.umh.es>
	<9063B752-07D5-11D9-ABE6-000A95D7BA10@mail.nih.gov>
Message-ID: <x2mzzqpgsg.fsf@biostat.ku.dk>

Sean Davis <sdavis2 at mail.nih.gov> writes:

> Maybe not the best solution, but something like:
> 
> lapply(mylist,function(x)
> {return(list(FirstCol=mylist[,1],FirstRow=mylist[1,]))})

ITYM  list(FirstCol=x[,1],FirstRow=x[1,])
 
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From sdavis2 at mail.nih.gov  Thu Sep 16 14:04:44 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 16 Sep 2004 08:04:44 -0400
Subject: [R] Indexing lists
In-Reply-To: <x2mzzqpgsg.fsf@biostat.ku.dk>
References: <79C6D1A4DD5E7B46B663C43C002123651458DC@mailer-e071.umh.es>
	<9063B752-07D5-11D9-ABE6-000A95D7BA10@mail.nih.gov>
	<x2mzzqpgsg.fsf@biostat.ku.dk>
Message-ID: <98B8538C-07D8-11D9-ABE6-000A95D7BA10@mail.nih.gov>


On Sep 16, 2004, at 7:57 AM, Peter Dalgaard wrote:

> Sean Davis <sdavis2 at mail.nih.gov> writes:
>
>> Maybe not the best solution, but something like:
>>
>> lapply(mylist,function(x)
>> {return(list(FirstCol=mylist[,1],FirstRow=mylist[1,]))})
>
> ITYM  list(FirstCol=x[,1],FirstRow=x[1,])
>
Uh, Duh!

Thanks.  Some help I am....



From ggrothendieck at myway.com  Thu Sep 16 14:08:05 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 16 Sep 2004 12:08:05 +0000 (UTC)
Subject: [R] Indexing lists
References: <79C6D1A4DD5E7B46B663C43C002123651458DC@mailer-e071.umh.es>
Message-ID: <loom.20040916T140650-77@post.gmane.org>

Perez Martin, Agustin <agustin.perez <at> umh.es> writes:


: I have a list with 500 elements, in each other there are data.frames and I
: want to take the first row and the first column of each elements of my list
: since the first to the 500-th.


Here are some variations depending on what you want.  Also try
all these with lapply replaced by sapply.

# test data
data(iris)
iris <- head(iris)
L <- list(iris, iris)

# various possibilities 
lapply(L, "[", 1, 1) # column 1, row 1
lapply(L, "[[", 1) # column 1 
lapply(L, "[", 1)  # column 1 as data frame
lapply(L, function(x) x[1,]) # row 1
lapply(L, function(x) list(x[1,],x[,1]))  # 2 el list with row 1 and column 1



From dmb at mrc-dunn.cam.ac.uk  Thu Sep 16 14:19:26 2004
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Thu, 16 Sep 2004 13:19:26 +0100 (BST)
Subject: [R] Conditionally swap two columns of a data.frame?
Message-ID: <Pine.LNX.4.21.0409161311360.8622-100000@mail.mrc-dunn.cam.ac.uk>


I am doing this a kinda dumb way, and it is apparetnly taking
forever.

I have a data frame with two numeric columns. I want to look at their
correlation, and I am looking at the size ratio between the two. 

i.e. 

plot(density(data$V1/data$V2))

This kinda gives me a normal curve showing something about the
distribution of the two values.

I want to make sure that V1/V2 is always > 1 ...

for (i in 1:length(row.names(data)) ){
  ratioV1V2 <- if(V1>V2) V1/V2 else V2/V1
}

This is a bit of a hack, and is taking forever for some reson (about
40,000 rows in my data.frame).

I would just like to swap the values in the data frame (to put the bigest
first for example), then use the above plot to get what I want.

Should I use the DB backend to the data to make the dump in this way?
(involves some hacky sql)

Considering I am interested in the range of the ratio between V1 and V2,
should I be looking at doing a different analysis?

I am so dumb, any help is appreciated,

Dan.



From ramasamy at cancer.org.uk  Thu Sep 16 14:15:25 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 16 Sep 2004 13:15:25 +0100
Subject: [R] Indexing lists
In-Reply-To: <79C6D1A4DD5E7B46B663C43C002123651458DC@mailer-e071.umh.es>
References: <79C6D1A4DD5E7B46B663C43C002123651458DC@mailer-e071.umh.es>
Message-ID: <1095336925.3034.3.camel@ndmpc126.ihs.ox.ac.uk>

m <- matrix(1:9, nc=3)
a <- list(m, m+10, m+100, m+1000)
sapply(a, function(mat) mat[1,1])
 [1]    1   11  101 1001


On Thu, 2004-09-16 at 12:33, Perez Martin, Agustin wrote:
> DeaR useRs:
>  
> I have a list with 500 elements, in each other there are data.frames and I
> want to take the first row and the first column of each elements of my list
> since the first to the 500-th.
>  
> Thanks and excuse my bad English.
> 
> ---
> 
> 
> 
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From vito.muggeo at giustizia.it  Thu Sep 16 14:21:53 2004
From: vito.muggeo at giustizia.it (Vito Muggeo)
Date: Thu, 16 Sep 2004 14:21:53 +0200
Subject: R: [R] Indexing lists
References: <79C6D1A4DD5E7B46B663C43C002123651458DC@mailer-e071.umh.es>
Message-ID: <00b501c49be7$c37cc060$5c13070a@PROCGEN>

Hi,
Probably it should be useful to obtain two "results" which you can combine
according to what you need. Here a possible solution:

a<-b<-data.frame(matrix(runif(30),10,3))
d<-list(a,b) #your list
#extract the 1st column. The output is a nrow(a)-by-length(d) matrix
sapply(d,function(x)x[,1])

#extract the 1st row. The output is a ncol(a)-by-length(d) matrix
sapply(d,function(x)x[1,]) #a ncol(a)-by-length(d) matrix

Note if the dimensions of dataframes are different you will get lists.
Anyway, if you prefer lists rather than matrices use lapply()

best,
vito


----- Original Message -----
From: Perez Martin, Agustin <agustin.perez at umh.es>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, September 16, 2004 1:33 PM
Subject: [R] Indexing lists


> DeaR useRs:
>
> I have a list with 500 elements, in each other there are data.frames and I
> want to take the first row and the first column of each elements of my
list
> since the first to the 500-th.
>
> Thanks and excuse my bad English.
>
> ---
>
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From chrodopoulos at mindshare.gr  Thu Sep 16 14:32:15 2004
From: chrodopoulos at mindshare.gr (Christos Rodopoulos)
Date: Thu, 16 Sep 2004 15:32:15 +0300
Subject: [R] How do I insert a newline in my title in a plot?
Message-ID: <BADBD2FA0E23CE4FB0C43B9DB62F1713108CBC@mant03.mindshare.gr>

 Hello, I want to help me with a simple I think question: How do I insert a
newline into the title of a plot I have made? 

 Is it only done with hershey fonts? vfont = ??? and so on? I do not
understand Hershey fonts, and I am afraid to use them, since I use greek
fonts (iso8859-7).

 I need propably something like: title("This is a title\nIn 2 lines");

 any help?



From dimitris.rizopoulos at med.kuleuven.ac.be  Thu Sep 16 14:34:00 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 16 Sep 2004 14:34:00 +0200
Subject: [R] Conditionally swap two columns of a data.frame?
References: <Pine.LNX.4.21.0409161311360.8622-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <003d01c49be9$711f52e0$b2133a86@www.domain>

Hi Dan,

do you need something like that,

dat <- data.frame(V1=rnorm(40000, 10), V2=rnorm(40000, 10))
ratioV1V2 <- ifelse(dat$V1>dat$V2, dat$V1/dat$V2, dat$V2/dat$V1)

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm

----- Original Message ----- 
From: "Dan Bolser" <dmb at mrc-dunn.cam.ac.uk>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, September 16, 2004 2:19 PM
Subject: [R] Conditionally swap two columns of a data.frame?


>
> I am doing this a kinda dumb way, and it is apparetnly taking
> forever.
>
> I have a data frame with two numeric columns. I want to look at
their
> correlation, and I am looking at the size ratio between the two.
>
> i.e.
>
> plot(density(data$V1/data$V2))
>
> This kinda gives me a normal curve showing something about the
> distribution of the two values.
>
> I want to make sure that V1/V2 is always > 1 ...
>
> for (i in 1:length(row.names(data)) ){
>   ratioV1V2 <- if(V1>V2) V1/V2 else V2/V1
> }
>
> This is a bit of a hack, and is taking forever for some reson (about
> 40,000 rows in my data.frame).
>
> I would just like to swap the values in the data frame (to put the
bigest
> first for example), then use the above plot to get what I want.
>
> Should I use the DB backend to the data to make the dump in this
way?
> (involves some hacky sql)
>
> Considering I am interested in the range of the ratio between V1 and
V2,
> should I be looking at doing a different analysis?
>
> I am so dumb, any help is appreciated,
>
> Dan.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Thu Sep 16 14:34:46 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Sep 2004 13:34:46 +0100 (BST)
Subject: [R] Conditionally swap two columns of a data.frame?
In-Reply-To: <Pine.LNX.4.21.0409161311360.8622-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <Pine.LNX.4.44.0409161331250.25162-100000@gannet.stats>

On Thu, 16 Sep 2004, Dan Bolser wrote:

> 
> I am doing this a kinda dumb way, and it is apparetnly taking
> forever.
> 
> I have a data frame with two numeric columns. I want to look at their
> correlation, and I am looking at the size ratio between the two. 
> 
> i.e. 
> 
> plot(density(data$V1/data$V2))
> 
> This kinda gives me a normal curve showing something about the
> distribution of the two values.
> 
> I want to make sure that V1/V2 is always > 1 ...
> 
> for (i in 1:length(row.names(data)) ){
>   ratioV1V2 <- if(V1>V2) V1/V2 else V2/V1
> }

data$ratioV1V2 <- ifelse(V1>V2, V1/V2, V2/V1) # or pmax(V1,V2)/pmin(V1, V2)

and either attach(data) or use inside with(data, ).

> This is a bit of a hack, and is taking forever for some reson (about
> 40,000 rows in my data.frame).

You appear to be doing a single calculation 40,000 times.  Did you not get 
a warning there?  (Maybe 40,000 warnings?)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmb at mrc-dunn.cam.ac.uk  Thu Sep 16 14:55:35 2004
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Thu, 16 Sep 2004 13:55:35 +0100 (BST)
Subject: [R] Conditionally swap two columns of a data.frame?
In-Reply-To: <003d01c49be9$711f52e0$b2133a86@www.domain>
Message-ID: <Pine.LNX.4.21.0409161355020.8622-100000@mail.mrc-dunn.cam.ac.uk>


Minter!

Is there an R cookbook? which lists this kind of common problem and common
solution?


On Thu, 16 Sep 2004, Dimitris Rizopoulos wrote:

>Hi Dan,
>
>do you need something like that,
>
>dat <- data.frame(V1=rnorm(40000, 10), V2=rnorm(40000, 10))
>ratioV1V2 <- ifelse(dat$V1>dat$V2, dat$V1/dat$V2, dat$V2/dat$V1)
>
>I hope it helps.
>
>Best,
>Dimitris
>
>----
>Dimitris Rizopoulos
>Ph.D. Student
>Biostatistical Centre
>School of Public Health
>Catholic University of Leuven
>
>Address: Kapucijnenvoer 35, Leuven, Belgium
>Tel: +32/16/396887
>Fax: +32/16/337015
>Web: http://www.med.kuleuven.ac.be/biostat/
>     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
>
>----- Original Message ----- 
>From: "Dan Bolser" <dmb at mrc-dunn.cam.ac.uk>
>To: <r-help at stat.math.ethz.ch>
>Sent: Thursday, September 16, 2004 2:19 PM
>Subject: [R] Conditionally swap two columns of a data.frame?
>
>
>>
>> I am doing this a kinda dumb way, and it is apparetnly taking
>> forever.
>>
>> I have a data frame with two numeric columns. I want to look at
>their
>> correlation, and I am looking at the size ratio between the two.
>>
>> i.e.
>>
>> plot(density(data$V1/data$V2))
>>
>> This kinda gives me a normal curve showing something about the
>> distribution of the two values.
>>
>> I want to make sure that V1/V2 is always > 1 ...
>>
>> for (i in 1:length(row.names(data)) ){
>>   ratioV1V2 <- if(V1>V2) V1/V2 else V2/V1
>> }
>>
>> This is a bit of a hack, and is taking forever for some reson (about
>> 40,000 rows in my data.frame).
>>
>> I would just like to swap the values in the data frame (to put the
>bigest
>> first for example), then use the above plot to get what I want.
>>
>> Should I use the DB backend to the data to make the dump in this
>way?
>> (involves some hacky sql)
>>
>> Considering I am interested in the range of the ratio between V1 and
>V2,
>> should I be looking at doing a different analysis?
>>
>> I am so dumb, any help is appreciated,
>>
>> Dan.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>http://www.R-project.org/posting-guide.html
>>
>



From abunn at whrc.org  Thu Sep 16 14:51:17 2004
From: abunn at whrc.org (Andy Bunn)
Date: Thu, 16 Sep 2004 08:51:17 -0400
Subject: [R] Conditionally swap two columns of a data.frame?
Message-ID: <NEBBIPHDAMMOKDKPOFFIKECHCJAA.abunn@whrc.org>


ifelse accomplishes this pretty easily (at least I think it does what you
want)

Look at ?apply too.

HTH, Andy


## Try this
foo.dat <- data.frame(Var1 = rnorm(40000, 1, 1),
                      Var2 = (rnorm(40000, 1, 1) * 0.25))
plot(density(foo.dat$Var1 / foo.dat$Var2))

RatioOne <- ifelse(foo.dat$Var1 > foo.dat$Var2,
                   foo.dat$Var1 / foo.dat$Var2,
                   foo.dat$Var2 / foo.dat$Var1)

RatioTwo <- numeric()
for (i in 1:nrow(foo.dat)) {
  RatioTwo[i] <- if(foo.dat$Var1[i] > foo.dat$Var2[i]) foo.dat$Var1[i] /
foo.dat$Var2[i]
                 else foo.dat$Var2[i] / foo.dat$Var1[i]
}
cor(RatioOne, RatioTwo)



From dimitris.rizopoulos at med.kuleuven.ac.be  Thu Sep 16 14:56:37 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 16 Sep 2004 14:56:37 +0200
Subject: [R] Conditionally swap two columns of a data.frame?
References: <Pine.LNX.4.21.0409161355020.8622-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <008101c49bec$9a165b00$b2133a86@www.domain>

type "help.start()" in the R console or open manually the "C:\Program
Files\R\rw1091\doc\html\rwin.html" file and you will get all the
available on-line documentation that ships with each R installation.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Dan Bolser" <dmb at mrc-dunn.cam.ac.uk>
To: "Dimitris Rizopoulos" <dimitris.rizopoulos at med.kuleuven.ac.be>
Cc: <r-help at stat.math.ethz.ch>
Sent: Thursday, September 16, 2004 2:55 PM
Subject: Re: [R] Conditionally swap two columns of a data.frame?


>
> Minter!
>
> Is there an R cookbook? which lists this kind of common problem and
common
> solution?
>
>
> On Thu, 16 Sep 2004, Dimitris Rizopoulos wrote:
>
> >Hi Dan,
> >
> >do you need something like that,
> >
> >dat <- data.frame(V1=rnorm(40000, 10), V2=rnorm(40000, 10))
> >ratioV1V2 <- ifelse(dat$V1>dat$V2, dat$V1/dat$V2, dat$V2/dat$V1)
> >
> >I hope it helps.
> >
> >Best,
> >Dimitris
> >
> >----
> >Dimitris Rizopoulos
> >Ph.D. Student
> >Biostatistical Centre
> >School of Public Health
> >Catholic University of Leuven
> >
> >Address: Kapucijnenvoer 35, Leuven, Belgium
> >Tel: +32/16/396887
> >Fax: +32/16/337015
> >Web: http://www.med.kuleuven.ac.be/biostat/
> >     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
> >
> >----- Original Message ----- 
> >From: "Dan Bolser" <dmb at mrc-dunn.cam.ac.uk>
> >To: <r-help at stat.math.ethz.ch>
> >Sent: Thursday, September 16, 2004 2:19 PM
> >Subject: [R] Conditionally swap two columns of a data.frame?
> >
> >
> >>
> >> I am doing this a kinda dumb way, and it is apparetnly taking
> >> forever.
> >>
> >> I have a data frame with two numeric columns. I want to look at
> >their
> >> correlation, and I am looking at the size ratio between the two.
> >>
> >> i.e.
> >>
> >> plot(density(data$V1/data$V2))
> >>
> >> This kinda gives me a normal curve showing something about the
> >> distribution of the two values.
> >>
> >> I want to make sure that V1/V2 is always > 1 ...
> >>
> >> for (i in 1:length(row.names(data)) ){
> >>   ratioV1V2 <- if(V1>V2) V1/V2 else V2/V1
> >> }
> >>
> >> This is a bit of a hack, and is taking forever for some reson
(about
> >> 40,000 rows in my data.frame).
> >>
> >> I would just like to swap the values in the data frame (to put
the
> >bigest
> >> first for example), then use the above plot to get what I want.
> >>
> >> Should I use the DB backend to the data to make the dump in this
> >way?
> >> (involves some hacky sql)
> >>
> >> Considering I am interested in the range of the ratio between V1
and
> >V2,
> >> should I be looking at doing a different analysis?
> >>
> >> I am so dumb, any help is appreciated,
> >>
> >> Dan.
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide!
> >http://www.R-project.org/posting-guide.html
> >>
> >
>



From chrodopoulos at mindshare.gr  Thu Sep 16 15:00:10 2004
From: chrodopoulos at mindshare.gr (Christos Rodopoulos)
Date: Thu, 16 Sep 2004 16:00:10 +0300
Subject: FW: [R] How do I insert a newline in my title in a plot?
Message-ID: <BADBD2FA0E23CE4FB0C43B9DB62F1713108CBD@mant03.mindshare.gr>


yes I have tries, and nothing. It just shows the strings with the slashn,
just like i typed it.
-----Original Message-----
From: Rashid Nassar [mailto:rnassar at duke.edu]
Sent: ÐÝì?ôç, 16 Óå?ôåìâñßïõ 2004 15:44
To: Christos Rodopoulos
Subject: Re: [R] How do I insert a newline in my title in a plot?


Have you not tried what you have already suggested:

   title("this is a title\nIn 2 lines")
?


On Thu, 16 Sep 2004, Christos Rodopoulos wrote:

>  Hello, I want to help me with a simple I think question: How do I insert
a
> newline into the title of a plot I have made?
>
>  Is it only done with hershey fonts? vfont = ??? and so on? I do not
> understand Hershey fonts, and I am afraid to use them, since I use greek
> fonts (iso8859-7).
>
>  I need propably something like: title("This is a title\nIn 2 lines");
>
>  any help?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From abunn at whrc.org  Thu Sep 16 14:58:40 2004
From: abunn at whrc.org (Andy Bunn)
Date: Thu, 16 Sep 2004 08:58:40 -0400
Subject: [R] How do I insert a newline in my title in a plot?
In-Reply-To: <BADBD2FA0E23CE4FB0C43B9DB62F1713108CBC@mant03.mindshare.gr>
Message-ID: <NEBBIPHDAMMOKDKPOFFICECICJAA.abunn@whrc.org>

You had it.

plot(1:5, main = "This is a title\nIn 2 lines")

HTH, Andy



From dmb at mrc-dunn.cam.ac.uk  Thu Sep 16 15:05:55 2004
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Thu, 16 Sep 2004 14:05:55 +0100 (BST)
Subject: [R] Conditionally swap two columns of a data.frame?
In-Reply-To: <Pine.LNX.4.44.0409161331250.25162-100000@gannet.stats>
Message-ID: <Pine.LNX.4.21.0409161356070.8622-100000@mail.mrc-dunn.cam.ac.uk>

On Thu, 16 Sep 2004, Prof Brian Ripley wrote:

>On Thu, 16 Sep 2004, Dan Bolser wrote:
>
>> 
>> I am doing this a kinda dumb way, and it is apparetnly taking
>> forever.
>> 
>> I have a data frame with two numeric columns. I want to look at their
>> correlation, and I am looking at the size ratio between the two. 
>> 
>> i.e. 
>> 
>> plot(density(data$V1/data$V2))
>> 
>> This kinda gives me a normal curve showing something about the
>> distribution of the two values.
>> 
>> I want to make sure that V1/V2 is always > 1 ...
>> 
>> for (i in 1:length(row.names(data)) ){
>>   ratioV1V2 <- if(V1>V2) V1/V2 else V2/V1
>> }
>
>data$ratioV1V2 <- ifelse(V1>V2, V1/V2, V2/V1) # or pmax(V1,V2)/pmin(V1, V2)
>
>and either attach(data) or use inside with(data, ).
>
>> This is a bit of a hack, and is taking forever for some reson (about
>> 40,000 rows in my data.frame).
>
>You appear to be doing a single calculation 40,000 times.  Did you not get 
>a warning there?  (Maybe 40,000 warnings?)

I don't know what happened.. I think R or emacs got stuck and crashed...

Here is my exact code...

# Read data
interface <- read.table("Data/interface_data", header = TRUE,
row.names="ROW")

About 40,000 rows...

# Sort the pairs...
interfaceRatio <- NULL

for(i in 1:length(row.names(interface))){
  interfaceRatio[i] <-
    if(interface[i,]$C1 > interface[i,]$C2)
      interface[i,]$C2 / interface[i,]$C1
    else
      interface[i,]$C1 / interface[i,]$C2
}

This never finishes (in the lifetime of my patience).

Sorry if this is garbeled junk - I am slow to understand the principals of
the R data structures.

Looking up values from a data.frame is most of what I never remember about
R.


Thanks for the ifelse.

Dan.

>
>



From dmb at mrc-dunn.cam.ac.uk  Thu Sep 16 15:12:17 2004
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Thu, 16 Sep 2004 14:12:17 +0100 (BST)
Subject: [R] Conditionally swap two columns of a data.frame?
In-Reply-To: <008101c49bec$9a165b00$b2133a86@www.domain>
Message-ID: <Pine.LNX.4.21.0409161411530.8622-100000@mail.mrc-dunn.cam.ac.uk>

On Thu, 16 Sep 2004, Dimitris Rizopoulos wrote:

>type "help.start()" in the R console or open manually the "C:\Program
>Files\R\rw1091\doc\html\rwin.html" file and you will get all the
>available on-line documentation that ships with each R installation.

That is the problem, you get it all ;)

Thanks though,
Dan.

>
>Best,
>Dimitris
>
>----
>Dimitris Rizopoulos
>Ph.D. Student
>Biostatistical Centre
>School of Public Health
>Catholic University of Leuven
>
>Address: Kapucijnenvoer 35, Leuven, Belgium
>Tel: +32/16/396887
>Fax: +32/16/337015
>Web: http://www.med.kuleuven.ac.be/biostat/
>     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
>
>
>----- Original Message ----- 
>From: "Dan Bolser" <dmb at mrc-dunn.cam.ac.uk>
>To: "Dimitris Rizopoulos" <dimitris.rizopoulos at med.kuleuven.ac.be>
>Cc: <r-help at stat.math.ethz.ch>
>Sent: Thursday, September 16, 2004 2:55 PM
>Subject: Re: [R] Conditionally swap two columns of a data.frame?
>
>
>>
>> Minter!
>>
>> Is there an R cookbook? which lists this kind of common problem and
>common
>> solution?
>>
>>
>> On Thu, 16 Sep 2004, Dimitris Rizopoulos wrote:
>>
>> >Hi Dan,
>> >
>> >do you need something like that,
>> >
>> >dat <- data.frame(V1=rnorm(40000, 10), V2=rnorm(40000, 10))
>> >ratioV1V2 <- ifelse(dat$V1>dat$V2, dat$V1/dat$V2, dat$V2/dat$V1)
>> >
>> >I hope it helps.
>> >
>> >Best,
>> >Dimitris
>> >
>> >----
>> >Dimitris Rizopoulos
>> >Ph.D. Student
>> >Biostatistical Centre
>> >School of Public Health
>> >Catholic University of Leuven
>> >
>> >Address: Kapucijnenvoer 35, Leuven, Belgium
>> >Tel: +32/16/396887
>> >Fax: +32/16/337015
>> >Web: http://www.med.kuleuven.ac.be/biostat/
>> >     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
>> >
>> >----- Original Message ----- 
>> >From: "Dan Bolser" <dmb at mrc-dunn.cam.ac.uk>
>> >To: <r-help at stat.math.ethz.ch>
>> >Sent: Thursday, September 16, 2004 2:19 PM
>> >Subject: [R] Conditionally swap two columns of a data.frame?
>> >
>> >
>> >>
>> >> I am doing this a kinda dumb way, and it is apparetnly taking
>> >> forever.
>> >>
>> >> I have a data frame with two numeric columns. I want to look at
>> >their
>> >> correlation, and I am looking at the size ratio between the two.
>> >>
>> >> i.e.
>> >>
>> >> plot(density(data$V1/data$V2))
>> >>
>> >> This kinda gives me a normal curve showing something about the
>> >> distribution of the two values.
>> >>
>> >> I want to make sure that V1/V2 is always > 1 ...
>> >>
>> >> for (i in 1:length(row.names(data)) ){
>> >>   ratioV1V2 <- if(V1>V2) V1/V2 else V2/V1
>> >> }
>> >>
>> >> This is a bit of a hack, and is taking forever for some reson
>(about
>> >> 40,000 rows in my data.frame).
>> >>
>> >> I would just like to swap the values in the data frame (to put
>the
>> >bigest
>> >> first for example), then use the above plot to get what I want.
>> >>
>> >> Should I use the DB backend to the data to make the dump in this
>> >way?
>> >> (involves some hacky sql)
>> >>
>> >> Considering I am interested in the range of the ratio between V1
>and
>> >V2,
>> >> should I be looking at doing a different analysis?
>> >>
>> >> I am so dumb, any help is appreciated,
>> >>
>> >> Dan.
>> >>
>> >> ______________________________________________
>> >> R-help at stat.math.ethz.ch mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide!
>> >http://www.R-project.org/posting-guide.html
>> >>
>> >
>>
>



From P.Lemmens at nici.ru.nl  Thu Sep 16 15:13:14 2004
From: P.Lemmens at nici.ru.nl (Paul Lemmens)
Date: Thu, 16 Sep 2004 15:13:14 +0200
Subject: [R] Conditionally swap two columns of a data.frame?
In-Reply-To: <Pine.LNX.4.21.0409161355020.8622-100000@mail.mrc-dunn.cam.ac.uk>
References: <Pine.LNX.4.21.0409161355020.8622-100000@mail.mrc-dunn.cam.ac.uk >
Message-ID: <D9B1AEE838A5D5962D6E052D@lemmens.socsci.kun.nl>

Hoi Dan,

--On donderdag 16 september 2004 13:55 +0100 Dan Bolser 
<dmb at mrc-dunn.cam.ac.uk> wrote:

> Is there an R cookbook?
>
Yes there is (sort of): StatsRus <http://www.ku.edu/~pauljohn/R/Rtips.html>

kind regards,
Paul



-- 
Paul Lemmens
NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
Montessorilaan 3 (B.01.05)                    Against HTML Mail \ /
NL-6525 HR Nijmegen                                              X
The Netherlands                                                 / \
Phonenumber    +31-24-3612648
Fax            +31-24-3616066



From P.Lemmens at nici.ru.nl  Thu Sep 16 15:21:18 2004
From: P.Lemmens at nici.ru.nl (Paul Lemmens)
Date: Thu, 16 Sep 2004 15:21:18 +0200
Subject: FW: [R] How do I insert a newline in my title in a plot?
In-Reply-To: <BADBD2FA0E23CE4FB0C43B9DB62F1713108CBD@mant03.mindshare.gr>
References: <BADBD2FA0E23CE4FB0C43B9DB62F1713108CBD@mant03.mindshare.gr>
Message-ID: <9195375B268086D356188D9F@lemmens.socsci.kun.nl>

Hoi Christos,

--On donderdag 16 september 2004 16:00 +0300 Christos Rodopoulos 
<chrodopoulos at mindshare.gr> wrote:

> yes I have tries, and nothing. It just shows the strings with the slashn,
> just like i typed it.
> -----Original Message-----
> From: Rashid Nassar [mailto:rnassar at duke.edu]
> Sent: ???????????, 16 ????????????????????? 2004 15:44
> To: Christos Rodopoulos
> Subject: Re: [R] How do I insert a newline in my title in a plot?
>
>
> Have you not tried what you have already suggested:
>
>    title("this is a title\nIn 2 lines")
> ?
>
I've tried it out and you should use single quotes, then it'll work.

So it's an interpretation matter. Unfortunately I cannot figure out the 
help page dealing with this :-/

kind regards,
Paul


-- 
Paul Lemmens
NICI, University of Nijmegen              ASCII Ribbon Campaign /"\
Montessorilaan 3 (B.01.05)                    Against HTML Mail \ /
NL-6525 HR Nijmegen                                              X
The Netherlands                                                 / \
Phonenumber    +31-24-3612648
Fax            +31-24-3616066



From wolski at molgen.mpg.de  Thu Sep 16 15:23:05 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 16 Sep 2004 15:23:05 +0200
Subject: [R] Conditionally swap two columns of a data.frame?
In-Reply-To: <Pine.LNX.4.21.0409161355020.8622-100000@mail.mrc-dunn.cam.ac.uk>
References: <Pine.LNX.4.21.0409161355020.8622-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <200409161523050365.012FB4FC@mail.math.fu-berlin.de>

Hi!
Better then a cookbook.
http://www.ku.edu/~pauljohn/R/Rtips.html

/E
Ps.


*********** REPLY SEPARATOR  ***********

On 9/16/2004 at 1:55 PM Dan Bolser wrote:

>>>Minter!
>>>
>>>Is there an R cookbook? which lists this kind of common problem and
>>>common
>>>solution?
>>>
>>>
>>>On Thu, 16 Sep 2004, Dimitris Rizopoulos wrote:
>>>
>>>>Hi Dan,
>>>>
>>>>do you need something like that,
>>>>
>>>>dat <- data.frame(V1=rnorm(40000, 10), V2=rnorm(40000, 10))
>>>>ratioV1V2 <- ifelse(dat$V1>dat$V2, dat$V1/dat$V2, dat$V2/dat$V1)
>>>>
>>>>I hope it helps.
>>>>
>>>>Best,
>>>>Dimitris
>>>>
>>>>----
>>>>Dimitris Rizopoulos
>>>>Ph.D. Student
>>>>Biostatistical Centre
>>>>School of Public Health
>>>>Catholic University of Leuven
>>>>
>>>>Address: Kapucijnenvoer 35, Leuven, Belgium
>>>>Tel: +32/16/396887
>>>>Fax: +32/16/337015
>>>>Web: http://www.med.kuleuven.ac.be/biostat/
>>>>     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
>>>>
>>>>----- Original Message ----- 
>>>>From: "Dan Bolser" <dmb at mrc-dunn.cam.ac.uk>
>>>>To: <r-help at stat.math.ethz.ch>
>>>>Sent: Thursday, September 16, 2004 2:19 PM
>>>>Subject: [R] Conditionally swap two columns of a data.frame?
>>>>
>>>>
>>>>>
>>>>> I am doing this a kinda dumb way, and it is apparetnly taking
>>>>> forever.
>>>>>
>>>>> I have a data frame with two numeric columns. I want to look at
>>>>their
>>>>> correlation, and I am looking at the size ratio between the two.
>>>>>
>>>>> i.e.
>>>>>
>>>>> plot(density(data$V1/data$V2))
>>>>>
>>>>> This kinda gives me a normal curve showing something about the
>>>>> distribution of the two values.
>>>>>
>>>>> I want to make sure that V1/V2 is always > 1 ...
>>>>>
>>>>> for (i in 1:length(row.names(data)) ){
>>>>>   ratioV1V2 <- if(V1>V2) V1/V2 else V2/V1
>>>>> }
>>>>>
>>>>> This is a bit of a hack, and is taking forever for some reson (about
>>>>> 40,000 rows in my data.frame).
>>>>>
>>>>> I would just like to swap the values in the data frame (to put the
>>>>bigest
>>>>> first for example), then use the above plot to get what I want.
>>>>>
>>>>> Should I use the DB backend to the data to make the dump in this
>>>>way?
>>>>> (involves some hacky sql)
>>>>>
>>>>> Considering I am interested in the range of the ratio between V1 and
>>>>V2,
>>>>> should I be looking at doing a different analysis?
>>>>>
>>>>> I am so dumb, any help is appreciated,
>>>>>
>>>>> Dan.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at stat.math.ethz.ch mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide!
>>>>http://www.R-project.org/posting-guide.html
>>>>>
>>>>
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin                'v'    
tel: 0049-30-83875219                        /   \       
mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
      wolski at molgen.mpg.de



From jfox at mcmaster.ca  Thu Sep 16 15:24:50 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 16 Sep 2004 09:24:50 -0400
Subject: [R] How do I insert a newline in my title in a plot?
In-Reply-To: <BADBD2FA0E23CE4FB0C43B9DB62F1713108CBD@mant03.mindshare.gr>
Message-ID: <20040916132450.RUKB29920.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Christos,

This works for me, and has many times in the past. Is it possible that you
used a forward-slash (/), rather than a back-slash (\)? Alternatively,
perhaps this has something to do with using Greek fonts.

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Christos Rodopoulos
> Sent: Thursday, September 16, 2004 8:00 AM
> To: 'R-help at stat.math.ethz.ch'
> Subject: FW: [R] How do I insert a newline in my title in a plot?
> 
> 
> yes I have tries, and nothing. It just shows the strings with 
> the slashn, just like i typed it.
> -----Original Message-----
> From: Rashid Nassar [mailto:rnassar at duke.edu]
> Sent: ÐÝì?ôç, 16 Óå?ôåìâñßïõ 2004 15:44
> To: Christos Rodopoulos
> Subject: Re: [R] How do I insert a newline in my title in a plot?
> 
> 
> Have you not tried what you have already suggested:
> 
>    title("this is a title\nIn 2 lines")
> ?
> 
> 
> On Thu, 16 Sep 2004, Christos Rodopoulos wrote:
> 
> >  Hello, I want to help me with a simple I think question: How do I 
> > insert
> a
> > newline into the title of a plot I have made?
> >
> >  Is it only done with hershey fonts? vfont = ??? and so on? 
> I do not 
> > understand Hershey fonts, and I am afraid to use them, since I use 
> > greek fonts (iso8859-7).
> >
> >  I need propably something like: title("This is a title\nIn 
> 2 lines");
> >
> >  any help?
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Thu Sep 16 15:26:50 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Sep 2004 14:26:50 +0100 (BST)
Subject: FW: [R] How do I insert a newline in my title in a plot?
In-Reply-To: <BADBD2FA0E23CE4FB0C43B9DB62F1713108CBD@mant03.mindshare.gr>
Message-ID: <Pine.LNX.4.44.0409161423570.25379-100000@gannet.stats>

On Thu, 16 Sep 2004, Christos Rodopoulos wrote:

> 
> yes I have tries, and nothing. It just shows the strings with the slashn,
> just like i typed it.

Please consult the R posting guide and give us some basic information
such as version of R, platform, graphics device and so on.

> plot(1:10)
> title("this is a title\nIn 2 lines")

should work, and does for me on Windows and Linux.  I dimly remember it
did not on a Mac at one point.


> -----Original Message-----
> From: Rashid Nassar [mailto:rnassar at duke.edu]
> Sent: ???????????, 16 ????????????????????? 2004 15:44
> To: Christos Rodopoulos
> Subject: Re: [R] How do I insert a newline in my title in a plot?
> 
> 
> Have you not tried what you have already suggested:
> 
>    title("this is a title\nIn 2 lines")
> ?
> 
> 
> On Thu, 16 Sep 2004, Christos Rodopoulos wrote:
> 
> >  Hello, I want to help me with a simple I think question: How do I insert
> a
> > newline into the title of a plot I have made?
> >
> >  Is it only done with hershey fonts? vfont = ??? and so on? I do not
> > understand Hershey fonts, and I am afraid to use them, since I use greek
> > fonts (iso8859-7).
> >
> >  I need propably something like: title("This is a title\nIn 2 lines");
> >
> >  any help?
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From chrodopoulos at mindshare.gr  Thu Sep 16 15:34:21 2004
From: chrodopoulos at mindshare.gr (Christos Rodopoulos)
Date: Thu, 16 Sep 2004 16:34:21 +0300
Subject: FW: FW: [R] How do I insert a newline in my title in a plot?
Message-ID: <BADBD2FA0E23CE4FB0C43B9DB62F1713108CBE@mant03.mindshare.gr>


platform: Linux Mandrake 10.0 AMD processor, X11 graphics with XFree latest,
R version 1.9.1 home-compiled.

 
-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: ??????, 16 ??????????? 2004 16:27
To: Christos Rodopoulos
Cc: 'R-help at stat.math.ethz.ch'
Subject: Re: FW: [R] How do I insert a newline in my title in a plot?


On Thu, 16 Sep 2004, Christos Rodopoulos wrote:

> 
> yes I have tries, and nothing. It just shows the strings with the slashn,
> just like i typed it.

Please consult the R posting guide and give us some basic information
such as version of R, platform, graphics device and so on.

> plot(1:10)
> title("this is a title\nIn 2 lines")

should work, and does for me on Windows and Linux.  I dimly remember it
did not on a Mac at one point.


> -----Original Message-----
> From: Rashid Nassar [mailto:rnassar at duke.edu]
> Sent: ???????????, 16 ????????????????????? 2004 15:44
> To: Christos Rodopoulos
> Subject: Re: [R] How do I insert a newline in my title in a plot?
> 
> 
> Have you not tried what you have already suggested:
> 
>    title("this is a title\nIn 2 lines")
> ?
> 
> 
> On Thu, 16 Sep 2004, Christos Rodopoulos wrote:
> 
> >  Hello, I want to help me with a simple I think question: How do I
insert
> a
> > newline into the title of a plot I have made?
> >
> >  Is it only done with hershey fonts? vfont = ??? and so on? I do not
> > understand Hershey fonts, and I am afraid to use them, since I use greek
> > fonts (iso8859-7).
> >
> >  I need propably something like: title("This is a title\nIn 2 lines");
> >
> >  any help?
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From chrodopoulos at mindshare.gr  Thu Sep 16 15:48:44 2004
From: chrodopoulos at mindshare.gr (Christos Rodopoulos)
Date: Thu, 16 Sep 2004 16:48:44 +0300
Subject: FW: [R] How do I insert a newline in my title in a plot?
Message-ID: <BADBD2FA0E23CE4FB0C43B9DB62F1713108CBF@mant03.mindshare.gr>


Thank you very much! I should have known...

 well, to inform you, this is the case:
 
  The problem was of a friend of mine, told to me me by phone.
  From the begining I was telling my friend BYPHONE .... to do this:

title("This is a title\nIn 2 lines")

 but my friend understood and did all the time this:

title("This is a title/nIn 2 lines").

 but it is my problem too:
 the problem is that I say slash and I mean backslash, or vice cersa (!) So
the phone-confusion occured, and I 
was reporting a problem which does not exist!

thank you all for your help. Thanks from my friend too, and sorry for the
confusion I created.
-----Original Message-----
From: John Fox [mailto:jfox at mcmaster.ca]
Sent: ÐÝì?ôç, 16 Óå?ôåìâñßïõ 2004 16:25
To: 'Christos Rodopoulos'
Cc: R-help at stat.math.ethz.ch
Subject: RE: [R] How do I insert a newline in my title in a plot?


Dear Christos,

This works for me, and has many times in the past. Is it possible that you
used a forward-slash (/), rather than a back-slash (\)? Alternatively,
perhaps this has something to do with using Greek fonts.

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Christos Rodopoulos
> Sent: Thursday, September 16, 2004 8:00 AM
> To: 'R-help at stat.math.ethz.ch'
> Subject: FW: [R] How do I insert a newline in my title in a plot?
> 
> 
> yes I have tries, and nothing. It just shows the strings with 
> the slashn, just like i typed it.
> -----Original Message-----
> From: Rashid Nassar [mailto:rnassar at duke.edu]
> Sent: ÐÝì?ôç, 16 Óå?ôåìâñßïõ 2004 15:44
> To: Christos Rodopoulos
> Subject: Re: [R] How do I insert a newline in my title in a plot?
> 
> 
> Have you not tried what you have already suggested:
> 
>    title("this is a title\nIn 2 lines")
> ?
> 
> 
> On Thu, 16 Sep 2004, Christos Rodopoulos wrote:
> 
> >  Hello, I want to help me with a simple I think question: How do I 
> > insert
> a
> > newline into the title of a plot I have made?
> >
> >  Is it only done with hershey fonts? vfont = ??? and so on? 
> I do not 
> > understand Hershey fonts, and I am afraid to use them, since I use 
> > greek fonts (iso8859-7).
> >
> >  I need propably something like: title("This is a title\nIn 
> 2 lines");
> >
> >  any help?
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Thu Sep 16 16:15:59 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Sep 2004 15:15:59 +0100 (BST)
Subject: FW: [R] How do I insert a newline in my title in a plot?
In-Reply-To: <9195375B268086D356188D9F@lemmens.socsci.kun.nl>
Message-ID: <Pine.LNX.4.44.0409161512170.25422-100000@gannet.stats>

On Thu, 16 Sep 2004, Paul Lemmens wrote:

> Hoi Christos,
> 
> --On donderdag 16 september 2004 16:00 +0300 Christos Rodopoulos 
> <chrodopoulos at mindshare.gr> wrote:
> 
> > yes I have tries, and nothing. It just shows the strings with the slashn,
> > just like i typed it.
> > -----Original Message-----
> > From: Rashid Nassar [mailto:rnassar at duke.edu]
> > Sent: ???????????, 16 ????????????????????? 2004 15:44
> > To: Christos Rodopoulos
> > Subject: Re: [R] How do I insert a newline in my title in a plot?
> >
> >
> > Have you not tried what you have already suggested:
> >
> >    title("this is a title\nIn 2 lines")
> > ?
> >
> I've tried it out and you should use single quotes, then it'll work.

At least inside R single and double quotes are equivalent.

> So it's an interpretation matter. Unfortunately I cannot figure out the 
> help page dealing with this :-/

That's because it's in R-lang:

String constants are delimited by a pair of single (@samp{'}) or double
(@samp{"}) quotes and can contain all other printable characters.
Quotes and other special characters within strings are specified using
@emph{escape sequences}:

A single quote may also be embedded directly in a double-quote delimited
string and vice versa.


It is possible that a front-end processor is interfering here, and so what 
is typed is not reaching R unchanged.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From smestrella at juno.com  Thu Sep 16 16:16:10 2004
From: smestrella at juno.com (smestrella@juno.com)
Date: Thu, 16 Sep 2004 14:16:10 GMT
Subject: [R] date library and notched boxplots
Message-ID: <20040916.071641.3306.851460@webmail11.lax.untd.com>


I'm having problems using the date library with notched boxplots.  I have separate month, day, and year columns and would like to plot the columns as a date against other variables.  I have used the mdy.date(month,day,year) command before with plot(), but it doesn't seem to work with boxplot().  Instead of the dates along the x-axis, I get a list of numbers.  Maybe I have the code wrong?  I have used the help() menu in R, but with no success.

Can somebody please help?

Thanks,
Stephanie



From Luisr at frs.fo  Thu Sep 16 16:28:13 2004
From: Luisr at frs.fo (Luis Rideau Cruz)
Date: Thu, 16 Sep 2004 15:28:13 +0100
Subject: [R] Multi-dimensional scaling
Message-ID: <s149b111.018@ffdata.setur.fo>

R-help,

Is there any package/function in R which can perform multi-dimensional
scaling?

Thank you in advance



From ccleland at optonline.net  Thu Sep 16 16:35:16 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 16 Sep 2004 10:35:16 -0400
Subject: [R] Multi-dimensional scaling
In-Reply-To: <s149b111.018@ffdata.setur.fo>
References: <s149b111.018@ffdata.setur.fo>
Message-ID: <4149A4A4.7050303@optonline.net>

  As recently discussed on this list, it's useful to search for 
functionality using the help.search() function. 

help.search("multidimensional scaling")


Luis Rideau Cruz wrote:

>R-help,
>
>Is there any package/function in R which can perform multi-dimensional
>scaling?
>
>Thank you in advance
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>

-- 
Chuck Cleland, Ph.D. 
NDRI, Inc. 
71 West 23rd Street, 8th floor 
New York, NY 10010 
tel: (212) 845-4495 (Tu, Th) 
tel: (732) 452-1424 (M, W, F) 
fax: (917) 438-0894



From ligges at statistik.uni-dortmund.de  Thu Sep 16 16:39:37 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 16 Sep 2004 16:39:37 +0200
Subject: [R] Multi-dimensional scaling
In-Reply-To: <s149b111.018@ffdata.setur.fo>
References: <s149b111.018@ffdata.setur.fo>
Message-ID: <4149A5A9.7060904@statistik.uni-dortmund.de>

Luis Rideau Cruz wrote:

> R-help,
> 
> Is there any package/function in R which can perform multi-dimensional
> scaling?

I'd look at the results given by

   help.search("multi-dimensional scaling")


Uwe Ligges



> Thank you in advance
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sdavis2 at mail.nih.gov  Thu Sep 16 16:41:43 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 16 Sep 2004 10:41:43 -0400
Subject: [R] Multi-dimensional scaling
In-Reply-To: <s149b111.018@ffdata.setur.fo>
References: <s149b111.018@ffdata.setur.fo>
Message-ID: <872B5DC8-07EE-11D9-ABE6-000A95D7BA10@mail.nih.gov>

see ?cmdscale

Sean

On Sep 16, 2004, at 10:28 AM, Luis Rideau Cruz wrote:

> R-help,
>
> Is there any package/function in R which can perform multi-dimensional
> scaling?
>
> Thank you in advance
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From wolski at molgen.mpg.de  Thu Sep 16 16:41:05 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 16 Sep 2004 16:41:05 +0200
Subject: [R] Multi-dimensional scaling
In-Reply-To: <s149b111.018@ffdata.setur.fo>
References: <s149b111.018@ffdata.setur.fo>
Message-ID: <200409161641050178.01771C78@mail.math.fu-berlin.de>

See:

www.r-project.org -> Documentation->Newsletter->Volume 3/3, December 2003

There is an artikle by Jonathan Edwards and Paul Oman
"Dimensional Reduction for Data Mapping"

/E


*********** REPLY SEPARATOR  ***********

On 9/16/2004 at 3:28 PM Luis Rideau Cruz wrote:

>>>R-help,
>>>
>>>Is there any package/function in R which can perform multi-dimensional
>>>scaling?
>>>
>>>Thank you in advance
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin                'v'    
tel: 0049-30-83875219                        /   \       
mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
      wolski at molgen.mpg.de



From jarioksa at sun3.oulu.fi  Thu Sep 16 16:43:00 2004
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 16 Sep 2004 17:43:00 +0300
Subject: [R] Multi-dimensional scaling
In-Reply-To: <s149b111.018@ffdata.setur.fo>
References: <s149b111.018@ffdata.setur.fo>
Message-ID: <1095345779.22643.5.camel@biol102145.oulu.fi>

On Thu, 2004-09-16 at 17:28, Luis Rideau Cruz wrote:

> Is there any package/function in R which can perform multi-dimensional
> scaling?
> 
Yes.

Ripley's MASS package has isoMDS for non-metric multidimensional
scaling. Moreover, the same package has function sammon for another
variant. Some people regard SOM as a "crude form of" multidimensional
scalling, and that is -- surprise -- in MASS, too (but there are other
implementations). Vasic R (or its stats component) has principal
co-ordinates analysis, a.k.a. as metric multidimensional scaling.
Finally, R has a utility help.search which would show you most of these
and something else, too (perhaps xgvis in the xgobi, if that's installed
in your system). Try help.search("multidimensional scaling").

cheers, jari oksane
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>



From ggrothendieck at myway.com  Thu Sep 16 16:44:14 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 16 Sep 2004 14:44:14 +0000 (UTC)
Subject: [R] date library and notched boxplots
References: <20040916.071641.3306.851460@webmail11.lax.untd.com>
Message-ID: <loom.20040916T163411-125@post.gmane.org>

smestrella <at> juno.com <smestrella <at> juno.com> writes:

: 
: I'm having problems using the date library with notched boxplots.  I have 
separate month, day, and year
: columns and would like to plot the columns as a date against other 
variables.  I have used the
: mdy.date(month,day,year) command before with plot(), but it doesn't seem to 
work with boxplot(). 
: Instead of the dates along the x-axis, I get a list of numbers.  Maybe I 
have the code wrong?  I have used the
: help() menu in R, but with no success.
: 
: Can somebody please help?

I think the reason no one is responding to your posts is that (1) not
many people use the date class (try using the Date class instead)
and (2) you are not providing a small reproduceable example of your
code together with the associated data so no one really knows the 
specifics of your problem.   There is a link to the posting guide
at the bottom of each post.



From ferri.leberl at gmx.at  Thu Sep 16 16:52:03 2004
From: ferri.leberl at gmx.at (Mag. Ferri Leberl)
Date: Thu, 16 Sep 2004 16:52:03 +0200
Subject: [R] There were 50 or more warnings (use warnings() to see the first
	50)
Message-ID: <200409161652.03053.ferri.leberl@gmx.at>

I employ R in the Slave-Mode.
The slave returns me the following feedback:

There were 50 or more warnings (use warnings() to see the first 50)

I have found no way so far to get the warnings viewed. Which command would be 
appropriate? warnings() (without an argument) returns NULL.
Thank you in advance.



From macq at llnl.gov  Thu Sep 16 16:52:10 2004
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 16 Sep 2004 07:52:10 -0700
Subject: [R] date library and notched boxplots
In-Reply-To: <20040916.071641.3306.851460@webmail11.lax.untd.com>
References: <20040916.071641.3306.851460@webmail11.lax.untd.com>
Message-ID: <p06002000bd6f58d01626@[128.115.153.6]>

Try formatting the dates as character strings, and supplying those to 
boxplot().

At 2:16 PM +0000 9/16/04, smestrella at juno.com wrote:
>I'm having problems using the date library with notched boxplots.  I 
>have separate month, day, and year columns and would like to plot 
>the columns as a date against other variables.  I have used the 
>mdy.date(month,day,year) command before with plot(), but it doesn't 
>seem to work with boxplot().  Instead of the dates along the x-axis, 
>I get a list of numbers.  Maybe I have the code wrong?  I have used 
>the help() menu in R, but with no success.
>
>Can somebody please help?
>
>Thanks,
>Stephanie
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From gwgilc at wm.edu  Thu Sep 16 16:59:35 2004
From: gwgilc at wm.edu (George W. Gilchrist)
Date: Thu, 16 Sep 2004 10:59:35 -0400
Subject: [R] Estimating parameters for a bimodal distribution
Message-ID: <BD6F2297.2382%gwgilc@wm.edu>

For several years, I have been using Splus to analyze an ongoing series of
datasets that have a bimodal distribution. I have used the following
functions, in particular the ms() function, to estimate the parameters: two
means, two standard deviations, and one proportion. Here is the code I've
been using in S:

    btmp.bi <- function(vec, p, m1, m2, sd1, sd2)
    {
        (exp(p)/(1+exp(p)))*dnorm(vec,mean=m1,sd=abs(sd1))+
            (1-(exp(p)/(1+exp(p))))*dnorm(vec,mean=m2,sd=abs(sd2))
    }
    btmp11 <- ms( ~  - sum(log((btmp.bi(btmp1$Temp, p, m1, m2,
             s1, s2)))), start = list(p = 0.4, m1 = 38, m2 = 40, s1
             = 1, s2 = 1), control = list(maxiter = 200))

I have looked in the archives and tried various alternatives, especially
optim(), but so far have had nothing but frustration. I've been running this
in a semi-automated program on several hundred datasets a few times each
month for several years now. I would like to figure out how to move this to
R. Thank you for any help you might offer.

==================================================================
George W. Gilchrist                        Email #1: gwgilc at wm.edu
Department of Biology, Box 8795          Email #2: kitesci at cox.net
College of William & Mary                    Phone: (757) 221-7751
Williamsburg, VA 23187-8795                    Fax: (757) 221-6483
http://gwgilc.people.wm.edu/



From ahenningsen at email.uni-kiel.de  Thu Sep 16 17:27:14 2004
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Thu, 16 Sep 2004 17:27:14 +0200
Subject: [R] newbie needs help using R as solver
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB02FEF95A@gimli.middleearth.kssg.com>
References: <6B5A9304046AD411BD0200508BDFB6CB02FEF95A@gimli.middleearth.kssg.com>
Message-ID: <200409161727.14630.ahenningsen@email.uni-kiel.de>

On Thursday 16 September 2004 11:44, Wayne Jones wrote:
> This is a linear programming problem. Although I am not sure what your
> objective function is!!
>
> Check out the R package linprog

Please use the package lpSolve, it's much better and _faster_ than linprog. I 
started writing linprog before lpSolve was published. After lpSolve was on 
cran, I mainly used this package and worked only very little on linprog. 
Thus, linprog is still an alpha version. There are only few cases when 
linprog might be prefered (e.g. dual values). I hope that the next version of 
lpSolve will include these cases (then I will ask to remove linprog from 
cran).

Best wishes,
Arne

> -----Original Message-----
> From: Andrej Uduc [mailto:odyn at email.si]
> Sent: 16 September 2004 10:29
> To: r-help at stat.math.ethz.ch
> Subject: [R] newbie needs help using R as solver
>
> Greetings
> I'm a total newbie in R and I'm trying to make a comparisson of Excel
> and R in the fields of:
> - optimisation modeling (using solver)
> -  decision trees
> -  simulation modeling
> as described in Winston, Wayne L.:  Practical Management Science.
> for optimisation modeling in Excel I would normaly use solver. In R
> however I can't seem to be able to find the solution. I've narrowed it
> down to optim, optimize functions (I might be totaly wrong), but I can't
> figure out how to set the conditions. I've read something about nlm
> model but I can't find the anwser (examples are not easy enough for me).
> what I wanna do is solve this simple task:
> a+b =< 500000
> c+d  =< 500000
> g  >= 0,25*c+d
> a+b+c+d+g =< 1000000
> a, b, c, d, g => 0
>
> I would very much appreciate any help in this matter. I need to locate
> the appropriate function for the task and figure out how to write this
> formulas. I'd also be very thankfull for any help (links) to simple
> examples of decision trees and/or simulation.
>
>     Andrej Udu??
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
>
> KSS Ltd
> Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS 
> England Company Registration Number 2800886
> Tel: +44 (0) 161 228 0040 Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com  http://www.kssg.com
>
>
> The information in this Internet email is confidential and m...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From gerifalte28 at hotmail.com  Thu Sep 16 17:22:16 2004
From: gerifalte28 at hotmail.com (F Z)
Date: Thu, 16 Sep 2004 15:22:16 +0000
Subject: [R] getting started on Bayesian analysis
Message-ID: <BAY2-F35sGcSiOarW2w0000f10b@hotmail.com>

As far as I understand, WinBUGS is currently free (it might not stay free 
for ever though) and has an output analysis suite for R called CODA, 
translated from S-Plus by Martyn Plummer.  You can read more about it at 
http://www-fis.iarc.fr/coda/

Good luck!

Francisco


>From: Martyn Plummer <plummer at iarc.fr>
>To: tpapp at princeton.edu
>CC: R-help mailing list <r-help at stat.math.ethz.ch>
>Subject: Re: [R] getting started on Bayesian analysis
>Date: Thu, 16 Sep 2004 13:00:15 +0200
>
>On Wed, 2004-09-15 at 02:19, Tamas K Papp wrote:
> > I am an economist who decided it's high time that I learned some
> > Bayesian statistics.  I am following An Introduction to Modern
> > Bayesian Econometrics by T. Lancaster.
> >
> > The book recommends using BUGS, but I wonder if there are any
> > alternatives which are free software and fully integrated to R (which
> > I have been using for more than two years for numerical computations.)
> > I would like to learn what R packages (or other software)
> > statisticians use for Bayesian analysis to R, if there are viable
> > alternatives to BUGS, etc.
>
>Bayesian analysis in R is relatively underdeveloped. However, Greg
>Warnes recently decided to get everyone involved with MCMC in R talking
>to each other.  The current state of the art can be seen here:
>
>http://research.warnes.net/Members/warnes/R-MCMC/
>
>All I can say is "watch this space" for future developments.
>Martyn
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From tplate at blackmesacapital.com  Thu Sep 16 17:35:44 2004
From: tplate at blackmesacapital.com (Tony Plate)
Date: Thu, 16 Sep 2004 09:35:44 -0600
Subject: [R] There were 50 or more warnings (use warnings() to see
	the first 50)
In-Reply-To: <200409161652.03053.ferri.leberl@gmx.at>
References: <200409161652.03053.ferri.leberl@gmx.at>
Message-ID: <6.1.0.6.2.20040916093313.04311710@mailhost.blackmesacapital.com>

Try putting options(warn=1) at the start of your R code.

This should cause the warnings to be printed as they occur, instead of the 
default of being saved up until the top-level command terminates.

See ?warning and ?option.

-- Tony Plate

At Thursday 08:52 AM 9/16/2004, Mag. Ferri Leberl wrote:
>I employ R in the Slave-Mode.
>The slave returns me the following feedback:
>
>There were 50 or more warnings (use warnings() to see the first 50)
>
>I have found no way so far to get the warnings viewed. Which command would be
>appropriate? warnings() (without an argument) returns NULL.
>Thank you in advance.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dimitris.rizopoulos at med.kuleuven.ac.be  Thu Sep 16 17:42:46 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 16 Sep 2004 17:42:46 +0200
Subject: [R] Estimating parameters for a bimodal distribution
References: <BD6F2297.2382%gwgilc@wm.edu>
Message-ID: <005e01c49c03$d07e7580$b2133a86@www.domain>

Hi George,

I tried the following and it worked for me,

btmp.bi <- function(par., vec){
    p <- par.[1]
    mu1 <- par.[2]
    mu2 <- par.[3]
    sigma1 <- par.[4]
    sigma2 <- par.[5]
    -sum(log( plogis(p)*dnorm(vec, mu1, abs(sigma1)) + 
(1-plogis(p))*dnorm(vec, mu2, abs(sigma2)) ))
}

vec <- ifelse(runif(500)<.4, rnorm(1, 38, 1), rnorm(1, 40, 1))
optim(par=c(p=0.4, mu1=38, mu2=40, sigma1=1, sigma2=1), btmp.bi, 
method="CG", vec=vec)

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "George W. Gilchrist" <gwgilc at wm.edu>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, September 16, 2004 4:59 PM
Subject: [R] Estimating parameters for a bimodal distribution


> For several years, I have been using Splus to analyze an ongoing 
> series of
> datasets that have a bimodal distribution. I have used the following
> functions, in particular the ms() function, to estimate the 
> parameters: two
> means, two standard deviations, and one proportion. Here is the code 
> I've
> been using in S:
>
>    btmp.bi <- function(vec, p, m1, m2, sd1, sd2)
>    {
>        (exp(p)/(1+exp(p)))*dnorm(vec,mean=m1,sd=abs(sd1))+
>            (1-(exp(p)/(1+exp(p))))*dnorm(vec,mean=m2,sd=abs(sd2))
>    }
>    btmp11 <- ms( ~  - sum(log((btmp.bi(btmp1$Temp, p, m1, m2,
>             s1, s2)))), start = list(p = 0.4, m1 = 38, m2 = 40, s1
>             = 1, s2 = 1), control = list(maxiter = 200))
>
> I have looked in the archives and tried various alternatives, 
> especially
> optim(), but so far have had nothing but frustration. I've been 
> running this
> in a semi-automated program on several hundred datasets a few times 
> each
> month for several years now. I would like to figure out how to move 
> this to
> R. Thank you for any help you might offer.
>
> ==================================================================
> George W. Gilchrist                        Email #1: gwgilc at wm.edu
> Department of Biology, Box 8795          Email #2: kitesci at cox.net
> College of William & Mary                    Phone: (757) 221-7751
> Williamsburg, VA 23187-8795                    Fax: (757) 221-6483
> http://gwgilc.people.wm.edu/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From kahra at mpsgr.it  Thu Sep 16 17:43:21 2004
From: kahra at mpsgr.it (Kahra Hannu)
Date: Thu, 16 Sep 2004 17:43:21 +0200
Subject: [R] Estimating parameters for a bimodal distribution
Message-ID: <C9FC71F7E9356F40AFE2ACC2099DE1471496A0@MAILSERVER-B.mpsgr.it>

George,

Venables & Ripley: Modern Applied Statistics with S, Springer 2002, Chapter 16 (An example: fitting a mixture model) may be helpful.

Hannu Kahra

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of George W.
Gilchrist
Sent: Thursday, September 16, 2004 5:00 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Estimating parameters for a bimodal distribution


For several years, I have been using Splus to analyze an ongoing series of
datasets that have a bimodal distribution. I have used the following
functions, in particular the ms() function, to estimate the parameters: two
means, two standard deviations, and one proportion. Here is the code I've
been using in S:

    btmp.bi <- function(vec, p, m1, m2, sd1, sd2)
    {
        (exp(p)/(1+exp(p)))*dnorm(vec,mean=m1,sd=abs(sd1))+
            (1-(exp(p)/(1+exp(p))))*dnorm(vec,mean=m2,sd=abs(sd2))
    }
    btmp11 <- ms( ~  - sum(log((btmp.bi(btmp1$Temp, p, m1, m2,
             s1, s2)))), start = list(p = 0.4, m1 = 38, m2 = 40, s1
             = 1, s2 = 1), control = list(maxiter = 200))

I have looked in the archives and tried various alternatives, especially
optim(), but so far have had nothing but frustration. I've been running this
in a semi-automated program on several hundred datasets a few times each
month for several years now. I would like to figure out how to move this to
R. Thank you for any help you might offer.

==================================================================
George W. Gilchrist                        Email #1: gwgilc at wm.edu
Department of Biology, Box 8795          Email #2: kitesci at cox.net
College of William & Mary                    Phone: (757) 221-7751
Williamsburg, VA 23187-8795                    Fax: (757) 221-6483
http://gwgilc.people.wm.edu/

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Tatsuki.Koyama at Vanderbilt.edu  Thu Sep 16 17:55:09 2004
From: Tatsuki.Koyama at Vanderbilt.edu (Tatsuki Koyama)
Date: Thu, 16 Sep 2004 10:55:09 -0500
Subject: [R] barplot with vcd library
Message-ID: <4149B75D.5070205@Vanderbilt.edu>

'barplot' doesn't seem to work with vcd library.
Am I supposed to detach vcd when I want to use barplot?
Here's an example.
Say I have the following matrix,

> m <- matrix(c(1,2,3, 4,5,6, 3,4,5, 2,3,4), ncol=4)
> m
     [,1] [,2] [,3] [,4]
[1,]    1    4    3    2
[2,]    2    5    4    3
[3,]    3    6    5    4

Then
> barplot(m)
gives a barplot of the data.

However, when I attach 'vcd' library, the same command does not seem
to work.
It only gives the first three bars and 2 warning messages.

> library(vcd)

Attaching package 'vcd':


        The following object(s) are masked from package:graphics :

         barplot.default fourfoldplot mosaicplot


        The following object(s) are masked from package:base :

         print.summary.table summary.table

> barplot(m)
Warning messages:
1: longer object length
        is not a multiple of shorter object length in: -0.01 * height
+ shift
2: longer object length
        is not a multiple of shorter object length in: height + shift

-- 
Tatsuki Koyama, Ph.D.
Department of Biostatistics
Vanderbilt University Medical Center
Email: Tatsuki.Koyama at Vanderbilt.Edu



From ripley at stats.ox.ac.uk  Thu Sep 16 17:57:28 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Sep 2004 16:57:28 +0100 (BST)
Subject: [R] Estimating parameters for a bimodal distribution
In-Reply-To: <BD6F2297.2382%gwgilc@wm.edu>
Message-ID: <Pine.LNX.4.44.0409161656340.26405-100000@gannet.stats>

MASS4, chapter 16 has examples of a mixture of two normals by various 
methods, very like this one, in both S-PLUS and R.

On Thu, 16 Sep 2004, George W. Gilchrist wrote:

> For several years, I have been using Splus to analyze an ongoing series of
> datasets that have a bimodal distribution. I have used the following
> functions, in particular the ms() function, to estimate the parameters: two
> means, two standard deviations, and one proportion. Here is the code I've
> been using in S:
> 
>     btmp.bi <- function(vec, p, m1, m2, sd1, sd2)
>     {
>         (exp(p)/(1+exp(p)))*dnorm(vec,mean=m1,sd=abs(sd1))+
>             (1-(exp(p)/(1+exp(p))))*dnorm(vec,mean=m2,sd=abs(sd2))
>     }
>     btmp11 <- ms( ~  - sum(log((btmp.bi(btmp1$Temp, p, m1, m2,
>              s1, s2)))), start = list(p = 0.4, m1 = 38, m2 = 40, s1
>              = 1, s2 = 1), control = list(maxiter = 200))
> 
> I have looked in the archives and tried various alternatives, especially
> optim(), but so far have had nothing but frustration. I've been running this
> in a semi-automated program on several hundred datasets a few times each
> month for several years now. I would like to figure out how to move this to
> R. Thank you for any help you might offer.
> 
> ==================================================================
> George W. Gilchrist                        Email #1: gwgilc at wm.edu
> Department of Biology, Box 8795          Email #2: kitesci at cox.net
> College of William & Mary                    Phone: (757) 221-7751
> Williamsburg, VA 23187-8795                    Fax: (757) 221-6483
> http://gwgilc.people.wm.edu/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Sep 16 18:03:09 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Sep 2004 17:03:09 +0100 (BST)
Subject: [R] linear regression: evaluating the result Q
In-Reply-To: <20040916171235.163cf1b8@portia.local>
Message-ID: <Pine.LNX.4.44.0409161659490.26405-100000@gannet.stats>

On Thu, 16 Sep 2004, RenE J.V. Bertin wrote:

> Dear all,
> 
> A few quick questions about interpreting and evaluating the results of
> linear regressions, to which I hope equally quick answers are possible.
> 
> 1) The summary.lm method prints the R and R^2 correlation coefficients
> (something reviewers like to see). It works on glm objects and (after
> tweaking it to initialise z$df.residual with rdf) also on rlm objects.
> Are the R, R^2 and also the p values reported reliable for these fit
> results? If not, how do I calculate them best?

Well, for rlm no, as it is not least-squares fitting and R^2 is very 
suseptible to outliers.  For glm, not really unless it is a Gaussian 
model.

> 2) For a simple 1st order linear fit, what is the best way to calculate
> the (95%) confidence interval on/of the slope?

Use confint.  (MASS chapter 7 has examples.)

> 3) The p values reported for the calculated coefficients and intercept
> indicate to what extent these values are significantly different from
> zero (right?). 

Yes.

> Aside from question 2), what is the best way to compare
> the calculated slope with another slope (say of the unity line)?

Use offset, as in y ~ x + offset(x) and test for the coefficient of x to
be zero.  (That's R only, BTW.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Thu Sep 16 18:16:06 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 16 Sep 2004 18:16:06 +0200
Subject: [R] SJava, Client X11
In-Reply-To: <85fz5m6o34.fsf@servant.blindglobe.net>
References: <Pine.LNX.4.44.0409131132420.15725-100000@gannet.stats>
	<85fz5m6o34.fsf@servant.blindglobe.net>
Message-ID: <16713.48198.556386.182981@gargle.gargle.HOWL>

>>>>> "tony" == A J Rossini <rossini at blindglobe.net>
>>>>>     on Mon, 13 Sep 2004 11:06:07 -0700 writes:

    tony> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
    >> In theory Omegahat has its own mailing lists. 

    tony> Possibly not in practice.  I can't remember which machine (ETH or
    tony> UWisc) they were once located on, either.  

not at ETH (or they would have continued to work ;-)

    tony> I'm sure someone will let me know, preferably in
    tony> public, so that we can know where to direct folks.  I
    tony> unsubscribed from them a while back because of the
    tony> level of spam originating from them at the point.

    tony> http://www.omegahat.org/mailman/listinfo 

    tony> reports:

    tony> Mailman CGI error!!!

      <...........>

A host lookup of 'www.omegahat.org' points to the location of
the most active Omegahat developer (to whom this msg is BCC'ed).

Regards,
Martin Maechler



From ggrothendieck at myway.com  Thu Sep 16 18:21:02 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 16 Sep 2004 16:21:02 +0000 (UTC)
Subject: [R] barplot with vcd library
References: <4149B75D.5070205@Vanderbilt.edu>
Message-ID: <loom.20040916T181909-379@post.gmane.org>

Tatsuki Koyama <Tatsuki.Koyama <at> Vanderbilt.edu> writes:

: 
: 'barplot' doesn't seem to work with vcd library.
: Am I supposed to detach vcd when I want to use barplot?
: Here's an example.
: Say I have the following matrix,
: 
: > m <- matrix(c(1,2,3, 4,5,6, 3,4,5, 2,3,4), ncol=4)
: > m
:      [,1] [,2] [,3] [,4]
: [1,]    1    4    3    2
: [2,]    2    5    4    3
: [3,]    3    6    5    4
: 
: Then
: > barplot(m)
: gives a barplot of the data.
: 
: However, when I attach 'vcd' library, the same command does not seem
: to work.

graphics::barplot(m)

will tell R you want the version in graphics rather than the one in vcd.



From ripley at stats.ox.ac.uk  Thu Sep 16 18:53:02 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Sep 2004 17:53:02 +0100 (BST)
Subject: [R] linear regression: evaluating the result Q
In-Reply-To: <20040916184501.290cfff1@portia.local>
Message-ID: <Pine.LNX.4.44.0409161751460.26685-100000@gannet.stats>

On Thu, 16 Sep 2004, RenE J.V. Bertin wrote:

> On Thu, 16 Sep 2004 17:03:09 +0100 (BST), Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote regarding
> "Re: [R] linear regression: evaluating the result Q"
> 
> Thank you, that should get me going into the right direction!
> 
> 8-) Well, for rlm no, as it is not least-squares fitting and R^2 is very 
> 8-) suseptible to outliers.  For glm, not really unless it is a Gaussian 
> 8-) model.
> 
> 	This is what I feared. How then would one evaluate the goodness of
> an rlm fit, on a comparable 0-1 scale?

Via the estimated robust scales.

> 8-) > Aside from question 2), what is the best way to compare
> 8-) > the calculated slope with another slope (say of the unity line)?
> 8-) 
> 8-) Use offset, as in y ~ x + offset(x) and test for the coefficient of x to
> 8-) be zero.  (That's R only, BTW.)
> 
> offset seems to be ignored by rlm(), is that correct? (Which isn't too
> much of a problem as long as confint operates correctly on rlm objects.)

Yes -- rlm was written before R existed.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From HStevens at MUOhio.edu  Thu Sep 16 22:02:32 2004
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Thu, 16 Sep 2004 16:02:32 -0400
Subject: [R] geoR/variog4() not returning all directions
Message-ID: <584FFE8E-081B-11D9-9CB3-000A958F43CC@MUOhio.edu>

Mac OS 10.3.5, R 2.0.0
latest version of geoR

I have an incomplete 5 x 20 spatial array of samples (60 out of 100 
possible locations) for which I would like to calculate directional 
variograms using variog4(). Unfortunately, I can't get it to return all 
4 directions. It returns variograms for 45, 90, and 135 degrees, 
omitting 0 degrees (pi/4, pi/2, 3pi/4, omitting 0). If I specify 0 
degrees, it returns a variogram with (binned) distances of 1, 2, 3, and 
4.

Any ideas what I am doing wrong, or what other information I could 
provide to better elucidate my problem?
Many thanks, as usual.
Hank Stevens

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From paulojus at est.ufpr.br  Thu Sep 16 22:44:06 2004
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Thu, 16 Sep 2004 17:44:06 -0300 (BRT)
Subject: [R] geoR/variog4() not returning all directions
In-Reply-To: <584FFE8E-081B-11D9-9CB3-000A958F43CC@MUOhio.edu>
References: <584FFE8E-081B-11D9-9CB3-000A958F43CC@MUOhio.edu>
Message-ID: <Pine.LNX.4.58L0.0409161742160.837@est.ufpr.br>

Hi Martin

The only pssible explanation I can find from your description is that the
code may not be fiuding pairs in one of the directions.

however...I never discard the possibility of a bug :)

Could you please send me the data and the piec of relevant code such that
i can rteproduce the error here?

Thanks
P.J,



On Thu, 16 Sep 2004, Martin Henry H. Stevens wrote:

> Mac OS 10.3.5, R 2.0.0
> latest version of geoR
>
> I have an incomplete 5 x 20 spatial array of samples (60 out of 100
> possible locations) for which I would like to calculate directional
> variograms using variog4(). Unfortunately, I can't get it to return all
> 4 directions. It returns variograms for 45, 90, and 135 degrees,
> omitting 0 degrees (pi/4, pi/2, 3pi/4, omitting 0). If I specify 0
> degrees, it returns a variogram with (binned) distances of 1, 2, 3, and
> 4.
>
> Any ideas what I am doing wrong, or what other information I could
> provide to better elucidate my problem?
> Many thanks, as usual.
> Hank Stevens
>
> Dr. Martin Henry H. Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/botany/bot/henry.html
> http://www.muohio.edu/ecology/
> http://www.muohio.edu/botany/
> "E Pluribus Unum"
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat??stica
Universidade Federal do Paran??
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3573
Fax: (+55) 41 361 3141
e-mail: paulojus at est.ufpr.br
http://www.est.ufpr.br/~paulojus

 /"\
 \ /  Campanha da fita ASCII - contra mail html
  X   ASCII ribbon campaign - against html mail
 / \



From Ray.Lindsay at abare.gov.au  Fri Sep 17 03:36:46 2004
From: Ray.Lindsay at abare.gov.au (Ray.Lindsay@abare.gov.au)
Date: Fri, 17 Sep 2004 11:36:46 +1000
Subject: [R] Problem with R-1.9.1 under Solaris 2.6
Message-ID: <3E4215C93D3CE24D84A9FF385DF88D8704B0BD95@afeb-ms-02>

Hi
I have installed R-1.9.1 on an 6 year old Sun running Solaris 2.6. After some initial failures to compile I used the :
gcc 2.7.2.3 
f77
compilers with gnu make. [could not get gcc 3.4.1 to compile]
 All but one of the .c programs compiled [that being src/main/connections.c which I manually compiled using cc] and the 
make check 
tests all worked [apart from the internet]. 

However I get the following, where weight is a column vector :
> np <- sum(weight)
> n <- nrow(weight)
> weight <- as.single((n*weight)/np)
Error in structure(.Internal(as.vector(x, "double")), Csingle = TRUE) :
        (list) object cannot be coerced to double
> dim(weight)
[1] 38  1

> version
         _
platform sparc-sun-solaris2.6
arch     sparc
os       solaris2.6
system   sparc, solaris2.6
status
major    1
minor    9.1
year     2004
month    06
day      21
language R

I have searched the R-help and R-devel archives but not seen anything directly relevant. Any help would be much appreciated.

Thanks

Ray Lindsay
Senior Statistician
Natural Resources Branch
ABARE
Canberra 
Australia
+61-2-6272 2215


---------------------------------------------------------------------- 
IMPORTANT - This message has been issued by The Department of Agriculture, Fisheries and Forestry (DAFF).  The information transmitted is for the use of the intended recipient only and may contain confidential and/or legally privileged material.  It is your responsibility to check any attachments for viruses and defects before opening or sending them on.  
Any reproduction, publication, communication, re-transmission, disclosure, dissemination or other use of the information contained in this e-mail by persons or entities other than the intended recipient is prohibited.  The taking of any action in reliance upon this information by persons or entities other than the intended recipient is prohibited.  If you have received this e-mail in error please notify the sender and delete all copies of this transmission together with any attachments.  If you have received this e-mail as part of a valid mailing list and no longer want to receive a message such as this one advise the sender by return e-mail accordingly.  Only e-mail correspondence which includes this footer, has been authorised by DAFF



From yogesh at wharton.upenn.edu  Fri Sep 17 04:54:29 2004
From: yogesh at wharton.upenn.edu (Joshi, Yogesh)
Date: Thu, 16 Sep 2004 22:54:29 -0400
Subject: [R] help with numerical solution for two simultaneous nonlinear
	equations in 2 variables
Message-ID: <218EDA661244704185C991AEA20D926401468D47@COURIER.wharton.upenn.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040916/2323501a/attachment.pl

From Charles.Annis at StatisticalEngineering.com  Fri Sep 17 05:07:49 2004
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Thu, 16 Sep 2004 23:07:49 -0400
Subject: [R] help with numerical solution for two simultaneous
	nonlinearequations in 2 variables
In-Reply-To: <218EDA661244704185C991AEA20D926401468D47@COURIER.wharton.upenn.edu>
Message-ID: <200409170307.i8H37rhi009452@hypatia.math.ethz.ch>

?optim  will be helpful.



Charles Annis, P.E.
 
Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  503-217-5849
http://www.StatisticalEngineering.com

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Joshi, Yogesh
Sent: Thursday, September 16, 2004 10:54 PM
To: r-help at stat.math.ethz.ch
Subject: [R] help with numerical solution for two simultaneous
nonlinearequations in 2 variables

Hi,

I am relatively new to R and am trying to solve two simultaneous
nonlinear equations in two variables numerically, and was wondering if
anyone knew if any of the packages could do that.  An alternative is
writing my own code using Newton-Raphson; I did that but was not able to
get good convergence. Any ideas please? 

Thanks

Yogesh

 


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Fri Sep 17 06:34:25 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 17 Sep 2004 05:34:25 +0100 (BST)
Subject: [R] Problem with R-1.9.1 under Solaris 2.6
In-Reply-To: <3E4215C93D3CE24D84A9FF385DF88D8704B0BD95@afeb-ms-02>
Message-ID: <Pine.LNX.4.44.0409170510140.29638-100000@gannet.stats>

On Fri, 17 Sep 2004 Ray.Lindsay at abare.gov.au wrote:

> Hi
> I have installed R-1.9.1 on an 6 year old Sun running Solaris 2.6. After some initial failures to compile I used the :
> gcc 2.7.2.3 
> f77
> compilers with gnu make. [could not get gcc 3.4.1 to compile]
>  All but one of the .c programs compiled 
> [that being src/main/connections.c which I manually compiled using cc] 
and the 

Out of curiosity, what was the error with ancient gcc?

> make check 
> tests all worked [apart from the internet]. 
> 
> However I get the following, where weight is a column vector :

There is no such thing in R (only vectors and 1D arrays).  What does
str(weight) say?  Here's my guess:

weight <- data.frame(x=rnorm(38))

reproduces your error.  So I think you have a one-column data frame, and 
you meant weight[[1]] (or weight[, 1] or weight[1]).

Next, why are you calling as.single?  This is not in the context which the 
help page says is the *only* place it should be used.

> > np <- sum(weight)
> > n <- nrow(weight)
> > weight <- as.single((n*weight)/np)
> Error in structure(.Internal(as.vector(x, "double")), Csingle = TRUE) :
>         (list) object cannot be coerced to double
> > dim(weight)
> [1] 38  1


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From david.netherway at adelaide.edu.au  Fri Sep 17 06:53:19 2004
From: david.netherway at adelaide.edu.au (David J. Netherway)
Date: Fri, 17 Sep 2004 14:23:19 +0930
Subject: [R] thickness of tick marks
Message-ID: <414A6DBF.2090702@adelaide.edu.au>

Hi,

I am unable to get the tick marks to appear thicker in plot. I have 
tried things like
par(lw=2) but this only seems to affect other line thicknesses.

The use of axes directly fixes the problem because lw = 2 applies to 
both the axis and the ticks.

Is there is  way of feeding a single parameter to plot or setting a par 
parameter to do this?

I am using R 1.9.0 on a windows 2000 platform.

Thanks, David



From ripley at stats.ox.ac.uk  Fri Sep 17 07:07:53 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 17 Sep 2004 06:07:53 +0100 (BST)
Subject: [R] thickness of tick marks
In-Reply-To: <414A6DBF.2090702@adelaide.edu.au>
Message-ID: <Pine.LNX.4.44.0409170602260.30001-100000@gannet.stats>

It is par(lwd)
            ^
The device's current setting of par(lwd) does not affect that used by 
axis() (as called by some plot methods).  So you have to call axis() 
yourself.  ?axis would have told you the default was 1.

There was a wishlist item on R-bugs (PR#7223) to change this recently, and 
some counter-arguments -- search on the R-devel list archives for more 
details.

On Fri, 17 Sep 2004, David J. Netherway wrote:

> I am unable to get the tick marks to appear thicker in plot. I have 
> tried things like
> par(lw=2) but this only seems to affect other line thicknesses.
> 
> The use of axes directly fixes the problem because lw = 2 applies to 
> both the axis and the ticks.
> 
> Is there is  way of feeding a single parameter to plot or setting a par 
> parameter to do this?
> 
> I am using R 1.9.0 on a windows 2000 platform.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tom_woody at swissinfo.org  Fri Sep 17 10:12:24 2004
From: tom_woody at swissinfo.org (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Fri, 17 Sep 2004 10:12:24 +0200
Subject: [R] loading error of the Rcmdr library on Debian Sid [SOLVED]
Message-ID: <414A9C68.6050509@swissinfo.org>

Hello,

hopefully someone will remember my previous problem to load the Rcmdr 
library from within GNU R resulting in an error message: 
"libnvidia-tls.so.1: cannot handle TLS data".

Some suggestions have been raised by Christian Schulz and others that 
unfortunately didn't work around this error.
Nevertheless I felt very grateful for your suggestions!

This morning I investigated this problem a bit more in depth. It turned 
out that a buggy NVidia driver (libnvidia-tls.so) is loaded by defualt 
provoking the reported problem.

After renaming /usrlib/tls/ too /usr/lib/tls_old (can also be entirely 
removed!) the problem vanished inmediately and R Commander works 
smoothly out of the box!

Just thought this might be of interest in case of someone else is 
affected by this NVidia related problem!

regards

Thomas



From jmoreira at fe.up.pt  Fri Sep 17 12:24:03 2004
From: jmoreira at fe.up.pt (jmoreira@fe.up.pt)
Date: Fri, 17 Sep 2004 11:24:03 +0100
Subject: [R] What is nu-regression for svm?
Message-ID: <1095416643.414abb436a119@webmail.fe.up.pt>


Does anyone knows what is the nu-regression option for the type parameter in 
svm (from package e1071)? I cannot find any explanation on that and I have a 
reasonable understanding on svm fundamentals.

Thanks

Joao Moreira



From rvaradha at jhsph.edu  Fri Sep 17 14:17:54 2004
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Fri, 17 Sep 2004 08:17:54 -0400
Subject: [R] help with numerical solution for two simultaneous
	nonlinearequations in 2 variables
In-Reply-To: <218EDA661244704185C991AEA20D926401468D47@COURIER.wharton.upenn.edu>
Message-ID: <OWA-2D973V7lNbx7AQu00006cab@owa-2.sph.ad.jhsph.edu>

Hi,

Suppose you have p equations in p unknowns:
F1(x1,x2,...,xp) =0
.
.
.
Fp(x1,x2,...,xp) = 0

You can solve the equivalent minimization problem: 
G(x1,x2,...,xp) = F1^2 + ... + Fp^2 = 0

So, you can use "optim" with G as your objective function. 

Hope this is helpful,
Ravi.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Joshi, Yogesh
Sent: Thursday, September 16, 2004 10:54 PM
To: r-help at stat.math.ethz.ch
Subject: [R] help with numerical solution for two simultaneous
nonlinearequations in 2 variables

Hi,

I am relatively new to R and am trying to solve two simultaneous
nonlinear equations in two variables numerically, and was wondering if
anyone knew if any of the packages could do that.  An alternative is
writing my own code using Newton-Raphson; I did that but was not able to
get good convergence. Any ideas please? 

Thanks

Yogesh

 


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From sdavis2 at mail.nih.gov  Fri Sep 17 14:35:53 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 17 Sep 2004 08:35:53 -0400
Subject: [R] pairs plot and legend
Message-ID: <1D7C0BBA-08A6-11D9-B5A4-000A95D7BA10@mail.nih.gov>

I would like to add a legend to a pairs plot.  Is there a simple way to 
do this?  Just doing legend(.....) doesn't seem to get it.

Thanks,
Sean



From maechler at stat.math.ethz.ch  Fri Sep 17 14:57:24 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 17 Sep 2004 14:57:24 +0200
Subject: [R] Proposal for New R List: Criticism? Comments?
In-Reply-To: <20040910145652.KSBB19123.tomts20-srv.bellnexxia.net@JohnDesktop8300>
References: <Pine.LNX.4.44.0409101113450.19494-100000@gannet.stats>
	<20040910145652.KSBB19123.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <16714.57140.768373.62149@gargle.gargle.HOWL>

Hi John et al.

I'm coming late to this thread (because of vacation),

>>>>> "JohnF" == John Fox <jfox at mcmaster.ca>
>>>>>     on Fri, 10 Sep 2004 10:56:51 -0400 writes:

    JohnF> Dear Brian et al.,

    JohnF> Jonathan's search site is excellent -- I use it
    JohnF> frequently -- and for some reason new users seem
    JohnF> unaware of help.search(), which, despite the fact
    JohnF> that it searches only in installed packages, I also
    JohnF> find very useful.

yes and yes.

    JohnF> A couple of comments, however: First, if help pages
    JohnF> from all packages were available at a central
    JohnF> location -- e.g., at CRAN -- help.search() could have
    JohnF> an option to search that location. Second, I still
    JohnF> feel that it would be useful to provide some other
    JohnF> way of searching the space of all available
    JohnF> functions. One idea, which I mentioned in an earlier
    JohnF> message on this thread, would be a keyword system
    JohnF> (again, different from the current set of standard
    JohnF> keywords). 

\concept{}  was introduced for this

    JohnF> The keywords could be accessed by help.search() 

and this happens (by default) for \concept{} entries

    JohnF> and also compiled into an index.

this doesn't happen yet.

The ``real problem'' of course is that package authors need to
write all these \concept{} entries before such an index can
really become useful.

Martin Maechler

    >> -----Original Message-----
    >> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
    >> Sent: Friday, September 10, 2004 5:26 AM
    >> To: Jonathan Baron
    >> Cc: Adaikalavan Ramasamy; John Fox; R-help; 'Berton Gunter'
    >> Subject: Re: [R] Proposal for New R List: Criticism? Comments?
    >> 
    >> On Fri, 10 Sep 2004, Jonathan Baron wrote:
    >> 
    >> > On 09/10/04 03:54, Adaikalavan Ramasamy wrote:
    >> > >There is another issue to be considered. Currently you 
    >> need to have 
    >> > >the relevant packages installed before help.search() bring 
    >> it up. My 
    >> > >work around this is to install all available packages just in case 
    >> > >the function I need is nestled in some non-standard 
    >> packages. I also 
    >> > >update them rather frequently.
    >> > 
    >> > I do this too, at my search site (where 
    >> "frequently"=monthly) and you 
    >> > can search functions only, and use Boolean search expressions and 
    >> > phrases.
    >> > 
    >> > But right now the entire set of packages takes about 885 
    >> meg (if I'm 
    >> > reading du correctly), which is less than my very modest 
    >> collection of 
    >> > digital photos, and a tiny fraction of a 3-year-old standard hard 
    >> > disk.  In other words, it is no big deal to install all the 
    >> packages 
    >> > if you have your own computer.
    >> 
    >> I am seeing about 520Mb for all base + CRAN packages under 
    >> 1.9.1, and it will be rather less under 2.0.0 as more parts 
    >> are stored compressed.
    >> BioC is a lot larger.
    >> 
    >> It is however, a BIG deal to install *all* the packages and 
    >> am I currently 10 short since they depend on other software 
    >> that I do not have a licence for or will not compile (and 
    >> there are three others I cannot reinstall using current gcc). 
    >> On AMD64 and Solaris there are several others, and something 
    >> like 20 do not install on Windows.  (I could use 
    >> --install-fake as the CRAN checks do, but I have the almost 
    >> complete set installed to test R changes, not test packages.)
    >> 
    >> So I do see some merit in having a full-text search for R 
    >> help available at some URL, as Jonathan has kindly provided.
    >> 
    >> -- 
    >> Brian D. Ripley,                  ripley at stats.ox.ac.uk
    >> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
    >> University of Oxford,             Tel:  +44 1865 272861 (self)
    >> 1 South Parks Road,                     +44 1865 272866 (PA)
    >> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Fri Sep 17 14:58:10 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 17 Sep 2004 14:58:10 +0200
Subject: [R] pairs plot and legend
In-Reply-To: <1D7C0BBA-08A6-11D9-B5A4-000A95D7BA10@mail.nih.gov>
References: <1D7C0BBA-08A6-11D9-B5A4-000A95D7BA10@mail.nih.gov>
Message-ID: <414ADF62.9080206@statistik.uni-dortmund.de>

Sean Davis wrote:

> I would like to add a legend to a pairs plot.  Is there a simple way to 
> do this?  Just doing legend(.....) doesn't seem to get it.


For sure you have specified wrong x,y values.
See par("usr") for the range or try it interactively using:

legend(locator(1), ......)

Uwe Ligges



> Thanks,
> Sean
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From yogesh at wharton.upenn.edu  Fri Sep 17 15:19:19 2004
From: yogesh at wharton.upenn.edu (Joshi, Yogesh)
Date: Fri, 17 Sep 2004 09:19:19 -0400
Subject: [R] help with numerical solution for two simultaneous
	nonlinearequations in 2 variables
Message-ID: <218EDA661244704185C991AEA20D926401468D48@COURIER.wharton.upenn.edu>

Thank you - optim has solved my problem.

Best regards,
Yogesh

-----Original Message-----
Hi,

Suppose you have p equations in p unknowns:
F1(x1,x2,...,xp) =0
.
.
.
Fp(x1,x2,...,xp) = 0

You can solve the equivalent minimization problem: 
G(x1,x2,...,xp) = F1^2 + ... + Fp^2 = 0

So, you can use "optim" with G as your objective function. 

Hope this is helpful,
Ravi.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Joshi, Yogesh
Sent: Thursday, September 16, 2004 10:54 PM
To: r-help at stat.math.ethz.ch
Subject: [R] help with numerical solution for two simultaneous
nonlinearequations in 2 variables

Hi,

I am relatively new to R and am trying to solve two simultaneous
nonlinear equations in two variables numerically, and was wondering if
anyone knew if any of the packages could do that.  An alternative is
writing my own code using Newton-Raphson; I did that but was not able to
get good convergence. Any ideas please? 

Thanks

Yogesh

 


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From tom_woody at swissinfo.org  Fri Sep 17 15:25:05 2004
From: tom_woody at swissinfo.org (=?ISO-8859-15?Q?Thomas_Sch=F6nhoff?=)
Date: Fri, 17 Sep 2004 15:25:05 +0200
Subject: [R] library functions looks up wrong directory
Message-ID: <414AE5B1.9000305@swissinfo.org>

Hello,

I just encountered this error from within R:

--------------------------------------------------------------
 > library()
Warning message:
library '/usr/local/lib/R/site-library' contains no package in: library()
---------------------------------------------------------------

which is basically correct since all the looked up packages are in 
/usr/lib/R/site-library, not in /usr/local

Now I am looking for a possibility to adjust my config too 
/usr/lib/R/site-library.
Is there a special config file to do this in R ?



platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    1
minor    9.1
year     2004
month    06
day      21
language R



From sdavis2 at mail.nih.gov  Fri Sep 17 15:38:40 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 17 Sep 2004 09:38:40 -0400
Subject: [R] controlling printing precision in paste()
In-Reply-To: <20040917152125.5f9b16b9@portia.local>
References: <20040917152125.5f9b16b9@portia.local>
Message-ID: <E2B6D12C-08AE-11D9-B5A4-000A95D7BA10@mail.nih.gov>

Rene,

Look at ?format.

Sean

On Sep 17, 2004, at 9:21 AM, RenE J.V. Bertin wrote:

> Hello,
>
> I can't seem to find the way to modify the precision with which 
> paste() prints its floating point numbers, more precisely the number 
> of decimal digits printed. This is apparently not controlled by 
> options( digits= ), and there is no appropriate argument to paste() 
> itself.
>
> Is this possible, and if so, how? Does one have to use round() for all 
> individual arguments, or is there a more global approach?
>
> Thanks,
> RenE Bertin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From rossini at blindglobe.net  Fri Sep 17 15:54:16 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 17 Sep 2004 06:54:16 -0700
Subject: [R] loading error of the Rcmdr library on Debian Sid [SOLVED]
In-Reply-To: <414A9C68.6050509@swissinfo.org> (Thomas
	=?iso-8859-1?q?Sch=F6nhoff's?= message of "Fri,
	17 Sep 2004 10:12:24 +0200")
References: <414A9C68.6050509@swissinfo.org>
Message-ID: <85pt4lrofr.fsf@servant.blindglobe.net>


That sounds like the result of having a too-old nvidia-common and
booting between 2.4 and 2.6 kernels.

I believe that nvidia until 2.6 likes the TLS libs, under 2.4 doesn't.




Thomas Sch??nhoff <tom_woody at swissinfo.org> writes:

> Hello,
>
> hopefully someone will remember my previous problem to load the Rcmdr
> library from within GNU R resulting in an error message:
> "libnvidia-tls.so.1: cannot handle TLS data".
>
> Some suggestions have been raised by Christian Schulz and others that
> unfortunately didn't work around this error.
> Nevertheless I felt very grateful for your suggestions!
>
> This morning I investigated this problem a bit more in depth. It
> turned out that a buggy NVidia driver (libnvidia-tls.so) is loaded by
> defualt provoking the reported problem.
>
> After renaming /usrlib/tls/ too /usr/lib/tls_old (can also be entirely
> removed!) the problem vanished inmediately and R Commander works
> smoothly out of the box!
>
> Just thought this might be of interest in case of someone else is
> affected by this NVidia related problem!
>
> regards
>
> Thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From dimitris.rizopoulos at med.kuleuven.ac.be  Fri Sep 17 16:00:24 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Fri, 17 Sep 2004 16:00:24 +0200
Subject: [R] controlling printing precision in paste()
References: <20040917152125.5f9b16b9@portia.local>
Message-ID: <003801c49cbe$adbf4810$b2133a86@www.domain>

Hi RenE,

you could easily modify the "paste" function to get what you want, 
i.e.,

paste. <- function (..., digits=16, sep=" ", collapse=NULL) {
    args <- list(...)
    if (length(args) == 0)
        if (length(collapse) == 0)
            character(0)
        else ""
    else{
        for(i in seq(along=args))
            if(is.numeric(args[[i]])) args[[i]] <- 
as.character(round(args[[i]], digits)) else args[[i]] <- 
as.character(args[[i]])
        .Internal(paste(args, sep, collapse))
    }
}
############
x <- rnorm(3)
x
paste.("x1=", x[1], ", x2=", x[2], ", x3=", x[3], sep="", 
collapse=",")
paste.("x1=", x[1], ", x2=", x[2], ", x3=", x[3], digits=3, sep="", 
collapse=",")


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "RenE J.V. Bertin" <rjvbertin at hotmail.com>
To: <r-help at r-project.org>
Sent: Friday, September 17, 2004 3:21 PM
Subject: [R] controlling printing precision in paste()


> Hello,
>
> I can't seem to find the way to modify the precision with which 
> paste() prints its floating point numbers, more precisely the number 
> of decimal digits printed. This is apparently not controlled by 
> options( digits= ), and there is no appropriate argument to paste() 
> itself.
>
> Is this possible, and if so, how? Does one have to use round() for 
> all individual arguments, or is there a more global approach?
>
> Thanks,
> RenE Bertin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Fri Sep 17 16:01:12 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 17 Sep 2004 16:01:12 +0200
Subject: [R] library functions looks up wrong directory
In-Reply-To: <414AE5B1.9000305@swissinfo.org>
References: <414AE5B1.9000305@swissinfo.org>
Message-ID: <414AEE28.20601@statistik.uni-dortmund.de>

Thomas Sch??nhoff wrote:

> Hello,
> 
> I just encountered this error from within R:
> 
> --------------------------------------------------------------
>  > library()
> Warning message:
> library '/usr/local/lib/R/site-library' contains no package in: library()
> ---------------------------------------------------------------
 >
> which is basically correct since all the looked up packages are in 
> /usr/lib/R/site-library, not in /usr/local
> 
> Now I am looking for a possibility to adjust my config too 
> /usr/lib/R/site-library.
> Is there a special config file to do this in R ?

See ?Startup

Uwe Ligges



> 
> 
> platform i386-pc-linux-gnu
> arch     i386
> os       linux-gnu
> system   i386, linux-gnu
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From buddanaak at ornl.gov  Fri Sep 17 16:09:03 2004
From: buddanaak at ornl.gov (Aruna Buddana)
Date: Fri, 17 Sep 2004 10:09:03 -0400
Subject: [R] Rggobi function error
Message-ID: <414AEFFF.4050209@ornl.gov>

Hello,
I was working  with Rggobi and was trying to use the function 
setIdentifyHandler.ggobi(f).
The error I am getting is
 Error in setIdentifyHandler.ggobi(f) : attempt to apply non-function

The function setIdentifyHandler.ggobi is

function (f, .gobi = getDefaultGGobi())
{
    gobj = unclass(.gobi)$ref
    gobj$AddCallback("identify-point", function(gg, sp, which,
        d) f(which, d))
}

AddCallback function is not recognised as a function and so the error - 
non-function.

Did I install Rggobi properly, or do I need any other add-on packages to 
implement the handlers?

I am using R-1.9.1 and Rggobi-1.0-0 in unix .

Thank you
Aruna



From wanr at ucalgary.ca  Fri Sep 17 16:32:55 2004
From: wanr at ucalgary.ca (wanr@ucalgary.ca)
Date: Fri, 17 Sep 2004 08:32:55 -0600
Subject: [R] How many records could I store in a dataframe?
Message-ID: <200409171432.i8HEWtC06770@smtp2.ucalgary.ca>

Hi all,

I have a dataframe with 2 variables and 6,000,000 records. It seems R will 
crash when the number of record is larger than 3,000,000. How many records 
could I store in a dataframe

Rui



From ligges at statistik.uni-dortmund.de  Fri Sep 17 17:05:22 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 17 Sep 2004 17:05:22 +0200
Subject: [R] How many records could I store in a dataframe?
In-Reply-To: <200409171432.i8HEWtC06770@smtp2.ucalgary.ca>
References: <200409171432.i8HEWtC06770@smtp2.ucalgary.ca>
Message-ID: <414AFD32.80205@statistik.uni-dortmund.de>

wanr at ucalgary.ca wrote:

> Hi all,
> 
> I have a dataframe with 2 variables and 6,000,000 records. It seems R will 
> crash when the number of record is larger than 3,000,000. How many records 
> could I store in a dataframe


Which version of R, which OS?
I don't think that R crashes, but it produces an error message telling 
that the amount of free memory R has access to is not sufficient.

If it really crashes, please specify a reproducible example.

In theory, if you have access to enough memory, I think something like 
2^32-1, AFAIR.

Uwe Ligges


> Rui
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jfox at mcmaster.ca  Fri Sep 17 18:35:21 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 17 Sep 2004 12:35:21 -0400
Subject: [R] Proposal for New R List: Criticism? Comments?
In-Reply-To: <16714.57140.768373.62149@gargle.gargle.HOWL>
Message-ID: <20040917163520.ZBIF4758.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Martin,

Thanks for pointing this out -- I'm ashamed to say that I forgot about
\concept{} entries. As you say (aside from people stupidly forgetting that
they exist), the problem is to get people to use them. How about requiring
one or more concept entries for each help file?

Regards,
 John

> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
> Sent: Friday, September 17, 2004 7:57 AM
> To: John Fox
> Cc: 'R-help'
> Subject: RE: [R] Proposal for New R List: Criticism? Comments?
> 
> Hi John et al.
> 
> I'm coming late to this thread (because of vacation),
> 
> >>>>> "JohnF" == John Fox <jfox at mcmaster.ca>
> >>>>>     on Fri, 10 Sep 2004 10:56:51 -0400 writes:
> 
>     JohnF> Dear Brian et al.,
> 
>     JohnF> Jonathan's search site is excellent -- I use it
>     JohnF> frequently -- and for some reason new users seem
>     JohnF> unaware of help.search(), which, despite the fact
>     JohnF> that it searches only in installed packages, I also
>     JohnF> find very useful.
> 
> yes and yes.
> 
>     JohnF> A couple of comments, however: First, if help pages
>     JohnF> from all packages were available at a central
>     JohnF> location -- e.g., at CRAN -- help.search() could have
>     JohnF> an option to search that location. Second, I still
>     JohnF> feel that it would be useful to provide some other
>     JohnF> way of searching the space of all available
>     JohnF> functions. One idea, which I mentioned in an earlier
>     JohnF> message on this thread, would be a keyword system
>     JohnF> (again, different from the current set of standard
>     JohnF> keywords). 
> 
> \concept{}  was introduced for this
> 
>     JohnF> The keywords could be accessed by help.search() 
> 
> and this happens (by default) for \concept{} entries
> 
>     JohnF> and also compiled into an index.
> 
> this doesn't happen yet.
> 
> The ``real problem'' of course is that package authors need 
> to write all these \concept{} entries before such an index 
> can really become useful.
> 
> Martin Maechler
> 
>     >> -----Original Message-----
>     >> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
>     >> Sent: Friday, September 10, 2004 5:26 AM
>     >> To: Jonathan Baron
>     >> Cc: Adaikalavan Ramasamy; John Fox; R-help; 'Berton Gunter'
>     >> Subject: Re: [R] Proposal for New R List: Criticism? Comments?
>     >> 
>     >> On Fri, 10 Sep 2004, Jonathan Baron wrote:
>     >> 
>     >> > On 09/10/04 03:54, Adaikalavan Ramasamy wrote:
>     >> > >There is another issue to be considered. Currently you 
>     >> need to have 
>     >> > >the relevant packages installed before help.search() bring 
>     >> it up. My 
>     >> > >work around this is to install all available 
> packages just in case 
>     >> > >the function I need is nestled in some non-standard 
>     >> packages. I also 
>     >> > >update them rather frequently.
>     >> > 
>     >> > I do this too, at my search site (where 
>     >> "frequently"=monthly) and you 
>     >> > can search functions only, and use Boolean search 
> expressions and 
>     >> > phrases.
>     >> > 
>     >> > But right now the entire set of packages takes about 885 
>     >> meg (if I'm 
>     >> > reading du correctly), which is less than my very modest 
>     >> collection of 
>     >> > digital photos, and a tiny fraction of a 3-year-old 
> standard hard 
>     >> > disk.  In other words, it is no big deal to install all the 
>     >> packages 
>     >> > if you have your own computer.
>     >> 
>     >> I am seeing about 520Mb for all base + CRAN packages under 
>     >> 1.9.1, and it will be rather less under 2.0.0 as more parts 
>     >> are stored compressed.
>     >> BioC is a lot larger.
>     >> 
>     >> It is however, a BIG deal to install *all* the packages and 
>     >> am I currently 10 short since they depend on other software 
>     >> that I do not have a licence for or will not compile (and 
>     >> there are three others I cannot reinstall using current gcc). 
>     >> On AMD64 and Solaris there are several others, and something 
>     >> like 20 do not install on Windows.  (I could use 
>     >> --install-fake as the CRAN checks do, but I have the almost 
>     >> complete set installed to test R changes, not test packages.)
>     >> 
>     >> So I do see some merit in having a full-text search for R 
>     >> help available at some URL, as Jonathan has kindly provided.
>     >> 
>     >> -- 
>     >> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>     >> Professor of Applied Statistics,  
> http://www.stats.ox.ac.uk/~ripley/
>     >> University of Oxford,             Tel:  +44 1865 272861 (self)
>     >> 1 South Parks Road,                     +44 1865 272866 (PA)
>     >> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ej at duvel.ir.iit.edu  Fri Sep 17 18:36:45 2004
From: ej at duvel.ir.iit.edu (Eric)
Date: Fri, 17 Sep 2004 11:36:45 -0500
Subject: [R] RSPerl Causes Segfaults with Perl 5.8.0 and R 1.9.1 on Redhat9
Message-ID: <20040917163645.GB20861@duvel.ir.iit.edu>

RSPerl causes random segfaults (it occassionally works) in
Rf_isValidName () from /usr/lib/R/bin/libR.so when I call wilcox.test
on some perl array references.  This is with R built from the
r-project source RPM modified to have the --enable-shared-R option and
RSPerl built with the default options, except for having to set
PERL_MODULES to not include modperl or Apache.

any ideas?
eric.

-- 
http://ir.iit.edu/~ej



From maechler at stat.math.ethz.ch  Fri Sep 17 18:39:33 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 17 Sep 2004 18:39:33 +0200
Subject: [R] bagplot()
In-Reply-To: <Pine.LNX.4.44.0409131645200.19598-100000@gannet.stats>
References: <web-1865915@calmail-be1.berkeley.edu>
	<Pine.LNX.4.44.0409131645200.19598-100000@gannet.stats>
Message-ID: <16715.4933.392083.824916@gargle.gargle.HOWL>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Mon, 13 Sep 2004 16:49:31 +0100 (BST) writes:

    BDR> There is no bagplot function in S-PLUS.
    BDR> There is one by Rousseeuw et al for S at

    BDR> http://www.agoras.ua.ac.be/Locdept.htm

    BDR> and a reply in the archives about the problems of porting at:

    BDR> http://maths.newcastle.edu.au/~rking/R/help/03b/4916.html

    BDR> My guess is that like several other cases, R porting
    BDR> has exposed bugs in the original code.

Indeed!
as mentioned in the r-help message in the above link,
Christian Keller had spent some time in porting it, and I had
(spent more time!) in try to modularize (separate computation
from plotting) and other enhancements.

This lead to more extensive testing that AFAIR revealed
quite problematic bugs (hidden in Fortran) that I never got
around to diagnose or fix.

E.g.,

 x0 <- c(1, 5,  6,  6,   6,  6,  6, 7, 7,  8, 11,  13)
 y0 <- c(2, 3.5,4,  4.5, 4.5,5,  5, 5, 5,  5.5,5.5, 7)

 r <- bagplot(x0,y0, ident=FALSE)
 ## gives

 ## [1] The coordinates of the Tukey median are ( 6.75 , 4.875 ).
 ## [1] "The bag is only plotted when there are at least 15 observations."
 
 ## and a 'spider' (instead of a bag) since it there only 12 observations.
 ## This is as desired.

but repeating the bagplot() call twice (hence, doing it three times)
leads to a segmentation fault, both in S-plus 6.2 with the
original code and in R ("all versions") with my improved code.


    BDR> On Mon, 13 Sep 2004, Matthew David Sylvester wrote:

    >> I saw a little discussion about this in the archives, but it was unclear
    >> to me whether someone had submitted a port to R of the Splus bagplot()
    >> function.  If so, does anyone know where I could get it?  Thanks.



From natalyat84 at mail.ru  Fri Sep 17 19:38:47 2004
From: natalyat84 at mail.ru (=?koi8-r?Q?=EE=C1=D4=C1=CC=C9=D1=20=F4=C9=D4=CF=D7=C1=20?=)
Date: Fri, 17 Sep 2004 13:38:47 -0400
Subject: [R] (no subject)
Message-ID: <E1C8Mh5-000LEU-00.natalyat84-mail-ru@f13.mail.ru>

I have one problem with finding the appropriate functions in R that would perform this operation: We have X, the independent variable, and Y, the response variable, so that a regression line of these variables can be calculated. Using the Student t distribution, we need to find the 95% prediction interval of the mean of Y for the certain value of X. For example, R has the built-in data ( data(cars) ) for cars' speed as the independent variable and cars' stopping distance as the response variable. Find 95% prediction interval of mean stopping distance for cars speeding at 30.  

I have another question: is there a certain function in R that can calculate the probability p using the Student t distribution given the certain value, the sample mean, and the sample standard deviation, and df (i.e., the one that functions like pnorm(), but deals with Student t distribution.)



From spencer.graves at pdf.com  Fri Sep 17 19:54:45 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 17 Sep 2004 10:54:45 -0700
Subject: [R] (no subject)
In-Reply-To: <E1C8Mh5-000LEU-00.natalyat84-mail-ru@f13.mail.ru>
References: <E1C8Mh5-000LEU-00.natalyat84-mail-ru@f13.mail.ru>
Message-ID: <414B24E5.6040804@pdf.com>

      Have you considered "predict.lm", at least in R 1.9.1?  (If I 
understand your question, it is answered in the "examples" to 
"predict.lm".) 

      hope this helps. 
p.s.  I believe this is described in Venables and Ripley, Modern Applied 
Statistics with S, but I don't have this book at my fingertips.  Also, 
have you read the posting" guide! 
http://www.R-project.org/posting-guide.html"?  Its suggestions might 
help you get quicker answers for yourself without waiting for this list 
to reply and might improve the quality of the replies to questions you 
submit. 

?????????????? ???????????? wrote:

>I have one problem with finding the appropriate functions in R that would perform this operation: We have X, the independent variable, and Y, the response variable, so that a regression line of these variables can be calculated. Using the Student t distribution, we need to find the 95% prediction interval of the mean of Y for the certain value of X. For example, R has the built-in data ( data(cars) ) for cars' speed as the independent variable and cars' stopping distance as the response variable. Find 95% prediction interval of mean stopping distance for cars speeding at 30.  
>
>I have another question: is there a certain function in R that can calculate the probability p using the Student t distribution given the certain value, the sample mean, and the sample standard deviation, and df (i.e., the one that functions like pnorm(), but deals with Student t distribution.)
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From deepayan at stat.wisc.edu  Fri Sep 17 21:24:43 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 17 Sep 2004 14:24:43 -0500
Subject: [R] lattice: bwplot and panel.lmline()
In-Reply-To: <20040917205220.4264cc16@portia.local>
References: <20040917205220.4264cc16@portia.local>
Message-ID: <200409171424.43601.deepayan@stat.wisc.edu>

On Friday 17 September 2004 13:52, RenE J.V. Bertin wrote:
> Hello again,
>
> I am doing regressions (using panel.lmline() (and panel.abline(
> rlm(...))) ) inside a panel method which I pass to bwplot().
>
> What I would like to do is create a boxplot of categorised data
> (binned on the independent variable), and superpose a regression line
> which is calculated using the non-categorised, raw data. I expect
> that would give more accurate regression results even if a bwplot
> panel used 'world' co-ordinates.
>
> My initial idea was to do something like
>
> > bwplot( y~x|cond, panel=bwpanel )

Does 

xyplot( y~x|cond, panel=bwpanel, horizontal = FALSE )

do any better?


>
> instead of
>
> > bwplot( y~ Classify(x, binwidth=0.2) | cond, panel=bwpanel )
>
> with Classify a function which bins x and returns the result in an
> ordered factor,
>
> and
>
> bwpanel <- function(x,y, ... )
> {
>  if( is.factor(x) ){
>   panel.bwplot(x,y, ... )
>   nx<-as.numeric(x)
>  }
>  else{
>   nx<-x
>   x<-Classify(nx, binwidth=0.2 )
>   panel.bwplot(x,y, ... )
>  }
>   # add a line showing the means:
>  panel.linejoin(x,y, fun=function(x) mean(x,na.rm=TRUE), 
>                      col="red", lwd=2, ...) 
>                      panel.lmline( nx, y, ... ) 
> # snip
> }
>
> But that doesn't work: bwplot seems to do work on/with x outside of
> the panel function which require x to be a factor.

Yes, it does. If x and y are both numeric, you should use xyplot. It's 
perfectly fine to use panel.bwplot as a panel function with xyplot.

> I then tried to copy the code from bwplot into a wrapper which would
> do the formula parsing, and call bwplot with x replaced by the
> properly categorised version, but got stuck along the way.
>
> I have thus written another wrapper, in which I basically do what I
> wanted to do in bwpanel, storing the 'raw' data AND the condition
> array in an environment. I then retrieve these inside bwpanel, make
> the proper selection using
>
> bwpanel(x, y, ... )
> {
>   # snip
>   xx<- xx[ cond == levels(cond)[ list(...)$panel.counter ] ]
>   # snip
>
> }

The 'right' way to do this would be 

bwpanel <- function(x, y, subscripts, ... )
{
  # snip
  xx<- xx[subscripts]
  # snip
}


> (xx will thus have the current-panel-appropriate subset of the raw
> independent data). Then I can do the regression with the raw
> observations (y being 'raw'), but now I have to transform the
> obtained coefficients so that they are plotted correctly in the
> viewport being used (basically, the smallest factor is mapped to 1,
> the next to 2, etc).
>
> I have this working (see http://rjvbertin.free.fr/RegrInBWPlot.pdf; I
> can send the code if somebody is interested), but I wonder if
>
> 1) something like this has not been foreseen already in lattice (in
> particular, panel.abline will in general not give correct results
> when called from a bwplot panel function!

Could you expand on that? Incorrect results in what sense? panel.abline 
just draws straight lines, it doesn't work with the panel data directly 
(so, for instance, whether or not x is a factor cannot affect it). For 
variables that are factors, the scales are set up so that the levels 
correspond to integers (in other words, as.numeric(x) should give the 
correct coordinates). Given that, I'm not sure how panel.abline can 
give incorrect results.

> 2) Am I doing the right thing to subset my raw independent value
> array -- in particular, there is also a list(...)$panel.number, which
> I have only seen having the same value as $panel.counter?

As mentioned above, you should probably be using subscripts.  
panel.number and panel.counter are going to be the same unless you mess 
with perm.cond and index.cond.

Deepayan



From macq at llnl.gov  Fri Sep 17 22:01:20 2004
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 17 Sep 2004 13:01:20 -0700
Subject: [R] Using R to send to SOAP server?
Message-ID: <p06002002bd70ead8519f@[128.115.153.6]>

I have an R process continuously monitoring a data stream. When the 
data meet certain criteria, I need to send a message to a SOAP server.

Currently I'm doing this by making a system() call to execute a perl 
script, passing the message as an argument to the perl script.

I'm wondering if it can be done directly by R, and if so, whether 
there might be any performance benefit.

I've looked at RSOAP, and as far as I can tell, it's designed to work 
only in the other direction, that is, a SOAP server passes client 
commands to R, and returns the R results to the client. If I'm wrong 
about that, I'd appreciate being told so.

Thanks for any suggestions.

-Don



Here are the essential parts of the perl script.

use SOAP::Lite;

## assumes one arg
$msg = $ARGV[0];

if ($msg) {
   print "[gm-nsps.pl]  sending to NSPS\n";
   $soap = SOAP::Lite
     -> uri('http://chous-devpc.eedad.llnl.gov:9000/axis/services')
       -> 
proxy('http://chous-devpc.eedad.llnl.gov:9000/axis/services/NspsIncidentService')
	-> notifyIncidents( "$msg" );
}



Version information:
>  version
          _
platform powerpc-apple-darwin6.8.5
arch     powerpc
os       darwin6.8.5
system   powerpc, darwin6.8.5
status
major    1
minor    9.1
year     2004
month    06
day      21
language R

-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From gunter.berton at gene.com  Fri Sep 17 22:32:08 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 17 Sep 2004 13:32:08 -0700
Subject: [R] lattice: bwplot and panel.lmline()
In-Reply-To: <20040917220455.6b617aad@portia.local>
Message-ID: <200409172032.i8HKW82O029289@ohm.gene.com>


 
 I think that for this 
> kind of purpose, it would be more intuitive if bwplot would 
> accept numerical x data, together with a 'binning' argument 
> (like histogram's nint).
> 
> RenE

I strongly disagree. That's what cut() and R's functional programming style
is for. The number of arguments should be (usually) minimized in favor of
expecting users to use the features that R already provides. I think
Deepayan (and Bill Cleveland, his forbearer with trellis plots in S-Plus)
has done a fine job of doing this.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box

From roebuck at odin.mdacc.tmc.edu  Fri Sep 17 22:32:41 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Fri, 17 Sep 2004 15:32:41 -0500 (CDT)
Subject: [R] Confused about specifying plot colors as RGB values
Message-ID: <Pine.OSF.4.58.0409171450050.16651@odin.mdacc.tmc.edu>

Based on reading 'rgb' documentation, I would have thought
the following would have produced identical results. Can
someone explain how to make this happen? I need to be able
to specify an array of rgb values for the 'col' parameter.


colnames.col <- c("black", "red", "blue", "green")
colnames.rgb <- apply(as.matrix(colnames.col), 1, col2rgb)
dimnames(colnames.rgb)[[2]] <- colnames.col

baseline <- 1:32
offset2 <- 2*baseline
offset3 <- 3*baseline
offset4 <- 4*baseline
offsets <- cbind(offset2, offset3, offset4)

# Produces expected result
X11()
matplot(baseline, col = colnames.col[1], type = "l")
matlines(offsets, col = colnames.col[-1])

# Displays a ??yellow?? line
X11()
matplot(baseline, col = as.matrix(colnames.rgb[,1]), type = "l")
matlines(offsets, col = colnames.rgb[,-1])


----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From roebuck at odin.mdacc.tmc.edu  Fri Sep 17 22:41:46 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Fri, 17 Sep 2004 15:41:46 -0500 (CDT)
Subject: [R] Using R to send to SOAP server?
In-Reply-To: <p06002002bd70ead8519f@[128.115.153.6]>
References: <p06002002bd70ead8519f@[128.115.153.6]>
Message-ID: <Pine.OSF.4.58.0409171538360.16651@odin.mdacc.tmc.edu>

On Fri, 17 Sep 2004, Don MacQueen wrote:

> I have an R process continuously monitoring a data stream. When the
> data meet certain criteria, I need to send a message to a SOAP server.
>
> Currently I'm doing this by making a system() call to execute a perl
> script, passing the message as an argument to the perl script.
>
> I'm wondering if it can be done directly by R, and if so, whether
> there might be any performance benefit.
>
> I've looked at RSOAP, and as far as I can tell, it's designed to work
> only in the other direction, that is, a SOAP server passes client
> commands to R, and returns the R results to the client. If I'm wrong
> about that, I'd appreciate being told so.

SSOAP allows R to invoke SOAP methods provided by a SOAP server.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From srivas at k-state.edu  Fri Sep 17 23:07:54 2004
From: srivas at k-state.edu (Sivakumar Mohandass)
Date: Fri, 17 Sep 2004 16:07:54 -0500
Subject: [R] Ploting Mean and SE on regression lines 
Message-ID: <200409172107.i8HL73fW023679@mail-h12-03.cc.ksu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040917/7b43dc9a/attachment.pl

From drf5n at maplepark.com  Fri Sep 17 23:11:24 2004
From: drf5n at maplepark.com (David Forrest)
Date: Fri, 17 Sep 2004 16:11:24 -0500 (CDT)
Subject: [R] Removing constants from a data frame
Message-ID: <Pine.LNX.4.58.0409171546340.451@maplepark.com>


Suppose I have

x<-data.frame(v1=1:4, v2=c(2,4,NA,7), v3=rep(1,4),
     v4=LETTERS[1:4],v5=rep('Z',4))

or a much larger frame, and I wish to test for and remove the constant
numeric columns.

I made:

   is.constant<-function(x){identical(min(x),max(x))}

and
   apply(x,2,is.constant) # Works for numerics
   x[,-which(apply(x,2,is.constant))]

I'd really like to be able to delete the constant columns without losing
my non-numerics.  Ignoring the character columns would be OK.

Any suggestions?

Dave
-- 
 Dave Forrest
 drf at vims.edu                                    (804)684-7900w
 drf5n at maplepark.com                             (804)642-0662h
                                   http://maplepark.com/~drf5n/



From sfalcon at fhcrc.org  Fri Sep 17 23:14:05 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 17 Sep 2004 14:14:05 -0700
Subject: [R] Help w/ custom pkg: ERROR: installing package indices failed
Message-ID: <414B539D.6060805@fhcrc.org>

I'm using R 1.9.1 on Linux and am having trouble installing a package 
that I've written.  Would very much appreciate a hint as to where to 
look to find my mistake.

I can build the package, but when I try to install it, I get an error like:

Error in FUN(X[[as.integer(1)]], ...) : subscript out of bounds
Execution halted
ERROR: installing package indices failed

After some trial and error, I find that there is one troublesome Rd 
file.  If I remove it, I can build and install the package.  But I can't 
figure out what's wrong with the Rd file!  E.g., in ESS it previews just 
fine and appears to get built in the transcript below.

Below is a transcript of building and installing...

Building:

$ ls capsim
DESCRIPTION  R  man

$ R CMD build capsim
* checking for file 'capsim/DESCRIPTION' ... OK
* preparing 'capsim':
* removing junk files
* building 'capsim_1.0.tar.gz'

Installing:

$ R CMD INSTALL capsim_1.0.tar.gz
* Installing *source* package 'capsim' ...
** R
** help
  >>> Building/Updating help pages for package 'capsim'
      Formats: text html latex example
   collect                           text    html    latex
   collectRunData                    text    html    latex
   combineAges                       text    html    latex
   combineAges.single                text    html    latex
   combineAges3                      text    html    latex
   combineIncidenceData              text    html    latex
   combineMortalityData              text    html    latex
   getAgeAdjustmentCounts            text    html    latex
   getAllStageIncidence              text    html    latex
   getMortByStage                    text    html    latex
   getRunResults                     text    html    latex
   getSeerStageInflateMatrix         text    html    latex
   inflateSeerData                   text    html    latex
   loadIncidenceData                 text    html    latex
   loadMortalityData                 text    html    latex
   loadRRSurvData                    text    html    latex
   loadSeerData                      text    html    latex
Error in FUN(X[[as.integer(1)]], ...) : subscript out of bounds
Execution halted
ERROR: installing package indices failed
** Removing '/home/sfalcon/util/lib/R/capsim'

Here's the troublesome Rd file:

\name{combineAges3}
\title{Age adjust data and combine SEER, SEERInflated and model data 
frames.}
\description{
Use \code{getAgeAdjustmentCounts} to get standard population counts and
combine age categories using appropriate weights.
}
\usage{
combineAges3(seer, seerInflated, model, col.names)
}
\arguments{
   \item{seer}{A data frame containing SEER data.  Must contain columns 
``year'' and ``age''.}
   \item{seerInflated}{A data frame containing inflated SEER data.  Must 
contain columns ``year'' and ``age''.}
   \item{model}{A data frame containing model data.  Must contain 
columns ``year'' and ``age''. }
   \item{col.names}{ Column name of the column in both data frames that 
should be adjusted.
       For example, ``incidence'' or ``mortality''.  }
}
\details{
Hmm, not yet.
}
\value{
A data frame with columns: year, age, and source, \code{col.names}.  The
source column is a factor with levels ``model'', ``seer'', and
``seerInflated'' indicating the source of the data.
}
\references{No ref}
\author{Seth Falcon}
\note{No Notes}

\keyword{manip}



From macq at llnl.gov  Fri Sep 17 23:14:53 2004
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 17 Sep 2004 14:14:53 -0700
Subject: [R] Using R to send to SOAP server?
In-Reply-To: <Pine.OSF.4.58.0409171538360.16651@odin.mdacc.tmc.edu>
References: <p06002002bd70ead8519f@[128.115.153.6]>
	<Pine.OSF.4.58.0409171538360.16651@odin.mdacc.tmc.edu>
Message-ID: <p06002004bd71044346b3@[128.115.153.6]>

Thank you.
-Don

At 3:41 PM -0500 9/17/04, Paul Roebuck wrote:
>On Fri, 17 Sep 2004, Don MacQueen wrote:
>
>>  I have an R process continuously monitoring a data stream. When the
>>  data meet certain criteria, I need to send a message to a SOAP server.
>>
>>  Currently I'm doing this by making a system() call to execute a perl
>>  script, passing the message as an argument to the perl script.
>>
>>  I'm wondering if it can be done directly by R, and if so, whether
>>  there might be any performance benefit.
>>
>>  I've looked at RSOAP, and as far as I can tell, it's designed to work
>>  only in the other direction, that is, a SOAP server passes client
>>  commands to R, and returns the R results to the client. If I'm wrong
>>  about that, I'd appreciate being told so.
>
>SSOAP allows R to invoke SOAP methods provided by a SOAP server.
>
>----------------------------------------------------------
>SIGSIG -- signature too long (core dumped)
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From sfalcon at fhcrc.org  Sat Sep 18 00:14:21 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 17 Sep 2004 15:14:21 -0700
Subject: [R] Help w/ custom pkg: ERROR: installing package indices failed
In-Reply-To: <414B539D.6060805@fhcrc.org>
References: <414B539D.6060805@fhcrc.org>
Message-ID: <414B61BD.5000601@fhcrc.org>

Turns out adding an \alias{} line to the problem Rd file fixed the 
issue.  I'm somewhat surprised that a missing \alias line leads to error 
in FUN(X[[as.interger(1)]], ...) message.  Perhaps there was something 
else going on (my Rd file is admittedly a bit sloppy)...

+ seth



From ethund at yahoo.com  Sat Sep 18 00:32:47 2004
From: ethund at yahoo.com (Don)
Date: Fri, 17 Sep 2004 15:32:47 -0700 (PDT)
Subject: [R] ANOVA help
Message-ID: <20040917223247.96273.qmail@web51901.mail.yahoo.com>

Hi,

I have a question about applying ANOVA model on a
specific experiment.  I have cell samples from 3
subjects.  Now I take some cells from them and treat
them with two agents at two levels each.  The data
look like this.

3 samples of control cell
3 cell samples of level 1 of treatment 1
3 cell samples of level 2 of treatment 1
3 cell samples of level 1 of treatment 2
3 cell samples of level 2 of treatment 2

Can I analyze the data with two-way ANOVA?  Thanks for
the response.



From kjetil at acelerate.com  Sat Sep 18 01:17:21 2004
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Fri, 17 Sep 2004 19:17:21 -0400
Subject: [R] Removing constants from a data frame
In-Reply-To: <Pine.LNX.4.58.0409171546340.451@maplepark.com>
References: <Pine.LNX.4.58.0409171546340.451@maplepark.com>
Message-ID: <414B7081.9020602@acelerate.com>

David Forrest wrote:

>Suppose I have
>
>x<-data.frame(v1=1:4, v2=c(2,4,NA,7), v3=rep(1,4),
>     v4=LETTERS[1:4],v5=rep('Z',4))
>
>or a much larger frame, and I wish to test for and remove the constant
>numeric columns.
>
>I made:
>
>   is.constant<-function(x){identical(min(x),max(x))}
>
>and
>   apply(x,2,is.constant) # Works for numerics
>   x[,-which(apply(x,2,is.constant))]
>
>I'd really like to be able to delete the constant columns without losing
>my non-numerics.  Ignoring the character columns would be OK.
>
>Any suggestions?
>
>Dave
>  
>
what about defing is.constant as
is.constant <-  function(x) {
                     if (is.numeric(x))  identical(min(x), max(x)) else 
FALSE }

Kjetil halvorsen

-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra



From deepayan at stat.wisc.edu  Sat Sep 18 03:40:13 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 17 Sep 2004 20:40:13 -0500
Subject: [R] lattice: bwplot and panel.lmline()
In-Reply-To: <20040917220455.6b617aad@portia.local>
References: <20040917205220.4264cc16@portia.local>
	<200409171424.43601.deepayan@stat.wisc.edu>
	<20040917220455.6b617aad@portia.local>
Message-ID: <200409172040.14013.deepayan@stat.wisc.edu>

On Friday 17 September 2004 15:04, RenE J.V. Bertin wrote:

[...]

>  Yes, somebody else pointed that out too. I had seen the argument,
> but not seen that it would carry the subscripts to the values being
> plotted in a given panel. Now it is obvious, of course ;) BTW: the
> xyplot manpage is not very explicit as to what arguments are common
> to all functions described: are they all?

Yes, pretty much, unless explicitly mentioned otherwise (e.g. for  
'box.ratio'). For functions not documented along with xyplot (like 
cloud, splom, etc), their own help pages will sometimes override the 
descriptions in ?xyplot.

> 8-) > 1) something like this has not been foreseen already in lattice
> (in 8-) > particular, panel.abline will in general not give correct
> results 8-) > when called from a bwplot panel function!
> 8-)
> 8-) Could you expand on that? Incorrect results in what sense?
> panel.abline 8-) just draws straight lines, it doesn't work with the
> panel data directly 8-) (so, for instance, whether or not x is a
> factor cannot affect it). For 8-) variables that are factors, the
> scales are set up so that the levels 8-) correspond to integers (in
> other words, as.numeric(x) should give the 8-) correct coordinates).
> Given that, I'm not sure how panel.abline can 8-) give incorrect
> results.
>
>  My "in general" above was a little bold. Incorrect results occur
> when your factors are in fact numerical categories, as in my case,
> where I 'bin' a [0:1] continuous variable into 0.2 wide bins. So I
> have factors 0, 0.2, ..., 1 . If I plot the full range, my category 0
> will be mapped onto your plotting co-ordinate 1, and my 1 onto your
> 6. If I then plot e.g. a unity line with panel.abline( 0, 1, ...),
> the drawn line does not correspond to the labels on the axes. Is it
> clear like that? In other words: the co-ordinates I need are
> as.numeric(as.character(x)), as my lines are expressed in terms of
> the numbers shown along both axes, and not in a frame where the
> leftmost point has X==1 and the rightmost X==levels(x)

Right, so the problem is not with panel.abline, which is doing what it's 
supposed to do, but with bwplot forcing one of its arguments from 
numeric -> factor -> numeric (actually numeric -> shingle -> numeric), 
in the process changing the numeric values.

> In this light, I'm not sure how panel.bwplot() is going to work when
> called through xyplot with numerical data: one would have to call it
> with factor(x)?. I think that for this kind of purpose, it would be
> more intuitive if bwplot would accept numerical x data, together with
> a 'binning' argument (like histogram's nint).

I see your point, but I don't think it makes sense to have bwplot accept 
numeric data. bwplot (as well as dotplot, stripplot and barchart) is 
designed to have a factor (or shingle) as one of it's variables, and in 
fact that's the main thing that makes it different from xyplot.

If you really want both variables to be numeric, you should use xyplot. 
Unfortunately, as you point out, panel.bwplot doesn't work correctly 
with xyplot; e.g., the following doesn't work:

xyplot(sample(0:5/5, 100, T) ~ rnorm(100), panel = panel.bwplot)

This should definitely be fixed, and in fact it is fixed in the 
pre-release version of 2.0.0, where panel.bwplot draws a boxplot for 
each unique value of y (or x if horizontal = F). The only thing is that 
the thickness of the `box'-es are calculated assuming a distance of 1 
between consecutive positions, so that has to be explicitly controlled, 
as in 

xyplot(sample(0:5/5, 100, T) ~ rnorm(100), panel = panel.bwplot,
       box.ratio = 0.1)

Deepayan



From jadhavpr at vcu.edu  Sat Sep 18 05:25:04 2004
From: jadhavpr at vcu.edu (Pravin)
Date: Fri, 17 Sep 2004 23:25:04 -0400
Subject: [R] Pharmacokinetics using R
Message-ID: <000d01c49d2f$172f5c20$0a00a8c0@Pravin>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040917/3764f4c6/attachment.pl

From TShort at epri-peac.com  Fri Sep 17 21:06:21 2004
From: TShort at epri-peac.com (Short, Tom)
Date: Fri, 17 Sep 2004 15:06:21 -0400
Subject: [R] [R-pkgs] 
	Announcing Rpad, a web-based workbook-style interface for R
Message-ID: <414B35AC.1030201@epri-peac.com>


Rpad is an interactive, web-based analysis system. Rpad pages are
interactive workbook-type sheets based on R. Rpad is an analysis package, a
web-page designer, and a gui designer all wrapped in one. Rpad pages are 
run from the browser and connect to R running on the server (the same 
server that hosts the web pages).

Rpad includes the R package "RpadUtils", which adds convenient code to
generate HTML widgets and convenience functions for generating web graphics
(png).

For more information and demonstrations, please see:

http://www.Rpad.org/Rpad/

Key features include:

(*) WYSIWYG editing -- The browser page is editable, so you can add 
comments or change the code or input data.

(*) GUI's -- Create GUI elements with R or with the Rpad interface.

(*) Fast -- No browser refreshes. The R process on the server stays alive 
while the browser page is open, so once the page is up and running, it is 
quite responsive.

(*) HTML output -- Create fancy HTML output using Eric Lecoutre's R2HTML.

(*) Simple plotting -- Has convenience functions to simplify creation and
presentation of web-friendly graphics.

(*) Flexible -- You can add features in a number of ways with javascript
and/or R.

(*) Cross platform -- Rpad pages work in Internet Explorer v5.5 or greater
and Mozilla (Firefox or Suite). The server-side code works in Apache in
Linux or Windows (although not as well in Windows).

(*) Open source -- Rpad brings together several powerful open-source
technologies, specifically: R, Mozile, HTMLArea, Statistics-R-0.02,
JSCookMenu, Apache, and R2HTML.

Feel free to use the r-sig-gui mailing list
(https://stat.ethz.ch/mailman/listinfo/r-sig-gui) for any feedback on Rpad, 
the demonstration pages, and especially for feedback and questions on
installing your own Rpad server.

- Tom

-- 
Tom Short
EPRI PEAC, www.epri-peac.com

T. A. Short, Electric Power Distribution Handbook, CRC Press, 2004.
http://www.crcpress.com/shopping_cart/products/product_detail.asp?sku=1791

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From ligges at statistik.uni-dortmund.de  Sat Sep 18 16:37:29 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 18 Sep 2004 16:37:29 +0200
Subject: [R] Confused about specifying plot colors as RGB values
In-Reply-To: <Pine.OSF.4.58.0409171450050.16651@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0409171450050.16651@odin.mdacc.tmc.edu>
Message-ID: <414C4829.2020406@statistik.uni-dortmund.de>

Paul Roebuck wrote:

> Based on reading 'rgb'

So, why are you not using rgb()?


 > documentation, I would have thought
> the following would have produced identical results. Can
> someone explain how to make this happen? I need to be able
> to specify an array of rgb values for the 'col' parameter.
> 
> 
> colnames.col <- c("black", "red", "blue", "green")
> colnames.rgb <- apply(as.matrix(colnames.col), 1, col2rgb)
> dimnames(colnames.rgb)[[2]] <- colnames.col
> 
> baseline <- 1:32
> offset2 <- 2*baseline
> offset3 <- 3*baseline
> offset4 <- 4*baseline
> offsets <- cbind(offset2, offset3, offset4)
> 
> # Produces expected result
> X11()
> matplot(baseline, col = colnames.col[1], type = "l")
> matlines(offsets, col = colnames.col[-1])
> 
> # Displays a ??yellow?? line
> X11()
> matplot(baseline, col = as.matrix(colnames.rgb[,1]), type = "l")
> matlines(offsets, col = colnames.rgb[,-1])
> 

Yes, because 255 is a color number that is interpreted as yellow.
Why do you think you can specify a matrix of integer values and R knows 
that you mean an rgb representation rather than color numbers?

What you can do now (but I don't think you really want to do it this 
way!) is:

   cn <- apply(colnames.rgb, 2,
     function(x) rgb(x[1], x[2], x[3], maxColorValue=255))

   matplot(baseline, col = cn[1]), type = "l")
   matlines(offsets, col = cn[-1])


Uwe Ligges



> ----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dmb at mrc-dunn.cam.ac.uk  Sat Sep 18 17:32:26 2004
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Sat, 18 Sep 2004 16:32:26 +0100 (BST)
Subject: [R] edit(crash)?
Message-ID: <Pine.LNX.4.21.0409181631360.32366-100000@mail.mrc-dunn.cam.ac.uk>


I found that the edit command kills my linux/R/emacs environment
sometimes.

How should I report this bug?



From p.dalgaard at biostat.ku.dk  Sat Sep 18 20:26:33 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Sep 2004 20:26:33 +0200
Subject: [R] edit(crash)?
In-Reply-To: <Pine.LNX.4.21.0409181631360.32366-100000@mail.mrc-dunn.cam.ac.uk>
References: <Pine.LNX.4.21.0409181631360.32366-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <x27jqrqvqe.fsf@biostat.ku.dk>

Dan Bolser <dmb at mrc-dunn.cam.ac.uk> writes:

> I found that the edit command kills my linux/R/emacs environment
> sometimes.
> 
> How should I report this bug?

Start by explaining exactly what goes wrong and what your setup is.
E.g. are you using ESS?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From murdoch at stats.uwo.ca  Sat Sep 18 20:46:23 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 18 Sep 2004 14:46:23 -0400
Subject: [R] edit(crash)?
In-Reply-To: <Pine.LNX.4.21.0409181631360.32366-100000@mail.mrc-dunn.cam.ac.uk>
References: <Pine.LNX.4.21.0409181631360.32366-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <0c0pk0poa1e0d9fj67einmrqgkb8svudd5@4ax.com>

On Sat, 18 Sep 2004 16:32:26 +0100 (BST), Dan Bolser
<dmb at mrc-dunn.cam.ac.uk> wrote:

>
>I found that the edit command kills my linux/R/emacs environment
>sometimes.
>
>How should I report this bug?

Figure out how to make the crash reproducible, then see if you can
figure out what causes the crash.  Try it out on the 2.0.0 alpha
release to see if the bug has been fixed.  If it looks like it hasn't,
use bug.report() to report all the details.

If you can't make it reproducible, it probably won't be fixed.  If you
can, and it's an R bug, it probably will be:  but it may well be an
ESS or Emacs bug.

Duncan Murdoch



From Andreas_Poller at gmx.de  Sun Sep 19 11:26:40 2004
From: Andreas_Poller at gmx.de (Andreas Poller)
Date: Sun, 19 Sep 2004 11:26:40 +0200
Subject: [R] StructTS; measurement variance zero
Message-ID: <414D50D0.90104@gmx.de>

Hello everybody,

I'm investigating several time series with StructTS, and for one series 
I get zero variance for the measurement errors (local level model).
I've read in Brian Dipleys article on time series in the R-Newsletter 
June/2002, that the airline passengers data set yields the same result.

Having the variance of epsilon as zero, I would expect the residuals (y 
- Z a) to be zero.  The substraction of data and fitted values for the 
states in fact yields zero, but the output of the KalmanRun for the 
residuals does not. So I don??t understand what??s going on.

Could someone help me with this problem?

Tanks a lot!

Andreas



From bitwrit at ozemail.com.au  Sun Sep 19 12:49:25 2004
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Sun, 19 Sep 2004 20:49:25 +1000
Subject: [R] Proposal for New R List: Criticism? Comments?
References: <20040917163520.ZBIF4758.tomts13-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <20040919121136.GBKX21774.smta02.mail.ozemail.net@there>

It seems to me that \concept{} is simply another code for "My keyword is
your search term". I do not consider myself to be one of the better
informed users of R, yet the frequency with which I resort to a full text
search is less than once a month. For such an infrequent task, I find it no
problem to fire off a full text search of the help files and occupy myself
otherwise for a minute or two.

Jim



From tom_woody at swissinfo.org  Sun Sep 19 14:21:35 2004
From: tom_woody at swissinfo.org (=?ISO-8859-15?Q?Thomas_Sch=F6nhoff?=)
Date: Sun, 19 Sep 2004 14:21:35 +0200
Subject: [R] WARNING: terminal is not fully functional
Message-ID: <414D79CF.9010609@swissinfo.org>

Hello,

first trials to run R from inside of Emacs repeatedly gives me:

----------------------------------------------------------------
 > ?sink

WARNING: terminal is not fully functional
-  (press RETURN)

-----------------------------------------------------------------

Seems like this is going to happen to all help calls using a questionmark!
Any idea how to change this, maybe this isn't subject to change at all!???





Thanks

Thomas





platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    1
minor    9.1
year     2004
month    06
day      21
language R

And:
emacs21        21.3+1-7
ess            5.2.2-2



From p.dalgaard at biostat.ku.dk  Sun Sep 19 14:40:28 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Sep 2004 14:40:28 +0200
Subject: [R] WARNING: terminal is not fully functional
In-Reply-To: <414D79CF.9010609@swissinfo.org>
References: <414D79CF.9010609@swissinfo.org>
Message-ID: <x2y8j6qvnn.fsf@biostat.ku.dk>

Thomas Sch??nhoff <tom_woody at swissinfo.org> writes:

> Hello,
> 
> first trials to run R from inside of Emacs repeatedly gives me:
> 
> ----------------------------------------------------------------
>  > ?sink
> 
> WARNING: terminal is not fully functional
> -  (press RETURN)
> 
> -----------------------------------------------------------------
> 
> Seems like this is going to happen to all help calls using a questionmark!
> Any idea how to change this, maybe this isn't subject to change at all!???
...
> emacs21        21.3+1-7
> ess            5.2.2-2

Odd. You'd get that sort of error if you tried to run a pager in a
shell buffer, but ESS should intercept it and dump the help page into
a separate buffer. Any chance you're not actually running ESS?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rossini at blindglobe.net  Sun Sep 19 16:01:15 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Sun, 19 Sep 2004 07:01:15 -0700
Subject: [R] WARNING: terminal is not fully functional
In-Reply-To: <x2y8j6qvnn.fsf@biostat.ku.dk> (Peter Dalgaard's message of "19
	Sep 2004 14:40:28 +0200")
References: <414D79CF.9010609@swissinfo.org> <x2y8j6qvnn.fsf@biostat.ku.dk>
Message-ID: <85wtyqs6hg.fsf@servant.blindglobe.net>


That looks like what happens if one runs R from one of the older
Emacs sub-shells.  (esp the pager bit).

It's possible but unlikely that something wrong with comint.  ESS
should have redirected the output of

    ?sink 

to a different buffer.

Another possibility is that you've configured things differently,
i.e. have you a edited any

    options()

(prompt, or more likely, pager, or other options?).  Emacs/ESS doesn't
like that unless you tell it about them.




Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> Thomas Sch??nhoff <tom_woody at swissinfo.org> writes:
>
>> Hello,
>> 
>> first trials to run R from inside of Emacs repeatedly gives me:
>> 
>> ----------------------------------------------------------------
>>  > ?sink
>> 
>> WARNING: terminal is not fully functional
>> -  (press RETURN)
>> 
>> -----------------------------------------------------------------
>> 
>> Seems like this is going to happen to all help calls using a questionmark!
>> Any idea how to change this, maybe this isn't subject to change at all!???
> ...
>> emacs21        21.3+1-7
>> ess            5.2.2-2
>
> Odd. You'd get that sort of error if you tried to run a pager in a
> shell buffer, but ESS should intercept it and dump the help page into
> a separate buffer. Any chance you're not actually running ESS?
>
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From adobbins at uab.edu  Sun Sep 19 17:58:15 2004
From: adobbins at uab.edu (Allan Dobbins)
Date: Sun, 19 Sep 2004 10:58:15 -0500
Subject: [R] Mac OS X Install Problem
Message-ID: <B74D0DA2-0A54-11D9-8DBC-000393DC7F62@uab.edu>

Hi,
	I just tried to install R-1.9.1 on a machine running Mac OSX 10.2.8.  
I am
the only user of the machine.  The install appears to go most of the 
way, then
fail late.  Looking at the messages written to the console, it appears 
that the
installation process does not have permission to do various things (such
as write to the disk!)

Normally when I install from a pre-built package, after hitting the 
Install button
there is a drop down box requiring that I supply the root password.  
This didn't
happen with the R install, making me wonder if the person who built the 
install
package set it up properly (perhaps there was an assumption that the 
machine
would be a multi-user machine and that software would only be installed 
by
the administrator?).

In any case, I would like to bring this to the attention of the OS X 
builder/maintainer
and see if anyone has a suggestion that doesn't require me to spend a 
lot of time.

Thanks,

Allan Dobbins



From tom_woody at swissinfo.org  Sun Sep 19 19:07:44 2004
From: tom_woody at swissinfo.org (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Sun, 19 Sep 2004 19:07:44 +0200
Subject: [R] WARNING: terminal is not fully functional
In-Reply-To: <x2y8j6qvnn.fsf@biostat.ku.dk>
References: <414D79CF.9010609@swissinfo.org> <x2y8j6qvnn.fsf@biostat.ku.dk>
Message-ID: <414DBCE0.5040704@swissinfo.org>

Hello Peter,

Peter Dalgaard schrieb:

>>emacs21        21.3+1-7
>>ess            5.2.2-2
> 
> 
> Odd. You'd get that sort of error if you tried to run a pager in a
> shell buffer, but ESS should intercept it and dump the help page into
> a separate buffer. Any chance you're not actually running ESS?
> 

Hmm, I'm running R within Emacs without calling ESS diretly. Thought, 
that ESS is activated by default when invoking R!?
Isn't this true!?


Thomas



From p.dalgaard at biostat.ku.dk  Sun Sep 19 19:42:39 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Sep 2004 19:42:39 +0200
Subject: [R] WARNING: terminal is not fully functional
In-Reply-To: <414DBCE0.5040704@swissinfo.org>
References: <414D79CF.9010609@swissinfo.org> <x2y8j6qvnn.fsf@biostat.ku.dk>
	<414DBCE0.5040704@swissinfo.org>
Message-ID: <x2u0tuqho0.fsf@biostat.ku.dk>

Thomas Sch??nhoff <tom_woody at swissinfo.org> writes:

> Hello Peter,
> 
> Peter Dalgaard schrieb:
> 
> >>emacs21        21.3+1-7
> >>ess            5.2.2-2
> > Odd. You'd get that sort of error if you tried to run a pager in a
> > shell buffer, but ESS should intercept it and dump the help page into
> > a separate buffer. Any chance you're not actually running ESS?
> >
> 
> Hmm, I'm running R within Emacs without calling ESS diretly. Thought,
> that ESS is activated by default when invoking R!?
> Isn't this true!?

I thought you might think that...

No. Loading ESS creates M-x R, which you should use to start R and get
all the associated goodies.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From tom_woody at swissinfo.org  Sun Sep 19 20:05:33 2004
From: tom_woody at swissinfo.org (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Sun, 19 Sep 2004 20:05:33 +0200
Subject: [R] WARNING: terminal is not fully functional
In-Reply-To: <x2u0tuqho0.fsf@biostat.ku.dk>
References: <414D79CF.9010609@swissinfo.org>
	<x2y8j6qvnn.fsf@biostat.ku.dk>	<414DBCE0.5040704@swissinfo.org>
	<x2u0tuqho0.fsf@biostat.ku.dk>
Message-ID: <414DCA6D.8020105@swissinfo.org>

Hello,

Peter Dalgaard schrieb:
> Thomas Sch??nhoff <tom_woody at swissinfo.org> writes:

>>Hmm, I'm running R within Emacs without calling ESS diretly. Thought,
>>that ESS is activated by default when invoking R!?
>>Isn't this true!?
> 
> 
> I thought you might think that...
> 
> No. Loading ESS creates M-x R, which you should use to start R and get
> all the associated goodies.

Ooops, yes really tricky...... an M-x-ess-imenu-R (Godness, there are a 
lot of ess-entries!?) did the trick..

Hmm, by the way, is there any tutorial or something similar point to how 
to use Emacs, ESS and GNU R?

Many thanks for helpful advices

Thomas



From sun at cae.wisc.edu  Mon Sep 20 00:02:21 2004
From: sun at cae.wisc.edu (Sun)
Date: Sun, 19 Sep 2004 17:02:21 -0500
Subject: [R] how to draw an overlaid plot for multiple curves using
	different symbols for each curve?
References: <414D79CF.9010609@swissinfo.org><x2y8j6qvnn.fsf@biostat.ku.dk>	<414DBCE0.5040704@swissinfo.org><x2u0tuqho0.fsf@biostat.ku.dk>
	<414DCA6D.8020105@swissinfo.org>
Message-ID: <00d801c49e94$56943b40$940a5c90@Boreal>

Hello, Rusers:

I have a question to ask for your help. The data has three columns: a, b and
c.

We need to draw an overlaid plot of curves of "a" versus "b" for different
c. That is, draw many curves in one plot and each curve uses a different
symbol.

Does R have such functions? I have searched for a while. But seems not. I am
new to R. Your help is highly appreciated.

Many thanks. Looking forward to your response,

Sun



From andrewr at uidaho.edu  Mon Sep 20 00:27:28 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Mon, 20 Sep 2004 08:27:28 +1000
Subject: [R] how to draw an overlaid plot for multiple curves
	using	different symbols for each curve?
In-Reply-To: <00d801c49e94$56943b40$940a5c90@Boreal>
References: <414D79CF.9010609@swissinfo.org> <x2y8j6qvnn.fsf@biostat.ku.dk>
	<414DBCE0.5040704@swissinfo.org> <x2u0tuqho0.fsf@biostat.ku.dk>
	<414DCA6D.8020105@swissinfo.org>
	<00d801c49e94$56943b40$940a5c90@Boreal>
Message-ID: <20040919222728.GA818@uidaho.edu>

Sun,

here are some options.  You can use points() to add new points to a
plot, or you can use par(new=T) to plot a new graph in a previously-
used device.  So, in code the two options would look like:

plot(x1, y1, pch=1)
points(x2, y2, pch=2)

(this preserves the original axes) or

plot(x1, y1, pch=1)
par(new=T)
plot(x2, y2, pch=2)

for which the new plot will have new axes etc., so if you want to
perserve the axis characteristics then you need to do so seperately.

I did not include details about subsetting.  I hope that this helps.

Andrew

On Sun, Sep 19, 2004 at 05:02:21PM -0500, Sun wrote:
> Hello, Rusers:
> 
> I have a question to ask for your help. The data has three columns: a, b and
> c.
> 
> We need to draw an overlaid plot of curves of "a" versus "b" for different
> c. That is, draw many curves in one plot and each curve uses a different
> symbol.
> 
> Does R have such functions? I have searched for a while. But seems not. I am
> new to R. Your help is highly appreciated.
> 
> Many thanks. Looking forward to your response,
> 
> Sun
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Andrew Robinson                      Ph: 208 885 7115
Department of Forest Resources       Fa: 208 885 6226
University of Idaho                  E : andrewr at uidaho.edu
PO Box 441133                        W : http://www.uidaho.edu/~andrewr
Moscow ID 83843                      Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.



From ruidantas at netcabo.pt  Mon Sep 20 01:00:34 2004
From: ruidantas at netcabo.pt (Rui Dantas)
Date: Mon, 20 Sep 2004 00:00:34 +0100
Subject: [R] Nnet: Returning the response
Message-ID: <012b01c49e9c$7bb12430$915c5451@maipcrpdantas>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040920/c644068d/attachment.pl

From sdavis2 at mail.nih.gov  Mon Sep 20 01:49:42 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Sun, 19 Sep 2004 19:49:42 -0400
Subject: [R] how to draw an overlaid plot for multiple curves
	usingdifferent symbols for each curve?
References: <414D79CF.9010609@swissinfo.org><x2y8j6qvnn.fsf@biostat.ku.dk>	<414DBCE0.5040704@swissinfo.org><x2u0tuqho0.fsf@biostat.ku.dk><414DCA6D.8020105@swissinfo.org>
	<00d801c49e94$56943b40$940a5c90@Boreal>
Message-ID: <001e01c49ea3$588dc380$04653744@WATSON>

You might look at library(lattice) for some relatively natural solutions for
your problem.

Sean

----- Original Message -----
From: "Sun" <sun at cae.wisc.edu>
To: "R User-Liste" <r-help at stat.math.ethz.ch>
Sent: Sunday, September 19, 2004 6:02 PM
Subject: [R] how to draw an overlaid plot for multiple curves usingdifferent
symbols for each curve?


> Hello, Rusers:
>
> I have a question to ask for your help. The data has three columns: a, b
and
> c.
>
> We need to draw an overlaid plot of curves of "a" versus "b" for different
> c. That is, draw many curves in one plot and each curve uses a different
> symbol.
>
> Does R have such functions? I have searched for a while. But seems not. I
am
> new to R. Your help is highly appreciated.
>
> Many thanks. Looking forward to your response,
>
> Sun
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From rossini at blindglobe.net  Mon Sep 20 01:50:39 2004
From: rossini at blindglobe.net (A.J. Rossini)
Date: Sun, 19 Sep 2004 16:50:39 -0700
Subject: [R] WARNING: terminal is not fully functional
In-Reply-To: <414DCA6D.8020105@swissinfo.org> (Thomas
	=?iso-8859-1?q?Sch=F6nhoff's?= message of "Sun,
	19 Sep 2004 20:05:33 +0200")
References: <414D79CF.9010609@swissinfo.org> <x2y8j6qvnn.fsf@biostat.ku.dk>
	<414DBCE0.5040704@swissinfo.org> <x2u0tuqho0.fsf@biostat.ku.dk>
	<414DCA6D.8020105@swissinfo.org>
Message-ID: <85vfe9rf74.fsf@servant.blindglobe.net>

Thomas Sch??nhoff <tom_woody at swissinfo.org> writes:

> Hello,
>
> Peter Dalgaard schrieb:
>> Thomas Sch??nhoff <tom_woody at swissinfo.org> writes:
>
>>>Hmm, I'm running R within Emacs without calling ESS diretly. Thought,
>>>that ESS is activated by default when invoking R!?
>>>Isn't this true!?
>> I thought you might think that...
>> No. Loading ESS creates M-x R, which you should use to start R and
>> get
>> all the associated goodies.
>
> Ooops, yes really tricky...... an M-x-ess-imenu-R (Godness, there are
> a lot of ess-entries!?) did the trick..
>
> Hmm, by the way, is there any tutorial or something similar point to
> how to use Emacs, ESS and GNU R?

There are a few, some at http://ESS.R-Project.org/

I'll put my versions up after I get settled in Basel (mid November).

best,
-tony

-- 
Anthony Rossini			    Research Associate Professor
rossini at u.washington.edu            http://www.analytics.washington.edu/ 
Biomedical and Health Informatics   University of Washington
Biostatistics, SCHARP/HVTN          Fred Hutchinson Cancer Research Center
UW (Tu/Th/F): 206-616-7630 FAX=206-543-3461 | Voicemail is unreliable
FHCRC  (M/W): 206-667-7025 FAX=206-667-4812 | use Email

CONFIDENTIALITY NOTICE: This e-mail message and any attachme...{{dropped}}



From sun at cae.wisc.edu  Mon Sep 20 01:55:20 2004
From: sun at cae.wisc.edu (Sun)
Date: Sun, 19 Sep 2004 18:55:20 -0500
Subject: [R] how to draw an overlaid plot for multiple curves
	usingdifferent symbols for each curve?
References: <414D79CF.9010609@swissinfo.org><x2y8j6qvnn.fsf@biostat.ku.dk>	<414DBCE0.5040704@swissinfo.org><x2u0tuqho0.fsf@biostat.ku.dk><414DCA6D.8020105@swissinfo.org>
	<00d801c49e94$56943b40$940a5c90@Boreal>
	<001e01c49ea3$588dc380$04653744@WATSON>
Message-ID: <015d01c49ea4$1ed2e7a0$940a5c90@Boreal>

Hi, Thanks all (Andrew, Peter, Sean)!

By the way, I looked at the "xyplot" in lattice library. It can draw "a"
versus "b", conditioned on "c". But it draws curves in different panels and
there seems no control on symbols.

I will try "points".

Many thanks again,

Sun
----- Original Message ----- 
From: "Sean Davis" <sdavis2 at mail.nih.gov>
To: "Sun" <sun at cae.wisc.edu>; "R User-Liste" <r-help at stat.math.ethz.ch>
Sent: Sunday, September 19, 2004 6:49 PM
Subject: Re: [R] how to draw an overlaid plot for multiple curves
usingdifferent symbols for each curve?


> You might look at library(lattice) for some relatively natural solutions
for
> your problem.
>
> Sean
>
> ----- Original Message -----
> From: "Sun" <sun at cae.wisc.edu>
> To: "R User-Liste" <r-help at stat.math.ethz.ch>
> Sent: Sunday, September 19, 2004 6:02 PM
> Subject: [R] how to draw an overlaid plot for multiple curves
usingdifferent
> symbols for each curve?
>
>
> > Hello, Rusers:
> >
> > I have a question to ask for your help. The data has three columns: a, b
> and
> > c.
> >
> > We need to draw an overlaid plot of curves of "a" versus "b" for
different
> > c. That is, draw many curves in one plot and each curve uses a different
> > symbol.
> >
> > Does R have such functions? I have searched for a while. But seems not.
I
> am
> > new to R. Your help is highly appreciated.
> >
> > Many thanks. Looking forward to your response,
> >
> > Sun
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
>
>
>



From deepayan at stat.wisc.edu  Mon Sep 20 02:26:14 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Sun, 19 Sep 2004 19:26:14 -0500
Subject: [R] how to draw an overlaid plot for multiple curves
	usingdifferent symbols for each curve?
In-Reply-To: <015d01c49ea4$1ed2e7a0$940a5c90@Boreal>
References: <414D79CF.9010609@swissinfo.org>
	<001e01c49ea3$588dc380$04653744@WATSON>
	<015d01c49ea4$1ed2e7a0$940a5c90@Boreal>
Message-ID: <200409191926.15077.deepayan@stat.wisc.edu>

On Sunday 19 September 2004 18:55, Sun wrote:
> Hi, Thanks all (Andrew, Peter, Sean)!
>
> By the way, I looked at the "xyplot" in lattice library. It can draw
> "a" versus "b", conditioned on "c". But it draws curves in different
> panels and there seems no control on symbols.

You should get what you want with 

xyplot(b ~ a, groups = c)

You can control plotting symbol with the 'pch' argument.

Deepayan



From Kevin.Wang at maths.anu.edu.au  Mon Sep 20 02:45:45 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Mon, 20 Sep 2004 10:45:45 +1000 (EST)
Subject: [R] Using eval() more efficiently?
Message-ID: <Pine.GSO.4.58.0409201037280.21838@yin>

Hi,

Suppose I have a vector:
  > names.select
  [1] "Idd13"   "Idd14"   "Idd8.12" "Idd7"
automatically generated by some selection criteria.

Now, if I have a data frame with many variables, of which the variables in
"names.select" are also variables from the data frame.  e.g.
  > all.df[1:5,]
    Mouse Idd5 Idd6.19.20 Idd13 Idd14 Idd8.12 Idd3.10.17.18 Idd9
  1   904   F1        NOD   NOD    F1     NOD            F1  NOD
  2   934  NOD         F1    F1    F1      F1           NOD  NOD
  3   950  NOD        NOD    F1   NOD      F1            F1  NOD
  4   977   F1        NOD   NOD    F1      F1            F1   F1
  5  1050   F1         F1   NOD   NOD     NOD           NOD   F1
    Idd15 Idd7 Idd2 Aire Idd4 Idd21 Cross
  1    F1  NOD  NOD  NOD  NOD   NOD     1
  2   NOD  NOD   F1   F1  NOD    F1     1
  3   NOD  NOD   F1   F1  NOD   NOD     1
  4   NOD   F1  NOD  NOD  NOD   NOD     1
  5   NOD   F1   F1   F1  NOD    F1     1

If I want to use the information from names.select to fit a glm() on
Cross, I can do something like:
  >  one.glm2 <- glm(eval(substitute(Cross ~ x1 + x2 + x3 + x4,
  +                                   list(x1 = as.name(names.select[1]),
  +                                        x2 = as.name(names.select[2]),
  +                                        x3 = as.name(names.select[3]),
  +                                        x4 =
as.name(names.select[4])))),
  +                    data = all.df, family = binomial)
which does exactly what I want.

However, this is kind of inefficient as if my selection criteria change,
the variables being selected in names.select may change and it will make
my eval() from one.glm2 invalid.

Is there a way to solve this?  e.g. if names.select has got 5 elements
then I'd want to fit something like:
  one.glm2 <- glm(eval(substitute(Cross ~ x1 + x2 + x3 + x4 + x5,
                                  list(x1 = as.name(names.select[1]),
                                       x2 = as.name(names.select[2]),
                                       x3 = as.name(names.select[3]),
                                       x4 = as.name(names.select[4]),
                                       x5 = as.name(names.select[5])))),
                  data = all.df, family = binomial)

(What I'm doing is writing a function which let's the user determine a
selection criteria, hence names.select will be unknown -- and so far I'm
very puzzled about how I can then use the information in names.select into
my one.glm2...*_*.

Cheers,

Kevin


--------------------------------
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From ggrothendieck at myway.com  Mon Sep 20 03:03:04 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 19 Sep 2004 21:03:04 -0400 (EDT)
Subject: [R] Using eval() more efficiently?
Message-ID: <20040920010304.025BE12CE3@mprdmxin.myway.com>




glm( Cross ~., all.df[,c("Cross", names.select)], family = binomial)


---

From:   	Kevin Wang <Kevin.Wang at maths.anu.edu.au>

Hi,

Suppose I have a vector:
> names.select
[1] "Idd13" "Idd14" "Idd8.12" "Idd7"
automatically generated by some selection criteria.

Now, if I have a data frame with many variables, of which the variables in
"names.select" are also variables from the data frame. e.g.
> all.df[1:5,]
Mouse Idd5 Idd6.19.20 Idd13 Idd14 Idd8.12 Idd3.10.17.18 Idd9
1 904 F1 NOD NOD F1 NOD F1 NOD
2 934 NOD F1 F1 F1 F1 NOD NOD
3 950 NOD NOD F1 NOD F1 F1 NOD
4 977 F1 NOD NOD F1 F1 F1 F1
5 1050 F1 F1 NOD NOD NOD NOD F1
Idd15 Idd7 Idd2 Aire Idd4 Idd21 Cross
1 F1 NOD NOD NOD NOD NOD 1
2 NOD NOD F1 F1 NOD F1 1
3 NOD NOD F1 F1 NOD NOD 1
4 NOD F1 NOD NOD NOD NOD 1
5 NOD F1 F1 F1 NOD F1 1

If I want to use the information from names.select to fit a glm() on
Cross, I can do something like:
> one.glm2 <- glm(eval(substitute(Cross ~ x1 + x2 + x3 + x4,
+ list(x1 = as.name(names.select[1]),
+ x2 = as.name(names.select[2]),
+ x3 = as.name(names.select[3]),
+ x4 =
as.name(names.select[4])))),
+ data = all.df, family = binomial)
which does exactly what I want.

However, this is kind of inefficient as if my selection criteria change,
the variables being selected in names.select may change and it will make
my eval() from one.glm2 invalid.

Is there a way to solve this? e.g. if names.select has got 5 elements
then I'd want to fit something like:
one.glm2 <- glm(eval(substitute(Cross ~ x1 + x2 + x3 + x4 + x5,
list(x1 = as.name(names.select[1]),
x2 = as.name(names.select[2]),
x3 = as.name(names.select[3]),
x4 = as.name(names.select[4]),
x5 = as.name(names.select[5])))),
data = all.df, family = binomial)

(What I'm doing is writing a function which let's the user determine a
selection criteria, hence names.select will be unknown -- and so far I'm
very puzzled about how I can then use the information in names.select into
my one.glm2...*_*.



From Toby.Patterson at csiro.au  Mon Sep 20 06:22:27 2004
From: Toby.Patterson at csiro.au (Toby.Patterson@csiro.au)
Date: Mon, 20 Sep 2004 14:22:27 +1000
Subject: [R] findInterval in compiled code.
Message-ID: <C4178DC99E08604EA5E2BDB989F09380025D0CD9@extas2-hba.tas.csiro.au>

Hi all, 
I am writing some C code where I want to use the findInterval function
documented in "Writing R extensions/Utility functions". i.e. the
C-version not the R version.

It all compiles but the shared library is causing seg-faults and I'm
obviously stuffing something up. 

Has anyone got any examples of calling this function they'd be will to
share? I've searched through the source of quite a few libraries and
can't find any. 

Thanks 
Toby



From respond_via_web at umr.edu  Mon Sep 20 07:48:10 2004
From: respond_via_web at umr.edu (UMR IT)
Date: Mon, 20 Sep 2004 00:48:10 -0500
Subject: [R] UMR Email Handling Issue
Message-ID: <200409200548.i8K5mA4A026285@syscron.cc.umr.edu>


You are receiving this email because our logs indicate you attempted
to send email to the following University of Missouri - Rolla (UMR)
recipients during the period from Wednesday, September 15, through
Sunday, September 19, 2004.

The following 1 messages were sent from your account to these UMR
recipients:

1 to fiolj at msx.umr.edu (Fiol, Juan)

Due to a technical issue with 1 of UMR's 12 spam handling servers some
email sent from your email account to the UMR recipients above may
have not been delivered during that time period. If you have sent
important email to the UMR recipients above and have not received a
suitable response, you should resend the message(s) as it may not have
been delivered properly.  If the recipient is not listed above, the
mail was delivered successfully.  UMR Information Technology has 
notified the recipient that some messages sent by you during that time
period may not have been delivered.

We sincerely apologize for any inconvenience this may cause.

If you have any questions or concerns please call the UMR IT Solution
Center at 573-341-4357 or you can send email to itcomm at umr.edu.



From petr.pikal at precheza.cz  Mon Sep 20 08:39:27 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 20 Sep 2004 08:39:27 +0200
Subject: [R] Removing constants from a data frame
In-Reply-To: <414B7081.9020602@acelerate.com>
References: <Pine.LNX.4.58.0409171546340.451@maplepark.com>
Message-ID: <414E973F.11607.2A8A32@localhost>



On 17 Sep 2004 at 19:17, Kjetil Brinchmann Halvorsen wrote:

> David Forrest wrote:
> 
> >Suppose I have
> >
> >x<-data.frame(v1=1:4, v2=c(2,4,NA,7), v3=rep(1,4),
> >     v4=LETTERS[1:4],v5=rep('Z',4))
> >
> >or a much larger frame, and I wish to test for and remove the
> >constant numeric columns.
> >
> >I made:
> >
> >   is.constant<-function(x){identical(min(x),max(x))}
> >
> >and
> >   apply(x,2,is.constant) # Works for numerics
> >   x[,-which(apply(x,2,is.constant))]
> >
> >I'd really like to be able to delete the constant columns without
> >losing my non-numerics.  Ignoring the character columns would be OK.
> >
> >Any suggestions?
> >
> >Dave
> >  
> >
> what about defing is.constant as
> is.constant <-  function(x) {
>                      if (is.numeric(x))  identical(min(x), max(x))
>                      else 
> FALSE }
> 
> Kjetil halvorsen

Hi
Maybe this will do it

> fff<-function(a) if(is.numeric(a)) diff(range(a, na.rm=T))==0 else FALSE
> x[,!mapply(fff,x)]
  v1 v2 v4 v5
1  1  2  A  Z
2  2  4  B  Z
3  3 NA  C  Z
4  4  7  D  Z
>
Cheers
Petr



> 
> -- 
> 
> Kjetil Halvorsen.
> 
> Peace is the most effective weapon of mass construction.
>                --  Mahdi Elmandjra
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From tom_woody at swissinfo.org  Mon Sep 20 08:44:24 2004
From: tom_woody at swissinfo.org (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Mon, 20 Sep 2004 08:44:24 +0200
Subject: [R] WARNING: terminal is not fully functional
In-Reply-To: <85vfe9rf74.fsf@servant.blindglobe.net>
References: <414D79CF.9010609@swissinfo.org>
	<x2y8j6qvnn.fsf@biostat.ku.dk>	<414DBCE0.5040704@swissinfo.org>
	<x2u0tuqho0.fsf@biostat.ku.dk>	<414DCA6D.8020105@swissinfo.org>
	<85vfe9rf74.fsf@servant.blindglobe.net>
Message-ID: <414E7C48.1090202@swissinfo.org>

Hello,

A.J. Rossini schrieb:
> Thomas Sch??nhoff <tom_woody at swissinfo.org> writes:
> 

>>
>>Peter Dalgaard schrieb:
>>
>>>Thomas Sch??nhoff <tom_woody at swissinfo.org> writes:
>>

>>
>>Hmm, by the way, is there any tutorial or something similar point to
>>how to use Emacs, ESS and GNU R?
> 
> 
> There are a few, some at http://ESS.R-Project.org/
> 
> I'll put my versions up after I get settled in Basel (mid November).


Thanks for advice!

Thomas



From geir.systad at nina.no  Mon Sep 20 12:00:37 2004
From: geir.systad at nina.no (geir.systad@nina.no)
Date: Mon, 20 Sep 2004 12:00:37 +0200
Subject: [R] compilation failed for package
Message-ID: <107A22D85FBCCC448BA66E2E8215DC48067C5D@alm.ninaniku.no>

Hello,
I am new to R on Linux (and to LINUX), running a 1.9.1 on a Linux MDK10.0. When updating or installing different packages, I get messages like this (under), the package doesn't install. Can anyone help me? I know this is all to little information, but I don't know were to start. I think there is something wrong in how or were the C++ or fortran compilator is installed??
Thanks, Geir S.


gcc -shared -L/usr/local/lib -o survival.so agexact.o agfit2.o agfit3.o agfit5.o agfit_null.o agmart2.o agmart.o agscore.o agsurv1.o agsurv2.o agsurv3.o char_date.o chinv2.o chinv3.o cholesky2.o cholesky3.o chsolve2.o chsolve3.o coxdetail.o coxfit2.o coxfit5.o coxmart.o coxph_wtest.o cox_Rcallback.o coxscho.o coxscore.o dmatrix.o doloop.o pyears1.o pyears2.o pyears3.o pystep.o surv_callback.o survdiff2.o survfit2.o survfit3.o survindex2.o survindex3.o survreg2.o survreg3.o survreg4.o survreg5.o
/usr/bin/ld: unrecognized option '--as-needed'
/usr/bin/ld: use the --help option for usage information
collect2: ld returned 1 exit status
make: *** [survival.so] Error 1
ERROR: compilation failed for package 'survival'
** Removing '/usr/lib/R/library/survival'
** Restoring previous '/usr/lib/R/library/survival'



From andy_liaw at merck.com  Mon Sep 20 12:22:33 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 20 Sep 2004 06:22:33 -0400
Subject: [R] Removing constants from a data frame
Message-ID: <3A822319EB35174CA3714066D590DCD504AF83DA@usrymx25.merck.com>

> From: Kjetil Brinchmann Halvorsen
> 
> David Forrest wrote:
> 
> >Suppose I have
> >
> >x<-data.frame(v1=1:4, v2=c(2,4,NA,7), v3=rep(1,4),
> >     v4=LETTERS[1:4],v5=rep('Z',4))
> >
> >or a much larger frame, and I wish to test for and remove 
> the constant
> >numeric columns.
> >
> >I made:
> >
> >   is.constant<-function(x){identical(min(x),max(x))}
> >
> >and
> >   apply(x,2,is.constant) # Works for numerics
> >   x[,-which(apply(x,2,is.constant))]
> >
> >I'd really like to be able to delete the constant columns 
> without losing
> >my non-numerics.  Ignoring the character columns would be OK.
> >
> >Any suggestions?
> >
> >Dave
> >  
> >
> what about defing is.constant as
> is.constant <-  function(x) {
>                      if (is.numeric(x))  identical(min(x), 
> max(x)) else 
> FALSE }

identical() is probably not the safest thing to use:
> x <- c(1, 2, NA)
> is.constant(x)
[1] TRUE

For data such as c(1, 1, 1, NA), I should think the safest answer should be
NA, because one really doesn't know whether that last number is 1 or not.

Andy
 
> -- 
> Kjetil Halvorsen.
> 
> Peace is the most effective weapon of mass construction.
>                --  Mahdi Elmandjra
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From agustin.perez at umh.es  Mon Sep 20 12:37:07 2004
From: agustin.perez at umh.es (Perez Martin, Agustin)
Date: Mon, 20 Sep 2004 12:37:07 +0200
Subject: [R] Memory Problem???
Message-ID: <79C6D1A4DD5E7B46B663C43C002123651458DF@mailer-e071.umh.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040920/3f1c8879/attachment.pl

From ligges at statistik.uni-dortmund.de  Mon Sep 20 12:52:29 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 20 Sep 2004 12:52:29 +0200
Subject: [R] Memory Problem???
In-Reply-To: <79C6D1A4DD5E7B46B663C43C002123651458DF@mailer-e071.umh.es>
References: <79C6D1A4DD5E7B46B663C43C002123651458DF@mailer-e071.umh.es>
Message-ID: <414EB66D.3090109@statistik.uni-dortmund.de>

Perez Martin, Agustin wrote:

> DeaR useRs:
>  
> I am working with 10000 files at the same time. These files are in some
> lists. When I begin to operate the memory size grows, but never exceeds the
> computer??s RAM. And suddenly R reports:
>  
>             Error: cannot allocate vector of size 23 Kb

Read the FAQs and see ?Memory, in partilcuar if you are under Windows.

Uwe Ligges

> Somebody know what can I do?
>  
> Thanks and excuse my English.
>  
> 
> ---
> 
> 
> 
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rmott at well.ox.ac.uk  Mon Sep 20 13:00:49 2004
From: rmott at well.ox.ac.uk (Richard Mott)
Date: Mon, 20 Sep 2004 12:00:49 +0100
Subject: [R] persiting complex R objects
Message-ID: <414EB861.4020000@well.ox.ac.uk>

Is there a method to save a large and complex R object (either as a 
binary or text file) so that it can be loaded and reused at a later 
time? Specifically, I am creating large lists (several thousand 
elements), each element of which is either a vector or a matrix (with ~ 
2000 rows). The dimensions of the matrices are not all the same. My 
ideal would be a set of functions of the form

obj <- create() # computes  the object
save(obj,filename)
obj <- load(filename)

-- 
----------------------------------------------------
Richard Mott       | Wellcome Trust Centre 
tel 01865 287588   | for Human Genetics
fax 01865 287697   | Roosevelt Drive, Oxford OX3 7BN



From maechler at stat.math.ethz.ch  Mon Sep 20 13:12:06 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 20 Sep 2004 13:12:06 +0200
Subject: [R] findInterval in compiled code.
In-Reply-To: <C4178DC99E08604EA5E2BDB989F09380025D0CD9@extas2-hba.tas.csiro.au>
References: <C4178DC99E08604EA5E2BDB989F09380025D0CD9@extas2-hba.tas.csiro.au>
Message-ID: <16718.47878.16597.128797@gargle.gargle.HOWL>

>>>>> "TobyP" ==   <Toby.Patterson at csiro.au>
>>>>>     on Mon, 20 Sep 2004 14:22:27 +1000 writes:

    TobyP> Hi all, 
    TobyP> I am writing some C code where I want to use the findInterval function
    TobyP> documented in "Writing R extensions/Utility functions". i.e. the
    TobyP> C-version not the R version.

(so, typically this should rather go to R-devel than R-help;
 but never mind for this time.)

    TobyP> It all compiles but the shared library is causing seg-faults and I'm
    TobyP> obviously stuffing something up. 

probably

    TobyP> Has anyone got any examples of calling this function
    TobyP> they'd be will to share? I've searched through the
    TobyP> source of quite a few libraries and can't find any.

indeed, there aren't any in the CRAN packages.

If you don't get other feedback, do try to isolate the problem
into a very minimalistic example, and if the problem persists,
use R-devel 
and give the details {maybe a URL to download the package source} 
of your (minimalistic!) package setup.
Then, we can help you further.

Regards,
Martin Maechler



From sdavis2 at mail.nih.gov  Mon Sep 20 13:15:39 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 20 Sep 2004 07:15:39 -0400
Subject: [R] persiting complex R objects
References: <414EB861.4020000@well.ox.ac.uk>
Message-ID: <001101c49f03$2c4a1f70$04653744@WATSON>

Richard,

Check out ?save and ?load.  You were correct on those.  Do you have
questions about "create"?  If so, you will probably have to be more
specific.

Sean

----- Original Message -----
From: "Richard Mott" <rmott at well.ox.ac.uk>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, September 20, 2004 7:00 AM
Subject: [R] persiting complex R objects


> Is there a method to save a large and complex R object (either as a
> binary or text file) so that it can be loaded and reused at a later
> time? Specifically, I am creating large lists (several thousand
> elements), each element of which is either a vector or a matrix (with ~
> 2000 rows). The dimensions of the matrices are not all the same. My
> ideal would be a set of functions of the form
>
> obj <- create() # computes  the object
> save(obj,filename)
> obj <- load(filename)
>
> --
> ----------------------------------------------------
> Richard Mott       | Wellcome Trust Centre
> tel 01865 287588   | for Human Genetics
> fax 01865 287697   | Roosevelt Drive, Oxford OX3 7BN
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From maechler at stat.math.ethz.ch  Mon Sep 20 13:16:10 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 20 Sep 2004 13:16:10 +0200
Subject: [R] persisting complex R objects
In-Reply-To: <414EB861.4020000@well.ox.ac.uk>
References: <414EB861.4020000@well.ox.ac.uk>
Message-ID: <16718.48122.699287.352054@gargle.gargle.HOWL>

>>>>> "Richard" == Richard Mott <rmott at well.ox.ac.uk>
>>>>>     on Mon, 20 Sep 2004 12:00:49 +0100 writes:

    Richard> Is there a method to save a large and complex R
    Richard> object (either as a binary or text file) so that it
    Richard> can be loaded and reused at a later time?
    Richard> Specifically, I am creating large lists (several
    Richard> thousand elements), each element of which is either
    Richard> a vector or a matrix (with ~ 2000 rows). The
    Richard> dimensions of the matrices are not all the same. My
    Richard> ideal would be a set of functions of the form

    Richard> obj <- create() # computes  the object
    Richard> save(obj,filename)
    Richard> obj <- load(filename)

that sounds alright.
I'd use 
    save(*, filename,  compress = TRUE)
                       ^^^^^^^^^^^^^^^
if dealing with largish objects.

Also note that
     attach(filename)
is an alternative that may be a bit cleaner for your situation
that's probably not used enough.

Regards,
Martin Maechler



From maechler at stat.math.ethz.ch  Mon Sep 20 13:19:41 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 20 Sep 2004 13:19:41 +0200
Subject: [R] Removing constants from a data frame
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF83DA@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF83DA@usrymx25.merck.com>
Message-ID: <16718.48333.450464.307950@gargle.gargle.HOWL>

>>>>> "AndyL" == Liaw, Andy <andy_liaw at merck.com>
>>>>>     on Mon, 20 Sep 2004 06:22:33 -0400 writes:

    >> From: Kjetil Brinchmann Halvorsen
    >> 
    >> David Forrest wrote:
    >> 
    >> >Suppose I have
    >> >
    >> >x<-data.frame(v1=1:4, v2=c(2,4,NA,7), v3=rep(1,4),
    >> >     v4=LETTERS[1:4],v5=rep('Z',4))
    >> >
    >> >or a much larger frame, and I wish to test for and remove 
    >> the constant
    >> >numeric columns.
    >> >
    >> >I made:
    >> >
    >> >   is.constant<-function(x){identical(min(x),max(x))}
    >> >
    >> >and
    >> >   apply(x,2,is.constant) # Works for numerics
    >> >   x[,-which(apply(x,2,is.constant))]
    >> >
    >> >I'd really like to be able to delete the constant columns 
    >> without losing
    >> >my non-numerics.  Ignoring the character columns would be OK.
    >> >
    >> >Any suggestions?
    >> >
    >> >Dave
    >> >  
    >> >
    >> what about defing is.constant as
    >> is.constant <-  function(x) {
    >>    if (is.numeric(x))  identical(min(x), max(x)) else  FALSE }

    AndyL> identical() is probably not the safest thing to use:
    >> x <- c(1, 2, NA)
    >> is.constant(x)
    AndyL> [1] TRUE

    AndyL> For data such as c(1, 1, 1, NA), I should think the
    AndyL> safest answer should be NA, because one really
    AndyL> doesn't know whether that last number is 1 or not.

yes.

Also note that is.numeric() is not what you want for data.frame
columns since it isn't true for factors and you may want to
remove constant factor columns as well.

Martin Maechler



From i.visser at uva.nl  Mon Sep 20 13:17:40 2004
From: i.visser at uva.nl (Ingmar Visser)
Date: Mon, 20 Sep 2004 13:17:40 +0200
Subject: [R] persiting complex R objects
In-Reply-To: <414EB861.4020000@well.ox.ac.uk>
Message-ID: <BD7488F4.7B32%i.visser@uva.nl>

did you look at ?save ?load ???
ingmar

On 9/20/04 1:00 PM, "Richard Mott" <rmott at well.ox.ac.uk> wrote:

> Is there a method to save a large and complex R object (either as a
> binary or text file) so that it can be loaded and reused at a later
> time? Specifically, I am creating large lists (several thousand
> elements), each element of which is either a vector or a matrix (with ~
> 2000 rows). The dimensions of the matrices are not all the same. My
> ideal would be a set of functions of the form
> 
> obj <- create() # computes  the object
> save(obj,filename)
> obj <- load(filename)



From s-plus at wiwi.uni-bielefeld.de  Mon Sep 20 13:23:40 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Mon, 20 Sep 2004 13:23:40 +0200
Subject: [R] persiting complex R objects
References: <414EB861.4020000@well.ox.ac.uk>
Message-ID: <414EBDBC.5090902@wiwi.uni-bielefeld.de>

Richard Mott wrote:

> Is there a method to save a large and complex R object (either as a 
> binary or text file) so that it can be loaded and reused at a later 
> time? Specifically, I am creating large lists (several thousand 
> elements), each element of which is either a vector or a matrix (with 
> ~ 2000 rows). The dimensions of the matrices are not all the same. My 
> ideal would be a set of functions of the form
>
> obj <- create() # computes  the object
> save(obj,filename)
> obj <- load(filename)
>
Have a look at

? dump
? source

Peter Wolf



From rmott at well.ox.ac.uk  Mon Sep 20 13:29:30 2004
From: rmott at well.ox.ac.uk (Richard Mott)
Date: Mon, 20 Sep 2004 12:29:30 +0100
Subject: [R] persiting complex R objects
In-Reply-To: <001101c49f03$2c4a1f70$04653744@WATSON>
References: <414EB861.4020000@well.ox.ac.uk>
	<001101c49f03$2c4a1f70$04653744@WATSON>
Message-ID: <414EBF1A.6040102@well.ox.ac.uk>

Thanks for the help; I feel rather foolish as I had not realised that 
the functions save() and load() already existed. They are not mentioned 
in the R docs (unless you know they exist and so can query them by name 
- the general docs describing how to manipulate R objects don't mention 
them)

- Richard

-- 
----------------------------------------------------
Richard Mott       | Wellcome Trust Centre 
tel 01865 287588   | for Human Genetics
fax 01865 287697   | Roosevelt Drive, Oxford OX3 7BN



From wolski at molgen.mpg.de  Mon Sep 20 13:32:00 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Mon, 20 Sep 2004 13:32:00 +0200
Subject: [R] persiting complex R objects
In-Reply-To: <414EB861.4020000@well.ox.ac.uk>
References: <414EB861.4020000@well.ox.ac.uk>
Message-ID: <200409201332000847.00F98A2B@mail.math.fu-berlin.de>

Hi!
?save
'save' writes an external representation of R objects to the
     specified file.  The objects can be read back from the file at a
     later date by using the function 'load' (or 'data' in some cases).


?load 

   Reload the datasets written to a file with the function 'save'.


/E
*********** REPLY SEPARATOR  ***********

On 9/20/2004 at 12:00 PM Richard Mott wrote:

>>>Is there a method to save a large and complex R object (either as a 
>>>binary or text file) so that it can be loaded and reused at a later 
>>>time? Specifically, I am creating large lists (several thousand 
>>>elements), each element of which is either a vector or a matrix (with ~ 
>>>2000 rows). The dimensions of the matrices are not all the same. My 
>>>ideal would be a set of functions of the form
>>>
>>>obj <- create() # computes  the object
>>>save(obj,filename)
>>>obj <- load(filename)
>>>
>>>-- 
>>>----------------------------------------------------
>>>Richard Mott       | Wellcome Trust Centre 
>>>tel 01865 287588   | for Human Genetics
>>>fax 01865 287697   | Roosevelt Drive, Oxford OX3 7BN
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin                'v'    
tel: 0049-30-83875219                        /   \       
mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
      wolski at molgen.mpg.de



From ahenningsen at email.uni-kiel.de  Mon Sep 20 13:34:55 2004
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Mon, 20 Sep 2004 13:34:55 +0200
Subject: [R] plot.Map with pattern instead of colors
Message-ID: <200409201334.56154.ahenningsen@email.uni-kiel.de>

Hi,

I am plotting shapefiles with plot.Map (package maptools). So far I use 
different colors for the shapes depending on the a value that belongs to the 
shape. Now, I need to produce maps only in black, gray and white for 
publication. Is it possible to fill shapes with pattern (e.g. hatched) 
instead of colors? 

Details of a simplified example:
I want to show the percentage change of a variable in a map:
e.g. following levels
a) >+10
b) +5% to +10%
c) -5% to +5%
d) -10% to -5%
e) <-10%

Now I have following colors
a) "red"
b) "orange"
c) "white"
d) "greenyellow"
e) "green3" 

Printing this on a monochrome printer is - of course - stupid, because levels 
a) and e) as well as b) and d) have approximately the same grayscale. 
I could fill a) = black and e) = white, and everything inbetween with an 
appropriate grayscale, but I prefer to have areas with no change to appear 
white rather than medium gray. Therefore, I thought of doing following:
a) black
b) gray
c) white
d) hatched with thin lines
e) hatched with thick lines (or double-hatched)

Any hints and ideas are welcome!
(BTW: I use R 1.9.1 on SuSE Linux 9.0)

Thanks,
Arne

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From K.E.Vorloou at durham.ac.uk  Mon Sep 20 13:38:42 2004
From: K.E.Vorloou at durham.ac.uk (Costas Vorlow)
Date: Mon, 20 Sep 2004 12:38:42 +0100
Subject: [R] GARCH model query
Message-ID: <414EC142.7030004@durham.ac.uk>

Hello,

I am trying to find an easy way to estimate  the following:

y = Function(x) + lag(x,1) + garch_error_component

Any clues?

Best regards,
Costas

---



From Roger.Bivand at nhh.no  Mon Sep 20 14:20:58 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 20 Sep 2004 14:20:58 +0200 (CEST)
Subject: [R] plot.Map with pattern instead of colors
In-Reply-To: <200409201334.56154.ahenningsen@email.uni-kiel.de>
Message-ID: <Pine.LNX.4.44.0409201411080.20563-100000@reclus.nhh.no>

On Mon, 20 Sep 2004, Arne Henningsen wrote:

> Hi,
> 
> I am plotting shapefiles with plot.Map (package maptools). So far I use 
> different colors for the shapes depending on the a value that belongs to the 
> shape. Now, I need to produce maps only in black, gray and white for 
> publication. Is it possible to fill shapes with pattern (e.g. hatched) 
> instead of colors? 

Not in plot.Map(). This is supported if you convert the shapefile polygons 
to a polylist object (Map2poly()), then use plot.polylist() - but this may 
not be your choice. Within plot.Map, I would suggest using the 
RColorBrewer package and the sequential "Greys" palette, which 
differentiates five grey colours very well for most media.

If you run this after example(plot.Map), it should illustrate a solution:

library(RColorBrewer)
pal <- brewer.pal(5, "Greys")
fgs <- pal[findInterval(x$att.data$BIR74, res$breaks, all.inside=TRUE)]
plot(x, fg=fgs)

for the default quantile breaks.

> 
> Details of a simplified example:
> I want to show the percentage change of a variable in a map:
> e.g. following levels
> a) >+10
> b) +5% to +10%
> c) -5% to +5%
> d) -10% to -5%
> e) <-10%
> 
> Now I have following colors
> a) "red"
> b) "orange"
> c) "white"
> d) "greenyellow"
> e) "green3" 
> 
> Printing this on a monochrome printer is - of course - stupid, because levels 
> a) and e) as well as b) and d) have approximately the same grayscale. 
> I could fill a) = black and e) = white, and everything inbetween with an 
> appropriate grayscale, but I prefer to have areas with no change to appear 
> white rather than medium gray. Therefore, I thought of doing following:
> a) black
> b) gray
> c) white
> d) hatched with thin lines
> e) hatched with thick lines (or double-hatched)
> 
> Any hints and ideas are welcome!
> (BTW: I use R 1.9.1 on SuSE Linux 9.0)
> 
> Thanks,
> Arne
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From francesca.mata at excite.it  Mon Sep 20 14:30:01 2004
From: francesca.mata at excite.it (francesca.mata@excite.it)
Date: Mon, 20 Sep 2004 14:30:01 +0200
Subject: [R] montecarlo simulation
Message-ID: <4136E8FA00037DD8@mail-2.tiscali.it>

Hy!
I would like to know how run a montecarlo simulation with R.
Thank you!!!!
Francesca Matalucci

__________________________________________________________________
Accesso Internet Gratis per utenti Excite! Attivalo subito!
http://www.excite.it/hitech/accesso

Il Mio Excite. Personalizza la tua Home page Excite come vuoi tu!
http://www.excite.it

AAA/Relazioni. Sfoglia gli annunci e trova la tua anima gemella
http://www.excite.it/relazioni



From david_foreman at doctors.org.uk  Mon Sep 20 12:33:37 2004
From: david_foreman at doctors.org.uk (david_foreman@doctors.org.uk)
Date: Mon, 20 Sep 2004 12:33:37 (GMT)
Subject: [R] asypow.noncent: how does it work?
Message-ID: <1095683617_11977@drn10msi01>

I am trying to do power calculations for the proportional odds model using the asypow library.

The code
 
noncenta90b10<-asypow.noncent(theta.ha=a9010,info.mat=infomatrixa90b10,constraints=constrt)

returns

Error in max(..., na.rm = na.rm) : invalid "mode" of argument.

the various arguments I've used are:
 a9010
           [,1]
[1,] -1.7357568
[2,] -0.1928619
specifying the theta.ha array as a row not a column makes no difference


> infomatrixa90b10
             [,1]         [,2]
[1,]  0.967005807 -0.004699262
[2,] -0.004699262  0.903852346
  
> constrt
     [,1] [,2] [,3]               
[1,] "1"  "a"  "-1.92861865194525"
[2,] "1"  "b"  "0"                


I'm probably missing something very simple, but I can't see what it is.  Can anyone help?


_______________________________________________________________________
Most doctors use http://www.Doctors.net.uk e-mail.
Move to a free professional address with spam and virus protection.



From ligges at statistik.uni-dortmund.de  Mon Sep 20 14:53:18 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 20 Sep 2004 14:53:18 +0200
Subject: [R] asypow.noncent: how does it work?
In-Reply-To: <1095683617_11977@drn10msi01>
References: <1095683617_11977@drn10msi01>
Message-ID: <414ED2BE.2070104@statistik.uni-dortmund.de>

david_foreman at doctors.org.uk wrote:

> I am trying to do power calculations for the proportional odds model using the asypow library.
> 
> The code
>  
> noncenta90b10<-asypow.noncent(theta.ha=a9010,info.mat=infomatrixa90b10,constraints=constrt)
> 
> returns
> 
> Error in max(..., na.rm = na.rm) : invalid "mode" of argument.
> 
> the various arguments I've used are:
>  a9010
>            [,1]
> [1,] -1.7357568
> [2,] -0.1928619
> specifying the theta.ha array as a row not a column makes no difference
> 
> 
> 
>>infomatrixa90b10
> 
>              [,1]         [,2]
> [1,]  0.967005807 -0.004699262
> [2,] -0.004699262  0.903852346
>   
> 
>>constrt
> 
>      [,1] [,2] [,3]               
> [1,] "1"  "a"  "-1.92861865194525"
> [2,] "1"  "b"  "0"                
> 

I don't think you can specify a character matrix as constraints -- for 
sure the package maintainer knows better.

Uwe Ligges



> I'm probably missing something very simple, but I can't see what it is.  Can anyone help?
> 
> 
> _______________________________________________________________________
> Most doctors use http://www.Doctors.net.uk e-mail.
> Move to a free professional address with spam and virus protection.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From david.meyer at wu-wien.ac.at  Mon Sep 20 14:48:21 2004
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Mon, 20 Sep 2004 14:48:21 +0200
Subject: [R] Re: What is nu-regression for svm?
In-Reply-To: <200409181013.i8IA581K018339@hypatia.math.ethz.ch>
References: <200409181013.i8IA581K018339@hypatia.math.ethz.ch>
Message-ID: <20040920144821.7fa0428d.david.meyer@wu-wien.ac.at>

Look up the reference given at the help-page, it tells you exactly what
nu-regression does.

best,
-d

> Date: Fri, 17 Sep 2004 11:24:03 +0100
> From: jmoreira at fe.up.pt
> Subject: [R] What is nu-regression for svm?
> To: r-help at stat.math.ethz.ch
> Message-ID: <1095416643.414abb436a119 at webmail.fe.up.pt>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> 
> Does anyone knows what is the nu-regression option for the type
> parameter in svm (from package e1071)? I cannot find any explanation
> on that and I have a reasonable understanding on svm fundamentals.
> 
> Thanks
> 
> Joao Moreira
>
 
----- 
David Meyer
Department of Information Systems

Vienna University of Economics and Business Administration
Augasse 2-6, A-1090 Wien, Austria, Europe
Fax: +43-1-313 36x746 
Tel: +43-1-313 36x4393
HP:  http://wi.wu-wien.ac.at/Wer_sind_wir/meyer/



From Joseph.Warfield at jhuapl.edu  Mon Sep 20 15:00:03 2004
From: Joseph.Warfield at jhuapl.edu (Warfield Jr., Joseph D.)
Date: Mon, 20 Sep 2004 09:00:03 -0400
Subject: [R] R/web interface
Message-ID: <DCDADCD5729B7749A817C533425F93E31BEC73@aplesliberty.dom1.jhuapl.edu>

I am trying to develop an interactive software and would like to know how I
can hook up R to the web.

Thanks
Joe Warfield



From ozric at web.de  Mon Sep 20 15:00:39 2004
From: ozric at web.de (Christian Schulz)
Date: Mon, 20 Sep 2004 15:00:39 +0200
Subject: [R] montecarlo simulation
In-Reply-To: <4136E8FA00037DD8@mail-2.tiscali.it>
References: <4136E8FA00037DD8@mail-2.tiscali.it>
Message-ID: <200409201500.39121.ozric@web.de>

imho one easy example:

n <- 50
reps  <- 1000
ms  <- single(reps)
set.seed(378216)
for(i in 1:reps) {
x <- exp(rnorm(n))
ms[i] <- median(x)
}

hist(ms)

regards, christian


Am Montag, 20. September 2004 14:30 schrieb francesca.mata at excite.it:
> Hy!
> I would like to know how run a montecarlo simulation with R.
> Thank you!!!!
> Francesca Matalucci
>
> __________________________________________________________________
> Accesso Internet Gratis per utenti Excite! Attivalo subito!
> http://www.excite.it/hitech/accesso
>
> Il Mio Excite. Personalizza la tua Home page Excite come vuoi tu!
> http://www.excite.it
>
> AAA/Relazioni. Sfoglia gli annunci e trova la tua anima gemella
> http://www.excite.it/relazioni
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From FowlerM at mar.dfo-mpo.gc.ca  Mon Sep 20 15:17:01 2004
From: FowlerM at mar.dfo-mpo.gc.ca (Fowler, Mark)
Date: Mon, 20 Sep 2004 10:17:01 -0300
Subject: [R] R/web interface
Message-ID: <1A4AC4BAB9C50A42854582B69B08C03402355171@MSGMARBIO05>

Some possibilities are RWeb, RPad and Rcgi. I only have experience with RWeb
myself. A decent collection of relevant links for this subject is:

http://biostat.mc.vanderbilt.edu/twiki/bin/view/Main/StatCompCourse

[The 2nd block of the page, titled 'WWW Statistical Computing Applications
using R']

>	Mark Fowler
>	Marine Fish Division
>	Bedford Inst of Oceanography
>	Dept Fisheries & Oceans
>	Dartmouth NS Canada
>	fowlerm at mar.dfo-mpo.gc.ca
>


-----Original Message-----
From: Warfield Jr., Joseph D. [mailto:Joseph.Warfield at jhuapl.edu] 
Sent: September 20, 2004 10:00 AM
To: 'r-help at stat.math.ethz.ch'
Subject: [R] R/web interface


I am trying to develop an interactive software and would like to know how I
can hook up R to the web.

Thanks
Joe Warfield

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Mon Sep 20 15:53:13 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 20 Sep 2004 15:53:13 +0200
Subject: [R] persisting complex R objects
In-Reply-To: <414EBF1A.6040102@well.ox.ac.uk>
References: <414EB861.4020000@well.ox.ac.uk>
	<001101c49f03$2c4a1f70$04653744@WATSON>
	<414EBF1A.6040102@well.ox.ac.uk>
Message-ID: <16718.57545.744892.792120@gargle.gargle.HOWL>

>>>>> "Richard" == Richard Mott <rmott at well.ox.ac.uk>
>>>>>     on Mon, 20 Sep 2004 12:29:30 +0100 writes:

    Richard> Thanks for the help; I feel rather foolish as I had
    Richard> not realised that the functions save() and load()
    Richard> already existed. 
aha!

    Richard> They are not mentioned in the R
    Richard> docs (unless you know they exist and so can query
    Richard> them by name - the general docs describing how to
    Richard> manipulate R objects don't mention them)

which ones ("don't mention them") did you mean?

In any case,   help.search("save")  would have helped you, too.
That's another function that is still not used often enough it
seems.

Regards,
Martin



From adelmaas at MUSC.EDU  Mon Sep 20 16:00:19 2004
From: adelmaas at MUSC.EDU (adelmaas@MUSC.EDU)
Date: Mon, 20 Sep 2004 10:00:19 -0400
Subject: [R] Getting the real names of variables within functions
Message-ID: <6821059C-0B0D-11D9-B8D7-000A9591E11C@musc.edu>

Greetings.

These days I find myself writing a lot of functions to handle routine 
things.  One of these  is a function to create a scatterplot of 
variables and draw a lowessed line so I can get some idea if there's 
any relationship between them.

lowessed.plot <- function(x, y)
{	plot(x, y)
	lines(lowess(x, y))
}

However, there's a slight problem:  the plot axes come out labeled "x" 
and "y", which isn't what I want.  I want the plot axes labeled with 
the names of the variables I passed into lowessed.plot for x and y.  Is 
there any way to do that?  Thanks in advance for any help anyone can 
provide.

Aaron

-----
Aaron Solomon?? (??ben Saul Joseph??) ??Adelman
E-mail??:  ??adelmaas at musc.edu
Web site??:  ??http??://??people.musc.edu??/??~adelmaas??/??
AOL Instant Messenger?? & ??Yahoo??! ??Messenger:  ??Hiergargo  (YM account 
now sometimes with the World's first statistical Webcam, Moran's Eye)
AIM chat-room (preferred):  Adelmania



From dimitris.rizopoulos at med.kuleuven.ac.be  Mon Sep 20 16:09:48 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Mon, 20 Sep 2004 16:09:48 +0200
Subject: [R] Getting the real names of variables within functions
References: <6821059C-0B0D-11D9-B8D7-000A9591E11C@musc.edu>
Message-ID: <004601c49f1b$7cfd3980$b2133a86@www.domain>

Hi Aaron,

try to use:

plot( x, y, xlab=deparse(substitute(x)), 
 ylab=deparse(substitute(y)) )

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: <adelmaas at MUSC.EDU>
To: "list" <r-help at stat.math.ethz.ch>
Sent: Monday, September 20, 2004 4:00 PM
Subject: [R] Getting the real names of variables within functions


> Greetings.
>
> These days I find myself writing a lot of functions to handle 
> routine things.  One of these  is a function to create a scatterplot 
> of variables and draw a lowessed line so I can get some idea if 
> there's any relationship between them.
>
> lowessed.plot <- function(x, y)
> { plot(x, y)
> lines(lowess(x, y))
> }
>
> However, there's a slight problem:  the plot axes come out labeled 
> "x" and "y", which isn't what I want.  I want the plot axes labeled 
> with the names of the variables I passed into lowessed.plot for x 
> and y.  Is there any way to do that?  Thanks in advance for any help 
> anyone can provide.
>
> Aaron
>
> -----
> Aaron Solomon?? (??ben Saul Joseph??) ??Adelman
> E-mail??:  ??adelmaas at musc.edu
> Web site??:  ??http??://??people.musc.edu??/??~adelmaas??/??
> AOL Instant Messenger?? & ??Yahoo??! ??Messenger:  ??Hiergargo  (YM 
> account now sometimes with the World's first statistical Webcam, 
> Moran's Eye)
> AIM chat-room (preferred):  Adelmania
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Mon Sep 20 16:10:28 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 20 Sep 2004 10:10:28 -0400
Subject: [R] Getting the real names of variables within functions
In-Reply-To: <6821059C-0B0D-11D9-B8D7-000A9591E11C@musc.edu>
References: <6821059C-0B0D-11D9-B8D7-000A9591E11C@musc.edu>
Message-ID: <71ptk09ij6v65qmjume1delpg347e6uorc@4ax.com>

On Mon, 20 Sep 2004 10:00:19 -0400, adelmaas at MUSC.EDU wrote :

>Greetings.
>
>These days I find myself writing a lot of functions to handle routine 
>things.  One of these  is a function to create a scatterplot of 
>variables and draw a lowessed line so I can get some idea if there's 
>any relationship between them.
>
>lowessed.plot <- function(x, y)
>{	plot(x, y)
>	lines(lowess(x, y))
>}
>
>However, there's a slight problem:  the plot axes come out labeled "x" 
>and "y", which isn't what I want.  I want the plot axes labeled with 
>the names of the variables I passed into lowessed.plot for x and y.  Is 
>there any way to do that?  Thanks in advance for any help anyone can 
>provide.

You could do this with

plot(x, y, xlab=deparse(substitute(x)), ylab=deparse(substitute(y)))

But it's better to add two arguments to the function with those as
default values, then pass them on to plot(); that way you can change
the labels if you want.  And add dots for other customization.


For example,

lowessed.plot <- function(x, y, xlab=deparse(substitute(x)),
ylab=deparse(substitute(y)), ...)
{	plot(x, y, xlab=xlab, ylab=ylab, ...)
	lines(lowess(x, y))
}

Duncan Murdoch



From adelmaas at musc.edu  Mon Sep 20 16:14:11 2004
From: adelmaas at musc.edu (adelmaas@musc.edu)
Date: Mon, 20 Sep 2004 10:14:11 -0400
Subject: [R] Getting the real names of variables within functions
In-Reply-To: <71ptk09ij6v65qmjume1delpg347e6uorc@4ax.com>
References: <6821059C-0B0D-11D9-B8D7-000A9591E11C@musc.edu>
	<71ptk09ij6v65qmjume1delpg347e6uorc@4ax.com>
Message-ID: <57E02A52-0B0F-11D9-B8D7-000A9591E11C@musc.edu>

It works great now.  Thanks, guys!

Aaron


On 20 ?????? 2004, at 10:10, Duncan Murdoch wrote:

> On Mon, 20 Sep 2004 10:00:19 -0400, adelmaas at MUSC.EDU wrote :
>
>> Greetings.
>>
>> These days I find myself writing a lot of functions to handle routine
>> things.  One of these  is a function to create a scatterplot of
>> variables and draw a lowessed line so I can get some idea if there's
>> any relationship between them.
>>
>> lowessed.plot <- function(x, y)
>> {	plot(x, y)
>> 	lines(lowess(x, y))
>> }
>>
>> However, there's a slight problem:  the plot axes come out labeled "x"
>> and "y", which isn't what I want.  I want the plot axes labeled with
>> the names of the variables I passed into lowessed.plot for x and y.  
>> Is
>> there any way to do that?  Thanks in advance for any help anyone can
>> provide.
>
> You could do this with
>
> plot(x, y, xlab=deparse(substitute(x)), ylab=deparse(substitute(y)))
>
> But it's better to add two arguments to the function with those as
> default values, then pass them on to plot(); that way you can change
> the labels if you want.  And add dots for other customization.
>
>
> For example,
>
> lowessed.plot <- function(x, y, xlab=deparse(substitute(x)),
> ylab=deparse(substitute(y)), ...)
> {	plot(x, y, xlab=xlab, ylab=ylab, ...)
> 	lines(lowess(x, y))
> }
>
> Duncan Murdoch
>
-----
Aaron Solomon?? (??ben Saul Joseph??) ??Adelman
E-mail??:  ??adelmaas at musc.edu
Web site??:  ??http??://??people.musc.edu??/??~adelmaas??/??
AOL Instant Messenger?? & ??Yahoo??! ??Messenger:  ??Hiergargo
AIM chat-room (preferred):  Adelmania



From sdavis2 at mail.nih.gov  Mon Sep 20 15:11:21 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 20 Sep 2004 09:11:21 -0400
Subject: [R] montecarlo simulation
References: <4136E8FA00037DD8@mail-2.tiscali.it>
Message-ID: <000601c49f1e$a8841440$04653744@WATSON>

Francesca,

Do help.search("monte carlo").  That will be a good start.

Sean

----- Original Message -----
From: <francesca.mata at excite.it>
To: <R-help at stat.math.ethz.ch>
Sent: Monday, September 20, 2004 8:30 AM
Subject: [R] montecarlo simulation


> Hy!
> I would like to know how run a montecarlo simulation with R.
> Thank you!!!!
> Francesca Matalucci
>
> __________________________________________________________________
> Accesso Internet Gratis per utenti Excite! Attivalo subito!
> http://www.excite.it/hitech/accesso
>
> Il Mio Excite. Personalizza la tua Home page Excite come vuoi tu!
> http://www.excite.it
>
> AAA/Relazioni. Sfoglia gli annunci e trova la tua anima gemella
> http://www.excite.it/relazioni
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From sdavis2 at mail.nih.gov  Mon Sep 20 15:14:08 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 20 Sep 2004 09:14:08 -0400
Subject: [R] R/web interface
References: <DCDADCD5729B7749A817C533425F93E31BEC73@aplesliberty.dom1.jhuapl.edu>
Message-ID: <000701c49f1e$a8a09cf0$04653744@WATSON>

Joe,

You can use CGI scripts to do the coordination between R and HTML served to
the browser.  There is a new R package:

http://www.rpad.org/Rpad/

that might be of use, also.

Sean

----- Original Message -----
From: "Warfield Jr., Joseph D." <Joseph.Warfield at jhuapl.edu>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, September 20, 2004 9:00 AM
Subject: [R] R/web interface


> I am trying to develop an interactive software and would like to know how
I
> can hook up R to the web.
>
> Thanks
> Joe Warfield
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From vito_ricci at yahoo.com  Mon Sep 20 17:11:11 2004
From: vito_ricci at yahoo.com (Vito Ricci)
Date: Mon, 20 Sep 2004 17:11:11 +0200 (CEST)
Subject: [R] montecarlo simulation
Message-ID: <20040920151111.99456.qmail@web41201.mail.yahoo.com>

Ciao Francesca,

here are some examples or R code using montecarlo
simulation concernig parameters estimates of sever
random variables:


Estimate of parameter theta of a uniform variable with
ML method
Stima del parametro theta di una v.a. unif(0,theta)
con metodo
dei momenti e confronto con la stima di massima
verosimiglianza (M.V.)


theta<-5
n<-50
x<-runif(n,0,theta)
est.theta<-2*mean(x) ## stima con metodo dei momenti
var.theta<-(est.theta^3)/(3*n) ## stima della varianza
di theta
mlest.theta<-max(x) ## stima di theta con il metodo
della M.V.
acc1<-(theta-est.theta)/theta
acc2<-(theta-mlest.theta)/theta
est.theta-mlest.theta

Simulazione di una v.a. uniforme (0,t), stima di theta
con metodo dei
momenti e della M.V. e stampa dei relativi grafici

t<-2.5 ## valore parametro
n<-20  ## dimensione campionaria
k<-200 ## numero di campioni da simulare
X<-matrix(runif(n*k,0,t),nrow=n)
est.tmom<-2*apply(X,2,mean)
est.tml<-apply(X,2,max)
hist(est.tmom,nclass=10)
hist(est.tml, nclass=10,add=T,col="red")
var.x<-apply(X,2,var) ## varianza della v.a.
var.mom<-var(est.tmom)## varianza della stima com
metodo dei momenti
var.ml<-var(est.tml)  ## varianza della stima com
metodo della M.V.

medie.stime<-c(mean(est.tml),mean(est.tmom))
var.stime<-c(var.ml,var.mom)
tabella<-data.frame(medie.stime,var.stime,metodo<-c("Stima
ML","Stima Momenti"))
names(tabella)[3]<-"Metodo"
tabella

Weibull simulation

n<-50
k<-500
X<-matrix(rweibull(n*k,shape=10,scale=5),nrow=n)
mediana<-apply(X,2,median)
avg.med<-mean(mediana)
var.med<-var(mediana)
hist(mediana,freq=T)
media<-apply(X,2,mean)
avg.media<-mean(media)
var.media<-var(media)
hist(media,freq=T)
tabella<-data.frame(c(avg.med,avg.media),c(var.med,var.media))
names(tabella)<-c("statistica","varianza")
qqnorm(mediana)
qqnorm(media)
shapiro.test(mediana)
shapiro.test(media)
qqplot(mediana,media)


Beta pdf simulation
Simulazione di una variabile beta

N<-1000 ##numero osservazioni totali
n<-50 ##numero di elementi per campione
k<-N/n ##numero dei campioni
for (i in 1:n)
{
X<-matrix(rbeta(N,10,20),nrow=n)
}

n<-20
k<-200
X<-matrix(rbeta(n*k,10,20),nrow=n)

Estimate of parameters of a beta pdf with ML method
using nlm()
Stima dei parametri di una v.a. Beta con metodo della
massima verosimiglianza 
usando la funzione nlm() per un campione di ampiezza
n=100 e dei relativi errori standard

 x<-rbeta(100,10,20)
 f<-function(p)
100*log(beta(p[1],p[2]))+(1-p[1])*sum(log(x))+(1-p[2])*sum(log(1-x))
 out<-nlm(f,p=c(20,20),hessian=TRUE)


Estimate of parameters of a Gamma pdf with ML method
using nlm().
Stima di massima verosimiglianza dei parametri di una
v.a. Gamma da cui ?? stato estratto un campione di
ampiezza n=200 con l'uso della funzione nlm()

x<-rgamma(200,10,5)
f<-function(p)
(-200*p[1]*log(p[2])+200*log(gamma(p[1]))+(1-p[1])*sum(log(x))+p[2]*sum(x))
out<-nlm(f,p=c(15,10),hessian=TRUE)
out

Best
Vito



Hy!
I would like to know how run a montecarlo simulation
with R.
Thank you!!!!
Francesca Matalucci

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml


		
___________________________________

http://it.seriea.fantasysports.yahoo.com/



From s.henderson at ucl.ac.uk  Mon Sep 20 17:28:44 2004
From: s.henderson at ucl.ac.uk (Stephen Henderson)
Date: Mon, 20 Sep 2004 16:28:44 +0100
Subject: [R] adding function to a Package
Message-ID: <E7CF6BC2744CBE41AE4E87635C7C893C1C6815@exc.wibr.ucl.ac.uk>

As a shortcut I have previously added my own functions to a Package (ipred)
under R-1.8.1,  changing the NAMESPACE file to accomodate this then
reinstalling. This doesn't now seem possible in R-1.9.0 is this correct?-- I
am getting an error saying:

"files NAMESPACE, R/ipred have the wrong MD5 checksums"

after I try to reinstall (which I can understand). Is there a quick way
round this avoiding having to build my own Package?

Thanks
Stephen


**********************************************************************
This email and any files transmitted with it are confidentia...{{dropped}}



From stephane.dray at umontreal.ca  Mon Sep 20 19:24:49 2004
From: stephane.dray at umontreal.ca (Stephane DRAY)
Date: Mon, 20 Sep 2004 13:24:49 -0400
Subject: [R] Multiple operations on list
Message-ID: <5.2.1.1.0.20040920131202.03900930@magellan.umontreal.ca>

Hello,

suppose I have a list with matrices:

a=list(x1=matrix(rnorm(10),5,2),x2=matrix(rnorm(10),5,2),x3=matrix(rnorm(10),5,2))

I want to compute for all combination of xi and xj (x1,x2 x1,x3 and x2,x3) 
a value.
This value is given for the pair x1,x2 by trace(x1%*%t(x1)%*%x2%*%t(x2)) / 
trace(x1%*%t(x1))*trace(x2%*%t(x2))

I know that product matrices t(xi)%*%xi can be obtained by:

aa=lapply(a,crossprod)

but I do not know how to "mix" the values in aa to obtain the desired values.

Is there a way to do it without for loop ?

Thanks in advances,

sincerely

St??phane DRAY
-------------------------------------------------------------------------------------------------- 

D??partement des Sciences Biologiques
Universit?? de Montr??al, C.P. 6128, succursale centre-ville
Montr??al, Qu??bec H3C 3J7, Canada

Tel : (514) 343-6111 poste 1233         Fax : (514) 343-2293
E-mail : stephane.dray at umontreal.ca
-------------------------------------------------------------------------------------------------- 

Web                                          http://www.steph280.freesurf.fr/



From wolski at molgen.mpg.de  Mon Sep 20 19:36:22 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Mon, 20 Sep 2004 19:36:22 +0200
Subject: [R] Multiple operations on list
In-Reply-To: <5.2.1.1.0.20040920131202.03900930@magellan.umontreal.ca>
References: <5.2.1.1.0.20040920131202.03900930@magellan.umontreal.ca>
Message-ID: <200409201936220053.0247559E@mail.math.fu-berlin.de>

Hi!

Not sure if I got your point. 
But if it is to compute apply a function
to all pairs (x1,x2);(x1,x3);(x2,x3) where x1,x2,x3 are stored in a list you can take look at the sources 
of  function listdist which computes an object of class dist from a list, in the package "pairseqsim" available from bioconducor, to get an idea how to do this.

/E

*********** REPLY SEPARATOR  ***********

On 20.09.2004 at 13:24 Stephane DRAY wrote:

>Hello,
>
>suppose I have a list with matrices:
>
>a=list(x1=matrix(rnorm(10),5,2),x2=matrix(rnorm(10),5,2),x3=matrix(rnorm(10),5,2))
>
>I want to compute for all combination of xi and xj (x1,x2 x1,x3 and x2,x3) 
>a value.
>This value is given for the pair x1,x2 by trace(x1%*%t(x1)%*%x2%*%t(x2)) / 
>trace(x1%*%t(x1))*trace(x2%*%t(x2))
>
>I know that product matrices t(xi)%*%xi can be obtained by:
>
>aa=lapply(a,crossprod)
>
>but I do not know how to "mix" the values in aa to obtain the desired
>values.
>
>Is there a way to do it without for loop ?
>
>Thanks in advances,
>
>sincerely
>
>St??phane DRAY
>-------------------------------------------------------------------------------------------------- 
>
>D??partement des Sciences Biologiques
>Universit?? de Montr??al, C.P. 6128, succursale centre-ville
>Montr??al, Qu??bec H3C 3J7, Canada
>
>Tel : (514) 343-6111 poste 1233         Fax : (514) 343-2293
>E-mail : stephane.dray at umontreal.ca
>-------------------------------------------------------------------------------------------------- 
>
>Web                                         
>http://www.steph280.freesurf.fr/
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From gunter.berton at gene.com  Mon Sep 20 19:36:46 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 20 Sep 2004 10:36:46 -0700
Subject: [R] Multiple operations on list
In-Reply-To: <5.2.1.1.0.20040920131202.03900930@magellan.umontreal.ca>
Message-ID: <200409201736.i8KHakX6026140@volta.gene.com>

Stephane:

1. apply() functions ARE (implicit) loops.
2. ?outer might be useful, but I suspect would be even more inefficient

... so I think the answer is, no, you must loop either explicitly or
implicitly.

However, my guess is that whatever you're trying to do is either built into
R or can be done much more efficiently. Explicit matrix multiplication is
almost always avoidable in statistics.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Stephane DRAY
> Sent: Monday, September 20, 2004 10:25 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Multiple operations on list
> 
> Hello,
> 
> suppose I have a list with matrices:
> 
> a=list(x1=matrix(rnorm(10),5,2),x2=matrix(rnorm(10),5,2),x3=ma
> trix(rnorm(10),5,2))
> 
> I want to compute for all combination of xi and xj (x1,x2 
> x1,x3 and x2,x3) 
> a value.
> This value is given for the pair x1,x2 by 
> trace(x1%*%t(x1)%*%x2%*%t(x2)) / 
> trace(x1%*%t(x1))*trace(x2%*%t(x2))
> 
> I know that product matrices t(xi)%*%xi can be obtained by:
> 
> aa=lapply(a,crossprod)
> 
> but I do not know how to "mix" the values in aa to obtain the 
> desired values.
> 
> Is there a way to do it without for loop ?
> 
> Thanks in advances,
> 
> sincerely
> 
> St?phane DRAY
> --------------------------------------------------------------
> ------------------------------------ 
> 
> D?partement des Sciences Biologiques
> Universit? de Montr?al, C.P. 6128, succursale centre-ville
> Montr?al, Qu?bec H3C 3J7, Canada
> 
> Tel : (514) 343-6111 poste 1233         Fax : (514) 343-2293
> E-mail : stephane.dray at umontreal.ca
> --------------------------------------------------------------
> ------------------------------------ 
> 
> Web                                          
> http://www.steph280.freesurf.fr/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

From HStevens at muohio.edu  Mon Sep 20 20:02:21 2004
From: HStevens at muohio.edu (Hank Stevens)
Date: Mon, 20 Sep 2004 14:02:21 -0400
Subject: [R] ?glmm with correlation structure?
Message-ID: <3831EE7E-0B2F-11D9-A253-000A95CFE878@muohio.edu>

Hi folks,
I am looking for the package that will allow me to do a generalized 
(poisson) linear mixed model with spatial correlation structure. If 
gls() in nlme does this, I don't understand how to implement different 
families. If glmmPQL() in MASS does this, I don't understand what 
correlation models it accepts. It does not appear to accept the same 
models as gls(), but I may be doing something wrong.
Is there a mixed model package or function I am overlooking?
Thanks,
Hank

Martin Henry H. Stevens
338 Pearson Hall
Department of Botany
Ecology Graduate Program
Miami University
Oxford, OH 45056 USA
tel: 513-529-4206
fax: 513-529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.units.muohio.edu/ecology/
http://www.cas.muohio.edu/botany/



From ggrothendieck at myway.com  Mon Sep 20 20:41:42 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 20 Sep 2004 14:41:42 -0400 (EDT)
Subject: [R] Multiple operations on list
Message-ID: <20040920184142.4183512CC7@mprdmxin.myway.com>



You could do it with a double sapply like this:

tr <- function(x) sum(diag(x))
sapply(a, function(x1) sapply(a, function(x2) 
  tr(x1%*%t(x1)%*%x2%*%t(x2)) / (tr(x1%*%t(x1))*tr(x2%*%t(x2)))))

Date:   	Mon, 20 Sep 2004 13:24:49 -0400
From:   	Stephane DRAY <stephane.dray at umontreal.ca>
To:   	<r-help at stat.math.ethz.ch>
Subject:   	[R] Multiple operations on list

Hello,

suppose I have a list with matrices:

a=list(x1=matrix(rnorm(10),5,2),x2=matrix(rnorm(10),5,2),x3=matrix(rnorm(10),5,2))

I want to compute for all combination of xi and xj (x1,x2 x1,x3 and x2,x3)
a value.
This value is given for the pair x1,x2 by trace(x1%*%t(x1)%*%x2%*%t(x2)) /
trace(x1%*%t(x1))*trace(x2%*%t(x2))

I know that product matrices t(xi)%*%xi can be obtained by:

aa=lapply(a,crossprod)

but I do not know how to "mix" the values in aa to obtain the desired values.

Is there a way to do it without for loop ?

Thanks in advances,

sincerely

Stéphane DRAY
--------------------------------------------------------------------------------------------------

Département des Sciences Biologiques
Université de Montréal, C.P. 6128, succursale centre-ville
Montréal, Québec H3C 3J7, Canada

Tel : (514) 343-6111 poste 1233 Fax : (514) 343-2293
E-mail : stephane.dray at umontreal.ca



From andy_liaw at merck.com  Mon Sep 20 21:53:21 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 20 Sep 2004 15:53:21 -0400
Subject: [R] Nnet: Returning the response
Message-ID: <3A822319EB35174CA3714066D590DCD504AF83E5@usrymx25.merck.com>

I don't think so.  ?nnet does not mention any `y=' arugment for that purpose
(and in fact `y' is used by the default method to specify the response for
training, not as a flag for returning values).

Andy

> From: Rui Dantas
> 
> Hello list.
> Maybe this is a simple question but I can't find the answer anywhere.
> 
> With lm I use the parameter y=TRUE to have the response 
> returned in $y. Of course, namely because of NA's in the data 
> frame, this might not include all the values in the original 
> column. For example:
> 
> > data(airquality)
> > length(airquality$Day)
> [1] 153
> > my.lm <- lm(Day~.,data=airquality,y=TRUE)
> > length(my.lm$y)
> [1] 111
> 
> When using nnet, is there a way to have the response returned 
> in a similar way?
> 
> Thanks in advance,
> Rui Dantas
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From jose.pinheiro at pharma.novartis.com  Mon Sep 20 23:06:57 2004
From: jose.pinheiro at pharma.novartis.com (jose.pinheiro@pharma.novartis.com)
Date: Mon, 20 Sep 2004 17:06:57 -0400
Subject: [R] ASA Stat. Computing and Stat. Graphics 2005 Student Paper
	competition
Message-ID: <OF36D15901.A30F10B6-ON85256F15.0073DDAA-85256F15.0073FE44@EU.novartis.net>

The Statistical Computing and Statistical Graphics Sections of the ASA
are co-sponsoring a student paper competition on the topics of
Statistical Computing and Statistical Graphics.  Students are
encouraged to submit a paper in one of these areas, which might be
original methodological research, some novel computing or graphical
application in statistics, or any other suitable contribution (for
example, a software-related project).  The selected winners will
present their papers in a topic-contributed session at the 2005 Joint
Statistical Meetings.  The Sections will pay registration fees for the
winners as well as a substantial allowance for transportation to the
meetings and lodging. Enclosed below is the full text of the award 
announcement.
More details can be found at the Stat. Computing Section website at
http://www.statcomputing.org. 



Best Regards,

--Jos? Pinheiro

Awards Chair
ASA Statistical Computing Section
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: StudentPaper2005.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040920/32b85bf0/StudentPaper2005.txt

From ajms at mail.nih.gov  Mon Sep 20 23:35:43 2004
From: ajms at mail.nih.gov (Alexa Sorant)
Date: Mon, 20 Sep 2004 17:35:43 -0400
Subject: [R] installing on alpha
Message-ID: <6.0.2.0.2.20040920133126.028d6680@ces12.nih.gov>

I am trying to install R-1.9.1 on an alpha (Tru64 unix) platform.  I had no 
problem previously installing R-1.4.0, but cannot get the new installation 
to work.  First I ran "configure" specifying an alternate installation 
directory:
         ./configure --prefix=/appl/R-1.9.1
then ran "make" (note that this is NOT gmake, which may make the 
difference).  The error message I get is:
         Make:  cannot open /share/make/vars.mk.  Stop.
The file share/make/vars.mk is there and readable, but share is a 
subdirectory of the main installation directory.  Upon examining Makefile 
and associated files, I found a statement in Makeconf
         include $(top_srcdir)/share/make/vars.mk
which I suspected was the problem -- perhaps the definition of top_srcdir 
not is carrying over from the Makefile that references Makeconf.  (One 
reason I suspect this statement is that it is new since the version of R 
that I installed easily, as well as the early reference to this particular 
file.)

I have tried a bunch of ways of modifying this statement, including an 
explicit path in this statement.  I think that did work, but a similar 
problem then occurred at a later point that I haven't yet located.

Has anyone gotten this installation to work on this platform?

Alexa J. M. Sorant
NIH/NHGRI
333 Cassell Drive Suite 2000
Baltimore, MD 21224

ajms at mail.nih.gov

(410) 550-7512 voice
(410) 550-7513 fax



From sje at mast.queensu.ca  Tue Sep 21 00:18:58 2004
From: sje at mast.queensu.ca (hpc1367)
Date: Mon, 20 Sep 2004 18:18:58 -0400
Subject: [R] unable to load shared library
	"/home/hpc1367/runs/taper/taper.so"
Message-ID: <414F5752.10C17F43@shannon.mast.queensu.ca>

I am trying to load a .so file and get the following error message:

> dyn.load("taper.so",local=F)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
"/home/hpc1367/runs/taper/taper.so":
  ld.so.1: /usr/local/lib/R/bin/R.bin: fatal: relocation error: file
/home/hpc1367/runs/taper/taper.so: symbol f90_init: referenced symbol
not found

also tried with default local=T and got same error.

my makefile (used to produce the .so) is included below

F90S = taper.f90
OBJS = taper.o
LIBS = -lsocket -lnsl -lintl
OPT = -fast
MODS = -M/opt/NAG/fnsol04dbl/nag_mod_dir
NAG = /opt/NAG/fnsol04dbl/libnagfl90.a

STATNAG = /opt/NAG/flsol20dal/libnag.a

taper.o : taper.f90
        f95 -c -dalign  $(OPT) $(MODS) taper.f90

taper.so: taper.f90
        f95 -o taper.so -G -dalign $(OPT) $(MODS) taper.f90

taper.x : taper.o
        f95 -o taper.x -dalign $(OPT) $(MODS) $(LIBS) taper.o $(OBJS)
$(NAG)

please, help
thank you very much
stoyan



From andy_liaw at merck.com  Tue Sep 21 01:39:25 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 20 Sep 2004 19:39:25 -0400
Subject: [R] Multiple operations on list
Message-ID: <3A822319EB35174CA3714066D590DCD504AF83E8@usrymx25.merck.com>

Hope this does what you want:

> library(gregmisc)
> cmb <- combinations(length(aa), 2)
> apply(cmb, 1, function(i) sum(diag(aa[[i[1]]] %*% aa[[i[2]]])) /
+       (sum(diag(aa[[i[1]]])) * sum(diag(aa[[i[2]]]))))
[1] 0.5363973 0.3336318 0.6593545

Andy


> From: Stephane DRAY
> 
> Hello,
> 
> suppose I have a list with matrices:
> 
> a=list(x1=matrix(rnorm(10),5,2),x2=matrix(rnorm(10),5,2),x3=ma
> trix(rnorm(10),5,2))
> 
> I want to compute for all combination of xi and xj (x1,x2 
> x1,x3 and x2,x3) 
> a value.
> This value is given for the pair x1,x2 by 
> trace(x1%*%t(x1)%*%x2%*%t(x2)) / 
> trace(x1%*%t(x1))*trace(x2%*%t(x2))
> 
> I know that product matrices t(xi)%*%xi can be obtained by:
> 
> aa=lapply(a,crossprod)
> 
> but I do not know how to "mix" the values in aa to obtain the 
> desired values.
> 
> Is there a way to do it without for loop ?
> 
> Thanks in advances,
> 
> sincerely
> 
> St??phane DRAY
> --------------------------------------------------------------
> ------------------------------------ 
> 
> D??partement des Sciences Biologiques
> Universit?? de Montr??al, C.P. 6128, succursale centre-ville
> Montr??al, Qu??bec H3C 3J7, Canada
> 
> Tel : (514) 343-6111 poste 1233         Fax : (514) 343-2293
> E-mail : stephane.dray at umontreal.ca
> --------------------------------------------------------------
> ------------------------------------ 
> 
> Web                                          
> http://www.steph280.freesurf.fr/
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From H955921 at ntu.edu.sg  Tue Sep 21 04:40:24 2004
From: H955921 at ntu.edu.sg (#AMELIA ANWAR#)
Date: Tue, 21 Sep 2004 10:40:24 +0800
Subject: [R] unable to download 
Message-ID: <399C2842DBCE6940B2CEBC15EBDC10743E9603@mail02.student.main.ntu.edu.sg>

Hi,
I am currently trying to install packages from BioConductor to R. However, I received a error stating: "unable to connect to 'www.bioconductor.org' on port 80"
May I know what is wrong and how may I correct it?? If possible give a step by step procedures on how can I do it...
Thanks alot,
Amelia
 
PS: Please reply ASAP as I am currently doing a Final Year Project on microarray analysis and already beyond scheduled.



From jgentry at jimmy.harvard.edu  Tue Sep 21 04:53:53 2004
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Mon, 20 Sep 2004 22:53:53 -0400 (EDT)
Subject: [R] unable to download 
In-Reply-To: <399C2842DBCE6940B2CEBC15EBDC10743E9603@mail02.student.main.ntu.edu.sg>
Message-ID: <Pine.SOL.4.20.0409202251290.25811-100000@santiam.dfci.harvard.edu>

> I am currently trying to install packages from BioConductor to R.

Then you probably want to post to the bioconductor mailing list instead of
the R mailing list.

> However, I received a error stating: "unable to connect to
> 'www.bioconductor.org' on port 80" May I know what is wrong and how

There are lots of things that could be wrong, but since the site actually
is currently active they are most likely to be related to your end.

> may I correct it?? If possible give a step by step procedures on how
> can I do it... Thanks alot, Amelia

The first step is to see if install functionality (install.packages,
download.packages, the pulldown if you're using Windows) work for
non-bioconductor software.  If not, then the second step is to see
question 2.17 in the R for Windows FAQ.

-J



From maustin at amgen.com  Tue Sep 21 05:01:00 2004
From: maustin at amgen.com (Austin, Matt)
Date: Mon, 20 Sep 2004 20:01:00 -0700
Subject: [R] unable to download 
Message-ID: <E7D5AB4811D20B489622AABA9C53859101F112C3@teal-exch.amgen.com>

You may need to supply some additional information about your setup.  

What operating system and version are you using?
How are you connecting to the internet?  
Can you download packages from other sources (such as CRAN)?
Exactly what procedure are you using to download the packages?
Have you tried to download individual packages and install locally?

Asking for help ASAP because you are running late is not considerate to
those willing to provide help, because most of us are already behind on our
own projects.

--Matt

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of #AMELIA ANWAR#
Sent: Monday, September 20, 2004 19:40 PM
To: R-help at stat.math.ethz.ch
Subject: [R] unable to download 


Hi,
I am currently trying to install packages from BioConductor to R. However, I
received a error stating: "unable to connect to 'www.bioconductor.org' on
port 80"
May I know what is wrong and how may I correct it?? If possible give a step
by step procedures on how can I do it...
Thanks alot,
Amelia
 
PS: Please reply ASAP as I am currently doing a Final Year Project on
microarray analysis and already beyond scheduled.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From 0034058 at fudan.edu.cn  Tue Sep 21 05:52:04 2004
From: 0034058 at fudan.edu.cn (rongguiwong)
Date: Tue, 21 Sep 2004 11:52:04 +0800
Subject: [R] how to take this experiment with R?
In-Reply-To: <000601c49f1e$a8841440$04653744@WATSON>
References: <4136E8FA00037DD8@mail-2.tiscali.it>
	<000601c49f1e$a8841440$04653744@WATSON>
Message-ID: <200409211152.05523.0034058@fudan.edu.cn>

i want to generate 30 independent variables and 1 dependent variable,each has 
50 draws from a unit normal distribution.
then, searching for the independent variables that together would do the best 
job for fitting the denpendent variabe.

my way to generate the data is.
x<-data.frame(matrix(rnorm(1550),c(50,31)))
but is there more better way to do it?

i want to use the followling is to search the model.
model<-step(lm(X1~X2+X3+X4.....))
but i don't know the to express the formula with lm function.i think there is 
a way the express it efficently.
i try ?lm .but on result be found.

any help is welcome!



From maustin at amgen.com  Tue Sep 21 06:03:37 2004
From: maustin at amgen.com (Austin, Matt)
Date: Mon, 20 Sep 2004 21:03:37 -0700
Subject: [R] how to take this experiment with R?
Message-ID: <E7D5AB4811D20B489622AABA9C53859101F112C4@teal-exch.amgen.com>

How about:

x <- data.frame(matrix(rnorm(1550),c(50,31)))
model <- step(lm(x[,1] ~ as.matrix(x[,2:31])))

--Matt

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of rongguiwong
Sent: Monday, September 20, 2004 20:52 PM
To: r-help at stat.math.ethz.ch
Subject: [R] how to take this experiment with R?


This message uses a character set that is not supported by the Internet
Service.  To view the original message content,  open the attached message.
If the text doesn't display correctly, save the attachment to disk, and then
open it using a viewer that can display the original character set.



From ggrothendieck at myway.com  Tue Sep 21 06:10:15 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 21 Sep 2004 00:10:15 -0400 (EDT)
Subject: [R] how to take this experiment with R?
Message-ID: <20040921041015.D7BA439A1@mprdmxin.myway.com>




You can express your model like this:

   lm(X1 ~., x)

?formula gives some help on formulas although the . notation
above does not seem to be referred to there.


Date:   	Tue, 21 Sep 2004 11:52:04 +0800
From:   	rongguiwong <0034058 at fudan.edu.cn>
To:   	<r-help at stat.math.ethz.ch>
Subject:   	[R] how to take this experiment with R?

i want to generate 30 independent variables and 1 dependent variable,each has
50 draws from a unit normal distribution.
then, searching for the independent variables that together would do the best
job for fitting the denpendent variabe.

my way to generate the data is.
x<-data.frame(matrix(rnorm(1550),c(50,31)))
but is there more better way to do it?

i want to use the followling is to search the model.
model<-step(lm(X1~X2+X3+X4.....))
but i don't know the to express the formula with lm function.i think there is
a way the express it efficently.
i try ?lm .but on result be found.

any help is welcome!



From eleisz at Macalester.edu  Tue Sep 21 06:10:59 2004
From: eleisz at Macalester.edu (Erin L. Leisz)
Date: Mon, 20 Sep 2004 23:10:59 -0500
Subject: [R] can't understand "R"
Message-ID: <47313468.1095721859@erin.doty.macalester.edu>

hi.  i really need help using this program.  computer language is a foreign 
language to me, and thus, i cannot make heads nor tails of the user manuals 
from the website.  i need to locate step-by-step examples of simple 
problems such as "graph f(x)+g(x) and f(g(x)) for the domain 0<x<2" and 
"graph 2H(x), H(x)+1, H(x+1)"  i do know how to define the functions, but 
that's it.  is there any help you could provide me?  i would appreciate 
some help asap.  thank you very much
erin leisz



From 0034058 at fudan.edu.cn  Tue Sep 21 06:27:38 2004
From: 0034058 at fudan.edu.cn (rongguiwong)
Date: Tue, 21 Sep 2004 12:27:38 +0800
Subject: [R] how to take this experiment with R?
In-Reply-To: <20040921041015.D7BA439A1@mprdmxin.myway.com>
References: <20040921041015.D7BA439A1@mprdmxin.myway.com>
Message-ID: <200409211227.38858.0034058@fudan.edu.cn>

ÔÚ 2004Äê9ÔÂ21ÈÕ ÐÇÆÚ¶þ 12:10£¬Gabor Grothendieck Ð´µÀ£º
it works.
but i come across anather problem.
i just wnat to select 3 of the best indepent variables.
but the reslut from  step(lm(X1 ~., x)) is :

Step:  AIC= -37.64
 X1 ~ X2 + X3 + X4 + X8 + X10 + X11 + X13 + X14 + X15 + X18 +
    X21 + X22 + X25 + X26 + X27 + X29 + X30 + X31
 
       Df Sum of Sq     RSS     AIC
<none>               11.014 -37.642
- X8    1     0.559  11.574 -37.165
- X27   1     0.867  11.881 -35.853
- X2    1     0.971  11.986 -35.416
- X18   1     0.978  11.992 -35.390
- X31   1     1.122  12.136 -34.793
- X10   1     1.400  12.414 -33.659
- X15   1     1.563  12.578 -33.005
- X29   1     1.608  12.622 -32.828
- X13   1     1.805  12.819 -32.055
- X30   1     1.880  12.894 -31.763
- X4    1     2.368  13.382 -29.906
- X14   1     2.495  13.509 -29.433
- X3    1     2.983  13.997 -27.659
- X22   1     2.999  14.013 -27.600
- X21   1     3.377  14.391 -26.271
- X25   1     4.323  15.338 -23.086
- X11   1     6.775  17.789 -15.672
- X26   1     7.232  18.246 -14.403

> You can express your model like this:
>
>
>
>    lm(X1 ~., x)
>
>
>
> ?formula gives some help on formulas although the . notation
>
> above does not seem to be referred to there.
>
>
>
>
>
> Date:   	Tue, 21 Sep 2004 11:52:04 +0800
>
> From:   	rongguiwong <0034058 at fudan.edu.cn>
>
> To:   	<r-help at stat.math.ethz.ch>
>
> Subject:   	[R] how to take this experiment with R?
>
>
>
> i want to generate 30 independent variables and 1 dependent variable,each
> has
>
> 50 draws from a unit normal distribution.
>
> then, searching for the independent variables that together would do the
> best
>
> job for fitting the denpendent variabe.
>
>
>
> my way to generate the data is.
>
> x<-data.frame(matrix(rnorm(1550),c(50,31)))
>
> but is there more better way to do it?
>
>
>
> i want to use the followling is to search the model.
>
> model<-step(lm(X1~X2+X3+X4.....))
>
> but i don't know the to express the formula with lm function.i think there
> is
>
> a way the express it efficently.
>
> i try ?lm .but on result be found.
>
>
>
> any help is welcome!
>
>
>
>
>
> _______________________________________________
> No banners. No pop-ups. No kidding.



From ggrothendieck at myway.com  Tue Sep 21 06:57:15 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 21 Sep 2004 00:57:15 -0400 (EDT)
Subject: [R] how to take this experiment with R?
Message-ID: <20040921045715.708C03969@mprdmxin.myway.com>



Suppose you just wanted variables 2,4 and 7 (which are in columns
3, 5 and 8, respectively).  Then you could do this:

   lm(X1 ~ X2 + X4 + X7, x)
or
   lm(X1 ~., x[,c(2,4,7)+1])


Date:   	Tue, 21 Sep 2004 12:27:38 +0800
From:   	rongguiwong <0034058 at fudan.edu.cn>
To:   	<r-help at stat.math.ethz.ch>
Subject:   	Re: [R] how to take this experiment with R?

ÔÚ 2004Äê9ÔÂ21ÈÕ ÐÇÆÚ¶þ 12:10£¬Gabor Grothendieck Ð´µÀ£º
it works.
but i come across anather problem.
i just wnat to select 3 of the best indepent variables.
but the reslut from step(lm(X1 ~., x)) is :

Step: AIC= -37.64
X1 ~ X2 + X3 + X4 + X8 + X10 + X11 + X13 + X14 + X15 + X18 +
X21 + X22 + X25 + X26 + X27 + X29 + X30 + X31

Df Sum of Sq RSS AIC
<none> 11.014 -37.642
- X8 1 0.559 11.574 -37.165
- X27 1 0.867 11.881 -35.853
- X2 1 0.971 11.986 -35.416
- X18 1 0.978 11.992 -35.390
- X31 1 1.122 12.136 -34.793
- X10 1 1.400 12.414 -33.659
- X15 1 1.563 12.578 -33.005
- X29 1 1.608 12.622 -32.828
- X13 1 1.805 12.819 -32.055
- X30 1 1.880 12.894 -31.763
- X4 1 2.368 13.382 -29.906
- X14 1 2.495 13.509 -29.433
- X3 1 2.983 13.997 -27.659
- X22 1 2.999 14.013 -27.600
- X21 1 3.377 14.391 -26.271
- X25 1 4.323 15.338 -23.086
- X11 1 6.775 17.789 -15.672
- X26 1 7.232 18.246 -14.403

> You can express your model like this:
>
>
>
> lm(X1 ~., x)
>
>
>
> ?formula gives some help on formulas although the . notation
>
> above does not seem to be referred to there.
>
>
>
>
>
> Date:      Tue, 21 Sep 2004 11:52:04 +0800
>
> From:      rongguiwong <0034058 at fudan.edu.cn>
>
> To:      <r-help at stat.math.ethz.ch>
>
> Subject:      [R] how to take this experiment with R?
>
>
>
> i want to generate 30 independent variables and 1 dependent variable,each
> has
>
> 50 draws from a unit normal distribution.
>
> then, searching for the independent variables that together would do the
> best
>
> job for fitting the denpendent variabe.
>
>
>
> my way to generate the data is.
>
> x<-data.frame(matrix(rnorm(1550),c(50,31)))
>
> but is there more better way to do it?
>
>
>
> i want to use the followling is to search the model.
>
> model<-step(lm(X1~X2+X3+X4.....))
>
> but i don't know the to express the formula with lm function.i think there
> is
>
> a way the express it efficently.
>
> i try ?lm .but on result be found.
>
>
>
> any help is welcome!
>



From maustin at amgen.com  Tue Sep 21 07:32:46 2004
From: maustin at amgen.com (Austin, Matt)
Date: Mon, 20 Sep 2004 22:32:46 -0700
Subject: [R] how to take this experiment with R?
Message-ID: <E7D5AB4811D20B489622AABA9C53859101F112C7@teal-exch.amgen.com>

My mistake, you can't use the structure I proposed with lm() in combination
with step().

If what was suggested earlier by Gabor was not what you wanted, and instead
you want the 'best' three variable model, then it may be easier to use the
leaps package.  


> library(leaps)
> x     <- data.frame(matrix(rnorm(1550),c(50,31)))
> model <- regsubsets(y=x[,1], x=x[,2:31])
> m1    <-summary(model, matrix=TRUE, matrix.logical=TRUE)
> apply(m1$outmat, 1, which)[3]
$"3  ( 1 )"
X10 X14 X15 
  9  13  14 

> lm.fit(x=as.matrix(x[,as.vector(unlist(apply(m1$outmat, 1,
which)[3])+1)]), y=x[,1])
$coefficients
       X10        X14        X15 
-0.2694923 -0.4055546 -0.2692063 


--Matt
-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Gabor Grothendieck
Sent: Monday, September 20, 2004 21:57 PM
To: 0034058 at fudan.edu.cn; r-help at stat.math.ethz.ch
Subject: Re: [R] how to take this experiment with R?




Suppose you just wanted variables 2,4 and 7 (which are in columns
3, 5 and 8, respectively).  Then you could do this:

   lm(X1 ~ X2 + X4 + X7, x)
or
   lm(X1 ~., x[,c(2,4,7)+1])


Date:   	Tue, 21 Sep 2004 12:27:38 +0800
From:   	rongguiwong <0034058 at fudan.edu.cn>
To:   	<r-help at stat.math.ethz.ch>
Subject:   	Re: [R] how to take this experiment with R?

???? 2004????9????21???? ???????????? 12:10????Gabor Grothendieck ????????????
it works.
but i come across anather problem.
i just wnat to select 3 of the best indepent variables.
but the reslut from step(lm(X1 ~., x)) is :

Step: AIC= -37.64
X1 ~ X2 + X3 + X4 + X8 + X10 + X11 + X13 + X14 + X15 + X18 +
X21 + X22 + X25 + X26 + X27 + X29 + X30 + X31

Df Sum of Sq RSS AIC
<none> 11.014 -37.642
- X8 1 0.559 11.574 -37.165
- X27 1 0.867 11.881 -35.853
- X2 1 0.971 11.986 -35.416
- X18 1 0.978 11.992 -35.390
- X31 1 1.122 12.136 -34.793
- X10 1 1.400 12.414 -33.659
- X15 1 1.563 12.578 -33.005
- X29 1 1.608 12.622 -32.828
- X13 1 1.805 12.819 -32.055
- X30 1 1.880 12.894 -31.763
- X4 1 2.368 13.382 -29.906
- X14 1 2.495 13.509 -29.433
- X3 1 2.983 13.997 -27.659
- X22 1 2.999 14.013 -27.600
- X21 1 3.377 14.391 -26.271
- X25 1 4.323 15.338 -23.086
- X11 1 6.775 17.789 -15.672
- X26 1 7.232 18.246 -14.403

> You can express your model like this:
>
>
>
> lm(X1 ~., x)
>
>
>
> ?formula gives some help on formulas although the . notation
>
> above does not seem to be referred to there.
>
>
>
>
>
> Date:      Tue, 21 Sep 2004 11:52:04 +0800
>
> From:      rongguiwong <0034058 at fudan.edu.cn>
>
> To:      <r-help at stat.math.ethz.ch>
>
> Subject:      [R] how to take this experiment with R?
>
>
>
> i want to generate 30 independent variables and 1 dependent variable,each
> has
>
> 50 draws from a unit normal distribution.
>
> then, searching for the independent variables that together would do the
> best
>
> job for fitting the denpendent variabe.
>
>
>
> my way to generate the data is.
>
> x<-data.frame(matrix(rnorm(1550),c(50,31)))
>
> but is there more better way to do it?
>
>
>
> i want to use the followling is to search the model.
>
> model<-step(lm(X1~X2+X3+X4.....))
>
> but i don't know the to express the formula with lm function.i think there
> is
>
> a way the express it efficently.
>
> i try ?lm .but on result be found.
>
>
>
> any help is welcome!
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Sep 21 08:04:09 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 21 Sep 2004 08:04:09 +0200
Subject: [R] can't understand "R"
In-Reply-To: <47313468.1095721859@erin.doty.macalester.edu>
References: <47313468.1095721859@erin.doty.macalester.edu>
Message-ID: <414FC459.9060800@statistik.uni-dortmund.de>

Erin L. Leisz wrote:
> hi.  i really need help using this program.  computer language is a 
> foreign language to me, and thus, i cannot make heads nor tails of the 
> user manuals from the website.  i need to locate step-by-step examples 
> of simple problems such as "graph f(x)+g(x) and f(g(x)) for the domain 
> 0<x<2" and "graph 2H(x), H(x)+1, H(x+1)"  i do know how to define the 
> functions, but that's it.  is there any help you could provide me?  i 
> would appreciate some help asap.  thank you very much
> erin leisz

If the manual "An Introduction to R is not sufficient for you, what 
about reading a book, e.g. Peter Dalgaard's "Introductory Statistics 
with R", Springer? Here you learn R along some basic statistical analyses.

Uwe Ligges


> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From jacques.veslot at cirad.fr  Tue Sep 21 09:31:40 2004
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Tue, 21 Sep 2004 11:31:40 +0400
Subject: [R] bubble plots
Message-ID: <HHEDKBCGCMDOHEDELFBCIEIPCCAA.jacques.veslot@cirad.fr>

Dear all,

I'm used to draw bubble plots (gstat) to get a first view of my spatial
marked data, but I can't find a way to label legend with marks after having
replaced them by a numeric scale.

I have a data frame with numeric coords and factors:

> names(data)
[1] "x"         "y"         "bloc"      "sub"       "inoc"      "etat"
etc...

> levels(data$etat)
[1] ""    "F"   "Fi"  "NF"  "NFi"


I do:

> levels(data$etat) <- c(0, 2, -2, 1, -1)

> data$etat <- as.numeric(as.vector(data$etat))

> C1 <- subset(data, sub=="C" & bloc=="1", select=c(x, y, etat))

> x11()
> lset(theme = col.whitebg())
> bubble(C1, xcol = 1, ycol = 2, zcol = 3,
	xlab = "", ylab = "", main = "Bloc 1  -  Substrat C",
	key.entries = min(C1[, 3]):max(C1[, 3]), maxsize=3)

I then obtain "-2", "-1", "O", etc. as legend labels and cannot find
argument making it possible to label my legend with initial marks: "F1",
NFi", etc.

Besides, I also tried with image() but I faced the following error message,
even though I ordered x- and y-coords:

Error in image.default(C1$x, C1$y, C1$etat) :
       increasing x and y values expected

I'd really appreciate if someone could give me either an option to label
adequately bubble plots, or even to make me know if there is another - maybe
better - way to plot spatial marked data.


Jacques VESLOT
CIRAD R??union



From tom_woody at swissinfo.org  Tue Sep 21 09:34:23 2004
From: tom_woody at swissinfo.org (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Tue, 21 Sep 2004 09:34:23 +0200
Subject: [R] can't understand "R"
In-Reply-To: <414FC459.9060800@statistik.uni-dortmund.de>
References: <47313468.1095721859@erin.doty.macalester.edu>
	<414FC459.9060800@statistik.uni-dortmund.de>
Message-ID: <414FD97F.2060607@swissinfo.org>

Hello,


Uwe Ligges schrieb:
> Erin L. Leisz wrote:

> If the manual "An Introduction to R is not sufficient for you, what 
> about reading a book, e.g. Peter Dalgaard's "Introductory Statistics 
> with R", Springer? Here you learn R along some basic statistical analyses.

BTW, can anybody recommend a book on "S/R and data mining"?


Thomas



From maechler at stat.math.ethz.ch  Tue Sep 21 10:00:35 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 21 Sep 2004 10:00:35 +0200
Subject: [R] unable to load shared library
	"/home/hpc1367/runs/taper/taper.so"
In-Reply-To: <414F5752.10C17F43@shannon.mast.queensu.ca>
References: <414F5752.10C17F43@shannon.mast.queensu.ca>
Message-ID: <16719.57251.96641.568403@gargle.gargle.HOWL>

>>>>> "hpc1367" == hpc1367  <sje at mast.queensu.ca>
>>>>>     on Mon, 20 Sep 2004 18:18:58 -0400 writes:

Why do you put the full filename in the e-mail subject?????
(We'd rather want to know your operating system, some
 kind of unix, probably Linux, seen from below)

    hpc1367> I am trying to load a .so file and get the
    hpc1367> following error message:
    >> dyn.load("taper.so",local=F)
    hpc1367> Error in dyn.load(x, as.logical(local),
    hpc1367> as.logical(now)) : unable to load shared library
    hpc1367> "/home/hpc1367/runs/taper/taper.so": ld.so.1:
    hpc1367> /usr/local/lib/R/bin/R.bin: fatal: relocation
    hpc1367> error: file /home/hpc1367/runs/taper/taper.so:
    hpc1367> symbol f90_init: referenced symbol not found
	     ^^^^^^^^^^^^^^^^
this is the crucial part !

    hpc1367> also tried with default local=T and got same error.

of course, since your fortran90 code needs    f90_init()
and that is evidently not linked into your taper.so
but is provided by your Fortran90 
    hpc1367> my makefile (used to produce the .so) is included below


    hpc1367> F90S = taper.f90
    hpc1367> OBJS = taper.o
    hpc1367> LIBS = -lsocket -lnsl -lintl
    hpc1367> OPT = -fast
    hpc1367> MODS = -M/opt/NAG/fnsol04dbl/nag_mod_dir
    hpc1367> NAG = /opt/NAG/fnsol04dbl/libnagfl90.a

    hpc1367> STATNAG = /opt/NAG/flsol20dal/libnag.a

    hpc1367> taper.o : taper.f90
    hpc1367> f95 -c -dalign  $(OPT) $(MODS) taper.f90

    hpc1367> taper.so: taper.f90
    hpc1367> f95 -o taper.so -G -dalign $(OPT) $(MODS) taper.f90

    hpc1367> taper.x : taper.o
    hpc1367> f95 -o taper.x -dalign $(OPT) $(MODS) $(LIBS) taper.o $(OBJS)
    hpc1367> $(NAG)

You must make sure that the "system" library which defines the
f90_init() symbol is specified at link time, i.e., when taper.so
is built. 
So I guess you need at least the $(LIBS) also in that line,
probably also $(NAG).

But we don't have your non-free NAG compilers and libraries and
it's hard to find out "from here".  Use 'nm' and 'ldd' but
probably rather ask someone at your institution who knows more
about compilation and linking.

    hpc1367> please, help
    hpc1367> thank you very much



From maechler at stat.math.ethz.ch  Tue Sep 21 10:06:39 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 21 Sep 2004 10:06:39 +0200
Subject: [R] installing on alpha
In-Reply-To: <6.0.2.0.2.20040920133126.028d6680@ces12.nih.gov>
References: <6.0.2.0.2.20040920133126.028d6680@ces12.nih.gov>
Message-ID: <16719.57615.794789.619756@gargle.gargle.HOWL>

>>>>> "Alexa" == Alexa Sorant <ajms at mail.nih.gov>
>>>>>     on Mon, 20 Sep 2004 17:35:43 -0400 writes:

    Alexa> I am trying to install R-1.9.1 on an alpha (Tru64 unix) platform.  I had no 
    Alexa> problem previously installing R-1.4.0, but cannot get the new installation 
    Alexa> to work.  First I ran "configure" specifying an alternate installation 
    Alexa> directory:
    Alexa> ./configure --prefix=/appl/R-1.9.1

We even recommend using an alternate *build* directory:

 mkdir <Rbuild>
 cd    <Rbuild>
 ../<Rsrc>/configure ....

and indeed, since R 2.0.0 is beta now (which means "testing" and
almost stable, not "unstable"!),
we'd appreciate (and feel more willing to support you) if you'd
tried to install R-2.0.0 directly.

    Alexa> then ran "make" (note that this is NOT gmake, which
    Alexa> may make the difference).  The error message I get is:
    Alexa> Make:  cannot open /share/make/vars.mk.  Stop.

    Alexa> The file share/make/vars.mk is there and readable,
    Alexa> but share is a subdirectory of the main installation
    Alexa> directory.  Upon examining Makefile and associated
    Alexa> files, I found a statement in Makeconf include
    Alexa> $(top_srcdir)/share/make/vars.mk which I suspected
    Alexa> was the problem -- perhaps the definition of
    Alexa> top_srcdir not is carrying over from the Makefile
    Alexa> that references Makeconf.

yes, that seems clear.  If your 'make' is not supporting such
'include' statements in Makefiles,  you definitely must use GNU
make (seemingly called 'gmake' on alpha) !

Did you look at the INSTALL file, or even consult the 
"R Administration and Installation" manual
(available from R-projec.org as well) ?

    Alexa> (One reason I suspect this statement is that it is new
    Alexa> since the version of R that I installed easily, as
    Alexa> well as the early reference to this particular file.)

    Alexa> I have tried a bunch of ways of modifying this
    Alexa> statement, including an explicit path in this
    Alexa> statement.  I think that did work, but a similar
    Alexa> problem then occurred at a later point that I haven't
    Alexa> yet located.

    Alexa> Has anyone gotten this installation to work on this platform?

    Alexa> Alexa J. M. Sorant
    Alexa> NIH/NHGRI
    Alexa> 333 Cassell Drive Suite 2000
    Alexa> Baltimore, MD 21224

    Alexa> ajms at mail.nih.gov

    Alexa> (410) 550-7512 voice
    Alexa> (410) 550-7513 fax



From ahenningsen at email.uni-kiel.de  Tue Sep 21 10:12:14 2004
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Tue, 21 Sep 2004 10:12:14 +0200
Subject: [R] plot.Map with pattern instead of colors
In-Reply-To: <Pine.LNX.4.44.0409201411080.20563-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0409201411080.20563-100000@reclus.nhh.no>
Message-ID: <200409211012.14206.ahenningsen@email.uni-kiel.de>

Dear Roger,

thank you for your valuable hints regarding plot.polylist, Map2poly and 
RColorBrewer( , "Greys" ). Adding pattern to some shapes with 
plot( Map2poly( x ), density = myDensities, add = TRUE ) works great!

Best wishes,
Arne

On Monday 20 September 2004 14:20, Roger Bivand wrote:
> On Mon, 20 Sep 2004, Arne Henningsen wrote:
> > Hi,
> >
> > I am plotting shapefiles with plot.Map (package maptools). So far I use
> > different colors for the shapes depending on the a value that belongs to
> > the shape. Now, I need to produce maps only in black, gray and white for
> > publication. Is it possible to fill shapes with pattern (e.g. hatched)
> > instead of colors?
>
> Not in plot.Map(). This is supported if you convert the shapefile polygons
> to a polylist object (Map2poly()), then use plot.polylist() - but this may
> not be your choice. Within plot.Map, I would suggest using the
> RColorBrewer package and the sequential "Greys" palette, which
> differentiates five grey colours very well for most media.
>
> If you run this after example(plot.Map), it should illustrate a solution:
>
> library(RColorBrewer)
> pal <- brewer.pal(5, "Greys")
> fgs <- pal[findInterval(x$att.data$BIR74, res$breaks, all.inside=TRUE)]
> plot(x, fg=fgs)
>
> for the default quantile breaks.
>
> > Details of a simplified example:
> > I want to show the percentage change of a variable in a map:
> > e.g. following levels
> > a) >+10
> > b) +5% to +10%
> > c) -5% to +5%
> > d) -10% to -5%
> > e) <-10%
> >
> > Now I have following colors
> > a) "red"
> > b) "orange"
> > c) "white"
> > d) "greenyellow"
> > e) "green3"
> >
> > Printing this on a monochrome printer is - of course - stupid, because
> > levels a) and e) as well as b) and d) have approximately the same
> > grayscale. I could fill a) = black and e) = white, and everything
> > inbetween with an appropriate grayscale, but I prefer to have areas with
> > no change to appear white rather than medium gray. Therefore, I thought
> > of doing following: a) black
> > b) gray
> > c) white
> > d) hatched with thin lines
> > e) hatched with thick lines (or double-hatched)
> >
> > Any hints and ideas are welcome!
> > (BTW: I use R 1.9.1 on SuSE Linux 9.0)
> >
> > Thanks,
> > Arne

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Sep 21 10:12:36 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue, 21 Sep 2004 10:12:36 +0200
Subject: [R] S/R and data mining (was can't understand "R")
References: <47313468.1095721859@erin.doty.macalester.edu><414FC459.9060800@statistik.uni-dortmund.de>
	<414FD97F.2060607@swissinfo.org>
Message-ID: <006d01c49fb2$c3862500$b2133a86@www.domain>

Hi Thomas,

@Book{hastie.et.al:01,
  author    = {T. Hastie and R. Tibshirani and J. Friedman},
  address   = {New York},
  publisher = {Springer-Verlag},
  title     = {The Elements of Statistical Learning: Data Mining, 
Inference and Prediction},
  year      = {2001}
}

might be helpful.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Thomas Sch??nhoff" <tom_woody at swissinfo.org>
To: "R User-Liste" <r-help at stat.math.ethz.ch>
Sent: Tuesday, September 21, 2004 9:34 AM
Subject: Re: [R] can't understand "R"


> Hello,
>
>
> Uwe Ligges schrieb:
>> Erin L. Leisz wrote:
>
>> If the manual "An Introduction to R is not sufficient for you, what 
>> about reading a book, e.g. Peter Dalgaard's "Introductory 
>> Statistics with R", Springer? Here you learn R along some basic 
>> statistical analyses.
>
> BTW, can anybody recommend a book on "S/R and data mining"?
>
>
> Thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Roger.Bivand at nhh.no  Tue Sep 21 10:20:53 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 21 Sep 2004 10:20:53 +0200 (CEST)
Subject: [R] compilation failed for package
In-Reply-To: <107A22D85FBCCC448BA66E2E8215DC48067C5D@alm.ninaniku.no>
Message-ID: <Pine.LNX.4.44.0409211012070.21476-100000@reclus.nhh.no>

On Mon, 20 Sep 2004 geir.systad at nina.no wrote:

> Hello, I am new to R on Linux (and to LINUX), running a 1.9.1 on a Linux
> MDK10.0. When updating or installing different packages, I get messages
> like this (under), the package doesn't install. Can anyone help me? I
> know this is all to little information, but I don't know were to start.
> I think there is something wrong in how or were the C++ or fortran
> compilator is installed?? Thanks, Geir S.

After some offline exchanges, the problem has been resolved. This Mandrake
10.0 installation had R installed from binary, had gcc 3.4.1, but (most
likely) binutils 2.14 that did not recognise the new --as-needed flag. For
this reason, update.packages() - this was the survival case mentioned in
the post - and install.packages() failed on compilation. The fact that
such a build system is broken is demonstrated by:

$ cat << EOF > hello.c
#include <stdio.h>
int main(void)
{
  printf("Hello World!\n");
  exit(0);
}
EOF
$ gcc -o hello hello.c
/usr/bin/ld: unrecognized option '--as-needed'
/usr/bin/ld: use the --help option for usage information
collect2: ld returned 1 exit status

Resolution by updating binutils or installing older gcc-* RPMs instead of 
3.4.1.

> 
> 
> gcc -shared -L/usr/local/lib -o survival.so agexact.o agfit2.o agfit3.o agfit5.o agfit_null.o agmart2.o agmart.o agscore.o agsurv1.o agsurv2.o agsurv3.o char_date.o chinv2.o chinv3.o cholesky2.o cholesky3.o chsolve2.o chsolve3.o coxdetail.o coxfit2.o coxfit5.o coxmart.o coxph_wtest.o cox_Rcallback.o coxscho.o coxscore.o dmatrix.o doloop.o pyears1.o pyears2.o pyears3.o pystep.o surv_callback.o survdiff2.o survfit2.o survfit3.o survindex2.o survindex3.o survreg2.o survreg3.o survreg4.o survreg5.o
> /usr/bin/ld: unrecognized option '--as-needed'
> /usr/bin/ld: use the --help option for usage information
> collect2: ld returned 1 exit status
> make: *** [survival.so] Error 1
> ERROR: compilation failed for package 'survival'
> ** Removing '/usr/lib/R/library/survival'
> ** Restoring previous '/usr/lib/R/library/survival'
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From ligges at statistik.uni-dortmund.de  Tue Sep 21 10:20:42 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 21 Sep 2004 10:20:42 +0200
Subject: [R] adding function to a Package
In-Reply-To: <E7CF6BC2744CBE41AE4E87635C7C893C1C6815@exc.wibr.ucl.ac.uk>
References: <E7CF6BC2744CBE41AE4E87635C7C893C1C6815@exc.wibr.ucl.ac.uk>
Message-ID: <414FE45A.3060100@statistik.uni-dortmund.de>

Stephen Henderson wrote:

> As a shortcut I have previously added my own functions to a Package (ipred)
> under R-1.8.1,  changing the NAMESPACE file to accomodate this then
> reinstalling. This doesn't now seem possible in R-1.9.0 is this correct?-- I
> am getting an error saying:
> 
> "files NAMESPACE, R/ipred have the wrong MD5 checksums"
> 
> after I try to reinstall (which I can understand). Is there a quick way
> round this avoiding having to build my own Package?


Looks like you have added to the binary rather than the soource package.
Please change the source package instaed and re-install.

BTW: It is a better idea to put the stuff in your own package, because 
it will be hard for you to go with each update of ipred, since you have 
to re-apply your patches again and again ...

Uwe Ligges


> Thanks
> Stephen
> 
> 
> **********************************************************************
> This email and any files transmitted with it are confidentia...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From vito_ricci at yahoo.com  Tue Sep 21 10:22:53 2004
From: vito_ricci at yahoo.com (Vito Ricci)
Date: Tue, 21 Sep 2004 10:22:53 +0200 (CEST)
Subject: [R] S/R and data mining (was can't understand "R")
Message-ID: <20040921082253.61275.qmail@web41213.mail.yahoo.com>

Hi Thomas,

see these papers or books (some are available on the
web):

Diego Kuonen, Introduction au data mining avec R :
vers la reconqu??te du `knowledge discovery in
databases' par les statisticiens. Bulletin of the
Swiss Statistical Society, 40:3-7, 2001.
Consultabile all??indirizzo web:
http://www.statoo.com/en/publications/2001.R.SSS.40/

Diego Kuonen and Reinhard Furrer, Data mining avec R
dans un monde libre. Flash Informatique Sp??cial ??t??,
pages 45-50, sep 2001.
Consultabile all??indirizzo web:
http://sawww.epfl.ch/SIC/SA/publications/FI01/fi-sp-1/sp-1-page45.html


Brian D. Ripley, Datamining: Large Databases and
Methods, in Proceedings  of "useR! 2004 - The R User
Conference", maggio 2004 Consultabile all??indirizzo
web:
http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/Ripley.pdf

Brian D. Ripley, Using Databases with R, R News,
Gennaio 2001, pagg. 18-20
Consultabile all??indirizzo web:
http://cran.r-project.org/doc/Rnews/Rnews_2001-1.pdf

B. D. Ripley, R. M. Ripley,  Applications of R Clients
and Servers in Proceedings of the Distributed
Statistical Computing 2001 Workshop, 2001, Vienna
University of Technology.
Consultabile all??indirizzo web:
http://www.ci.tuwien.ac.at/Conferences/DSC-2001/Proceedings/Ripley.pdf


Torsten Hothorn, David A. James, Brian D. Ripley,  R/S
Interfaces to Databases  in Proceedings of the
Distributed Statistical Computing 2001 Workshop,
2001,Vienna University of Technology.
Consultabile all??indirizzo web:
http://www.ci.tuwien.ac.at/Conferences/DSC-2001/Proceedings/HothornJamesRipley.pdf

Lu??s Torgo, Data Mining with R. Learning by case
studies, Maggio 2003
Consultabile all??indirizzo web:
http://www.liacc.up.pt/~ltorgo/DataMiningWithR/
	
Trevor Hastie , Robert Tibshirani,  Jerome Friedman, 
The Elements of Statistical Learning: Data Mining,
Inference, and Prediction, 2001, Springer-Verlag.
http://www-stat.stanford.edu/~tibs/ElemStatLearn/

I'm find too for some R application for DM.
Best
Vito

Thomas Sch??nhoff wrote:

Hello,

Uwe Ligges schrieb:
> Erin L. Leisz wrote:

> If the manual "An Introduction to R is not
sufficient for you, what 
> about reading a book, e.g. Peter Dalgaard's
"Introductory Statistics 
> with R", Springer? Here you learn R along some basic
statistical analyses.

BTW, can anybody recommend a book on "S/R and data
mining"?


Thomas

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml


		
___________________________________

http://it.seriea.fantasysports.yahoo.com/



From rdiaz at cnio.es  Tue Sep 21 10:23:31 2004
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Tue, 21 Sep 2004 10:23:31 +0200
Subject: [R] can't understand "R"
In-Reply-To: <47313468.1095721859@erin.doty.macalester.edu>
References: <47313468.1095721859@erin.doty.macalester.edu>
Message-ID: <200409211023.31713.rdiaz@cnio.es>

Dear Erin,


On Tuesday 21 September 2004 06:10, Erin L. Leisz wrote:
> hi.  i really need help using this program.  computer language is a foreign
> language to me, and thus, i cannot make heads nor tails of the user manuals
> from the website.  i need to locate step-by-step examples of simple

If you plan to use R more than once, I think you probably want to get used to 
using the manuals (starting with "An introduction to R", and maybe some of 
the other intro material available from the R web site).

> problems such as "graph f(x)+g(x) and f(g(x)) for the domain 0<x<2" and
> "graph 2H(x), H(x)+1, H(x+1)"  i do know how to define the functions, but
> that's it.  is there any help you could provide me?  i would appreciate
> some help asap.  thank you very much

For this particular case of plotting f(x), you can take a look at the function 
"curve" (do:
"?curve"
at the R prompt).

Hope this helps.

R.


> erin leisz
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Ram??n D??az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol??gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern??ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)



From schween at snafu.de  Tue Sep 21 10:40:51 2004
From: schween at snafu.de (Sven C. Koehler)
Date: Tue, 21 Sep 2004 10:40:51 +0200
Subject: [R] can't understand "R"
In-Reply-To: <414FD97F.2060607@swissinfo.org>
References: <47313468.1095721859@erin.doty.macalester.edu>
	<414FC459.9060800@statistik.uni-dortmund.de>
	<414FD97F.2060607@swissinfo.org>
Message-ID: <20040921084051.GA1074@boing.buug.de>

On Tue, Sep 21, 2004 at 09:34:23AM +0200, Thomas Sch??nhoff wrote:
> BTW, can anybody recommend a book on "S/R and data mining"?

Try this one, it's not finished but yet available for free:
``Data Mining with R - learning by case studies'' by Lu??s Torgo;
<http://www.liacc.up.pt/~ltorgo/DataMiningWithR/>.

Regards

Sven C. Koehler



From geir.systad at nina.no  Tue Sep 21 11:04:49 2004
From: geir.systad at nina.no (geir.systad@nina.no)
Date: Tue, 21 Sep 2004 11:04:49 +0200
Subject: SV: [R] compilation failed for package
Message-ID: <107A22D85FBCCC448BA66E2E8215DC48067C67@alm.ninaniku.no>

Thanks to Roger Bivand, my problem was solved. binutils 2.14 was updatet to binutils 2.15, as indicated under.

Geir Helge Systad
Norwegian Institute for Nature Research
Arctic Ecology, Polarmilj??senteret, N-9296 Troms??, Norway
Adress aug-04 to feb-05:
Albert Pettersonsvei 13, N-5750 Odda
fax      +47 85 03 82 14
phone    +47 53 64 24 94
mobil    +47 91 63 70 55
E-mail: geir.systad at nina.no Internett: http://www.ninaniku.no

-----Opprinnelig melding-----
Fra:	Roger Bivand [mailto:Roger.Bivand at nhh.no]
Sendt:	ti 21.09.2004 10:20
Til:	Systad, Geir
Kopi:	r-help at stat.math.ethz.ch
Emne:	Re: [R] compilation failed for package
On Mon, 20 Sep 2004 geir.systad at nina.no wrote:

> Hello, I am new to R on Linux (and to LINUX), running a 1.9.1 on a Linux
> MDK10.0. When updating or installing different packages, I get messages
> like this (under), the package doesn't install. Can anyone help me? I
> know this is all to little information, but I don't know were to start.
> I think there is something wrong in how or were the C++ or fortran
> compilator is installed?? Thanks, Geir S.

After some offline exchanges, the problem has been resolved. This Mandrake
10.0 installation had R installed from binary, had gcc 3.4.1, but (most
likely) binutils 2.14 that did not recognise the new --as-needed flag. For
this reason, update.packages() - this was the survival case mentioned in
the post - and install.packages() failed on compilation. The fact that
such a build system is broken is demonstrated by:

$ cat << EOF > hello.c
#include <stdio.h>
int main(void)
{
  printf("Hello World!\n");
  exit(0);
}
EOF
$ gcc -o hello hello.c
/usr/bin/ld: unrecognized option '--as-needed'
/usr/bin/ld: use the --help option for usage information
collect2: ld returned 1 exit status

Resolution by updating binutils or installing older gcc-* RPMs instead of 
3.4.1.

> 
> 
> gcc -shared -L/usr/local/lib -o survival.so agexact.o agfit2.o agfit3.o agfit5.o agfit_null.o agmart2.o agmart.o agscore.o agsurv1.o agsurv2.o agsurv3.o char_date.o chinv2.o chinv3.o cholesky2.o cholesky3.o chsolve2.o chsolve3.o coxdetail.o coxfit2.o coxfit5.o coxmart.o coxph_wtest.o cox_Rcallback.o coxscho.o coxscore.o dmatrix.o doloop.o pyears1.o pyears2.o pyears3.o pystep.o surv_callback.o survdiff2.o survfit2.o survfit3.o survindex2.o survindex3.o survreg2.o survreg3.o survreg4.o survreg5.o
> /usr/bin/ld: unrecognized option '--as-needed'
> /usr/bin/ld: use the --help option for usage information
> collect2: ld returned 1 exit status
> make: *** [survival.so] Error 1
> ERROR: compilation failed for package 'survival'
> ** Removing '/usr/lib/R/library/survival'
> ** Restoring previous '/usr/lib/R/library/survival'
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From tom_woody at swissinfo.org  Tue Sep 21 11:09:00 2004
From: tom_woody at swissinfo.org (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Tue, 21 Sep 2004 11:09:00 +0200
Subject: [R] S/R and data mining (was can't understand "R")
In-Reply-To: <006d01c49fb2$c3862500$b2133a86@www.domain>
References: <47313468.1095721859@erin.doty.macalester.edu><414FC459.9060800@statistik.uni-dortmund.de>
	<414FD97F.2060607@swissinfo.org>
	<006d01c49fb2$c3862500$b2133a86@www.domain>
Message-ID: <414FEFAC.7050109@swissinfo.org>

Thanks Dimitri and Vito,

I'll soon have a look at your recommendations (except the mentioned book 
which might take some time to get hands at!


Thomas



From rob.foxall at bbsrc.ac.uk  Tue Sep 21 12:43:23 2004
From: rob.foxall at bbsrc.ac.uk (rob foxall (IFR))
Date: Tue, 21 Sep 2004 11:43:23 +0100
Subject: [R] lda predict
Message-ID: <1CF0B26CECD746438AE02DBF7DDE1C7B17F44F@ifre2knas1.ifrxp.bbsrc.reserved>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040921/af95b5cd/attachment.pl

From a.trapletti at bluewin.ch  Tue Sep 21 12:45:36 2004
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Tue, 21 Sep 2004 12:45:36 +0200
Subject: [R] GARCH model query
Message-ID: <41500650.9090400@bluewin.ch>

> Hello,
>
> I am trying to find an easy way to estimate  the following:
>
> y = Function(x) + lag(x,1) + garch_error_component


E.g. estimate the mean component first and then use garch from tseries 
on the residuals from step 1.

Best
Adrian

>
> Any clues?
>
> Best regards,
> Costas
>
> ---



From steve.roberts at man.ac.uk  Tue Sep 21 13:38:12 2004
From: steve.roberts at man.ac.uk (Steve Roberts)
Date: Tue, 21 Sep 2004 12:38:12 +0100
Subject: [R] lme RE variance computation
Message-ID: <415020B2.1503.2A0C40DD@localhost>

As I understand it lme (in R v1.9.x) estimates random effect variances 
on a log scale, constraining them to be positive. Whilst this seems 
sensible, it does lead to apparently biased estimates if the variance is 
actually  zero - which makes our simulation results look strange. Whilst 
we need to think a bit deeper about it - I still haven't got my head 
around what a negative variance could mean - does anyone know a 
way to take away the contraint and allowing zero or negative 
variances?

Steve.  Dr Steve Roberts 
  steve.roberts at man.ac.uk

Senior Lecturer in Medical Statistics,
CMMCH NHS Trust and University of Manchester Biostatistics Group,
0161 275 5192 / 0161 276 5785



From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Sep 21 14:31:17 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue, 21 Sep 2004 14:31:17 +0200
Subject: [R] lme RE variance computation
References: <415020B2.1503.2A0C40DD@localhost>
Message-ID: <002201c49fd6$e456d490$b2133a86@www.domain>

Hi Steve,

Estimation problems for the variance components in linear mixed models 
are usually occur for two reasons:

1. Due to model misspecification, i.e., using years instead of decades 
may show no variability in the slopes

2. Because the data do not support the assumptions of the linear mixed 
model (i.e., positive definite covariance matrix for the 
random-effects => increasing variance with time).

These may cause zero or even negative variance components. For more 
info you could take a look at Verbeke and Molenberghs (2000, Section 
5.6) and Searle, Casella and McCullogh (1992, Section 3.5).

I don't know the exact formulation you are using, but maybe you could 
consider an analogue of you model using "gls", i.e.,

lme(..., random=~1|id)
gls(..., corr=corCompSymm(form=~1|id))


The references mentioned above are:

@Book{verbeke.molenberghs:00,
  author    = {G. Verbeke and G. Molenberghs},
  title     = {Linear Mixed Models for Longitudinal Data},
  year      = {2000},
  address   = {New York},
  publisher = {Springer-Verlag}
}

@Book{searle.et.al:92,
  author    = {S. Searle and G. Cassela and C. McCulloch},
  title     = {Variance Components},
  year      = {1992},
  address   = {New York},
  publisher = {Wiley}
}

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Steve Roberts" <steve.roberts at man.ac.uk>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, September 21, 2004 1:38 PM
Subject: [R] lme RE variance computation


> As I understand it lme (in R v1.9.x) estimates random effect 
> variances
> on a log scale, constraining them to be positive. Whilst this seems
> sensible, it does lead to apparently biased estimates if the 
> variance is
> actually  zero - which makes our simulation results look strange. 
> Whilst
> we need to think a bit deeper about it - I still haven't got my head
> around what a negative variance could mean - does anyone know a
> way to take away the contraint and allowing zero or negative
> variances?
>
> Steve.  Dr Steve Roberts
>  steve.roberts at man.ac.uk
>
> Senior Lecturer in Medical Statistics,
> CMMCH NHS Trust and University of Manchester Biostatistics Group,
> 0161 275 5192 / 0161 276 5785
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From wolski at molgen.mpg.de  Tue Sep 21 15:14:12 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Tue, 21 Sep 2004 15:14:12 +0200
Subject: [R] How to plot  residuals vs. fitted of "trgls" object
 (spatial::surf.gls)
Message-ID: <200409211514120079.067DAC9C@mail.math.fu-berlin.de>

Hi!

Would like to to make a plot of residuals vs. fitted and Y vs. predicted values   from an object of class "trgls" as returned by spatial::surf.gls directly.
(without calling spatial::predict.trgls)
Is it possible? on which list components should I look at?

/E



From bruno.nogent at metaxis.fr  Tue Sep 21 15:28:04 2004
From: bruno.nogent at metaxis.fr (Bruno Nogent)
Date: Tue, 21 Sep 2004 15:28:04 +0200
Subject: [R] How to call a R function from C or C++ ?
Message-ID: <006501c49fde$d386a7f0$0600a8c0@calimero2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040921/86007625/attachment.pl

From ligges at statistik.uni-dortmund.de  Tue Sep 21 15:34:23 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 21 Sep 2004 15:34:23 +0200
Subject: [R] How to call a R function from C or C++ ?
In-Reply-To: <006501c49fde$d386a7f0$0600a8c0@calimero2>
References: <006501c49fde$d386a7f0$0600a8c0@calimero2>
Message-ID: <41502DDF.3040704@statistik.uni-dortmund.de>

Bruno Nogent wrote:

> Have you some simple examples ?

See the manual "Writing R Extensions".

Uwe Ligges

> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From paul.bliese at us.army.mil  Tue Sep 21 15:41:29 2004
From: paul.bliese at us.army.mil (Bliese, Paul D MAJ USAMH)
Date: Tue, 21 Sep 2004 15:41:29 +0200
Subject: [R] Bootstrap ICC estimate with nested data
Message-ID: <B32E0B24DEA2E344930910DEC438D0CF013198E3@amedmlmhah02.heidelberg.amedd.army.mil>

I would appreciate some thoughts on using the bootstrap functions in the
library "bootstrap" to estimate confidence intervals of ICC values
calculated in lme.

In lme, the ICC is calculated as tau/(tau+sigma-squared).  So, for instance
the ICC in the following example is 0.116:

> tmod<-lme(CINISMO~1,random=~1|IDGRUP,data=TDAT)
> VarCorr(tmod)
IDGRUP = pdLogChol(1) 
            Variance  StdDev  
(Intercept) 0.1829931 0.427777
Residual    1.3907732 1.179310
> 0.18299/(0.18299+1.39077)
[1] 0.1162757

Using the bootstrap library, I can set up theta to do the ICC as follows:

>theta<-function(x,DATA){tmod<-lme(CINISMO~1,random=~1|IDGRUP,data=DATA[x,])
OUT<-as.numeric(VarCorr(tmod)[[1]])/(as.numeric(VarCorr(tmod)[[1]])+as.numer
ic(VarCorr(tmod)[[2]]))
return(OUT)}

Finally, I can run the bootstrap-t confidence limit function (or other
functions) as follows:

> bootout<-boott(1:nrow(TDAT),100,theta,data=TDAT)

This seems to work, but the estimates also seem strange.  For intance, the
observed ICC value is larger than the 95% confidence intervals provided by
the bootstrap.  It occurs to me that the results might be strange because
the sampling with replacement is being done without regard to group
membership.  That is, I might select individual 1 from group 1 10 times
(even though in the sample the group only has 5 members), and I might not
select any individuals from group 2.

My fundamental question is:  "What are people's thoughts about using
bootstaping in nested data?  Does one have to sample with replacement taking
into consideration the group structure in the data?"  If so, any suggestions
on how to do this?


Paul Bliese
US Army Medical Research Unit - Europe



From e.j.pebesma at zonnet.nl  Tue Sep 21 15:41:44 2004
From: e.j.pebesma at zonnet.nl (Edzer Pebesma)
Date: Tue, 21 Sep 2004 15:41:44 +0200
Subject: [R] bubble plots
Message-ID: <41502F98.7060209@zonnet.nl>

Jacques, please try the following:

 > z=factor(c('a', 'b','c'))
 > z
[1] a b c
Levels: a b c
 > x = c(1,2,3)
 > y = c(3,2,1)
 > xyplot(y~x,groups=z,auto.key=T,asp=diff(range(y))/diff(range(x)))

the asp argument takes care of one unit in x being equal to one unit in y.
If you add e.g. pch=z to vary symbols, auto.key will have to be replaced
by the more complex key argument, see ?xyplot

Color and symbol type are better to distinguish factor variables than
size is, so I'd recommend using xyplot rather than bubble (which uses
xyplot to plot bubbles)
--
Edzer



From andrewr at uidaho.edu  Tue Sep 21 16:12:37 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Wed, 22 Sep 2004 00:12:37 +1000
Subject: [R] Bootstrap ICC estimate with nested data
Message-ID: <20040921141237.GP4024@uidaho.edu>

Paul,

I think that you should account for the group structure.

My reading of Davison and Hinkley "Bootstrap Methods and their
Application" (1997, p. 100) suggests that for balanced data structures
with more than, say, 10 clusters, one should apply the bootstrap to
the clusters, but not within the clusters.  They provide some further
notes that you might find useful.

I hope that this helps.

Andrew

On Tue, Sep 21, 2004 at 03:41:29PM +0200, Bliese, Paul D MAJ USAMH wrote:
> I would appreciate some thoughts on using the bootstrap functions in the
> library "bootstrap" to estimate confidence intervals of ICC values
> calculated in lme.
> 
> In lme, the ICC is calculated as tau/(tau+sigma-squared).  So, for instance
> the ICC in the following example is 0.116:
> 
> > tmod<-lme(CINISMO~1,random=~1|IDGRUP,data=TDAT)
> > VarCorr(tmod)
> IDGRUP = pdLogChol(1) 
>             Variance  StdDev  
> (Intercept) 0.1829931 0.427777
> Residual    1.3907732 1.179310
> > 0.18299/(0.18299+1.39077)
> [1] 0.1162757
> 
> Using the bootstrap library, I can set up theta to do the ICC as follows:
> 
> >theta<-function(x,DATA){tmod<-lme(CINISMO~1,random=~1|IDGRUP,data=DATA[x,])
> OUT<-as.numeric(VarCorr(tmod)[[1]])/(as.numeric(VarCorr(tmod)[[1]])+as.numer
> ic(VarCorr(tmod)[[2]]))
> return(OUT)}
> 
> Finally, I can run the bootstrap-t confidence limit function (or other
> functions) as follows:
> 
> > bootout<-boott(1:nrow(TDAT),100,theta,data=TDAT)
> 
> This seems to work, but the estimates also seem strange.  For intance, the
> observed ICC value is larger than the 95% confidence intervals provided by
> the bootstrap.  It occurs to me that the results might be strange because
> the sampling with replacement is being done without regard to group
> membership.  That is, I might select individual 1 from group 1 10 times
> (even though in the sample the group only has 5 members), and I might not
> select any individuals from group 2.
> 
> My fundamental question is:  "What are people's thoughts about using
> bootstaping in nested data?  Does one have to sample with replacement taking
> into consideration the group structure in the data?"  If so, any suggestions
> on how to do this?
> 
> 
> Paul Bliese
> US Army Medical Research Unit - Europe
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Andrew Robinson                      Ph: 208 885 7115
Department of Forest Resources       Fa: 208 885 6226
University of Idaho                  E : andrewr at uidaho.edu
PO Box 441133                        W : http://www.uidaho.edu/~andrewr
Moscow ID 83843                      Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.

----- End forwarded message -----

-- 
Andrew Robinson                      Ph: 208 885 7115
Department of Forest Resources       Fa: 208 885 6226
University of Idaho                  E : andrewr at uidaho.edu
PO Box 441133                        W : http://www.uidaho.edu/~andrewr
Moscow ID 83843                      Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.



From 0034058 at fudan.edu.cn  Tue Sep 21 16:51:56 2004
From: 0034058 at fudan.edu.cn (rongguiwong)
Date: Tue, 21 Sep 2004 22:51:56 +0800
Subject: [R] how to do jaccknife validation with R
In-Reply-To: <20040921141237.GP4024@uidaho.edu>
References: <20040921141237.GP4024@uidaho.edu>
Message-ID: <200409212251.56428.0034058@fudan.edu.cn>

i can only find jackknife validation after boot.
but this may be not the things i want.



From Scott at creditre.net  Tue Sep 21 16:59:31 2004
From: Scott at creditre.net (Scott Higginbotham)
Date: Tue, 21 Sep 2004 09:59:31 -0500
Subject: [R] R 1.9.1 Fails to Start on WinXP SP2
Message-ID: <D6ADF73299F5804D91FFED53FAC44D712D1935@creditre-svr.creditre.local>

I have two computers both of which are running Windows XP SP2. R 1.9.1
runs just fine on one but not the other. Both installations of R came
from the same installation package. When I click on the desktop icon an
hourglass shows up then disappears. Similarly, if I start RGUI the
process shows up in task-manager then abruptly disappears.
Interestingly, I can access R in Excel via the D(COM) Server on both
computers.

Any ideas?

Thanks,

Scott



From deepayan at stat.wisc.edu  Tue Sep 21 17:00:54 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Tue, 21 Sep 2004 10:00:54 -0500
Subject: [R] bubble plots
In-Reply-To: <41502F98.7060209@zonnet.nl>
References: <41502F98.7060209@zonnet.nl>
Message-ID: <200409211000.55097.deepayan@stat.wisc.edu>

On Tuesday 21 September 2004 08:41, Edzer Pebesma wrote:
> Jacques, please try the following:
>  > z=factor(c('a', 'b','c'))
>  > z
>
> [1] a b c
> Levels: a b c
>
>  > x = c(1,2,3)
>  > y = c(3,2,1)
>  > xyplot(y~x,groups=z,auto.key=T,asp=diff(range(y))/diff(range(x)))
>
> the asp argument takes care of one unit in x being equal to one unit
> in y. 

FWIW, In R 2.0.0 (currently beta), you can also do this with 
aspect="iso".

> If you add e.g. pch=z to vary symbols, auto.key will have to be 
> replaced by the more complex key argument, see ?xyplot

An alternative would be to change the settings (which is the only way 
the panel function and auto.key can share information). Temporary 
changes in settings can be attached to a trellis object as follows:

xyplot(y~x,groups=z,auto.key=T,asp=diff(range(y))/diff(range(x)),
       par.settings = 
       list(superpose.symbol = list(cex = 2, pch = levels(z))))

Deepayan



From Hagen.Schmoeller at iaew.rwth-aachen.de  Tue Sep 21 17:17:45 2004
From: Hagen.Schmoeller at iaew.rwth-aachen.de (=?iso-8859-1?Q?Hagen_Schm=F6ller?=)
Date: Tue, 21 Sep 2004 17:17:45 +0200
Subject: [R] DSE: covariance of white noise
Message-ID: <001c01c49fee$28c21f60$5c6a8286@iaew.rwthaachen.de>

Hi R-Community,

I estimated a VARMA model with bft in dse1 without input: A(L)yt = B(L)et

I got the auto-regressive polynomial array A and the moving-average
polynomial array B, but how can I access the covariances of the white noise
et (disturbance vector), e.g. for simulation?

Much thanks in advance,

Hagen Schmoeller
--
Dipl.-Ing. Hagen K. Schm??ller
Leiter Forschungsgruppe Stromerzeugung und -handel
Institut f??r Elektrische Anlagen und Energiewirtschaft, RWTH Aachen
Schinkelstra??e 6, D-52056 Aachen, Germany
Tel.: +49 (0)241 80-96734
Fax : +49 (0)241 80-92197
Hagen.Schmoeller at iaew.rwth-aachen.de



From calenge at biomserv.univ-lyon1.fr  Tue Sep 21 17:29:31 2004
From: calenge at biomserv.univ-lyon1.fr (=?iso-8859-1?Q?Cl=E9ment?= Calenge)
Date: Tue, 21 Sep 2004 17:29:31 +0200
Subject: [R] png problem
Message-ID: <5.1.0.14.0.20040921165434.02a557d0@biomserv.univ-lyon1.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040921/5b26c36d/attachment.pl

From aarthi_ireddy at yahoo.com  Tue Sep 21 17:40:40 2004
From: aarthi_ireddy at yahoo.com (aarthi ireddy)
Date: Tue, 21 Sep 2004 16:40:40 +0100 (BST)
Subject: [R] unable to install dse package
Message-ID: <20040921154040.74113.qmail@web50808.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040921/3b1796d8/attachment.pl

From lina1 at umbc.edu  Tue Sep 21 17:40:53 2004
From: lina1 at umbc.edu (lina1@umbc.edu)
Date: Tue, 21 Sep 2004 11:40:53 -0400 (EDT)
Subject: [R] S-PLUS and R 
Message-ID: <1255.68.67.255.208.1095781253.squirrel@68.67.255.208>

Hello,

How do I import data from Excel onto R? I am using S-Plus Envstat module.
I need to use some of the data that already exist in the Envstat and put
it into R to make graphs, find basic informations like mean, median,
standard deviation, etc. I have been reading the help links, but I don't
see anything in reference to this.

Please help me!

-Maher Lina



From aarthi_ireddy at yahoo.com  Tue Sep 21 17:41:12 2004
From: aarthi_ireddy at yahoo.com (aarthi ireddy)
Date: Tue, 21 Sep 2004 16:41:12 +0100 (BST)
Subject: [R] unable to install dse package
Message-ID: <20040921154112.51267.qmail@web50801.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040921/c0e19615/attachment.pl

From rpeng at jhsph.edu  Tue Sep 21 17:49:28 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 21 Sep 2004 11:49:28 -0400
Subject: [R] S-PLUS and R
In-Reply-To: <1255.68.67.255.208.1095781253.squirrel@68.67.255.208>
References: <1255.68.67.255.208.1095781253.squirrel@68.67.255.208>
Message-ID: <41504D88.2070103@jhsph.edu>

There is information in the R Data Import/Export manual:

http://cran.r-project.org/doc/manuals/R-data.pdf

-roger

lina1 at umbc.edu wrote:
> Hello,
> 
> How do I import data from Excel onto R? I am using S-Plus Envstat module.
> I need to use some of the data that already exist in the Envstat and put
> it into R to make graphs, find basic informations like mean, median,
> standard deviation, etc. I have been reading the help links, but I don't
> see anything in reference to this.
> 
> Please help me!
> 
> -Maher Lina
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Tue Sep 21 17:52:11 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 21 Sep 2004 17:52:11 +0200
Subject: [R] unable to install dse package
In-Reply-To: <20040921154040.74113.qmail@web50808.mail.yahoo.com>
References: <20040921154040.74113.qmail@web50808.mail.yahoo.com>
Message-ID: <41504E2B.5060002@statistik.uni-dortmund.de>

aarthi ireddy wrote:

> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file 'a:/project.txt'
>

Error in question: Required information missing
In addition: Warning message:
Cannot reply if version of R, dse, and OS, as well as details about the 
way of installation are missing.
Warning message: Name of e-mail sender is missing

please help

Uwe Ligges



> please help
> 
> 		
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Sep 21 17:53:27 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 21 Sep 2004 17:53:27 +0200
Subject: [R] S-PLUS and R
In-Reply-To: <1255.68.67.255.208.1095781253.squirrel@68.67.255.208>
References: <1255.68.67.255.208.1095781253.squirrel@68.67.255.208>
Message-ID: <41504E77.1010401@statistik.uni-dortmund.de>

lina1 at umbc.edu wrote:

> Hello,
> 
> How do I import data from Excel onto R? I am using S-Plus Envstat module.
> I need to use some of the data that already exist in the Envstat and put
> it into R to make graphs, find basic informations like mean, median,
> standard deviation, etc. I have been reading the help links, but I don't
> see anything in reference to this.
> 
> Please help me!

See the R Data Import/Export Manual.

Uwe Ligges

> -Maher Lina
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From HDoran at air.org  Tue Sep 21 17:55:15 2004
From: HDoran at air.org (Doran, Harold)
Date: Tue, 21 Sep 2004 11:55:15 -0400
Subject: [R] S-PLUS and R 
Message-ID: <88EAF3512A55DF46B06B1954AEF73F740578240D@dc1ex2.air.org>

?read.table 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of lina1 at umbc.edu
Sent: Tuesday, September 21, 2004 11:41 AM
To: R-help at stat.math.ethz.ch
Subject: [R] S-PLUS and R 

Hello,

How do I import data from Excel onto R? I am using S-Plus Envstat
module.
I need to use some of the data that already exist in the Envstat and put
it into R to make graphs, find basic informations like mean, median,
standard deviation, etc. I have been reading the help links, but I don't
see anything in reference to this.

Please help me!

-Maher Lina

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Tue Sep 21 17:57:37 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Sep 2004 17:57:37 +0200
Subject: [R] unable to install dse package
In-Reply-To: <20040921154040.74113.qmail@web50808.mail.yahoo.com>
References: <20040921154040.74113.qmail@web50808.mail.yahoo.com>
Message-ID: <x2vfe7mx72.fsf@biostat.ku.dk>

aarthi ireddy <aarthi_ireddy at yahoo.com> writes:

> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file 'a:/project.txt'

Er, what were you trying to do and why would you be reading from the
diskette? 

(Was there a previous message? I don't see it.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From JonesW at kssg.com  Tue Sep 21 17:55:22 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Tue, 21 Sep 2004 16:55:22 +0100
Subject: [R] S-PLUS and R 
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB02FEFA5D@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040921/7d64f798/attachment.pl

From kahra at mpsgr.it  Tue Sep 21 18:04:54 2004
From: kahra at mpsgr.it (Kahra Hannu)
Date: Tue, 21 Sep 2004 18:04:54 +0200
Subject: [R] unable to install dse package
Message-ID: <C9FC71F7E9356F40AFE2ACC2099DE1471C2616@MAILSERVER-B.mpsgr.it>

>Error in file(file, "r") : unable to open connection
>In addition: Warning message:
>cannot open file 'a:/project.txt'
 
>please help
help(read.table)

Hannu Kahra
		
---------------------------------

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From vito_ricci at yahoo.com  Tue Sep 21 18:19:24 2004
From: vito_ricci at yahoo.com (Vito Ricci)
Date: Tue, 21 Sep 2004 18:19:24 +0200 (CEST)
Subject: [R] S-PLUS and R
Message-ID: <20040921161924.87399.qmail@web41203.mail.yahoo.com>

Hi,

a shortcut to import data from an Excel sheet is:

In Excel
1) select cells including data
2) press CTRL+C (copy in clipboard)
open a window starting R

In R
type read.delim("clipboard",header=TRUE) 
if the are headers in excel data
or read.delim("clipboard",header=FALSE) 
if there are not headers 

See:

http://www.sciviews.org/_rgui/projects/RDcom.html
to use R in Excel.

Best
Vito
You wrote:

Hello,

How do I import data from Excel onto R? I am using
S-Plus Envstat module.
I need to use some of the data that already exist in
the Envstat and put
it into R to make graphs, find basic informations like
mean, median,
standard deviation, etc. I have been reading the help
links, but I don't
see anything in reference to this.

Please help me!

-Maher Lina

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml


		
___________________________________

http://it.seriea.fantasysports.yahoo.com/



From luke.keele at politics.ox.ac.uk  Tue Sep 21 18:48:12 2004
From: luke.keele at politics.ox.ac.uk (Luke Keele)
Date: Tue, 21 Sep 2004 12:48:12 -0400
Subject: [R] Problems with boot and optim
Message-ID: <000001c49ffa$c94f14e0$050aa8c0@HQ80G31>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040921/6909ecdf/attachment.pl

From spencer.graves at pdf.com  Tue Sep 21 19:01:44 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 21 Sep 2004 10:01:44 -0700
Subject: [R] Bootstrap ICC estimate with nested data
In-Reply-To: <20040921141237.GP4024@uidaho.edu>
References: <20040921141237.GP4024@uidaho.edu>
Message-ID: <41505E78.1010505@pdf.com>

      Have you considered "simulate.lme" in package nlme?  This is not 
bootstrapping, but it's not obvious to me how to bootstrap with a 
complicated structure and get anything with a simple interpretation.  
More information on this is provided in Pinhiero and Bates (2000) 
Mixed-Effects Models in S and S-Plus (Springer).  Bates is the primary 
architect of lme, nlme, etc.  I have found this book quite valuable. 

      hope this helps.  spencer graves

Andrew Robinson wrote:

>Paul,
>
>I think that you should account for the group structure.
>
>My reading of Davison and Hinkley "Bootstrap Methods and their
>Application" (1997, p. 100) suggests that for balanced data structures
>with more than, say, 10 clusters, one should apply the bootstrap to
>the clusters, but not within the clusters.  They provide some further
>notes that you might find useful.
>
>I hope that this helps.
>
>Andrew
>
>On Tue, Sep 21, 2004 at 03:41:29PM +0200, Bliese, Paul D MAJ USAMH wrote:
>  
>
>>I would appreciate some thoughts on using the bootstrap functions in the
>>library "bootstrap" to estimate confidence intervals of ICC values
>>calculated in lme.
>>
>>In lme, the ICC is calculated as tau/(tau+sigma-squared).  So, for instance
>>the ICC in the following example is 0.116:
>>
>>    
>>
>>>tmod<-lme(CINISMO~1,random=~1|IDGRUP,data=TDAT)
>>>VarCorr(tmod)
>>>      
>>>
>>IDGRUP = pdLogChol(1) 
>>            Variance  StdDev  
>>(Intercept) 0.1829931 0.427777
>>Residual    1.3907732 1.179310
>>    
>>
>>>0.18299/(0.18299+1.39077)
>>>      
>>>
>>[1] 0.1162757
>>
>>Using the bootstrap library, I can set up theta to do the ICC as follows:
>>
>>    
>>
>>>theta<-function(x,DATA){tmod<-lme(CINISMO~1,random=~1|IDGRUP,data=DATA[x,])
>>>      
>>>
>>OUT<-as.numeric(VarCorr(tmod)[[1]])/(as.numeric(VarCorr(tmod)[[1]])+as.numer
>>ic(VarCorr(tmod)[[2]]))
>>return(OUT)}
>>
>>Finally, I can run the bootstrap-t confidence limit function (or other
>>functions) as follows:
>>
>>    
>>
>>>bootout<-boott(1:nrow(TDAT),100,theta,data=TDAT)
>>>      
>>>
>>This seems to work, but the estimates also seem strange.  For intance, the
>>observed ICC value is larger than the 95% confidence intervals provided by
>>the bootstrap.  It occurs to me that the results might be strange because
>>the sampling with replacement is being done without regard to group
>>membership.  That is, I might select individual 1 from group 1 10 times
>>(even though in the sample the group only has 5 members), and I might not
>>select any individuals from group 2.
>>
>>My fundamental question is:  "What are people's thoughts about using
>>bootstaping in nested data?  Does one have to sample with replacement taking
>>into consideration the group structure in the data?"  If so, any suggestions
>>on how to do this?
>>
>>
>>Paul Bliese
>>US Army Medical Research Unit - Europe
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>    
>>
>
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From spencer.graves at pdf.com  Tue Sep 21 19:16:26 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 21 Sep 2004 10:16:26 -0700
Subject: [R] lme RE variance computation
In-Reply-To: <002201c49fd6$e456d490$b2133a86@www.domain>
References: <415020B2.1503.2A0C40DD@localhost>
	<002201c49fd6$e456d490$b2133a86@www.domain>
Message-ID: <415061EA.4030402@pdf.com>

      It may help to explicitly distinguish between parameter estimates 
and the true but unknown and unknowable "reality" that is assumed to 
have generated the data.  In that "reality", all variance components are 
nonnegative.  Generally inferior algorithms can compute negative 
variance components.  These were quite useful prior to the advent of 
modern computers and software like the nlme package. 

      I suggest you think very carefully about the problem you want to 
solve.  I have found Pinheiro and Bates (2000) Mixed-Effects Models in S 
and S-Plus (Springer) quite helpful both in theory and in how to 
implement it.  Bates is the primary architect of lme, nlme, etc., and 
this book provides basic documentation for that package.  In particular, 
I would expect that "simulate.lme" could be quite useful if you have any 
doubts about any issue. 

      hope this helps.  spencer graves

Dimitris Rizopoulos wrote:

> Hi Steve,
>
> Estimation problems for the variance components in linear mixed models 
> are usually occur for two reasons:
>
> 1. Due to model misspecification, i.e., using years instead of decades 
> may show no variability in the slopes
>
> 2. Because the data do not support the assumptions of the linear mixed 
> model (i.e., positive definite covariance matrix for the 
> random-effects => increasing variance with time).
>
> These may cause zero or even negative variance components. For more 
> info you could take a look at Verbeke and Molenberghs (2000, Section 
> 5.6) and Searle, Casella and McCullogh (1992, Section 3.5).
>
> I don't know the exact formulation you are using, but maybe you could 
> consider an analogue of you model using "gls", i.e.,
>
> lme(..., random=~1|id)
> gls(..., corr=corCompSymm(form=~1|id))
>
>
> The references mentioned above are:
>
> @Book{verbeke.molenberghs:00,
>  author    = {G. Verbeke and G. Molenberghs},
>  title     = {Linear Mixed Models for Longitudinal Data},
>  year      = {2000},
>  address   = {New York},
>  publisher = {Springer-Verlag}
> }
>
> @Book{searle.et.al:92,
>  author    = {S. Searle and G. Cassela and C. McCulloch},
>  title     = {Variance Components},
>  year      = {1992},
>  address   = {New York},
>  publisher = {Wiley}
> }
>
> I hope it helps.
>
> Best,
> Dimitris
>
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
>
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/396887
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
>
>
> ----- Original Message ----- From: "Steve Roberts" 
> <steve.roberts at man.ac.uk>
> To: <r-help at stat.math.ethz.ch>
> Sent: Tuesday, September 21, 2004 1:38 PM
> Subject: [R] lme RE variance computation
>
>
>> As I understand it lme (in R v1.9.x) estimates random effect variances
>> on a log scale, constraining them to be positive. Whilst this seems
>> sensible, it does lead to apparently biased estimates if the variance is
>> actually  zero - which makes our simulation results look strange. Whilst
>> we need to think a bit deeper about it - I still haven't got my head
>> around what a negative variance could mean - does anyone know a
>> way to take away the contraint and allowing zero or negative
>> variances?
>>
>> Steve.  Dr Steve Roberts
>>  steve.roberts at man.ac.uk
>>
>> Senior Lecturer in Medical Statistics,
>> CMMCH NHS Trust and University of Manchester Biostatistics Group,
>> 0161 275 5192 / 0161 276 5785
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html


-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From HDoran at air.org  Tue Sep 21 19:57:33 2004
From: HDoran at air.org (Doran, Harold)
Date: Tue, 21 Sep 2004 13:57:33 -0400
Subject: [R] Lme warning with coef() 
Message-ID: <88EAF3512A55DF46B06B1954AEF73F74057824CB@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040921/3c4b0175/attachment.pl

From Jason.L.Higbee at stls.frb.org  Tue Sep 21 20:26:29 2004
From: Jason.L.Higbee at stls.frb.org (Jason.L.Higbee@stls.frb.org)
Date: Tue, 21 Sep 2004 13:26:29 -0500
Subject: [R] constrained optimization in R
Message-ID: <20040921182633.94A6B1D434@p3fed1.frb.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040921/56e0c924/attachment.pl

From murdoch at stats.uwo.ca  Tue Sep 21 20:35:02 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 21 Sep 2004 14:35:02 -0400
Subject: [R] R 1.9.1 Fails to Start on WinXP SP2
In-Reply-To: <D6ADF73299F5804D91FFED53FAC44D712D1935@creditre-svr.creditre.local>
References: <D6ADF73299F5804D91FFED53FAC44D712D1935@creditre-svr.creditre.local>
Message-ID: <lvs0l05se2r1m6od075qf4th9pi21jm1am@4ax.com>

On Tue, 21 Sep 2004 09:59:31 -0500, "Scott Higginbotham"
<Scott at creditre.net> wrote :

>I have two computers both of which are running Windows XP SP2. R 1.9.1
>runs just fine on one but not the other. Both installations of R came
>from the same installation package. When I click on the desktop icon an
>hourglass shows up then disappears. Similarly, if I start RGUI the
>process shows up in task-manager then abruptly disappears.
>Interestingly, I can access R in Excel via the D(COM) Server on both
>computers.
>
>Any ideas?

Not a one!  Could you please try the beta build available on CRAN at

http://cran.r-project.org/bin/windows/base/rdevel.html

Thanks!

Duncan Murdoch



From spencer.graves at pdf.com  Tue Sep 21 20:46:33 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 21 Sep 2004 11:46:33 -0700
Subject: [R] constrained optimization in R
In-Reply-To: <20040921182633.94A6B1D434@p3fed1.frb.org>
References: <20040921182633.94A6B1D434@p3fed1.frb.org>
Message-ID: <41507709.5060201@pdf.com>

      Have you considered doing an unconstrained penalized optimization, 
e.g.

       pen.f(x, X, penalty) = function(x)(f(x[1], x[2])+penalty*(g(x[1], 
x[2])-X)^2)

        Then give "pen.f" to optim.  Start out with "penalty" small, 
then use optim's answers with one value of penalty as starting values 
for optim with double or 10 times the penalty.  As long as f and g are 
reasonably well behaved, this should produce an answer without excessive 
effort. 

       hope this helps.  spencer graves      

Jason.L.Higbee at stls.frb.org wrote:

>R:
>
>I need to minimize a function such that the parameters when used in 
>another function result in a particular value, which i fix.  That is, I 
>need min(f(a,b)) given g(a,b)=X, where min(.) is the minimum, f(.) and 
>g(.) are functions (with unknown gradients) of parameters a and b and X is 
>a fixed value.  What optimization function(s) in R do you suggest? 
>constrOptim looks like it will work except I don't know the gradient of 
>the functions.
>
>Thanks,
>
>Jason Higbee
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From Scott at creditre.net  Tue Sep 21 21:15:51 2004
From: Scott at creditre.net (Scott Higginbotham)
Date: Tue, 21 Sep 2004 14:15:51 -0500
Subject: [R] R 1.9.1 Fails to Start on WinXP SP2
Message-ID: <D6ADF73299F5804D91FFED53FAC44D712D193D@creditre-svr.creditre.local>


I should have noted in my first post that I had already tried that to no
avail.

Scott

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
Sent: Tuesday, September 21, 2004 1:35 PM
To: Scott Higginbotham
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] R 1.9.1 Fails to Start on WinXP SP2

On Tue, 21 Sep 2004 09:59:31 -0500, "Scott Higginbotham"
<Scott at creditre.net> wrote :

>I have two computers both of which are running Windows XP SP2. R 1.9.1
>runs just fine on one but not the other. Both installations of R came
>from the same installation package. When I click on the desktop icon an
>hourglass shows up then disappears. Similarly, if I start RGUI the
>process shows up in task-manager then abruptly disappears.
>Interestingly, I can access R in Excel via the D(COM) Server on both
>computers.
>
>Any ideas?

Not a one!  Could you please try the beta build available on CRAN at

http://cran.r-project.org/bin/windows/base/rdevel.html

Thanks!

Duncan Murdoch



From kjetil at acelerate.com  Tue Sep 21 21:16:07 2004
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Tue, 21 Sep 2004 15:16:07 -0400
Subject: [R] asypow.noncent: how does it work?
In-Reply-To: <1095683617_11977@drn10msi01>
References: <1095683617_11977@drn10msi01>
Message-ID: <41507DF7.3080903@acelerate.com>

david_foreman at doctors.org.uk wrote:

>I am trying to do power calculations for the proportional odds model using the asypow library.
>
>The code
> 
>noncenta90b10<-asypow.noncent(theta.ha=a9010,info.mat=infomatrixa90b10,constraints=constrt)
>
>returns
>
>Error in max(..., na.rm = na.rm) : invalid "mode" of argument.
>
>the various arguments I've used are:
> a9010
>           [,1]
>[1,] -1.7357568
>[2,] -0.1928619
>specifying the theta.ha array as a row not a column makes no difference
>
>
>  
>
>>infomatrixa90b10
>>    
>>
>             [,1]         [,2]
>[1,]  0.967005807 -0.004699262
>[2,] -0.004699262  0.903852346
>  
>  
>
>>constrt
>>    
>>
>     [,1] [,2] [,3]               
>[1,] "1"  "a"  "-1.92861865194525"
>[2,] "1"  "b"  "0"                
>
>
>I'm probably missing something very simple, but I can't see what it is.  Can anyone help?
>
>  
>
Problem is with your constarint matrix. From the help file (which 
admittedlt could be clearer)
constrain is a 3-column matrix. First element in a row should be 1 to 
indicate a param set == to a value,
2 to indicate equality of two params. You put 1, so we assume first 
case.  Second row element should be , in this case,
index of param set to value, and cannot be "a" or "b". Lets suppose 
yours are first and second parameter, then it shoud be 1 and 2, 
respectively.
Finally, in this case, third row element should be value.

So you should use something like
constrt <- matrix( c(1,1,-1.9286, 1,2,0), 2, 3, byrow=TRUE)

and then, using your values for the other arguments,

 > asypow.noncent(a9010, infomatrix, constrt)
$w
           [,1]
[1,] 0.06993048

$df
[1] 2

Kjetil


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra



From tlumley at u.washington.edu  Tue Sep 21 21:46:15 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 21 Sep 2004 12:46:15 -0700 (PDT)
Subject: [R] constrained optimization in R
In-Reply-To: <20040921182633.94A6B1D434@p3fed1.frb.org>
References: <20040921182633.94A6B1D434@p3fed1.frb.org>
Message-ID: <Pine.A41.4.61.0409211245570.35860@homer09.u.washington.edu>

On Tue, 21 Sep 2004 Jason.L.Higbee at stls.frb.org wrote:

> R:
>
> I need to minimize a function such that the parameters when used in
> another function result in a particular value, which i fix.  That is, I
> need min(f(a,b)) given g(a,b)=X, where min(.) is the minimum, f(.) and
> g(.) are functions (with unknown gradients) of parameters a and b and X is
> a fixed value.  What optimization function(s) in R do you suggest?
> constrOptim looks like it will work except I don't know the gradient of
> the functions.

constrOptim won't work -- it does INequality constraints.

 	-thomas


> Thanks,
>
> Jason Higbee
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From eric.rhelp at kostello.net  Tue Sep 21 22:14:07 2004
From: eric.rhelp at kostello.net (eric.rhelp@kostello.net)
Date: Tue, 21 Sep 2004 13:14:07 -0700
Subject: [R] can't understand "R"
In-Reply-To: <47313468.1095721859@erin.doty.macalester.edu>
References: <47313468.1095721859@erin.doty.macalester.edu>
Message-ID: <1095797647.26857.204855525@webmail.messagingengine.com>

Krause and Olson's "The Basics of S-PLUS" offers a very, very gentle
introduction to S-PLUS and R. (How gentle? It even explains how to
use a mouse!) It does not attempt to teach statistics or data analysis,
although the reader will certainly learn something by being exposed
to well-designed examples. "The Basics" teaches by example and
then explains more abstract aspects of what you have done. Because 
the step-by-step instructions are very clear, this works well.

I would not teach an S-PLUS or R based data analytic class without
at least placing it on the recommended reading list. I believe it
takes the place of nearly all material typically place on "tip
sheets." Nevertheless, it gets all the way through to writing simple
scripts and programs.

For a reader already familiar with script-based analysis in either
R or S-PLUS this book will not offer much value. For the reader
who needs to move beyond "point-and-click" into more solid data
analytic skills, I strongly recommend it.

Disclaimer: this is based on my review of the second edition, so
updates or corrections for the third edition may be in order.

Eric Kostello 

On Mon, 20 Sep 2004 23:10:59 -0500, "Erin L. Leisz"
<eleisz at Macalester.edu> said:
> hi.  i really need help using this program.  computer language is a
> foreign 
> language to me, and thus, i cannot make heads nor tails of the user
> manuals 
> from the website.  i need to locate step-by-step examples of simple 
> problems such as "graph f(x)+g(x) and f(g(x)) for the domain 0<x<2" and 
> "graph 2H(x), H(x)+1, H(x+1)"  i do know how to define the functions, but 
> that's it.  is there any help you could provide me?  i would appreciate 
> some help asap.  thank you very much
> erin leisz



From pauljohn at ku.edu  Wed Sep 22 00:34:32 2004
From: pauljohn at ku.edu (Paul Johnson)
Date: Tue, 21 Sep 2004 17:34:32 -0500
Subject: [R] Ever see a stata import problem like this?
Message-ID: <4150AC78.7060700@ku.edu>

Greetings Everybody:

I generated a 1.2MB dta file based on the general social survey with 
Stata8 for linux. The file can be re-opened with Stata, but when I bring 
it into R, it says all the values are missing for most of the variables.

This dataset is called "morgen.dta" and I dropped a copy online in case 
you are interested

http://www.ku.edu/~pauljohn/R/morgen.dta

looks like this to R (I tried various options on the read.dta command):

 > myDat <- read.dta("morgen.dta")
 > summary(myDat)
      CASEID              year            id         hrs1         hrs2
Min.   :   19721   Min.   :1972   Min.   :   1   NAP :    0   NAP :    0
1st Qu.: 1983475   1st Qu.:1978   1st Qu.: 445   DK  :    0   DK  :    0
Median : 1996808   Median :1987   Median : 905   NA  :    0   NA  :    0
Mean   : 9963040   Mean   :1986   Mean   : 990   NA's:40933   NA's:40933
  3rd Qu.:19872187   3rd Qu.:1994   3rd Qu.:1358
  Max.   :20002817   Max.   :2000   Max.   :3247

       prestige      agewed        age          educ        paeduc
  DK,NA,NAP:    0   NAP :    0   DK  :    0   NAP :    0   NAP :    0
  NA's     :40933   DK  :    0   NA  :    0   DK  :    0   DK  :    0
                    NA  :    0   NA's:40933   NA  :    0   NA  :    0
                    NA's:40933                NA's:40933   NA's:40933



   maeduc       speduc                 income
  NAP :    0   NAP :    0   $25000 OR MORE:14525
  DK  :    0   DK  :    0   $10000 - 14999: 5022
  NA  :    0   NA  :    0   $15000 - 19999: 3869
  NA's:40933   NA's:40933   $20000 - 24999: 3664
                            REFUSED       : 1877
                            (Other)       : 8523
                            NA's          : 3453
 >


Here's what Stata sees when I load the same thing:

summarize, detail

                  Case identification number
-------------------------------------------------------------
       Percentiles      Smallest
  1%       197432          19721
  5%       199649          19722
10%      1974116          19723       Obs               40933
25%      1983475          19724       Sum of Wgt.       40933

50%      1996808                      Mean            9963040
                         Largest       Std. Dev.       9006352
75%     1.99e+07       2.00e+07
90%     2.00e+07       2.00e+07       Variance       8.11e+13
95%     2.00e+07       2.00e+07       Skewness         .18931
99%     2.00e+07       2.00e+07       Kurtosis       1.045409

                 GSS YEAR FOR THIS RESPONDENT
-------------------------------------------------------------
       Percentiles      Smallest
  1%         1972           1972
  5%         1973           1972
10%         1974           1972       Obs               40933
25%         1978           1972       Sum of Wgt.       40933

50%         1987                      Mean           1986.421
                         Largest       Std. Dev.       8.61136
75%         1994           2000
90%         1998           2000       Variance       74.15552
95%         2000           2000       Skewness      -.0789223
99%         2000           2000       Kurtosis       1.799939

                     RESPONDENT ID NUMBER
-------------------------------------------------------------
       Percentiles      Smallest
  1%           18              1
  5%           89              1
10%          178              1       Obs               40933
25%          445              1       Sum of Wgt.       40933

50%          905                      Mean           989.9129
                         Largest       Std. Dev.      689.0596
75%         1358           3244
90%         2027           3245       Variance       474803.2
95%         2437           3246       Skewness       .8359211
99%         2867           3247       Kurtosis       3.311248

               NUMBER OF HOURS WORKED LAST WEEK
-------------------------------------------------------------
       Percentiles      Smallest
  1%            6              0
  5%           15              0
10%           21              0       Obs               23279
25%           37              0       Sum of Wgt.       23279

50%           40                      Mean           41.05206
                         Largest       Std. Dev.      13.95931
75%           48             89
90%           60             89       Variance       194.8624
95%           65             89       Skewness        .195045
99%           82             89       Kurtosis       4.448998

              NUMBER OF HOURS USUALLY WORK A WEEK
-------------------------------------------------------------
       Percentiles      Smallest
  1%            4              0
  5%           15              0
10%           20              1       Obs                 774
25%           38              2       Sum of Wgt.         774

50%           40                      Mean           39.79199
                         Largest       Std. Dev.      13.43383
75%           45             89
90%           55             89       Variance       180.4677
95%           60             89       Skewness      -.0002332
99%           80             89       Kurtosis       5.009869

            RS OCCUPATIONAL PRESTIGE SCORE  (1970)
-------------------------------------------------------------
       Percentiles      Smallest
  1%           14             12
  5%           17             12
10%           20             12       Obs               24267
25%           30             12       Sum of Wgt.       24267

50%           39                      Mean           39.35645
                         Largest       Std. Dev.      14.03712
75%           48             82
90%           60             82       Variance       197.0407
95%           62             82       Skewness       .2927414
99%           76             82       Kurtosis       2.775553

                    AGE WHEN FIRST MARRIED
-------------------------------------------------------------
       Percentiles      Smallest
  1%           15             12
  5%           17             12
10%           17             12       Obs               25382
25%           19             12       Sum of Wgt.       25382

50%           21                      Mean           22.09609
                         Largest       Std. Dev.      4.813944
75%           24             63
90%           28             68       Variance       23.17405
95%           31             73       Skewness       2.002265
99%           39             73       Kurtosis       11.28279

                       AGE OF RESPONDENT
-------------------------------------------------------------
       Percentiles      Smallest
  1%           19             18
  5%           21             18
10%           24             18       Obs               40790
25%           30             18       Sum of Wgt.       40790

50%           42                      Mean           45.14798
                         Largest       Std. Dev.      17.53519
75%           58             89
90%           71             89       Variance       307.4828
95%           77             89       Skewness       .4774907
99%           86             89       Kurtosis       2.239618

               HIGHEST YEAR OF SCHOOL COMPLETED
-------------------------------------------------------------
       Percentiles      Smallest
  1%            3              0
  5%            7              0
10%            8              0       Obs               40806
25%           11              0       Sum of Wgt.       40806

50%           12                      Mean           12.48152
                         Largest       Std. Dev.      3.176226
75%           14             20
90%           16             20       Variance       10.08841
95%           18             20       Skewness      -.3389303
99%           20             20       Kurtosis       3.960311

             HIGHEST YEAR SCHOOL COMPLETED, FATHER
-------------------------------------------------------------
       Percentiles      Smallest
  1%            0              0
  5%            3              0
10%            4              0       Obs               29347
25%            8              0       Sum of Wgt.       29347

50%           11                      Mean           10.20994
                         Largest       Std. Dev.      4.342143
75%           12             20
90%           16             20       Variance       18.85421
95%           17             20       Skewness      -.1628909
99%           20             20       Kurtosis       2.826482

             HIGHEST YEAR SCHOOL COMPLETED, MOTHER
-------------------------------------------------------------
       Percentiles      Smallest
  1%            0              0
  5%            3              0
10%            6              0       Obs               34151
25%            8              0       Sum of Wgt.       34151

50%           12                      Mean           10.41478
                         Largest       Std. Dev.      3.709352
75%           12             20
90%           14             20       Variance       13.75929
95%           16             20       Skewness      -.6324499
99%           18             20       Kurtosis       3.605715

             HIGHEST YEAR SCHOOL COMPLETED, SPOUSE
-------------------------------------------------------------
       Percentiles      Smallest
  1%            4              0
  5%            7              0
10%            8              0       Obs               22780
25%           12              0       Sum of Wgt.       22780

50%           12                      Mean           12.53095
                         Largest       Std. Dev.      3.103418
75%           14             20
90%           16             20       Variance       9.631203
95%           18             20       Skewness       -.287755
99%           20             20       Kurtosis       4.051822

                      TOTAL FAMILY INCOME
-------------------------------------------------------------
       Percentiles      Smallest
  1%            1              1
  5%            3              1
10%            5              1       Obs               37480
25%            9              1       Sum of Wgt.       37480

50%           11                      Mean            9.75619
                         Largest       Std. Dev.      2.994967
75%           12             13
90%           12             13       Variance       8.969825
95%           13             13       Skewness       -1.29205
99%           13             13       Kurtosis       3.759778

.


-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From jonathan_li at agilent.com  Wed Sep 22 03:05:58 2004
From: jonathan_li at agilent.com (jonathan_li@agilent.com)
Date: Tue, 21 Sep 2004 18:05:58 -0700
Subject: [R] RMySQL and Blob 
Message-ID: <65213341217E8D458E7C78E6640C74958BDD49@waglmb01.labs.agilent.com>

Dear R experts,

Does RMySQL package handle Blob datatype in a MySQL database? Blob can represent an image, a sound or some other 
large and complex binary objects. In an article published by R-database special interest group, named "A common database interface (DBI)" (updated June 2003),  it's mentioned in "open issues and limitations" that "We need to carefully plan how to deal with binary objects". 

Before I invest time to try, I would appreciate any experts' opinions.

Thanks,
Jonathan



From tlumley at u.washington.edu  Wed Sep 22 03:13:55 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 21 Sep 2004 18:13:55 -0700 (PDT)
Subject: [R] Ever see a stata import problem like this?
In-Reply-To: <4150AC78.7060700@ku.edu>
References: <4150AC78.7060700@ku.edu>
Message-ID: <Pine.A41.4.61.0409211811410.138406@homer07.u.washington.edu>

On Tue, 21 Sep 2004, Paul Johnson wrote:

> Greetings Everybody:
>
> I generated a 1.2MB dta file based on the general social survey with Stata8 
> for linux. The file can be re-opened with Stata, but when I bring it into R, 
> it says all the values are missing for most of the variables.

You need read.dta( ,convert.factors=FALSE)

You have variables with labels for some, but not all, of their values. 
When these are converted to R factors you lose the unlabelled values.  R 
does not have a data type that is sometimes labelled and sometimes 
numeric.

When you use convert.factors=FALSE the label information is still read in 
and returned as an attribute of the data frame, so you can set individual 
variables to be factors.

 	-thomas


>
> This dataset is called "morgen.dta" and I dropped a copy online in case you 
> are interested
>
> http://www.ku.edu/~pauljohn/R/morgen.dta
>
> looks like this to R (I tried various options on the read.dta command):
>
>> myDat <- read.dta("morgen.dta")
>> summary(myDat)
>     CASEID              year            id         hrs1         hrs2
> Min.   :   19721   Min.   :1972   Min.   :   1   NAP :    0   NAP :    0
> 1st Qu.: 1983475   1st Qu.:1978   1st Qu.: 445   DK  :    0   DK  :    0
> Median : 1996808   Median :1987   Median : 905   NA  :    0   NA  :    0
> Mean   : 9963040   Mean   :1986   Mean   : 990   NA's:40933   NA's:40933
> 3rd Qu.:19872187   3rd Qu.:1994   3rd Qu.:1358
> Max.   :20002817   Max.   :2000   Max.   :3247
>
>      prestige      agewed        age          educ        paeduc
> DK,NA,NAP:    0   NAP :    0   DK  :    0   NAP :    0   NAP :    0
> NA's     :40933   DK  :    0   NA  :    0   DK  :    0   DK  :    0
>                   NA  :    0   NA's:40933   NA  :    0   NA  :    0
>                   NA's:40933                NA's:40933   NA's:40933
>
>
>
>  maeduc       speduc                 income
> NAP :    0   NAP :    0   $25000 OR MORE:14525
> DK  :    0   DK  :    0   $10000 - 14999: 5022
> NA  :    0   NA  :    0   $15000 - 19999: 3869
> NA's:40933   NA's:40933   $20000 - 24999: 3664
>                           REFUSED       : 1877
>                           (Other)       : 8523
>                           NA's          : 3453
>>
>
>
> Here's what Stata sees when I load the same thing:
>
> summarize, detail
>
>                 Case identification number
> -------------------------------------------------------------
>      Percentiles      Smallest
> 1%       197432          19721
> 5%       199649          19722
> 10%      1974116          19723       Obs               40933
> 25%      1983475          19724       Sum of Wgt.       40933
>
> 50%      1996808                      Mean            9963040
>                        Largest       Std. Dev.       9006352
> 75%     1.99e+07       2.00e+07
> 90%     2.00e+07       2.00e+07       Variance       8.11e+13
> 95%     2.00e+07       2.00e+07       Skewness         .18931
> 99%     2.00e+07       2.00e+07       Kurtosis       1.045409
>
>                GSS YEAR FOR THIS RESPONDENT
> -------------------------------------------------------------
>      Percentiles      Smallest
> 1%         1972           1972
> 5%         1973           1972
> 10%         1974           1972       Obs               40933
> 25%         1978           1972       Sum of Wgt.       40933
>
> 50%         1987                      Mean           1986.421
>                        Largest       Std. Dev.       8.61136
> 75%         1994           2000
> 90%         1998           2000       Variance       74.15552
> 95%         2000           2000       Skewness      -.0789223
> 99%         2000           2000       Kurtosis       1.799939
>
>                    RESPONDENT ID NUMBER
> -------------------------------------------------------------
>      Percentiles      Smallest
> 1%           18              1
> 5%           89              1
> 10%          178              1       Obs               40933
> 25%          445              1       Sum of Wgt.       40933
>
> 50%          905                      Mean           989.9129
>                        Largest       Std. Dev.      689.0596
> 75%         1358           3244
> 90%         2027           3245       Variance       474803.2
> 95%         2437           3246       Skewness       .8359211
> 99%         2867           3247       Kurtosis       3.311248
>
>              NUMBER OF HOURS WORKED LAST WEEK
> -------------------------------------------------------------
>      Percentiles      Smallest
> 1%            6              0
> 5%           15              0
> 10%           21              0       Obs               23279
> 25%           37              0       Sum of Wgt.       23279
>
> 50%           40                      Mean           41.05206
>                        Largest       Std. Dev.      13.95931
> 75%           48             89
> 90%           60             89       Variance       194.8624
> 95%           65             89       Skewness        .195045
> 99%           82             89       Kurtosis       4.448998
>
>             NUMBER OF HOURS USUALLY WORK A WEEK
> -------------------------------------------------------------
>      Percentiles      Smallest
> 1%            4              0
> 5%           15              0
> 10%           20              1       Obs                 774
> 25%           38              2       Sum of Wgt.         774
>
> 50%           40                      Mean           39.79199
>                        Largest       Std. Dev.      13.43383
> 75%           45             89
> 90%           55             89       Variance       180.4677
> 95%           60             89       Skewness      -.0002332
> 99%           80             89       Kurtosis       5.009869
>
>           RS OCCUPATIONAL PRESTIGE SCORE  (1970)
> -------------------------------------------------------------
>      Percentiles      Smallest
> 1%           14             12
> 5%           17             12
> 10%           20             12       Obs               24267
> 25%           30             12       Sum of Wgt.       24267
>
> 50%           39                      Mean           39.35645
>                        Largest       Std. Dev.      14.03712
> 75%           48             82
> 90%           60             82       Variance       197.0407
> 95%           62             82       Skewness       .2927414
> 99%           76             82       Kurtosis       2.775553
>
>                   AGE WHEN FIRST MARRIED
> -------------------------------------------------------------
>      Percentiles      Smallest
> 1%           15             12
> 5%           17             12
> 10%           17             12       Obs               25382
> 25%           19             12       Sum of Wgt.       25382
>
> 50%           21                      Mean           22.09609
>                        Largest       Std. Dev.      4.813944
> 75%           24             63
> 90%           28             68       Variance       23.17405
> 95%           31             73       Skewness       2.002265
> 99%           39             73       Kurtosis       11.28279
>
>                      AGE OF RESPONDENT
> -------------------------------------------------------------
>      Percentiles      Smallest
> 1%           19             18
> 5%           21             18
> 10%           24             18       Obs               40790
> 25%           30             18       Sum of Wgt.       40790
>
> 50%           42                      Mean           45.14798
>                        Largest       Std. Dev.      17.53519
> 75%           58             89
> 90%           71             89       Variance       307.4828
> 95%           77             89       Skewness       .4774907
> 99%           86             89       Kurtosis       2.239618
>
>              HIGHEST YEAR OF SCHOOL COMPLETED
> -------------------------------------------------------------
>      Percentiles      Smallest
> 1%            3              0
> 5%            7              0
> 10%            8              0       Obs               40806
> 25%           11              0       Sum of Wgt.       40806
>
> 50%           12                      Mean           12.48152
>                        Largest       Std. Dev.      3.176226
> 75%           14             20
> 90%           16             20       Variance       10.08841
> 95%           18             20       Skewness      -.3389303
> 99%           20             20       Kurtosis       3.960311
>
>            HIGHEST YEAR SCHOOL COMPLETED, FATHER
> -------------------------------------------------------------
>      Percentiles      Smallest
> 1%            0              0
> 5%            3              0
> 10%            4              0       Obs               29347
> 25%            8              0       Sum of Wgt.       29347
>
> 50%           11                      Mean           10.20994
>                        Largest       Std. Dev.      4.342143
> 75%           12             20
> 90%           16             20       Variance       18.85421
> 95%           17             20       Skewness      -.1628909
> 99%           20             20       Kurtosis       2.826482
>
>            HIGHEST YEAR SCHOOL COMPLETED, MOTHER
> -------------------------------------------------------------
>      Percentiles      Smallest
> 1%            0              0
> 5%            3              0
> 10%            6              0       Obs               34151
> 25%            8              0       Sum of Wgt.       34151
>
> 50%           12                      Mean           10.41478
>                        Largest       Std. Dev.      3.709352
> 75%           12             20
> 90%           14             20       Variance       13.75929
> 95%           16             20       Skewness      -.6324499
> 99%           18             20       Kurtosis       3.605715
>
>            HIGHEST YEAR SCHOOL COMPLETED, SPOUSE
> -------------------------------------------------------------
>      Percentiles      Smallest
> 1%            4              0
> 5%            7              0
> 10%            8              0       Obs               22780
> 25%           12              0       Sum of Wgt.       22780
>
> 50%           12                      Mean           12.53095
>                        Largest       Std. Dev.      3.103418
> 75%           14             20
> 90%           16             20       Variance       9.631203
> 95%           18             20       Skewness       -.287755
> 99%           20             20       Kurtosis       4.051822
>
>                     TOTAL FAMILY INCOME
> -------------------------------------------------------------
>      Percentiles      Smallest
> 1%            1              1
> 5%            3              1
> 10%            5              1       Obs               37480
> 25%            9              1       Sum of Wgt.       37480
>
> 50%           11                      Mean            9.75619
>                        Largest       Std. Dev.      2.994967
> 75%           12             13
> 90%           12             13       Variance       8.969825
> 95%           13             13       Skewness       -1.29205
> 99%           13             13       Kurtosis       3.759778
>
> .
>
>
> -- 
> Paul E. Johnson                       email: pauljohn at ku.edu
> Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
> 1541 Lilac Lane, Rm 504
> University of Kansas                  Office: (785) 864-9086
> Lawrence, Kansas 66044-3177           FAX: (785) 864-5700
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From murdoch at stats.uwo.ca  Wed Sep 22 04:15:58 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 21 Sep 2004 22:15:58 -0400
Subject: [R] R 1.9.1 Fails to Start on WinXP SP2
In-Reply-To: <D6ADF73299F5804D91FFED53FAC44D712D193D@creditre-svr.creditre.local>
References: <D6ADF73299F5804D91FFED53FAC44D712D193D@creditre-svr.creditre.local>
Message-ID: <isn1l09budvh1nlg7i63on5cihpu5v7dnh@4ax.com>

On Tue, 21 Sep 2004 14:15:51 -0500, "Scott Higginbotham"
<Scott at creditre.net> wrote:

>
>I should have noted in my first post that I had already tried that to no
>avail.

In that case, things aren't easy.  You need to see where in the
startup sequence it's bailing out.  We don't have debug code installed
to do that (because this isn't a common problem!), so the only way I
know to find that is to compile R with debug information, and run it
under a debugger.  If you've never done that, it's a big job.

Duncan Murdoch


>
>Scott
>
>-----Original Message-----
>From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
>Sent: Tuesday, September 21, 2004 1:35 PM
>To: Scott Higginbotham
>Cc: r-help at stat.math.ethz.ch
>Subject: Re: [R] R 1.9.1 Fails to Start on WinXP SP2
>
>On Tue, 21 Sep 2004 09:59:31 -0500, "Scott Higginbotham"
><Scott at creditre.net> wrote :
>
>>I have two computers both of which are running Windows XP SP2. R 1.9.1
>>runs just fine on one but not the other. Both installations of R came
>>from the same installation package. When I click on the desktop icon an
>>hourglass shows up then disappears. Similarly, if I start RGUI the
>>process shows up in task-manager then abruptly disappears.
>>Interestingly, I can access R in Excel via the D(COM) Server on both
>>computers.
>>
>>Any ideas?
>
>Not a one!  Could you please try the beta build available on CRAN at
>
>http://cran.r-project.org/bin/windows/base/rdevel.html
>
>Thanks!
>
>Duncan Murdoch
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Wed Sep 22 04:31:08 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 21 Sep 2004 22:31:08 -0400
Subject: [R] R 1.9.1 Fails to Start on WinXP SP2
In-Reply-To: <D6ADF73299F5804D91FFED53FAC44D712D193D@creditre-svr.creditre.local>
References: <D6ADF73299F5804D91FFED53FAC44D712D193D@creditre-svr.creditre.local>
Message-ID: <9so1l05vroat2706e98gspqscrruau113s@4ax.com>

One other suggestion:

Run the msconfig "System configuration utility" to turn off most of
the software that loads on your machine at startup, and see if that
allows R to start.  Then gradually add it back until you find the
culprit, if there is one.

Duncan Murdoch



From andy_liaw at merck.com  Wed Sep 22 04:31:17 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 21 Sep 2004 22:31:17 -0400
Subject: [R] R 1.9.1 Fails to Start on WinXP SP2
Message-ID: <3A822319EB35174CA3714066D590DCD504AF83F2@usrymx25.merck.com>

Perhaps a couple of things to try before that:

1. See what Rterm.exe does.
2. See whether it makes any difference if the --vanilla flag is added to the
shortcut to Rgui.exe.  (E.g., was Rgui trying to load an existing .rda file
or execute some startup code on the computer that had the problem, and
otherwise on the other?)

Andy

> From: Duncan Murdoch
> 
> On Tue, 21 Sep 2004 14:15:51 -0500, "Scott Higginbotham"
> <Scott at creditre.net> wrote:
> 
> >
> >I should have noted in my first post that I had already 
> tried that to no
> >avail.
> 
> In that case, things aren't easy.  You need to see where in the
> startup sequence it's bailing out.  We don't have debug code installed
> to do that (because this isn't a common problem!), so the only way I
> know to find that is to compile R with debug information, and run it
> under a debugger.  If you've never done that, it's a big job.
> 
> Duncan Murdoch
> 
> 
> >
> >Scott
> >
> >-----Original Message-----
> >From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
> >Sent: Tuesday, September 21, 2004 1:35 PM
> >To: Scott Higginbotham
> >Cc: r-help at stat.math.ethz.ch
> >Subject: Re: [R] R 1.9.1 Fails to Start on WinXP SP2
> >
> >On Tue, 21 Sep 2004 09:59:31 -0500, "Scott Higginbotham"
> ><Scott at creditre.net> wrote :
> >
> >>I have two computers both of which are running Windows XP 
> SP2. R 1.9.1
> >>runs just fine on one but not the other. Both installations 
> of R came
> >>from the same installation package. When I click on the 
> desktop icon an
> >>hourglass shows up then disappears. Similarly, if I start RGUI the
> >>process shows up in task-manager then abruptly disappears.
> >>Interestingly, I can access R in Excel via the D(COM) Server on both
> >>computers.
> >>
> >>Any ideas?
> >
> >Not a one!  Could you please try the beta build available on CRAN at
> >
> >http://cran.r-project.org/bin/windows/base/rdevel.html
> >
> >Thanks!
> >
> >Duncan Murdoch
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From roger at ysidro.econ.uiuc.edu  Wed Sep 22 04:42:54 2004
From: roger at ysidro.econ.uiuc.edu (roger koenker)
Date: Tue, 21 Sep 2004 21:42:54 -0500
Subject: [R] ordered probit and cauchit
Message-ID: <1AB257FA-0C41-11D9-B246-000393A361A2@ysidro.econ.uiuc.edu>

What is the current state of the R-art for ordered probit models, and 
more
esoterically is there any available R strategy for ordered cauchit 
models,
i.e. ordered multinomial alternatives with a cauchy link function.  MCMC
is an option, obviously, but for a univariate latent variable model 
this seems
to be overkill... standard mle methods should be preferable.  (??)

Googling reveals that spss provides such functions... just to wave a red
flag.

> url:    www.econ.uiuc.edu/~roger                Roger Koenker
> email   rkoenker at uiuc.edu                       Department of Economics
> vox:    217-333-4558                            University of Illinois
> fax:    217-244-6678                            Champaign, IL 61820



From p.murrell at auckland.ac.nz  Wed Sep 22 07:03:35 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 22 Sep 2004 17:03:35 +1200
Subject: [R] png problem
References: <5.1.0.14.0.20040921165434.02a557d0@biomserv.univ-lyon1.fr>
Message-ID: <415107A7.3090506@stat.auckland.ac.nz>

Hi


Cl??ment Calenge wrote:
> Dear R-users,
> 
> I have a small problem with the function png(), when used with the
> argument colortype="pseudo.cube".
> 
>  > png("toto.png", colortype="pseudo.cube")
>  > image(matrix(rnorm(10000), 100, 100))
>  > dev.off()
> 
> R is blocked at the last command (R does not
> print any prompt after the last command). Nothing is
> written in the file (Gimp indicates that the file is corrupted).


Did you wait long enough?  This example took a little while to complete 
for me (may need someone more familiar with the code to tell us why it 
is so slow).

Paul


> However,
> 
>  > png("toto.png")
>  > image(matrix(rnorm(10000), 100, 100))
>  > dev.off()
> 
> works fine.
> I tried:
> 
>  > options(X11colortype = "pseudo.cube")
>  > png("toto.png")
>  > image(matrix(rnorm(10000), 100, 100))
>  > dev.off()
> 
> But, here again, R is blocked. I tried to replace dev.off() by
> graphics.off(), but this does not resolve the problem.
> The problem does not occurs when the function X11() is used
> instead of the function png().
> 
> I searched through the mail archive, the FAQ, on google,
> but I did not found any solution to this problem.
> On the help page on the function png(),
> it is indicated that "The colour handling will be that of the 'X11'
> device in use".
> 
> I never used these functions before, but maybe png()
> is not suitable with colortype="pseudo.cube" ?
> Can you tell me where I have missed something ?
> Thanks in Advance,
> 
> Cl??ment Calenge.
> 
>  >version
>           _
> platform sparc-sun-solaris2.9
> arch     sparc
> os       solaris2.9
> system   sparc, solaris2.9
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From ripley at stats.ox.ac.uk  Wed Sep 22 07:46:13 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Sep 2004 06:46:13 +0100 (BST)
Subject: [R] lda predict
In-Reply-To: <1CF0B26CECD746438AE02DBF7DDE1C7B17F44F@ifre2knas1.ifrxp.bbsrc.reserved>
Message-ID: <Pine.LNX.4.44.0409220645270.14428-100000@gannet.stats>

On Tue, 21 Sep 2004, rob foxall (IFR) wrote:

> Dear R-helpers,
> 
>             I have a model created by lda, and I would like to use this
> model to make predictions for new or old data. The catch is, I want to
> do this without using the "predict" function, i.e. only using
> information directly from the foo.lda object to create my posterior
> probabilities. 

Well, that's what predict.lda does, so please read its code.

> In anticipation of likely responses, I will be brushing
> up my lda knowledge using the given references when I have time, but am
> being hassled for an answer asap!


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From nmi13 at student.canterbury.ac.nz  Wed Sep 22 09:19:55 2004
From: nmi13 at student.canterbury.ac.nz (nmi13)
Date: Wed, 22 Sep 2004 19:19:55 +1200
Subject: [R] Bootstrap
Message-ID: <4150A295@webmail>

Dear Any,

Can someone please inform me, if they have a code to estimate the varaince 
using bootstrap resampling method under a two stage cluster design.

Thanks for all your help and time.

Murthy.M.N.,
PhD, Student,
University of Canterbury,
New Zealand.



From calenge at biomserv.univ-lyon1.fr  Wed Sep 22 09:31:33 2004
From: calenge at biomserv.univ-lyon1.fr (=?iso-8859-1?Q?Cl=E9ment?= Calenge)
Date: Wed, 22 Sep 2004 09:31:33 +0200
Subject: [R] png problem
In-Reply-To: <415107A7.3090506@stat.auckland.ac.nz>
References: <5.1.0.14.0.20040921165434.02a557d0@biomserv.univ-lyon1.fr>
Message-ID: <5.1.0.14.0.20040922091210.02a55618@biomserv.univ-lyon1.fr>

Hello,

Thanks for the fast reply.

Paul Murrell wrote:
>Hi
>
>
>Cl??ment Calenge wrote:
>>Dear R-users,
>>I have a small problem with the function png(), when used with the
>>argument colortype="pseudo.cube".
>>  > png("toto.png", colortype="pseudo.cube")
>>  > image(matrix(rnorm(10000), 100, 100))
>>  > dev.off()
>>R is blocked at the last command (R does not
>>print any prompt after the last command). Nothing is
>>written in the file (Gimp indicates that the file is corrupted).
>
>
>Did you wait long enough?  This example took a little while to complete 
>for me (may need someone more familiar with the code to tell us why it is 
>so slow).

You're right, it took 45 minutes for me.
However, since I need to use this code to build a Sweave vignette,
I cannot use it too often (I have about thirty files to create, this
would take about 20 hours to build the vignette !).
I also need the colortype argument (some graphics cards
do not allow the compilation of the vignette without).
Does anyone knows how to speed up the process ?

Cl??ment.


>Paul
>
>
>>However,
>>  > png("toto.png")
>>  > image(matrix(rnorm(10000), 100, 100))
>>  > dev.off()
>>works fine.
>>I tried:
>>  > options(X11colortype = "pseudo.cube")
>>  > png("toto.png")
>>  > image(matrix(rnorm(10000), 100, 100))
>>  > dev.off()
>>But, here again, R is blocked. I tried to replace dev.off() by
>>graphics.off(), but this does not resolve the problem.
>>The problem does not occurs when the function X11() is used
>>instead of the function png().
>>I searched through the mail archive, the FAQ, on google,
>>but I did not found any solution to this problem.
>>On the help page on the function png(),
>>it is indicated that "The colour handling will be that of the 'X11'
>>device in use".
>>I never used these functions before, but maybe png()
>>is not suitable with colortype="pseudo.cube" ?
>>Can you tell me where I have missed something ?
>>Thanks in Advance,
>>Cl??ment Calenge.
>>  >version
>>           _
>>platform sparc-sun-solaris2.9
>>arch     sparc
>>os       solaris2.9
>>system   sparc, solaris2.9
>>status
>>major    1
>>minor    9.1
>>year     2004
>>month    06
>>day      21
>>language R
>>         [[alternative HTML version deleted]]
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>--
>Dr Paul Murrell
>Department of Statistics
>The University of Auckland
>Private Bag 92019
>Auckland
>New Zealand
>64 9 3737599 x85392
>paul at stat.auckland.ac.nz
>http://www.stat.auckland.ac.nz/~paul/
>

======================================
UMR CNRS 5558 - Equipe "Ecologie Statistique"
Laboratoire de Biom??trie et Biologie Evolutive
Universit?? Claude Bernard Lyon 1
43, Boulevard du 11 novembre 1918
69622 Villeurbanne Cedex
FRANCE
tel. (+33) 04.72.43.27.57
fax. (+33) 04.72.43.13.88



From kan_liu1 at yahoo.com  Wed Sep 22 09:52:22 2004
From: kan_liu1 at yahoo.com (kan Liu)
Date: Wed, 22 Sep 2004 00:52:22 -0700 (PDT)
Subject: [R] t test problem?
Message-ID: <20040922075222.12142.qmail@web53908.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040922/9868e331/attachment.pl

From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Sep 22 10:00:16 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 22 Sep 2004 10:00:16 +0200
Subject: [R] t test problem?
References: <20040922075222.12142.qmail@web53908.mail.yahoo.com>
Message-ID: <004001c4a07a$326e9a20$b2133a86@www.domain>

Hi Liu,

before applying a t-test (or any test) you should first check if the 
assumptions of the test are supported by your data, i.e., in a t-test 
x and y must be normally distributed.

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "kan Liu" <kan_liu1 at yahoo.com>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, September 22, 2004 9:52 AM
Subject: [R] t test problem?


> Hello,
>
> I got two sets of data
> x=(124738, 128233, 85901, 33806, ...)
> y=(25292, 21877, 45498, 63973, ....)
> When I did a t test, I got two tail p-value = 0.117, which is not 
> significantly different.
>
> If I changed x, y to log scale, and re-do the t test, I got two tail 
> p-value = 0.042, which is significantly different.
>
> Now I got confused which one is correct. Any help would be very 
> appreciated.
>
> Thanks,
> Liu
>
> __________________________________________________
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From vito_ricci at yahoo.com  Wed Sep 22 10:03:21 2004
From: vito_ricci at yahoo.com (Vito Ricci)
Date: Wed, 22 Sep 2004 10:03:21 +0200 (CEST)
Subject: [R] t test problem?
Message-ID: <20040922080321.76076.qmail@web41207.mail.yahoo.com>

Hi,

maybe your data are distributed according a log-normal
distribution, so logs are normally distributed.
But remerber the significancy of t test can applied
only on log transformated data and not on original
data. See basic hypothesis for t testing, in
alternative use non-parametric methods to compare
results.
Best
Vito

You wrote:

Hello,
 
I got two sets of data
x=(124738, 128233, 85901, 33806, ...)
y=(25292, 21877, 45498, 63973, ....)
When I did a t test, I got two tail p-value = 0.117,
which is not significantly different.
 
If I changed x, y to log scale, and re-do the t test,
I got two tail p-value = 0.042, which is significantly
different.
 
Now I got confused which one is correct. Any help
would be very appreciated.
 
Thanks,
Liu

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml


		
___________________________________

http://it.seriea.fantasysports.yahoo.com/



From andrewr at uidaho.edu  Wed Sep 22 10:19:52 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Wed, 22 Sep 2004 18:19:52 +1000
Subject: [R] t test problem?
In-Reply-To: <004001c4a07a$326e9a20$b2133a86@www.domain>
References: <20040922075222.12142.qmail@web53908.mail.yahoo.com>
	<004001c4a07a$326e9a20$b2133a86@www.domain>
Message-ID: <20040922081952.GF2148@uidaho.edu>

Hi Dimitris,

you are describing a more stringent requirement than the t-test
actually requires.  It's the sampling distribution of the mean that
should be normal, and this condition is addressed by the Central
Limit Theorem.

Whether or not the CLT can be invoked depends on numerous factors,
including the distribution of the sample, and the size of the sample,
neither of which we have any information about. 

Liu, the problem you describe is associated with the application of
the test rather than the test itself.  The difference between log- and
natural- scaled data can often profitably be thought about by asking
whether you would naturally assume that the variation is additive
(natural scale) or multiplicative (log scale).  Given the information
that you've presented there's no way we can tell which version of the
test is more reliable. 

I hope that this helps.

Andrew

On Wed, Sep 22, 2004 at 10:00:16AM +0200, Dimitris Rizopoulos wrote:
> Hi Liu,
> 
> before applying a t-test (or any test) you should first check if the 
> assumptions of the test are supported by your data, i.e., in a t-test 
> x and y must be normally distributed.
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/396887
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message ----- 
> From: "kan Liu" <kan_liu1 at yahoo.com>
> To: <r-help at stat.math.ethz.ch>
> Sent: Wednesday, September 22, 2004 9:52 AM
> Subject: [R] t test problem?
> 
> 
> >Hello,
> >
> >I got two sets of data
> >x=(124738, 128233, 85901, 33806, ...)
> >y=(25292, 21877, 45498, 63973, ....)
> >When I did a t test, I got two tail p-value = 0.117, which is not 
> >significantly different.
> >
> >If I changed x, y to log scale, and re-do the t test, I got two tail 
> >p-value = 0.042, which is significantly different.
> >
> >Now I got confused which one is correct. Any help would be very 
> >appreciated.
> >
> >Thanks,
> >Liu
> >
> >__________________________________________________
> >
> >
> >
> >[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> >http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

-- 
Andrew Robinson                      Ph: 208 885 7115
Department of Forest Resources       Fa: 208 885 6226
University of Idaho                  E : andrewr at uidaho.edu
PO Box 441133                        W : http://www.uidaho.edu/~andrewr
Moscow ID 83843                      Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.



From pbrouilly at gphy.campus.univ-poitiers.fr  Wed Sep 22 10:43:18 2004
From: pbrouilly at gphy.campus.univ-poitiers.fr (pbrouilly@gphy.campus.univ-poitiers.fr)
Date: Wed, 22 Sep 2004 10:43:18 +0200
Subject: [R]
Message-ID: <1095842598.41513b26f348d@gphy.campus.univ-poitiers.fr>

Dear Any,

Is there a fonction in R to change a string to uppercase ?

Thanks for all your help



From d.firth at warwick.ac.uk  Wed Sep 22 11:04:12 2004
From: d.firth at warwick.ac.uk (David Firth)
Date: Wed, 22 Sep 2004 10:04:12 +0100
Subject: [R] ordered probit and cauchit
In-Reply-To: <1AB257FA-0C41-11D9-B246-000393A361A2@ysidro.econ.uiuc.edu>
Message-ID: <5ED50CE8-0C76-11D9-B3B9-000A95A6625E@warwick.ac.uk>

On Wednesday, Sep 22, 2004, at 03:42 Europe/London, roger koenker wrote:

> What is the current state of the R-art for ordered probit models, and 
> more
> esoterically is there any available R strategy for ordered cauchit 
> models,
> i.e. ordered multinomial alternatives with a cauchy link function.  
> MCMC
> is an option, obviously, but for a univariate latent variable model 
> this seems
> to be overkill... standard mle methods should be preferable.  (??)
>

A quick look at polr (in the MASS package) suggests to me that it 
wouldn't be all that hard to extend it to link functions other than 
logistic.

Is MLE known to be well behaved in these models if the latent variable 
is Cauchy?

David


> Googling reveals that spss provides such functions... just to wave a 
> red
> flag.
>
>> url:    www.econ.uiuc.edu/~roger                Roger Koenker
>> email   rkoenker at uiuc.edu                       Department of 
>> Economics
>> vox:    217-333-4558                            University of Illinois
>> fax:    217-244-6678                            Champaign, IL 61820
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From john_hendrickx at yahoo.com  Wed Sep 22 11:00:29 2004
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Wed, 22 Sep 2004 02:00:29 -0700 (PDT)
Subject: [R] Ever see a stata import problem like this?
In-Reply-To: <4150AC78.7060700@ku.edu>
Message-ID: <20040922090029.82705.qmail@web52707.mail.yahoo.com>

I've had a similar problem once. What may have caused the problem
then was a variate for which value lables had been defined for the
highest and lowest values. What complicates things is that the file
had been originally converted from SPSS to Stata. A workaround was to
set "convert.factor=FALSE" and that seems to work here too (using R
1.91 and the latest update for foreign): 

> m2<-read.dta("morgen.dta",convert.factors=FALSE)
> summary(m2)
     CASEID              year            id            hrs1         
 Min.   :   19721   Min.   :1972   Min.   :   1   Min.   :    0.00  
 1st Qu.: 1983475   1st Qu.:1978   1st Qu.: 445   1st Qu.:   37.00  
 Median : 1996808   Median :1987   Median : 905   Median :   40.00  
 Mean   : 9963040   Mean   :1986   Mean   : 990   Mean   :   41.05  
 3rd Qu.:19872187   3rd Qu.:1994   3rd Qu.:1358   3rd Qu.:   48.00  
 Max.   :20002817   Max.   :2000   Max.   :3247   Max.   :   89.00  
                                                  NA's   :17654.00  
      hrs2             prestige            agewed              age   
    
 Min.   :    0.00   Min.   :   12.00   Min.   :   12.00   Min.   :
18.00  
 1st Qu.:   38.00   1st Qu.:   30.00   1st Qu.:   19.00   1st Qu.:
30.00  
 Median :   40.00   Median :   39.00   Median :   21.00   Median :
42.00  
 Mean   :   39.79   Mean   :   39.36   Mean   :   22.10   Mean   :
45.15  
 3rd Qu.:   45.00   3rd Qu.:   48.00   3rd Qu.:   24.00   3rd Qu.:
58.00  
 Max.   :   89.00   Max.   :   82.00   Max.   :   73.00   Max.   :
89.00  
 NA's   :40159.00   NA's   :16666.00   NA's   :15551.00   NA's  
:143.00  
      educ            paeduc             maeduc            speduc    
   
 Min.   :  0.00   Min.   :    0.00   Min.   :   0.00   Min.   :   
0.00  
 1st Qu.: 11.00   1st Qu.:    8.00   1st Qu.:   8.00   1st Qu.:  
12.00  
 Median : 12.00   Median :   11.00   Median :  12.00   Median :  
12.00  
 Mean   : 12.48   Mean   :   10.21   Mean   :  10.41   Mean   :  
12.53  
 3rd Qu.: 14.00   3rd Qu.:   12.00   3rd Qu.:  12.00   3rd Qu.:  
14.00  
 Max.   : 20.00   Max.   :   20.00   Max.   :  20.00   Max.   :  
20.00  
 NA's   :127.00   NA's   :11586.00   NA's   :6782.00   NA's  
:18153.00  
     income        
 Min.   :   1.000  
 1st Qu.:   9.000  
 Median :  11.000  
 Mean   :   9.756  
 3rd Qu.:  12.000  
 Max.   :  13.000  
 NA's   :3453.000  
> 


--- Paul Johnson <pauljohn at ku.edu> wrote:

> Greetings Everybody:
> 
> I generated a 1.2MB dta file based on the general social survey
> with 
> Stata8 for linux. The file can be re-opened with Stata, but when I
> bring 
> it into R, it says all the values are missing for most of the
> variables.
> 
> This dataset is called "morgen.dta" and I dropped a copy online in
> case 
> you are interested
> 
> http://www.ku.edu/~pauljohn/R/morgen.dta
> 
[snip]



From Wanzare at HCJP.com  Wed Sep 22 11:12:48 2004
From: Wanzare at HCJP.com (Manoj - Hachibushu Capital)
Date: Wed, 22 Sep 2004 18:12:48 +0900
Subject: [R]
Message-ID: <111C3CD246AB774790496EBB3CD220080334B7@mothra.hcjp.com>

?toupper


p.s:
By default, generally everything on this list *is* regarding R; hence it
would be nice to see a more imaginative subject line.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
pbrouilly at gphy.campus.univ-poitiers.fr
Sent: Wednesday, September 22, 2004 5:43 PM
To: r-help at stat.math.ethz.ch
Subject: [R]

Dear Any,

Is there a fonction in R to change a string to uppercase ?

Thanks for all your help

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From JonesW at kssg.com  Wed Sep 22 11:09:32 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Wed, 22 Sep 2004 10:09:32 +0100
Subject: [R]
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB02FEFA88@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040922/5b3e3dc3/attachment.pl

From ligges at statistik.uni-dortmund.de  Wed Sep 22 11:14:58 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 22 Sep 2004 11:14:58 +0200
Subject: [R] convert string to uppercase; was: <nothing>
In-Reply-To: <1095842598.41513b26f348d@gphy.campus.univ-poitiers.fr>
References: <1095842598.41513b26f348d@gphy.campus.univ-poitiers.fr>
Message-ID: <41514292.10209@statistik.uni-dortmund.de>

pbrouilly at gphy.campus.univ-poitiers.fr wrote:

> Dear Any,
> 
> Is there a fonction in R to change a string to uppercase ?
> 
> Thanks for all your help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Please read the posting guide and learn

a) to use a sensible subject line
b) to use R's help facilities

You are looking for
?toupper

Uwe Ligges



From ahenningsen at email.uni-kiel.de  Wed Sep 22 11:18:23 2004
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Wed, 22 Sep 2004 11:18:23 +0200
Subject: [R]
In-Reply-To: <1095842598.41513b26f348d@gphy.campus.univ-poitiers.fr>
References: <1095842598.41513b26f348d@gphy.campus.univ-poitiers.fr>
Message-ID: <200409221118.24039.ahenningsen@email.uni-kiel.de>

help.search("upper")
"chartr(base)            Character Translation and Casefolding"

?chartr 
refers to the function
toupper()

Best wishes,
Arne

On Wednesday 22 September 2004 10:43, pbrouilly at gphy.campus.univ-poitiers.fr 
wrote:
> Dear Any,
>
> Is there a fonction in R to change a string to uppercase ?
>
> Thanks for all your help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From kan_liu1 at yahoo.com  Wed Sep 22 11:21:55 2004
From: kan_liu1 at yahoo.com (kan Liu)
Date: Wed, 22 Sep 2004 02:21:55 -0700 (PDT)
Subject: [R] t test problem?
In-Reply-To: <20040922081952.GF2148@uidaho.edu>
Message-ID: <20040922092155.23773.qmail@web53910.mail.yahoo.com>

Hi, Many thanks for your helpful comments and suggestions. The attached are the data in both log10 scale and original scale. It would be very grateful if you could suggest which version of test should be used. 
 
By the way, how to check whether the variation is additive (natural scale) or multiplicative (log scale) in R? How to check whether the distribution of the data is normal? 
 
PS, Can I confirm that do your suggestions mean that in order to check whether there is a difference between x and y in terms of mean I need check the distribution of x and that of y in both natual and log scales and to see which present normal distribution? and then perform a t test using the data scale which presents normal distribution? If both scales present normal distribution, then the t tests with both scales should give the similar results?
 
 
 
Thanks again.
 
Liu

Andrew Robinson <andrewr at uidaho.edu> wrote:
Hi Dimitris,

you are describing a more stringent requirement than the t-test
actually requires. It's the sampling distribution of the mean that
should be normal, and this condition is addressed by the Central
Limit Theorem.

Whether or not the CLT can be invoked depends on numerous factors,
including the distribution of the sample, and the size of the sample,
neither of which we have any information about. 

Liu, the problem you describe is associated with the application of
the test rather than the test itself. The difference between log- and
natural- scaled data can often profitably be thought about by asking
whether you would naturally assume that the variation is additive
(natural scale) or multiplicative (log scale). Given the information
that you've presented there's no way we can tell which version of the
test is more reliable. 

I hope that this helps.

Andrew

On Wed, Sep 22, 2004 at 10:00:16AM +0200, Dimitris Rizopoulos wrote:
> Hi Liu,
> 
> before applying a t-test (or any test) you should first check if the 
> assumptions of the test are supported by your data, i.e., in a t-test 
> x and y must be normally distributed.
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/396887
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
> http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message ----- 
> From: "kan Liu" 
> To: 
> Sent: Wednesday, September 22, 2004 9:52 AM
> Subject: [R] t test problem?
> 
> 
> >Hello,
> >
> >I got two sets of data
> >x=(124738, 128233, 85901, 33806, ...)
> >y=(25292, 21877, 45498, 63973, ....)
> >When I did a t test, I got two tail p-value = 0.117, which is not 
> >significantly different.
> >
> >If I changed x, y to log scale, and re-do the t test, I got two tail 
> >p-value = 0.042, which is significantly different.
> >
> >Now I got confused which one is correct. Any help would be very 
> >appreciated.
> >
> >Thanks,
> >Liu
> >
> >__________________________________________________
> >
> >
> >
> >[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> >http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

-- 
Andrew Robinson Ph: 208 885 7115
Department of Forest Resources Fa: 208 885 6226
University of Idaho E : andrewr at uidaho.edu
PO Box 441133 W : http://www.uidaho.edu/~andrewr
Moscow ID 83843 Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.


		
---------------------------------

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: data_natural.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040922/26d446fe/data_natural.txt
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: data_log10.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040922/26d446fe/data_log10.txt

From bruno.nogent at metaxis.fr  Wed Sep 22 11:29:41 2004
From: bruno.nogent at metaxis.fr (Bruno Nogent)
Date: Wed, 22 Sep 2004 11:29:41 +0200
Subject: [R] Create bitmap graphic in C
Message-ID: <018e01c4a086$b05f6480$0600a8c0@calimero2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040922/8b023ae2/attachment.pl

From andrewr at uidaho.edu  Wed Sep 22 11:34:48 2004
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Wed, 22 Sep 2004 19:34:48 +1000
Subject: [R] t test problem?
In-Reply-To: <20040922092155.23773.qmail@web53910.mail.yahoo.com>
References: <20040922081952.GF2148@uidaho.edu>
	<20040922092155.23773.qmail@web53910.mail.yahoo.com>
Message-ID: <20040922093448.GH2148@uidaho.edu>

> Hi, Many thanks for your helpful comments and suggestions. 

You're welcome.

> The attached are the data in both log10 scale and original scale. It
> would be very grateful if you could suggest which version of test
> should be used.

I feel that it would be inappropriate.  It depends on the origin
of the data.  You, as the analyst, must make that decision.  If you're
analyzing the data for someone else, then you should make that
decision with their input, or have them make it.

> By the way, how to check whether the variation is additive (natural
> scale) or multiplicative (log scale) in R? 

Unfortuantely you can't do that.  It depends on the context of the
data, which is not amenable to testing.

> How to check whether the distribution of the data is normal?

Tests exist for this, but there are problems with their usage.  Try
searching the help or your preferred search engine for more information.

> PS, Can I confirm that do your suggestions mean that in order to
> check whether there is a difference between x and y in terms of mean
> I need check the distribution of x and that of y in both natual and
> log scales and to see which present normal distribution? 

No, I don't agree with that statement, and I don't think that it
reflects my earlier message.

> and then perform a t test using the data scale which presents normal
> distribution?

Again, I don't agree.  I would advise you to apply the appropriate
test (maybe a t test, maybe not) to the data on the scale that is
suggested by the sampling scheme, the origin of the data, and the
hypothesis that interests you.

I hope that this helps.

Andrew
-- 
Andrew Robinson                      Ph: 208 885 7115
Department of Forest Resources       Fa: 208 885 6226
University of Idaho                  E : andrewr at uidaho.edu
PO Box 441133                        W : http://www.uidaho.edu/~andrewr
Moscow ID 83843                      Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.



From vito_ricci at yahoo.com  Wed Sep 22 11:44:03 2004
From: vito_ricci at yahoo.com (Vito Ricci)
Date: Wed, 22 Sep 2004 11:44:03 +0200 (CEST)
Subject: [R] t test problem?
Message-ID: <20040922094403.60429.qmail@web41205.mail.yahoo.com>

Hi Liu,

I'd suggest you to use non-parametric tests (see 
http://www.cas.lancs.ac.uk/glossary_v1.1/nonparam.html)
such as:
wilcox.test() in stats package
pairwise.wilcox.test() in stats package

and see the result tou got (significancy/non
significancy) and compare it with t test result;

Parametric Test   Analogous Non-Parametric test 

Student T-test   Wilcoxon Rank Sum Test 
Paired t-test    Wilcoxon Signed Rank Test or the Sign
Test 

to test normality you can use:

shapiro.test() in stats package 

if you decide to use log scale, you must use this for
both samples.



bye
Vito


You wrote:

Hi, Many thanks for your helpful comments and
suggestions. The attached are the data in both log10
scale and original scale. It would be very grateful if
you could suggest which version of test should be
used. 
 
By the way, how to check whether the variation is
additive (natural scale) or multiplicative (log scale)
in R? How to check whether the distribution of the
data is normal? 
 
PS, Can I confirm that do your suggestions mean that
in order to check whether there is a difference
between x and y in terms of mean I need check the
distribution of x and that of y in both natual and log
scales and to see which present normal distribution?
and then perform a t test using the data scale which
presents normal distribution? If both scales present
normal distribution, then the t tests with both scales
should give the similar results?
 
 
 
Thanks again.
 
Liu

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml


		
___________________________________

http://it.seriea.fantasysports.yahoo.com/



From christian.hoffmann at wsl.ch  Wed Sep 22 11:53:27 2004
From: christian.hoffmann at wsl.ch (Christian Hoffmann)
Date: Wed, 22 Sep 2004 11:53:27 +0200
Subject: [R] is.constant
In-Reply-To: <200409211010.i8LA4705019317@hypatia.math.ethz.ch>
References: <200409211010.i8LA4705019317@hypatia.math.ethz.ch>
Message-ID: <41514B97.4040005@wsl.ch>


>>x <- c(1, 2, NA)
>>is.constant(x)
> 
> [1] TRUE
> 
> For data such as c(1, 1, 1, NA), I should think the safest answer should be
> NA, because one really doesn't know whether that last number is 1 or not.
> 
> Andy
>  
My version is
is.constant <-  function(x) {
   if (is.numeric(x) & !any(is.na(x)))  identical(min(x), max(x)) else FALSE
}

rendering
 > is.constant(c(1,1,NA))
[1] FALSE
 > is.constant(c(1,1,NaN))
[1] FALSE
 > is.constant(rep(c(sin(pi/2),1),10)) # TRUE
[1] TRUE
-- 
Dr.sc.math.Christian W. Hoffmann, 
http://www.wsl.ch/staff/christian.hoffmann
Mathematics + Statistical Computing   e-mail: christian.hoffmann at wsl.ch
Swiss Federal Research Institute WSL  Tel: ++41-44-73922-   -77  (office)
CH-8903 Birmensdorf, Switzerland             -11(exchange), -15  (fax)



From i.visser at uva.nl  Wed Sep 22 11:54:02 2004
From: i.visser at uva.nl (Ingmar Visser)
Date: Wed, 22 Sep 2004 11:54:02 +0200
Subject: [R] Bootstrap
In-Reply-To: <4150A295@webmail>
Message-ID: <BD77185A.7C97%i.visser@uva.nl>

did you look at library(boot) ?boot

On 9/22/04 9:19 AM, "nmi13" <nmi13 at student.canterbury.ac.nz> wrote:

> Dear Any,
> 
> Can someone please inform me, if they have a code to estimate the varaince
> using bootstrap resampling method under a two stage cluster design.
> 
> Thanks for all your help and time.
> 
> Murthy.M.N.,
> PhD, Student,
> University of Canterbury,
> New Zealand.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From JonesW at kssg.com  Wed Sep 22 12:27:00 2004
From: JonesW at kssg.com (Wayne Jones)
Date: Wed, 22 Sep 2004 11:27:00 +0100
Subject: [R] t test problem?
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB02FEFA98@gimli.middleearth.kssg.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040922/057f517d/attachment.pl

From andy_liaw at merck.com  Wed Sep 22 12:31:31 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 22 Sep 2004 06:31:31 -0400
Subject: [R] is.constant
Message-ID: <3A822319EB35174CA3714066D590DCD504AF83F5@usrymx25.merck.com>

> Christian Hoffmann
> 
> >>x <- c(1, 2, NA)
> >>is.constant(x)
> > 
> > [1] TRUE
> > 
> > For data such as c(1, 1, 1, NA), I should think the safest 
> answer should be
> > NA, because one really doesn't know whether that last 
> number is 1 or not.
> > 
> > Andy
> >  
> My version is
> is.constant <-  function(x) {
>    if (is.numeric(x) & !any(is.na(x)))  identical(min(x), 
> max(x)) else FALSE
> }
> 
> rendering
>  > is.constant(c(1,1,NA))
> [1] FALSE

As I said, the `safest' thing is to return NA, as the NA could be 1, or it
could be something else.  We just don't know.  It's probably a cleaner style
to have is.constant() return NA in the case that the input contains contants
and some NAs, and TRUE or FALSE otherwise; e.g., is.constant(c(1,2,NA))
should clearly be FALSE.  Then the output of is.constant() should be checked
for possible NA.

Just my $0.02...

Andy

>  > is.constant(c(1,1,NaN))
> [1] FALSE
>  > is.constant(rep(c(sin(pi/2),1),10)) # TRUE
> [1] TRUE
> -- 
> Dr.sc.math.Christian W. Hoffmann, 
> http://www.wsl.ch/staff/christian.hoffmann
> Mathematics + Statistical Computing   e-mail: 
> christian.hoffmann at wsl.ch
> Swiss Federal Research Institute WSL  Tel: ++41-44-73922-   
> -77  (office)
> CH-8903 Birmensdorf, Switzerland             -11(exchange), -15  (fax)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From david_foreman at doctors.org.uk  Wed Sep 22 10:33:11 2004
From: david_foreman at doctors.org.uk (david_foreman@doctors.org.uk)
Date: Wed, 22 Sep 2004 10:33:11 (GMT)
Subject: [R] asypow.noncent.  Thanks!!
Message-ID: <1095849191_2372@drn10msi01>

Thank y'all for a) pointing out what I was doing wrong b) being so patient with what, in retrospect, was such an obvious blunder by me.  I'm afraid I was confused by the accompanying pdf file, which is not entirely consistent with the help files.




From rvalliant at survey.umd.edu  Wed Sep 22 12:32:51 2004
From: rvalliant at survey.umd.edu (Richard Valliant)
Date: Wed, 22 Sep 2004 06:32:51 -0400
Subject: [R] Re: R-help Digest, Vol 19, Issue 22
Message-ID: <s1511c9f.003@SURVEYGWIA.UMD.EDU>

I will be out of the office 9/22/04 - 9/27/04. For immediate help,
please call the JPSM main number, 301-314-7911.



From sdrees at sdrees.de  Wed Sep 22 12:56:29 2004
From: sdrees at sdrees.de (Stefan Drees)
Date: Wed, 22 Sep 2004 12:56:29 +0200
Subject: [R] function to change a string to uppercase
In-Reply-To: <1095842598.41513b26f348d@gphy.campus.univ-poitiers.fr>
References: <1095842598.41513b26f348d@gphy.campus.univ-poitiers.fr>
Message-ID: <20040922105629.GA19865@knoten.biz>

On Wed, Sep 22, 2004 at 10:43:18AM +0200 - a wonderful day 
		- pbrouilly at gphy.campus.univ-poitiers.fr wrote:
> Is there a fonction in R to change a string to uppercase ?
toupper()

hint: basic functionality is in package base ;) which is 
easy to investigate in html-help -> packages in my installation 
second entry from top of list ...

All the best,
Stefan.
-- 
.o. e-mail: stefan at drees.name, web: www.sdrees.org, +49 700 SDREESDE
..o fingerprint = 516C C4EF 712A B26F 15C9  C7B7 5651 6964 D508 1B56
ooo  stefan drees  -  consulting and lecturing  -  problems to tasks



From Simon.Bond at mrc-bsu.cam.ac.uk  Wed Sep 22 12:58:06 2004
From: Simon.Bond at mrc-bsu.cam.ac.uk (Simon.Bond)
Date: Wed, 22 Sep 2004 11:58:06 +0100 (BST)
Subject: [R] impenetrable warning
In-Reply-To: <200409221037.i8MAReqf010402@hypatia.math.ethz.ch>
References: <200409221037.i8MAReqf010402@hypatia.math.ethz.ch>
Message-ID: <Pine.GSO.4.58.0409221151250.8766@bononcini>

Dear R-help,

Can anyone explain the meaning of  the warning,

Singular precision matrix in level -1, block 1

? Or how to track down where it comes from?

More precisely, using the nlme package, I'm issued with the warning

itt2 <- lme(lrna~rx.nrti+lbrna, random=~1|patid,
cor=corExp(form=~days|patid,nugget=T), weights=varPower(
form=~lbrna),data=rna3)
Warning messages:
1: Singular precision matrix in level -1, block 1
2: Singular precision matrix in level -1, block 1

the output is:

Linear mixed-effects model fit by REML
  Data: rna3
  Log-restricted-likelihood: -4990.142
  Fixed: lrna ~ rx.nrti + lbrna
   (Intercept) rx.nrtiZDV+3TC rx.nrtiZDV+ABC          lbrna
     2.6597552      0.8589514      0.4259504      0.2929222

Random effects:
 Formula: ~1 | patid
        (Intercept)  Residual
StdDev:    1.251113 0.2105329

Correlation Structure: Exponential spatial correlation
 Formula: ~days | patid
 Parameter estimate(s):
      range      nugget
204.6422150   0.3349336
Variance function:
 Structure: Power of variance covariate
 Formula: ~lbrna
 Parameter estimates:
    power
0.9733358
Number of Observations: 2390
Number of Groups: 124



Thanks,

Simon Bond.



From christian.hoffmann at wsl.ch  Wed Sep 22 13:21:27 2004
From: christian.hoffmann at wsl.ch (Christian Hoffmann)
Date: Wed, 22 Sep 2004 13:21:27 +0200
Subject: [R] capitalize etc string
Message-ID: <41516037.4020705@wsl.ch>

 >Dear Any,

 >Is there a fonction in R to change a string to uppercase ?

 >Thanks for all your help


Use the following:


capply <- function(str, ff) {
   sapply(lapply(strsplit(str, NULL), ff), paste, collapse="")
}

cap <- function(char) {
   # change lower letters to upper, others leave unchanged
   if (any(ind <- letters==char)) LETTERS[ind]
   else char
}

capitalize <- function(str) { # vector of words
   ff <- function(x) paste(lapply(unlist(strsplit(x, 
NULL)),cap),collapse="")
   capply(str,ff)
}

lower <- function(char) {
   # change upper letters to lower, others leave unchanged
   if (any(ind <- LETTERS==char)) letters[ind]
   else char
}

lowerize <- function(str) {
   ff <- function(x) paste(lapply(unlist(strsplit(x, 
NULL)),lower),collapse="")
   capply(str,ff)
}

"CapLeading" <- function(str) {
   ff <- function(x) {r <- x; r[1]<-cap(x[1]); r}
   capply(str,ff)
}

#cap("f")
#cap("R")
#capitalize(c("TruE","faLSe"))
#capitalize(c("faLSe","TruE"))
#lower("f")
#lower("R")
#lowerize("TruE")
#lowerize("faLSe")

-- 
Dr.sc.math.Christian W. Hoffmann, 
http://www.wsl.ch/staff/christian.hoffmann
Mathematics + Statistical Computing   e-mail: christian.hoffmann at wsl.ch
Swiss Federal Research Institute WSL  Tel: ++41-44-73922-   -77  (office)
CH-8903 Birmensdorf, Switzerland             -11(exchange), -15  (fax)



From Ted.Harding at nessie.mcc.ac.uk  Wed Sep 22 13:07:07 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 22 Sep 2004 12:07:07 +0100 (BST)
Subject: [R] t test problem?
In-Reply-To: <20040922092155.23773.qmail@web53910.mail.yahoo.com>
Message-ID: <XFMail.040922120707.Ted.Harding@nessie.mcc.ac.uk>

On 22-Sep-04 kan Liu wrote:
> Hi, Many thanks for your helpful comments and suggestions. The attached
> are the data in both log10 scale and original scale. It would be very
> grateful if you could suggest which version of test should be used. 
>  
> By the way, how to check whether the variation is additive (natural
> scale) or multiplicative (log scale) in R? How to check whether the
> distribution of the data is normal? 

As for additive vs multiplicative, this can only be judged in terms
of the process by which the values are created in the real world.
As for normality vs non-normality, an appraisal can often be made
simply by looking at a histogram of the data.

In your case, the commands
  hist(x,breaks=10000*(0:100))
  hist(y,breaks=10000*(0:100))
indicate that the distributions of x and y do not look at all
"normal", since they both have considerable positive skewness
(i.e. long upper tails relative to the main mass of the distribution).

This does strongly suggest that a logarithmic transformation would
give data which are more nearly normally distributed, as indeed
is confirmed by the commands
  hist(log(x))
  hist(log(y))
though in both cases the histograms show some irregularity compared
with what you would expect from a sample from a normal distribution:
the commands
  hist(log(x),breaks=0.2*(40:80))
  hist(log(y),breaks=0.2*(40:80))
show that log(x) has an excessive peak at around 11.7,
while log(y) has holes at around 11.1 and 12.1.

Nevertheless, this inspection of the data shows that the use of
log(x) and log(y) will come much closer to fulfilling the conditions
of validity of the t test than using the raw data x and y.

However, it is not merely the *normality* of each which is needed:
the conditions for the usual t test also require that the two
populations sampled for log(x) and log(y) should have the same
standard deviations. In your case, this also turns out to be
nearly enough true:

  > sd(log(x))
  [1] 0.902579
  > sd(log(y))
  [1] 0.9314807

> PS, Can I confirm that do your suggestions mean that in order to check
> whether there is a difference between x and y in terms of mean I need
> check the distribution of x and that of y in both natual and log scales
> and to see which present normal distribution?

See above for an approach to this: the answer to your question is,
in effect, "yes". It could of course have happened that neither the
raw nor the log scale would be satisfactory, in which case you would
need to consider other possibilities. And, if the SDs had turned out
to be very different, you should not use the standard t test but
a variant which is adpated to the situation (e.g. the Welch test).

You can, of course, also perform formal tests for skewness, for
normality, and for equality of variances.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861   [NB: New number!]
Date: 22-Sep-04                                       Time: 12:07:07
------------------------------ XFMail ------------------------------



From christian.hoffmann at wsl.ch  Wed Sep 22 13:29:38 2004
From: christian.hoffmann at wsl.ch (Christian Hoffmann)
Date: Wed, 22 Sep 2004 13:29:38 +0200
Subject: [R]  is.constant 2
Message-ID: <41516222.7010200@wsl.ch>

 >>x <- c(1, 2, NA)
 >>>>is.constant(x)
 >
 >>
 >> [1] TRUE
 >>
 >> For data such as c(1, 1, 1, NA), I should think the safest answer 
should be
 >> NA, because one really doesn't know whether that last number is 1 or 
not.
 >>
 >> Andy
 >>

 >My version is
 >is.constant <-  function(x) {
 >   if (is.numeric(x) & !any(is.na(x)))  identical(min(x), max(x)) else 
 >FALSE
 >}

Since the issue of factors surfaced, I improved my function:

is.constant <-  function(x) {
   if (is.factor(x)) (length(attributes(x)$levels)==1) && 
(!any(is.na(as.character(x))))
   else (is.numeric(x) && !any(is.na(x)) && identical(min(x), max(x)))
}

  is.constant(rep(c(sin(pi/2),1),10)) # TRUE
  x <- factor(c(1,1,NA))
  is.constant(x)            # FALSE because of NA
  is.constant(x[1:2])       # TRUE
  is.constant(c(1,1,NA))    # FALSE because of NA
  is.constant(c(1,1,2))     # FALSE
  is.constant(c(1,1,1))     # TRUE

-- 
Dr.sc.math.Christian W. Hoffmann, 
http://www.wsl.ch/staff/christian.hoffmann
Mathematics + Statistical Computing   e-mail: christian.hoffmann at wsl.ch
Swiss Federal Research Institute WSL  Tel: ++41-44-73922-   -77  (office)
CH-8903 Birmensdorf, Switzerland             -11(exchange), -15  (fax)



From david.crabb at ntu.ac.uk  Wed Sep 22 13:46:43 2004
From: david.crabb at ntu.ac.uk (Crabb, David)
Date: Wed, 22 Sep 2004 12:46:43 +0100
Subject: [R] Residuals, smoothers and estimates of noise
Message-ID: <E2AEBF332DE0BE43966A19AB2622749DF08EEB@poplar.ads.ntu.ac.uk>

We have a clinical measurement on patients over time. Each patient has
about 5 of these measurements over a period of two years, but the
measurement are not necessarily taken at equal space in time. We want to
use this data to establish test-retest variability. My first thought was
to look at the residuals from fitting simple linear regression (the
measurement may deteriorate over time and we wish to remove this trend
-assuming of course that it is linear). But then what residual do I
choose to represent the variability for each patient? Would it be good
to use the mean of these? Has anyone got any better solutions with some
known functions in R? Do running medians or other smoothers require the
data to be a time series with equal spaces between time points?

Any help/references/suggestions in R would be gratefully received.

-----------------------------------------------
Dr. David Crabb
School of Science,
The Nottingham Trent University,
Clifton Campus, Nottingham. NG11 8NS
Tel: 0115 848 3275   Fax: 0115 848 6690



From umberto_maggiore at hotmail.com  Wed Sep 22 14:12:03 2004
From: umberto_maggiore at hotmail.com (Umberto Maggiore)
Date: Wed, 22 Sep 2004 12:12:03 +0000
Subject: [R] loops: pasting indexes in variables names
Message-ID: <BAY8-F7x27kBnccYTjr000024a7@hotmail.com>

I cannot figure out how, using R, I can paste indexes or characters to the 
variable
names which are used within loops. I will explain this with a simple 
example:
Immagine I have a huge series of variables, each one taken two times, say
x1 x2 y1 y2 z1 z2.....
Now, immagine that I want to compute a variable from the difference of
each couple, say dx=x1-x2, dy=y1-y2, dz=z1-z2...
In Stata, for example,  this wold be straightforward:
foreach i in x y z   {
		gen  d`i'= `i'1-`i'2
		}
With R I tried to use paste( ) but I found that it applies to objects,
not to variable names.
best regards,
Umberto



From ggrothendieck at myway.com  Wed Sep 22 14:16:10 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 22 Sep 2004 12:16:10 +0000 (UTC)
Subject: [R]  is.constant 2
References: <41516222.7010200@wsl.ch>
Message-ID: <loom.20040922T140923-847@post.gmane.org>

Christian Hoffmann <christian.hoffmann <at> wsl.ch> writes:

> 
> >>x <- c(1, 2, NA)
>  >>>>is.constant(x)
>  >
>  >>
>  >> [1] TRUE
>  >>
>  >> For data such as c(1, 1, 1, NA), I should think the safest answer 
> should be
>  >> NA, because one really doesn't know whether that last number is 1 or 
> not.
>  >>
>  >> Andy
>  >>
> 
>  >My version is
>  >is.constant <-  function(x) {
>  >   if (is.numeric(x) & !any(is.na(x)))  identical(min(x), max(x)) else 
>  >FALSE
>  >}
> 
> Since the issue of factors surfaced, I improved my function:
> 
> is.constant <-  function(x) {
>    if (is.factor(x)) (length(attributes(x)$levels)==1) && 
> (!any(is.na(as.character(x))))
>    else (is.numeric(x) && !any(is.na(x)) && identical(min(x), max(x)))
> }

Suggest you use an S3 generic and a separate methods for factor, and
in the future, other classes.  Also to make it more consistent with
other R functions have an na.rm= argument which defaults to TRUE.
If na.rm = FALSE then it should return NA  there are any NAs in
the same way that sum(c(1,2,NA), na.rm = FALSE) returns NA. There is 
some question of how to handle zero length arguments (or ones
that become zero length after removing NAs).

is.constant <- function(x, ...) UseMethod("is.constant")
is.constant.factor <- function(x, na.rm = TRUE) ... code for factor ...
is.constant.default <- function(x, na.rm = TRUE) ... code for default ...



From andy_liaw at merck.com  Wed Sep 22 14:09:34 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 22 Sep 2004 08:09:34 -0400
Subject: [R] impenetrable warning
Message-ID: <3A822319EB35174CA3714066D590DCD504AF83F6@usrymx25.merck.com>

Generally you can set options(warn=2), run the code, then do traceback().

Andy

> From: Simon.Bond
> 
> Dear R-help,
> 
> Can anyone explain the meaning of  the warning,
> 
> Singular precision matrix in level -1, block 1
> 
> ? Or how to track down where it comes from?
> 
> More precisely, using the nlme package, I'm issued with the warning
> 
> itt2 <- lme(lrna~rx.nrti+lbrna, random=~1|patid,
> cor=corExp(form=~days|patid,nugget=T), weights=varPower(
> form=~lbrna),data=rna3)
> Warning messages:
> 1: Singular precision matrix in level -1, block 1
> 2: Singular precision matrix in level -1, block 1
> 
> the output is:
> 
> Linear mixed-effects model fit by REML
>   Data: rna3
>   Log-restricted-likelihood: -4990.142
>   Fixed: lrna ~ rx.nrti + lbrna
>    (Intercept) rx.nrtiZDV+3TC rx.nrtiZDV+ABC          lbrna
>      2.6597552      0.8589514      0.4259504      0.2929222
> 
> Random effects:
>  Formula: ~1 | patid
>         (Intercept)  Residual
> StdDev:    1.251113 0.2105329
> 
> Correlation Structure: Exponential spatial correlation
>  Formula: ~days | patid
>  Parameter estimate(s):
>       range      nugget
> 204.6422150   0.3349336
> Variance function:
>  Structure: Power of variance covariate
>  Formula: ~lbrna
>  Parameter estimates:
>     power
> 0.9733358
> Number of Observations: 2390
> Number of Groups: 124
> 
> 
> 
> Thanks,
> 
> Simon Bond.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Sep 22 14:27:19 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 22 Sep 2004 14:27:19 +0200
Subject: [R] loops: pasting indexes in variables names
References: <BAY8-F7x27kBnccYTjr000024a7@hotmail.com>
Message-ID: <000401c4a09f$80c5afe0$b2133a86@www.domain>

Hi Umberto,

look at ?get, ?assign, ?paste and try the following:

x1 <- rnorm(10)
x2 <- rnorm(10)
y1 <- rnorm(10)
y2 <- rnorm(10)
z1 <- rnorm(10)
z2 <- rnorm(10)
######
names. <- c("x", "y", "z")
for(i in names.){
    res1 <- get(paste(i,"1",sep=""))
    res2 <- get(paste(i,"2",sep=""))
    assign(paste("d",i,sep=""), res1-res2)
}
#######
all.equal(dx, x1-x2)
all.equal(dy, y1-y2)
all.equal(dz, z1-z2)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Umberto Maggiore" <umberto_maggiore at hotmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, September 22, 2004 2:12 PM
Subject: [R] loops: pasting indexes in variables names


>I cannot figure out how, using R, I can paste indexes or characters 
>to the variable
> names which are used within loops. I will explain this with a simple 
> example:
> Immagine I have a huge series of variables, each one taken two 
> times, say
> x1 x2 y1 y2 z1 z2.....
> Now, immagine that I want to compute a variable from the difference 
> of
> each couple, say dx=x1-x2, dy=y1-y2, dz=z1-z2...
> In Stata, for example,  this wold be straightforward:
> foreach i in x y z   {
> gen  d`i'= `i'1-`i'2
> }
> With R I tried to use paste( ) but I found that it applies to 
> objects,
> not to variable names.
> best regards,
> Umberto
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ggrothendieck at myway.com  Wed Sep 22 14:31:03 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 22 Sep 2004 12:31:03 +0000 (UTC)
Subject: [R] loops: pasting indexes in variables names
References: <BAY8-F7x27kBnccYTjr000024a7@hotmail.com>
Message-ID: <loom.20040922T142454-557@post.gmane.org>

Umberto Maggiore <umberto_maggiore <at> hotmail.com> writes:

> 
> I cannot figure out how, using R, I can paste indexes or characters to the 
> variable
> names which are used within loops. I will explain this with a simple 
> example:
> Immagine I have a huge series of variables, each one taken two times, say
> x1 x2 y1 y2 z1 z2.....
> Now, immagine that I want to compute a variable from the difference of
> each couple, say dx=x1-x2, dy=y1-y2, dz=z1-z2...
> In Stata, for example,  this wold be straightforward:
> foreach i in x y z   {
> 		gen  d`i'= `i'1-`i'2
> 		}
> With R I tried to use paste( ) but I found that it applies to objects,
> not to variable names.
> best regards,
> Umberto

You can try this:

paste. <- function(...) paste(..., sep = "")
for(i in c("x", "y", "z"))
   assign(paste.("d", i), get(paste.(i, 1) - paste.(i, 2)))

You also might review why you need this since you may prefer
to use vectors, matrices, arrays, lists or data frames for
this sort of processing.  For example, if they were in a data
frame, DF, then you could write:

   DF[,1] - DF[,2]

and perform all the subtractions at once.



From murdoch at stats.uwo.ca  Wed Sep 22 14:40:40 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 22 Sep 2004 08:40:40 -0400
Subject: [R]  is.constant 2
In-Reply-To: <loom.20040922T140923-847@post.gmane.org>
References: <41516222.7010200@wsl.ch> <loom.20040922T140923-847@post.gmane.org>
Message-ID: <55s2l0l51evd4qceqlifpqsfijge6d3ia5@4ax.com>

On Wed, 22 Sep 2004 12:16:10 +0000 (UTC), Gabor Grothendieck
<ggrothendieck at myway.com> wrote :

>Suggest you use an S3 generic and a separate methods for factor, and
>in the future, other classes.  

That's not a bad idea, but is it really worth the trouble?  Why not
piggyback on the unique() generic, and define it as something like

is.constant <- function(x, na.rm = FALSE, ...) {
  vals <- unique(x, ...)
  if (na.rm) vals <- vals[!is.na(vals)]
  
  # What should the value be for c(1, NA)?  If FALSE is wanted,

  length(vals) == 1

  # but if NA is desired

  #  ifelse (any(is.na(vals)),  NA, length(vals) == 1)
}

>Also to make it more consistent with
>other R functions have an na.rm= argument which defaults to TRUE.

The more common default is FALSE.

Duncan Murdoch



From schnitzlerj at lyon.who.int  Wed Sep 22 14:45:34 2004
From: schnitzlerj at lyon.who.int (Johannes SCHNITZLER)
Date: Wed, 22 Sep 2004 14:45:34 +0200
Subject: [R] dot density maps
Message-ID: <AD1C47A0C9C12C46987E2D31EE1E63B4360AEC@lps001.lyon.who.int>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040922/bc5ba2c9/attachment.pl

From s-plus at wiwi.uni-bielefeld.de  Wed Sep 22 14:45:35 2004
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Wed, 22 Sep 2004 14:45:35 +0200
Subject: [R] loops: pasting indexes in variables names
References: <BAY8-F7x27kBnccYTjr000024a7@hotmail.com>
Message-ID: <415173EF.3060906@wiwi.uni-bielefeld.de>

Umberto Maggiore wrote:

> I cannot figure out how, using R, I can paste indexes or characters to 
> the variable
> names which are used within loops. I will explain this with a simple 
> example:
> Immagine I have a huge series of variables, each one taken two times, say
> x1 x2 y1 y2 z1 z2.....
> Now, immagine that I want to compute a variable from the difference of
> each couple, say dx=x1-x2, dy=y1-y2, dz=z1-z2...
> In Stata, for example,  this wold be straightforward:
> foreach i in x y z   {
>         gen  d`i'= `i'1-`i'2
>         }
> With R I tried to use paste( ) but I found that it applies to objects,
> not to variable names.
> best regards,
> Umberto
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

Try:
x1<-10
x2<-20
y1<-5
y2<-22
z1<-4
z2<-7
for(i in c("x","y","z")){
  eval(parse(text=paste("d",i,"<-",i,"1 - ",i,"2",sep="")))
}
ls(pattern="d")

output-start
Wed Sep 22 14:38:28 2004
[1] "dx" "dy" "dz"
output-end

but why don't  you  store x1,y1,z1  and x2,y2,z2  in a list:

a<-list(x=1:4, y=1:7, z=1:5)
b<-list(x=(1:4)*10, y=1:7, z=(1:5)-20)
d<-sapply(1:3, function(i) a[[i]]-b[[i]] )

@
output-start
Wed Sep 22 14:43:09 2004
[[1]]
[1]  -9 -18 -27 -36
[[2]]
[1] 0 0 0 0 0 0 0
[[3]]
[1] 20 20 20 20 20
output-end

Peter Wolf



From bruno.nogent at metaxis.fr  Wed Sep 22 15:00:49 2004
From: bruno.nogent at metaxis.fr (Bruno Nogent)
Date: Wed, 22 Sep 2004 15:00:49 +0200
Subject: [R] DCOM server high quality graphics ?
Message-ID: <001d01c4a0a4$2f32b6f0$0600a8c0@calimero2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040922/0edd504b/attachment.pl

From martin.ploederl at sbg.ac.at  Wed Sep 22 15:04:41 2004
From: martin.ploederl at sbg.ac.at (=?ISO-8859-1?Q?Martin_Pl=F6derl?=)
Date: Wed, 22 Sep 2004 15:04:41 +0200
Subject: [R] Multinomial Response Variable: Estimating the parameters
Message-ID: <41517869.4050607@sbg.ac.at>

Hello!

In a dyslexia-spelling-study we have a multinomial response variable 
with four categories.
There are 12 subjects. Each subject was tested on 30 words, i.e. there 
are 30 responses for each subject.
We are interested in estimating the parameters pi1, pi2, pi3, pi4, if 
possible point estimates and confidence intervals.
Is there a possibility in R to conduct this analysis?

-- 
Dr. Martin Pl??derl
Universit??t Salzburg
Fachbereich Psychologie
Abteilung Sozialpsychologie
Hellbrunnerstr. 34
5020 Salzburg

Phone: +43 662 8044 5130
martin.ploederl at sbg.ac.at



From highstat at highstat.com  Wed Sep 22 15:30:05 2004
From: highstat at highstat.com (Highland Statistics Ltd.)
Date: Wed, 22 Sep 2004 14:30:05 +0100
Subject: [R] R course
Message-ID: <6.1.2.0.0.20040922142834.01a0b9d8@Pop.highstat.com>

Apologies for cross-posting

We would like to announce a 3 day course: "R programming for beginners".

When: 10-12 January 2005 (Monday-Wednesday).
Location: The Ythan hotel in Newburgh (UK).  Newburgh is a small coastal 
village 10 miles north of Aberdeen airport.
Host: Organised by Highland Statistics Ltd.
Price: 500 Euro for 3 days, excluding 17.5% VAT. The course fee includes a 
copy of "Introductory Statistics with R" by P. Dalgaard.
You will need to bring you own laptop.
Accommodation is available at the Ythan hotel at a special rate of 30 UK 
pounds per night (including breakfast). Early booking is essential!


In this course, we teach how to use and program in the software package R. 
It is also relevant for S-Plus users who wish to learn script programming. 
The book "Introductory Statistics with R" from Peter Dalgaard is used as 
course material. We discuss how to import data into R, define vectors and 
nominal variables, make exploratory graphs, and apply ANOVA and linear 
regression. We assume that course attendants are familiar with the basic 
aspects of regression and ANOVA. Course attendants are encouraged to bring 
their own data.

There is only place for 10 people on this course.

Registration:   http://www.brodgar.com/statscourse.htm



Kind regards,

Alain Zuur



Dr. Alain F. Zuur
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh

Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com  (Brodgar complies with R GNU license)

Our 5-day statistics course: "Analysing Biological and Environmental Field 
data"
Brodgar: Software for multivariate analysis and multivariate time series 
analysis

Statistical consultancy, courses, data analysis and software



From dj at research.bell-labs.com  Wed Sep 22 16:04:54 2004
From: dj at research.bell-labs.com (David James)
Date: Wed, 22 Sep 2004 10:04:54 -0400
Subject: [R] RMySQL and Blob
In-Reply-To: <65213341217E8D458E7C78E6640C74958BDD49@waglmb01.labs.agilent.com>;
	from jonathan_li@agilent.com on Tue, Sep 21, 2004 at 06:05:58PM -0700
References: <65213341217E8D458E7C78E6640C74958BDD49@waglmb01.labs.agilent.com>
Message-ID: <20040922100454.B20269@jessie.research.bell-labs.com>

Hi Jonathan,

Currently RMySQL doesn't handle blob objects.  The mechanics of
inserting and extracting blob objects by itself is not too hard,
but issues such as how should blobs be made available to R, how to
prevent buffers overflows, how to prevent huge blobs from exhausting
the available memory, should R callback functions be invoked
as chunks of the blob are brought in, etc., need more consideration.
And these issues are not R/MySQL specific, but also relevant to
other databases and other non-dbms interfaces.

BTW there are R facilities (e.g., external pointers, finalizers) that 
seems quite important for this type of implementation.  

What type and how big are the blobs that want to import?

--
David

jonathan_li at agilent.com wrote:
> Dear R experts,
> 
> Does RMySQL package handle Blob datatype in a MySQL database? Blob can represent an image, a sound or some other 
> large and complex binary objects. In an article published by R-database special interest group, named "A common database interface (DBI)" (updated June 2003),  it's mentioned in "open issues and limitations" that "We need to carefully plan how to deal with binary objects". 
> 
> Before I invest time to try, I would appreciate any experts' opinions.
> 
> Thanks,
> Jonathan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Scott at creditre.net  Wed Sep 22 16:28:03 2004
From: Scott at creditre.net (Scott Higginbotham)
Date: Wed, 22 Sep 2004 09:28:03 -0500
Subject: [R] R 1.9.1 Fails to Start on WinXP SP2
Message-ID: <D6ADF73299F5804D91FFED53FAC44D712D194C@creditre-svr.creditre.local>

>One other suggestion:

>Run the msconfig "System configuration utility" to turn off most of
>the software that loads on your machine at startup, and see if that
>allows R to start.  Then gradually add it back until you find the
>culprit, if there is one.

Bingo! You rock Duncan. I had Rage3D (a video card overclocking utility)
installed on the machine that wouldn't run R and I was able to isolate
that as the problem. Once I uninstalled it, everything worked perfectly.

Thanks a million!

Scott



From jacques.veslot at cirad.fr  Wed Sep 22 16:32:08 2004
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Wed, 22 Sep 2004 18:32:08 +0400
Subject: [R] layout for xyplot
Message-ID: <HHEDKBCGCMDOHEDELFBCIEKPCCAA.jacques.veslot@cirad.fr>

Dear all,

I tried to use layout argument in xyplot to get one panel per page.

I have a dataframe named 'data' with the following variables:

x, y = coords,
sub, bloc = 2-level factors,
etat = 5-level factor,


I did :

>   lset(theme = col.whitebg())
>   xyplot(y ~ x | bloc*sub , data=data, groups=etat,
+       layout=c(0,1,4),
+       main="Etat des plantes dans chaque bloc",
+       auto.key=list(columns=5, cex=.8),
+       scales=list(relation="free", draw=FALSE),
+       xlab="", ylab="",
+       ylim=list(c(52, 69), c(16, 33), c(35, 51), c(-1, 15)))


and received this error message :

Error in if (!any(cond.max.level - cond.current.level < 0) && (row - 1) *  :
        missing value where TRUE/FALSE needed

I tried some changes in arguments - notably layout=c(0,1), but anything
works.

Thanks for helping...

Jacques VESLOT
CIRAD R??union



From murdoch at stats.uwo.ca  Wed Sep 22 16:36:12 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 22 Sep 2004 10:36:12 -0400
Subject: [R] R 1.9.1 Fails to Start on WinXP SP2
In-Reply-To: <D6ADF73299F5804D91FFED53FAC44D712D194C@creditre-svr.creditre.local>
References: <D6ADF73299F5804D91FFED53FAC44D712D194C@creditre-svr.creditre.local>
Message-ID: <mb33l0d66c7lv4sd7j5ad89gmr0om31hoa@4ax.com>

On Wed, 22 Sep 2004 09:28:03 -0500, "Scott Higginbotham"
<Scott at creditre.net> wrote :

>>One other suggestion:
>
>>Run the msconfig "System configuration utility" to turn off most of
>>the software that loads on your machine at startup, and see if that
>>allows R to start.  Then gradually add it back until you find the
>>culprit, if there is one.
>
>Bingo! You rock Duncan. I had Rage3D (a video card overclocking utility)
>installed on the machine that wouldn't run R and I was able to isolate
>that as the problem. Once I uninstalled it, everything worked perfectly.
>
>Thanks a million!

You're welcome.  You might want to let the Rage3D people know about
the problem; they might be in a position to see what's going wrong
with the R load process, and if it's their bug they might fix it.  I'd
be happy to correspond with them if they need info about R.

Duncan Murdoch



From kan_liu1 at yahoo.com  Wed Sep 22 16:38:41 2004
From: kan_liu1 at yahoo.com (kan Liu)
Date: Wed, 22 Sep 2004 07:38:41 -0700 (PDT)
Subject: [R] t test problem?
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB02FEFA98@gimli.middleearth.kssg.com>
Message-ID: <20040922143841.97912.qmail@web53907.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040922/41697b6a/attachment.pl

From ozric at web.de  Wed Sep 22 16:36:57 2004
From: ozric at web.de (Christian Schulz)
Date: Wed, 22 Sep 2004 16:36:57 +0200
Subject: [R] Multinomial Response Variable: Estimating the parameters
In-Reply-To: <41517869.4050607@sbg.ac.at>
References: <41517869.4050607@sbg.ac.at>
Message-ID: <200409221636.57697.ozric@web.de>

hmm,  the design sounds for me similiar to choice-data from 
choice-based-conjoint. 

IMHO check library(MNP) ?

regrads,christian


Am Mittwoch, 22. September 2004 15:04 schrieb Martin Pl??derl:
> Hello!
>
> In a dyslexia-spelling-study we have a multinomial response variable
> with four categories.
> There are 12 subjects. Each subject was tested on 30 words, i.e. there
> are 30 responses for each subject.
> We are interested in estimating the parameters pi1, pi2, pi3, pi4, if
> possible point estimates and confidence intervals.
> Is there a possibility in R to conduct this analysis?



From HStevens at MUOhio.edu  Wed Sep 22 16:54:15 2004
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Wed, 22 Sep 2004 10:54:15 -0400
Subject: [R] glmmPQL correlation structure
Message-ID: <45DF47D8-0CA7-11D9-B24A-000A958F43CC@MUOhio.edu>

Running Mac OS 10.3.5 and R 2.0
Does glmmPQL use the same spatial dependence models as gls in nmle? It 
does not seem to - I get the following, for example:
 > m2 <- glmmPQL(S.Early ~ fertilized*watered, data=geodat, 
family="poisson", random=~1|col)
iteration 1
iteration 2
 > plot(Variogram(m2, form=~col+row))
 > m3 <- update(m2,correlation=corSpher(c(5,.5), form=~col+row, 
nugget=T))
iteration 1
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
	invalid variable type
 >

Any leads on how to specify exponential or spherical models would be 
appreciated (e.g., pageg or chapter in Venables and Ripley 2002).

Cheers,
Hank


Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From deepayan at stat.wisc.edu  Wed Sep 22 17:17:39 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 22 Sep 2004 10:17:39 -0500
Subject: [R] layout for xyplot
In-Reply-To: <HHEDKBCGCMDOHEDELFBCIEKPCCAA.jacques.veslot@cirad.fr>
References: <HHEDKBCGCMDOHEDELFBCIEKPCCAA.jacques.veslot@cirad.fr>
Message-ID: <200409221017.39498.deepayan@stat.wisc.edu>


Have you read the posting guide, which says:

<quote>
For questions about unexpected behavior or a possible bug provide 
details about your platform (Windows2000, Linux, OS X) and R version 
(type version at the R prompt). State the full version number, e.g., 
`1.8.1', not just `1.8'. State whether you installed a pre-compiled 
binary version of R or compiled it yourself. If the function is in a 
package other than `base', include the header output from 
library(help=thatPackage). If you are using an old version of R and 
think it does not work properly, upgrade. 
</quote>

Further, we don't have access to your data, so there's no way we can 
reproduce what you have done. 

My guess is that you are using an old version of R and lattice, and this 
bug has already been fixed. I have no idea if it would help, but have 
you tried layout = c(1,1,4)?

Deepayan

On Wednesday 22 September 2004 09:32, Jacques VESLOT wrote:
> Dear all,
>
> I tried to use layout argument in xyplot to get one panel per page.
>
> I have a dataframe named 'data' with the following variables:
>
> x, y = coords,
> sub, bloc = 2-level factors,
> etat = 5-level factor,
>
> I did :
> >   lset(theme = col.whitebg())
> >   xyplot(y ~ x | bloc*sub , data=data, groups=etat,
>
> +       layout=c(0,1,4),
> +       main="Etat des plantes dans chaque bloc",
> +       auto.key=list(columns=5, cex=.8),
> +       scales=list(relation="free", draw=FALSE),
> +       xlab="", ylab="",
> +       ylim=list(c(52, 69), c(16, 33), c(35, 51), c(-1, 15)))
>
>
> and received this error message :
>
> Error in if (!any(cond.max.level - cond.current.level < 0) && (row -
> 1) *  : missing value where TRUE/FALSE needed
>
> I tried some changes in arguments - notably layout=c(0,1), but
> anything works.
>
> Thanks for helping...
>
> Jacques VESLOT
> CIRAD R??union
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From kahra at mpsgr.it  Wed Sep 22 17:22:20 2004
From: kahra at mpsgr.it (Kahra Hannu)
Date: Wed, 22 Sep 2004 17:22:20 +0200
Subject: [R] block statistics with POSIX classes
Message-ID: <C9FC71F7E9356F40AFE2ACC2099DE1471496B4@MAILSERVER-B.mpsgr.it>

I have a monthly price index series x, the related return series y = diff(log(x)) and a POSIXlt date-time variable dp. I would like to apply annual blocks to compute for example annual block maxima and mean of y.

When studying the POSIX classes, in the first stage of the learning curve, I computed the maximum drawdown of x:
> mdd <- maxdrawdown(x)
> max.dd <- mdd$maxdrawdown
> from <- as.character(dp[mdd$from]) 
> to <- as.character(dp[mdd$to])                       
> from; to
[1] "2000-08-31"
[1] "2003-03-31"
that gives me the POSIX dates of the start and end of the period and suggests that I have done something correctly.

Two questions:
(1) how to implement annual blocks and compute e.g. annual max, min and mean of y (each year's max, min, mean)?
(2) how to apply POSIX variables with the 'block' argument in gev in the evir package?

The S+FinMetrics function aggregateSeries does the job in that module; but I do not know, how handle it in R. My guess is that (1) is done by using the function aggregate, but how to define the 'by' argument with POSIX variables?

Thanks!
Hannu Kahra 
Progetti Speciali 
Monte Paschi Asset Management SGR S.p.A. 
Via San Vittore, 37
IT-20123 Milano, Italia 

Tel.: +39 02 43828 754 
Mobile: +39 333 876 1558 
Fax: +39 02 43828 247 
E-mail: kahra at mpsgr.it 
Web: www.mpsam.it



From morrct at andrew.cmu.edu  Wed Sep 22 17:29:15 2004
From: morrct at andrew.cmu.edu (Mark G Orr)
Date: Wed, 22 Sep 2004 11:29:15 -0400 (EDT)
Subject: [R] Sample without replacement
Message-ID: <Pine.LNX.4.60-041.0409221112490.3710@unix47.andrew.cmu.edu>

Hello, I have a simple problem (checked the archives and the appropriate 
help pages, to no avail).  I want to creat a vector that is length(2000). 
The vector is to consist of two strings( "std" and "dev") with 1760 "std"s 
and 240 "dev"s.  Furthermore, for each element of the vector, i want the 
selection of one of the strings to be approx. random.  The end result will 
be a vector with the following proportions:  .12 "dev" and .88 "std". 
My solution, below, almost works, but i don't get the exact desired 
proportions:


sample.from.vector <- c(rep("std",1760),rep("dev",240))

make.vector <- rep(99,2000)

for (i in 1:2000){
   make.vector[i] <- sample(sample.from.vector,1,replace=F)
}


As I understand the above code (which is not very well, obviously), each 
iteration assigns one element from the sample.from.vector  to the current 
make.vector element;  the element choosen from sample.from.vector is 
tagged so that i is not selected again.  However, after the loop, 
make.vector contains, for example, 1758 stds  and 242 devs.  Each 
iteration results in a different proportion of stds and devs (although 
close to the desired, not right on).

Any help would be greatly apprecitated.

-Mark Orr





________________________________
Mark G. Orr
Postdoctoral Research Fellow
Dept. of Neuroscience
RM 825 Kennedy Center
Albert Einstein College of Medicine
Bronx, NY  10461

718-430-2610



From p.dalgaard at biostat.ku.dk  Wed Sep 22 17:37:20 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Sep 2004 17:37:20 +0200
Subject: [R] Sample without replacement
In-Reply-To: <Pine.LNX.4.60-041.0409221112490.3710@unix47.andrew.cmu.edu>
References: <Pine.LNX.4.60-041.0409221112490.3710@unix47.andrew.cmu.edu>
Message-ID: <x26566e2mn.fsf@biostat.ku.dk>

Mark G Orr <morrct at andrew.cmu.edu> writes:

> Hello, I have a simple problem (checked the archives and the
> appropriate help pages, to no avail).  I want to creat a vector that
> is length(2000). The vector is to consist of two strings( "std" and
> "dev") with 1760 "std"s and 240 "dev"s.  Furthermore, for each element
> of the vector, i want the selection of one of the strings to be
> approx. random.  The end result will be a vector with the following
> proportions:  .12 "dev" and .88 "std". My solution, below, almost
> works, but i don't get the exact desired proportions:
> 
> 
> sample.from.vector <- c(rep("std",1760),rep("dev",240))
> 
> make.vector <- rep(99,2000)
> 
> for (i in 1:2000){
>    make.vector[i] <- sample(sample.from.vector,1,replace=F)
> }
> 
> 
> As I understand the above code (which is not very well, obviously),
> each iteration assigns one element from the sample.from.vector  to the
> current make.vector element;  the element choosen from
> sample.from.vector is tagged so that i is not selected again.
> However, after the loop, make.vector contains, for example, 1758 stds
> and 242 devs.  Each iteration results in a different proportion of
> stds and devs (although close to the desired, not right on).
> 
> Any help would be greatly apprecitated.

It's staring you right in the face:

make.vector <- sample(sample.from.vector)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From vedefont at jhsph.edu  Wed Sep 22 17:39:56 2004
From: vedefont at jhsph.edu (Valeria Edefonti)
Date: Wed, 22 Sep 2004 11:39:56 -0400
Subject: [R] pairs, panel.functions, xlim and ylim
Message-ID: <A7E8281E-0CAD-11D9-9DCC-00039303A6C4@jhsph.edu>

Hi,

I have the following problem.
I wanted to get a matrix of scatterplots and I used pairs.
I wanted to add the line y=x in each plot and I created a panel 
function for this scope.
I used points and abline in the following way:

## put y=x in each plot
     panel.lin<- function(x, y)
     {
         points(x,y, pch=21, bg=par("bg"), col = "black",cex=2)
         abline(0,1,lwd=2, col="red")
     }

and it works.
Now, I want that each plot has the same scale on the axis and I try 
with this modification:

## put y=x in each plot - same scale for all the plots
     panel.lincor<- function(x, y)
     {
         points(x,y, pch=21, bg=par("bg"), col = 
"black",cex=2,xlim=c(-1,1),ylim=c(-1,1))
         abline(0,1,lwd=2, col="red")
     }

but R tells me that xlim and ylim couldn't be set in high level plot 
functions.
I try to use plot() instead of points, but I realized immediately that 
I can't use plot as a panel function.
I know I could have added xlim and ylim directly in pairs() function, 
if I hadn't had a panel function, but I need the line y=x in every plot 
and I don't know other ways to get it.
Any idea?
Thank you very much
Valeria Edefonti



From dreinke at dowlinginc.com  Wed Sep 22 17:44:40 2004
From: dreinke at dowlinginc.com (David Reinke)
Date: Wed, 22 Sep 2004 08:44:40 -0700
Subject: [R] ordered probit and cauchit
In-Reply-To: <5ED50CE8-0C76-11D9-B3B9-000A95A6625E@warwick.ac.uk>
Message-ID: <NGEEIJFBPOOOEBFLNPGLGENIDBAA.dreinke@dowlinginc.com>

The Political Science Computational Laboratory at Stanford has R code for
ordered probit (courtesy of Simon Jackman):
http://pscl.stanford.edu/oprobit.

David Reinke


-----Original Message-----
From: David Firth [mailto:d.firth at warwick.ac.uk]
Sent: Wednesday, September 22, 2004 02:04
To: roger koenker
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] ordered probit and cauchit

On Wednesday, Sep 22, 2004, at 03:42 Europe/London, roger koenker wrote:

> What is the current state of the R-art for ordered probit models, and
> more
> esoterically is there any available R strategy for ordered cauchit
> models,
> i.e. ordered multinomial alternatives with a cauchy link function.
> MCMC
> is an option, obviously, but for a univariate latent variable model
> this seems
> to be overkill... standard mle methods should be preferable.  (??)
>

A quick look at polr (in the MASS package) suggests to me that it
wouldn't be all that hard to extend it to link functions other than
logistic.

Is MLE known to be well behaved in these models if the latent variable
is Cauchy?

David


> Googling reveals that spss provides such functions... just to wave a
> red
> flag.
>
>> url:    www.econ.uiuc.edu/~roger                Roger Koenker
>> email   rkoenker at uiuc.edu                       Department of
>> Economics
>> vox:    217-333-4558                            University of Illinois
>> fax:    217-244-6678                            Champaign, IL 61820
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From petr.pikal at precheza.cz  Wed Sep 22 17:56:44 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 22 Sep 2004 17:56:44 +0200
Subject: [R] block statistics with POSIX classes
In-Reply-To: <C9FC71F7E9356F40AFE2ACC2099DE1471496B4@MAILSERVER-B.mpsgr.it>
Message-ID: <4151BCDC.31717.20BFC90@localhost>



From jonathan_li at agilent.com  Wed Sep 22 18:08:26 2004
From: jonathan_li at agilent.com (jonathan_li@agilent.com)
Date: Wed, 22 Sep 2004 09:08:26 -0700
Subject: [R] RMySQL and Blob
Message-ID: <65213341217E8D458E7C78E6640C74958BDD4B@waglmb01.labs.agilent.com>

Hi David,

The application I have in mind is for images. In my case, size of images is known and they are not big. As an example, a 64*32 image will have 2048 pixels. If they are 8-bit grey-level pixels, the image occupies 2KB memory. 

I may venture to guess that the unknown size and type of a blob object in MySQL prevent it from being very usable in R since R doesn't have a datatype for a binary blob?

Thanks!
Jonathan


-----Original Message-----
From: David James [mailto:dj at research.bell-labs.com]
Sent: Wednesday, September 22, 2004 7:05 AM
To: LI,JONATHAN (A-Labs,ex1)
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] RMySQL and Blob


Hi Jonathan,

Currently RMySQL doesn't handle blob objects.  The mechanics of
inserting and extracting blob objects by itself is not too hard,
but issues such as how should blobs be made available to R, how to
prevent buffers overflows, how to prevent huge blobs from exhausting
the available memory, should R callback functions be invoked
as chunks of the blob are brought in, etc., need more consideration.
And these issues are not R/MySQL specific, but also relevant to
other databases and other non-dbms interfaces.

BTW there are R facilities (e.g., external pointers, finalizers) that 
seems quite important for this type of implementation.  

What type and how big are the blobs that want to import?

--
David

jonathan_li at agilent.com wrote:
> Dear R experts,
> 
> Does RMySQL package handle Blob datatype in a MySQL database? Blob can represent an image, a sound or some other 
> large and complex binary objects. In an article published by R-database special interest group, named "A common database interface (DBI)" (updated June 2003),  it's mentioned in "open issues and limitations" that "We need to carefully plan how to deal with binary objects". 
> 
> Before I invest time to try, I would appreciate any experts' opinions.
> 
> Thanks,
> Jonathan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jrausch at nd.edu  Wed Sep 22 18:51:32 2004
From: jrausch at nd.edu (Joe Rausch)
Date: Wed, 22 Sep 2004 11:51:32 -0500
Subject: [R] Issue with predict() for glm models 
Message-ID: <5.1.0.14.2.20040922110623.00c9c710@imap.nd.edu>



From spencer.graves at pdf.com  Wed Sep 22 18:55:13 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 22 Sep 2004 09:55:13 -0700
Subject: [R] glmmPQL correlation structure
In-Reply-To: <45DF47D8-0CA7-11D9-B24A-000A958F43CC@MUOhio.edu>
References: <45DF47D8-0CA7-11D9-B24A-000A958F43CC@MUOhio.edu>
Message-ID: <4151AE71.5050204@pdf.com>

      Have you tried GLMM in lme4?  Doug Bates is the primary architect 
of both nlme and lme4.  Therefore, I would think that a spatial 
dependence model that works in nlme might also work in GLMM. 

      hope this helps.  spencer graves

Martin Henry H. Stevens wrote:

> Running Mac OS 10.3.5 and R 2.0
> Does glmmPQL use the same spatial dependence models as gls in nmle? It 
> does not seem to - I get the following, for example:
> > m2 <- glmmPQL(S.Early ~ fertilized*watered, data=geodat, 
> family="poisson", random=~1|col)
> iteration 1
> iteration 2
> > plot(Variogram(m2, form=~col+row))
> > m3 <- update(m2,correlation=corSpher(c(5,.5), form=~col+row, nugget=T))
> iteration 1
> Error in model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>     invalid variable type
> >
>
> Any leads on how to specify exponential or spherical models would be 
> appreciated (e.g., pageg or chapter in Venables and Ripley 2002).
>
> Cheers,
> Hank
>
>
> Dr. Martin Henry H. Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/botany/bot/henry.html
> http://www.muohio.edu/ecology/
> http://www.muohio.edu/botany/
> "E Pluribus Unum"
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html


-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From morrct at andrew.cmu.edu  Wed Sep 22 18:55:44 2004
From: morrct at andrew.cmu.edu (Mark G Orr)
Date: Wed, 22 Sep 2004 12:55:44 -0400 (EDT)
Subject: [R] THanks, random/repl. prob. SOLVED.
Message-ID: <Pine.LNX.4.60-041.0409221255040.10015@unix42.andrew.cmu.edu>

Thanks for the help, it worked.





________________________________
Mark G. Orr
Postdoctoral Research Fellow
Dept. of Neuroscience
RM 825 Kennedy Center
Albert Einstein College of Medicine
Bronx, NY  10461

718-430-2610



From spencer.graves at pdf.com  Wed Sep 22 18:59:34 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 22 Sep 2004 09:59:34 -0700
Subject: [R] impenetrable warning
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF83F6@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF83F6@usrymx25.merck.com>
Message-ID: <4151AF76.60803@pdf.com>

      In this case, this trick will identify the specify command in the 
lme code that produce the error. 

      If that does not lead you to an answer, have you tried simplifying 
your lme call to identify more clearly which part (or combination) seems 
to generate the problem? 

      hope this helps.  spencer graves

Liaw, Andy wrote:

>Generally you can set options(warn=2), run the code, then do traceback().
>
>Andy
>
>  
>
>>From: Simon.Bond
>>
>>Dear R-help,
>>
>>Can anyone explain the meaning of  the warning,
>>
>>Singular precision matrix in level -1, block 1
>>
>>? Or how to track down where it comes from?
>>
>>More precisely, using the nlme package, I'm issued with the warning
>>
>>itt2 <- lme(lrna~rx.nrti+lbrna, random=~1|patid,
>>cor=corExp(form=~days|patid,nugget=T), weights=varPower(
>>form=~lbrna),data=rna3)
>>Warning messages:
>>1: Singular precision matrix in level -1, block 1
>>2: Singular precision matrix in level -1, block 1
>>
>>the output is:
>>
>>Linear mixed-effects model fit by REML
>>  Data: rna3
>>  Log-restricted-likelihood: -4990.142
>>  Fixed: lrna ~ rx.nrti + lbrna
>>   (Intercept) rx.nrtiZDV+3TC rx.nrtiZDV+ABC          lbrna
>>     2.6597552      0.8589514      0.4259504      0.2929222
>>
>>Random effects:
>> Formula: ~1 | patid
>>        (Intercept)  Residual
>>StdDev:    1.251113 0.2105329
>>
>>Correlation Structure: Exponential spatial correlation
>> Formula: ~days | patid
>> Parameter estimate(s):
>>      range      nugget
>>204.6422150   0.3349336
>>Variance function:
>> Structure: Power of variance covariate
>> Formula: ~lbrna
>> Parameter estimates:
>>    power
>>0.9733358
>>Number of Observations: 2390
>>Number of Groups: 124
>>
>>
>>
>>Thanks,
>>
>>Simon Bond.
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From jrausch at nd.edu  Wed Sep 22 19:01:50 2004
From: jrausch at nd.edu (Joe Rausch)
Date: Wed, 22 Sep 2004 12:01:50 -0500
Subject: [R] Issue with predict() for glm models 
Message-ID: <5.1.0.14.2.20040922120117.00ca1af8@imap.nd.edu>



From joehl at gmx.de  Wed Sep 22 19:32:34 2004
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Wed, 22 Sep 2004 19:32:34 +0200 (MEST)
Subject: [R] pairs, panel.functions, xlim and ylim
Message-ID: <20937.1095874354@www10.gmx.net>


Valerie,

A bit ugly, because you must ignore some warnings,
but for me works the code below.

Best


Jens Oehlschl??gel


x <- rnorm(100, sd=0.2)
x <- cbind(x=x-0.1, y=x+0.1)
pairs(x
, panel=function(x,y){
  function to be called with xlim=, ylim= parameters
	points(x, y)
	abline(0,1)
  }
)

pairs(x
, panel=function(x,y, ...)
  { # adding the three points here allows your panel function to accept the
additional xlim=, ylim= parameters
   	points(x, y)
	abline(0,1)
  }
, xlim=c(-1, 1)
, ylim=c(-1, 1)
)


> I have the following problem.
> I wanted to get a matrix of scatterplots and I used pairs.
> I wanted to add the line y=x in each plot and I created a panel 
> function for this scope.
> I used points and abline in the following way:
> 
> ## put y=x in each plot
>      panel.lin<- function(x, y)
>      {
>          points(x,y, pch=21, bg=par("bg"), col = "black",cex=2)
>          abline(0,1,lwd=2, col="red")
>      }
> 
> and it works.
> Now, I want that each plot has the same scale on the axis and I try 
> with this modification:
> 
> ## put y=x in each plot - same scale for all the plots
>      panel.lincor<- function(x, y)
>      {
>          points(x,y, pch=21, bg=par("bg"), col = 
> "black",cex=2,xlim=c(-1,1),ylim=c(-1,1))
>          abline(0,1,lwd=2, col="red")
>      }
> 
> but R tells me that xlim and ylim couldn't be set in high level plot 
> functions.
> I try to use plot() instead of points, but I realized immediately that 
> I can't use plot as a panel function.
> I know I could have added xlim and ylim directly in pairs() function, 
> if I hadn't had a panel function, but I need the line y=x in every plot 
> and I don't know other ways to get it.
> Any idea?
> Thank you very much
> Valeria Edefonti

-- 
GMX ProMail mit bestem Virenschutz http://www.gmx.net/de/go/mail
+++ Empfehlung der Redaktion +++ Internet Professionell 10/04 +++



From lisa at infinito.it  Wed Sep 22 19:47:33 2004
From: lisa at infinito.it (Lisa)
Date: Wed, 22 Sep 2004 19:47:33 +0200
Subject: [R] aparchFit()$fitted.value
Message-ID: <000b01c4a0cc$3d641c00$ba0f3152@userxwov7q21jr>

Dear R people,
I'm not able to have the component residuals, fitted.value ....from an
aparchFit() estimation as explain in the Value of aparchFit Help, package
fSeries.

Could someone help me?
Thanks in advance.
Lisa



From jrausch at nd.edu  Wed Sep 22 19:52:37 2004
From: jrausch at nd.edu (jrausch@nd.edu)
Date: Wed, 22 Sep 2004 12:52:37 -0500
Subject: [R] Issue with predict() for glm models
Message-ID: <1095875557.4151bbe59c4fe@webmail.nd.edu>


Hello everyone, 

I am having a problem using the predict (or the predict.glm) function in R.
Basically, I run the glm model on a "training" data set and try to obtain
predictions for a set of new predictors from a "test" data set (i.e., not the
predictors that were utilized to obtain the glm parameter estimates).
Unfortunately, every time that I attempt this, I obtain the predictions for the
predictors that were used to fit the glm model. I have looked at the R mailing
list archives and don't believe I am making the same mistakes that have been
made in the past and also have tried to closely follow the predict.glm example
in the help file. Here is an example of what I am trying to do: 

########################################################
set.seed(545345)

################
# Necessary Variables # 
################

p <- 2
train.n <- 20
test.n <- 25 
mean.vec.1 <- c(1,1)
mean.vec.2 <- c(0,0)

Sigma.1 <- matrix(c(1,.5,.5,1),p,p)
Sigma.2 <- matrix(c(1,.5,.5,1),p,p)

###############
# Load MASS Library #
###############

library(MASS)

###################################
# Data to Parameters for Logistic Regression Model #
###################################

train.data.1 <- mvrnorm(train.n,mu=mean.vec.1,Sigma=Sigma.1)
train.data.2 <- mvrnorm(train.n,mu=mean.vec.2,Sigma=Sigma.2)
train.class.var <- as.factor(c(rep(1,train.n),rep(2,train.n)))
predictors.train <- rbind(train.data.1,train.data.2)

##############################################
# Test Data Where Predictions for Probabilities Using Logistic Reg.  #
# From Training Data are of Interest                                          #
############################################## 

test.data.1 <- mvrnorm(test.n,mu=mean.vec.1,Sigma=Sigma.1)
test.data.2 <- mvrnorm(test.n,mu=mean.vec.2,Sigma=Sigma.2)
predictors.test <- rbind(test.data.1,test.data.2)

##############################
# Run Logistic Regression on Training Data #
##############################

log.reg <- glm(train.class.var~predictors.train,
family=binomial(link="logit"))
log.reg

#> log.reg

#Call:  glm(formula = train.class.var ~ predictors.train, family =
#binomial(link = "logit")) 
#
#Coefficients:
#      (Intercept)  predictors.train1  predictors.train2  
#           0.5105            -0.2945            -1.0811  
#
#Degrees of Freedom: 39 Total (i.e. Null);  37 Residual
#Null Deviance:      55.45 
#Residual Deviance: 41.67        AIC: 47.67 

###########################
# Predicted Probabilities for Test Data #
###########################

New.Data <- data.frame(predictors.train1=predictors.test[,1],
predictors.train2=predictors.test[,2])

logreg.pred.prob.test <- predict.glm(log.reg,New.Data,type="response")
logreg.pred.prob.test

#logreg.pred.prob.test
# [1] 0.51106406 0.15597423 0.04948404 0.03863875 0.35587589 0.71331091
# [7] 0.17320087 0.14176632 0.30966718 0.61878952 0.12525988 0.21271139
#[13] 0.70068113 0.18340723 0.10295501 0.44591568 0.72285161 0.31499339
#[19] 0.65789420 0.42750139 0.14435889 0.93008117 0.70798465 0.80109005
#[25] 0.89161472 0.47480625 0.56520952 0.63981834 0.57595189 0.60075882
#[31] 0.96493393 0.77015507 0.87643986 0.62973986 0.63043351 0.45398955
#[37] 0.80855782 0.90835588 0.54809117 0.11568637
########################################################

Of course, notice that the vector for the predicted probabilities has only 40
elements, while the "New.Data" has 50 elements (since n.test has 25 per group
for 2 groups) and thus should have 50 predicted probabilities. As it turns out,
the output is for the training data predictors and not for the "New.Data" as I
would like it to be. I should also note that I have made sure that the names
for the predictors in the "New.Data" are the same as the names for the
predictors within the glm object (i.e., within "log.reg") as this is what is
done in the example for predict.glm() within the help files. 

Could some one help me understand either what I am doing incorrectly or what
problems there might be within the predict() function? I should mention that I
tried the same program using predict.glm() and obtained the same problematic
results. 

Thanks and take care, 

Joe 


Joe Rausch, M.A. 
Psychology Liaison 
Lab for Social Research 
917 Flanner Hall 
University of Notre Dame 
Notre Dame, IN 46556
(574) 631-3910

"If we knew what it was we were doing, it would not be called research, would
it?"
- Albert Einstein



From FowlerM at mar.dfo-mpo.gc.ca  Wed Sep 22 20:17:23 2004
From: FowlerM at mar.dfo-mpo.gc.ca (Fowler, Mark)
Date: Wed, 22 Sep 2004 15:17:23 -0300
Subject: [R] Issue with predict() for glm models
Message-ID: <1A4AC4BAB9C50A42854582B69B08C03402355177@MSGMARBIO05>

Perhaps your approach reflects a method of producing a prediction dataframe
that is just unfamiliar to me, but it looks to me like you have created two
predictor variables based on the names of the levels of the original
predictor (predictors.train1, predictors.train2). I don't know how the glm
function would know that predictors.train1 and predictors.train2 are two
subs for predictors.train. Maybe try just using one prediction variable, and
give it the original variable name (predictors.train). If this works, just
repeat for your second set of values.

>	Mark Fowler
>	Marine Fish Division
>	Bedford Inst of Oceanography
>	Dept Fisheries & Oceans
>	Dartmouth NS Canada
>	fowlerm at mar.dfo-mpo.gc.ca
>


-----Original Message-----
From: jrausch at nd.edu [mailto:jrausch at nd.edu] 
Sent: September 22, 2004 2:53 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Issue with predict() for glm models



Hello everyone, 

I am having a problem using the predict (or the predict.glm) function in R.
Basically, I run the glm model on a "training" data set and try to obtain
predictions for a set of new predictors from a "test" data set (i.e., not
the predictors that were utilized to obtain the glm parameter estimates).
Unfortunately, every time that I attempt this, I obtain the predictions for
the predictors that were used to fit the glm model. I have looked at the R
mailing list archives and don't believe I am making the same mistakes that
have been made in the past and also have tried to closely follow the
predict.glm example in the help file. Here is an example of what I am trying
to do: 

########################################################
set.seed(545345)

################
# Necessary Variables # 
################

p <- 2
train.n <- 20
test.n <- 25 
mean.vec.1 <- c(1,1)
mean.vec.2 <- c(0,0)

Sigma.1 <- matrix(c(1,.5,.5,1),p,p)
Sigma.2 <- matrix(c(1,.5,.5,1),p,p)

###############
# Load MASS Library #
###############

library(MASS)

###################################
# Data to Parameters for Logistic Regression Model #
###################################

train.data.1 <- mvrnorm(train.n,mu=mean.vec.1,Sigma=Sigma.1)
train.data.2 <- mvrnorm(train.n,mu=mean.vec.2,Sigma=Sigma.2)
train.class.var <- as.factor(c(rep(1,train.n),rep(2,train.n)))
predictors.train <- rbind(train.data.1,train.data.2)

##############################################
# Test Data Where Predictions for Probabilities Using Logistic Reg.  #
# From Training Data are of Interest
#
############################################## 

test.data.1 <- mvrnorm(test.n,mu=mean.vec.1,Sigma=Sigma.1)
test.data.2 <- mvrnorm(test.n,mu=mean.vec.2,Sigma=Sigma.2)
predictors.test <- rbind(test.data.1,test.data.2)

##############################
# Run Logistic Regression on Training Data # ##############################

log.reg <- glm(train.class.var~predictors.train,
family=binomial(link="logit"))
log.reg

#> log.reg

#Call:  glm(formula = train.class.var ~ predictors.train, family =
#binomial(link = "logit")) 
#
#Coefficients:
#      (Intercept)  predictors.train1  predictors.train2  
#           0.5105            -0.2945            -1.0811  
#
#Degrees of Freedom: 39 Total (i.e. Null);  37 Residual
#Null Deviance:      55.45 
#Residual Deviance: 41.67        AIC: 47.67 

###########################
# Predicted Probabilities for Test Data # ###########################

New.Data <- data.frame(predictors.train1=predictors.test[,1],
predictors.train2=predictors.test[,2])

logreg.pred.prob.test <- predict.glm(log.reg,New.Data,type="response")
logreg.pred.prob.test

#logreg.pred.prob.test
# [1] 0.51106406 0.15597423 0.04948404 0.03863875 0.35587589 0.71331091 #
[7] 0.17320087 0.14176632 0.30966718 0.61878952 0.12525988 0.21271139 #[13]
0.70068113 0.18340723 0.10295501 0.44591568 0.72285161 0.31499339 #[19]
0.65789420 0.42750139 0.14435889 0.93008117 0.70798465 0.80109005 #[25]
0.89161472 0.47480625 0.56520952 0.63981834 0.57595189 0.60075882 #[31]
0.96493393 0.77015507 0.87643986 0.62973986 0.63043351 0.45398955 #[37]
0.80855782 0.90835588 0.54809117 0.11568637
########################################################

Of course, notice that the vector for the predicted probabilities has only
40 elements, while the "New.Data" has 50 elements (since n.test has 25 per
group for 2 groups) and thus should have 50 predicted probabilities. As it
turns out, the output is for the training data predictors and not for the
"New.Data" as I would like it to be. I should also note that I have made
sure that the names for the predictors in the "New.Data" are the same as the
names for the predictors within the glm object (i.e., within "log.reg") as
this is what is done in the example for predict.glm() within the help files.


Could some one help me understand either what I am doing incorrectly or what
problems there might be within the predict() function? I should mention that
I tried the same program using predict.glm() and obtained the same
problematic results. 

Thanks and take care, 

Joe 


Joe Rausch, M.A. 
Psychology Liaison 
Lab for Social Research 
917 Flanner Hall 
University of Notre Dame 
Notre Dame, IN 46556
(574) 631-3910

"If we knew what it was we were doing, it would not be called research,
would it?"
- Albert Einstein

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From jfox at mcmaster.ca  Wed Sep 22 22:21:26 2004
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 22 Sep 2004 16:21:26 -0400
Subject: [R] Issue with predict() for glm models
In-Reply-To: <1A4AC4BAB9C50A42854582B69B08C03402355177@MSGMARBIO05>
Message-ID: <web-65903320@cgpsrv2.cis.mcmaster.ca>

Dear Mark and Joe,

Actually, the problem here appears to be caused by the use of a matrix
on the RHS of the model formula. I'm not sure why this doesn't work (I
must be missing something -- perhaps someone else can say what), but
Joe can get the output he expects by specifying the columns of his
matrix as individual predictors in the model formula. BTW, it's better
form to call the generic predict() rather than the method predict.glm()
directly, though the latter will work here.

Editing the original input:

> x1 <- predictors.train[,1]
> x2 <- predictors.train[,2]
> 
> log.reg <- glm(train.class.var ~ x1 + x2,
+         family=binomial(link="logit"))
> log.reg

Call:  glm(formula = train.class.var ~ x1 + x2, family = binomial(link
= "logit")) 

Coefficients:
(Intercept)           x1           x2  
     0.5102      -0.6118      -0.3192  

Degrees of Freedom: 39 Total (i.e. Null);  37 Residual
Null Deviance:      55.45 
Residual Deviance: 46.49        AIC: 52.49 
> New.Data <- data.frame(x1=predictors.test[,1],
x2=predictors.test[,2])
> 
> logreg.pred.prob.test <- predict(log.reg,New.Data, type="response")
> logreg.pred.prob.test
 [1] 0.2160246 0.2706139 0.3536572 0.6206490 0.5218391 0.2363767
0.1072153
 [8] 0.6405459 0.4436666 0.6680043 0.3377492 0.5892127 0.3230353
0.7540425
[15] 0.2889855 0.5163141 0.6187335 0.1447511 0.5066670 0.4424428
0.4141701
[22] 0.3947212 0.4065674 0.6226195 0.5053101 0.4311552 0.4261810
0.4784102
[29] 0.5126050 0.6756437 0.6147516 0.7659146 0.5219031 0.3938457
0.6495470
[36] 0.5178400 0.8185613 0.7167129 0.5414552 0.8687371 0.5415976
0.8048741
[43] 0.7796451 0.5565636 0.6058371 0.7053130 0.1521769 0.7120320
0.4073465
[50] 0.6801101


I hope this helps,
 John



On Wed, 22 Sep 2004 15:17:23 -0300
 "Fowler, Mark" <FowlerM at mar.dfo-mpo.gc.ca> wrote:
> Perhaps your approach reflects a method of producing a prediction
> dataframe
> that is just unfamiliar to me, but it looks to me like you have
> created two
> predictor variables based on the names of the levels of the original
> predictor (predictors.train1, predictors.train2). I don't know how
> the glm
> function would know that predictors.train1 and predictors.train2 are
> two
> subs for predictors.train. Maybe try just using one prediction
> variable, and
> give it the original variable name (predictors.train). If this works,
> just
> repeat for your second set of values.
> 
> >	Mark Fowler
> >	Marine Fish Division
> >	Bedford Inst of Oceanography
> >	Dept Fisheries & Oceans
> >	Dartmouth NS Canada
> >	fowlerm at mar.dfo-mpo.gc.ca
> >
> 
> 
> -----Original Message-----
> From: jrausch at nd.edu [mailto:jrausch at nd.edu] 
> Sent: September 22, 2004 2:53 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Issue with predict() for glm models
> 
> 
> 
> Hello everyone, 
> 
> I am having a problem using the predict (or the predict.glm) function
> in R.
> Basically, I run the glm model on a "training" data set and try to
> obtain
> predictions for a set of new predictors from a "test" data set (i.e.,
> not
> the predictors that were utilized to obtain the glm parameter
> estimates).
> Unfortunately, every time that I attempt this, I obtain the
> predictions for
> the predictors that were used to fit the glm model. I have looked at
> the R
> mailing list archives and don't believe I am making the same mistakes
> that
> have been made in the past and also have tried to closely follow the
> predict.glm example in the help file. Here is an example of what I am
> trying
> to do: 
> 
> ########################################################
> set.seed(545345)
> 
> ################
> # Necessary Variables # 
> ################
> 
> p <- 2
> train.n <- 20
> test.n <- 25 
> mean.vec.1 <- c(1,1)
> mean.vec.2 <- c(0,0)
> 
> Sigma.1 <- matrix(c(1,.5,.5,1),p,p)
> Sigma.2 <- matrix(c(1,.5,.5,1),p,p)
> 
> ###############
> # Load MASS Library #
> ###############
> 
> library(MASS)
> 
> ###################################
> # Data to Parameters for Logistic Regression Model #
> ###################################
> 
> train.data.1 <- mvrnorm(train.n,mu=mean.vec.1,Sigma=Sigma.1)
> train.data.2 <- mvrnorm(train.n,mu=mean.vec.2,Sigma=Sigma.2)
> train.class.var <- as.factor(c(rep(1,train.n),rep(2,train.n)))
> predictors.train <- rbind(train.data.1,train.data.2)
> 
> ##############################################
> # Test Data Where Predictions for Probabilities Using Logistic Reg.
>  #
> # From Training Data are of Interest
> #
> ############################################## 
> 
> test.data.1 <- mvrnorm(test.n,mu=mean.vec.1,Sigma=Sigma.1)
> test.data.2 <- mvrnorm(test.n,mu=mean.vec.2,Sigma=Sigma.2)
> predictors.test <- rbind(test.data.1,test.data.2)
> 
> ##############################
> # Run Logistic Regression on Training Data #
> ##############################
> 
> log.reg <- glm(train.class.var~predictors.train,
> family=binomial(link="logit"))
> log.reg
> 
> #> log.reg
> 
> #Call:  glm(formula = train.class.var ~ predictors.train, family =
> #binomial(link = "logit")) 
> #
> #Coefficients:
> #      (Intercept)  predictors.train1  predictors.train2  
> #           0.5105            -0.2945            -1.0811  
> #
> #Degrees of Freedom: 39 Total (i.e. Null);  37 Residual
> #Null Deviance:      55.45 
> #Residual Deviance: 41.67        AIC: 47.67 
> 
> ###########################
> # Predicted Probabilities for Test Data # ###########################
> 
> New.Data <- data.frame(predictors.train1=predictors.test[,1],
> predictors.train2=predictors.test[,2])
> 
> logreg.pred.prob.test <-
> predict.glm(log.reg,New.Data,type="response")
> logreg.pred.prob.test
> 
> #logreg.pred.prob.test
> # [1] 0.51106406 0.15597423 0.04948404 0.03863875 0.35587589
> 0.71331091 #
> [7] 0.17320087 0.14176632 0.30966718 0.61878952 0.12525988 0.21271139
> #[13]
> 0.70068113 0.18340723 0.10295501 0.44591568 0.72285161 0.31499339
> #[19]
> 0.65789420 0.42750139 0.14435889 0.93008117 0.70798465 0.80109005
> #[25]
> 0.89161472 0.47480625 0.56520952 0.63981834 0.57595189 0.60075882
> #[31]
> 0.96493393 0.77015507 0.87643986 0.62973986 0.63043351 0.45398955
> #[37]
> 0.80855782 0.90835588 0.54809117 0.11568637
> ########################################################
> 
> Of course, notice that the vector for the predicted probabilities has
> only
> 40 elements, while the "New.Data" has 50 elements (since n.test has
> 25 per
> group for 2 groups) and thus should have 50 predicted probabilities.
> As it
> turns out, the output is for the training data predictors and not for
> the
> "New.Data" as I would like it to be. I should also note that I have
> made
> sure that the names for the predictors in the "New.Data" are the same
> as the
> names for the predictors within the glm object (i.e., within
> "log.reg") as
> this is what is done in the example for predict.glm() within the help
> files.
> 
> 
> Could some one help me understand either what I am doing incorrectly
> or what
> problems there might be within the predict() function? I should
> mention that
> I tried the same program using predict.glm() and obtained the same
> problematic results. 
> 
> Thanks and take care, 
> 
> Joe 
> 
> 
> Joe Rausch, M.A. 
> Psychology Liaison 
> Lab for Social Research 
> 917 Flanner Hall 
> University of Notre Dame 
> Notre Dame, IN 46556
> (574) 631-3910
> 
> "If we knew what it was we were doing, it would not be called
> research,
> would it?"
> - Albert Einstein
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From cliff at ms.washington.edu  Wed Sep 22 23:27:31 2004
From: cliff at ms.washington.edu (Cliff Lunneborg)
Date: Wed, 22 Sep 2004 14:27:31 -0700
Subject: [R] t-test problem
Message-ID: <007a01c4a0ea$f899b1b0$6401a8c0@C56909A>



Kan Liu wrote:

> Hello,

> I got two sets of data
> x=(124738, 128233, 85901, 33806, ...)
> y=(25292, 21877, 45498, 63973, ....)
> When I did a t test, I got two tail p-value = 0.117, which is not
significantly different.

> If I changed x, y to log scale, and re-do the t test, I got two tail
p-value = 0.042, which is
> significantly different.

> Now I got confused which one is correct. Any help would be very
appreciated.

If you are unsure about the metric of the attribute being measured, it
would be preferable to use a rank test, the Wilcoxon-Mann-Whitney,
rather than the parametric t-test.

**********************************************************
Cliff Lunneborg, Professor Emeritus, Statistics &
Psychology, University of Washington, Seattle
cliff at ms.washington.edu



From nchaudhr at usc.edu  Wed Sep 22 23:59:10 2004
From: nchaudhr at usc.edu (neha chaudhry)
Date: Wed, 22 Sep 2004 14:59:10 -0700
Subject: [R] Facing problems with C code compilation - Please help.
Message-ID: <e644b4bf12800.4151933e@usc.edu>

Hello,

I started using R a month ago - so I am a novice in this area. I am stuck with a problem and need some help urgently.
I am using windows version of R 1.9.1. I am trying to compile C code in it. I have my C code - "hello.c" is lying in C:\Program Files\R\rw1091

This code is - 

#include <R.h>
void hello(int *n)
{
  int i;
  for(i=0;i< *n; i++)
  {
     Rprintf("Hello World ! \n");
  }
}

=======
Code hello1.R is also lying in the same directory.
This code is -
hello2 <- function(n)
 {
   .C("hello", as.integer))
 }
=======

>From the command prompt, I go into the directory  C:\Program Files\R\rw1091\bin
and I do 
C:\Program Files\R\rw1091\bin>R CMD SHLIB hello.c
'make' is not recognized as an internal or external command,
operable program or batch file.

Perl is installed on my machine. I was wondering why am I getting this error. Could someone please provide me with some pointers on this? Your help will be greatly appreciated.

Thanks,
Neha



From p.murrell at auckland.ac.nz  Thu Sep 23 00:19:22 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 23 Sep 2004 10:19:22 +1200
Subject: [R] png problem
References: <5.1.0.14.0.20040921165434.02a557d0@biomserv.univ-lyon1.fr>
	<5.1.0.14.0.20040922091210.02a55618@biomserv.univ-lyon1.fr>
Message-ID: <4151FA6A.6030100@stat.auckland.ac.nz>

Hi


Cl??ment Calenge wrote:
> Hello,
> 
> Thanks for the fast reply.
> 
> Paul Murrell wrote:
> 
>> Hi
>>
>>
>> Cl??ment Calenge wrote:
>>
>>> Dear R-users,
>>> I have a small problem with the function png(), when used with the
>>> argument colortype="pseudo.cube".
>>>  > png("toto.png", colortype="pseudo.cube")
>>>  > image(matrix(rnorm(10000), 100, 100))
>>>  > dev.off()
>>> R is blocked at the last command (R does not
>>> print any prompt after the last command). Nothing is
>>> written in the file (Gimp indicates that the file is corrupted).
>>
>>
>>
>> Did you wait long enough?  This example took a little while to 
>> complete for me (may need someone more familiar with the code to tell 
>> us why it is so slow).
> 
> 
> You're right, it took 45 minutes for me.
> However, since I need to use this code to build a Sweave vignette,
> I cannot use it too often (I have about thirty files to create, this
> would take about 20 hours to build the vignette !).
> I also need the colortype argument (some graphics cards
> do not allow the compilation of the vignette without).
> Does anyone knows how to speed up the process ?


Wow!  It didn't take that long for me (maybe a minute or two).

A possibly useful observation in case anyone else takes a look at this 
before me:  when I debugged it and ctrl-C'ed to interrupt every now and 
then, the interrupt always happened inside a call to XQueryColor (in 
bitgp(), in devX11.c), so that may be the slow part.

Paul


>> Paul
>>
>>
>>> However,
>>>  > png("toto.png")
>>>  > image(matrix(rnorm(10000), 100, 100))
>>>  > dev.off()
>>> works fine.
>>> I tried:
>>>  > options(X11colortype = "pseudo.cube")
>>>  > png("toto.png")
>>>  > image(matrix(rnorm(10000), 100, 100))
>>>  > dev.off()
>>> But, here again, R is blocked. I tried to replace dev.off() by
>>> graphics.off(), but this does not resolve the problem.
>>> The problem does not occurs when the function X11() is used
>>> instead of the function png().
>>> I searched through the mail archive, the FAQ, on google,
>>> but I did not found any solution to this problem.
>>> On the help page on the function png(),
>>> it is indicated that "The colour handling will be that of the 'X11'
>>> device in use".
>>> I never used these functions before, but maybe png()
>>> is not suitable with colortype="pseudo.cube" ?
>>> Can you tell me where I have missed something ?
>>> Thanks in Advance,
>>> Cl??ment Calenge.
>>>  >version
>>>           _
>>> platform sparc-sun-solaris2.9
>>> arch     sparc
>>> os       solaris2.9
>>> system   sparc, solaris2.9
>>> status
>>> major    1
>>> minor    9.1
>>> year     2004
>>> month    06
>>> day      21
>>> language R
>>>         [[alternative HTML version deleted]]
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>
>>
>>
>> -- 
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>>
> 
> ======================================
> UMR CNRS 5558 - Equipe "Ecologie Statistique"
> Laboratoire de Biom??trie et Biologie Evolutive
> Universit?? Claude Bernard Lyon 1
> 43, Boulevard du 11 novembre 1918
> 69622 Villeurbanne Cedex
> FRANCE
> tel. (+33) 04.72.43.27.57
> fax. (+33) 04.72.43.13.88
> 


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From minhan.science at gmail.com  Thu Sep 23 00:20:28 2004
From: minhan.science at gmail.com (Min-Han Tan)
Date: Wed, 22 Sep 2004 18:20:28 -0400
Subject: [R] Cox proportional hazards model
Message-ID: <7902152a04092215207bdc28a3@mail.gmail.com>

Good afternoon,

I am currently trying to do some work on survival analysis.

- I hope to seek your advice re: 2 questions (1 general and 1 specific)

(1) I'm trying to do a stratified Cox analysis and subsequently
plot(survfit(object)). It seems to work for some strata, but not for
others.

I have tumor grade, which is a range of 1 - 4. 

When I divide this range of 1:4 into 2 groups, it works fine for
strata(grade>2) and strata(grade > 3). However, if I do a
strata(grade>1), there is an error when I do a survfit( <coxph object>
)

Call: survfit.coxph(object = s)

Error in print.survfit(structure(list(n = as.integer(46), time = c(22,  : 
        length of dimnames [1] not equal to array extent

(2) As a general question, is it possible to distinguish between
confounding and interaction in the Cox proportional hazards model?

Thanks!

Min-Han



From account-update at amazon.com  Thu Sep 23 02:03:56 2004
From: account-update at amazon.com (account-update@amazon.com)
Date: Wed, 22 Sep 2004 17:03:56 -0700
Subject: [R] Re: Your Amazon.com Inquiry
Message-ID: <i8N03u3H016703.200409230003@mail-admin-1.amazon.com>


Greetings from Amazon.com.

We're sorry. You replied to a notification-only address that cannot
accept incoming e-mail. But that's OK--this automated response will
direct you to the right place at Amazon.com to answer your question or
help you make changes to your order.

To change any unshipped orders, make other changes to your account, or
view your order history, visit:

http://www.amazon.com/your-account

For answers to questions about how to order, our shipping rates, and
how to use any of our services, visit:

http://www.amazon.com/help

We hope our online resources meet all your needs. If you've explored
the above links but find you still need to get in touch with us,
please use the e-mail form available in our online Help department.

Thanks for shopping at Amazon.com!

Sincerely,

Amazon.com Customer Service
http://www.amazon.com

P.S. You received this message because Amazon.com received
the following message:

>From r-help at lists.r-project.org  Wed Sep 22 17:03:56 2004
Received: from mail-border-1001.vdc.amazon.com (mail-border-1001.vdc.amazon.com [10.139.9.251])
	by mail-admin-1.amazon.com (8.12.7/) with ESMTP id i8N03jsQ016597
	for <account-update-autoresponse at mail-admin-1.amazon.com>; Wed, 22 Sep 2004 17:03:46 -0700
Received: from service-5-internal.amazon.com by mail-border-1001.vdc.amazon.com with SMTP 
	(crosscheck: service-5-internal.amazon.com [10.16.42.51])
	id i8N03gKb025643
	for <account-update at amazon.com>; Thu, 23 Sep 2004 00:03:43 GMT
Message-Id: <i8N03gKb025643.200409230003 at mail-border-1001.vdc.amazon.com>
X-Amazon-External-Source: yes
X-Amazon-External-Envelope-Sender: r-help at lists.r-project.org
From: r-help at lists.r-project.org
To: account-update at amazon.com
Received: from ga-cmng-cuda2-c2b-182.atlaga.adelphia.net ([68.71.182.182]) by service-5-internal.amazon.com
          via smtpd (for mail-border-1001.vdc.amazon.com [10.139.9.251]) with SMTP; 23 Sep 2004 00:03:42 UT
Subject: %]Re: Hi
Date: Wed, 22 Sep 2004 20:03:39 -0400
MIME-Version: 1.0
Content-Type: multipart/mixed;
	boundary="----=_NextPart_000_0016----=_NextPart_000_0016"
X-Priority: 3
X-MSMail-Priority: Normal
X-PMX-Version: 4.7.0.111621, Antispam-Engine: 2.0.1.0, Antispam-Data: 2004.9.22.3
X-AMAZON-GAUGE: XXXXXXXXXIIII
X-PMX-REPORT: The following antispam rules were triggered by this message:
	Rule                 Score Description
	RELAY_IN_CBL         8.000 Composite Blocking List, see http://cbl.abuseat.org/:
				   182.182.71.68.cbl.abuseat.org
	MIME_BOUND_NEXTPART  2.100 Spam tool pattern in MIME boundary
	PRIORITY_NO_NAME     0.716 Message has priority setting, but no X-Mailer
	NO_REAL_NAME         0.000 From: does not include a real name



From andy_liaw at merck.com  Thu Sep 23 02:12:18 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 22 Sep 2004 20:12:18 -0400
Subject: [R] Facing problems with C code compilation - Please help.
Message-ID: <3A822319EB35174CA3714066D590DCD504AF83FB@usrymx25.merck.com>

Read and follow the instructions in c:\Program
Files\R\rw1091\README.packages _very_, _very_ carefully.  Stray from it even
a bit and you get what you deserve.

Andy

> From: neha chaudhry
> 
> Hello,
> 
> I started using R a month ago - so I am a novice in this 
> area. I am stuck with a problem and need some help urgently.
> I am using windows version of R 1.9.1. I am trying to compile 
> C code in it. I have my C code - "hello.c" is lying in 
> C:\Program Files\R\rw1091
> 
> This code is - 
> 
> #include <R.h>
> void hello(int *n)
> {
>   int i;
>   for(i=0;i< *n; i++)
>   {
>      Rprintf("Hello World ! \n");
>   }
> }
> 
> =======
> Code hello1.R is also lying in the same directory.
> This code is -
> hello2 <- function(n)
>  {
>    .C("hello", as.integer))
>  }
> =======
> 
> >From the command prompt, I go into the directory  C:\Program 
> Files\R\rw1091\bin
> and I do 
> C:\Program Files\R\rw1091\bin>R CMD SHLIB hello.c
> 'make' is not recognized as an internal or external command,
> operable program or batch file.
> 
> Perl is installed on my machine. I was wondering why am I 
> getting this error. Could someone please provide me with some 
> pointers on this? Your help will be greatly appreciated.
> 
> Thanks,
> Neha
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From arrayprofile at yahoo.com  Thu Sep 23 02:36:09 2004
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 22 Sep 2004 17:36:09 -0700 (PDT)
Subject: [R] multinomial logistic regression
Message-ID: <20040923003609.58715.qmail@web41214.mail.yahoo.com>

Hi, how can I do multinomial logistic regression in R?
I think glm() can only handle binary response
variable, and polr() can only handle ordinal response
variable. how to do logistic regression with
multinomial response variable?

Thanks


		
__________________________________



From Kevin.Wang at maths.anu.edu.au  Thu Sep 23 02:44:35 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Thu, 23 Sep 2004 10:44:35 +1000
Subject: [R] multinomial logistic regression
In-Reply-To: <20040923003609.58715.qmail@web41214.mail.yahoo.com>
References: <20040923003609.58715.qmail@web41214.mail.yahoo.com>
Message-ID: <41521C73.6010101@maths.anu.edu.au>

array chip wrote:

> I think glm() can only handle binary response
> variable, 

That's not true, have you looked at ?glm and ?family ?

HTH,

Kevin


-- 
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From nchaudhr at usc.edu  Thu Sep 23 06:39:17 2004
From: nchaudhr at usc.edu (neha chaudhry)
Date: Wed, 22 Sep 2004 21:39:17 -0700
Subject: [R] Facing problems with C code compilation - Please help.
Message-ID: <12933ce21520b.4151f105@usc.edu>

Hi Guys,

Thanks a ton for all the help. My code is finally compiling and running.

-Neha

----- Original Message -----
From: "Liaw, Andy" <andy_liaw at merck.com>
Date: Wednesday, September 22, 2004 5:12 pm
Subject: RE: [R] Facing problems with C code compilation - Please help.

> Read and follow the instructions in c:\Program
> Files\R\rw1091\README.packages _very_, _very_ carefully.  Stray from it even
> a bit and you get what you deserve.
> 
> Andy
> 
> > From: neha chaudhry
> > 
> > Hello,
> > 
> > I started using R a month ago - so I am a novice in this 
> > area. I am stuck with a problem and need some help urgently.
> > I am using windows version of R 1.9.1. I am trying to compile 
> > C code in it. I have my C code - "hello.c" is lying in 
> > C:\Program Files\R\rw1091
> > 
> > This code is - 
> > 
> > #include <R.h>
> > void hello(int *n)
> > {
> >   int i;
> >   for(i=0;i< *n; i++)
> >   {
> >      Rprintf("Hello World ! \n");
> >   }
> > }
> > 
> > =======
> > Code hello1.R is also lying in the same directory.
> > This code is -
> > hello2 <- function(n)
> >  {
> >    .C("hello", as.integer))
> >  }
> > =======
> > 
> > >From the command prompt, I go into the directory  C:\Program 
> > Files\R\rw1091\bin
> > and I do 
> > C:\Program Files\R\rw1091\bin>R CMD SHLIB hello.c
> > 'make' is not recognized as an internal or external command,
> > operable program or batch file.
> > 
> > Perl is installed on my machine. I was wondering why am I 
> > getting this error. Could someone please provide me with some 
> > pointers on this? Your help will be greatly appreciated.
> > 
> > Thanks,
> > Neha
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 
> ---------------------------------------------------------------------------
> ---
> Notice:  This e-mail message, together with any attachments, contains 
> information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New 
> Jersey, USA 08889), and/or its affiliates (which may be known outside the 
> United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
> Banyu) that may be confidential, proprietary copyrighted and/or legally 
> privileged. It is intended solely for the use of the individual or entity 
> named on this message.  If you are not the intended recipient, and have 
> received this message in error, please notify us immediately by reply e-
> mail and then delete it from your system.
> ---------------------------------------------------------------------------
> ---
>



From jacques.veslot at cirad.fr  Thu Sep 23 07:30:31 2004
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Thu, 23 Sep 2004 09:30:31 +0400
Subject: [R] layout for xyplot
In-Reply-To: <200409221017.39498.deepayan@stat.wisc.edu>
Message-ID: <HHEDKBCGCMDOHEDELFBCKELFCCAA.jacques.veslot@cirad.fr>

thanks a lot !

My version is 1.9.1. :
         _

platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.0
year     2004
month    04
day      12
language R

and I'm working on a Windows2000 platform.

Besides I tried layout = c(1,1,4), but it doesn't work anymore (same error
message).

Please find my dataframe as attached file, and the first 6 columns summary
just below:

      x               y        bloc    sub     inoc     etat
 Min.   : 0.00   Min.   : 0.0   1:240   C:240   2:135      : 83
 1st Qu.: 3.25   1st Qu.:16.3   2:240   S:240   8:105   F  : 55
 Median : 6.00   Median :34.0                   T:240   Fi : 38
 Mean   : 6.02   Mean   :34.0                           NF :302
 3rd Qu.: 8.75   3rd Qu.:50.8                           NFi:  2
 Max.   :12.00   Max.   :68.0


Is there another means to operate better than with index.cond, by dropping
all combination of conditioning variables but one and ploting it with
layout=c(1,1).

Thanks for helping...

jacques



-----Message d'origine-----
De : Deepayan Sarkar [mailto:deepayan at stat.wisc.edu]
Envoy? : mercredi 22 septembre 2004 19:18
? : r-help at stat.math.ethz.ch; jacques.veslot at cirad.fr
Objet : Re: [R] layout for xyplot



Have you read the posting guide, which says:

<quote>
For questions about unexpected behavior or a possible bug provide
details about your platform (Windows2000, Linux, OS X) and R version
(type version at the R prompt). State the full version number, e.g.,
`1.8.1', not just `1.8'. State whether you installed a pre-compiled
binary version of R or compiled it yourself. If the function is in a
package other than `base', include the header output from
library(help=thatPackage). If you are using an old version of R and
think it does not work properly, upgrade.
</quote>

Further, we don't have access to your data, so there's no way we can
reproduce what you have done.

My guess is that you are using an old version of R and lattice, and this
bug has already been fixed. I have no idea if it would help, but have
you tried layout = c(1,1,4)?

Deepayan

On Wednesday 22 September 2004 09:32, Jacques VESLOT wrote:
> Dear all,
>
> I tried to use layout argument in xyplot to get one panel per page.
>
> I have a dataframe named 'data' with the following variables:
>
> x, y = coords,
> sub, bloc = 2-level factors,
> etat = 5-level factor,
>
> I did :
> >   lset(theme = col.whitebg())
> >   xyplot(y ~ x | bloc*sub , data=data, groups=etat,
>
> +       layout=c(0,1,4),
> +       main="Etat des plantes dans chaque bloc",
> +       auto.key=list(columns=5, cex=.8),
> +       scales=list(relation="free", draw=FALSE),
> +       xlab="", ylab="",
> +       ylim=list(c(52, 69), c(16, 33), c(35, 51), c(-1, 15)))
>
>
> and received this error message :
>
> Error in if (!any(cond.max.level - cond.current.level < 0) && (row -
> 1) *  : missing value where TRUE/FALSE needed
>
> I tried some changes in arguments - notably layout=c(0,1), but
> anything works.
>
> Thanks for helping...
>
> Jacques VESLOT
> CIRAD R?union
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-----------------------------------------------------
CIRAD Reunion - MailScanner - NO VIRUS found
-----------------------------------------------------

From ligges at statistik.uni-dortmund.de  Thu Sep 23 08:20:37 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 23 Sep 2004 08:20:37 +0200
Subject: [R] aparchFit()$fitted.value
In-Reply-To: <000b01c4a0cc$3d641c00$ba0f3152@userxwov7q21jr>
References: <000b01c4a0cc$3d641c00$ba0f3152@userxwov7q21jr>
Message-ID: <41526B35.10000@statistik.uni-dortmund.de>

Lisa wrote:

> Dear R people,
> I'm not able to have the component residuals, fitted.value ....from an
> aparchFit() estimation as explain in the Value of aparchFit Help, package
> fSeries.

OK, let's try together:

# starting with the second example on the cited help page:

  temp <- aparchFit(ts,
    order = list(alpha.lags = 1, beta.lags = c(1, 5), delta = 1),
    opt = list(gamma=FALSE, delta=FALSE, disparm=FALSE),
    doprint=FALSE)

  temp$fitted.values # Hmmm ..
NULL

  str(temp) # Ahh!

List of 13
  $ par        : num [1:4] 12.807 -1.833 -1.174 -0.687
  $ value      : num -51190
  $ counts     : Named int [1:2] 167 NA
   ..- attr(*, "names")= chr [1:2] "function" "gradient"
  $ convergence: int 0

[SNIP]

  - attr(*, "class")= chr "fAPARCH"

Obviously, this is a documentation bug. Please send bug reports re. 
contributed packages to the package maintainer!

I'm CCing to the maintainer, Diethelm Wuertz.

Uwe Ligges



> Could someone help me?
> Thanks in advance.
> Lisa
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu Sep 23 08:32:32 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 23 Sep 2004 08:32:32 +0200
Subject: [R] Issue with predict() for glm models
In-Reply-To: <1095875557.4151bbe59c4fe@webmail.nd.edu>
References: <1095875557.4151bbe59c4fe@webmail.nd.edu>
Message-ID: <41526E00.4070802@statistik.uni-dortmund.de>

jrausch at nd.edu wrote:

> Hello everyone, 
> 
> I am having a problem using the predict (or the predict.glm) function in R.
> Basically, I run the glm model on a "training" data set and try to obtain
> predictions for a set of new predictors from a "test" data set (i.e., not the
> predictors that were utilized to obtain the glm parameter estimates).
> Unfortunately, every time that I attempt this, I obtain the predictions for the
> predictors that were used to fit the glm model. I have looked at the R mailing
> list archives and don't believe I am making the same mistakes that have been
> made in the past and also have tried to closely follow the predict.glm example
> in the help file. Here is an example of what I am trying to do: 
> 
> ########################################################
> set.seed(545345)
> 
> ################
> # Necessary Variables # 
> ################
> 
> p <- 2
> train.n <- 20
> test.n <- 25 
> mean.vec.1 <- c(1,1)
> mean.vec.2 <- c(0,0)
> 
> Sigma.1 <- matrix(c(1,.5,.5,1),p,p)
> Sigma.2 <- matrix(c(1,.5,.5,1),p,p)
> 
> ###############
> # Load MASS Library #
> ###############
> 
> library(MASS)
> 
> ###################################
> # Data to Parameters for Logistic Regression Model #
> ###################################
> 
> train.data.1 <- mvrnorm(train.n,mu=mean.vec.1,Sigma=Sigma.1)
> train.data.2 <- mvrnorm(train.n,mu=mean.vec.2,Sigma=Sigma.2)
> train.class.var <- as.factor(c(rep(1,train.n),rep(2,train.n)))
> predictors.train <- rbind(train.data.1,train.data.2)
> 
> ##############################################
> # Test Data Where Predictions for Probabilities Using Logistic Reg.  #
> # From Training Data are of Interest                                          #
> ############################################## 
> 
> test.data.1 <- mvrnorm(test.n,mu=mean.vec.1,Sigma=Sigma.1)
> test.data.2 <- mvrnorm(test.n,mu=mean.vec.2,Sigma=Sigma.2)
> predictors.test <- rbind(test.data.1,test.data.2)
> 
> ##############################
> # Run Logistic Regression on Training Data #
> ##############################
> 
> log.reg <- glm(train.class.var~predictors.train,
> family=binomial(link="logit"))

Well, you haven't specified the "data" argument, but given the two 
variables directly. Exactly those variables will be used in the 
predict() step below! If you want the predict() step to work, use 
something like:

   train <- data.frame(class = train.class.var,
                       predictors = predictors.train)
   log.reg <- glm(class ~ ., data = train,
                  family=binomial(link="logit"))



> log.reg
> 
> #> log.reg
> 
> #Call:  glm(formula = train.class.var ~ predictors.train, family =
> #binomial(link = "logit")) 
> #
> #Coefficients:
> #      (Intercept)  predictors.train1  predictors.train2  
> #           0.5105            -0.2945            -1.0811  
> #
> #Degrees of Freedom: 39 Total (i.e. Null);  37 Residual
> #Null Deviance:      55.45 
> #Residual Deviance: 41.67        AIC: 47.67 
> 
> ###########################
> # Predicted Probabilities for Test Data #
> ###########################
> 
> New.Data <- data.frame(predictors.train1=predictors.test[,1],
> predictors.train2=predictors.test[,2])
> 
> logreg.pred.prob.test <- predict.glm(log.reg,New.Data,type="response")
> logreg.pred.prob.test

Instead, use:

   test <- data.frame(predictors = predictors.test)
   predict(log.reg, newdata = test, type="response")


note also: please call the generic predict() rather than its glm method.


Uwe Ligges


> #logreg.pred.prob.test
> # [1] 0.51106406 0.15597423 0.04948404 0.03863875 0.35587589 0.71331091
> # [7] 0.17320087 0.14176632 0.30966718 0.61878952 0.12525988 0.21271139
> #[13] 0.70068113 0.18340723 0.10295501 0.44591568 0.72285161 0.31499339
> #[19] 0.65789420 0.42750139 0.14435889 0.93008117 0.70798465 0.80109005
> #[25] 0.89161472 0.47480625 0.56520952 0.63981834 0.57595189 0.60075882
> #[31] 0.96493393 0.77015507 0.87643986 0.62973986 0.63043351 0.45398955
> #[37] 0.80855782 0.90835588 0.54809117 0.11568637
> ########################################################
> 
> Of course, notice that the vector for the predicted probabilities has only 40
> elements, while the "New.Data" has 50 elements (since n.test has 25 per group
> for 2 groups) and thus should have 50 predicted probabilities. As it turns out,
> the output is for the training data predictors and not for the "New.Data" as I
> would like it to be. I should also note that I have made sure that the names
> for the predictors in the "New.Data" are the same as the names for the
> predictors within the glm object (i.e., within "log.reg") as this is what is
> done in the example for predict.glm() within the help files. 
> 
> Could some one help me understand either what I am doing incorrectly or what
> problems there might be within the predict() function? I should mention that I
> tried the same program using predict.glm() and obtained the same problematic
> results. 
> 
> Thanks and take care, 
> 
> Joe 
> 
> 
> Joe Rausch, M.A. 
> Psychology Liaison 
> Lab for Social Research 
> 917 Flanner Hall 
> University of Notre Dame 
> Notre Dame, IN 46556
> (574) 631-3910
> 
> "If we knew what it was we were doing, it would not be called research, would
> it?"
> - Albert Einstein
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Thu Sep 23 08:43:47 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 23 Sep 2004 08:43:47 +0200
Subject: [R] Facing problems with C code compilation - Please help.
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF83FB@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF83FB@usrymx25.merck.com>
Message-ID: <x2d60dqycc.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> Read and follow the instructions in c:\Program
> Files\R\rw1091\README.packages _very_, _very_ carefully.  Stray from it even
> a bit and you get what you deserve.

Well, not what you want, anyway... (In this case, the first problem
seems to be that you need make.exe from the toolkit *and* to have it
in your path.)
 
> Andy
> 
> > From: neha chaudhry
> > 
> > Hello,
> > 
> > I started using R a month ago - so I am a novice in this 
> > area. I am stuck with a problem and need some help urgently.
> > I am using windows version of R 1.9.1. I am trying to compile 
> > C code in it. I have my C code - "hello.c" is lying in 
> > C:\Program Files\R\rw1091
> > 
> > This code is - 
> > 
> > #include <R.h>
> > void hello(int *n)
> > {
> >   int i;
> >   for(i=0;i< *n; i++)
> >   {
> >      Rprintf("Hello World ! \n");
> >   }
> > }
> > 
> > =======
> > Code hello1.R is also lying in the same directory.
> > This code is -
> > hello2 <- function(n)
> >  {
> >    .C("hello", as.integer))

Make that as.integer(n) or things will surely come crashing down...

> >  }

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From rdiaz at cnio.es  Thu Sep 23 10:27:23 2004
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Thu, 23 Sep 2004 10:27:23 +0200
Subject: [R] t test problem?
In-Reply-To: <XFMail.040922120707.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.040922120707.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <200409231027.23317.rdiaz@cnio.es>

On Wednesday 22 September 2004 13:07, Ted Harding wrote:
> On 22-Sep-04 kan Liu wrote:
> > Hi, Many thanks for your helpful comments and suggestions. The attached
> > are the data in both log10 scale and original scale. It would be very
> > grateful if you could suggest which version of test should be used.
> >
> > By the way, how to check whether the variation is additive (natural
> > scale) or multiplicative (log scale) in R? How to check whether the
> > distribution of the data is normal?
>
> As for additive vs multiplicative, this can only be judged in terms
> of the process by which the values are created in the real world.


Just my 2 cents: I often find it helpful to ask myself (or the "client") 
whether, if there was a difference ("something") between the two samples, 
I/she/he thinks the appropriate model is (please, read the "=" as "approx. 
equal")

sample.1 = sample.2 + something [1]

OR

sample.1 = sample.2 * something [2]

(i.e., the ratio of means is a constant: sample.1/sample.2 = something)

which, by log transforming becomes

log(sample.1) = log(sample.2) + log(something)

I am not including here the issue of error distribution, but often times when 
the model for the means is like [2] the error terms are multiplicative (i.e., 
additive in the log scale). At least in many biological and engineering 
problems it is often evident whether [1] or [2] should be appropriate for the 
data, given what we know about the subject.

Best,

R.

> As for normality vs non-normality, an appraisal can often be made
> simply by looking at a histogram of the data.
>
> In your case, the commands
>   hist(x,breaks=10000*(0:100))
>   hist(y,breaks=10000*(0:100))
> indicate that the distributions of x and y do not look at all
> "normal", since they both have considerable positive skewness
> (i.e. long upper tails relative to the main mass of the distribution).
>
> This does strongly suggest that a logarithmic transformation would
> give data which are more nearly normally distributed, as indeed
> is confirmed by the commands
>   hist(log(x))
>   hist(log(y))
> though in both cases the histograms show some irregularity compared
> with what you would expect from a sample from a normal distribution:
> the commands
>   hist(log(x),breaks=0.2*(40:80))
>   hist(log(y),breaks=0.2*(40:80))
> show that log(x) has an excessive peak at around 11.7,
> while log(y) has holes at around 11.1 and 12.1.
>
> Nevertheless, this inspection of the data shows that the use of
> log(x) and log(y) will come much closer to fulfilling the conditions
> of validity of the t test than using the raw data x and y.
>
> However, it is not merely the *normality* of each which is needed:
> the conditions for the usual t test also require that the two
> populations sampled for log(x) and log(y) should have the same
> standard deviations. In your case, this also turns out to be
>
> nearly enough true:
>   > sd(log(x))
>
>   [1] 0.902579
>
>   > sd(log(y))
>
>   [1] 0.9314807
>
> > PS, Can I confirm that do your suggestions mean that in order to check
> > whether there is a difference between x and y in terms of mean I need
> > check the distribution of x and that of y in both natual and log scales
> > and to see which present normal distribution?
>
> See above for an approach to this: the answer to your question is,
> in effect, "yes". It could of course have happened that neither the
> raw nor the log scale would be satisfactory, in which case you would
> need to consider other possibilities. And, if the SDs had turned out
> to be very different, you should not use the standard t test but
> a variant which is adpated to the situation (e.g. the Welch test).
>
> You can, of course, also perform formal tests for skewness, for
> normality, and for equality of variances.
>
> Best wishes,
> Ted.
>
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861   [NB: New number!]
> Date: 22-Sep-04                                       Time: 12:07:07
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Ram??n D??az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol??gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern??ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)



From rn001 at cebas.csic.es  Fri Sep 24 11:12:30 2004
From: rn001 at cebas.csic.es (javier garcia - CEBAS)
Date: Fri, 24 Sep 2004 11:12:30 +0200
Subject: [R] Best device for printing quality
Message-ID: <20040923091035.BE816A7AC7@cebas.csic.es>

Hi all;
Just to ask you for your advise about what is the best way to get the best 
quality for graphics to be incorporated into a printed article

(I'm mainly a Linux useR, but also use the windows R version)

Thanks and best regards,

Javier Garcia



From wolski at molgen.mpg.de  Thu Sep 23 11:23:21 2004
From: wolski at molgen.mpg.de (Wolski)
Date: Thu, 23 Sep 2004 11:23:21 +0200
Subject: [R] Best device for printing quality
In-Reply-To: <20040923091035.BE816A7AC7@cebas.csic.es>
References: <20040923091035.BE816A7AC7@cebas.csic.es>
Message-ID: <200409231123210872.036257D4@mail.math.fu-berlin.de>

Hi!

I would first check what kind of graphic format the article publisher of the article accepts.

If ps/pdf is ok I would use ?postscript. Otherwise I would change the journal.

/E

*********** REPLY SEPARATOR  ***********

On 9/24/2004 at 11:12 AM javier garcia - CEBAS wrote:

>>>Hi all;
>>>Just to ask you for your advise about what is the best way to get the
>>>best 
>>>quality for graphics to be incorporated into a printed article
>>>
>>>(I'm mainly a Linux useR, but also use the windows R version)
>>>
>>>Thanks and best regards,
>>>
>>>Javier Garcia
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



Dipl. bio-chem. Witold Eryk Wolski             @         MPI-Moleculare Genetic   
Ihnestrasse 63-73 14195 Berlin                'v'    
tel: 0049-30-83875219                        /   \       
mail: witek96 at users.sourceforge.net        ---W-W----    http://www.molgen.mpg.de/~wolski 
      wolski at molgen.mpg.de



From lisa at infinito.it  Thu Sep 23 12:13:12 2004
From: lisa at infinito.it (Lisa)
Date: Thu, 23 Sep 2004 12:13:12 +0200
Subject: [R] aparchFit()$fitted.value
Message-ID: <000001c4a155$efb69930$bb0f3152@userxwov7q21jr>

...unfortunately I was suspicious of this.
Could You give me some insight to obtain that values?

Thanks a lot!
Lisa



From ggrothendieck at myway.com  Thu Sep 23 12:56:05 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 23 Sep 2004 10:56:05 +0000 (UTC)
Subject: [R] block statistics with POSIX classes
References: <C9FC71F7E9356F40AFE2ACC2099DE1471496B4@MAILSERVER-B.mpsgr.it>
Message-ID: <loom.20040923T124253-799@post.gmane.org>

Kahra Hannu <kahra <at> mpsgr.it> writes:

: 
: I have a monthly price index series x, the related return series y = diff(log
(x)) and a POSIXlt date-time
: variable dp. I would like to apply annual blocks to compute for example 
annual block maxima and mean of y.
: 
: When studying the POSIX classes, in the first stage of the learning curve, I 
computed the maximum drawdown
: of x:
: > mdd <- maxdrawdown(x)
: > max.dd <- mdd$maxdrawdown
: > from <- as.character(dp[mdd$from]) 
: > to <- as.character(dp[mdd$to])                       
: > from; to
: [1] "2000-08-31"
: [1] "2003-03-31"
: that gives me the POSIX dates of the start and end of the period and 
suggests that I have done something correctly.
: 
: Two questions:
: (1) how to implement annual blocks and compute e.g. annual max, min and mean 
of y (each year's max, min, mean)?
: (2) how to apply POSIX variables with the 'block' argument in gev in the 
evir package?
: 
: The S+FinMetrics function aggregateSeries does the job in that module; but I 
do not know, how handle it in R.
: My guess is that (1) is done by using the function aggregate, but how to 
define the 'by' argument with POSIX variables?


1. To create a ts monthly time series you specify the first month
and a frequency of 12 like this.  

z.m <- ts(rep(1:6,4), start = c(2000,1), freq = 12)
z.m

# Annual aggregate is done using aggregate.ts with nfreq = 1
z.y <- aggregate(z.m, nfreq = 1, max)
z.y

# To create a POSIXct series of times using seq
# (This will use GMT.  Use tz="" arg to ISOdate if you want current tz.)
z.y.times <- seq(ISOdate(2000,1,1), length = length(z.y), by = "year")
z.y.times

2. Have not used evir but looking at ?gev it seems you can
use block = 12 if you have monthly data and want the blocks to be 
successive 12 month periods or you can add a POSIXct times attribute to 
your data as below (also see comment re tz above) and then use 
block = "year" in your gev call.

attr(z.m, "times") <- seq(ISOdate(2000,1,1), length=length(z.m), by="month")
str(z.m)  # display z.m along with attribute info



From d.firth at warwick.ac.uk  Thu Sep 23 13:37:35 2004
From: d.firth at warwick.ac.uk (David Firth)
Date: Thu, 23 Sep 2004 12:37:35 +0100
Subject: [R] multinomial logistic regression
In-Reply-To: <20040923003609.58715.qmail@web41214.mail.yahoo.com>
References: <20040923003609.58715.qmail@web41214.mail.yahoo.com>
Message-ID: <F6FE7171-0D54-11D9-98F7-0050E4C03977@warwick.ac.uk>

On 23 Sep 2004, at 01:36, array chip wrote:

> Hi, how can I do multinomial logistic regression in R?
> I think glm() can only handle binary response
> variable, and polr() can only handle ordinal response
> variable. how to do logistic regression with
> multinomial response variable?

Perhaps multinom() in package nnet (in bundle VR) will do what you want?

Regards,
David

>
> Thanks
>
>
> 		
> __________________________________
>

> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From christoph.lehmann at gmx.ch  Thu Sep 23 13:37:20 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Thu, 23 Sep 2004 13:37:20 +0200
Subject: [R] nnet with weights parameter: odd error
Message-ID: <4152B570.4000308@gmx.ch>

Dear R-users

I use nnet for a classification (2 classes) problem. I use the code 
CVnn1, CVnn2 as described in  V&R.

The thing I changed to the code is: I define the (class) weight for each 
observation in each cv 'bag' and give the vector of weights as parameter 
of nnet(..weights = weight.vector...)

Unfortunately I get an error during some (but not all!) inner-fold cv runs:

	Error in model.frame(formula, rownames, variables, varnames, 	
	extras, extranames,  :
         	variable lengths differ

If you just remove the weights parameter in nnet() it runs fine!!

I debugged the code but could not resolve the problem- it is really very 
strange and I need your help! I tried it very simple in defining the 
weights as = 1 for each obs (as it is by default)!:


CVnn2 <- function(formula, data,
                   size = c(0,4,4,10,10), lambda = c(0, rep(c(0.001, 
0.01),2)),
                   nreps = 1, nifold = 5, verbose = 99, ...)
{
     resmatrix <- function(predict.matrix, learn, data, ri, i)
     {
        rae.matrix <-   predict.matrix
        rae.matrix[,] <- 0
        rae.vector <- as.numeric(as.factor((predict(learn, data[ri == i,],
                                                    type = "class"))))
        for (k in 1:dim(rae.matrix)[1]) {
          if (rae.vector[k] == 1)
              rae.matrix[k,1] <- rae.matrix[k,1] + 1
          else
              rae.matrix[k,2] <- rae.matrix[k,2] + 1
        }
        rae.matrix
     }


     CVnn1 <- function(formula, data, nreps=1, ri, verbose,  ...)
     {
         totalerror <- 0
         truth <- data[,deparse(formula[[2]])]
         res <-  matrix(0, nrow(data), length(levels(truth)))
         if(verbose > 20) cat("  inner fold")
         for (i in sort(unique(ri))) {
             if(verbose > 20) cat(" ", i,  sep="")
             data.training <- data[ri != i,]$GROUP

             weight.vector <- rep(1, dim(data[ri !=i,])[1])

             for(rep in 1:nreps) {
                 learn <- nnet(formula, data[ri !=i,],
                               weights = weight.vector,
                               trace = F, ...)
                 #res[ri == i,] <- res[ri == i,] + predict(learn, 
data[ri == i,])
                 res[ri == i,] <- res[ri == i,] + resmatrix(res[ri == i,],
                                                            learn, data, 
ri, i)
             }
         }
         if(verbose > 20) cat("\n")
         sum(as.numeric(truth) != max.col(res/nreps))
     }
     truth <- data[,deparse(formula[[2]])]
     res <-  matrix(0, nrow(data), length(levels(truth)))
     choice <- numeric(length(lambda))
     for (i in sort(unique(rand))) {
         if(verbose > 0) cat("fold ", i,"\n", sep="")
         set.seed(i*i)
         ri <- sample(nifold, sum(rand!=i), replace=T)
         for(j in seq(along=lambda)) {
             if(verbose > 10)
                 cat("  size =", size[j], "decay =", lambda[j], "\n")
             choice[j] <- CVnn1(formula, data[rand != i,], nreps=nreps,
                                ri=ri, size=size[j], decay=lambda[j],
                                verbose=verbose, ...)
         }
         decay <- lambda[which.is.max(-choice)]
         csize <- size[which.is.max(-choice)]
         if(verbose > 5) cat("  #errors:", choice, "  ") #
         if(verbose > 1) cat("chosen size = ", csize,
                             " decay = ", decay, "\n", sep="")
         for(rep in 1:nreps) {
             data.training <- data[rand != i,]$GROUP
             weight.vector <- rep(1, dim(data[rand !=i,])[1])
             learn <- nnet(formula, data[rand != i,],
                       weights = weight.vector,
                       trace=F,
                       size=csize, decay=decay, ...)
             #res[rand == i,] <- res[rand == i,] + predict(learn, 
data[rand == i,])
             res[rand == i,] <- res[rand == i,] + resmatrix(res[rand == 
i,],learn,data, rand, i)
         }
     }
     factor(levels(truth)[max.col(res/nreps)], levels = levels(truth))
}



res.nn2 <- CVnn2(GROUP ~ ., rae.data.subsetted1, skip = T, maxit = 500,
                  nreps = cv.repeat)
con(true = rae.data.subsetted$GROUP, predicted = res.nn2)



###


Coordinates:
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    9.1
year     2004
month    06
day      21
language R


########

Thanks a lot

Best regards

Christoph
-- 
Christoph Lehmann                            Phone:  ++41 31 930 93 83
Department of Psychiatric Neurophysiology    Mobile: ++41 76 570 28 00
University Hospital of Clinical Psychiatry   Fax:    ++41 31 930 99 61
Waldau                                            lehmann at puk.unibe.ch
CH-3000 Bern 60         http://www.puk.unibe.ch/cl/pn_ni_cv_cl_03.html



From pierre.bady at univ-lyon1.fr  Thu Sep 23 14:16:47 2004
From: pierre.bady at univ-lyon1.fr (Pierre BADY)
Date: Thu, 23 Sep 2004 14:16:47 +0200
Subject: [R] multinomial logistic regression
In-Reply-To: <20040923003609.58715.qmail@web41214.mail.yahoo.com>
Message-ID: <5.1.0.14.2.20040923140038.00bba9e0@pop.univ-lyon1.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040923/d78ce4aa/attachment.pl

From kjetil at acelerate.com  Thu Sep 23 14:15:47 2004
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Thu, 23 Sep 2004 08:15:47 -0400
Subject: [R] ordered probit and cauchit
In-Reply-To: <1AB257FA-0C41-11D9-B246-000393A361A2@ysidro.econ.uiuc.edu>
References: <1AB257FA-0C41-11D9-B246-000393A361A2@ysidro.econ.uiuc.edu>
Message-ID: <4152BE73.3020701@acelerate.com>

roger koenker wrote:

> What is the current state of the R-art for ordered probit models, and 
> more
> esoterically is there any available R strategy for ordered cauchit 
> models,
> i.e. ordered multinomial alternatives with a cauchy link function.  MCMC
> is an option, obviously, but for a univariate latent variable model 
> this seems
> to be overkill... standard mle methods should be preferable.  (??)
>
> Googling reveals that spss provides such functions... just to wave a red
> flag.
>
I find
polr(MASS)                 Ordered Logistic or Probit Regression
MCMCoprobit(MCMCpack)      Markov chain Monte Carlo for Ordered Probit
                           Regression
and in Jim Lindsey's gnlm  there is
nordr           Nonlinear Ordinal Regression
ordglm          Generalized Linear Ordinal Regression

Kjetil

-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra



From v_bill_pikounis at merck.com  Thu Sep 23 14:22:57 2004
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Thu, 23 Sep 2004 08:22:57 -0400
Subject: [R] FYI: DeveloperWorks News article on R
Message-ID: <CFBD404F5E0C9547B4E10B7BDC3DFA2F041565DF@usrymx18.merck.com>


First of a 3 part series, apparently:

http://www-106.ibm.com/developerworks/linux/library/l-r1/?ca=dgr-lnxw02aAre
<http://www-106.ibm.com/developerworks/linux/library/l-r1/?ca=dgr-lnxw02aAre
> 

(Apologies if someone has already posted this link to R-help)

Best Regards,
Bill

----------------------------------------
Bill Pikounis, Ph.D.

Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY33-300  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

Phone: 732 594 3913
Fax: 732 594 1565



From v_bill_pikounis at merck.com  Thu Sep 23 14:43:17 2004
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Thu, 23 Sep 2004 08:43:17 -0400
Subject: [R] [Job Ad] Position at Merck Research Laboratories, NJ USA
Message-ID: <CFBD404F5E0C9547B4E10B7BDC3DFA2F041565E1@usrymx18.merck.com>

Please direct *all* inquiries to Vladimir Svetnik, the hiring manager. His
contact information is below.

(Also, please accept my apologies, for cross-posting to those subscribed to
both R-help and S-news, and for any offense since this is a repost I made of
the same position month ago. That short time spacing will not be repeated.)

Thanks,
Bill

################################################################

Job description:  Computational statistician/biometrician   

The Biometrics Research Department at Merck Research Laboratories, Merck &
Co., Inc. in Rahway, NJ, is seeking a highly motivated statistician/data
analyst to work in its basic research and drug discovery area.  The
applicant should have broad expertise in statistical computing.   Experience
and/or education relevant to signal processing, image processing, pattern
recognition and machine learning are preferred.  The position will involve
providing statistical, mathematical, and software development support for
one or more of following areas: medical imaging, biological signal analysis,
and computational chemistry.   We are looking for a Ph.D. with a background
and/or post-doctoral experience in at least one of the following fields:
Statistics, Electrical/Computer or Biomedical Engineering, Computer Science,
Applied Mathematics, or Physics.   Advanced computer programming skills
(including, but not limited to R, S-PLUS, Matlab, C/C++) and excellent
communication skills are essential. An ability to lead statistical analysis
efforts within a multidisciplinary team is required.   The position may also
involve general statistical consulting and training.

Our dedication to delivering quality medicines in innovative ways and our
commitment to bringing out the best in our people are just some of the
reasons why we're ranked among Fortune magazine's "100 Best Companies to
Work for in America."  We offer a competitive salary, an outstanding
benefits package, and a professional work environment with a company known
for scientific excellence.  To apply, please forward your CV or resume and
cover letter to

ATTENTION: Open Position  
Vladimir Svetnik, Ph.D.  
Biometrics Research Dept.  
Merck Research Laboratories
RY33-300
126 E. Lincoln Avenue
Rahway, NJ 07065-0900 
vladimir_svetnik at merck.com



From jfox at mcmaster.ca  Thu Sep 23 14:49:23 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 23 Sep 2004 08:49:23 -0400
Subject: [R] Issue with predict() for glm models
In-Reply-To: <41526E00.4070802@statistik.uni-dortmund.de>
Message-ID: <20040923124921.CMLX7925.tomts25-srv.bellnexxia.net@JohnDesktop8300>

Dear Uwe,

Unless I've somehow messed this up, as I mentioned yesterday, what you
suggest doesn't seem to work when the predictor is a matrix. Here's a
simplified example:

> X <- matrix(rnorm(200), 100, 2)
> y <- (X %*% c(1,2) + rnorm(100)) > 0
> dat <- data.frame(y=y, X=X)
> mod <- glm(y ~ X, family=binomial, data=dat)
> new <- data.frame(X = matrix(rnorm(20),2))
> predict(mod, new)
           1            2            3            4            5
6 
  1.81224443  -5.92955128   1.98718051 -10.05331521   2.65065555
-2.50635812 
           7            8            9           10           11
12 
  5.63728698  -0.94845276  -3.61657377  -1.63141320   5.03417372
1.80400271 
          13           14           15           16           17
18 
  9.32876273  -5.32723406   5.29373023  -3.90822713 -10.95065186
4.90038016 

 . . .

           97           98           99          100 
 -6.92509812   0.59357486  -1.17205723   0.04209578 


Note that there are 100 rather than 10 predicted values.

But with individuals predictors (rather than a matrix),

> x1 <- X[,1]
> x2 <- X[,2]
> dat.2 <- data.frame(y=y, x1=x1, x2=x2)
> mod.2 <- glm(y ~ x1 + x2, family=binomial, data=dat.2)
> new.2 <- data.frame(x1=rnorm(10), x2=rnorm(10))
> predict(mod.2, new.2)
         1          2          3          4          5          6          7

 6.5723823  0.6356392  4.0291018 -4.7914650  2.1435485 -3.1738096 -2.8261585

         8          9         10 
-1.5255329 -4.7087592  4.0619290 

works as expected (?).

Regards,
 John
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Uwe Ligges
> Sent: Thursday, September 23, 2004 1:33 AM
> To: jrausch at nd.edu
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Issue with predict() for glm models
> 
> jrausch at nd.edu wrote:
> 
> > Hello everyone,
> > 
> > I am having a problem using the predict (or the 
> predict.glm) function in R.
> > Basically, I run the glm model on a "training" data set and try to 
> > obtain predictions for a set of new predictors from a 
> "test" data set 
> > (i.e., not the predictors that were utilized to obtain the 
> glm parameter estimates).
> > Unfortunately, every time that I attempt this, I obtain the 
> > predictions for the predictors that were used to fit the 
> glm model. I 
> > have looked at the R mailing list archives and don't believe I am 
> > making the same mistakes that have been made in the past 
> and also have 
> > tried to closely follow the predict.glm example in the help 
> file. Here is an example of what I am trying to do:
> > 
> > ########################################################
> > set.seed(545345)
> > 
> > ################
> > # Necessary Variables #
> > ################
> > 
> > p <- 2
> > train.n <- 20
> > test.n <- 25
> > mean.vec.1 <- c(1,1)
> > mean.vec.2 <- c(0,0)
> > 
> > Sigma.1 <- matrix(c(1,.5,.5,1),p,p)
> > Sigma.2 <- matrix(c(1,.5,.5,1),p,p)
> > 
> > ###############
> > # Load MASS Library #
> > ###############
> > 
> > library(MASS)
> > 
> > ###################################
> > # Data to Parameters for Logistic Regression Model # 
> > ###################################
> > 
> > train.data.1 <- mvrnorm(train.n,mu=mean.vec.1,Sigma=Sigma.1)
> > train.data.2 <- mvrnorm(train.n,mu=mean.vec.2,Sigma=Sigma.2)
> > train.class.var <- as.factor(c(rep(1,train.n),rep(2,train.n)))
> > predictors.train <- rbind(train.data.1,train.data.2)
> > 
> > ##############################################
> > # Test Data Where Predictions for Probabilities Using 
> Logistic Reg.  #
> > # From Training Data are of Interest                        
>                   #
> > ##############################################
> > 
> > test.data.1 <- mvrnorm(test.n,mu=mean.vec.1,Sigma=Sigma.1)
> > test.data.2 <- mvrnorm(test.n,mu=mean.vec.2,Sigma=Sigma.2)
> > predictors.test <- rbind(test.data.1,test.data.2)
> > 
> > ##############################
> > # Run Logistic Regression on Training Data # 
> > ##############################
> > 
> > log.reg <- glm(train.class.var~predictors.train,
> > family=binomial(link="logit"))
> 
> Well, you haven't specified the "data" argument, but given 
> the two variables directly. Exactly those variables will be 
> used in the
> predict() step below! If you want the predict() step to work, 
> use something like:
> 
>    train <- data.frame(class = train.class.var,
>                        predictors = predictors.train)
>    log.reg <- glm(class ~ ., data = train,
>                   family=binomial(link="logit"))
> 
> 
> 
> > log.reg
> > 
> > #> log.reg
> > 
> > #Call:  glm(formula = train.class.var ~ predictors.train, family = 
> > #binomial(link = "logit")) #
> > #Coefficients:
> > #      (Intercept)  predictors.train1  predictors.train2  
> > #           0.5105            -0.2945            -1.0811  
> > #
> > #Degrees of Freedom: 39 Total (i.e. Null);  37 Residual
> > #Null Deviance:      55.45 
> > #Residual Deviance: 41.67        AIC: 47.67 
> > 
> > ###########################
> > # Predicted Probabilities for Test Data # 
> ###########################
> > 
> > New.Data <- data.frame(predictors.train1=predictors.test[,1],
> > predictors.train2=predictors.test[,2])
> > 
> > logreg.pred.prob.test <- 
> predict.glm(log.reg,New.Data,type="response")
> > logreg.pred.prob.test
> 
> Instead, use:
> 
>    test <- data.frame(predictors = predictors.test)
>    predict(log.reg, newdata = test, type="response")
> 
> 
> note also: please call the generic predict() rather than its 
> glm method.
> 
> 
> Uwe Ligges
> 
> 
> > #logreg.pred.prob.test
> > # [1] 0.51106406 0.15597423 0.04948404 0.03863875 0.35587589 
> > 0.71331091 # [7] 0.17320087 0.14176632 0.30966718 0.61878952 
> > 0.12525988 0.21271139 #[13] 0.70068113 0.18340723 0.10295501 
> > 0.44591568 0.72285161 0.31499339 #[19] 0.65789420 0.42750139 
> > 0.14435889 0.93008117 0.70798465 0.80109005 #[25] 0.89161472 
> > 0.47480625 0.56520952 0.63981834 0.57595189 0.60075882 #[31] 
> > 0.96493393 0.77015507 0.87643986 0.62973986 0.63043351 0.45398955 
> > #[37] 0.80855782 0.90835588 0.54809117 0.11568637 
> > ########################################################
> > 
> > Of course, notice that the vector for the predicted 
> probabilities has 
> > only 40 elements, while the "New.Data" has 50 elements 
> (since n.test 
> > has 25 per group for 2 groups) and thus should have 50 predicted 
> > probabilities. As it turns out, the output is for the training data 
> > predictors and not for the "New.Data" as I would like it to be. I 
> > should also note that I have made sure that the names for the 
> > predictors in the "New.Data" are the same as the names for the 
> > predictors within the glm object (i.e., within "log.reg") 
> as this is what is done in the example for predict.glm() 
> within the help files.
> > 
> > Could some one help me understand either what I am doing 
> incorrectly 
> > or what problems there might be within the predict() function? I 
> > should mention that I tried the same program using 
> predict.glm() and 
> > obtained the same problematic results.
> > 
> > Thanks and take care,
> > 
> > Joe
> > 
> > 
> > Joe Rausch, M.A. 
> > Psychology Liaison
> > Lab for Social Research
> > 917 Flanner Hall
> > University of Notre Dame
> > Notre Dame, IN 46556
> > (574) 631-3910
> > 
> > "If we knew what it was we were doing, it would not be called 
> > research, would it?"
> > - Albert Einstein
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From kahra at mpsgr.it  Thu Sep 23 15:04:48 2004
From: kahra at mpsgr.it (Kahra Hannu)
Date: Thu, 23 Sep 2004 15:04:48 +0200
Subject: [R] block statistics with POSIX classes
Message-ID: <C9FC71F7E9356F40AFE2ACC2099DE1471496B7@MAILSERVER-B.mpsgr.it>

Thank you Petr and Gabor for the answers.

They did not, however, solve my original problem. When I have a monthly time series y with a POSIX date variable dp, the most obvious way to compute e.g. the annual means is to use aggregate(y, 1, mean) that works with time series. However, I got stuck with the idea of using the 'by' argument as by = dp$year. But in that case y has to be a data.frame. The easiest way must be the best way.

Regards,
Hannu 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Gabor Grothendieck
Sent: Thursday, September 23, 2004 12:56 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] block statistics with POSIX classes


Kahra Hannu <kahra <at> mpsgr.it> writes:

: 
: I have a monthly price index series x, the related return series y = diff(log
(x)) and a POSIXlt date-time
: variable dp. I would like to apply annual blocks to compute for example 
annual block maxima and mean of y.
: 
: When studying the POSIX classes, in the first stage of the learning curve, I 
computed the maximum drawdown
: of x:
: > mdd <- maxdrawdown(x)
: > max.dd <- mdd$maxdrawdown
: > from <- as.character(dp[mdd$from]) 
: > to <- as.character(dp[mdd$to])                       
: > from; to
: [1] "2000-08-31"
: [1] "2003-03-31"
: that gives me the POSIX dates of the start and end of the period and 
suggests that I have done something correctly.
: 
: Two questions:
: (1) how to implement annual blocks and compute e.g. annual max, min and mean 
of y (each year's max, min, mean)?
: (2) how to apply POSIX variables with the 'block' argument in gev in the 
evir package?
: 
: The S+FinMetrics function aggregateSeries does the job in that module; but I 
do not know, how handle it in R.
: My guess is that (1) is done by using the function aggregate, but how to 
define the 'by' argument with POSIX variables?


1. To create a ts monthly time series you specify the first month
and a frequency of 12 like this.  

z.m <- ts(rep(1:6,4), start = c(2000,1), freq = 12)
z.m

# Annual aggregate is done using aggregate.ts with nfreq = 1
z.y <- aggregate(z.m, nfreq = 1, max)
z.y

# To create a POSIXct series of times using seq
# (This will use GMT.  Use tz="" arg to ISOdate if you want current tz.)
z.y.times <- seq(ISOdate(2000,1,1), length = length(z.y), by = "year")
z.y.times

2. Have not used evir but looking at ?gev it seems you can
use block = 12 if you have monthly data and want the blocks to be 
successive 12 month periods or you can add a POSIXct times attribute to 
your data as below (also see comment re tz above) and then use 
block = "year" in your gev call.

attr(z.m, "times") <- seq(ISOdate(2000,1,1), length=length(z.m), by="month")
str(z.m)  # display z.m along with attribute info

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu Sep 23 15:06:06 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 23 Sep 2004 15:06:06 +0200
Subject: [R] Issue with predict() for glm models
In-Reply-To: <20040923124921.CMLX7925.tomts25-srv.bellnexxia.net@JohnDesktop8300>
References: <20040923124921.CMLX7925.tomts25-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <4152CA3E.7040009@statistik.uni-dortmund.de>

John Fox wrote:

> Dear Uwe,
> 
> Unless I've somehow messed this up, as I mentioned yesterday, what you
> suggest doesn't seem to work when the predictor is a matrix. Here's a
> simplified example:
> 
> 
>>X <- matrix(rnorm(200), 100, 2)
>>y <- (X %*% c(1,2) + rnorm(100)) > 0
>>dat <- data.frame(y=y, X=X)
>>mod <- glm(y ~ X, family=binomial, data=dat)
>>new <- data.frame(X = matrix(rnorm(20),2))
>>predict(mod, new)

Dear John,

the questioner had a 2 column matrix with 40 and one with 50 
observations (not a 100 column matrix with 2 observation) and for those 
matrices it works ...

Best,
Uwe







>            1            2            3            4            5
> 6 
>   1.81224443  -5.92955128   1.98718051 -10.05331521   2.65065555
> -2.50635812 
>            7            8            9           10           11
> 12 
>   5.63728698  -0.94845276  -3.61657377  -1.63141320   5.03417372
> 1.80400271 
>           13           14           15           16           17
> 18 
>   9.32876273  -5.32723406   5.29373023  -3.90822713 -10.95065186
> 4.90038016 
> 
>  . . .
> 
>            97           98           99          100 
>  -6.92509812   0.59357486  -1.17205723   0.04209578 
> 
> 
> Note that there are 100 rather than 10 predicted values.
> 
> But with individuals predictors (rather than a matrix),
> 
> 
>>x1 <- X[,1]
>>x2 <- X[,2]
>>dat.2 <- data.frame(y=y, x1=x1, x2=x2)
>>mod.2 <- glm(y ~ x1 + x2, family=binomial, data=dat.2)
>>new.2 <- data.frame(x1=rnorm(10), x2=rnorm(10))
>>predict(mod.2, new.2)
> 
>          1          2          3          4          5          6          7
> 
>  6.5723823  0.6356392  4.0291018 -4.7914650  2.1435485 -3.1738096 -2.8261585
> 
>          8          9         10 
> -1.5255329 -4.7087592  4.0619290 
> 
> works as expected (?).
> 
> Regards,
>  John
>  
> 
> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Uwe Ligges
>>Sent: Thursday, September 23, 2004 1:33 AM
>>To: jrausch at nd.edu
>>Cc: r-help at stat.math.ethz.ch
>>Subject: Re: [R] Issue with predict() for glm models
>>
>>jrausch at nd.edu wrote:
>>
>>
>>>Hello everyone,
>>>
>>>I am having a problem using the predict (or the 
>>
>>predict.glm) function in R.
>>
>>>Basically, I run the glm model on a "training" data set and try to 
>>>obtain predictions for a set of new predictors from a 
>>
>>"test" data set 
>>
>>>(i.e., not the predictors that were utilized to obtain the 
>>
>>glm parameter estimates).
>>
>>>Unfortunately, every time that I attempt this, I obtain the 
>>>predictions for the predictors that were used to fit the 
>>
>>glm model. I 
>>
>>>have looked at the R mailing list archives and don't believe I am 
>>>making the same mistakes that have been made in the past 
>>
>>and also have 
>>
>>>tried to closely follow the predict.glm example in the help 
>>
>>file. Here is an example of what I am trying to do:
>>
>>>########################################################
>>>set.seed(545345)
>>>
>>>################
>>># Necessary Variables #
>>>################
>>>
>>>p <- 2
>>>train.n <- 20
>>>test.n <- 25
>>>mean.vec.1 <- c(1,1)
>>>mean.vec.2 <- c(0,0)
>>>
>>>Sigma.1 <- matrix(c(1,.5,.5,1),p,p)
>>>Sigma.2 <- matrix(c(1,.5,.5,1),p,p)
>>>
>>>###############
>>># Load MASS Library #
>>>###############
>>>
>>>library(MASS)
>>>
>>>###################################
>>># Data to Parameters for Logistic Regression Model # 
>>>###################################
>>>
>>>train.data.1 <- mvrnorm(train.n,mu=mean.vec.1,Sigma=Sigma.1)
>>>train.data.2 <- mvrnorm(train.n,mu=mean.vec.2,Sigma=Sigma.2)
>>>train.class.var <- as.factor(c(rep(1,train.n),rep(2,train.n)))
>>>predictors.train <- rbind(train.data.1,train.data.2)
>>>
>>>##############################################
>>># Test Data Where Predictions for Probabilities Using 
>>
>>Logistic Reg.  #
>>
>>># From Training Data are of Interest                        
>>
>>                  #
>>
>>>##############################################
>>>
>>>test.data.1 <- mvrnorm(test.n,mu=mean.vec.1,Sigma=Sigma.1)
>>>test.data.2 <- mvrnorm(test.n,mu=mean.vec.2,Sigma=Sigma.2)
>>>predictors.test <- rbind(test.data.1,test.data.2)
>>>
>>>##############################
>>># Run Logistic Regression on Training Data # 
>>>##############################
>>>
>>>log.reg <- glm(train.class.var~predictors.train,
>>>family=binomial(link="logit"))
>>
>>Well, you haven't specified the "data" argument, but given 
>>the two variables directly. Exactly those variables will be 
>>used in the
>>predict() step below! If you want the predict() step to work, 
>>use something like:
>>
>>   train <- data.frame(class = train.class.var,
>>                       predictors = predictors.train)
>>   log.reg <- glm(class ~ ., data = train,
>>                  family=binomial(link="logit"))
>>
>>
>>
>>
>>>log.reg
>>>
>>>#> log.reg
>>>
>>>#Call:  glm(formula = train.class.var ~ predictors.train, family = 
>>>#binomial(link = "logit")) #
>>>#Coefficients:
>>>#      (Intercept)  predictors.train1  predictors.train2  
>>>#           0.5105            -0.2945            -1.0811  
>>>#
>>>#Degrees of Freedom: 39 Total (i.e. Null);  37 Residual
>>>#Null Deviance:      55.45 
>>>#Residual Deviance: 41.67        AIC: 47.67 
>>>
>>>###########################
>>># Predicted Probabilities for Test Data # 
>>
>>###########################
>>
>>>New.Data <- data.frame(predictors.train1=predictors.test[,1],
>>>predictors.train2=predictors.test[,2])
>>>
>>>logreg.pred.prob.test <- 
>>
>>predict.glm(log.reg,New.Data,type="response")
>>
>>>logreg.pred.prob.test
>>
>>Instead, use:
>>
>>   test <- data.frame(predictors = predictors.test)
>>   predict(log.reg, newdata = test, type="response")
>>
>>
>>note also: please call the generic predict() rather than its 
>>glm method.
>>
>>
>>Uwe Ligges
>>
>>
>>
>>>#logreg.pred.prob.test
>>># [1] 0.51106406 0.15597423 0.04948404 0.03863875 0.35587589 
>>>0.71331091 # [7] 0.17320087 0.14176632 0.30966718 0.61878952 
>>>0.12525988 0.21271139 #[13] 0.70068113 0.18340723 0.10295501 
>>>0.44591568 0.72285161 0.31499339 #[19] 0.65789420 0.42750139 
>>>0.14435889 0.93008117 0.70798465 0.80109005 #[25] 0.89161472 
>>>0.47480625 0.56520952 0.63981834 0.57595189 0.60075882 #[31] 
>>>0.96493393 0.77015507 0.87643986 0.62973986 0.63043351 0.45398955 
>>>#[37] 0.80855782 0.90835588 0.54809117 0.11568637 
>>>########################################################
>>>
>>>Of course, notice that the vector for the predicted 
>>
>>probabilities has 
>>
>>>only 40 elements, while the "New.Data" has 50 elements 
>>
>>(since n.test 
>>
>>>has 25 per group for 2 groups) and thus should have 50 predicted 
>>>probabilities. As it turns out, the output is for the training data 
>>>predictors and not for the "New.Data" as I would like it to be. I 
>>>should also note that I have made sure that the names for the 
>>>predictors in the "New.Data" are the same as the names for the 
>>>predictors within the glm object (i.e., within "log.reg") 
>>
>>as this is what is done in the example for predict.glm() 
>>within the help files.
>>
>>>Could some one help me understand either what I am doing 
>>
>>incorrectly 
>>
>>>or what problems there might be within the predict() function? I 
>>>should mention that I tried the same program using 
>>
>>predict.glm() and 
>>
>>>obtained the same problematic results.
>>>
>>>Thanks and take care,
>>>
>>>Joe
>>>
>>>
>>>Joe Rausch, M.A. 
>>>Psychology Liaison
>>>Lab for Social Research
>>>917 Flanner Hall
>>>University of Notre Dame
>>>Notre Dame, IN 46556
>>>(574) 631-3910
>>>
>>>"If we knew what it was we were doing, it would not be called 
>>>research, would it?"
>>>- Albert Einstein
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! 
>>>http://www.R-project.org/posting-guide.html
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Thu Sep 23 15:10:45 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 23 Sep 2004 09:10:45 -0400
Subject: [R] Issue with predict() for glm models
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8401@usrymx25.merck.com>



> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of John Fox
> Sent: Thursday, September 23, 2004 8:49 AM
> To: 'Uwe Ligges'
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] Issue with predict() for glm models
> 
> 
> Dear Uwe,
> 
> Unless I've somehow messed this up, as I mentioned yesterday, what you
> suggest doesn't seem to work when the predictor is a matrix. Here's a
> simplified example:
> 
> > X <- matrix(rnorm(200), 100, 2)
> > y <- (X %*% c(1,2) + rnorm(100)) > 0
> > dat <- data.frame(y=y, X=X)
> > mod <- glm(y ~ X, family=binomial, data=dat)
> > new <- data.frame(X = matrix(rnorm(20),2))
> > predict(mod, new)
>            1            2            3            4            5
> 6 
>   1.81224443  -5.92955128   1.98718051 -10.05331521   2.65065555
> -2.50635812 
>            7            8            9           10           11
> 12 
>   5.63728698  -0.94845276  -3.61657377  -1.63141320   5.03417372
> 1.80400271 
>           13           14           15           16           17
> 18 
>   9.32876273  -5.32723406   5.29373023  -3.90822713 -10.95065186
> 4.90038016 
> 
>  . . .
> 
>            97           98           99          100 
>  -6.92509812   0.59357486  -1.17205723   0.04209578 
> 
> 
> Note that there are 100 rather than 10 predicted values.
> 
> But with individuals predictors (rather than a matrix),
> 
> > x1 <- X[,1]
> > x2 <- X[,2]
> > dat.2 <- data.frame(y=y, x1=x1, x2=x2)
> > mod.2 <- glm(y ~ x1 + x2, family=binomial, data=dat.2)
> > new.2 <- data.frame(x1=rnorm(10), x2=rnorm(10))
> > predict(mod.2, new.2)
>          1          2          3          4          5        
>   6          7
> 
>  6.5723823  0.6356392  4.0291018 -4.7914650  2.1435485 
> -3.1738096 -2.8261585
> 
>          8          9         10 
> -1.5255329 -4.7087592  4.0619290 
> 
> works as expected (?).
> 
> Regards,
>  John
>  

My apologies: I have not kept up with the earlier messages in this thread,
so this might be covered already:

> X <- matrix(rnorm(200), 100, 2)
> y <- (X %*% c(1,2) + rnorm(100)) > 0
> dat <- data.frame(y=y, X=X)
> mod <- glm(y ~ X, family=binomial, data=dat)
> newmat <- matrix(rnorm(20), ncol=2)
> new <- data.frame(X = newmat)
> new2 <- data.frame(X = I(newmat))
> str(predict(mod, new))
 Named num [1:100] 3.30 8.08 4.65 4.72 2.15 ...
 - attr(*, "names")= chr [1:100] "1" "2" "3" "4" ...
> str(predict(mod, new2))
 Named num [1:10]  7.358  0.241 -5.418  2.094 -0.885 ...
 - attr(*, "names")= chr [1:10] "1" "2" "3" "4" ...

The bottom line is that the data frame passed to predict() must have
variables that matches exactly with what's used in the original formula.
Passing `new' doesn't work as expected because it's a data frame with two
variables, rather than one variable whose name is `X' and is a two-column
matrix.

Best,
Andy


 
> > From: Uwe Ligges
> > 
> > jrausch at nd.edu wrote:
> > 
> > > Hello everyone,
> > > 
> > > I am having a problem using the predict (or the 
> > predict.glm) function in R.
> > > Basically, I run the glm model on a "training" data set 
> and try to 
> > > obtain predictions for a set of new predictors from a 
> > "test" data set 
> > > (i.e., not the predictors that were utilized to obtain the 
> > glm parameter estimates).
> > > Unfortunately, every time that I attempt this, I obtain the 
> > > predictions for the predictors that were used to fit the 
> > glm model. I 
> > > have looked at the R mailing list archives and don't believe I am 
> > > making the same mistakes that have been made in the past 
> > and also have 
> > > tried to closely follow the predict.glm example in the help 
> > file. Here is an example of what I am trying to do:
> > > 
> > > ########################################################
> > > set.seed(545345)
> > > 
> > > ################
> > > # Necessary Variables #
> > > ################
> > > 
> > > p <- 2
> > > train.n <- 20
> > > test.n <- 25
> > > mean.vec.1 <- c(1,1)
> > > mean.vec.2 <- c(0,0)
> > > 
> > > Sigma.1 <- matrix(c(1,.5,.5,1),p,p)
> > > Sigma.2 <- matrix(c(1,.5,.5,1),p,p)
> > > 
> > > ###############
> > > # Load MASS Library #
> > > ###############
> > > 
> > > library(MASS)
> > > 
> > > ###################################
> > > # Data to Parameters for Logistic Regression Model # 
> > > ###################################
> > > 
> > > train.data.1 <- mvrnorm(train.n,mu=mean.vec.1,Sigma=Sigma.1)
> > > train.data.2 <- mvrnorm(train.n,mu=mean.vec.2,Sigma=Sigma.2)
> > > train.class.var <- as.factor(c(rep(1,train.n),rep(2,train.n)))
> > > predictors.train <- rbind(train.data.1,train.data.2)
> > > 
> > > ##############################################
> > > # Test Data Where Predictions for Probabilities Using 
> > Logistic Reg.  #
> > > # From Training Data are of Interest                        
> >                   #
> > > ##############################################
> > > 
> > > test.data.1 <- mvrnorm(test.n,mu=mean.vec.1,Sigma=Sigma.1)
> > > test.data.2 <- mvrnorm(test.n,mu=mean.vec.2,Sigma=Sigma.2)
> > > predictors.test <- rbind(test.data.1,test.data.2)
> > > 
> > > ##############################
> > > # Run Logistic Regression on Training Data # 
> > > ##############################
> > > 
> > > log.reg <- glm(train.class.var~predictors.train,
> > > family=binomial(link="logit"))
> > 
> > Well, you haven't specified the "data" argument, but given 
> > the two variables directly. Exactly those variables will be 
> > used in the
> > predict() step below! If you want the predict() step to work, 
> > use something like:
> > 
> >    train <- data.frame(class = train.class.var,
> >                        predictors = predictors.train)
> >    log.reg <- glm(class ~ ., data = train,
> >                   family=binomial(link="logit"))
> > 
> > 
> > 
> > > log.reg
> > > 
> > > #> log.reg
> > > 
> > > #Call:  glm(formula = train.class.var ~ predictors.train, 
> family = 
> > > #binomial(link = "logit")) #
> > > #Coefficients:
> > > #      (Intercept)  predictors.train1  predictors.train2  
> > > #           0.5105            -0.2945            -1.0811  
> > > #
> > > #Degrees of Freedom: 39 Total (i.e. Null);  37 Residual
> > > #Null Deviance:      55.45 
> > > #Residual Deviance: 41.67        AIC: 47.67 
> > > 
> > > ###########################
> > > # Predicted Probabilities for Test Data # 
> > ###########################
> > > 
> > > New.Data <- data.frame(predictors.train1=predictors.test[,1],
> > > predictors.train2=predictors.test[,2])
> > > 
> > > logreg.pred.prob.test <- 
> > predict.glm(log.reg,New.Data,type="response")
> > > logreg.pred.prob.test
> > 
> > Instead, use:
> > 
> >    test <- data.frame(predictors = predictors.test)
> >    predict(log.reg, newdata = test, type="response")
> > 
> > 
> > note also: please call the generic predict() rather than its 
> > glm method.
> > 
> > 
> > Uwe Ligges
> > 
> > 
> > > #logreg.pred.prob.test
> > > # [1] 0.51106406 0.15597423 0.04948404 0.03863875 0.35587589 
> > > 0.71331091 # [7] 0.17320087 0.14176632 0.30966718 0.61878952 
> > > 0.12525988 0.21271139 #[13] 0.70068113 0.18340723 0.10295501 
> > > 0.44591568 0.72285161 0.31499339 #[19] 0.65789420 0.42750139 
> > > 0.14435889 0.93008117 0.70798465 0.80109005 #[25] 0.89161472 
> > > 0.47480625 0.56520952 0.63981834 0.57595189 0.60075882 #[31] 
> > > 0.96493393 0.77015507 0.87643986 0.62973986 0.63043351 0.45398955 
> > > #[37] 0.80855782 0.90835588 0.54809117 0.11568637 
> > > ########################################################
> > > 
> > > Of course, notice that the vector for the predicted 
> > probabilities has 
> > > only 40 elements, while the "New.Data" has 50 elements 
> > (since n.test 
> > > has 25 per group for 2 groups) and thus should have 50 predicted 
> > > probabilities. As it turns out, the output is for the 
> training data 
> > > predictors and not for the "New.Data" as I would like it to be. I 
> > > should also note that I have made sure that the names for the 
> > > predictors in the "New.Data" are the same as the names for the 
> > > predictors within the glm object (i.e., within "log.reg") 
> > as this is what is done in the example for predict.glm() 
> > within the help files.
> > > 
> > > Could some one help me understand either what I am doing 
> > incorrectly 
> > > or what problems there might be within the predict() function? I 
> > > should mention that I tried the same program using 
> > predict.glm() and 
> > > obtained the same problematic results.
> > > 
> > > Thanks and take care,
> > > 
> > > Joe
> > > 
> > > 
> > > Joe Rausch, M.A. 
> > > Psychology Liaison
> > > Lab for Social Research
> > > 917 Flanner Hall
> > > University of Notre Dame
> > > Notre Dame, IN 46556
> > > (574) 631-3910
> > > 
> > > "If we knew what it was we were doing, it would not be called 
> > > research, would it?"
> > > - Albert Einstein
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > > http://www.R-project.org/posting-guide.html
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ggrothendieck at myway.com  Thu Sep 23 15:51:46 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 23 Sep 2004 13:51:46 +0000 (UTC)
Subject: [R] block statistics with POSIX classes
References: <C9FC71F7E9356F40AFE2ACC2099DE1471496B7@MAILSERVER-B.mpsgr.it>
Message-ID: <loom.20040923T153154-424@post.gmane.org>

I am not sure that I understand what you are looking
for since you did not provide any sample data with
corresponding output to clarify your question.

Here is another guess.

If y is just a numeric vector with monthly data 
and dp is a POSIXlt vector of the same length then:

   aggregate(list(y=y), list(dp$year), mean)$y

will perform aggregation, as will

  aggregate(ts(y, start=c(d$year[1],d$mon[1]+1), freq = 12), nfreq=1, mean)

which converts y to ts and then performs the aggregation.  The first
one will work even if y is irregular while the second one assumes that
y must be monthly.  The second one returns a ts object.

By the way, I had a look at gev's source and it seems that despite the
documentation it does not use POSIXct anywhere internally.  If the
block is "year" or other character value then it simply assumes that
whatever datetime class is used has an as.POSIXlt method.  If your dates
were POSIXct rather than POSIXlt then it would be important to ensure
that whatever timezone is assumed (which I did not check) in the conversion 
is the one you are using.  You could use character dates or Date class to 
avoid this problem.  Since you appear to be using POSIXlt datetimes from
the beginning I think you should be ok.


Kahra Hannu <kahra <at> mpsgr.it> writes:

: 
: Thank you Petr and Gabor for the answers.
: 
: They did not, however, solve my original problem. When I have a monthly time 
series y with a POSIX date
: variable dp, the most obvious way to compute e.g. the annual means is to use 
aggregate(y, 1, mean) that
: works with time series. However, I got stuck with the idea of using the 'by' 
argument as by = dp$year. But in
: that case y has to be a data.frame. The easiest way must be the best way.
: 
: Regards,
: Hannu 
: 
: -----Original Message-----
: From: r-help-bounces <at> stat.math.ethz.ch
: [mailto:r-help-bounces <at> stat.math.ethz.ch]On Behalf Of Gabor Grothendieck
: Sent: Thursday, September 23, 2004 12:56 PM
: To: r-help <at> stat.math.ethz.ch
: Subject: Re: [R] block statistics with POSIX classes
: 
: 
: Kahra Hannu <kahra <at> mpsgr.it> writes:
: 
: : 
: : I have a monthly price index series x, the related return series y = diff
(log
: (x)) and a POSIXlt date-time
: : variable dp. I would like to apply annual blocks to compute for example 
: annual block maxima and mean of y.
: : 
: : When studying the POSIX classes, in the first stage of the learning curve, 
I 
: computed the maximum drawdown
: : of x:
: : > mdd <- maxdrawdown(x)
: : > max.dd <- mdd$maxdrawdown
: : > from <- as.character(dp[mdd$from]) 
: : > to <- as.character(dp[mdd$to])                       
: : > from; to
: : [1] "2000-08-31"
: : [1] "2003-03-31"
: : that gives me the POSIX dates of the start and end of the period and 
: suggests that I have done something correctly.
: : 
: : Two questions:
: : (1) how to implement annual blocks and compute e.g. annual max, min and 
mean 
: of y (each year's max, min, mean)?
: : (2) how to apply POSIX variables with the 'block' argument in gev in the 
: evir package?
: : 
: : The S+FinMetrics function aggregateSeries does the job in that module; but 
I 
: do not know, how handle it in R.
: : My guess is that (1) is done by using the function aggregate, but how to 
: define the 'by' argument with POSIX variables?
: 
: 1. To create a ts monthly time series you specify the first month
: and a frequency of 12 like this.  
: 
: z.m <- ts(rep(1:6,4), start = c(2000,1), freq = 12)
: z.m
: 
: # Annual aggregate is done using aggregate.ts with nfreq = 1
: z.y <- aggregate(z.m, nfreq = 1, max)
: z.y
: 
: # To create a POSIXct series of times using seq
: # (This will use GMT.  Use tz="" arg to ISOdate if you want current tz.)
: z.y.times <- seq(ISOdate(2000,1,1), length = length(z.y), by = "year")
: z.y.times
: 
: 2. Have not used evir but looking at ?gev it seems you can
: use block = 12 if you have monthly data and want the blocks to be 
: successive 12 month periods or you can add a POSIXct times attribute to 
: your data as below (also see comment re tz above) and then use 
: block = "year" in your gev call.
: 
: attr(z.m, "times") <- seq(ISOdate(2000,1,1), length=length(z.m), by="month")
: str(z.m)  # display z.m along with attribute info
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://stat.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://stat.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From jeaneid at chass.utoronto.ca  Thu Sep 23 16:03:04 2004
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Thu, 23 Sep 2004 10:03:04 -0400
Subject: [R] gsub
Message-ID: <Pine.SGI.4.40.0409231002140.24923311-100000@origin.chass.utoronto.ca>

Hi

A while back I used gsub to do the following

temp<-"000US00231"
gsub("something here", "", temp)
"00231"

I think it involved the `meta characters' somehow.

I do not know how to do this anymore. I know strsplit will also work but I
remember gsub was much faster.  In essence the question is how to delete
all characters before a particular pattern.

If anyone has some help file for this, it will be greatly appreciated.


Jean Eid



From sdavis2 at mail.nih.gov  Thu Sep 23 16:11:39 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 23 Sep 2004 10:11:39 -0400
Subject: [R] gsub
In-Reply-To: <Pine.SGI.4.40.0409231002140.24923311-100000@origin.chass.utoronto.ca>
References: <Pine.SGI.4.40.0409231002140.24923311-100000@origin.chass.utoronto.ca>
Message-ID: <7C8E3FF7-0D6A-11D9-B970-000A95D7BA10@mail.nih.gov>

You might want to look at ?regex.

Sean

On Sep 23, 2004, at 10:03 AM, Jean Eid wrote:

> Hi
>
> A while back I used gsub to do the following
>
> temp<-"000US00231"
> gsub("something here", "", temp)
> "00231"
>
> I think it involved the `meta characters' somehow.
>
> I do not know how to do this anymore. I know strsplit will also work 
> but I
> remember gsub was much faster.  In essence the question is how to 
> delete
> all characters before a particular pattern.
>
> If anyone has some help file for this, it will be greatly appreciated.
>
>
> Jean Eid
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From christoph.lehmann at gmx.ch  Thu Sep 23 16:12:23 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Thu, 23 Sep 2004 16:12:23 +0200
Subject: [R] nnet and weights: error analysis using V&R example
Message-ID: <4152D9C7.8010201@gmx.ch>

Dear R-users, dear Prof. Ripley as package maintainer

I tried to investigate the odd error, when I call nnet together with a 
'weights' parameter, using the 'fgl' example in V&R p 348

The error I get is:

	Error in eval(expr, envir, enclos) : Object "w" not found

I think it is a kind of scoping problem, but I really cannot see, what 
the problem exactly is.

and here is my code: the only thing which changed is the definition of a 
weight-parameter ('w') which is given to the nnet-call. Of course the 
weight vector with '1's makes no sense here, but it will be defined 
according to the class sizes later.

###
library(MASS)
data(flg)

con <- function(...)
{
     print(tab <- table(...))
     diag(tab) <- 0
     cat("error rate = ",
         round(100*sum(tab)/length(list(...)[[1]]), 2), "%\n")
     invisible()
}


set.seed(123)
rand <- sample(10, dim(fgl)[1], replace = T)

fgl1 <- fgl
fgl1[1:9] <- lapply(fgl[, 1:9], function(x) {r <- range(x); (x - 
r[1])/diff(r)})


CVnn2 <- function(formula, data,
                   size = c(0,4,4,10,10), lambda = c(0, rep(c(0.001, 
0.01),2)),
                   nreps = 1, nifold = 5, verbose = 99, ...)
{

     CVnn1 <- function(formula, data, nreps=1, ri, verbose,  ...)
     {
         totalerror <- 0
         truth <- data[,deparse(formula[[2]])]
         res <-  matrix(0, nrow(data), length(levels(truth)))
         if(verbose > 20) cat("  inner fold")
         for (i in sort(unique(ri))) {
             if(verbose > 20) cat(" ", i,  sep="")
             data.training <- data[ri != i,]$GROUP

             w <- rep(1, dim(data[ri !=i,])[1])

             for(rep in 1:nreps) {
                 learn <- nnet(formula, data[ri !=i,],
                               weights = w,
                               trace = F, ...)
                 res[ri == i,] <- res[ri == i,] + predict(learn, data[ri 
== i,])

             }
         }
         if(verbose > 20) cat("\n")
         sum(as.numeric(truth) != max.col(res/nreps))
     }
     truth <- data[,deparse(formula[[2]])]
     res <-  matrix(0, nrow(data), length(levels(truth)))
     choice <- numeric(length(lambda))
     for (i in sort(unique(rand))) {
         if(verbose > 0) cat("fold ", i,"\n", sep="")
         set.seed(i*i)
         ri <- sample(nifold, sum(rand!=i), replace=T)
         for(j in seq(along=lambda)) {
             if(verbose > 10)
                 cat("  size =", size[j], "decay =", lambda[j], "\n")
             choice[j] <- CVnn1(formula, data[rand != i,], nreps=nreps,
                                ri=ri, size=size[j], decay=lambda[j],
                                verbose=verbose, ...)
         }
         decay <- lambda[which.is.max(-choice)]
         csize <- size[which.is.max(-choice)]
         if(verbose > 5) cat("  #errors:", choice, "  ") #
         if(verbose > 1) cat("chosen size = ", csize,
                             " decay = ", decay, "\n", sep="")
         for(rep in 1:nreps) {
             data.training <- data[rand != i,]$GROUP
             w <- rep(1, dim(data[rand !=i,])[1])
             learn <- nnet(formula, data[rand != i,],
                       weights = w,
                       trace=F,
                       size=csize, decay=decay, ...)
             res[rand == i,] <- res[rand == i,] + predict(learn, 
data[rand == i,])
         }
     }
     factor(levels(truth)[max.col(res/nreps)], levels = levels(truth))
}


res.nn2 <- CVnn2(type ~ ., fgl1, skip = T, maxit = 500, nreps = 10)

con(true = fgl$type, predicted = res.nn2)
##


many thanks for your help

Christoph

###


Coordinates:
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    1
minor    9.1
year     2004
month    06
day      21
language R


-- 
Christoph Lehmann                            Phone:  ++41 31 930 93 83
Department of Psychiatric Neurophysiology    Mobile: ++41 76 570 28 00
University Hospital of Clinical Psychiatry   Fax:    ++41 31 930 99 61
Waldau                                            lehmann at puk.unibe.ch
CH-3000 Bern 60         http://www.puk.unibe.ch/cl/pn_ni_cv_cl_03.html



From Phguardiol at aol.com  Thu Sep 23 16:22:18 2004
From: Phguardiol at aol.com (Phguardiol@aol.com)
Date: Thu, 23 Sep 2004 10:22:18 -0400
Subject: [R] detection of outliers
Message-ID: <70DD3AF7.4CA76F15.0C58B543@aol.com>

Hi,
this is both a statistical and a R question...
what would the best way / test to detect an outlier value among a series of 10 to 30 values ? for instance if we have the following dataset: 10,11,12,15,20,22,25,30,500 I d like to have a way to identify the last data as an outlier (only one direction). One way would be to calculate abs(mean - median) and if elevated (to what extent ?) delete the extreme data then redo.. but is it valid to do so with so few data ? is the (trimmed mean - mean) more efficient ? if so, what would be the maximal tolerable value to use as a threshold ? (I guess it will be experiment dependent...) tests for skweness will probably required a larger dataset ? 
any suggestions are very welcome !
thanks for your help
Philippe Guardiola, MD



From jfox at mcmaster.ca  Thu Sep 23 16:22:34 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 23 Sep 2004 10:22:34 -0400
Subject: [R] Issue with predict() for glm models
In-Reply-To: <4152CA3E.7040009@statistik.uni-dortmund.de>
Message-ID: <20040923142232.SACR25796.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Uwe, 

> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
> Sent: Thursday, September 23, 2004 8:06 AM
> To: John Fox
> Cc: jrausch at nd.edu; r-help at stat.math.ethz.ch
> Subject: Re: [R] Issue with predict() for glm models
> 
> John Fox wrote:
> 
> > Dear Uwe,
> > 
> > Unless I've somehow messed this up, as I mentioned 
> yesterday, what you 
> > suggest doesn't seem to work when the predictor is a 
> matrix. Here's a 
> > simplified example:
> > 
> > 
> >>X <- matrix(rnorm(200), 100, 2)
> >>y <- (X %*% c(1,2) + rnorm(100)) > 0
> >>dat <- data.frame(y=y, X=X)
> >>mod <- glm(y ~ X, family=binomial, data=dat) new <- data.frame(X = 
> >>matrix(rnorm(20),2)) predict(mod, new)
> 
> Dear John,
> 
> the questioner had a 2 column matrix with 40 and one with 50 
> observations (not a 100 column matrix with 2 observation) and 
> for those matrices it works ...
> 

Indeed, and in my example the matrix predictor X has 2 columns and 100 rows;
I did screw up the matrix for the "new" data to be used for predictions (in
the example I sent today but not yesterday), but even when this is done
right -- where the new data has 10 rows and 2 columns -- there are 100 (not
10) predicted values:

> X <- matrix(rnorm(200), 100, 2)  # original predictor matrix with 100 rows
> y <- (X %*% c(1,2) + rnorm(100)) > 0
> dat <- data.frame(y=y, X=X)
> mod <- glm(y ~ X, family=binomial, data=dat)
> new <- data.frame(X = matrix(rnorm(20),10, 2)) # corrected -- note 10 rows
> predict(mod, new) # note 100 predicted values
           1            2            3            4            5
6 
  5.75238091   0.31874587  -3.00515893  -3.77282121  -1.97511221
0.54712914 
           7            8            9           10           11
12 
  1.85091226   4.38465524  -0.41028694  -1.53942869   0.57613555
-1.82761518 

 . . .

          91           92           93           94           95
96 
  0.36210780   1.71358713  -9.63612775  -4.54257576  -5.29740468
2.64363405 
          97           98           99          100 
 -4.45478627  -2.44973209   2.51587537  -4.09584837 

Actually, I now see the source of the problem:

The data frames dat and new don't contain a matrix named "X"; rather the
matrix is split columnwise:

> names(dat)
[1] "y"   "X.1" "X.2"
> names(new)
[1] "X.1" "X.2"

Consequently, both glm and predict pick up the X in the global environment
(since there is none in dat or new), which accounts for why there are 100
predicted values.

Using list() rather than data.frame() produces the originally expected
behaviour:

> new <- list(X = matrix(rnorm(20),10, 2))
> predict(mod, new)
         1          2          3          4          5          6          7

 5.9373064  0.3687360 -8.3793045  0.7645584 -2.6773842  2.4130547  0.7387318

         8          9         10 
-0.4347916  8.4678728 -0.8976054 

Regards,
 John

> Best,
> Uwe
> 
> 
> 
> 
> 
> 
> 
> >            1            2            3            4            5
> > 6 
> >   1.81224443  -5.92955128   1.98718051 -10.05331521   2.65065555
> > -2.50635812 
> >            7            8            9           10           11
> > 12 
> >   5.63728698  -0.94845276  -3.61657377  -1.63141320   5.03417372
> > 1.80400271 
> >           13           14           15           16           17
> > 18 
> >   9.32876273  -5.32723406   5.29373023  -3.90822713 -10.95065186
> > 4.90038016
> > 
> >  . . .
> > 
> >            97           98           99          100 
> >  -6.92509812   0.59357486  -1.17205723   0.04209578 
> > 
> > 
> > Note that there are 100 rather than 10 predicted values.
> > 
> > But with individuals predictors (rather than a matrix),
> > 
> > 
> >>x1 <- X[,1]
> >>x2 <- X[,2]
> >>dat.2 <- data.frame(y=y, x1=x1, x2=x2)
> >>mod.2 <- glm(y ~ x1 + x2, family=binomial, data=dat.2)
> >>new.2 <- data.frame(x1=rnorm(10), x2=rnorm(10)) 
> predict(mod.2, new.2)
> > 
> >          1          2          3          4          5      
>     6          7
> > 
> >  6.5723823  0.6356392  4.0291018 -4.7914650  2.1435485 -3.1738096 
> > -2.8261585
> > 
> >          8          9         10 
> > -1.5255329 -4.7087592  4.0619290
> > 
> > works as expected (?).
> > 
> > Regards,
> >  John
> >  
> > 
> > 
> >>-----Original Message-----
> >>From: r-help-bounces at stat.math.ethz.ch 
> >>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Uwe Ligges
> >>Sent: Thursday, September 23, 2004 1:33 AM
> >>To: jrausch at nd.edu
> >>Cc: r-help at stat.math.ethz.ch
> >>Subject: Re: [R] Issue with predict() for glm models
> >>
> >>jrausch at nd.edu wrote:
> >>
> >>
> >>>Hello everyone,
> >>>
> >>>I am having a problem using the predict (or the
> >>
> >>predict.glm) function in R.
> >>
> >>>Basically, I run the glm model on a "training" data set and try to 
> >>>obtain predictions for a set of new predictors from a
> >>
> >>"test" data set
> >>
> >>>(i.e., not the predictors that were utilized to obtain the
> >>
> >>glm parameter estimates).
> >>
> >>>Unfortunately, every time that I attempt this, I obtain the 
> >>>predictions for the predictors that were used to fit the
> >>
> >>glm model. I
> >>
> >>>have looked at the R mailing list archives and don't believe I am 
> >>>making the same mistakes that have been made in the past
> >>
> >>and also have
> >>
> >>>tried to closely follow the predict.glm example in the help
> >>
> >>file. Here is an example of what I am trying to do:
> >>
> >>>########################################################
> >>>set.seed(545345)
> >>>
> >>>################
> >>># Necessary Variables #
> >>>################
> >>>
> >>>p <- 2
> >>>train.n <- 20
> >>>test.n <- 25
> >>>mean.vec.1 <- c(1,1)
> >>>mean.vec.2 <- c(0,0)
> >>>
> >>>Sigma.1 <- matrix(c(1,.5,.5,1),p,p)
> >>>Sigma.2 <- matrix(c(1,.5,.5,1),p,p)
> >>>
> >>>###############
> >>># Load MASS Library #
> >>>###############
> >>>
> >>>library(MASS)
> >>>
> >>>###################################
> >>># Data to Parameters for Logistic Regression Model # 
> >>>###################################
> >>>
> >>>train.data.1 <- mvrnorm(train.n,mu=mean.vec.1,Sigma=Sigma.1)
> >>>train.data.2 <- mvrnorm(train.n,mu=mean.vec.2,Sigma=Sigma.2)
> >>>train.class.var <- as.factor(c(rep(1,train.n),rep(2,train.n)))
> >>>predictors.train <- rbind(train.data.1,train.data.2)
> >>>
> >>>##############################################
> >>># Test Data Where Predictions for Probabilities Using
> >>
> >>Logistic Reg.  #
> >>
> >>># From Training Data are of Interest                        
> >>
> >>                  #
> >>
> >>>##############################################
> >>>
> >>>test.data.1 <- mvrnorm(test.n,mu=mean.vec.1,Sigma=Sigma.1)
> >>>test.data.2 <- mvrnorm(test.n,mu=mean.vec.2,Sigma=Sigma.2)
> >>>predictors.test <- rbind(test.data.1,test.data.2)
> >>>
> >>>##############################
> >>># Run Logistic Regression on Training Data # 
> >>>##############################
> >>>
> >>>log.reg <- glm(train.class.var~predictors.train,
> >>>family=binomial(link="logit"))
> >>
> >>Well, you haven't specified the "data" argument, but given the two 
> >>variables directly. Exactly those variables will be used in the
> >>predict() step below! If you want the predict() step to work, use 
> >>something like:
> >>
> >>   train <- data.frame(class = train.class.var,
> >>                       predictors = predictors.train)
> >>   log.reg <- glm(class ~ ., data = train,
> >>                  family=binomial(link="logit"))
> >>
> >>
> >>
> >>
> >>>log.reg
> >>>
> >>>#> log.reg
> >>>
> >>>#Call:  glm(formula = train.class.var ~ predictors.train, family = 
> >>>#binomial(link = "logit")) #
> >>>#Coefficients:
> >>>#      (Intercept)  predictors.train1  predictors.train2  
> >>>#           0.5105            -0.2945            -1.0811  
> >>>#
> >>>#Degrees of Freedom: 39 Total (i.e. Null);  37 Residual
> >>>#Null Deviance:      55.45 
> >>>#Residual Deviance: 41.67        AIC: 47.67 
> >>>
> >>>###########################
> >>># Predicted Probabilities for Test Data #
> >>
> >>###########################
> >>
> >>>New.Data <- data.frame(predictors.train1=predictors.test[,1],
> >>>predictors.train2=predictors.test[,2])
> >>>
> >>>logreg.pred.prob.test <-
> >>
> >>predict.glm(log.reg,New.Data,type="response")
> >>
> >>>logreg.pred.prob.test
> >>
> >>Instead, use:
> >>
> >>   test <- data.frame(predictors = predictors.test)
> >>   predict(log.reg, newdata = test, type="response")
> >>
> >>
> >>note also: please call the generic predict() rather than its glm 
> >>method.
> >>
> >>
> >>Uwe Ligges
> >>
> >>
> >>
> >>>#logreg.pred.prob.test
> >>># [1] 0.51106406 0.15597423 0.04948404 0.03863875 0.35587589
> >>>0.71331091 # [7] 0.17320087 0.14176632 0.30966718 0.61878952
> >>>0.12525988 0.21271139 #[13] 0.70068113 0.18340723 0.10295501
> >>>0.44591568 0.72285161 0.31499339 #[19] 0.65789420 0.42750139
> >>>0.14435889 0.93008117 0.70798465 0.80109005 #[25] 0.89161472
> >>>0.47480625 0.56520952 0.63981834 0.57595189 0.60075882 #[31]
> >>>0.96493393 0.77015507 0.87643986 0.62973986 0.63043351 0.45398955 
> >>>#[37] 0.80855782 0.90835588 0.54809117 0.11568637 
> >>>########################################################
> >>>
> >>>Of course, notice that the vector for the predicted
> >>
> >>probabilities has
> >>
> >>>only 40 elements, while the "New.Data" has 50 elements
> >>
> >>(since n.test
> >>
> >>>has 25 per group for 2 groups) and thus should have 50 predicted 
> >>>probabilities. As it turns out, the output is for the 
> training data 
> >>>predictors and not for the "New.Data" as I would like it to be. I 
> >>>should also note that I have made sure that the names for the 
> >>>predictors in the "New.Data" are the same as the names for the 
> >>>predictors within the glm object (i.e., within "log.reg")
> >>
> >>as this is what is done in the example for predict.glm() within the 
> >>help files.
> >>
> >>>Could some one help me understand either what I am doing
> >>
> >>incorrectly
> >>
> >>>or what problems there might be within the predict() function? I 
> >>>should mention that I tried the same program using
> >>
> >>predict.glm() and
> >>
> >>>obtained the same problematic results.
> >>>
> >>>Thanks and take care,
> >>>
> >>>Joe
> >>>
> >>>
> >>>Joe Rausch, M.A. 
> >>>Psychology Liaison
> >>>Lab for Social Research
> >>>917 Flanner Hall
> >>>University of Notre Dame
> >>>Notre Dame, IN 46556
> >>>(574) 631-3910
> >>>
> >>>"If we knew what it was we were doing, it would not be called 
> >>>research, would it?"
> >>>- Albert Einstein
> >>>
> >>>______________________________________________
> >>>R-help at stat.math.ethz.ch mailing list 
> >>>https://stat.ethz.ch/mailman/listinfo/r-help
> >>>PLEASE do read the posting guide! 
> >>>http://www.R-project.org/posting-guide.html
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! 
> >>http://www.R-project.org/posting-guide.html
>



From ggrothendieck at myway.com  Thu Sep 23 16:27:30 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 23 Sep 2004 14:27:30 +0000 (UTC)
Subject: [R] gsub
References: <Pine.SGI.4.40.0409231002140.24923311-100000@origin.chass.utoronto.ca>
Message-ID: <loom.20040923T162619-708@post.gmane.org>

Jean Eid <jeaneid <at> chass.utoronto.ca> writes:

: 
: Hi
: 
: A while back I used gsub to do the following
: 
: temp<-"000US00231"
: gsub("something here", "", temp)
: "00231"
: 
: I think it involved the `meta characters' somehow.
: 
: I do not know how to do this anymore. I know strsplit will also work but I
: remember gsub was much faster.  In essence the question is how to delete
: all characters before a particular pattern.
: 
: If anyone has some help file for this, it will be greatly appreciated.
: 

I think you want sub in this case, not gsub.

There are many possibilities here depending on what the
general case is.  The following all give the desired
result for the example but their general cases differ.
These are just some of the numerous variations possible.

temp<-"000US00231"
sub(".*US", "", temp)
sub(".*S", "", temp)
sub("[[:digit:]]*[[:alpha:]]*", "", temp)
sub(".*[[:alpha:]]", "", temp)
sub(".*[[:alpha:]][[:alpha:]]", "", temp)
sub(".*[[:upper:]]", "", temp)
sub(".*[[:upper:]][[:upper:]]", "", temp)
sub(".....", "", temp)
substring(temp, 6)



From jrausch at nd.edu  Thu Sep 23 16:45:14 2004
From: jrausch at nd.edu (jrausch@nd.edu)
Date: Thu, 23 Sep 2004 09:45:14 -0500
Subject: [R] Issue with predict() for glm models
Message-ID: <1095950714.4152e17a0eb73@webmail.nd.edu>


Thanks to John Fox, Andy Liaw, and Uwe Ligges for their help with my problem
regarding the use of the predict()  function to obtain predictions for a new
set of predictor values. It appears that the bottom line (at least for my
purposes) is that the names and the setup for the data of the predictors in the
glm and the new data need to be consistent. The safest way that I know to do
this from reading  John, Andy, and Uwe's responses is to label each predictor
separately and place them into the glm model separately. Then, when creating a
new data frame to utilize in the predict() function, ensure to consistently
name the predictors. For illustrative examples, see the reply emails of John,
Andy, and Uwe.  

Thanks again, 

Joe  




Joe Rausch, M.A. 
Psychology Liaison 
Lab for Social Research 
917 Flanner Hall 
University of Notre Dame 
Notre Dame, IN 46556
(574) 631-3910
www.nd.edu/~jrausch

"If we knew what it was we were doing, it would not be called research, would
it?"
- Albert Einstein



From ggrothendieck at myway.com  Thu Sep 23 16:52:05 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 23 Sep 2004 14:52:05 +0000 (UTC)
Subject: [R] detection of outliers
References: <70DD3AF7.4CA76F15.0C58B543@aol.com>
Message-ID: <loom.20040923T164815-203@post.gmane.org>

 <Phguardiol <at> aol.com> writes:

: 
: Hi,
: this is both a statistical and a R question...
: what would the best way / test to detect an outlier value among a series of 
10 to 30 values ? for instance if we
: have the following dataset: 10,11,12,15,20,22,25,30,500 I d like to have a 
way to identify the last data
: as an outlier (only one direction). One way would be to calculate abs(mean - 
median) and if elevated (to
: what extent ?) delete the extreme data then redo.. but is it valid to do so 
with so few data ? is the (trimmed
: mean - mean) more efficient ? if so, what would be the maximal tolerable 
value to use as a threshold ? (I guess
: it will be experiment dependent...) tests for skweness will probably 
required a larger dataset ? 
: any suggestions are very welcome !
: thanks for your help
: Philippe Guardiola, MD


If z is your vector the following all detect outliers:

	boxplot(z)  # will show the outlier

	plot(lm(z ~ 1))  # the various plots show this as well

	require(car)
	outlier.test(lm(z ~ 1)) # tests most extreme value



From jacques.meyohas at fioprev.org.br  Thu Sep 23 16:56:37 2004
From: jacques.meyohas at fioprev.org.br (Jacques Mendes Meyohas)
Date: Thu, 23 Sep 2004 11:56:37 -0300
Subject: [R] Problem with R 1.9.1
Message-ID: <002e01c4a17d$86836b00$0210000a@jacques>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040923/08677bee/attachment.pl

From dimitris.rizopoulos at med.kuleuven.ac.be  Thu Sep 23 16:57:23 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Thu, 23 Sep 2004 16:57:23 +0200
Subject: [R] detection of outliers
References: <70DD3AF7.4CA76F15.0C58B543@aol.com>
Message-ID: <000c01c4a17d$a2066ad0$b2133a86@www.domain>

Hi Philippe,

you could consider using the Windsorized mean,

winds.mean <-  function(x, k=2){
    y <- x[!is.na(x)]
    mu <- mean(y)
    stdev <- sd(y)
    outliers.up <- y[y>mu+k*stdev]
    outliers.lo <- y[y<mu-k*stdev]
    y[y==outliers.up] <- mu+k*stdev
    y[y==outliers.lo] <- mu-k*stdev
    list(mean=sum(y)/length(y), outliers.up=outliers.up, 
outliers.lo=outliers.lo)
}
##################

x <- c(10,11,12,15,20,22,25,30,500)
mean(x)
winds.mean(x)

I hope this helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: <Phguardiol at aol.com>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, September 23, 2004 4:22 PM
Subject: [R] detection of outliers


> Hi,
> this is both a statistical and a R question...
> what would the best way / test to detect an outlier value among a 
> series of 10 to 30 values ? for instance if we have the following 
> dataset: 10,11,12,15,20,22,25,30,500 I d like to have a way to 
> identify the last data as an outlier (only one direction). One way 
> would be to calculate abs(mean - median) and if elevated (to what 
> extent ?) delete the extreme data then redo.. but is it valid to do 
> so with so few data ? is the (trimmed mean - mean) more efficient ? 
> if so, what would be the maximal tolerable value to use as a 
> threshold ? (I guess it will be experiment dependent...) tests for 
> skweness will probably required a larger dataset ?
> any suggestions are very welcome !
> thanks for your help
> Philippe Guardiola, MD
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From sdavis2 at mail.nih.gov  Thu Sep 23 17:04:44 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 23 Sep 2004 11:04:44 -0400
Subject: [R] Gridbase basic question
Message-ID: <E6ED8BE8-0D71-11D9-B970-000A95D7BA10@mail.nih.gov>

All,

I have a simple plot(x,y) and I would like to then insert rectangles of  
some length (in native coordinates) and height fixed to 0.5 in native  
coordinates.  I can't quite get the code right to do this.  Can anyone  
give me a quick example of how to do this?  I looked the gridBase index  
and the tutorial (from R-news?) but just haven't gotten it down yet.

 > plot(1:10,1:10)
 > par(new=T);vps <- baseViewports()
 > pushViewport(vps$inner,vps$figure,vps$plot)
viewport[GRID.VP.28]
 > pushViewport(viewport(x=unit(1,"native"),y=unit(2,"native")))
viewport[GRID.VP.29]
 >  
grid.rect(height=unit(0.5,"native"),width=unit(1.5,"native"),just='botto 
m')

This draws a very large rectangle going from 2 to 7 (y) and to 8 (x).

Thanks,
Sean



From remigijus.lapinskas at mif.vu.lt  Thu Sep 23 16:29:24 2004
From: remigijus.lapinskas at mif.vu.lt (Remigijus Lapinskas)
Date: Thu, 23 Sep 2004 17:29:24 +0300
Subject: [R] R vs EViews - serial correlation
In-Reply-To: <222021406.20040923170950@mif.vu.lt>
References: <222021406.20040923170950@mif.vu.lt>
Message-ID: <8723194734.20040923172924@mif.vu.lt>


Dear all,

I met with some problems when dealing with a time series with serial correlation.

FIRST, I generate a series with correlated errors

set.seed(1)
x=1:50
y=x+arima.sim(n = 50, list(ar = c(0.47)))

SECOND, I estimate three constants (a, b and rho) in the model Y=a+b*X+u, where u=rho*u(-1)+eps
 
library(nlme)
gls(y~x,correlation = corAR1(0.5))     # Is it the right procedure?

Coefficients:
(Intercept)           x 
  0.1410465   1.0023341 

Correlation Structure: AR(1)
 Formula: ~1 
 Parameter estimate(s):
     Phi 
0.440594 
Degrees of freedom: 50 total; 48 residual
Residual standard error: 0.9835158

THIRD, I do the same procedure with EViews as LS Y C X AR(1) and get
Y = 0.1375 + 1.0024*X + [AR(1)=0.3915]

My problem is actually connected with the fitting procedure. As far as I understand 

gls(y~x,correlation = corAR1(0.5))$fit

is obtained through the linear equation 0.1410+1.0023*X while in EViews through the nonlinear equation 

Y=rho*Y(-1) + (1-rho)*a+(X-rho*X(-1))*b

where either dynamic or static fitting procedures are applied. 

    X       Y    YF_D    YF_S gls.fit
1   1  1.1592      NA      NA  1.1434
2   2  3.5866  2.1499  2.1499  2.1457
3   3  4.1355  3.1478  3.7103  3.1480
4   4  3.9125  4.1484  4.5352  4.1504
5   5  2.7442  5.1502  5.0578  5.1527
6   6  6.0647  6.1523  5.2103  6.1551
7   7  6.9855  7.1547  7.1203  7.1574
.....................................
47 47 49.4299 47.2521 47.5288 47.2507
48 48 48.7748 48.2545 49.1072 48.2531
49 49 48.3200 49.2570 49.4607 49.2554
50 50 50.2501 50.2594 49.8926 50.2578

All gls.fit values are on a line, YF_D (D for dynamic) soon begin
to follow a line and YF_S (S for static) try to mimic Y.

My question is: do R and EViews estimate the same model? If yes, why
the estimates are different and which of the two (three?) procedures
is "correct"?

Thanking you in advance,
Rem



From murdoch at stats.uwo.ca  Thu Sep 23 17:06:57 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 23 Sep 2004 11:06:57 -0400
Subject: [R] Problem with R 1.9.1
In-Reply-To: <002e01c4a17d$86836b00$0210000a@jacques>
References: <002e01c4a17d$86836b00$0210000a@jacques>
Message-ID: <lgp5l0djusu6npijoh3s317ud0o0cqsvn3@4ax.com>

On Thu, 23 Sep 2004 11:56:37 -0300, "Jacques Mendes Meyohas"
<jacques.meyohas at fioprev.org.br> wrote :

>Hi,
>
>Could someone help me ?
>When I??m running the following command in the new R 1.9.1 version the error message appear. It didn??t happen on R 1.8.0
>
>> glm(indenizacao/sinistros ~ sexo + plano + faixa, family=Gamma(link="log"), weights=sinistros)
>Error in x[good, ] * w : non-conformable arrays

Someone might recognize this problem, but you're likely to get a
better response (or figure out the problem yourself!) if you try to
simplify things to something completely self-contained.  

I'm guessing there's something wrong with your weight vector
"sinistros", but I can't check to be sure.

Duncan Murdoch



From Michael.Wolf at bezreg-muenster.nrw.de  Thu Sep 23 17:08:49 2004
From: Michael.Wolf at bezreg-muenster.nrw.de (Wolf, Michael)
Date: Thu, 23 Sep 2004 17:08:49 +0200
Subject: [R] How to improve the quality of curve/line plots?
Message-ID: <9E00F1C36CEF614CA4AA6CC2587B594D360DFD@EXCHANGE2.harz.bezreg-muenster.nrw.de>

Dear list,

I'm using the windows version of R. When plotting a curve or a line for time series with annual data , e. g. GDP growth 1991-2003, the line seems to exist of a lot of smaller lines. Printing the results the curves and lines seems to be "unclean" (because of using small resolution bitmaps?). Comparing the result of R with the same results of Excel the lines in excel seems to havve a higher qualitiy. In Excel you also can produce curves instead of lines.

Are there any possibilities how to improve the quality of the plots in R? How can R be influenced to plot "clean" lines with a higher resolution on the screen (I think it's not a question of the pdf- or png command.). Perhaps, it's a problem of the graphical possibilites of R because the most line plots which can be seen on the web have these problems.

Thanks,

Dr. Michael Wolf
Bezirksregierung M??nster
Dezernat 61
Domplatz 1-3    48161 M??nster
Tel.:   ++ 49 (02 51) / 4 11 - 17 95
Fax.:   ++ 49 (02 51) / 4 11 - 8 17 95
E-Mail: michael.wolf at bezreg-muenster.nrw.de



From fm3a004 at math.uni-hamburg.de  Thu Sep 23 17:14:24 2004
From: fm3a004 at math.uni-hamburg.de (Christian Hennig)
Date: Thu, 23 Sep 2004 17:14:24 +0200 (MEST)
Subject: [R] detection of outliers
In-Reply-To: <70DD3AF7.4CA76F15.0C58B543@aol.com>
Message-ID: <Pine.GSO.3.95q.1040923170653.17411F-100000@sun12.math.uni-hamburg.de>

On Thu, 23 Sep 2004 Phguardiol at aol.com wrote:

> Hi,
> this is both a statistical and a R question...
> what would the best way / test to detect an outlier value among a series of 10 to 30 values ? for instance if we have the following dataset: 10,11,12,15,20,22,25,30,500 I d like to have a way to identify the last data as an outlier (only one direction). One way would be to calculate abs(mean - median) and if elevated (to what extent ?) delete the extreme data then redo.. but is it valid to do so with so few data ? is the (trimmed mean - mean) more efficient ? if so, what would be the maximal tolerable value to use as a threshold ? (I guess it will be experiment dependent...) tests for skweness will probably required a larger dataset ? 
> any suggestions are very welcome !
> thanks for your help
> Philippe Guardiola, MD
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

You may want to read 
Davies and Gather, The identification of multiple outliers, JASA 88 (1993),
782-801.

The simplest recommendation is to nominate all points with distance larger
than c*mad(data) from the median as outliers. Choices of c depending on n
are given in the above paper.

This is somewhat better founded theoretically than the boxplot method
recommended by Gabor G., but it is based on the assumption that the
distribution on the non-outliers is close to the normal and especially not
strongly skewed (the boxplot method
seems to be a bit more robust against skewness).

Christian
 
***********************************************************************
Christian Hennig
Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag-online.de



From vito_ricci at yahoo.com  Thu Sep 23 17:19:45 2004
From: vito_ricci at yahoo.com (Vito Ricci)
Date: Thu, 23 Sep 2004 17:19:45 +0200 (CEST)
Subject: [R] detection of outliers
Message-ID: <20040923151945.52950.qmail@web41204.mail.yahoo.com>

Hi,
give a look to:

http://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm

it's the Grubbs' Test for Outliers. It is based on the
assumption of normality of data.

Other methods of outliers' could:

Run-Sequence Plot
Histogram
Normal Probability Plot
Box-plot

Best
Vito



you wrote:

Hi,
this is both a statistical and a R question...
what would the best way / test to detect an outlier
value among a series of 10 to 30 values ? for instance
if we have the following dataset:
10,11,12,15,20,22,25,30,500 I d like to have a way to
identify the last data as an outlier (only one
direction). One way would be to calculate abs(mean -
median) and if elevated (to what extent ?) delete the
extreme data then redo.. but is it valid to do so with
so few data ? is the (trimmed mean - mean) more
efficient ? if so, what would be the maximal tolerable
value to use as a threshold ? (I guess it will be
experiment dependent...) tests for skweness will
probably required a larger dataset ? 
any suggestions are very welcome !
thanks for your help
Philippe Guardiola, MD

=====
Diventare costruttori di soluzioni

Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml


		
___________________________________

http://it.seriea.fantasysports.yahoo.com/



From gunter.berton at gene.com  Thu Sep 23 17:32:17 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 23 Sep 2004 08:32:17 -0700
Subject: [R] detection of outliers
In-Reply-To: <70DD3AF7.4CA76F15.0C58B543@aol.com>
Message-ID: <200409231532.i8NFWIxB005183@compton.gene.com>

Not to oversimplify ...

1. (At least) dozens of books and thousands of papers have been written on
this...

2. Most important question is: What is an outlier? (Many smart folks says
that the concept is illogical/flawed -- there is no mystical boundary that
one crosses to become a statistical pariah; many other smart folks
disagree).

3. Equivalently: What is the model with respect to which values are
outlying? (with apologies to Winston Churchill's: "That is an indignity up
with which I will not put.")

So good advice here is: Beware of good advice about this. (Of course, I may
just be an outlier ...)

;)

Cheers,

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Phguardiol at aol.com
> Sent: Thursday, September 23, 2004 7:22 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] detection of outliers
> 
> Hi,
> this is both a statistical and a R question...
> what would the best way / test to detect an outlier value 
> among a series of 10 to 30 values ? for instance if we have 
> the following dataset: 10,11,12,15,20,22,25,30,500 I d like 
> to have a way to identify the last data as an outlier (only 
> one direction). One way would be to calculate abs(mean - 
> median) and if elevated (to what extent ?) delete the extreme 
> data then redo.. but is it valid to do so with so few data ? 
> is the (trimmed mean - mean) more efficient ? if so, what 
> would be the maximal tolerable value to use as a threshold ? 
> (I guess it will be experiment dependent...) tests for 
> skweness will probably required a larger dataset ? 
> any suggestions are very welcome !
> thanks for your help
> Philippe Guardiola, MD
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

From kahra at mpsgr.it  Thu Sep 23 17:42:59 2004
From: kahra at mpsgr.it (Kahra Hannu)
Date: Thu, 23 Sep 2004 17:42:59 +0200
Subject: [R] block statistics with POSIX classes
Message-ID: <C9FC71F7E9356F40AFE2ACC2099DE1471496B8@MAILSERVER-B.mpsgr.it>

I have followed Gabor's instructions:

> aggregate(list(y=y), list(dp$year), mean)$y 			# returns NULL since y is a time series
NULL
 
> aggregate(list(y=as.vector(y)), list(dp$year), mean)$y	# returns annual means
[1]  0.0077656696  0.0224050294  0.0099991898  0.0240550925 -0.0084085867
[6] -0.0170950194 -0.0355641251  0.0065873997  0.0008253111

> aggregate(list(y=y), list(dp$year), mean)			# returns the same as the previous one
  Group.1      Series.1
1      96  0.0077656696
2      97  0.0224050294
3      98  0.0099991898
4      99  0.0240550925
5     100 -0.0084085867
6     101 -0.0170950194
7     102 -0.0355641251
8     103  0.0065873997
9     104  0.0008253111

Gabor's second suggestion returns different results:

> aggregate(ts(y, start=c(dp$year[1],dp$mon[1]+1), freq = 12), nfreq=1, mean)
Time Series:
Start = 96.33333 
End = 103.3333 
Frequency = 1 
         Series 1
[1,]  0.016120895
[2,]  0.024257131
[3,]  0.007526997
[4,]  0.017466118
[5,] -0.016024846
[6,] -0.017145159
[7,] -0.036047765
[8,]  0.014198501

> aggregate(y, 1, mean) 		# verifies the result above
Time Series:
Start = 1996.333 
End = 2003.333 
Frequency = 1 
         Series 1
[1,]  0.016120895
[2,]  0.024257131
[3,]  0.007526997
[4,]  0.017466118
[5,] -0.016024846
[6,] -0.017145159
[7,] -0.036047765
[8,]  0.014198501

The data is from 1996:5 to 2004:8. The difference of the results must depend on the fact that the beginning of the data is not January and the end is not December? The first two solutions give nine annual means while the last two give only eight means. The block size in the last two must be 12 months, as is said in ?aggregate, instead of a calender year that I am looking for. Gabor's first suggestion solved my problem.

Thank you,
Hannu
  


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Gabor Grothendieck
Sent: Thursday, September 23, 2004 3:52 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] block statistics with POSIX classes


I am not sure that I understand what you are looking
for since you did not provide any sample data with
corresponding output to clarify your question.

Here is another guess.

If y is just a numeric vector with monthly data 
and dp is a POSIXlt vector of the same length then:

   aggregate(list(y=y), list(dp$year), mean)$y

will perform aggregation, as will

  aggregate(ts(y, start=c(d$year[1],d$mon[1]+1), freq = 12), nfreq=1, mean)

which converts y to ts and then performs the aggregation.  The first
one will work even if y is irregular while the second one assumes that
y must be monthly.  The second one returns a ts object.

By the way, I had a look at gev's source and it seems that despite the
documentation it does not use POSIXct anywhere internally.  If the
block is "year" or other character value then it simply assumes that
whatever datetime class is used has an as.POSIXlt method.  If your dates
were POSIXct rather than POSIXlt then it would be important to ensure
that whatever timezone is assumed (which I did not check) in the conversion 
is the one you are using.  You could use character dates or Date class to 
avoid this problem.  Since you appear to be using POSIXlt datetimes from
the beginning I think you should be ok.


Kahra Hannu <kahra <at> mpsgr.it> writes:

: 
: Thank you Petr and Gabor for the answers.
: 
: They did not, however, solve my original problem. When I have a monthly time 
series y with a POSIX date
: variable dp, the most obvious way to compute e.g. the annual means is to use 
aggregate(y, 1, mean) that
: works with time series. However, I got stuck with the idea of using the 'by' 
argument as by = dp$year. But in
: that case y has to be a data.frame. The easiest way must be the best way.
: 
: Regards,
: Hannu 
: 
: -----Original Message-----
: From: r-help-bounces <at> stat.math.ethz.ch
: [mailto:r-help-bounces <at> stat.math.ethz.ch]On Behalf Of Gabor Grothendieck
: Sent: Thursday, September 23, 2004 12:56 PM
: To: r-help <at> stat.math.ethz.ch
: Subject: Re: [R] block statistics with POSIX classes
: 
: 
: Kahra Hannu <kahra <at> mpsgr.it> writes:
: 
: : 
: : I have a monthly price index series x, the related return series y = diff
(log
: (x)) and a POSIXlt date-time
: : variable dp. I would like to apply annual blocks to compute for example 
: annual block maxima and mean of y.
: : 
: : When studying the POSIX classes, in the first stage of the learning curve, 
I 
: computed the maximum drawdown
: : of x:
: : > mdd <- maxdrawdown(x)
: : > max.dd <- mdd$maxdrawdown
: : > from <- as.character(dp[mdd$from]) 
: : > to <- as.character(dp[mdd$to])                       
: : > from; to
: : [1] "2000-08-31"
: : [1] "2003-03-31"
: : that gives me the POSIX dates of the start and end of the period and 
: suggests that I have done something correctly.
: : 
: : Two questions:
: : (1) how to implement annual blocks and compute e.g. annual max, min and 
mean 
: of y (each year's max, min, mean)?
: : (2) how to apply POSIX variables with the 'block' argument in gev in the 
: evir package?
: : 
: : The S+FinMetrics function aggregateSeries does the job in that module; but 
I 
: do not know, how handle it in R.
: : My guess is that (1) is done by using the function aggregate, but how to 
: define the 'by' argument with POSIX variables?
: 
: 1. To create a ts monthly time series you specify the first month
: and a frequency of 12 like this.  
: 
: z.m <- ts(rep(1:6,4), start = c(2000,1), freq = 12)
: z.m
: 
: # Annual aggregate is done using aggregate.ts with nfreq = 1
: z.y <- aggregate(z.m, nfreq = 1, max)
: z.y
: 
: # To create a POSIXct series of times using seq
: # (This will use GMT.  Use tz="" arg to ISOdate if you want current tz.)
: z.y.times <- seq(ISOdate(2000,1,1), length = length(z.y), by = "year")
: z.y.times
: 
: 2. Have not used evir but looking at ?gev it seems you can
: use block = 12 if you have monthly data and want the blocks to be 
: successive 12 month periods or you can add a POSIXct times attribute to 
: your data as below (also see comment re tz above) and then use 
: block = "year" in your gev call.
: 
: attr(z.m, "times") <- seq(ISOdate(2000,1,1), length=length(z.m), by="month")
: str(z.m)  # display z.m along with attribute info
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://stat.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://stat.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From shuangge at biostat.wisc.edu  Thu Sep 23 18:25:31 2004
From: shuangge at biostat.wisc.edu (Shuangge Ma)
Date: Thu, 23 Sep 2004 11:25:31 -0500 (CDT)
Subject: [R] R glm
Message-ID: <Pine.GSO.4.58.0409231123260.19298@naos.biostat.wisc.edu>

Hello:
would you please help me with the following glm question?

for the R function glm, what I understand is: once you specify the
"family", then the link function is fixed.

My question is: is it possible I use, for example, "log" link function,
but the estimation approach for the guassian family?

Thanks,

Shuangge Ma, Ph.D.
********************************************
* CHSCC, Department of Biostatistics       *
* University of Washington                 *
* Building 29, Suite 310, 6200 NE 74th ST. *
* Seattle, WA 98115                        *
* Tel: 206-685-7123 Fax: 206-616-4075      *



From ligges at statistik.uni-dortmund.de  Thu Sep 23 18:31:48 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 23 Sep 2004 18:31:48 +0200
Subject: [R] Problem with R 1.9.1
In-Reply-To: <002e01c4a17d$86836b00$0210000a@jacques>
References: <002e01c4a17d$86836b00$0210000a@jacques>
Message-ID: <4152FA74.2000503@statistik.uni-dortmund.de>

Jacques Mendes Meyohas wrote:
> Hi,
> 
> Could someone help me ?
> When I??m running the following command in the new R 1.9.1 version the error message appear. It didn??t happen on R 1.8.0
> 
> 
>>glm(indenizacao/sinistros ~ sexo + plano + faixa, family=Gamma(link="log"), weights=sinistros)
> 
> Error in x[good, ] * w : non-conformable arrays

We cannot help if we don't know anything about the data you are using.
You also might want to try out R-2.0.0 beta (but I guess it is user error).

Uwe Ligges



> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From uleopold at science.uva.nl  Thu Sep 23 18:33:00 2004
From: uleopold at science.uva.nl (Ulrich Leopold)
Date: 23 Sep 2004 18:33:00 +0200
Subject: [R] fitting weibull distribution
Message-ID: <1095957180.7733.4.camel@snowdon.science.uva.nl>

Dear all,

I get the following error message. And I cannot quite work out what is
wrong. I think the optim gets infinite values. Certainly my data do not
have any infinite values. How can I solve this?

fitdistr(A1, "weibull")
Error in optim(start, mylogfn, x = x, hessian = TRUE, ...) :
        non-finite value supplied by optim


I am using R version 1.9.1 on RedHat Linux, Kernel 2.6.8.

Ulrich



From ligges at statistik.uni-dortmund.de  Thu Sep 23 18:37:04 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 23 Sep 2004 18:37:04 +0200
Subject: [R] Issue with predict() for glm models
In-Reply-To: <20040923142232.SACR25796.tomts36-srv.bellnexxia.net@JohnDesktop8300>
References: <20040923142232.SACR25796.tomts36-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <4152FBB0.5050503@statistik.uni-dortmund.de>

John Fox wrote:

> Dear Uwe, 
> 
> 
>>-----Original Message-----
>>From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
>>Sent: Thursday, September 23, 2004 8:06 AM
>>To: John Fox
>>Cc: jrausch at nd.edu; r-help at stat.math.ethz.ch
>>Subject: Re: [R] Issue with predict() for glm models
>>
>>John Fox wrote:
>>
>>
>>>Dear Uwe,
>>>
>>>Unless I've somehow messed this up, as I mentioned 
>>
>>yesterday, what you 
>>
>>>suggest doesn't seem to work when the predictor is a 
>>
>>matrix. Here's a 
>>
>>>simplified example:
>>>
>>>
>>>
>>>>X <- matrix(rnorm(200), 100, 2)
>>>>y <- (X %*% c(1,2) + rnorm(100)) > 0
>>>>dat <- data.frame(y=y, X=X)
>>>>mod <- glm(y ~ X, family=binomial, data=dat) new <- data.frame(X = 
>>>>matrix(rnorm(20),2)) predict(mod, new)
>>
>>Dear John,
>>
>>the questioner had a 2 column matrix with 40 and one with 50 
>>observations (not a 100 column matrix with 2 observation) and 
>>for those matrices it works ...
>>
> 
> 
> Indeed, and in my example the matrix predictor X has 2 columns and 100 rows;
> I did screw up the matrix for the "new" data to be used for predictions (in
> the example I sent today but not yesterday), but even when this is done
> right -- where the new data has 10 rows and 2 columns -- there are 100 (not
> 10) predicted values:
> 
> 
>>X <- matrix(rnorm(200), 100, 2)  # original predictor matrix with 100 rows
>>y <- (X %*% c(1,2) + rnorm(100)) > 0
>>dat <- data.frame(y=y, X=X)
>>mod <- glm(y ~ X, family=binomial, data=dat)

John,

note that I used glm(y ~ .) (the dot!),
because the names are automatically chosen to be X.1 and X.2, hence you 
cannot use "X" in the formula in this case ...

Best,
Uwe


>>new <- data.frame(X = matrix(rnorm(20),10, 2)) # corrected -- note 10 rows
>>predict(mod, new) # note 100 predicted values



From kahra at mpsgr.it  Thu Sep 23 18:47:28 2004
From: kahra at mpsgr.it (Kahra Hannu)
Date: Thu, 23 Sep 2004 18:47:28 +0200
Subject: [R] R glm
Message-ID: <C9FC71F7E9356F40AFE2ACC2099DE1471496B9@MAILSERVER-B.mpsgr.it>

In Venables & Ripley: Modern Applied Statistics with S (MASS), (4th edition), on page 184 there is a table "Families and link functions" that gives you the available links with different families. The default and the only link with the gaussian family is identity.

ciao,
Hannu Kahra

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Shuangge Ma
Sent: Thursday, September 23, 2004 6:26 PM
To: r-help at stat.math.ethz.ch
Subject: [R] R glm


Hello:
would you please help me with the following glm question?

for the R function glm, what I understand is: once you specify the
"family", then the link function is fixed.

My question is: is it possible I use, for example, "log" link function,
but the estimation approach for the guassian family?

Thanks,

Shuangge Ma, Ph.D.
********************************************
* CHSCC, Department of Biostatistics       *
* University of Washington                 *
* Building 29, Suite 310, 6200 NE 74th ST. *
* Seattle, WA 98115                        *
* Tel: 206-685-7123 Fax: 206-616-4075      *

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From HStevens at MUOhio.edu  Thu Sep 23 18:48:19 2004
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Thu, 23 Sep 2004 12:48:19 -0400
Subject: [R] R glm
In-Reply-To: <Pine.GSO.4.58.0409231123260.19298@naos.biostat.wisc.edu>
References: <Pine.GSO.4.58.0409231123260.19298@naos.biostat.wisc.edu>
Message-ID: <5FD270D0-0D80-11D9-9988-000A958F43CC@MUOhio.edu>

Dear Shuangge - There exists a default link function for each family, 
but you can specify the link, as well.
see ?family (e.g., in html help click on the "family" link from the glm 
help page).
Hank
On Sep 23, 2004, at 12:25 PM, Shuangge Ma wrote:

> Hello:
> would you please help me with the following glm question?
>
> for the R function glm, what I understand is: once you specify the
> "family", then the link function is fixed.
>
> My question is: is it possible I use, for example, "log" link function,
> but the estimation approach for the guassian family?
>
> Thanks,
>
> Shuangge Ma, Ph.D.
> ********************************************
> * CHSCC, Department of Biostatistics       *
> * University of Washington                 *
> * Building 29, Suite 310, 6200 NE 74th ST. *
> * Seattle, WA 98115                        *
> * Tel: 206-685-7123 Fax: 206-616-4075      *
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>
Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From ggrothendieck at myway.com  Thu Sep 23 19:03:32 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 23 Sep 2004 17:03:32 +0000 (UTC)
Subject: [R] block statistics with POSIX classes
References: <C9FC71F7E9356F40AFE2ACC2099DE1471496B8@MAILSERVER-B.mpsgr.it>
Message-ID: <loom.20040923T181458-796@post.gmane.org>


Kahra Hannu <kahra <at> mpsgr.it> writes:

: 
: I have followed Gabor's instructions:
: 
: > aggregate(list(y=y), list(dp$year), mean)$y 			# 
returns NULL since y is a time series
: NULL
:  
: > aggregate(list(y=as.vector(y)), list(dp$year), mean)$y	# returns 
annual means
: [1]  0.0077656696  0.0224050294  0.0099991898  0.0240550925 -0.0084085867
: [6] -0.0170950194 -0.0355641251  0.0065873997  0.0008253111
: 
: > aggregate(list(y=y), list(dp$year), mean)			# returns the 
same as the previous one
:   Group.1      Series.1
: 1      96  0.0077656696
: 2      97  0.0224050294
: 3      98  0.0099991898
: 4      99  0.0240550925
: 5     100 -0.0084085867
: 6     101 -0.0170950194
: 7     102 -0.0355641251
: 8     103  0.0065873997
: 9     104  0.0008253111
: 
: Gabor's second suggestion returns different results:
: 
: > aggregate(ts(y, start=c(dp$year[1],dp$mon[1]+1), freq = 12), nfreq=1, mean)
: Time Series:
: Start = 96.33333 
: End = 103.3333 
: Frequency = 1 
:          Series 1
: [1,]  0.016120895
: [2,]  0.024257131
: [3,]  0.007526997
: [4,]  0.017466118
: [5,] -0.016024846
: [6,] -0.017145159
: [7,] -0.036047765
: [8,]  0.014198501
: 
: > aggregate(y, 1, mean) 		# verifies the result above
: Time Series:
: Start = 1996.333 
: End = 2003.333 
: Frequency = 1 
:          Series 1
: [1,]  0.016120895
: [2,]  0.024257131
: [3,]  0.007526997
: [4,]  0.017466118
: [5,] -0.016024846
: [6,] -0.017145159
: [7,] -0.036047765
: [8,]  0.014198501
: 
: The data is from 1996:5 to 2004:8. The difference of the results must depend 
on the fact that the beginning of
: the data is not January and the end is not December? The first two solutions 
give nine annual means while the
: last two give only eight means. The block size in the last two must be 12 
months, as is said in ?aggregate,
: instead of a calender year that I am looking for. Gabor's first suggestion 
solved my problem.

Yes, that seems to be the case.  Using length instead of 
mean we find that the aggregate.data.frame example used calendar 
years as the basis of aggregation whereas the aggregate.ts example
used successive 12 month periods starting from the first month discarding
the 4 points at the end which do not fill out a full year.

R> set.seed(1)
R> dp <- as.POSIXlt(seq(from=as.Date("1996-5-1"), to=as.Date("2004-8-1"), 
+          by="month"))
R> y <- rnorm(length(dp$year))

R> aggregate(list(y=y), list(dp$year), length)$y
[1]  8 12 12 12 12 12 12 12  8

R> aggregate(ts(y, start=c(dp$year[1],dp$mon[1]+1), freq = 12), nfreq=1, 
length)
Time Series:
Start = 96.33333 
End = 103.3333 
Frequency = 1 
[1] 12 12 12 12 12 12 12 12



From pauljohn at ku.edu  Thu Sep 23 19:02:57 2004
From: pauljohn at ku.edu (Paul Johnson)
Date: Thu, 23 Sep 2004 12:02:57 -0500
Subject: followup: Re: [R] Issue with predict() for glm models
In-Reply-To: <20040923142232.SACR25796.tomts36-srv.bellnexxia.net@JohnDesktop8300>
References: <20040923142232.SACR25796.tomts36-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <415301C1.6070207@ku.edu>

I have a follow up question that fits with this thread.

Can you force an overlaid plot showing predicted values to follow the 
scaling of the axes of the plot over which it is laid?

Here is an example based on linear regression, just for clarity.  I have 
followed the procedure described below to create predictions and now 
want to plot the predicted values "on top" of a small section of the x-y 
scatterplot.

x <- rnorm(100, 10, 10)
e <- rnorm(100, 0, 5)
y <- 5 + 10 *x + e

myReg1 <- lm (y~x)
plot(x,y)
newX <- seq(1,10,1)
myPred <- predict(myReg1,data.frame(x=newX))

Now, if I do this, I get 2 graphs "overlaid" but their axes do not "line 
up".

par(new=T)
plot(newX,myPred$fit)

The problem is that the second one uses the "whole width" of the graph 
space, when I'd rather just have it go from the small subset where its x 
is defined, from 1 to 10.  Its stretching the range (1,10) for newX to 
use the same scale that goes from (-15, 35) where it plots x

I know abline() can do this for lm, but for some other kinds of models, 
no  lines() method is provided, and so I am doing this the old fashioned 
way.

pj

John Fox wrote:
> Dear Uwe, 
> 
> 
>>-----Original Message-----
>>From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
>>Sent: Thursday, September 23, 2004 8:06 AM
>>To: John Fox
>>Cc: jrausch at nd.edu; r-help at stat.math.ethz.ch
>>Subject: Re: [R] Issue with predict() for glm models
>>
>>John Fox wrote:
>>
>>
>>>Dear Uwe,
>>>
>>>Unless I've somehow messed this up, as I mentioned 
>>
>>yesterday, what you 
>>
>>>suggest doesn't seem to work when the predictor is a 
>>
>>matrix. Here's a 
>>
>>>simplified example:
>>>
>>>
>>>
>>>>X <- matrix(rnorm(200), 100, 2)
>>>>y <- (X %*% c(1,2) + rnorm(100)) > 0
>>>>dat <- data.frame(y=y, X=X)
>>>>mod <- glm(y ~ X, family=binomial, data=dat) new <- data.frame(X = 
>>>>matrix(rnorm(20),2)) predict(mod, new)
>>
>>Dear John,
>>
>>the questioner had a 2 column matrix with 40 and one with 50 
>>observations (not a 100 column matrix with 2 observation) and 
>>for those matrices it works ...
>>
> 
> 
> Indeed, and in my example the matrix predictor X has 2 columns and 100 rows;
> I did screw up the matrix for the "new" data to be used for predictions (in
> the example I sent today but not yesterday), but even when this is done
> right -- where the new data has 10 rows and 2 columns -- there are 100 (not
> 10) predicted values:
> 
> 
>>X <- matrix(rnorm(200), 100, 2)  # original predictor matrix with 100 rows
>>y <- (X %*% c(1,2) + rnorm(100)) > 0
>>dat <- data.frame(y=y, X=X)
>>mod <- glm(y ~ X, family=binomial, data=dat)
>>new <- data.frame(X = matrix(rnorm(20),10, 2)) # corrected -- note 10 rows
>>predict(mod, new) # note 100 predicted values
> 
>            1            2            3            4            5
> 6 
>   5.75238091   0.31874587  -3.00515893  -3.77282121  -1.97511221
> 0.54712914 
>            7            8            9           10           11
> 12 
>   1.85091226   4.38465524  -0.41028694  -1.53942869   0.57613555
> -1.82761518 
> 
>  . . .
> 
>           91           92           93           94           95
> 96 
>   0.36210780   1.71358713  -9.63612775  -4.54257576  -5.29740468
> 2.64363405 
>           97           98           99          100 
>  -4.45478627  -2.44973209   2.51587537  -4.09584837 
> 
> Actually, I now see the source of the problem:
> 
> The data frames dat and new don't contain a matrix named "X"; rather the
> matrix is split columnwise:
> 
> 
>>names(dat)
> 
> [1] "y"   "X.1" "X.2"
> 
>>names(new)
> 
> [1] "X.1" "X.2"
> 
> Consequently, both glm and predict pick up the X in the global environment
> (since there is none in dat or new), which accounts for why there are 100
> predicted values.
> 
> Using list() rather than data.frame() produces the originally expected
> behaviour:
> 
> 
>>new <- list(X = matrix(rnorm(20),10, 2))
>>predict(mod, new)
> 
>          1          2          3          4          5          6          7
> 
>  5.9373064  0.3687360 -8.3793045  0.7645584 -2.6773842  2.4130547  0.7387318
> 
>          8          9         10 
> -0.4347916  8.4678728 -0.8976054 
> 
> Regards,
>  John
> 
> 
>>Best,
>>Uwe
>>
>>
>>
>>
>>
>>
>>
>>
>>>           1            2            3            4            5
>>>6 
>>>  1.81224443  -5.92955128   1.98718051 -10.05331521   2.65065555
>>>-2.50635812 
>>>           7            8            9           10           11
>>>12 
>>>  5.63728698  -0.94845276  -3.61657377  -1.63141320   5.03417372
>>>1.80400271 
>>>          13           14           15           16           17
>>>18 
>>>  9.32876273  -5.32723406   5.29373023  -3.90822713 -10.95065186
>>>4.90038016
>>>
>>> . . .
>>>
>>>           97           98           99          100 
>>> -6.92509812   0.59357486  -1.17205723   0.04209578 
>>>
>>>
>>>Note that there are 100 rather than 10 predicted values.
>>>
>>>But with individuals predictors (rather than a matrix),
>>>
>>>
>>>
>>>>x1 <- X[,1]
>>>>x2 <- X[,2]
>>>>dat.2 <- data.frame(y=y, x1=x1, x2=x2)
>>>>mod.2 <- glm(y ~ x1 + x2, family=binomial, data=dat.2)
>>>>new.2 <- data.frame(x1=rnorm(10), x2=rnorm(10)) 
>>
>>predict(mod.2, new.2)
>>
>>>         1          2          3          4          5      
>>
>>    6          7
>>
>>> 6.5723823  0.6356392  4.0291018 -4.7914650  2.1435485 -3.1738096 
>>>-2.8261585
>>>
>>>         8          9         10 
>>>-1.5255329 -4.7087592  4.0619290
>>>
>>>works as expected (?).
>>>
>>>Regards,
>>> John
>>> 
>>>
>>>
>>>
>>>>-----Original Message-----
>>>>From: r-help-bounces at stat.math.ethz.ch 
>>>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Uwe Ligges
>>>>Sent: Thursday, September 23, 2004 1:33 AM
>>>>To: jrausch at nd.edu
>>>>Cc: r-help at stat.math.ethz.ch
>>>>Subject: Re: [R] Issue with predict() for glm models
>>>>
>>>>jrausch at nd.edu wrote:
>>>>
>>>>
>>>>
>>>>>Hello everyone,
>>>>>
>>>>>I am having a problem using the predict (or the
>>>>
>>>>predict.glm) function in R.
>>>>
>>>>
>>>>>Basically, I run the glm model on a "training" data set and try to 
>>>>>obtain predictions for a set of new predictors from a
>>>>
>>>>"test" data set
>>>>
>>>>
>>>>>(i.e., not the predictors that were utilized to obtain the
>>>>
>>>>glm parameter estimates).
>>>>
>>>>
>>>>>Unfortunately, every time that I attempt this, I obtain the 
>>>>>predictions for the predictors that were used to fit the
>>>>
>>>>glm model. I
>>>>
>>>>
>>>>>have looked at the R mailing list archives and don't believe I am 
>>>>>making the same mistakes that have been made in the past
>>>>
>>>>and also have
>>>>
>>>>
>>>>>tried to closely follow the predict.glm example in the help
>>>>
>>>>file. Here is an example of what I am trying to do:
>>>>
>>>>
>>>>>########################################################
>>>>>set.seed(545345)
>>>>>
>>>>>################
>>>>># Necessary Variables #
>>>>>################
>>>>>
>>>>>p <- 2
>>>>>train.n <- 20
>>>>>test.n <- 25
>>>>>mean.vec.1 <- c(1,1)
>>>>>mean.vec.2 <- c(0,0)
>>>>>
>>>>>Sigma.1 <- matrix(c(1,.5,.5,1),p,p)
>>>>>Sigma.2 <- matrix(c(1,.5,.5,1),p,p)
>>>>>
>>>>>###############
>>>>># Load MASS Library #
>>>>>###############
>>>>>
>>>>>library(MASS)
>>>>>
>>>>>###################################
>>>>># Data to Parameters for Logistic Regression Model # 
>>>>>###################################
>>>>>
>>>>>train.data.1 <- mvrnorm(train.n,mu=mean.vec.1,Sigma=Sigma.1)
>>>>>train.data.2 <- mvrnorm(train.n,mu=mean.vec.2,Sigma=Sigma.2)
>>>>>train.class.var <- as.factor(c(rep(1,train.n),rep(2,train.n)))
>>>>>predictors.train <- rbind(train.data.1,train.data.2)
>>>>>
>>>>>##############################################
>>>>># Test Data Where Predictions for Probabilities Using
>>>>
>>>>Logistic Reg.  #
>>>>
>>>>
>>>>># From Training Data are of Interest                        
>>>>
>>>>                 #
>>>>
>>>>
>>>>>##############################################
>>>>>
>>>>>test.data.1 <- mvrnorm(test.n,mu=mean.vec.1,Sigma=Sigma.1)
>>>>>test.data.2 <- mvrnorm(test.n,mu=mean.vec.2,Sigma=Sigma.2)
>>>>>predictors.test <- rbind(test.data.1,test.data.2)
>>>>>
>>>>>##############################
>>>>># Run Logistic Regression on Training Data # 
>>>>>##############################
>>>>>
>>>>>log.reg <- glm(train.class.var~predictors.train,
>>>>>family=binomial(link="logit"))
>>>>
>>>>Well, you haven't specified the "data" argument, but given the two 
>>>>variables directly. Exactly those variables will be used in the
>>>>predict() step below! If you want the predict() step to work, use 
>>>>something like:
>>>>
>>>>  train <- data.frame(class = train.class.var,
>>>>                      predictors = predictors.train)
>>>>  log.reg <- glm(class ~ ., data = train,
>>>>                 family=binomial(link="logit"))
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>>log.reg
>>>>>
>>>>>#> log.reg
>>>>>
>>>>>#Call:  glm(formula = train.class.var ~ predictors.train, family = 
>>>>>#binomial(link = "logit")) #
>>>>>#Coefficients:
>>>>>#      (Intercept)  predictors.train1  predictors.train2  
>>>>>#           0.5105            -0.2945            -1.0811  
>>>>>#
>>>>>#Degrees of Freedom: 39 Total (i.e. Null);  37 Residual
>>>>>#Null Deviance:      55.45 
>>>>>#Residual Deviance: 41.67        AIC: 47.67 
>>>>>
>>>>>###########################
>>>>># Predicted Probabilities for Test Data #
>>>>
>>>>###########################
>>>>
>>>>
>>>>>New.Data <- data.frame(predictors.train1=predictors.test[,1],
>>>>>predictors.train2=predictors.test[,2])
>>>>>
>>>>>logreg.pred.prob.test <-
>>>>
>>>>predict.glm(log.reg,New.Data,type="response")
>>>>
>>>>
>>>>>logreg.pred.prob.test
>>>>
>>>>Instead, use:
>>>>
>>>>  test <- data.frame(predictors = predictors.test)
>>>>  predict(log.reg, newdata = test, type="response")
>>>>
>>>>
>>>>note also: please call the generic predict() rather than its glm 
>>>>method.
>>>>
>>>>
>>>>Uwe Ligges
>>>>
>>>>
>>>>
>>>>
>>>>>#logreg.pred.prob.test
>>>>># [1] 0.51106406 0.15597423 0.04948404 0.03863875 0.35587589
>>>>>0.71331091 # [7] 0.17320087 0.14176632 0.30966718 0.61878952
>>>>>0.12525988 0.21271139 #[13] 0.70068113 0.18340723 0.10295501
>>>>>0.44591568 0.72285161 0.31499339 #[19] 0.65789420 0.42750139
>>>>>0.14435889 0.93008117 0.70798465 0.80109005 #[25] 0.89161472
>>>>>0.47480625 0.56520952 0.63981834 0.57595189 0.60075882 #[31]
>>>>>0.96493393 0.77015507 0.87643986 0.62973986 0.63043351 0.45398955 
>>>>>#[37] 0.80855782 0.90835588 0.54809117 0.11568637 
>>>>>########################################################
>>>>>
>>>>>Of course, notice that the vector for the predicted
>>>>
>>>>probabilities has
>>>>
>>>>
>>>>>only 40 elements, while the "New.Data" has 50 elements
>>>>
>>>>(since n.test
>>>>
>>>>
>>>>>has 25 per group for 2 groups) and thus should have 50 predicted 
>>>>>probabilities. As it turns out, the output is for the 
>>
>>training data 
>>
>>>>>predictors and not for the "New.Data" as I would like it to be. I 
>>>>>should also note that I have made sure that the names for the 
>>>>>predictors in the "New.Data" are the same as the names for the 
>>>>>predictors within the glm object (i.e., within "log.reg")
>>>>
>>>>as this is what is done in the example for predict.glm() within the 
>>>>help files.
>>>>
>>>>
>>>>>Could some one help me understand either what I am doing
>>>>
>>>>incorrectly
>>>>
>>>>
>>>>>or what problems there might be within the predict() function? I 
>>>>>should mention that I tried the same program using
>>>>
>>>>predict.glm() and
>>>>
>>>>
>>>>>obtained the same problematic results.
>>>>>
>>>>>Thanks and take care,
>>>>>
>>>>>Joe
>>>>>
>>>>>
>>>>>Joe Rausch, M.A. 
>>>>>Psychology Liaison
>>>>>Lab for Social Research
>>>>>917 Flanner Hall
>>>>>University of Notre Dame
>>>>>Notre Dame, IN 46556
>>>>>(574) 631-3910
>>>>>
>>>>>"If we knew what it was we were doing, it would not be called 
>>>>>research, would it?"
>>>>>- Albert Einstein
>>>>>
>>>>>______________________________________________
>>>>>R-help at stat.math.ethz.ch mailing list 
>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>PLEASE do read the posting guide! 
>>>>>http://www.R-project.org/posting-guide.html
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! 
>>>>http://www.R-project.org/posting-guide.html
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From pauljohn at ku.edu  Thu Sep 23 19:04:26 2004
From: pauljohn at ku.edu (Paul Johnson)
Date: Thu, 23 Sep 2004 12:04:26 -0500
Subject: [R] R glm
In-Reply-To: <C9FC71F7E9356F40AFE2ACC2099DE1471496B9@MAILSERVER-B.mpsgr.it>
References: <C9FC71F7E9356F40AFE2ACC2099DE1471496B9@MAILSERVER-B.mpsgr.it>
Message-ID: <4153021A.8060406@ku.edu>

No!

 > ?family

  The 'gaussian' family accepts the links '"identity"', '"log"' and
           '"inverse"';

Kahra Hannu wrote:
> In Venables & Ripley: Modern Applied Statistics with S (MASS), (4th edition), on page 184 there is a table "Families and link functions" that gives you the available links with different families. The default and the only link with the gaussian family is identity.
> 
> ciao,
> Hannu Kahra
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Shuangge Ma
> Sent: Thursday, September 23, 2004 6:26 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] R glm
> 
> 
> Hello:
> would you please help me with the following glm question?
> 
> for the R function glm, what I understand is: once you specify the
> "family", then the link function is fixed.
> 
> My question is: is it possible I use, for example, "log" link function,
> but the estimation approach for the guassian family?
> 
> Thanks,
> 
> Shuangge Ma, Ph.D.
> ********************************************
> * CHSCC, Department of Biostatistics       *
> * University of Washington                 *
> * Building 29, Suite 310, 6200 NE 74th ST. *
> * Seattle, WA 98115                        *
> * Tel: 206-685-7123 Fax: 206-616-4075      *
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From maustin at amgen.com  Thu Sep 23 19:20:09 2004
From: maustin at amgen.com (Austin, Matt)
Date: Thu, 23 Sep 2004 10:20:09 -0700
Subject: followup: Re: [R] Issue with predict() for glm models
Message-ID: <E7D5AB4811D20B489622AABA9C53859101F112FD@teal-exch.amgen.com>

Could you just use

lines(newX, myPred, col=2)

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Paul Johnson
Sent: Thursday, September 23, 2004 10:3 AM
To: r help
Subject: followup: Re: [R] Issue with predict() for glm models


I have a follow up question that fits with this thread.

Can you force an overlaid plot showing predicted values to follow the 
scaling of the axes of the plot over which it is laid?

Here is an example based on linear regression, just for clarity.  I have 
followed the procedure described below to create predictions and now 
want to plot the predicted values "on top" of a small section of the x-y 
scatterplot.

x <- rnorm(100, 10, 10)
e <- rnorm(100, 0, 5)
y <- 5 + 10 *x + e

myReg1 <- lm (y~x)
plot(x,y)
newX <- seq(1,10,1)
myPred <- predict(myReg1,data.frame(x=newX))

Now, if I do this, I get 2 graphs "overlaid" but their axes do not "line 
up".

par(new=T)
plot(newX,myPred$fit)

The problem is that the second one uses the "whole width" of the graph 
space, when I'd rather just have it go from the small subset where its x 
is defined, from 1 to 10.  Its stretching the range (1,10) for newX to 
use the same scale that goes from (-15, 35) where it plots x

I know abline() can do this for lm, but for some other kinds of models, 
no  lines() method is provided, and so I am doing this the old fashioned 
way.

pj

John Fox wrote:
> Dear Uwe, 
> 
> 
>>-----Original Message-----
>>From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
>>Sent: Thursday, September 23, 2004 8:06 AM
>>To: John Fox
>>Cc: jrausch at nd.edu; r-help at stat.math.ethz.ch
>>Subject: Re: [R] Issue with predict() for glm models
>>
>>John Fox wrote:
>>
>>
>>>Dear Uwe,
>>>
>>>Unless I've somehow messed this up, as I mentioned 
>>
>>yesterday, what you 
>>
>>>suggest doesn't seem to work when the predictor is a 
>>
>>matrix. Here's a 
>>
>>>simplified example:
>>>
>>>
>>>
>>>>X <- matrix(rnorm(200), 100, 2)
>>>>y <- (X %*% c(1,2) + rnorm(100)) > 0
>>>>dat <- data.frame(y=y, X=X)
>>>>mod <- glm(y ~ X, family=binomial, data=dat) new <- data.frame(X = 
>>>>matrix(rnorm(20),2)) predict(mod, new)
>>
>>Dear John,
>>
>>the questioner had a 2 column matrix with 40 and one with 50 
>>observations (not a 100 column matrix with 2 observation) and 
>>for those matrices it works ...
>>
> 
> 
> Indeed, and in my example the matrix predictor X has 2 columns and 100
rows;
> I did screw up the matrix for the "new" data to be used for predictions
(in
> the example I sent today but not yesterday), but even when this is done
> right -- where the new data has 10 rows and 2 columns -- there are 100
(not
> 10) predicted values:
> 
> 
>>X <- matrix(rnorm(200), 100, 2)  # original predictor matrix with 100 rows
>>y <- (X %*% c(1,2) + rnorm(100)) > 0
>>dat <- data.frame(y=y, X=X)
>>mod <- glm(y ~ X, family=binomial, data=dat)
>>new <- data.frame(X = matrix(rnorm(20),10, 2)) # corrected -- note 10 rows
>>predict(mod, new) # note 100 predicted values
> 
>            1            2            3            4            5
> 6 
>   5.75238091   0.31874587  -3.00515893  -3.77282121  -1.97511221
> 0.54712914 
>            7            8            9           10           11
> 12 
>   1.85091226   4.38465524  -0.41028694  -1.53942869   0.57613555
> -1.82761518 
> 
>  . . .
> 
>           91           92           93           94           95
> 96 
>   0.36210780   1.71358713  -9.63612775  -4.54257576  -5.29740468
> 2.64363405 
>           97           98           99          100 
>  -4.45478627  -2.44973209   2.51587537  -4.09584837 
> 
> Actually, I now see the source of the problem:
> 
> The data frames dat and new don't contain a matrix named "X"; rather the
> matrix is split columnwise:
> 
> 
>>names(dat)
> 
> [1] "y"   "X.1" "X.2"
> 
>>names(new)
> 
> [1] "X.1" "X.2"
> 
> Consequently, both glm and predict pick up the X in the global environment
> (since there is none in dat or new), which accounts for why there are 100
> predicted values.
> 
> Using list() rather than data.frame() produces the originally expected
> behaviour:
> 
> 
>>new <- list(X = matrix(rnorm(20),10, 2))
>>predict(mod, new)
> 
>          1          2          3          4          5          6
7
> 
>  5.9373064  0.3687360 -8.3793045  0.7645584 -2.6773842  2.4130547
0.7387318
> 
>          8          9         10 
> -0.4347916  8.4678728 -0.8976054 
> 
> Regards,
>  John
> 
> 
>>Best,
>>Uwe
>>
>>
>>
>>
>>
>>
>>
>>
>>>           1            2            3            4            5
>>>6 
>>>  1.81224443  -5.92955128   1.98718051 -10.05331521   2.65065555
>>>-2.50635812 
>>>           7            8            9           10           11
>>>12 
>>>  5.63728698  -0.94845276  -3.61657377  -1.63141320   5.03417372
>>>1.80400271 
>>>          13           14           15           16           17
>>>18 
>>>  9.32876273  -5.32723406   5.29373023  -3.90822713 -10.95065186
>>>4.90038016
>>>
>>> . . .
>>>
>>>           97           98           99          100 
>>> -6.92509812   0.59357486  -1.17205723   0.04209578 
>>>
>>>
>>>Note that there are 100 rather than 10 predicted values.
>>>
>>>But with individuals predictors (rather than a matrix),
>>>
>>>
>>>
>>>>x1 <- X[,1]
>>>>x2 <- X[,2]
>>>>dat.2 <- data.frame(y=y, x1=x1, x2=x2)
>>>>mod.2 <- glm(y ~ x1 + x2, family=binomial, data=dat.2)
>>>>new.2 <- data.frame(x1=rnorm(10), x2=rnorm(10)) 
>>
>>predict(mod.2, new.2)
>>
>>>         1          2          3          4          5      
>>
>>    6          7
>>
>>> 6.5723823  0.6356392  4.0291018 -4.7914650  2.1435485 -3.1738096 
>>>-2.8261585
>>>
>>>         8          9         10 
>>>-1.5255329 -4.7087592  4.0619290
>>>
>>>works as expected (?).
>>>
>>>Regards,
>>> John
>>> 
>>>
>>>
>>>
>>>>-----Original Message-----
>>>>From: r-help-bounces at stat.math.ethz.ch 
>>>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Uwe Ligges
>>>>Sent: Thursday, September 23, 2004 1:33 AM
>>>>To: jrausch at nd.edu
>>>>Cc: r-help at stat.math.ethz.ch
>>>>Subject: Re: [R] Issue with predict() for glm models
>>>>
>>>>jrausch at nd.edu wrote:
>>>>
>>>>
>>>>
>>>>>Hello everyone,
>>>>>
>>>>>I am having a problem using the predict (or the
>>>>
>>>>predict.glm) function in R.
>>>>
>>>>
>>>>>Basically, I run the glm model on a "training" data set and try to 
>>>>>obtain predictions for a set of new predictors from a
>>>>
>>>>"test" data set
>>>>
>>>>
>>>>>(i.e., not the predictors that were utilized to obtain the
>>>>
>>>>glm parameter estimates).
>>>>
>>>>
>>>>>Unfortunately, every time that I attempt this, I obtain the 
>>>>>predictions for the predictors that were used to fit the
>>>>
>>>>glm model. I
>>>>
>>>>
>>>>>have looked at the R mailing list archives and don't believe I am 
>>>>>making the same mistakes that have been made in the past
>>>>
>>>>and also have
>>>>
>>>>
>>>>>tried to closely follow the predict.glm example in the help
>>>>
>>>>file. Here is an example of what I am trying to do:
>>>>
>>>>
>>>>>########################################################
>>>>>set.seed(545345)
>>>>>
>>>>>################
>>>>># Necessary Variables #
>>>>>################
>>>>>
>>>>>p <- 2
>>>>>train.n <- 20
>>>>>test.n <- 25
>>>>>mean.vec.1 <- c(1,1)
>>>>>mean.vec.2 <- c(0,0)
>>>>>
>>>>>Sigma.1 <- matrix(c(1,.5,.5,1),p,p)
>>>>>Sigma.2 <- matrix(c(1,.5,.5,1),p,p)
>>>>>
>>>>>###############
>>>>># Load MASS Library #
>>>>>###############
>>>>>
>>>>>library(MASS)
>>>>>
>>>>>###################################
>>>>># Data to Parameters for Logistic Regression Model # 
>>>>>###################################
>>>>>
>>>>>train.data.1 <- mvrnorm(train.n,mu=mean.vec.1,Sigma=Sigma.1)
>>>>>train.data.2 <- mvrnorm(train.n,mu=mean.vec.2,Sigma=Sigma.2)
>>>>>train.class.var <- as.factor(c(rep(1,train.n),rep(2,train.n)))
>>>>>predictors.train <- rbind(train.data.1,train.data.2)
>>>>>
>>>>>##############################################
>>>>># Test Data Where Predictions for Probabilities Using
>>>>
>>>>Logistic Reg.  #
>>>>
>>>>
>>>>># From Training Data are of Interest                        
>>>>
>>>>                 #
>>>>
>>>>
>>>>>##############################################
>>>>>
>>>>>test.data.1 <- mvrnorm(test.n,mu=mean.vec.1,Sigma=Sigma.1)
>>>>>test.data.2 <- mvrnorm(test.n,mu=mean.vec.2,Sigma=Sigma.2)
>>>>>predictors.test <- rbind(test.data.1,test.data.2)
>>>>>
>>>>>##############################
>>>>># Run Logistic Regression on Training Data # 
>>>>>##############################
>>>>>
>>>>>log.reg <- glm(train.class.var~predictors.train,
>>>>>family=binomial(link="logit"))
>>>>
>>>>Well, you haven't specified the "data" argument, but given the two 
>>>>variables directly. Exactly those variables will be used in the
>>>>predict() step below! If you want the predict() step to work, use 
>>>>something like:
>>>>
>>>>  train <- data.frame(class = train.class.var,
>>>>                      predictors = predictors.train)
>>>>  log.reg <- glm(class ~ ., data = train,
>>>>                 family=binomial(link="logit"))
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>>log.reg
>>>>>
>>>>>#> log.reg
>>>>>
>>>>>#Call:  glm(formula = train.class.var ~ predictors.train, family = 
>>>>>#binomial(link = "logit")) #
>>>>>#Coefficients:
>>>>>#      (Intercept)  predictors.train1  predictors.train2  
>>>>>#           0.5105            -0.2945            -1.0811  
>>>>>#
>>>>>#Degrees of Freedom: 39 Total (i.e. Null);  37 Residual
>>>>>#Null Deviance:      55.45 
>>>>>#Residual Deviance: 41.67        AIC: 47.67 
>>>>>
>>>>>###########################
>>>>># Predicted Probabilities for Test Data #
>>>>
>>>>###########################
>>>>
>>>>
>>>>>New.Data <- data.frame(predictors.train1=predictors.test[,1],
>>>>>predictors.train2=predictors.test[,2])
>>>>>
>>>>>logreg.pred.prob.test <-
>>>>
>>>>predict.glm(log.reg,New.Data,type="response")
>>>>
>>>>
>>>>>logreg.pred.prob.test
>>>>
>>>>Instead, use:
>>>>
>>>>  test <- data.frame(predictors = predictors.test)
>>>>  predict(log.reg, newdata = test, type="response")
>>>>
>>>>
>>>>note also: please call the generic predict() rather than its glm 
>>>>method.
>>>>
>>>>
>>>>Uwe Ligges
>>>>
>>>>
>>>>
>>>>
>>>>>#logreg.pred.prob.test
>>>>># [1] 0.51106406 0.15597423 0.04948404 0.03863875 0.35587589
>>>>>0.71331091 # [7] 0.17320087 0.14176632 0.30966718 0.61878952
>>>>>0.12525988 0.21271139 #[13] 0.70068113 0.18340723 0.10295501
>>>>>0.44591568 0.72285161 0.31499339 #[19] 0.65789420 0.42750139
>>>>>0.14435889 0.93008117 0.70798465 0.80109005 #[25] 0.89161472
>>>>>0.47480625 0.56520952 0.63981834 0.57595189 0.60075882 #[31]
>>>>>0.96493393 0.77015507 0.87643986 0.62973986 0.63043351 0.45398955 
>>>>>#[37] 0.80855782 0.90835588 0.54809117 0.11568637 
>>>>>########################################################
>>>>>
>>>>>Of course, notice that the vector for the predicted
>>>>
>>>>probabilities has
>>>>
>>>>
>>>>>only 40 elements, while the "New.Data" has 50 elements
>>>>
>>>>(since n.test
>>>>
>>>>
>>>>>has 25 per group for 2 groups) and thus should have 50 predicted 
>>>>>probabilities. As it turns out, the output is for the 
>>
>>training data 
>>
>>>>>predictors and not for the "New.Data" as I would like it to be. I 
>>>>>should also note that I have made sure that the names for the 
>>>>>predictors in the "New.Data" are the same as the names for the 
>>>>>predictors within the glm object (i.e., within "log.reg")
>>>>
>>>>as this is what is done in the example for predict.glm() within the 
>>>>help files.
>>>>
>>>>
>>>>>Could some one help me understand either what I am doing
>>>>
>>>>incorrectly
>>>>
>>>>
>>>>>or what problems there might be within the predict() function? I 
>>>>>should mention that I tried the same program using
>>>>
>>>>predict.glm() and
>>>>
>>>>
>>>>>obtained the same problematic results.
>>>>>
>>>>>Thanks and take care,
>>>>>
>>>>>Joe
>>>>>
>>>>>
>>>>>Joe Rausch, M.A. 
>>>>>Psychology Liaison
>>>>>Lab for Social Research
>>>>>917 Flanner Hall
>>>>>University of Notre Dame
>>>>>Notre Dame, IN 46556
>>>>>(574) 631-3910
>>>>>
>>>>>"If we knew what it was we were doing, it would not be called 
>>>>>research, would it?"
>>>>>- Albert Einstein
>>>>>
>>>>>______________________________________________
>>>>>R-help at stat.math.ethz.ch mailing list 
>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>PLEASE do read the posting guide! 
>>>>>http://www.R-project.org/posting-guide.html
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! 
>>>>http://www.R-project.org/posting-guide.html
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html


-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From jeaneid at chass.utoronto.ca  Thu Sep 23 19:43:16 2004
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Thu, 23 Sep 2004 13:43:16 -0400
Subject: [R] gsub
In-Reply-To: <loom.20040923T162619-708@post.gmane.org>
Message-ID: <Pine.SGI.4.40.0409231340200.37184933-100000@origin.chass.utoronto.ca>

Thank you all for the help, specially Gabor that is exactly what I needed.
A few examples that do the same thing is very helpful in understanding the
structure of the call.


Thank you again,


Jean

 On Thu, 23 Sep 2004, Gabor Grothendieck wrote:

> Jean Eid <jeaneid <at> chass.utoronto.ca> writes:
>
> :
> : Hi
> :
> : A while back I used gsub to do the following
> :
> : temp<-"000US00231"
> : gsub("something here", "", temp)
> : "00231"
> :
> : I think it involved the `meta characters' somehow.
> :
> : I do not know how to do this anymore. I know strsplit will also work but I
> : remember gsub was much faster.  In essence the question is how to delete
> : all characters before a particular pattern.
> :
> : If anyone has some help file for this, it will be greatly appreciated.
> :
>
> I think you want sub in this case, not gsub.
>
> There are many possibilities here depending on what the
> general case is.  The following all give the desired
> result for the example but their general cases differ.
> These are just some of the numerous variations possible.
>
> temp<-"000US00231"
> sub(".*US", "", temp)
> sub(".*S", "", temp)
> sub("[[:digit:]]*[[:alpha:]]*", "", temp)
> sub(".*[[:alpha:]]", "", temp)
> sub(".*[[:alpha:]][[:alpha:]]", "", temp)
> sub(".*[[:upper:]]", "", temp)
> sub(".*[[:upper:]][[:upper:]]", "", temp)
> sub(".....", "", temp)
> substring(temp, 6)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From HStevens at MUOhio.edu  Thu Sep 23 19:38:31 2004
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Thu, 23 Sep 2004 13:38:31 -0400
Subject: [R] R glm
In-Reply-To: <4153021A.8060406@ku.edu>
References: <C9FC71F7E9356F40AFE2ACC2099DE1471496B9@MAILSERVER-B.mpsgr.it>
	<4153021A.8060406@ku.edu>
Message-ID: <630AA368-0D87-11D9-9988-000A958F43CC@MUOhio.edu>

Upon examining Table 7.1 on page 184 of V&R 4th edition, I can see 
where the ambiguity would arise, however. Always best to check the 
help, I guess.
Hank
On Sep 23, 2004, at 1:04 PM, Paul Johnson wrote:

> No!
>
> > ?family
>
>  The 'gaussian' family accepts the links '"identity"', '"log"' and
>           '"inverse"';
>
> Kahra Hannu wrote:
>> In Venables & Ripley: Modern Applied Statistics with S (MASS), (4th 
>> edition), on page 184 there is a table "Families and link functions" 
>> that gives you the available links with different families. The 
>> default and the only link with the gaussian family is identity.
>> ciao,
>> Hannu Kahra
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Shuangge Ma
>> Sent: Thursday, September 23, 2004 6:26 PM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] R glm
>> Hello:
>> would you please help me with the following glm question?
>> for the R function glm, what I understand is: once you specify the
>> "family", then the link function is fixed.
>> My question is: is it possible I use, for example, "log" link 
>> function,
>> but the estimation approach for the guassian family?
>> Thanks,
>> Shuangge Ma, Ph.D.
>> ********************************************
>> * CHSCC, Department of Biostatistics       *
>> * University of Washington                 *
>> * Building 29, Suite 310, 6200 NE 74th ST. *
>> * Seattle, WA 98115                        *
>> * Tel: 206-685-7123 Fax: 206-616-4075      *
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
> -- 
> Paul E. Johnson                       email: pauljohn at ku.edu
> Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
> 1541 Lilac Lane, Rm 504
> University of Kansas                  Office: (785) 864-9086
> Lawrence, Kansas 66044-3177           FAX: (785) 864-5700
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>
Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From MSchwartz at MedAnalytics.com  Thu Sep 23 19:42:32 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 23 Sep 2004 12:42:32 -0500
Subject: followup: Re: [R] Issue with predict() for glm models
In-Reply-To: <415301C1.6070207@ku.edu>
References: <20040923142232.SACR25796.tomts36-srv.bellnexxia.net@JohnDesktop8300>
	<415301C1.6070207@ku.edu>
Message-ID: <1095961351.20401.104.camel@localhost.localdomain>

On Thu, 2004-09-23 at 12:02, Paul Johnson wrote:
> I have a follow up question that fits with this thread.
> 
> Can you force an overlaid plot showing predicted values to follow the 
> scaling of the axes of the plot over which it is laid?
> 
> Here is an example based on linear regression, just for clarity.  I have 
> followed the procedure described below to create predictions and now 
> want to plot the predicted values "on top" of a small section of the x-y 
> scatterplot.
> 
> x <- rnorm(100, 10, 10)
> e <- rnorm(100, 0, 5)
> y <- 5 + 10 *x + e
> 
> myReg1 <- lm (y~x)
> plot(x,y)
> newX <- seq(1,10,1)
> myPred <- predict(myReg1,data.frame(x=newX))
> 
> Now, if I do this, I get 2 graphs "overlaid" but their axes do not "line 
> up".
> 
> par(new=T)
> plot(newX,myPred$fit)
> 
> The problem is that the second one uses the "whole width" of the graph 
> space, when I'd rather just have it go from the small subset where its x 
> is defined, from 1 to 10.  Its stretching the range (1,10) for newX to 
> use the same scale that goes from (-15, 35) where it plots x
> 
> I know abline() can do this for lm, but for some other kinds of models, 
> no  lines() method is provided, and so I am doing this the old fashioned 
> way.

Paul,

Instead of using plot() for the second set of points, use points():

x <- rnorm(100, 10, 10)
e <- rnorm(100, 0, 5)
y <- 5 + 10 * x + e

myReg1 <- lm (y ~ x)
plot(x, y)

newX <- seq(1, 10, 1)
myPred <- predict(myReg1, data.frame(x = newX))

points(newX, myPred$fit, pch = 19)


This will preserve the axis scaling. If you use plot() without
explicitly indicating xlim and ylim, it will automatically scale the
axes based upon your new data, even if you indicated that the underlying
plot should not be cleared.

Alternatively, you could also use the lines() function, which will draw
point to point lines:

lines(newX, myPred$fit, col = "red")

If you want fitted lines and prediction/confidence intervals, you could
use a function like matlines(), presuming that a predict method exists
for the model type you want to use.

There is an example of using this in "R Help Desk" in R News Vol 3
Number 2 (October 2003), in the first example, with a standard linear
regression model.

HTH,

Marc Schwartz



From ritz at dina.kvl.dk  Thu Sep 23 19:52:15 2004
From: ritz at dina.kvl.dk (Christian Ritz)
Date: Thu, 23 Sep 2004 19:52:15 +0200
Subject: [R] fitting weibull distribution
References: <1095957180.7733.4.camel@snowdon.science.uva.nl>
Message-ID: <004b01c4a196$10380690$3ba23e50@santamaria>

Hi.

I think there may be one or more zeros in your data set, causing the
problem:

x <- rgamma(100)
fitdistr(x, "weibull")
fitdistr(c(x,0), "weibull")

Maybe you should omit the zeros.

Christian



From jfox at mcmaster.ca  Thu Sep 23 20:08:50 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 23 Sep 2004 14:08:50 -0400
Subject: [R] Issue with predict() for glm models
In-Reply-To: <4152FBB0.5050503@statistik.uni-dortmund.de>
Message-ID: <20040923180847.XQER25796.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Uwe, 

> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
> Sent: Thursday, September 23, 2004 11:37 AM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Issue with predict() for glm models
> 
. . .

> 
> John,
> 
> note that I used glm(y ~ .) (the dot!),
> because the names are automatically chosen to be X.1 and X.2, 
> hence you cannot use "X" in the formula in this case ...
> 
> Best,
> Uwe

OK -- I see. I did notice that you used . in the formula but didn't make the
proper connection!

Thanks,
 John



From strivens at bcm.tmc.edu  Thu Sep 23 20:08:53 2004
From: strivens at bcm.tmc.edu (Mark Strivens)
Date: Thu, 23 Sep 2004 13:08:53 -0500
Subject: [R] decompose a correlation matrix
Message-ID: <EMEFKCCDELAAHINIPAJHAEFJCAAA.strivens@bcm.tmc.edu>

Is there a simple way to decompose the upper triangle
of a correlation matrix to a linear list;

For example:

  X Y Z
X 1 2 3
Y 2 1 4
Z 3 4 1

so you get a list like:

xy 2
XZ 3
YZ 4

I suspect you can do it with a matrix transformation, but
that beyond me at present.

Many thanks

Mark
_________________________
Department of Molecular and Human Genetics,
Baylor College of Medicine,



From brandt at unt.edu  Thu Sep 23 20:24:12 2004
From: brandt at unt.edu (Patrick Brandt)
Date: Thu, 23 Sep 2004 13:24:12 -0500
Subject: [R] R vs EViews - serial correlation
In-Reply-To: <8723194734.20040923172924@mif.vu.lt>
References: <222021406.20040923170950@mif.vu.lt>
	<8723194734.20040923172924@mif.vu.lt>
Message-ID: <415314CC.1020803@unt.edu>

The issue here is that you have confused an AR(1) process for the 
variable of interest with an AR(1) process for its residuals.  The 
former is a true AR(1) process, while the latter is really an MA(1) 
process, in terms of Box-Jenkins style ARIMA models.

Interpreting your original post:

> I met with some problems when dealing with a time series with serial correlation.
> 
> FIRST, I generate a series with correlated errors
> 
> set.seed(1)
> x=1:50
> y=x+arima.sim(n = 50, list(ar = c(0.47)))


This generates an ARIMA(1,0,0) dataset of 50 observations.  So the d.v. 
has an AR(1) process.

> 
> SECOND, I estimate three constants (a, b and rho) in the model Y=a+b*X+u, where u=rho*u(-1)+eps
>  
> library(nlme)
> gls(y~x,correlation = corAR1(0.5))     # Is it the right procedure?
> 
> Coefficients:
> (Intercept)           x 
>   0.1410465   1.0023341 
> 
> Correlation Structure: AR(1)
>  Formula: ~1 
>  Parameter estimate(s):
>      Phi 
> 0.440594 
> Degrees of freedom: 50 total; 48 residual
> Residual standard error: 0.9835158
> 


This estimates an AR(1) error process model -- or an ARIMA(0,0,1).  By 
the Wold decomposition, the AR(1) dgp we should expect the MA(q) process 
to have a longer order than 1.

> THIRD, I do the same procedure with EViews as LS Y C X AR(1) and get
> Y = 0.1375 + 1.0024*X + [AR(1)=0.3915]
> 

This fits an AR(1) error process (ARIMA(0,0,1)) if I recall my Eviews 
syntax.

> My problem is actually connected with the fitting procedure. As far as I understand 
> 
> gls(y~x,correlation = corAR1(0.5))$fit
> 
> is obtained through the linear equation 0.1410+1.0023*X while in EViews through the nonlinear equation 
> 
> Y=rho*Y(-1) + (1-rho)*a+(X-rho*X(-1))*b
> 
> where either dynamic or static fitting procedures are applied. 
> 
>     X       Y    YF_D    YF_S gls.fit
> 1   1  1.1592      NA      NA  1.1434
> 2   2  3.5866  2.1499  2.1499  2.1457
> 3   3  4.1355  3.1478  3.7103  3.1480
> 4   4  3.9125  4.1484  4.5352  4.1504
> 5   5  2.7442  5.1502  5.0578  5.1527
> 6   6  6.0647  6.1523  5.2103  6.1551
> 7   7  6.9855  7.1547  7.1203  7.1574
> .....................................
> 47 47 49.4299 47.2521 47.5288 47.2507
> 48 48 48.7748 48.2545 49.1072 48.2531
> 49 49 48.3200 49.2570 49.4607 49.2554
> 50 50 50.2501 50.2594 49.8926 50.2578

Again, both of the models you fit are NOT the DGP you simulated.

> 
> All gls.fit values are on a line, YF_D (D for dynamic) soon begin
> to follow a line and YF_S try to mimic Y.
> 

Correct since you are fitting a model of correlated INNOVATIONS, rather 
than a model of correlated Y's

> My question is: do R and EViews estimate the same model? If yes, why
> the estimates are different and which of the two (three?) procedures
> is "correct"?
> 

If you want to fit the DGP you proposed above, you should use

arima(y, order=c(1,0,0), xreg=x)

Hope that helps.

-- 
Patrick T. Brandt
Assistant Professor
Department of Political Science
University of North Texas
brandt at unt.edu
http://www.psci.unt.edu/~brandt



From murdoch at stats.uwo.ca  Thu Sep 23 20:39:10 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 23 Sep 2004 14:39:10 -0400
Subject: [R] decompose a correlation matrix
In-Reply-To: <EMEFKCCDELAAHINIPAJHAEFJCAAA.strivens@bcm.tmc.edu>
References: <EMEFKCCDELAAHINIPAJHAEFJCAAA.strivens@bcm.tmc.edu>
Message-ID: <4r56l05aghivt8i1vmsvsgfc5ptdcgm37v@4ax.com>

On Thu, 23 Sep 2004 13:08:53 -0500, "Mark Strivens"
<strivens at bcm.tmc.edu> wrote :

>Is there a simple way to decompose the upper triangle
>of a correlation matrix to a linear list;
>
>For example:
>
>  X Y Z
>X 1 2 3
>Y 2 1 4
>Z 3 4 1
>
>so you get a list like:
>
>xy 2
>XZ 3
>YZ 4
>
>I suspect you can do it with a matrix transformation, but
>that beyond me at present.

x[ row(x) < col(x) ]

will give the entries you want.

Duncan Murdoch



From andy_liaw at merck.com  Thu Sep 23 20:40:01 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 23 Sep 2004 14:40:01 -0400
Subject: [R] R glm
Message-ID: <3A822319EB35174CA3714066D590DCD504AF840A@usrymx25.merck.com>

As ?glm says, see ?family.

Andy

> From: Kahra Hannu
> 
> In Venables & Ripley: Modern Applied Statistics with S 
> (MASS), (4th edition), on page 184 there is a table "Families 
> and link functions" that gives you the available links with 
> different families. The default and the only link with the 
> gaussian family is identity.
> 
> ciao,
> Hannu Kahra
> 
> From: Shuangge Ma
> 
> Hello:
> would you please help me with the following glm question?
> 
> for the R function glm, what I understand is: once you specify the
> "family", then the link function is fixed.
> 
> My question is: is it possible I use, for example, "log" link 
> function,
> but the estimation approach for the guassian family?
> 
> Thanks,
> 
> Shuangge Ma, Ph.D.
> ********************************************
> * CHSCC, Department of Biostatistics       *
> * University of Washington                 *
> * Building 29, Suite 310, 6200 NE 74th ST. *
> * Seattle, WA 98115                        *
> * Tel: 206-685-7123 Fax: 206-616-4075      *
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From RBaskin at ahrq.gov  Thu Sep 23 20:44:38 2004
From: RBaskin at ahrq.gov (Baskin, Robert)
Date: Thu, 23 Sep 2004 14:44:38 -0400
Subject: [R] decompose a correlation matrix
Message-ID: <6BCD3F430455B1418750004BCD2792590292634C@exchange2.ahrq.gov>

This may not have things in the order you want but you can see if it gets
close to what you want:

> x <- matrix(1:16,ncol=4)
> x
     [,1] [,2] [,3] [,4]
[1,]    1    5    9   13
[2,]    2    6   10   14
[3,]    3    7   11   15
[4,]    4    8   12   16
> y <- x[row(x) < col(x)]
> y
[1]  5  9 10 13 14 15
> 

bob



-----Original Message-----
From: Mark Strivens [mailto:strivens at bcm.tmc.edu] 
Sent: Thursday, September 23, 2004 2:09 PM
To: r-help at stat.math.ethz.ch
Subject: [R] decompose a correlation matrix


Is there a simple way to decompose the upper triangle
of a correlation matrix to a linear list;

For example:

  X Y Z
X 1 2 3
Y 2 1 4
Z 3 4 1

so you get a list like:

xy 2
XZ 3
YZ 4

I suspect you can do it with a matrix transformation, but
that beyond me at present.

Many thanks

Mark
_________________________
Department of Molecular and Human Genetics,
Baylor College of Medicine,

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From strivens at bcm.tmc.edu  Thu Sep 23 20:46:13 2004
From: strivens at bcm.tmc.edu (Mark Strivens)
Date: Thu, 23 Sep 2004 13:46:13 -0500
Subject: [R] decompose a correlation matrix
Message-ID: <EMEFKCCDELAAHINIPAJHKEFKCAAA.strivens@bcm.tmc.edu>

Thanks for the answers the appear to be just
right. 

i.e. 

corrmat[upper.tri(corrmat)]

or

x[col(x)>row(x)] 

The slight problem is I lose all the column &
row labels from the correlation matrix, so I 
am not sure of the order of the values (i.e.
which combination of markers the value 
represents).

Is there anyway to drag the labels along with
the value extraction?
_________________________
Department of Molecular and Human Genetics,
Baylor College of Medicine,



From andy_liaw at merck.com  Thu Sep 23 20:48:13 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 23 Sep 2004 14:48:13 -0400
Subject: [R] decompose a correlation matrix
Message-ID: <3A822319EB35174CA3714066D590DCD504AF840B@usrymx25.merck.com>

> From: Duncan Murdoch
> 
> On Thu, 23 Sep 2004 13:08:53 -0500, "Mark Strivens"
> <strivens at bcm.tmc.edu> wrote :
> 
> >Is there a simple way to decompose the upper triangle
> >of a correlation matrix to a linear list;
> >
> >For example:
> >
> >  X Y Z
> >X 1 2 3
> >Y 2 1 4
> >Z 3 4 1
> >
> >so you get a list like:
> >
> >xy 2
> >XZ 3
> >YZ 4
> >
> >I suspect you can do it with a matrix transformation, but
> >that beyond me at present.
> 
> x[ row(x) < col(x) ]
> 
> will give the entries you want.
> 
> Duncan Murdoch

Perhaps slightly more transparent:

x[upper.tri(x)]

or

x[lower.tri(x)]

Best,
Andy



From andy_liaw at merck.com  Thu Sep 23 21:04:44 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 23 Sep 2004 15:04:44 -0400
Subject: [R] decompose a correlation matrix
Message-ID: <3A822319EB35174CA3714066D590DCD504AF840C@usrymx25.merck.com>

> From: Mark Strivens
> 
> Thanks for the answers the appear to be just
> right. 
> 
> i.e. 
> 
> corrmat[upper.tri(corrmat)]
> 
> or
> 
> x[col(x)>row(x)] 
> 
> The slight problem is I lose all the column &
> row labels from the correlation matrix, so I 
> am not sure of the order of the values (i.e.
> which combination of markers the value 
> represents).
> 
> Is there anyway to drag the labels along with
> the value extraction?
> _________________________
> Department of Molecular and Human Genetics,
> Baylor College of Medicine,

idx <- upper.tri(x)
cbind(row=row(x)[idx], col=col(x)[idx], value=x[idx])

Best,
Andy



From Ted.Harding at nessie.mcc.ac.uk  Thu Sep 23 21:37:36 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 23 Sep 2004 20:37:36 +0100 (BST)
Subject: [R] decompose a correlation matrix
In-Reply-To: <EMEFKCCDELAAHINIPAJHAEFJCAAA.strivens@bcm.tmc.edu>
Message-ID: <XFMail.040923203736.Ted.Harding@nessie.mcc.ac.uk>

On 23-Sep-04 Mark Strivens wrote:
> Is there a simple way to decompose the upper triangle
> of a correlation matrix to a linear list;
> 
> For example:
> 
>   X Y Z
> X 1 2 3
> Y 2 1 4
> Z 3 4 1
> 
> so you get a list like:
> 
> xy 2
> XZ 3
> YZ 4
> 
> I suspect you can do it with a matrix transformation, but
> that beyond me at present.

Let C be your correlation matrix. Then:

  C[lower.tri(C)]

or equivalently

  C[upper.tri(C)]

E.g. (in your notation):

  > C
       [,1] [,2] [,3] [,4]
  [1,]    1    2    3    4
  [2,]    2    1    5    6
  [3,]    3    5    1    7
  [4,]    4    6    7    1

  > (C[lower.tri(C)])
  [1] 2 3 4 5 6 7

See ?lower.tri

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861   [NB: New number!]
Date: 23-Sep-04                                       Time: 20:37:36
------------------------------ XFMail ------------------------------



From ligges at statistik.uni-dortmund.de  Thu Sep 23 21:59:10 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 23 Sep 2004 21:59:10 +0200
Subject: [R] Issue with predict() for glm models
In-Reply-To: <20040923180847.XQER25796.tomts36-srv.bellnexxia.net@JohnDesktop8300>
References: <20040923180847.XQER25796.tomts36-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <41532B0E.2070007@statistik.uni-dortmund.de>

John Fox wrote:

> Dear Uwe, 
> 
> 
>>-----Original Message-----
>>From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
>>Sent: Thursday, September 23, 2004 11:37 AM
>>To: John Fox
>>Cc: r-help at stat.math.ethz.ch
>>Subject: Re: [R] Issue with predict() for glm models
>>
> 
> . . .
> 
> 
>>John,
>>
>>note that I used glm(y ~ .) (the dot!),
>>because the names are automatically chosen to be X.1 and X.2, 
>>hence you cannot use "X" in the formula in this case ...
>>
>>Best,
>>Uwe
> 
> 
> OK -- I see. I did notice that you used . in the formula but didn't make the
> proper connection!

Sorry, my first reply was too short and imprecisely.
Thank you to help clarifying things.

Uwe


> Thanks,
>  John



From gcutler at amgen.com  Thu Sep 23 21:59:24 2004
From: gcutler at amgen.com (Gene Cutler)
Date: Thu, 23 Sep 2004 12:59:24 -0700
Subject: [R] folding table into a matrix
Message-ID: <1108AF23-0D9B-11D9-BB40-000A95C91324@amgen.com>

I'm just getting started with R, so feel free to point me to the 
appropriate documentation if this is already answered somewhere (though 
I've been unable to find it myself).  This does seem like a rather 
basic question.
I want to fold a table into a matrix.  The table is formatted like so:

Column_Index  Value
1             486
2             688
3             447
4             555
5             639
1             950
2             881
3             1785
4             1216
1             612
2             790
3             542
4             1310
5             976

And I want to end up with something like this:

       [,1]  [,2]  [,3]  [,4]  [,5]
[1,]   486   688   447   555   639
[2,]   950   881  1785  1216    NA
[3,]   612   790   512  1310   976

Since not all the rows are complete, I can't just reformat using 
matrix(), I need to go by the index information in the Column_Index 
column.  This seems like something simple to do, but I'm stumped.

Thanks.

-- Gene



From spencer.graves at pdf.com  Thu Sep 23 22:22:37 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 23 Sep 2004 13:22:37 -0700
Subject: [R] folding table into a matrix
In-Reply-To: <1108AF23-0D9B-11D9-BB40-000A95C91324@amgen.com>
References: <1108AF23-0D9B-11D9-BB40-000A95C91324@amgen.com>
Message-ID: <4153308D.4000006@pdf.com>

      Have you looked at "index arrays" in "An Introduction to R", 
available as the first menu option after "help.start()" in R?  The 
version I got with R 1.9.1 for Windows includes the following: 

     > x <- array(1:20,dim=c(4,5))   # Generate a 4 by 5 array.

     > x

          [,1] [,2] [,3] [,4] [,5]

     [1,]    1    5    9   13   17

     [2,]    2    6   10   14   18

     [3,]    3    7   11   15   19

     [4,]    4    8   12   16   20

     > i <- array(c(1:3,3:1),dim=c(3,2))

     > i                             # i is a 3 by 2 index array.

          [,1] [,2]

     [1,]    1    3

     [2,]    2    2

     [3,]    3    1

     > x[i]                          # Extract those elements

     [1] 9 6 3

     > x[i] <- 0                     # Replace those elements by zeros.

     > x

          [,1] [,2] [,3] [,4] [,5]

     [1,]    1    5    0   13   17

     [2,]    2    0   10   14   18

     [3,]    0    7   11   15   19

     [4,]    4    8   12   16   20

     >
      The key point here is that "i" is a 3x2 array, and x[i] references 
the 3 elements of x that have the row and column indices in x.  Does 
this provide the information you need? 

      hope this helps.  spencer graves

Gene Cutler wrote:

> I'm just getting started with R, so feel free to point me to the 
> appropriate documentation if this is already answered somewhere 
> (though I've been unable to find it myself).  This does seem like a 
> rather basic question.
> I want to fold a table into a matrix.  The table is formatted like so:
>
> Column_Index  Value
> 1             486
> 2             688
> 3             447
> 4             555
> 5             639
> 1             950
> 2             881
> 3             1785
> 4             1216
> 1             612
> 2             790
> 3             542
> 4             1310
> 5             976
>
> And I want to end up with something like this:
>
>       [,1]  [,2]  [,3]  [,4]  [,5]
> [1,]   486   688   447   555   639
> [2,]   950   881  1785  1216    NA
> [3,]   612   790   512  1310   976
>
> Since not all the rows are complete, I can't just reformat using 
> matrix(), I need to go by the index information in the Column_Index 
> column.  This seems like something simple to do, but I'm stumped.
>
> Thanks.
>
> -- Gene
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html


-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From canty at math.mcmaster.ca  Thu Sep 23 22:25:08 2004
From: canty at math.mcmaster.ca (Angelo Canty)
Date: Thu, 23 Sep 2004 16:25:08 -0400 (EDT)
Subject: [R] Problems with boot and optim
In-Reply-To: <000001c49ffa$c94f14e0$050aa8c0@HQ80G31>
Message-ID: <Pine.LNX.4.44.0409231618450.30812-100000@mathserv>

Hi Luke,

I think your problem is in the function lik.hetprobit and not 
remembering that R is case sensitive so X and x are not the same.

The parameters passed in are called X, Y and Z which change for each
bootstrap dataset.  Within the function, however, your first three 
lines are
Y <- as.matrix(y)
X <- as.matrix(x)
Z <- as.matrix(z)

since x, y, z (lowercase) do not exist in the function, they are being
sought in the global workspace which remains the same for each bootstrap
dataset so that after these three lines your X, Y and Z (uppercase) take
on these values no matter what was input to the function.

Replace x, y and z in the function by X, Y and Z and it should work.

HTH, Angelo
  
On Tue, 21 Sep 2004, Luke Keele wrote:

>  
> I am trying to bootstrap the parameters for a model that is estimated
> through the optim() function and find that when I make the call to boot,
> it runs but returns the exact same estimate for all of the bootstrap
> estimates.  I managed to replicate the same problem using a glm() model
> but was able to fix it when I made a call to the variables as data frame
> by their exact names.  But no matter how I refer to the variables in the
> het.fit function (see below) I get the same result.  I could bootstrap
> it with the sample command and a loop, but then the analysis in the next
> step isn't as nice
>  
> The code for the likelihood and the call to boot is below.  I have tried
> numerous other permutations as well.
>  
> I am using R 1.9.1 on Windows XP pro.
>  
> Thanks
>  
> Luke Keele
>  
>  
> #Define Likelihood
> lik.hetprobit <-function(par, X, Y, Z){
>  
> #Pull Out Parameters
> Y <- as.matrix(y)
> X <- as.matrix(x)
> Z <- as.matrix(z)
> K <-ncol(X)
> M <-ncol(Z)
> b <- as.matrix(par[1:K])
> gamma <- as.matrix(par[K+1:M])
>  
> mu <- (X%*%b)
> sd <- exp(Z%*%gamma)
>  
> mu.sd <-(mu/sd)
>  
> #Form Likelihood
>  
>    log.phi <- pnorm(ifelse(Y == 0, -1, 1) * mu.sd, log.p = TRUE)
>    2 * sum(log.phi)
> }
>  
> y <- as.matrix(abhlth)
> x <- as.matrix(reliten) 
> ones = rep(1, nrow(x)) 
> x = cbind(ones,x) 
> z = as.matrix(abinfo)
>  
> data.het <- as.matrix(cbind(y,x,z))
>  
> het.fit <- function(data){
>     mod <- optim(c(1,0,0), lik.hetprobit, Y=data$y, X=data$x, Z=data$z,
> method="BFGS", 
>                    control=list(fnscale=-1), hessian=T)
>     c(mod$par)
>     }
> case.fun <- function(d,i)
> het.fit(d[i,])
>  
> het.case <- boot(data.het, case.fun, R=50)
> Luke Keele
> Post-Doctoral Fellow in Quantitative Methods
> Nuffield College, Oxford University
> Oxford, UK
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
------------------------------------------------------------------
|   Angelo J. Canty                Email: cantya at mcmaster.ca     |
|   Mathematics and Statistics     Phone: (905) 525-9140 x 27079 |
|   McMaster University            Fax  : (905) 522-0935         |
|   1280 Main St. W.                                             |
|   Hamilton ON L8S 4K1                                          |



From p.dalgaard at biostat.ku.dk  Thu Sep 23 22:38:31 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 23 Sep 2004 22:38:31 +0200
Subject: [R] folding table into a matrix
In-Reply-To: <1108AF23-0D9B-11D9-BB40-000A95C91324@amgen.com>
References: <1108AF23-0D9B-11D9-BB40-000A95C91324@amgen.com>
Message-ID: <x265644t6g.fsf@biostat.ku.dk>

Gene Cutler <gcutler at amgen.com> writes:

> I'm just getting started with R, so feel free to point me to the
> appropriate documentation if this is already answered somewhere
> (though I've been unable to find it myself).  This does seem like a
> rather basic question.
> I want to fold a table into a matrix.  The table is formatted like so:
> 
> Column_Index  Value
> 1             486
> 2             688
> 3             447
> 4             555
> 5             639
> 1             950
> 2             881
> 3             1785
> 4             1216
> 1             612
> 2             790
> 3             542
> 4             1310
> 5             976
> 
> And I want to end up with something like this:
> 
>        [,1]  [,2]  [,3]  [,4]  [,5]
> [1,]   486   688   447   555   639
> [2,]   950   881  1785  1216    NA
> [3,]   612   790   512  1310   976
> 
> Since not all the rows are complete, I can't just reformat using
> matrix(), I need to go by the index information in the Column_Index
> column.  This seems like something simple to do, but I'm stumped.

It's not completely trivial, since you're relying on ordering
information: the missing col.5 value goes in the 2nd row, but you only
know that because values are ordered in row blocks.

If you supply the rows that things belong in, the task does becomes
simple:

Row_Index <- rep(1:3,c(5,4,5))
M <- matrix(NA, 3, 5)
M[cbind(Row_Index,Column_Index)] <- Value

Now how to compute Row_Index from Column_Index? If you know that each
group starts with a "1", you might use (rename Column_Index as cc for
brevity) 

> cumsum(cc==1)
 [1] 1 1 1 1 1 2 2 2 2 3 3 3 3 3

If you can't make that assumption, you might consider something like

> cumsum(c(1,diff(cc)<0))
 [1] 1 1 1 1 1 2 2 2 2 3 3 3 3 3


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From strivens at bcm.tmc.edu  Thu Sep 23 23:09:49 2004
From: strivens at bcm.tmc.edu (Mark Strivens)
Date: Thu, 23 Sep 2004 16:09:49 -0500
Subject: [R] decompose a correlation matrix
Message-ID: <EMEFKCCDELAAHINIPAJHMEFMCAAA.strivens@bcm.tmc.edu>

Thanks guys for the help, here's the final (grizzly?)
solution:

#generate a correlation matrix
cm<-cor(someDataFrame, y = NULL ...)

# get the list of labels (included in the dataframe)
labels<-labels(cm)[[1]]

# retrieve the uppper portion of the correlation matrix (as logical values)
idx <- upper.tri(cm)

# combine the logical values with the marker list
mcm<-cbind(marker=paste((markers[col(t(cm))[idx]],'&',markers[row(t(cm))[idx
]]),
	row=row(t(cm))[idx], col=col(t(cm))[idx], value=cm[idx])

gives the format:

label2 & label1	1	2	0.97712
label3 & label1	1	3	0.84587
label4 & label1	1	4	0.92184
label5 & label1	1	5	0.54698


There seemed to be some issues with the row()and col()
commands not thinking the output of cor() was a matrix
so I used t() to force it into a table...

_________________________
Department of Molecular and Human Genetics,
Baylor College of Medicine,
1 Baylor Plaza,
Houston,
TX 77030.

713-798-1947 (work)
832-876-7956 (cell)



From f.harrell at vanderbilt.edu  Thu Sep 23 12:01:52 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 23 Sep 2004 06:01:52 -0400
Subject: [R] Cox proportional hazards model
In-Reply-To: <7902152a04092215207bdc28a3@mail.gmail.com>
References: <7902152a04092215207bdc28a3@mail.gmail.com>
Message-ID: <41529F10.3050605@vanderbilt.edu>

Min-Han Tan wrote:
> Good afternoon,
> 
> I am currently trying to do some work on survival analysis.
> 
> - I hope to seek your advice re: 2 questions (1 general and 1 specific)
> 
> (1) I'm trying to do a stratified Cox analysis and subsequently
> plot(survfit(object)). It seems to work for some strata, but not for
> others.
> 
> I have tumor grade, which is a range of 1 - 4. 
> 
> When I divide this range of 1:4 into 2 groups, it works fine for
> strata(grade>2) and strata(grade > 3). However, if I do a
> strata(grade>1), there is an error when I do a survfit( <coxph object>
> )
> 
> Call: survfit.coxph(object = s)
> 
> Error in print.survfit(structure(list(n = as.integer(46), time = c(22,  : 
>         length of dimnames [1] not equal to array extent
> 
> (2) As a general question, is it possible to distinguish between
> confounding and interaction in the Cox proportional hazards model?
> 
> Thanks!
> 
> Min-Han

The Design package provides another way to use the survival package.

library(Design)  # also issues library(Hmisc) so need to install both
d <- datadist(mydataframe); options(datadist='d')
f <- cph(Surv(...) ~ ... + strat(z), surv=TRUE)   # note strat instead 
of strata
survplot(f, z=vector of strata values to plot survival curves for)

survplot has many options

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From Paul.Schwarz at gartner.com  Fri Sep 24 01:17:37 2004
From: Paul.Schwarz at gartner.com (Schwarz,Paul)
Date: Thu, 23 Sep 2004 16:17:37 -0700
Subject: [R] "moving average" method for time series objects
Message-ID: <A00D32D4F8342C4CB741761ACE09130AE3D306@elk.gartner.com>

Dear R-Help readers,

I suspect that this question must be a FAQ, but my investigation of the archives has not been very revealing.  Is there an R function for calculating moving averages of time series objects?

Thank you for your time and patience.

-Paul

Paul Schwarz, Ph.D.
Associate Director of Methodology
Gartner
Vendor Marketing Solutions, Custom Research
+1 503 241 8036 x186



From jonathan_li at agilent.com  Fri Sep 24 02:31:28 2004
From: jonathan_li at agilent.com (jonathan_li@agilent.com)
Date: Thu, 23 Sep 2004 17:31:28 -0700
Subject: [R] RMySQL and Blob
Message-ID: <65213341217E8D458E7C78E6640C74958360BC@waglmb01.labs.agilent.com>

Hi,

I tried your suggestion to blindly import the blob into R, doing the following:

> con <- dbConnect("MySQL", host="host", user="user", dbname="db")
> rs <- dbGetQuery(con, statement=paste("select picture from db where id=1")

It didn't crash R. But rs is not usable. It seems that it has been converted to a character object.

In addition, we need to pass an image format to R, like png, bmp or something. It's unclear to me how to achieve this even if we can read "rs" as a binary object as you suggested.

Any ideas?

Thanks for suggestions!
Jonathan





-----Original Message-----
From: David James [mailto:dj at research.bell-labs.com]
Sent: Wednesday, September 22, 2004 10:06 AM
To: LI,JONATHAN (A-Labs,ex1)
Cc: David James
Subject: Re: [R] RMySQL and Blob


jonathan_li at agilent.com wrote:
> Hi David,
> 
> The application I have in mind is for images. In my case, size of images is known and they are not big. As an example, a 64*32 image will have 2048 pixels. If they are 8-bit grey-level pixels, the image occupies 2KB memory. 
> 
> I may venture to guess that the unknown size and type of a blob object in MySQL prevent it from being very usable in R since R doesn't have a datatype for a binary blob?

You could just blindly try to import it into R (but do it on a clean
workspace, since it may crash R and you could loose your data!).
The underlying C code clearly identifies FIELD_TYPE_BLOB and goes
ahead and puts it in an R character vector (with comments clearly
stating that it is a hack).  Once it moves the data from the MySQL
result set buffer to the R vector, it computes the length in both
places and prints a warning if they differ.

Or you could try to hack something.  For instance, what happens if
instead of bringing the blob you import, say, as a string?
    con <- dbConnect("MySQL", ....)
    rs <- dbSendQuery(con, "select SUBSTRING(blob, 0) from table")
    dd <- fetch(rs)

One possible general solution would be to define a new class
"binaryConnection" simmilar to textConnection, so that you
can readBin() and writeBin() from it.  In this way, blobs could
return a binary buffer (just a pointer to a block of C memory) 
that could be given to binaryConnection:

   data <- fetch(rs)
   for(i in seq(nrow(data)){
      ## extract blobs from each row and create a binary connection
      bcon = binaryConnection(blobs$image[1])
      img = readBin(bcon, "integer", n = 2048)
      
      ## work with the image
   }

let me know what happens if you try to naively import a blob...

--
David

> 
> Thanks!
> Jonathan
> 
> 
> -----Original Message-----
> From: David James [mailto:dj at research.bell-labs.com]
> Sent: Wednesday, September 22, 2004 7:05 AM
> To: LI,JONATHAN (A-Labs,ex1)
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] RMySQL and Blob
> 
> 
> Hi Jonathan,
> 
> Currently RMySQL doesn't handle blob objects.  The mechanics of
> inserting and extracting blob objects by itself is not too hard,
> but issues such as how should blobs be made available to R, how to
> prevent buffers overflows, how to prevent huge blobs from exhausting
> the available memory, should R callback functions be invoked
> as chunks of the blob are brought in, etc., need more consideration.
> And these issues are not R/MySQL specific, but also relevant to
> other databases and other non-dbms interfaces.
> 
> BTW there are R facilities (e.g., external pointers, finalizers) that 
> seems quite important for this type of implementation.  
> 
> What type and how big are the blobs that want to import?
> 
> --
> David
> 
> jonathan_li at agilent.com wrote:
> > Dear R experts,
> > 
> > Does RMySQL package handle Blob datatype in a MySQL database? Blob can represent an image, a sound or some other 
> > large and complex binary objects. In an article published by R-database special interest group, named "A common database interface (DBI)" (updated June 2003),  it's mentioned in "open issues and limitations" that "We need to carefully plan how to deal with binary objects". 
> > 
> > Before I invest time to try, I would appreciate any experts' opinions.
> > 
> > Thanks,
> > Jonathan
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
David A. James
Statistics Research, Room 2C-276            Phone:  (908) 582-3082       
Bell Labs, Lucent Technologies              Fax:    (908) 582-3340
Murray Hill, NJ 09794-0636



From xmeng at capitalbio.com  Fri Sep 24 03:56:13 2004
From: xmeng at capitalbio.com (=?gb2312?B?w8/QwA==?=)
Date: Fri, 24 Sep 2004 09:56:13 +0800
Subject: [R] Intrduction of function
Message-ID: <295990973.12756@capitalbio.com>

Hi all: I've written a function and saved the worksapce.When the workspace of my function is re-open,I want display some introduction or step by step guidance of the function for the users.How can I do it? Thanks a lot! 

My best regards!



From ggrothendieck at myway.com  Fri Sep 24 03:52:24 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 24 Sep 2004 01:52:24 +0000 (UTC)
Subject: [R] folding table into a matrix
References: <1108AF23-0D9B-11D9-BB40-000A95C91324@amgen.com>
Message-ID: <loom.20040924T034922-875@post.gmane.org>

Gene Cutler <gcutler <at> amgen.com> writes:

: 
: I'm just getting started with R, so feel free to point me to the 
: appropriate documentation if this is already answered somewhere (though 
: I've been unable to find it myself).  This does seem like a rather 
: basic question.
: I want to fold a table into a matrix.  The table is formatted like so:
: 
: Column_Index  Value
: 1             486
: 2             688
: 3             447
: 4             555
: 5             639
: 1             950
: 2             881
: 3             1785
: 4             1216
: 1             612
: 2             790
: 3             542
: 4             1310
: 5             976
: 
: And I want to end up with something like this:
: 
:        [,1]  [,2]  [,3]  [,4]  [,5]
: [1,]   486   688   447   555   639
: [2,]   950   881  1785  1216    NA
: [3,]   612   790   512  1310   976
: 
: Since not all the rows are complete, I can't just reformat using 
: matrix(), I need to go by the index information in the Column_Index 
: column.  This seems like something simple to do, but I'm stumped.

Suppose z is the two column matrix which we wish
to reshape. Using Peter's cumsum expression to distinguish
the groups, tapply ts to each group turning each into
a ts object.  cbind these ts objects together (which 
has the effect of adding the NAs at the end automatically)
and finally transpose the result (which also turns it
back into a matrix).  The following one liner solves
the example problem:

t(do.call("cbind",tapply(z[,2], cumsum(z[,1]==1), ts)))


This approach also extends to the case where the indices in
column 1 have gaps.  In this case we need an irregular time
series package.  Using zoo we carry out the analogous
operations using the indices in column 1 for a group as the
times and the values in column 2 as the time series values.
We make use of zoo's multiway merge and Peter's second, more
general, cumsum expression to define the groups:

require(zoo)
f <- function(i) zoo(z[i,2], z[i,1])
g <- cumsum(c(1,diff(z[,1])<0))
t(as.matrix(do.call("merge", tapply(1:nrow(z), g, f))))



From ggrothendieck at myway.com  Fri Sep 24 03:54:39 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Fri, 24 Sep 2004 01:54:39 +0000 (UTC)
Subject: [R] "moving average" method for time series objects
References: <A00D32D4F8342C4CB741761ACE09130AE3D306@elk.gartner.com>
Message-ID: <loom.20040924T035420-191@post.gmane.org>

Schwarz,Paul <Paul.Schwarz <at> gartner.com> writes:

: 
: Dear R-Help readers,
: 
: I suspect that this question must be a FAQ, but my investigation of the 
archives has not been very revealing. 
: Is there an R function for calculating moving averages of time series 
objects?
: 
: Thank you for your time and patience.
: 
: -Paul

Check out:

https://stat.ethz.ch/pipermail/r-sig-finance/2004q3/000104.html



From 0034058 at fudan.edu.cn  Fri Sep 24 04:40:38 2004
From: 0034058 at fudan.edu.cn (rongguiwong)
Date: Fri, 24 Sep 2004 10:40:38 +0800
Subject: [R] can I get these result with R?
In-Reply-To: <295990973.12756@capitalbio.com>
References: <295990973.12756@capitalbio.com>
Message-ID: <200409241040.38470.0034058@fudan.edu.cn>

i want to check if the previously stock of social capital  has impact on the 
present economoc performace.so i get the following variables:economic 
performace ,stock of socail capital ;each of them from year 1996 to 2002,from 
30 different areas.
the data as following:
performance   stock    year    ereas
12,            32        1996     1
11             12         1996     2
123          34           1996     3
¡­¡­¡­¡­¡­¡­
12,            332        1997     1
11             212         1997     2
123          32           1997     3
¡­¡­¡­¡­
13,            232        2002     1
12             212         2002     2
12            33          2002     3

so i want to see if the 
1/stock[1996],stock[1997],stock[1998],stock[1999],sotck[2000],stock[2001],stock[2002] 
has impact on performance[2002]?
2/stock[1996],stock[1997],stock[1998],stock[1999],sotck[2000],stock[2001] has 
impact on performance[2001],
3/stock[1996],stock[1997],stock[1998],stock[1999],sotck[2000], has impact on 
performance[2000],
¡­¡­
and to see if the 
1/performace of year 1996,1997,1998,1999,2000,2001 has impact on performace of 
year 2002,
2/performace of year 1996,1997,1998,1999,2000 has impact on performace of year 
2001,
1/performace of year 1996,1997,1998,1999, has impact on performace of year 
2000,
¡­¡­

arima model seems not work,as i have data from 31 eareas,and i want to see if 
the differeces in economic performace of differenct areas has relation to the 
differences in the stock of social capital in each areas.
is it impossible mission?
any help will be appreciated.



From akhan at cs.otago.ac.nz  Fri Sep 24 07:44:40 2004
From: akhan at cs.otago.ac.nz (Anar Khan)
Date: Fri, 24 Sep 2004 17:44:40 +1200 (NZST)
Subject: [R] SJava Issue
Message-ID: <Pine.OSF.4.44.0409241733020.149269-100000@hermes.otago.ac.nz>


Hi,

I have downloaded and installed SJava-0.68-0 on my linux box.  When I try
to initialise the JVM from within R this is what I get:

> .JavaInit()
(1) error initializing manager class can't find class java/lang/Hashtable
Error in .JavaInit() : Couldn't start Java Virtual Machine: can't find
class java/lang/Hashtable

My JAVA_HOME variable is set in my .tcshrc script, so it shouldn't
really have any problem finding java.  (And its strange that its looking
for Hashtable in java.lang!)

This problem was posted on the mailing list by someone else also using
the j2sdk1.4.2_01 JDK from Sun last year
(http://www.mail-archive.com/r-help at stat.math.ethz.ch/msg09080.html) and I
was wondering if anyone had figured out how to resolve it?


Cheers,

Anar



From ligges at statistik.uni-dortmund.de  Fri Sep 24 08:45:26 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 24 Sep 2004 08:45:26 +0200
Subject: [R] Intrduction of function
In-Reply-To: <295990973.12756@capitalbio.com>
References: <295990973.12756@capitalbio.com>
Message-ID: <4153C286.6050101@statistik.uni-dortmund.de>

?????? wrote:

> Hi all: I've written a function and saved the worksapce.When the workspace of my function is re-open,I want display some introduction or step by step guidance of the function for the users.How can I do it? Thanks a lot! 

??, you don't want to do distribute a workspace, but you want to create 
and build an R package that can easily be distributed (even to different 
platforms). See "Writing R Extensions" on how to do that.

Uwe Ligges


> My best regards!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Sep 24 08:59:54 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 24 Sep 2004 08:59:54 +0200
Subject: [R] How to improve the quality of curve/line plots?
In-Reply-To: <9E00F1C36CEF614CA4AA6CC2587B594D360DFD@EXCHANGE2.harz.bezreg-muenster.nrw.de>
References: <9E00F1C36CEF614CA4AA6CC2587B594D360DFD@EXCHANGE2.harz.bezreg-muenster.nrw.de>
Message-ID: <4153C5EA.2080900@statistik.uni-dortmund.de>

Wolf, Michael wrote:

> Dear list,
> 
> I'm using the windows version of R. When plotting a curve or a line for time series with annual data , e. g. GDP growth 1991-2003, the line seems to exist of a lot of smaller lines. Printing the results the curves and lines seems to be "unclean" (because of using small resolution bitmaps?). Comparing the result of R with the same results of Excel the lines in excel seems to havve a higher qualitiy. In Excel you also can produce curves instead of lines.
> 
> Are there any possibilities how to improve the quality of the plots in R? How can R be influenced to plot "clean" lines with a higher resolution on the screen (I think it's not a question of the pdf- or png command.). Perhaps, it's a problem of the graphical possibilites of R because the most line plots which can be seen on the web have these problems.

Can you specify an example please? I cannot remember any "unclean" plot. 
In particular, no bitmaps are used to render graphics in R.

What I guess is that you have a line plot and each observation is 
connected with the subsequent one by a line. If you want to smooth it 
(and you think smoothing is appropriate here), you have to apply a 
smoothing technique before plotting.

Uwe Ligges


> Thanks,
> 
> Dr. Michael Wolf
> Bezirksregierung M??nster
> Dezernat 61
> Domplatz 1-3    48161 M??nster
> Tel.:   ++ 49 (02 51) / 4 11 - 17 95
> Fax.:   ++ 49 (02 51) / 4 11 - 8 17 95
> E-Mail: michael.wolf at bezreg-muenster.nrw.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Michael.Wolf at bezreg-muenster.nrw.de  Fri Sep 24 09:35:58 2004
From: Michael.Wolf at bezreg-muenster.nrw.de (Wolf, Michael)
Date: Fri, 24 Sep 2004 09:35:58 +0200
Subject: AW: [R] How to improve the quality of curve/line plots?
Message-ID: <9E00F1C36CEF614CA4AA6CC2587B594D360E09@EXCHANGE2.harz.bezreg-muenster.nrw.de>

Thanks for the tip using a smoothing technique before plotiing in order to get a curve instead of a line connecting the observations.

But that's not the solution for my main problem with the "unclean" line plot. In order to show my problem let's take this simple example:

> xval <- c(1, 2, 3, 4, 5, 6, 7, 8)
> yval <- c(10, 30, 40, 50, 70, 90, 100, 110)
> plot (xval, yval, type="l")

If you look to the result in the graphic window you will see that the line seems to exist of many points between the observations; e. g. between xval=1 and xval=2 the line contains 8 or more sublines. Perhaps, you can also observe a break of the line at xval=4. That's what I call an "unclean line". 

Even if you try to export the plot with the png command you can observe the same phenomenon. The line has not an exact appearance like Excel diagram plots. If there are no other techniques to get better line plots it seems to be a problem of the graphic output!? 

Michael Wolf

-----Urspr??ngliche Nachricht-----
Von: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Gesendet: Freitag, 24. September 2004 09:00
An: Wolf, Michael
Cc: r-help at stat.math.ethz.ch
Betreff: Re: [R] How to improve the quality of curve/line plots?

Wolf, Michael wrote:

> Dear list,
> 
> I'm using the windows version of R. When plotting a curve or a line for time series with annual data , e. g. GDP growth 1991-2003, the line seems to exist of a lot of smaller lines. Printing the results the curves and lines seems to be "unclean" (because of using small resolution bitmaps?). Comparing the result of R with the same results of Excel the lines in excel seems to havve a higher qualitiy. In Excel you also can produce curves instead of lines.
> 
> Are there any possibilities how to improve the quality of the plots in R? How can R be influenced to plot "clean" lines with a higher resolution on the screen (I think it's not a question of the pdf- or png command.). Perhaps, it's a problem of the graphical possibilites of R because the most line plots which can be seen on the web have these problems.

Can you specify an example please? I cannot remember any "unclean" plot. 
In particular, no bitmaps are used to render graphics in R.

What I guess is that you have a line plot and each observation is connected with the subsequent one by a line. If you want to smooth it (and you think smoothing is appropriate here), you have to apply a smoothing technique before plotting.

Uwe Ligges


> Thanks,
> 
> Dr. Michael Wolf
> Bezirksregierung M??nster
> Dezernat 61
> Domplatz 1-3    48161 M??nster
> Tel.:   ++ 49 (02 51) / 4 11 - 17 95
> Fax.:   ++ 49 (02 51) / 4 11 - 8 17 95
> E-Mail: michael.wolf at bezreg-muenster.nrw.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ahenningsen at email.uni-kiel.de  Fri Sep 24 10:01:21 2004
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Fri, 24 Sep 2004 10:01:21 +0200
Subject: AW: [R] How to improve the quality of curve/line plots?
In-Reply-To: <9E00F1C36CEF614CA4AA6CC2587B594D360E09@EXCHANGE2.harz.bezreg-muenster.nrw.de>
References: <9E00F1C36CEF614CA4AA6CC2587B594D360E09@EXCHANGE2.harz.bezreg-muenster.nrw.de>
Message-ID: <200409241001.21277.ahenningsen@email.uni-kiel.de>

On Friday 24 September 2004 09:35, Wolf, Michael wrote:
> Thanks for the tip using a smoothing technique before plotiing in order to
> get a curve instead of a line connecting the observations.
>
> But that's not the solution for my main problem with the "unclean" line 
plot. In order to show my problem let's take this simple example:
> > xval <- c(1, 2, 3, 4, 5, 6, 7, 8)
> > yval <- c(10, 30, 40, 50, 70, 90, 100, 110)
> > plot (xval, yval, type="l")
>
> If you look to the result in the graphic window you will see that the line
> seems to exist of many points between the observations; e. g. between
> xval=1 and xval=2 the line contains 8 or more sublines. Perhaps, you can
> also observe a break of the line at xval=4. That's what I call an "unclean
> line".

You can increase the linewidth with, e.g.:
plot (xval, yval, type="l", lwd=2)

> Even if you try to export the plot with the png command you can observe the
> same phenomenon. The line has not an exact appearance like Excel diagram
> plots. If there are no other techniques to get better line plots it seems
> to be a problem of the graphic output!?

And you can increase the resolution, e.g.:
png( "myplot.png", 1000, 1000 )

Best wishes,
Arne

> Michael Wolf
>
> -----Urspr??ngliche Nachricht-----
> Von: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> Gesendet: Freitag, 24. September 2004 09:00
> An: Wolf, Michael
> Cc: r-help at stat.math.ethz.ch
> Betreff: Re: [R] How to improve the quality of curve/line plots?
>
> Wolf, Michael wrote:
> > Dear list,
> >
> > I'm using the windows version of R. When plotting a curve or a line for
> > time series with annual data , e. g. GDP growth 1991-2003, the line seems
> > to exist of a lot of smaller lines. Printing the results the curves and
> > lines seems to be "unclean" (because of using small resolution bitmaps?).
> > Comparing the result of R with the same results of Excel the lines in
> > excel seems to havve a higher qualitiy. In Excel you also can produce
> > curves instead of lines.
> >
> > Are there any possibilities how to improve the quality of the plots in R?
> > How can R be influenced to plot "clean" lines with a higher resolution on
> > the screen (I think it's not a question of the pdf- or png command.).
> > Perhaps, it's a problem of the graphical possibilites of R because the
> > most line plots which can be seen on the web have these problems.
>
> Can you specify an example please? I cannot remember any "unclean" plot.
> In particular, no bitmaps are used to render graphics in R.
>
> What I guess is that you have a line plot and each observation is connected
> with the subsequent one by a line. If you want to smooth it (and you think
> smoothing is appropriate here), you have to apply a smoothing technique
> before plotting.
>
> Uwe Ligges
>
> > Thanks,
> >
> > Dr. Michael Wolf
> > Bezirksregierung M??nster
> > Dezernat 61
> > Domplatz 1-3    48161 M??nster
> > Tel.:   ++ 49 (02 51) / 4 11 - 17 95
> > Fax.:   ++ 49 (02 51) / 4 11 - 8 17 95
> > E-Mail: michael.wolf at bezreg-muenster.nrw.de
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From ligges at statistik.uni-dortmund.de  Fri Sep 24 10:05:24 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 24 Sep 2004 10:05:24 +0200
Subject: AW: [R] How to improve the quality of curve/line plots?
In-Reply-To: <9E00F1C36CEF614CA4AA6CC2587B594D360E09@EXCHANGE2.harz.bezreg-muenster.nrw.de>
References: <9E00F1C36CEF614CA4AA6CC2587B594D360E09@EXCHANGE2.harz.bezreg-muenster.nrw.de>
Message-ID: <4153D544.6060602@statistik.uni-dortmund.de>

Wolf, Michael wrote:

> Thanks for the tip using a smoothing technique before plotiing in order to get a curve instead of a line connecting the observations.
> 
> But that's not the solution for my main problem with the "unclean" line plot. In order to show my problem let's take this simple example:
> 
> 
>>xval <- c(1, 2, 3, 4, 5, 6, 7, 8)
>>yval <- c(10, 30, 40, 50, 70, 90, 100, 110)
>>plot (xval, yval, type="l")
> 
> 
> If you look to the result in the graphic window you will see that the line seems to exist of many points between the observations; e. g. between xval=1 and xval=2 the line contains 8 or more sublines. Perhaps, you can also observe a break of the line at xval=4. That's what I call an "unclean line". 
> 
> Even if you try to export the plot with the png command you can observe the same phenomenon. The line has not an exact appearance like Excel diagram plots. If there are no other techniques to get better line plots it seems to be a problem of the graphic output!? 


No. The problem is the "small" resolution of your screen. Note that the 
screen is a bitmap! The graphics are vectorized!
So it's a matter of displaying the graphics on your dise, not of 
generating them.

Uwe Ligges




> Michael Wolf
> 
> -----Urspr??ngliche Nachricht-----
> Von: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
> Gesendet: Freitag, 24. September 2004 09:00
> An: Wolf, Michael
> Cc: r-help at stat.math.ethz.ch
> Betreff: Re: [R] How to improve the quality of curve/line plots?
> 
> Wolf, Michael wrote:
> 
> 
>>Dear list,
>>
>>I'm using the windows version of R. When plotting a curve or a line for time series with annual data , e. g. GDP growth 1991-2003, the line seems to exist of a lot of smaller lines. Printing the results the curves and lines seems to be "unclean" (because of using small resolution bitmaps?). Comparing the result of R with the same results of Excel the lines in excel seems to havve a higher qualitiy. In Excel you also can produce curves instead of lines.
>>
>>Are there any possibilities how to improve the quality of the plots in R? How can R be influenced to plot "clean" lines with a higher resolution on the screen (I think it's not a question of the pdf- or png command.). Perhaps, it's a problem of the graphical possibilites of R because the most line plots which can be seen on the web have these problems.
> 
> 
> Can you specify an example please? I cannot remember any "unclean" plot. 
> In particular, no bitmaps are used to render graphics in R.
> 
> What I guess is that you have a line plot and each observation is connected with the subsequent one by a line. If you want to smooth it (and you think smoothing is appropriate here), you have to apply a smoothing technique before plotting.
> 
> Uwe Ligges
> 
> 
> 
>>Thanks,
>>
>>Dr. Michael Wolf
>>Bezirksregierung M??nster
>>Dezernat 61
>>Domplatz 1-3    48161 M??nster
>>Tel.:   ++ 49 (02 51) / 4 11 - 17 95
>>Fax.:   ++ 49 (02 51) / 4 11 - 8 17 95
>>E-Mail: michael.wolf at bezreg-muenster.nrw.de
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Roger.Bivand at nhh.no  Fri Sep 24 10:11:29 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 24 Sep 2004 10:11:29 +0200 (CEST)
Subject: AW: [R] How to improve the quality of curve/line plots?
In-Reply-To: <9E00F1C36CEF614CA4AA6CC2587B594D360E09@EXCHANGE2.harz.bezreg-m
	uenster.nrw.de>
Message-ID: <Pine.LNX.4.44.0409240948460.24170-100000@reclus.nhh.no>

On Fri, 24 Sep 2004, Wolf, Michael wrote:

> Thanks for the tip using a smoothing technique before plotiing in order
> to get a curve instead of a line connecting the observations.
> 
> But that's not the solution for my main problem with the "unclean" line
> plot. In order to show my problem let's take this simple example:
> 
> > xval <- c(1, 2, 3, 4, 5, 6, 7, 8)
> > yval <- c(10, 30, 40, 50, 70, 90, 100, 110)
> > plot (xval, yval, type="l")
> 
> If you look to the result in the graphic window you will see that the
> line seems to exist of many points between the observations; e. g.
> between xval=1 and xval=2 the line contains 8 or more sublines. Perhaps,
> you can also observe a break of the line at xval=4. That's what I call
> an "unclean line".

I think you are confusing yourself by mistaking what you "see" on a 
particular platform (OS, screen hardware, drivers, resolution) and the 
underlying model. The underlying model is vector graphics, so your first 
line segment is represented by approximations to lines on raster devices, 
like computer screens or PNG, but is still vector when the output device 
is vector.

> postscript()
> plot (xval, yval, type="l", axes=FALSE, xlab="", ylab="")
> dev.off()

and Rplots.ps contains:

%%Page: 1 1
bp
77.04 91.44 793.65 518.24 cl
0 0 0 rgb
0.75 setlinewidth
[] 0 setdash
1 setlinecap
1 setlinejoin
10.00 setmiterlimit
np
103.58 107.25 m
94.79 79.03 l
94.79 39.52 l
94.79 39.52 l
94.79 79.04 l
94.79 79.03 l
94.79 39.52 l
94.79 39.52 l
o
18.00 18.00 823.89 577.28 cl
ep
%%Trailer
%%Pages: 1

which is a vector representation in the scale of the output device (move 
to (103.58 107.25), draw a line to (94.79 79.03) from here, ...). But if 
you display the postscript file on a screen, it has to be rasterised - it 
has to be rasterised to be printed too, but most printers have much higher 
resolution than screens. Note that "exact appearance" is just what the 
second word says, "appearance". For making vector graphics output, you may 
find the postscript and pdf devices useful, and I think Windows metafiles 
on that platform (reading src/gnuwin32/graphapp/metafile.c shows how much 
work is needed to get graphics to work!). 

> 
> Even if you try to export the plot with the png command you can observe
> the same phenomenon. The line has not an exact appearance like Excel
> diagram plots. If there are no other techniques to get better line plots
> it seems to be a problem of the graphic output!?
> 
> Michael Wolf
> 
> -----Urspr??ngliche Nachricht-----
> Von: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
> Gesendet: Freitag, 24. September 2004 09:00
> An: Wolf, Michael
> Cc: r-help at stat.math.ethz.ch
> Betreff: Re: [R] How to improve the quality of curve/line plots?
> 
> Wolf, Michael wrote:
> 
> > Dear list,
> > 
> > I'm using the windows version of R. When plotting a curve or a line for time series with annual data , e. g. GDP growth 1991-2003, the line seems to exist of a lot of smaller lines. Printing the results the curves and lines seems to be "unclean" (because of using small resolution bitmaps?). Comparing the result of R with the same results of Excel the lines in excel seems to havve a higher qualitiy. In Excel you also can produce curves instead of lines.
> > 
> > Are there any possibilities how to improve the quality of the plots in R? How can R be influenced to plot "clean" lines with a higher resolution on the screen (I think it's not a question of the pdf- or png command.). Perhaps, it's a problem of the graphical possibilites of R because the most line plots which can be seen on the web have these problems.
> 
> Can you specify an example please? I cannot remember any "unclean" plot. 
> In particular, no bitmaps are used to render graphics in R.
> 
> What I guess is that you have a line plot and each observation is connected with the subsequent one by a line. If you want to smooth it (and you think smoothing is appropriate here), you have to apply a smoothing technique before plotting.
> 
> Uwe Ligges
> 
> 
> > Thanks,
> > 
> > Dr. Michael Wolf
> > Bezirksregierung M??nster
> > Dezernat 61
> > Domplatz 1-3    48161 M??nster
> > Tel.:   ++ 49 (02 51) / 4 11 - 17 95
> > Fax.:   ++ 49 (02 51) / 4 11 - 8 17 95
> > E-Mail: michael.wolf at bezreg-muenster.nrw.de
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From angel_lul at hotmail.com  Fri Sep 24 10:19:29 2004
From: angel_lul at hotmail.com (Angel Lopez)
Date: Fri, 24 Sep 2004 10:19:29 +0200
Subject: AW: [R] How to improve the quality of curve/line plots?
In-Reply-To: <9E00F1C36CEF614CA4AA6CC2587B594D360E09@EXCHANGE2.harz.bezreg-muenster.nrw.de>
References: <9E00F1C36CEF614CA4AA6CC2587B594D360E09@EXCHANGE2.harz.bezreg-muenster.nrw.de>
Message-ID: <4153D891.2010508@hotmail.com>

I posted a similar question while ago:
http://tolstoy.newcastle.edu.au/R/help/04/03/0590.html
with not much success.
The only replies I recieved were in private, the one i keep in my inbox is:
"Is this just a "rasterization" effect?  i.e., a conceptually smooth 
line looks jagged because the screen can only turn on the pixels closest 
to where the line goes.  The example looks smooth when printed right(?)"
The reply is that it looks better (although not perfect) when printed or 
when I use a postscript device.
Angel

Wolf, Michael wrote:
> Thanks for the tip using a smoothing technique before plotiing in order to get a curve instead of a line connecting the observations.
> 
> But that's not the solution for my main problem with the "unclean" line plot. In order to show my problem let's take this simple example:
> 
> 
>>xval <- c(1, 2, 3, 4, 5, 6, 7, 8)
>>yval <- c(10, 30, 40, 50, 70, 90, 100, 110)
>>plot (xval, yval, type="l")
> 
> 
> If you look to the result in the graphic window you will see that the line seems to exist of many points between the observations; e. g. between xval=1 and xval=2 the line contains 8 or more sublines. Perhaps, you can also observe a break of the line at xval=4. That's what I call an "unclean line". 
> 
> Even if you try to export the plot with the png command you can observe the same phenomenon. The line has not an exact appearance like Excel diagram plots. If there are no other techniques to get better line plots it seems to be a problem of the graphic output!? 
> 
> Michael Wolf
> 
> -----Urspr??ngliche Nachricht-----
> Von: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
> Gesendet: Freitag, 24. September 2004 09:00
> An: Wolf, Michael
> Cc: r-help at stat.math.ethz.ch
> Betreff: Re: [R] How to improve the quality of curve/line plots?
> 
> Wolf, Michael wrote:
> 
> 
>>Dear list,
>>
>>I'm using the windows version of R. When plotting a curve or a line for time series with annual data , e. g. GDP growth 1991-2003, the line seems to exist of a lot of smaller lines. Printing the results the curves and lines seems to be "unclean" (because of using small resolution bitmaps?). Comparing the result of R with the same results of Excel the lines in excel seems to havve a higher qualitiy. In Excel you also can produce curves instead of lines.
>>
>>Are there any possibilities how to improve the quality of the plots in R? How can R be influenced to plot "clean" lines with a higher resolution on the screen (I think it's not a question of the pdf- or png command.). Perhaps, it's a problem of the graphical possibilites of R because the most line plots which can be seen on the web have these problems.
> 
> 
> Can you specify an example please? I cannot remember any "unclean" plot. 
> In particular, no bitmaps are used to render graphics in R.
> 
> What I guess is that you have a line plot and each observation is connected with the subsequent one by a line. If you want to smooth it (and you think smoothing is appropriate here), you have to apply a smoothing technique before plotting.
> 
> Uwe Ligges
> 
> 
> 
>>Thanks,
>>
>>Dr. Michael Wolf
>>Bezirksregierung M??nster
>>Dezernat 61
>>Domplatz 1-3    48161 M??nster
>>Tel.:   ++ 49 (02 51) / 4 11 - 17 95
>>Fax.:   ++ 49 (02 51) / 4 11 - 8 17 95
>>E-Mail: michael.wolf at bezreg-muenster.nrw.de
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> .
>



From Michael.Wolf at bezreg-muenster.nrw.de  Fri Sep 24 10:43:56 2004
From: Michael.Wolf at bezreg-muenster.nrw.de (Wolf, Michael)
Date: Fri, 24 Sep 2004 10:43:56 +0200
Subject: AW: AW: [R] How to improve the quality of curve/line plots?
Message-ID: <9E00F1C36CEF614CA4AA6CC2587B594D360E0D@EXCHANGE2.harz.bezreg-muenster.nrw.de>

Thanks for your help. 

When testing your examples and hints I saw that printing the graph
results in a better (optimal) appearance of the line. Consequently, the
postscript command will lead to "clean" line appearances using a high
resolution/quality printer. At least, that's the decisive point in order
to get an optimal output!

Best wishes,

Michael Wolf



From G.BLANCHER at isa-lille.fr  Fri Sep 24 10:54:55 2004
From: G.BLANCHER at isa-lille.fr (BLANCHER Guillaume)
Date: Fri, 24 Sep 2004 10:54:55 +0200
Subject: [R] anova and post hoc multicomparison tests
Message-ID: <F2B8DADA7A384D48925C74D52D68AE702484DC@srv-exch.isa.net>

Hello everyone, 

Like a lot of people, I have been looking for functions in R doing ANOVA
(ok) and performing multicomparisons (like Student-Newman-Keuls, etc.).
As I have been a little bit disappointed, I have bee looking through the
net for such "open source" softwares. I found one in:
http://www.statpages.org/miller/openstat/OS4.html
I have begun to use it, and it seems good and simple to understand (as
for a non-specialist like me).
Sorry for R, but I prefer OpenStat4 to R for ANOVAs and post hoc tests.

Guillaume



From as1524933 at sapo.pt  Fri Sep 24 11:57:34 2004
From: as1524933 at sapo.pt (Miguel Ribeiro)
Date: Fri, 24 Sep 2004 10:57:34 +0100
Subject: [R] (sem assunto)
Message-ID: <001001c4a21c$eaaff2c0$bc339b52@miguel9ik59ct1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040924/edc447b6/attachment.pl

From Ted.Harding at nessie.mcc.ac.uk  Fri Sep 24 11:55:08 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 24 Sep 2004 10:55:08 +0100 (BST)
Subject: AW: [R] How to improve the quality of curve/line plots?
In-Reply-To: <9E00F1C36CEF614CA4AA6CC2587B594D360E09@EXCHANGE2.harz.bezreg-muenster.nrw.de>
Message-ID: <XFMail.040924105508.Ted.Harding@nessie.mcc.ac.uk>

On 24-Sep-04 Wolf, Michael wrote:
> Thanks for the tip using a smoothing technique before plotiing in order
> to get a curve instead of a line connecting the observations.
> 
> But that's not the solution for my main problem with the "unclean" line
> plot. In order to show my problem let's take this simple example:
> 
>> xval <- c(1, 2, 3, 4, 5, 6, 7, 8)
>> yval <- c(10, 30, 40, 50, 70, 90, 100, 110)
>> plot (xval, yval, type="l")
> 
> If you look to the result in the graphic window you will see that the
> line seems to exist of many points between the observations; e. g.
> between xval=1 and xval=2 the line contains 8 or more sublines.
> Perhaps, you can also observe a break of the line at xval=4. That's
> what I call an "unclean line". 
> 
> Even if you try to export the plot with the png command you can observe
> the same phenomenon. The line has not an exact appearance like Excel
> diagram plots. If there are no other techniques to get better line
> plots it seems to be a problem of the graphic output!? 

You might describe it in this way! The fundamental issue is that on
screen the display is generated by assigning different colours to
each of an array of tiny panels, the "pixels". The actual size of
a pixel depends on the hardware, i.e. your monitor, but typically
it is of the order of 1/100 inch (i.e. 1/4 mm). This size is quite
visible and can give a ragged or "stepped" appearance to things
which you might expect to show as smooth curves or lines. This
effect is also different between CRT monitors (where the pixel
is illuminated by a scanning electon beam) and TFT monitors where
each pixel is a physical entity and is activated under electronic
control. TFT pixels are more sharply defined then CRT pixels, and
have a clearly visible square shape. Thus, for instance, the
representation of letters on the screen (e.g. "c" or "C") will
also show rough edges if looked at closely. CRT pixels are a bit
"fuzzy" at the edges and corners, and so look smoother.

When a plot is sent to the screen, the pixel which is turned on
is (or should be) the one which is nearest to the mathemtical point
in the ideal plot. This inevitably results in a somewhat "broken"
appearance such as you describe. The same applies to any bit-mapped
representation.

One solution for printing purposes is to save the plot in any
vector-graphic format (PostScript or Windows Metafile), where lines
and curves are mathematically defined and when rendered (on, e.g. a
printer which has pixels of the order of 1/1200 inche or 1/300 mm,
or smaller) give results which, to the naked eye, look much smoother
since the dots are much smaller (also, printer "pixels" are often
approximately circles rather than squares). Nevertheless, you can
still detect the roughness if you use a strong magnifying glass.

On screen, there is a rendering technique called "anti-aliasing".
This means that as well as activating a given pixel as above,
neighbouring pixels are also activated at lower intensities,
so that each "real" pixel is surrounded by a halo of "false"
pixels at lower intensity, thereby artifically fuzzing the edges
and giving the eye the impression of smoothness.

It may be (though I don't know) that this is what Excel does,
thereby giving you the impression that the lines are "clean"
rather than "dirty".

But the fundamental message is that every image which is rendered
on a device based on bit-mapping is necessarily "dirty", even if
optical trickery gives the opposite impression!

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861   [NB: New number!]
Date: 24-Sep-04                                       Time: 10:55:08
------------------------------ XFMail ------------------------------



From sdavis2 at mail.nih.gov  Fri Sep 24 12:12:56 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 24 Sep 2004 06:12:56 -0400
Subject: [R] RMySQL and Blob
In-Reply-To: <65213341217E8D458E7C78E6640C74958360BC@waglmb01.labs.agilent.com>
References: <65213341217E8D458E7C78E6640C74958360BC@waglmb01.labs.agilent.com>
Message-ID: <4E3765A1-0E12-11D9-AC51-000A95D7BA10@mail.nih.gov>

Jonathan,

Just a suggestion, but why not just export the images to disk, save a 
URL to them, and do your queries as a two-step process.  1) get URL and 
2) load URL.  This seems to solve both problems.  You just add a table 
to the MySQL database with the urls, fast and easy to work with, and 
use the pixmap library 
(http://cran.us.r-project.org/src/contrib/Descriptions/pixmap.html) to 
load the images from the resulting url.  This may be faster than using 
the database anyway, but even if not, I don't think it would be much 
slower and certainly seems simpler (comments?).

Sean

On Sep 23, 2004, at 8:31 PM, <jonathan_li at agilent.com> wrote:

> Hi,
>
> I tried your suggestion to blindly import the blob into R, doing the 
> following:
>
>> con <- dbConnect("MySQL", host="host", user="user", dbname="db")
>> rs <- dbGetQuery(con, statement=paste("select picture from db where 
>> id=1")
>
> It didn't crash R. But rs is not usable. It seems that it has been 
> converted to a character object.
>
> In addition, we need to pass an image format to R, like png, bmp or 
> something. It's unclear to me how to achieve this even if we can read 
> "rs" as a binary object as you suggested.
>
> Any ideas?
>
> Thanks for suggestions!
> Jonathan
>
>
>
>
>
> -----Original Message-----
> From: David James [mailto:dj at research.bell-labs.com]
> Sent: Wednesday, September 22, 2004 10:06 AM
> To: LI,JONATHAN (A-Labs,ex1)
> Cc: David James
> Subject: Re: [R] RMySQL and Blob
>
>
> jonathan_li at agilent.com wrote:
>> Hi David,
>>
>> The application I have in mind is for images. In my case, size of 
>> images is known and they are not big. As an example, a 64*32 image 
>> will have 2048 pixels. If they are 8-bit grey-level pixels, the image 
>> occupies 2KB memory.
>>
>> I may venture to guess that the unknown size and type of a blob 
>> object in MySQL prevent it from being very usable in R since R 
>> doesn't have a datatype for a binary blob?
>
> You could just blindly try to import it into R (but do it on a clean
> workspace, since it may crash R and you could loose your data!).
> The underlying C code clearly identifies FIELD_TYPE_BLOB and goes
> ahead and puts it in an R character vector (with comments clearly
> stating that it is a hack).  Once it moves the data from the MySQL
> result set buffer to the R vector, it computes the length in both
> places and prints a warning if they differ.
>
> Or you could try to hack something.  For instance, what happens if
> instead of bringing the blob you import, say, as a string?
>     con <- dbConnect("MySQL", ....)
>     rs <- dbSendQuery(con, "select SUBSTRING(blob, 0) from table")
>     dd <- fetch(rs)
>
> One possible general solution would be to define a new class
> "binaryConnection" simmilar to textConnection, so that you
> can readBin() and writeBin() from it.  In this way, blobs could
> return a binary buffer (just a pointer to a block of C memory)
> that could be given to binaryConnection:
>
>    data <- fetch(rs)
>    for(i in seq(nrow(data)){
>       ## extract blobs from each row and create a binary connection
>       bcon = binaryConnection(blobs$image[1])
>       img = readBin(bcon, "integer", n = 2048)
>
>       ## work with the image
>    }
>
> let me know what happens if you try to naively import a blob...
>
> --
> David
>
>>
>> Thanks!
>> Jonathan
>>
>>
>> -----Original Message-----
>> From: David James [mailto:dj at research.bell-labs.com]
>> Sent: Wednesday, September 22, 2004 7:05 AM
>> To: LI,JONATHAN (A-Labs,ex1)
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] RMySQL and Blob
>>
>>
>> Hi Jonathan,
>>
>> Currently RMySQL doesn't handle blob objects.  The mechanics of
>> inserting and extracting blob objects by itself is not too hard,
>> but issues such as how should blobs be made available to R, how to
>> prevent buffers overflows, how to prevent huge blobs from exhausting
>> the available memory, should R callback functions be invoked
>> as chunks of the blob are brought in, etc., need more consideration.
>> And these issues are not R/MySQL specific, but also relevant to
>> other databases and other non-dbms interfaces.
>>
>> BTW there are R facilities (e.g., external pointers, finalizers) that
>> seems quite important for this type of implementation.
>>
>> What type and how big are the blobs that want to import?
>>
>> --
>> David
>>
>> jonathan_li at agilent.com wrote:
>>> Dear R experts,
>>>
>>> Does RMySQL package handle Blob datatype in a MySQL database? Blob 
>>> can represent an image, a sound or some other
>>> large and complex binary objects. In an article published by 
>>> R-database special interest group, named "A common database 
>>> interface (DBI)" (updated June 2003),  it's mentioned in "open 
>>> issues and limitations" that "We need to carefully plan how to deal 
>>> with binary objects".
>>>
>>> Before I invest time to try, I would appreciate any experts' 
>>> opinions.
>>>
>>> Thanks,
>>> Jonathan
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>
>
> -- 
> David A. James
> Statistics Research, Room 2C-276            Phone:  (908) 582-3082
> Bell Labs, Lucent Technologies              Fax:    (908) 582-3340
> Murray Hill, NJ 09794-0636
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From petr.pikal at precheza.cz  Fri Sep 24 12:19:20 2004
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 24 Sep 2004 12:19:20 +0200
Subject: [R] block statistics with POSIX classes
In-Reply-To: <C9FC71F7E9356F40AFE2ACC2099DE1471496B7@MAILSERVER-B.mpsgr.it>
Message-ID: <415410C8.31037.F11FA9@localhost>

Hi

You are probably mixing several things together. 
Are your data time series? 
What does is.ts(y) tell you? 
Is the result TRUE?
In thet cas your construction aggregate(y, 1, mean) can work.

A by argument has to be list in case of aggregate. Is it?

So please try to read help pages to any function you use and 
especially the examples, they can help a lot.

Cheers
Petr

On 23 Sep 2004 at 15:04, Kahra Hannu wrote:

> Thank you Petr and Gabor for the answers.
> 
> They did not, however, solve my original problem. When I have a
> monthly time series y with a POSIX date variable dp, the most obvious
> way to compute e.g. the annual means is to use aggregate(y, 1, mean)
> that works with time series. However, I got stuck with the idea of
> using the 'by' argument as by = dp$year. But in that case y has to be
> a data.frame. The easiest way must be the best way.
> 
> Regards,
> Hannu 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Gabor
> Grothendieck Sent: Thursday, September 23, 2004 12:56 PM To:
> r-help at stat.math.ethz.ch Subject: Re: [R] block statistics with POSIX
> classes
> 
> 
> Kahra Hannu <kahra <at> mpsgr.it> writes:
> 
> : 
> : I have a monthly price index series x, the related return series y =
> diff(log (x)) and a POSIXlt date-time : variable dp. I would like to
> apply annual blocks to compute for example annual block maxima and
> mean of y. : : When studying the POSIX classes, in the first stage of
> the learning curve, I computed the maximum drawdown : of x: : > mdd <-
> maxdrawdown(x) : > max.dd <- mdd$maxdrawdown : > from <-
> as.character(dp[mdd$from]) : > to <- as.character(dp[mdd$to])         
>              : > from; to : [1] "2000-08-31" : [1] "2003-03-31" : that
> gives me the POSIX dates of the start and end of the period and
> suggests that I have done something correctly. : : Two questions: :
> (1) how to implement annual blocks and compute e.g. annual max, min
> and mean of y (each year's max, min, mean)? : (2) how to apply POSIX
> variables with the 'block' argument in gev in the evir package? : :
> The S+FinMetrics function aggregateSeries does the job in that module;
> but I do not know, how handle it in R. : My guess is that (1) is done
> by using the function aggregate, but how to define the 'by' argument
> with POSIX variables?
> 
> 
> 1. To create a ts monthly time series you specify the first month and
> a frequency of 12 like this.  
> 
> z.m <- ts(rep(1:6,4), start = c(2000,1), freq = 12)
> z.m
> 
> # Annual aggregate is done using aggregate.ts with nfreq = 1
> z.y <- aggregate(z.m, nfreq = 1, max)
> z.y
> 
> # To create a POSIXct series of times using seq
> # (This will use GMT.  Use tz="" arg to ISOdate if you want current
> # tz.)
> z.y.times <- seq(ISOdate(2000,1,1), length = length(z.y), by = "year")
> z.y.times
> 
> 2. Have not used evir but looking at ?gev it seems you can
> use block = 12 if you have monthly data and want the blocks to be
> successive 12 month periods or you can add a POSIXct times attribute
> to your data as below (also see comment re tz above) and then use
> block = "year" in your gev call.
> 
> attr(z.m, "times") <- seq(ISOdate(2000,1,1), length=length(z.m),
> by="month") str(z.m)  # display z.m along with attribute info
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From tom_woody at swissinfo.org  Fri Sep 24 12:39:43 2004
From: tom_woody at swissinfo.org (=?ISO-8859-15?Q?Thomas_Sch=F6nhoff?=)
Date: Fri, 24 Sep 2004 12:39:43 +0200
Subject: [R] fix and edit don't work the expected way
Message-ID: <4153F96F.4070302@swissinfo.org>

Hello,

I am tinkering a bit with options(), namely, how to query and set them 
up to suit my needs.

1)
The basic problem seems that the editor entry in options looks like this:
 > options()
---------------------------------------------------------
$editor
[1] "emacsclient"
---------------------------------------------------------

After setting this option to /usr/bin/emacs by doing:

 > options(editor="/usr/bin/emacs")

I try to run fix(fun) or edit(fun) and run into this error:
-----------------------------------------------------------------
Error in edit(name, file, editor) : An error occurred on line 17
use a command like
x <- edit()
------------------------------------------------------------------

This error is also noticed when loading the function into edit()/fix(), 
doing some changes and trying to save these modifications too tmp buffer.


2)
Furthermore I try to set the $editor option not only for current but 
also for future session!? It seems like that I run regularily into 
troubles starting $editor(emacsclient) from within Emacs/ESS/R enviromnent.

How to do that?
I've read in FAQ that local copies of .Options are quietly disregarded 
at start up.
So I started looking at the global one in /etc/R/Renvir directory and 
also tried :
----------------------------------------------------------------------
 > save.image()
---------------------------------------------------------------------

But this wasn't of much help to store the $editor variable on the long run!
(Since I am at the beginning of my exploration of R I didn't want to 
mess up the whole system configuration by doing some modifications to 
this file)

Obviousely, I don't do it correctly, but I can't figure out whats wrong? 
Anyone help is appreciated.

Thanks

Thomas

------------------------------------------------------------------------------------------------------------
platform i386-pc-linux-gnu
arch     i386
os       linux-gnu (Debian)
system   i386, linux-gnu
status
major    1
minor    9.1
year     2004
month    06
day      21
language R

Emacs21        21.3+1-7
ESS            5.2.2-2



From tom_woody at swissinfo.org  Fri Sep 24 13:03:27 2004
From: tom_woody at swissinfo.org (=?ISO-8859-15?Q?Thomas_Sch=F6nhoff?=)
Date: Fri, 24 Sep 2004 13:03:27 +0200
Subject: [R] debugging functions within Emacs/ESS/R
Message-ID: <4153FEFF.6050200@swissinfo.org>

Hi,

I currently following some introductory material "Data mining with R", 
which was highly reccommended to me (its really great!).

During my studies I tried to run a given function to identify and 
substitute unknown values.
Seemingly, running this function (page 57) did not work and gives me an 
error message.

It would be very easy just to copy and paste this function to ask for 
help on this list. Guess' that most afficiandos on this list need a 
simple glimpse to tell me whats wrong,
but I am more interested in learning how to debug buggy functions within 
Emacs/ESS/R by myself!


Reading FAQ, ?debug, ?traceback, ?recover, ?browse help files didn't 
prove to be a good starting point for me (sorry, my programming skills 
are somewhat limited at the moment).

Is there any learning-by-doing example of debugging functions in 
Emacs/ESS/R I may have not noticed now?

Thanks

Thomas



From alkauffm at rz.uni-potsdam.de  Fri Sep 24 13:36:55 2004
From: alkauffm at rz.uni-potsdam.de (Albrecht Kauffmann)
Date: Fri, 24 Sep 2004 13:36:55 +0200 (CEST)
Subject: [R] maps for Russian Federation
Message-ID: <Pine.GSO.4.58.0409241327050.14176@persius.rz.uni-potsdam.de>

Dear all,

I am interested in plotting maps visualizing spatial statistics in an
aggregated fashion, according to administrative boundaries. Partially, I
want to visualize some spatial data for administrative units (autonomous
republics, oblasts, krays) of the Russian Federation on a geographical
map.

I have found the maps package (and related) and would like to use this
package e.g. in a kind of:
map("state",fill=T,col=color)
where color is dependent on the statistic of interest.

Still I lack a data file for counties' boundaries in Russia. Does anybody
know where to find one? What format do I need? Is there any convenient
tool for converting from other formats?

With many thanks for any hint

Albrecht Kauffmann
economist, Potsdam university



From fprass at yahoo.com.br  Fri Sep 24 14:13:38 2004
From: fprass at yahoo.com.br (Fernando Prass)
Date: Fri, 24 Sep 2004 09:13:38 -0300 (ART)
Subject: [R] members of clusters
In-Reply-To: <1095957180.7733.4.camel@snowdon.science.uva.nl>
Message-ID: <20040924121338.47107.qmail@web42004.mail.yahoo.com>

Hi,

How I can see the members of clusters generate by AGNES or DIANA (package
"clusters")?

Thanks,


Fernando Prass



From Roger.Bivand at nhh.no  Fri Sep 24 14:23:03 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 24 Sep 2004 14:23:03 +0200 (CEST)
Subject: [R] maps for Russian Federation
In-Reply-To: <Pine.GSO.4.58.0409241327050.14176@persius.rz.uni-potsdam.de>
Message-ID: <Pine.LNX.4.44.0409241353260.24170-100000@reclus.nhh.no>

On Fri, 24 Sep 2004, Albrecht Kauffmann wrote:

> Dear all,
> 
> I am interested in plotting maps visualizing spatial statistics in an
> aggregated fashion, according to administrative boundaries. Partially, I
> want to visualize some spatial data for administrative units (autonomous
> republics, oblasts, krays) of the Russian Federation on a geographical
> map.
> 
> I have found the maps package (and related) and would like to use this
> package e.g. in a kind of:
> map("state",fill=T,col=color)
> where color is dependent on the statistic of interest.
> 
> Still I lack a data file for counties' boundaries in Russia. Does anybody
> know where to find one? What format do I need? Is there any convenient
> tool for converting from other formats?
> 

It may be that someone has boundary data compiled in maps package format, 
and can let you know. Googling on "Russian federation" and shapefile gave:

http://polyglot.lss.wisc.edu/creeca/kaiser/oblasty.zip

which has 88 spatial units in geographical coordinates, and seems not to
be restricted (though you should probably ask the provider for
permission).

http://polyglot.lss.wisc.edu/creeca/kaiser/rayony.zip

seems to have 1916 units, also in geographical coordinates.

Shapefiles may be used in R with packages maptools or shapefiles.

http://wagda.lib.washington.edu/data/russianfed/

has listings of data in ArcInfo e00 format - in addition to zipped 
shapefiles - e00 files may be read using the R package RArcInfo; these 
are projected, Albers equal-area, metadata on the website. The shapefile 
of rayony has 2415 units, that of oblasty 195 (maybe the numbers differ 
if several parts are parts of one multiple polygon object in one source, 
and are separate polygons in the other, this seems to be the case here).

Note that boundary files do get out-of-date, and need careful matching to 
your own data to maintain integrity. Smaller administrative areas 
notoriously merge or split, so a boundary map may only apply so a very 
short time window.

Roger Bivand


> With many thanks for any hint
> 
> Albrecht Kauffmann
> economist, Potsdam university
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From tobias.verbeke at bivv.be  Fri Sep 24 14:56:02 2004
From: tobias.verbeke at bivv.be (tobias.verbeke@bivv.be)
Date: Fri, 24 Sep 2004 14:56:02 +0200
Subject: [R] debugging functions within Emacs/ESS/R
In-Reply-To: <4153FEFF.6050200@swissinfo.org>
Message-ID: <OF1E455E8C.BC51A9E7-ONC1256F19.0046DC4F-C1256F19.00470CAD@BIVV.BE>



From tobias.verbeke at telenet.be  Fri Sep 24 15:12:58 2004
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Fri, 24 Sep 2004 13:12:58 +0000
Subject: [R] debugging functions within Emacs/ESS/R
Message-ID: <W314401621916481096031578@asteria.telenet-ops.be>


I'm sorry. My message just pointed to
the document by Roger Peng:

http://www.biostat.jhsph.edu/~rpeng/docs/R-debug-tools.pdf

HTH,
T.



From kjetil at acelerate.com  Fri Sep 24 14:34:19 2004
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Fri, 24 Sep 2004 08:34:19 -0400
Subject: [R] "moving average" method for time series objects
In-Reply-To: <A00D32D4F8342C4CB741761ACE09130AE3D306@elk.gartner.com>
References: <A00D32D4F8342C4CB741761ACE09130AE3D306@elk.gartner.com>
Message-ID: <4154144B.5000708@acelerate.com>

Schwarz,Paul wrote:

>Dear R-Help readers,
>
>I suspect that this question must be a FAQ, but my investigation of the archives has not been very revealing.  Is there an R function for calculating moving averages of time series objects?
>
>  
>
 library(gregmisc)
 ?running
 test <- ts(rnorm(100))

 test2 <- running(test, fun=median, width=10)
 length(test2)
[1] 91

you want fun=mean

Kjetil

-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra



From James_A_Rogers at groton.pfizer.com  Fri Sep 24 15:23:12 2004
From: James_A_Rogers at groton.pfizer.com (Rogers, James A [PGRD Groton])
Date: Fri, 24 Sep 2004 09:23:12 -0400
Subject: [R] anova and post hoc multicomparison tests
Message-ID: <C735670CCC69D61193DA0002A58EE9900D7F5425@groexmb07.pfizer.com>

Guillaume, 

Your comments are a compliment to R.

Undoubtedly other software is preferable if you want to do
Student-Newman-Keuls or Fisher's "protected" LSD (ANOVA F-test followed by
unadjusted T-tests). Perhaps the reason is that neither Student-Newman-Keuls
nor Fisher's "protected" LSD is a valid multiple comparison procedure.
Student-Newman-Keuls does not even control the probability of making at
least one false assertion of inequality (which is the almost the minimum one
could ask of a multiple comparison procedure). For details, including
examples of where these methods fail, see:

Hsu, J.C. (1996). Multiple Comparisons: Theory and Methods. Chapman & Hall.

If you want to use R to perform valid multiple comparisons, such as
Dunnett's MCC or Tukey's HSD, see the function TukeyHSD and also the
multcomp package. 

Jim Rogers

> Message: 78
> Date: Fri, 24 Sep 2004 10:54:55 +0200
> From: "BLANCHER Guillaume" <G.BLANCHER at isa-lille.fr>
> Subject: [R] anova and post hoc multicomparison tests
> To: <r-help at stat.math.ethz.ch>
> Message-ID: <F2B8DADA7A384D48925C74D52D68AE702484DC at srv-exch.isa.net>
> Content-Type: text/plain;	charset="us-ascii"
> 
> Hello everyone, 
> 
> Like a lot of people, I have been looking for functions in R doing ANOVA
> (ok) and performing multicomparisons (like Student-Newman-Keuls, etc.).
> As I have been a little bit disappointed, I have bee looking through the
> net for such "open source" softwares. I found one in:
> http://www.statpages.org/miller/openstat/OS4.html
> I have begun to use it, and it seems good and simple to understand (as
> for a non-specialist like me).
> Sorry for R, but I prefer OpenStat4 to R for ANOVAs and post hoc tests.
> 
> Guillaume


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From poizot at cnam.fr  Fri Sep 24 15:24:06 2004
From: poizot at cnam.fr (Poizot Emmanuel)
Date: Fri, 24 Sep 2004 15:24:06 +0200
Subject: [R] R from outside program
Message-ID: <200409241524.06305.poizot@cnam.fr>

Hi all,
I'm writing a program in C++ in witch there should be some graphical outputs.
To do so, I would like to use R with the command :
R --no-save < cmdfile.R ,  where  I put the R graphic commands in the 
cmdfile.R file.
I call R from my C++ code but as R seems to run in batch mode, there are no 
graphical outputs!
How can I do to get the graphics outputs ?
-- 
Sincerely
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Emmanuel Poizot
Cnam/Intechmer
B.P. 324
50103 Cherbourg Cedex
T??l: (33)(0)233887342
Fax: (33)(0)233887339
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From sdavis2 at mail.nih.gov  Fri Sep 24 15:42:46 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 24 Sep 2004 09:42:46 -0400
Subject: [R] R from outside program
In-Reply-To: <200409241524.06305.poizot@cnam.fr>
References: <200409241524.06305.poizot@cnam.fr>
Message-ID: <9E21F0C0-0E2F-11D9-AC51-000A95D7BA10@mail.nih.gov>

You'll probably need to send your cmdfile.R to see what is in it, as 
that is where the problem likely is.  However, if you do something 
line:

pdf('my.pdf')
plot(1:10,1:10)
dev.off()

in your cmdfile.R, you will get a pdf file of the plot saved in the 
directory where you ran your script.  Note that you need to open a 
device like pdf, png, etc. for plots to be saved.  They aren't saved 
automatically

Sean

On Sep 24, 2004, at 9:24 AM, Poizot Emmanuel wrote:

> Hi all,
> I'm writing a program in C++ in witch there should be some graphical 
> outputs.
> To do so, I would like to use R with the command :
> R --no-save < cmdfile.R ,  where  I put the R graphic commands in the
> cmdfile.R file.
> I call R from my C++ code but as R seems to run in batch mode, there 
> are no
> graphical outputs!
> How can I do to get the graphics outputs ?
> -- 
> Sincerely
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Emmanuel Poizot
> Cnam/Intechmer
> B.P. 324
> 50103 Cherbourg Cedex
> T??l: (33)(0)233887342
> Fax: (33)(0)233887339
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Sep 24 15:43:29 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 24 Sep 2004 15:43:29 +0200
Subject: [R] R from outside program
In-Reply-To: <200409241524.06305.poizot@cnam.fr>
References: <200409241524.06305.poizot@cnam.fr>
Message-ID: <41542481.6000902@statistik.uni-dortmund.de>

Poizot Emmanuel wrote:

> Hi all,
> I'm writing a program in C++ in witch there should be some graphical outputs.
> To do so, I would like to use R with the command :
> R --no-save < cmdfile.R ,  where  I put the R graphic commands in the 
> cmdfile.R file.
> I call R from my C++ code but as R seems to run in batch mode, there are no 
> graphical outputs!
> How can I do to get the graphics outputs ?

Open a device, plot, and close the device.
See ?Device

Uwe Ligges



From m.conrad at exec.uoguelph.ca  Fri Sep 24 15:51:21 2004
From: m.conrad at exec.uoguelph.ca (Mark Conrad)
Date: Fri, 24 Sep 2004 09:51:21 -0400
Subject: [R] geographically weighted glm
Message-ID: <41542659.1070502@exec.uoguelph.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040924/2f533460/attachment.pl

From dj at research.bell-labs.com  Fri Sep 24 16:05:18 2004
From: dj at research.bell-labs.com (David James)
Date: Fri, 24 Sep 2004 10:05:18 -0400
Subject: [R] RMySQL and Blob
In-Reply-To: <65213341217E8D458E7C78E6640C74958360BC@waglmb01.labs.agilent.com>;
	from jonathan_li@agilent.com on Thu, Sep 23, 2004 at 05:31:28PM -0700
References: <65213341217E8D458E7C78E6640C74958360BC@waglmb01.labs.agilent.com>
Message-ID: <20040924100517.B26174@jessie.research.bell-labs.com>

jonathan_li at agilent.com wrote:
> Hi,
> 
> I tried your suggestion to blindly import the blob into R, doing the following:
> 
> > con <- dbConnect("MySQL", host="host", user="user", dbname="db")
> > rs <- dbGetQuery(con, statement=paste("select picture from db where id=1")
> 
> It didn't crash R. But rs is not usable. It seems that it has been converted to a character object.

That's exactly correct -- that's what I mentioned the code does, but
what I was wondering is whether you could make use of such a character 
vector -- now I see that you can't.

> 
> In addition, we need to pass an image format to R, like png, bmp or something. It's unclear to me how to achieve this even if we can read "rs" as a binary object as you suggested.

Indeed the problem is more interesting than just bringing a blob
into R.  In general R cannot possibly know all the blob types
(there are just too many -- images, movies, sounds, binary data of
any kind, and many more yet to be created), so we have to define
a general mechanism for pluging in user-specified converters that
take a pointer to a blob and produce something that can be used
in R computations (see my comments re: a binaryConnection class to
work with binary buffers in my previous email quoted below.)

> 
> Any ideas?

I haven't worked with images, but the email from Sean Davis suggesting
dumping the images to files and then importing them with the pixmap
library seems quite reasonable to me.

Regards,

--
David

> 
> Thanks for suggestions!
> Jonathan
> 
> 
> 
> 
> 
> -----Original Message-----
> From: David James [mailto:dj at research.bell-labs.com]
> Sent: Wednesday, September 22, 2004 10:06 AM
> To: LI,JONATHAN (A-Labs,ex1)
> Cc: David James
> Subject: Re: [R] RMySQL and Blob
> 
> 
> jonathan_li at agilent.com wrote:
> > Hi David,
> > 
> > The application I have in mind is for images. In my case, size of images is known and they are not big. As an example, a 64*32 image will have 2048 pixels. If they are 8-bit grey-level pixels, the image occupies 2KB memory. 
> > 
> > I may venture to guess that the unknown size and type of a blob object in MySQL prevent it from being very usable in R since R doesn't have a datatype for a binary blob?
> 
> You could just blindly try to import it into R (but do it on a clean
> workspace, since it may crash R and you could loose your data!).
> The underlying C code clearly identifies FIELD_TYPE_BLOB and goes
> ahead and puts it in an R character vector (with comments clearly
> stating that it is a hack).  Once it moves the data from the MySQL
> result set buffer to the R vector, it computes the length in both
> places and prints a warning if they differ.
> 
> Or you could try to hack something.  For instance, what happens if
> instead of bringing the blob you import, say, as a string?
>     con <- dbConnect("MySQL", ....)
>     rs <- dbSendQuery(con, "select SUBSTRING(blob, 0) from table")
>     dd <- fetch(rs)
> 
> One possible general solution would be to define a new class
> "binaryConnection" simmilar to textConnection, so that you
> can readBin() and writeBin() from it.  In this way, blobs could
> return a binary buffer (just a pointer to a block of C memory) 
> that could be given to binaryConnection:
> 
>    data <- fetch(rs)
>    for(i in seq(nrow(data)){
>       ## extract blobs from each row and create a binary connection
>       bcon = binaryConnection(blobs$image[1])
>       img = readBin(bcon, "integer", n = 2048)
>       
>       ## work with the image
>    }
> 
> let me know what happens if you try to naively import a blob...
> 
> --
> David
> 
> > 
> > Thanks!
> > Jonathan
> > 
> > 
> > -----Original Message-----
> > From: David James [mailto:dj at research.bell-labs.com]
> > Sent: Wednesday, September 22, 2004 7:05 AM
> > To: LI,JONATHAN (A-Labs,ex1)
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] RMySQL and Blob
> > 
> > 
> > Hi Jonathan,
> > 
> > Currently RMySQL doesn't handle blob objects.  The mechanics of
> > inserting and extracting blob objects by itself is not too hard,
> > but issues such as how should blobs be made available to R, how to
> > prevent buffers overflows, how to prevent huge blobs from exhausting
> > the available memory, should R callback functions be invoked
> > as chunks of the blob are brought in, etc., need more consideration.
> > And these issues are not R/MySQL specific, but also relevant to
> > other databases and other non-dbms interfaces.
> > 
> > BTW there are R facilities (e.g., external pointers, finalizers) that 
> > seems quite important for this type of implementation.  
> > 
> > What type and how big are the blobs that want to import?
> > 
> > --
> > David
> > 
> > jonathan_li at agilent.com wrote:
> > > Dear R experts,
> > > 
> > > Does RMySQL package handle Blob datatype in a MySQL database? Blob can represent an image, a sound or some other 
> > > large and complex binary objects. In an article published by R-database special interest group, named "A common database interface (DBI)" (updated June 2003),  it's mentioned in "open issues and limitations" that "We need to carefully plan how to deal with binary objects". 
> > > 
> > > Before I invest time to try, I would appreciate any experts' opinions.
> > > 
> > > Thanks,
> > > Jonathan
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > 
>



From meinhardploner at gmx.net  Fri Sep 24 16:05:19 2004
From: meinhardploner at gmx.net (Meinhard Ploner)
Date: Fri, 24 Sep 2004 16:05:19 +0200
Subject: [R] emacs, Mac OS X, R
Message-ID: <C4958F90-0E32-11D9-9448-0003938C0ABE@gmx.net>

Hi!

Since August I am using emacs on my Macintosh to edit the R objects. I 
have installed R 1.9.1, Mac OS X 10.3.5 and GNU Emacs 21.2.1. However 
there are some issues I haven't resolved:

a) switch the caps lock key to the meta key (and when this is not 
possible, switch the alt/option key to the meta). The switch should 
work only within emacs!

b) having different colors for the code, i.e. comments, commands, 
strings, ...

thanks in advance!
Meinhard



From Roger.Bivand at nhh.no  Fri Sep 24 16:15:44 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 24 Sep 2004 16:15:44 +0200 (CEST)
Subject: [R] geographically weighted glm
In-Reply-To: <41542659.1070502@exec.uoguelph.ca>
Message-ID: <Pine.LNX.4.44.0409241609540.24170-100000@reclus.nhh.no>

On Fri, 24 Sep 2004, Mark Conrad wrote:

> Hi all,
> I am interested in obtaining R code related to geographically weighted 
> regression.
> 
> In particular, I am interested in building geographically weighted 
> Poisson GLMs.  The model will contain categorical and continuous x 
> independent variables, with interaction effects between categorical and 
> continuous variables.
> 
> Anybody have anything I can look at?

Look at draft packages sp and spgwr on:

http://sourceforge.net/projects/r-spatial/

where spgwr contains gwr functions for linear models. These would need to
be modified to suit glm, but as glm.fit accepts weights, this ought to be
feasible. You need sp too, because spgwr depends on the S4 spatial classes
defined there. These are packages in an unfinished state, but progress on
sp (and back-fitting analysis packages onto sp) is (we hope) going to
happen at a workshop in Lancaster, UK, 2-5 November (where interested
people can join in online). YMMV with GWR, by the way.

Roger Bivand

Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From kwright at eskimo.com  Fri Sep 24 16:24:10 2004
From: kwright at eskimo.com (Kevin Wright)
Date: Fri, 24 Sep 2004 07:24:10 -0700 (PDT)
Subject: [R] Function sort.data.frame
Message-ID: <200409241424.HAA07214@eskimo.com>


I can never remember how to use "order" to sort the rows of a data frame,
so like any good, lazy programmer, I decided to write my own function.

The idea is to specify a data.frame and a one-sided formula with +/- 
indicating ascending/descending.  For example:
  sort.data.frame(~ +nitro -Variety, Oats)

Since sorting of a data.frame is an oft-asked question on this list, I am
posting my function in hopes that others may find it useful.  

Computing 'on the language' (formulas) is not my strongest point, so the
function can probably be improved.  A similar idea could be used for
matrix objects.  Feedback is welcome.

Kevin Wright




sort.data.frame <- function(form,dat){
  # Author: Kevin Wright
  # Some ideas from Andy Liaw
  #   http://tolstoy.newcastle.edu.au/R/help/04/07/1076.html

  # Use + for ascending, - for decending.  
  # Sorting is left to right in the formula
  
  # Useage is either of the following:
  # sort.data.frame(~Block-Variety,Oats)
  # sort.data.frame(Oats,~-Variety+Block)
  
  # If dat is the formula, then switch form and dat
  if(inherits(dat,"formula")){
    f=dat
    dat=form
    form=f
  }
  if(form[[1]] != "~")
    stop("Formula must be one-sided.")

  # Make the formula into character and remove spaces
  formc <- as.character(form[2]) 
  formc <- gsub(" ","",formc) 
  # If the first character is not + or -, add +
  if(!is.element(substring(formc,1,1),c("+","-")))
    formc <- paste("+",formc,sep="")
  # Extract the variables from the formula
  vars <- unlist(strsplit(formc, "[\\+\\-]"))
  vars <- vars[vars!=""] # Remove spurious "" terms

  # Build a list of arguments to pass to "order" function
  calllist <- list()
  pos=1 # Position of + or -
  for(i in 1:length(vars)){
    varsign <- substring(formc,pos,pos)
    pos <- pos+1+nchar(vars[i])
    if(is.factor(dat[,vars[i]])){
      if(varsign=="-")
        calllist[[i]] <- -rank(dat[,vars[i]])
      else
        calllist[[i]] <- rank(dat[,vars[i]])
    }
    else {
      if(varsign=="-")
        calllist[[i]] <- -dat[,vars[i]]
      else
        calllist[[i]] <- dat[,vars[i]]
    }
  }
  dat[do.call("order",calllist),]

}


d = data.frame(b=factor(c("Hi","Med","Hi","Low"),levels=c("Low","Med","Hi"),
               ordered=TRUE),
               x=c("A","D","A","C"),y=c(8,3,9,9),z=c(1,1,1,2))
sort.data.frame(~-z-b,d)
sort.data.frame(~x+y+z,d)
sort.data.frame(~-x+y+z,d)
sort.data.frame(d,~x-y+z)



From kjetil at acelerate.com  Fri Sep 24 16:17:48 2004
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Fri, 24 Sep 2004 10:17:48 -0400
Subject: [R] geographically weighted glm
In-Reply-To: <41542659.1070502@exec.uoguelph.ca>
References: <41542659.1070502@exec.uoguelph.ca>
Message-ID: <41542C8C.4090209@acelerate.com>

Mark Conrad wrote:

>Hi all,
>I am interested in obtaining R code related to geographically weighted 
>regression.
>
>In particular, I am interested in building geographically weighted 
>Poisson GLMs.  The model will contain categorical and continuous x 
>independent variables, with interaction effects between categorical and 
>continuous variables.
>
>Anybody have anything I can look at?
>
>
>thanks,
>Mark.
>
>  
>
Have a look at CRAN package  geoRglm

Kjetil

-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra



From David.Brahm at geodecapital.com  Fri Sep 24 17:08:52 2004
From: David.Brahm at geodecapital.com (Brahm, David)
Date: Fri, 24 Sep 2004 11:08:52 -0400
Subject: [R] "moving average" method for time series objects
Message-ID: <6AF7541D27821A4BAB515245C1A2FEED03776ACC@MSGBOSCLC2WIN.DMN1.FMR.COM>

Paul Schwarz <Paul.Schwarz at gartner.com> wrote:
> Is there an R function for calculating moving averages of time series
objects?

Others have replied, but here's the "simple" answer for a trailing 5-day
moving average, no non-standard packages needed:
R> x <- 1:20
R> filter(x, rep(1/5,5), sides=1)

-- David Brahm (brahm at alum.mit.edu)



From B.Rowlingson at lancaster.ac.uk  Fri Sep 24 17:35:51 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 24 Sep 2004 16:35:51 +0100
Subject: [R] Throwing expressions around
Message-ID: <41543ED7.4060802@lancaster.ac.uk>

I'm trying to write some code that throws a few expressions around the
place, and I've boiled down the problem to be equivalent to this.

Consider the curve function which plots expressions in 'x':

  > curve(x^2)

Now wrap that in the most naive wrapper function:

  > fc=function(m){curve(m)}

  and try it:

  > fc(x^2)
  Error in eval(expr, envir, enclos) : Object "x" not found

What could be done to my 'fc' or the expression processing of curve to
make this sort of thing work?

What I also want to do is provide a default, something like:

  fc = function(m=sqrt(x)){curve(m)}

It's not actually curve() that I want to call, but something similar 
I've written myself, so I can fiddle with that as I wish.

I've had a read of the R Language Definition - I imagine the answer is 
in there somewhere...

Barry



From simon at stats.gla.ac.uk  Fri Sep 24 17:41:17 2004
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Fri, 24 Sep 2004 16:41:17 +0100 (BST)
Subject: [R] geographically weighted glm
In-Reply-To: <41542659.1070502@exec.uoguelph.ca>
References: <41542659.1070502@exec.uoguelph.ca>
Message-ID: <Pine.LNX.4.58.0409241630200.26229@moon.stats.gla.ac.uk>

> I am interested in obtaining R code related to geographically weighted 
> regression.
- package mgcv's gam function allows you to fit `variable parameter 
models' which include geographically weighted regression as a special 
case. For example if you think `income' depends on `age', but expect this 
to vary with space (x,z), then you might fit a model something like:

income = const + \beta(x,z)*age + error

where \beta(x,z) is the geographically varying coefficient. `gam' could be 
used to fit this with a call something like: 

gam(income~age + s(x,z,by=age))

(the Poisson case is handled by using family=poisson, in the usual way). 
The degree of smoothness of the variation in \beta will be chosen 
automatically from the data (although you can over-ride this if you like). 
If you have more than a few thousand data, then you might need to use the 
efficiency tricks covered in ?gam.

Simon

_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk        www.stats.gla.ac.uk/~simon/
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814



From rpeng at jhsph.edu  Fri Sep 24 17:42:45 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 24 Sep 2004 11:42:45 -0400
Subject: [R] Throwing expressions around
In-Reply-To: <41543ED7.4060802@lancaster.ac.uk>
References: <41543ED7.4060802@lancaster.ac.uk>
Message-ID: <41544075.5090805@jhsph.edu>

I think you want some eval/substitute action, such as

fc <- function(m) { eval(substitute(curve(m))) }

-roger

Barry Rowlingson wrote:
> I'm trying to write some code that throws a few expressions around the
> place, and I've boiled down the problem to be equivalent to this.
> 
> Consider the curve function which plots expressions in 'x':
> 
>  > curve(x^2)
> 
> Now wrap that in the most naive wrapper function:
> 
>  > fc=function(m){curve(m)}
> 
>  and try it:
> 
>  > fc(x^2)
>  Error in eval(expr, envir, enclos) : Object "x" not found
> 
> What could be done to my 'fc' or the expression processing of curve to
> make this sort of thing work?
> 
> What I also want to do is provide a default, something like:
> 
>  fc = function(m=sqrt(x)){curve(m)}
> 
> It's not actually curve() that I want to call, but something similar 
> I've written myself, so I can fiddle with that as I wish.
> 
> I've had a read of the R Language Definition - I imagine the answer is 
> in there somewhere...
> 
> Barry
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From sdavis2 at mail.nih.gov  Fri Sep 24 17:48:41 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 24 Sep 2004 11:48:41 -0400
Subject: [R] Error with repeat lines() in function
Message-ID: <352CBEB2-0E41-11D9-AC51-000A95D7BA10@mail.nih.gov>

I have a function that does some plotting.  I then add lines to the  
plot.  If executed one line at a time, there is not a problem.  If I  
execute the function, though, I get:

Error in ans[[1]] : subscript out of bounds

This always occurs after the second lines command, and doesn't happen  
with all of my data points (some do not have errors).  Any ideas?

Thanks,
Sean


  function(x,annot,rat1,rat2,rf,...) {
     par(las=2)
     wh <- which(annot[,5]==x)
     xmax <- max(annot[wh,4])
     xmin <- min(annot[wh,3])
     chr <- annot[wh,2][1]
     wh.rf <- rf$chrom==as.character(chr) & rf$txStart>xmin &  
rf$txEnd<xmax
     par(mfrow=c(2,1))
     plot(annot[wh,3],rat1[wh],type="l",xlab="",ylab="log2  
Ratio",main=x,...)
     points(annot[wh,3],rat1[wh])
     apply(rf[wh.rf,],1,function(z) {
       browser()
       if (z[4]=="+") {
         color <- 'green'
         yoffset=1
       } else {
         color <- 'red'
         yoffset=-1
       }
        
lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/ 
10)),lwd=2,col=color)
        
lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/ 
10)),lwd=2,col=color)
     })
     abline(h=0,lty=2)
}



From ligges at statistik.uni-dortmund.de  Fri Sep 24 18:00:19 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 24 Sep 2004 18:00:19 +0200
Subject: [R] Throwing expressions around
In-Reply-To: <41543ED7.4060802@lancaster.ac.uk>
References: <41543ED7.4060802@lancaster.ac.uk>
Message-ID: <41544493.5010706@statistik.uni-dortmund.de>

Barry Rowlingson wrote:

> I'm trying to write some code that throws a few expressions around the
> place, and I've boiled down the problem to be equivalent to this.
> 
> Consider the curve function which plots expressions in 'x':
> 
>  > curve(x^2)
> 
> Now wrap that in the most naive wrapper function:
> 
>  > fc=function(m){curve(m)}
> 
>  and try it:
> 
>  > fc(x^2)


You can try

  fc <- function(m) do.call("curve", list(substitute(m)))
  fc(x^2)


Uwe Ligges



>  Error in eval(expr, envir, enclos) : Object "x" not found
> 
> What could be done to my 'fc' or the expression processing of curve to
> make this sort of thing work?
> 
> What I also want to do is provide a default, something like:
> 
>  fc = function(m=sqrt(x)){curve(m)}
> 
> It's not actually curve() that I want to call, but something similar 
> I've written myself, so I can fiddle with that as I wish.
> 
> I've had a read of the R Language Definition - I imagine the answer is 
> in there somewhere...
> 
> Barry
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Sep 24 18:05:13 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 24 Sep 2004 18:05:13 +0200
Subject: [R] Error with repeat lines() in function
In-Reply-To: <352CBEB2-0E41-11D9-AC51-000A95D7BA10@mail.nih.gov>
References: <352CBEB2-0E41-11D9-AC51-000A95D7BA10@mail.nih.gov>
Message-ID: <415445B9.3070505@statistik.uni-dortmund.de>

Sean Davis wrote:

> I have a function that does some plotting.  I then add lines to the  
> plot.  If executed one line at a time, there is not a problem.  If I  
> execute the function, though, I get:
> 
> Error in ans[[1]] : subscript out of bounds
> 
> This always occurs after the second lines command, and doesn't happen  
> with all of my data points (some do not have errors).  Any ideas?

Please give an example how to produce the error,
i.e. specify a very small toy example (including generated data and the 
call to your function).
Many people on this list are quite busy these days and don't want to 
think about how to call your function and invent an example ...

Uwe Ligges



> Thanks,
> Sean
> 
> 
>  function(x,annot,rat1,rat2,rf,...) {
>     par(las=2)
>     wh <- which(annot[,5]==x)
>     xmax <- max(annot[wh,4])
>     xmin <- min(annot[wh,3])
>     chr <- annot[wh,2][1]
>     wh.rf <- rf$chrom==as.character(chr) & rf$txStart>xmin &  rf$txEnd<xmax
>     par(mfrow=c(2,1))
>     plot(annot[wh,3],rat1[wh],type="l",xlab="",ylab="log2  
> Ratio",main=x,...)
>     points(annot[wh,3],rat1[wh])
>     apply(rf[wh.rf,],1,function(z) {
>       browser()
>       if (z[4]=="+") {
>         color <- 'green'
>         yoffset=1
>       } else {
>         color <- 'red'
>         yoffset=-1
>       }
>        lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/ 
> 10)),lwd=2,col=color)
>        lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/ 
> 10)),lwd=2,col=color)
>     })
>     abline(h=0,lty=2)
> }
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From nassar at noos.fr  Fri Sep 24 17:23:09 2004
From: nassar at noos.fr (Naji)
Date: Fri, 24 Sep 2004 17:23:09 +0200
Subject: [R] Contout plot options
Message-ID: <BD7A087D.59%nassar@noos.fr>

Hi all


As a new user of R, I need some help for a contour plot..
- How can I change x,y labels format ie .01 -> 1%
- Is is possible to change Axis & Grph fonts to Times 11?
- How can I change the xaxp? I gave it several trials without success..

Par(xaxp(0,1,4)
Contour(x,y,z,label=c("2%","4%","6%","8%","10%","12%","14%","16%","18%"))
Title("Isoquant Market share", xlab="Availability",ylab="Share of
Prefeences")

Thanks for help

-> Is there any tutorial for R graphs?

Best regards
Naji



From sdavis2 at mail.nih.gov  Fri Sep 24 18:23:51 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 24 Sep 2004 12:23:51 -0400
Subject: [R] Error with repeat lines() in function
In-Reply-To: <OFF7EDB7CE.3D2E32D9-ON85256F19.00598575@nd.convergys.com>
References: <OFF7EDB7CE.3D2E32D9-ON85256F19.00598575@nd.convergys.com>
Message-ID: <1EDAFFAB-0E46-11D9-AC51-000A95D7BA10@mail.nih.gov>

Working on a toy example.  I have run the debugger/browser on the 
example to find what line generates the error.  However, I can't step 
into lines()--hence the question.

Thanks for the help.

Sean

On Sep 24, 2004, at 12:18 PM, james.holtman at convergys.com wrote:

>
>
>
>
> Can you provide an example.  Have you run debug or browser on the 
> function?
> __________________________________________________________
> James Holtman        "What is the problem you are trying to solve?"
> Executive Technical Consultant  --  Office of Technology, Convergys
> james.holtman at convergys.com
> +1 (513) 723-2929
>
>
>
>                       Sean Davis
>                       <sdavis2 at mail.nih        To:       James 
> Holtman/CIMG/CVG at CVG
>                       .gov>                    cc:
>                                                Subject:  Re: [R] Error 
> with repeat lines() in function
>                       09/24/2004 12:11
>
>
>
>
>
>
> James,
>
> The first lines command works without a problem (the error is in the
> second lines command), and it is identical to the second.  That is the
> confusing part.
>
> Sean
>
> On Sep 24, 2004, at 12:03 PM, james.holtman at convergys.com wrote:
>
>>
>>
>>
>>
>> I would assume that the data that you are passing into the function in
>> the
>> 'apply' statement might not have the dimensionality that you assume;
>> e.g.,
>> z[5] or z[6] are out of range.  Have you checked to make sure your
>> data is
>> correct?
>> __________________________________________________________
>> James Holtman        "What is the problem you are trying to solve?"
>> Executive Technical Consultant  --  Office of Technology, Convergys
>> james.holtman at convergys.com
>> +1 (513) 723-2929
>>
>>
>>
>>                       Sean Davis
>>                       <sdavis2 at mail.nih.gov        To:       r-help
>> <r-help at stat.math.ethz.ch>
>>>                            cc:
>>                       Sent by:                     Subject:  [R] Error
>> with repeat lines() in function
>>                       r-help-bounces at stat.m
>>                       ath.ethz.ch
>>
>>
>>                       09/24/2004 11:48
>>
>>
>>
>>
>>
>>
>> I have a function that does some plotting.  I then add lines to the
>> plot.  If executed one line at a time, there is not a problem.  If I
>> execute the function, though, I get:
>>
>> Error in ans[[1]] : subscript out of bounds
>>
>> This always occurs after the second lines command, and doesn't happen
>> with all of my data points (some do not have errors).  Any ideas?
>>
>> Thanks,
>> Sean
>>
>>
>>   function(x,annot,rat1,rat2,rf,...) {
>>      par(las=2)
>>      wh <- which(annot[,5]==x)
>>      xmax <- max(annot[wh,4])
>>      xmin <- min(annot[wh,3])
>>      chr <- annot[wh,2][1]
>>      wh.rf <- rf$chrom==as.character(chr) & rf$txStart>xmin &
>> rf$txEnd<xmax
>>      par(mfrow=c(2,1))
>>      plot(annot[wh,3],rat1[wh],type="l",xlab="",ylab="log2
>> Ratio",main=x,...)
>>      points(annot[wh,3],rat1[wh])
>>      apply(rf[wh.rf,],1,function(z) {
>>        browser()
>>        if (z[4]=="+") {
>>          color <- 'green'
>>          yoffset=1
>>        } else {
>>          color <- 'red'
>>          yoffset=-1
>>        }
>>
>> lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/
>> 10)),lwd=2,col=color)
>>
>> lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/
>> 10)),lwd=2,col=color)
>>      })
>>      abline(h=0,lty=2)
>> }
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>>
>
>
>



From umalvarez at fata.unam.mx  Fri Sep 24 18:32:29 2004
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Fri, 24 Sep 2004 11:32:29 -0500 (CDT)
Subject: [R] emacs, Mac OS X, R
In-Reply-To: <C4958F90-0E32-11D9-9448-0003938C0ABE@gmx.net>
Message-ID: <Pine.LNX.4.44.0409241125030.14428-100000@athena.fata.unam.mx>

Hi!

Don't know about how to switch the keys (I suspect that if you take a 
look at the Emacs manual you'll find that's not difficult at all). 
But if you like to have different colors for R within Emacs you should use 
ESS (Emacs Speaks Statistics), which is available at 
http://ess.r-project.org/  

Good look.

On Fri, 24 Sep 2004, Meinhard Ploner wrote:

> Hi!
> 
> Since August I am using emacs on my Macintosh to edit the R objects. I 
> have installed R 1.9.1, Mac OS X 10.3.5 and GNU Emacs 21.2.1. However 
> there are some issues I haven't resolved:
> 
> a) switch the caps lock key to the meta key (and when this is not 
> possible, switch the alt/option key to the meta). The switch should 
> work only within emacs!
> 
> b) having different colors for the code, i.e. comments, commands, 
> strings, ...
> 
> thanks in advance!
> Meinhard
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
u-m-a-l-v-a-r-e-z AT f-a-t-a DOT u-n-a-m DOT m-x
Tels: (442)-238-1144
       (5)-5623-4144 
Fax:  (442)-238-1165
       (5)-5623-4165



From ligges at statistik.uni-dortmund.de  Fri Sep 24 18:38:10 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 24 Sep 2004 18:38:10 +0200
Subject: [R] Error with repeat lines() in function
In-Reply-To: <1EDAFFAB-0E46-11D9-AC51-000A95D7BA10@mail.nih.gov>
References: <OFF7EDB7CE.3D2E32D9-ON85256F19.00598575@nd.convergys.com>
	<1EDAFFAB-0E46-11D9-AC51-000A95D7BA10@mail.nih.gov>
Message-ID: <41544D72.8020506@statistik.uni-dortmund.de>

Sean Davis wrote:

> Working on a toy example. I have run the debugger/browser on the
> example to find what line generates the error.  However, I can't step 
> into lines()--hence the question.

Hint:
  options(error=recover)

Uwe Ligges



> 
> Thanks for the help.
> 
> Sean
> 
> On Sep 24, 2004, at 12:18 PM, james.holtman at convergys.com wrote:
> 
>>
>>
>>
>>
>> Can you provide an example.  Have you run debug or browser on the 
>> function?
>> __________________________________________________________
>> James Holtman        "What is the problem you are trying to solve?"
>> Executive Technical Consultant  --  Office of Technology, Convergys
>> james.holtman at convergys.com
>> +1 (513) 723-2929
>>
>>
>>
>>                       Sean Davis
>>                       <sdavis2 at mail.nih        To:       James 
>> Holtman/CIMG/CVG at CVG
>>                       .gov>                    cc:
>>                                                Subject:  Re: [R] Error 
>> with repeat lines() in function
>>                       09/24/2004 12:11
>>
>>
>>
>>
>>
>>
>> James,
>>
>> The first lines command works without a problem (the error is in the
>> second lines command), and it is identical to the second.  That is the
>> confusing part.
>>
>> Sean
>>
>> On Sep 24, 2004, at 12:03 PM, james.holtman at convergys.com wrote:
>>
>>>
>>>
>>>
>>>
>>> I would assume that the data that you are passing into the function in
>>> the
>>> 'apply' statement might not have the dimensionality that you assume;
>>> e.g.,
>>> z[5] or z[6] are out of range.  Have you checked to make sure your
>>> data is
>>> correct?
>>> __________________________________________________________
>>> James Holtman        "What is the problem you are trying to solve?"
>>> Executive Technical Consultant  --  Office of Technology, Convergys
>>> james.holtman at convergys.com
>>> +1 (513) 723-2929
>>>
>>>
>>>
>>>                       Sean Davis
>>>                       <sdavis2 at mail.nih.gov        To:       r-help
>>> <r-help at stat.math.ethz.ch>
>>>
>>>>                            cc:
>>>
>>>                       Sent by:                     Subject:  [R] Error
>>> with repeat lines() in function
>>>                       r-help-bounces at stat.m
>>>                       ath.ethz.ch
>>>
>>>
>>>                       09/24/2004 11:48
>>>
>>>
>>>
>>>
>>>
>>>
>>> I have a function that does some plotting.  I then add lines to the
>>> plot.  If executed one line at a time, there is not a problem.  If I
>>> execute the function, though, I get:
>>>
>>> Error in ans[[1]] : subscript out of bounds
>>>
>>> This always occurs after the second lines command, and doesn't happen
>>> with all of my data points (some do not have errors).  Any ideas?
>>>
>>> Thanks,
>>> Sean
>>>
>>>
>>>   function(x,annot,rat1,rat2,rf,...) {
>>>      par(las=2)
>>>      wh <- which(annot[,5]==x)
>>>      xmax <- max(annot[wh,4])
>>>      xmin <- min(annot[wh,3])
>>>      chr <- annot[wh,2][1]
>>>      wh.rf <- rf$chrom==as.character(chr) & rf$txStart>xmin &
>>> rf$txEnd<xmax
>>>      par(mfrow=c(2,1))
>>>      plot(annot[wh,3],rat1[wh],type="l",xlab="",ylab="log2
>>> Ratio",main=x,...)
>>>      points(annot[wh,3],rat1[wh])
>>>      apply(rf[wh.rf,],1,function(z) {
>>>        browser()
>>>        if (z[4]=="+") {
>>>          color <- 'green'
>>>          yoffset=1
>>>        } else {
>>>          color <- 'red'
>>>          yoffset=-1
>>>        }
>>>
>>> lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/
>>> 10)),lwd=2,col=color)
>>>
>>> lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/
>>> 10)),lwd=2,col=color)
>>>      })
>>>      abline(h=0,lty=2)
>>> }
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>>
>>>
>>
>>
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From Scott.Waichler at pnl.gov  Fri Sep 24 18:42:21 2004
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Fri, 24 Sep 2004 09:42:21 -0700
Subject: [R] bwplot panels like stripplot
Message-ID: <7E4C06F49D6FEB49BE4B60E5FC92ED7A96D8EC@pnlmse35.pnl.gov>


I would like to plot horizontal box-and-whisker plots in lattice where
each
factor has its own panel and scales are "free."  Below is a stripplot
version
of what I have in mind.  Substituting "bwplot" doesn't work.  I know
it's gotta
be simple but I can't find the way . . .

x <- c(runif(100, 0, 1), runif(100, 1, 2), runif(100, 2, 3))
y <- c(rep("First", 100), rep("Second", 100), rep("Third", 100))
stripplot(x | y,
            layout=c(1,3),
            scales=list(relation="free"),
            as.table=T,
            bg="white"
  )

Thanks,
Scott Waichler
Pacific Northwest National Laboratory
scott.waichler at pnl.gov



From sdavis2 at mail.nih.gov  Fri Sep 24 19:09:13 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 24 Sep 2004 13:09:13 -0400
Subject: [R] Error with repeat lines() in function
In-Reply-To: <415445B9.3070505@statistik.uni-dortmund.de>
References: <352CBEB2-0E41-11D9-AC51-000A95D7BA10@mail.nih.gov>
	<415445B9.3070505@statistik.uni-dortmund.de>
Message-ID: <7528DC68-0E4C-11D9-AC51-000A95D7BA10@mail.nih.gov>

Here is an example that seems to reproduce the error:

rf1 <- matrix(sort(abs(round(runif(4)*1000000))),nrow=1)
annot1 <- sort(abs(round(runif(193)*1000000)))
annot2 <- annot1 + 70
annot3 <- cbind(annot1,annot2)
rat2 <- rnorm(193)
rat1 <- rnorm(193)
plotter <-
function(annot,rat1,rat2,rf1,...) {
     par(las=2)
     xmax <- max(annot[,2])
     xmin <- min(annot[,1])
     par(mfrow=c(2,1))
     plot(annot[,1],rat1,type="l",xlab="",ylab="log2 Ratio",...)
     points(annot[,1],rat1)
     apply(rf1,1,function(z) {
       if (z[4]=="+") {
         color <- 'green'
         yoffset=1
       } else {
         color <- 'red'
         yoffset=-1
       }
        
lines(list(x=c(z[1],z[4]),y=c(-2-yoffset/10,-2-yoffset/ 
10)),lwd=2,col=color)
        
lines(list(x=c(z[2],z[3]),y=c(-2-yoffset/10,-2-yoffset/ 
10)),lwd=4,col=color)
     })
     abline(h=0,lty=2)
   }
plotter(annot3,rat1,rat2,rf1)
Error in ans[[1]] : subscript out of bounds

Enter a frame number, or 0 to exit
1:plotter(annot3, rat1, rat2, rf1)
2:apply(rf1, 1, function(z) {
Selection: 0

On Sep 24, 2004, at 12:05 PM, Uwe Ligges wrote:

> Sean Davis wrote:
>
>> I have a function that does some plotting.  I then add lines to the   
>> plot.  If executed one line at a time, there is not a problem.  If I   
>> execute the function, though, I get:
>> Error in ans[[1]] : subscript out of bounds
>> This always occurs after the second lines command, and doesn't happen  
>>  with all of my data points (some do not have errors).  Any ideas?
>
> Please give an example how to produce the error,
> i.e. specify a very small toy example (including generated data and  
> the call to your function).
> Many people on this list are quite busy these days and don't want to  
> think about how to call your function and invent an example ...
>
> Uwe Ligges
>
>
>
>> Thanks,
>> Sean
>>  function(x,annot,rat1,rat2,rf,...) {
>>     par(las=2)
>>     wh <- which(annot[,5]==x)
>>     xmax <- max(annot[wh,4])
>>     xmin <- min(annot[wh,3])
>>     chr <- annot[wh,2][1]
>>     wh.rf <- rf$chrom==as.character(chr) & rf$txStart>xmin &   
>> rf$txEnd<xmax
>>     par(mfrow=c(2,1))
>>     plot(annot[wh,3],rat1[wh],type="l",xlab="",ylab="log2   
>> Ratio",main=x,...)
>>     points(annot[wh,3],rat1[wh])
>>     apply(rf[wh.rf,],1,function(z) {
>>       browser()
>>       if (z[4]=="+") {
>>         color <- 'green'
>>         yoffset=1
>>       } else {
>>         color <- 'red'
>>         yoffset=-1
>>       }
>>        lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/  
>> 10)),lwd=2,col=color)
>>        lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/  
>> 10)),lwd=2,col=color)
>>     })
>>     abline(h=0,lty=2)
>> }
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!  
>> http://www.R-project.org/posting-guide.html



From h.wickham at gmail.com  Fri Sep 24 19:18:46 2004
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 24 Sep 2004 12:18:46 -0500
Subject: [R] Raster images from sweave
Message-ID: <f8e6ff050409241018481827cf@mail.gmail.com>

Is it possible to get sweave to produce raster (eg. png/jpg) plot
images?  I'm writing a vignette that contains plots with tens of
thousands of points which results in very large pdf files (13 megs
before compression).

Thanks,

Hadley



From Roger.Bivand at nhh.no  Fri Sep 24 19:36:54 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 24 Sep 2004 19:36:54 +0200 (CEST)
Subject: [R] Raster images from sweave
In-Reply-To: <f8e6ff050409241018481827cf@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0409241928150.24254-100000@reclus.nhh.no>

On Fri, 24 Sep 2004, hadley wickham wrote:

> Is it possible to get sweave to produce raster (eg. png/jpg) plot
> images?  I'm writing a vignette that contains plots with tens of
> thousands of points which results in very large pdf files (13 megs
> before compression).

Yes. I do it by including these chunks after \begin{document}

<<echo=FALSE>>= 
.PngNo <- 0
@

<<label=afig,echo=FALSE,eval=FALSE>>= 
.PngNo <- .PngNo + 1; file <- paste("Fig-bitmap-", .PngNo, ".png", sep="")
png(file=file, width = 1200, height = 1200, pointsize = 24, bg = "white")
@

<<label=zfig,echo=FALSE,eval=FALSE>>= 
dev.null <- dev.off()
cat("\\includegraphics{", file, "}\n\n", sep="")
@

then for each figure e.g.:

<<label=quad,echo=FALSE,eval=FALSE>>= 
plot(drumlin.xy)
@

\begin{scriptsize}
<<fig=FALSE,echo=TRUE, eval=FALSE>>= 
<<quad>>
@ 
\end{scriptsize}

\begin{center} 
<<results=tex,echo=FALSE>>= 
<<afig>>
<<quad>>
<<zfig>>
@ 
\end{center}

maybe putting the graphic in a figure environment if it is not just a 
slide. I find I need to hand tune the output resultion and pointsize 
depending on the output medium.

Roger Bivand

> 
> Thanks,
> 
> Hadley
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From richard.kittler at amd.com  Fri Sep 24 19:41:10 2004
From: richard.kittler at amd.com (richard.kittler@amd.com)
Date: Fri, 24 Sep 2004 10:41:10 -0700
Subject: [R] Fitting Zernike polynomials
Message-ID: <B12C66F25ECCE044A48128DA57AC244563E946@SSVLEXMB1.amd.com>

I was looking for some routines to fit Zernike polynomials but nothing came up in the archive search.  Can anyone provide a lead?  

--Rich

Richard Kittler 
AMD TDG
408-749-4099



From deepayan at stat.wisc.edu  Fri Sep 24 19:49:43 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 24 Sep 2004 12:49:43 -0500
Subject: [R] bwplot panels like stripplot
In-Reply-To: <7E4C06F49D6FEB49BE4B60E5FC92ED7A96D8EC@pnlmse35.pnl.gov>
References: <7E4C06F49D6FEB49BE4B60E5FC92ED7A96D8EC@pnlmse35.pnl.gov>
Message-ID: <200409241249.43200.deepayan@stat.wisc.edu>



On Friday 24 September 2004 11:42, Waichler, Scott R wrote:
> I would like to plot horizontal box-and-whisker plots in lattice where
> each
> factor has its own panel and scales are "free."  Below is a stripplot
> version
> of what I have in mind.  Substituting "bwplot" doesn't work.  I know
> it's gotta
> be simple but I can't find the way . . .
>
> x <- c(runif(100, 0, 1), runif(100, 1, 2), runif(100, 2, 3))
> y <- c(rep("First", 100), rep("Second", 100), rep("Third", 100))
> stripplot(x | y,
>             layout=c(1,3),
>             scales=list(relation="free"),
>             as.table=T,
>             bg="white"
>   )

This won't work (easily) with R <= 1.9.1. Try with 2.0.0 beta, and let us know 
if you still have problems.

Deepayan



From ligges at statistik.uni-dortmund.de  Fri Sep 24 20:15:45 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 24 Sep 2004 20:15:45 +0200
Subject: [R] Error with repeat lines() in function
In-Reply-To: <7528DC68-0E4C-11D9-AC51-000A95D7BA10@mail.nih.gov>
References: <352CBEB2-0E41-11D9-AC51-000A95D7BA10@mail.nih.gov>	<415445B9.3070505@statistik.uni-dortmund.de>
	<7528DC68-0E4C-11D9-AC51-000A95D7BA10@mail.nih.gov>
Message-ID: <41546451.7050907@statistik.uni-dortmund.de>

Sean Davis wrote:

> Here is an example that seems to reproduce the error:


Well, debugging in apply() isn't funny and I'm tooo lazy at quarter past 
eight on a friday evening. Anyway, you can
(a) do it using a loop (which isn't that inefficient compared to the 
apply() approach), or
(b) the clever (vectorized) way that follows:


plotter <- function(annot,rat1,rat2,rf1,...) {
   par(las=2)
   xmax <- max(annot[,2])
   xmin <- min(annot[,1])
   par(mfrow=c(2,1))
   plot(annot[,1],rat1,type="l",xlab="",ylab="log2 Ratio",...)
   points(annot[,1],rat1)

   yoffset <- ifelse(rf1[,4] == "+", 1, -1)
   color <- ifelse(rf1[,4] == "+", "green", "red")
   segments(rf1[,1], -2-yoffset/10, rf1[,4], -2-yoffset/ 10,
     lwd=2, col=color)
   segments(rf1[,2], -2-yoffset/10, rf1[,3], -2-yoffset/ 10,
     lwd=4, col=color)

   abline(h=0,lty=2)
}


Uwe Ligges







> rf1 <- matrix(sort(abs(round(runif(4)*1000000))),nrow=1)
> annot1 <- sort(abs(round(runif(193)*1000000)))
> annot2 <- annot1 + 70
> annot3 <- cbind(annot1,annot2)
> rat2 <- rnorm(193)
> rat1 <- rnorm(193)
> plotter <-
> function(annot,rat1,rat2,rf1,...) {
>     par(las=2)
>     xmax <- max(annot[,2])
>     xmin <- min(annot[,1])
>     par(mfrow=c(2,1))
>     plot(annot[,1],rat1,type="l",xlab="",ylab="log2 Ratio",...)
>     points(annot[,1],rat1)
>     apply(rf1,1,function(z) {
>       if (z[4]=="+") {
>         color <- 'green'
>         yoffset=1
>       } else {
>         color <- 'red'
>         yoffset=-1
>       }
>        lines(list(x=c(z[1],z[4]),y=c(-2-yoffset/10,-2-yoffset/ 
> 10)),lwd=2,col=color)
>        lines(list(x=c(z[2],z[3]),y=c(-2-yoffset/10,-2-yoffset/ 
> 10)),lwd=4,col=color)
>     })
>     abline(h=0,lty=2)
>   }
> plotter(annot3,rat1,rat2,rf1)
> Error in ans[[1]] : subscript out of bounds
> 
> Enter a frame number, or 0 to exit
> 1:plotter(annot3, rat1, rat2, rf1)
> 2:apply(rf1, 1, function(z) {
> Selection: 0
> 
> On Sep 24, 2004, at 12:05 PM, Uwe Ligges wrote:
> 
>> Sean Davis wrote:
>>
>>> I have a function that does some plotting.  I then add lines to the   
>>> plot.  If executed one line at a time, there is not a problem.  If 
>>> I   execute the function, though, I get:
>>> Error in ans[[1]] : subscript out of bounds
>>> This always occurs after the second lines command, and doesn't 
>>> happen   with all of my data points (some do not have errors).  Any 
>>> ideas?
>>
>>
>> Please give an example how to produce the error,
>> i.e. specify a very small toy example (including generated data and  
>> the call to your function).
>> Many people on this list are quite busy these days and don't want to  
>> think about how to call your function and invent an example ...
>>
>> Uwe Ligges
>>
>>
>>
>>> Thanks,
>>> Sean
>>>  function(x,annot,rat1,rat2,rf,...) {
>>>     par(las=2)
>>>     wh <- which(annot[,5]==x)
>>>     xmax <- max(annot[wh,4])
>>>     xmin <- min(annot[wh,3])
>>>     chr <- annot[wh,2][1]
>>>     wh.rf <- rf$chrom==as.character(chr) & rf$txStart>xmin &   
>>> rf$txEnd<xmax
>>>     par(mfrow=c(2,1))
>>>     plot(annot[wh,3],rat1[wh],type="l",xlab="",ylab="log2   
>>> Ratio",main=x,...)
>>>     points(annot[wh,3],rat1[wh])
>>>     apply(rf[wh.rf,],1,function(z) {
>>>       browser()
>>>       if (z[4]=="+") {
>>>         color <- 'green'
>>>         yoffset=1
>>>       } else {
>>>         color <- 'red'
>>>         yoffset=-1
>>>       }
>>>        lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/  
>>> 10)),lwd=2,col=color)
>>>        lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/  
>>> 10)),lwd=2,col=color)
>>>     })
>>>     abline(h=0,lty=2)
>>> }
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!  
>>> http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Sep 24 20:24:06 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 24 Sep 2004 20:24:06 +0200
Subject: [R] Contout plot options
In-Reply-To: <BD7A087D.59%nassar@noos.fr>
References: <BD7A087D.59%nassar@noos.fr>
Message-ID: <41546646.1080601@statistik.uni-dortmund.de>

Naji wrote:

> Hi all
> 
> 
> As a new user of R, I need some help for a contour plot..
> - How can I change x,y labels format ie .01 -> 1%
> - Is is possible to change Axis & Grph fonts to Times 11?
> - How can I change the xaxp? I gave it several trials without success..
> 
> Par(xaxp(0,1,4)
> Contour(x,y,z,label=c("2%","4%","6%","8%","10%","12%","14%","16%","18%"))
> Title("Isoquant Market share", xlab="Availability",ylab="Share of
> Prefeences")

par(xaxp = c(0,1,4))
contour(x, y, z, label = paste(seq(2, 18, 2), "\%", sep = ""))
title("Isoquant Market share", xlab="Availability",
     ylab="Share of Prefeences")

Uwe Ligges

> Thanks for help
> 
> -> Is there any tutorial for R graphs?
> 
> Best regards
> Naji
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From james.holtman at convergys.com  Fri Sep 24 20:33:37 2004
From: james.holtman at convergys.com (james.holtman@convergys.com)
Date: Fri, 24 Sep 2004 14:33:37 -0400
Subject: [R] Error with repeat lines() in function
Message-ID: <OFE9848A21.DFEB6D27-ON85256F19.0065BEB7@nd.convergys.com>






The problem was is that you were not return a value from the apply
function.  It was trying to store the result of the apply into an array and
there was no value.

See the line I added in your function.
__________________________________________________________
James Holtman        "What is the problem you are trying to solve?"
Executive Technical Consultant  --  Office of Technology, Convergys
james.holtman at convergys.com
+1 (513) 723-2929


                                                                                                                                           
                      Sean Davis                                                                                                           
                      <sdavis2 at mail.nih.gov        To:       Uwe Ligges <ligges at statistik.uni-dortmund.de>                                 
                      >                            cc:       r-help <r-help at stat.math.ethz.ch>                                             
                      Sent by:                     Subject:  Re: [R] Error with repeat lines() in function                                 
                      r-help-bounces at stat.m                                                                                                
                      ath.ethz.ch                                                                                                          
                                                                                                                                           
                                                                                                                                           
                      09/24/2004 13:09                                                                                                     
                                                                                                                                           
                                                                                                                                           




Here is an example that seems to reproduce the error:

rf1 <- matrix(sort(abs(round(runif(4)*1000000))),nrow=1)
annot1 <- sort(abs(round(runif(193)*1000000)))
annot2 <- annot1 + 70
annot3 <- cbind(annot1,annot2)
rat2 <- rnorm(193)
rat1 <- rnorm(193)
plotter <-
function(annot,rat1,rat2,rf1,...) {
     par(las=2)
     xmax <- max(annot[,2])
     xmin <- min(annot[,1])
     par(mfrow=c(2,1))
     plot(annot[,1],rat1,type="l",xlab="",ylab="log2 Ratio",...)
     points(annot[,1],rat1)
     apply(rf1,1,function(z) {
       if (z[4]=="+") {
         color <- 'green'
         yoffset=1
       } else {
         color <- 'red'
         yoffset=-1
       }

lines(list(x=c(z[1],z[4]),y=c(-2-yoffset/10,-2-yoffset/
10)),lwd=2,col=color)

lines(list(x=c(z[2],z[3]),y=c(-2-yoffset/10,-2-yoffset/
10)),lwd=4,col=color)

1     #  fake a return value

     })
     abline(h=0,lty=2)
   }
plotter(annot3,rat1,rat2,rf1)
Error in ans[[1]] : subscript out of bounds

Enter a frame number, or 0 to exit
1:plotter(annot3, rat1, rat2, rf1)
2:apply(rf1, 1, function(z) {
Selection: 0

On Sep 24, 2004, at 12:05 PM, Uwe Ligges wrote:

> Sean Davis wrote:
>
>> I have a function that does some plotting.  I then add lines to the
>> plot.  If executed one line at a time, there is not a problem.  If I
>> execute the function, though, I get:
>> Error in ans[[1]] : subscript out of bounds
>> This always occurs after the second lines command, and doesn't happen
>>  with all of my data points (some do not have errors).  Any ideas?
>
> Please give an example how to produce the error,
> i.e. specify a very small toy example (including generated data and
> the call to your function).
> Many people on this list are quite busy these days and don't want to
> think about how to call your function and invent an example ...
>
> Uwe Ligges
>
>
>
>> Thanks,
>> Sean
>>  function(x,annot,rat1,rat2,rf,...) {
>>     par(las=2)
>>     wh <- which(annot[,5]==x)
>>     xmax <- max(annot[wh,4])
>>     xmin <- min(annot[wh,3])
>>     chr <- annot[wh,2][1]
>>     wh.rf <- rf$chrom==as.character(chr) & rf$txStart>xmin &
>> rf$txEnd<xmax
>>     par(mfrow=c(2,1))
>>     plot(annot[wh,3],rat1[wh],type="l",xlab="",ylab="log2
>> Ratio",main=x,...)
>>     points(annot[wh,3],rat1[wh])
>>     apply(rf[wh.rf,],1,function(z) {
>>       browser()
>>       if (z[4]=="+") {
>>         color <- 'green'
>>         yoffset=1
>>       } else {
>>         color <- 'red'
>>         yoffset=-1
>>       }
>>        lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/
>> 10)),lwd=2,col=color)
>>        lines(list(x=c(z[5],z[6]),y=c(-2-yoffset/10,-2-yoffset/
>> 10)),lwd=2,col=color)
>>     })
>>     abline(h=0,lty=2)
>> }
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Scott.Waichler at pnl.gov  Fri Sep 24 21:45:47 2004
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Fri, 24 Sep 2004 12:45:47 -0700
Subject: [R] bwplot panels like stripplot
Message-ID: <7E4C06F49D6FEB49BE4B60E5FC92ED7A96D942@pnlmse35.pnl.gov>

>> I would like to plot horizontal box-and-whisker plots in lattice
where 
>> each factor has its own panel and scales are "free."  Below is a 
>> stripplot version of what I have in mind.  Substituting "bwplot" 
>> doesn't work. 

> This won't work (easily) with R <= 1.9.1. Try with 2.0.0 beta, and let
us know if you still have problems.
>
> Deepayan 

It still doesn't work.  Once again,

> R.version.string
[1] "R version 2.0.0, 2004-09-24"

x <- c(runif(100, 0, 1), runif(100, 1, 2), runif(100, 2, 3)) 
y <- c(rep("First", 100), rep("Second", 100), rep("Third", 100)) 

# this works fine
stripplot(x | y,
          layout=c(1,3),
          scales=list(relation="free"),
          as.table=T,
          bg="white"
         )

# this doesn't
bwplot(x ~ y,
       layout=c(1,3),
       scales=list(relation="free"),
       as.table=T,
       bg="white",
       horizontal=T
      )

Error in Ops.unit(do.call("max", lab.unit), tick.unit) :
        Both operands must be units
In addition: Warning messages:
1: x should be numeric in: bwplot(x ~ y, layout = c(1, 3), scales =
list(relation = "free"),
2: no finite arguments to max; returning -Inf


Scott



From andy_liaw at merck.com  Fri Sep 24 22:02:36 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 24 Sep 2004 16:02:36 -0400
Subject: [R] using tcltk in R under ESS/XEmacs on Windows
Message-ID: <3A822319EB35174CA3714066D590DCD504AF842F@usrymx25.merck.com>

Sorry for the cross-post.  Not sure where the problem is...

A while back I posted an R function to R-help:

cd <- function (dir = tclvalue(tkchooseDirectory()), saveOld = FALSE, 
    loadNew = TRUE) {
    stopifnot(require(tcltk))
    if (saveOld) 
        save.image(compress = TRUE)
    setwd(dir)
    rm(list = ls(all = TRUE, envir = .GlobalEnv), envir = .GlobalEnv)
    if (loadNew && file.exists(".RData")) {
        loaded <- load(".RData", envir = .GlobalEnv)
        return(invisible(loaded))
    }

where the default value for the `dir' argument is to run the tcltk directory
chooser and get the directory name chosen.  (Thanks to Prof. John Fox for
the tcltk part!!)  While this function works fine under Rgui on Windows, it
doesn't work when running R within ESS (5.2.3) and XEmacs (21.4.13).  The
directory chooser never shows up, and dir just gets the empty string.  Does
anyone have any idea what could be the problem?  I'd very much appreciate
any pointers.

Best,
Andy



From jfox at mcmaster.ca  Fri Sep 24 22:16:21 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 24 Sep 2004 16:16:21 -0400
Subject: [R] RE: using tcltk in R under ESS/XEmacs on Windows
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF842F@usrymx25.merck.com>
Message-ID: <20040924201619.DUIH2542.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Andy,

Perhaps it's possible, but I've never been able to get tcltk to work
properly under ESS/Xemacs on Windows. 

Regards,
 John

> -----Original Message-----
> From: ess-help-bounces at stat.math.ethz.ch 
> [mailto:ess-help-bounces at stat.math.ethz.ch] On Behalf Of Liaw, Andy
> Sent: Friday, September 24, 2004 3:03 PM
> To: r-help at stat.math.ethz.ch; ESS (Help list)
> Subject: using tcltk in R under ESS/XEmacs on Windows
> 
> Sorry for the cross-post.  Not sure where the problem is...
> 
> A while back I posted an R function to R-help:
> 
> cd <- function (dir = tclvalue(tkchooseDirectory()), saveOld = FALSE, 
>     loadNew = TRUE) {
>     stopifnot(require(tcltk))
>     if (saveOld) 
>         save.image(compress = TRUE)
>     setwd(dir)
>     rm(list = ls(all = TRUE, envir = .GlobalEnv), envir = .GlobalEnv)
>     if (loadNew && file.exists(".RData")) {
>         loaded <- load(".RData", envir = .GlobalEnv)
>         return(invisible(loaded))
>     }
> 
> where the default value for the `dir' argument is to run the 
> tcltk directory chooser and get the directory name chosen.  
> (Thanks to Prof. John Fox for the tcltk part!!)  While this 
> function works fine under Rgui on Windows, it doesn't work 
> when running R within ESS (5.2.3) and XEmacs (21.4.13).  The 
> directory chooser never shows up, and dir just gets the empty 
> string.  Does anyone have any idea what could be the problem? 
>  I'd very much appreciate any pointers.
> 
> Best,
> Andy
> 
> ______________________________________________
> ESS-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/ess-help



From deepayan at stat.wisc.edu  Fri Sep 24 22:19:30 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 24 Sep 2004 15:19:30 -0500
Subject: [R] bwplot panels like stripplot
In-Reply-To: <7E4C06F49D6FEB49BE4B60E5FC92ED7A96D942@pnlmse35.pnl.gov>
References: <7E4C06F49D6FEB49BE4B60E5FC92ED7A96D942@pnlmse35.pnl.gov>
Message-ID: <200409241519.30575.deepayan@stat.wisc.edu>

On Friday 24 September 2004 14:45, Waichler, Scott R wrote:
> >> I would like to plot horizontal box-and-whisker plots in lattice
>
> where
>
> >> each factor has its own panel and scales are "free."  Below is a
> >> stripplot version of what I have in mind.  Substituting "bwplot"
> >> doesn't work.
> >
> > This won't work (easily) with R <= 1.9.1. Try with 2.0.0 beta, and
> > let
>
> us know if you still have problems.
>
> > Deepayan
>
> It still doesn't work.  Once again,
>
> > R.version.string
>
> [1] "R version 2.0.0, 2004-09-24"
>
> x <- c(runif(100, 0, 1), runif(100, 1, 2), runif(100, 2, 3))
> y <- c(rep("First", 100), rep("Second", 100), rep("Third", 100))
>
> # this works fine
> stripplot(x | y,
>           layout=c(1,3),
>           scales=list(relation="free"),
>           as.table=T,
>           bg="white"
>          )
>
> # this doesn't
> bwplot(x ~ y,
>        layout=c(1,3),
>        scales=list(relation="free"),
>        as.table=T,
>        bg="white",
>        horizontal=T
>       )
>
> Error in Ops.unit(do.call("max", lab.unit), tick.unit) :
>         Both operands must be units
> In addition: Warning messages:
> 1: x should be numeric in: bwplot(x ~ y, layout = c(1, 3), scales =
> list(relation = "free"),
> 2: no finite arguments to max; returning -Inf

I'm completely confused.

First of all, your two calls are not comparable -- stripplot has the 
`formula' x|y (which incidentally is undocumented and completely 
unreliable), while bwplot has x ~ y. 

Secondly, y is a character vector, which is inappropriate (you probably 
want it to be a factor). You might still have expected it to work, but 
to make things more complicated, horizontal=T, which means your 'x' 
should be the factor, which makes your 'y' completely uninterpretable.

The bwplot equivalent of your stripplot call (with the formula changed 
to a valid equivalent), namely

bwplot(~x | y,
       layout=c(1,3),
       scales=list(relation="free"),
       as.table=T,
       bg="white"
       )

works as expected for me. I have no idea what you expect bg="white" to 
achieve, though.

Deepayan



From MSchwartz at MedAnalytics.com  Fri Sep 24 22:32:03 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Fri, 24 Sep 2004 15:32:03 -0500
Subject: [R] using tcltk in R under ESS/XEmacs on Windows
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF842F@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF842F@usrymx25.merck.com>
Message-ID: <1096057923.10998.22.camel@localhost.localdomain>

On Fri, 2004-09-24 at 15:02, Liaw, Andy wrote:
> Sorry for the cross-post.  Not sure where the problem is...
> 
> A while back I posted an R function to R-help:
> 
> cd <- function (dir = tclvalue(tkchooseDirectory()), saveOld = FALSE, 
>     loadNew = TRUE) {
>     stopifnot(require(tcltk))
>     if (saveOld) 
>         save.image(compress = TRUE)
>     setwd(dir)
>     rm(list = ls(all = TRUE, envir = .GlobalEnv), envir = .GlobalEnv)
>     if (loadNew && file.exists(".RData")) {
>         loaded <- load(".RData", envir = .GlobalEnv)
>         return(invisible(loaded))
>     }
> 
> where the default value for the `dir' argument is to run the tcltk directory
> chooser and get the directory name chosen.  (Thanks to Prof. John Fox for
> the tcltk part!!)  While this function works fine under Rgui on Windows, it
> doesn't work when running R within ESS (5.2.3) and XEmacs (21.4.13).  The
> directory chooser never shows up, and dir just gets the empty string.  Does
> anyone have any idea what could be the problem?  I'd very much appreciate
> any pointers.
> 
> Best,
> Andy

Andy,

This works under FC2 using ESS 5.2.3 with XEmacs version 21.4.15, so
presumably there is something specific to the Windows implementation?

Also, two things:

1. You are missing a closing brace above, which I presume may be a
simple copy and paste issue.

2. If you successfully change the directory, the cd() function itself is
deleted from the global environment via your rm(...), as you currently
have it implemented. I am not sure if this is intentional or not.

HTH,

Marc



From jfox at mcmaster.ca  Fri Sep 24 22:44:20 2004
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 24 Sep 2004 16:44:20 -0400
Subject: [R] RE: using tcltk in R under ESS/XEmacs on Windows
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF8433@usrymx25.merck.com>
Message-ID: <20040924204417.PYXG2048.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Andy,

I've taken the liberty of copying this reply to the r-help and ess-help
lists since my last reply was misleading.

I believe that the problem with tkchooseDirectory() (you can see it by just
calling that function directly) is that it brings up a native Windows
dialog, and it's that kind of tcltk command that I've had trouble with in
ESS/XEmacs under Windows.

Regards,
 John

> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com] 
> Sent: Friday, September 24, 2004 3:23 PM
> To: 'John Fox'
> Subject: RE: using tcltk in R under ESS/XEmacs on Windows
> 
> Hi John,
> 
> demo(tkfaq) did work for me.  Maybe that's the exception...
> 
> Thanks!
> Andy
> 
> > From: John Fox
> > 
> > Dear Andy,
> > 
> > Perhaps it's possible, but I've never been able to get 
> tcltk to work 
> > properly under ESS/Xemacs on Windows.
> > 
> > Regards,
> >  John
> > 
> > > -----Original Message-----
> > > From: ess-help-bounces at stat.math.ethz.ch
> > > [mailto:ess-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Liaw, Andy
> > > Sent: Friday, September 24, 2004 3:03 PM
> > > To: r-help at stat.math.ethz.ch; ESS (Help list)
> > > Subject: using tcltk in R under ESS/XEmacs on Windows
> > > 
> > > Sorry for the cross-post.  Not sure where the problem is...
> > > 
> > > A while back I posted an R function to R-help:
> > > 
> > > cd <- function (dir = tclvalue(tkchooseDirectory()),
> > saveOld = FALSE,
> > >     loadNew = TRUE) {
> > >     stopifnot(require(tcltk))
> > >     if (saveOld) 
> > >         save.image(compress = TRUE)
> > >     setwd(dir)
> > >     rm(list = ls(all = TRUE, envir = .GlobalEnv), envir =
> > .GlobalEnv)
> > >     if (loadNew && file.exists(".RData")) {
> > >         loaded <- load(".RData", envir = .GlobalEnv)
> > >         return(invisible(loaded))
> > >     }
> > > 
> > > where the default value for the `dir' argument is to run 
> the tcltk 
> > > directory chooser and get the directory name chosen.
> > > (Thanks to Prof. John Fox for the tcltk part!!)  While 
> this function 
> > > works fine under Rgui on Windows, it doesn't work when running R 
> > > within ESS (5.2.3) and XEmacs (21.4.13).  The directory chooser 
> > > never shows up, and dir just gets the empty string.  Does anyone 
> > > have any idea what could be the problem?
> > >  I'd very much appreciate any pointers.
> > > 
> > > Best,
> > > Andy
> > > 
> > > ______________________________________________
> > > ESS-help at stat.math.ethz.ch mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/ess-help
> > 
> > 
> > 
> 
> 
> --------------------------------------------------------------
> ----------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New Jersey, USA 08889), and/or its 
> affiliates (which may be known outside the United States as 
> Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as 
> Banyu) that may be confidential, proprietary copyrighted 
> and/or legally privileged. It is intended solely for the use 
> of the individual or entity named on this message.  If you 
> are not the intended recipient, and have received this 
> message in error, please notify us immediately by reply 
> e-mail and then delete it from your system.
> --------------------------------------------------------------
> ----------------



From andy_liaw at merck.com  Fri Sep 24 23:48:18 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 24 Sep 2004 17:48:18 -0400
Subject: [R] using tcltk in R under ESS/XEmacs on Windows
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8434@usrymx25.merck.com>

> From: Marc Schwartz
> 
> On Fri, 2004-09-24 at 15:02, Liaw, Andy wrote:
> > Sorry for the cross-post.  Not sure where the problem is...
> > 
> > A while back I posted an R function to R-help:
> > 
> > cd <- function (dir = tclvalue(tkchooseDirectory()), 
> saveOld = FALSE, 
> >     loadNew = TRUE) {
> >     stopifnot(require(tcltk))
> >     if (saveOld) 
> >         save.image(compress = TRUE)
> >     setwd(dir)
> >     rm(list = ls(all = TRUE, envir = .GlobalEnv), envir = 
> .GlobalEnv)
> >     if (loadNew && file.exists(".RData")) {
> >         loaded <- load(".RData", envir = .GlobalEnv)
> >         return(invisible(loaded))
> >     }
> > 
> > where the default value for the `dir' argument is to run 
> the tcltk directory
> > chooser and get the directory name chosen.  (Thanks to 
> Prof. John Fox for
> > the tcltk part!!)  While this function works fine under 
> Rgui on Windows, it
> > doesn't work when running R within ESS (5.2.3) and XEmacs 
> (21.4.13).  The
> > directory chooser never shows up, and dir just gets the 
> empty string.  Does
> > anyone have any idea what could be the problem?  I'd very 
> much appreciate
> > any pointers.
> > 
> > Best,
> > Andy
> 
> Andy,
> 
> This works under FC2 using ESS 5.2.3 with XEmacs version 21.4.15, so
> presumably there is something specific to the Windows implementation?

Given Prof. Fox's follow-up and your obvservation, I guess the problem _is_
Windows-specific. 8-(
 
> Also, two things:
> 
> 1. You are missing a closing brace above, which I presume may be a
> simple copy and paste issue.

Yes.  My apologies.

> 2. If you successfully change the directory, the cd() 
> function itself is
> deleted from the global environment via your rm(...), as you currently
> have it implemented. I am not sure if this is intentional or not.

Well, sort of.  I've placed it in a small package along with other handy
stuff, so that won't be a problem.

Best,
Andy
 
> HTH,
> 
> Marc
> 
> 
> 
>



From maechler at stat.math.ethz.ch  Fri Sep 24 23:53:08 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 24 Sep 2004 23:53:08 +0200
Subject: [R] "moving average" method for time series objects
In-Reply-To: <4154144B.5000708@acelerate.com>
References: <A00D32D4F8342C4CB741761ACE09130AE3D306@elk.gartner.com>
	<4154144B.5000708@acelerate.com>
Message-ID: <16724.38724.315501.821323@gargle.gargle.HOWL>

>>>>> "Kjetil" == Kjetil Brinchmann Halvorsen <kjetil at acelerate.com>
>>>>>     on Fri, 24 Sep 2004 08:34:19 -0400 writes:

    Kjetil> Schwarz,Paul wrote:
    >> Dear R-Help readers,
    >> 
    >> I suspect that this question must be a FAQ, but my
    >> investigation of the archives has not been very
    >> revealing.  Is there an R function for calculating moving
    >> averages of time series objects?
    >> 
    >> 
    >> 
    Kjetil>  library(gregmisc) ?running test <- ts(rnorm(100))

    Kjetil>  test2 <- running(test, fun=median, width=10)
    Kjetil> length(test2) [1] 91

    Kjetil> you want fun=mean

Note that really for 
  - running mean, you should use  filter()
  - running median, you use       runmed()

Greg's running() function is probably appropriate for anything
else *but* these two cases...

Martin Maechler



From meles at free.fr  Sat Sep 25 00:08:25 2004
From: meles at free.fr (TRAMIER Blaise)
Date: Sat, 25 Sep 2004 00:08:25 +0200
Subject: [R] exponential correlation?
Message-ID: <20040924220825.GA19125@free.fr>

Hello,
	I have been asked to perform a exponential correlation on a data set.
Unfortunately, i did not find any simple example on how to do that with R. 
If the correlation is significant, one asked me to also find the thresold 
of the acceleration slope.

Have any of you a little example or a good link to get me started?

Best regards

Blaise
-- 
Mutt, c'est de la balle, quand ??a marche :-)



From krj at cs.toronto.edu  Sat Sep 25 10:43:47 2004
From: krj at cs.toronto.edu (Ken Jackson)
Date: Sat, 25 Sep 2004 04:43:47 -0400
Subject: [R] I'm here, but ...
Message-ID: <04Sep25.044348edt.25223-2124@sanpedro.cs.toronto.edu>

This is an automatic reply generated by the "vacation" program.

I'm here, but I am way behind on my emails.  Your message has been
saved; I will look at it as soon as possible.  However, if it is
urgent and you don't get a reply from me within the next few days, it
may be better to phone me at either 416-978-3619 or 416-978-7075.



From manodomilharal at bol.com.br  Sat Sep 25 17:48:51 2004
From: manodomilharal at bol.com.br (manodomilharal)
Date: Sat, 25 Sep 2004 12:48:51 -0300
Subject: [R] Help with package SJava
Message-ID: <I4LT9F$40195B43806652854D88DA0BC0E13DE1@bol.com.br>

Hi All!!

This is my first post here and it is an urgent one!!

I installed the SJava package, no problems, but when I
try to load it at R I get the following error (I have
Linux, not Windows):

> library(SJava)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
"/usr/lib/R/library/SJava/libs/SJava.so":
  libRSNativeJava.so: cannot open shared object file: No
such file or directory
Error in library(SJava) : .First.lib failed
>

This libRSNativeJava.so file it mentioned is there, it
is not missing...

Can anyone help please??? Thanks in advance!!!
 
__________________________________________________________________________
Acabe com aquelas janelinhas que pulam na sua tela.
AntiPop-up UOL - ?? gr??tis!
http://antipopup.uol.com.br/



From cliff at ms.washington.edu  Sat Sep 25 17:52:35 2004
From: cliff at ms.washington.edu (Cliff Lunneborg)
Date: Sat, 25 Sep 2004 08:52:35 -0700
Subject: [R] detection of outliers
Message-ID: <021801c4a317$ae0ba2f0$6401a8c0@C56909A>

Dimitris Rizopoulos writes, in part:

> Hi Philippe,
>
> you could consider using the Windsorized mean,
>
> winds.mean <-  function(x, k=2){

FYI, the shrinking of tails process of Winsorization was brought to the
attention of the statistical community by John Tukey. It is named after
its originator, Charley Winsor, and not after the House of Windsor.

**********************************************************
Cliff Lunneborg, Professor Emeritus, Statistics &
Psychology, University of Washington, Seattle
cliff at ms.washington.edu



From adrian.alexa at gmail.com  Sat Sep 25 18:26:11 2004
From: adrian.alexa at gmail.com (Adrian Alexa)
Date: Sat, 25 Sep 2004 18:26:11 +0200
Subject: [R] Strange behavior of is.na() on lists
Message-ID: <4062eb8d040925092648023fa4@mail.gmail.com>

Hello R-users, 


I have observed that is.na() behaves strange on some lists. Here is a
simple example:


> a = list(list('asd'))
> a
[[1]]
[[1]][[1]]
[1] "asd"


> for(i in 1:5)
+ print(is.na(a))
[1] TRUE
[1] FALSE
[1] TRUE
[1] TRUE
[1] TRUE
>
> for(i in 1:10)
+ print(as.integer(is.na(a)))
[1] 0
[1] 10
[1] 1
[1] 0
[1] 140897024
[1] 134567568
[1] 1
[1] 1953720684
[1] 145687400
[1] 1886352499
>


This is a very strange thing. The result is similar when applying
is.na() on more
complex lists: list(list(list(.....)). A concrete example where I
found this behavior is
the following list:


> str(as.list(hgu95av2GO)[1:5])
List of 5
 $ 1114_at  :List of 6
  ..$ GO:0005125:List of 3
  .. ..$ GOID    : chr "GO:0005125"
  .. ..$ Evidence: chr "IEA"
  .. ..$ Ontology: chr "MF"

  ...................................

  ..$ GO:0040007:List of 3
  .. ..$ GOID    : chr "GO:0040007"
  .. ..$ Evidence: chr "IEA"
  .. ..$ Ontology: chr "BP"
 $ 36421_at : logi NA
 $ 329_s_at :List of 5
  ..$ GO:0005198:List of 3
  .. ..$ GOID    : chr "GO:0005198"
  .. ..$ Evidence: chr "TAS"
  .. ..$ Ontology: chr "MF"

  ...................................

  ..$ GO:0005634:List of 3
  .. ..$ GOID    : chr "GO:0005634"
  .. ..$ Evidence: chr "TAS"
  .. ..$ Ontology: chr "CC"
 $ 34687_at :List of 3
  ..$ GO:0016020:List of 3
  .. ..$ GOID    : chr "GO:0016020"
  .. ..$ Evidence: chr "IEA"
  .. ..$ Ontology: chr "CC"
  
  ...................................



Is this behavior normal? I should mention that I try the examples on
different versions of R:

1  R 1.9.1	 Debian Sarge
2  R 2.0.0 beta	 Debian Sarge
3  R 1.9.1	 Windows
4  R 1.8.1	 SunOS


In my view this seems to be a bug. If is not, can somebody explain me what is 
really happening and how can I overcome this behavior?


Many thanks, 

Adrian 


-- 
Adrian Alexa             
Max-Planck-Institut fuer Informatik  
Stuhlsatzenhausweg 85 Room 514 
66123 Saarbruecken, Germany



From ggrothendieck at myway.com  Sat Sep 25 19:33:02 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 25 Sep 2004 13:33:02 -0400 (EDT)
Subject: [R] Strange behavior of is.na() on lists
Message-ID: <20040925173302.8411339D8@mprdmxin.myway.com>


Adrian Alexa <adrian.alexa at gmail.com> writes:
> 
> I have observed that is.na() behaves strange on some lists. Here is a
> simple example:
> 
> 
> > a = list(list('asd'))
> > a
> [[1]]
> [[1]][[1]]
> [1] "asd"
> 
> 
> > for(i in 1:5)
> + print(is.na(a))
> [1] TRUE
> [1] FALSE
> [1] TRUE
> [1] TRUE
> [1] TRUE
> >
> 
> [...snip...]
> 
> In my view this seems to be a bug. If is not, can somebody explain me what is
> really happening and how can I overcome this behavior?

This looks like a bug to me.  As far as a workaround goes you
could try this:


is.na <- function(x)
   if (length(x) == 0) {
      mode(x) <- "logical"
      x
   } else if (inherits(x, "list")) {
      lapply(x, function(i) if (is.atomic(x)) base::is.na(x) else FALSE)
   } else 
      base::is.na(x)



From murdoch at stats.uwo.ca  Sat Sep 25 19:33:40 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 25 Sep 2004 13:33:40 -0400
Subject: [R] Strange behavior of is.na() on lists
In-Reply-To: <4062eb8d040925092648023fa4@mail.gmail.com>
References: <4062eb8d040925092648023fa4@mail.gmail.com>
Message-ID: <du9bl0lmegdp96nd905hb98l59d9oncmsn@4ax.com>

On Sat, 25 Sep 2004 18:26:11 +0200, Adrian Alexa
<adrian.alexa at gmail.com> wrote:

>Hello R-users, 
>
>
>I have observed that is.na() behaves strange on some lists. Here is a
>simple example:
>
>
>> a = list(list('asd'))
>> a
>[[1]]
>[[1]][[1]]
>[1] "asd"
>
>
>> for(i in 1:5)
>+ print(is.na(a))
>[1] TRUE
>[1] FALSE
>[1] TRUE
>[1] TRUE
>[1] TRUE

Yes, this is a bug.  The problem is that the code leaves the result
unset in this case (no default on an incomplete switch statement).
I'll fix it.

Thanks for the report!

Duncan Murdoch



From spencer.graves at pdf.com  Sat Sep 25 22:21:34 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 25 Sep 2004 13:21:34 -0700
Subject: [R] exponential correlation?
In-Reply-To: <20040924220825.GA19125@free.fr>
References: <20040924220825.GA19125@free.fr>
Message-ID: <4155D34E.905@pdf.com>

      The "nlme" package has "corExp" for estimating the nuggett effect 
n and the range d for an exponential spatial correlation structure = n + 
(1-n)*exp(-r/d), where r = distance between two observations.  See 
library(nlme);  ?corExp, plus Pinheiro and Bates (2000) Mixed-Effects 
Models for S and S-Plus (Springer). 

      Is this what you want? 

      hope this helps. 
      spencer graves
p.s.  If this is NOT adequate, please read the posting guide! 
"http://www.R-project.org/posting-guide.html".  This might help you 
answer some questions for yourself, thereby getting you quicker answers 
than otherwise.  Moreover, it could increase your chances of getting a 
response that actually helps solve your problem.  In particular, please 
provide a toy example showing something that a reader can easily copy 
from an email and paste into R to try something just a little different. 

TRAMIER Blaise wrote:

>Hello,
>	I have been asked to perform a exponential correlation on a data set.
>Unfortunately, i did not find any simple example on how to do that with R. 
>If the correlation is significant, one asked me to also find the thresold 
>of the acceleration slope.
>
>Have any of you a little example or a good link to get me started?
>
>Best regards
>
>Blaise
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From chumpytown at gmail.com  Sat Sep 25 23:30:39 2004
From: chumpytown at gmail.com (chumpy town)
Date: Sat, 25 Sep 2004 14:30:39 -0700
Subject: [R] making custom function compute/return multiple items
Message-ID: <82b25009040925143012f50e@mail.gmail.com>

Hello, I'm relatively new to R.  I've read the intro guide, but I
can't quite figure out how to:

I have a function:

Jcost <- function (theta, in, out) {
  a <- output - input %*% theta
  1/2 * t(a) %*% a
}

where 
"theta" is a 2x1 matrix
"in" is a 20x2 matrix
"out" is a 20x1 matrix
return value is a scaler

This works well when I only want to compute given 1 theta matrix.  How
do I compute several (say N) 2x1 theta matrices and get back N scaler
values?

Thanks!

-- 
-david
David Chu



From p.dalgaard at biostat.ku.dk  Sat Sep 25 23:53:06 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 25 Sep 2004 23:53:06 +0200
Subject: [R] making custom function compute/return multiple items
In-Reply-To: <82b25009040925143012f50e@mail.gmail.com>
References: <82b25009040925143012f50e@mail.gmail.com>
Message-ID: <x2ekkquibh.fsf@biostat.ku.dk>

chumpy town <chumpytown at gmail.com> writes:

> Hello, I'm relatively new to R.  I've read the intro guide, but I
> can't quite figure out how to:
> 
> I have a function:
> 
> Jcost <- function (theta, in, out) {
>   a <- output - input %*% theta
>   1/2 * t(a) %*% a
> }
> 
> where 
> "theta" is a 2x1 matrix
> "in" is a 20x2 matrix
> "out" is a 20x1 matrix
> return value is a scaler
> 
> This works well when I only want to compute given 1 theta matrix.  How
> do I compute several (say N) 2x1 theta matrices and get back N scaler
> values?
> 
> Thanks!

Two tricks:

(A) You can't do this

> matrix(1:10,10,1)-matrix(1:20,10,2)
Error in matrix(1:10, 10, 1) - matrix(1:20, 10, 2) :
        non-conformable arrays

but you can do this (vector recycling)

> as.vector(matrix(1:10,10,1))-matrix(1:20,10,2)
      [,1] [,2]
 [1,]    0  -10
 [2,]    0  -10
 [3,]    0  -10
 [4,]    0  -10
 [5,]    0  -10
 [6,]    0  -10
 [7,]    0  -10
 [8,]    0  -10
 [9,]    0  -10
[10,]    0  -10

so if you put your theta vectors into a 2xN matrix you can get a 20xN
"a" matrix.

(B) If "a" has more than one column, you can use diag(t(a)%*%a) to get
the N scalars that you want, but that computes all the cross-products
unnecessarily. It will be much better to use colSums(a^2).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ggrothendieck at myway.com  Sun Sep 26 01:28:02 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sat, 25 Sep 2004 23:28:02 +0000 (UTC)
Subject: [R] making custom function compute/return multiple items
References: <82b25009040925143012f50e@mail.gmail.com>
Message-ID: <loom.20040926T011028-181@post.gmane.org>

chumpy town <chumpytown <at> gmail.com> writes:

: 
: Hello, I'm relatively new to R.  I've read the intro guide, but I
: can't quite figure out how to:
: 
: I have a function:
: 
: Jcost <- function (theta, in, out) {
:   a <- output - input %*% theta
:   1/2 * t(a) %*% a
: }
: 
: where 
: "theta" is a 2x1 matrix
: "in" is a 20x2 matrix
: "out" is a 20x1 matrix
: return value is a scaler
: 
: This works well when I only want to compute given 1 theta matrix.  How
: do I compute several (say N) 2x1 theta matrices and get back N scaler
: values?

Assuming `theta' is 2xN, apply the formula over the columns, i.e. dimension 2,
of `theta'.

By the way, note that `in', which is used above as a parameter to `Jcost', is
a reserved word in R and so should be avoided.

Jcost <- function(theta, input, output) 
      apply(as.matrix(theta), 2, function(theta) 
         1/2 * crossprod(output - input %*% theta))
      
Jcost(1:2, matrix(1:40,20), 1:20)
Jcost(3:4, matrix(1:40,20), 1:20)

# the following combines both of the above two lines into one:
Jcost(cbind(1:2, 3:4), matrix(1:40,20), 1:20)



From blindglobe at gmail.com  Sun Sep 26 05:03:49 2004
From: blindglobe at gmail.com (A.J. Rossini)
Date: Sat, 25 Sep 2004 23:03:49 -0400
Subject: [R] using tcltk in R under ESS/XEmacs on Windows
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF8434@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD504AF8434@usrymx25.merck.com>
Message-ID: <1abe3fa904092520035de0110a@mail.gmail.com>

It most likely is Windows specific.  It's most amazing that we
actually have ESS/(X)Emacs working under windows in the first place.

Unfortunately, I'm in transit for the next few weeks, but I'll
probably have a windows machine on my desk sometime after that.  Argh.

best,
-tony


On Fri, 24 Sep 2004 17:48:18 -0400, Liaw, Andy <andy_liaw at merck.com> wrote:
> > From: Marc Schwartz
> >
> > On Fri, 2004-09-24 at 15:02, Liaw, Andy wrote:
> > > Sorry for the cross-post.  Not sure where the problem is...
> > >
> > > A while back I posted an R function to R-help:
> > >
> > > cd <- function (dir = tclvalue(tkchooseDirectory()),
> > saveOld = FALSE,
> > >     loadNew = TRUE) {
> > >     stopifnot(require(tcltk))
> > >     if (saveOld)
> > >         save.image(compress = TRUE)
> > >     setwd(dir)
> > >     rm(list = ls(all = TRUE, envir = .GlobalEnv), envir =
> > .GlobalEnv)
> > >     if (loadNew && file.exists(".RData")) {
> > >         loaded <- load(".RData", envir = .GlobalEnv)
> > >         return(invisible(loaded))
> > >     }
> > >
> > > where the default value for the `dir' argument is to run
> > the tcltk directory
> > > chooser and get the directory name chosen.  (Thanks to
> > Prof. John Fox for
> > > the tcltk part!!)  While this function works fine under
> > Rgui on Windows, it
> > > doesn't work when running R within ESS (5.2.3) and XEmacs
> > (21.4.13).  The
> > > directory chooser never shows up, and dir just gets the
> > empty string.  Does
> > > anyone have any idea what could be the problem?  I'd very
> > much appreciate
> > > any pointers.
> > >
> > > Best,
> > > Andy
> >
> > Andy,
> >
> > This works under FC2 using ESS 5.2.3 with XEmacs version 21.4.15, so
> > presumably there is something specific to the Windows implementation?
> 
> Given Prof. Fox's follow-up and your obvservation, I guess the problem _is_
> Windows-specific. 8-(
> 
> > Also, two things:
> >
> > 1. You are missing a closing brace above, which I presume may be a
> > simple copy and paste issue.
> 
> Yes.  My apologies.
> 
> > 2. If you successfully change the directory, the cd()
> > function itself is
> > deleted from the global environment via your rm(...), as you currently
> > have it implemented. I am not sure if this is intentional or not.
> 
> Well, sort of.  I've placed it in a small package along with other handy
> stuff, so that won't be a problem.
> 
> Best,
> Andy
> 
> 
> 
> > HTH,
> >
> > Marc
> >
> >
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 



-- 
A.J. Rossini
blindglobe at gmail.com



From hi_ono2001 at ybb.ne.jp  Sun Sep 26 10:38:25 2004
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Sun, 26 Sep 2004 17:38:25 +0900 (JST)
Subject: [R] maps for Russian Federation
In-Reply-To: <Pine.LNX.4.44.0409241353260.24170-100000@reclus.nhh.no>
Message-ID: <20040926083825.70298.qmail@web1709.mail.yahoo.co.jp>

> > Dear all,
> > 
> > I am interested in plotting maps visualizing
> spatial statistics in an
> > aggregated fashion, according to administrative
> boundaries. Partially, I
> > want to visualize some spatial data for
> administrative units (autonomous
> > republics, oblasts, krays) of the Russian
> Federation on a geographical
> > map.
> > 

 How about "Shapefiles for Epi Info".

 They are free. But they are "not in the public domain and
are intended for use with Epi Info
?Epi Map only."

 Their formats are shapefile.

 Although their boundaries are in 1998.


 Regards.



From ozric at web.de  Sun Sep 26 11:14:45 2004
From: ozric at web.de (Christian Schulz)
Date: Sun, 26 Sep 2004 11:14:45 +0200
Subject: [R] avoiding loops?
Message-ID: <200409261114.45926.ozric@web.de>

Hi,

is it possible doing this "moving average" 
without a loop, because it is not really
fast for dim(x) 300.000 50. 
I make some attempts with apply and sapply,but didn't get success  until now.

many thanks , christian


ma <- function(x, FUN=mean, lag=5) 
 { 
         FUN=match.fun(FUN)
         n <-  ncol(x) - lag 
         frame <-  matrix(0,nrow=nrow(x),ncol=n)
         for(k in 1:nrow(frame)){
         for (i in 1:ncol(frame)) { 
         frame[k,i] <- FUN(x[k,i]:x[k,i + lag])
         } }
         return(as.data.frame(frame) )
 }



From iip at chead.org  Sun Sep 26 12:30:24 2004
From: iip at chead.org (iip)
Date: Sun, 26 Sep 2004 17:30:24 +0700
Subject: [R] help for stata user
Message-ID: <14217950120.20040926173024@smunsa.cjb.net>

Hi,

I'm new to R, and I'm STATA user before, could you help me where I can
get document about comparison command between STATA and R.

Thank you very much,

Best regards,
-iip-



From ligges at statistik.uni-dortmund.de  Sun Sep 26 12:40:00 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 26 Sep 2004 12:40:00 +0200
Subject: [R] avoiding loops?
In-Reply-To: <200409261114.45926.ozric@web.de>
References: <200409261114.45926.ozric@web.de>
Message-ID: <41569C80.3020204@statistik.uni-dortmund.de>

Christian Schulz wrote:

> Hi,
> 
> is it possible doing this "moving average" 
> without a loop, because it is not really
> fast for dim(x) 300.000 50. 


On the other hand, building a matrix before consumes too much memory. 
The best way of doing it is using an already existing function (you 
might want to look whether, e.g., filter() helps) or porting the loops to C.

Uwe Ligges

> I make some attempts with apply and sapply,but didn't get success  until now.
> 
> many thanks , christian
> 
> 
> ma <- function(x, FUN=mean, lag=5) 
>  { 
>          FUN=match.fun(FUN)
>          n <-  ncol(x) - lag 
>          frame <-  matrix(0,nrow=nrow(x),ncol=n)
>          for(k in 1:nrow(frame)){
>          for (i in 1:ncol(frame)) { 
>          frame[k,i] <- FUN(x[k,i]:x[k,i + lag])
>          } }
>          return(as.data.frame(frame) )
>  }
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From tom_woody at swissinfo.org  Sun Sep 26 13:01:12 2004
From: tom_woody at swissinfo.org (=?ISO-8859-15?Q?Thomas_Sch=F6nhoff?=)
Date: Sun, 26 Sep 2004 13:01:12 +0200
Subject: [R] how to set options (variables) permanently
Message-ID: <4156A178.7010202@swissinfo.org>

Hi,

after starting Emacs/ESS/R environment I tried to launch "edit" or 
"fix". This normally should fire up the $editor, isn't it.

Instead of this I regularily I run into an error that there something 
wrong with $editor.


-----------------------------------------------
 >  op <- options(); str(op)

Amongst many entries you'll find this:

  $ editor               : chr "emacsclient"
------------------------------------------------

Seems to be plain obivious that this command (instead of 'emacs' or 
'/usr/bin/emacs') would never run.

So an options(editor="emacs") does the trick, I already found out......

But it is very uncomfortable to set the $editor variable every time when 
you return to R!

I've tried to achieve this by:

save.image()
or
q("yes")

and also:

options(OPT = emacs)
options(EDITOR=emcas)

but this didn't work! Next time I fired up Emacs/ESS/R again, the 
$editor variable is still defaulting to "emacsclient"?!

Is there any possiblity to adjust and store this variable (and others) 
permanently ? My search on this topic in R-Mailing-Archives failed.

regards

Thomas


platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    1
minor    9.1
year     2004
month    06
day      21
language R



From 0034058 at fudan.edu.cn  Sun Sep 26 13:49:06 2004
From: 0034058 at fudan.edu.cn (rongguiwong)
Date: Sun, 26 Sep 2004 19:49:06 +0800
Subject: [R] want some materials about data manipulation.
In-Reply-To: <4156A178.7010202@swissinfo.org>
References: <4156A178.7010202@swissinfo.org>
Message-ID: <200409261949.07019.0034058@fudan.edu.cn>

in the offical documnets,not much about data maniplution.
any one can give me some hints about data manipulation with R or awk or sed?
any help will be appreciated.
i want to tranfer from windows to linux,but when i deal with data 
manipulation,i have to turn to windows,i hope i can do my job under MDK linux 
whole.



From ggrothendieck at myway.com  Sun Sep 26 14:15:12 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Sun, 26 Sep 2004 12:15:12 +0000 (UTC)
Subject: [R] want some materials about data manipulation.
References: <4156A178.7010202@swissinfo.org>
	<200409261949.07019.0034058@fudan.edu.cn>
Message-ID: <loom.20040926T141211-765@post.gmane.org>

rongguiwong <0034058 <at> fudan.edu.cn> writes:

: 
: in the offical documnets,not much about data maniplution.
: any one can give me some hints about data manipulation with R or awk or sed?
: any help will be appreciated.
: i want to tranfer from windows to linux,but when i deal with data 
: manipulation,i have to turn to windows,i hope i can do my job under MDK 
linux 
: whole.

If your question is how, in general, to find information on R,
go the R home page by entering the single letter R into google and then
look at the links under Documentation in the left hand pane.

If your question is how to preprocess data with sed or awk try this:

mydata <- read.table(pipe("awk -f filter.awk input.txt"))



From patrick.drechsler at gmx.net  Sun Sep 26 14:24:31 2004
From: patrick.drechsler at gmx.net (Patrick Drechsler)
Date: Sun, 26 Sep 2004 14:24:31 +0200
Subject: [R] Sweave: superfluous newline (`\\') in tex file
Message-ID: <m3wtyh8bgg.fsf@pdrechsler.fqdn.th-h.de>

Hi,

I'm having trouble sweaving the following example:

--8<------------------------schnipp------------------------->8---
\documentclass{article}
\begin{document}
\SweaveOpts{echo=FALSE}
@ 
<<>>=
rm(list=c(ls()))
library(Hmisc)
library(ISwR)
data(energy)
energy$log <- log(energy$expend)
attach(energy)
@ %def 

@ 
<<results=tex>>=
mysum <- summary(stature ~ expend + log, method="reverse", test=T)
latex(mysum, file='',
      caption="foo bar",
      label="tab:foobar"
      )
@ %def 

\end{document}
--8<------------------------schnapp------------------------->8---

Here's the resulting tex file (sorry for the long lines):

--8<------------------------schnipp------------------------->8---
\documentclass{article}
\usepackage{/usr/local/lib/R/share/texmf/Sweave}
\begin{document}


% latex.default(cstats, title = title, caption = caption, rowlabel = rowlabel,      col.just = col.just, numeric.dollar = FALSE, insert.bottom = legend,      rowname = lab, dcolumn = dcolumn, extracolheads = extracolheads,      extracolsize = Nsize, ...) 
%
\begin{table}[!tbp]
 \caption{foo bar\label{tab:foobar}} 
 \begin{center}
 \begin{tabular}{lccc}\hline\hline
\multicolumn{1}{l}{}&
\multicolumn{1}{c}{lean}&
\multicolumn{1}{c}{obese}&
\multicolumn{1}{c}{Test Statistic}
\\   &\multicolumn{1}{c}{{\scriptsize $N=13$}}&\multicolumn{1}{c}{{\scriptsize $N=9$}}&\\ \hline
expend&{\scriptsize  7.48~}{ 7.90 }{\scriptsize  8.11} &{\scriptsize  9.21~}{ 9.69 }{\scriptsize 11.51} &$ F_{1,20}=17 ,~ P<0.001  $\\
log&{\scriptsize 2.012233~}{2.066863 }{\scriptsize 2.093098} &{\scriptsize 2.220290~}{2.271094 }{\scriptsize 2.443216} &$ F_{1,20}=17 ,~ P<0.001  $\\
\hline
\end{tabular}

\end{center}

\noindent {\scriptsize $a$\ }{$b$\ }{\scriptsize $c$\ } represent the lower quartile $a$, the median $b$, and the upper quartile $c$\ for continuous variables.\\

 \\ %% <- ERROR!
 

 Test used: Wilcoxon test
\end{table}
\end{document}
--8<------------------------schnapp------------------------->8---

And here's the error message:

,----
| ERROR: LaTeX Error: There's no line here to end.
| 
| --- TeX said ---
| 
| See the LaTeX manual or LaTeX Companion for explanation.
| Type  H <return>  for immediate help.
|  ...                                              
|                                                   
| l.27 
|      
| --- HELP ---
| A \newline or \\ command appears between paragraphs, where it
| makes no sense. If you're trying to ``leave a blank line'', use
| a \vspace command.
`----

Is there a way to suppress the extra newline `\\' without editing
the Rnw file? I couldn't find anything in the archives
describing this problem.

TIA,

Patrick

Versions:

Thorsten's noweb-mode (PRERELEASE). RCS: $Id: noweb-mode.el,v 1.14 2002/06/20 21:52:06 rsparapa Exp $

Emacs  : GNU Emacs 21.3.50.6 (i686-pc-linux-gnu, X toolkit, Xaw3d scroll bars)
 of 2004-09-07 on trurl
Package: ess-mode 5.2.3

R : Copyright 2004, The R Foundation for Statistical Computing
Version 1.9.1 alpha (2004-06-07), ISBN 3-900051-00-3


-- 
"I'm all in favor of keeping dangerous weapons out of the hands of
fools. Let's start with typewriters." 
    -- Frank Lloyd Wright (1868-1959)



From patrick.drechsler at gmx.net  Sun Sep 26 14:28:50 2004
From: patrick.drechsler at gmx.net (Patrick Drechsler)
Date: Sun, 26 Sep 2004 14:28:50 +0200
Subject: [R] Sweave: superfluous newline (`\\') in tex file
References: <m3wtyh8bgg.fsf@pdrechsler.fqdn.th-h.de>
Message-ID: <m3r7op8b99.fsf@pdrechsler.fqdn.th-h.de>


Patrick Drechsler wrote on 26 Sep 2004 13:24:31 MET:

> Is there a way to suppress the extra newline `\\' without editing
> the Rnw file? 

sorry, typo: s/Rnw/tex/

Patrick
-- 
Black Holes result from God 
dividing the universe by zero.



From aragon at berkeley.edu  Sun Sep 26 21:06:30 2004
From: aragon at berkeley.edu (Tomas Aragon)
Date: Sun, 26 Sep 2004 12:06:30 -0700 (PDT)
Subject: [R] help for stata user
In-Reply-To: <14217950120.20040926173024@smunsa.cjb.net>
Message-ID: <20040926190630.56949.qmail@web80103.mail.yahoo.com>

--- iip <iip at chead.org> wrote:
> Hi,
> 
> I'm new to R, and I'm STATA user before, could you help me where I
> can
> get document about comparison command between STATA and R.
> 
> Thank you very much,
> 
> Best regards,
> -iip-
> 
I am a former Stata user. Although I have no direct comparison between
R and Stata, you might get an idea from some of our links:

I post my draft R manual on at
http://www.medepi.net/aragon

Look at our R course syllabus at 
http://www.idready.org/courses/2004/fall/2004FallEpiUsingR.html
(There is link to great tutorial by Mark Myatt)

I have some computer-based labs based on CDC outbreak modules at
http://www.idready.org/epi/lab/index.html

I am very slowly building "epitools" R package, available at 
http://www.epitools.net

Eventually, www.epitools.net will become the portal for all these
documents.

Tomas


=====
Tomas Aragon, MD, DrPH, Director
Center for Infectious Disease Preparedness
UC Berkeley School of Public Health
1918 University Ave., 4th Fl., MC-7350
Berkeley, CA 94720-7350
http://www.idready.org



From hellerma at yahoo.com  Sun Sep 26 22:04:14 2004
From: hellerma at yahoo.com (Martin Heller)
Date: Sun, 26 Sep 2004 13:04:14 -0700 (PDT)
Subject: [R] (no subject)
Message-ID: <20040926200414.9387.qmail@web52402.mail.yahoo.com>

Hello R help mailing list,
I'm having difficulty saving a series of figures in an
analysis.  I have attempted to save them in a for loop with
the following code: 

for(i in 1:20){
	sF<-paste("fig",i,".jpeg",sep="")
jpeg(file=sF,width=600,height=500,quality=100,pointsize=12)
	attach(plotData)
	xyplot(CHC~1:13),
	detach(plotData)
	graphics.off()
}

If I break apart the for loop and write the code 20 times,
the images save correctly.  When I run the for loop the
saved images are blank.  Any help would be greatly
appreciated,
Martin



From andy_liaw at merck.com  Sun Sep 26 22:14:04 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sun, 26 Sep 2004 16:14:04 -0400
Subject: no plots in for loop (was RE: [R] (no subject))
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8439@usrymx25.merck.com>

1. Please use a meaningful subject, as the Posting Guide asked you to.

2. You need to wrap xyplot() (or any other lattice plotting functions) in
print().  I believe this is in the FAQ.

Andy

> From: Martin Heller
> 
> Hello R help mailing list,
> I'm having difficulty saving a series of figures in an
> analysis.  I have attempted to save them in a for loop with
> the following code: 
> 
> for(i in 1:20){
> 	sF<-paste("fig",i,".jpeg",sep="")
> jpeg(file=sF,width=600,height=500,quality=100,pointsize=12)
> 	attach(plotData)
> 	xyplot(CHC~1:13),
> 	detach(plotData)
> 	graphics.off()
> }
> 
> If I break apart the for loop and write the code 20 times,
> the images save correctly.  When I run the for loop the
> saved images are blank.  Any help would be greatly
> appreciated,
> Martin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ramasamy at cancer.org.uk  Sun Sep 26 22:41:00 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Sun, 26 Sep 2004 21:41:00 +0100
Subject: [R] (no subject)
In-Reply-To: <20040926200414.9387.qmail@web52402.mail.yahoo.com>
References: <20040926200414.9387.qmail@web52402.mail.yahoo.com>
Message-ID: <1096231260.28446.22.camel@localhost.localdomain>

1) Read the posting guide http://www.R-project.org/posting-guide.html
which tells you to
 a) use a meaningful subject line
 b) give a reproducible example. I cannot find plotData and there is a
syntax error (comma after the xyplot line).


2) The following example works fine for me

for(i in 1:20){
  sF<-paste("fig",i,".jpeg",sep="")
  jpeg(file=sF,width=600,height=500,quality=100,pointsize=12)
  plot( rnorm(100) )
  graphics.off()
}


3) Try replacing graphics.off() with dev.off(). From
help("graphics.off") :

     'dev.off' shuts down the specified (by default the current)
     device. 'graphics.off()' shuts down all open graphics devices.


4) If you use postscript or pdf, you can have multiple graphs in one
document. E.g.

postscript(file="aaa.ps")
for(i in 1:20){
  plot( rnorm(100) ) 
} 
dev.off()



On Sun, 2004-09-26 at 21:04, Martin Heller wrote:
> Hello R help mailing list,
> I'm having difficulty saving a series of figures in an
> analysis.  I have attempted to save them in a for loop with
> the following code: 
> 
> for(i in 1:20){
> 	sF<-paste("fig",i,".jpeg",sep="")
> jpeg(file=sF,width=600,height=500,quality=100,pointsize=12)
> 	attach(plotData)
> 	xyplot(CHC~1:13),
> 	detach(plotData)
> 	graphics.off()
> }
> 
> If I break apart the for loop and write the code 20 times,
> the images save correctly.  When I run the for loop the
> saved images are blank.  Any help would be greatly
> appreciated,
> Martin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From wuertz at itp.phys.ethz.ch  Sun Sep 26 22:59:37 2004
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Sun, 26 Sep 2004 20:59:37 +0000
Subject: [R] aparchFit()$fitted.value
In-Reply-To: <000b01c4a0cc$3d641c00$ba0f3152@userxwov7q21jr>
References: <000b01c4a0cc$3d641c00$ba0f3152@userxwov7q21jr>
Message-ID: <41572DB9.8050800@itp.phys.ethz.ch>


Indeed, fitted.values and residuals methods are missing for aparch. They 
are only available
for garch. This was not properly expressed in the help page.

Since I'm writing a complete new package for ARCH and related models 
using S4 methods
the methods will be available in the new package. In the old package the 
methods will not
be added for aparch. I made a notice in the help page.

Regards Diethelm


Lisa wrote:

>Dear R people,
>I'm not able to have the component residuals, fitted.value ....from an
>aparchFit() estimation as explain in the Value of aparchFit Help, package
>fSeries.
>
>Could someone help me?
>Thanks in advance.
>Lisa
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From konradb at fluit.cs.vu.nl  Mon Sep 27 04:13:14 2004
From: konradb at fluit.cs.vu.nl (Banachewicz KP)
Date: Mon, 27 Sep 2004 04:13:14 +0200 (CEST)
Subject: [R] multiple time series
Message-ID: <Pine.GSO.4.56.0409270404350.16613@fluit.cs.vu.nl>

Hello everybody,
I have the following problem: I read a multiple time series (along with
column names), and then need to manipulate the univariate components
separately in order to compute the statistics of interest. Can someone
tell me how can I access the univariates separately through their names ?
I need to do it on a ts object (and not data frame, where I know how to),
for the sake of later use of tsboot. Thanks for help


					rg,

					Konrad



From edd at debian.org  Mon Sep 27 04:29:25 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 26 Sep 2004 21:29:25 -0500
Subject: [R] multiple time series
In-Reply-To: <Pine.GSO.4.56.0409270404350.16613@fluit.cs.vu.nl>
References: <Pine.GSO.4.56.0409270404350.16613@fluit.cs.vu.nl>
Message-ID: <20040927022925.GA2371@sonny.eddelbuettel.com>

On Mon, Sep 27, 2004 at 04:13:14AM +0200, Banachewicz KP wrote:
> Hello everybody,
> I have the following problem: I read a multiple time series (along with
> column names), and then need to manipulate the univariate components
> separately in order to compute the statistics of interest. Can someone
> tell me how can I access the univariates separately through their names ?

It works the usual way:

> z <- ts(matrix(rnorm(300), 100, 3), start=c(1961, 1), frequency=12)
> colnames(z) <- c("foo","bar","boo")
> summary(z[,"boo"])
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
-1.92700 -0.79140 -0.08982 -0.10660  0.54350  2.32600
>                                                                         

You could also use z$foo, or z[,1] -- i.e. it works just like the data frames.

Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From konradb at fluit.cs.vu.nl  Mon Sep 27 04:50:06 2004
From: konradb at fluit.cs.vu.nl (Banachewicz KP)
Date: Mon, 27 Sep 2004 04:50:06 +0200 (CEST)
Subject: [R] multiple time series
In-Reply-To: <20040927022925.GA2371@sonny.eddelbuettel.com>
References: <Pine.GSO.4.56.0409270404350.16613@fluit.cs.vu.nl>
	<20040927022925.GA2371@sonny.eddelbuettel.com>
Message-ID: <Pine.GSO.4.56.0409270446160.16727@fluit.cs.vu.nl>

thanks Dirk, I missed the obvious z[,i] option (shame on me ;-(
however, when I tried to use z$foo I get a NULL, despite the fact that
this particular column is not empty. any idea why ?

					rg,

					Konrad

On Sun, 26 Sep 2004, Dirk Eddelbuettel wrote:
> It works the usual way:>
> > z <- ts(matrix(rnorm(300), 100, 3), start=c(1961, 1), frequency=12)
> > colnames(z) <- c("foo","bar","boo")
> > summary(z[,"boo"])
>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
> -1.92700 -0.79140 -0.08982 -0.10660  0.54350  2.32600
> >
>
> You could also use z$foo, or z[,1] -- i.e. it works just like the data frames.
>
> Dirk
>
> --
> Those are my principles, and if you don't like them... well, I have others.
>                                                 -- Groucho Marx
>



From ggrothendieck at myway.com  Mon Sep 27 07:45:32 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 27 Sep 2004 05:45:32 +0000 (UTC)
Subject: [R] multiple time series
References: <Pine.GSO.4.56.0409270404350.16613@fluit.cs.vu.nl>
	<20040927022925.GA2371@sonny.eddelbuettel.com>
	<Pine.GSO.4.56.0409270446160.16727@fluit.cs.vu.nl>
Message-ID: <loom.20040927T074019-76@post.gmane.org>


There is no $.ts defined in R; however, you can define your own if you wish.

"$.ts" <- function(x, i) x[,as.character(substitute(i))]
z$foo # using z from below



Banachewicz KP <konradb <at> fluit.cs.vu.nl> writes:

: 
: thanks Dirk, I missed the obvious z[,i] option (shame on me ;-(
: however, when I tried to use z$foo I get a NULL, despite the fact that
: this particular column is not empty. any idea why ?
: 
: 					rg,
: 
: 					Konrad
: 
: On Sun, 26 Sep 2004, Dirk Eddelbuettel wrote:
: > It works the usual way:>
: > > z <- ts(matrix(rnorm(300), 100, 3), start=c(1961, 1), frequency=12)
: > > colnames(z) <- c("foo","bar","boo")
: > > summary(z[,"boo"])
: >     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
: > -1.92700 -0.79140 -0.08982 -0.10660  0.54350  2.32600
: > >
: >
: > You could also use z$foo, or z[,1] -- i.e. it works just like the data 
frames.



From ripley at stats.ox.ac.uk  Mon Sep 27 08:30:14 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 27 Sep 2004 07:30:14 +0100 (BST)
Subject: [R] multiple time series
In-Reply-To: <Pine.GSO.4.56.0409270446160.16727@fluit.cs.vu.nl>
Message-ID: <Pine.LNX.4.44.0409270727280.29572-100000@gannet.stats>

On Mon, 27 Sep 2004, Banachewicz KP wrote:

> thanks Dirk, I missed the obvious z[,i] option (shame on me ;-(
> however, when I tried to use z$foo I get a NULL, despite the fact that
> this particular column is not empty. any idea why ?

A multiple time series (as created by ts()) is a *matrix* not a data 
frame.  [You can create ts data frames via ts.union.]

So index its columns as a matrix, only.

> 
> 					rg,
> 
> 					Konrad
> 
> On Sun, 26 Sep 2004, Dirk Eddelbuettel wrote:
> > It works the usual way:>
> > > z <- ts(matrix(rnorm(300), 100, 3), start=c(1961, 1), frequency=12)
> > > colnames(z) <- c("foo","bar","boo")
> > > summary(z[,"boo"])
> >     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
> > -1.92700 -0.79140 -0.08982 -0.10660  0.54350  2.32600
> > >
> >
> > You could also use z$foo, or z[,1] -- i.e. it works just like the data frames.
> >
> > Dirk
> >
> > --
> > Those are my principles, and if you don't like them... well, I have others.
> >                                                 -- Groucho Marx
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From john_hendrickx at yahoo.com  Mon Sep 27 11:02:29 2004
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Mon, 27 Sep 2004 02:02:29 -0700 (PDT)
Subject: [R] help for stata user
In-Reply-To: <14217950120.20040926173024@smunsa.cjb.net>
Message-ID: <20040927090229.59735.qmail@web52706.mail.yahoo.com>

--- iip <iip at chead.org> wrote:

> Hi,
> 
> I'm new to R, and I'm STATA user before, could you help me where I
> can
> get document about comparison command between STATA and R.
> 
R is more of a statistical programming language whereas Stata is a
statistical package. R is more powerful but also has a steeper
learning curve. I like R's builtin matrix facilities, which are much
better than Stata's (although there are user-written extensions to
the Stata matrix facilities). R has good debugging tools and
user-written help files are integrated in the help.search() system. 

An area where Stata has the advantage is converting between strings
and variables. R has constructs like
"eval(parse(text=paste(object,"string),sep="")))", very confusing.
See 7.21 of the R faq for some examples.

Below are two sample jobs in R and in Stata. They read in a
space-delimited data file, define labels, summarize the data, run
tables, and estimate linear regression, multinomial logit, and
ordered logit models. The data are available from the "catspec"
package if you'd like to experiment with them yourself. Hope they get
you started in R. See "An introduction to R" to help you along a
little further (included in the R distribution). I also found John
Maindonald's "Using R for Data Analysis and Graphics" very helpful;
it's available at http://cran.r-project.org/other-docs.html

Good luck,
John Hendrickx

---- sampjob.do ----------------------------------------------------
/* Sample data used in Logan (1983: 332-333)
   Data are from the 1972-1978 merged Genderal Social Surveys (GSS)
   of the National Opinion Research Center (NORC). The selection is
   restricted to males, aged 25 to 34 at the time of the interview,
who
   were in the labour force at the time of interview, and who had
   non-missing values for respondent's education and occupation and
for
   father's occupation and education. N=838.

   Logan, J. (1983). "A multivariate model for mobility tables."
   American Journal of Sociology 89: 324-349.
*/
#delimit ;
label define occs 1 "Farm"          /* occupations */
                  2 "Operatives"    /* service, and laborers */
                  3 "Craftsmen"     /* and kindred workers */
                  4 "Sales"         /* and clerical" */
                  5 "Professional"; /* technical, and mangerial"*/
#delimit cr
label define race 1 "black" 0 "non-black"

infile byte(occ focc educ black) using logan.dat
label variable occ "occupation"
label variable focc "father's occupation at age 16"
label variable educ "education in years"
label variable black "race"
label values occ occs
label values focc occs
label values black race

summarize

tab focc
tab occ
tab focc occ
tab black
tab occ black
tab occ black, col
tab focc occ, row col

regress occ educ black
mlogit occ educ black, base(1)
ologit occ educ black
/* Sample data used in Logan (1983: 332-333)
   Data are from the 1972-1978 merged Genderal Social Surveys (GSS)
   of the National Opinion Research Center (NORC). The selection is
   restricted to males, aged 25 to 34 at the time of the interview,
who
   were in the labour force at the time of interview, and who had
   non-missing values for respondent's education and occupation and
for
   father's occupation and education. N=838.

   Logan, J. (1983). "A multivariate model for mobility tables."
   American Journal of Sociology 89: 324-349.
*/
#delimit ;
label define occs 1 "Farm"          /* occupations */
                  2 "Operatives"    /* service, and laborers */
                  3 "Craftsmen"     /* and kindred workers */
                  4 "Sales"         /* and clerical" */
                  5 "Professional"; /* technical, and mangerial"*/
#delimit cr
label define race 1 "black" 0 "non-black"

infile byte(occ focc educ black) using logan.dat
label variable occ "occupation"
label variable focc "father's occupation at age 16"
label variable educ "education in years"
label variable black "race"
label values occ occs
label values focc occs
label values black race

summarize

tab focc
tab occ
tab focc occ
tab black
tab occ black
tab occ black, col
tab focc occ, row col

regress occ educ black
mlogit occ educ black, base(1)
ologit occ educ black
/* Sample data used in Logan (1983: 332-333)
   Data are from the 1972-1978 merged Genderal Social Surveys (GSS)
   of the National Opinion Research Center (NORC). The selection is
   restricted to males, aged 25 to 34 at the time of the interview,
who
   were in the labour force at the time of interview, and who had
   non-missing values for respondent's education and occupation and
for
   father's occupation and education. N=838.

   Logan, J. (1983). "A multivariate model for mobility tables."
   American Journal of Sociology 89: 324-349.
*/
#delimit ;
label define occs 1 "Farm"          /* occupations */
                  2 "Operatives"    /* service, and laborers */
                  3 "Craftsmen"     /* and kindred workers */
                  4 "Sales"         /* and clerical" */
                  5 "Professional"; /* technical, and mangerial"*/
#delimit cr
label define race 1 "black" 0 "non-black"

infile byte(occ focc educ black) using logan.dat
label variable occ "occupation"
label variable focc "father's occupation at age 16"
label variable educ "education in years"
label variable black "race"
label values occ occs
label values focc occs
label values black race

summarize

tab focc
tab occ
tab focc occ
tab black
tab occ black
tab occ black, col
tab focc occ, row col

regress occ educ black
mlogit occ educ black, base(1)
ologit occ educ black
--------------------------------------------------------------------

--- sampjob.R -------------------------------------------------------
mytab <- function (x,y) {
	prop.table(table(x,y),2)*100
}

logan <- read.table("logan.dat")
names(logan) <- c("occ", "focc", "educ", "black")
attach(logan)
occ.codes <- c("farm", "operatives", "craftsmen", "sales",
"professional")
occ <- factor(occ,label=occ.codes)
focc <- factor(focc,label=occ.codes)
black <- factor(black,label=c("non-black", "black"))

summary(logan)

table(focc)
table(occ)
dit<-mytab(focc,occ)
dit
table(black)
mytab(occ,black)

library(gregmisc)
CrossTable(occ,black,prop.t=F,prop.r=F,fisher=FALSE)
CrossTable(focc,occ,prop.t=F,fisher=FALSE)
detach(package:gregmisc)

fm <- lm(occ~ educ+black, data=logan)
summary(fm)
anova(fm)

library(nnet)
mnl.logit<-multinom(occ ~ educ+black, data=logan)
summary(mnl.logit,correlation=FALSE)
detach(package:nnet)

library(MASS)
or.logit <- polr(occ ~ educ+black)
summary(or.logit)
detach(package:MASS)



From Torsten.Hothorn at rzmail.uni-erlangen.de  Mon Sep 27 11:27:40 2004
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Mon, 27 Sep 2004 11:27:40 +0200 (CEST)
Subject: [R] R courses in Germany
Message-ID: <Pine.LNX.4.51.0409271116070.8552@artemis.imbe.med.uni-erlangen.de>


The second part of the R courses at the University of Hanover will take
place at November 15th and 16th. Topics include

* Multiple Comparisons in R (Frank Bretz and Ludwig A. Hothorn)

* Regression and Classification in R (Torsten Hothorn) and

* Survival Analysis in R (Axel Benner).

More details are available from

	http://www.bioinf.uni-hannover.de/R-Kurse/

Best,

Torsten



From meinhardploner at gmx.net  Mon Sep 27 11:27:34 2004
From: meinhardploner at gmx.net (Meinhard Ploner)
Date: Mon, 27 Sep 2004 11:27:34 +0200
Subject: [R] emacs, Mac OS X, R
In-Reply-To: <E59E4292-0E41-11D9-B31A-0003930C7D76@louisville.edu>
References: <C4958F90-0E32-11D9-9448-0003938C0ABE@gmx.net>
	<E59E4292-0E41-11D9-B31A-0003930C7D76@louisville.edu>
Message-ID: <76C6E4CF-1067-11D9-90F2-0003938C0ABE@gmx.net>


On Sep 24, 2004, at 5:53 PM, Bill Rising wrote:

> On Sep 24, 2004, at 10:05, Meinhard Ploner wrote:
>
>> Hi!
>>
>> Since August I am using emacs on my Macintosh to edit the R objects. 
>> I have installed R 1.9.1, Mac OS X 10.3.5 and GNU Emacs 21.2.1. 
>> However there are some issues I haven't resolved:
>>
>> a) switch the caps lock key to the meta key (and when this is not 
>> possible, switch the alt/option key to the meta).
>
> You can use only the command or option key for the meta key. To see 
> the method, try looking at
>
> http://members.shaw.ca/akochoi-emacs/stories/faq.html
>
>> The switch should work only within emacs!
>>
>> b) having different colors for the code, i.e. comments, commands, 
>> strings, ...
>
> I'd advise using ESS, whose home page is
>
> http://stat.ethz.ch/ESS/
after installing ESS 5.2.3 I called emacs and within emacs M-x R and I 
get the following:

 > options(STERM='iESS', editor='emacsclient')
 >
 > fix(fun1)
emacsclient: can't find socket; have you started the server?
Error in edit(name, file, editor) : problem with running editor 
emacsclient
 >

What did I wrong?
Meinhard


>
> Bill
>



From marwan.khawaja at aub.edu.lb  Mon Sep 27 18:48:50 2004
From: marwan.khawaja at aub.edu.lb (Marwan Khawaja)
Date: Mon, 27 Sep 2004 12:48:50 -0400
Subject: [R] help for stata user
In-Reply-To: <20040927090229.59735.qmail@web52706.mail.yahoo.com>
Message-ID: <CLECJBOEBGOMOKJHJNDAEEFEEEAA.marwan.khawaja@aub.edu.lb>


> R is more of a statistical programming language whereas Stata is a
> statistical package. R is more powerful but also has a steeper
> learning curve. I like R's builtin matrix facilities, which are much
> better than Stata's (although there are user-written extensions to
> the Stata matrix facilities). R has good debugging tools and
> user-written help files are integrated in the help.search() system.

Well -- Stata does have a powerful macro facility -- and you can program
virtually anything you need for stat.

Marwan

-------------------------------------------------------------------
Marwan Khawaja         http://staff.aub.edu.lb/~mk36/
-------------------------------------------------------------------



>
> An area where Stata has the advantage is converting between strings
> and variables. R has constructs like
> "eval(parse(text=paste(object,"string),sep="")))", very confusing.
> See 7.21 of the R faq for some examples.
>
> Below are two sample jobs in R and in Stata. They read in a
> space-delimited data file, define labels, summarize the data, run
> tables, and estimate linear regression, multinomial logit, and
> ordered logit models. The data are available from the "catspec"
> package if you'd like to experiment with them yourself. Hope they get
> you started in R. See "An introduction to R" to help you along a
> little further (included in the R distribution). I also found John
> Maindonald's "Using R for Data Analysis and Graphics" very helpful;
> it's available at http://cran.r-project.org/other-docs.html
>
> Good luck,
> John Hendrickx
>
> ---- sampjob.do ----------------------------------------------------
> /* Sample data used in Logan (1983: 332-333)
>    Data are from the 1972-1978 merged Genderal Social Surveys (GSS)
>    of the National Opinion Research Center (NORC). The selection is
>    restricted to males, aged 25 to 34 at the time of the interview,
> who
>    were in the labour force at the time of interview, and who had
>    non-missing values for respondent's education and occupation and
> for
>    father's occupation and education. N=838.
>
>    Logan, J. (1983). "A multivariate model for mobility tables."
>    American Journal of Sociology 89: 324-349.
> */
> #delimit ;
> label define occs 1 "Farm"          /* occupations */
>                   2 "Operatives"    /* service, and laborers */
>                   3 "Craftsmen"     /* and kindred workers */
>                   4 "Sales"         /* and clerical" */
>                   5 "Professional"; /* technical, and mangerial"*/
> #delimit cr
> label define race 1 "black" 0 "non-black"
>
> infile byte(occ focc educ black) using logan.dat
> label variable occ "occupation"
> label variable focc "father's occupation at age 16"
> label variable educ "education in years"
> label variable black "race"
> label values occ occs
> label values focc occs
> label values black race
>
> summarize
>
> tab focc
> tab occ
> tab focc occ
> tab black
> tab occ black
> tab occ black, col
> tab focc occ, row col
>
> regress occ educ black
> mlogit occ educ black, base(1)
> ologit occ educ black
> /* Sample data used in Logan (1983: 332-333)
>    Data are from the 1972-1978 merged Genderal Social Surveys (GSS)
>    of the National Opinion Research Center (NORC). The selection is
>    restricted to males, aged 25 to 34 at the time of the interview,
> who
>    were in the labour force at the time of interview, and who had
>    non-missing values for respondent's education and occupation and
> for
>    father's occupation and education. N=838.
>
>    Logan, J. (1983). "A multivariate model for mobility tables."
>    American Journal of Sociology 89: 324-349.
> */
> #delimit ;
> label define occs 1 "Farm"          /* occupations */
>                   2 "Operatives"    /* service, and laborers */
>                   3 "Craftsmen"     /* and kindred workers */
>                   4 "Sales"         /* and clerical" */
>                   5 "Professional"; /* technical, and mangerial"*/
> #delimit cr
> label define race 1 "black" 0 "non-black"
>
> infile byte(occ focc educ black) using logan.dat
> label variable occ "occupation"
> label variable focc "father's occupation at age 16"
> label variable educ "education in years"
> label variable black "race"
> label values occ occs
> label values focc occs
> label values black race
>
> summarize
>
> tab focc
> tab occ
> tab focc occ
> tab black
> tab occ black
> tab occ black, col
> tab focc occ, row col
>
> regress occ educ black
> mlogit occ educ black, base(1)
> ologit occ educ black
> /* Sample data used in Logan (1983: 332-333)
>    Data are from the 1972-1978 merged Genderal Social Surveys (GSS)
>    of the National Opinion Research Center (NORC). The selection is
>    restricted to males, aged 25 to 34 at the time of the interview,
> who
>    were in the labour force at the time of interview, and who had
>    non-missing values for respondent's education and occupation and
> for
>    father's occupation and education. N=838.
>
>    Logan, J. (1983). "A multivariate model for mobility tables."
>    American Journal of Sociology 89: 324-349.
> */
> #delimit ;
> label define occs 1 "Farm"          /* occupations */
>                   2 "Operatives"    /* service, and laborers */
>                   3 "Craftsmen"     /* and kindred workers */
>                   4 "Sales"         /* and clerical" */
>                   5 "Professional"; /* technical, and mangerial"*/
> #delimit cr
> label define race 1 "black" 0 "non-black"
>
> infile byte(occ focc educ black) using logan.dat
> label variable occ "occupation"
> label variable focc "father's occupation at age 16"
> label variable educ "education in years"
> label variable black "race"
> label values occ occs
> label values focc occs
> label values black race
>
> summarize
>
> tab focc
> tab occ
> tab focc occ
> tab black
> tab occ black
> tab occ black, col
> tab focc occ, row col
>
> regress occ educ black
> mlogit occ educ black, base(1)
> ologit occ educ black
> --------------------------------------------------------------------
>
> --- sampjob.R -------------------------------------------------------
> mytab <- function (x,y) {
> 	prop.table(table(x,y),2)*100
> }
>
> logan <- read.table("logan.dat")
> names(logan) <- c("occ", "focc", "educ", "black")
> attach(logan)
> occ.codes <- c("farm", "operatives", "craftsmen", "sales",
> "professional")
> occ <- factor(occ,label=occ.codes)
> focc <- factor(focc,label=occ.codes)
> black <- factor(black,label=c("non-black", "black"))
>
> summary(logan)
>
> table(focc)
> table(occ)
> dit<-mytab(focc,occ)
> dit
> table(black)
> mytab(occ,black)
>
> library(gregmisc)
> CrossTable(occ,black,prop.t=F,prop.r=F,fisher=FALSE)
> CrossTable(focc,occ,prop.t=F,fisher=FALSE)
> detach(package:gregmisc)
>
> fm <- lm(occ~ educ+black, data=logan)
> summary(fm)
> anova(fm)
>
> library(nnet)
> mnl.logit<-multinom(occ ~ educ+black, data=logan)
> summary(mnl.logit,correlation=FALSE)
> detach(package:nnet)
>
> library(MASS)
> or.logit <- polr(occ ~ educ+black)
> summary(or.logit)
> detach(package:MASS)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From sam.kemp2 at ntlworld.com  Mon Sep 27 12:20:45 2004
From: sam.kemp2 at ntlworld.com (Samuel Kemp)
Date: Mon, 27 Sep 2004 11:20:45 +0100
Subject: [R] greek letters for labelling axes
Message-ID: <4157E97D.9020307@ntlworld.com>

Hi,

Does anyone have any ideas on how to show greek letters on the x and y axes?

I have tried

 > plot(x,y, xlab=expression(delta), ylab=expression(gamma))

but the output on the x-axis is "d" and on the y-axis it is "g".

Any help will be very much appreciated.

Cheers,

Sam.



From tom_woody at swissinfo.org  Mon Sep 27 12:37:39 2004
From: tom_woody at swissinfo.org (=?ISO-8859-15?Q?Thomas_Sch=F6nhoff?=)
Date: Mon, 27 Sep 2004 12:37:39 +0200
Subject: [R] mtrace and debug
Message-ID: <4157ED73.2020003@swissinfo.org>

Hello,

pointed to the article "Debugging Without (Too Many) Tears" of Mark 
Bravington in Rnews Vol 3/3, December 2003 there is a package mvbutils 
mentioned.
So I started to install this package from within R

 > install.package(mvbutils)

I receive an error essage that this package is not found! Is due to a 
merge,removal or rename of this package?

When I try to follow this article by typing i.e:

mtrace

I receive also an error message, that function mtrace is not found?

Where do I find the above mentioned package?


thanks

Thomas

----------------------------------------------------------------------------------------
platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    1
minor    9.1
year     2004
month    06
day      21
language R



From patrick at burns-stat.com  Mon Sep 27 12:40:05 2004
From: patrick at burns-stat.com (Patrick Burns)
Date: Mon, 27 Sep 2004 11:40:05 +0100
Subject: [R] new release of POP Portfolio Construction Suite
Message-ID: <4157EE05.6030308@burns-stat.com>

Version 2 of POP Portfolio Construction Suite has just been released.
Note there is a license fee for this package.  The code runs in both R
and S-PLUS.

Version 2 is faster, better, smoother.

The functionality includes optimal portfolio selection, asset allocation,
and statistical factor models.  The most important functionality is probably
the generation of random portfolios -- sort of analogous to bootstrapping.

The POP User's Manual is available on the Burns Statistics website, and
is useful for those wanting to learn about portfolio construction as well as
those using the software.

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")



From msvika at mscc.huji.ac.il  Mon Sep 27 12:45:11 2004
From: msvika at mscc.huji.ac.il (Vicky Landsman)
Date: Mon, 27 Sep 2004 12:45:11 +0200
Subject: [R] Numerical two-dimensional integration 
Message-ID: <000c01c4a47f$105fc450$4101020a@Home3>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040927/ffb0647f/attachment.pl

From ligges at statistik.uni-dortmund.de  Mon Sep 27 12:51:39 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 27 Sep 2004 12:51:39 +0200
Subject: [R] greek letters for labelling axes
In-Reply-To: <4157E97D.9020307@ntlworld.com>
References: <4157E97D.9020307@ntlworld.com>
Message-ID: <4157F0BB.5010503@statistik.uni-dortmund.de>

Samuel Kemp wrote:

> Hi,
> 
> Does anyone have any ideas on how to show greek letters on the x and y 
> axes?
> 
> I have tried
> 
>  > plot(x,y, xlab=expression(delta), ylab=expression(gamma))
> 
> but the output on the x-axis is "d" and on the y-axis it is "g".

Which device, which version of R, which OS? Please specify a 
reproducible example. Works for me in all configurations I can imagine ...

Uwe Ligges



> Any help will be very much appreciated.
> 
> Cheers,
> 
> Sam.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Mon Sep 27 12:55:13 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 27 Sep 2004 12:55:13 +0200
Subject: [R] mtrace and debug
In-Reply-To: <4157ED73.2020003@swissinfo.org>
References: <4157ED73.2020003@swissinfo.org>
Message-ID: <4157F191.6060408@statistik.uni-dortmund.de>

Thomas Sch??nhoff wrote:

> Hello,
> 
> pointed to the article "Debugging Without (Too Many) Tears" of Mark 
> Bravington in Rnews Vol 3/3, December 2003 there is a package mvbutils 
> mentioned.
> So I started to install this package from within R
> 
>  > install.package(mvbutils)

You get the following error:
Error: couldn't find function "install.package"

after correcting the function name to
   install.packages(mvbutils)
you get the follwoing error:
Error in install.packages(mvbutils) : Object "mvbutils" not found

after correcting the package name to be character, it should work:
   install.packages("mvbutils")


Please read the error messages!!! No error message told you that the 
package is not available.


Uwe Ligges




> I receive an error essage that this package is not found! Is due to a 
> merge,removal or rename of this package?
> 
> When I try to follow this article by typing i.e:
> 
> mtrace
> 
> I receive also an error message, that function mtrace is not found?
> 
> Where do I find the above mentioned package?
> 
> 
> thanks
> 
> Thomas
> 
> ---------------------------------------------------------------------------------------- 
> 
> platform i386-pc-linux-gnu
> arch     i386
> os       linux-gnu
> system   i386, linux-gnu
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Mon Sep 27 12:57:28 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 27 Sep 2004 12:57:28 +0200
Subject: [R] Numerical two-dimensional integration
In-Reply-To: <000c01c4a47f$105fc450$4101020a@Home3>
References: <000c01c4a47f$105fc450$4101020a@Home3>
Message-ID: <4157F218.7010205@statistik.uni-dortmund.de>

Vicky Landsman wrote:

> Dear all,
> I need to compute (numerically) the two-dimensional integral: int(int f(x,y)dy)dx. 
> What is the more efficient(fast) way to do it? 
> Is adapt function appropriate for this problem?  

That's what adapt is designed for -- according to its help pages.
So it does not work for you, or why do you ask?

Uwe Ligges


> I will much appreciate your help and attention. 
> Vicky. 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From kahra at mpsgr.it  Mon Sep 27 13:00:47 2004
From: kahra at mpsgr.it (Kahra Hannu)
Date: Mon, 27 Sep 2004 13:00:47 +0200
Subject: [R] block statistics with POSIX classes
Message-ID: <C9FC71F7E9356F40AFE2ACC2099DE1471496C0@MAILSERVER-B.mpsgr.it>

In a private mail Petr noted that I had mixed POSIX with a time series class in a call to aggregate, that was the case. Petr's sugestion

usa <- diff(log(MXNA/XEU))
z <- aggregate(usa, list(annual=cut(dp,"year")), mean, na.rm=T)

also gives the result I was looking for. In my original code usa was a time series.

Thank you Gabor and Petr!

Hannu  

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Gabor Grothendieck
Sent: Thursday, September 23, 2004 7:04 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] block statistics with POSIX classes



Kahra Hannu <kahra <at> mpsgr.it> writes:

: 
: I have followed Gabor's instructions:
: 
: > aggregate(list(y=y), list(dp$year), mean)$y 			# 
returns NULL since y is a time series
: NULL
:  
: > aggregate(list(y=as.vector(y)), list(dp$year), mean)$y	# returns 
annual means
: [1]  0.0077656696  0.0224050294  0.0099991898  0.0240550925 -0.0084085867
: [6] -0.0170950194 -0.0355641251  0.0065873997  0.0008253111
: 
: > aggregate(list(y=y), list(dp$year), mean)			# returns the 
same as the previous one
:   Group.1      Series.1
: 1      96  0.0077656696
: 2      97  0.0224050294
: 3      98  0.0099991898
: 4      99  0.0240550925
: 5     100 -0.0084085867
: 6     101 -0.0170950194
: 7     102 -0.0355641251
: 8     103  0.0065873997
: 9     104  0.0008253111
: 
: Gabor's second suggestion returns different results:
: 
: > aggregate(ts(y, start=c(dp$year[1],dp$mon[1]+1), freq = 12), nfreq=1, mean)
: Time Series:
: Start = 96.33333 
: End = 103.3333 
: Frequency = 1 
:          Series 1
: [1,]  0.016120895
: [2,]  0.024257131
: [3,]  0.007526997
: [4,]  0.017466118
: [5,] -0.016024846
: [6,] -0.017145159
: [7,] -0.036047765
: [8,]  0.014198501
: 
: > aggregate(y, 1, mean) 		# verifies the result above
: Time Series:
: Start = 1996.333 
: End = 2003.333 
: Frequency = 1 
:          Series 1
: [1,]  0.016120895
: [2,]  0.024257131
: [3,]  0.007526997
: [4,]  0.017466118
: [5,] -0.016024846
: [6,] -0.017145159
: [7,] -0.036047765
: [8,]  0.014198501
: 
: The data is from 1996:5 to 2004:8. The difference of the results must depend 
on the fact that the beginning of
: the data is not January and the end is not December? The first two solutions 
give nine annual means while the
: last two give only eight means. The block size in the last two must be 12 
months, as is said in ?aggregate,
: instead of a calender year that I am looking for. Gabor's first suggestion 
solved my problem.

Yes, that seems to be the case.  Using length instead of 
mean we find that the aggregate.data.frame example used calendar 
years as the basis of aggregation whereas the aggregate.ts example
used successive 12 month periods starting from the first month discarding
the 4 points at the end which do not fill out a full year.

R> set.seed(1)
R> dp <- as.POSIXlt(seq(from=as.Date("1996-5-1"), to=as.Date("2004-8-1"), 
+          by="month"))
R> y <- rnorm(length(dp$year))

R> aggregate(list(y=y), list(dp$year), length)$y
[1]  8 12 12 12 12 12 12 12  8

R> aggregate(ts(y, start=c(dp$year[1],dp$mon[1]+1), freq = 12), nfreq=1, 
length)
Time Series:
Start = 96.33333 
End = 103.3333 
Frequency = 1 
[1] 12 12 12 12 12 12 12 12

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From matthieu.cornec at insee.fr  Mon Sep 27 13:44:31 2004
From: matthieu.cornec at insee.fr (Cornec Matthieu)
Date: Mon, 27 Sep 2004 13:44:31 +0200
Subject: [R] Arguments for functions
Message-ID: <4BFA0FD18E9ED311AC040000F6AF04890595E28D@S54X01>

hello,

Could you help me to find out how to give arguments to a function step  by
step?
In others words, if the output depends on inputs given by the user step by
step, how R can handle this? 
Thanks in advance,

Matthieu Cornec



From bxc at steno.dk  Mon Sep 27 13:57:12 2004
From: bxc at steno.dk (BXC (Bendix Carstensen))
Date: Mon, 27 Sep 2004 13:57:12 +0200
Subject: [R] Funny behaviour of coef() and vcov() if X is singular
Message-ID: <0ABD88905D18E347874E0FB71C0B29E90237C86C@exdkba022.novo.dk>

coef() and vcov() have different dimensions if a model contains alised
parameters
as the following example illustrates.

A search on "alised" gave noting as far as I could see.

Is this a known bug?

Bendix C
----------------------
Bendix Carstensen
Senior Statistician
Steno Diabetes Center
Niels Steensens Vej 2
DK-2820 Gentofte
Denmark
tel: +45 44 43 87 38
mob: +45 30 75 87 38
fax: +45 44 43 07 06
bxc at steno.dk
www.biostat.ku.dk/~bxc
----------------------

> x <- rnorm(100)
> y <- rnorm(100)
> z <- rnorm(100)
> summary( mu <- lm( y ~x + I(x-z)+z ) )

Call:
lm(formula = y ~ x + I(x - z) + z)

Residuals:
      Min        1Q    Median        3Q       Max 
-1.917325 -0.633091 -0.003363  0.561464  2.473183 

Coefficients: (1 not defined because of singularities)
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.07806    0.09118   0.856   0.3940
x           -0.27373    0.11415  -2.398   0.0184
I(x - z)     0.08617    0.08524   1.011   0.3146
z                 NA         NA      NA       NA

Residual standard error: 0.9061 on 97 degrees of freedom
Multiple R-Squared: 0.05813,    Adjusted R-squared: 0.03871 
F-statistic: 2.993 on 2 and 97 DF,  p-value: 0.05476 

> coef( mu )
(Intercept)           x    I(x - z)           z 
 0.07805884 -0.27373500  0.08617152          NA 
> vcov( mu )
              (Intercept)             x      I(x - z)
(Intercept)  8.313341e-03 -5.702109e-05  0.0007248947
x           -5.702109e-05  1.303028e-02 -0.0057006507
I(x - z)     7.248947e-04 -5.700651e-03  0.0072657814
> length( coef( mu ) )
[1] 4
> dim( vcov( mu ) )
[1] 3 3
> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    1              
minor    9.1            
year     2004           
month    06             
day      21             
language R



From ramasamy at cancer.org.uk  Mon Sep 27 14:04:56 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 27 Sep 2004 13:04:56 +0100
Subject: [R] Arguments for functions
In-Reply-To: <4BFA0FD18E9ED311AC040000F6AF04890595E28D@S54X01>
References: <4BFA0FD18E9ED311AC040000F6AF04890595E28D@S54X01>
Message-ID: <1096286695.3046.3.camel@ndmpc126.ihs.ox.ac.uk>

See "Writing your own functions" (section 10 or page 47) or the
"Introduction to R" (http://cran.r-project.org/doc/manuals/R-intro.pdf).

On Mon, 2004-09-27 at 12:44, Cornec Matthieu wrote:
> hello,
> 
> Could you help me to find out how to give arguments to a function step  by
> step?
> In others words, if the output depends on inputs given by the user step by
> step, how R can handle this? 
> Thanks in advance,
> 
> Matthieu Cornec
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Matthias.Kohl at uni-bayreuth.de  Mon Sep 27 15:28:04 2004
From: Matthias.Kohl at uni-bayreuth.de (Matthias Kohl)
Date: Mon, 27 Sep 2004 14:28:04 +0100
Subject: [R] Numerical two-dimensional integration
In-Reply-To: <4157F218.7010205@statistik.uni-dortmund.de>
References: <000c01c4a47f$105fc450$4101020a@Home3>
	<4157F218.7010205@statistik.uni-dortmund.de>
Message-ID: <41581564.10506@uni-bayreuth.de>

a survey is given in:

http://www.jstatsoft.org/v08/i13/article.pdf

Matthias Kohl

Uwe Ligges schrieb:

> Vicky Landsman wrote:
>
>> Dear all,
>> I need to compute (numerically) the two-dimensional integral: int(int 
>> f(x,y)dy)dx. What is the more efficient(fast) way to do it? Is adapt 
>> function appropriate for this problem?  
>
>
> That's what adapt is designed for -- according to its help pages.
> So it does not work for you, or why do you ask?
>
> Uwe Ligges
>
>
>> I will much appreciate your help and attention. Vicky. 
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Mon Sep 27 14:45:56 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 27 Sep 2004 13:45:56 +0100 (BST)
Subject: [R] Funny behaviour of coef() and vcov() if X is singular
In-Reply-To: <0ABD88905D18E347874E0FB71C0B29E90237C86C@exdkba022.novo.dk>
Message-ID: <Pine.LNX.4.44.0409271343240.30264-100000@gannet.stats>

Yes, and that's intentional.  You don't want non-information on
unestimated parameters, do you?  (What would you do with it?)

BTW, you forgot the very important caveat `the "lm" methods of coef() and
vcov()'.

On Mon, 27 Sep 2004, BXC (Bendix Carstensen) wrote:

> coef() and vcov() have different dimensions if a model contains alised
> parameters
> as the following example illustrates.
> 
> A search on "alised" gave noting as far as I could see.
> 
> Is this a known bug?
> 
> Bendix C
> ----------------------
> Bendix Carstensen
> Senior Statistician
> Steno Diabetes Center
> Niels Steensens Vej 2
> DK-2820 Gentofte
> Denmark
> tel: +45 44 43 87 38
> mob: +45 30 75 87 38
> fax: +45 44 43 07 06
> bxc at steno.dk
> www.biostat.ku.dk/~bxc
> ----------------------
> 
> > x <- rnorm(100)
> > y <- rnorm(100)
> > z <- rnorm(100)
> > summary( mu <- lm( y ~x + I(x-z)+z ) )
> 
> Call:
> lm(formula = y ~ x + I(x - z) + z)
> 
> Residuals:
>       Min        1Q    Median        3Q       Max 
> -1.917325 -0.633091 -0.003363  0.561464  2.473183 
> 
> Coefficients: (1 not defined because of singularities)
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)  0.07806    0.09118   0.856   0.3940
> x           -0.27373    0.11415  -2.398   0.0184
> I(x - z)     0.08617    0.08524   1.011   0.3146
> z                 NA         NA      NA       NA
> 
> Residual standard error: 0.9061 on 97 degrees of freedom
> Multiple R-Squared: 0.05813,    Adjusted R-squared: 0.03871 
> F-statistic: 2.993 on 2 and 97 DF,  p-value: 0.05476 
> 
> > coef( mu )
> (Intercept)           x    I(x - z)           z 
>  0.07805884 -0.27373500  0.08617152          NA 
> > vcov( mu )
>               (Intercept)             x      I(x - z)
> (Intercept)  8.313341e-03 -5.702109e-05  0.0007248947
> x           -5.702109e-05  1.303028e-02 -0.0057006507
> I(x - z)     7.248947e-04 -5.700651e-03  0.0072657814
> > length( coef( mu ) )
> [1] 4
> > dim( vcov( mu ) )
> [1] 3 3
> > version
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    1              
> minor    9.1            
> year     2004           
> month    06             
> day      21             
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Mon Sep 27 15:49:11 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 27 Sep 2004 06:49:11 -0700
Subject: [R] Arguments for functions
In-Reply-To: <1096286695.3046.3.camel@ndmpc126.ihs.ox.ac.uk>
References: <4BFA0FD18E9ED311AC040000F6AF04890595E28D@S54X01>
	<1096286695.3046.3.camel@ndmpc126.ihs.ox.ac.uk>
Message-ID: <41581A57.9000306@pdf.com>

    If I understood the question correctly, you may also want to include 
"scan" in the function, e.g.: 

 > read2 <- function(){
+   cat("Step1 input=")
+   a <- scan()
+   cat("Step2 input=")
+   b <- scan()
+   list(Step1.input=a, Step2.input=b)
+ }
 > read2()
Step1 input=1: 2
2: 3
3:
Read 2 items
Step2 input=1: "a"
1: "b"
Error in scan() : "scan" expected a real, got ""a""
 > read2()
Step1 input=1: 1
2: 2
3: 3
4:
Read 3 items
Step2 input=1: 2
2: 3
3: 4
4:
Read 3 items
$Step1.input
[1] 1 2 3

$Step2.input
[1] 2 3 4

      hope this helps.  spencer graves

Adaikalavan Ramasamy wrote:

>See "Writing your own functions" (section 10 or page 47) or the
>"Introduction to R" (http://cran.r-project.org/doc/manuals/R-intro.pdf).
>
>On Mon, 2004-09-27 at 12:44, Cornec Matthieu wrote:
>  
>
>>hello,
>>
>>Could you help me to find out how to give arguments to a function step  by
>>step?
>>In others words, if the output depends on inputs given by the user step by
>>step, how R can handle this? 
>>Thanks in advance,
>>
>>Matthieu Cornec
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>

-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From smalladi at lexgen.com  Mon Sep 27 16:17:38 2004
From: smalladi at lexgen.com (Malladi, Sukhaswami)
Date: Mon, 27 Sep 2004 09:17:38 -0500
Subject: [R] Enright/Chi-square periodogram / periodicity
Message-ID: <2D42B4DF9845F74E9318DF707D5956D901852691@wdexch02.lexgen.com>

I am trying to compute the periodicity of a time series.
I would like to know which function in R does it. 

Also, how do I plot a Enright / Chi-square periodogram using R ?
( Enright, J.T., 1965, Journal of Theoret. Biol. 8,426-468) 

Greatly appreciate your help.

Thanks in advance,
Sukhaswami Malladi




*************************************************************************** 
 The contents of this communication are intended only for th...{{dropped}}



From florence.combes at paris7.jussieu.fr  Mon Sep 27 16:17:14 2004
From: florence.combes at paris7.jussieu.fr (Florence Combes)
Date: Mon, 27 Sep 2004 16:17:14 +0200
Subject: [R] KS test
Message-ID: <6.0.0.22.2.20040927160428.01d03c48@paris7.jussieu.fr>

Dear all,

I have a question about the ks.test() function, in order to perform a 
Kolmogorov-Smirnov test.

I think that my question is very simple for many of you, but I cannot find 
an answer right now...

I have a sample, and I want to test if its distribution is normal. So I 
would like to perform a one sample KS test but I cannot find the "y" 
argument representing  the "character string naming a distribution 
function" according to the ?ks.test help page.
It is impossible forme to have a list of these character strings naming a 
distribution function.

I think it is "pnorm" for a normal distribution, bu I would like to be sure...

Thanks a lot for your help,

Florence.
PS: I know that the KS test is not the best test for normality, I also 
performed the Shapiro-Wilk test.



From danbebber at forestecology.co.uk  Mon Sep 27 16:46:11 2004
From: danbebber at forestecology.co.uk (Dan Bebber)
Date: Mon, 27 Sep 2004 15:46:11 +0100
Subject: [R] cannot assign dimnames
In-Reply-To: <200409211009.i8LA47xv019317@hypatia.math.ethz.ch>
Message-ID: <000001c4a4a0$bb777fb0$7d2501a3@plants.ox.ac.uk>

Dear list,

If anyone knows how to assign dimnames to matrices or arrays I would be most
grateful for help. I've tried various permutations of likely-looking code
but get error messages every time. I could find no example in the
documentation.

Many thanks,
Dan Bebber

Department of Plant Sciences
University of Oxford
South Parks Road
Oxford OX1 3RB
UK
Tel. 01865 275000



From vito_ricci at yahoo.com  Mon Sep 27 16:47:14 2004
From: vito_ricci at yahoo.com (Vito Ricci)
Date: Mon, 27 Sep 2004 16:47:14 +0200 (CEST)
Subject: [R] KS test
Message-ID: <20040927144714.30228.qmail@web41214.mail.yahoo.com>

Dear Florence,

you should specify parameters of normal distribution
(mean and sd) see this example.

 z<-rnorm(100,2,10)
ks.test(z,pnorm,2,10)

One-sample Kolmogorov-Smirnov test

data:  z 
D = 0.0508, p-value = 0.9585
alternative hypothesis: two.sided 


best
Vito
You wrote:

Dear all,

I have a question about the ks.test() function, in
order to perform a 
Kolmogorov-Smirnov test.

I think that my question is very simple for many of
you, but I cannot find 
an answer right now...

I have a sample, and I want to test if its
distribution is normal. So I 
would like to perform a one sample KS test but I
cannot find the "y" 
argument representing  the "character string naming a
distribution 
function" according to the ?ks.test help page.
It is impossible forme to have a list of these
character strings naming a 
distribution function.

I think it is "pnorm" for a normal distribution, bu I
would like to be sure...

Thanks a lot for your help,

Florence.
PS: I know that the KS test is not the best test for
normality, I also 
performed the Shapiro-Wilk test.

Dear Florence,

you should specify parameters of normal distribution
(mean and sd) see this example.


 x<-rnorm(100)
> ks.test(x,pnorm,0,1)

One-sample Kolmogorov-Smirnov test

data:  x 
D = 0.164, p-value = 0.009235
alternative hypothesis: two.sided 


=====
Diventare costruttori di soluzioni

"The business of the statistician is to catalyze 
the scientific learning process."  
George E. P. Box


Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml


		
___________________________________

http://it.seriea.fantasysports.yahoo.com/



From andy_liaw at merck.com  Mon Sep 27 16:54:34 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 27 Sep 2004 10:54:34 -0400
Subject: [R] cannot assign dimnames
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8441@usrymx25.merck.com>

I believe the posting guide ask you to show an example of what you tried,
just so people have a better idea of where you went off track.

I thought ?dimnames is rather explicit on this:

[...]
Usage:

     dimnames(x)
     dimnames(x) <- value

Arguments:

       x: an R object, for example a matrix, array or data frame.

   value: a possible value for 'dimnames(x)': see "Value".

[...]

Value:

     The dimnames of a matrix or array can be 'NULL' or a list of the
     same length as 'dim(x)'.  If a list, its components are either
     'NULL' or a character vector the length of the appropriate
     dimension of 'x'.

Thus, something like:

> x <- matrix(1:12, 3, 4)
> x
     [,1] [,2] [,3] [,4]
[1,]    1    4    7   10
[2,]    2    5    8   11
[3,]    3    6    9   12
> dimnames(x) <- list(letters[1:nrow(x)], LETTERS[1:ncol(x)])
> x
  A B C  D
a 1 4 7 10
b 2 5 8 11
c 3 6 9 12

Andy

> From: Dan Bebber
> 
> Dear list,
> 
> If anyone knows how to assign dimnames to matrices or arrays 
> I would be most
> grateful for help. I've tried various permutations of 
> likely-looking code
> but get error messages every time. I could find no example in the
> documentation.
> 
> Many thanks,
> Dan Bebber
> 
> Department of Plant Sciences
> University of Oxford
> South Parks Road
> Oxford OX1 3RB
> UK
> Tel. 01865 275000
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From rpeng at jhsph.edu  Mon Sep 27 16:56:52 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 27 Sep 2004 10:56:52 -0400
Subject: [R] cannot assign dimnames
In-Reply-To: <000001c4a4a0$bb777fb0$7d2501a3@plants.ox.ac.uk>
References: <000001c4a4a0$bb777fb0$7d2501a3@plants.ox.ac.uk>
Message-ID: <41582A34.3040804@jhsph.edu>

Take a look at

?"dimnames<-"

Note the quotes.

-roger

Dan Bebber wrote:
> Dear list,
> 
> If anyone knows how to assign dimnames to matrices or arrays I would be most
> grateful for help. I've tried various permutations of likely-looking code
> but get error messages every time. I could find no example in the
> documentation.
> 
> Many thanks,
> Dan Bebber
> 
> Department of Plant Sciences
> University of Oxford
> South Parks Road
> Oxford OX1 3RB
> UK
> Tel. 01865 275000
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dimitris.rizopoulos at med.kuleuven.ac.be  Mon Sep 27 16:57:17 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Mon, 27 Sep 2004 16:57:17 +0200
Subject: [R] cannot assign dimnames
References: <000001c4a4a0$bb777fb0$7d2501a3@plants.ox.ac.uk>
Message-ID: <003401c4a4a2$482cf6a0$b2133a86@www.domain>

Hi Dan,

try this:

?dimnames
mat <- matrix(rnorm(10*3), 10, 3)
dimnames(mat) <- list(letters[1:10], c("X", "Y", "Z"))
mat

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Dan Bebber" <danbebber at forestecology.co.uk>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, September 27, 2004 4:46 PM
Subject: [R] cannot assign dimnames


> Dear list,
>
> If anyone knows how to assign dimnames to matrices or arrays I would 
> be most
> grateful for help. I've tried various permutations of likely-looking 
> code
> but get error messages every time. I could find no example in the
> documentation.
>
> Many thanks,
> Dan Bebber
>
> Department of Plant Sciences
> University of Oxford
> South Parks Road
> Oxford OX1 3RB
> UK
> Tel. 01865 275000
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From jgoebel at diw.de  Mon Sep 27 17:08:03 2004
From: jgoebel at diw.de (Jan Goebel)
Date: Mon, 27 Sep 2004 17:08:03 +0200
Subject: [R] cannot assign dimnames
In-Reply-To: <000001c4a4a0$bb777fb0$7d2501a3@plants.ox.ac.uk>
References: <200409211009.i8LA47xv019317@hypatia.math.ethz.ch>
	<000001c4a4a0$bb777fb0$7d2501a3@plants.ox.ac.uk>
Message-ID: <20040927150803.GA14071@diw138134.diw-berlin.de>

Dear Dan,

a simple example:

> mat<-matrix(1:6, ncol=3)
> mat
     [,1] [,2] [,3]
[1,]    1    3    5
[2,]    2    4    6
> dimnames(mat)<-list(1:2, 1:3)
> mat
  1 2 3
1 1 3 5
2 2 4 6
> dimnames(mat)<-list(1:2, letters[1:3])
> mat
  a b c
1 1 3 5
2 2 4 6
> dimnames(mat)
[[1]]
[1] "1" "2"

[[2]]
[1] "a" "b" "c"

dimnames need a list!

HIH

jan


On Mon, 27 Sep 2004, Dan Bebber wrote:

> Dear list,
> 
> If anyone knows how to assign dimnames to matrices or arrays I would be most
> grateful for help. I've tried various permutations of likely-looking code
> but get error messages every time. I could find no example in the
> documentation.
> 
> Many thanks,
> Dan Bebber
> 
> Department of Plant Sciences
> University of Oxford
> South Parks Road
> Oxford OX1 3RB
> UK
> Tel. 01865 275000
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
+-----------------------------------------
 Jan Goebel 
 j g o e b e l @ d i w . d e

 DIW Berlin 
 German Socio-Economic Panel Study (GSOEP) 
 K??nigin-Luise-Str. 5
 D-14195 Berlin -- Germany --
 phone: 49 30 89789-377
+-----------------------------------------



From danbebber at forestecology.co.uk  Mon Sep 27 17:16:48 2004
From: danbebber at forestecology.co.uk (Dan Bebber)
Date: Mon, 27 Sep 2004 16:16:48 +0100
Subject: [R] Re: cannot assign dimnames
In-Reply-To: <200409211009.i8LA47xv019317@hypatia.math.ethz.ch>
Message-ID: <000701c4a4a5$023bf760$7d2501a3@plants.ox.ac.uk>

Dear list,

Please ignore my earlier message on this topic. I was under the mistaken
impression that dimnames() named the dimensions themselves, rather than the
indices within the dimensions.

Many thanks,
Dan Bebber



From ggrothendieck at myway.com  Mon Sep 27 17:39:09 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 27 Sep 2004 15:39:09 +0000 (UTC)
Subject: [R] cannot assign dimnames
References: <200409211009.i8LA47xv019317@hypatia.math.ethz.ch>
	<000001c4a4a0$bb777fb0$7d2501a3@plants.ox.ac.uk>
Message-ID: <loom.20040927T171113-402@post.gmane.org>

Dan Bebber <danbebber <at> forestecology.co.uk> writes:


: If anyone knows how to assign dimnames to matrices or arrays I would be most
: grateful for help. I've tried various permutations of likely-looking code
: but get error messages every time. I could find no example in the
: documentation.



Here are 4 ways of assigning dimnames to a matrix.  

# matrix - 1
mat1 <- matrix(1:12,4,3, dimnames = list(letters[1:4], LETTERS[1:3]))

# matrix - 2
mat2 <- matrix(1:12,4,3) 
dimnames(mat2) <- list(letters[1:4], LETTERS[1:3])

# matrix - 3
mat3 <- matrix(1:12,4,3) 
attr(mat3, "dimnames") <- list(letters[1:4], LETTERS[1:3])

# matrix - 4
mat4 <- matrix(1:12,4,3)
rownames(mat4) <- letters[1:4]
colnames(mat4) <- LETTERS[1:3]


# For arrays its similar, e.g. here is #1 redone for an array:
arr <- array(1:24, c(2,3,4),dimnames=list(letters[1:2],LETTERS[1:3],month.abb
[1:4]))


# For a data frame the various forms above also work except that
# (a) this form is also available 
DF <- data.frame(A = 1:4, B = 5:8, C = 9:12, row.names = letters[1:4])

# and (b) for data frames one must use row.names in place of 
# rownames though colnames still works as does names (which works 
# like colnames)



From calenge at biomserv.univ-lyon1.fr  Fri Sep 24 17:03:09 2004
From: calenge at biomserv.univ-lyon1.fr (=?iso-8859-1?Q?Cl=E9ment?= Calenge)
Date: Fri, 24 Sep 2004 17:03:09 +0200
Subject: [R] [R-pkgs] New package: adehabitat
Message-ID: <5.1.0.14.0.20040923151115.02a77108@biomserv.univ-lyon1.fr>

Dear all,

I have just uploaded a package to CRAN a new package called 'adehabitat'.
This package is intended for ecologists who want to analyse the use of 
space by animals.
Many functions currently used in this field are available to
highlight habitat selection by animals (selection ratios, ENFA, habitat 
suitability maps
with the algorithm DOMAIN or Resource Selection Functions)
or to describe the movements and area used in radio-tracking studies 
(kernel or
minimum convex polygon home range, computation of travel speed and turning 
angles).
ASCII raster maps exported from Arcview can also be imported, and basic GIS 
operations
are available (e.g. spatial join, computation of buffers).

The package comes with a pdf documentation file which
contains an overview of the main classes of maps available
in the package.

Questions, comments and suggestions are greatly appreciated.

Here is the description file of the package:

Package: adehabitat
Version: 1.1
Date: 2004/09/15
Title: Analysis of habitat selection by animals
Author: Cl??ment Calenge, contributions from Mathieu Basille
Maintainer: Cl??ment Calenge <calenge at biomserv.univ-lyon1.fr>
Depends: R (>= 1.8.0), ade4
Description: A collection of tools for the analysis of habitat selection by 
animals
License: GPL version 2 or newer

Happy testing


Cl??ment Calenge

======================================
UMR CNRS 5558 - Equipe "Ecologie Statistique"
Laboratoire de Biom??trie et Biologie Evolutive
Universit?? Claude Bernard Lyon 1
43, Boulevard du 11 novembre 1918
69622 Villeurbanne Cedex
FRANCE
tel. (+33) 04.72.43.27.57
fax. (+33) 04.72.43.13.88

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From juerg.schmidli at env.ethz.ch  Mon Sep 27 14:33:44 2004
From: juerg.schmidli at env.ethz.ch (Schmidli Juerg)
Date: Mon, 27 Sep 2004 14:33:44 +0200
Subject: [R] [R-pkgs] New package: ncvar
Message-ID: <415808A8.9090006@env.ethz.ch>

Dear all,

I would like to announce the availability of a new package on CRAN:

ncvar: High-level R Interface to NetCDF Datasets

This package provides a high-level R interface to Unidata's NetCDF
data files. Using this package netCDF datasets, and all their
associated metadata, can be read and written in one go. It is also
easy to create datasets including lots of metadata.
This package supports both the CF and default NetCDF metadata conventions.
It requires the low-level NetCDF package RNetCDF by Pavel Michna.

Feedback is greatly appreciated.

Juerg

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From barbaro at uni-mainz.de  Mon Sep 27 18:03:23 2004
From: barbaro at uni-mainz.de (Salvatore Barbaro)
Date: Mon, 27 Sep 2004 18:03:23 +0200
Subject: [R] Bootstrapping with weighted data sample
Message-ID: <415839CB.90404@uni-mainz.de>

Hi all!

Consider a sample, x, like this:
#
x<- matrix(rbind(4,8,0,2, 25,30,5,32), ncol=2)
#

Weight  Income
4    25
8    30
0    5
2    32

Here the "Weight" assigns the weight of each observation. It is easy to 
compute any measure of inequality, for instance

library(ineq)
Gini(rep(x[,2], x[,1]))

However, what happens is that the original sample is extended (from four 
observations to 14 (sum(x[,1]) instead of length(x[,1])). The problem I 
have arises when I try to compute a confidence interval surrounding this 
Gini coefficient via bootstrap, because the bootstrap-sample should of 
course not exceed the number of observations.

Has anybody an idea or experience with such a problem.

Thanks in advance.


P.S. I am using library(bootstrap) with bcanon() to obtain boostrap 
confidence intervals.

s.



From nderby at u.washington.edu  Mon Sep 27 18:02:39 2004
From: nderby at u.washington.edu (Nathaniel B. Derby)
Date: Mon, 27 Sep 2004 09:02:39 -0700 (PDT)
Subject: [R] optim error in arima
Message-ID: <Pine.LNX.4.43.0409270902390.21744@hymn15.u.washington.edu>

Hello,

I'm fitting a series of ARIMA models to a data set to compare fits.  After taking the logs of the data and then differencing them to induce stationarity, I execute

arima( y, order=c( p, 0, q ), seasonal=list( order=c( P, 0, Q ), period=7 ) )

for various values of p, q, P and Q.  For one set of these values, I get

Error in optim(init[mask], armafn, method = "BFGS", hessian = TRUE ... :
         non-finite finite-difference value [0]

which tells me that when computing derivatives of the objective function (armafn) by finite differencing, one of the values is NA, +Inf or -Inf.  Any ideas?  I would like to print some values of armafn, but how do I get that from my data set, and what would I look for?


Thanks,

Nate



From flom at ndri.org  Mon Sep 27 18:14:18 2004
From: flom at ndri.org (Peter Flom)
Date: Mon, 27 Sep 2004 12:14:18 -0400
Subject: [R] Getting code for functions
Message-ID: <s1580440.075@MAIL.NDRI.ORG>

Hello

Pardon for the elementary question, I did try searching the archives
with various terms, but to no avail.  I am using R1.9.1 on a windows
machine

One of the great advantages of R (to me, anyway) is being able to see
the code for a function , e.g. by typing sd one sees the code for
getting a standard deviation.

However, for many functions this only provides info. including
UseMethod, eg. typing mosaicplot yields

function (x, ...) 
UseMethod("mosaicplot")
<environment: namespace:graphics>


How can I see the code for such functions?



Thanks in advance as always

Peter

Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)



From bates at stat.wisc.edu  Mon Sep 27 18:28:35 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 27 Sep 2004 11:28:35 -0500
Subject: [R] Getting code for functions
In-Reply-To: <s1580440.075@MAIL.NDRI.ORG>
References: <s1580440.075@MAIL.NDRI.ORG>
Message-ID: <41583FB3.9070805@stat.wisc.edu>

Peter Flom wrote:
> Hello
> 
> Pardon for the elementary question, I did try searching the archives
> with various terms, but to no avail.  I am using R1.9.1 on a windows
> machine
> 
> One of the great advantages of R (to me, anyway) is being able to see
> the code for a function , e.g. by typing sd one sees the code for
> getting a standard deviation.
> 
> However, for many functions this only provides info. including
> UseMethod, eg. typing mosaicplot yields
> 
> function (x, ...) 
> UseMethod("mosaicplot")
> <environment: namespace:graphics>
> 
> 
> How can I see the code for such functions?

Any function whose body contains a call to UseMethod is an S3 generic 
function.  To see all the possible methods for the function, use

methods("mosaicplot")

The default method will be called mosaicplot.default and that's probably 
the one you want to examine.



From sundar.dorai-raj at PDF.COM  Mon Sep 27 18:31:09 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Mon, 27 Sep 2004 09:31:09 -0700
Subject: [R] Getting code for functions
In-Reply-To: <s1580440.075@MAIL.NDRI.ORG>
References: <s1580440.075@MAIL.NDRI.ORG>
Message-ID: <4158404D.2040401@pdf.com>



Peter Flom wrote:

> Hello
> 
> Pardon for the elementary question, I did try searching the archives
> with various terms, but to no avail.  I am using R1.9.1 on a windows
> machine
> 
> One of the great advantages of R (to me, anyway) is being able to see
> the code for a function , e.g. by typing sd one sees the code for
> getting a standard deviation.
> 
> However, for many functions this only provides info. including
> UseMethod, eg. typing mosaicplot yields
> 
> function (x, ...) 
> UseMethod("mosaicplot")
> <environment: namespace:graphics>
> 
> 
> How can I see the code for such functions?
> 
> 

Peter,

UseMethod implies that mosaicplot is a generic method. You can see which 
classes allow mosaicplot by using ?methods:

 > methods("mosaicplot")
[1] mosaicplot.default* mosaicplot.formula*

     Non-visible functions are asterisked
 >

Now that last statement tells me that mosaicplot.default and 
mosaicplot.formula are not exported objects in the graphics namespace. 
To actually see the code for say the default mosaicplot, use 
?getAnywhere (or ?getS3method):

 > getAnywhere("mosaicplot.default")
A single object matching 'mosaicplot.default' was found
It was found in the following places
   registered S3 method for mosaicplot from namespace graphics
   namespace:graphics
with value

function (x, main = deparse(substitute(x)), sub = NULL, xlab = NULL,
     ylab = NULL, sort = NULL, off = NULL, dir = NULL, color = FALSE,
     shade = FALSE, margin = NULL, cex.axis = 0.66, las = par("las"),
     type = c("pearson", "deviance", "FT"), ...)
{
<snip>

}

You can learn about object-oriented programming in R from several 
places, but "Writing R Extensions" might be a good place to start.

--sundar



From cs377 at cam.ac.uk  Mon Sep 27 19:16:53 2004
From: cs377 at cam.ac.uk (Camille Szmaragd)
Date: 27 Sep 2004 18:16:53 +0100
Subject: [R] multinom object :way of plotting??
Message-ID: <Prayer.1.0.11.0409271816530.3144@hermes-1.csi.cam.ac.uk>

Dear all,

I'm fitting a multinom function to my dataset (multinom(outcome~age+K+D)) 
and I need to present my results on a poster. Does someone know a nice way 
of doing that? I think I saw in an archive that you cannot plot a 
multinom.object, is it true?

Thank you by advance for your help,

Cheers

Camille



From jeff.hamann at forestinformatics.com  Mon Sep 27 19:33:54 2004
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Mon, 27 Sep 2004 10:33:54 -0700
Subject: [R] Sweave with other fonts looks weird in pdf file
Message-ID: <013201c4a4b8$2c47d7a0$0b00a8c0@rodan>

I've become an avid user of Sweave and would like to able to use other fonts 
but when I added the following lines to a sweave file,

\renewcommand{\familydefault}{cmss}
\renewcommand{\rmdefault}{cmss}
\renewcommand{\sfdefault}{cmr}
\normalfont\normalsize

the pdf file generated with pdflatex the text for the sections that aren't 
generated by sweave (all the "non-chunks") have that "jaggedy" look when 
displayed in acrobat reader. When I print the document, the text looks fine. 
I'm using,

C:\st521\homework\hw1>pdflatex -version
MiKTeX-pdfTeX 2.3.1222 (1.10b) (MiKTeX 2.3)
Copyright (C) 1982 D. E. Knuth, (C) 1996-2002 Han The Thanh
TeX is a trademark of the American Mathematical Society.

and don't know if this is a sweave problem, MiKTeX problem, or something 
else.

Any ideas?

Thanks,
Jeff.


---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
541-754-1428
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From xiyanlon at gmail.com  Mon Sep 27 20:08:39 2004
From: xiyanlon at gmail.com (Xiyan Lon)
Date: Mon, 27 Sep 2004 20:08:39 +0200
Subject: [R] random discrete from the first tuple
Message-ID: <9a38bfc704092711087963ba19@mail.gmail.com>

Dear UseR
I have a dataset, for instance x1(A, B, C), x2(M,F), x3(X1,X2,X3,X4)
and x4(W,F,P). I want to make a small dataset with the random tuple. I
know package e1071 can handle a random discrete,

> library(e1071)
> x1 <- rdiscrete(6, c(2,2,2),   c("A","B","C"))
> x2 <- rdiscrete(6, c(3,3),     c("M","F"))
> x3 <- rdiscrete(6, c(2,2,1,1), c("X1","X2","X3","X4"))
> x4 <- rdiscrete(6, c(2,2,2),   c("W","F","P"))
> x  <- data.frame(cbind(x1,x2,x3,x4))
> x
  x1 x2 x3 x4
1  C  F X1  F
2  B  M X2  F
3  A  F X2  W
4  A  F X2  F
5  C  M X3  P
6  A  F X1  F
> 

but I want to make from the first tuple only one variable change to next tuple, 

C  F   X1  F
B  F   X1  F
A  F   X1  F
C  M  X1  F
B  M  X1  F
A  M  X1  F
C  F   X2  F
B  F   X2  F
A  F   X2  F
C  M  X2  F
B  M  X2  F
A  M  X2  F
.
.
.
Are there any package can handle this problem.

Xiyan Lon



From meles at free.fr  Mon Sep 27 20:06:52 2004
From: meles at free.fr (TRAMIER Blaise)
Date: Mon, 27 Sep 2004 20:06:52 +0200
Subject: [R] exponential correlation?
In-Reply-To: <4155D34E.905@pdf.com>
References: <20040924220825.GA19125@free.fr> <4155D34E.905@pdf.com>
Message-ID: <20040927180652.GA12911@free.fr>

On Sat, Sep 25, 2004 at 01:21:34PM -0700, Spencer Graves wrote:
>      The "nlme" package has "corExp" for estimating the nuggett effect 
> n and the range d for an exponential spatial correlation structure = n + 
> (1-n)*exp(-r/d), where r = distance between two observations.  See 
> library(nlme);  ?corExp, plus Pinheiro and Bates (2000) Mixed-Effects 
> Models for S and S-Plus (Springer). 
>      Is this what you want? 
> 
Thanks, for your answer.
I'm afraid I was'nt very clear on what I needed.

In fact, I have a set of paired quantitatve values. When I plot them,
it looks like if the values where following a 1/exp(x) equation. 

I would like to make a regression on this dataset to find the equation and
eventually find the x-value where the slope becomes more tough (I'm not
sure it's the appropriate word, I hope you'll understand anyway). In
fact I need to find the cutoff value.

I'm not sure of what method to use to achieve that.

Here is a subset of the dataset (Y are RR):
X     Y
82.0  1.00
72.0  2.45
53.0  3.88
45.0  8.76
71.0  1.00
60.0  2.00
40.0  4.76
20.0  12.05
8.0   11.62
87.0  1.00
78.0  1.03
65.0  1.21
41.0  2.78
75.0  1.00
67.5  1.53
45.0  1.81
30.0  3.76
75.0  1.00
62.0  1.90
42.0  4.10
17.0  5.40
86.0  1.00

so far I tried to do a non linear regression (nls):
> fm1<-nls(rrm ~ a/(exp(clr*c)),start=list(a=1,c=0.033),trace=T)
437.4397 :  1.000 0.033
120.0999 :  7.78174860 0.01381373
70.89977 :  13.15418549  0.03034625
67.18951 :  14.63044976  0.03070568
67.18892 :  14.62649511  0.03066069
67.18892 :  14.6270777  0.0306623
>summary(fm1)
Formula: rrm ~ a/(exp(clr * c))
Parameters:
   Estimate Std. Error t value Pr(>|t|)
a 14.627078   2.217950   6.595 2.01e-06 ***
c  0.030662   0.004876   6.288 3.87e-06 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Residual standard error: 1.833 on 20 degrees of freedom

Correlation of Parameter Estimates:
       a
c 0.8091

But I'm not sure I'm going the right way. If somebody could give me an
advice on the way to proceed, it would be great.

To find the cutoff value for x, should try to use the equation
obtained by the regression or should I use the residuals between
original data and the fitted values?

Best Regards

Blaise

PS: I hope I've been more explicit this time and that my english is
readable.



From Peter.Ruckdeschel at uni-bayreuth.de  Mon Sep 27 20:46:46 2004
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Mon, 27 Sep 2004 20:46:46 +0200
Subject: [R] [R-pkgs] new version of package "distr" available
Message-ID: <41586016.7060705@uni-bayreuth.de>

We would like to announce the availability on CRAN of a new version (1.4)
of our package "distr" .
-----------------------------------------------------------------------------------------
Changes from 1.3 to 1.4
-To avoid name collisions with short forms for TRUE and FALSE: classes T
 and F (T- and F-distributions) renamed to Td and Fd
-The package is now loaded as a binary => considerable speed gain
-Using subsititute, the bodies of the r,d,p,q-function-slots
 distributions show the parameter values with which they were 
 generated
-Convolutions and applications of the math group may now be traced in
 r-slot of a distribution object, compare
              r(sin(Norm()) + cos(Unif() * 3 + 2))
-Parameters of a distribution (mean, sd, etc) are now tested on length 1
  *we see the objects as implementations of univariate distributions, so
   vectors  make  no sense here; rather one could gather several objects 
   with possibly different parameters to a vector of distributions.
   Of course, the original R-functions rnorm etc remain unchanged and
   still allow for vector-valued parameters.
  *
-Classes "Parameter" , "Distribution" , "UnivariateDistribution" are no
 longer VIRTUAL
-"AbscontParameter" and "DiscreteParameter" are replaced by "Parameter"
-Type of slots d,p,q  and param is changed to "OptionalFunction" and
 "OptionalParameter" respectively

-----------------------------------------------------------------------------------------
Short Description of "distr":
"distr" is to provide a conceptual treatment of random variables
(r.v.'s) by means of S4--classes. A virtual mother class "Distribution" 
is introduced.
All distributions of the "base" package are implemented as subclasses of
either "AbscontDistribution" or "DiscreteDistribution".

Using these classes, we also provide (default) methods to automatically
generate the image distributions under unary mathematical operations as
well as a general convolution algorithm.

Additionally, we also provide classes for a standardized treatment of
simulations (also under contaminations) and evaluations of statistical
procedures on such simulations.
-----------------------------------------------------------------------------------------


DESCRIPTION:

Package: distr
Version: 1.4
Date: 2004/09/23
Title: distr
Authors: Peter Ruckdeschel <peter.ruckdeschel at uni-bayreuth.de>,
Matthias Kohl <matthias.kohl at uni-bayreuth.de>,
Thomas Stabla <statho3 at web.de>,
Florian Camphausen <fcampi at gmx.de>
Maintainer: Peter Ruckdeschel <peter.ruckdeschel at uni-bayreuth.de>
Description: S4 Classes for Distributions
Depends: R (>= 1.9.0),  (versions for <=1.8.x, on URL cited below),
                setRNG (>= 2004.3-1)
License: GPL version 2 or later
URL: http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR/

Reference:  
http://www.uni-bayreuth.de/departments/math/org/mathe7/DISTR/distr.pdf

We look forward to receiving questions, comments and suggestions

Peter Ruckdeschel
Matthias Kohl
Thomas Stabla
Florian Camphausen

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From ggrothendieck at myway.com  Mon Sep 27 21:54:28 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 27 Sep 2004 19:54:28 +0000 (UTC)
Subject: [R] Re: cannot assign dimnames
References: <200409211009.i8LA47xv019317@hypatia.math.ethz.ch>
	<000701c4a4a5$023bf760$7d2501a3@plants.ox.ac.uk>
Message-ID: <loom.20040927T212857-433@post.gmane.org>

Dan Bebber <danbebber <at> forestecology.co.uk> writes:


: Please ignore my earlier message on this topic. I was under the mistaken
: impression that dimnames() named the dimensions themselves, rather than the
: indices within the dimensions.

What you are referring to is done in R by referring to the names of
the dimnames, as opposed to the dimnames, themselves.  Here is an
example:

R> mat <- matrix(1:12,4, dimnames = list(letters[1:4],LETTERS[1:3]))
R> names(dimnames(mat)) <- c("FirstDim", "SecondDim")
R> mat
        SecondDim
FirstDim A B  C
       a 1 5  9
       b 2 6 10
       c 3 7 11
       d 4 8 12



From ggrothendieck at myway.com  Mon Sep 27 22:01:42 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Mon, 27 Sep 2004 20:01:42 +0000 (UTC)
Subject: [R] Re: cannot assign dimnames
References: <200409211009.i8LA47xv019317@hypatia.math.ethz.ch>
	<000701c4a4a5$023bf760$7d2501a3@plants.ox.ac.uk>
	<loom.20040927T212857-433@post.gmane.org>
Message-ID: <loom.20040927T220021-364@post.gmane.org>

Gabor Grothendieck <ggrothendieck <at> myway.com> writes:

: 
: Dan Bebber <danbebber <at> forestecology.co.uk> writes:
: 
: : Please ignore my earlier message on this topic. I was under the mistaken
: : impression that dimnames() named the dimensions themselves, rather than the
: : indices within the dimensions.
: 
: What you are referring to is done in R by referring to the names of
: the dimnames, as opposed to the dimnames, themselves.  Here is an
: example:
: 
: R> mat <- matrix(1:12,4, dimnames = list(letters[1:4],LETTERS[1:3]))
: R> names(dimnames(mat)) <- c("FirstDim", "SecondDim")
: R> mat
:         SecondDim
: FirstDim A B  C
:        a 1 5  9
:        b 2 6 10
:        c 3 7 11
:        d 4 8 12

Perhaps I should have also mentioned that the above could be done
in a single line like this:

R> mat <- matrix(1:12,4, dimnames = list(FirstDim = letters[1:4], SecondDim = 
LETTERS[1:3]))
R> mat
        SecondDim
FirstDim A B  C
       a 1 5  9
       b 2 6 10
       c 3 7 11
       d 4 8 12



From p.dalgaard at biostat.ku.dk  Mon Sep 27 22:28:59 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Sep 2004 22:28:59 +0200
Subject: [R] Re: cannot assign dimnames
In-Reply-To: <000701c4a4a5$023bf760$7d2501a3@plants.ox.ac.uk>
References: <000701c4a4a5$023bf760$7d2501a3@plants.ox.ac.uk>
Message-ID: <x2acvbtq0k.fsf@biostat.ku.dk>

"Dan Bebber" <danbebber at forestecology.co.uk> writes:

> Dear list,
> 
> Please ignore my earlier message on this topic. I was under the mistaken
> impression that dimnames() named the dimensions themselves, rather than the
> indices within the dimensions.

The dimnames list can be named though:

> matrix(1:4,2,dimnames=list(foo=1:2,bar=c(10,20)))
   bar
foo 10 20
  1  1  3
  2  2  4


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From nderby at u.washington.edu  Mon Sep 27 23:25:39 2004
From: nderby at u.washington.edu (Nathaniel B. Derby)
Date: Mon, 27 Sep 2004 14:25:39 -0700 (PDT)
Subject: [R] Looking for .Call functions
Message-ID: <Pine.LNX.4.43.0409271425390.9676@hymn16.u.washington.edu>

Hi,

In my ongoing quest to track down the source of an error (see message "[R] optim error in arima" above), I find in the cource code for arima0 the following:

     arma0f <- function(p) {
         par <- as.double(fixed)
         par[mask] <- p
         .Call("arma0fa", G, par, PACKAGE = "stats")
     }

I would like to know what the function "arma0f" does.  Does the above mean that there is a function called "arma0fa" somewhere in R?  Where is it?  I couldn't find anything in Rinternals.h.


Thanks,

Nate



From jfox at mcmaster.ca  Mon Sep 27 23:27:59 2004
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 27 Sep 2004 17:27:59 -0400
Subject: [R] multinom object :way of plotting??
In-Reply-To: <Prayer.1.0.11.0409271816530.3144@hermes-1.csi.cam.ac.uk>
Message-ID: <web-66530798@cgpsrv2.cis.mcmaster.ca>

Dear Camille,

You might be interested in a paper (available at
http://socserv.socsci.mcmaster.ca/jfox/logit-effect-displays.pdf) that
Bob Andersen and I wrote on this topic. The paper deals with graphing
multinomial-logit and proportional-odds models.

Regards,
 John

On 27 Sep 2004 18:16:53 +0100
 Camille Szmaragd <cs377 at cam.ac.uk> wrote:
> Dear all,
> 
> I'm fitting a multinom function to my dataset
> (multinom(outcome~age+K+D)) and I need to present my results on a
> poster. Does someone know a nice way of doing that? I think I saw in
> an archive that you cannot plot a multinom.object, is it true?
> 
> Thank you by advance for your help,
> 
> Cheers
> 
> Camille
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/



From bates at stat.wisc.edu  Mon Sep 27 23:49:13 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 27 Sep 2004 16:49:13 -0500
Subject: [R] Looking for .Call functions
In-Reply-To: <Pine.LNX.4.43.0409271425390.9676@hymn16.u.washington.edu>
References: <Pine.LNX.4.43.0409271425390.9676@hymn16.u.washington.edu>
Message-ID: <41588AD9.8080004@stat.wisc.edu>

Nathaniel B. Derby wrote:
> Hi,
> 
> In my ongoing quest to track down the source of an error (see message 
> "[R] optim error in arima" above), I find in the cource code for arima0 
> the following:
> 
>     arma0f <- function(p) {
>         par <- as.double(fixed)
>         par[mask] <- p
>         .Call("arma0fa", G, par, PACKAGE = "stats")
>     }
> 
> I would like to know what the function "arma0f" does.  Does the above 
> mean that there is a function called "arma0fa" somewhere in R?  Where is 
> it?  I couldn't find anything in Rinternals.h.

It means that in one of the .c source files in 
$RSRC/src/library/stats/src there will be a C function declared as

SEXP arma0fa(SEXP, SEXP);

(In fact it is declared in ts.h and defined in pacf.c in that directory)



From p.murrell at auckland.ac.nz  Mon Sep 27 23:57:43 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 28 Sep 2004 09:57:43 +1200
Subject: [R] Gridbase basic question
References: <E6ED8BE8-0D71-11D9-B970-000A95D7BA10@mail.nih.gov>
Message-ID: <41588CD7.1050103@stat.auckland.ac.nz>

Hi


Sean Davis wrote:
> All,
> 
> I have a simple plot(x,y) and I would like to then insert rectangles of  
> some length (in native coordinates) and height fixed to 0.5 in native  
> coordinates.  I can't quite get the code right to do this.  Can anyone  
> give me a quick example of how to do this?  I looked the gridBase index  
> and the tutorial (from R-news?) but just haven't gotten it down yet.
> 
>  > plot(1:10,1:10)
>  > par(new=T);vps <- baseViewports()
>  > pushViewport(vps$inner,vps$figure,vps$plot)
> viewport[GRID.VP.28]


At this point you are within a viewport which has x- and y-scales 
corresponding to the plot(1:10, 1:10).


>  > pushViewport(viewport(x=unit(1,"native"),y=unit(2,"native")))
> viewport[GRID.VP.29]


You have just created a new viewport at location (1, 2) in the plot, but 
  the scales on this new viewport are the default (0, 1).  i.e., you are 
now in a completely different coordinate system.  Also, this new 
viewport is as wide and as high as the plot region -- for example, it 
extends well beyong the left edge of the window/page.


> grid.rect(height=unit(0.5,"native"),width=unit(1.5,"native"),just='botto 
> m')


This draws a rectangle half as high as the current viewport and 1.5 
times as wide (the native scale in the current viewport is (0, 1) in 
both dimensions).  Importantly, the "native" coordinate systems you are 
referring to no longer correspond to the scales on the plot.


> This draws a very large rectangle going from 2 to 7 (y) and to 8 (x).


Three things:

(i) If drawing rectangles relative to the current "native" (or user) 
coordinates is all you want to do then you could just use rect() and 
ignore gridBase altogether.  For example, ...

x <- sample(1:10, 10)
y <- 1:10
w <- runif(10)
h <- 0.5

plot(1:10,1:10)
rect(x - w/2, y - h/2, x + w/2, y + h/2)


(ii) Using grid and gridBase, the above example becomes ...

plot(1:10,1:10)
par(new=T);vps <- baseViewports()
pushViewport(vps$inner,vps$figure,vps$plot)
grid.rect(x=x, y=y, width=w, height=h, default.units="native")
popViewport(3)

... but as mentioned, this is like using a sledge hammer to kill a cat 
or whatever the expression is.

(iii) There would be justification in using grid and gridBase if you 
want to draw more than just a rectangle, especially if you want to use 
coordinates other than native.  Here's a trivial example (adds fixed 
size "whiskers" to the corners of the rectangles) ...

plot(1:10,1:10)
par(new=T);vps <- baseViewports()
pushViewport(vps$inner,vps$figure,vps$plot)
for (i in 1:10) {
   pushViewport(viewport(x=x[i], y=y[i], width=w[i], height=h,
                         default.units="native"))
   grid.rect()
   grid.segments(0, 0, unit(-1, "mm"), unit(-1, "mm"))
   grid.segments(0, 1, unit(-1, "mm"),
                 unit(1, "npc") + unit(1, "mm"))
   grid.segments(1, 1,
                 unit(1, "npc") + unit(1, "mm"),
                 unit(1, "npc") + unit(1, "mm"))
   grid.segments(1, 0,
                 unit(1, "npc") + unit(1, "mm"),
                 unit(-1, "mm"))
   popViewport()
}

... (but pushing a viewport per data point like this is a LOT slower).

Hope that helps

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From vograno at evafunds.com  Tue Sep 28 00:23:35 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Mon, 27 Sep 2004 15:23:35 -0700
Subject: [R] passing formula arg to mgcv::gam 
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A56D861F@phost015.EVAFUNDS.intermedia.net>

Hi,

I have a function, callGam, that fits a gam model to a subset of a dataframe. The argument to callGam is a formula, the subset is determined inside the function itself. My na??ve approach generates and error, see below. I guess this is because 'idx' is loocked up in the environment of 'formula', but I am too ignorant about environments to be able to tell for sure. Could someone please suggest a way around?

Thanks,
Vadim

> library("mgcv")
> 
> callGam <- function(formula) {
+   idx <- seq(10)
+   gam(formula, data=data.frame(x=rnorm(100), y=rnorm(100)), subset=idx)
+ }
> 
> gam.fit <- callGam(y ~ x)
Error in eval(expr, envir, enclos) : Object "idx" not found
>



From vograno at evafunds.com  Tue Sep 28 00:57:43 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Mon, 27 Sep 2004 15:57:43 -0700
Subject: [R] passing formula arg to mgcv::gam 
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A56D8625@phost015.EVAFUNDS.intermedia.net>

This is a self-response :-).

It was indeed a problem with environments. One way to get around is to "reset" the environment, e.g. inside callGam do
formula <- as.formula(unclass(formula)) 


Not too aesthetic, but works. Is there a less kludgy way to do this?

BTW, forgot to mention. This is R-1.9.1 on RH-7.3.

Thanks,
Vadim

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Vadim 
> Ogranovich
> Sent: Monday, September 27, 2004 3:24 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] passing formula arg to mgcv::gam 
> 
> Hi,
> 
> I have a function, callGam, that fits a gam model to a subset 
> of a dataframe. The argument to callGam is a formula, the 
> subset is determined inside the function itself. My na??ve 
> approach generates and error, see below. I guess this is 
> because 'idx' is loocked up in the environment of 'formula', 
> but I am too ignorant about environments to be able to tell 
> for sure. Could someone please suggest a way around?
> 
> Thanks,
> Vadim
> 
> > library("mgcv")
> > 
> > callGam <- function(formula) {
> +   idx <- seq(10)
> +   gam(formula, data=data.frame(x=rnorm(100), y=rnorm(100)), 
> + subset=idx) }
> > 
> > gam.fit <- callGam(y ~ x)
> Error in eval(expr, envir, enclos) : Object "idx" not found
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From epurdom at stanford.edu  Tue Sep 28 02:08:09 2004
From: epurdom at stanford.edu (Elizabeth Purdom)
Date: Mon, 27 Sep 2004 17:08:09 -0700
Subject: [R] sapply behavior
Message-ID: <5.2.1.1.2.20040927165704.00bdfec0@epurdom.pobox.stanford.edu>

Hi,

I use sapply very frequently, but I have recently noticed a behavior of 
sapply which I don't understand and have never seen before. Basically, 
sapply returns what looks like a matrix,  says it a matrix, and appears to 
let me do matrix things (like transpose). But it is also a list and behaves 
like a list when I subset it, not a vector (so I can't sort a row for 
instance). I don't know where this is coming from so as to avoid it, nor 
how to handle the beast that sapply is returning. I double checked my old 
version of R and apparently this same thing happens in 1.8.0, though I 
never experienced it. I had a hard time reproducing it, and I don't know 
what's setting it off, but the code below seems to do it for me. (I'm using 
R on Windows XP, either 1.8.0 or 1.9.1)

Thanks for any help,
Elizabeth Purdom


 > temp2<-matrix(sample(1:6,6,replace=F),byrow=F,nrow=6,ncol=4)
 > colnames(temp2)<-paste("A",as.character(1:4),sep="")
 > temp2<-as.data.frame(temp2)
 > 
newtemp2<-sapply((1:6),function(x){xmat<-temp2[temp2[,1]==x,,drop=F];return(xmat[1,])})
 > print(newtemp2) #looks like matrix
    [,1] [,2] [,3] [,4] [,5] [,6]
A1 1    2    3    4    5    6
A2 1    2    3    4    5    6
A3 1    2    3    4    5    6
A4 1    2    3    4    5    6
 > is.matrix(newtemp2) #says it's matrix
[1] TRUE
 > class(newtemp2)
[1] "matrix"
 > is.list(newtemp2) #but also list
[1] TRUE
 > newtemp2[,1] #can't subset and get a vector back; same thing happens for 
rows.
$A1
[1] 1

$A2
[1] 1

$A3
[1] 1

$A4
[1] 1
#other things about it:
 > names(newtemp2)
NULL
 > dimnames(newtemp2)
[[1]]
[1] "A1" "A2" "A3" "A4"

[[2]]
NULL
 > dim(newtemp2)
[1] 4 6
 > length(newtemp2)
[1] 24



From shawn at ori.org  Tue Sep 28 02:49:03 2004
From: shawn at ori.org (Shawn Boles)
Date: Mon, 27 Sep 2004 17:49:03 -0700
Subject: [R] using tcltk in R under ESS/XEmacs on Windows
Message-ID: <FF0BFD201501C441882C9CADB8D3AB373D15A0@vidar.ori-eug.ori.org>

Tony:

It is indeed most amazing that you have been able to get ESS/Emacs
running under Windows.  And much appreciated by those of us who have to
moil around 
with MessySoft machines.

Thanks to all who have contributed to the effort.

Cheers,

Shawn Boles




-----Original Message-----
From: A.J. Rossini [mailto:blindglobe at gmail.com] 
Sent: Saturday, September 25, 2004 8:04 PM
To: Liaw, Andy
Cc: R-Help; MSchwartz at MedAnalytics.com; ESS (Help list)
Subject: Re: [R] using tcltk in R under ESS/XEmacs on Windows

It most likely is Windows specific.  It's most amazing that we
actually have ESS/(X)Emacs working under windows in the first place.

Unfortunately, I'm in transit for the next few weeks, but I'll
probably have a windows machine on my desk sometime after that.  Argh.

best,
-tony


On Fri, 24 Sep 2004 17:48:18 -0400, Liaw, Andy <andy_liaw at merck.com>
wrote:
> > From: Marc Schwartz
> >
> > On Fri, 2004-09-24 at 15:02, Liaw, Andy wrote:
> > > Sorry for the cross-post.  Not sure where the problem is...
> > >
> > > A while back I posted an R function to R-help:
> > >
> > > cd <- function (dir = tclvalue(tkchooseDirectory()),
> > saveOld = FALSE,
> > >     loadNew = TRUE) {
> > >     stopifnot(require(tcltk))
> > >     if (saveOld)
> > >         save.image(compress = TRUE)
> > >     setwd(dir)
> > >     rm(list = ls(all = TRUE, envir = .GlobalEnv), envir =
> > .GlobalEnv)
> > >     if (loadNew && file.exists(".RData")) {
> > >         loaded <- load(".RData", envir = .GlobalEnv)
> > >         return(invisible(loaded))
> > >     }
> > >
> > > where the default value for the `dir' argument is to run
> > the tcltk directory
> > > chooser and get the directory name chosen.  (Thanks to
> > Prof. John Fox for
> > > the tcltk part!!)  While this function works fine under
> > Rgui on Windows, it
> > > doesn't work when running R within ESS (5.2.3) and XEmacs
> > (21.4.13).  The
> > > directory chooser never shows up, and dir just gets the
> > empty string.  Does
> > > anyone have any idea what could be the problem?  I'd very
> > much appreciate
> > > any pointers.
> > >
> > > Best,
> > > Andy
> >
> > Andy,
> >
> > This works under FC2 using ESS 5.2.3 with XEmacs version 21.4.15, so
> > presumably there is something specific to the Windows
implementation?
> 
> Given Prof. Fox's follow-up and your obvservation, I guess the problem
_is_
> Windows-specific. 8-(
> 
> > Also, two things:
> >
> > 1. You are missing a closing brace above, which I presume may be a
> > simple copy and paste issue.
> 
> Yes.  My apologies.
> 
> > 2. If you successfully change the directory, the cd()
> > function itself is
> > deleted from the global environment via your rm(...), as you
currently
> > have it implemented. I am not sure if this is intentional or not.
> 
> Well, sort of.  I've placed it in a small package along with other
handy
> stuff, so that won't be a problem.
> 
> Best,
> Andy
> 
> 
> 
> > HTH,
> >
> > Marc
> >
> >
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> 



-- 
A.J. Rossini
blindglobe at gmail.com

______________________________________________
ESS-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/ess-help



From andy_liaw at merck.com  Tue Sep 28 03:12:07 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 27 Sep 2004 21:12:07 -0400
Subject: [R] sapply behavior
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8457@usrymx25.merck.com>

The problem is that temp2 is a data frame, and the function you are
sapply()ing to returns a row from a data frame.  A data frame is really a
list, with each variable corresponding to a component.  If you extract a row
of a data frame, you get another data frame, not a vector, even if all
variables are the same type.  sapply() can really `simplify' the right way
if it's given a vector (or matrix).  Consider:

> str(temp2)
`data.frame':   6 obs. of  4 variables:
 $ A1: int  5 2 4 6 1 3
 $ A2: int  5 2 4 6 1 3
 $ A3: int  5 2 4 6 1 3
 $ A4: int  5 2 4 6 1 3
> temp2 <- as.matrix(temp2)
> str(temp2)
 int [1:6, 1:4] 5 2 4 6 1 3 5 2 4 6 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:6] "1" "2" "3" "4" ...
  ..$ : chr [1:4] "A1" "A2" "A3" "A4"
> str(sapply(1:6,function(x){xmat<-temp2[temp2[,1]==x,,drop=F]; xmat[1,]}))
 int [1:4, 1:6] 1 1 1 1 2 2 2 2 3 3 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:4] "A1" "A2" "A3" "A4"
  ..$ : NULL

(The is.matrix() function probably just check whether the dim attribute is a
vector of length 2, and not a data frame (as it says in ?is.matrix).  The
newtemp2 object you get is a list with 24 components, each component is a
vector of one integer, and has a dim attribute of c(4, 6).  Not what I would
call a matrix.)

HTH,
Andy


> From: Elizabeth Purdom
> 
> Hi,
> 
> I use sapply very frequently, but I have recently noticed a 
> behavior of 
> sapply which I don't understand and have never seen before. 
> Basically, 
> sapply returns what looks like a matrix,  says it a matrix, 
> and appears to 
> let me do matrix things (like transpose). But it is also a 
> list and behaves 
> like a list when I subset it, not a vector (so I can't sort a row for 
> instance). I don't know where this is coming from so as to 
> avoid it, nor 
> how to handle the beast that sapply is returning. I double 
> checked my old 
> version of R and apparently this same thing happens in 1.8.0, 
> though I 
> never experienced it. I had a hard time reproducing it, and I 
> don't know 
> what's setting it off, but the code below seems to do it for 
> me. (I'm using 
> R on Windows XP, either 1.8.0 or 1.9.1)
> 
> Thanks for any help,
> Elizabeth Purdom
> 
> 
>  > temp2<-matrix(sample(1:6,6,replace=F),byrow=F,nrow=6,ncol=4)
>  > colnames(temp2)<-paste("A",as.character(1:4),sep="")
>  > temp2<-as.data.frame(temp2)
>  > 
> newtemp2<-sapply((1:6),function(x){xmat<-temp2[temp2[,1]==x,,d
> rop=F];return(xmat[1,])})
>  > print(newtemp2) #looks like matrix
>     [,1] [,2] [,3] [,4] [,5] [,6]
> A1 1    2    3    4    5    6
> A2 1    2    3    4    5    6
> A3 1    2    3    4    5    6
> A4 1    2    3    4    5    6
>  > is.matrix(newtemp2) #says it's matrix
> [1] TRUE
>  > class(newtemp2)
> [1] "matrix"
>  > is.list(newtemp2) #but also list
> [1] TRUE
>  > newtemp2[,1] #can't subset and get a vector back; same 
> thing happens for 
> rows.
> $A1
> [1] 1
> 
> $A2
> [1] 1
> 
> $A3
> [1] 1
> 
> $A4
> [1] 1
> #other things about it:
>  > names(newtemp2)
> NULL
>  > dimnames(newtemp2)
> [[1]]
> [1] "A1" "A2" "A3" "A4"
> 
> [[2]]
> NULL
>  > dim(newtemp2)
> [1] 4 6
>  > length(newtemp2)
> [1] 24
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From bates at stat.wisc.edu  Tue Sep 28 03:13:13 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 27 Sep 2004 20:13:13 -0500
Subject: [R] sapply behavior
In-Reply-To: <5.2.1.1.2.20040927165704.00bdfec0@epurdom.pobox.stanford.edu>
References: <5.2.1.1.2.20040927165704.00bdfec0@epurdom.pobox.stanford.edu>
Message-ID: <4158BAA9.4070401@stat.wisc.edu>

Elizabeth Purdom wrote:

> I use sapply very frequently, but I have recently noticed a behavior of 
> sapply which I don't understand and have never seen before. Basically, 
> sapply returns what looks like a matrix,  says it a matrix, and appears 
> to let me do matrix things (like transpose). But it is also a list and 
> behaves like a list when I subset it, not a vector (so I can't sort a 
> row for instance). I don't know where this is coming from so as to avoid 
> it, nor how to handle the beast that sapply is returning. I double 
> checked my old version of R and apparently this same thing happens in 
> 1.8.0, though I never experienced it. I had a hard time reproducing it, 
> and I don't know what's setting it off, but the code below seems to do 
> it for me. (I'm using R on Windows XP, either 1.8.0 or 1.9.1)
> 
> Thanks for any help,
> Elizabeth Purdom
> 
> 
>  > temp2<-matrix(sample(1:6,6,replace=F),byrow=F,nrow=6,ncol=4)
>  > colnames(temp2)<-paste("A",as.character(1:4),sep="")
>  > temp2<-as.data.frame(temp2)

It is this coercion to the data frame that is injecting a list-like 
property into the result.  Try your script without that line and it will 
work as you expect.

>  > newtemp2<-sapply((1:6),function(x){xmat<-temp2[temp2[,1]==x,,drop=F];return(xmat[1,])}) 
>  > print(newtemp2) #looks like matrix
>    [,1] [,2] [,3] [,4] [,5] [,6]
> A1 1    2    3    4    5    6
> A2 1    2    3    4    5    6
> A3 1    2    3    4    5    6
> A4 1    2    3    4    5    6

The best thing to do in a situation like this is to use the str function 
to see the details of the structure of the object.



From ggrothendieck at myway.com  Tue Sep 28 03:14:58 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 28 Sep 2004 01:14:58 +0000 (UTC)
Subject: [R] sapply behavior
References: <5.2.1.1.2.20040927165704.00bdfec0@epurdom.pobox.stanford.edu>
Message-ID: <loom.20040928T031023-771@post.gmane.org>

Elizabeth Purdom <epurdom <at> stanford.edu> writes:

: 
: Hi,
: 
: I use sapply very frequently, but I have recently noticed a behavior of 
: sapply which I don't understand and have never seen before. Basically, 
: sapply returns what looks like a matrix,  says it a matrix, and appears to 
: let me do matrix things (like transpose). But it is also a list and behaves 
: like a list when I subset it, not a vector (so I can't sort a row for 
: instance). I don't know where this is coming from so as to avoid it, nor 
: how to handle the beast that sapply is returning. I double checked my old 
: version of R and apparently this same thing happens in 1.8.0, though I 
: never experienced it. I had a hard time reproducing it, and I don't know 
: what's setting it off, but the code below seems to do it for me. (I'm using 
: R on Windows XP, either 1.8.0 or 1.9.1)
: 
: Thanks for any help,
: Elizabeth Purdom
: 
: 
:  > temp2<-matrix(sample(1:6,6,replace=F),byrow=F,nrow=6,ncol=4)
:  > colnames(temp2)<-paste("A",as.character(1:4),sep="")
:  > temp2<-as.data.frame(temp2)
:  > 
: newtemp2<-sapply((1:6),function(x){xmat<-temp2[temp2[,1]==x,,drop=F];return
(xmat[1,])})
:  > print(newtemp2) #looks like matrix
:     [,1] [,2] [,3] [,4] [,5] [,6]
: A1 1    2    3    4    5    6
: A2 1    2    3    4    5    6
: A3 1    2    3    4    5    6
: A4 1    2    3    4    5    6
:  > is.matrix(newtemp2) #says it's matrix
: [1] TRUE
:  > class(newtemp2)
: [1] "matrix"
:  > is.list(newtemp2) #but also list
: [1] TRUE
:  > newtemp2[,1] #can't subset and get a vector back; same thing happens for 
: rows.
: $A1
: [1] 1
: 
: $A2
: [1] 1
: 
: $A3
: [1] 1
: 
: $A4
: [1] 1
: #other things about it:
:  > names(newtemp2)
: NULL
:  > dimnames(newtemp2)
: [[1]]
: [1] "A1" "A2" "A3" "A4"
: 
: [[2]]
: NULL
:  > dim(newtemp2)
: [1] 4 6
:  > length(newtemp2)
: [1] 24


The problem is that your function is returning a one row data frame
and when sapply tries to simplify the resulting list of 6 data frames 
that gives a list with dimensions rather what you were expecting
which is a vector with dimensions.

Let us call the original anonymous function in your post (i.e. the one
passed to sapply there), f.  We can modify it to produce f2 which is like
f except that we wrap the return expression in c() to turn it into a
vector:

  f2 <- function(x){xmat<-temp2[temp2[,1]==x,,drop=F];return(c(xmat[1,]))}
  sapply(1:6, f2)

If you really do want to return a one row data frame then
use rbind to bind the data frames together rather than sapply:

   do.call("rbind", lapply(1:6, f))



From ggrothendieck at myway.com  Tue Sep 28 03:19:33 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 28 Sep 2004 01:19:33 +0000 (UTC)
Subject: [R] passing formula arg to mgcv::gam
References: <C698D707214E6F4AB39AB7096C3DE5A56D8625@phost015.EVAFUNDS.intermedia.net>
Message-ID: <loom.20040928T031832-379@post.gmane.org>


How about

   environment(formula) <- environment()


Vadim Ogranovich <vograno <at> evafunds.com> writes:

: 
: This is a self-response .
: 
: It was indeed a problem with environments. One way to get around is 
to "reset" the environment, e.g. inside
: callGam do
: formula <- as.formula(unclass(formula)) 
: 
: Not too aesthetic, but works. Is there a less kludgy way to do this?
: 
: BTW, forgot to mention. This is R-1.9.1 on RH-7.3.
: 
: Thanks,
: Vadim
: 
: > -----Original Message-----
: > From: r-help-bounces <at> stat.math.ethz.ch 
: > [mailto:r-help-bounces <at> stat.math.ethz.ch] On Behalf Of Vadim 
: > Ogranovich
: > Sent: Monday, September 27, 2004 3:24 PM
: > To: r-help <at> stat.math.ethz.ch
: > Subject: [R] passing formula arg to mgcv::gam 
: > 
: > Hi,
: > 
: > I have a function, callGam, that fits a gam model to a subset 
: > of a dataframe. The argument to callGam is a formula, the 
: > subset is determined inside the function itself. My na??ve 
: > approach generates and error, see below. I guess this is 
: > because 'idx' is loocked up in the environment of 'formula', 
: > but I am too ignorant about environments to be able to tell 
: > for sure. Could someone please suggest a way around?
: > 
: > Thanks,
: > Vadim
: > 
: > > library("mgcv")
: > > 
: > > callGam <- function(formula) {
: > +   idx <- seq(10)
: > +   gam(formula, data=data.frame(x=rnorm(100), y=rnorm(100)), 
: > + subset=idx) }
: > > 
: > > gam.fit <- callGam(y ~ x)
: > Error in eval(expr, envir, enclos) : Object "idx" not found



From emuqum at comcast.net  Tue Sep 28 03:26:03 2004
From: emuqum at comcast.net (Matt Gibbs)
Date: Mon, 27 Sep 2004 21:26:03 -0400
Subject: [R] smoothing noisy data with a twist
Message-ID: <4158BDAB.1080204@comcast.net>

Hi,

I have a set of observations (x,y), derived from a previous estimation. 
For each observation I also have an estimated variance s(y) derived from 
the first stage.

The problem is that I need to smooth the data (x,y) while taking into 
account the fact that the y's have been estimated at a previous stage 
and thus already come with a variance. So, if I smooth the data I 
somehow need to take into account *two errors*, one from the smoothing 
and the other from the already noisy data that I start off with.

Does anyone have any idea how to do this?

thanks, matt.



From vograno at evafunds.com  Tue Sep 28 03:34:16 2004
From: vograno at evafunds.com (Vadim Ogranovich)
Date: Mon, 27 Sep 2004 18:34:16 -0700
Subject: [R] private on site R training solicited
Message-ID: <C698D707214E6F4AB39AB7096C3DE5A56D8636@phost015.EVAFUNDS.intermedia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040927/885156a4/attachment.pl

From andy_liaw at merck.com  Tue Sep 28 03:57:43 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 27 Sep 2004 21:57:43 -0400
Subject: [R] smoothing noisy data with a twist
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8459@usrymx25.merck.com>

One thing I would try is to supply 1/sd(y) as the weights to smoothers that
can accept them; e.g., loess().

Andy

> From: Matt Gibbs
> 
> Hi,
> 
> I have a set of observations (x,y), derived from a previous 
> estimation. 
> For each observation I also have an estimated variance s(y) 
> derived from 
> the first stage.
> 
> The problem is that I need to smooth the data (x,y) while taking into 
> account the fact that the y's have been estimated at a previous stage 
> and thus already come with a variance. So, if I smooth the data I 
> somehow need to take into account *two errors*, one from the 
> smoothing 
> and the other from the already noisy data that I start off with.
> 
> Does anyone have any idea how to do this?
> 
> thanks, matt.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From elvis at xlsolutions-corp.com  Tue Sep 28 05:45:00 2004
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Mon, 27 Sep 2004 20:45:00 -0700
Subject: [R] Course***Splus/R: Complementing and Extending Statistical
	Computing for SAS Users
Message-ID: <20040928034500.31186.qmail@webmail03.mesa1.secureserver.net>

XLSolutions Corporation (www.xlsolutions-corp.com) is pleased to 
announce a two-day course, "Splus/R: Complementing and Extending
Statistical Computing for SAS Users" www.xlsolutions-corp.com/Rsas.htm

Dates/City: October 28-29  Raleigh, NC
                 November 4-5  Boston, MA
            

This course is designed for SAS users who want to learn how to
complement 
and extend statistical computing with Splus and/or R system. 
The course will give participants a strong foundation for becoming 
a versatile programmer. 

Course Description:

This two-day course focuses on a broad spectrum of topics:

*Data manipulations in S and R (data frame and matrix operations) 
and SAS (the data step) -- issues of importing, formatting,
transformation,
cataloging, exporting 
*Splus/R Functions vs macros in SAS for programming repetitive
processes. 
*The iteration models of SAS vs whole-object modeling 
*Specific comparison: linear modeling, glms, gees, lmes.
*etc

Complete course description: www.xlsolutions-corp.com/Rsas.htm


Earlybird ends October 10th. 

Ask for group discount!

Registration: 

Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578




Share Your Thoughts:

Are there any additional topics you would like for this course to
address?
Would you like for this course to be offered in another city? 

Please let us know by contributing to our recommendation list: 
training at xlsolutions-corp.com.


Elvis Miller, PhD
Manager Training and Technical Support
North American Division
XLSolutions Corporation
Email: elvis at xlsolutions-corp.com
Phone: 206-686-1578
Web: www.xlsolutions-corp.com



From mpiktas at gmail.com  Tue Sep 28 06:48:22 2004
From: mpiktas at gmail.com (Vaidotas Zemlys)
Date: Tue, 28 Sep 2004 07:48:22 +0300
Subject: [R] optim error in arima
In-Reply-To: <Pine.LNX.4.43.0409270902390.21744@hymn15.u.washington.edu>
References: <Pine.LNX.4.43.0409270902390.21744@hymn15.u.washington.edu>
Message-ID: <e4780832040927214816d298ff@mail.gmail.com>

Hi,


On Mon, 27 Sep 2004 09:02:39 -0700 (PDT), Nathaniel B. Derby
<nderby at u.washington.edu> wrote:
> Hello,
> 
> I'm fitting a series of ARIMA models to a data set to compare fits.  After 
> taking the logs of the data and then differencing them to induce stationarity,
> I execute
> 
> arima( y, order=c( p, 0, q ), seasonal=list( order=c( P, 0, Q ), period=7 ) )
> 
> for various values of p, q, P and Q.  For one set of these values, I get
> 
> Error in optim(init[mask], armafn, method = "BFGS", hessian = TRUE ... :
>          non-finite finite-difference value [0]
> 
> which tells me that when computing derivatives of the objective function 
> (armafn) by finite differencing, one of the values is NA, +Inf or -Inf.  Any 
> ideas?  I would like to print some values of armafn, but how do I get that 
> from my data set, and what would I look for?

This probably means, that for your values of p, q, P, Q the arima
model is not valid arima model, i.e. it is not stationary.

Vaidotas



From alan.simpson at robertsresearch.com.au  Tue Sep 28 06:51:40 2004
From: alan.simpson at robertsresearch.com.au (Alan Simpson)
Date: Tue, 28 Sep 2004 14:51:40 +1000
Subject: [R] An index of all possible combinations of variables in a data
	fram e
Message-ID: <BC4231C30D143F43BFD514168020196935DA7C@lurch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040928/0b0edec1/attachment.pl

From mpiktas at gmail.com  Tue Sep 28 07:03:39 2004
From: mpiktas at gmail.com (Vaidotas Zemlys)
Date: Tue, 28 Sep 2004 08:03:39 +0300
Subject: [R] KS test
In-Reply-To: <6.0.0.22.2.20040927160428.01d03c48@paris7.jussieu.fr>
References: <6.0.0.22.2.20040927160428.01d03c48@paris7.jussieu.fr>
Message-ID: <e478083204092722031fa75b5b@mail.gmail.com>

Hi,


> I have a sample, and I want to test if its distribution is normal. So I
> would like to perform a one sample KS test but I cannot find the "y"
> argument representing  the "character string naming a distribution
> function" according to the ?ks.test help page.
> It is impossible forme to have a list of these character strings naming a
> distribution function.
> 
> I think it is "pnorm" for a normal distribution, bu I would like to be sure...
> 

>From examples in ks.test manual:
# Does x come from a shifted gamma distribution with shape 3 and scale 2?
     ks.test(x+2, "pgamma", 3, 2) # two-sided
     ks.test(x+2, "pgamma", 3, 2, alternative = "gr")

So you can be sure, that it will be "pnorm" for normal distribution.

Vaidotas



From ggrothendieck at myway.com  Tue Sep 28 07:13:11 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 28 Sep 2004 05:13:11 +0000 (UTC)
Subject: [R] An index of all possible combinations of variables in a
	=?utf-8?b?ZGF0YQlmcmFt?= e
References: <BC4231C30D143F43BFD514168020196935DA7C@lurch>
Message-ID: <loom.20040928T071049-766@post.gmane.org>

Alan Simpson <alan.simpson <at> robertsresearch.com.au> writes:

: Does anybody know of any way to create an index of all the possible
: combinations of variables (factors) in a data frame? ie for 3 factors A, B &
: C we have 
: 
: A
: B
: C
: AB
: AC
: BC
: ABC
:  
: which equates to columns 1, 2, 3, 1:2, (1,3), 2:3 and 1:3.
: 
: I realise that a function like model.matrix does this, but how to get the
: seqence of the index?
: 

Is this what you are looking for?

R> attributes(terms(~ a * b * c))$term.labels
[1] "a"     "b"     "c"     "a:b"   "a:c"   "b:c"   "a:b:c"



From a.trapletti at bluewin.ch  Tue Sep 28 07:25:10 2004
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Tue, 28 Sep 2004 07:25:10 +0200
Subject: [R] Re: tseries Package for R
In-Reply-To: <61CBB4C9-10C7-11D9-A624-000D932E990C@comcast.net>
References: <61CBB4C9-10C7-11D9-A624-000D932E990C@comcast.net>
Message-ID: <4158F5B6.3020103@bluewin.ch>

Wizon wrote:

> I am using Mac OSX.  I am first starting to use R and have not 
> installed any packages yet.  I searched through the CRAN site for a 
> Mac OSX version, but did not find one.  I downloaded the tar.gz 
> package.  Will this work on the Mac?  Is there a way to get a package 
> that I don't have to compile?  Thanks in advance for your help.
>
> Adam
>
>
Dear Adam

Sorry, I can't help you since I never used R under MacOS. However, I cc 
your mail to R-help. Maybe you get some feedback from there.

Best regards
Adrian



From YiYao_Jiang at smics.com  Tue Sep 28 07:44:07 2004
From: YiYao_Jiang at smics.com (YiYao_Jiang)
Date: Tue, 28 Sep 2004 13:44:07 +0800
Subject: [R] (no subject)
Message-ID: <CD0374F1F9FDC842A5CFBEA4906FDC2501FD508F@ex103.smic-sh.com>

Hello everybody:

I can't setup a library for some functions.
Can anybody kindly give me an example about setup a library. From build a package to library.

Thanks!


Best Regards

YiYao Jiang



From patrick.drechsler at gmx.net  Tue Sep 28 07:50:54 2004
From: patrick.drechsler at gmx.net (Patrick Drechsler)
Date: Tue, 28 Sep 2004 07:50:54 +0200
Subject: [Hmisc] proposal for change in latex.summary.formula.reverse (was:
	[R] Sweave: superfluous newline (`\\') in tex file)
References: <m3wtyh8bgg.fsf@pdrechsler.fqdn.th-h.de>
Message-ID: <m3vfdzlz5t.fsf@pdrechsler.fqdn.th-h.de>

Hi,

well, it wasn't a Sweave problem after all. Seems to have
something to do with the function
`latex.summary.formula.reverse' in the package Hmisc.

Following change seems to help (at least for my purpose):

--8<------------------------schnipp------------------------->8---
*** /usr/local/lib/R/library/Hmisc/R/Hmisc	2004-09-28 07:37:26.000000000 +0200
--- /usr/local/lib/R/library/Hmisc/R/Hmisc.original	2004-09-28 07:38:28.000000000 +0200
***************
*** 16156,16162 ****
                        'Numbers after percents are frequencies.',
                        sep="\n")
        if(length(testUsed))
!         legend <-paste(legend,'\n\n',
                         if(length(testUsed)==1)'Test used:' else 'Tests used:',
                         if(length(testUsed)==1) paste(testUsed,'test') else
                         paste(paste('$^{',1:length(testUsed),'}$',testUsed,
--- 16156,16162 ----
                        'Numbers after percents are frequencies.',
                        sep="\n")
        if(length(testUsed))
!         legend <-paste(legend,'\\\\\n','\n\n',
                         if(length(testUsed)==1)'Test used:' else 'Tests used:',
                         if(length(testUsed)==1) paste(testUsed,'test') else
                         paste(paste('$^{',1:length(testUsed),'}$',testUsed,
--8<------------------------schnapp------------------------->8---

But since my knowledge of R is rather small I have no idea if
these has any other drawbacks.

Any comments?

How would I go about changing this for my setup only? Is
renaming Hmisc to something like pdHmisc ok?

Patrick
-- 
Do you remember when you only had to pay
for windows when *you* broke them?



From Kevin.Wang at maths.anu.edu.au  Tue Sep 28 07:59:14 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Tue, 28 Sep 2004 15:59:14 +1000 (EST)
Subject: [R] (no subject)
In-Reply-To: <CD0374F1F9FDC842A5CFBEA4906FDC2501FD508F@ex103.smic-sh.com>
References: <CD0374F1F9FDC842A5CFBEA4906FDC2501FD508F@ex103.smic-sh.com>
Message-ID: <Pine.GSO.4.58.0409281558160.28463@yin>

Hi,

On Tue, 28 Sep 2004, YiYao_Jiang wrote:

> Hello everybody:
>
> I can't setup a library for some functions.
> Can anybody kindly give me an example about setup a library. From build a package to library.

I am guessing you meant you want to compile a package from source?  Have
you looked at Writing R Extensions?

HTH,

Kevin


--------------------------------
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From stenwa at yahoo.co.uk  Tue Sep 28 08:09:48 2004
From: stenwa at yahoo.co.uk (shane stanton)
Date: Tue, 28 Sep 2004 07:09:48 +0100 (BST)
Subject: [R] memory increase for large  r simulation
Message-ID: <20040928060948.13485.qmail@web25101.mail.ukl.yahoo.com>

Hi,

I am running R from windows 95. I have a large
simulation, which R does not get very far through
before telling me:

"error  cannot allocate vector of size 871875 Kb"

and warning message "reached total allocation of 127
Mb"

I have been trying to increase the memory allocation
to R from my computer, using various commands at the R
prompt, such as memory.limit(size=......) to which R
responds "NULL" or "cannot decrease memory limit" (no
matter how large I try to make the argument of
memory.limit. 

Does anybody have any ideas re how I can get this
simulation to run?

Many thanks,

Shane Stanton



From ripley at stats.ox.ac.uk  Tue Sep 28 08:20:21 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Sep 2004 07:20:21 +0100 (BST)
Subject: [R] sapply behavior
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF8457@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.44.0409280717350.27997-100000@gannet.stats>

On Mon, 27 Sep 2004, Liaw, Andy wrote:

> The problem is that temp2 is a data frame, and the function you are
> sapply()ing to returns a row from a data frame.  A data frame is really a
> list, with each variable corresponding to a component.  If you extract a row
> of a data frame, you get another data frame, not a vector, even if all
> variables are the same type.  sapply() can really `simplify' the right way
> if it's given a vector (or matrix).  Consider:
> 
> > str(temp2)
> `data.frame':   6 obs. of  4 variables:
>  $ A1: int  5 2 4 6 1 3
>  $ A2: int  5 2 4 6 1 3
>  $ A3: int  5 2 4 6 1 3
>  $ A4: int  5 2 4 6 1 3
> > temp2 <- as.matrix(temp2)
> > str(temp2)
>  int [1:6, 1:4] 5 2 4 6 1 3 5 2 4 6 ...
>  - attr(*, "dimnames")=List of 2
>   ..$ : chr [1:6] "1" "2" "3" "4" ...
>   ..$ : chr [1:4] "A1" "A2" "A3" "A4"
> > str(sapply(1:6,function(x){xmat<-temp2[temp2[,1]==x,,drop=F]; xmat[1,]}))
>  int [1:4, 1:6] 1 1 1 1 2 2 2 2 3 3 ...
>  - attr(*, "dimnames")=List of 2
>   ..$ : chr [1:4] "A1" "A2" "A3" "A4"
>   ..$ : NULL
> 
> (The is.matrix() function probably just check whether the dim attribute is a
> vector of length 2, and not a data frame (as it says in ?is.matrix).  The
> newtemp2 object you get is a list with 24 components, each component is a
> vector of one integer, and has a dim attribute of c(4, 6).  Not what I would
> call a matrix.)

That *is* a matrix, though, and is useful for lists of length greater than
one.  A matrix in R is just a vector with a dim attribute (and length the
product of the dims's), so as well as any of the atomic vectors it can be
a generic vector aka list.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Sep 28 08:24:05 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Sep 2004 07:24:05 +0100 (BST)
Subject: [R] memory increase for large  r simulation
In-Reply-To: <20040928060948.13485.qmail@web25101.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.44.0409280721480.27997-100000@gannet.stats>

Please read the appropriate FAQ (rw-FAQ), as the posting guide asks.
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^
  2.7 There seems to be a limit on the memory it uses!

lokks relevant, and is.  (So was some more info given with that error 
message.)

On Tue, 28 Sep 2004, shane stanton wrote:

> Hi,
> 
> I am running R from windows 95. I have a large
> simulation, which R does not get very far through
> before telling me:
> 
> "error  cannot allocate vector of size 871875 Kb"
> 
> and warning message "reached total allocation of 127
> Mb"
> 
> I have been trying to increase the memory allocation
> to R from my computer, using various commands at the R
> prompt, such as memory.limit(size=......) to which R
> responds "NULL" or "cannot decrease memory limit" (no
> matter how large I try to make the argument of
> memory.limit. 
> 
> Does anybody have any ideas re how I can get this
> simulation to run?
> 
> Many thanks,
> 
> Shane Stanton
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From YiYao_Jiang at smics.com  Tue Sep 28 08:26:02 2004
From: YiYao_Jiang at smics.com (YiYao_Jiang)
Date: Tue, 28 Sep 2004 14:26:02 +0800
Subject: [R] (no subject)
Message-ID: <CD0374F1F9FDC842A5CFBEA4906FDC25031ABCAF@ex103.smic-sh.com>

*******************************************************
On Tue, 28 Sep 2004, YiYao_Jiang wrote:

I can't setup a library for some functions.
Can anybody kindly give me an example about setup a library. From build a package to library.
*******************************************************

Actually I have read " Writing R Extensions"£¬ I tried many command: build, check, INSTALL, library , package.skeleton. But I still can't compile a package, Can anybody kindly give me an example about it?
Thanks.



Best Regards

YiYao Jiang  

Product Division/ product Testing Department
Semiconductor Manufacturing International Corporation
18 ZhangJiang Road, PuDong New Area, Shanghai  ZIP: 201203
Tel:86-21-5080-2000 Ext. 15173



From YiYao_Jiang at smics.com  Tue Sep 28 08:59:39 2004
From: YiYao_Jiang at smics.com (YiYao_Jiang)
Date: Tue, 28 Sep 2004 14:59:39 +0800
Subject: [R] (no subject)
Message-ID: <CD0374F1F9FDC842A5CFBEA4906FDC2501FD5091@ex103.smic-sh.com>

******************************
Could you perhaps describe exactly what "can't compile" means, please?
It's hard to know what you've tried without a little more information.
******************************

1). I type these command:

         f <- function(x,y) x+y
         g <- function(x,y) x-y
         d <- data.frame(a=1,b=2)
         e <- rnorm(1000)
         package.skeleton(list=c("f","g","d","e"), name="AnExample")

This is an example in "package.skeleton" . And I find a new folder "AnExample" created in "D:\ R\ rw109\ ". Enter the  "AnExample" folder , there are 4 folders "data", "mam", "R","src" and 2 files "DESCRIPTION" and "README". 
 
2). I type "> search()" but no "AnExample". What should I do to setup the package?

Thanks.


Best Regards

YiYao Jiang  

Product Division/ product Testing Department
Semiconductor Manufacturing International Corporation
18 ZhangJiang Road, PuDong New Area, Shanghai  ZIP: 201203
Tel:86-21-5080-2000 Ext. 15173



From poizot at cnam.fr  Tue Sep 28 09:29:56 2004
From: poizot at cnam.fr (Poizot Emmanuel)
Date: Tue, 28 Sep 2004 09:29:56 +0200
Subject: [R] array construction
Message-ID: <200409280929.56959.poizot@cnam.fr>

Hi all,

I've got a file of the following format:

X  Y  Z  u  v  w
0  0  0  x  x  x
0  0  1  x  x  x
0  0  2  x  x  x
..  ..  ..  ..  ..  ..
0  1  0  x  x  x
0  1  1  x  x  x
0  1  2  x  x  x
..  ..  ..  ..  ..  ..
1  0  0  x  x  x
1  0  1  x  x  x
1  0  2  x  x  x
........ etc

x stand for decimal values
X coordinate is 3h, Y and Z are h length.
I read that file with:
data <- read.table("filename", fill=T)
I extract coordinates with:
coord <- data[1:length,1:3]    with length the number of lines of the file
I get the x values with:
values<-data[1:length,4:6]

I would like now to create an 3D array storing the values on the correct 
order:
uvw <- array(data[1:length],dim=c(3h,h,h))   with h predifened of course

Is that command correct ?

-- 
Cordialement
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Emmanuel Poizot
Cnam/Intechmer
B.P. 324
50103 Cherbourg Cedex
T??l: (33)(0)233887342
Fax: (33)(0)233887339
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Sep 28 09:38:00 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue, 28 Sep 2004 09:38:00 +0200
Subject: [R] An index of all possible combinations of variables in a
	datafram e
References: <BC4231C30D143F43BFD514168020196935DA7C@lurch>
Message-ID: <006801c4a52e$16983910$b2133a86@www.domain>

Hi Alan,

you could also try the following function which has been submitted to 
s-news some time ago:

powerSet <- function(x){
 if(length(x)==0) return(vector(mode(x), 0))
 x <- sort(unique(x))
 K <- NULL
 for(m in x) K <- rbind(cbind(K, FALSE), cbind(K, TRUE))
 out <- apply(K, 1, function(x, s) s[x], s=x)[-1]
 names(out) <- NULL
 return(out)
}

powerSet(1:5)

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Alan Simpson" <alan.simpson at robertsresearch.com.au>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, September 28, 2004 6:51 AM
Subject: [R] An index of all possible combinations of variables in a 
datafram e


> Hello list
>
> Does anybody know of any way to create an index of all the possible
> combinations of variables (factors) in a data frame? ie for 3 
> factors A, B &
> C we have
>
> A
> B
> C
> AB
> AC
> BC
> ABC
>
> which equates to columns 1, 2, 3, 1:2, (1,3), 2:3 and 1:3.
>
> I realise that a function like model.matrix does this, but how to 
> get the
> seqence of the index?
>
> Any help would be greatly appreciated.
>
> Regards
>
> Alan Simpson
> Roberts Research Group
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From xiyanlon at yahoo.com  Tue Sep 28 09:52:27 2004
From: xiyanlon at yahoo.com (Xiyan Lon)
Date: Tue, 28 Sep 2004 00:52:27 -0700 (PDT)
Subject: [R] random discrete from the first tuple
Message-ID: <20040928075227.33640.qmail@web52008.mail.yahoo.com>

Dear UseR
I have a dataset, for instance x1(A, B, C), x2(M,F),
x3(X1,X2,X3,X4) and x4(W,F,P). I want to make a small
dataset with the random tuple. I know package e1071
can handle a random discrete,

> library(e1071)
> x1 <- rdiscrete(6, c(2,2,2),c("A","B","C"))
> x2 <- rdiscrete(6, c(3,3),c("M","F"))
> x3 <- rdiscrete(6,
c(2,2,1,1),c("X1","X2","X3","X4"))
> x4 <- rdiscrete(6, c(2,2,2),c("W","F","P"))
> x  <- data.frame(cbind(x1,x2,x3,x4))
> x
 x1 x2 x3 x4
1  C  F X1  F
2  B  M X2  F
3  A  F X2  W
4  A  F X2  F
5  C  M X3  P
6  A  F X1  F
>

but I want to make from the first tuple only one
variable change to next tuple,

C  F  X1  F
B  F  X1  F
A  F  X1  F
C  M  X1  F
B  M  X1  F
A  M  X1  F
C  F  X2  F
B  F  X2  F
A  F  X2  F
C  M  X2  F
B  M  X2  F
A  M  X2  F
.
.
.
Are there any package can handle this problem.

Xiyan Lon



From a.trapletti at bluewin.ch  Tue Sep 28 10:16:25 2004
From: a.trapletti at bluewin.ch (Adrian Trapletti)
Date: Tue, 28 Sep 2004 10:16:25 +0200
Subject: [Fwd: [R] Re: tseries Package for R]
Message-ID: <41591DD9.3020202@bluewin.ch>



-------- Original Message --------
Subject: 	[R] Re: tseries Package for R
Date: 	Mon, 27 Sep 2004 23:56:34 -0800
From: 	Martin Renner <martin.renner at stonebow.otago.ac.nz>
To: 	Adrian Trapletti <a.trapletti at bluewin.ch>
References: 	<61CBB4C9-10C7-11D9-A624-000D932E990C at comcast.net> 
<4158F5B6.3020103 at bluewin.ch>



see http://cran.stat.ucla.edu/bin/macosx/ and
http://cran.stat.ucla.edu/bin/macosx/RMacOSX-FAQ.html

(or your nearest cran-mirror).

The gui allows you to installe precompiled binaries.


>Wizon wrote:
>
>>I am using Mac OSX.  I am first starting to use R and have not 
>>installed any packages yet.  I searched through the CRAN site for a 
>>Mac OSX version, but did not find one.  I downloaded the tar.gz 
>>package.  Will this work on the Mac?  Is there a way to get a 
>>package that I don't have to compile?  Thanks in advance for your 
>>help.
>>
>>Adam
>>
>Dear Adam
>
>Sorry, I can't help you since I never used R under MacOS. However, I 
>cc your mail to R-help. Maybe you get some feedback from there.
>
>Best regards
>Adrian
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From christoph.lehmann at gmx.ch  Tue Sep 28 10:13:13 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Tue, 28 Sep 2004 10:13:13 +0200
Subject: [R] memory increase for large  r simulation
In-Reply-To: <20040928060948.13485.qmail@web25101.mail.ukl.yahoo.com>
References: <20040928060948.13485.qmail@web25101.mail.ukl.yahoo.com>
Message-ID: <41591D19.8000107@gmx.ch>

I don't know your details, but some remarks, which might be concerned 
with memory problems under windows

(1) consider e.g. linux, which is better able to manage 2Gb of RAM.

(2) look at the gc() (garbage collector): call it after a rm() command, 
to really free memory

(3)allocate memory for arrays this way:
x <- rep(0, 64 * 64 * 16 * 1000)
dim(x) <- c(64,64,16,1000)
and call gc() after this definition, since even this way twice the 
memory necessary for x is assigned

Cheers

Christoph

shane stanton wrote:
> Hi,
> 
> I am running R from windows 95. I have a large
> simulation, which R does not get very far through
> before telling me:
> 
> "error  cannot allocate vector of size 871875 Kb"
> 
> and warning message "reached total allocation of 127
> Mb"
> 
> I have been trying to increase the memory allocation
> to R from my computer, using various commands at the R
> prompt, such as memory.limit(size=......) to which R
> responds "NULL" or "cannot decrease memory limit" (no
> matter how large I try to make the argument of
> memory.limit. 
> 
> Does anybody have any ideas re how I can get this
> simulation to run?
> 
> Many thanks,
> 
> Shane Stanton
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From ligges at statistik.uni-dortmund.de  Tue Sep 28 10:19:13 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 28 Sep 2004 10:19:13 +0200
Subject: [R] (no subject)
In-Reply-To: <CD0374F1F9FDC842A5CFBEA4906FDC2501FD5091@ex103.smic-sh.com>
References: <CD0374F1F9FDC842A5CFBEA4906FDC2501FD5091@ex103.smic-sh.com>
Message-ID: <41591E81.1050803@statistik.uni-dortmund.de>

YiYao_Jiang wrote:

> ******************************
> Could you perhaps describe exactly what "can't compile" means, please?
> It's hard to know what you've tried without a little more information.
> ******************************
> 
> 1). I type these command:
> 
>          f <- function(x,y) x+y
>          g <- function(x,y) x-y
>          d <- data.frame(a=1,b=2)
>          e <- rnorm(1000)
>          package.skeleton(list=c("f","g","d","e"), name="AnExample")
> 
> This is an example in "package.skeleton" . And I find a new folder "AnExample" created in "D:\ R\ rw109\ ". Enter the  "AnExample" folder , there are 4 folders "data", "mam", "R","src" and 2 files "DESCRIPTION" and "README". 
>  
> 2). I type "> search()" but no "AnExample". What should I do to setup the package?
> 
> Thanks.


As you already have been asked:
Please read the manual "Writing R Extensions"! It's in there!

Also read the content of the file  .../src/gnuwin32/readme.packages how
to setup an appropriate environment (since you are on Windows, what you
have not told us before).

Uwe Ligges

> 
> Best Regards
> 
> YiYao Jiang  
> 
> Product Division/ product Testing Department
> Semiconductor Manufacturing International Corporation
> 18 ZhangJiang Road, PuDong New Area, Shanghai  ZIP: 201203
> Tel:86-21-5080-2000 Ext. 15173
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Michael.Jacob at bruker-axs.de  Tue Sep 28 10:27:41 2004
From: Michael.Jacob at bruker-axs.de (Jacob, Michael J.)
Date: Tue, 28 Sep 2004 10:27:41 +0200
Subject: [R] Plotting large texts into pdf file
Message-ID: <BE8D670EB24788439EA310AEF622D37001951F50@MAILSRV.bruker-axs.de>

Is there an easy way to include larger amounts of text in a plot?
I need to include a text report in a pdf file that is automtically
created by a R script.

I open a pdf device, then create several plots which are nicely output
each on a page in
the resulting pdf file, then I want to append page(s) that contain only
text.

The best I came up with is the following:

# create a new page
frame()
# setup some dummy coordinate system
plot.window(c(0,10),c(0,10))
# read the report as whole file (vector of lines)
f <- readLines(filename)
# concatenate the first 50 lines into on string with lines separated by
\n newline
t <- paste(f[1:50], collapse="\n")
# output text
text(0, 5, t, pos=4, cex=0.8, xpd=NA)

The problem is that the text is always centered in some way (with pos =
4 vertically,
and I cant easily put it into several pages.

Is there an easier way to do this that I overlooked?

For automation reasons I would like to have R output the text directly
into the pdf.

Thanks in advance

Michael


**********************************************************************
Der Inhalt dieser E-Mail ist vertraulich und ausschliesslich fuer den bezeichneten Adressaten bestimmt. Wenn Sie nicht der vorgesehene Adressat dieser E-Mail oder dessen Vertreter sein sollten, so beachten Sie bitte, dass jede Form der Kenntnisnahme, Veroeffentlichung, Vervielfaeltigung oder Weitergabe des Inhalts dieser E-Mail unzulaessig ist. Wir bitten Sie, sich in diesem Fall mit dem Absender der E-Mail in Verbindung zu setzen.



From Bernhard.Pfaff at drkw.com  Tue Sep 28 10:53:26 2004
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Tue, 28 Sep 2004 10:53:26 +0200
Subject: [R] Plotting large texts into pdf file
Message-ID: <18D602BD42B7E24EB810D6454A58DB900A29BB67@ibfftce505.de.ad.drkw.net>

> 
> Is there an easy way to include larger amounts of text in a plot?
> I need to include a text report in a pdf file that is automtically
> created by a R script.
> 
> I open a pdf device, then create several plots which are nicely output
> each on a page in
> the resulting pdf file, then I want to append page(s) that 
> contain only
> text.
> 
> The best I came up with is the following:
> 
> # create a new page
> frame()
> # setup some dummy coordinate system
> plot.window(c(0,10),c(0,10))
> # read the report as whole file (vector of lines)
> f <- readLines(filename)
> # concatenate the first 50 lines into on string with lines 
> separated by
> \n newline
> t <- paste(f[1:50], collapse="\n")
> # output text
> text(0, 5, t, pos=4, cex=0.8, xpd=NA)
> 
> The problem is that the text is always centered in some way 
> (with pos =
> 4 vertically,
> and I cant easily put it into several pages.
> 
> Is there an easier way to do this that I overlooked?
> 
> For automation reasons I would like to have R output the text directly
> into the pdf.


Have you considered Sweave()? There is also a nice and well written tutorial
by Friedrich Leisch in R News:
 
Friedrich Leisch. Sweave, part I: Mixing R and LATEX. R News, 2(3):28-31,
December 2002
Friedrich Leisch. Sweave, part II: Package vignettes. R News, 3(2):21-24,
October 2003

as well as the referenced URLs within this tutorial.

HTH,
Bernhard

> 
> Thanks in advance
> 
> Michael
> 
> 
> **********************************************************************
> Der Inhalt dieser E-Mail ist vertraulich und ausschliesslich 
> fuer den bezeichneten Adressaten bestimmt. Wenn Sie nicht der 
> vorgesehene Adressat dieser E-Mail oder dessen Vertreter sein 
> sollten, so beachten Sie bitte, dass jede Form der 
> Kenntnisnahme, Veroeffentlichung, Vervielfaeltigung oder 
> Weitergabe des Inhalts dieser E-Mail unzulaessig ist. Wir 
> bitten Sie, sich in diesem Fall mit dem Absender der E-Mail 
> in Verbindung zu setzen.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html


--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From ernesto at ipimar.pt  Tue Sep 28 11:22:57 2004
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Tue, 28 Sep 2004 10:22:57 +0100
Subject: [R] memory increase for large  r simulation
In-Reply-To: <20040928060948.13485.qmail@web25101.mail.ukl.yahoo.com>
References: <20040928060948.13485.qmail@web25101.mail.ukl.yahoo.com>
Message-ID: <1096363377.6232.17.camel@mordor.ipimar.pt>

On Tue, 2004-09-28 at 07:09, shane stanton wrote:
> Hi,
> 
> I am running R from windows 95. I have a large
> simulation, which R does not get very far through
> before telling me:
> 
> "error  cannot allocate vector of size 871875 Kb"
> 
> and warning message "reached total allocation of 127
> Mb"
> 
> I have been trying to increase the memory allocation
> to R from my computer, using various commands at the R
> prompt, such as memory.limit(size=......) to which R
> responds "NULL" or "cannot decrease memory limit" (no
> matter how large I try to make the argument of
> memory.limit. 
> 
> Does anybody have any ideas re how I can get this
> simulation to run?
> 
> Many thanks,
> 
> Shane Stanton
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Hi Shane,

I had a similar problem and the way to go over it is to save simulation
results to the disk and clean the workspace. 

Imagine you're running 1000 simulations and you save each result into a
list. You're object will grow and eat all you're memory. One way to go
is to save each simulation result to you're hard drive with "save" and
run the next simulation reusing the results object. That way you keep
memory requirements controlled. Off course you must be able to run one
simulation, if not than you should check you're code and try to improve
it. Something that might also help is to remove the results object after
saved to the hard drive.

Regards

EJ



From pbrouilly at gphy.campus.univ-poitiers.fr  Tue Sep 28 11:09:53 2004
From: pbrouilly at gphy.campus.univ-poitiers.fr (pbrouilly@gphy.campus.univ-poitiers.fr)
Date: Tue, 28 Sep 2004 11:09:53 +0200
Subject: [R] replacing values in vector
Message-ID: <1096362593.41592a615beb2@gphy.campus.univ-poitiers.fr>

Hi everybody !!

I have a vector named v1 with a lot of values from 0 to 10.
Is there a solution to replace all 0 by 1 ??

I have tried with a 'FOR' loop...

Thank you very much



From dimitris.rizopoulos at med.kuleuven.ac.be  Tue Sep 28 11:35:29 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Tue, 28 Sep 2004 11:35:29 +0200
Subject: [R] replacing values in vector
References: <1096362593.41592a615beb2@gphy.campus.univ-poitiers.fr>
Message-ID: <003f01c4a53e$7dda9950$b2133a86@www.domain>

just use

v1[v1==0] <- 1

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: <pbrouilly at gphy.campus.univ-poitiers.fr>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, September 28, 2004 11:09 AM
Subject: [R] replacing values in vector


> Hi everybody !!
>
> I have a vector named v1 with a lot of values from 0 to 10.
> Is there a solution to replace all 0 by 1 ??
>
> I have tried with a 'FOR' loop...
>
> Thank you very much
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From f.harrell at vanderbilt.edu  Tue Sep 28 11:38:27 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 28 Sep 2004 05:38:27 -0400
Subject: [R] Re: [Hmisc] proposal for change in latex.summary.formula.reverse
In-Reply-To: <m3vfdzlz5t.fsf@pdrechsler.fqdn.th-h.de>
References: <m3wtyh8bgg.fsf@pdrechsler.fqdn.th-h.de>
	<m3vfdzlz5t.fsf@pdrechsler.fqdn.th-h.de>
Message-ID: <41593113.6080509@vanderbilt.edu>

Patrick Drechsler wrote:
> Hi,
> 
> well, it wasn't a Sweave problem after all. Seems to have
> something to do with the function
> `latex.summary.formula.reverse' in the package Hmisc.
> 
> Following change seems to help (at least for my purpose):
> 
> --8<------------------------schnipp------------------------->8---
> *** /usr/local/lib/R/library/Hmisc/R/Hmisc	2004-09-28 07:37:26.000000000 +0200
> --- /usr/local/lib/R/library/Hmisc/R/Hmisc.original	2004-09-28 07:38:28.000000000 +0200
> ***************
> *** 16156,16162 ****
>                         'Numbers after percents are frequencies.',
>                         sep="\n")
>         if(length(testUsed))
> !         legend <-paste(legend,'\n\n',
>                          if(length(testUsed)==1)'Test used:' else 'Tests used:',
>                          if(length(testUsed)==1) paste(testUsed,'test') else
>                          paste(paste('$^{',1:length(testUsed),'}$',testUsed,
> --- 16156,16162 ----
>                         'Numbers after percents are frequencies.',
>                         sep="\n")
>         if(length(testUsed))
> !         legend <-paste(legend,'\\\\\n','\n\n',
>                          if(length(testUsed)==1)'Test used:' else 'Tests used:',
>                          if(length(testUsed)==1) paste(testUsed,'test') else
>                          paste(paste('$^{',1:length(testUsed),'}$',testUsed,
> --8<------------------------schnapp------------------------->8---
> 
> But since my knowledge of R is rather small I have no idea if
> these has any other drawbacks.
> 
> Any comments?
> 
> How would I go about changing this for my setup only? Is
> renaming Hmisc to something like pdHmisc ok?

That's not the way to go.  It's best to contact the package maintainer 
(e.g., me) with a request.  I did not save your first message as it did 
not refer to Hmisc or latex.* so if you can send it to me, state the 
problem, and show me the exact portions of commands you are suggesting 
to change, I'll try to incorporate into the master file.

Frank Harrell

> 
> Patrick


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From B.Rowlingson at lancaster.ac.uk  Tue Sep 28 11:56:07 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 28 Sep 2004 10:56:07 +0100
Subject: [R] Displaying environment differences
Message-ID: <41593537.9040802@lancaster.ac.uk>

Sometimes after playing around in R for a while, I find myself thinking, 
"What have I done?". Which boils down to "What's the difference between 
the objects I currently have in my R session and those that were loaded 
from my .RData when I started R".

So I bashed this out in five minutes, just to test the principles.

differ <- function(file){
   load(file)
   inFile <- ls()
   inMemory <- ls(1)

   inBoth <- inFile[inFile %in% inMemory]

   for(thing in inBoth){
     if(identical(get(thing,1),get(thing))){
       cat(paste("Object :",thing," identical\n"))
     }else{
       cat(paste("Object :",thing," changed\n"))
     }
   }

   list(inFile,inMemory,inBoth)
}

  Eventually I'd make it display objects only in the .RData (these would 
be things deleted since load), only in environment 1 (things newly 
created since load), those in both but unchanged, and those in both yet 
changed.

  But then I thought, "Hey, its coffee time, lets see if anyone on 
R-help has done this already and when I get back refreshed it'll be done".

  I'm also not sure if 'get()'ting the things is the right thing to do.

Barry



From sdavis2 at mail.nih.gov  Tue Sep 28 12:13:03 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 28 Sep 2004 06:13:03 -0400
Subject: [R] Gridbase basic question
In-Reply-To: <41588CD7.1050103@stat.auckland.ac.nz>
References: <E6ED8BE8-0D71-11D9-B970-000A95D7BA10@mail.nih.gov>
	<41588CD7.1050103@stat.auckland.ac.nz>
Message-ID: <FB8849C8-1136-11D9-AA48-000A95D7BA10@mail.nih.gov>

Paul,

Thanks for the extensive and clear explanation.  The reason I started  
with grid is that I am hoping to use a combination of segments,  
rectangles, and text to describe relatively complex (genes) objects  
that relate to the x-axis in a plot.  I do appreciate the insight from  
you and others that the added complexity of grid may not be necessary.

Sean

On Sep 27, 2004, at 5:57 PM, Paul Murrell wrote:

> Hi
>
>
> Sean Davis wrote:
>> All,
>> I have a simple plot(x,y) and I would like to then insert rectangles  
>> of  some length (in native coordinates) and height fixed to 0.5 in  
>> native  coordinates.  I can't quite get the code right to do this.   
>> Can anyone  give me a quick example of how to do this?  I looked the  
>> gridBase index  and the tutorial (from R-news?) but just haven't  
>> gotten it down yet.
>>  > plot(1:10,1:10)
>>  > par(new=T);vps <- baseViewports()
>>  > pushViewport(vps$inner,vps$figure,vps$plot)
>> viewport[GRID.VP.28]
>
>
> At this point you are within a viewport which has x- and y-scales  
> corresponding to the plot(1:10, 1:10).
>
>
>>  > pushViewport(viewport(x=unit(1,"native"),y=unit(2,"native")))
>> viewport[GRID.VP.29]
>
>
> You have just created a new viewport at location (1, 2) in the plot,  
> but  the scales on this new viewport are the default (0, 1).  i.e.,  
> you are now in a completely different coordinate system.  Also, this  
> new viewport is as wide and as high as the plot region -- for example,  
> it extends well beyong the left edge of the window/page.
>
>
>> grid.rect(height=unit(0.5,"native"),width=unit(1.5,"native"),just='bot 
>> to m')
>
>
> This draws a rectangle half as high as the current viewport and 1.5  
> times as wide (the native scale in the current viewport is (0, 1) in  
> both dimensions).  Importantly, the "native" coordinate systems you  
> are referring to no longer correspond to the scales on the plot.
>
>
>> This draws a very large rectangle going from 2 to 7 (y) and to 8 (x).
>
>
> Three things:
>
> (i) If drawing rectangles relative to the current "native" (or user)  
> coordinates is all you want to do then you could just use rect() and  
> ignore gridBase altogether.  For example, ...
>
> x <- sample(1:10, 10)
> y <- 1:10
> w <- runif(10)
> h <- 0.5
>
> plot(1:10,1:10)
> rect(x - w/2, y - h/2, x + w/2, y + h/2)
>
>
> (ii) Using grid and gridBase, the above example becomes ...
>
> plot(1:10,1:10)
> par(new=T);vps <- baseViewports()
> pushViewport(vps$inner,vps$figure,vps$plot)
> grid.rect(x=x, y=y, width=w, height=h, default.units="native")
> popViewport(3)
>
> ... but as mentioned, this is like using a sledge hammer to kill a cat  
> or whatever the expression is.
>
> (iii) There would be justification in using grid and gridBase if you  
> want to draw more than just a rectangle, especially if you want to use  
> coordinates other than native.  Here's a trivial example (adds fixed  
> size "whiskers" to the corners of the rectangles) ...
>
> plot(1:10,1:10)
> par(new=T);vps <- baseViewports()
> pushViewport(vps$inner,vps$figure,vps$plot)
> for (i in 1:10) {
>   pushViewport(viewport(x=x[i], y=y[i], width=w[i], height=h,
>                         default.units="native"))
>   grid.rect()
>   grid.segments(0, 0, unit(-1, "mm"), unit(-1, "mm"))
>   grid.segments(0, 1, unit(-1, "mm"),
>                 unit(1, "npc") + unit(1, "mm"))
>   grid.segments(1, 1,
>                 unit(1, "npc") + unit(1, "mm"),
>                 unit(1, "npc") + unit(1, "mm"))
>   grid.segments(1, 0,
>                 unit(1, "npc") + unit(1, "mm"),
>                 unit(-1, "mm"))
>   popViewport()
> }
>
> ... (but pushing a viewport per data point like this is a LOT slower).
>
> Hope that helps
>
> Paul
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/



From josep.perarnau at upc.es  Tue Sep 28 11:38:12 2004
From: josep.perarnau at upc.es (Josep Perarnau)
Date: Tue, 28 Sep 2004 11:38:12 +0200
Subject: [R] S latex listings
Message-ID: <000101c4a53e$df454230$6703a8c0@BAETULO>

Hello,

I would like to insert S code to my latex document. I was looking for a
listings package that supports S. In www.r-project.or in the
software/other section there is an item with a link to latex package
listings, but it seems that the link is broken. Does anybody know an
alternative to get the package?

Thanks in advance,



From josh8912 at yahoo.com  Tue Sep 28 12:29:51 2004
From: josh8912 at yahoo.com (J)
Date: Tue, 28 Sep 2004 03:29:51 -0700 (PDT)
Subject: [R] changing the number of tic marks on a plot
Message-ID: <20040928102952.27255.qmail@web51706.mail.yahoo.com>

Hello everyone.  Im quite new to R and have been
trying all night to simply change the number of tic
marks on a log graph...I would love a simple example
if anyone could offer one.  My plot statement looks
like this:

plot(cbind(c(minx,maxx),c(miny,maxy)),type="n",log="x",
main = "title", xlab= "dose", lab=c(2,2,7))

minx and maxx are the min and max values of x, same
goes for miny,maxy.  Once it is created, I draw three
different lines onto this basic plot.  Ive tried every
combination of par commands I can think of, but
nothing seems to change the number of tic marks.  And
how do you get minor and major tic marks?  I dont
suppose there is any automatic way to place a legend
where it covers the fewest points, is there?  Thanks
much.  John


		
_______________________________

Declare Yourself - Register online to vote today!



From vikas at mail.jnu.ac.in  Tue Sep 28 12:34:22 2004
From: vikas at mail.jnu.ac.in (Vikas Rawal)
Date: Tue, 28 Sep 2004 16:04:22 +0530
Subject: [R] add-on packages
Message-ID: <41593E2E.3050405@mail.jnu.ac.in>

I want to add RMySQL and RODBC packages to my R installation on redhat 
linux box. The command install.packages gives following output. What 
could be wrong?


********************
install.packages(RMySQL)
trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 202145 bytes
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... .......
downloaded 197Kb

Error in unique(pkgs) : Object "RMySQL" not found
**********************

Vikas



From copellifulvio at yahoo.it  Tue Sep 28 12:34:27 2004
From: copellifulvio at yahoo.it (Fulvio Copex)
Date: Tue, 28 Sep 2004 12:34:27 +0200 (CEST)
Subject: [R] call R scripts from python
Message-ID: <20040928103427.79154.qmail@web86907.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040928/4d8f1425/attachment.pl

From josh8912 at yahoo.com  Tue Sep 28 12:46:44 2004
From: josh8912 at yahoo.com (J)
Date: Tue, 28 Sep 2004 03:46:44 -0700 (PDT)
Subject: [R] Re: changing the number of tic marks on a plot
Message-ID: <20040928104644.37362.qmail@web51701.mail.yahoo.com>

Ah, I just figured it out.  You change the number of
tic marks using the axis() function.  I tried variious
par() statments but that did not seem to do anything. 

John



From patrick.drechsler at gmx.net  Tue Sep 28 12:49:44 2004
From: patrick.drechsler at gmx.net (Patrick Drechsler)
Date: Tue, 28 Sep 2004 12:49:44 +0200
Subject: [R] Re: [Hmisc] proposal for change in
	latex.summary.formula.reverse
References: <m3wtyh8bgg.fsf@pdrechsler.fqdn.th-h.de>
	<m3vfdzlz5t.fsf@pdrechsler.fqdn.th-h.de>
	<41593113.6080509@vanderbilt.edu>
Message-ID: <m3oejq1xdj.fsf@pdrechsler.fqdn.th-h.de>

Hi Frank,

Frank E. Harrell, Jr. wrote on 28 Sep 2004 10:38:27 MET:

[snip]
> That's not the way to go.  It's best to contact the package
> maintainer (e.g., me) with a request.

Ok, personal mail sent.

Cheers

Patrick
-- 
Millions long for immortality who do not know what to do with
themselves on a rainy Sunday afternoon.
		-- Susan Ertz



From ramasamy at cancer.org.uk  Tue Sep 28 12:54:01 2004
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 28 Sep 2004 11:54:01 +0100
Subject: [R] An index of all possible combinations of variables in a
	datafram e
In-Reply-To: <006801c4a52e$16983910$b2133a86@www.domain>
References: <BC4231C30D143F43BFD514168020196935DA7C@lurch>
	<006801c4a52e$16983910$b2133a86@www.domain>
Message-ID: <1096368841.3061.15.camel@ndmpc126.ihs.ox.ac.uk>

Alternatively you can use the combinations() function in gregmisc.

library(gregmisc)
n <- 3
sapply(1:n, function(x) apply(combinations(n, x, LETTERS[1:n]), 1, 
paste, collapse="") )

Here is the same code written with a for loop
n <- 3
out <- NULL
for(i in 1:n){
  tmp <- combinations(n, i, LETTERS[1:n])
  out <- c(out, apply(tmp, 1, paste, collapse=""))
}
out
[1] "A"   "B"   "C"   "AB"  "AC"  "BC"  "ABC"




On Tue, 2004-09-28 at 08:38, Dimitris Rizopoulos wrote:
> Hi Alan,
> 
> you could also try the following function which has been submitted to 
> s-news some time ago:
> 
> powerSet <- function(x){
>  if(length(x)==0) return(vector(mode(x), 0))
>  x <- sort(unique(x))
>  K <- NULL
>  for(m in x) K <- rbind(cbind(K, FALSE), cbind(K, TRUE))
>  out <- apply(K, 1, function(x, s) s[x], s=x)[-1]
>  names(out) <- NULL
>  return(out)
> }
> 
> powerSet(1:5)
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/396887
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message ----- 
> From: "Alan Simpson" <alan.simpson at robertsresearch.com.au>
> To: <r-help at stat.math.ethz.ch>
> Sent: Tuesday, September 28, 2004 6:51 AM
> Subject: [R] An index of all possible combinations of variables in a 
> datafram e
> 
> 
> > Hello list
> >
> > Does anybody know of any way to create an index of all the possible
> > combinations of variables (factors) in a data frame? ie for 3 
> > factors A, B &
> > C we have
> >
> > A
> > B
> > C
> > AB
> > AC
> > BC
> > ABC
> >
> > which equates to columns 1, 2, 3, 1:2, (1,3), 2:3 and 1:3.
> >
> > I realise that a function like model.matrix does this, but how to 
> > get the
> > seqence of the index?
> >
> > Any help would be greatly appreciated.
> >
> > Regards
> >
> > Alan Simpson
> > Roberts Research Group
> >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From wolski at molgen.mpg.de  Tue Sep 28 12:53:53 2004
From: wolski at molgen.mpg.de (Witold Eryk Wolski)
Date: Tue, 28 Sep 2004 12:53:53 +0200
Subject: [R] add-on packages
In-Reply-To: <41593E2E.3050405@mail.jnu.ac.in>
References: <41593E2E.3050405@mail.jnu.ac.in>
Message-ID: <415942C1.7030508@molgen.mpg.de>

Hi!


install.packages("RMySQL")
                         ^               ^
note the parenthesis

/E

Vikas Rawal wrote:

> I want to add RMySQL and RODBC packages to my R installation on redhat 
> linux box. The command install.packages gives following output. What 
> could be wrong?
>
>
> ********************
>
> trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
> Content type `text/plain; charset=iso-8859-1' length 202145 bytes
> opened URL
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... .......
> downloaded 197Kb
>
> Error in unique(pkgs) : Object "RMySQL" not found
> **********************
>
> Vikas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>


-- 
Dipl. bio-chem. Witold Eryk Wolski         
MPI-Moleculare Genetic
Ihnestrasse 63-73 14195 Berlin           _
tel: 0049-30-83875219                   'v'
http://www.molgen.mpg.de/~wolski       /   \
mail: witek96 at users.sourceforge.net  ---W-W----
      wolski at molgen.mpg.de



From sdavis2 at mail.nih.gov  Tue Sep 28 12:55:16 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 28 Sep 2004 06:55:16 -0400
Subject: [R] add-on packages
In-Reply-To: <41593E2E.3050405@mail.jnu.ac.in>
References: <41593E2E.3050405@mail.jnu.ac.in>
Message-ID: <E1DC8DDD-113C-11D9-AA48-000A95D7BA10@mail.nih.gov>

I believe you need quotes around RMySQL.

Try:

install.packages("RMySQL")


On Sep 28, 2004, at 6:34 AM, Vikas Rawal wrote:

> I want to add RMySQL and RODBC packages to my R installation on redhat 
> linux box. The command install.packages gives following output. What 
> could be wrong?
>
>
> ********************
> install.packages(RMySQL)
> trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
> Content type `text/plain; charset=iso-8859-1' length 202145 bytes
> opened URL
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... .......
> downloaded 197Kb
>
> Error in unique(pkgs) : Object "RMySQL" not found
> **********************
>
> Vikas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From patrick.drechsler at gmx.net  Tue Sep 28 12:57:34 2004
From: patrick.drechsler at gmx.net (Patrick Drechsler)
Date: Tue, 28 Sep 2004 12:57:34 +0200
Subject: [R] S latex listings
References: <000101c4a53e$df454230$6703a8c0@BAETULO>
Message-ID: <m3k6ue1x0h.fsf@pdrechsler.fqdn.th-h.de>


Josep Perarnau wrote on 28 Sep 2004 10:38:12 MET:

[...search of listings package for latex...]

<URL:http://www.ctan.org/tex-archive/macros/latex/contrib/listings/>

HTH

Patrick
-- 
I hate quotations.  Tell me what you know.  (Ralph Waldo Emerson)



From ligges at statistik.uni-dortmund.de  Tue Sep 28 12:57:52 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 28 Sep 2004 12:57:52 +0200
Subject: [R] add-on packages
In-Reply-To: <41593E2E.3050405@mail.jnu.ac.in>
References: <41593E2E.3050405@mail.jnu.ac.in>
Message-ID: <415943B0.9020004@statistik.uni-dortmund.de>

Vikas Rawal wrote:

> I want to add RMySQL and RODBC packages to my R installation on redhat 
> linux box. The command install.packages gives following output. What 
> could be wrong?
> 
> 
> ********************
> install.packages(RMySQL)
> trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
> Content type `text/plain; charset=iso-8859-1' length 202145 bytes
> opened URL
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... .......
> downloaded 197Kb
> 
> Error in unique(pkgs) : Object "RMySQL" not found
> **********************


There is no *object* RMySQL in your workspace. Quite probably you mean 
the package RMySQL. You have to quote the name:

install.packages("RMySQL")

Uwe Ligges

> Vikas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From vikas at mail.jnu.ac.in  Tue Sep 28 12:59:24 2004
From: vikas at mail.jnu.ac.in (Vikas Rawal)
Date: Tue, 28 Sep 2004 16:29:24 +0530
Subject: [R] add-on packages
In-Reply-To: <415942C1.7030508@molgen.mpg.de>
References: <41593E2E.3050405@mail.jnu.ac.in> <415942C1.7030508@molgen.mpg.de>
Message-ID: <4159440C.9020202@mail.jnu.ac.in>

Thanks. That was simple.

Vikas
Witold Eryk Wolski wrote:

> Hi!
>
>
> install.packages("RMySQL")
>                         ^               ^
> note the parenthesis
>
> /E
>
> Vikas Rawal wrote:
>
>> I want to add RMySQL and RODBC packages to my R installation on 
>> redhat linux box. The command install.packages gives following 
>> output. What could be wrong?
>>
>>
>> ********************
>>
>> trying URL `http://cran.r-project.org/src/contrib/PACKAGES'
>> Content type `text/plain; charset=iso-8859-1' length 202145 bytes
>> opened URL
>> .......... .......... .......... .......... ..........
>> .......... .......... .......... .......... ..........
>> .......... .......... .......... .......... ..........
>> .......... .......... .......... .......... .......
>> downloaded 197Kb
>>
>> Error in unique(pkgs) : Object "RMySQL" not found
>> **********************
>>
>> Vikas
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>
>



From cdeclercq at nordnet.fr  Tue Sep 28 12:59:29 2004
From: cdeclercq at nordnet.fr (Christophe Declercq)
Date: Tue, 28 Sep 2004 12:59:29 +0200
Subject: [R] S latex listings
In-Reply-To: <000101c4a53e$df454230$6703a8c0@BAETULO>
Message-ID: <MJELLLFFFCNHMHOOLCMBAEFMCLAA.cdeclercq@nordnet.fr>



> De : r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]De la part de Josep Perarnau
> Envoye : mardi 28 septembre 2004 10:38
> A : r-help at stat.math.ethz.ch
> Objet : [R] S latex listings
>
>
> Hello,
>
> I would like to insert S code to my latex document. I was looking for a
> listings package that supports S. In www.r-project.or in the
> software/other section there is an item with a link to latex package
> listings, but it seems that the link is broken. Does anybody know an
> alternative to get the package?
[...]

Try the TeX catalogue online:
http://www.tug.org/tex-archive/help/Catalogue/brief.html

You will find that you can get the 'listings' package at:
http://www.tug.org/tex-archive/macros/latex/contrib/listings/


Christophe
--
Christophe Declercq, MD
Observatoire regional de la sante Nord-Pas-de-Calais
13, rue Faidherbe
F-59046 LILLE Cedex
Phone 33 3 20 15 49 24
Fax 33 3 20 55 92 30
E-mail c.declercq at orsnpdc.org



From B.Rowlingson at lancaster.ac.uk  Tue Sep 28 13:08:47 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 28 Sep 2004 12:08:47 +0100
Subject: [R] call R scripts from python
In-Reply-To: <20040928103427.79154.qmail@web86907.mail.ukl.yahoo.com>
References: <20040928103427.79154.qmail@web86907.mail.ukl.yahoo.com>
Message-ID: <4159463F.5010109@lancaster.ac.uk>

Fulvio Copex wrote:

> I know this can be a bit OT, but is there a function in python accomplishing the same task?

os.popen - opens a pipe to a command:

[unixy example]

#!/usr/bin/python
import os
catter=os.popen("cat","w")
catter.write( "hello" )


  http://docs.python.org/ is very useful.

  There are other R-Python integration methods, try this:

http://www.omegahat.org/RSPython/index.html

Barry



From vikas at mail.jnu.ac.in  Tue Sep 28 13:11:01 2004
From: vikas at mail.jnu.ac.in (Vikas Rawal)
Date: Tue, 28 Sep 2004 16:41:01 +0530
Subject: [R] read dbf files into R
Message-ID: <415946C5.60200@mail.jnu.ac.in>

I run R on redhat linux.
What would be the easiest way to read dbf files into R?

Vikas



From Nael-Al.Anaswah at WIWI.UNI-MUENSTER.DE  Tue Sep 28 13:46:04 2004
From: Nael-Al.Anaswah at WIWI.UNI-MUENSTER.DE (Nael Al Anaswah)
Date: Tue, 28 Sep 2004 13:46:04 +0200
Subject: [R] slow loops in Monte Carlo Simulations
Message-ID: <41596B1E.15238.67A8A93@WIWI.UNI-MUENSTER.DE>

Hi there,

I am running Monte Carlo Simulations in R using ordinary "while 
(condition)" loops. Since the number of iterations is something like 
100.000 and within each iteration a given subsample is extended 
sequentially it takes hours to run the simulation. 

Does anyone know if there is either a way to avoid using loops in 
Monte Carlo Simulations or how to include possible faster "c++" 
commands in R code?

many thanks in advance.

Nael Al-Anaswah



-----------------------------------------------------
Nael Al-Anaswah
Department of Econometrics
University of Muenster
Germany



From vito_ricci at yahoo.com  Tue Sep 28 13:54:28 2004
From: vito_ricci at yahoo.com (Vito Ricci)
Date: Tue, 28 Sep 2004 13:54:28 +0200 (CEST)
Subject: [R] read dbf files into R
Message-ID: <20040928115428.65877.qmail@web41214.mail.yahoo.com>

Hi,

read the manual: 
R Data Import/Export
http://cran.r-project.org/doc/manuals/R-data.pdf

Another way is to convert .dbf file in .txt and use
read.table(), scan() an similar.

Best
Vito


You wrote:

I run R on redhat linux.
What would be the easiest way to read dbf files into
R?

Vikas

=====
Diventare costruttori di soluzioni

"The business of the statistician is to catalyze 
the scientific learning process."  
George E. P. Box


Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml


		
___________________________________

http://it.seriea.fantasysports.yahoo.com/



From edd at debian.org  Tue Sep 28 14:08:06 2004
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 28 Sep 2004 07:08:06 -0500
Subject: [R] call R scripts from python
In-Reply-To: <4159463F.5010109@lancaster.ac.uk>
References: <20040928103427.79154.qmail@web86907.mail.ukl.yahoo.com>
	<4159463F.5010109@lancaster.ac.uk>
Message-ID: <20040928120806.GA16246@sonny.eddelbuettel.com>

On Tue, Sep 28, 2004 at 12:08:47PM +0100, Barry Rowlingson wrote:
> Fulvio Copex wrote:
> >I know this can be a bit OT, but is there a function in python 
> >accomplishing the same task?
[...]
>  There are other R-Python integration methods, try this:
> 
> http://www.omegahat.org/RSPython/index.html

RPy at Sourceforge (http://rpy.sf.net) is IMHO easier to set up and use.

Under Debian, this is as simple as 'apt-get install python-rpy'

Hth, Dirk

-- 
Those are my principles, and if you don't like them... well, I have others.
                                                -- Groucho Marx



From partha_bagchi at hgsi.com  Tue Sep 28 14:10:09 2004
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Tue, 28 Sep 2004 08:10:09 -0400
Subject: [R] read dbf files into R
Message-ID: <OF4800CAE3.5A4191D1-ON85256F1D.004288E0-85256F1D.0042D984@hgsi.com>

Have you checkout out "R Data Import / Export"? In particular, check out 
RODBC developed by Brian Ripley and Michael Lapsley.

HTH,
Partha





Vikas Rawal <vikas at mail.jnu.ac.in>
Sent by: r-help-bounces at stat.math.ethz.ch
09/28/2004 07:11 AM

 
        To:     r-help at stat.math.ethz.ch
        cc: 
        Subject:        [R] read dbf files into R


I run R on redhat linux.
What would be the easiest way to read dbf files into R?

Vikas

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From brandt at unt.edu  Tue Sep 28 14:18:19 2004
From: brandt at unt.edu (Patrick Brandt)
Date: Tue, 28 Sep 2004 07:18:19 -0500
Subject: [Fwd: [R] Re: tseries Package for R]
In-Reply-To: <41591DD9.3020202@bluewin.ch>
References: <41591DD9.3020202@bluewin.ch>
Message-ID: <7BB9422F-1148-11D9-9389-000A95AC74A2@unt.edu>

In R 1.9.1 for OSX 10.3.5 , install.packages("tseries") works fine, 
compiles correctly and seems to produce a working pkg just fine.

Patrick T. Brandt
Assistant Professor
Department of Political Science
University of North Texas
http://www.psci.unt.edu/~brandt

On Sep 28, 2004, at 3:16 AM, Adrian Trapletti wrote:

>
>
> -------- Original Message --------
> Subject: 	[R] Re: tseries Package for R
> Date: 	Mon, 27 Sep 2004 23:56:34 -0800
> From: 	Martin Renner <martin.renner at stonebow.otago.ac.nz>
> To: 	Adrian Trapletti <a.trapletti at bluewin.ch>
> References: 	<61CBB4C9-10C7-11D9-A624-000D932E990C at comcast.net> 
> <4158F5B6.3020103 at bluewin.ch>
>
>
>
> see http://cran.stat.ucla.edu/bin/macosx/ and
> http://cran.stat.ucla.edu/bin/macosx/RMacOSX-FAQ.html
>
> (or your nearest cran-mirror).
>
> The gui allows you to installe precompiled binaries.
>
>
>> Wizon wrote:
>>
>>> I am using Mac OSX.  I am first starting to use R and have not 
>>> installed any packages yet.  I searched through the CRAN site for a 
>>> Mac OSX version, but did not find one.  I downloaded the tar.gz 
>>> package.  Will this work on the Mac?  Is there a way to get a 
>>> package that I don't have to compile?  Thanks in advance for your 
>>> help.
>>>
>>> Adam
>>>
>> Dear Adam
>>
>> Sorry, I can't help you since I never used R under MacOS. However, I 
>> cc your mail to R-help. Maybe you get some feedback from there.
>>
>> Best regards
>> Adrian
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From andy_liaw at merck.com  Tue Sep 28 14:25:49 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 28 Sep 2004 08:25:49 -0400
Subject: [R] An index of all possible combinations of variables in a
	d ata frame
Message-ID: <3A822319EB35174CA3714066D590DCD504AF845B@usrymx25.merck.com>

This might be a bit of an abuse of the functions, but it seems to work:

> dat <- data.frame(A=1, B=2, C=3)
> f <- ~ .^3
> colnames(attr(terms(f, data=dat), "factors"))
[1] "A"     "B"     "C"     "A:B"   "A:C"   "B:C"   "A:B:C"

Cheers,
Andy

> From: Alan Simpson
> 
> Hello list
>  
> Does anybody know of any way to create an index of all the possible
> combinations of variables (factors) in a data frame? ie for 3 
> factors A, B &
> C we have 
>  
> A
> B
> C
> AB
> AC
> BC
> ABC
>  
> which equates to columns 1, 2, 3, 1:2, (1,3), 2:3 and 1:3.
>  
> I realise that a function like model.matrix does this, but 
> how to get the
> seqence of the index?
>  
> Any help would be greatly appreciated.
>  
> Regards
>  
> Alan Simpson
> Roberts Research Group
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From hi_ono2001 at ybb.ne.jp  Tue Sep 28 14:33:23 2004
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Tue, 28 Sep 2004 21:33:23 +0900 (JST)
Subject: [R] read dbf files into R
In-Reply-To: <OF4800CAE3.5A4191D1-ON85256F1D.004288E0-85256F1D.0042D984@hgsi.com>
Message-ID: <20040928123323.69516.qmail@web1708.mail.yahoo.co.jp>

 How about maptools package's internal function dbf.read?

 Try to use as follows.

 maptools:::dbf.read("test.dbf")

 maptools packages also has dbf.write, however it can only
write out integer data.


 Best wishes.

> 
> Vikas Rawal <vikas at mail.jnu.ac.in>
> Sent by: r-help-bounces at stat.math.ethz.ch
> 09/28/2004 07:11 AM
> 
>  
>         To:     r-help at stat.math.ethz.ch
>         cc: 
>         Subject:        [R] read dbf files into R
> 
> 
> I run R on redhat linux.
> What would be the easiest way to read dbf files into
> R?
> 
> Vikas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From martin at ist.org  Tue Sep 28 14:43:05 2004
From: martin at ist.org (martin@ist.org)
Date: Tue, 28 Sep 2004 12:43:05 -0000
Subject: [R] specifying exports for R CMD SHLIB
Message-ID: <twig.1096375385.9550@ist.org>

Hi,

How can I specify which functions should be exported when I build a 
shared library with 'R CMD SHLIB foo.c'??
I tried putting a file named foo.def in the same directory with the 
line 'EXPORTS' and the names of the functions to be exported, but the 
file is deleted in the build process.

Any help is appreciated, 

Martin Keller-Ressel



From ggrothendieck at myway.com  Tue Sep 28 14:44:02 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 28 Sep 2004 12:44:02 +0000 (UTC)
Subject: [R] An index of all possible combinations of variables in
	=?utf-8?b?YQlk?= ata frame
References: <3A822319EB35174CA3714066D590DCD504AF845B@usrymx25.merck.com>
Message-ID: <loom.20040928T143448-372@post.gmane.org>


And here is a variation on your idea of using the factors 
attribute of terms with some minor reductions, this one
returning a list of numeric vectors:

   fac <- attributes(terms(~ a * b * c))$factors
   apply(fac == 1, 2, which)

Liaw, Andy <andy_liaw <at> merck.com> writes:

: 
: This might be a bit of an abuse of the functions, but it seems to work:
: 
: > dat <- data.frame(A=1, B=2, C=3)
: > f <- ~ .^3
: > colnames(attr(terms(f, data=dat), "factors"))
: [1] "A"     "B"     "C"     "A:B"   "A:C"   "B:C"   "A:B:C"
: 
: Cheers,
: Andy
: 
: > From: Alan Simpson
: > 
: > Hello list
: >  
: > Does anybody know of any way to create an index of all the possible
: > combinations of variables (factors) in a data frame? ie for 3 
: > factors A, B &
: > C we have 
: >  
: > A
: > B
: > C
: > AB
: > AC
: > BC
: > ABC
: >  
: > which equates to columns 1, 2, 3, 1:2, (1,3), 2:3 and 1:3.
: >  
: > I realise that a function like model.matrix does this, but 
: > how to get the
: > seqence of the index?
: >  
: > Any help would be greatly appreciated.
: >  
: > Regards
: >  
: > Alan Simpson
: > Roberts Research Group
: >  
: > 
: > 	[[alternative HTML version deleted]]
: > 
: > ______________________________________________
: > R-help <at> stat.math.ethz.ch mailing list
: > https://stat.ethz.ch/mailman/listinfo/r-help
: > PLEASE do read the posting guide! 
: > http://www.R-project.org/posting-guide.html
: > 
: >
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://stat.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From B.Rowlingson at lancaster.ac.uk  Tue Sep 28 14:49:29 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 28 Sep 2004 13:49:29 +0100
Subject: [R] read dbf files into R
In-Reply-To: <20040928123323.69516.qmail@web1708.mail.yahoo.co.jp>
References: <20040928123323.69516.qmail@web1708.mail.yahoo.co.jp>
Message-ID: <41595DD9.600@lancaster.ac.uk>

Hisaji ONO wrote:

>  maptools:::dbf.read("test.dbf")
> 
>  maptools packages also has dbf.write, however it can only
> write out integer data.
> 

I'll stick my Rmap oar in. My Rmap package (not in CRAN) can access dbf
files using the dbf access library in shapelib. And instead of reading
the dbf file in, it creates a 'proxy' object that points to the dbf.

> admin <- dbfproxy("admin98.dbf")
Warning message:
Invalid names in DBF file, new names are:
 FIPS_ADMIN is now FIPS.ADMIN
GMI_ADMIN is now GMI.ADMIN
> names(admin)
 [1] "FIPS.ADMIN" "GMI.ADMIN"  "ADMIN.NAME" "FIPS.CNTRY" "GMI.CNTRY"
 [6] "CNTRY.NAME" "REGION"     "CONTINENT"  "POP.ADMIN"  "SQKM.ADMIN"
[11] "SQMI.ADMIN" "TYPE.ENG"   "TYPE.LOC"   "COLOR.MAP"
> dim(admin)
[1] 2604   14

 You can even subset it by rows and columns - it keeps the proxy nature
so the file doesn't change, the object just tracks the selected rows and
columns.

> admin
DBF proxy object, file is /home/rowlings/Geog/Maps/admin98.dbf
With 2604 rows and 14 columns
Selected from 2604 records with 14 items
> admin[1:4,]
DBF proxy object, file is /home/rowlings/Geog/Maps/admin98.dbf
With 4 rows and 14 columns
Selected from 2604 records with 14 items

 to get the actual data, use as.data.frame, or access columns with $NAME
syntax.

Of course Rmap is tricky to fully install, probably only works reliably
on Unix, leads to hair loss, etc etc.

Baz



From f.harrell at vanderbilt.edu  Tue Sep 28 14:54:16 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 28 Sep 2004 08:54:16 -0400
Subject: [R] S latex listings
In-Reply-To: <000101c4a53e$df454230$6703a8c0@BAETULO>
References: <000101c4a53e$df454230$6703a8c0@BAETULO>
Message-ID: <41595EF8.8020203@vanderbilt.edu>

Josep Perarnau wrote:
> Hello,
> 
> I would like to insert S code to my latex document. I was looking for a
> listings package that supports S. In www.r-project.or in the
> software/other section there is an item with a link to latex package
> listings, but it seems that the link is broken. Does anybody know an
> alternative to get the package?
> 
See http://biostat.mc.vanderbilt.edu/twiki/bin/view/Main/DocProcess for 
a Perl script that works with a LaTeX style to pretty-print S code snippets.

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From murdoch at stats.uwo.ca  Tue Sep 28 14:58:19 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 28 Sep 2004 08:58:19 -0400
Subject: [R] slow loops in Monte Carlo Simulations
In-Reply-To: <41596B1E.15238.67A8A93@WIWI.UNI-MUENSTER.DE>
References: <41596B1E.15238.67A8A93@WIWI.UNI-MUENSTER.DE>
Message-ID: <hpnil011ktbrt8ekjjmnrvh6tj446h47e8@4ax.com>

On Tue, 28 Sep 2004 13:46:04 +0200, "Nael Al Anaswah"
<Nael-Al.Anaswah at WIWI.UNI-MUENSTER.DE> wrote :

>Hi there,
>
>I am running Monte Carlo Simulations in R using ordinary "while 
>(condition)" loops. Since the number of iterations is something like 
>100.000 and within each iteration a given subsample is extended 
>sequentially it takes hours to run the simulation. 
>
>Does anyone know if there is either a way to avoid using loops in 
>Monte Carlo Simulations or how to include possible faster "c++" 
>commands in R code?

It'll be a lot faster if you assign your storage at the start:

 - a 100000 long vector to hold the results at the start
 - enough space to hold a full iteration at the start

Extending vectors is slow, because it requires a new allocation and a
copy operation.

The Writing R Extensions manual talks about linking C, C++ or Fortran
code into R.  It'll likely be faster, but if you need to allocated R
storage from within it, there's a bit of a learning curve.

Duncan Murdoch



From sam.kemp2 at ntlworld.com  Tue Sep 28 15:00:33 2004
From: sam.kemp2 at ntlworld.com (Samuel Kemp)
Date: Tue, 28 Sep 2004 14:00:33 +0100
Subject: [R] package error message
Message-ID: <41596071.2070200@ntlworld.com>

Hi,

I am trying to make my own package in Windows XP with R 1.9.1. using 
Rcmd build/ Rcmd.

The initial Rcmd build compiles ok with no error messages. However, when 
I run Rcmd check it runs ok up until

* checking for file 'GammaTest/DESCRIPTION' ... OK
* checking if this is a source package ... OK
* checking whether package 'GammaTest' can be installed ... ERROR
Installation failed.
See 'c:/Documents and Settings/Samuel Kemp/My Documents/R 
Files/GammaTest.Rcheck/00install.out' for details.

This file contains the following.....

installing R.css in c:/DOCUME~1/SAMUEL~1/MYDOCU~1/RFILES~1/GAMMAT~1.RCH


---------- Making package GammaTest ------------
  adding build stamp to DESCRIPTION
make[2]: *** No rule to make target `R/Create', needed by 
`c:/DOCUME~1/SAMUEL~1/MYDOCU~1/RFILES~1/GAMMAT~1.RCH/GammaTest/R/GammaTest'.  
Stop.
make[1]: *** [all] Error 2
make: *** [pkg-GammaTest] Error 2
*** Installation of GammaTest failed ***

Can anyone shed light on what it is trying to tell me?

Cheers,

Sam.



From ripley at stats.ox.ac.uk  Tue Sep 28 15:06:20 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Sep 2004 14:06:20 +0100 (BST)
Subject: [R] specifying exports for R CMD SHLIB
In-Reply-To: <twig.1096375385.9550@ist.org>
Message-ID: <Pine.LNX.4.44.0409281405090.28320-100000@gannet.stats>

What OS?

If this is Windows, you cannot (and why do you want to, as the DLL is just 
to be loaded into R?).

On Tue, 28 Sep 2004 martin at ist.org wrote:

> How can I specify which functions should be exported when I build a 
> shared library with 'R CMD SHLIB foo.c'??
> I tried putting a file named foo.def in the same directory with the 
> line 'EXPORTS' and the names of the functions to be exported, but the 
> file is deleted in the build process.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From HStevens at MUOhio.edu  Tue Sep 28 15:14:59 2004
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Tue, 28 Sep 2004 09:14:59 -0400
Subject: [R] Re: tseries Package for R
In-Reply-To: <4158F5B6.3020103@bluewin.ch>
References: <61CBB4C9-10C7-11D9-A624-000D932E990C@comcast.net>
	<4158F5B6.3020103@bluewin.ch>
Message-ID: <663F19CE-1150-11D9-9988-000A958F43CC@MUOhio.edu>

Load the R framework put together by Jan de Leeuw; Professor and Chair, 
UCLA Department of Statistics, available at http://gifi.stat.ucla.edu/
Hank
On Sep 28, 2004, at 1:25 AM, Adrian Trapletti wrote:

> Wizon wrote:
>
>> I am using Mac OSX.  I am first starting to use R and have not 
>> installed any packages yet.  I searched through the CRAN site for a 
>> Mac OSX version, but did not find one.  I downloaded the tar.gz 
>> package.  Will this work on the Mac?  Is there a way to get a package 
>> that I don't have to compile?  Thanks in advance for your help.
>>
>> Adam
>>
>>
> Dear Adam
>
> Sorry, I can't help you since I never used R under MacOS. However, I 
> cc your mail to R-help. Maybe you get some feedback from there.
>
> Best regards
> Adrian
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>
Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From chris.jackson at imperial.ac.uk  Tue Sep 28 15:18:39 2004
From: chris.jackson at imperial.ac.uk (Chris Jackson)
Date: Tue, 28 Sep 2004 14:18:39 +0100
Subject: [R] An index of all possible combinations of variables in a data
	fram e
In-Reply-To: <BC4231C30D143F43BFD514168020196935DA7C@lurch>
References: <BC4231C30D143F43BFD514168020196935DA7C@lurch>
Message-ID: <415964AF.8000206@imperial.ac.uk>

Yet another solution might be to abuse expand.grid:

dat <- expand.grid(rep(list(c(FALSE,TRUE)), 3))
apply(dat, 1, function(x)which(x))

This gives you a list of the numeric column indices, including an empty
component at the beginning corresponding to none of the variables
present.

Alan Simpson wrote:
> Hello list
>  
> Does anybody know of any way to create an index of all the possible
> combinations of variables (factors) in a data frame? ie for 3 factors A, B &
> C we have 
>  
> A
> B
> C
> AB
> AC
> BC
> ABC
>  
> which equates to columns 1, 2, 3, 1:2, (1,3), 2:3 and 1:3.
>  
> I realise that a function like model.matrix does this, but how to get the
> seqence of the index?

-- 
Christopher Jackson <chris.jackson at imperial.ac.uk>, Research Associate,
Department of Epidemiology and Public Health, Imperial College
School of Medicine, Norfolk Place, London W2 1PG, tel. 020 759 43371



From martin at ist.org  Tue Sep 28 15:33:18 2004
From: martin at ist.org (martin@ist.org)
Date: Tue, 28 Sep 2004 13:33:18 -0000
Subject: [R] specifying exports for R CMD SHLIB
Message-ID: <twig.1096378398.69195@ist.org>

Yes it is Windows and I'm using a cygwin version of gcc to compile.
I thought it would be 'cleaner' to have only the functions exported 
that are intended to be called from R. It is no big deal though, I 
just wondered if I'm using the wrong format for the .def file or 
making another simple mistake.
I will also have another look at the R-ext manual like Jari suggested.

Thanks for your help, 

Martin Keller-Ressel



Am Tue, 28 Sep 2004 14:06:20 +0100 (BST) hat Prof Brian Ripley 
<ripley at stats.ox.ac.uk> geschrieben:

> What OS?
>
> If this is Windows, you cannot (and why do you want to, as the DLL 
is 
> just
> to be loaded into R?).
>
> On Tue, 28 Sep 2004 martin at ist.org wrote:
>
>> How can I specify which functions should be exported when I build a
>> shared library with 'R CMD SHLIB foo.c'??
>> I tried putting a file named foo.def in the same directory with the
>> line 'EXPORTS' and the names of the functions to be exported, but 
the
>> file is deleted in the build process.
>



--



From ligges at statistik.uni-dortmund.de  Tue Sep 28 15:35:10 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 28 Sep 2004 15:35:10 +0200
Subject: [R] package error message
In-Reply-To: <41596071.2070200@ntlworld.com>
References: <41596071.2070200@ntlworld.com>
Message-ID: <4159688E.1040708@statistik.uni-dortmund.de>

Samuel Kemp wrote:

> Hi,
> 
> I am trying to make my own package in Windows XP with R 1.9.1. using 
> Rcmd build/ Rcmd.
> 
> The initial Rcmd build compiles ok with no error messages. However, when 
> I run Rcmd check it runs ok up until
> 
> * checking for file 'GammaTest/DESCRIPTION' ... OK
> * checking if this is a source package ... OK
> * checking whether package 'GammaTest' can be installed ... ERROR
> Installation failed.
> See 'c:/Documents and Settings/Samuel Kemp/My Documents/R 
> Files/GammaTest.Rcheck/00install.out' for details.
> 
> This file contains the following.....
> 
> installing R.css in c:/DOCUME~1/SAMUEL~1/MYDOCU~1/RFILES~1/GAMMAT~1.RCH

It's still a bad idea (even if this is not the reason for the error 
below, I guess) to have blanks in your path names.



> ---------- Making package GammaTest ------------
>  adding build stamp to DESCRIPTION
> make[2]: *** No rule to make target `R/Create', needed by 
> `c:/DOCUME~1/SAMUEL~1/MYDOCU~1/RFILES~1/GAMMAT~1.RCH/GammaTest/R/GammaTest'.  
> Stop.
> make[1]: *** [all] Error 2
> make: *** [pkg-GammaTest] Error 2
> *** Installation of GammaTest failed ***

Have you followed "Writing R Extensions" and the file 
./src/gnuwin32/readme.packages EXACTLY ?

Try to start with the most simple package and add functions step by 
step. Is your DESCRIPTION file OK?

Uwe Ligges



> Can anyone shed light on what it is trying to tell me?
> 
> Cheers,
> 
> Sam.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From sam.kemp2 at ntlworld.com  Tue Sep 28 15:42:48 2004
From: sam.kemp2 at ntlworld.com (Samuel Kemp)
Date: Tue, 28 Sep 2004 14:42:48 +0100
Subject: [R] package error message
In-Reply-To: <4159688E.1040708@statistik.uni-dortmund.de>
References: <41596071.2070200@ntlworld.com>
	<4159688E.1040708@statistik.uni-dortmund.de>
Message-ID: <41596A58.20601@ntlworld.com>

Hi,

Yes the blanks did seem to cause this error.

Cheers,

Sam.

Uwe Ligges wrote:

> Samuel Kemp wrote:
>
>> Hi,
>>
>> I am trying to make my own package in Windows XP with R 1.9.1. using 
>> Rcmd build/ Rcmd.
>>
>> The initial Rcmd build compiles ok with no error messages. However, 
>> when I run Rcmd check it runs ok up until
>>
>> * checking for file 'GammaTest/DESCRIPTION' ... OK
>> * checking if this is a source package ... OK
>> * checking whether package 'GammaTest' can be installed ... ERROR
>> Installation failed.
>> See 'c:/Documents and Settings/Samuel Kemp/My Documents/R 
>> Files/GammaTest.Rcheck/00install.out' for details.
>>
>> This file contains the following.....
>>
>> installing R.css in c:/DOCUME~1/SAMUEL~1/MYDOCU~1/RFILES~1/GAMMAT~1.RCH
>
>
> It's still a bad idea (even if this is not the reason for the error 
> below, I guess) to have blanks in your path names.
>
>
>
>> ---------- Making package GammaTest ------------
>>  adding build stamp to DESCRIPTION
>> make[2]: *** No rule to make target `R/Create', needed by 
>> `c:/DOCUME~1/SAMUEL~1/MYDOCU~1/RFILES~1/GAMMAT~1.RCH/GammaTest/R/GammaTest'.  
>> Stop.
>> make[1]: *** [all] Error 2
>> make: *** [pkg-GammaTest] Error 2
>> *** Installation of GammaTest failed ***
>
>
> Have you followed "Writing R Extensions" and the file 
> ./src/gnuwin32/readme.packages EXACTLY ?
>
> Try to start with the most simple package and add functions step by 
> step. Is your DESCRIPTION file OK?
>
> Uwe Ligges
>
>
>
>> Can anyone shed light on what it is trying to tell me?
>>
>> Cheers,
>>
>> Sam.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
>
>



From murdoch at stats.uwo.ca  Tue Sep 28 15:53:28 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 28 Sep 2004 09:53:28 -0400
Subject: [R] specifying exports for R CMD SHLIB
In-Reply-To: <twig.1096378398.69195@ist.org>
References: <twig.1096378398.69195@ist.org>
Message-ID: <k1ril0tjhd30a340g8ce8s3ljvatj4053n@4ax.com>

On Tue, 28 Sep 2004 13:33:18 -0000, <martin at ist.org> wrote :

>Yes it is Windows and I'm using a cygwin version of gcc to compile.

We recommend using MinGW; that's what R is compiled with.  If you use
Cygwin, you'll pull in the cygwin1.dll, and possibly other DLLs, and
they may conflict with the R runtime library somehow.

>I thought it would be 'cleaner' to have only the functions exported 
>that are intended to be called from R. It is no big deal though, I 
>just wondered if I'm using the wrong format for the .def file or 
>making another simple mistake.

When you call a function using .C or .Call, you should name the
package; that means there won't be collisions between your names and
the names exported by some other DLL.

Duncan Murdoch



From ggrothendieck at myway.com  Tue Sep 28 15:56:48 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 28 Sep 2004 13:56:48 +0000 (UTC)
Subject: [R] (no subject)
References: <CD0374F1F9FDC842A5CFBEA4906FDC2501FD5091@ex103.smic-sh.com>
Message-ID: <loom.20040928T155227-492@post.gmane.org>

YiYao_Jiang <YiYao_Jiang <at> smics.com> writes:

: 
: ******************************
: Could you perhaps describe exactly what "can't compile" means, please?
: It's hard to know what you've tried without a little more information.
: ******************************
: 
: 1). I type these command:
: 
:          f <- function(x,y) x+y
:          g <- function(x,y) x-y
:          d <- data.frame(a=1,b=2)
:          e <- rnorm(1000)
:          package.skeleton(list=c("f","g","d","e"), name="AnExample")
: 
: This is an example in "package.skeleton" . And I find a new 
folder "AnExample" created in "D:\ R\ rw109\ ".
: Enter the  "AnExample" folder , there are 4 folders "data", "mam", "R","src" 
and 2 files "DESCRIPTION" and
: "README". 
: 
: 2). I type "> search()" but no "AnExample". What should I do to setup the 
package?

Try these 3 steps (assuming Windows 1.9.1 patched):

1. In R,
	f <- function(x,y) x+y
	g <- function(x,y) x-y
	d <- data.frame(a=1,b=2)
	e <- rnorm(1000)
	package.skeleton(list=c("f","g","d","e"), name="AnExample")
	# optionally edit DESCRIPTION file and help files

2. In command line:
	cd \Program Files\R\rw1091pat
	bin\R CMD build anExample
	bin\R CMD check anExample
	bin\R CMD build anExample --binary
        # at this point you should have AnExample_1.0.zip 

3. In R,
	install.packages("AnExample_1.0.zip", CRAN = NULL) 
	library(anExample)
	f(1,2)



From tlumley at u.washington.edu  Tue Sep 28 16:34:22 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 28 Sep 2004 07:34:22 -0700 (PDT)
Subject: [R] passing formula arg to mgcv::gam 
In-Reply-To: <C698D707214E6F4AB39AB7096C3DE5A56D861F@phost015.EVAFUNDS.intermedia.net>
References: <C698D707214E6F4AB39AB7096C3DE5A56D861F@phost015.EVAFUNDS.intermedia.net>
Message-ID: <Pine.A41.4.61.0409280732430.224070@homer05.u.washington.edu>


I think that this should work in gam(), but in any case a fix is to put 
the subset variable into the data frame.  The formula interface works best 
this way.  In your example you could add idx=1:100 to the data frame and 
then use subset=idx %in%  1:10

 	-thomas


On Mon, 27 Sep 2004, Vadim Ogranovich wrote:

> Hi,
>
> I have a function, callGam, that fits a gam model to a subset of a dataframe. The argument to callGam is a formula, the subset is determined inside the function itself. My na?ve approach generates and error, see below. I guess this is because 'idx' is loocked up in the environment of 'formula', but I am too ignorant about environments to be able to tell for sure. Could someone please suggest a way around?
>
> Thanks,
> Vadim
>
>> library("mgcv")
>>
>> callGam <- function(formula) {
> +   idx <- seq(10)
> +   gam(formula, data=data.frame(x=rnorm(100), y=rnorm(100)), subset=idx)
> + }
>>
>> gam.fit <- callGam(y ~ x)
> Error in eval(expr, envir, enclos) : Object "idx" not found
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From tlumley at u.washington.edu  Tue Sep 28 16:47:42 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 28 Sep 2004 07:47:42 -0700 (PDT)
Subject: [Fwd: [R] Re: tseries Package for R]
In-Reply-To: <41591DD9.3020202@bluewin.ch>
References: <41591DD9.3020202@bluewin.ch>
Message-ID: <Pine.A41.4.61.0409280743480.224070@homer05.u.washington.edu>


Adrian,

There is no prebuilt binary for tseries, which fairly reliably indicates a 
problem in compiling it.  When I try (and unfortunately I have only a 
pre2.0.0 system, not 1.9.1) I get an error at the final linking stage

ld: dsumsl.o has local relocation entries in non-writable section 
(__TEXT,__const)

The file dsumsl.o was created by
g77   -fno-common  -g -O2 -c dsumsl.f -o dsumsl.o

If you can tell me other tests you would like done I can try doing them.

It sounds as though other compiler combinations can make it work; I'm 
using the C compilers that come with the Apple Developer Toolkit on OS X 
10.3 and the Fortran compiler that Stefano recommends.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

On Tue, 28 Sep 2004, Adrian Trapletti wrote:

>
>
> -------- Original Message --------
> Subject: 	[R] Re: tseries Package for R
> Date: 	Mon, 27 Sep 2004 23:56:34 -0800
> From: 	Martin Renner <martin.renner at stonebow.otago.ac.nz>
> To: 	Adrian Trapletti <a.trapletti at bluewin.ch>
> References: 	<61CBB4C9-10C7-11D9-A624-000D932E990C at comcast.net> 
> <4158F5B6.3020103 at bluewin.ch>
>
>
>
> see http://cran.stat.ucla.edu/bin/macosx/ and
> http://cran.stat.ucla.edu/bin/macosx/RMacOSX-FAQ.html
>
> (or your nearest cran-mirror).
>
> The gui allows you to installe precompiled binaries.
>
>
>> Wizon wrote:
>> 
>>> I am using Mac OSX.  I am first starting to use R and have not installed 
>>> any packages yet.  I searched through the CRAN site for a Mac OSX version, 
>>> but did not find one.  I downloaded the tar.gz package.  Will this work on 
>>> the Mac?  Is there a way to get a package that I don't have to compile? 
>>> Thanks in advance for your help.
>>> 
>>> Adam
>>> 
>> Dear Adam
>> 
>> Sorry, I can't help you since I never used R under MacOS. However, I cc 
>> your mail to R-help. Maybe you get some feedback from there.
>> 
>> Best regards
>> Adrian
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From wolski at molgen.mpg.de  Tue Sep 28 15:09:37 2004
From: wolski at molgen.mpg.de (Witold Eryk Wolski)
Date: Tue, 28 Sep 2004 15:09:37 +0200
Subject: [R] slow loops in Monte Carlo Simulations
In-Reply-To: <41596B1E.15238.67A8A93@WIWI.UNI-MUENSTER.DE>
References: <41596B1E.15238.67A8A93@WIWI.UNI-MUENSTER.DE>
Message-ID: <41596291.4060805@molgen.mpg.de>

Hi!

Have you taken a look at the MCMCpack - package on cran:
"This package contains functions for posterior simulation for a number 
of statistical models. All simulation is done in compiled C++ written in 
the Scythe Statistical Library Version 1.0. All models return coda mcmc 
objects that can then be summarized using the coda package."

/E

Nael Al Anaswah wrote:

>Hi there,
>
>I am running Monte Carlo Simulations in R using ordinary "while 
>(condition)" loops. Since the number of iterations is something like 
>100.000 and within each iteration a given subsample is extended 
>sequentially it takes hours to run the simulation. 
>
>Does anyone know if there is either a way to avoid using loops in 
>Monte Carlo Simulations or how to include possible faster "c++" 
>commands in R code?
>
>many thanks in advance.
>
>Nael Al-Anaswah
>
>
>
>-----------------------------------------------------
>Nael Al-Anaswah
>Department of Econometrics
>University of Muenster
>Germany
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>


-- 
Dipl. bio-chem. Witold Eryk Wolski         
MPI-Moleculare Genetic
Ihnestrasse 63-73 14195 Berlin           _
tel: 0049-30-83875219                   'v'
http://www.molgen.mpg.de/~wolski       /   \
mail: witek96 at users.sourceforge.net  ---W-W----
      wolski at molgen.mpg.de



From johannesson1 at llnl.gov  Tue Sep 28 17:18:01 2004
From: johannesson1 at llnl.gov (Gardar Johannesson)
Date: Tue, 28 Sep 2004 08:18:01 -0700
Subject: [R] slow loops in Monte Carlo Simulations
In-Reply-To: <41596B1E.15238.67A8A93@WIWI.UNI-MUENSTER.DE>
Message-ID: <5.2.0.9.2.20040928081314.0229e528@mail.llnl.gov>

The key is to assign space in advance -- e.g., compare:

 > N <- 20000
 >
 > res <- NULL
 > system.time( for(i in 1:N) res <- c(res, sample(10)) )
[1] 28.62  8.91 37.79  0.00  0.00
 >
 > res <- vector("list",N)
 > system.time( for(i in 1:N) res[[i]] <- sample(10) )
[1] 0.45 0.00 0.44 0.00 0.00
 >
 > res <- matrix(0.0, N,10)
 > system.time( for(i in 1:N) res[i,] <- sample(10) )
[1] 0.47 0.01 0.47 0.00 0.00
 >


Gardar

At 01:46 PM 9/28/2004 +0200, Nael Al Anaswah wrote:
>Hi there,
>
>I am running Monte Carlo Simulations in R using ordinary "while
>(condition)" loops. Since the number of iterations is something like
>100.000 and within each iteration a given subsample is extended
>sequentially it takes hours to run the simulation.
>
>Does anyone know if there is either a way to avoid using loops in
>Monte Carlo Simulations or how to include possible faster "c++"
>commands in R code?
>
>many thanks in advance.
>
>Nael Al-Anaswah
>
>
>
>-----------------------------------------------------
>Nael Al-Anaswah
>Department of Econometrics
>University of Muenster
>Germany
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From minhan.science at gmail.com  Tue Sep 28 17:41:00 2004
From: minhan.science at gmail.com (Min-Han Tan)
Date: Tue, 28 Sep 2004 11:41:00 -0400
Subject: [R] Validating a Cox model on an external set
Message-ID: <7902152a04092808413bb32d7c@mail.gmail.com>

Good morning,

Sorry to trouble the list. 

I have a problem I hope to seek your advice on. 
 
Essentially, I am trying to 'validate' a multivariate Cox proportional
hazards model built in a training set, by testing it on an external
test set. I have performed a survfit using the Cox model to predict
survival for the test set, and obtained individual predictions for
survival time, with standard error for each test sample. Each of these
cases has an actual survival time, some censored.
 
How can we decide whether the Cox model has been validated or not?
 
I was suggested survdiff in the survival package, but survdiff works
between curves; am not sure how I could use it (I have a predicted
curve for each curve, but no 'observed curve' - the only observation
is death or censoring at time x)

Thank you all so much! 
 
Min-Han Tan
Van Andel Institute



From cliff at ms.washington.edu  Tue Sep 28 19:07:54 2004
From: cliff at ms.washington.edu (Cliff Lunneborg)
Date: Tue, 28 Sep 2004 10:07:54 -0700
Subject: [R] Bootstrapping with weighted data sample
Message-ID: <019701c4a57d$b227bbe0$6401a8c0@C56909A>

Salvatore Barbaro writes, in part:


> Consider a sample, x, like this:
> #
> x<- matrix(rbind(4,8,0,2, 25,30,5,32), ncol=2)
> #
>
> Weight  Income
> 4    25
> 8    30
> 0    5
> 2    32
>
> Here the "Weight" assigns the weight of each observation.
> P.S. I am using library(bootstrap) with bcanon() to obtain boostrap
> confidence intervals.

You may want to use functions from the boot package instead. The boot
function accommodates weighted observations in drawing new samples.


**********************************************************
Cliff Lunneborg, Professor Emeritus, Statistics &
Psychology, University of Washington, Seattle
cliff at ms.washington.edu



From f.harrell at vanderbilt.edu  Tue Sep 28 19:10:34 2004
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 28 Sep 2004 12:10:34 -0500
Subject: [R] Validating a Cox model on an external set
In-Reply-To: <7902152a04092808413bb32d7c@mail.gmail.com>
References: <7902152a04092808413bb32d7c@mail.gmail.com>
Message-ID: <41599B0A.7000101@vanderbilt.edu>

Min-Han Tan wrote:
> Good morning,
> 
> Sorry to trouble the list. 
> 
> I have a problem I hope to seek your advice on. 
>  
> Essentially, I am trying to 'validate' a multivariate Cox proportional
> hazards model built in a training set, by testing it on an external
> test set. I have performed a survfit using the Cox model to predict
> survival for the test set, and obtained individual predictions for
> survival time, with standard error for each test sample. Each of these
> cases has an actual survival time, some censored.
>  
> How can we decide whether the Cox model has been validated or not?

This is what the Design package and its cph and validate.cph and 
calibrate.cph functions are for.

>  
> I was suggested survdiff in the survival package, but survdiff works
> between curves; am not sure how I could use it (I have a predicted
> curve for each curve, but no 'observed curve' - the only observation
> is death or censoring at time x)
> 
> Thank you all so much! 
>  
> Min-Han Tan
> Van Andel Institute
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From tlumley at u.washington.edu  Tue Sep 28 19:24:35 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 28 Sep 2004 10:24:35 -0700 (PDT)
Subject: [R] Validating a Cox model on an external set
In-Reply-To: <7902152a04092808413bb32d7c@mail.gmail.com>
References: <7902152a04092808413bb32d7c@mail.gmail.com>
Message-ID: <Pine.A41.4.61.0409281024100.80200@homer08.u.washington.edu>

On Tue, 28 Sep 2004, Min-Han Tan wrote:

>
> Essentially, I am trying to 'validate' a multivariate Cox proportional
> hazards model built in a training set, by testing it on an external
> test set. I have performed a survfit using the Cox model to predict
> survival for the test set, and obtained individual predictions for
> survival time, with standard error for each test sample. Each of these
> cases has an actual survival time, some censored.
>

There is an example of comparing data to a fitted Cox model in 
help(survexp).

 	-thomas



From gunter.berton at gene.com  Tue Sep 28 19:55:50 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 28 Sep 2004 10:55:50 -0700
Subject: [R] Validating a Cox model on an external set
In-Reply-To: <41599B0A.7000101@vanderbilt.edu>
Message-ID: <200409281755.i8SHtosC018574@volta.gene.com>


But note that there may be deeper, non-statistical, issues of what you mean
by "validation" here: how good must the predictions be on the validation
data? How similar or dissimilar should the validation data be to the
"training" data? To what end/population is the fitted model to be applied?
For example, AFAIK in most scientific research, a model is not considered
"validated" unless results can be substantively reproduced (??) in different
labs, sometimes with alternative methods.

Think of the 1916 (I think it was) measurements of star positions during a
total solar eclipse to "validate" Einstein's Theory of General Relativity.
My point is not to say that this kind of "validation" is appropriate for a
Cox model, but only that the issues are worth thinking about.


-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank 
> E Harrell Jr
> Sent: Tuesday, September 28, 2004 10:11 AM
> To: Min-Han Tan
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Validating a Cox model on an external set
> 
> Min-Han Tan wrote:
> > Good morning,
> > 
> > Sorry to trouble the list. 
> > 
> > I have a problem I hope to seek your advice on. 
> >  
> > Essentially, I am trying to 'validate' a multivariate Cox 
> proportional
> > hazards model built in a training set, by testing it on an external
> > test set. I have performed a survfit using the Cox model to predict
> > survival for the test set, and obtained individual predictions for
> > survival time, with standard error for each test sample. 
> Each of these
> > cases has an actual survival time, some censored.
> >  
> > How can we decide whether the Cox model has been validated or not?
> 
> This is what the Design package and its cph and validate.cph and 
> calibrate.cph functions are for.
> 
> >  
> > I was suggested survdiff in the survival package, but survdiff works
> > between curves; am not sure how I could use it (I have a predicted
> > curve for each curve, but no 'observed curve' - the only observation
> > is death or censoring at time x)
> > 
> > Thank you all so much! 
> >  
> > Min-Han Tan
> > Van Andel Institute
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> > 
> 
> 
> -- 
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                       Department of Biostatistics   
> Vanderbilt University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

From minhan.science at gmail.com  Tue Sep 28 20:45:35 2004
From: minhan.science at gmail.com (Min-Han Tan)
Date: Tue, 28 Sep 2004 14:45:35 -0400
Subject: [R] Validating a Cox model on an external set
In-Reply-To: <200409281755.i8SHtosC018574@volta.gene.com>
References: <41599B0A.7000101@vanderbilt.edu>
	<200409281755.i8SHtosC018574@volta.gene.com>
Message-ID: <7902152a0409281145451c04b3@mail.gmail.com>

Thank you all for your very insightful comments! And thank you for the
directions to the packages!

Re: non-statistical issues, yes, I was looking through Altman and
Royston's Stat Med 2000 article "What do we mean by validating a
prognostic model?" last night and it was very interesting. I'm working
on expression profiling in tumor samples, and there are several
difficulties in designing an experiment along those 'ideal'
guidelines.

A. Small sample size is of course the most common recurring problem,
with concomitant even lower event rate.

B. Patient recruitment issues are yet another issue, as many of the
samples are degraded after time - the older the sample, the more
degraded it usually is! So that biases selection towards recent cases.
Different centres have different storage techniques, resulting in
extensive degradation in samples from 1 centre and relatively intact
samples from others. So there is no choice but to perform "data-driven
selection" of cases - i.e. only samples which have good RNA.

Other problems I've encountered include:

C. Computational time. using a training sample size of 50 arrays,
running a full internal cross-validation of a model derived using
pamr.cv.cox took my computer about one and a half hours (with no other
process running). (P4, 3 GHz, 2 GB RAM, R 1.9.1., Windows XP) And
that's just *one* randomization!

Min-Han

On Tue, 28 Sep 2004 10:55:50 -0700, Berton Gunter
<gunter.berton at gene.com> wrote:
> 
> But note that there may be deeper, non-statistical, issues of what you mean
> by "validation" here: how good must the predictions be on the validation
> data? How similar or dissimilar should the validation data be to the
> "training" data? To what end/population is the fitted model to be applied?
> For example, AFAIK in most scientific research, a model is not considered
> "validated" unless results can be substantively reproduced (??) in different
> labs, sometimes with alternative methods.
> 
> Think of the 1916 (I think it was) measurements of star positions during a
> total solar eclipse to "validate" Einstein's Theory of General Relativity.
> My point is not to say that this kind of "validation" is appropriate for a
> Cox model, but only that the issues are worth thinking about.
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
> 
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
> 
> 
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank
> > E Harrell Jr
> > Sent: Tuesday, September 28, 2004 10:11 AM
> > To: Min-Han Tan
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] Validating a Cox model on an external set
> >
> > Min-Han Tan wrote:
> > > Good morning,
> > >
> > > Sorry to trouble the list.
> > >
> > > I have a problem I hope to seek your advice on.
> > >
> > > Essentially, I am trying to 'validate' a multivariate Cox
> > proportional
> > > hazards model built in a training set, by testing it on an external
> > > test set. I have performed a survfit using the Cox model to predict
> > > survival for the test set, and obtained individual predictions for
> > > survival time, with standard error for each test sample.
> > Each of these
> > > cases has an actual survival time, some censored.
> > >
> > > How can we decide whether the Cox model has been validated or not?
> >
> > This is what the Design package and its cph and validate.cph and
> > calibrate.cph functions are for.
> >
> > >
> > > I was suggested survdiff in the survival package, but survdiff works
> > > between curves; am not sure how I could use it (I have a predicted
> > > curve for each curve, but no 'observed curve' - the only observation
> > > is death or censoring at time x)
> > >
> > > Thank you all so much!
> > >
> > > Min-Han Tan
> > > Van Andel Institute
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> >
> >
> > --
> > Frank E Harrell Jr   Professor and Chair           School of Medicine
> >                       Department of Biostatistics
> > Vanderbilt University
> > 
> > ______________________________________________
> 
> 
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> 
> 
> 
>



From minhan.science at gmail.com  Tue Sep 28 20:45:35 2004
From: minhan.science at gmail.com (Min-Han Tan)
Date: Tue, 28 Sep 2004 14:45:35 -0400
Subject: [R] Validating a Cox model on an external set
In-Reply-To: <200409281755.i8SHtosC018574@volta.gene.com>
References: <41599B0A.7000101@vanderbilt.edu>
	<200409281755.i8SHtosC018574@volta.gene.com>
Message-ID: <7902152a0409281145451c04b3@mail.gmail.com>

Thank you all for your very insightful comments! And thank you for the
directions to the packages!

Re: non-statistical issues, yes, I was looking through Altman and
Royston's Stat Med 2000 article "What do we mean by validating a
prognostic model?" last night and it was very interesting. I'm working
on expression profiling in tumor samples, and there are several
difficulties in designing an experiment along those 'ideal'
guidelines.

A. Small sample size is of course the most common recurring problem,
with concomitant even lower event rate.

B. Patient recruitment issues are yet another issue, as many of the
samples are degraded after time - the older the sample, the more
degraded it usually is! So that biases selection towards recent cases.
Different centres have different storage techniques, resulting in
extensive degradation in samples from 1 centre and relatively intact
samples from others. So there is no choice but to perform "data-driven
selection" of cases - i.e. only samples which have good RNA.

Other problems I've encountered include:

C. Computational time. using a training sample size of 50 arrays,
running a full internal cross-validation of a model derived using
pamr.cv.cox took my computer about one and a half hours (with no other
process running). (P4, 3 GHz, 2 GB RAM, R 1.9.1., Windows XP) And
that's just *one* randomization!

Min-Han

On Tue, 28 Sep 2004 10:55:50 -0700, Berton Gunter
<gunter.berton at gene.com> wrote:
> 
> But note that there may be deeper, non-statistical, issues of what you mean
> by "validation" here: how good must the predictions be on the validation
> data? How similar or dissimilar should the validation data be to the
> "training" data? To what end/population is the fitted model to be applied?
> For example, AFAIK in most scientific research, a model is not considered
> "validated" unless results can be substantively reproduced (??) in different
> labs, sometimes with alternative methods.
> 
> Think of the 1916 (I think it was) measurements of star positions during a
> total solar eclipse to "validate" Einstein's Theory of General Relativity.
> My point is not to say that this kind of "validation" is appropriate for a
> Cox model, but only that the issues are worth thinking about.
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
> 
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
> 
> 
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank
> > E Harrell Jr
> > Sent: Tuesday, September 28, 2004 10:11 AM
> > To: Min-Han Tan
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] Validating a Cox model on an external set
> >
> > Min-Han Tan wrote:
> > > Good morning,
> > >
> > > Sorry to trouble the list.
> > >
> > > I have a problem I hope to seek your advice on.
> > >
> > > Essentially, I am trying to 'validate' a multivariate Cox
> > proportional
> > > hazards model built in a training set, by testing it on an external
> > > test set. I have performed a survfit using the Cox model to predict
> > > survival for the test set, and obtained individual predictions for
> > > survival time, with standard error for each test sample.
> > Each of these
> > > cases has an actual survival time, some censored.
> > >
> > > How can we decide whether the Cox model has been validated or not?
> >
> > This is what the Design package and its cph and validate.cph and
> > calibrate.cph functions are for.
> >
> > >
> > > I was suggested survdiff in the survival package, but survdiff works
> > > between curves; am not sure how I could use it (I have a predicted
> > > curve for each curve, but no 'observed curve' - the only observation
> > > is death or censoring at time x)
> > >
> > > Thank you all so much!
> > >
> > > Min-Han Tan
> > > Van Andel Institute
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> >
> >
> > --
> > Frank E Harrell Jr   Professor and Chair           School of Medicine
> >                       Department of Biostatistics
> > Vanderbilt University
> > 
> > ______________________________________________
> 
> 
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> 
> 
> 
>



From minhan.science at gmail.com  Tue Sep 28 20:45:35 2004
From: minhan.science at gmail.com (Min-Han Tan)
Date: Tue, 28 Sep 2004 14:45:35 -0400
Subject: [R] Validating a Cox model on an external set
In-Reply-To: <200409281755.i8SHtosC018574@volta.gene.com>
References: <41599B0A.7000101@vanderbilt.edu>
	<200409281755.i8SHtosC018574@volta.gene.com>
Message-ID: <7902152a0409281145451c04b3@mail.gmail.com>

Thank you all for your very insightful comments! And thank you for the
directions to the packages!

Re: non-statistical issues, yes, I was looking through Altman and
Royston's Stat Med 2000 article "What do we mean by validating a
prognostic model?" last night and it was very interesting. I'm working
on expression profiling in tumor samples, and there are several
difficulties in designing an experiment along those 'ideal'
guidelines.

A. Small sample size is of course the most common recurring problem,
with concomitant even lower event rate.

B. Patient recruitment issues are yet another issue, as many of the
samples are degraded after time - the older the sample, the more
degraded it usually is! So that biases selection towards recent cases.
Different centres have different storage techniques, resulting in
extensive degradation in samples from 1 centre and relatively intact
samples from others. So there is no choice but to perform "data-driven
selection" of cases - i.e. only samples which have good RNA.

Other problems I've encountered include:

C. Computational time. using a training sample size of 50 arrays,
running a full internal cross-validation of a model derived using
pamr.cv.cox took my computer about one and a half hours (with no other
process running). (P4, 3 GHz, 2 GB RAM, R 1.9.1., Windows XP) And
that's just *one* randomization!

Min-Han

On Tue, 28 Sep 2004 10:55:50 -0700, Berton Gunter
<gunter.berton at gene.com> wrote:
> 
> But note that there may be deeper, non-statistical, issues of what you mean
> by "validation" here: how good must the predictions be on the validation
> data? How similar or dissimilar should the validation data be to the
> "training" data? To what end/population is the fitted model to be applied?
> For example, AFAIK in most scientific research, a model is not considered
> "validated" unless results can be substantively reproduced (??) in different
> labs, sometimes with alternative methods.
> 
> Think of the 1916 (I think it was) measurements of star positions during a
> total solar eclipse to "validate" Einstein's Theory of General Relativity.
> My point is not to say that this kind of "validation" is appropriate for a
> Cox model, but only that the issues are worth thinking about.
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
> 
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
> 
> 
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank
> > E Harrell Jr
> > Sent: Tuesday, September 28, 2004 10:11 AM
> > To: Min-Han Tan
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] Validating a Cox model on an external set
> >
> > Min-Han Tan wrote:
> > > Good morning,
> > >
> > > Sorry to trouble the list.
> > >
> > > I have a problem I hope to seek your advice on.
> > >
> > > Essentially, I am trying to 'validate' a multivariate Cox
> > proportional
> > > hazards model built in a training set, by testing it on an external
> > > test set. I have performed a survfit using the Cox model to predict
> > > survival for the test set, and obtained individual predictions for
> > > survival time, with standard error for each test sample.
> > Each of these
> > > cases has an actual survival time, some censored.
> > >
> > > How can we decide whether the Cox model has been validated or not?
> >
> > This is what the Design package and its cph and validate.cph and
> > calibrate.cph functions are for.
> >
> > >
> > > I was suggested survdiff in the survival package, but survdiff works
> > > between curves; am not sure how I could use it (I have a predicted
> > > curve for each curve, but no 'observed curve' - the only observation
> > > is death or censoring at time x)
> > >
> > > Thank you all so much!
> > >
> > > Min-Han Tan
> > > Van Andel Institute
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> >
> >
> > --
> > Frank E Harrell Jr   Professor and Chair           School of Medicine
> >                       Department of Biostatistics
> > Vanderbilt University
> > 
> > ______________________________________________
> 
> 
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> 
> 
> 
>



From minhan.science at gmail.com  Tue Sep 28 20:45:35 2004
From: minhan.science at gmail.com (Min-Han Tan)
Date: Tue, 28 Sep 2004 14:45:35 -0400
Subject: [R] Validating a Cox model on an external set
In-Reply-To: <200409281755.i8SHtosC018574@volta.gene.com>
References: <41599B0A.7000101@vanderbilt.edu>
	<200409281755.i8SHtosC018574@volta.gene.com>
Message-ID: <7902152a0409281145451c04b3@mail.gmail.com>

Thank you all for your very insightful comments! And thank you for the
directions to the packages!

Re: non-statistical issues, yes, I was looking through Altman and
Royston's Stat Med 2000 article "What do we mean by validating a
prognostic model?" last night and it was very interesting. I'm working
on expression profiling in tumor samples, and there are several
difficulties in designing an experiment along those 'ideal'
guidelines.

A. Small sample size is of course the most common recurring problem,
with concomitant even lower event rate.

B. Patient recruitment issues are yet another issue, as many of the
samples are degraded after time - the older the sample, the more
degraded it usually is! So that biases selection towards recent cases.
Different centres have different storage techniques, resulting in
extensive degradation in samples from 1 centre and relatively intact
samples from others. So there is no choice but to perform "data-driven
selection" of cases - i.e. only samples which have good RNA.

Other problems I've encountered include:

C. Computational time. using a training sample size of 50 arrays,
running a full internal cross-validation of a model derived using
pamr.cv.cox took my computer about one and a half hours (with no other
process running). (P4, 3 GHz, 2 GB RAM, R 1.9.1., Windows XP) And
that's just *one* randomization!

Min-Han

On Tue, 28 Sep 2004 10:55:50 -0700, Berton Gunter
<gunter.berton at gene.com> wrote:
> 
> But note that there may be deeper, non-statistical, issues of what you mean
> by "validation" here: how good must the predictions be on the validation
> data? How similar or dissimilar should the validation data be to the
> "training" data? To what end/population is the fitted model to be applied?
> For example, AFAIK in most scientific research, a model is not considered
> "validated" unless results can be substantively reproduced (??) in different
> labs, sometimes with alternative methods.
> 
> Think of the 1916 (I think it was) measurements of star positions during a
> total solar eclipse to "validate" Einstein's Theory of General Relativity.
> My point is not to say that this kind of "validation" is appropriate for a
> Cox model, but only that the issues are worth thinking about.
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
> 
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
> 
> 
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank
> > E Harrell Jr
> > Sent: Tuesday, September 28, 2004 10:11 AM
> > To: Min-Han Tan
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] Validating a Cox model on an external set
> >
> > Min-Han Tan wrote:
> > > Good morning,
> > >
> > > Sorry to trouble the list.
> > >
> > > I have a problem I hope to seek your advice on.
> > >
> > > Essentially, I am trying to 'validate' a multivariate Cox
> > proportional
> > > hazards model built in a training set, by testing it on an external
> > > test set. I have performed a survfit using the Cox model to predict
> > > survival for the test set, and obtained individual predictions for
> > > survival time, with standard error for each test sample.
> > Each of these
> > > cases has an actual survival time, some censored.
> > >
> > > How can we decide whether the Cox model has been validated or not?
> >
> > This is what the Design package and its cph and validate.cph and
> > calibrate.cph functions are for.
> >
> > >
> > > I was suggested survdiff in the survival package, but survdiff works
> > > between curves; am not sure how I could use it (I have a predicted
> > > curve for each curve, but no 'observed curve' - the only observation
> > > is death or censoring at time x)
> > >
> > > Thank you all so much!
> > >
> > > Min-Han Tan
> > > Van Andel Institute
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> >
> >
> > --
> > Frank E Harrell Jr   Professor and Chair           School of Medicine
> >                       Department of Biostatistics
> > Vanderbilt University
> > 
> > ______________________________________________
> 
> 
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> 
> 
> 
>



From numero.primo at tele2.it  Tue Sep 28 21:37:07 2004
From: numero.primo at tele2.it (Landini Massimiliano)
Date: Tue, 28 Sep 2004 21:37:07 +0200
Subject: [R] How compare pre-treatment vs. post-treatment assessments
Message-ID: <r9fjl0hp914jtr1v5r3knghton8ass23k0@4ax.com>

Please consider 

Trt_No	Plot	Sub	metpru_0dat	metpru_2dat	metpru_7dat
metpru_14dat
1	1	1	9	14	12	5
1	1	2	6	7	6	5
1	1	3	6	15	13	5
1	1	4	10	10	9	10
1	1	5	7	7	8	14
1	1	6	9	10	12	11
1	1	7	6	5	8	9
1	1	8	15	9	13	15
1	1	9	15	7	15	6
1	1	10	14	11	15	7
2	2	1	13	7	9	9
2	2	2	13	8	14	13
2	2	3	15	8	11	7
2	2	4	8	13	11	12
2	2	5	12	10	5	14
2	2	6	8	5	11	7
2	2	7	7	6	5	14
2	2	8	12	14	10	11
2	2	9	5	7	9	6
2	2	10	7	15	14	9
3	3	1	4	14	14	5
3	3	2	4	11	9	12
3	3	3	10	8	9	8
3	3	4	6	12	15	13
3	3	5	9	5	10	11
3	3	6	10	8	9	14
3	3	7	4	14	15	11
3	3	8	11	10	8	15
3	3	9	15	12	9	12
3	3	10	14	12	9	7
4	4	1	11	13	15	8
4	4	2	12	14	5	10
4	4	3	15	14	11	14
4	4	4	12	14	8	10
4	4	5	10	7	5	10
4	4	6	7	12	13	7
4	4	7	12	14	9	11
4	4	8	5	9	15	5
4	4	9	12	13	6	5
4	4	10	9	5	10	6
5	5	1	12	2	2	5
5	5	2	14	11	5	5
5	5	3	14	3	1	3
5	5	4	9	5	5	6
5	5	5	14	3	6	5
5	5	6	7	7	7	6
5	5	7	6	10	6	1
5	5	8	4	7	10	11
5	5	9	8	7	2	1
5	5	10	7	4	8	3
3	6	1	11	11	5	14
3	6	2	5	11	12	13
3	6	3	9	8	15	10
3	6	4	15	14	14	13
3	6	5	14	8	12	14
3	6	6	7	6	7	10
3	6	7	13	8	11	14
3	6	8	5	13	14	5
3	6	9	14	11	5	6
3	6	10	7	10	14	11
2	7	1	11	9	12	6
2	7	2	8	9	9	15
2	7	3	7	11	13	5
2	7	4	4	7	7	10
2	7	5	4	15	14	5
2	7	6	10	5	5	9
2	7	7	7	9	7	6
2	7	8	13	13	12	10
2	7	9	9	11	6	7
2	7	10	8	9	9	7
5	8	1	11	6	9	10
5	8	2	10	8	4	11
5	8	3	6	2	11	8
5	8	4	12	6	8	4
5	8	5	9	11	7	10
5	8	6	7	3	3	9
5	8	7	11	10	8	5
5	8	8	14	6	5	2
5	8	9	13	1	1	2
5	8	10	4	7	5	1
1	9	1	13	15	10	8
1	9	2	13	6	11	8
1	9	3	11	6	6	6
1	9	4	6	10	12	12
1	9	5	5	12	9	10
1	9	6	4	7	14	5
1	9	7	13	15	5	9
1	9	8	10	14	5	8
1	9	9	4	12	9	12
1	9	10	4	12	12	14
4	10	1	9	13	7	13
4	10	2	14	11	12	7
4	10	3	9	9	6	14
4	10	4	11	7	10	5
4	10	5	5	7	6	11
4	10	6	8	8	15	6
4	10	7	15	11	13	5
4	10	8	13	7	7	11
4	10	9	15	7	12	14
4	10	10	7	7	11	13
5	11	1	12	3	5	8
5	11	2	14	4	5	1
5	11	3	5	4	5	8
5	11	4	9	10	8	3
5	11	5	6	11	3	1
5	11	6	9	3	11	10
5	11	7	10	9	1	6
5	11	8	12	10	2	11
5	11	9	9	1	7	7
5	11	10	7	2	6	5
3	12	1	5	8	7	6
3	12	2	4	15	7	14
3	12	3	13	15	11	14
3	12	4	8	15	15	5
3	12	5	6	12	9	14
3	12	6	15	8	10	9
3	12	7	7	12	10	8
3	12	8	8	13	10	15
3	12	9	6	7	6	10
3	12	10	11	5	14	7
4	13	1	12	15	15	7
4	13	2	13	7	13	11
4	13	3	4	12	8	13
4	13	4	9	11	15	6
4	13	5	8	10	7	10
4	13	6	10	9	14	12
4	13	7	9	12	13	13
4	13	8	4	13	11	8
4	13	9	7	10	8	10
4	13	10	4	9	5	11
1	14	1	4	15	11	5
1	14	2	11	12	14	9
1	14	3	10	7	14	12
1	14	4	7	7	13	7
1	14	5	5	6	8	11
1	14	6	13	9	8	5
1	14	7	7	7	12	13
1	14	8	10	15	15	11
1	14	9	8	5	7	5
1	14	10	12	13	7	12
2	15	1	5	8	10	14
2	15	2	10	15	12	7
2	15	3	13	9	10	8
2	15	4	12	15	15	14
2	15	5	12	7	15	7
2	15	6	7	12	14	12
2	15	7	9	10	10	11
2	15	8	9	15	10	10
2	15	9	8	9	5	7
2	15	10	4	12	6	15
4	16	1	15	9	6	8
4	16	2	6	7	5	12
4	16	3	5	8	14	8
4	16	4	13	14	10	9
4	16	5	14	6	10	15
4	16	6	7	10	13	7
4	16	7	12	14	9	8
4	16	8	4	10	13	10
4	16	9	9	11	12	8
4	16	10	8	15	7	7
3	17	1	7	13	14	7
3	17	2	5	7	12	8
3	17	3	12	11	13	6
3	17	4	15	10	10	13
3	17	5	14	6	9	8
3	17	6	12	12	9	7
3	17	7	14	10	10	5
3	17	8	6	14	12	11
3	17	9	9	15	5	10
3	17	10	12	7	10	10
1	18	1	6	6	12	5
1	18	2	6	14	6	5
1	18	3	4	5	8	8
1	18	4	9	9	8	15
1	18	5	6	11	14	15
1	18	6	6	13	5	7
1	18	7	5	12	6	15
1	18	8	11	13	5	12
1	18	9	13	6	5	9
1	18	10	6	8	8	12
2	19	1	14	5	5	13
2	19	2	8	14	14	14
2	19	3	13	14	7	10
2	19	4	6	5	15	13
2	19	5	7	5	7	14
2	19	6	6	12	14	8
2	19	7	6	7	7	12
2	19	8	11	8	14	9
2	19	9	10	5	7	10
2	19	10	4	8	13	7
5	20	1	6	6	4	1
5	20	2	5	6	11	10
5	20	3	5	10	4	11
5	20	4	8	10	4	3
5	20	5	8	3	11	9
5	20	6	7	4	2	10
5	20	7	8	10	1	3
5	20	8	10	4	5	6
5	20	9	12	3	8	5
5	20	10	11	5	9	7


These are count of metcalfa colony at 0 DaysAfterTreatment (=> before trt), 2,
7 and 14 DAT (=>three column of data after treatment)

First column  contain  the number of the treatment
1=>check
2=>experimental insecticide @low rate
3=>experimental insecticide @normal rate
4=>experimental insecticide @double rate
5=> Standard insecticide

Second column contain progressive number of plot (randomized treatment)
Third column contain progressive number of each sub sample.
So
how can I perform pre-post control following Henderson-Tilton formula that is

(1-(insect_in_control_before_trt * insect_in_treatment_after_trt) /
((insect_in_control_after_trt * insect_in_treatment_before_trt))*100

so can anybody suggest me how can I sum every sub sample by each plot(20 data
per column) and perform H-T formula?

or ABBOT

100*(1-(insect_in_treatment_after_trt / insect in control after trt)


tnx in advance

-------------------------------------------------------------------------------------------------------------------------
Landini Dr. Massimiliano
Tel. mob. (+39) 347 140 11 94
Tel./Fax. (+39) 051 762 196
e-mail: numero (dot) primo (at) tele2 (dot) it
-------------------------------------------------------------------------------------------------------------------------
Regola del righello: La linea retta non esiste.



From ggrothendieck at myway.com  Tue Sep 28 22:02:01 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 28 Sep 2004 20:02:01 +0000 (UTC)
Subject: [R] Bug? using { as a function in lapply
Message-ID: <loom.20040928T215129-758@post.gmane.org>


This seems like a bug to me.  Can someone verify this?  

First we define a function f that returns its second argument and 
lapply it to 1:2 using 9 as the second argument and all seems well.

Note that "{" as a function does the same thing as f, as illustrated 
with f(1,9) and "{"(1,9); however, when we attempt to use "{" in the 
very same way we used f in lapply, we get an error message about ... 
being used in an incorrect context, as shown.

I am using R on windows with the version shown at the end.


R> f <- function(x,y)y
R> f(1,9)
[1] 9
R> lapply(1:2, f, 9)
[[1]]
[1] 9

[[2]]
[1] 9
 
R> "{"(1,9)
[1] 9
R> lapply(1:2, "{", 9)
Error in lapply(1:2, "{", 9) : ... used in an incorrect context

R> R.version.string
[1] "R version 1.9.1, 2004-08-03"



From wolski at molgen.mpg.de  Tue Sep 28 22:12:51 2004
From: wolski at molgen.mpg.de (Witold Eryk Wolski)
Date: Tue, 28 Sep 2004 22:12:51 +0200
Subject: [R] Bug? using { as a function in lapply
In-Reply-To: <loom.20040928T215129-758@post.gmane.org>
References: <loom.20040928T215129-758@post.gmane.org>
Message-ID: <4159C5C3.7000202@molgen.mpg.de>

Hi,

 > "{" <- function(x,y)y
 > "{"(1,9)
[1] 9
 > lapply(1:2, "{", 9)
[[1]]
[1] 9

[[2]]
[1] 9

 > R.version.string
[1] "R version 2.0.0, 2004-09-20"


/E

Gabor Grothendieck wrote:

>This seems like a bug to me.  Can someone verify this?  
>
>First we define a function f that returns its second argument and 
>lapply it to 1:2 using 9 as the second argument and all seems well.
>
>Note that "{" as a function does the same thing as f, as illustrated 
>with f(1,9) and "{"(1,9); however, when we attempt to use "{" in the 
>very same way we used f in lapply, we get an error message about ... 
>being used in an incorrect context, as shown.
>
>I am using R on windows with the version shown at the end.
>
>
>R> f <- function(x,y)y
>R> f(1,9)
>[1] 9
>R> lapply(1:2, f, 9)
>[[1]]
>[1] 9
>
>[[2]]
>[1] 9
> 
>R> "{"(1,9)
>[1] 9
>R> lapply(1:2, "{", 9)
>Error in lapply(1:2, "{", 9) : ... used in an incorrect context
>
>R> R.version.string
>[1] "R version 1.9.1, 2004-08-03"
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>


-- 
Dipl. bio-chem. Witold Eryk Wolski         
MPI-Moleculare Genetic
Ihnestrasse 63-73 14195 Berlin           _
tel: 0049-30-83875219                   'v'
http://www.molgen.mpg.de/~wolski       /   \
mail: witek96 at users.sourceforge.net  ---W-W----
      wolski at molgen.mpg.de



From ggrothendieck at myway.com  Tue Sep 28 22:20:29 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 28 Sep 2004 20:20:29 +0000 (UTC)
Subject: [R] Bug? using =?utf-8?b?ew==?= as a function in lapply
References: <loom.20040928T215129-758@post.gmane.org>
	<4159C5C3.7000202@molgen.mpg.de>
Message-ID: <loom.20040928T221843-574@post.gmane.org>


Thanks for pointing out that this is already fixed in the upcoming 
version of R.

Witold Eryk Wolski <wolski <at> molgen.mpg.de> writes:

: 
: Hi,
: 
:  > "{" <- function(x,y)y
:  > "{"(1,9)
: [1] 9
:  > lapply(1:2, "{", 9)
: [[1]]
: [1] 9
: 
: [[2]]
: [1] 9
: 
:  > R.version.string
: [1] "R version 2.0.0, 2004-09-20"
: 
: /E
: 
: Gabor Grothendieck wrote:
: 
: >This seems like a bug to me.  Can someone verify this?  
: >
: >First we define a function f that returns its second argument and 
: >lapply it to 1:2 using 9 as the second argument and all seems well.
: >
: >Note that "{" as a function does the same thing as f, as illustrated 
: >with f(1,9) and "{"(1,9); however, when we attempt to use "{" in the 
: >very same way we used f in lapply, we get an error message about ... 
: >being used in an incorrect context, as shown.
: >
: >I am using R on windows with the version shown at the end.
: >
: >
: >R> f <- function(x,y)y
: >R> f(1,9)
: >[1] 9
: >R> lapply(1:2, f, 9)
: >[[1]]
: >[1] 9
: >
: >[[2]]
: >[1] 9
: > 
: >R> "{"(1,9)
: >[1] 9
: >R> lapply(1:2, "{", 9)
: >Error in lapply(1:2, "{", 9) : ... used in an incorrect context
: >
: >R> R.version.string
: >[1] "R version 1.9.1, 2004-08-03"
: >
: >______________________________________________
: >R-help <at> stat.math.ethz.ch mailing list
: >https://stat.ethz.ch/mailman/listinfo/r-help
: >PLEASE do read the posting guide! http://www.R-project.org/posting-
guide.html
: >
: >  
: >
:



From nderby at u.washington.edu  Tue Sep 28 22:23:28 2004
From: nderby at u.washington.edu (Nathaniel B. Derby)
Date: Tue, 28 Sep 2004 13:23:28 -0700 (PDT)
Subject: [R] Looking for .Call functions
In-Reply-To: <41588AD9.8080004@stat.wisc.edu>
Message-ID: <Pine.LNX.4.43.0409281323280.27651@hymn06.u.washington.edu>

Hello,

Thanks for the help.  Unfortunately, my version of R (1.9.1) doesn't have that directory (i.e., within $RSRC\src\library, there is just a subdirectory entitled "windlgs"), and has neither ts.h nor pacf.c in any of its directories.  Could it be that this function is embedded inside a .dll file (like stats.dll)?


thanks,

Nate


> It means that in one of the .c source files in $RSRC/src/library/stats/src 
> there will be a C function declared as
>
> SEXP arma0fa(SEXP, SEXP);
>
> (In fact it is declared in ts.h and defined in pacf.c in that directory)


> Nathaniel B. Derby wrote:
>> Hi,
>> 
>> In my ongoing quest to track down the source of an error (see message "[R] 
>> optim error in arima" above), I find in the cource code for arima0 the 
>> following:
>> 
>>     arma0f <- function(p) {
>>         par <- as.double(fixed)
>>         par[mask] <- p
>>         .Call("arma0fa", G, par, PACKAGE = "stats")
>>     }
>> 
>> I would like to know what the function "arma0f" does.  Does the above mean 
>> that there is a function called "arma0fa" somewhere in R?  Where is it?  I 
>> couldn't find anything in Rinternals.h.



From andy_liaw at merck.com  Tue Sep 28 22:23:58 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 28 Sep 2004 16:23:58 -0400
Subject: [R] Bug? using { as a function in lapply
Message-ID: <3A822319EB35174CA3714066D590DCD504AF846E@usrymx25.merck.com>

But (it seems like) "{" as a primitive function can take arbitrary number of
argument, and return the last argument.  So Gabor's usage seems right, yet
somehow within lapply() "{" doesn't like the way it's being called.

Also, be very careful:

> "{" <- function(x, y) y
> f <- function(a, b) { exp(a+b); a+b; a-b }
> f(1, 2)
Error in { : unused argument(s) ( ...)
> f <- function(a, b) { exp(a+b); a+b }
> f(1, 2)
[1] 3
> f <- function(a, b) { exp(a+b) }
> f(1, 2)
Error in { : Argument "y" is missing, with no default

Andy

> From: Witold 
> 
> Hi,
> 
>  > "{" <- function(x,y)y
>  > "{"(1,9)
> [1] 9
>  > lapply(1:2, "{", 9)
> [[1]]
> [1] 9
> 
> [[2]]
> [1] 9
> 
>  > R.version.string
> [1] "R version 2.0.0, 2004-09-20"
> 
> 
> /E
> 
> Gabor Grothendieck wrote:
> 
> >This seems like a bug to me.  Can someone verify this?  
> >
> >First we define a function f that returns its second argument and 
> >lapply it to 1:2 using 9 as the second argument and all seems well.
> >
> >Note that "{" as a function does the same thing as f, as illustrated 
> >with f(1,9) and "{"(1,9); however, when we attempt to use "{" in the 
> >very same way we used f in lapply, we get an error message about ... 
> >being used in an incorrect context, as shown.
> >
> >I am using R on windows with the version shown at the end.
> >
> >
> >R> f <- function(x,y)y
> >R> f(1,9)
> >[1] 9
> >R> lapply(1:2, f, 9)
> >[[1]]
> >[1] 9
> >
> >[[2]]
> >[1] 9
> > 
> >R> "{"(1,9)
> >[1] 9
> >R> lapply(1:2, "{", 9)
> >Error in lapply(1:2, "{", 9) : ... used in an incorrect context
> >
> >R> R.version.string
> >[1] "R version 1.9.1, 2004-08-03"
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> >  
> >
> 
> 
> -- 
> 
> Dipl. bio-chem. Witold Eryk Wolski         
> MPI-Moleculare Genetic
> Ihnestrasse 63-73 14195 Berlin           _
> tel: 0049-30-83875219                   'v'
> http://www.molgen.mpg.de/~wolski       /   \
> mail: witek96 at users.sourceforge.net  ---W-W----
>       wolski at molgen.mpg.de
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From roebuck at odin.mdacc.tmc.edu  Tue Sep 28 22:24:45 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Tue, 28 Sep 2004 15:24:45 -0500 (CDT)
Subject: [R] S4 method selection based on second argument
Message-ID: <Pine.OSF.4.58.0409281445370.401577@odin.mdacc.tmc.edu>

I'm translating some Matlab code and need some help figuring
out how to change this call into an S4 generic method.

In matlab, there's a function called 'repmat' with three
calling sequences (all I have to deal with anyway):
    1) B = repmat(A, m, n)
    2) B = repmat(A, [m n])
    3) B = repmat(A, n)
In all cases, A is the fill value, m is number of rows,
and n is number of columns.

As separate functions, the translations would roughly be:

repmat1 <- function(A, m, n) {
    kronecker(matrix(1, n, m), A)
}

repmat2 <- function(A, rc) {
    repmat1(A, rc[1], rc[2])
}

repmat3 <- function(A, n) {
    repmat1(A, n, n)
}

Suggestions?


----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From p.murrell at auckland.ac.nz  Tue Sep 28 22:25:50 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 29 Sep 2004 08:25:50 +1200
Subject: [R] Gridbase basic question
References: <E6ED8BE8-0D71-11D9-B970-000A95D7BA10@mail.nih.gov>
	<41588CD7.1050103@stat.auckland.ac.nz>
	<FB8849C8-1136-11D9-AA48-000A95D7BA10@mail.nih.gov>
Message-ID: <4159C8CE.8060409@stat.auckland.ac.nz>

Hi


Sean Davis wrote:
> Paul,
> 
> Thanks for the extensive and clear explanation.  The reason I started  
> with grid is that I am hoping to use a combination of segments,  
> rectangles, and text to describe relatively complex (genes) objects  
> that relate to the x-axis in a plot.  I do appreciate the insight from  
> you and others that the added complexity of grid may not be necessary.


One alternative possibly not yet explored is that you could just use 
grid.  If all you need the traditional graphics for is a bounding box 
and some axes, then something like ...

x <- sample(1:10, 10)
y <- 1:10
w <- runif(10)
h <- 0.5

pushViewport(plotViewport(c(5, 4, 4, 2)), dataViewport(x, y))
grid.rect()
grid.xaxis()
grid.yaxis()
grid.rect(x=x, y=y, width=w, height=h, default.units="native")
popViewport(2)

... does the trick (again, the advantage is that you don't need to mess 
with gridBase).

Paul


> On Sep 27, 2004, at 5:57 PM, Paul Murrell wrote:
> 
>> Hi
>>
>>
>> Sean Davis wrote:
>>
>>> All,
>>> I have a simple plot(x,y) and I would like to then insert rectangles  
>>> of  some length (in native coordinates) and height fixed to 0.5 in  
>>> native  coordinates.  I can't quite get the code right to do this.   
>>> Can anyone  give me a quick example of how to do this?  I looked the  
>>> gridBase index  and the tutorial (from R-news?) but just haven't  
>>> gotten it down yet.
>>>  > plot(1:10,1:10)
>>>  > par(new=T);vps <- baseViewports()
>>>  > pushViewport(vps$inner,vps$figure,vps$plot)
>>> viewport[GRID.VP.28]
>>
>>
>>
>> At this point you are within a viewport which has x- and y-scales  
>> corresponding to the plot(1:10, 1:10).
>>
>>
>>>  > pushViewport(viewport(x=unit(1,"native"),y=unit(2,"native")))
>>> viewport[GRID.VP.29]
>>
>>
>>
>> You have just created a new viewport at location (1, 2) in the plot,  
>> but  the scales on this new viewport are the default (0, 1).  i.e.,  
>> you are now in a completely different coordinate system.  Also, this  
>> new viewport is as wide and as high as the plot region -- for 
>> example,  it extends well beyong the left edge of the window/page.
>>
>>
>>> grid.rect(height=unit(0.5,"native"),width=unit(1.5,"native"),just='bot 
>>> to m')
>>
>>
>>
>> This draws a rectangle half as high as the current viewport and 1.5  
>> times as wide (the native scale in the current viewport is (0, 1) in  
>> both dimensions).  Importantly, the "native" coordinate systems you  
>> are referring to no longer correspond to the scales on the plot.
>>
>>
>>> This draws a very large rectangle going from 2 to 7 (y) and to 8 (x).
>>
>>
>>
>> Three things:
>>
>> (i) If drawing rectangles relative to the current "native" (or user)  
>> coordinates is all you want to do then you could just use rect() and  
>> ignore gridBase altogether.  For example, ...
>>
>> x <- sample(1:10, 10)
>> y <- 1:10
>> w <- runif(10)
>> h <- 0.5
>>
>> plot(1:10,1:10)
>> rect(x - w/2, y - h/2, x + w/2, y + h/2)
>>
>>
>> (ii) Using grid and gridBase, the above example becomes ...
>>
>> plot(1:10,1:10)
>> par(new=T);vps <- baseViewports()
>> pushViewport(vps$inner,vps$figure,vps$plot)
>> grid.rect(x=x, y=y, width=w, height=h, default.units="native")
>> popViewport(3)
>>
>> ... but as mentioned, this is like using a sledge hammer to kill a 
>> cat  or whatever the expression is.
>>
>> (iii) There would be justification in using grid and gridBase if you  
>> want to draw more than just a rectangle, especially if you want to 
>> use  coordinates other than native.  Here's a trivial example (adds 
>> fixed  size "whiskers" to the corners of the rectangles) ...
>>
>> plot(1:10,1:10)
>> par(new=T);vps <- baseViewports()
>> pushViewport(vps$inner,vps$figure,vps$plot)
>> for (i in 1:10) {
>>   pushViewport(viewport(x=x[i], y=y[i], width=w[i], height=h,
>>                         default.units="native"))
>>   grid.rect()
>>   grid.segments(0, 0, unit(-1, "mm"), unit(-1, "mm"))
>>   grid.segments(0, 1, unit(-1, "mm"),
>>                 unit(1, "npc") + unit(1, "mm"))
>>   grid.segments(1, 1,
>>                 unit(1, "npc") + unit(1, "mm"),
>>                 unit(1, "npc") + unit(1, "mm"))
>>   grid.segments(1, 0,
>>                 unit(1, "npc") + unit(1, "mm"),
>>                 unit(-1, "mm"))
>>   popViewport()
>> }
>>
>> ... (but pushing a viewport per data point like this is a LOT slower).
>>
>> Hope that helps
>>
>> Paul
>> -- 
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
> 


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From andy_liaw at merck.com  Tue Sep 28 22:25:37 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 28 Sep 2004 16:25:37 -0400
Subject: [R] Bug? using { as a function in lapply
Message-ID: <3A822319EB35174CA3714066D590DCD504AF846F@usrymx25.merck.com>

> From: Gabor Grothendieck
> 
> Thanks for pointing out that this is already fixed in the upcoming 
> version of R.

It's not.  I was using R-2.0.0beta from 2004-09-24, and it's still that way.

Andy

 
> Witold Eryk Wolski <wolski <at> molgen.mpg.de> writes:
> 
> : 
> : Hi,
> : 
> :  > "{" <- function(x,y)y
> :  > "{"(1,9)
> : [1] 9
> :  > lapply(1:2, "{", 9)
> : [[1]]
> : [1] 9
> : 
> : [[2]]
> : [1] 9
> : 
> :  > R.version.string
> : [1] "R version 2.0.0, 2004-09-20"
> : 
> : /E
> : 
> : Gabor Grothendieck wrote:
> : 
> : >This seems like a bug to me.  Can someone verify this?  
> : >
> : >First we define a function f that returns its second argument and 
> : >lapply it to 1:2 using 9 as the second argument and all seems well.
> : >
> : >Note that "{" as a function does the same thing as f, as 
> illustrated 
> : >with f(1,9) and "{"(1,9); however, when we attempt to use 
> "{" in the 
> : >very same way we used f in lapply, we get an error message 
> about ... 
> : >being used in an incorrect context, as shown.
> : >
> : >I am using R on windows with the version shown at the end.
> : >
> : >
> : >R> f <- function(x,y)y
> : >R> f(1,9)
> : >[1] 9
> : >R> lapply(1:2, f, 9)
> : >[[1]]
> : >[1] 9
> : >
> : >[[2]]
> : >[1] 9
> : > 
> : >R> "{"(1,9)
> : >[1] 9
> : >R> lapply(1:2, "{", 9)
> : >Error in lapply(1:2, "{", 9) : ... used in an incorrect context
> : >
> : >R> R.version.string
> : >[1] "R version 1.9.1, 2004-08-03"
> : >
> : >______________________________________________
> : >R-help <at> stat.math.ethz.ch mailing list
> : >https://stat.ethz.ch/mailman/listinfo/r-help
> : >PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html
> : >
> : >  
> : >
> :
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From andy_liaw at merck.com  Tue Sep 28 22:34:10 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 28 Sep 2004 16:34:10 -0400
Subject: [R] Looking for .Call functions
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8470@usrymx25.merck.com>

You need to download the source for R.  C source is not included with binary
distributions.

Andy

> From: Nathaniel B. Derby
> 
> Hello,
> 
> Thanks for the help.  Unfortunately, my version of R (1.9.1) 
> doesn't have that directory (i.e., within $RSRC\src\library, 
> there is just a subdirectory entitled "windlgs"), and has 
> neither ts.h nor pacf.c in any of its directories.  Could it 
> be that this function is embedded inside a .dll file (like stats.dll)?
> 
> 
> thanks,
> 
> Nate
> 
> 
> > It means that in one of the .c source files in 
> $RSRC/src/library/stats/src 
> > there will be a C function declared as
> >
> > SEXP arma0fa(SEXP, SEXP);
> >
> > (In fact it is declared in ts.h and defined in pacf.c in 
> that directory)
> 
> 
> > Nathaniel B. Derby wrote:
> >> Hi,
> >> 
> >> In my ongoing quest to track down the source of an error 
> (see message "[R] 
> >> optim error in arima" above), I find in the cource code 
> for arima0 the 
> >> following:
> >> 
> >>     arma0f <- function(p) {
> >>         par <- as.double(fixed)
> >>         par[mask] <- p
> >>         .Call("arma0fa", G, par, PACKAGE = "stats")
> >>     }
> >> 
> >> I would like to know what the function "arma0f" does.  
> Does the above mean 
> >> that there is a function called "arma0fa" somewhere in R?  
> Where is it?  I 
> >> couldn't find anything in Rinternals.h.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From linkpema at muohio.edu  Tue Sep 28 22:58:56 2004
From: linkpema at muohio.edu (Melanie A. Link-Perez)
Date: Tue, 28 Sep 2004 16:58:56 -0400 (EDT)
Subject: [R] not understanding geoR "nugget" output
Message-ID: <3990.134.53.9.199.1096405136.squirrel@webmail.muohio.edu>

I am having difficulty understanding the output from a likfit call,
specifically the output for the nugget.  When the partial sill is non-zero,
the estimated nugget that is returned is zero.  When the partial sill is zero,
I get a non-zero nugget.  The following output may be helpful:

Estimation method: maximum likelihood

Parameters of the mean component (trend):
  beta0   beta1   beta2   beta3   beta4   beta5
 2.4299  2.5095  4.8184 -0.0084 -0.0625 -0.0057

Parameters of the spatial component:
   correlation function: spherical
      (estimated) variance parameter sigmasq (partial sill) =  1694
      (estimated) cor. fct. parameter phi (range parameter)  =  32.1
   anisotropy parameters:
      (fixed) anisotropy angle = 0  ( 0 degrees )
      (fixed) anisotropy ratio = 1

Parameter of the error component:
      (estimated) nugget =  0

Transformation parameter:
      (fixed) Box-Cox parameter = 1 (no transformation)

Maximised Likelihood:
   log.L n.params      AIC      BIC
"-98.92"      "9"  "215.8"  "224.8"

non spatial model:
   log.L n.params      AIC      BIC
"-101.5"      "8"  "219.0"  "226.9"

Call:
likfit(geodata = geodataK, trend = "2nd", ini.cov.pars = c(1700,
    50), cov.model = "sph", method.lik = "ML")


---
This is the code I used:

geodataK <- as.geodata(data[,c(2,3,11)], coords.col=1:2, data.col=3)
geodataK
bin4 <- variog(geodataK, uvec=seq(0,163.44,l=21), max.dist=50,
estimator.type="modulus", trend="2nd"); plot(bin4, main = "(f) Potassium",
xlab = "", ylab = "")
mod1 <- likfit(cov.model="sph",geodataK, trend="2nd",ini=c(1700,50),
method="ML");summary(mod1)
lines(mod1, lty=1)

---

I am also trying to figure out how to calculate R^2 values for the likfit
models that I fit to the semivariogram.

I am using R version 1.9.1 (rw1091) and geoR version  1.4-8 on a PC running MS
Windows XP Professional version 2002.


Many thanks,
Melanie Link-Perez
Miami University



From ggrothendieck at myway.com  Tue Sep 28 23:19:46 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 28 Sep 2004 21:19:46 +0000 (UTC)
Subject: [R] Bug? using =?utf-8?b?ew==?= as a function in lapply
References: <3A822319EB35174CA3714066D590DCD504AF846F@usrymx25.merck.com>
Message-ID: <loom.20040928T231529-943@post.gmane.org>

That is odd.  I guess I was premature in jumping to that conclusion.
As another data point, it does work correctly for me in 1.9.1 patched
if I switch from lapply to mapply:

R> lapply(1:2, "{", 9)
Error in lapply(1:2, "{", 9) : ... used in an incorrect context

R> mapply("{", 1:2, 9, SIMPLIFY = FALSE)
[[1]]
[1] 9

[[2]]
[1] 9

R> R.version.string
[1] "R version 1.9.1, 2004-08-03"
 

Liaw, Andy <andy_liaw <at> merck.com> writes:

: 
: > From: Gabor Grothendieck
: > 
: > Thanks for pointing out that this is already fixed in the upcoming 
: > version of R.
: 
: It's not.  I was using R-2.0.0beta from 2004-09-24, and it's still that way.
: 
: Andy
: 
: 
: > Witold Eryk Wolski <wolski <at> molgen.mpg.de> writes:
: > 
: > : 
: > : Hi,
: > : 
: > :  > "{" <- function(x,y)y
: > :  > "{"(1,9)
: > : [1] 9
: > :  > lapply(1:2, "{", 9)
: > : [[1]]
: > : [1] 9
: > : 
: > : [[2]]
: > : [1] 9
: > : 
: > :  > R.version.string
: > : [1] "R version 2.0.0, 2004-09-20"
: > : 
: > : /E
: > : 
: > : Gabor Grothendieck wrote:
: > : 
: > : >This seems like a bug to me.  Can someone verify this?  
: > : >
: > : >First we define a function f that returns its second argument and 
: > : >lapply it to 1:2 using 9 as the second argument and all seems well.
: > : >
: > : >Note that "{" as a function does the same thing as f, as 
: > illustrated 
: > : >with f(1,9) and "{"(1,9); however, when we attempt to use 
: > "{" in the 
: > : >very same way we used f in lapply, we get an error message 
: > about ... 
: > : >being used in an incorrect context, as shown.
: > : >
: > : >I am using R on windows with the version shown at the end.
: > : >
: > : >
: > : >R> f <- function(x,y)y
: > : >R> f(1,9)
: > : >[1] 9
: > : >R> lapply(1:2, f, 9)
: > : >[[1]]
: > : >[1] 9
: > : >
: > : >[[2]]
: > : >[1] 9
: > : > 
: > : >R> "{"(1,9)
: > : >[1] 9
: > : >R> lapply(1:2, "{", 9)
: > : >Error in lapply(1:2, "{", 9) : ... used in an incorrect context
: > : >
: > : >R> R.version.string
: > : >[1] "R version 1.9.1, 2004-08-03"
: > : >
: > : >______________________________________________
: > : >R-help <at> stat.math.ethz.ch mailing list
: > : >https://stat.ethz.ch/mailman/listinfo/r-help
: > : >PLEASE do read the posting guide! http://www.R-project.org/posting-
: > guide.html
: > : >
: > : >  
: > : >
: > :
: > 
: > ______________________________________________
: > R-help <at> stat.math.ethz.ch mailing list
: > https://stat.ethz.ch/mailman/listinfo/r-help
: > PLEASE do read the posting guide! 
: > http://www.R-project.org/posting-guide.html
: > 
: >
: 
: ______________________________________________
: R-help <at> stat.math.ethz.ch mailing list
: https://stat.ethz.ch/mailman/listinfo/r-help
: PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
: 
:



From p.dalgaard at biostat.ku.dk  Tue Sep 28 23:40:33 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 28 Sep 2004 23:40:33 +0200
Subject: [R] Bug? using { as a function in lapply
In-Reply-To: <loom.20040928T221843-574@post.gmane.org>
References: <loom.20040928T215129-758@post.gmane.org>
	<4159C5C3.7000202@molgen.mpg.de>
	<loom.20040928T221843-574@post.gmane.org>
Message-ID: <x2d606ysvi.fsf@biostat.ku.dk>

Gabor Grothendieck <ggrothendieck at myway.com> writes:

> Thanks for pointing out that this is already fixed in the upcoming 
> version of R.

It isn't. Look closer.

I'm not sure this qualifies as a bug though. It boils down to

> f <- function(...){...}
> f()
Error in f() : ... used in an incorrect context

This doesn't work in S-PLUS either:

> f <- function(...){...}
> f()
Problem in f(): "..." may only be used as an argument in a call
Use traceback() to see the call stack

But S(-PLUS) doesn't actually have a function "{", it's part of syntax
but not actually put into functions (and if R had better deparsing,
may it could do likewise).

-------------
 
> Witold Eryk Wolski <wolski <at> molgen.mpg.de> writes:
> 
> : 
> : Hi,
> : 
> :  > "{" <- function(x,y)y
> :  > "{"(1,9)
> : [1] 9
> :  > lapply(1:2, "{", 9)
> : [[1]]
> : [1] 9
> : 
> : [[2]]
> : [1] 9
> : 
> :  > R.version.string
> : [1] "R version 2.0.0, 2004-09-20"
> : 
> : /E
> : 
> : Gabor Grothendieck wrote:
> : 
> : >This seems like a bug to me.  Can someone verify this?  
> : >
> : >First we define a function f that returns its second argument and 
> : >lapply it to 1:2 using 9 as the second argument and all seems well.
> : >
> : >Note that "{" as a function does the same thing as f, as illustrated 
> : >with f(1,9) and "{"(1,9); however, when we attempt to use "{" in the 
> : >very same way we used f in lapply, we get an error message about ... 
> : >being used in an incorrect context, as shown.
> : >
> : >I am using R on windows with the version shown at the end.
> : >
> : >
> : >R> f <- function(x,y)y
> : >R> f(1,9)
> : >[1] 9
> : >R> lapply(1:2, f, 9)
> : >[[1]]
> : >[1] 9
> : >
> : >[[2]]
> : >[1] 9
> : > 
> : >R> "{"(1,9)
> : >[1] 9
> : >R> lapply(1:2, "{", 9)
> : >Error in lapply(1:2, "{", 9) : ... used in an incorrect context
> : >
> : >R> R.version.string
> : >[1] "R version 1.9.1, 2004-08-03"
> : >
> : >______________________________________________
> : >R-help <at> stat.math.ethz.ch mailing list
> : >https://stat.ethz.ch/mailman/listinfo/r-help
> : >PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html
> : >
> : >  
> : >
> :
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From wolski at molgen.mpg.de  Wed Sep 29 00:24:12 2004
From: wolski at molgen.mpg.de (Witold Eryk Wolski)
Date: Wed, 29 Sep 2004 00:24:12 +0200
Subject: [R] S4 method selection based on second argument
In-Reply-To: <Pine.OSF.4.58.0409281445370.401577@odin.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0409281445370.401577@odin.mdacc.tmc.edu>
Message-ID: <4159E48C.7090803@molgen.mpg.de>

Hi,
If it's the only reason why you think you have to use S4 then take a 
look at ?missing.
If you are interested in S4:
The first version gives an overview of setMethods. Then I give a simpler 
example. And finally a pure ?missing solution.

A) Declare function repmat as generic
if(!isGeneric("repmat"))
setGeneric("repmat"
           ,function(obx,oby,obz,...)
           standardGeneric("repmat"))

#B = repmat(A, m, n)

setMethod("repmat",signature(obx="numeric",oby="numeric",obz="numeric")
    ,function(obx,oby,obz){print("thre arg call")
    })

#B = repmat(A, [m n])
#B = repmat(A, n)

setMethod("repmat",signature(obx="numeric",oby="numeric",obz="missing")
    ,function(obx,oby)
    {
       print("two arg")
    #handle the difference in oby.
        if(length(oby)==1)
         oby
       else
         obx
    })

##END A ###
#simpler

#if(!isGeneric("repmat")) #commented out because you have already declared it.
setGeneric("repmat"
           ,function(object,...)
           standardGeneric("repmat"))

setMethod("repmat",signature(object="numeric")
,function(object,oby,obz)
{
	#using ?missing handle the differences.
	if(missing(obz))
	print("new version")
})

Note that you can have the same in S3 using ?missing
something like this.

repmat <- function(A, m, n) {
	if(missing(n)
	{
		if(length(m)==2)
			{	
				repmat1(A, m[1], m[2])
			}
		else
		kronecker(matrix(1, m, m), A)	
	}
	kronecker(matrix(1, n, m), A)}
}
/E



Paul Roebuck wrote:

>I'm translating some Matlab code and need some help figuring
>out how to change this call into an S4 generic method.
>
>In matlab, there's a function called 'repmat' with three
>calling sequences (all I have to deal with anyway):
>    1) B = repmat(A, m, n)
>    2) B = repmat(A, [m n])
>    3) B = repmat(A, n)
>In all cases, A is the fill value, m is number of rows,
>and n is number of columns.
>
>As separate functions, the translations would roughly be:
>
>repmat1 <- function(A, m, n) {
>    kronecker(matrix(1, n, m), A)
>}
>  
>

>repmat2 <- function(A, rc) {
>    repmat1(A, rc[1], rc[2])
>}
>
>repmat3 <- function(A, n) {
>    repmat1(A, n, n)
>}
>
>Suggestions?
>
>
>----------------------------------------------------------
>SIGSIG -- signature too long (core dumped)
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>


-- 
Dipl. bio-chem. Witold Eryk Wolski         
MPI-Moleculare Genetic
Ihnestrasse 63-73 14195 Berlin           _
tel: 0049-30-83875219                   'v'
http://www.molgen.mpg.de/~wolski       /   \
mail: witek96 at users.sourceforge.net  ---W-W----
      wolski at molgen.mpg.de



From ggrothendieck at myway.com  Wed Sep 29 00:28:03 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 28 Sep 2004 22:28:03 +0000 (UTC)
Subject: [R] Bug? using =?utf-8?b?ew==?= as a function in lapply
References: <loom.20040928T215129-758@post.gmane.org>
	<4159C5C3.7000202@molgen.mpg.de>
	<loom.20040928T221843-574@post.gmane.org>
	<x2d606ysvi.fsf@biostat.ku.dk>
Message-ID: <loom.20040929T002444-474@post.gmane.org>

Peter Dalgaard <p.dalgaard <at> biostat.ku.dk> writes:

: 
: Gabor Grothendieck <ggrothendieck <at> myway.com> writes:
: 
: > Thanks for pointing out that this is already fixed in the upcoming 
: > version of R.
: 
: It isn't. Look closer.
: 
: I'm not sure this qualifies as a bug though. It boils down to
: 
: > f <- function(...){...}
: > f()
: Error in f() : ... used in an incorrect context
: 
: This doesn't work in S-PLUS either:
: 
: > f <- function(...){...}
: > f()
: Problem in f(): "..." may only be used as an argument in a call
: Use traceback() to see the call stack
: 
: But S(-PLUS) doesn't actually have a function "{", it's part of syntax
: but not actually put into functions (and if R had better deparsing,
: may it could do likewise).

Perhaps that explains why it fails but its not clear to me that this
justifies the error, especially when you consider the fact that mapply 
got it right.



From ggrothendieck at myway.com  Wed Sep 29 00:40:43 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 28 Sep 2004 22:40:43 +0000 (UTC)
Subject: [R] S4 method selection based on second argument
References: <Pine.OSF.4.58.0409281445370.401577@odin.mdacc.tmc.edu>
Message-ID: <loom.20040929T003529-49@post.gmane.org>

Paul Roebuck <roebuck <at> odin.mdacc.tmc.edu> writes:

: 
: I'm translating some Matlab code and need some help figuring
: out how to change this call into an S4 generic method.
: 
: In matlab, there's a function called 'repmat' with three
: calling sequences (all I have to deal with anyway):
:     1) B = repmat(A, m, n)
:     2) B = repmat(A, [m n])
:     3) B = repmat(A, n)
: In all cases, A is the fill value, m is number of rows,
: and n is number of columns.
: 
: As separate functions, the translations would roughly be:
: 
: repmat1 <- function(A, m, n) {
:     kronecker(matrix(1, n, m), A)
: }
: 
: repmat2 <- function(A, rc) {
:     repmat1(A, rc[1], rc[2])
: }
: 
: repmat3 <- function(A, n) {
:     repmat1(A, n, n)
: }
: 
: Suggestions?

This can be done easily without any oo dispatch like this:

repmat <- function(A, m, n = if (length(m) == 1)m) {
	m <- c(m, n)
	stopifnot(length(m) == 2)
	kronecker(matrix(1,m[1],m[2]),A)
}



From p.dalgaard at biostat.ku.dk  Wed Sep 29 01:02:50 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Sep 2004 01:02:50 +0200
Subject: [R] Bug? using { as a function in lapply
In-Reply-To: <loom.20040929T002444-474@post.gmane.org>
References: <loom.20040928T215129-758@post.gmane.org>
	<4159C5C3.7000202@molgen.mpg.de>
	<loom.20040928T221843-574@post.gmane.org>
	<x2d606ysvi.fsf@biostat.ku.dk>
	<loom.20040929T002444-474@post.gmane.org>
Message-ID: <x24qliyp2d.fsf@biostat.ku.dk>

Gabor Grothendieck <ggrothendieck at myway.com> writes:

> Peter Dalgaard <p.dalgaard <at> biostat.ku.dk> writes:
> 
> : 
> : Gabor Grothendieck <ggrothendieck <at> myway.com> writes:
> : 
> : > Thanks for pointing out that this is already fixed in the upcoming 
> : > version of R.
> : 
> : It isn't. Look closer.
> : 
> : I'm not sure this qualifies as a bug though. It boils down to
> : 
> : > f <- function(...){...}
> : > f()
> : Error in f() : ... used in an incorrect context
> : 
> : This doesn't work in S-PLUS either:
> : 
> : > f <- function(...){...}
> : > f()
> : Problem in f(): "..." may only be used as an argument in a call
> : Use traceback() to see the call stack
> : 
> : But S(-PLUS) doesn't actually have a function "{", it's part of syntax
> : but not actually put into functions (and if R had better deparsing,
> : may it could do likewise).
> 
> Perhaps that explains why it fails but its not clear to me that this
> justifies the error, especially when you consider the fact that mapply 
> got it right.

mapply doesn't pass "extras" using "...", but uses the MoreArgs list
instead.
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From ggrothendieck at myway.com  Wed Sep 29 01:32:23 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Tue, 28 Sep 2004 23:32:23 +0000 (UTC)
Subject: [R] Bug? using =?utf-8?b?ew==?= as a function in lapply
References: <loom.20040928T215129-758@post.gmane.org>
	<4159C5C3.7000202@molgen.mpg.de>
	<loom.20040928T221843-574@post.gmane.org>
	<x2d606ysvi.fsf@biostat.ku.dk>
	<loom.20040929T002444-474@post.gmane.org>
	<x24qliyp2d.fsf@biostat.ku.dk>
Message-ID: <loom.20040929T013021-389@post.gmane.org>

Peter Dalgaard <p.dalgaard <at> biostat.ku.dk> writes:

: 
: Gabor Grothendieck <ggrothendieck <at> myway.com> writes:
: 
: > Peter Dalgaard <p.dalgaard <at> biostat.ku.dk> writes:
: > 
: > : 
: > : Gabor Grothendieck <ggrothendieck <at> myway.com> writes:
: > : 
: > : > Thanks for pointing out that this is already fixed in the upcoming 
: > : > version of R.
: > : 
: > : It isn't. Look closer.
: > : 
: > : I'm not sure this qualifies as a bug though. It boils down to
: > : 
: > : > f <- function(...){...}
: > : > f()
: > : Error in f() : ... used in an incorrect context
: > : 
: > : This doesn't work in S-PLUS either:
: > : 
: > : > f <- function(...){...}
: > : > f()
: > : Problem in f(): "..." may only be used as an argument in a call
: > : Use traceback() to see the call stack
: > : 
: > : But S(-PLUS) doesn't actually have a function "{", it's part of syntax
: > : but not actually put into functions (and if R had better deparsing,
: > : may it could do likewise).
: > 
: > Perhaps that explains why it fails but its not clear to me that this
: > justifies the error, especially when you consider the fact that mapply 
: > got it right.
: 
: mapply doesn't pass "extras" using "...", but uses the MoreArgs list
: instead.

lapply could contain a statement such as:

   moreargs <- list(...)

to reduce it to that case.



From paulojus at est.ufpr.br  Wed Sep 29 03:32:42 2004
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Tue, 28 Sep 2004 22:32:42 -0300 (BRT)
Subject: [R] not understanding geoR "nugget" output
In-Reply-To: <3990.134.53.9.199.1096405136.squirrel@webmail.muohio.edu>
References: <3990.134.53.9.199.1096405136.squirrel@webmail.muohio.edu>
Message-ID: <Pine.LNX.4.58L0.0409282227050.26194@est.ufpr.br>

Melaine

When estimated phi=0 or sigmasq=0 the odel is a "pure nugget effect" and
you cannot distinguish between sigmasq and tausq
Therefore it is a convention in geoR to assign the estimated varioance to
tausq.

Regarding R^2:
forgaussian models you can compute this values using the maximised
likelihood and othe model information

Alternatively you can use likfit with the argument components=T.
This will return the estimated model components frwom which you can
compute R^2.

Since this is a package specific question feel free to contact me directly
if you have any further queries
best
P.J.



On Tue, 28 Sep 2004, Melanie A. Link-Perez wrote:

> I am having difficulty understanding the output from a likfit call,
> specifically the output for the nugget.  When the partial sill is non-zero,
> the estimated nugget that is returned is zero.  When the partial sill is zero,
> I get a non-zero nugget.  The following output may be helpful:
>
> Estimation method: maximum likelihood
>
> Parameters of the mean component (trend):
>   beta0   beta1   beta2   beta3   beta4   beta5
>  2.4299  2.5095  4.8184 -0.0084 -0.0625 -0.0057
>
> Parameters of the spatial component:
>    correlation function: spherical
>       (estimated) variance parameter sigmasq (partial sill) =  1694
>       (estimated) cor. fct. parameter phi (range parameter)  =  32.1
>    anisotropy parameters:
>       (fixed) anisotropy angle = 0  ( 0 degrees )
>       (fixed) anisotropy ratio = 1
>
> Parameter of the error component:
>       (estimated) nugget =  0
>
> Transformation parameter:
>       (fixed) Box-Cox parameter = 1 (no transformation)
>
> Maximised Likelihood:
>    log.L n.params      AIC      BIC
> "-98.92"      "9"  "215.8"  "224.8"
>
> non spatial model:
>    log.L n.params      AIC      BIC
> "-101.5"      "8"  "219.0"  "226.9"
>
> Call:
> likfit(geodata = geodataK, trend = "2nd", ini.cov.pars = c(1700,
>     50), cov.model = "sph", method.lik = "ML")
>
>
> ---
> This is the code I used:
>
> geodataK <- as.geodata(data[,c(2,3,11)], coords.col=1:2, data.col=3)
> geodataK
> bin4 <- variog(geodataK, uvec=seq(0,163.44,l=21), max.dist=50,
> estimator.type="modulus", trend="2nd"); plot(bin4, main = "(f) Potassium",
> xlab = "", ylab = "")
> mod1 <- likfit(cov.model="sph",geodataK, trend="2nd",ini=c(1700,50),
> method="ML");summary(mod1)
> lines(mod1, lty=1)
>
> ---
>
> I am also trying to figure out how to calculate R^2 values for the likfit
> models that I fit to the semivariogram.
>
> I am using R version 1.9.1 (rw1091) and geoR version  1.4-8 on a PC running MS
> Windows XP Professional version 2002.
>
>
> Many thanks,
> Melanie Link-Perez
> Miami University
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>

Paulo Justiniano Ribeiro Jr
Departamento de Estat??stica
Universidade Federal do Paran??
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 361 3573
Fax: (+55) 41 361 3141
e-mail: paulojus at est.ufpr.br
http://www.est.ufpr.br/~paulojus

 /"\
 \ /  Campanha da fita ASCII - contra mail html
  X   ASCII ribbon campaign - against html mail
 / \



From vikas at mail.jnu.ac.in  Wed Sep 29 07:10:07 2004
From: vikas at mail.jnu.ac.in (Vikas Rawal)
Date: Wed, 29 Sep 2004 10:40:07 +0530
Subject: [R] Re: read dbf files into R
In-Reply-To: <20040928115428.65877.qmail@web41214.mail.yahoo.com>
References: <20040928115428.65877.qmail@web41214.mail.yahoo.com>
Message-ID: <415A43AF.90106@mail.jnu.ac.in>


Is there a linux-based/free command line tool for converting dbf files 
into txt? Conceptually, it is not a great way of doing things. We have a 
dbf file with a well defined structure. We convert it into a text file, 
which has a loose structure, undefined variables types etc. And then we 
read the text file. I should be much better to directly read a dbf file 
and use its database structure definition to ensure that data come into 
R correctly.

RODBC route does not seem suitable for my needs. I need to read some 300 
files, and combine all the data. Using ODBC would mean that I would have 
to set up 300 DSNs in the odbc.ini.

Or is there a way to set it up from the command line as well? I suppose 
it must be possible to write a script that will suitably modify odbc.ini 
file. But that sounds far too complicated.

I have been a user of SAS for a long time. This exercise would be done 
in a flash there. I wish there was a simple way of doing it in R.

Don't we have a simple command that will read a dbf file, or in fact, a 
set of commands that will read common file formats. I see that we can 
read SAS, STATA and SPSS files. Somebody would have thought of doing the 
same for dbf. Isn't it?

Vikas

Vikas



Vito Ricci wrote:

>Hi,
>
>read the manual: 
>R Data Import/Export
>http://cran.r-project.org/doc/manuals/R-data.pdf
>
>Another way is to convert .dbf file in .txt and use
>read.table(), scan() an similar.
>
>Best
>Vito
>
>
>You wrote:
>
>I run R on redhat linux.
>What would be the easiest way to read dbf files into
>R?
>
>Vikas
>
>=====
>Diventare costruttori di soluzioni
>
>"The business of the statistician is to catalyze 
>the scientific learning process."  
>George E. P. Box
>
>
>Visitate il portale http://www.modugno.it/
>e in particolare la sezione su Palese http://www.modugno.it/archivio/cat_palese.shtml
>
>
>		
>___________________________________
>
>
>  
>



From vikas at mail.jnu.ac.in  Wed Sep 29 07:19:55 2004
From: vikas at mail.jnu.ac.in (Vikas Rawal)
Date: Wed, 29 Sep 2004 10:49:55 +0530
Subject: [R] read dbf files into R
In-Reply-To: <OF4800CAE3.5A4191D1-ON85256F1D.004288E0-85256F1D.0042D984@hgsi.com>
References: <OF4800CAE3.5A4191D1-ON85256F1D.004288E0-85256F1D.0042D984@hgsi.com>
Message-ID: <415A45FB.2000004@mail.jnu.ac.in>

It looks like there is no free dbf driver for unixodbc.

Vikas

partha_bagchi at hgsi.com wrote:

>Have you checkout out "R Data Import / Export"? In particular, check out 
>RODBC developed by Brian Ripley and Michael Lapsley.
>
>HTH,
>Partha
>
>
>
>
>
>Vikas Rawal <vikas at mail.jnu.ac.in>
>Sent by: r-help-bounces at stat.math.ethz.ch
>09/28/2004 07:11 AM
>
> 
>        To:     r-help at stat.math.ethz.ch
>        cc: 
>        Subject:        [R] read dbf files into R
>
>
>I run R on redhat linux.
>What would be the easiest way to read dbf files into R?
>
>Vikas
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>
>  
>



From kbartz at loyaltymatrix.com  Wed Sep 29 07:27:38 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Tue, 28 Sep 2004 22:27:38 -0700
Subject: [R] Re: read dbf files into R
In-Reply-To: <415A43AF.90106@mail.jnu.ac.in>
References: <20040928115428.65877.qmail@web41214.mail.yahoo.com>
	<415A43AF.90106@mail.jnu.ac.in>
Message-ID: <415A47CA.2010803@loyaltymatrix.com>

Vikas Rawal wrote:
> 
> Is there a linux-based/free command line tool for converting dbf files 
> into txt? Conceptually, it is not a great way of doing things. We have a 
> dbf file with a well defined structure. We convert it into a text file, 
> which has a loose structure, undefined variables types etc. And then we 
> read the text file. I should be much better to directly read a dbf file 
> and use its database structure definition to ensure that data come into 
> R correctly.
> 
> RODBC route does not seem suitable for my needs. I need to read some 300 
> files, and combine all the data. Using ODBC would mean that I would have 
> to set up 300 DSNs in the odbc.ini.
> 
> Or is there a way to set it up from the command line as well? I suppose 
> it must be possible to write a script that will suitably modify odbc.ini 
> file. But that sounds far too complicated.
> 
> I have been a user of SAS for a long time. This exercise would be done 
> in a flash there. I wish there was a simple way of doing it in R.
> 
> Don't we have a simple command that will read a dbf file, or in fact, a 
> set of commands that will read common file formats. I see that we can 
> read SAS, STATA and SPSS files. Somebody would have thought of doing the 
> same for dbf. Isn't it?
> 
> Vikas
> 
> Vikas
> 
> 
> 
> Vito Ricci wrote:
> 
>> Hi,
>>
>> read the manual: R Data Import/Export
>> http://cran.r-project.org/doc/manuals/R-data.pdf
>>
>> Another way is to convert .dbf file in .txt and use
>> read.table(), scan() an similar.
>>
>> Best
>> Vito
>>
>>
>> You wrote:
>>
>> I run R on redhat linux.
>> What would be the easiest way to read dbf files into
>> R?
>>
>> Vikas
>>
>> =====
>> Diventare costruttori di soluzioni
>>
>> "The business of the statistician is to catalyze the scientific 
>> learning process."  George E. P. Box
>>
>>
>> Visitate il portale http://www.modugno.it/
>> e in particolare la sezione su Palese 
>> http://www.modugno.it/archivio/cat_palese.shtml
>>
>>
>>        
>> ___________________________________
>>
>>
>>  
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 

Hi Vikas,

I use dbf.read from the maptools package available on CRAN. The package 
itself is intended to read Arcview shapefiles, but dbf.read can read a 
general dbf and throw it into an R data frame. Because dbf.read's not in 
maptools' namespace, however, you'll have to access it directly; e.g.,

## Non-trivial example: Read ZIP-county mapping file from www.census.gov
 > zipnov <- maptools:::dbf.read("/home/kevin/census/zipnov99.DBF")
 > head(zipnov)
   ZIP_CODE   LATITUDE   LONGITUDE ZIP_CLASS     PONAME STATE COUNTY
1    00210 +43.005895 -071.013202         U PORTSMOUTH    33    015
2    00211 +43.005895 -071.013202         U PORTSMOUTH    33    015
3    00212 +43.005895 -071.013202         U PORTSMOUTH    33    015
4    00213 +43.005895 -071.013202         U PORTSMOUTH    33    015
5    00214 +43.005895 -071.013202         U PORTSMOUTH    33    015
6    00215 +43.005895 -071.013202         U PORTSMOUTH    33    015

 From there, you could write it out into a text file:

## Write to csv with usual options set
write.table(zipnov, row.names = F, sep = ",", file = "zipnov.csv")

Let me know if you have any questions.

Kevin



From leisch at ci.tuwien.ac.at  Wed Sep 29 09:55:12 2004
From: leisch at ci.tuwien.ac.at (Friedrich Leisch)
Date: Wed, 29 Sep 2004 09:55:12 +0200
Subject: [R] Pixmap problem
In-Reply-To: <Pine.LNX.4.44.0408252058240.19494-100000@reclus.nhh.no>
References: <001001c48a8e$a953ff60$434e2880@geol.ucl.ac.uk>
	<Pine.LNX.4.44.0408252058240.19494-100000@reclus.nhh.no>
Message-ID: <E1CCZIu-0000qE-00@celebrian.ci.tuwien.ac.at>

>>>>> On Wed, 25 Aug 2004 21:42:55 +0200 (CEST),
>>>>> Roger Bivand (RB) wrote:

  > On Wed, 25 Aug 2004, Benjamin Lloyd-Hughes wrote:
  >> Hi,
  >> 
  >> I'm having trouble writing .pnm images which I think is due to a problem
  >> with my colour space.  The pixmap object seems to be looking for 72 of 8
  >> colours (one per cell?) which doesn't seem healthy...
  >> 
  >> > library(pixmap)
  >> > x <- pixmapIndexed(rep(1:8, 9), nrow=6, col=rainbow(8))
  >> > x
  >> Pixmap image
  >> Type          : pixmapIndexed 
  >> Size          : 6x12 
  >> Resolution    : 1x1 
  >> Bounding box  : 0 0 12 6 
  >> Nr. of colors : 72 of 8 
  >> 
  >> > write.pnm(x, file="D:/Temp/output.pnm")
  >> Error in options(x) : evaluation nested too deeply: infinite recursion /
  >> options(expression=)?

  > This one is in:

  >> x <- pixmapIndexed(rep(1:8, 9), nrow=6, col=rainbow(8))
  >> as(x, "pixmapRGB")
  > Error in options(x) : evaluation nested too deeply: infinite recursion / 
  > options(expression=)?


Actually that was a bug in the methods package of R which was
triggered by pixmap, i.e., no pixmap problem. It has been fixed in the
soon to be released version 2.0.0 of R. Sorry for the late answer, I
have been travelling for most of the last month and didn't have
Internet access all the time, hence the pile of unanswered emails got
larger and larger.

Best,
Fritz

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f????r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit????t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra????e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch



From B.Rowlingson at lancaster.ac.uk  Wed Sep 29 10:32:28 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 29 Sep 2004 09:32:28 +0100
Subject: [R] Re: read dbf files into R
In-Reply-To: <415A43AF.90106@mail.jnu.ac.in>
References: <20040928115428.65877.qmail@web41214.mail.yahoo.com>
	<415A43AF.90106@mail.jnu.ac.in>
Message-ID: <415A731C.20005@lancaster.ac.uk>

Vikas Rawal wrote:
> 
> Is there a linux-based/free command line tool for converting dbf files 
> into txt? 

  If you really want to do this, and you dont really need this read dbfs 
into R, there's "dbfdump" in the shapefile library.

   http://shapelib.maptools.org/

   http://shapelib.maptools.org/shapelib-tools.html#dbfdump

> I should be much better to directly read a dbf file 
> and use its database structure definition to ensure that data come into 
> R correctly.

  Several solutions posted to R-help recently.

Barry



From Soren.Hojsgaard at agrsci.dk  Wed Sep 29 11:48:47 2004
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Wed, 29 Sep 2004 11:48:47 +0200
Subject: [R] Getting the model matrix etc from a gee object
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC01AACC9B@DJFPOST01.djf.agrsci.dk>

Dear all,
I am trying to get the model matrix out of a gee object, but that functionality does not seem 
to be there. Similarly with model.frame for gee objects... Or have I overlooked something?
Best regards
S??ren

============================================================================================= 
S??ren H??jsgaard,  PhD, Head of Research Unit    Phone: +45 8999 1703 
Biometry Research Unit,                         Fax:     +45 8999 1300 
Danish Institute of Agricultural Sciences       E-mail: sorenh at agrsci.dk 
Research Centre Foulum, DK-8830 Tjele, Denmark  Homepage : http://www.jbs.agrsci.dk/~sorenh/ 

.... Time flies like an arrow, fruit flies like a banana ....



From Ted.Harding at nessie.mcc.ac.uk  Wed Sep 29 12:43:44 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 29 Sep 2004 11:43:44 +0100 (BST)
Subject: [R] Re: read dbf files into R
In-Reply-To: <415A43AF.90106@mail.jnu.ac.in>
Message-ID: <XFMail.040929114344.Ted.Harding@nessie.mcc.ac.uk>

On 29-Sep-04 Vikas Rawal wrote:
> 
> Is there a linux-based/free command line tool for converting
> dbf files into txt?

It might not be difficult to write one. You basically need to
first decipher the file header, after which reading in the
database records is straightfoward.

DBF file structure (byte counts start at 0):

    0: dBASE version number
 1- 3: Date of last update (YY MM DD as 3 separate BCD bytes)
 4- 7: (binary int) Number of records in file
 8- 9: (binary int) Total number of bytes in header (incl final "0Dh")
10-11: (binary int) Number of bytes per record
12-31: Reserved (not needed for reading file)
32-**: Series of 32-byte descriptions, one for each field
Last : "Carriage-return" byte (hex "0D")

For each 32-byte field descriptor:

 0-10: Name of field (padded with zero "00" bytes)
   11: Field type (ASCII letter: C N L D or M)
12-15: Field RAM address (not relevant for reading file)
   16: (binary int) Length of field in bytes
   17: (binary int) Number of decimal places
18-31: Not usefully informative for reading file

So if there are N fields, the header will occupy 32*(N+1)+1 bytes.

Thereafter, you can work out the length of each record in bytes
from the info in the field descriptors; each record starts with
an additional byte which is "*" if the record is marked for
deletion, otherwise " " (space). There is no delimiter at the
end of a field, nor at the end of a record (so use simply byte
counts).

Then read in that number of bytes, dissect it into fields (according
to field lengths), and output the contents (e.g. comma-delimited)
into one line of the destination. Repeat until no more records remain.

All info in fields is stored as ASCII-coded characters, so can
be written straight out once read in.

Note that Logical data (always 1 byte) may be
"?" "Y", "y", "N", "n", "T", "t", "F", "f"

and Date data are YYYYMMDD

(I'm assuming that there are no "Memo" data, which are not stored
in the DBF file but in a separate DBT file).

Hope this helps,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861  [NB: New number!]
Date: 29-Sep-04                                       Time: 11:43:44
------------------------------ XFMail ------------------------------



From john.gavin at ubs.com  Wed Sep 29 13:17:12 2004
From: john.gavin at ubs.com (john.gavin@ubs.com)
Date: Wed, 29 Sep 2004 12:17:12 +0100
Subject: [R] defining a template for functions via do.call and substitute.
Message-ID: <012821F286ED1D4ABDC72F9E1DD63D0C041EA9C3@NLDNC003PEX1.ubsgs.ubsgroup.net>

Hi,

Given a function

  fun <- function(a, b) a + b

how do I generate the function 'function(x, y) x + y'?

Working from the help files and Bill Venables' R-news article (June 2002),
I have tried various permutations with substitute without success. 
e.g.
  do.call("substitute", list(fun, list(a = as.name("x"), b = as.name("y"))))

Regards,

John.

John Gavin <john.gavin at ubs.com>,
Quantitative Risk Models and Statistics,
UBS Investment Bank, 6th floor, 
100 Liverpool St., London EC2M 2RH, UK.
Phone +44 (0) 207 567 4289
Fax   +44 (0) 207 568 5352

Visit our website at http://www.ubs.com

This message contains confidential information and is intend...{{dropped}}



From hi_ono2001 at ybb.ne.jp  Wed Sep 29 13:49:32 2004
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Wed, 29 Sep 2004 20:49:32 +0900 (JST)
Subject: [R] Re: read dbf files into R
In-Reply-To: <XFMail.040929114344.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <20040929114932.23456.qmail@web1702.mail.yahoo.co.jp>

> > Is there a linux-based/free command line tool for
> converting
> > dbf files into txt?
> 

 How about DBF2CSV 1.0 in
http://www.dirfile.com/dbf2csv.htm.

 This is a perl script.

 Best wishes.



From allan at stats.uct.ac.za  Wed Sep 29 13:58:12 2004
From: allan at stats.uct.ac.za (allan clark)
Date: Wed, 29 Sep 2004 13:58:12 +0200
Subject: [R] R: string connections
Message-ID: <415AA354.6FEE452F@stats.uct.ac.za>

hi all


i have a simple question:

lets assume that i can enter a variable (a) equal to some value, say
100. obviously a could be any value. i would like to create a plot with
a main heading as
hi all


"some writing" + a

how would own create a string by combining a string with a numeric
variable?

hope the question is not too confusing.

e.g. say a=5  then i want something like  plot(x, main="some writing"+a)

this obviously does not work since the syntax is incorrect.

thankful for your replies.



From andy_liaw at merck.com  Wed Sep 29 14:04:32 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 29 Sep 2004 08:04:32 -0400
Subject: [R] R: string connections
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8474@usrymx25.merck.com>

Use paste(), which coerces non-character arguments into characters before
concatenating them.

Andy

> From: allan clark
> 
> hi all
> 
> 
> i have a simple question:
> 
> lets assume that i can enter a variable (a) equal to some value, say
> 100. obviously a could be any value. i would like to create a 
> plot with
> a main heading as
> hi all
> 
> 
> "some writing" + a
> 
> how would own create a string by combining a string with a numeric
> variable?
> 
> hope the question is not too confusing.
> 
> e.g. say a=5  then i want something like  plot(x, main="some 
> writing"+a)
> 
> this obviously does not work since the syntax is incorrect.
> 
> thankful for your replies.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From partha_bagchi at hgsi.com  Wed Sep 29 14:05:08 2004
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Wed, 29 Sep 2004 08:05:08 -0400
Subject: [R] R: string connections
Message-ID: <OFDC981DC0.6994EF2C-ON85256F1E.00425CFC-85256F1E.00426423@hgsi.com>

?paste





allan clark <allan at stats.uct.ac.za>
Sent by: r-help-bounces at stat.math.ethz.ch
09/29/2004 07:58 AM

 
        To:     Rhelp <r-help at stat.math.ethz.ch>
        cc: 
        Subject:        [R] R: string connections


hi all


i have a simple question:

lets assume that i can enter a variable (a) equal to some value, say
100. obviously a could be any value. i would like to create a plot with
a main heading as
hi all


"some writing" + a

how would own create a string by combining a string with a numeric
variable?

hope the question is not too confusing.

e.g. say a=5  then i want something like  plot(x, main="some writing"+a)

this obviously does not work since the syntax is incorrect.

thankful for your replies.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Sep 29 14:10:06 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 29 Sep 2004 14:10:06 +0200
Subject: [R] R: string connections
References: <415AA354.6FEE452F@stats.uct.ac.za>
Message-ID: <001c01c4a61d$41c309e0$b2133a86@www.domain>

Hi Allan,

look at ?paste, e.g.,

a <- 10
plot(1:10, 1:10, main=paste("The value of a is", a))

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "allan clark" <allan at stats.uct.ac.za>
To: "Rhelp" <r-help at stat.math.ethz.ch>
Sent: Wednesday, September 29, 2004 1:58 PM
Subject: [R] R: string connections


> hi all
>
>
> i have a simple question:
>
> lets assume that i can enter a variable (a) equal to some value, say
> 100. obviously a could be any value. i would like to create a plot 
> with
> a main heading as
> hi all
>
>
> "some writing" + a
>
> how would own create a string by combining a string with a numeric
> variable?
>
> hope the question is not too confusing.
>
> e.g. say a=5  then i want something like  plot(x, main="some 
> writing"+a)
>
> this obviously does not work since the syntax is incorrect.
>
> thankful for your replies.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Wed Sep 29 14:13:22 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 29 Sep 2004 08:13:22 -0400
Subject: [R] defining a template for functions via do.call and substit ute.
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8475@usrymx25.merck.com>

Here's one not-so-straightforward way:

> f <- function(a, b) a + b
> flist <- as.list(f)
> names(flist)[1:2] <- c("x", "y")
> flist[[3]] <- do.call("substitute", list(body(f), list(a=as.name("x"),
b=as.name("y"))))
> g <- as.function(flist)
> g
function (x, y) 
x + y

HTH,
Andy

> From: john.gavin at ubs.com
> 
> Hi,
> 
> Given a function
> 
>   fun <- function(a, b) a + b
> 
> how do I generate the function 'function(x, y) x + y'?
> 
> Working from the help files and Bill Venables' R-news article 
> (June 2002),
> I have tried various permutations with substitute without success. 
> e.g.
>   do.call("substitute", list(fun, list(a = as.name("x"), b = 
> as.name("y"))))
> 
> Regards,
> 
> John.
> 
> John Gavin <john.gavin at ubs.com>,
> Quantitative Risk Models and Statistics,
> UBS Investment Bank, 6th floor, 
> 100 Liverpool St., London EC2M 2RH, UK.
> Phone +44 (0) 207 567 4289
> Fax   +44 (0) 207 568 5352
> 
> Visit our website at http://www.ubs.com
> 
> This message contains confidential information and is 
> intend...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From allan at stats.uct.ac.za  Wed Sep 29 14:24:31 2004
From: allan at stats.uct.ac.za (allan clark)
Date: Wed, 29 Sep 2004 14:24:31 +0200
Subject: [Fwd: [R] R: string connections]
Message-ID: <415AA97F.6ABA76D4@stats.uct.ac.za>

thanx my problem has been solved
-------------- next part --------------
An embedded message was scrubbed...
From: "Dimitris Rizopoulos" <dimitris.rizopoulos at med.kuleuven.ac.be>
Subject: Re: [R] R: string connections
Date: Wed, 29 Sep 2004 14:10:06 +0200
Size: 3179
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040929/574d5ff4/attachment.mht

From meinhardploner at gmx.net  Wed Sep 29 14:34:59 2004
From: meinhardploner at gmx.net (Meinhard Ploner)
Date: Wed, 29 Sep 2004 14:34:59 +0200
Subject: [R] problems with ESS & R ...
Message-ID: <FA40FC4D-1213-11D9-B067-0003930EA956@gmx.net>

Hi!
I have R 1.9.1, Mac OS X 10.3.5, GNU Emacs 21.2.1 and ESS 5.2.3.
I installed today the ESS by not changing ess-site.el, but creating 
.emacs in $home with the single line:

$ cat ~/.emacs
(load "/usr/local/lib/ess-5.2.3/lisp/ess-site")

If I start now emacs and then R (with M-x R) then I get:

 > options(STERM='iESS', editor='emacsclient')

but using fix() oder edit() doesn't work:

 > fix(pc)
emacsclient: can't find socket; have you started the server?
Error in edit(name, file, editor) : problem with running editor 
emacsclient

Maybe I forgot to do some simple steps??

Hope anybody could help me
Meinhard



From dimitris.rizopoulos at med.kuleuven.ac.be  Wed Sep 29 14:43:26 2004
From: dimitris.rizopoulos at med.kuleuven.ac.be (Dimitris Rizopoulos)
Date: Wed, 29 Sep 2004 14:43:26 +0200
Subject: [R] defining a template for functions via do.call and substit ute.
References: <3A822319EB35174CA3714066D590DCD504AF8475@usrymx25.merck.com>
Message-ID: <007b01c4a621$e9e1fdd0$b2133a86@www.domain>

Or a slight modification

fun <- function(a, b) a+b
####
g <- function(){}
body(g) <- do.call("substitute", list(body(fun), list(a=as.name("x"), 
b=as.name("y"))))
formals(g) <- alist(x=, y=)
g

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/396887
Fax: +32/16/337015
Web: http://www.med.kuleuven.ac.be/biostat/
     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Liaw, Andy" <andy_liaw at merck.com>
To: <john.gavin at ubs.com>; <r-help at stat.math.ethz.ch>
Sent: Wednesday, September 29, 2004 2:13 PM
Subject: RE: [R] defining a template for functions via do.call and 
substit ute.


> Here's one not-so-straightforward way:
>
>> f <- function(a, b) a + b
>> flist <- as.list(f)
>> names(flist)[1:2] <- c("x", "y")
>> flist[[3]] <- do.call("substitute", list(body(f), 
>> list(a=as.name("x"),
> b=as.name("y"))))
>> g <- as.function(flist)
>> g
> function (x, y)
> x + y
>
> HTH,
> Andy
>
>> From: john.gavin at ubs.com
>>
>> Hi,
>>
>> Given a function
>>
>>   fun <- function(a, b) a + b
>>
>> how do I generate the function 'function(x, y) x + y'?
>>
>> Working from the help files and Bill Venables' R-news article
>> (June 2002),
>> I have tried various permutations with substitute without success.
>> e.g.
>>   do.call("substitute", list(fun, list(a = as.name("x"), b =
>> as.name("y"))))
>>
>> Regards,
>>
>> John.
>>
>> John Gavin <john.gavin at ubs.com>,
>> Quantitative Risk Models and Statistics,
>> UBS Investment Bank, 6th floor,
>> 100 Liverpool St., London EC2M 2RH, UK.
>> Phone +44 (0) 207 567 4289
>> Fax   +44 (0) 207 568 5352
>>
>> Visit our website at http://www.ubs.com
>>
>> This message contains confidential information and is
>> intend...{{dropped}}
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From patrick.drechsler at gmx.net  Wed Sep 29 14:46:41 2004
From: patrick.drechsler at gmx.net (Patrick Drechsler)
Date: Wed, 29 Sep 2004 14:46:41 +0200
Subject: [R] displaying sample size in boxplots
Message-ID: <m3u0thfdji.fsf@pdrechsler.fqdn.th-h.de>

Hi,

I was wondering if there is a ready made function or parameter
for indicating the sample size in boxplots?

Here's what I came up with so far:

library(ISwR)
data(energy)
attach(energy)
boxplot(expend~stature)
sample.size <- tapply(expend, stature, length)
sample.size <- paste("N=", sample.size, sep="")
mtext(sample.size, at=1:length(unique(stature)), line=2, side=1)

TIA,

Patrick
-- 
"What happens if a big asteroid hits Earth ? Judging from
 realistic simulations involving a sledge hammer and a common
 laboratory frog, we can assume it will be pretty bad."
                                                -- Dave Barry



From emily.knight at ctsu.ox.ac.uk  Wed Sep 29 14:56:38 2004
From: emily.knight at ctsu.ox.ac.uk (Emily Knight)
Date: Wed, 29 Sep 2004 13:56:38 +0100
Subject: [R] R: string connections
In-Reply-To: <001c01c4a61d$41c309e0$b2133a86@www.domain>
Message-ID: <415ABF16.7233.11C52CD@localhost>

I had a similar problem, but with trying to join text and an expression.
What I wanted to print in my title was <text> <expression> <text>
Paste doesn't work because it just pastes the expression(...) into the string, and I can make the text into an 
expression, but then I don't know how to join 2 expressions together.
Any ideas?
Thanks.
Emily.

On 29 Sep 2004 at 14:10, Dimitris Rizopoulos wrote:

> Hi Allan,
> 
> look at ?paste, e.g.,
> 
> a <- 10
> plot(1:10, 1:10, main=paste("The value of a is", a))
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/396887
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.ac.be/biostat/
>      http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
> 
>



From ferri.leberl at gmx.at  Wed Sep 29 15:03:24 2004
From: ferri.leberl at gmx.at (Mag. Ferri Leberl)
Date: Wed, 29 Sep 2004 15:03:24 +0200
Subject: [R] Warning: number of items to replace is not a multiple of
	replacement length
Message-ID: <200409291503.24845.ferri.leberl@gmx.at>

What does this warning mean precisely?
Is there any reason to care about it?
Can I Avoid it by another way of programming?
Thank you in advance.



From rpeng at jhsph.edu  Wed Sep 29 15:06:01 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 29 Sep 2004 09:06:01 -0400
Subject: [R] R: string connections
In-Reply-To: <415ABF16.7233.11C52CD@localhost>
References: <415ABF16.7233.11C52CD@localhost>
Message-ID: <415AB339.6070905@jhsph.edu>

You mean something like?

plot(0,0,main=expression(paste("hello ", theta, " symbol")))

-roger

Emily Knight wrote:
> I had a similar problem, but with trying to join text and an expression.
> What I wanted to print in my title was <text> <expression> <text>
> Paste doesn't work because it just pastes the expression(...) into the string, and I can make the text into an 
> expression, but then I don't know how to join 2 expressions together.
> Any ideas?
> Thanks.
> Emily.
> 
> On 29 Sep 2004 at 14:10, Dimitris Rizopoulos wrote:
> 
> 
>>Hi Allan,
>>
>>look at ?paste, e.g.,
>>
>>a <- 10
>>plot(1:10, 1:10, main=paste("The value of a is", a))
>>
>>I hope it helps.
>>
>>Best,
>>Dimitris
>>
>>----
>>Dimitris Rizopoulos
>>Ph.D. Student
>>Biostatistical Centre
>>School of Public Health
>>Catholic University of Leuven
>>
>>Address: Kapucijnenvoer 35, Leuven, Belgium
>>Tel: +32/16/396887
>>Fax: +32/16/337015
>>Web: http://www.med.kuleuven.ac.be/biostat/
>>     http://www.student.kuleuven.ac.be/~m0390867/dimitris.htm
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From MSchwartz at MedAnalytics.com  Wed Sep 29 15:08:19 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 29 Sep 2004 08:08:19 -0500
Subject: [R] displaying sample size in boxplots
In-Reply-To: <m3u0thfdji.fsf@pdrechsler.fqdn.th-h.de>
References: <m3u0thfdji.fsf@pdrechsler.fqdn.th-h.de>
Message-ID: <1096463299.3533.42.camel@localhost.localdomain>

On Wed, 2004-09-29 at 07:46, Patrick Drechsler wrote:
> Hi,
> 
> I was wondering if there is a ready made function or parameter
> for indicating the sample size in boxplots?
> 
> Here's what I came up with so far:
> 
> library(ISwR)
> data(energy)
> attach(energy)
> boxplot(expend~stature)
> sample.size <- tapply(expend, stature, length)
> sample.size <- paste("N=", sample.size, sep="")
> mtext(sample.size, at=1:length(unique(stature)), line=2, side=1)


Note that boxplot() returns values, which includes a variety of summary
information on each group within your data. See the "Value" section of
?boxplot and ?boxplot.stats for more information.

Thus, you can do something like (using the first example in ?boxplot):

data(InsectSprays)

# Save the returned values from boxplot() in "S"
S <- boxplot(count ~ spray, data = InsectSprays, col = "lightgray")

# S$n is the sample size for each group
# S$names contains the group names
mtext(side = 1, text = S$n, at = 1:length(S$names), line = 2)

HTH,

Marc Schwartz



From Roger.Bivand at nhh.no  Wed Sep 29 15:09:17 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 29 Sep 2004 15:09:17 +0200 (CEST)
Subject: [R] displaying sample size in boxplots
In-Reply-To: <m3u0thfdji.fsf@pdrechsler.fqdn.th-h.de>
Message-ID: <Pine.LNX.4.44.0409291506220.12880-100000@reclus.nhh.no>

On Wed, 29 Sep 2004, Patrick Drechsler wrote:

> Hi,
> 
> I was wondering if there is a ready made function or parameter
> for indicating the sample size in boxplots?
> 
> Here's what I came up with so far:
> 
> library(ISwR)
> data(energy)
> attach(energy)
> boxplot(expend~stature)
> sample.size <- tapply(expend, stature, length)
> sample.size <- paste("N=", sample.size, sep="")
> mtext(sample.size, at=1:length(unique(stature)), line=2, side=1)
> 

Perhaps use the names= argument (width can help too):

> boxplot(expend~stature, width=sample.size/length(expend), 
+ names=paste(levels(stature), ", N=", sample.size, sep=""))


> TIA,
> 
> Patrick
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From roebuck at odin.mdacc.tmc.edu  Wed Sep 29 15:13:35 2004
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Wed, 29 Sep 2004 08:13:35 -0500 (CDT)
Subject: [R] Warning: number of items to replace is not a multiple
	ofreplacement length
In-Reply-To: <200409291503.24845.ferri.leberl@gmx.at>
References: <200409291503.24845.ferri.leberl@gmx.at>
Message-ID: <Pine.OSF.4.58.0409290808290.458619@odin.mdacc.tmc.edu>

On Wed, 29 Sep 2004, Mag. Ferri Leberl wrote:

> What does this warning mean precisely?

Usually means there isn't enough room to store your results.

> Is there any reason to care about it?

You probably should.

> Can I Avoid it by another way of programming?

Yes you can. Had you provided an example that caused the
problem, you could have received more help!

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From murdoch at stats.uwo.ca  Wed Sep 29 15:13:58 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 29 Sep 2004 09:13:58 -0400
Subject: [R] Warning: number of items to replace is not a multiple of
	replacement length
In-Reply-To: <200409291503.24845.ferri.leberl@gmx.at>
References: <200409291503.24845.ferri.leberl@gmx.at>
Message-ID: <f7dll0p2ie6mnmevjc94t8nsnoi7u1rcoo@4ax.com>

On Wed, 29 Sep 2004 15:03:24 +0200, "Mag. Ferri Leberl"
<ferri.leberl at gmx.at> wrote :

>What does this warning mean precisely?

You get this when you do something like this:

x <- 1:11
y <- 1:2

x[1:11] <- y

In the last line, R makes 11 assignments, reusing the values in y[1]
six times and y[2] five times.

>Is there any reason to care about it?

You rarely want recycling to work that way.  It's usually a sign that
you thought y contained a single value, and you wanted it repeated
throughout x.

>Can I Avoid it by another way of programming?

Usually correcting your code removes the message.  If you really
wanted this without the warning, you could do it in two lines:

x[1:10] <- y
x[11] <- y[1]

Duncan Murdoch

P.S. Your reply address ferri.leberl at gmx.at doesn't work; I get a
"mailbox disabled message".



From blindglobe at gmail.com  Wed Sep 29 15:17:58 2004
From: blindglobe at gmail.com (A.J. Rossini)
Date: Wed, 29 Sep 2004 09:17:58 -0400
Subject: [R] problems with ESS & R ...
In-Reply-To: <FA40FC4D-1213-11D9-B067-0003930EA956@gmx.net>
References: <FA40FC4D-1213-11D9-B067-0003930EA956@gmx.net>
Message-ID: <1abe3fa904092906171f771c07@mail.gmail.com>

PLEASE send ESS/R related problems to the ESS list.

We just recently answered that one over there.  Read the manuals and
HELP pages in the doc directory, you aren't using it right.  You want
to C-c C-d.




On Wed, 29 Sep 2004 14:34:59 +0200, Meinhard Ploner
<meinhardploner at gmx.net> wrote:
> Hi!
> I have R 1.9.1, Mac OS X 10.3.5, GNU Emacs 21.2.1 and ESS 5.2.3.
> I installed today the ESS by not changing ess-site.el, but creating
> .emacs in $home with the single line:
> 
> $ cat ~/.emacs
> (load "/usr/local/lib/ess-5.2.3/lisp/ess-site")
> 
> If I start now emacs and then R (with M-x R) then I get:
> 
> > options(STERM='iESS', editor='emacsclient')
> 
> but using fix() oder edit() doesn't work:
> 
> > fix(pc)
> emacsclient: can't find socket; have you started the server?
> Error in edit(name, file, editor) : problem with running editor
> emacsclient
> 
> Maybe I forgot to do some simple steps??
> 
> Hope anybody could help me
> Meinhard
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 



-- 
A.J. Rossini
blindglobe at gmail.com



From bob.ohara at helsinki.fi  Wed Sep 29 15:24:23 2004
From: bob.ohara at helsinki.fi (Anon.)
Date: Wed, 29 Sep 2004 16:24:23 +0300
Subject: [R] [Fwd: OpenBUGS]
Message-ID: <415AB787.9080109@helsinki.fi>

This is slightly off-topic, but there was a discussion about MCMC a 
couple of weeks ago.  OpenBUGS can operate from R, at least in Windows 
(there are some problems in Linux at the moment).

The interface with R is one are that there are plans to work on: it's a 
bit basic at the moment.

Bob

-- 
Bob O'Hara

Dept. of Mathematics and Statistics
P.O. Box 68 (Gustaf H??llstr??min katu 2b)
FIN-00014 University of Helsinki
Finland

Telephone: +358-9-191 51479
Mobile: +358 50 599 0540
Fax:  +358-9-191 51400
WWW:  http://www.RNI.Helsinki.FI/~boh/
Journal of Negative Results - EEB: http://www.jnr-eeb.org


-------- Original Message --------
Subject: OpenBUGS
Date: Wed, 29 Sep 2004 13:53:30 +0100
From: Andrew Thomas <ant at RNI.HELSINKI.FI>
Reply-To: Andrew Thomas <ant at RNI.HELSINKI.FI>
To: BUGS at JISCMAIL.AC.UK



We would like to announce that OpenBUGS an open source version of BUGS
is now available and has its own web page at
http://mathstat.helsinki.fi/openbugs/

Eventually the OpenBUGS code base will replace v1.4 of WinBUGS

Enjoy

     Andrew Thomas



From stecalza at tiscali.it  Wed Sep 29 17:39:01 2004
From: stecalza at tiscali.it (Stefano Calza)
Date: Wed, 29 Sep 2004 15:39:01 +0000
Subject: [R] displaying sample size in boxplots
In-Reply-To: <1096463299.3533.42.camel@localhost.localdomain>
References: <m3u0thfdji.fsf@pdrechsler.fqdn.th-h.de>
	<1096463299.3533.42.camel@localhost.localdomain>
Message-ID: <20040929153901.GF4514@med.unibs.it>

On Wed, Sep 29, 2004 at 08:08:19AM -0500, Marc Schwartz wrote:
> On Wed, 2004-09-29 at 07:46, Patrick Drechsler wrote:
> > Hi,
> > 
> > I was wondering if there is a ready made function or parameter
> > for indicating the sample size in boxplots?
> > 
> > Here's what I came up with so far:
> > 
> > library(ISwR)
> > data(energy)
> > attach(energy)
> > boxplot(expend~stature)
> > sample.size <- tapply(expend, stature, length)
> > sample.size <- paste("N=", sample.size, sep="")
> > mtext(sample.size, at=1:length(unique(stature)), line=2, side=1)
> 

In vol 3/2 October 2003 of R news there's an extended version of boxplot, with median and mean ticks, etc. and also sample dimension.

HIH,
Stefano

> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Ted.Harding at nessie.mcc.ac.uk  Wed Sep 29 14:52:14 2004
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 29 Sep 2004 13:52:14 +0100 (BST)
Subject: [R] Re: read dbf files into R
In-Reply-To: <20040929114932.23456.qmail@web1702.mail.yahoo.co.jp>
Message-ID: <XFMail.040929135214.Ted.Harding@nessie.mcc.ac.uk>

On 29-Sep-04 Hisaji ONO wrote:
>> > Is there a linux-based/free command line tool for
>> converting
>> > dbf files into txt?
>> 
> 
>  How about DBF2CSV 1.0 in
> http://www.dirfile.com/dbf2csv.htm.
> 
>  This is a perl script.

This seems to work well in extracting the field-names and
data from a DBF file.

However, it seems also that it wraps every field inside
quotation marks, as in

"....","....","....",...

which will not usually be wanted (this use of quotation
marks is strictly speaking only needed in CSV for fields
where a comma is part of the field data).

However, in unix/linux at least, the resulting CSV file
can be mended by piping it through 'tr', as in

  cat oldCSVfil.csv | tr -d '"' > newCSVfile.csv

(assuming, of course, that you don't have field data
with commas inside ... )

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861  [NB: New number!]
Date: 29-Sep-04                                       Time: 13:52:14
------------------------------ XFMail ------------------------------



From patrick.drechsler at gmx.net  Wed Sep 29 15:39:10 2004
From: patrick.drechsler at gmx.net (Patrick Drechsler)
Date: Wed, 29 Sep 2004 15:39:10 +0200
Subject: [R] displaying sample size in boxplots
References: <m3u0thfdji.fsf@pdrechsler.fqdn.th-h.de>
	<1096463299.3533.42.camel@localhost.localdomain>
Message-ID: <m3oejpfb41.fsf@pdrechsler.fqdn.th-h.de>

Hi Marc,

Marc Schwartz wrote on 29 Sep 2004 14:08:19 MET:

> On Wed, 2004-09-29 at 07:46, Patrick Drechsler wrote:
>> I was wondering if there is a ready made function or parameter
>> for indicating the sample size in boxplots?
[...]

> Note that boxplot() returns values, which includes a variety of
> summary information on each group within your data. See the
> "Value" section of ?boxplot and ?boxplot.stats for more
> information.
>
> Thus, you can do something like (using the first example in
> ?boxplot):
>
> data(InsectSprays)
>
> # Save the returned values from boxplot() in "S"
> S <- boxplot(count ~ spray, data = InsectSprays, col = "lightgray")
>
> # S$n is the sample size for each group
> # S$names contains the group names
> mtext(side = 1, text = S$n, at = 1:length(S$names), line = 2)

Thank you very much--just what I was looking for!

Patrick
-- 
"Ludwig Boltzmann, who spent much of his life studying statistical
mechanics, died in 1906, by his own hand. Paul Ehrenfest, carrying on
the work, died similarly in 1933. Now it is our turn to study
statistical mechanics. Perhaps it will be wise to approach the subject
cautiously."  from "States of Matter" by David Goodstein



From maechler at stat.math.ethz.ch  Wed Sep 29 09:16:51 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 29 Sep 2004 09:16:51 +0200
Subject: [R] R-devel not R-help (was "Bug? using { as a function ...")
In-Reply-To: <loom.20040928T215129-758@post.gmane.org>
References: <loom.20040928T215129-758@post.gmane.org>
Message-ID: <16730.24931.773197.999690@gargle.gargle.HOWL>

>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck at myway.com>
>>>>>     on Tue, 28 Sep 2004 20:02:01 +0000 (UTC) writes:

    Gabor> This seems like a bug to me.  Can someone verify
    Gabor> this?

By the way, Gabor (and everyone else) :

This has been a typical topic *not* fitting well into R-help 
(because it's quite technical and not about solving a real
 problem with R, etc,etc) -- pretty much those things belonging to
R-devel as explained in the posting guide.

Martin Maechler

   < ........ >



From maechler at stat.math.ethz.ch  Tue Sep 28 09:24:57 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Sep 2004 09:24:57 +0200
Subject: [R] Enright/Chi-square periodogram / periodicity
In-Reply-To: <2D42B4DF9845F74E9318DF707D5956D901852691@wdexch02.lexgen.com>
References: <2D42B4DF9845F74E9318DF707D5956D901852691@wdexch02.lexgen.com>
Message-ID: <16729.4553.16356.76320@gargle.gargle.HOWL>

>>>>> "MalladiS" == Malladi, Sukhaswami <smalladi at lexgen.com>
>>>>>     on Mon, 27 Sep 2004 09:17:38 -0500 writes:

    MalladiS> I am trying to compute the periodicity of a time
    MalladiS> series.  I would like to know which function in R
    MalladiS> does it.

Have you considered using  spectrum()  with its many variants?

I guess that its methodology is much better than the one in

    MalladiS> Also, how do I plot a Enright / Chi-square
    MalladiS> periodogram using R ?  ( Enright, J.T., 1965,
    MalladiS> Journal of Theoret. Biol. 8,426-468)

(a bit old)

    MalladiS> Greatly appreciate your help.

You're welcome
Martin Maechler, ETH Zurich



From maechler at stat.math.ethz.ch  Tue Sep 28 10:54:57 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Sep 2004 10:54:57 +0200
Subject: [R] emacs, Mac OS X, R
In-Reply-To: <76C6E4CF-1067-11D9-90F2-0003938C0ABE@gmx.net>
References: <C4958F90-0E32-11D9-9448-0003938C0ABE@gmx.net>
	<E59E4292-0E41-11D9-B31A-0003930C7D76@louisville.edu>
	<76C6E4CF-1067-11D9-90F2-0003938C0ABE@gmx.net>
Message-ID: <16729.9953.896438.853912@gargle.gargle.HOWL>

Redirected to ESS-help,
this has become an ESS/Emacs topic much more than an R one.
{Please drop R-help entirely if you reply to this! MM}

>>>>> "Meinhard" == Meinhard Ploner <meinhardploner at gmx.net>
>>>>>     on Mon, 27 Sep 2004 11:27:34 +0200 writes:

    Meinhard> On Sep 24, 2004, at 5:53 PM, Bill Rising wrote:

    >> On Sep 24, 2004, at 10:05, Meinhard Ploner wrote:
    >> 
    >>> Hi!
    >>> 
    >>> Since August I am using emacs on my Macintosh to edit
    >>> the R objects.  I have installed R 1.9.1, Mac OS X
    >>> 10.3.5 and GNU Emacs 21.2.1.  However there are some
    >>> issues I haven't resolved:
    >>> 
    >>> a) switch the caps lock key to the meta key (and when
    >>> this is not possible, switch the alt/option key to the
    >>> meta).
    >>  You can use only the command or option key for the meta
    >> key. To see the method, try looking at
    >> 
    >> http://members.shaw.ca/akochoi-emacs/stories/faq.html
    >> 
    >>> The switch should work only within emacs!
    >>> 
    >>> b) having different colors for the code, i.e. comments,
    >>> commands, strings, ...
    >>  I'd advise using ESS, whose home page is
    >> 
    >> http://stat.ethz.ch/ESS/

    Meinhard> after installing ESS 5.2.3 I called emacs and
    Meinhard> within emacs M-x R and I get the following:

    >> options(STERM='iESS', editor='emacsclient')
    >> 
    >> fix(fun1)

    Meinhard> emacsclient: can't find socket; have you started
    Meinhard> the server?

If you want to use the emacsclient, you need to start its server
(as the above question suggests!):
    M-x server-start

If you need this often, add it to your auto-initialization.
We have something like

	(if (not xemacs-p)
	    (server-start nil))

wrapped inside an 
  (add-hook
    'inferior-ess-mode-hook
    '(lambda()
    ..... 
  ))
clause, but you can do it unconditionally.

    Meinhard>   Error in edit(name, file, editor) :
    Meinhard> problem with running editor emacsclient
    >>

    Meinhard> What did I wrong?

using fix() at all :-)

Reall don't work with fix() once ``you've seen the light'' of ESS.
We strongly advocate using source files everywhere - something
which is particularly easy with ESS.
A compromise {between fix() and real source files} would be to
use  C-c C-d  {dump R object to file and start editing that file}

Martin Maechler, ETH Zurich



From B.Rowlingson at lancaster.ac.uk  Wed Sep 29 15:41:41 2004
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 29 Sep 2004 14:41:41 +0100
Subject: [R] Warning: number of items to replace is not a multiple of
	replacement length
In-Reply-To: <200409291503.24845.ferri.leberl@gmx.at>
References: <200409291503.24845.ferri.leberl@gmx.at>
Message-ID: <415ABB95.2090206@lancaster.ac.uk>

Mag. Ferri Leberl wrote:
> What does this warning mean precisely?

When R replaces parts of a vector with another vector, it repeats the 
replacing value until it is as long as the number of values it needs to 
replace. For example:

  > x = 1:10
  > x[1:3]=1

   - will do, effectively, x[1:3] = rep(1,3)

  Now, if you replace with a vector that isn't an integer multiple of 
the things being replaced, you get that error:

  > x[1:3]=c(1,2)
  Warning message:
  number of items to replace is not a multiple of replacement length

  Note that if it is an integer multiple, you don't get the error:

  > x[1:6]=c(1,2)

  but it repeats the (1,2) 3 times to fill the six places:

  > x
   [1]  1  2  1  2  1  2  7  8  9 10


> Is there any reason to care about it?

  Yes, it usually means you've specified something wrong. What have you 
done?

Baz



From macq at llnl.gov  Wed Sep 29 15:49:16 2004
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 29 Sep 2004 06:49:16 -0700
Subject: [R] displaying sample size in boxplots
In-Reply-To: <m3u0thfdji.fsf@pdrechsler.fqdn.th-h.de>
References: <m3u0thfdji.fsf@pdrechsler.fqdn.th-h.de>
Message-ID: <p06002001bd806d8150f4@[128.115.153.6]>

Here is how I do it:

function (x, ...)
{
     bx <- boxplot(x, plot = F, ...)
     bx$names <- paste(bx$names, "\nn = ", bx$n, sep = "")
     tmp <- bxp(bx, tcl = 0, xaxt = "n")
     axis(1, at = tmp, labels = bx$names, tick = FALSE)
     invisible(c(bx, list(x = tmp)))
}

-Don

At 2:46 PM +0200 9/29/04, Patrick Drechsler wrote:
>Hi,
>
>I was wondering if there is a ready made function or parameter
>for indicating the sample size in boxplots?
>
>Here's what I came up with so far:
>
>library(ISwR)
>data(energy)
>attach(energy)
>boxplot(expend~stature)
>sample.size <- tapply(expend, stature, length)
>sample.size <- paste("N=", sample.size, sep="")
>mtext(sample.size, at=1:length(unique(stature)), line=2, side=1)
>
>TIA,
>
>Patrick
>--
>"What happens if a big asteroid hits Earth ? Judging from
>  realistic simulations involving a sledge hammer and a common
>  laboratory frog, we can assume it will be pretty bad."
>                                                 -- Dave Barry
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From patrick.drechsler at gmx.net  Wed Sep 29 15:52:03 2004
From: patrick.drechsler at gmx.net (Patrick Drechsler)
Date: Wed, 29 Sep 2004 15:52:03 +0200
Subject: [R] displaying sample size in boxplots
References: <m3u0thfdji.fsf@pdrechsler.fqdn.th-h.de>
	<Pine.LNX.4.44.0409291506220.12880-100000@reclus.nhh.no>
Message-ID: <m3is9xfaik.fsf@pdrechsler.fqdn.th-h.de>

Hi Roger,

Roger Bivand wrote on 29 Sep 2004 14:09:17 MET:

> On Wed, 29 Sep 2004, Patrick Drechsler wrote:
>
>> I was wondering if there is a ready made function or parameter
>> for indicating the sample size in boxplots?
>> 
>> Here's what I came up with so far:
>> 
>> library(ISwR)
>> data(energy)
>> attach(energy)
>> boxplot(expend~stature)
>> sample.size <- tapply(expend, stature, length)
>> sample.size <- paste("N=", sample.size, sep="")
>> mtext(sample.size, at=1:length(unique(stature)), line=2, side=1)
>> 
>
> Perhaps use the names= argument (width can help too):
>
>> boxplot(expend~stature, width=sample.size/length(expend), 
> + names=paste(levels(stature), ", N=", sample.size, sep=""))

Also many thanks to you for the quick help!

Your solution (as well as Marc's) work like a charm!

Cheers

Patrick
-- 
Snoopy (on being house-trained with a rolled-up newspaper): 
It does tend however to give one a rather distorted view of the press!



From ym at climpact.com  Wed Sep 29 16:00:47 2004
From: ym at climpact.com (Yves Magliulo)
Date: 29 Sep 2004 16:00:47 +0200
Subject: [R] Warning: number of items to replace is not a multiple of
	replacement length
In-Reply-To: <200409291503.24845.ferri.leberl@gmx.at>
References: <200409291503.24845.ferri.leberl@gmx.at>
Message-ID: <1096466446.17086.189.camel@new-york.climpact.net>

hi, 

that means you're doing operation whith matrix or dataframe with  row or
column with different length. this can be a real reason to care about
and sometimes it could be an error and not only a warning.
you'd better adjust the length of your vector (array) to be the same in
order to avoid this warning and be sure you're doing excatly what you
want.

here's a sample of what i meant.

> toto=matrix(0,5,5)
> toto
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    0    0    0
[2,]    0    0    0    0    0
[3,]    0    0    0    0    0
[4,]    0    0    0    0    0
[5,]    0    0    0    0    0
> tata=c(1,2,3)
> toto[,1]=tata
Error in "[<-"(*tmp*, , 1, value = tata) :
        number of items to replace is not a multiple of replacement
length

here's the correct syntax

> toto[1:length(tata)]=tata



 
Le mer 29/09/2004 ?? 15:03, Mag. Ferri Leberl a ??crit :
> What does this warning mean precisely?
> Is there any reason to care about it?
> Can I Avoid it by another way of programming?
> Thank you in advance.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
-- 
------
Yves Magliulo <ym at climpact.com>
R&D Engineer, CLIMPACT

Tel.   : +33 (0) 1 44 27 34 31
Fax.   : +33 (0) 1 44 27 49 96 
Universite Pierre et Marie Curie
Boite 101 - Tour 45 - 5eme etage - Couloir 45/46
4 place Jussieu, 75252 Paris CEDEX 05, France



From christoph.lehmann at gmx.ch  Wed Sep 29 16:04:37 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Wed, 29 Sep 2004 16:04:37 +0200
Subject: [R] glm.fit and predict.glm: error ' no terms component'
Message-ID: <415AC0F5.9080009@gmx.ch>

Hi

when I fit a glm by

	glm.fit(x,y,family = binomial())
	
and then try to use the object for prediction of newdata by:

	predict.glm(object, newdata)

I get the error:

Error in terms.default(object) : no terms component

I know I can use glm() and a formula, but for my case I prefer 
glm.fit(x,y)...


thanks for a hint

christoph

$platform
[1] "i686-pc-linux-gnu"

$arch
[1] "i686"

$os
[1] "linux-gnu"

$system
[1] "i686, linux-gnu"

$status
[1] ""

$major
[1] "1"

$minor
[1] "9.1"

$year
[1] "2004"

$month
[1] "06"

$day
[1] "21"

$language
[1] "R"



From lars.feistner at iwr.uni-heidelberg.de  Wed Sep 29 16:09:38 2004
From: lars.feistner at iwr.uni-heidelberg.de (Lars Feistner)
Date: Wed, 29 Sep 2004 14:09:38 +0000
Subject: [R] Howto store objects in a matrix or in an array
Message-ID: <415AC222.3050903@iwr.uni-heidelberg.de>

Hello,

i am working with the R.oo package. I want to store objects (instances 
of classes) in a n-dimensional array.
I tried this:

t <- array(list(),dim=c(8,8))
t[1,1] <- someObject
print(t[1,1])  results in:
[[1]]
[1] NA

the same with any S4 classes
setClass("track,representation(x="numeric",y="numeric"))
t1 <- new("track",x=1:5,y=5:10)
t[1,1] <- t1
Error in "[<-"(`*tmp*`, 1, 1, value = t1) :
        nothing to replace with

Is there any chance not to use a list in list construction?

Sincerly
Lars Feistner

-- 
----------------------------------------------------------------------
Lars Feistner                                   feistner at justis.de

Untere Neckarstr 32                             Tel:  +49 6221 8935279
D-69117 Heidelberg                              Mobil:+49 173 3205195



From jeff.hamann at forestinformatics.com  Wed Sep 29 16:14:36 2004
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Wed, 29 Sep 2004 07:14:36 -0700
Subject: [R] dbf I/O package suggestions?
Message-ID: <001301c4a62e$a9799340$0b00a8c0@rodan>

I saw a note in the R-help mailing list about dbf file I/O in R. The 
suggestion was made to utilize (or at least take a look at) RODBC. While 
RODBC is fine for most Windows abusers, I find ODBC under Linux cumbersome. 
I have lots of need for a direct and simple dbf interface and have been 
thinking about writing a package for R using the shapelib dbf (or 
equivalent) functions. I wanted to get some feedback from R users for the 
demand. Any suggestions?

Jeff.

---
Jeff D. Hamann
Forest Informatics, Inc.
PO Box 1421
Corvallis, Oregon USA 97339-1421
541-754-1428
jeff.hamann at forestinformatics.com
www.forestinformatics.com



From friendly at yorku.ca  Wed Sep 29 16:32:38 2004
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 29 Sep 2004 10:32:38 -0400
Subject: [R] lattice .ps graphic is rotated in LaTeX slides
Message-ID: <415AC786.4040706@yorku.ca>

I've generated a version of the classic dotplot of the barley data with

library(lattice)
data(barley)

trellis.device("postscript", color=TRUE, file="barley2x3.ps")
old.settings <- trellis.par.get()
trellis.par.set("background", list(col = "white"))
lset(list(superpose.symbol=list(pch=c(19, 1, 25, 2, 15, 22, 23),
        cex=rep(1,7),col=c("blue", "red", "darkgreen", "brown",
        "orange", "turquoise", "orchid") )))
lset(list(fontsize = list(default = 14)))

n <- length(levels(barley$year))
dotplot(variety ~ yield | site, data = barley, groups = year,
  layout = c(2, 3), aspect = .5,
  xlab = "Barley Yield (bushels/acre)",
  key = list(points = Rows(trellis.par.get("superpose.symbol"), 1:n),
    text = list(levels(barley$year)), columns = n))
dev.off()
lset(theme=old.settings)

It looks fine with gv (though I'd like to make the bounding box 
tighter), but when I embed it in a LaTeX slide
(landscape, using seminar package),

\begin{slide}
  \includegraphics[,height=.6\textheight]{fig/barley2x3.ps}
\end{slide}

the image is rotated 90 deg CCW.  I tried to adjust for this with

  \includegraphics[angle=-90,height=.6\textheight]{fig/barley2x3.ps}

but  that gives
! Package graphics Error: Division by 0.
 
What am I doing wrong, or how could I do it differently so it would work?

thanks

-- 
Michael Friendly     Email: friendly at yorku.ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From larsenmtl at comcast.net  Wed Sep 29 16:39:15 2004
From: larsenmtl at comcast.net (larsenmtl@comcast.net)
Date: Wed, 29 Sep 2004 14:39:15 +0000
Subject: [R] RSXML - Parsing XML Documents on Internet
Message-ID: <092920041439.12460.415AC912000ED875000030AC2200734748049B03020A9C9D0E04@comcast.net>

R Users -

I asked about this a few months ago and never did quite figure it out, so with more information, allow me to try again.

If I use the following code:

library(xml)
xmlTreeParse("http://home.comcast.net/~larsenmtl/xmlTestDoc.xml", isURL = TRUE)
 
I receive this error:
Error in xmlTreeParse("http://home.comcast.net/~larsenmtl/xmlTestDoc.xml"",  : 
        error in creating parser for http://home.comcast.net/~larsenmtl/xmlTestDoc.xml"

Now I know that xmlTreeParse uses the libxml facilities for downloading and parsing off the web.   Along with one of our network people, I did some packet sniffing and it looks like libxml doesn't go through our proxy server (it tries to directly connect to the above URL), which is the reason for the error.  Is there anyway to force it through the proxy?  Am I missing some setting or option?  If I download the xml file and parse it locally it works without error.

Please Note that the URL is valid and I can open it in my browser.  Also note that I must start R with the --internet2 option so it'll use our proxy server.  

Details:
Windows 2000
R1.9.1
RSXML 0.97-0
libxml2-2.4.13 distribution for Windows

I also tried this on a Mandrake 9.2 box with R1.9.1, XML0.95-6, and libxml2 2.6.13.  Results were the same but with the additional error message:
I/O warning: falied to load external entity "http://...."

Thanks,

Mark Larsen



From ozric at web.de  Wed Sep 29 16:39:06 2004
From: ozric at web.de (Christian Schulz)
Date: Wed, 29 Sep 2004 16:39:06 +0200
Subject: [R] maximizing log-likelihood function
Message-ID: <200409291639.06442.ozric@web.de>

Hello,

I know that i have to use optim, but i'm confused how its
possible  maximize  the sum over all l[i] and get the optimized
r  and alpha?

LL <- function(trans,time){
   for(i in 1:length(trans){
     l[i] <- log(lgamma(r+trans[i] - 
gamma(r+1)*(alpha/alpha+t[i]))**r)*(t[i]/alpha+t[i])**trans[i]
}
return(sum(l))
   }

i'm confused how i have to set r and alpha 
and i found no related help in archives?

...in Excel it works with solver but only for ~65.000 rows :-)

#This notation is 1 for trans  and 1  for time insteda the Startvalues for r 
and alpha?

optim(c(1,1),-LL)

many thanks  for an easy example or hint 
regards,christian



From tlumley at u.washington.edu  Wed Sep 29 16:55:40 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 29 Sep 2004 07:55:40 -0700 (PDT)
Subject: [R] glm.fit and predict.glm: error ' no terms component'
In-Reply-To: <415AC0F5.9080009@gmx.ch>
References: <415AC0F5.9080009@gmx.ch>
Message-ID: <Pine.A41.4.61.0409290746340.169788@homer11.u.washington.edu>

On Wed, 29 Sep 2004, Christoph Lehmann wrote:

> Hi
>
> when I fit a glm by
>
> 	glm.fit(x,y,family = binomial())
> 	and then try to use the object for prediction of newdata by:
>
> 	predict.glm(object, newdata)
>
> I get the error:
>
> Error in terms.default(object) : no terms component
>
> I know I can use glm() and a formula, but for my case I prefer 
> glm.fit(x,y)...

Well, you can't use predict.glm that way.  As the function name suggests, 
it is a predict method for objects of class "glm", which in your case you 
do not have.

There are two reasons why it won't work.  For type="terms" the formula is 
needed to identify terms, and for any type of prediction the formula is 
needed to convert the data frame newdata into a model matrix.

You would need to write a function where the new data was a model matrix. 
If you only need point predictions then

predict_glm_fit<-function(glmfit, newmatrix, addintercept=TRUE){
    if (addintercept)
 	newmatrix<-cbind(1,newmatrix)
    eta<-glmfit$coef %*% newmatrix
    family$linkinv(eta)
}

would work.

 	-thomas



From nassar at noos.fr  Wed Sep 29 16:59:48 2004
From: nassar at noos.fr (Naji)
Date: Wed, 29 Sep 2004 16:59:48 +0200
Subject: [R] Approximate a f(x,y)
Message-ID: <BD809A84.1AC%nassar@noos.fr>

Hi all,


Running simulations, I'm generating market response to 2 factors X&Y..
There is no closed form for the market response.. The results are store in a
matrix Z(X <- seq(.02,.98,.02), Y <- seq(.01,.19,.01))..
For optmization purpose I need to approximate the values for any factor X in
0,02-0,98 and Y in 0,01-0,19

How can I do it ?

For one factor : Xn-1 < x <= Xn
f(x)=(f(Xn-1)*(x-Xn-1)+f(Xn)*(Xn-x))/(Xn-Xn-1)
I don't know how to generalize this for two factors..


Thanks in Advance
Naji



From andy_liaw at merck.com  Wed Sep 29 17:09:23 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 29 Sep 2004 11:09:23 -0400
Subject: [R] Approximate a f(x,y)
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8480@usrymx25.merck.com>

The `akima' package on CRAN probably would help.

HTH,
Andy

> From: Naji
> 
> Hi all,
> 
> 
> Running simulations, I'm generating market response to 2 factors X&Y..
> There is no closed form for the market response.. The results 
> are store in a
> matrix Z(X <- seq(.02,.98,.02), Y <- seq(.01,.19,.01))..
> For optmization purpose I need to approximate the values for 
> any factor X in
> 0,02-0,98 and Y in 0,01-0,19
> 
> How can I do it ?
> 
> For one factor : Xn-1 < x <= Xn
> f(x)=(f(Xn-1)*(x-Xn-1)+f(Xn)*(Xn-x))/(Xn-Xn-1)
> I don't know how to generalize this for two factors..
> 
> 
> Thanks in Advance
> Naji
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ggrothendieck at myway.com  Wed Sep 29 17:33:17 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 29 Sep 2004 15:33:17 +0000 (UTC)
Subject: [R] R-devel not R-help (was "Bug? using =?utf-8?b?ew==?= as a
	function ...")
References: <loom.20040928T215129-758@post.gmane.org>
	<16730.24931.773197.999690@gargle.gargle.HOWL>
Message-ID: <loom.20040929T170805-316@post.gmane.org>

Martin Maechler <maechler <at> stat.math.ethz.ch> writes:

> 
> >>>>> "Gabor" == Gabor Grothendieck <ggrothendieck <at> myway.com>
> >>>>>     on Tue, 28 Sep 2004 20:02:01 +0000 (UTC) writes:
> 
>     Gabor> This seems like a bug to me.  Can someone verify
>     Gabor> this?
> 
> By the way, Gabor (and everyone else) :
> 
> This has been a typical topic *not* fitting well into R-help 
> (because it's quite technical and not about solving a real
>  problem with R, 

The real problem is how to create a list with given names
and constant content.  I find I need to do that and when I noticed
a recent problem posted on r-help that required it I decided it was 
time that I figured out a better way to do it.  I simplified the 
problem for purpose of bringing out the error more clearly but it
otherwise does stem from a real problem.

To illustrate, we will use this test data:

	nams <- letters[1:3]
	v <- 1:2

The following will do it:

	L <- rep(list(v), length(nams))
	names(L) <- nams

but I wanted a more compact expression.  This next line
reduces it from two statements to a single expression but I
still find it annoying that one must refer to nams twice
plus it seems there should be a shorter solution since it
seems like such a simple requirement:

	array(rep(list(v), length(nams)), dimnames = list(nams))

It occurred to me that this would be briefer:

	sapply(nams, function(x,y)v, simplify = F)

however, the anonymous function gives me a headache but 
further simplification does give

	sapply(nams, function(x,y)y, v, simplify = F)

and finally (except that this does not work) the following
is pleasingly compact:

	sapply(nams, "{", v, simplify = F) ###

which might seem a bit opaque but would be OK once you got used
to it as an idiom.  I ultimately settled on this:

	mapply("{", nams, list(v), SIMPLIFY = F)

which admittedly is only slightly longer than ### but its nevertheless
frustrating that ### gives an error.  

As an aside the next problem is how to create a general list with
given names such as 

	as.list(array(1:3, dimnames = list(nams)))
or
	array(as.list(1:3), dimnames = list(nams))

which works but its a bit annoying that one must first
create an array and then turn it into a list or visa
versa.  In this case the mapply solution generalizes:

	mapply("{", nams, 1:3, SIMPLIFY = F)

though, in practice, I would probably use the array
solution.  At any rate, I still would like to keep the
sapply solution, were it to work, around for the simpler
case and I think its important to get one's idioms straight.

More importantly, I think its nice to have
simple functions such as the identity function,
last argument function, etc. in one's arsenal as they
can often be combined with others in powerful ways so I
think it would be desirable to fix the { problem.



From reid_huntsinger at merck.com  Wed Sep 29 17:42:11 2004
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Wed, 29 Sep 2004 11:42:11 -0400
Subject: [R] Approximate a f(x,y)
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A9101@uswpmx00.merck.com>

Akima is "free for non-commercial use" but this may be a commercial
application. 

Your solution for 1 variable is called piecewise linear interpolation; there
are many ways to extend this to 2 variables. Piecewise linear on triangles,
for example, or piecewise bilinear. For the latter, given x=(x1,x2) and the
values at integers in f[,] compute the interpolated value as

i <- floor(x)
w <- x - i
m <- f[i[1]:(i[1]+1),i[2]:(i[2]+1)]
f1 <- c(1-w[1],w[1])%*%m
c(1-w[2],w[2])%*%f1

ie there are 4 nearest grid points and the weights are just products of the
1-variable weights.

Reid Huntsinger


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Liaw, Andy
Sent: Wednesday, September 29, 2004 11:09 AM
To: 'Naji'; r-help at stat.math.ethz.ch
Subject: RE: [R] Approximate a f(x,y)


The `akima' package on CRAN probably would help.

HTH,
Andy

> From: Naji
> 
> Hi all,
> 
> 
> Running simulations, I'm generating market response to 2 factors X&Y..
> There is no closed form for the market response.. The results 
> are store in a
> matrix Z(X <- seq(.02,.98,.02), Y <- seq(.01,.19,.01))..
> For optmization purpose I need to approximate the values for 
> any factor X in
> 0,02-0,98 and Y in 0,01-0,19
> 
> How can I do it ?
> 
> For one factor : Xn-1 < x <= Xn
> f(x)=(f(Xn-1)*(x-Xn-1)+f(Xn)*(Xn-x))/(Xn-Xn-1)
> I don't know how to generalize this for two factors..
> 
> 
> Thanks in Advance
> Naji
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

----------------------------------------------------------------------------
--
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From maechler at stat.math.ethz.ch  Wed Sep 29 18:11:13 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 29 Sep 2004 18:11:13 +0200
Subject: [R] displaying sample size in boxplots
In-Reply-To: <Pine.LNX.4.44.0409291506220.12880-100000@reclus.nhh.no>
References: <m3u0thfdji.fsf@pdrechsler.fqdn.th-h.de>
	<Pine.LNX.4.44.0409291506220.12880-100000@reclus.nhh.no>
Message-ID: <16730.56993.882269.874478@gargle.gargle.HOWL>

>>>>> "Roger" == Roger Bivand <Roger.Bivand at nhh.no>
>>>>>     on Wed, 29 Sep 2004 15:09:17 +0200 (CEST) writes:

    Roger> On Wed, 29 Sep 2004, Patrick Drechsler wrote:
    >> Hi,
    >> 
    >> I was wondering if there is a ready made function or parameter
    >> for indicating the sample size in boxplots?
    >> 
    >> Here's what I came up with so far:
    >> 
    >> library(ISwR)
    >> data(energy)
    >> attach(energy)
    >> boxplot(expend~stature)
    >> sample.size <- tapply(expend, stature, length)
    >> sample.size <- paste("N=", sample.size, sep="")
    >> mtext(sample.size, at=1:length(unique(stature)), line=2, side=1)
    >> 

    Roger> Perhaps use the names= argument (width can help too):
                                            ^^^^^^^^^^^^^^^^^^
Indeed!
And that's why -- "in the good ol' times" when the box plot was invented
and enhanced, the inventors thought about it.
For that reason there's the  'varwidth = TRUE/FALSE' argument
in boxplot() 

Note from help(boxplot) however that the inventors thought
it wiser to make the width proportional to the SQRT of the
sample size rather than the sample.size itself, i.e.,
'varwidth = TRUE' and your proposal are not equivalent.

    >> boxplot(expend~stature, width=sample.size/length(expend), 
    >>   + names=paste(levels(stature), ", N=", sample.size, sep=""))

Here are the current proposals [for cut & paste]:

library(ISwR)
data(energy)
attach(energy)

## 1
boxplot(expend~stature)
sample.size <- tapply(expend, stature, length)
ss.ch <- paste("N=", sample.size, sep="")
mtext(ss.ch, at=1:length(unique(stature)), line=2, side=1)

## 2 (Roger)
boxplot(expend~stature, width=sample.size/length(expend),
        names=paste(levels(stature), ", N=", sample.size, sep=""))

## 3 (Roger + Martin):
boxplot(expend ~ stature, varwidth= TRUE,
        names=paste(levels(stature), ", N=", sample.size, sep=""))



From M.Mamin at intershop.de  Wed Sep 29 18:09:19 2004
From: M.Mamin at intershop.de (Marc Mamin)
Date: Wed, 29 Sep 2004 18:09:19 +0200
Subject: [R] multiple match question
Message-ID: <A03188C6623C0D46A703CB5AA59907F201C11BF4@JENMAIL01.ad.intershop.net>


Hello,

 I'm looking for a fast way to retrieve the position of elements  from a vector which match element in another vector.

Example

va<-c('a','e')
vb<-c('a','b','c','d','e','f','e')

f(va,vb) should return c(1,5,7)

I have 2 different cases: 

I) my vector vb contains only distinct values
II) my vector vb may contains the same values more than once.

for I) I use following which is fast enough:

	as.vector(na.omit(unlist(lapply(va,match,vb))))

Thanks for any help,

Marc



From andy_liaw at merck.com  Wed Sep 29 18:26:18 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 29 Sep 2004 12:26:18 -0400
Subject: [R] multiple match question
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8483@usrymx25.merck.com>

Something like:

> which(vb %in% va)
[1] 1 5 7

should handle both cases, I believe.

Andy

> From: Marc Mamin
> 
> Hello,
> 
>  I'm looking for a fast way to retrieve the position of 
> elements  from a vector which match element in another vector.
> 
> Example
> 
> va<-c('a','e')
> vb<-c('a','b','c','d','e','f','e')
> 
> f(va,vb) should return c(1,5,7)
> 
> I have 2 different cases: 
> 
> I) my vector vb contains only distinct values
> II) my vector vb may contains the same values more than once.
> 
> for I) I use following which is fast enough:
> 
> 	as.vector(na.omit(unlist(lapply(va,match,vb))))
> 
> Thanks for any help,
> 
> Marc
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ligges at statistik.uni-dortmund.de  Wed Sep 29 18:30:51 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 29 Sep 2004 18:30:51 +0200
Subject: [R] multiple match question
In-Reply-To: <A03188C6623C0D46A703CB5AA59907F201C11BF4@JENMAIL01.ad.intershop.net>
References: <A03188C6623C0D46A703CB5AA59907F201C11BF4@JENMAIL01.ad.intershop.net>
Message-ID: <415AE33B.5000700@statistik.uni-dortmund.de>

Marc Mamin wrote:

> Hello,
> 
>  I'm looking for a fast way to retrieve the position of elements  from a vector which match element in another vector.
> 
> Example
> 
> va<-c('a','e')
> vb<-c('a','b','c','d','e','f','e')
> 
> f(va,vb) should return c(1,5,7)
> 
> I have 2 different cases: 
> 
> I) my vector vb contains only distinct values
> II) my vector vb may contains the same values more than once.
> 
> for I) I use following which is fast enough:
> 
> 	as.vector(na.omit(unlist(lapply(va,match,vb))))


  which(vb %in% va)

Uwe Ligges


> Thanks for any help,
> 
> Marc
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Wed Sep 29 18:37:05 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Sep 2004 18:37:05 +0200
Subject: [R] multiple match question
In-Reply-To: <A03188C6623C0D46A703CB5AA59907F201C11BF4@JENMAIL01.ad.intershop.net>
References: <A03188C6623C0D46A703CB5AA59907F201C11BF4@JENMAIL01.ad.intershop.net>
Message-ID: <x2pt45rpzi.fsf@biostat.ku.dk>

"Marc Mamin" <M.Mamin at intershop.de> writes:

> Hello,
> 
>  I'm looking for a fast way to retrieve the position of elements  from a vector which match element in another vector.
> 
> Example
> 
> va<-c('a','e')
> vb<-c('a','b','c','d','e','f','e')
> 
> f(va,vb) should return c(1,5,7)
> 
> I have 2 different cases: 
> 
> I) my vector vb contains only distinct values
> II) my vector vb may contains the same values more than once.
> 
> for I) I use following which is fast enough:
> 
> 	as.vector(na.omit(unlist(lapply(va,match,vb))))

Wouldn't know about speed, but

  which(apply(outer(va,vb,"=="),2,any))
  which(sapply(vb,"%in%",va))

both seem to do the trick.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From kbartz at loyaltymatrix.com  Wed Sep 29 18:40:32 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Wed, 29 Sep 2004 09:40:32 -0700
Subject: [R] multiple match question
In-Reply-To: <A03188C6623C0D46A703CB5AA59907F201C11BF4@JENMAIL01.ad.intershop.net>
References: <A03188C6623C0D46A703CB5AA59907F201C11BF4@JENMAIL01.ad.intershop.net>
Message-ID: <415AE580.60301@loyaltymatrix.com>

Marc Mamin wrote:
> Hello,
> 
>  I'm looking for a fast way to retrieve the position of elements  from a vector which match element in another vector.
> 
> Example
> 
> va<-c('a','e')
> vb<-c('a','b','c','d','e','f','e')
> 
> f(va,vb) should return c(1,5,7)
> 
> I have 2 different cases: 
> 
> I) my vector vb contains only distinct values
> II) my vector vb may contains the same values more than once.
> 
> for I) I use following which is fast enough:
> 
> 	as.vector(na.omit(unlist(lapply(va,match,vb))))
> 
> Thanks for any help,
> 
> Marc
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

Hi Marc,

How about this?

which(vb %in% va)

Let me know if you have any more questions.

Kevin



From p.dalgaard at biostat.ku.dk  Wed Sep 29 18:44:28 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Sep 2004 18:44:28 +0200
Subject: [R] multiple match question
In-Reply-To: <x2pt45rpzi.fsf@biostat.ku.dk>
References: <A03188C6623C0D46A703CB5AA59907F201C11BF4@JENMAIL01.ad.intershop.net>
	<x2pt45rpzi.fsf@biostat.ku.dk>
Message-ID: <x2lletrpn7.fsf@biostat.ku.dk>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> Wouldn't know about speed, but
> 
>   which(apply(outer(va,vb,"=="),2,any))
>   which(sapply(vb,"%in%",va))
> 
> both seem to do the trick.

Drats... Andy and Uwe are of course right: which(vb %in% va) suffices.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From joehl at gmx.de  Wed Sep 29 18:46:26 2004
From: joehl at gmx.de (=?ISO-8859-1?Q?=22Jens_Oehlschl=E4gel=22?=)
Date: Wed, 29 Sep 2004 18:46:26 +0200 (MEST)
Subject: [R] R-devel not R-help (was "Bug? using { as a function ...")
Message-ID: <32195.1096476386@www27.gmx.net>


Gabor,

> The real problem is how to create a list with given names
> and constant content.  

When this is your problem to solve, why don't you do the following?

as.constlist <- function(content, names){
	content <- rep(list(content), length=length(names))
	names(content) <- names
	content
}
nams <- letters[1:3]
v <- 1:2
as.constlist(v, nams)


Best 


Jens Oehlschl??gel


> I find I need to do that and when I noticed
> a recent problem posted on r-help that required it I decided it was 
> time that I figured out a better way to do it.  I simplified the 
> problem for purpose of bringing out the error more clearly but it
> otherwise does stem from a real problem.
> 
> To illustrate, we will use this test data:
> 
> 		 nams <- letters[1:3]
> 		 v <- 1:2
> 
> The following will do it:
> 
> 		 L <- rep(list(v), length(nams))
> 		 names(L) <- nams
> 
> but I wanted a more compact expression.

-- 
GMX ProMail mit bestem Virenschutz http://www.gmx.net/de/go/mail
+++ Empfehlung der Redaktion +++ Internet Professionell 10/04 +++



From gunter.berton at gene.com  Wed Sep 29 18:55:24 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 29 Sep 2004 09:55:24 -0700
Subject: [R] defining a template for functions via do.call and substitute.
In-Reply-To: <012821F286ED1D4ABDC72F9E1DD63D0C041EA9C3@NLDNC003PEX1.ubsgs.ubsgroup.net>
Message-ID: <200409291655.i8TGtO3e022213@hertz.gene.com>

John:

Andy and Dimitris have already fully answered your query. However, as you
seem to mainly be interested in simple string substitution, I wanted to
point out that there is a perhaps more transparent approach using gsub()
that does just this. 

Here's a slightly more complicated function form to illustrate the idea:

> f<-function(a,b){z<-a+b; b+z*sin(b)}
 
> ## Get the body of the function and convert it to a character vector:
>  bf<-deparse(body(f))
 
> orig<-c('a','b')  ## original symbols
> changed<-c('x','y') ## the character strings you wish to substitute for
them
 
> ## perform the string substitution
>  for(i in seq(along=changed))bf<-gsub(orig[i],changed[i],bf)
 
> ## re-parse the body and change the formals
>  body(f)<-parse(text=bf)
>  names(formals(f))<-changed
 
> f
function (x, y) 
{
    z <- x + y
    y + z * sin(y)
}

substitute's real power lies in its ability to substitute whole expressions
bound to a symbol in an environment, and this might be overkill here.

Cheers,

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> john.gavin at ubs.com
> Sent: Wednesday, September 29, 2004 4:17 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] defining a template for functions via do.call 
> and substitute.
> 
> Hi,
> 
> Given a function
> 
>   fun <- function(a, b) a + b
> 
> how do I generate the function 'function(x, y) x + y'?
> 
> Working from the help files and Bill Venables' R-news article 
> (June 2002),
> I have tried various permutations with substitute without success. 
> e.g.
>   do.call("substitute", list(fun, list(a = as.name("x"), b = 
> as.name("y"))))
> 
> Regards,
> 
> John.
> 
> John Gavin <john.gavin at ubs.com>,
> Quantitative Risk Models and Statistics,
> UBS Investment Bank, 6th floor, 
> 100 Liverpool St., London EC2M 2RH, UK.
> Phone +44 (0) 207 567 4289
> Fax   +44 (0) 207 568 5352
> 
> Visit our website at http://www.ubs.com
> 
> This message contains confidential information and is 
> intend...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From tom_woody at swissinfo.org  Wed Sep 29 18:58:42 2004
From: tom_woody at swissinfo.org (=?ISO-8859-1?Q?Thomas_Sch=F6nhoff?=)
Date: Wed, 29 Sep 2004 18:58:42 +0200
Subject: [R] problems with ESS & R ...
In-Reply-To: <FA40FC4D-1213-11D9-B067-0003930EA956@gmx.net>
References: <FA40FC4D-1213-11D9-B067-0003930EA956@gmx.net>
Message-ID: <415AE9C2.7080209@swissinfo.org>

Hello,

Meinhard Ploner schrieb:
> Hi!
> I have R 1.9.1, Mac OS X 10.3.5, GNU Emacs 21.2.1 and ESS 5.2.3.
> I installed today the ESS by not changing ess-site.el, but creating 
> .emacs in $home with the single line:
> 
> $ cat ~/.emacs
> (load "/usr/local/lib/ess-5.2.3/lisp/ess-site")
> 
> If I start now emacs and then R (with M-x R) then I get:
> 
>  > options(STERM='iESS', editor='emacsclient')
> 
> but using fix() oder edit() doesn't work:
> 
>  > fix(pc)
> emacsclient: can't find socket; have you started the server?
> Error in edit(name, file, editor) : problem with running editor emacsclient

I was suffering from the same behavior of ESS/Emacs/R under Debian GNULinux.

Maybe

C -c C- d   (C= CTRL!)

combination is helpful to try!

Maybe this works also under MAC OSX

regards

Thomas



From ozric at web.de  Wed Sep 29 19:11:17 2004
From: ozric at web.de (Christian Schulz)
Date: Wed, 29 Sep 2004 19:11:17 +0200
Subject: [R] optim "a log-likelihood function"
Message-ID: <200409291911.17378.ozric@web.de>

Hello,

i know that i have to use optim, but i'm confused how its
possible  maximize  the sum over all l[i] and get the optimized
max(LL), r  and alpha?

LL <- function(trans,time){
   for(i in 1:length(trans){
     l[i] <- log(lgamma(r+trans[i] - 
gamma(r+1)*(alpha/alpha+t[i]))**r)*(t[i]/alpha+t[i]))**trans[i]
}
return(sum(l))
   }

i'm confused how i have to set r and alpha 
and i found no related help in archives?

...in Excel it works with solver but only for ~65.000 rows :-)

#This notation is 1 for trans  and 1  for time instead the Startvalues for r 
and alpha?

optim(c(1,1),-LL)

many thanks  for an easy example or hint 
regards,christian



From tlumley at u.washington.edu  Wed Sep 29 19:24:36 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 29 Sep 2004 10:24:36 -0700 (PDT)
Subject: [R] defining a template for functions via do.call and substitute.
In-Reply-To: <200409291655.i8TGtO3e022213@hertz.gene.com>
References: <200409291655.i8TGtO3e022213@hertz.gene.com>
Message-ID: <Pine.A41.4.61.0409291022380.267054@homer06.u.washington.edu>

On Wed, 29 Sep 2004, Berton Gunter wrote:

> John:
>
> Andy and Dimitris have already fully answered your query. However, as you
> seem to mainly be interested in simple string substitution, I wanted to
> point out that there is a perhaps more transparent approach using gsub()
> that does just this.
>
> Here's a slightly more complicated function form to illustrate the idea:
>
>> f<-function(a,b){z<-a+b; b+z*sin(b)}
>
>> ## Get the body of the function and convert it to a character vector:
>>  bf<-deparse(body(f))
>
>> orig<-c('a','b')  ## original symbols
>> changed<-c('x','y') ## the character strings you wish to substitute for
> them

The problem with this is that it will substitute xx for aa, and xy for ab, 
and so on.  You need at least to tokenize the code, even if you don't 
necessarily need to parse it.

 	-thomas


>> ## perform the string substitution
>>  for(i in seq(along=changed))bf<-gsub(orig[i],changed[i],bf)
>
>> ## re-parse the body and change the formals
>>  body(f)<-parse(text=bf)
>>  names(formals(f))<-changed
>
>> f
> function (x, y)
> {
>    z <- x + y
>    y + z * sin(y)
> }
>
> substitute's real power lies in its ability to substitute whole expressions
> bound to a symbol in an environment, and this might be overkill here.
>
> Cheers,
>
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
>
>
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
>> john.gavin at ubs.com
>> Sent: Wednesday, September 29, 2004 4:17 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] defining a template for functions via do.call
>> and substitute.
>>
>> Hi,
>>
>> Given a function
>>
>>   fun <- function(a, b) a + b
>>
>> how do I generate the function 'function(x, y) x + y'?
>>
>> Working from the help files and Bill Venables' R-news article
>> (June 2002),
>> I have tried various permutations with substitute without success.
>> e.g.
>>   do.call("substitute", list(fun, list(a = as.name("x"), b =
>> as.name("y"))))
>>
>> Regards,
>>
>> John.
>>
>> John Gavin <john.gavin at ubs.com>,
>> Quantitative Risk Models and Statistics,
>> UBS Investment Bank, 6th floor,
>> 100 Liverpool St., London EC2M 2RH, UK.
>> Phone +44 (0) 207 567 4289
>> Fax   +44 (0) 207 568 5352
>>
>> Visit our website at http://www.ubs.com
>>
>> This message contains confidential information and is
>> intend...{{dropped}}
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From gunter.berton at gene.com  Wed Sep 29 19:25:35 2004
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 29 Sep 2004 10:25:35 -0700
Subject: [R] defining a template for functions via do.call and substit ute.
In-Reply-To: <3A822319EB35174CA3714066D590DCD504AF8487@usrymx25.merck.com>
Message-ID: <200409291725.i8THPZmF003316@hertz.gene.com>

THE FLAW!  :-(

-- Bert 

> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com] 
> Sent: Wednesday, September 29, 2004 10:11 AM
> To: 'Berton Gunter'
> Subject: RE: [R] defining a template for functions via 
> do.call and substit ute.
> 
> Bert,
> 
> I thought about that, too, but I believe that approach is not 
> as safe, as
> one could run into trouble if the body of the function has 
> something like
> aCupOfCofee + someCream, which would ended up as xCupOfCofee 
> + someCrexm...
> 
> Cheers,
> Andy



From ggrothendieck at myway.com  Wed Sep 29 19:38:00 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Wed, 29 Sep 2004 17:38:00 +0000 (UTC)
Subject: [R] defining a template for functions via do.call and substitute.
References: <200409291655.i8TGtO3e022213@hertz.gene.com>
	<Pine.A41.4.61.0409291022380.267054@homer06.u.washington.edu>
Message-ID: <loom.20040929T192820-624@post.gmane.org>

Thomas Lumley <tlumley <at> u.washington.edu> writes:

: 
: On Wed, 29 Sep 2004, Berton Gunter wrote:
: 
: > John:
: >
: > Andy and Dimitris have already fully answered your query. However, as you
: > seem to mainly be interested in simple string substitution, I wanted to
: > point out that there is a perhaps more transparent approach using gsub()
: > that does just this.
: >
: > Here's a slightly more complicated function form to illustrate the idea:
: >
: >> f<-function(a,b){z<-a+b; b+z*sin(b)}
: >
: >> ## Get the body of the function and convert it to a character vector:
: >>  bf<-deparse(body(f))
: >
: >> orig<-c('a','b')  ## original symbols
: >> changed<-c('x','y') ## the character strings you wish to substitute for
: > them
: 
: The problem with this is that it will substitute xx for aa, and xy for ab, 
: and so on.  You need at least to tokenize the code, even if you don't 
: necessarily need to parse it.

The problems with the lexical approach cited by Thomas, viz. you must redo
the tokeniziation whereas with the earlier parsing approaches R takes care
of that for you, make the parsing approaches superior and really simpler but a 
partial rescue of the lexical approach can be obtained by using perl regexps
with the word boundary operator.  I am not sure whether or not perl's regexp's
idea of word boundary is the actually the same as R's but its close enough
for this example and likely many others.  Note that in the first call to
subst.fun za mistakenly got replaced with zx but in the second example
it did not.


R> # previous example wrapped into a function with ... args just in case
R> subst.fun <- function(f, orig, changed, ...) {
+    bf<-deparse(body(f))
+    for(i in seq(along=changed))bf<-gsub(orig[i],changed[i],bf,...)
+    body(f)<-parse(text=bf)
+    names(formals(f))<-changed
+    f
+ }
R> # modify f so it uses za rather than z from the original example
R> f<-function(a,b){za<-a+b; b+za*sin(b)}
R> subst.fun(f, c("a","b"), c("x","y"))  # note za becomes zx !!!
function (x, y) 
{
    zx <- x + y
    y + zx * sin(y)
}
<environment: 01BDE0FC>

R> #########
R> # We could fix this up using perl expressions with word boundaries
 
R> subst.fun(f, c("\\ba\\b","\\bb\\b"), c("x","y"), perl = TRUE)
function (x, y) 
{
    za <- x + y
    y + za * sin(y)
}
<environment: 01BE4954>



From William.Simpson at drdc-rddc.gc.ca  Wed Sep 29 19:40:27 2004
From: William.Simpson at drdc-rddc.gc.ca (Bill Simpson)
Date: Wed, 29 Sep 2004 13:40:27 -0400 (EDT)
Subject: [R] principal components question
Message-ID: <Pine.LNX.4.44.0409291338420.23944-100000@localhost.localdomain>

I have the following problem with PCA.

I have measures from lots of people (>200) on variables sf1, sf2, sf4, 
sf8, sf16, sf24. The goal is to see underlying "channels" using PCA. Each 
person i has a "contrast sensitivity function" s_i(f) composed of the 
summed output of several channels c(f), each weighted differently for each 
subject:

s_i(f) = a_1i * c_1(f) + a_2i * c_2(f) + ... + a_ni * c_n(f)

(s_i(f) was measured at 6 values of f, sf1-sf24)

This all works well using prcomp.

My question. I would like to fit the average s(f) across subjects using 
the derived channels c_1(f) - c_n(f). Somehow I need to get the weights 
a_1 to a_n

s(f) = a_1 * c_1(f) + a_2 * c_2(f) + ... + a_n * c_n(f)

Here is what I did, but there is probably a better solution.
dd is the data frame.

sf<-c(1,2,4,8,16,24)
ddmean<-apply(dd,2,mean)
out<-prcomp(dd)
r1<-out$rotation[,1];r2<-out$rotation[,2];r3<-out$rotation[,3]

#rotate the loadings to give "simple structure"
Sr<- varimax(out$rotation[,1:3])$loadings
Sr1<-Sr[,1];Sr2<-Sr[,2];Sr3<-Sr[,3]  #I just used the first 3 PCs

fn <- function(p) sum((ddmean - (p[4]+p[1]*Sr1 +p[2]*Sr2+p[3]*Sr3))^2)
fit<-nlm(fn,p=c(-1000,-100,-100,10),hessian=TRUE)
b<-fit$estimate

plot(sf,ddmean,log="x",ylim=c(5,225),xaxt="n",ylab="",xlab="",pch=15)
lines(sf,b[4]+b[1]*Sr1 + b[2]*Sr2 + b[3]*Sr3,lwd=3)
lines(sf,b[4]/3+b[1]*Sr1,lty=1)
lines(sf,b[4]/3+b[2]*Sr2,lty=2)
lines(sf,b[4]/3+b[3]*Sr3,lty=3)

Thanks very much for any help.

BTW, I have heard of "functional PCA" and it sounds more appropriate for 
what I am doing. Any pointers on how to do that in R or to any info are 
appreciated.

Bill Simpson



From sundar.dorai-raj at PDF.COM  Wed Sep 29 19:41:45 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 29 Sep 2004 10:41:45 -0700
Subject: [R] optim "a log-likelihood function"
In-Reply-To: <200409291911.17378.ozric@web.de>
References: <200409291911.17378.ozric@web.de>
Message-ID: <415AF3D9.4080803@pdf.com>



Christian Schulz wrote:

> Hello,
> 
> i know that i have to use optim, but i'm confused how its
> possible  maximize  the sum over all l[i] and get the optimized
> max(LL), r  and alpha?
> 
> LL <- function(trans,time){
>    for(i in 1:length(trans){
>      l[i] <- log(lgamma(r+trans[i] - 
> gamma(r+1)*(alpha/alpha+t[i]))**r)*(t[i]/alpha+t[i]))**trans[i]
> }
> return(sum(l))
>    }
> 
> i'm confused how i have to set r and alpha 
> and i found no related help in archives?
> 
> ...in Excel it works with solver but only for ~65.000 rows :-)
> 
> #This notation is 1 for trans  and 1  for time instead the Startvalues for r 
> and alpha?
> 

I'm not sure what the above statement means, so I may have 
misinterpretted what you are trying to accomplish.

> optim(c(1,1),-LL)
> 
> many thanks  for an easy example or hint 
> regards,christian
> 

Did you look at the first example in ?optim? There also numerous errors 
in LL: missing parans, time is not used, t is undefined in the function.

LL <- function(x, trans, time) {
   r <- x[1]
   alpha <- x[2]
   ...
   sum(l)
}

optim(c(1, 1), LL, control = list(fnscale = -1),
       trans = trans, time = time)

Some style issues:
1. Break up lines that run too long, especially if you expect others to 
read your code.
2. You don't need an explicit "return" at the end of a function.
3. You should remove the "for" loop in LL and vectorise "l", which 
should be easy.

Hope this is helpful,

--sundar



From patrick.drechsler at gmx.net  Wed Sep 29 19:47:26 2004
From: patrick.drechsler at gmx.net (Patrick Drechsler)
Date: Wed, 29 Sep 2004 19:47:26 +0200
Subject: [R] displaying sample size in boxplots
References: <m3u0thfdji.fsf@pdrechsler.fqdn.th-h.de>
	<Pine.LNX.4.44.0409291506220.12880-100000@reclus.nhh.no>
	<16730.56993.882269.874478@gargle.gargle.HOWL>
Message-ID: <m3fz51rmq9.fsf@pdrechsler.fqdn.th-h.de>


Martin Maechler wrote on 29 Sep 2004 17:11:13 MET:

>>>>>> "Roger" == Roger Bivand <Roger.Bivand at nhh.no>
>>>>>>     on Wed, 29 Sep 2004 15:09:17 +0200 (CEST) writes:
[snip]

>     Roger> Perhaps use the names= argument (width can help too):
>                                             ^^^^^^^^^^^^^^^^^^
> Indeed!
> And that's why -- "in the good ol' times" when the box plot was invented
> and enhanced, the inventors thought about it.
> For that reason there's the  'varwidth = TRUE/FALSE' argument
> in boxplot() 
>
> Note from help(boxplot) however that the inventors thought
> it wiser to make the width proportional to the SQRT of the
> sample size rather than the sample.size itself, i.e.,
> 'varwidth = TRUE' and your proposal are not equivalent.
>
>     >> boxplot(expend~stature, width=sample.size/length(expend), 
>     >>   + names=paste(levels(stature), ", N=", sample.size, sep=""))
>
> Here are the current proposals [for cut & paste]:
>
> library(ISwR)
> data(energy)
> attach(energy)
>
> ## 1
> boxplot(expend~stature)
> sample.size <- tapply(expend, stature, length)
> ss.ch <- paste("N=", sample.size, sep="")
> mtext(ss.ch, at=1:length(unique(stature)), line=2, side=1)
>
> ## 2 (Roger)
> boxplot(expend~stature, width=sample.size/length(expend),
>         names=paste(levels(stature), ", N=", sample.size, sep=""))
>
> ## 3 (Roger + Martin):
> boxplot(expend ~ stature, varwidth= TRUE,
>         names=paste(levels(stature), ", N=", sample.size, sep=""))

Thanks for the explanation and the nice summary Martin! I can see
the point you're making about varwidth. I've read that part in
the documentation before but I have to admit that up to now I
didn't see the purpose of this parameter. Although there are
situations were I prefer to see the number in print somewhere on
the plot which I can now easily accomplish with `names'.

Also thanks to Stephano for the pointer to the r-newsletter
article and to Don for showing me how one implements user
defined functions!

Cheers

Patrick
-- 
For animals, the entire universe has been neatly divided into things
to (a) mate with, (b) eat, (c) run away from, and (d) rocks.
        -- (Terry Pratchett, Equal Rites)



From liuwensui at gmail.com  Wed Sep 29 21:03:01 2004
From: liuwensui at gmail.com (Wensui Liu)
Date: Wed, 29 Sep 2004 15:03:01 -0400
Subject: [R] how to read the tables in ACCESS database into R ?
Message-ID: <1115a2b004092912034623656a@mail.gmail.com>

is there anything similar to proc import in SAS?

thank you all. have a nice day.

wensui



From ozric at web.de  Wed Sep 29 21:10:15 2004
From: ozric at web.de (Christian Schulz)
Date: Wed, 29 Sep 2004 21:10:15 +0200
Subject: [R] optim "a log-likelihood function"
In-Reply-To: <415AF3D9.4080803@pdf.com>
References: <200409291911.17378.ozric@web.de> <415AF3D9.4080803@pdf.com>
Message-ID: <200409292110.15229.ozric@web.de>

many thanks , that x are my parameters is the help !
christian


>
> LL <- function(x, trans, time) {
>    r <- x[1]
>    alpha <- x[2]
>    ...
>    sum(l)
> }
>
> optim(c(1, 1), LL, control = list(fnscale = -1),
>        trans = trans, time = time)
>
> Some style issues:
> 1. Break up lines that run too long, especially if you expect others to
> read your code.
> 2. You don't need an explicit "return" at the end of a function.
> 3. You should remove the "for" loop in LL and vectorise "l", which
> should be easy.
>
> Hope this is helpful,
>
> --sundar
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From tlumley at u.washington.edu  Wed Sep 29 21:17:01 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 29 Sep 2004 12:17:01 -0700 (PDT)
Subject: [R] how to read the tables in ACCESS database into R ?
In-Reply-To: <1115a2b004092912034623656a@mail.gmail.com>
References: <1115a2b004092912034623656a@mail.gmail.com>
Message-ID: <Pine.A41.4.61.0409291214280.267054@homer06.u.washington.edu>

On Wed, 29 Sep 2004, Wensui Liu wrote:

> is there anything similar to proc import in SAS?
>

You probably want the RODBC package. Read the Data Import/Export Manual 
for details.

 	-thomas

PS: 10/10 for informative subject line, but please include the information 
in the message body as well, so that it is comprehensible on its own.



From nderby at u.washington.edu  Wed Sep 29 21:19:51 2004
From: nderby at u.washington.edu (Nathaniel B. Derby)
Date: Wed, 29 Sep 2004 12:19:51 -0700 (PDT)
Subject: [R] arima vs arima0
Message-ID: <Pine.LNX.4.43.0409291219510.26354@hymn05.u.washington.edu>

What is the difference between arima and arima0?



From liuwensui at gmail.com  Wed Sep 29 21:41:54 2004
From: liuwensui at gmail.com (Wensui Liu)
Date: Wed, 29 Sep 2004 15:41:54 -0400
Subject: [R] solution for reading access tables into R
Message-ID: <1115a2b00409291241796ee5b7@mail.gmail.com>

Thanks for the response from Thomas Lumley. There is the way to read
access tables into R, just for someone else who might be interested.
#######################################################
 f>or instance, if
 >there is a table named patient in the access file named patient_data
 >in my C drive. 

You need to set up a DSN for the file using the ODBC program in the
Control Panel.  This is the name ODBC uses for your database. Suppose you
call it "patientdb"

Now
  library(RODBC)
  channel <- odbcConnect("patientdb")
to connect to the database
  sqlTables(channel)
to list the available tables
  sqlFetch(channel, "patient")
to fetch the table called "patient"
  odbcClose(channel)
to close the connection.



From larsenmtl at comcast.net  Wed Sep 29 23:12:37 2004
From: larsenmtl at comcast.net (larsenmtl@comcast.net)
Date: Wed, 29 Sep 2004 21:12:37 +0000
Subject: [R] RSXML - Parsing XML Documents on Internet
Message-ID: <092920042112.2044.415B25450008BC8A000007FC2200734748049B03020A9C9D0E04@comcast.net>

R Users -

I asked about this a few months ago and never did quite figure it out, so with 
more information, allow me to try again.

If I use the following code:

library(xml)
xmlTreeParse("http://home.comcast.net/~larsenmtl/xmlTestDoc.xml", isURL = TRUE)
 
I receive this error:
Error in xmlTreeParse("http://home.comcast.net/~larsenmtl/xmlTestDoc.xml"",  : 
        error in creating parser for 
http://home.comcast.net/~larsenmtl/xmlTestDoc.xml"

Now I know that xmlTreeParse uses the libxml facilities for downloading and 
parsing off the web.   Along with one of our network people, I did some packet 
sniffing and it looks like libxml doesn't go through our proxy server (it tries 
to directly connect to the above URL), which is the reason for the error.  Is 
there anyway to force it through the proxy?  Am I missing some setting or 
option?  If I download the xml file and parse it locally it works without error.

Please Note that the URL is valid and I can open it in my browser.  Also note 
that I must start R with the --internet2 option so it'll use our proxy server.  

Details:
Windows 2000
R1.9.1
RSXML 0.97-0
libxml2-2.4.13 distribution for Windows

I also tried this on a Mandrake 9.2 box with R1.9.1, XML0.95-6, and libxml2 
2.6.13.  Results were the same but with the additional error message:
I/O warning: falied to load external entity "http://...."

Thanks,

Mark Larsen



From davidr at rhotrading.com  Wed Sep 29 23:28:09 2004
From: davidr at rhotrading.com (davidr@rhotrading.com)
Date: Wed, 29 Sep 2004 16:28:09 -0500
Subject: [R] How to print landscape from script in Windows:
	dev.print(win.print, printer="local printer name",
	...) does not accept horizontal=TRUE 
Message-ID: <12AE52872B5C5348BE5CF47C707FF53A3271FD@rhosvr02.rhotrading.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040929/1f5c01bf/attachment.pl

From kjetil at acelerate.com  Thu Sep 30 00:53:28 2004
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Wed, 29 Sep 2004 18:53:28 -0400
Subject: [R] arima vs arima0
In-Reply-To: <Pine.LNX.4.43.0409291219510.26354@hymn05.u.washington.edu>
References: <Pine.LNX.4.43.0409291219510.26354@hymn05.u.washington.edu>
Message-ID: <415B3CE8.8090405@acelerate.com>

Nathaniel B. Derby wrote:

> What is the difference between arima and arima0?

form
?arima0

"This is a preliminary version, and will be replaced by |arima 
<cid:part1.08080208.05030809 at acelerate.com>|."

arima0 can be faster, though, in some cases, but does'nt handle NA's
as arima does.

If you don't have a very good reason to use arima0, use arima

Kjetil Halvorsen



>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra



From christoph.lehmann at gmx.ch  Thu Sep 30 02:01:51 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Thu, 30 Sep 2004 02:01:51 +0200
Subject: [R] glm.fit and predict.glm: error ' no terms component'
In-Reply-To: <Pine.A41.4.61.0409290746340.169788@homer11.u.washington.edu>
References: <415AC0F5.9080009@gmx.ch>
	<Pine.A41.4.61.0409290746340.169788@homer11.u.washington.edu>
Message-ID: <415B4CEF.5030201@gmx.ch>

many thanks I did it the following way, based on Thomas' suggestion

predict.glm.fit<-function(glmfit, newmatrix){
    newmatrix<-cbind(1,newmatrix)
    coef <- rbind(1, as.matrix(glmfit$coef))
    eta <- as.matrix(newmatrix) %*% as.matrix(coef)
    exp(eta)/(1 + exp(eta))
}


cheers

christoph







Thomas Lumley wrote:
> On Wed, 29 Sep 2004, Christoph Lehmann wrote:
> 
>> Hi
>>
>> when I fit a glm by
>>
>>     glm.fit(x,y,family = binomial())
>>     and then try to use the object for prediction of newdata by:
>>
>>     predict.glm(object, newdata)
>>
>> I get the error:
>>
>> Error in terms.default(object) : no terms component
>>
>> I know I can use glm() and a formula, but for my case I prefer 
>> glm.fit(x,y)...
> 
> 
> Well, you can't use predict.glm that way.  As the function name 
> suggests, it is a predict method for objects of class "glm", which in 
> your case you do not have.
> 
> There are two reasons why it won't work.  For type="terms" the formula 
> is needed to identify terms, and for any type of prediction the formula 
> is needed to convert the data frame newdata into a model matrix.
> 
> You would need to write a function where the new data was a model 
> matrix. If you only need point predictions then
> 
> predict_glm_fit<-function(glmfit, newmatrix, addintercept=TRUE){
>    if (addintercept)
>     newmatrix<-cbind(1,newmatrix)
>    eta<-glmfit$coef %*% newmatrix
>    family$linkinv(eta)
> }
> 
> would work.
> 
>     -thomas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From nusbj at hotmail.com  Thu Sep 30 03:00:48 2004
From: nusbj at hotmail.com (Zhen Pang)
Date: Thu, 30 Sep 2004 09:00:48 +0800
Subject: [R] optim "a log-likelihood function"
Message-ID: <BAY22-F3220lbhsKd6Q00016b1a@hotmail.com>


>From: Sundar Dorai-Raj <sundar.dorai-raj at pdf.com>
>Reply-To: sundar.dorai-raj at pdf.com
>To: Christian Schulz <ozric at web.de>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] optim "a log-likelihood function"
>Date: Wed, 29 Sep 2004 10:41:45 -0700
>
>
>
>Christian Schulz wrote:
>
>>Hello,
>>
>>i know that i have to use optim, but i'm confused how its
>>possible  maximize  the sum over all l[i] and get the optimized
>>max(LL), r  and alpha?
>>
>>LL <- function(trans,time){
>>    for(i in 1:length(trans){
>>      l[i] <- log(lgamma(r+trans[i] - 
>>gamma(r+1)*(alpha/alpha+t[i]))**r)*(t[i]/alpha+t[i]))**trans[i]
>>}
>>return(sum(l))
>>    }
>>
>>i'm confused how i have to set r and alpha and i found no related help in 
>>archives?
>>
>>...in Excel it works with solver but only for ~65.000 rows :-)
>>
>>#This notation is 1 for trans  and 1  for time instead the Startvalues for 
>>r and alpha?
>>
>
>I'm not sure what the above statement means, so I may have misinterpretted 
>what you are trying to accomplish.
>
>>optim(c(1,1),-LL)
>>
>>many thanks  for an easy example or hint regards,christian
>>
>
>Did you look at the first example in ?optim? There also numerous errors in 
>LL: missing parans, time is not used, t is undefined in the function.
>
>LL <- function(x, trans, time) {
>   r <- x[1]
>   alpha <- x[2]
>   ...
>   sum(l)
>}
>
>optim(c(1, 1), LL, control = list(fnscale = -1),
>       trans = trans, time = time)
>
>Some style issues:
>1. Break up lines that run too long, especially if you expect others to 
>read your code.
>2. You don't need an explicit "return" at the end of a function.
>3. You should remove the "for" loop in LL and vectorise "l", which should 
>be easy.
>

I also use optim, however, for my case, can you show some light on avoiding 
the loop?

There are around 200 sets of (i,j,k) where i<=j<=k. 3 situations exist 
whether "=" hold, I list one for example,

                      l<-i:(k-j+i)
                      s<-rep(0,k)
                      s[l]<-choose(j,i)*choose((k-j),(l-i))/choose(k,l)
                      ss<-sum(s*x0)

then sum all the log(ss) is my log-liklihood function.

One loop from 1 to 200 is inevitable. I have tried to use vector, however, I 
only can simply to this situation.  Thanks.

Regards,

Zhen

>Hope this is helpful,
>
>--sundar
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From sundar.dorai-raj at PDF.COM  Thu Sep 30 03:21:17 2004
From: sundar.dorai-raj at PDF.COM (Sundar Dorai-Raj)
Date: Wed, 29 Sep 2004 18:21:17 -0700
Subject: Vectorising and loop (was Re: [R] optim "a log-likelihood function")
In-Reply-To: <BAY22-F3220lbhsKd6Q00016b1a@hotmail.com>
References: <BAY22-F3220lbhsKd6Q00016b1a@hotmail.com>
Message-ID: <415B5F8D.2060603@pdf.com>



Zhen Pang wrote:

> 
> I also use optim, however, for my case, can you show some light on 
> avoiding the loop?
> 
> There are around 200 sets of (i,j,k) where i<=j<=k. 3 situations exist 
> whether "=" hold, I list one for example,
> 
>                      l<-i:(k-j+i)
>                      s<-rep(0,k)
>                      s[l]<-choose(j,i)*choose((k-j),(l-i))/choose(k,l)
>                      ss<-sum(s*x0)
> 
> then sum all the log(ss) is my log-liklihood function.
> 
> One loop from 1 to 200 is inevitable. I have tried to use vector, 
> however, I only can simply to this situation.  Thanks.
> 
> Regards,
> 
> Zhen
> 

Zhen,
   Your question doesn't really have much to do with optim, so I changed 
the subject line.

It's difficult to see what you're trying to accomplish without a 
complete example. Could you post one? Also, for loops are necessarily bad.

One thing to note is that you're better off using lchoose in the above 
code. I.e.

log.s <- lchoose(j, i) + lchoose(k - j, l - i) - lchoose(k, l)
s[l] <- exp(log.s)

--sundar



From johnnyzhz at yahoo.com  Thu Sep 30 04:35:10 2004
From: johnnyzhz at yahoo.com (Johnny Zhang)
Date: Wed, 29 Sep 2004 19:35:10 -0700 (PDT)
Subject: [R] read irregular data set
Message-ID: <20040930023510.43707.qmail@web51501.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040929/db253afc/attachment.pl

From nusbj at hotmail.com  Thu Sep 30 04:57:32 2004
From: nusbj at hotmail.com (Zhen Pang)
Date: Thu, 30 Sep 2004 10:57:32 +0800
Subject: Vectorising and loop (was Re: [R] optim "a log-likelihood
	function")
Message-ID: <BAY22-F4y4FypKsEgJX00001a74@hotmail.com>




>From: Sundar Dorai-Raj <sundar.dorai-raj at PDF.COM>
>Reply-To: sundar.dorai-raj at PDF.COM
>To: Zhen Pang <nusbj at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Vectorising and loop (was Re: [R] optim "a log-likelihood 
>function")
>Date: Wed, 29 Sep 2004 18:21:17 -0700
>
>
>
>Zhen Pang wrote:
>
>>
>>I also use optim, however, for my case, can you show some light on 
>>avoiding the loop?
>>
>>There are around 200 sets of (i,j,k) where i<=j<=k. 3 situations exist 
>>whether "=" hold, I list one for example,
>>
>>                      l<-i:(k-j+i)
>>                      s<-rep(0,k)
>>                      s[l]<-choose(j,i)*choose((k-j),(l-i))/choose(k,l)
>>                      ss<-sum(s*x0)
>>
>>then sum all the log(ss) is my log-liklihood function.
>>
>>One loop from 1 to 200 is inevitable. I have tried to use vector, however, 
>>I only can simply to this situation.  Thanks.
>>
>>Regards,
>>
>>Zhen
>>
>
>Zhen,
>   Your question doesn't really have much to do with optim, so I changed 
>the subject line.
>
>It's difficult to see what you're trying to accomplish without a complete 
>example. Could you post one? Also, for loops are necessarily bad.
>
>One thing to note is that you're better off using lchoose in the above 
>code. I.e.
>
>log.s <- lchoose(j, i) + lchoose(k - j, l - i) - lchoose(k, l)
>s[l] <- exp(log.s)
>
>--sundar
>
>
I have a matrix of 200 by 2, namely z, the columns are i and j. K is the 
maximum of j.

x0 is a k dimension vector.

ss<-rep(0,200)
for (m in 1:200)
   {i<-z[m,1]
    j<-z[m,2]
    l<-i:(k-j+i)
    s<-rep(0,k)
    s[l]<-choose(j,i)*choose((k-j),(l-i))/choose(k,l) # we only define some 
of s to be non-zero, since dim(l) might be smaller than dim(s)
    ss[m]<-sum(s*x0)  # ss[m] is a weighted sum of x0
    }
sum(log(ss))

How to avoid the loop of m? I tried to define i<-z[,1] and j<-z[,2], but 
failed. Thanks.

Regards,

Zhen



From d.scott at auckland.ac.nz  Thu Sep 30 05:02:12 2004
From: d.scott at auckland.ac.nz (David Scott)
Date: Thu, 30 Sep 2004 15:02:12 +1200 (NZST)
Subject: [R] nlme: cannot allocate vector of size 126064 Kb
Message-ID: <Pine.LNX.4.61.0409301443140.22886@hydra.stat.auckland.ac.nz>


I have around 4000 observations of a time series. I am trying to fit a 
regression with ARMA error structure using gls from the package nlme.

I have encountered the error: cannot allocate vector of size 126064 Kb

I know this has come up many times before and I will check out the 
suggestions in the mail archive. I was wondering though if there is an 
alternative package that will fit such a model? I did a quick help.search 
on ARIMA and ARMA but only found arma and arma0.

David Scott

_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
 		The University of Auckland, PB 92019
 		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz


Graduate Officer, Department of Statistics



From MSchwartz at MedAnalytics.com  Thu Sep 30 05:13:28 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Wed, 29 Sep 2004 22:13:28 -0500
Subject: [R] read irregular data set
In-Reply-To: <20040930023510.43707.qmail@web51501.mail.yahoo.com>
References: <20040930023510.43707.qmail@web51501.mail.yahoo.com>
Message-ID: <1096514008.22871.16.camel@localhost.localdomain>

On Wed, 2004-09-29 at 21:35, Johnny Zhang wrote:
> Hi Friends,
> I have a data set like this
> 1
> 2 3 4 5
> 6 7
> 8 9 10
> Is there a way to read it into R as a row or column vector?


You can use scan(). Presuming that your data above is in a file called
"MyFile.txt":

> MyData <- scan("MyFile.txt")
Read 10 items

> MyData
 [1]  1  2  3  4  5  6  7  8  9 10

See ?scan for more information.

HTH,

Marc Schwartz



From ggrothendieck at myway.com  Thu Sep 30 06:18:27 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 30 Sep 2004 04:18:27 +0000 (UTC)
Subject: Vectorising and loop (was Re: [R] optim "a
	=?utf-8?b?bG9nLWxpa2VsaWhvb2QJZnVuY3Rpb24iKQ==?=
References: <BAY22-F4y4FypKsEgJX00001a74@hotmail.com>
Message-ID: <loom.20040930T060741-984@post.gmane.org>

Zhen Pang <nusbj <at> hotmail.com> writes:

: 
: >From: Sundar Dorai-Raj <sundar.dorai-raj <at> PDF.COM>
: >Reply-To: sundar.dorai-raj <at> PDF.COM
: >To: Zhen Pang <nusbj <at> hotmail.com>
: >CC: r-help <at> stat.math.ethz.ch
: >Subject: Vectorising and loop (was Re: [R] optim "a log-likelihood 
: >function")
: >Date: Wed, 29 Sep 2004 18:21:17 -0700
: >
: >
: >
: >Zhen Pang wrote:
: >
: >>
: >>I also use optim, however, for my case, can you show some light on 
: >>avoiding the loop?
: >>
: >>There are around 200 sets of (i,j,k) where i<=j<=k. 3 situations exist 
: >>whether "=" hold, I list one for example,
: >>
: >>                      l<-i:(k-j+i)
: >>                      s<-rep(0,k)
: >>                      s[l]<-choose(j,i)*choose((k-j),(l-i))/choose(k,l)
: >>                      ss<-sum(s*x0)
: >>
: >>then sum all the log(ss) is my log-liklihood function.
: >>
: >>One loop from 1 to 200 is inevitable. I have tried to use vector, however, 
: >>I only can simply to this situation.  Thanks.
: >>
: >>Regards,
: >>
: >>Zhen
: >>
: >
: >Zhen,
: >   Your question doesn't really have much to do with optim, so I changed 
: >the subject line.
: >
: >It's difficult to see what you're trying to accomplish without a complete 
: >example. Could you post one? Also, for loops are necessarily bad.
: >
: >One thing to note is that you're better off using lchoose in the above 
: >code. I.e.
: >
: >log.s <- lchoose(j, i) + lchoose(k - j, l - i) - lchoose(k, l)
: >s[l] <- exp(log.s)
: >
: >--sundar
: >
: >
: I have a matrix of 200 by 2, namely z, the columns are i and j. K is the 
: maximum of j.
: 
: x0 is a k dimension vector.
: 
: ss<-rep(0,200)
: for (m in 1:200)
:    {i<-z[m,1]
:     j<-z[m,2]
:     l<-i:(k-j+i)
:     s<-rep(0,k)
:     s[l]<-choose(j,i)*choose((k-j),(l-i))/choose(k,l) # we only define some 
: of s to be non-zero, since dim(l) might be smaller than dim(s)
:     ss[m]<-sum(s*x0)  # ss[m] is a weighted sum of x0
:     }
: sum(log(ss))
: 
: How to avoid the loop of m? I tried to define i<-z[,1] and j<-z[,2], but 
: failed. Thanks.

When Sundar was referring to a *complete* example he was referring to 
both code and data -- something that someone else could simply copy
from your post, paste it into an R session and get the answer as per
the posting guide.

At any rate, if f(x) is the function which takes z[m,] as its single 
argument and returns ss[m] then the above is equivalent to:

   sum(log(apply(z, 1, f)))

Not sure if that really qualifies as getting rid of the loop but it
does get rid of the for and the initialization of ss.



From ripley at stats.ox.ac.uk  Thu Sep 30 08:47:32 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 30 Sep 2004 07:47:32 +0100 (BST)
Subject: [R] How to print landscape from script in Windows:
	dev.print(win.print, 
	printer="local printer name", ...) does not accept horizontal=TRUE 
In-Reply-To: <12AE52872B5C5348BE5CF47C707FF53A3271FD@rhosvr02.rhotrading.com>
Message-ID: <Pine.LNX.4.44.0409300742520.2227-100000@gannet.stats>

Set width and height appropriately for a landscape plot, and set landscape 
in the options for the printer driver (if supported).

Whereas the postscript device can rotate a plot by 90^o, no Windows device 
has that encoded.  Why?  Because the Windows print spooler gives you the 
option to rotate and Unix ones do not.

Or use postscript() + a PostScript printer/printer utility (e.g. GSView on 
Windows).

On Wed, 29 Sep 2004 davidr at rhotrading.com wrote:

> This is a windows-specific question.
> 
>  
> 
> After generating a plot, I can print from scripts or the command line
> with 
> 
>  
> 
> > dev.print(win.print,printer="local windows printer name")
> 
>  
> 
> I would like to print in landscape mode. From the menus, I can
> accomplish this by changing the properties of the printer before
> clicking "print".
> 
> However, I tried adding "horizontal=TRUE" to the command, but it gives
> an error message:
> 
>  
> 
> > dev.print(win.print,horizontal=TRUE,printer="\\\\RhoSvr01\\HP LaserJet
> 8150 PCL 6")
> 
> Error in device(...) : unused argument(s) (horizontal ...)
> 
>  
> 
> I can see from ?device and then ?win.print that, sure enough, there is
> no 'horizontal' parameter in win.print.
> 
>  
> 
> There are many examples like this on the help archives and in the docs,
> apparently for other devices,
> 
> so I am puzzled how to accomplish what I want.
> 
>  
> 
>  
> 
> BTW,
> 
> This is on Windows XP SP2 and
> 
>  
> 
> > R.version
> 
>          _              
> 
> platform i386-pc-mingw32
> 
> arch     i386           
> 
> os       mingw32        
> 
> system   i386, mingw32  
> 
> status   Patched        
> 
> major    1              
> 
> minor    9.1            
> 
> year     2004           
> 
> month    09             
> 
> day      22             
> 
> language R              
> 
>  
> 
> Any help will be much appreciated!
> 
>  
> 
>  
> 
> David L. Reiner
> 
>  
> 
> Rho Trading
> 
> 440 S. LaSalle St -- Suite 620
> 
> Chicago  IL  60605
> 
>  
> 
> 312-362-4963 (voice)
> 
> 312-362-4941 (fax)
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Sep 30 08:52:08 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 30 Sep 2004 07:52:08 +0100 (BST)
Subject: [R] RSXML - Parsing XML Documents on Internet
In-Reply-To: <092920042112.2044.415B25450008BC8A000007FC2200734748049B03020A9C9D0E04@comcast.net>
Message-ID: <Pine.LNX.4.44.0409300751110.2227-100000@gannet.stats>

On Wed, 29 Sep 2004 larsenmtl at comcast.net wrote:

> R Users -
> 
> I asked about this a few months ago and never did quite figure it out, so with 
> more information, allow me to try again.
> 
> If I use the following code:
> 
> library(xml)
> xmlTreeParse("http://home.comcast.net/~larsenmtl/xmlTestDoc.xml", isURL = TRUE)
>  
> I receive this error:
> Error in xmlTreeParse("http://home.comcast.net/~larsenmtl/xmlTestDoc.xml"",  : 
>         error in creating parser for 
> http://home.comcast.net/~larsenmtl/xmlTestDoc.xml"
> 
> Now I know that xmlTreeParse uses the libxml facilities for downloading and 
> parsing off the web.   Along with one of our network people, I did some packet 
> sniffing and it looks like libxml doesn't go through our proxy server (it tries 
> to directly connect to the above URL), which is the reason for the error.  Is 
> there anyway to force it through the proxy?  Am I missing some setting or 
> option?  If I download the xml file and parse it locally it works without error.
> 
> Please Note that the URL is valid and I can open it in my browser.  Also note 
> that I must start R with the --internet2 option so it'll use our proxy server.  

That's your problem.  You can use proxies without --internet2 (see 
?download.file) and 

> 
> Details:
> Windows 2000
> R1.9.1
> RSXML 0.97-0
> libxml2-2.4.13 distribution for Windows
> 
> I also tried this on a Mandrake 9.2 box with R1.9.1, XML0.95-6, and libxml2 
> 2.6.13.  Results were the same but with the additional error message:
> I/O warning: falied to load external entity "http://...."
> 
> Thanks,
> 
> Mark Larsen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Sep 30 08:57:00 2004
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 30 Sep 2004 07:57:00 +0100 (BST)
Subject: [R] RSXML - Parsing XML Documents on Internet
In-Reply-To: <Pine.LNX.4.44.0409300751110.2227-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0409300753000.2227-100000@gannet.stats>

Sorry, my flaky connection (I am on a slow dialup) broke this up: here's 
the rest.

On Thu, 30 Sep 2004, Prof Brian Ripley wrote:

> On Wed, 29 Sep 2004 larsenmtl at comcast.net wrote:

[...]

> > Now I know that xmlTreeParse uses the libxml facilities for downloading and 
> > parsing off the web.   Along with one of our network people, I did some packet 
> > sniffing and it looks like libxml doesn't go through our proxy server (it tries 
> > to directly connect to the above URL), which is the reason for the error.  Is 
> > there anyway to force it through the proxy?  Am I missing some setting or 
> > option?  If I download the xml file and parse it locally it works without error.
> > 
> > Please Note that the URL is valid and I can open it in my browser.  Also note 
> > that I must start R with the --internet2 option so it'll use our proxy server.  
> 
> That's your problem.  You *can* use proxies without --internet2 (see 
> ?download.file) and the XML code uses the standard version of the code.

The first issue is that you have not configured R to use your proxy, so 
please get that working.

Issue two is that you may need to get an older version of XML compiled 
against an older libxml, as the current one has not been tested.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From nusbj at hotmail.com  Thu Sep 30 09:06:24 2004
From: nusbj at hotmail.com (Zhen Pang)
Date: Thu, 30 Sep 2004 15:06:24 +0800
Subject: Vectorising and loop (was Re: [R] optim "alog-likelihood
	function")
Message-ID: <BAY22-F16tDQGiKAe2h00002c14@hotmail.com>


ok. You just simulate a 200 by 3 matrix z, all positive integers. The first 
column is i, the second column is j, and the third column is in fact the 
frequency of (i,j) combination, you can set the third column to be 1 for 
simplification.  Notice that i<j, and k=max of the second column. theta is a 
k dimension vector I want to maximize over.

ll <- function(theta)
   {t<-0
    for (ii in 1:k)
       {t<-t+exp(theta[ii])}
    lll<-0
    x00<-1/(1+t)
    x0<-x00*exp(theta)
for (m in 1:200)
    {i<-z[m,1]
     j<-z[m,2]
     a<-z[m,3]
     l<-i:(k-j+i)
     s<-rep(0,k)
     s[l]<-choose(j,i)*choose((k-j),(l-i))/choose(k,l) # we only define some
of s to be non-zero, since dim(l) might be smaller than dim(s)
     ss<-sum(s*x0)  # ss is a weighted sum of x0
      lll<-lll+a*log(ss)
     }
-lll
# the negative sign is to find the maximum of the log-likelihood function. 
It can be omitted if we use the finscale option in optim.
}

Then I need to optim(b0,ll,hessian=T), where b0 is k dimension starting 
value.

I have tried to use eval() and modify my function, it seems to be able to 
remove the m loop, however, optim() can not recognize it. So my main concern 
is to avoid the loop and optim() can works for my function. Thanks.

Regards,

Zhen



From jharris at hss.caltech.edu  Thu Sep 30 09:33:30 2004
From: jharris at hss.caltech.edu (Jonathan Harris)
Date: Thu, 30 Sep 2004 03:33:30 -0400
Subject: [R] Retrieving objects from functions...
Message-ID: <06AD4D91-12B3-11D9-9BF4-000D93C5257A@hss.caltech.edu>

I've written a program that involves a loop that creates a matrix. I'd 
like to be able to manipulate that matrix on my R desktop, but after I 
run the function, that matrix does not appear when I type ls(). How can 
I make that matrix become an object that I can manipulate?

Thanks!



From christoph.lehmann at gmx.ch  Thu Sep 30 09:33:16 2004
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Thu, 30 Sep 2004 09:33:16 +0200
Subject: [R] biplot.princomp with loadings only
Message-ID: <415BB6BC.6070307@gmx.ch>

Hi

is there a way to plot only the loadings in a biplot (with the nice 
arrows), and to skip the scores?

thanks
christoph



From Kevin.Wang at maths.anu.edu.au  Thu Sep 30 09:59:40 2004
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Thu, 30 Sep 2004 17:59:40 +1000 (EST)
Subject: [R] Retrieving objects from functions...
In-Reply-To: <06AD4D91-12B3-11D9-9BF4-000D93C5257A@hss.caltech.edu>
References: <06AD4D91-12B3-11D9-9BF4-000D93C5257A@hss.caltech.edu>
Message-ID: <Pine.GSO.4.58.0409301758020.18765@yin>

Hi,

On Thu, 30 Sep 2004, Jonathan Harris wrote:

> I've written a program that involves a loop that creates a matrix. I'd
> like to be able to manipulate that matrix on my R desktop, but after I
> run the function, that matrix does not appear when I type ls(). How can
> I make that matrix become an object that I can manipulate?

If I understand you right, you want something like:
  foo <- function() {
     goo <- matrix(1:10, nrow = 5, ncol = 2)
  }
then be able to call goo after running foo()?  If this is what you want,
then you need to do something like:
  foo <- function() {
     goo <<- matrix(1:10, nrow = 5, ncol = 2)
  }
to force goo to become a global variable, instead of a local variable to
foo().

HTH,

Kevin

--------------------------------
Ko-Kang Kevin Wang
PhD Student
Centre for Mathematics and its Applications
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 0200
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From ggrothendieck at myway.com  Thu Sep 30 10:08:07 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 30 Sep 2004 08:08:07 +0000 (UTC)
Subject: [R] Retrieving objects from functions...
References: <06AD4D91-12B3-11D9-9BF4-000D93C5257A@hss.caltech.edu>
Message-ID: <loom.20040930T100236-629@post.gmane.org>

Jonathan Harris <jharris <at> hss.caltech.edu> writes:


: I've written a program that involves a loop that creates a matrix. I'd 
: like to be able to manipulate that matrix on my R desktop, but after I 
: run the function, that matrix does not appear when I type ls(). How can 
: I make that matrix become an object that I can manipulate?

Just return the matrix as the value of your function.  If you are already
returning something else as the value of the function return a list with
that value and the matrix as the two components.

Check out the builtin eigen function is an example of this as it returns 
both eigenvalues and eigenvectors.  

The aforementioned is probably the best strategy but if you must then
you could alternately assign the matrix into the parent or global environment
from within your function using assign:

assign("mat", mat, parent.frame())  
assign("mat", mat, .GlobalEnv)



From ligges at statistik.uni-dortmund.de  Thu Sep 30 10:10:59 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 30 Sep 2004 10:10:59 +0200
Subject: [R] Retrieving objects from functions...
In-Reply-To: <06AD4D91-12B3-11D9-9BF4-000D93C5257A@hss.caltech.edu>
References: <06AD4D91-12B3-11D9-9BF4-000D93C5257A@hss.caltech.edu>
Message-ID: <415BBF93.3040803@statistik.uni-dortmund.de>

Jonathan Harris wrote:

> I've written a program that involves a loop that creates a matrix. I'd 
> like to be able to manipulate that matrix on my R desktop, but after I 
> run the function, that matrix does not appear when I type ls(). How can 
> I make that matrix become an object that I can manipulate?

Return it from the function and assign it outside:

foo <- function(anything){
   TheMatrix <- fun(anything)
   return(TheMatrix)
}

result <- foo(something)

Now, you have the resulting matrix assigned to an object called "result".


Please read "An Introduction to R"!

Uwe Ligges


> Thanks!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu Sep 30 10:12:42 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 30 Sep 2004 10:12:42 +0200
Subject: [R] Retrieving objects from functions...
In-Reply-To: <Pine.GSO.4.58.0409301758020.18765@yin>
References: <06AD4D91-12B3-11D9-9BF4-000D93C5257A@hss.caltech.edu>
	<Pine.GSO.4.58.0409301758020.18765@yin>
Message-ID: <415BBFFA.2000506@statistik.uni-dortmund.de>

Kevin Wang wrote:

> Hi,
> 
> On Thu, 30 Sep 2004, Jonathan Harris wrote:
> 
> 
>>I've written a program that involves a loop that creates a matrix. I'd
>>like to be able to manipulate that matrix on my R desktop, but after I
>>run the function, that matrix does not appear when I type ls(). How can
>>I make that matrix become an object that I can manipulate?
> 
> 
> If I understand you right, you want something like:
>   foo <- function() {
>      goo <- matrix(1:10, nrow = 5, ncol = 2)
>   }
> then be able to call goo after running foo()?  If this is what you want,
> then you need to do something like:
>   foo <- function() {
>      goo <<- matrix(1:10, nrow = 5, ncol = 2)

No, you don't want to do it that way, but you want to return(), in 
almost all cases I can imagine ...

Uwe


>   }
> to force goo to become a global variable, instead of a local variable to
> foo().
> 
> HTH,
> 
> Kevin
> 
> --------------------------------
> Ko-Kang Kevin Wang
> PhD Student
> Centre for Mathematics and its Applications
> Building 27, Room 1004
> Mathematical Sciences Institute (MSI)
> Australian National University
> Canberra, ACT 0200
> Australia
> 
> Homepage: http://wwwmaths.anu.edu.au/~wangk/
> Ph (W): +61-2-6125-2431
> Ph (H): +61-2-6125-7407
> Ph (M): +61-40-451-8301
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From salvati at ds.unifi.it  Thu Sep 30 11:40:24 2004
From: salvati at ds.unifi.it (salvati nicola)
Date: Thu, 30 Sep 2004 10:40:24 +0100
Subject: [R] Matrix
Message-ID: <006a01c4a6d1$85beb4a0$8003a8c0@stat.firenze>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040930/69e14879/attachment.pl

From pbrouilly at gphy.campus.univ-poitiers.fr  Thu Sep 30 10:39:35 2004
From: pbrouilly at gphy.campus.univ-poitiers.fr (pbrouilly@gphy.campus.univ-poitiers.fr)
Date: Thu, 30 Sep 2004 10:39:35 +0200
Subject: [R] Interface between R and Perl
Message-ID: <1096533575.415bc64748635@gphy.campus.univ-poitiers.fr>

Hi,

I have made a GUI in PerlTk and I would use R within perl.
I actually try to install RSPerl but I have some problems during the compilation

In order to call R from perl I use actually an other system based on the OPEN
command in perl.
It works fine but when I tried to call the fonction plot() of R from perl the
plot do not appears and a file named plot.ps is generated.
Unfortunalelly, my plot is dynamic (I also use the identify() command) so I
can't integrate this plot as an jpeg image for example.

My question is :
Is there a solution to call the plot() and identify() R commands from perl in
order to have a dynamic plot ??
can RSPerl do this or not ??
If it can I will spend more time to install it.... but it looks hard

Thank you very much and excuse me for my english :-)



From ozric at web.de  Thu Sep 30 11:09:20 2004
From: ozric at web.de (Christian Schulz)
Date: Thu, 30 Sep 2004 11:09:20 +0200
Subject: [R] optim "a log-likelihood function"
In-Reply-To: <415AF3D9.4080803@pdf.com>
References: <200409291911.17378.ozric@web.de> <415AF3D9.4080803@pdf.com>
Message-ID: <200409301109.21254.ozric@web.de>

dear optim experts,

optim(c(1,1),LL,control=list(fnscale=-1),trans=trans,times=times)

Error in optim(c(1, 1), LL, control = list(fnscale = -1), trans = trans,  : 
	Function cannot be evaluated at initial parameters

Finally  i would constraint r and alpha > than a small positive number?

optim(c(1,1),LL,lower=c(0.0001,0.001),upper=Inf,method="L-BFGS-B",control=list(fnscale=-1),trans=trans,times=times)
Error in optim(c(1, 1), LL, lower = c(0.001, 0.001), upper = Inf, method = 
"L-BFGS-B",  : 
	L-BFGS-B needs finite values of fn

where are my mistakes?

Many thanks, christian

########## The data and function

dm <- subset(dm09,select=c(ID,TRANS,TIMES))

trans <- dm$TRANS
> length(trans)
[1] 269732
times <- dm$TIMES
> length(times)
[1] 269732

LL <- function(x,trans,times){
r <- x[1]
alpha <- x[2]
l0 <- 
exp(lgamma(r+trans)-lgamma(r))/gamma(trans+1)*(alpha/(alpha+times))**r*(times/(alpha+times))**trans
l <- log(l0)
sum(l)
}



Am Mittwoch, 29. September 2004 19:41 schrieb Sundar Dorai-Raj:
> Christian Schulz wrote:
> > Hello,
> >
> > i know that i have to use optim, but i'm confused how its
> > possible  maximize  the sum over all l[i] and get the optimized
> > max(LL), r  and alpha?
> >
> > LL <- function(trans,time){
> >    for(i in 1:length(trans){
> >      l[i] <- log(lgamma(r+trans[i] -
> > gamma(r+1)*(alpha/alpha+t[i]))**r)*(t[i]/alpha+t[i]))**trans[i]
> > }
> > return(sum(l))
> >    }
> >
> > i'm confused how i have to set r and alpha
> > and i found no related help in archives?
> >
> > ...in Excel it works with solver but only for ~65.000 rows :-)
> >
> > #This notation is 1 for trans  and 1  for time instead the Startvalues
> > for r and alpha?
>
> I'm not sure what the above statement means, so I may have
> misinterpretted what you are trying to accomplish.
>
> > optim(c(1,1),-LL)
> >
> > many thanks  for an easy example or hint
> > regards,christian
>
> Did you look at the first example in ?optim? There also numerous errors
> in LL: missing parans, time is not used, t is undefined in the function.
>
> LL <- function(x, trans, time) {
>    r <- x[1]
>    alpha <- x[2]
>    ...
>    sum(l)
> }
>
> optim(c(1, 1), LL, control = list(fnscale = -1),
>        trans = trans, time = time)
>
> Some style issues:
> 1. Break up lines that run too long, especially if you expect others to
> read your code.
> 2. You don't need an explicit "return" at the end of a function.
> 3. You should remove the "for" loop in LL and vectorise "l", which
> should be easy.
>
> Hope this is helpful,
>
> --sundar
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From arv at ono.com  Thu Sep 30 11:40:48 2004
From: arv at ono.com (arv@ono.com)
Date: Thu, 30 Sep 2004 11:40:48 +0200
Subject: [R] Can't load rgl library
In-Reply-To: <1096533575.415bc64748635@gphy.campus.univ-poitiers.fr>
Message-ID: <4158BE6B00001823@mta01.ono.com>

Hi,

I've installed rgl package through R CMD INSTALL on a Debian-Sarge machine
(PIV) without any compiling error (see attached file), but when trying to
load this package within R (and also Rcmdr library) I get:

> library(rgl)
RGL: GLX extension missing on server
Error in firstlib(which.lib.loc, package) :
error rgl_init
error in library(rgl) : .First.lib failed
Segmentation fault

Same failure problem if I use the apt option (apt-get install r-cran-gl).
I've searched through the R mail archives but couldn't find or understand
the answer for this problem.

Thanks in advance!

Antonio Rodr?guez

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: rgl_rcmdr_compilation.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040930/c54fd6ca/rgl_rcmdr_compilation.txt

From ligges at statistik.uni-dortmund.de  Thu Sep 30 11:43:24 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 30 Sep 2004 11:43:24 +0200
Subject: [R] Matrix
In-Reply-To: <006a01c4a6d1$85beb4a0$8003a8c0@stat.firenze>
References: <006a01c4a6d1$85beb4a0$8003a8c0@stat.firenze>
Message-ID: <415BD53C.8020304@statistik.uni-dortmund.de>

salvati nicola wrote:

> I have a matrix 2900X2900 and I have to solve it. But R says that it can't allocate 67899kb.
> How can I do?

a) Clean up your workspace before trying to work on the matrix
b) Is this an outdated R version on Windows? Then (i) please upgrade and 
(ii) please read the R for Windows FAQs and ?Memory.
c) Buy more memory, if you have less than 512MB. 512 MB suffices for me 
(in a clean workspace!) in ~5 min. using Rblas.dll linked against ATLAS. 
You probably want to have ~1GB of memory for serious other calculations 
with those matrices.

Uwe Ligges



> Appreciate your kindly help! 
> Salvati Nicola
> Dipartimento di Statistica "G.Parenti"
> salvati at ds.unifi.it
> tel. 055.4237.224
> fax 055.4223560
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Thu Sep 30 12:00:51 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 30 Sep 2004 06:00:51 -0400
Subject: [R] Can't load rgl library
In-Reply-To: <4158BE6B00001823@mta01.ono.com>
References: <1096533575.415bc64748635@gphy.campus.univ-poitiers.fr>
	<4158BE6B00001823@mta01.ono.com>
Message-ID: <f2mnl0pautcae4v196n5c8shlnau8strqp@4ax.com>

On Thu, 30 Sep 2004 11:40:48 +0200, arv at ono.com wrote:

>Hi,
>
>I've installed rgl package through R CMD INSTALL on a Debian-Sarge machine
>(PIV) without any compiling error (see attached file), but when trying to
>load this package within R (and also Rcmdr library) I get:
>
>> library(rgl)
>RGL: GLX extension missing on server
>Error in firstlib(which.lib.loc, package) :
>error rgl_init
>error in library(rgl) : .First.lib failed
>Segmentation fault

Problems about packages should be sent to the maintainer of the
package, in this case Daniel Adler <dadler at uni-goettingen.de>.

But it does sound as though you don't have OpenGL or Mesa installed on
your machine.

Duncan Murdoch



From sdavis2 at mail.nih.gov  Thu Sep 30 12:06:35 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 30 Sep 2004 06:06:35 -0400
Subject: [R] Interface between R and Perl
In-Reply-To: <1096533575.415bc64748635@gphy.campus.univ-poitiers.fr>
References: <1096533575.415bc64748635@gphy.campus.univ-poitiers.fr>
Message-ID: <69AE8318-12C8-11D9-B695-000A95D7BA10@mail.nih.gov>

I don't think RSPerl can do this  from within perl, but others would 
know better than I.  Have you considered using tcltk for R?  You could 
recreate the GUI there, if the GUI is that is the use of perl in your 
application.

Sean

On Sep 30, 2004, at 4:39 AM, pbrouilly at gphy.campus.univ-poitiers.fr 
wrote:

> Hi,
>
> I have made a GUI in PerlTk and I would use R within perl.
> I actually try to install RSPerl but I have some problems during the 
> compilation
>
> In order to call R from perl I use actually an other system based on 
> the OPEN
> command in perl.
> It works fine but when I tried to call the fonction plot() of R from 
> perl the
> plot do not appears and a file named plot.ps is generated.
> Unfortunalelly, my plot is dynamic (I also use the identify() command) 
> so I
> can't integrate this plot as an jpeg image for example.
>
> My question is :
> Is there a solution to call the plot() and identify() R commands from 
> perl in
> order to have a dynamic plot ??
> can RSPerl do this or not ??
> If it can I will spend more time to install it.... but it looks hard
>
> Thank you very much and excuse me for my english :-)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From rvalliant at survey.umd.edu  Thu Sep 30 12:06:50 2004
From: rvalliant at survey.umd.edu (Richard Valliant)
Date: Thu, 30 Sep 2004 06:06:50 -0400
Subject: [R] Re: R-help Digest, Vol 19, Issue 30
Message-ID: <s15ba290.092@SURVEYGWIA.UMD.EDU>

I will be out of the office 9/30/04 - 10/4/04. For immediate help,
please call the JPSM main number, 301-314-7911.



From nusbj at hotmail.com  Thu Sep 30 12:10:52 2004
From: nusbj at hotmail.com (Zhen Pang)
Date: Thu, 30 Sep 2004 18:10:52 +0800
Subject: Vectorising and loop (was Re: [R] optim "alog-likelihoodfunction")
Message-ID: <BAY22-F2VfdY6hlHK9100012189@hotmail.com>

Mr. Grothendieck does suggest me to paste the data here. I just show a small 
one here. I must metion that I made a mistake in my former email. The first 
column should be j and is greater than the second column. I have corrected 
ll.

z is the matrix below

2 1 3
3 1 1
3 3 1
5 2 4

k<-max(z[,1])
ll <- function(theta)
  {t<-0
   for (ii in 1:k)
      {t<-t+exp(theta[ii])}
   lll<-0
   x00<-1/(1+t)
   x0<-x00*exp(theta)
for (m in 1:length(z[,1]))
   {j<-z[m,1]
    i<-z[m,2]
    a<-z[m,3]
    l<-i:(k-j+i)
    s<-rep(0,k)
    s[l]<-choose(j,i)*choose((k-j),(l-i))/choose(k,l)
# we only define some of s to be non-zero, since dim(l) might be smaller 
than dim(s)
    ss<-sum(s*x0)  # ss is a weighted sum of x0
     lll<-lll+a*log(ss)
    }
-lll
# the negative sign is to find the maximum of the log-likelihood function. 
It can be omitted if we #use the finscale option in optim.
}



Then I need to optim(b0,ll,hessian=T),
where b0<-c(0.8331934, 20.8009068, -7.0893623,  1.2109221, 18.7213273).

optim(b0,ll,hessian=T)
$par
[1]  0.8331934 20.8009068 -7.0893623  1.2109221 18.7213273

$value
[1] 5.182791

$counts
function gradient
      52       NA

$convergence
[1] 0

$message
NULL

$hessian
              [,1]          [,2]          [,3]          [,4]          [,5]
[1,]  1.065814e-08 -9.325873e-09  0.000000e+00 -3.330669e-10 -2.109424e-09
[2,] -9.325873e-09  8.887936e-01 -3.330669e-10 -1.620926e-08 -8.887936e-01
[3,]  0.000000e+00 -3.330669e-10 -6.661338e-10  0.000000e+00  0.000000e+00
[4,] -3.330669e-10 -1.620926e-08  0.000000e+00  7.549517e-09  7.105427e-09
[5,] -2.109424e-09 -8.887936e-01  0.000000e+00  7.105427e-09  8.887936e-01


I have tried to use eval() and modify my function, it seems to be able to 
remove the m loop, however, optim() can not recognize it. So my main concern 
is to avoid the loop and optim() can works for my function. Thanks.



From arv at ono.com  Thu Sep 30 12:41:45 2004
From: arv at ono.com (arv@ono.com)
Date: Thu, 30 Sep 2004 12:41:45 +0200
Subject: Asunto: Re: [R] Can't load rgl library
In-Reply-To: <f2mnl0pautcae4v196n5c8shlnau8strqp@4ax.com>
Message-ID: <4158BE6B00001910@mta01.ono.com>

Hi,

Yes I have installed xlibmesa-gl and xlibmesa-glu. Anyway I'll follow your
advice and write to the developpers

cheers,

Antonio


>-- Mensaje original --
>From: Duncan Murdoch <murdoch at stats.uwo.ca>
>To: arv at ono.com
>Cc: r-help at stat.math.ethz.ch, Daniel Adler <dadler at uni-goettingen.de>
>Subject: Re: [R] Can't load rgl library
>Date: Thu, 30 Sep 2004 06:00:51 -0400
>
>
>On Thu, 30 Sep 2004 11:40:48 +0200, arv at ono.com wrote:
>
>>Hi,
>>
>>I've installed rgl package through R CMD INSTALL on a Debian-Sarge machine
>>(PIV) without any compiling error (see attached file), but when trying
to
>>load this package within R (and also Rcmdr library) I get:
>>
>>> library(rgl)
>>RGL: GLX extension missing on server
>>Error in firstlib(which.lib.loc, package) :
>>error rgl_init
>>error in library(rgl) : .First.lib failed
>>Segmentation fault
>
>Problems about packages should be sent to the maintainer of the
>package, in this case Daniel Adler <dadler at uni-goettingen.de>.
>
>But it does sound as though you don't have OpenGL or Mesa installed on
>your machine.
>
>Duncan Murdoch



From john.gavin at ubs.com  Thu Sep 30 12:43:30 2004
From: john.gavin at ubs.com (john.gavin@ubs.com)
Date: Thu, 30 Sep 2004 11:43:30 +0100
Subject: [R] defining a template for functions via do.call and substitute.
Message-ID: <012821F286ED1D4ABDC72F9E1DD63D0C041EA9CA@NLDNC003PEX1.ubsgs.ubsgroup.net>

Hi,

Many thanks for the responses which solved my problem.

Fyi, my actual application is

copulaClayton <- function(u, v, alpha) 
  (u^-alpha + v^-alpha - 1)^(-1/alpha)
g <- function(){}
body(g) <- do.call("substitute", list(body(copulaClayton), 
  list(u = as.name("w"), v = quote(pnorm(var - qnorm(w))))))
formals(g) <- alist(w=, var=, alpha=)
g

and the substitutions seem to be working fine.

Thanks to 
Liaw, Andy [andy_liaw at merck.com]
Dimitris Rizopoulos [dimitris.rizopoulos at med.kuleuven.ac.be]
Bert Gunter [gunter.berton at gene.com] and
Thomas Lumley [tlumley at u.washington.edu],
Gabor Grothendieck <ggrothendieck at myway.com>

Regards,

John.

-----Original Message-----
From: Gavin, John 
Sent: 29 September 2004 12:17
To: 'r-help at stat.math.ethz.ch'
Subject: defining a template for functions via do.call and substitute.

Hi,

Given a function

  fun <- function(a, b) a + b

how do I generate the function 'function(x, y) x + y'?

Working from the help files and Bill Venables' R-news article (June 2002),
I have tried various permutations with substitute without success. 
e.g.
  do.call("substitute", list(fun, list(a = as.name("x"), b = as.name("y"))))

Regards,

John.

John Gavin <john.gavin at ubs.com>,
Quantitative Risk Models and Statistics,
UBS Investment Bank, 6th floor, 
100 Liverpool St., London EC2M 2RH, UK.
Phone +44 (0) 207 567 4289
Fax   +44 (0) 207 568 5352

Visit our website at http://www.ubs.com

This message contains confidential information and is intend...{{dropped}}



From bitwrit at ozemail.com.au  Thu Sep 30 13:11:45 2004
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Thu, 30 Sep 2004 21:11:45 +1000
Subject: [R] Warning: number of items to replace is not a multiple of
	replacement length
In-Reply-To: <200409291503.24845.ferri.leberl@gmx.at>
References: <200409291503.24845.ferri.leberl@gmx.at>
Message-ID: <20040930110510.WRCJ25882.smta08.mail.ozemail.net@there>

Mag. Ferri Leberl wrote:
> What does this warning mean precisely?
> Is there any reason to care about it?
> Can I Avoid it by another way of programming?

As you have already gotten most of your questions answered, here is a 
possible answer to the last. You may want to care about it, but not 
necessarily. I have had to use the recycling capability of R without knowing 
whether the length of the result would be a multiple of that of the source 
vector. Say I want to label a vector of daily observations, but I do not know 
which day the observations start or how many there are:

label.weekdays<-function(ndays,start=1) {
 daynames<-rep(c("Sun","Mon","Tue","Wed","Thu","Fri","Sat"),ndays/7+1)
 return(daynames[start:(start+ndays-1)])
}

By creating a vector that is intentionally too long, then truncating it on 
one or both ends, I can recycle the source vector and avoid the warning.

Jim



From gavin.simpson at ucl.ac.uk  Thu Sep 30 14:36:47 2004
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 30 Sep 2004 13:36:47 +0100
Subject: [R] biplot.princomp with loadings only
In-Reply-To: <415BB6BC.6070307@gmx.ch>
References: <415BB6BC.6070307@gmx.ch>
Message-ID: <415BFDDF.2010604@ucl.ac.uk>

Christoph Lehmann wrote:
> Hi
> 
> is there a way to plot only the loadings in a biplot (with the nice 
> arrows), and to skip the scores?
> 
> thanks
> christoph
> 

Hi Christoph,

Three options I can think of:

1) Hack the source for biplot.princomp and biplot.default (which does 
the plotting) by commenting out the lines that plot the scores or 
altering the code to plot only the scores. You want to plot just y[,1] 
against y[,2] and ignore the x[,1] and x[,2] bits in biplot.default.

2) Write your own function based on biplot.default and biplot.princomp

3) If you don't like hacking/coding then see package vegan and the 
function scores, which has a method for class princomp, which can 
extract the loadings and the scores (in princomp terms, vegan calls them 
something else). Function ordiplot (also in vegan) provides direct 
plotting of various ordination results including objects from princomp.

All the best,

Gav

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From V.Khamenia at biovision-discovery.de  Thu Sep 30 14:47:19 2004
From: V.Khamenia at biovision-discovery.de (Khamenia, Valery)
Date: Thu, 30 Sep 2004 14:47:19 +0200
Subject: [R] How to save graphics in portable way in batch mode?
Message-ID: <D15343265276D31197BC00A024A6C110C793B7@EXS_BDC>

Hi all,

What is the right portable way to save graphics 
in batch mode?

Remarks:

  1. Problem is STFWed and RTFMed. In particular a short note 
     about png() is found in R-FAQ. In fact, there were stated 
     that png() is not reliable under Linux in batch mode.

  2. savePlot under windows is quite convenient, but 
     not supplied under Linux.

  3. pdf() + postscript() < savePlot()
     Indeed, savePlot does support much more image formats 
     and is flexible in changing type of output via its
     argument.

  4. The scheme 

     "postscript(); plot(); dev.off();" 

     makes R-scripts not really nice. Indeed, if one's script 
     had about 15 plot calls then in order to save graphics 
     one need to add 15 times the postscript() in prior of 
     plot() call and then 15 times the dev.off() as epilogue 
     to plot() call.

  5. Hm, one could create function similar to Sweave() 
     (see R-1.9.1\src\library\utils\R\Sweave.R) and 
     benefit from automatic name generation and saving.
     But it is quite unnatural, isn't it?
      
so, it would be nice to know what is the "right way".

P.S. BTW, will be there any specific changes in R-2.x?

Thank you a priori for your comments,
Valery.



From murdoch at stats.uwo.ca  Thu Sep 30 14:51:16 2004
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 30 Sep 2004 08:51:16 -0400
Subject: [R] How to print landscape from script in Windows:
	dev.print(win.print, printer="local printer name",
	...) does not accept horizontal=TRUE 
In-Reply-To: <12AE52872B5C5348BE5CF47C707FF53A3271FD@rhosvr02.rhotrading.com>
References: <12AE52872B5C5348BE5CF47C707FF53A3271FD@rhosvr02.rhotrading.com>
Message-ID: <ruvnl0hjnbahvodnab9hcqrqnd9o6e96gm@4ax.com>

On Wed, 29 Sep 2004 16:28:09 -0500, <davidr at rhotrading.com> wrote :

>This is a windows-specific question.
>
> 
>
>After generating a plot, I can print from scripts or the command line
>with 
>
> 
>
>> dev.print(win.print,printer="local windows printer name")
>
> 
>
>I would like to print in landscape mode. From the menus, I can
>accomplish this by changing the properties of the printer before
>clicking "print".

I think the easiest way to do this is to create a new printer which
defaults to landscape, and then do

 dev.print(win.print,printer="local landscape printer name")

I think it's unlikely we'll add this to win.print(); there are just
too many options in Windows printer drivers, and it's fairly easy to
set them using the Windows dialogs.

Duncan Murdoch



From ccleland at optonline.net  Thu Sep 30 15:06:03 2004
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 30 Sep 2004 09:06:03 -0400
Subject: [R] How to save graphics in portable way in batch mode?
In-Reply-To: <D15343265276D31197BC00A024A6C110C793B7@EXS_BDC>
References: <D15343265276D31197BC00A024A6C110C793B7@EXS_BDC>
Message-ID: <415C04BB.7080305@optonline.net>

   Have you considered the following approach to creating a single PDF 
file with multiple pages of plots?

pdf(file="c:\\myfigs.pdf")
plot()
plot()
plot()
dev.off()

   Or if you want a file for each figure with names generated 
automatically, try something like:

pdf(onefile=FALSE)
plot()
plot()
plot()
dev.off()

   It seems like as long as the PDF device is going to have the same 
settings (e.g., width, height, and pointsize) across plots, there is no 
need to call pdf() and dev.off() multiple times within a script.

hope this helps,

Chuck Cleland

Khamenia, Valery wrote:
> Hi all,
> 
> What is the right portable way to save graphics 
> in batch mode?
> 
> Remarks:
> 
>   1. Problem is STFWed and RTFMed. In particular a short note 
>      about png() is found in R-FAQ. In fact, there were stated 
>      that png() is not reliable under Linux in batch mode.
> 
>   2. savePlot under windows is quite convenient, but 
>      not supplied under Linux.
> 
>   3. pdf() + postscript() < savePlot()
>      Indeed, savePlot does support much more image formats 
>      and is flexible in changing type of output via its
>      argument.
> 
>   4. The scheme 
> 
>      "postscript(); plot(); dev.off();" 
> 
>      makes R-scripts not really nice. Indeed, if one's script 
>      had about 15 plot calls then in order to save graphics 
>      one need to add 15 times the postscript() in prior of 
>      plot() call and then 15 times the dev.off() as epilogue 
>      to plot() call.
> 
>   5. Hm, one could create function similar to Sweave() 
>      (see R-1.9.1\src\library\utils\R\Sweave.R) and 
>      benefit from automatic name generation and saving.
>      But it is quite unnatural, isn't it?
>       
> so, it would be nice to know what is the "right way".
> 
> P.S. BTW, will be there any specific changes in R-2.x?
> 
> Thank you a priori for your comments,
> Valery.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From bates at stat.wisc.edu  Thu Sep 30 15:07:15 2004
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 30 Sep 2004 08:07:15 -0500
Subject: [R] Matrix
In-Reply-To: <415BD53C.8020304@statistik.uni-dortmund.de>
References: <006a01c4a6d1$85beb4a0$8003a8c0@stat.firenze>
	<415BD53C.8020304@statistik.uni-dortmund.de>
Message-ID: <415C0503.4090804@stat.wisc.edu>

Uwe Ligges wrote:
> salvati nicola wrote:
> 
>> I have a matrix 2900X2900 and I have to solve it. But R says that it 
>> can't allocate 67899kb.
>> How can I do?
> 
> 
> a) Clean up your workspace before trying to work on the matrix
> b) Is this an outdated R version on Windows? Then (i) please upgrade and 
> (ii) please read the R for Windows FAQs and ?Memory.
> c) Buy more memory, if you have less than 512MB. 512 MB suffices for me 
> (in a clean workspace!) in ~5 min. using Rblas.dll linked against ATLAS. 
> You probably want to have ~1GB of memory for serious other calculations 
> with those matrices.
> 
> Uwe Ligges

5 Min?

On a modest desktop system (Athlon XP 2500+, approx 1.8 GHz) it took 
about 20 seconds for the inversion and about 8 seconds for the LU 
decomposition.  This is using the Matrix package.

 > mm <- Matrix(rnorm(2900*2900), ncol = 2900)
 > object.size(mm)
[1] 67280636
 > system.time(rcond(mm))
[1] 7.73 0.10 7.96 0.00 0.00
 > object.size(mm)
[1] 134573052
 > system.time(minv <- solve(mm))
[1] 19.93  0.10 20.04  0.00  0.00
 > rcond(mm)
[1] 2.466351e-07

The initial call to rcond calculates and stores the LU decomposition. 
That is why the size of the object approximately doubles.

I get similar results without the matrix package except that the 
decomposition must be recomputed for each such operation on the matrix.

 > m1 <- matrix(rnorm(2900*2900), ncol = 2900)
 > system.time(minv1 <- solve(m1))
[1] 30.08  0.86 32.32  0.00  0.00



From p.dalgaard at biostat.ku.dk  Thu Sep 30 15:13:36 2004
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 30 Sep 2004 15:13:36 +0200
Subject: [R] How to save graphics in portable way in batch mode?
In-Reply-To: <D15343265276D31197BC00A024A6C110C793B7@EXS_BDC>
References: <D15343265276D31197BC00A024A6C110C793B7@EXS_BDC>
Message-ID: <x2r7oj2933.fsf@biostat.ku.dk>

"Khamenia, Valery" <V.Khamenia at biovision-discovery.de> writes:

> Hi all,
> 
> What is the right portable way to save graphics 
> in batch mode?
> 
> Remarks:
> 
>   1. Problem is STFWed and RTFMed. In particular a short note 
>      about png() is found in R-FAQ. In fact, there were stated 
>      that png() is not reliable under Linux in batch mode.
> 
>   2. savePlot under windows is quite convenient, but 
>      not supplied under Linux.
> 
>   3. pdf() + postscript() < savePlot()
>      Indeed, savePlot does support much more image formats 
>      and is flexible in changing type of output via its
>      argument.
> 
>   4. The scheme 
> 
>      "postscript(); plot(); dev.off();" 
> 
>      makes R-scripts not really nice. Indeed, if one's script 
>      had about 15 plot calls then in order to save graphics 
>      one need to add 15 times the postscript() in prior of 
>      plot() call and then 15 times the dev.off() as epilogue 
>      to plot() call.
> 
>   5. Hm, one could create function similar to Sweave() 
>      (see R-1.9.1\src\library\utils\R\Sweave.R) and 
>      benefit from automatic name generation and saving.
>      But it is quite unnatural, isn't it?
>       
> so, it would be nice to know what is the "right way".

Looks like you may have RTFM but didn't RTWFM (or even RTWHP). Check
out the "onefile" argument in postscript().


> P.S. BTW, will be there any specific changes in R-2.x?

The sources are available....

E.g. https://svn.r-project.org/R/trunk/NEWS

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907



From V.Khamenia at biovision-discovery.de  Thu Sep 30 15:26:53 2004
From: V.Khamenia at biovision-discovery.de (Khamenia, Valery)
Date: Thu, 30 Sep 2004 15:26:53 +0200
Subject: AW: [R] How to save graphics in portable way in batch mode?
Message-ID: <D15343265276D31197BC00A024A6C110C793B8@EXS_BDC>

> pdf(onefile=FALSE)
> plot()
> plot()
> plot()
> dev.off()

oh, nice hint. The following:

  pdf(file="aaa%02d.pdf", onefile=FALSE) 

is very close to compromise, thank you, Chunk!
--
Valery.



From ligges at statistik.uni-dortmund.de  Thu Sep 30 15:31:37 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 30 Sep 2004 15:31:37 +0200
Subject: [R] Matrix
In-Reply-To: <415C0503.4090804@stat.wisc.edu>
References: <006a01c4a6d1$85beb4a0$8003a8c0@stat.firenze>
	<415BD53C.8020304@statistik.uni-dortmund.de>
	<415C0503.4090804@stat.wisc.edu>
Message-ID: <415C0AB9.2010302@statistik.uni-dortmund.de>

Douglas Bates wrote:

> Uwe Ligges wrote:
> 
>> salvati nicola wrote:
>>
>>> I have a matrix 2900X2900 and I have to solve it. But R says that it 
>>> can't allocate 67899kb.
>>> How can I do?
>>
>>
>>
>> a) Clean up your workspace before trying to work on the matrix
>> b) Is this an outdated R version on Windows? Then (i) please upgrade 
>> and (ii) please read the R for Windows FAQs and ?Memory.
>> c) Buy more memory, if you have less than 512MB. 512 MB suffices for 
>> me (in a clean workspace!) in ~5 min. using Rblas.dll linked against 
>> ATLAS. You probably want to have ~1GB of memory for serious other 
>> calculations with those matrices.
>>
>> Uwe Ligges
> 
> 
> 5 Min?
> 
> On a modest desktop system (Athlon XP 2500+, approx 1.8 GHz) it took 
> about 20 seconds for the inversion and about 8 seconds for the LU 
> decomposition.  This is using the Matrix package.
> 
>  > mm <- Matrix(rnorm(2900*2900), ncol = 2900)
>  > object.size(mm)
> [1] 67280636
>  > system.time(rcond(mm))
> [1] 7.73 0.10 7.96 0.00 0.00
>  > object.size(mm)
> [1] 134573052
>  > system.time(minv <- solve(mm))
> [1] 19.93  0.10 20.04  0.00  0.00
>  > rcond(mm)
> [1] 2.466351e-07
> 
> The initial call to rcond calculates and stores the LU decomposition. 
> That is why the size of the object approximately doubles.
> 
> I get similar results without the matrix package except that the 
> decomposition must be recomputed for each such operation on the matrix.
> 
>  > m1 <- matrix(rnorm(2900*2900), ncol = 2900)
>  > system.time(minv1 <- solve(m1))
> [1] 30.08  0.86 32.32  0.00  0.00


I'm sorry, I only thought I had used the ATLAS optimized version (but it 
was the standard Rblas.dll), it really has

 > system.time(minv <- solve(mm))
[1] 31.69  1.82 34.14    NA    NA

(R-1.9.1, ATLAS, WinNT4.0, Athlon with real 1.67 GHz)

Uwe



From rxg218 at psu.edu  Thu Sep 30 15:57:53 2004
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Thu, 30 Sep 2004 09:57:53 -0400
Subject: [R] Rpy vs RSPython
Message-ID: <1096552672.8152.1.camel@blue.chem.psu.edu>

Hi, I'm planning to write some code in Python using R functions.
I'm aware of the two R<->Python packages - Rpy and RSPython.

Rpy seems easier to get up and running with, but does anybody have any
comments regarding which would be a better system to work with in the
long run?

Thanks,

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
I live in my own little world...
but it's OK, they like me there



From Jan.Kleinn at partnerre.com  Thu Sep 30 16:14:22 2004
From: Jan.Kleinn at partnerre.com (Jan.Kleinn@partnerre.com)
Date: Thu, 30 Sep 2004 16:14:22 +0200
Subject: [R] pointsize in png graphics
Message-ID: <OF46ABB7D4.86DF0E0C-ONC1256F1F.004D6A0C-C1256F1F.004E43F1@global.partnerre.net>

Dear all,

I'm trying to produce 2 png files, one consisting of an image plot and a
color-table (also an image plot) and the other one consisting of 4 image
plots and a color table. I'd like the color table to be exactly the same.
The way I proceded is the following:

for one plot and the color-table
png(file = png.file, width = 650, height = 800, pointsize = 16)
layout(matrix(c(1, 2), ncol = 2, nrow = 1, byrow = T),
       widths = c(6, 1), heights = 1)
par(mar = c(0.2, 0.2, 0.2, 0.2), mgp = c(2, 1, 0), las = 0)
...
dev.off()

for 4 plots and the color-table
png(file = png.file, width = 650, height = 800, pointsize = 16)
layout(matrix(c(1, 2, 5, 3, 4, 5), ncol = 3, nrow = 2, byrow = T),
       widths = c(3, 3, 1), heights = c(1, 1))
par(mar = c(0.2, 0.2, 0.2, 0.2), mgp = c(2, 1, 0), las = 0)
...
dev.off()

The only difference is the layout of the plot. The outcome though is
completely different. It seems that the definition of the size of one point
is different in the two plots as the graphics with 4 plots and color table
has smaller fonts and smaller margins. What do I have to do to be sure the
size of the fonts is the same in two different png graphcis of exactly the
same size when the pointsize is the same?

I'm working with Windows XP and tried both running the R script as a batch
job and running it within Emacs with ESS.

> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    9.1
year     2004
month    06
day      21
language R

Many thanks in advance and best regards, Jan:-)



From tlumley at u.washington.edu  Thu Sep 30 16:16:36 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 30 Sep 2004 07:16:36 -0700 (PDT)
Subject: [R] glm.fit and predict.glm: error ' no terms component'
In-Reply-To: <415B4CEF.5030201@gmx.ch>
References: <415AC0F5.9080009@gmx.ch>
	<Pine.A41.4.61.0409290746340.169788@homer11.u.washington.edu>
	<415B4CEF.5030201@gmx.ch>
Message-ID: <Pine.A41.4.61.0409300714170.195392@homer04.u.washington.edu>

On Thu, 30 Sep 2004, Christoph Lehmann wrote:

> many thanks I did it the following way, based on Thomas' suggestion

There was a reason why I didn't call the function predict.glm.fit: it 
isn't a method for predict. You will be calling it directly, rather than 
via predict as you should for a method.

 	-thomas

> predict.glm.fit<-function(glmfit, newmatrix){
>   newmatrix<-cbind(1,newmatrix)
>   coef <- rbind(1, as.matrix(glmfit$coef))
>   eta <- as.matrix(newmatrix) %*% as.matrix(coef)
>   exp(eta)/(1 + exp(eta))
> }
>
>
> cheers
>
> christoph
>
>
>
>
>
>
>
> Thomas Lumley wrote:
>> On Wed, 29 Sep 2004, Christoph Lehmann wrote:
>> 
>>> Hi
>>> 
>>> when I fit a glm by
>>> 
>>>     glm.fit(x,y,family = binomial())
>>>     and then try to use the object for prediction of newdata by:
>>> 
>>>     predict.glm(object, newdata)
>>> 
>>> I get the error:
>>> 
>>> Error in terms.default(object) : no terms component
>>> 
>>> I know I can use glm() and a formula, but for my case I prefer 
>>> glm.fit(x,y)...
>> 
>> 
>> Well, you can't use predict.glm that way.  As the function name suggests, 
>> it is a predict method for objects of class "glm", which in your case you 
>> do not have.
>> 
>> There are two reasons why it won't work.  For type="terms" the formula is 
>> needed to identify terms, and for any type of prediction the formula is 
>> needed to convert the data frame newdata into a model matrix.
>> 
>> You would need to write a function where the new data was a model matrix. 
>> If you only need point predictions then
>> 
>> predict_glm_fit<-function(glmfit, newmatrix, addintercept=TRUE){
>>    if (addintercept)
>>     newmatrix<-cbind(1,newmatrix)
>>    eta<-glmfit$coef %*% newmatrix
>>    family$linkinv(eta)
>> }
>> 
>> would work.
>> 
>>     -thomas
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>> 
>> 
>
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From nderby at u.washington.edu  Thu Sep 30 16:20:17 2004
From: nderby at u.washington.edu (Nathaniel B. Derby)
Date: Thu, 30 Sep 2004 07:20:17 -0700 (PDT)
Subject: [R] Using try()
Message-ID: <Pine.LNX.4.43.0409300720170.28111@hymn04.u.washington.edu>

Hello R people,

I am need some help using the try() function.  Currently I am running a loop which uses arima() for some values of p and q, which sometimes crashes.  When it crashes, I want the program to just ignore it and move on to the next values to loop through.  I currently have this, looping through a range of values for p and q:

lo = try( arima1 <- arima( y, order=c( p, 0, q ) )
if( !inherits( lo, "try-error" ) ){
      ... code here ...
      }

This works perfectly for my purposes, with one exception:  Everytime the program invokes try(), I have to press Esc in the R console for the program to continue.  How can I avoid this (so that I don't have to keep pushing Esc).

I tried reading the help file for tryCatch(), which showed a wide range of options to try (no pun intended), but this confused me.


Thanks,

Nate



From filippobiscarini at anafi.it  Thu Sep 30 16:34:47 2004
From: filippobiscarini at anafi.it (Filippo BISCARINI)
Date: Thu, 30 Sep 2004 16:34:47 +0200
Subject: [R] tcl/tk
Message-ID: <FJEIKCLHGHILBFFGLEKJOEBJCBAA.filippobiscarini@anafi.it>

Hi all,

I am already using R under Window and would like now to try and install it
under Unix; I read I need tcl/tk installed so I connected to
http://www.scriptics.com downloaded the file and extracted them to a
directory tcltk beside R. I configured (./configure) both packages (tcl and
tk) and compiled (make) them but I am not sure about how to proceed now:
should I launch the command make install? Should I edit the config.site of R
to specify some configuration variables? But how?
Does anybody know anything about it and have suggestions on how to go on and
properly install tcl/tk and subsequently R?

I should be able to complete the installation of R once I worked around this
tcl/tk hindrance.

Thank you very much,

Filippo Biscarini

     ****************************
     Filippo Biscarini,
     Research and Development
     ANAFI (Italian Holstein Association)
     Via Bergamo, 292
     26100, Cremona, Italy
     tel: +39.0372.474234
     *****************************



From Arne.Muller at aventis.com  Thu Sep 30 16:41:27 2004
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Thu, 30 Sep 2004 16:41:27 +0200
Subject: [R] Boxplot, space to axis
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADE01846337@crbsmxsusr04.pharma.aventis.com>

Hello,

I've crearted a boxplot with 84 boxes. So fat everything is as I expect, but there is quite some space between the 1st box and axis 2 and the last box and axis 4. Since 84 boxes get very slim anyway I'd like to discribute as much of the horizontal space over the x-axis.

Maybe I've forgotten about a graphics parameter?

	Thanks for your help,

	Arne



From ligges at statistik.uni-dortmund.de  Thu Sep 30 16:51:55 2004
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 30 Sep 2004 16:51:55 +0200
Subject: [R] tcl/tk
In-Reply-To: <FJEIKCLHGHILBFFGLEKJOEBJCBAA.filippobiscarini@anafi.it>
References: <FJEIKCLHGHILBFFGLEKJOEBJCBAA.filippobiscarini@anafi.it>
Message-ID: <415C1D8B.9020807@statistik.uni-dortmund.de>

Filippo BISCARINI wrote:

> Hi all,
> 
> I am already using R under Window and would like now to try and install it
> under Unix; I read I need tcl/tk installed so I connected to
> http://www.scriptics.com downloaded the file and extracted them to a
> directory tcltk beside R. I configured (./configure) both packages (tcl and
> tk) and compiled (make) them but I am not sure about how to proceed now:
> should I launch the command make install? Should I edit the config.site of R
> to specify some configuration variables? But how?

Yes, make install is sufficient on most systems.


> Does anybody know anything about it and have suggestions on how to go on and
> properly install tcl/tk and subsequently R?

./configure
make
make install

In the common case, R's configure detects the tcl/tk installation ...

Uwe Ligges



> I should be able to complete the installation of R once I worked around this
> tcl/tk hindrance.
> 
> Thank you very much,
> 
> Filippo Biscarini
> 
>      ****************************
>      Filippo Biscarini,
>      Research and Development
>      ANAFI (Italian Holstein Association)
>      Via Bergamo, 292
>      26100, Cremona, Italy
>      tel: +39.0372.474234
>      *****************************
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From kbartz at loyaltymatrix.com  Thu Sep 30 16:53:04 2004
From: kbartz at loyaltymatrix.com (Kevin Bartz)
Date: Thu, 30 Sep 2004 07:53:04 -0700
Subject: [R] pointsize in png graphics
In-Reply-To: <OF46ABB7D4.86DF0E0C-ONC1256F1F.004D6A0C-C1256F1F.004E43F1@global.partnerre.net>
References: <OF46ABB7D4.86DF0E0C-ONC1256F1F.004D6A0C-C1256F1F.004E43F1@global.partnerre.net>
Message-ID: <415C1DD0.8020701@loyaltymatrix.com>

Jan.Kleinn at partnerre.com wrote:
> Dear all,
> 
> I'm trying to produce 2 png files, one consisting of an image plot and a
> color-table (also an image plot) and the other one consisting of 4 image
> plots and a color table. I'd like the color table to be exactly the same.
> The way I proceded is the following:
> 
> for one plot and the color-table
> png(file = png.file, width = 650, height = 800, pointsize = 16)
> layout(matrix(c(1, 2), ncol = 2, nrow = 1, byrow = T),
>        widths = c(6, 1), heights = 1)
> par(mar = c(0.2, 0.2, 0.2, 0.2), mgp = c(2, 1, 0), las = 0)
> ...
> dev.off()
> 
> for 4 plots and the color-table
> png(file = png.file, width = 650, height = 800, pointsize = 16)
> layout(matrix(c(1, 2, 5, 3, 4, 5), ncol = 3, nrow = 2, byrow = T),
>        widths = c(3, 3, 1), heights = c(1, 1))
> par(mar = c(0.2, 0.2, 0.2, 0.2), mgp = c(2, 1, 0), las = 0)
> ...
> dev.off()
> 
> The only difference is the layout of the plot. The outcome though is
> completely different. It seems that the definition of the size of one point
> is different in the two plots as the graphics with 4 plots and color table
> has smaller fonts and smaller margins. What do I have to do to be sure the
> size of the fonts is the same in two different png graphcis of exactly the
> same size when the pointsize is the same?
> 
> I'm working with Windows XP and tried both running the R script as a batch
> job and running it within Emacs with ESS.
> 
> 
>>version
> 
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    9.1
> year     2004
> month    06
> day      21
> language R
> 
> Many thanks in advance and best regards, Jan:-)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

Hi Jan,

Generally, I've found it very undesirable to set pointsize when calling 
a graphics device. Instead, I set the cex parameter, either globally 
through "par" or for each individual plot. If you don't tweak the 
defaults, then cex effectively works in picas, so you can divide your 
desired point size by 12 to come up with the right value of cex. Why 
don't you give that a try and let me know how it turns out?

Also, are you sure that you managed to run that code as a batched 
script? png() is one of the graphics devices that doesn't work in batch. 
To get batched pngs, I typically have to use bitmap(type = "png16m", ...).

Kevin



From deepayan at stat.wisc.edu  Thu Sep 30 17:11:46 2004
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Thu, 30 Sep 2004 10:11:46 -0500
Subject: [R] Boxplot, space to axis
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE01846337@crbsmxsusr04.pharma.aventis.com>
References: <C80ECAFA2ACC1B45BE45D133ED660ADE01846337@crbsmxsusr04.pharma.aventis.com>
Message-ID: <200409301011.46218.deepayan@stat.wisc.edu>

On Thursday 30 September 2004 09:41, Arne.Muller at aventis.com wrote:
> Hello,
>
> I've crearted a boxplot with 84 boxes. So fat everything is as I
> expect, but there is quite some space between the 1st box and axis 2
> and the last box and axis 4. Since 84 boxes get very slim anyway I'd
> like to discribute as much of the horizontal space over the x-axis.
>
> Maybe I've forgotten about a graphics parameter?

Perhaps par(xaxs = "i") ?

Deepayan



From larsenmtl at comcast.net  Thu Sep 30 17:16:59 2004
From: larsenmtl at comcast.net (larsenmtl@comcast.net)
Date: Thu, 30 Sep 2004 15:16:59 +0000
Subject: [R] RSXML - Parsing XML Documents on Internet
Message-ID: <093020041516.25471.415C236A000B23D30000637F2200758942049B03020A9C9D0E04@comcast.net>

Professors Ripley and Lang,

Thanks.  Your fix was dead-on, setting the env var http_proxy solved my problem.

Mark


> Sorry, my flaky connection (I am on a slow dialup) broke this up: here's 
> the rest.
> 
> On Thu, 30 Sep 2004, Prof Brian Ripley wrote:
> 
> > On Wed, 29 Sep 2004 larsenmtl at comcast.net wrote:
> 
> [...]
> 
> > > Now I know that xmlTreeParse uses the libxml facilities for downloading and 
> > > parsing off the web.   Along with one of our network people, I did some 
> packet 
> > > sniffing and it looks like libxml doesn't go through our proxy server (it 
> tries 
> > > to directly connect to the above URL), which is the reason for the error.  
> Is 
> > > there anyway to force it through the proxy?  Am I missing some setting or 
> > > option?  If I download the xml file and parse it locally it works without 
> error.
> > > 
> > > Please Note that the URL is valid and I can open it in my browser.  Also 
> note 
> > > that I must start R with the --internet2 option so it'll use our proxy 
> server.  
> > 
> > That's your problem.  You *can* use proxies without --internet2 (see 
> > ?download.file) and the XML code uses the standard version of the code.
> 
> The first issue is that you have not configured R to use your proxy, so 
> please get that working.
> 
> Issue two is that you may need to get an older version of XML compiled 
> against an older libxml, as the current one has not been tested.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From Arne.Muller at aventis.com  Thu Sep 30 17:22:28 2004
From: Arne.Muller at aventis.com (Arne.Muller@aventis.com)
Date: Thu, 30 Sep 2004 17:22:28 +0200
Subject: [R] Boxplot, space to axis
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADE01846339@crbsmxsusr04.pharma.aventis.com>

Hello Deepayan,

thanks for your suggestion, xaxs='i' works, but it leaves no space at all. I though this may be configurable by a real value.

	kind regards,

	Arne

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Deepayan Sarkar
> Sent: 30 September 2004 17:12
> To: r-help at stat.math.ethz.ch
> Cc: Muller, Arne PH/FR
> Subject: Re: [R] Boxplot, space to axis
> 
> 
> On Thursday 30 September 2004 09:41, Arne.Muller at aventis.com wrote:
> > Hello,
> >
> > I've crearted a boxplot with 84 boxes. So fat everything is as I
> > expect, but there is quite some space between the 1st box and axis 2
> > and the last box and axis 4. Since 84 boxes get very slim anyway I'd
> > like to discribute as much of the horizontal space over the x-axis.
> >
> > Maybe I've forgotten about a graphics parameter?
> 
> Perhaps par(xaxs = "i") ?
> 
> Deepayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From davidhughjones at gmail.com  Thu Sep 30 17:41:52 2004
From: davidhughjones at gmail.com (David Hugh-Jones)
Date: Thu, 30 Sep 2004 16:41:52 +0100
Subject: [R] expand.model.frame gives "object not found"
Message-ID: <f5d84806040930084170c2e6e4@mail.gmail.com>

Hello,

I am a (relatively) experienced programmer, but new to R.

I have a problem using R 1.9.1. I have fit some data using glm(), from
within a function:

        formula = as.formula(paste(depvarname, "~", rhs), env=globalenv())
        return (glm(formula, family=binomial(link=logit)))

I have now come back to the formula and want to add some more
variables to it. So I do:

expand.model.frame(formulaname, ~ new_variable)

but I get the response

Error in eval(expr, envir, enclos) : Object "foreignaid.dummy" not found

where foreignaid.dummy is my dependent variable. However,
foreignaid.dummy is clearly visible in the global environment:

> ls(pat="foreignaid.dummy", envir=globalenv())
 [1] "foreignaid.dummy"
 ...

So why is my dependent variable lost?

I have read the earlier comments on the same topic, but they seem to
indicate that a previous bug was fixed. Am I missing the point about
scoping?

Any help much appreciated.

David Hugh-Jones
Essex University Govt Dept



From Emilie.Berthiaume at USherbrooke.ca  Thu Sep 30 18:05:53 2004
From: Emilie.Berthiaume at USherbrooke.ca (Emilie Berthiaume)
Date: Thu, 30 Sep 2004 12:05:53 -0400
Subject: [R] function by
Message-ID: <1096560353.415c2ee1c3b78@www.usherbrooke.ca>

Hi,

I'm just getting started with R and I'm having problems with some simple
operations: I want to get the the sum of the column "SStot" for each year using
the function by.  The data set is named "SS".  I've tried this:

by (SS, year, sum(SStot))

and it's not working.  Is it because there's a different number of rows for each
year?  How else can I do this?

--
Emilie Berthiaume
Graduate student
Biology Departement
Universit?? de Sherbrooke
2500 boul. de l'Universit??
Sherbrooke, Qu??bec
J1K 2R1 CANADA

T??l: 1-819-821-8000 poste 2059
Fax: 1-819-821-8049
Emilie.Berthiaume at USherbrooke.ca



From MSchwartz at MedAnalytics.com  Thu Sep 30 18:09:30 2004
From: MSchwartz at MedAnalytics.com (Marc Schwartz)
Date: Thu, 30 Sep 2004 11:09:30 -0500
Subject: [R] Boxplot, space to axis
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE01846339@crbsmxsusr04.pharma.aventis.com>
References: <C80ECAFA2ACC1B45BE45D133ED660ADE01846339@crbsmxsusr04.pharma.aventis.com>
Message-ID: <1096560570.26080.55.camel@localhost.localdomain>

On Thu, 2004-09-30 at 10:22, Arne.Muller at aventis.com wrote:
> Hello Deepayan,
> 
> thanks for your suggestion, xaxs='i' works, but it leaves no space at
> all. I though this may be configurable by a real value.
> 
> 	kind regards,
> 
> 	Arne
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Deepayan
> Sarkar
> > Sent: 30 September 2004 17:12
> > To: r-help at stat.math.ethz.ch
> > Cc: Muller, Arne PH/FR
> > Subject: Re: [R] Boxplot, space to axis
> > 
> > 
> > On Thursday 30 September 2004 09:41, Arne.Muller at aventis.com wrote:
> > > Hello,
> > >
> > > I've crearted a boxplot with 84 boxes. So fat everything is as I
> > > expect, but there is quite some space between the 1st box and axis
> 2
> > > and the last box and axis 4. Since 84 boxes get very slim anyway
> I'd
> > > like to discribute as much of the horizontal space over the
> x-axis.
> > >
> > > Maybe I've forgotten about a graphics parameter?
> > 
> > Perhaps par(xaxs = "i") ?
> > 
> > Deepayan


Here is a possible solution, albeit a little kludgy.

The problem is that there is no way to define the x axis range in the
call to boxplot(), which would allow you to make some adjustments that
way. If you trace through the code for boxplot() and then bxp() [the
latter actually does the plotting], you could figure out how the range
of the x axis is computed and the factors that influence that
calculation. With that knowledge, you could feasibly adjust the 'at'
argument for the placement of the boxes. However, that may be more
complicated than my approach below.

Create some test data:

set.seed(2)
MyData <- matrix(rnorm(84 * 100), ncol = 84)

and then plot it normally:

boxplot(as.data.frame(MyData))

You can then see the par("usr") values:

> par("usr")
[1] -2.860000 87.860000 -4.379829  3.844485

Note the extra space on the x axis range.


Now, let's control that part of the process:

# Open a new plotting device
plot.new()

# Now specify the plotting coordinate system
# There are 84 boxes, so let's add one unit before
# and after to the 'xlim'. Also, specify 'i' for 
# xaxs, so there is no expansion of the x axis
# range as per the default.
plot.window(xlim = c(0, 85), ylim = range(MyData), xaxs = "i")

# Now do the boxplot, setting 'add = TRUE' so that
# the plot is added to the current window, also
# specifying the 'at' argument
boxplot(as.data.frame(MyData), add = TRUE, at = 1:84)


Now note the par("usr") values:
> par("usr")
[1]  0.000000 85.000000 -4.379829  3.844485


You can do further adjustments to the x axis range as you require in the
call to plot.window().

HTH,

Marc Schwartz



From wolski at molgen.mpg.de  Thu Sep 30 18:21:23 2004
From: wolski at molgen.mpg.de (Witold Eryk Wolski)
Date: Thu, 30 Sep 2004 18:21:23 +0200
Subject: [R] function by
In-Reply-To: <1096560353.415c2ee1c3b78@www.usherbrooke.ca>
References: <1096560353.415c2ee1c3b78@www.usherbrooke.ca>
Message-ID: <415C3283.4040407@molgen.mpg.de>

?by
FUN: a function to be applied to data frame subsets of 'data'.

...: further arguments to 'FUN'.


by (SS, year, sum)

/E



Emilie Berthiaume wrote:

>Hi,
>
>I'm just getting started with R and I'm having problems with some simple
>operations: I want to get the the sum of the column "SStot" for each year using
>the function by.  The data set is named "SS".  I've tried this:
>
>by (SS, year, sum(SStot))
>
>and it's not working.  Is it because there's a different number of rows for each
>year?  How else can I do this?
>
>--
>Emilie Berthiaume
>Graduate student
>Biology Departement
>Universit?? de Sherbrooke
>2500 boul. de l'Universit??
>Sherbrooke, Qu??bec
>J1K 2R1 CANADA
>
>T??l: 1-819-821-8000 poste 2059
>Fax: 1-819-821-8049
>Emilie.Berthiaume at USherbrooke.ca
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>


-- 
Dipl. bio-chem. Witold Eryk Wolski         
MPI-Moleculare Genetic
Ihnestrasse 63-73 14195 Berlin           _
tel: 0049-30-83875219                   'v'
http://www.molgen.mpg.de/~wolski       /   \
mail: witek96 at users.sourceforge.net  ---W-W----
      wolski at molgen.mpg.de



From HDoran at air.org  Thu Sep 30 18:38:32 2004
From: HDoran at air.org (Doran, Harold)
Date: Thu, 30 Sep 2004 12:38:32 -0400
Subject: [R] Creating a text codebook
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7405B03CB7@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040930/f665c034/attachment.pl

From sfalcon at fhcrc.org  Thu Sep 30 18:40:13 2004
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 30 Sep 2004 09:40:13 -0700
Subject: [R] Rpy vs RSPython
In-Reply-To: <1096552672.8152.1.camel@blue.chem.psu.edu>
References: <1096552672.8152.1.camel@blue.chem.psu.edu>
Message-ID: <20040930164013.GB3606@queenbee.fhcrc.org>

On Thu, Sep 30, 2004 at 09:57:53AM -0400, Rajarshi Guha wrote:
> Rpy seems easier to get up and running with, but does anybody have any
> comments regarding which would be a better system to work with in the
> long run?

I've been using rpy for a number of months and have been very pleased
with it.  On the other hand, I haven't tried RSPython so I can't
really compare.  

+ seth



From spencer.graves at pdf.com  Thu Sep 30 18:49:15 2004
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 30 Sep 2004 11:49:15 -0500
Subject: [R] Using try()
In-Reply-To: <Pine.LNX.4.43.0409300720170.28111@hymn04.u.washington.edu>
References: <Pine.LNX.4.43.0409300720170.28111@hymn04.u.washington.edu>
Message-ID: <415C390B.1010108@pdf.com>

      Are you using ESS?  If yes, can you try to code in RGui, without 
Emacs or XEmacs? 

      If that fails, "PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html", and tell us which version 
of R, what operating system, etc. 

      hope this helps. 
      spencer graves

Nathaniel B. Derby wrote:

> Hello R people,
>
> I am need some help using the try() function.  Currently I am running 
> a loop which uses arima() for some values of p and q, which sometimes 
> crashes.  When it crashes, I want the program to just ignore it and 
> move on to the next values to loop through.  I currently have this, 
> looping through a range of values for p and q:
>
> lo = try( arima1 <- arima( y, order=c( p, 0, q ) )
> if( !inherits( lo, "try-error" ) ){
>      ... code here ...
>      }
>
> This works perfectly for my purposes, with one exception:  Everytime 
> the program invokes try(), I have to press Esc in the R console for 
> the program to continue.  How can I avoid this (so that I don't have 
> to keep pushing Esc).
>
> I tried reading the help file for tryCatch(), which showed a wide 
> range of options to try (no pun intended), but this confused me.
>
>
> Thanks,
>
> Nate
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html


-- 
Spencer Graves, PhD, Senior Development Engineer
O:  (408)938-4420;  mobile:  (408)655-4567



From wanr at ucalgary.ca  Thu Sep 30 18:52:16 2004
From: wanr at ucalgary.ca (wanr@ucalgary.ca)
Date: Thu, 30 Sep 2004 10:52:16 -0600
Subject: [R] Is there any way to release memory in running time?
Message-ID: <200409301652.i8UGqGl28979@smtp1.ucalgary.ca>

Hi all,

I am doing some intensive computation right now. My system is Pentium4 3.20G 
+ 1.0G RAM + WindowsXP + R1.9.1. It seems my computer is very powerful. 
However, when I do some simple matrix algebra operations based on a matrix 
(DD) with dimension 5000000 by 2, I found that the consumption of RAM is 
huge. For example, the command a <- 1 - DD[,2] eats my 100M RAM. Does anyone 
know how to release memory in the middle of program (running time)? BTW, the 
command rm() does not free memory unless you quit R as I as know. Thanks in 
advance.

Rui



From tom_woody at swissinfo.org  Thu Sep 30 18:59:07 2004
From: tom_woody at swissinfo.org (=?ISO-8859-15?Q?Thomas_Sch=F6nhoff?=)
Date: Thu, 30 Sep 2004 18:59:07 +0200
Subject: [R] Can't load rgl library
In-Reply-To: <4158BE6B00001823@mta01.ono.com>
References: <4158BE6B00001823@mta01.ono.com>
Message-ID: <415C3B5B.8010304@swissinfo.org>

Hello,

arv at ono.com schrieb:
> Hi,
> 
> I've installed rgl package through R CMD INSTALL on a Debian-Sarge machine
> (PIV) without any compiling error (see attached file), but when trying to
> load this package within R (and also Rcmdr library) I get:
> 
> 
>>library(rgl)
> 
> RGL: GLX extension missing on server
> Error in firstlib(which.lib.loc, package) :
> error rgl_init
> error in library(rgl) : .First.lib failed
> Segmentation fault
Sounds like you're missing opengl/ xlibmesa(gl) +(glut) packages; make 
sure that these packages are installed and work flawlessly.


HtH



From sdavis2 at mail.nih.gov  Thu Sep 30 19:04:57 2004
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 30 Sep 2004 13:04:57 -0400
Subject: [R] Is there any way to release memory in running time?
In-Reply-To: <200409301652.i8UGqGl28979@smtp1.ucalgary.ca>
References: <200409301652.i8UGqGl28979@smtp1.ucalgary.ca>
Message-ID: <DB983B10-1302-11D9-B695-000A95D7BA10@mail.nih.gov>

See ?gc.

Sean

On Sep 30, 2004, at 12:52 PM, <wanr at ucalgary.ca> wrote:

> Hi all,
>
> I am doing some intensive computation right now. My system is Pentium4 
> 3.20G
> + 1.0G RAM + WindowsXP + R1.9.1. It seems my computer is very powerful.
> However, when I do some simple matrix algebra operations based on a 
> matrix
> (DD) with dimension 5000000 by 2, I found that the consumption of RAM 
> is
> huge. For example, the command a <- 1 - DD[,2] eats my 100M RAM. Does 
> anyone
> know how to release memory in the middle of program (running time)? 
> BTW, the
> command rm() does not free memory unless you quit R as I as know. 
> Thanks in
> advance.
>
> Rui
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From wolski at molgen.mpg.de  Thu Sep 30 19:06:26 2004
From: wolski at molgen.mpg.de (Witold Eryk Wolski)
Date: Thu, 30 Sep 2004 19:06:26 +0200
Subject: [R] Is there any way to release memory in running time?
In-Reply-To: <200409301652.i8UGqGl28979@smtp1.ucalgary.ca>
References: <200409301652.i8UGqGl28979@smtp1.ucalgary.ca>
Message-ID: <415C3D12.8040204@molgen.mpg.de>

?gc
/E
wanr at ucalgary.ca wrote:

>Hi all,
>
>I am doing some intensive computation right now. My system is Pentium4 3.20G 
>+ 1.0G RAM + WindowsXP + R1.9.1. It seems my computer is very powerful. 
>However, when I do some simple matrix algebra operations based on a matrix 
>(DD) with dimension 5000000 by 2, I found that the consumption of RAM is 
>huge. For example, the command a <- 1 - DD[,2] eats my 100M RAM. Does anyone 
>know how to release memory in the middle of program (running time)? BTW, the 
>command rm() does not free memory unless you quit R as I as know. Thanks in 
>advance.
>
>Rui
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>


-- 
Dipl. bio-chem. Witold Eryk Wolski         
MPI-Moleculare Genetic
Ihnestrasse 63-73 14195 Berlin           _
tel: 0049-30-83875219                   'v'
http://www.molgen.mpg.de/~wolski       /   \
mail: witek96 at users.sourceforge.net  ---W-W----
      wolski at molgen.mpg.de



From tom_woody at swissinfo.org  Thu Sep 30 19:15:32 2004
From: tom_woody at swissinfo.org (=?ISO-8859-15?Q?Thomas_Sch=F6nhoff?=)
Date: Thu, 30 Sep 2004 19:15:32 +0200
Subject: [R] Can't load rgl library
In-Reply-To: <4158BE6B00001823@mta01.ono.com>
References: <4158BE6B00001823@mta01.ono.com>
Message-ID: <415C3F34.8030901@swissinfo.org>


Hello,

arv at ono.com schrieb:
> Hi,
> 
> I've installed rgl package through R CMD INSTALL on a Debian-Sarge machine
> (PIV) without any compiling error (see attached file), but when trying to
> load this package within R (and also Rcmdr library) I get:
> 
> 
>>library(rgl)
> 
> RGL: GLX extension missing on server
> Error in firstlib(which.lib.loc, package) :
> error rgl_init
> error in library(rgl) : .First.lib failed
> Segmentation fault
> 
> Same failure problem if I use the apt option (apt-get install r-cran-gl).
> I've searched through the R mail archives but couldn't find or understand
> the answer for this problem.

I just forgot to say that you also could try to rename /usr/share/tls 
(IIRC, its tls directory!) to /usr/share/tls_old and re-try loading the 
package.
Maybe default installation doesn't recognize the working drivers, 
especially if you run NVidia driver on your box!

HtH



From tlumley at u.washington.edu  Thu Sep 30 19:25:14 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 30 Sep 2004 10:25:14 -0700 (PDT)
Subject: [R] function by
In-Reply-To: <415C3283.4040407@molgen.mpg.de>
References: <1096560353.415c2ee1c3b78@www.usherbrooke.ca>
	<415C3283.4040407@molgen.mpg.de>
Message-ID: <Pine.A41.4.61.0409301024200.121360@homer08.u.washington.edu>

On Thu, 30 Sep 2004, Witold Eryk Wolski wrote:

> ?by
> FUN: a function to be applied to data frame subsets of 'data'.
>
> ...: further arguments to 'FUN'.
>
>
> by (SS, year, sum)

Quite likely
    by(SS, year, function(these) sum(these$SStot))
will be needed.  There are probably some columns for which sum() won't 
work

 	-thomas

> /E
>
>
>
> Emilie Berthiaume wrote:
>
>> Hi,
>> 
>> I'm just getting started with R and I'm having problems with some simple
>> operations: I want to get the the sum of the column "SStot" for each year 
>> using
>> the function by.  The data set is named "SS".  I've tried this:
>> 
>> by (SS, year, sum(SStot))
>> 
>> and it's not working.  Is it because there's a different number of rows for 
>> each
>> year?  How else can I do this?
>> 
>> --
>> Emilie Berthiaume
>> Graduate student
>> Biology Departement
>> Universit? de Sherbrooke
>> 2500 boul. de l'Universit?
>> Sherbrooke, Qu?bec
>> J1K 2R1 CANADA
>> 
>> T?l: 1-819-821-8000 poste 2059
>> Fax: 1-819-821-8049
>> Emilie.Berthiaume at USherbrooke.ca
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>> 
>> 
>
>
> -- 
> Dipl. bio-chem. Witold Eryk Wolski         MPI-Moleculare Genetic
> Ihnestrasse 63-73 14195 Berlin           _
> tel: 0049-30-83875219                   'v'
> http://www.molgen.mpg.de/~wolski       /   \
> mail: witek96 at users.sourceforge.net  ---W-W----
>     wolski at molgen.mpg.de
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From rpeng at jhsph.edu  Thu Sep 30 19:31:14 2004
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 30 Sep 2004 13:31:14 -0400
Subject: [R] Is there any way to release memory in running time?
In-Reply-To: <200409301652.i8UGqGl28979@smtp1.ucalgary.ca>
References: <200409301652.i8UGqGl28979@smtp1.ucalgary.ca>
Message-ID: <415C42E2.9020005@jhsph.edu>

I'm not sure I understand your problem.  Your `DD' matrix should 
occupy ~75MB of memory and your `a' vector should occupy ~38MB of 
memory.  That adds up to over 100MB as far as I can see.

As far as I know, there is no way to explicitly give memory back to 
the *operating system*, if that's what you need.

-roger

wanr at ucalgary.ca wrote:
> Hi all,
> 
> I am doing some intensive computation right now. My system is Pentium4 3.20G 
> + 1.0G RAM + WindowsXP + R1.9.1. It seems my computer is very powerful. 
> However, when I do some simple matrix algebra operations based on a matrix 
> (DD) with dimension 5000000 by 2, I found that the consumption of RAM is 
> huge. For example, the command a <- 1 - DD[,2] eats my 100M RAM. Does anyone 
> know how to release memory in the middle of program (running time)? BTW, the 
> command rm() does not free memory unless you quit R as I as know. Thanks in 
> advance.
> 
> Rui
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From tlumley at u.washington.edu  Thu Sep 30 19:31:20 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 30 Sep 2004 10:31:20 -0700 (PDT)
Subject: [R] Creating a text codebook
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7405B03CB7@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F7405B03CB7@dc1ex2.air.org>
Message-ID: <Pine.A41.4.61.0409301026170.121360@homer08.u.washington.edu>

On Thu, 30 Sep 2004, Doran, Harold wrote:

> Is there a currently existing method in an R package for creating a
> codebook from a dataframe? Preferably, I would like to be able to export
> to a text file all relevant information.
>

There's something along these lines (though not quite what you want) in 
the latest version of the "foreign" package.

The function write.foreign writes out two text files, one of data and one 
of code to read those data into some other package. It currently handles 
SPSS and Stata, and  writeForeignSPSS writes out variable names and factor 
levels into the SPSS code file.  It doesn't handle more complicated things 
such as dates, though.


 	-thomas



From nderby at u.washington.edu  Thu Sep 30 19:53:32 2004
From: nderby at u.washington.edu (Nathaniel B. Derby)
Date: Thu, 30 Sep 2004 10:53:32 -0700 (PDT)
Subject: [R] Using try()
In-Reply-To: <415C390B.1010108@pdf.com>
Message-ID: <Pine.LNX.4.43.0409301053320.3473@hymn12.u.washington.edu>

Thanks, Spencer!

As a neophyte to the R mailing lists, I shall follow the guidelines of the posting guide.  As for my specific question (which concerns R 1.9.1 on WinXP, using WinEdt as my editor), I solved it myself in the following manner:


options( show.error.messages = FALSE, error=expression( NULL ) )
   # supresses the error messages and stops
for( ... values of p and q ... ){
      lo = try( arima1 <- arima( y, order=c( p, 0, q ) )
      if( !inherits( lo, "try-error" ) ){
           ... code here ...
           }
      }
options( show.error.messages = TRUE, error=NULL )
   # brings back the error messages and stops


Following a tip from ?stop, it's quite adviseable to bring back the stops and error messages after the loop!


Thanks,

Nate



On Thu, 30 Sep 2004, Spencer Graves wrote:

>     Are you using ESS?  If yes, can you try to code in RGui, without Emacs or 
> XEmacs?      If that fails, "PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html", and tell us which version of R, 
> what operating system, etc.      hope this helps.      spencer graves
>



From ggrothendieck at myway.com  Thu Sep 30 19:59:21 2004
From: ggrothendieck at myway.com (Gabor Grothendieck)
Date: Thu, 30 Sep 2004 17:59:21 +0000 (UTC)
Subject: Vectorising and loop (was Re: [R] optim "alog-likelihoodfunction")
References: <BAY22-F2VfdY6hlHK9100012189@hotmail.com>
Message-ID: <loom.20040930T195701-583@post.gmane.org>

Zhen Pang <nusbj <at> hotmail.com> writes:

: 
: Mr. Grothendieck does suggest me to paste the data here. I just show a small 
: one here. I must metion that I made a mistake in my former email. The first 
: column should be j and is greater than the second column. I have corrected 
: ll.
: 
: z is the matrix below
: 
: 2 1 3
: 3 1 1
: 3 3 1
: 5 2 4
: 
: k<-max(z[,1])
: ll <- function(theta)
:   {t<-0
:    for (ii in 1:k)
:       {t<-t+exp(theta[ii])}
:    lll<-0
:    x00<-1/(1+t)
:    x0<-x00*exp(theta)
: for (m in 1:length(z[,1]))
:    {j<-z[m,1]
:     i<-z[m,2]
:     a<-z[m,3]
:     l<-i:(k-j+i)
:     s<-rep(0,k)
:     s[l]<-choose(j,i)*choose((k-j),(l-i))/choose(k,l)
: # we only define some of s to be non-zero, since dim(l) might be smaller 
: than dim(s)
:     ss<-sum(s*x0)  # ss is a weighted sum of x0
:      lll<-lll+a*log(ss)
:     }
: -lll
: # the negative sign is to find the maximum of the log-likelihood function. 
: It can be omitted if we #use the finscale option in optim.
: }
: 
: Then I need to optim(b0,ll,hessian=T),
: where b0<-c(0.8331934, 20.8009068, -7.0893623,  1.2109221, 18.7213273).
: 
: optim(b0,ll,hessian=T)
: $par
: [1]  0.8331934 20.8009068 -7.0893623  1.2109221 18.7213273
: 
: $value
: [1] 5.182791
: 
: $counts
: function gradient
:       52       NA
: 
: $convergence
: [1] 0
: 
: $message
: NULL
: 
: $hessian
:               [,1]          [,2]          [,3]          [,4]          [,5]
: [1,]  1.065814e-08 -9.325873e-09  0.000000e+00 -3.330669e-10 -2.109424e-09
: [2,] -9.325873e-09  8.887936e-01 -3.330669e-10 -1.620926e-08 -8.887936e-01
: [3,]  0.000000e+00 -3.330669e-10 -6.661338e-10  0.000000e+00  0.000000e+00
: [4,] -3.330669e-10 -1.620926e-08  0.000000e+00  7.549517e-09  7.105427e-09
: [5,] -2.109424e-09 -8.887936e-01  0.000000e+00  7.105427e-09  8.887936e-01
: 
: 
: I have tried to use eval() and modify my function, it seems to be able to 
: remove the m loop, however, optim() can not recognize it. So my main concern 
: is to avoid the loop and optim() can works for my function. Thanks.



I suspect your code may be wrong but taking it at face value
s does not depend on the input theta so precalculate it
as a matrix whose mth column is s[,m].  Also the only
purpose of the loop indexed by m is to calculate lll and
the final iteration of that loop calculates an lll which
does not depend on the prior iterations so remove the loop
and just run the final iteration.  Similarly we only need
the final value of x0 that is calculated.  Note that the
value of ll(b0), your loopy function, and ll2(b0) the one
line non-loopy function using the precalculated s, give 
the same result:

R> z <- matrix(c( 2,1,3, 3,1,1, 3,3,1, 5,2,4), 4, 3, byrow = TRUE)
R> b0<-c(0.8331934, 20.8009068, -7.0893623, 1.2109221, 18.7213273)
R> 
R> k<-max(z[,1])
R> s <- apply(z, 1, function(z) {
+ j<-z[1]; i<-z[2]
+ l<-i:(k-j+i)
+ s<-rep(0,k)
+ s[l]<-choose(j,i)*choose((k-j),(l-i))/choose(k,l)
+ s
+ })

R> ll2 <- function(theta) {
+ - sum(z[,3]*log(crossprod(s, exp(theta)* 1/(1+sum(exp(theta))))))
+ }
R> ll(b0) # this is the ll function from your post
[1] 5.182791
R> ll2(b0)
[1] 5.182791



From lilianroos at yahoo.com  Thu Sep 30 20:20:11 2004
From: lilianroos at yahoo.com (Lilian Roos)
Date: Thu, 30 Sep 2004 11:20:11 -0700 (PDT)
Subject: [R] scan with Apple
Message-ID: <20040930182011.49934.qmail@web41002.mail.yahoo.com>

Dear Madam, Sir,

I wonder me how I can scan a file in R when I work at
an Apple (Mac OS X). I know how to do in a Windows
surrounding, but not in the Apple one. Can you help
me?

Hope to hear from you and thanks in front,

Lilian Roos

PS. I have to scan "verzoeken2.txt" and this file is
at my USB DISK drive.

=====
"All the freaky people make a beauty of the world" - Michael Franti
















		
_______________________________

Declare Yourself - Register online to vote today!



From jfox at mcmaster.ca  Thu Sep 30 20:35:03 2004
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 30 Sep 2004 14:35:03 -0400
Subject: [R] Creating a text codebook
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7405B03CB7@dc1ex2.air.org>
Message-ID: <20040930183459.VCMH2048.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Harold,

I'm not sure what you have in mind, but take a look at the prompt()
function, which can create a skeleton .Rd (R documentation) for a data
frame. It will distinguish between numeric variables and factors, and will
show the various levels of each factor. I don't think that there's any other
"relevant information" in the data frame.

I hope that this helps,
 John

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Doran, Harold
> Sent: Thursday, September 30, 2004 11:39 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Creating a text codebook
> 
> Is there a currently existing method in an R package for 
> creating a codebook from a dataframe? Preferably, I would 
> like to be able to export to a text file all relevant information.
>



From Roger.Bivand at nhh.no  Thu Sep 30 20:41:45 2004
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 30 Sep 2004 20:41:45 +0200 (CEST)
Subject: [R] dot density maps
In-Reply-To: <AD1C47A0C9C12C46987E2D31EE1E63B4360AEC@lps001.lyon.who.int>
Message-ID: <Pine.LNX.4.44.0409301357100.13686-100000@reclus.nhh.no>

On Wed, 22 Sep 2004, Johannes SCHNITZLER wrote:

> Dear All,
> 
> In the moment i'm using the map and maptools package to read shapefiles
> and display the maps. 
> 
> I'm looking for the possibility to draw points (randomly positioned or
> positioned according to a grid) into the polygons instead of filling the
> polygons with colors.
> 

I apologize for not replying earlier. I think that you can combine the 
polylist class from the maptools package with the csr function in the 
splancs package to position points randomly (the gridpts() finction can 
be used instead of csr() to give grid points):

> library(maptools)
> library(splancs)
> source("dotsinpolys.R")
> x <- read.shape(system.file("shapes/sids.shp", package="maptools")[1])
> ncpolys <- Map2poly(x, raw=FALSE)
> names(x$att.data)
> plot(ncpolys)
> try1 <- dotsInPolys(ncpolys, x$att.data$SID74)
> xx <- lapply(try1, function(x) {if (!is.null(x)) points(x, pch=18, 
+ col="red")})
> try2 <- dotsInPolys(ncpolys, x$att.data$SID74, f=gridpts)
> plot(ncpolys)
> xx <- lapply(try2, function(x) {if (!is.null(x)) points(x, pch=18, 
+ col="red")})

where dotsinpolys.R is:

dotsInPolys <- function(pl, x, f=csr) {
    if (!inherits(pl, "polylist")) stop("not a polylist object")
    if (length(pl) != length(x)) stop("different lengths")
    n <- length(pl)
    res <- vector(mode="list", length=n)
    for (i in 1:n) {
        if (x[i] > 0) {
            if (attr(pl[[i]], "nParts") == 1) {
                if (attr(pl[[i]], "ringDir") != 1)
                    warning(paste("hole with content at:", i))
                res[[i]] <- f(matrix(c(ncpolys[[i]]), ncol=2), x[i])
            } else {
                areas <- rep(0, attr(pl[[i]], "nParts"))
                for (j in 1:attr(pl[[i]], "nParts")) {
                    if (attr(pl[[i]], "ringDir")[j] == 1) {
                        from <- attr(pl[[i]], "pstart")$from[j]
                        to <- attr(pl[[i]], "pstart")$to[j]
                        areas[j] <- areapl(matrix(c(ncpolys[[i]][from:to,]), 
                            ncol=2))
                    }
                }
                pareas <- areas/sum(areas)
                px <- as.integer(round(pareas*x[i], digits = 0))
                for (j in 1:attr(pl[[i]], "nParts")) {
                    if (px[j] > 0) {
                        from <- attr(pl[[i]], "pstart")$from[j]
                        to <- attr(pl[[i]], "pstart")$to[j]
			pj <- matrix(c(ncpolys[[i]][from:to,]), ncol=2)
			res[[i]] <- rbind(res[[i]], f(pj, px[j]))
                    }
                }
            }
            res[[i]] <- matrix(res[[i]], ncol=2)
        }
    }
    res
}

The extra work is because not all polygon units are a single polygon, and 
some may be "lakes" within other polygons, doubling up on area. I suspect 
that the more sophisticated polygons in spatstat may be able to prevent 
sampled points landing in the water. In multi-polygon units, points are 
divided by relative area, and because of rounding may not be exactly the 
same as the input count. The gridded points are also not likely to add up 
exactly.

Could you indicate whether this function is any use, and if you would like 
it added to some suitable package?

Roger Bivand 

>  
> 
> For example: 
> 
> a map (shapefile) with 10 countries, 15 points in the polygon of country
> A, 20 points in the polygon of country B.....
> 
>  
> 
>  
> 
> Thank you in advance for your help
> 
>  
> 
> Johannes 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no



From holck at hawaii.edu  Thu Sep 30 20:56:28 2004
From: holck at hawaii.edu (Peter Holck)
Date: Thu, 30 Sep 2004 08:56:28 -1000
Subject: [R] Discriminant function analysis eigenvalue standard error
	calculations
Message-ID: <000101c4a71f$312f8880$3788fea9@psh>

I am trying to use the machinery of linear discriminant function analysis to
identify group membership for a dataset with many groups, and few members
(2) per group. The MASS package lda() function conveniently returns
eigenvectors specifying the linear combination of my group member covariates
which best discriminant members into groups. I would like to obtain a
standard error for the corresponding maximum eigenvalue (although the
eigenvalue itself does not seem to be returned by lda() ?). Does anyone have
any suggestions on an appropriate method to consider in calculating a
standard error?
Thanks in advance - 

Peter Holck



From blindglobe at gmail.com  Thu Sep 30 21:11:13 2004
From: blindglobe at gmail.com (A.J. Rossini)
Date: Thu, 30 Sep 2004 15:11:13 -0400
Subject: [R] Creating a text codebook
In-Reply-To: <20040930183459.VCMH2048.tomts10-srv.bellnexxia.net@JohnDesktop8300>
References: <88EAF3512A55DF46B06B1954AEF73F7405B03CB7@dc1ex2.air.org>
	<20040930183459.VCMH2048.tomts10-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <1abe3fa9040930121174871ec6@mail.gmail.com>

Something like summary() will produce the start of a codebook for a
dataset within a data.frame, but it probably would need to be munged
up a bit more.

Actually, the first use of literate statistical analysis (noweb-style)
was done to produce a codebook.


On Thu, 30 Sep 2004 14:35:03 -0400, John Fox <jfox at mcmaster.ca> wrote:
> Dear Harold,
> 
> I'm not sure what you have in mind, but take a look at the prompt()
> function, which can create a skeleton .Rd (R documentation) for a data
> frame. It will distinguish between numeric variables and factors, and will
> show the various levels of each factor. I don't think that there's any other
> "relevant information" in the data frame.
> 
> I hope that this helps,
> John
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Doran, Harold
> > Sent: Thursday, September 30, 2004 11:39 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Creating a text codebook
> >
> > Is there a currently existing method in an R package for
> > creating a codebook from a dataframe? Preferably, I would
> > like to be able to export to a text file all relevant information.
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 



-- 
A.J. Rossini
blindglobe at gmail.com



From tlumley at u.washington.edu  Thu Sep 30 21:48:15 2004
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 30 Sep 2004 12:48:15 -0700 (PDT)
Subject: [R] scan with Apple
In-Reply-To: <20040930182011.49934.qmail@web41002.mail.yahoo.com>
References: <20040930182011.49934.qmail@web41002.mail.yahoo.com>
Message-ID: <Pine.A41.4.61.0409301246120.331760@homer07.u.washington.edu>

On Thu, 30 Sep 2004, Lilian Roos wrote:

> Dear Madam, Sir,
>
> I wonder me how I can scan a file in R when I work at
> an Apple (Mac OS X). I know how to do in a Windows
> surrounding, but not in the Apple one. Can you help
> me?
>
> Hope to hear from you and thanks in front,
>
> Lilian Roos
>
> PS. I have to scan "verzoeken2.txt" and this file is
> at my USB DISK drive.
>

The same way. You need to know the path for the file. Look in the Finder 
to see the name of your USB disk drive. Suppose it is called UNNAMED 
(which is the default for some brands). Then
   scan("/Volumes/UNNAMED/verzoeken2.txt")
would work

 	-thomas

> =====
> "All the freaky people make a beauty of the world" - Michael Franti
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> _______________________________
>
> Declare Yourself - Register online to vote today!
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From bill.shipley at usherbrooke.ca  Thu Sep 30 22:08:40 2004
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Thu, 30 Sep 2004 16:08:40 -0400
Subject: [R] histograms with more than one variable
Message-ID: <004401c4a729$473d1660$8c1ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20040930/d556ef8a/attachment.pl

From andy_liaw at merck.com  Thu Sep 30 22:23:17 2004
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 30 Sep 2004 16:23:17 -0400
Subject: [R] histograms with more than one variable
Message-ID: <3A822319EB35174CA3714066D590DCD504AF8497@usrymx25.merck.com>

Sounds like you want something similar to:

library(lattice)
y <- rnorm(40)
group <- rep(1:2, each=20)
histogram(~y | group)

Andy

> From: Bill Shipley
> 
>  
> 
> y          group
> 
> 1.2       1
> 
> 3.3       1
> 
> 2.4       2
> 
> 5.7       1
> 
> 0.2       2
> 
> etc.
> 
>  
> 
> Bill Shipley
> 
> Subject Matter Editor, Ecology
> 
> North American Editor, Annals of Botany
> 
> D??partement de biologie, Universit?? de Sherbrooke,
> 
> Sherbrooke (Qu??bec) J1K 2R1 CANADA
> 
> Bill.Shipley at USherbrooke.ca
> 
 <http://callisto.si.usherb.ca:8080/bshipley/>
http://callisto.si.usherb.ca:8080/bshipley/

 


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From p.murrell at auckland.ac.nz  Thu Sep 30 22:51:25 2004
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 01 Oct 2004 08:51:25 +1200
Subject: [R] pointsize in png graphics
References: <OF46ABB7D4.86DF0E0C-ONC1256F1F.004D6A0C-C1256F1F.004E43F1@global.partnerre.net>
Message-ID: <415C71CD.1090800@stat.auckland.ac.nz>

Hi


Jan.Kleinn at partnerre.com wrote:
> Dear all,
> 
> I'm trying to produce 2 png files, one consisting of an image plot and a
> color-table (also an image plot) and the other one consisting of 4 image
> plots and a color table. I'd like the color table to be exactly the same.
> The way I proceded is the following:
> 
> for one plot and the color-table
> png(file = png.file, width = 650, height = 800, pointsize = 16)
> layout(matrix(c(1, 2), ncol = 2, nrow = 1, byrow = T),
>        widths = c(6, 1), heights = 1)
> par(mar = c(0.2, 0.2, 0.2, 0.2), mgp = c(2, 1, 0), las = 0)
> ...
> dev.off()
> 
> for 4 plots and the color-table
> png(file = png.file, width = 650, height = 800, pointsize = 16)
> layout(matrix(c(1, 2, 5, 3, 4, 5), ncol = 3, nrow = 2, byrow = T),
>        widths = c(3, 3, 1), heights = c(1, 1))
> par(mar = c(0.2, 0.2, 0.2, 0.2), mgp = c(2, 1, 0), las = 0)
> ...
> dev.off()
> 
> The only difference is the layout of the plot. The outcome though is
> completely different. It seems that the definition of the size of one point
> is different in the two plots as the graphics with 4 plots and color table
> has smaller fonts and smaller margins. What do I have to do to be sure the
> size of the fonts is the same in two different png graphcis of exactly the
> same size when the pointsize is the same?
> 
> I'm working with Windows XP and tried both running the R script as a batch
> job and running it within Emacs with ESS.


I think the problem is that R is trying to think for you.  R 
automatically reduces text size when there are more than three plots (or 
more than three cells in a layout) on a page.  Below are two suggestions 
for making the two layouts the same:


# dummy image plot
dummyplot <- function(col) {
   plot.new()
   usr <- par("usr")
   rect(usr[1], usr[3], usr[2], usr[4], col=col)
}

# original problem
x11()
layout(matrix(c(1, 2), ncol = 2, nrow = 1, byrow = T),
        widths = c(6, 1), heights = 1)
par(mar = c(0.2, 0.2, 0.2, 0.2), mgp = c(2, 1, 0), las = 0)
dummyplot("orange")
dummyplot("blue")

x11()
layout(matrix(c(1, 2, 5, 3, 4, 5), ncol = 3, nrow = 2, byrow = T),
        widths = c(3, 3, 1), heights = c(1, 1))
par(mar = c(0.2, 0.2, 0.2, 0.2), mgp = c(2, 1, 0), las = 0)
dummyplot("red")
dummyplot("yellow")
dummyplot("pink")
dummyplot("violet")
dummyplot("blue")

# solution 1: make second layout same as first
# leave first page alone
# revert auto cex decrease on second page
x11()
layout(matrix(c(1, 2), ncol = 2, nrow = 1, byrow = T),
        widths = c(6, 1), heights = 1)
par(mar = c(0.2, 0.2, 0.2, 0.2), mgp = c(2, 1, 0), las = 0)
dummyplot("orange")
dummyplot("blue")

x11()
layout(matrix(c(1, 2, 5, 3, 4, 5), ncol = 3, nrow = 2, byrow = T),
        widths = c(3, 3, 1), heights = c(1, 1))
par(mar = c(0.2, 0.2, 0.2, 0.2), mgp = c(2, 1, 0), las = 0,
     ### CHANGES HERE
     cex=1.5, mex=0.66)
dummyplot("red")
dummyplot("yellow")
dummyplot("pink")
dummyplot("violet")
dummyplot("blue")

# solution 2: make first layout same as second
# make same number of columns/rows in first layout
# leave second page alone
x11()
layout(### CHANGES HERE
        matrix(c(1, 1, 2, 1, 1, 2), ncol = 3, nrow = 2, byrow = T),
        widths = c(6, 1), heights = 1)
par(mar = c(0.2, 0.2, 0.2, 0.2), mgp = c(2, 1, 0), las = 0)
dummyplot("orange")
dummyplot("blue")

x11()
layout(matrix(c(1, 2, 5, 3, 4, 5), ncol = 3, nrow = 2, byrow = T),
        widths = c(3, 3, 1), heights = c(1, 1))
par(mar = c(0.2, 0.2, 0.2, 0.2), mgp = c(2, 1, 0), las = 0)
dummyplot("red")
dummyplot("yellow")
dummyplot("pink")
dummyplot("violet")
dummyplot("blue")

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From hodgess at gator.uhd.edu  Thu Sep 30 23:11:51 2004
From: hodgess at gator.uhd.edu (Erin Hodgess)
Date: Thu, 30 Sep 2004 16:11:51 -0500
Subject: [R] dev.print and win.print
Message-ID: <200409302111.i8ULBp927686@gator.dt.uh.edu>

Dear R Users:

Was there an answer to the question about
using dev.print and win.print to print as horizontal = FALSE,
please?

I was working on it and I didn't find the solution.

R 1.9.1 Windows
Thanks,
Erin Hodgess
mailto: hodgess at gator.uhd.edu



From pauljohn at ku.edu  Thu Sep 30 23:40:56 2004
From: pauljohn at ku.edu (Paul Johnson)
Date: Thu, 30 Sep 2004 16:40:56 -0500
Subject: [R] polr (MASS) and lrm (Design) differences in tests of statistical
 signifcance 
Message-ID: <415C7D68.2020103@ku.edu>

Greetings:

I'm running R-1.9.1 on Fedora Core 2 Linux.

I tested a proportional odds logistic regression with MASS's polr and 
Design's lrm.  Parameter estimates between the 2 are consistent, but the 
standard errors are quite different, and the conclusions from the t and 
Wald tests are dramatically different. I cranked the "abstol" argument 
up quite a bit in the polr method and it did not make the differences go 
away.

So

1. Can you help me see why the std. errors in the polr are so much 
smaller, and

2. Can I hear more opinions on the question of t vs. Wald in making 
these signif tests. So far, I understand the t is based on the 
asymptotic Normality of the estimate of b, and for finite samples b/se 
is not exactly distributed as a t. But I also had the impression that 
the Wald value was an approximation as well.

 > summary(polr(as.factor(RENUCYC) ~ DOCS + PCT65PLS*RANNEY2 + OLDCRASH 
+  FISCAL2 + PCTMETRO + ADMLICEN, data=elaine1))

Re-fitting to get Hessian

Call:
polr(formula = as.factor(RENUCYC) ~ DOCS + PCT65PLS * RANNEY2 +
     OLDCRASH + FISCAL2 + PCTMETRO + ADMLICEN, data = elaine1)

Coefficients:
                         Value  Std. Error   t value
DOCS              0.004942217 0.002952001  1.674192
PCT65PLS          0.454638558 0.113504288  4.005475
RANNEY2           0.110473483 0.010829826 10.200855
OLDCRASH          0.139808663 0.042245692  3.309418
FISCAL2           0.025592117 0.011465812  2.232037
PCTMETRO          0.018184093 0.007792680  2.333484
ADMLICEN         -0.028490387 0.011470999 -2.483688
PCT65PLS:RANNEY2 -0.008559228 0.001456543 -5.876400

Intercepts:
       Value   Std. Error t value
2|3    6.6177  0.3019    21.9216
3|4    7.1524  0.2773    25.7938
4|5   10.5856  0.2149    49.2691
5|6   12.2132  0.1858    65.7424
6|8   12.2704  0.1856    66.1063
8|10  13.0345  0.2184    59.6707
10|12 13.9801  0.3517    39.7519
12|18 14.6806  0.5587    26.2782

Residual Deviance: 587.0995
AIC: 619.0995


 > lrm(RENUCYC ~ DOCS + PCT65PLS*RANNEY2 + OLDCRASH +  FISCAL2 + 
PCTMETRO + ADMLICEN, data=elaine1)

Logistic Regression Model

lrm(formula = RENUCYC ~ DOCS + PCT65PLS * RANNEY2 + OLDCRASH +
     FISCAL2 + PCTMETRO + ADMLICEN, data = elaine1)


Frequencies of Responses
   2   3   4   5   6   8  10  12  18
  21  12 149  46   1  10   6   2   2

Frequencies of Missing Values Due to Each Variable
  RENUCYC     DOCS PCT65PLS  RANNEY2 OLDCRASH  FISCAL2 PCTMETRO ADMLICEN
        5        0        0        6        0        5        0        5

        Obs  Max Deriv Model L.R.       d.f.          P          C 
   Dxy
        249      7e-05      56.58          8          0      0.733 
0.465
      Gamma      Tau-a         R2      Brier
       0.47      0.278       0.22      0.073

                    Coef       S.E.     Wald Z P
y>=3                -6.617857 6.716688 -0.99  0.3245
y>=4                -7.152561 6.716571 -1.06  0.2869
y>=5               -10.585705 6.742222 -1.57  0.1164
y>=6               -12.213340 6.755656 -1.81  0.0706
y>=8               -12.270506 6.755571 -1.82  0.0693
y>=10              -13.034584 6.756829 -1.93  0.0537
y>=12              -13.980235 6.767724 -2.07  0.0389
y>=18              -14.680760 6.786639 -2.16  0.0305
DOCS                 0.004942 0.002932  1.69  0.0918
PCT65PLS             0.454653 0.552430  0.82  0.4105
RANNEY2              0.110475 0.076438  1.45  0.1484
OLDCRASH             0.139805 0.042104  3.32  0.0009
FISCAL2              0.025592 0.011374  2.25  0.0245
PCTMETRO             0.018184 0.007823  2.32  0.0201
ADMLICEN            -0.028490 0.011576 -2.46  0.0138
PCT65PLS * RANNEY2  -0.008559 0.006417 -1.33  0.1822

 >

-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From maechler at stat.math.ethz.ch  Wed Sep 29 22:25:21 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 29 Sep 2004 22:25:21 +0200
Subject: [R] arima vs arima0
In-Reply-To: <Pine.LNX.4.43.0409291219510.26354@hymn05.u.washington.edu>
References: <Pine.LNX.4.43.0409291219510.26354@hymn05.u.washington.edu>
Message-ID: <16731.6705.279595.229973@gargle.gargle.HOWL>

>>>>> "Nathaniel" == Nathaniel B Derby <nderby at u.washington.edu>
>>>>>     on Wed, 29 Sep 2004 12:19:51 -0700 (PDT) writes:

    Nathaniel> What is the difference between arima and arima0?

Mainly:
  arima0 is the predecessor of arima.
  AFAIK, it has only be retained for back-compatibility but
  shouldn't really be used in "new "rojects".

In more details:
  1) carefully read their help pages
  2) read the source code :-)

Martin



From maechler at stat.math.ethz.ch  Wed Sep 29 09:16:51 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 29 Sep 2004 09:16:51 +0200
Subject: [R] R-devel not R-help (was "Bug? using { as a function ...")
In-Reply-To: <loom.20040928T215129-758@post.gmane.org>
References: <loom.20040928T215129-758@post.gmane.org>
Message-ID: <16730.24931.773197.999690@gargle.gargle.HOWL>

>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck at myway.com>
>>>>>     on Tue, 28 Sep 2004 20:02:01 +0000 (UTC) writes:

    Gabor> This seems like a bug to me.  Can someone verify
    Gabor> this?

By the way, Gabor (and everyone else) :

This has been a typical topic *not* fitting well into R-help 
(because it's quite technical and not about solving a real
 problem with R, etc,etc) -- pretty much those things belonging to
R-devel as explained in the posting guide.

Martin Maechler

   < ........ >



From maechler at stat.math.ethz.ch  Tue Sep 28 10:54:57 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Sep 2004 10:54:57 +0200
Subject: [R] emacs, Mac OS X, R
In-Reply-To: <76C6E4CF-1067-11D9-90F2-0003938C0ABE@gmx.net>
References: <C4958F90-0E32-11D9-9448-0003938C0ABE@gmx.net>
	<E59E4292-0E41-11D9-B31A-0003930C7D76@louisville.edu>
	<76C6E4CF-1067-11D9-90F2-0003938C0ABE@gmx.net>
Message-ID: <16729.9953.896438.853912@gargle.gargle.HOWL>

Redirected to ESS-help,
this has become an ESS/Emacs topic much more than an R one.
{Please drop R-help entirely if you reply to this! MM}

>>>>> "Meinhard" == Meinhard Ploner <meinhardploner at gmx.net>
>>>>>     on Mon, 27 Sep 2004 11:27:34 +0200 writes:

    Meinhard> On Sep 24, 2004, at 5:53 PM, Bill Rising wrote:

    >> On Sep 24, 2004, at 10:05, Meinhard Ploner wrote:
    >> 
    >>> Hi!
    >>> 
    >>> Since August I am using emacs on my Macintosh to edit
    >>> the R objects.  I have installed R 1.9.1, Mac OS X
    >>> 10.3.5 and GNU Emacs 21.2.1.  However there are some
    >>> issues I haven't resolved:
    >>> 
    >>> a) switch the caps lock key to the meta key (and when
    >>> this is not possible, switch the alt/option key to the
    >>> meta).
    >>  You can use only the command or option key for the meta
    >> key. To see the method, try looking at
    >> 
    >> http://members.shaw.ca/akochoi-emacs/stories/faq.html
    >> 
    >>> The switch should work only within emacs!
    >>> 
    >>> b) having different colors for the code, i.e. comments,
    >>> commands, strings, ...
    >>  I'd advise using ESS, whose home page is
    >> 
    >> http://stat.ethz.ch/ESS/

    Meinhard> after installing ESS 5.2.3 I called emacs and
    Meinhard> within emacs M-x R and I get the following:

    >> options(STERM='iESS', editor='emacsclient')
    >> 
    >> fix(fun1)

    Meinhard> emacsclient: can't find socket; have you started
    Meinhard> the server?

If you want to use the emacsclient, you need to start its server
(as the above question suggests!):
    M-x server-start

If you need this often, add it to your auto-initialization.
We have something like

	(if (not xemacs-p)
	    (server-start nil))

wrapped inside an 
  (add-hook
    'inferior-ess-mode-hook
    '(lambda()
    ..... 
  ))
clause, but you can do it unconditionally.

    Meinhard>   Error in edit(name, file, editor) :
    Meinhard> problem with running editor emacsclient
    >>

    Meinhard> What did I wrong?

using fix() at all :-)

Reall don't work with fix() once ``you've seen the light'' of ESS.
We strongly advocate using source files everywhere - something
which is particularly easy with ESS.
A compromise {between fix() and real source files} would be to
use  C-c C-d  {dump R object to file and start editing that file}

Martin Maechler, ETH Zurich



From maechler at stat.math.ethz.ch  Tue Sep 28 09:24:57 2004
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Sep 2004 09:24:57 +0200
Subject: [R] Enright/Chi-square periodogram / periodicity
In-Reply-To: <2D42B4DF9845F74E9318DF707D5956D901852691@wdexch02.lexgen.com>
References: <2D42B4DF9845F74E9318DF707D5956D901852691@wdexch02.lexgen.com>
Message-ID: <16729.4553.16356.76320@gargle.gargle.HOWL>

>>>>> "MalladiS" == Malladi, Sukhaswami <smalladi at lexgen.com>
>>>>>     on Mon, 27 Sep 2004 09:17:38 -0500 writes:

    MalladiS> I am trying to compute the periodicity of a time
    MalladiS> series.  I would like to know which function in R
    MalladiS> does it.

Have you considered using  spectrum()  with its many variants?

I guess that its methodology is much better than the one in

    MalladiS> Also, how do I plot a Enright / Chi-square
    MalladiS> periodogram using R ?  ( Enright, J.T., 1965,
    MalladiS> Journal of Theoret. Biol. 8,426-468)

(a bit old)

    MalladiS> Greatly appreciate your help.

You're welcome
Martin Maechler, ETH Zurich



