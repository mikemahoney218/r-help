From pai1981 at gmail.com  Sat Oct  1 01:21:54 2016
From: pai1981 at gmail.com (Debasish Pai Mazumder)
Date: Fri, 30 Sep 2016 17:21:54 -0600
Subject: [R] OPeNDAP access / OPeNDAP subsetting with R
In-Reply-To: <CAAcGz98bDa8njpY=Cio5ATpdgq2bpyR47QtT4Nh01+iWA-v=KQ@mail.gmail.com>
References: <CAM9mbiDWSCY-V4VVR3pEUY26RHEmvPOsUS3UosrO=jWO4tp4iA@mail.gmail.com>
	<20C79DFE-6AB1-488D-A5BC-311C4017A601@noaa.gov>
	<CAM9mbiBMU=4fC-5PSvbvdUvHB2=i8vEuO0omVn9Vumr90SWWwA@mail.gmail.com>
	<68C6E1C5-BAE5-4D5F-8DF4-BF1FC2AF5303@noaa.gov>
	<CAAcGz98bDa8njpY=Cio5ATpdgq2bpyR47QtT4Nh01+iWA-v=KQ@mail.gmail.com>
Message-ID: <CAM9mbiAedU8J4YcyX-5DBEMfbagAVQKWJDsxqrqUo6R==Ly8AQ@mail.gmail.com>

Hi
Now I am using netcdfSubset and I am able to download the file but not sure
how to read the files. here my scripts
library("ncdf4")

gribfile<-"
http://thredds.ucar.edu/thredds/ncss/grib/NCEP/GFS/Pacific_40km/best/dataset.html
"
download.file(gribfile,basename(gribfile),mode = "wb")
x<-nc_open(gribfile)

gribfile<-"
http://thredds.ucar.edu/thredds/ncss/grib/NCEP/GFS/Global_0p5deg/best?north=47.0126&west=-114.841&east=-112.641&south=44.8534&time_start=present&time_duration=PT3H&accept=netcdf&var=v-component_of_wind_height_above_ground,u-component_of_wind_height_above_ground"

download.file(gribfile,basename(gribfile),mode = "wb")
x<-nc_open(gribfile)


nc_open doesn't work.

which command should I use?

with regards
-Deb


On Tue, Sep 27, 2016 at 9:30 PM, Michael Sumner <mdsumner at gmail.com> wrote:

> Opendap won't work on Windows CRAN build of ncdf4, though the rgdal build
> does work directly on grib.
>
> Summary: download the files wholus for use on Windows, or set your own
> system on Linux.
>
> Building ncdf4 on Windows is not too hard if you know about doing that.
>
> Cheers, Mike
>
> On Wed, 28 Sep 2016, 06:49 Roy Mendelssohn - NOAA Federal <
> roy.mendelssohn at noaa.gov> wrote:
>
>> Please post the code of what you tried, as I have no idea otherwise what
>> did or did not work for you.
>>
>> -Roy
>>
>> > On Sep 27, 2016, at 12:44 PM, Debasish Pai Mazumder <pai1981 at gmail.com>
>> wrote:
>> >
>> > Hi Roy,
>> > Thanks for your response. I have tried according your suggestion but it
>> doesn't work.
>> > the OPeNDAP link of the data
>> > http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_
>> forecast_ts_9mon/2014/201404/20140403/2014040312/
>> >
>> > datafile:
>> > tmax.01.2014040312.daily.grb2
>> >
>> > Thanks
>> > -Deb
>> >
>> > On Tue, Sep 27, 2016 at 11:51 AM, Roy Mendelssohn - NOAA Federal <
>> roy.mendelssohn at noaa.gov> wrote:
>> > Look at the package ncdf4.  You can use an OPeNDAP URL in place of the
>> file name to perform subsets.,
>> >
>> > -Roy
>> >
>> > > On Sep 27, 2016, at 9:06 AM, Debasish Pai Mazumder <pai1981 at gmail.com>
>> wrote:
>> > >
>> > > Hi all,
>> > >
>> > > I would like to access and subset following OpeNDAP files.
>> > > server:
>> > > http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_
>> forecast_ts_9mon/2014/201404/20140403/2014040312/
>> > >
>> > > file name: tmax.01.2014040312.daily.grb2
>> > > <http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_
>> forecast_ts_9mon/2014/201404/20140403/2014040312/catalog.
>> html?dataset=modeldata/cfsv2_forecast_ts_9mon/2014/201404/
>> 20140403/2014040312/tmax.01.2014040312.daily.grb2>
>> > > I would like to access and subset the file. Any help will be
>> appreciated.
>> > >
>> > > with regards
>> > > -Deb
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > **********************
>> > "The contents of this message do not reflect any position of the U.S.
>> Government or NOAA."
>> > **********************
>> > Roy Mendelssohn
>> > Supervisory Operations Research Analyst
>> > NOAA/NMFS
>> > Environmental Research Division
>> > Southwest Fisheries Science Center
>> > ***Note new address and phone***
>> > 110 Shaffer Road
>> > Santa Cruz, CA 95060
>> > Phone: (831)-420-3666
>> > Fax: (831) 420-3980
>> > e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>> >
>> > "Old age and treachery will overcome youth and skill."
>> > "From those who have been given much, much will be expected"
>> > "the arc of the moral universe is long, but it bends toward justice"
>> -MLK Jr.
>> >
>> >
>>
>> **********************
>> "The contents of this message do not reflect any position of the U.S.
>> Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new address and phone***
>> 110 Shaffer Road
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK
>> Jr.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Sat Oct  1 01:53:56 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 30 Sep 2016 16:53:56 -0700
Subject: [R] OPeNDAP access / OPeNDAP subsetting with R
In-Reply-To: <CAM9mbiAedU8J4YcyX-5DBEMfbagAVQKWJDsxqrqUo6R==Ly8AQ@mail.gmail.com>
References: <CAM9mbiDWSCY-V4VVR3pEUY26RHEmvPOsUS3UosrO=jWO4tp4iA@mail.gmail.com>
	<20C79DFE-6AB1-488D-A5BC-311C4017A601@noaa.gov>
	<CAM9mbiBMU=4fC-5PSvbvdUvHB2=i8vEuO0omVn9Vumr90SWWwA@mail.gmail.com>
	<68C6E1C5-BAE5-4D5F-8DF4-BF1FC2AF5303@noaa.gov>
	<CAAcGz98bDa8njpY=Cio5ATpdgq2bpyR47QtT4Nh01+iWA-v=KQ@mail.gmail.com>
	<CAM9mbiAedU8J4YcyX-5DBEMfbagAVQKWJDsxqrqUo6R==Ly8AQ@mail.gmail.com>
Message-ID: <D9CB6267-BCD9-4DF6-B692-C736951666F8@noaa.gov>

Hi Deb:

> > gribfile <- 'http://thredds.ucar.edu/thredds/ncss/grib/NCEP/GFS/Global_0p5deg/best?north=47.0126&west=-114.841&east=-112.641&south=44.8534&time_start=present&time_duration=PT3H&accept=netcdf&var=v-component_of_wind_height_above_ground,u-component_of_wind_height_above_ground'
> > download.file(gribfile,'junk.nc',mode = "wb")
> trying URL 'http://thredds.ucar.edu/thredds/ncss/grib/NCEP/GFS/Global_0p5deg/best?north=47.0126&west=-114.841&east=-112.641&south=44.8534&time_start=present&time_duration=PT3H&accept=netcdf&var=v-component_of_wind_height_above_ground,u-component_of_wind_height_above_ground'
> Content type 'application/x-netcdf' length unknown
> ....
> downloaded 4360 bytes
> 
> > library(ncdf4)
> > junkFile <- nc_open('junk.nc')
> > str(junkFile)
> List of 14
>  $ filename   : chr "junk.nc"
>  $ writable   : logi FALSE
>  $ id         : int 65536
>  $ safemode   : logi FALSE
>  $ format     : chr "NC_FORMAT_CLASSIC"
>  $ is_GMT     : logi FALSE
>  $ groups     :List of 1
>   ..$ :List of 7
>   .. ..$ id   : int 65536
>   .. ..$ name : chr ""
>   .. ..$ ndims: int 4
>   .. ..$ nvars: int 7
>   .. ..$ natts: int 13
>   .. ..$ dimid: int [1:4(1d)] 0 1 2 3
>   .. ..$ fqgn : chr ""
>   .. ..- attr(*, "class")= chr "ncgroup4"
>  $ fqgn2Rindex:List of 1
>   ..$ : int 1
>  $ ndims      : num 4
>  $ natts      : num 13
>  $ dim        :List of 4
> 

<snip>

I cut off the rest as that is not important for your question.

HTH,

-Roy

> On Sep 30, 2016, at 4:21 PM, Debasish Pai Mazumder <pai1981 at gmail.com> wrote:
> 
> Hi 
> Now I am using netcdfSubset and I am able to download the file but not sure how to read the files. here my scripts 
> library("ncdf4")
> 
> gribfile<-"http://thredds.ucar.edu/thredds/ncss/grib/NCEP/GFS/Pacific_40km/best/dataset.html"
> download.file(gribfile,basename(gribfile),mode = "wb")
> x<-nc_open(gribfile)
> 
> gribfile<-"http://thredds.ucar.edu/thredds/ncss/grib/NCEP/GFS/Global_0p5deg/best?north=47.0126&west=-114.841&east=-112.641&south=44.8534&time_start=present&time_duration=PT3H&accept=netcdf&var=v-component_of_wind_height_above_ground,u-component_of_wind_height_above_ground"  
> download.file(gribfile,basename(gribfile),mode = "wb")
> x<-nc_open(gribfile)
> 
> 
> nc_open doesn't work.
> 
> which command should I use?
> 
> with regards
> -Deb
> 
> 
> On Tue, Sep 27, 2016 at 9:30 PM, Michael Sumner <mdsumner at gmail.com> wrote:
> Opendap won't work on Windows CRAN build of ncdf4, though the rgdal build does work directly on grib.
> 
> Summary: download the files wholus for use on Windows, or set your own system on Linux.
> 
> Building ncdf4 on Windows is not too hard if you know about doing that.
> 
> Cheers, Mike
> 
> On Wed, 28 Sep 2016, 06:49 Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> Please post the code of what you tried, as I have no idea otherwise what did or did not work for you.
> 
> -Roy
> 
> > On Sep 27, 2016, at 12:44 PM, Debasish Pai Mazumder <pai1981 at gmail.com> wrote:
> >
> > Hi Roy,
> > Thanks for your response. I have tried according your suggestion but it doesn't work.
> > the OPeNDAP link of the data
> > http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/
> >
> > datafile:
> > tmax.01.2014040312.daily.grb2
> >
> > Thanks
> > -Deb
> >
> > On Tue, Sep 27, 2016 at 11:51 AM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> > Look at the package ncdf4.  You can use an OPeNDAP URL in place of the file name to perform subsets.,
> >
> > -Roy
> >
> > > On Sep 27, 2016, at 9:06 AM, Debasish Pai Mazumder <pai1981 at gmail.com> wrote:
> > >
> > > Hi all,
> > >
> > > I would like to access and subset following OpeNDAP files.
> > > server:
> > > http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/
> > >
> > > file name: tmax.01.2014040312.daily.grb2
> > > <http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/catalog.html?dataset=modeldata/cfsv2_forecast_ts_9mon/2014/201404/20140403/2014040312/tmax.01.2014040312.daily.grb2>
> > > I would like to access and subset the file. Any help will be appreciated.
> > >
> > > with regards
> > > -Deb
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > **********************
> > "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> > **********************
> > Roy Mendelssohn
> > Supervisory Operations Research Analyst
> > NOAA/NMFS
> > Environmental Research Division
> > Southwest Fisheries Science Center
> > ***Note new address and phone***
> > 110 Shaffer Road
> > Santa Cruz, CA 95060
> > Phone: (831)-420-3666
> > Fax: (831) 420-3980
> > e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> >
> > "Old age and treachery will overcome youth and skill."
> > "From those who have been given much, much will be expected"
> > "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> >
> >
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> -- 
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
> 
> 

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From valkremk at gmail.com  Sat Oct  1 02:23:06 2016
From: valkremk at gmail.com (Val)
Date: Fri, 30 Sep 2016 19:23:06 -0500
Subject: [R] transform
Message-ID: <CAJOiR6agyeMw-Yv18ec6QQhD0qH_Ocs+kOfxGLyRtz0W+sTrig@mail.gmail.com>

Hi all,
I want to standardize  a variable based on certain condition
Here is my sample of data

obs, Year, bb, kk,  y
1,  2001, 25 ,100, 12.6
2,  2001,  15 ,111, 24.7
3,  2001,  53, 110, 13.8
4,  2001,  50, 75,  9.6
5, 2001,  125, 101, 31.5
6,  2001,  205, 407, 65.7
7,  2001,  250, 75, 69.1

If the value of "bb" is  greater than 75 and the value of "kk" is
greater than 100 then I want get  the mean and STD values of "y".  In
this example obs 5 and 6 satisfy the condition.  The mean is 48.6 and
STDEV is 24.18
Then I want to transform the "y" values  with  mean = 10 and SDTEV of 3.
 w= ((y- 48.6)/24.183)*3 +10

My question, how can i pas those mean  and STDEV values  to create the
new variable (w)?

The result looks as follows

obs, Year, bb, kk,  y,     w
1, 2001, 25 ,100 , 12.6,  5.534062435
2, 2001, 15, 111,  24.7,   7.035113672
3, 2001, 53, 110, 13.8,   5.68292702
4, 2001, 50, 75,   9.6,    7.642977396
5, 2001, 125, 101, 31.5,   7.878679656
6, 2001, 205, 407, 65.7,  12.12132034
7, 2001, 250, 75 , 69.1, 12.54310334

Thank you in advance


From bryanmac.24 at gmail.com  Sat Oct  1 03:44:19 2016
From: bryanmac.24 at gmail.com (Bryan Mac)
Date: Fri, 30 Sep 2016 18:44:19 -0700
Subject: [R] Bootstrapping in R
In-Reply-To: <20160929201655.Horde.3eE2mopuZGp8trrU2jNt_Pt@mail.sapo.pt>
References: <20160929201655.Horde.3eE2mopuZGp8trrU2jNt_Pt@mail.sapo.pt>
Message-ID: <4F7BC824-B9E1-44E9-851A-579AC53CBED1@gmail.com>

Hi,

I have read the help page and it was helpful but, I am having concerns because each time I run this code I get the same value. 
I expected that each time I run the code, I will get different values due to random sampling.

How do I get this randomization? The values shouldn?t be the same each time the code is run, correct? 


result <- boot(n_data, statistic = DataSummary, R = 100).


Best,

Bryan Mac
bryanmac.24 at gmail.com



> On Sep 29, 2016, at 12:16 PM, ruipbarradas at sapo.pt wrote:
> 
> Hello,
> 
> Read the help page ?boot::boot.
> For instance, try the following.
> 
> 
> library(boot)
> 
> x <- rnorm(100)
> stat <- function(x, f) mean(x[f])
> boot(x, stat, R = 100)
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> 
> Citando bryan.mac24 <bryan.mac24 at gmail.com>:
> 
>> Hi all,
>> I am wondering how to conduct bootstrapping in R. I need bootstrap 100 times. The trick I need to figure out is how to do get a random sample of 100 out of the total number of case.
>> Best,
>> BM
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Oct  1 09:50:47 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 1 Oct 2016 17:50:47 +1000
Subject: [R] transform
In-Reply-To: <CAJOiR6agyeMw-Yv18ec6QQhD0qH_Ocs+kOfxGLyRtz0W+sTrig@mail.gmail.com>
References: <CAJOiR6agyeMw-Yv18ec6QQhD0qH_Ocs+kOfxGLyRtz0W+sTrig@mail.gmail.com>
Message-ID: <CA+8X3fV260bB1OBs5bak4hwmUjvjghy5jRkFSCzkmoJRcV1fgA@mail.gmail.com>

Hi Val,
Perhaps like this?

valdat<-read.table(text="obs, Year, bb, kk,  y
1,  2001, 25 ,100, 12.6
2,  2001,  15 ,111, 24.7
3,  2001,  53, 110, 13.8
4,  2001,  50, 75,  9.6
5, 2001,  125, 101, 31.5
6,  2001,  205, 407, 65.7
7,  2001,  250, 75, 69.1",sep=",",header=TRUE)

selectval<-valdat$bb > 75 & valdat$kk > 100
valdat$w<-NA
meanselecty<-mean(valdat$y[selectval],na.rm=TRUE)
sdselecty<-sd(valdat$y[selectval],na.rm=TRUE)
valdat$w<-((valdat$y-48.6)/24.183)*3 +10
valdat

Jim


On Sat, Oct 1, 2016 at 10:23 AM, Val <valkremk at gmail.com> wrote:
> Hi all,
> I want to standardize  a variable based on certain condition
> Here is my sample of data
>
> obs, Year, bb, kk,  y
> 1,  2001, 25 ,100, 12.6
> 2,  2001,  15 ,111, 24.7
> 3,  2001,  53, 110, 13.8
> 4,  2001,  50, 75,  9.6
> 5, 2001,  125, 101, 31.5
> 6,  2001,  205, 407, 65.7
> 7,  2001,  250, 75, 69.1
>
> If the value of "bb" is  greater than 75 and the value of "kk" is
> greater than 100 then I want get  the mean and STD values of "y".  In
> this example obs 5 and 6 satisfy the condition.  The mean is 48.6 and
> STDEV is 24.18
> Then I want to transform the "y" values  with  mean = 10 and SDTEV of 3.
>  w= ((y- 48.6)/24.183)*3 +10
>
> My question, how can i pas those mean  and STDEV values  to create the
> new variable (w)?
>
> The result looks as follows
>
> obs, Year, bb, kk,  y,     w
> 1, 2001, 25 ,100 , 12.6,  5.534062435
> 2, 2001, 15, 111,  24.7,   7.035113672
> 3, 2001, 53, 110, 13.8,   5.68292702
> 4, 2001, 50, 75,   9.6,    7.642977396
> 5, 2001, 125, 101, 31.5,   7.878679656
> 6, 2001, 205, 407, 65.7,  12.12132034
> 7, 2001, 250, 75 , 69.1, 12.54310334
>
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Sat Oct  1 11:24:54 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sat, 1 Oct 2016 10:24:54 +0100
Subject: [R] Bootstrapping in R
In-Reply-To: <4F7BC824-B9E1-44E9-851A-579AC53CBED1@gmail.com>
References: <20160929201655.Horde.3eE2mopuZGp8trrU2jNt_Pt@mail.sapo.pt>
	<4F7BC824-B9E1-44E9-851A-579AC53CBED1@gmail.com>
Message-ID: <419da17b-e37e-4fd0-e360-1abb856a54f1@dewey.myzen.co.uk>

Dear Bryan

You are not resetting the seed each time by any chance?

Michael

On 01/10/2016 02:44, Bryan Mac wrote:
> Hi,
>
> I have read the help page and it was helpful but, I am having concerns because each time I run this code I get the same value.
> I expected that each time I run the code, I will get different values due to random sampling.
>
> How do I get this randomization? The values shouldn?t be the same each time the code is run, correct?
>
>
> result <- boot(n_data, statistic = DataSummary, R = 100).
>
>
> Best,
>
> Bryan Mac
> bryanmac.24 at gmail.com
>
>
>
>> On Sep 29, 2016, at 12:16 PM, ruipbarradas at sapo.pt wrote:
>>
>> Hello,
>>
>> Read the help page ?boot::boot.
>> For instance, try the following.
>>
>>
>> library(boot)
>>
>> x <- rnorm(100)
>> stat <- function(x, f) mean(x[f])
>> boot(x, stat, R = 100)
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>> Citando bryan.mac24 <bryan.mac24 at gmail.com>:
>>
>>> Hi all,
>>> I am wondering how to conduct bootstrapping in R. I need bootstrap 100 times. The trick I need to figure out is how to do get a random sample of 100 out of the total number of case.
>>> Best,
>>> BM
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From kristi.glover at hotmail.com  Sat Oct  1 13:29:05 2016
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sat, 1 Oct 2016 11:29:05 +0000
Subject: [R] Rearranging sub-folders, how?
Message-ID: <CY1PR13MB01422B76FBC5297311ACAB47FAC00@CY1PR13MB0142.namprd13.prod.outlook.com>

Hi R user,

I was wondering how we can rearrange the folders in R. for example

original data has been put with the following arrangement:

foldA\subFoldB\subFoldC\subFoldD\subFoldE\


SubFoldE contains several dataset


I want to rearrange the subFoldE into following sequence:


foldA\subFoldB\subFoldD\subFoldC\subFoldE\


Any suggestions?

Thanks

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Oct  1 14:07:51 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 1 Oct 2016 22:07:51 +1000
Subject: [R] Rearranging sub-folders, how?
In-Reply-To: <CY1PR13MB01422B76FBC5297311ACAB47FAC00@CY1PR13MB0142.namprd13.prod.outlook.com>
References: <CY1PR13MB01422B76FBC5297311ACAB47FAC00@CY1PR13MB0142.namprd13.prod.outlook.com>
Message-ID: <CA+8X3fU3qH3jS_JHq=Zjg8_WFNMWNbJnjeHqPjDpizWEg1=2Uw@mail.gmail.com>

Hi Kristi,
I assume that B, C and D are not empty, otherwise the answer is trivial.

create a directory under B named D
move the contents of the old D to the new D
delete the directory E beneath the new D
create a new directory C under the new D
move the contents of the old C to the new C
recursively delete D under the new C
move the old E under the new C
recursively delete the old C

Jim


On Sat, Oct 1, 2016 at 9:29 PM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> Hi R user,
>
> I was wondering how we can rearrange the folders in R. for example
>
> original data has been put with the following arrangement:
>
> foldA\subFoldB\subFoldC\subFoldD\subFoldE\
>
>
> SubFoldE contains several dataset
>
>
> I want to rearrange the subFoldE into following sequence:
>
>
> foldA\subFoldB\subFoldD\subFoldC\subFoldE\
>
>
> Any suggestions?
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kristi.glover at hotmail.com  Sat Oct  1 14:50:08 2016
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sat, 1 Oct 2016 12:50:08 +0000
Subject: [R] Rearranging sub-folders, how?
In-Reply-To: <CA+8X3fU3qH3jS_JHq=Zjg8_WFNMWNbJnjeHqPjDpizWEg1=2Uw@mail.gmail.com>
References: <CY1PR13MB01422B76FBC5297311ACAB47FAC00@CY1PR13MB0142.namprd13.prod.outlook.com>,
	<CA+8X3fU3qH3jS_JHq=Zjg8_WFNMWNbJnjeHqPjDpizWEg1=2Uw@mail.gmail.com>
Message-ID: <CY1PR13MB014231CEAFDDCFF5B623B06AFAC00@CY1PR13MB0142.namprd13.prod.outlook.com>

Thanks Jim for the suggestions.

I used following but it seems not working

dir.create(foldA\subFoldB\subFoldD\subFoldC\subFoldE)

I got a trouble in moving contents of one folder to another.

________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: October 1, 2016 6:07 AM
To: Kristi Glover
Cc: r-help at r-project.org
Subject: Re: [R] Rearranging sub-folders, how?

Hi Kristi,
I assume that B, C and D are not empty, otherwise the answer is trivial.

create a directory under B named D
move the contents of the old D to the new D
delete the directory E beneath the new D
create a new directory C under the new D
move the contents of the old C to the new C
recursively delete D under the new C
move the old E under the new C
recursively delete the old C

Jim


On Sat, Oct 1, 2016 at 9:29 PM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> Hi R user,
>
> I was wondering how we can rearrange the folders in R. for example
>
> original data has been put with the following arrangement:
>
> foldA\subFoldB\subFoldC\subFoldD\subFoldE\
>
>
> SubFoldE contains several dataset
>
>
> I want to rearrange the subFoldE into following sequence:
>
>
> foldA\subFoldB\subFoldD\subFoldC\subFoldE\
>
>
> Any suggestions?
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From djnordlund at gmail.com  Sat Oct  1 16:11:31 2016
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Sat, 1 Oct 2016 07:11:31 -0700
Subject: [R] Bootstrapping in R
In-Reply-To: <4F7BC824-B9E1-44E9-851A-579AC53CBED1@gmail.com>
References: <20160929201655.Horde.3eE2mopuZGp8trrU2jNt_Pt@mail.sapo.pt>
	<4F7BC824-B9E1-44E9-851A-579AC53CBED1@gmail.com>
Message-ID: <1bb2778d-72ca-8bf7-1953-2015240fb47a@gmail.com>

On 9/30/2016 6:44 PM, Bryan Mac wrote:
> Hi,
>
> I have read the help page and it was helpful but, I am having concerns because each time I run this code I get the same value.
> I expected that each time I run the code, I will get different values due to random sampling.
>
> How do I get this randomization? The values shouldn?t be the same each time the code is run, correct?
>
>
> result <- boot(n_data, statistic = DataSummary, R = 100).
>
>
> Best,
>
> Bryan Mac
> bryanmac.24 at gmail.com
>
>
>
>> On Sep 29, 2016, at 12:16 PM, ruipbarradas at sapo.pt wrote:
>>
>> Hello,
>>
>> Read the help page ?boot::boot.
>> For instance, try the following.
>>
>>
>> library(boot)
>>
>> x <- rnorm(100)
>> stat <- function(x, f) mean(x[f])
>> boot(x, stat, R = 100)
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>> Citando bryan.mac24 <bryan.mac24 at gmail.com>:
>>
>>> Hi all,
>>> I am wondering how to conduct bootstrapping in R. I need bootstrap 100 times. The trick I need to figure out is how to do get a random sample of 100 out of the total number of case.
>>> Best,
>>> BM
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Bryan,

You haven't told us anything about the structure of your data, or the 
definition of the DataSummary function.  We are left to guess what you 
are doing.  The posting guide calls for a reproducible example.  At a 
minimum give us some sample data (myabe use dput()), the definition of 
DataSummary, the code you use to set up and call the boot() funtion, and 
examples of your output that shows you "getting the same answer."

Someone may then be able to do more than guess at what the problem is.

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From mar.lamack at hotmail.com  Sat Oct  1 16:45:01 2016
From: mar.lamack at hotmail.com (L... L...)
Date: Sat, 1 Oct 2016 11:45:01 -0300
Subject: [R] concatenating text within a function
Message-ID: <BLU175-W186795A771E8CA19E1BFA996C00@phx.gbl>

Dear all, I have the following variables:
fc	<-	quote(sqrt(2) * pi ^ (-0.1e1 / 0.2e1) * (x / theta) ^ alpha * alpha / x * exp(-(x / theta) ^ (2 * alpha) / 2))
and 
d2 <- D(D(fc, "alpha"), "alpha")
I would like to create a function formed by the product of fc and d2. I tried:
fcd2 <- function(x) {}
body(fcd2) <- c(d2, "*", fc)
but I did not succeed. Any suggestion is welcome.
Best regards
ML 		 	   		  
	[[alternative HTML version deleted]]


From c.puschmann at student.unsw.edu.au  Sat Oct  1 11:42:53 2016
From: c.puschmann at student.unsw.edu.au (Christoph Puschmann)
Date: Sat, 1 Oct 2016 09:42:53 +0000
Subject: [R] Bootstrapping in R
In-Reply-To: <419da17b-e37e-4fd0-e360-1abb856a54f1@dewey.myzen.co.uk>
References: <20160929201655.Horde.3eE2mopuZGp8trrU2jNt_Pt@mail.sapo.pt>
	<4F7BC824-B9E1-44E9-851A-579AC53CBED1@gmail.com>
	<419da17b-e37e-4fd0-e360-1abb856a54f1@dewey.myzen.co.uk>
Message-ID: <07DCF831-B54C-490E-838D-1FD12EB357FA@ad.unsw.edu.au>

Dear Bryan,

Did you try to include formula in the boot command? like: 

results <- boot(data, statistic, R, formula) 

All the best,

Christoph

> On 1 Oct 2016, at 19:24, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> 
> Dear Bryan
> 
> You are not resetting the seed each time by any chance?
> 
> Michael
> 
> On 01/10/2016 02:44, Bryan Mac wrote:
>> Hi,
>> 
>> I have read the help page and it was helpful but, I am having concerns because each time I run this code I get the same value.
>> I expected that each time I run the code, I will get different values due to random sampling.
>> 
>> How do I get this randomization? The values shouldn?t be the same each time the code is run, correct?
>> 
>> 
>> result <- boot(n_data, statistic = DataSummary, R = 100).
>> 
>> 
>> Best,
>> 
>> Bryan Mac
>> bryanmac.24 at gmail.com
>> 
>> 
>> 
>>> On Sep 29, 2016, at 12:16 PM, ruipbarradas at sapo.pt wrote:
>>> 
>>> Hello,
>>> 
>>> Read the help page ?boot::boot.
>>> For instance, try the following.
>>> 
>>> 
>>> library(boot)
>>> 
>>> x <- rnorm(100)
>>> stat <- function(x, f) mean(x[f])
>>> boot(x, stat, R = 100)
>>> 
>>> Hope this helps,
>>> 
>>> Rui Barradas
>>> 
>>> 
>>> 
>>> Citando bryan.mac24 <bryan.mac24 at gmail.com>:
>>> 
>>>> Hi all,
>>>> I am wondering how to conduct bootstrapping in R. I need bootstrap 100 times. The trick I need to figure out is how to do get a random sample of 100 out of the total number of case.
>>>> Best,
>>>> BM
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sat Oct  1 11:49:30 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Sat, 01 Oct 2016 10:49:30 +0100
Subject: [R] Bootstrapping in R
In-Reply-To: <07DCF831-B54C-490E-838D-1FD12EB357FA@ad.unsw.edu.au>
References: <20160929201655.Horde.3eE2mopuZGp8trrU2jNt_Pt@mail.sapo.pt>
	<4F7BC824-B9E1-44E9-851A-579AC53CBED1@gmail.com>
	<419da17b-e37e-4fd0-e360-1abb856a54f1@dewey.myzen.co.uk>
	<07DCF831-B54C-490E-838D-1FD12EB357FA@ad.unsw.edu.au>
Message-ID: <20161001104930.Horde.F4UoSJ6WzJtX74aqYf8iT7A@mail.sapo.pt>

Sorry, but what formula? formula is not a ?boot argument.
To the OP: Michael is probably right, if you reset the seed each time,  
you'll get equal values, otherwise you should get different results  
due to randomization.

Rui Barradas


Quoting Christoph Puschmann <c.puschmann at student.unsw.edu.au>:

> Dear Bryan,
>
> Did you try to include formula in the boot command? like:
>
> results <- boot(data, statistic, R, formula)
>
> All the best,
>
> Christoph
>
>> On 1 Oct 2016, at 19:24, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>>
>> Dear Bryan
>>
>> You are not resetting the seed each time by any chance?
>>
>> Michael
>>
>> On 01/10/2016 02:44, Bryan Mac wrote:
>>> Hi,
>>>
>>> I have read the help page and it was helpful but, I am having  
>>> concerns because each time I run this code I get the same value.
>>> I expected that each time I run the code, I will get different  
>>> values due to random sampling.
>>>
>>> How do I get this randomization? The values shouldn?t be the same  
>>> each time the code is run, correct?
>>>
>>>
>>> result <- boot(n_data, statistic = DataSummary, R = 100).
>>>
>>>
>>> Best,
>>>
>>> Bryan Mac
>>> bryanmac.24 at gmail.com
>>>
>>>
>>>
>>>> On Sep 29, 2016, at 12:16 PM, ruipbarradas at sapo.pt wrote:
>>>>
>>>> Hello,
>>>>
>>>> Read the help page ?boot::boot.
>>>> For instance, try the following.
>>>>
>>>>
>>>> library(boot)
>>>>
>>>> x <- rnorm(100)
>>>> stat <- function(x, f) mean(x[f])
>>>> boot(x, stat, R = 100)
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>>
>>>>
>>>> Citando bryan.mac24 <bryan.mac24 at gmail.com>:
>>>>
>>>>> Hi all,
>>>>> I am wondering how to conduct bootstrapping in R. I need  
>>>>> bootstrap 100 times. The trick I need to figure out is how to do  
>>>>> get a random sample of 100 out of the total number of case.
>>>>> Best,
>>>>> BM
>>>>> 	[[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide  
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide  
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> --
>> Michael
>> http://www.dewey.myzen.co.uk/home.html
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From c.puschmann at student.unsw.edu.au  Sat Oct  1 12:36:58 2016
From: c.puschmann at student.unsw.edu.au (Christoph Puschmann)
Date: Sat, 1 Oct 2016 10:36:58 +0000
Subject: [R] Bootstrapping in R
In-Reply-To: <20161001104930.Horde.F4UoSJ6WzJtX74aqYf8iT7A@mail.sapo.pt>
References: <20160929201655.Horde.3eE2mopuZGp8trrU2jNt_Pt@mail.sapo.pt>
	<4F7BC824-B9E1-44E9-851A-579AC53CBED1@gmail.com>
	<419da17b-e37e-4fd0-e360-1abb856a54f1@dewey.myzen.co.uk>
	<07DCF831-B54C-490E-838D-1FD12EB357FA@ad.unsw.edu.au>
	<20161001104930.Horde.F4UoSJ6WzJtX74aqYf8iT7A@mail.sapo.pt>
Message-ID: <449E1BBD-994C-46DE-AF5C-1D50200377D5@ad.unsw.edu.au>

Dear Rui,

You can insert a ?formula? argument in the code. For example, if you boot a regression, you can insert the formula in the command. Though I just realised that it is not necessary to do.

All the best,

Christoph


> On 1 Oct 2016, at 19:49, ruipbarradas at sapo.pt wrote:
> 
> Sorry, but what formula? formula is not a ?boot argument.
> To the OP: Michael is probably right, if you reset the seed each time, you'll get equal values, otherwise you should get different results due to randomization.
> 
> Rui Barradas
> 
> 
> Quoting Christoph Puschmann <c.puschmann at student.unsw.edu.au>:
> 
>> Dear Bryan,
>> 
>> Did you try to include formula in the boot command? like:
>> 
>> results <- boot(data, statistic, R, formula)
>> 
>> All the best,
>> 
>> Christoph
>> 
>>> On 1 Oct 2016, at 19:24, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>>> 
>>> Dear Bryan
>>> 
>>> You are not resetting the seed each time by any chance?
>>> 
>>> Michael
>>> 
>>> On 01/10/2016 02:44, Bryan Mac wrote:
>>>> Hi,
>>>> 
>>>> I have read the help page and it was helpful but, I am having concerns because each time I run this code I get the same value.
>>>> I expected that each time I run the code, I will get different values due to random sampling.
>>>> 
>>>> How do I get this randomization? The values shouldn?t be the same each time the code is run, correct?
>>>> 
>>>> 
>>>> result <- boot(n_data, statistic = DataSummary, R = 100).
>>>> 
>>>> 
>>>> Best,
>>>> 
>>>> Bryan Mac
>>>> bryanmac.24 at gmail.com
>>>> 
>>>> 
>>>> 
>>>>> On Sep 29, 2016, at 12:16 PM, ruipbarradas at sapo.pt wrote:
>>>>> 
>>>>> Hello,
>>>>> 
>>>>> Read the help page ?boot::boot.
>>>>> For instance, try the following.
>>>>> 
>>>>> 
>>>>> library(boot)
>>>>> 
>>>>> x <- rnorm(100)
>>>>> stat <- function(x, f) mean(x[f])
>>>>> boot(x, stat, R = 100)
>>>>> 
>>>>> Hope this helps,
>>>>> 
>>>>> Rui Barradas
>>>>> 
>>>>> 
>>>>> 
>>>>> Citando bryan.mac24 <bryan.mac24 at gmail.com>:
>>>>> 
>>>>>> Hi all,
>>>>>> I am wondering how to conduct bootstrapping in R. I need bootstrap 100 times. The trick I need to figure out is how to do get a random sample of 100 out of the total number of case.
>>>>>> Best,
>>>>>> BM
>>>>>> 	[[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> 
>>>>> 
>>>> 
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> --
>>> Michael
>>> http://www.dewey.myzen.co.uk/home.html
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> 


From dwinsemius at comcast.net  Sat Oct  1 17:42:01 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 1 Oct 2016 08:42:01 -0700
Subject: [R] concatenating text within a function
In-Reply-To: <BLU175-W186795A771E8CA19E1BFA996C00@phx.gbl>
References: <BLU175-W186795A771E8CA19E1BFA996C00@phx.gbl>
Message-ID: <C4B13286-B1AA-4456-BA84-318EB6769E3B@comcast.net>


> On Oct 1, 2016, at 7:45 AM, L... L... <mar.lamack at hotmail.com> wrote:
> 
> Dear all, I have the following variables:
> fc	<-	quote(sqrt(2) * pi ^ (-0.1e1 / 0.2e1) * (x / theta) ^ alpha * alpha / x * exp(-(x / theta) ^ (2 * alpha) / 2))
> and 
> d2 <- D(D(fc, "alpha"), "alpha")
> I would like to create a function formed by the product of fc and d2. I tried:
> fcd2 <- function(x) {}
> body(fcd2) <- c(d2, "*", fc)

Try instead using bquote to get an expression object:

> bquote( .(fc) * .(d2) )
sqrt(2) * pi^(-1/2) * (x/theta)^alpha * alpha/x * exp(-(x/theta)^(2 * 
    alpha)/2) * ((sqrt(2) * pi^(-1/2) * ((x/theta)^alpha * log((x/theta)) * 
    log((x/theta))) * alpha + sqrt(2) * pi^(-1/2) * ((x/theta)^alpha * 
    log((x/theta))) + sqrt(2) * pi^(-1/2) * ((x/theta)^alpha * 
    log((x/theta))))/x * exp(-(x/theta)^(2 * alpha)/2) - (sqrt(2) * 
    pi^(-1/2) * ((x/theta)^alpha * log((x/theta))) * alpha + 
    sqrt(2) * pi^(-1/2) * (x/theta)^alpha)/x * (exp(-(x/theta)^(2 * 
    alpha)/2) * ((x/theta)^(2 * alpha) * (log((x/theta)) * 2)/2)) - 
    ((sqrt(2) * pi^(-1/2) * ((x/theta)^alpha * log((x/theta))) * 
        alpha + sqrt(2) * pi^(-1/2) * (x/theta)^alpha)/x * (exp(-(x/theta)^(2 * 
        alpha)/2) * ((x/theta)^(2 * alpha) * (log((x/theta)) * 
        2)/2)) + sqrt(2) * pi^(-1/2) * (x/theta)^alpha * alpha/x * 
        (exp(-(x/theta)^(2 * alpha)/2) * ((x/theta)^(2 * alpha) * 
            (log((x/theta)) * 2) * (log((x/theta)) * 2)/2) - 
            exp(-(x/theta)^(2 * alpha)/2) * ((x/theta)^(2 * alpha) * 
                (log((x/theta)) * 2)/2) * ((x/theta)^(2 * alpha) * 
                (log((x/theta)) * 2)/2))))

> fcd2 <- function(x) {}
> body(fcd2) <- bquote( .(fc) * .(d2) )
> fcd2
function (x) 
sqrt(2) * pi^(-1/2) * (x/theta)^alpha * alpha/x * exp(-(x/theta)^(2 * 
    alpha)/2) * ((sqrt(2) * pi^(-1/2) * ((x/theta)^alpha * log((x/theta)) * 
    log((x/theta))) * alpha + sqrt(2) * pi^(-1/2) * ((x/theta)^alpha * 
    log((x/theta))) + sqrt(2) * pi^(-1/2) * ((x/theta)^alpha * 
    log((x/theta))))/x * exp(-(x/theta)^(2 * alpha)/2) - (sqrt(2) * 
    pi^(-1/2) * ((x/theta)^alpha * log((x/theta))) * alpha + 
    sqrt(2) * pi^(-1/2) * (x/theta)^alpha)/x * (exp(-(x/theta)^(2 * 
    alpha)/2) * ((x/theta)^(2 * alpha) * (log((x/theta)) * 2)/2)) - 
    ((sqrt(2) * pi^(-1/2) * ((x/theta)^alpha * log((x/theta))) * 
        alpha + sqrt(2) * pi^(-1/2) * (x/theta)^alpha)/x * (exp(-(x/theta)^(2 * 
        alpha)/2) * ((x/theta)^(2 * alpha) * (log((x/theta)) * 
        2)/2)) + sqrt(2) * pi^(-1/2) * (x/theta)^alpha * alpha/x * 
        (exp(-(x/theta)^(2 * alpha)/2) * ((x/theta)^(2 * alpha) * 
            (log((x/theta)) * 2) * (log((x/theta)) * 2)/2) - 
            exp(-(x/theta)^(2 * alpha)/2) * ((x/theta)^(2 * alpha) * 
                (log((x/theta)) * 2)/2) * ((x/theta)^(2 * alpha) * 
                (log((x/theta)) * 2)/2))))



> but I did not succeed. Any suggestion is welcome.
> Best regards
> ML 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jan.kacaba at gmail.com  Sat Oct  1 17:44:50 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Sat, 1 Oct 2016 17:44:50 +0200
Subject: [R] strange output of cat function used in recursive function
Message-ID: <CAHby=D2EGHUf_6=D5oia58m9zE3d3O9oMCQRY+uN-SeCrPhZLg@mail.gmail.com>

Hello Dear R-help

I  tried to understand how recursive programming works in R. Bellow is
simple recursive function.

binary1 <- function(n) {
  if(n > 1) {
    binary(as.integer(n/2))
  }
  cat(n %% 2)
}
When I call binary1(10) I get 1010. I believe that cat function stores
value to a buffer appending values as recursion proceeds and at the
end it prints the buffer. Am I right?

I tried to modify the function to get some understanding:

binary2 <- function(n) {
  if(n > 1) {
    binary2(as.integer(n/2))
  }
  cat(n %% 2, sep=",")
}

With call binary2(10) I get also 1010. Why the output is not separated
by commas?

If I use in binary2 function cat(n %% 2, ",") on last line, the output
is separated. Outside recursive function the cat function prints
separated output in both cases e.g. cat(c(1:10), sep=",") and
cat(c(1:10), ",")

Derek


From dwinsemius at comcast.net  Sat Oct  1 17:50:01 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 1 Oct 2016 08:50:01 -0700
Subject: [R] Rearranging sub-folders, how?
In-Reply-To: <CY1PR13MB014231CEAFDDCFF5B623B06AFAC00@CY1PR13MB0142.namprd13.prod.outlook.com>
References: <CY1PR13MB01422B76FBC5297311ACAB47FAC00@CY1PR13MB0142.namprd13.prod.outlook.com>
	<CA+8X3fU3qH3jS_JHq=Zjg8_WFNMWNbJnjeHqPjDpizWEg1=2Uw@mail.gmail.com>
	<CY1PR13MB014231CEAFDDCFF5B623B06AFAC00@CY1PR13MB0142.namprd13.prod.outlook.com>
Message-ID: <5D28BF12-0509-48DF-8D86-9807A8727CA1@comcast.net>


> On Oct 1, 2016, at 5:50 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> 
> Thanks Jim for the suggestions.
> 
> I used following but it seems not working
> 
> dir.create(foldA\subFoldB\subFoldD\subFoldC\subFoldE)

In R character values need to be quoted and backslashes need to be escaped ... with backslashes. Read the R-FAQ:

https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-does-backslash-behave-strangely-inside-strings_003f


-- 
david.

> 
> I got a trouble in moving contents of one folder to another.
> 
> ________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: October 1, 2016 6:07 AM
> To: Kristi Glover
> Cc: r-help at r-project.org
> Subject: Re: [R] Rearranging sub-folders, how?
> 
> Hi Kristi,
> I assume that B, C and D are not empty, otherwise the answer is trivial.
> 
> create a directory under B named D
> move the contents of the old D to the new D
> delete the directory E beneath the new D
> create a new directory C under the new D
> move the contents of the old C to the new C
> recursively delete D under the new C
> move the old E under the new C
> recursively delete the old C
> 
> Jim
> 
> 
> On Sat, Oct 1, 2016 at 9:29 PM, Kristi Glover <kristi.glover at hotmail.com> wrote:
>> Hi R user,
>> 
>> I was wondering how we can rearrange the folders in R. for example
>> 
>> original data has been put with the following arrangement:
>> 
>> foldA\subFoldB\subFoldC\subFoldD\subFoldE\
>> 
>> 
>> SubFoldE contains several dataset
>> 
>> 
>> I want to rearrange the subFoldE into following sequence:
>> 
>> 
>> foldA\subFoldB\subFoldD\subFoldC\subFoldE\
>> 
>> 
>> Any suggestions?
>> 
>> Thanks
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Oct  1 18:02:03 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 1 Oct 2016 09:02:03 -0700
Subject: [R] strange output of cat function used in recursive function
In-Reply-To: <CAHby=D2EGHUf_6=D5oia58m9zE3d3O9oMCQRY+uN-SeCrPhZLg@mail.gmail.com>
References: <CAHby=D2EGHUf_6=D5oia58m9zE3d3O9oMCQRY+uN-SeCrPhZLg@mail.gmail.com>
Message-ID: <45EE6BD6-CABD-4446-8718-4107A661F347@comcast.net>


> On Oct 1, 2016, at 8:44 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
> 
> Hello Dear R-help
> 
> I  tried to understand how recursive programming works in R. Bellow is
> simple recursive function.
> 
> binary1 <- function(n) {
>  if(n > 1) {
>    binary(as.integer(n/2))
>  }
>  cat(n %% 2)
> }

Did you mean to type "binary1(as.integer(n)"?

> When I call binary1(10) I get 1010. I believe that cat function stores
> value to a buffer appending values as recursion proceeds and at the
> end it prints the buffer. Am I right?

No. Read the ?cat help page. It returns NULL. The material you see at the console is a side-effect.
> 
> I tried to modify the function to get some understanding:
> 
> binary2 <- function(n) {
>  if(n > 1) {
>    binary2(as.integer(n/2))
>  }
>  cat(n %% 2, sep=",")
> }
> 
> With call binary2(10) I get also 1010. Why the output is not separated
> by commas?

I think because there is nothing to separate when it prints (since there was no "buffer".

> 
> If I use in binary2 function cat(n %% 2, ",") on last line, the output
> is separated. Outside recursive function the cat function prints
> separated output in both cases e.g. cat(c(1:10), sep=",") and
> cat(c(1:10), ",")
> 
> Derek
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jan.kacaba at gmail.com  Sat Oct  1 18:29:25 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Sat, 1 Oct 2016 18:29:25 +0200
Subject: [R] strange output of cat function used in recursive function
In-Reply-To: <45EE6BD6-CABD-4446-8718-4107A661F347@comcast.net>
References: <CAHby=D2EGHUf_6=D5oia58m9zE3d3O9oMCQRY+uN-SeCrPhZLg@mail.gmail.com>
	<45EE6BD6-CABD-4446-8718-4107A661F347@comcast.net>
Message-ID: <CAHby=D3vhScjWT2tQ6G6rzRSdL=CVZ+G6HYWy_UTcM+c4VQTrg@mail.gmail.com>

2016-10-01 18:02 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:
>
>> On Oct 1, 2016, at 8:44 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>>
>> Hello Dear R-help
>>
>> I  tried to understand how recursive programming works in R. Bellow is
>> simple recursive function.
>>
>> binary1 <- function(n) {
>>  if(n > 1) {
>>    binary(as.integer(n/2))
>>  }
>>  cat(n %% 2)
>> }
>
> Did you mean to type "binary1(as.integer(n)"?

Yes I meant that.

>> When I call binary1(10) I get 1010. I believe that cat function stores
>> value to a buffer appending values as recursion proceeds and at the
>> end it prints the buffer. Am I right?
>
> No. Read the ?cat help page. It returns NULL. The material you see at the console is a side-effect.
>>
>> I tried to modify the function to get some understanding:
>>
>> binary2 <- function(n) {
>>  if(n > 1) {
>>    binary2(as.integer(n/2))
>>  }
>>  cat(n %% 2, sep=",")
>> }
>>
>> With call binary2(10) I get also 1010. Why the output is not separated
>> by commas?
>
> I think because there is nothing to separate when it prints (since there was no "buffer".

If I use function:
binary3 <- function(n) {
if(n > 1) {
   binary3(as.integer(n/2))
  }
   cat(n %% 2, ",")
 }

and call binary3(10) the console output is separated. So there must be
some kind of buffer and also it looks like there is some inconsistency
in how cat function behaves. Probably there is other explanation.


From dwinsemius at comcast.net  Sat Oct  1 18:39:50 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 1 Oct 2016 09:39:50 -0700
Subject: [R] strange output of cat function used in recursive function
In-Reply-To: <CAHby=D3vhScjWT2tQ6G6rzRSdL=CVZ+G6HYWy_UTcM+c4VQTrg@mail.gmail.com>
References: <CAHby=D2EGHUf_6=D5oia58m9zE3d3O9oMCQRY+uN-SeCrPhZLg@mail.gmail.com>
	<45EE6BD6-CABD-4446-8718-4107A661F347@comcast.net>
	<CAHby=D3vhScjWT2tQ6G6rzRSdL=CVZ+G6HYWy_UTcM+c4VQTrg@mail.gmail.com>
Message-ID: <AB9D6518-4B04-4625-A42F-97771056278C@comcast.net>


> On Oct 1, 2016, at 9:29 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
> 
> 2016-10-01 18:02 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:
>> 
>>> On Oct 1, 2016, at 8:44 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>>> 
>>> Hello Dear R-help
>>> 
>>> I  tried to understand how recursive programming works in R. Bellow is
>>> simple recursive function.
>>> 
>>> binary1 <- function(n) {
>>> if(n > 1) {
>>>   binary(as.integer(n/2))
>>> }
>>> cat(n %% 2)
>>> }
>> 
>> Did you mean to type "binary1(as.integer(n)"?
> 
> Yes I meant that.
> 
>>> When I call binary1(10) I get 1010. I believe that cat function stores
>>> value to a buffer appending values as recursion proceeds and at the
>>> end it prints the buffer. Am I right?
>> 
>> No. Read the ?cat help page. It returns NULL. The material you see at the console is a side-effect.
>>> 
>>> I tried to modify the function to get some understanding:
>>> 
>>> binary2 <- function(n) {
>>> if(n > 1) {
>>>   binary2(as.integer(n/2))
>>> }
>>> cat(n %% 2, sep=",")
>>> }
>>> 
>>> With call binary2(10) I get also 1010. Why the output is not separated
>>> by commas?
>> 
>> I think because there is nothing to separate when it prints (since there was no "buffer".
> 
> If I use function:
> binary3 <- function(n) {
> if(n > 1) {
>   binary3(as.integer(n/2))
>  }
>   cat(n %% 2, ",")
> }
> 
> and call binary3(10) the console output is separated. So there must be
> some kind of buffer and also it looks like there is some inconsistency
> in how cat function behaves. Probably there is other explanation.

The only inconsistency is how you sent arguments to cat. In the first instance you asked cat to display a single character value (and to separate multiple characters _if_present_ with a comma, .... but there were never any instances of a cat call with multiple arguments).

In the second instance you told it to display single character values followed by a comma and it did that 4 times when the argument to the enclosing function was a decimal 10.

If by buffer you mean the console stream, then I suppose I misunderstood your use of the term.

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Oct  1 18:46:31 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 1 Oct 2016 09:46:31 -0700
Subject: [R] strange output of cat function used in recursive function
In-Reply-To: <AB9D6518-4B04-4625-A42F-97771056278C@comcast.net>
References: <CAHby=D2EGHUf_6=D5oia58m9zE3d3O9oMCQRY+uN-SeCrPhZLg@mail.gmail.com>
	<45EE6BD6-CABD-4446-8718-4107A661F347@comcast.net>
	<CAHby=D3vhScjWT2tQ6G6rzRSdL=CVZ+G6HYWy_UTcM+c4VQTrg@mail.gmail.com>
	<AB9D6518-4B04-4625-A42F-97771056278C@comcast.net>
Message-ID: <DC1D8A8E-C415-4665-970E-9C4ED24A88B8@comcast.net>


> On Oct 1, 2016, at 9:39 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Oct 1, 2016, at 9:29 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>> 
>> 2016-10-01 18:02 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:
>>> 
>>>> On Oct 1, 2016, at 8:44 AM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>>>> 
>>>> Hello Dear R-help
>>>> 
>>>> I  tried to understand how recursive programming works in R. Bellow is
>>>> simple recursive function.
>>>> 
>>>> binary1 <- function(n) {
>>>> if(n > 1) {
>>>>  binary(as.integer(n/2))
>>>> }
>>>> cat(n %% 2)
>>>> }
>>> 
>>> Did you mean to type "binary1(as.integer(n)"?
>> 
>> Yes I meant that.
>> 
>>>> When I call binary1(10) I get 1010. I believe that cat function stores
>>>> value to a buffer appending values as recursion proceeds and at the
>>>> end it prints the buffer. Am I right?
>>> 
>>> No. Read the ?cat help page. It returns NULL. The material you see at the console is a side-effect.
>>>> 
>>>> I tried to modify the function to get some understanding:
>>>> 
>>>> binary2 <- function(n) {
>>>> if(n > 1) {
>>>>  binary2(as.integer(n/2))
>>>> }
>>>> cat(n %% 2, sep=",")
>>>> }
>>>> 
>>>> With call binary2(10) I get also 1010. Why the output is not separated
>>>> by commas?
>>> 
>>> I think because there is nothing to separate when it prints (since there was no "buffer".
>> 
>> If I use function:
>> binary3 <- function(n) {
>> if(n > 1) {
>>  binary3(as.integer(n/2))
>> }
>>  cat(n %% 2, ",")
>> }
>> 
>> and call binary3(10) the console output is separated. So there must be
>> some kind of buffer and also it looks like there is some inconsistency
>> in how cat function behaves. Probably there is other explanation.
> 
> The only inconsistency is how you sent arguments to cat. In the first instance you asked cat to display a single character value (and to separate multiple characters _if_present_ with a comma, .... but there were never any instances of a cat call with multiple arguments).
> 
> In the second instance you told it to display single character values followed by a comma and it did that 4 times when the argument to the enclosing function was a decimal 10.
> 
> If by buffer you mean the console stream, then I suppose I misunderstood your use of the term.

On the matter of a buffer, there is output buffering and a flush.console() function. The only way I could get a regursive function to demonstrate a  pause between output with Sys.sleep was to instead use the Recall function:

?Recall
binary4 <- function(n) {
              if(n > 1) {
                   Recall(as.integer(n/2))
                        }
              cat(n %% 2, ","); flush.console(); Sys.sleep(2)
              }

# halting 2 seconds between each appearance of a digit followed by a comma:

> binary4(10)
1 ,0 ,1 ,0 ,


> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From therneau at mayo.edu  Sun Oct  2 04:44:15 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Sun, 02 Oct 2016 02:44:15 +0000
Subject: [R] isssues with predict.coxph, offset, type = "expected",
	and newdata
Message-ID: <021cdb$4h19mb@ironport10.mayo.edu>

I'm off on vacation and checking email only intermittently.   
Wrt the offset issue, I expect that you are correct.  This is not a case that I had ever envisioned, and so was not on my "list" when writing the code and certainly has no test case.  That does not mean that it shouldn't work, just that I am not shocked to see it.   I will look into this.

For the second case of a NULL model I am less sympathetic.  This is, in theory, just reading off values from a Nelson hazard estimate at specific time points; using a coxph call to do so is a case of swatting a fly with a hammer.   A bit more background might make me more excited about extending the code to this case.

Terry Therneau


From jeff.roemer at gmail.com  Sat Oct  1 18:23:18 2016
From: jeff.roemer at gmail.com (=?utf-8?Q?Jeff_R=C3=B8mer?=)
Date: Sat, 1 Oct 2016 18:23:18 +0200
Subject: [R] I get only NA values into my loop - Need to find mean of max
 CR_Art per Experiment per Mussel
Message-ID: <57efe2f5.a914190a.3ff03.b2d3@mx.google.com>


Importing datafile "Raadata.csv" 
(Headers: Treatment, Mussel, Experiment, Interval, CR_Art, CR_Rho, CHR??_Art, FR_C_Art , CHR_Rho, FR_C_Rho). 
Some fields are empty. Not all treatments have values in all columns. 
read.csv2 is used because of European standards, I have to convert comma to dot.
    Max_CR_FR <- read.csv2(file="Raadata.csv", header=T, sep=";",skipNul=TRUE)
Grouping data by Mussel & Experiment:
    Max_CR_FR$Group= factor(paste(Max_CR_FR$Mussel, Max_CR_FR$Experiment))
Selecting on treatment and de-selecting?CR_Art?with NA:
    Art=subset(Max_CR_FR, Treatment=="Artemia" & !is.na(Max_CR_FR$CR_Art))
Everything works fine until here at least?
Calculating the mean of maximum values of CR_Art for each group:
    F<-function(Data){
    Exp_max=tapply(Data$CR_Art, Data$Group, max, na.rm=TRUE)
    mean(Exp_max)
    }
Bootstrapping:
    boots=list()
    for(i in 1:1000) boots[[i]]=Art[ sample.int(nrow(Art),replace=TRUE) ,]
    means= lapply( boots, F)
    meanstab = do.call(rbind,means)
Intervals of probability:
    apply(meanstab,2,quantile,probs=c(0.025,0.975),na.rm=TRUE)

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 7C05F919DB1B4B869011925C3906D1E6.png
Type: image/png
Size: 15867 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161001/5ddda036/attachment.png>

From suman4apr at gmail.com  Sat Oct  1 19:58:13 2016
From: suman4apr at gmail.com (suman4apr at gmail.com)
Date: Sat, 1 Oct 2016 23:28:13 +0530
Subject: [R] installation error
Message-ID: <57eff93c.cfae420a.d8718.c308@mx.google.com>

Hello,

I?m suman kumar. I am trying to use ?syuzhet? packages and already installed it but when using it then facing some error.
I have run these codes but in second line, it is showing errors.

library(syuzhet)
textdata= get_text_as_string("G:/SEM-3/DSE-PROJECT/AGASHIYEmain.txt")
s_v = get_sentences(textdata)
s_v


errors:-
Error: .onLoad failed in loadNamespace() for 'rJava', details:
  call: fun(libname, pkgname)
  error: JAVA_HOME cannot be determined from the Registry


please help me to remove this error. Thanks in advance.

Thanks
Suman kumar 

Sent from Mail for Windows 10


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Oct  2 10:26:16 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 2 Oct 2016 01:26:16 -0700
Subject: [R] installation error
In-Reply-To: <57eff93c.cfae420a.d8718.c308@mx.google.com>
References: <57eff93c.cfae420a.d8718.c308@mx.google.com>
Message-ID: <B66409C3-5109-4DD0-AA78-760E1AB6B33A@comcast.net>


> On Oct 1, 2016, at 10:58 AM, <suman4apr at gmail.com> <suman4apr at gmail.com> wrote:
> 
> Hello,
> 
> I?m suman kumar. I am trying to use ?syuzhet? packages and already installed it but when using it then facing some error.
> I have run these codes but in second line, it is showing errors.
> 
> library(syuzhet)
> textdata= get_text_as_string("G:/SEM-3/DSE-PROJECT/AGASHIYEmain.txt")
> s_v = get_sentences(textdata)
> s_v
> 
> 
> errors:-
> Error: .onLoad failed in loadNamespace() for 'rJava', details:
>  call: fun(libname, pkgname)
>  error: JAVA_HOME cannot be determined from the Registry
> 
> 
> please help me to remove this error. Thanks in advance.

You have not provided enough information. How did you install Java? Or did you?
> 
> Thanks
> Suman kumar 
> 
> Sent from Mail for Windows 10
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Sun Oct  2 12:11:49 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 2 Oct 2016 12:11:49 +0200
Subject: [R] Bootstrapping in R
In-Reply-To: <1bb2778d-72ca-8bf7-1953-2015240fb47a@gmail.com>
References: <20160929201655.Horde.3eE2mopuZGp8trrU2jNt_Pt@mail.sapo.pt>
	<4F7BC824-B9E1-44E9-851A-579AC53CBED1@gmail.com>
	<1bb2778d-72ca-8bf7-1953-2015240fb47a@gmail.com>
Message-ID: <019A773B-8E05-44B8-893B-5EE07EB0C748@gmail.com>


> On 01 Oct 2016, at 16:11 , Daniel Nordlund <djnordlund at gmail.com> wrote:
> 
> You haven't told us anything about the structure of your data, or the definition of the DataSummary function.

Yes. Just let me add that a common error with boot() is not to pay attention to the required form of the statistic= function argument. It should depend on the data and a set of indices and (for nonparametic bootstrap) it is the indices that are random. 

Typical mistakes are to completely ignore the index argument, or to write clumsy code that ignores the data specification, as in 
coef(lm(df$y~df$x, data=d[f])).


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mashranga at yahoo.com  Sun Oct  2 12:40:49 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Sun, 2 Oct 2016 10:40:49 +0000 (UTC)
Subject: [R] Convert a list with NULL to a dataframe with NA
References: <183645276.2888105.1475404849516.ref@mail.yahoo.com>
Message-ID: <183645276.2888105.1475404849516@mail.yahoo.com>

Hi, 

I have a list like below. 

OB1 <- structure(list(aa0 = NULL, 
aa1 = structure("23403", .Names = "BB10"), 
aa2 = structure("54904", .Names = "BB20"), 
aa3 = structure("22897", .Names = "BB30"), 
aa4 = structure("3751", .Names = "BB40"), 
aa5 = NULL, 
aa6 = structure("3679", .Names = "BB50"), 
aa7 = structure("440193", .Names = "BB60"), 
aa8 = structure("23144", .Names = "BB70"), 
aa9 = structure("84667", .Names = "BB80"), 
aa10 = structure("130540", .Names = "BB90")), 
.Names = c("aa0", "aa1", "aa2", "aa3", 
"aa4", "aa5", "aa6", "aa7", 
"aa8", "aa9", "aa10"))

I am expecting an output like below
OB2 <- structure(list(V1 = structure(c(3L, 5L, 8L, 1L, 4L, 2L, 10L, 
7L, 9L, 11L, 6L), .Label = c("aa3", "aa5", "aa0", 
"aa4", "aa1", "aa10", "aa7", "aa2", 
"aa8", "aa6", "aa9"), class = "factor"), 
id = structure(c(NA, 4L, 8L, 2L, 6L, NA, 5L, 7L, 3L, 9L, 
1L), .Label = c("130540", "22897", "23144", "23403", "3679", 
"3751", "440193", "54904", "84667"), class = "factor"), nam = structure(c(NA, 
4L, 8L, 3L, 7L, NA, 6L, 2L, 9L, 5L, 1L), .Label = c("BB90", 
"BB60", "BB30", "BB10", "BB80", "BB50", "BB40", 
"BB20", "BB70"), class = "factor")), .Names = c("V1", 
"id", "nam"), row.names = c(NA, -11L), class = "data.frame")

Problems :
1. Get OB1 to OB2
2. Get OB2 to OB1

I  will be great-full if anyone can share idea how to solve the problem .
Thanks in advance !!



 
Tanvir Ahamed 
G?teborg, Sweden  |  mashranga at yahoo.com 


From bob at rud.is  Sun Oct  2 12:55:02 2016
From: bob at rud.is (Bob Rudis)
Date: Sun, 2 Oct 2016 06:55:02 -0400
Subject: [R] Convert a list with NULL to a dataframe with NA
In-Reply-To: <183645276.2888105.1475404849516@mail.yahoo.com>
References: <183645276.2888105.1475404849516.ref@mail.yahoo.com>
	<183645276.2888105.1475404849516@mail.yahoo.com>
Message-ID: <CAA-FpKWLMQV=qErcp8gSRusnfcZ+bWqSScDM0JfyZA7xKRQM6g@mail.gmail.com>

It's fairly straightforward with help from the purrr package:

library(purrr)

map_df(OB1, function(x) {
  if (length(x) == 0) {
    data.frame(id=NA_character_, nam=NA_character_, stringsAsFactors=FALSE)
  } else {
    data.frame(id=x[1], nam=names(x), stringsAsFactors=FALSE)
  }
}, .id="V1")



On Sun, Oct 2, 2016 at 6:40 AM, Mohammad Tanvir Ahamed via R-help <
r-help at r-project.org> wrote:

> Hi,
>
> I have a list like below.
>
> OB1 <- structure(list(aa0 = NULL,
> aa1 = structure("23403", .Names = "BB10"),
> aa2 = structure("54904", .Names = "BB20"),
> aa3 = structure("22897", .Names = "BB30"),
> aa4 = structure("3751", .Names = "BB40"),
> aa5 = NULL,
> aa6 = structure("3679", .Names = "BB50"),
> aa7 = structure("440193", .Names = "BB60"),
> aa8 = structure("23144", .Names = "BB70"),
> aa9 = structure("84667", .Names = "BB80"),
> aa10 = structure("130540", .Names = "BB90")),
> .Names = c("aa0", "aa1", "aa2", "aa3",
> "aa4", "aa5", "aa6", "aa7",
> "aa8", "aa9", "aa10"))
>
> I am expecting an output like below
> OB2 <- structure(list(V1 = structure(c(3L, 5L, 8L, 1L, 4L, 2L, 10L,
> 7L, 9L, 11L, 6L), .Label = c("aa3", "aa5", "aa0",
> "aa4", "aa1", "aa10", "aa7", "aa2",
> "aa8", "aa6", "aa9"), class = "factor"),
> id = structure(c(NA, 4L, 8L, 2L, 6L, NA, 5L, 7L, 3L, 9L,
> 1L), .Label = c("130540", "22897", "23144", "23403", "3679",
> "3751", "440193", "54904", "84667"), class = "factor"), nam =
> structure(c(NA,
> 4L, 8L, 3L, 7L, NA, 6L, 2L, 9L, 5L, 1L), .Label = c("BB90",
> "BB60", "BB30", "BB10", "BB80", "BB50", "BB40",
> "BB20", "BB70"), class = "factor")), .Names = c("V1",
> "id", "nam"), row.names = c(NA, -11L), class = "data.frame")
>
> Problems :
> 1. Get OB1 to OB2
> 2. Get OB2 to OB1
>
> I  will be great-full if anyone can share idea how to solve the problem .
> Thanks in advance !!
>
>
>
>
> Tanvir Ahamed
> G?teborg, Sweden  |  mashranga at yahoo.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sun Oct  2 14:37:50 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Sun, 02 Oct 2016 13:37:50 +0100
Subject: [R] Bootstrapping in R
In-Reply-To: <019A773B-8E05-44B8-893B-5EE07EB0C748@gmail.com>
References: <20160929201655.Horde.3eE2mopuZGp8trrU2jNt_Pt@mail.sapo.pt>
	<4F7BC824-B9E1-44E9-851A-579AC53CBED1@gmail.com>
	<1bb2778d-72ca-8bf7-1953-2015240fb47a@gmail.com>
	<019A773B-8E05-44B8-893B-5EE07EB0C748@gmail.com>
Message-ID: <20161002133750.Horde.VcvwnCaVQDIDrpGU1boqnIG@mail.sapo.pt>

Right.
To see it in action just compare the results of the two calls to boot.

library(boot)

set.seed(1007)

x <- rnorm(100)
y <- x + rnorm(100)
dat <- data.frame(x, y)

#Wrong
stat1 <- function(DF, f){
	model <- lm(DF$y ~ DF$x, data = DF[f,])  #Doesn't bootstrap DF
	coef(model)
}

#Correct
stat2 <- function(DF, f){
	model <- lm(y ~ x, data = DF[f,])
	coef(model)
}

boot(dat, stat1, R = 100)
boot(dat, stat2, R = 100)


Rui Barradas


Citando peter dalgaard <pdalgd at gmail.com>:

>> On 01 Oct 2016, at 16:11 , Daniel Nordlund <djnordlund at gmail.com> wrote:
>>
>> You haven't told us anything about the structure of your data, or  
>> the definition of the DataSummary function.
>
> Yes. Just let me add that a common error with boot() is not to pay  
> attention to the required form of the statistic= function argument.  
> It should depend on the data and a set of indices and (for  
> nonparametic bootstrap) it is the indices that are random.
>
> Typical mistakes are to completely ignore the index argument, or to  
> write clumsy code that ignores the data specification, as in
> coef(lm(df$y~df$x, data=d[f])).
>
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mviljamaa at kapsi.fi  Sun Oct  2 18:24:02 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Sun, 02 Oct 2016 19:24:02 +0300
Subject: [R] Can I get odd ratios from lm() model or only glm()?
Message-ID: <b5f201be000d235772fa7be56041a57a@kapsi.fi>

I'm doing logistic regression and I need to infer the coefficients as 
odds ratios.

I first did my model using lm(), but now that I need odd ratios, then 
should I have used glm() like displayed here:

http://r.789695.n4.nabble.com/Odds-ratio-from-Logistic-model-in-R-td2630277.html


From elysa.mitova at gmail.com  Sun Oct  2 10:19:58 2016
From: elysa.mitova at gmail.com (Elysa Mitova)
Date: Sun, 2 Oct 2016 10:19:58 +0200
Subject: [R] Histogram using Sturges' Bining Errors
Message-ID: <CAMfjniFg3eihX810dSqLY_t8EJM6BE-5fJx+N=C+6SAYb-omBA@mail.gmail.com>

Histogram using Sturges' bining

Hello,

I am trying to create a histogram using Sturges' bining rule, yet I keep
getting 2 errors, which probably have to do with the variable I am using.

Here is my process and the errors, what would you suggest?

k <- ggplot (world, aes (x=polstab))

wid <- ceiling ((max(world$polstab)- min (world$polstab))/
nclass.Sturges(world$polstab))

k + geom_histogram(col = "black", fill = "white", binwidth = wid)

Now, I get two error messages:

1: Removed 9 rows containing non-finite values (stat_bin).
2: Computation failed in `stat_bin()`:
missing value where TRUE/FALSE needed

The first one I understand, the second one is more problematic. What could
I do to remove this error?



Thank you in advance!

	[[alternative HTML version deleted]]


From fabien.tarrade at gmail.com  Sun Oct  2 18:48:30 2016
From: fabien.tarrade at gmail.com (Fabien Tarrade)
Date: Sun, 2 Oct 2016 18:48:30 +0200
Subject: [R] remove a "corrupted file" after using download.file() with
 R on Windows 7
In-Reply-To: <1148b676-bf8e-4a55-7144-4f36586073e8@atsu.edu>
References: <1b860c3c-ebbf-1928-1bf0-6515210d9614@gmail.com>
	<1148b676-bf8e-4a55-7144-4f36586073e8@atsu.edu>
Message-ID: <19a7c5a8-7c68-d0dc-6e15-04229494ae8d@gmail.com>

Hi Robert,

sorry for the delays
>> Sometime download.file() failed to download the file and I would like 
>> to remove the correspond file.
> No answers, but a couple of additional questions:
> 1)  Does the issue persist if you close R or does the file remain 
> locked against deletion?
no, if I close R then I can remove the file
> 2) If so, is there a related process in the task list if you use 
> CTRL-ALT-DEL?
nothing special a part from R studio
> 3) Does       print(e$message) yield any useful information when it 
> hangs?
I have an url to access the pages of .tiff documents. The issue that I 
don't know how many pages have each documents. So I try to copy and 
incrememt the index for the number of pges until it failed. I know it is 
not an idea solution but this is I have now until we get this info into 
a DB.
> Would debugging in R Studio shed additional light?
I will give a try.

Thanks
Cheers
Fabien

-- 
Dr Fabien Tarrade

Quantitative Analyst/Developer - Data Scientist

Senior data analyst specialised in the modelling, processing and 
statistical treatment of data.
PhD in Physics, 10 years of experience as researcher at the forefront of 
international scientific research.
Fascinated by finance and data modelling.

Geneva, Switzerland

Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>
Phone : +33 (0)6 14 78 70 90

LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter 
<https://twitter.com/fabtar> Google 
<https://plus.google.com/+FabienTarradeProfile/posts> Facebook 
<https://www.facebook.com/fabien.tarrade.eu> Google 
<skype:fabtarhiggs?call> Xing <https://www.xing.com/profile/Fabien_Tarrade>


From fabien.tarrade at gmail.com  Sun Oct  2 18:51:53 2016
From: fabien.tarrade at gmail.com (Fabien Tarrade)
Date: Sun, 2 Oct 2016 18:51:53 +0200
Subject: [R] remove a "corrupted file" after using download.file() with
 R on Windows 7
In-Reply-To: <CAFDcVCQruAP-rdYbDxRVOUqZ6n5CKxdGY+T=ZF11HZbbMAHLVQ@mail.gmail.com>
References: <1b860c3c-ebbf-1928-1bf0-6515210d9614@gmail.com>
	<CAFDcVCQruAP-rdYbDxRVOUqZ6n5CKxdGY+T=ZF11HZbbMAHLVQ@mail.gmail.com>
Message-ID: <4e77963a-15c7-f158-ad9f-d7a7956fd413@gmail.com>

Hi Henrik,

> 1. It could be that a virus checker locks the file.
This is some internal document so I don't think so and this was monitor 
by our IT security team.
> 2. There are Windows software tools that identify which process locks
> a particular file, e.g. LockHunter (http://lockhunter.com/).  Those
> should help you figure out what's going on.
ok, thanks.
> 3. R.utils::downloadFile() tries it's best to download files
> atomically, i.e. it either gives you a fully downloaded file or not
> all.  In your case, you might still end up with a temporary corrupt
> file, but at least it will have a filename that is different than the
> one you ask for.
My issue is that if I run over 300'000 documents and I will get the same 
amount of corrupted files.
I will try some solution with R or try with python

Thanks
Cheers
Fabien
>
>> Hi there,
>>
>> Sometime download.file() failed to download the file and I would like to
>> remove the correspond file.
>> The issue is that I am not able to do it and Windows complain that the file
>> is use by another application.
>> I try to closeAllConnections(), or unlink() before removing the file but
>> without sucess.
>>
>> Any idea how I should proceed &
>>
>> Please find the code below
>>
>>   # consider warning as an error
>>    options(warn=2)
>>
>>    # try to download the file
>>    tryCatch({
>>      download.file(url,path_file,mode="wb",quiet=quiet)
>>      return(0)
>>    },error = function(e){
>>      if(verbose){
>>        print(e)
>>        print(e$message)
>>      }
>>      # close file when it failed
>>      if (file.exists(path_file)){
>>        closeAllConnections()
>>        #unlink(path_file, recursive=TRUE)
>>        #file.create(path_file,overwrite=TRUE,showWarning=TRUE)
>>        #system(paste0('open "', path_file, '"'))
>>        file.remove(path_file,overwrite=TRUE,showWarning=TRUE)
>>      }
>>      return(1)
>>      }
>> )
>>
>> Thanks a lot
>> Cheers
>> Fabien
>>
>> --
>> Dr Fabien Tarrade
>>
>> Quantitative Analyst/Developer - Data Scientist
>>
>> Senior data analyst specialised in the modelling, processing and statistical
>> treatment of data.
>> PhD in Physics, 10 years of experience as researcher at the forefront of
>> international scientific research.
>> Fascinated by finance and data modelling.
>>
>> Geneva, Switzerland
>>
>> Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
>> Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>
>> Phone : +33 (0)6 14 78 70 90
>>
>> LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter
>> <https://twitter.com/fabtar> Google
>> <https://plus.google.com/+FabienTarradeProfile/posts> Facebook
>> <https://www.facebook.com/fabien.tarrade.eu> Google <skype:fabtarhiggs?call>
>> Xing <https://www.xing.com/profile/Fabien_Tarrade>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Fabien Tarrade

Quantitative Analyst/Developer - Data Scientist

Senior data analyst specialised in the modelling, processing and 
statistical treatment of data.
PhD in Physics, 10 years of experience as researcher at the forefront of 
international scientific research.
Fascinated by finance and data modelling.

Geneva, Switzerland

Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>
Phone : +33 (0)6 14 78 70 90

LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter 
<https://twitter.com/fabtar> Google 
<https://plus.google.com/+FabienTarradeProfile/posts> Facebook 
<https://www.facebook.com/fabien.tarrade.eu> Google 
<skype:fabtarhiggs?call> Xing <https://www.xing.com/profile/Fabien_Tarrade>


From beberking at gmail.com  Sun Oct  2 20:19:30 2016
From: beberking at gmail.com (Bertrand Marc)
Date: Sun, 2 Oct 2016 20:19:30 +0200
Subject: [R] Extract an invertible submatrix
Message-ID: <c70b0700-af99-31fa-a5e8-3cd95e7821c8@gmail.com>

Dear R helpers,

I am looking for an efficient way to extract (any) one of the biggest invertible submatrix.

I have a rectangular matrix A (p x n), with rank k <= min(p, n). I would like to get a submatrix (k x k) invertible, or even better, the list of rows and columns of A which
would form the submatrix (A[rows, columns] would be invertible, with length(rows)=length(columns)=k).

This is the general problem, but in my particular R code, the rank of A would be p (p<n), so I only need to select p columns to get the submatrix. But I am not sure it is
easier.
For now, my (very bad) solution would be to try every submatrix until I find one invertible.

Do you think of any solution which would be more efficient ?

Best regards,
Bertrand


From dwinsemius at comcast.net  Sun Oct  2 21:50:28 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 2 Oct 2016 12:50:28 -0700
Subject: [R] Can I get odd ratios from lm() model or only glm()?
In-Reply-To: <b5f201be000d235772fa7be56041a57a@kapsi.fi>
References: <b5f201be000d235772fa7be56041a57a@kapsi.fi>
Message-ID: <8B950F22-98A0-4D5B-A46E-E458DE383443@comcast.net>


> On Oct 2, 2016, at 9:24 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> 
> I'm doing logistic regression and I need to infer the coefficients as odds ratios.
> 
> I first did my model using lm(), but now that I need odd ratios, then should I have used glm() like displayed here:
> 
> http://r.789695.n4.nabble.com/Odds-ratio-from-Logistic-model-in-R-td2630277.html

Yes.


-- 
David Winsemius
Alameda, CA, USA


From rmh at temple.edu  Sun Oct  2 22:10:43 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 2 Oct 2016 16:10:43 -0400
Subject: [R] Extract an invertible submatrix
In-Reply-To: <c70b0700-af99-31fa-a5e8-3cd95e7821c8@gmail.com>
References: <c70b0700-af99-31fa-a5e8-3cd95e7821c8@gmail.com>
Message-ID: <CAGx1TMBRBmbgMCjBGvuo2ogE8ht56PX_WGL5Rg4V7wxhhf9mJA@mail.gmail.com>

Use qr

tmp <- cbind(matrix(rnorm(30), 5, 6), 0)[, c(1,2,3,4,7,5,6)]
tmp
tmp.qr <- qr(tmp)
tmp.qr
tmp.qr$pivot
tmp.subset <- tmp[, tmp.qr$pivot[1:tmp.qr$rank]]
solve(tmp.subset)


On Sun, Oct 2, 2016 at 2:19 PM, Bertrand Marc <beberking at gmail.com> wrote:
> Dear R helpers,
>
> I am looking for an efficient way to extract (any) one of the biggest invertible submatrix.
>
> I have a rectangular matrix A (p x n), with rank k <= min(p, n). I would like to get a submatrix (k x k) invertible, or even better, the list of rows and columns of A which
> would form the submatrix (A[rows, columns] would be invertible, with length(rows)=length(columns)=k).
>
> This is the general problem, but in my particular R code, the rank of A would be p (p<n), so I only need to select p columns to get the submatrix. But I am not sure it is
> easier.
> For now, my (very bad) solution would be to try every submatrix until I find one invertible.
>
> Do you think of any solution which would be more efficient ?
>
> Best regards,
> Bertrand
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Sun Oct  2 22:55:59 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 3 Oct 2016 09:55:59 +1300
Subject: [R] Font problem.
Message-ID: <26cd8676-bf91-bd21-9334-14047df2617f@auckland.ac.nz>


Dunno exactly whom I should ask about this problem, but I thought I'd 
start with good old r-help.

I have recently acquired a new laptop, and have installed Ubuntu 16.04 
on it.  Still having some teething problems.

If I do

plot(1:10,ylab=expression(italic(J(r)))

I get the error:

Error in title(...) :
   X11 font -*-courier-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 5 at size 15 
could not be loaded

So it would seem that I am missing a font.  Fonts have always been a 
complete mystery to me.  Can anyone suggest how I might rectify this 
deficiency in the fonts on my system?  If so, *please* be as explicit as 
you can in your instructions; I am all at sea here.

cheers,

Rolf Turner

P. S.  I have also just noticed that if I do:

plot(1:10,ylab=expression(alpha))

I get an "a" as the y-axis label, rather than the Greek letter alpha.

Likewise if I do plot(1:10,ylab=expression(Sigma)) I get a capital "S" 
rather than an upper case Greek Sigma symbol.  No error thrown, but.

Any ideas as to how to fix this problem?

For what it's worth, here is my sessionInfo():

R version 3.3.1 (2016-06-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.1 LTS

locale:
  [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] misc_0.0-16

loaded via a namespace (and not attached):
  [1] deldir_0.1-13       Matrix_1.2-3        mgcv_1.8-12
  [4] abind_1.4-3         spatstat_1.46-1.036 rpart_4.1-10
  [7] nlme_3.1-128        grid_3.3.1          polyclip_1.5-0
[10] lattice_0.20-33     goftest_1.0-3       tensor_1.5

R. T.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From varinsacha at yahoo.fr  Mon Oct  3 00:11:29 2016
From: varinsacha at yahoo.fr (varin sacha)
Date: Sun, 2 Oct 2016 22:11:29 +0000 (UTC)
Subject: [R] BCa confidence bands around fitted curves MARS regression
In-Reply-To: <CAGxFJbQ48AW6scAvfjX0W1LTBEGZnWagd97kDNNoO0BeSZ3jWg@mail.gmail.com>
References: <2091422228.8503672.1474831199161.ref@mail.yahoo.com>
	<2091422228.8503672.1474831199161@mail.yahoo.com>
	<CAGxFJbQ48AW6scAvfjX0W1LTBEGZnWagd97kDNNoO0BeSZ3jWg@mail.gmail.com>
Message-ID: <143028262.1323832.1475446289627@mail.yahoo.com>

Hi,
So, I can draw/plot the usual 95% least squares confidence bands around the 3 fitted curves for MARS regression, but I don't know how to get the 95% BCa bootstrapped confidence bands. 

Any help would be highly appreciated.


Reproducible example :


##################

Dataset = data.frame(PIBparHab=c(43931,67524,48348,44827,52409,15245,24453,57636,28992,17102,51495,47243,40908,22494,12784,48391,44221,32514,35132,46679,106022,9817,99635,38678,49128,12876,20732,17151,19670,41053,22488,57134,83295,10660),  QUALITESANSREDONDANCE=c(1082.5,1066.6,1079.3,1079.9,1074.9,1008.6,1007.5,1111.3,1108.2,1109.7,1059.6,1165.1,1026.7,1035.1,997.8,1044.8,1073.6,1085.7,1083.8,1021.6,1036.2,1075.3,1069.3,1101.4,1086.9,1072.1,1166.7,983.9,1004.5,1082.5,1123.5,1094.9,1105.1,1010.8),  competitivite=c(89,83,78,73,90,71,77,85,61,67,98,82,70,43,57,78,72,79,61,71,86,63,90,75,87,64,60,56,66,80,53,91,97,62),  innovation=c(56,52,53,54,57,43,54,60,47,55,58,62,52,35,47,59,56,56,45,52,58,33,57,57,61,40,45,41,50,61,50,65,68,34)) 
install.packages("earth") 
library(earth) 
newdata=na.omit(Dataset) 
model=earth(PIBparHab ~ QUALITESANSREDONDANCE + competitivite + innovation,data=newdata, penalty=-1) 
summary(model) 
plot(model) 
plotmo(model) 
model2 <- earth(PIBparHab ~ QUALITESANSREDONDANCE + competitivite + innovation,data=newdata, penalty=-1, varmod.method="lm",nfold=10,ncross=3) 
plotmo(model2, pt.col=1, level=.95)


boot.MARS=function(formula,data,indices) {
d=data[indices,]
fit=earth(formula,data=d)
return(coef(fit))
}

library(boot)
results=boot(data=newdata, statistic=boot.MARS, R=1000,formula=PIBparHab ~ QUALITESANSREDONDANCE + competitivite + innovation)

boot.ci(results, type= "bca", index=2)


##################

________________________________
De : Bert Gunter <bgunter.4567 at gmail.com>

Cc : R-help Mailing List <r-help at r-project.org>
Envoy? le : Dimanche 25 septembre 2016 22h39
Objet : Re: [R] BCa confidence bands around fitted curves MARS regression


Presumably the "earth" package lacks this functionality ...?

So, obvious query: did you try using the boot package? If not, why
not? If so, show us the code that failed.

Or am I missing the point?

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )



On Sun, Sep 25, 2016 at 12:19 PM, varin sacha via R-help
<r-help at r-project.org> wrote:
> Dear R-experts,
>
> I have fitted a MARS regression and am trying now to plot/draw the BCa confidence bands around the 3 fitted curves (QUALITESANSREDONDANC, competitivite and innovation).
>
>
> Here is the reproducible example.
>
>
> ############################
>
> Dataset = data.frame(PIBparHab=c(43931,67524,48348,44827,52409,15245,24453,57636,28992,17102,51495,47243,40908,22494,12784,48391,44221,32514,35132,46679,106022,9817,99635,38678,49128,12876,20732,17151,19670,41053,22488,57134,83295,10660),
>
> QUALITESANSREDONDANCE=c(1082.5,1066.6,1079.3,1079.9,1074.9,1008.6,1007.5,1111.3,1108.2,1109.7,1059.6,1165.1,1026.7,1035.1,997.8,1044.8,1073.6,1085.7,1083.8,1021.6,1036.2,1075.3,1069.3,1101.4,1086.9,1072.1,1166.7,983.9,1004.5,1082.5,1123.5,1094.9,1105.1,1010.8),
>
> competitivite=c(89,83,78,73,90,71,77,85,61,67,98,82,70,43,57,78,72,79,61,71,86,63,90,75,87,64,60,56,66,80,53,91,97,62),
>
> innovation=c(56,52,53,54,57,43,54,60,47,55,58,62,52,35,47,59,56,56,45,52,58,33,57,57,61,40,45,41,50,61,50,65,68,34))
>
> install.packages("earth")
>
> library(earth)
>
> newdata=na.omit(Dataset)
>
> model=earth(PIBparHab ~ QUALITESANSREDONDANCE + competitivite + innovation,data=newdata, penalty=-1)
>
> summary(model)
>
> plot(model)
>
> plotmo(model)
>
>
> ############################
>
> Best Regards,
> S
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Oct  3 00:46:25 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 3 Oct 2016 09:46:25 +1100
Subject: [R] Histogram using Sturges' Bining Errors
In-Reply-To: <CAMfjniFg3eihX810dSqLY_t8EJM6BE-5fJx+N=C+6SAYb-omBA@mail.gmail.com>
References: <CAMfjniFg3eihX810dSqLY_t8EJM6BE-5fJx+N=C+6SAYb-omBA@mail.gmail.com>
Message-ID: <CA+8X3fWLEw3uLDaGsRCuEfsv98HS2ikU19eT3wySG8UsKKPLJw@mail.gmail.com>

Hi Elysa,
This is pretty much a guess. If you understand the first error, i.e.
that there are nine rows in your input data frame (?) that contain NA,
NaN, or Inf values, have you tried manually removing those rows and
feeding the remainder to your code?

Jim


On Sun, Oct 2, 2016 at 7:19 PM, Elysa Mitova <elysa.mitova at gmail.com> wrote:
> Histogram using Sturges' bining
>
> Hello,
>
> I am trying to create a histogram using Sturges' bining rule, yet I keep
> getting 2 errors, which probably have to do with the variable I am using.
>
> Here is my process and the errors, what would you suggest?
>
> k <- ggplot (world, aes (x=polstab))
>
> wid <- ceiling ((max(world$polstab)- min (world$polstab))/
> nclass.Sturges(world$polstab))
>
> k + geom_histogram(col = "black", fill = "white", binwidth = wid)
>
> Now, I get two error messages:
>
> 1: Removed 9 rows containing non-finite values (stat_bin).
> 2: Computation failed in `stat_bin()`:
> missing value where TRUE/FALSE needed
>
> The first one I understand, the second one is more problematic. What could
> I do to remove this error?
>
>
>
> Thank you in advance!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Oct  3 00:49:52 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 3 Oct 2016 09:49:52 +1100
Subject: [R] Font problem.
In-Reply-To: <26cd8676-bf91-bd21-9334-14047df2617f@auckland.ac.nz>
References: <26cd8676-bf91-bd21-9334-14047df2617f@auckland.ac.nz>
Message-ID: <CA+8X3fUX=HHWLRQpm0sJAjxPGqdZ9acg_LQU_9DyzuEkLg+Vyw@mail.gmail.com>

Hi Rolf,
I would try using dnf (or whatever the Ubuntu equivalent is) to
install the X11 fonts. You may have a GUI method for this in Ubuntu.

Jim


On Mon, Oct 3, 2016 at 7:55 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> Dunno exactly whom I should ask about this problem, but I thought I'd start
> with good old r-help.
>
> I have recently acquired a new laptop, and have installed Ubuntu 16.04 on
> it.  Still having some teething problems.
>
> If I do
>
> plot(1:10,ylab=expression(italic(J(r)))
>
> I get the error:
>
> Error in title(...) :
>   X11 font -*-courier-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 5 at size 15 could
> not be loaded
>
> So it would seem that I am missing a font.  Fonts have always been a
> complete mystery to me.  Can anyone suggest how I might rectify this
> deficiency in the fonts on my system?  If so, *please* be as explicit as you
> can in your instructions; I am all at sea here.
>
> cheers,
>
> Rolf Turner
>
> P. S.  I have also just noticed that if I do:
>
> plot(1:10,ylab=expression(alpha))
>
> I get an "a" as the y-axis label, rather than the Greek letter alpha.
>
> Likewise if I do plot(1:10,ylab=expression(Sigma)) I get a capital "S"
> rather than an upper case Greek Sigma symbol.  No error thrown, but.
>
> Any ideas as to how to fix this problem?
>
> For what it's worth, here is my sessionInfo():
>
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.1 LTS
>
> locale:
>  [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
>  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
>  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] misc_0.0-16
>
> loaded via a namespace (and not attached):
>  [1] deldir_0.1-13       Matrix_1.2-3        mgcv_1.8-12
>  [4] abind_1.4-3         spatstat_1.46-1.036 rpart_4.1-10
>  [7] nlme_3.1-128        grid_3.3.1          polyclip_1.5-0
> [10] lattice_0.20-33     goftest_1.0-3       tensor_1.5
>
> R. T.
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Oct  3 02:24:33 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 02 Oct 2016 17:24:33 -0700
Subject: [R] Font problem.
In-Reply-To: <26cd8676-bf91-bd21-9334-14047df2617f@auckland.ac.nz>
References: <26cd8676-bf91-bd21-9334-14047df2617f@auckland.ac.nz>
Message-ID: <4B87A798-12A2-4EC3-B41C-B250F9494843@dcn.davis.ca.us>

There is R-sig-debian (Ubuntu is a derivative of Debian), but to be honest, this seems more like a question for askubuntu.com.
-- 
Sent from my phone. Please excuse my brevity.

On October 2, 2016 1:55:59 PM PDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>Dunno exactly whom I should ask about this problem, but I thought I'd 
>start with good old r-help.
>
>I have recently acquired a new laptop, and have installed Ubuntu 16.04 
>on it.  Still having some teething problems.
>
>If I do
>
>plot(1:10,ylab=expression(italic(J(r)))
>
>I get the error:
>
>Error in title(...) :
>   X11 font -*-courier-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 5 at size 15 
>could not be loaded
>
>So it would seem that I am missing a font.  Fonts have always been a 
>complete mystery to me.  Can anyone suggest how I might rectify this 
>deficiency in the fonts on my system?  If so, *please* be as explicit
>as 
>you can in your instructions; I am all at sea here.
>
>cheers,
>
>Rolf Turner
>
>P. S.  I have also just noticed that if I do:
>
>plot(1:10,ylab=expression(alpha))
>
>I get an "a" as the y-axis label, rather than the Greek letter alpha.
>
>Likewise if I do plot(1:10,ylab=expression(Sigma)) I get a capital "S" 
>rather than an upper case Greek Sigma symbol.  No error thrown, but.
>
>Any ideas as to how to fix this problem?
>
>For what it's worth, here is my sessionInfo():
>
>R version 3.3.1 (2016-06-21)
>Platform: x86_64-pc-linux-gnu (64-bit)
>Running under: Ubuntu 16.04.1 LTS
>
>locale:
>  [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
>  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
>  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>other attached packages:
>[1] misc_0.0-16
>
>loaded via a namespace (and not attached):
>  [1] deldir_0.1-13       Matrix_1.2-3        mgcv_1.8-12
>  [4] abind_1.4-3         spatstat_1.46-1.036 rpart_4.1-10
>  [7] nlme_3.1-128        grid_3.3.1          polyclip_1.5-0
>[10] lattice_0.20-33     goftest_1.0-3       tensor_1.5
>
>R. T.


From daj025 at gmail.com  Mon Oct  3 04:40:41 2016
From: daj025 at gmail.com (David James)
Date: Sun, 2 Oct 2016 22:40:41 -0400
Subject: [R] isssues with predict.coxph, offset, type = "expected",
	and newdata
In-Reply-To: <021cdb$4h19ma@ironport10.mayo.edu>
References: <021cdb$4h19ma@ironport10.mayo.edu>
Message-ID: <CAFuGCETvRkjhoR3MsnxEtU+DF8-fhG7oA5skcSiH8QqTjNt5Lg@mail.gmail.com>

Thanks Terry,

Re: the second case (predicting from a null model with a newdata=
argument), I agree that it looks a bit over the top for such a
straight forward computation, so maybe it is more a wish than anything
else.  In this one instance, this computation is embedded in a wider
multi-state simulation in Epi::simLexis() where transition hazards are
modeled  as functions of covariates via Cox proportional hazards, and
a subset of transitions happen not to depend on any covariate, thus
the null model(s).   There are ways to circumvent this special case
within Epi::simLexis(), so even in this one example I wouldn't
consider it high priority at all.  But maybe it would be nice to have.


On Sat, Oct 1, 2016 at 10:44 PM, Therneau, Terry M., Ph.D.
<therneau at mayo.edu> wrote:
> I'm off on vacation and checking email only intermittently.
> Wrt the offset issue, I expect that you are correct.  This is not a case that I had ever envisioned, and so was not on my "list" when writing the code and certainly has no test case.  That does not mean that it shouldn't work, just that I am not shocked to see it.   I will look into this.
>
> For the second case of a NULL model I am less sympathetic.  This is, in theory, just reading off values from a Nelson hazard estimate at specific time points; using a coxph call to do so is a case of swatting a fly with a hammer.   A bit more background might make me more excited about extending the code to this case.
>
> Terry Therneau


From faradj.g at gmail.com  Mon Oct  3 09:15:39 2016
From: faradj.g at gmail.com (Faradj Koliev)
Date: Mon, 3 Oct 2016 09:15:39 +0200
Subject: [R] How to plot predicted probabilities with 95% CIs
Message-ID: <7CBD9ABD-347C-4394-9F61-B340E00AC535@gmail.com>

Dear all, 

I need a little help with plotting predicted probabilities (values). Consider the following example

**
data(?mtcars?) 

mfit = lm(mpg ~ vs + disp + cyl, data=mtcars)

newcar=data.frame(vs=c(0,1), disp=230, cyl=6.188)

Pmodel<?predict(mfit, newcar) 
**

I want to plot the effect of ?vs? ( 0 and 1) when all other variables are held constant (mean).  

To do this I run this code below:
**
plot(1:2, Pmodel$estimates[1:2,1],ylim=c(0,1),pch=19, xlim=c(.5,2.5), xlab=?X", ylab=?Predicted value of Y", xaxt="n", main= ?Predicted value of Y with 95% CIs")
arrows(1:2, (Pmodel $estimates[1:2,1]-1.96*Pmodel$estimates[1:2,2]), 1:2, (Pmodel$estimates[1:2,1]+1.96*Pmodel$estimates[1:2,2]), length=0.05, angle=90, code=3)
axis(1,at=c(1,2), labels=c(?Yes?,"No"))
**
What am I doing wring here? Thanks! 

Best, 
Faradj 
	[[alternative HTML version deleted]]


From friendly at yorku.ca  Mon Oct  3 14:25:52 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 3 Oct 2016 08:25:52 -0400
Subject: [R] How to plot predicted probabilities with 95% CIs
In-Reply-To: <7CBD9ABD-347C-4394-9F61-B340E00AC535@gmail.com>
References: <7CBD9ABD-347C-4394-9F61-B340E00AC535@gmail.com>
Message-ID: <cf4e343e-2f7c-6758-2133-c34d18a08ca2@yorku.ca>

Why not use the effects package -- designed for this task.

library(effects)
plot(allEffects(mfit))

?plot.eff   # for details

On 10/3/2016 3:15 AM, Faradj Koliev wrote:
> Dear all,
>
> I need a little help with plotting predicted probabilities (values). Consider the following example
>
> **
> data(?mtcars?)
>
> mfit = lm(mpg ~ vs + disp + cyl, data=mtcars)
>
> newcar=data.frame(vs=c(0,1), disp=230, cyl=6.188)
>
> Pmodel<?predict(mfit, newcar)
> **
>
> I want to plot the effect of ?vs? ( 0 and 1) when all other variables are held constant (mean).
>
> To do this I run this code below:
> **
> plot(1:2, Pmodel$estimates[1:2,1],ylim=c(0,1),pch=19, xlim=c(.5,2.5), xlab=?X", ylab=?Predicted value of Y", xaxt="n", main= ?Predicted value of Y with 95% CIs")
> arrows(1:2, (Pmodel $estimates[1:2,1]-1.96*Pmodel$estimates[1:2,2]), 1:2, (Pmodel$estimates[1:2,1]+1.96*Pmodel$estimates[1:2,2]), length=0.05, angle=90, code=3)
> axis(1,at=c(1,2), labels=c(?Yes?,"No"))
> **
> What am I doing wring here? Thanks!
>
> Best,
> Faradj
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bob at rud.is  Sat Oct  1 19:25:44 2016
From: bob at rud.is (Bob Rudis)
Date: Sat, 1 Oct 2016 13:25:44 -0400
Subject: [R] [R-pkgs] A few new packages on CRAN
Message-ID: <CAA-FpKWE=Nv0fi+3BAWbMbSeznTZ8eBP4zYydq7RmCmkWvBxVw@mail.gmail.com>

- ndjdon : Wicked Fast ndjson Reader

  Reads in ndjson significantly faster than jsonlite::stream_in(), flattens
each
  JSON record and returns a data.table.

  https://cran.r-project.org/web/packages/ndjson/index.html


- htmltidy : Clean Up or Pretty Print Gnarly HTML and XHTML

  C-backed package that includes the HTML Tidy library. Useful for cleaning
up
  HTML beyond what you get with the HTML parsing in the libxml2-based
packages.

  https://cran.r-project.org/web/packages/htmltidy/index.html

  (v0.3.0 on github is a tad more robust and will be in CRAN later in
October)


- wand : Retrieve 'Magic' Attributes from Files and Directories

  Uses libmagic (file.exe on Windows for the time being) to discern file
types.

  https://cran.r-project.org/web/packages/wand/index.html

  (100% libmagic version coming later in October)


- gdns : Tools to work with the Google DNS over HTTPS API

  Provides full access to the Google DNS HTTPS API and also toold to work
with
  SPF records. Great for validating your local provider DNS lookups and for
  generating features for cybersecurity machine learning.

  https://cran.r-project.org/web/packages/gdns/index.html


- qrencoder : Quick Response Code (QR Code) / Matrix Barcode Creator

  C-backed package to generate QR codes (it's being used in some bitcoin
Shiny
  projects).

  https://cran.r-project.org/web/packages/qrencoder/index.html


- darksky : Tools to Work with the Dark Sky API
  Data retrieval and some default plotting for this weather API.

  https://cran.r-project.org/web/packages/darksky/index.html

Issues/enhancement requests are most welcome at each pkg's GH issues page.

-Bob

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From vivek4 at mail.usf.edu  Mon Oct  3 18:13:05 2016
From: vivek4 at mail.usf.edu (Vivek Singh)
Date: Mon, 3 Oct 2016 12:13:05 -0400
Subject: [R] R Mysql Not reading all table names
Message-ID: <CAJGK8=-uWgH1UQ7NQkEu926RCcVdZVWbB0M_tLMEFw74ff9OAw@mail.gmail.com>

Hi All:

I am using R with MySQL, following is my code:

library(RMySQL)
con <- dbConnect(MySQL(), user="user", password="password", dbname="db",
host="localhost")
rs1 <- dbSendQuery(con, "show tables like \"%padded\"")
all_tables3<- fetch(rs1, n=-1)

There are 25 tables in the database when I execute the above query on the
MySQL prompt. However, the above R code giving me only 9 tables. It seems
there is some cache from which R is getting 9 tables instead of 25 tables.
Please help.

Regards,

Vivek Kumar Singh

PhD student,
Information Systems Decision Sciences,
MUMA College of Business,
USF
Phone- (813) 5809131
Web: http://vivek4.myweb.usf.edu/

	[[alternative HTML version deleted]]


From f_j_rod at hotmail.com  Mon Oct  3 18:29:00 2016
From: f_j_rod at hotmail.com (Frank S.)
Date: Mon, 3 Oct 2016 16:29:00 +0000
Subject: [R] Elegant way to get specific dates within prespecified period
In-Reply-To: <D413E543.18763A%macqueen1@llnl.gov>
References: <D413E543.18763A%macqueen1@llnl.gov>
Message-ID: <AM5PR0402MB2689B1B8A1118FC0DC6DD1F3BAC20@AM5PR0402MB2689.eurprd04.prod.outlook.com>

Don, many thanks for your tip. I will apply it in the future when programming my code.


Best,


Fran K.

________________________________
De: MacQueen, Don <macqueen1 at llnl.gov>
Enviat el: divendres, 30 de setembre de 2016 18:56:45
Per a: Frank S.; r-help at r-project.org
Tema: Re: [R] Elegant way to get specific dates within prespecified period

I would probably try a different strategy.

First, construct a sequence of January 1 dates that is a little bit too
long. For example, start with the January in the same year as "open" and
finish with the January in the same year as "close". You can construct the
vector using seq(), like this:

> seq(as.Date('2007-1-1'), as.Date('2011-1-1'), by='year')
[1] "2007-01-01" "2008-01-01" "2009-01-01" "2010-01-01" "2011-01-01"

Then test all those dates for whether they fit your rules, and remove
those that don't.

I think this will be easier than constructing fancy ifelse statements. It
should certainly be easier to understand the code, i.e., when you come
back and look at it a few years from now. Or if a colleague wants to look
at it and understand it.

-Don


--
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 9/30/16, 9:38 AM, "R-help on behalf of Frank S."
<r-help-bounces at r-project.org on behalf of f_j_rod at hotmail.com> wrote:

>Dear R users,
>
>I have two dates, ["open", "close"], which can be any dates such "close"
>is strictly later than "open".
>I wanted to write an R code that displays the following:  To construct a
>vector "v" with all 1st January
>
>days located between "open" and "close" dates:  v = (dp_1, dp_2, ...,
>dp_n). Moreover:
>
>a) Regard to the first date "dp_1":
>    a1) If "open" is on a 1st January day, "dp_1" is on 1st January of
>the year after "open".
>    a2) In case difftime between "open" and the following 1st January is
>lower than 30 days,
>       "dp_1" will be on 1st January of the year after the year of that
>1st January.
>
>b) Regard to the last date "dp_n":
>   b1) If "close" is on a 1st January day, dp_n is on 1st January of the
>year before "close"
>   b2) In case difftime between "close" and the previous 1st January is
>lower than 30 days,
>       "dp_n" will be on 1st January of the year before the year of that
>1st January.
>
>Example 1: [open = 2007-01-01, close = 2011-04-05]
>v = (2008-01-01, 2009-01-01, 2010-01-01, 2011-01-01) # Since open is
>already on a 1st January
>
>                         # Since difftime(2011-04-05, 2011-01-01) >= 30
>days
>Example 2: [open = 2006-12-15, close = 2011-01-19]
>v = (2008-01-01, 2009-01-01, 2010-01-01)      # Since
>difftime(2007-01-01, 2006-12-15) < 30 days
>
>       # Since difftime(2011-01-19, 2011-01-01) < 30 days
>
>
>My code is (for example 2):
>
>open <- as.Date('2006-12-15')
>close <- as.Date('2011-01-19')
>
>dp_1 <- as.Date(ifelse(
> as.Date(paste(as.character(as.numeric(format(open, "%Y")) + 1), 1, 1,
>sep = "-")) - open >= 30,
> as.Date(paste(as.character(as.numeric(format(open, "%Y")) + 1), 1, 1,
>sep = "-")),
> as.Date(paste(as.character(as.numeric(format(open, "%Y")) + 2), 1, 1,
>sep = "-"))),
> origin = "1970-01-01")
>
>dp_n <- as.Date(ifelse(
>      close - as.Date(paste(as.character(as.numeric(format(close,
>"%Y"))), 1, 1, sep = "-")) >= 30,
>      as.Date(paste(as.character(as.numeric(format(close, "%Y"))), 1, 1,
>sep = "-")),
> as.Date(paste(as.character(as.numeric(format(close, "%Y")) - 1), 1, 1,
>sep = "-"))),
> origin = "1970-01-01")
>
>v <- seq(dp_1, dp_n, by = "year")
>
>
>However, above code is not too large, so I'm almost sure that there might
>be a better way of doing it.
>Is there a better way to get the vector "v"?
>
[[elided Hotmail spam]]
>
>Frank S.
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Mon Oct  3 18:29:33 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 3 Oct 2016 11:29:33 -0500
Subject: [R] R Mysql Not reading all table names
In-Reply-To: <CAJGK8=-uWgH1UQ7NQkEu926RCcVdZVWbB0M_tLMEFw74ff9OAw@mail.gmail.com>
References: <CAJGK8=-uWgH1UQ7NQkEu926RCcVdZVWbB0M_tLMEFw74ff9OAw@mail.gmail.com>
Message-ID: <CAAJSdjhEexBQr6wGJuzUptqHgY9yiz-Ddi-4XK2zB2dXG4sVMw@mail.gmail.com>

On Mon, Oct 3, 2016 at 11:13 AM, Vivek Singh <vivek4 at mail.usf.edu> wrote:

> Hi All:
>
> I am using R with MySQL, following is my code:
>
> library(RMySQL)
> con <- dbConnect(MySQL(), user="user", password="password", dbname="db",
> host="localhost")
> rs1 <- dbSendQuery(con, "show tables like \"%padded\"")
> all_tables3<- fetch(rs1, n=-1)
>
> There are 25 tables in the database when I execute the above query on the
> MySQL prompt. However, the above R code giving me only 9 tables. It seems
> there is some cache from which R is getting 9 tables instead of 25 tables.
> Please help.
>

?Just to be sure that I am understanding you correctly. When you say there
are "25 tables" do you mean a total of 25 tables, of all names, or a total
of 25 tables which whose names end with the characters "padded". I ask
because your SHOW TABLES is only looking for the names of tables which end
in "padded". Please forgive me if this is a stupid question.?



>
> Regards,
>
> Vivek Kumar Singh
>
> PhD student,
> Information Systems Decision Sciences,
> MUMA College of Business,
> USF
> Phone- (813) 5809131
> Web: http://vivek4.myweb.usf.edu/
>
>

-- 
Heisenberg may have been here.

Unicode: http://xkcd.com/1726/

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Oct  3 18:40:41 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 3 Oct 2016 16:40:41 +0000
Subject: [R] Rearranging sub-folders, how?
In-Reply-To: <CY1PR13MB01422B76FBC5297311ACAB47FAC00@CY1PR13MB0142.namprd13.prod.outlook.com>
References: <CY1PR13MB01422B76FBC5297311ACAB47FAC00@CY1PR13MB0142.namprd13.prod.outlook.com>
Message-ID: <b5821ff4492e4001ae1cc304c785edef@exch-2p-mbx-w2.ads.tamu.edu>

If this is a one-time change, it will be simpler to use the Windows File explorer (I assume Windows since you are using backslashes). If it needs to be done using R functions, this seems to work:

> dir.create("A/B/C/D/E", recursive=TRUE)
> list.dirs("A")
[1] "A"         "A/B"       "A/B/C"     "A/B/C/D"   "A/B/C/D/E"
> file.rename("A/B/C/D", "A/B/D")
[1] TRUE
> list.dirs("A")
[1] "A"       "A/B"     "A/B/C"   "A/B/D"   "A/B/D/E"
> file.rename("A/B/C", "A/B/D/C")
[1] TRUE
> list.dirs("A")
[1] "A"       "A/B"     "A/B/D"   "A/B/D/C" "A/B/D/E"
> file.rename("A/B/D/E", "A/B/D/C/E")
[1] TRUE
> list.dirs("A")
[1] "A"         "A/B"       "A/B/D"     "A/B/D/C"   "A/B/D/C/E"

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kristi Glover
Sent: Saturday, October 1, 2016 6:29 AM
To: r-help at r-project.org
Subject: [R] Rearranging sub-folders, how?

Hi R user,

I was wondering how we can rearrange the folders in R. for example

original data has been put with the following arrangement:

foldA\subFoldB\subFoldC\subFoldD\subFoldE\


SubFoldE contains several dataset


I want to rearrange the subFoldE into following sequence:


foldA\subFoldB\subFoldD\subFoldC\subFoldE\


Any suggestions?

Thanks

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From f_j_rod at hotmail.com  Mon Oct  3 19:17:35 2016
From: f_j_rod at hotmail.com (Frank S.)
Date: Mon, 3 Oct 2016 17:17:35 +0000
Subject: [R] Looping through data tables (or data frames) by removing
 previous individuals
Message-ID: <AM5PR0402MB2689721B919E3606AD55ECF3BAC20@AM5PR0402MB2689.eurprd04.prod.outlook.com>

Dear R users,

With this mail I send my third and last question I wanted to ask these days. First of all, many thanks

for the received support in my previous mails! My question is this: Starting from a series of (for example)

"k" different dates (all contained in vector "v"), I want to get a list of "k" data tables (or data frames) so

that each contains those individuals who for the first time are at least 65, looping on each of the dates of

vector "v". Let's consider the following example with 5 individuals:


dt <- data.table(
   id = 1:5,
   fborn = as.Date(c("1935-07-25", "1942-10-05", "1942-09-07", "1943-09-07", "1943-12-31")),
   sex = as.factor(rep(c(0, 1), c(2, 3)))
   )

v <- seq(as.Date("2006-01-01"), as.Date("2009-01-01"), by ="year") # k=4


I would expect to obtain k=4 data tables so that:
dt_p1: contains id = 1 (he is for the first time at least 65 on date v[1])
dt_p2: is NULL (no subject reach for the first time 65 on date v[2])
dt_p3: contains id = 2 & id = 3 (they are for the first time at least 65 on v[3])
dt_p4: contains id = 4 & id = 5 (they are for the first time at least 65 on v[4])


I have tried:

dt_p <- list( )                        # Empty list to alocate data tables

for (i in 1:length(v)) {
  dt_p[[i]] <- dt[ !(id %in% dt_p[[1:(i-1)]]$id) &  # Remove subjects from previous dt_p's
         round((v[i] - fborn)/365.25, 2) >= 65, ][ , list(id, fborn, sex)]

 dt.names <- paste0("dt_p", 1:length(v))
 assign(dt.names[i], dt_p[[i]])         # Assign a name to each data table
 }

However, I cannot express correctly the previous data tables, because for the first data

table in the loop, there are not any previous. Consequently, I get an error message:

# Error in dt_p[[1:(i - 1)]] : no such index at level 1


I would be very grateful for anu suggestion!

Frank S.

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon Oct  3 09:56:15 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Mon, 03 Oct 2016 08:56:15 +0100
Subject: [R] Bootstrapping in R
In-Reply-To: <C207B957-6D52-40EA-8AF6-9A47D486EA79@gmail.com>
References: <20160929201655.Horde.3eE2mopuZGp8trrU2jNt_Pt@mail.sapo.pt>
	<4F7BC824-B9E1-44E9-851A-579AC53CBED1@gmail.com>
	<1bb2778d-72ca-8bf7-1953-2015240fb47a@gmail.com>
	<019A773B-8E05-44B8-893B-5EE07EB0C748@gmail.com>
	<20161002133750.Horde.VcvwnCaVQDIDrpGU1boqnIG@mail.sapo.pt>
	<C207B957-6D52-40EA-8AF6-9A47D486EA79@gmail.com>
Message-ID: <20161003085615.Horde.e_A4XElTPLz6c3vZUBqdD0V@mail.sapo.pt>

Hello,

I've just ran your code and it all went well.
So my doubt is: if you have 1269 rows why choose only 100 and  
bootstrap? It doesn't seem to make much sense to me.
Try to run the entire df through DataSummary? and compare the results  
with the bootstrap results.

Rui Barradas
?

Citando Bryan Mac <bryanmac.24 at gmail.com>:

> Hi all, ?
> Here is the first six rows of my data. In total I have 1269 rows. ?
> My goal is to get conduct nonparametric bootstrap and case resampling.?
> I would like to randomly select 100 out of the 1269 After that, I  
> wish to bootstrap that randomly selected 100 out of 1269.
> ?
> I assume I need to set the seed to conduct this randomization, as  
> with bootstrapping you would get varied results each time the code  
> is run.
> ?
> ##   NAR  SQRTNAR NIC  SQRTNIC ## 1 2.6 1.612452 5.6 2.366432 ## 2  
> 8.1 2.846050 9.9 3.146427 ## 3 5.7 2.387467 7.1 2.664583 ## 4 8.3  
> 2.880972 8.1 2.846050 ## 5 7.3 2.701851 9.9 3.146427 ## 6 4.9  
> 2.213594 8.6 2.932576
> Here is my definition of the DataSummary function.
> ?
> DataSummary <- function(df, indices){  sample <- df[indices, ]      
> sumry_for_NAR <- summary(sample$NAR)  nms <- names(sumry_for_NAR)   
> nms <- c(nms, 'std')  out_for_NAR <- c(sumry_for_NAR,  
> sd(sample$NAR))  names(out_for_NAR) <- nms     sumry_for_SQRTNAR <-  
> summary(sample$SQRTNAR)  nms <- names(sumry_for_SQRTNAR)  nms <-  
> c(nms, 'std')  out_for_SQRTNAR <- c(sumry_for_SQRTNAR,  
> sd(sample$SQRTNAR))  names(out_for_SQRTNAR) <- nms     sumry_for_NIC  
> <- summary(sample$NIC)  nms <- names(sumry_for_NIC)  nms <- c(nms,  
> 'std')  out_for_NIC <- c(sumry_for_NIC, sd(sample$NIC))   
> names(out_for_NIC) <- nms     sumry_for_SQRTNIC <-  
> summary(sample$SQRTNIC)  nms <- names(sumry_for_SQRTNIC)  nms <-  
> c(nms, 'std')  out_for_SQRTNIC <- c(sumry_for_SQRTNIC,  
> sd(sample$SQRTNIC))  names(out_for_SQRTNIC) <- nms     OUT <-  
> c(out_for_NAR, out_for_SQRTNAR, out_for_NIC, out_for_SQRTNIC)      
> return(OUT)} Again, here is my attempt at bootstrapping.
>
> ?
> result <- boot(n_data, statistic = DataSummary, R = 100)result
> ?
> ?Per suggestions, would I go with this code to achieve my goal? ?So,  
> the best reference/resource is the boot help page. I found code  
> through various sites and I got really confused because they were  
> very different from each other.
> ?
>
>> set.seed(1007)
>>
>> x <- rnorm(100)
>> y <- x + rnorm(100)
>> dat <- data.frame(x, y)
>
>> stat2 <- function(DF, f){
>> model <- lm(y ~ x, data = DF[f,])
>> coef(model)
>> }
>>
>> boot(dat, stat1, R = 100)
>> boot(dat, stat2, R = 100)
>
> ?
>
> ?
> ? Bryan Mac
> bryanmac.24 at gmail.com
> ?
>
> ?
>
>> On Oct 2, 2016, at 5:37 AM, ruipbarradas at sapo.pt wrote:
>> ?  Right.
>> To see it in action just compare the results of the two calls to boot.
>>
>> library(boot)
>>
>> set.seed(1007)
>>
>> x <- rnorm(100)
>> y <- x + rnorm(100)
>> dat <- data.frame(x, y)
>>
>> #Wrong
>> stat1 <- function(DF, f){
>> model <- lm(DF$y ~ DF$x, data = DF[f,]) ?#Doesn't bootstrap DF
>> coef(model)
>> }
>>
>> #Correct
>> stat2 <- function(DF, f){
>> model <- lm(y ~ x, data = DF[f,])
>> coef(model)
>> }
>>
>> boot(dat, stat1, R = 100)
>> boot(dat, stat2, R = 100)
>>
>> Rui Barradas
>>
>> Citando peter dalgaard <pdalgd at gmail.com>:
>> ?
>>>> On 01 Oct 2016, at 16:11 , Daniel Nordlund <djnordlund at gmail.com> wrote:
>>>>
>>>> You haven't told us anything about the structure of your data, or  
>>>> the definition of the DataSummary function.
>>>
>>> Yes. Just let me add that a common error with boot() is not to pay  
>>> attention to the required form of the statistic= function  
>>> argument. It should depend on the data and a set of indices and  
>>> (for nonparametic bootstrap) it is the indices that are random.
>>>
>>> Typical mistakes are to completely ignore the index argument, or  
>>> to write clumsy code that ignores the data specification, as in
>>> coef(lm(df$y~df$x, data=d[f])).
>>>
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk ?Priv: PDalgd at gmail.com
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide  
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ?

?

	[[alternative HTML version deleted]]


From bryanmac.24 at gmail.com  Mon Oct  3 09:24:50 2016
From: bryanmac.24 at gmail.com (Bryan Mac)
Date: Mon, 3 Oct 2016 00:24:50 -0700
Subject: [R] Bootstrapping in R
In-Reply-To: <20161002133750.Horde.VcvwnCaVQDIDrpGU1boqnIG@mail.sapo.pt>
References: <20160929201655.Horde.3eE2mopuZGp8trrU2jNt_Pt@mail.sapo.pt>
	<4F7BC824-B9E1-44E9-851A-579AC53CBED1@gmail.com>
	<1bb2778d-72ca-8bf7-1953-2015240fb47a@gmail.com>
	<019A773B-8E05-44B8-893B-5EE07EB0C748@gmail.com>
	<20161002133750.Horde.VcvwnCaVQDIDrpGU1boqnIG@mail.sapo.pt>
Message-ID: <C207B957-6D52-40EA-8AF6-9A47D486EA79@gmail.com>

Hi all,

Here is the first six rows of my data. In total I have 1269 rows.  
My goal is to get conduct nonparametric bootstrap and case resampling. 
I would like to randomly select 100 out of the 1269 After that, I wish to bootstrap that randomly selected 100 out of 1269.

I assume I need to set the seed to conduct this randomization, as with bootstrapping you would get varied results each time the code is run.

##   NAR  SQRTNAR NIC  SQRTNIC
## 1 2.6 1.612452 5.6 2.366432
## 2 8.1 2.846050 9.9 3.146427
## 3 5.7 2.387467 7.1 2.664583
## 4 8.3 2.880972 8.1 2.846050
## 5 7.3 2.701851 9.9 3.146427
## 6 4.9 2.213594 8.6 2.932576
Here is my definition of the DataSummary function.

DataSummary <- function(df, indices){
  sample <- df[indices, ]
  
  sumry_for_NAR <- summary(sample$NAR)
  nms <- names(sumry_for_NAR)
  nms <- c(nms, 'std')
  out_for_NAR <- c(sumry_for_NAR, sd(sample$NAR))
  names(out_for_NAR) <- nms
  
  sumry_for_SQRTNAR <- summary(sample$SQRTNAR)
  nms <- names(sumry_for_SQRTNAR)
  nms <- c(nms, 'std')
  out_for_SQRTNAR <- c(sumry_for_SQRTNAR, sd(sample$SQRTNAR))
  names(out_for_SQRTNAR) <- nms
  
  sumry_for_NIC <- summary(sample$NIC)
  nms <- names(sumry_for_NIC)
  nms <- c(nms, 'std')
  out_for_NIC <- c(sumry_for_NIC, sd(sample$NIC))
  names(out_for_NIC) <- nms
  
  sumry_for_SQRTNIC <- summary(sample$SQRTNIC)
  nms <- names(sumry_for_SQRTNIC)
  nms <- c(nms, 'std')
  out_for_SQRTNIC <- c(sumry_for_SQRTNIC, sd(sample$SQRTNIC))
  names(out_for_SQRTNIC) <- nms
  
  OUT <- c(out_for_NAR, out_for_SQRTNAR, out_for_NIC, out_for_SQRTNIC)
  
  return(OUT)
}
Again, here is my attempt at bootstrapping.

result <- boot(n_data, statistic = DataSummary, R = 100)
result

 Per suggestions, would I go with this code to achieve my goal?  So, the best reference/resource is the boot help page. I found code through various sites and I got really confused because they were very different from each other.

> set.seed(1007)
> 
> x <- rnorm(100)
> y <- x + rnorm(100)
> dat <- data.frame(x, y)

> stat2 <- function(DF, f){
> 	model <- lm(y ~ x, data = DF[f,])
> 	coef(model)
> }
> 
> boot(dat, stat1, R = 100)
> boot(dat, stat2, R = 100)




Bryan Mac
bryanmac.24 at gmail.com



> On Oct 2, 2016, at 5:37 AM, ruipbarradas at sapo.pt wrote:
> 
> Right.
> To see it in action just compare the results of the two calls to boot.
> 
> library(boot)
> 
> set.seed(1007)
> 
> x <- rnorm(100)
> y <- x + rnorm(100)
> dat <- data.frame(x, y)
> 
> #Wrong
> stat1 <- function(DF, f){
> 	model <- lm(DF$y ~ DF$x, data = DF[f,])  #Doesn't bootstrap DF
> 	coef(model)
> }
> 
> #Correct
> stat2 <- function(DF, f){
> 	model <- lm(y ~ x, data = DF[f,])
> 	coef(model)
> }
> 
> boot(dat, stat1, R = 100)
> boot(dat, stat2, R = 100)
> 
> 
> Rui Barradas
> 
> 
> Citando peter dalgaard <pdalgd at gmail.com>:
> 
>>> On 01 Oct 2016, at 16:11 , Daniel Nordlund <djnordlund at gmail.com> wrote:
>>> 
>>> You haven't told us anything about the structure of your data, or the definition of the DataSummary function.
>> 
>> Yes. Just let me add that a common error with boot() is not to pay attention to the required form of the statistic= function argument. It should depend on the data and a set of indices and (for nonparametic bootstrap) it is the indices that are random.
>> 
>> Typical mistakes are to completely ignore the index argument, or to write clumsy code that ignores the data specification, as in
>> coef(lm(df$y~df$x, data=d[f])).
>> 
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


	[[alternative HTML version deleted]]


From c.kuempel at uq.edu.au  Mon Oct  3 07:47:11 2016
From: c.kuempel at uq.edu.au (Caitie Kuempel)
Date: Mon, 3 Oct 2016 05:47:11 +0000
Subject: [R] Error in aictab with CLM model "function not yet defined"
Message-ID: <cb84ce6b22614415a40df8aa56f99a25@uq-exmbx6.soe.uq.edu.au>

Hi R help,

I am trying to do some AIC model averaging on a CLM model in R and keep getting the error:

Error in aictab.default(cand.set = Cand.model0, modnames = Modnames0,  :
Function not yet defined for this object class


The MuMIn package says that the functions should work for clm and clmm models so I'm not sure if I'm missing something or if there is an extra step?  Any help or examples would be appreciated.

My model (m1) works fine- which I fit using the clm() function from the package ordinal.  Then I run the following:

dred<-dredge(m1,rank="AICc",trace=TRUE,evaluate=FALSE)
Cand.model0<-list()
r2val<-rep(0,length(dred)) # r-square values
for(i in 1:length(dred))
{
  print(length(dred)-i)
  Cand.model0[[i]]<-clm(as.character(dred[[i]])[2],data=datt2,REML=FALSE)
  #r2val[i]<-summary(Cand.model0[[i]])$r.squared
}

Modnames0 <- paste("mod", 1:length(Cand.model0), sep = " ")
t0<-aictab(cand.set=Cand.model0, modnames=Modnames0, sort = TRUE, second.ord = TRUE,nobs = NULL)
Error in aictab.default(cand.set = Cand.model0, modnames = Modnames0,  :
Function not yet defined for this object class

Thanks for your time.

Best,

Caitie

	[[alternative HTML version deleted]]


From syelamohdnoor at gmail.com  Mon Oct  3 19:23:21 2016
From: syelamohdnoor at gmail.com (Syela Mohd Noor)
Date: Tue, 4 Oct 2016 01:23:21 +0800
Subject: [R] Trouble with parameter estimation in nonlinear regression model
Message-ID: <CAF4yKE-uTuupx3EMKe9JcMveodFENMmkbLXSnm_R_oZEbz00zw@mail.gmail.com>

Hi all, I had a problem with the parameter estimation of the Brass Gompertz
model for my dissertation. I run the code for several times based on
different years and it was fine until the seventh year onward where I got
negative values for the parameter (a) which did not make sense since it
represents the total fertility rate of a country.
This is my code :

gom.eq=function(a, b, c)

{

    age=c(17.5, 22.5, 27.5, 32.5, 37.5, 42.5 , 47.5)

    k=(-(age-14)/b)

    (a*((c/b)*(exp((k)-(c*(exp(k)))))))

}



varlist=list(
ASFR$Y1960,ASFR$Y1965,ASFR$Y1970,ASFR$Y1975,ASFR$Y1980,ASFR$Y1985,

ASFR$Y1990,ASFR$Y1995,ASFR$Y2000,ASFR$Y2005,ASFR$Y2010,ASFR$Y2013)



gom.models=lapply(varlist, function(varlist)

{

nlsLM(varlist~gom.eq(a,b,c),data=ASFR,start=list(a=1 , b=1, c=1),trace=T)

})

summary(gom.models)



gom.models[1:12]




Any idea to solve the problem?


Regards,

Syela M.N.

	[[alternative HTML version deleted]]


From setareh227 at gmail.com  Mon Oct  3 13:43:39 2016
From: setareh227 at gmail.com (maryam moazam)
Date: Mon, 3 Oct 2016 15:13:39 +0330
Subject: [R] Please help with creating the improved image with pheatmap
	package
Message-ID: <CAM=b0pf23aX9EzYyX5siTF-YNJz5uNep5u-O0f3i-sO69kkjRg@mail.gmail.com>

Hi all,

I'm trying to show about 190 items using "pheatmap" package. I'm working
with R 3.3.1 on windows 7. I used the following code:

pheatmap(mat_data, cellwidth=20, cluster_rows = FALSE, cluster_cols =
FALSE, fontsize=5, fontsize_row=5, margins=c(5,10))


The resulted image is attached. Please take a look at it. As you could see,
the image quality is not good, in fact, the label of each row has not been
appropriately shown at all in the picture. Could you please help me how I
can modify the code to improve the image?




Thank you very much in advance

Best regards,
Maryam
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image_pheatmap.png
Type: image/png
Size: 33445 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161003/62253c76/attachment.png>

From patrick-breheny at uiowa.edu  Mon Oct  3 18:35:08 2016
From: patrick-breheny at uiowa.edu (Patrick Breheny)
Date: Mon, 3 Oct 2016 11:35:08 -0500
Subject: [R] John M. Chambers Statistical Software Award
Message-ID: <450910b6-c509-952e-2b52-31add90d4ae9@uiowa.edu>

John M. Chambers Statistical Software Award 2017

The Statistical Computing Section of the American Statistical 
Association announces the competition for the John M. Chambers 
Statistical Software Award. In 1998 the Association for Computing 
Machinery presented its Software System Award to John Chambers for the 
design and development of S. Dr. Chambers generously donated his award 
to the Statistical Computing Section to endow an annual prize for 
statistical software written by, or in collaboration with, an 
undergraduate or graduate student. The prize carries with it a cash 
award of $1,000.

Both individuals and teams are eligible to participate in the 
competition. To be eligible, at least one individual within the team 
must have begun the development while a student and must either 
currently be a student, or have completed all requirements for her/his 
last degree after January 1, 2016.  The award will be given to the 
student, or split between student team members if the team consists of 
multiple students, up to a maximum of three students. If the software 
was created by a team, the contribution of the student(s) must be 
substantial.

To apply for the award, teams must provide the following materials:

* Current CVs of all student team members.

* A letter from a faculty mentor at the academic institution of one of 
the students. The letter should confirm that the student had substantial 
participation in the development of the software, certify her/his 
student status when the software began to be developed, confirm that 
he/she is still a student (or provide a date of degree completion), and 
briefly discuss the importance of the software to statistical practice.

* A brief, one to two page description of the software, summarizing what 
it does, how it does it, and why it is an important contribution. If any 
student team member has continued developing the software after 
finishing her/his studies, the description should indicate what was 
developed when the individual was a student and what has been added since.

* An installable software package with its source code for use by the 
award committee. It should be accompanied by enough information to allow 
the judges to effectively use and evaluate the software (including its 
design considerations). This information can be provided in a variety of 
ways, including but not limited to: a user manual, a manuscript, a URL, 
and online help to the system.

All materials must be in English. We prefer that electronic text be 
submitted as PDF files. The entries will be judged on a variety of 
dimensions, including the importance and relevance for statistical 
practice of the tasks performed by the software, ease of use, clarity of 
description, elegance and availability for use by the statistical 
community. Preference will be given to those entries that are grounded 
in software design rather than calculation. The decision of the award 
committee is final.

All application materials must be received by Thursday, December 15, 
2016 and should be sent to the e-mail address below.  The winner will be 
announced by January 15.  The award will be presented at the 2017 Joint 
Statistical Meetings, and the winner(s) will be given an opportunity to 
present their work in a topic-contributed session at the meetings.

Note that the Statistical Computing Section also runs, with the 
Statistical Graphics Section, a student paper competition.  Students are 
eligible to submit an application to both competitions for the same 
work, but would only be allowed to accept one of the awards.

Inquiries and application materials should be sent to:

Patrick Breheny
Department of Biostatistics
University of Iowa
patrick-breheny at uiowa.edu


From s.atasever at gmail.com  Mon Oct  3 11:03:54 2016
From: s.atasever at gmail.com (Sema Atasever)
Date: Mon, 3 Oct 2016 12:03:54 +0300
Subject: [R] To submit R jobs via SLURM
Message-ID: <CAAir+Cph-tX5KQVUbkr99L3TNNx-FGWCP5c0NzcU2jRJ6K2uzg@mail.gmail.com>

Dear Authorized Sir / Madam,

I have an R script file in which it includes this lines:

How can i to submit this R jobs via SLURM? Thanks in advance.

*testscript.R*
data=read.table("seqDist.50", header=FALSE)[-1]
attach(data)
d=as.matrix(data)
library(cluster)
cluster.pam = pam(d,6)
table(cluster.pam$clustering)

filenameclu = paste("outputfile", ".txt")
write.table(cluster.pam$clustering, file=outputfile,sep=",")

	[[alternative HTML version deleted]]


From dosc3612 at colorado.edu  Mon Oct  3 21:10:34 2016
From: dosc3612 at colorado.edu (Dominik Schneider)
Date: Mon, 3 Oct 2016 13:10:34 -0600
Subject: [R] To submit R jobs via SLURM
In-Reply-To: <CAAir+Cph-tX5KQVUbkr99L3TNNx-FGWCP5c0NzcU2jRJ6K2uzg@mail.gmail.com>
References: <CAAir+Cph-tX5KQVUbkr99L3TNNx-FGWCP5c0NzcU2jRJ6K2uzg@mail.gmail.com>
Message-ID: <CAF1jk_ku2UXjC-D-a+ss5r0uRJvZwAru8uO+ZygZkUQVAqP6bg@mail.gmail.com>

I typically call Rscript inside an sbatch file.

*batch_r.sh*
#! /bin/bash

cd /home/<myusername>/aso_regression_project #make sure you change to your
correct working directory
Rscript scripts/run_splitsample-modeling.R


and on the commandline of the login node:
sbatch batch_r.sh


There are lots of slurm configurations you can specify. Google for them.
Just add these under the first line and modify as needed:
#SBATCH --qos=
#SBATCH --mem=
#SBATCH --mail-type=begin,end,abort
#SBATCH --mail-user=userid at email.com
#SBATCH --time=
#SBATCH --nodes=
#SBATCH --job-name=myjob
#SBATCH --output=/home/<username>/run-%A_%a.Sout #special output filename


Dominik


On Mon, Oct 3, 2016 at 3:03 AM, Sema Atasever <s.atasever at gmail.com> wrote:

> Dear Authorized Sir / Madam,
>
> I have an R script file in which it includes this lines:
>
> How can i to submit this R jobs via SLURM? Thanks in advance.
>
> *testscript.R*
> data=read.table("seqDist.50", header=FALSE)[-1]
> attach(data)
> d=as.matrix(data)
> library(cluster)
> cluster.pam = pam(d,6)
> table(cluster.pam$clustering)
>
> filenameclu = paste("outputfile", ".txt")
> write.table(cluster.pam$clustering, file=outputfile,sep=",")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Mon Oct  3 21:33:38 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 3 Oct 2016 19:33:38 +0000
Subject: [R] R Mysql Not reading all table names
In-Reply-To: <CAJGK8=-uWgH1UQ7NQkEu926RCcVdZVWbB0M_tLMEFw74ff9OAw@mail.gmail.com>
References: <CAJGK8=-uWgH1UQ7NQkEu926RCcVdZVWbB0M_tLMEFw74ff9OAw@mail.gmail.com>
Message-ID: <D417FF12.187B42%macqueen1@llnl.gov>

You could try
  dbListTables()
and do the subsetting afterwards.

Also try
  dbGetQuery()
instead of dbSendQuery()

(There's no obvious reason that I can see to use dbSendQuery() followed by
fetch. It would be interesting if the two ways return different lists of
tables.)

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/3/16, 9:13 AM, "R-help on behalf of Vivek Singh"
<r-help-bounces at r-project.org on behalf of vivek4 at mail.usf.edu> wrote:

>Hi All:
>
>I am using R with MySQL, following is my code:
>
>library(RMySQL)
>con <- dbConnect(MySQL(), user="user", password="password", dbname="db",
>host="localhost")
>rs1 <- dbSendQuery(con, "show tables like \"%padded\"")
>all_tables3<- fetch(rs1, n=-1)
>
>There are 25 tables in the database when I execute the above query on the
>MySQL prompt. However, the above R code giving me only 9 tables. It seems
>there is some cache from which R is getting 9 tables instead of 25 tables.
>Please help.
>
>Regards,
>
>Vivek Kumar Singh
>
>PhD student,
>Information Systems Decision Sciences,
>MUMA College of Business,
>USF
>Phone- (813) 5809131
>Web: http://vivek4.myweb.usf.edu/
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Mon Oct  3 21:34:32 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 3 Oct 2016 15:34:32 -0400
Subject: [R] Looping through data tables (or data frames) by removing
 previous individuals
In-Reply-To: <AM5PR0402MB2689721B919E3606AD55ECF3BAC20@AM5PR0402MB2689.eurprd04.prod.outlook.com>
References: <AM5PR0402MB2689721B919E3606AD55ECF3BAC20@AM5PR0402MB2689.eurprd04.prod.outlook.com>
Message-ID: <CA+vqiLHQWoF=gO6dE2_ALCmx_FsRdCvSm51tt1JqBrrTgiVBUw@mail.gmail.com>

Hi Frank,

How about

library(lubridate)
dtf <- merge(dt, expand.grid(id = dt$id, refdate = v), by = "id")
dtf[, gt65 := as.period(interval(fborn, refdate), unit = "years") > years(65)]
dtf <- dtf[gt65 == TRUE,][, .SD[refdate == min(refdate)], by = id]

Best,
Ista

On Mon, Oct 3, 2016 at 1:17 PM, Frank S. <f_j_rod at hotmail.com> wrote:
> Dear R users,
>
> With this mail I send my third and last question I wanted to ask these days. First of all, many thanks
>
> for the received support in my previous mails! My question is this: Starting from a series of (for example)
>
> "k" different dates (all contained in vector "v"), I want to get a list of "k" data tables (or data frames) so
>
> that each contains those individuals who for the first time are at least 65, looping on each of the dates of
>
> vector "v". Let's consider the following example with 5 individuals:
>
>
> dt <- data.table(
>    id = 1:5,
>    fborn = as.Date(c("1935-07-25", "1942-10-05", "1942-09-07", "1943-09-07", "1943-12-31")),
>    sex = as.factor(rep(c(0, 1), c(2, 3)))
>    )
>
> v <- seq(as.Date("2006-01-01"), as.Date("2009-01-01"), by ="year") # k=4
>
>
> I would expect to obtain k=4 data tables so that:
> dt_p1: contains id = 1 (he is for the first time at least 65 on date v[1])
> dt_p2: is NULL (no subject reach for the first time 65 on date v[2])
> dt_p3: contains id = 2 & id = 3 (they are for the first time at least 65 on v[3])
> dt_p4: contains id = 4 & id = 5 (they are for the first time at least 65 on v[4])
>
>
> I have tried:
>
> dt_p <- list( )                        # Empty list to alocate data tables
>
> for (i in 1:length(v)) {
>   dt_p[[i]] <- dt[ !(id %in% dt_p[[1:(i-1)]]$id) &  # Remove subjects from previous dt_p's
>          round((v[i] - fborn)/365.25, 2) >= 65, ][ , list(id, fborn, sex)]
>
>  dt.names <- paste0("dt_p", 1:length(v))
>  assign(dt.names[i], dt_p[[i]])         # Assign a name to each data table
>  }
>
> However, I cannot express correctly the previous data tables, because for the first data
>
> table in the loop, there are not any previous. Consequently, I get an error message:
>
> # Error in dt_p[[1:(i - 1)]] : no such index at level 1
>
>
> I would be very grateful for anu suggestion!
>
> Frank S.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erinm.hodgess at gmail.com  Mon Oct  3 21:35:29 2016
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Mon, 3 Oct 2016 14:35:29 -0500
Subject: [R] To submit R jobs via SLURM
In-Reply-To: <CAF1jk_ku2UXjC-D-a+ss5r0uRJvZwAru8uO+ZygZkUQVAqP6bg@mail.gmail.com>
References: <CAAir+Cph-tX5KQVUbkr99L3TNNx-FGWCP5c0NzcU2jRJ6K2uzg@mail.gmail.com>
	<CAF1jk_ku2UXjC-D-a+ss5r0uRJvZwAru8uO+ZygZkUQVAqP6bg@mail.gmail.com>
Message-ID: <CACxE24n_oe6Lx3mszRn1rqzRPYLfXK-fDxdBCbjGpaWi-8TfzA@mail.gmail.com>

Get a SLURM batch file from someone there and make the appropriate changes
to it.  Best way to learn.



On Mon, Oct 3, 2016 at 2:10 PM, Dominik Schneider <dosc3612 at colorado.edu>
wrote:

> I typically call Rscript inside an sbatch file.
>
> *batch_r.sh*
> #! /bin/bash
>
> cd /home/<myusername>/aso_regression_project #make sure you change to your
> correct working directory
> Rscript scripts/run_splitsample-modeling.R
>
>
> and on the commandline of the login node:
> sbatch batch_r.sh
>
>
> There are lots of slurm configurations you can specify. Google for them.
> Just add these under the first line and modify as needed:
> #SBATCH --qos=
> #SBATCH --mem=
> #SBATCH --mail-type=begin,end,abort
> #SBATCH --mail-user=userid at email.com
> #SBATCH --time=
> #SBATCH --nodes=
> #SBATCH --job-name=myjob
> #SBATCH --output=/home/<username>/run-%A_%a.Sout #special output filename
>
>
> Dominik
>
>
> On Mon, Oct 3, 2016 at 3:03 AM, Sema Atasever <s.atasever at gmail.com>
> wrote:
>
> > Dear Authorized Sir / Madam,
> >
> > I have an R script file in which it includes this lines:
> >
> > How can i to submit this R jobs via SLURM? Thanks in advance.
> >
> > *testscript.R*
> > data=read.table("seqDist.50", header=FALSE)[-1]
> > attach(data)
> > d=as.matrix(data)
> > library(cluster)
> > cluster.pam = pam(d,6)
> > table(cluster.pam$clustering)
> >
> > filenameclu = paste("outputfile", ".txt")
> > write.table(cluster.pam$clustering, file=outputfile,sep=",")
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From ccberry at ucsd.edu  Mon Oct  3 21:38:05 2016
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Mon, 3 Oct 2016 12:38:05 -0700
Subject: [R] Looping through data tables (or data frames) by removing
 previous individuals
In-Reply-To: <AM5PR0402MB2689721B919E3606AD55ECF3BAC20@AM5PR0402MB2689.eurprd04.prod.outlook.com>
References: <AM5PR0402MB2689721B919E3606AD55ECF3BAC20@AM5PR0402MB2689.eurprd04.prod.outlook.com>
Message-ID: <alpine.OSX.2.20.1610031229200.908@charles-berrys-macbook.local>

On Mon, 3 Oct 2016, Frank S. wrote:

> Dear R users,
>
>

[deleted]

> I want to get a list of "k" data tables (or data frames) so that each 
> contains those individuals who for the first time are at least 65, 
> looping on each of the dates of vector "v". Let's consider the following 
> example with 5 individuals:
>
>
> dt <- data.table(
>   id = 1:5,
>   fborn = as.Date(c("1935-07-25", "1942-10-05", "1942-09-07", "1943-09-07", "1943-12-31")),
>   sex = as.factor(rep(c(0, 1), c(2, 3)))
>   )
>
> v <- seq(as.Date("2006-01-01"), as.Date("2009-01-01"), by ="year") # k=4
>
>
> I would expect to obtain k=4 data tables so that:
> dt_p1: contains id = 1 (he is for the first time at least 65 on date v[1])
> dt_p2: is NULL (no subject reach for the first time 65 on date v[2])
> dt_p3: contains id = 2 & id = 3 (they are for the first time at least 65 on v[3])
> dt_p4: contains id = 4 & id = 5 (they are for the first time at least 65 on v[4])
>
>

Here is a start (using a data.frame for dt):

> vp <- as.POSIXlt( c( as.Date("1000-01-01"), v ))
> vp$year <- vp$year-65
> dt.cut <- as.numeric(cut(as.POSIXlt(dt$fborn),vp))
> split(dt,factor(dt.cut, 1:length(v)))
$`1`
   id      fborn sex
1  1 1935-07-25   0

$`2`
[1] id    fborn sex
<0 rows> (or 0-length row.names)

$`3`
   id      fborn sex
2  2 1942-10-05   0
3  3 1942-09-07   1

$`4`
   id      fborn sex
4  4 1943-09-07   1
5  5 1943-12-31   1


See
   ?as.POSIXlt
   ?cut.POSIXt
   ?split

HTH,

Chuck


From dwinsemius at comcast.net  Mon Oct  3 22:56:07 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 3 Oct 2016 13:56:07 -0700
Subject: [R] Please help with creating the improved image with pheatmap
	package
In-Reply-To: <CAM=b0pf23aX9EzYyX5siTF-YNJz5uNep5u-O0f3i-sO69kkjRg@mail.gmail.com>
References: <CAM=b0pf23aX9EzYyX5siTF-YNJz5uNep5u-O0f3i-sO69kkjRg@mail.gmail.com>
Message-ID: <1049A186-5FEE-4367-A039-7A92E04B5249@comcast.net>


> On Oct 3, 2016, at 4:43 AM, maryam moazam <setareh227 at gmail.com> wrote:
> 
> Hi all,
> 
> I'm trying to show about 190 items using "pheatmap" package. I'm working
> with R 3.3.1 on windows 7. I used the following code:
> 
> pheatmap(mat_data, cellwidth=20, cluster_rows = FALSE, cluster_cols =
> FALSE, fontsize=5, fontsize_row=5, margins=c(5,10))
> 
> 
> The resulted image is attached. Please take a look at it. As you could see,
> the image quality is not good, in fact, the label of each row has not been
> appropriately shown at all in the picture. Could you please help me how I
> can modify the code to improve the image?
> 

If png() is your desired target then you probably will want to set different plotting parameters since your image is so tall.

?grDevices
?png   # guessing you need to set 'height' much higher
?par
?points  # good examples of low-level control 


> 
> 
> 
> Thank you very much in advance
> 
> Best regards,
> Maryam
> <image_pheatmap.png>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Tue Oct  4 00:19:08 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 4 Oct 2016 09:19:08 +1100
Subject: [R] Please help with creating the improved image with pheatmap
	package
In-Reply-To: <CAM=b0pf23aX9EzYyX5siTF-YNJz5uNep5u-O0f3i-sO69kkjRg@mail.gmail.com>
References: <CAM=b0pf23aX9EzYyX5siTF-YNJz5uNep5u-O0f3i-sO69kkjRg@mail.gmail.com>
Message-ID: <CA+8X3fV+anvL-GE8Psw7tmRtPosnAzaCf7Vh-Zd55TSsCrF87Q@mail.gmail.com>

Hi Maryam,
Your labels have been "greeked" as the font is too small to be
displayed properly. If you must use PNG format, specify your image
file at least twice as high.

png("pheatmap.png",width=1254,height=5000)

PDF would be a better choice as you can just zoom in and scroll down.

Jim


On Mon, Oct 3, 2016 at 10:43 PM, maryam moazam <setareh227 at gmail.com> wrote:
> Hi all,
>
> I'm trying to show about 190 items using "pheatmap" package. I'm working
> with R 3.3.1 on windows 7. I used the following code:
>
> pheatmap(mat_data, cellwidth=20, cluster_rows = FALSE, cluster_cols =
> FALSE, fontsize=5, fontsize_row=5, margins=c(5,10))
>
>
> The resulted image is attached. Please take a look at it. As you could see,
> the image quality is not good, in fact, the label of each row has not been
> appropriately shown at all in the picture. Could you please help me how I
> can modify the code to improve the image?
>
>
>
>
> Thank you very much in advance
>
> Best regards,
> Maryam
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Oct  4 00:25:52 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 4 Oct 2016 09:25:52 +1100
Subject: [R] Trouble with parameter estimation in nonlinear regression
	model
In-Reply-To: <CAF4yKE-uTuupx3EMKe9JcMveodFENMmkbLXSnm_R_oZEbz00zw@mail.gmail.com>
References: <CAF4yKE-uTuupx3EMKe9JcMveodFENMmkbLXSnm_R_oZEbz00zw@mail.gmail.com>
Message-ID: <CA+8X3fU+=riawANp8M7QCZBHCzA1NKNohKtwroFroLOG9is41w@mail.gmail.com>

Hi Syela,
Are the values in ASFR monotonically increasing with year?

Jim


On Tue, Oct 4, 2016 at 4:23 AM, Syela Mohd Noor <syelamohdnoor at gmail.com> wrote:
> Hi all, I had a problem with the parameter estimation of the Brass Gompertz
> model for my dissertation. I run the code for several times based on
> different years and it was fine until the seventh year onward where I got
> negative values for the parameter (a) which did not make sense since it
> represents the total fertility rate of a country.
> This is my code :
>
> gom.eq=function(a, b, c)
>
> {
>
>     age=c(17.5, 22.5, 27.5, 32.5, 37.5, 42.5 , 47.5)
>
>     k=(-(age-14)/b)
>
>     (a*((c/b)*(exp((k)-(c*(exp(k)))))))
>
> }
>
>
>
> varlist=list(
> ASFR$Y1960,ASFR$Y1965,ASFR$Y1970,ASFR$Y1975,ASFR$Y1980,ASFR$Y1985,
>
> ASFR$Y1990,ASFR$Y1995,ASFR$Y2000,ASFR$Y2005,ASFR$Y2010,ASFR$Y2013)
>
>
>
> gom.models=lapply(varlist, function(varlist)
>
> {
>
> nlsLM(varlist~gom.eq(a,b,c),data=ASFR,start=list(a=1 , b=1, c=1),trace=T)
>
> })
>
> summary(gom.models)
>
>
>
> gom.models[1:12]
>
>
>
>
> Any idea to solve the problem?
>
>
> Regards,
>
> Syela M.N.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From prseye at gmail.com  Tue Oct  4 00:30:03 2016
From: prseye at gmail.com (Paul Sanfilippo)
Date: Tue, 4 Oct 2016 09:30:03 +1100
Subject: [R] Multivariable Wald to test equality of multinomial coefficients
Message-ID: <etPan.57f2dbeb.5d0563b0.147@gmail.com>

Hi,

I am trying to replicate a test in the Hosmer - Applied Logistic regression text (pp 289, 3rd ed) that uses a Multivariable Wald test to test the equality of coefficients across the 2 logits of a 3 category response multinomial model. I?d like to see whether (from a ?statistical standpoint) it is acceptable to collapse the 2 response categories and then simply use a binary logistic regression. The idea is that if the coefficients across the 2 logits are similar (non-significant p value with Wald test), then it is reasonable to pool the categories.

There does not seem to be a built in way to do this in R?

Using the mtcars dataset as an example (for the sake of the example, using cyl as a 3-factor response), does anyone have any ideas how to do this

library(nnet)
data(mtcars)
mtcars$cyl <- as.factor(mtcars$cyl) ?
mtcars$am <- as.factor(mtcars$am) ?
mod <- multinom(cyl ~ am + hp, data=mtcars)
summary(mod)

> summary(mod)
Call:
multinom(formula = cyl ~ am + hp, data = mtcars)

Coefficients:
? (Intercept) ? ? ? am1 ? ? ? ?hp
6 ? -42.03847 ?-3.77398 0.4147498
8 ? -92.30944 -26.27554 0.7836576

So, I want to simultaneously test whether the 3 coefficients across the 2 logits are similar.

Thank you.



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Oct  4 01:08:11 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 3 Oct 2016 16:08:11 -0700
Subject: [R] Multivariable Wald to test equality of multinomial
	coefficients
In-Reply-To: <etPan.57f2dbeb.5d0563b0.147@gmail.com>
References: <etPan.57f2dbeb.5d0563b0.147@gmail.com>
Message-ID: <CAGxFJbTh9ypc=gUESzbPYTdKHe1Q0SnLG9ftG-BjLF22ZRkAZg@mail.gmail.com>

See inline.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Oct 3, 2016 at 3:30 PM, Paul Sanfilippo <prseye at gmail.com> wrote:
> Hi,
>
> I am trying to replicate a test in the Hosmer - Applied Logistic regression text (pp 289, 3rd ed) that uses a Multivariable Wald test to test the equality of coefficients across the 2 logits of a 3 category response multinomial model. I?d like to see whether (from a  statistical standpoint) it is acceptable to collapse the 2 response categories and then simply use a binary logistic regression.


"The idea is that if the coefficients across the 2 logits are similar
(non-significant p value with Wald test), then it is reasonable to
pool the categories."

IMHO, this is a bad idea. See
http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503.

Significance or lack of it is not a legitimate criterion on which to
base scientific decisions.



>
> There does not seem to be a built in way to do this in R?
>
> Using the mtcars dataset as an example (for the sake of the example, using cyl as a 3-factor response), does anyone have any ideas how to do this
>
> library(nnet)
> data(mtcars)
> mtcars$cyl <- as.factor(mtcars$cyl)
> mtcars$am <- as.factor(mtcars$am)
> mod <- multinom(cyl ~ am + hp, data=mtcars)
> summary(mod)
>
>> summary(mod)
> Call:
> multinom(formula = cyl ~ am + hp, data = mtcars)
>
> Coefficients:
>   (Intercept)       am1        hp
> 6   -42.03847  -3.77398 0.4147498
> 8   -92.30944 -26.27554 0.7836576
>
> So, I want to simultaneously test whether the 3 coefficients across the 2 logits are similar.
>
> Thank you.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From prseye at gmail.com  Tue Oct  4 01:15:13 2016
From: prseye at gmail.com (Paul Sanfilippo)
Date: Tue, 4 Oct 2016 10:15:13 +1100
Subject: [R] Multivariable Wald to test equality of multinomial
 coefficients
In-Reply-To: <CAGxFJbTh9ypc=gUESzbPYTdKHe1Q0SnLG9ftG-BjLF22ZRkAZg@mail.gmail.com>
References: <etPan.57f2dbeb.5d0563b0.147@gmail.com>
	<CAGxFJbTh9ypc=gUESzbPYTdKHe1Q0SnLG9ftG-BjLF22ZRkAZg@mail.gmail.com>
Message-ID: <etPan.57f2e682.3e14145a.147@gmail.com>

Thanks Bert,

I realise that and am not distilling it down to the p value. I am primarily considering the issue of collapsing down in the larger context of the added value/information that the extra categories give. However, I am curious to see (as I said from a statistical standpoint) whether the coefficients are sufficiently dissimilar.

Regards,

Paul Sanfilippo?



On 4 October 2016 at 10:08:12 am, Bert Gunter (bgunter.4567 at gmail.com) wrote:

See inline.  

-- Bert  

Bert Gunter  

"The trouble with having an open mind is that people keep coming along  
and sticking things into it."  
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )  


On Mon, Oct 3, 2016 at 3:30 PM, Paul Sanfilippo <prseye at gmail.com> wrote:  
> Hi,  
>  
> I am trying to replicate a test in the Hosmer - Applied Logistic regression text (pp 289, 3rd ed) that uses a Multivariable Wald test to test the equality of coefficients across the 2 logits of a 3 category response multinomial model. I?d like to see whether (from a statistical standpoint) it is acceptable to collapse the 2 response categories and then simply use a binary logistic regression.  


"The idea is that if the coefficients across the 2 logits are similar  
(non-significant p value with Wald test), then it is reasonable to  
pool the categories."  

IMHO, this is a bad idea. See  
http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503.  

Significance or lack of it is not a legitimate criterion on which to  
base scientific decisions.  



>  
> There does not seem to be a built in way to do this in R?  
>  
> Using the mtcars dataset as an example (for the sake of the example, using cyl as a 3-factor response), does anyone have any ideas how to do this  
>  
> library(nnet)  
> data(mtcars)  
> mtcars$cyl <- as.factor(mtcars$cyl)  
> mtcars$am <- as.factor(mtcars$am)  
> mod <- multinom(cyl ~ am + hp, data=mtcars)  
> summary(mod)  
>  
>> summary(mod)  
> Call:  
> multinom(formula = cyl ~ am + hp, data = mtcars)  
>  
> Coefficients:  
> (Intercept) am1 hp  
> 6 -42.03847 -3.77398 0.4147498  
> 8 -92.30944 -26.27554 0.7836576  
>  
> So, I want to simultaneously test whether the 3 coefficients across the 2 logits are similar.  
>  
> Thank you.  
>  
>  
>  
> [[alternative HTML version deleted]]  
>  
> ______________________________________________  
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see  
> https://stat.ethz.ch/mailman/listinfo/r-help  
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html  
> and provide commented, minimal, self-contained, reproducible code.  

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Oct  4 01:23:47 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 4 Oct 2016 01:23:47 +0200
Subject: [R] Multivariable Wald to test equality of multinomial
	coefficients
In-Reply-To: <etPan.57f2dbeb.5d0563b0.147@gmail.com>
References: <etPan.57f2dbeb.5d0563b0.147@gmail.com>
Message-ID: <BC76729D-977E-45B1-AEBC-2EB7AB4E4CA9@gmail.com>


> On 04 Oct 2016, at 00:30 , Paul Sanfilippo <prseye at gmail.com> wrote:
> 
> Hi,
> 
> I am trying to replicate a test in the Hosmer - Applied Logistic regression text (pp 289, 3rd ed) that uses a Multivariable Wald test to test the equality of coefficients across the 2 logits of a 3 category response multinomial model. I?d like to see whether (from a  statistical standpoint) it is acceptable to collapse the 2 response categories and then simply use a binary logistic regression. The idea is that if the coefficients across the 2 logits are similar (non-significant p value with Wald test), then it is reasonable to pool the categories.
> 
> There does not seem to be a built in way to do this in R?
> 
> Using the mtcars dataset as an example (for the sake of the example, using cyl as a 3-factor response), does anyone have any ideas how to do this
> 
> library(nnet)
> data(mtcars)
> mtcars$cyl <- as.factor(mtcars$cyl)  
> mtcars$am <- as.factor(mtcars$am)  
> mod <- multinom(cyl ~ am + hp, data=mtcars)
> summary(mod)
> 
>> summary(mod)
> Call:
> multinom(formula = cyl ~ am + hp, data = mtcars)
> 
> Coefficients:
>   (Intercept)       am1        hp
> 6   -42.03847  -3.77398 0.4147498
> 8   -92.30944 -26.27554 0.7836576
> 
> So, I want to simultaneously test whether the 3 coefficients across the 2 logits are similar.

R and R-packages do not always produce every single test that someone have thought up. Sometimes, you just get the tools to roll your own, and are expected to know enough theory to do so.

The generic technique for a Wald test would be to 

(a) extract the variance-covariance matrix (V) of the coefficients (beta)
(b) write the linear relation that you wish to test in matrix form A beta = 0
(c) the variance-covariance matrix of A beta will be A V A'
(d) the Wald test is (A beta)' (A V A')^{-1} (A beta)

For the case of multinom(), a little extra care is needed because it presents the coefficients as a matrix, and the variance covariance matrix is ordered as if the coefficients were organized as a vector _by row_:

> vcov(mod)
              6:(Intercept)       6:am1        6:hp 8:(Intercept)        8:am1
6:(Intercept)    771.682250  69.0782649 -7.61945359    168.212743  -463.676388
6:am1             69.078265  10.6015542 -0.71221686     13.069175   -38.850954
6:hp              -7.619454  -0.7122169  0.07550636     -1.647338     4.560144
8:(Intercept)    168.212743  13.0691754 -1.64733776   1019.860307 -1473.837691
8:am1           -463.676388 -38.8509537  4.56014436  -1473.837691  2195.306673
8:hp              -3.169803  -0.2992327  0.03147124     -7.719801    11.719345
                     8:hp
6:(Intercept) -3.16980299
6:am1         -0.29923273
6:hp           0.03147124
8:(Intercept) -7.71980097
8:am1         11.71934471
8:hp           0.06548745
> coef(mod)
  (Intercept)       am1        hp
6   -42.03847  -3.77398 0.4147498
8   -92.30944 -26.27554 0.7836576

So the thing to do would be roughly like this (the code can surely be improved):

> beta <- as.vector(t(coef(mod)))
> A  <- rbind(c(1,0,0,-1,0,0), c(0,1,0,0,-1,0), c(0,0,1,0,0,-1)) 
> A
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    1    0    0   -1    0    0
[2,]    0    1    0    0   -1    0
[3,]    0    0    1    0    0   -1
> A %*% beta
           [,1]
[1,] 50.2709610
[2,] 22.5015565
[3,] -0.3689079
> t(A %*% beta) %*% solve(A %*% vcov(mod) %*% t(A), A %*% beta) 
         [,1]
[1,] 3.592326

And then get the p-value from the asymptotic chi-square on 3-df

> pchisq(3.59, 3, lower=FALSE)
[1] 0.3092756

 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From prseye at gmail.com  Tue Oct  4 02:03:25 2016
From: prseye at gmail.com (Paul Sanfilippo)
Date: Tue, 4 Oct 2016 11:03:25 +1100
Subject: [R] Multivariable Wald to test equality of multinomial
 coefficients
In-Reply-To: <BC76729D-977E-45B1-AEBC-2EB7AB4E4CA9@gmail.com>
References: <etPan.57f2dbeb.5d0563b0.147@gmail.com>
	<BC76729D-977E-45B1-AEBC-2EB7AB4E4CA9@gmail.com>
Message-ID: <etPan.57f2f1cd.3f0bd743.147@gmail.com>

Thank you very much Peter - very enlightening to do it from first principles!

Regards,

Paul



On 4 October 2016 at 10:23:52 am, peter dalgaard (pdalgd at gmail.com) wrote:


> On 04 Oct 2016, at 00:30 , Paul Sanfilippo <prseye at gmail.com> wrote:  
>  
> Hi,  
>  
> I am trying to replicate a test in the Hosmer - Applied Logistic regression text (pp 289, 3rd ed) that uses a Multivariable Wald test to test the equality of coefficients across the 2 logits of a 3 category response multinomial model. I?d like to see whether (from a statistical standpoint) it is acceptable to collapse the 2 response categories and then simply use a binary logistic regression. The idea is that if the coefficients across the 2 logits are similar (non-significant p value with Wald test), then it is reasonable to pool the categories.  
>  
> There does not seem to be a built in way to do this in R?  
>  
> Using the mtcars dataset as an example (for the sake of the example, using cyl as a 3-factor response), does anyone have any ideas how to do this  
>  
> library(nnet)  
> data(mtcars)  
> mtcars$cyl <- as.factor(mtcars$cyl)  
> mtcars$am <- as.factor(mtcars$am)  
> mod <- multinom(cyl ~ am + hp, data=mtcars)  
> summary(mod)  
>  
>> summary(mod)  
> Call:  
> multinom(formula = cyl ~ am + hp, data = mtcars)  
>  
> Coefficients:  
> (Intercept) am1 hp  
> 6 -42.03847 -3.77398 0.4147498  
> 8 -92.30944 -26.27554 0.7836576  
>  
> So, I want to simultaneously test whether the 3 coefficients across the 2 logits are similar.  

R and R-packages do not always produce every single test that someone have thought up. Sometimes, you just get the tools to roll your own, and are expected to know enough theory to do so.  

The generic technique for a Wald test would be to  

(a) extract the variance-covariance matrix (V) of the coefficients (beta)  
(b) write the linear relation that you wish to test in matrix form A beta = 0  
(c) the variance-covariance matrix of A beta will be A V A'  
(d) the Wald test is (A beta)' (A V A')^{-1} (A beta)  

For the case of multinom(), a little extra care is needed because it presents the coefficients as a matrix, and the variance covariance matrix is ordered as if the coefficients were organized as a vector _by row_:  

> vcov(mod)  
6:(Intercept) 6:am1 6:hp 8:(Intercept) 8:am1  
6:(Intercept) 771.682250 69.0782649 -7.61945359 168.212743 -463.676388  
6:am1 69.078265 10.6015542 -0.71221686 13.069175 -38.850954  
6:hp -7.619454 -0.7122169 0.07550636 -1.647338 4.560144  
8:(Intercept) 168.212743 13.0691754 -1.64733776 1019.860307 -1473.837691  
8:am1 -463.676388 -38.8509537 4.56014436 -1473.837691 2195.306673  
8:hp -3.169803 -0.2992327 0.03147124 -7.719801 11.719345  
8:hp  
6:(Intercept) -3.16980299  
6:am1 -0.29923273  
6:hp 0.03147124  
8:(Intercept) -7.71980097  
8:am1 11.71934471  
8:hp 0.06548745  
> coef(mod)  
(Intercept) am1 hp  
6 -42.03847 -3.77398 0.4147498  
8 -92.30944 -26.27554 0.7836576  

So the thing to do would be roughly like this (the code can surely be improved):  

> beta <- as.vector(t(coef(mod)))  
> A <- rbind(c(1,0,0,-1,0,0), c(0,1,0,0,-1,0), c(0,0,1,0,0,-1))  
> A  
[,1] [,2] [,3] [,4] [,5] [,6]  
[1,] 1 0 0 -1 0 0  
[2,] 0 1 0 0 -1 0  
[3,] 0 0 1 0 0 -1  
> A %*% beta  
[,1]  
[1,] 50.2709610  
[2,] 22.5015565  
[3,] -0.3689079  
> t(A %*% beta) %*% solve(A %*% vcov(mod) %*% t(A), A %*% beta)  
[,1]  
[1,] 3.592326  

And then get the p-value from the asymptotic chi-square on 3-df  

> pchisq(3.59, 3, lower=FALSE)  
[1] 0.3092756  



--  
Peter Dalgaard, Professor,  
Center for Statistics, Copenhagen Business School  
Solbjerg Plads 3, 2000 Frederiksberg, Denmark  
Phone: (+45)38153501  
Office: A 4.23  
Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com  










	[[alternative HTML version deleted]]


From pingpong.tktan at gmail.com  Tue Oct  4 07:55:50 2016
From: pingpong.tktan at gmail.com (Teck Kiang Tan)
Date: Tue, 4 Oct 2016 13:55:50 +0800
Subject: [R] VGAM - complementary log-log Model
Message-ID: <CAGetN7WECg1MRN4AvcWD_mtURSOXoUy7fPCAz39y1-i+Q7icCQ@mail.gmail.com>

While running the vglm() with specification of cumulative(link=cloglog)
with a more complicated model, the following errors appeared. How to go
about solving it?


Error in if ((temp <- sum(wz[, 1:M, drop = FALSE] < wzepsilon)))
warning(paste(temp,  :

  argument is not interpretable as logical

In addition: Warning message:

In Deviance.categorical.data.vgam(mu = mu, y = y, w = w, residuals =
residuals,  :

  fitted values close to 0 or 1



Thanks.


TK

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Oct  4 08:19:27 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 4 Oct 2016 19:19:27 +1300
Subject: [R] Problem installing rgdal.
Message-ID: <0411eb09-a03f-2a52-62de-fe988f2e5a3b@auckland.ac.nz>


I have recently acquired a new laptop and a new OS (Ubuntu 16.04) and 
have encountered a problem when trying to install rgdal.

The initial hiccups were overcome by installing "libgdal-dev" and 
"libproj-dev" on my system, and then re-installing the package "sp" (as 
advised by postings that I googled up on StackOverflow.

But then I came to a shuddering halt when I got the following error 
response to run install.packages("rgdal",lib="/home/rolf/Rlib")

Error in dyn.load(file, DLLpath = DLLpath, ...) :
   unable to load shared object '/home/rolf/Rlib/rgdal/libs/rgdal.so':
   /home/rolf/Rlib/rgdal/libs/rgdal.so: undefined symbol: 
CPLQuietErrorHandler

I've googled around a bit on that and could find nothing that I could 
comprehend.

Can anyone point me in the right direction?  Ta.

cheers,

Rolf Turner
-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From f_j_rod at hotmail.com  Tue Oct  4 12:31:50 2016
From: f_j_rod at hotmail.com (Frank S.)
Date: Tue, 4 Oct 2016 10:31:50 +0000
Subject: [R] Looping through data tables (or data frames) by removing
 previous individuals
In-Reply-To: <alpine.OSX.2.20.1610031229200.908@charles-berrys-macbook.local>
References: <AM5PR0402MB2689721B919E3606AD55ECF3BAC20@AM5PR0402MB2689.eurprd04.prod.outlook.com>,
	<alpine.OSX.2.20.1610031229200.908@charles-berrys-macbook.local>
Message-ID: <AM5PR0402MB268928280918E8F4BAB5D9F8BAC50@AM5PR0402MB2689.eurprd04.prod.outlook.com>

Thank you very much Ista and Zahn!


Best,


Frank S.

________________________________
De: Charles C. Berry <ccberry at ucsd.edu>
Enviat el: dilluns, 3 d'octubre de 2016 21:38:05
Per a: Frank S.
A/c: r-help at r-project.org
Tema: Re: Looping through data tables (or data frames) by removing previous individuals

On Mon, 3 Oct 2016, Frank S. wrote:

> Dear R users,
>
>

[deleted]

> I want to get a list of "k" data tables (or data frames) so that each
> contains those individuals who for the first time are at least 65,
> looping on each of the dates of vector "v". Let's consider the following
> example with 5 individuals:
>
>
> dt <- data.table(
>   id = 1:5,
>   fborn = as.Date(c("1935-07-25", "1942-10-05", "1942-09-07", "1943-09-07", "1943-12-31")),
>   sex = as.factor(rep(c(0, 1), c(2, 3)))
>   )
>
> v <- seq(as.Date("2006-01-01"), as.Date("2009-01-01"), by ="year") # k=4
>
>
> I would expect to obtain k=4 data tables so that:
> dt_p1: contains id = 1 (he is for the first time at least 65 on date v[1])
> dt_p2: is NULL (no subject reach for the first time 65 on date v[2])
> dt_p3: contains id = 2 & id = 3 (they are for the first time at least 65 on v[3])
> dt_p4: contains id = 4 & id = 5 (they are for the first time at least 65 on v[4])
>
>

Here is a start (using a data.frame for dt):

> vp <- as.POSIXlt( c( as.Date("1000-01-01"), v ))
> vp$year <- vp$year-65
> dt.cut <- as.numeric(cut(as.POSIXlt(dt$fborn),vp))
> split(dt,factor(dt.cut, 1:length(v)))
$`1`
   id      fborn sex
1  1 1935-07-25   0

$`2`
[1] id    fborn sex
<0 rows> (or 0-length row.names)

$`3`
   id      fborn sex
2  2 1942-10-05   0
3  3 1942-09-07   1

$`4`
   id      fborn sex
4  4 1943-09-07   1
5  5 1943-12-31   1


See
   ?as.POSIXlt
   ?cut.POSIXt
   ?split

HTH,

Chuck

	[[alternative HTML version deleted]]


From kamil.barton at go2.pl  Tue Oct  4 13:18:13 2016
From: kamil.barton at go2.pl (=?UTF-8?Q?Kamil_Barto=c5=84?=)
Date: Tue, 4 Oct 2016 13:18:13 +0200
Subject: [R] Error in aictab with CLM model "function not yet defined"
In-Reply-To: <mailman.7.1475575201.4391.r-help@r-project.org>
References: <mailman.7.1475575201.4391.r-help@r-project.org>
Message-ID: <1c699f1d-8545-1769-808f-4a791acceeff@go2.pl>

Hi Caitie,
whatever it is you want to achieve, you seem to be doing it in a very complicated way. The code you 
gave appears to be for producing a model selection table, yet you say you're trying to do model 
averaging.

If you want a model selection table, why not use the one `dredge` produces (with evaluate=TRUE, you 
can add R^2 via argument 'extra')?
If you actually mean model averaging, there is `model.avg` that can be used directly on `dredge`'s 
output.

cheers,
k



W dniu 2016-10-04 o 12:00, r-help-request at r-project.org pisze:
> Message: 10
> Date: Mon, 3 Oct 2016 05:47:11 +0000
> From: Caitie Kuempel <c.kuempel at uq.edu.au>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] Error in aictab with CLM model "function not yet defined"
> Message-ID: <cb84ce6b22614415a40df8aa56f99a25 at uq-exmbx6.soe.uq.edu.au>
> Content-Type: text/plain; charset="UTF-8"
>
> Hi R help,
>
> I am trying to do some AIC model averaging on a CLM model in R and keep getting the error:
>
> Error in aictab.default(cand.set = Cand.model0, modnames = Modnames0,  :
> Function not yet defined for this object class
>
>
> The MuMIn package says that the functions should work for clm and clmm models so I'm not sure if I'm missing something or if there is an extra step?  Any help or examples would be appreciated.
>
> My model (m1) works fine- which I fit using the clm() function from the package ordinal.  Then I run the following:
>
> dred<-dredge(m1,rank="AICc",trace=TRUE,evaluate=FALSE)
> Cand.model0<-list()
> r2val<-rep(0,length(dred)) # r-square values
> for(i in 1:length(dred))
> {
>   print(length(dred)-i)
>   Cand.model0[[i]]<-clm(as.character(dred[[i]])[2],data=datt2,REML=FALSE)
>   #r2val[i]<-summary(Cand.model0[[i]])$r.squared
> }
>
> Modnames0 <- paste("mod", 1:length(Cand.model0), sep = " ")
> t0<-aictab(cand.set=Cand.model0, modnames=Modnames0, sort = TRUE, second.ord = TRUE,nobs = NULL)
> Error in aictab.default(cand.set = Cand.model0, modnames = Modnames0,  :
> Function not yet defined for this object class
>
> Thanks for your time.
>
> Best,
>
> Caitie
>
> 	[[alternative HTML version deleted]]
>
>


From profjcnash at gmail.com  Tue Oct  4 14:10:09 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Tue, 4 Oct 2016 08:10:09 -0400
Subject: [R] Problem installing rgdal.
In-Reply-To: <0411eb09-a03f-2a52-62de-fe988f2e5a3b@auckland.ac.nz>
References: <0411eb09-a03f-2a52-62de-fe988f2e5a3b@auckland.ac.nz>
Message-ID: <88d79342-950f-4dbf-bd13-55d5cdd06728@gmail.com>

I found that I have libgdal1-dev installed too.

john at john-J6-2015 ~ $ dpkg -l | grep gdal
ii  libgdal-dev                                 1.10.1+dfsg-5ubuntu1                                amd64
Geospatial Data Abstraction Library - Development files
ii  libgdal1-dev                                1.10.1+dfsg-5ubuntu1                                all
Geospatial Data Abstraction Library - Transitional package
ii  libgdal1h                                   1.10.1+dfsg-5ubuntu1                                amd64
Geospatial Data Abstraction Library
john at john-J6-2015 ~ $

and I get the following outputs in R:

> library(rgdal)
Loading required package: sp
rgdal: version: 1.1-10, (SVN revision 622)
 Geospatial Data Abstraction Library extensions to R successfully loaded
 Loaded GDAL runtime: GDAL 1.10.1, released 2013/08/26
 Path to GDAL shared files: /usr/share/gdal/1.10
 Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
 Path to PROJ.4 shared files: (autodetected)
 Linking to sp version: 1.2-3
> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.4 LTS

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
 [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
 [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rgdal_1.1-10 sp_1.2-3

loaded via a namespace (and not attached):
[1] grid_3.3.1      lattice_0.20-33
>

Hope this is helpful.

JN

On 16-10-04 02:19 AM, Rolf Turner wrote:
> 
> I have recently acquired a new laptop and a new OS (Ubuntu 16.04) and have encountered a problem when trying to install
> rgdal.
> 
> The initial hiccups were overcome by installing "libgdal-dev" and "libproj-dev" on my system, and then re-installing the
> package "sp" (as advised by postings that I googled up on StackOverflow.
> 
> But then I came to a shuddering halt when I got the following error response to run
> install.packages("rgdal",lib="/home/rolf/Rlib")
> 
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>   unable to load shared object '/home/rolf/Rlib/rgdal/libs/rgdal.so':
>   /home/rolf/Rlib/rgdal/libs/rgdal.so: undefined symbol: CPLQuietErrorHandler
> 
> I've googled around a bit on that and could find nothing that I could comprehend.
> 
> Can anyone point me in the right direction?  Ta.
> 
> cheers,
> 
> Rolf Turner


From jvadams at usgs.gov  Tue Oct  4 15:26:22 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 4 Oct 2016 08:26:22 -0500
Subject: [R] Trouble with parameter estimation in nonlinear regression
	model
In-Reply-To: <CAF4yKE-uTuupx3EMKe9JcMveodFENMmkbLXSnm_R_oZEbz00zw@mail.gmail.com>
References: <CAF4yKE-uTuupx3EMKe9JcMveodFENMmkbLXSnm_R_oZEbz00zw@mail.gmail.com>
Message-ID: <CAN5YmCFBGGckPttQ6iY5bzYJp4CYez0wL7Dqr2wL_cazWN0SWg@mail.gmail.com>

Syela,

If you want to constrain parameter "a" to be positive, you can rewrite the
equation replacing "a" with "exp(theta)".  Then when you get the estimate
for "theta", simply convert it back to "a".

Jean

On Mon, Oct 3, 2016 at 12:23 PM, Syela Mohd Noor <syelamohdnoor at gmail.com>
wrote:

> Hi all, I had a problem with the parameter estimation of the Brass Gompertz
> model for my dissertation. I run the code for several times based on
> different years and it was fine until the seventh year onward where I got
> negative values for the parameter (a) which did not make sense since it
> represents the total fertility rate of a country.
> This is my code :
>
> gom.eq=function(a, b, c)
>
> {
>
>     age=c(17.5, 22.5, 27.5, 32.5, 37.5, 42.5 , 47.5)
>
>     k=(-(age-14)/b)
>
>     (a*((c/b)*(exp((k)-(c*(exp(k)))))))
>
> }
>
>
>
> varlist=list(
> ASFR$Y1960,ASFR$Y1965,ASFR$Y1970,ASFR$Y1975,ASFR$Y1980,ASFR$Y1985,
>
> ASFR$Y1990,ASFR$Y1995,ASFR$Y2000,ASFR$Y2005,ASFR$Y2010,ASFR$Y2013)
>
>
>
> gom.models=lapply(varlist, function(varlist)
>
> {
>
> nlsLM(varlist~gom.eq(a,b,c),data=ASFR,start=list(a=1 , b=1, c=1),trace=T)
>
> })
>
> summary(gom.models)
>
>
>
> gom.models[1:12]
>
>
>
>
> Any idea to solve the problem?
>
>
> Regards,
>
> Syela M.N.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From mviljamaa at kapsi.fi  Tue Oct  4 17:39:42 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Tue, 04 Oct 2016 18:39:42 +0300
Subject: [R] What does lm() output coefficient mean when it's been given a
 categorical predictor of string values?
Message-ID: <9bfc69cbe3634b0df892d1df0c85b9ac@kapsi.fi>

I'm using lm() for a model that has a predictor that has two values 
{poika, tytt?} (boy and girl in Finnish).

I make a model with this categorical variable:

fit1 <- lm(dta$X.U.FEFF..mpist. ~ dta$sukup + dta$HISEI + dta$SES)

and while the variable/vector is here named as dta$sukup, what lm() 
returns is a coefficient

dta$sukuptytt?
      -6.19756

What does the added 'tytt?' in the variable mean? Does it mean that 
'tytt?' has been interpreted as 1 and 'poika' as 0?


From dwinsemius at comcast.net  Tue Oct  4 18:18:38 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 4 Oct 2016 09:18:38 -0700
Subject: [R] What does lm() output coefficient mean when it's been given
	a categorical predictor of string values?
In-Reply-To: <9bfc69cbe3634b0df892d1df0c85b9ac@kapsi.fi>
References: <9bfc69cbe3634b0df892d1df0c85b9ac@kapsi.fi>
Message-ID: <8996706F-B3A4-4B65-9BED-B813D79139FF@comcast.net>


> On Oct 4, 2016, at 8:39 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> 
> I'm using lm() for a model that has a predictor that has two values {poika, tytt?} (boy and girl in Finnish).
> 
> I make a model with this categorical variable:
> 
> fit1 <- lm(dta$X.U.FEFF..mpist. ~ dta$sukup + dta$HISEI + dta$SES)
> 
> and while the variable/vector is here named as dta$sukup, what lm() returns is a coefficient
> 
> dta$sukuptytt?
>     -6.19756
> 
> What does the added 'tytt?' in the variable mean? Does it mean that 'tytt?' has been interpreted as 1 and 'poika' as 0?

Yes.


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Tue Oct  4 18:45:10 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 4 Oct 2016 18:45:10 +0200
Subject: [R] What does lm() output coefficient mean when it's been given
	a categorical predictor of string values?
In-Reply-To: <9bfc69cbe3634b0df892d1df0c85b9ac@kapsi.fi>
References: <9bfc69cbe3634b0df892d1df0c85b9ac@kapsi.fi>
Message-ID: <664E30C8-FEB9-4AFF-A2B0-4222FC1664AA@gmail.com>


> On 04 Oct 2016, at 17:39 , mviljamaa <mviljamaa at kapsi.fi> wrote:
> 
> I'm using lm() for a model that has a predictor that has two values {poika, tytt?} (boy and girl in Finnish).
> 
> I make a model with this categorical variable:
> 
> fit1 <- lm(dta$X.U.FEFF..mpist. ~ dta$sukup + dta$HISEI + dta$SES)
> 
> and while the variable/vector is here named as dta$sukup, what lm() returns is a coefficient
> 
> dta$sukuptytt?
>   -6.19756
> 
> What does the added 'tytt?' in the variable mean? Does it mean that 'tytt?' has been interpreted as 1 and 'poika' as 0?

Short answer: Yes.

Long answer: Yes, if treatment contrast parametrization is being used.

See help(contrasts) for a lead-in to an even longer answer.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From fabien.verger at gmail.com  Tue Oct  4 18:51:16 2016
From: fabien.verger at gmail.com (fabien verger)
Date: Tue, 4 Oct 2016 18:51:16 +0200
Subject: [R] NA treatment when comparing two vectors
Message-ID: <CA+9bzniqCCqxrM3ArcyDgunCSUuktACjZyGt_com2mQErLdmAQ@mail.gmail.com>

Hello,

I want to get the differences when comparing 2 vectors, by pair (element by
element).
I'd like to get TRUEs when:
- the two compared elements are different and non-missing (like `!=` does)
- one element is missing and the other is not missing (unfortunatelly `!=`
gives NA and not TRUE)
Note that I don't want to get TRUEs when both are missing. NA or FALSE are
fine.

Given a and b:
> a <- c(1, 2, 3,  NA, NA)
> b <- c(1, 9, NA, 4 , NA)

The only solution I found is:

> a != b | (is.na(a) != is.na(b))
[1] FALSE  TRUE  TRUE  TRUE    NA

Is there a single function which can do the same?
I searched for other comparison tools but found nothing relevant.

And I would like also to avoid using `!=` because I'm often comparing
floating numbers computed by different algorithms (so rounded differently).

I found identical() interesting (for exemple, !(identical(NA, 99)) gives
TRUE) but the result of !(identical(a, b) is a single logical, not a vector
of logicals.

Many thanks in advance for your help.
P.S. I am new to R, coming from SAS. Actually, I'm looking for the R
function that replicates the SAS instruction: if a ^= b;

	[[alternative HTML version deleted]]


From s.atasever at gmail.com  Tue Oct  4 11:49:21 2016
From: s.atasever at gmail.com (Sema Atasever)
Date: Tue, 4 Oct 2016 12:49:21 +0300
Subject: [R] To submit R jobs via SLURM
In-Reply-To: <CACxE24n_oe6Lx3mszRn1rqzRPYLfXK-fDxdBCbjGpaWi-8TfzA@mail.gmail.com>
References: <CAAir+Cph-tX5KQVUbkr99L3TNNx-FGWCP5c0NzcU2jRJ6K2uzg@mail.gmail.com>
	<CAF1jk_ku2UXjC-D-a+ss5r0uRJvZwAru8uO+ZygZkUQVAqP6bg@mail.gmail.com>
	<CACxE24n_oe6Lx3mszRn1rqzRPYLfXK-fDxdBCbjGpaWi-8TfzA@mail.gmail.com>
Message-ID: <CAAir+Cr6ggBtFwehNByzkgsjywNxcUzCZJYoZDE6ccOuUPHq_w@mail.gmail.com>

Thank you very much for your help.

On Mon, Oct 3, 2016 at 10:35 PM, Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Get a SLURM batch file from someone there and make the appropriate changes
> to it.  Best way to learn.
>
>
>
> On Mon, Oct 3, 2016 at 2:10 PM, Dominik Schneider <dosc3612 at colorado.edu>
> wrote:
>
>> I typically call Rscript inside an sbatch file.
>>
>> *batch_r.sh*
>> #! /bin/bash
>>
>> cd /home/<myusername>/aso_regression_project #make sure you change to
>> your
>> correct working directory
>> Rscript scripts/run_splitsample-modeling.R
>>
>>
>> and on the commandline of the login node:
>> sbatch batch_r.sh
>>
>>
>> There are lots of slurm configurations you can specify. Google for them.
>> Just add these under the first line and modify as needed:
>> #SBATCH --qos=
>> #SBATCH --mem=
>> #SBATCH --mail-type=begin,end,abort
>> #SBATCH --mail-user=userid at email.com
>> #SBATCH --time=
>> #SBATCH --nodes=
>> #SBATCH --job-name=myjob
>> #SBATCH --output=/home/<username>/run-%A_%a.Sout #special output filename
>>
>>
>> Dominik
>>
>>
>> On Mon, Oct 3, 2016 at 3:03 AM, Sema Atasever <s.atasever at gmail.com>
>> wrote:
>>
>> > Dear Authorized Sir / Madam,
>> >
>> > I have an R script file in which it includes this lines:
>> >
>> > How can i to submit this R jobs via SLURM? Thanks in advance.
>> >
>> > *testscript.R*
>> > data=read.table("seqDist.50", header=FALSE)[-1]
>> > attach(data)
>> > d=as.matrix(data)
>> > library(cluster)
>> > cluster.pam = pam(d,6)
>> > table(cluster.pam$clustering)
>> >
>> > filenameclu = paste("outputfile", ".txt")
>> > write.table(cluster.pam$clustering, file=outputfile,sep=",")
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>

	[[alternative HTML version deleted]]


From kamil.barton at go2.pl  Tue Oct  4 13:14:49 2016
From: kamil.barton at go2.pl (=?UTF-8?Q?Kamil_Barto=c5=84?=)
Date: Tue, 4 Oct 2016 13:14:49 +0200
Subject: [R] R-help Digest, Vol 164, Issue 4
In-Reply-To: <mailman.7.1475575201.4391.r-help@r-project.org>
References: <mailman.7.1475575201.4391.r-help@r-project.org>
Message-ID: <63f8f031-07cb-daf1-bf28-aaeda133e2ce@go2.pl>

Hi Caitie,
whatever it is you want to achieve, you seem to be doing it in a very complicated way. The code you 
gave appears to be for producing a model selection table, yet you say you're trying to do model 
averaging.

If you want a model selection table, why not use the one `dredge` produces (with evaluate=TRUE, you 
can add R^2 via argument 'extra')?
If you actually mean model averaging, there is `model.avg` that can be used directly on `dredge`'s 
output.

cheers,
k



W dniu 2016-10-04 o 12:00, r-help-request at r-project.org pisze:
> Message: 10
> Date: Mon, 3 Oct 2016 05:47:11 +0000
> From: Caitie Kuempel <c.kuempel at uq.edu.au>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] Error in aictab with CLM model "function not yet defined"
> Message-ID: <cb84ce6b22614415a40df8aa56f99a25 at uq-exmbx6.soe.uq.edu.au>
> Content-Type: text/plain; charset="UTF-8"
>
> Hi R help,
>
> I am trying to do some AIC model averaging on a CLM model in R and keep getting the error:
>
> Error in aictab.default(cand.set = Cand.model0, modnames = Modnames0,  :
> Function not yet defined for this object class
>
>
> The MuMIn package says that the functions should work for clm and clmm models so I'm not sure if I'm missing something or if there is an extra step?  Any help or examples would be appreciated.
>
> My model (m1) works fine- which I fit using the clm() function from the package ordinal.  Then I run the following:
>
> dred<-dredge(m1,rank="AICc",trace=TRUE,evaluate=FALSE)
> Cand.model0<-list()
> r2val<-rep(0,length(dred)) # r-square values
> for(i in 1:length(dred))
> {
>   print(length(dred)-i)
>   Cand.model0[[i]]<-clm(as.character(dred[[i]])[2],data=datt2,REML=FALSE)
>   #r2val[i]<-summary(Cand.model0[[i]])$r.squared
> }
>
> Modnames0 <- paste("mod", 1:length(Cand.model0), sep = " ")
> t0<-aictab(cand.set=Cand.model0, modnames=Modnames0, sort = TRUE, second.ord = TRUE,nobs = NULL)
> Error in aictab.default(cand.set = Cand.model0, modnames = Modnames0,  :
> Function not yet defined for this object class
>
> Thanks for your time.
>
> Best,
>
> Caitie
>
> 	[[alternative HTML version deleted]]
>
>


From bgunter.4567 at gmail.com  Tue Oct  4 19:33:47 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 4 Oct 2016 10:33:47 -0700
Subject: [R] NA treatment when comparing two vectors
In-Reply-To: <CA+9bzniqCCqxrM3ArcyDgunCSUuktACjZyGt_com2mQErLdmAQ@mail.gmail.com>
References: <CA+9bzniqCCqxrM3ArcyDgunCSUuktACjZyGt_com2mQErLdmAQ@mail.gmail.com>
Message-ID: <CAGxFJbQEt1o6Zoc4hj1hiycKY28ekVCg596THdcjUmbQ8n87sA@mail.gmail.com>

Fabien:

In general, R's philosophy as a programming language is that it should
make it easy (and maybe efficient) to do the (data analysis) things
you want to do, not necessarily provide all pre-packaged procedures
(although with all the packages, it seems to come close to that!). So
the following seems to fall into that paradigm (using your example a
and b)

> tol <- 1e-15

> xor(is.na(a),is.na(b)) | (abs(b-a) > tol)
[1] FALSE  TRUE  TRUE  TRUE    NA


As you noted, defining equality of floating point numbers is a tricky
business, so that you may prefer some other approach to that which I
used. There may well be "pre-packaged" ways to do this, but I didn't
look. You might try searching rseek.org for "defining numerical
equality in R" or some such to see.


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Oct 4, 2016 at 9:51 AM, fabien verger <fabien.verger at gmail.com> wrote:
> Hello,
>
> I want to get the differences when comparing 2 vectors, by pair (element by
> element).
> I'd like to get TRUEs when:
> - the two compared elements are different and non-missing (like `!=` does)
> - one element is missing and the other is not missing (unfortunatelly `!=`
> gives NA and not TRUE)
> Note that I don't want to get TRUEs when both are missing. NA or FALSE are
> fine.
>
> Given a and b:
>> a <- c(1, 2, 3,  NA, NA)
>> b <- c(1, 9, NA, 4 , NA)
>
> The only solution I found is:
>
>> a != b | (is.na(a) != is.na(b))
> [1] FALSE  TRUE  TRUE  TRUE    NA
>
> Is there a single function which can do the same?
> I searched for other comparison tools but found nothing relevant.
>
> And I would like also to avoid using `!=` because I'm often comparing
> floating numbers computed by different algorithms (so rounded differently).
>
> I found identical() interesting (for exemple, !(identical(NA, 99)) gives
> TRUE) but the result of !(identical(a, b) is a single logical, not a vector
> of logicals.
>
> Many thanks in advance for your help.
> P.S. I am new to R, coming from SAS. Actually, I'm looking for the R
> function that replicates the SAS instruction: if a ^= b;
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Tue Oct  4 20:37:33 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 04 Oct 2016 13:37:33 -0500
Subject: [R] NA treatment when comparing two vectors
In-Reply-To: <CAGxFJbQEt1o6Zoc4hj1hiycKY28ekVCg596THdcjUmbQ8n87sA@mail.gmail.com>
References: <CA+9bzniqCCqxrM3ArcyDgunCSUuktACjZyGt_com2mQErLdmAQ@mail.gmail.com>
	<CAGxFJbQEt1o6Zoc4hj1hiycKY28ekVCg596THdcjUmbQ8n87sA@mail.gmail.com>
Message-ID: <280A2F2F-F484-4067-9525-0A7B3EC02AE7@me.com>

Hi,

A couple of comments:

1. Fabien, since you are transitioning from SAS, you may find the resources that Bob Muenchen has made available to be of value:

    http://r4stats.com/ <http://r4stats.com/>

There is a free download (PDF) of an earlier version of his book available via his web site as well.


2. Presuming that Bert's approach satisfies your functional requirements in this case, you can encapsulate his code into a function that you might find easier to use moving forward. For example:

IsDiff <- function(a, b, tol = 1e-15) {
  xor(is.na(a),is.na(b)) | (abs(b-a) > tol)
}

a <- c(1, 2, 3,  NA, NA)
b <- c(1, 9, NA, 4 , NA)

> IsDiff(a, b)
[1] FALSE  TRUE  TRUE  TRUE    NA

Of course, you can call the function anything you wish, as long as it is a legal object name in R.

You could even create a new infix operator along the lines of the following, with the restriction that this approach can only take two arguments, so you would hard code the tolerance level in the function body:

"%ID%" <- function(a, b) {
  xor(is.na(a),is.na(b)) | (abs(b-a) > 1e-15)
}

> a %ID% b
[1] FALSE  TRUE  TRUE  TRUE    NA


Bear in mind that a substantial portion of R is written in R itself, with a core set of functionality in C and FORTRAN where performance is materially enhanced by the use of compiled code. Thus, extending R's functionality, as Bert notes, is typically done by useRs encapsulating enhanced functionality in new R functions and the now thousands of packages on CRAN generally follow that same paradigm for specific applications.

Regards,

Marc Schwartz


> On Oct 4, 2016, at 12:33 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Fabien:
> 
> In general, R's philosophy as a programming language is that it should
> make it easy (and maybe efficient) to do the (data analysis) things
> you want to do, not necessarily provide all pre-packaged procedures
> (although with all the packages, it seems to come close to that!). So
> the following seems to fall into that paradigm (using your example a
> and b)
> 
>> tol <- 1e-15
> 
>> xor(is.na(a),is.na(b)) | (abs(b-a) > tol)
> [1] FALSE  TRUE  TRUE  TRUE    NA
> 
> 
> As you noted, defining equality of floating point numbers is a tricky
> business, so that you may prefer some other approach to that which I
> used. There may well be "pre-packaged" ways to do this, but I didn't
> look. You might try searching rseek.org for "defining numerical
> equality in R" or some such to see.
> 
> 
> Cheers,
> Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Tue, Oct 4, 2016 at 9:51 AM, fabien verger <fabien.verger at gmail.com> wrote:
>> Hello,
>> 
>> I want to get the differences when comparing 2 vectors, by pair (element by
>> element).
>> I'd like to get TRUEs when:
>> - the two compared elements are different and non-missing (like `!=` does)
>> - one element is missing and the other is not missing (unfortunatelly `!=`
>> gives NA and not TRUE)
>> Note that I don't want to get TRUEs when both are missing. NA or FALSE are
>> fine.
>> 
>> Given a and b:
>>> a <- c(1, 2, 3,  NA, NA)
>>> b <- c(1, 9, NA, 4 , NA)
>> 
>> The only solution I found is:
>> 
>>> a != b | (is.na(a) != is.na(b))
>> [1] FALSE  TRUE  TRUE  TRUE    NA
>> 
>> Is there a single function which can do the same?
>> I searched for other comparison tools but found nothing relevant.
>> 
>> And I would like also to avoid using `!=` because I'm often comparing
>> floating numbers computed by different algorithms (so rounded differently).
>> 
>> I found identical() interesting (for exemple, !(identical(NA, 99)) gives
>> TRUE) but the result of !(identical(a, b) is a single logical, not a vector
>> of logicals.
>> 
>> Many thanks in advance for your help.
>> P.S. I am new to R, coming from SAS. Actually, I'm looking for the R
>> function that replicates the SAS instruction: if a ^= b;


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Oct  4 21:02:25 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 4 Oct 2016 12:02:25 -0700
Subject: [R] NA treatment when comparing two vectors
In-Reply-To: <CA+9bzniqCCqxrM3ArcyDgunCSUuktACjZyGt_com2mQErLdmAQ@mail.gmail.com>
References: <CA+9bzniqCCqxrM3ArcyDgunCSUuktACjZyGt_com2mQErLdmAQ@mail.gmail.com>
Message-ID: <CAF8bMcbOptxFYLKQhNmdjmnKU9__Ro_LEowPCGxDnmC38Fx33g@mail.gmail.com>

The all.equal function returns TRUE if two objects are pretty similar to
one another and a textual description of the differences if not.  Use
isTRUE on its output if you just want a TRUE/FALSE answer.

  > all.equal(c(1,2*(1+.Machine$double.eps),NaN), c(1,2,NaN))
  [1] TRUE
  > all.equal(c(1,2*(1+.Machine$double.eps),NaN), c(1,2,NaN), tolerance=0)
  [1] "Mean relative difference: 2.220446e-16"
  > isTRUE(all.equal(c(1,2*(1+.Machine$double.eps),NaN), c(1,2,NaN),
tolerance=0))
  [1] FALSE
  > all.equal(c(a=1, b=2), c(x=1, b=2))
  [1] "Names: 1 string mismatch"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Oct 4, 2016 at 9:51 AM, fabien verger <fabien.verger at gmail.com>
wrote:

> Hello,
>
> I want to get the differences when comparing 2 vectors, by pair (element by
> element).
> I'd like to get TRUEs when:
> - the two compared elements are different and non-missing (like `!=` does)
> - one element is missing and the other is not missing (unfortunatelly `!=`
> gives NA and not TRUE)
> Note that I don't want to get TRUEs when both are missing. NA or FALSE are
> fine.
>
> Given a and b:
> > a <- c(1, 2, 3,  NA, NA)
> > b <- c(1, 9, NA, 4 , NA)
>
> The only solution I found is:
>
> > a != b | (is.na(a) != is.na(b))
> [1] FALSE  TRUE  TRUE  TRUE    NA
>
> Is there a single function which can do the same?
> I searched for other comparison tools but found nothing relevant.
>
> And I would like also to avoid using `!=` because I'm often comparing
> floating numbers computed by different algorithms (so rounded differently).
>
> I found identical() interesting (for exemple, !(identical(NA, 99)) gives
> TRUE) but the result of !(identical(a, b) is a single logical, not a vector
> of logicals.
>
> Many thanks in advance for your help.
> P.S. I am new to R, coming from SAS. Actually, I'm looking for the R
> function that replicates the SAS instruction: if a ^= b;
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Oct  4 21:17:50 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 04 Oct 2016 14:17:50 -0500
Subject: [R] NA treatment when comparing two vectors
In-Reply-To: <CAF8bMcbOptxFYLKQhNmdjmnKU9__Ro_LEowPCGxDnmC38Fx33g@mail.gmail.com>
References: <CA+9bzniqCCqxrM3ArcyDgunCSUuktACjZyGt_com2mQErLdmAQ@mail.gmail.com>
	<CAF8bMcbOptxFYLKQhNmdjmnKU9__Ro_LEowPCGxDnmC38Fx33g@mail.gmail.com>
Message-ID: <73BC74DF-DB29-4E05-B2C2-66F40A0AD490@me.com>

Bill,

I had initially thought of using all.equal() along with isTrue(), however Fabien's desire for a pairwise element based approach, along with the specific NA handling steered me away from it and towards code along the lines of what Bert had offered, which builds on the basic notion of approximate numeric equality as used in all.equal().

Regards,

Marc


> On Oct 4, 2016, at 2:02 PM, William Dunlap via R-help <r-help at r-project.org> wrote:
> 
> The all.equal function returns TRUE if two objects are pretty similar to
> one another and a textual description of the differences if not.  Use
> isTRUE on its output if you just want a TRUE/FALSE answer.
> 
>> all.equal(c(1,2*(1+.Machine$double.eps),NaN), c(1,2,NaN))
>  [1] TRUE
>> all.equal(c(1,2*(1+.Machine$double.eps),NaN), c(1,2,NaN), tolerance=0)
>  [1] "Mean relative difference: 2.220446e-16"
>> isTRUE(all.equal(c(1,2*(1+.Machine$double.eps),NaN), c(1,2,NaN),
> tolerance=0))
>  [1] FALSE
>> all.equal(c(a=1, b=2), c(x=1, b=2))
>  [1] "Names: 1 string mismatch"
> 
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Tue, Oct 4, 2016 at 9:51 AM, fabien verger <fabien.verger at gmail.com>
> wrote:
> 
>> Hello,
>> 
>> I want to get the differences when comparing 2 vectors, by pair (element by
>> element).
>> I'd like to get TRUEs when:
>> - the two compared elements are different and non-missing (like `!=` does)
>> - one element is missing and the other is not missing (unfortunatelly `!=`
>> gives NA and not TRUE)
>> Note that I don't want to get TRUEs when both are missing. NA or FALSE are
>> fine.
>> 
>> Given a and b:
>>> a <- c(1, 2, 3,  NA, NA)
>>> b <- c(1, 9, NA, 4 , NA)
>> 
>> The only solution I found is:
>> 
>>> a != b | (is.na(a) != is.na(b))
>> [1] FALSE  TRUE  TRUE  TRUE    NA
>> 
>> Is there a single function which can do the same?
>> I searched for other comparison tools but found nothing relevant.
>> 
>> And I would like also to avoid using `!=` because I'm often comparing
>> floating numbers computed by different algorithms (so rounded differently).
>> 
>> I found identical() interesting (for exemple, !(identical(NA, 99)) gives
>> TRUE) but the result of !(identical(a, b) is a single logical, not a vector
>> of logicals.
>> 
>> Many thanks in advance for your help.
>> P.S. I am new to R, coming from SAS. Actually, I'm looking for the R
>> function that replicates the SAS instruction: if a ^= b;
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cbarros at hbs.edu  Tue Oct  4 20:27:07 2016
From: cbarros at hbs.edu (Barros, Chris)
Date: Tue, 4 Oct 2016 18:27:07 +0000
Subject: [R] R Compile From Source Issue RHEL 6.5
Message-ID: <73F29FC1-C8C3-41DA-BE6E-C08BC17661FD@hbs.edu>

Hi-

I?m compiling R from source and running into an issue when enabling --enable-R-shlib. I get the following below. I did try and add ?-fPIC" to the bzip2 makefile with no luck.

/usr/bin/ld: /usr/local/apps/R/3.3.1/library/lib/libbz2.a(bzlib.o): relocation R_X86_64_32S against `.text' can not be used when making a shared object; recompile with -fPIC

/usr/local/apps/R/3.3.1/library/lib/libbz2.a: could not read symbols: Bad value

collect2: ld returned 1 exit status




apps/R/3.3.1/library/include/  -c g_cntrlify.c -o g_cntrlify.o

gcc -std=gnu99 -I../../src/extra  -I. -I../../src/include -I../../src/include  -I/usr/local/include -I../../src/nmath -DHAVE_CONFIG_H   -fopenmp -fpic  -I/usr/local/apps/R/3.3.1/library/include/ -I/usr/local/apps/R/3.3.1/library/include/  -c g_fontdb.c -o g_fontdb.o

gcc -std=gnu99 -I../../src/extra  -I. -I../../src/include -I../../src/include  -I/usr/local/include -I../../src/nmath -DHAVE_CONFIG_H   -fopenmp -fpic  -I/usr/local/apps/R/3.3.1/library/include/ -I/usr/local/apps/R/3.3.1/library/include/  -c g_her_glyph.c -o g_her_glyph.o

gfortran  -fopenmp -fpic  -g -O2  -c xxxpr.f -o xxxpr.o

gcc -std=gnu99 -shared -fopenmp -L/usr/local/apps/R/3.3.1/library/lib  -o libR.so CommandLineArgs.o Rdynload.o Renviron.o RNG.o agrep.o apply.o arithmetic.o array.o attrib.o bind.o builtin.o character.o coerce.o colors.o complex.o connections.o context.o cum.o dcf.o datetime.o debug.o deparse.o devices.o dotcode.o dounzip.o dstruct.o duplicate.o edit.o engine.o envir.o errors.o eval.o format.o gevents.o gram.o gram-ex.o graphics.o grep.o identical.o inlined.o inspect.o internet.o iosupport.o lapack.o list.o localecharset.o logic.o main.o mapply.o match.o memory.o names.o objects.o options.o paste.o platform.o plot.o plot3d.o plotmath.o print.o printarray.o printvector.o printutils.o qsort.o radixsort.o random.o raw.o registration.o relop.o rlocale.o saveload.o scan.o seq.o serialize.o sort.o source.o split.o sprintf.o startup.o subassign.o subscript.o subset.o summary.o sysutils.o times.o unique.o util.o version.o g_alab_her.o g_cntrlify.o g_fontdb.o g_her_glyph.o xxxpr.o   `ls ../unix/*.o ../appl/*.o ../nmath/*.o` ../extra/tre/libtre.a    -L../../lib -lRblas -lgfortran -lm   -lreadline  -lpcre -llzma -lbz2 -lz -lrt -ldl -lm

/usr/bin/ld: /usr/local/apps/R/3.3.1/library/lib/libbz2.a(bzlib.o): relocation R_X86_64_32S against `.text' can not be used when making a shared object; recompile with -fPIC

/usr/local/apps/R/3.3.1/library/lib/libbz2.a: could not read symbols: Bad value

collect2: ld returned 1 exit status

make[3]: *** [libR.so] Error 1

make[3]: Leaving directory `/usr/local/apps/R/3.3.1/R-3.3.1-source/src/main'

make[2]: *** [R] Error 2

make[2]: Leaving directory `/usr/local/apps/R/3.3.1/R-3.3.1-source/src/main'

make[1]: *** [R] Error 1

make[1]: Leaving directory `/usr/local/apps/R/3.3.1/R-3.3.1-source/src'

make: *** [R] Error 1

Any help would be appreciated.

Christopher Barros | Sr. Systems Engineer| Information Technology Group | Harvard Business School| 617.496.5180<tel:617.496.5180>| cbarros at hbs.edu<mailto:cbarros at hbs.edu>


	[[alternative HTML version deleted]]


From fabien.verger at gmail.com  Tue Oct  4 22:08:31 2016
From: fabien.verger at gmail.com (fabien verger)
Date: Tue, 4 Oct 2016 22:08:31 +0200
Subject: [R] NA treatment when comparing two vectors
In-Reply-To: <73BC74DF-DB29-4E05-B2C2-66F40A0AD490@me.com>
References: <CA+9bzniqCCqxrM3ArcyDgunCSUuktACjZyGt_com2mQErLdmAQ@mail.gmail.com>
	<CAF8bMcbOptxFYLKQhNmdjmnKU9__Ro_LEowPCGxDnmC38Fx33g@mail.gmail.com>
	<73BC74DF-DB29-4E05-B2C2-66F40A0AD490@me.com>
Message-ID: <CA+9bzng3etn4FU4QqhgU=ztr-UKP-Nrzco2dnYhs_FzZgOXb3g@mail.gmail.com>

Thank you all - Bert, Marc and William - for your suggestions and the
material (Rseek, r4stats.com...).
Following your advices, I will create a dedicated function since I will
have to use this tool in many programs.
Actually, I regularly load economic data from various sources and I need to
spot what is *different* than the previous version, and what is *new*,
hence the utility of this function and this special NA treatment.
Thanks again for your help and for your reactivity.
Fabien


2016-10-04 21:17 GMT+02:00 Marc Schwartz <marc_schwartz at me.com>:

> Bill,
>
> I had initially thought of using all.equal() along with isTrue(), however
> Fabien's desire for a pairwise element based approach, along with the
> specific NA handling steered me away from it and towards code along the
> lines of what Bert had offered, which builds on the basic notion of
> approximate numeric equality as used in all.equal().
>
> Regards,
>
> Marc
>
>
> > On Oct 4, 2016, at 2:02 PM, William Dunlap via R-help <
> r-help at r-project.org> wrote:
> >
> > The all.equal function returns TRUE if two objects are pretty similar to
> > one another and a textual description of the differences if not.  Use
> > isTRUE on its output if you just want a TRUE/FALSE answer.
> >
> >> all.equal(c(1,2*(1+.Machine$double.eps),NaN), c(1,2,NaN))
> >  [1] TRUE
> >> all.equal(c(1,2*(1+.Machine$double.eps),NaN), c(1,2,NaN), tolerance=0)
> >  [1] "Mean relative difference: 2.220446e-16"
> >> isTRUE(all.equal(c(1,2*(1+.Machine$double.eps),NaN), c(1,2,NaN),
> > tolerance=0))
> >  [1] FALSE
> >> all.equal(c(a=1, b=2), c(x=1, b=2))
> >  [1] "Names: 1 string mismatch"
> >
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Tue, Oct 4, 2016 at 9:51 AM, fabien verger <fabien.verger at gmail.com>
> > wrote:
> >
> >> Hello,
> >>
> >> I want to get the differences when comparing 2 vectors, by pair
> (element by
> >> element).
> >> I'd like to get TRUEs when:
> >> - the two compared elements are different and non-missing (like `!=`
> does)
> >> - one element is missing and the other is not missing (unfortunatelly
> `!=`
> >> gives NA and not TRUE)
> >> Note that I don't want to get TRUEs when both are missing. NA or FALSE
> are
> >> fine.
> >>
> >> Given a and b:
> >>> a <- c(1, 2, 3,  NA, NA)
> >>> b <- c(1, 9, NA, 4 , NA)
> >>
> >> The only solution I found is:
> >>
> >>> a != b | (is.na(a) != is.na(b))
> >> [1] FALSE  TRUE  TRUE  TRUE    NA
> >>
> >> Is there a single function which can do the same?
> >> I searched for other comparison tools but found nothing relevant.
> >>
> >> And I would like also to avoid using `!=` because I'm often comparing
> >> floating numbers computed by different algorithms (so rounded
> differently).
> >>
> >> I found identical() interesting (for exemple, !(identical(NA, 99)) gives
> >> TRUE) but the result of !(identical(a, b) is a single logical, not a
> vector
> >> of logicals.
> >>
> >> Many thanks in advance for your help.
> >> P.S. I am new to R, coming from SAS. Actually, I'm looking for the R
> >> function that replicates the SAS instruction: if a ^= b;
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Oct  4 22:53:53 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 04 Oct 2016 13:53:53 -0700
Subject: [R] R Compile From Source Issue RHEL 6.5
In-Reply-To: <73F29FC1-C8C3-41DA-BE6E-C08BC17661FD@hbs.edu>
References: <73F29FC1-C8C3-41DA-BE6E-C08BC17661FD@hbs.edu>
Message-ID: <8D096903-A210-4274-BBE0-4D30CD6379F0@dcn.davis.ca.us>

You may get a response here, but the Posting Guide is pretty clear that this is not the recommended place to ask this question.
-- 
Sent from my phone. Please excuse my brevity.

On October 4, 2016 11:27:07 AM PDT, "Barros, Chris" <cbarros at hbs.edu> wrote:
>Hi-
>
>I?m compiling R from source and running into an issue when enabling
>--enable-R-shlib. I get the following below. I did try and add ?-fPIC"
>to the bzip2 makefile with no luck.
>
>/usr/bin/ld: /usr/local/apps/R/3.3.1/library/lib/libbz2.a(bzlib.o):
>relocation R_X86_64_32S against `.text' can not be used when making a
>shared object; recompile with -fPIC
>
>/usr/local/apps/R/3.3.1/library/lib/libbz2.a: could not read symbols:
>Bad value
>
>collect2: ld returned 1 exit status
>
>
>
>
>apps/R/3.3.1/library/include/  -c g_cntrlify.c -o g_cntrlify.o
>
>gcc -std=gnu99 -I../../src/extra  -I. -I../../src/include
>-I../../src/include  -I/usr/local/include -I../../src/nmath
>-DHAVE_CONFIG_H   -fopenmp -fpic 
>-I/usr/local/apps/R/3.3.1/library/include/
>-I/usr/local/apps/R/3.3.1/library/include/  -c g_fontdb.c -o g_fontdb.o
>
>gcc -std=gnu99 -I../../src/extra  -I. -I../../src/include
>-I../../src/include  -I/usr/local/include -I../../src/nmath
>-DHAVE_CONFIG_H   -fopenmp -fpic 
>-I/usr/local/apps/R/3.3.1/library/include/
>-I/usr/local/apps/R/3.3.1/library/include/  -c g_her_glyph.c -o
>g_her_glyph.o
>
>gfortran  -fopenmp -fpic  -g -O2  -c xxxpr.f -o xxxpr.o
>
>gcc -std=gnu99 -shared -fopenmp -L/usr/local/apps/R/3.3.1/library/lib 
>-o libR.so CommandLineArgs.o Rdynload.o Renviron.o RNG.o agrep.o
>apply.o arithmetic.o array.o attrib.o bind.o builtin.o character.o
>coerce.o colors.o complex.o connections.o context.o cum.o dcf.o
>datetime.o debug.o deparse.o devices.o dotcode.o dounzip.o dstruct.o
>duplicate.o edit.o engine.o envir.o errors.o eval.o format.o gevents.o
>gram.o gram-ex.o graphics.o grep.o identical.o inlined.o inspect.o
>internet.o iosupport.o lapack.o list.o localecharset.o logic.o main.o
>mapply.o match.o memory.o names.o objects.o options.o paste.o
>platform.o plot.o plot3d.o plotmath.o print.o printarray.o
>printvector.o printutils.o qsort.o radixsort.o random.o raw.o
>registration.o relop.o rlocale.o saveload.o scan.o seq.o serialize.o
>sort.o source.o split.o sprintf.o startup.o subassign.o subscript.o
>subset.o summary.o sysutils.o times.o unique.o util.o version.o
>g_alab_her.o g_cntrlify.o g_fontdb.o g_her_glyph.o xxxpr.o   `ls
>../unix/*.o ../appl/*.o ../nmath/*.o` ../extra/tre/libtre.a   
>-L../../lib -lRblas -lgfortran -lm   -lreadline  -lpcre -llzma -lbz2
>-lz -lrt -ldl -lm
>
>/usr/bin/ld: /usr/local/apps/R/3.3.1/library/lib/libbz2.a(bzlib.o):
>relocation R_X86_64_32S against `.text' can not be used when making a
>shared object; recompile with -fPIC
>
>/usr/local/apps/R/3.3.1/library/lib/libbz2.a: could not read symbols:
>Bad value
>
>collect2: ld returned 1 exit status
>
>make[3]: *** [libR.so] Error 1
>
>make[3]: Leaving directory
>`/usr/local/apps/R/3.3.1/R-3.3.1-source/src/main'
>
>make[2]: *** [R] Error 2
>
>make[2]: Leaving directory
>`/usr/local/apps/R/3.3.1/R-3.3.1-source/src/main'
>
>make[1]: *** [R] Error 1
>
>make[1]: Leaving directory `/usr/local/apps/R/3.3.1/R-3.3.1-source/src'
>
>make: *** [R] Error 1
>
>Any help would be appreciated.
>
>Christopher Barros | Sr. Systems Engineer| Information Technology Group
>| Harvard Business School| 617.496.5180<tel:617.496.5180>|
>cbarros at hbs.edu<mailto:cbarros at hbs.edu>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Tue Oct  4 23:07:50 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 5 Oct 2016 10:07:50 +1300
Subject: [R] Problem installing rgdal.
In-Reply-To: <88d79342-950f-4dbf-bd13-55d5cdd06728@gmail.com>
References: <0411eb09-a03f-2a52-62de-fe988f2e5a3b@auckland.ac.nz>
	<88d79342-950f-4dbf-bd13-55d5cdd06728@gmail.com>
Message-ID: <f12e0316-c93f-92fd-b07e-936deb85be69@auckland.ac.nz>

On 05/10/16 01:10, ProfJCNash wrote:
> I found that I have libgdal1-dev installed too.
>
> john at john-J6-2015 ~ $ dpkg -l | grep gdal
> ii  libgdal-dev                                 1.10.1+dfsg-5ubuntu1                                amd64
> Geospatial Data Abstraction Library - Development files
> ii  libgdal1-dev                                1.10.1+dfsg-5ubuntu1                                all
> Geospatial Data Abstraction Library - Transitional package
> ii  libgdal1h                                   1.10.1+dfsg-5ubuntu1                                amd64
> Geospatial Data Abstraction Library
> john at john-J6-2015 ~ $
>
> and I get the following outputs in R:
>
>> library(rgdal)
> Loading required package: sp
> rgdal: version: 1.1-10, (SVN revision 622)
>  Geospatial Data Abstraction Library extensions to R successfully loaded
>  Loaded GDAL runtime: GDAL 1.10.1, released 2013/08/26
>  Path to GDAL shared files: /usr/share/gdal/1.10
>  Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
>  Path to PROJ.4 shared files: (autodetected)
>  Linking to sp version: 1.2-3
>> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.4 LTS
>
> locale:
>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rgdal_1.1-10 sp_1.2-3
>
> loaded via a namespace (and not attached):
> [1] grid_3.3.1      lattice_0.20-33
>>
>
> Hope this is helpful.


Afraid not.  I did not have libgdal1-dev installed, but having installed 
it I tried install.packages("rgdal",lib="/home/rolf/Rlib")
again and got the same damned error message as before.

> ** testing if installed package can be loaded
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>   unable to load shared object '/home/rolf/Rlib/rgdal/libs/rgdal.so':
>   /home/rolf/Rlib/rgdal/libs/rgdal.so: undefined symbol: CPLQuietErrorHandler
> Error: loading failed
> Execution halted

Has anyone out there any other ideas as to what's going wrong for me and 
how I might fix it?

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From profjcnash at gmail.com  Wed Oct  5 01:56:25 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Tue, 4 Oct 2016 19:56:25 -0400
Subject: [R] Problem installing rgdal.
In-Reply-To: <f12e0316-c93f-92fd-b07e-936deb85be69@auckland.ac.nz>
References: <0411eb09-a03f-2a52-62de-fe988f2e5a3b@auckland.ac.nz>
	<88d79342-950f-4dbf-bd13-55d5cdd06728@gmail.com>
	<f12e0316-c93f-92fd-b07e-936deb85be69@auckland.ac.nz>
Message-ID: <001ab230-feab-d601-7c3d-07cb3beb0680@gmail.com>

Can you build/install the source package? I had a problem once where my libraries were "too recent" for the R package,
but I could build against my installed base. In any event, it may point out the source of the problem.

I can appreciate your frustration -- been there, but wish I hadn't.

Best, JN

On 16-10-04 05:07 PM, Rolf Turner wrote:
> On 05/10/16 01:10, ProfJCNash wrote:
>> I found that I have libgdal1-dev installed too.
>>
>> john at john-J6-2015 ~ $ dpkg -l | grep gdal
>> ii  libgdal-dev                                 1.10.1+dfsg-5ubuntu1                                amd64
>> Geospatial Data Abstraction Library - Development files
>> ii  libgdal1-dev                                1.10.1+dfsg-5ubuntu1                                all
>> Geospatial Data Abstraction Library - Transitional package
>> ii  libgdal1h                                   1.10.1+dfsg-5ubuntu1                                amd64
>> Geospatial Data Abstraction Library
>> john at john-J6-2015 ~ $
>>
>> and I get the following outputs in R:
>>
>>> library(rgdal)
>> Loading required package: sp
>> rgdal: version: 1.1-10, (SVN revision 622)
>>  Geospatial Data Abstraction Library extensions to R successfully loaded
>>  Loaded GDAL runtime: GDAL 1.10.1, released 2013/08/26
>>  Path to GDAL shared files: /usr/share/gdal/1.10
>>  Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
>>  Path to PROJ.4 shared files: (autodetected)
>>  Linking to sp version: 1.2-3
>>> sessionInfo()
>> R version 3.3.1 (2016-06-21)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.4 LTS
>>
>> locale:
>>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>>  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] rgdal_1.1-10 sp_1.2-3
>>
>> loaded via a namespace (and not attached):
>> [1] grid_3.3.1      lattice_0.20-33
>>>
>>
>> Hope this is helpful.
> 
> 
> Afraid not.  I did not have libgdal1-dev installed, but having installed it I tried
> install.packages("rgdal",lib="/home/rolf/Rlib")
> again and got the same damned error message as before.
> 
>> ** testing if installed package can be loaded
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>   unable to load shared object '/home/rolf/Rlib/rgdal/libs/rgdal.so':
>>   /home/rolf/Rlib/rgdal/libs/rgdal.so: undefined symbol: CPLQuietErrorHandler
>> Error: loading failed
>> Execution halted
> 
> Has anyone out there any other ideas as to what's going wrong for me and how I might fix it?
> 
> cheers,
> 
> Rolf
>


From r.turner at auckland.ac.nz  Wed Oct  5 02:31:22 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 5 Oct 2016 13:31:22 +1300
Subject: [R] Problem installing rgdal.
In-Reply-To: <001ab230-feab-d601-7c3d-07cb3beb0680@gmail.com>
References: <0411eb09-a03f-2a52-62de-fe988f2e5a3b@auckland.ac.nz>
	<88d79342-950f-4dbf-bd13-55d5cdd06728@gmail.com>
	<f12e0316-c93f-92fd-b07e-936deb85be69@auckland.ac.nz>
	<001ab230-feab-d601-7c3d-07cb3beb0680@gmail.com>
Message-ID: <456f2861-9574-2a7f-0ad6-01b6f0d6afa4@auckland.ac.nz>

On 05/10/16 12:56, ProfJCNash wrote:
> Can you build/install the source package? I had a problem once where my libraries were "too recent" for the R package,
> but I could build against my installed base. In any event, it may point out the source of the problem.
>
> I can appreciate your frustration -- been there, but wish I hadn't.

Essentially install.packages() builds from source.

I also tried to install from the source tarball; same error resulted.

Surely there *must* be somebody out there who understands what's going 
on and how to fix it.  Mustn't there?

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bob at rud.is  Wed Oct  5 03:12:31 2016
From: bob at rud.is (Bob Rudis)
Date: Tue, 4 Oct 2016 21:12:31 -0400
Subject: [R] Problem installing rgdal.
In-Reply-To: <456f2861-9574-2a7f-0ad6-01b6f0d6afa4@auckland.ac.nz>
References: <0411eb09-a03f-2a52-62de-fe988f2e5a3b@auckland.ac.nz>
	<88d79342-950f-4dbf-bd13-55d5cdd06728@gmail.com>
	<f12e0316-c93f-92fd-b07e-936deb85be69@auckland.ac.nz>
	<001ab230-feab-d601-7c3d-07cb3beb0680@gmail.com>
	<456f2861-9574-2a7f-0ad6-01b6f0d6afa4@auckland.ac.nz>
Message-ID: <CAA-FpKXSg=Kckn2u6TH1Awgnw9Z2ChAv4NvaffM+QirHNFTMZg@mail.gmail.com>

?Hey Ron,

I (literally, in the correct use of the term) fired up an Ubuntu 16.04
vagrant box - https://atlas.hashicorp.com/bento/boxes/ubuntu-16.04 - and
then did:

lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description: Ubuntu 16.04.1 LTS
Release: 16.04
Codename: xenial

and, then:

sudo echo "deb http://cran.rstudio.com/bin/linux/ubuntu xenial/" | sudo tee
-a /etc/apt/sources.list
gpg --keyserver keyserver.ubuntu.com --recv-key E084DAB9
gpg -a --export E084DAB9 | sudo apt-key add -
sudo apt-get update
sudo apt-get install r-base r-base-dev
sudo apt-get install libgdal-dev
sudo apt-get install libproj4-dev

and then did

install.packages("rgdal")

in an R session and it's working fine:

> library(rgdal)
Loading required package: sp
rgdal: version: 1.1-10, (SVN revision 622)
 Geospatial Data Abstraction Library extensions to R successfully loaded
 Loaded GDAL runtime: GDAL 1.11.3, released 2015/09/16
 Path to GDAL shared files: /usr/share/gdal/1.11
 Loaded PROJ.4 runtime: Rel. 4.9.2, 08 September 2015, [PJ_VERSION: 492]
 Path to PROJ.4 shared files: (autodetected)
 Linking to sp version: 1.2-3

I wish I could have run into errors and helped debug your issue, but it
went in flawlessly.

-Bob
?


On Tue, Oct 4, 2016 at 8:31 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 05/10/16 12:56, ProfJCNash wrote:
>
>> Can you build/install the source package? I had a problem once where my
>> libraries were "too recent" for the R package,
>> but I could build against my installed base. In any event, it may point
>> out the source of the problem.
>>
>> I can appreciate your frustration -- been there, but wish I hadn't.
>>
>
> Essentially install.packages() builds from source.
>
> I also tried to install from the source tarball; same error resulted.
>
> Surely there *must* be somebody out there who understands what's going on
> and how to fix it.  Mustn't there?
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Oct  5 03:25:41 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 04 Oct 2016 18:25:41 -0700
Subject: [R] Problem installing rgdal.
In-Reply-To: <CAA-FpKXSg=Kckn2u6TH1Awgnw9Z2ChAv4NvaffM+QirHNFTMZg@mail.gmail.com>
References: <0411eb09-a03f-2a52-62de-fe988f2e5a3b@auckland.ac.nz>
	<88d79342-950f-4dbf-bd13-55d5cdd06728@gmail.com>
	<f12e0316-c93f-92fd-b07e-936deb85be69@auckland.ac.nz>
	<001ab230-feab-d601-7c3d-07cb3beb0680@gmail.com>
	<456f2861-9574-2a7f-0ad6-01b6f0d6afa4@auckland.ac.nz>
	<CAA-FpKXSg=Kckn2u6TH1Awgnw9Z2ChAv4NvaffM+QirHNFTMZg@mail.gmail.com>
Message-ID: <A1ED42EF-33CC-4E40-ADA2-93E3C55241B2@dcn.davis.ca.us>

And if that was not intuitively obvious, googling "CRAN Ubuntu" would lead you to [1]. There is also R-sig-debian for these kinds of OS-specific questions next time. (I wish there was an R-sig-windows, but I suppose no one would support it.)

[1] https://cran.r-project.org/bin/linux/ubuntu/
-- 
Sent from my phone. Please excuse my brevity.

On October 4, 2016 6:12:31 PM PDT, Bob Rudis <bob at rud.is> wrote:
>?Hey Ron,
>
>I (literally, in the correct use of the term) fired up an Ubuntu 16.04
>vagrant box - https://atlas.hashicorp.com/bento/boxes/ubuntu-16.04 -
>and
>then did:
>
>lsb_release -a
>No LSB modules are available.
>Distributor ID: Ubuntu
>Description: Ubuntu 16.04.1 LTS
>Release: 16.04
>Codename: xenial
>
>and, then:
>
>sudo echo "deb http://cran.rstudio.com/bin/linux/ubuntu xenial/" | sudo
>tee
>-a /etc/apt/sources.list
>gpg --keyserver keyserver.ubuntu.com --recv-key E084DAB9
>gpg -a --export E084DAB9 | sudo apt-key add -
>sudo apt-get update
>sudo apt-get install r-base r-base-dev
>sudo apt-get install libgdal-dev
>sudo apt-get install libproj4-dev
>
>and then did
>
>install.packages("rgdal")
>
>in an R session and it's working fine:
>
>> library(rgdal)
>Loading required package: sp
>rgdal: version: 1.1-10, (SVN revision 622)
>Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.11.3, released 2015/09/16
> Path to GDAL shared files: /usr/share/gdal/1.11
>Loaded PROJ.4 runtime: Rel. 4.9.2, 08 September 2015, [PJ_VERSION: 492]
> Path to PROJ.4 shared files: (autodetected)
> Linking to sp version: 1.2-3
>
>I wish I could have run into errors and helped debug your issue, but it
>went in flawlessly.
>
>-Bob
>?
>
>
>On Tue, Oct 4, 2016 at 8:31 PM, Rolf Turner <r.turner at auckland.ac.nz>
>wrote:
>
>> On 05/10/16 12:56, ProfJCNash wrote:
>>
>>> Can you build/install the source package? I had a problem once where
>my
>>> libraries were "too recent" for the R package,
>>> but I could build against my installed base. In any event, it may
>point
>>> out the source of the problem.
>>>
>>> I can appreciate your frustration -- been there, but wish I hadn't.
>>>
>>
>> Essentially install.packages() builds from source.
>>
>> I also tried to install from the source tarball; same error resulted.
>>
>> Surely there *must* be somebody out there who understands what's
>going on
>> and how to fix it.  Mustn't there?
>>
>> cheers,
>>
>> Rolf
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Rainer at krugs.de  Wed Oct  5 09:47:11 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Wed, 05 Oct 2016 09:47:11 +0200
Subject: [R] Problem installing rgdal.
In-Reply-To: <456f2861-9574-2a7f-0ad6-01b6f0d6afa4@auckland.ac.nz> (Rolf
	Turner's message of "Wed, 5 Oct 2016 13:31:22 +1300")
References: <0411eb09-a03f-2a52-62de-fe988f2e5a3b@auckland.ac.nz>
	<88d79342-950f-4dbf-bd13-55d5cdd06728@gmail.com>
	<f12e0316-c93f-92fd-b07e-936deb85be69@auckland.ac.nz>
	<001ab230-feab-d601-7c3d-07cb3beb0680@gmail.com>
	<456f2861-9574-2a7f-0ad6-01b6f0d6afa4@auckland.ac.nz>
Message-ID: <m2lgy3i6f4.fsf@krugs.de>

Rolf Turner <r.turner at auckland.ac.nz> writes:

> On 05/10/16 12:56, ProfJCNash wrote:
>> Can you build/install the source package? I had a problem once where my libraries were "too recent" for the R package,
>> but I could build against my installed base. In any event, it may point out the source of the problem.
>>
>> I can appreciate your frustration -- been there, but wish I hadn't.
>
> Essentially install.packages() builds from source.
>
> I also tried to install from the source tarball; same error resulted.
>
> Surely there *must* be somebody out there who understands what's going
> on and how to fix it.  Mustn't there?

I didn't follow the thread closely, but these types of errors can mean
version conflicts, i.e. that you have either two versions of gdal
installed and the installer picks up the wrong version or a mix of
versions or that you have the wrong version installed.

Check you gdal installations (from source, package manager, whatever
there is), uninstall gdal completely and search thoroughly if there are
any leftovers (apt-get purge ...). Then I would logout and login again -
just to be sure that all caches are up to date (although I doubt this
is necessary).

Than I would check if there are any stray installations or rgdal sitting
in any library.

Than I would install all ubuntu packages neeed for gdal (from the CRAN
for rgdal: "for building from source: GDAL >= 1.6.3, library from http://trac.osgeo.org/gdal/wiki/DownloadSource and PROJ.4 (proj >= 4.4.9) from http://download.osgeo.org/proj/"), make sure that
they are working from the commandline, and that try again installing the
version of rgdal.

And if not, there is r-sig-spatial which is a much better place to ask
rgdal related questions than r-help.

Hope this helps,

Rainer

>
> cheers,
>
> Rolf

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161005/a6611fb9/attachment.bin>

From r.turner at auckland.ac.nz  Wed Oct  5 10:39:43 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 5 Oct 2016 21:39:43 +1300
Subject: [R] Problem installing rgdal.
In-Reply-To: <m2lgy3i6f4.fsf@krugs.de>
References: <0411eb09-a03f-2a52-62de-fe988f2e5a3b@auckland.ac.nz>
	<88d79342-950f-4dbf-bd13-55d5cdd06728@gmail.com>
	<f12e0316-c93f-92fd-b07e-936deb85be69@auckland.ac.nz>
	<001ab230-feab-d601-7c3d-07cb3beb0680@gmail.com>
	<456f2861-9574-2a7f-0ad6-01b6f0d6afa4@auckland.ac.nz>
	<m2lgy3i6f4.fsf@krugs.de>
Message-ID: <89783921-02ee-ce88-4a5b-7b6659fc6525@auckland.ac.nz>

On 05/10/16 20:47, Rainer M Krug wrote:
> Rolf Turner <r.turner at auckland.ac.nz> writes:
>
>> On 05/10/16 12:56, ProfJCNash wrote:
>>> Can you build/install the source package? I had a problem once where my libraries were "too recent" for the R package,
>>> but I could build against my installed base. In any event, it may point out the source of the problem.
>>>
>>> I can appreciate your frustration -- been there, but wish I hadn't.
>>
>> Essentially install.packages() builds from source.
>>
>> I also tried to install from the source tarball; same error resulted.
>>
>> Surely there *must* be somebody out there who understands what's going
>> on and how to fix it.  Mustn't there?
>
> I didn't follow the thread closely, but these types of errors can mean
> version conflicts, i.e. that you have either two versions of gdal
> installed and the installer picks up the wrong version or a mix of
> versions or that you have the wrong version installed.
>
> Check you gdal installations (from source, package manager, whatever
> there is), uninstall gdal completely and search thoroughly if there are
> any leftovers (apt-get purge ...). Then I would logout and login again -
> just to be sure that all caches are up to date (although I doubt this
> is necessary).
>
> Than I would check if there are any stray installations or rgdal sitting
> in any library.
>
> Than I would install all ubuntu packages neeed for gdal (from the CRAN
> for rgdal: "for building from source: GDAL >= 1.6.3, library from http://trac.osgeo.org/gdal/wiki/DownloadSource and PROJ.4 (proj >= 4.4.9) from http://download.osgeo.org/proj/"), make sure that
> they are working from the commandline, and that try again installing the
> version of rgdal.
>
> And if not, there is r-sig-spatial which is a much better place to ask
> rgdal related questions than r-help.
>
> Hope this helps.

Thanks.  That seems to be good advice.  I'll try it.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From lists at dewey.myzen.co.uk  Wed Oct  5 11:09:22 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 5 Oct 2016 10:09:22 +0100
Subject: [R] What does lm() output coefficient mean when it's been given
 a categorical predictor of string values?
In-Reply-To: <9bfc69cbe3634b0df892d1df0c85b9ac@kapsi.fi>
References: <9bfc69cbe3634b0df892d1df0c85b9ac@kapsi.fi>
Message-ID: <27a2edea-fa2d-8b7c-72e4-bc7a5f52c286@dewey.myzen.co.uk>

See inline

On 04/10/2016 16:39, mviljamaa wrote:
> I'm using lm() for a model that has a predictor that has two values
> {poika, tytt?} (boy and girl in Finnish).
>
> I make a model with this categorical variable:
>
> fit1 <- lm(dta$X.U.FEFF..mpist. ~ dta$sukup + dta$HISEI + dta$SES)
>

You will find your code easier to read if you go

  fit1 <- lm(X.U.FEFF..mpist. ~ sukup + HISEI + SES, data = dta)


> and while the variable/vector is here named as dta$sukup, what lm()
> returns is a coefficient
>
> dta$sukuptytt?
>      -6.19756
>
> What does the added 'tytt?' in the variable mean? Does it mean that
> 'tytt?' has been interpreted as 1 and 'poika' as 0?


If you would like it the other way round then see ?relevel
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From mdsumner at gmail.com  Wed Oct  5 11:09:38 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 05 Oct 2016 09:09:38 +0000
Subject: [R] Problem installing rgdal.
In-Reply-To: <89783921-02ee-ce88-4a5b-7b6659fc6525@auckland.ac.nz>
References: <0411eb09-a03f-2a52-62de-fe988f2e5a3b@auckland.ac.nz>
	<88d79342-950f-4dbf-bd13-55d5cdd06728@gmail.com>
	<f12e0316-c93f-92fd-b07e-936deb85be69@auckland.ac.nz>
	<001ab230-feab-d601-7c3d-07cb3beb0680@gmail.com>
	<456f2861-9574-2a7f-0ad6-01b6f0d6afa4@auckland.ac.nz>
	<m2lgy3i6f4.fsf@krugs.de>
	<89783921-02ee-ce88-4a5b-7b6659fc6525@auckland.ac.nz>
Message-ID: <CAAcGz99qeW4s+bwNxM=Hm+9DHcOmuQP8f4cmwuvu80vGhEQn6g@mail.gmail.com>

>From source I always consult Edzer's Travis configurations such as:
https://github.com/edzer/spacetime/blob/master/.travis.yml
<https://github.com/edzer/gstat/blob/master/.travis.yml>

For really bleeding edge and all the other hard install libs on Docker  I
just go straight to the rockerverse:
https://hub.docker.com/r/rocker/hadleyverse/

For package installs, this is more or less what I do from scratch on Ubuntu
16.04, I *always* go for the updated packages to ensure GDAL is reasonably
up to date (current GDAL is 2.1.1 and PROJ.4 is 4.9.2).

(Everything else advice-wise seems to be forever out of date. )

(I include PROJ.4, GEOS, HDF4, NetCDF4 and their tools since I always need
them.)

## manual set config and key for apt-get update, see
http://cran.r-project.org/bin/linux/ubuntu/README
# echo 'deb https://cloud.r-project.org/bin/linux/ubuntu xenial/' >>
/etc/apt/sources.list
# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9

## manually set updated GDAL
## https://launchpad.net/~ubuntugis/+archive/ubuntu/ubuntugis-unstable
# add-apt-repository ppa:ubuntugis/ubuntugis-unstable --yes

apt-get update
apt-get upgrade

## Install 3rd parties ymmv

## HDF4
apt-get install libhdf4-dev
apt-get install hdf4-tools

## NetCDF
apt-get install libnetcdf-dev
apt-get install netcdf-bin

## GEOS
apt-get install libgeos-dev

## PROJ.4 and GDAL
apt-get install proj-bin
apt-get install libproj-dev
apt-get install libgdal-dev
apt-get install gdal-bin

## now R
apt-get install r-base r-base-dev

Rscript -e 'install.packages(c("rgdal"))'

Cheers, Mike.

On Wed, 5 Oct 2016 at 19:41 Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 05/10/16 20:47, Rainer M Krug wrote:
> > Rolf Turner <r.turner at auckland.ac.nz> writes:
> >
> >> On 05/10/16 12:56, ProfJCNash wrote:
> >>> Can you build/install the source package? I had a problem once where
> my libraries were "too recent" for the R package,
> >>> but I could build against my installed base. In any event, it may
> point out the source of the problem.
> >>>
> >>> I can appreciate your frustration -- been there, but wish I hadn't.
> >>
> >> Essentially install.packages() builds from source.
> >>
> >> I also tried to install from the source tarball; same error resulted.
> >>
> >> Surely there *must* be somebody out there who understands what's going
> >> on and how to fix it.  Mustn't there?
> >
> > I didn't follow the thread closely, but these types of errors can mean
> > version conflicts, i.e. that you have either two versions of gdal
> > installed and the installer picks up the wrong version or a mix of
> > versions or that you have the wrong version installed.
> >
> > Check you gdal installations (from source, package manager, whatever
> > there is), uninstall gdal completely and search thoroughly if there are
> > any leftovers (apt-get purge ...). Then I would logout and login again -
> > just to be sure that all caches are up to date (although I doubt this
> > is necessary).
> >
> > Than I would check if there are any stray installations or rgdal sitting
> > in any library.
> >
> > Than I would install all ubuntu packages neeed for gdal (from the CRAN
> > for rgdal: "for building from source: GDAL >= 1.6.3, library from
> http://trac.osgeo.org/gdal/wiki/DownloadSource and PROJ.4 (proj >= 4.4.9)
> from http://download.osgeo.org/proj/"), make sure that
> > they are working from the commandline, and that try again installing the
> > version of rgdal.
> >
> > And if not, there is r-sig-spatial which is a much better place to ask
> > rgdal related questions than r-help.
> >
> > Hope this helps.
>
> Thanks.  That seems to be good advice.  I'll try it.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276 <+64%209-373%207599>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Wed Oct  5 14:46:42 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 5 Oct 2016 14:46:42 +0200
Subject: [R] How to plot a bunch of dichotomous code variables in one plot
	using ggplot2
Message-ID: <OFD0ECA92E.5DC907EF-ONC1258043.00454304-C1258043.0046322C@lotus.hawesko.de>

Hi All,

I have a bunch of dichotomous code variables which shall be plotted in one 
graph using one of their values, this is "1" in this case.

The dataset looks like this:

-- cut --
var1 <- c(1,0,1,0,0,1,1,1,0,1)
var2 <- c(0,1,1,1,1,0,0,0,0,0)
var3 <- c(1,1,1,1,1,1,1,1,0,1)

ds <- data.frame(var1, var2, var3)
-- cut --

I would like to have a bar plot like this



                      *
                      *
                      *
                      *
*                     *
*                     *
*          *          *
*          *          *
*          *          *
*          *          *
-------------------------
var1      var2       var3

If this possible in R? If so, how can I achieve this?

Kind regards

Georg


From jfox at mcmaster.ca  Wed Oct  5 15:01:48 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 5 Oct 2016 13:01:48 +0000
Subject: [R] How to plot a bunch of dichotomous code variables in one
 plot	using ggplot2
In-Reply-To: <OFD0ECA92E.5DC907EF-ONC1258043.00454304-C1258043.0046322C@lotus.hawesko.de>
References: <OFD0ECA92E.5DC907EF-ONC1258043.00454304-C1258043.0046322C@lotus.hawesko.de>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8365825A6@FHSDB2D11-2.csu.mcmaster.ca>

Dear Georg,

How about barplot(colSums(ds)) ?

Best,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: October 5, 2016 8:47 AM
> To: r-help at r-project.org
> Subject: [R] How to plot a bunch of dichotomous code variables in one plot
> using ggplot2
> 
> Hi All,
> 
> I have a bunch of dichotomous code variables which shall be plotted in one
> graph using one of their values, this is "1" in this case.
> 
> The dataset looks like this:
> 
> -- cut --
> var1 <- c(1,0,1,0,0,1,1,1,0,1)
> var2 <- c(0,1,1,1,1,0,0,0,0,0)
> var3 <- c(1,1,1,1,1,1,1,1,0,1)
> 
> ds <- data.frame(var1, var2, var3)
> -- cut --
> 
> I would like to have a bar plot like this
> 
> 
> 
>                       *
>                       *
>                       *
>                       *
> *                     *
> *                     *
> *          *          *
> *          *          *
> *          *          *
> *          *          *
> -------------------------
> var1      var2       var3
> 
> If this possible in R? If so, how can I achieve this?
> 
> Kind regards
> 
> Georg
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Wed Oct  5 15:55:56 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 5 Oct 2016 15:55:56 +0200
Subject: [R] Antwort: RE: How to plot a bunch of dichotomous code variables
 in one plot	using ggplot2
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365825A6@FHSDB2D11-2.csu.mcmaster.ca>
References: <OFD0ECA92E.5DC907EF-ONC1258043.00454304-C1258043.0046322C@lotus.hawesko.de>
	<ACD1644AA6C67E4FBD0C350625508EC8365825A6@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <OF6E0C4EE0.A19E61C2-ONC1258043.004B0C68-C1258043.004C88B6@lotus.hawesko.de>

Hi Bob,
Hi John,
Hi readers,

many thanks for your reply.

I did

barplot(colSums(dataset %>% select(FirstVar:LastVar)))

and it worked fine.

How would I do it with ggplot2?

Kind regards

Georg




Von:    "Fox, John" <jfox at mcmaster.ca>
An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>, 
Kopie:  "r-help at r-project.org" <r-help at r-project.org>
Datum:  05.10.2016 15:01
Betreff:        RE: [R] How to plot a bunch of dichotomous code variables 
in one plot     using ggplot2



Dear Georg,

How about barplot(colSums(ds)) ?

Best,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: October 5, 2016 8:47 AM
> To: r-help at r-project.org
> Subject: [R] How to plot a bunch of dichotomous code variables in one 
plot
> using ggplot2
> 
> Hi All,
> 
> I have a bunch of dichotomous code variables which shall be plotted in 
one
> graph using one of their values, this is "1" in this case.
> 
> The dataset looks like this:
> 
> -- cut --
> var1 <- c(1,0,1,0,0,1,1,1,0,1)
> var2 <- c(0,1,1,1,1,0,0,0,0,0)
> var3 <- c(1,1,1,1,1,1,1,1,0,1)
> 
> ds <- data.frame(var1, var2, var3)
> -- cut --
> 
> I would like to have a bar plot like this
> 
> 
> 
>                       *
>                       *
>                       *
>                       *
> *                     *
> *                     *
> *          *          *
> *          *          *
> *          *          *
> *          *          *
> -------------------------
> var1      var2       var3
> 
> If this possible in R? If so, how can I achieve this?
> 
> Kind regards
> 
> Georg
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Wed Oct  5 16:17:57 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 5 Oct 2016 16:17:57 +0200
Subject: [R] Antwort: RE: How to plot a bunch of dichotomous code
 variables in one plot using ggplot2
In-Reply-To: <OF6E0C4EE0.A19E61C2-ONC1258043.004B0C68-C1258043.004C88B6@lotus.hawesko.de>
References: <OFD0ECA92E.5DC907EF-ONC1258043.00454304-C1258043.0046322C@lotus.hawesko.de>
	<ACD1644AA6C67E4FBD0C350625508EC8365825A6@FHSDB2D11-2.csu.mcmaster.ca>
	<OF6E0C4EE0.A19E61C2-ONC1258043.004B0C68-C1258043.004C88B6@lotus.hawesko.de>
Message-ID: <CAJuCY5xWKQeLk2O26BNWwfmyg79E5z2kOCzsx0xUUN72fPSBUQ@mail.gmail.com>

Here is a ggplot2, tidyr, dplyr solution

library(tidyr)
library(dplyr)
library(ggplot2)
ds %>%
  gather() %>%
  group_by(key) %>%
  summarize(total = sum(value)) %>%
  ggplot(aes(x = key, y = total)) +
  geom_bar(stat = "identity")


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-10-05 15:55 GMT+02:00 <G.Maubach at weinwolf.de>:

> Hi Bob,
> Hi John,
> Hi readers,
>
> many thanks for your reply.
>
> I did
>
> barplot(colSums(dataset %>% select(FirstVar:LastVar)))
>
> and it worked fine.
>
> How would I do it with ggplot2?
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    "Fox, John" <jfox at mcmaster.ca>
> An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>,
> Kopie:  "r-help at r-project.org" <r-help at r-project.org>
> Datum:  05.10.2016 15:01
> Betreff:        RE: [R] How to plot a bunch of dichotomous code variables
> in one plot     using ggplot2
>
>
>
> Dear Georg,
>
> How about barplot(colSums(ds)) ?
>
> Best,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > G.Maubach at weinwolf.de
> > Sent: October 5, 2016 8:47 AM
> > To: r-help at r-project.org
> > Subject: [R] How to plot a bunch of dichotomous code variables in one
> plot
> > using ggplot2
> >
> > Hi All,
> >
> > I have a bunch of dichotomous code variables which shall be plotted in
> one
> > graph using one of their values, this is "1" in this case.
> >
> > The dataset looks like this:
> >
> > -- cut --
> > var1 <- c(1,0,1,0,0,1,1,1,0,1)
> > var2 <- c(0,1,1,1,1,0,0,0,0,0)
> > var3 <- c(1,1,1,1,1,1,1,1,0,1)
> >
> > ds <- data.frame(var1, var2, var3)
> > -- cut --
> >
> > I would like to have a bar plot like this
> >
> >
> >
> >                       *
> >                       *
> >                       *
> >                       *
> > *                     *
> > *                     *
> > *          *          *
> > *          *          *
> > *          *          *
> > *          *          *
> > -------------------------
> > var1      var2       var3
> >
> > If this possible in R? If so, how can I achieve this?
> >
> > Kind regards
> >
> > Georg
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Wed Oct  5 16:34:21 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 05 Oct 2016 14:34:21 +0000
Subject: [R] Antwort: RE: How to plot a bunch of dichotomous code
 variables in one plot using ggplot2
In-Reply-To: <OF6E0C4EE0.A19E61C2-ONC1258043.004B0C68-C1258043.004C88B6@lotus.hawesko.de>
References: <OFD0ECA92E.5DC907EF-ONC1258043.00454304-C1258043.0046322C@lotus.hawesko.de>
	<ACD1644AA6C67E4FBD0C350625508EC8365825A6@FHSDB2D11-2.csu.mcmaster.ca>
	<OF6E0C4EE0.A19E61C2-ONC1258043.004B0C68-C1258043.004C88B6@lotus.hawesko.de>
Message-ID: <CAKVAULMXtdrFAs6r1tJO4ZmxN=jmbfj_DhH+2H05WBnsBMtYKQ@mail.gmail.com>

I have a version looking like the original request even

library(tidyr)
library(ggplot2)

var1 <- c(1,0,1,0,0,1,1,1,0,1)
var2 <- c(0,1,1,1,1,0,0,0,0,0)
var3 <- c(1,1,1,1,1,1,1,1,0,1)

ds <- data.frame(var1, var2, var3)

ds %>% gather() %>% group_by(key) %>% filter(value > 0) %>% mutate(fake_y =
c(1:n())) %>%
  ggplot() +
  aes(x = key, y = fake_y) +
  geom_point()

ds %>% gather() %>% group_by(key) %>% mutate(var_count = sum(value)) %>%
  ggplot() +
  aes(x = key, y = var_count) +
  geom_bar(stat = "identity")

ds %>% gather() %>%
  ggplot() +
  aes(x = key, y = value) +
  stat_summary(fun.y = sum, geom = "bar")

I prefer to do all manipulation before plotting as I find this more
informative but having ggplot doing the sum is also possible.

Best,
Ulrik


On Wed, 5 Oct 2016 at 16:04 <G.Maubach at weinwolf.de> wrote:

> Hi Bob,
> Hi John,
> Hi readers,
>
> many thanks for your reply.
>
> I did
>
> barplot(colSums(dataset %>% select(FirstVar:LastVar)))
>
> and it worked fine.
>
> How would I do it with ggplot2?
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    "Fox, John" <jfox at mcmaster.ca>
> An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>,
> Kopie:  "r-help at r-project.org" <r-help at r-project.org>
> Datum:  05.10.2016 15:01
> Betreff:        RE: [R] How to plot a bunch of dichotomous code variables
> in one plot     using ggplot2
>
>
>
> Dear Georg,
>
> How about barplot(colSums(ds)) ?
>
> Best,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > G.Maubach at weinwolf.de
> > Sent: October 5, 2016 8:47 AM
> > To: r-help at r-project.org
> > Subject: [R] How to plot a bunch of dichotomous code variables in one
> plot
> > using ggplot2
> >
> > Hi All,
> >
> > I have a bunch of dichotomous code variables which shall be plotted in
> one
> > graph using one of their values, this is "1" in this case.
> >
> > The dataset looks like this:
> >
> > -- cut --
> > var1 <- c(1,0,1,0,0,1,1,1,0,1)
> > var2 <- c(0,1,1,1,1,0,0,0,0,0)
> > var3 <- c(1,1,1,1,1,1,1,1,0,1)
> >
> > ds <- data.frame(var1, var2, var3)
> > -- cut --
> >
> > I would like to have a bar plot like this
> >
> >
> >
> >                       *
> >                       *
> >                       *
> >                       *
> > *                     *
> > *                     *
> > *          *          *
> > *          *          *
> > *          *          *
> > *          *          *
> > -------------------------
> > var1      var2       var3
> >
> > If this possible in R? If so, how can I achieve this?
> >
> > Kind regards
> >
> > Georg
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bob at rud.is  Wed Oct  5 16:35:01 2016
From: bob at rud.is (Bob Rudis)
Date: Wed, 5 Oct 2016 10:35:01 -0400
Subject: [R] Antwort: RE: How to plot a bunch of dichotomous code
 variables in one plot using ggplot2
In-Reply-To: <CAJuCY5xWKQeLk2O26BNWwfmyg79E5z2kOCzsx0xUUN72fPSBUQ@mail.gmail.com>
References: <OFD0ECA92E.5DC907EF-ONC1258043.00454304-C1258043.0046322C@lotus.hawesko.de>
	<ACD1644AA6C67E4FBD0C350625508EC8365825A6@FHSDB2D11-2.csu.mcmaster.ca>
	<OF6E0C4EE0.A19E61C2-ONC1258043.004B0C68-C1258043.004C88B6@lotus.hawesko.de>
	<CAJuCY5xWKQeLk2O26BNWwfmyg79E5z2kOCzsx0xUUN72fPSBUQ@mail.gmail.com>
Message-ID: <CAA-FpKUcSbVScpnu19NjhdBZ6f7vBd131qBWJoYmgd9QpFdTYQ@mail.gmail.com>

No need to bring in so many dependencies for a simple ggplot2 marplot:

ds <- stack(ds)
ggplot(ds[ds$values==1,], aes(ind)) + geom_bar()

On Wed, Oct 5, 2016 at 10:17 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Here is a ggplot2, tidyr, dplyr solution
>
> library(tidyr)
> library(dplyr)
> library(ggplot2)
> ds %>%
>   gather() %>%
>   group_by(key) %>%
>   summarize(total = sum(value)) %>%
>   ggplot(aes(x = key, y = total)) +
>   geom_bar(stat = "identity")
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-10-05 15:55 GMT+02:00 <G.Maubach at weinwolf.de>:
>
>> Hi Bob,
>> Hi John,
>> Hi readers,
>>
>> many thanks for your reply.
>>
>> I did
>>
>> barplot(colSums(dataset %>% select(FirstVar:LastVar)))
>>
>> and it worked fine.
>>
>> How would I do it with ggplot2?
>>
>> Kind regards
>>
>> Georg
>>
>>
>>
>>
>> Von:    "Fox, John" <jfox at mcmaster.ca>
>> An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>,
>> Kopie:  "r-help at r-project.org" <r-help at r-project.org>
>> Datum:  05.10.2016 15:01
>> Betreff:        RE: [R] How to plot a bunch of dichotomous code variables
>> in one plot     using ggplot2
>>
>>
>>
>> Dear Georg,
>>
>> How about barplot(colSums(ds)) ?
>>
>> Best,
>>  John
>>
>> -----------------------------
>> John Fox, Professor
>> McMaster University
>> Hamilton, Ontario
>> Canada L8S 4M4
>> Web: socserv.mcmaster.ca/jfox
>>
>>
>> > -----Original Message-----
>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> > G.Maubach at weinwolf.de
>> > Sent: October 5, 2016 8:47 AM
>> > To: r-help at r-project.org
>> > Subject: [R] How to plot a bunch of dichotomous code variables in one
>> plot
>> > using ggplot2
>> >
>> > Hi All,
>> >
>> > I have a bunch of dichotomous code variables which shall be plotted in
>> one
>> > graph using one of their values, this is "1" in this case.
>> >
>> > The dataset looks like this:
>> >
>> > -- cut --
>> > var1 <- c(1,0,1,0,0,1,1,1,0,1)
>> > var2 <- c(0,1,1,1,1,0,0,0,0,0)
>> > var3 <- c(1,1,1,1,1,1,1,1,0,1)
>> >
>> > ds <- data.frame(var1, var2, var3)
>> > -- cut --
>> >
>> > I would like to have a bar plot like this
>> >
>> >
>> >
>> >                       *
>> >                       *
>> >                       *
>> >                       *
>> > *                     *
>> > *                     *
>> > *          *          *
>> > *          *          *
>> > *          *          *
>> > *          *          *
>> > -------------------------
>> > var1      var2       var3
>> >
>> > If this possible in R? If so, how can I achieve this?
>> >
>> > Kind regards
>> >
>> > Georg
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-
>> > guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From bob at rud.is  Wed Oct  5 16:35:32 2016
From: bob at rud.is (Bob Rudis)
Date: Wed, 5 Oct 2016 10:35:32 -0400
Subject: [R] Antwort: RE: How to plot a bunch of dichotomous code
 variables in one plot using ggplot2
In-Reply-To: <CAA-FpKUcSbVScpnu19NjhdBZ6f7vBd131qBWJoYmgd9QpFdTYQ@mail.gmail.com>
References: <OFD0ECA92E.5DC907EF-ONC1258043.00454304-C1258043.0046322C@lotus.hawesko.de>
	<ACD1644AA6C67E4FBD0C350625508EC8365825A6@FHSDB2D11-2.csu.mcmaster.ca>
	<OF6E0C4EE0.A19E61C2-ONC1258043.004B0C68-C1258043.004C88B6@lotus.hawesko.de>
	<CAJuCY5xWKQeLk2O26BNWwfmyg79E5z2kOCzsx0xUUN72fPSBUQ@mail.gmail.com>
	<CAA-FpKUcSbVScpnu19NjhdBZ6f7vBd131qBWJoYmgd9QpFdTYQ@mail.gmail.com>
Message-ID: <CAA-FpKX7KMAdwdAQBzYAbQXA-1=vbvuzEkyehZdKdNVeR0Z8gg@mail.gmail.com>

(s/marplot/barplot)

On Wed, Oct 5, 2016 at 10:35 AM, Bob Rudis <bob at rud.is> wrote:

> No need to bring in so many dependencies for a simple ggplot2 marplot:
>
> ds <- stack(ds)
> ggplot(ds[ds$values==1,], aes(ind)) + geom_bar()
>
> On Wed, Oct 5, 2016 at 10:17 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Here is a ggplot2, tidyr, dplyr solution
>>
>> library(tidyr)
>> library(dplyr)
>> library(ggplot2)
>> ds %>%
>>   gather() %>%
>>   group_by(key) %>%
>>   summarize(total = sum(value)) %>%
>>   ggplot(aes(x = key, y = total)) +
>>   geom_bar(stat = "identity")
>>
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-10-05 15:55 GMT+02:00 <G.Maubach at weinwolf.de>:
>>
>>> Hi Bob,
>>> Hi John,
>>> Hi readers,
>>>
>>> many thanks for your reply.
>>>
>>> I did
>>>
>>> barplot(colSums(dataset %>% select(FirstVar:LastVar)))
>>>
>>> and it worked fine.
>>>
>>> How would I do it with ggplot2?
>>>
>>> Kind regards
>>>
>>> Georg
>>>
>>>
>>>
>>>
>>> Von:    "Fox, John" <jfox at mcmaster.ca>
>>> An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>,
>>> Kopie:  "r-help at r-project.org" <r-help at r-project.org>
>>> Datum:  05.10.2016 15:01
>>> Betreff:        RE: [R] How to plot a bunch of dichotomous code variables
>>> in one plot     using ggplot2
>>>
>>>
>>>
>>> Dear Georg,
>>>
>>> How about barplot(colSums(ds)) ?
>>>
>>> Best,
>>>  John
>>>
>>> -----------------------------
>>> John Fox, Professor
>>> McMaster University
>>> Hamilton, Ontario
>>> Canada L8S 4M4
>>> Web: socserv.mcmaster.ca/jfox
>>>
>>>
>>> > -----Original Message-----
>>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> > G.Maubach at weinwolf.de
>>> > Sent: October 5, 2016 8:47 AM
>>> > To: r-help at r-project.org
>>> > Subject: [R] How to plot a bunch of dichotomous code variables in one
>>> plot
>>> > using ggplot2
>>> >
>>> > Hi All,
>>> >
>>> > I have a bunch of dichotomous code variables which shall be plotted in
>>> one
>>> > graph using one of their values, this is "1" in this case.
>>> >
>>> > The dataset looks like this:
>>> >
>>> > -- cut --
>>> > var1 <- c(1,0,1,0,0,1,1,1,0,1)
>>> > var2 <- c(0,1,1,1,1,0,0,0,0,0)
>>> > var3 <- c(1,1,1,1,1,1,1,1,0,1)
>>> >
>>> > ds <- data.frame(var1, var2, var3)
>>> > -- cut --
>>> >
>>> > I would like to have a bar plot like this
>>> >
>>> >
>>> >
>>> >                       *
>>> >                       *
>>> >                       *
>>> >                       *
>>> > *                     *
>>> > *                     *
>>> > *          *          *
>>> > *          *          *
>>> > *          *          *
>>> > *          *          *
>>> > -------------------------
>>> > var1      var2       var3
>>> >
>>> > If this possible in R? If so, how can I achieve this?
>>> >
>>> > Kind regards
>>> >
>>> > Georg
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posting-
>>> > guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From pd.mes at cbs.dk  Wed Oct  5 19:43:42 2016
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Wed, 5 Oct 2016 17:43:42 +0000
Subject: [R] R-3.3.2 on October 31
Message-ID: <232793BA-DFE1-496D-BD7D-0B2DEF61ECC0@cbs.dk>

Just a quick heads-up, mostly for those who want to keep their packages up to date with respect to updates of R: We intend to have a patch release on October 31. Nickname and detailed schedule will be made available on developer.r-project.org in due course.

For the R Core Team

Peter Dalgaard

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From bgunter.4567 at gmail.com  Wed Oct  5 20:12:23 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 5 Oct 2016 11:12:23 -0700
Subject: [R] A note on == versus logical operators for logical comparisons
Message-ID: <CAGxFJbRx1__E5XtkjcVZSK5i+piMsFhj7djLuPBsL8pStwmY1g@mail.gmail.com>

Folks:

This post was suggested by a recent post of Fabien Verger. In it, he used
a != b
as an exclusive-or operator for two logical vectors, a and b. As R
already has an exlcusive-or operator, I suggested
xor(a,b),
which is implemented as
(x | y) & !(x & y)
i.e. through purely logical operators.

However,

> b <- sample(c(TRUE,FALSE),1e6,rep=TRUE)
> a <- sample(c(TRUE,FALSE),1e6,rep=TRUE)

> system.time(as.logical(b) != as.logical(a))
   user  system elapsed
  0.002   0.000   0.002

> system.time(xor(a,b))
   user  system elapsed
  0.022   0.002   0.023

I added the as.logical() cast to handle the case, e.g. a = 1 and b = 2
, for which xor() gives FALSE and a != b gives TRUE without the cast.
Such mixups can occur.

So given the must greater efficiency of != (or ==) I wondered why that
wasn't used for xor(). Here's why:

> xor("A","B")
Error in x | y :
  operations are possible only for numeric, logical or complex types

> as.logical("A") != as.logical("B")
[1] NA

That is, xor()'s behavior as a logical operator is consistent with the
other logical operators (of course) , while the != implementation is
not.

There's a moral or two here maybe (beside: "Bert's not the brightest
bulb in the chandelier"):

1) There is almost always a good reason why R's core implementation
does things the way it does, at least at the user level (I of course
cannot comment on the underlying C code). If you think there's a
better way, it's probably worthwhile to think again.

2) == is actually a pretty blunt instrument for vector comparisons
(which Fabien explicitly noted in his post in the context of numeric
comparisons); unless you have pretty strong control over what's being
compared, other perhaps less efficient but more robust methods should
be considered.

Just my view of course.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


From pdalgd at gmail.com  Wed Oct  5 19:48:47 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 5 Oct 2016 19:48:47 +0200
Subject: [R] R-3.3.2 on October 31
Message-ID: <97739CEE-FC57-4B03-8DDD-C3CE0EE036FA@gmail.com>

Just a quick heads-up, mostly for those who want to keep their packages up to date with respect to updates of R: We intend to have a patch release on October 31. Nickname and detailed schedule will be made available on developer.r-project.org in due course.

For the R Core Team

Peter Dalgaard

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com









-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From federico.calboli at helsinki.fi  Thu Oct  6 14:56:23 2016
From: federico.calboli at helsinki.fi (Federico Calboli)
Date: Thu, 6 Oct 2016 15:56:23 +0300
Subject: [R] replicating PLINK's --genome calculations.
Message-ID: <60A84872-14FB-4FC3-8B8B-D0B070ABCEA9@helsinki.fi>

Hi All,

I have some genetic data and I want to resample it changing the number of individuals and/or the number of markers to show the effects of smaller sample sizes on the pairwise-IBD calculations.  The ?standard? I need to follow is PLINK, specifically the --genome option.  I could create multiple subsets of the data, export it an have PLINK do the needed calculations, and then reimport the results in R, but this is obviously pretty silly, especially because it would require creating, exporting and importing a few hundreds files.  I could write the needed functions to do what PLINK does, but I?d rather not reinvent the wheel so it might be worth asking:  is there any package/function that would do (in R) what PLINK does with --genome?   

Bets wishes

F

--
Federico Calboli
Ecological Genetics Research Unit
Department of Biosciences
PO Box 65 (Biocenter 3, Viikinkaari 1)
FIN-00014 University of Helsinki
Finland

federico.calboli at helsinki.fi


From bgunter.4567 at gmail.com  Thu Oct  6 16:51:29 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 6 Oct 2016 07:51:29 -0700
Subject: [R] replicating PLINK's --genome calculations.
In-Reply-To: <60A84872-14FB-4FC3-8B8B-D0B070ABCEA9@helsinki.fi>
References: <60A84872-14FB-4FC3-8B8B-D0B070ABCEA9@helsinki.fi>
Message-ID: <CAGxFJbSAxiBkUBOEZPm4tAn-zw5uM7ugCbtG79ocf99DDc4--Q@mail.gmail.com>

You may get an answer here, but the Bioconductor site/list is almost
certainly a better place to post this.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Oct 6, 2016 at 5:56 AM, Federico Calboli
<federico.calboli at helsinki.fi> wrote:
> Hi All,
>
> I have some genetic data and I want to resample it changing the number of individuals and/or the number of markers to show the effects of smaller sample sizes on the pairwise-IBD calculations.  The ?standard? I need to follow is PLINK, specifically the --genome option.  I could create multiple subsets of the data, export it an have PLINK do the needed calculations, and then reimport the results in R, but this is obviously pretty silly, especially because it would require creating, exporting and importing a few hundreds files.  I could write the needed functions to do what PLINK does, but I?d rather not reinvent the wheel so it might be worth asking:  is there any package/function that would do (in R) what PLINK does with --genome?
>
> Bets wishes
>
> F
>
> --
> Federico Calboli
> Ecological Genetics Research Unit
> Department of Biosciences
> PO Box 65 (Biocenter 3, Viikinkaari 1)
> FIN-00014 University of Helsinki
> Finland
>
> federico.calboli at helsinki.fi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From abhishekpandey_1983 at rediffmail.com  Thu Oct  6 09:55:28 2016
From: abhishekpandey_1983 at rediffmail.com (abhishek pandey)
Date: 6 Oct 2016 07:55:28 -0000
Subject: [R] (no subject)
Message-ID: <20161006075528.30220.qmail@f5mail-224-158.rediffmail.com>

kindly solve my problem sir.


	[[alternative HTML version deleted]]


From sinenhlanhla.mdluli at yahoo.com  Thu Oct  6 10:36:47 2016
From: sinenhlanhla.mdluli at yahoo.com (Sinenhlanhla Mdluli)
Date: Thu, 6 Oct 2016 08:36:47 +0000 (UTC)
Subject: [R] Dates
References: <797041145.2334781.1475743007635.ref@mail.yahoo.com>
Message-ID: <797041145.2334781.1475743007635@mail.yahoo.com>

All

I am having trouble converting dates into a uniform type using the R-code,I am not sure what is wrong with my syntax.But could you please tell me a more efficient way to qorking with time-series dates .I have attached the excel file that I want to convert dates on
Regards

From abhishekpandey_1983 at rediffmail.com  Thu Oct  6 16:07:03 2016
From: abhishekpandey_1983 at rediffmail.com (abhishek pandey)
Date: 6 Oct 2016 14:07:03 -0000
Subject: [R] =?utf-8?q?Fw=3A_how_to_use_97=2E5=25=2C2=2E5=25_values_of_par?=
	=?utf-8?q?ameters_for_next_calculation?=
Message-ID: <1475740479.S.11077.18359.f5mail-224-158.rediffmail.com.1475762823.26318@webmail.rediffmail.com>

Sent from RediffmailNG on Android

From: &quot;abhishek pandey&quot;abhishekpandey_1983 at rediffmail.com
Sent:Thu, 06 Oct 2016 13:24:39 +0530
To: r-help-owner at r-project.org
Subject: how to use 97.5%,2.5% values of parameters for next calculation
Sir 
 I request you to help me for completing my programm.
 SIZE STEPS Age BASEANDSTEPS num.thin num.chain num.iter num.burn ##NUMBER OF ITERATIONS common for cohort model
 > ITER time A1 library(R2WinBUGS)
 Loading required package: boot
 Warning messages:
 1: package ?R2WinBUGS? was built under R version 3.1.3 
 2: package ?boot? was built under R version 3.1.3 
 > A1 J K low up lowl phi.ul  phi.ll =c(18.776362,131.380765,20.367508, 50.197501,16.199959,1.262005, 1.148303)
 > data parameters inits inits tfrsim tfrsim
	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Thu Oct  6 17:31:43 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 6 Oct 2016 10:31:43 -0500
Subject: [R] (no subject)
In-Reply-To: <20161006075528.30220.qmail@f5mail-224-158.rediffmail.com>
References: <20161006075528.30220.qmail@f5mail-224-158.rediffmail.com>
Message-ID: <CAAJSdjh-C7kbBPV6X0dN0bi4g7dg2u3MRYbF4SBnRSonz436rw@mail.gmail.com>

On Thu, Oct 6, 2016 at 2:55 AM, abhishek pandey <
abhishekpandey_1983 at rediffmail.com> wrote:

> kindly solve my problem sir.
>
>
?A very polite request. Unfortunately it is impossible because your email
was HTML formatted and the list software removed the most of your email
before sending it out. You must use "plain text" only. Also, depending on
exactly what your request is, your response may well be "we don't do
homework" (if it looks like class work), or if it appears that you want
someone to write code for you, instead of helping with a specific problem
in your code, then it is unlikely to be done because the list is not,
generall, inhabited by unpaid consultants.?



-- 
Heisenberg may have been here.

Unicode: http://xkcd.com/1726/

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From federico.calboli at helsinki.fi  Thu Oct  6 18:03:34 2016
From: federico.calboli at helsinki.fi (Federico Calboli)
Date: Thu, 6 Oct 2016 19:03:34 +0300
Subject: [R] replicating PLINK's --genome calculations.
In-Reply-To: <CAGxFJbSAxiBkUBOEZPm4tAn-zw5uM7ugCbtG79ocf99DDc4--Q@mail.gmail.com>
References: <60A84872-14FB-4FC3-8B8B-D0B070ABCEA9@helsinki.fi>
	<CAGxFJbSAxiBkUBOEZPm4tAn-zw5uM7ugCbtG79ocf99DDc4--Q@mail.gmail.com>
Message-ID: <2EF835FA-EE18-458D-93E6-6643C02878F7@helsinki.fi>


> On 6 Oct 2016, at 17:51, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> You may get an answer here, but the Bioconductor site/list is almost
> certainly a better place to post this.

Good call ? I would have never though of checking BioC.  In fact the package SNPRelate seems to do what I need.

Best

F



> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Oct 6, 2016 at 5:56 AM, Federico Calboli
> <federico.calboli at helsinki.fi> wrote:
>> Hi All,
>> 
>> I have some genetic data and I want to resample it changing the number of individuals and/or the number of markers to show the effects of smaller sample sizes on the pairwise-IBD calculations.  The ?standard? I need to follow is PLINK, specifically the --genome option.  I could create multiple subsets of the data, export it an have PLINK do the needed calculations, and then reimport the results in R, but this is obviously pretty silly, especially because it would require creating, exporting and importing a few hundreds files.  I could write the needed functions to do what PLINK does, but I?d rather not reinvent the wheel so it might be worth asking:  is there any package/function that would do (in R) what PLINK does with --genome?
>> 
>> Bets wishes
>> 
>> F
>> 
>> --
>> Federico Calboli
>> Ecological Genetics Research Unit
>> Department of Biosciences
>> PO Box 65 (Biocenter 3, Viikinkaari 1)
>> FIN-00014 University of Helsinki
>> Finland
>> 
>> federico.calboli at helsinki.fi
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

--
Federico Calboli
Ecological Genetics Research Unit
Department of Biosciences
PO Box 65 (Biocenter 3, Viikinkaari 1)
FIN-00014 University of Helsinki
Finland

federico.calboli at helsinki.fi


From ruipbarradas at sapo.pt  Thu Oct  6 18:45:53 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 06 Oct 2016 17:45:53 +0100
Subject: [R] Dates
In-Reply-To: <797041145.2334781.1475743007635@mail.yahoo.com>
References: <797041145.2334781.1475743007635.ref@mail.yahoo.com>
	<797041145.2334781.1475743007635@mail.yahoo.com>
Message-ID: <20161006174553.Horde.CZda1d98D3oOei3ObwJsjHP@mail.sapo.pt>

Hello,

Your attachment didn't come through, save the file in the csv format  
and name it *.txt.
Moreover, you ask what is wrong with your syntax, but what syntax?  
What is your code? Post a minimal example of what you are trying if  
you want answers from us.
In the mean time at an R pormpt try

> ?as.Date
> ?format

Hope this helps,

Rui Barradas



Citando Sinenhlanhla Mdluli via R-help <r-help at r-project.org>:

> All
>
> I am having trouble converting dates into a uniform type using the  
> R-code,I am not sure what is wrong with my syntax.But could you  
> please tell me a more efficient way to qorking with time-series  
> dates .I have attached the excel file that I want to convert dates on
> Regards
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Oct  6 21:06:20 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 6 Oct 2016 12:06:20 -0700
Subject: [R] how to use 97.5%,
	2.5% values of parameters for next calculation
In-Reply-To: <1475740479.S.11077.18359.f5mail-224-158.rediffmail.com.1475762823.26318@webmail.rediffmail.com>
References: <1475740479.S.11077.18359.f5mail-224-158.rediffmail.com.1475762823.26318@webmail.rediffmail.com>
Message-ID: <726659CC-6EAC-4B87-A554-15B8CA967F7D@comcast.net>


> On Oct 6, 2016, at 7:07 AM, abhishek pandey <abhishekpandey_1983 at rediffmail.com> wrote:
> 
> Sent from RediffmailNG on Android
> 
> From: &quot;abhishek pandey&quot;abhishekpandey_1983 at rediffmail.com
> Sent:Thu, 06 Oct 2016 13:24:39 +0530
> To: r-help-owner at r-project.org
> Subject: how to use 97.5%,2.5% values of parameters for next calculation
> Sir 
> I request you to help me for completing my programm.
> SIZE STEPS Age BASEANDSTEPS num.thin num.chain num.iter num.burn ##NUMBER OF ITERATIONS common for cohort model
>> ITER time A1 library(R2WinBUGS)
> Loading required package: boot
> Warning messages:
> 1: package ?R2WinBUGS? was built under R version 3.1.3 
> 2: package ?boot? was built under R version 3.1.3 
>> A1 J K low up lowl phi.ul  phi.ll =c(18.776362,131.380765,20.367508, 50.197501,16.199959,1.262005, 1.148303)
>> data parameters inits inits tfrsim tfrsim
> 	[[alternative HTML version deleted]]
> 

As you can see, the fact that you (still) have not read the Posting Guide and posted in HTML has left this message unreadable. Please _now_ take the time to read the Posting Guide.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help

\/\/\/\/\/\/\/\/\/\/\/\/\/\/\
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AND \/\/\/\/\/\/\
> and provide commented, minimal, self-contained, reproducible code.

Which mean you need to include data either as a text  attachment(with extension '.txt') or inline.

^^^^^^^^^^^^^^^^^^
David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Thu Oct  6 22:20:03 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 7 Oct 2016 09:20:03 +1300
Subject: [R] (no subject)
In-Reply-To: <20161006075528.30220.qmail@f5mail-224-158.rediffmail.com>
References: <20161006075528.30220.qmail@f5mail-224-158.rediffmail.com>
Message-ID: <81fc9a87-77b3-cb01-df51-1fb513222562@auckland.ac.nz>

On 06/10/16 20:55, abhishek pandey wrote:
> kindly solve my problem sir.

That's it, in its entirety.  Shouldn't that win some sort of prize?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From drjimlemon at gmail.com  Fri Oct  7 00:26:22 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 7 Oct 2016 09:26:22 +1100
Subject: [R] (no subject)
In-Reply-To: <81fc9a87-77b3-cb01-df51-1fb513222562@auckland.ac.nz>
References: <20161006075528.30220.qmail@f5mail-224-158.rediffmail.com>
	<81fc9a87-77b3-cb01-df51-1fb513222562@auckland.ac.nz>
Message-ID: <CA+8X3fV-v+hsSREPDdeq22Y5R+_GRM3OYfTVcYoytiLN7ANJ-g@mail.gmail.com>

It certainly does. As we are often confronted with requests for
solutions of problems so minimally defined as to challenge the most
eminent mindreader, this excels. We have a meta-problem as the
supplicant him- (or her-, I cannot even ascertain this) does not
appear to know what it is. Thus me are asked to both pose and solve
the problem. While this may seem trivial to the casual reader, we must
recall Adams' Paradox, that we might supply an answer, but be unable
to state the question.

Pardon the enthusiasm - I have just solved two gratuitous problems and
I was, so to speak, primed for this message.

Jim

On Fri, Oct 7, 2016 at 7:20 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 06/10/16 20:55, abhishek pandey wrote:
>>
>> kindly solve my problem sir.
>
>
> That's it, in its entirety.  Shouldn't that win some sort of prize?
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ddalthorp at usgs.gov  Fri Oct  7 00:48:04 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Thu, 6 Oct 2016 15:48:04 -0700
Subject: [R] (no subject)
In-Reply-To: <CA+8X3fV-v+hsSREPDdeq22Y5R+_GRM3OYfTVcYoytiLN7ANJ-g@mail.gmail.com>
References: <20161006075528.30220.qmail@f5mail-224-158.rediffmail.com>
	<81fc9a87-77b3-cb01-df51-1fb513222562@auckland.ac.nz>
	<CA+8X3fV-v+hsSREPDdeq22Y5R+_GRM3OYfTVcYoytiLN7ANJ-g@mail.gmail.com>
Message-ID: <CAJeYpE_wqLBRMe6SPegVO05Qogj9zkhEB+EEOErnFfJ9cuDgEg@mail.gmail.com>

Question and answer:

6*9 = (4)*13^1 + (2)*13^0

On Thu, Oct 6, 2016 at 3:26 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> It certainly does. As we are often confronted with requests for
> solutions of problems so minimally defined as to challenge the most
> eminent mindreader, this excels. We have a meta-problem as the
> supplicant him- (or her-, I cannot even ascertain this) does not
> appear to know what it is. Thus me are asked to both pose and solve
> the problem. While this may seem trivial to the casual reader, we must
> recall Adams' Paradox, that we might supply an answer, but be unable
> to state the question.
>
> Pardon the enthusiasm - I have just solved two gratuitous problems and
> I was, so to speak, primed for this message.
>
> Jim
>
> On Fri, Oct 7, 2016 at 7:20 AM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> > On 06/10/16 20:55, abhishek pandey wrote:
> >>
> >> kindly solve my problem sir.
> >
> >
> > That's it, in its entirety.  Shouldn't that win some sort of prize?
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Oct  7 00:54:15 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 7 Oct 2016 09:54:15 +1100
Subject: [R] (no subject)
In-Reply-To: <CAJeYpE_wqLBRMe6SPegVO05Qogj9zkhEB+EEOErnFfJ9cuDgEg@mail.gmail.com>
References: <20161006075528.30220.qmail@f5mail-224-158.rediffmail.com>
	<81fc9a87-77b3-cb01-df51-1fb513222562@auckland.ac.nz>
	<CA+8X3fV-v+hsSREPDdeq22Y5R+_GRM3OYfTVcYoytiLN7ANJ-g@mail.gmail.com>
	<CAJeYpE_wqLBRMe6SPegVO05Qogj9zkhEB+EEOErnFfJ9cuDgEg@mail.gmail.com>
Message-ID: <CA+8X3fVjtTDYRjVkp4i2FmJDQLae5A_m5X8+KCJ4xGox3quWDg@mail.gmail.com>

No, I'm quite certain that the answer is:

7*6 = 3*2^4 - 36/6

but I don't know the question

Jim

On Fri, Oct 7, 2016 at 9:48 AM, Dalthorp, Daniel <ddalthorp at usgs.gov> wrote:
> Question and answer:
>
> 6*9 = (4)*13^1 + (2)*13^0
>
> On Thu, Oct 6, 2016 at 3:26 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> It certainly does. As we are often confronted with requests for
>> solutions of problems so minimally defined as to challenge the most
>> eminent mindreader, this excels. We have a meta-problem as the
>> supplicant him- (or her-, I cannot even ascertain this) does not
>> appear to know what it is. Thus me are asked to both pose and solve
>> the problem. While this may seem trivial to the casual reader, we must
>> recall Adams' Paradox, that we might supply an answer, but be unable
>> to state the question.
>>
>> Pardon the enthusiasm - I have just solved two gratuitous problems and
>> I was, so to speak, primed for this message.
>>
>> Jim
>>
>> On Fri, Oct 7, 2016 at 7:20 AM, Rolf Turner <r.turner at auckland.ac.nz>
>> wrote:
>> > On 06/10/16 20:55, abhishek pandey wrote:
>> >>
>> >> kindly solve my problem sir.
>> >
>> >
>> > That's it, in its entirety.  Shouldn't that win some sort of prize?
>> >
>> > cheers,
>> >
>> > Rolf Turner
>> >
>> > --
>> > Technical Editor ANZJS
>> > Department of Statistics
>> > University of Auckland
>> > Phone: +64-9-373-7599 ext. 88276
>> >
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Dan Dalthorp, PhD
> USGS Forest and Rangeland Ecosystem Science Center
> Forest Sciences Lab, Rm 189
> 3200 SW Jefferson Way
> Corvallis, OR 97331
> ph: 541-750-0953
> ddalthorp at usgs.gov
>


From ddalthorp at usgs.gov  Fri Oct  7 01:19:54 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Thu, 6 Oct 2016 16:19:54 -0700
Subject: [R] (no subject)
In-Reply-To: <CA+8X3fVjtTDYRjVkp4i2FmJDQLae5A_m5X8+KCJ4xGox3quWDg@mail.gmail.com>
References: <20161006075528.30220.qmail@f5mail-224-158.rediffmail.com>
	<81fc9a87-77b3-cb01-df51-1fb513222562@auckland.ac.nz>
	<CA+8X3fV-v+hsSREPDdeq22Y5R+_GRM3OYfTVcYoytiLN7ANJ-g@mail.gmail.com>
	<CAJeYpE_wqLBRMe6SPegVO05Qogj9zkhEB+EEOErnFfJ9cuDgEg@mail.gmail.com>
	<CA+8X3fVjtTDYRjVkp4i2FmJDQLae5A_m5X8+KCJ4xGox3quWDg@mail.gmail.com>
Message-ID: <CAJeYpE83YVwOXUv2NgN82S4ekHODjJNBCFJo9+j8ziP00Vh_xQ@mail.gmail.com>

The answer is 42 (in base 13). The question is "What do you get when you
multiply six by nine?"

On Thu, Oct 6, 2016 at 3:54 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> No, I'm quite certain that the answer is:
>
> 7*6 = 3*2^4 - 36/6
>
> but I don't know the question
>
> Jim
>
> On Fri, Oct 7, 2016 at 9:48 AM, Dalthorp, Daniel <ddalthorp at usgs.gov>
> wrote:
> > Question and answer:
> >
> > 6*9 = (4)*13^1 + (2)*13^0
> >
> > On Thu, Oct 6, 2016 at 3:26 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> It certainly does. As we are often confronted with requests for
> >> solutions of problems so minimally defined as to challenge the most
> >> eminent mindreader, this excels. We have a meta-problem as the
> >> supplicant him- (or her-, I cannot even ascertain this) does not
> >> appear to know what it is. Thus me are asked to both pose and solve
> >> the problem. While this may seem trivial to the casual reader, we must
> >> recall Adams' Paradox, that we might supply an answer, but be unable
> >> to state the question.
> >>
> >> Pardon the enthusiasm - I have just solved two gratuitous problems and
> >> I was, so to speak, primed for this message.
> >>
> >> Jim
> >>
> >> On Fri, Oct 7, 2016 at 7:20 AM, Rolf Turner <r.turner at auckland.ac.nz>
> >> wrote:
> >> > On 06/10/16 20:55, abhishek pandey wrote:
> >> >>
> >> >> kindly solve my problem sir.
> >> >
> >> >
> >> > That's it, in its entirety.  Shouldn't that win some sort of prize?
> >> >
> >> > cheers,
> >> >
> >> > Rolf Turner
> >> >
> >> > --
> >> > Technical Editor ANZJS
> >> > Department of Statistics
> >> > University of Auckland
> >> > Phone: +64-9-373-7599 ext. 88276
> >> >
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> >
> > --
> > Dan Dalthorp, PhD
> > USGS Forest and Rangeland Ecosystem Science Center
> > Forest Sciences Lab, Rm 189
> > 3200 SW Jefferson Way
> > Corvallis, OR 97331
> > ph: 541-750-0953
> > ddalthorp at usgs.gov
> >
>
>


-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Oct  7 01:22:56 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 06 Oct 2016 16:22:56 -0700
Subject: [R] (no subject)
In-Reply-To: <CA+8X3fV-v+hsSREPDdeq22Y5R+_GRM3OYfTVcYoytiLN7ANJ-g@mail.gmail.com>
References: <20161006075528.30220.qmail@f5mail-224-158.rediffmail.com>
	<81fc9a87-77b3-cb01-df51-1fb513222562@auckland.ac.nz>
	<CA+8X3fV-v+hsSREPDdeq22Y5R+_GRM3OYfTVcYoytiLN7ANJ-g@mail.gmail.com>
Message-ID: <28F85688-F148-41C7-B925-7D69511810E7@dcn.davis.ca.us>

The OP sent a separate email which was slightly less obscure. Taken together with this email, they suggest more a lack of familiarity with the concept of an email thread and with the time scale and features of email support, rather than a presumption of mind reading skills. One can hope that careful reading of the Posting Guide and referenced materials by the OP will correct this deficiency. 

I will admit to considering a fortune nomination at first reading though.
-- 
Sent from my phone. Please excuse my brevity.

On October 6, 2016 3:26:22 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>It certainly does. As we are often confronted with requests for
>solutions of problems so minimally defined as to challenge the most
>eminent mindreader, this excels. We have a meta-problem as the
>supplicant him- (or her-, I cannot even ascertain this) does not
>appear to know what it is. Thus me are asked to both pose and solve
>the problem. While this may seem trivial to the casual reader, we must
>recall Adams' Paradox, that we might supply an answer, but be unable
>to state the question.
>
>Pardon the enthusiasm - I have just solved two gratuitous problems and
>I was, so to speak, primed for this message.
>
>Jim
>
>On Fri, Oct 7, 2016 at 7:20 AM, Rolf Turner <r.turner at auckland.ac.nz>
>wrote:
>> On 06/10/16 20:55, abhishek pandey wrote:
>>>
>>> kindly solve my problem sir.
>>
>>
>> That's it, in its entirety.  Shouldn't that win some sort of prize?
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Oct  7 06:30:42 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 6 Oct 2016 21:30:42 -0700
Subject: [R] (no subject)
In-Reply-To: <28F85688-F148-41C7-B925-7D69511810E7@dcn.davis.ca.us>
References: <20161006075528.30220.qmail@f5mail-224-158.rediffmail.com>
	<81fc9a87-77b3-cb01-df51-1fb513222562@auckland.ac.nz>
	<CA+8X3fV-v+hsSREPDdeq22Y5R+_GRM3OYfTVcYoytiLN7ANJ-g@mail.gmail.com>
	<28F85688-F148-41C7-B925-7D69511810E7@dcn.davis.ca.us>
Message-ID: <2F59B114-ACD1-4A9C-932D-76EF4C8FBF55@comcast.net>


> On Oct 6, 2016, at 4:22 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> The OP sent a separate email which was slightly less obscure. Taken together with this email, they suggest more a lack of familiarity with the concept of an email thread and with the time scale and features of email support, rather than a presumption of mind reading skills. One can hope that careful reading of the Posting Guide and referenced materials by the OP will correct this deficiency. 
> 
> I will admit to considering a fortune nomination at first reading though.

Sigh. 

As a moderator of "non-subscriber postings", I initially rejected a posting from this email address 2 days ago with advice to read the Posting Guide and re-post with a more complete request and to avoid using HTML. So far, I have not seen a responsive effort to respond to that advice.

The advice we moderators follow is to use a very liberal filter for what should be posted, but this poster does seem to be a challenge to that interpretation.

Perhaps we should be referring some of these poorly documented postings to StackOverflow at the moderations event? What say you, members of the esteemed audience?

-- 
David Winsemius


> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On October 6, 2016 3:26:22 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>> It certainly does. As we are often confronted with requests for
>> solutions of problems so minimally defined as to challenge the most
>> eminent mindreader, this excels. We have a meta-problem as the
>> supplicant him- (or her-, I cannot even ascertain this) does not
>> appear to know what it is. Thus me are asked to both pose and solve
>> the problem. While this may seem trivial to the casual reader, we must
>> recall Adams' Paradox, that we might supply an answer, but be unable
>> to state the question.
>> 
>> Pardon the enthusiasm - I have just solved two gratuitous problems and
>> I was, so to speak, primed for this message.
>> 
>> Jim
>> 
>> On Fri, Oct 7, 2016 at 7:20 AM, Rolf Turner <r.turner at auckland.ac.nz>
>> wrote:
>>> On 06/10/16 20:55, abhishek pandey wrote:
>>>> 
>>>> kindly solve my problem sir.
>>> 
>>> 
>>> That's it, in its entirety.  Shouldn't that win some sort of prize?
>>> 
>>> cheers,
>>> 
>>> Rolf Turner
>>> 

David Winsemius
Alameda, CA, USA


From jwd at surewest.net  Fri Oct  7 08:15:16 2016
From: jwd at surewest.net (John Dougherty)
Date: Thu, 6 Oct 2016 23:15:16 -0700
Subject: [R] (no subject)
In-Reply-To: <20161006075528.30220.qmail@f5mail-224-158.rediffmail.com>
References: <20161006075528.30220.qmail@f5mail-224-158.rediffmail.com>
Message-ID: <20161006231516.44081993@draco>

On 6 Oct 2016 07:55:28 -0000
"abhishek pandey" <abhishekpandey_1983 at rediffmail.com> wrote:

> kindly solve my problem sir.
> 
> 
The answer obviously is 42.

JWDougherty


From davidsmi at microsoft.com  Fri Oct  7 15:21:13 2016
From: davidsmi at microsoft.com (David Smith)
Date: Fri, 7 Oct 2016 13:21:13 +0000
Subject: [R] Revolutions blog: September 2016 Roundup
Message-ID: <CY1PR0301MB2105BD46C4181AC7BDBBB0F5C8C60@CY1PR0301MB2105.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have written about R every weekday at the
Revolutions blog: http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the month of September:

The R-Ladies meetups and the Women in R Taskforce support gender diversity in the R community:
http://blog.revolutionanalytics.com/2016/09/all-the-r-ladies.html

Highlights from the Microsoft Data Science Summit include recordings of many presentations about R, and the keynote "The
Future of Data Analysis" by Edward Tufte:
http://blog.revolutionanalytics.com/2016/09/data-science-summit-highlights.html

An R-based fraud detection model scores credit card transactions in SQL Server at a rate of 1 million records per
second: http://blog.revolutionanalytics.com/2016/09/fraud-detection.html

The Financial Times uses R for quantitative journalism (and made some lovely animations comparing European
football teams): http://blog.revolutionanalytics.com/2016/09/financial-times-quantitative-journalism.html

Part 3 in a series on Deep Learning looks at combining CNNs with RNNs:
http://blog.revolutionanalytics.com/2016/09/deep-learning-part-3.html

There were many real-world applications of R presented at the EARL London conference
http://blog.revolutionanalytics.com/2016/09/reflections-on-earl-london-2016.html, including applications of Microsoft R
at Investec, British Car Auctions and Beazley Group
http://blog.revolutionanalytics.com/2016/09/microsoft-r-at-the-earl-conference.html.

Tips on choosing the right data science tool for a project:
http://blog.revolutionanalytics.com/2016/09/choose-the-right-tool.html

Tidyverse: a collection of packages for working with data in R:
http://blog.revolutionanalytics.com/2016/09/tidyverse.html

The Linux Data Science Virtual Machine has been upgraded with new tools including Microsoft R Server:
http://blog.revolutionanalytics.com/2016/09/linux-dsvm-upgrade.html

The Pirate's Guide to R: a video and 250-page e-book to learn the R language:
http://blog.revolutionanalytics.com/2016/09/pirates-guide-to-r.html

The 2016 O'Reilly Data Science Salary Survey reveals the most-used tools are SQL (70%), R (57%) and Python (54%):
http://blog.revolutionanalytics.com/2016/09/2016-data-science-salary-survey.html

A simple explanation of Convolutional Neural Networks:
http://blog.revolutionanalytics.com/2016/09/how-the-algorithm-behind-deep-learning-works.html

A template for building a predictive maintenance application with SQL Server R Services:
http://blog.revolutionanalytics.com/2016/09/r-services-maintenance.html

The R Consortium awarded a grant of $10,000 to The R Documentation Task Force to design and build the next generation R
documentation system: http://blog.revolutionanalytics.com/2016/09/volunteer-to-help-improve-rs-documentation.html

Scaling R-based applications with DeployR grid nodes and slots:
http://blog.revolutionanalytics.com/2016/09/the-elements-of-scaling-r-based-applications-with-deployr.html

An R packages to extract colour palettes from satellite imagery:
http://blog.revolutionanalytics.com/2016/09/the-pallettes-of-earth.html

A guide for porting SAS programs for financial data manipulation to R:
http://blog.revolutionanalytics.com/2016/09/rewriting-sas-in-r-for-finance.html

How to analyze basketball data and create animations of player movements with R:
http://blog.revolutionanalytics.com/2016/09/analyzing-nba-basketball-data-with-r.html

Create a more perceptive heatmap colour scale with the viridis package:
http://blog.revolutionanalytics.com/2016/09/choose-a-good-heatmap-color-scale-with-viridis.html

General interest stories (not related to R) in the past month included: how a newspaper was printed in 1973
(http://blog.revolutionanalytics.com/2016/09/because-its-friday-typesetting-in-the-olden-days.html), illusions caused by
our poor peripheral vision (http://blog.revolutionanalytics.com/2016/09/peripheral-illusions.html), a chart (to scale!)
about climate change
(http://blog.revolutionanalytics.com/2016/09/because-its-friday-a-big-chart-about-climate-change.html), a happier
version of the X Files Theme (http://blog.revolutionanalytics.com/2016/09/because-its-friday-the-happy-files.html), and
a short film on the creation of the universe
(http://blog.revolutionanalytics.com/2016/09/because-its-friday-the-creation-of-the-universe-in-paint-and-salt.html).

If you're looking for more articles about R, you can find summaries from previous months at
http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like
blogtrottr.com.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From roger.bos at rothschild.com  Fri Oct  7 15:24:31 2016
From: roger.bos at rothschild.com (Bos, Roger)
Date: Fri, 7 Oct 2016 13:24:31 +0000
Subject: [R] weighted regression inside FOREACH loop
Message-ID: <0765308CD028654885F30322557308D831B3E5BA@NYCSM0208.rth.ad.rothschild.com>

I have a foreach loop that runs regressions in parallel and works fine, but when I try to add the weights parameter to the regression the coefficients don?t get stored in the ?models? variable like they are supposed to.  Below is my reproducible example:

library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
fmla <- as.formula("y ~ .")
models <- foreach(d=1:10, .combine=rbind, .errorhandling='remove') %dopar% {
  datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
  weights <- rep(c(1,2), 50)
  mod <- lm(fmla, data=datdf, weights=weights)
  #mod <- lm(fmla, data=datdf)
  return(mod$coef)
}
models

You can change the commenting on the two ?mod <-? lines to see that the non-weighted one works and the weighted regression doesn?t work.  I tried using .export="weights" in the foreach line, but R says that weights is already being exported.

Thanks in advance for any suggestions.





***************************************************************
This message and any attachments are for the intended recipient's use only.
This message may contain confidential, proprietary or legally privileged
information. No right to confidential or privileged treatment
of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately
notify the sender by e-mail, delete the message, any attachments and all
copies from your system and destroy any hard copies.  You must
not, directly or indirectly, use, disclose, distribute,
print or copy any part of this message or any attachments if you are not
the intended recipient.


From thierry.onkelinx at inbo.be  Fri Oct  7 15:47:14 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 7 Oct 2016 15:47:14 +0200
Subject: [R] weighted regression inside FOREACH loop
In-Reply-To: <0765308CD028654885F30322557308D831B3E5BA@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D831B3E5BA@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <CAJuCY5yFHo5_j8WeFhE72yQKFOnsDfRZhGgSs9=tZ4Ps_=U4wA@mail.gmail.com>

Dear Roger,

Maybe you want to return(mod) instead of return(mod$coef)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-10-07 15:24 GMT+02:00 Bos, Roger <roger.bos at rothschild.com>:

> I have a foreach loop that runs regressions in parallel and works fine,
> but when I try to add the weights parameter to the regression the
> coefficients don?t get stored in the ?models? variable like they are
> supposed to.  Below is my reproducible example:
>
> library(doParallel)
> cl <- makeCluster(4)
> registerDoParallel(cl)
> fmla <- as.formula("y ~ .")
> models <- foreach(d=1:10, .combine=rbind, .errorhandling='remove') %dopar%
> {
>   datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
>   weights <- rep(c(1,2), 50)
>   mod <- lm(fmla, data=datdf, weights=weights)
>   #mod <- lm(fmla, data=datdf)
>   return(mod$coef)
> }
> models
>
> You can change the commenting on the two ?mod <-? lines to see that the
> non-weighted one works and the weighted regression doesn?t work.  I tried
> using .export="weights" in the foreach line, but R says that weights is
> already being exported.
>
> Thanks in advance for any suggestions.
>
>
>
>
>
> ***************************************************************
> This message and any attachments are for the intended recipient's use only.
> This message may contain confidential, proprietary or legally privileged
> information. No right to confidential or privileged treatment
> of this message is waived or lost by an error in transmission.
> If you have received this message in error, please immediately
> notify the sender by e-mail, delete the message, any attachments and all
> copies from your system and destroy any hard copies.  You must
> not, directly or indirectly, use, disclose, distribute,
> print or copy any part of this message or any attachments if you are not
> the intended recipient.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From roger.bos at rothschild.com  Fri Oct  7 16:44:27 2016
From: roger.bos at rothschild.com (Bos, Roger)
Date: Fri, 7 Oct 2016 14:44:27 +0000
Subject: [R] weighted regression inside FOREACH loop
In-Reply-To: <0765308CD028654885F30322557308D831B3E5BA@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D831B3E5BA@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <0765308CD028654885F30322557308D831B3FD64@NYCSM0208.rth.ad.rothschild.com>

All,

I figured out how to get it to work, so I am posting the solution in case anyone is interested.  I had to use attr to set the weights as an attribute of the data object for the linear model.  Seems convoluted, but anytime I tried to pass a named vector as the weights the foreach loop could not find the variable, even if I tried exporting it.  If anybody knows of a better way please let me know as this does not seem ideal to me, but it works.

library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
fmla <- as.formula("y ~ .")
models <- foreach(d=1:10, .combine=rbind, .errorhandling='pass') %dopar% {
  datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
  attr(datdf, "weights") <- rep(c(1,2), 50)
  mod <- lm(fmla, data=datdf, weights=attr(data, "weights"))
  return(mod$coef)
}
Models





-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bos, Roger
Sent: Friday, October 07, 2016 9:25 AM
To: R-help
Subject: [R] weighted regression inside FOREACH loop

I have a foreach loop that runs regressions in parallel and works fine, but when I try to add the weights parameter to the regression the coefficients don?t get stored in the ?models? variable like they are supposed to.  Below is my reproducible example:

library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
fmla <- as.formula("y ~ .")
models <- foreach(d=1:10, .combine=rbind, .errorhandling='remove') %dopar% {
  datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
  weights <- rep(c(1,2), 50)
  mod <- lm(fmla, data=datdf, weights=weights)
  #mod <- lm(fmla, data=datdf)
  return(mod$coef)
}
models

You can change the commenting on the two ?mod <-? lines to see that the non-weighted one works and the weighted regression doesn?t work.  I tried using .export="weights" in the foreach line, but R says that weights is already being exported.

Thanks in advance for any suggestions.





***************************************************************
This message and any attachments are for the intended recipient's use only.
This message may contain confidential, proprietary or legally privileged information. No right to confidential or privileged treatment of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately notify the sender by e-mail, delete the message, any attachments and all copies from your system and destroy any hard copies.  You must not, directly or indirectly, use, disclose, distribute, print or copy any part of this message or any attachments if you are not the intended recipient.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From wdunlap at tibco.com  Fri Oct  7 17:18:25 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 7 Oct 2016 08:18:25 -0700
Subject: [R] weighted regression inside FOREACH loop
In-Reply-To: <0765308CD028654885F30322557308D831B3FD64@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D831B3E5BA@NYCSM0208.rth.ad.rothschild.com>
	<0765308CD028654885F30322557308D831B3FD64@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <CAF8bMcbNrpfV_P5EF8eMfvkb1mvbvJRuSeH7rGo3rQTDPUPC_A@mail.gmail.com>

A more general way is to change the environment of your formula to
a child of its original environment and add variables like 'weights' or
'subset' to the child environment.  Since you change the environment
inside a function call it won't affect the formula outside of the function
call.
E.g.

fmla <- as.formula("y ~ .")

models <- foreach(d=1:10, .combine=rbind, .errorhandling='remove') %dopar% {
  datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
  localEnvir <- new.env(parent=environment(fmla))
  environment(fmla) <- localEnvir
  localEnvir$weights <- rep(c(1,2), 50)
  mod <- lm(fmla, data=datdf, weights=weights)
  return(mod$coef)
}
models
#          (Intercept)         x
#result.1  -0.16910860 1.0022022
#result.2   0.03326814 0.9968325
#result.3  -0.08177174 1.0022907
#...
environment(fmla)
#<environment: R_GlobalEnv>



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Oct 7, 2016 at 7:44 AM, Bos, Roger <roger.bos at rothschild.com> wrote:

> All,
>
> I figured out how to get it to work, so I am posting the solution in case
> anyone is interested.  I had to use attr to set the weights as an attribute
> of the data object for the linear model.  Seems convoluted, but anytime I
> tried to pass a named vector as the weights the foreach loop could not find
> the variable, even if I tried exporting it.  If anybody knows of a better
> way please let me know as this does not seem ideal to me, but it works.
>
> library(doParallel)
> cl <- makeCluster(4)
> registerDoParallel(cl)
> fmla <- as.formula("y ~ .")
> models <- foreach(d=1:10, .combine=rbind, .errorhandling='pass') %dopar% {
>   datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
>   attr(datdf, "weights") <- rep(c(1,2), 50)
>   mod <- lm(fmla, data=datdf, weights=attr(data, "weights"))
>   return(mod$coef)
> }
> Models
>
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bos, Roger
> Sent: Friday, October 07, 2016 9:25 AM
> To: R-help
> Subject: [R] weighted regression inside FOREACH loop
>
> I have a foreach loop that runs regressions in parallel and works fine,
> but when I try to add the weights parameter to the regression the
> coefficients don?t get stored in the ?models? variable like they are
> supposed to.  Below is my reproducible example:
>
> library(doParallel)
> cl <- makeCluster(4)
> registerDoParallel(cl)
> fmla <- as.formula("y ~ .")
> models <- foreach(d=1:10, .combine=rbind, .errorhandling='remove') %dopar%
> {
>   datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
>   weights <- rep(c(1,2), 50)
>   mod <- lm(fmla, data=datdf, weights=weights)
>   #mod <- lm(fmla, data=datdf)
>   return(mod$coef)
> }
> models
>
> You can change the commenting on the two ?mod <-? lines to see that the
> non-weighted one works and the weighted regression doesn?t work.  I tried
> using .export="weights" in the foreach line, but R says that weights is
> already being exported.
>
> Thanks in advance for any suggestions.
>
>
>
>
>
> ***************************************************************
> This message and any attachments are for the intended recipient's use only.
> This message may contain confidential, proprietary or legally privileged
> information. No right to confidential or privileged treatment of this
> message is waived or lost by an error in transmission.
> If you have received this message in error, please immediately notify the
> sender by e-mail, delete the message, any attachments and all copies from
> your system and destroy any hard copies.  You must not, directly or
> indirectly, use, disclose, distribute, print or copy any part of this
> message or any attachments if you are not the intended recipient.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Oct  7 17:56:36 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 7 Oct 2016 08:56:36 -0700
Subject: [R] weighted regression inside FOREACH loop
In-Reply-To: <CAF8bMcbNrpfV_P5EF8eMfvkb1mvbvJRuSeH7rGo3rQTDPUPC_A@mail.gmail.com>
References: <0765308CD028654885F30322557308D831B3E5BA@NYCSM0208.rth.ad.rothschild.com>
	<0765308CD028654885F30322557308D831B3FD64@NYCSM0208.rth.ad.rothschild.com>
	<CAF8bMcbNrpfV_P5EF8eMfvkb1mvbvJRuSeH7rGo3rQTDPUPC_A@mail.gmail.com>
Message-ID: <CAF8bMcYVpHmjjkezXiAOwxp8WqVd0OzHJgao9Ni9icm-tMYNBw@mail.gmail.com>

Using the temporary child environment works because model.frame, hence lm,
looks for the variables used in the formula, subset, and weights arguments
first in the data argument and then, if the data argument is not an
environment, in the environment of the formula argument.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Oct 7, 2016 at 8:18 AM, William Dunlap <wdunlap at tibco.com> wrote:

> A more general way is to change the environment of your formula to
> a child of its original environment and add variables like 'weights' or
> 'subset' to the child environment.  Since you change the environment
> inside a function call it won't affect the formula outside of the function
> call.
> E.g.
>
> fmla <- as.formula("y ~ .")
>
> models <- foreach(d=1:10, .combine=rbind, .errorhandling='remove') %dopar%
> {
>   datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
>   localEnvir <- new.env(parent=environment(fmla))
>   environment(fmla) <- localEnvir
>   localEnvir$weights <- rep(c(1,2), 50)
>   mod <- lm(fmla, data=datdf, weights=weights)
>   return(mod$coef)
> }
> models
> #          (Intercept)         x
> #result.1  -0.16910860 1.0022022
> #result.2   0.03326814 0.9968325
> #result.3  -0.08177174 1.0022907
> #...
> environment(fmla)
> #<environment: R_GlobalEnv>
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Oct 7, 2016 at 7:44 AM, Bos, Roger <roger.bos at rothschild.com>
> wrote:
>
>> All,
>>
>> I figured out how to get it to work, so I am posting the solution in case
>> anyone is interested.  I had to use attr to set the weights as an attribute
>> of the data object for the linear model.  Seems convoluted, but anytime I
>> tried to pass a named vector as the weights the foreach loop could not find
>> the variable, even if I tried exporting it.  If anybody knows of a better
>> way please let me know as this does not seem ideal to me, but it works.
>>
>> library(doParallel)
>> cl <- makeCluster(4)
>> registerDoParallel(cl)
>> fmla <- as.formula("y ~ .")
>> models <- foreach(d=1:10, .combine=rbind, .errorhandling='pass') %dopar% {
>>   datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
>>   attr(datdf, "weights") <- rep(c(1,2), 50)
>>   mod <- lm(fmla, data=datdf, weights=attr(data, "weights"))
>>   return(mod$coef)
>> }
>> Models
>>
>>
>>
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bos,
>> Roger
>> Sent: Friday, October 07, 2016 9:25 AM
>> To: R-help
>> Subject: [R] weighted regression inside FOREACH loop
>>
>> I have a foreach loop that runs regressions in parallel and works fine,
>> but when I try to add the weights parameter to the regression the
>> coefficients don?t get stored in the ?models? variable like they are
>> supposed to.  Below is my reproducible example:
>>
>> library(doParallel)
>> cl <- makeCluster(4)
>> registerDoParallel(cl)
>> fmla <- as.formula("y ~ .")
>> models <- foreach(d=1:10, .combine=rbind, .errorhandling='remove')
>> %dopar% {
>>   datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
>>   weights <- rep(c(1,2), 50)
>>   mod <- lm(fmla, data=datdf, weights=weights)
>>   #mod <- lm(fmla, data=datdf)
>>   return(mod$coef)
>> }
>> models
>>
>> You can change the commenting on the two ?mod <-? lines to see that the
>> non-weighted one works and the weighted regression doesn?t work.  I tried
>> using .export="weights" in the foreach line, but R says that weights is
>> already being exported.
>>
>> Thanks in advance for any suggestions.
>>
>>
>>
>>
>>
>> ***************************************************************
>> This message and any attachments are for the intended recipient's use
>> only.
>> This message may contain confidential, proprietary or legally privileged
>> information. No right to confidential or privileged treatment of this
>> message is waived or lost by an error in transmission.
>> If you have received this message in error, please immediately notify the
>> sender by e-mail, delete the message, any attachments and all copies from
>> your system and destroy any hard copies.  You must not, directly or
>> indirectly, use, disclose, distribute, print or copy any part of this
>> message or any attachments if you are not the intended recipient.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From cimentadaj at gmail.com  Fri Oct  7 18:06:21 2016
From: cimentadaj at gmail.com (Jorge Cimentada)
Date: Fri, 7 Oct 2016 18:06:21 +0200
Subject: [R] Error creating named character vectors from column names in
	data frame.
Message-ID: <CALdB+JF1+=_3X8K6fuXkyYs2mUBwyUm+U7kzaZFpTQpOiZCurw@mail.gmail.com>

Hi everyone,

I was hoping someone would explain why this doesn't work.

c("a" = "b") # named character vector
class("a") # character
class("b") # character

c(names(mtcars)[1] = names(mtcars[2]) # error
class(names(mtcars)[1]) # character
class(names(mtcars)[2]) # character


Thanks,
Jorge Cimentada

	[[alternative HTML version deleted]]


From cimentadaj at gmail.com  Fri Oct  7 18:20:29 2016
From: cimentadaj at gmail.com (Jorge Cimentada)
Date: Fri, 7 Oct 2016 18:20:29 +0200
Subject: [R] Error creating named character vectors from column names in
	data frame.
In-Reply-To: <CALdB+JF1+=_3X8K6fuXkyYs2mUBwyUm+U7kzaZFpTQpOiZCurw@mail.gmail.com>
References: <CALdB+JF1+=_3X8K6fuXkyYs2mUBwyUm+U7kzaZFpTQpOiZCurw@mail.gmail.com>
Message-ID: <CALdB+JGO8-syJc3zSE+4+X_L=pwX4RPpfeS-3cHYwHvbWrgDaQ@mail.gmail.com>

I'm sorry, there was a typo. The result is still the same:

c("a" = "b") # named character vector
class("a") # character
class("b") # character

c(names(mtcars)[1] = names(mtcars)[2]) # error
class(names(mtcars)[1]) # character
class(names(mtcars)[2]) # character

Thanks,
Jorge Cimentada

	[[alternative HTML version deleted]]


From roger.bos at rothschild.com  Fri Oct  7 18:23:20 2016
From: roger.bos at rothschild.com (Bos, Roger)
Date: Fri, 7 Oct 2016 16:23:20 +0000
Subject: [R] weighted regression inside FOREACH loop
In-Reply-To: <CAF8bMcYVpHmjjkezXiAOwxp8WqVd0OzHJgao9Ni9icm-tMYNBw@mail.gmail.com>
References: <0765308CD028654885F30322557308D831B3E5BA@NYCSM0208.rth.ad.rothschild.com>
	<0765308CD028654885F30322557308D831B3FD64@NYCSM0208.rth.ad.rothschild.com>
	<CAF8bMcbNrpfV_P5EF8eMfvkb1mvbvJRuSeH7rGo3rQTDPUPC_A@mail.gmail.com>
	<CAF8bMcYVpHmjjkezXiAOwxp8WqVd0OzHJgao9Ni9icm-tMYNBw@mail.gmail.com>
Message-ID: <0765308CD028654885F30322557308D831B3FDF7@NYCSM0208.rth.ad.rothschild.com>

Bill,

Thanks for your help.  Not that I ever doubted you, but I tried your method on my actual data and I can confirm it does work.  I guess I am still wondering why using .export in foreach doesn?t allow the variable to be found as that method would seem to be the most straightforward.

Thanks again for your help!

Roger




This message and any attachments are for the intended recipient?s use only.

This message may contain confidential, proprietary or legally privileged

information. No right to confidential or privileged treatment

of this message is waived or lost by an error in transmission.

If you have received this message in error, please immediately

notify the sender by e-mail, delete the message, any attachments and all

copies from your system and destroy any hard copies.  You must

not, directly or indirectly, use, disclose, distribute,

print or copy any part of this message or any attachments if you are not

the intended recipient.
From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: Friday, October 07, 2016 11:57 AM
To: Bos, Roger
Cc: R-help
Subject: Re: [R] weighted regression inside FOREACH loop

Using the temporary child environment works because model.frame, hence lm, looks for the variables used in the formula, subset, and weights arguments first in the data argument and then, if the data argument is not an environment, in the environment of the formula argument.

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Fri, Oct 7, 2016 at 8:18 AM, William Dunlap <wdunlap at tibco.com<mailto:wdunlap at tibco.com>> wrote:
A more general way is to change the environment of your formula to
a child of its original environment and add variables like 'weights' or
'subset' to the child environment.  Since you change the environment
inside a function call it won't affect the formula outside of the function call.
E.g.

fmla <- as.formula("y ~ .")

models <- foreach(d=1:10, .combine=rbind, .errorhandling='remove') %dopar% {
  datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
  localEnvir <- new.env(parent=environment(fmla))
  environment(fmla) <- localEnvir
  localEnvir$weights <- rep(c(1,2), 50)
  mod <- lm(fmla, data=datdf, weights=weights)
  return(mod$coef)
}
models
#          (Intercept)         x
#result.1  -0.16910860 1.0022022
#result.2   0.03326814 0.9968325
#result.3  -0.08177174 1.0022907
#...
environment(fmla)
#<environment: R_GlobalEnv>



Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Fri, Oct 7, 2016 at 7:44 AM, Bos, Roger <roger.bos at rothschild.com<mailto:roger.bos at rothschild.com>> wrote:
All,

I figured out how to get it to work, so I am posting the solution in case anyone is interested.  I had to use attr to set the weights as an attribute of the data object for the linear model.  Seems convoluted, but anytime I tried to pass a named vector as the weights the foreach loop could not find the variable, even if I tried exporting it.  If anybody knows of a better way please let me know as this does not seem ideal to me, but it works.

library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
fmla <- as.formula("y ~ .")
models <- foreach(d=1:10, .combine=rbind, .errorhandling='pass') %dopar% {
  datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
  attr(datdf, "weights") <- rep(c(1,2), 50)
  mod <- lm(fmla, data=datdf, weights=attr(data, "weights"))
  return(mod$coef)
}
Models





-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Bos, Roger
Sent: Friday, October 07, 2016 9:25 AM
To: R-help
Subject: [R] weighted regression inside FOREACH loop

I have a foreach loop that runs regressions in parallel and works fine, but when I try to add the weights parameter to the regression the coefficients don?t get stored in the ?models? variable like they are supposed to.  Below is my reproducible example:

library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)
fmla <- as.formula("y ~ .")
models <- foreach(d=1:10, .combine=rbind, .errorhandling='remove') %dopar% {
  datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
  weights <- rep(c(1,2), 50)
  mod <- lm(fmla, data=datdf, weights=weights)
  #mod <- lm(fmla, data=datdf)
  return(mod$coef)
}
models

You can change the commenting on the two ?mod <-? lines to see that the non-weighted one works and the weighted regression doesn?t work.  I tried using .export="weights" in the foreach line, but R says that weights is already being exported.

Thanks in advance for any suggestions.





***************************************************************
This message and any attachments are for the intended recipient's use only.
This message may contain confidential, proprietary or legally privileged information. No right to confidential or privileged treatment of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately notify the sender by e-mail, delete the message, any attachments and all copies from your system and destroy any hard copies.  You must not, directly or indirectly, use, disclose, distribute, print or copy any part of this message or any attachments if you are not the intended recipient.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From Simon.Heather at epa.gov  Fri Oct  7 18:41:30 2016
From: Simon.Heather at epa.gov (Simon, Heather)
Date: Fri, 7 Oct 2016 16:41:30 +0000
Subject: [R] date comparison doesn't match value
Message-ID: <BLUPR09MB089862605DCE8F4E64B12F47E1C60@BLUPR09MB0898.namprd09.prod.outlook.com>

I am running into trouble when trying to compare date fields in my dataset.  When I view a field, it looks like it is a date in 2011:


> alldata$new.date.local[1]
[1] "2011-07-01 12:08:07 EDT"

However, when I try to compare it to a character string, it seems to think it is equal to sometime between the years 1310 and 1309

> alldata$new.date.local[1] < "1310-01-01 00:00:00 EDT"
[1] TRUE
> alldata$new.date.local[1] < "1309-12-31 23:59:59 EDT"
[1] FALSE

But not exactly equal to midnight of Dec 31 in 1309, so it is not equal to any exact time:

> alldata$new.date.local[1] == "1309-12-31 23:59:59 EDT"
[1] FALSE
> alldata$new.date.local[1] < "1309-12-31 23:59:59 EDT"
[1] FALSE
> alldata$new.date.local[1] > "1309-12-31 23:59:59 EDT"
[1] TRUE

Even though this date field was created using as.POSIXct from a text string, I have tried fixing this by reapplying the as.POSIXct function:

>alldata$new.date.local <- as.POSIXct(alldata$new.date.local, tz = "EDT")

But this does not seem to fix the problem.  When I try recreating the date from a character string I get the same behavior.  Any suggestions would be much appreciated.

-Heather



	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Oct  7 18:58:39 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 7 Oct 2016 12:58:39 -0400
Subject: [R] date comparison doesn't match value
In-Reply-To: <BLUPR09MB089862605DCE8F4E64B12F47E1C60@BLUPR09MB0898.namprd09.prod.outlook.com>
References: <BLUPR09MB089862605DCE8F4E64B12F47E1C60@BLUPR09MB0898.namprd09.prod.outlook.com>
Message-ID: <CAM_vju=18HK6MfHw93kA+o_BgRXmou=PnzJQrG7A2BaDg=mObA@mail.gmail.com>

Hi Heather,

I can't duplicate your problem: "looks like a date" is not helpful. If
you use dput() to provide actual data, then maybe we can actually help
you. Providing sessionInfo() would also help, as some time problems
may be OS-related.

Meanwhile, see if working thru this can help you get it sorted out.


mydatetxt <- "2011-07-01 12:08:07 EDT"
mydatect <- as.POSIXct(mydatetxt, tz="EDT")

str(mydatetxt)
str(mydatect)

mydatetxt < "1310-01-01 00:00:00 EDT"
mydatect < "1310-01-01 00:00:00 EDT"

mydatetxt < "1309-12-31 23:59:59 EDT"
mydatect < "1309-12-31 23:59:59 EDT"


# more useful

mydatetxt  < "2009-12-31 23:59:59 EDT"
mydatetxt  < "2011-12-31 23:59:59 EDT"

mydatect  < "2009-12-31 23:59:59 EDT"
mydatect  < "2011-12-31 23:59:59 EDT"

mydatect  < as.POSIXct("2009-12-31 23:59:59 EDT", tz="EDT")
mydatect  < as.POSIXct("2011-12-31 23:59:59 EDT", tz="EDT")

# as run:

> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: Fedora 23 (Twenty Three)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
LC_TIME=en_US.UTF-8
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8
LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
LC_ADDRESS=C
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8
LC_IDENTIFICATION=C

> mydatetxt <- "2011-07-01 12:08:07 EDT"
> mydatect <- as.POSIXct(mydatetxt, tz="EDT")
>
> str(mydatetxt)
 chr "2011-07-01 12:08:07 EDT"
> str(mydatect)
 POSIXct[1:1], format: "2011-07-01 12:08:07"
>
> mydatetxt < "1310-01-01 00:00:00 EDT"
[1] FALSE
> mydatect < "1310-01-01 00:00:00 EDT"
[1] FALSE
>
> mydatetxt < "1309-12-31 23:59:59 EDT"
[1] FALSE
> mydatect < "1309-12-31 23:59:59 EDT"
[1] FALSE
>
>
> # more useful
>
> mydatetxt  < "2009-12-31 23:59:59 EDT"
[1] FALSE
> mydatetxt  < "2011-12-31 23:59:59 EDT"
[1] TRUE
>
> mydatect  < "2009-12-31 23:59:59 EDT"
[1] FALSE
> mydatect  < "2011-12-31 23:59:59 EDT"
[1] TRUE
>
> mydatect  < as.POSIXct("2009-12-31 23:59:59 EDT", tz="EDT")
[1] FALSE
> mydatect  < as.POSIXct("2011-12-31 23:59:59 EDT", tz="EDT")
[1] TRUE
>


On Fri, Oct 7, 2016 at 12:41 PM, Simon, Heather <Simon.Heather at epa.gov> wrote:
> I am running into trouble when trying to compare date fields in my dataset.  When I view a field, it looks like it is a date in 2011:
>
>
>> alldata$new.date.local[1]
> [1] "2011-07-01 12:08:07 EDT"
>
> However, when I try to compare it to a character string, it seems to think it is equal to sometime between the years 1310 and 1309
>
>> alldata$new.date.local[1] < "1310-01-01 00:00:00 EDT"
> [1] TRUE
>> alldata$new.date.local[1] < "1309-12-31 23:59:59 EDT"
> [1] FALSE
>
> But not exactly equal to midnight of Dec 31 in 1309, so it is not equal to any exact time:
>
>> alldata$new.date.local[1] == "1309-12-31 23:59:59 EDT"
> [1] FALSE
>> alldata$new.date.local[1] < "1309-12-31 23:59:59 EDT"
> [1] FALSE
>> alldata$new.date.local[1] > "1309-12-31 23:59:59 EDT"
> [1] TRUE
>
> Even though this date field was created using as.POSIXct from a text string, I have tried fixing this by reapplying the as.POSIXct function:
>
>>alldata$new.date.local <- as.POSIXct(alldata$new.date.local, tz = "EDT")
>
> But this does not seem to fix the problem.  When I try recreating the date from a character string I get the same behavior.  Any suggestions would be much appreciated.
>
> -Heather
>
>


From wdunlap at tibco.com  Fri Oct  7 19:14:07 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 7 Oct 2016 10:14:07 -0700
Subject: [R] weighted regression inside FOREACH loop
In-Reply-To: <0765308CD028654885F30322557308D831B3FDF7@NYCSM0208.rth.ad.rothschild.com>
References: <0765308CD028654885F30322557308D831B3E5BA@NYCSM0208.rth.ad.rothschild.com>
	<0765308CD028654885F30322557308D831B3FD64@NYCSM0208.rth.ad.rothschild.com>
	<CAF8bMcbNrpfV_P5EF8eMfvkb1mvbvJRuSeH7rGo3rQTDPUPC_A@mail.gmail.com>
	<CAF8bMcYVpHmjjkezXiAOwxp8WqVd0OzHJgao9Ni9icm-tMYNBw@mail.gmail.com>
	<0765308CD028654885F30322557308D831B3FDF7@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <CAF8bMcZvHVv=5rpvsePTtQ8ZyPnpbgJ0-rVVywHyBhpe+4mnyg@mail.gmail.com>

foreach's '.export' argument lists the objects that should be copied to the
environment in which the expression is to be evaluated, which is not the
global environment.  In your example, environment(formula) is the global
environment so lm(formula, data=d, weights=weights) only looks in the
data.frame d and the global environment for a variable called 'weights'.

The following example uses the subset argument instead of weights.  Note
that all the variables involved are exported, but to the environment in
which coef(lm(...)) will be evaluated, not the global environment, hence
they are not found by lm (really, model.frame) when it looks in
environment(formula).

> d <- data.frame(x=log(1:4), y=1:4)
> formula <- y ~ x
> subsets <- list(1:2, 2:3, 3:4)
> foreach(k=1, .combine=list) %dopar% { list(
    FormulaObjects=objects(environment(formula), all=TRUE),
    LocalObjects=objects(environment(), all=TRUE),
    tryCatch(error=function(e)conditionMessage(e), coef(lm(data=d, formula,
subset=subsets[[k]])))) }
$FormulaObjects
[1] ".Random.seed"

$LocalObjects
[1] "d"       "formula" "k"       "subsets"

[[3]]
[1] "object 'subsets' not found"

Using the temporary child environment for things like this is helpful is
lots of situations, not just when using foreach.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Oct 7, 2016 at 9:23 AM, Bos, Roger <roger.bos at rothschild.com> wrote:

> Bill,
>
>
>
> Thanks for your help.  Not that I ever doubted you, but I tried your
> method on my actual data and I can confirm it does work.  I guess I am
> still wondering why using .export in foreach doesn?t allow the variable to
> be found as that method would seem to be the most straightforward.
>
>
>
> Thanks again for your help!
>
>
>
> Roger
>
>
>
>
>
> This message and any attachments are for the intended recipient?s use
> only.
>
> This message may contain confidential, proprietary or legally privileged
>
> information. No right to confidential or privileged treatment
>
> of this message is waived or lost by an error in transmission.
>
> If you have received this message in error, please immediately
>
> notify the sender by e-mail, delete the message, any attachments and all
>
> copies from your system and destroy any hard copies.  You must
>
> not, directly or indirectly, use, disclose, distribute,
>
> print or copy any part of this message or any attachments if you are not
>
> the intended recipient.
>
> *From:* William Dunlap [mailto:wdunlap at tibco.com]
> *Sent:* Friday, October 07, 2016 11:57 AM
> *To:* Bos, Roger
> *Cc:* R-help
> *Subject:* Re: [R] weighted regression inside FOREACH loop
>
>
>
> Using the temporary child environment works because model.frame, hence lm,
> looks for the variables used in the formula, subset, and weights arguments
> first in the data argument and then, if the data argument is not an
> environment, in the environment of the formula argument.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
>
> On Fri, Oct 7, 2016 at 8:18 AM, William Dunlap <wdunlap at tibco.com> wrote:
>
> A more general way is to change the environment of your formula to
>
> a child of its original environment and add variables like 'weights' or
>
> 'subset' to the child environment.  Since you change the environment
>
> inside a function call it won't affect the formula outside of the function
> call.
>
> E.g.
>
>
>
> fmla <- as.formula("y ~ .")
>
>
>
> models <- foreach(d=1:10, .combine=rbind, .errorhandling='remove') %dopar%
> {
>
>   datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
>
>   localEnvir <- new.env(parent=environment(fmla))
>
>   environment(fmla) <- localEnvir
>
>   localEnvir$weights <- rep(c(1,2), 50)
>
>   mod <- lm(fmla, data=datdf, weights=weights)
>
>   return(mod$coef)
>
> }
>
> models
>
> #          (Intercept)         x
>
> #result.1  -0.16910860 1.0022022
>
> #result.2   0.03326814 0.9968325
>
> #result.3  -0.08177174 1.0022907
>
> #...
>
> environment(fmla)
>
> #<environment: R_GlobalEnv>
>
>
>
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
>
> On Fri, Oct 7, 2016 at 7:44 AM, Bos, Roger <roger.bos at rothschild.com>
> wrote:
>
> All,
>
> I figured out how to get it to work, so I am posting the solution in case
> anyone is interested.  I had to use attr to set the weights as an attribute
> of the data object for the linear model.  Seems convoluted, but anytime I
> tried to pass a named vector as the weights the foreach loop could not find
> the variable, even if I tried exporting it.  If anybody knows of a better
> way please let me know as this does not seem ideal to me, but it works.
>
> library(doParallel)
> cl <- makeCluster(4)
> registerDoParallel(cl)
> fmla <- as.formula("y ~ .")
> models <- foreach(d=1:10, .combine=rbind, .errorhandling='pass') %dopar% {
>   datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
>   attr(datdf, "weights") <- rep(c(1,2), 50)
>   mod <- lm(fmla, data=datdf, weights=attr(data, "weights"))
>   return(mod$coef)
> }
> Models
>
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bos, Roger
> Sent: Friday, October 07, 2016 9:25 AM
> To: R-help
> Subject: [R] weighted regression inside FOREACH loop
>
> I have a foreach loop that runs regressions in parallel and works fine,
> but when I try to add the weights parameter to the regression the
> coefficients don?t get stored in the ?models? variable like they are
> supposed to.  Below is my reproducible example:
>
> library(doParallel)
> cl <- makeCluster(4)
> registerDoParallel(cl)
> fmla <- as.formula("y ~ .")
> models <- foreach(d=1:10, .combine=rbind, .errorhandling='remove') %dopar%
> {
>   datdf <- data.frame(y = 1:100+2*rnorm(100), x = 1:100+rnorm(100))
>   weights <- rep(c(1,2), 50)
>   mod <- lm(fmla, data=datdf, weights=weights)
>   #mod <- lm(fmla, data=datdf)
>   return(mod$coef)
> }
> models
>
> You can change the commenting on the two ?mod <-? lines to see that the
> non-weighted one works and the weighted regression doesn?t work.  I tried
> using .export="weights" in the foreach line, but R says that weights is
> already being exported.
>
> Thanks in advance for any suggestions.
>
>
>
>
>
> ***************************************************************
> This message and any attachments are for the intended recipient's use only.
> This message may contain confidential, proprietary or legally privileged
> information. No right to confidential or privileged treatment of this
> message is waived or lost by an error in transmission.
> If you have received this message in error, please immediately notify the
> sender by e-mail, delete the message, any attachments and all copies from
> your system and destroy any hard copies.  You must not, directly or
> indirectly, use, disclose, distribute, print or copy any part of this
> message or any attachments if you are not the intended recipient.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Oct  7 19:34:21 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 7 Oct 2016 10:34:21 -0700
Subject: [R] Error creating named character vectors from column names in
 data frame.
In-Reply-To: <CALdB+JF1+=_3X8K6fuXkyYs2mUBwyUm+U7kzaZFpTQpOiZCurw@mail.gmail.com>
References: <CALdB+JF1+=_3X8K6fuXkyYs2mUBwyUm+U7kzaZFpTQpOiZCurw@mail.gmail.com>
Message-ID: <CAGxFJbTeSJ9Pz4y-L2MvYeQhWNE-6L5CzJYahRHJtMNGKXuKGw@mail.gmail.com>

I think you have R semantics confused. What do you think

c("a" = "b")

means?

Note that:

> c("a" = "b")
  a
"b"
> a
Error: object 'a' not found


And of course:

class("a") # character
class("b") # character

but this has *nothing* to do with the line immediately above it.

Have you gone through any  basic R tutorials? There are many good ones
on the web.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Oct 7, 2016 at 9:06 AM, Jorge Cimentada <cimentadaj at gmail.com> wrote:
> Hi everyone,
>
> I was hoping someone would explain why this doesn't work.
>
> c("a" = "b") # named character vector
> class("a") # character
> class("b") # character
>
> c(names(mtcars)[1] = names(mtcars[2]) # error
> class(names(mtcars)[1]) # character
> class(names(mtcars)[2]) # character
>
>
> Thanks,
> Jorge Cimentada
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cimentadaj at gmail.com  Fri Oct  7 19:44:41 2016
From: cimentadaj at gmail.com (Jorge Cimentada)
Date: Fri, 7 Oct 2016 19:44:41 +0200
Subject: [R] Error creating named character vectors from column names in
 data frame.
In-Reply-To: <CAGxFJbTeSJ9Pz4y-L2MvYeQhWNE-6L5CzJYahRHJtMNGKXuKGw@mail.gmail.com>
References: <CALdB+JF1+=_3X8K6fuXkyYs2mUBwyUm+U7kzaZFpTQpOiZCurw@mail.gmail.com>
	<CAGxFJbTeSJ9Pz4y-L2MvYeQhWNE-6L5CzJYahRHJtMNGKXuKGw@mail.gmail.com>
Message-ID: <CALdB+JG8r2s3_aXi2+qosZZmqARUqG6-167sLac1-fOSPNOnqQ@mail.gmail.com>

Hi Bert,

Yes, I'm aware of the difference between a and "a" but in terms of object
classes I don't see the difference between "a" and names(mtcars)[1].
They're both strings. However, for creating a named character vector, this
works:

c("a" = "b)

But this doesn't

c(names(mtcars)[1] = "b")

For example:

df <- data.frame("a" = 1:5)
c("a" = "b")
c(names(df)[1] = "b") # error

But

identical(names(df)[1], "a")

That was my initial question.

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Fri Oct  7 20:24:00 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Fri, 7 Oct 2016 18:24:00 +0000
Subject: [R] prcomp(): How do I multiply two matrices
Message-ID: <1475864652131.76935@kent.ac.uk>

Dear R-users,

I am trying to do a principal components analysis using the attached data. My code looks as follows. I want to calculate the time series of the principal components (PC) . To this end, I transform the coefficients and the data into matrices and employ a matrix multiplication but it does not work.



data<-equityfunds[,-1]

PC<-prcomp(data)

coef1<-PC$rotation

data<-as.matrix(data)

PC1<-coef1 %*% data



This is the error message I get.

Error in coef1 %*% data : non-conformable arguments



So, what is wrong with my code? How do I multiply the coefficients with the observations?

From pdalgd at gmail.com  Fri Oct  7 20:42:05 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 7 Oct 2016 20:42:05 +0200
Subject: [R] prcomp(): How do I multiply two matrices
In-Reply-To: <1475864652131.76935@kent.ac.uk>
References: <1475864652131.76935@kent.ac.uk>
Message-ID: <E6E9996F-9AA1-44AE-BDC1-B2AE9B89545D@gmail.com>

You need to check your theory, and the dimensions of your data structures. Typically, data is (n x p) and your rotation matrix is (p x p) so pre-multiplying  by coef1 fits like a round peg in a square hole. Post-multiplying has a better chance, but I have long forgotten whether you need to transpose the rotation matrix first.

- Peter D.

> On 07 Oct 2016, at 20:24 , T.Riedle <tr206 at kent.ac.uk> wrote:
> 
> Dear R-users,
> 
> I am trying to do a principal components analysis using the attached data. My code looks as follows. I want to calculate the time series of the principal components (PC) . To this end, I transform the coefficients and the data into matrices and employ a matrix multiplication but it does not work.
> 
> 
> 
> data<-equityfunds[,-1]
> 
> PC<-prcomp(data)
> 
> coef1<-PC$rotation
> 
> data<-as.matrix(data)
> 
> PC1<-coef1 %*% data
> 
> 
> 
> This is the error message I get.
> 
> Error in coef1 %*% data : non-conformable arguments
> 
> 
> 
> So, what is wrong with my code? How do I multiply the coefficients with the observations?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Fri Oct  7 20:56:53 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 7 Oct 2016 14:56:53 -0400
Subject: [R] Error creating named character vectors from column names in
 data frame.
In-Reply-To: <CALdB+JG8r2s3_aXi2+qosZZmqARUqG6-167sLac1-fOSPNOnqQ@mail.gmail.com>
References: <CALdB+JF1+=_3X8K6fuXkyYs2mUBwyUm+U7kzaZFpTQpOiZCurw@mail.gmail.com>
	<CAGxFJbTeSJ9Pz4y-L2MvYeQhWNE-6L5CzJYahRHJtMNGKXuKGw@mail.gmail.com>
	<CALdB+JG8r2s3_aXi2+qosZZmqARUqG6-167sLac1-fOSPNOnqQ@mail.gmail.com>
Message-ID: <f92c58f0-0178-92bd-3798-e5a4c8c94e0c@gmail.com>

On 07/10/2016 1:44 PM, Jorge Cimentada wrote:
> Hi Bert,
>
> Yes, I'm aware of the difference between a and "a" but in terms of object
> classes I don't see the difference between "a" and names(mtcars)[1].
> They're both strings. However, for creating a named character vector, this
> works:
>
> c("a" = "b)
>
> But this doesn't
>
> c(names(mtcars)[1] = "b")
>
> For example:
>
> df <- data.frame("a" = 1:5)
> c("a" = "b")
> c(names(df)[1] = "b") # error
>
> But
>
> identical(names(df)[1], "a")
>
> That was my initial question.

It's a parser issue.  The parser is looking for a name before the equal 
sign; it finds a string literal, and just to be nice, treats it as a 
name.  But it never evaluates it as an expression; evaluation happens later.

The parser would be simpler (and apparently less confusing) if it just 
refused to accept "a" where a name is needed, but at the time this was 
written, there was no other way to express a name that was syntactically 
a name, e.g. "bad name".  Later the `bad name` notation was added, and 
it makes more sense to use that.

If you really want the result you expected, you can get it this way:

structure("b", names = names(df)[1])

Duncan Murdoch


From bogaso.christofer at gmail.com  Fri Oct  7 21:58:43 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sat, 8 Oct 2016 01:28:43 +0530
Subject: [R] gsub() could not replace my string
Message-ID: <CA+dpOJmB3XDLx5cAvcGibxSigeYmKdthjAxijurNtqE8yFPHvw@mail.gmail.com>

Hello again,

I have few many string elements, and some of those elements contain a
special phrase as '"[NA]NA%", which I planned to replace by some
Blank. So I tried with below code in R

> gsub("[NA]NA%", "", "[NA]NA%abcde")
[1] "[NA]NA%abcde"

It appears that, my code could not replace "[NA]NA%" as I wanted to
see "abcde". Can you please help me with what would be the correct
code for doing so.

Thanks in advance


From wdunlap at tibco.com  Fri Oct  7 22:10:45 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 7 Oct 2016 13:10:45 -0700
Subject: [R] gsub() could not replace my string
In-Reply-To: <CA+dpOJmB3XDLx5cAvcGibxSigeYmKdthjAxijurNtqE8yFPHvw@mail.gmail.com>
References: <CA+dpOJmB3XDLx5cAvcGibxSigeYmKdthjAxijurNtqE8yFPHvw@mail.gmail.com>
Message-ID: <CAF8bMcZkzz09mu5Hf=m7YFRfjz6RVv3vi0N_M53Q42Nu4D75qg@mail.gmail.com>

Either backslash the square brackets, as they have a special meaning
(character range) in regular expressions, or use the fixed=TRUE argument to
indicate that your pattern is not a regular expression.
> gsub("\\[NA\\]NA%", "", "[NA]NA%abcde")
[1] "abcde"
> gsub("[NA]NA%", "", "[NA]NA%abcde", fixed=TRUE)
[1] "abcde"

Your original code would replace ANA% or NNA% with a blank.
> gsub("[NA]NA%", "", c("NNA%abcde", "ANA%abcde"))
[1] "abcde" "abcde"




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Oct 7, 2016 at 12:58 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hello again,
>
> I have few many string elements, and some of those elements contain a
> special phrase as '"[NA]NA%", which I planned to replace by some
> Blank. So I tried with below code in R
>
> > gsub("[NA]NA%", "", "[NA]NA%abcde")
> [1] "[NA]NA%abcde"
>
> It appears that, my code could not replace "[NA]NA%" as I wanted to
> see "abcde". Can you please help me with what would be the correct
> code for doing so.
>
> Thanks in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Oct  8 00:26:43 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 7 Oct 2016 15:26:43 -0700
Subject: [R] Error creating named character vectors from column names in
	data frame.
In-Reply-To: <CALdB+JG8r2s3_aXi2+qosZZmqARUqG6-167sLac1-fOSPNOnqQ@mail.gmail.com>
References: <CALdB+JF1+=_3X8K6fuXkyYs2mUBwyUm+U7kzaZFpTQpOiZCurw@mail.gmail.com>
	<CAGxFJbTeSJ9Pz4y-L2MvYeQhWNE-6L5CzJYahRHJtMNGKXuKGw@mail.gmail.com>
	<CALdB+JG8r2s3_aXi2+qosZZmqARUqG6-167sLac1-fOSPNOnqQ@mail.gmail.com>
Message-ID: <A53DE1FF-0789-4CA3-B8A9-0BF6138C9525@comcast.net>


> On Oct 7, 2016, at 10:44 AM, Jorge Cimentada <cimentadaj at gmail.com> wrote:
> 
> Hi Bert,
> 
> Yes, I'm aware of the difference between a and "a" but in terms of object
> classes I don't see the difference between "a" and names(mtcars)[1].
> They're both strings.

They are not both "strings". One is a character value and the other is an expression that requires two different function evaluations. Inside the call to `c()`, the expressions on either side of an "="-sign are handled differently than they are outside a matching set of function parentheses. I _think_ they are parsed as 'alists', and teh which the ?alist page says the alist()-function does not evaluate the LHS of a pair being formed by the "="-operator. I was, however, not able to find descriptions of this in either The R Language Definition or R Internals.

I see Duncan has pointed out that "a" is converted to an R symbol/name as a "courtesy". There is some irony in the fact that the `names` function does not return R names, which are language objects with mode name.


-- 
David

> However, for creating a named character vector, this
> works:
> 
> c("a" = "b)
> 
> But this doesn't
> 
> c(names(mtcars)[1] = "b")

> For example:
> 
> df <- data.frame("a" = 1:5)
> c("a" = "b")
> c(names(df)[1] = "b") # error
> 
> But
> 
> identical(names(df)[1], "a")
> 

The `identical` function evaluates both its arguments.


> That was my initial question.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Sat Oct  8 03:25:40 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 8 Oct 2016 14:25:40 +1300
Subject: [R] Font problem --- SOLVED.
In-Reply-To: <CA+8X3fUX=HHWLRQpm0sJAjxPGqdZ9acg_LQU_9DyzuEkLg+Vyw@mail.gmail.com>
References: <26cd8676-bf91-bd21-9334-14047df2617f@auckland.ac.nz>
	<CA+8X3fUX=HHWLRQpm0sJAjxPGqdZ9acg_LQU_9DyzuEkLg+Vyw@mail.gmail.com>
Message-ID: <392fd216-7211-fbcc-3c8c-24b2300efae5@auckland.ac.nz>


> On Mon, Oct 3, 2016 at 7:55 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>> Dunno exactly whom I should ask about this problem, but I thought I'd start
>> with good old r-help.
>>
>> I have recently acquired a new laptop, and have installed Ubuntu 16.04 on
>> it.  Still having some teething problems.
>>
>> If I do
>>
>> plot(1:10,ylab=expression(italic(J(r)))
>>
>> I get the error:
>>
>> Error in title(...) :
>>   X11 font -*-courier-%s-%s-*-*-%d-*-*-*-*-*-*-*, face 5 at size 15 could
>> not be loaded
>>
>> So it would seem that I am missing a font.  Fonts have always been a
>> complete mystery to me.  Can anyone suggest how I might rectify this
>> deficiency in the fonts on my system?  If so, *please* be as explicit as you
>> can in your instructions; I am all at sea here.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> P. S.  I have also just noticed that if I do:
>>
>> plot(1:10,ylab=expression(alpha))
>>
>> I get an "a" as the y-axis label, rather than the Greek letter alpha.
>>
>> Likewise if I do plot(1:10,ylab=expression(Sigma)) I get a capital "S"
>> rather than an upper case Greek Sigma symbol.  No error thrown, but.
>>
>> Any ideas as to how to fix this problem?
>>
>> For what it's worth, here is my sessionInfo():
>>
>> R version 3.3.1 (2016-06-21)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 16.04.1 LTS
>>
>> locale:
>>  [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
>>  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
>>  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] misc_0.0-16
>>
>> loaded via a namespace (and not attached):
>>  [1] deldir_0.1-13       Matrix_1.2-3        mgcv_1.8-12
>>  [4] abind_1.4-3         spatstat_1.46-1.036 rpart_4.1-10
>>  [7] nlme_3.1-128        grid_3.3.1          polyclip_1.5-0
>> [10] lattice_0.20-33     goftest_1.0-3       tensor_1.5

Turns out that all I had to do was:

sudo apt-get install xfonts-100dpi
sudo-apt-get install xfonts-75dpi

I'd had to do something like this on my old Fedora-running laptop. 
Finally figured out the apt-get command analogous to the old yum 
command.  (Different package name(s); took me a while to find/figure out 
what the appropriate names are.  I'm *slow*!!!)

Thanks to everyone who tried to help me overcome my stupidity!

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From klebyn at yahoo.com.br  Sat Oct  8 04:15:21 2016
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Fri, 7 Oct 2016 23:15:21 -0300
Subject: [R] how to work ttkspinbox ?
Message-ID: <57c33fd4-7451-19d7-a533-5e4f48cf9e2a@yahoo.com.br>

hello all,

somebody have a example of use of  ttkspinbox ?
I tried to use like others widgets but I get error.

Thanks in advanced for any help

cleber

###################
 > library( tcltk )
 >
 > t <- tktoplevel()
 >
 > spin <- ttkspinbox( t )
Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
   [tcl] invalid command name "ttk::spinbox".
 >
 > combo <- ttkcombobox( t )
 > tkpack( combo )
<Tcl>
 >



---
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus


From tr206 at kent.ac.uk  Sat Oct  8 07:50:53 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sat, 8 Oct 2016 05:50:53 +0000
Subject: [R] Cannot install package write.xls
Message-ID: <1475905865933.33833@kent.ac.uk>

Dear R users,



I am trying to export my results to excel using write.xls or write.table but I cannot install the packages.



Instead, I get the message



Warning in install.packages :
  package 'write.table' is not available (for R version 3.3.1)





What can I do?

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Oct  8 08:14:12 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 07 Oct 2016 23:14:12 -0700
Subject: [R] Cannot install package write.xls
In-Reply-To: <1475905865933.33833@kent.ac.uk>
References: <1475905865933.33833@kent.ac.uk>
Message-ID: <1D698627-BAEB-4746-A5B7-353DE3FC9A5A@dcn.davis.ca.us>

I have never heard of a write.xls package. Try searching for it with Google... you might be misspelling it.

I have never heard of a write.table package either.  There is a write.table FUNCTION in base R with which you can create various text files that Excel can read.  Enter ?write.table at the R console.
-- 
Sent from my phone. Please excuse my brevity.

On October 7, 2016 10:50:53 PM PDT, "T.Riedle" <tr206 at kent.ac.uk> wrote:
>Dear R users,
>
>
>
>I am trying to export my results to excel using write.xls or
>write.table but I cannot install the packages.
>
>
>
>Instead, I get the message
>
>
>
>Warning in install.packages :
>  package 'write.table' is not available (for R version 3.3.1)
>
>
>
>
>
>What can I do?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From djnordlund at gmail.com  Sat Oct  8 08:18:19 2016
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Fri, 7 Oct 2016 23:18:19 -0700
Subject: [R] Cannot install package write.xls
In-Reply-To: <1475905865933.33833@kent.ac.uk>
References: <1475905865933.33833@kent.ac.uk>
Message-ID: <b05e1f83-992d-6c67-9ef3-03064bbf4b14@gmail.com>

On 10/7/2016 10:50 PM, T.Riedle wrote:
> Dear R users,
>
>
>
> I am trying to export my results to excel using write.xls or write.table but I cannot install the packages.
>
>
>
> Instead, I get the message
>
>
>
> Warning in install.packages :
>   package 'write.table' is not available (for R version 3.3.1)
>
>
>
>
>
> What can I do?
>

As far as I know, write.xls and write.table are not packages, they are 
functions. There is a write.xls function in the xlsx (and also the 
openxlsx) package and write.table is a built-in R function that exists 
in the util package.

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From bryanmac.24 at gmail.com  Sat Oct  8 09:40:39 2016
From: bryanmac.24 at gmail.com (Bryan Mac)
Date: Sat, 8 Oct 2016 00:40:39 -0700
Subject: [R] Least Median Square Regression
Message-ID: <444B7266-76A3-4E33-8218-000292E45091@gmail.com>

Hi R-help,

How do you perform least median square regression in R? Here is what I have but received no output. 

LMSRegression <- function(df, indices){
  sample <- df[indices, ]
  LMS_NAR_NIC_relation <- lm(sample$NAR~sample$NIC, data = sample, method = "lms")
  rsquared_lms_nar_nic <- summary(LMS_NAR_NIC_relation)$r.square
  
  LMS_SQRTNAR_SQRTNIC_relation <- lm(sample$SQRTNAR~sample$SQRTNIC, data = sample, method = "lms")
  rsquared_lms_sqrtnar_sqrtnic <- summary(LMS_SQRTNAR_SQRTNIC_relation)$r.square
  
  out <- c(rsquared_lms_nar_nic, rsquared_lms_sqrtnar_sqrtnic)
  return(out)
}
 
Also, which value should be looked at decide whether this is best regression model to use?

Bryan Mac
bryanmac.24 at gmail.com




	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sat Oct  8 11:33:24 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Sat, 08 Oct 2016 10:33:24 +0100
Subject: [R] Least Median Square Regression
In-Reply-To: <444B7266-76A3-4E33-8218-000292E45091@gmail.com>
Message-ID: <20161008103324.Horde.RmwU0p8tTNDBLRQY4cKE4kf@mail.sapo.pt>

Hello,


Use package quantreg, function rq().

install.packages("quantreg")
?rq

Hope this helps,

Rui Barradas

Citando Bryan Mac <bryanmac.24 at gmail.com>:

> Hi R-help,
>
> How do you perform least median square regression in R? Here is what  
> I have but received no output.
>
> LMSRegression <- function(df, indices){
>   sample <- df[indices, ]
>   LMS_NAR_NIC_relation <- lm(sample$NAR~sample$NIC, data = sample,  
> method = "lms")
>   rsquared_lms_nar_nic <- summary(LMS_NAR_NIC_relation)$r.square
>
>   LMS_SQRTNAR_SQRTNIC_relation <- lm(sample$SQRTNAR~sample$SQRTNIC,  
> data = sample, method = "lms")
>   rsquared_lms_sqrtnar_sqrtnic <-  
> summary(LMS_SQRTNAR_SQRTNIC_relation)$r.square
>
>   out <- c(rsquared_lms_nar_nic, rsquared_lms_sqrtnar_sqrtnic)
>   return(out)
> }
>
> Also, which value should be looked at decide whether this is best  
> regression model to use?
>
> Bryan Mac
> bryanmac.24 at gmail.com
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Oct  8 12:05:25 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 8 Oct 2016 21:05:25 +1100
Subject: [R] date comparison doesn't match value
In-Reply-To: <CA+8X3fUN0Y35+RPCBhrU_h52cRTaPQxhSXfKAScZGExDSR+0qA@mail.gmail.com>
References: <BLUPR09MB089862605DCE8F4E64B12F47E1C60@BLUPR09MB0898.namprd09.prod.outlook.com>
	<CA+8X3fUN0Y35+RPCBhrU_h52cRTaPQxhSXfKAScZGExDSR+0qA@mail.gmail.com>
Message-ID: <CA+8X3fX8OsqTrw_LRsRH+uwC7qG0z2VBH=9Fg1Q7=ygRrETDrA@mail.gmail.com>

Hi Heather,
I think the problem may be that you are trying to compare a date field
and a character string. R helpfully tries to wrangle the two into
comparable data types. While I don't know exactly what you have done,
as R for:

as.numeric(alldata$new.date.local)

and look at the value you get.

Jim


From ranjanagirish30 at gmail.com  Sat Oct  8 13:19:44 2016
From: ranjanagirish30 at gmail.com (Ranjana Girish)
Date: Sat, 8 Oct 2016 16:49:44 +0530
Subject: [R] In SOM package all entities are predicted to the same class
Message-ID: <CAF5P65nuZV7SmaEeURsAFZYamgrHGHokc5hf0GupXZE=utPERw@mail.gmail.com>

From: "Ranjana Girish" <ranjanagirish30 at gmail.com>
Date: Oct 7, 2016 3:14 PM
Subject: help:In SOM package all entities are predicted to the same class
Cc: <r-help-request at r-project.org>

Hi All,,,

Every-time when i run the below code it is predicting the same class for
all the test cases.So i have added few more parameters while forming the
grid, but it still predicting the same result.
>
> Can somebody please help me to resolve this issue.
>
> library(kohonen)
> library(tm)
> library(qdap)
> library(SnowballC)
> dataSet <- read.csv("E:/TempDataSetWithAttributes.csv", header = TRUE)
> head(dataSet)
> ##   **nItemId**                **sUnSpsc**
> ## 1 7440421 26121609 Network cable
> ## 2 7440442 26121609 Network cable
> ## 3 7440522 26121609 Network cable
> ## 4 7440623 26121609 Network cable
> ## 5 7460893 26121609 Network cable
> ## 6 7462277 26121609 Network cable
>
##
**ProductDesctiption**
> ## 1 Copper cable, category 6A F/FTP, low smoke zero halogen (LSZH),
4-pair, conductors are 23 AWG with PE insulation, twisted in pairs, wrapped
in foil, surrounded by an overall metallic foil shield and protected by a
low smoke, flame retardant LSZH jacket, w
> ## 2 Category 6A, Low Smoke Zero Halogen (LSZH), 4-pair, F/FTP copper
cable. Copper conductors are 23 AWG with PE insulation. Conductors are
twisted in pairs, wrapped in foil, surrounded by an overall metallic foil
shield and protected by a low smoke, flame re
> ## 3 Category 6A, Low Smoke Zero Halogen (LSZH), 4-pair, F/FTP copper
cable. Copper conductors are 23 AWG with PE insulation. Conductors are
twisted in pairs, wrapped in foil, surrounded by an overall metallic foil
shield and protected by a low smoke, flame re
> ## 4 Category 6A, Low Smoke Zero Halogen (LSZH), 4-pair, F/FTP copper
cable. Copper conductors are 23 AWG with PE insulation. Conductors are
twisted in pairs, wrapped in foil, surrounded by an overall metallic foil
shield and protected by a low smoke, flame re
> ## 5                                Category 6A 4-pair, 23 AWG U/UTP
copper cable, LSZH (IEC60332-1), blue.|Length: 1000 FT|Construction: LSZH
PVC|Color: Blue|Number Of Pins: 4|Brand Name: Panduit|Outside Diameter:
0.285 IN|Type: NetKey Cable|Sub Brand: NetKey
> ## 6 Shielded marine MUD-resistant copper cable, category 7 S/FTP, low
smoke zero halogen (LSZH), 4-pair, conductors are 22 AWG construction with
foamed PE insulation, twisted in pairs, each surrounded by a foil, covered
with an overall braided shield, within
>
> **CREATING CORPUS**
> documents <- Corpus(VectorSource(dataSet$ProductDesctiption))
>
> **PRE-PROCESSING**
> documents <- tm_map(documents, content_transformer(tolower),lazy=TRUE)
> documents <- tm_map(documents, removePunctuation,lazy=TRUE)
> documents <- tm_map(documents, stripWhitespace,lazy=TRUE)
> documents <- tm_map(documents, removeNumbers,lazy=TRUE)
> documents <- tm_map(documents, stripWhitespace,lazy=TRUE)
> documents <- tm_map(documents, removeWords,
stopwords("english"),lazy=TRUE)
> documents <- tm_map(documents, stripWhitespace,lazy=TRUE)
> documents <- tm_map(documents, stemDocument, language =
"english",lazy=TRUE)
> documents <- tm_map(documents, stripWhitespace,lazy=TRUE)
>
> **CREATION OF DOCUMENT-TERM MATRIX**
> documentTermMatrix <- DocumentTermMatrix(documents)
>
>
> **Create Data Matrix**
> documentTermMatrixFrame <- data.matrix(documentTermMatrix)
> head(documentTermMatrixFrame[40,])
> ##         aaa        abov         abs    absbrand absmounting
accept
> ##           0           0           0           0           0           0
>
>
> **Create Training set**
> training <- sample(nrow(documentTermMatrixFrame), 750)
> Scaling of Document term Matrix
>
> Scaledtraining <- scale(documentTermMatrixFrame[training,])
> ScaledNonNAtraining <- Scaledtraining[, colSums(is.na(Scaledtraining)) !=
nrow(Scaledtraining)]
> UnSupervised learning using Self Organizing maps
>
> som.wines <- som(ScaledNonNAtraining, grid = somgrid(5, 5, "rectangular"))
> Scaling of Test Set
>
> Xtest <- scale(documentTermMatrixFrame[-training,])
> ScaledXtest <- Xtest[, colSums(is.na(Xtest)) != nrow(Xtest)]
>
>
> x<- dataSet$sUnSpsc
> y<- dataSet$nItemId
>
> **Prediction using SOM trained model**
> som.prediction <- predict(som.wines, newdata =
ScaledXtest,trainY=as.factor(x[training]))
>
> som.prediction$unit.classif
> ##   [1]  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5
5  5
> ##  [24]  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5
5  5
> ##  [47]  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5
5  5
> ##  [70]  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5
5 25
> ##  [93]  ## Heading ##5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5
5  5  5  5  5  5
> ## [116]  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5
5  5
> ## [139]  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5
5  5
> ## [162]  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5
5  5
> ## [185]  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5
5  5
> ## [208]  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5
5  5
> ## [231]  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5
> **Accuracy calculation**
> confusion.mat <- (table("Predictions" = som.prediction$unit.classif,
Actual = x[-training]))
> resultinmatrix<- as.data.frame.array(confusion.mat)
> accuracy <- sum(diag(confusion.mat))/nrow(Xtest) * 100
> accuracy

	[[alternative HTML version deleted]]


From ranjanagirish30 at gmail.com  Sat Oct  8 13:23:43 2016
From: ranjanagirish30 at gmail.com (Ranjana Girish)
Date: Sat, 8 Oct 2016 16:53:43 +0530
Subject: [R] In SOM package all entities are predicted to the same class
In-Reply-To: <CAF5P65kEitDbwe1q0U1=WJoQXzDgD5_Z-N89k_RvD2PgFfGk9g@mail.gmail.com>
References: <CAF5P65kEitDbwe1q0U1=WJoQXzDgD5_Z-N89k_RvD2PgFfGk9g@mail.gmail.com>
Message-ID: <CAF5P65kKFNdm0MUnxW94+cB-6AvZQ1RnKpnzBdACY1U3fmUxeQ@mail.gmail.com>

From: "Ranjana Girish" <ranjanagirish30 at gmail.com>
Date: Oct 7, 2016 3:39 PM
Subject: Re:In SOM package all entities are predicted to the same class

Cc: <r-help at r-project.org>

> Even after trying with different parameters of SOM still all entities are
getting predicted to same class..
>
> Note: for each run, class are different because nrow considers train set
each time randomly.
>
> 1)som.prediction$unit.classif
> som.wines <- som(ScaledNonNAtraining, grid = somgrid(5, 5, "hexagonal"))
> [1]  4  4  4  4 23  4  4  4  4  4  4  4  4  4  4  4 21  4  4  4  4  4  4
 4  4  4  4  4  4  4
> [31]  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4
 4  4  4  4  4  4  4
> [61]  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4
 4  4  4  4  4  4  4
> [91]  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4
 4  4  4  4  4  4  4
> [121]  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4
 4  4  4  4  4  4  4  4
> [151]  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4
 4  4  4  4  4  4  4  4
> [181]  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4
 4  4  4  4  4  4  4  4
> [211]  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4
 4  4  4  4  4  4  4  4
> [241]  4  4  4  4  4  4  4  4  4
> Accuracy 2.811245
>
> 2)som.wines <- som(ScaledNonNAtraining, grid = somgrid(5, 5,
"rectangular")) som.prediction$unit.classif [1] 15 15 15 15 15 15 15 15 15
15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15
[35] 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 2 15 15 15 15
15 15 15 15 15 15 15 15 15 15 [69] 15 15 15 15 15 15 15 15 15 15 15 15 15
15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 [103] 15 15
15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15
15 15 15 15 15 15 15 [137] 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15
15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 1 15 [171] 15 15 15 15 15
15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 2 25 25 15 15 15 15 15
15 15 15 15 [205] 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 2 15 15 15
15 15 15 15 15 2 15 15 15 15 15 15 15 15 15 [239] 15 15 15 15 15 15 15 15
15 15 15 accuracy [1] 1.204819
>
> 3)som.wines <- som(ScaledNonNAtraining, grid = somgrid(5, 5,
"rectangular"), rlen = 5000) som.prediction$unit.classif [1] 25 25 25 25 25
25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
25 25 25 25 [35] 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 [69] 25 25 25 25 25 25 25 25
25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
25 [103] 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25
25 25 25 25 25 25 25 25 25 25 25 25 [137] 25 25 25 25 25 25 25 25 25 25 25
25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 [171]
25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 4 25 25
25 25 25 25 25 25 25 25 25 [205] 25 25 25 25 25 25 25 25 25 25 25 25 25 25
25 4 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 [239] 25 25 25
25 25 25 25 25 25 25 25 accuracy [1] 0
>
> 4)om.wines <- som(ScaledNonNAtraining, grid = somgrid(5, 5,
"rectangular"), alpha = 0.15, rlen = 5000) som.prediction$unit.classif [1]
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 [52] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 [103] 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 [154] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 [205] 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>
>

	[[alternative HTML version deleted]]


From c.puschmann at student.unsw.edu.au  Fri Oct  7 22:22:59 2016
From: c.puschmann at student.unsw.edu.au (Christoph Puschmann)
Date: Fri, 7 Oct 2016 20:22:59 +0000
Subject: [R] Loop to check for large dataset
Message-ID: <4FCBB54C-C002-43DE-ABA3-BBCD01F24DE9@ad.unsw.edu.au>

Hey all,

I would like to know if anyone, can put in the right direction of the following problem:

I am currently want to use it to check if a column with a length of 61327 is consistent over an 1 to 157 interval until the end of the column. In the case the interval is interrupted I want to know which values are missing and where the missing values are located. I started of with the following code to assign 1s, if we have a number ? 157 and 0 if not.



I tried to do a double loop:



    n=61327
    Control = matrix(
    0,
    nrow = n,
    ncol = 1)



    for (i in length(FD$WEEK)) {
    for (j in 1:157) {
    if(FD$WEEK[j] <=  157) {
      Control[,1] = 1
    } else {
      Control[,1] = 0
      }
    }
    }



I believe that this code is not correct, but I am unable to wrap my head around how I can check that the interval always will be followed.

All the best,

Christoph


	[[alternative HTML version deleted]]


From sstoline at gmail.com  Sat Oct  8 00:56:10 2016
From: sstoline at gmail.com (Steven Stoline)
Date: Fri, 7 Oct 2016 18:56:10 -0400
Subject: [R] =?utf-8?b?4oCcbG9nLXJhbmsgdGVzdOKAnSBhbmQg4oCcS2FwbGFuIE1l?=
	=?utf-8?q?ier_actuarial_plots_=28time_to_event_curve=29=E2=80=9D?=
Message-ID: <CAHDp66D2TCRKPDHafC6iTsvRLQ9fJvdTdq0GkU8Wteh5edBvRQ@mail.gmail.com>

Dear All:



I do need your help with the ?log-rank test? and ?Kaplan Meier actuarial
plots (time to event curve)? with adding the confidence intervals bands for
the average score for each time to the curve of each group.


*Group variable:* 1 = group 1, 2 = group 2


*Time points:* time1, time2, time3, time4, time5


The goal is to compare the average scores of the two groups at each time
point and obtain the Kaplan Meier actuarial plots (time to event curve) for
the 5 time points for both groups in the plot.



Please use the following data for the test.


time1    time2    time3    time4    time5    groups

0              0              1              1              1              1

0              4              0              1              1              1

0              0              3              1              1              1

0              2              0              1              1              1

0              0              3              0              0              1

0              0              0              1              2              1

0              1              1              1
1

0              0              2              1              1              1

0              3              1              1              1              1

0              0              0              1
1

0              0              1              0              0              1

0              0              0              1              1              1

0              1              1              0              1              1

0              0              1              3              4              1

0              1              0              0              0              1

0              1              1              1              2              1

0              1              1              4              1              1

0              0              0              0
1

0              2              1              1              2              1


2

0              0              0              0              0              2


2

0
2

0              0              3              2              2              2

0              3              0              1              1              2

0              0              1              1              1              2

0
2

0              0              0              1              1              2

0              1              2              0              1              2

0              0              1              1
2

0              0              1              1              2              2

0              1              1              1              1              2

0              0              0              1              1              2

0              0              1              1              1              2


2

0              2              2              1
2

0              0              1              1
2

0              0              0              0              0              2

0              3              3              1              2              2

0              1              1              1
2

0              0              0              1              1              2

0              1              1              1              4              2

0              1              1              1              1              2

0              1              2              1              3              2





Thank you in advance

steve


-------------------------
Steven M. Stoline
sstoline at gmail.com

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sat Oct  8 14:32:25 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Sat, 08 Oct 2016 13:32:25 +0100
Subject: [R] Loop to check for large dataset
In-Reply-To: <4FCBB54C-C002-43DE-ABA3-BBCD01F24DE9@ad.unsw.edu.au>
Message-ID: <20161008133225.Horde.RL7gFMt7kEUZ0kVlNpTgYuZ@mail.sapo.pt>

Hello,

I'm not at all sure if the following is what you need but instead of

for (i in length(FD$WEEK))

try

for (i in 1:length(FD$WEEK))

or even better

for (i in seq_len(FD$WEEK))

And use Control[i, 1], not Control[, 1]

Hope thi helps,

Rui Barradas





Citando Christoph Puschmann <c.puschmann at student.unsw.edu.au>:

> Hey all,
>
> I would like to know if anyone, can put in the right direction of  
> the following problem:
>
> I am currently want to use it to check if a column with a length of  
> 61327 is consistent over an 1 to 157 interval until the end of the  
> column. In the case the interval is interrupted I want to know which  
> values are missing and where the missing values are located. I  
> started of with the following code to assign 1s, if we have a number  
> ? 157 and 0 if not.
>
>
>
> I tried to do a double loop:
>
>
>
>     n=61327
>     Control = matrix(
>     0,
>     nrow = n,
>     ncol = 1)
>
>
>
>     for (i in length(FD$WEEK)) {
>     for (j in 1:157) {
>     if(FD$WEEK[j] <=  157) {
>       Control[,1] = 1
>     } else {
>       Control[,1] = 0
>       }
>     }
>     }
>
>
>
> I believe that this code is not correct, but I am unable to wrap my  
> head around how I can check that the interval always will be followed.
>
> All the best,
>
> Christoph
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dusa.adrian at unibuc.ro  Sat Oct  8 14:32:34 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Sat, 8 Oct 2016 15:32:34 +0300
Subject: [R] Loop to check for large dataset
In-Reply-To: <4FCBB54C-C002-43DE-ABA3-BBCD01F24DE9@ad.unsw.edu.au>
References: <4FCBB54C-C002-43DE-ABA3-BBCD01F24DE9@ad.unsw.edu.au>
Message-ID: <CAJ=0CtBK6MnmmJ4EzVei=G4Yzj_kCRctMke-mF7xAc-cgNYWBw@mail.gmail.com>

It would help to have a minimal, reproducible example.
Unless revealing the structure of your FD object, it is difficult to
understand how a column having 61327 values would be "consistent over an 1
to 157 interval": is this interval cyclic until it reaches 61327 values?

>From your example using FD$WEEK, you are using a column called WEEK within
a dataframe names FD, and you only loop over the first 157 values of that
column. So where is the "column having 61327 values"?

For these types of problems you don't even need a loop, R is a vectorised
language (please note that you have a double loop but never use the "i"
one).

Very unclear, so please try to create a MRE, as the posting guide advices.


On Fri, Oct 7, 2016 at 11:22 PM, Christoph Puschmann <
c.puschmann at student.unsw.edu.au> wrote:

> Hey all,
>
> I would like to know if anyone, can put in the right direction of the
> following problem:
>
> I am currently want to use it to check if a column with a length of 61327
> is consistent over an 1 to 157 interval until the end of the column. In the
> case the interval is interrupted I want to know which values are missing
> and where the missing values are located. I started of with the following
> code to assign 1s, if we have a number ? 157 and 0 if not.
>
>
>
> I tried to do a double loop:
>
>
>
>     n=61327
>     Control = matrix(
>     0,
>     nrow = n,
>     ncol = 1)
>
>
>
>     for (i in length(FD$WEEK)) {
>     for (j in 1:157) {
>     if(FD$WEEK[j] <=  157) {
>       Control[,1] = 1
>     } else {
>       Control[,1] = 0
>       }
>     }
>     }
>
>
>
> I believe that this code is not correct, but I am unable to wrap my head
> around how I can check that the interval always will be followed.
>
> All the best,
>
> Christoph
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From es at enricoschumann.net  Sat Oct  8 15:17:09 2016
From: es at enricoschumann.net (Enrico Schumann)
Date: Sat, 08 Oct 2016 15:17:09 +0200
Subject: [R] Least Median Square Regression
In-Reply-To: <444B7266-76A3-4E33-8218-000292E45091@gmail.com> (Bryan Mac's
	message of "Sat, 8 Oct 2016 00:40:39 -0700")
References: <444B7266-76A3-4E33-8218-000292E45091@gmail.com>
Message-ID: <87k2djyo8a.fsf@enricoschumann.net>

On Sat, 08 Oct 2016, Bryan Mac <bryanmac.24 at gmail.com> writes:

> Hi R-help,
>
> How do you perform least median square regression in R? Here is what I have but received no output. 
>
> LMSRegression <- function(df, indices){
>   sample <- df[indices, ]
>   LMS_NAR_NIC_relation <- lm(sample$NAR~sample$NIC, data = sample, method = "lms")
>   rsquared_lms_nar_nic <- summary(LMS_NAR_NIC_relation)$r.square
>   
>   LMS_SQRTNAR_SQRTNIC_relation <- lm(sample$SQRTNAR~sample$SQRTNIC, data = sample, method = "lms")
>   rsquared_lms_sqrtnar_sqrtnic <- summary(LMS_SQRTNAR_SQRTNIC_relation)$r.square
>   
>   out <- c(rsquared_lms_nar_nic, rsquared_lms_sqrtnar_sqrtnic)
>   return(out)
> }
>  
> Also, which value should be looked at decide whether this is best regression model to use?
>
> Bryan Mac
> bryanmac.24 at gmail.com
>

A tutorial on how to run such regressions is included
in the NMOF package.

https://cran.r-project.org/package=NMOF/vignettes/PSlms.pdf


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From marc_grt at yahoo.fr  Sat Oct  8 18:50:11 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Sat, 8 Oct 2016 18:50:11 +0200
Subject: [R] bquote in list to be used with do.plot()
Message-ID: <630b98da-4338-89d3-b8f9-13d286c39f1e@yahoo.fr>

Dear members,

Has someone have a solution to include a bquote() statement in a list to 
be used with do.call() ?

Here is an exemple:
     scaleY <- 10000
     plot(x=1, y=1, ylab=bquote(.(format(scaleY), scientific=FALSE)^"-1"))

Like that, it works.

Now he same in a list:
     L <- list(x=1, y=1, ylab=bquote(.(format(scaleY), 
scientific=FALSE)^"-1"))
     do.call(plot, L)
         Error in "10000"^"-1" : argument non num?rique pour un 
op?rateur binaire

It produces an error.

Any solution?

(I tries also with substitute() and expression() but I fail also)

Thanks

Marc


From murdoch.duncan at gmail.com  Sat Oct  8 19:11:29 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 8 Oct 2016 13:11:29 -0400
Subject: [R] bquote in list to be used with do.plot()
In-Reply-To: <630b98da-4338-89d3-b8f9-13d286c39f1e@yahoo.fr>
References: <630b98da-4338-89d3-b8f9-13d286c39f1e@yahoo.fr>
Message-ID: <d7203d1d-e91c-739f-d056-5a051ce09207@gmail.com>

On 08/10/2016 12:50 PM, Marc Girondot via R-help wrote:
> Dear members,
>
> Has someone have a solution to include a bquote() statement in a list to
> be used with do.call() ?
>
> Here is an exemple:
>      scaleY <- 10000
>      plot(x=1, y=1, ylab=bquote(.(format(scaleY), scientific=FALSE)^"-1"))
>
> Like that, it works.
>
> Now he same in a list:
>      L <- list(x=1, y=1, ylab=bquote(.(format(scaleY),
> scientific=FALSE)^"-1"))
>      do.call(plot, L)
>          Error in "10000"^"-1" : argument non num?rique pour un
> op?rateur binaire
>
> It produces an error.
>
> Any solution?
>
> (I tries also with substitute() and expression() but I fail also)

This seems to work:

L <- list(x=1, y=1, ylab=bquote(expression(.(format(scaleY),
           scientific=FALSE)^"-1")))
do.call(plot, L)

Duncan Murdoch


From bgunter.4567 at gmail.com  Sat Oct  8 20:39:44 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 8 Oct 2016 11:39:44 -0700
Subject: [R] bquote in list to be used with do.plot()
In-Reply-To: <d7203d1d-e91c-739f-d056-5a051ce09207@gmail.com>
References: <630b98da-4338-89d3-b8f9-13d286c39f1e@yahoo.fr>
	<d7203d1d-e91c-739f-d056-5a051ce09207@gmail.com>
Message-ID: <CAGxFJbTfZZNEf-F3vOJQfVAnqKry=mVTO4_rZE9kcZsZqovGxA@mail.gmail.com>

I think there's an error here, although it doesn't affect the result.
It should be:

L <- list(x=1, y=1,
ylab=bquote(expression(.(format(scaleY,
                                             scientific=FALSE)^"-1"))))
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Oct 8, 2016 at 10:11 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 08/10/2016 12:50 PM, Marc Girondot via R-help wrote:
>>
>> Dear members,
>>
>> Has someone have a solution to include a bquote() statement in a list to
>> be used with do.call() ?
>>
>> Here is an exemple:
>>      scaleY <- 10000
>>      plot(x=1, y=1, ylab=bquote(.(format(scaleY), scientific=FALSE)^"-1"))
>>
>> Like that, it works.
>>
>> Now he same in a list:
>>      L <- list(x=1, y=1, ylab=bquote(.(format(scaleY),
>> scientific=FALSE)^"-1"))
>>      do.call(plot, L)
>>          Error in "10000"^"-1" : argument non num?rique pour un
>> op?rateur binaire
>>
>> It produces an error.
>>
>> Any solution?
>>
>> (I tries also with substitute() and expression() but I fail also)
>
>
> This seems to work:
>
> L <- list(x=1, y=1, ylab=bquote(expression(.(format(scaleY),
>           scientific=FALSE)^"-1")))
> do.call(plot, L)
>
> Duncan Murdoch
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Oct  8 20:43:34 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 8 Oct 2016 11:43:34 -0700
Subject: [R] bquote in list to be used with do.plot()
In-Reply-To: <CAGxFJbTfZZNEf-F3vOJQfVAnqKry=mVTO4_rZE9kcZsZqovGxA@mail.gmail.com>
References: <630b98da-4338-89d3-b8f9-13d286c39f1e@yahoo.fr>
	<d7203d1d-e91c-739f-d056-5a051ce09207@gmail.com>
	<CAGxFJbTfZZNEf-F3vOJQfVAnqKry=mVTO4_rZE9kcZsZqovGxA@mail.gmail.com>
Message-ID: <CAGxFJbRsw49roC_EUPgpC2XkBm8-6he2WR-twnBrV25-y6bAhw@mail.gmail.com>

(Sent too early by mistake)

... and I find that this a bit more transparent:

L <- list(x=1,y=1, ylab = bquote( expression(.(z)^-1),
                          where=list(z = format(scaleY, scientific=FALSE))))


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Oct 8, 2016 at 11:39 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> I think there's an error here, although it doesn't affect the result.
> It should be:
>
> L <- list(x=1, y=1,
> ylab=bquote(expression(.(format(scaleY,
>                                              scientific=FALSE)^"-1"))))
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Oct 8, 2016 at 10:11 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 08/10/2016 12:50 PM, Marc Girondot via R-help wrote:
>>>
>>> Dear members,
>>>
>>> Has someone have a solution to include a bquote() statement in a list to
>>> be used with do.call() ?
>>>
>>> Here is an exemple:
>>>      scaleY <- 10000
>>>      plot(x=1, y=1, ylab=bquote(.(format(scaleY), scientific=FALSE)^"-1"))
>>>
>>> Like that, it works.
>>>
>>> Now he same in a list:
>>>      L <- list(x=1, y=1, ylab=bquote(.(format(scaleY),
>>> scientific=FALSE)^"-1"))
>>>      do.call(plot, L)
>>>          Error in "10000"^"-1" : argument non num?rique pour un
>>> op?rateur binaire
>>>
>>> It produces an error.
>>>
>>> Any solution?
>>>
>>> (I tries also with substitute() and expression() but I fail also)
>>
>>
>> This seems to work:
>>
>> L <- list(x=1, y=1, ylab=bquote(expression(.(format(scaleY),
>>           scientific=FALSE)^"-1")))
>> do.call(plot, L)
>>
>> Duncan Murdoch
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bryanmac.24 at gmail.com  Sat Oct  8 22:10:10 2016
From: bryanmac.24 at gmail.com (Bryan Mac)
Date: Sat, 8 Oct 2016 13:10:10 -0700
Subject: [R] Least Median Square Regression
In-Reply-To: <87k2djyo8a.fsf@enricoschumann.net>
References: <444B7266-76A3-4E33-8218-000292E45091@gmail.com>
	<87k2djyo8a.fsf@enricoschumann.net>
Message-ID: <18D428D5-83C5-43EE-BEFF-13C08F01008B@gmail.com>

I am confused reading the document. 

I have installed and added the package (MASS).

What is the function for LMS Regression?


Bryan Mac
bryanmac.24 at gmail.com



> On Oct 8, 2016, at 6:17 AM, Enrico Schumann <es at enricoschumann.net> wrote:
> 
> On Sat, 08 Oct 2016, Bryan Mac <bryanmac.24 at gmail.com> writes:
> 
>> Hi R-help,
>> 
>> How do you perform least median square regression in R? Here is what I have but received no output. 
>> 
>> LMSRegression <- function(df, indices){
>>  sample <- df[indices, ]
>>  LMS_NAR_NIC_relation <- lm(sample$NAR~sample$NIC, data = sample, method = "lms")
>>  rsquared_lms_nar_nic <- summary(LMS_NAR_NIC_relation)$r.square
>> 
>>  LMS_SQRTNAR_SQRTNIC_relation <- lm(sample$SQRTNAR~sample$SQRTNIC, data = sample, method = "lms")
>>  rsquared_lms_sqrtnar_sqrtnic <- summary(LMS_SQRTNAR_SQRTNIC_relation)$r.square
>> 
>>  out <- c(rsquared_lms_nar_nic, rsquared_lms_sqrtnar_sqrtnic)
>>  return(out)
>> }
>> 
>> Also, which value should be looked at decide whether this is best regression model to use?
>> 
>> Bryan Mac
>> bryanmac.24 at gmail.com
>> 
> 
> A tutorial on how to run such regressions is included
> in the NMOF package.
> 
> https://cran.r-project.org/package=NMOF/vignettes/PSlms.pdf
> 
> 
> -- 
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net


From bgunter.4567 at gmail.com  Sat Oct  8 22:36:38 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 8 Oct 2016 13:36:38 -0700
Subject: [R] Least Median Square Regression
In-Reply-To: <18D428D5-83C5-43EE-BEFF-13C08F01008B@gmail.com>
References: <444B7266-76A3-4E33-8218-000292E45091@gmail.com>
	<87k2djyo8a.fsf@enricoschumann.net>
	<18D428D5-83C5-43EE-BEFF-13C08F01008B@gmail.com>
Message-ID: <CAGxFJbRuOHPJ4Q6=rNP2QzD4E-wpUZ64jMQkLq1Fq9PdoU=+Gw@mail.gmail.com>

Well, first of all, note that there is no "lms" method for the stats
package's lm() function. You can't just make stuff up, you know!

And second, ?lmsreg -- after loading MASS via library(MASS), if you
haven't already done this after your install --  is what you want.
Other than ?lmsreg and what Enrico pointed you to, however, you'll
have to manage on your own. Statistical tutorials are not the remit of
this list. You might wish to consult with someone locally for help.
You may be able to get an answer to a post of a specific question
about usage **if you post code that fails** and otherwise follow the
posting guide (below).

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Oct 8, 2016 at 1:10 PM, Bryan Mac <bryanmac.24 at gmail.com> wrote:
> I am confused reading the document.
>
> I have installed and added the package (MASS).
>
> What is the function for LMS Regression?
>
>
> Bryan Mac
> bryanmac.24 at gmail.com
>
>
>
>> On Oct 8, 2016, at 6:17 AM, Enrico Schumann <es at enricoschumann.net> wrote:
>>
>> On Sat, 08 Oct 2016, Bryan Mac <bryanmac.24 at gmail.com> writes:
>>
>>> Hi R-help,
>>>
>>> How do you perform least median square regression in R? Here is what I have but received no output.
>>>
>>> LMSRegression <- function(df, indices){
>>>  sample <- df[indices, ]
>>>  LMS_NAR_NIC_relation <- lm(sample$NAR~sample$NIC, data = sample, method = "lms")
>>>  rsquared_lms_nar_nic <- summary(LMS_NAR_NIC_relation)$r.square
>>>
>>>  LMS_SQRTNAR_SQRTNIC_relation <- lm(sample$SQRTNAR~sample$SQRTNIC, data = sample, method = "lms")
>>>  rsquared_lms_sqrtnar_sqrtnic <- summary(LMS_SQRTNAR_SQRTNIC_relation)$r.square
>>>
>>>  out <- c(rsquared_lms_nar_nic, rsquared_lms_sqrtnar_sqrtnic)
>>>  return(out)
>>> }
>>>
>>> Also, which value should be looked at decide whether this is best regression model to use?
>>>
>>> Bryan Mac
>>> bryanmac.24 at gmail.com
>>>
>>
>> A tutorial on how to run such regressions is included
>> in the NMOF package.
>>
>> https://cran.r-project.org/package=NMOF/vignettes/PSlms.pdf
>>
>>
>> --
>> Enrico Schumann
>> Lucerne, Switzerland
>> http://enricoschumann.net
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From es at enricoschumann.net  Sat Oct  8 22:43:01 2016
From: es at enricoschumann.net (Enrico Schumann)
Date: Sat, 08 Oct 2016 22:43:01 +0200
Subject: [R] Least Median Square Regression
In-Reply-To: <18D428D5-83C5-43EE-BEFF-13C08F01008B@gmail.com> (Bryan Mac's
	message of "Sat, 8 Oct 2016 13:10:10 -0700")
References: <444B7266-76A3-4E33-8218-000292E45091@gmail.com>
	<87k2djyo8a.fsf@enricoschumann.net>
	<18D428D5-83C5-43EE-BEFF-13C08F01008B@gmail.com>
Message-ID: <87a8ee8td6.fsf@enricoschumann.net>

On Sat, 08 Oct 2016, Bryan Mac <bryanmac.24 at gmail.com> writes:

> I am confused reading the document. 
>
> I have installed and added the package (MASS).
>
> What is the function for LMS Regression?
>

In MASS, it is 'lqs'.

But the vignette provides a code example for how to
compute 'manually' an LMS-regression, i.e. how to do
the actual optimisation.

>
>> On Oct 8, 2016, at 6:17 AM, Enrico Schumann <es at enricoschumann.net> wrote:
>> 
>> On Sat, 08 Oct 2016, Bryan Mac <bryanmac.24 at gmail.com> writes:
>> 
>>> Hi R-help,
>>> 
>>> How do you perform least median square regression in R? Here is what I have but received no output. 
>>> 
>>> LMSRegression <- function(df, indices){
>>>  sample <- df[indices, ]
>>>  LMS_NAR_NIC_relation <- lm(sample$NAR~sample$NIC, data = sample, method = "lms")
>>>  rsquared_lms_nar_nic <- summary(LMS_NAR_NIC_relation)$r.square
>>> 
>>>  LMS_SQRTNAR_SQRTNIC_relation <- lm(sample$SQRTNAR~sample$SQRTNIC, data = sample, method = "lms")
>>>  rsquared_lms_sqrtnar_sqrtnic <- summary(LMS_SQRTNAR_SQRTNIC_relation)$r.square
>>> 
>>>  out <- c(rsquared_lms_nar_nic, rsquared_lms_sqrtnar_sqrtnic)
>>>  return(out)
>>> }
>>> 
>>> Also, which value should be looked at decide whether this is best regression model to use?
>>> 
>>> Bryan Mac
>>> bryanmac.24 at gmail.com
>>> 
>> 
>> A tutorial on how to run such regressions is included
>> in the NMOF package.
>> 
>> https://cran.r-project.org/package=NMOF/vignettes/PSlms.pdf
>> 

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From dwinsemius at comcast.net  Sat Oct  8 22:51:59 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 8 Oct 2016 13:51:59 -0700
Subject: [R] how to work ttkspinbox ?
In-Reply-To: <57c33fd4-7451-19d7-a533-5e4f48cf9e2a@yahoo.com.br>
References: <57c33fd4-7451-19d7-a533-5e4f48cf9e2a@yahoo.com.br>
Message-ID: <C652834C-801E-4FF3-9701-15C13B9D5049@comcast.net>


> On Oct 7, 2016, at 7:15 PM, Cleber N.Borges via R-help <r-help at r-project.org> wrote:
> 
> hello all,
> 
> somebody have a example of use of  ttkspinbox ?
> I tried to use like others widgets but I get error.
> 
> Thanks in advanced for any help
> 
> cleber
> 
> ###################
> > library( tcltk )
> >
> > t <- tktoplevel()
> >
> > spin <- ttkspinbox( t )
> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>  [tcl] invalid command name "ttk::spinbox".
> >
> > combo <- ttkcombobox( t )
> > tkpack( combo )
> <Tcl>
> >
> 
This displays a spinbox in an X-window:

t <- tktoplevel()
s = ttkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval')
tkpack(s)


> 
> 
> ---
> Este email foi escaneado pelo Avast antiv?rus.
> https://www.avast.com/antivirus
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Oct  8 23:01:03 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 8 Oct 2016 14:01:03 -0700
Subject: [R] =?utf-8?b?4oCcbG9nLXJhbmsgdGVzdOKAnSBhbmQg4oCcS2FwbGFuIE1l?=
 =?utf-8?q?ier_actuarial_plots_=28time_to_event_curve=29=E2=80=9D?=
In-Reply-To: <CAHDp66D2TCRKPDHafC6iTsvRLQ9fJvdTdq0GkU8Wteh5edBvRQ@mail.gmail.com>
References: <CAHDp66D2TCRKPDHafC6iTsvRLQ9fJvdTdq0GkU8Wteh5edBvRQ@mail.gmail.com>
Message-ID: <75BBAEBA-51C9-4F51-94C8-65A8DBF9DA5D@comcast.net>


> On Oct 7, 2016, at 3:56 PM, Steven Stoline <sstoline at gmail.com> wrote:
> 
> Dear All:
> 
> 
> 
> I do need your help with the ?log-rank test? and ?Kaplan Meier actuarial
> plots (time to event curve)? with adding the confidence intervals bands for
> the average score for each time to the curve of each group.

If this is a request for homework assistance then the Posting Guide advises you instead to consult with your resources at whatever academic institution you are studying. The Posting Guide also suggests that you post in plain text. It appears irregular because you posted in HTML.


> 
> 
> *Group variable:* 1 = group 1, 2 = group 2
> 
> 
> *Time points:* time1, time2, time3, time4, time5
> 
> 
> The goal is to compare the average scores of the two groups at each time
> point and obtain the Kaplan Meier actuarial plots (time to event curve) for
> the 5 time points for both groups in the plot.
> 
> 
> 
> Please use the following data for the test.
> 
> 
> time1    time2    time3    time4    time5    groups
> 
> 0              0              1              1              1              1
> 
> 0              4              0              1              1              1

You should also explain to whomever is tutoring you what a "4" or any of the other values mean at time2.

-- 
David Winsemius


> 
> 0              0              3              1              1              1
> 
> 0              2              0              1              1              1
> 
> 0              0              3              0              0              1
> 
> 0              0              0              1              2              1
> 
> 0              1              1              1
> 1
> 
> 0              0              2              1              1              1
> 
> 0              3              1              1              1              1
> 
> 0              0              0              1
> 1
> 
> 0              0              1              0              0              1
> 
> 0              0              0              1              1              1
> 
> 0              1              1              0              1              1
> 
> 0              0              1              3              4              1
> 
> 0              1              0              0              0              1
> 
> 0              1              1              1              2              1
> 
> 0              1              1              4              1              1
> 
> 0              0              0              0
> 1
> 
> 0              2              1              1              2              1
> 
> 
> 2
> 
> 0              0              0              0              0              2
> 
> 
> 2
> 
> 0
> 2
> 
> 0              0              3              2              2              2
> 
> 0              3              0              1              1              2
> 
> 0              0              1              1              1              2
> 
> 0
> 2
> 
> 0              0              0              1              1              2
> 
> 0              1              2              0              1              2
> 
> 0              0              1              1
> 2
> 
> 0              0              1              1              2              2
> 
> 0              1              1              1              1              2
> 
> 0              0              0              1              1              2
> 
> 0              0              1              1              1              2
> 
> 
> 2
> 
> 0              2              2              1
> 2
> 
> 0              0              1              1
> 2
> 
> 0              0              0              0              0              2
> 
> 0              3              3              1              2              2
> 
> 0              1              1              1
> 2
> 
> 0              0              0              1              1              2
> 
> 0              1              1              1              4              2
> 
> 0              1              1              1              1              2
> 
> 0              1              2              1              3              2
> 
> 
> 
> 
> 
> Thank you in advance
> 
> steve
> 
> 
> -------------------------
> Steven M. Stoline
> sstoline at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From klebyn at yahoo.com.br  Sat Oct  8 23:07:46 2016
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Sat, 8 Oct 2016 18:07:46 -0300
Subject: [R] how to work ttkspinbox ? win BUG ??
In-Reply-To: <C652834C-801E-4FF3-9701-15C13B9D5049@comcast.net>
References: <57c33fd4-7451-19d7-a533-5e4f48cf9e2a@yahoo.com.br>
	<C652834C-801E-4FF3-9701-15C13B9D5049@comcast.net>
Message-ID: <4d99b1a8-a05b-8612-5f02-40d11cde5400@yahoo.com.br>

thanks David for your help

thanks for your help, David
I suspect that there are a bug in windows version...

:-(

cleber


#######################################################
 > library( tcltk )
 > t <- tktoplevel()
 > s = ttkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval')
Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
   [tcl] invalid command name "ttk::spinbox".
 > tkpack(s)
Error in .Tcl.args.objv(...) : object 's' not found
 >
 >
 > sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7600)

locale:
[1] LC_COLLATE=Portuguese_Brazil.1252 LC_CTYPE=Portuguese_Brazil.1252
[3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C
[5] LC_TIME=Portuguese_Brazil.1252

attached base packages:
[1] tcltk     stats     graphics  grDevices utils     datasets methods   
base
 >


Em 08/10/2016 17:51, David Winsemius escreveu:
>> On Oct 7, 2016, at 7:15 PM, Cleber N.Borges via R-help <r-help at r-project.org> wrote:
>>
>> hello all,
>>
>> somebody have a example of use of  ttkspinbox ?
>> I tried to use like others widgets but I get error.
>>
>> Thanks in advanced for any help
>>
>> cleber
>>
>> ###################
>>> library( tcltk )
>>>
>>> t <- tktoplevel()
>>>
>>> spin <- ttkspinbox( t )
>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>>   [tcl] invalid command name "ttk::spinbox".
>>> combo <- ttkcombobox( t )
>>> tkpack( combo )
>> <Tcl>
>>
> This displays a spinbox in an X-window:
>
> t <- tktoplevel()
> s = ttkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval')
> tkpack(s)
>
> David Winsemius
> Alameda, CA, USA
>
>


---
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus


From jfox at mcmaster.ca  Sat Oct  8 23:51:20 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 8 Oct 2016 21:51:20 +0000
Subject: [R] how to work ttkspinbox ? win BUG ??
In-Reply-To: <4d99b1a8-a05b-8612-5f02-40d11cde5400@yahoo.com.br>
References: <57c33fd4-7451-19d7-a533-5e4f48cf9e2a@yahoo.com.br>
	<C652834C-801E-4FF3-9701-15C13B9D5049@comcast.net>
	<4d99b1a8-a05b-8612-5f02-40d11cde5400@yahoo.com.br>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8365835F5@FHSDB2D11-2.csu.mcmaster.ca>

Dear Cleber,

I can verify this problem on Windows; my session info:

---------- snip --------

> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

locale:
[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252    LC_MONETARY=English_Canada.1252
[4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252    

attached base packages:
[1] tcltk     stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.3.1

---------- snip --------

I suspect that ttk::spinbox is missing from the supplied Tcl/Tk (though other ttk widgets are present).

You can use spinbox from Tk by defining your own tkspinbox() function (there isn't one in the tcltk package):

	tkspinbox <- function(parent, ...) tkwidget(parent, "spinbox", ...)

Then, e.g., 

	t <- tktoplevel()
	s <- tkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval')
	tkpack(s)

works for me.

Best,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cleber
> N.Borges via R-help
> Sent: October 8, 2016 5:08 PM
> To: r-help at r-project.org
> Subject: Re: [R] how to work ttkspinbox ? win BUG ??
> 
> thanks David for your help
> 
> thanks for your help, David
> I suspect that there are a bug in windows version...
> 
> :-(
> 
> cleber
> 
> 
> #######################################################
>  > library( tcltk )
>  > t <- tktoplevel()
>  > s = ttkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval') Error in
> structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>    [tcl] invalid command name "ttk::spinbox".
>  > tkpack(s)
> Error in .Tcl.args.objv(...) : object 's' not found  >  >  > sessionInfo() R version
> 3.3.1 (2016-06-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
> (build 7600)
> 
> locale:
> [1] LC_COLLATE=Portuguese_Brazil.1252 LC_CTYPE=Portuguese_Brazil.1252
> [3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C [5]
> LC_TIME=Portuguese_Brazil.1252
> 
> attached base packages:
> [1] tcltk     stats     graphics  grDevices utils     datasets methods
> base
>  >
> 
> 
> Em 08/10/2016 17:51, David Winsemius escreveu:
> >> On Oct 7, 2016, at 7:15 PM, Cleber N.Borges via R-help <r-help at r-
> project.org> wrote:
> >>
> >> hello all,
> >>
> >> somebody have a example of use of  ttkspinbox ?
> >> I tried to use like others widgets but I get error.
> >>
> >> Thanks in advanced for any help
> >>
> >> cleber
> >>
> >> ###################
> >>> library( tcltk )
> >>>
> >>> t <- tktoplevel()
> >>>
> >>> spin <- ttkspinbox( t )
> >> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
> >>   [tcl] invalid command name "ttk::spinbox".
> >>> combo <- ttkcombobox( t )
> >>> tkpack( combo )
> >> <Tcl>
> >>
> > This displays a spinbox in an X-window:
> >
> > t <- tktoplevel()
> > s = ttkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval')
> > tkpack(s)
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
> 
> 
> ---
> Este email foi escaneado pelo Avast antiv?rus.
> https://www.avast.com/antivirus
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From christian at echoffmann.ch  Sat Oct  8 16:21:12 2016
From: christian at echoffmann.ch (Christian Hoffmann)
Date: Sat, 8 Oct 2016 16:21:12 +0200
Subject: [R] print (names and) values of parameters of function
Message-ID: <fe5a95aa-5ebf-bbda-7e2a-9d9f17480491@echoffmann.ch>

I try to print  (names and) values of parameters of a function within 
that function, like:

F <- function(x, y, z=4, ...) {

print("x = ", x, " , y = ",  y, "... = " , ...)

in a fashion that avoids the explicit mention of "x = ", x, " , y = ",  
y, "... = " , ...

Combinations of eval, substitute, formals, etc. should be able to do the 
job, but I didn't find help online.

Anyone lend a helping hand?
TIA  Christian

-- 
Christian W. Hoffmann
CH - 8915 Hausen am Albis, Schweiz
Rigiblickstrasse 15 b, Tel.+41-44-7640853
mailto: christian at echoffmann.ch
home: www.echoffmann.ch


From ash369ster at gmail.com  Sat Oct  8 22:42:10 2016
From: ash369ster at gmail.com (Ashwini Patil)
Date: Sat, 8 Oct 2016 16:42:10 -0400
Subject: [R] simulate AR1 process with uniform distribution and different y0
	values
In-Reply-To: <CAEK8ckDxx3egC0PXpCGeDtMpMNzOmrcWbd=OuB8+S-pzZd6n+w@mail.gmail.com>
References: <CAEK8ckDzFRO49Vz+GV3GEyWdwdpZQmApXixvaNY=DqQ_yq1VGA@mail.gmail.com>
	<CAEK8ckDxx3egC0PXpCGeDtMpMNzOmrcWbd=OuB8+S-pzZd6n+w@mail.gmail.com>
Message-ID: <CAEK8ckBR=2ZGiYt=pF0pdDMQpBM_gQCZF=Ojk2tVRQtj+z4+cQ@mail.gmail.com>

Hello

I need to plot an ar1 graph for process yk=0.75y (k-1) + ek, for y0=1 and
another graph for y0=10.

assume ek is uniformly distributed on interval [-0.5,0.5].

i have the following code but i am not sure how to control y0.

#----------#Start#---------#
rm(list=ls())
library(tseries)
#library(zoo)
set.seed(0)
y<-arima.sim(model=list(ar=.75), n=100, innov = runif(100, 0, 1))
y.1<-y-0.5
ts.plot(y.1)

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Oct  9 01:44:04 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 9 Oct 2016 12:44:04 +1300
Subject: [R] [FORGED] simulate AR1 process with uniform distribution and
 different y0 values
In-Reply-To: <CAEK8ckBR=2ZGiYt=pF0pdDMQpBM_gQCZF=Ojk2tVRQtj+z4+cQ@mail.gmail.com>
References: <CAEK8ckDzFRO49Vz+GV3GEyWdwdpZQmApXixvaNY=DqQ_yq1VGA@mail.gmail.com>
	<CAEK8ckDxx3egC0PXpCGeDtMpMNzOmrcWbd=OuB8+S-pzZd6n+w@mail.gmail.com>
	<CAEK8ckBR=2ZGiYt=pF0pdDMQpBM_gQCZF=Ojk2tVRQtj+z4+cQ@mail.gmail.com>
Message-ID: <c0ccbbd4-d642-8e10-8fd1-dc873b1c9a72@auckland.ac.nz>

On 09/10/16 09:42, Ashwini Patil wrote:
> Hello
>
> I need to plot an ar1 graph for process yk=0.75y (k-1) + ek, for y0=1 and
> another graph for y0=10.
>
> assume ek is uniformly distributed on interval [-0.5,0.5].
>
> i have the following code but i am not sure how to control y0.
>
> #----------#Start#---------#
> rm(list=ls())
> library(tseries)
> #library(zoo)
> set.seed(0)
> y<-arima.sim(model=list(ar=.75), n=100, innov = runif(100, 0, 1))
> y.1<-y-0.5
> ts.plot(y.1)

I don't understand the last three lines; shouldn't "innov" be equal to 
runif(100, -0.5, 0.5), and subtracting 0.5 be skipped?

I think that the following does what you want:

set.seed(42)
y<- arima.sim(model=list(ar=0.75),n.start=1,start.innov=10,n=100,
                  innov=runif(100,-0.5,0.5))

Or you could simply do:

set.seed(42)
e <- runif(100,-0.5,0.5)
yy <- numeric(101)
yy[1] <- 10
for(i in 1:100) yy[i+1] <- 0.75*yy[i] + e[i]
yy <- as.ts(yy[-1])

Same-same.

(Or you could apply filter() to c(10,e) with method="recursive".)

cheers,

Rolf Turner

P.S. I am not convinced that what you want to do makes much sense, but 
the foregoing shows how to do it if you must.

R. T.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dwinsemius at comcast.net  Sun Oct  9 05:07:43 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 8 Oct 2016 20:07:43 -0700
Subject: [R] print (names and) values of parameters of function
In-Reply-To: <fe5a95aa-5ebf-bbda-7e2a-9d9f17480491@echoffmann.ch>
References: <fe5a95aa-5ebf-bbda-7e2a-9d9f17480491@echoffmann.ch>
Message-ID: <674298A9-9B27-449F-B71D-4AA935FDBA68@comcast.net>


> On Oct 8, 2016, at 7:21 AM, Christian Hoffmann <christian at echoffmann.ch> wrote:
> 
> I try to print  (names and) values of parameters of a function within that function, like:
> 
> F <- function(x, y, z=4, ...) {
> 
> print("x = ", x, " , y = ",  y, "... = " , ...)
> 
> in a fashion that avoids the explicit mention of "x = ", x, " , y = ",  y, "... = " , ...
> 
> Combinations of eval, substitute, formals, etc. should be able to do the job, but I didn't find help online.

Try this:

 F <- function(x, y, z=4, ...) {this_call <- sys.call()
                                print(this_call) }
 F(x=2,y=3,z=5)
# F(x = 2, y = 3, z = 5)

> 
> Anyone lend a helping hand?
> TIA  Christian
> 
> -- 
> Christian W. Hoffmann
> CH - 8915 Hausen am Albis, Schweiz
> Rigiblickstrasse 15 b, Tel.+41-44-7640853
> mailto: christian at echoffmann.ch
> home: www.echoffmann.ch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Oct  9 05:13:45 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 8 Oct 2016 20:13:45 -0700
Subject: [R] bquote in list to be used with do.plot()
In-Reply-To: <630b98da-4338-89d3-b8f9-13d286c39f1e@yahoo.fr>
References: <630b98da-4338-89d3-b8f9-13d286c39f1e@yahoo.fr>
Message-ID: <5C65A970-751F-40C0-AC09-9E68DEC8E802@comcast.net>


> On Oct 8, 2016, at 9:50 AM, Marc Girondot via R-help <r-help at r-project.org> wrote:
> 
> Dear members,
> 
> Has someone have a solution to include a bquote() statement in a list to be used with do.call() ?
> 
> Here is an exemple:
>    scaleY <- 10000
>    plot(x=1, y=1, ylab=bquote(.(format(scaleY), scientific=FALSE)^"-1"))
> 
> Like that, it works.
> 
> Now he same in a list:
>    L <- list(x=1, y=1, ylab=bquote(.(format(scaleY), scientific=FALSE)^"-1"))
>    do.call(plot, L)
>        Error in "10000"^"-1" : argument non num?rique pour un op?rateur binaire
> 
> It produces an error.
> 
> Any solution?
> 
> (I tries also with substitute() and expression() but I fail also)

Try this:

L <- list(x=1, y=1, ylab=as.expression(bquote(.(format(scaleY), scientific=FALSE)^"-1")))
do.call(plot, L)

`bquote` actually doesn't return an object with mode expression but rather of mode call, so sometimes as.expression is needed to coerce the result. The `expression` function isn't really designed to do that.

> 
> Thanks
> 
> Marc
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From c.puschmann at student.unsw.edu.au  Sun Oct  9 01:26:40 2016
From: c.puschmann at student.unsw.edu.au (Christoph Puschmann)
Date: Sat, 8 Oct 2016 23:26:40 +0000
Subject: [R] Loop to check for large dataset
In-Reply-To: <CAJ=0CtBK6MnmmJ4EzVei=G4Yzj_kCRctMke-mF7xAc-cgNYWBw@mail.gmail.com>
References: <4FCBB54C-C002-43DE-ABA3-BBCD01F24DE9@ad.unsw.edu.au>
	<CAJ=0CtBK6MnmmJ4EzVei=G4Yzj_kCRctMke-mF7xAc-cgNYWBw@mail.gmail.com>
Message-ID: <9C546083-5909-4EFE-B102-225FAA94A6B7@ad.unsw.edu.au>

Dear Adrian,

Yes it is a cyclical data set and theoretically it should repeat this interval until 61327. The data set itself is divided into 2 Parts:
1. Product category (column 10)
2. Number of Stores Participating (column 01)
Overall there are 22 different products and in each you have 19 different stores participating. And theoretically each store over each product category should have a 1 - 157 week interval.

The part I am struggling with is how do I run a loop over the whole data set, while checking if all stores participated 157 weeks over the different products.

So far I came up with this:

n=61327                           # Generate Matrix to check for values
Control = matrix(
  0,
  nrow = n,
  ncol = 1)

s <- seq(from =1 , to = 157, by = 1)
CW = matrix(
  s,
  nrow = 157,
  ncol = 1
)

colnames(CW)[1] <- ?s'

CW = as.data.frame(CW)

for (i in 1:nrow(FD)) {           # Let run trhough all the rows
  for (j in 1:157) {
if(FD$WEEk[j] == C$s[j]) {
  Control[i] = 1                 # coresponding control row = 1
} else {
  Control[i] = 0                 # corresponding control row = 0
}
}
}

I coded a  MRE and attached an sample of my data set.

MRE:

#MRE

dat <- data.frame(
  Store = c(rep(8, times = 157), rep(12, times = 157)),  # Number of stores
  WEEK = rep(seq(from=1, to = 157, by = 1), times = 2)
)





From pdalgd at gmail.com  Sun Oct  9 13:14:10 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 9 Oct 2016 13:14:10 +0200
Subject: [R] how to work ttkspinbox ? win BUG ??
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365835F5@FHSDB2D11-2.csu.mcmaster.ca>
References: <57c33fd4-7451-19d7-a533-5e4f48cf9e2a@yahoo.com.br>
	<C652834C-801E-4FF3-9701-15C13B9D5049@comcast.net>
	<4d99b1a8-a05b-8612-5f02-40d11cde5400@yahoo.com.br>
	<ACD1644AA6C67E4FBD0C350625508EC8365835F5@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <666DC8C1-D5D5-4C81-92F3-E46C51BA2546@gmail.com>

According to the gospel of St.Google, our good friends Lawrence & Verzani have in their book "Programming Graphical User Interfaces in R" 

https://books.google.dk/books?id=J-3RBQAAQBAJ&lpg=PA404&ots=MPoWYqHK-h&dq=ttk%20spinbox%20windows&pg=PA404#v=onepage&q=ttk%20spinbox%20windows&f=false

(In case the link breaks, the gist is that the themed spinbox was introduced in Tk 8.5.9, but at the time of writing Windows R shipped with Tk 8.5.8)

Thumbing back through R-core internal discussions reveals that the reason for the current state of things lies in some complicated Windows C toolkit issues, so we're stuck with 8.5.8 for the 3.3.x series, but R-devel builds will have 8.6.4 or .5.

-pd 

> On 08 Oct 2016, at 23:51 , Fox, John <jfox at mcmaster.ca> wrote:
> 
> Dear Cleber,
> 
> I can verify this problem on Windows; my session info:
> 
> ---------- snip --------
> 
>> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
> 
> locale:
> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252    LC_MONETARY=English_Canada.1252
> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252    
> 
> attached base packages:
> [1] tcltk     stats     graphics  grDevices utils     datasets  methods   base     
> 
> loaded via a namespace (and not attached):
> [1] tools_3.3.1
> 
> ---------- snip --------
> 
> I suspect that ttk::spinbox is missing from the supplied Tcl/Tk (though other ttk widgets are present).
> 
> You can use spinbox from Tk by defining your own tkspinbox() function (there isn't one in the tcltk package):
> 
> 	tkspinbox <- function(parent, ...) tkwidget(parent, "spinbox", ...)
> 
> Then, e.g., 
> 
> 	t <- tktoplevel()
> 	s <- tkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval')
> 	tkpack(s)
> 
> works for me.
> 
> Best,
> John
> 
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
> 
> 
> 
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cleber
>> N.Borges via R-help
>> Sent: October 8, 2016 5:08 PM
>> To: r-help at r-project.org
>> Subject: Re: [R] how to work ttkspinbox ? win BUG ??
>> 
>> thanks David for your help
>> 
>> thanks for your help, David
>> I suspect that there are a bug in windows version...
>> 
>> :-(
>> 
>> cleber
>> 
>> 
>> #######################################################
>>> library( tcltk )
>>> t <- tktoplevel()
>>> s = ttkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval') Error in
>> structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>>   [tcl] invalid command name "ttk::spinbox".
>>> tkpack(s)
>> Error in .Tcl.args.objv(...) : object 's' not found  >  >  > sessionInfo() R version
>> 3.3.1 (2016-06-21)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>> (build 7600)
>> 
>> locale:
>> [1] LC_COLLATE=Portuguese_Brazil.1252 LC_CTYPE=Portuguese_Brazil.1252
>> [3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C [5]
>> LC_TIME=Portuguese_Brazil.1252
>> 
>> attached base packages:
>> [1] tcltk     stats     graphics  grDevices utils     datasets methods
>> base
>>> 
>> 
>> 
>> Em 08/10/2016 17:51, David Winsemius escreveu:
>>>> On Oct 7, 2016, at 7:15 PM, Cleber N.Borges via R-help <r-help at r-
>> project.org> wrote:
>>>> 
>>>> hello all,
>>>> 
>>>> somebody have a example of use of  ttkspinbox ?
>>>> I tried to use like others widgets but I get error.
>>>> 
>>>> Thanks in advanced for any help
>>>> 
>>>> cleber
>>>> 
>>>> ###################
>>>>> library( tcltk )
>>>>> 
>>>>> t <- tktoplevel()
>>>>> 
>>>>> spin <- ttkspinbox( t )
>>>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>>>>  [tcl] invalid command name "ttk::spinbox".
>>>>> combo <- ttkcombobox( t )
>>>>> tkpack( combo )
>>>> <Tcl>
>>>> 
>>> This displays a spinbox in an X-window:
>>> 
>>> t <- tktoplevel()
>>> s = ttkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval')
>>> tkpack(s)
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> 
>> 
>> 
>> ---
>> Este email foi escaneado pelo Avast antiv?rus.
>> https://www.avast.com/antivirus
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jfox at mcmaster.ca  Sun Oct  9 15:27:22 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Sun, 9 Oct 2016 13:27:22 +0000
Subject: [R] how to work ttkspinbox ? win BUG ??
In-Reply-To: <666DC8C1-D5D5-4C81-92F3-E46C51BA2546@gmail.com>
References: <57c33fd4-7451-19d7-a533-5e4f48cf9e2a@yahoo.com.br>
	<C652834C-801E-4FF3-9701-15C13B9D5049@comcast.net>
	<4d99b1a8-a05b-8612-5f02-40d11cde5400@yahoo.com.br>
	<ACD1644AA6C67E4FBD0C350625508EC8365835F5@FHSDB2D11-2.csu.mcmaster.ca>
	<666DC8C1-D5D5-4C81-92F3-E46C51BA2546@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836583760@FHSDB2D11-2.csu.mcmaster.ca>

Dear Peter,

Thanks for the explanation.

Is there a reason that there's no (unthemed) tkspinbox() in tclctk, defined as  tkspinbox <- function(parent, ...) tkwidget(parent, "spinbox", ...) ?

I noticed this quite some time ago (and probably should have mentioned it earlier). I define tkspinbox() in this manner in the Rcmdr package.

Best,
 John

> -----Original Message-----
> From: peter dalgaard [mailto:pdalgd at gmail.com]
> Sent: October 9, 2016 7:14 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: Cleber N.Borges <klebyn at yahoo.com.br>; r-help at r-project.org
> Subject: Re: [R] how to work ttkspinbox ? win BUG ??
> 
> According to the gospel of St.Google, our good friends Lawrence & Verzani
> have in their book "Programming Graphical User Interfaces in R"
> 
> https://books.google.dk/books?id=J-
> 3RBQAAQBAJ&lpg=PA404&ots=MPoWYqHK-
> h&dq=ttk%20spinbox%20windows&pg=PA404#v=onepage&q=ttk%20spinbox
> %20windows&f=false
> 
> (In case the link breaks, the gist is that the themed spinbox was introduced in
> Tk 8.5.9, but at the time of writing Windows R shipped with Tk 8.5.8)
> 
> Thumbing back through R-core internal discussions reveals that the reason for
> the current state of things lies in some complicated Windows C toolkit issues,
> so we're stuck with 8.5.8 for the 3.3.x series, but R-devel builds will have 8.6.4
> or .5.
> 
> -pd
> 
> > On 08 Oct 2016, at 23:51 , Fox, John <jfox at mcmaster.ca> wrote:
> >
> > Dear Cleber,
> >
> > I can verify this problem on Windows; my session info:
> >
> > ---------- snip --------
> >
> >> sessionInfo()
> > R version 3.3.1 (2016-06-21)
> > Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
> > x64 (build 9200)
> >
> > locale:
> > [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
> LC_MONETARY=English_Canada.1252
> > [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
> >
> > attached base packages:
> > [1] tcltk     stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.3.1
> >
> > ---------- snip --------
> >
> > I suspect that ttk::spinbox is missing from the supplied Tcl/Tk (though other
> ttk widgets are present).
> >
> > You can use spinbox from Tk by defining your own tkspinbox() function (there
> isn't one in the tcltk package):
> >
> > 	tkspinbox <- function(parent, ...) tkwidget(parent, "spinbox", ...)
> >
> > Then, e.g.,
> >
> > 	t <- tktoplevel()
> > 	s <- tkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval')
> > 	tkpack(s)
> >
> > works for me.
> >
> > Best,
> > John
> >
> > -----------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > Web: socserv.mcmaster.ca/jfox
> >
> >
> >
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> >> Cleber N.Borges via R-help
> >> Sent: October 8, 2016 5:08 PM
> >> To: r-help at r-project.org
> >> Subject: Re: [R] how to work ttkspinbox ? win BUG ??
> >>
> >> thanks David for your help
> >>
> >> thanks for your help, David
> >> I suspect that there are a bug in windows version...
> >>
> >> :-(
> >>
> >> cleber
> >>
> >>
> >> #######################################################
> >>> library( tcltk )
> >>> t <- tktoplevel()
> >>> s = ttkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval')
> >>> Error in
> >> structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
> >>   [tcl] invalid command name "ttk::spinbox".
> >>> tkpack(s)
> >> Error in .Tcl.args.objv(...) : object 's' not found  >  >  >
> >> sessionInfo() R version
> >> 3.3.1 (2016-06-21)
> >> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7
> >> x64 (build 7600)
> >>
> >> locale:
> >> [1] LC_COLLATE=Portuguese_Brazil.1252 LC_CTYPE=Portuguese_Brazil.1252
> >> [3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C [5]
> >> LC_TIME=Portuguese_Brazil.1252
> >>
> >> attached base packages:
> >> [1] tcltk     stats     graphics  grDevices utils     datasets methods
> >> base
> >>>
> >>
> >>
> >> Em 08/10/2016 17:51, David Winsemius escreveu:
> >>>> On Oct 7, 2016, at 7:15 PM, Cleber N.Borges via R-help <r-help at r-
> >> project.org> wrote:
> >>>>
> >>>> hello all,
> >>>>
> >>>> somebody have a example of use of  ttkspinbox ?
> >>>> I tried to use like others widgets but I get error.
> >>>>
> >>>> Thanks in advanced for any help
> >>>>
> >>>> cleber
> >>>>
> >>>> ###################
> >>>>> library( tcltk )
> >>>>>
> >>>>> t <- tktoplevel()
> >>>>>
> >>>>> spin <- ttkspinbox( t )
> >>>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
> >>>>  [tcl] invalid command name "ttk::spinbox".
> >>>>> combo <- ttkcombobox( t )
> >>>>> tkpack( combo )
> >>>> <Tcl>
> >>>>
> >>> This displays a spinbox in an X-window:
> >>>
> >>> t <- tktoplevel()
> >>> s = ttkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval')
> >>> tkpack(s)
> >>>
> >>> David Winsemius
> >>> Alameda, CA, USA
> >>>
> >>>
> >>
> >>
> >> ---
> >> Este email foi escaneado pelo Avast antiv?rus.
> >> https://www.avast.com/antivirus
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html and provide commented, minimal, self-contained,
> >> reproducible code.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000
> Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 


From pdalgd at gmail.com  Sun Oct  9 16:10:06 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 9 Oct 2016 16:10:06 +0200
Subject: [R] how to work ttkspinbox ? win BUG ??
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836583760@FHSDB2D11-2.csu.mcmaster.ca>
References: <57c33fd4-7451-19d7-a533-5e4f48cf9e2a@yahoo.com.br>
	<C652834C-801E-4FF3-9701-15C13B9D5049@comcast.net>
	<4d99b1a8-a05b-8612-5f02-40d11cde5400@yahoo.com.br>
	<ACD1644AA6C67E4FBD0C350625508EC8365835F5@FHSDB2D11-2.csu.mcmaster.ca>
	<666DC8C1-D5D5-4C81-92F3-E46C51BA2546@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC836583760@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <A5764ADB-C17D-4F93-BAEB-51AC92234434@gmail.com>


> On 09 Oct 2016, at 15:27 , Fox, John <jfox at mcmaster.ca> wrote:
> 
> Dear Peter,
> 
> Thanks for the explanation.
> 
> Is there a reason that there's no (unthemed) tkspinbox() in tclctk, defined as  tkspinbox <- function(parent, ...) tkwidget(parent, "spinbox", ...) ?

Only historical coincidence, I think. I "tkwidgeted" everything in sight in May 2000, Brian added ttk widgets in March 2008, and I added some more stuff in August 2015. So

(a) ordinary Tk widgets introduced later than 2000 haven't really been considered.

(b) ttkspinbox was included in the August 2015 update; I may have assumed that Tk would be updated to 8.6+ for 3.3.0 on all platforms, but this slipped through the cracks in the compiler toolchain update.  

-pd

> I noticed this quite some time ago (and probably should have mentioned it earlier). I define tkspinbox() in this manner in the Rcmdr package.
> 
> Best,
> John
> 
>> -----Original Message-----
>> From: peter dalgaard [mailto:pdalgd at gmail.com]
>> Sent: October 9, 2016 7:14 AM
>> To: Fox, John <jfox at mcmaster.ca>
>> Cc: Cleber N.Borges <klebyn at yahoo.com.br>; r-help at r-project.org
>> Subject: Re: [R] how to work ttkspinbox ? win BUG ??
>> 
>> According to the gospel of St.Google, our good friends Lawrence & Verzani
>> have in their book "Programming Graphical User Interfaces in R"
>> 
>> https://books.google.dk/books?id=J-
>> 3RBQAAQBAJ&lpg=PA404&ots=MPoWYqHK-
>> h&dq=ttk%20spinbox%20windows&pg=PA404#v=onepage&q=ttk%20spinbox
>> %20windows&f=false
>> 
>> (In case the link breaks, the gist is that the themed spinbox was introduced in
>> Tk 8.5.9, but at the time of writing Windows R shipped with Tk 8.5.8)
>> 
>> Thumbing back through R-core internal discussions reveals that the reason for
>> the current state of things lies in some complicated Windows C toolkit issues,
>> so we're stuck with 8.5.8 for the 3.3.x series, but R-devel builds will have 8.6.4
>> or .5.
>> 
>> -pd
>> 
>>> On 08 Oct 2016, at 23:51 , Fox, John <jfox at mcmaster.ca> wrote:
>>> 
>>> Dear Cleber,
>>> 
>>> I can verify this problem on Windows; my session info:
>>> 
>>> ---------- snip --------
>>> 
>>>> sessionInfo()
>>> R version 3.3.1 (2016-06-21)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
>>> x64 (build 9200)
>>> 
>>> locale:
>>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>> LC_MONETARY=English_Canada.1252
>>> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>>> 
>>> attached base packages:
>>> [1] tcltk     stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] tools_3.3.1
>>> 
>>> ---------- snip --------
>>> 
>>> I suspect that ttk::spinbox is missing from the supplied Tcl/Tk (though other
>> ttk widgets are present).
>>> 
>>> You can use spinbox from Tk by defining your own tkspinbox() function (there
>> isn't one in the tcltk package):
>>> 
>>> 	tkspinbox <- function(parent, ...) tkwidget(parent, "spinbox", ...)
>>> 
>>> Then, e.g.,
>>> 
>>> 	t <- tktoplevel()
>>> 	s <- tkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval')
>>> 	tkpack(s)
>>> 
>>> works for me.
>>> 
>>> Best,
>>> John
>>> 
>>> -----------------------------
>>> John Fox, Professor
>>> McMaster University
>>> Hamilton, Ontario
>>> Canada L8S 4M4
>>> Web: socserv.mcmaster.ca/jfox
>>> 
>>> 
>>> 
>>> 
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>> Cleber N.Borges via R-help
>>>> Sent: October 8, 2016 5:08 PM
>>>> To: r-help at r-project.org
>>>> Subject: Re: [R] how to work ttkspinbox ? win BUG ??
>>>> 
>>>> thanks David for your help
>>>> 
>>>> thanks for your help, David
>>>> I suspect that there are a bug in windows version...
>>>> 
>>>> :-(
>>>> 
>>>> cleber
>>>> 
>>>> 
>>>> #######################################################
>>>>> library( tcltk )
>>>>> t <- tktoplevel()
>>>>> s = ttkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval')
>>>>> Error in
>>>> structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>>>>  [tcl] invalid command name "ttk::spinbox".
>>>>> tkpack(s)
>>>> Error in .Tcl.args.objv(...) : object 's' not found  >  >  >
>>>> sessionInfo() R version
>>>> 3.3.1 (2016-06-21)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7
>>>> x64 (build 7600)
>>>> 
>>>> locale:
>>>> [1] LC_COLLATE=Portuguese_Brazil.1252 LC_CTYPE=Portuguese_Brazil.1252
>>>> [3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C [5]
>>>> LC_TIME=Portuguese_Brazil.1252
>>>> 
>>>> attached base packages:
>>>> [1] tcltk     stats     graphics  grDevices utils     datasets methods
>>>> base
>>>>> 
>>>> 
>>>> 
>>>> Em 08/10/2016 17:51, David Winsemius escreveu:
>>>>>> On Oct 7, 2016, at 7:15 PM, Cleber N.Borges via R-help <r-help at r-
>>>> project.org> wrote:
>>>>>> 
>>>>>> hello all,
>>>>>> 
>>>>>> somebody have a example of use of  ttkspinbox ?
>>>>>> I tried to use like others widgets but I get error.
>>>>>> 
>>>>>> Thanks in advanced for any help
>>>>>> 
>>>>>> cleber
>>>>>> 
>>>>>> ###################
>>>>>>> library( tcltk )
>>>>>>> 
>>>>>>> t <- tktoplevel()
>>>>>>> 
>>>>>>> spin <- ttkspinbox( t )
>>>>>> Error in structure(.External(.C_dotTclObjv, objv), class = "tclObj") :
>>>>>> [tcl] invalid command name "ttk::spinbox".
>>>>>>> combo <- ttkcombobox( t )
>>>>>>> tkpack( combo )
>>>>>> <Tcl>
>>>>>> 
>>>>> This displays a spinbox in an X-window:
>>>>> 
>>>>> t <- tktoplevel()
>>>>> s = ttkspinbox(t, from = 1.0, to = 100.0, textvariable='spinval')
>>>>> tkpack(s)
>>>>> 
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>> 
>>>>> 
>>>> 
>>>> 
>>>> ---
>>>> Este email foi escaneado pelo Avast antiv?rus.
>>>> https://www.avast.com/antivirus
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>>> guide.html and provide commented, minimal, self-contained,
>>>> reproducible code.
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000
>> Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sewashm at gmail.com  Sun Oct  9 16:56:47 2016
From: sewashm at gmail.com (Ashta)
Date: Sun, 9 Oct 2016 09:56:47 -0500
Subject: [R] create variable
Message-ID: <CADDFq30dXR44v3AfwRhw4=rAVLq5ijng73gVG8fZ3TNXi0x9xA@mail.gmail.com>

I am trying to query data from Hive service and create a variable.


dbGetQuery(hivecon,"select date1, date2 from  dateTable limit 10")
date1,  date2, Diif
4/5/1999,  6/14/2000
7/2/1999, 6/26/2000
8/14/1999, 8/19/2000
11/10/1999, 9/18/2000
8/25/2000, 6/5/2001
3/14/2012, 3/15/2004


Here is  what I wanted to do. While I am querying I want create a
variable diff= dat1e1-date2.
I may use this variable "diff"  to do some statistics (mean, mode,
etc) and also in the where clause l like as the following.

test_date=dbGetQuery(hivecon,"select date1, date2 from  dateTable
where diff gt 1000 limit 10")

I would appreciate if you suggest me how to do this.



Here is the sample of the data and  result

date1,  date2, Diif
4/5/1999,  6/14/2000, -436
7/2/1999, 6/26/2000, -360
8/14/1999, 8/19/2000, -371
11/10/1999, 9/18/2000, -313
8/25/2000, 6/5/2001, -284
3/14/2012, 3/15/2004, 2921

Thank you in advance


From gaopinglei at 163.com  Sun Oct  9 13:21:16 2016
From: gaopinglei at 163.com (Pinglei Gao)
Date: Sun, 9 Oct 2016 19:21:16 +0800
Subject: [R] Finding starting values for the parameters using nls() or nls2()
Message-ID: <013a01d2221f$40b46360$c21d2a20$@163.com>

Hi,

I have some data that i'm trying to fit a double exponential model: data.
Frame (Area=c (521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91, 989.05,
1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 2629.2),

Retention=c (95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 23.46,
9.72, 97.92, 71.44, 44.52, 24.44, 15.26) ) and the formula of the double
exponential is: exp (b0*exp (b1*x^th)).

 

I failed to guess the initial parameter values and then I learned a measure
to find starting values from Nonlinear Regression with R (pp. 25-27):

 

> cl<-data.frame(Area =c(521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91,
989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 2629.2),

+ Retention =c(95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 23.46,
9.72, 97.92, 71.44, 44.52, 24.44, 15.26) )

> expFct <- function(Area, b0, b1,th) {exp(b0*exp(b1*Area^th))}

> grid.Disperse <- expand.grid(list(b0 = seq(0.01,4, by = 0.01), th =
c(0.02),b1 = seq(0.01, 4, by = 0.01)))

> Disperse.m2a <- nls2(Retention ~expFct(Area, b0, b1,th), data = cl, start
= grid.Disperse, algorithm = "brute-force")

> Disperse.m2a

Nonlinear regression model

  model: Retention ~ expFct(Area, b0, th, b1)

   data: cl

b0   th   b1

3.82 0.02 0.01

residual sum-of-squares: 13596

Number of iterations to convergence: 160000

Achieved convergence tolerance: NA

 

I got no error then I use the output as starting values to nls2 ():

> nls.m2<- nls2(Retention ~ expFct(Area, b0, b1, th), data = cl, start =
list(b0 = 3.82, b1 = 0.02, th = 0.01))

Error in (function (formula, data = parent.frame(), start, control =
nls.control(),  :

Singular gradient

 

Why? Did I do something wrong or misunderstand something?

 

Later, I found another measure from Modern Applied Statistics with S (pp.
216-217):

 

> negexp <- selfStart(model = ~ exp(b0*exp(b1*x^th)),initial =
negexp.SSival, parameters = c("b0", "b1", "th"),

+ template = function(x, b0, b1, th) {})

> Disperse.ss <- nls(Retention ~ negexp(Area, b0, b1, th),data = cl, trace =
T)

         b0          b1          th

   4.208763  144.205455 1035.324595

Error in qr.default(.swts * attr(rhs, "gradient")) :

 NA/NaN/Inf (arg1) can not be called when the external function is called.

 

Error happened again. How can I fix it? I am desperate.

 

Best regards,

 

Pinglei Gao

 


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Oct  9 17:36:07 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 9 Oct 2016 08:36:07 -0700
Subject: [R] create variable
In-Reply-To: <CADDFq30dXR44v3AfwRhw4=rAVLq5ijng73gVG8fZ3TNXi0x9xA@mail.gmail.com>
References: <CADDFq30dXR44v3AfwRhw4=rAVLq5ijng73gVG8fZ3TNXi0x9xA@mail.gmail.com>
Message-ID: <CAGxFJbR15zLK-MaLOtHAP-P+4o=Zk5-JP9Vb4-EfJHo7K34E_Q@mail.gmail.com>

I think you need to do some homework on your own first. Have you gone
through any R tutorials? -- there are many good ones on the web.
Including ones on date-time processing in R.

To answer your question directly, read up on date/time classes and
functions with ?"date-time"  . You may also find the "lubridate"
package useful, as it is intended to standardize and simplify typical
date-time processing and analysis.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Oct 9, 2016 at 7:56 AM, Ashta <sewashm at gmail.com> wrote:
> I am trying to query data from Hive service and create a variable.
>
>
> dbGetQuery(hivecon,"select date1, date2 from  dateTable limit 10")
> date1,  date2, Diif
> 4/5/1999,  6/14/2000
> 7/2/1999, 6/26/2000
> 8/14/1999, 8/19/2000
> 11/10/1999, 9/18/2000
> 8/25/2000, 6/5/2001
> 3/14/2012, 3/15/2004
>
>
> Here is  what I wanted to do. While I am querying I want create a
> variable diff= dat1e1-date2.
> I may use this variable "diff"  to do some statistics (mean, mode,
> etc) and also in the where clause l like as the following.
>
> test_date=dbGetQuery(hivecon,"select date1, date2 from  dateTable
> where diff gt 1000 limit 10")
>
> I would appreciate if you suggest me how to do this.
>
>
>
> Here is the sample of the data and  result
>
> date1,  date2, Diif
> 4/5/1999,  6/14/2000, -436
> 7/2/1999, 6/26/2000, -360
> 8/14/1999, 8/19/2000, -371
> 11/10/1999, 9/18/2000, -313
> 8/25/2000, 6/5/2001, -284
> 3/14/2012, 3/15/2004, 2921
>
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Oct  9 18:10:29 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 9 Oct 2016 09:10:29 -0700
Subject: [R] create variable
In-Reply-To: <CADDFq30dXR44v3AfwRhw4=rAVLq5ijng73gVG8fZ3TNXi0x9xA@mail.gmail.com>
References: <CADDFq30dXR44v3AfwRhw4=rAVLq5ijng73gVG8fZ3TNXi0x9xA@mail.gmail.com>
Message-ID: <51905C81-7591-4395-BA57-43D9965A1CD6@comcast.net>


> On Oct 9, 2016, at 7:56 AM, Ashta <sewashm at gmail.com> wrote:
> 
> I am trying to query data from Hive service and create a variable.
> 
> 
> dbGetQuery(hivecon,"select date1, date2 from  dateTable limit 10")
> date1,  date2, Diif
> 4/5/1999,  6/14/2000
> 7/2/1999, 6/26/2000
> 8/14/1999, 8/19/2000
> 11/10/1999, 9/18/2000
> 8/25/2000, 6/5/2001
> 3/14/2012, 3/15/2004
> 
> 
> Here is  what I wanted to do. While I am querying I want create a
> variable diff= dat1e1-date2.
> I may use this variable "diff"  to do some statistics (mean, mode,
> etc) and also in the where clause l like as the following.
> 
> test_date=dbGetQuery(hivecon,"select date1, date2 from  dateTable
> where diff gt 1000 limit 10")
> 
> I would appreciate if you suggest me how to do this.
> 
> 
> 
> Here is the sample of the data and  result
> 
> date1,  date2, Diif
> 4/5/1999,  6/14/2000, -436
> 7/2/1999, 6/26/2000, -360
> 8/14/1999, 8/19/2000, -371
> 11/10/1999, 9/18/2000, -313
> 8/25/2000, 6/5/2001, -284
> 3/14/2012, 3/15/2004, 2921
> 
> Thank you in advance
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Oct  9 18:16:33 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 9 Oct 2016 09:16:33 -0700
Subject: [R] create variable
In-Reply-To: <CADDFq30dXR44v3AfwRhw4=rAVLq5ijng73gVG8fZ3TNXi0x9xA@mail.gmail.com>
References: <CADDFq30dXR44v3AfwRhw4=rAVLq5ijng73gVG8fZ3TNXi0x9xA@mail.gmail.com>
Message-ID: <A2326220-9507-4930-B210-41786F4ABAF5@comcast.net>


> On Oct 9, 2016, at 7:56 AM, Ashta <sewashm at gmail.com> wrote:
> 
> I am trying to query data from Hive service and create a variable.
> 
> 
> dbGetQuery(hivecon,"select date1, date2 from  dateTable limit 10")
> date1,  date2, Diif
> 4/5/1999,  6/14/2000
> 7/2/1999, 6/26/2000
> 8/14/1999, 8/19/2000
> 11/10/1999, 9/18/2000
> 8/25/2000, 6/5/2001
> 3/14/2012, 3/15/2004
> 
> 
> Here is  what I wanted to do. While I am querying I want create a
> variable diff= dat1e1-date2.
> I may use this variable "diff"  to do some statistics (mean, mode,
> etc) and also in the where clause l like as the following.
> 
> test_date=dbGetQuery(hivecon,"select date1, date2 from  dateTable
> where diff gt 1000 limit 10")
> 
> I would appreciate if you suggest me how to do this.

Sorry for the blank message earlier. My reading of the use of Hive queries is that you would need to use the `datediff` function. I further suspect you need to define a variable name to which then apply your limits. I also read that hive dates are actually strings types represented as POSIX style character values and might need a to_date funciton. This is all guesswork since I don't have a hive cluster to run this against:

 So perhaps something like one of these:

try1 <- dbGetQuery(hivecon,"select date1, date2, datediff(TO_DATE(date1),TO_DATE(date2)) as d12diff from  dateTable where d12diff GT 1000 limit 10")

try2 <- dbGetQuery(hivecon,"select date1, date2, datediff(dat1,date2) as d12diff from  dateTable where d12diff GT 1000 limit 10")

Obviously these are just guesses.

-- 
David.
> 
> 
> 
> Here is the sample of the data and  result
> 
> date1,  date2, Diif
> 4/5/1999,  6/14/2000, -436
> 7/2/1999, 6/26/2000, -360
> 8/14/1999, 8/19/2000, -371
> 11/10/1999, 9/18/2000, -313
> 8/25/2000, 6/5/2001, -284
> 3/14/2012, 3/15/2004, 2921
> 
> Thank you in advance
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Sun Oct  9 19:02:13 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 09 Oct 2016 10:02:13 -0700
Subject: [R] create variable
In-Reply-To: <A2326220-9507-4930-B210-41786F4ABAF5@comcast.net>
References: <CADDFq30dXR44v3AfwRhw4=rAVLq5ijng73gVG8fZ3TNXi0x9xA@mail.gmail.com>
	<A2326220-9507-4930-B210-41786F4ABAF5@comcast.net>
Message-ID: <D4A55BA1-65E7-42E7-830F-1BF94D8E2DBB@dcn.davis.ca.us>

This being the R-help mailing list, not being fluent in random SQL variants is normal. There is a place for discussing the intersection of R and databases where the intersection of R with such knowledge might be more typical. I suggest that Ashta read the Posting Guide to learn about appropriate mailing lists and other useful background. If in fact this question is about R, then confusing the issue with SQL should not be necessary since a sample of the output of a database query can be provided as dput() output. If the question is purely about Hive then it doesn't belong on any R list anyway.
-- 
Sent from my phone. Please excuse my brevity.

On October 9, 2016 9:16:33 AM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Oct 9, 2016, at 7:56 AM, Ashta <sewashm at gmail.com> wrote:
>> 
>> I am trying to query data from Hive service and create a variable.
>> 
>> 
>> dbGetQuery(hivecon,"select date1, date2 from  dateTable limit 10")
>> date1,  date2, Diif
>> 4/5/1999,  6/14/2000
>> 7/2/1999, 6/26/2000
>> 8/14/1999, 8/19/2000
>> 11/10/1999, 9/18/2000
>> 8/25/2000, 6/5/2001
>> 3/14/2012, 3/15/2004
>> 
>> 
>> Here is  what I wanted to do. While I am querying I want create a
>> variable diff= dat1e1-date2.
>> I may use this variable "diff"  to do some statistics (mean, mode,
>> etc) and also in the where clause l like as the following.
>> 
>> test_date=dbGetQuery(hivecon,"select date1, date2 from  dateTable
>> where diff gt 1000 limit 10")
>> 
>> I would appreciate if you suggest me how to do this.
>
>Sorry for the blank message earlier. My reading of the use of Hive
>queries is that you would need to use the `datediff` function. I
>further suspect you need to define a variable name to which then apply
>your limits. I also read that hive dates are actually strings types
>represented as POSIX style character values and might need a to_date
>funciton. This is all guesswork since I don't have a hive cluster to
>run this against:
>
> So perhaps something like one of these:
>
>try1 <- dbGetQuery(hivecon,"select date1, date2,
>datediff(TO_DATE(date1),TO_DATE(date2)) as d12diff from  dateTable
>where d12diff GT 1000 limit 10")
>
>try2 <- dbGetQuery(hivecon,"select date1, date2, datediff(dat1,date2)
>as d12diff from  dateTable where d12diff GT 1000 limit 10")
>
>Obviously these are just guesses.


From wdunlap at tibco.com  Sun Oct  9 20:06:06 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 9 Oct 2016 11:06:06 -0700
Subject: [R] print (names and) values of parameters of function
In-Reply-To: <fe5a95aa-5ebf-bbda-7e2a-9d9f17480491@echoffmann.ch>
References: <fe5a95aa-5ebf-bbda-7e2a-9d9f17480491@echoffmann.ch>
Message-ID: <CAF8bMcbAney7czU3wXGZ=WCWN+aDgxW+bTfwTrxaEeJQr-Fq8w@mail.gmail.com>

There is no perfect way to do this because you can write functions
that depend on the order of evaluation of their arguments or that
must evaluate some code in the body of the function before evaluating
an argument (e.g., stats:::print.formula) or that don't evaluate them in
the usual sense.  However, print(ls.str(environment())), as the first line
of the function, can be useful:

> trace(nls, quote(print(ls.str(environment()))))
Tracing function "nls" in package "stats"
[1] "nls"
> d <- data.frame(x=log(1:10),y=1:10)
> fit <- nls(y~a*x^b, data=d, start=c(a=1,b=1))
Tracing nls(y ~ a * x^b, data = d, start = c(a = 1, b = 1)) on entry
algorithm :  chr [1:3] "default" "plinear" "port"
control : List of 5
 $ maxiter  : num 50
 $ tol      : num 1e-05
 $ minFactor: num 0.000977
 $ printEval: logi FALSE
 $ warnOnly : logi FALSE
data : 'data.frame':    10 obs. of  2 variables:
 $ x: num  0 0.693 1.099 1.386 1.609 ...
 $ y: int  1 2 3 4 5 6 7 8 9 10
formula : Class 'formula'  language y ~ a * x^b
lower :  num -Inf
model :  logi FALSE
na.action : <missing>
start :  Named num [1:2] 1 1
subset : <missing>
trace :  logi FALSE
upper :  num Inf
weights : <missing>


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Oct 8, 2016 at 7:21 AM, Christian Hoffmann <christian at echoffmann.ch>
wrote:

> I try to print  (names and) values of parameters of a function within that
> function, like:
>
> F <- function(x, y, z=4, ...) {
>
> print("x = ", x, " , y = ",  y, "... = " , ...)
>
> in a fashion that avoids the explicit mention of "x = ", x, " , y = ",  y,
> "... = " , ...
>
> Combinations of eval, substitute, formals, etc. should be able to do the
> job, but I didn't find help online.
>
> Anyone lend a helping hand?
> TIA  Christian
>
> --
> Christian W. Hoffmann
> CH - 8915 Hausen am Albis, Schweiz
> Rigiblickstrasse 15 b, Tel.+41-44-7640853
> mailto: christian at echoffmann.ch
> home: www.echoffmann.ch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sewashm at gmail.com  Sun Oct  9 20:53:01 2016
From: sewashm at gmail.com (Ashta)
Date: Sun, 9 Oct 2016 13:53:01 -0500
Subject: [R] create variable
In-Reply-To: <A2326220-9507-4930-B210-41786F4ABAF5@comcast.net>
References: <CADDFq30dXR44v3AfwRhw4=rAVLq5ijng73gVG8fZ3TNXi0x9xA@mail.gmail.com>
	<A2326220-9507-4930-B210-41786F4ABAF5@comcast.net>
Message-ID: <CADDFq30hqBwa1Owc0WADSOgbA5KrdHGSHdbynLnqfST5ZEJVVQ@mail.gmail.com>

Thank you so much David!  Your suggestions worked for me.


On Sun, Oct 9, 2016 at 11:16 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Oct 9, 2016, at 7:56 AM, Ashta <sewashm at gmail.com> wrote:
>>
>> I am trying to query data from Hive service and create a variable.
>>
>>
>> dbGetQuery(hivecon,"select date1, date2 from  dateTable limit 10")
>> date1,  date2, Diif
>> 4/5/1999,  6/14/2000
>> 7/2/1999, 6/26/2000
>> 8/14/1999, 8/19/2000
>> 11/10/1999, 9/18/2000
>> 8/25/2000, 6/5/2001
>> 3/14/2012, 3/15/2004
>>
>>
>> Here is  what I wanted to do. While I am querying I want create a
>> variable diff= dat1e1-date2.
>> I may use this variable "diff"  to do some statistics (mean, mode,
>> etc) and also in the where clause l like as the following.
>>
>> test_date=dbGetQuery(hivecon,"select date1, date2 from  dateTable
>> where diff gt 1000 limit 10")
>>
>> I would appreciate if you suggest me how to do this.
>
> Sorry for the blank message earlier. My reading of the use of Hive queries is that you would need to use the `datediff` function. I further suspect you need to define a variable name to which then apply your limits. I also read that hive dates are actually strings types represented as POSIX style character values and might need a to_date funciton. This is all guesswork since I don't have a hive cluster to run this against:
>
>  So perhaps something like one of these:
>
> try1 <- dbGetQuery(hivecon,"select date1, date2, datediff(TO_DATE(date1),TO_DATE(date2)) as d12diff from  dateTable where d12diff GT 1000 limit 10")
>
> try2 <- dbGetQuery(hivecon,"select date1, date2, datediff(dat1,date2) as d12diff from  dateTable where d12diff GT 1000 limit 10")
>
> Obviously these are just guesses.
>
> --
> David.
>>
>>
>>
>> Here is the sample of the data and  result
>>
>> date1,  date2, Diif
>> 4/5/1999,  6/14/2000, -436
>> 7/2/1999, 6/26/2000, -360
>> 8/14/1999, 8/19/2000, -371
>> 11/10/1999, 9/18/2000, -313
>> 8/25/2000, 6/5/2001, -284
>> 3/14/2012, 3/15/2004, 2921
>>
>> Thank you in advance
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From axel.urbiz at gmail.com  Sun Oct  9 22:47:12 2016
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Sun, 9 Oct 2016 16:47:12 -0400
Subject: [R] Extending sparklyr
Message-ID: <CAAyVsX+SJXJDS09x19AxQ-Awx4VeK_16Zp9LZzmk9P9k=ZXxJQ@mail.gmail.com>

Hi All,

Just started to experiment with "sparklyr" and already loving it.

I'm trying to build an extension by constructing an R wrapper to Spark's
Gaussian Mixtures. My attempt is below, and so is the error message. Not
sure if this is possible to do, and if so, what is wrong with my code.

Any hints would be much appreciated.

Best,
Axel.

-----

library(sparklyr)
library(dplyr)
sc <- spark_connect(master = "local")

x <- copy_to(sc, iris)
x <- x %>% select(Petal_Width, Petal_Length)

# set params
k <- 3
iter.max <- 100
features <- dplyr::tbl_vars(x)
compute.cost <- TRUE
tolerance <- 1e-4
ml.options <- ml_options()

df <- spark_dataframe(x)
sc <- spark_connection(df)
df <- ml_prepare_features(
  x = df,
  features = features,
  envir = environment()
  # ml.options = ml.options
)
envir <- new.env(parent = emptyenv())
envir$id <- ml.options$id.column
df <- df %>%
  sdf_with_unique_id(envir$id) %>%
  spark_dataframe()
tdf <- ml_prepare_dataframe(df, features, ml.options = ml.options, envir =
envir)
envir$model <- "org.apache.spark.ml.clustering.GaussianMixture"
gmm <- invoke_new(sc, envir$model)
>Error: failed to invoke spark command
>16/10/09 16:35:35 ERROR <init> on
org.apache.spark.ml.clustering.GaussianMixture failed

	[[alternative HTML version deleted]]


From A.Robinson at ms.unimelb.edu.au  Mon Oct 10 00:05:49 2016
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 10 Oct 2016 09:05:49 +1100
Subject: [R] Finding starting values for the parameters using nls() or
	nls2()
In-Reply-To: <013a01d2221f$40b46360$c21d2a20$@163.com>
References: <013a01d2221f$40b46360$c21d2a20$@163.com>
Message-ID: <CAHyGmd763iOdtg=n+EG5qjWELqPSWaDz8jtY4RcbK84i48XTkw@mail.gmail.com>

Here are some things to try.  Maybe divide Area by 1000 and retention
by 100.  Try plotting the data and superimposing the line that
corresponds to the 'fit' from nls2.  See if you can correct it with
some careful guesses.

Getting suitable starting parameters for non-linear modeling is one of
the black arts of statistical fitting. Good luck!  And don't forget to
check for sensitivity.

Andrew

On 9 October 2016 at 22:21, Pinglei Gao <gaopinglei at 163.com> wrote:
> Hi,
>
> I have some data that i'm trying to fit a double exponential model: data.
> Frame (Area=c (521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91, 989.05,
> 1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 2629.2),
>
> Retention=c (95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 23.46,
> 9.72, 97.92, 71.44, 44.52, 24.44, 15.26) ) and the formula of the double
> exponential is: exp (b0*exp (b1*x^th)).
>
>
>
> I failed to guess the initial parameter values and then I learned a measure
> to find starting values from Nonlinear Regression with R (pp. 25-27):
>
>
>
>> cl<-data.frame(Area =c(521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91,
> 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 2629.2),
>
> + Retention =c(95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 23.46,
> 9.72, 97.92, 71.44, 44.52, 24.44, 15.26) )
>
>> expFct <- function(Area, b0, b1,th) {exp(b0*exp(b1*Area^th))}
>
>> grid.Disperse <- expand.grid(list(b0 = seq(0.01,4, by = 0.01), th =
> c(0.02),b1 = seq(0.01, 4, by = 0.01)))
>
>> Disperse.m2a <- nls2(Retention ~expFct(Area, b0, b1,th), data = cl, start
> = grid.Disperse, algorithm = "brute-force")
>
>> Disperse.m2a
>
> Nonlinear regression model
>
>   model: Retention ~ expFct(Area, b0, th, b1)
>
>    data: cl
>
> b0   th   b1
>
> 3.82 0.02 0.01
>
> residual sum-of-squares: 13596
>
> Number of iterations to convergence: 160000
>
> Achieved convergence tolerance: NA
>
>
>
> I got no error then I use the output as starting values to nls2 ():
>
>> nls.m2<- nls2(Retention ~ expFct(Area, b0, b1, th), data = cl, start =
> list(b0 = 3.82, b1 = 0.02, th = 0.01))
>
> Error in (function (formula, data = parent.frame(), start, control =
> nls.control(),  :
>
> Singular gradient
>
>
>
> Why? Did I do something wrong or misunderstand something?
>
>
>
> Later, I found another measure from Modern Applied Statistics with S (pp.
> 216-217):
>
>
>
>> negexp <- selfStart(model = ~ exp(b0*exp(b1*x^th)),initial =
> negexp.SSival, parameters = c("b0", "b1", "th"),
>
> + template = function(x, b0, b1, th) {})
>
>> Disperse.ss <- nls(Retention ~ negexp(Area, b0, b1, th),data = cl, trace =
> T)
>
>          b0          b1          th
>
>    4.208763  144.205455 1035.324595
>
> Error in qr.default(.swts * attr(rhs, "gradient")) :
>
>  NA/NaN/Inf (arg1) can not be called when the external function is called.
>
>
>
> Error happened again. How can I fix it? I am desperate.
>
>
>
> Best regards,
>
>
>
> Pinglei Gao
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Andrew Robinson
Deputy Director, CEBRA, School of Biosciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au
Website: http://www.ms.unimelb.edu.au/~andrewpr

MSME: http://www.crcpress.com/product/isbn/9781439858028
FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
SPuR: http://www.ms.unimelb.edu.au/spuRs/


From bgunter.4567 at gmail.com  Mon Oct 10 00:40:17 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 9 Oct 2016 15:40:17 -0700
Subject: [R] Finding starting values for the parameters using nls() or
	nls2()
In-Reply-To: <CAHyGmd763iOdtg=n+EG5qjWELqPSWaDz8jtY4RcbK84i48XTkw@mail.gmail.com>
References: <013a01d2221f$40b46360$c21d2a20$@163.com>
	<CAHyGmd763iOdtg=n+EG5qjWELqPSWaDz8jtY4RcbK84i48XTkw@mail.gmail.com>
Message-ID: <CAGxFJbSDOwCschCboz+uJLiTuaMj8OvsXvyD-TW1R08Zdwhrqg@mail.gmail.com>

Well... (inline -- and I hope this isn't homework!)




On Sun, Oct 9, 2016 at 3:05 PM, Andrew Robinson
<A.Robinson at ms.unimelb.edu.au> wrote:
> Here are some things to try.  Maybe divide Area by 1000 and retention
> by 100.  Try plotting the data and superimposing the line that
> corresponds to the 'fit' from nls2.  See if you can correct it with
> some careful guesses.
>
> Getting suitable starting parameters for non-linear modeling is one of
> the black arts of statistical fitting. ...
>
> Andrew

True. But it's usually worthwhile thinking about the math a bit before guessing.

Note that the model can be linearized to:

log(log(Retention)) = b0 + b1*Area^th

So a plot of log(log(Retention)) vs Area may be informative and useful
for finding starting values. e.g., for a grid of th's, do linear
regression fits .

However, when I look at that plot, it seems pretty linear with a
negative slope. This suggests that you may have an overparametrization
problem . i.e. fix th =1 and use the b0 and b1 from the above
regression for starting values.

Do note that this strategy isn't foolproof, as it ignores that the
error term is additive in the above transformed metric, rather than
the original. This can sometimes mislead. But this is just a
heuristic.

Cheers,
Bert







>
> On 9 October 2016 at 22:21, Pinglei Gao <gaopinglei at 163.com> wrote:
>> Hi,
>>
>> I have some data that i'm trying to fit a double exponential model: data.
>> Frame (Area=c (521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91, 989.05,
>> 1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 2629.2),
>>
>> Retention=c (95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 23.46,
>> 9.72, 97.92, 71.44, 44.52, 24.44, 15.26) ) and the formula of the double
>> exponential is: exp (b0*exp (b1*x^th)).
>>
>>
>>
>> I failed to guess the initial parameter values and then I learned a measure
>> to find starting values from Nonlinear Regression with R (pp. 25-27):
>>
>>
>>
>>> cl<-data.frame(Area =c(521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91,
>> 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 2629.2),
>>
>> + Retention =c(95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 23.46,
>> 9.72, 97.92, 71.44, 44.52, 24.44, 15.26) )
>>
>>> expFct <- function(Area, b0, b1,th) {exp(b0*exp(b1*Area^th))}
>>
>>> grid.Disperse <- expand.grid(list(b0 = seq(0.01,4, by = 0.01), th =
>> c(0.02),b1 = seq(0.01, 4, by = 0.01)))
>>
>>> Disperse.m2a <- nls2(Retention ~expFct(Area, b0, b1,th), data = cl, start
>> = grid.Disperse, algorithm = "brute-force")
>>
>>> Disperse.m2a
>>
>> Nonlinear regression model
>>
>>   model: Retention ~ expFct(Area, b0, th, b1)
>>
>>    data: cl
>>
>> b0   th   b1
>>
>> 3.82 0.02 0.01
>>
>> residual sum-of-squares: 13596
>>
>> Number of iterations to convergence: 160000
>>
>> Achieved convergence tolerance: NA
>>
>>
>>
>> I got no error then I use the output as starting values to nls2 ():
>>
>>> nls.m2<- nls2(Retention ~ expFct(Area, b0, b1, th), data = cl, start =
>> list(b0 = 3.82, b1 = 0.02, th = 0.01))
>>
>> Error in (function (formula, data = parent.frame(), start, control =
>> nls.control(),  :
>>
>> Singular gradient
>>
>>
>>
>> Why? Did I do something wrong or misunderstand something?
>>
>>
>>
>> Later, I found another measure from Modern Applied Statistics with S (pp.
>> 216-217):
>>
>>
>>
>>> negexp <- selfStart(model = ~ exp(b0*exp(b1*x^th)),initial =
>> negexp.SSival, parameters = c("b0", "b1", "th"),
>>
>> + template = function(x, b0, b1, th) {})
>>
>>> Disperse.ss <- nls(Retention ~ negexp(Area, b0, b1, th),data = cl, trace =
>> T)
>>
>>          b0          b1          th
>>
>>    4.208763  144.205455 1035.324595
>>
>> Error in qr.default(.swts * attr(rhs, "gradient")) :
>>
>>  NA/NaN/Inf (arg1) can not be called when the external function is called.
>>
>>
>>
>> Error happened again. How can I fix it? I am desperate.
>>
>>
>>
>> Best regards,
>>
>>
>>
>> Pinglei Gao
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Andrew Robinson
> Deputy Director, CEBRA, School of Biosciences
> Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
> School of Mathematics and Statistics                        Fax: +61-3-8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: a.robinson at ms.unimelb.edu.au
> Website: http://www.ms.unimelb.edu.au/~andrewpr
>
> MSME: http://www.crcpress.com/product/isbn/9781439858028
> FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
> SPuR: http://www.ms.unimelb.edu.au/spuRs/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon Oct 10 01:40:56 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 10 Oct 2016 01:40:56 +0200
Subject: [R] Finding starting values for the parameters using nls() or
	nls2()
In-Reply-To: <CAGxFJbSDOwCschCboz+uJLiTuaMj8OvsXvyD-TW1R08Zdwhrqg@mail.gmail.com>
References: <013a01d2221f$40b46360$c21d2a20$@163.com>
	<CAHyGmd763iOdtg=n+EG5qjWELqPSWaDz8jtY4RcbK84i48XTkw@mail.gmail.com>
	<CAGxFJbSDOwCschCboz+uJLiTuaMj8OvsXvyD-TW1R08Zdwhrqg@mail.gmail.com>
Message-ID: <E4A983A8-363A-422E-9382-533CA6E8A8AA@gmail.com>


> On 10 Oct 2016, at 00:40 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Well... (inline -- and I hope this isn't homework!)
> 

Pretty much same as I thought. 

Fixing th=0.02 in the grid search looks wrong. Bert's plot is pretty linear, so th=1 is a good guesstimate. There's a slight curvature but to reduce it, you would increase th, not decrease it. Running the regression, as Bert suggests, indicates that b0=5.16 and b1= -0.00024 could work as reasonable starting values. Notice that the grid search had "b1 = seq(0.01, 4, by = 0.01)" which is wrong in both sign and scale.

Andrew's suggestion of dividing Retention by 100 is tempting, since it looks like a percentage, but that would make all Y values less than 1 and the double exponential function as written has values that are always bigger than 1. (It is conceivable that the model itself is wrong, though. E.g. it could be that Retention on a scale from 0 to 1 could be modeled as exp(-something), but we really have no idea of the context here.)

(If this was in fact homework, you should now go and write a proper SelfStart initializer routine for this model. Even if it isn't homework, you do need to study the text again, because you have clearly not understood how self-starting models work.)

-pd

> 
> 
> 
> On Sun, Oct 9, 2016 at 3:05 PM, Andrew Robinson
> <A.Robinson at ms.unimelb.edu.au> wrote:
>> Here are some things to try.  Maybe divide Area by 1000 and retention
>> by 100.  Try plotting the data and superimposing the line that
>> corresponds to the 'fit' from nls2.  See if you can correct it with
>> some careful guesses.
>> 
>> Getting suitable starting parameters for non-linear modeling is one of
>> the black arts of statistical fitting. ...
>> 
>> Andrew
> 
> True. But it's usually worthwhile thinking about the math a bit before guessing.
> 
> Note that the model can be linearized to:
> 
> log(log(Retention)) = b0 + b1*Area^th
> 
> So a plot of log(log(Retention)) vs Area may be informative and useful
> for finding starting values. e.g., for a grid of th's, do linear
> regression fits .
> 
> However, when I look at that plot, it seems pretty linear with a
> negative slope. This suggests that you may have an overparametrization
> problem . i.e. fix th =1 and use the b0 and b1 from the above
> regression for starting values.
> 
> Do note that this strategy isn't foolproof, as it ignores that the
> error term is additive in the above transformed metric, rather than
> the original. This can sometimes mislead. But this is just a
> heuristic.
> 
> Cheers,
> Bert
> 
> 
> 
> 
> 
> 
> 
>> 
>> On 9 October 2016 at 22:21, Pinglei Gao <gaopinglei at 163.com> wrote:
>>> Hi,
>>> 
>>> I have some data that i'm trying to fit a double exponential model: data.
>>> Frame (Area=c (521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91, 989.05,
>>> 1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 2629.2),
>>> 
>>> Retention=c (95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 23.46,
>>> 9.72, 97.92, 71.44, 44.52, 24.44, 15.26) ) and the formula of the double
>>> exponential is: exp (b0*exp (b1*x^th)).
>>> 
>>> 
>>> 
>>> I failed to guess the initial parameter values and then I learned a measure
>>> to find starting values from Nonlinear Regression with R (pp. 25-27):
>>> 
>>> 
>>> 
>>>> cl<-data.frame(Area =c(521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91,
>>> 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 2629.2),
>>> 
>>> + Retention =c(95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 23.46,
>>> 9.72, 97.92, 71.44, 44.52, 24.44, 15.26) )
>>> 
>>>> expFct <- function(Area, b0, b1,th) {exp(b0*exp(b1*Area^th))}
>>> 
>>>> grid.Disperse <- expand.grid(list(b0 = seq(0.01,4, by = 0.01), th =
>>> c(0.02),b1 = seq(0.01, 4, by = 0.01)))
>>> 
>>>> Disperse.m2a <- nls2(Retention ~expFct(Area, b0, b1,th), data = cl, start
>>> = grid.Disperse, algorithm = "brute-force")
>>> 
>>>> Disperse.m2a
>>> 
>>> Nonlinear regression model
>>> 
>>>  model: Retention ~ expFct(Area, b0, th, b1)
>>> 
>>>   data: cl
>>> 
>>> b0   th   b1
>>> 
>>> 3.82 0.02 0.01
>>> 
>>> residual sum-of-squares: 13596
>>> 
>>> Number of iterations to convergence: 160000
>>> 
>>> Achieved convergence tolerance: NA
>>> 
>>> 
>>> 
>>> I got no error then I use the output as starting values to nls2 ():
>>> 
>>>> nls.m2<- nls2(Retention ~ expFct(Area, b0, b1, th), data = cl, start =
>>> list(b0 = 3.82, b1 = 0.02, th = 0.01))
>>> 
>>> Error in (function (formula, data = parent.frame(), start, control =
>>> nls.control(),  :
>>> 
>>> Singular gradient
>>> 
>>> 
>>> 
>>> Why? Did I do something wrong or misunderstand something?
>>> 
>>> 
>>> 
>>> Later, I found another measure from Modern Applied Statistics with S (pp.
>>> 216-217):
>>> 
>>> 
>>> 
>>>> negexp <- selfStart(model = ~ exp(b0*exp(b1*x^th)),initial =
>>> negexp.SSival, parameters = c("b0", "b1", "th"),
>>> 
>>> + template = function(x, b0, b1, th) {})
>>> 
>>>> Disperse.ss <- nls(Retention ~ negexp(Area, b0, b1, th),data = cl, trace =
>>> T)
>>> 
>>>         b0          b1          th
>>> 
>>>   4.208763  144.205455 1035.324595
>>> 
>>> Error in qr.default(.swts * attr(rhs, "gradient")) :
>>> 
>>> NA/NaN/Inf (arg1) can not be called when the external function is called.
>>> 
>>> 
>>> 
>>> Error happened again. How can I fix it? I am desperate.
>>> 
>>> 
>>> 
>>> Best regards,
>>> 
>>> 
>>> 
>>> Pinglei Gao
>>> 
>>> 
>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> --
>> Andrew Robinson
>> Deputy Director, CEBRA, School of Biosciences
>> Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
>> School of Mathematics and Statistics                        Fax: +61-3-8344 4599
>> University of Melbourne, VIC 3010 Australia
>> Email: a.robinson at ms.unimelb.edu.au
>> Website: http://www.ms.unimelb.edu.au/~andrewpr
>> 
>> MSME: http://www.crcpress.com/product/isbn/9781439858028
>> FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
>> SPuR: http://www.ms.unimelb.edu.au/spuRs/
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From profjcnash at gmail.com  Mon Oct 10 02:14:36 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Sun, 9 Oct 2016 20:14:36 -0400
Subject: [R] Finding starting values for the parameters using nls() or
 nls2()
In-Reply-To: <E4A983A8-363A-422E-9382-533CA6E8A8AA@gmail.com>
References: <013a01d2221f$40b46360$c21d2a20$@163.com>
	<CAHyGmd763iOdtg=n+EG5qjWELqPSWaDz8jtY4RcbK84i48XTkw@mail.gmail.com>
	<CAGxFJbSDOwCschCboz+uJLiTuaMj8OvsXvyD-TW1R08Zdwhrqg@mail.gmail.com>
	<E4A983A8-363A-422E-9382-533CA6E8A8AA@gmail.com>
Message-ID: <e8368d85-d1ba-b7c4-0d5a-b135e6413254@gmail.com>

I didn't try very hard, but got a solution from .1, 1, .1 with nlxb() from nlmrt. It took a lot
of iterations and looks to be pretty ill-conditioned. Note nlmrt uses analytic derivatives if it
can, and a Marquardt method. It is designed to be a pit bull -- tenacious, not fast.

I'm working on a replacement for this and nls(), but it will be a while. However, I welcome
short scripts like this as tests. My script below

Best, JN

cl<-data.frame(Area =c(521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91,
989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 2629.2),

Retention =c(95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 23.46,
9.72, 97.92, 71.44, 44.52, 24.44, 15.26) )

expFct <- function(Area, b0, b1,th) {exp(b0*exp(b1*Area^th))}
expf2 <- "Retention ~ exp(b0*exp(b1*Area^th))"

# grid.Disperse <- expand.grid(list(b0 = seq(0.01,4, by = 0.01), th =
#c(0.02),b1 = seq(0.01, 4, by = 0.01)))

#> Disperse.m2a <- nls2(Retention ~expFct(Area, b0, b1,th), data = cl, start
#= grid.Disperse, algorithm = "brute-force")

# Disperse.m2a

library(nlmrt)
test <- nlxb(expf2, start= c(b0=.1, b1=1, th=.1), trace=TRUE, data=cl)



On 16-10-09 07:40 PM, peter dalgaard wrote:
> 
>> On 10 Oct 2016, at 00:40 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Well... (inline -- and I hope this isn't homework!)
>>
> 
> Pretty much same as I thought. 
> 
> Fixing th=0.02 in the grid search looks wrong. Bert's plot is pretty linear, so th=1 is a good guesstimate. There's a slight curvature but to reduce it, you would increase th, not decrease it. Running the regression, as Bert suggests, indicates that b0=5.16 and b1= -0.00024 could work as reasonable starting values. Notice that the grid search had "b1 = seq(0.01, 4, by = 0.01)" which is wrong in both sign and scale.
> 
> Andrew's suggestion of dividing Retention by 100 is tempting, since it looks like a percentage, but that would make all Y values less than 1 and the double exponential function as written has values that are always bigger than 1. (It is conceivable that the model itself is wrong, though. E.g. it could be that Retention on a scale from 0 to 1 could be modeled as exp(-something), but we really have no idea of the context here.)
> 
> (If this was in fact homework, you should now go and write a proper SelfStart initializer routine for this model. Even if it isn't homework, you do need to study the text again, because you have clearly not understood how self-starting models work.)
> 
> -pd
> 
>>
>>
>>
>> On Sun, Oct 9, 2016 at 3:05 PM, Andrew Robinson
>> <A.Robinson at ms.unimelb.edu.au> wrote:
>>> Here are some things to try.  Maybe divide Area by 1000 and retention
>>> by 100.  Try plotting the data and superimposing the line that
>>> corresponds to the 'fit' from nls2.  See if you can correct it with
>>> some careful guesses.
>>>
>>> Getting suitable starting parameters for non-linear modeling is one of
>>> the black arts of statistical fitting. ...
>>>
>>> Andrew
>>
>> True. But it's usually worthwhile thinking about the math a bit before guessing.
>>
>> Note that the model can be linearized to:
>>
>> log(log(Retention)) = b0 + b1*Area^th
>>
>> So a plot of log(log(Retention)) vs Area may be informative and useful
>> for finding starting values. e.g., for a grid of th's, do linear
>> regression fits .
>>
>> However, when I look at that plot, it seems pretty linear with a
>> negative slope. This suggests that you may have an overparametrization
>> problem . i.e. fix th =1 and use the b0 and b1 from the above
>> regression for starting values.
>>
>> Do note that this strategy isn't foolproof, as it ignores that the
>> error term is additive in the above transformed metric, rather than
>> the original. This can sometimes mislead. But this is just a
>> heuristic.
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>>
>>
>>
>>>
>>> On 9 October 2016 at 22:21, Pinglei Gao <gaopinglei at 163.com> wrote:
>>>> Hi,
>>>>
>>>> I have some data that i'm trying to fit a double exponential model: data.
>>>> Frame (Area=c (521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91, 989.05,
>>>> 1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 2629.2),
>>>>
>>>> Retention=c (95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 23.46,
>>>> 9.72, 97.92, 71.44, 44.52, 24.44, 15.26) ) and the formula of the double
>>>> exponential is: exp (b0*exp (b1*x^th)).
>>>>
>>>>
>>>>
>>>> I failed to guess the initial parameter values and then I learned a measure
>>>> to find starting values from Nonlinear Regression with R (pp. 25-27):
>>>>
>>>>
>>>>
>>>>> cl<-data.frame(Area =c(521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91,
>>>> 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 2629.2),
>>>>
>>>> + Retention =c(95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 23.46,
>>>> 9.72, 97.92, 71.44, 44.52, 24.44, 15.26) )
>>>>
>>>>> expFct <- function(Area, b0, b1,th) {exp(b0*exp(b1*Area^th))}
>>>>
>>>>> grid.Disperse <- expand.grid(list(b0 = seq(0.01,4, by = 0.01), th =
>>>> c(0.02),b1 = seq(0.01, 4, by = 0.01)))
>>>>
>>>>> Disperse.m2a <- nls2(Retention ~expFct(Area, b0, b1,th), data = cl, start
>>>> = grid.Disperse, algorithm = "brute-force")
>>>>
>>>>> Disperse.m2a
>>>>
>>>> Nonlinear regression model
>>>>
>>>>  model: Retention ~ expFct(Area, b0, th, b1)
>>>>
>>>>   data: cl
>>>>
>>>> b0   th   b1
>>>>
>>>> 3.82 0.02 0.01
>>>>
>>>> residual sum-of-squares: 13596
>>>>
>>>> Number of iterations to convergence: 160000
>>>>
>>>> Achieved convergence tolerance: NA
>>>>
>>>>
>>>>
>>>> I got no error then I use the output as starting values to nls2 ():
>>>>
>>>>> nls.m2<- nls2(Retention ~ expFct(Area, b0, b1, th), data = cl, start =
>>>> list(b0 = 3.82, b1 = 0.02, th = 0.01))
>>>>
>>>> Error in (function (formula, data = parent.frame(), start, control =
>>>> nls.control(),  :
>>>>
>>>> Singular gradient
>>>>
>>>>
>>>>
>>>> Why? Did I do something wrong or misunderstand something?
>>>>
>>>>
>>>>
>>>> Later, I found another measure from Modern Applied Statistics with S (pp.
>>>> 216-217):
>>>>
>>>>
>>>>
>>>>> negexp <- selfStart(model = ~ exp(b0*exp(b1*x^th)),initial =
>>>> negexp.SSival, parameters = c("b0", "b1", "th"),
>>>>
>>>> + template = function(x, b0, b1, th) {})
>>>>
>>>>> Disperse.ss <- nls(Retention ~ negexp(Area, b0, b1, th),data = cl, trace =
>>>> T)
>>>>
>>>>         b0          b1          th
>>>>
>>>>   4.208763  144.205455 1035.324595
>>>>
>>>> Error in qr.default(.swts * attr(rhs, "gradient")) :
>>>>
>>>> NA/NaN/Inf (arg1) can not be called when the external function is called.
>>>>
>>>>
>>>>
>>>> Error happened again. How can I fix it? I am desperate.
>>>>
>>>>
>>>>
>>>> Best regards,
>>>>
>>>>
>>>>
>>>> Pinglei Gao
>>>>
>>>>
>>>>
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>> --
>>> Andrew Robinson
>>> Deputy Director, CEBRA, School of Biosciences
>>> Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
>>> School of Mathematics and Statistics                        Fax: +61-3-8344 4599
>>> University of Melbourne, VIC 3010 Australia
>>> Email: a.robinson at ms.unimelb.edu.au
>>> Website: http://www.ms.unimelb.edu.au/~andrewpr
>>>
>>> MSME: http://www.crcpress.com/product/isbn/9781439858028
>>> FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
>>> SPuR: http://www.ms.unimelb.edu.au/spuRs/
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From klebyn at yahoo.com.br  Mon Oct 10 02:59:34 2016
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Sun, 9 Oct 2016 21:59:34 -0300
Subject: [R] pure TCL run a command within the R via the tcltk package?
Message-ID: <149fc6fc-ed68-08aa-23cf-c996eacb33e1@yahoo.com.br>

Dear,
is there any way of a button on pure TCL run a command within the R via 
the tcltk package?
thank you in advance for informations
cleber
what I have in mind is something like:  (below)
##########################################################################################
sink("simpletest.tcl")
cat('
toplevel .t
button .t.b -text "but" -command {"some tcltk command for push data into R"}
checkbutton .t.c -text "ck1" -variable "chkvar"
pack .t.b
pack .t.c '
)
sink()

library( tcltk )
#tcl('set', 'argc', '0')
#tcl('set', 'argv', '0')
tcl('source', "simpletest.tcl" )

 > tclvalue('chkvar')
[1] "1"
 > tclvalue('chkvar') # after click in screen
[1] "0"
 >

### after click in button  get error:

invalid command name "some tcltk command for push data into R"
invalid command name "some tcltk command for push data into R"
     while executing
""some tcltk command for push data into R""
     invoked from within
".t.b invoke"
     ("uplevel" body line 1)
     invoked from within
"uplevel #0 [list $w invoke]"
     (procedure "tk::ButtonUp" line 24)
     invoked from within
"tk::ButtonUp .t.b"
     (command bound to event)
  ##########################################################################################
 > sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7600)

locale:
[1] LC_COLLATE=Portuguese_Brazil.1252 LC_CTYPE=Portuguese_Brazil.1252
[3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C
[5] LC_TIME=Portuguese_Brazil.1252

attached base packages:
[1] tcltk     stats     graphics  grDevices utils     datasets methods   
base
 >



---
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus


From ggrothendieck at gmail.com  Mon Oct 10 03:24:02 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 9 Oct 2016 21:24:02 -0400
Subject: [R] Finding starting values for the parameters using nls() or
	nls2()
In-Reply-To: <CAP01uR=+H_Vf_DQGBx9=WsN0TU3itDQPqr1=cLV+o9snxQjL1A@mail.gmail.com>
References: <013a01d2221f$40b46360$c21d2a20$@163.com>
	<CAP01uR=+H_Vf_DQGBx9=WsN0TU3itDQPqr1=cLV+o9snxQjL1A@mail.gmail.com>
Message-ID: <CAP01uR=E9asrPMJ24rY6k=Z0QA7uqsvH49-VGjV0KVD-Dru+uQ@mail.gmail.com>

If you are not tied to that model the SSasymp() model in R could be
considered and is easy to fit:

    # to plot points in order
    o <- order(cl$Area)
    cl.o <- cl[o, ]

    fm <- nls(Retention ~ SSasymp(Area, Asym, R0, lrc), cl.o)
    summary(fm)

    plot(Retention ~ Area, cl.o)
    lines(fitted(fm) ~ Area, cl.o, col = "red")


From profjcnash at gmail.com  Mon Oct 10 04:37:40 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Sun, 9 Oct 2016 22:37:40 -0400
Subject: [R] Finding starting values for the parameters using nls() or
 nls2()
In-Reply-To: <CAP01uR=E9asrPMJ24rY6k=Z0QA7uqsvH49-VGjV0KVD-Dru+uQ@mail.gmail.com>
References: <013a01d2221f$40b46360$c21d2a20$@163.com>
	<CAP01uR=+H_Vf_DQGBx9=WsN0TU3itDQPqr1=cLV+o9snxQjL1A@mail.gmail.com>
	<CAP01uR=E9asrPMJ24rY6k=Z0QA7uqsvH49-VGjV0KVD-Dru+uQ@mail.gmail.com>
Message-ID: <5da99b85-501f-6565-0ae0-33195baeaa68@gmail.com>

Despite nlmrt "solving" the OP's problem, I think Gabor's suggestion likely gives a more sensible approach
to the underlying modelling problem.

It is, of course, sometimes important to fit a particular model, in which case nls2 and nlmrt are set up to grind away.
And hopefully the follow-up to nlmrt I'm working on will have enough capability in getting analytic derivatives
to work for a wider class of models. Note that functional approaches in nlmrt and minpack.lm allow users to
provide derivatives. Too many users think numerical approximations are a panacea, but my experience is that
most problems benefit from very accurate derivatives, of which analytic expressions are generally the best.

JN

On 16-10-09 09:24 PM, Gabor Grothendieck wrote:
> If you are not tied to that model the SSasymp() model in R could be
> considered and is easy to fit:
> 
>     # to plot points in order
>     o <- order(cl$Area)
>     cl.o <- cl[o, ]
> 
>     fm <- nls(Retention ~ SSasymp(Area, Asym, R0, lrc), cl.o)
>     summary(fm)
> 
>     plot(Retention ~ Area, cl.o)
>     lines(fitted(fm) ~ Area, cl.o, col = "red")
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From c.puschmann at student.unsw.edu.au  Mon Oct 10 09:33:52 2016
From: c.puschmann at student.unsw.edu.au (Christoph Puschmann)
Date: Mon, 10 Oct 2016 07:33:52 +0000
Subject: [R] Loop to check for large dataset
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5040CB5@SRVEXCHMBX.precheza.cz>
References: <4FCBB54C-C002-43DE-ABA3-BBCD01F24DE9@ad.unsw.edu.au>
	<CAJ=0CtBK6MnmmJ4EzVei=G4Yzj_kCRctMke-mF7xAc-cgNYWBw@mail.gmail.com>
	<9C546083-5909-4EFE-B102-225FAA94A6B7@ad.unsw.edu.au>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5040CB5@SRVEXCHMBX.precheza.cz>
Message-ID: <BAF1D80E-C999-475A-B1BF-6418FA0DED4A@ad.unsw.edu.au>

Dear Petr,

I attached a sample file, which contains the first 4 products.

It is more that I have: 157 weeks, 19 different Stores and 22 products: 157*19*22 = 65,626 rows. And as I sated I have roughly 63,127 rows. (so some have to be missing).

All the best,

Christoph


From petr.pikal at precheza.cz  Mon Oct 10 08:27:18 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 10 Oct 2016 06:27:18 +0000
Subject: [R] Loop to check for large dataset
In-Reply-To: <9C546083-5909-4EFE-B102-225FAA94A6B7@ad.unsw.edu.au>
References: <4FCBB54C-C002-43DE-ABA3-BBCD01F24DE9@ad.unsw.edu.au>
	<CAJ=0CtBK6MnmmJ4EzVei=G4Yzj_kCRctMke-mF7xAc-cgNYWBw@mail.gmail.com>
	<9C546083-5909-4EFE-B102-225FAA94A6B7@ad.unsw.edu.au>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5040CB5@SRVEXCHMBX.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Christoph
> Puschmann
> Sent: Sunday, October 9, 2016 1:27 AM
> To: Adrian Du?a <dusa.adrian at unibuc.ro>
> Cc: r-help at r-project.org; Christoph Puschmann
> <c.puschmann at student.unsw.edu.au>
> Subject: Re: [R] Loop to check for large dataset
>
> Dear Adrian,
>
> Yes it is a cyclical data set and theoretically it should repeat this interval until
> 61327. The data set itself is divided into 2 Parts:
> 1. Product category (column 10)
> 2. Number of Stores Participating (column 01) Overall there are 22 different
> products and in each you have 19 different stores participating. And
> theoretically each store over each product category should have a 1 - 157
> week interval.

Not much clearer and definitely not reproducible.

From what I understand you have 22*19= 418 combinations of product/store. How do you want to put these 418 combinations into 157 rows?

It seems to me that it can be somehow done with aggregate function, however without some small reproducible example we are fishing in murky water.

Try to post data with let say 3 stores and 4 products to explain how your data is structured and what is or is not correct.

Cheers
Petr

>
> The part I am struggling with is how do I run a loop over the whole data set,
> while checking if all stores participated 157 weeks over the different
> products.
>
> So far I came up with this:
>
> n=61327                           # Generate Matrix to check for values
> Control = matrix(
>   0,
>   nrow = n,
>   ncol = 1)
>
> s <- seq(from =1 , to = 157, by = 1)
> CW = matrix(
>   s,
>   nrow = 157,
>   ncol = 1
> )
>
> colnames(CW)[1] <- ?s'
>
> CW = as.data.frame(CW)
>
> for (i in 1:nrow(FD)) {           # Let run trhough all the rows
>   for (j in 1:157) {
> if(FD$WEEk[j] == C$s[j]) {
>   Control[i] = 1                 # coresponding control row = 1
> } else {
>   Control[i] = 0                 # corresponding control row = 0
> }
> }
> }
>
> I coded a  MRE and attached an sample of my data set.
>
> MRE:
>
> #MRE
>
> dat <- data.frame(
>   Store = c(rep(8, times = 157), rep(12, times = 157)),  # Number of stores
>   WEEK = rep(seq(from=1, to = 157, by = 1), times = 2)
> )
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Mon Oct 10 11:00:39 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 10 Oct 2016 09:00:39 +0000
Subject: [R] Loop to check for large dataset
In-Reply-To: <BAF1D80E-C999-475A-B1BF-6418FA0DED4A@ad.unsw.edu.au>
References: <4FCBB54C-C002-43DE-ABA3-BBCD01F24DE9@ad.unsw.edu.au>
	<CAJ=0CtBK6MnmmJ4EzVei=G4Yzj_kCRctMke-mF7xAc-cgNYWBw@mail.gmail.com>
	<9C546083-5909-4EFE-B102-225FAA94A6B7@ad.unsw.edu.au>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5040CB5@SRVEXCHMBX.precheza.cz>
	<BAF1D80E-C999-475A-B1BF-6418FA0DED4A@ad.unsw.edu.au>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5040D9C@SRVEXCHMBX.precheza.cz>

Hi

I named your data test

res <- xtabs(~STORE+WEEK+Description, data=test)

should give you values in which there is for given Description WEEK and STORE missing.

you can select week and store by

which(res[, ,1]==0, arr.ind=T)

for description 1 and so on.

Another option is to generate full set STORE, WEEK and description and merge it with original data by merge.

Cheers
Petr

From: Christoph Puschmann [mailto:c.puschmann at student.unsw.edu.au]
Sent: Monday, October 10, 2016 9:34 AM
To: PIKAL Petr <petr.pikal at precheza.cz>; r-help at r-project.org
Subject: Re: [R] Loop to check for large dataset

Dear Petr,

I attached a sample file, which contains the first 4 products.

It is more that I have: 157 weeks, 19 different Stores and 22 products: 157*19*22 = 65,626 rows. And as I sated I have roughly 63,127 rows. (so some have to be missing).

All the best,

Christoph


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From silvia1.giussani at gmail.com  Fri Oct  7 18:57:58 2016
From: silvia1.giussani at gmail.com (silvia giussani)
Date: Fri, 7 Oct 2016 18:57:58 +0200
Subject: [R]  turning comma separated string from multiple choices into
Message-ID: <CAFY_TcTzCbssFhwRrfHK2oAQ1iDQdgzbaTMEpFjVvVUcy-o78Q@mail.gmail.com>

Hi all,



could you please tell me if you find a solution to this problem (in
Subject)?



June Kim wrote:

>* Hello,*

>

>* I use google docs' Forms to conduct surveys online. Multiple choices*

>* questions are coded as comma separated values.*

>

>* For example,*

>

>* if the question is like:*

>

>* 1. What magazines do you currently subscribe to? (you can choose*

>* multiple choices)*

>* 1) Fast Company*

>* 2) Havard Business Review*

>* 3) Business Week*

>* 4) The Economist*

>

>* And if the subject chose 1) and 3), the data is coded as a cell in a*

>* spreadsheet as,*

>

>* "Fast Company, Business Week"*

>

>* I read the data with read.csv into R. To analyze the data, I have to*

>* change that string into something like flags(indicator variables?).*

>* That is, there should be 4 variables, of which values are either 1 or*

>* 0, indicating chosen or not-chosen respectively.*

>

>* Suppose the data is something like,*

>

>

>>* survey1*

>>

>*   age                                    favorite_magazine*

>* 1  29                                         Fast Company*

>* 2  31                          Fast Company, Business Week*

>* 3  32 Havard Business Review, Business Week, The Economist*

>

>

>* Then I have to chop the string in favorite_magazine column to turn*

>* that data into something like,*

>

>

>>* survey1transformed*

>>

>*   age Fast Company Havard Business Review Business Week The Economist*

>* 1  29            1                      0             0             0*

>* 2  31            1                      0             1             0*

>* 3  32            0                      1             1             1*

>

>

>* Actually I have many more multiple choice questions in the survey.*

>

>* What is the easy elegant and natural way in R to do the job?*

>



I'd look into something like as.data.frame(lapply(strings, grep,

x=favorite_magazine, fixed=TRUE)), where strings <- c("Fast Company",

"Havard Business Review", ...).



(I take it that the mechanism is such that you can rely on at least

having everything misspelled in the same way? If it is alternatingly

"Havard" and "Harvard", then things get a bit trickier.)



Thank you and regards,

Silvia Giussani

	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Mon Oct 10 12:25:46 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Mon, 10 Oct 2016 13:25:46 +0300
Subject: [R] Loop to check for large dataset
In-Reply-To: <9C546083-5909-4EFE-B102-225FAA94A6B7@ad.unsw.edu.au>
References: <4FCBB54C-C002-43DE-ABA3-BBCD01F24DE9@ad.unsw.edu.au>
	<CAJ=0CtBK6MnmmJ4EzVei=G4Yzj_kCRctMke-mF7xAc-cgNYWBw@mail.gmail.com>
	<9C546083-5909-4EFE-B102-225FAA94A6B7@ad.unsw.edu.au>
Message-ID: <CAJ=0CtDs+MvYMLi=gfR211C9NOx2xtrKNQBjW2o=_rHfsWGdAw@mail.gmail.com>

This is an example of how a reproducible code looks like, assuming you have
three columns in your dataset named S (store), P (product) and W (week),
and also assuming they have integer values from 1 to 19, 1 to 22 and 1 to
157 respectively:

#########

mydata <- expand.grid(seq(19), seq(22), seq(157))
names(mydata) <- c("S", "P", "W")

# randomly delete 65626 - 63127 = 2499 rows
set.seed(12345) # make it replicable

mydata <- mydata[-sample(seq(nrow(mydata)), nrow(mydata) - 63127), ]

#########


Now the dataframe mydata contains exactly 63127 rows, just as in your case.
The task is to find which weeks are missing, from which store and for which
product.
Below is a possible code to do that. Given you have a small number of
stores and products, I'll keep it simple and stupid, by using for loops:


#########

result <- matrix(nrow = 0, ncol = 3)

for (i in seq(19)) {
    for (j in seq(22)) {
        miss <- setdiff(seq(157), mydata$W[mydata$S == i & mydata$P == j])
        if (length(miss) > 0) {
            result <- rbind(result, cbind(S = i, P = j, W = miss))
        }
    }
}

# The result matrix contains 2499 rows that are missing.

> head(result)
     S P   W
[1,] 1 1  10
[2,] 1 1  11
[3,] 1 1  82
[4,] 1 1 100
[5,] 1 1 117
[6,] 1 1 148

#########


In this example, for S(tore) number 1 and P(roduct) number 1, you are
missing W(eek) 10, 11, 82 and so on.

In hoping you can adapt this code to your particular example,
Adrian


On Sun, Oct 9, 2016 at 2:26 AM, Christoph Puschmann <
c.puschmann at student.unsw.edu.au> wrote:
>
> Dear Adrian,
>
> Yes it is a cyclical data set and theoretically it should repeat this
interval until 61327. The data set itself is divided into 2 Parts:
> 1. Product category (column 10)
> 2. Number of Stores Participating (column 01)
> Overall there are 22 different products and in each you have 19 different
stores participating. And theoretically each store over each product
category should have a 1 - 157 week interval.
>
> The part I am struggling with is how do I run a loop over the whole data
set, while checking if all stores participated 157 weeks over the different
products.
>
> So far I came up with this:
>
> n=61327                           # Generate Matrix to check for values
> Control = matrix(
>   0,
>   nrow = n,
>   ncol = 1)
>
> s <- seq(from =1 , to = 157, by = 1)
> CW = matrix(
>   s,
>   nrow = 157,
>   ncol = 1
> )
>
> colnames(CW)[1] <- ?s'
>
> CW = as.data.frame(CW)
>
> for (i in 1:nrow(FD)) {           # Let run trhough all the rows
>   for (j in 1:157) {
> if(FD$WEEk[j] == C$s[j]) {
>   Control[i] = 1                 # coresponding control row = 1
> } else {
>   Control[i] = 0                 # corresponding control row = 0
> }
> }
> }
>
> I coded a  MRE and attached an sample of my data set.
>
> MRE:
>
> #MRE
>
> dat <- data.frame(
>   Store = c(rep(8, times = 157), rep(12, times = 157)),  # Number of
stores
>   WEEK = rep(seq(from=1, to = 157, by = 1), times = 2)
> )
>
>
>
>



--
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Oct 10 12:44:25 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 10 Oct 2016 10:44:25 +0000
Subject: [R] Loop to check for large dataset
In-Reply-To: <CAJ=0CtDs+MvYMLi=gfR211C9NOx2xtrKNQBjW2o=_rHfsWGdAw@mail.gmail.com>
References: <4FCBB54C-C002-43DE-ABA3-BBCD01F24DE9@ad.unsw.edu.au>
	<CAJ=0CtBK6MnmmJ4EzVei=G4Yzj_kCRctMke-mF7xAc-cgNYWBw@mail.gmail.com>
	<9C546083-5909-4EFE-B102-225FAA94A6B7@ad.unsw.edu.au>
	<CAJ=0CtDs+MvYMLi=gfR211C9NOx2xtrKNQBjW2o=_rHfsWGdAw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5040E27@SRVEXCHMBX.precheza.cz>

Hi

Given this example data, you can get same answer with less typing and without loops.

res<-xtabs(~W+P+S,mydata)
res1<-which(res==0, arr.ind=T)
head(res1)
      W P S
10   10 1 1
11   11 1 1
82   82 1 1
100 100 1 1
117 117 1 1
148 148 1 1

Cheers
Petr


From: dusa.adrian at gmail.com [mailto:dusa.adrian at gmail.com] On Behalf Of Adrian Du?a
Sent: Monday, October 10, 2016 12:26 PM
To: Christoph Puschmann <c.puschmann at student.unsw.edu.au>
Cc: r-help at r-project.org; PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] Loop to check for large dataset

This is an example of how a reproducible code looks like, assuming you have three columns in your dataset named S (store), P (product) and W (week), and also assuming they have integer values from 1 to 19, 1 to 22 and 1 to 157 respectively:

#########
mydata <- expand.grid(seq(19), seq(22), seq(157))
names(mydata) <- c("S", "P", "W")

# randomly delete 65626 - 63127 = 2499 rows
set.seed(12345) # make it replicable
mydata <- mydata[-sample(seq(nrow(mydata)), nrow(mydata) - 63127), ]
#########


Now the dataframe mydata contains exactly 63127 rows, just as in your case. The task is to find which weeks are missing, from which store and for which product.
Below is a possible code to do that. Given you have a small number of stores and products, I'll keep it simple and stupid, by using for loops:


#########

result <- matrix(nrow = 0, ncol = 3)

for (i in seq(19)) {
    for (j in seq(22)) {
        miss <- setdiff(seq(157), mydata$W[mydata$S == i & mydata$P == j])
        if (length(miss) > 0) {
            result <- rbind(result, cbind(S = i, P = j, W = miss))
        }
    }
}

# The result matrix contains 2499 rows that are missing.

> head(result)
     S P   W
[1,] 1 1  10
[2,] 1 1  11
[3,] 1 1  82
[4,] 1 1 100
[5,] 1 1 117
[6,] 1 1 148

#########


In this example, for S(tore) number 1 and P(roduct) number 1, you are missing W(eek) 10, 11, 82 and so on.

In hoping you can adapt this code to your particular example,
Adrian


On Sun, Oct 9, 2016 at 2:26 AM, Christoph Puschmann <c.puschmann at student.unsw.edu.au<mailto:c.puschmann at student.unsw.edu.au>> wrote:
>
> Dear Adrian,
>
> Yes it is a cyclical data set and theoretically it should repeat this interval until 61327. The data set itself is divided into 2 Parts:
> 1. Product category (column 10)
> 2. Number of Stores Participating (column 01)
> Overall there are 22 different products and in each you have 19 different stores participating. And theoretically each store over each product category should have a 1 - 157 week interval.
>
> The part I am struggling with is how do I run a loop over the whole data set, while checking if all stores participated 157 weeks over the different products.
>
> So far I came up with this:
>
> n=61327                           # Generate Matrix to check for values
> Control = matrix(
>   0,
>   nrow = n,
>   ncol = 1)
>
> s <- seq(from =1 , to = 157, by = 1)
> CW = matrix(
>   s,
>   nrow = 157,
>   ncol = 1
> )
>
> colnames(CW)[1] <- ?s'
>
> CW = as.data.frame(CW)
>
> for (i in 1:nrow(FD)) {           # Let run trhough all the rows
>   for (j in 1:157) {
> if(FD$WEEk[j] == C$s[j]) {
>   Control[i] = 1                 # coresponding control row = 1
> } else {
>   Control[i] = 0                 # corresponding control row = 0
> }
> }
> }
>
> I coded a  MRE and attached an sample of my data set.
>
> MRE:
>
> #MRE
>
> dat <- data.frame(
>   Store = c(rep(8, times = 157), rep(12, times = 157)),  # Number of stores
>   WEEK = rep(seq(from=1, to = 157, by = 1), times = 2)
> )
>
>
>
>



--
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From francois.vieille at mel.lincoln.fr  Mon Oct 10 11:30:44 2016
From: francois.vieille at mel.lincoln.fr (Francois vieille)
Date: Mon, 10 Oct 2016 11:30:44 +0200
Subject: [R] [R-pkgs] aVirtualTwins available on CRAN
Message-ID: <D28EF69F27EB064FA9FD0F5F09ADFCE517203923E9@srv-exchange.lincoln-outils.fr>


[markdown format]

I'm glad to introduce you the new package aVirtualTwins. This package is an adaptation of VirtualTwins method of subgroup identification from [Foster, J. C., Taylor, J. M.G. and Ruberg, S. J. (2011)](http://onlinelibrary.wiley.com/doi/10.1002/sim.4322/abstract).

### Explanation

Virtual Twins has been created to find subgroup of patients in a random clinical trial with enhanced treatment effect, if it exists. Theorically, this method can be used for binary and continous outcome. This package only deals with binary outcome in a two arms clinical trial.

Virutal Twins is also adapted for A/B testing of course.

Virtual Twins is based on random forest and regression/classification trees.

### Quick preview

Here's a example of aVirtualTwins use with a well known dataset (_sepsis_) in subgroup decovery:

_Sepsis_ contains simulated data on 470 subjects with a binary outcome survival, that stores survival status for patient after 28 days of treatment, value of 1 for subjects who died after 28 days and 0 otherwise. There are 11 covariates, listed below, all of which are numerical variables.


```r
library(aVirtualTwins)

# Load data
data(sepsis)
# Format data
vt.obj <- vt.data(dataset         = sepsis,
                  outcome.field   = "survival",
                  treatment.field = "THERAPY",
                  interactions    = TRUE)
## "1" will be the favorable outcome
# view of data
head(sepsis)
##   survival THERAPY PRAPACHE    AGE BLGCS ORGANNUM   BLIL6  BLLPLAT
## 1        0       1       19 42.921    15        1  301.80 191.0000
## 2        1       1       48 68.818    11        2  118.90 264.1565
## 3        0       1       20 68.818    15        2   92.80 123.0000
## 4        0       1       19 33.174    14        2 1232.00 244.0000
## 5        0       1       48 46.532     3        4 2568.00  45.0000
## 6        0       0       21 56.098    14        1  162.65 137.0000
##    BLLBILI BLLCREAT TIMFIRST BLADL blSOFA
## 1 2.913416 1.000000    17.17     0   5.00
## 2 0.400000 1.100000    17.17     5  10.00
## 3 5.116471 1.000000    10.00     1   7.50
## 4 3.142092 1.200000    17.17     0   6.25
## 5 4.052668 3.000000    10.00     0  12.00
## 6 0.500000 4.662556    10.00     0   8.75
# Print Incidences of sepsis data
vt.obj$getIncidences()
## $table
##            trt
## resp        0    1     sum  
##   0         101  188   289  
##   1         52   129   181  
##   sum       153  317   470  
##   Incidence 0.34 0.407 0.385
## 
## $rr
## [1] 1.197059
# $table
#            trt
# resp        0    1     sum  
#   0         101  188   289  
#   1         52   129   181  
#   sum       153  317   470  
#   Incidence 0.34 0.407 0.385
#
# $rr
# [1] 1.197059
#

# First step : create random forest model
vt.for <- vt.forest(forest.type  = "one",
                    vt.data      = vt.obj,
                    interactions = TRUE,
                    ntree        = 500)
# Second step : find rules in data 
vt.trees <- vt.tree(tree.type = "class",
                    vt.difft  = vt.for, 
                    threshold = quantile(vt.for$difft, seq(.5,.8,.1)),
                    maxdepth  = 2)
# Print results
vt.sbgrps <- vt.subgroups(vt.trees)
knitr::kable(vt.sbgrps)
```

        Subgroup                      Subgroup size   Treatement event rate   Control event rate   Treatment sample size   Control sample size    RR (resub)   RR (snd)
------  ----------------------------  --------------  ----------------------  -------------------  ----------------------  --------------------  -----------  ---------
tree1   PRAPACHE>=26.5                157             0.752                   0.327                105                     52                          2.300      1.774
tree3   PRAPACHE>=26.5 & AGE>=51.74   120             0.897                   0.31                 78                      42                          2.894      1.924


aVirtualTwins can be found on [CRAN](https://cran.r-project.org/package=aVirtualTwins) and [github](https://github.com/prise6/aVirtualTwins). Feel free to contribute.

Francois.

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From stefan.schroedl at gmx.de  Wed Oct  5 06:46:42 2016
From: stefan.schroedl at gmx.de (=?UTF-8?Q?=22Stefan_Schr=C3=B6dl=22?=)
Date: Wed, 5 Oct 2016 06:46:42 +0200
Subject: [R] [R-pkgs] New Package: Plotluck
In-Reply-To: <mailman.0.1475642105.27394.r-packages@r-project.org>
References: <mailman.0.1475642105.27394.r-packages@r-project.org>
Message-ID: <trinity-ac927d4e-f330-4cd3-b5e2-c9a63689042b-1475642802266@3capp-gmx-bs26>


Dear useRs,

I am happy to announce that my package "plotluck" is now on CRAN:
[1]https://cran.r-project.org/web/packages/plotluck/

The aim of the package is to let the user focus on what to plot, rather than on
 the "how" during exploratory data analysis. Based on  the characteristics of a
 data frame and a formula, it tries to automatically choose the most suitable t
ype of plot (supported options are scatter, violin, box, bar, density, hexagon
bin, spine plot, and heat map). It also automates handling of observation weigh
ts, logarithmic axis scaling, reordering of factor levels, and overlaying smoot
hing curves and median lines. Plots are drawn using 'ggplot2'. Please see the v
ignette for some examples.

I welcome all feedback, suggestions, bug reports and feature requests.
Thank you!


   - Stefan

References

   1. https://cran.r-project.org/web/packages/plotluck/
_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From johanlarsson at outlook.com  Mon Oct 10 08:33:07 2016
From: johanlarsson at outlook.com (Johan Larsson)
Date: Mon, 10 Oct 2016 06:33:07 +0000
Subject: [R] [R-pkgs] Announcing qualpalr 0.2.1
Message-ID: <AM5PR0801MB1732DF4DA9D81DE41665BAFFC0DB0@AM5PR0801MB1732.eurprd08.prod.outlook.com>

Dear R users,

I would like to announce an updated version of qualpalr:

https://cran.r-project.org/package=qualpalr

qualpalr uses color difference equations to generate distinct qualitative color palettes for use in R graphics. Version 0.2.1 has been redesigned to use a better, more efficient optimization method and moreover introduces methods to adapt palettes to color blindness.

Please see the vignette (https://cran.r-project.org/web/packages/qualpalr/vignettes/introduction.html) if you'd like to learn more or visit the repository on GitHub (https://github.com/jolars/qualpalr) if you want to contribute.
All the best,
Johan

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From profjcnash at gmail.com  Mon Oct 10 17:26:40 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Mon, 10 Oct 2016 11:26:40 -0400
Subject: [R] Finding starting values for the parameters using nls() or
 nls2()
In-Reply-To: <000a01d22304$70edce00$52c96a00$@163.com>
References: <000a01d22304$70edce00$52c96a00$@163.com>
Message-ID: <7397bfe9-c366-0292-95e0-bbb86e3159cc@gmail.com>

The key lines are

library(nlmrt)
test <- nlxb(expf2, start= c(b0=.1, b1=1, th=.1), trace=TRUE, data=cl)

Thus I started with .1 1 and .1. The "solution" from nlxb, which is using analytic derivatives
and a very aggressive Marquardt code to keep trying even in bad situations, was
as you included below. Note that the singular values of the Jacobian are given (they are
recorded on the same table as the parameters, but do NOT correspond to the parameters.
The placement was simply a tidy place to put these numbers.)

The ratio of these sv's is 1.735e+16/0.004635 or approx 4E+18, so the condition number
of the traditional Gauss Newton approach is about 1E+37. Not a nice problem!

You probably should reformulate.

JN




On 16-10-10 10:41 AM, Pinglei Gao wrote:
> Thanks very much for your kindness help. I run your script then came out
> lots of outputs and I also studied the solution you posted. Forgive my
> ignorance, I still can't find the suitable starting values. Did I
> misunderstand something?
> 
> Best,
> 
> Pinglei Gao
> 
> -----????-----
> ???: ProfJCNash [mailto:profjcnash at gmail.com] 
> ????: 2016?10?10? 10:41
> ???: Gabor Grothendieck; Pinglei Gao
> ??: Re: [R] Finding starting values for the parameters using nls() or
> nls2()
> 
> I forgot to post the "solution" found by nlmrt:
> 
> nlmrt class object: x
> residual sumsquares =  1086.8  on  15 observations
>     after  5001    Jacobian and  6991 function evaluations
>   name            coeff          SE       tstat      pval      gradient
> JSingval
> b0            5.3274e-14            NA         NA         NA  -6.614e+13
> 1.735e+16
> b1               33.5574            NA         NA         NA      -3.466
> 11518
> th           -0.00721203            NA         NA         NA      -740.8
> 0.004635
> 
> 
> Note the singular values -- this is the worst SV(max)/SV(min) ratio I've
> observed!
> 
> JN
> 
> 
>


From highstat at highstat.com  Mon Oct 10 17:57:41 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 10 Oct 2016 16:57:41 +0100
Subject: [R] Stats course in Montreal
Message-ID: <430dbe2a-3951-7ae6-fd58-be46eec07f8b@highstat.com>


We would like to announce the following statistics course:

Course: Data exploration, regression, GLM & GAM with R

Where:  Montreal, Canada

When:   9-13 January 2017

Course website: http://www.highstat.com/statscourse.htm

Course flyer: 
http://highstat.com/Courses/Flyers/Flyer2017_01Montreal_RGG.pdf


Kind regards,

Alain Zuur


Other open courses in 2017:

Data exploration, regression, GLM & GAM with introduction to R. 13-17 
February 2017. Lisbon.
Introduction to Regression Models with Spatial and Temporal Correlation. 
20-24 February 2017. Lisbon.
Introduction to Regression Models with Spatial and Temporal Correlation. 
8-12 May 2017. Genoa.
Linear Mixed Effects Models and GLMM with R. Frequentist and Bayesian 
approaches. 9-13 October 2017. Trondheim.
Introduction to Regression Models with Spatial and Temporal Correlation. 
23-27 October 2017. Southampton


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com


	[[alternative HTML version deleted]]


From pgmandava at yahoo.com  Mon Oct 10 16:03:17 2016
From: pgmandava at yahoo.com (Pitch Mandava)
Date: Mon, 10 Oct 2016 14:03:17 +0000 (UTC)
Subject: [R] Having trouble with running ldBands in Hmisc package. Posted in
 StackExchange
References: <1840244298.2113148.1476108197936.ref@mail.yahoo.com>
Message-ID: <1840244298.2113148.1476108197936@mail.yahoo.com>

I am trying to run the example from Hmisc package in RStudio environment under Windows 10 and downloaded ld98.exe> .libPaths()Produces the following output[1] "C:/Users/username/X1_Carbon/Documents/R/win-library/3.2"[2] "C:/Program Files/R/R-3.2.5/library"I moved the ld98.exe to C:/Users/username/X1_Carbon/Documents/R/win-library/3.2Then installed Hmisc and ran the following> require(Hmisc)
> b <- ldBands(5, pr=FALSE)Produces the followingError: could not find function "ldBands"To see if ld98.exe is working in the directory I ran the ld98.exe in the Windows environment I get the following outputProgram for computations related to group sequential boundaries using spending functions.Is this an interactive session? (1=yes,0=no)yes interactive = 1etc.....
	[[alternative HTML version deleted]]


From gaopinglei at 163.com  Mon Oct 10 16:27:40 2016
From: gaopinglei at 163.com (Pinglei Gao)
Date: Mon, 10 Oct 2016 22:27:40 +0800
Subject: [R] =?gb2312?b?tPC4tDogIEZpbmRpbmcgc3RhcnRpbmcgdmFsdWVzIGZvciB0?=
	=?gb2312?b?aGUgcGFyYW1ldGVycyB1c2luZyBubHMoKSBvciBubHMyKCk=?=
In-Reply-To: <E4A983A8-363A-422E-9382-533CA6E8A8AA@gmail.com>
References: <013a01d2221f$40b46360$c21d2a20$@163.com>
	<CAHyGmd763iOdtg=n+EG5qjWELqPSWaDz8jtY4RcbK84i48XTkw@mail.gmail.com>
	<CAGxFJbSDOwCschCboz+uJLiTuaMj8OvsXvyD-TW1R08Zdwhrqg@mail.gmail.com>
	<E4A983A8-363A-422E-9382-533CA6E8A8AA@gmail.com>
Message-ID: <000801d22302$74eb2540$5ec16fc0$@163.com>

Thanks very much for taking time on this. Your assistances are very much
appreciated. But, I am afraid that I still have a question to bother you. 

I am working on a paper about weed seeds dispersal with harvest machine. I
found three general models for seed dispersal and retention after a review
of relevant literature. All models were optimized using nonlinear least
squares via the nls function in the statistical package R. The model that
best described the data will be determined by comparing Akaike Information
Criterion (AIC) values and the model with the lowest AIC score will be
selected. 

The first general model incorporated simple exponential and power
exponential functions, its starting value was easily to be found. But, I am
stuck with model 2 (which was mentioned previously) and model 3 with the
form:  Retention = (b0*Area^th+1)^b1. The model 3 is totally different to
others. I tried the measures that you were mentioned. But I still can?t
find suitable starting values because of my limited knowledge. I hope you
can do me the favor again. I can send the draft to you when I finished the
paper, if it is necessary. Maybe you can give me some constructive
suggestion about statistic and model construction and I can name you as a
coauthor for your contributions.

Best,

Pinglei Gao

-----????-----
???: peter dalgaard [mailto:pdalgd at gmail.com] 
????: 2016?10?10? 7:41
???: Pinglei Gao
??: Andrew Robinson; R help (r-help at r-project.org); Bert Gunter
??: Re: [R] Finding starting values for the parameters using nls() or
nls2()


> On 10 Oct 2016, at 00:40 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Well... (inline -- and I hope this isn't homework!)
> 

Pretty much same as I thought. 

Fixing th=0.02 in the grid search looks wrong. Bert's plot is pretty linear,
so th=1 is a good guesstimate. There's a slight curvature but to reduce it,
you would increase th, not decrease it. Running the regression, as Bert
suggests, indicates that b0=5.16 and b1= -0.00024 could work as reasonable
starting values. Notice that the grid search had "b1 = seq(0.01, 4, by =
0.01)" which is wrong in both sign and scale.

Andrew's suggestion of dividing Retention by 100 is tempting, since it looks
like a percentage, but that would make all Y values less than 1 and the
double exponential function as written has values that are always bigger
than 1. (It is conceivable that the model itself is wrong, though. E.g. it
could be that Retention on a scale from 0 to 1 could be modeled as
exp(-something), but we really have no idea of the context here.)

(If this was in fact homework, you should now go and write a proper
SelfStart initializer routine for this model. Even if it isn't homework, you
do need to study the text again, because you have clearly not understood how
self-starting models work.)

-pd

> 
> 
> 
> On Sun, Oct 9, 2016 at 3:05 PM, Andrew Robinson 
> <A.Robinson at ms.unimelb.edu.au> wrote:
>> Here are some things to try.  Maybe divide Area by 1000 and retention 
>> by 100.  Try plotting the data and superimposing the line that 
>> corresponds to the 'fit' from nls2.  See if you can correct it with 
>> some careful guesses.
>> 
>> Getting suitable starting parameters for non-linear modeling is one 
>> of the black arts of statistical fitting. ...
>> 
>> Andrew
> 
> True. But it's usually worthwhile thinking about the math a bit before
guessing.
> 
> Note that the model can be linearized to:
> 
> log(log(Retention)) = b0 + b1*Area^th
> 
> So a plot of log(log(Retention)) vs Area may be informative and useful 
> for finding starting values. e.g., for a grid of th's, do linear 
> regression fits .
> 
> However, when I look at that plot, it seems pretty linear with a 
> negative slope. This suggests that you may have an overparametrization 
> problem . i.e. fix th =1 and use the b0 and b1 from the above 
> regression for starting values.
> 
> Do note that this strategy isn't foolproof, as it ignores that the 
> error term is additive in the above transformed metric, rather than 
> the original. This can sometimes mislead. But this is just a 
> heuristic.
> 
> Cheers,
> Bert
> 
> 
> 
> 
> 
> 
> 
>> 
>> On 9 October 2016 at 22:21, Pinglei Gao <gaopinglei at 163.com> wrote:
>>> Hi,
>>> 
>>> I have some data that i'm trying to fit a double exponential model:
data.
>>> Frame (Area=c (521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91, 
>>> 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 
>>> 2629.2),
>>> 
>>> Retention=c (95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 
>>> 23.46, 9.72, 97.92, 71.44, 44.52, 24.44, 15.26) ) and the formula of 
>>> the double exponential is: exp (b0*exp (b1*x^th)).
>>> 
>>> 
>>> 
>>> I failed to guess the initial parameter values and then I learned a 
>>> measure to find starting values from Nonlinear Regression with R (pp.
25-27):
>>> 
>>> 
>>> 
>>>> cl<-data.frame(Area =c(521.5, 689.78, 1284.71, 2018.8, 2560.46, 
>>>> 524.91,
>>> 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 
>>> 2629.2),
>>> 
>>> + Retention =c(95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 
>>> + 33.04, 23.46,
>>> 9.72, 97.92, 71.44, 44.52, 24.44, 15.26) )
>>> 
>>>> expFct <- function(Area, b0, b1,th) {exp(b0*exp(b1*Area^th))}
>>> 
>>>> grid.Disperse <- expand.grid(list(b0 = seq(0.01,4, by = 0.01), th =
>>> c(0.02),b1 = seq(0.01, 4, by = 0.01)))
>>> 
>>>> Disperse.m2a <- nls2(Retention ~expFct(Area, b0, b1,th), data = cl, 
>>>> start
>>> = grid.Disperse, algorithm = "brute-force")
>>> 
>>>> Disperse.m2a
>>> 
>>> Nonlinear regression model
>>> 
>>>  model: Retention ~ expFct(Area, b0, th, b1)
>>> 
>>>   data: cl
>>> 
>>> b0   th   b1
>>> 
>>> 3.82 0.02 0.01
>>> 
>>> residual sum-of-squares: 13596
>>> 
>>> Number of iterations to convergence: 160000
>>> 
>>> Achieved convergence tolerance: NA
>>> 
>>> 
>>> 
>>> I got no error then I use the output as starting values to nls2 ():
>>> 
>>>> nls.m2<- nls2(Retention ~ expFct(Area, b0, b1, th), data = cl, 
>>>> start =
>>> list(b0 = 3.82, b1 = 0.02, th = 0.01))
>>> 
>>> Error in (function (formula, data = parent.frame(), start, control = 
>>> nls.control(),  :
>>> 
>>> Singular gradient
>>> 
>>> 
>>> 
>>> Why? Did I do something wrong or misunderstand something?
>>> 
>>> 
>>> 
>>> Later, I found another measure from Modern Applied Statistics with S
(pp.
>>> 216-217):
>>> 
>>> 
>>> 
>>>> negexp <- selfStart(model = ~ exp(b0*exp(b1*x^th)),initial =
>>> negexp.SSival, parameters = c("b0", "b1", "th"),
>>> 
>>> + template = function(x, b0, b1, th) {})
>>> 
>>>> Disperse.ss <- nls(Retention ~ negexp(Area, b0, b1, th),data = cl, 
>>>> trace =
>>> T)
>>> 
>>>         b0          b1          th
>>> 
>>>   4.208763  144.205455 1035.324595
>>> 
>>> Error in qr.default(.swts * attr(rhs, "gradient")) :
>>> 
>>> NA/NaN/Inf (arg1) can not be called when the external function is
called.
>>> 
>>> 
>>> 
>>> Error happened again. How can I fix it? I am desperate.
>>> 
>>> 
>>> 
>>> Best regards,
>>> 
>>> 
>>> 
>>> Pinglei Gao
>>> 
>>> 
>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> --
>> Andrew Robinson
>> Deputy Director, CEBRA, School of Biosciences Reader & Associate 
>> Professor in Applied Statistics  Tel: (+61) 0403 138 955
>> School of Mathematics and Statistics                        Fax:
+61-3-8344 4599
>> University of Melbourne, VIC 3010 Australia
>> Email: a.robinson at ms.unimelb.edu.au
>> Website: http://www.ms.unimelb.edu.au/~andrewpr
>> 
>> MSME: http://www.crcpress.com/product/isbn/9781439858028
>> FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
>> SPuR: http://www.ms.unimelb.edu.au/spuRs/
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000
Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From gaopinglei at 163.com  Mon Oct 10 16:41:51 2016
From: gaopinglei at 163.com (Pinglei Gao)
Date: Mon, 10 Oct 2016 22:41:51 +0800
Subject: [R] Finding starting values for the parameters using nls() or
	nls2()
Message-ID: <000a01d22304$70edce00$52c96a00$@163.com>

Thanks very much for your kindness help. I run your script then came out
lots of outputs and I also studied the solution you posted. Forgive my
ignorance, I still can't find the suitable starting values. Did I
misunderstand something?

Best,

Pinglei Gao

-----????-----
???: ProfJCNash [mailto:profjcnash at gmail.com] 
????: 2016?10?10? 10:41
???: Gabor Grothendieck; Pinglei Gao
??: Re: [R] Finding starting values for the parameters using nls() or
nls2()

I forgot to post the "solution" found by nlmrt:

nlmrt class object: x
residual sumsquares =  1086.8  on  15 observations
    after  5001    Jacobian and  6991 function evaluations
  name            coeff          SE       tstat      pval      gradient
JSingval
b0            5.3274e-14            NA         NA         NA  -6.614e+13
1.735e+16
b1               33.5574            NA         NA         NA      -3.466
11518
th           -0.00721203            NA         NA         NA      -740.8
0.004635


Note the singular values -- this is the worst SV(max)/SV(min) ratio I've
observed!

JN


From Margaret.MacDougall at ed.ac.uk  Mon Oct 10 16:56:18 2016
From: Margaret.MacDougall at ed.ac.uk (MACDOUGALL Margaret)
Date: Mon, 10 Oct 2016 14:56:18 +0000
Subject: [R] Recoding lists of categories of a variable
Message-ID: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>

Hello

The R code
mydata$newvar[oldvar = "topic1"] <- "parenttopic"

is intended to recode the category 'topic 1' of the old  varaible 'oldvar' a new category label 'parenttopic' by defining the new variable 'newvar'.

Is there a convenient way to edit this code to allow me to recode a list of categories 'topic 1', 'topic 9' and 'topic 14', say, of the the old variable 'oldvar' as 'parenttopic' by means of the new variable 'newvar', while also mapping system missing values to system missing values?

Thanks in advance

Best wishes
Margaret

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161010/4887f76b/attachment.pl>

From javier at rstudio.com  Mon Oct 10 17:29:41 2016
From: javier at rstudio.com (Javier Luraschi)
Date: Mon, 10 Oct 2016 08:29:41 -0700
Subject: [R] Extending sparklyr
In-Reply-To: <CAAyVsX+SJXJDS09x19AxQ-Awx4VeK_16Zp9LZzmk9P9k=ZXxJQ@mail.gmail.com>
References: <CAAyVsX+SJXJDS09x19AxQ-Awx4VeK_16Zp9LZzmk9P9k=ZXxJQ@mail.gmail.com>
Message-ID: <CAOrRV3c3wd0BxwToqL_DJb7N0YmJvqNTQx=XH4Vt6jgbcP_pUQ@mail.gmail.com>

For versions 1.6.1 and 2.0.0 of Spark, the GaussianMixture is under the ml
namespace not mllib, try this instead:

envir$model <- "org.apache.spark.mllib.clustering.GaussianMixture"

Best, Javier

On Sun, Oct 9, 2016 at 1:47 PM, Axel Urbiz <axel.urbiz at gmail.com> wrote:

> Hi All,
>
> Just started to experiment with "sparklyr" and already loving it.
>
> I'm trying to build an extension by constructing an R wrapper to Spark's
> Gaussian Mixtures. My attempt is below, and so is the error message. Not
> sure if this is possible to do, and if so, what is wrong with my code.
>
> Any hints would be much appreciated.
>
> Best,
> Axel.
>
> -----
>
> library(sparklyr)
> library(dplyr)
> sc <- spark_connect(master = "local")
>
> x <- copy_to(sc, iris)
> x <- x %>% select(Petal_Width, Petal_Length)
>
> # set params
> k <- 3
> iter.max <- 100
> features <- dplyr::tbl_vars(x)
> compute.cost <- TRUE
> tolerance <- 1e-4
> ml.options <- ml_options()
>
> df <- spark_dataframe(x)
> sc <- spark_connection(df)
> df <- ml_prepare_features(
>   x = df,
>   features = features,
>   envir = environment()
>   # ml.options = ml.options
> )
> envir <- new.env(parent = emptyenv())
> envir$id <- ml.options$id.column
> df <- df %>%
>   sdf_with_unique_id(envir$id) %>%
>   spark_dataframe()
> tdf <- ml_prepare_dataframe(df, features, ml.options = ml.options, envir =
> envir)
> envir$model <- "org.apache.spark.ml.clustering.GaussianMixture"
> gmm <- invoke_new(sc, envir$model)
> >Error: failed to invoke spark command
> >16/10/09 16:35:35 ERROR <init> on org.apache.spark.ml.clustering.GaussianMixture
> failed
>
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Mon Oct 10 18:08:40 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 10 Oct 2016 17:08:40 +0100
Subject: [R] Recoding lists of categories of a variable
In-Reply-To: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
References: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403FEA09DBF@GBTEDVPEXCMB04.corp.lgc-group.com>

> Is there a convenient way to edit this code to allow me to recode a list of
> categories 'topic 1', 'topic 9' and 'topic 14', say, of the the old variable 'oldvar'
> as 'parenttopic' by means of the new variable 'newvar', while also mapping
> system missing values to system missing values?

You could look at 'recode()' in the car package.

There's a fair description of other options at http://www.uni-kiel.de/psychologie/rexrepos/posts/recode.html

S Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From kontakt at benjaminschlegel.ch  Mon Oct 10 16:19:19 2016
From: kontakt at benjaminschlegel.ch (kontakt at benjaminschlegel.ch)
Date: Mon, 10 Oct 2016 16:19:19 +0200
Subject: [R] [R-pkgs] new package glm.predict
Message-ID: <004e01d22301$4a378e20$dea6aa60$@benjaminschlegel.ch>

Dear R users,

 

I'm pleased to announce that my first package has been accepted in CRAN.

 

https://cran.r-project.org/web/packages/glm.predict/

 

With glm.predict it is possible to calculate discrete changes with
confidence intervals for glm(), glm_nb(), polr() and multinom() models.

It is possible to calculate many discrete changes with just one line of
code. The output is a data.frame.

 

The functions calculate the confidence intervals with simulation, so the
results are only true asymptotically.

 

Comments and suggestions are welcome.

 

Best

Benjamin

------------------------------------------------------

Benjamin Schlegel

University of Zurich

Institut of Political Science
Affolternstrasse 56
8050 Zurich

kontakt at benjaminschlegel.ch

+41 44 634 62 08


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From klebyn at yahoo.com.br  Mon Oct 10 18:26:57 2016
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Mon, 10 Oct 2016 13:26:57 -0300
Subject: [R] pure TCL run a command within the R via the tcltk package?
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836583B49@FHSDB2D11-2.csu.mcmaster.ca>
References: <149fc6fc-ed68-08aa-23cf-c996eacb33e1@yahoo.com.br>
	<ACD1644AA6C67E4FBD0C350625508EC836583B49@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <281eb0ce-220f-208d-1191-973b2c1a7485@yahoo.com.br>

thanks Jonh Fox!  :-)
my solution (partial and temporary) was as follows.
cleber
( for the  r-help history file )
############################################
library( tcltk )
# from  ?.Tcl
f <- function()cat("HI!\n")
.Tcl.callback(f)

sink("simpletest.tcl")
cat('toplevel .t\n')
cat('button .t.b -text "but" -command { ',  .Tcl.callback(f), ' }\n' )
cat('checkbutton .t.c -text "ck1" -variable "chkvar"\n' )
cat('pack .t.b\n')
cat('pack .t.c\n')
sink()

#tcl('set', 'argc', '0') # for use with code generated by vTcl
#tcl('set', 'argv', '0') # for use with code generated by vTcl
tcl('source', "simpletest.tcl" )
tclvalue('chkvar')

unlink('simpletest.tcl')


Em 10/10/2016 11:02, Fox, John escreveu:
> Dear Cleber,
>
> See ?.Tcl
>
> I hope this helps,
>   John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cleber
>> N.Borges via R-help
>> Sent: October 9, 2016 9:00 PM
>> To: r-help at r-project.org
>> Subject: [R] pure TCL run a command within the R via the tcltk package?
>>
>> Dear,
>> is there any way of a button on pure TCL run a command within the R via the
>> tcltk package?
>> thank you in advance for informations
>> cleber
>> what I have in mind is something like:  (below)
>> ##################################################################
>> ########################
>> sink("simpletest.tcl")
>> cat('
>> toplevel .t
>> button .t.b -text "but" -command {"some tcltk command for push data into R"}
>> checkbutton .t.c -text "ck1" -variable "chkvar"
>> pack .t.b
>> pack .t.c '
>> )
>> sink()
>>
>> library( tcltk )
>> #tcl('set', 'argc', '0')
>> #tcl('set', 'argv', '0')
>> tcl('source', "simpletest.tcl" )
>>
>>   > tclvalue('chkvar')
>> [1] "1"
>>   > tclvalue('chkvar') # after click in screen [1] "0"
>>   >
>>
>> ### after click in button  get error:
>>
>> invalid command name "some tcltk command for push data into R"
>> invalid command name "some tcltk command for push data into R"
>>       while executing
>> ""some tcltk command for push data into R""
>>       invoked from within
>> ".t.b invoke"
>>       ("uplevel" body line 1)
>>       invoked from within
>> "uplevel #0 [list $w invoke]"
>>       (procedure "tk::ButtonUp" line 24)
>>       invoked from within
>> "tk::ButtonUp .t.b"
>>       (command bound to event)
>>
>> ##################################################################
>> ########################
>>   > sessionInfo()
>> R version 3.3.1 (2016-06-21)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>> (build 7600)
>>
>> locale:
>> [1] LC_COLLATE=Portuguese_Brazil.1252 LC_CTYPE=Portuguese_Brazil.1252
>> [3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C [5]
>> LC_TIME=Portuguese_Brazil.1252
>>
>> attached base packages:
>> [1] tcltk     stats     graphics  grDevices utils     datasets methods
>> base
>>   >
>>

---
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus


From dwinsemius at comcast.net  Mon Oct 10 18:39:53 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 10 Oct 2016 09:39:53 -0700
Subject: [R] Having trouble with running ldBands in Hmisc package.
	Posted in StackExchange
In-Reply-To: <1840244298.2113148.1476108197936@mail.yahoo.com>
References: <1840244298.2113148.1476108197936.ref@mail.yahoo.com>
	<1840244298.2113148.1476108197936@mail.yahoo.com>
Message-ID: <F7620AC5-C3F9-4839-9A7E-EE4E165A91A8@comcast.net>


> On Oct 10, 2016, at 7:03 AM, Pitch Mandava via R-help <r-help at r-project.org> wrote:
> 
> I am trying to run the example from Hmisc package in RStudio environment under Windows 10 and downloaded ld98.exe> .libPaths()Produces the following output[1] "C:/Users/username/X1_Carbon/Documents/R/win-library/3.2"[2] "C:/Program Files/R/R-3.2.5/library"I moved the ld98.exe to C:/Users/username/X1_Carbon/Documents/R/win-library/3.2Then installed Hmisc and ran the following> require(Hmisc)
>> b <- ldBands(5, pr=FALSE)Produces the followingError: could not find function "ldBands"To see if ld98.exe is working in the directory I ran the ld98.exe in the Windows environment I get the following outputProgram for computations related to group sequential boundaries using spending functions.Is this an interactive session? (1=yes,0=no)yes interactive = 1etc.....
> 	[[alternative HTML version deleted]]
> 

You should check the NEWS file. That function was removed in Hmisc version 3.14

-- 
David,


> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From marc_schwartz at me.com  Mon Oct 10 19:10:58 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 10 Oct 2016 12:10:58 -0500
Subject: [R] Having trouble with running ldBands in Hmisc
 package.	Posted in StackExchange
In-Reply-To: <F7620AC5-C3F9-4839-9A7E-EE4E165A91A8@comcast.net>
References: <1840244298.2113148.1476108197936.ref@mail.yahoo.com>
	<1840244298.2113148.1476108197936@mail.yahoo.com>
	<F7620AC5-C3F9-4839-9A7E-EE4E165A91A8@comcast.net>
Message-ID: <F0ABC3EB-07B5-4826-B5AC-BE46B5BE8164@me.com>


> On Oct 10, 2016, at 11:39 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Oct 10, 2016, at 7:03 AM, Pitch Mandava via R-help <r-help at r-project.org> wrote:
>> 
>> I am trying to run the example from Hmisc package in RStudio environment under Windows 10 and downloaded ld98.exe> .libPaths()Produces the following output[1] "C:/Users/username/X1_Carbon/Documents/R/win-library/3.2"[2] "C:/Program Files/R/R-3.2.5/library"I moved the ld98.exe to C:/Users/username/X1_Carbon/Documents/R/win-library/3.2Then installed Hmisc and ran the following> require(Hmisc)
>>> b <- ldBands(5, pr=FALSE)Produces the followingError: could not find function "ldBands"To see if ld98.exe is working in the directory I ran the ld98.exe in the Windows environment I get the following outputProgram for computations related to group sequential boundaries using spending functions.Is this an interactive session? (1=yes,0=no)yes interactive = 1etc.....
>> 	[[alternative HTML version deleted]]
>> 
> 
> You should check the NEWS file. That function was removed in Hmisc version 3.14
> 
> -- 
> David,



Hi,

Just to augment David's reply with some additional direction, if you specifically need the Lan-DeMets methodology.

The Clinical Trials Task View:

  https://cran.r-project.org/web/views/ClinicalTrials.html <https://cran.r-project.org/web/views/ClinicalTrials.html>

provides names of other packages that provide for group sequential boundary calculations, although it looks like the entry for Hmisc needs to be edited there. I am cc'ing the CT TV maintainer here as a heads up.

Regards,

Marc Schwartz


	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Oct 10 19:17:11 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 10 Oct 2016 17:17:11 +0000
Subject: [R] Recoding lists of categories of a variable
In-Reply-To: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
References: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
Message-ID: <bbd489a9074042e186bed763a6f175f2@exch-2p-mbx-w2.ads.tamu.edu>

Your code suggests that you do not understand R or what you are doing. The line

mydata$newvar[oldvar = "topic1"] <- "parenttopic"

does not recode cases where oldvar is "topic1", it creates a new variable called oldvar (not the same as mydata$oldvar) and sets it to "topic1" because a single equals sign assigns a value to a variable whereas two equals signs create a logical expression. The result is that all values of mydata$newvar become "parenttopic". You did not give us any data, so it is not clear if oldvar is a character variable or a factor. Assuming it is a factor try the following and then spend a few hours reading some tutorials on R:

> # Create reproducible data
> set.seed(42)
> mydata <- data.frame(oldvar=paste("topic", sample(1:20, 200, replace=TRUE)))
> str(mydata)
'data.frame':   200 obs. of  1 variable:
 $ oldvar: Factor w/ 20 levels "topic 1","topic 10",..: 11 11 17 9 5 3 7 14 6 7 ...
> # Note factor levels are ordered alphabetically. Fix that with
> mydata$oldvar <- factor(mydata$oldvar, levels=c(paste("topic", 1:20)))
> str(mydata)
'data.frame':   200 obs. of  1 variable:
 $ oldvar: Factor w/ 20 levels "topic 1","topic 2",..: 19 19 6 17 13 11 15 3 14 15 ...
> levels(mydata$oldvar)
 [1] "topic 1"  "topic 2"  "topic 3"  "topic 4"  "topic 5"  "topic 6"  "topic 7"  "topic 8" 
 [9] "topic 9"  "topic 10" "topic 11" "topic 12" "topic 13" "topic 14" "topic 15" "topic 16"
[17] "topic 17" "topic 18" "topic 19" "topic 20"
> mydata$newvar <- mydata$oldvar
> levels(mydata$newvar)[c(1, 9, 14)] <- "parenttopic"
> table(mydata$newvar)

parenttopic     topic 2     topic 3     topic 4     topic 5     topic 6     topic 7     topic 8 
         26           6          14          10           8           7           7          11 
   topic 10    topic 11    topic 12    topic 13    topic 15    topic 16    topic 17    topic 18 
          8          10           9          13          19          12          11           3 
   topic 19    topic 20 
         18           8


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of MACDOUGALL Margaret
Sent: Monday, October 10, 2016 9:56 AM
To: r-help at r-project.org
Subject: [R] Recoding lists of categories of a variable

Hello

The R code
mydata$newvar[oldvar = "topic1"] <- "parenttopic"

is intended to recode the category 'topic 1' of the old  varaible 'oldvar' a new category label 'parenttopic' by defining the new variable 'newvar'.

Is there a convenient way to edit this code to allow me to recode a list of categories 'topic 1', 'topic 9' and 'topic 14', say, of the the old variable 'oldvar' as 'parenttopic' by means of the new variable 'newvar', while also mapping system missing values to system missing values?

Thanks in advance

Best wishes
Margaret


From bgunter.4567 at gmail.com  Mon Oct 10 19:39:03 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 10 Oct 2016 10:39:03 -0700
Subject: [R] Recoding lists of categories of a variable
In-Reply-To: <1A8C1289955EF649A09086A153E2672403FEA09DBF@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
	<1A8C1289955EF649A09086A153E2672403FEA09DBF@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <CAGxFJbRugDMXmUP3J+tt6UiycYK32pKL6W7=RqEhezioM_Hi3w@mail.gmail.com>

Well, I think that's kind of overkill.

Assuming "oldvar" is a factor in the data frame mydata, then the
following shows how to do it:

> set.seed(27)
> d <- data.frame(a = sample(c(letters[1:3],NA),15,replace = TRUE))
> d
      a
1  <NA>
2     a
3  <NA>
4     b
5     a
6     b
7     a
8     a
9     a
10    a
11    c
12 <NA>
13    c
14    c
15 <NA>


> d$b <- factor(d$a,labels = LETTERS[3:1])
> d
      a    b
1  <NA> <NA>
2     a    C
3  <NA> <NA>
4     b    B
5     a    C
6     b    B
7     a    C
8     a    C
9     a    C
10    a    C
11    c    A
12 <NA> <NA>
13    c    A
14    c    A
15 <NA> <NA>


See ?factor for details.

Incidentally note that in the OP's post,

mydata$newvar[oldvar = "topic1"] <- "parenttopic"

is completely incorrect; it should probably be:

mydata$newvar[mydata$oldvar == "topic1"] <- "parenttopic";

This suggests to me that the OP would probably find it useful to spend
some time with one or more of the many good R tutorials on the web.

Cheers,
Bert











Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Oct 10, 2016 at 9:08 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:
>> Is there a convenient way to edit this code to allow me to recode a list of
>> categories 'topic 1', 'topic 9' and 'topic 14', say, of the the old variable 'oldvar'
>> as 'parenttopic' by means of the new variable 'newvar', while also mapping
>> system missing values to system missing values?
>
> You could look at 'recode()' in the car package.
>
> There's a fair description of other options at http://www.uni-kiel.de/psychologie/rexrepos/posts/recode.html
>
> S Ellison
>
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:8}}


From pai1981 at gmail.com  Mon Oct 10 21:25:47 2016
From: pai1981 at gmail.com (Debasish Pai Mazumder)
Date: Mon, 10 Oct 2016 13:25:47 -0600
Subject: [R] OPeNDAP access / OPeNDAP subsetting with R
In-Reply-To: <D9CB6267-BCD9-4DF6-B692-C736951666F8@noaa.gov>
References: <CAM9mbiDWSCY-V4VVR3pEUY26RHEmvPOsUS3UosrO=jWO4tp4iA@mail.gmail.com>
	<20C79DFE-6AB1-488D-A5BC-311C4017A601@noaa.gov>
	<CAM9mbiBMU=4fC-5PSvbvdUvHB2=i8vEuO0omVn9Vumr90SWWwA@mail.gmail.com>
	<68C6E1C5-BAE5-4D5F-8DF4-BF1FC2AF5303@noaa.gov>
	<CAAcGz98bDa8njpY=Cio5ATpdgq2bpyR47QtT4Nh01+iWA-v=KQ@mail.gmail.com>
	<CAM9mbiAedU8J4YcyX-5DBEMfbagAVQKWJDsxqrqUo6R==Ly8AQ@mail.gmail.com>
	<D9CB6267-BCD9-4DF6-B692-C736951666F8@noaa.gov>
Message-ID: <CAM9mbiDpkvgEt-FRE6QhjjjZ4NfCU4GLVCJZi65GOAdUNXOUTA@mail.gmail.com>

Hi Roy,
Thanks for your help. It works perfectly. if I am trying to read multiple
files similar ways, how do I do that?
with regards
-Deb



On Fri, Sep 30, 2016 at 5:53 PM, Roy Mendelssohn - NOAA Federal <
roy.mendelssohn at noaa.gov> wrote:

> Hi Deb:
>
> > > gribfile <- 'http://thredds.ucar.edu/thredds/ncss/grib/NCEP/GFS/
> Global_0p5deg/best?north=47.0126&west=-114.841&east=-112.
> 641&south=44.8534&time_start=present&time_duration=PT3H&
> accept=netcdf&var=v-component_of_wind_height_above_ground,u-
> component_of_wind_height_above_ground'
> > > download.file(gribfile,'junk.nc',mode = "wb")
> > trying URL 'http://thredds.ucar.edu/thredds/ncss/grib/NCEP/GFS/
> Global_0p5deg/best?north=47.0126&west=-114.841&east=-112.
> 641&south=44.8534&time_start=present&time_duration=PT3H&
> accept=netcdf&var=v-component_of_wind_height_above_ground,u-
> component_of_wind_height_above_ground'
> > Content type 'application/x-netcdf' length unknown
> > ....
> > downloaded 4360 bytes
> >
> > > library(ncdf4)
> > > junkFile <- nc_open('junk.nc')
> > > str(junkFile)
> > List of 14
> >  $ filename   : chr "junk.nc"
> >  $ writable   : logi FALSE
> >  $ id         : int 65536
> >  $ safemode   : logi FALSE
> >  $ format     : chr "NC_FORMAT_CLASSIC"
> >  $ is_GMT     : logi FALSE
> >  $ groups     :List of 1
> >   ..$ :List of 7
> >   .. ..$ id   : int 65536
> >   .. ..$ name : chr ""
> >   .. ..$ ndims: int 4
> >   .. ..$ nvars: int 7
> >   .. ..$ natts: int 13
> >   .. ..$ dimid: int [1:4(1d)] 0 1 2 3
> >   .. ..$ fqgn : chr ""
> >   .. ..- attr(*, "class")= chr "ncgroup4"
> >  $ fqgn2Rindex:List of 1
> >   ..$ : int 1
> >  $ ndims      : num 4
> >  $ natts      : num 13
> >  $ dim        :List of 4
> >
>
> <snip>
>
> I cut off the rest as that is not important for your question.
>
> HTH,
>
> -Roy
>
> > On Sep 30, 2016, at 4:21 PM, Debasish Pai Mazumder <pai1981 at gmail.com>
> wrote:
> >
> > Hi
> > Now I am using netcdfSubset and I am able to download the file but not
> sure how to read the files. here my scripts
> > library("ncdf4")
> >
> > gribfile<-"http://thredds.ucar.edu/thredds/ncss/grib/
> NCEP/GFS/Pacific_40km/best/dataset.html"
> > download.file(gribfile,basename(gribfile),mode = "wb")
> > x<-nc_open(gribfile)
> >
> > gribfile<-"http://thredds.ucar.edu/thredds/ncss/grib/
> NCEP/GFS/Global_0p5deg/best?north=47.0126&west=-114.841&
> east=-112.641&south=44.8534&time_start=present&time_
> duration=PT3H&accept=netcdf&var=v-component_of_wind_height_above_ground,u-
> component_of_wind_height_above_ground"
> > download.file(gribfile,basename(gribfile),mode = "wb")
> > x<-nc_open(gribfile)
> >
> >
> > nc_open doesn't work.
> >
> > which command should I use?
> >
> > with regards
> > -Deb
> >
> >
> > On Tue, Sep 27, 2016 at 9:30 PM, Michael Sumner <mdsumner at gmail.com>
> wrote:
> > Opendap won't work on Windows CRAN build of ncdf4, though the rgdal
> build does work directly on grib.
> >
> > Summary: download the files wholus for use on Windows, or set your own
> system on Linux.
> >
> > Building ncdf4 on Windows is not too hard if you know about doing that.
> >
> > Cheers, Mike
> >
> > On Wed, 28 Sep 2016, 06:49 Roy Mendelssohn - NOAA Federal <
> roy.mendelssohn at noaa.gov> wrote:
> > Please post the code of what you tried, as I have no idea otherwise what
> did or did not work for you.
> >
> > -Roy
> >
> > > On Sep 27, 2016, at 12:44 PM, Debasish Pai Mazumder <pai1981 at gmail.com>
> wrote:
> > >
> > > Hi Roy,
> > > Thanks for your response. I have tried according your suggestion but
> it doesn't work.
> > > the OPeNDAP link of the data
> > > http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_
> forecast_ts_9mon/2014/201404/20140403/2014040312/
> > >
> > > datafile:
> > > tmax.01.2014040312.daily.grb2
> > >
> > > Thanks
> > > -Deb
> > >
> > > On Tue, Sep 27, 2016 at 11:51 AM, Roy Mendelssohn - NOAA Federal <
> roy.mendelssohn at noaa.gov> wrote:
> > > Look at the package ncdf4.  You can use an OPeNDAP URL in place of the
> file name to perform subsets.,
> > >
> > > -Roy
> > >
> > > > On Sep 27, 2016, at 9:06 AM, Debasish Pai Mazumder <
> pai1981 at gmail.com> wrote:
> > > >
> > > > Hi all,
> > > >
> > > > I would like to access and subset following OpeNDAP files.
> > > > server:
> > > > http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_
> forecast_ts_9mon/2014/201404/20140403/2014040312/
> > > >
> > > > file name: tmax.01.2014040312.daily.grb2
> > > > <http://nomads.ncdc.noaa.gov/thredds/dodsC/modeldata/cfsv2_
> forecast_ts_9mon/2014/201404/20140403/2014040312/catalog.
> html?dataset=modeldata/cfsv2_forecast_ts_9mon/2014/201404/
> 20140403/2014040312/tmax.01.2014040312.daily.grb2>
> > > > I would like to access and subset the file. Any help will be
> appreciated.
> > > >
> > > > with regards
> > > > -Deb
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > **********************
> > > "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> > > **********************
> > > Roy Mendelssohn
> > > Supervisory Operations Research Analyst
> > > NOAA/NMFS
> > > Environmental Research Division
> > > Southwest Fisheries Science Center
> > > ***Note new address and phone***
> > > 110 Shaffer Road
> > > Santa Cruz, CA 95060
> > > Phone: (831)-420-3666
> > > Fax: (831) 420-3980
> > > e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> > >
> > > "Old age and treachery will overcome youth and skill."
> > > "From those who have been given much, much will be expected"
> > > "the arc of the moral universe is long, but it bends toward justice"
> -MLK Jr.
> > >
> > >
> >
> > **********************
> > "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> > **********************
> > Roy Mendelssohn
> > Supervisory Operations Research Analyst
> > NOAA/NMFS
> > Environmental Research Division
> > Southwest Fisheries Science Center
> > ***Note new address and phone***
> > 110 Shaffer Road
> > Santa Cruz, CA 95060
> > Phone: (831)-420-3666
> > Fax: (831) 420-3980
> > e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> >
> > "Old age and treachery will overcome youth and skill."
> > "From those who have been given much, much will be expected"
> > "the arc of the moral universe is long, but it bends toward justice"
> -MLK Jr.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > --
> > Dr. Michael Sumner
> > Software and Database Engineer
> > Australian Antarctic Division
> > 203 Channel Highway
> > Kingston Tasmania 7050 Australia
> >
> >
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Mon Oct 10 21:31:43 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 10 Oct 2016 19:31:43 +0000
Subject: [R] Recoding lists of categories of a variable
In-Reply-To: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
References: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836583CD8@FHSDB2D11-2.csu.mcmaster.ca>

Dear Margaret,

You've had one suggestion of an alternative for recoding variables, but in addition your code is in error (see below).

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> MACDOUGALL Margaret
> Sent: Monday, October 10, 2016 10:56 AM
> To: r-help at r-project.org
> Subject: [R] Recoding lists of categories of a variable
> 
> Hello
> 
> The R code
> mydata$newvar[oldvar = "topic1"] <- "parenttopic"

That should be

   mydata$newvar[oldvar == "topic1"] <- "parenttopic"

Moreover, the code assumes that oldvar is visible, which may not be the case if it lives in mydata and mydata isn't attach()ed.

Best,
 John

--------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
Web: socserv.mcmaster.ca/jfox

> 
> is intended to recode the category 'topic 1' of the old  varaible
> 'oldvar' a new category label 'parenttopic' by defining the new variable
> 'newvar'.
> 
> Is there a convenient way to edit this code to allow me to recode a list
> of categories 'topic 1', 'topic 9' and 'topic 14', say, of the the old
> variable 'oldvar' as 'parenttopic' by means of the new variable
> 'newvar', while also mapping system missing values to system missing
> values?
> 
> Thanks in advance
> 
> Best wishes
> Margaret


From Margaret.MacDougall at ed.ac.uk  Mon Oct 10 22:38:29 2016
From: Margaret.MacDougall at ed.ac.uk (MACDOUGALL Margaret)
Date: Mon, 10 Oct 2016 20:38:29 +0000
Subject: [R] Recoding lists of categories of a variable
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836583CD8@FHSDB2D11-2.csu.mcmaster.ca>
References: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
	<ACD1644AA6C67E4FBD0C350625508EC836583CD8@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <VI1PR0502MB3021F385630639E9ACEC0F93C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>

Thank you for the valued suggestions in response to my query.

Margaret


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


-----Original Message-----
From: Fox, John [mailto:jfox at mcmaster.ca] 
Sent: 10 October 2016 20:32
To: MACDOUGALL Margaret <Margaret.MacDougall at ed.ac.uk>
Cc: r-help at r-project.org
Subject: RE: Recoding lists of categories of a variable

Dear Margaret,

You've had one suggestion of an alternative for recoding variables, but in addition your code is in error (see below).

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
> MACDOUGALL Margaret
> Sent: Monday, October 10, 2016 10:56 AM
> To: r-help at r-project.org
> Subject: [R] Recoding lists of categories of a variable
> 
> Hello
> 
> The R code
> mydata$newvar[oldvar = "topic1"] <- "parenttopic"

That should be

   mydata$newvar[oldvar == "topic1"] <- "parenttopic"

Moreover, the code assumes that oldvar is visible, which may not be the case if it lives in mydata and mydata isn't attach()ed.

Best,
 John

--------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
Web: socserv.mcmaster.ca/jfox

> 
> is intended to recode the category 'topic 1' of the old  varaible 
> 'oldvar' a new category label 'parenttopic' by defining the new 
> variable 'newvar'.
> 
> Is there a convenient way to edit this code to allow me to recode a 
> list of categories 'topic 1', 'topic 9' and 'topic 14', say, of the 
> the old variable 'oldvar' as 'parenttopic' by means of the new 
> variable 'newvar', while also mapping system missing values to system 
> missing values?
> 
> Thanks in advance
> 
> Best wishes
> Margaret


From drjimlemon at gmail.com  Mon Oct 10 23:08:07 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 11 Oct 2016 08:08:07 +1100
Subject: [R] Recoding lists of categories of a variable
In-Reply-To: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
References: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
Message-ID: <CA+8X3fU8rVP2iZKq9qUxiMtD-b48Hxr7FykG+tSdoCjHQ1Jd0w@mail.gmail.com>

Hi Margaret,
This may be a misunderstanding of your request, but what about:

mydata<-data.frame(oldvar=paste("topic",sample(1:9,20,TRUE),sep=""))
mydata$newvar<-sapply(mydata$oldvar,gsub,"topic.","parenttopic")

Jim


On Tue, Oct 11, 2016 at 1:56 AM, MACDOUGALL Margaret
<Margaret.MacDougall at ed.ac.uk> wrote:
> Hello
>
> The R code
> mydata$newvar[oldvar = "topic1"] <- "parenttopic"
>
> is intended to recode the category 'topic 1' of the old  varaible 'oldvar' a new category label 'parenttopic' by defining the new variable 'newvar'.
>
> Is there a convenient way to edit this code to allow me to recode a list of categories 'topic 1', 'topic 9' and 'topic 14', say, of the the old variable 'oldvar' as 'parenttopic' by means of the new variable 'newvar', while also mapping system missing values to system missing values?
>
> Thanks in advance
>
> Best wishes
> Margaret
>
>
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dusa.adrian at unibuc.ro  Mon Oct 10 23:34:33 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Tue, 11 Oct 2016 00:34:33 +0300
Subject: [R] Loop to check for large dataset
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5040E27@SRVEXCHMBX.precheza.cz>
References: <4FCBB54C-C002-43DE-ABA3-BBCD01F24DE9@ad.unsw.edu.au>
	<CAJ=0CtBK6MnmmJ4EzVei=G4Yzj_kCRctMke-mF7xAc-cgNYWBw@mail.gmail.com>
	<9C546083-5909-4EFE-B102-225FAA94A6B7@ad.unsw.edu.au>
	<CAJ=0CtDs+MvYMLi=gfR211C9NOx2xtrKNQBjW2o=_rHfsWGdAw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5040E27@SRVEXCHMBX.precheza.cz>
Message-ID: <CAJ=0CtCz-3pZnDBtVH6eFzZj_Jioeo7UQiFgoRmTYtO-5qfaaA@mail.gmail.com>

Granted,, there are better solutions than my "KISS" (keep it simple and
stupid) example.

Hopefully, Christoph will have learned from both.

Best,
Adrian

On 10 Oct 2016 13:44, "PIKAL Petr" <petr.pikal at precheza.cz> wrote:

> Hi
>
>
>
> Given this example data, you can get same answer with less typing and
> without loops.
>
>
>
> res<-xtabs(~W+P+S,mydata)
>
> res1<-which(res==0, arr.ind=T)
>
> head(res1)
>
>       W P S
>
> 10   10 1 1
>
> 11   11 1 1
>
> 82   82 1 1
>
> 100 100 1 1
>
> 117 117 1 1
>
> 148 148 1 1
>
>
>
> Cheers
>
> Petr
>
>
>
>
>
> *From:* dusa.adrian at gmail.com [mailto:dusa.adrian at gmail.com] *On Behalf
> Of *Adrian Du?a
> *Sent:* Monday, October 10, 2016 12:26 PM
> *To:* Christoph Puschmann <c.puschmann at student.unsw.edu.au>
> *Cc:* r-help at r-project.org; PIKAL Petr <petr.pikal at precheza.cz>
> *Subject:* Re: [R] Loop to check for large dataset
>
>
>
> This is an example of how a reproducible code looks like, assuming you
> have three columns in your dataset named S (store), P (product) and W
> (week), and also assuming they have integer values from 1 to 19, 1 to 22
> and 1 to 157 respectively:
>
> #########
>
> mydata <- expand.grid(seq(19), seq(22), seq(157))
> names(mydata) <- c("S", "P", "W")
>
> # randomly delete 65626 - 63127 = 2499 rows
> set.seed(12345) # make it replicable
>
> mydata <- mydata[-sample(seq(nrow(mydata)), nrow(mydata) - 63127), ]
>
> #########
>
>
> Now the dataframe mydata contains exactly 63127 rows, just as in your
> case. The task is to find which weeks are missing, from which store and for
> which product.
>
> Below is a possible code to do that. Given you have a small number of
> stores and products, I'll keep it simple and stupid, by using for loops:
>
>
>
>
>
> #########
>
>
>
> result <- matrix(nrow = 0, ncol = 3)
>
>
>
> for (i in seq(19)) {
>
>     for (j in seq(22)) {
>
>         miss <- setdiff(seq(157), mydata$W[mydata$S == i & mydata$P == j])
>
>         if (length(miss) > 0) {
>
>             result <- rbind(result, cbind(S = i, P = j, W = miss))
>
>         }
>
>     }
>
> }
>
>
>
> # The result matrix contains 2499 rows that are missing.
>
>
>
> > head(result)
>
>      S P   W
>
> [1,] 1 1  10
>
> [2,] 1 1  11
>
> [3,] 1 1  82
>
> [4,] 1 1 100
>
> [5,] 1 1 117
>
> [6,] 1 1 148
>
>
>
> #########
>
>
>
>
>
> In this example, for S(tore) number 1 and P(roduct) number 1, you are
> missing W(eek) 10, 11, 82 and so on.
>
>
>
> In hoping you can adapt this code to your particular example,
>
> Adrian
>
>
>
> On Sun, Oct 9, 2016 at 2:26 AM, Christoph Puschmann <
> c.puschmann at student.unsw.edu.au> wrote:
> >
> > Dear Adrian,
> >
> > Yes it is a cyclical data set and theoretically it should repeat this
> interval until 61327. The data set itself is divided into 2 Parts:
> > 1. Product category (column 10)
> > 2. Number of Stores Participating (column 01)
> > Overall there are 22 different products and in each you have 19
> different stores participating. And theoretically each store over each
> product category should have a 1 - 157 week interval.
> >
> > The part I am struggling with is how do I run a loop over the whole data
> set, while checking if all stores participated 157 weeks over the different
> products.
> >
> > So far I came up with this:
> >
> > n=61327                           # Generate Matrix to check for values
> > Control = matrix(
> >   0,
> >   nrow = n,
> >   ncol = 1)
> >
> > s <- seq(from =1 , to = 157, by = 1)
> > CW = matrix(
> >   s,
> >   nrow = 157,
> >   ncol = 1
> > )
> >
> > colnames(CW)[1] <- ?s'
> >
> > CW = as.data.frame(CW)
> >
> > for (i in 1:nrow(FD)) {           # Let run trhough all the rows
> >   for (j in 1:157) {
> > if(FD$WEEk[j] == C$s[j]) {
> >   Control[i] = 1                 # coresponding control row = 1
> > } else {
> >   Control[i] = 0                 # corresponding control row = 0
> > }
> > }
> > }
> >
> > I coded a  MRE and attached an sample of my data set.
> >
> > MRE:
> >
> > #MRE
> >
> > dat <- data.frame(
> >   Store = c(rep(8, times = 157), rep(12, times = 157)),  # Number of
> stores
> >   WEEK = rep(seq(from=1, to = 157, by = 1), times = 2)
> > )
> >
> >
> >
> >
>
>
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Tue Oct 11 01:32:08 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 11 Oct 2016 00:32:08 +0100
Subject: [R] Recoding lists of categories of a variable
In-Reply-To: <CAGxFJbRugDMXmUP3J+tt6UiycYK32pKL6W7=RqEhezioM_Hi3w@mail.gmail.com>
References: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
	<1A8C1289955EF649A09086A153E2672403FEA09DBF@GBTEDVPEXCMB04.corp.lgc-group.com>,
	<CAGxFJbRugDMXmUP3J+tt6UiycYK32pKL6W7=RqEhezioM_Hi3w@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403FE7A2EDA@GBTEDVPEXCMB04.corp.lgc-group.com>

> Well, I think that's kind of overkill.
Depends whether you want to recode all or some, and how robust you want the answer to be. 
recode() allows you to recode a few levels of many, without dependence on level ordering; that's kind of neat. 

tbh, though,  I don't use recode() a lot; I generally find myself need to change a fair proportion of level labels. 

But I do get nervous about relying on specific ordering; it can break without visible warning if the data change (eg if you lose a factor level with a slightly different data set, integer indexing will give you apparently valid reassignment to the wrong new codes).  So I tend to go via named vectors even if it costs me a lot of typing. For example to change 
lcase<-c('a', 'b', 'c') 

to c('B', 'A', 'C') I'll use something like 

c(a='B', b='A', c='C')[lcase] 

or, if lcase were a factor, 
c(a='B', b='A', c='C')[as.character(lcase)] 

Unlike using the numeric levels, that doesn't fail if some of the levels I expect are absent; it only fails (and does so visibly) when there's a value in there that I haven't assigned a coding to. So it's a tad more robust.

Steve E






*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From luysgarcia at gmail.com  Tue Oct 11 04:25:08 2016
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Mon, 10 Oct 2016 23:25:08 -0300
Subject: [R] Question about ggplot2 symbol and legend change
Message-ID: <CANxP2S7cBTqYcLFVFBckgSiCZ9LG4O3BTSYRzt__WBJ4SnyH5A@mail.gmail.com>

Dear R experts,

Maybe my question is too basic and I apologize for that. I am having an
issue currently by trying to change manually the symbols of the series. I
need to put them manually, instead of using the symbols that R gives by
default and produce a plot with the classic style. For example I need to
put the symbols 16 and 2, but I have been unable to do it so far. Also, I
need to remove the grey background from the seiries but I have been unable
to do it too.

Any help you can provide will be really helpful.

Below, I am providing the script as well as the picture I gio with it If
necessary I added the dataset.

Many thanks


#################################################################################


it<-read.table("immotime.txt",header=TRUE)
it
str(it)
names(it)
fit3<-lm(Time ~ Sp*Ratio, data=it)
anova(fit3)
plot(fit3)
summary(fit3)
a$lPeso <- log(Peso)
library(ggplot2)
p <- ggplot(it,aes(x=Ratio,y=Time)) + geom_point(aes(shape=factor(Sp)))
p=p + geom_smooth(aes(linetype=factor(Sp), ),colour="black", method='lm',
se=F)+theme(panel.grid.major = element_blank(), panel.grid.minor =
element_blank(),
              panel.background = element_blank(), axis.line =
element_line(colour = "black"))
p



#################################################################################

Plot: https://postimg.org/image/3vm2uleip/
dataset "it" http://textuploader.com/d593h

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Oct 11 05:49:02 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 10 Oct 2016 20:49:02 -0700
Subject: [R] Recoding lists of categories of a variable
In-Reply-To: <1A8C1289955EF649A09086A153E2672403FE7A2EDA@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
	<1A8C1289955EF649A09086A153E2672403FEA09DBF@GBTEDVPEXCMB04.corp.lgc-group.com>
	<CAGxFJbRugDMXmUP3J+tt6UiycYK32pKL6W7=RqEhezioM_Hi3w@mail.gmail.com>
	<1A8C1289955EF649A09086A153E2672403FE7A2EDA@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <CAGxFJbTFCtUU87ifhcUXAT5fF43h4c16-v44v0OTNBSQJpYDOA@mail.gmail.com>

Still overkill, I believe.


" Unlike using the numeric levels, that doesn't fail if some of the
levels I expect are absent; it only fails (and does so visibly) when
there's a value in there that I haven't assigned a coding to. So it's
a tad more robust. "


If you are concerned about missing levels -- which I agree is
legitimate -- then the following simple modification works (for
**factors** of course):

> d <- factor(letters[1:2],levels= letters[1:3])
> d
[1] a b
Levels: a b c
> f <- factor(d,levels = levels(d), labels = LETTERS[3:1])
> f
[1] C B
Levels: C B A

## No levels lost !

Does that allay your concerns?

Cheers,
Bert


From bob at rud.is  Mon Oct 10 13:59:56 2016
From: bob at rud.is (Bob Rudis)
Date: Mon, 10 Oct 2016 07:59:56 -0400
Subject: [R] turning comma separated string from multiple choices into
In-Reply-To: <CAFY_TcTzCbssFhwRrfHK2oAQ1iDQdgzbaTMEpFjVvVUcy-o78Q@mail.gmail.com>
References: <CAFY_TcTzCbssFhwRrfHK2oAQ1iDQdgzbaTMEpFjVvVUcy-o78Q@mail.gmail.com>
Message-ID: <CAA-FpKXaarkgGdYwtbvniTYP4U2zexp3vvJWm+nj4Hk7zU6fLQ@mail.gmail.com>

Take a look at tidyr::separate()

On Fri, Oct 7, 2016 at 12:57 PM, silvia giussani
<silvia1.giussani at gmail.com> wrote:
> Hi all,
>
>
>
> could you please tell me if you find a solution to this problem (in
> Subject)?
>
>
>
> June Kim wrote:
>
>>* Hello,*
>
>>
>
>>* I use google docs' Forms to conduct surveys online. Multiple choices*
>
>>* questions are coded as comma separated values.*
>
>>
>
>>* For example,*
>
>>
>
>>* if the question is like:*
>
>>
>
>>* 1. What magazines do you currently subscribe to? (you can choose*
>
>>* multiple choices)*
>
>>* 1) Fast Company*
>
>>* 2) Havard Business Review*
>
>>* 3) Business Week*
>
>>* 4) The Economist*
>
>>
>
>>* And if the subject chose 1) and 3), the data is coded as a cell in a*
>
>>* spreadsheet as,*
>
>>
>
>>* "Fast Company, Business Week"*
>
>>
>
>>* I read the data with read.csv into R. To analyze the data, I have to*
>
>>* change that string into something like flags(indicator variables?).*
>
>>* That is, there should be 4 variables, of which values are either 1 or*
>
>>* 0, indicating chosen or not-chosen respectively.*
>
>>
>
>>* Suppose the data is something like,*
>
>>
>
>>
>
>>>* survey1*
>
>>>
>
>>*   age                                    favorite_magazine*
>
>>* 1  29                                         Fast Company*
>
>>* 2  31                          Fast Company, Business Week*
>
>>* 3  32 Havard Business Review, Business Week, The Economist*
>
>>
>
>>
>
>>* Then I have to chop the string in favorite_magazine column to turn*
>
>>* that data into something like,*
>
>>
>
>>
>
>>>* survey1transformed*
>
>>>
>
>>*   age Fast Company Havard Business Review Business Week The Economist*
>
>>* 1  29            1                      0             0             0*
>
>>* 2  31            1                      0             1             0*
>
>>* 3  32            0                      1             1             1*
>
>>
>
>>
>
>>* Actually I have many more multiple choice questions in the survey.*
>
>>
>
>>* What is the easy elegant and natural way in R to do the job?*
>
>>
>
>
>
> I'd look into something like as.data.frame(lapply(strings, grep,
>
> x=favorite_magazine, fixed=TRUE)), where strings <- c("Fast Company",
>
> "Havard Business Review", ...).
>
>
>
> (I take it that the mechanism is such that you can rely on at least
>
> having everything misspelled in the same way? If it is alternatingly
>
> "Havard" and "Harvard", then things get a bit trickier.)
>
>
>
> Thank you and regards,
>
> Silvia Giussani
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Tue Oct 11 09:47:13 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 11 Oct 2016 09:47:13 +0200
Subject: [R] Question about ggplot2 symbol and legend change
In-Reply-To: <CANxP2S7cBTqYcLFVFBckgSiCZ9LG4O3BTSYRzt__WBJ4SnyH5A@mail.gmail.com>
References: <CANxP2S7cBTqYcLFVFBckgSiCZ9LG4O3BTSYRzt__WBJ4SnyH5A@mail.gmail.com>
Message-ID: <CAJuCY5xskSBDc4ANqsdBRhcY7DeJeGOzScjkjN34Y1-XGv9VGA@mail.gmail.com>

Dear Luis,

Please don't post in HTML, it mangles the code.

You want something like

p + scale_shape_manual(values = c(16, 2))

Untested as you failed to provide a reproducible example.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-10-11 4:25 GMT+02:00 Luis Fernando Garc?a <luysgarcia at gmail.com>:

> Dear R experts,
>
> Maybe my question is too basic and I apologize for that. I am having an
> issue currently by trying to change manually the symbols of the series. I
> need to put them manually, instead of using the symbols that R gives by
> default and produce a plot with the classic style. For example I need to
> put the symbols 16 and 2, but I have been unable to do it so far. Also, I
> need to remove the grey background from the seiries but I have been unable
> to do it too.
>
> Any help you can provide will be really helpful.
>
> Below, I am providing the script as well as the picture I gio with it If
> necessary I added the dataset.
>
> Many thanks
>
>
> ############################################################
> #####################
>
>
> it<-read.table("immotime.txt",header=TRUE)
> it
> str(it)
> names(it)
> fit3<-lm(Time ~ Sp*Ratio, data=it)
> anova(fit3)
> plot(fit3)
> summary(fit3)
> a$lPeso <- log(Peso)
> library(ggplot2)
> p <- ggplot(it,aes(x=Ratio,y=Time)) + geom_point(aes(shape=factor(Sp)))
> p=p + geom_smooth(aes(linetype=factor(Sp), ),colour="black", method='lm',
> se=F)+theme(panel.grid.major = element_blank(), panel.grid.minor =
> element_blank(),
>               panel.background = element_blank(), axis.line =
> element_line(colour = "black"))
> p
>
>
>
> ############################################################
> #####################
>
> Plot: https://postimg.org/image/3vm2uleip/
> dataset "it" http://textuploader.com/d593h
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From teotjunk at hotmail.com  Tue Oct 11 09:56:35 2016
From: teotjunk at hotmail.com (TJUN KIAT TEO)
Date: Tue, 11 Oct 2016 07:56:35 +0000
Subject: [R] Hclust
Message-ID: <SG2PR01MB099293BA2183EE23C5B48343DFDA0@SG2PR01MB0992.apcprd01.prod.exchangelabs.com>

For the hclust function in R, is there a predict function that would  work to tell me which cluster does a new observation belong to? Same question for dbscan and self organizing map


Thanks


Tjun Kiat Teo

	[[alternative HTML version deleted]]


From lordpreetam at gmail.com  Tue Oct 11 10:13:44 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Tue, 11 Oct 2016 13:43:44 +0530
Subject: [R] Output formatting in PDF
Message-ID: <CAHVFrXHkuKYf0yiZYfF9KsB5RGfbd_d-LDtYX+bYL1vkqU1SZw@mail.gmail.com>

Hi,

Can you please help me with the following output formatting:
I am planning to include 2 plots and some general description in a one-page
PDF document, such that

   - I'll leave some appropriate margin on the PDF- say, 1.5 inches
   top,right, bottom and left (will decide based on overall appearance)
   - the 2 plots are placed side-by-side (looks best for comparison)
   - the margins for each plot can be 4 lines on the top and the bottom &
    2 lines on the left and the right
   - each of these 2 plots would have time (0 to 260) along x-axis and two
   time-series (daily USD-GBP and USD-EUR FX rates) on the y-axis, i.e. 2
   time-series would be plotted on each of the 2 graphs. I would need a
   different color for each plot to demarcate them
   - I need to add some text (eg: "Independent analysis of Exchange Rate
   dynamics") with reduced font size (not high priority though-just good to
   have a different size)
   - The general discussion (may be a paragraph) would come right below the
   2 plots - I can specify this text as an argument in a function, may be. I
   am not sure how to arrange the entire PDF as per the format I mentioned
   above

I shall really appreciate any help with this - the time series analysis is
not difficult, I can manage that - however, I don't know how to manage the
formatting part though, so that the 1-pager output looks decently
presentable. Thanks.

Regards,
Preetam

	[[alternative HTML version deleted]]


From es at enricoschumann.net  Tue Oct 11 10:59:59 2016
From: es at enricoschumann.net (Enrico Schumann)
Date: Tue, 11 Oct 2016 10:59:59 +0200
Subject: [R] Output formatting in PDF
In-Reply-To: <CAHVFrXHkuKYf0yiZYfF9KsB5RGfbd_d-LDtYX+bYL1vkqU1SZw@mail.gmail.com>
	(Preetam Pal's message of "Tue, 11 Oct 2016 13:43:44 +0530")
References: <CAHVFrXHkuKYf0yiZYfF9KsB5RGfbd_d-LDtYX+bYL1vkqU1SZw@mail.gmail.com>
Message-ID: <87k2dfdzw0.fsf@enricoschumann.net>

On Tue, 11 Oct 2016, Preetam Pal <lordpreetam at gmail.com> writes:

> Hi,
>
> Can you please help me with the following output formatting:
> I am planning to include 2 plots and some general description in a one-page
> PDF document, such that
>
>    - I'll leave some appropriate margin on the PDF- say, 1.5 inches
>    top,right, bottom and left (will decide based on overall appearance)
>    - the 2 plots are placed side-by-side (looks best for comparison)
>    - the margins for each plot can be 4 lines on the top and the bottom &
>     2 lines on the left and the right
>    - each of these 2 plots would have time (0 to 260) along x-axis and two
>    time-series (daily USD-GBP and USD-EUR FX rates) on the y-axis, i.e. 2
>    time-series would be plotted on each of the 2 graphs. I would need a
>    different color for each plot to demarcate them
>    - I need to add some text (eg: "Independent analysis of Exchange Rate
>    dynamics") with reduced font size (not high priority though-just good to
>    have a different size)
>    - The general discussion (may be a paragraph) would come right below the
>    2 plots - I can specify this text as an argument in a function, may be. I
>    am not sure how to arrange the entire PDF as per the format I mentioned
>    above
>
> I shall really appreciate any help with this - the time series analysis is
> not difficult, I can manage that - however, I don't know how to manage the
> formatting part though, so that the 1-pager output looks decently
> presentable. Thanks.
>
> Regards,
> Preetam

If using LaTeX is an option, I would suggest
?Sweave. There are many tutorials on the web that
should get you started.


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From letter at openmailbox.org  Tue Oct 11 11:37:12 2016
From: letter at openmailbox.org (message)
Date: Tue, 11 Oct 2016 09:37:12 +0000
Subject: [R] multiple uses ifelse function
Message-ID: <fb0d4c644a5ed048d20617fffd5adea6@openmailbox.org>

Readers,

Could someone please explain how to apply the function 'ifelse' to 
change a vector, for various conditions?

testseq<-seq(1:20)
testchange<-ifelse(testseq<=4,'x',testseq)
testchange<-c(ifelse(testseq<=4,'x',testseq),ifelse(testseq>=5,'y',testseq))

The last instruction causes the vector 'testchange' to change 
dimensions, when the result wanted is:

testchange
x x x x y y y y y y y y y y y y y y y y


From cimentadaj at gmail.com  Tue Oct 11 11:46:50 2016
From: cimentadaj at gmail.com (Jorge Cimentada)
Date: Tue, 11 Oct 2016 11:46:50 +0200
Subject: [R] multiple uses ifelse function
In-Reply-To: <fb0d4c644a5ed048d20617fffd5adea6@openmailbox.org>
References: <fb0d4c644a5ed048d20617fffd5adea6@openmailbox.org>
Message-ID: <CALdB+JG=MpyjZatUUmb+FEY_K3dFnDzL07vFuVAOiUYXyyEKPA@mail.gmail.com>

Hi Letter,

This should do it:
testchange <- ifelse(testseq <= 4,'x', ifelse(testseq >= 5, 'y', testseq))

Read it as: if testseq <=4, print x, ifelse test seq >=5, print y, any
other case, print testseq.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Oct 11 11:59:14 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 11 Oct 2016 11:59:14 +0200
Subject: [R] Recoding lists of categories of a variable
In-Reply-To: <1A8C1289955EF649A09086A153E2672403FE7A2EDA@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
	<1A8C1289955EF649A09086A153E2672403FEA09DBF@GBTEDVPEXCMB04.corp.lgc-group.com>,
	<CAGxFJbRugDMXmUP3J+tt6UiycYK32pKL6W7=RqEhezioM_Hi3w@mail.gmail.com>
	<1A8C1289955EF649A09086A153E2672403FE7A2EDA@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <628A0689-89EE-4DCA-8EFC-86EA73391C16@gmail.com>


On 11 Oct 2016, at 01:32 , S Ellison <S.Ellison at LGCGroup.com> wrote:

>> Well, I think that's kind of overkill.
> Depends whether you want to recode all or some, and how robust you want the answer to be. 
> recode() allows you to recode a few levels of many, without dependence on level ordering; that's kind of neat. 
> 
> tbh, though,  I don't use recode() a lot; I generally find myself need to change a fair proportion of level labels. 
> 
> But I do get nervous about relying on specific ordering; it can break without visible warning if the data change (eg if you lose a factor level with a slightly different data set, integer indexing will give you apparently valid reassignment to the wrong new codes).  So I tend to go via named vectors even if it costs me a lot of typing. For example to change 
> lcase<-c('a', 'b', 'c') 
> 
> to c('B', 'A', 'C') I'll use something like 
> 
> c(a='B', b='A', c='C')[lcase] 
> 
> or, if lcase were a factor, 
> c(a='B', b='A', c='C')[as.character(lcase)] 

Notice that similar functionality is available via levels<-() (see help page for more features)

> f <- factor(c("a","b","c"))
> levels(f) <- list(A="a", B="b", C="c")
> f
[1] A B C
Levels: A B C

The main advantage of this is that you control the level ordering, and also that you don't quite as easily get caught out by unused levels:

> f <- factor(c("a","c"))
> levels(f) <- list(A="a", B="b", C="c")
> table(f)
f
A B C 
1 0 1 

(in which the 0 count might be important).

-pd

> 
> Unlike using the numeric levels, that doesn't fail if some of the levels I expect are absent; it only fails (and does so visibly) when there's a value in there that I haven't assigned a coding to. So it's a tad more robust.
> 
> Steve E
> 
> 
> 
> 
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From petr.pikal at precheza.cz  Tue Oct 11 12:22:12 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 11 Oct 2016 10:22:12 +0000
Subject: [R] multiple uses ifelse function
In-Reply-To: <CALdB+JG=MpyjZatUUmb+FEY_K3dFnDzL07vFuVAOiUYXyyEKPA@mail.gmail.com>
References: <fb0d4c644a5ed048d20617fffd5adea6@openmailbox.org>
	<CALdB+JG=MpyjZatUUmb+FEY_K3dFnDzL07vFuVAOiUYXyyEKPA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C504108A@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jorge
> Cimentada
> Sent: Tuesday, October 11, 2016 11:47 AM
> To: message <letter at openmailbox.org>
> Cc: r-help at R-project.org
> Subject: Re: [R] multiple uses ifelse function
>
> Hi Letter,
>
> This should do it:
> testchange <- ifelse(testseq <= 4,'x', ifelse(testseq >= 5, 'y', testseq))

This is a little bit complicated.

Enough for this simple recoding is
testchange<-ifelse(testseq<=4,'x',"y")

However

testchange <- cut(testseq, breaks=c(0,4,21), labels=c("x","y"))

is more versatile as it can handle easily more than 2 levels.

Cheers
Petr

>
> Read it as: if testseq <=4, print x, ifelse test seq >=5, print y, any other case,
> print testseq.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From G.Maubach at weinwolf.de  Tue Oct 11 13:13:33 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 11 Oct 2016 13:13:33 +0200
Subject: [R] Documenting a function using roxygen2
Message-ID: <OF5936C9FF.71D382C3-ONC1258049.003D10A5-C1258049.003DAAC2@lotus.hawesko.de>

Hi All,

I began to document my functions using roxygen2. This is an example of a 
function I would like to write for training and testing purposes:

t_simple_table <- function(variable,
                           useNA = TRUE,
                           print = FALSE) {
    #' @title Create a simple table for one variable.
    #'
    #' @description t_simple_table() creates absolute and relative 
    #' frequencies, cumulative sums and column sums for both as well as
    #' overall statistics about valid N and missing values.
    #' 
    #' 
    #' @param variable (vector, list, data.frame): variable the table is
    #' created for.
    #' @param useNA (logical): flag to include or exclude missing values
    #' from the computation.
    #' @param print (logical): flag to print/not print a table before
    #' returning it as an object.
    #' 
    #' @operation
    #' Coerces the given variable to a factor.
    #' If useNA = TRUE NA is also transformed to a valid value,
    #' if useNA = FALSE it is disregarded in all operations.
    #' 
    #' @return Returns a table with the following statistics:
    #' 
    #' <Variable Name> Frequencies   Percent   Cumulative
    #'                                         Percent
    #' Valid                     .         .
    #' Missing                   .         .
    #' Total                     .       100
    #' Categories
    #'   Cat 1                   .         .            .
    #'   Cat 2                   .         .            .
    #'   Cat 3                   .         .            .
    #'   ...                     .         .          100
    #'   Total                   .       100
    #'
    #' @errorhandling None
    #' 
    #' @version "0.1"
    #' 
    #' @created "2016-10-11"
    #' @updated "2016-10-11"
    #' 
    #' @status development
    #'
    #' @see Manderscheid: Sozialwissenschaftliche Datenanalyse mit R, 
    #' p. 79ff
    #'
    #' @author Georg
    #'
    #' @license GPL-2
 
# function body to be defined

}

Is this a correct header for a function?

How could I do better?

Kind regards

Georg


From utz.ryan at gmail.com  Tue Oct 11 13:59:50 2016
From: utz.ryan at gmail.com (Ryan Utz)
Date: Tue, 11 Oct 2016 07:59:50 -0400
Subject: [R] Opening or activating a URL to access data,
	alternative to browseURL
In-Reply-To: <CAA-FpKVRRZtYtBeKiYHpz9VUW5kZaJ_qiFjeg+TQTCTQ=7rwbA@mail.gmail.com>
References: <CAKJ8KVi5KULDekvhA1zfNcAw2EtGjO1C6uJBc9qa3s3jLYEPQA@mail.gmail.com>
	<0000c9bc-d908-2bad-656b-10fea6e2d39f@gmail.com>
	<CAA-FpKVRRZtYtBeKiYHpz9VUW5kZaJ_qiFjeg+TQTCTQ=7rwbA@mail.gmail.com>
Message-ID: <CAKJ8KVjmVKOay5HwopoDKKqXmiCQLwM4vFNc5MLhGDc8Y-hMUA@mail.gmail.com>

Bob/Duncan,

Thanks for writing. I think some of the things Bob mentioned might work,
but I'm still not quite getting there. Below is the example I'm working
with:

#1
browseURL('http://pick18.discoverlife.org/mp/20m?plot=
2&kind=Hypoprepia+fucosa&site=33.9+-83.3&date1=2011,2012,
2013&flags=build_txt:')
# This opens the URL and creates a link to machine-readable data on the
page, which I can then download by simply doing this:

#2
read.delim('http://pick18.discoverlife.org/tmp/Hypoprepia_fucosa_33.9_-83.3_
2011,2012,2013.txt')
#This is what I need to read in terms of data, but this URL only exists if
the URL ran above is activated first

So, for example, try running line #2 without the first line- it won't work.
Next run #1 then #2- works fine.

See what I mean?


On Thu, Sep 29, 2016 at 5:09 PM, Bob Rudis <bob at rud.is> wrote:

> The rvest/httr/curl trio can do the cookie management pretty well. Make
> the initial connection via rvest::html_session() and then hopefully be able
> to use other rvest function calls, but curl and httr calls will use the
> cached in-memory handle info seamlessly. You'd need to store and retrieve
> cookies if you need them preserved between R sessions.
>
> Failing the above and assuming this would not need to be lightning fast,
> use the phantomjs or firefox web driver (either with RSelenium or some new
> stuff rOpenSci is cooking up) which will then do what browsers do best and
> maintain all this state for you. You can still slurp the page contents up
> with xml2::read_html() and use the super handy processing idioms in the
> scraping tidyverse (it needs it's own name).
>
> A concrete example (assuming the URLs aren't sensitive) would enable me or
> someone else to mock up something for you.
>
>
> On Thu, Sep 29, 2016 at 4:59 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 29/09/2016 3:29 PM, Ryan Utz wrote:
>>
>>> Hi all,
>>>
>>> I've got a situation that involves activating a URL so that a link to
>>> some
>>> data becomes available for download. I can easily use 'browseURL' to do
>>> so,
>>> but I'm hoping to make this batch-process-able, and I would prefer to not
>>> have 100s of browser windows open when I go to download multiple data
>>> sets.
>>>
>>> Here's the example:
>>>
>>> #1
>>> browseURL('
>>> http://pick18.discoverlife.org/mp/20m?plot=2&kind=Hypoprepia
>>> +fucosa&site=33.9+-83.3&date1=2011,2012,2013&flags=build_txt:
>>> ')
>>> # This opens the URL and creates a link to machine-readable data on the
>>> page, which I can then download by simply doing this:
>>>
>>> #2
>>> read.delim('
>>> http://pick18.discoverlife.org/tmp/Hypoprepia_fucosa_33.9_-8
>>> 3.3_2011,2012,2013.txt
>>> ')
>>>
>>> However, I can only get the second line above to work if the thing in
>>> line
>>> #1 has been opened in a browser already. Is there any way to allow me to
>>> either 1) close the browser after it's been opened or 2) execute the line
>>> #2 above without having to open a browser? We have hundreds of species
>>> that
>>> you can see after the '&kind=' bit of the URL, so I'm trying to keep the
>>> browsing situation sane.
>>>
>>> Thanks!
>>> R
>>>
>>>
>> You'll need to figure out what happens when you open the first page. Does
>> it set a cookie?  Does it record your IP address?  Does it just build the
>> file but record nothing about you?
>>
>> If it's one of the simpler versions, you can just read the first page,
>> wait a bit, then read the second one.
>>
>> If you need to manage cookies, you'll need something more complicated. I
>> don't know the easiest way to do that.
>>
>> Duncan Murdoch
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 

Ryan Utz, Ph.D.
Assistant professor of water resources
*chatham**UNIVERSITY*
Home/Cell: (724) 272-7769

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Oct 11 15:13:09 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 11 Oct 2016 06:13:09 -0700
Subject: [R] Output formatting in PDF
In-Reply-To: <87k2dfdzw0.fsf@enricoschumann.net>
References: <CAHVFrXHkuKYf0yiZYfF9KsB5RGfbd_d-LDtYX+bYL1vkqU1SZw@mail.gmail.com>
	<87k2dfdzw0.fsf@enricoschumann.net>
Message-ID: <B965C3EE-51F7-4812-8666-79B0F192F70E@dcn.davis.ca.us>

Or package "knitr". Note that knitr can be used with LaTeX or markdown syntax, but from your description the former would be advised. 
-- 
Sent from my phone. Please excuse my brevity.

On October 11, 2016 1:59:59 AM PDT, Enrico Schumann <es at enricoschumann.net> wrote:
>On Tue, 11 Oct 2016, Preetam Pal <lordpreetam at gmail.com> writes:
>
>> Hi,
>>
>> Can you please help me with the following output formatting:
>> I am planning to include 2 plots and some general description in a
>one-page
>> PDF document, such that
>>
>>    - I'll leave some appropriate margin on the PDF- say, 1.5 inches
>>    top,right, bottom and left (will decide based on overall
>appearance)
>>    - the 2 plots are placed side-by-side (looks best for comparison)
>>    - the margins for each plot can be 4 lines on the top and the
>bottom &
>>     2 lines on the left and the right
>>    - each of these 2 plots would have time (0 to 260) along x-axis
>and two
>>    time-series (daily USD-GBP and USD-EUR FX rates) on the y-axis,
>i.e. 2
>>    time-series would be plotted on each of the 2 graphs. I would need
>a
>>    different color for each plot to demarcate them
>>    - I need to add some text (eg: "Independent analysis of Exchange
>Rate
>>    dynamics") with reduced font size (not high priority though-just
>good to
>>    have a different size)
>>    - The general discussion (may be a paragraph) would come right
>below the
>>    2 plots - I can specify this text as an argument in a function,
>may be. I
>>    am not sure how to arrange the entire PDF as per the format I
>mentioned
>>    above
>>
>> I shall really appreciate any help with this - the time series
>analysis is
>> not difficult, I can manage that - however, I don't know how to
>manage the
>> formatting part though, so that the 1-pager output looks decently
>> presentable. Thanks.
>>
>> Regards,
>> Preetam
>
>If using LaTeX is an option, I would suggest
>?Sweave. There are many tutorials on the web that
>should get you started.


From murdoch.duncan at gmail.com  Tue Oct 11 15:21:35 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 11 Oct 2016 09:21:35 -0400
Subject: [R] Opening or activating a URL to access data,
 alternative to browseURL
In-Reply-To: <CAKJ8KVjmVKOay5HwopoDKKqXmiCQLwM4vFNc5MLhGDc8Y-hMUA@mail.gmail.com>
References: <CAKJ8KVi5KULDekvhA1zfNcAw2EtGjO1C6uJBc9qa3s3jLYEPQA@mail.gmail.com>
	<0000c9bc-d908-2bad-656b-10fea6e2d39f@gmail.com>
	<CAA-FpKVRRZtYtBeKiYHpz9VUW5kZaJ_qiFjeg+TQTCTQ=7rwbA@mail.gmail.com>
	<CAKJ8KVjmVKOay5HwopoDKKqXmiCQLwM4vFNc5MLhGDc8Y-hMUA@mail.gmail.com>
Message-ID: <b15f9c84-7b3d-6d7b-2c8b-f52a79f81984@gmail.com>

On 11/10/2016 7:59 AM, Ryan Utz wrote:
> Bob/Duncan,
>
> Thanks for writing. I think some of the things Bob mentioned might work,
> but I'm still not quite getting there. Below is the example I'm working
> with:
>

It worked for me when I replaced the browseURL call with a readLines 
call, as I suggested the other day.  What went wrong for you?

Duncan Murdoch

> #1
> browseURL('http://pick18.discoverlife.org/mp/20m?plot=2&kind=Hypoprepia+fucosa&site=33.9+-83.3&date1=2011,2012,2013&flags=build_txt:
> <http://pick18.discoverlife.org/mp/20m?plot=2&kind=Hypoprepia+fucosa&site=33.9+-83.3&date1=2011,2012,2013&flags=build_txt:>')
> # This opens the URL and creates a link to machine-readable data on the
> page, which I can then download by simply doing this:
>
> #2
> read.delim('http://pick18.discoverlife.org/tmp/Hypoprepia_fucosa_33.9_-83.3_2011,2012,2013.txt
> <http://pick18.discoverlife.org/tmp/Hypoprepia_fucosa_33.9_-83.3_2011,2012,2013.txt>')
> #This is what I need to read in terms of data, but this URL only exists
> if the URL ran above is activated first
>
> So, for example, try running line #2 without the first line- it won't
> work. Next run #1 then #2- works fine.
>
> See what I mean?
>
>
> On Thu, Sep 29, 2016 at 5:09 PM, Bob Rudis <bob at rud.is
> <mailto:bob at rud.is>> wrote:
>
>     The rvest/httr/curl trio can do the cookie management pretty well.
>     Make the initial connection via rvest::html_session() and then
>     hopefully be able to use other rvest function calls, but curl and
>     httr calls will use the cached in-memory handle info seamlessly.
>     You'd need to store and retrieve cookies if you need them preserved
>     between R sessions.
>
>     Failing the above and assuming this would not need to be lightning
>     fast, use the phantomjs or firefox web driver (either with RSelenium
>     or some new stuff rOpenSci is cooking up) which will then do what
>     browsers do best and maintain all this state for you. You can still
>     slurp the page contents up with xml2::read_html() and use the super
>     handy processing idioms in the scraping tidyverse (it needs it's own
>     name).
>
>     A concrete example (assuming the URLs aren't sensitive) would enable
>     me or someone else to mock up something for you.
>
>
>     On Thu, Sep 29, 2016 at 4:59 PM, Duncan Murdoch
>     <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>         On 29/09/2016 3:29 PM, Ryan Utz wrote:
>
>             Hi all,
>
>             I've got a situation that involves activating a URL so that
>             a link to some
>             data becomes available for download. I can easily use
>             'browseURL' to do so,
>             but I'm hoping to make this batch-process-able, and I would
>             prefer to not
>             have 100s of browser windows open when I go to download
>             multiple data sets.
>
>             Here's the example:
>
>             #1
>             browseURL('
>             http://pick18.discoverlife.org/mp/20m?plot=2&kind=Hypoprepia+fucosa&site=33.9+-83.3&date1=2011,2012,2013&flags=build_txt
>             <http://pick18.discoverlife.org/mp/20m?plot=2&kind=Hypoprepia+fucosa&site=33.9+-83.3&date1=2011,2012,2013&flags=build_txt>:
>             ')
>             # This opens the URL and creates a link to machine-readable
>             data on the
>             page, which I can then download by simply doing this:
>
>             #2
>             read.delim('
>             http://pick18.discoverlife.org/tmp/Hypoprepia_fucosa_33.9_-83.3_2011,2012,2013.txt
>             <http://pick18.discoverlife.org/tmp/Hypoprepia_fucosa_33.9_-83.3_2011,2012,2013.txt>
>             ')
>
>             However, I can only get the second line above to work if the
>             thing in line
>             #1 has been opened in a browser already. Is there any way to
>             allow me to
>             either 1) close the browser after it's been opened or 2)
>             execute the line
>             #2 above without having to open a browser? We have hundreds
>             of species that
>             you can see after the '&kind=' bit of the URL, so I'm trying
>             to keep the
>             browsing situation sane.
>
>             Thanks!
>             R
>
>
>         You'll need to figure out what happens when you open the first
>         page. Does it set a cookie?  Does it record your IP address?
>         Does it just build the file but record nothing about you?
>
>         If it's one of the simpler versions, you can just read the first
>         page, wait a bit, then read the second one.
>
>         If you need to manage cookies, you'll need something more
>         complicated. I don't know the easiest way to do that.
>
>         Duncan Murdoch
>
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
> --
>
> Ryan Utz, Ph.D.
> Assistant professor of water resources
> *chatham**UNIVERSITY*
> Home/Cell: (724) 272-7769
>


From thierry.onkelinx at inbo.be  Tue Oct 11 15:46:51 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 11 Oct 2016 15:46:51 +0200
Subject: [R] Documenting a function using roxygen2
In-Reply-To: <OF5936C9FF.71D382C3-ONC1258049.003D10A5-C1258049.003DAAC2@lotus.hawesko.de>
References: <OF5936C9FF.71D382C3-ONC1258049.003D10A5-C1258049.003DAAC2@lotus.hawesko.de>
Message-ID: <CAJuCY5wXUAS+M8TLUh18ga7ScMNs=Fa-rSV-5Uqo_Q4K24_QxA@mail.gmail.com>

Dear Georg,

My 2 eurocents.

- I'd place the Roxygen header just above the function instead of instead
the function. That makes your function more readable.
- Use only tags that Roxygen knows about.
- Use version controle instead of the version, created and updated tags.
- You can specify the author, license and version at the package level.
devtools and Roxygen make it very easy to create a package. Even if it
would contain only one or a few functions.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-10-11 13:13 GMT+02:00 <G.Maubach at weinwolf.de>:

> Hi All,
>
> I began to document my functions using roxygen2. This is an example of a
> function I would like to write for training and testing purposes:
>
> t_simple_table <- function(variable,
>                            useNA = TRUE,
>                            print = FALSE) {
>     #' @title Create a simple table for one variable.
>     #'
>     #' @description t_simple_table() creates absolute and relative
>     #' frequencies, cumulative sums and column sums for both as well as
>     #' overall statistics about valid N and missing values.
>     #'
>     #'
>     #' @param variable (vector, list, data.frame): variable the table is
>     #' created for.
>     #' @param useNA (logical): flag to include or exclude missing values
>     #' from the computation.
>     #' @param print (logical): flag to print/not print a table before
>     #' returning it as an object.
>     #'
>     #' @operation
>     #' Coerces the given variable to a factor.
>     #' If useNA = TRUE NA is also transformed to a valid value,
>     #' if useNA = FALSE it is disregarded in all operations.
>     #'
>     #' @return Returns a table with the following statistics:
>     #'
>     #' <Variable Name> Frequencies   Percent   Cumulative
>     #'                                         Percent
>     #' Valid                     .         .
>     #' Missing                   .         .
>     #' Total                     .       100
>     #' Categories
>     #'   Cat 1                   .         .            .
>     #'   Cat 2                   .         .            .
>     #'   Cat 3                   .         .            .
>     #'   ...                     .         .          100
>     #'   Total                   .       100
>     #'
>     #' @errorhandling None
>     #'
>     #' @version "0.1"
>     #'
>     #' @created "2016-10-11"
>     #' @updated "2016-10-11"
>     #'
>     #' @status development
>     #'
>     #' @see Manderscheid: Sozialwissenschaftliche Datenanalyse mit R,
>     #' p. 79ff
>     #'
>     #' @author Georg
>     #'
>     #' @license GPL-2
>
> # function body to be defined
>
> }
>
> Is this a correct header for a function?
>
> How could I do better?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lordpreetam at gmail.com  Tue Oct 11 12:26:43 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Tue, 11 Oct 2016 15:56:43 +0530
Subject: [R] Output formatting in PDF
In-Reply-To: <87k2dfdzw0.fsf@enricoschumann.net>
References: <CAHVFrXHkuKYf0yiZYfF9KsB5RGfbd_d-LDtYX+bYL1vkqU1SZw@mail.gmail.com>
	<87k2dfdzw0.fsf@enricoschumann.net>
Message-ID: <CAHVFrXHT=D42j8StvWp3fq1qm4H_KoJSiTQ1CGeazQ6MoOjr-g@mail.gmail.com>

Hey Enrico,
LaTex is not possible actually.

On Tue, Oct 11, 2016 at 2:29 PM, Enrico Schumann <es at enricoschumann.net>
wrote:

> On Tue, 11 Oct 2016, Preetam Pal <lordpreetam at gmail.com> writes:
>
> > Hi,
> >
> > Can you please help me with the following output formatting:
> > I am planning to include 2 plots and some general description in a
> one-page
> > PDF document, such that
> >
> >    - I'll leave some appropriate margin on the PDF- say, 1.5 inches
> >    top,right, bottom and left (will decide based on overall appearance)
> >    - the 2 plots are placed side-by-side (looks best for comparison)
> >    - the margins for each plot can be 4 lines on the top and the bottom &
> >     2 lines on the left and the right
> >    - each of these 2 plots would have time (0 to 260) along x-axis and
> two
> >    time-series (daily USD-GBP and USD-EUR FX rates) on the y-axis, i.e. 2
> >    time-series would be plotted on each of the 2 graphs. I would need a
> >    different color for each plot to demarcate them
> >    - I need to add some text (eg: "Independent analysis of Exchange Rate
> >    dynamics") with reduced font size (not high priority though-just good
> to
> >    have a different size)
> >    - The general discussion (may be a paragraph) would come right below
> the
> >    2 plots - I can specify this text as an argument in a function, may
> be. I
> >    am not sure how to arrange the entire PDF as per the format I
> mentioned
> >    above
> >
> > I shall really appreciate any help with this - the time series analysis
> is
> > not difficult, I can manage that - however, I don't know how to manage
> the
> > formatting part though, so that the 1-pager output looks decently
> > presentable. Thanks.
> >
> > Regards,
> > Preetam
>
> If using LaTeX is an option, I would suggest
> ?Sweave. There are many tutorials on the web that
> should get you started.
>
>
> --
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
>



-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From mamushbukana at gmail.com  Tue Oct 11 16:01:35 2016
From: mamushbukana at gmail.com (mamuash bukana)
Date: Tue, 11 Oct 2016 16:01:35 +0200
Subject: [R] Error in reading netcdf files into R
Message-ID: <CAFxDEqLjuTJovv7140ZdZBWmFzF1kGTe5iQjo3gO6LTtHB3NHg@mail.gmail.com>

Dear all,
I have installed necessary packages such as ncdf4 and RNetCDF. But
still my machine can't read netcdf files into R. Below are the file
formats and the respective errors:

> open.nc("cru.ts3.23.1901.2014.tmx.dat.nc")
Error: No such file or directory

> open.nc("cru_ts3_23_1901_2014_pre_dat.nc")
Error: NetCDF: Unknown file format


I am using Windows 7 64-bit.


Thanks for your suggestions and comments in advance

Mamuash


From jdnewmil at dcn.davis.ca.us  Tue Oct 11 16:07:27 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 11 Oct 2016 07:07:27 -0700
Subject: [R] Documenting a function using roxygen2
In-Reply-To: <CAJuCY5wXUAS+M8TLUh18ga7ScMNs=Fa-rSV-5Uqo_Q4K24_QxA@mail.gmail.com>
References: <OF5936C9FF.71D382C3-ONC1258049.003D10A5-C1258049.003DAAC2@lotus.hawesko.de>
	<CAJuCY5wXUAS+M8TLUh18ga7ScMNs=Fa-rSV-5Uqo_Q4K24_QxA@mail.gmail.com>
Message-ID: <94F08E69-F2E4-4D75-8041-DB079FDB02A8@dcn.davis.ca.us>

I was under the impression that the comment block is attached to the global object that immediately follows the comment block, so this placement is NOT optional.
-- 
Sent from my phone. Please excuse my brevity.

On October 11, 2016 6:46:51 AM PDT, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>Dear Georg,
>
>My 2 eurocents.
>
>- I'd place the Roxygen header just above the function instead of
>instead
>the function. That makes your function more readable.
>- Use only tags that Roxygen knows about.
>- Use version controle instead of the version, created and updated
>tags.
>- You can specify the author, license and version at the package level.
>devtools and Roxygen make it very easy to create a package. Even if it
>would contain only one or a few functions.
>
>Best regards,
>
>ir. Thierry Onkelinx
>Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>and
>Forest
>team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>Kliniekstraat 25
>1070 Anderlecht
>Belgium
>
>To call in the statistician after the experiment is done may be no more
>than asking him to perform a post-mortem examination: he may be able to
>say
>what the experiment died of. ~ Sir Ronald Aylmer Fisher
>The plural of anecdote is not data. ~ Roger Brinner
>The combination of some data and an aching desire for an answer does
>not
>ensure that a reasonable answer can be extracted from a given body of
>data.
>~ John Tukey
>
>2016-10-11 13:13 GMT+02:00 <G.Maubach at weinwolf.de>:
>
>> Hi All,
>>
>> I began to document my functions using roxygen2. This is an example
>of a
>> function I would like to write for training and testing purposes:
>>
>> t_simple_table <- function(variable,
>>                            useNA = TRUE,
>>                            print = FALSE) {
>>     #' @title Create a simple table for one variable.
>>     #'
>>     #' @description t_simple_table() creates absolute and relative
>>     #' frequencies, cumulative sums and column sums for both as well
>as
>>     #' overall statistics about valid N and missing values.
>>     #'
>>     #'
>>     #' @param variable (vector, list, data.frame): variable the table
>is
>>     #' created for.
>>     #' @param useNA (logical): flag to include or exclude missing
>values
>>     #' from the computation.
>>     #' @param print (logical): flag to print/not print a table before
>>     #' returning it as an object.
>>     #'
>>     #' @operation
>>     #' Coerces the given variable to a factor.
>>     #' If useNA = TRUE NA is also transformed to a valid value,
>>     #' if useNA = FALSE it is disregarded in all operations.
>>     #'
>>     #' @return Returns a table with the following statistics:
>>     #'
>>     #' <Variable Name> Frequencies   Percent   Cumulative
>>     #'                                         Percent
>>     #' Valid                     .         .
>>     #' Missing                   .         .
>>     #' Total                     .       100
>>     #' Categories
>>     #'   Cat 1                   .         .            .
>>     #'   Cat 2                   .         .            .
>>     #'   Cat 3                   .         .            .
>>     #'   ...                     .         .          100
>>     #'   Total                   .       100
>>     #'
>>     #' @errorhandling None
>>     #'
>>     #' @version "0.1"
>>     #'
>>     #' @created "2016-10-11"
>>     #' @updated "2016-10-11"
>>     #'
>>     #' @status development
>>     #'
>>     #' @see Manderscheid: Sozialwissenschaftliche Datenanalyse mit R,
>>     #' p. 79ff
>>     #'
>>     #' @author Georg
>>     #'
>>     #' @license GPL-2
>>
>> # function body to be defined
>>
>> }
>>
>> Is this a correct header for a function?
>>
>> How could I do better?
>>
>> Kind regards
>>
>> Georg
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dosc3612 at colorado.edu  Tue Oct 11 16:07:08 2016
From: dosc3612 at colorado.edu (Dominik Schneider)
Date: Tue, 11 Oct 2016 08:07:08 -0600
Subject: [R] Output formatting in PDF
In-Reply-To: <CAHVFrXHT=D42j8StvWp3fq1qm4H_KoJSiTQ1CGeazQ6MoOjr-g@mail.gmail.com>
References: <CAHVFrXHkuKYf0yiZYfF9KsB5RGfbd_d-LDtYX+bYL1vkqU1SZw@mail.gmail.com>
	<87k2dfdzw0.fsf@enricoschumann.net>
	<CAHVFrXHT=D42j8StvWp3fq1qm4H_KoJSiTQ1CGeazQ6MoOjr-g@mail.gmail.com>
Message-ID: <CAF1jk_md7Cx-9uD2v__sjbMWD1V2J6ob6LcWsiz6CXiUpZFYdA@mail.gmail.com>

You may be able to do everything you need with the cowplot package.

On Tue, Oct 11, 2016 at 4:26 AM, Preetam Pal <lordpreetam at gmail.com> wrote:

> Hey Enrico,
> LaTex is not possible actually.
>
> On Tue, Oct 11, 2016 at 2:29 PM, Enrico Schumann <es at enricoschumann.net>
> wrote:
>
> > On Tue, 11 Oct 2016, Preetam Pal <lordpreetam at gmail.com> writes:
> >
> > > Hi,
> > >
> > > Can you please help me with the following output formatting:
> > > I am planning to include 2 plots and some general description in a
> > one-page
> > > PDF document, such that
> > >
> > >    - I'll leave some appropriate margin on the PDF- say, 1.5 inches
> > >    top,right, bottom and left (will decide based on overall appearance)
> > >    - the 2 plots are placed side-by-side (looks best for comparison)
> > >    - the margins for each plot can be 4 lines on the top and the
> bottom &
> > >     2 lines on the left and the right
> > >    - each of these 2 plots would have time (0 to 260) along x-axis and
> > two
> > >    time-series (daily USD-GBP and USD-EUR FX rates) on the y-axis,
> i.e. 2
> > >    time-series would be plotted on each of the 2 graphs. I would need a
> > >    different color for each plot to demarcate them
> > >    - I need to add some text (eg: "Independent analysis of Exchange
> Rate
> > >    dynamics") with reduced font size (not high priority though-just
> good
> > to
> > >    have a different size)
> > >    - The general discussion (may be a paragraph) would come right below
> > the
> > >    2 plots - I can specify this text as an argument in a function, may
> > be. I
> > >    am not sure how to arrange the entire PDF as per the format I
> > mentioned
> > >    above
> > >
> > > I shall really appreciate any help with this - the time series analysis
> > is
> > > not difficult, I can manage that - however, I don't know how to manage
> > the
> > > formatting part though, so that the 1-pager output looks decently
> > > presentable. Thanks.
> > >
> > > Regards,
> > > Preetam
> >
> > If using LaTeX is an option, I would suggest
> > ?Sweave. There are many tutorials on the web that
> > should get you started.
> >
> >
> > --
> > Enrico Schumann
> > Lucerne, Switzerland
> > http://enricoschumann.net
> >
>
>
>
> --
> Preetam Pal
> (+91)-9432212774
> M-Stat 2nd Year,                                             Room No. N-114
> Statistics Division,                                           C.V.Raman
> Hall
> Indian Statistical Institute,                                 B.H.O.S.
> Kolkata.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Tue Oct 11 18:01:36 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 11 Oct 2016 17:01:36 +0100
Subject: [R] multiple uses ifelse function
In-Reply-To: <fb0d4c644a5ed048d20617fffd5adea6@openmailbox.org>
References: <fb0d4c644a5ed048d20617fffd5adea6@openmailbox.org>
Message-ID: <1A8C1289955EF649A09086A153E2672403FEA0A044@GBTEDVPEXCMB04.corp.lgc-group.com>



> -----Original Message-----
> testseq<-seq(1:20)
> testchange<-ifelse(testseq<=4,'x',testseq)
> testchange<-c(ifelse(testseq<=4,'x',testseq),ifelse(testseq>=5,'y',testseq))
> 
> The last instruction causes the vector 'testchange' to change dimensions,

Of course it does. ifelse(test, yes, no) returns a vector of length length(test). Your last line concatenates two of them, so you'll get a vector of length 40.

You might also want to note that you are replacing numbers with character strings, so 
ifelse(testseq<=4,'x',testseq)

will return four 'x's and then - because R has to coerce everything to a single type - character representations of numbers 5:20. That will not then respond well to subsequent numeric comparisons ...

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at LGCGroup.com  Tue Oct 11 18:19:06 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 11 Oct 2016 17:19:06 +0100
Subject: [R] Recoding lists of categories of a variable
In-Reply-To: <CAGxFJbTFCtUU87ifhcUXAT5fF43h4c16-v44v0OTNBSQJpYDOA@mail.gmail.com>
References: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
	<1A8C1289955EF649A09086A153E2672403FEA09DBF@GBTEDVPEXCMB04.corp.lgc-group.com>
	<CAGxFJbRugDMXmUP3J+tt6UiycYK32pKL6W7=RqEhezioM_Hi3w@mail.gmail.com>
	<1A8C1289955EF649A09086A153E2672403FE7A2EDA@GBTEDVPEXCMB04.corp.lgc-group.com>
	<CAGxFJbTFCtUU87ifhcUXAT5fF43h4c16-v44v0OTNBSQJpYDOA@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403FEA0A04A@GBTEDVPEXCMB04.corp.lgc-group.com>

> If you are concerned about missing levels -- which I agree is legitimate -- then
> the following simple modification works (for
> **factors** of course):
> 
> > d <- factor(letters[1:2],levels= letters[1:3]) d
> [1] a b
> Levels: a b c
> > f <- factor(d,levels = levels(d), labels = LETTERS[3:1]) f
> [1] C B
> Levels: C B A
> 
> ## No levels lost !
> 
> Does that allay your concerns?

If you control the factor creation, sure. But it gets a bit untidy if your factors are created on data reading or similar; read.table doesn?t give you the option to set levels on factor creation. You have to go back over your data frame etc to fix it. That's legit, of course, but would amount to recoding the same factor twice - once to re-set the levels to the full set, and a second time to recode them.

Hardly a showstopper though; we're in timtowdi territory here and we're allowed a bit of personal preference. My preference just happens to be conditioned by SQL and other applications where ordering is explicitly _not_ guaranteed unless you specify it. So relying on implicit ordering makes me decidedly nervous, and I see associative arrays and other order-independent operations as  much safer. 

S




*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From Simon.Heather at epa.gov  Tue Oct 11 19:01:38 2016
From: Simon.Heather at epa.gov (Simon, Heather)
Date: Tue, 11 Oct 2016 17:01:38 +0000
Subject: [R] date comparison doesn't match value
In-Reply-To: <CA+8X3fUN0Y35+RPCBhrU_h52cRTaPQxhSXfKAScZGExDSR+0qA@mail.gmail.com>
References: <BLUPR09MB089862605DCE8F4E64B12F47E1C60@BLUPR09MB0898.namprd09.prod.outlook.com>
	<CA+8X3fUN0Y35+RPCBhrU_h52cRTaPQxhSXfKAScZGExDSR+0qA@mail.gmail.com>
Message-ID: <BLUPR09MB08981AA1B7F73A34BAF15B80E1DA0@BLUPR09MB0898.namprd09.prod.outlook.com>

Thanks Jim and others who have responded to this post!

Jim, this is exactly what happened.  I was having some trouble with date comparisons which turned out to be a time zone conversion issue even though the two dates I was comparing both said they were EST, when you subtracted one from the other the differences was 4 hours off from what the answer should have been (i.e. one date was interpreted as GMT).  However, when I started trying to debug I compared the as.POSIXct object to a date character string.  R interpreted the character string as a numeric value that translated to sometime in the year 1309.

Thanks for everyone's help.

Cheers,
Heather

-----Original Message-----
From: Jim Lemon [mailto:drjimlemon at gmail.com] 
Sent: Saturday, October 08, 2016 6:04 AM
To: Simon, Heather <Simon.Heather at epa.gov>
Subject: Re: [R] date comparison doesn't match value

Hi Heather,
I think the problem may be that you are trying to compare a date field and a character string. R helpfully tries to wrangle the two into comparable data types. While I don't know exactly what you have done, as R for:

as.numeric(alldata$new.date.local)

and look at the value you get.

JIm


On Sat, Oct 8, 2016 at 3:41 AM, Simon, Heather <Simon.Heather at epa.gov> wrote:
> I am running into trouble when trying to compare date fields in my dataset.  When I view a field, it looks like it is a date in 2011:
>
>
>> alldata$new.date.local[1]
> [1] "2011-07-01 12:08:07 EDT"
>
> However, when I try to compare it to a character string, it seems to 
> think it is equal to sometime between the years 1310 and 1309
>
>> alldata$new.date.local[1] < "1310-01-01 00:00:00 EDT"
> [1] TRUE
>> alldata$new.date.local[1] < "1309-12-31 23:59:59 EDT"
> [1] FALSE
>
> But not exactly equal to midnight of Dec 31 in 1309, so it is not equal to any exact time:
>
>> alldata$new.date.local[1] == "1309-12-31 23:59:59 EDT"
> [1] FALSE
>> alldata$new.date.local[1] < "1309-12-31 23:59:59 EDT"
> [1] FALSE
>> alldata$new.date.local[1] > "1309-12-31 23:59:59 EDT"
> [1] TRUE
>
> Even though this date field was created using as.POSIXct from a text string, I have tried fixing this by reapplying the as.POSIXct function:
>
>>alldata$new.date.local <- as.POSIXct(alldata$new.date.local, tz = 
>>"EDT")
>
> But this does not seem to fix the problem.  When I try recreating the date from a character string I get the same behavior.  Any suggestions would be much appreciated.
>
> -Heather
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From bgunter.4567 at gmail.com  Tue Oct 11 19:08:07 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 11 Oct 2016 10:08:07 -0700
Subject: [R] Recoding lists of categories of a variable
In-Reply-To: <1A8C1289955EF649A09086A153E2672403FEA0A04A@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <VI1PR0502MB3021FE32C6163F0C56797221C5DB0@VI1PR0502MB3021.eurprd05.prod.outlook.com>
	<1A8C1289955EF649A09086A153E2672403FEA09DBF@GBTEDVPEXCMB04.corp.lgc-group.com>
	<CAGxFJbRugDMXmUP3J+tt6UiycYK32pKL6W7=RqEhezioM_Hi3w@mail.gmail.com>
	<1A8C1289955EF649A09086A153E2672403FE7A2EDA@GBTEDVPEXCMB04.corp.lgc-group.com>
	<CAGxFJbTFCtUU87ifhcUXAT5fF43h4c16-v44v0OTNBSQJpYDOA@mail.gmail.com>
	<1A8C1289955EF649A09086A153E2672403FEA0A04A@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <CAGxFJbRG5t-LPcqsxJ7DzFHfsXY1VqJG9XVGn6xkT66ebLDjBA@mail.gmail.com>

> Hardly a showstopper though; we're in timtowdi territory here and we're allowed a bit of personal preference.


Absolutely. I appreciate your constructive comments, however.

Cheers,
Bert


From dcarlson at tamu.edu  Tue Oct 11 21:28:52 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 11 Oct 2016 19:28:52 +0000
Subject: [R] Hclust
In-Reply-To: <SG2PR01MB099293BA2183EE23C5B48343DFDA0@SG2PR01MB0992.apcprd01.prod.exchangelabs.com>
References: <SG2PR01MB099293BA2183EE23C5B48343DFDA0@SG2PR01MB0992.apcprd01.prod.exchangelabs.com>
Message-ID: <c88b98465c20423db2d796095079d16c@exch-2p-mbx-w2.ads.tamu.edu>

Not for hclust() since it provides results for all clusters from 1 to n (the number of observations). Adding a point can change the definition of the clusters. You could use cutree() to assign the observations to clusters for a particular number of clusters, but then you must decide what rule to use in assigning your new point to one of those clusters (the method= argument in hclust). A simple solution would be to identify to which of the original points, your new point is closest. Assign the new point to the cluster that point is in. Another would be to use aggregate() to compute the centers of the clusters and assign the new point to the closest center. These two approaches will not necessarily agree with one another.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of TJUN KIAT TEO
Sent: Tuesday, October 11, 2016 2:57 AM
To: r-help at r-project.org
Subject: [R] Hclust

For the hclust function in R, is there a predict function that would  work to tell me which cluster does a new observation belong to? Same question for dbscan and self organizing map


Thanks


Tjun Kiat Teo

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Wed Oct 12 00:05:59 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 12 Oct 2016 09:05:59 +1100
Subject: [R] Output formatting in PDF
In-Reply-To: <CAHVFrXHkuKYf0yiZYfF9KsB5RGfbd_d-LDtYX+bYL1vkqU1SZw@mail.gmail.com>
References: <CAHVFrXHkuKYf0yiZYfF9KsB5RGfbd_d-LDtYX+bYL1vkqU1SZw@mail.gmail.com>
Message-ID: <000501d2240b$a6dc6eb0$f4954c10$@bigpond.com>

Hi

There is also the basic option of using the grid package and viewports.
You can then place the plots where you want and annotate them

    pdf(file    = paste0("01", ".pdf"),
        height  = 3.5,
        width   = 7,
        paper   = "special",
        onefile = TRUE,
        family  = "Helvetica",
        pointsize = 12,
        colormodel = "rgb")
        
    vpl <- viewport(x = 0.25, y = 0.5, width = 0.45, height = 0.9)
    pushViewport(vpl)
    grid.rect(gp = gpar(lty = "dashed"))
    popViewport()

    vpr <- viewport(x = 0.75, y = 0.5, width = 0.45, height = 0.9)
    pushViewport(vpr)
    grid.rect(gp = gpar(lty = "dashed"))
    grid.circle(x = 0.6, y = 0.4, r = 0.3)
    popViewport()
    
    dev.off()

In your case you may need to have a viewport of the whole page

see  http://www.amstat.org/publications/jse/v18n3/zhou.pdf for examples

also have a look at the grid.clip function

Regards

Duncan Mackay

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Preetam Pal
Sent: Tuesday, 11 October 2016 19:14
To: r-help at r-project.org
Subject: [R] Output formatting in PDF

Hi,

Can you please help me with the following output formatting:
I am planning to include 2 plots and some general description in a one-page
PDF document, such that

   - I'll leave some appropriate margin on the PDF- say, 1.5 inches
   top,right, bottom and left (will decide based on overall appearance)
   - the 2 plots are placed side-by-side (looks best for comparison)
   - the margins for each plot can be 4 lines on the top and the bottom &
    2 lines on the left and the right
   - each of these 2 plots would have time (0 to 260) along x-axis and two
   time-series (daily USD-GBP and USD-EUR FX rates) on the y-axis, i.e. 2
   time-series would be plotted on each of the 2 graphs. I would need a
   different color for each plot to demarcate them
   - I need to add some text (eg: "Independent analysis of Exchange Rate
   dynamics") with reduced font size (not high priority though-just good to
   have a different size)
   - The general discussion (may be a paragraph) would come right below the
   2 plots - I can specify this text as an argument in a function, may be. I
   am not sure how to arrange the entire PDF as per the format I mentioned
   above

I shall really appreciate any help with this - the time series analysis is
not difficult, I can manage that - however, I don't know how to manage the
formatting part though, so that the 1-pager output looks decently
presentable. Thanks.

Regards,
Preetam

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From klebyn at yahoo.com.br  Wed Oct 12 02:13:26 2016
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Tue, 11 Oct 2016 21:13:26 -0300
Subject: [R] which properly to avoid pointer copy Tcl Tk? 'externalptr'
Message-ID: <5ab27675-47e5-2a0a-270c-b8351f141adb@yahoo.com.br>

hello,
I'm trying to disable an tkentry widget with a tkcheckbutton using an R
function via the command flag.
but I get an error regardding copy of the pointer: 'externalptr'
which properly way to avoid this?

thanks,
cleber
####################
 > library( tcltk )
 > tp <- tktoplevel()
 >
 > chk <- tclVar( TRUE )
 > statusentry <- tclVar( "normal" ) # normal, disabled
 > anystring <- tclVar( "anystring" )
 >
 > chebut <- ttkcheckbutton( tp, variable=chk, text='Save with new name:
', onvalue=TRUE, offvalue=FALSE,
+ command=function(...) ifelse( as.numeric(tclvalue(chk)),
+    tkconfigure(ent1,'-state','normal'),
+    tkconfigure(ent1,'-state','disabled') )
+   )
 > tcl( 'pack', chebut )
<Tcl>
 >
 > ent1 <- ttkentry( tp, textvariable=anystring, state='normal' )
 > tcl( 'pack', ent1 )
<Tcl>
Error in rep(no, length.out = length(ans)) :
   attempt to replicate an object of type 'externalptr'
 >



---
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From marna.wagley at gmail.com  Wed Oct 12 10:49:28 2016
From: marna.wagley at gmail.com (Marna Wagley)
Date: Wed, 12 Oct 2016 01:49:28 -0700
Subject: [R] can we visualize water flows with 3d in R?
Message-ID: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>

Hi R Users,
Is it possible to visualize river flow in  3D (latitude, longitude with
respect to depth)?
The example of my data looks like. Any suggestions?

> dat1
    long lat depth flow
1 1015.9 857  1.00 1.50
2 1015.9 857  1.25 1.23
3 1015.9 857  0.50 2.00
4 1015.9 858  0.10 1.95
5 1015.9 858  0.20 1.50
6 1025.0 858  0.30 1.20
7 1025.0 858  0.40 0.50
8 1025.0 858  0.35 0.70
9 1025.0 858  0.24 1.20

Thanks for your help.
thanks

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Oct 12 11:49:27 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 12 Oct 2016 20:49:27 +1100
Subject: [R] can we visualize water flows with 3d in R?
In-Reply-To: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
References: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
Message-ID: <CA+8X3fVMGZcQZg60T6DizcVdHh-H7_nSX5orpC-W0tGc-osgTQ@mail.gmail.com>

Hi Marna,
Isn't the conventional way to visualize depth as shades of blue?

library(plotrix)
depth.col<-color.scale(dat1$depth,extremes=c("lightblue",blue"))

Then color the lon/lat rectangles with depth.col

Jim



On Wed, Oct 12, 2016 at 7:49 PM, Marna Wagley <marna.wagley at gmail.com> wrote:
> Hi R Users,
> Is it possible to visualize river flow in  3D (latitude, longitude with
> respect to depth)?
> The example of my data looks like. Any suggestions?
>
>> dat1
>     long lat depth flow
> 1 1015.9 857  1.00 1.50
> 2 1015.9 857  1.25 1.23
> 3 1015.9 857  0.50 2.00
> 4 1015.9 858  0.10 1.95
> 5 1015.9 858  0.20 1.50
> 6 1025.0 858  0.30 1.20
> 7 1025.0 858  0.40 0.50
> 8 1025.0 858  0.35 0.70
> 9 1025.0 858  0.24 1.20
>
> Thanks for your help.
> thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michal.kubista at nielsen.com  Wed Oct 12 11:27:29 2016
From: michal.kubista at nielsen.com (Michal Kubista)
Date: Wed, 12 Oct 2016 11:27:29 +0200
Subject: [R] can we visualize water flows with 3d in R?
In-Reply-To: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
References: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
Message-ID: <CACW3oCRNkVudOF5s+kOczZhfzPcfzTDN9PSUdR6juoceikX+Gw@mail.gmail.com>

Dear Marna,
This might come handy:
http://www.geo.ut.ee/aasa/LOOM02331/heatmap_in_R.html

Best regards,
Michal


*Michal Kubi?ta*
Retail Analytics Support
Europe Central/East
Nielsen
tel (+420) 242 438 737
www.nielsen.com

[image: nielsen] <http://www.nielsen.com/>

2016-10-12 10:49 GMT+02:00 Marna Wagley <marna.wagley at gmail.com>:

> Hi R Users,
> Is it possible to visualize river flow in  3D (latitude, longitude with
> respect to depth)?
> The example of my data looks like. Any suggestions?
>
> > dat1
>     long lat depth flow
> 1 1015.9 857  1.00 1.50
> 2 1015.9 857  1.25 1.23
> 3 1015.9 857  0.50 2.00
> 4 1015.9 858  0.10 1.95
> 5 1015.9 858  0.20 1.50
> 6 1025.0 858  0.30 1.20
> 7 1025.0 858  0.40 0.50
> 8 1025.0 858  0.35 0.70
> 9 1025.0 858  0.24 1.20
>
> Thanks for your help.
> thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Oct 12 13:28:55 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 12 Oct 2016 07:28:55 -0400
Subject: [R] can we visualize water flows with 3d in R?
In-Reply-To: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
References: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
Message-ID: <b9652b19-25ba-ec08-c124-b77d4d34f70e@gmail.com>

On 12/10/2016 4:49 AM, Marna Wagley wrote:
> Hi R Users,
> Is it possible to visualize river flow in  3D (latitude, longitude with
> respect to depth)?
> The example of my data looks like. Any suggestions?
>
>> dat1
>     long lat depth flow
> 1 1015.9 857  1.00 1.50
> 2 1015.9 857  1.25 1.23
> 3 1015.9 857  0.50 2.00
> 4 1015.9 858  0.10 1.95
> 5 1015.9 858  0.20 1.50
> 6 1025.0 858  0.30 1.20
> 7 1025.0 858  0.40 0.50
> 8 1025.0 858  0.35 0.70
> 9 1025.0 858  0.24 1.20
>
> Thanks for your help.

It may be, but it's hard to give a nice looking graphic of that small 
dataset.  You could try the rgl package and use plot3d to show spheres 
with radius depending on the flow rate, for example

plot3d(cbind(long, lat, depth), type="s", col="blue", radius=flow/5)

Duncan Murdoch


From clark.richards at gmail.com  Wed Oct 12 16:27:31 2016
From: clark.richards at gmail.com (clark richards)
Date: Wed, 12 Oct 2016 11:27:31 -0300
Subject: [R] can we visualize water flows with 3d in R?
Message-ID: <CAJx09A=VDojOQOG07dJHoPjWYTJFtd-+Zxs_Tv4_x5tXdPXc-Q@mail.gmail.com>

Hi Marna,

It's hard to tell exactly what you're looking for, since making "3D" plots
of fluid flow has significant interpretative challenges (e.g. how do you
see the flow for points that are "inside" the domain?). It is common in
fields like oceanography to plot 2D "sections" of the 3D flow -- e.g. a
latitude-depth plot at a range of different longitudes. Someone else
pointed out the `heatmap()` function, but I would also point out the
`imagep()` function in the `oce` package, which can make image plots (with
a palette, or colorbar).

Cheers,
Clark

On Wed, Oct 12, 2016 at 7:00 AM, <r-help-request at r-project.org> wrote:

>
> Message: 18
> Date: Wed, 12 Oct 2016 01:49:28 -0700
> From: Marna Wagley <marna.wagley at gmail.com>
> To: r-help mailing list <r-help at r-project.org>
> Subject: [R] can we visualize water flows with 3d in R?
> Message-ID:
>         <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q at mail.
> gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Hi R Users,
> Is it possible to visualize river flow in  3D (latitude, longitude with
> respect to depth)?
> The example of my data looks like. Any suggestions?
>
> > dat1
>     long lat depth flow
> 1 1015.9 857  1.00 1.50
> 2 1015.9 857  1.25 1.23
> 3 1015.9 857  0.50 2.00
> 4 1015.9 858  0.10 1.95
> 5 1015.9 858  0.20 1.50
> 6 1025.0 858  0.30 1.20
> 7 1025.0 858  0.40 0.50
> 8 1025.0 858  0.35 0.70
> 9 1025.0 858  0.24 1.20
>
> Thanks for your help.
> thanks
>
>         [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> Message: 19
> Date: Wed, 12 Oct 2016 20:49:27 +1100
> From: Jim Lemon <drjimlemon at gmail.com>
> To: Marna Wagley <marna.wagley at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] can we visualize water flows with 3d in R?
> Message-ID:
>         <CA+8X3fVMGZcQZg60T6DizcVdHh-H7_nSX5orpC-W0tGc-osgTQ at mail.
> gmail.com>
> Content-Type: text/plain; charset=UTF-8
>
> Hi Marna,
> Isn't the conventional way to visualize depth as shades of blue?
>
> library(plotrix)
> depth.col<-color.scale(dat1$depth,extremes=c("lightblue",blue"))
>
> Then color the lon/lat rectangles with depth.col
>
> Jim
>
>
>
> On Wed, Oct 12, 2016 at 7:49 PM, Marna Wagley <marna.wagley at gmail.com>
> wrote:
> > Hi R Users,
> > Is it possible to visualize river flow in  3D (latitude, longitude with
> > respect to depth)?
> > The example of my data looks like. Any suggestions?
> >
> >> dat1
> >     long lat depth flow
> > 1 1015.9 857  1.00 1.50
> > 2 1015.9 857  1.25 1.23
> > 3 1015.9 857  0.50 2.00
> > 4 1015.9 858  0.10 1.95
> > 5 1015.9 858  0.20 1.50
> > 6 1025.0 858  0.30 1.20
> > 7 1025.0 858  0.40 0.50
> > 8 1025.0 858  0.35 0.70
> > 9 1025.0 858  0.24 1.20
> >
> > Thanks for your help.
> > thanks
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ------------------------------
>
> End of R-help Digest, Vol 164, Issue 12
> ***************************************
>

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Wed Oct 12 17:11:12 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 12 Oct 2016 08:11:12 -0700
Subject: [R] xtractomatic package is now available in CRAN
Message-ID: <4846C376-7476-4D9D-8000-AF4CB2C90E23@noaa.gov>

I am pleased to announce that the xtractomatic package is now available from CRAN.

xtractomatic is an R package developed to subset and extract satellite and other oceanographic related data from a remote server. The program can extract data for a moving point in time along a user-supplied set of longitude, latitude and time points; in a 3D bounding box; or within a polygon (through time). The xtractomatic functions were originally developed for the marine biology tagging community, to match up environmental data available from satellites (sea-surface temperature, sea-surface chlorophyll, sea-surface height, sea-surface salinity, vector winds) to track data from various tagged animals or shiptracks (xtracto). The package has since been extended to include the routines that extract data a 3D bounding box (xtracto_3D) or within a polygon (xtractogon). The xtractomatic package accesses data that are served through the ERDDAP  server at the NOAA/SWFSC Environmental Research Division in Santa Cruz, California. The ERDDAP server can also be directly accessed at http://coastwatch.pfeg.noaa.gov/erddap. ERDDAP is a simple to use yet powerful web data service developed by Bob Simons. 


-Roy



**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From oriolebaltimore at gmail.com  Wed Oct 12 18:20:38 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Wed, 12 Oct 2016 12:20:38 -0400
Subject: [R] barplot beside=TRUE - values differ on scales
Message-ID: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>

Dear group,
I have been struggling to barplot two different measurements from one
subject. These two measures differ in range.  I want to plot row 1
axis on left side and row 2 values on right side.

For a given column I want to plot GN and CN next to each other.

my dput code is below
:

structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
"CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
)))


As you can see:
   DC5 DC8 DC14 DC18 DC19 DC20 DC23
GN 112 579  131 2234 2892  528  582
CN   0   1    1    2    1    0    2

GN values are range from 100 - 3000
while CN are always -2 or -1 or 0 or 1 or 2

Also I cannot log GN values and plot because a difference in 100 units
also matters in my experiment.

Any help would be greatly appreciated.

Thanks
Adrian


From S.Ellison at LGCGroup.com  Wed Oct 12 18:36:27 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 12 Oct 2016 17:36:27 +0100
Subject: [R] barplot beside=TRUE - values differ on scales
In-Reply-To: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
References: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403FEA0A285@GBTEDVPEXCMB04.corp.lgc-group.com>

I have suspect that the most common answer to this will be 'don't', for all the reasons statisticians don't like mixing vertical scales on the same plot. See http://www.perceptualedge.com/articles/visual_business_intelligence/dual-scaled_axes.pdf for one article on that topic.

But if you must, is there any reason you can't divide the first row by (say) 1000, barplot normally with axes=false, and then put an explicit axis up each side with something like
axis(2, at=seq(0,3, 0.5), labels= seq(0,2500,500)) ) #first row axis, left column
axis(4)

S Ellison


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Adrian
> Johnson
> Sent: 12 October 2016 17:21
> To: r-help
> Subject: [R] barplot beside=TRUE - values differ on scales
> 
> Dear group,
> I have been struggling to barplot two different measurements from one
> subject. These two measures differ in range.  I want to plot row 1 axis on left
> side and row 2 values on right side.
> 
> For a given column I want to plot GN and CN next to each other.
> 
> my dput code is below
> :
> 
> structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L, 528L, 0L, 582L, 2L),
> .Dim = c(2L, 7L), .Dimnames = list(c("GN", "CN"), c("DC5", "DC8", "DC14",
> "DC18", "DC19", "DC20", "DC23"
> )))
> 
> 
> As you can see:
>    DC5 DC8 DC14 DC18 DC19 DC20 DC23
> GN 112 579  131 2234 2892  528  582
> CN   0   1    1    2    1    0    2
> 
> GN values are range from 100 - 3000
> while CN are always -2 or -1 or 0 or 1 or 2
> 
> Also I cannot log GN values and plot because a difference in 100 units also
> matters in my experiment.
> 
> Any help would be greatly appreciated.
> 
> Thanks
> Adrian
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jvadams at usgs.gov  Wed Oct 12 18:36:58 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 12 Oct 2016 11:36:58 -0500
Subject: [R] barplot beside=TRUE - values differ on scales
In-Reply-To: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
References: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
Message-ID: <CAN5YmCGALnyGtWSaPq9hPcv2QxfmPibyt3CL5xYQyJJ1WVMJ1g@mail.gmail.com>

Adrian,

What story are you trying to tell?  Or what question are you trying to
answer by visualizing these data?  How is a bar plot of these numbers going
to help?  I'm just wondering if perhaps a different visualization might
make more sense, for example, a scatter plot of GN vs. CN.

m <- structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
  528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
  "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
  )))
plot(m["GN", ], m["CN", ])

Jean


On Wed, Oct 12, 2016 at 11:20 AM, Adrian Johnson <oriolebaltimore at gmail.com>
wrote:

> Dear group,
> I have been struggling to barplot two different measurements from one
> subject. These two measures differ in range.  I want to plot row 1
> axis on left side and row 2 values on right side.
>
> For a given column I want to plot GN and CN next to each other.
>
> my dput code is below
> :
>
> structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
> 528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
> "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
> )))
>
>
> As you can see:
>    DC5 DC8 DC14 DC18 DC19 DC20 DC23
> GN 112 579  131 2234 2892  528  582
> CN   0   1    1    2    1    0    2
>
> GN values are range from 100 - 3000
> while CN are always -2 or -1 or 0 or 1 or 2
>
> Also I cannot log GN values and plot because a difference in 100 units
> also matters in my experiment.
>
> Any help would be greatly appreciated.
>
> Thanks
> Adrian
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Oct 12 18:42:57 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 12 Oct 2016 12:42:57 -0400
Subject: [R] barplot beside=TRUE - values differ on scales
In-Reply-To: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
References: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
Message-ID: <2d69881b-d884-b18e-3e46-9133481d65cb@gmail.com>

On 12/10/2016 12:20 PM, Adrian Johnson wrote:
> Dear group,
> I have been struggling to barplot two different measurements from one
> subject. These two measures differ in range.  I want to plot row 1
> axis on left side and row 2 values on right side.
>
> For a given column I want to plot GN and CN next to each other.
>
> my dput code is below
> :
>
> structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
> 528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
> "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
> )))
>
>
> As you can see:
>     DC5 DC8 DC14 DC18 DC19 DC20 DC23
> GN 112 579  131 2234 2892  528  582
> CN   0   1    1    2    1    0    2
>
> GN values are range from 100 - 3000
> while CN are always -2 or -1 or 0 or 1 or 2
>
> Also I cannot log GN values and plot because a difference in 100 units
> also matters in my experiment.
>
> Any help would be greatly appreciated.

I would simply rescale one row and add a second axis.  For example, if d 
holds your matrix:

scale <- max(d[1,])/max(d[2,])
adjusted <- d
adjusted[2,] <- scale*adjusted[2,]
barplot(adjusted, beside = TRUE)
ticks <- pretty(d[2,])
axis(side = 4, at = ticks*scale, labels = ticks)

Duncan Murdoch


From oriolebaltimore at gmail.com  Wed Oct 12 18:55:59 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Wed, 12 Oct 2016 12:55:59 -0400
Subject: [R] barplot beside=TRUE - values differ on scales
In-Reply-To: <CAN5YmCGALnyGtWSaPq9hPcv2QxfmPibyt3CL5xYQyJJ1WVMJ1g@mail.gmail.com>
References: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
	<CAN5YmCGALnyGtWSaPq9hPcv2QxfmPibyt3CL5xYQyJJ1WVMJ1g@mail.gmail.com>
Message-ID: <CAL2fYnMtx2ghLh8R7vHAZx5GekrcJ7JSc01L+-vFgugObwUFmQ@mail.gmail.com>

Hi Adams,
The story I am trying to show visually relationship between GN and CN
for every column. Each column represents a patient. In each patient, a
particular chromosome region (CN) is either lost (-2 or -1) or gained
(1 or 2). Typically if loss (one copy loss - as humans have pair of
chromosome) or homozygous (two copies loss) theoretically indicate
decrease in number of copies of gene located in that region of
chromosome. The number of copies of a gene located in that chromosomal
regions are indicated by GN.
through this barplot, I intend to show that in 7 cases (columns) if a
relationship exist by plotting GN and CN next to each other.  If I log
values in GN, I am loosing the minor differences between cases in GN.
hope I could convince/explain.
thanks
adrian

On Wed, Oct 12, 2016 at 12:36 PM, Adams, Jean <jvadams at usgs.gov> wrote:
> Adrian,
>
> What story are you trying to tell?  Or what question are you trying to
> answer by visualizing these data?  How is a bar plot of these numbers going
> to help?  I'm just wondering if perhaps a different visualization might make
> more sense, for example, a scatter plot of GN vs. CN.
>
> m <- structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
>   528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
>   "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
>   )))
> plot(m["GN", ], m["CN", ])
>
> Jean
>
>
> On Wed, Oct 12, 2016 at 11:20 AM, Adrian Johnson <oriolebaltimore at gmail.com>
> wrote:
>>
>> Dear group,
>> I have been struggling to barplot two different measurements from one
>> subject. These two measures differ in range.  I want to plot row 1
>> axis on left side and row 2 values on right side.
>>
>> For a given column I want to plot GN and CN next to each other.
>>
>> my dput code is below
>> :
>>
>> structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
>> 528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
>> "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
>> )))
>>
>>
>> As you can see:
>>    DC5 DC8 DC14 DC18 DC19 DC20 DC23
>> GN 112 579  131 2234 2892  528  582
>> CN   0   1    1    2    1    0    2
>>
>> GN values are range from 100 - 3000
>> while CN are always -2 or -1 or 0 or 1 or 2
>>
>> Also I cannot log GN values and plot because a difference in 100 units
>> also matters in my experiment.
>>
>> Any help would be greatly appreciated.
>>
>> Thanks
>> Adrian
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From oriolebaltimore at gmail.com  Wed Oct 12 18:59:46 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Wed, 12 Oct 2016 12:59:46 -0400
Subject: [R] barplot beside=TRUE - values differ on scales
In-Reply-To: <2d69881b-d884-b18e-3e46-9133481d65cb@gmail.com>
References: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
	<2d69881b-d884-b18e-3e46-9133481d65cb@gmail.com>
Message-ID: <CAL2fYnM0CzXzLoRJe3_q6LHUR-+ZFxfUs525X-yurWFQ0Axv_A@mail.gmail.com>

Thanks Duncan.
I am sorry I cannot scale second row (d[2,]).
I was looking for a way to plot d[2,] values next to d[1,]  with a
right side axis=4  on right side. -2,-1,0,1,2
thanks
Adrian

On Wed, Oct 12, 2016 at 12:42 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 12/10/2016 12:20 PM, Adrian Johnson wrote:
>>
>> Dear group,
>> I have been struggling to barplot two different measurements from one
>> subject. These two measures differ in range.  I want to plot row 1
>> axis on left side and row 2 values on right side.
>>
>> For a given column I want to plot GN and CN next to each other.
>>
>> my dput code is below
>> :
>>
>> structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
>> 528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
>> "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
>> )))
>>
>>
>> As you can see:
>>     DC5 DC8 DC14 DC18 DC19 DC20 DC23
>> GN 112 579  131 2234 2892  528  582
>> CN   0   1    1    2    1    0    2
>>
>> GN values are range from 100 - 3000
>> while CN are always -2 or -1 or 0 or 1 or 2
>>
>> Also I cannot log GN values and plot because a difference in 100 units
>> also matters in my experiment.
>>
>> Any help would be greatly appreciated.
>
>
> I would simply rescale one row and add a second axis.  For example, if d
> holds your matrix:
>
> scale <- max(d[1,])/max(d[2,])
> adjusted <- d
> adjusted[2,] <- scale*adjusted[2,]
> barplot(adjusted, beside = TRUE)
> ticks <- pretty(d[2,])
> axis(side = 4, at = ticks*scale, labels = ticks)
>
> Duncan Murdoch
>
>


From murdoch.duncan at gmail.com  Wed Oct 12 19:25:39 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 12 Oct 2016 13:25:39 -0400
Subject: [R] barplot beside=TRUE - values differ on scales
In-Reply-To: <CAL2fYnM0CzXzLoRJe3_q6LHUR-+ZFxfUs525X-yurWFQ0Axv_A@mail.gmail.com>
References: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
	<2d69881b-d884-b18e-3e46-9133481d65cb@gmail.com>
	<CAL2fYnM0CzXzLoRJe3_q6LHUR-+ZFxfUs525X-yurWFQ0Axv_A@mail.gmail.com>
Message-ID: <339ec6b3-3d30-d8a4-6d99-692f75766ef7@gmail.com>

On 12/10/2016 12:59 PM, Adrian Johnson wrote:
> Thanks Duncan.
> I am sorry I cannot scale second row (d[2,]).
> I was looking for a way to plot d[2,] values next to d[1,]  with a
> right side axis=4  on right side. -2,-1,0,1,2

That doesn't really make graphical sense, but you can use any 
transformation you like, not just a rescaling.  If you want -2 for the 
2nd row to be the same as 0 on the first row, just work out the 
transformation that achieves that, and use it.

Duncan Murdoch
> thanks
> Adrian
>
> On Wed, Oct 12, 2016 at 12:42 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> > On 12/10/2016 12:20 PM, Adrian Johnson wrote:
> >>
> >> Dear group,
> >> I have been struggling to barplot two different measurements from one
> >> subject. These two measures differ in range.  I want to plot row 1
> >> axis on left side and row 2 values on right side.
> >>
> >> For a given column I want to plot GN and CN next to each other.
> >>
> >> my dput code is below
> >> :
> >>
> >> structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
> >> 528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
> >> "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
> >> )))
> >>
> >>
> >> As you can see:
> >>     DC5 DC8 DC14 DC18 DC19 DC20 DC23
> >> GN 112 579  131 2234 2892  528  582
> >> CN   0   1    1    2    1    0    2
> >>
> >> GN values are range from 100 - 3000
> >> while CN are always -2 or -1 or 0 or 1 or 2
> >>
> >> Also I cannot log GN values and plot because a difference in 100 units
> >> also matters in my experiment.
> >>
> >> Any help would be greatly appreciated.
> >
> >
> > I would simply rescale one row and add a second axis.  For example, if d
> > holds your matrix:
> >
> > scale <- max(d[1,])/max(d[2,])
> > adjusted <- d
> > adjusted[2,] <- scale*adjusted[2,]
> > barplot(adjusted, beside = TRUE)
> > ticks <- pretty(d[2,])
> > axis(side = 4, at = ticks*scale, labels = ticks)
> >
> > Duncan Murdoch
> >
> >


From jvadams at usgs.gov  Wed Oct 12 19:44:01 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 12 Oct 2016 12:44:01 -0500
Subject: [R] barplot beside=TRUE - values differ on scales
In-Reply-To: <CAL2fYnMtx2ghLh8R7vHAZx5GekrcJ7JSc01L+-vFgugObwUFmQ@mail.gmail.com>
References: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
	<CAN5YmCGALnyGtWSaPq9hPcv2QxfmPibyt3CL5xYQyJJ1WVMJ1g@mail.gmail.com>
	<CAL2fYnMtx2ghLh8R7vHAZx5GekrcJ7JSc01L+-vFgugObwUFmQ@mail.gmail.com>
Message-ID: <CAN5YmCGpah_pHcvm-Y5EMo7Uns1FAC2TC5YF68kWzEN7wO71KQ@mail.gmail.com>

Adrian,

Very interesting.

What do you think of using colors to indicate the five possible loss/gain
levels?
For example:

a <- structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
  528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
  "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
  )))

loss.gain <- c(-2, -1, 0, 1, 2)
colorz <- c("blue", "lightblue", "gray", "orange", "red")
barplot(a["GN", ], col=colorz[match(a["CN", ], loss.gain)])

Jean

On Wed, Oct 12, 2016 at 11:55 AM, Adrian Johnson <oriolebaltimore at gmail.com>
wrote:

> Hi Adams,
> The story I am trying to show visually relationship between GN and CN
> for every column. Each column represents a patient. In each patient, a
> particular chromosome region (CN) is either lost (-2 or -1) or gained
> (1 or 2). Typically if loss (one copy loss - as humans have pair of
> chromosome) or homozygous (two copies loss) theoretically indicate
> decrease in number of copies of gene located in that region of
> chromosome. The number of copies of a gene located in that chromosomal
> regions are indicated by GN.
> through this barplot, I intend to show that in 7 cases (columns) if a
> relationship exist by plotting GN and CN next to each other.  If I log
> values in GN, I am loosing the minor differences between cases in GN.
> hope I could convince/explain.
> thanks
> adrian
>
> On Wed, Oct 12, 2016 at 12:36 PM, Adams, Jean <jvadams at usgs.gov> wrote:
> > Adrian,
> >
> > What story are you trying to tell?  Or what question are you trying to
> > answer by visualizing these data?  How is a bar plot of these numbers
> going
> > to help?  I'm just wondering if perhaps a different visualization might
> make
> > more sense, for example, a scatter plot of GN vs. CN.
> >
> > m <- structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
> >   528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
> >   "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
> >   )))
> > plot(m["GN", ], m["CN", ])
> >
> > Jean
> >
> >
> > On Wed, Oct 12, 2016 at 11:20 AM, Adrian Johnson <
> oriolebaltimore at gmail.com>
> > wrote:
> >>
> >> Dear group,
> >> I have been struggling to barplot two different measurements from one
> >> subject. These two measures differ in range.  I want to plot row 1
> >> axis on left side and row 2 values on right side.
> >>
> >> For a given column I want to plot GN and CN next to each other.
> >>
> >> my dput code is below
> >> :
> >>
> >> structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
> >> 528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
> >> "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
> >> )))
> >>
> >>
> >> As you can see:
> >>    DC5 DC8 DC14 DC18 DC19 DC20 DC23
> >> GN 112 579  131 2234 2892  528  582
> >> CN   0   1    1    2    1    0    2
> >>
> >> GN values are range from 100 - 3000
> >> while CN are always -2 or -1 or 0 or 1 or 2
> >>
> >> Also I cannot log GN values and plot because a difference in 100 units
> >> also matters in my experiment.
> >>
> >> Any help would be greatly appreciated.
> >>
> >> Thanks
> >> Adrian
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
>

	[[alternative HTML version deleted]]


From sewashm at gmail.com  Wed Oct 12 20:20:11 2016
From: sewashm at gmail.com (Ashta)
Date: Wed, 12 Oct 2016 13:20:11 -0500
Subject: [R] create variable
In-Reply-To: <A2326220-9507-4930-B210-41786F4ABAF5@comcast.net>
References: <CADDFq30dXR44v3AfwRhw4=rAVLq5ijng73gVG8fZ3TNXi0x9xA@mail.gmail.com>
	<A2326220-9507-4930-B210-41786F4ABAF5@comcast.net>
Message-ID: <CADDFq32ei+mC33iDL1DvBRqpQJTBv8pMuc5YN9EZ9ty-M7FhJg@mail.gmail.com>

Hi  David and  all,

I want run the following script in a loop but faced difficulty.

trt=c(1,2,2,4,5,6,7,8)
for(i  in 1:length (trt))
{
   try[i] <- (select  trt, date1, date2, datediff(date1,date2) as
d12diff [i]  from
             dateTable  where trt=[i]")
}

I would appreciate if you point me the problem.

Thank you in  advance


On Sun, Oct 9, 2016 at 11:16 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Oct 9, 2016, at 7:56 AM, Ashta <sewashm at gmail.com> wrote:
>>
>> I am trying to query data from Hive service and create a variable.
>>
>>
>> dbGetQuery(hivecon,"select date1, date2 from  dateTable limit 10")
>> date1,  date2, Diif
>> 4/5/1999,  6/14/2000
>> 7/2/1999, 6/26/2000
>> 8/14/1999, 8/19/2000
>> 11/10/1999, 9/18/2000
>> 8/25/2000, 6/5/2001
>> 3/14/2012, 3/15/2004
>>
>>
>> Here is  what I wanted to do. While I am querying I want create a
>> variable diff= dat1e1-date2.
>> I may use this variable "diff"  to do some statistics (mean, mode,
>> etc) and also in the where clause l like as the following.
>>
>> test_date=dbGetQuery(hivecon,"select date1, date2 from  dateTable
>> where diff gt 1000 limit 10")
>>
>> I would appreciate if you suggest me how to do this.
>
> Sorry for the blank message earlier. My reading of the use of Hive queries is that you would need to use the `datediff` function. I further suspect you need to define a variable name to which then apply your limits. I also read that hive dates are actually strings types represented as POSIX style character values and might need a to_date funciton. This is all guesswork since I don't have a hive cluster to run this against:
>
>  So perhaps something like one of these:
>
> try1 <- dbGetQuery(hivecon,"select date1, date2, datediff(TO_DATE(date1),TO_DATE(date2)) as d12diff from  dateTable where d12diff GT 1000 limit 10")
>
> try2 <- dbGetQuery(hivecon,"select date1, date2, datediff(dat1,date2) as d12diff from  dateTable where d12diff GT 1000 limit 10")
>
> Obviously these are just guesses.
>
> --
> David.
>>
>>
>>
>> Here is the sample of the data and  result
>>
>> date1,  date2, Diif
>> 4/5/1999,  6/14/2000, -436
>> 7/2/1999, 6/26/2000, -360
>> 8/14/1999, 8/19/2000, -371
>> 11/10/1999, 9/18/2000, -313
>> 8/25/2000, 6/5/2001, -284
>> 3/14/2012, 3/15/2004, 2921
>>
>> Thank you in advance
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From dcarlson at tamu.edu  Wed Oct 12 21:46:21 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 12 Oct 2016 19:46:21 +0000
Subject: [R] barplot beside=TRUE - values differ on scales
In-Reply-To: <CAN5YmCGpah_pHcvm-Y5EMo7Uns1FAC2TC5YF68kWzEN7wO71KQ@mail.gmail.com>
References: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
	<CAN5YmCGALnyGtWSaPq9hPcv2QxfmPibyt3CL5xYQyJJ1WVMJ1g@mail.gmail.com>
	<CAL2fYnMtx2ghLh8R7vHAZx5GekrcJ7JSc01L+-vFgugObwUFmQ@mail.gmail.com>
	<CAN5YmCGpah_pHcvm-Y5EMo7Uns1FAC2TC5YF68kWzEN7wO71KQ@mail.gmail.com>
Message-ID: <0f88c1c6625843068301a99490f05d7c@exch-2p-mbx-w2.ads.tamu.edu>

Are you looking for something like this?

Assuming your data is d:

> d[2, ] <- d[2, ]*500
> oldp <- par(mar=c(4.1, 4.1, 4.1, 4.1))
> barplot(d, ylim=c(-1000, 3000), beside=TRUE, axes=FALSE)
> axis(2, c(0, 1000, 2000, 3000))
> axis(4, c(-1000, -500, 0, 500, 1000), c(-2, -1, 0, 1, 2))
> mtext("GN", 2, 2)
> mtext("CN", 4, 2, at=0)
> par(oldp)



-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Adams, Jean
Sent: Wednesday, October 12, 2016 12:44 PM
To: Adrian Johnson
Cc: r-help
Subject: Re: [R] barplot beside=TRUE - values differ on scales

Adrian,

Very interesting.

What do you think of using colors to indicate the five possible loss/gain
levels?
For example:

a <- structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
  528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
  "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
  )))

loss.gain <- c(-2, -1, 0, 1, 2)
colorz <- c("blue", "lightblue", "gray", "orange", "red")
barplot(a["GN", ], col=colorz[match(a["CN", ], loss.gain)])

Jean

On Wed, Oct 12, 2016 at 11:55 AM, Adrian Johnson <oriolebaltimore at gmail.com>
wrote:

> Hi Adams,
> The story I am trying to show visually relationship between GN and CN
> for every column. Each column represents a patient. In each patient, a
> particular chromosome region (CN) is either lost (-2 or -1) or gained
> (1 or 2). Typically if loss (one copy loss - as humans have pair of
> chromosome) or homozygous (two copies loss) theoretically indicate
> decrease in number of copies of gene located in that region of
> chromosome. The number of copies of a gene located in that chromosomal
> regions are indicated by GN.
> through this barplot, I intend to show that in 7 cases (columns) if a
> relationship exist by plotting GN and CN next to each other.  If I log
> values in GN, I am loosing the minor differences between cases in GN.
> hope I could convince/explain.
> thanks
> adrian
>
> On Wed, Oct 12, 2016 at 12:36 PM, Adams, Jean <jvadams at usgs.gov> wrote:
> > Adrian,
> >
> > What story are you trying to tell?  Or what question are you trying to
> > answer by visualizing these data?  How is a bar plot of these numbers
> going
> > to help?  I'm just wondering if perhaps a different visualization might
> make
> > more sense, for example, a scatter plot of GN vs. CN.
> >
> > m <- structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
> >   528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
> >   "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
> >   )))
> > plot(m["GN", ], m["CN", ])
> >
> > Jean
> >
> >
> > On Wed, Oct 12, 2016 at 11:20 AM, Adrian Johnson <
> oriolebaltimore at gmail.com>
> > wrote:
> >>
> >> Dear group,
> >> I have been struggling to barplot two different measurements from one
> >> subject. These two measures differ in range.  I want to plot row 1
> >> axis on left side and row 2 values on right side.
> >>
> >> For a given column I want to plot GN and CN next to each other.
> >>
> >> my dput code is below
> >> :
> >>
> >> structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
> >> 528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
> >> "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
> >> )))
> >>
> >>
> >> As you can see:
> >>    DC5 DC8 DC14 DC18 DC19 DC20 DC23
> >> GN 112 579  131 2234 2892  528  582
> >> CN   0   1    1    2    1    0    2
> >>
> >> GN values are range from 100 - 3000
> >> while CN are always -2 or -1 or 0 or 1 or 2
> >>
> >> Also I cannot log GN values and plot because a difference in 100 units
> >> also matters in my experiment.
> >>
> >> Any help would be greatly appreciated.
> >>
> >> Thanks
> >> Adrian
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Wed Oct 12 22:15:06 2016
From: valkremk at gmail.com (Val)
Date: Wed, 12 Oct 2016 15:15:06 -0500
Subject: [R] Incremental
Message-ID: <CAJOiR6Z0Cu_OS_nF4WrW0FBbUVZphSzbi1pwRmYz403vjVxB8w@mail.gmail.com>

Hi all,

I have a data set like
dat<-read.table(text=" y1, flag
39958,S
40058,R
40105,X
40294,H
40332,S
40471,R
40493,R
40533,X
40718,H
40771,S
40829,R
40892,X
41056,H
41110,S
41160,R
41222,R
41250,R
41289,R
41324,X
41355,R
41415,X
41562,X
41562,H
41586,S
",sep=",",header=TRUE)

First sort the data by y1.
Then
I want to create two columns .
1. the first new column is  (x1):  if flag is "S"  then  x1=1  and
assign the following/subsequent rows 1 as well.   When we reach to
the next "S"  then  x1=2 and the subsequent rows will be assigned to
2.

2. the second variable (z2). Within each x1 find the difference
between the first y1 and subsequent y1 values

Example  for the first few rows
  y1,   flag, x1, z2
39958, S, 1,    0          z2 is calculated as     z2=(39958, 39958)
40058, R, 1, 100         z2 is calculated as     z2=(40058, 39958)
40105, X, 1, 147         z2 is calculated as     z2=(40105, 39958)
40294, H, 1, 336         z2 is calculated as     z2=(40294, 39958)
40332, S, 2,  0            z2 is calculated as     z2=(40332, 40332)
etc

Here is the complete output for the sample  data
39958,S,1,0
40058,R,1,100
40105,X,1,147
40294,H,1,336
40332,S,2,0
40471,R,2,139
40493,R,2,161
40533,X,2,201
40718,H,2,386
40771,S,3,0
40829,R,3,58
40892,X,3,121
41056,H,3,285
41110,S,4,0
41160,R,4,50
41222,R,4,112
41250,R,4,140
41289,R,4,179
41324,X,4,214
41355,R,4,245
41415,X,4,305
41562,X,4,452
41562,H,4,452
41586,S,5,0

Val


From oriolebaltimore at gmail.com  Wed Oct 12 22:25:35 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Wed, 12 Oct 2016 16:25:35 -0400
Subject: [R] barplot beside=TRUE - values differ on scales
In-Reply-To: <0f88c1c6625843068301a99490f05d7c@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
	<CAN5YmCGALnyGtWSaPq9hPcv2QxfmPibyt3CL5xYQyJJ1WVMJ1g@mail.gmail.com>
	<CAL2fYnMtx2ghLh8R7vHAZx5GekrcJ7JSc01L+-vFgugObwUFmQ@mail.gmail.com>
	<CAN5YmCGpah_pHcvm-Y5EMo7Uns1FAC2TC5YF68kWzEN7wO71KQ@mail.gmail.com>
	<0f88c1c6625843068301a99490f05d7c@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAL2fYnNZMm5re4xpjOE953ZW=1Mq3utfoL_99pE65_DJMxmMxw@mail.gmail.com>

Hello Dr. Carlson,
thanks for the tip. It is exactly what I am looking for.

I see the trick lies in
axis(4, c(-1000, -500, 0, 500, 1000), c(-2, -1, 0, 1, 2))

Would you please help understand why two different vectors of ranges
are defined and yet I see only vector with -2,-1,0,1,2 is visible.

Thanks a lot.
Adrian





On Wed, Oct 12, 2016 at 3:46 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> Are you looking for something like this?
>
> Assuming your data is d:
>
>> d[2, ] <- d[2, ]*500
>> oldp <- par(mar=c(4.1, 4.1, 4.1, 4.1))
>> barplot(d, ylim=c(-1000, 3000), beside=TRUE, axes=FALSE)
>> axis(2, c(0, 1000, 2000, 3000))
>> axis(4, c(-1000, -500, 0, 500, 1000), c(-2, -1, 0, 1, 2))
>> mtext("GN", 2, 2)
>> mtext("CN", 4, 2, at=0)
>> par(oldp)
>
>
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Adams, Jean
> Sent: Wednesday, October 12, 2016 12:44 PM
> To: Adrian Johnson
> Cc: r-help
> Subject: Re: [R] barplot beside=TRUE - values differ on scales
>
> Adrian,
>
> Very interesting.
>
> What do you think of using colors to indicate the five possible loss/gain
> levels?
> For example:
>
> a <- structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
>   528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
>   "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
>   )))
>
> loss.gain <- c(-2, -1, 0, 1, 2)
> colorz <- c("blue", "lightblue", "gray", "orange", "red")
> barplot(a["GN", ], col=colorz[match(a["CN", ], loss.gain)])
>
> Jean
>
> On Wed, Oct 12, 2016 at 11:55 AM, Adrian Johnson <oriolebaltimore at gmail.com>
> wrote:
>
>> Hi Adams,
>> The story I am trying to show visually relationship between GN and CN
>> for every column. Each column represents a patient. In each patient, a
>> particular chromosome region (CN) is either lost (-2 or -1) or gained
>> (1 or 2). Typically if loss (one copy loss - as humans have pair of
>> chromosome) or homozygous (two copies loss) theoretically indicate
>> decrease in number of copies of gene located in that region of
>> chromosome. The number of copies of a gene located in that chromosomal
>> regions are indicated by GN.
>> through this barplot, I intend to show that in 7 cases (columns) if a
>> relationship exist by plotting GN and CN next to each other.  If I log
>> values in GN, I am loosing the minor differences between cases in GN.
>> hope I could convince/explain.
>> thanks
>> adrian
>>
>> On Wed, Oct 12, 2016 at 12:36 PM, Adams, Jean <jvadams at usgs.gov> wrote:
>> > Adrian,
>> >
>> > What story are you trying to tell?  Or what question are you trying to
>> > answer by visualizing these data?  How is a bar plot of these numbers
>> going
>> > to help?  I'm just wondering if perhaps a different visualization might
>> make
>> > more sense, for example, a scatter plot of GN vs. CN.
>> >
>> > m <- structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
>> >   528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
>> >   "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
>> >   )))
>> > plot(m["GN", ], m["CN", ])
>> >
>> > Jean
>> >
>> >
>> > On Wed, Oct 12, 2016 at 11:20 AM, Adrian Johnson <
>> oriolebaltimore at gmail.com>
>> > wrote:
>> >>
>> >> Dear group,
>> >> I have been struggling to barplot two different measurements from one
>> >> subject. These two measures differ in range.  I want to plot row 1
>> >> axis on left side and row 2 values on right side.
>> >>
>> >> For a given column I want to plot GN and CN next to each other.
>> >>
>> >> my dput code is below
>> >> :
>> >>
>> >> structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
>> >> 528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
>> >> "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
>> >> )))
>> >>
>> >>
>> >> As you can see:
>> >>    DC5 DC8 DC14 DC18 DC19 DC20 DC23
>> >> GN 112 579  131 2234 2892  528  582
>> >> CN   0   1    1    2    1    0    2
>> >>
>> >> GN values are range from 100 - 3000
>> >> while CN are always -2 or -1 or 0 or 1 or 2
>> >>
>> >> Also I cannot log GN values and plot because a difference in 100 units
>> >> also matters in my experiment.
>> >>
>> >> Any help would be greatly appreciated.
>> >>
>> >> Thanks
>> >> Adrian
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From oriolebaltimore at gmail.com  Wed Oct 12 22:27:28 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Wed, 12 Oct 2016 16:27:28 -0400
Subject: [R] barplot beside=TRUE - values differ on scales
In-Reply-To: <CAL2fYnNZMm5re4xpjOE953ZW=1Mq3utfoL_99pE65_DJMxmMxw@mail.gmail.com>
References: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
	<CAN5YmCGALnyGtWSaPq9hPcv2QxfmPibyt3CL5xYQyJJ1WVMJ1g@mail.gmail.com>
	<CAL2fYnMtx2ghLh8R7vHAZx5GekrcJ7JSc01L+-vFgugObwUFmQ@mail.gmail.com>
	<CAN5YmCGpah_pHcvm-Y5EMo7Uns1FAC2TC5YF68kWzEN7wO71KQ@mail.gmail.com>
	<0f88c1c6625843068301a99490f05d7c@exch-2p-mbx-w2.ads.tamu.edu>
	<CAL2fYnNZMm5re4xpjOE953ZW=1Mq3utfoL_99pE65_DJMxmMxw@mail.gmail.com>
Message-ID: <CAL2fYnMDSU1u0J+qNpp23Uz7-sXeoFrtd5U7sdp-xVg9zXLa3g@mail.gmail.com>

As Dr.Murdoch suggested, transformation of row 2 is important to make
sense in graphical depiction.
Thanks to all.


On Wed, Oct 12, 2016 at 4:25 PM, Adrian Johnson
<oriolebaltimore at gmail.com> wrote:
> Hello Dr. Carlson,
> thanks for the tip. It is exactly what I am looking for.
>
> I see the trick lies in
> axis(4, c(-1000, -500, 0, 500, 1000), c(-2, -1, 0, 1, 2))
>
> Would you please help understand why two different vectors of ranges
> are defined and yet I see only vector with -2,-1,0,1,2 is visible.
>
> Thanks a lot.
> Adrian
>
>
>
>
>
> On Wed, Oct 12, 2016 at 3:46 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>> Are you looking for something like this?
>>
>> Assuming your data is d:
>>
>>> d[2, ] <- d[2, ]*500
>>> oldp <- par(mar=c(4.1, 4.1, 4.1, 4.1))
>>> barplot(d, ylim=c(-1000, 3000), beside=TRUE, axes=FALSE)
>>> axis(2, c(0, 1000, 2000, 3000))
>>> axis(4, c(-1000, -500, 0, 500, 1000), c(-2, -1, 0, 1, 2))
>>> mtext("GN", 2, 2)
>>> mtext("CN", 4, 2, at=0)
>>> par(oldp)
>>
>>
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Adams, Jean
>> Sent: Wednesday, October 12, 2016 12:44 PM
>> To: Adrian Johnson
>> Cc: r-help
>> Subject: Re: [R] barplot beside=TRUE - values differ on scales
>>
>> Adrian,
>>
>> Very interesting.
>>
>> What do you think of using colors to indicate the five possible loss/gain
>> levels?
>> For example:
>>
>> a <- structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
>>   528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
>>   "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
>>   )))
>>
>> loss.gain <- c(-2, -1, 0, 1, 2)
>> colorz <- c("blue", "lightblue", "gray", "orange", "red")
>> barplot(a["GN", ], col=colorz[match(a["CN", ], loss.gain)])
>>
>> Jean
>>
>> On Wed, Oct 12, 2016 at 11:55 AM, Adrian Johnson <oriolebaltimore at gmail.com>
>> wrote:
>>
>>> Hi Adams,
>>> The story I am trying to show visually relationship between GN and CN
>>> for every column. Each column represents a patient. In each patient, a
>>> particular chromosome region (CN) is either lost (-2 or -1) or gained
>>> (1 or 2). Typically if loss (one copy loss - as humans have pair of
>>> chromosome) or homozygous (two copies loss) theoretically indicate
>>> decrease in number of copies of gene located in that region of
>>> chromosome. The number of copies of a gene located in that chromosomal
>>> regions are indicated by GN.
>>> through this barplot, I intend to show that in 7 cases (columns) if a
>>> relationship exist by plotting GN and CN next to each other.  If I log
>>> values in GN, I am loosing the minor differences between cases in GN.
>>> hope I could convince/explain.
>>> thanks
>>> adrian
>>>
>>> On Wed, Oct 12, 2016 at 12:36 PM, Adams, Jean <jvadams at usgs.gov> wrote:
>>> > Adrian,
>>> >
>>> > What story are you trying to tell?  Or what question are you trying to
>>> > answer by visualizing these data?  How is a bar plot of these numbers
>>> going
>>> > to help?  I'm just wondering if perhaps a different visualization might
>>> make
>>> > more sense, for example, a scatter plot of GN vs. CN.
>>> >
>>> > m <- structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
>>> >   528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
>>> >   "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
>>> >   )))
>>> > plot(m["GN", ], m["CN", ])
>>> >
>>> > Jean
>>> >
>>> >
>>> > On Wed, Oct 12, 2016 at 11:20 AM, Adrian Johnson <
>>> oriolebaltimore at gmail.com>
>>> > wrote:
>>> >>
>>> >> Dear group,
>>> >> I have been struggling to barplot two different measurements from one
>>> >> subject. These two measures differ in range.  I want to plot row 1
>>> >> axis on left side and row 2 values on right side.
>>> >>
>>> >> For a given column I want to plot GN and CN next to each other.
>>> >>
>>> >> my dput code is below
>>> >> :
>>> >>
>>> >> structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
>>> >> 528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
>>> >> "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
>>> >> )))
>>> >>
>>> >>
>>> >> As you can see:
>>> >>    DC5 DC8 DC14 DC18 DC19 DC20 DC23
>>> >> GN 112 579  131 2234 2892  528  582
>>> >> CN   0   1    1    2    1    0    2
>>> >>
>>> >> GN values are range from 100 - 3000
>>> >> while CN are always -2 or -1 or 0 or 1 or 2
>>> >>
>>> >> Also I cannot log GN values and plot because a difference in 100 units
>>> >> also matters in my experiment.
>>> >>
>>> >> Any help would be greatly appreciated.
>>> >>
>>> >> Thanks
>>> >> Adrian
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >
>>>
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Oct 12 22:34:00 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 12 Oct 2016 21:34:00 +0100
Subject: [R] Incremental
In-Reply-To: <CAJOiR6Z0Cu_OS_nF4WrW0FBbUVZphSzbi1pwRmYz403vjVxB8w@mail.gmail.com>
References: <CAJOiR6Z0Cu_OS_nF4WrW0FBbUVZphSzbi1pwRmYz403vjVxB8w@mail.gmail.com>
Message-ID: <57FE9E38.1040800@sapo.pt>

Hello,

Seems simple:


# 1)
dat$x1 <- cumsum(dat$flag == "S")

# 2)
dat$z2 <- unlist(tapply(dat$y1, dat$x1, function(y) y - y[1]))

Hope this helps,

Rui Barradas

Em 12-10-2016 21:15, Val escreveu:
> Hi all,
>
> I have a data set like
> dat<-read.table(text=" y1, flag
> 39958,S
> 40058,R
> 40105,X
> 40294,H
> 40332,S
> 40471,R
> 40493,R
> 40533,X
> 40718,H
> 40771,S
> 40829,R
> 40892,X
> 41056,H
> 41110,S
> 41160,R
> 41222,R
> 41250,R
> 41289,R
> 41324,X
> 41355,R
> 41415,X
> 41562,X
> 41562,H
> 41586,S
> ",sep=",",header=TRUE)
>
> First sort the data by y1.
> Then
> I want to create two columns .
> 1. the first new column is  (x1):  if flag is "S"  then  x1=1  and
> assign the following/subsequent rows 1 as well.   When we reach to
> the next "S"  then  x1=2 and the subsequent rows will be assigned to
> 2.
>
> 2. the second variable (z2). Within each x1 find the difference
> between the first y1 and subsequent y1 values
>
> Example  for the first few rows
>    y1,   flag, x1, z2
> 39958, S, 1,    0          z2 is calculated as     z2=(39958, 39958)
> 40058, R, 1, 100         z2 is calculated as     z2=(40058, 39958)
> 40105, X, 1, 147         z2 is calculated as     z2=(40105, 39958)
> 40294, H, 1, 336         z2 is calculated as     z2=(40294, 39958)
> 40332, S, 2,  0            z2 is calculated as     z2=(40332, 40332)
> etc
>
> Here is the complete output for the sample  data
> 39958,S,1,0
> 40058,R,1,100
> 40105,X,1,147
> 40294,H,1,336
> 40332,S,2,0
> 40471,R,2,139
> 40493,R,2,161
> 40533,X,2,201
> 40718,H,2,386
> 40771,S,3,0
> 40829,R,3,58
> 40892,X,3,121
> 41056,H,3,285
> 41110,S,4,0
> 41160,R,4,50
> 41222,R,4,112
> 41250,R,4,140
> 41289,R,4,179
> 41324,X,4,214
> 41355,R,4,245
> 41415,X,4,305
> 41562,X,4,452
> 41562,H,4,452
> 41586,S,5,0
>
> Val
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From valkremk at gmail.com  Wed Oct 12 22:53:43 2016
From: valkremk at gmail.com (Val)
Date: Wed, 12 Oct 2016 15:53:43 -0500
Subject: [R] Incremental
In-Reply-To: <57FE9E38.1040800@sapo.pt>
References: <CAJOiR6Z0Cu_OS_nF4WrW0FBbUVZphSzbi1pwRmYz403vjVxB8w@mail.gmail.com>
	<57FE9E38.1040800@sapo.pt>
Message-ID: <CAJOiR6Z8mRnb-+C-QOfd6jqD7vB-8VkQCj+gGgbf7Cim=tkusw@mail.gmail.com>

Rui,
Thank You!

the second one gave me NULL.
dat$z2 <- unlist(tapply(dat$y1, dat$x1, function(y) y - y[1]))

dat$z2
NULL



On Wed, Oct 12, 2016 at 3:34 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Seems simple:
>
>
> # 1)
> dat$x1 <- cumsum(dat$flag == "S")
>
> # 2)
> dat$z2 <- unlist(tapply(dat$y1, dat$x1, function(y) y - y[1]))
>
> Hope this helps,
>
> Rui Barradas
>
>
> Em 12-10-2016 21:15, Val escreveu:
>>
>> Hi all,
>>
>> I have a data set like
>> dat<-read.table(text=" y1, flag
>> 39958,S
>> 40058,R
>> 40105,X
>> 40294,H
>> 40332,S
>> 40471,R
>> 40493,R
>> 40533,X
>> 40718,H
>> 40771,S
>> 40829,R
>> 40892,X
>> 41056,H
>> 41110,S
>> 41160,R
>> 41222,R
>> 41250,R
>> 41289,R
>> 41324,X
>> 41355,R
>> 41415,X
>> 41562,X
>> 41562,H
>> 41586,S
>> ",sep=",",header=TRUE)
>>
>> First sort the data by y1.
>> Then
>> I want to create two columns .
>> 1. the first new column is  (x1):  if flag is "S"  then  x1=1  and
>> assign the following/subsequent rows 1 as well.   When we reach to
>> the next "S"  then  x1=2 and the subsequent rows will be assigned to
>> 2.
>>
>> 2. the second variable (z2). Within each x1 find the difference
>> between the first y1 and subsequent y1 values
>>
>> Example  for the first few rows
>>    y1,   flag, x1, z2
>> 39958, S, 1,    0          z2 is calculated as     z2=(39958, 39958)
>> 40058, R, 1, 100         z2 is calculated as     z2=(40058, 39958)
>> 40105, X, 1, 147         z2 is calculated as     z2=(40105, 39958)
>> 40294, H, 1, 336         z2 is calculated as     z2=(40294, 39958)
>> 40332, S, 2,  0            z2 is calculated as     z2=(40332, 40332)
>> etc
>>
>> Here is the complete output for the sample  data
>> 39958,S,1,0
>> 40058,R,1,100
>> 40105,X,1,147
>> 40294,H,1,336
>> 40332,S,2,0
>> 40471,R,2,139
>> 40493,R,2,161
>> 40533,X,2,201
>> 40718,H,2,386
>> 40771,S,3,0
>> 40829,R,3,58
>> 40892,X,3,121
>> 41056,H,3,285
>> 41110,S,4,0
>> 41160,R,4,50
>> 41222,R,4,112
>> 41250,R,4,140
>> 41289,R,4,179
>> 41324,X,4,214
>> 41355,R,4,245
>> 41415,X,4,305
>> 41562,X,4,452
>> 41562,H,4,452
>> 41586,S,5,0
>>
>> Val
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From utz.ryan at gmail.com  Wed Oct 12 23:28:39 2016
From: utz.ryan at gmail.com (Ryan Utz)
Date: Wed, 12 Oct 2016 17:28:39 -0400
Subject: [R] Opening or activating a URL to access data,
	alternative to browseURL
In-Reply-To: <b15f9c84-7b3d-6d7b-2c8b-f52a79f81984@gmail.com>
References: <CAKJ8KVi5KULDekvhA1zfNcAw2EtGjO1C6uJBc9qa3s3jLYEPQA@mail.gmail.com>
	<0000c9bc-d908-2bad-656b-10fea6e2d39f@gmail.com>
	<CAA-FpKVRRZtYtBeKiYHpz9VUW5kZaJ_qiFjeg+TQTCTQ=7rwbA@mail.gmail.com>
	<CAKJ8KVjmVKOay5HwopoDKKqXmiCQLwM4vFNc5MLhGDc8Y-hMUA@mail.gmail.com>
	<b15f9c84-7b3d-6d7b-2c8b-f52a79f81984@gmail.com>
Message-ID: <CAKJ8KViDj80Jud1oJMvUpFb7js_WHZG5mB8o5AY8Zm-Y4G6xkQ@mail.gmail.com>

Eureka! I wish I could send a box of digital donuts. Thanks so much!!!!

On Tue, Oct 11, 2016 at 9:21 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 11/10/2016 7:59 AM, Ryan Utz wrote:
>
>> Bob/Duncan,
>>
>> Thanks for writing. I think some of the things Bob mentioned might work,
>> but I'm still not quite getting there. Below is the example I'm working
>> with:
>>
>>
> It worked for me when I replaced the browseURL call with a readLines call,
> as I suggested the other day.  What went wrong for you?
>
> Duncan Murdoch
>
> #1
>> browseURL('http://pick18.discoverlife.org/mp/20m?plot=2&
>> kind=Hypoprepia+fucosa&site=33.9+-83.3&date1=2011,2012,2013&
>> flags=build_txt:
>> <http://pick18.discoverlife.org/mp/20m?plot=2&kind=Hypoprepi
>> a+fucosa&site=33.9+-83.3&date1=2011,2012,2013&flags=build_txt:>')
>> # This opens the URL and creates a link to machine-readable data on the
>> page, which I can then download by simply doing this:
>>
>> #2
>> read.delim('http://pick18.discoverlife.org/tmp/Hypoprepia_
>> fucosa_33.9_-83.3_2011,2012,2013.txt
>> <http://pick18.discoverlife.org/tmp/Hypoprepia_fucosa_33.9_-
>> 83.3_2011,2012,2013.txt>')
>> #This is what I need to read in terms of data, but this URL only exists
>> if the URL ran above is activated first
>>
>> So, for example, try running line #2 without the first line- it won't
>> work. Next run #1 then #2- works fine.
>>
>> See what I mean?
>>
>>
>> On Thu, Sep 29, 2016 at 5:09 PM, Bob Rudis <bob at rud.is
>> <mailto:bob at rud.is>> wrote:
>>
>>     The rvest/httr/curl trio can do the cookie management pretty well.
>>     Make the initial connection via rvest::html_session() and then
>>     hopefully be able to use other rvest function calls, but curl and
>>     httr calls will use the cached in-memory handle info seamlessly.
>>     You'd need to store and retrieve cookies if you need them preserved
>>     between R sessions.
>>
>>     Failing the above and assuming this would not need to be lightning
>>     fast, use the phantomjs or firefox web driver (either with RSelenium
>>     or some new stuff rOpenSci is cooking up) which will then do what
>>     browsers do best and maintain all this state for you. You can still
>>     slurp the page contents up with xml2::read_html() and use the super
>>     handy processing idioms in the scraping tidyverse (it needs it's own
>>     name).
>>
>>     A concrete example (assuming the URLs aren't sensitive) would enable
>>     me or someone else to mock up something for you.
>>
>>
>>     On Thu, Sep 29, 2016 at 4:59 PM, Duncan Murdoch
>>     <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>         On 29/09/2016 3:29 PM, Ryan Utz wrote:
>>
>>             Hi all,
>>
>>             I've got a situation that involves activating a URL so that
>>             a link to some
>>             data becomes available for download. I can easily use
>>             'browseURL' to do so,
>>             but I'm hoping to make this batch-process-able, and I would
>>             prefer to not
>>             have 100s of browser windows open when I go to download
>>             multiple data sets.
>>
>>             Here's the example:
>>
>>             #1
>>             browseURL('
>>             http://pick18.discoverlife.org/mp/20m?plot=2&kind=Hypoprepia
>> +fucosa&site=33.9+-83.3&date1=2011,2012,2013&flags=build_txt
>>             <http://pick18.discoverlife.org/mp/20m?plot=2&kind=Hypoprepi
>> a+fucosa&site=33.9+-83.3&date1=2011,2012,2013&flags=build_txt>:
>>             ')
>>             # This opens the URL and creates a link to machine-readable
>>             data on the
>>             page, which I can then download by simply doing this:
>>
>>             #2
>>             read.delim('
>>             http://pick18.discoverlife.org/tmp/Hypoprepia_fucosa_33.9_-
>> 83.3_2011,2012,2013.txt
>>             <http://pick18.discoverlife.org/tmp/Hypoprepia_fucosa_33.9_-
>> 83.3_2011,2012,2013.txt>
>>             ')
>>
>>             However, I can only get the second line above to work if the
>>             thing in line
>>             #1 has been opened in a browser already. Is there any way to
>>             allow me to
>>             either 1) close the browser after it's been opened or 2)
>>             execute the line
>>             #2 above without having to open a browser? We have hundreds
>>             of species that
>>             you can see after the '&kind=' bit of the URL, so I'm trying
>>             to keep the
>>             browsing situation sane.
>>
>>             Thanks!
>>             R
>>
>>
>>         You'll need to figure out what happens when you open the first
>>         page. Does it set a cookie?  Does it record your IP address?
>>         Does it just build the file but record nothing about you?
>>
>>         If it's one of the simpler versions, you can just read the first
>>         page, wait a bit, then read the second one.
>>
>>         If you need to manage cookies, you'll need something more
>>         complicated. I don't know the easiest way to do that.
>>
>>         Duncan Murdoch
>>
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>         -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>>
>> --
>>
>> Ryan Utz, Ph.D.
>> Assistant professor of water resources
>> *chatham**UNIVERSITY*
>> Home/Cell: (724) 272-7769
>>
>>
>


-- 

Ryan Utz, Ph.D.
Assistant professor of water resources
*chatham**UNIVERSITY*
Home/Cell: (724) 272-7769

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Oct 12 23:52:23 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 12 Oct 2016 14:52:23 -0700
Subject: [R] create variable
In-Reply-To: <CADDFq32ei+mC33iDL1DvBRqpQJTBv8pMuc5YN9EZ9ty-M7FhJg@mail.gmail.com>
References: <CADDFq30dXR44v3AfwRhw4=rAVLq5ijng73gVG8fZ3TNXi0x9xA@mail.gmail.com>
	<A2326220-9507-4930-B210-41786F4ABAF5@comcast.net>
	<CADDFq32ei+mC33iDL1DvBRqpQJTBv8pMuc5YN9EZ9ty-M7FhJg@mail.gmail.com>
Message-ID: <D8D46E29-D206-44C0-804B-7E172631E493@comcast.net>


> On Oct 12, 2016, at 11:20 AM, Ashta <sewashm at gmail.com> wrote:
> 
> Hi  David and  all,
> 
> I want run the following script in a loop but faced difficulty.
> 
> trt=c(1,2,2,4,5,6,7,8)
> for(i  in 1:length (trt))
> {
>   try[i] <- (select  trt, date1, date2, datediff(date1,date2) as
> d12diff [i]  from
>             dateTable  where trt=[i]")
> }
> 
> I would appreciate if you point me the problem.

The problem(s) is/are that dbGetQuery is not being used and that even if it were used, it expects a character value as its second argument.

-- 
David.
> 
> Thank you in  advance
> 
> 
> On Sun, Oct 9, 2016 at 11:16 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Oct 9, 2016, at 7:56 AM, Ashta <sewashm at gmail.com> wrote:
>>> 
>>> I am trying to query data from Hive service and create a variable.
>>> 
>>> 
>>> dbGetQuery(hivecon,"select date1, date2 from  dateTable limit 10")
>>> date1,  date2, Diif
>>> 4/5/1999,  6/14/2000
>>> 7/2/1999, 6/26/2000
>>> 8/14/1999, 8/19/2000
>>> 11/10/1999, 9/18/2000
>>> 8/25/2000, 6/5/2001
>>> 3/14/2012, 3/15/2004
>>> 
>>> 
>>> Here is  what I wanted to do. While I am querying I want create a
>>> variable diff= dat1e1-date2.
>>> I may use this variable "diff"  to do some statistics (mean, mode,
>>> etc) and also in the where clause l like as the following.
>>> 
>>> test_date=dbGetQuery(hivecon,"select date1, date2 from  dateTable
>>> where diff gt 1000 limit 10")
>>> 
>>> I would appreciate if you suggest me how to do this.
>> 
>> Sorry for the blank message earlier. My reading of the use of Hive queries is that you would need to use the `datediff` function. I further suspect you need to define a variable name to which then apply your limits. I also read that hive dates are actually strings types represented as POSIX style character values and might need a to_date funciton. This is all guesswork since I don't have a hive cluster to run this against:
>> 
>> So perhaps something like one of these:
>> 
>> try1 <- dbGetQuery(hivecon,"select date1, date2, datediff(TO_DATE(date1),TO_DATE(date2)) as d12diff from  dateTable where d12diff GT 1000 limit 10")
>> 
>> try2 <- dbGetQuery(hivecon,"select date1, date2, datediff(dat1,date2) as d12diff from  dateTable where d12diff GT 1000 limit 10")
>> 
>> Obviously these are just guesses.
>> 
>> --
>> David.
>>> 
>>> 
>>> 
>>> Here is the sample of the data and  result
>>> 
>>> date1,  date2, Diif
>>> 4/5/1999,  6/14/2000, -436
>>> 7/2/1999, 6/26/2000, -360
>>> 8/14/1999, 8/19/2000, -371
>>> 11/10/1999, 9/18/2000, -313
>>> 8/25/2000, 6/5/2001, -284
>>> 3/14/2012, 3/15/2004, 2921
>>> 
>>> Thank you in advance
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Thu Oct 13 00:06:40 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 13 Oct 2016 09:06:40 +1100
Subject: [R] barplot beside=TRUE - values differ on scales
In-Reply-To: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
References: <CAL2fYnONAx9N+PaywYrZiA3YW2Bu7o+zt8p5vS85H7TAKvGNjw@mail.gmail.com>
Message-ID: <CA+8X3fWdP7AM5pFmjoLO=r3FGrbxOFA9v+3mJeO3zSK_QcQ=0A@mail.gmail.com>

Hi Adrian,
Perhaps what you want is this:

ajdat<-structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
"CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
)))
library(plotrix)
twoord.plot(0.8:6.8,ajdat[2,],1.2:7.2,ajdat[1,],
 main="Gene expression by chromosome loss/gain",
 lylim=c(-2.2,10),lytickpos=-2:2,
 xtickpos=1:7,xticklab=colnames(ajdat),
 ylab="Chromosome loss/gain",rylab="GN",
 type="bar",lcol=2,rcol=3,halfwidth=0.2)

Jim


On Thu, Oct 13, 2016 at 3:20 AM, Adrian Johnson
<oriolebaltimore at gmail.com> wrote:
> Dear group,
> I have been struggling to barplot two different measurements from one
> subject. These two measures differ in range.  I want to plot row 1
> axis on left side and row 2 values on right side.
>
> For a given column I want to plot GN and CN next to each other.
>
> my dput code is below
> :
>
> structure(c(112L, 0L, 579L, 1L, 131L, 1L, 2234L, 2L, 2892L, 1L,
> 528L, 0L, 582L, 2L), .Dim = c(2L, 7L), .Dimnames = list(c("GN",
> "CN"), c("DC5", "DC8", "DC14", "DC18", "DC19", "DC20", "DC23"
> )))
>
>
> As you can see:
>    DC5 DC8 DC14 DC18 DC19 DC20 DC23
> GN 112 579  131 2234 2892  528  582
> CN   0   1    1    2    1    0    2
>
> GN values are range from 100 - 3000
> while CN are always -2 or -1 or 0 or 1 or 2
>
> Also I cannot log GN values and plot because a difference in 100 units
> also matters in my experiment.
>
> Any help would be greatly appreciated.
>
> Thanks
> Adrian
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Oct 13 00:12:32 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 12 Oct 2016 15:12:32 -0700
Subject: [R] can we visualize water flows with 3d in R?
In-Reply-To: <b9652b19-25ba-ec08-c124-b77d4d34f70e@gmail.com>
References: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
	<b9652b19-25ba-ec08-c124-b77d4d34f70e@gmail.com>
Message-ID: <CE61A0C6-EE67-4CF2-AF70-69F0386841B2@comcast.net>


> On Oct 12, 2016, at 4:28 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 12/10/2016 4:49 AM, Marna Wagley wrote:
>> Hi R Users,
>> Is it possible to visualize river flow in  3D (latitude, longitude with
>> respect to depth)?
>> The example of my data looks like. Any suggestions?
>> 
>>> dat1
>>    long lat depth flow
>> 1 1015.9 857  1.00 1.50
>> 2 1015.9 857  1.25 1.23
>> 3 1015.9 857  0.50 2.00
>> 4 1015.9 858  0.10 1.95
>> 5 1015.9 858  0.20 1.50
>> 6 1025.0 858  0.30 1.20
>> 7 1025.0 858  0.40 0.50
>> 8 1025.0 858  0.35 0.70
>> 9 1025.0 858  0.24 1.20
>> 
>> Thanks for your help.
> 
> It may be, but it's hard to give a nice looking graphic of that small dataset.  You could try the rgl package and use plot3d to show spheres with radius depending on the flow rate, for example
> 
> plot3d(cbind(long, lat, depth), type="s", col="blue", radius=flow/5)

A complementary option is to install the plot3D package which I see also has a plot3Drgl "co-package". The advantage to this option is the association with beautiful modeling packages that Karline Soetaert, Peter M. J. Herman, and Thomas Petzoldt have been offering to ecologists for the last decade. (Packages: deSolve, marelac, seacarb, AquaEnv) A lot of her work has been on flows within systems. 

I usually think of "flows" in rivers as being vector fields in an incompressible fluid (water) with 6 components per point, but you can also think of them as being scalar state variables. So I suppose you could be modeling something other than mass flows.  (See Package::ReacTran for the R portal to that mathematical world.)

Best;
David Winsemius


> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From maillists at pp.inet.fi  Thu Oct 13 08:02:38 2016
From: maillists at pp.inet.fi (K. Elo)
Date: Thu, 13 Oct 2016 09:02:38 +0300
Subject: [R] Maybe OT: Forking in R scripts?
Message-ID: <cb0b5b29-0baf-ef83-9071-93cea9988917@pp.inet.fi>

Dear all,

I am currently working a research project on social media interaction. 
As a part of this project, mostly for teaching purposes, I should 
develop a R-based approach for real-time visualisation of streamed data 
(from Twitter).

My idea is simple (and working :) ): A Python-script stream Twitter for 
selected keywords/hashtags/users and redirects the output as JSON in a 
text file. My R-script reads the new entries from this text file every 
5-10 minutes, process the input and updates network and other graphical 
presentations.

Thus far everything is working fine. However, I would like to have the 
possibility to work with my data when my script is sleeping. I just 
wonder whether a simple 'mcparallel({ Sys.sleep(300); TRUE})' (from 
'parallel') would solve my problem? Or is there something I have to take 
into account when using 'parallel'?

My R environment runs on Linux, so forking should work...

Best regrads and thanks in advance,
Kimmo

--
?bo Akademi University, Finland
Dep. for German studies


From dulcalma at bigpond.com  Thu Oct 13 08:05:48 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 13 Oct 2016 17:05:48 +1100
Subject: [R] can we visualize water flows with 3d in R?
In-Reply-To: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
References: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
Message-ID: <000f01d22517$d89080b0$89b18210$@bigpond.com>

Hi

With a small data set 3D is not really an option;  reduce the number of
dimensions-- 2D conditional

library(lattice)
xyplot(flow ~ depth|factor(long), dat1, groups = lat, type = c("p","r"), pch
= 16)

I had started with lat and long reversed doing EDA gave the above
? latitude effect

Regards

Duncan


Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marna Wagley
Sent: Wednesday, 12 October 2016 19:49
To: r-help mailing list
Subject: [R] can we visualize water flows with 3d in R?

Hi R Users,
Is it possible to visualize river flow in  3D (latitude, longitude with
respect to depth)?
The example of my data looks like. Any suggestions?

> dat1
    long lat depth flow
1 1015.9 857  1.00 1.50
2 1015.9 857  1.25 1.23
3 1015.9 857  0.50 2.00
4 1015.9 858  0.10 1.95
5 1015.9 858  0.20 1.50
6 1025.0 858  0.30 1.20
7 1025.0 858  0.40 0.50
8 1025.0 858  0.35 0.70
9 1025.0 858  0.24 1.20

Thanks for your help.
thanks

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Thu Oct 13 10:18:08 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 13 Oct 2016 10:18:08 +0200
Subject: [R] Visibility of libraries called from within functions
Message-ID: <OFE6B06F19.244507CD-ONC125804B.002CC585-C125804B.002D9790@lotus.hawesko.de>

Hi All,

in my R programs I use different libraries to work with Excel sheets, i. 
e. xlsx, excel.link.

When running chunks of code repeatedly and not always in the order the 
program should run for development purposes I ran into trouble. There were 
conflicts between the methods within these functions causing R to crash.

I thought about defining functions for the different task and calling the 
libraries locally to there functions. Doing this test

-- cut --

f_test <- function() {
    library(xlsx)
    cat("Loaded packages AFTER loading library")
    print(search())
}

cat("Loaded packages BEFORE function call ----------------------------")
search()

f_test()

cat("Loaded packages AFTER function call -----------------------------")
search()

-- cut --

showed that the library "xlsx" was loaded into the global environment and 
stayed there although I had expected R to unload the library when leaving 
the function. Thus confilics can occur more often.

I had a look into ?library and saw that there is no argument telling R to 
hold the library in the calling environment.

How can I load libraries locally to the calling functions?

Kind regards

Georg


From rni.boh at gmail.com  Thu Oct 13 10:29:06 2016
From: rni.boh at gmail.com (Bob O'Hara)
Date: Thu, 13 Oct 2016 10:29:06 +0200
Subject: [R] (no subject)
Message-ID: <CAN-Z0xWC4jcwtsJ4CVCZ4mv0CLAs_q3EFLudAaMKtkqaJOgRRw@mail.gmail.com>

I've just come across an odd problem with sorting in ls(): it doesn't
seem to order the object names correctly. If I do the following, the
order isn't what I expect:

> ls(sorted=TRUE)
 [1] "AridData"          "AridDataToBUGS"    "Arid.df"
"Arid.hpd"          "AridPrecip.sd"     "Break.df"
 [7] "Break.hpd"         "Cols"              "Data"
"DataFrames"        "DataToBUGS"        "DataToBUGS.nonlog"
[13] "FitBRugs"          "Fixed.df"          "Fixed.hpd"
"FormatData"        "GetCol"            "GetHPD"
[19] "GetMCMC"           "GetRow"            "HPDIs"
"Int.alpha12"       "Int.alpha21"       "ModisData"
[25] "ModisDataToBUGS"   "Modis.df"          "ModisFixed.df"
"ModisFixed.hpd"    "Modis.hpd"         "ModisPrecip.sd"
[31] "ModisShrink.df"    "ModisShrink.hpd"   "ModisYears"
"OrigData"          "OrigDataToBUGS"    "Orig.df"
[37] "Orig.hpd"          "OrigPrecip.sd"     "OrigYears"
"PlotChecks"        "PlotEff"           "plothpd"
[43] "ProvinceNames"     "ResNames"          "ResNamesOrder"
"Shrink.df"         "Shrink.hpd"        "SimInits"

Specifically, the Modis* objects are sorted like this:

> ls(sorted=TRUE)[26:30]
[1] "Modis.df"       "ModisFixed.df"  "ModisFixed.hpd" "Modis.hpd"
 "ModisPrecip.sd"

With Modis.* coming both before and after ModisF*. I can't see why
there would be any odd problems with character sets changing (this was
all done on a single computer with no weird locale switching), and the
objects are all created within a single R session:

> sessionInfo()
R version 3.2.5 (2016-04-14)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.1 LTS

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
LC_TIME=en_GB.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_US.UTF-8
LC_PAPER=en_GB.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] MCMCglmm_2.22.1    ape_3.5            Matrix_1.2-7.1
RColorBrewer_1.1-2 plyr_1.8.4         coda_0.18-1

loaded via a namespace (and not attached):
[1] cubature_1.1-2  corpcor_1.6.8   tools_3.2.5     Rcpp_0.12.7
nlme_3.1-128    grid_3.2.5      knitr_1.14
[8] tensorA_0.36    lattice_0.20-34

Can anyone explain what's going on?

Bob

-- 
Bob O'Hara

Biodiversity and Climate Research Centre
Senckenberganlage 25
D-60325 Frankfurt am Main,
Germany

Tel: +49 69 798 40226
Mobile: +49 1515 888 5440
WWW:   http://www.bik-f.de/root/index.php?page_id=219
Blog: http://occamstypewriter.org/boboh/
Journal of Negative Results - EEB: www.jnr-eeb.org


From murdoch.duncan at gmail.com  Thu Oct 13 10:43:40 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 13 Oct 2016 04:43:40 -0400
Subject: [R] Visibility of libraries called from within functions
In-Reply-To: <OFE6B06F19.244507CD-ONC125804B.002CC585-C125804B.002D9790@lotus.hawesko.de>
References: <OFE6B06F19.244507CD-ONC125804B.002CC585-C125804B.002D9790@lotus.hawesko.de>
Message-ID: <71dfc6e2-89a5-0d1b-d64a-2e3960676eec@gmail.com>

On 13/10/2016 4:18 AM, G.Maubach at weinwolf.de wrote:
> Hi All,
>
> in my R programs I use different libraries to work with Excel sheets, i.
> e. xlsx, excel.link.
>
> When running chunks of code repeatedly and not always in the order the
> program should run for development purposes I ran into trouble. There were
> conflicts between the methods within these functions causing R to crash.
>
> I thought about defining functions for the different task and calling the
> libraries locally to there functions. Doing this test
>
> -- cut --
>
> f_test <- function() {
>     library(xlsx)
>     cat("Loaded packages AFTER loading library")
>     print(search())
> }
>
> cat("Loaded packages BEFORE function call ----------------------------")
> search()
>
> f_test()
>
> cat("Loaded packages AFTER function call -----------------------------")
> search()
>
> -- cut --
>
> showed that the library "xlsx" was loaded into the global environment and
> stayed there although I had expected R to unload the library when leaving
> the function. Thus confilics can occur more often.
>
> I had a look into ?library and saw that there is no argument telling R to
> hold the library in the calling environment.
>
> How can I load libraries locally to the calling functions?

You can detach at the end of your function, but that's tricky to get 
right:  the package might have been on the search list before your 
function was called.  It's better not to touch the search list at all.

The best solution is to use :: notation to get functions without putting 
them on the search list.  For example, use

xlsx::write.xlsx(data, file)

If you are not sure if your user has xlsx installed, you can use 
requireNamespace() to check.

Duncan Murdoch


From petr.pikal at precheza.cz  Thu Oct 13 11:26:51 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 13 Oct 2016 09:26:51 +0000
Subject: [R] (no subject)
In-Reply-To: <CAN-Z0xWC4jcwtsJ4CVCZ4mv0CLAs_q3EFLudAaMKtkqaJOgRRw@mail.gmail.com>
References: <CAN-Z0xWC4jcwtsJ4CVCZ4mv0CLAs_q3EFLudAaMKtkqaJOgRRw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50414D1@SRVEXCHMBX.precheza.cz>

Hi

Just a wild guess. Dot is ignored and the output is alphabetically sorted.

You could try sort it yourself by

sort(ls())

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bob
> O'Hara
> Sent: Thursday, October 13, 2016 10:29 AM
> To: r-help <r-help at r-project.org>
> Subject: [R] (no subject)
>
> I've just come across an odd problem with sorting in ls(): it doesn't seem to
> order the object names correctly. If I do the following, the order isn't what I
> expect:
>
> > ls(sorted=TRUE)
>  [1] "AridData"          "AridDataToBUGS"    "Arid.df"
> "Arid.hpd"          "AridPrecip.sd"     "Break.df"
>  [7] "Break.hpd"         "Cols"              "Data"
> "DataFrames"        "DataToBUGS"        "DataToBUGS.nonlog"
> [13] "FitBRugs"          "Fixed.df"          "Fixed.hpd"
> "FormatData"        "GetCol"            "GetHPD"
> [19] "GetMCMC"           "GetRow"            "HPDIs"
> "Int.alpha12"       "Int.alpha21"       "ModisData"
> [25] "ModisDataToBUGS"   "Modis.df"          "ModisFixed.df"
> "ModisFixed.hpd"    "Modis.hpd"         "ModisPrecip.sd"
> [31] "ModisShrink.df"    "ModisShrink.hpd"   "ModisYears"
> "OrigData"          "OrigDataToBUGS"    "Orig.df"
> [37] "Orig.hpd"          "OrigPrecip.sd"     "OrigYears"
> "PlotChecks"        "PlotEff"           "plothpd"
> [43] "ProvinceNames"     "ResNames"          "ResNamesOrder"
> "Shrink.df"         "Shrink.hpd"        "SimInits"
>
> Specifically, the Modis* objects are sorted like this:
>
> > ls(sorted=TRUE)[26:30]
> [1] "Modis.df"       "ModisFixed.df"  "ModisFixed.hpd" "Modis.hpd"
>  "ModisPrecip.sd"
>
> With Modis.* coming both before and after ModisF*. I can't see why there
> would be any odd problems with character sets changing (this was all done
> on a single computer with no weird locale switching), and the objects are all
> created within a single R session:
>
> > sessionInfo()
> R version 3.2.5 (2016-04-14)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.1 LTS
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> LC_TIME=en_GB.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_US.UTF-8
> LC_PAPER=en_GB.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] MCMCglmm_2.22.1    ape_3.5            Matrix_1.2-7.1
> RColorBrewer_1.1-2 plyr_1.8.4         coda_0.18-1
>
> loaded via a namespace (and not attached):
> [1] cubature_1.1-2  corpcor_1.6.8   tools_3.2.5     Rcpp_0.12.7
> nlme_3.1-128    grid_3.2.5      knitr_1.14
> [8] tensorA_0.36    lattice_0.20-34
>
> Can anyone explain what's going on?
>
> Bob
>
> --
> Bob O'Hara
>
> Biodiversity and Climate Research Centre Senckenberganlage 25
> D-60325 Frankfurt am Main,
> Germany
>
> Tel: +49 69 798 40226
> Mobile: +49 1515 888 5440
> WWW:   http://www.bik-f.de/root/index.php?page_id=219
> Blog: http://occamstypewriter.org/boboh/
> Journal of Negative Results - EEB: www.jnr-eeb.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From rni.boh at gmail.com  Thu Oct 13 11:55:04 2016
From: rni.boh at gmail.com (Bob O'Hara)
Date: Thu, 13 Oct 2016 11:55:04 +0200
Subject: [R] (no subject)
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50414D1@SRVEXCHMBX.precheza.cz>
References: <CAN-Z0xWC4jcwtsJ4CVCZ4mv0CLAs_q3EFLudAaMKtkqaJOgRRw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50414D1@SRVEXCHMBX.precheza.cz>
Message-ID: <CAN-Z0xVVpEhctTZPh_hBPpUgr6EFcEyNKLz8GpBXme_fu2iHJQ@mail.gmail.com>

Yes, thanks. That seems to be it:

thing <- c("M1", "M2", "M.1", "M.2")
> sort(thing)
[1] "M1"  "M.1" "M2"  "M.2"

The only documentation I can find is from ?Comparison:
"Collation of non-letters (spaces, punctuation signs, hyphens,
fractions and so on) is even more problematic."

Indeed.

Bob

On 13 October 2016 at 11:26, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Hi
>
> Just a wild guess. Dot is ignored and the output is alphabetically sorted.
>
> You could try sort it yourself by
>
> sort(ls())
>
> Cheers
> Petr
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bob
>> O'Hara
>> Sent: Thursday, October 13, 2016 10:29 AM
>> To: r-help <r-help at r-project.org>
>> Subject: [R] (no subject)
>>
>> I've just come across an odd problem with sorting in ls(): it doesn't seem to
>> order the object names correctly. If I do the following, the order isn't what I
>> expect:
>>
>> > ls(sorted=TRUE)
>>  [1] "AridData"          "AridDataToBUGS"    "Arid.df"
>> "Arid.hpd"          "AridPrecip.sd"     "Break.df"
>>  [7] "Break.hpd"         "Cols"              "Data"
>> "DataFrames"        "DataToBUGS"        "DataToBUGS.nonlog"
>> [13] "FitBRugs"          "Fixed.df"          "Fixed.hpd"
>> "FormatData"        "GetCol"            "GetHPD"
>> [19] "GetMCMC"           "GetRow"            "HPDIs"
>> "Int.alpha12"       "Int.alpha21"       "ModisData"
>> [25] "ModisDataToBUGS"   "Modis.df"          "ModisFixed.df"
>> "ModisFixed.hpd"    "Modis.hpd"         "ModisPrecip.sd"
>> [31] "ModisShrink.df"    "ModisShrink.hpd"   "ModisYears"
>> "OrigData"          "OrigDataToBUGS"    "Orig.df"
>> [37] "Orig.hpd"          "OrigPrecip.sd"     "OrigYears"
>> "PlotChecks"        "PlotEff"           "plothpd"
>> [43] "ProvinceNames"     "ResNames"          "ResNamesOrder"
>> "Shrink.df"         "Shrink.hpd"        "SimInits"
>>
>> Specifically, the Modis* objects are sorted like this:
>>
>> > ls(sorted=TRUE)[26:30]
>> [1] "Modis.df"       "ModisFixed.df"  "ModisFixed.hpd" "Modis.hpd"
>>  "ModisPrecip.sd"
>>
>> With Modis.* coming both before and after ModisF*. I can't see why there
>> would be any odd problems with character sets changing (this was all done
>> on a single computer with no weird locale switching), and the objects are all
>> created within a single R session:
>>
>> > sessionInfo()
>> R version 3.2.5 (2016-04-14)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 16.04.1 LTS
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> LC_TIME=en_GB.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_US.UTF-8
>> LC_PAPER=en_GB.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] MCMCglmm_2.22.1    ape_3.5            Matrix_1.2-7.1
>> RColorBrewer_1.1-2 plyr_1.8.4         coda_0.18-1
>>
>> loaded via a namespace (and not attached):
>> [1] cubature_1.1-2  corpcor_1.6.8   tools_3.2.5     Rcpp_0.12.7
>> nlme_3.1-128    grid_3.2.5      knitr_1.14
>> [8] tensorA_0.36    lattice_0.20-34
>>
>> Can anyone explain what's going on?
>>
>> Bob
>>
>> --
>> Bob O'Hara
>>
>> Biodiversity and Climate Research Centre Senckenberganlage 25
>> D-60325 Frankfurt am Main,
>> Germany
>>
>> Tel: +49 69 798 40226
>> Mobile: +49 1515 888 5440
>> WWW:   http://www.bik-f.de/root/index.php?page_id=219
>> Blog: http://occamstypewriter.org/boboh/
>> Journal of Negative Results - EEB: www.jnr-eeb.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



-- 
Bob O'Hara

Biodiversity and Climate Research Centre
Senckenberganlage 25
D-60325 Frankfurt am Main,
Germany

Tel: +49 69 798 40226
Mobile: +49 1515 888 5440
WWW:   http://www.bik-f.de/root/index.php?page_id=219
Blog: http://occamstypewriter.org/boboh/
Journal of Negative Results - EEB: www.jnr-eeb.org


From G.Maubach at weinwolf.de  Thu Oct 13 12:21:42 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 13 Oct 2016 12:21:42 +0200
Subject: [R] Antwort: Re: Visibility of libraries called from within
	functions
In-Reply-To: <71dfc6e2-89a5-0d1b-d64a-2e3960676eec@gmail.com>
References: <OFE6B06F19.244507CD-ONC125804B.002CC585-C125804B.002D9790@lotus.hawesko.de>
	<71dfc6e2-89a5-0d1b-d64a-2e3960676eec@gmail.com>
Message-ID: <OF4C94BDD9.87E4BD2B-ONC125804B.00388B35-C125804B.0038E7C8@lotus.hawesko.de>

Hi Duncan,

many thanks for your reply.

Your suggestion of using requireNamespace() together with explicit 
namespace calling using the "::" operator is what I was looking for:

-- cut --

f_test <- function() {
    requireNamespace("openxlsx")
    cat("Loaded packages AFTER loading library")
    print(search())
    xlsx::read.xlsx(file = "c:/temp/test.xlsx",
                    sheetName = "test")
}

cat("Loaded packages BEFORE function call ----------------------------")
search()

f_test()

cat("Loaded packages AFTER function call -----------------------------")
search()

-- cut  --

When reading ?requireNamespace I did not really get how R operates behind 
the scenes.

Using "library" attaches the namespace to the search path. Using 
"requireNamespace" does not do that.

But how does R find the namespace then? What kind of list or directory 
used R to to store the namespace and lookup the correct function or 
methods of this namespace?

Kind regards

Georg




Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
An:     G.Maubach at weinwolf.de, r-help at r-project.org, 
Datum:  13.10.2016 10:43
Betreff:        Re: [R] Visibility of libraries called from within 
functions



On 13/10/2016 4:18 AM, G.Maubach at weinwolf.de wrote:
> Hi All,
>
> in my R programs I use different libraries to work with Excel sheets, i.
> e. xlsx, excel.link.
>
> When running chunks of code repeatedly and not always in the order the
> program should run for development purposes I ran into trouble. There 
were
> conflicts between the methods within these functions causing R to crash.
>
> I thought about defining functions for the different task and calling 
the
> libraries locally to there functions. Doing this test
>
> -- cut --
>
> f_test <- function() {
>     library(xlsx)
>     cat("Loaded packages AFTER loading library")
>     print(search())
> }
>
> cat("Loaded packages BEFORE function call ----------------------------")
> search()
>
> f_test()
>
> cat("Loaded packages AFTER function call -----------------------------")
> search()
>
> -- cut --
>
> showed that the library "xlsx" was loaded into the global environment 
and
> stayed there although I had expected R to unload the library when 
leaving
> the function. Thus confilics can occur more often.
>
> I had a look into ?library and saw that there is no argument telling R 
to
> hold the library in the calling environment.
>
> How can I load libraries locally to the calling functions?

You can detach at the end of your function, but that's tricky to get 
right:  the package might have been on the search list before your 
function was called.  It's better not to touch the search list at all.

The best solution is to use :: notation to get functions without putting 
them on the search list.  For example, use

xlsx::write.xlsx(data, file)

If you are not sure if your user has xlsx installed, you can use 
requireNamespace() to check.

Duncan Murdoch


From ruipbarradas at sapo.pt  Thu Oct 13 12:30:08 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 13 Oct 2016 11:30:08 +0100
Subject: [R] Incremental
In-Reply-To: <CAJOiR6Z8mRnb-+C-QOfd6jqD7vB-8VkQCj+gGgbf7Cim=tkusw@mail.gmail.com>
References: <CAJOiR6Z0Cu_OS_nF4WrW0FBbUVZphSzbi1pwRmYz403vjVxB8w@mail.gmail.com>
	<57FE9E38.1040800@sapo.pt>
	<CAJOiR6Z8mRnb-+C-QOfd6jqD7vB-8VkQCj+gGgbf7Cim=tkusw@mail.gmail.com>
Message-ID: <57FF6230.5090609@sapo.pt>

Hello,

You must run the code to create x1 first, part 1), then part 2).
I've tested with your data and all went well, the result is the following.

 > dput(dat)
structure(list(y1 = c(39958L, 40058L, 40105L, 40294L, 40332L,
40471L, 40493L, 40533L, 40718L, 40771L, 40829L, 40892L, 41056L,
41110L, 41160L, 41222L, 41250L, 41289L, 41324L, 41355L, 41415L,
41562L, 41562L, 41586L), flag = structure(c(3L, 2L, 4L, 1L, 3L,
2L, 2L, 4L, 1L, 3L, 2L, 4L, 1L, 3L, 2L, 2L, 2L, 2L, 4L, 2L, 4L,
4L, 1L, 3L), .Label = c("H", "R", "S", "X"), class = "factor"),
     x1 = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L), z2 = c(0L, 100L,
     147L, 336L, 0L, 139L, 161L, 201L, 386L, 0L, 58L, 121L, 285L,
     0L, 50L, 112L, 140L, 179L, 214L, 245L, 305L, 452L, 452L,
     0L)), .Names = c("y1", "flag", "x1", "z2"), row.names = c(NA,
-24L), class = "data.frame")


Rui Barradas

Em 12-10-2016 21:53, Val escreveu:
> Rui,
> Thank You!
>
> the second one gave me NULL.
> dat$z2 <- unlist(tapply(dat$y1, dat$x1, function(y) y - y[1]))
>
> dat$z2
> NULL
>
>
>
> On Wed, Oct 12, 2016 at 3:34 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>> Hello,
>>
>> Seems simple:
>>
>>
>> # 1)
>> dat$x1 <- cumsum(dat$flag == "S")
>>
>> # 2)
>> dat$z2 <- unlist(tapply(dat$y1, dat$x1, function(y) y - y[1]))
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> Em 12-10-2016 21:15, Val escreveu:
>>>
>>> Hi all,
>>>
>>> I have a data set like
>>> dat<-read.table(text=" y1, flag
>>> 39958,S
>>> 40058,R
>>> 40105,X
>>> 40294,H
>>> 40332,S
>>> 40471,R
>>> 40493,R
>>> 40533,X
>>> 40718,H
>>> 40771,S
>>> 40829,R
>>> 40892,X
>>> 41056,H
>>> 41110,S
>>> 41160,R
>>> 41222,R
>>> 41250,R
>>> 41289,R
>>> 41324,X
>>> 41355,R
>>> 41415,X
>>> 41562,X
>>> 41562,H
>>> 41586,S
>>> ",sep=",",header=TRUE)
>>>
>>> First sort the data by y1.
>>> Then
>>> I want to create two columns .
>>> 1. the first new column is  (x1):  if flag is "S"  then  x1=1  and
>>> assign the following/subsequent rows 1 as well.   When we reach to
>>> the next "S"  then  x1=2 and the subsequent rows will be assigned to
>>> 2.
>>>
>>> 2. the second variable (z2). Within each x1 find the difference
>>> between the first y1 and subsequent y1 values
>>>
>>> Example  for the first few rows
>>>     y1,   flag, x1, z2
>>> 39958, S, 1,    0          z2 is calculated as     z2=(39958, 39958)
>>> 40058, R, 1, 100         z2 is calculated as     z2=(40058, 39958)
>>> 40105, X, 1, 147         z2 is calculated as     z2=(40105, 39958)
>>> 40294, H, 1, 336         z2 is calculated as     z2=(40294, 39958)
>>> 40332, S, 2,  0            z2 is calculated as     z2=(40332, 40332)
>>> etc
>>>
>>> Here is the complete output for the sample  data
>>> 39958,S,1,0
>>> 40058,R,1,100
>>> 40105,X,1,147
>>> 40294,H,1,336
>>> 40332,S,2,0
>>> 40471,R,2,139
>>> 40493,R,2,161
>>> 40533,X,2,201
>>> 40718,H,2,386
>>> 40771,S,3,0
>>> 40829,R,3,58
>>> 40892,X,3,121
>>> 41056,H,3,285
>>> 41110,S,4,0
>>> 41160,R,4,50
>>> 41222,R,4,112
>>> 41250,R,4,140
>>> 41289,R,4,179
>>> 41324,X,4,214
>>> 41355,R,4,245
>>> 41415,X,4,305
>>> 41562,X,4,452
>>> 41562,H,4,452
>>> 41586,S,5,0
>>>
>>> Val
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>


From murdoch.duncan at gmail.com  Thu Oct 13 12:34:42 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 13 Oct 2016 06:34:42 -0400
Subject: [R] Antwort: Re: Visibility of libraries called from within
 functions
In-Reply-To: <OF4C94BDD9.87E4BD2B-ONC125804B.00388B35-C125804B.0038E7C8@lotus.hawesko.de>
References: <OFE6B06F19.244507CD-ONC125804B.002CC585-C125804B.002D9790@lotus.hawesko.de>
	<71dfc6e2-89a5-0d1b-d64a-2e3960676eec@gmail.com>
	<OF4C94BDD9.87E4BD2B-ONC125804B.00388B35-C125804B.0038E7C8@lotus.hawesko.de>
Message-ID: <112952d8-00d6-76ee-3909-6b56d740deeb@gmail.com>

On 13/10/2016 6:21 AM, G.Maubach at weinwolf.de wrote:
> Hi Duncan,
>
> many thanks for your reply.
>
> Your suggestion of using requireNamespace() together with explicit
> namespace calling using the "::" operator is what I was looking for:
>
> -- cut --
>
> f_test <- function() {
>     requireNamespace("openxlsx")
>     cat("Loaded packages AFTER loading library")
>     print(search())
>     xlsx::read.xlsx(file = "c:/temp/test.xlsx",
>                     sheetName = "test")
> }

Not sure if that's a typo in your message or a real error, but you 
require "openxlsx" and then use "xlsx".


>
> cat("Loaded packages BEFORE function call ----------------------------")
> search()
>
> f_test()
>
> cat("Loaded packages AFTER function call -----------------------------")
> search()
>
> -- cut  --
>
> When reading ?requireNamespace I did not really get how R operates behind
> the scenes.
>
> Using "library" attaches the namespace to the search path. Using
> "requireNamespace" does not do that.
>
> But how does R find the namespace then? What kind of list or directory
> used R to to store the namespace and lookup the correct function or
> methods of this namespace?

R has an internal list of packages that are loaded.  Functions in them 
are only visible to user code if the package is *also* on the search 
list, or if the package name prefix is used with ::.

If xlsx is loaded, xlsx::read.xlsx will just use it; if it is not 
loaded, the package will be loaded to make the call.  So you don't need 
the requireNamespace call if you can be sure that xlsx will be found. 
You would normally use its return value (FALSE if the package is not 
found) to test whether it will be safe to make the xlsx::read.xlsx call.

Duncan Murdoch

>
> Kind regards
>
> Georg
>
>
>
>
> Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
> An:     G.Maubach at weinwolf.de, r-help at r-project.org,
> Datum:  13.10.2016 10:43
> Betreff:        Re: [R] Visibility of libraries called from within
> functions
>
>
>
> On 13/10/2016 4:18 AM, G.Maubach at weinwolf.de wrote:
>> Hi All,
>>
>> in my R programs I use different libraries to work with Excel sheets, i.
>> e. xlsx, excel.link.
>>
>> When running chunks of code repeatedly and not always in the order the
>> program should run for development purposes I ran into trouble. There
> were
>> conflicts between the methods within these functions causing R to crash.
>>
>> I thought about defining functions for the different task and calling
> the
>> libraries locally to there functions. Doing this test
>>
>> -- cut --
>>
>> f_test <- function() {
>>     library(xlsx)
>>     cat("Loaded packages AFTER loading library")
>>     print(search())
>> }
>>
>> cat("Loaded packages BEFORE function call ----------------------------")
>> search()
>>
>> f_test()
>>
>> cat("Loaded packages AFTER function call -----------------------------")
>> search()
>>
>> -- cut --
>>
>> showed that the library "xlsx" was loaded into the global environment
> and
>> stayed there although I had expected R to unload the library when
> leaving
>> the function. Thus confilics can occur more often.
>>
>> I had a look into ?library and saw that there is no argument telling R
> to
>> hold the library in the calling environment.
>>
>> How can I load libraries locally to the calling functions?
>
> You can detach at the end of your function, but that's tricky to get
> right:  the package might have been on the search list before your
> function was called.  It's better not to touch the search list at all.
>
> The best solution is to use :: notation to get functions without putting
> them on the search list.  For example, use
>
> xlsx::write.xlsx(data, file)
>
> If you are not sure if your user has xlsx installed, you can use
> requireNamespace() to check.
>
> Duncan Murdoch
>
>
>
>
>


From maechler at stat.math.ethz.ch  Thu Oct 13 13:00:29 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 13 Oct 2016 13:00:29 +0200
Subject: [R] sort()ing strings
In-Reply-To: <CAN-Z0xVVpEhctTZPh_hBPpUgr6EFcEyNKLz8GpBXme_fu2iHJQ@mail.gmail.com>
References: <CAN-Z0xWC4jcwtsJ4CVCZ4mv0CLAs_q3EFLudAaMKtkqaJOgRRw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50414D1@SRVEXCHMBX.precheza.cz>
	<CAN-Z0xVVpEhctTZPh_hBPpUgr6EFcEyNKLz8GpBXme_fu2iHJQ@mail.gmail.com>
Message-ID: <22527.26957.281028.757452@stat.math.ethz.ch>

>>>>> Bob O'Hara <rni.boh at gmail.com>
>>>>>     on Thu, 13 Oct 2016 11:55:04 +0200 writes:

    > Yes, thanks. That seems to be it: 
    > thing <- c("M1", "M2", "M.1", "M.2")
    >> sort(thing)
    > [1] "M1" "M.1" "M2" "M.2"

which I do find strange, indeed, given your sessionInfo which
contains
	LC_COLLATE=en_US.UTF-8

    > The only documentation I can find is from ?Comparison:
    > "Collation of non-letters (spaces, punctuation signs,
    > hyphens, fractions and so on) is even more problematic."

Well.  That help page contains more information further down,
notably about ICU.  If

     capabilities("ICU")

gives TRUE for you (I assume it will as you use a modern ubuntu version),
you can tweak the behavior to be more "reasonable" than above

via R functions icu(Set|Get)Collate()

BTW, I say "strange" above, because for me - also on modern
Linux (Fedora 24), I "always" see

> sort( c("M1", "M2", "M.1", "M.2") )
[1] "M.1" "M.2" "M1"  "M2" 


> Sys.setlocale("LC_COLLATE", "de_CH.UTF-8")
[1] "de_CH.UTF-8"
> sort( c("M1", "M2", "M.1", "M.2") )
[1] "M.1" "M.2" "M1"  "M2" 
> Sys.setlocale("LC_COLLATE", "en_US.UTF-8")
[1] "en_US.UTF-8"
> sort( c("M1", "M2", "M.1", "M.2") )
[1] "M.1" "M.2" "M1"  "M2" 

> Sys.setlocale("LC_COLLATE", "C") # <--> ASCII ("the ole' time default)
[1] "C"
> sort( c("M1", "M2", "M.1", "M.2") )
[1] "M.1" "M.2" "M1"  "M2" 
> 

I do use a newer R version (3.3.1 patched)
but would not have expected that to matter here.

Martin


    > Indeed.

    > Bob

    > On 13 October 2016 at 11:26, PIKAL Petr
    > <petr.pikal at precheza.cz> wrote:
    >> Hi
    >> 
    >> Just a wild guess. Dot is ignored and the output is
    >> alphabetically sorted.
    >> 
    >> You could try sort it yourself by
    >> 
    >> sort(ls())
    >> 
    >> Cheers Petr
    >> 
    >>> -----Original Message----- From: R-help
    >>> [mailto:r-help-bounces at r-project.org] On Behalf Of Bob
    >>> O'Hara Sent: Thursday, October 13, 2016 10:29 AM To:
    >>> r-help <r-help at r-project.org> Subject: [R] (no subject)
    >>> 
    >>> I've just come across an odd problem with sorting in
    >>> ls(): it doesn't seem to order the object names
    >>> correctly. If I do the following, the order isn't what I
    >>> expect:
    >>> 
    >>> > ls(sorted=TRUE) [1] "AridData" "AridDataToBUGS"
    >>> "Arid.df" "Arid.hpd" "AridPrecip.sd" "Break.df" [7]
    >>> "Break.hpd" "Cols" "Data" "DataFrames" "DataToBUGS"
    >>> "DataToBUGS.nonlog" [13] "FitBRugs" "Fixed.df"
    >>> "Fixed.hpd" "FormatData" "GetCol" "GetHPD" [19]
    >>> "GetMCMC" "GetRow" "HPDIs" "Int.alpha12" "Int.alpha21"
    >>> "ModisData" [25] "ModisDataToBUGS" "Modis.df"
    >>> "ModisFixed.df" "ModisFixed.hpd" "Modis.hpd"
    >>> "ModisPrecip.sd" [31] "ModisShrink.df" "ModisShrink.hpd"
    >>> "ModisYears" "OrigData" "OrigDataToBUGS" "Orig.df" [37]
    >>> "Orig.hpd" "OrigPrecip.sd" "OrigYears" "PlotChecks"
    >>> "PlotEff" "plothpd" [43] "ProvinceNames" "ResNames"
    >>> "ResNamesOrder" "Shrink.df" "Shrink.hpd" "SimInits"
    >>> 
    >>> Specifically, the Modis* objects are sorted like this:
    >>> 
    >>> > ls(sorted=TRUE)[26:30] [1] "Modis.df" "ModisFixed.df"
    >>> "ModisFixed.hpd" "Modis.hpd" "ModisPrecip.sd"
    >>> 
    >>> With Modis.* coming both before and after ModisF*. I
    >>> can't see why there would be any odd problems with
    >>> character sets changing (this was all done on a single
    >>> computer with no weird locale switching), and the
    >>> objects are all created within a single R session:
    >>> 
    >>> > sessionInfo() R version 3.2.5 (2016-04-14) Platform:
    >>> x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu
    >>> 16.04.1 LTS
    >>> 
    >>> locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
    >>> LC_TIME=en_GB.UTF-8 LC_COLLATE=en_US.UTF-8 [5]
    >>> LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_US.UTF-8
    >>> LC_PAPER=en_GB.UTF-8 LC_NAME=C [9] LC_ADDRESS=C
    >>> LC_TELEPHONE=C LC_MEASUREMENT=en_GB.UTF-8
    >>> LC_IDENTIFICATION=C
    >>> 
    >>> attached base packages: [1] stats graphics grDevices
    >>> utils datasets methods base
    >>> 
    >>> other attached packages: [1] MCMCglmm_2.22.1 ape_3.5
    >>> Matrix_1.2-7.1 RColorBrewer_1.1-2 plyr_1.8.4 coda_0.18-1
    >>> 
    >>> loaded via a namespace (and not attached): [1]
    >>> cubature_1.1-2 corpcor_1.6.8 tools_3.2.5 Rcpp_0.12.7
    >>> nlme_3.1-128 grid_3.2.5 knitr_1.14 [8] tensorA_0.36
    >>> lattice_0.20-34
    >>> 
    >>> Can anyone explain what's going on?
    >>> 
    >>> Bob
    >>> --
    >>> Bob O'Hara
    >>> 
    >>> Biodiversity and Climate Research Centre
    >>> Senckenberganlage 25 D-60325 Frankfurt am Main, Germany
    >>> 
    >>> Tel: +49 69 798 40226 Mobile: +49 1515 888 5440 WWW:
    >>> http://www.bik-f.de/root/index.php?page_id=219 Blog:
    >>> http://occamstypewriter.org/boboh/ Journal of Negative
    >>> Results - EEB: www.jnr-eeb.org


From G.Maubach at weinwolf.de  Thu Oct 13 13:07:31 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 13 Oct 2016 13:07:31 +0200
Subject: [R] Antwort: Re: Antwort: Re: Visibility of libraries called from
 within functions
In-Reply-To: <112952d8-00d6-76ee-3909-6b56d740deeb@gmail.com>
References: <OFE6B06F19.244507CD-ONC125804B.002CC585-C125804B.002D9790@lotus.hawesko.de>
	<71dfc6e2-89a5-0d1b-d64a-2e3960676eec@gmail.com>
	<OF4C94BDD9.87E4BD2B-ONC125804B.00388B35-C125804B.0038E7C8@lotus.hawesko.de>
	<112952d8-00d6-76ee-3909-6b56d740deeb@gmail.com>
Message-ID: <OF0AC7A3C7.441CD585-ONC125804B.003CEFC5-C125804B.003D1993@lotus.hawesko.de>

Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
An:     G.Maubach at weinwolf.de, r-help at r-project.org, 
Datum:  13.10.2016 12:34
Betreff:        Re: Antwort: Re: [R] Visibility of libraries called from 
within functions



On 13/10/2016 6:21 AM, G.Maubach at weinwolf.de wrote:
> Hi Duncan,
>
> many thanks for your reply.
>
> Your suggestion of using requireNamespace() together with explicit
> namespace calling using the "::" operator is what I was looking for:
>
> -- cut --
>
> f_test <- function() {
>     requireNamespace("openxlsx")
>     cat("Loaded packages AFTER loading library")
>     print(search())
>     xlsx::read.xlsx(file = "c:/temp/test.xlsx",
>                     sheetName = "test")
> }

Not sure if that's a typo in your message or a real error, but you 
require "openxlsx" and then use "xlsx".

It's a typo!


>
> cat("Loaded packages BEFORE function call ----------------------------")
> search()
>
> f_test()
>
> cat("Loaded packages AFTER function call -----------------------------")
> search()
>
> -- cut  --
>
> When reading ?requireNamespace I did not really get how R operates 
behind
> the scenes.
>
> Using "library" attaches the namespace to the search path. Using
> "requireNamespace" does not do that.
>
> But how does R find the namespace then? What kind of list or directory
> used R to to store the namespace and lookup the correct function or
> methods of this namespace?

R has an internal list of packages that are loaded.  Functions in them 
are only visible to user code if the package is *also* on the search 
list, or if the package name prefix is used with ::.

Can I have a look at this internal list like I can do with search() for 
pachages or ls() for objects?

If xlsx is loaded, xlsx::read.xlsx will just use it; if it is not 
loaded, the package will be loaded to make the call.  So you don't need 
the requireNamespace call if you can be sure that xlsx will be found. 
You would normally use its return value (FALSE if the package is not 
found) to test whether it will be safe to make the xlsx::read.xlsx call.

Got it!



Duncan Murdoch

>
> Kind regards
>
> Georg
>
>
>
>
> Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
> An:     G.Maubach at weinwolf.de, r-help at r-project.org,
> Datum:  13.10.2016 10:43
> Betreff:        Re: [R] Visibility of libraries called from within
> functions
>
>
>
> On 13/10/2016 4:18 AM, G.Maubach at weinwolf.de wrote:
>> Hi All,
>>
>> in my R programs I use different libraries to work with Excel sheets, 
i.
>> e. xlsx, excel.link.
>>
>> When running chunks of code repeatedly and not always in the order the
>> program should run for development purposes I ran into trouble. There
> were
>> conflicts between the methods within these functions causing R to 
crash.
>>
>> I thought about defining functions for the different task and calling
> the
>> libraries locally to there functions. Doing this test
>>
>> -- cut --
>>
>> f_test <- function() {
>>     library(xlsx)
>>     cat("Loaded packages AFTER loading library")
>>     print(search())
>> }
>>
>> cat("Loaded packages BEFORE function call 
----------------------------")
>> search()
>>
>> f_test()
>>
>> cat("Loaded packages AFTER function call 
-----------------------------")
>> search()
>>
>> -- cut --
>>
>> showed that the library "xlsx" was loaded into the global environment
> and
>> stayed there although I had expected R to unload the library when
> leaving
>> the function. Thus confilics can occur more often.
>>
>> I had a look into ?library and saw that there is no argument telling R
> to
>> hold the library in the calling environment.
>>
>> How can I load libraries locally to the calling functions?
>
> You can detach at the end of your function, but that's tricky to get
> right:  the package might have been on the search list before your
> function was called.  It's better not to touch the search list at all.
>
> The best solution is to use :: notation to get functions without putting
> them on the search list.  For example, use
>
> xlsx::write.xlsx(data, file)
>
> If you are not sure if your user has xlsx installed, you can use
> requireNamespace() to check.
>
> Duncan Murdoch
>
>
>
>
>


From tea3rd at gmail.com  Thu Oct 13 14:35:34 2016
From: tea3rd at gmail.com (Thomas Adams)
Date: Thu, 13 Oct 2016 08:35:34 -0400
Subject: [R] can we visualize water flows with 3d in R?
In-Reply-To: <CE61A0C6-EE67-4CF2-AF70-69F0386841B2@comcast.net>
References: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
	<b9652b19-25ba-ec08-c124-b77d4d34f70e@gmail.com>
	<CE61A0C6-EE67-4CF2-AF70-69F0386841B2@comcast.net>
Message-ID: <CAGxgkWhYa1wftNweixM=vTcxR3JeETX07E6snf=geb4wpeK9NQ@mail.gmail.com>

All,

Very respectfully, there are no R packages that can do what Marna desires.
His/Her data, undoubtably, comes from a 1-D hydraulic model simulation --
where output is generated at channel cross-sections -- representing the
sloping water surface elevation of the centerline of flow in a stream or
river. With mapping software for such problems, the assumption is made that
the water surface intersects the topography (within or beyond the stream
channel) perpendicular to the direction of flow. Hydrodynamically, this is
generally not correct, but it's a reasonable approximation. To do this,
typically, the topography -- in the from of a raster digital elevation
model (DEM) -- is converted to a triangular irregular network (TIN) to
facilitate the creation of a smoother line of intersection between the
water surface and topography. Because, the water surface slopes in a
downstream direction, contour lines are crossed. Hydraulic modeling
software usually is accompanied by this mapping capability, such as with
HEC-RAS with RAS-Mapper, developed by the US Army Corps of Engineers, or
with HEC-GeoRAS, which requires ESRI ARC GIS; but, there is also a QGIS
plugin module that can do this, I believe. These software packages do
facilitate representing the flow in 3D.

Tom


On Wed, Oct 12, 2016 at 6:12 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Oct 12, 2016, at 4:28 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> >
> > On 12/10/2016 4:49 AM, Marna Wagley wrote:
> >> Hi R Users,
> >> Is it possible to visualize river flow in  3D (latitude, longitude with
> >> respect to depth)?
> >> The example of my data looks like. Any suggestions?
> >>
> >>> dat1
> >>    long lat depth flow
> >> 1 1015.9 857  1.00 1.50
> >> 2 1015.9 857  1.25 1.23
> >> 3 1015.9 857  0.50 2.00
> >> 4 1015.9 858  0.10 1.95
> >> 5 1015.9 858  0.20 1.50
> >> 6 1025.0 858  0.30 1.20
> >> 7 1025.0 858  0.40 0.50
> >> 8 1025.0 858  0.35 0.70
> >> 9 1025.0 858  0.24 1.20
> >>
> >> Thanks for your help.
> >
> > It may be, but it's hard to give a nice looking graphic of that small
> dataset.  You could try the rgl package and use plot3d to show spheres with
> radius depending on the flow rate, for example
> >
> > plot3d(cbind(long, lat, depth), type="s", col="blue", radius=flow/5)
>
> A complementary option is to install the plot3D package which I see also
> has a plot3Drgl "co-package". The advantage to this option is the
> association with beautiful modeling packages that Karline Soetaert, Peter
> M. J. Herman, and Thomas Petzoldt have been offering to ecologists for the
> last decade. (Packages: deSolve, marelac, seacarb, AquaEnv) A lot of her
> work has been on flows within systems.
>
> I usually think of "flows" in rivers as being vector fields in an
> incompressible fluid (water) with 6 components per point, but you can also
> think of them as being scalar state variables. So I suppose you could be
> modeling something other than mass flows.  (See Package::ReacTran for the R
> portal to that mathematical world.)
>
> Best;
> David Winsemius
>
>
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Oct 13 14:52:12 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 13 Oct 2016 14:52:12 +0200
Subject: [R] (no subject)
In-Reply-To: <CAN-Z0xWC4jcwtsJ4CVCZ4mv0CLAs_q3EFLudAaMKtkqaJOgRRw@mail.gmail.com>
References: <CAN-Z0xWC4jcwtsJ4CVCZ4mv0CLAs_q3EFLudAaMKtkqaJOgRRw@mail.gmail.com>
Message-ID: <F492512F-6DD4-492B-A5A3-2E0537749233@gmail.com>

Collating orders are a weird and wooly bunch...  

My hunch is that you have one of those that ignore punctuation and sorts AaBbCc<etc>, so that you are seeing Modis{d-F-F-h-P}. ?Comparison for details.

-pd

> On 13 Oct 2016, at 10:29 , Bob O'Hara <rni.boh at gmail.com> wrote:
> 
> I've just come across an odd problem with sorting in ls(): it doesn't
> seem to order the object names correctly. If I do the following, the
> order isn't what I expect:
> 
>> ls(sorted=TRUE)
> [1] "AridData"          "AridDataToBUGS"    "Arid.df"
> "Arid.hpd"          "AridPrecip.sd"     "Break.df"
> [7] "Break.hpd"         "Cols"              "Data"
> "DataFrames"        "DataToBUGS"        "DataToBUGS.nonlog"
> [13] "FitBRugs"          "Fixed.df"          "Fixed.hpd"
> "FormatData"        "GetCol"            "GetHPD"
> [19] "GetMCMC"           "GetRow"            "HPDIs"
> "Int.alpha12"       "Int.alpha21"       "ModisData"
> [25] "ModisDataToBUGS"   "Modis.df"          "ModisFixed.df"
> "ModisFixed.hpd"    "Modis.hpd"         "ModisPrecip.sd"
> [31] "ModisShrink.df"    "ModisShrink.hpd"   "ModisYears"
> "OrigData"          "OrigDataToBUGS"    "Orig.df"
> [37] "Orig.hpd"          "OrigPrecip.sd"     "OrigYears"
> "PlotChecks"        "PlotEff"           "plothpd"
> [43] "ProvinceNames"     "ResNames"          "ResNamesOrder"
> "Shrink.df"         "Shrink.hpd"        "SimInits"
> 
> Specifically, the Modis* objects are sorted like this:
> 
>> ls(sorted=TRUE)[26:30]
> [1] "Modis.df"       "ModisFixed.df"  "ModisFixed.hpd" "Modis.hpd"
> "ModisPrecip.sd"
> 
> With Modis.* coming both before and after ModisF*. I can't see why
> there would be any odd problems with character sets changing (this was
> all done on a single computer with no weird locale switching), and the
> objects are all created within a single R session:
> 
>> sessionInfo()
> R version 3.2.5 (2016-04-14)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.1 LTS
> 
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> LC_TIME=en_GB.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_US.UTF-8
> LC_PAPER=en_GB.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] MCMCglmm_2.22.1    ape_3.5            Matrix_1.2-7.1
> RColorBrewer_1.1-2 plyr_1.8.4         coda_0.18-1
> 
> loaded via a namespace (and not attached):
> [1] cubature_1.1-2  corpcor_1.6.8   tools_3.2.5     Rcpp_0.12.7
> nlme_3.1-128    grid_3.2.5      knitr_1.14
> [8] tensorA_0.36    lattice_0.20-34
> 
> Can anyone explain what's going on?
> 
> Bob
> 
> -- 
> Bob O'Hara
> 
> Biodiversity and Climate Research Centre
> Senckenberganlage 25
> D-60325 Frankfurt am Main,
> Germany
> 
> Tel: +49 69 798 40226
> Mobile: +49 1515 888 5440
> WWW:   http://www.bik-f.de/root/index.php?page_id=219
> Blog: http://occamstypewriter.org/boboh/
> Journal of Negative Results - EEB: www.jnr-eeb.org
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Thu Oct 13 15:20:23 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 13 Oct 2016 09:20:23 -0400
Subject: [R] can we visualize water flows with 3d in R?
In-Reply-To: <CAGxgkWhYa1wftNweixM=vTcxR3JeETX07E6snf=geb4wpeK9NQ@mail.gmail.com>
References: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
	<b9652b19-25ba-ec08-c124-b77d4d34f70e@gmail.com>
	<CE61A0C6-EE67-4CF2-AF70-69F0386841B2@comcast.net>
	<CAGxgkWhYa1wftNweixM=vTcxR3JeETX07E6snf=geb4wpeK9NQ@mail.gmail.com>
Message-ID: <3ccc56d1-a1f9-094d-74a0-f54b9d0221cc@gmail.com>

On 13/10/2016 8:35 AM, Thomas Adams wrote:
> All,
>
> Very respectfully, there are no R packages that can do what Marna desires.

I would guess that's not literally true, in that there are several 
graphics packages that are very flexible.   You could well be right that 
there are none that are designed specifically for this purpose, so she's 
probably going to have to do some work to get what she wants.

> His/Her data, undoubtably, comes from a 1-D hydraulic model simulation 
> -- where output is generated at channel cross-sections -- representing 
> the sloping water surface elevation of the centerline of flow in a 
> stream or river. With mapping software for such problems, the 
> assumption is made that the water surface intersects the topography 
> (within or beyond the stream channel) perpendicular to the direction 
> of flow. Hydrodynamically, this is generally not correct, but it's a 
> reasonable approximation. To do this, typically, the topography -- in 
> the from of a raster digital elevation model (DEM) -- is converted to 
> a triangular irregular network (TIN) to facilitate the creation of a 
> smoother line of intersection between the water surface and 
> topography. Because, the water surface slopes in a downstream 
> direction, contour lines are crossed. Hydraulic modeling software 
> usually is accompanied by this mapping capability, such as with 
> HEC-RAS with RAS-Mapper, developed by the US Army Corps of Engineers, 
> or with HEC-GeoRAS, which requires ESRI ARC GIS; but, there is also a 
> QGIS plugin module that can do this, I believe. These software 
> packages do facilitate representing the flow in 3D.

Do you know any sample figures online that would show the type of graph 
that is usually used here?

Duncan Murdoch
>
> Tom
>
>
> On Wed, Oct 12, 2016 at 6:12 PM, David Winsemius 
> <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
>
>
>     > On Oct 12, 2016, at 4:28 AM, Duncan Murdoch
>     <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>     >
>     > On 12/10/2016 4:49 AM, Marna Wagley wrote:
>     >> Hi R Users,
>     >> Is it possible to visualize river flow in 3D (latitude,
>     longitude with
>     >> respect to depth)?
>     >> The example of my data looks like. Any suggestions?
>     >>
>     >>> dat1
>     >>    long lat depth flow
>     >> 1 1015.9 857  1.00 1.50
>     >> 2 1015.9 857  1.25 1.23
>     >> 3 1015.9 857  0.50 2.00
>     >> 4 1015.9 858  0.10 1.95
>     >> 5 1015.9 858  0.20 1.50
>     >> 6 1025.0 858  0.30 1.20
>     >> 7 1025.0 858  0.40 0.50
>     >> 8 1025.0 858  0.35 0.70
>     >> 9 1025.0 858  0.24 1.20
>     >>
>     >> Thanks for your help.
>     >
>     > It may be, but it's hard to give a nice looking graphic of that
>     small dataset.  You could try the rgl package and use plot3d to
>     show spheres with radius depending on the flow rate, for example
>     >
>     > plot3d(cbind(long, lat, depth), type="s", col="blue", radius=flow/5)
>
>     A complementary option is to install the plot3D package which I
>     see also has a plot3Drgl "co-package". The advantage to this
>     option is the association with beautiful modeling packages that
>     Karline Soetaert, Peter M. J. Herman, and Thomas Petzoldt have
>     been offering to ecologists for the last decade. (Packages:
>     deSolve, marelac, seacarb, AquaEnv) A lot of her work has been on
>     flows within systems.
>
>     I usually think of "flows" in rivers as being vector fields in an
>     incompressible fluid (water) with 6 components per point, but you
>     can also think of them as being scalar state variables. So I
>     suppose you could be modeling something other than mass flows.
>     (See Package::ReacTran for the R portal to that mathematical world.)
>
>     Best;
>     David Winsemius
>
>
>     >
>     > Duncan Murdoch
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     David Winsemius
>     Alameda, CA, USA
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>


From Karline.Soetaert at nioz.nl  Thu Oct 13 15:29:38 2016
From: Karline.Soetaert at nioz.nl (Karline Soetaert)
Date: Thu, 13 Oct 2016 13:29:38 +0000
Subject: [R] can we visualize water flows with 3d in R?
In-Reply-To: <3ccc56d1-a1f9-094d-74a0-f54b9d0221cc@gmail.com>
References: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
	<b9652b19-25ba-ec08-c124-b77d4d34f70e@gmail.com>
	<CE61A0C6-EE67-4CF2-AF70-69F0386841B2@comcast.net>
	<CAGxgkWhYa1wftNweixM=vTcxR3JeETX07E6snf=geb4wpeK9NQ@mail.gmail.com>
	<3ccc56d1-a1f9-094d-74a0-f54b9d0221cc@gmail.com>
Message-ID: <db85b545838c42bc87315dea81786e0b@livia.nioz.nl>

... and maybe she can find some inspiration at this website:
http://www.rforscience.com/rpackages/visualisation/oceanview/


Karline

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: donderdag 13 oktober 2016 15:20
To: Thomas Adams <tea3rd at gmail.com>; David Winsemius <dwinsemius at comcast.net>
Cc: r-help mailing list <r-help at r-project.org>; Karline Soetaert <Karline.Soetaert at nioz.nl>
Subject: Re: [R] can we visualize water flows with 3d in R?

On 13/10/2016 8:35 AM, Thomas Adams wrote:
> All,
>
> Very respectfully, there are no R packages that can do what Marna desires.

I would guess that's not literally true, in that there are several 
graphics packages that are very flexible.   You could well be right that 
there are none that are designed specifically for this purpose, so she's probably going to have to do some work to get what she wants.

> His/Her data, undoubtably, comes from a 1-D hydraulic model simulation
> -- where output is generated at channel cross-sections -- representing 
> the sloping water surface elevation of the centerline of flow in a 
> stream or river. With mapping software for such problems, the 
> assumption is made that the water surface intersects the topography 
> (within or beyond the stream channel) perpendicular to the direction 
> of flow. Hydrodynamically, this is generally not correct, but it's a 
> reasonable approximation. To do this, typically, the topography -- in 
> the from of a raster digital elevation model (DEM) -- is converted to 
> a triangular irregular network (TIN) to facilitate the creation of a 
> smoother line of intersection between the water surface and 
> topography. Because, the water surface slopes in a downstream 
> direction, contour lines are crossed. Hydraulic modeling software 
> usually is accompanied by this mapping capability, such as with 
> HEC-RAS with RAS-Mapper, developed by the US Army Corps of Engineers, 
> or with HEC-GeoRAS, which requires ESRI ARC GIS; but, there is also a 
> QGIS plugin module that can do this, I believe. These software 
> packages do facilitate representing the flow in 3D.

Do you know any sample figures online that would show the type of graph that is usually used here?

Duncan Murdoch
>
> Tom
>
>
> On Wed, Oct 12, 2016 at 6:12 PM, David Winsemius 
> <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
>
>
>     > On Oct 12, 2016, at 4:28 AM, Duncan Murdoch
>     <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>     >
>     > On 12/10/2016 4:49 AM, Marna Wagley wrote:
>     >> Hi R Users,
>     >> Is it possible to visualize river flow in 3D (latitude,
>     longitude with
>     >> respect to depth)?
>     >> The example of my data looks like. Any suggestions?
>     >>
>     >>> dat1
>     >>    long lat depth flow
>     >> 1 1015.9 857  1.00 1.50
>     >> 2 1015.9 857  1.25 1.23
>     >> 3 1015.9 857  0.50 2.00
>     >> 4 1015.9 858  0.10 1.95
>     >> 5 1015.9 858  0.20 1.50
>     >> 6 1025.0 858  0.30 1.20
>     >> 7 1025.0 858  0.40 0.50
>     >> 8 1025.0 858  0.35 0.70
>     >> 9 1025.0 858  0.24 1.20
>     >>
>     >> Thanks for your help.
>     >
>     > It may be, but it's hard to give a nice looking graphic of that
>     small dataset.  You could try the rgl package and use plot3d to
>     show spheres with radius depending on the flow rate, for example
>     >
>     > plot3d(cbind(long, lat, depth), type="s", col="blue", 
> radius=flow/5)
>
>     A complementary option is to install the plot3D package which I
>     see also has a plot3Drgl "co-package". The advantage to this
>     option is the association with beautiful modeling packages that
>     Karline Soetaert, Peter M. J. Herman, and Thomas Petzoldt have
>     been offering to ecologists for the last decade. (Packages:
>     deSolve, marelac, seacarb, AquaEnv) A lot of her work has been on
>     flows within systems.
>
>     I usually think of "flows" in rivers as being vector fields in an
>     incompressible fluid (water) with 6 components per point, but you
>     can also think of them as being scalar state variables. So I
>     suppose you could be modeling something other than mass flows.
>     (See Package::ReacTran for the R portal to that mathematical 
> world.)
>
>     Best;
>     David Winsemius
>
>
>     >
>     > Duncan Murdoch
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     David Winsemius
>     Alameda, CA, USA
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>


From rni.boh at gmail.com  Thu Oct 13 16:26:00 2016
From: rni.boh at gmail.com (Bob O'Hara)
Date: Thu, 13 Oct 2016 16:26:00 +0200
Subject: [R] sort()ing strings
In-Reply-To: <22527.26957.281028.757452@stat.math.ethz.ch>
References: <CAN-Z0xWC4jcwtsJ4CVCZ4mv0CLAs_q3EFLudAaMKtkqaJOgRRw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50414D1@SRVEXCHMBX.precheza.cz>
	<CAN-Z0xVVpEhctTZPh_hBPpUgr6EFcEyNKLz8GpBXme_fu2iHJQ@mail.gmail.com>
	<22527.26957.281028.757452@stat.math.ethz.ch>
Message-ID: <CAN-Z0xWw9=jr1wdGE7AQCs2dTmE2C8oo=NBO8YJvEkrpMA19bA@mail.gmail.com>

Thanks - strangely capabilities("ICU") is FALSE (I'm using ubuntu
16.04, and icu-devtools is installed). So I guess I'll conclude that
there's something odd, but I don't want to delve into these issues (a
new locale & new computer for me in a couple of months).

Bob

On 13 October 2016 at 13:00, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>>>>>> Bob O'Hara <rni.boh at gmail.com>
>>>>>>     on Thu, 13 Oct 2016 11:55:04 +0200 writes:
>
>     > Yes, thanks. That seems to be it:
>     > thing <- c("M1", "M2", "M.1", "M.2")
>     >> sort(thing)
>     > [1] "M1" "M.1" "M2" "M.2"
>
> which I do find strange, indeed, given your sessionInfo which
> contains
>         LC_COLLATE=en_US.UTF-8
>
>     > The only documentation I can find is from ?Comparison:
>     > "Collation of non-letters (spaces, punctuation signs,
>     > hyphens, fractions and so on) is even more problematic."
>
> Well.  That help page contains more information further down,
> notably about ICU.  If
>
>      capabilities("ICU")
>
> gives TRUE for you (I assume it will as you use a modern ubuntu version),
> you can tweak the behavior to be more "reasonable" than above
>
> via R functions icu(Set|Get)Collate()
>
> BTW, I say "strange" above, because for me - also on modern
> Linux (Fedora 24), I "always" see
>
>> sort( c("M1", "M2", "M.1", "M.2") )
> [1] "M.1" "M.2" "M1"  "M2"
>
>
>> Sys.setlocale("LC_COLLATE", "de_CH.UTF-8")
> [1] "de_CH.UTF-8"
>> sort( c("M1", "M2", "M.1", "M.2") )
> [1] "M.1" "M.2" "M1"  "M2"
>> Sys.setlocale("LC_COLLATE", "en_US.UTF-8")
> [1] "en_US.UTF-8"
>> sort( c("M1", "M2", "M.1", "M.2") )
> [1] "M.1" "M.2" "M1"  "M2"
>
>> Sys.setlocale("LC_COLLATE", "C") # <--> ASCII ("the ole' time default)
> [1] "C"
>> sort( c("M1", "M2", "M.1", "M.2") )
> [1] "M.1" "M.2" "M1"  "M2"
>>
>
> I do use a newer R version (3.3.1 patched)
> but would not have expected that to matter here.
>
> Martin
>
>
>     > Indeed.
>
>     > Bob
>
>     > On 13 October 2016 at 11:26, PIKAL Petr
>     > <petr.pikal at precheza.cz> wrote:
>     >> Hi
>     >>
>     >> Just a wild guess. Dot is ignored and the output is
>     >> alphabetically sorted.
>     >>
>     >> You could try sort it yourself by
>     >>
>     >> sort(ls())
>     >>
>     >> Cheers Petr
>     >>
>     >>> -----Original Message----- From: R-help
>     >>> [mailto:r-help-bounces at r-project.org] On Behalf Of Bob
>     >>> O'Hara Sent: Thursday, October 13, 2016 10:29 AM To:
>     >>> r-help <r-help at r-project.org> Subject: [R] (no subject)
>     >>>
>     >>> I've just come across an odd problem with sorting in
>     >>> ls(): it doesn't seem to order the object names
>     >>> correctly. If I do the following, the order isn't what I
>     >>> expect:
>     >>>
>     >>> > ls(sorted=TRUE) [1] "AridData" "AridDataToBUGS"
>     >>> "Arid.df" "Arid.hpd" "AridPrecip.sd" "Break.df" [7]
>     >>> "Break.hpd" "Cols" "Data" "DataFrames" "DataToBUGS"
>     >>> "DataToBUGS.nonlog" [13] "FitBRugs" "Fixed.df"
>     >>> "Fixed.hpd" "FormatData" "GetCol" "GetHPD" [19]
>     >>> "GetMCMC" "GetRow" "HPDIs" "Int.alpha12" "Int.alpha21"
>     >>> "ModisData" [25] "ModisDataToBUGS" "Modis.df"
>     >>> "ModisFixed.df" "ModisFixed.hpd" "Modis.hpd"
>     >>> "ModisPrecip.sd" [31] "ModisShrink.df" "ModisShrink.hpd"
>     >>> "ModisYears" "OrigData" "OrigDataToBUGS" "Orig.df" [37]
>     >>> "Orig.hpd" "OrigPrecip.sd" "OrigYears" "PlotChecks"
>     >>> "PlotEff" "plothpd" [43] "ProvinceNames" "ResNames"
>     >>> "ResNamesOrder" "Shrink.df" "Shrink.hpd" "SimInits"
>     >>>
>     >>> Specifically, the Modis* objects are sorted like this:
>     >>>
>     >>> > ls(sorted=TRUE)[26:30] [1] "Modis.df" "ModisFixed.df"
>     >>> "ModisFixed.hpd" "Modis.hpd" "ModisPrecip.sd"
>     >>>
>     >>> With Modis.* coming both before and after ModisF*. I
>     >>> can't see why there would be any odd problems with
>     >>> character sets changing (this was all done on a single
>     >>> computer with no weird locale switching), and the
>     >>> objects are all created within a single R session:
>     >>>
>     >>> > sessionInfo() R version 3.2.5 (2016-04-14) Platform:
>     >>> x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu
>     >>> 16.04.1 LTS
>     >>>
>     >>> locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
>     >>> LC_TIME=en_GB.UTF-8 LC_COLLATE=en_US.UTF-8 [5]
>     >>> LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_US.UTF-8
>     >>> LC_PAPER=en_GB.UTF-8 LC_NAME=C [9] LC_ADDRESS=C
>     >>> LC_TELEPHONE=C LC_MEASUREMENT=en_GB.UTF-8
>     >>> LC_IDENTIFICATION=C
>     >>>
>     >>> attached base packages: [1] stats graphics grDevices
>     >>> utils datasets methods base
>     >>>
>     >>> other attached packages: [1] MCMCglmm_2.22.1 ape_3.5
>     >>> Matrix_1.2-7.1 RColorBrewer_1.1-2 plyr_1.8.4 coda_0.18-1
>     >>>
>     >>> loaded via a namespace (and not attached): [1]
>     >>> cubature_1.1-2 corpcor_1.6.8 tools_3.2.5 Rcpp_0.12.7
>     >>> nlme_3.1-128 grid_3.2.5 knitr_1.14 [8] tensorA_0.36
>     >>> lattice_0.20-34
>     >>>
>     >>> Can anyone explain what's going on?
>     >>>
>     >>> Bob
>     >>> --
>     >>> Bob O'Hara
>     >>>
>     >>> Biodiversity and Climate Research Centre
>     >>> Senckenberganlage 25 D-60325 Frankfurt am Main, Germany
>     >>>
>     >>> Tel: +49 69 798 40226 Mobile: +49 1515 888 5440 WWW:
>     >>> http://www.bik-f.de/root/index.php?page_id=219 Blog:
>     >>> http://occamstypewriter.org/boboh/ Journal of Negative
>     >>> Results - EEB: www.jnr-eeb.org



-- 
Bob O'Hara

Biodiversity and Climate Research Centre
Senckenberganlage 25
D-60325 Frankfurt am Main,
Germany

Tel: +49 69 798 40226
Mobile: +49 1515 888 5440
WWW:   http://www.bik-f.de/root/index.php?page_id=219
Blog: http://occamstypewriter.org/boboh/
Journal of Negative Results - EEB: www.jnr-eeb.org


From pai1981 at gmail.com  Thu Oct 13 16:53:45 2016
From: pai1981 at gmail.com (Debasish Pai Mazumder)
Date: Thu, 13 Oct 2016 08:53:45 -0600
Subject: [R] download multiple files in one file
Message-ID: <CAM9mbiDh+kFtAD294t7M2pdwGNQPYi_CJnA4AMXUt4ym-mQsbA@mail.gmail.com>

Hi All,
I have downloaded single file from the web using following scripts

gribfile<-"
http://nomads.ncdc.noaa.gov/thredds/ncss/grid/modeldata/cfsv2_forecast_ts_9mon/2011/201104/20110401/2011040100/tmax.01.2011040100.daily.grb2?north=47.0126&west=-114.841&east=-112.641&south=44.8534&time_start=2011-06-01&time_end=2011-06-31&accept=netcdf&var=Maximum_temperature
"

download.file(gribfile,basename('file.nc'),mode = "wb")
File <- nc_open('file.nc')
str(File)
lat = ncvar_get(File, "lat") # coordinate variable
temp =ncvar_get(File, "Maximum_temperature")

Now I have multiple files and they are

..../2011/201104/20110401/2011040100/tmax.01.2011040100.daily.grb2
..../2011/201104/20110401/2011040106/tmax.01.2011040106.daily.grb2
..../2011/201104/20110401/2011040112/tmax.01.2011040112.daily.grb2
..../2011/201104/20110401/2011040118/tmax.01.2011040118.daily.grb2

Is there any way to read them together and store them in file.nc

sincerely
-Deb

	[[alternative HTML version deleted]]


From tea3rd at gmail.com  Thu Oct 13 17:14:12 2016
From: tea3rd at gmail.com (Thomas Adams)
Date: Thu, 13 Oct 2016 11:14:12 -0400
Subject: [R] can we visualize water flows with 3d in R?
In-Reply-To: <3ccc56d1-a1f9-094d-74a0-f54b9d0221cc@gmail.com>
References: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
	<b9652b19-25ba-ec08-c124-b77d4d34f70e@gmail.com>
	<CE61A0C6-EE67-4CF2-AF70-69F0386841B2@comcast.net>
	<CAGxgkWhYa1wftNweixM=vTcxR3JeETX07E6snf=geb4wpeK9NQ@mail.gmail.com>
	<3ccc56d1-a1f9-094d-74a0-f54b9d0221cc@gmail.com>
Message-ID: <CAGxgkWhv1f5MemWcu9xbg_ML7bkeZY0qYKKoy=fqge9Ek=jzFg@mail.gmail.com>

Duncan,

Oh, to be sure, with a fair amount of work, you're probably correct that
one could mash up something. Here are some examples:

http://www.illinoisfloods.org/documents/2013_IAFSM_Conference/Conference_Presentations/5C-1_HEC-GeoRAS_Part1.pdf
<--- lots of graphics

http://rivergis.com/

also...
http://www2.egr.uh.edu/~aleon3/courses/Transient_flows/Tutorials/Geo_RAS/georastutorial.pdf
-- pages 35->
https://www.crwr.utexas.edu/reports/pdf/1999/rpt99-1.pdf -- pages 70->
(figures 4-17, 4-18), p. 147

Best,
Tom

On Thu, Oct 13, 2016 at 9:20 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 13/10/2016 8:35 AM, Thomas Adams wrote:
>
>> All,
>>
>> Very respectfully, there are no R packages that can do what Marna desires.
>>
>
> I would guess that's not literally true, in that there are several
> graphics packages that are very flexible.   You could well be right that
> there are none that are designed specifically for this purpose, so she's
> probably going to have to do some work to get what she wants.
>
> His/Her data, undoubtably, comes from a 1-D hydraulic model simulation --
>> where output is generated at channel cross-sections -- representing the
>> sloping water surface elevation of the centerline of flow in a stream or
>> river. With mapping software for such problems, the assumption is made that
>> the water surface intersects the topography (within or beyond the stream
>> channel) perpendicular to the direction of flow. Hydrodynamically, this is
>> generally not correct, but it's a reasonable approximation. To do this,
>> typically, the topography -- in the from of a raster digital elevation
>> model (DEM) -- is converted to a triangular irregular network (TIN) to
>> facilitate the creation of a smoother line of intersection between the
>> water surface and topography. Because, the water surface slopes in a
>> downstream direction, contour lines are crossed. Hydraulic modeling
>> software usually is accompanied by this mapping capability, such as with
>> HEC-RAS with RAS-Mapper, developed by the US Army Corps of Engineers, or
>> with HEC-GeoRAS, which requires ESRI ARC GIS; but, there is also a QGIS
>> plugin module that can do this, I believe. These software packages do
>> facilitate representing the flow in 3D.
>>
>
> Do you know any sample figures online that would show the type of graph
> that is usually used here?
>
> Duncan Murdoch
>
>>
>> Tom
>>
>>
>> On Wed, Oct 12, 2016 at 6:12 PM, David Winsemius <dwinsemius at comcast.net
>> <mailto:dwinsemius at comcast.net>> wrote:
>>
>>
>>     > On Oct 12, 2016, at 4:28 AM, Duncan Murdoch
>>     <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>>     >
>>     > On 12/10/2016 4:49 AM, Marna Wagley wrote:
>>     >> Hi R Users,
>>     >> Is it possible to visualize river flow in 3D (latitude,
>>     longitude with
>>     >> respect to depth)?
>>     >> The example of my data looks like. Any suggestions?
>>     >>
>>     >>> dat1
>>     >>    long lat depth flow
>>     >> 1 1015.9 857  1.00 1.50
>>     >> 2 1015.9 857  1.25 1.23
>>     >> 3 1015.9 857  0.50 2.00
>>     >> 4 1015.9 858  0.10 1.95
>>     >> 5 1015.9 858  0.20 1.50
>>     >> 6 1025.0 858  0.30 1.20
>>     >> 7 1025.0 858  0.40 0.50
>>     >> 8 1025.0 858  0.35 0.70
>>     >> 9 1025.0 858  0.24 1.20
>>     >>
>>     >> Thanks for your help.
>>     >
>>     > It may be, but it's hard to give a nice looking graphic of that
>>     small dataset.  You could try the rgl package and use plot3d to
>>     show spheres with radius depending on the flow rate, for example
>>     >
>>     > plot3d(cbind(long, lat, depth), type="s", col="blue", radius=flow/5)
>>
>>     A complementary option is to install the plot3D package which I
>>     see also has a plot3Drgl "co-package". The advantage to this
>>     option is the association with beautiful modeling packages that
>>     Karline Soetaert, Peter M. J. Herman, and Thomas Petzoldt have
>>     been offering to ecologists for the last decade. (Packages:
>>     deSolve, marelac, seacarb, AquaEnv) A lot of her work has been on
>>     flows within systems.
>>
>>     I usually think of "flows" in rivers as being vector fields in an
>>     incompressible fluid (water) with 6 components per point, but you
>>     can also think of them as being scalar state variables. So I
>>     suppose you could be modeling something other than mass flows.
>>     (See Package::ReacTran for the R portal to that mathematical world.)
>>
>>     Best;
>>     David Winsemius
>>
>>
>>     >
>>     > Duncan Murdoch
>>     >
>>     > ______________________________________________
>>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>     -- To UNSUBSCRIBE and more, see
>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>     > PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     <http://www.R-project.org/posting-guide.html>
>>     > and provide commented, minimal, self-contained, reproducible code.
>>
>>     David Winsemius
>>     Alameda, CA, USA
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     <http://www.R-project.org/posting-guide.html>
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From aanchalsharma833 at gmail.com  Thu Oct 13 18:58:31 2016
From: aanchalsharma833 at gmail.com (Aanchal Sharma)
Date: Thu, 13 Oct 2016 12:58:31 -0400
Subject: [R] ERROR : unable to start device PNG on server
Message-ID: <CAFp0Li2xNa2W1Yor4sRpmA7PHYJLSeLC6K5DDhLUsFrj5vmQcw@mail.gmail.com>

Hi

I realize that this question has been asked earlier also, but my problem is
slightly different.
I am running a rscript which runs for multiple datasets in loop and
generates png for every file in the loop. When I run this only local
machine (mac) it runs fine, just that that it takes very long to finish. I
am running it on server, it runs fine till some files but then starts
throwing the following error:

ERROR : unable to start device PNG

before firing the rscript when I check the status for capabilities it gives
me following:

> capabilities()
       jpeg         png        tiff       tcltk         X11        aqua
      FALSE        TRUE       FALSE        TRUE        TRUE       FALSE
   http/ftp     sockets      libxml        fifo      cledit       iconv
       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE
        NLS     profmem       cairo         ICU long.double     libcurl
       TRUE       FALSE       FALSE       FALSE        TRUE        TRUE

When I run it and it terminates giving above error, then the capabilities()
gives following:


> capabilities()
       jpeg         png        tiff       tcltk         X11        aqua
      FALSE       FALSE       FALSE        TRUE       FALSE       FALSE
   http/ftp     sockets      libxml        fifo      cledit       iconv
       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE
        NLS     profmem       cairo         ICU long.double     libcurl
       TRUE       FALSE       FALSE       FALSE        TRUE        TRUE

Note that png and X11 are turned FALSE once it terminates.

Why does this happen automatically? How can I rescue this?
For information, I am using R version 3.3.1 (2016-06-21).

-- 
Anchal Sharma, PhD
Postdoctoral Fellow
195, Little Albany street,
Cancer Institute of New Jersey
Rutgers University
NJ-08901

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Thu Oct 13 19:21:36 2016
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 13 Oct 2016 11:21:36 -0600
Subject: [R] Maybe OT: Forking in R scripts?
In-Reply-To: <cb0b5b29-0baf-ef83-9071-93cea9988917@pp.inet.fi>
References: <cb0b5b29-0baf-ef83-9071-93cea9988917@pp.inet.fi>
Message-ID: <CAFEqCdxEEgYeuyt7dL9WXHgeL8Lwk=U=SrEZCJj0eOks5QQhHw@mail.gmail.com>

I don't know if the parallel approach would work or not, but a
possibly simpler approach would be to use the tclTaskSchedule function
from the tcltk package.  You could use this to schedule your update
code to run on a regular basis, then you have access to the command
line between times that it runs.

You just need to be careful, if you are accessing a data object at the
same time that the update code runs on that same object, then there
could be problems.



On Thu, Oct 13, 2016 at 12:02 AM, K. Elo <maillists at pp.inet.fi> wrote:
> Dear all,
>
> I am currently working a research project on social media interaction. As a
> part of this project, mostly for teaching purposes, I should develop a
> R-based approach for real-time visualisation of streamed data (from
> Twitter).
>
> My idea is simple (and working :) ): A Python-script stream Twitter for
> selected keywords/hashtags/users and redirects the output as JSON in a text
> file. My R-script reads the new entries from this text file every 5-10
> minutes, process the input and updates network and other graphical
> presentations.
>
> Thus far everything is working fine. However, I would like to have the
> possibility to work with my data when my script is sleeping. I just wonder
> whether a simple 'mcparallel({ Sys.sleep(300); TRUE})' (from 'parallel')
> would solve my problem? Or is there something I have to take into account
> when using 'parallel'?
>
> My R environment runs on Linux, so forking should work...
>
> Best regrads and thanks in advance,
> Kimmo
>
> --
> ?bo Akademi University, Finland
> Dep. for German studies
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From rtreacy87 at gmail.com  Thu Oct 13 18:48:42 2016
From: rtreacy87 at gmail.com (Ryan Treacy)
Date: Thu, 13 Oct 2016 10:48:42 -0600
Subject: [R] Help reproducing this boxplot
Message-ID: <CAO6-2iOUsr4AqOg4NdQoWqnhnwRFK5XGM68nd7jkw+KSUjKkwQ@mail.gmail.com>

I am trying to reproduce the style of boxplot pictured in the attached
image.  The code below is close but I cannot get the control values the
correct color.

library(ggplot2)

box.print <- function(C1M,C1, D2, QCDC2, QCSDT4, num){
  NAME <- names(D2[num])
  adjsdt4 <- C1M[,num]
  sdt4 <- C1[,num]
  disco2 <- D2[,num]
  qcdc <- QCDC2[,num]
  qcsdt4 <- QCSDT4[,num]
  adj <- data.frame(Intensity=c(adjsdt4,qcsdt4),
                    Study= rep("adjSDT4",length(adjsdt4)+length(qcsdt4)),
                    QC=
c(rep("cases",length(adjsdt4)),rep("QC",length(qcsdt4)))

  )
  nadj <- data.frame(Intensity=c(sdt4,qcsdt4),
                     Study= rep("SDT4",length(sdt4)+length(qcsdt4)),
                     QC=
c(rep("cases",length(sdt4)),rep("QC",length(qcsdt4)))

  )
  disco <- data.frame(Intensity=c(disco2,qcdc),
                      Study= rep("DISCO2",length(disco2)+length(qcdc)),
                      QC=
c(rep("cases",length(disco2)),rep("QC",length(qcdc)))

  )
  full <- rbind(adj,nadj,disco)

  g1 <- ggplot(full, aes(x=Study, y=Intensity))+geom_boxplot(outlier.shape
= NA)+ggtitle(NAME)+
    geom_jitter(alpha=0.5, aes(color=Study,label=Study,shape=QC),position =
position_jitter(width = .8),size=2)
  g1 = g1+theme(panel.grid.major= element_blank(),
                panel.grid.minor= element_blank(),
                panel.background= element_blank(),
                panel.border= element_rect(colour="black",fill=NA),
                legend.position="none")
  g1= g1+scale_shape_manual(values=c(19,1))+scale_fill_discrete(guide=FALSE)
  print(g1)
}

A <- data.frame(1.557, 1.663, 1.637, 1.740, 1.597, 1.473, 1.399 ,1.403,
1.210, 1.375, 1.387, 1.515, 1.456,
  1.121, 1.211, 1.165, 1.428, 1.749, 1.231, 1.209, 1.272, 1.580, 1.254,
1.099, 1.151, 1.239,
  1.753, 1.415, 1.653, 1.555, 1.748, 1.951, 1.734, 1.519, 1.397, 1.391,
1.825, 1.722, 1.715,
  1.777, 2.014, 1.676, 1.803, 1.332, 1.560, 1.605, 1.564, 1.588, 1.583,
1.701, 1.297, 1.583,
  1.778, 1.343, 1.427, 1.472, 1.663, 1.472, 1.726, 1.327, 1.466, 1.890,
1.601, 1.474, 1.671,
  1.492, 1.277, 1.524, 1.394, 1.477, 1.525, 1.502, 1.371, 1.479, 0.966,
1.239, 1.415, 1.316,
  1.336, 1.244, 2.040, 1.823, 1.853, 1.712, 1.805, 1.593, 1.630, 1.578,
1.648, 1.581, 1.661,
  1.731, 1.360, 1.572, 1.788, 1.668, 1.663, 1.519)
A <- t(A)
B <- A*.3
C <- A*2
QA <- data.frame(1.951, 1.734, 1.519, 1.397, 1.391, 1.825)
QA <- t(QA)
QC <- QA*1.5

box.print(A,B,C,QA,QC,1)
-------------- next part --------------
A non-text attachment was scrubbed...
Name: goal.png
Type: image/png
Size: 40893 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161013/0eb5abd9/attachment.png>

From baronahugo31 at gmail.com  Thu Oct 13 18:42:58 2016
From: baronahugo31 at gmail.com (hugo)
Date: Thu, 13 Oct 2016 11:42:58 -0500
Subject: [R] Function Distributions does not exist in package stats
Message-ID: <33040457-7b81-ab55-9eb6-a46427c2d4bd@gmail.com>

I was looking function Distribution into stats package: it does not exist!

I am working with:

version
                _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          3
minor          3.1
year           2016
month          06
day            21
svn rev        70800
language       R
version.string R version 3.3.1 (2016-06-21)
nickname       Bug in Your Hair

Sincerely


From ruipbarradas at sapo.pt  Thu Oct 13 20:59:41 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 13 Oct 2016 19:59:41 +0100
Subject: [R] Function Distributions does not exist in package stats
In-Reply-To: <33040457-7b81-ab55-9eb6-a46427c2d4bd@gmail.com>
References: <33040457-7b81-ab55-9eb6-a46427c2d4bd@gmail.com>
Message-ID: <57FFD99D.9050803@sapo.pt>

Hello,

'Distribution' is not the name of a function in package stats.
At an R prompt type ?Distributions. In that help page you will read

"Distributions {stats}	R Documentation
Distributions in the stats package
Description

Density, cumulative distribution function, quantile function and random 
variate generation for many standard probability distributions are 
available in the stats package. "

followed by the available distributions. There are also many other 
distributions available in the many packages on CRAN.

Hope this helps,

Rui Barradas

Em 13-10-2016 17:42, hugo escreveu:
> I was looking function Distribution into stats package: it does not exist!
>
> I am working with:
>
> version
>                 _
> platform       x86_64-pc-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          3
> minor          3.1
> year           2016
> month          06
> day            21
> svn rev        70800
> language       R
> version.string R version 3.3.1 (2016-06-21)
> nickname       Bug in Your Hair
>
> Sincerely
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Oct 13 23:10:46 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 13 Oct 2016 17:10:46 -0400
Subject: [R] can we visualize water flows with 3d in R?
In-Reply-To: <CAGxgkWhv1f5MemWcu9xbg_ML7bkeZY0qYKKoy=fqge9Ek=jzFg@mail.gmail.com>
References: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
	<b9652b19-25ba-ec08-c124-b77d4d34f70e@gmail.com>
	<CE61A0C6-EE67-4CF2-AF70-69F0386841B2@comcast.net>
	<CAGxgkWhYa1wftNweixM=vTcxR3JeETX07E6snf=geb4wpeK9NQ@mail.gmail.com>
	<3ccc56d1-a1f9-094d-74a0-f54b9d0221cc@gmail.com>
	<CAGxgkWhv1f5MemWcu9xbg_ML7bkeZY0qYKKoy=fqge9Ek=jzFg@mail.gmail.com>
Message-ID: <82a1060f-7349-c502-3250-0e6d68968ffb@gmail.com>

On 13/10/2016 11:14 AM, Thomas Adams wrote:
> Duncan,
>
> Oh, to be sure, with a fair amount of work, you're probably correct that
> one could mash up something. Here are some examples:
>
> http://www.illinoisfloods.org/documents/2013_IAFSM_Conference/Conference_Presentations/5C-1_HEC-GeoRAS_Part1.pdf
> <--- lots of graphics
>
> http://rivergis.com/
>
> also...
> http://www2.egr.uh.edu/~aleon3/courses/Transient_flows/Tutorials/Geo_RAS/georastutorial.pdf
> -- pages 35->
> https://www.crwr.utexas.edu/reports/pdf/1999/rpt99-1.pdf -- pages 70->
> (figures 4-17, 4-18), p. 147

Thanks.  I guess it's up to Marna to say whether any of those figures 
are like what she wants to produce from her data.

Duncan Murdoch

>
> Best,
> Tom
>
> On Thu, Oct 13, 2016 at 9:20 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 13/10/2016 8:35 AM, Thomas Adams wrote:
>
>         All,
>
>         Very respectfully, there are no R packages that can do what
>         Marna desires.
>
>
>     I would guess that's not literally true, in that there are several
>     graphics packages that are very flexible.   You could well be right
>     that there are none that are designed specifically for this purpose,
>     so she's probably going to have to do some work to get what she wants.
>
>         His/Her data, undoubtably, comes from a 1-D hydraulic model
>         simulation -- where output is generated at channel
>         cross-sections -- representing the sloping water surface
>         elevation of the centerline of flow in a stream or river. With
>         mapping software for such problems, the assumption is made that
>         the water surface intersects the topography (within or beyond
>         the stream channel) perpendicular to the direction of flow.
>         Hydrodynamically, this is generally not correct, but it's a
>         reasonable approximation. To do this, typically, the topography
>         -- in the from of a raster digital elevation model (DEM) -- is
>         converted to a triangular irregular network (TIN) to facilitate
>         the creation of a smoother line of intersection between the
>         water surface and topography. Because, the water surface slopes
>         in a downstream direction, contour lines are crossed. Hydraulic
>         modeling software usually is accompanied by this mapping
>         capability, such as with HEC-RAS with RAS-Mapper, developed by
>         the US Army Corps of Engineers, or with HEC-GeoRAS, which
>         requires ESRI ARC GIS; but, there is also a QGIS plugin module
>         that can do this, I believe. These software packages do
>         facilitate representing the flow in 3D.
>
>
>     Do you know any sample figures online that would show the type of
>     graph that is usually used here?
>
>     Duncan Murdoch
>
>
>         Tom
>
>
>         On Wed, Oct 12, 2016 at 6:12 PM, David Winsemius
>         <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>
>         <mailto:dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>>>
>         wrote:
>
>
>             > On Oct 12, 2016, at 4:28 AM, Duncan Murdoch
>             <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>         <mailto:murdoch.duncan at gmail.com
>         <mailto:murdoch.duncan at gmail.com>>> wrote:
>             >
>             > On 12/10/2016 4:49 AM, Marna Wagley wrote:
>             >> Hi R Users,
>             >> Is it possible to visualize river flow in 3D (latitude,
>             longitude with
>             >> respect to depth)?
>             >> The example of my data looks like. Any suggestions?
>             >>
>             >>> dat1
>             >>    long lat depth flow
>             >> 1 1015.9 857  1.00 1.50
>             >> 2 1015.9 857  1.25 1.23
>             >> 3 1015.9 857  0.50 2.00
>             >> 4 1015.9 858  0.10 1.95
>             >> 5 1015.9 858  0.20 1.50
>             >> 6 1025.0 858  0.30 1.20
>             >> 7 1025.0 858  0.40 0.50
>             >> 8 1025.0 858  0.35 0.70
>             >> 9 1025.0 858  0.24 1.20
>             >>
>             >> Thanks for your help.
>             >
>             > It may be, but it's hard to give a nice looking graphic of
>         that
>             small dataset.  You could try the rgl package and use plot3d to
>             show spheres with radius depending on the flow rate, for example
>             >
>             > plot3d(cbind(long, lat, depth), type="s", col="blue",
>         radius=flow/5)
>
>             A complementary option is to install the plot3D package which I
>             see also has a plot3Drgl "co-package". The advantage to this
>             option is the association with beautiful modeling packages that
>             Karline Soetaert, Peter M. J. Herman, and Thomas Petzoldt have
>             been offering to ecologists for the last decade. (Packages:
>             deSolve, marelac, seacarb, AquaEnv) A lot of her work has
>         been on
>             flows within systems.
>
>             I usually think of "flows" in rivers as being vector fields
>         in an
>             incompressible fluid (water) with 6 components per point,
>         but you
>             can also think of them as being scalar state variables. So I
>             suppose you could be modeling something other than mass flows.
>             (See Package::ReacTran for the R portal to that mathematical
>         world.)
>
>             Best;
>             David Winsemius
>
>
>             >
>             > Duncan Murdoch
>             >
>             > ______________________________________________
>             > R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>         mailing list
>             -- To UNSUBSCRIBE and more, see
>             > https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>             <https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>             > PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>             <http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>>
>             > and provide commented, minimal, self-contained,
>         reproducible code.
>
>             David Winsemius
>             Alameda, CA, USA
>
>             ______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>         mailing list --
>             To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>             <https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>             PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>             <http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>>
>             and provide commented, minimal, self-contained, reproducible
>         code.
>
>
>
>
>
>
>
>


From drjimlemon at gmail.com  Thu Oct 13 23:23:08 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 14 Oct 2016 08:23:08 +1100
Subject: [R] (no subject)
In-Reply-To: <CAN-Z0xVVpEhctTZPh_hBPpUgr6EFcEyNKLz8GpBXme_fu2iHJQ@mail.gmail.com>
References: <CAN-Z0xWC4jcwtsJ4CVCZ4mv0CLAs_q3EFLudAaMKtkqaJOgRRw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50414D1@SRVEXCHMBX.precheza.cz>
	<CAN-Z0xVVpEhctTZPh_hBPpUgr6EFcEyNKLz8GpBXme_fu2iHJQ@mail.gmail.com>
Message-ID: <CA+8X3fVGD8yVDu=nv7LPZ-B=33mriXRebpGKO=ArfhGeVoGORg@mail.gmail.com>

The crucial thing is probably:

"... they are translated to UTF-8 before comparison."

Although the first 127 characters seem to be identical to ASCII, in
which punctuation marks sorted before digits or letters, the encoding
to UTF-8 may make that impractical.

Jim


On Thu, Oct 13, 2016 at 8:55 PM, Bob O'Hara <rni.boh at gmail.com> wrote:
> Yes, thanks. That seems to be it:
>
> thing <- c("M1", "M2", "M.1", "M.2")
>> sort(thing)
> [1] "M1"  "M.1" "M2"  "M.2"
>
> The only documentation I can find is from ?Comparison:
> "Collation of non-letters (spaces, punctuation signs, hyphens,
> fractions and so on) is even more problematic."
>
> Indeed.
>
> Bob
>
> On 13 October 2016 at 11:26, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>> Hi
>>
>> Just a wild guess. Dot is ignored and the output is alphabetically sorted.
>>
>> You could try sort it yourself by
>>
>> sort(ls())
>>
>> Cheers
>> Petr
>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bob
>>> O'Hara
>>> Sent: Thursday, October 13, 2016 10:29 AM
>>> To: r-help <r-help at r-project.org>
>>> Subject: [R] (no subject)
>>>
>>> I've just come across an odd problem with sorting in ls(): it doesn't seem to
>>> order the object names correctly. If I do the following, the order isn't what I
>>> expect:
>>>
>>> > ls(sorted=TRUE)
>>>  [1] "AridData"          "AridDataToBUGS"    "Arid.df"
>>> "Arid.hpd"          "AridPrecip.sd"     "Break.df"
>>>  [7] "Break.hpd"         "Cols"              "Data"
>>> "DataFrames"        "DataToBUGS"        "DataToBUGS.nonlog"
>>> [13] "FitBRugs"          "Fixed.df"          "Fixed.hpd"
>>> "FormatData"        "GetCol"            "GetHPD"
>>> [19] "GetMCMC"           "GetRow"            "HPDIs"
>>> "Int.alpha12"       "Int.alpha21"       "ModisData"
>>> [25] "ModisDataToBUGS"   "Modis.df"          "ModisFixed.df"
>>> "ModisFixed.hpd"    "Modis.hpd"         "ModisPrecip.sd"
>>> [31] "ModisShrink.df"    "ModisShrink.hpd"   "ModisYears"
>>> "OrigData"          "OrigDataToBUGS"    "Orig.df"
>>> [37] "Orig.hpd"          "OrigPrecip.sd"     "OrigYears"
>>> "PlotChecks"        "PlotEff"           "plothpd"
>>> [43] "ProvinceNames"     "ResNames"          "ResNamesOrder"
>>> "Shrink.df"         "Shrink.hpd"        "SimInits"
>>>
>>> Specifically, the Modis* objects are sorted like this:
>>>
>>> > ls(sorted=TRUE)[26:30]
>>> [1] "Modis.df"       "ModisFixed.df"  "ModisFixed.hpd" "Modis.hpd"
>>>  "ModisPrecip.sd"
>>>
>>> With Modis.* coming both before and after ModisF*. I can't see why there
>>> would be any odd problems with character sets changing (this was all done
>>> on a single computer with no weird locale switching), and the objects are all
>>> created within a single R session:
>>>
>>> > sessionInfo()
>>> R version 3.2.5 (2016-04-14)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Ubuntu 16.04.1 LTS
>>>
>>> locale:
>>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>> LC_TIME=en_GB.UTF-8        LC_COLLATE=en_US.UTF-8
>>>  [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_US.UTF-8
>>> LC_PAPER=en_GB.UTF-8       LC_NAME=C
>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] MCMCglmm_2.22.1    ape_3.5            Matrix_1.2-7.1
>>> RColorBrewer_1.1-2 plyr_1.8.4         coda_0.18-1
>>>
>>> loaded via a namespace (and not attached):
>>> [1] cubature_1.1-2  corpcor_1.6.8   tools_3.2.5     Rcpp_0.12.7
>>> nlme_3.1-128    grid_3.2.5      knitr_1.14
>>> [8] tensorA_0.36    lattice_0.20-34
>>>
>>> Can anyone explain what's going on?
>>>
>>> Bob
>>>
>>> --
>>> Bob O'Hara
>>>
>>> Biodiversity and Climate Research Centre Senckenberganlage 25
>>> D-60325 Frankfurt am Main,
>>> Germany
>>>
>>> Tel: +49 69 798 40226
>>> Mobile: +49 1515 888 5440
>>> WWW:   http://www.bik-f.de/root/index.php?page_id=219
>>> Blog: http://occamstypewriter.org/boboh/
>>> Journal of Negative Results - EEB: www.jnr-eeb.org
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
>> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
>> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
>
>
>
> --
> Bob O'Hara
>
> Biodiversity and Climate Research Centre
> Senckenberganlage 25
> D-60325 Frankfurt am Main,
> Germany
>
> Tel: +49 69 798 40226
> Mobile: +49 1515 888 5440
> WWW:   http://www.bik-f.de/root/index.php?page_id=219
> Blog: http://occamstypewriter.org/boboh/
> Journal of Negative Results - EEB: www.jnr-eeb.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Oct 13 23:29:19 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 14 Oct 2016 08:29:19 +1100
Subject: [R] Function Distributions does not exist in package stats
In-Reply-To: <33040457-7b81-ab55-9eb6-a46427c2d4bd@gmail.com>
References: <33040457-7b81-ab55-9eb6-a46427c2d4bd@gmail.com>
Message-ID: <CA+8X3fU4z=f2cU97OwP-W=ZU7XvQ1ap14b65rnWvFNitiDvMKw@mail.gmail.com>

Hi Hugo,
If you look at the help page for "distributions", you will see that it
describes a number of functions that return density functions, etc.
for specific distributions. If you are looking for something that
informs you which distribution might approximate an existing set of
values, try the "fitdistr" function in the MASS package.

Jim


On Fri, Oct 14, 2016 at 3:42 AM, hugo <baronahugo31 at gmail.com> wrote:
> I was looking function Distribution into stats package: it does not exist!
>
> I am working with:
>
> version
>                _
> platform       x86_64-pc-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          3
> minor          3.1
> year           2016
> month          06
> day            21
> svn rev        70800
> language       R
> version.string R version 3.3.1 (2016-06-21)
> nickname       Bug in Your Hair
>
> Sincerely
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Thu Oct 13 23:30:08 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 13 Oct 2016 23:30:08 +0200
Subject: [R] sort()ing strings
In-Reply-To: <22527.26957.281028.757452@stat.math.ethz.ch>
References: <CAN-Z0xWC4jcwtsJ4CVCZ4mv0CLAs_q3EFLudAaMKtkqaJOgRRw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50414D1@SRVEXCHMBX.precheza.cz>
	<CAN-Z0xVVpEhctTZPh_hBPpUgr6EFcEyNKLz8GpBXme_fu2iHJQ@mail.gmail.com>
	<22527.26957.281028.757452@stat.math.ethz.ch>
Message-ID: <05CD50AB-EAF2-4F27-843C-EA572444BC1E@gmail.com>


> On 13 Oct 2016, at 13:00 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
> which I do find strange, indeed, given your sessionInfo which
> contains
> 	LC_COLLATE=en_US.UTF-8
> 

One of the _really_ strange things about localization is that there is no standardization. Names don't necessarily mean the same thing cross-platform. 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From teotjunk at hotmail.com  Fri Oct 14 06:07:12 2016
From: teotjunk at hotmail.com (TJUN KIAT TEO)
Date: Fri, 14 Oct 2016 04:07:12 +0000
Subject: [R] Subclass Prediction
Message-ID: <SG2PR01MB09926D965B62B5D415085833DFDF0@SG2PR01MB0992.apcprd01.prod.exchangelabs.com>

I am trying to work clustering problem where I actually know the sublcass. For example


Suppose I am trying to predict cluster patients a group of people into male and female where I actually know the label male and female but I take it I don't know


Suppose my clustering method produces subclasses label 1 and 2. Is there a quick method of how to assign which labels 1 and 2 to male or female to maximize my prediction accuracy? Obvious in this case since there are only two cases it is trivial but when the number of subclasses gets big it, trying all the possible combinations can be very time consuming.


Regards


Tjun Kiat


	[[alternative HTML version deleted]]


From ranjanagirish30 at gmail.com  Fri Oct 14 07:27:34 2016
From: ranjanagirish30 at gmail.com (Ranjana Girish)
Date: Fri, 14 Oct 2016 10:57:34 +0530
Subject: [R] regarding predicted value from xgboost package
Message-ID: <CAF5P65mukGSbyC-Zk6VqNAD+781pbAaCCCLX4G-K50DawxytUQ@mail.gmail.com>

hai everyone.....

i am using model building  function xgboost() using code :

fit <- xgboost(data =sparse_matrix , label = trainSet$OutputClass,
max.depth = 4,eta = 1, nthread = 2, nround = 10, eval_metric =
"merror",objective = "multi:softmax",num_class = 45)

when i use the prediction function:

Prediction <- predict(fit,sparse_matrixtestSet)

the above code gave output as below( instead of class names its giving
numerical equivalent value eventhough  "*label = trainSet$OutputClass*"
contain class names)

*output:*
[1]  1  1  1  1  1 35  3  3  3  4 31  7  7  7  3  3  9  9  9  9  9  9  9 10
10 11
 [27] 11 11 11 11 11 11 11 11 11 13 13 13 13 13 13 13 13 13 14 14 14 14 14
14 10 10
 [53] 15 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16 16 16 16 16
18 18 18
 [79] 18 18 18 18 35 35 35 18 21 21 21 21 32  1  1 25 25 25 25 26 27 27 27
27 27 27
[105] 27 27 29 29 29 29 29 30 30 30 30 30 30 30 30 30 30 35 35 32 32 32 43
43 32 32
[131] 32 32 32 32 32 32 43 32 32 32 32 32 33

i have also set *stringsAsFactors=FALSE* while reading data set

could some one please help, how to get prediction in term of class name
instead of numerical equivalent value.

Thanks in advance....

	[[alternative HTML version deleted]]


From andreas.nord at biol.lu.se  Fri Oct 14 08:17:21 2016
From: andreas.nord at biol.lu.se (Andreas Nord)
Date: Fri, 14 Oct 2016 06:17:21 +0000
Subject: [R] ifelse for creating discriminating variable based on two
	conditions
Message-ID: <4cf5198dd7d34033a4e075e6524ab2b6@biol.lu.se>


Dear list,

Apologies for a likely naive question.


I am trying to create a discriminating dummy variable using 'ifelse' based on conditions in two variables.


Specifically, I want to assign levels in a new factor as '0' or '1' based on a user-defined cut off. I.e. something similar to:

  >data1<-data.frame(molecule=runif(30,min=0,max=1e3))

>data1$newcol<-ifelse(data1$molecule>2*sd(data1$molecule),1,0)


Which is all straightforward.


But how do I go on to assign values in variable 'molecule'based on the same cut off, but separately for each level of a second variable, in this case the factor 'fruit' with three levels. That is, how do I derive fruit-specific cut-offs using a data frame with the general structure of that below?

>data2<-data.frame(molecule=runif(30,min=0,max=1e3),fruit=factor(rep(c('apple','pear','orange'),10)))


Many thanks in advance!



	[[alternative HTML version deleted]]


From david.hutchinson at canada.ca  Thu Oct 13 23:40:47 2016
From: david.hutchinson at canada.ca (Hutchinson, David (EC))
Date: Thu, 13 Oct 2016 21:40:47 +0000
Subject: [R] can we visualize water flows with 3d in R?
In-Reply-To: <82a1060f-7349-c502-3250-0e6d68968ffb@gmail.com>
References: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
	<b9652b19-25ba-ec08-c124-b77d4d34f70e@gmail.com>
	<CE61A0C6-EE67-4CF2-AF70-69F0386841B2@comcast.net>
	<CAGxgkWhYa1wftNweixM=vTcxR3JeETX07E6snf=geb4wpeK9NQ@mail.gmail.com>
	<3ccc56d1-a1f9-094d-74a0-f54b9d0221cc@gmail.com>
	<CAGxgkWhv1f5MemWcu9xbg_ML7bkeZY0qYKKoy=fqge9Ek=jzFg@mail.gmail.com>
	<82a1060f-7349-c502-3250-0e6d68968ffb@gmail.com>
Message-ID: <201610132140.u9DLesRG001231@hypatia.math.ethz.ch>

Karline, 

You may want to explore Green Kenue (http://www.nrc-cnrc.gc.ca/eng/solutions/advisory/green_kenue_index.html). It is freely available (download through an email request) and supports 3D data visualization and I believe it now has a python API to allow some automation.
 
Unfortunately it is only supported for Windows-based OS.

Dave

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Murdoch
Sent: October 13, 2016 2:11 PM
To: Thomas Adams
Cc: r-help mailing list; Karline Soetaert
Subject: Re: [R] can we visualize water flows with 3d in R?

On 13/10/2016 11:14 AM, Thomas Adams wrote:
> Duncan,
>
> Oh, to be sure, with a fair amount of work, you're probably correct 
> that one could mash up something. Here are some examples:
>
> http://www.illinoisfloods.org/documents/2013_IAFSM_Conference/Conferen
> ce_Presentations/5C-1_HEC-GeoRAS_Part1.pdf
> <--- lots of graphics
>
> http://rivergis.com/
>
> also...
> http://www2.egr.uh.edu/~aleon3/courses/Transient_flows/Tutorials/Geo_R
> AS/georastutorial.pdf
> -- pages 35->
> https://www.crwr.utexas.edu/reports/pdf/1999/rpt99-1.pdf -- pages 70-> 
> (figures 4-17, 4-18), p. 147

Thanks.  I guess it's up to Marna to say whether any of those figures are like what she wants to produce from her data.

Duncan Murdoch

>
> Best,
> Tom
>
> On Thu, Oct 13, 2016 at 9:20 AM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 13/10/2016 8:35 AM, Thomas Adams wrote:
>
>         All,
>
>         Very respectfully, there are no R packages that can do what
>         Marna desires.
>
>
>     I would guess that's not literally true, in that there are several
>     graphics packages that are very flexible.   You could well be right
>     that there are none that are designed specifically for this purpose,
>     so she's probably going to have to do some work to get what she wants.
>
>         His/Her data, undoubtably, comes from a 1-D hydraulic model
>         simulation -- where output is generated at channel
>         cross-sections -- representing the sloping water surface
>         elevation of the centerline of flow in a stream or river. With
>         mapping software for such problems, the assumption is made that
>         the water surface intersects the topography (within or beyond
>         the stream channel) perpendicular to the direction of flow.
>         Hydrodynamically, this is generally not correct, but it's a
>         reasonable approximation. To do this, typically, the topography
>         -- in the from of a raster digital elevation model (DEM) -- is
>         converted to a triangular irregular network (TIN) to facilitate
>         the creation of a smoother line of intersection between the
>         water surface and topography. Because, the water surface slopes
>         in a downstream direction, contour lines are crossed. Hydraulic
>         modeling software usually is accompanied by this mapping
>         capability, such as with HEC-RAS with RAS-Mapper, developed by
>         the US Army Corps of Engineers, or with HEC-GeoRAS, which
>         requires ESRI ARC GIS; but, there is also a QGIS plugin module
>         that can do this, I believe. These software packages do
>         facilitate representing the flow in 3D.
>
>
>     Do you know any sample figures online that would show the type of
>     graph that is usually used here?
>
>     Duncan Murdoch
>
>
>         Tom
>
>
>         On Wed, Oct 12, 2016 at 6:12 PM, David Winsemius
>         <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>
>         <mailto:dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>>>
>         wrote:
>
>
>             > On Oct 12, 2016, at 4:28 AM, Duncan Murdoch
>             <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>         <mailto:murdoch.duncan at gmail.com
>         <mailto:murdoch.duncan at gmail.com>>> wrote:
>             >
>             > On 12/10/2016 4:49 AM, Marna Wagley wrote:
>             >> Hi R Users,
>             >> Is it possible to visualize river flow in 3D (latitude,
>             longitude with
>             >> respect to depth)?
>             >> The example of my data looks like. Any suggestions?
>             >>
>             >>> dat1
>             >>    long lat depth flow
>             >> 1 1015.9 857  1.00 1.50
>             >> 2 1015.9 857  1.25 1.23
>             >> 3 1015.9 857  0.50 2.00
>             >> 4 1015.9 858  0.10 1.95
>             >> 5 1015.9 858  0.20 1.50
>             >> 6 1025.0 858  0.30 1.20
>             >> 7 1025.0 858  0.40 0.50
>             >> 8 1025.0 858  0.35 0.70
>             >> 9 1025.0 858  0.24 1.20
>             >>
>             >> Thanks for your help.
>             >
>             > It may be, but it's hard to give a nice looking graphic of
>         that
>             small dataset.  You could try the rgl package and use plot3d to
>             show spheres with radius depending on the flow rate, for example
>             >
>             > plot3d(cbind(long, lat, depth), type="s", col="blue",
>         radius=flow/5)
>
>             A complementary option is to install the plot3D package which I
>             see also has a plot3Drgl "co-package". The advantage to this
>             option is the association with beautiful modeling packages that
>             Karline Soetaert, Peter M. J. Herman, and Thomas Petzoldt have
>             been offering to ecologists for the last decade. (Packages:
>             deSolve, marelac, seacarb, AquaEnv) A lot of her work has
>         been on
>             flows within systems.
>
>             I usually think of "flows" in rivers as being vector fields
>         in an
>             incompressible fluid (water) with 6 components per point,
>         but you
>             can also think of them as being scalar state variables. So I
>             suppose you could be modeling something other than mass flows.
>             (See Package::ReacTran for the R portal to that mathematical
>         world.)
>
>             Best;
>             David Winsemius
>
>
>             >
>             > Duncan Murdoch
>             >
>             > ______________________________________________
>             > R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>         mailing list
>             -- To UNSUBSCRIBE and more, see
>             > https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>             <https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>             > PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>             <http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>>
>             > and provide commented, minimal, self-contained,
>         reproducible code.
>
>             David Winsemius
>             Alameda, CA, USA
>
>             ______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org>
>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>         mailing list --
>             To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>             <https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>             PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>             <http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>>
>             and provide commented, minimal, self-contained, reproducible
>         code.
>
>
>
>
>
>
>
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From info at individual-it.net  Thu Oct 13 21:12:21 2016
From: info at individual-it.net (Artur Neumann)
Date: Thu, 13 Oct 2016 21:12:21 +0200
Subject: [R] read.epiinfo() returns wrong data when reading epiinfo files
 with \032 at the end
Message-ID: <9f30126d-ad89-f47f-54eb-78a53734da41@individual-it.net>

Sorry to send this report by email, but I cannot see a way how to create
a login on https://bugs.r-project.org

Problem-Description:
I'm using the foreign package to read EPIINFO 6 files. (.REC)
All my .REC files end with a single character after the last line break.
Octal: 032 / Hex: 1A
The output data frame of read.epiinfo() has an extra line that has the
content of the first line but with shifted data and \032 added at the
beginning

Expected result:
the last line (content: " \032") would be ignored

How to reproduce:

Read an epiinfo 6 file with Octal: 032 / Hex: 1A as the only character
in the last line

--------------------------------------------------
earData2<-read.epiinfo("EAR35.REC")
Warnmeldungen:
1: In read.epiinfo("EAR35.REC") : wrong number of records
2: In matrix(datalines, nrow = multiline) :
  Datenl?nge [3226] ist kein Teiler oder Vielfaches der Anzahl der
Zeilen [3]
--------------------------------------------------

Now the first data line is added at the end again and the data is partly
shifted

------------------------------------------------------------------------------------
earData2[1,]
             FIRSTNAME         SURNAME AGEYEARS MTHS SEX  VDC SYRINGED
1 OM LAL               SUBEDI                41   NA   M BUR     FALSE
  AUDIO FIRSTEARMA OTHEREARMA SNHLDETAIL CHLOTOSCLE DUMBYN CSOMDETAIL
1  TRUE        CSO        CSO       <NA>         NA     NA         TT
  OTHERDIAGN OPERATIONY GROMMETS HEARINGAID MYRINGTYMP EARDROPS
1       <NA>       TRUE     <NA>       <NA>          2       NA
  MASTOIDECT ORALANTIBI STAPEDECTO OTHERTR OTHEROP TREATMENTD
1       <NA>         NA       <NA>      NA    <NA>       <NA>

earData2[nrow(earData2),]
                   FIRSTNAME         SURNAME AGEYEARS MTHS  SEX  VDC
1076 \032OM LAL               SUBEDI                4    1 <NA> MBUR
     SYRINGED AUDIO FIRSTEARMA OTHEREARMA SNHLDETAIL CHLOTOSCLE DUMBYN
1076       NA FALSE        YCS        OCS        O           NA     NA
     CSOMDETAIL
1076          T
                                                            OTHERDIAGN
1076 T
     OPERATIONY GROMMETS HEARINGAID MYRINGTYMP EARDROPS MASTOIDECT
1076         NA        Y       <NA>       <NA>       NA       <NA>
     ORALANTIBI STAPEDECTO OTHERTR OTHEROP TREATMENTD
1076         NA       <NA>      NA    <NA>          !
------------------------------------------------------------------------------------


Debugging:
The problem is in
https://github.com/cran/foreign/blob/master/R/read.epiinfo.R#L74

after row 66 datalines look like that:

.........
[2737] "GOBINDA             RAJ            34  MTIJ NNO.EO.E
             !"
[2738] "                                              N   Y
             !"
[2739] " BETNESOL                 !"

[2740] "AMAR                RAJ            40  MKAL NNMYRNOR
             !"
[2741] "                                              N   Y
             !"
[2742] " GENT HC                  !"

[2743] "\032"

Warning is shown in line 73


after line 74:

datalines[,1]
[1] "HARI SUNDAR         SHRESTHA       37  MDIP NNNORNOR
EPISTAXIS          !"
[2] "                                              N
          !"
[3] " NEOSPORIN                !"

and

datalines[,915]
[1] "\032"

[2] "HARI SUNDAR         SHRESTHA       37  MDIP NNNORNOR
EPISTAXIS          !"
[3] "

this does result in a wrong result.
I propose to ignore a last line that only contains "\032"
Maybe something like this in line 67:

if(identical(tail(datalines, n=1),c("\032"))) {
length(datalines)<-(length(datalines)-1) }

------------------------------------------------------------------
Package: foreign
 Version: 0.8-67
 Maintainer: R Core Team <R-core at R-project.org>
 Built: R 3.3.1; x86_64-pc-linux-gnu; 2016-09-26 12:57:55 UTC; unix

R Version:
 platform = x86_64-pc-linux-gnu
 arch = x86_64
 os = linux-gnu
 system = x86_64, linux-gnu
 status =
 major = 3
 minor = 3.1
 year = 2016
 month = 06
 day = 21
 svn rev = 70800
 language = R
 version.string = R version 3.3.1 (2016-06-21)
 nickname = Bug in Your Hair

Locale:
 LC_CTYPE=de_DE.utf8;LC_NUMERIC=C;LC_TIME=de_DE.utf8;LC_COLLATE=de_DE.utf8;LC_MONETARY=de_DE.utf8;LC_MESSAGES=de_DE.utf8;LC_PAPER=de_DE.utf8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=de_DE.utf8;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:stats, package:graphics, package:grDevices,
 package:utils, package:datasets, package:methods, Autoloads,
 package:base


This package has a bug submission web page, which we will now attempt
to open.  The information above may be useful in your report. If the web
page doesn't work, you should send email to the maintainer,
R Core Team <R-core at R-project.org>.


Mit freundlichen Gr??en
Artur Neumann

-- 
www.individual-it-services.de
EDV L?sungen, die auf Ihre W?nsche und Anforderungen angepasst sind.
Blog: http://individualit.wordpress.com/
Aktuelle Infos: http://twitter.com/INDIVIDUALIT

Bankverbindung:
KtoNr:    46201786
BLZ:     47650130
Sparkasse Detmold

Steuernummer:   313/5277/1775


From Johnny.Tan at moodys.com  Thu Oct 13 23:36:56 2016
From: Johnny.Tan at moodys.com (Tan, Johnny)
Date: Thu, 13 Oct 2016 21:36:56 +0000
Subject: [R] Is there a way to prevent Rscript from opening help page when
 given an error
Message-ID: <6C228691429996469DEE54C0DD597678247B7B@PTC-WBMSX704.ad.moodys.net>

I posted this on stackoverflow but there hasn't been any replies, does anyone know a solution for this?





I am running a script via command line using Rscript nameOfmyRscript. I notice that when there is an error, my browser would open with the help page. Now my script contained repeated errors of the same type so my browser had 10 tabs of the same help page. Is there a command or way to prevent R from opening up these pages? I know that you can suppress all warnings by doing option(warn=-1) and that you can use sink() to write errors and warnings to file. I currently have the errors and warnings written to separate files, but the help page keeps opening. I would prefer to not have any help pages open at all.

The following error would open the mean.html help page

Error in mean.default(workshop) :

(converted from warning) argument is not numeric or logical: returning NA


    Thanks
-----------------------------------------

The information contained in this e-mail message, and any attachment thereto, is confidential and may not be disclosed without our express permission. If you are not the intended recipient or an employee or agent responsible for delivering this message to the intended recipient, you are hereby notified that you have received this message in error and that any review, dissemination, distribution or copying of this message, or any attachment thereto, in whole or in part, is strictly prohibited. If you have received this message in error, please immediately notify us by telephone, fax or e-mail and delete the message and all of its attachments. Thank you. Every effort is made to keep our network free from viruses. You should, however, review this e-mail message, as well as any attachment thereto, for viruses. We take no responsibility and have no liability for any computer virus which may be transferred via this e-mail message.

	[[alternative HTML version deleted]]


From Sowmya.Vijayakumar at astrazeneca.com  Fri Oct 14 09:05:21 2016
From: Sowmya.Vijayakumar at astrazeneca.com (Vijayakumar, Sowmya)
Date: Fri, 14 Oct 2016 07:05:21 +0000
Subject: [R] Compatible version of R software for OEL v6.5 Linux OS
Message-ID: <HE1PR0401MB24586C926A4801A262CDF72C8ADF0@HE1PR0401MB2458.eurprd04.prod.outlook.com>

Hi R-Help team,


Greeting from AstraZeneca India!!



We are currently using *R 3.1.1* in Windows machine for one of our application. We have a plan to upgrade the application. Please let us know the steps to download the R which is compatible with *Oracle Enterprise Linux (OEL) v6.5.*

Thanks,
Sowmya

________________________________

Confidentiality Notice: This message is private and may ...{{dropped:10}}


From dulcalma at bigpond.com  Fri Oct 14 10:13:06 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 14 Oct 2016 19:13:06 +1100
Subject: [R] can we visualize water flows with 3d in R?
In-Reply-To: <CAMwU6B1bj5ybehtCPVU3=tF=ye_LFBANe6oGLYTiA+psYLM8aQ@mail.gmail.com>
References: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
	<000f01d22517$d89080b0$89b18210$@bigpond.com>
	<CAMwU6B1bj5ybehtCPVU3=tF=ye_LFBANe6oGLYTiA+psYLM8aQ@mail.gmail.com>
Message-ID: <000901d225f2$cb41b4c0$61c51e40$@bigpond.com>

Hi Marna

 

These are a few suggestions for EDA of your data

 

Firstly check it ? it is laborious work but it needs to be done ? use a proper database if R is not suitable (memory,time)

 

dat <- read.csv("G:/1/example_subsetdata.csv")

dat <- subset(dat, !is.na(depth))

 

apply(dat,2,range,na.rm=T)

table(cut(dat$depth, breaks = seq(496.5, 498.5, 0.25), include.lowest = TRUE, labels = F)) # needs more groups to even out numbers 

# use hand drafted breaks

table(dat$Y)

 

dat$ldepth <- cut(dat$depth, breaks = seq(496.5, 498.5, 0.25), include.lowest = TRUE, labels = F)

xyplot(Y ~ X|factor(ldepth), subset(dat, Y > 400), pch = ".", as.table = TRUE)

xyplot(flow ~ X|factor(ldepth), subset(dat, Y > 400), pch = ".", as.table = TRUE, col =1)

xyplot(flow ~ Y|factor(ldepth), subset(dat, Y > 400), pch = ".", as.table = TRUE, col =1)

 

I have made pch = ?.? so that  points are not overtopping. increase by by units ie cex = 2 , cex =3 if you want to make them larger

 

Have a look a lattice::par.settings  and names(trellis.par.get()) these will make things easier if you you are using panel functions.

 

I did not go further but the next step in this would be lattice 3d plots contourplot wireframe etc.
You will get more information in working with the full dataset
 
I have not really gone into spatials  but you should look at the task view on spatial analysis.
and the spatial SIG
 
How you proceed will be partly determined by your future requirements of which I am not qualified.
 
Regards
 
Duncan

 

 

 

From: Marna Wagley [mailto:marna.wagley at gmail.com] 
Sent: Friday, 14 October 2016 03:13
To: Duncan Mackay
Subject: Re: [R] can we visualize water flows with 3d in R?

 

Hi Duncan, 

Thank you very much for the message. Indeed I do have a very big data set with a grid size of 10cm * 10 cm. Every 10 cm*10cm grid has the value of X,Y, depth and flow measurement. I have attached a subset of the data. 

Thanks 

 

 

On Wed, Oct 12, 2016 at 11:05 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:

Hi

With a small data set 3D is not really an option;  reduce the number of
dimensions-- 2D conditional

library(lattice)
xyplot(flow ~ depth|factor(long), dat1, groups = lat, type = c("p","r"), pch
= 16)

I had started with lat and long reversed doing EDA gave the above
? latitude effect

Regards

Duncan


Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marna Wagley
Sent: Wednesday, 12 October 2016 19:49
To: r-help mailing list
Subject: [R] can we visualize water flows with 3d in R?

Hi R Users,
Is it possible to visualize river flow in  3D (latitude, longitude with
respect to depth)?
The example of my data looks like. Any suggestions?

> dat1
    long lat depth flow
1 1015.9 857  1.00 1.50
2 1015.9 857  1.25 1.23
3 1015.9 857  0.50 2.00
4 1015.9 858  0.10 1.95
5 1015.9 858  0.20 1.50
6 1025.0 858  0.30 1.20
7 1025.0 858  0.40 0.50
8 1025.0 858  0.35 0.70
9 1025.0 858  0.24 1.20

Thanks for your help.
thanks

        [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




	[[alternative HTML version deleted]]


From marna.wagley at gmail.com  Fri Oct 14 10:37:59 2016
From: marna.wagley at gmail.com (Marna Wagley)
Date: Fri, 14 Oct 2016 01:37:59 -0700
Subject: [R] can we visualize water flows with 3d in R?
In-Reply-To: <82a1060f-7349-c502-3250-0e6d68968ffb@gmail.com>
References: <CAMwU6B30hE4z-bORjGBgcmZNZjc9_4Q8ZUgQNhZ3SFoTc+ss=Q@mail.gmail.com>
	<b9652b19-25ba-ec08-c124-b77d4d34f70e@gmail.com>
	<CE61A0C6-EE67-4CF2-AF70-69F0386841B2@comcast.net>
	<CAGxgkWhYa1wftNweixM=vTcxR3JeETX07E6snf=geb4wpeK9NQ@mail.gmail.com>
	<3ccc56d1-a1f9-094d-74a0-f54b9d0221cc@gmail.com>
	<CAGxgkWhv1f5MemWcu9xbg_ML7bkeZY0qYKKoy=fqge9Ek=jzFg@mail.gmail.com>
	<82a1060f-7349-c502-3250-0e6d68968ffb@gmail.com>
Message-ID: <CAMwU6B2FnNaeeLTDgL5iH1siH7okD9b7G_Q31BmxB+F_Yi2gOw@mail.gmail.com>

Thanks for everyone for your suggestions. I am trying to use the techniques
that you suggested and I will update you its outcome so that it might be
useful to other too.
Thanks,


On Thu, Oct 13, 2016 at 2:10 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 13/10/2016 11:14 AM, Thomas Adams wrote:
>
>> Duncan,
>>
>> Oh, to be sure, with a fair amount of work, you're probably correct that
>> one could mash up something. Here are some examples:
>>
>> http://www.illinoisfloods.org/documents/2013_IAFSM_Conferenc
>> e/Conference_Presentations/5C-1_HEC-GeoRAS_Part1.pdf
>> <--- lots of graphics
>>
>> http://rivergis.com/
>>
>> also...
>> http://www2.egr.uh.edu/~aleon3/courses/Transient_flows/
>> Tutorials/Geo_RAS/georastutorial.pdf
>> -- pages 35->
>> https://www.crwr.utexas.edu/reports/pdf/1999/rpt99-1.pdf -- pages 70->
>> (figures 4-17, 4-18), p. 147
>>
>
> Thanks.  I guess it's up to Marna to say whether any of those figures are
> like what she wants to produce from her data.
>
> Duncan Murdoch
>
>
>> Best,
>> Tom
>>
>> On Thu, Oct 13, 2016 at 9:20 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 13/10/2016 8:35 AM, Thomas Adams wrote:
>>
>>         All,
>>
>>         Very respectfully, there are no R packages that can do what
>>         Marna desires.
>>
>>
>>     I would guess that's not literally true, in that there are several
>>     graphics packages that are very flexible.   You could well be right
>>     that there are none that are designed specifically for this purpose,
>>     so she's probably going to have to do some work to get what she wants.
>>
>>         His/Her data, undoubtably, comes from a 1-D hydraulic model
>>         simulation -- where output is generated at channel
>>         cross-sections -- representing the sloping water surface
>>         elevation of the centerline of flow in a stream or river. With
>>         mapping software for such problems, the assumption is made that
>>         the water surface intersects the topography (within or beyond
>>         the stream channel) perpendicular to the direction of flow.
>>         Hydrodynamically, this is generally not correct, but it's a
>>         reasonable approximation. To do this, typically, the topography
>>         -- in the from of a raster digital elevation model (DEM) -- is
>>         converted to a triangular irregular network (TIN) to facilitate
>>         the creation of a smoother line of intersection between the
>>         water surface and topography. Because, the water surface slopes
>>         in a downstream direction, contour lines are crossed. Hydraulic
>>         modeling software usually is accompanied by this mapping
>>         capability, such as with HEC-RAS with RAS-Mapper, developed by
>>         the US Army Corps of Engineers, or with HEC-GeoRAS, which
>>         requires ESRI ARC GIS; but, there is also a QGIS plugin module
>>         that can do this, I believe. These software packages do
>>         facilitate representing the flow in 3D.
>>
>>
>>     Do you know any sample figures online that would show the type of
>>     graph that is usually used here?
>>
>>     Duncan Murdoch
>>
>>
>>         Tom
>>
>>
>>         On Wed, Oct 12, 2016 at 6:12 PM, David Winsemius
>>         <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>
>>         <mailto:dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>>>
>>         wrote:
>>
>>
>>             > On Oct 12, 2016, at 4:28 AM, Duncan Murdoch
>>             <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>>         <mailto:murdoch.duncan at gmail.com
>>
>>         <mailto:murdoch.duncan at gmail.com>>> wrote:
>>             >
>>             > On 12/10/2016 4:49 AM, Marna Wagley wrote:
>>             >> Hi R Users,
>>             >> Is it possible to visualize river flow in 3D (latitude,
>>             longitude with
>>             >> respect to depth)?
>>             >> The example of my data looks like. Any suggestions?
>>             >>
>>             >>> dat1
>>             >>    long lat depth flow
>>             >> 1 1015.9 857  1.00 1.50
>>             >> 2 1015.9 857  1.25 1.23
>>             >> 3 1015.9 857  0.50 2.00
>>             >> 4 1015.9 858  0.10 1.95
>>             >> 5 1015.9 858  0.20 1.50
>>             >> 6 1025.0 858  0.30 1.20
>>             >> 7 1025.0 858  0.40 0.50
>>             >> 8 1025.0 858  0.35 0.70
>>             >> 9 1025.0 858  0.24 1.20
>>             >>
>>             >> Thanks for your help.
>>             >
>>             > It may be, but it's hard to give a nice looking graphic of
>>         that
>>             small dataset.  You could try the rgl package and use plot3d
>> to
>>             show spheres with radius depending on the flow rate, for
>> example
>>             >
>>             > plot3d(cbind(long, lat, depth), type="s", col="blue",
>>         radius=flow/5)
>>
>>             A complementary option is to install the plot3D package which
>> I
>>             see also has a plot3Drgl "co-package". The advantage to this
>>             option is the association with beautiful modeling packages
>> that
>>             Karline Soetaert, Peter M. J. Herman, and Thomas Petzoldt have
>>             been offering to ecologists for the last decade. (Packages:
>>             deSolve, marelac, seacarb, AquaEnv) A lot of her work has
>>         been on
>>             flows within systems.
>>
>>             I usually think of "flows" in rivers as being vector fields
>>         in an
>>             incompressible fluid (water) with 6 components per point,
>>         but you
>>             can also think of them as being scalar state variables. So I
>>             suppose you could be modeling something other than mass flows.
>>             (See Package::ReacTran for the R portal to that mathematical
>>         world.)
>>
>>             Best;
>>             David Winsemius
>>
>>
>>             >
>>             > Duncan Murdoch
>>             >
>>             > ______________________________________________
>>             > R-help at r-project.org <mailto:R-help at r-project.org>
>>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>>         mailing list
>>             -- To UNSUBSCRIBE and more, see
>>             > https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>             <https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>             > PLEASE do read the posting guide
>>             http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>             <http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>>
>>             > and provide commented, minimal, self-contained,
>>         reproducible code.
>>
>>             David Winsemius
>>             Alameda, CA, USA
>>
>>             ______________________________________________
>>             R-help at r-project.org <mailto:R-help at r-project.org>
>>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>>         mailing list --
>>             To UNSUBSCRIBE and more, see
>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>             <https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>             PLEASE do read the posting guide
>>             http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>             <http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>>
>>             and provide commented, minimal, self-contained, reproducible
>>         code.
>>
>>
>>
>>
>>
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Oct 14 10:50:40 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 14 Oct 2016 19:50:40 +1100
Subject: [R] ifelse for creating discriminating variable based on two
	conditions
In-Reply-To: <4cf5198dd7d34033a4e075e6524ab2b6@biol.lu.se>
References: <4cf5198dd7d34033a4e075e6524ab2b6@biol.lu.se>
Message-ID: <CA+8X3fVtn4_dJ3=3FgJ-oQa-RD+Svi3=ibZmWJkj2Vua8Vj1Ng@mail.gmail.com>

Hi Andreas,
Try this:

fruit_2sds<-by(data2$molecule,data2$fruit,sd)*2
data2$newcol<-ifelse(data2$molecule>fruit_2sds[data2$fruit],1,0)

or even just:

data$newcol<-as.numeric(data2$molecule>fruit_2sds[data2$fruit])

Jim


On Fri, Oct 14, 2016 at 5:17 PM, Andreas Nord <andreas.nord at biol.lu.se> wrote:
>
> Dear list,
>
> Apologies for a likely naive question.
>
>
> I am trying to create a discriminating dummy variable using 'ifelse' based on conditions in two variables.
>
>
> Specifically, I want to assign levels in a new factor as '0' or '1' based on a user-defined cut off. I.e. something similar to:
>
>   >data1<-data.frame(molecule=runif(30,min=0,max=1e3))
>
>>data1$newcol<-ifelse(data1$molecule>2*sd(data1$molecule),1,0)
>
>
> Which is all straightforward.
>
>
> But how do I go on to assign values in variable 'molecule'based on the same cut off, but separately for each level of a second variable, in this case the factor 'fruit' with three levels. That is, how do I derive fruit-specific cut-offs using a data frame with the general structure of that below?
>
>>data2<-data.frame(molecule=runif(30,min=0,max=1e3),fruit=factor(rep(c('apple','pear','orange'),10)))
>
>
> Many thanks in advance!
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Fri Oct 14 11:03:51 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 14 Oct 2016 09:03:51 +0000
Subject: [R] Subclass Prediction
In-Reply-To: <SG2PR01MB09926D965B62B5D415085833DFDF0@SG2PR01MB0992.apcprd01.prod.exchangelabs.com>
References: <SG2PR01MB09926D965B62B5D415085833DFDF0@SG2PR01MB0992.apcprd01.prod.exchangelabs.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5041B26@SRVEXCHMBX.precheza.cz>

Hi

?factor
?expand.grid

something like

ff<-factor(sample(1:3, 10, replace=T))
factor(ff, labels=c("male", "female", "mixed"))
 [1] male   female mixed  mixed  female female female female mixed  male
Levels: male female mixed

Cheers
Petr

>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of TJUN KIAT
> TEO
> Sent: Friday, October 14, 2016 6:07 AM
> To: r-help at r-project.org
> Subject: [R] Subclass Prediction
>
> I am trying to work clustering problem where I actually know the sublcass.
> For example
>
>
> Suppose I am trying to predict cluster patients a group of people into male
> and female where I actually know the label male and female but I take it I
> don't know
>
>
> Suppose my clustering method produces subclasses label 1 and 2. Is there a
> quick method of how to assign which labels 1 and 2 to male or female to
> maximize my prediction accuracy? Obvious in this case since there are only
> two cases it is trivial but when the number of subclasses gets big it, trying all
> the possible combinations can be very time consuming.
>
>
> Regards
>
>
> Tjun Kiat
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Oct 14 11:13:08 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 14 Oct 2016 09:13:08 +0000
Subject: [R] ifelse for creating discriminating variable based on
	two	conditions
In-Reply-To: <CA+8X3fVtn4_dJ3=3FgJ-oQa-RD+Svi3=ibZmWJkj2Vua8Vj1Ng@mail.gmail.com>
References: <4cf5198dd7d34033a4e075e6524ab2b6@biol.lu.se>
	<CA+8X3fVtn4_dJ3=3FgJ-oQa-RD+Svi3=ibZmWJkj2Vua8Vj1Ng@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5041B74@SRVEXCHMBX.precheza.cz>

Hi

Another option is to use ave

1*(data2$molecule>ave(data2$molecule, data2$fruit, FUN=function(x) 2*sd(x)))

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Friday, October 14, 2016 10:51 AM
> To: Andreas Nord <andreas.nord at biol.lu.se>
> Cc: r-help at r-project.org
> Subject: Re: [R] ifelse for creating discriminating variable based on two
> conditions
>
> Hi Andreas,
> Try this:
>
> fruit_2sds<-by(data2$molecule,data2$fruit,sd)*2
> data2$newcol<-ifelse(data2$molecule>fruit_2sds[data2$fruit],1,0)
>
> or even just:
>
> data$newcol<-as.numeric(data2$molecule>fruit_2sds[data2$fruit])
>
> Jim
>
>
> On Fri, Oct 14, 2016 at 5:17 PM, Andreas Nord <andreas.nord at biol.lu.se>
> wrote:
> >
> > Dear list,
> >
> > Apologies for a likely naive question.
> >
> >
> > I am trying to create a discriminating dummy variable using 'ifelse' based on
> conditions in two variables.
> >
> >
> > Specifically, I want to assign levels in a new factor as '0' or '1' based on a
> user-defined cut off. I.e. something similar to:
> >
> >   >data1<-data.frame(molecule=runif(30,min=0,max=1e3))
> >
> >>data1$newcol<-ifelse(data1$molecule>2*sd(data1$molecule),1,0)
> >
> >
> > Which is all straightforward.
> >
> >
> > But how do I go on to assign values in variable 'molecule'based on the same
> cut off, but separately for each level of a second variable, in this case the
> factor 'fruit' with three levels. That is, how do I derive fruit-specific cut-offs
> using a data frame with the general structure of that below?
> >
> >>data2<-
> data.frame(molecule=runif(30,min=0,max=1e3),fruit=factor(rep(c(
> >>'apple','pear','orange'),10)))
> >
> >
> > Many thanks in advance!
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From manu.reddy52 at gmail.com  Fri Oct 14 11:37:48 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Fri, 14 Oct 2016 15:07:48 +0530
Subject: [R] Reg : R : How to capture cpu usage,
 memory usage and disks info using R language
Message-ID: <CADG9u0BpE6DBVWtRXunviWAL00jV0QD2TRZ3P6t82p6FC_YMyg@mail.gmail.com>

Hi,

? Is there any possibility that we can capture cpu usage ,memory usage and
disks info using R language on *windows family OS* ?



  I would like to see data that?s looks like
?a?
 below



   Cpu usage : 70 %

   Memory usage  : 80 %

   Disks        : C drive ? 40 % full,D dive ? 60 %,full E drive ? 30 % full


?   for more info please find the attachement.?


 Thanks in Advance ,Manu.?
-------------- next part --------------
A non-text attachment was scrubbed...
Name: system_monitor_info.PNG
Type: image/png
Size: 37629 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161014/29dc8be2/attachment.png>

From Rainer at krugs.de  Fri Oct 14 11:42:19 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 14 Oct 2016 11:42:19 +0200
Subject: [R] Getting cited references and times cited from DOI for analysis
	in R?
Message-ID: <m2vawv4684.fsf@krugs.de>

Hi

This sounds off topic, but as I want to analyse the data in R and the R
community is extremely knowledgeable in many respects.

So here I go:

I have "inherited" a literature list for further analysis containing
more than 5000 references. What I would like to do is construct citation
trees (who has cited whom) and analyze the times each reference has been
cited. Noe the literature list does unfortunately not contain the
references cited in each reference.

I have seen the "scholary" paper which allows me to get information on
an author - but is there something similar for getting a list of the
cited papers and the count of how often the paper has been cited? 

I have access to web of science, which can provide this information, but
can I somehow do this in a scripted R way as I want to analyse the data
in R afterwards?

Thanks,

Rainer

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161014/da6cc67d/attachment.bin>

From bjpmodi2016 at gmail.com  Fri Oct 14 16:00:23 2016
From: bjpmodi2016 at gmail.com (Narendra Modi)
Date: Fri, 14 Oct 2016 09:00:23 -0500
Subject: [R] Share R.net dll without having to share R script code?
Message-ID: <CAPq=xQC2EOwJf5QKvmv9d1KGZ9KZqQaz700mN8ga=b+-jKYvrg@mail.gmail.com>

Hello Gurus,

I have built a code snippet using R.net wherein I call couple of R
scripts to run optimization packages and use the output in C# code.
The way I call the R scripts is just by providing its location in the
C# code.

So, if I have to share the .dll of the complete program, I will also
have to share the R scripts; actual code. Is there anyway to avoid it;
not having to share the r script code with users/testers.
I am considerably new to R. Any suggestion in this direction is appreciated!

Regards,
NM


From murdoch.duncan at gmail.com  Fri Oct 14 16:18:36 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 14 Oct 2016 10:18:36 -0400
Subject: [R] Share R.net dll without having to share R script code?
In-Reply-To: <CAPq=xQC2EOwJf5QKvmv9d1KGZ9KZqQaz700mN8ga=b+-jKYvrg@mail.gmail.com>
References: <CAPq=xQC2EOwJf5QKvmv9d1KGZ9KZqQaz700mN8ga=b+-jKYvrg@mail.gmail.com>
Message-ID: <2384fc30-3dd3-4af4-839e-e00d86854a01@gmail.com>

On 14/10/2016 10:00 AM, Narendra Modi wrote:
> Hello Gurus,
>
> I have built a code snippet using R.net wherein I call couple of R
> scripts to run optimization packages and use the output in C# code.
> The way I call the R scripts is just by providing its location in the
> C# code.
>
> So, if I have to share the .dll of the complete program, I will also
> have to share the R scripts; actual code. Is there anyway to avoid it;
> not having to share the r script code with users/testers.
> I am considerably new to R. Any suggestion in this direction is appreciated!
>

I don't know what the R.net .dll is, but if it includes R, you need to 
share the complete source code of anything you distribute that includes 
it.  The R scripts will be only a small part of that.

Sharing less than that is a copyright violation, since you are only 
licensed to distribute R under the GPL license, and it requires that you 
share code of the original and your modifications.

Duncan Murdoch


From bjpmodi2016 at gmail.com  Fri Oct 14 16:43:58 2016
From: bjpmodi2016 at gmail.com (Narendra Modi)
Date: Fri, 14 Oct 2016 09:43:58 -0500
Subject: [R] Share R.net dll without having to share R script code?
In-Reply-To: <2384fc30-3dd3-4af4-839e-e00d86854a01@gmail.com>
References: <CAPq=xQC2EOwJf5QKvmv9d1KGZ9KZqQaz700mN8ga=b+-jKYvrg@mail.gmail.com>
	<2384fc30-3dd3-4af4-839e-e00d86854a01@gmail.com>
Message-ID: <CAPq=xQB6nSz2gLpGYyztivc5cZDTvhzz3KQCN_uPXa1z1r2M7w@mail.gmail.com>

Thanks Duncan. That's useful to know.

On Fri, Oct 14, 2016 at 9:18 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 14/10/2016 10:00 AM, Narendra Modi wrote:
>>
>> Hello Gurus,
>>
>> I have built a code snippet using R.net wherein I call couple of R
>> scripts to run optimization packages and use the output in C# code.
>> The way I call the R scripts is just by providing its location in the
>> C# code.
>>
>> So, if I have to share the .dll of the complete program, I will also
>> have to share the R scripts; actual code. Is there anyway to avoid it;
>> not having to share the r script code with users/testers.
>> I am considerably new to R. Any suggestion in this direction is
>> appreciated!
>>
>
> I don't know what the R.net .dll is, but if it includes R, you need to share
> the complete source code of anything you distribute that includes it.  The R
> scripts will be only a small part of that.
>
> Sharing less than that is a copyright violation, since you are only licensed
> to distribute R under the GPL license, and it requires that you share code
> of the original and your modifications.
>
> Duncan Murdoch
>


From bob at rud.is  Fri Oct 14 16:55:20 2016
From: bob at rud.is (Bob Rudis)
Date: Fri, 14 Oct 2016 10:55:20 -0400
Subject: [R] Share R.net dll without having to share R script code?
In-Reply-To: <CAPq=xQB6nSz2gLpGYyztivc5cZDTvhzz3KQCN_uPXa1z1r2M7w@mail.gmail.com>
References: <CAPq=xQC2EOwJf5QKvmv9d1KGZ9KZqQaz700mN8ga=b+-jKYvrg@mail.gmail.com>
	<2384fc30-3dd3-4af4-839e-e00d86854a01@gmail.com>
	<CAPq=xQB6nSz2gLpGYyztivc5cZDTvhzz3KQCN_uPXa1z1r2M7w@mail.gmail.com>
Message-ID: <CAA-FpKVxOHg09F7=aiVN-1d9Mu=a3JoEeOc+v2f5OFNtT3DtpA@mail.gmail.com>

Ugly idea/option, but you could base64 encode the R script (solely to
avoid the need to do string quoting) and have that string in the
source of the R.net code, then pass it in to the eval portion or write
it out to a temp dir and pass that to the eval portion of the code.
That way the script is embedded with the DLL and not an extra asset
that needs to be managed.

On Fri, Oct 14, 2016 at 10:43 AM, Narendra Modi <bjpmodi2016 at gmail.com> wrote:
> Thanks Duncan. That's useful to know.
>
> On Fri, Oct 14, 2016 at 9:18 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 14/10/2016 10:00 AM, Narendra Modi wrote:
>>>
>>> Hello Gurus,
>>>
>>> I have built a code snippet using R.net wherein I call couple of R
>>> scripts to run optimization packages and use the output in C# code.
>>> The way I call the R scripts is just by providing its location in the
>>> C# code.
>>>
>>> So, if I have to share the .dll of the complete program, I will also
>>> have to share the R scripts; actual code. Is there anyway to avoid it;
>>> not having to share the r script code with users/testers.
>>> I am considerably new to R. Any suggestion in this direction is
>>> appreciated!
>>>
>>
>> I don't know what the R.net .dll is, but if it includes R, you need to share
>> the complete source code of anything you distribute that includes it.  The R
>> scripts will be only a small part of that.
>>
>> Sharing less than that is a copyright violation, since you are only licensed
>> to distribute R under the GPL license, and it requires that you share code
>> of the original and your modifications.
>>
>> Duncan Murdoch
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tr206 at kent.ac.uk  Fri Oct 14 19:47:54 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Fri, 14 Oct 2016 17:47:54 +0000
Subject: [R] Return.clean () - PerformanceAnalytics package
Message-ID: <1476467282814.55989@kent.ac.uk>

Dear all,

I am trying to clean return data using the Return.clean() function in the PerformanceAnalytics package. Hence, my code looks as follows but I get an error message.



cleantest <- read.csv("D:/Studie_vola_difference/cleantest.csv")
data<-as.vector(cleantest)
test<-Return.clean(data,method="boudt",alpha=0.01)

Error in checkData(R, method = "xts") :
The data cannot be converted into a time series.  If you are trying to pass in names from a data object with one column, you should use the form 'data[rows, columns, drop = FALSE]'.  Rownames should have standard date formats, such as '1985-03-15'.



Can anybody help me on this error? What is wrong with my code?



Thanks for your support.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Oct 14 20:12:08 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Oct 2016 11:12:08 -0700
Subject: [R] Is there a way to prevent Rscript from opening help page
	when given an error
In-Reply-To: <6C228691429996469DEE54C0DD597678247B7B@PTC-WBMSX704.ad.moodys.net>
References: <6C228691429996469DEE54C0DD597678247B7B@PTC-WBMSX704.ad.moodys.net>
Message-ID: <E628798F-844F-4753-9805-73E839EDA879@comcast.net>


> On Oct 13, 2016, at 2:36 PM, Tan, Johnny <Johnny.Tan at moodys.com> wrote:
> 
> I posted this on stackoverflow but there hasn't been any replies, does anyone know a solution for this?
> 
> 
> 
> 
> 
> I am running a script via command line using Rscript nameOfmyRscript. I notice that when there is an error, my browser would open with the help page. Now my script contained repeated errors of the same type so my browser had 10 tabs of the same help page. Is there a command or way to prevent R from opening up these pages? I know that you can suppress all warnings by doing option(warn=-1) and that you can use sink() to write errors and warnings to file. I currently have the errors and warnings written to separate files, but the help page keeps opening. I would prefer to not have any help pages open at all.
> 
> The following error would open the mean.html help page
> 
> Error in mean.default(workshop) :
> 
> (converted from warning) argument is not numeric or logical: returning NA

That's not standard behavior, although I can see that it might be desired in a teaching situation. How was your installation of R created and on what operating system. (Answering those two questions and other useful advice  are offered in the Posting Guide which I would suggest you read in its entirety ... now ... before you draft a response.)
> 
> 
>    Thanks
> -----------------------------------------
> 
> The information contained in this e-mail message, and any attachment thereto, is confidential and may not be disclosed without our express permission. If you are not the intended recipient or an employee or agent responsible for delivering this message to the intended recipient, you are hereby notified that you have received this message in error and that any review, dissemination, distribution or copying of this message, or any attachment thereto, in whole or in part, is strictly prohibited. If you have received this message in error, please immediately notify us by telephone, fax or e-mail and delete the message and all of its attachments. Thank you. Every effort is made to keep our network free from viruses. You should, however, review this e-mail message, as well as any attachment thereto, for viruses. We take no responsibility and have no liability for any computer virus which may be transferred via this e-mail message.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Oct 14 20:14:36 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Oct 2016 11:14:36 -0700
Subject: [R] Compatible version of R software for OEL v6.5 Linux OS
In-Reply-To: <HE1PR0401MB24586C926A4801A262CDF72C8ADF0@HE1PR0401MB2458.eurprd04.prod.outlook.com>
References: <HE1PR0401MB24586C926A4801A262CDF72C8ADF0@HE1PR0401MB2458.eurprd04.prod.outlook.com>
Message-ID: <A6BEF5D5-1499-4DBD-BC3E-20079895056A@comcast.net>


> On Oct 14, 2016, at 12:05 AM, Vijayakumar, Sowmya <Sowmya.Vijayakumar at astrazeneca.com> wrote:
> 
> Hi R-Help team,
> 
> 
> Greeting from AstraZeneca India!!
> 
> 
> 
> We are currently using *R 3.1.1* in Windows machine for one of our application. We have a plan to upgrade the application. Please let us know the steps to download the R which is compatible with *Oracle Enterprise Linux (OEL) v6.5.*

I'm curious why you think we are supposed to know the answer to that question? I would think it should be asked of the people at Oracle.


> 
> Thanks,
> Sowmya
> 
> ________________________________
> 
> Confidentiality Notice: This message is private and may ...{{dropped:10}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bob at rud.is  Fri Oct 14 20:18:56 2016
From: bob at rud.is (Bob Rudis)
Date: Fri, 14 Oct 2016 14:18:56 -0400
Subject: [R] Compatible version of R software for OEL v6.5 Linux OS
In-Reply-To: <A6BEF5D5-1499-4DBD-BC3E-20079895056A@comcast.net>
References: <HE1PR0401MB24586C926A4801A262CDF72C8ADF0@HE1PR0401MB2458.eurprd04.prod.outlook.com>
	<A6BEF5D5-1499-4DBD-BC3E-20079895056A@comcast.net>
Message-ID: <CAA-FpKVh=8oP4myCh4CBEPtgPg3-QmZWH5gnJ1hMa7jxrmBpjw@mail.gmail.com>

Having worked in big pharma for over 10 years, I'm _fairly_ certain
AstraZeneca can afford some paid R consulting.

On Fri, Oct 14, 2016 at 2:14 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Oct 14, 2016, at 12:05 AM, Vijayakumar, Sowmya <Sowmya.Vijayakumar at astrazeneca.com> wrote:
>>
>> Hi R-Help team,
>>
>>
>> Greeting from AstraZeneca India!!
>>
>>
>>
>> We are currently using *R 3.1.1* in Windows machine for one of our application. We have a plan to upgrade the application. Please let us know the steps to download the R which is compatible with *Oracle Enterprise Linux (OEL) v6.5.*
>
> I'm curious why you think we are supposed to know the answer to that question? I would think it should be asked of the people at Oracle.
>
>
>>
>> Thanks,
>> Sowmya
>>
>> ________________________________
>>
>> Confidentiality Notice: This message is private and may ...{{dropped:10}}
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Fri Oct 14 20:26:10 2016
From: sewashm at gmail.com (Ashta)
Date: Fri, 14 Oct 2016 13:26:10 -0500
Subject: [R] Subset and sumerize
Message-ID: <CADDFq32TiMzcLhrP6E8MBs-hGfcbD73tcAp=DBK8wBQ=pAnWkw@mail.gmail.com>

Hi all,

I am trying to summarize  big data set  by   selecting a row
conditionally. and tried  to do it in a loop

Here is  the sample of my data and my attempt

dat<-read.table(text=" ID,x1,x2,y
1,a,b,15
1,x,z,21
1,x,b,16
1,x,k,25
2,d,z,31
2,x,z,28
2,g,t,41
3,h,e,32
3,x,z,38
3,x,g,45
",sep=",",header=TRUE)

For  each unique ID,  I want to select  a data when x1= "x" and x2="z"
Here is the selected data (newdat)
ID,x1,x2,y
1,x,z,21
2,x,z,28
3,x,z,38

Then I want summarize  Y values and out put as follows
Summerize
summary(newdat[i])
######################################################
ID   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
1
2
3
.
.
.
28
####################################################

Here is my attempt but did not work,

trt=c(1:28)
for(i  in 1:length (trt))
{
  day[i]= newdat[which(newdat$ID== trt[i] &  newdat$x1 =="x" &
newdat$x2 =="z"),]
NR[i]=dim(day[i])[1]
print(paste("Number of Records      :", NR[i]))
sm[i]=summary(day[i])
}

Thank you in advance


From sarah.goslee at gmail.com  Fri Oct 14 20:54:28 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 14 Oct 2016 14:54:28 -0400
Subject: [R] Subset and sumerize
In-Reply-To: <CADDFq32TiMzcLhrP6E8MBs-hGfcbD73tcAp=DBK8wBQ=pAnWkw@mail.gmail.com>
References: <CADDFq32TiMzcLhrP6E8MBs-hGfcbD73tcAp=DBK8wBQ=pAnWkw@mail.gmail.com>
Message-ID: <CAM_vjun3_rYT9k40TOBiiPQHgVNWkjZh+tBntssQ_piyK++VUA@mail.gmail.com>

For the data you provide, it's simply:

summary(subset(dat, x1 == "x" & x2 == "z")$y)

Note that x1 and x2 are factors in your example.

We also don't know what you want to do if there are more than one
combination of that per ID, or if there ID values with no matching
rows.

Sarah

On Fri, Oct 14, 2016 at 2:26 PM, Ashta <sewashm at gmail.com> wrote:
> Hi all,
>
> I am trying to summarize  big data set  by   selecting a row
> conditionally. and tried  to do it in a loop
>
> Here is  the sample of my data and my attempt
>
> dat<-read.table(text=" ID,x1,x2,y
> 1,a,b,15
> 1,x,z,21
> 1,x,b,16
> 1,x,k,25
> 2,d,z,31
> 2,x,z,28
> 2,g,t,41
> 3,h,e,32
> 3,x,z,38
> 3,x,g,45
> ",sep=",",header=TRUE)
>
> For  each unique ID,  I want to select  a data when x1= "x" and x2="z"
> Here is the selected data (newdat)
> ID,x1,x2,y
> 1,x,z,21
> 2,x,z,28
> 3,x,z,38
>
> Then I want summarize  Y values and out put as follows
> Summerize
> summary(newdat[i])
> ######################################################
> ID   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> 1
> 2
> 3
> .
> .
> .
> 28
> ####################################################
>
> Here is my attempt but did not work,
>
> trt=c(1:28)
> for(i  in 1:length (trt))
> {
>   day[i]= newdat[which(newdat$ID== trt[i] &  newdat$x1 =="x" &
> newdat$x2 =="z"),]
> NR[i]=dim(day[i])[1]
> print(paste("Number of Records      :", NR[i]))
> sm[i]=summary(day[i])
> }
>
> Thank you in advance
>


From rshepard at appl-ecosys.com  Fri Oct 14 21:03:33 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 14 Oct 2016 12:03:33 -0700 (PDT)
Subject: [R] Adjusting axis labels on lattice xyplot
Message-ID: <alpine.LNX.2.11.1610141153020.8550@localhost>

   I've read chapters 7 and 8 in the Lattice book and do not see how to thin
labels on the x and y axes of an xyplot(), and how to rotate the dates on
the x axis for easier reading (rot did not do the job for me.)

   The data (as raindata.dat) and the existing plot (as precip.pdf) are
attached.

   The ploting command used is:

xyplot(rain$amount ~ rain$date | rain$station, main="Weather Stations",
xlab="Date", ylab="Amount (inches)", pch=16, col=132)

   Please point me to the appropriate place in the book where the prepanel
function to change the axis lable spacing and rotation is discussed. I
expected it to be in chapter 8. Or, if there's another reference I should
read, please point me to that.

   For some reason I've not yet tracked down, there is no longer help
available within the R session (running in emacs with ESS) when I type, for
example, ?xyplot. R returns the message that there's no documentation in the
specified packages and libraries. Obviously something changed since I last
used R.

Rich
-------------- next part --------------
structure(list(station = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L), .Label = c("0.3E", 
"0.6W", "1.0WNW", "1.5N", "4.3WNW", "Airport"), class = "factor"), 
    date = structure(c(32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 
    40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 51L, 
    52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 1L, 
    2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
    27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 
    39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 
    51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 
    1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
    27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 
    39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 
    51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 
    1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
    27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 
    39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 
    51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 
    1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
    27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 
    39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 
    51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 
    1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
    27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 
    39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 
    51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L
    ), .Label = c("2013-12-01", "2013-12-02", "2013-12-03", "2013-12-04", 
    "2013-12-05", "2013-12-06", "2013-12-07", "2013-12-08", "2013-12-09", 
    "2013-12-10", "2013-12-11", "2013-12-12", "2013-12-13", "2013-12-14", 
    "2013-12-15", "2013-12-16", "2013-12-17", "2013-12-18", "2013-12-19", 
    "2013-12-20", "2013-12-21", "2013-12-22", "2013-12-23", "2013-12-24", 
    "2013-12-25", "2013-12-26", "2013-12-27", "2013-12-28", "2013-12-29", 
    "2013-12-30", "2013-12-31", "2014-01-01", "2014-01-02", "2014-01-03", 
    "2014-01-04", "2014-01-05", "2014-01-06", "2014-01-07", "2014-01-08", 
    "2014-01-09", "2014-01-10", "2014-01-11", "2014-01-12", "2014-01-13", 
    "2014-01-14", "2014-01-15", "2014-01-16", "2014-01-17", "2014-01-18", 
    "2014-01-19", "2014-01-20", "2014-01-21", "2014-01-22", "2014-01-23", 
    "2014-01-24", "2014-01-25", "2014-01-26", "2014-01-27", "2014-01-28", 
    "2014-01-29", "2014-01-30", "2014-01-31"), class = "factor"), 
    amount = structure(c(1L, 1L, 3L, 2L, 2L, 2L, 12L, 18L, 34L, 
    14L, 32L, 39L, 20L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 1L, 
    2L, 2L, 2L, 1L, 9L, 33L, 5L, 1L, 24L, 45L, 6L, 1L, 2L, 3L, 
    3L, 2L, 2L, 1L, 2L, 2L, 10L, 3L, 4L, 3L, 3L, 1L, 11L, 4L, 
    15L, 3L, 1L, 4L, 3L, 3L, 1L, 1L, 1L, 2L, 6L, 4L, 3L, 4L, 
    3L, 1L, 2L, 13L, 20L, 35L, 16L, 33L, 4L, 3L, 1L, 3L, 1L, 
    1L, 2L, 2L, 2L, 2L, 2L, 2L, 8L, 33L, 5L, 5L, 1L, 1L, 1L, 
    1L, 7L, 2L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 1L, 9L, 2L, 3L, 4L, 
    3L, 3L, 12L, 3L, 3L, 2L, 2L, 6L, 3L, 1L, 2L, 3L, 3L, 2L, 
    7L, 1L, 1L, 3L, 3L, 4L, 2L, 2L, 2L, 13L, 18L, 35L, 35L, 29L, 
    40L, 17L, 3L, 4L, 3L, 3L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 8L, 31L, 4L, 4L, 42L, 12L, 2L, 2L, 2L, 48L, 2L, 2L, 
    2L, 2L, 2L, 9L, 3L, 3L, 4L, 2L, 2L, 9L, 2L, 12L, 48L, 48L, 
    4L, 48L, 2L, 2L, 2L, 2L, 2L, 48L, 7L, 2L, 3L, 3L, 2L, 2L, 
    7L, 22L, 28L, 8L, 3L, 43L, 26L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 8L, 26L, 14L, 3L, 7L, 21L, 44L, 
    5L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 9L, 1L, 3L, 3L, 3L, 
    1L, 11L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    3L, 3L, 3L, 2L, 2L, 2L, 13L, 19L, 34L, 12L, 30L, 36L, 23L, 
    2L, 3L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 8L, 
    33L, 4L, 4L, 27L, 47L, 15L, 2L, 2L, 5L, 3L, 2L, 2L, 2L, 2L, 
    2L, 14L, 4L, 1L, 1L, 1L, 1L, 1L, 5L, 20L, 4L, 4L, 7L, 3L, 
    2L, 1L, 2L, 4L, 2L, 3L, 6L, 4L, 6L, 3L, 1L, 2L, 15L, 25L, 
    41L, 37L, 37L, 46L, 29L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 3L, 1L, 2L, 2L, 2L, 9L, 38L, 12L, 7L), .Label = c("", 
    "0.00", "0.01", "0.02", "0.03", "0.04", "0.05", "0.06", "0.07", 
    "0.08", "0.09", "0.10", "0.11", "0.12", "0.13", "0.15", "0.21", 
    "0.22", "0.23", "0.24", "0.25", "0.27", "0.28", "0.32", "0.34", 
    "0.36", "0.40", "0.42", "0.44", "0.45", "0.46", "0.47", "0.48", 
    "0.49", "0.54", "0.60", "0.61", "0.62", "0.70", "0.71", "0.84", 
    "0.87", "0.90", "0.91", "0.92", "1.00", "1.06", "T"), class = "factor")), .Names = c("station", 
"date", "amount"), class = "data.frame", row.names = c(NA, -341L
))
-------------- next part --------------
A non-text attachment was scrubbed...
Name: precip.pdf
Type: application/pdf
Size: 13071 bytes
Desc: 
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161014/e501664e/attachment.pdf>

From msharp at txbiomed.org  Fri Oct 14 21:04:26 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Fri, 14 Oct 2016 19:04:26 +0000
Subject: [R] Subset and sumerize
In-Reply-To: <CADDFq32TiMzcLhrP6E8MBs-hGfcbD73tcAp=DBK8wBQ=pAnWkw@mail.gmail.com>
References: <CADDFq32TiMzcLhrP6E8MBs-hGfcbD73tcAp=DBK8wBQ=pAnWkw@mail.gmail.com>
Message-ID: <FEAE0EB1-A5FD-4B1E-830F-516ABA41DEAB@TxBiomed.org>

Ashta,

## I may have misunderstood your question and if so I apologize.

## I had to remove the extra line after "45" before
## the ",sep=" to use your code.
## You could have used dput(dat) to send a more reliable (robust) version.
dat <- structure(list(ID = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L),
    x1 = structure(c(1L, 5L, 5L, 5L, 2L, 5L, 3L, 4L, 5L, 5L), .Label = c("a",
    "d", "g", "h", "x"), class = "factor"), x2 = structure(c(1L,
    6L, 1L, 4L, 6L, 6L, 5L, 2L, 6L, 3L), .Label = c("b", "e",
    "g", "k", "t", "z"), class = "factor"), y = c(15L, 21L, 16L,
    25L, 31L, 28L, 41L, 32L, 38L, 45L)), .Names = c("ID", "x1",
"x2", "y"), class = "data.frame", row.names = c(NA, -10L))

# In your proposed solution "newdat" is never defined yet you are using it as if it were.

## It is my understanding that your goal is to define newdat as a
## subset of dat where x1 == "x" and x2 == "z".
## This can be done with one line.

newdat <- dat[dat$x1 == "x" & dat$x2 == "z", ]
newdat

> On Oct 14, 2016, at 1:26 PM, Ashta <sewashm at gmail.com> wrote:
>
> Hi all,
>
> I am trying to summarize  big data set  by   selecting a row
> conditionally. and tried  to do it in a loop
>
> Here is  the sample of my data and my attempt
>
> dat<-read.table(text=" ID,x1,x2,y
> 1,a,b,15
> 1,x,z,21
> 1,x,b,16
> 1,x,k,25
> 2,d,z,31
> 2,x,z,28
> 2,g,t,41
> 3,h,e,32
> 3,x,z,38
> 3,x,g,45
> ",sep=",",header=TRUE)
>
> For  each unique ID,  I want to select  a data when x1= "x" and x2="z"
> Here is the selected data (newdat)
> ID,x1,x2,y
> 1,x,z,21
> 2,x,z,28
> 3,x,z,38
>
> Then I want summarize  Y values and out put as follows
> Summerize
> summary(newdat[i])
> ######################################################
> ID   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> 1
> 2
> 3
> .
> .
> .
> 28
> ####################################################
>
> Here is my attempt but did not work,
>
> trt=c(1:28)
> for(i  in 1:length (trt))
> {
>  day[i]= newdat[which(newdat$ID== trt[i] &  newdat$x1 =="x" &
> newdat$x2 =="z"),]
> NR[i]=dim(day[i])[1]
> print(paste("Number of Records      :", NR[i]))
> sm[i]=summary(day[i])
> }
>
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From valkremk at gmail.com  Fri Oct 14 21:06:35 2016
From: valkremk at gmail.com (Val)
Date: Fri, 14 Oct 2016 14:06:35 -0500
Subject: [R] Incremental
In-Reply-To: <57FF6230.5090609@sapo.pt>
References: <CAJOiR6Z0Cu_OS_nF4WrW0FBbUVZphSzbi1pwRmYz403vjVxB8w@mail.gmail.com>
	<57FE9E38.1040800@sapo.pt>
	<CAJOiR6Z8mRnb-+C-QOfd6jqD7vB-8VkQCj+gGgbf7Cim=tkusw@mail.gmail.com>
	<57FF6230.5090609@sapo.pt>
Message-ID: <CAJOiR6aSU780Sr5demaUDT4ECUn5Q-PyE=_qj49=FY3oak4LvA@mail.gmail.com>

Thank you Rui,

It Worked!

How about if the first variable is date format? Like the following
dat<-read.table(text=" y1, flag
24-01-2016,S
24-02-2016,R
24-03-2016,X
24-04-2016,H
24-01-2016,S
24-11-2016,R
24-10-2016,R
24-02-2016,X
24-01-2016,H
24-11-2016,S
24-02-2016,R
24-10-2016,X
24-03-2016,H
24-04-2016,S
",sep=",",header=TRUE)
dat
dat$x1 <- cumsum(dat$flag == "S")
dat$z2 <- unlist(tapply(dat$y1, dat$x1, function(y) y - y[1]))

error message
In Ops.factor(y, y[1]) : ?-? not meaningful for factors



On Thu, Oct 13, 2016 at 5:30 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> You must run the code to create x1 first, part 1), then part 2).
> I've tested with your data and all went well, the result is the following.
>
>> dput(dat)
> structure(list(y1 = c(39958L, 40058L, 40105L, 40294L, 40332L,
> 40471L, 40493L, 40533L, 40718L, 40771L, 40829L, 40892L, 41056L,
> 41110L, 41160L, 41222L, 41250L, 41289L, 41324L, 41355L, 41415L,
> 41562L, 41562L, 41586L), flag = structure(c(3L, 2L, 4L, 1L, 3L,
> 2L, 2L, 4L, 1L, 3L, 2L, 4L, 1L, 3L, 2L, 2L, 2L, 2L, 4L, 2L, 4L,
> 4L, 1L, 3L), .Label = c("H", "R", "S", "X"), class = "factor"),
>     x1 = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L), z2 = c(0L, 100L,
>     147L, 336L, 0L, 139L, 161L, 201L, 386L, 0L, 58L, 121L, 285L,
>     0L, 50L, 112L, 140L, 179L, 214L, 245L, 305L, 452L, 452L,
>     0L)), .Names = c("y1", "flag", "x1", "z2"), row.names = c(NA,
> -24L), class = "data.frame")
>
>
> Rui Barradas
>
>
> Em 12-10-2016 21:53, Val escreveu:
>>
>> Rui,
>> Thank You!
>>
>> the second one gave me NULL.
>> dat$z2 <- unlist(tapply(dat$y1, dat$x1, function(y) y - y[1]))
>>
>> dat$z2
>> NULL
>>
>>
>>
>> On Wed, Oct 12, 2016 at 3:34 PM, Rui Barradas <ruipbarradas at sapo.pt>
>> wrote:
>>>
>>> Hello,
>>>
>>> Seems simple:
>>>
>>>
>>> # 1)
>>> dat$x1 <- cumsum(dat$flag == "S")
>>>
>>> # 2)
>>> dat$z2 <- unlist(tapply(dat$y1, dat$x1, function(y) y - y[1]))
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>> Em 12-10-2016 21:15, Val escreveu:
>>>>
>>>>
>>>> Hi all,
>>>>
>>>> I have a data set like
>>>> dat<-read.table(text=" y1, flag
>>>> 39958,S
>>>> 40058,R
>>>> 40105,X
>>>> 40294,H
>>>> 40332,S
>>>> 40471,R
>>>> 40493,R
>>>> 40533,X
>>>> 40718,H
>>>> 40771,S
>>>> 40829,R
>>>> 40892,X
>>>> 41056,H
>>>> 41110,S
>>>> 41160,R
>>>> 41222,R
>>>> 41250,R
>>>> 41289,R
>>>> 41324,X
>>>> 41355,R
>>>> 41415,X
>>>> 41562,X
>>>> 41562,H
>>>> 41586,S
>>>> ",sep=",",header=TRUE)
>>>>
>>>> First sort the data by y1.
>>>> Then
>>>> I want to create two columns .
>>>> 1. the first new column is  (x1):  if flag is "S"  then  x1=1  and
>>>> assign the following/subsequent rows 1 as well.   When we reach to
>>>> the next "S"  then  x1=2 and the subsequent rows will be assigned to
>>>> 2.
>>>>
>>>> 2. the second variable (z2). Within each x1 find the difference
>>>> between the first y1 and subsequent y1 values
>>>>
>>>> Example  for the first few rows
>>>>     y1,   flag, x1, z2
>>>> 39958, S, 1,    0          z2 is calculated as     z2=(39958, 39958)
>>>> 40058, R, 1, 100         z2 is calculated as     z2=(40058, 39958)
>>>> 40105, X, 1, 147         z2 is calculated as     z2=(40105, 39958)
>>>> 40294, H, 1, 336         z2 is calculated as     z2=(40294, 39958)
>>>> 40332, S, 2,  0            z2 is calculated as     z2=(40332, 40332)
>>>> etc
>>>>
>>>> Here is the complete output for the sample  data
>>>> 39958,S,1,0
>>>> 40058,R,1,100
>>>> 40105,X,1,147
>>>> 40294,H,1,336
>>>> 40332,S,2,0
>>>> 40471,R,2,139
>>>> 40493,R,2,161
>>>> 40533,X,2,201
>>>> 40718,H,2,386
>>>> 40771,S,3,0
>>>> 40829,R,3,58
>>>> 40892,X,3,121
>>>> 41056,H,3,285
>>>> 41110,S,4,0
>>>> 41160,R,4,50
>>>> 41222,R,4,112
>>>> 41250,R,4,140
>>>> 41289,R,4,179
>>>> 41324,X,4,214
>>>> 41355,R,4,245
>>>> 41415,X,4,305
>>>> 41562,X,4,452
>>>> 41562,H,4,452
>>>> 41586,S,5,0
>>>>
>>>> Val
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>


From ruipbarradas at sapo.pt  Fri Oct 14 21:16:46 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 14 Oct 2016 20:16:46 +0100
Subject: [R] Incremental
In-Reply-To: <CAJOiR6aSU780Sr5demaUDT4ECUn5Q-PyE=_qj49=FY3oak4LvA@mail.gmail.com>
References: <CAJOiR6Z0Cu_OS_nF4WrW0FBbUVZphSzbi1pwRmYz403vjVxB8w@mail.gmail.com>
	<57FE9E38.1040800@sapo.pt>
	<CAJOiR6Z8mRnb-+C-QOfd6jqD7vB-8VkQCj+gGgbf7Cim=tkusw@mail.gmail.com>
	<57FF6230.5090609@sapo.pt>
	<CAJOiR6aSU780Sr5demaUDT4ECUn5Q-PyE=_qj49=FY3oak4LvA@mail.gmail.com>
Message-ID: <58012F1E.6030408@sapo.pt>

Hello,

You have to convert y1 to class "Date" first, then do date arithmetic. 
The complete code would be


dat<-read.table(text=" y1, flag
24-01-2016,S
24-02-2016,R
24-03-2016,X
24-04-2016,H
24-01-2016,S
24-11-2016,R
24-10-2016,R
24-02-2016,X
24-01-2016,H
24-11-2016,S
24-02-2016,R
24-10-2016,X
24-03-2016,H
24-04-2016,S
",sep=",",header=TRUE)

str(dat)   # See what we have, y1 is a factor
dat$y1 <- as.Date(dat$y1, format = "%d-%m-%Y")
str(dat)   # now y1 is a Date

dat$x1 <- cumsum(dat$flag == "S")
dat$z2 <- unlist(tapply(dat$y1, dat$x1, function(y) y - y[1]))
dat


Instead of y - y[1] you can also use ?difftime.

Rui Barradas

Em 14-10-2016 20:06, Val escreveu:
> Thank you Rui,
>
> It Worked!
>
> How about if the first variable is date format? Like the following
> dat<-read.table(text=" y1, flag
> 24-01-2016,S
> 24-02-2016,R
> 24-03-2016,X
> 24-04-2016,H
> 24-01-2016,S
> 24-11-2016,R
> 24-10-2016,R
> 24-02-2016,X
> 24-01-2016,H
> 24-11-2016,S
> 24-02-2016,R
> 24-10-2016,X
> 24-03-2016,H
> 24-04-2016,S
> ",sep=",",header=TRUE)
> dat
> dat$x1 <- cumsum(dat$flag == "S")
> dat$z2 <- unlist(tapply(dat$y1, dat$x1, function(y) y - y[1]))
>
> error message
> In Ops.factor(y, y[1]) : ?-? not meaningful for factors
>
>
>
> On Thu, Oct 13, 2016 at 5:30 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>> Hello,
>>
>> You must run the code to create x1 first, part 1), then part 2).
>> I've tested with your data and all went well, the result is the following.
>>
>>> dput(dat)
>> structure(list(y1 = c(39958L, 40058L, 40105L, 40294L, 40332L,
>> 40471L, 40493L, 40533L, 40718L, 40771L, 40829L, 40892L, 41056L,
>> 41110L, 41160L, 41222L, 41250L, 41289L, 41324L, 41355L, 41415L,
>> 41562L, 41562L, 41586L), flag = structure(c(3L, 2L, 4L, 1L, 3L,
>> 2L, 2L, 4L, 1L, 3L, 2L, 4L, 1L, 3L, 2L, 2L, 2L, 2L, 4L, 2L, 4L,
>> 4L, 1L, 3L), .Label = c("H", "R", "S", "X"), class = "factor"),
>>      x1 = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
>>      4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L), z2 = c(0L, 100L,
>>      147L, 336L, 0L, 139L, 161L, 201L, 386L, 0L, 58L, 121L, 285L,
>>      0L, 50L, 112L, 140L, 179L, 214L, 245L, 305L, 452L, 452L,
>>      0L)), .Names = c("y1", "flag", "x1", "z2"), row.names = c(NA,
>> -24L), class = "data.frame")
>>
>>
>> Rui Barradas
>>
>>
>> Em 12-10-2016 21:53, Val escreveu:
>>>
>>> Rui,
>>> Thank You!
>>>
>>> the second one gave me NULL.
>>> dat$z2 <- unlist(tapply(dat$y1, dat$x1, function(y) y - y[1]))
>>>
>>> dat$z2
>>> NULL
>>>
>>>
>>>
>>> On Wed, Oct 12, 2016 at 3:34 PM, Rui Barradas <ruipbarradas at sapo.pt>
>>> wrote:
>>>>
>>>> Hello,
>>>>
>>>> Seems simple:
>>>>
>>>>
>>>> # 1)
>>>> dat$x1 <- cumsum(dat$flag == "S")
>>>>
>>>> # 2)
>>>> dat$z2 <- unlist(tapply(dat$y1, dat$x1, function(y) y - y[1]))
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>>
>>>> Em 12-10-2016 21:15, Val escreveu:
>>>>>
>>>>>
>>>>> Hi all,
>>>>>
>>>>> I have a data set like
>>>>> dat<-read.table(text=" y1, flag
>>>>> 39958,S
>>>>> 40058,R
>>>>> 40105,X
>>>>> 40294,H
>>>>> 40332,S
>>>>> 40471,R
>>>>> 40493,R
>>>>> 40533,X
>>>>> 40718,H
>>>>> 40771,S
>>>>> 40829,R
>>>>> 40892,X
>>>>> 41056,H
>>>>> 41110,S
>>>>> 41160,R
>>>>> 41222,R
>>>>> 41250,R
>>>>> 41289,R
>>>>> 41324,X
>>>>> 41355,R
>>>>> 41415,X
>>>>> 41562,X
>>>>> 41562,H
>>>>> 41586,S
>>>>> ",sep=",",header=TRUE)
>>>>>
>>>>> First sort the data by y1.
>>>>> Then
>>>>> I want to create two columns .
>>>>> 1. the first new column is  (x1):  if flag is "S"  then  x1=1  and
>>>>> assign the following/subsequent rows 1 as well.   When we reach to
>>>>> the next "S"  then  x1=2 and the subsequent rows will be assigned to
>>>>> 2.
>>>>>
>>>>> 2. the second variable (z2). Within each x1 find the difference
>>>>> between the first y1 and subsequent y1 values
>>>>>
>>>>> Example  for the first few rows
>>>>>      y1,   flag, x1, z2
>>>>> 39958, S, 1,    0          z2 is calculated as     z2=(39958, 39958)
>>>>> 40058, R, 1, 100         z2 is calculated as     z2=(40058, 39958)
>>>>> 40105, X, 1, 147         z2 is calculated as     z2=(40105, 39958)
>>>>> 40294, H, 1, 336         z2 is calculated as     z2=(40294, 39958)
>>>>> 40332, S, 2,  0            z2 is calculated as     z2=(40332, 40332)
>>>>> etc
>>>>>
>>>>> Here is the complete output for the sample  data
>>>>> 39958,S,1,0
>>>>> 40058,R,1,100
>>>>> 40105,X,1,147
>>>>> 40294,H,1,336
>>>>> 40332,S,2,0
>>>>> 40471,R,2,139
>>>>> 40493,R,2,161
>>>>> 40533,X,2,201
>>>>> 40718,H,2,386
>>>>> 40771,S,3,0
>>>>> 40829,R,3,58
>>>>> 40892,X,3,121
>>>>> 41056,H,3,285
>>>>> 41110,S,4,0
>>>>> 41160,R,4,50
>>>>> 41222,R,4,112
>>>>> 41250,R,4,140
>>>>> 41289,R,4,179
>>>>> 41324,X,4,214
>>>>> 41355,R,4,245
>>>>> 41415,X,4,305
>>>>> 41562,X,4,452
>>>>> 41562,H,4,452
>>>>> 41586,S,5,0
>>>>>
>>>>> Val
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>


From oriolebaltimore at gmail.com  Sat Oct 15 00:28:38 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Fri, 14 Oct 2016 18:28:38 -0400
Subject: [R] pheatmap - clustering on some columns only
Message-ID: <CAL2fYnNRhmKcQt82yL3uXNW5LWU8=U7D4QP8h5jCA4bsaadUcA@mail.gmail.com>

Dear group,
I have a matrix (300 rows X 475columns).
The data is divided into many classes.
For examples:
475 columns are split into 3 categories - A, B and C

Is it possible to force clustering of columns in A followed by B and C.
I do not want to cluster whole matrix. I want to cluster by 3 categories.

Thanks in advance.

Adrian


From dwinsemius at comcast.net  Sat Oct 15 00:28:41 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Oct 2016 15:28:41 -0700
Subject: [R] Adjusting axis labels on lattice xyplot
In-Reply-To: <alpine.LNX.2.11.1610141153020.8550@localhost>
References: <alpine.LNX.2.11.1610141153020.8550@localhost>
Message-ID: <291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>


> On Oct 14, 2016, at 12:03 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  I've read chapters 7 and 8 in the Lattice book and do not see how to thin
> labels on the x and y axes of an xyplot(), and how to rotate the dates on
> the x axis for easier reading (rot did not do the job for me.)
> 
>  The data (as raindata.dat) and the existing plot (as precip.pdf) are
> attached.

The structure( .. ) call would need to be sourced:

> rain <- source("~/raindata.dat")
> str(rain)
List of 2
 $ value  :'data.frame':	341 obs. of  3 variables:
  ..$ station: Factor w/ 6 levels "0.3E","0.6W",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..$ date   : Factor w/ 62 levels "2013-12-01","2013-12-02",..: 32 33 34 35 36 37 38 39 40 41 ...
  ..$ amount : Factor w/ 48 levels "","0.00","0.01",..: 1 1 3 2 2 2 12 18 34 14 ...
 $ visible: logi TRUE

When you do that you can see the only the first item in the length2 list is likely to be useful:

> str(rain[[1]])
'data.frame':	341 obs. of  3 variables:
 $ station: Factor w/ 6 levels "0.3E","0.6W",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ date   : Factor w/ 62 levels "2013-12-01","2013-12-02",..: 32 33 34 35 36 37 38 39 40 41 ...
 $ amount : Factor w/ 48 levels "","0.00","0.01",..: 1 1 3 2 2 2 12 18 34 14 ...

#So re-assign#

rain <- rain[[1]]

And the date column is a factor. Fortunately the as.Date.factor function doesn't need as.chaacter anymore:

rain$date=as.Date(rain$date)


> 
>  The ploting command used is:
> 
> xyplot(rain$amount ~ rain$date | rain$station, main="Weather Stations",
> xlab="Date", ylab="Amount (inches)", pch=16, col=132)
> 
>  Please point me to the appropriate place in the book where the prepanel
> function to change the axis lable spacing and rotation is discussed.

The place on the ?xyplot help page to look is in the section on `scales`. There's no difficulty using 'rot' as long as it is in the correct place which in this instance is `x` sublist of the `scales` list

xyplot(amount ~ date | station, data=rain, main="Weather Stations",
    xlab="Date", ylab="Amount (inches)", pch=16, col=132, 
    scales=list(y=list(at=0:4), 
                x=list(at=seq(min(rain$date), max(rain$date), by='week'), rot=90) )
      )




> I
> expected it to be in chapter 8. Or, if there's another reference I should
> read, please point me to that.


> 
>  For some reason I've not yet tracked down, there is no longer help
> available within the R session (running in emacs with ESS) when I type, for
> example, ?xyplot. R returns the message that there's no documentation in the
> specified packages and libraries. Obviously something changed since I last
> used R.
> 
> Rich<raindata.dat><precip.pdf>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rshepard at appl-ecosys.com  Sat Oct 15 00:51:39 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 14 Oct 2016 15:51:39 -0700 (PDT)
Subject: [R] Adjusting axis labels on lattice xyplot
In-Reply-To: <291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>
References: <alpine.LNX.2.11.1610141153020.8550@localhost>
	<291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>
Message-ID: <alpine.LNX.2.11.1610141540310.8550@localhost>

On Fri, 14 Oct 2016, David Winsemius wrote:

>> rain <- source("~/raindata.dat")
>> str(rain)
> List of 2
> $ value  :'data.frame':	341 obs. of  3 variables:
>  ..$ station: Factor w/ 6 levels "0.3E","0.6W",..: 1 1 1 1 1 1 1 1 1 1 ...
>  ..$ date   : Factor w/ 62 levels "2013-12-01","2013-12-02",..: 32 33 34 35 36 37 38 39 40 41 ...
>  ..$ amount : Factor w/ 48 levels "","0.00","0.01",..: 1 1 3 2 2 2 12 18 34 14 ...
> $ visible: logi TRUE

David,

   I left the station as a factor and changed the date using
as.Date(as.character...) and the amount using as.numeric.

> When you do that you can see the only the first item in the length2 list
> is likely to be useful:

   I'm not seeing to what the 'List of 2' refers in the data.frame.

   This is the script I sourced:

rain <- read.csv("daily_records.csv", header=T, sep=",")
require(lattice)
rain$date <- as.Date(as.character(rain$date))
rain$amount <- as.numeric(rain$amount)
xyplot(rain$amount ~ rain$date | rain$station, main="Weather Stations", xlab="Date", ylab="Amount (inches)", pch=20, col=132)

   What did I do incorrectly here?

> And the date column is a factor. Fortunately the as.Date.factor function
> doesn't need as.chaacter anymore:

   Oh. Thanks.

> The place on the ?xyplot help page to look is in the section on `scales`.
> There's no difficulty using 'rot' as long as it is in the correct place
> which in this instance is `x` sublist of the `scales` list

> xyplot(amount ~ date | station, data=rain, main="Weather Stations",
>    xlab="Date", ylab="Amount (inches)", pch=16, col=132,
>    scales=list(y=list(at=0:4),
>                x=list(at=seq(min(rain$date), max(rain$date), by='week'), rot=90) )
>      )

   That's what I missed: where the scales command is placed, and
understanding how to use all the components.

   I need to figure out why I'm no longer seeing the help files. As far as I
know they should be loaded when I invoke R.

Thanks very much,

Rich


From joeceradini at gmail.com  Sat Oct 15 01:16:23 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Fri, 14 Oct 2016 17:16:23 -0600
Subject: [R] Split strings based on multiple patterns
Message-ID: <CAKq2vL6q2jQKwSZ54GxpccE641h8Oj65_Kxcg3VzDm0Nmsq80g@mail.gmail.com>

Afternoon,

I unfortunately inherited a dataframe with a column that has many fields
smashed together. My goal is to split the strings in the column into
separate columns based on patterns.

Example of what I'm working with:

ugly <- c("Water temp:14: F Waterbody type:Permanent Lake/Pond: Water
pH:Unkwn:
Conductivity:Unkwn: Water color: Clear: Water turbidity: clear:
Manmade:no  Permanence:permanent:  Max water depth: <3: Primary
substrate: Silt/Mud: Evidence of cattle grazing: none:
Shoreline Emergent Veg(%): 1-25: Fish present: yes: Fish species: unkwn: no
amphibians observed")
ugly

Far as I can tell, there is not a single pattern that would work for
splitting this string. Splitting on ":" is close but not quite consistent.
Each of these attributes should be a separate column:

attributes <- c("Water temp", "Waterbody type", "Water pH", "Conductivity",
"Water color", "Water turbidity", "Manmade", "Permanence", "Max water
depth", "Primary substrate", "Evidence of cattle grazing", "Shoreline
Emergent Veg(%)", "Fish present", "Fish species")

So, conceptually, I want to do something like this, where the string is
split for each of the patterns in attributes. However, strsplit only uses
the 1st value of attributes
strsplit(ugly, attributes)

Should I loop through the values of "attributes"?
Is there an argument in strsplit I'm missing that will do what I want?
Different approach altogether?

Thanks! Happy Friday.
Joe

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Oct 15 01:46:05 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Oct 2016 16:46:05 -0700
Subject: [R] Adjusting axis labels on lattice xyplot
In-Reply-To: <alpine.LNX.2.11.1610141540310.8550@localhost>
References: <alpine.LNX.2.11.1610141153020.8550@localhost>
	<291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>
	<alpine.LNX.2.11.1610141540310.8550@localhost>
Message-ID: <58836C90-708D-41AF-B62B-2634D36CF003@comcast.net>


> On Oct 14, 2016, at 3:51 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Fri, 14 Oct 2016, David Winsemius wrote:
> 
>>> rain <- source("~/raindata.dat")
>>> str(rain)
>> List of 2
>> $ value  :'data.frame':	341 obs. of  3 variables:
>> ..$ station: Factor w/ 6 levels "0.3E","0.6W",..: 1 1 1 1 1 1 1 1 1 1 ...
>> ..$ date   : Factor w/ 62 levels "2013-12-01","2013-12-02",..: 32 33 34 35 36 37 38 39 40 41 ...
>> ..$ amount : Factor w/ 48 levels "","0.00","0.01",..: 1 1 3 2 2 2 12 18 34 14 ...
>> $ visible: logi TRUE
> 
> David,
> 
>  I left the station as a factor and changed the date using
> as.Date(as.character...) and the amount using as.numeric.
> 
>> When you do that you can see the only the first item in the length2 list
>> is likely to be useful:
> 
>  I'm not seeing to what the 'List of 2' refers in the data.frame.
> 
>  This is the script I sourced:
> 
> rain <- read.csv("daily_records.csv", header=T, sep=",")
> require(lattice)
> rain$date <- as.Date(as.character(rain$date))
> rain$amount <- as.numeric(rain$amount)
> xyplot(rain$amount ~ rain$date | rain$station, main="Weather Stations", xlab="Date", ylab="Amount (inches)", pch=20, col=132)
> 
>  What did I do incorrectly here?

Well, you didn't send a text file with the contents of "daily_records.csv"; rather you sent a text file that was R code that would return a data object. I assigned it to the name `rain` before I realized it was a two item list. I then fixed the problems that assignment and the factor Dates presented so that I could then give a `data=rain` parameter to the xyplot function.
> 
> 
>> And the date column is a factor. Fortunately the as.Date.factor function
>> doesn't need as.chaacter anymore:
> 
>  Oh. Thanks.
> 
>> The place on the ?xyplot help page to look is in the section on `scales`.
>> There's no difficulty using 'rot' as long as it is in the correct place
>> which in this instance is `x` sublist of the `scales` list
> 
>> xyplot(amount ~ date | station, data=rain, main="Weather Stations",
>>   xlab="Date", ylab="Amount (inches)", pch=16, col=132,
>>   scales=list(y=list(at=0:4),
>>               x=list(at=seq(min(rain$date), max(rain$date), by='week'), rot=90) )
>>     )

Notice that the formula has just the column names rather than using `$`. But need to give `rain$date` to functions in hte scales list. It always seemed to me that the evaluation of names inside the scales list should also be evaluated inside the `data` environment but Deepayan didn't design it that way, so you need to "reach out" to get them pulled back in.

> 
>  That's what I missed: where the scales command is placed, and
> understanding how to use all the components.
> 
>  I need to figure out why I'm no longer seeing the help files. As far as I
> know they should be loaded when I invoke R.

So typing ?xyplot at the console doesn't bring up a help page? That would imply that you need to reinstall R.
> 
> Thanks very much,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Oct 15 01:49:19 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Oct 2016 16:49:19 -0700
Subject: [R] Split strings based on multiple patterns
In-Reply-To: <CAKq2vL6q2jQKwSZ54GxpccE641h8Oj65_Kxcg3VzDm0Nmsq80g@mail.gmail.com>
References: <CAKq2vL6q2jQKwSZ54GxpccE641h8Oj65_Kxcg3VzDm0Nmsq80g@mail.gmail.com>
Message-ID: <B8F28C57-A88B-4EDE-B6ED-B66D8E462452@comcast.net>


> On Oct 14, 2016, at 4:16 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
> 
> Afternoon,
> 
> I unfortunately inherited a dataframe with a column that has many fields
> smashed together. My goal is to split the strings in the column into
> separate columns based on patterns.
> 
> Example of what I'm working with:
> 
> ugly <- c("Water temp:14: F Waterbody type:Permanent Lake/Pond: Water
> pH:Unkwn:
> Conductivity:Unkwn: Water color: Clear: Water turbidity: clear:
> Manmade:no  Permanence:permanent:  Max water depth: <3: Primary
> substrate: Silt/Mud: Evidence of cattle grazing: none:
> Shoreline Emergent Veg(%): 1-25: Fish present: yes: Fish species: unkwn: no
> amphibians observed")
> ugly
> 
> Far as I can tell, there is not a single pattern that would work for
> splitting this string. Splitting on ":" is close but not quite consistent.
> Each of these attributes should be a separate column:
> 
> attributes <- c("Water temp", "Waterbody type", "Water pH", "Conductivity",
> "Water color", "Water turbidity", "Manmade", "Permanence", "Max water
> depth", "Primary substrate", "Evidence of cattle grazing", "Shoreline
> Emergent Veg(%)", "Fish present", "Fish species")
> 
> So, conceptually, I want to do something like this, where the string is
> split for each of the patterns in attributes. However, strsplit only uses
> the 1st value of attributes
> strsplit(ugly, attributes)
> 
> Should I loop through the values of "attributes"?
> Is there an argument in strsplit I'm missing that will do what I want?
> Different approach altogether?
> 
> Thanks! Happy Friday.
> Joe
> 
> 	[[alternative HTML version deleted]]

Need to post in plain text. We cannot see where your "carriage returns" are located in that data. HTML uses some other character(s?) that doesn't get translated by our mailserver.


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

Yes, please do read that.

> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rshepard at appl-ecosys.com  Sat Oct 15 01:50:18 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 14 Oct 2016 16:50:18 -0700 (PDT)
Subject: [R] Adjusting axis labels on lattice xyplot
In-Reply-To: <58836C90-708D-41AF-B62B-2634D36CF003@comcast.net>
References: <alpine.LNX.2.11.1610141153020.8550@localhost>
	<291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>
	<alpine.LNX.2.11.1610141540310.8550@localhost>
	<58836C90-708D-41AF-B62B-2634D36CF003@comcast.net>
Message-ID: <alpine.LNX.2.11.1610141648490.8550@localhost>

On Fri, 14 Oct 2016, David Winsemius wrote:

> Notice that the formula has just the column names rather than using `$`.
> But need to give `rain$date` to functions in hte scales list. It always
> seemed to me that the evaluation of names inside the scales list should
> also be evaluated inside the `data` environment but Deepayan didn't design
> it that way, so you need to "reach out" to get them pulled back in.

David,

   Mea culpa. I left off the data argument.

> So typing ?xyplot at the console doesn't bring up a help page? That would
> imply that you need to reinstall R.

   Will rebuild and re-install tomorrow morning.

   Thanks again.

Carpe weekend,

Rich


From joeceradini at gmail.com  Sat Oct 15 03:53:08 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Fri, 14 Oct 2016 19:53:08 -0600
Subject: [R] Split strings based on multiple patterns (plain text)
Message-ID: <CAKq2vL4v3CDpRGUY=0U4z_2shTMSirJud+omx=jNpXOyXqug=A@mail.gmail.com>

Hopefully this looks better. I did not realize gmail default was html.

I have a dataframe with a column that has many field smashed together.
I need to split the strings in the column into separate columns based
on patterns.

Example of a string that needs to be split:

ugly <- c("Water temp:14: F Waterbody type:Permanent Lake/Pond: Water
pH:Unkwn: Conductivity:Unkwn: Water color: Clear: Water turbidity:
clear: Manmade:no  Permanence:permanent:  Max water depth: <3: Primary
substrate: Silt/Mud: Evidence of cattle grazing: none: Shoreline
Emergent Veg(%): 1-25: Fish present: yes: Fish species: unkwn: no
amphibians observed")
ugly

Far as I can tell, there is not a single pattern that would work for
splitting. Splitting on ":" is close, but not quite right. Each of the
below attributes should be in a separate column, and are present in
the string (above) that needs to be split:

attributes <- c("Water temp", "Waterbody type", "Water pH",
"Conductivity", "Water color", "Water turbidity", "Manmade",
"Permanence", "Max water depth", "Primary substrate", "Evidence of
cattle grazing", "Shoreline Emergent Veg(%)", "Fish present", "Fish
species")

Conceptually, I want to use the vector of attributes to split the
string. However, strsplit only uses the 1st value of the attributes
object:

strplit(ugly, attributes).

Should I loop through the values of "attributes"?
Is there an argument in strsplit I'm missing that will do what I want?
Different approach altogether?

Thanks! Happy Friday.
Joe


From joeceradini at gmail.com  Sat Oct 15 03:55:41 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Fri, 14 Oct 2016 19:55:41 -0600
Subject: [R] Split strings based on multiple patterns (plain text)
In-Reply-To: <CAKq2vL4v3CDpRGUY=0U4z_2shTMSirJud+omx=jNpXOyXqug=A@mail.gmail.com>
References: <CAKq2vL4v3CDpRGUY=0U4z_2shTMSirJud+omx=jNpXOyXqug=A@mail.gmail.com>
Message-ID: <CAKq2vL7X3sPqwxap4bQ_mTCrAP0+20DdyjNjQTXC7XkPsSuwbA@mail.gmail.com>

should be strsplit(ugly, attributes) not strplit(ugly, attributes)....

On Fri, Oct 14, 2016 at 7:53 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
> Hopefully this looks better. I did not realize gmail default was html.
>
> I have a dataframe with a column that has many field smashed together.
> I need to split the strings in the column into separate columns based
> on patterns.
>
> Example of a string that needs to be split:
>
> ugly <- c("Water temp:14: F Waterbody type:Permanent Lake/Pond: Water
> pH:Unkwn: Conductivity:Unkwn: Water color: Clear: Water turbidity:
> clear: Manmade:no  Permanence:permanent:  Max water depth: <3: Primary
> substrate: Silt/Mud: Evidence of cattle grazing: none: Shoreline
> Emergent Veg(%): 1-25: Fish present: yes: Fish species: unkwn: no
> amphibians observed")
> ugly
>
> Far as I can tell, there is not a single pattern that would work for
> splitting. Splitting on ":" is close, but not quite right. Each of the
> below attributes should be in a separate column, and are present in
> the string (above) that needs to be split:
>
> attributes <- c("Water temp", "Waterbody type", "Water pH",
> "Conductivity", "Water color", "Water turbidity", "Manmade",
> "Permanence", "Max water depth", "Primary substrate", "Evidence of
> cattle grazing", "Shoreline Emergent Veg(%)", "Fish present", "Fish
> species")
>
> Conceptually, I want to use the vector of attributes to split the
> string. However, strsplit only uses the 1st value of the attributes
> object:
>
> strplit(ugly, attributes).
>
> Should I loop through the values of "attributes"?
> Is there an argument in strsplit I'm missing that will do what I want?
> Different approach altogether?
>
> Thanks! Happy Friday.
> Joe



-- 
Cooperative Fish and Wildlife Research Unit
Zoology and Physiology Dept.
University of Wyoming
JoeCeradini at gmail.com / 914.707.8506
wyocoopunit.org


From dwinsemius at comcast.net  Sat Oct 15 08:40:49 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Oct 2016 23:40:49 -0700
Subject: [R] Split strings based on multiple patterns (plain text)
In-Reply-To: <CAKq2vL4v3CDpRGUY=0U4z_2shTMSirJud+omx=jNpXOyXqug=A@mail.gmail.com>
References: <CAKq2vL4v3CDpRGUY=0U4z_2shTMSirJud+omx=jNpXOyXqug=A@mail.gmail.com>
Message-ID: <F0F96A33-8EB6-4C2C-A34A-6173648AC698@comcast.net>


> On Oct 14, 2016, at 6:53 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
> 
> Hopefully this looks better. I did not realize gmail default was html.
> 
> I have a dataframe with a column that has many field smashed together.
> I need to split the strings in the column into separate columns based
> on patterns.
> 
> Example of a string that needs to be split:
> 
> ugly <- c("Water temp:14: F Waterbody type:Permanent Lake/Pond: Water
> pH:Unkwn: Conductivity:Unkwn: Water color: Clear: Water turbidity:
> clear: Manmade:no  Permanence:permanent:  Max water depth: <3: Primary
> substrate: Silt/Mud: Evidence of cattle grazing: none: Shoreline
> Emergent Veg(%): 1-25: Fish present: yes: Fish species: unkwn: no
> amphibians observed")
> ugly
> 
> Far as I can tell, there is not a single pattern that would work for
> splitting. Splitting on ":" is close, but not quite right. Each of the
> below attributes should be in a separate column, and are present in
> the string (above) that needs to be split:
> 
> attributes <- c("Water temp", "Waterbody type", "Water pH",
> "Conductivity", "Water color", "Water turbidity", "Manmade",
> "Permanence", "Max water depth", "Primary substrate", "Evidence of
> cattle grazing", "Shoreline Emergent Veg(%)", "Fish present", "Fish
> species")
> 
> Conceptually, I want to use the vector of attributes to split the
> string. However, strsplit only uses the 1st value of the attributes
> object:
> 
> strplit(ugly, attributes).

I tried this:

strsplit( ugly, split=paste0(attributes, collapse="|")  )

And noticed soem of hte attributes were not actually splitting so went back and did the data entry after making sure that there were no "\n"'s in the middle of attribute names:

dput(attributes)
c("Water temp", "Waterbody type", "Water pH", "Conductivity", 
"Water color", "Water turbidity", "Manmade", "Permanence", "Max water depth", 
"Primary substrate", "Evidence of cattle grazing", "Shoreline Emergent Veg(%)", 
"Fish present", "Fish species")

strsplit( ugly, split=paste0(attributes, collapse="|")  )
[[1]]
 [1] ""                                                                                                        
 [2] ":14: F "                                                                                                 
 [3] ":Permanent Lake/Pond: Water\npH:Unkwn: "                                                                 
 [4] ":Unkwn: "                                                                                                
 [5] ": Clear: "                                                                                               
 [6] ":\nclear: "                                                                                              
 [7] ":no  "                                                                                                   
 [8] ":permanent:  "                                                                                           
 [9] ": <3: Primary\nsubstrate: Silt/Mud: Evidence of cattle grazing: none: Shoreline\nEmergent Veg(%): 1-25: "
[10] ": yes: Fish species: unkwn: no\namphibians observed"        

> 
> Should I loop through the values of "attributes"?
> Is there an argument in strsplit I'm missing that will do what I want? \\

I don't think strsplit has such an argument. There may be packages that will support this. Perhaps the gubfn package?


> Different approach altogether?
> 
> Thanks! Happy Friday.
> Joe
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From anze.dejak at gmail.com  Fri Oct 14 20:52:06 2016
From: anze.dejak at gmail.com (=?UTF-8?Q?An=C5=BEe_Dejak?=)
Date: Fri, 14 Oct 2016 20:52:06 +0200
Subject: [R] Difficulties with setting working directory
Message-ID: <CAE8BV_Uk5iyPdZvssjWk6DTXsfFvv4htvi=mqL+PDpdrehHrmg@mail.gmail.com>

Greetings,

Firstly, I'd hope this is the correct e-mail address to ask about specific
problems refering to problems with R. If it isn't, I kindly ask of you to
re-direct me to the correct contact person.

So, the thing with my version of R (I'm using RStudio for R x64 3.3.0 in,
currently, Windows 7) is, that I'm able to set the working directory
temporary (through using setwd() function), but once I try to set it
permanently (through "Session -> Set Working Directory -> Choose
Directory..."), this error appears: Error in setwd("~/...") : cannot change
working directory.

As I've seen online on certain forums, the problem, supposedly, is that R
in Windows is unable to recognize the ~ sign. But without it, I'm unable to
set the working directory for more than a session.

I'd hope you have a possible answer to this error.

Thank you for your time and for reading this long e-mail and I hope you
have a fine day, An?e D.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Oct 15 12:06:26 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 15 Oct 2016 21:06:26 +1100
Subject: [R] Return.clean () - PerformanceAnalytics package
In-Reply-To: <1476467282814.55989@kent.ac.uk>
References: <1476467282814.55989@kent.ac.uk>
Message-ID: <CA+8X3fVQknfe2o6329aYKQCvzyyVtYgQX2robDFDza6fcUx-FA@mail.gmail.com>

Hi T,
Have you tried converting "clearntest" or "data" into a time series?

Jim


On Sat, Oct 15, 2016 at 4:47 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
> Dear all,
>
> I am trying to clean return data using the Return.clean() function in the PerformanceAnalytics package. Hence, my code looks as follows but I get an error message.
>
>
>
> cleantest <- read.csv("D:/Studie_vola_difference/cleantest.csv")
> data<-as.vector(cleantest)
> test<-Return.clean(data,method="boudt",alpha=0.01)
>
> Error in checkData(R, method = "xts") :
> The data cannot be converted into a time series.  If you are trying to pass in names from a data object with one column, you should use the form 'data[rows, columns, drop = FALSE]'.  Rownames should have standard date formats, such as '1985-03-15'.
>
>
>
> Can anybody help me on this error? What is wrong with my code?
>
>
>
> Thanks for your support.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Oct 15 12:12:37 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 15 Oct 2016 21:12:37 +1100
Subject: [R] Difficulties with setting working directory
In-Reply-To: <CAE8BV_Uk5iyPdZvssjWk6DTXsfFvv4htvi=mqL+PDpdrehHrmg@mail.gmail.com>
References: <CAE8BV_Uk5iyPdZvssjWk6DTXsfFvv4htvi=mqL+PDpdrehHrmg@mail.gmail.com>
Message-ID: <CA+8X3fXKk3E1fcCNYAV8PiVdSopf-XVUy+dAbdNFoDYtcqtuBA@mail.gmail.com>

Hi Anze,
I'm not sure that this will work on Windows, but you can create a
function named ".First" (note the leading period) with something like
this:

.First<-function() setwd("C:/Users/anze")

To do this, start a session, enter the above line and then quit the
session, saving the current workspace. When you start R again, it
should change to that working directory. Of course you should make
sure what your home directory is.

Jim


On Sat, Oct 15, 2016 at 5:52 AM, An?e Dejak <anze.dejak at gmail.com> wrote:
> Greetings,
>
> Firstly, I'd hope this is the correct e-mail address to ask about specific
> problems refering to problems with R. If it isn't, I kindly ask of you to
> re-direct me to the correct contact person.
>
> So, the thing with my version of R (I'm using RStudio for R x64 3.3.0 in,
> currently, Windows 7) is, that I'm able to set the working directory
> temporary (through using setwd() function), but once I try to set it
> permanently (through "Session -> Set Working Directory -> Choose
> Directory..."), this error appears: Error in setwd("~/...") : cannot change
> working directory.
>
> As I've seen online on certain forums, the problem, supposedly, is that R
> in Windows is unable to recognize the ~ sign. But without it, I'm unable to
> set the working directory for more than a session.
>
> I'd hope you have a possible answer to this error.
>
> Thank you for your time and for reading this long e-mail and I hope you
> have a fine day, An?e D.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Oct 15 12:20:03 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 15 Oct 2016 06:20:03 -0400
Subject: [R] Difficulties with setting working directory
In-Reply-To: <CAE8BV_Uk5iyPdZvssjWk6DTXsfFvv4htvi=mqL+PDpdrehHrmg@mail.gmail.com>
References: <CAE8BV_Uk5iyPdZvssjWk6DTXsfFvv4htvi=mqL+PDpdrehHrmg@mail.gmail.com>
Message-ID: <09d482cb-2b15-4ac4-9026-99eb098e5828@gmail.com>

On 14/10/2016 2:52 PM, An?e Dejak wrote:
> Greetings,
>
> Firstly, I'd hope this is the correct e-mail address to ask about specific
> problems refering to problems with R. If it isn't, I kindly ask of you to
> re-direct me to the correct contact person.
>
> So, the thing with my version of R (I'm using RStudio for R x64 3.3.0 in,
> currently, Windows 7) is, that I'm able to set the working directory
> temporary (through using setwd() function), but once I try to set it
> permanently (through "Session -> Set Working Directory -> Choose
> Directory..."), this error appears: Error in setwd("~/...") : cannot change
> working directory.
>
> As I've seen online on certain forums, the problem, supposedly, is that R
> in Windows is unable to recognize the ~ sign. But without it, I'm unable to
> set the working directory for more than a session.

That explanation is incorrect.  R in Windows simulates a Unix shell 
interpretation of ~ .  See ?path.expand for an explanation, and run

path.expand("~")

to see how it is currently being expanded for you.

However, the fact that R interprets ~ doesn't mean it is always possible 
to use setwd() to go there.

It's also possible that RStudio has a bug, and is trying to change to a 
nonexistent directory before displaying choices to you, assuming you're 
getting the error before being offered the dialog to pick a directory.
If that's the case, you might be able to avoid the problem by asking R 
to make the change:

setwd(choose.dir())

or

setwd("a/specific/directory")

Duncan Murdoch


From ggrothendieck at gmail.com  Sat Oct 15 13:50:28 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 15 Oct 2016 07:50:28 -0400
Subject: [R] Split strings based on multiple patterns
In-Reply-To: <CAKq2vL6q2jQKwSZ54GxpccE641h8Oj65_Kxcg3VzDm0Nmsq80g@mail.gmail.com>
References: <CAKq2vL6q2jQKwSZ54GxpccE641h8Oj65_Kxcg3VzDm0Nmsq80g@mail.gmail.com>
Message-ID: <CAP01uRmLz+1i+hh5qEP8Q2gRwEzLCU0Tya-VW1XXVt6CS0KTUw@mail.gmail.com>

Replace newlines and colons with a space since they seem to be junk,
generate a pattern to replace the attributes with a comma and do the
replacement and finally read in what is left into a data frame using
the attributes as column names.

(I have indented each line of code below by 2 spaces so if any line
starts before that then it's been wrapped around by the email and
needs to be adjusted.)

  attributes <-
  c("Water temp", "Waterbody type", "Water pH", "Conductivity",
  "Water color", "Water turbidity", "Manmade", "Permanence", "Max water depth",
  "Primary substrate", "Evidence of cattle grazing", "Shoreline
Emergent Veg(%)",
  "Fish present", "Fish species")

  ugly2 <- gsub("[:\n]", " ", ugly)

  pat <- paste(gsub("([[:punct:]])", ".", attributes), collapse = "|")
  ugly3 <- gsub(pat, ",", ugly2)

  dd <- read.table(text = ugly3, sep = ",", strip.white = TRUE,
col.names = c("", attributes))[-1]


On Fri, Oct 14, 2016 at 7:16 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
> Afternoon,
>
> I unfortunately inherited a dataframe with a column that has many fields
> smashed together. My goal is to split the strings in the column into
> separate columns based on patterns.
>
> Example of what I'm working with:
>
> ugly <- c("Water temp:14: F Waterbody type:Permanent Lake/Pond: Water
> pH:Unkwn:
> Conductivity:Unkwn: Water color: Clear: Water turbidity: clear:
> Manmade:no  Permanence:permanent:  Max water depth: <3: Primary
> substrate: Silt/Mud: Evidence of cattle grazing: none:
> Shoreline Emergent Veg(%): 1-25: Fish present: yes: Fish species: unkwn: no
> amphibians observed")
> ugly
>
> Far as I can tell, there is not a single pattern that would work for
> splitting this string. Splitting on ":" is close but not quite consistent.
> Each of these attributes should be a separate column:
>
> attributes <- c("Water temp", "Waterbody type", "Water pH", "Conductivity",
> "Water color", "Water turbidity", "Manmade", "Permanence", "Max water
> depth", "Primary substrate", "Evidence of cattle grazing", "Shoreline
> Emergent Veg(%)", "Fish present", "Fish species")
>
> So, conceptually, I want to do something like this, where the string is
> split for each of the patterns in attributes. However, strsplit only uses
> the 1st value of attributes
> strsplit(ugly, attributes)
>
> Should I loop through the values of "attributes"?
> Is there an argument in strsplit I'm missing that will do what I want?
> Different approach altogether?
>
> Thanks! Happy Friday.
> Joe
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From tr206 at kent.ac.uk  Sat Oct 15 14:27:26 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sat, 15 Oct 2016 12:27:26 +0000
Subject: [R] Return.clean () - PerformanceAnalytics package
In-Reply-To: <CA+8X3fVQknfe2o6329aYKQCvzyyVtYgQX2robDFDza6fcUx-FA@mail.gmail.com>
References: <1476467282814.55989@kent.ac.uk>,
	<CA+8X3fVQknfe2o6329aYKQCvzyyVtYgQX2robDFDza6fcUx-FA@mail.gmail.com>
Message-ID: <1476534454885.65672@kent.ac.uk>

Hi Jim,
no, I calculated the return series in Excel and imported the data into R. Then I transformed the data into a vector as I need a vector object of asset returns and did the calculation. 

Kind regards,
T.
________________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: 15 October 2016 11:06
To: T.Riedle
Cc: R-help at r-project.org
Subject: Re: [R] Return.clean () - PerformanceAnalytics package

Hi T,
Have you tried converting "clearntest" or "data" into a time series?

Jim


On Sat, Oct 15, 2016 at 4:47 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
> Dear all,
>
> I am trying to clean return data using the Return.clean() function in the PerformanceAnalytics package. Hence, my code looks as follows but I get an error message.
>
>
>
> cleantest <- read.csv("D:/Studie_vola_difference/cleantest.csv")
> data<-as.vector(cleantest)
> test<-Return.clean(data,method="boudt",alpha=0.01)
>
> Error in checkData(R, method = "xts") :
> The data cannot be converted into a time series.  If you are trying to pass in names from a data object with one column, you should use the form 'data[rows, columns, drop = FALSE]'.  Rownames should have standard date formats, such as '1985-03-15'.
>
>
>
> Can anybody help me on this error? What is wrong with my code?
>
>
>
> Thanks for your support.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_grt at yahoo.fr  Sat Oct 15 15:29:46 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Sat, 15 Oct 2016 15:29:46 +0200
Subject: [R] ggplot() and annotation_custom()
Message-ID: <a583444c-f305-4364-6d2d-79a0af277246@yahoo.fr>

Until now I was using plot() and I check the possibility to shift to 
ggplot2.

All is OK until now except to write text out of the plotting region 
[equivalent of par(xpd=TRUE); text(x, y, labels)].

I have found using google recommendation to use annotation_custom() but 
I still failed to print text out of the plotting region:

library("ggplot2")

df <- data.frame(x = 1:10, y = 1:10)
ggplot(data=df, mapping=aes(x, y))+
   geom_line(color="black") +
   annotation_custom(
   grob = textGrob(label="essai"), xmin=2.5, xmax=5, ymin=10, ymax=11
) + theme(plot.margin = unit(c(1.5, 1, 0.5, 0.5), "cm"))

If someone has the solution, I could continue to explore ggplot2 !

Thanks a lot,

Marc


From mviljamaa at kapsi.fi  Sat Oct 15 17:24:35 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Sat, 15 Oct 2016 18:24:35 +0300
Subject: [R] How to read prediction intervals given by predict()?
Message-ID: <7a0e84560370b6de2765d33772093e65@kapsi.fi>

My conception of prediction intervals is the following:

"a prediction interval gives an interval within which we expect next y_i 
to lie with a specified probability"

So when using predict() for my model:

predict(fit4, interval="prediction")[1:20,]

I get:

         fit      lwr      upr
1  491.1783 381.3486 601.0081
2  515.4883 405.7128 625.2638
3  581.5957 447.9569 715.2344
4  522.4979 412.5086 632.4872
5  604.6008 492.2796 716.9221
6  520.2881 410.3108 630.2655
7  620.7379 507.9045 733.5713
8  621.0925 505.8731 736.3119
9  527.1810 417.2760 637.0859
10 519.4651 406.1622 632.7680
11 622.0051 512.0082 732.0021
12 536.6924 424.3415 649.0434
13 504.8618 394.9034 614.8202
14 545.5920 433.6530 657.5309
15 475.6153 362.4383 588.7923
16 462.5341 350.6090 574.4593
17 559.0888 448.1212 670.0564
18 544.0051 432.0583 655.9519
19 471.1450 355.2377 587.0523
20 604.3028 470.6925 737.9130

Now since the prediction interval gives the interval within which the 
_next_ y_i will fall, then how to read the above results? Does the 
previous row's "lwr" and "upr" refer to the next row's "fit"'s interval?


From ceritaahmad at gmail.com  Sat Oct 15 12:37:57 2016
From: ceritaahmad at gmail.com (Ahmad Nursalim)
Date: Sat, 15 Oct 2016 17:37:57 +0700
Subject: [R]  Error in solve.default(object$hessian)
Message-ID: <CAGGEV7Mgs=Pp2wrVe+moX1byK52a2oHut1G5ny82Eia6jxt_kA@mail.gmail.com>

I have the problem use R

Error in solve.default(object$hessian)

system is computationally singular: reciprocal condition number = 1.42892e-30


what is the problem ?and what it means
help me
--

	[[alternative HTML version deleted]]


From quanghuy1258 at gmail.com  Sat Oct 15 18:19:14 2016
From: quanghuy1258 at gmail.com (=?UTF-8?B?SHV5IE5ndXnhu4Vu?=)
Date: Sat, 15 Oct 2016 23:19:14 +0700
Subject: [R] Problem with sample(...,size = 1000000000,...)
Message-ID: <CADR9BXRYMGW3gpL7j+7id=zsC1RbdBf5uNZuJJVM02Oi5gJu2A@mail.gmail.com>

When I ran this code:
"
x<-sample(1:5,1000000000,TRUE,c(0.1,0.2,0.4,0.2,0.1))
print(table(x)/1000000000)
plot(table(x)/1000000000,type="h",xlab="x",ylab="P(x)")
"
My laptop was frozen and didn't respond. Although I used ctrl+alt+del to
terminate r program, my laptop still did nothing. And I must restart my
laptop immediately or my laptop might be broken down.
Thus, I think in the future the program should have something to control
the memory and time when it is running and can be terminated if necessary.

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Sat Oct 15 18:57:07 2016
From: valkremk at gmail.com (Val)
Date: Sat, 15 Oct 2016 11:57:07 -0500
Subject: [R] lag, count
Message-ID: <CAJOiR6YdmwzgjJng8_1Cz0svdOURQuBLOvOJS1TL6aotyrFw=w@mail.gmail.com>

Hi all,

I want sort the data by ID and Y2 then count the number of rows within
IDs.  Assign a "flag" variable to reach row starting from first  to
the last row.
For instance, in the following data ID "1" has three rows   and each
row is assigned flag sequentially 1, 2,3.

2. In the second step, within each ID, I want get the difference
between the subsequent row values of y1 and y2(date) values.
Within each ID the first value of y1diff  and y2diff are always 0. The
second values for each will  be the current row minus the previous
row.



lag<-read.table(text=" ID, y1, y2
ID,Y1,y2
1,0,12/25/2014
1,125,9/15/2015
1,350,1/30/2016
2,0,12/25/2012
2,450,9/15/2014
2,750,1/30/2016
2,  656, 11/30/2016
",sep=",",header=TRUE)

output looks like as follows

ID,flag,y1,y2,y1dif,y2dif
1,1,0,12/25/2014,0,0
1,2,125,9/15/2015,125,264
1,3,350,1/30/2016,225,137
2,1,0,12/25/2012,0,0
2,2,450,9/15/2014,450,629
2,3,750,1/30/2016,300,502
2, 4, 656 11/30/2016, -94, 305

Thank you


From ruipbarradas at sapo.pt  Sat Oct 15 20:45:50 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 15 Oct 2016 19:45:50 +0100
Subject: [R] lag, count
In-Reply-To: <CAJOiR6YdmwzgjJng8_1Cz0svdOURQuBLOvOJS1TL6aotyrFw=w@mail.gmail.com>
References: <CAJOiR6YdmwzgjJng8_1Cz0svdOURQuBLOvOJS1TL6aotyrFw=w@mail.gmail.com>
Message-ID: <5802795E.9010807@sapo.pt>

Hello,

Try the following.


lag<-read.table(text=" ID, y1, y2
1,0,12/25/2014
1,125,9/15/2015
1,350,1/30/2016
2,0,12/25/2012
2,450,9/15/2014
2,750,1/30/2016
2,  656, 11/30/2016
",sep=",",header=TRUE)

str(lag)
lag$y2 <- as.Date(lag$y2, format = "%m/%d/%Y")
str(lag)

# 1)
flag <- ave(lag$ID, lag$ID, FUN = seq_along)
lag2 <- cbind(lag[1], flag, lag[-1])

# 2)
y1dif <- ave(lag2$y1, lag2$ID, FUN = function(y) c(0, y[-1] - 
y[-length(y)]))
y2dif <- unlist(tapply(lag2$y2, lag2$ID, FUN = function(y) c(0, y[-1] - 
y[-length(y)])))

lag2 <- cbind(lag2, y1dif, y2dif)
lag2

Hope this helps,

Rui Barradas

Em 15-10-2016 17:57, Val escreveu:
> Hi all,
>
> I want sort the data by ID and Y2 then count the number of rows within
> IDs.  Assign a "flag" variable to reach row starting from first  to
> the last row.
> For instance, in the following data ID "1" has three rows   and each
> row is assigned flag sequentially 1, 2,3.
>
> 2. In the second step, within each ID, I want get the difference
> between the subsequent row values of y1 and y2(date) values.
> Within each ID the first value of y1diff  and y2diff are always 0. The
> second values for each will  be the current row minus the previous
> row.
>
>
>
> lag<-read.table(text=" ID, y1, y2
> ID,Y1,y2
> 1,0,12/25/2014
> 1,125,9/15/2015
> 1,350,1/30/2016
> 2,0,12/25/2012
> 2,450,9/15/2014
> 2,750,1/30/2016
> 2,  656, 11/30/2016
> ",sep=",",header=TRUE)
>
> output looks like as follows
>
> ID,flag,y1,y2,y1dif,y2dif
> 1,1,0,12/25/2014,0,0
> 1,2,125,9/15/2015,125,264
> 1,3,350,1/30/2016,225,137
> 2,1,0,12/25/2012,0,0
> 2,2,450,9/15/2014,450,629
> 2,3,750,1/30/2016,300,502
> 2, 4, 656 11/30/2016, -94, 305
>
> Thank you
>


From ruipbarradas at sapo.pt  Sat Oct 15 20:54:33 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 15 Oct 2016 19:54:33 +0100
Subject: [R] lag, count
In-Reply-To: <5802795E.9010807@sapo.pt>
References: <CAJOiR6YdmwzgjJng8_1Cz0svdOURQuBLOvOJS1TL6aotyrFw=w@mail.gmail.com>
	<5802795E.9010807@sapo.pt>
Message-ID: <58027B69.5070403@sapo.pt>

I forgot about the sorting part and assumed the data.frame was already 
sorted. If not, after converting y2 to class Date, you can do

lag <- lag[order(lag$ID, lag$y2), ]

Rui Barradas

Em 15-10-2016 19:45, Rui Barradas escreveu:
> Hello,
>
> Try the following.
>
>
> lag<-read.table(text=" ID, y1, y2
> 1,0,12/25/2014
> 1,125,9/15/2015
> 1,350,1/30/2016
> 2,0,12/25/2012
> 2,450,9/15/2014
> 2,750,1/30/2016
> 2,  656, 11/30/2016
> ",sep=",",header=TRUE)
>
> str(lag)
> lag$y2 <- as.Date(lag$y2, format = "%m/%d/%Y")
> str(lag)
>
> # 1)
> flag <- ave(lag$ID, lag$ID, FUN = seq_along)
> lag2 <- cbind(lag[1], flag, lag[-1])
>
> # 2)
> y1dif <- ave(lag2$y1, lag2$ID, FUN = function(y) c(0, y[-1] -
> y[-length(y)]))
> y2dif <- unlist(tapply(lag2$y2, lag2$ID, FUN = function(y) c(0, y[-1] -
> y[-length(y)])))
>
> lag2 <- cbind(lag2, y1dif, y2dif)
> lag2
>
> Hope this helps,
>
> Rui Barradas
>
> Em 15-10-2016 17:57, Val escreveu:
>> Hi all,
>>
>> I want sort the data by ID and Y2 then count the number of rows within
>> IDs.  Assign a "flag" variable to reach row starting from first  to
>> the last row.
>> For instance, in the following data ID "1" has three rows   and each
>> row is assigned flag sequentially 1, 2,3.
>>
>> 2. In the second step, within each ID, I want get the difference
>> between the subsequent row values of y1 and y2(date) values.
>> Within each ID the first value of y1diff  and y2diff are always 0. The
>> second values for each will  be the current row minus the previous
>> row.
>>
>>
>>
>> lag<-read.table(text=" ID, y1, y2
>> ID,Y1,y2
>> 1,0,12/25/2014
>> 1,125,9/15/2015
>> 1,350,1/30/2016
>> 2,0,12/25/2012
>> 2,450,9/15/2014
>> 2,750,1/30/2016
>> 2,  656, 11/30/2016
>> ",sep=",",header=TRUE)
>>
>> output looks like as follows
>>
>> ID,flag,y1,y2,y1dif,y2dif
>> 1,1,0,12/25/2014,0,0
>> 1,2,125,9/15/2015,125,264
>> 1,3,350,1/30/2016,225,137
>> 2,1,0,12/25/2012,0,0
>> 2,2,450,9/15/2014,450,629
>> 2,3,750,1/30/2016,300,502
>> 2, 4, 656 11/30/2016, -94, 305
>>
>> Thank you
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sat Oct 15 21:58:56 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 15 Oct 2016 15:58:56 -0400
Subject: [R] lag, count
In-Reply-To: <58027B69.5070403@sapo.pt>
References: <CAJOiR6YdmwzgjJng8_1Cz0svdOURQuBLOvOJS1TL6aotyrFw=w@mail.gmail.com>
	<5802795E.9010807@sapo.pt> <58027B69.5070403@sapo.pt>
Message-ID: <CAAxdm-4oY8u1m+Wr9Pty3=w2fcXyHuSPHna96RkW_HRqnpAqiQ@mail.gmail.com>

Here is a solution using 'dplyr'

> require(dplyr)
> lag<-read.table(text=" ID, y1, y2
+ 1,0,12/25/2014
+ 1,125,9/15/2015
+ 1,350,1/30/2016
+ 2,0,12/25/2012
+ 2,450,9/15/2014
+ 2,750,1/30/2016
+ 2,  656, 11/30/2016
+ ",sep=",",header=TRUE)
>
> new_lag <- lag %>%
+             mutate(y2 = as.Date(y2, format = "%m/%d/%Y")) %>%  # convert date
+             arrange(ID, y2) %>%  # sort if necessary
+             group_by(ID) %>%
+             mutate(flag = seq(n()),
+                 y1diff = c(0, diff(y1)),
+                 y2diff = c(0, diff(y2))
+                 )
>
>
> new_lag
Source: local data frame [7 x 6]
Groups: ID [2]

     ID    y1         y2  flag y1diff y2diff
  <int> <int>     <date> <int>  <dbl>  <dbl>
1     1     0 2014-12-25     1      0      0
2     1   125 2015-09-15     2    125    264
3     1   350 2016-01-30     3    225    137
4     2     0 2012-12-25     1      0      0
5     2   450 2014-09-15     2    450    629
6     2   750 2016-01-30     3    300    502
7     2   656 2016-11-30     4    -94    305

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sat, Oct 15, 2016 at 2:54 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> I forgot about the sorting part and assumed the data.frame was already
> sorted. If not, after converting y2 to class Date, you can do
>
> lag <- lag[order(lag$ID, lag$y2), ]
>
> Rui Barradas
>
>
> Em 15-10-2016 19:45, Rui Barradas escreveu:
>>
>> Hello,
>>
>> Try the following.
>>
>>
>> lag<-read.table(text=" ID, y1, y2
>> 1,0,12/25/2014
>> 1,125,9/15/2015
>> 1,350,1/30/2016
>> 2,0,12/25/2012
>> 2,450,9/15/2014
>> 2,750,1/30/2016
>> 2,  656, 11/30/2016
>> ",sep=",",header=TRUE)
>>
>> str(lag)
>> lag$y2 <- as.Date(lag$y2, format = "%m/%d/%Y")
>> str(lag)
>>
>> # 1)
>> flag <- ave(lag$ID, lag$ID, FUN = seq_along)
>> lag2 <- cbind(lag[1], flag, lag[-1])
>>
>> # 2)
>> y1dif <- ave(lag2$y1, lag2$ID, FUN = function(y) c(0, y[-1] -
>> y[-length(y)]))
>> y2dif <- unlist(tapply(lag2$y2, lag2$ID, FUN = function(y) c(0, y[-1] -
>> y[-length(y)])))
>>
>> lag2 <- cbind(lag2, y1dif, y2dif)
>> lag2
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 15-10-2016 17:57, Val escreveu:
>>>
>>> Hi all,
>>>
>>> I want sort the data by ID and Y2 then count the number of rows within
>>> IDs.  Assign a "flag" variable to reach row starting from first  to
>>> the last row.
>>> For instance, in the following data ID "1" has three rows   and each
>>> row is assigned flag sequentially 1, 2,3.
>>>
>>> 2. In the second step, within each ID, I want get the difference
>>> between the subsequent row values of y1 and y2(date) values.
>>> Within each ID the first value of y1diff  and y2diff are always 0. The
>>> second values for each will  be the current row minus the previous
>>> row.
>>>
>>>
>>>
>>> lag<-read.table(text=" ID, y1, y2
>>> ID,Y1,y2
>>> 1,0,12/25/2014
>>> 1,125,9/15/2015
>>> 1,350,1/30/2016
>>> 2,0,12/25/2012
>>> 2,450,9/15/2014
>>> 2,750,1/30/2016
>>> 2,  656, 11/30/2016
>>> ",sep=",",header=TRUE)
>>>
>>> output looks like as follows
>>>
>>> ID,flag,y1,y2,y1dif,y2dif
>>> 1,1,0,12/25/2014,0,0
>>> 1,2,125,9/15/2015,125,264
>>> 1,3,350,1/30/2016,225,137
>>> 2,1,0,12/25/2012,0,0
>>> 2,2,450,9/15/2014,450,629
>>> 2,3,750,1/30/2016,300,502
>>> 2, 4, 656 11/30/2016, -94, 305
>>>
>>> Thank you
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sat Oct 15 22:06:32 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 15 Oct 2016 16:06:32 -0400
Subject: [R] Problem with sample(...,size = 1000000000,...)
In-Reply-To: <CADR9BXRYMGW3gpL7j+7id=zsC1RbdBf5uNZuJJVM02Oi5gJu2A@mail.gmail.com>
References: <CADR9BXRYMGW3gpL7j+7id=zsC1RbdBf5uNZuJJVM02Oi5gJu2A@mail.gmail.com>
Message-ID: <CAAxdm-47aqeEiVKLX9dGzOxGF=fTJrCQAD6kn0ohTHLYnN5g6w@mail.gmail.com>

Do you realize you are trying to create a vector with 1 billion
entries, so this will take some time.  How much memory do you have on
your computer?

Here are some times to generate increasing sample sizes.  I have 16GB
on my computer and it took only 30 seconds to generate the data and
used almost 12GB of memory.

> system.time(x<-sample(1:5,100000,TRUE,c(0.1,0.2,0.4,0.2,0.1)))
   user  system elapsed
      0       0       0
> system.time(x<-sample(1:5,1000000,TRUE,c(0.1,0.2,0.4,0.2,0.1)))
   user  system elapsed
   0.03    0.00    0.03
> system.time(x<-sample(1:5,10000000,TRUE,c(0.1,0.2,0.4,0.2,0.1)))
   user  system elapsed
   0.47    0.02    0.49
> system.time(x<-sample(1:5,100000000,TRUE,c(0.1,0.2,0.4,0.2,0.1)))
   user  system elapsed
   3.09    0.24    3.33
> system.time(x<-sample(1:5,1000000000,TRUE,c(0.1,0.2,0.4,0.2,0.1)))
   user  system elapsed
  30.76    1.70   32.92
> memory.size()
[1] 11502.52

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sat, Oct 15, 2016 at 12:19 PM, Huy Nguy?n <quanghuy1258 at gmail.com> wrote:
> When I ran this code:
> "
> x<-sample(1:5,1000000000,TRUE,c(0.1,0.2,0.4,0.2,0.1))
> print(table(x)/1000000000)
> plot(table(x)/1000000000,type="h",xlab="x",ylab="P(x)")
> "
> My laptop was frozen and didn't respond. Although I used ctrl+alt+del to
> terminate r program, my laptop still did nothing. And I must restart my
> laptop immediately or my laptop might be broken down.
> Thus, I think in the future the program should have something to control
> the memory and time when it is running and can be terminated if necessary.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sat Oct 15 22:17:05 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 15 Oct 2016 16:17:05 -0400
Subject: [R] Problem with sample(...,size = 1000000000,...)
In-Reply-To: <CAAxdm-47aqeEiVKLX9dGzOxGF=fTJrCQAD6kn0ohTHLYnN5g6w@mail.gmail.com>
References: <CADR9BXRYMGW3gpL7j+7id=zsC1RbdBf5uNZuJJVM02Oi5gJu2A@mail.gmail.com>
	<CAAxdm-47aqeEiVKLX9dGzOxGF=fTJrCQAD6kn0ohTHLYnN5g6w@mail.gmail.com>
Message-ID: <CAAxdm-6dapW+y+Ykc4F6+orkpinVfiMrfW8GHUo+shUqnA8ZNw@mail.gmail.com>

I forgot to add that if you have less than 16GB of memory, then you
were probably paging memory to disk and that would have take a much,
much, longer time.  When you are trying to do something BIG, do it in
some smaller steps and look at the resources that it takes (memory,
cpu, ...).

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sat, Oct 15, 2016 at 4:06 PM, jim holtman <jholtman at gmail.com> wrote:
> Do you realize you are trying to create a vector with 1 billion
> entries, so this will take some time.  How much memory do you have on
> your computer?
>
> Here are some times to generate increasing sample sizes.  I have 16GB
> on my computer and it took only 30 seconds to generate the data and
> used almost 12GB of memory.
>
>> system.time(x<-sample(1:5,100000,TRUE,c(0.1,0.2,0.4,0.2,0.1)))
>    user  system elapsed
>       0       0       0
>> system.time(x<-sample(1:5,1000000,TRUE,c(0.1,0.2,0.4,0.2,0.1)))
>    user  system elapsed
>    0.03    0.00    0.03
>> system.time(x<-sample(1:5,10000000,TRUE,c(0.1,0.2,0.4,0.2,0.1)))
>    user  system elapsed
>    0.47    0.02    0.49
>> system.time(x<-sample(1:5,100000000,TRUE,c(0.1,0.2,0.4,0.2,0.1)))
>    user  system elapsed
>    3.09    0.24    3.33
>> system.time(x<-sample(1:5,1000000000,TRUE,c(0.1,0.2,0.4,0.2,0.1)))
>    user  system elapsed
>   30.76    1.70   32.92
>> memory.size()
> [1] 11502.52
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Sat, Oct 15, 2016 at 12:19 PM, Huy Nguy?n <quanghuy1258 at gmail.com> wrote:
>> When I ran this code:
>> "
>> x<-sample(1:5,1000000000,TRUE,c(0.1,0.2,0.4,0.2,0.1))
>> print(table(x)/1000000000)
>> plot(table(x)/1000000000,type="h",xlab="x",ylab="P(x)")
>> "
>> My laptop was frozen and didn't respond. Although I used ctrl+alt+del to
>> terminate r program, my laptop still did nothing. And I must restart my
>> laptop immediately or my laptop might be broken down.
>> Thus, I think in the future the program should have something to control
>> the memory and time when it is running and can be terminated if necessary.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From joeceradini at gmail.com  Sat Oct 15 22:32:18 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Sat, 15 Oct 2016 14:32:18 -0600
Subject: [R] Split strings based on multiple patterns (plain text)
In-Reply-To: <F0F96A33-8EB6-4C2C-A34A-6173648AC698@comcast.net>
References: <CAKq2vL4v3CDpRGUY=0U4z_2shTMSirJud+omx=jNpXOyXqug=A@mail.gmail.com>
	<F0F96A33-8EB6-4C2C-A34A-6173648AC698@comcast.net>
Message-ID: <CAKq2vL4Z=oFBZRMDs4ob-KAvSqQt5ASFv3NjzdASUXszBB3-jg@mail.gmail.com>

Thank you David Wolfskill, David Winsemius, and Gabor! All very
helpful and interesting fixes for the problem (compiled below)! Now I
will see which one works best on the 944 rows that each have a cell of
smooshed attributes...the attribute names should be the same in all
the rows, if there is any mercy :)

Joe Ceradini
University of Wyoming

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

On 10/14/16, David Wolfskill <david at catwhisker.org> wrote:
> Happy Friday, indeed.
>
> It seems to me that the data need a bit of cleamup before attempting to
> parse -- for example, that "F" looks to be improperly delimited by ':'
> on either side.  I can't tell from a single example if that's typical
> (either for that field, or for random fields throughout the complete
> dataset).  On the off-chance it's the former, here's a bit of exercise
> that may lead you a bit closer to a solution:
>
> First, starting with "ugly":
>
>> ugly <- c("Water temp:14: F Waterbody type:Permanent Lake/Pond: Water
>> pH:Unkwn: Conductivity:Unkwn: Water color: Clear: Water turbidity: clear:
>> Manmade:no  Permanence:permanent:  Max water depth: <3: Primary substrate:
>> Silt/Mud: Evidence of cattle grazing: none: Shoreline Emergent Veg(%):
>> 1-25: Fish present: yes: Fish species: unkwn: no amphibians observed")
>> ugly
> [1] "Water temp:14: F Waterbody type:Permanent Lake/Pond: Water pH:Unkwn:
> Conductivity:Unkwn: Water color: Clear: Water turbidity: clear: Manmade:no
> Permanence:permanent:  Max water depth: <3: Primary substrate: Silt/Mud:
> Evidence of cattle grazing: none: Shoreline Emergent Veg(%): 1-25: Fish
> present: yes: Fish species: unkwn: no amphibians observed"
>
> # First, see what a naive strsplit() does:
>
>> strsplit(ugly, ":")
> [[1]]
>  [1] "Water temp"                  "14"
>  [3] " F Waterbody type"           "Permanent Lake/Pond"
>  [5] " Water pH"                   "Unkwn"
>  [7] " Conductivity"               "Unkwn"
>  [9] " Water color"                " Clear"
> [11] " Water turbidity"            " clear"
> [13] " Manmade"                    "no  Permanence"
> [15] "permanent"                   "  Max water depth"
> [17] " <3"                         " Primary substrate"
> [19] " Silt/Mud"                   " Evidence of cattle grazing"
> [21] " none"                       " Shoreline Emergent Veg(%)"
> [23] " 1-25"                       " Fish present"
> [25] " yes"                        " Fish species"
> [27] " unkwn"                      " no amphibians observed"
>
> # OK; let's fix the "F":
>
>> ugly1 <- sub(": F ", "F: ", ugly)
>> ugly1
> [1] "Water temp:14F: Waterbody type:Permanent Lake/Pond: Water pH:Unkwn:
> Conductivity:Unkwn: Water color: Clear: Water turbidity: clear: Manmade:no
> Permanence:permanent:  Max water depth: <3: Primary substrate: Silt/Mud:
> Evidence of cattle grazing: none: Shoreline Emergent Veg(%): 1-25: Fish
> present: yes: Fish species: unkwn: no amphibians observed"
>
> # Now, that substring "Manmade:no  Permanence:permanent:" is problematic;
> # the "  " in there should apparently be ": " -- but we can't just do that
> # to all "  " substrings, because that would also affect
> # "Permanence:permanent:  Max water depth: <3:" -- the differnce, though,
> # is that the one we don't want to change contains ":  ", so let's change
> # those.  I'm assuming(!) that we don't really care about leading or
> # trailing spaces in the fields:
>
>> ugly2 <- gsub(" *: *", ":", ugly1)
>> ugly2
> [1] "Water temp:14F:Waterbody type:Permanent Lake/Pond:Water
> pH:Unkwn:Conductivity:Unkwn:Water color:Clear:Water
> turbidity:clear:Manmade:no  Permanence:permanent:Max water depth:<3:Primary
> substrate:Silt/Mud:Evidence of cattle grazing:none:Shoreline Emergent
> Veg(%):1-25:Fish present:yes:Fish species:unkwn:no amphibians observed"
>
> # Now that "  " shows up like a sore thumb.  Just to make the point even
> # clearer, try the "naive" strsplit on what we have:
>
>> strsplit(ugly2, ":")
> [[1]]
>  [1] "Water temp"                 "14F"
>  [3] "Waterbody type"             "Permanent Lake/Pond"
>  [5] "Water pH"                   "Unkwn"
>  [7] "Conductivity"               "Unkwn"
>  [9] "Water color"                "Clear"
> [11] "Water turbidity"            "clear"
> [13] "Manmade"                    "no  Permanence"
> [15] "permanent"                  "Max water depth"
> [17] "<3"                         "Primary substrate"
> [19] "Silt/Mud"                   "Evidence of cattle grazing"
> [21] "none"                       "Shoreline Emergent Veg(%)"
> [23] "1-25"                       "Fish present"
> [25] "yes"                        "Fish species"
> [27] "unkwn"                      "no amphibians observed"
>
>>
>
> # Note element [14]:  that's the one we need to fix.  I'll assume(!)
> # that that sort of thing may occur just about anywhere, so let's just
> # whack 'em all:
>
>> ugly3 <- gsub("  ", ":", ugly2)
>> ugly3
> [1] "Water temp:14F:Waterbody type:Permanent Lake/Pond:Water
> pH:Unkwn:Conductivity:Unkwn:Water color:Clear:Water
> turbidity:clear:Manmade:no:Permanence:permanent:Max water depth:<3:Primary
> substrate:Silt/Mud:Evidence of cattle grazing:none:Shoreline Emergent
> Veg(%):1-25:Fish present:yes:Fish species:unkwn:no amphibians observed"
>
> # Again, check a naive strsplpit():
>
>> strsplit(ugly3, ":")
> [[1]]
>  [1] "Water temp"                 "14F"
>  [3] "Waterbody type"             "Permanent Lake/Pond"
>  [5] "Water pH"                   "Unkwn"
>  [7] "Conductivity"               "Unkwn"
>  [9] "Water color"                "Clear"
> [11] "Water turbidity"            "clear"
> [13] "Manmade"                    "no"
> [15] "Permanence"                 "permanent"
> [17] "Max water depth"            "<3"
> [19] "Primary substrate"          "Silt/Mud"
> [21] "Evidence of cattle grazing" "none"
> [23] "Shoreline Emergent Veg(%)"  "1-25"
> [25] "Fish present"               "yes"
> [27] "Fish species"               "unkwn"
> [29] "no amphibians observed"
>
>>
>
> # OK; not what we want, but it's a lot closer.  Now, watch this:
>
>> ugly4 <- gsub("([^:]*:[^:]*): *", "\\1\001", ugly3, perl = TRUE)
>> strsplit(ugly4, "\001")
> [[1]]
>  [1] "Water temp:14F"                     "Waterbody type:Permanent
> Lake/Pond"
>  [3] "Water pH:Unkwn"                     "Conductivity:Unkwn"
>
>  [5] "Water color:Clear"                  "Water turbidity:clear"
>
>  [7] "Manmade:no"                         "Permanence:permanent"
>
>  [9] "Max water depth:<3"                 "Primary substrate:Silt/Mud"
>
> [11] "Evidence of cattle grazing:none"    "Shoreline Emergent Veg(%):1-25"
>
> [13] "Fish present:yes"                   "Fish species:unkwn"
>
> [15] "no amphibians observed"
>
>>
>
> # At this point, at least elements [1] - [14] are each of the form
> # "tag:value", and thus, readily parsable.  Element [15] appears to be
> # a somewhat-random comment; I suppose you could check for elements that
> # lack a (single) ':' and treat them "specially"....
>
> I hope that helps.  Good luck!
>
> Peace,
> david
> --
> David H. Wolfskill				david at catwhisker.org
> Those who would murder in the name of God or prophet are blasphemous
> cowards.
>
> See http://www.catwhisker.org/~david/publickey.gpg for my public key.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

On 10/15/16, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Replace newlines and colons with a space since they seem to be junk,
> generate a pattern to replace the attributes with a comma and do the
> replacement and finally read in what is left into a data frame using
> the attributes as column names.
>
> (I have indented each line of code below by 2 spaces so if any line
> starts before that then it's been wrapped around by the email and
> needs to be adjusted.)
>
>   attributes <-
>   c("Water temp", "Waterbody type", "Water pH", "Conductivity",
>   "Water color", "Water turbidity", "Manmade", "Permanence", "Max water
> depth",
>   "Primary substrate", "Evidence of cattle grazing", "Shoreline
> Emergent Veg(%)",
>   "Fish present", "Fish species")
>
>   ugly2 <- gsub("[:\n]", " ", ugly)
>
>   pat <- paste(gsub("([[:punct:]])", ".", attributes), collapse = "|")
>   ugly3 <- gsub(pat, ",", ugly2)
>
>   dd <- read.table(text = ugly3, sep = ",", strip.white = TRUE,
> col.names = c("", attributes))[-1]

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

On 10/15/16, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Oct 14, 2016, at 6:53 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
>>
>> Hopefully this looks better. I did not realize gmail default was html.
>>
>> I have a dataframe with a column that has many field smashed together.
>> I need to split the strings in the column into separate columns based
>> on patterns.
>>
>> Example of a string that needs to be split:
>>
>> ugly <- c("Water temp:14: F Waterbody type:Permanent Lake/Pond: Water
>> pH:Unkwn: Conductivity:Unkwn: Water color: Clear: Water turbidity:
>> clear: Manmade:no  Permanence:permanent:  Max water depth: <3: Primary
>> substrate: Silt/Mud: Evidence of cattle grazing: none: Shoreline
>> Emergent Veg(%): 1-25: Fish present: yes: Fish species: unkwn: no
>> amphibians observed")
>> ugly
>>
>> Far as I can tell, there is not a single pattern that would work for
>> splitting. Splitting on ":" is close, but not quite right. Each of the
>> below attributes should be in a separate column, and are present in
>> the string (above) that needs to be split:
>>
>> attributes <- c("Water temp", "Waterbody type", "Water pH",
>> "Conductivity", "Water color", "Water turbidity", "Manmade",
>> "Permanence", "Max water depth", "Primary substrate", "Evidence of
>> cattle grazing", "Shoreline Emergent Veg(%)", "Fish present", "Fish
>> species")
>>
>> Conceptually, I want to use the vector of attributes to split the
>> string. However, strsplit only uses the 1st value of the attributes
>> object:
>>
>> strplit(ugly, attributes).
>
> I tried this:
>
> strsplit( ugly, split=paste0(attributes, collapse="|")  )
>
> And noticed soem of hte attributes were not actually splitting so went back
> and did the data entry after making sure that there were no "\n"'s in the
> middle of attribute names:
>
> dput(attributes)
> c("Water temp", "Waterbody type", "Water pH", "Conductivity",
> "Water color", "Water turbidity", "Manmade", "Permanence", "Max water
> depth",
> "Primary substrate", "Evidence of cattle grazing", "Shoreline Emergent
> Veg(%)",
> "Fish present", "Fish species")
>
> strsplit( ugly, split=paste0(attributes, collapse="|")  )
> [[1]]
>  [1] ""
>
>  [2] ":14: F "
>
>  [3] ":Permanent Lake/Pond: Water\npH:Unkwn: "
>
>  [4] ":Unkwn: "
>
>  [5] ": Clear: "
>
>  [6] ":\nclear: "
>
>  [7] ":no  "
>
>  [8] ":permanent:  "
>
>  [9] ": <3: Primary\nsubstrate: Silt/Mud: Evidence of cattle grazing: none:
> Shoreline\nEmergent Veg(%): 1-25: "
> [10] ": yes: Fish species: unkwn: no\namphibians observed"
>
>>
>> Should I loop through the values of "attributes"?
>> Is there an argument in strsplit I'm missing that will do what I want? \\
>
> I don't think strsplit has such an argument. There may be packages that will
> support this. Perhaps the gubfn package?
>
>
>> Different approach altogether?
>>
>> Thanks! Happy Friday.
>> Joe
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From r.turner at auckland.ac.nz  Sat Oct 15 22:46:43 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 16 Oct 2016 09:46:43 +1300
Subject: [R] How to read prediction intervals given by predict()?
In-Reply-To: <7a0e84560370b6de2765d33772093e65@kapsi.fi>
References: <7a0e84560370b6de2765d33772093e65@kapsi.fi>
Message-ID: <b22d2833-76e2-58c9-10a7-a7b46774589d@auckland.ac.nz>

On 16/10/16 04:24, mviljamaa wrote:
> My conception of prediction intervals is the following:
>
> "a prediction interval gives an interval within which we expect next y_i
> to lie with a specified probability"
>
> So when using predict() for my model:
>
> predict(fit4, interval="prediction")[1:20,]
>
> I get:
>
>         fit      lwr      upr
> 1  491.1783 381.3486 601.0081
> 2  515.4883 405.7128 625.2638
> 3  581.5957 447.9569 715.2344
> 4  522.4979 412.5086 632.4872
> 5  604.6008 492.2796 716.9221
> 6  520.2881 410.3108 630.2655
> 7  620.7379 507.9045 733.5713
> 8  621.0925 505.8731 736.3119
> 9  527.1810 417.2760 637.0859
> 10 519.4651 406.1622 632.7680
> 11 622.0051 512.0082 732.0021
> 12 536.6924 424.3415 649.0434
> 13 504.8618 394.9034 614.8202
> 14 545.5920 433.6530 657.5309
> 15 475.6153 362.4383 588.7923
> 16 462.5341 350.6090 574.4593
> 17 559.0888 448.1212 670.0564
> 18 544.0051 432.0583 655.9519
> 19 471.1450 355.2377 587.0523
> 20 604.3028 470.6925 737.9130
>
> Now since the prediction interval gives the interval within which the
> _next_ y_i will fall, then how to read the above results? Does the
> previous row's "lwr" and "upr" refer to the next row's "fit"'s interval?

(a) This is really off-topic since it's more of a statistics question 
than an R question.

(b) Your understanding of prediction intervals is incorrect and 
confused.  A 95% (for example)  prediction interval will contain a *new*
independent observation of y, at the same predictor value(s) with 
probability 0.95.  Get your hands on an elementary statistics textbook 
and read it!

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewmil at dcn.davis.ca.us  Sat Oct 15 23:01:02 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 15 Oct 2016 14:01:02 -0700
Subject: [R] How to read prediction intervals given by predict()?
In-Reply-To: <7a0e84560370b6de2765d33772093e65@kapsi.fi>
References: <7a0e84560370b6de2765d33772093e65@kapsi.fi>
Message-ID: <207EDE32-000F-4CA7-BAE0-675578AFE85F@dcn.davis.ca.us>

No, you need to specify the inputs corresponding to the next value in order to obtain a production for that point. Read ?predict.lm or whatever function is appropriate for your model about the newdata argument. 
-- 
Sent from my phone. Please excuse my brevity.

On October 15, 2016 8:24:35 AM PDT, mviljamaa <mviljamaa at kapsi.fi> wrote:
>My conception of prediction intervals is the following:
>
>"a prediction interval gives an interval within which we expect next
>y_i 
>to lie with a specified probability"
>
>So when using predict() for my model:
>
>predict(fit4, interval="prediction")[1:20,]
>
>I get:
>
>         fit      lwr      upr
>1  491.1783 381.3486 601.0081
>2  515.4883 405.7128 625.2638
>3  581.5957 447.9569 715.2344
>4  522.4979 412.5086 632.4872
>5  604.6008 492.2796 716.9221
>6  520.2881 410.3108 630.2655
>7  620.7379 507.9045 733.5713
>8  621.0925 505.8731 736.3119
>9  527.1810 417.2760 637.0859
>10 519.4651 406.1622 632.7680
>11 622.0051 512.0082 732.0021
>12 536.6924 424.3415 649.0434
>13 504.8618 394.9034 614.8202
>14 545.5920 433.6530 657.5309
>15 475.6153 362.4383 588.7923
>16 462.5341 350.6090 574.4593
>17 559.0888 448.1212 670.0564
>18 544.0051 432.0583 655.9519
>19 471.1450 355.2377 587.0523
>20 604.3028 470.6925 737.9130
>
>Now since the prediction interval gives the interval within which the 
>_next_ y_i will fall, then how to read the above results? Does the 
>previous row's "lwr" and "upr" refer to the next row's "fit"'s
>interval?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Oct 16 00:03:31 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 15 Oct 2016 15:03:31 -0700
Subject: [R] Error in solve.default(object$hessian)
In-Reply-To: <CAGGEV7Mgs=Pp2wrVe+moX1byK52a2oHut1G5ny82Eia6jxt_kA@mail.gmail.com>
References: <CAGGEV7Mgs=Pp2wrVe+moX1byK52a2oHut1G5ny82Eia6jxt_kA@mail.gmail.com>
Message-ID: <00237E27-AC7F-4468-9F84-0E3E83D8EEBE@comcast.net>


> On Oct 15, 2016, at 3:37 AM, Ahmad Nursalim <ceritaahmad at gmail.com> wrote:
> 
> I have the problem use R
> 
> Error in solve.default(object$hessian)
> 
> system is computationally singular: reciprocal condition number = 1.42892e-30
> 
> 
> what is the problem ?and what it means
> help me

You should learn to help yourself. I use:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help

I'm sure this question has been asked an answered many times.

> --
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rshepard at appl-ecosys.com  Sun Oct 16 00:28:46 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Sat, 15 Oct 2016 15:28:46 -0700 (PDT)
Subject: [R] Adjusting axis labels on lattice xyplot
In-Reply-To: <alpine.LNX.2.11.1610141648490.8550@localhost>
References: <alpine.LNX.2.11.1610141153020.8550@localhost>
	<291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>
	<alpine.LNX.2.11.1610141540310.8550@localhost>
	<58836C90-708D-41AF-B62B-2634D36CF003@comcast.net>
	<alpine.LNX.2.11.1610141648490.8550@localhost>
Message-ID: <alpine.LNX.2.11.1610151526290.26543@localhost>

On Fri, 14 Oct 2016, Rich Shepard wrote:

>> So typing ?xyplot at the console doesn't bring up a help page? That would
>> imply that you need to reinstall R.

>  Will rebuild and re-install tomorrow morning.

   Sigh. User error. I entered the string as a function, e.g., ?xyplot()
rather than by its name.

   When entered correctly the help page appears.

Apologies,

Rich


From r.turner at auckland.ac.nz  Sun Oct 16 00:48:37 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 16 Oct 2016 11:48:37 +1300
Subject: [R] Adjusting axis labels on lattice xyplot
In-Reply-To: <alpine.LNX.2.11.1610151526290.26543@localhost>
References: <alpine.LNX.2.11.1610141153020.8550@localhost>
	<291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>
	<alpine.LNX.2.11.1610141540310.8550@localhost>
	<58836C90-708D-41AF-B62B-2634D36CF003@comcast.net>
	<alpine.LNX.2.11.1610141648490.8550@localhost>
	<alpine.LNX.2.11.1610151526290.26543@localhost>
Message-ID: <448a57e7-ec7b-3c0c-ae7b-32ee4e24c339@auckland.ac.nz>

On 16/10/16 11:28, Rich Shepard wrote:
> On Fri, 14 Oct 2016, Rich Shepard wrote:
>
>>> So typing ?xyplot at the console doesn't bring up a help page? That
>>> would
>>> imply that you need to reinstall R.
>
>>  Will rebuild and re-install tomorrow morning.
>
>   Sigh. User error. I entered the string as a function, e.g., ?xyplot()
> rather than by its name.
>
>   When entered correctly the help page appears.
>
> Apologies.

Just out of interest, I tried typing "?xyplot()" and it worked just as 
if I'd typed "?xyplot" (without the parentheses).

So I am puzzled as to why this didn't work for you (despite your --- 
very mild! --- user error).  Presumably you are running (yeuccch) 
Windoze, whereas I (being a Sensible Person) am running Ubuntu Linux.
Could this make a difference?

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dwinsemius at comcast.net  Sun Oct 16 01:02:15 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 15 Oct 2016 16:02:15 -0700
Subject: [R] Adjusting axis labels on lattice xyplot
In-Reply-To: <448a57e7-ec7b-3c0c-ae7b-32ee4e24c339@auckland.ac.nz>
References: <alpine.LNX.2.11.1610141153020.8550@localhost>
	<291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>
	<alpine.LNX.2.11.1610141540310.8550@localhost>
	<58836C90-708D-41AF-B62B-2634D36CF003@comcast.net>
	<alpine.LNX.2.11.1610141648490.8550@localhost>
	<alpine.LNX.2.11.1610151526290.26543@localhost>
	<448a57e7-ec7b-3c0c-ae7b-32ee4e24c339@auckland.ac.nz>
Message-ID: <ACEB51AD-0796-4B8A-BDDE-5A1E03AFD1F8@comcast.net>


> On Oct 15, 2016, at 3:48 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 16/10/16 11:28, Rich Shepard wrote:
>> On Fri, 14 Oct 2016, Rich Shepard wrote:
>> 
>>>> So typing ?xyplot at the console doesn't bring up a help page? That
>>>> would
>>>> imply that you need to reinstall R.
>> 
>>> Will rebuild and re-install tomorrow morning.
>> 
>>  Sigh. User error. I entered the string as a function, e.g., ?xyplot()
>> rather than by its name.
>> 
>>  When entered correctly the help page appears.
>> 
>> Apologies.
> 
> Just out of interest, I tried typing "?xyplot()" and it worked just as if I'd typed "?xyplot" (without the parentheses).
> 
> So I am puzzled as to why this didn't work for you (despite your --- very mild! --- user error).  Presumably you are running (yeuccch) Windoze, whereas I (being a Sensible Person) am running Ubuntu Linux.
> Could this make a difference?

I am not the one to answer the windoze question but my Mac (being less sensible than Rolf) also pops up a help window when queried with ?xyplot()

Best;
David.
> 
> cheers,
> 
> Rolf
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rshepard at appl-ecosys.com  Sun Oct 16 01:07:11 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Sat, 15 Oct 2016 16:07:11 -0700 (PDT)
Subject: [R] Adjusting axis labels on lattice xyplot
In-Reply-To: <448a57e7-ec7b-3c0c-ae7b-32ee4e24c339@auckland.ac.nz>
References: <alpine.LNX.2.11.1610141153020.8550@localhost>
	<291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>
	<alpine.LNX.2.11.1610141540310.8550@localhost>
	<58836C90-708D-41AF-B62B-2634D36CF003@comcast.net>
	<alpine.LNX.2.11.1610141648490.8550@localhost>
	<alpine.LNX.2.11.1610151526290.26543@localhost>
	<448a57e7-ec7b-3c0c-ae7b-32ee4e24c339@auckland.ac.nz>
Message-ID: <alpine.LNX.2.11.1610151606300.26543@localhost>

On Sun, 16 Oct 2016, Rolf Turner wrote:

> Presumably you are running (yeuccch) Windoze,

Rolf,

   Not since mid-1997. Slackware-14.1 on this host.

Rich


From rshepard at appl-ecosys.com  Sun Oct 16 01:10:47 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Sat, 15 Oct 2016 16:10:47 -0700 (PDT)
Subject: [R] Adjusting axis labels on lattice xyplot
In-Reply-To: <ACEB51AD-0796-4B8A-BDDE-5A1E03AFD1F8@comcast.net>
References: <alpine.LNX.2.11.1610141153020.8550@localhost>
	<291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>
	<alpine.LNX.2.11.1610141540310.8550@localhost>
	<58836C90-708D-41AF-B62B-2634D36CF003@comcast.net>
	<alpine.LNX.2.11.1610141648490.8550@localhost>
	<alpine.LNX.2.11.1610151526290.26543@localhost>
	<448a57e7-ec7b-3c0c-ae7b-32ee4e24c339@auckland.ac.nz>
	<ACEB51AD-0796-4B8A-BDDE-5A1E03AFD1F8@comcast.net>
Message-ID: <alpine.LNX.2.11.1610151608230.26543@localhost>

On Sat, 15 Oct 2016, David Winsemius wrote:

> I am not the one to answer the windoze question but my Mac (being less
> sensible than Rolf) also pops up a help window when queried with ?xyplot()

David,

   Well, on my Slackware system writing in emacs with ESS ?read.csv()
produces the error message that there's no documentation for that, while
?read.csv brings up the help page.

Shrug,

Rich


From naresh_gurbuxani at hotmail.com  Sun Oct 16 01:43:31 2016
From: naresh_gurbuxani at hotmail.com (Naresh Gurbuxani)
Date: Sat, 15 Oct 2016 23:43:31 +0000
Subject: [R] suppress labels in lattice barchart
Message-ID: <CY1PR07MB258841C4C868194E420B14F7FADE0@CY1PR07MB2588.namprd07.prod.outlook.com>

I would like to print a barchart without labels for categorical variables. ?What change should be made to below command?

Thanks,
Naresh

boy.age <- data.frame(name = c("alpha", "beta", "charlie", "gerald"), age = c(7, 9, 6, 5))

boy.age$name <- with(boy.age, reorder(name, age))

# draws with names on labels
barchart(name ~ age, data = boy.age, scales = list(y = list(alternating = FALSE)))

# draws with names on labels
barchart(name ~ age, data = boy.age, ylab = "")

From r.turner at auckland.ac.nz  Sun Oct 16 02:36:59 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 16 Oct 2016 13:36:59 +1300
Subject: [R] Adjusting axis labels on lattice xyplot
In-Reply-To: <alpine.LNX.2.11.1610151608230.26543@localhost>
References: <alpine.LNX.2.11.1610141153020.8550@localhost>
	<291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>
	<alpine.LNX.2.11.1610141540310.8550@localhost>
	<58836C90-708D-41AF-B62B-2634D36CF003@comcast.net>
	<alpine.LNX.2.11.1610141648490.8550@localhost>
	<alpine.LNX.2.11.1610151526290.26543@localhost>
	<448a57e7-ec7b-3c0c-ae7b-32ee4e24c339@auckland.ac.nz>
	<ACEB51AD-0796-4B8A-BDDE-5A1E03AFD1F8@comcast.net>
	<alpine.LNX.2.11.1610151608230.26543@localhost>
Message-ID: <aedcb53c-b783-76b3-7681-0217fe762950@auckland.ac.nz>

On 16/10/16 12:10, Rich Shepard wrote:
> On Sat, 15 Oct 2016, David Winsemius wrote:
>
>> I am not the one to answer the windoze question but my Mac (being less
>> sensible than Rolf) also pops up a help window when queried with
>> ?xyplot()
>
> David,
>
>   Well, on my Slackware system writing in emacs with ESS ?read.csv()
> produces the error message that there's no documentation for that, while
> ?read.csv brings up the help page.
>
> Shrug.

Ah!  It's Emacs.  Enuff said! :-)  (IMHO Emacs is too clever by half.)

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From milujisb at gmail.com  Sun Oct 16 15:32:18 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Sun, 16 Oct 2016 15:32:18 +0200
Subject: [R] Merge data by coordinates
Message-ID: <CAMLwc7NPDg+PB3hREFNB32ogd8y1mL4ZEfnJkqu-Fqgx94y5vA@mail.gmail.com>

Dear all,

I have two dataframe 1 by latitude and longitude but they always do not
match. Is it possible to merge them (e.g. nearest distance)?

# Dataframe 1
structure(list(lat = c(54L, 55L, 51L, 54L, 53L, 50L, 47L, 51L,
49L, 54L), lon = c(14L, 8L, 15L, 7L, 6L, 5L, 13L, 5L, 13L, 11L
), PPP2000_40 = c(4606, 6575, 6593, 7431, 9393, 10773, 11716,
12226, 13544, 14526)), .Names = c("lat", "lon", "PPP2000_40"), row.names =
c(6764L,
8796L, 8901L, 9611L, 11649L, 12819L, 13763L, 14389L, 15641L,
16571L), class = "data.frame")

# Dataframe 2
structure(list(lat = c(47, 47, 47, 47, 47, 47, 48, 48, 48, 48
), lon = c(7, 8, 9, 10, 11, 12, 7, 8, 9, 10), GDP = c(19.09982,
13.31977, 14.95925, 6.8575635, 23.334565, 6.485748, 24.01197,
14.30393075, 21.33759675, 9.71803675)), .Names = c("lat", "lon",
"GDP"), row.names = c(NA, 10L), class = "data.frame")

Thank you so much!

Sincerely,

Milu

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sun Oct 16 17:07:27 2016
From: jholtman at gmail.com (jim holtman)
Date: Sun, 16 Oct 2016 11:07:27 -0400
Subject: [R] Reg : R : How to capture cpu usage,
 memory usage and disks info using R language
In-Reply-To: <CADG9u0BpE6DBVWtRXunviWAL00jV0QD2TRZ3P6t82p6FC_YMyg@mail.gmail.com>
References: <CADG9u0BpE6DBVWtRXunviWAL00jV0QD2TRZ3P6t82p6FC_YMyg@mail.gmail.com>
Message-ID: <CAAxdm-7EEMq0JUisuKy3uwHs-Umum0EH48n2iSnscxGK86MDww@mail.gmail.com>

Here is a start on the solution.  This will create a VBS script that
will gather the CPU data and return it in a character vector that you
can extract the data from.  You can add to it to get the other data
you are looking for.

########################
> temp <- tempfile(fileext = '.vbs')  # get a temp file
>
> # create the VBS file to collect processor data
> writeLines('Set objWMIService = GetObject("winmgmts:\\\\localhost\\root\\CIMV2")
+ Set CPUInfo = objWMIService.ExecQuery("SELECT * FROM
Win32_PerfFormattedData_PerfOS_Processor",,48)
+ For Each Item in CPUInfo
+     Wscript.Echo "PercentProcessorTime: " & Item.PercentProcessorTime & _
+          "  processor:" & Item.Name
+ Next',
+  temp)
>
> results <- shell(paste("cscript", temp), intern = TRUE)  # execute using 'cscript'
> results # all the data
[1] "Microsoft (R) Windows Script Host Version 5.8"
[2] "Copyright (C) Microsoft Corporation. All rights reserved."
[3] ""
[4] "PercentProcessorTime: 18  processor:0"
[5] "PercentProcessorTime: 6  processor:1"
[6] "PercentProcessorTime: 6  processor:2"
[7] "PercentProcessorTime: 0  processor:3"
[8] "PercentProcessorTime: 7  processor:_Total"
> grep("processor:", results, value = TRUE)  # get just processor data
[1] "PercentProcessorTime: 18  processor:0"     "PercentProcessorTime:
6  processor:1"
[3] "PercentProcessorTime: 6  processor:2"      "PercentProcessorTime:
0  processor:3"
[5] "PercentProcessorTime: 7  processor:_Total"
>
>
#####################################


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Oct 14, 2016 at 5:37 AM, Manohar Reddy <manu.reddy52 at gmail.com> wrote:
> Hi,
>
> Is there any possibility that we can capture cpu usage ,memory usage and
> disks info using R language on *windows family OS* ?
>
>
>
>   I would like to see data that?s looks like
> a
>  below
>
>
>
>    Cpu usage : 70 %
>
>    Memory usage  : 80 %
>
>    Disks        : C drive ? 40 % full,D dive ? 60 %,full E drive ? 30 % full
>
>
>    for more info please find the attachement.
>
>
>  Thanks in Advance ,Manu.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Oct 16 19:24:33 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 16 Oct 2016 10:24:33 -0700
Subject: [R] Merge data by coordinates
In-Reply-To: <CAMLwc7NPDg+PB3hREFNB32ogd8y1mL4ZEfnJkqu-Fqgx94y5vA@mail.gmail.com>
References: <CAMLwc7NPDg+PB3hREFNB32ogd8y1mL4ZEfnJkqu-Fqgx94y5vA@mail.gmail.com>
Message-ID: <1BE7CB8B-766B-48A9-ADFD-C3D03AFD665A@comcast.net>


> On Oct 16, 2016, at 6:32 AM, Miluji Sb <milujisb at gmail.com> wrote:
> 
> Dear all,
> 
> I have two dataframe 1 by latitude and longitude but they always do not
> match. Is it possible to merge them (e.g. nearest distance)?
> 
> # Dataframe 1
> structure(list(lat = c(54L, 55L, 51L, 54L, 53L, 50L, 47L, 51L,
> 49L, 54L), lon = c(14L, 8L, 15L, 7L, 6L, 5L, 13L, 5L, 13L, 11L
> ), PPP2000_40 = c(4606, 6575, 6593, 7431, 9393, 10773, 11716,
> 12226, 13544, 14526)), .Names = c("lat", "lon", "PPP2000_40"), row.names =
> c(6764L,
> 8796L, 8901L, 9611L, 11649L, 12819L, 13763L, 14389L, 15641L,
> 16571L), class = "data.frame")
> 
> # Dataframe 2
> structure(list(lat = c(47, 47, 47, 47, 47, 47, 48, 48, 48, 48
> ), lon = c(7, 8, 9, 10, 11, 12, 7, 8, 9, 10), GDP = c(19.09982,
> 13.31977, 14.95925, 6.8575635, 23.334565, 6.485748, 24.01197,
> 14.30393075, 21.33759675, 9.71803675)), .Names = c("lat", "lon",
> "GDP"), row.names = c(NA, 10L), class = "data.frame")

I think you should first do this:

plot(d1$lat,d1$lon)
points(d2$lat,d2$lon, col="red")

And then respond to my suggestion that this is not a well-posed computing problem. Explain why the red dots should have a 1-1 relationship with the black dots.


-- 
David.

> 
> Thank you so much!
> 
> Sincerely,
> 
> Milu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dulcalma at bigpond.com  Mon Oct 17 06:01:35 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Mon, 17 Oct 2016 15:01:35 +1100
Subject: [R] suppress labels in lattice barchart
In-Reply-To: <CY1PR07MB258841C4C868194E420B14F7FADE0@CY1PR07MB2588.namprd07.prod.outlook.com>
References: <CY1PR07MB258841C4C868194E420B14F7FADE0@CY1PR07MB2588.namprd07.prod.outlook.com>
Message-ID: <001001d2282b$27b6c580$77245080$@bigpond.com>

Hi

Try

barchart(name ~ age, data = boy.age, scales = list(y = list(alternating =
FALSE, at = 1:4, labels = rep("",4))))

see ?lattice::xyplot for details 

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Naresh
Gurbuxani
Sent: Sunday, 16 October 2016 10:44
To: R-help at r-project.org
Subject: [R] suppress labels in lattice barchart

I would like to print a barchart without labels for categorical variables.
?What change should be made to below command?

Thanks,
Naresh

boy.age <- data.frame(name = c("alpha", "beta", "charlie", "gerald"), age =
c(7, 9, 6, 5))

boy.age$name <- with(boy.age, reorder(name, age))

# draws with names on labels
barchart(name ~ age, data = boy.age, scales = list(y = list(alternating =
FALSE)))

# draws with names on labels
barchart(name ~ age, data = boy.age, ylab = "")
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Mon Oct 17 11:07:03 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 17 Oct 2016 22:07:03 +1300
Subject: [R] Problem installing rgdal on a laptop running Ubuntu 16.04.1
In-Reply-To: <5e8126a8-3480-2f08-99c1-8e5b6996f8fc@gmail.com>
References: <e5e6186d-02fa-a805-7f74-4f4f641f3914@auckland.ac.nz>
	<5e8126a8-3480-2f08-99c1-8e5b6996f8fc@gmail.com>
Message-ID: <8aec931b-a597-4199-4400-72c6b574c905@auckland.ac.nz>


> On 10/04/2016 05:54 PM, Rolf Turner wrote:
>>
>> I previously sent a cri de coeur about this problem to the r-help list
>> but so far have not managed to extract a solution.  So I am trying here.
>> (Uh, Ubuntu *is* a "special instance" of Debian, isn't it?)
>>
>> The problem is that I cannot install rgdal, and I need it.  Rather
>> desperately.
>>
>> I do:
>>
>>     install.packages("rgdal",lib="/home/rolf/Rlib")
>>
>> and get the error message:
>>
>>> ** testing if installed package can be loaded
>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>   unable to load shared object '/home/rolf/Rlib/rgdal/libs/rgdal.so':
>>>   /home/rolf/Rlib/rgdal/libs/rgdal.so: undefined symbol:
>>> CPLQuietErrorHandler
>>> Error: loading failed
>>> Execution halted

Since I (in my desperation) cross-posted to r-sig-debian and r-help, I 
am sending this "SOLVED" message to both lists.

The solution took a long while to find, but in the end it was very simple.

Quite a while back I was having problems with installing some package
(I *think* it was one of my own packages, hmm.discnp), and someone (the 
details are lost in the mists of time) advised me to create a directory 
".R" in my home directory and in it place a file "Makevars" containing 
the lines:

> FCFLAGS = -g -O2 -mtune=native -fbounds-check
> FFLAGS = -g -O2 -mtune=native -fbounds-check
> PKG_LIBS=$(LAPACK_LIBS) $(BLAS_LIBS) $(FLIBS)

This solved the problem that I was having at that time.  I had long 
forgotten the directory ".R" and *that* was  what was causing the problem.

A *very* clever and knowledgeable young Linux whiz, who kindly agreed to 
help me with this problem, eventually tracked down the fact that it 
originated from ".R".  When I removed ".R", the problem with rgdal (and
problems with several other packages, that subsequently surfaced) went away.

My system is now humming away smoothly.

Thanks to everyone who (futilely!) attempted to help me out.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From manu.reddy52 at gmail.com  Mon Oct 17 11:58:03 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Mon, 17 Oct 2016 15:28:03 +0530
Subject: [R] Reg : R : How to capture cpu usage,
 memory usage and disks info using R language
In-Reply-To: <CAAxdm-7EEMq0JUisuKy3uwHs-Umum0EH48n2iSnscxGK86MDww@mail.gmail.com>
References: <CADG9u0BpE6DBVWtRXunviWAL00jV0QD2TRZ3P6t82p6FC_YMyg@mail.gmail.com>
	<CAAxdm-7EEMq0JUisuKy3uwHs-Umum0EH48n2iSnscxGK86MDww@mail.gmail.com>
Message-ID: <CADG9u0B4BGUSw-xrL1ircHhPoB3bV3mOrZqqvei3=zPjM-qHBg@mail.gmail.com>

Thanks Jim.



   Actually my requirement is I have ~ 20 servers which are running on
windows server family OS,if I want to check any server cpu usge,memory
usage or disk info I need to log into every server instead of doing like
this if I  get that kind of information using R then I can save it in some
RDBMS database then I will populate this live data on some dashboard like
which are made by R using shiny,so that I can view/get the all the
information on single page.



   Here for me challenging work is how to capture cpu,memory,disk info
using R .

On Sun, Oct 16, 2016 at 8:37 PM, jim holtman <jholtman at gmail.com> wrote:

> Here is a start on the solution.  This will create a VBS script that
> will gather the CPU data and return it in a character vector that you
> can extract the data from.  You can add to it to get the other data
> you are looking for.
>
> ########################
> > temp <- tempfile(fileext = '.vbs')  # get a temp file
> >
> > # create the VBS file to collect processor data
> > writeLines('Set objWMIService = GetObject("winmgmts:\\\\
> localhost\\root\\CIMV2")
> + Set CPUInfo = objWMIService.ExecQuery("SELECT * FROM
> Win32_PerfFormattedData_PerfOS_Processor",,48)
> + For Each Item in CPUInfo
> +     Wscript.Echo "PercentProcessorTime: " & Item.PercentProcessorTime & _
> +          "  processor:" & Item.Name
> + Next',
> +  temp)
> >
> > results <- shell(paste("cscript", temp), intern = TRUE)  # execute using
> 'cscript'
> > results # all the data
> [1] "Microsoft (R) Windows Script Host Version 5.8"
> [2] "Copyright (C) Microsoft Corporation. All rights reserved."
> [3] ""
> [4] "PercentProcessorTime: 18  processor:0"
> [5] "PercentProcessorTime: 6  processor:1"
> [6] "PercentProcessorTime: 6  processor:2"
> [7] "PercentProcessorTime: 0  processor:3"
> [8] "PercentProcessorTime: 7  processor:_Total"
> > grep("processor:", results, value = TRUE)  # get just processor data
> [1] "PercentProcessorTime: 18  processor:0"     "PercentProcessorTime:
> 6  processor:1"
> [3] "PercentProcessorTime: 6  processor:2"      "PercentProcessorTime:
> 0  processor:3"
> [5] "PercentProcessorTime: 7  processor:_Total"
> >
> >
> #####################################
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Fri, Oct 14, 2016 at 5:37 AM, Manohar Reddy <manu.reddy52 at gmail.com>
> wrote:
> > Hi,
> >
> > Is there any possibility that we can capture cpu usage ,memory usage and
> > disks info using R language on *windows family OS* ?
> >
> >
> >
> >   I would like to see data that?s looks like
> > a
> >  below
> >
> >
> >
> >    Cpu usage : 70 %
> >
> >    Memory usage  : 80 %
> >
> >    Disks        : C drive ? 40 % full,D dive ? 60 %,full E drive ? 30 %
> full
> >
> >
> >    for more info please find the attachement.
> >
> >
> >  Thanks in Advance ,Manu.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 


*Manu.*

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Oct 17 12:03:58 2016
From: jholtman at gmail.com (jim holtman)
Date: Mon, 17 Oct 2016 06:03:58 -0400
Subject: [R] Reg : R : How to capture cpu usage,
 memory usage and disks info using R language
In-Reply-To: <CADG9u0B4BGUSw-xrL1ircHhPoB3bV3mOrZqqvei3=zPjM-qHBg@mail.gmail.com>
References: <CADG9u0BpE6DBVWtRXunviWAL00jV0QD2TRZ3P6t82p6FC_YMyg@mail.gmail.com>
	<CAAxdm-7EEMq0JUisuKy3uwHs-Umum0EH48n2iSnscxGK86MDww@mail.gmail.com>
	<CADG9u0B4BGUSw-xrL1ircHhPoB3bV3mOrZqqvei3=zPjM-qHBg@mail.gmail.com>
Message-ID: <CAAxdm-4H110+4Vqf_j7GR0YXvauDUoBM=C2M9agjb8w0wjxpMA@mail.gmail.com>

within the VBS script you can easily access remote computers.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Mon, Oct 17, 2016 at 5:58 AM, Manohar Reddy <manu.reddy52 at gmail.com> wrote:
> Thanks Jim.
>
>
>
>    Actually my requirement is I have ~ 20 servers which are running on
> windows server family OS,if I want to check any server cpu usge,memory usage
> or disk info I need to log into every server instead of doing like this if I
> get that kind of information using R then I can save it in some RDBMS
> database then I will populate this live data on some dashboard like which
> are made by R using shiny,so that I can view/get the all the information on
> single page.
>
>
>
>    Here for me challenging work is how to capture cpu,memory,disk info using
> R .
>
>
> On Sun, Oct 16, 2016 at 8:37 PM, jim holtman <jholtman at gmail.com> wrote:
>>
>> Here is a start on the solution.  This will create a VBS script that
>> will gather the CPU data and return it in a character vector that you
>> can extract the data from.  You can add to it to get the other data
>> you are looking for.
>>
>> ########################
>> > temp <- tempfile(fileext = '.vbs')  # get a temp file
>> >
>> > # create the VBS file to collect processor data
>> > writeLines('Set objWMIService =
>> > GetObject("winmgmts:\\\\localhost\\root\\CIMV2")
>> + Set CPUInfo = objWMIService.ExecQuery("SELECT * FROM
>> Win32_PerfFormattedData_PerfOS_Processor",,48)
>> + For Each Item in CPUInfo
>> +     Wscript.Echo "PercentProcessorTime: " & Item.PercentProcessorTime &
>> _
>> +          "  processor:" & Item.Name
>> + Next',
>> +  temp)
>> >
>> > results <- shell(paste("cscript", temp), intern = TRUE)  # execute using
>> > 'cscript'
>> > results # all the data
>> [1] "Microsoft (R) Windows Script Host Version 5.8"
>> [2] "Copyright (C) Microsoft Corporation. All rights reserved."
>> [3] ""
>> [4] "PercentProcessorTime: 18  processor:0"
>> [5] "PercentProcessorTime: 6  processor:1"
>> [6] "PercentProcessorTime: 6  processor:2"
>> [7] "PercentProcessorTime: 0  processor:3"
>> [8] "PercentProcessorTime: 7  processor:_Total"
>> > grep("processor:", results, value = TRUE)  # get just processor data
>> [1] "PercentProcessorTime: 18  processor:0"     "PercentProcessorTime:
>> 6  processor:1"
>> [3] "PercentProcessorTime: 6  processor:2"      "PercentProcessorTime:
>> 0  processor:3"
>> [5] "PercentProcessorTime: 7  processor:_Total"
>> >
>> >
>> #####################################
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>>
>> On Fri, Oct 14, 2016 at 5:37 AM, Manohar Reddy <manu.reddy52 at gmail.com>
>> wrote:
>> > Hi,
>> >
>> > Is there any possibility that we can capture cpu usage ,memory usage and
>> > disks info using R language on *windows family OS* ?
>> >
>> >
>> >
>> >   I would like to see data that?s looks like
>> > a
>> >  below
>> >
>> >
>> >
>> >    Cpu usage : 70 %
>> >
>> >    Memory usage  : 80 %
>> >
>> >    Disks        : C drive ? 40 % full,D dive ? 60 %,full E drive ? 30 %
>> > full
>> >
>> >
>> >    for more info please find the attachement.
>> >
>> >
>> >  Thanks in Advance ,Manu.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
>
>
> Manu.


From bob at rud.is  Mon Oct 17 15:21:09 2016
From: bob at rud.is (Bob Rudis)
Date: Mon, 17 Oct 2016 09:21:09 -0400
Subject: [R] Reg : R : How to capture cpu usage,
 memory usage and disks info using R language
In-Reply-To: <CAAxdm-4H110+4Vqf_j7GR0YXvauDUoBM=C2M9agjb8w0wjxpMA@mail.gmail.com>
References: <CADG9u0BpE6DBVWtRXunviWAL00jV0QD2TRZ3P6t82p6FC_YMyg@mail.gmail.com>
	<CAAxdm-7EEMq0JUisuKy3uwHs-Umum0EH48n2iSnscxGK86MDww@mail.gmail.com>
	<CADG9u0B4BGUSw-xrL1ircHhPoB3bV3mOrZqqvei3=zPjM-qHBg@mail.gmail.com>
	<CAAxdm-4H110+4Vqf_j7GR0YXvauDUoBM=C2M9agjb8w0wjxpMA@mail.gmail.com>
Message-ID: <CAA-FpKVjMT=1zt8Nx0QojW4nyATP1_NKvzvQZSTh2U_fcG0Dww@mail.gmail.com>

You can do something like:
https://www.simple-talk.com/sql/performance/collecting-performance-data-into-a-sql-server-table/
and avoid the R step. Let the log perf data directly.

On Mon, Oct 17, 2016 at 6:03 AM, jim holtman <jholtman at gmail.com> wrote:
> within the VBS script you can easily access remote computers.
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Mon, Oct 17, 2016 at 5:58 AM, Manohar Reddy <manu.reddy52 at gmail.com> wrote:
>> Thanks Jim.
>>
>>
>>
>>    Actually my requirement is I have ~ 20 servers which are running on
>> windows server family OS,if I want to check any server cpu usge,memory usage
>> or disk info I need to log into every server instead of doing like this if I
>> get that kind of information using R then I can save it in some RDBMS
>> database then I will populate this live data on some dashboard like which
>> are made by R using shiny,so that I can view/get the all the information on
>> single page.
>>
>>
>>
>>    Here for me challenging work is how to capture cpu,memory,disk info using
>> R .
>>
>>
>> On Sun, Oct 16, 2016 at 8:37 PM, jim holtman <jholtman at gmail.com> wrote:
>>>
>>> Here is a start on the solution.  This will create a VBS script that
>>> will gather the CPU data and return it in a character vector that you
>>> can extract the data from.  You can add to it to get the other data
>>> you are looking for.
>>>
>>> ########################
>>> > temp <- tempfile(fileext = '.vbs')  # get a temp file
>>> >
>>> > # create the VBS file to collect processor data
>>> > writeLines('Set objWMIService =
>>> > GetObject("winmgmts:\\\\localhost\\root\\CIMV2")
>>> + Set CPUInfo = objWMIService.ExecQuery("SELECT * FROM
>>> Win32_PerfFormattedData_PerfOS_Processor",,48)
>>> + For Each Item in CPUInfo
>>> +     Wscript.Echo "PercentProcessorTime: " & Item.PercentProcessorTime &
>>> _
>>> +          "  processor:" & Item.Name
>>> + Next',
>>> +  temp)
>>> >
>>> > results <- shell(paste("cscript", temp), intern = TRUE)  # execute using
>>> > 'cscript'
>>> > results # all the data
>>> [1] "Microsoft (R) Windows Script Host Version 5.8"
>>> [2] "Copyright (C) Microsoft Corporation. All rights reserved."
>>> [3] ""
>>> [4] "PercentProcessorTime: 18  processor:0"
>>> [5] "PercentProcessorTime: 6  processor:1"
>>> [6] "PercentProcessorTime: 6  processor:2"
>>> [7] "PercentProcessorTime: 0  processor:3"
>>> [8] "PercentProcessorTime: 7  processor:_Total"
>>> > grep("processor:", results, value = TRUE)  # get just processor data
>>> [1] "PercentProcessorTime: 18  processor:0"     "PercentProcessorTime:
>>> 6  processor:1"
>>> [3] "PercentProcessorTime: 6  processor:2"      "PercentProcessorTime:
>>> 0  processor:3"
>>> [5] "PercentProcessorTime: 7  processor:_Total"
>>> >
>>> >
>>> #####################################
>>>
>>>
>>> Jim Holtman
>>> Data Munger Guru
>>>
>>> What is the problem that you are trying to solve?
>>> Tell me what you want to do, not how you want to do it.
>>>
>>>
>>> On Fri, Oct 14, 2016 at 5:37 AM, Manohar Reddy <manu.reddy52 at gmail.com>
>>> wrote:
>>> > Hi,
>>> >
>>> > Is there any possibility that we can capture cpu usage ,memory usage and
>>> > disks info using R language on *windows family OS* ?
>>> >
>>> >
>>> >
>>> >   I would like to see data that?s looks like
>>> > a
>>> >  below
>>> >
>>> >
>>> >
>>> >    Cpu usage : 70 %
>>> >
>>> >    Memory usage  : 80 %
>>> >
>>> >    Disks        : C drive ? 40 % full,D dive ? 60 %,full E drive ? 30 %
>>> > full
>>> >
>>> >
>>> >    for more info please find the attachement.
>>> >
>>> >
>>> >  Thanks in Advance ,Manu.
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>> --
>>
>>
>> Manu.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dogrdc at gmail.com  Mon Oct 17 05:53:14 2016
From: dogrdc at gmail.com (=?UTF-8?Q?David_Gonz=C3=A1lez?=)
Date: Sun, 16 Oct 2016 20:53:14 -0700 (PDT)
Subject: [R] Specific question on LDheatmap
In-Reply-To: <6461D613558064479012D1FDB7DD9C87012C1CA4@EXV5.ds.umcutrecht.nl>
References: <6461D613558064479012D1FDB7DD9C87012C1CA4@EXV5.ds.umcutrecht.nl>
Message-ID: <453078f6-5d3b-43c2-a678-dc92e2a8150f@googlegroups.com>

Have you been codify your SNP to numbers (ej. 0, 1, 2) and perform analysis 
again?

El martes, 8 de julio de 2008, 7:36:00 (UTC-6), Boks, M.P.M. escribi?:
>
>
> Dear R-friends,
>
> I am stuck making an LD plot of a small genotype set:
>
> An exert of my data (genotypes)
>
> >tempped.exert
> V27/V28 V33/V34 V39/V40 V41/V42
> 1      B/B     B/B     A/A     B/B
> 2      B/A     B/B     A/B     B/B
> 3      B/B     B/B     A/A     B/B
> 4      B/A     B/A     A/B     B/A
> 5      B/B     B/B     A/A     B/B
>
> The command:
> >LDheatmap(tempped.exert)
>
> Gives me the desired LD map of the first two columns only.
>
> How do I make it to take all 4 SNP's/colomns?
>
> Your help is highly appreciated,
>
> Thanks,
>
> Marco
>
> ______________________________________________
> R-h... at r-project.org <javascript:> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

From dogrdc at gmail.com  Mon Oct 17 06:01:47 2016
From: dogrdc at gmail.com (=?UTF-8?Q?David_Gonz=C3=A1lez?=)
Date: Sun, 16 Oct 2016 21:01:47 -0700 (PDT)
Subject: [R] LDheatmap
In-Reply-To: <CAJOiR6aUvacA40aCX-rep0MQMvMqAvqYFfhL6M3yNYRKjL8BOA@mail.gmail.com>
References: <CADDFq31Fp-z7TgNTex__o90LgR1Xk_i3qoQb6FcKaekaZWDWLA@mail.gmail.com>
	<CAGxFJbTKC2kv1ezJF_mA+dKgwBoPg1=Lq+vWNHxMPOO8pMJdXg@mail.gmail.com>
	<CAJOiR6aUvacA40aCX-rep0MQMvMqAvqYFfhL6M3yNYRKjL8BOA@mail.gmail.com>
Message-ID: <a41cb7fa-59bc-4c5c-9ab1-7808872cf584@googlegroups.com>

Yes, I used LDheatmap just a moment... First you need to convert your 
matrix (ej. your geno file) to snp.matrix usin the package "chopsticks", 
web> https://bioconductor.org/packages/release/bioc/html/chopsticks.html.

This package is no in R library. You need use a sourse. Use this code>

## try http:// if https:// URLs are not supported
source("https://bioconductor.org/biocLite.R")
biocLite("chopsticks")

Then, a example to convert your matrix (geno file) to snp.matrix and use LDheatmap function

# Pass LDheatmap a snp.matrix object
set.seed(1)
#make an example matrix of genotypes, coded as 0, 1 2 copies of an index allele
gdat<-matrix(rbinom(n=500,size=2,prob=.5),ncol=5) 
require(chopsticks)
gdat<-as(gdat,"snp.matrix")
library(LDheatmap)
LDheatmap(gdat,genetic.distances=c(0,1000,3000,4000,10000))

I hope help you..




El mi?rcoles, 3 de febrero de 2016, 18:08:46 (UTC-6), Val escribi?:
>
> Thank you Bert, 
>
> Yes I looked a this one and I was looking for if any one has used it or 
> not 
> before?  My data set is different what they are showing in the paper 
>
>
>
>
>
> On Wed, Feb 3, 2016 at 4:00 PM, Bert Gunter <bgunte... at gmail.com 
> <javascript:>> wrote: 
>
> > Have you looked here (found immediately by an internet search!)? 
> > 
> > 
> https://cran.r-project.org/web/packages/LDheatmap/vignettes/LDheatmap.pdf 
> > 
> > Cheers, 
> > Bert 
> > 
> > 
> > 
> > Bert Gunter 
> > 
> > "The trouble with having an open mind is that people keep coming along 
> > and sticking things into it." 
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip ) 
> > 
> > 
> > On Wed, Feb 3, 2016 at 1:49 PM, Ashta <sew... at gmail.com <javascript:>> 
> wrote: 
> > > Hi all, 
> > > 
> > > I am  looking for an R package that calculates  a pair wise LD 
> > > (linkage disequilibrium) I came up with  library(LDheatmap).  has any 
> > > one used this library? I would appreciate if I get a help how to use 
> > > this library for my set of data.. 
> > > 
> > > 
> > > My data set look like 
> > > 
> > > Geno file 
> > > Name1 1 1 2 2 2 2 
> > > Name2 2 2 2 2 2 2 
> > > Name3 2 2 2 2 2 2 
> > > Name4  2 2 2 2 2 2 
> > > Name5 1 1 2 2 2 2 
> > > 
> > > 
> > > NameN  1   1 1 2 2 2 2 
> > > 
> > > 
> > > The other file is map file 
> > > Chromosome, SNP, Location (physical) 
> > > 
> > > 
> > > Thank you in advance 
> > > 
> > > ______________________________________________ 
> > > R-h... at r-project.org <javascript:> mailing list -- To UNSUBSCRIBE and 
> more, see 
> > > https://stat.ethz.ch/mailman/listinfo/r-help 
> > > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html 
> > > and provide commented, minimal, self-contained, reproducible code. 
> > 
> > ______________________________________________ 
> > R-h... at r-project.org <javascript:> mailing list -- To UNSUBSCRIBE and 
> more, see 
> > https://stat.ethz.ch/mailman/listinfo/r-help 
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html 
> > and provide commented, minimal, self-contained, reproducible code. 
> > 
>
>         [[alternative HTML version deleted]] 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list -- To UNSUBSCRIBE and 
> more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From h.attia at aucegypt.edu  Mon Oct 17 10:52:03 2016
From: h.attia at aucegypt.edu (Heba Attia)
Date: Mon, 17 Oct 2016 10:52:03 +0200
Subject: [R] Caret Train does not output the Accuracy SD
Message-ID: <CAHS-EesDfYH5WsoOhMEuQfY3M2uL+12=ULjOJdmXe2f0WDDgww@mail.gmail.com>

Hello Rescuers,

I have a problem with retrieving the Accuracy Standard Deviation for a
"nnet" model trained by "train" in the "caret" package.

Below is my code. I checked several examples online whose published output
shows Accuracy SD but I could not get to finding a difference between these
codes and mine. I hope someone can help with identifying where my problem
is.

*set.seed(42)*
*control <- trainControl(method="repeatedcv", number=10, repeats=5)*

*rfFit <- train(Label ~., data = Train_2.4.16,*
*                 method = "rf",*
*                 preProc = c("center", "scale"),*
*                 tuneLength = 10,*
*                 metric = "Accuracy",*
*                 trControl=control,*
*                 allowParallel=TRUE)*
*print(rfFit) *

?Below is the output I get:
?
?*Random Forest *

*3141 samples*
* 110 predictor*
*   5 classes: '(2.81,3.19]', '(3.19,3.48]', '(3.48,3.74]', '(3.74,4]',
'[0.43,2.81]' *

*No pre-processing*
*Resampling: Cross-Validated (10 fold, repeated 5 times) *
*Summary of sample sizes: 2827, 2827, 2828, 2827, 2828, 2827, ... *
*Resampling results:*

*  Accuracy   Kappa    *
*  0.7520328  0.6900293*

*Tuning parameter 'mtry' was held constant at a value of 10.48809?*

?If relevant, I am using Windows ?10, RStudio and the Caret package updated
as of today version 6.0-71

?Thank you,
Heba. ?

-- 


*Heba AtteyaResearch Analyst Data Analytics and Institutional Researchtel.
20.2.2615. 2230"Information is the oil of the 21st century, and analytics
is the combustion engine" ~Senior VP, Gartner Research*

	[[alternative HTML version deleted]]


From johanlarsson at outlook.com  Sun Oct 16 11:49:05 2016
From: johanlarsson at outlook.com (Johan Larsson)
Date: Sun, 16 Oct 2016 09:49:05 +0000
Subject: [R] [R-pkgs] New package: eulerr 0.1.0
Message-ID: <AM5PR0801MB1732ADA1AEAB51A947BC6CC3C0D10@AM5PR0801MB1732.eurprd08.prod.outlook.com>

Dear R users,



I would like to announce the first version of eulerr (https://cran.r-project.org/package=eulerr). eulerr generates area-proportional euler diagrams that display set relationships (intersections, unions, and disjoints) with circles. Euler diagrams (https://en.wikipedia.org/wiki/Euler_diagram) are Venn diagrams without the requirement that all set interactions be present (whether they are empty or not). That is, depending on input, eulerr will sometimes produce Venn diagrams and sometimes not.



Please see the vignette (https://cran.r-project.org/web/packages/eulerr/vignettes/introduction.html) for a brief introduction or visit the repository on GitHub (https://github.com/jolars/eulerr) to contribute.



All the best,

Johan

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From rshepard at appl-ecosys.com  Mon Oct 17 16:45:08 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Mon, 17 Oct 2016 07:45:08 -0700 (PDT)
Subject: [R] Adjusting axis labels on lattice xyplot
In-Reply-To: <58836C90-708D-41AF-B62B-2634D36CF003@comcast.net>
References: <alpine.LNX.2.11.1610141153020.8550@localhost>
	<291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>
	<alpine.LNX.2.11.1610141540310.8550@localhost>
	<58836C90-708D-41AF-B62B-2634D36CF003@comcast.net>
Message-ID: <alpine.LNX.2.11.1610170742330.26904@localhost>

On Fri, 14 Oct 2016, David Winsemius wrote:

> xyplot(amount ~ date | station, data=rain, main="Weather Stations",
>   xlab="Date", ylab="Amount (inches)", pch=16, col=132,
>   scales=list(y=list(at=0:4),
>               x=list(at=seq(min(rain$date), max(rain$date), by='week'), rot=90) )
>     )

David,

   I searched ?xyplot for the 'by' option in scales and did not find it. I
understand the other parameters of scales and would like to learn how to use
'by' when appropriate.

TIA,

Rich


From ruipbarradas at sapo.pt  Mon Oct 17 17:31:11 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 17 Oct 2016 16:31:11 +0100
Subject: [R] Adjusting axis labels on lattice xyplot
In-Reply-To: <alpine.LNX.2.11.1610170742330.26904@localhost>
References: <alpine.LNX.2.11.1610141153020.8550@localhost>	<291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>	<alpine.LNX.2.11.1610141540310.8550@localhost>	<58836C90-708D-41AF-B62B-2634D36CF003@comcast.net>
	<alpine.LNX.2.11.1610170742330.26904@localhost>
Message-ID: <5804EEBF.9070206@sapo.pt>

Hello,

I'm not a lattice user but the 'by' argument is not an argument of 
xyplot, it's an argument of ?seq.Date.

Hope this helps,

Rui Barradas

Em 17-10-2016 15:45, Rich Shepard escreveu:
> On Fri, 14 Oct 2016, David Winsemius wrote:
>
>> xyplot(amount ~ date | station, data=rain, main="Weather Stations",
>>   xlab="Date", ylab="Amount (inches)", pch=16, col=132,
>>   scales=list(y=list(at=0:4),
>>               x=list(at=seq(min(rain$date), max(rain$date),
>> by='week'), rot=90) )
>>     )
>
> David,
>
>    I searched ?xyplot for the 'by' option in scales and did not find it. I
> understand the other parameters of scales and would like to learn how to
> use
> 'by' when appropriate.
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From c.danyluck at gmail.com  Mon Oct 17 17:42:14 2016
From: c.danyluck at gmail.com (Chad Danyluck)
Date: Mon, 17 Oct 2016 11:42:14 -0400
Subject: [R] Is it possible to extract coefficient '(Intercept)' with an
 identifier (Group ID)
Message-ID: <CA+_f+REzrN5ndSh8mA_RiN5Xps7jS6J6U0WuJM628LBPeiwoNw@mail.gmail.com>

Hello,

I have a data set with 80 observations (21 groups) on which I have run an
MLM (using lme).
I want to extract the coefficients for the intercept from my MLM using:

coefficients(summary(mig1.mlm))$'(Intercept)'

This produces a list of 21 intercepts, one for each group. For another test
I want to run, I need to know which coefficient corresponds to which group,
however, it is not clear to me how the list of intercepts are ordered.
Thus, I do not know which group size to assign to each intercept. Does
anyone know if there is a set order in which coefficients get listed when
using the 'coefficients()' function on an lme object? Is there a way to
extract group ID along with these coefficients?

I have provided the dput code for reproducing the results of my lme object
on a small sample of my data set, which only includes observations for 16
groups. I apologize that the dput code is a bit long, but if I use fewer
observations the lme() will not run.

structure(list(modelStruct = structure(list(reStruct = structure(list(
    mig1.data.group.id = structure(c(0.542553815682571, -3.00715767259167,
    -0.0442257816422898), formula = ~1 + mig1.data.minutes, Dimnames = list(
        c("(Intercept)", "mig1.data.minutes"), c("(Intercept)",
        "mig1.data.minutes")), class = c("pdLogChol", "pdSymm",
    "pdMat"))), .Names = "mig1.data.group.id", settings = c(1,
1, 0, 4), class = "reStruct", plen = structure(3L, .Names = "
mig1.data.group.id"))), .Names = "reStruct", settings = c(1,
0, 1, 4), class = c("lmeStructInt", "lmeStruct", "modelStruct"
), pmap = structure(c(TRUE, TRUE, TRUE), .Dim = c(3L, 1L), .Dimnames = list(
    NULL, "reStruct"))), dims = structure(list(N = 19L, Q = 1L,
    qvec = c(2, 0, 0), ngrps = structure(c(14L, 1L, 1L), .Names = c("
mig1.data.group.id",
    "X", "y")), ncol = c(2, 6, 1)), .Names = c("N", "Q", "qvec",
"ngrps", "ncol")), contrasts = structure(list(), .Names = character(0)),
    coefficients = structure(list(fixed = structure(c(0.592247813206646,
    -0.014327735870407, 0.511918311092002, 0.115144106181435,
    -0.528777081078343, -0.672133737297911), .Names = c("(Intercept)",
    "c.group.size", "poly(c.minutes, 2)1", "poly(c.minutes, 2)2",
    "c.group.size:poly(c.minutes, 2)1", "c.group.size:poly(c.minutes, 2)2"
    )), random = structure(list(mig1.data.group.id =
structure(c(0.0570720466445653,
    -0.0201731190981803, 0.0799015267182444, -0.031341565397712,
    -0.0381722036361848, 0.0114736430861277, -0.066744648680322,
    -0.00465893340911505, 0.020902212048436, 0.103713939575392,
    0.0341701969323794, -0.127867324157186, 0.0139879650936152,
    -0.0322637357200584, 0.000462148038646844, 0.00106241177658854,
    -0.000443527404792683, 0.000657233443565595, 0.00098128378165296,
    -0.00165073855689212, -0.000552460717034177, -3.8563057004643e-05,
    -0.000438319931643705, -0.00268379571707918, -0.000716549920599101,
    0.00328705496268145, -0.000204144495804703, 0.000277967797714908
    ), .Dim = c(14L, 2L), .Dimnames = list(c("2", "3", "4", "5",
    "7", "8", "10", "11", "12", "13", "16", "17", "20", "21"),
        c("(Intercept)", "mig1.data.minutes")))), .Names = "
mig1.data.group.id")), .Names = c("fixed",
    "random")), varFix = structure(c(0.000801580029879769,
-4.89031257398402e-06,
    0.000560846217563802, 0.00158064241688306, -0.00222841423081078,
    -0.0013850278556988, -4.89031257398402e-06, 0.000998585707455886,
    -0.0034436196730218, -0.0015456585682428, 0.00116336495693562,
    0.00434765229782492, 0.000560846217563802, -0.0034436196730218,
    0.0244392316273714, 0.00996105608959828, -0.00854131836998962,
    -0.0224942435104164, 0.00158064241688306, -0.0015456585682428,
    0.00996105608959828, 0.0158945692774124, -0.0133452835173244,
    -0.0153057275817998, -0.00222841423081078, 0.00116336495693562,
    -0.00854131836998962, -0.0133452835173244, 0.0227078394482903,
    0.0170647625679209, -0.0013850278556988, 0.00434765229782492,
    -0.0224942435104164, -0.0153057275817998, 0.0170647625679209,
    0.0349630532188317), .Dim = c(6L, 6L), .Dimnames =
list(c("(Intercept)",
    "c.group.size", "poly(c.minutes, 2)1", "poly(c.minutes, 2)2",
    "c.group.size:poly(c.minutes, 2)1", "c.group.size:poly(c.minutes, 2)2"
    ), c("(Intercept)", "c.group.size", "poly(c.minutes, 2)1",
    "poly(c.minutes, 2)2", "c.group.size:poly(c.minutes, 2)1",
    "c.group.size:poly(c.minutes, 2)2"))), sigma = 0.0524019104240361,
    apVar = structure(c(0.195521445237494, 0.385341061075355,
    -0.286676275652333, -0.150058129917539, 0.385341061075355,
    3.44522079913615, 0.17521882332131, -0.88335110165811,
-0.286676275652333,
    0.17521882332131, 2.73770494209246, -0.319576762409392,
-0.150058129917539,
    -0.88335110165811, -0.319576762409392, 0.493177764041453), .Dim = c(4L,
    4L), .Dimnames = list(c("reStruct.mig1.data.group.id1",
"reStruct.mig1.data.group.id2",
    "reStruct.mig1.data.group.id3", "lSigma"),
c("reStruct.mig1.data.group.id1",
    "reStruct.mig1.data.group.id2", "reStruct.mig1.data.group.id3",
    "lSigma")), Pars = structure(c(-2.40625841416319, -5.66195117995023,
    -1.60981405306962, -2.94881222984576), .Names =
c("reStruct.mig1.data.group.id1",
    "reStruct.mig1.data.group.id2", "reStruct.mig1.data.group.id3",
    "lSigma")), natural = TRUE), logLik = 11.3100253625345, numIter = NULL,
    groups = structure(list(mig1.data.group.id = structure(c(5L,
    2L, 12L, 1L, 10L, 10L, 7L, 1L, 6L, 8L, 9L, 13L, 2L, 4L, 3L,
    6L, 14L, 14L, 11L), .Label = c("2", "3", "4", "5", "7", "8",
    "10", "11", "12", "13", "16", "17", "20", "21"), class = "factor")),
.Names = "mig1.data.group.id", row.names = c("216",
    "347", "413", "555", "446", "182", "481", "559", "387", "471",
    "126", "549", "90", "173", "30", "245", "43", "44", "422"
    ), class = "data.frame"), call = lme.formula(fixed =
mig1.data.stnd.alpha ~
        c.group.size * poly(c.minutes, 2), data = mig1.small.sample,
        random = ~1 + mig1.data.minutes | mig1.data.group.id,
        na.action = "na.exclude"), terms = mig1.data.stnd.alpha ~
        c.group.size * poly(c.minutes, 2), method = "REML", fitted =
structure(c(0.481069271212693,
    0.407996506778899, 0.481069271212693, 0.654207415156227,
    0.660323053771328, 0.481069271212693, 0.654207415156227,
    0.502826045508831, 0.619699566918199, 0.678669969616632,
    0.473185648482867, 0.641692134120051, 0.619699566918199,
    0.570206450385443, 0.562812539762185, 0.67376954812038,
0.217915945757991,
    0.279144044677716, 0.376164846580292, 0.442897067576508,
    0.425007799861318, 0.353201947055507, 0.720522422573729,
    0.710361079005136, 0.584783210788085, 0.576413552135221,
    0.559898092153396, 0.589904746082024, 0.673239775067424,
    0.491896260873085, 0.65363865425562, 0.626086742234732,
0.542151052205559,
    0.636061155408539, 0.660482112853126, 0.188431888015082,
    0.248270147946232, 0.406752293909676), .Dim = c(19L, 2L), .Dimnames =
list(
        c("216", "347", "413", "555", "446", "182", "481", "559",
        "387", "471", "126", "549", "90", "173", "30", "245",
        "43", "44", "422"), c("fixed", "mig1.data.group.id"))),
    residuals = structure(c(-0.0510692712126929, 0.0420034932211007,
    -0.171069271212693, 0.105792584843773, 0.0496769462286719,
    0.138930728787307, -0.124207415156227, 0.0571739544911692,
    -0.0696995669181989, -0.00866996961663191, 0.0268143515171326,
    0.0183078658799486, -0.019699566918199, -0.040206450385443,
    0.117187460237815, 0.0162304518796199, -0.0579159457579912,
    -0.019144044677716, 0.0438351534197082, -0.0128970675765082,
    0.0249922001386821, -0.0432019470555072, 0.0394775774262709,
    -0.000361079005136378, 0.0352167892119151, -0.0464135521352211,
    0.00010190784660391, -0.0399047460820235, -0.00323977506742401,
    0.00810373912691509, 0.00636134574438041, -0.0260867422347322,
    -0.0121510522055589, 0.0439388445914611, 0.029517887146874,
    -0.0284318880150819, 0.0117298520537678, 0.0132477060903243
    ), .Dim = c(19L, 2L), .Dimnames = list(c("216", "347", "413",
    "555", "446", "182", "481", "559", "387", "471", "126", "549",
    "90", "173", "30", "245", "43", "44", "422"), c("fixed",
    "mig1.data.group.id")), std = c(0.0524019104240361, 0.0524019104240361,
    0.0524019104240361, 0.0524019104240361, 0.0524019104240361,
    0.0524019104240361, 0.0524019104240361, 0.0524019104240361,
    0.0524019104240361, 0.0524019104240361, 0.0524019104240361,
    0.0524019104240361, 0.0524019104240361, 0.0524019104240361,
    0.0524019104240361, 0.0524019104240361, 0.0524019104240361,
    0.0524019104240361, 0.0524019104240361)), fixDF = structure(list(
        X = structure(c(12, 12, 1, 1, 1, 1), .Names = c("(Intercept)",
        "c.group.size", "poly(c.minutes, 2)1", "poly(c.minutes, 2)2",
        "c.group.size:poly(c.minutes, 2)1", "c.group.size:poly(c.minutes,
2)2"
        )), terms = structure(c(12, 12, 1, 1), .Names = c("(Intercept)",
        "c.group.size", "poly(c.minutes, 2)", "c.group.size:poly(c.minutes,
2)"
        ))), .Names = c("X", "terms"), assign = structure(list(
        `(Intercept)` = 1L, c.group.size = 2L, `poly(c.minutes, 2)` = 3:4,
        `c.group.size:poly(c.minutes, 2)` = 5:6), .Names = c("(Intercept)",
    "c.group.size", "poly(c.minutes, 2)", "c.group.size:poly(c.minutes, 2)"
    )), varFixFact = structure(c(0.0234727714330888, 0.00308441687443628,
    -0.00126641961760248, 0.00412548417580657, 0.0129462509558636,
    0.00740719592892987, 0, 0.0192212361398047, -0.00494132395826749,
    -0.000413333499730955, 0.00799450545612366, -0.0232514546681108,
    0, 0, 0.0968118427734171, 0.0134638356779811, -0.0203288282252088,
    0.120300301736998, 0, 0, 0, 0.0824249430578822, 0.0489931708259258,
    0.0818557710350283, 0, 0, 0, 0, -0.119911935622324,
-0.0912631751781513,
    0, 0, 0, 0, 0, -0.186984098839531), .Dim = c(6L, 6L))), na.action =
structure(c(1L,
    2L, 3L, 5L, 8L, 23L), .Names = c("172", "497", "250", "147",
    "82", "249"), class = "exclude"), data =
structure(list(mig1.data.stnd.alpha = c(NA,
    NA, NA, 0.43, NA, 0.45, 0.31, NA, 0.76, 0.71, 0.62, 0.53,
    0.56, 0.55, 0.67, 0.5, 0.66, 0.6, 0.53, 0.68, 0.69, 0.16,
    NA, 0.26, 0.42), c.group.size = c(0.7, -0.3, 1.7, -0.3, -0.3,
    0.7, -0.3, 0.7, -1.3, -0.3, -0.3, -1.3, -1.3, 0.7, 2.7, -0.3,
    0.7, 0.7, 0.7, -0.3, 0.7, -2.3, 1.7, -2.3, -1.3), c.minutes = c(12.5,
    17.5, 7.5, -17.5, 7.5, 17.5, -17.5, 7.5, 2.5, 2.5, -17.5,
    2.5, -17.5, 7.5, 2.5, -12.5, -7.5, 7.5, -12.5, -2.5, -2.5,
    -7.5, 17.5, -12.5, -12.5), mig1.data.minutes = c(30, 35,
    25, 0, 25, 35, 0, 25, 20, 20, 0, 20, 0, 25, 20, 5, 10, 25,
    5, 15, 15, 10, 35, 5, 5), mig1.data.group.id = c(5L, 14L,
    18L, 7L, 17L, 3L, 17L, 5L, 2L, 13L, 13L, 10L, 2L, 8L, 11L,
    12L, 20L, 3L, 5L, 4L, 8L, 21L, 18L, 21L, 16L)), .Names =
c("mig1.data.stnd.alpha",
    "c.group.size", "c.minutes", "mig1.data.minutes", "mig1.data.group.id"
    ), row.names = c(172L, 497L, 250L, 216L, 147L, 347L, 413L,
    82L, 555L, 446L, 182L, 481L, 559L, 387L, 471L, 126L, 549L,
    90L, 173L, 30L, 245L, 43L, 249L, 44L, 422L), class = "data.frame")),
.Names = c("modelStruct",
"dims", "contrasts", "coefficients", "varFix", "sigma", "apVar",
"logLik", "numIter", "groups", "call", "terms", "method", "fitted",
"residuals", "fixDF", "na.action", "data"), class = "lme")





-- 
Chad M. Danyluck, MA
PhD Candidate, Psychology
University of Toronto



?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Mon Oct 17 17:42:25 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 17 Oct 2016 17:42:25 +0200
Subject: [R] Reshaping geographic data
Message-ID: <OF1BFFA8CA.872FE9CA-ONC125804F.0055C1D8-C125804F.00564666@lotus.hawesko.de>

Hi All,

I need to reshape an ESRI shape file: http://arnulf.us/PLZ and resp 
http://www.metaspatial.net/download/plz.tar.gz

I found an instruction for T-SQL Server:

https://blog.oraylis.de/2010/05/german-map-spatial-data-for-plz-postal-code-regions/

How can I do this using R?

Kind regards

Georg

-- cut --
Here's my code so far:

download.file(
    url = "http://www.metaspatial.net/download/plz.tar.gz",
    destfile = "C:/temp/plz.tar.gz")

untar(tarfile = "C:/temp/plz.tar.gz",
      exdir = "C:/temp",
      compressed = "gzip")


From rshepard at appl-ecosys.com  Mon Oct 17 18:09:42 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Mon, 17 Oct 2016 09:09:42 -0700 (PDT)
Subject: [R] Adjusting axis labels on lattice xyplot [RESOLVED]
In-Reply-To: <5804EEBF.9070206@sapo.pt>
References: <alpine.LNX.2.11.1610141153020.8550@localhost>
	<291A4F86-FCF5-42F3-A5A3-7B5BA47B3DA3@comcast.net>
	<alpine.LNX.2.11.1610141540310.8550@localhost>
	<58836C90-708D-41AF-B62B-2634D36CF003@comcast.net>
	<alpine.LNX.2.11.1610170742330.26904@localhost>
	<5804EEBF.9070206@sapo.pt>
Message-ID: <alpine.LNX.2.11.1610170908410.26904@localhost>

On Mon, 17 Oct 2016, Rui Barradas wrote:

> I'm not a lattice user but the 'by' argument is not an argument of xyplot,
> it's an argument of ?seq.Date.

Rui,

   Yes, this does help.

Thanks very much,

Rich


From bjpmodi2016 at gmail.com  Mon Oct 17 20:46:48 2016
From: bjpmodi2016 at gmail.com (Narendra Modi)
Date: Mon, 17 Oct 2016 13:46:48 -0500
Subject: [R] lb and ub for variables - nloptr
Message-ID: <CAPq=xQB1bs-LPK-GgceJbTR37=umvyWF-fPRARmb=VpKij9oew@mail.gmail.com>

Hello All,
I use nloptr to perform optimization.
In one example,the lb for each variable is 0 and ub is Inf during the first run.

x <- c(10,10,10,10) # initial values
lb <- c(0,0,0,0)
ub <- c(Inf,Inf,Inf,Inf)

optimised.answer  = 4.2,0.001,20,21

To run the second time for a better match, I set a condition in the ub
matrix saying if the value of any of optimized variable in the first
run is less than 0.01, set the ub for that variable as 0; both lb and
ub for that variable is 0. So I expect that during the second run,
this variable is not varied by the optimizer at all.

i.e. new.x <- c(4.2,0,20,21)
But when I run the optimizer the second time with the "new.x",all the
above variable is still varied by the optimizer!

Is there anyway to not have the second variable varied?

NM


From macqueen1 at llnl.gov  Mon Oct 17 20:49:59 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 17 Oct 2016 18:49:59 +0000
Subject: [R] Reshaping geographic data
In-Reply-To: <OF1BFFA8CA.872FE9CA-ONC125804F.0055C1D8-C125804F.00564666@lotus.hawesko.de>
References: <OF1BFFA8CA.872FE9CA-ONC125804F.0055C1D8-C125804F.00564666@lotus.hawesko.de>
Message-ID: <D42A69F0.18AF2D%macqueen1@llnl.gov>

I suggest you simplify your computing task by making this into three
distinct tasks:

1. get copies of the shapefiles on your computer. Do this outside of R.
Since this has two parts, i.e., downloading and unzipping, it will be
easier at first to do it outside of r. Then later you can figure out how
to do it using R if necessary.

2. figure out how to load shapefiles into R (the key package is rgdal)

3. figure out how to reshape a shapefile in R (I don't know what you mean
by reshape a shape file).

For steps 2 and 3, ask further questions on r-sig-geo

Are you aware that a "shapefile" is actually several files, all with the
same prefix but different suffixes? I'd suggest putting them in a
subdirectory of your working directory.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/17/16, 8:42 AM, "R-help on behalf of G.Maubach at weinwolf.de"
<r-help-bounces at r-project.org on behalf of G.Maubach at weinwolf.de> wrote:

>Hi All,
>
>I need to reshape an ESRI shape file: http://arnulf.us/PLZ and resp
>http://www.metaspatial.net/download/plz.tar.gz
>
>I found an instruction for T-SQL Server:
>
>https://blog.oraylis.de/2010/05/german-map-spatial-data-for-plz-postal-cod
>e-regions/
>
>How can I do this using R?
>
>Kind regards
>
>Georg
>
>-- cut --
>Here's my code so far:
>
>download.file(
>    url = "http://www.metaspatial.net/download/plz.tar.gz",
>    destfile = "C:/temp/plz.tar.gz")
>
>untar(tarfile = "C:/temp/plz.tar.gz",
>      exdir = "C:/temp",
>      compressed = "gzip")
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dmit-cher at mail.ru  Mon Oct 17 21:03:25 2016
From: dmit-cher at mail.ru (=?UTF-8?B?RG1pdHJpeSBDaGVybnlraA==?=)
Date: Mon, 17 Oct 2016 22:03:25 +0300
Subject: [R] =?utf-8?q?findInterval=28=29_surprising_behavior?=
Message-ID: <1476731005.578838968@f384.i.mail.ru>

Hello,

I call function findInterval in the following way:

findInterval(x=c(6, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE),

and expect that it will return 4 1 1 1. But the function returns 4 2 1 1 instead. Moreover, if I change the first element in x to, say, 4 -

findInterval(x=c(4, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE)

then the function returns 3 1 1 1.

Why are results for identical elements in x not the same? And why is element in x influenced by previous one? I suspect this is a bug but I am not 100% sure.

Technical details:

sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

locale:
?[1] LC_CTYPE=ru_RU.UTF-8?????? LC_NUMERIC=C?????????????? LC_TIME=ru_RU.UTF-8??????? LC_COLLATE=ru_RU.UTF-8???? LC_MONETARY=ru_RU.UTF-8? ?
?[6] LC_MESSAGES=ru_RU.UTF-8??? LC_PAPER=ru_RU.UTF-8?????? LC_NAME=C????????????????? LC_ADDRESS=C?????????????? LC_TELEPHONE=C?????????? ?
[11] LC_MEASUREMENT=ru_RU.UTF-8 LC_IDENTIFICATION=C????? ?

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods?? base??? ?

loaded via a namespace (and not attached):
[1] tools_3.3.1


Thanks.

-- 
Dmitrii Chernykh
	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon Oct 17 21:48:19 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 17 Oct 2016 20:48:19 +0100
Subject: [R] findInterval() surprising behavior
In-Reply-To: <1476731005.578838968@f384.i.mail.ru>
References: <1476731005.578838968@f384.i.mail.ru>
Message-ID: <58052B03.9040607@sapo.pt>

Hello,

Same on Windows 7.

 > findInterval(x=c(6, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE)
[1] 4 2 1 1
 > findInterval(x=c(4, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE)
[1] 3 1 1 1
 > sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=Portuguese_Portugal.1252 
LC_CTYPE=Portuguese_Portugal.1252
[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lattice_0.20-33

loaded via a namespace (and not attached):
[1] tools_3.3.1 grid_3.3.1

Rui Barradas

Em 17-10-2016 20:03, Dmitriy Chernykh via R-help escreveu:
> Hello,
>
> I call function findInterval in the following way:
>
> findInterval(x=c(6, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE),
>
> and expect that it will return 4 1 1 1. But the function returns 4 2 1 1 instead. Moreover, if I change the first element in x to, say, 4 -
>
> findInterval(x=c(4, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE)
>
> then the function returns 3 1 1 1.
>
> Why are results for identical elements in x not the same? And why is element in x influenced by previous one? I suspect this is a bug but I am not 100% sure.
>
> Technical details:
>
> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.5 LTS
>
> locale:
>   [1] LC_CTYPE=ru_RU.UTF-8       LC_NUMERIC=C               LC_TIME=ru_RU.UTF-8        LC_COLLATE=ru_RU.UTF-8     LC_MONETARY=ru_RU.UTF-8
>   [6] LC_MESSAGES=ru_RU.UTF-8    LC_PAPER=ru_RU.UTF-8       LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=ru_RU.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.3.1
>
>
> Thanks.
>


From bjpmodi2016 at gmail.com  Tue Oct 18 00:22:20 2016
From: bjpmodi2016 at gmail.com (Narendra Modi)
Date: Mon, 17 Oct 2016 17:22:20 -0500
Subject: [R] Share R.net dll without having to share R script code?
In-Reply-To: <CAA-FpKVxOHg09F7=aiVN-1d9Mu=a3JoEeOc+v2f5OFNtT3DtpA@mail.gmail.com>
References: <CAPq=xQC2EOwJf5QKvmv9d1KGZ9KZqQaz700mN8ga=b+-jKYvrg@mail.gmail.com>
	<2384fc30-3dd3-4af4-839e-e00d86854a01@gmail.com>
	<CAPq=xQB6nSz2gLpGYyztivc5cZDTvhzz3KQCN_uPXa1z1r2M7w@mail.gmail.com>
	<CAA-FpKVxOHg09F7=aiVN-1d9Mu=a3JoEeOc+v2f5OFNtT3DtpA@mail.gmail.com>
Message-ID: <CAPq=xQCXpqrxenxwmFNuDDjj=RSFuEdx9H=p_fSU5gSYKP_jUQ@mail.gmail.com>

Hi Bob,
Could you explain a bit more on this? How do I use/configure base64?
Any document/example do you have?



On Fri, Oct 14, 2016 at 9:55 AM, Bob Rudis <bob at rud.is> wrote:
> Ugly idea/option, but you could base64 encode the R script (solely to
> avoid the need to do string quoting) and have that string in the
> source of the R.net code, then pass it in to the eval portion or write
> it out to a temp dir and pass that to the eval portion of the code.
> That way the script is embedded with the DLL and not an extra asset
> that needs to be managed.
>
> On Fri, Oct 14, 2016 at 10:43 AM, Narendra Modi <bjpmodi2016 at gmail.com> wrote:
>> Thanks Duncan. That's useful to know.
>>
>> On Fri, Oct 14, 2016 at 9:18 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>> On 14/10/2016 10:00 AM, Narendra Modi wrote:
>>>>
>>>> Hello Gurus,
>>>>
>>>> I have built a code snippet using R.net wherein I call couple of R
>>>> scripts to run optimization packages and use the output in C# code.
>>>> The way I call the R scripts is just by providing its location in the
>>>> C# code.
>>>>
>>>> So, if I have to share the .dll of the complete program, I will also
>>>> have to share the R scripts; actual code. Is there anyway to avoid it;
>>>> not having to share the r script code with users/testers.
>>>> I am considerably new to R. Any suggestion in this direction is
>>>> appreciated!
>>>>
>>>
>>> I don't know what the R.net .dll is, but if it includes R, you need to share
>>> the complete source code of anything you distribute that includes it.  The R
>>> scripts will be only a small part of that.
>>>
>>> Sharing less than that is a copyright violation, since you are only licensed
>>> to distribute R under the GPL license, and it requires that you share code
>>> of the original and your modifications.
>>>
>>> Duncan Murdoch
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From akumar at stat.tamu.edu  Mon Oct 17 22:54:52 2016
From: akumar at stat.tamu.edu (Maity, Arnab K)
Date: Mon, 17 Oct 2016 20:54:52 +0000
Subject: [R] Error message in SIS package
Message-ID: <1476737643452.97275@stat.tamu.edu>

I try to run the following code:

sis.fit <- SIS(y = Surv(time = y[, 1], event = y[, 2]), x = x, family = "cox", penalty = "lasso", tune = "cv",
                 nfolds = 10, type.measure = "deviance", nsis = min(dim(x)), iter = FALSE, seed = 334)

I get the following error:

Error in names(coef.beta) = paste("X", ix1, sep = "") :
  'names' attribute [1] must be the same length as the vector [0].

here is some information about the data.

> head(y)
  time status
1   24      1
2   31      0
3   39      0
4   64      1
5   72      1
6    6      0
> str(y)
 num [1:46, 1:2] 24 31 39 64 72 6 87 17 53 54 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:46] "1" "2" "3" "4" ...
  ..$ : chr [1:2] "time" "status"
> str(x)
 num [1:46, 1:66] 0.59234 0.30042 0.28278 -0.00966 0.08189 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:46] "1" "2" "3" "4" ...
  ..$ : chr [1:66] "EIF4EBP1" "TP53BP1" "AKT1.AKT2.AKT3" "AR" ...
> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] survival_2.39-4 SIS_0.8-3       glmnet_2.0-5    foreach_1.4.3   Matrix_1.2-6

loaded via a namespace (and not attached):
[1] tools_3.3.1      splines_3.3.1    codetools_0.2-14 grid_3.3.1       iterators_1.0.8  ncvreg_3.6-0     lattice_0.20-33
>

Please help!?




Arnab Kumar Maity
Department of Statistics
Texas A&M University
3143 TAMU, Room 401A
College Station, TX 77843
akumar at stat.tamu.edu<mailto:arnabkrmaity at stat.tamu.edu>
+1 779 777 3428<tel:%2B1%20779%20777%203428>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Oct 18 03:04:15 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 17 Oct 2016 18:04:15 -0700
Subject: [R] Share R.net dll without having to share R script code?
In-Reply-To: <CAPq=xQCXpqrxenxwmFNuDDjj=RSFuEdx9H=p_fSU5gSYKP_jUQ@mail.gmail.com>
References: <CAPq=xQC2EOwJf5QKvmv9d1KGZ9KZqQaz700mN8ga=b+-jKYvrg@mail.gmail.com>
	<2384fc30-3dd3-4af4-839e-e00d86854a01@gmail.com>
	<CAPq=xQB6nSz2gLpGYyztivc5cZDTvhzz3KQCN_uPXa1z1r2M7w@mail.gmail.com>
	<CAA-FpKVxOHg09F7=aiVN-1d9Mu=a3JoEeOc+v2f5OFNtT3DtpA@mail.gmail.com>
	<CAPq=xQCXpqrxenxwmFNuDDjj=RSFuEdx9H=p_fSU5gSYKP_jUQ@mail.gmail.com>
Message-ID: <BFA699B7-1B92-4E98-8C92-C6C629A4DC2C@comcast.net>


> On Oct 17, 2016, at 3:22 PM, Narendra Modi <bjpmodi2016 at gmail.com> wrote:
> 
> Hi Bob,
> Could you explain a bit more on this? How do I use/configure base64?
> Any document/example do you have?
> 

To Narendra;

I get the idea that this line of inquiry is designed to obfuscate R code and derivative works, which in turn I see as an effort to defeat the open source nature of the R movement. It at least violates the spirit of the various licenses under which R and the CRAN packaging policies are distributed.

I'm suggesting that those people who support an open source basis of R not continue to use Rhelp as a venue for an effort to undermine the openness of coding supported by R. If Bob disagrees with me, he is at liberty to correspond with you privately. I have no authority to enforce such advice, and anyone is free to opine on the ethics and legality of this proposed effort.

-- 

David.
> 
> 
> On Fri, Oct 14, 2016 at 9:55 AM, Bob Rudis <bob at rud.is> wrote:
>> Ugly idea/option, but you could base64 encode the R script (solely to
>> avoid the need to do string quoting) and have that string in the
>> source of the R.net code, then pass it in to the eval portion or write
>> it out to a temp dir and pass that to the eval portion of the code.
>> That way the script is embedded with the DLL and not an extra asset
>> that needs to be managed.
>> 
>> On Fri, Oct 14, 2016 at 10:43 AM, Narendra Modi <bjpmodi2016 at gmail.com> wrote:
>>> Thanks Duncan. That's useful to know.
>>> 
>>> On Fri, Oct 14, 2016 at 9:18 AM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>> On 14/10/2016 10:00 AM, Narendra Modi wrote:
>>>>> 
>>>>> Hello Gurus,
>>>>> 
>>>>> I have built a code snippet using R.net wherein I call couple of R
>>>>> scripts to run optimization packages and use the output in C# code.
>>>>> The way I call the R scripts is just by providing its location in the
>>>>> C# code.
>>>>> 
>>>>> So, if I have to share the .dll of the complete program, I will also
>>>>> have to share the R scripts; actual code. Is there anyway to avoid it;
>>>>> not having to share the r script code with users/testers.
>>>>> I am considerably new to R. Any suggestion in this direction is
>>>>> appreciated!
>>>>> 
>>>> 
>>>> I don't know what the R.net .dll is, but if it includes R, you need to share
>>>> the complete source code of anything you distribute that includes it.  The R
>>>> scripts will be only a small part of that.
>>>> 
>>>> Sharing less than that is a copyright violation, since you are only licensed
>>>> to distribute R under the GPL license, and it requires that you share code
>>>> of the original and your modifications.
>>>> 
>>>> Duncan Murdoch
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Tue Oct 18 03:25:58 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 18 Oct 2016 14:25:58 +1300
Subject: [R] [FORGED] Re: Share R.net dll without having to share R
 script code?
In-Reply-To: <BFA699B7-1B92-4E98-8C92-C6C629A4DC2C@comcast.net>
References: <CAPq=xQC2EOwJf5QKvmv9d1KGZ9KZqQaz700mN8ga=b+-jKYvrg@mail.gmail.com>
	<2384fc30-3dd3-4af4-839e-e00d86854a01@gmail.com>
	<CAPq=xQB6nSz2gLpGYyztivc5cZDTvhzz3KQCN_uPXa1z1r2M7w@mail.gmail.com>
	<CAA-FpKVxOHg09F7=aiVN-1d9Mu=a3JoEeOc+v2f5OFNtT3DtpA@mail.gmail.com>
	<CAPq=xQCXpqrxenxwmFNuDDjj=RSFuEdx9H=p_fSU5gSYKP_jUQ@mail.gmail.com>
	<BFA699B7-1B92-4E98-8C92-C6C629A4DC2C@comcast.net>
Message-ID: <cdcb2c23-f41f-1d94-75ca-59a938a51795@auckland.ac.nz>

On 18/10/16 14:04, David Winsemius wrote:
>
>> On Oct 17, 2016, at 3:22 PM, Narendra Modi <bjpmodi2016 at gmail.com> wrote:
>>
>> Hi Bob,
>> Could you explain a bit more on this? How do I use/configure base64?
>> Any document/example do you have?
>>
>
> To Narendra;
>
> I get the idea that this line of inquiry is designed to obfuscate R
code and derivative works, which in turn I see as an effort to defeat
the open source nature of the R movement. It at least violates the
spirit of the various licenses under which R and the CRAN packaging
policies are distributed.
>
> I'm suggesting that those people who support an open source basis of
> R
not continue to use Rhelp as a venue for an effort to undermine the
openness of coding supported by R. If Bob disagrees with me, he is at
liberty to correspond with you privately. I have no authority to enforce
such advice, and anyone is free to opine on the ethics and legality of
this proposed effort.

I concur with David completely.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewmil at dcn.davis.ca.us  Tue Oct 18 04:58:37 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 17 Oct 2016 19:58:37 -0700
Subject: [R] Error message in SIS package
In-Reply-To: <1476737643452.97275@stat.tamu.edu>
References: <1476737643452.97275@stat.tamu.edu>
Message-ID: <DDD2C6BB-BCCB-4DF5-BDF3-3D344562A771@dcn.davis.ca.us>

I doubt I will know how to help you in any case, but I can see that you are shackling yourself to a very small (possibly empty) set of helpers by not making your example reproducible. 

You will also slow any helpers down once you change that if you post again in HTML format... set your email program to send plain text so the code you supply doesn't get corrupted. 

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

http://adv-r.had.co.nz/Reproducibility.html

PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
-- 
Sent from my phone. Please excuse my brevity.

On October 17, 2016 1:54:52 PM PDT, "Maity, Arnab K" <akumar at stat.tamu.edu> wrote:
>I try to run the following code:
>
>sis.fit <- SIS(y = Surv(time = y[, 1], event = y[, 2]), x = x, family =
>"cox", penalty = "lasso", tune = "cv",
>nfolds = 10, type.measure = "deviance", nsis = min(dim(x)), iter =
>FALSE, seed = 334)
>
>I get the following error:
>
>Error in names(coef.beta) = paste("X", ix1, sep = "") :
>  'names' attribute [1] must be the same length as the vector [0].
>
>here is some information about the data.
>
>> head(y)
>  time status
>1   24      1
>2   31      0
>3   39      0
>4   64      1
>5   72      1
>6    6      0
>> str(y)
> num [1:46, 1:2] 24 31 39 64 72 6 87 17 53 54 ...
> - attr(*, "dimnames")=List of 2
>  ..$ : chr [1:46] "1" "2" "3" "4" ...
>  ..$ : chr [1:2] "time" "status"
>> str(x)
> num [1:46, 1:66] 0.59234 0.30042 0.28278 -0.00966 0.08189 ...
> - attr(*, "dimnames")=List of 2
>  ..$ : chr [1:46] "1" "2" "3" "4" ...
>  ..$ : chr [1:66] "EIF4EBP1" "TP53BP1" "AKT1.AKT2.AKT3" "AR" ...
>> sessionInfo()
>R version 3.3.1 (2016-06-21)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows >= 8 x64 (build 9200)
>
>locale:
>[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>States.1252    LC_MONETARY=English_United States.1252
>[4] LC_NUMERIC=C                           LC_TIME=English_United
>States.1252
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>other attached packages:
>[1] survival_2.39-4 SIS_0.8-3       glmnet_2.0-5    foreach_1.4.3  
>Matrix_1.2-6
>
>loaded via a namespace (and not attached):
>[1] tools_3.3.1      splines_3.3.1    codetools_0.2-14 grid_3.3.1      
>iterators_1.0.8  ncvreg_3.6-0     lattice_0.20-33
>>
>
>Please help!?
>
>
>
>
>Arnab Kumar Maity
>Department of Statistics
>Texas A&M University
>3143 TAMU, Room 401A
>College Station, TX 77843
>akumar at stat.tamu.edu<mailto:arnabkrmaity at stat.tamu.edu>
>+1 779 777 3428<tel:%2B1%20779%20777%203428>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From abhinabaroy09 at gmail.com  Tue Oct 18 13:38:48 2016
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Tue, 18 Oct 2016 17:08:48 +0530
Subject: [R] JSON to Dataframe
Message-ID: <CANtKHPWCrr0xKiYj4oeV+_RU4rxRsprLE8MJ-N3YK4CBCRYF+g@mail.gmail.com>

Hi R helpers,

I have json inputs from an app which I want to convert to dataframes. Below
are the two inputs. Can someone help me in converting these to dataframes

*Input1*

{"booking":{"id":"54092","createdOn":"2016-10-06T06:29:00.0000000+0000","bookingDateTime":"2016-10-08T06:45:00.0000000+0000","checkInDateTime":null,"checkOutDateTime":null,"tableNumbers":null,"pax":3,"type":"calling","status":"booked","source":"concierge","specialInstruction":"test
hoppi","outlet":{"id":"46a97c2e-c921-4339-819c-50e17f25d09a","name":"Hoppipolla"},"customer":{"name":"Hoppi","email":"
hoppi at xmail.com
","countryCallingCode":"91","phone":"8901234567"}},"eventType":"booked","serverDateTime":"2016-10-06T06:28:25.0000558+0000"}

{"booking":{"id":"54093","createdOn":"2016-10-06T06:30:00.0000000+0000","bookingDateTime":"2016-10-08T06:46:00.0000000+0000","checkInDateTime":null,"checkOutDateTime":null,"tableNumbers":null,"pax":3,"type":"calling","status":"booked","source":"concierge","specialInstruction":"test
hoppi","outlet":{"id":"46a97c2e-c922-4339-819c-50e17f25d09a","name":"Hoppipolla"},"customer":{"name":"Ravi","email":"
ravi at xmail.com
","countryCallingCode":"91","phone":"8901234548"}},"eventType":"booked","serverDateTime":"2016-10-06T06:28:25.0000558+0000"}


*Input2*


{"feedback":{"dateTime":"2016-10-06T09:24:05.0000730+0000","customerName":"mytestdevcog","averageRating":4,"isNegativeByComments":false,"outlet":{"id":"f9e9c21f-2e52-462e-a1f2-012dab216d27","name":"cholan
's Darbar"},"customer":{"name":"mytestdevcog","email":"
mytestdevcog123 at gmail.com","countryCallingCode":"91","phone":"7895478745"},"responses":[{"question":"Was
your waiting time too
long?","response":"No","questionType":"yes_no"},{"question":"Service","response":"3","questionType":"rating"},{"question":"desserts","response":"4","questionType":"rating"},{"question":"Comments","response":"good","questionType":"short_answer"},{"question":"How
likely is it that you would recommend us to a friend or
colleague?","response":"5","questionType":"nps"},{"question":"Portion
Size","response":"5","questionType":"rating"},{"question":"Indian
Food","response":"4","questionType":"rating"},{"question":"Desert
spread","response":"4","questionType":"rating"}]},"serverDateTime":"2016-10-06T09:24:27.0000644+0000"}

{"feedback":{"dateTime":"2016-10-06T09:24:05.0000730+0000","customerName":"mytestdevcog","averageRating":4,"isNegativeByComments":false,"outlet":{"id":"f9e9c21f-2e52-462e-a1f2-012dab216d27","name":"cholan
's Darbar"},"customer":{"name":"mytestdevcog","email":"
mytestdevcog123 at gmail.com","countryCallingCode":"91","phone":"7895478745"},"responses":[{"question":"Was
your waiting time too
long?","response":"No","questionType":"yes_no"},{"question":"Service","response":"3","questionType":"rating"},{"question":"desserts","response":"4","questionType":"rating"},{"question":"Comments","response":"good","questionType":"short_answer"},{"question":"How
likely is it that you would recommend us to a friend or
colleague?","response":"5","questionType":"nps"},{"question":"Portion
Size","response":"5","questionType":"rating"},{"question":"Indian
Food","response":"4","questionType":"rating"},{"question":"Desert
spread","response":"4","questionType":"rating"}]},"serverDateTime":"2016-10-06T09:24:27.0000644+0000"}


Would require two seperate dataframes for two inputs. Help would be highly
appreciated


Regards,

Abhinaba

	[[alternative HTML version deleted]]


From maillists at pp.inet.fi  Tue Oct 18 13:49:53 2016
From: maillists at pp.inet.fi (K. Elo)
Date: Tue, 18 Oct 2016 14:49:53 +0300
Subject: [R] JSON to Dataframe
In-Reply-To: <CANtKHPWCrr0xKiYj4oeV+_RU4rxRsprLE8MJ-N3YK4CBCRYF+g@mail.gmail.com>
References: <CANtKHPWCrr0xKiYj4oeV+_RU4rxRsprLE8MJ-N3YK4CBCRYF+g@mail.gmail.com>
Message-ID: <4dde2a41-ec20-e450-f75f-6265b83df6e8@pp.inet.fi>

Hi!

18.10.2016, 14:38, Abhinaba Roy wrote:
> Hi R helpers,
>
> I have json inputs from an app which I want to convert to dataframes. Below
> are the two inputs. Can someone help me in converting these to dataframes
>
[...]

IMHO, the best way is to use the package 'jsonlite', see:

* https://cran.r-project.org/web/packages/jsonlite/index.html

A good documentation comes with the package, but the links listed on the 
CRAN site provide useful information, too.

HTH,
Kimmo


From bob at rud.is  Tue Oct 18 13:58:40 2016
From: bob at rud.is (Bob Rudis)
Date: Tue, 18 Oct 2016 07:58:40 -0400
Subject: [R] JSON to Dataframe
In-Reply-To: <4dde2a41-ec20-e450-f75f-6265b83df6e8@pp.inet.fi>
References: <CANtKHPWCrr0xKiYj4oeV+_RU4rxRsprLE8MJ-N3YK4CBCRYF+g@mail.gmail.com>
	<4dde2a41-ec20-e450-f75f-6265b83df6e8@pp.inet.fi>
Message-ID: <CAA-FpKX1Z=yXrn87sWd7HKJ7NHqTBihf8KO4mys05FNAqvMeow@mail.gmail.com>

If those are in "ndjson" files or are indeed single records, `ndjson`
functions will be a few orders of magnitude faster and will produce
perfectly "flat" data frames. It's not intended to be a replacement
for `jsonlite` (a.k.a. the quintessential JSON pkg for R) but it's
tailor made for making quick work of (potentially deeply nested)
ndjson records/files.

On Tue, Oct 18, 2016 at 7:49 AM, K. Elo <maillists at pp.inet.fi> wrote:
> Hi!
>
> 18.10.2016, 14:38, Abhinaba Roy wrote:
>>
>> Hi R helpers,
>>
>> I have json inputs from an app which I want to convert to dataframes.
>> Below
>> are the two inputs. Can someone help me in converting these to dataframes
>>
> [...]
>
> IMHO, the best way is to use the package 'jsonlite', see:
>
> * https://cran.r-project.org/web/packages/jsonlite/index.html
>
> A good documentation comes with the package, but the links listed on the
> CRAN site provide useful information, too.
>
> HTH,
> Kimmo
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michal.kubista at nielsen.com  Tue Oct 18 15:59:14 2016
From: michal.kubista at nielsen.com (Michal Kubista)
Date: Tue, 18 Oct 2016 15:59:14 +0200
Subject: [R] Merge data by coordinates
In-Reply-To: <1BE7CB8B-766B-48A9-ADFD-C3D03AFD665A@comcast.net>
References: <CAMLwc7NPDg+PB3hREFNB32ogd8y1mL4ZEfnJkqu-Fqgx94y5vA@mail.gmail.com>
	<1BE7CB8B-766B-48A9-ADFD-C3D03AFD665A@comcast.net>
Message-ID: <CACW3oCRuZt0FB03OVJWuG879=EmZ21pHtWd3x0=GZ+JheSC4sQ@mail.gmail.com>

Dear Milu,
If your objective is to match the places from one table to the nearest
place in the second table, you can generally use knn algorithm for 1
nearest neighbourhood.
But please, check what David suggests first.

Best regards,
Michal

2016-10-16 19:24 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:

>
> > On Oct 16, 2016, at 6:32 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >
> > Dear all,
> >
> > I have two dataframe 1 by latitude and longitude but they always do not
> > match. Is it possible to merge them (e.g. nearest distance)?
> >
> > # Dataframe 1
> > structure(list(lat = c(54L, 55L, 51L, 54L, 53L, 50L, 47L, 51L,
> > 49L, 54L), lon = c(14L, 8L, 15L, 7L, 6L, 5L, 13L, 5L, 13L, 11L
> > ), PPP2000_40 = c(4606, 6575, 6593, 7431, 9393, 10773, 11716,
> > 12226, 13544, 14526)), .Names = c("lat", "lon", "PPP2000_40"), row.names
> =
> > c(6764L,
> > 8796L, 8901L, 9611L, 11649L, 12819L, 13763L, 14389L, 15641L,
> > 16571L), class = "data.frame")
> >
> > # Dataframe 2
> > structure(list(lat = c(47, 47, 47, 47, 47, 47, 48, 48, 48, 48
> > ), lon = c(7, 8, 9, 10, 11, 12, 7, 8, 9, 10), GDP = c(19.09982,
> > 13.31977, 14.95925, 6.8575635, 23.334565, 6.485748, 24.01197,
> > 14.30393075, 21.33759675, 9.71803675)), .Names = c("lat", "lon",
> > "GDP"), row.names = c(NA, 10L), class = "data.frame")
>
> I think you should first do this:
>
> plot(d1$lat,d1$lon)
> points(d2$lat,d2$lon, col="red")
>
> And then respond to my suggestion that this is not a well-posed computing
> problem. Explain why the red dots should have a 1-1 relationship with the
> black dots.
>
>
> --
> David.
>
> >
> > Thank you so much!
> >
> > Sincerely,
> >
> > Milu
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From proebuck at mdanderson.org  Tue Oct 18 18:38:33 2016
From: proebuck at mdanderson.org (Roebuck,Paul L)
Date: Tue, 18 Oct 2016 16:38:33 +0000
Subject: [R] tar()/untar()  argument symmetry
Message-ID: <D42BBA37.1018DD%proebuck@mdanderson.org>

Any reason untar() has an "exdir" argument (the equivalent of "tar -C"),
but tar() does not?

The information contained in this e-mail message may be privileged, confidential, and/or protected from disclosure. This e-mail message may contain protected health information (PHI); dissemination of PHI should comply with applicable federal and state laws. If you are not the intended recipient, or an authorized representative of the intended recipient, any further review, disclosure, use, dissemination, distribution, or copying of this message or any attachment (or the information contained therein) is strictly prohibited. If you think that you have received this e-mail message in error, please notify the sender by return e-mail and delete all references to it and its contents from your systems.

	[[alternative HTML version deleted]]


From proebuck at mdanderson.org  Tue Oct 18 19:07:03 2016
From: proebuck at mdanderson.org (Roebuck,Paul L)
Date: Tue, 18 Oct 2016 17:07:03 +0000
Subject: [R] Difficulties with setting working directory
In-Reply-To: <CAE8BV_Uk5iyPdZvssjWk6DTXsfFvv4htvi=mqL+PDpdrehHrmg@mail.gmail.com>
References: <CAE8BV_Uk5iyPdZvssjWk6DTXsfFvv4htvi=mqL+PDpdrehHrmg@mail.gmail.com>
Message-ID: <D42BBF96.1018E3%proebuck@mdanderson.org>

On 10/14/16, 1:52 PM, "R-help on behalf of An?e Dejak" wrote:

>So, the thing with my version of R (I'm using RStudio for R x64 3.3.0 in,
>currently, Windows 7) is, that I'm able to set the working directory
>temporary (through using setwd() function), but once I try to set it
>permanently (through "Session -> Set Working Directory -> Choose
>Directory..."), this error appears: Error in setwd("~/...") : cannot
>change
>working directory.
>
>As I've seen online on certain forums, the problem, supposedly, is that R
>in Windows is unable to recognize the ~ sign. But without it, I'm unable
>to
>set the working directory for more than a session.
>
>I'd hope you have a possible answer to this error.

Two problems:

1) R won't convert "~" to its shell equivalent without using path.expand()
2) There is no "..." directory [only "." (current) or ".." (parent)]

The information contained in this e-mail message may be privileged, confidential, and/or protected from disclosure. This e-mail message may contain protected health information (PHI); dissemination of PHI should comply with applicable federal and state laws. If you are not the intended recipient, or an authorized representative of the intended recipient, any further review, disclosure, use, dissemination, distribution, or copying of this message or any attachment (or the information contained therein) is strictly prohibited. If you think that you have received this e-mail message in error, please notify the sender by return e-mail and delete all references to it and its contents from your systems.


From kagbones at gmail.com  Tue Oct 18 19:27:52 2016
From: kagbones at gmail.com (Kirsten Green)
Date: Tue, 18 Oct 2016 11:27:52 -0600
Subject: [R] MDS, line of best fit, and id of variables
Message-ID: <CALEO0efMScbb0fqcdi=CmGf-UP8GmKbhduCv_8NrP53=qHnSMA@mail.gmail.com>

Hi,

I have created a dataset that includes 28 rows (burials) and 27 columns
(variables) that are coded binomially. I have gotten metaMDS to run in the
pst but now can't seem to get it run at all.
Error message:
> mortdata.mds <- metaMDS(mortdata)
Error in FUN(X[[i]], ...) :
  only defined on a data frame with all numeric variables
In addition: Warning message:
In Ops.factor(left, right) : ?<? not meaningful for factors

I'd like to create a 3D MDS plot and add the line of best fit for the 3
dimensions (3 variables). I am also trying to figure out, or understand,
which variables are causing the variation.

I ran PCA and it told me that with 3 variables approximately 50% of the
data variation is explained. So I assumed that meant that running MDS in 3
dimensions would show me 3 variables causing the variation but I can't get
that to work.

Here is my code so far (i've also attached it to the email):

mortdata<-read.csv("Table5.5.csv", header=TRUE)
mortdata
row.names(mortdata) <- mortdata[,1]
mortdata <- mortdata[,-1]
mortdata

mortdata.mds <- metaMDS(mortdata)
mortdata.mds.alt <- metaMDS(mortdata, distance="euclidean", k=3, trymax=50,
      autotransform=FALSE, noshare=FALSE)


*object = mortdata.mds.alt

names(mortdata.mds.alt)

mortdata.mds.alt
summary(mortdata.mds.alt)

*stress plot
stressplot(mortdata.mds.alt)

x <- mortdata.mds.alt$species
y <- mortdata.mds.alt$points
na.exclude(mortdata.mds.alt)
vScoresScale <- scale(, center = TRUE, scale = TRUE)


plot(mortdata.mds.alt)
plot(mortdata.mds.alt, type="t")

*multiple linear regression model
lm(formula = x ~ y)
abline(lm(x ~ y), col="red")


*scatterplot3D
library(scatterplot3d)
attach(mortdata.mds.alt)
scatterplot3d(mortdata.mds.alt, x="sampleScores", y="variableScores",
main="3D Scatterplot")

Any help would be greatly appreciated. I can also send the dataset if that
helps.

-- 
*Kirsten Green*
kagbones at gmail.com
916-712-5193

From murdoch.duncan at gmail.com  Tue Oct 18 19:52:41 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 18 Oct 2016 13:52:41 -0400
Subject: [R] tar()/untar() argument symmetry
In-Reply-To: <D42BBA37.1018DD%proebuck@mdanderson.org>
References: <D42BBA37.1018DD%proebuck@mdanderson.org>
Message-ID: <74904e93-dbaf-a285-a4a0-273e166b034b@gmail.com>

On 18/10/2016 12:38 PM, Roebuck,Paul L wrote:
> Any reason untar() has an "exdir" argument (the equivalent of "tar -C"),
> but tar() does not?

Because you can specify the source directory in the files argument using 
list.files().  There's no need to duplicate that in tar().

Duncan Murdoch


From proebuck at mdanderson.org  Tue Oct 18 20:47:27 2016
From: proebuck at mdanderson.org (Roebuck,Paul L)
Date: Tue, 18 Oct 2016 18:47:27 +0000
Subject: [R] tar()/untar() argument symmetry
In-Reply-To: <74904e93-dbaf-a285-a4a0-273e166b034b@gmail.com>
References: <D42BBA37.1018DD%proebuck@mdanderson.org>
	<74904e93-dbaf-a285-a4a0-273e166b034b@gmail.com>
Message-ID: <D42BD4D1.1018F8%proebuck@mdanderson.org>

On 10/18/16, 12:52 PM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:

>On 18/10/2016 12:38 PM, Roebuck,Paul L wrote:
>> Any reason untar() has an "exdir" argument (the equivalent of "tar -C"),
>> but tar() does not?
>
>Because you can specify the source directory in the files argument using
>list.files().  There's no need to duplicate that in tar().

But that solution introduces (undesired) intermediate directory paths
into the tar archive.


Any other thoughts outside using something like below:

stopifnot(dir.exists(local))
savedir <- ""
tryCatch({
    savedir <- setwd(local)
    tar(?)
  },
  finally = setwd(savedir))

The information contained in this e-mail message may be privileged, confidential, and/or protected from disclosure. This e-mail message may contain protected health information (PHI); dissemination of PHI should comply with applicable federal and state laws. If you are not the intended recipient, or an authorized representative of the intended recipient, any further review, disclosure, use, dissemination, distribution, or copying of this message or any attachment (or the information contained therein) is strictly prohibited. If you think that you have received this e-mail message in error, please notify the sender by return e-mail and delete all references to it and its contents from your systems.


From dcarlson at tamu.edu  Tue Oct 18 21:23:53 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 18 Oct 2016 19:23:53 +0000
Subject: [R] MDS, line of best fit, and id of variables
In-Reply-To: <CALEO0efMScbb0fqcdi=CmGf-UP8GmKbhduCv_8NrP53=qHnSMA@mail.gmail.com>
References: <CALEO0efMScbb0fqcdi=CmGf-UP8GmKbhduCv_8NrP53=qHnSMA@mail.gmail.com>
Message-ID: <24ebf05358d24fc6b2763e543bc7a8a2@exch-2p-mbx-w2.ads.tamu.edu>

What do you get with str(mortdata)? The error message indicates that at least one of the variables is not numeric and the second suggests it is a factor. You said the values were coded binomially, but they must be numeric, e.g. 0, 1 and not "Present" "Absent" or something like that. If they are all factors, something like

mortdata1 <- sapply(mortdata, as.numeric)-1

would convert factor levels of 1 and 2 to 0 and 1.
-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kirsten Green
Sent: Tuesday, October 18, 2016 12:28 PM
To: r-help at r-project.org
Subject: [R] MDS, line of best fit, and id of variables

Hi,

I have created a dataset that includes 28 rows (burials) and 27 columns
(variables) that are coded binomially. I have gotten metaMDS to run in the
pst but now can't seem to get it run at all.
Error message:
> mortdata.mds <- metaMDS(mortdata)
Error in FUN(X[[i]], ...) :
  only defined on a data frame with all numeric variables
In addition: Warning message:
In Ops.factor(left, right) : ?<? not meaningful for factors

I'd like to create a 3D MDS plot and add the line of best fit for the 3
dimensions (3 variables). I am also trying to figure out, or understand,
which variables are causing the variation.

I ran PCA and it told me that with 3 variables approximately 50% of the
data variation is explained. So I assumed that meant that running MDS in 3
dimensions would show me 3 variables causing the variation but I can't get
that to work.

Here is my code so far (i've also attached it to the email):

mortdata<-read.csv("Table5.5.csv", header=TRUE)
mortdata
row.names(mortdata) <- mortdata[,1]
mortdata <- mortdata[,-1]
mortdata

mortdata.mds <- metaMDS(mortdata)
mortdata.mds.alt <- metaMDS(mortdata, distance="euclidean", k=3, trymax=50,
      autotransform=FALSE, noshare=FALSE)


*object = mortdata.mds.alt

names(mortdata.mds.alt)

mortdata.mds.alt
summary(mortdata.mds.alt)

*stress plot
stressplot(mortdata.mds.alt)

x <- mortdata.mds.alt$species
y <- mortdata.mds.alt$points
na.exclude(mortdata.mds.alt)
vScoresScale <- scale(, center = TRUE, scale = TRUE)


plot(mortdata.mds.alt)
plot(mortdata.mds.alt, type="t")

*multiple linear regression model
lm(formula = x ~ y)
abline(lm(x ~ y), col="red")


*scatterplot3D
library(scatterplot3d)
attach(mortdata.mds.alt)
scatterplot3d(mortdata.mds.alt, x="sampleScores", y="variableScores",
main="3D Scatterplot")

Any help would be greatly appreciated. I can also send the dataset if that
helps.

-- 
*Kirsten Green*
kagbones at gmail.com
916-712-5193
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From dcarlson at tamu.edu  Tue Oct 18 21:50:55 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 18 Oct 2016 19:50:55 +0000
Subject: [R] MDS, line of best fit, and id of variables
In-Reply-To: <CALEO0ecnNg2uoLxqCT7LkcUw7C0iYp+7LdEz5=eoJybFM09N1w@mail.gmail.com>
References: <CALEO0efMScbb0fqcdi=CmGf-UP8GmKbhduCv_8NrP53=qHnSMA@mail.gmail.com>
	<24ebf05358d24fc6b2763e543bc7a8a2@exch-2p-mbx-w2.ads.tamu.edu>
	<CALEO0ecnNg2uoLxqCT7LkcUw7C0iYp+7LdEz5=eoJybFM09N1w@mail.gmail.com>
Message-ID: <d1ff5b1349014ce5bae3e8cd667a8c88@exch-2p-mbx-w2.ads.tamu.edu>

You do not need to change it to numeric if it is integer. But if you want to change it, you need to follow the example I included and use sapply(). 

Here is my effort to replicate your error. Since I'm using random data, it fails to converge, but I do not get the error message you are getting. This is the best I can do since you have not given us reproducible data. 

> set.seed(42)
> mortdata <- data.frame(matrix(sample(0:1, 28*27, replace=TRUE), 28, 27))
> dim(mortdata)
[1] 28 27
> library(vegan)
Loading required package: permute
Loading required package: lattice
This is vegan 2.4-1
> sapply(mortdata, type)
Error in match.fun(FUN) : object 'type' not found
> sapply(mortdata, class)  # Is everything numeric (which includes integer)?
       X1        X2        X3        X4        X5        X6        X7        X8        X9 
"integer" "integer" "integer" "integer" "integer" "integer" "integer" "integer" "integer" 
      X10       X11       X12       X13       X14       X15       X16       X17       X18 
"integer" "integer" "integer" "integer" "integer" "integer" "integer" "integer" "integer" 
      X19       X20       X21       X22       X23       X24       X25       X26       X27 
"integer" "integer" "integer" "integer" "integer" "integer" "integer" "integer" "integer" 
> mortdata.mds <- metaMDS(mortdata)
. . . Many messages 
... New best solution
... Procrustes: rmse 0.07861438  max resid 0.2210256 
Run 18 stress 0.277969 
Run 19 stress 0.2633298 
Run 20 stress 0.2838487 
*** No convergence -- monoMDS stopping criteria:
    20: stress ratio > sratmax

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




From: Kirsten Green [mailto:kagbones at gmail.com] 
Sent: Tuesday, October 18, 2016 2:27 PM
To: David L Carlson
Cc: r-help at r-project.org
Subject: Re: [R] MDS, line of best fit, and id of variables

David,

I have run the str() function and all my data is int (integer). So I am trying to change it to numeric using:
str(mortdata)
class(mortdata)
is.numeric(mortdata)
mortdata.num <- as.numeric(data.frame(mortdata))

But I keep getting an error: > mortdata.num <- as.numeric(data.frame(mortdata))
Error: (list) object cannot be coerced to type 'double

On Tue, Oct 18, 2016 at 1:23 PM, David L Carlson <dcarlson at tamu.edu> wrote:
What do you get with str(mortdata)? The error message indicates that at least one of the variables is not numeric and the second suggests it is a factor. You said the values were coded binomially, but they must be numeric, e.g. 0, 1 and not "Present" "Absent" or something like that. If they are all factors, something like

mortdata1 <- sapply(mortdata, as.numeric)-1

would convert factor levels of 1 and 2 to 0 and 1.
-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kirsten Green
Sent: Tuesday, October 18, 2016 12:28 PM
To: r-help at r-project.org
Subject: [R] MDS, line of best fit, and id of variables
Hi,

I have created a dataset that includes 28 rows (burials) and 27 columns
(variables) that are coded binomially. I have gotten metaMDS to run in the
pst but now can't seem to get it run at all.
Error message:
> mortdata.mds <- metaMDS(mortdata)
Error in FUN(X[[i]], ...) :
? only defined on a data frame with all numeric variables
In addition: Warning message:
In Ops.factor(left, right) : ?<? not meaningful for factors

I'd like to create a 3D MDS plot and add the line of best fit for the 3
dimensions (3 variables). I am also trying to figure out, or understand,
which variables are causing the variation.

I ran PCA and it told me that with 3 variables approximately 50% of the
data variation is explained. So I assumed that meant that running MDS in 3
dimensions would show me 3 variables causing the variation but I can't get
that to work.

Here is my code so far (i've also attached it to the email):

mortdata<-read.csv("Table5.5.csv", header=TRUE)
mortdata
row.names(mortdata) <- mortdata[,1]
mortdata <- mortdata[,-1]
mortdata

mortdata.mds <- metaMDS(mortdata)
mortdata.mds.alt <- metaMDS(mortdata, distance="euclidean", k=3, trymax=50,
? ? ? autotransform=FALSE, noshare=FALSE)


*object = mortdata.mds.alt

names(mortdata.mds.alt)

mortdata.mds.alt
summary(mortdata.mds.alt)

*stress plot
stressplot(mortdata.mds.alt)

x <- mortdata.mds.alt$species
y <- mortdata.mds.alt$points
na.exclude(mortdata.mds.alt)
vScoresScale <- scale(, center = TRUE, scale = TRUE)


plot(mortdata.mds.alt)
plot(mortdata.mds.alt, type="t")

*multiple linear regression model
lm(formula = x ~ y)
abline(lm(x ~ y), col="red")


*scatterplot3D
library(scatterplot3d)
attach(mortdata.mds.alt)
scatterplot3d(mortdata.mds.alt, x="sampleScores", y="variableScores",
main="3D Scatterplot")

Any help would be greatly appreciated. I can also send the dataset if that
helps.

--
*Kirsten Green*
kagbones at gmail.com
916-712-5193
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



-- 
*Kirsten Green*
kagbones at gmail.com
916-712-5193

From kagbones at gmail.com  Tue Oct 18 21:27:05 2016
From: kagbones at gmail.com (Kirsten Green)
Date: Tue, 18 Oct 2016 13:27:05 -0600
Subject: [R] MDS, line of best fit, and id of variables
In-Reply-To: <24ebf05358d24fc6b2763e543bc7a8a2@exch-2p-mbx-w2.ads.tamu.edu>
References: <CALEO0efMScbb0fqcdi=CmGf-UP8GmKbhduCv_8NrP53=qHnSMA@mail.gmail.com>
	<24ebf05358d24fc6b2763e543bc7a8a2@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CALEO0ecnNg2uoLxqCT7LkcUw7C0iYp+7LdEz5=eoJybFM09N1w@mail.gmail.com>

David,

I have run the str() function and all my data is int (integer). So I am
trying to change it to numeric using:
str(mortdata)
class(mortdata)
is.numeric(mortdata)
mortdata.num <- as.numeric(data.frame(mortdata))

But I keep getting an error: > mortdata.num <- as.numeric(data.frame(
mortdata))
Error: (list) object cannot be coerced to type 'double

On Tue, Oct 18, 2016 at 1:23 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> What do you get with str(mortdata)? The error message indicates that at
> least one of the variables is not numeric and the second suggests it is a
> factor. You said the values were coded binomially, but they must be
> numeric, e.g. 0, 1 and not "Present" "Absent" or something like that. If
> they are all factors, something like
>
> mortdata1 <- sapply(mortdata, as.numeric)-1
>
> would convert factor levels of 1 and 2 to 0 and 1.
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kirsten
> Green
> Sent: Tuesday, October 18, 2016 12:28 PM
> To: r-help at r-project.org
> Subject: [R] MDS, line of best fit, and id of variables
>
> Hi,
>
> I have created a dataset that includes 28 rows (burials) and 27 columns
> (variables) that are coded binomially. I have gotten metaMDS to run in the
> pst but now can't seem to get it run at all.
> Error message:
> > mortdata.mds <- metaMDS(mortdata)
> Error in FUN(X[[i]], ...) :
>   only defined on a data frame with all numeric variables
> In addition: Warning message:
> In Ops.factor(left, right) : ?<? not meaningful for factors
>
> I'd like to create a 3D MDS plot and add the line of best fit for the 3
> dimensions (3 variables). I am also trying to figure out, or understand,
> which variables are causing the variation.
>
> I ran PCA and it told me that with 3 variables approximately 50% of the
> data variation is explained. So I assumed that meant that running MDS in 3
> dimensions would show me 3 variables causing the variation but I can't get
> that to work.
>
> Here is my code so far (i've also attached it to the email):
>
> mortdata<-read.csv("Table5.5.csv", header=TRUE)
> mortdata
> row.names(mortdata) <- mortdata[,1]
> mortdata <- mortdata[,-1]
> mortdata
>
> mortdata.mds <- metaMDS(mortdata)
> mortdata.mds.alt <- metaMDS(mortdata, distance="euclidean", k=3, trymax=50,
>       autotransform=FALSE, noshare=FALSE)
>
>
> *object = mortdata.mds.alt
>
> names(mortdata.mds.alt)
>
> mortdata.mds.alt
> summary(mortdata.mds.alt)
>
> *stress plot
> stressplot(mortdata.mds.alt)
>
> x <- mortdata.mds.alt$species
> y <- mortdata.mds.alt$points
> na.exclude(mortdata.mds.alt)
> vScoresScale <- scale(, center = TRUE, scale = TRUE)
>
>
> plot(mortdata.mds.alt)
> plot(mortdata.mds.alt, type="t")
>
> *multiple linear regression model
> lm(formula = x ~ y)
> abline(lm(x ~ y), col="red")
>
>
> *scatterplot3D
> library(scatterplot3d)
> attach(mortdata.mds.alt)
> scatterplot3d(mortdata.mds.alt, x="sampleScores", y="variableScores",
> main="3D Scatterplot")
>
> Any help would be greatly appreciated. I can also send the dataset if that
> helps.
>
> --
> *Kirsten Green*
> kagbones at gmail.com
> 916-712-5193
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
*Kirsten Green*
kagbones at gmail.com
916-712-5193

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Oct 18 23:48:54 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 18 Oct 2016 14:48:54 -0700
Subject: [R] MDS, line of best fit, and id of variables
In-Reply-To: <CALEO0ecnNg2uoLxqCT7LkcUw7C0iYp+7LdEz5=eoJybFM09N1w@mail.gmail.com>
References: <CALEO0efMScbb0fqcdi=CmGf-UP8GmKbhduCv_8NrP53=qHnSMA@mail.gmail.com>
	<24ebf05358d24fc6b2763e543bc7a8a2@exch-2p-mbx-w2.ads.tamu.edu>
	<CALEO0ecnNg2uoLxqCT7LkcUw7C0iYp+7LdEz5=eoJybFM09N1w@mail.gmail.com>
Message-ID: <CAGxFJbRB87Lvw9228c01Zp+UeS4sgLdPSbhTo+kiG7Fm8ysPjw@mail.gmail.com>

You need to spend time with an R tutorial or two. Your error is due to
ignorance of basic R data structures.

Bert

On Oct 18, 2016 10:48 PM, "Kirsten Green" <kagbones at gmail.com> wrote:

> David,
>
> I have run the str() function and all my data is int (integer). So I am
> trying to change it to numeric using:
> str(mortdata)
> class(mortdata)
> is.numeric(mortdata)
> mortdata.num <- as.numeric(data.frame(mortdata))
>
> But I keep getting an error: > mortdata.num <- as.numeric(data.frame(
> mortdata))
> Error: (list) object cannot be coerced to type 'double
>
> On Tue, Oct 18, 2016 at 1:23 PM, David L Carlson <dcarlson at tamu.edu>
> wrote:
>
> > What do you get with str(mortdata)? The error message indicates that at
> > least one of the variables is not numeric and the second suggests it is a
> > factor. You said the values were coded binomially, but they must be
> > numeric, e.g. 0, 1 and not "Present" "Absent" or something like that. If
> > they are all factors, something like
> >
> > mortdata1 <- sapply(mortdata, as.numeric)-1
> >
> > would convert factor levels of 1 and 2 to 0 and 1.
> > -------------------------------------
> > David L Carlson
> > Department of Anthropology
> > Texas A&M University
> > College Station, TX 77840-4352
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kirsten
> > Green
> > Sent: Tuesday, October 18, 2016 12:28 PM
> > To: r-help at r-project.org
> > Subject: [R] MDS, line of best fit, and id of variables
> >
> > Hi,
> >
> > I have created a dataset that includes 28 rows (burials) and 27 columns
> > (variables) that are coded binomially. I have gotten metaMDS to run in
> the
> > pst but now can't seem to get it run at all.
> > Error message:
> > > mortdata.mds <- metaMDS(mortdata)
> > Error in FUN(X[[i]], ...) :
> >   only defined on a data frame with all numeric variables
> > In addition: Warning message:
> > In Ops.factor(left, right) : ?<? not meaningful for factors
> >
> > I'd like to create a 3D MDS plot and add the line of best fit for the 3
> > dimensions (3 variables). I am also trying to figure out, or understand,
> > which variables are causing the variation.
> >
> > I ran PCA and it told me that with 3 variables approximately 50% of the
> > data variation is explained. So I assumed that meant that running MDS in
> 3
> > dimensions would show me 3 variables causing the variation but I can't
> get
> > that to work.
> >
> > Here is my code so far (i've also attached it to the email):
> >
> > mortdata<-read.csv("Table5.5.csv", header=TRUE)
> > mortdata
> > row.names(mortdata) <- mortdata[,1]
> > mortdata <- mortdata[,-1]
> > mortdata
> >
> > mortdata.mds <- metaMDS(mortdata)
> > mortdata.mds.alt <- metaMDS(mortdata, distance="euclidean", k=3,
> trymax=50,
> >       autotransform=FALSE, noshare=FALSE)
> >
> >
> > *object = mortdata.mds.alt
> >
> > names(mortdata.mds.alt)
> >
> > mortdata.mds.alt
> > summary(mortdata.mds.alt)
> >
> > *stress plot
> > stressplot(mortdata.mds.alt)
> >
> > x <- mortdata.mds.alt$species
> > y <- mortdata.mds.alt$points
> > na.exclude(mortdata.mds.alt)
> > vScoresScale <- scale(, center = TRUE, scale = TRUE)
> >
> >
> > plot(mortdata.mds.alt)
> > plot(mortdata.mds.alt, type="t")
> >
> > *multiple linear regression model
> > lm(formula = x ~ y)
> > abline(lm(x ~ y), col="red")
> >
> >
> > *scatterplot3D
> > library(scatterplot3d)
> > attach(mortdata.mds.alt)
> > scatterplot3d(mortdata.mds.alt, x="sampleScores", y="variableScores",
> > main="3D Scatterplot")
> >
> > Any help would be greatly appreciated. I can also send the dataset if
> that
> > helps.
> >
> > --
> > *Kirsten Green*
> > kagbones at gmail.com
> > 916-712-5193
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> *Kirsten Green*
> kagbones at gmail.com
> 916-712-5193
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From tgraves_cs at yahoo.com  Tue Oct 18 23:06:54 2016
From: tgraves_cs at yahoo.com (Tom Graves)
Date: Tue, 18 Oct 2016 21:06:54 +0000 (UTC)
Subject: [R] install R in relative path
References: <289312802.345844.1476824814057.ref@mail.yahoo.com>
Message-ID: <289312802.345844.1476824814057@mail.yahoo.com>

Hello everyone,
I am trying to figure out if I can install R in a relative path? ?The reason I need to do this is to send R along to a Hadoop cluster so that I can use sparkR with the R version I shipped. The Hadoop cluster doesn't have R installed and the admin won't install it.?
I tried a few things but the things I had tried didn't work. Are there any options to configure or PATHs I could use to do this?
Any help is appreciated.
Thanks,Tom
	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Oct 19 08:21:04 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 19 Oct 2016 06:21:04 +0000
Subject: [R] MDS, line of best fit, and id of variables
In-Reply-To: <CALEO0ecnNg2uoLxqCT7LkcUw7C0iYp+7LdEz5=eoJybFM09N1w@mail.gmail.com>
References: <CALEO0efMScbb0fqcdi=CmGf-UP8GmKbhduCv_8NrP53=qHnSMA@mail.gmail.com>
	<24ebf05358d24fc6b2763e543bc7a8a2@exch-2p-mbx-w2.ads.tamu.edu>
	<CALEO0ecnNg2uoLxqCT7LkcUw7C0iYp+7LdEz5=eoJybFM09N1w@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5043583@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kirsten
> Green
> Sent: Tuesday, October 18, 2016 9:27 PM
> To: David L Carlson <dcarlson at tamu.edu>
> Cc: r-help at r-project.org
> Subject: Re: [R] MDS, line of best fit, and id of variables
>
> David,
>
> I have run the str() function and all my data is int (integer). So I am trying to

It is strange. Error from metaMDS(mortdata) indicates that you have some nonnumeric data in your data frame which definitely should be indicated by str.

e.g.
str(data.frame(a=factor(1:5), b=rnorm(5)))
'data.frame':   5 obs. of  2 variables:
 $ a: Factor w/ 5 levels "1","2","3","4",..: 1 2 3 4 5
 $ b: num  -0.201 -1.639 0.108 0.259 -1.33

> change it to numeric using:
> str(mortdata)
> class(mortdata)
> is.numeric(mortdata)
> mortdata.num <- as.numeric(data.frame(mortdata))

As Bert said you should spent some time to evaluate distinctions among various object types. For making data frame numeric you need to use sapply.

str(sapply(data.frame(a=factor(1:5), b=rnorm(5)), as.numeric))
 num [1:5, 1:2] 1 2 3 4 5 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:2] "a" "b"

however if you have factors in your data frame you could get some nasty surprise with such simple approach and it also changes data.frame to matrix.

Cheers
Petr

>
> But I keep getting an error: > mortdata.num <- as.numeric(data.frame(
> mortdata))
> Error: (list) object cannot be coerced to type 'double
>
> On Tue, Oct 18, 2016 at 1:23 PM, David L Carlson <dcarlson at tamu.edu>
> wrote:
>
> > What do you get with str(mortdata)? The error message indicates that
> > at least one of the variables is not numeric and the second suggests
> > it is a factor. You said the values were coded binomially, but they
> > must be numeric, e.g. 0, 1 and not "Present" "Absent" or something
> > like that. If they are all factors, something like
> >
> > mortdata1 <- sapply(mortdata, as.numeric)-1
> >
> > would convert factor levels of 1 and 2 to 0 and 1.
> > -------------------------------------
> > David L Carlson
> > Department of Anthropology
> > Texas A&M University
> > College Station, TX 77840-4352
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Kirsten Green
> > Sent: Tuesday, October 18, 2016 12:28 PM
> > To: r-help at r-project.org
> > Subject: [R] MDS, line of best fit, and id of variables
> >
> > Hi,
> >
> > I have created a dataset that includes 28 rows (burials) and 27
> > columns
> > (variables) that are coded binomially. I have gotten metaMDS to run in
> > the pst but now can't seem to get it run at all.
> > Error message:
> > > mortdata.mds <- metaMDS(mortdata)
> > Error in FUN(X[[i]], ...) :
> >   only defined on a data frame with all numeric variables In addition:
> > Warning message:
> > In Ops.factor(left, right) : ?<? not meaningful for factors
> >
> > I'd like to create a 3D MDS plot and add the line of best fit for the
> > 3 dimensions (3 variables). I am also trying to figure out, or
> > understand, which variables are causing the variation.
> >
> > I ran PCA and it told me that with 3 variables approximately 50% of
> > the data variation is explained. So I assumed that meant that running
> > MDS in 3 dimensions would show me 3 variables causing the variation
> > but I can't get that to work.
> >
> > Here is my code so far (i've also attached it to the email):
> >
> > mortdata<-read.csv("Table5.5.csv", header=TRUE) mortdata
> > row.names(mortdata) <- mortdata[,1]
> > mortdata <- mortdata[,-1]
> > mortdata
> >
> > mortdata.mds <- metaMDS(mortdata)
> > mortdata.mds.alt <- metaMDS(mortdata, distance="euclidean", k=3,
> trymax=50,
> >       autotransform=FALSE, noshare=FALSE)
> >
> >
> > *object = mortdata.mds.alt
> >
> > names(mortdata.mds.alt)
> >
> > mortdata.mds.alt
> > summary(mortdata.mds.alt)
> >
> > *stress plot
> > stressplot(mortdata.mds.alt)
> >
> > x <- mortdata.mds.alt$species
> > y <- mortdata.mds.alt$points
> > na.exclude(mortdata.mds.alt)
> > vScoresScale <- scale(, center = TRUE, scale = TRUE)
> >
> >
> > plot(mortdata.mds.alt)
> > plot(mortdata.mds.alt, type="t")
> >
> > *multiple linear regression model
> > lm(formula = x ~ y)
> > abline(lm(x ~ y), col="red")
> >
> >
> > *scatterplot3D
> > library(scatterplot3d)
> > attach(mortdata.mds.alt)
> > scatterplot3d(mortdata.mds.alt, x="sampleScores", y="variableScores",
> > main="3D Scatterplot")
> >
> > Any help would be greatly appreciated. I can also send the dataset if
> > that helps.
> >
> > --
> > *Kirsten Green*
> > kagbones at gmail.com
> > 916-712-5193
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html and provide commented, minimal, self-contained,
> > reproducible code.
> >
>
>
>
> --
> *Kirsten Green*
> kagbones at gmail.com
> 916-712-5193
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From mohan221213 at gmail.com  Wed Oct 19 08:31:17 2016
From: mohan221213 at gmail.com (Mohan V)
Date: Wed, 19 Oct 2016 12:01:17 +0530
Subject: [R] =?utf-8?q?Why_do_we_get_=E2=80=9CDon=27t_know_how_to_add_o_to?=
	=?utf-8?b?IGEgcGxvdOKAnSBFcnJvcj8=?=
Message-ID: <CAPGqCU798JZmcixuW_5Aum-D_=Y_qJkaHkjJe9jQGS9_qqjdWw@mail.gmail.com>

Hello All,

Trying to implement the twitter sentiment analysis. Everything worked fine,
but when I try to make Barplots of tweets and getting the error as

    Error: Don't know how to add o to a plot

When i tried the first time it given me the proper output. But after that
it is giving me the above error

I would like to know why do we get the above error. In my case I am getting
this error in below cases.

# add variables to data frame
scores$drink = factor(rep(c("wine", "beer", "coffee", "soda"), nd))
scores$very.pos = as.numeric(scores$score >= 2)
scores$very.neg = as.numeric(scores$score <= -2)
# how many very positives and very negatives
numpos = sum(scores$very.pos)
numneg = sum(scores$very.neg)
# global score
global_score = round( 100 * numpos / (numpos + numneg) )
# colors
cols = c("#7CAE00", "#00BFC4", "#F8766D", "#C77CFF")
names(cols) = c("beer", "coffee", "soda", "wine")
1)  # barplot of average score
meanscore = tapply(scores$score, scores$drink, mean)
df = data.frame(drink=names(meanscore), meanscore=meanscore)
df$drinks <- reorder(df$drink, df$meanscore)

ggplot(df, aes(y=meanscore)) +
geom_bar(data=df, aes(x=drinks, fill=drinks)) +
scale_fill_manual(values=cols[order(df$meanscore)]) +
opts(title = "Average Sentiment Score",
    legend.position = "none")2)  # barplot of average very positive
drink_pos = ddply(scores, .(drink), summarise, mean_pos=mean(very.pos))
drink_pos$drinks <- reorder(drink_pos$drink, drink_pos$mean_pos)

ggplot(drink_pos, aes(y=mean_pos)) +
geom_bar(data=drink_pos, aes(x=drinks, fill=drinks)) +
scale_fill_manual(values=cols[order(drink_pos$mean_pos)]) +
options(title = "Average Very Positive Sentiment Score",
    legend.position = "none")
3) # barplot of average very negative
drink_neg = ddply(scores, .(drink), summarise, mean_neg=mean(very.neg))
drink_neg$drinks <- reorder(drink_neg$drink, drink_neg$mean_neg)

ggplot(drink_neg, aes(y=mean_neg)) +
geom_bar(data=drink_neg, aes(x=drinks, fill=drinks)) +
scale_fill_manual(values=cols[order(drink_neg$mean_neg)]) +
options(title = "Average Very Negative Sentiment Score",
legend.position = "none")

Above in all the three cases I am getting the same issue. please suggest me
why I am getting this error. How can I solve it.

Please suggest me.

Thanks in advance,

Mohan.V

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Wed Oct 19 10:37:59 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 19 Oct 2016 10:37:59 +0200
Subject: [R] install R in relative path
In-Reply-To: <289312802.345844.1476824814057@mail.yahoo.com>
References: <289312802.345844.1476824814057.ref@mail.yahoo.com>
	<289312802.345844.1476824814057@mail.yahoo.com>
Message-ID: <22535.12519.823865.163315@stat.math.ethz.ch>

>>>>> Tom Graves via R-help <r-help at r-project.org>
>>>>>     on Tue, 18 Oct 2016 21:06:54 +0000 writes:

    > Hello everyone, I am trying to figure out if I can install
    > R in a relative path?

Yes.   Even better you don't have to "install" it at all in the
strict sense.
Just *build* it and run it from the build directory.

If you use the source tarball 
currently,  R-3.3.1.tar.gz,  in 12 days will be R-3.2.2.tar.gz

Let's assume you'd want everything in your

 $HOME/R-inst/

Then you do

----------------------------------------------------

cd ~/R-inst
tar xfz <whereever>/R-3.3.1.tar.gz
    # now has created  R-3.3.1
    # we strongly recommend to use a *separate* build directory :
mkdir R-3.3.1-build
cd   R-3.3.1-build
../R-3.3.1/configure
make
	# and optionally, recommended but not for a hadoop run !!
make check-all	

----------------------------------------------------

Note that you do *NEVER* type  'make install'  in the above setup

The only important remaining step is
make a symbolic link of    R-3.3.1-build/bin/R
to a directory part of your PATH.  If you are on a standard
unix/linux/(Mac?) setup :

  mkdir -p ~/bin
  cd ~/bin
  ln -s ~/R-inst/R-3.3.1-build/bin/R .

Alternatively, you could do

  export PATH=$HOME/R-inst/R-3.3.1-build/bin/R:$PATH

but I never do that.
Indeed, I use many R versions in this way, and in the above case
would use

  ln -s  ........../R-3.3.1-build/bin/R   R-3.3.1

and then have R-3.0.0, R-3.0.1, ..., R-3.2.5  R-3.3.0  R-3.3.1 
all in my PATH and all via symbolic links

(and ESS = Emacs Speaks Statistics finds all these
 automagically, so I can each start easily from within Emacs).

Martin Maechler
ETH Zurich

    > ?The reason I need to do this is to
    > send R along to a Hadoop cluster so that I can use sparkR
    > with the R version I shipped. The Hadoop cluster doesn't
    > have R installed and the admin won't install it.?  I tried
    > a few things but the things I had tried didn't work. Are
    > there any options to configure or PATHs I could use to do
    > this?  Any help is appreciated.  Thanks,Tom [[alternative
    > HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From wewolski at gmail.com  Wed Oct 19 11:27:36 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Wed, 19 Oct 2016 11:27:36 +0200
Subject: [R] rstudio mailing list
Message-ID: <CAAjnpdikCRG1jpycxFgOVEbm_9sH7ZfC7WVWSSGXneE8wKvHhg@mail.gmail.com>

Is there a mailing list for Rstudio related questions? I searched the
web but did not find one.

Thank you

-- 
Witold Eryk Wolski


From S.Ellison at LGCGroup.com  Wed Oct 19 12:17:13 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 19 Oct 2016 11:17:13 +0100
Subject: [R]
 =?windows-1252?q?Why_do_we_get_=93Don=27t_know_how_to_add_o_t?=
 =?windows-1252?q?o_a_plot=94_Error=3F?=
In-Reply-To: <CAPGqCU798JZmcixuW_5Aum-D_=Y_qJkaHkjJe9jQGS9_qqjdWw@mail.gmail.com>
References: <CAPGqCU798JZmcixuW_5Aum-D_=Y_qJkaHkjJe9jQGS9_qqjdWw@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403FE7A2EEE@GBTEDVPEXCMB04.corp.lgc-group.com>

> Why do we get ?Don't know how to add o to a plot? Error?
I seem to have responded to this post, and read answers to it, on at least two other forums. 

Suggest you look at the answers on R-forge and stackexchange; they are both correct.

If you'd like to post a coherent summary of the answers here, though, I'm sure that would be appreciated.

S Ellison
________________________________________



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From marc_schwartz at me.com  Wed Oct 19 13:12:34 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 19 Oct 2016 06:12:34 -0500
Subject: [R] rstudio mailing list
In-Reply-To: <CAAjnpdikCRG1jpycxFgOVEbm_9sH7ZfC7WVWSSGXneE8wKvHhg@mail.gmail.com>
References: <CAAjnpdikCRG1jpycxFgOVEbm_9sH7ZfC7WVWSSGXneE8wKvHhg@mail.gmail.com>
Message-ID: <E532B9D7-D58F-4FF4-97D8-5CA9F9933843@me.com>


> On Oct 19, 2016, at 4:27 AM, Witold E Wolski <wewolski at gmail.com> wrote:
> 
> Is there a mailing list for Rstudio related questions? I searched the
> web but did not find one.
> 
> Thank you
> 
> -- 
> Witold Eryk Wolski


It is linked to on their web site under Resources -> Support:

  https://support.rstudio.com/hc/en-us

Regards,

Marc Schwartz


From 1101011 at gmx.net  Wed Oct 19 13:21:12 2016
From: 1101011 at gmx.net (Mike meyer)
Date: Wed, 19 Oct 2016 13:21:12 +0200
Subject: [R] nls.lm
Message-ID: <trinity-e7580b2d-fd35-4504-87ea-f4ec95d17001-1476876072926@3capp-gmx-bs58>


Greetings,

 

The description of nls.lm specifies that in minimizing a sum of squares of residuals
 the number of residuals must be no less than the dimension of the independent variable
 ("par").
 In fact the algorithm does not work otherwise (termination code 0).
 But this condition is senseless, since it can be vacuously satisfied by adding zero residuals
 without altering the minimization problem.
 Nor, to the best of my knowledge does the number of residuals play a role in the Levenberg-Marquardt
 algorithm.

 So why does the R-implementation need this condition?

 

I am also not clear how the Jacobian should be formatted. I am assuming that it contains the gradients

of the residuals in the same order as the residuals occur in the function fn -- but this is not working for me.


From pdalgd at gmail.com  Wed Oct 19 13:38:00 2016
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Wed, 19 Oct 2016 13:38:00 +0200
Subject: [R] nls.lm
In-Reply-To: <trinity-e7580b2d-fd35-4504-87ea-f4ec95d17001-1476876072926@3capp-gmx-bs58>
References: <trinity-e7580b2d-fd35-4504-87ea-f4ec95d17001-1476876072926@3capp-gmx-bs58>
Message-ID: <84306527-EBAF-4A56-9673-F378EAE91E3E@gmail.com>

This would seem to apply to the add-on package minpack.lm. That package has a maintainer...

Offhand, I would expect that this is a sanity check that, broadly speaking, prevents you from trying to solve a system of equations with more unknowns than equations. This is not a sufficient condition: Increasing the number of equations by adding trivial equations like 0=0 may kill the sanity check, but it doesn't make the system any more solvable.

-pd

> On 19 Oct 2016, at 13:21 , Mike meyer <1101011 at gmx.net> wrote:
> 
> 
> Greetings,
> 
> 
> 
> The description of nls.lm specifies that in minimizing a sum of squares of residuals
> the number of residuals must be no less than the dimension of the independent variable
> ("par").
> In fact the algorithm does not work otherwise (termination code 0).
> But this condition is senseless, since it can be vacuously satisfied by adding zero residuals
> without altering the minimization problem.
> Nor, to the best of my knowledge does the number of residuals play a role in the Levenberg-Marquardt
> algorithm.
> 
> So why does the R-implementation need this condition?
> 
> 
> 
> I am also not clear how the Jacobian should be formatted. I am assuming that it contains the gradients
> 
> of the residuals in the same order as the residuals occur in the function fn -- but this is not working for me.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kevin.thorpe at utoronto.ca  Wed Oct 19 13:54:50 2016
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 19 Oct 2016 07:54:50 -0400
Subject: [R] Error installing packages
Message-ID: <467607ff-45a2-cd8e-cc5c-ce69095cdca0@utoronto.ca>

Hello.

I am posting this on behalf of one of my students who is getting error 
messages when installing some packages. I have not seen this before nor 
have I been able to replicate it. I'm including the relevant (I think) 
information. I get the students to install rms with dependencies. As you 
can see, rms does get installed but when the attempt is made to attach 
it, ggplot2 cannot be loaded. Thus I tried explicitly installing ggplot2 
and you can see then ensuing errors below. I have included the 
sessionInfo() at the end.

I hope someone can point me at a solution.


R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

   Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

 > install.packages("rms",dependencies=TRUE)
Installing package into ?C:/Users/Leticia/Documents/R/win-library/3.3?
(as ?lib? is unspecified)
--- Please select a CRAN mirror for use in this session ---
trying URL 
'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/rms_4.5-0.zip'
Content type 'application/zip' length 1074995 bytes (1.0 MB)
downloaded 1.0 MB

package ?rms? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
         C:\Users\Leticia\AppData\Local\Temp\Rtmpa0q2o2\downloaded_packages
 > library(rms)
Loading required package: Hmisc
Loading required package: lattice
Loading required package: survival
Loading required package: Formula
Loading required package: ggplot2
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), 
versionCheck = vI[[j]]) :
   there is no package called ?Rcpp?
Error: package ?ggplot2? could not be loaded
 > install.packages("ggplot2",dependencies=TRUE)
Installing package into ?C:/Users/Leticia/Documents/R/win-library/3.3?
(as ?lib? is unspecified)
also installing the dependency ?maptools?

trying URL 
'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/maptools_0.8-39.zip'
Content type 'application/zip' length 1816384 bytes (1.7 MB)
downloaded 0 bytes

trying URL 
'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/ggplot2_2.1.0.zip'
Content type 'application/zip' length 1996146 bytes (1.9 MB)
downloaded 4096 bytes

Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", 
"Type")) :
   cannot open the connection
In addition: Warning messages:
1: In download.file(url, destfile, method, mode = "wb", ...) :
   downloaded length 0 != reported length 1816384
2: In download.file(url, destfile, method, mode = "wb", ...) :
   downloaded length 4096 != reported length 1996146
3: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
4: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
   cannot open compressed file 'maptools/DESCRIPTION', probable reason 
'No such file or directory'
 > library(rms)
Loading required package: Hmisc
Loading required package: ggplot2
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), 
versionCheck = vI[[j]]) :
   there is no package called ?Rcpp?
Error: package ?ggplot2? could not be loaded
 > session.info()
Error: could not find function "session.info"
 > sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 10586)

locale:
[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252 
LC_MONETARY=English_Canada.1252
[4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] Formula_1.2-1   survival_2.39-4 lattice_0.20-33

loaded via a namespace (and not attached):
[1] Matrix_1.2-6  tools_3.3.1   gtable_0.2.0  splines_3.3.1 grid_3.3.1
 >

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From G.Maubach at weinwolf.de  Wed Oct 19 13:57:59 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 19 Oct 2016 13:57:59 +0200
Subject: [R] Storing long string with white space in variable
Message-ID: <OFC27CD8DE.0D3F3BE7-ONC1258051.00410308-C1258051.0041BB91@lotus.hawesko.de>

Hi All,

I would like to store a long string with white space in a variable:

-- cut --
  # Create README.md
  readme <- "---
title: "Your project title here"
author: "Author(s) name(s) here"
date: "Current date here"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
```
# Project Context

# Goals

# Approach

# Reference to main program
???{r}
source("main_program.R")
???

# Information on used system and configuration
```{r}
cat("Gathering system information ...\n)
sessionInfo()
```
"
cat(readme, file = "README.md")

-- cut --

I am looking for an equivalent to Pythons """  """ long string feature.

I searched the web and found this:

http://stackoverflow.com/questions/6329962/split-code-over-multiple-lines-in-an-r-script
https://stat.ethz.ch/pipermail/r-help/2006-October/115358.html

But this is not the solution to the problem.

How can I store long strings with white space in a variable?

Kind regards

Georg

PS: This is a template for a project folder for each project. I would like 
to create it with R script instead of distributing it as a template file. 
This way one needs only the R script to setup a project like this:

#-----------------------------------------------------------------------
# Module        : t_setup_project_directory.R
# Author        : Georg Maubach
# Date          : 2016-10-19
# Update        : 2016-10-19
# Description   : Setup a directory structure for a new analytics
#                 project
# Source System : R 3.3.0 (64 Bit)
# Target System : R 3.3.0 (64 Bit)
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
#--------1---------2---------3---------4---------5---------6---------7--

t_version = "2016-10-19"
t_module_name = "t_setup_project_directory.R"
t_status = "development"

cat(
    paste0(
        "\n",
        t_module_name,
        " (Version: ",
        t_version,
        ", Status: ",
        t_status,
        ")",
        "\n",
        "\n",
        "Copyright (C) Georg Maubach 2016

        This software comes with ABSOLUTELY NO WARRANTY.",
        "\n",
        "\n"
    )
)

library(svDialogs)

# If do_test is not defined globally define it here locally by 
un-commenting it
t_do_test <- FALSE

# [ Function Defintion 
]--------------------------------------------------------
t_setup_project_directory <- function() {
 
#-----------------------------------------------------------------------------
  # Setup a directory structure for a new analytics
  #
  # Args:
  #   None.
  #
  # Operation:
  #   The user can create or select a directory for the projects files.
  #   The function then places all sub directories in this project
  #   folder.
  #   The function saves a RData file with objects containing the path
  #   to project directory and its sub folders.
  #
  # Returns:
  #   Nothing.
  #
  # Error handling:
  #   None.
  #
  # See also:
  #   ./.
 
#-----------------------------------------------------------------------------

  # Get and/or create project directory
  v_project_dir <- svDialogs::dlgDir()$res

  # Define names for sub directories
  data          <- "data"             # data to be loaded into or
                                      # saved from R
  documentation <- "documentation"    # explanatory material for results
                                      # (e. g. knitR documents)
  fundamentals  <- "fundamentals"     # background knowledge
  input         <- "data/input"       # input data eventually manually
                                      # revised for import
  meta          <- "data/meta"        # meta data (e. g. lookup tables)
  output        <- "data/output"
  raw           <- "data/raw"         # a copy of all input data never
                                      # touched for safety reasons and
                                      # not read by R
  program       <- "program"          # all scripts and runnable files
  modules       <- "program/modules"  # project specific packages, files
                                      # or functions in separate files as
                                      # well as all other sub routines to
                                      # be sourced or loaded
  results       <- "results"          # container for all resulring data
                                      # in an aggregated form
  graphics      <- "results/graphics"
  tables        <- "results/tables"
  presentations <- "results/presentations"
  temp          <- "temp"

  v_paths_relative <- list(
    project       = v_project_dir,
    documentation = documentation,
    fundamentals  = fundamentals,
    input         = input,
    meta          = meta,
    output        = output,
    raw           = raw,
    program       = program,
    modules       = modules,
    graphic       = graphics,
    table         = tables,
    presentation  = presentations,
    temp          = temp
  )
  v_paths_full      <- list(
    documentation = file.path(v_project_dir, documentation),
    fundamentals  = file.path(v_project_dir, fundamentals),
    input         = file.path(v_project_dir, input),
    meta          = file.path(v_project_dir, meta),
    output        = file.path(v_project_dir, output),
    raw           = file.path(v_project_dir, raw),
    program       = file.path(v_project_dir, program),
    modules       = file.path(v_project_dir, modules),
    graphic       = file.path(v_project_dir, graphics),
    table         = file.path(v_project_dir, tables),
    presentation  = file.path(v_project_dir, presentations),
    temp          = file.path(v_project_dir, temp)
    )

  # Create sub directories if they are not there
  cat("-------------------------------------------------------------\n")
  cat("Creating directories ...\n")
  for (entry in v_paths_full) {
    if (file.exists(entry)) {
      cat("Directory ", entry, " NOT created. Exists already!\n")
    } else {
      dir.create(path = entry, recursive = TRUE)
      cat("Directory ", entry, " created!\n")
    }  # end if
  }  # end for
  cat("... Done! (Creating directories)\n")
  cat("-------------------------------------------------------------\n")

  # Create README.md
  readme <- "---
title: "Your project title here"
author: "Author(s) name(s) here"
date: "Current date here"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
```
# Project Context

# Goals

# Approach

# Reference to main program
???{r}
source("main_program.R")
???

# Information on used system and configuration
```{r}
cat("Gathering system information ...\n)
sessionInfo()
cat("... Done! (Gathering system information)\n")
```
"


  # Save config file
  cat("-------------------------------------------------------------\n")
  cat("Saving project config file ...\n")
  v_file_config <- file.path(v_paths_full$program,
                             "project_config.RData")
  save(list = c("v_paths_full", "v_paths_relative"),
       file = v_file_config
  )
  cat("File ", v_file_config, " created!\n")
  cat("... Done! (Saving path names)\n")
  cat("-------------------------------------------------------------\n")
}  # end function

# [ Test Defintion 
]------------------------------------------------------------
t_test <- function(do_test = FALSE) {
  if (do_test == TRUE) {
    t_setup_project_directory()
    }  # end if
}  # end function

# [ Test Run 
]------------------------------------------------------------------
t_test(do_test = t_do_test)

# [ Clean up 
]------------------------------------------------------------------
rm("t_module_name", "t_version", "t_status", "t_do_test", "t_test")

# EOF .


From 1101011 at gmx.net  Wed Oct 19 14:09:51 2016
From: 1101011 at gmx.net (Mike meyer)
Date: Wed, 19 Oct 2016 14:09:51 +0200
Subject: [R] nls.lm
Message-ID: <trinity-f1301bb3-f544-4193-a8f2-0134a79dfeed-1476878991595@3capp-gmx-bs58>

@pd: you know that a System of equations with more variables than equations is always solvable
and if a unique solution is desired one of mimimal norm can be used.

According to "Methods for nonlinear least squares problems" by Madsen, Nielsen and Tingleff the LM-algorithm
solves Systems of the form 
                            [J(x)'J(x)+\mu*I]x=...
with \mu>0 so that the Matrix on the left is always positive definite, especially nonsingular.


From marc_schwartz at me.com  Wed Oct 19 14:32:56 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 19 Oct 2016 07:32:56 -0500
Subject: [R] Error installing packages
In-Reply-To: <467607ff-45a2-cd8e-cc5c-ce69095cdca0@utoronto.ca>
References: <467607ff-45a2-cd8e-cc5c-ce69095cdca0@utoronto.ca>
Message-ID: <61AB9D49-D682-49A7-A346-10E12DB562F1@me.com>


> On Oct 19, 2016, at 6:54 AM, Kevin E. Thorpe <kevin.thorpe at utoronto.ca> wrote:
> 
> Hello.
> 
> I am posting this on behalf of one of my students who is getting error messages when installing some packages. I have not seen this before nor have I been able to replicate it. I'm including the relevant (I think) information. I get the students to install rms with dependencies. As you can see, rms does get installed but when the attempt is made to attach it, ggplot2 cannot be loaded. Thus I tried explicitly installing ggplot2 and you can see then ensuing errors below. I have included the sessionInfo() at the end.
> 
> I hope someone can point me at a solution.
> 
> 
> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
> Copyright (C) 2016 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>  Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
> > install.packages("rms",dependencies=TRUE)
> Installing package into ?C:/Users/Leticia/Documents/R/win-library/3.3?
> (as ?lib? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/rms_4.5-0.zip'
> Content type 'application/zip' length 1074995 bytes (1.0 MB)
> downloaded 1.0 MB
> 
> package ?rms? successfully unpacked and MD5 sums checked
> 
> The downloaded binary packages are in
>        C:\Users\Leticia\AppData\Local\Temp\Rtmpa0q2o2\downloaded_packages
> > library(rms)
> Loading required package: Hmisc
> Loading required package: lattice
> Loading required package: survival
> Loading required package: Formula
> Loading required package: ggplot2
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :
>  there is no package called ?Rcpp?
> Error: package ?ggplot2? could not be loaded
> > install.packages("ggplot2",dependencies=TRUE)
> Installing package into ?C:/Users/Leticia/Documents/R/win-library/3.3?
> (as ?lib? is unspecified)
> also installing the dependency ?maptools?
> 
> trying URL 'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/maptools_0.8-39.zip'
> Content type 'application/zip' length 1816384 bytes (1.7 MB)
> downloaded 0 bytes
> 
> trying URL 'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/ggplot2_2.1.0.zip'
> Content type 'application/zip' length 1996146 bytes (1.9 MB)
> downloaded 4096 bytes
> 
> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>  cannot open the connection
> In addition: Warning messages:
> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>  downloaded length 0 != reported length 1816384
> 2: In download.file(url, destfile, method, mode = "wb", ...) :
>  downloaded length 4096 != reported length 1996146
> 3: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
> 4: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>  cannot open compressed file 'maptools/DESCRIPTION', probable reason 'No such file or directory'
> > library(rms)
> Loading required package: Hmisc
> Loading required package: ggplot2
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :
>  there is no package called ?Rcpp?
> Error: package ?ggplot2? could not be loaded
> > session.info()
> Error: could not find function "session.info"
> > sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 10586)
> 
> locale:
> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252 LC_MONETARY=English_Canada.1252
> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] Formula_1.2-1   survival_2.39-4 lattice_0.20-33
> 
> loaded via a namespace (and not attached):
> [1] Matrix_1.2-6  tools_3.3.1   gtable_0.2.0  splines_3.3.1 grid_3.3.1
> >
> 

Kevin,

My first reaction is that some of the downloaded packages were corrupted, therefore not properly installed. There may be a problem with the mirror and/or the internet connection was compromised. There are messages above indicating file length differences between what was downloaded versus what the server indicated as the file size.

You might try a different CRAN mirror to see if that resolves the issue, albeit, I just tried to directly download a couple of the zip files on my Mac from the same mirror and did not have any issues, so it may be a transient server problem.

It is also possible that if the local package installation on their computer is corrupted in some manner, you may need to delete all CRAN based packages they installed fully and re-install all of the packages that are required, so that you have a level of comfort in the integrity of the local package installation.

Regards,

Marc Schwartz


From jdnewmil at dcn.davis.ca.us  Wed Oct 19 14:42:22 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 19 Oct 2016 05:42:22 -0700
Subject: [R] Error installing packages
In-Reply-To: <467607ff-45a2-cd8e-cc5c-ce69095cdca0@utoronto.ca>
References: <467607ff-45a2-cd8e-cc5c-ce69095cdca0@utoronto.ca>
Message-ID: <E2E904C7-5C11-485E-B33F-DE496600D828@dcn.davis.ca.us>

Different mirror?
-- 
Sent from my phone. Please excuse my brevity.

On October 19, 2016 4:54:50 AM PDT, "Kevin E. Thorpe" <kevin.thorpe at utoronto.ca> wrote:
>Hello.
>
>I am posting this on behalf of one of my students who is getting error 
>messages when installing some packages. I have not seen this before nor
>
>have I been able to replicate it. I'm including the relevant (I think) 
>information. I get the students to install rms with dependencies. As
>you 
>can see, rms does get installed but when the attempt is made to attach 
>it, ggplot2 cannot be loaded. Thus I tried explicitly installing
>ggplot2 
>and you can see then ensuing errors below. I have included the 
>sessionInfo() at the end.
>
>I hope someone can point me at a solution.
>
>
>R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
>Copyright (C) 2016 The R Foundation for Statistical Computing
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>
>R is free software and comes with ABSOLUTELY NO WARRANTY.
>You are welcome to redistribute it under certain conditions.
>Type 'license()' or 'licence()' for distribution details.
>
>   Natural language support but running in an English locale
>
>R is a collaborative project with many contributors.
>Type 'contributors()' for more information and
>'citation()' on how to cite R or R packages in publications.
>
>Type 'demo()' for some demos, 'help()' for on-line help, or
>'help.start()' for an HTML browser interface to help.
>Type 'q()' to quit R.
>
> > install.packages("rms",dependencies=TRUE)
>Installing package into ?C:/Users/Leticia/Documents/R/win-library/3.3?
>(as ?lib? is unspecified)
>--- Please select a CRAN mirror for use in this session ---
>trying URL 
>'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/rms_4.5-0.zip'
>Content type 'application/zip' length 1074995 bytes (1.0 MB)
>downloaded 1.0 MB
>
>package ?rms? successfully unpacked and MD5 sums checked
>
>The downloaded binary packages are in
>     C:\Users\Leticia\AppData\Local\Temp\Rtmpa0q2o2\downloaded_packages
> > library(rms)
>Loading required package: Hmisc
>Loading required package: lattice
>Loading required package: survival
>Loading required package: Formula
>Loading required package: ggplot2
>Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), 
>versionCheck = vI[[j]]) :
>   there is no package called ?Rcpp?
>Error: package ?ggplot2? could not be loaded
> > install.packages("ggplot2",dependencies=TRUE)
>Installing package into ?C:/Users/Leticia/Documents/R/win-library/3.3?
>(as ?lib? is unspecified)
>also installing the dependency ?maptools?
>
>trying URL 
>'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/maptools_0.8-39.zip'
>Content type 'application/zip' length 1816384 bytes (1.7 MB)
>downloaded 0 bytes
>
>trying URL 
>'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/ggplot2_2.1.0.zip'
>Content type 'application/zip' length 1996146 bytes (1.9 MB)
>downloaded 4096 bytes
>
>Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", 
>"Type")) :
>   cannot open the connection
>In addition: Warning messages:
>1: In download.file(url, destfile, method, mode = "wb", ...) :
>   downloaded length 0 != reported length 1816384
>2: In download.file(url, destfile, method, mode = "wb", ...) :
>   downloaded length 4096 != reported length 1996146
>3: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
>file
>4: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
>:
>   cannot open compressed file 'maptools/DESCRIPTION', probable reason 
>'No such file or directory'
> > library(rms)
>Loading required package: Hmisc
>Loading required package: ggplot2
>Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), 
>versionCheck = vI[[j]]) :
>   there is no package called ?Rcpp?
>Error: package ?ggplot2? could not be loaded
> > session.info()
>Error: could not find function "session.info"
> > sessionInfo()
>R version 3.3.1 (2016-06-21)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows 10 x64 (build 10586)
>
>locale:
>[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252 
>LC_MONETARY=English_Canada.1252
>[4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>other attached packages:
>[1] Formula_1.2-1   survival_2.39-4 lattice_0.20-33
>
>loaded via a namespace (and not attached):
>[1] Matrix_1.2-6  tools_3.3.1   gtable_0.2.0  splines_3.3.1 grid_3.3.1
> >
>
>-- 
>Kevin E. Thorpe
>Head of Biostatistics,  Applied Health Research Centre (AHRC)
>Li Ka Shing Knowledge Institute of St. Michael's Hospital
>Assistant Professor, Dalla Lana School of Public Health
>University of Toronto
>email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From profjcnash at gmail.com  Wed Oct 19 14:56:35 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Wed, 19 Oct 2016 08:56:35 -0400
Subject: [R] nls.lm
In-Reply-To: <trinity-f1301bb3-f544-4193-a8f2-0134a79dfeed-1476878991595@3capp-gmx-bs58>
References: <trinity-f1301bb3-f544-4193-a8f2-0134a79dfeed-1476878991595@3capp-gmx-bs58>
Message-ID: <59308cc7-0da5-cdaf-e0fe-5e9d7330b1cf@gmail.com>

Peter is right that the conditions may be embedded in the underlying code. (Ask Kate!)

My nlmrt package is all in R, so the conditions are visible. I'm currently in process of rejigging this
using some work Duncan Murdoch helped with a while ago (I've had some other things get in the way), so
I can change such conditions. In the present case, I think I'd issue a warning, but haven't checked
whether I do or not.

I'd be very happy to have the usual "minimal reproducible example" scripts of issues with any nonlinear
least squares problems to use as tests to keep knocking the rough edges off the codes I'm working on.
Note, in particular, that the new code (named nlsr) tries to use analytic derivatives that are computed
from the model expression. Ultimately would like to have automatic derivatives to apply to functions too,
and migrate that to optimrx/optimr which are recently on Rforge/CRAN (optimr has fewer solvers to avoid
the "your program doesn't work" when a solver is changed/removed).

Best, JN

On 16-10-19 08:09 AM, Mike meyer wrote:
> @pd: you know that a System of equations with more variables than equations is always solvable
> and if a unique solution is desired one of mimimal norm can be used.
> 
> According to "Methods for nonlinear least squares problems" by Madsen, Nielsen and Tingleff the LM-algorithm
> solves Systems of the form 
>                             [J(x)'J(x)+\mu*I]x=...
> with \mu>0 so that the Matrix on the left is always positive definite, especially nonsingular.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Wed Oct 19 15:09:31 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 19 Oct 2016 06:09:31 -0700
Subject: [R] Storing long string with white space in variable
In-Reply-To: <OFC27CD8DE.0D3F3BE7-ONC1258051.00410308-C1258051.0041BB91@lotus.hawesko.de>
References: <OFC27CD8DE.0D3F3BE7-ONC1258051.00410308-C1258051.0041BB91@lotus.hawesko.de>
Message-ID: <465F5B61-6F0D-4E31-B357-9B3AB9C7B11F@dcn.davis.ca.us>

The best way to do this is to put your code in a package and put the files into a dedicated directory in the package that you just copy files from using system.file.

R does not have Python """ strings or Perl "here" files. You can create a script that reads the files in with readlines and writes out the source code version of those files with dput, but that is very un-R-like.
-- 
Sent from my phone. Please excuse my brevity.

On October 19, 2016 4:57:59 AM PDT, G.Maubach at weinwolf.de wrote:
>Hi All,
>
>I would like to store a long string with white space in a variable:
>
>-- cut --
>  # Create README.md
>  readme <- "---
>title: "Your project title here"
>author: "Author(s) name(s) here"
>date: "Current date here"
>output: html_document
>---
>
>```{r setup, include=FALSE}
>knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
>```
># Project Context
>
># Goals
>
># Approach
>
># Reference to main program
>???{r}
>source("main_program.R")
>???
>
># Information on used system and configuration
>```{r}
>cat("Gathering system information ...\n)
>sessionInfo()
>```
>"
>cat(readme, file = "README.md")
>
>-- cut --
>
>I am looking for an equivalent to Pythons """  """ long string feature.
>
>I searched the web and found this:
>
>http://stackoverflow.com/questions/6329962/split-code-over-multiple-lines-in-an-r-script
>https://stat.ethz.ch/pipermail/r-help/2006-October/115358.html
>
>But this is not the solution to the problem.
>
>How can I store long strings with white space in a variable?
>
>Kind regards
>
>Georg
>
>PS: This is a template for a project folder for each project. I would
>like 
>to create it with R script instead of distributing it as a template
>file. 
>This way one needs only the R script to setup a project like this:
>
>#-----------------------------------------------------------------------
># Module        : t_setup_project_directory.R
># Author        : Georg Maubach
># Date          : 2016-10-19
># Update        : 2016-10-19
># Description   : Setup a directory structure for a new analytics
>#                 project
># Source System : R 3.3.0 (64 Bit)
># Target System : R 3.3.0 (64 Bit)
>#
># This program is distributed in the hope that it will be useful,
># but WITHOUT ANY WARRANTY; without even the implied warranty of
># MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
>#--------1---------2---------3---------4---------5---------6---------7--
>
>t_version = "2016-10-19"
>t_module_name = "t_setup_project_directory.R"
>t_status = "development"
>
>cat(
>    paste0(
>        "\n",
>        t_module_name,
>        " (Version: ",
>        t_version,
>        ", Status: ",
>        t_status,
>        ")",
>        "\n",
>        "\n",
>        "Copyright (C) Georg Maubach 2016
>
>        This software comes with ABSOLUTELY NO WARRANTY.",
>        "\n",
>        "\n"
>    )
>)
>
>library(svDialogs)
>
># If do_test is not defined globally define it here locally by 
>un-commenting it
>t_do_test <- FALSE
>
># [ Function Defintion 
>]--------------------------------------------------------
>t_setup_project_directory <- function() {
> 
>#-----------------------------------------------------------------------------
>  # Setup a directory structure for a new analytics
>  #
>  # Args:
>  #   None.
>  #
>  # Operation:
>  #   The user can create or select a directory for the projects files.
>  #   The function then places all sub directories in this project
>  #   folder.
>  #   The function saves a RData file with objects containing the path
>  #   to project directory and its sub folders.
>  #
>  # Returns:
>  #   Nothing.
>  #
>  # Error handling:
>  #   None.
>  #
>  # See also:
>  #   ./.
> 
>#-----------------------------------------------------------------------------
>
>  # Get and/or create project directory
>  v_project_dir <- svDialogs::dlgDir()$res
>
>  # Define names for sub directories
>  data          <- "data"             # data to be loaded into or
>                                      # saved from R
> documentation <- "documentation"    # explanatory material for results
>                                      # (e. g. knitR documents)
>  fundamentals  <- "fundamentals"     # background knowledge
>  input         <- "data/input"       # input data eventually manually
>                                      # revised for import
>  meta          <- "data/meta"        # meta data (e. g. lookup tables)
>  output        <- "data/output"
>  raw           <- "data/raw"         # a copy of all input data never
>                                      # touched for safety reasons and
>                                      # not read by R
>  program       <- "program"          # all scripts and runnable files
> modules       <- "program/modules"  # project specific packages, files
>                                    # or functions in separate files as
>                                    # well as all other sub routines to
>                                      # be sourced or loaded
> results       <- "results"          # container for all resulring data
>                                      # in an aggregated form
>  graphics      <- "results/graphics"
>  tables        <- "results/tables"
>  presentations <- "results/presentations"
>  temp          <- "temp"
>
>  v_paths_relative <- list(
>    project       = v_project_dir,
>    documentation = documentation,
>    fundamentals  = fundamentals,
>    input         = input,
>    meta          = meta,
>    output        = output,
>    raw           = raw,
>    program       = program,
>    modules       = modules,
>    graphic       = graphics,
>    table         = tables,
>    presentation  = presentations,
>    temp          = temp
>  )
>  v_paths_full      <- list(
>    documentation = file.path(v_project_dir, documentation),
>    fundamentals  = file.path(v_project_dir, fundamentals),
>    input         = file.path(v_project_dir, input),
>    meta          = file.path(v_project_dir, meta),
>    output        = file.path(v_project_dir, output),
>    raw           = file.path(v_project_dir, raw),
>    program       = file.path(v_project_dir, program),
>    modules       = file.path(v_project_dir, modules),
>    graphic       = file.path(v_project_dir, graphics),
>    table         = file.path(v_project_dir, tables),
>    presentation  = file.path(v_project_dir, presentations),
>    temp          = file.path(v_project_dir, temp)
>    )
>
>  # Create sub directories if they are not there
> cat("-------------------------------------------------------------\n")
>  cat("Creating directories ...\n")
>  for (entry in v_paths_full) {
>    if (file.exists(entry)) {
>      cat("Directory ", entry, " NOT created. Exists already!\n")
>    } else {
>      dir.create(path = entry, recursive = TRUE)
>      cat("Directory ", entry, " created!\n")
>    }  # end if
>  }  # end for
>  cat("... Done! (Creating directories)\n")
> cat("-------------------------------------------------------------\n")
>
>  # Create README.md
>  readme <- "---
>title: "Your project title here"
>author: "Author(s) name(s) here"
>date: "Current date here"
>output: html_document
>---
>
>```{r setup, include=FALSE}
>knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
>```
># Project Context
>
># Goals
>
># Approach
>
># Reference to main program
>???{r}
>source("main_program.R")
>???
>
># Information on used system and configuration
>```{r}
>cat("Gathering system information ...\n)
>sessionInfo()
>cat("... Done! (Gathering system information)\n")
>```
>"
>
>
>  # Save config file
> cat("-------------------------------------------------------------\n")
>  cat("Saving project config file ...\n")
>  v_file_config <- file.path(v_paths_full$program,
>                             "project_config.RData")
>  save(list = c("v_paths_full", "v_paths_relative"),
>       file = v_file_config
>  )
>  cat("File ", v_file_config, " created!\n")
>  cat("... Done! (Saving path names)\n")
> cat("-------------------------------------------------------------\n")
>}  # end function
>
># [ Test Defintion 
>]------------------------------------------------------------
>t_test <- function(do_test = FALSE) {
>  if (do_test == TRUE) {
>    t_setup_project_directory()
>    }  # end if
>}  # end function
>
># [ Test Run 
>]------------------------------------------------------------------
>t_test(do_test = t_do_test)
>
># [ Clean up 
>]------------------------------------------------------------------
>rm("t_module_name", "t_version", "t_status", "t_do_test", "t_test")
>
># EOF .
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Wed Oct 19 15:38:59 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 19 Oct 2016 15:38:59 +0200
Subject: [R] nls.lm
In-Reply-To: <trinity-f1301bb3-f544-4193-a8f2-0134a79dfeed-1476878991595@3capp-gmx-bs58>
References: <trinity-f1301bb3-f544-4193-a8f2-0134a79dfeed-1476878991595@3capp-gmx-bs58>
Message-ID: <8D9C473B-082E-42C6-9794-A30503796FD1@xs4all.nl>


> On 19 Oct 2016, at 14:09, Mike meyer <1101011 at gmx.net> wrote:
> 
> @pd: you know that a System of equations with more variables than equations is always solvable
> and if a unique solution is desired one of mimimal norm can be used.
> 

You won't get  a minimum norm solution by using a least squares algorithm on the residuals.

> According to "Methods for nonlinear least squares problems" by Madsen, Nielsen and Tingleff the LM-algorithm
> solves Systems of the form 
>                            [J(x)'J(x)+\mu*I]x=...
> with \mu>0 so that the Matrix on the left is always positive definite, especially nonsingular.
> 

I found the pdf for the book you mention here: http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3215/pdf/imm3215.pdf
(from 2004; correct?).

In the first chapter at the very beginning it is clearly stated that the number of residuals (m) must be larger or equal to the number of independent variables (n).

And if m < n you have an underdetermined system of equations. You can't let a least squares method loose on that.
There is an infinity of solutions. You will first have to set the kind of solution you want: a minimum norm solution or something else.

I believe you are mistaken in your assertion.

Berend


From S.Ellison at LGCGroup.com  Wed Oct 19 16:16:07 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 19 Oct 2016 15:16:07 +0100
Subject: [R] nls.lm
In-Reply-To: <trinity-f1301bb3-f544-4193-a8f2-0134a79dfeed-1476878991595@3capp-gmx-bs58>
References: <trinity-f1301bb3-f544-4193-a8f2-0134a79dfeed-1476878991595@3capp-gmx-bs58>
Message-ID: <1A8C1289955EF649A09086A153E2672403FE7A2EF4@GBTEDVPEXCMB04.corp.lgc-group.com>


> Mike meyer 
> @pd: you know that a System of equations with more variables than equations is always solvable
> and if a unique solution is desired one of mimimal norm can be used.

Here's an example of what you _said_:

x + y + z = 2
3x - y +4z = 4

Find a unique single-valued solution for all of x, y and z.

Are you quite sure that that is what you _meant_?


S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From bgunter.4567 at gmail.com  Wed Oct 19 16:48:47 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 19 Oct 2016 07:48:47 -0700
Subject: [R] rstudio mailing list
In-Reply-To: <CAAjnpdikCRG1jpycxFgOVEbm_9sH7ZfC7WVWSSGXneE8wKvHhg@mail.gmail.com>
References: <CAAjnpdikCRG1jpycxFgOVEbm_9sH7ZfC7WVWSSGXneE8wKvHhg@mail.gmail.com>
Message-ID: <CAGxFJbQk=MgszY7vEv+Cst8KaeckQf-PGdM5iN_sv74JXunzZg@mail.gmail.com>

Try searching at Rstudio???  They have an faq, community forum, etc.

Bert

On Oct 19, 2016 11:28 AM, "Witold E Wolski" <wewolski at gmail.com> wrote:

> Is there a mailing list for Rstudio related questions? I searched the
> web but did not find one.
>
> Thank you
>
> --
> Witold Eryk Wolski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wewolski at gmail.com  Wed Oct 19 17:01:10 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Wed, 19 Oct 2016 17:01:10 +0200
Subject: [R] create n suffixes of length 1:n from string of length n
Message-ID: <CAAjnpdh5uYa2XrLGZ5L54Bxu+UQ9az3w-ivHfB5f92vY47Fsvw@mail.gmail.com>

Is there a build in function, which creates n suffixes of length 1:n
from string of length n?
e.g given abcd

produces
"a"
"ab"
"abc"


FAST.

equally nice to have would be:

e.g.
given c("a", "b", "c")
produces
"a"
"a","b"
"a","b","c"

Thank you
Witold


-- 
Witold Eryk Wolski


From bob at rud.is  Wed Oct 19 17:26:48 2016
From: bob at rud.is (Bob Rudis)
Date: Wed, 19 Oct 2016 11:26:48 -0400
Subject: [R] create n suffixes of length 1:n from string of length n
In-Reply-To: <CAAjnpdh5uYa2XrLGZ5L54Bxu+UQ9az3w-ivHfB5f92vY47Fsvw@mail.gmail.com>
References: <CAAjnpdh5uYa2XrLGZ5L54Bxu+UQ9az3w-ivHfB5f92vY47Fsvw@mail.gmail.com>
Message-ID: <CAA-FpKXjsoY-uMDykVboxw21cwvuFifxEc9j4RLK=C-5hDMmFg@mail.gmail.com>

purrr::map(paste0(letters, collapse=""), ~purrr::map2_chr(.,
1:nchar(.), ~substr(.x, 1, .y)))[[1]]

seems to crank really fast at least on my system

what did you try that was slow?

On Wed, Oct 19, 2016 at 11:01 AM, Witold E Wolski <wewolski at gmail.com> wrote:
> Is there a build in function, which creates n suffixes of length 1:n
> from string of length n?
> e.g given abcd
>
> produces
> "a"
> "ab"
> "abc"
>
>
> FAST.
>
> equally nice to have would be:
>
> e.g.
> given c("a", "b", "c")
> produces
> "a"
> "a","b"
> "a","b","c"
>
> Thank you
> Witold
>
>
> --
> Witold Eryk Wolski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Wed Oct 19 17:28:07 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 19 Oct 2016 17:28:07 +0200
Subject: [R] nls.lm
In-Reply-To: <trinity-f1301bb3-f544-4193-a8f2-0134a79dfeed-1476878991595@3capp-gmx-bs58>
References: <trinity-f1301bb3-f544-4193-a8f2-0134a79dfeed-1476878991595@3capp-gmx-bs58>
Message-ID: <4E857925-A5AF-42E8-BEED-47FF16B4BA6B@xs4all.nl>


> On 19 Oct 2016, at 14:09, Mike meyer <1101011 at gmx.net> wrote:
> 
> @pd: you know that a System of equations with more variables than equations is always solvable
> and if a unique solution is desired one of mimimal norm can be used.
> 

Not true.

Take the system with 3 variables and 2 equations

x+y+z = 3
x+y+z = 4

This does not have a solution.
See https://en.wikipedia.org/wiki/Consistent_and_inconsistent_equations

Berend

> According to "Methods for nonlinear least squares problems" by Madsen, Nielsen and Tingleff the LM-algorithm
> solves Systems of the form 
>                            [J(x)'J(x)+\mu*I]x=...
> with \mu>0 so that the Matrix on the left is always positive definite, especially nonsingular.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bryanmac.24 at gmail.com  Wed Oct 19 17:28:00 2016
From: bryanmac.24 at gmail.com (Bryan Mac)
Date: Wed, 19 Oct 2016 08:28:00 -0700
Subject: [R] Bootstrapping in R
In-Reply-To: <58060037.70406@sapo.pt>
References: <20160929201655.Horde.3eE2mopuZGp8trrU2jNt_Pt@mail.sapo.pt>
	<4F7BC824-B9E1-44E9-851A-579AC53CBED1@gmail.com>
	<1bb2778d-72ca-8bf7-1953-2015240fb47a@gmail.com>
	<019A773B-8E05-44B8-893B-5EE07EB0C748@gmail.com>
	<20161002133750.Horde.VcvwnCaVQDIDrpGU1boqnIG@mail.sapo.pt>
	<C207B957-6D52-40EA-8AF6-9A47D486EA79@gmail.com>
	<20161003085615.Horde.e_A4XElTPLz6c3vZUBqdD0V@mail.sapo.pt>
	<B6A7D458-EF5F-4BC6-A679-96244A3F29FD@gmail.com>
	<20161004115621.Horde.wqW5XuQVd9-RtDiChLFDCqQ@mail.sapo.pt>
	<1D5C83A5-F3ED-404E-B103-B90E702ADEFE@gmail.com>
	<20161005112747.Horde.u0qK8GchIo5f1vWoOBxFTbx@mail.sapo.pt>
	<0AFC8FE7-F750-42C1-863E-AF96090A6005@gmail.com>
	<20161006114832.Horde.0T6KMQtULyRblm9Iq3AbdJi@mail.sapo.pt>
	<9098C8AB-AFBA-4071-83C5-EA3F69C11408@gmail.com>
	<20161007214110.Horde.c9HswuSoaW02YuDTGjfyt9O@mail.sapo.pt>
	<C5933EAA-BC5E-49B2-B667-F503F8846661@gmail.com>
	<58060037.70406@sapo.pt>
Message-ID: <E1819F2A-09CE-47F0-B785-5441085A4914@gmail.com>

Hi,

After running the bootstrapping, I would like to the output of the bootstrapped samples. How can I view the bootstrapped samples of each variable?

Bryan Mac
bryanmac.24 at gmail.com



> On Oct 18, 2016, at 3:57 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> It means that the sd of the bootstrap samples is 0.21.
> See function ?boot.ci for confidence intervals.
> You should also start a new thread in R-Help, you will have more and better answers.
> 
> Em 18-10-2016 08:15, Bryan Mac escreveu:
>> Hi Rui,
>> 
>> I am having trouble understanding what this means exactly? Does this
>> mean that the bootstrapped number is +/-0.21 from the original?
>> 
>> 
>> How would i show all of the t?s in the bootstrap? I have about t1 to t28
>> so far. Would it be possible to show all of them?
> 
> I don't understand what you mean by this. All of the results are returned and printed by boot().
> 
> Rui Barradas
>> 
>> Bryan Mac
>> bryanmac.24 at gmail.com <mailto:bryanmac.24 at gmail.com>
>> 
>> 
>> 
>>> On Oct 7, 2016, at 1:41 PM, ruipbarradas at sapo.pt
>>> <mailto:ruipbarradas at sapo.pt> wrote:
>>> 
>>> Hello,
>>> 
>>> That's just the definition of a function, you have to actually call
>>> it, in a call to boot(9, for instance.
>>> 
>>> 
>>> OLSCoef_NAR_NIC <- function(df, indices){
>>>  sample <- df[indices, ]
>>>  OLS_NAR_NIC_relation <- lm(NAR ~ NIC, data = sample)
>>>  coef_ols_nar_nic <- coef(OLS_NAR_NIC_relation)
>>>  coef_ols_nar_nic
>>> }
>>> 
>>> boot(n_data, statistic = OLSCoef_NAR_NIC, R = 100)
>>> 
>>> ORDINARY NONPARAMETRIC BOOTSTRAP
>>> 
>>> 
>>> Call:
>>> boot(data = n_data, statistic = OLSCoef_NAR_NIC, R = 100)
>>> 
>>> 
>>> Bootstrap Statistics :
>>>     original       bias    std. error
>>> t1* 1.8788189 -0.013771706  0.59596631
>>> t2* 0.5003911  0.002478478  0.09016857
>>> 
>>> 
>>> As for the output in the format you want, I sugest you call lm(9, with
>>> your entire df, since it is big there's no reason to bootstrap it.
>>> Something like this:
>>> 
>>> > model <- lm(NAR ~ NIC, data = data)
>>> > summary(model)
>>> 
>>> Call:
>>> lm(formula = NAR ~ NIC, data = data)
>>> 
>>> Residuals:
>>>    Min      1Q  Median      3Q     Max
>>> -6.0459 -1.1916  0.2126  1.3424  4.8094
>>> 
>>> Coefficients:
>>>            Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)  1.66395    0.18859   8.823   <2e-16 ***
>>> NIC          0.56384    0.02588  21.783   <2e-16 ***
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> Residual standard error: 1.886 on 1267 degrees of freedom
>>> Multiple R-squared:  0.2725,    Adjusted R-squared:  0.2719
>>> F-statistic: 474.5 on 1 and 1267 DF,  p-value: < 2.2e-16
>>> 
>>> Rui Barradas
>>> 
>>> Citando Bryan Mac <bryanmac.24 at gmail.com <mailto:bryanmac.24 at gmail.com>>:
>>> 
>>>> By the way, when I ran the code, i didn?t see any output of results.
>>>> 
>>>> This is what I got.
>>>> <OLS.PNG>
>>>> Bryan Mac
>>>> bryanmac.24 at gmail.com <mailto:bryanmac.24 at gmail.com>
>>>>> On Oct 6, 2016, at 3:48 AM, ruipbarradas at sapo.pt
>>>>> <mailto:ruipbarradas at sapo.pt> wrote:
>>> 
>>> Hello,
>>> 
>>> I believe that your code is correct, I don't understand what you mean
>>> by "not showing up".
>>> If you want the coefficients, residuals, etc, your bootstrap statistic
>>> function needs to return those values. You can, for instance, use a
>>> different function, one to return the r-squared, another to return the
>>> coefficients or t.value, etc.
>>> 
>>> This function would return the coefficients. Note that if you use the
>>> argument data = ... you don't need the name of the df in your formula.
>>> It makes the code more readable.
>>> 
>>> 
>>> OLSCoef_NAR_NIC <- function(df, indices){
>>>  sample <- df[indices, ]
>>>  OLS_NAR_NIC_relation <- lm(NAR ~ NIC, data = sample)
>>>  coef_ols_nar_nic <- coef(OLS_NAR_NIC_relation)
>>>  coef_ols_nar_nic
>>> }
>>> 
>>> Rui Barradas
>>> 
>>> Citando Bryan Mac <bryanmac.24 at gmail.com <mailto:bryanmac.24 at gmail.com>>:
>>> 
>>>> Hi Rui,
>>>> 
>>>> My next steps is to run both Least Median Square Regression and
>>>> Ordinary Least Square Regression after the bootstrap.
>>>> Me and my colleague wrote the code for it. I am having doubts that it
>>>> is correct. Is this how you compete the OLS and LMS Regression?
>>>> Doesn?t my output have to model the sample below? I believe I do have
>>>> the code that can model it but its not showing up, but i do not see
>>>> the residuals or the coefficients (estimate/std. error,t.value,etc.)
>>>> Sample Code:
>>>>  Call:
>>>> ## lm(formula = crime ~ poverty + single, data = cdata)
>>>> ##
>>>> ## Residuals:
>>>> ##    Min     1Q Median     3Q    Max
>>>> ## -811.1 -114.3  -22.4  121.9  689.8
>>>> ##
>>>> ## Coefficients:
>>>> ##             Estimate Std. Error t value Pr(>|t|)
>>>> ## (Intercept) -1368.19     187.21   -7.31  2.5e-09 ***
>>>> ## poverty         6.79       8.99    0.76     0.45
>>>> ## single        166.37      19.42    8.57  3.1e-11 ***
>>>> ## ---
>>>> ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>> ##
>>>> ## Residual standard error: 244 on 48 degrees of freedom
>>>> ## Multiple R-squared:  0.707, Adjusted R-squared:  0.695
>>>> ## F-statistic:   58 on 2 and 48 DF,  p-value: 1.58e-13
>>>> This is our code:
>>>> OLSRegression <- function(df, indices){
>>>> sample <- df[indices, ]
>>>> OLS_NAR_NIC_relation <- lm(sample$NAR~sample$NIC, data = sample)
>>>> rsquared_ols_nar_nic <- summary(OLS_NAR_NIC_relation)$r.square
>>>> 
>>>> 
>>>> OLS_SQRTNAR_SQRTNIC_relation <- lm(sample$SQRTNAR~sample$SQRTNIC,
>>>> data = sample)
>>>> rsquared_ols_sqrtnar_sqrtnic <-
>>>> summary(OLS_SQRTNAR_SQRTNIC_relation)$r.square
>>>> 
>>>> 
>>>> out <- c(rsquared_ols_nar_nic, rsquared_ols_sqrtnar_sqrtnic)
>>>>  return(out)
>>>> }
>>>> LMSRegression <- function(df, indices){
>>>> sample <- df[indices, ]
>>>> LMS_NAR_NIC_relation <- lm(sample$NAR~sample$NIC, data = sample,
>>>> method = "lms")
>>>> rsquared_lms_nar_nic <- summary(LMS_NAR_NIC_relation)$r.square
>>>> 
>>>> 
>>>> LMS_SQRTNAR_SQRTNIC_relation <- lm(sample$SQRTNAR~sample$SQRTNIC,
>>>> data = sample, method = "lms")
>>>> rsquared_lms_sqrtnar_sqrtnic <-
>>>> summary(LMS_SQRTNAR_SQRTNIC_relation)$r.square
>>>> 
>>>> 
>>>> out <- c(rsquared_lms_nar_nic, rsquared_lms_sqrtnar_sqrtnic)
>>>>  return(out)
>>>> }
>>>> boot.out.ols <- boot(n_data, statistic = OLSRegression, R = 100)
>>>> boot.out.ols
>>>> plot(boot.out.ols, index = 1)
>>>> title(sub = "Histogram and Q-Q plot for relation between NAR-NIC
>>>> (OLS; R-Squared Value)", line = 4)
>>>> plot(boot.out.ols, index = 2)
>>>> title(sub = "Histogram and Q-Q plot for relation between
>>>> SQRTNAR-SQRTNIC (OLS; R-Squared Value)", line = 4)
>>>> ci_ols_1 <- boot.ci(boot.out.ols, index = 1, type = "all")
>>>> ci_ols_1
>>>> ci_ols_filtered_1 <- ci_ols_1$bca[, c(4,5)]
>>>> ci_ols_filtered_1
>>>> hist(boot.out.ols$t[,1], main = 'Determination of Coefficient:
>>>> NAR-NIC', xlab = 'R-Squared', col = 'LightBlue', probability = T)
>>>> lines(density(boot.out.ols$t[,1]), col = 'Red')
>>>> abline(v = ci_ols_filtered_1, col = 'brown')
>>>> ci_ols_2 <- boot.ci(boot.out.ols, index = 2, type = "all")
>>>> ci_ols_2
>>>> ci_ols_filtered_2 <- ci_ols_2$bca[, c(4,5)]
>>>> ci_ols_filtered_2
>>>> hist(boot.out.ols$t[,2], main = 'Determination of Coefficient:
>>>> SQRTNAR-SQRTNIC', xlab = 'R-Squared', col = 'LightBlue', probability = T)
>>>> lines(density(boot.out.ols$t[,2]), col = 'Red')
>>>> abline(v = ci_ols_filtered_2, col = 'brown')
>>>> boot.out.lms <- boot(n_data, statistic = LMSRegression, R = 100)
>>>> boot.out.lms
>>>> plot(boot.out.lms, index = 1)
>>>> title(sub = "Histogram and Q-Q plot for relation between NAR-NIC
>>>> (OLS; R-Squared Value)", line = 4)
>>>> plot(boot.out.lms, index = 2)
>>>> title(sub = "Histogram and Q-Q plot for relation between
>>>> SQRTNAR-SQRTNIC (OLS; R-Squared Value)", line = 4)
>>>> ci_lms_1<- boot.ci(boot.out.lms, index = 1, type = "all")
>>>> ci_lms_1
>>>> ci_lms_filtered_1 <- ci_lms_1$bca[, c(4,5)]
>>>> ci_lms_filtered_1
>>>> hist(boot.out.lms$t[,1], main = 'Determination of Coefficient:
>>>> NAR-NIC', xlab = 'R-Squared', col = 'LightBlue', probability = T)
>>>> lines(density(boot.out.lms$t[,1]), col = 'Red')
>>>> abline(v = ci_ols_filtered_1, col = 'brown')
>>>> ci_lms_2<- boot.ci(boot.out.lms, index = 2, type = "all")
>>>> ci_lms_2
>>>> ci_lms_filtered_2 <- ci_lms_2$bca[, c(4,5)]
>>>> ci_lms_filtered_2
>>>> hist(boot.out.lms$t[,2], main = 'Determination of Coefficient:
>>>> SQRTNAR-SQRTNIC', xlab = 'R-Squared', col = 'LightBlue', probability = T)
>>>> lines(density(boot.out.lms$t[,2]), col = 'Red')
>>>> abline(v = ci_ols_filtered_2, col = 'brown')
>>>> Bryan Mac
>>>> bryanmac.24 at gmail.com <mailto:bryanmac.24 at gmail.com>
>>>>> On Oct 5, 2016, at 3:27 AM, ruipbarradas at sapo.pt
>>>>> <mailto:ruipbarradas at sapo.pt> wrote:
>>> 
>>> Hello,
>>> 
>>> Inline.
>>> 
>>> Citando Bryan Mac <bryanmac.24 at gmail.com <mailto:bryanmac.24 at gmail.com>>:
>>> 
>>>> Hi Rui, Thanks.
>>>> 
>>>> About this part of the code, I thought because we are bootstrapping
>>>> which is random sample WITH replacement, it would be replace=TRUE ?
>>>> Or is it replace=FALSE because its not trying to replace the values
>>>> in the columns, but just trying to randomly call 100 cases out of the
>>>> total?
>>>> 
>>>> Yes, you said that you want to select a sub-df and _then_ bootstrap
>>>> it, so you should choose it without replacement, it's the bootstrap
>>>> that uses sampling with replacement.
>>>> 
>>>> Rui Barradas
>>>> ix <- sample(1269, 100, replace = FALSE)
>>>> n_|data <- data[ix, cols]|
>>>> Also, I got no errors as well. Thanks.
>>>> Best,
>>>> Bryan Mac
>>>> bryanmac.24 at gmail.com <mailto:bryanmac.24 at gmail.com>
>>>>> On Oct 4, 2016, at 3:56 AM, ruipbarradas at sapo.pt
>>>>> <mailto:ruipbarradas at sapo.pt> wrote:
>>> 
>>> Two more things.
>>> 
>>> 1) Don't call your df data or df, those are names of R functions.
>>> 2) I've just ran boot(data, statistic = DataSummary, R = 100), with
>>> the 1269 rows, and it gave me no error.
>>> 
>>> Rui Barradas
>>> 
>>> Citando Bryan Mac <bryanmac.24 at gmail.com <mailto:bryanmac.24 at gmail.com>>:
>>> 
>>>> Hi Rui,
>>>> 
>>>> Its for a project that I am dealing with at work. It has to do with
>>>> estimation of advertisement performance.
>>>> What the code has to accomplish is to randomly select 100 cases each
>>>> time it is run and bootstrap it 100 times.
>>>> It can?t be just only the first 100 cases of the 1269 rows. It can be
>>>> anywhere between the first row to 1269 row.
>>>> I think for now what I am asking help on is, is there a functional
>>>> code where I will randomly select 100 rows out of my total (1269)?
>>>> Where each time it is run, you get different df/DataSummary and
>>>> bootstrap sample.
>>>> I think i need to edit this to achieve my purpose of randomly
>>>> selecting 100 rows out of my total
>>>> |cols  <-  c('NAR','SQRTNAR','NIC','SQRTNIC')
>>>> data[,cols]  <-  lapply(data[,cols],as.numeric)  #to convert the variables into numeric values if not.
>>>> n_data  <-  data[(1:100),cols]|
>>>> I wanted to look at the trend if I increased the number of
>>>> bootstrapped samples (i.e.. 100, 200, 300, etc.) When i increased the
>>>> bootstrapped sample, the distribution got exponentially larger.
>>>> I thought that due to random sampling/bootstrapping you would get a
>>>> variation of scores.
>>>> I ran the df through the df through DataSummary and the bootstrap
>>>> results;  I compared them and they are identical results.
>>>> By the way, i kept getting errors when I did 100 bootstrap samples
>>>> and had 1269 rows. It said that the sample was too small.
>>>> Bryan Mac
>>>> bryanmac.24 at gmail.com <mailto:bryanmac.24 at gmail.com>
>>>> P.S. I am attaching an excel fie to show you what I mean. I
>>>> essentially randomly choose 100 cases out of total in the NAR column.
>>>> Once randomly selecting those 100 cases, bootstrap it 100 times.
>>>> Thats what I am looking to do.
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>> 


From dwinsemius at comcast.net  Wed Oct 19 17:31:48 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Oct 2016 08:31:48 -0700
Subject: [R] Error installing packages
In-Reply-To: <467607ff-45a2-cd8e-cc5c-ce69095cdca0@utoronto.ca>
References: <467607ff-45a2-cd8e-cc5c-ce69095cdca0@utoronto.ca>
Message-ID: <688D86A9-2295-4951-B96F-9C502FF69F29@comcast.net>


> On Oct 19, 2016, at 4:54 AM, Kevin E. Thorpe <kevin.thorpe at utoronto.ca> wrote:
> 
> Hello.
> 
> I am posting this on behalf of one of my students who is getting error messages when installing some packages. I have not seen this before nor have I been able to replicate it. I'm including the relevant (I think) information. I get the students to install rms with dependencies. As you can see, rms does get installed but when the attempt is made to attach it, ggplot2 cannot be loaded. Thus I tried explicitly installing ggplot2 and you can see then ensuing errors below. I have included the sessionInfo() at the end.
> 
> I hope someone can point me at a solution.
> 
> 
> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
> Copyright (C) 2016 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>  Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
> > install.packages("rms",dependencies=TRUE)
> Installing package into ?C:/Users/Leticia/Documents/R/win-library/3.3?
> (as ?lib? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/rms_4.5-0.zip'
> Content type 'application/zip' length 1074995 bytes (1.0 MB)
> downloaded 1.0 MB
> 
> package ?rms? successfully unpacked and MD5 sums checked
> 
> The downloaded binary packages are in
>        C:\Users\Leticia\AppData\Local\Temp\Rtmpa0q2o2\downloaded_packages
> > library(rms)
> Loading required package: Hmisc
> Loading required package: lattice
> Loading required package: survival
> Loading required package: Formula
> Loading required package: ggplot2
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :
>  there is no package called ?Rcpp?

When I try to debug the installation errors, I always first try to fix the first error. In this case it is because Rcpp was not installed. The use of dependencies=TRUE does not cause a recursive installation of dependencies of dependencies. I would have simply used:

install.packages('Rcpp", dependencies=TRUE)


> Error: package ?ggplot2? could not be loaded
> > install.packages("ggplot2",dependencies=TRUE)

That was not the problem.

> Installing package into ?C:/Users/Leticia/Documents/R/win-library/3.3?
> (as ?lib? is unspecified)
> also installing the dependency ?maptools?
> 
> trying URL 'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/maptools_0.8-39.zip'
> Content type 'application/zip' length 1816384 bytes (1.7 MB)
> downloaded 0 bytes
> 
> trying URL 'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/ggplot2_2.1.0.zip'
> Content type 'application/zip' length 1996146 bytes (1.9 MB)
> downloaded 4096 bytes
> 
> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>  cannot open the connection
> In addition: Warning messages:
> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>  downloaded length 0 != reported length 1816384
> 2: In download.file(url, destfile, method, mode = "wb", ...) :
>  downloaded length 4096 != reported length 1996146
> 3: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
> 4: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>  cannot open compressed file 'maptools/DESCRIPTION', probable reason 'No such file or directory'

The second error suggests a temporary difficulty in the download process. I'm guessing the user will not encounter it on a second attempt.


Best;
David.

> > library(rms)
> Loading required package: Hmisc
> Loading required package: ggplot2
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :
>  there is no package called ?Rcpp?
> Error: package ?ggplot2? could not be loaded
> > session.info()
> Error: could not find function "session.info"
> > sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 10586)
> 
> locale:
> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252 LC_MONETARY=English_Canada.1252
> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] Formula_1.2-1   survival_2.39-4 lattice_0.20-33
> 
> loaded via a namespace (and not attached):
> [1] Matrix_1.2-6  tools_3.3.1   gtable_0.2.0  splines_3.3.1 grid_3.3.1
> >
> 
> -- 
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's Hospital
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Wed Oct 19 17:44:34 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 19 Oct 2016 08:44:34 -0700
Subject: [R] create n suffixes of length 1:n from string of length n
In-Reply-To: <CAAjnpdh5uYa2XrLGZ5L54Bxu+UQ9az3w-ivHfB5f92vY47Fsvw@mail.gmail.com>
References: <CAAjnpdh5uYa2XrLGZ5L54Bxu+UQ9az3w-ivHfB5f92vY47Fsvw@mail.gmail.com>
Message-ID: <BB80809E-B933-4846-AE7C-4F0F9A088CAE@dcn.davis.ca.us>

These don't look like "suffixes" to me,  but whatever.

s <- "abc"
substr( rep( s, length(s) ), 1, seq.int( length(s) ) )

-- 
Sent from my phone. Please excuse my brevity.

On October 19, 2016 8:01:10 AM PDT, Witold E Wolski <wewolski at gmail.com> wrote:
>Is there a build in function, which creates n suffixes of length 1:n
>from string of length n?
>e.g given abcd
>
>produces
>"a"
>"ab"
>"abc"
>
>
>FAST.
>
>equally nice to have would be:
>
>e.g.
>given c("a", "b", "c")
>produces
>"a"
>"a","b"
>"a","b","c"
>
>Thank you
>Witold


From 1101011 at gmx.net  Wed Oct 19 17:47:14 2016
From: 1101011 at gmx.net (Mike meyer)
Date: Wed, 19 Oct 2016 17:47:14 +0200
Subject: [R] nls.lm
Message-ID: <trinity-f8b13a11-005a-4821-8fba-f9f5b44e00fa-1476892034643@3capp-gmx-bs28>

@SE: yes, not every system of equations with more variables than equations is solvable,
we need an additional condition e.g. full rank of the coefficient matrix.
Uniqueness of the solution was not required.

@BH:

Yes this is the document, it is a nice presentation.
I did not read the first page but note:

Minimizing a sum of squares f(x)=\sum_jf_j(x)^2
is a well defined problem regardless of the number of variables x_i (see f(x)=||x||?).

The condition m>=n really is nonsensical since it can be achieved in any number of ways such as
repeating each residual the same number of times etc. and therefore implies nothing.
What is m>=n supposed to ensure???
Surely not that the matrix Jf(x)'Jf(x) is nonsingular, where Jf denotes the Jacobian of f=(f_1,...,f_m).

Jf(x)'Jf(x) nonsingular, for all x, is a reasonable condition, m>=n is not.


From tgraves_cs at yahoo.com  Wed Oct 19 17:53:20 2016
From: tgraves_cs at yahoo.com (Tom Graves)
Date: Wed, 19 Oct 2016 15:53:20 +0000 (UTC)
Subject: [R] install R in relative path
In-Reply-To: <22535.12519.823865.163315@stat.math.ethz.ch>
References: <289312802.345844.1476824814057.ref@mail.yahoo.com>
	<289312802.345844.1476824814057@mail.yahoo.com>
	<22535.12519.823865.163315@stat.math.ethz.ch>
Message-ID: <1549128613.1022317.1476892400049@mail.yahoo.com>

Thanks. ?I will give this a try. ?I was doing the install step and trying to configure the relative path before.
Tom 

    On Wednesday, October 19, 2016 3:38 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
 

 >>>>> Tom Graves via R-help <r-help at r-project.org>
>>>>>? ? on Tue, 18 Oct 2016 21:06:54 +0000 writes:

? ? > Hello everyone, I am trying to figure out if I can install
? ? > R in a relative path?

Yes.? Even better you don't have to "install" it at all in the
strict sense.
Just *build* it and run it from the build directory.

If you use the source tarball 
currently,? R-3.3.1.tar.gz,? in 12 days will be R-3.2.2.tar.gz

Let's assume you'd want everything in your

 $HOME/R-inst/

Then you do

----------------------------------------------------

cd ~/R-inst
tar xfz <whereever>/R-3.3.1.tar.gz
? ? # now has created? R-3.3.1
? ? # we strongly recommend to use a *separate* build directory :
mkdir R-3.3.1-build
cd? R-3.3.1-build
../R-3.3.1/configure
make
[[elided Yahoo spam]]
make check-all??? 

----------------------------------------------------

Note that you do *NEVER* type? 'make install'? in the above setup

The only important remaining step is
make a symbolic link of? ? R-3.3.1-build/bin/R
to a directory part of your PATH.? If you are on a standard
unix/linux/(Mac?) setup :

? mkdir -p ~/bin
? cd ~/bin
? ln -s ~/R-inst/R-3.3.1-build/bin/R .

Alternatively, you could do

? export PATH=$HOME/R-inst/R-3.3.1-build/bin/R:$PATH

but I never do that.
Indeed, I use many R versions in this way, and in the above case
would use

? ln -s? ........../R-3.3.1-build/bin/R? R-3.3.1

and then have R-3.0.0, R-3.0.1, ..., R-3.2.5? R-3.3.0? R-3.3.1 
all in my PATH and all via symbolic links

(and ESS = Emacs Speaks Statistics finds all these
 automagically, so I can each start easily from within Emacs).

Martin Maechler
ETH Zurich

? ? > ?The reason I need to do this is to
? ? > send R along to a Hadoop cluster so that I can use sparkR
? ? > with the R version I shipped. The Hadoop cluster doesn't
? ? > have R installed and the admin won't install it.?? I tried
? ? > a few things but the things I had tried didn't work. Are
? ? > there any options to configure or PATHs I could use to do
? ? > this?? Any help is appreciated.? Thanks,Tom [[alternative
? ? > HTML version deleted]]

? ? > ______________________________________________
? ? > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
? ? > more, see https://stat.ethz.ch/mailman/listinfo/r-help
? ? > PLEASE do read the posting guide
? ? > http://www.R-project.org/posting-guide.html
? ? > and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From 1101011 at gmx.net  Wed Oct 19 18:04:10 2016
From: 1101011 at gmx.net (Mike meyer)
Date: Wed, 19 Oct 2016 18:04:10 +0200
Subject: [R] nls.lm
Message-ID: <trinity-37756513-a5b4-4108-bdcb-02ef32f210e3-1476893050161@3capp-gmx-bs28>

Make that f(x,u)=||x||?.


From 538280 at gmail.com  Wed Oct 19 18:19:24 2016
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 19 Oct 2016 10:19:24 -0600
Subject: [R] Split strings based on multiple patterns
In-Reply-To: <CAKq2vL6q2jQKwSZ54GxpccE641h8Oj65_Kxcg3VzDm0Nmsq80g@mail.gmail.com>
References: <CAKq2vL6q2jQKwSZ54GxpccE641h8Oj65_Kxcg3VzDm0Nmsq80g@mail.gmail.com>
Message-ID: <CAFEqCdwpL9j+3Zf2_x+JUkWv26A91f99mUTb3wozEze1TgT5LQ@mail.gmail.com>

I would suggest looking at the strapply function in the gsubfn
package.  That gives you more flexibility in specifying what to look
for in the structure of the data, then extract only those pieces that
you want.


On Fri, Oct 14, 2016 at 5:16 PM, Joe Ceradini <joeceradini at gmail.com> wrote:
> Afternoon,
>
> I unfortunately inherited a dataframe with a column that has many fields
> smashed together. My goal is to split the strings in the column into
> separate columns based on patterns.
>
> Example of what I'm working with:
>
> ugly <- c("Water temp:14: F Waterbody type:Permanent Lake/Pond: Water
> pH:Unkwn:
> Conductivity:Unkwn: Water color: Clear: Water turbidity: clear:
> Manmade:no  Permanence:permanent:  Max water depth: <3: Primary
> substrate: Silt/Mud: Evidence of cattle grazing: none:
> Shoreline Emergent Veg(%): 1-25: Fish present: yes: Fish species: unkwn: no
> amphibians observed")
> ugly
>
> Far as I can tell, there is not a single pattern that would work for
> splitting this string. Splitting on ":" is close but not quite consistent.
> Each of these attributes should be a separate column:
>
> attributes <- c("Water temp", "Waterbody type", "Water pH", "Conductivity",
> "Water color", "Water turbidity", "Manmade", "Permanence", "Max water
> depth", "Primary substrate", "Evidence of cattle grazing", "Shoreline
> Emergent Veg(%)", "Fish present", "Fish species")
>
> So, conceptually, I want to do something like this, where the string is
> split for each of the patterns in attributes. However, strsplit only uses
> the 1st value of attributes
> strsplit(ugly, attributes)
>
> Should I loop through the values of "attributes"?
> Is there an argument in strsplit I'm missing that will do what I want?
> Different approach altogether?
>
> Thanks! Happy Friday.
> Joe
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From joeceradini at gmail.com  Wed Oct 19 18:24:35 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Wed, 19 Oct 2016 10:24:35 -0600
Subject: [R] Split strings based on multiple patterns
In-Reply-To: <CAFEqCdwpL9j+3Zf2_x+JUkWv26A91f99mUTb3wozEze1TgT5LQ@mail.gmail.com>
References: <CAKq2vL6q2jQKwSZ54GxpccE641h8Oj65_Kxcg3VzDm0Nmsq80g@mail.gmail.com>
	<CAFEqCdwpL9j+3Zf2_x+JUkWv26A91f99mUTb3wozEze1TgT5LQ@mail.gmail.com>
Message-ID: <CAKq2vL489tj15QssFVN850eS0BHsHOcPSHp_95brz4NisBmyow@mail.gmail.com>

Thanks for the additional approach, Greg. I had success with Gabor's
recommendation but will take a look at gsubfn as well.

Joe

On Wed, Oct 19, 2016 at 10:19 AM, Greg Snow <538280 at gmail.com> wrote:

> I would suggest looking at the strapply function in the gsubfn
> package.  That gives you more flexibility in specifying what to look
> for in the structure of the data, then extract only those pieces that
> you want.
>
>
> On Fri, Oct 14, 2016 at 5:16 PM, Joe Ceradini <joeceradini at gmail.com>
> wrote:
> > Afternoon,
> >
> > I unfortunately inherited a dataframe with a column that has many fields
> > smashed together. My goal is to split the strings in the column into
> > separate columns based on patterns.
> >
> > Example of what I'm working with:
> >
> > ugly <- c("Water temp:14: F Waterbody type:Permanent Lake/Pond: Water
> > pH:Unkwn:
> > Conductivity:Unkwn: Water color: Clear: Water turbidity: clear:
> > Manmade:no  Permanence:permanent:  Max water depth: <3: Primary
> > substrate: Silt/Mud: Evidence of cattle grazing: none:
> > Shoreline Emergent Veg(%): 1-25: Fish present: yes: Fish species: unkwn:
> no
> > amphibians observed")
> > ugly
> >
> > Far as I can tell, there is not a single pattern that would work for
> > splitting this string. Splitting on ":" is close but not quite
> consistent.
> > Each of these attributes should be a separate column:
> >
> > attributes <- c("Water temp", "Waterbody type", "Water pH",
> "Conductivity",
> > "Water color", "Water turbidity", "Manmade", "Permanence", "Max water
> > depth", "Primary substrate", "Evidence of cattle grazing", "Shoreline
> > Emergent Veg(%)", "Fish present", "Fish species")
> >
> > So, conceptually, I want to do something like this, where the string is
> > split for each of the patterns in attributes. However, strsplit only uses
> > the 1st value of attributes
> > strsplit(ugly, attributes)
> >
> > Should I loop through the values of "attributes"?
> > Is there an argument in strsplit I'm missing that will do what I want?
> > Different approach altogether?
> >
> > Thanks! Happy Friday.
> > Joe
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>



-- 
Cooperative Fish and Wildlife Research Unit
Zoology and Physiology Dept.
University of Wyoming
JoeCeradini at gmail.com / 914.707.8506
wyocoopunit.org

	[[alternative HTML version deleted]]


From profjcnash at gmail.com  Wed Oct 19 18:28:46 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Wed, 19 Oct 2016 12:28:46 -0400
Subject: [R] nls.lm
In-Reply-To: <4E857925-A5AF-42E8-BEED-47FF16B4BA6B@xs4all.nl>
References: <trinity-f1301bb3-f544-4193-a8f2-0134a79dfeed-1476878991595@3capp-gmx-bs58>
	<4E857925-A5AF-42E8-BEED-47FF16B4BA6B@xs4all.nl>
Message-ID: <a3bdd4b4-63fb-f1e1-8697-25050c4ad31b@gmail.com>

I sometimes find it useful to use nonlinear least squares for fitting an approximation i.e., zero
residual model. That could be underdetermined.

Does adding the set of residuals that is the parameters force a minimum length solution? If the
equations are inconsistent, then the residuals apart from the parameters would, I believe, be
non-zero. Of course, if they turn out non-zero, it doesn't mean there is no solution -- the method
may have failed, but if they are zero, we have constructed a solution.

While I've used this approach, I'm thinking that it deserves closer examination and testing.

Best, JN


On 16-10-19 11:28 AM, Berend Hasselman wrote:
> 
>> On 19 Oct 2016, at 14:09, Mike meyer <1101011 at gmx.net> wrote:
>>
>> @pd: you know that a System of equations with more variables than equations is always solvable
>> and if a unique solution is desired one of mimimal norm can be used.
>>
> 
> Not true.
> 
> Take the system with 3 variables and 2 equations
> 
> x+y+z = 3
> x+y+z = 4
> 
> This does not have a solution.
> See https://en.wikipedia.org/wiki/Consistent_and_inconsistent_equations
> 
> Berend
> 
>> According to "Methods for nonlinear least squares problems" by Madsen, Nielsen and Tingleff the LM-algorithm
>> solves Systems of the form 
>>                            [J(x)'J(x)+\mu*I]x=...
>> with \mu>0 so that the Matrix on the left is always positive definite, especially nonsingular.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Wed Oct 19 18:36:25 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Oct 2016 09:36:25 -0700
Subject: [R] create n suffixes of length 1:n from string of length n
In-Reply-To: <BB80809E-B933-4846-AE7C-4F0F9A088CAE@dcn.davis.ca.us>
References: <CAAjnpdh5uYa2XrLGZ5L54Bxu+UQ9az3w-ivHfB5f92vY47Fsvw@mail.gmail.com>
	<BB80809E-B933-4846-AE7C-4F0F9A088CAE@dcn.davis.ca.us>
Message-ID: <C76CE177-2820-49DF-B615-618678ACF201@comcast.net>


> On Oct 19, 2016, at 8:44 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> These don't look like "suffixes" to me,  but whatever.
> 
> s <- "abc"
> substr( rep( s, length(s) ), 1, seq.int( length(s) ) )

I suspect that `nchar` was meant instead of `length` but it still failed. How about:

lets <- paste0(letters,collapse=TRUE)
unname( mapply( substr, lets, 1, 1:26) )  # mapply will recycle 

-- 
David.

> 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On October 19, 2016 8:01:10 AM PDT, Witold E Wolski <wewolski at gmail.com> wrote:
>> Is there a build in function, which creates n suffixes of length 1:n
>> from string of length n?
>> e.g given abcd
>> 
>> produces
>> "a"
>> "ab"
>> "abc"
>> 
>> 
>> FAST.
>> 
>> equally nice to have would be:
>> 
>> e.g.
>> given c("a", "b", "c")
>> produces
>> "a"
>> "a","b"
>> "a","b","c"
>> 
>> Thank you
>> Witold
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Wed Oct 19 18:41:10 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 19 Oct 2016 09:41:10 -0700
Subject: [R] create n suffixes of length 1:n from string of length n
In-Reply-To: <C76CE177-2820-49DF-B615-618678ACF201@comcast.net>
References: <CAAjnpdh5uYa2XrLGZ5L54Bxu+UQ9az3w-ivHfB5f92vY47Fsvw@mail.gmail.com>
	<BB80809E-B933-4846-AE7C-4F0F9A088CAE@dcn.davis.ca.us>
	<C76CE177-2820-49DF-B615-618678ACF201@comcast.net>
Message-ID: <1EF96A6D-27A2-4EC9-9E22-2FC39CB0765E@dcn.davis.ca.us>

When I replace length with nchar, it works fine for me without mapply.

substr( rep( s, nchar(s) ), 1, seq.int( nchar(s) ) )
-- 
Sent from my phone. Please excuse my brevity.

On October 19, 2016 9:36:25 AM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Oct 19, 2016, at 8:44 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> 
>> These don't look like "suffixes" to me,  but whatever.
>> 
>> s <- "abc"
>> substr( rep( s, length(s) ), 1, seq.int( length(s) ) )
>
>I suspect that `nchar` was meant instead of `length` but it still
>failed. How about:
>
>lets <- paste0(letters,collapse=TRUE)
>unname( mapply( substr, lets, 1, 1:26) )  # mapply will recycle


From rmh at temple.edu  Wed Oct 19 18:45:43 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 19 Oct 2016 12:45:43 -0400
Subject: [R] Error installing packages
In-Reply-To: <688D86A9-2295-4951-B96F-9C502FF69F29@comcast.net>
References: <467607ff-45a2-cd8e-cc5c-ce69095cdca0@utoronto.ca>
	<688D86A9-2295-4951-B96F-9C502FF69F29@comcast.net>
Message-ID: <CAGx1TMAofiGx6d5r_Cqrw+LCk8Bs-+kRYCMfzN68CQv72KzycQ@mail.gmail.com>

I run into this type of problem quite frequently on Windows.
I see no rhyme or reason for when it happens.
It seems random as to which package it can't move.

The problem is at least a year old, and bit one of my students yesterday.

The specific is that there is a problem with copying from a temporary location

package ?Rcpp? successfully unpacked and MD5 sums checked
Warning: unable to move temporary installation
?C:\Users\userid\Documents\R\win-library\3.3\file2bb4515e370d\Rcpp? to
?C:\Users\userid\Documents\R\win-library\3.3\Rcpp?

It isn't always Rcpp, although I think that is one of the more
frequently observed packages to display the problem.

Then there is a secondary problem that catches the attention of the
student.  Some other package that depends
on the missing one won't load.

I have three fixes:

1.  This usually works.  just do another
install.packages("Rcpp")

2.  This usually works when the first one doesn't

Keeping R open, manually move (with two Window Explorer windows) Rcpp from
C:\Users\userid\Documents\R\win-library\3.3\file2bb4515e370d\Rcpp
to
C:\Users\userid\Documents\R\win-library\3.3\Rcpp


3.  This is rarely needed because the first two usually work.
Copy the entire directory
C:\Users\userid\Documents\R\win-library\3.3\Rcpp
from one Windows computer onto a memory stick, and then
copy it from the memory stick to the other Windows computer.
It must be from Windows to Windows.  Method 3 will not work from Mac to Windows.

On Wed, Oct 19, 2016 at 11:31 AM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
>> On Oct 19, 2016, at 4:54 AM, Kevin E. Thorpe <kevin.thorpe at utoronto.ca> wrote:
>>
>> Hello.
>>
>> I am posting this on behalf of one of my students who is getting error messages when installing some packages. I have not seen this before nor have I been able to replicate it. I'm including the relevant (I think) information. I get the students to install rms with dependencies. As you can see, rms does get installed but when the attempt is made to attach it, ggplot2 cannot be loaded. Thus I tried explicitly installing ggplot2 and you can see then ensuing errors below. I have included the sessionInfo() at the end.
>>
>> I hope someone can point me at a solution.
>>
>>
>> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
>> Copyright (C) 2016 The R Foundation for Statistical Computing
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>>  Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> > install.packages("rms",dependencies=TRUE)
>> Installing package into ?C:/Users/Leticia/Documents/R/win-library/3.3?
>> (as ?lib? is unspecified)
>> --- Please select a CRAN mirror for use in this session ---
>> trying URL 'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/rms_4.5-0.zip'
>> Content type 'application/zip' length 1074995 bytes (1.0 MB)
>> downloaded 1.0 MB
>>
>> package ?rms? successfully unpacked and MD5 sums checked
>>
>> The downloaded binary packages are in
>>        C:\Users\Leticia\AppData\Local\Temp\Rtmpa0q2o2\downloaded_packages
>> > library(rms)
>> Loading required package: Hmisc
>> Loading required package: lattice
>> Loading required package: survival
>> Loading required package: Formula
>> Loading required package: ggplot2
>> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :
>>  there is no package called ?Rcpp?
>
> When I try to debug the installation errors, I always first try to fix the first error. In this case it is because Rcpp was not installed. The use of dependencies=TRUE does not cause a recursive installation of dependencies of dependencies. I would have simply used:
>
> install.packages('Rcpp", dependencies=TRUE)
>
>
>> Error: package ?ggplot2? could not be loaded
>> > install.packages("ggplot2",dependencies=TRUE)
>
> That was not the problem.
>
>> Installing package into ?C:/Users/Leticia/Documents/R/win-library/3.3?
>> (as ?lib? is unspecified)
>> also installing the dependency ?maptools?
>>
>> trying URL 'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/maptools_0.8-39.zip'
>> Content type 'application/zip' length 1816384 bytes (1.7 MB)
>> downloaded 0 bytes
>>
>> trying URL 'http://cran.utstat.utoronto.ca/bin/windows/contrib/3.3/ggplot2_2.1.0.zip'
>> Content type 'application/zip' length 1996146 bytes (1.9 MB)
>> downloaded 4096 bytes
>>
>> Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>  cannot open the connection
>> In addition: Warning messages:
>> 1: In download.file(url, destfile, method, mode = "wb", ...) :
>>  downloaded length 0 != reported length 1816384
>> 2: In download.file(url, destfile, method, mode = "wb", ...) :
>>  downloaded length 4096 != reported length 1996146
>> 3: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
>> 4: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
>>  cannot open compressed file 'maptools/DESCRIPTION', probable reason 'No such file or directory'
>
> The second error suggests a temporary difficulty in the download process. I'm guessing the user will not encounter it on a second attempt.
>
>
> Best;
> David.
>
>> > library(rms)
>> Loading required package: Hmisc
>> Loading required package: ggplot2
>> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :
>>  there is no package called ?Rcpp?
>> Error: package ?ggplot2? could not be loaded
>> > session.info()
>> Error: could not find function "session.info"
>> > sessionInfo()
>> R version 3.3.1 (2016-06-21)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 10586)
>>
>> locale:
>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252 LC_MONETARY=English_Canada.1252
>> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] Formula_1.2-1   survival_2.39-4 lattice_0.20-33
>>
>> loaded via a namespace (and not attached):
>> [1] Matrix_1.2-6  tools_3.3.1   gtable_0.2.0  splines_3.3.1 grid_3.3.1
>> >
>>
>> --
>> Kevin E. Thorpe
>> Head of Biostatistics,  Applied Health Research Centre (AHRC)
>> Li Ka Shing Knowledge Institute of St. Michael's Hospital
>> Assistant Professor, Dalla Lana School of Public Health
>> University of Toronto
>> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Oct 19 18:45:51 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Oct 2016 09:45:51 -0700
Subject: [R] create n suffixes of length 1:n from string of length n
In-Reply-To: <1EF96A6D-27A2-4EC9-9E22-2FC39CB0765E@dcn.davis.ca.us>
References: <CAAjnpdh5uYa2XrLGZ5L54Bxu+UQ9az3w-ivHfB5f92vY47Fsvw@mail.gmail.com>
	<BB80809E-B933-4846-AE7C-4F0F9A088CAE@dcn.davis.ca.us>
	<C76CE177-2820-49DF-B615-618678ACF201@comcast.net>
	<1EF96A6D-27A2-4EC9-9E22-2FC39CB0765E@dcn.davis.ca.us>
Message-ID: <7C6E5CBD-06D1-44F8-9B90-5650C39EE5D1@comcast.net>


> On Oct 19, 2016, at 9:41 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> When I replace length with nchar, it works fine for me without mapply.
> 
> substr( rep( s, nchar(s) ), 1, seq.int( nchar(s) ) )

I failed to make the second `nchar` -> `length` substitution. It now works for me as well.

-- 
David

> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On October 19, 2016 9:36:25 AM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Oct 19, 2016, at 8:44 AM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us> wrote:
>>> 
>>> These don't look like "suffixes" to me,  but whatever.
>>> 
>>> s <- "abc"
>>> substr( rep( s, length(s) ), 1, seq.int( length(s) ) )
>> 
>> I suspect that `nchar` was meant instead of `length` but it still
>> failed. How about:
>> 
>> lets <- paste0(letters,collapse=TRUE)
>> unname( mapply( substr, lets, 1, 1:26) )  # mapply will recycle 
> 

David Winsemius
Alameda, CA, USA


From frank.black.1988 at gmail.com  Wed Oct 19 19:05:13 2016
From: frank.black.1988 at gmail.com (Frank Black)
Date: Wed, 19 Oct 2016 19:05:13 +0200
Subject: [R] Confidence interval on quantile regression (quantreg)
Message-ID: <CAP0QN_YYMjS9Z=ny-pC_z2uxWW-1p3z_gmAnbPJ-1hEavQxnsA@mail.gmail.com>

Hi all,

I am using the quantile regression package for estimating some models.
However, in some cases the intervals' upper bounds are either abnormally
high or low, with values such as -1.797693e+308 or 1.797693e+308. Actually,
the number is the same in absolute terms.

Does anyone know a reasonable explanation for this?

Thanks.

Kind regards,
Frank

	[[alternative HTML version deleted]]


From 1101011 at gmx.net  Wed Oct 19 19:12:34 2016
From: 1101011 at gmx.net (Mike meyer)
Date: Wed, 19 Oct 2016 19:12:34 +0200
Subject: [R] nls.lm
Message-ID: <trinity-dbe6a003-095b-4c81-b8ac-4d0e1f5e18b6-1476897154458@3capp-gmx-bs28>

>From my reading of the above cited document I get the impression that the algorithm
(algorithm 3.16, p27) can easily be adapted to handle the case m<n.
In this case the Jacobian Jf(x) is mxn and the matrix A(x)=Jf(x)'Jf(x) is nxn and rank deficient.

This seems to be a problem since the search direction h at iterate x is computed from
       (A(x)+mu*I)h=-J(x)'f(x)
where mu -> 0 and so the system becomes ill conditioned.

Why can we not get around this as follows: as soon as mu is below some threshold
we solve instead the seemingly worse A(x)h=-J(x)'f(x) which however is of the form

      J(x)'J(x)h=-J(x)'f(x)

and can be solved by solving J(x)h=-f(x) and the condition for this to be solvable
is that J(x) have full rank. In fact this is the Gauss-Newton step
and to switch to that in the case of small mu is exactly in keeping with the idea of the
LM-algorithm.

If h is _any_ solution we have h'F'(x)=-||J(x)h||?<=0 (document, p21, eq(3.10))
and is a descent direction if this is in fact < 0.
If it is equal to zero, then f(x)=J(x)h=0 and we have a global minimum at x. 


From pdalgd at gmail.com  Wed Oct 19 19:18:40 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 19 Oct 2016 19:18:40 +0200
Subject: [R] nls.lm
In-Reply-To: <trinity-f8b13a11-005a-4821-8fba-f9f5b44e00fa-1476892034643@3capp-gmx-bs28>
References: <trinity-f8b13a11-005a-4821-8fba-f9f5b44e00fa-1476892034643@3capp-gmx-bs28>
Message-ID: <A08D19F7-CFF9-4D16-AD78-D93D4746F1AC@gmail.com>


> On 19 Oct 2016, at 17:47 , Mike meyer <1101011 at gmx.net> wrote:
> Jf(x)'Jf(x) nonsingular, for all x, is a reasonable condition, m>=n is not.

If Jf(x) has more columns than rows, then Jf(x)'Jf(x) is certainly singular. The reverse is not true, but what's wrong with a simple pre-check? 

What you possibly _could_ argue is that you want a (non-unique) solution even in the singular case. Presumably, that could give you the correct minimum sum of squares, the rank, and a degenerate variance-covariance matrix of the estimated coefficients. That could be useful, either if you just want the minimum or if you need to see the cov. matrix in order to see which parameters are unidentifiable.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From 1101011 at gmx.net  Wed Oct 19 19:20:41 2016
From: 1101011 at gmx.net (Mike meyer)
Date: Wed, 19 Oct 2016 19:20:41 +0200
Subject: [R] nls.lm
Message-ID: <trinity-a2e789d9-2f14-4d31-832b-aac3ef7c0d13-1476897641751@3capp-gmx-bs28>

And finally, to put to rest the notion that the number of residuals is in any way significant for the
solution of the least squares problem I submit to you the function

f(x,y)=(x?+y?)?

of 2 variables but only one residual f_1(x,y)=x?+y? which nonetheless has a unique minimum
at the point (0,0).


From rshepard at appl-ecosys.com  Wed Oct 19 19:48:41 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 19 Oct 2016 10:48:41 -0700 (PDT)
Subject: [R] Lattice xyplot(): adding a legend
Message-ID: <alpine.LNX.2.11.1610191038100.8962@localhost>

   After reading ?xyplot and pages 161-162 in Deepayan's book I'm still not
getting the syntax correct to add a legend to a scatterplot. The data are
attached as filename rain.dput.

   Without the legend (and testing interactively) the data plot but not the
legend. Sourcing the script opens the display but neither data nor legend
appear. I know that I'll need to adjust the legend's position so it fits in
the empty space at the top, left center, but I need to see where it is
first.

   I tried adding the legend to the xyplot() command with no difference in
the results.

   In both cases R displays this error:

source("plot-rain-by-day.R")
Error in as.graphicsAnnot(legend) (from plot-rain-by-day.R#16) :
   argument "legend" is missing, with no default

   I've not found an example to follow so pointers to how to add the legend
are needed.

   The script:

# This scatter plot has rain amounts by day for each station, distinguished by color.

# load rain data file
rain

# Create a factor from the date
raindate <- as.factor(rain$date)

# Save original plotting parameters
opar <- par(xpd=NA,no.readonly=T)

# Prepare the plot of the data
rainbyday <- xyplot(rain$amount ~ raindate, main="Area Precipitation", ylab="Daily Total Amount (in)", xlab="Date", scales=list(x=list(at=c(1,8,15,22,29,36,43,50,57,62), rot=90)), pch=as.numeric(rain$station), col=c("black","red","dark green","dark blue","dark goldenrod","dark goldenrod"))

# Add a legend
legend(x=0.83, y=-1.65, pch=as.numeric(rainbyday), col=c("black","red","dark green","dark blue","dark goldenrod","dark goldenrod"))

# Plot it
plot(rainbyday)

# Reset display parameters
par(opar)

TIA,

Rich
-------------- next part --------------
structure(list(station = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L), .Label = c("0.3E", 
"0.6W", "1.0WNW", "1.5N", "4.3WNW", "Airport"), class = "factor"), 
    date = structure(c(16071, 16072, 16073, 16074, 16075, 16076, 
    16077, 16078, 16079, 16080, 16081, 16082, 16083, 16084, 16085, 
    16086, 16087, 16088, 16089, 16090, 16091, 16092, 16093, 16094, 
    16095, 16096, 16097, 16098, 16099, 16100, 16101, 16040, 16041, 
    16042, 16043, 16044, 16045, 16046, 16047, 16048, 16049, 16050, 
    16051, 16052, 16053, 16054, 16055, 16056, 16057, 16058, 16059, 
    16060, 16061, 16062, 16063, 16064, 16065, 16066, 16067, 16068, 
    16069, 16070, 16071, 16072, 16073, 16074, 16075, 16076, 16077, 
    16078, 16079, 16080, 16081, 16082, 16083, 16084, 16085, 16086, 
    16087, 16088, 16089, 16090, 16091, 16092, 16093, 16094, 16095, 
    16096, 16097, 16098, 16099, 16100, 16101, 16040, 16041, 16042, 
    16043, 16044, 16045, 16046, 16047, 16048, 16049, 16050, 16051, 
    16052, 16053, 16054, 16055, 16056, 16057, 16058, 16059, 16060, 
    16061, 16062, 16063, 16064, 16065, 16066, 16067, 16068, 16069, 
    16070, 16071, 16072, 16073, 16074, 16075, 16076, 16077, 16078, 
    16079, 16080, 16081, 16082, 16083, 16084, 16085, 16086, 16087, 
    16088, 16089, 16090, 16091, 16092, 16093, 16094, 16095, 16096, 
    16097, 16098, 16099, 16100, 16101, 16040, 16041, 16042, 16043, 
    16044, 16045, 16046, 16047, 16048, 16049, 16050, 16051, 16052, 
    16053, 16054, 16055, 16056, 16057, 16058, 16059, 16060, 16061, 
    16062, 16063, 16064, 16065, 16066, 16067, 16068, 16069, 16070, 
    16071, 16072, 16073, 16074, 16075, 16076, 16077, 16078, 16079, 
    16080, 16081, 16082, 16083, 16084, 16085, 16086, 16087, 16088, 
    16089, 16090, 16091, 16092, 16093, 16094, 16095, 16096, 16097, 
    16098, 16099, 16100, 16101, 16040, 16041, 16042, 16043, 16044, 
    16045, 16046, 16047, 16048, 16049, 16050, 16051, 16052, 16053, 
    16054, 16055, 16056, 16057, 16058, 16059, 16060, 16061, 16062, 
    16063, 16064, 16065, 16066, 16067, 16068, 16069, 16070, 16071, 
    16072, 16073, 16074, 16075, 16076, 16077, 16078, 16079, 16080, 
    16081, 16082, 16083, 16084, 16085, 16086, 16087, 16088, 16089, 
    16090, 16091, 16092, 16093, 16094, 16095, 16096, 16097, 16098, 
    16099, 16100, 16101, 16040, 16041, 16042, 16043, 16044, 16045, 
    16046, 16047, 16048, 16049, 16050, 16051, 16052, 16053, 16054, 
    16055, 16056, 16057, 16058, 16059, 16060, 16061, 16062, 16063, 
    16064, 16065, 16066, 16067, 16068, 16069, 16070, 16071, 16072, 
    16073, 16074, 16075, 16076, 16077, 16078, 16079, 16080, 16081, 
    16082, 16083, 16084, 16085, 16086, 16087, 16088, 16089, 16090, 
    16091, 16092, 16093, 16094, 16095, 16096, 16097, 16098, 16099, 
    16100, 16101), class = "Date"), amount = c(NA, NA, 0.01, 
    0, 0, 0, 0.1, 0.22, 0.49, 0.12, 0.47, 0.7, 0.24, 0.01, 0.01, 
    0.01, 0.01, 0.01, 0.01, 0, 0, 0.01, NA, 0, 0, 0, NA, 0.07, 
    0.48, 0.03, NA, 0.32, 0.92, 0.04, NA, 0, 0.01, 0.01, 0, 0, 
    NA, 0, 0, 0.08, 0.01, 0.02, 0.01, 0.01, NA, 0.09, 0.02, 0.13, 
    0.01, NA, 0.02, 0.01, 0.01, NA, NA, NA, 0, 0.04, 0.02, 0.01, 
    0.02, 0.01, NA, 0, 0.11, 0.24, 0.54, 0.15, 0.48, 0.02, 0.01, 
    NA, 0.01, NA, NA, 0, 0, 0, 0, 0, 0, 0.06, 0.48, 0.03, 0.03, 
    NA, NA, NA, NA, 0.05, 0, 0, 0.01, 0, 0, 0, 0, 0, NA, 0.07, 
    0, 0.01, 0.02, 0.01, 0.01, 0.1, 0.01, 0.01, 0, 0, 0.04, 0.01, 
    NA, 0, 0.01, 0.01, 0, 0.05, NA, NA, 0.01, 0.01, 0.02, 0, 
    0, 0, 0.11, 0.22, 0.54, 0.54, 0.44, 0.71, 0.21, 0.01, 0.02, 
    0.01, 0.01, 0.01, 0.01, 0, 0, 0, 0, 0, 0, 0, 0, 0.06, 0.46, 
    0.02, 0.02, 0.87, 0.1, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0.07, 
    0.01, 0.01, 0.02, 0, 0, 0.07, 0, 0.1, NA, NA, 0.02, NA, 0, 
    0, 0, 0, 0, NA, 0.05, 0, 0.01, 0.01, 0, 0, 0.05, 0.27, 0.42, 
    0.06, 0.01, 0.9, 0.36, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
    0, 0, 0.06, 0.36, 0.12, 0.01, 0.05, 0.25, 0.91, 0.03, 0, 
    0, NA, 0, 0, 0, 0, 0, 0, 0.07, NA, 0.01, 0.01, 0.01, NA, 
    0.09, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0.01, 
    0.01, 0.01, 0, 0, 0, 0.11, 0.23, 0.49, 0.1, 0.45, 0.6, 0.28, 
    0, 0.01, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06, 0.48, 
    0.02, 0.02, 0.4, 1.06, 0.13, 0, 0, 0.03, 0.01, 0, 0, 0, 0, 
    0, 0.12, 0.02, NA, NA, NA, NA, NA, 0.03, 0.24, 0.02, 0.02, 
    0.05, 0.01, 0, NA, 0, 0.02, 0, 0.01, 0.04, 0.02, 0.04, 0.01, 
    NA, 0, 0.13, 0.34, 0.84, 0.61, 0.61, 1, 0.44, 0.02, 0.02, 
    0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.01, NA, 0, 0, 
    0, 0.07, 0.62, 0.1, 0.05)), .Names = c("station", "date", 
"amount"), row.names = c(NA, -341L), class = "data.frame")

From bhh at xs4all.nl  Wed Oct 19 19:51:59 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 19 Oct 2016 19:51:59 +0200
Subject: [R] nls.lm
In-Reply-To: <trinity-dbe6a003-095b-4c81-b8ac-4d0e1f5e18b6-1476897154458@3capp-gmx-bs28>
References: <trinity-dbe6a003-095b-4c81-b8ac-4d0e1f5e18b6-1476897154458@3capp-gmx-bs28>
Message-ID: <31A768F7-DCFD-48B0-9452-7E66D2ED4475@xs4all.nl>


> On 19 Oct 2016, at 19:12, Mike meyer <1101011 at gmx.net> wrote:
> 
>> From my reading of the above cited document I get the impression that the algorithm
> (algorithm 3.16, p27) can easily be adapted to handle the case m<n.
> In this case the Jacobian Jf(x) is mxn and the matrix A(x)=Jf(x)'Jf(x) is nxn and rank deficient.
> 
> This seems to be a problem since the search direction h at iterate x is computed from
>       (A(x)+mu*I)h=-J(x)'f(x)
> where mu -> 0 and so the system becomes ill conditioned.
> 
> Why can we not get around this as follows: as soon as mu is below some threshold
> we solve instead the seemingly worse A(x)h=-J(x)'f(x) which however is of the form
> 
>      J(x)'J(x)h=-J(x)'f(x)
> 
> and can be solved by solving J(x)h=-f(x) and the condition for this to be solvable
> is that J(x) have full rank. In fact this is the Gauss-Newton step



Oh?

You are solving a system

Ax=b where A is a matrix mxn with m<n with full rank (m).

Let Aplus be the generalized inverse of A.
Let z <- runif(nrow(Aplus))

The general solution of that linear system is   Aplus %*% b + (diag(nrow(Aplus)) - Aplus %*% A) %*% z
where the minimum norm solution is  Aplus %*% b.

Since z is any random vector there are many solutions.
So which one is the Gauss-Newton step?
 
Berend

> and to switch to that in the case of small mu is exactly in keeping with the idea of the
> LM-algorithm.
> 
> If h is _any_ solution we have h'F'(x)=-||J(x)h||?<=0 (document, p21, eq(3.10))
> and is a descent direction if this is in fact < 0.
> If it is equal to zero, then f(x)=J(x)h=0 and we have a global minimum at x. 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ccberry at ucsd.edu  Wed Oct 19 20:32:02 2016
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Wed, 19 Oct 2016 11:32:02 -0700
Subject: [R] Escaping quotes WAS: Storing long string with white space in
 variable
In-Reply-To: <OFC27CD8DE.0D3F3BE7-ONC1258051.00410308-C1258051.0041BB91@lotus.hawesko.de>
References: <OFC27CD8DE.0D3F3BE7-ONC1258051.00410308-C1258051.0041BB91@lotus.hawesko.de>
Message-ID: <alpine.OSX.2.20.1610191112360.665@charlessmacbook.dynamic.ucsd.edu>

On Wed, 19 Oct 2016, G.Maubach at weinwolf.de wrote:

> Hi All,
>
> I would like to store a long string with white space in a variable:
>
> -- cut --
>  # Create README.md
>  readme <- "---
> title: "Your project title here"
> author: "Author(s) name(s) here"
> date: "Current date here"
> output: html_document
> ---

[snip]

> "
> cat(readme, file = "README.md")
>
> -- cut --
>
> I am looking for an equivalent to Pythons """  """ long string feature.


Whitespace isn;t the issue here. Embedded quotes are the problem.

See

 	?Quotes

In this case, if your replace the first and last double quotes with single 
quotes, you will get a single string of 464 characters, which is what you 
want.

In other cases where you have embedded single quotes, you can escape them 
and the double quotes and get what you want.

[snip]

> PS: This is a template for a project folder for each project. I would like
> to create it with R script instead of distributing it as a template file.
> This way one needs only the R script to setup a project like this:
>

[rest deleted]

There are templating procedures available. Package brew might be worth a 
look. It can take a template string with embedded R code and return 
a string with the R results spliced in. Package knitr has some ability to 
deal with templates, too, and I think there are other packages.

Jeff Newmiller's suggestion to make a package seems right to me whether 
you use brew or not. Long term it will probably be the easiest path.

HTH,

Chuck


From 1101011 at gmx.net  Wed Oct 19 21:16:23 2016
From: 1101011 at gmx.net (Mike meyer)
Date: Wed, 19 Oct 2016 21:16:23 +0200
Subject: [R] nls.lm
Message-ID: <trinity-6990f702-31a2-4ab3-9d04-dfb58a40f5a6-1476904583462@3capp-gmx-bs28>

How do you reply to a specific post on this board instead of the thread?
I am too incompetent to find this out myself.

Thanks,

Michael
unaffiliated


From dwinsemius at comcast.net  Wed Oct 19 21:20:16 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Oct 2016 12:20:16 -0700
Subject: [R] Lattice xyplot(): adding a legend
In-Reply-To: <alpine.LNX.2.11.1610191038100.8962@localhost>
References: <alpine.LNX.2.11.1610191038100.8962@localhost>
Message-ID: <0DA29E48-DEA2-4C47-AEA5-F0331EF2B58E@comcast.net>


> On Oct 19, 2016, at 10:48 AM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  After reading ?xyplot and pages 161-162 in Deepayan's book I'm still not
> getting the syntax correct to add a legend to a scatterplot. The data are
> attached as filename rain.dput.
> 
>  Without the legend (and testing interactively) the data plot but not the
> legend. Sourcing the script opens the display but neither data nor legend
> appear. I know that I'll need to adjust the legend's position so it fits in
> the empty space at the top, left center, but I need to see where it is
> first.
> 
>  I tried adding the legend to the xyplot() command with no difference in
> the results.
> 
>  In both cases R displays this error:
> 
> source("plot-rain-by-day.R")
> Error in as.graphicsAnnot(legend) (from plot-rain-by-day.R#16) :
>  argument "legend" is missing, with no default
> 
>  I've not found an example to follow so pointers to how to add the legend
> are needed.


> 
>  The script:
> 
> # This scatter plot has rain amounts by day for each station, distinguished by color.
> 
> # load rain data file
> rain
> 
> # Create a factor from the date
> raindate <- as.factor(rain$date)
> 
> # Save original plotting parameters
> opar <- par(xpd=NA,no.readonly=T)
> 
> # Prepare the plot of the data
> rainbyday <- xyplot(rain$amount ~ raindate, main="Area Precipitation", ylab="Daily Total Amount (in)", xlab="Date", scales=list(x=list(at=c(1,8,15,22,29,36,43,50,57,62), rot=90)), pch=as.numeric(rain$station), col=c("black","red","dark green","dark blue","dark goldenrod","dark goldenrod"))
> 
> # Add a legend
> legend(x=0.83, y=-1.65, pch=as.numeric(rainbyday), col=c("black","red","dark green","dark blue","dark goldenrod","dark goldenrod"))


The `legend` function is used with base graphics plotting (as is the par function). I think you might first read ?Lattice since it makes reference to the fact that you can update trellis structures after they have been created.  The commands to add "legend" features to lattice plots are found under the argument items with names "key". Search in ?xyplot for the strings 'legend' and 'key'. It would probably be easier to incorporate these in a new plot call. There are several examples (well, four anyway)  at the ?xyplot page. Since you mentioned having Sarkar's book, the place to look for more examples is chapter 9 "Labels and Legends".


> # Plot it
> plot(rainbyday)
> 
> # Reset display parameters
> par(opar)
> 
> TIA,
> 
> Rich<rain.dput>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Oct 19 21:23:12 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Oct 2016 12:23:12 -0700
Subject: [R] nls.lm
In-Reply-To: <trinity-6990f702-31a2-4ab3-9d04-dfb58a40f5a6-1476904583462@3capp-gmx-bs28>
References: <trinity-6990f702-31a2-4ab3-9d04-dfb58a40f5a6-1476904583462@3capp-gmx-bs28>
Message-ID: <02EBD37D-92F1-4872-A273-5EB84FD572D6@comcast.net>


> On Oct 19, 2016, at 12:16 PM, Mike meyer <1101011 at gmx.net> wrote:
> 
> How do you reply to a specific post on this board instead of the thread?
> I am too incompetent to find this out myself.

Most of us use a mail-client that supports 'reply-to-all'. And the Posting Guide asks you to include sufficient context which you have been consistently failing to do.

-- 
David.
> 
> Thanks,
> 
> Michael
> unaffiliated
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rshepard at appl-ecosys.com  Wed Oct 19 21:48:01 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 19 Oct 2016 12:48:01 -0700 (PDT)
Subject: [R] Lattice xyplot(): adding a legend
In-Reply-To: <0DA29E48-DEA2-4C47-AEA5-F0331EF2B58E@comcast.net>
References: <alpine.LNX.2.11.1610191038100.8962@localhost>
	<0DA29E48-DEA2-4C47-AEA5-F0331EF2B58E@comcast.net>
Message-ID: <alpine.LNX.2.11.1610191242060.8962@localhost>

On Wed, 19 Oct 2016, David Winsemius wrote:

> The `legend` function is used with base graphics plotting (as is the par
> function).

David,

   And that's how I used it before so it is the wrong template for this plot.
Mea culpa!

> I think you might first read ?Lattice since it makes reference to the fact
> that you can update trellis structures after they have been created.

   That's what I was trying to do but with the incorrect name.

> The commands to add "legend" features to lattice plots are found under the
> argument items with names "key". Search in ?xyplot for the strings
> 'legend' and 'key'. It would probably be easier to incorporate these in a
> new plot call. There are several examples (well, four anyway) at the
> ?xyplot page. Since you mentioned having Sarkar's book, the place to look
> for more examples is chapter 9 "Labels and Legends".

   I did read that but mis-applied what I read. Tried auto.key but that did
not work as desired. Now I know to learn how to apply 'key'.

Thanks,

Rich


From etienne.borocco at dauphine.fr  Wed Oct 19 17:36:01 2016
From: etienne.borocco at dauphine.fr (Etienne Borocco)
Date: Wed, 19 Oct 2016 17:36:01 +0200
Subject: [R] rsync: failed to connect to cran.r-project.org (137.208.57.37):
 No route to host (113)
Message-ID: <6723df1a-1e10-90c3-2f9b-8ad9d60c7890@dauphine.fr>

Hello,

I folowed this tutorial here:
http://singmann.org/installing-r-devel-on-linux/

I tried to install r-dev to compile gstoos that I can't manage to
compile now on my ubuntu 16.04 distribution.

I get an error with rsync:

 1. bash ./tools/rsync-recommended

There is the output of the shell:

rsync: failed to connect to cran.r-project.org (137.208.57.37): No route
to host (113)
rsync error: error in socket IO (code 10) at clientserver.c(128)
[Receiver=3.1.1]
*** rsync failed to update Recommended files ***

I saw this old post from 2008 but it does not seem to adress my issue:
https://stat.ethz.ch/pipermail/r-devel/2008-October/050973.html

Best regards,

-- 
Etienne Borocco
PhD Student in Economics - Paris Dauphine University


	[[alternative HTML version deleted]]


From evaliliane at aims.ac.za  Wed Oct 19 10:59:40 2016
From: evaliliane at aims.ac.za (Eva Liliane Ujeneza)
Date: Wed, 19 Oct 2016 10:59:40 +0200
Subject: [R] Use optim with multiple processors
Message-ID: <CANE8-von23sb8WrwJVpGKrmxZFSDfE5iaQ8agpnnYUDP=JaG9Q@mail.gmail.com>

Dear all,

I am trying to estimate the parameters* 3N + 2 *of a function using optim,
using a big longitudinal dataset of *N* patients observations. I defined
two functions: funct0 which calculate the residual sum of square for a
single individual, and *funct1* which calls funct0 using multiple cores and
return the total  sum of the residuals (I tried two different approaches,
both fail).

>> Code Desscription

funct1 <- (data,parameters){
test <- pbdLapply(data, funct0, parameters)   # calculate individual RSS
res <- sum(unlist(test))
return(res)
?      # Total RSS?

}

?funct1 <- (data,parameters){
jid <- data[get.jid(length(data))]
test <- lapply(data, funct0, parameters)   # calculate individual RSS
res <- sum(unlist(test))
return(res)       # Total RSS
}
?
?
result <- optim(parmeters, fn = funct1, yyy = data, method = "L-BFGS-B",
control=list(maxit=100, trace= TRUE )

<< End Code

?When I run the above with P processor?
?s, P-1 would complete?
? (I can see the output on the screen)?
? but the last one does not. There is no error,  and  no sign that the last
processor is still optimizing. The job just does not complete and seems
stack/still. Thus, I get no value output for *result*?. Does anyone have an
idea about what could be going wrong here ?

Cheers,

Eva


=====================================================
Eva Liliane Ujeneza, PhD student
DST/NRF Centre of Excellence in Epidemiological
Modelling and Analysis (SACEMA)

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Oct 19 22:06:50 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Oct 2016 13:06:50 -0700
Subject: [R] Error message in SIS package
In-Reply-To: <1476737643452.97275@stat.tamu.edu>
References: <1476737643452.97275@stat.tamu.edu>
Message-ID: <521EF458-BB2E-429E-9219-6CFE7C6D5072@comcast.net>


> On Oct 17, 2016, at 1:54 PM, Maity, Arnab K <akumar at stat.tamu.edu> wrote:
> 
> I try to run the following code:
> 
> sis.fit <- SIS(y = Surv(time = y[, 1], event = y[, 2]), x = x, family = "cox", penalty = "lasso", tune = "cv",
>                 nfolds = 10, type.measure = "deviance", nsis = min(dim(x)), iter = FALSE, seed = 334)
> 
> I get the following error:
> 
> Error in names(coef.beta) = paste("X", ix1, sep = "") :
>  'names' attribute [1] must be the same length as the vector [0].

You supplied a matrix as an argument to 'x' but the error message is suggesting to me that the code was written to expect a list (or dataframe). (On the other hand I suppose you could have a matrix accessioned with a length-1 'i' or 'j' argument that would return a "named"-vector.)

Reading the help page for SIS, one sees that x was supposed to be a "design matrix, of dimensions n * p, without an intercept." I cannot determine whether your 'x' argument qualifies as such. Others may be able to determine from the circumstantial evidence whether that is possibly the case. Rhelp's posting guide suggest that questions about unexpected behavior should be accompanied by a discussion that include prior correspondence with the package maintainer as well as data ojects from `dump` or `dput` that would allow replication of the error.

The code to obtain the maintainer's email address :

maintainer('SIS')

-- 
David.
> 
> here is some information about the data.
> 
>> head(y)
>  time status
> 1   24      1
> 2   31      0
> 3   39      0
> 4   64      1
> 5   72      1
> 6    6      0
>> str(y)
> num [1:46, 1:2] 24 31 39 64 72 6 87 17 53 54 ...
> - attr(*, "dimnames")=List of 2
>  ..$ : chr [1:46] "1" "2" "3" "4" ...
>  ..$ : chr [1:2] "time" "status"
>> str(x)
> num [1:46, 1:66] 0.59234 0.30042 0.28278 -0.00966 0.08189 ...
> - attr(*, "dimnames")=List of 2
>  ..$ : chr [1:46] "1" "2" "3" "4" ...
>  ..$ : chr [1:66] "EIF4EBP1" "TP53BP1" "AKT1.AKT2.AKT3" "AR" ...
>> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] survival_2.39-4 SIS_0.8-3       glmnet_2.0-5    foreach_1.4.3   Matrix_1.2-6
> 
> loaded via a namespace (and not attached):
> [1] tools_3.3.1      splines_3.3.1    codetools_0.2-14 grid_3.3.1       iterators_1.0.8  ncvreg_3.6-0     lattice_0.20-33
>> 
> 
> Please help!?
> 
> 
> 
> 
> Arnab Kumar Maity
> Department of Statistics
> Texas A&M University
> 3143 TAMU, Room 401A
> College Station, TX 77843
> akumar at stat.tamu.edu<mailto:arnabkrmaity at stat.tamu.edu>
> +1 779 777 3428<tel:%2B1%20779%20777%203428>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Wed Oct 19 22:46:20 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 19 Oct 2016 16:46:20 -0400
Subject: [R] rsync: failed to connect to cran.r-project.org
 (137.208.57.37): No route to host (113)
In-Reply-To: <6723df1a-1e10-90c3-2f9b-8ad9d60c7890@dauphine.fr>
References: <6723df1a-1e10-90c3-2f9b-8ad9d60c7890@dauphine.fr>
Message-ID: <167ae4a6-65ac-7008-3865-c14a0f91a19d@gmail.com>

On 19/10/2016 11:36 AM, Etienne Borocco wrote:
> Hello,
>
> I folowed this tutorial here:
> http://singmann.org/installing-r-devel-on-linux/
>
> I tried to install r-dev to compile gstoos that I can't manage to
> compile now on my ubuntu 16.04 distribution.
>
> I get an error with rsync:
>
>  1. bash ./tools/rsync-recommended
>
> There is the output of the shell:
>
> rsync: failed to connect to cran.r-project.org (137.208.57.37): No route
> to host (113)
> rsync error: error in socket IO (code 10) at clientserver.c(128)
> [Receiver=3.1.1]
> *** rsync failed to update Recommended files ***
>
> I saw this old post from 2008 but it does not seem to adress my issue:
> https://stat.ethz.ch/pipermail/r-devel/2008-October/050973.html

Other people have been having trouble today getting through to some of 
the Vienna machines.  I've got no idea if it's a problem in Vienna or 
somewhere else, but it will probably be fixed pretty quickly.  However, 
it's now after office hours, so if the problem is actually in Vienna, it 
might not be fixed until tomorrow.

Duncan Murdoch


From rshepard at appl-ecosys.com  Wed Oct 19 22:54:04 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 19 Oct 2016 13:54:04 -0700 (PDT)
Subject: [R] read.table() question
Message-ID: <alpine.LNX.2.11.1610191344190.8962@localhost>

   The file, daily_records.dat, contains these data:

"station","date","amount"
"0.3E",2014-01-01,
"0.3E",2014-01-02,
"0.3E",2014-01-03,0.01
"0.3E",2014-01-04,0.00
"0.3E",2014-01-05,0.00
"0.3E",2014-01-06,0.00
"0.3E",2014-01-07,0.10
"0.3E",2014-01-08,0.22
"0.3E",2014-01-09,0.49

   Using read.table("daily_records.dat", header = TRUE, sep = ",", quote =
"\"\"") the data are assigned to a data.frame named 'rain.'

   I expect the structure to show station and date as factors with amount as
numeric, but they're all factors:

str(rain)
'data.frame':	341 obs. of  3 variables:
  $ station: Factor w/ 6 levels "0.3E","0.6W",..: 1 1 ...
  $ date   : Factor w/ 62 levels "2013-12-01","2013-12-02",..: 32 33 34 ...
  $ amount : Factor w/ 48 levels "","0.00","0.01",..: 1 1 3 2 ...

   Why is amount taken as a factor rather than numeric? I do not recall
having numbers read as factors before this.

   I expect to need to convert dates using as.Date() but not to convert
numbers.

TIA,

Rich


From murdoch.duncan at gmail.com  Wed Oct 19 23:07:11 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 19 Oct 2016 17:07:11 -0400
Subject: [R] read.table() question
In-Reply-To: <alpine.LNX.2.11.1610191344190.8962@localhost>
References: <alpine.LNX.2.11.1610191344190.8962@localhost>
Message-ID: <6dcbac87-35bb-6d7f-7b2b-0fc631aabff3@gmail.com>

On 19/10/2016 4:54 PM, Rich Shepard wrote:
>    The file, daily_records.dat, contains these data:
>
> "station","date","amount"
> "0.3E",2014-01-01,
> "0.3E",2014-01-02,
> "0.3E",2014-01-03,0.01
> "0.3E",2014-01-04,0.00
> "0.3E",2014-01-05,0.00
> "0.3E",2014-01-06,0.00
> "0.3E",2014-01-07,0.10
> "0.3E",2014-01-08,0.22
> "0.3E",2014-01-09,0.49
>
>    Using read.table("daily_records.dat", header = TRUE, sep = ",", quote =
> "\"\"") the data are assigned to a data.frame named 'rain.'
>
>    I expect the structure to show station and date as factors with amount as
> numeric, but they're all factors:
>
> str(rain)
> 'data.frame':	341 obs. of  3 variables:
>   $ station: Factor w/ 6 levels "0.3E","0.6W",..: 1 1 ...
>   $ date   : Factor w/ 62 levels "2013-12-01","2013-12-02",..: 32 33 34 ...
>   $ amount : Factor w/ 48 levels "","0.00","0.01",..: 1 1 3 2 ...
>
>    Why is amount taken as a factor rather than numeric? I do not recall
> having numbers read as factors before this.

I don't get that from those 9 observations, so there's likely something 
else going on further down in the file.

Try which(is.na(as.numeric(as.character(rain$station)))) to find out 
which lines are causing problems for that column, and similarly for 
rain$amount.

Duncan Murdoch


>
>    I expect to need to convert dates using as.Date() but not to convert
> numbers.
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Wed Oct 19 23:12:47 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Oct 2016 14:12:47 -0700
Subject: [R] read.table() question
In-Reply-To: <alpine.LNX.2.11.1610191344190.8962@localhost>
References: <alpine.LNX.2.11.1610191344190.8962@localhost>
Message-ID: <CB2931B8-2F6E-4F6B-B8A9-2E980D5E381D@comcast.net>


> On Oct 19, 2016, at 1:54 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  The file, daily_records.dat, contains these data:
> 
> "station","date","amount"
> "0.3E",2014-01-01,
> "0.3E",2014-01-02,
> "0.3E",2014-01-03,0.01
> "0.3E",2014-01-04,0.00
> "0.3E",2014-01-05,0.00
> "0.3E",2014-01-06,0.00
> "0.3E",2014-01-07,0.10
> "0.3E",2014-01-08,0.22
> "0.3E",2014-01-09,0.49
> 
>  Using read.table("daily_records.dat", header = TRUE, sep = ",", quote =
> "\"\"") the data are assigned to a data.frame named 'rain.'
> 
>  I expect the structure to show station and date as factors with amount as
> numeric, but they're all factors:

I got both station and amounts as numeric:

dat <- read.table(text='"station","date","amount"
"0.3E",2014-01-01,
"0.3E",2014-01-02,
"0.3E",2014-01-03,0.01
"0.3E",2014-01-04,0.00
"0.3E",2014-01-05,0.00
"0.3E",2014-01-06,0.00
"0.3E",2014-01-07,0.10
"0.3E",2014-01-08,0.22
"0.3E",2014-01-09,0.49', header = TRUE, sep = ",",quote =
"\"\"")
str(dat)
'data.frame':	9 obs. of  3 variables:
 $ station: num  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3
 $ date   : Factor w/ 9 levels "2014-01-01","2014-01-02",..: 1 2 3 4 5 6 7 8 9
 $ amount : num  NA NA 0.01 0 0 0 0.1 0.22 0.49


Why aren't you using colClasses?


> 
> str(rain)
> 'data.frame':	341 obs. of  3 variables:
> $ station: Factor w/ 6 levels "0.3E","0.6W",..: 1 1 ...
> $ date   : Factor w/ 62 levels "2013-12-01","2013-12-02",..: 32 33 34 ...
> $ amount : Factor w/ 48 levels "","0.00","0.01",..: 1 1 3 2 ...
> 
>  Why is amount taken as a factor rather than numeric? I do not recall
> having numbers read as factors before this.
> 
>  I expect to need to convert dates using as.Date() but not to convert
> numbers.
> 
> TIA,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From akumar at stat.tamu.edu  Wed Oct 19 23:17:58 2016
From: akumar at stat.tamu.edu (Maity, Arnab K)
Date: Wed, 19 Oct 2016 21:17:58 +0000
Subject: [R] Error message in SIS package
In-Reply-To: <521EF458-BB2E-429E-9219-6CFE7C6D5072@comcast.net>
References: <1476737643452.97275@stat.tamu.edu>,
	<521EF458-BB2E-429E-9219-6CFE7C6D5072@comcast.net>
Message-ID: <1476911878293.90661@stat.tamu.edu>

Thank you all. That helps. I provided "x" as matrix. Actually the data is huge. When I work with a small subset of the data the error goes away. Let me try to post a reproducible data which can throw the same error.  

Arnab Kumar Maity
Department of Statistics
Texas A&M University
3143 TAMU, Room 401A
College Station, TX 77843
akumar at stat.tamu.edu
+1 779 777 3428

________________________________________
From: David Winsemius <dwinsemius at comcast.net>
Sent: Wednesday, October 19, 2016 3:06 PM
To: Maity, Arnab K
Cc: r-help at r-project.org
Subject: Re: [R] Error message in SIS package

> On Oct 17, 2016, at 1:54 PM, Maity, Arnab K <akumar at stat.tamu.edu> wrote:
>
> I try to run the following code:
>
> sis.fit <- SIS(y = Surv(time = y[, 1], event = y[, 2]), x = x, family = "cox", penalty = "lasso", tune = "cv",
>                 nfolds = 10, type.measure = "deviance", nsis = min(dim(x)), iter = FALSE, seed = 334)
>
> I get the following error:
>
> Error in names(coef.beta) = paste("X", ix1, sep = "") :
>  'names' attribute [1] must be the same length as the vector [0].

You supplied a matrix as an argument to 'x' but the error message is suggesting to me that the code was written to expect a list (or dataframe). (On the other hand I suppose you could have a matrix accessioned with a length-1 'i' or 'j' argument that would return a "named"-vector.)

Reading the help page for SIS, one sees that x was supposed to be a "design matrix, of dimensions n * p, without an intercept." I cannot determine whether your 'x' argument qualifies as such. Others may be able to determine from the circumstantial evidence whether that is possibly the case. Rhelp's posting guide suggest that questions about unexpected behavior should be accompanied by a discussion that include prior correspondence with the package maintainer as well as data ojects from `dump` or `dput` that would allow replication of the error.

The code to obtain the maintainer's email address :

maintainer('SIS')

--
David.
>
> here is some information about the data.
>
>> head(y)
>  time status
> 1   24      1
> 2   31      0
> 3   39      0
> 4   64      1
> 5   72      1
> 6    6      0
>> str(y)
> num [1:46, 1:2] 24 31 39 64 72 6 87 17 53 54 ...
> - attr(*, "dimnames")=List of 2
>  ..$ : chr [1:46] "1" "2" "3" "4" ...
>  ..$ : chr [1:2] "time" "status"
>> str(x)
> num [1:46, 1:66] 0.59234 0.30042 0.28278 -0.00966 0.08189 ...
> - attr(*, "dimnames")=List of 2
>  ..$ : chr [1:46] "1" "2" "3" "4" ...
>  ..$ : chr [1:66] "EIF4EBP1" "TP53BP1" "AKT1.AKT2.AKT3" "AR" ...
>> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] survival_2.39-4 SIS_0.8-3       glmnet_2.0-5    foreach_1.4.3   Matrix_1.2-6
>
> loaded via a namespace (and not attached):
> [1] tools_3.3.1      splines_3.3.1    codetools_0.2-14 grid_3.3.1       iterators_1.0.8  ncvreg_3.6-0     lattice_0.20-33
>>
>
> Please help!?
>
>
>
>
> Arnab Kumar Maity
> Department of Statistics
> Texas A&M University
> 3143 TAMU, Room 401A
> College Station, TX 77843
> akumar at stat.tamu.edu<mailto:arnabkrmaity at stat.tamu.edu>
> +1 779 777 3428<tel:%2B1%20779%20777%203428>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From marc_schwartz at me.com  Wed Oct 19 23:22:14 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 19 Oct 2016 16:22:14 -0500
Subject: [R] read.table() question
In-Reply-To: <CB2931B8-2F6E-4F6B-B8A9-2E980D5E381D@comcast.net>
References: <alpine.LNX.2.11.1610191344190.8962@localhost>
	<CB2931B8-2F6E-4F6B-B8A9-2E980D5E381D@comcast.net>
Message-ID: <3ED9111A-6628-4B45-8DA9-3423CE025D93@me.com>


> On Oct 19, 2016, at 4:12 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Oct 19, 2016, at 1:54 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>> 
>> The file, daily_records.dat, contains these data:
>> 
>> "station","date","amount"
>> "0.3E",2014-01-01,
>> "0.3E",2014-01-02,
>> "0.3E",2014-01-03,0.01
>> "0.3E",2014-01-04,0.00
>> "0.3E",2014-01-05,0.00
>> "0.3E",2014-01-06,0.00
>> "0.3E",2014-01-07,0.10
>> "0.3E",2014-01-08,0.22
>> "0.3E",2014-01-09,0.49
>> 
>> Using read.table("daily_records.dat", header = TRUE, sep = ",", quote =
>> "\"\"") the data are assigned to a data.frame named 'rain.'
>> 
>> I expect the structure to show station and date as factors with amount as
>> numeric, but they're all factors:
> 
> I got both station and amounts as numeric:
> 
> dat <- read.table(text='"station","date","amount"
> "0.3E",2014-01-01,
> "0.3E",2014-01-02,
> "0.3E",2014-01-03,0.01
> "0.3E",2014-01-04,0.00
> "0.3E",2014-01-05,0.00
> "0.3E",2014-01-06,0.00
> "0.3E",2014-01-07,0.10
> "0.3E",2014-01-08,0.22
> "0.3E",2014-01-09,0.49', header = TRUE, sep = ",",quote =
> "\"\"")
> str(dat)
> 'data.frame':	9 obs. of  3 variables:
> $ station: num  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3
> $ date   : Factor w/ 9 levels "2014-01-01","2014-01-02",..: 1 2 3 4 5 6 7 8 9
> $ amount : num  NA NA 0.01 0 0 0 0.1 0.22 0.49
> 
> 
> Why aren't you using colClasses?


'station' comes over as numeric because the 'E' is presumed to be for scientific notation in the limited data copied here. 

It appears that the actual data file has a 'W' suffix, presumably for a directional designation (East versus West), as seen below in Rich's str() output.

> str(type.convert("0.3E"))
 num 0.3

> str(type.convert("0.3W"))
 Factor w/ 1 level "0.3W": 1

> str(type.convert(c("0.3E", "0.3W")))
 Factor w/ 2 levels "0.3E","0.3W": 1 2


As David and Duncan experienced, 'amount' came over as numeric for me as well, again with the limited data here. So as Duncan noted, there is likely a value somewhere in that column that results in the coercion to factor when ?type.convert is applied to the column, because the value is not a proper number.

Regards,

Marc Schwartz


> 
> 
>> 
>> str(rain)
>> 'data.frame':	341 obs. of  3 variables:
>> $ station: Factor w/ 6 levels "0.3E","0.6W",..: 1 1 ...
>> $ date   : Factor w/ 62 levels "2013-12-01","2013-12-02",..: 32 33 34 ...
>> $ amount : Factor w/ 48 levels "","0.00","0.01",..: 1 1 3 2 ...
>> 
>> Why is amount taken as a factor rather than numeric? I do not recall
>> having numbers read as factors before this.
>> 
>> I expect to need to convert dates using as.Date() but not to convert
>> numbers.
>> 
>> TIA,
>> 
>> Rich
> 
> ______________


From rshepard at appl-ecosys.com  Wed Oct 19 23:24:19 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 19 Oct 2016 14:24:19 -0700 (PDT)
Subject: [R] read.table() question
In-Reply-To: <6dcbac87-35bb-6d7f-7b2b-0fc631aabff3@gmail.com>
References: <alpine.LNX.2.11.1610191344190.8962@localhost>
	<6dcbac87-35bb-6d7f-7b2b-0fc631aabff3@gmail.com>
Message-ID: <alpine.LNX.2.11.1610191423090.8962@localhost>

On Wed, 19 Oct 2016, Duncan Murdoch wrote:

> I don't get that from those 9 observations, so there's likely something
> else going on further down in the file.

Duncan,

   Sigh. I thought I had removed all 'T's (for trace amounts) from the file,
but I hadn't.

   Yes, this explains it.

Many thanks,

Rich


From cadeb at usgs.gov  Wed Oct 19 23:43:23 2016
From: cadeb at usgs.gov (Cade, Brian)
Date: Wed, 19 Oct 2016 15:43:23 -0600
Subject: [R] Confidence interval on quantile regression (quantreg)
In-Reply-To: <CAP0QN_YYMjS9Z=ny-pC_z2uxWW-1p3z_gmAnbPJ-1hEavQxnsA@mail.gmail.com>
References: <CAP0QN_YYMjS9Z=ny-pC_z2uxWW-1p3z_gmAnbPJ-1hEavQxnsA@mail.gmail.com>
Message-ID: <CAM5M9BQVGBOxoQR6qDjqyr-LOUznKxt+w6_1QFCeedQJxMux_w@mail.gmail.com>

Depending on the procedure used for estimating the CI, especially if the
default rankscore inversion method, then it is possible that legitimate end
points of the intervals for some quantiles with a given alpha (e.g., 0.05
for 95% CI) cannot be refined beyond plus or minus infinity.  Of course,
this typically happens for smaller sample sizes, more extreme taus, and
more complex models.  But unusual distributional characteristics of the
data distributions can also contribute to this issue.

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Wed, Oct 19, 2016 at 11:05 AM, Frank Black <frank.black.1988 at gmail.com>
wrote:

> Hi all,
>
> I am using the quantile regression package for estimating some models.
> However, in some cases the intervals' upper bounds are either abnormally
> high or low, with values such as -1.797693e+308 or 1.797693e+308. Actually,
> the number is the same in absolute terms.
>
> Does anyone know a reasonable explanation for this?
>
> Thanks.
>
> Kind regards,
> Frank
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From bjpmodi2016 at gmail.com  Wed Oct 19 23:59:08 2016
From: bjpmodi2016 at gmail.com (Narendra Modi)
Date: Wed, 19 Oct 2016 16:59:08 -0500
Subject: [R] Optimize selected variables but not all - nloptr
Message-ID: <CAPq=xQBwiSetEFd5dmgX8vALsaDi8AkOk=Rvn_hT+qF273x6Lg@mail.gmail.com>

Hello All,
I have a matrix with initial values as below and I need to optimize
the variables that are greater than 0.

          TAU       fij      fij2
 [1,] 14.33375 0.0000000 0.01449572
 [2,] 14.33375 0.0000000 0.00000000
 [3,] 14.33375 0.0000000 0.00000000
 [4,] 14.33375 0.0000000 0.02206446
 [5,] 14.33375 0.0000000 0.00000000
 [6,] 14.33375 0.0000000 0.00000000
 [7,] 14.33375 0.0000000 0.00000000
 [8,] 14.33375 0.8279846 0.00000000
 [9,] 14.33375 0.0000000 0.03695833
[10,] 14.33375 0.0000000 0.00000000

Or structure(c(14.3337481730129, 14.3337481730129, 14.3337481730129,
14.3337481730129, 14.3337481730129, 14.3337481730129, 14.3337481730129,
14.3337481730129, 14.3337481730129, 14.3337481730129, 0, 0, 0,
0, 0, 0, 0, 0.827984553120177, 0, 0, 0.0144957197835888, 0, 0,
0.0220644627842788, 0, 0, 0, 0, 0.0369583294835073, 0), .Dim = c(10L,
3L), .Dimnames = list(NULL, c("TAU", "fij", "fij2")))

Is it possible to provide lowerbound and upperbound as 0 for variables
(< 0 in the initial matrix) and nloptr will consider them "unchanged"
during optimization?

Rstudio crashes when I try to do that. Is this a bug or I should
approach it differently?

NM


From davef at otter-rsch.com  Wed Oct 19 23:47:12 2016
From: davef at otter-rsch.com (dave fournier)
Date: Wed, 19 Oct 2016 14:47:12 -0700
Subject: [R] Finding starting values for the parameters using nls() or
 nls2()
In-Reply-To: <000a01d22304$70edce00$52c96a00$@163.com>
References: <000a01d22304$70edce00$52c96a00$@163.com>
Message-ID: <6976a8bb-cb56-c6e1-2388-ea6d2f2b251b@otter-rsch.com>

Actually this converges very nicely if you use these starting values 
that I obtained with
AD Model Builder

        th     9.1180e-01
        b0    5.2104e+00
        b1   -4.6725e-04

The R result looks like

nls.m2
Nonlinear regression model
   model: Retention ~ expFct(Area, b0, b1, th)
    data: structure(list(Area = c(521.5, 689.78, 1284.71, 2018.8, 
2560.46, 524.91, 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 
1432.5, 2144.74, 2629.2), Retention = c(95.3, 87.18, 44.94, 26.36, 
18.12, 84.68, 37.24, 33.04, 23.46, 9.72, 97.92, 71.44, 44.52, 24.44, 
15.26)), .Names = c("Area", "Retention"), row.names = c(NA, -15L), class 
= "data.frame")
         b0         b1         th
  5.2104466 -0.0004672  0.9118029
  residual sum-of-squares: 686.8

Number of iterations to convergence: 1
Achieved convergence tolerance: 1.75e-06


From rshepard at appl-ecosys.com  Thu Oct 20 01:04:59 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 19 Oct 2016 16:04:59 -0700 (PDT)
Subject: [R] Lattice xyplot(): adding a legend
In-Reply-To: <alpine.LNX.2.11.1610191242060.8962@localhost>
References: <alpine.LNX.2.11.1610191038100.8962@localhost>
	<0DA29E48-DEA2-4C47-AEA5-F0331EF2B58E@comcast.net>
	<alpine.LNX.2.11.1610191242060.8962@localhost>
Message-ID: <alpine.LNX.2.11.1610191556470.8962@localhost>

On Wed, 19 Oct 2016, Rich Shepard wrote:

>  I did read that but mis-applied what I read. Tried auto.key but that did
> not work as desired. Now I know to learn how to apply 'key'.

   Almost there after another careful reading Section 9.2.3 ff in the book.
Here's the command to produce the plot:

rainbyday <- xyplot(rain$amount ~ raindate, data = rain, main = "Area Precipitation",
     ylab = "Daily Total Amount (in)", xlab = "Date",
     scales = list(x=list(at=c(1,8,15,22,29,36,43,50,57,62), rot = 90),
     y = list(at=c(min(rain$amount), max(rain$amount)))),
     pch = 20,
     col = c("black","red","dark green","dark blue","dark goldenrod","purple"),
     key = simpleKey(text = levels(rain$station)[1:6],
       x = 0.2, y = 0.6, corner = c(0, 0), points = TRUE))

   My question is how to pass pch = 20 to the key. simpleKey accepts only the
logical TRUE as an argument and this produces a plot with filled circles for
the data but unfilled circles for the key. I find no example of specifying
pch for points in the key in either the book or ?xyplot, and I'm sure there
is a way of having the key symbols match both pch and color as the data
symbols.

   Is use of Rows() the solution?

Rich


From jdnewmil at dcn.davis.ca.us  Thu Oct 20 01:15:27 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 19 Oct 2016 16:15:27 -0700
Subject: [R] Optimize selected variables but not all - nloptr
In-Reply-To: <CAPq=xQBwiSetEFd5dmgX8vALsaDi8AkOk=Rvn_hT+qF273x6Lg@mail.gmail.com>
References: <CAPq=xQBwiSetEFd5dmgX8vALsaDi8AkOk=Rvn_hT+qF273x6Lg@mail.gmail.com>
Message-ID: <0A23969C-A8EB-436A-BF81-6943DB6E27FA@dcn.davis.ca.us>

You provided the data but not the broken code. 
-- 
Sent from my phone. Please excuse my brevity.

On October 19, 2016 2:59:08 PM PDT, Narendra Modi <bjpmodi2016 at gmail.com> wrote:
>Hello All,
>I have a matrix with initial values as below and I need to optimize
>the variables that are greater than 0.
>
>          TAU       fij      fij2
> [1,] 14.33375 0.0000000 0.01449572
> [2,] 14.33375 0.0000000 0.00000000
> [3,] 14.33375 0.0000000 0.00000000
> [4,] 14.33375 0.0000000 0.02206446
> [5,] 14.33375 0.0000000 0.00000000
> [6,] 14.33375 0.0000000 0.00000000
> [7,] 14.33375 0.0000000 0.00000000
> [8,] 14.33375 0.8279846 0.00000000
> [9,] 14.33375 0.0000000 0.03695833
>[10,] 14.33375 0.0000000 0.00000000
>
>Or structure(c(14.3337481730129, 14.3337481730129, 14.3337481730129,
>14.3337481730129, 14.3337481730129, 14.3337481730129, 14.3337481730129,
>14.3337481730129, 14.3337481730129, 14.3337481730129, 0, 0, 0,
>0, 0, 0, 0, 0.827984553120177, 0, 0, 0.0144957197835888, 0, 0,
>0.0220644627842788, 0, 0, 0, 0, 0.0369583294835073, 0), .Dim = c(10L,
>3L), .Dimnames = list(NULL, c("TAU", "fij", "fij2")))
>
>Is it possible to provide lowerbound and upperbound as 0 for variables
>(< 0 in the initial matrix) and nloptr will consider them "unchanged"
>during optimization?
>
>Rstudio crashes when I try to do that. Is this a bug or I should
>approach it differently?
>
>NM
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From profjcnash at gmail.com  Thu Oct 20 03:48:47 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Wed, 19 Oct 2016 21:48:47 -0400
Subject: [R] Optimize selected variables but not all - nloptr
In-Reply-To: <CAPq=xQBwiSetEFd5dmgX8vALsaDi8AkOk=Rvn_hT+qF273x6Lg@mail.gmail.com>
References: <CAPq=xQBwiSetEFd5dmgX8vALsaDi8AkOk=Rvn_hT+qF273x6Lg@mail.gmail.com>
Message-ID: <a71e58fb-591a-7766-08de-1887d676d5ec@gmail.com>

I refer to such parameters as "masked" in my 2014 book Nonlinear parameter optimization with R tools.
Recently I put package optimrx on R-forge (and optimr with fewer solvers on CRAN) that allows for masks with
all the parameters. The masks can be specified as you suggest with start=lower=upper. However, for reasons
I won't go into here, nloptr solvers are not yet included. However, I suspect either Rvmmin or Rcgmin will
work fine.

I will guess that nloptr does NOT cater for masks.

JN

On 16-10-19 05:59 PM, Narendra Modi wrote:
> Hello All,
> I have a matrix with initial values as below and I need to optimize
> the variables that are greater than 0.
> 
>           TAU       fij      fij2
>  [1,] 14.33375 0.0000000 0.01449572
>  [2,] 14.33375 0.0000000 0.00000000
>  [3,] 14.33375 0.0000000 0.00000000
>  [4,] 14.33375 0.0000000 0.02206446
>  [5,] 14.33375 0.0000000 0.00000000
>  [6,] 14.33375 0.0000000 0.00000000
>  [7,] 14.33375 0.0000000 0.00000000
>  [8,] 14.33375 0.8279846 0.00000000
>  [9,] 14.33375 0.0000000 0.03695833
> [10,] 14.33375 0.0000000 0.00000000
> 
> Or structure(c(14.3337481730129, 14.3337481730129, 14.3337481730129,
> 14.3337481730129, 14.3337481730129, 14.3337481730129, 14.3337481730129,
> 14.3337481730129, 14.3337481730129, 14.3337481730129, 0, 0, 0,
> 0, 0, 0, 0, 0.827984553120177, 0, 0, 0.0144957197835888, 0, 0,
> 0.0220644627842788, 0, 0, 0, 0, 0.0369583294835073, 0), .Dim = c(10L,
> 3L), .Dimnames = list(NULL, c("TAU", "fij", "fij2")))
> 
> Is it possible to provide lowerbound and upperbound as 0 for variables
> (< 0 in the initial matrix) and nloptr will consider them "unchanged"
> during optimization?
> 
> Rstudio crashes when I try to do that. Is this a bug or I should
> approach it differently?
> 
> NM
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dulcalma at bigpond.com  Thu Oct 20 07:10:32 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 20 Oct 2016 16:10:32 +1100
Subject: [R] Lattice xyplot(): adding a legend
In-Reply-To: <alpine.LNX.2.11.1610191556470.8962@localhost>
References: <alpine.LNX.2.11.1610191038100.8962@localhost>	<0DA29E48-DEA2-4C47-AEA5-F0331EF2B58E@comcast.net>	<alpine.LNX.2.11.1610191242060.8962@localhost>
	<alpine.LNX.2.11.1610191556470.8962@localhost>
Message-ID: <000001d22a90$48c34660$da49d320$@bigpond.com>

Hi Rich

Without an example to check I think you need to fill in the arguments for
par.settings eg 

par.settings = list(plot.symbol = list(c("black","red","dark green","dark
blue","dark goldenrod","purple"),
                                                                        pch
= 20,
                                                                       cex =
1),
if you have groups 

par.settings = list(superpose.symbol = list(c("black","red","dark
green","dark blue","dark goldenrod","purple"),
 
pch = 20,
 
cex = 1)),

For other types such as barchart  type 
barchart  and at the top there is

plot.symbol <- trellis.par.get("plot.symbol")
    plot.line <- trellis.par.get("plot.line")
    superpose.symbol <- trellis.par.get("superpose.symbol")
    superpose.line <- trellis.par.get("superpose.line")

Similar occurs for panel.xyplot

I find that ? xyplot  and ?panel. ... give the most uptodate methods things
change overtime.
There are some words on how information is passed to the key in ?xyplot
You either have to set trellis.par.set() or use the par.settings arguments

For older versions things may be slightly different.

If in a hurry I try the easiest but if that fails on the first go I just use
key = list(text = ... etc
 
Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rich Shepard
Sent: Thursday, 20 October 2016 10:05
To: r-help at r-project.org
Subject: Re: [R] Lattice xyplot(): adding a legend

On Wed, 19 Oct 2016, Rich Shepard wrote:

>  I did read that but mis-applied what I read. Tried auto.key but that did
> not work as desired. Now I know to learn how to apply 'key'.

   Almost there after another careful reading Section 9.2.3 ff in the book.
Here's the command to produce the plot:

rainbyday <- xyplot(rain$amount ~ raindate, data = rain, main = "Area
Precipitation",
     ylab = "Daily Total Amount (in)", xlab = "Date",
     scales = list(x=list(at=c(1,8,15,22,29,36,43,50,57,62), rot = 90),
     y = list(at=c(min(rain$amount), max(rain$amount)))),
     pch = 20,
     col = c("black","red","dark green","dark blue","dark
goldenrod","purple"),
     key = simpleKey(text = levels(rain$station)[1:6],
       x = 0.2, y = 0.6, corner = c(0, 0), points = TRUE))

   My question is how to pass pch = 20 to the key. simpleKey accepts only
the
logical TRUE as an argument and this produces a plot with filled circles for
the data but unfilled circles for the key. I find no example of specifying
pch for points in the key in either the book or ?xyplot, and I'm sure there
is a way of having the key symbols match both pch and color as the data
symbols.

   Is use of Rows() the solution?

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Thu Oct 20 07:18:53 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 20 Oct 2016 16:18:53 +1100
Subject: [R] Lattice xyplot(): adding a legend
In-Reply-To: <000001d22a90$48c34660$da49d320$@bigpond.com>
References: <alpine.LNX.2.11.1610191038100.8962@localhost>	<0DA29E48-DEA2-4C47-AEA5-F0331EF2B58E@comcast.net>	<alpine.LNX.2.11.1610191242060.8962@localhost>	<alpine.LNX.2.11.1610191556470.8962@localhost>
	<000001d22a90$48c34660$da49d320$@bigpond.com>
Message-ID: <000201d22a91$73a73c50$5af5b4f0$@bigpond.com>

I had not seen Davids reply so will add to my note

The legend is for special keys or multiple keys

eg
https://stat.ethz.ch/pipermail/r-help/2010-May/240341.html

It may involve draw.key()

Duncan

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan
Mackay
Sent: Thursday, 20 October 2016 16:11
To: R
Subject: Re: [R] Lattice xyplot(): adding a legend

Hi Rich

Without an example to check I think you need to fill in the arguments for
par.settings eg 

par.settings = list(plot.symbol = list(c("black","red","dark green","dark
blue","dark goldenrod","purple"),
                                                                        pch
= 20,
                                                                       cex =
1),
if you have groups 

par.settings = list(superpose.symbol = list(c("black","red","dark
green","dark blue","dark goldenrod","purple"),
 
pch = 20,
 
cex = 1)),

For other types such as barchart  type 
barchart  and at the top there is

plot.symbol <- trellis.par.get("plot.symbol")
    plot.line <- trellis.par.get("plot.line")
    superpose.symbol <- trellis.par.get("superpose.symbol")
    superpose.line <- trellis.par.get("superpose.line")

Similar occurs for panel.xyplot

I find that ? xyplot  and ?panel. ... give the most uptodate methods things
change overtime.
There are some words on how information is passed to the key in ?xyplot
You either have to set trellis.par.set() or use the par.settings arguments

For older versions things may be slightly different.

If in a hurry I try the easiest but if that fails on the first go I just use
key = list(text = ... etc
 
Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rich Shepard
Sent: Thursday, 20 October 2016 10:05
To: r-help at r-project.org
Subject: Re: [R] Lattice xyplot(): adding a legend

On Wed, 19 Oct 2016, Rich Shepard wrote:

>  I did read that but mis-applied what I read. Tried auto.key but that did
> not work as desired. Now I know to learn how to apply 'key'.

   Almost there after another careful reading Section 9.2.3 ff in the book.
Here's the command to produce the plot:

rainbyday <- xyplot(rain$amount ~ raindate, data = rain, main = "Area
Precipitation",
     ylab = "Daily Total Amount (in)", xlab = "Date",
     scales = list(x=list(at=c(1,8,15,22,29,36,43,50,57,62), rot = 90),
     y = list(at=c(min(rain$amount), max(rain$amount)))),
     pch = 20,
     col = c("black","red","dark green","dark blue","dark
goldenrod","purple"),
     key = simpleKey(text = levels(rain$station)[1:6],
       x = 0.2, y = 0.6, corner = c(0, 0), points = TRUE))

   My question is how to pass pch = 20 to the key. simpleKey accepts only
the
logical TRUE as an argument and this produces a plot with filled circles for
the data but unfilled circles for the key. I find no example of specifying
pch for points in the key in either the book or ?xyplot, and I'm sure there
is a way of having the key symbols match both pch and color as the data
symbols.

   Is use of Rows() the solution?

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Oct 20 07:42:58 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Oct 2016 22:42:58 -0700
Subject: [R] Lattice xyplot(): adding a legend
In-Reply-To: <alpine.LNX.2.11.1610191556470.8962@localhost>
References: <alpine.LNX.2.11.1610191038100.8962@localhost>
	<0DA29E48-DEA2-4C47-AEA5-F0331EF2B58E@comcast.net>
	<alpine.LNX.2.11.1610191242060.8962@localhost>
	<alpine.LNX.2.11.1610191556470.8962@localhost>
Message-ID: <E6104510-8BEE-4F75-AF7B-AC68421BBB5D@comcast.net>


> On Oct 19, 2016, at 4:04 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Wed, 19 Oct 2016, Rich Shepard wrote:
> 
>> I did read that but mis-applied what I read. Tried auto.key but that did
>> not work as desired. Now I know to learn how to apply 'key'.
> 
>  Almost there after another careful reading Section 9.2.3 ff in the book.
> Here's the command to produce the plot:
> 
> rainbyday <- xyplot(rain$amount ~ raindate, data = rain, main = "Area Precipitation",

I am getting annoyed, exhausted, and frustrated reading code like that. Never, ever, ... ever,  use the "$" operator in a formula.

Use the 'data' argument and the 'formula' as they are supposed to be used.



>    ylab = "Daily Total Amount (in)", xlab = "Date",
>    scales = list(x=list(at=c(1,8,15,22,29,36,43,50,57,62), rot = 90),
>    y = list(at=c(min(rain$amount), max(rain$amount)))),
>    pch = 20,
>    col = c("black","red","dark green","dark blue","dark goldenrod","purple"),

> cl <- colors()
 
> which(cl=="dark goldenrod")
integer(0)
> which(cl=="darkgoldenrod")
[1] 75

Admittedly the error message was completely opaque.


>    key = simpleKey(text = levels(rain$station)[1:6],



>      x = 0.2, y = 0.6, corner = c(0, 0), points = TRUE))
> 
>  My question is how to pass pch = 20 to the key. simpleKey accepts only the
> logical TRUE as an argument and this produces a plot with filled circles for
> the data but unfilled circles for the key. I find no example of specifying
> pch for points in the key in either the book or ?xyplot, and I'm sure there
> is a way of having the key symbols match both pch and color as the data
> symbols.
> 

rainbyday <- xyplot(amount ~ raindate, data = rain, main = "Area Precipitation",
   ylab = "Daily Total Amount (in)", xlab = "Date",
   scales = list(x=list(at=c(1,8,15,22,29,36,43,50,57,62), rot = 90),
   y = list(at=c(min(rain$amount), max(rain$amount)))),
   pch = 20,
   col = c("black","red","dark green","dark blue","dark goldenrod","purple")[rain$station],
# Note: the need to "pick" the colors from a palette with a vector.
   key = simpleKey( text=as.character( unique(rain$station )), 
               col = c("black","red","darkgreen","darkblue","darkgoldenrod","purple"),
               pch = 20,
     x = 0.2, y = 0.6, corner = c(0, 0), points = TRUE)); print(rainbyday)


>  Is use of Rows() the solution?

I am unaware of any 'Rows" function.

> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Thu Oct 20 12:33:30 2016
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Thu, 20 Oct 2016 12:33:30 +0200
Subject: [R] findInterval() surprising behavior
In-Reply-To: <58052B03.9040607@sapo.pt>
References: <1476731005.578838968@f384.i.mail.ru> <58052B03.9040607@sapo.pt>
Message-ID: <BDC53031-2102-4341-BD9A-8E4F7816CEB3@gmail.com>

It's a bug (left.open=FALSE code gets executed in some cases). Hoping to have a fix tested and in place before 3.3.2.

-pd

> On 17 Oct 2016, at 21:48 , Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> Same on Windows 7.
> 
> > findInterval(x=c(6, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE)
> [1] 4 2 1 1
> > findInterval(x=c(4, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE)
> [1] 3 1 1 1
> > sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> locale:
> [1] LC_COLLATE=Portuguese_Portugal.1252 LC_CTYPE=Portuguese_Portugal.1252
> [3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C 
> [5] LC_TIME=Portuguese_Portugal.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] lattice_0.20-33
> 
> loaded via a namespace (and not attached):
> [1] tools_3.3.1 grid_3.3.1
> 
> Rui Barradas
> 
> Em 17-10-2016 20:03, Dmitriy Chernykh via R-help escreveu:
>> Hello,
>> 
>> I call function findInterval in the following way:
>> 
>> findInterval(x=c(6, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE),
>> 
>> and expect that it will return 4 1 1 1. But the function returns 4 2 1 1 instead. Moreover, if I change the first element in x to, say, 4 -
>> 
>> findInterval(x=c(4, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE)
>> 
>> then the function returns 3 1 1 1.
>> 
>> Why are results for identical elements in x not the same? And why is element in x influenced by previous one? I suspect this is a bug but I am not 100% sure.
>> 
>> Technical details:
>> 
>> sessionInfo()
>> R version 3.3.1 (2016-06-21)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.5 LTS
>> 
>> locale:
>>  [1] LC_CTYPE=ru_RU.UTF-8       LC_NUMERIC=C               LC_TIME=ru_RU.UTF-8        LC_COLLATE=ru_RU.UTF-8     LC_MONETARY=ru_RU.UTF-8
>>  [6] LC_MESSAGES=ru_RU.UTF-8    LC_PAPER=ru_RU.UTF-8       LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=ru_RU.UTF-8 LC_IDENTIFICATION=C
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> loaded via a namespace (and not attached):
>> [1] tools_3.3.1
>> 
>> 
>> Thanks.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Thu Oct 20 13:05:37 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 20 Oct 2016 12:05:37 +0100
Subject: [R] nls.lm
In-Reply-To: <trinity-6990f702-31a2-4ab3-9d04-dfb58a40f5a6-1476904583462@3capp-gmx-bs28>
References: <trinity-6990f702-31a2-4ab3-9d04-dfb58a40f5a6-1476904583462@3capp-gmx-bs28>
Message-ID: <1A8C1289955EF649A09086A153E2672403FEAD5CBC@GBTEDVPEXCMB04.corp.lgc-group.com>

> How do you reply to a specific post on this board instead of the thread?

You can reply to the individual, as I just did.

But I strongly suggest that you don't. You would be much better advised to discontinue debate and follow the essential advice given by nls.lm, which - no matter whether couched in terms of count of residuals - is simply to make sure that you have more independent data than variables when seeking a unique numerical solution by non-linear least squares. If you don't you'll get nonsense.


S Ellison





*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From mviljamaa at kapsi.fi  Thu Oct 20 13:40:26 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Thu, 20 Oct 2016 14:40:26 +0300
Subject: [R] How to use predict() so that one retains the rows that they're
 associated with?
Message-ID: <23c16c4904dfdfd1c77627fc3ad0f4ae@kapsi.fi>

I'm using predict() for my glm() logistic model, but I'm having trouble 
relating the predicted results to the rows that produced them.

I want to be able to plot predictions along some categorical variables.

So what can I do in order to get predicted values but also know what 
variable values produced them?


From petr.pikal at precheza.cz  Thu Oct 20 14:43:09 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 20 Oct 2016 12:43:09 +0000
Subject: [R] How to use predict() so that one retains the rows that
 they're associated with?
In-Reply-To: <23c16c4904dfdfd1c77627fc3ad0f4ae@kapsi.fi>
References: <23c16c4904dfdfd1c77627fc3ad0f4ae@kapsi.fi>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50439C3@SRVEXCHMBX.precheza.cz>

Hi.

I am a bit puzzled. You do not get predicted values from variables but from estimated model. AFAIK order of predicted values is the same as order of original values.

> x<-1:10
> y<-5*x+3+rnorm(10)
> plot(x,y)
> a<-sample(letters[1:3], 10, replace=T)
> fit<-lm(y~x)
> points(x, predict(fit), col=as.numeric(as.factor(a)), pch=19)
>

Do if you have some categorical variable and want to distinguish result according to them, you can use similar approach.

Cheers
Petr



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of mviljamaa
> Sent: Thursday, October 20, 2016 1:40 PM
> To: r-help at r-project.org
> Subject: [R] How to use predict() so that one retains the rows that they're
> associated with?
>
> I'm using predict() for my glm() logistic model, but I'm having trouble relating
> the predicted results to the rows that produced them.
>
> I want to be able to plot predictions along some categorical variables.
>
> So what can I do in order to get predicted values but also know what variable
> values produced them?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From lists at dewey.myzen.co.uk  Thu Oct 20 14:44:03 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 20 Oct 2016 13:44:03 +0100
Subject: [R] How to use predict() so that one retains the rows that
 they're associated with?
In-Reply-To: <23c16c4904dfdfd1c77627fc3ad0f4ae@kapsi.fi>
References: <23c16c4904dfdfd1c77627fc3ad0f4ae@kapsi.fi>
Message-ID: <08396834-df19-b315-1196-55a279a66379@dewey.myzen.co.uk>

Some more context would help here but here goes anyway.

You should have a vector of predictions with length equal to the number 
of rows in your original data-set so you can just use cbind. If that is 
not true check the documentation for the correct setting of na.action. 
If you used newdata = in your call to predict then your predictions 
apply to the new data, not the old, so amend my statement as appropriate.

If that does not answer then make a small example data-set, run glm on 
it, run predict, and then show us the data-set, the output from glm, the 
output from predict, and what went wrong when you tried to cbind them.

On 20/10/2016 12:40, mviljamaa wrote:
> I'm using predict() for my glm() logistic model, but I'm having trouble
> relating the predicted results to the rows that produced them.
>
> I want to be able to plot predictions along some categorical variables.
>
> So what can I do in order to get predicted values but also know what
> variable values produced them?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From rmh at temple.edu  Thu Oct 20 15:05:26 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 20 Oct 2016 09:05:26 -0400
Subject: [R] How to use predict() so that one retains the rows that
 they're associated with?
In-Reply-To: <23c16c4904dfdfd1c77627fc3ad0f4ae@kapsi.fi>
References: <23c16c4904dfdfd1c77627fc3ad0f4ae@kapsi.fi>
Message-ID: <CAGx1TMBTDATK6_hWtPQK3B97QjVcTy34G=cb0p=N3Oy4LSUtFg@mail.gmail.com>

I believe you have missing values and therefore you need to use
the argument
glm(formula, data, na.action=na.exclude, ...)

?na.exclude

The relevant line is

     when 'na.exclude' is used the residuals and
     predictions are padded to the correct length by inserting 'NA's
     for cases omitted by 'na.exclude'.

Rich

On Thu, Oct 20, 2016 at 7:40 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> I'm using predict() for my glm() logistic model, but I'm having trouble
> relating the predicted results to the rows that produced them.
>
> I want to be able to plot predictions along some categorical variables.
>
> So what can I do in order to get predicted values but also know what
> variable values produced them?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Oct 20 15:20:29 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 20 Oct 2016 13:20:29 +0000
Subject: [R] How to use predict() so that one retains the rows that
 they're associated with?
In-Reply-To: <CAGx1TMBTDATK6_hWtPQK3B97QjVcTy34G=cb0p=N3Oy4LSUtFg@mail.gmail.com>
References: <23c16c4904dfdfd1c77627fc3ad0f4ae@kapsi.fi>
	<CAGx1TMBTDATK6_hWtPQK3B97QjVcTy34G=cb0p=N3Oy4LSUtFg@mail.gmail.com>
Message-ID: <ceebefcb46a64e00872c4e26d38e0458@exch-2p-mbx-w2.ads.tamu.edu>

One additional issue, since you are using logistic regression, you are predicting a dichotomy (i.e. 0 and 1 or factor with 2 categories). The value returned by predict() is a log odds ratio of belonging in the second category. Alternatively if you use the type="response" argument with predict(), you get the estimated probability of being in the second category. You can use ifelse() to convert the fitted values back to your original categories, but you must decide where to break the values (.5 is an obvious choice for the probabilities or 0 for the log odds, but these are not always the best). 

There are a number of tutorials on the web that discuss logistic regression. You should look at one of them.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Richard M. Heiberger
Sent: Thursday, October 20, 2016 8:05 AM
To: mviljamaa
Cc: r-help
Subject: Re: [R] How to use predict() so that one retains the rows that they're associated with?

I believe you have missing values and therefore you need to use
the argument
glm(formula, data, na.action=na.exclude, ...)

?na.exclude

The relevant line is

     when 'na.exclude' is used the residuals and
     predictions are padded to the correct length by inserting 'NA's
     for cases omitted by 'na.exclude'.

Rich

On Thu, Oct 20, 2016 at 7:40 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> I'm using predict() for my glm() logistic model, but I'm having trouble
> relating the predicted results to the rows that produced them.
>
> I want to be able to plot predictions along some categorical variables.
>
> So what can I do in order to get predicted values but also know what
> variable values produced them?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From profjcnash at gmail.com  Thu Oct 20 15:26:23 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Thu, 20 Oct 2016 09:26:23 -0400
Subject: [R] nls.lm
In-Reply-To: <1A8C1289955EF649A09086A153E2672403FEAD5CBC@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <trinity-6990f702-31a2-4ab3-9d04-dfb58a40f5a6-1476904583462@3capp-gmx-bs28>
	<1A8C1289955EF649A09086A153E2672403FEAD5CBC@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <248822ac-a35b-2efb-db95-b4b517148cc5@gmail.com>

>From a statistician's point of view, "nonsense" may be OK, but there are other applications of R where
(partial or non-unique) solutions may be needed.

Yesterday I raised the question of how nonlinear least squares could be adapted to underdetermined problems.
Many folk are unaware of such possibilities, even in the linear case. In the nonlinear case, the m>n condition is
far from adequate to provide appropriate warnings to users. What should we do to detect non-unique solutions?

My interest is in building better nonlinear least squares and optimization software, and I find software users
(including R users) have some belief that those of us building the tools they use are magic wizards or fairy
godmothers who have provided everything they need in bullet-proof packages. This is so far from reality. All of
the tools I have worked with have weaknesses. To close the loopholes we need those "small reproducible examples",
including cases like these, so that better diagnostics can be devised.

We also need discussion on what to present as diagnostics and how to do so for maximum benefit and least
"get in the way". A two-way communication with users can aid immensely.

Sorry for the rant, but I'm in the midst of trying to prepare a unification of nls/nlmrt/minpack.lm and some
of the effort is pretty messy, especially in the area of derivatives and diagnostics.

Below is a little script that tries Berend's problem. The nonlinear least squares "runs" but the output fails
except for str(). The script will stop on failure at some points, so you need to paste some statements. I welcome
similar scripts/examples to build the necessary tests for improved packages.

JN

Here's the script.

# try to solve undetermined system by nonlinear least squares
X1 <- c(1,1)
Y1 <- c(1,1)
Z1 <- c(1,1)
RHS1 <- c(3,4)
X2 <- c(1,2)
RHS2 <- c(3,6)
mydata <- data.frame(X1, X2, Y1, Z1, RHS1, RHS2)
require(nlmrt)
st1 <- c(px=1,py=1,pz=1)
st0 <- c(px=0,py=0,pz=0)
sol10 <- nlxb(RHS1 ~ px*X1 + py*Y1 + pz*Z1, data=mydata, trace=1, start=st0)
summary(sol10)
print(sol10)
str(sol10)
sol11 <- nlxb(RHS1 ~ px*X1 + py*Y1 + pz*Z1, data=mydata, trace=1, start=st1)
summary(sol11)
print(sol11)
str(sol11)
## try RHS2
sol20 <- nlxb(RHS2 ~ px*X1 + py*Y1 + pz*Z1, data=mydata, trace=1, start=st0)
summary(sol20)
print(sol20)
str(sol20)
sol21 <- nlxb(RHS2 ~ px*X1 + py*Y1 + pz*Z1, data=mydata, trace=1, start=st1)
summary(sol21)
print(sol21)
str(sol21)
# change first column -- then we get solutions
sol220 <- nlxb(RHS2 ~ px*X2 + py*Y1 + pz*Z1, data=mydata, trace=1, start=st0)
summary(sol220)
print(sol220)
str(sol220)
sol221 <- nlxb(RHS2 ~ px*X2 + py*Y1 + pz*Z1, data=mydata, trace=1, start=st1)
summary(sol221)
print(sol221)
str(sol221)



On 16-10-20 07:05 AM, S Ellison wrote:
>> How do you reply to a specific post on this board instead of the thread?
> 
> You can reply to the individual, as I just did.
> 
> But I strongly suggest that you don't. You would be much better advised to discontinue debate and follow the essential advice given by nls.lm, which - no matter whether couched in terms of count of residuals - is simply to make sure that you have more independent data than variables when seeking a unique numerical solution by non-linear least squares. If you don't you'll get nonsense.
> 
> 
> S Ellison
> 
> 
> 
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From andreas.nord at biol.lu.se  Thu Oct 20 12:36:27 2016
From: andreas.nord at biol.lu.se (Andreas Nord)
Date: Thu, 20 Oct 2016 10:36:27 +0000
Subject: [R] outlier labels incorrectly assigned with ggplot2 box plot
Message-ID: <8ebdd81647654407a3e0fefe56f23479@biol.lu.se>

Dear list,

I want to label outliers in a ggplot box plot with the name of the subject for which outlying data were observed.


I have proceeded by creating a simple function to identify outliers:

is_outlier <- function(x) {

  return(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x))

}


And then the 'safe_ifelse' workaround to get 'ifelse' to function properly with factors.

safe.ifelse <- function(cond, yes, no) {

  class.y <- class(yes)

  if (class.y == "factor") {

    levels.y = levels(yes)

  }

  X <- ifelse(cond,yes,no)

  if (class.y == "factor") {

    X = as.factor(X)

    levels(X) = levels.y

  } else {

    class(X) <- class.y

  }

  return(X)

}


>From here, I have ran data through a dplyr pipeline to produce the plot.

**data at https://www.dropbox.com/s/2pcuuclxiqw1va1/data.csv?dl=0


library(dplyr)
data<-subset(data,data$variable1!='NA')
p1<-
  data %>%
  group_by(season,location) %>%
  mutate(outlier=safe.ifelse(is_outlier(variable1),subject,as.numeric(NA))) %>%
  ggplot(aes(x=factor(season),y=variable1))+
  geom_boxplot()+
  facet_wrap(~location,nrow=2)+
  guides(fill=FALSE)+
  geom_text(aes(label=outlier),na.rm=TRUE,hjust=1.5,size=2.5)

While outliers are correctly identified, labelling does not work as it should. Rather than getting subject-specific outlier labels, three levels of the 'subject' factor are printed repeatedly and erroneously (and seemingly randomly). Labelling outliers by their numerical values (i.e. by changing 'subject' to 'variable1' in the 'safe_ifelse function) does not cause problems.

I assume I am missing something obvious here - perhaps someone could kindly indicate where I am going wrong?

Thanks,
Andreas

	[[alternative HTML version deleted]]


From Anusha.Indhira at controlsdata.com  Thu Oct 20 10:25:50 2016
From: Anusha.Indhira at controlsdata.com (Indhira, Anusha)
Date: Thu, 20 Oct 2016 08:25:50 +0000
Subject: [R] need help in customising function in stat_summary function
	ggplot2
Message-ID: <CE1899A9C6A8D64099DFB344ECF0F754863F@DERCORCEXH02.ds-s.com>

Hi,

I would like to print percentage of points in a group which are greater than median value in boxplot. I have tried below code but it always prints zero in the graph. Can you let me know, how to modify code to get desired result?


perc.greaterthan.median <- function(x){
  cnt = 0
  for(i in 1:length(x)){
   ifelse(x[i] > median(x),cnt+1,cnt)
  }
  return(c(y = median(x)*1.7, label = round((cnt/length(x))*100,2)))
}

ggplot(st_chg_51, aes(x=factor(st_dv), P3))+ #label=rownames(st_chg_51))) +
  geom_boxplot(fill = "grey80", colour = "#3366FF") +
  stat_summary(fun.data = perc.greaterthan.median, geom = "text", fun.y = median) +
  theme_bw()+theme(axis.text = element_text(angle = 90, hjust = 1))

Why does cnt in the function doesn't get incremented in the loop?

Thanks,
Anusha

This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Oct 20 17:33:57 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 20 Oct 2016 15:33:57 +0000
Subject: [R] need help in customising function in stat_summary
	function	ggplot2
In-Reply-To: <CE1899A9C6A8D64099DFB344ECF0F754863F@DERCORCEXH02.ds-s.com>
References: <CE1899A9C6A8D64099DFB344ECF0F754863F@DERCORCEXH02.ds-s.com>
Message-ID: <b048ef81c74247a9991c49317d73310d@exch-2p-mbx-w2.ads.tamu.edu>

You do know that the median is defined as the point with half the values above it and half below it? For even sample sizes it will always be 50%.

Your function is not working because you used the ifelse() function instead of the programming command if() else:

> ?Control # Note the capital "C"
> ?ifelse

But you do not understand basic R so you should spend some time using a tutorial before you try to write functions. 

> set.seed(42)    # Set random number seed
> x <- rnorm(100) # Draw 100 random normal values with mean=0 and sd=1
> sum(x > median(x))/length(x)*100  # Compute the % greater than the median
[1] 50

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Indhira, Anusha
Sent: Thursday, October 20, 2016 3:26 AM
To: r-help at r-project.org
Subject: [R] need help in customising function in stat_summary function ggplot2

Hi,

I would like to print percentage of points in a group which are greater than median value in boxplot. I have tried below code but it always prints zero in the graph. Can you let me know, how to modify code to get desired result?


perc.greaterthan.median <- function(x){
  cnt = 0
  for(i in 1:length(x)){
   ifelse(x[i] > median(x),cnt+1,cnt)
  }
  return(c(y = median(x)*1.7, label = round((cnt/length(x))*100,2)))
}

ggplot(st_chg_51, aes(x=factor(st_dv), P3))+ #label=rownames(st_chg_51))) +
  geom_boxplot(fill = "grey80", colour = "#3366FF") +
  stat_summary(fun.data = perc.greaterthan.median, geom = "text", fun.y = median) +
  theme_bw()+theme(axis.text = element_text(angle = 90, hjust = 1))

Why does cnt in the function doesn't get incremented in the loop?

Thanks,
Anusha

This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bjpmodi2016 at gmail.com  Thu Oct 20 17:59:46 2016
From: bjpmodi2016 at gmail.com (Narendra Modi)
Date: Thu, 20 Oct 2016 10:59:46 -0500
Subject: [R] Optimize selected variables but not all - nloptr
In-Reply-To: <a71e58fb-591a-7766-08de-1887d676d5ec@gmail.com>
References: <CAPq=xQBwiSetEFd5dmgX8vALsaDi8AkOk=Rvn_hT+qF273x6Lg@mail.gmail.com>
	<a71e58fb-591a-7766-08de-1887d676d5ec@gmail.com>
Message-ID: <CAPq=xQBUN=wTJmMNBtvkdUXU3xQwXgbKTBK1FYjC8duY=-e2Pw@mail.gmail.com>

Thanks Prof Nash.
The reason I used nlopr() in my problem is due to non linear
constraints. I wonder if optimrx/optim can model the below scenario. I
will be elated if it can.
The problem in hand goes like this:

There are 2 injectors and 2 producers. Consider these as some entity.

I have an actual dataset, Act.Matrix; assume row=50, col=2.
The predicted dataset is calculated by using the attached equation,
i.e for each row of the prediction, that equation is used.

The parameters to be evaluated are Tau, and a set of Fij's such that
sum of Fij's <=1 .
Fij represents connectivity between each inj to each prod, hence for
this example there will be a total of 4 fij. and 2 tau (one tau for
each producer)

The lb for each parameter that I provided is 0 and ub as Inf

    TAU                 fij                fij2
>>  [1,] 14.3      0.01        0.01449572
>>  [2,] 14.3      0.2          0.00000000

The constraints being Sum of each column of Fij<=1.

With nloptr (algorithm NLOPT_LN_COYLA) , I am able to solve it to some
extent. but when the dataset is scaled (consider having 50 producers
and 25 injectors!! ), the number of variables to be solved is much
higher!

Do you think OPTIMX/OPTIMRX can handle non linear constraints like
that? if it can then I can definitely use the MASKED parameters.

NM


On Wed, Oct 19, 2016 at 8:48 PM, ProfJCNash <profjcnash at gmail.com> wrote:
> I refer to such parameters as "masked" in my 2014 book Nonlinear parameter optimization with R tools.
> Recently I put package optimrx on R-forge (and optimr with fewer solvers on CRAN) that allows for masks with
> all the parameters. The masks can be specified as you suggest with start=lower=upper. However, for reasons
> I won't go into here, nloptr solvers are not yet included. However, I suspect either Rvmmin or Rcgmin will
> work fine.
>
> I will guess that nloptr does NOT cater for masks.
>
> JN
>
> On 16-10-19 05:59 PM, Narendra Modi wrote:
>> Hello All,
>> I have a matrix with initial values as below and I need to optimize
>> the variables that are greater than 0.
>>
>>           TAU       fij      fij2
>>  [1,] 14.33375 0.0000000 0.01449572
>>  [2,] 14.33375 0.0000000 0.00000000
>>  [3,] 14.33375 0.0000000 0.00000000
>>  [4,] 14.33375 0.0000000 0.02206446
>>  [5,] 14.33375 0.0000000 0.00000000
>>  [6,] 14.33375 0.0000000 0.00000000
>>  [7,] 14.33375 0.0000000 0.00000000
>>  [8,] 14.33375 0.8279846 0.00000000
>>  [9,] 14.33375 0.0000000 0.03695833
>> [10,] 14.33375 0.0000000 0.00000000
>>
>> Or structure(c(14.3337481730129, 14.3337481730129, 14.3337481730129,
>> 14.3337481730129, 14.3337481730129, 14.3337481730129, 14.3337481730129,
>> 14.3337481730129, 14.3337481730129, 14.3337481730129, 0, 0, 0,
>> 0, 0, 0, 0, 0.827984553120177, 0, 0, 0.0144957197835888, 0, 0,
>> 0.0220644627842788, 0, 0, 0, 0, 0.0369583294835073, 0), .Dim = c(10L,
>> 3L), .Dimnames = list(NULL, c("TAU", "fij", "fij2")))
>>
>> Is it possible to provide lowerbound and upperbound as 0 for variables
>> (< 0 in the initial matrix) and nloptr will consider them "unchanged"
>> during optimization?
>>
>> Rstudio crashes when I try to do that. Is this a bug or I should
>> approach it differently?
>>
>> NM
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: equation.PNG
Type: image/png
Size: 6087 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161020/82e67e1b/attachment.png>

From wdunlap at tibco.com  Thu Oct 20 18:17:29 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 20 Oct 2016 09:17:29 -0700
Subject: [R] need help in customising function in stat_summary function
	ggplot2
In-Reply-To: <CE1899A9C6A8D64099DFB344ECF0F754863F@DERCORCEXH02.ds-s.com>
References: <CE1899A9C6A8D64099DFB344ECF0F754863F@DERCORCEXH02.ds-s.com>
Message-ID: <CAF8bMcavru0uiCDOWEUXN4VcTf_1QecLm9AzUWVS3wbo7dqjqA@mail.gmail.com>

Your code,
  cnt = 0
  for(i in 1:length(x)){
   ifelse(x[i] > median(x),cnt+1,cnt)
  }
sets cnt to zero and never sets it to anything else.  Hence it is zero
at the end of the loop.  if you set cnt to the value of your call to ifelse
you should get the desired result
    cnt <- ifelse(x[i] > median(x),cnt+1,cnt)

By the way, the more R-ish way of counting the number of x strictly
greater than the median is just
   cnt <- sum(x > median(x))
instead of those 4 lines above.
('cnt' should be about length(x)/2 unless there are a lot of points at the
median).

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Oct 20, 2016 at 1:25 AM, Indhira, Anusha <
Anusha.Indhira at controlsdata.com> wrote:

> Hi,
>
> I would like to print percentage of points in a group which are greater
> than median value in boxplot. I have tried below code but it always prints
> zero in the graph. Can you let me know, how to modify code to get desired
> result?
>
>
> perc.greaterthan.median <- function(x){
>   cnt = 0
>   for(i in 1:length(x)){
>    ifelse(x[i] > median(x),cnt+1,cnt)
>   }
>   return(c(y = median(x)*1.7, label = round((cnt/length(x))*100,2)))
> }
>
> ggplot(st_chg_51, aes(x=factor(st_dv), P3))+ #label=rownames(st_chg_51))) +
>   geom_boxplot(fill = "grey80", colour = "#3366FF") +
>   stat_summary(fun.data = perc.greaterthan.median, geom = "text", fun.y =
> median) +
>   theme_bw()+theme(axis.text = element_text(angle = 90, hjust = 1))
>
> Why does cnt in the function doesn't get incremented in the loop?
>
> Thanks,
> Anusha
>
> This e-mail (including attachments) contains contents owned by Rolls-Royce
> plc and its subsidiaries, affiliated companies or customers and covered by
> the laws of England and Wales, Brazil, US, or Canada (federal, state or
> provincial). The information is intended to be confidential and may be
> legally privileged. If you are not the intended recipient, you are hereby
> notified that any retention, dissemination, distribution, interception or
> copying of this communication is strictly prohibited and may subject you to
> further legal action. Reply to the sender if you received this email by
> accident, and then delete the email and any attachments.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Thu Oct 20 18:20:17 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 20 Oct 2016 09:20:17 -0700 (PDT)
Subject: [R] Lattice xyplot(): adding a legend
In-Reply-To: <E6104510-8BEE-4F75-AF7B-AC68421BBB5D@comcast.net>
References: <alpine.LNX.2.11.1610191038100.8962@localhost>
	<0DA29E48-DEA2-4C47-AEA5-F0331EF2B58E@comcast.net>
	<alpine.LNX.2.11.1610191242060.8962@localhost>
	<alpine.LNX.2.11.1610191556470.8962@localhost>
	<E6104510-8BEE-4F75-AF7B-AC68421BBB5D@comcast.net>
Message-ID: <alpine.LNX.2.11.1610200901060.18589@localhost>

On Wed, 19 Oct 2016, David Winsemius wrote:

> I am getting annoyed, exhausted, and frustrated reading code like that.
> Never, ever, ... ever, use the "$" operator in a formula. Use the 'data'
> argument and the 'formula' as they are supposed to be used.

David,

   I apologize for annoying, exhausting, and frustrating you. It is not my
intent and I learned to use the data argument and not the "$" operator a
while ago. I have not be able to find why that's not working here.

   Following the 'usage' section in ?xyplot I specify 'x'/'formula' followed
by the data specification. When I omit the "$" operator R (version 3.3.1)
displays an empty device window and an error message (shown below the source
file). The dput() file is attached and the script presented here:

----
# This scatter plot displays amount by day for each station, distinguished
# by color. 'plot-rain-by-date.R'

# load rain data file
rain <- read.table("daily_records.dat", header = TRUE, sep = ",", quote = "\"\"")
rain$date <- as.Date(rain$date)

# Create a factor from the date
raindate <- as.factor(rain$date)

# Save original plotting parameters
opar <- par(xpd=NA,no.readonly=T)

# Prepare the plot of the data
rainbyday <- xyplot(rain$amount ~ raindate, data = rain, main = "Area Precipitation",
                     ylab = "Daily Total Amount (in)", xlab = "Date",
                     scales = list(x=list(at=c(1,8,15,22,29,36,43,50,57,62), rot = 90),
                         y = list(at=c(min(rain$amount), max(rain$amount)))),
                     pch = 20,
                     col = c("black","red","dark green","dark blue","dark goldenrod","dark magenta"),
                     key = simpleKey(text = levels(rain$station)[1:6],
                         x = 0.2, y = 0.6, corner = c(0, 0), points = TRUE),
                     par.settings = list(plot.symbol = list(c("black","red","dark green","dark blue",
                                             "dark goldenrod","dark magenta"), pch = 20, cex = 1.2)))

# Plot it
plot(rainbyday)

# Reset display parameters
par(opar)
-----

   When I eliminate the "$" operator this is the error message:
> source("plot-rain-by-day.R")
Error in xyplot.formula(amount ~ raindate, data = rain, main =
  "Area Precipitation",  (from plot-rain-by-day.R#14) :
   object 'amount' not found

   The "$" operator appears 4 times; removing any one (or all) of them
produces the same not found error. If there's another syntax error in the
xyplot() call, or a logic error in the script please show me my mistake.

   With the "$" operator there's no error, but the key does not use pch=20;
have I mis-placed Duncan's suggested par.settings?

Rich


-------------- next part --------------
structure(list(station = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L), .Label = c("0.3E", 
"0.6W", "1..0WNW", "1.5N", "4.3WNW", "Airport"), class = "factor"), 
    date = structure(c(32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 
    40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 51L, 
    52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 1L, 
    2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
    27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 
    39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 
    51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 
    1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
    27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 
    39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 
    51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 
    1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
    27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 
    39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 
    51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 
    1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
    27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 
    39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 
    51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 
    1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
    27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 
    39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 
    51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L
    ), .Label = c("2013-12-01", "2013-12-02", "2013-12-03", "2013-12-04", 
    "2013-12-05", "2013-12-06", "2013-12-07", "2013-12-08", "2013-12-09", 
    "2013-12-10", "2013-12-11", "2013-12-12", "2013-12-13", "2013-12-14", 
    "2013-12-15", "2013-12-16", "2013-12-17", "2013-12-18", "2013-12-19", 
    "2013-12-20", "2013-12-21", "2013-12-22", "2013-12-23", "2013-12-24", 
    "2013-12-25", "2013-12-26", "2013-12-27", "2013-12-28", "2013-12-29", 
    "2013-12-30", "2013-12-31", "2014-01-01", "2014-01-02", "2014-01-03", 
    "2014-01-04", "2014-01-05", "2014-01-06", "2014-01-07", "2014-01-08", 
    "2014-01-09", "2014-01-10", "2014-01-11", "2014-01-12", "2014-01-13", 
    "2014-01-14", "2014-01-15", "2014-01-16", "2014-01-17", "2014-01-18", 
    "2014-01-19", "2014-01-20", "2014-01-21", "2014-01-22", "2014-01-23", 
    "2014-01-24", "2014-01-25", "2014-01-26", "2014-01-27", "2014-01-28", 
    "2014-01-29", "2014-01-30", "2014-01-31"), class = "factor"), 
    amount = c(NA, NA, 0.01, 0, 0, 0, 0.1, 0.22, 0.49, 0.12, 
    0.47, 0.7, 0.24, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0, 0, 
    0.01, NA, 0, 0, 0, NA, 0.07, 0.48, 0.03, NA, 0.32, 0.92, 
    0.04, NA, 0, 0.01, 0.01, 0, 0, NA, 0, 0, 0.08, 0.01, 0.02, 
    0.01, 0.01, NA, 0.09, 0.02, 0.13, 0.01, NA, 0.02, 0.01, 0.01, 
    NA, NA, NA, 0, 0.04, 0.02, 0.01, 0.02, 0.01, NA, 0, 0.11, 
    0.24, 0.54, 0.15, 0.48, 0.02, 0.01, NA, 0.01, NA, NA, 0, 
    0, 0, 0, 0, 0, 0.06, 0.48, 0.03, 0.03, NA, NA, NA, NA, 0.05, 
    0, 0, 0.01, 0, 0, 0, 0, 0, NA, 0.07, 0, 0.01, 0.02, 0.01, 
    0.01, 0.1, 0.01, 0.01, 0, 0, 0.04, 0.01, NA, 0, 0.01, 0.01, 
    0, 0.05, NA, NA, 0.01, 0.01, 0.02, 0, 0, 0, 0.11, 0.22, 0.54, 
    0.54, 0.44, 0.71, 0.21, 0.01, 0.02, 0.01, 0.01, 0.01, 0.01, 
    0, 0, 0, 0, 0, 0, 0, 0, 0.06, 0.46, 0.02, 0.02, 0.87, 0.1, 
    0, 0, 0, NA, 0, 0, 0, 0, 0, 0.07, 0.01, 0.01, 0.02, 0, 0, 
    0.07, 0, 0.1, NA, NA, 0.02, NA, 0, 0, 0, 0, 0, NA, 0.05, 
    0, 0.01, 0.01, 0, 0, 0.05, 0.27, 0.42, 0.06, 0.01, 0.9, 0.36, 
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06, 0.36, 0.12, 
    0.01, 0.05, 0.25, 0.91, 0.03, 0, 0, NA, 0, 0, 0, 0, 0, 0, 
    0.07, NA, 0.01, 0.01, 0.01, NA, 0.09, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, 0.01, 0.01, 0.01, 0, 0, 0, 0.11, 
    0.23, 0.49, 0.1, 0.45, 0.6, 0.28, 0, 0.01, NA, 0, 0, 0, 0, 
    0, 0, 0, 0, 0, 0, 0, 0.06, 0.48, 0.02, 0.02, 0.4, 1.06, 0.13, 
    0, 0, 0.03, 0.01, 0, 0, 0, 0, 0, 0.12, 0.02, NA, NA, NA, 
    NA, NA, 0.03, 0.24, 0.02, 0.02, 0.05, 0.01, 0, NA, 0, 0.02, 
    0, 0.01, 0.04, 0.02, 0.04, 0.01, NA, 0, 0.13, 0.34, 0.84, 
    0.61, 0.61, 1, 0.44, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 
    0.02, 0.02, 0.02, 0.01, NA, 0, 0, 0, 0.07, 0.62, 0.1, 0.05
    )), .Names = c("station", "date", "amount"), class = "data.frame", row.names = c(NA, 
-341L))

From msharp at txbiomed.org  Thu Oct 20 18:20:31 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Thu, 20 Oct 2016 16:20:31 +0000
Subject: [R] need help in customising function in stat_summary
	function	ggplot2
In-Reply-To: <CE1899A9C6A8D64099DFB344ECF0F754863F@DERCORCEXH02.ds-s.com>
References: <CE1899A9C6A8D64099DFB344ECF0F754863F@DERCORCEXH02.ds-s.com>
Message-ID: <6A7B028C-7F27-4610-AE0A-B5FB39FDADFF@TxBiomed.org>

Indhira,

You have to assign cnt and new value in the loop if you want it to update in the loop. However, to count the number of values of x > median(x), there are multiple options. You are using a loop where none is needed in R, which has many implicit vector functions that run with relational operators and assignments.

x <- rnorm(10)
cnt <- sum(ifelse(x > median(x), 1, 0))

Because TRUE evaluates to 1 and FALSE evaluates to 0, you can also use
cnt <- sum(x > median(x))

I cannot help you with the ggplot question directly since you have not provided a definition of the object st_chg_51.

Mark

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Oct 20, 2016, at 3:25 AM, Indhira, Anusha <Anusha.Indhira at controlsdata.com> wrote:
>
> Hi,
>
> I would like to print percentage of points in a group which are greater than median value in boxplot. I have tried below code but it always prints zero in the graph. Can you let me know, how to modify code to get desired result?
>
>
> perc.greaterthan.median <- function(x){
>  cnt = 0
>  for(i in 1:length(x)){
>   ifelse(x[i] > median(x),cnt+1,cnt)
>  }
>  return(c(y = median(x)*1.7, label = round((cnt/length(x))*100,2)))
> }
>
> ggplot(st_chg_51, aes(x=factor(st_dv), P3))+ #label=rownames(st_chg_51))) +
>  geom_boxplot(fill = "grey80", colour = "#3366FF") +
>  stat_summary(fun.data = perc.greaterthan.median, geom = "text", fun.y = median) +
>  theme_bw()+theme(axis.text = element_text(angle = 90, hjust = 1))
>
> Why does cnt in the function doesn't get incremented in the loop?
>
> Thanks,
> Anusha
>
> This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From ruipbarradas at sapo.pt  Thu Oct 20 18:28:21 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 20 Oct 2016 17:28:21 +0100
Subject: [R] findInterval() surprising behavior
In-Reply-To: <BDC53031-2102-4341-BD9A-8E4F7816CEB3@gmail.com>
References: <1476731005.578838968@f384.i.mail.ru> <58052B03.9040607@sapo.pt>
	<BDC53031-2102-4341-BD9A-8E4F7816CEB3@gmail.com>
Message-ID: <5808F0A5.2010106@sapo.pt>

Thanks.
It really seemed to be a bug.

Rui Barradas

Em 20-10-2016 11:33, Peter Dalgaard escreveu:
> It's a bug (left.open=FALSE code gets executed in some cases). Hoping to have a fix tested and in place before 3.3.2.
>
> -pd
>
>> On 17 Oct 2016, at 21:48 , Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>> Same on Windows 7.
>>
>>> findInterval(x=c(6, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE)
>> [1] 4 2 1 1
>>> findInterval(x=c(4, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE)
>> [1] 3 1 1 1
>>> sessionInfo()
>> R version 3.3.1 (2016-06-21)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>> locale:
>> [1] LC_COLLATE=Portuguese_Portugal.1252 LC_CTYPE=Portuguese_Portugal.1252
>> [3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C
>> [5] LC_TIME=Portuguese_Portugal.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] lattice_0.20-33
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.3.1 grid_3.3.1
>>
>> Rui Barradas
>>
>> Em 17-10-2016 20:03, Dmitriy Chernykh via R-help escreveu:
>>> Hello,
>>>
>>> I call function findInterval in the following way:
>>>
>>> findInterval(x=c(6, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE),
>>>
>>> and expect that it will return 4 1 1 1. But the function returns 4 2 1 1 instead. Moreover, if I change the first element in x to, say, 4 -
>>>
>>> findInterval(x=c(4, 1, 1, 1), vec=c(0, 1, 3, 5, 10), left.open=TRUE)
>>>
>>> then the function returns 3 1 1 1.
>>>
>>> Why are results for identical elements in x not the same? And why is element in x influenced by previous one? I suspect this is a bug but I am not 100% sure.
>>>
>>> Technical details:
>>>
>>> sessionInfo()
>>> R version 3.3.1 (2016-06-21)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Ubuntu 14.04.5 LTS
>>>
>>> locale:
>>>   [1] LC_CTYPE=ru_RU.UTF-8       LC_NUMERIC=C               LC_TIME=ru_RU.UTF-8        LC_COLLATE=ru_RU.UTF-8     LC_MONETARY=ru_RU.UTF-8
>>>   [6] LC_MESSAGES=ru_RU.UTF-8    LC_PAPER=ru_RU.UTF-8       LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=ru_RU.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_3.3.1
>>>
>>>
>>> Thanks.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Thu Oct 20 19:02:42 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 20 Oct 2016 10:02:42 -0700
Subject: [R] Lattice xyplot(): adding a legend
In-Reply-To: <alpine.LNX.2.11.1610200901060.18589@localhost>
References: <alpine.LNX.2.11.1610191038100.8962@localhost>
	<0DA29E48-DEA2-4C47-AEA5-F0331EF2B58E@comcast.net>
	<alpine.LNX.2.11.1610191242060.8962@localhost>
	<alpine.LNX.2.11.1610191556470.8962@localhost>
	<E6104510-8BEE-4F75-AF7B-AC68421BBB5D@comcast.net>
	<alpine.LNX.2.11.1610200901060.18589@localhost>
Message-ID: <CAGxFJbRdXN_E1q5om1xT-Hs6RkwaSgpunr-_b9gr0E4OU9v2BQ@mail.gmail.com>

1. Your par(), opar() business is junk -- lattice displays do not use or
modify these. See ?trellis.par.set .

2. You do *not* need rain$ in your formula with the data=rain argument; you
*do* need it in the at argument and elsewhere. The data argument only
controls where the variables in the formula (or subset or group) are
evaluated. This is clearly stated in ?xyplot. Did you read it?

If that doesn't work, your data are screwed up. Incidentally, I counted 3
times where rain$ appears, not 4. Did I miss one or did you err?

3. *Please* reread the key documentation in xyplot carefully. The key
parameters are determined by the points, etc component lists of the key.
The par.settings list controls the **plot** settings.

Finally, are you sure you want date as a factor? Wouldn't that get the date
order all messed up?

Please note that all of this is clearly documented. It's terse, but it's
there. You need to pay careful attention, and then you,David, and everyone
else will be happy and free of frustration.

Bert

On Oct 20, 2016 6:21 PM, "Rich Shepard" <rshepard at appl-ecosys.com> wrote:

> On Wed, 19 Oct 2016, David Winsemius wrote:
>
> I am getting annoyed, exhausted, and frustrated reading code like that.
>> Never, ever, ... ever, use the "$" operator in a formula. Use the 'data'
>> argument and the 'formula' as they are supposed to be used.
>>
>
> David,
>
>   I apologize for annoying, exhausting, and frustrating you. It is not my
> intent and I learned to use the data argument and not the "$" operator a
> while ago. I have not be able to find why that's not working here.
>
>   Following the 'usage' section in ?xyplot I specify 'x'/'formula' followed
> by the data specification. When I omit the "$" operator R (version 3.3.1)
> displays an empty device window and an error message (shown below the
> source
> file). The dput() file is attached and the script presented here:
>
> ----
> # This scatter plot displays amount by day for each station, distinguished
> # by color. 'plot-rain-by-date.R'
>
> # load rain data file
> rain <- read.table("daily_records.dat", header = TRUE, sep = ",", quote =
> "\"\"")
> rain$date <- as.Date(rain$date)
>
> # Create a factor from the date
> raindate <- as.factor(rain$date)
>
> # Save original plotting parameters
> opar <- par(xpd=NA,no.readonly=T)
>
> # Prepare the plot of the data
> rainbyday <- xyplot(rain$amount ~ raindate, data = rain, main = "Area
> Precipitation",
>                     ylab = "Daily Total Amount (in)", xlab = "Date",
>                     scales = list(x=list(at=c(1,8,15,22,29,36,43,50,57,62),
> rot = 90),
>                         y = list(at=c(min(rain$amount),
> max(rain$amount)))),
>                     pch = 20,
>                     col = c("black","red","dark green","dark blue","dark
> goldenrod","dark magenta"),
>                     key = simpleKey(text = levels(rain$station)[1:6],
>                         x = 0.2, y = 0.6, corner = c(0, 0), points = TRUE),
>                     par.settings = list(plot.symbol =
> list(c("black","red","dark green","dark blue",
>                                             "dark goldenrod","dark
> magenta"), pch = 20, cex = 1.2)))
>
> # Plot it
> plot(rainbyday)
>
> # Reset display parameters
> par(opar)
> -----
>
>   When I eliminate the "$" operator this is the error message:
>
>> source("plot-rain-by-day.R")
>>
> Error in xyplot.formula(amount ~ raindate, data = rain, main =
>  "Area Precipitation",  (from plot-rain-by-day.R#14) :
>   object 'amount' not found
>
>   The "$" operator appears 4 times; removing any one (or all) of them
> produces the same not found error. If there's another syntax error in the
> xyplot() call, or a logic error in the script please show me my mistake.
>
>   With the "$" operator there's no error, but the key does not use pch=20;
> have I mis-placed Duncan's suggested par.settings?
>
> Rich
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From profjcnash at gmail.com  Thu Oct 20 19:28:00 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Thu, 20 Oct 2016 13:28:00 -0400
Subject: [R] Optimize selected variables but not all - nloptr
In-Reply-To: <CAPq=xQBUN=wTJmMNBtvkdUXU3xQwXgbKTBK1FYjC8duY=-e2Pw@mail.gmail.com>
References: <CAPq=xQBwiSetEFd5dmgX8vALsaDi8AkOk=Rvn_hT+qF273x6Lg@mail.gmail.com>
	<a71e58fb-591a-7766-08de-1887d676d5ec@gmail.com>
	<CAPq=xQBUN=wTJmMNBtvkdUXU3xQwXgbKTBK1FYjC8duY=-e2Pw@mail.gmail.com>
Message-ID: <81421af0-11d5-28dd-2845-4a4ae2c20a2d@gmail.com>

optimr/optimrx are for unconstrained and bounds constrained problems.

I think you are going to have to do the masking yourself. It's more messy and tedious than
difficult. The optimization is on a new set of parameters newpar that has
fewer components, so in your objective function and constraints you have to expand it to the
full set of parameters, putting in the fixed values. A bit of back and forth, but
it does work.

However, do test, test, test to make sure things are working before you try the
optimization. It is REALLY easy to make a silly mistake. I see someone who has
made lots every time I look in a mirror.

Best,

JN



On 16-10-20 11:59 AM, Narendra Modi wrote:
> Thanks Prof Nash.
> The reason I used nlopr() in my problem is due to non linear
> constraints. I wonder if optimrx/optim can model the below scenario. I
> will be elated if it can.
> The problem in hand goes like this:
> 
> There are 2 injectors and 2 producers. Consider these as some entity.
> 
> I have an actual dataset, Act.Matrix; assume row=50, col=2.
> The predicted dataset is calculated by using the attached equation,
> i.e for each row of the prediction, that equation is used.
> 
> The parameters to be evaluated are Tau, and a set of Fij's such that
> sum of Fij's <=1 .
> Fij represents connectivity between each inj to each prod, hence for
> this example there will be a total of 4 fij. and 2 tau (one tau for
> each producer)
> 
> The lb for each parameter that I provided is 0 and ub as Inf
> 
>     TAU                 fij                fij2
>>>  [1,] 14.3      0.01        0.01449572
>>>  [2,] 14.3      0.2          0.00000000
> 
> The constraints being Sum of each column of Fij<=1.
> 
> With nloptr (algorithm NLOPT_LN_COYLA) , I am able to solve it to some
> extent. but when the dataset is scaled (consider having 50 producers
> and 25 injectors!! ), the number of variables to be solved is much
> higher!
> 
> Do you think OPTIMX/OPTIMRX can handle non linear constraints like
> that? if it can then I can definitely use the MASKED parameters.
> 
> NM
> 
> 
> On Wed, Oct 19, 2016 at 8:48 PM, ProfJCNash <profjcnash at gmail.com> wrote:
>> I refer to such parameters as "masked" in my 2014 book Nonlinear parameter optimization with R tools.
>> Recently I put package optimrx on R-forge (and optimr with fewer solvers on CRAN) that allows for masks with
>> all the parameters. The masks can be specified as you suggest with start=lower=upper. However, for reasons
>> I won't go into here, nloptr solvers are not yet included. However, I suspect either Rvmmin or Rcgmin will
>> work fine.
>>
>> I will guess that nloptr does NOT cater for masks.
>>
>> JN
>>
>> On 16-10-19 05:59 PM, Narendra Modi wrote:
>>> Hello All,
>>> I have a matrix with initial values as below and I need to optimize
>>> the variables that are greater than 0.
>>>
>>>           TAU       fij      fij2
>>>  [1,] 14.33375 0.0000000 0.01449572
>>>  [2,] 14.33375 0.0000000 0.00000000
>>>  [3,] 14.33375 0.0000000 0.00000000
>>>  [4,] 14.33375 0.0000000 0.02206446
>>>  [5,] 14.33375 0.0000000 0.00000000
>>>  [6,] 14.33375 0.0000000 0.00000000
>>>  [7,] 14.33375 0.0000000 0.00000000
>>>  [8,] 14.33375 0.8279846 0.00000000
>>>  [9,] 14.33375 0.0000000 0.03695833
>>> [10,] 14.33375 0.0000000 0.00000000
>>>
>>> Or structure(c(14.3337481730129, 14.3337481730129, 14.3337481730129,
>>> 14.3337481730129, 14.3337481730129, 14.3337481730129, 14.3337481730129,
>>> 14.3337481730129, 14.3337481730129, 14.3337481730129, 0, 0, 0,
>>> 0, 0, 0, 0, 0.827984553120177, 0, 0, 0.0144957197835888, 0, 0,
>>> 0.0220644627842788, 0, 0, 0, 0, 0.0369583294835073, 0), .Dim = c(10L,
>>> 3L), .Dimnames = list(NULL, c("TAU", "fij", "fij2")))
>>>
>>> Is it possible to provide lowerbound and upperbound as 0 for variables
>>> (< 0 in the initial matrix) and nloptr will consider them "unchanged"
>>> during optimization?
>>>
>>> Rstudio crashes when I try to do that. Is this a bug or I should
>>> approach it differently?
>>>
>>> NM
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From mviljamaa at kapsi.fi  Thu Oct 20 19:33:38 2016
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Thu, 20 Oct 2016 20:33:38 +0300
Subject: [R] How is label parameter used in text() when passing it a vector?
Message-ID: <afdf6993a61cff7388c55c864513a780@kapsi.fi>

I have a slight doubt with using text() with the label parameter having 
to contain a vector of of integers (specifically integers in the range 
[1, 21] corresponding to factors of my categorical variable that I want 
to numbers to tell).

What I'm currently plotting is the following command:

text(dta[trt == 0 & skin == 1 & gender == 0,]$age,invlogit(predict(fit5, 
newdata=dta[trt == 0 & skin == 1 & gender == 0,])),label=1:21, col = 
dta[trt == 0 & skin == 1 & gender == 0,]$exposure)

(it's a plot of a logistic model)

$exposure is the categorical variable that takes values of integers in 
the range [1, 21]. The coloring seems to work, but I'm not sure whether 
label=1:21 makes it so that it actually labels the point with the 
corresponding exposure level or whether it just walks through 1 to 21 
and 1 to 21 over and over again.

Can someone explain?

Also how can I get the label parameter to put the number of the level of 
the exposure as the corresponding point?


From pauljohn32 at gmail.com  Thu Oct 20 19:58:01 2016
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 20 Oct 2016 12:58:01 -0500
Subject: [R] Error installing packages
In-Reply-To: <688D86A9-2295-4951-B96F-9C502FF69F29@comcast.net>
References: <467607ff-45a2-cd8e-cc5c-ce69095cdca0@utoronto.ca>
	<688D86A9-2295-4951-B96F-9C502FF69F29@comcast.net>
Message-ID: <CAErODj_NoMF_Xf7x9w1i+PYrJR-nNO1HxYKSpTD9JD_xD8ym+w@mail.gmail.com>

On Wed, Oct 19, 2016 at 10:31 AM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
>> On Oct 19, 2016, at 4:54 AM, Kevin E. Thorpe <kevin.thorpe at utoronto.ca> wrote:
>>
>> Hello.
>>
>> I am posting this on behalf of one of my students who is getting error messages when installing some packages. I have not seen this before nor have I been able to replicate it. I'm including the relevant (I think) information. I get the students to install rms with dependencies. As you can see, rms does get installed but when the attempt is made to attach it, ggplot2 cannot be loaded. Thus I tried explicitly installing ggplot2 and you can see then ensuing errors below. I have included the sessionInfo() at the end.
>>
>> I hope someone can point me at a solution.
>>

I have just seen this on Win10 for the first time on a student's new
laptop.  Anti-virus software is possible reason for this, but I don't
know.

I did find a very direct solution.

WHen you run the package install, and it says "cannot move from
temporary C:\Users\yourname\AppData\XYZ to user directory
C:\Users\yourname\Documents\R\site-library", just move the folder
manually.  It works every time.

Unfortunately, Windows hides AppData.  In the Windows explorer view
options, tell it not to hide protected files.  Then in explorer
navigate into the user's AppData\Temp\Rxxx folder, you'll see the
downloaded zip files there for Rcpp and such.  Doubleclick the zip
file, right click copy the directory name "Rcpp" and paste it into the
user's R folder, under C:/Users/yourname/Documents/R/3.3/site-library
(or whatever that's called).

We ran into about 2 packages that have this failure to copy from
temporary space, but this old-fashioned copy a folder over method
worked fine. After this, R was able to load Rcpp, RcppEigen.

There is no indication that those R files are in a virus quarantine,
so I can't say for sure the security software is the cause.  At first,
I thought the problem was the usual one that we have been aware of for
some time--Windows thinks those files are in use and will not replace
them.

 We are trying to remove a layer of virus protection programs
installed by Dell to see if this happens later. If I hear back from
that student, I'll let you know. Another layer in this story is that
her 30 day free trials were expired, and I have feeling this means
that not only is McAfee still installed, but it is also running but
refusing to let you interact with it.

pj

-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

I only use this account for email list memberships. To write directly,
address me at pauljohn at ku.edu.


From dwinsemius at comcast.net  Thu Oct 20 20:19:09 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 20 Oct 2016 11:19:09 -0700
Subject: [R] Lattice xyplot(): adding a legend
In-Reply-To: <alpine.LNX.2.11.1610200901060.18589@localhost>
References: <alpine.LNX.2.11.1610191038100.8962@localhost>
	<0DA29E48-DEA2-4C47-AEA5-F0331EF2B58E@comcast.net>
	<alpine.LNX.2.11.1610191242060.8962@localhost>
	<alpine.LNX.2.11.1610191556470.8962@localhost>
	<E6104510-8BEE-4F75-AF7B-AC68421BBB5D@comcast.net>
	<alpine.LNX.2.11.1610200901060.18589@localhost>
Message-ID: <E9D1863F-4355-4CD2-8D97-CA69646C346B@comcast.net>


> On Oct 20, 2016, at 9:20 AM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Wed, 19 Oct 2016, David Winsemius wrote:
> 
>> I am getting annoyed, exhausted, and frustrated reading code like that.
>> Never, ever, ... ever, use the "$" operator in a formula. Use the 'data'
>> argument and the 'formula' as they are supposed to be used.
> 
> David,
> 
>  I apologize for annoying, exhausting, and frustrating you. It is not my
> intent and I learned to use the data argument and not the "$" operator a
> while ago. I have not be able to find why that's not working here.
> 
>  Following the 'usage' section in ?xyplot I specify 'x'/'formula' followed
> by the data specification. When I omit the "$" operator R (version 3.3.1)
> displays an empty device window and an error message (shown below the source
> file). The dput() file is attached and the script presented here:
> 
> ----
> # This scatter plot displays amount by day for each station, distinguished
> # by color. 'plot-rain-by-date.R'
> 
> # load rain data file
> rain <- read.table("daily_records.dat", header = TRUE, sep = ",", quote = "\"\"")
> rain$date <- as.Date(rain$date)
> 
> # Create a factor from the date
> raindate <- as.factor(rain$date)

Why are you creating this factor? The `date` column has the desirable properties associated with the "Date" class. Axis labeling will be correct.


> 
> # Save original plotting parameters
> opar <- par(xpd=NA,no.readonly=T)
> 
> # Prepare the plot of the data
> rainbyday <- xyplot(rain$amount ~ raindate, data = rain, main = "Area Precipitation",

#This should have succeeded (.. had you used the dataframe as a data delivery vehicle.)

rainbyday <- xyplot( amount ~ date, data = rain, ...)



>                    ylab = "Daily Total Amount (in)", xlab = "Date",
>                    scales = list(x=list(at=c(1,8,15,22,29,36,43,50,57,62), rot = 90),
>                        y = list(at=c(min(rain$amount), max(rain$amount)))),
>                    pch = 20,
>                    col = c("black","red","dark green","dark blue","dark goldenrod","dark magenta"),

Unless you map those colors to the 'station' vector (as I demonstrated in a earlier reply, the coloring of the points will be arbitrary. 

>                    key = simpleKey(text = levels(rain$station)[1:6],
>                        x = 0.2, y = 0.6, corner = c(0, 0), points = TRUE),
>                    par.settings = list(plot.symbol = list(c("black","red","dark green","dark blue",
>                                            "dark goldenrod","dark magenta"),

Unless you map those colors to the levels of 'station' as I earlier demonstrated, the coloring in the legend will be arbitrary.


> pch = 20, cex = 1.2)))
> 
> # Plot it
> plot(rainbyday)
> 
> # Reset display parameters
> par(opar)
> -----
> 
>  When I eliminate the "$" operator this is the error message:
>> source("plot-rain-by-day.R")

We don't have any way of viewing that code. I feel confident it has an error:

Here is code that I believe gives the correct labeling and coloring of points and legend. It took some experimentation to get the points in the legend to fill correctly:

rainbyday2 <- xyplot(amount ~ date, data = rain, main = "Area Precipitation",
   ylab = "Daily Total Amount (in)", xlab = "Date",
   scales = list(x=list(at=rain$date[ c(1,8,15,22,29,36,43,50,57,62)], rot = 90),
   y = list(at=c(min(rain$amount), max(rain$amount)))),
   pch = 20,
   col = c("black","red","dark green","dark blue","dark goldenrod","purple")[rain$station], 
 # Needed to use the 'station'-factor to properly index the colors. Otherwise there is no 1-1 relationship.
   key = list( text=list(levels(rain$station)), 
               fill = c("black","red","darkgreen","darkblue","darkgoldenrod","purple"),
               pch = 16,
     x = 0.2, y = 0.6, corner = c(0, 0), points = TRUE)); print(rainbyday2)


Reading the archives shows that this is not the first time this problem of getting fills with the `key` parameter for xyplot has caused problems for you. Back in 2013 Richard Heiberger and S Ellison were your correspondents. I found that using `simpleKey` was unsuccessful due to problematic defaults.

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+lattice+key+filled+points#query:list%3Aorg.r-project.r-help%20lattice%20key%20filled%20points+page:1+mid:3wbw2rs22uek6okp+state:results


> Error in xyplot.formula(amount ~ raindate, data = rain, main =
> "Area Precipitation",  (from plot-rain-by-day.R#14) :
>  object 'amount' not found

> 
>  The "$" operator appears 4 times; removing any one (or all) of them
> produces the same not found error. If there's another syntax error in the
> xyplot() call, or a logic error in the script please show me my mistake.
> 
>  With the "$" operator there's no error, but the key does not use pch=20;
> have I mis-placed Duncan's suggested par.settings?
> 
> Rich
> 
> 
> <rain.dput>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rshepard at appl-ecosys.com  Thu Oct 20 20:56:06 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 20 Oct 2016 11:56:06 -0700 (PDT)
Subject: [R] Lattice xyplot(): adding a legend [RESOLVED]
In-Reply-To: <E9D1863F-4355-4CD2-8D97-CA69646C346B@comcast.net>
References: <alpine.LNX.2.11.1610191038100.8962@localhost>
	<0DA29E48-DEA2-4C47-AEA5-F0331EF2B58E@comcast.net>
	<alpine.LNX.2.11.1610191242060.8962@localhost>
	<alpine.LNX.2.11.1610191556470.8962@localhost>
	<E6104510-8BEE-4F75-AF7B-AC68421BBB5D@comcast.net>
	<alpine.LNX.2.11.1610200901060.18589@localhost>
	<E9D1863F-4355-4CD2-8D97-CA69646C346B@comcast.net>
Message-ID: <alpine.LNX.2.11.1610201142190.18589@localhost>

On Thu, 20 Oct 2016, David Winsemius wrote:

> Why are you creating this factor? The `date` column has the desirable
> properties associated with the "Date" class. Axis labeling will be
> correct.

David, et al.:

   Because originally I mis-understood the parameters; it's gone now.

> rainbyday2 <- xyplot(amount ~ date, data = rain, main = "Area Precipitation",
>   ylab = "Daily Total Amount (in)", xlab = "Date",
>   scales = list(x=list(at=rain$date[ c(1,8,15,22,29,36,43,50,57,62)], rot = 90),
>   y = list(at=c(min(rain$amount), max(rain$amount)))),
>   pch = 20,
>   col = c("black","red","dark green","dark blue","dark goldenrod","purple")[rain$station],
> # Needed to use the 'station'-factor to properly index the colors. Otherwise there is no 1-1 relationship.
>   key = list( text=list(levels(rain$station)),
>               fill = c("black","red","darkgreen","darkblue","darkgoldenrod","purple"),
>               pch = 16,
>     x = 0.2, y = 0.6, corner = c(0, 0), points = TRUE)); print(rainbyday2)

   I was getting close to this by stripping the xyplot() code to basics and
adding one element at a time. I removed the scales component and let xyplot
assign the date and quantity labels by default. You filled in the last piece
with the station factor.

   The symbols for the key using 'fill' are all black circles. Changing that
option to 'col' displays both station name and circles in the stated colors.
That makes it much easier to identify individual data points.

   Next time I'll do much better on my own and will research my saved
threads, search for mail list archived threads, and more closely read the
help pages for functions.

> Reading the archives shows that this is not the first time this problem of
> getting fills with the `key` parameter for xyplot has caused problems for
> you. Back in 2013 Richard Heiberger and S Ellison were your
> correspondents. I found that using `simpleKey` was unsuccessful due to
> problematic defaults.

   And that was the last time I used R for a project. Not all my projects
require R, GRASS, PostgreSQL, or other technical software so I am not a
constant user of any, other than LaTeX.

Many thanks for your patient help,

Rich


From jan.kacaba at gmail.com  Thu Oct 20 23:47:56 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Thu, 20 Oct 2016 23:47:56 +0200
Subject: [R] function which returns number of occurrences of a pattern in
	string
Message-ID: <CAHby=D02jVZX_b3YR0+eXFvLanQo2evr0z+RAeT-1BbgJSPSFw@mail.gmail.com>

Hello dear R-help

I tried to find function which returns number of occurrences of a pattern
in string. The closest match I've found is str_locate_all in stringr
package. I can use str_locate_all but write my function but I don't want
reinvent wheel.

JK

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Oct 20 23:50:25 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 21 Oct 2016 08:50:25 +1100
Subject: [R] How is label parameter used in text() when passing it a
	vector?
In-Reply-To: <afdf6993a61cff7388c55c864513a780@kapsi.fi>
References: <afdf6993a61cff7388c55c864513a780@kapsi.fi>
Message-ID: <CA+8X3fX85U_fXzg5gD17ZZqVctPGrxue-FEXAcXPgJ0Ok2YoCg@mail.gmail.com>

Hi mviljama,
Without knowing what "dta" contains, it's a bit difficult. Here is an example:

set.seed(2345)
dta<-data.frame(age=sample(20:80,50),skin=sample(0:1,50,TRUE),
 gender=sample(0:1,50,TRUE),trt=sample(0:1,50,TRUE),
 exposure=sample(1:21,50,TRUE),fit5=runif(50))
# define your subset here for better readability
samp010<-dta$trt==0 & dta$skin==1 & dta$gender==0
library(plotrix)
# create your exposure colors
expcol<-color.scale(dta$exposure,extremes=c("red","green"))
par(mar=c(5,4,4,4))
# set up an empty plot
plot(x=dta$age[samp010],y=dta$fit5[samp010],type="n")
# add the points as text
text(x=dta$age[samp010],y=dta$fit5[samp010],col=expcol[samp010])
legend.values<-seq(1,21,length.out=5)
# add a legend for the colors
color.legend(47,0.2,49,0.5,gradient="y",legend=legend.values,
 rect.col=color.scale(legend.values,extremes=c("red","green")))
# label the legend
text(48,0.55,"Exposure")

Jim


On Fri, Oct 21, 2016 at 4:33 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> I have a slight doubt with using text() with the label parameter having to
> contain a vector of of integers (specifically integers in the range [1, 21]
> corresponding to factors of my categorical variable that I want to numbers
> to tell).
>
> What I'm currently plotting is the following command:
>
> text(dta[trt == 0 & skin == 1 & gender == 0,]$age,invlogit(predict(fit5,
> newdata=dta[trt == 0 & skin == 1 & gender == 0,])),label=1:21, col = dta[trt
> == 0 & skin == 1 & gender == 0,]$exposure)
>
> (it's a plot of a logistic model)
>
> $exposure is the categorical variable that takes values of integers in the
> range [1, 21]. The coloring seems to work, but I'm not sure whether
> label=1:21 makes it so that it actually labels the point with the
> corresponding exposure level or whether it just walks through 1 to 21 and 1
> to 21 over and over again.
>
> Can someone explain?
>
> Also how can I get the label parameter to put the number of the level of the
> exposure as the corresponding point?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Oct 20 23:55:29 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 21 Oct 2016 08:55:29 +1100
Subject: [R] How is label parameter used in text() when passing it a
	vector?
In-Reply-To: <CA+8X3fX85U_fXzg5gD17ZZqVctPGrxue-FEXAcXPgJ0Ok2YoCg@mail.gmail.com>
References: <afdf6993a61cff7388c55c864513a780@kapsi.fi>
	<CA+8X3fX85U_fXzg5gD17ZZqVctPGrxue-FEXAcXPgJ0Ok2YoCg@mail.gmail.com>
Message-ID: <CA+8X3fXVvU3=TSHpKhqw5BBdi_AcWPGdT3hi-vEfVGmLoXxToQ@mail.gmail.com>

Hi again,
Sorry, the text command should read:

text(x=dta$age[samp010],y=dta$fit5[samp010],labels=dta$exposure[samp010],
 col=expcol[samp010])

Jim

On Fri, Oct 21, 2016 at 8:50 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi mviljama,
> Without knowing what "dta" contains, it's a bit difficult. Here is an example:
>
> set.seed(2345)
> dta<-data.frame(age=sample(20:80,50),skin=sample(0:1,50,TRUE),
>  gender=sample(0:1,50,TRUE),trt=sample(0:1,50,TRUE),
>  exposure=sample(1:21,50,TRUE),fit5=runif(50))
> # define your subset here for better readability
> samp010<-dta$trt==0 & dta$skin==1 & dta$gender==0
> library(plotrix)
> # create your exposure colors
> expcol<-color.scale(dta$exposure,extremes=c("red","green"))
> par(mar=c(5,4,4,4))
> # set up an empty plot
> plot(x=dta$age[samp010],y=dta$fit5[samp010],type="n")
> # add the points as text
> text(x=dta$age[samp010],y=dta$fit5[samp010],col=expcol[samp010])
> legend.values<-seq(1,21,length.out=5)
> # add a legend for the colors
> color.legend(47,0.2,49,0.5,gradient="y",legend=legend.values,
>  rect.col=color.scale(legend.values,extremes=c("red","green")))
> # label the legend
> text(48,0.55,"Exposure")
>
> Jim
>
>
> On Fri, Oct 21, 2016 at 4:33 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:
>> I have a slight doubt with using text() with the label parameter having to
>> contain a vector of of integers (specifically integers in the range [1, 21]
>> corresponding to factors of my categorical variable that I want to numbers
>> to tell).
>>
>> What I'm currently plotting is the following command:
>>
>> text(dta[trt == 0 & skin == 1 & gender == 0,]$age,invlogit(predict(fit5,
>> newdata=dta[trt == 0 & skin == 1 & gender == 0,])),label=1:21, col = dta[trt
>> == 0 & skin == 1 & gender == 0,]$exposure)
>>
>> (it's a plot of a logistic model)
>>
>> $exposure is the categorical variable that takes values of integers in the
>> range [1, 21]. The coloring seems to work, but I'm not sure whether
>> label=1:21 makes it so that it actually labels the point with the
>> corresponding exposure level or whether it just walks through 1 to 21 and 1
>> to 21 over and over again.
>>
>> Can someone explain?
>>
>> Also how can I get the label parameter to put the number of the level of the
>> exposure as the corresponding point?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From msharp at txbiomed.org  Fri Oct 21 00:02:10 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Thu, 20 Oct 2016 22:02:10 +0000
Subject: [R] function which returns number of occurrences of a pattern
	in	string
In-Reply-To: <CAHby=D02jVZX_b3YR0+eXFvLanQo2evr0z+RAeT-1BbgJSPSFw@mail.gmail.com>
References: <CAHby=D02jVZX_b3YR0+eXFvLanQo2evr0z+RAeT-1BbgJSPSFw@mail.gmail.com>
Message-ID: <DDF2D95E-071B-4197-A9C9-31F4A3C231A2@TxBiomed.org>

Jan,

Within the stringr package you can find the function str_count().

Mark


R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Oct 20, 2016, at 4:47 PM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
>
> Hello dear R-help
>
> I tried to find function which returns number of occurrences of a pattern
> in string. The closest match I've found is str_locate_all in stringr
> package. I can use str_locate_all but write my function but I don't want
> reinvent wheel.
>
> JK
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From bob at rud.is  Fri Oct 21 03:47:50 2016
From: bob at rud.is (Bob Rudis)
Date: Thu, 20 Oct 2016 21:47:50 -0400
Subject: [R] function which returns number of occurrences of a pattern
	in string
In-Reply-To: <CAHby=D02jVZX_b3YR0+eXFvLanQo2evr0z+RAeT-1BbgJSPSFw@mail.gmail.com>
References: <CAHby=D02jVZX_b3YR0+eXFvLanQo2evr0z+RAeT-1BbgJSPSFw@mail.gmail.com>
Message-ID: <CAA-FpKUowYCRpEU+paqbU=95bdc06VABADt_Peaboatq9Ov_3Q@mail.gmail.com>

`stringi::stri_count()`

I know that the `stringr` pkg saves some typing (it wraps the
`stringi` pkg), but you should really just use the `stringi` package.
It has many more very useful functions with not too much more typing.

On Thu, Oct 20, 2016 at 5:47 PM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
> Hello dear R-help
>
> I tried to find function which returns number of occurrences of a pattern
> in string. The closest match I've found is str_locate_all in stringr
> package. I can use str_locate_all but write my function but I don't want
> reinvent wheel.
>
> JK
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 1101011 at gmx.net  Fri Oct 21 06:00:07 2016
From: 1101011 at gmx.net (Mike meyer)
Date: Fri, 21 Oct 2016 06:00:07 +0200
Subject: [R] nls.lm
In-Reply-To: <248822ac-a35b-2efb-db95-b4b517148cc5@gmail.com>
References: <trinity-6990f702-31a2-4ab3-9d04-dfb58a40f5a6-1476904583462@3capp-gmx-bs28>
	<1A8C1289955EF649A09086A153E2672403FEAD5CBC@GBTEDVPEXCMB04.corp.lgc-group.com>,
	<248822ac-a35b-2efb-db95-b4b517148cc5@gmail.com>
Message-ID: <trinity-4d100170-7b33-4705-afc4-de87f62cc493-1477022407715@3capp-gmx-bs11>

Let's take a different view of the problem.
Given f=(f_1,...,f_m):R^n -> R^m we want to minimize ||f(x)||.

What distinguishes this from a general minimization problem is that you know the structure of the
objective function F(x)=||f(x)||? and have the individual constituents f_j.
Make use of that information as appropriate.

This is more general than trying to solve the system f(x)=0 or fitting a model to data.
In this more general setting notions such as underdetermined/overdetermined system do not apply.

The restricted view of model fitting serves only to confuse the issue.
For that reason it is (in my view) a bad idea to force the user to set up his problem in 
R-model notation.

Michael
unaffiliated


> Gesendet: Donnerstag, 20. Oktober 2016 um 15:26 Uhr
> Von: ProfJCNash <profjcnash at gmail.com>
> An: "S Ellison" <S.Ellison at LGCGroup.com>, "Mike meyer" <1101011 at gmx.net>
> Cc: "r-help at r-project.org" <r-help at r-project.org>, "Berend Hasselman" <bhh at xs4all.nl>
> Betreff: Re: [R] nls.lm
>
> From a statistician's point of view, "nonsense" may be OK, but there are other applications of R where
> (partial or non-unique) solutions may be needed.
> 
> Yesterday I raised the question of how nonlinear least squares could be adapted to underdetermined problems.
> Many folk are unaware of such possibilities, even in the linear case. In the nonlinear case, the m>n condition is
> far from adequate to provide appropriate warnings to users. What should we do to detect non-unique solutions?
> 
> My interest is in building better nonlinear least squares and optimization software, and I find software users
> (including R users) have some belief that those of us building the tools they use are magic wizards or fairy
> godmothers who have provided everything they need in bullet-proof packages. This is so far from reality. All of
> the tools I have worked with have weaknesses. To close the loopholes we need those "small reproducible examples",
> including cases like these, so that better diagnostics can be devised.
> 
> We also need discussion on what to present as diagnostics and how to do so for maximum benefit and least
> "get in the way". A two-way communication with users can aid immensely.
> 
> Sorry for the rant, but I'm in the midst of trying to prepare a unification of nls/nlmrt/minpack.lm and some
> of the effort is pretty messy, especially in the area of derivatives and diagnostics.
> 
> Below is a little script that tries Berend's problem. The nonlinear least squares "runs" but the output fails
> except for str(). The script will stop on failure at some points, so you need to paste some statements. I welcome
> similar scripts/examples to build the necessary tests for improved packages.
> 
> JN
> 
> Here's the script.
> 
> # try to solve undetermined system by nonlinear least squares
> X1 <- c(1,1)
> Y1 <- c(1,1)
> Z1 <- c(1,1)
> RHS1 <- c(3,4)
> X2 <- c(1,2)
> RHS2 <- c(3,6)
> mydata <- data.frame(X1, X2, Y1, Z1, RHS1, RHS2)
> require(nlmrt)
> st1 <- c(px=1,py=1,pz=1)
> st0 <- c(px=0,py=0,pz=0)
> sol10 <- nlxb(RHS1 ~ px*X1 + py*Y1 + pz*Z1, data=mydata, trace=1, start=st0)
> summary(sol10)
> print(sol10)
> str(sol10)
> sol11 <- nlxb(RHS1 ~ px*X1 + py*Y1 + pz*Z1, data=mydata, trace=1, start=st1)
> summary(sol11)
> print(sol11)
> str(sol11)
> ## try RHS2
> sol20 <- nlxb(RHS2 ~ px*X1 + py*Y1 + pz*Z1, data=mydata, trace=1, start=st0)
> summary(sol20)
> print(sol20)
> str(sol20)
> sol21 <- nlxb(RHS2 ~ px*X1 + py*Y1 + pz*Z1, data=mydata, trace=1, start=st1)
> summary(sol21)
> print(sol21)
> str(sol21)
> # change first column -- then we get solutions
> sol220 <- nlxb(RHS2 ~ px*X2 + py*Y1 + pz*Z1, data=mydata, trace=1, start=st0)
> summary(sol220)
> print(sol220)
> str(sol220)
> sol221 <- nlxb(RHS2 ~ px*X2 + py*Y1 + pz*Z1, data=mydata, trace=1, start=st1)
> summary(sol221)
> print(sol221)
> str(sol221)
> 
> 
> 
> On 16-10-20 07:05 AM, S Ellison wrote:
> >> How do you reply to a specific post on this board instead of the thread?
> > 
> > You can reply to the individual, as I just did.
> > 
> > But I strongly suggest that you don't. You would be much better advised to discontinue debate and follow the essential advice given by nls.lm, which - no matter whether couched in terms of count of residuals - is simply to make sure that you have more independent data than variables when seeking a unique numerical solution by non-linear least squares. If you don't you'll get nonsense.
> > 
> > 
> > S Ellison
> > 
> > 
> > 
> > 
> > 
> > *******************************************************************
> > This email and any attachments are confidential. Any use...{{dropped:8}}
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 
>


From manu.reddy52 at gmail.com  Fri Oct 21 08:52:02 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Fri, 21 Oct 2016 12:22:02 +0530
Subject: [R] Reg :  : How to plot the live streaming graph in R ?
Message-ID: <CADG9u0CwFaumjAG7Ln+=E8dOqTTrcRF4UKZ+j71g-rZwKmkFEw@mail.gmail.com>

Hi,



  I have a data which is stored in sql table and in every minute data
inserting to this table .Now my requirement is I need to plot the live
streaming  graph as per below link or PFA. Can anyone help out me how to do
that in R ?

  link : http://www.highcharts.com/studies/live-server.htm

 Thanks in Advance !

?Note :

  The graph will be keep on moving .?

*Manu.*
-------------- next part --------------
A non-text attachment was scrubbed...
Name: live_Streaming_graph.PNG
Type: image/png
Size: 49921 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161021/797f2f08/attachment.png>

From ulrik.stervbo at gmail.com  Fri Oct 21 09:02:28 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 21 Oct 2016 07:02:28 +0000
Subject: [R] Reg : : How to plot the live streaming graph in R ?
In-Reply-To: <CADG9u0CwFaumjAG7Ln+=E8dOqTTrcRF4UKZ+j71g-rZwKmkFEw@mail.gmail.com>
References: <CADG9u0CwFaumjAG7Ln+=E8dOqTTrcRF4UKZ+j71g-rZwKmkFEw@mail.gmail.com>
Message-ID: <CAKVAULP=m2RNptb93HrftZTJvNTDpkqbgWr3dt=G0KMeiEQ34g@mail.gmail.com>

Hi Manu,

I'm by far no expert, but if you use Shiny I believe you can refresh using
'reactiveTimer' and just plot the last n points

HTH
Ulrik

On Fri, 21 Oct 2016 at 08:53 Manohar Reddy <manu.reddy52 at gmail.com> wrote:

> Hi,
>
>
>
>   I have a data which is stored in sql table and in every minute data
> inserting to this table .Now my requirement is I need to plot the live
> streaming  graph as per below link or PFA. Can anyone help out me how to do
> that in R ?
>
>   link : http://www.highcharts.com/studies/live-server.htm
>
>  Thanks in Advance !
>
> ?Note :
>
>   The graph will be keep on moving .?
>
> *Manu.*
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Fri Oct 21 09:39:24 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 21 Oct 2016 09:39:24 +0200
Subject: [R] nls.lm
In-Reply-To: <trinity-4d100170-7b33-4705-afc4-de87f62cc493-1477022407715@3capp-gmx-bs11>
References: <trinity-6990f702-31a2-4ab3-9d04-dfb58a40f5a6-1476904583462@3capp-gmx-bs28>
	<1A8C1289955EF649A09086A153E2672403FEAD5CBC@GBTEDVPEXCMB04.corp.lgc-group.com>
	<248822ac-a35b-2efb-db95-b4b517148cc5@gmail.com>
	<trinity-4d100170-7b33-4705-afc4-de87f62cc493-1477022407715@3capp-gmx-bs11>
Message-ID: <71CB38F1-154B-4FC1-B413-61B98C388898@xs4all.nl>


> On 21 Oct 2016, at 06:00, Mike meyer <1101011 at gmx.net> wrote:
> 
> Let's take a different view of the problem.
> Given f=(f_1,...,f_m):R^n -> R^m we want to minimize ||f(x)||.
> 
> What distinguishes this from a general minimization problem is that you know the structure of the
> objective function F(x)=||f(x)||? and have the individual constituents f_j.
> Make use of that information as appropriate.
> 
> This is more general than trying to solve the system f(x)=0 or fitting a model to data.
> In this more general setting notions such as underdetermined/overdetermined system do not apply.
> 
> The restricted view of model fitting serves only to confuse the issue.
> For that reason it is (in my view) a bad idea to force the user to set up his problem in 
> R-model notation.
> 

I assume that you have been referring to the R package minpack.lm.

I've had a look at the underlying Fortran code (from Minpack and developed by More et.al.  made in a distant past) as used by the package.
That underlying code returns an error when the condition:  number of functions (m)  >=  the number of independent variables (n)
is not satisfied i.e. when m < n.

Making that more general would entail a lot of thinking and reworking of the code. As far as I can see it is not possible to just remove the condition m>=n from the underlying Fortran. More (possibly many) changes would be required. Blaming R and/or the package author/maintainer is unfair.

If you require a more general version of the algorithm or if you want something else you will have to roll your own package/code.
If you don't feel that minpack.lm is appropriate for your application and you want changes you'll have to discuss matters with Mor? (http://www.mcs.anl.gov/~more/) if I got the correct link.

Berend


From profjcnash at gmail.com  Fri Oct 21 14:41:04 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Fri, 21 Oct 2016 08:41:04 -0400
Subject: [R] nls.lm
In-Reply-To: <71CB38F1-154B-4FC1-B413-61B98C388898@xs4all.nl>
References: <trinity-6990f702-31a2-4ab3-9d04-dfb58a40f5a6-1476904583462@3capp-gmx-bs28>
	<1A8C1289955EF649A09086A153E2672403FEAD5CBC@GBTEDVPEXCMB04.corp.lgc-group.com>
	<248822ac-a35b-2efb-db95-b4b517148cc5@gmail.com>
	<trinity-4d100170-7b33-4705-afc4-de87f62cc493-1477022407715@3capp-gmx-bs11>
	<71CB38F1-154B-4FC1-B413-61B98C388898@xs4all.nl>
Message-ID: <65ff499c-1b27-0e71-b5c8-c65955dde192@gmail.com>

Berend's point is well-taken. It's a lot of work to re-jig a code, especially one more than
30 years old.

On the other hand, nlmrt is all-R, and it does more or less work on underdetermined systems as I
illustrated in a small script. The changes needed to treat the problem as Mike suggests are
pretty easy, but they imply that some aspects of the modeling computations have to be omitted.
Mike: If you give that a try, I'd be interested in outcomes, and am willing to answer questions
on how the code works.

Indeed, I want to include the sort of "diagnostics" that allow underdetermined systems
in my packages, so that some results are replaced with NA or NULL and helpful warnings rather
than "Failed m<n" are reported.

Best, JN

On 16-10-21 03:39 AM, Berend Hasselman wrote:
> 
>> On 21 Oct 2016, at 06:00, Mike meyer <1101011 at gmx.net> wrote:
>>
>> Let's take a different view of the problem.
>> Given f=(f_1,...,f_m):R^n -> R^m we want to minimize ||f(x)||.
>>
>> What distinguishes this from a general minimization problem is that you know the structure of the
>> objective function F(x)=||f(x)||? and have the individual constituents f_j.
>> Make use of that information as appropriate.
>>
>> This is more general than trying to solve the system f(x)=0 or fitting a model to data.
>> In this more general setting notions such as underdetermined/overdetermined system do not apply.
>>
>> The restricted view of model fitting serves only to confuse the issue.
>> For that reason it is (in my view) a bad idea to force the user to set up his problem in 
>> R-model notation.
>>
> 
> I assume that you have been referring to the R package minpack.lm.
> 
> I've had a look at the underlying Fortran code (from Minpack and developed by More et.al.  made in a distant past) as used by the package.
> That underlying code returns an error when the condition:  number of functions (m)  >=  the number of independent variables (n)
> is not satisfied i.e. when m < n.
> 
> Making that more general would entail a lot of thinking and reworking of the code. As far as I can see it is not possible to just remove the condition m>=n from the underlying Fortran. More (possibly many) changes would be required. Blaming R and/or the package author/maintainer is unfair.
> 
> If you require a more general version of the algorithm or if you want something else you will have to roll your own package/code.
> If you don't feel that minpack.lm is appropriate for your application and you want changes you'll have to discuss matters with Mor? (http://www.mcs.anl.gov/~more/) if I got the correct link.
> 
> Berend
>


From Anusha.Indhira at controlsdata.com  Fri Oct 21 10:35:24 2016
From: Anusha.Indhira at controlsdata.com (Indhira, Anusha)
Date: Fri, 21 Oct 2016 08:35:24 +0000
Subject: [R] need help in customising function in stat_summary
	function	ggplot2
In-Reply-To: <6A7B028C-7F27-4610-AE0A-B5FB39FDADFF@TxBiomed.org>
References: <CE1899A9C6A8D64099DFB344ECF0F754863F@DERCORCEXH02.ds-s.com>
	<6A7B028C-7F27-4610-AE0A-B5FB39FDADFF@TxBiomed.org>
Message-ID: <CE1899A9C6A8D64099DFB344ECF0F7548733@DERCORCEXH02.ds-s.com>

Thanks  mark for pointing out my mistake and suggestion.I can get desired output now

-----Original Message-----
From: Mark Sharp [mailto:msharp at TxBiomed.org]
Sent: 20 October 2016 17:21
To: Indhira, Anusha
Cc: r-help at r-project.org
Subject: Re: [R] need help in customising function in stat_summary function ggplot2

Indhira,

You have to assign cnt and new value in the loop if you want it to update in the loop. However, to count the number of values of x > median(x), there are multiple options. You are using a loop where none is needed in R, which has many implicit vector functions that run with relational operators and assignments.

x <- rnorm(10)
cnt <- sum(ifelse(x > median(x), 1, 0))

Because TRUE evaluates to 1 and FALSE evaluates to 0, you can also use cnt <- sum(x > median(x))

I cannot help you with the ggplot question directly since you have not provided a definition of the object st_chg_51.

Mark

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center Texas Biomedical Research Institute P.O. Box 760549 San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Oct 20, 2016, at 3:25 AM, Indhira, Anusha <Anusha.Indhira at controlsdata.com> wrote:
>
> Hi,
>
> I would like to print percentage of points in a group which are greater than median value in boxplot. I have tried below code but it always prints zero in the graph. Can you let me know, how to modify code to get desired result?
>
>
> perc.greaterthan.median <- function(x){  cnt = 0  for(i in
> 1:length(x)){
>   ifelse(x[i] > median(x),cnt+1,cnt)
>  }
>  return(c(y = median(x)*1.7, label = round((cnt/length(x))*100,2))) }
>
> ggplot(st_chg_51, aes(x=factor(st_dv), P3))+
> #label=rownames(st_chg_51))) +  geom_boxplot(fill = "grey80", colour =
> "#3366FF") +  stat_summary(fun.data = perc.greaterthan.median, geom =
> "text", fun.y = median) +  theme_bw()+theme(axis.text =
> element_text(angle = 90, hjust = 1))
>
> Why does cnt in the function doesn't get incremented in the loop?
>
> Thanks,
> Anusha
>
> This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:22}}


From ragia11 at hotmail.com  Fri Oct 21 18:30:07 2016
From: ragia11 at hotmail.com (Ragia .)
Date: Fri, 21 Oct 2016 16:30:07 +0000
Subject: [R] cdf in R give probability of random variable
Message-ID: <AMSPR03MB584111458EE8878ADC29E94B3D40@AMSPR03MB584.eurprd03.prod.outlook.com>


Dear Grooup

kindly

how can I plot  these  graphs in R..


Suppose that X is a discrete random variable with P(X = 0) = .25, P(X = 1) =
.125, P(X = 2) = .125, and P(X = 3) = .5. Graph the frequency function and
the cumulative distribution function of X.



my solution was:

x=c(0,1,3)
px=c(.25,.125,.5)
plot( x,px ,type="h"  ) # to plot the frequency  , is it correct

 how to plot the cdf?



thanks in advance


Ragia



	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Oct 21 20:23:42 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 21 Oct 2016 20:23:42 +0200
Subject: [R] cdf in R give probability of random variable
In-Reply-To: <AMSPR03MB584111458EE8878ADC29E94B3D40@AMSPR03MB584.eurprd03.prod.outlook.com>
References: <AMSPR03MB584111458EE8878ADC29E94B3D40@AMSPR03MB584.eurprd03.prod.outlook.com>
Message-ID: <23D09BE5-040C-495D-8C7D-05E3ABB88DDC@gmail.com>

This looks like homework, but doing it in R might not be, so I'll give you the benefit of doubt...


> On 21 Oct 2016, at 18:30 , Ragia . <ragia11 at hotmail.com> wrote:
> 
> 
> Dear Grooup
> 
> kindly
> 
> how can I plot  these  graphs in R..
> 
> 
> Suppose that X is a discrete random variable with P(X = 0) = .25, P(X = 1) =
> .125, P(X = 2) = .125, and P(X = 3) = .5. Graph the frequency function and
> the cumulative distribution function of X.
> 
> 
> 
> my solution was:
> 
> x=c(0,1,3)
> px=c(.25,.125,.5)
> plot( x,px ,type="h"  ) # to plot the frequency  , is it correct
> 

You forgot X=2 in there (check the sum). 

> how to plot the cdf?
> 

cumsum() is your friend.

In both cases it works out nicer if you do

names(px) <- x
barplot(px)

-pd

> 	[[alternative HTML version deleted]]

Notice that plain text posting is strongly preferred in here. HTML messes up code badly sometimes.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Fri Oct 21 22:10:22 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 21 Oct 2016 22:10:22 +0200
Subject: [R] cdf in R give probability of random variable
In-Reply-To: <23D09BE5-040C-495D-8C7D-05E3ABB88DDC@gmail.com>
References: <AMSPR03MB584111458EE8878ADC29E94B3D40@AMSPR03MB584.eurprd03.prod.outlook.com>
	<23D09BE5-040C-495D-8C7D-05E3ABB88DDC@gmail.com>
Message-ID: <A012119D-A0F7-4681-8D7E-EC6BCBCA7794@gmail.com>


> On 21 Oct 2016, at 20:23 , peter dalgaard <pdalgd at gmail.com> wrote:
> 
> In both cases it works out nicer if you do
> 
> names(px) <- x
> barplot(px)
> 

Um, unless of course you want the cdf as a step function, in which case check the help page for plot for possible values of the type= argument.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tring at gvdnet.dk  Sat Oct 22 10:50:52 2016
From: tring at gvdnet.dk (Troels Ring)
Date: Sat, 22 Oct 2016 10:50:52 +0200
Subject: [R] gtools Gator infected...
Message-ID: <3acd73dc-bcfd-d211-4563-5fba5ed467e7@gvdnet.dk>

Hi friends - just installed gtools to make rstan run. Was rapidly 
informed by Spyhunter 4 that gtools.dll harboured Gator. Spyhunter 4 
then aggressively removed Gator - and gtools were gone and rstan out of 
function. Kind of sorry about this.

Best wishes

Troels Ring

Aalborg, Denmark


From bob at rud.is  Sat Oct 22 13:12:24 2016
From: bob at rud.is (Bob Rudis)
Date: Sat, 22 Oct 2016 07:12:24 -0400
Subject: [R] gtools Gator infected...
In-Reply-To: <3acd73dc-bcfd-d211-4563-5fba5ed467e7@gvdnet.dk>
References: <3acd73dc-bcfd-d211-4563-5fba5ed467e7@gvdnet.dk>
Message-ID: <CAA-FpKU0N-_igHgVEXQwMKmtZfAmJ2JfHCcBJjyuk4n5tb2n3A@mail.gmail.com>

I think your tool is a bit overzealous. VirusTotal -
https://virustotal.com/en/file/5fd1b2fc5c061c0836a70cbad620893a89a27d9251358a5c42c3e49113c9456c/analysis/
& https://virustotal.com/en/file/e133ebf5001e1e991f1f6b425adcfbab170fe3c02656e3a697a5ebea961e909c/analysis/
- shows no sign of any malware in the 32-bit DLLor 64-bit DLL (I
tested  r-release: gtools_3.5.0.zip)

On Sat, Oct 22, 2016 at 4:50 AM, Troels Ring <tring at gvdnet.dk> wrote:
> Hi friends - just installed gtools to make rstan run. Was rapidly informed
> by Spyhunter 4 that gtools.dll harboured Gator. Spyhunter 4 then
> aggressively removed Gator - and gtools were gone and rstan out of function.
> Kind of sorry about this.
>
> Best wishes
>
> Troels Ring
>
> Aalborg, Denmark
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tring at gvdnet.dk  Sat Oct 22 13:31:24 2016
From: tring at gvdnet.dk (Troels Ring)
Date: Sat, 22 Oct 2016 13:31:24 +0200
Subject: [R] gtools Gator infected...
In-Reply-To: <3acd73dc-bcfd-d211-4563-5fba5ed467e7@gvdnet.dk>
References: <3acd73dc-bcfd-d211-4563-5fba5ed467e7@gvdnet.dk>
Message-ID: <31f7d972-99f9-5f90-63c0-7fe36ab0dc85@gvdnet.dk>

Thanks a lot - I have asked enigmasoftware to go and check up on this - 
and they'll also see your letter!

BW
Troels


Den 22-10-2016 kl. 13:12 skrev Bob Rudis:
> I think your tool is a bit overzealous. VirusTotal -
> https://virustotal.com/en/file/5fd1b2fc5c061c0836a70cbad620893a89a27d9251358a5c42c3e49113c9456c/analysis/
> & https://virustotal.com/en/file/e133ebf5001e1e991f1f6b425adcfbab170fe3c02656e3a697a5ebea961e909c/analysis/
> - shows no sign of any malware in the 32-bit DLLor 64-bit DLL (I
> tested  r-release: gtools_3.5.0.zip)
>
> On Sat, Oct 22, 2016 at 4:50 AM, Troels Ring <tring at gvdnet.dk> wrote:
>> Hi friends - just installed gtools to make rstan run. Was rapidly informed
>> by Spyhunter 4 that gtools.dll harboured Gator. Spyhunter 4 then
>> aggressively removed Gator - and gtools were gone and rstan out of function.
>> Kind of sorry about this.
>>
>> Best wishes
>>
>> Troels Ring
>>
>> Aalborg, Denmark
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From maechler at stat.math.ethz.ch  Sat Oct 22 16:59:08 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 22 Oct 2016 16:59:08 +0200
Subject: [R] cdf in R give probability of random variable
In-Reply-To: <A012119D-A0F7-4681-8D7E-EC6BCBCA7794@gmail.com>
References: <AMSPR03MB584111458EE8878ADC29E94B3D40@AMSPR03MB584.eurprd03.prod.outlook.com>
	<23D09BE5-040C-495D-8C7D-05E3ABB88DDC@gmail.com>
	<A012119D-A0F7-4681-8D7E-EC6BCBCA7794@gmail.com>
Message-ID: <22539.32444.359036.883566@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Fri, 21 Oct 2016 22:10:22 +0200 writes:

    >> On 21 Oct 2016, at 20:23 , peter dalgaard
    >> <pdalgd at gmail.com> wrote:
    >> 
    >> In both cases it works out nicer if you do
    >> 
    >> names(px) <- x
    >> barplot(px)

    > Um, unless of course you want the cdf as a step function,
    > in which case check the help page for plot for possible
    > values of the type= argument.

and if it is not homework, (or even then ;-)  just use
	
  plot(ecdf(x))


Martin Maechler, ETH Zurich


From chocold12 at gmail.com  Sat Oct 22 19:50:10 2016
From: chocold12 at gmail.com (lily li)
Date: Sat, 22 Oct 2016 11:50:10 -0600
Subject: [R] About reshape dataset
Message-ID: <CAN5afy-RbskEnw8z3ezcZhUSy=smVhYGtodmwqXEMGEkoBhcpQ@mail.gmail.com>

Hi R users,

I want to melt a dataframe, but it mixed up the variables.

DF is the original dataset:
year  month  day  site1_elev  site2_elev  site1_temp  site2_temp
2000     5        6        1300          1500            20              21

2000     5        7        1300          1500            21              22
2000     5        8        1300          1500            19              20
2000     5        9        1300          1500            22              23

How to melt the dataframe and get the following dataset? Thanks for your
help.

year  month  day  siteID   elev   temp
2000    5         6       1      1300    20
2000    5         6       2      1500    21
2000    5         7       1      1300    21
2000    5         7       2      1500    22

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Sat Oct 22 19:52:28 2016
From: chocold12 at gmail.com (lily li)
Date: Sat, 22 Oct 2016 11:52:28 -0600
Subject: [R] About reshape dataset
In-Reply-To: <CAN5afy-RbskEnw8z3ezcZhUSy=smVhYGtodmwqXEMGEkoBhcpQ@mail.gmail.com>
References: <CAN5afy-RbskEnw8z3ezcZhUSy=smVhYGtodmwqXEMGEkoBhcpQ@mail.gmail.com>
Message-ID: <CAN5afy_4cM6ZEO0A0-Kcb0FSgPH1jYoEL8wVyd3XKJG1zWgVHQ@mail.gmail.com>

The code I'm using is:
require(reshape)
DF2 = melt(DF, id.vars = c('year', 'month', 'day'), measure.vars =
c('site1_elev', 'site2_elev', 'site1_temp', 'site2_temp'))

But it didn't work.

On Sat, Oct 22, 2016 at 11:50 AM, lily li <chocold12 at gmail.com> wrote:

> Hi R users,
>
> I want to melt a dataframe, but it mixed up the variables.
>
> DF is the original dataset:
> year  month  day  site1_elev  site2_elev  site1_temp  site2_temp
> 2000     5        6        1300          1500            20
>  21
> 2000     5        7        1300          1500            21              22
> 2000     5        8        1300          1500            19              20
> 2000     5        9        1300          1500            22              23
>
> How to melt the dataframe and get the following dataset? Thanks for your
> help.
>
> year  month  day  siteID   elev   temp
> 2000    5         6       1      1300    20
> 2000    5         6       2      1500    21
> 2000    5         7       1      1300    21
> 2000    5         7       2      1500    22
>
>

	[[alternative HTML version deleted]]


From djnordlund at gmail.com  Sat Oct 22 21:22:04 2016
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Sat, 22 Oct 2016 12:22:04 -0700
Subject: [R] About reshape dataset
In-Reply-To: <CAN5afy_4cM6ZEO0A0-Kcb0FSgPH1jYoEL8wVyd3XKJG1zWgVHQ@mail.gmail.com>
References: <CAN5afy-RbskEnw8z3ezcZhUSy=smVhYGtodmwqXEMGEkoBhcpQ@mail.gmail.com>
	<CAN5afy_4cM6ZEO0A0-Kcb0FSgPH1jYoEL8wVyd3XKJG1zWgVHQ@mail.gmail.com>
Message-ID: <5441b577-6369-2520-9642-e68810cfea13@gmail.com>

On 10/22/2016 10:52 AM, lily li wrote:
> The code I'm using is:
> require(reshape)
> DF2 = melt(DF, id.vars = c('year', 'month', 'day'), measure.vars =
> c('site1_elev', 'site2_elev', 'site1_temp', 'site2_temp'))
>
> But it didn't work.
>
> On Sat, Oct 22, 2016 at 11:50 AM, lily li <chocold12 at gmail.com> wrote:
>
>> Hi R users,
>>
>> I want to melt a dataframe, but it mixed up the variables.
>>
>> DF is the original dataset:
>> year  month  day  site1_elev  site2_elev  site1_temp  site2_temp
>> 2000     5        6        1300          1500            20
>>  21
>> 2000     5        7        1300          1500            21              22
>> 2000     5        8        1300          1500            19              20
>> 2000     5        9        1300          1500            22              23
>>
>> How to melt the dataframe and get the following dataset? Thanks for your
>> help.
>>
>> year  month  day  siteID   elev   temp
>> 2000    5         6       1      1300    20
>> 2000    5         6       2      1500    21
>> 2000    5         7       1      1300    21
>> 2000    5         7       2      1500    22
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

I am sure someone will come along with a "better" answer, but I played 
with this a bit and this is what I came up with. After running your code 
I ran

DF2$site <- substr(as.character(DF2$variable),1,5)
DF2$var <- substr(as.character(DF2$variable),7,10)
DF3 <- cast(DF2,year + month + day + site ~ var )


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From sqy190 at gmail.com  Sat Oct 22 22:56:17 2016
From: sqy190 at gmail.com (=?UTF-8?B?5a6L5bqG5a6H?=)
Date: Sun, 23 Oct 2016 04:56:17 +0800
Subject: [R] Anchoring Vignettes
Message-ID: <CA+fA9oekyHkM9Mb6gzhxx1ZCimhzFJvMkqfL_NKP1VP7OJcDoA@mail.gmail.com>

Hello dear R-help,

I tried to use the code of anchors.mexchn2, but when I tried to
trim.data(), I was encountered with the error?more details is as follows:

> data(selfan)

> fo <- list(self = xsay ~ 1, vign = cbind( xsay1,xsay2) ~ 1)

> ra <- anchors( fo, data=selfan, method="C")

> selfan.cut <- trim.data( selfan, ra)

Error in if ((anchors$method == "chopit" && anchors$delete != "listwise"))
stop(paste("trim.data() not defined for anchors.data objects created with
\n", : missing value where TRUE/FALSE needed

How to solve this problem?

Thanks in advance,

Soukeiu

	[[alternative HTML version deleted]]


From 1101011 at gmx.net  Sun Oct 23 09:56:19 2016
From: 1101011 at gmx.net (Mike meyer)
Date: Sun, 23 Oct 2016 09:56:19 +0200
Subject: [R] nls.lm
In-Reply-To: <71CB38F1-154B-4FC1-B413-61B98C388898@xs4all.nl>
References: <trinity-6990f702-31a2-4ab3-9d04-dfb58a40f5a6-1476904583462@3capp-gmx-bs28>
	<1A8C1289955EF649A09086A153E2672403FEAD5CBC@GBTEDVPEXCMB04.corp.lgc-group.com>
	<248822ac-a35b-2efb-db95-b4b517148cc5@gmail.com>
	<trinity-4d100170-7b33-4705-afc4-de87f62cc493-1477022407715@3capp-gmx-bs11>,
	<71CB38F1-154B-4FC1-B413-61B98C388898@xs4all.nl>
Message-ID: <trinity-96ce0f1a-8051-4bf8-a546-d359a5b20150-1477209379884@3capp-gmx-bs49>

Please accept my apologies as I was in fact wrong.

It was not my intention to attack minpack.lm or criticize the maintainer.
I like minpack.lm and am fully aware of the effort involved in rewriting the
code. Next time I'll use more careful wording.

Thanks also to Professor Nash for his efforts. I look forward to the results.


Best regards,

Michael
unaffiliatd




> Gesendet: Freitag, 21. Oktober 2016 um 09:39 Uhr
> Von: "Berend Hasselman" <bhh at xs4all.nl>
> An: "Mike meyer" <1101011 at gmx.net>
> Cc: ProfJCNash <profjcnash at gmail.com>, "r-help at r-project.org" <r-help at r-project.org>
> Betreff: Re: [R] nls.lm
>
> 
> > On 21 Oct 2016, at 06:00, Mike meyer <1101011 at gmx.net> wrote:
> > 
> > Let's take a different view of the problem.
> > Given f=(f_1,...,f_m):R^n -> R^m we want to minimize ||f(x)||.
> > 
> > What distinguishes this from a general minimization problem is that you know the structure of the
> > objective function F(x)=||f(x)||? and have the individual constituents f_j.
> > Make use of that information as appropriate.
> > 
> > This is more general than trying to solve the system f(x)=0 or fitting a model to data.
> > In this more general setting notions such as underdetermined/overdetermined system do not apply.
> > 
> > The restricted view of model fitting serves only to confuse the issue.
> > For that reason it is (in my view) a bad idea to force the user to set up his problem in 
> > R-model notation.
> > 
> 
> I assume that you have been referring to the R package minpack.lm.
> 
> I've had a look at the underlying Fortran code (from Minpack and developed by More et.al.  made in a distant past) as used by the package.
> That underlying code returns an error when the condition:  number of functions (m)  >=  the number of independent variables (n)
> is not satisfied i.e. when m < n.
> 
> Making that more general would entail a lot of thinking and reworking of the code. As far as I can see it is not possible to just remove the condition m>=n from the underlying Fortran. More (possibly many) changes would be required. Blaming R and/or the package author/maintainer is unfair.
> 
> If you require a more general version of the algorithm or if you want something else you will have to roll your own package/code.
> If you don't feel that minpack.lm is appropriate for your application and you want changes you'll have to discuss matters with Mor? (http://www.mcs.anl.gov/~more/) if I got the correct link.
> 
> Berend
> 
>


From philipt900 at iinet.net.au  Sun Oct 23 03:39:19 2016
From: philipt900 at iinet.net.au (P Tennant)
Date: Sun, 23 Oct 2016 12:39:19 +1100
Subject: [R] About reshape dataset
In-Reply-To: <CAN5afy-RbskEnw8z3ezcZhUSy=smVhYGtodmwqXEMGEkoBhcpQ@mail.gmail.com>
References: <CAN5afy-RbskEnw8z3ezcZhUSy=smVhYGtodmwqXEMGEkoBhcpQ@mail.gmail.com>
Message-ID: <580C14C7.9060100@iinet.net.au>

You could convert your data from a wide format to a long format using 
the reshape function in base R:

DF2 <- reshape(DF, direction="long",
         idvar=names(DF)[1:3],
         varying=c("site1_elev", "site1_temp", "site2_elev", "site2_temp"),
         v.names=c("elev", "temp"),
         times=1:2,
         timevar = "siteID")

rownames(DF2) <- NULL
DF2

   year month day siteID elev temp
1 2000     5   6      1 1300   20
2 2000     5   7      1 1300   21
3 2000     5   8      1 1300   19
4 2000     5   9      1 1300   22
5 2000     5   6      2 1500   21
6 2000     5   7      2 1500   22
7 2000     5   8      2 1500   20
8 2000     5   9      2 1500   23

Philip


On 23/10/2016 4:50 AM, lily li wrote:
> Hi R users,
>
> I want to melt a dataframe, but it mixed up the variables.
>
> DF is the original dataset:
> year  month  day  site1_elev  site2_elev  site1_temp  site2_temp
> 2000     5        6        1300          1500            20              21
>
> 2000     5        7        1300          1500            21              22
> 2000     5        8        1300          1500            19              20
> 2000     5        9        1300          1500            22              23
>
> How to melt the dataframe and get the following dataset? Thanks for your
> help.
>
> year  month  day  siteID   elev   temp
> 2000    5         6       1      1300    20
> 2000    5         6       2      1500    21
> 2000    5         7       1      1300    21
> 2000    5         7       2      1500    22
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mkopyt at wne.uw.edu.pl  Sun Oct 23 11:57:43 2016
From: mkopyt at wne.uw.edu.pl (Mateusz Kopyt)
Date: Sun, 23 Oct 2016 11:57:43 +0200
Subject: [R] gtools Gator infected...
In-Reply-To: <31f7d972-99f9-5f90-63c0-7fe36ab0dc85@gvdnet.dk>
References: <3acd73dc-bcfd-d211-4563-5fba5ed467e7@gvdnet.dk>
	<31f7d972-99f9-5f90-63c0-7fe36ab0dc85@gvdnet.dk>
Message-ID: <fc89166a-7b93-7319-0c74-6657c7899cba@wne.uw.edu.pl>

One of my student also noticed such report (about Gator) from Spyhunter. 
We have checked that the file on the computer is identical to this from 
repo.
So probably it was a false alarm. If you have some information from 
enigmasoftware, please share on the list.

Best regards
Mateusz Kopyt
WNE UW, Poland

W dniu 22.10.2016 o 13:31, Troels Ring pisze:
> Thanks a lot - I have asked enigmasoftware to go and check up on this 
> - and they'll also see your letter!
>
> BW
> Troels
>
>
> Den 22-10-2016 kl. 13:12 skrev Bob Rudis:
>> I think your tool is a bit overzealous. VirusTotal -
>> https://virustotal.com/en/file/5fd1b2fc5c061c0836a70cbad620893a89a27d9251358a5c42c3e49113c9456c/analysis/ 
>>
>> & 
>> https://virustotal.com/en/file/e133ebf5001e1e991f1f6b425adcfbab170fe3c02656e3a697a5ebea961e909c/analysis/
>> - shows no sign of any malware in the 32-bit DLLor 64-bit DLL (I
>> tested  r-release: gtools_3.5.0.zip)
>>
>> On Sat, Oct 22, 2016 at 4:50 AM, Troels Ring <tring at gvdnet.dk> wrote:
>>> Hi friends - just installed gtools to make rstan run. Was rapidly 
>>> informed
>>> by Spyhunter 4 that gtools.dll harboured Gator. Spyhunter 4 then
>>> aggressively removed Gator - and gtools were gone and rstan out of 
>>> function.
>>> Kind of sorry about this.
>>>
>>> Best wishes
>>>
>>> Troels Ring
>>>
>>> Aalborg, Denmark
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tring at gvdnet.dk  Sun Oct 23 12:57:25 2016
From: tring at gvdnet.dk (Troels Ring)
Date: Sun, 23 Oct 2016 12:57:25 +0200
Subject: [R] gtools Gator infected...
In-Reply-To: <31f7d972-99f9-5f90-63c0-7fe36ab0dc85@gvdnet.dk>
References: <3acd73dc-bcfd-d211-4563-5fba5ed467e7@gvdnet.dk>
	<31f7d972-99f9-5f90-63c0-7fe36ab0dc85@gvdnet.dk>
Message-ID: <e3e3cf94-cb8c-6ff4-69fb-f883b908f18a@gvdnet.dk>

I have informed the vendor that perhaps spyhunter 4 is too aggressive. 
They suggested I could make an exclusion - but it turned out to be not 
looking for Gator rather than not looking in gtools.dll. I shall inform 
if anything appears

BW

Troels


Den 23-10-2016 kl. 11:57 skrev Mateusz Kopyt:
> One of my student also noticed such report (about Gator) from 
> Spyhunter. We have checked that the file on the computer is identical 
> to this from repo.
> So probably it was a false alarm. If you have some information from 
> enigmasoftware, please share on the list.
>
> Best regards
> Mateusz Kopyt
> WNE UW, Poland
>
> W dniu 22.10.2016 o 13:31, Troels Ring pisze:
>> Thanks a lot - I have asked enigmasoftware to go and check up on this 
>> - and they'll also see your letter!
>>
>> BW
>> Troels
>>
>>
>> Den 22-10-2016 kl. 13:12 skrev Bob Rudis:
>>> I think your tool is a bit overzealous. VirusTotal -
>>> https://virustotal.com/en/file/5fd1b2fc5c061c0836a70cbad620893a89a27d9251358a5c42c3e49113c9456c/analysis/ 
>>>
>>> & 
>>> https://virustotal.com/en/file/e133ebf5001e1e991f1f6b425adcfbab170fe3c02656e3a697a5ebea961e909c/analysis/
>>> - shows no sign of any malware in the 32-bit DLLor 64-bit DLL (I
>>> tested  r-release: gtools_3.5.0.zip)
>>>
>>> On Sat, Oct 22, 2016 at 4:50 AM, Troels Ring <tring at gvdnet.dk> wrote:
>>>> Hi friends - just installed gtools to make rstan run. Was rapidly 
>>>> informed
>>>> by Spyhunter 4 that gtools.dll harboured Gator. Spyhunter 4 then
>>>> aggressively removed Gator - and gtools were gone and rstan out of 
>>>> function.
>>>> Kind of sorry about this.
>>>>
>>>> Best wishes
>>>>
>>>> Troels Ring
>>>>
>>>> Aalborg, Denmark
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From cbenjami at BTBOCES.ORG  Sun Oct 23 17:56:33 2016
From: cbenjami at BTBOCES.ORG (Courtney Benjamin)
Date: Sun, 23 Oct 2016 15:56:33 +0000
Subject: [R] Significance of Svyrepdesign Object Warning
Message-ID: <1477238188762.32714@BTBOCES.ORG>

Hello R Users,

I am using Lumley's Survey Package in R to analyze complex survey data that involves 200 balanced repeated replicate (BRR) weight variables.  I have ensured that my svyrepdesign object that specifies the application of the BRR weights to the data set is accurate and I have matched the published standard errors of the data set.

When doing a logistic regression through the svyglm call, I receive the following warning:

In object$survey.design$pweights * presid^2 :
  longer object length is not a multiple of shorter object length?
I have search around quite a bit online and have not been able to find any good interpretation of its meaning.  I want to be sure that I am not making some type of mistake that is causing this warning to be produced.  Any advisement is greatly appreciated.
The following is an MRE that can be pasted into the R console:
library(RCurl)
library(survey)
data <- getURL("https://raw.githubusercontent.com/cbenjamin1821/careertech-ed/master/elsq1adj.csv")
elsq1ch <- read.csv(text = data)
#Specifying the svyrepdesign object which applies the BRR weights
elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights = elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type = "BRR")
elsq1ch_brr
#Logistic regression call which yields a warning regarding svyrepdesign object
svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
allCC <- summary(svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude))
allCC

#Session Info
#R version 3.3.1 (2016-06-21)
#Platform: x86_64-w64-mingw32/x64 (64-bit)
#Running under: Windows >= 8 x64 (build 9200)

#locale:
#  [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
#[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
#[5] LC_TIME=English_United States.1252
#attached base packages:
#  [1] grid      stats     graphics  grDevices utils     datasets  methods   base
#other attached packages:
#[1] survey_3.31-2   survival_2.39-4 Matrix_1.2-6    RCurl_1.95-4.8  bitops_1.0-6
#loaded via a namespace (and not attached):
#[1] tools_3.3.1     splines_3.3.1   knitr_1.14      lattice_0.20-33


Courtney Benjamin

Broome-Tioga BOCES

Automotive Technology II Teacher

Located at Gault Toyota

Doctoral Candidate-Educational Theory & Practice

State University of New York at Binghamton

cbenjami at btboces.org<mailto:cbenjami at btboces.org>

607-763-8633

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Oct 23 18:18:17 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 23 Oct 2016 09:18:17 -0700
Subject: [R] Using with() to avoid $ ?
In-Reply-To: <CAGxFJbQcSimmdOmKvckGU7O=4Xi1sWxP38MFLdg-RTu3ZMUwXA@mail.gmail.com>
References: <CAGxFJbSQEN98S5uu9Z4Gpd2ywi=CaaRN=wneyFT3oc0q2XJ+YQ@mail.gmail.com>
	<CAGxFJbRd=3d8asajk+dm4YGfigpd63cLbAUiG4e2zcSCYfN-zw@mail.gmail.com>
	<CAGxFJbRaiAhub8jDsGkGgS5WRhLdeLVZoAVZXRH2csL1k1bQqQ@mail.gmail.com>
	<CAGxFJbRQ75UVtFQGZucdAS=w1=G3ufn-sd4nLS0ASm6Tmg8tmQ@mail.gmail.com>
	<CAGxFJbQVCy_uNu3D5Aqsx7fAYTR-mO+KhVsGQNGDMFnqAGB34Q@mail.gmail.com>
	<CAGxFJbS1GaMinQW2fiDGy=4YwD1ZqjODOivC_2+AGfFXGTZi5w@mail.gmail.com>
	<CAGxFJbRK1Gy1q-1q0ggmCKO+N-t_VW6EX4htLh6C_+uHR08C_A@mail.gmail.com>
	<CAGxFJbRUwcZ26Wm_pebfH8wrEA6g2a1M7oibWP2enwH1S+km1g@mail.gmail.com>
	<CAGxFJbSNARhTjYQH01=FKCNLBpn4UiRZasky=_P5j=hmnOP7cg@mail.gmail.com>
	<CAGxFJbQ83tuAjFLrrwV-xLYP2Ev0SjSS=gJzTShULNOdB15NVA@mail.gmail.com>
	<CAGxFJbRhEX1=2EwezHgd8ssngTt=d47v8zZZr2hdiOeaLseZvA@mail.gmail.com>
	<CAGxFJbS9usiDSCacNATo6GOmowLbdrwP2QOCuA1BjDzDzU2DWg@mail.gmail.com>
	<CAGxFJbRxN1fgD4hTM1mF8BDqemPAJ5mu+oCw0Rq7tXwBwS_6WQ@mail.gmail.com>
	<CAGxFJbTR4RXKcitfvWpinqqS6B9gZF8KpfNKYE8x7rvm8hOxgw@mail.gmail.com>
	<CAGxFJbTScSie7WRd41-0wQXn7PkeDbBsJTmmgTVOvZ+=5k6OWw@mail.gmail.com>
	<CAGxFJbRfCAq60WeJ9gSkUf-govXCu7_ucAKxO-85jRAOdZ7Vrg@mail.gmail.com>
	<CAGxFJbRd=qdfnvdAv5hhDjAkqQLXPKWykSeMRm8UFsdQ4gL00Q@mail.gmail.com>
	<CAGxFJbS+CK79AyrWtr6L8iU9-8Vub-Z1Fm+MC9WOdiPW04LZOQ@mail.gmail.com>
	<CAGxFJbT1Ob3TsPWR=1by14h4f0tFjQvV9_UnFpKYdE8Tu1GJiA@mail.gmail.com>
	<CAGxFJbTZ-Z65nb-fKe-KRsc_sYGReSneifXWT=AORx0J4VL8Uw@mail.gmail.com>
	<CAGxFJbS6_AnN9Aype-yWCREHPw287siMjwe3jVN0cXe1Vh_RPA@mail.gmail.com>
	<CAGxFJbQD-Q=R1ikADh+eiRP8=5yTzdSasdS5sMEAOTYJP9Ah7Q@mail.gmail.com>
	<CAGxFJbQg8=9Zau3jEhn1SyOTuhfSjKf5hnwTeQ3nyR+VgnMDVg@mail.gmail.com>
	<CAGxFJbQS9Wq5iW-3k7fe5btO3cCg4DzgGVZmZBqqSjzfQT-Mtw@mail.gmail.com>
	<CAGxFJbQcSimmdOmKvckGU7O=4Xi1sWxP38MFLdg-RTu3ZMUwXA@mail.gmail.com>
Message-ID: <CAGxFJbRRqAftjDprpxe4bG8C8QZK794FwDTNadB47fP1SLrxnQ@mail.gmail.com>

As has been noted oftimes on this list
f( y ~ x1 + x2 + x3 + ... , data = foo,  ...)

is much preferable to
f( foo$y ~ foo$x1 + foo$x2 + foo$x3 + ...,  ...)

(with no data argument), using nse = non-standard evaluation to set the
environment for formula evaluation. However, as queries here recently
demonstrate,  the formula variables (y, x1, x2, x3, ...) or other variables
in foo are also sometimes needed as further arguments of f,  and these have
to be explicitly and tediously given as foo$whatever or equivalent indexing.

So my question is, can/should with() be used instead in the form
with(foo, f( y ~ x1 + x2 + x3 + ... , data = foo,  ...))  with no explicit
$ or indexing in ... variables?

or even
with(foo, f( y ~ x1 + x2 + x3 + ... ,  ...))

with no data argument for nse or indexing, though this seems to me
questionable in that it may affect the formula's  environment
differently.(??)

Please correct any misstatements of fact in the above as well as clarifying
anything else I seem confused about.

Many thanks.

Bert

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Oct 23 19:24:06 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 23 Oct 2016 10:24:06 -0700
Subject: [R] Using with() to avoid $ ?
In-Reply-To: <CAGxFJbRRqAftjDprpxe4bG8C8QZK794FwDTNadB47fP1SLrxnQ@mail.gmail.com>
References: <CAGxFJbSQEN98S5uu9Z4Gpd2ywi=CaaRN=wneyFT3oc0q2XJ+YQ@mail.gmail.com>
	<CAGxFJbTR4RXKcitfvWpinqqS6B9gZF8KpfNKYE8x7rvm8hOxgw@mail.gmail.com>
	<CAGxFJbTScSie7WRd41-0wQXn7PkeDbBsJTmmgTVOvZ+=5k6OWw@mail.gmail.com>
	<CAGxFJbRfCAq60WeJ9gSkUf-govXCu7_ucAKxO-85jRAOdZ7Vrg@mail.gmail.com>
	<CAGxFJbRd=qdfnvdAv5hhDjAkqQLXPKWykSeMRm8UFsdQ4gL00Q@mail.gmail.com>
	<CAGxFJbS+CK79AyrWtr6L8iU9-8Vub-Z1Fm+MC9WOdiPW04LZOQ@mail.gmail.com>
	<CAGxFJbT1Ob3TsPWR=1by14h4f0tFjQvV9_UnFpKYdE8Tu1GJiA@mail.gmail.com>
	<CAGxFJbTZ-Z65nb-fKe-KRsc_sYGReSneifXWT=AORx0J4VL8Uw@mail.gmail.com>
	<CAGxFJbS6_AnN9Aype-yWCREHPw287siMjwe3jVN0cXe1Vh_RPA@mail.gmail.com>
	<CAGxFJbQD-Q=R1ikADh+eiRP8=5yTzdSasdS5sMEAOTYJP9Ah7Q@mail.gmail.com>
	<CAGxFJbQg8=9Zau3jEhn1SyOTuhfSjKf5hnwTeQ3nyR+VgnMDVg@mail.gmail.com>
	<CAGxFJbQS9Wq5iW-3k7fe5btO3cCg4DzgGVZmZBqqSjzfQT-Mtw@mail.gmail.com>
	<CAGxFJbQcSimmdOmKvckGU7O=4Xi1sWxP38MFLdg-RTu3ZMUwXA@mail.gmail.com>
	<CAGxFJbRRqAftjDprpxe4bG8C8QZK794FwDTNadB47fP1SLrxnQ@mail.gmail.com>
Message-ID: <9B73F3F5-7604-466C-A809-FD69B6BB5658@dcn.davis.ca.us>

No. And I don't know why you are conflating the treatment of variables in the formula with treatment of variables passed as other arguments. It is sort of like thinking the x symbols in foo$x[ x < 0 ] refer to the same data. 

foo$y ~ foo$x1 + foo$x2 + foo$x3 is not preferable, and given the availability of a data argument such redundancy is unnecessary. NSE is already in use for the formula. It is not (necessarily) in use for the other arguments, so you just have to learn which arguments are being handled with NSE by any particular function and which are not... good docs would be the preferred avenue but recognizing the error message that arises when you fail to specify foo$ for the non-formula arguments gets me by if the docs are unclear. 

However, it is dangerous to apply NSE tricks recursively, so piling "with" on top of the existing formula eval-with-data is only likely to confuse the evaluation context even more. 

-- 
Sent from my phone. Please excuse my brevity.

On October 23, 2016 9:18:17 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>As has been noted oftimes on this list
>f( y ~ x1 + x2 + x3 + ... , data = foo,  ...)
>
>is much preferable to
>f( foo$y ~ foo$x1 + foo$x2 + foo$x3 + ...,  ...)
>
>(with no data argument), using nse = non-standard evaluation to set the
>environment for formula evaluation. However, as queries here recently
>demonstrate,  the formula variables (y, x1, x2, x3, ...) or other
>variables
>in foo are also sometimes needed as further arguments of f,  and these
>have
>to be explicitly and tediously given as foo$whatever or equivalent
>indexing.
>
>So my question is, can/should with() be used instead in the form
>with(foo, f( y ~ x1 + x2 + x3 + ... , data = foo,  ...))  with no
>explicit
>$ or indexing in ... variables?
>
>or even
>with(foo, f( y ~ x1 + x2 + x3 + ... ,  ...))
>
>with no data argument for nse or indexing, though this seems to me
>questionable in that it may affect the formula's  environment
>differently.(??)
>
>Please correct any misstatements of fact in the above as well as
>clarifying
>anything else I seem confused about.
>
>Many thanks.
>
>Bert
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Sun Oct 23 20:17:35 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Sun, 23 Oct 2016 14:17:35 -0400
Subject: [R] Significance of Svyrepdesign Object Warning
In-Reply-To: <1477238188762.32714@BTBOCES.ORG>
References: <1477238188762.32714@BTBOCES.ORG>
Message-ID: <CAOwvMDy-RPreSvxgU-Gbo6gXb4xBzOaTsig2Qt8vYjNX7f_=og@mail.gmail.com>

hi, great example.  i am ccing survey package author/maintainer dr.
lumley.  why do you have `na.action=na.exclude`?  if you remove it, things
work as expected--


    library(RCurl)
    library(survey)
    data <- getURL("
https://raw.githubusercontent.com/cbenjamin1821/careertech-ed/master/elsq1adj.csv
")
    elsq1ch <- read.csv(text = data)
    #Specifying the svyrepdesign object which applies the BRR weights
    elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights =
elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type =
"BRR")
    elsq1ch_brr
    #Logistic regression call which yields a warning regarding svyrepdesign
object

    # your warning
    a <-
svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
    summary(a)

    # works fine
    a <-
svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1)
    summary(a)



    the mismatch of vectors generating that warning happens inside

    debug(survey:::summary.svrepglm)

    [..snip..]

    Browse[2]> length(presid)
    [1] 12614
    Browse[2]> length(object$survey.design$pweights)
    [1] 8397


    and including vs excluding the na.action=na.exclude gives you a
slightly different dispersion parameter calculation

        (Dispersion parameter for binomial family taken to be 0.7756235)

        (Dispersion parameter for binomial family taken to be 0.7849244)


not sure if the two survey:::residuals.sv* methods should deal with the
na.action= parameter?


thanks

On Sun, Oct 23, 2016 at 11:56 AM, Courtney Benjamin <cbenjami at btboces.org>
wrote:

> Hello R Users,
>
> I am using Lumley's Survey Package in R to analyze complex survey data
> that involves 200 balanced repeated replicate (BRR) weight variables.  I
> have ensured that my svyrepdesign object that specifies the application of
> the BRR weights to the data set is accurate and I have matched the
> published standard errors of the data set.
>
> When doing a logistic regression through the svyglm call, I receive the
> following warning:
>
> In object$survey.design$pweights * presid^2 :
>   longer object length is not a multiple of shorter object length?
> I have search around quite a bit online and have not been able to find any
> good interpretation of its meaning.  I want to be sure that I am not making
> some type of mistake that is causing this warning to be produced.  Any
> advisement is greatly appreciated.
> The following is an MRE that can be pasted into the R console:
> library(RCurl)
> library(survey)
> data <- getURL("https://raw.githubusercontent.com/
> cbenjamin1821/careertech-ed/master/elsq1adj.csv")
> elsq1ch <- read.csv(text = data)
> #Specifying the svyrepdesign object which applies the BRR weights
> elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights =
> elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type =
> "BRR")
> elsq1ch_brr
> #Logistic regression call which yields a warning regarding svyrepdesign
> object
> svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+
> F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=
> elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
> allCC <- summary(svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+
> F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",
> design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude))
> allCC
>
> #Session Info
> #R version 3.3.1 (2016-06-21)
> #Platform: x86_64-w64-mingw32/x64 (64-bit)
> #Running under: Windows >= 8 x64 (build 9200)
>
> #locale:
> #  [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
> #[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> #[5] LC_TIME=English_United States.1252
> #attached base packages:
> #  [1] grid      stats     graphics  grDevices utils     datasets
> methods   base
> #other attached packages:
> #[1] survey_3.31-2   survival_2.39-4 Matrix_1.2-6    RCurl_1.95-4.8
> bitops_1.0-6
> #loaded via a namespace (and not attached):
> #[1] tools_3.3.1     splines_3.3.1   knitr_1.14      lattice_0.20-33
>
>
> Courtney Benjamin
>
> Broome-Tioga BOCES
>
> Automotive Technology II Teacher
>
> Located at Gault Toyota
>
> Doctoral Candidate-Educational Theory & Practice
>
> State University of New York at Binghamton
>
> cbenjami at btboces.org<mailto:cbenjami at btboces.org>
>
> 607-763-8633
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Oct 23 20:24:04 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 23 Oct 2016 11:24:04 -0700
Subject: [R] Significance of Svyrepdesign Object Warning
In-Reply-To: <CAOwvMDy-RPreSvxgU-Gbo6gXb4xBzOaTsig2Qt8vYjNX7f_=og@mail.gmail.com>
References: <1477238188762.32714@BTBOCES.ORG>
	<CAOwvMDy-RPreSvxgU-Gbo6gXb4xBzOaTsig2Qt8vYjNX7f_=og@mail.gmail.com>
Message-ID: <CAF8bMcaZqm=0ykGfEYkBOYObraxY2AGCQ9uMOi+WmE9wdTRV_g@mail.gmail.com>

The immediate problem could be solved by changing the following lines in
survey:::summary.svrepglm from
    presid <- resid(object, "pearson")
    dispersion <- sum(object$survey.design$pweights * presid^2,
        na.rm = TRUE)/sum(object$survey.design$pweights)
to
    presid <- resid(object, "pearson")
    pweights <- naresid(object$na.action, object$survey.design$pweights)
    dispersion <- sum(pweights * presid^2, na.rm = TRUE)/sum(pweights,
        na.rm = TRUE)

'naresid' uses the information from na.exclude to match up the residuals
with the row in the data that they correspond to.  resid() calls it so it
should
also be applied to pweights so they line up correctly.




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Oct 23, 2016 at 11:17 AM, Anthony Damico <ajdamico at gmail.com> wrote:

> hi, great example.  i am ccing survey package author/maintainer dr.
> lumley.  why do you have `na.action=na.exclude`?  if you remove it, things
> work as expected--
>
>
>     library(RCurl)
>     library(survey)
>     data <- getURL("
> https://raw.githubusercontent.com/cbenjamin1821/careertech-
> ed/master/elsq1adj.csv
> ")
>     elsq1ch <- read.csv(text = data)
>     #Specifying the svyrepdesign object which applies the BRR weights
>     elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights =
> elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type =
> "BRR")
>     elsq1ch_brr
>     #Logistic regression call which yields a warning regarding svyrepdesign
> object
>
>     # your warning
>     a <-
> svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+
> F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=
> elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
>     summary(a)
>
>     # works fine
>     a <-
> svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+
> F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=
> elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1)
>     summary(a)
>
>
>
>     the mismatch of vectors generating that warning happens inside
>
>     debug(survey:::summary.svrepglm)
>
>     [..snip..]
>
>     Browse[2]> length(presid)
>     [1] 12614
>     Browse[2]> length(object$survey.design$pweights)
>     [1] 8397
>
>
>     and including vs excluding the na.action=na.exclude gives you a
> slightly different dispersion parameter calculation
>
>         (Dispersion parameter for binomial family taken to be 0.7756235)
>
>         (Dispersion parameter for binomial family taken to be 0.7849244)
>
>
> not sure if the two survey:::residuals.sv* methods should deal with the
> na.action= parameter?
>
>
> thanks
>
> On Sun, Oct 23, 2016 at 11:56 AM, Courtney Benjamin <cbenjami at btboces.org>
> wrote:
>
> > Hello R Users,
> >
> > I am using Lumley's Survey Package in R to analyze complex survey data
> > that involves 200 balanced repeated replicate (BRR) weight variables.  I
> > have ensured that my svyrepdesign object that specifies the application
> of
> > the BRR weights to the data set is accurate and I have matched the
> > published standard errors of the data set.
> >
> > When doing a logistic regression through the svyglm call, I receive the
> > following warning:
> >
> > In object$survey.design$pweights * presid^2 :
> >   longer object length is not a multiple of shorter object length?
> > I have search around quite a bit online and have not been able to find
> any
> > good interpretation of its meaning.  I want to be sure that I am not
> making
> > some type of mistake that is causing this warning to be produced.  Any
> > advisement is greatly appreciated.
> > The following is an MRE that can be pasted into the R console:
> > library(RCurl)
> > library(survey)
> > data <- getURL("https://raw.githubusercontent.com/
> > cbenjamin1821/careertech-ed/master/elsq1adj.csv")
> > elsq1ch <- read.csv(text = data)
> > #Specifying the svyrepdesign object which applies the BRR weights
> > elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights =
> > elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type =
> > "BRR")
> > elsq1ch_brr
> > #Logistic regression call which yields a warning regarding svyrepdesign
> > object
> > svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+
> > F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=
> > elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
> > allCC <- summary(svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+
> > F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",
> > design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude))
> > allCC
> >
> > #Session Info
> > #R version 3.3.1 (2016-06-21)
> > #Platform: x86_64-w64-mingw32/x64 (64-bit)
> > #Running under: Windows >= 8 x64 (build 9200)
> >
> > #locale:
> > #  [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> > States.1252
> > #[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> > #[5] LC_TIME=English_United States.1252
> > #attached base packages:
> > #  [1] grid      stats     graphics  grDevices utils     datasets
> > methods   base
> > #other attached packages:
> > #[1] survey_3.31-2   survival_2.39-4 Matrix_1.2-6    RCurl_1.95-4.8
> > bitops_1.0-6
> > #loaded via a namespace (and not attached):
> > #[1] tools_3.3.1     splines_3.3.1   knitr_1.14      lattice_0.20-33
> >
> >
> > Courtney Benjamin
> >
> > Broome-Tioga BOCES
> >
> > Automotive Technology II Teacher
> >
> > Located at Gault Toyota
> >
> > Doctoral Candidate-Educational Theory & Practice
> >
> > State University of New York at Binghamton
> >
> > cbenjami at btboces.org<mailto:cbenjami at btboces.org>
> >
> > 607-763-8633
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Oct 23 21:43:46 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 23 Oct 2016 12:43:46 -0700
Subject: [R] Using with() to avoid $ ?
In-Reply-To: <9B73F3F5-7604-466C-A809-FD69B6BB5658@dcn.davis.ca.us>
References: <CAGxFJbSQEN98S5uu9Z4Gpd2ywi=CaaRN=wneyFT3oc0q2XJ+YQ@mail.gmail.com>
	<CAGxFJbTR4RXKcitfvWpinqqS6B9gZF8KpfNKYE8x7rvm8hOxgw@mail.gmail.com>
	<CAGxFJbTScSie7WRd41-0wQXn7PkeDbBsJTmmgTVOvZ+=5k6OWw@mail.gmail.com>
	<CAGxFJbRfCAq60WeJ9gSkUf-govXCu7_ucAKxO-85jRAOdZ7Vrg@mail.gmail.com>
	<CAGxFJbRd=qdfnvdAv5hhDjAkqQLXPKWykSeMRm8UFsdQ4gL00Q@mail.gmail.com>
	<CAGxFJbS+CK79AyrWtr6L8iU9-8Vub-Z1Fm+MC9WOdiPW04LZOQ@mail.gmail.com>
	<CAGxFJbT1Ob3TsPWR=1by14h4f0tFjQvV9_UnFpKYdE8Tu1GJiA@mail.gmail.com>
	<CAGxFJbTZ-Z65nb-fKe-KRsc_sYGReSneifXWT=AORx0J4VL8Uw@mail.gmail.com>
	<CAGxFJbS6_AnN9Aype-yWCREHPw287siMjwe3jVN0cXe1Vh_RPA@mail.gmail.com>
	<CAGxFJbQD-Q=R1ikADh+eiRP8=5yTzdSasdS5sMEAOTYJP9Ah7Q@mail.gmail.com>
	<CAGxFJbQg8=9Zau3jEhn1SyOTuhfSjKf5hnwTeQ3nyR+VgnMDVg@mail.gmail.com>
	<CAGxFJbQS9Wq5iW-3k7fe5btO3cCg4DzgGVZmZBqqSjzfQT-Mtw@mail.gmail.com>
	<CAGxFJbQcSimmdOmKvckGU7O=4Xi1sWxP38MFLdg-RTu3ZMUwXA@mail.gmail.com>
	<CAGxFJbRRqAftjDprpxe4bG8C8QZK794FwDTNadB47fP1SLrxnQ@mail.gmail.com>
	<9B73F3F5-7604-466C-A809-FD69B6BB5658@dcn.davis.ca.us>
Message-ID: <CAGxFJbSm20dOPNokW-0ac-KZxz9KLkTTXv4v4Xr5zXiyGJsKSA@mail.gmail.com>

Yes, variables in the formula should be handled by nse with the data
argument. Got it -- thanks. But still ... can with() be used to handle
those and/or any other variables in foo that appear as arguments. I see no
problems in doing so, but ... ?

Bert

(But see inline below)

On Oct 23, 2016 7:24 PM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:
>
> No. And I don't know why you are conflating the treatment of variables in
the formula with treatment of variables passed as other arguments. It is
sort of like thinking the x symbols in foo$x[ x < 0 ] refer to the same
data.

In my query they explicitly do, though. Nevertheless your response was
apropos.

>
> foo$y ~ foo$x1 + foo$x2 + foo$x3 is not preferable, and given the
availability of a data argument such redundancy is unnecessary. NSE is
already in use for the formula. It is not (necessarily) in use for the
other arguments, so you just have to learn which arguments are being
handled with NSE by any particular function and which are not... good docs
would be the preferred avenue but recognizing the error message that arises
when you fail to specify foo$ for the non-formula arguments gets me by if
the docs are unclear.
>
> However, it is dangerous to apply NSE tricks recursively, so piling
"with" on top of the existing formula eval-with-data is only likely to
confuse the evaluation context even more.

This is what I'm not sure of. Can you give an example of when such
confusion would occur?


>
> --
> Sent from my phone. Please excuse my brevity.
>
> On October 23, 2016 9:18:17 AM PDT, Bert Gunter <bgunter.4567 at gmail.com>
wrote:
> >As has been noted oftimes on this list
> >f( y ~ x1 + x2 + x3 + ... , data = foo,  ...)
> >
> >is much preferable to
> >f( foo$y ~ foo$x1 + foo$x2 + foo$x3 + ...,  ...)
> >
> >(with no data argument), using nse = non-standard evaluation to set the
> >environment for formula evaluation. However, as queries here recently
> >demonstrate,  the formula variables (y, x1, x2, x3, ...) or other
> >variables
> >in foo are also sometimes needed as further arguments of f,  and these
> >have
> >to be explicitly and tediously given as foo$whatever or equivalent
> >indexing.
> >
> >So my question is, can/should with() be used instead in the form
> >with(foo, f( y ~ x1 + x2 + x3 + ... , data = foo,  ...))  with no
> >explicit
> >$ or indexing in ... variables?
> >
> >or even
> >with(foo, f( y ~ x1 + x2 + x3 + ... ,  ...))
> >
> >with no data argument for nse or indexing, though this seems to me
> >questionable in that it may affect the formula's  environment
> >differently.(??)
> >
> >Please correct any misstatements of fact in the above as well as
> >clarifying
> >anything else I seem confused about.
> >
> >Many thanks.
> >
> >Bert
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cbenjami at BTBOCES.ORG  Sun Oct 23 22:31:17 2016
From: cbenjami at BTBOCES.ORG (Courtney Benjamin)
Date: Sun, 23 Oct 2016 20:31:17 +0000
Subject: [R] Significance of Svyrepdesign Object Warning
In-Reply-To: <CAF8bMcaZqm=0ykGfEYkBOYObraxY2AGCQ9uMOi+WmE9wdTRV_g@mail.gmail.com>
References: <1477238188762.32714@BTBOCES.ORG>
	<CAOwvMDy-RPreSvxgU-Gbo6gXb4xBzOaTsig2Qt8vYjNX7f_=og@mail.gmail.com>,
	<CAF8bMcaZqm=0ykGfEYkBOYObraxY2AGCQ9uMOi+WmE9wdTRV_g@mail.gmail.com>
Message-ID: <1477254672775.39745@BTBOCES.ORG>

?Thank you for your help.  I did try Anthony's recommendation of removing the 'na.action=na.exclude' ; I thought I needed that argument as the data set includes NA values.  I found it interesting that without the 'na.action=na.exclude' argument, the baseline level of two of my predictor variables (BYINCOME & F1HIMATH) were changed.


Courtney Benjamin

Broome-Tioga BOCES

Automotive Technology II Teacher

Located at Gault Toyota

Doctoral Candidate-Educational Theory & Practice

State University of New York at Binghamton

cbenjami at btboces.org<mailto:cbenjami at btboces.org>

607-763-8633

________________________________
From: William Dunlap <wdunlap at tibco.com>
Sent: Sunday, October 23, 2016 2:24 PM
To: Anthony Damico
Cc: Courtney Benjamin; r-help at r-project.org; Thomas Lumley
Subject: Re: [R] Significance of Svyrepdesign Object Warning

The immediate problem could be solved by changing the following lines in survey:::summary.svrepglm from
    presid <- resid(object, "pearson")
    dispersion <- sum(object$survey.design$pweights * presid^2,
        na.rm = TRUE)/sum(object$survey.design$pweights)
to
    presid <- resid(object, "pearson")
    pweights <- naresid(object$na.action, object$survey.design$pweights)
    dispersion <- sum(pweights * presid^2, na.rm = TRUE)/sum(pweights,
        na.rm = TRUE)

'naresid' uses the information from na.exclude to match up the residuals
with the row in the data that they correspond to.  resid() calls it so it should
also be applied to pweights so they line up correctly.




Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Sun, Oct 23, 2016 at 11:17 AM, Anthony Damico <ajdamico at gmail.com<mailto:ajdamico at gmail.com>> wrote:
hi, great example.  i am ccing survey package author/maintainer dr.
lumley.  why do you have `na.action=na.exclude`?  if you remove it, things
work as expected--


    library(RCurl)
    library(survey)
    data <- getURL("
https://raw.githubusercontent.com/cbenjamin1821/careertech-ed/master/elsq1adj.csv
")
    elsq1ch <- read.csv(text = data)
    #Specifying the svyrepdesign object which applies the BRR weights
    elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights =
elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type =
"BRR")
    elsq1ch_brr
    #Logistic regression call which yields a warning regarding svyrepdesign
object

    # your warning
    a <-
svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
    summary(a)

    # works fine
    a <-
svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1)
    summary(a)



    the mismatch of vectors generating that warning happens inside

    debug(survey:::summary.svrepglm)

    [..snip..]

    Browse[2]> length(presid)
    [1] 12614
    Browse[2]> length(object$survey.design$pweights)
    [1] 8397


    and including vs excluding the na.action=na.exclude gives you a
slightly different dispersion parameter calculation

        (Dispersion parameter for binomial family taken to be 0.7756235)

        (Dispersion parameter for binomial family taken to be 0.7849244)


not sure if the two survey:::residuals.sv<http://residuals.sv>* methods should deal with the
na.action= parameter?


thanks

On Sun, Oct 23, 2016 at 11:56 AM, Courtney Benjamin <cbenjami at btboces.org<mailto:cbenjami at btboces.org>>
wrote:

> Hello R Users,
>
> I am using Lumley's Survey Package in R to analyze complex survey data
> that involves 200 balanced repeated replicate (BRR) weight variables.  I
> have ensured that my svyrepdesign object that specifies the application of
> the BRR weights to the data set is accurate and I have matched the
> published standard errors of the data set.
>
> When doing a logistic regression through the svyglm call, I receive the
> following warning:
>
> In object$survey.design$pweights * presid^2 :
>   longer object length is not a multiple of shorter object length?
> I have search around quite a bit online and have not been able to find any
> good interpretation of its meaning.  I want to be sure that I am not making
> some type of mistake that is causing this warning to be produced.  Any
> advisement is greatly appreciated.
> The following is an MRE that can be pasted into the R console:
> library(RCurl)
> library(survey)
> data <- getURL("https://raw.githubusercontent.com/
> cbenjamin1821/careertech-ed/master/elsq1adj.csv")
> elsq1ch <- read.csv(text = data)
> #Specifying the svyrepdesign object which applies the BRR weights
> elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights =
> elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type =
> "BRR")
> elsq1ch_brr
> #Logistic regression call which yields a warning regarding svyrepdesign
> object
> svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+
> F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=
> elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
> allCC <- summary(svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+
> F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",
> design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude))
> allCC
>
> #Session Info
> #R version 3.3.1 (2016-06-21)
> #Platform: x86_64-w64-mingw32/x64 (64-bit)
> #Running under: Windows >= 8 x64 (build 9200)
>
> #locale:
> #  [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
> #[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> #[5] LC_TIME=English_United States.1252
> #attached base packages:
> #  [1] grid      stats     graphics  grDevices utils     datasets
> methods   base
> #other attached packages:
> #[1] survey_3.31-2   survival_2.39-4 Matrix_1.2-6    RCurl_1.95-4.8
> bitops_1.0-6
> #loaded via a namespace (and not attached):
> #[1] tools_3.3.1     splines_3.3.1   knitr_1.14      lattice_0.20-33
>
>
> Courtney Benjamin
>
> Broome-Tioga BOCES
>
> Automotive Technology II Teacher
>
> Located at Gault Toyota
>
> Doctoral Candidate-Educational Theory & Practice
>
> State University of New York at Binghamton
>
> cbenjami at btboces.org<mailto:cbenjami at btboces.org><mailto:cbenjami at btboces.org<mailto:cbenjami at btboces.org>>
>
> 607-763-8633<tel:607-763-8633>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Oct 24 00:22:46 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 23 Oct 2016 18:22:46 -0400
Subject: [R] Using with() to avoid $ ?
In-Reply-To: <CAGxFJbSm20dOPNokW-0ac-KZxz9KLkTTXv4v4Xr5zXiyGJsKSA@mail.gmail.com>
References: <CAGxFJbSQEN98S5uu9Z4Gpd2ywi=CaaRN=wneyFT3oc0q2XJ+YQ@mail.gmail.com>
	<CAGxFJbRfCAq60WeJ9gSkUf-govXCu7_ucAKxO-85jRAOdZ7Vrg@mail.gmail.com>
	<CAGxFJbRd=qdfnvdAv5hhDjAkqQLXPKWykSeMRm8UFsdQ4gL00Q@mail.gmail.com>
	<CAGxFJbS+CK79AyrWtr6L8iU9-8Vub-Z1Fm+MC9WOdiPW04LZOQ@mail.gmail.com>
	<CAGxFJbT1Ob3TsPWR=1by14h4f0tFjQvV9_UnFpKYdE8Tu1GJiA@mail.gmail.com>
	<CAGxFJbTZ-Z65nb-fKe-KRsc_sYGReSneifXWT=AORx0J4VL8Uw@mail.gmail.com>
	<CAGxFJbS6_AnN9Aype-yWCREHPw287siMjwe3jVN0cXe1Vh_RPA@mail.gmail.com>
	<CAGxFJbQD-Q=R1ikADh+eiRP8=5yTzdSasdS5sMEAOTYJP9Ah7Q@mail.gmail.com>
	<CAGxFJbQg8=9Zau3jEhn1SyOTuhfSjKf5hnwTeQ3nyR+VgnMDVg@mail.gmail.com>
	<CAGxFJbQS9Wq5iW-3k7fe5btO3cCg4DzgGVZmZBqqSjzfQT-Mtw@mail.gmail.com>
	<CAGxFJbQcSimmdOmKvckGU7O=4Xi1sWxP38MFLdg-RTu3ZMUwXA@mail.gmail.com>
	<CAGxFJbRRqAftjDprpxe4bG8C8QZK794FwDTNadB47fP1SLrxnQ@mail.gmail.com>
	<9B73F3F5-7604-466C-A809-FD69B6BB5658@dcn.davis.ca.us>
	<CAGxFJbSm20dOPNokW-0ac-KZxz9KLkTTXv4v4Xr5zXiyGJsKSA@mail.gmail.com>
Message-ID: <9f4eade0-f168-e3bc-916f-167ec20b7c98@gmail.com>

On 23/10/2016 3:43 PM, Bert Gunter wrote:
> Yes, variables in the formula should be handled by nse with the data
> argument. Got it -- thanks. But still ... can with() be used to handle
> those and/or any other variables in foo that appear as arguments. I see no
> problems in doing so, but ... ?

One possible problem:

Formulas aren't just the bits you can see, they have environments 
attached.  The NSE part of evaluating them makes sure that the 
environment contains the variables in the data argument early in the chain.

This means that your function can pass the evaluated formula to another 
function, and it will carry the appropriate data with it.

If you evaluate a formula within with(), things will get complicated. 
The environment attached to the formula in

with(foo, f( y ~ x1 + x2 + x3 + ... , data = foo,  ...))

will likely contain two different copies of the variables in foo.  The 
first will be the usual one described above.  But since formulas can 
refer to things in the environment that called f(), it is added to the 
chain of environments that are the parent of the first one.

Environments are reference objects, so f() could decide to modify some 
of the variables.  It would likely get very confused if there were two 
copies of them, one in one environment, one in another.

So I'd advise to use one form or the other, i.e. don't use with(), or if 
you do, don't use data=.

Duncan Murdoch

>
> Bert
>
> (But see inline below)
>
> On Oct 23, 2016 7:24 PM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> No. And I don't know why you are conflating the treatment of variables in
> the formula with treatment of variables passed as other arguments. It is
> sort of like thinking the x symbols in foo$x[ x < 0 ] refer to the same
> data.
>
> In my query they explicitly do, though. Nevertheless your response was
> apropos.
>
>>
>> foo$y ~ foo$x1 + foo$x2 + foo$x3 is not preferable, and given the
> availability of a data argument such redundancy is unnecessary. NSE is
> already in use for the formula. It is not (necessarily) in use for the
> other arguments, so you just have to learn which arguments are being
> handled with NSE by any particular function and which are not... good docs
> would be the preferred avenue but recognizing the error message that arises
> when you fail to specify foo$ for the non-formula arguments gets me by if
> the docs are unclear.
>>
>> However, it is dangerous to apply NSE tricks recursively, so piling
> "with" on top of the existing formula eval-with-data is only likely to
> confuse the evaluation context even more.
>
> This is what I'm not sure of. Can you give an example of when such
> confusion would occur?
>
>
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On October 23, 2016 9:18:17 AM PDT, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>>> As has been noted oftimes on this list
>>> f( y ~ x1 + x2 + x3 + ... , data = foo,  ...)
>>>
>>> is much preferable to
>>> f( foo$y ~ foo$x1 + foo$x2 + foo$x3 + ...,  ...)
>>>
>>> (with no data argument), using nse = non-standard evaluation to set the
>>> environment for formula evaluation. However, as queries here recently
>>> demonstrate,  the formula variables (y, x1, x2, x3, ...) or other
>>> variables
>>> in foo are also sometimes needed as further arguments of f,  and these
>>> have
>>> to be explicitly and tediously given as foo$whatever or equivalent
>>> indexing.
>>>
>>> So my question is, can/should with() be used instead in the form
>>> with(foo, f( y ~ x1 + x2 + x3 + ... , data = foo,  ...))  with no
>>> explicit
>>> $ or indexing in ... variables?
>>>
>>> or even
>>> with(foo, f( y ~ x1 + x2 + x3 + ... ,  ...))
>>>
>>> with no data argument for nse or indexing, though this seems to me
>>> questionable in that it may affect the formula's  environment
>>> differently.(??)
>>>
>>> Please correct any misstatements of fact in the above as well as
>>> clarifying
>>> anything else I seem confused about.
>>>
>>> Many thanks.
>>>
>>> Bert
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Mon Oct 24 00:50:18 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 23 Oct 2016 15:50:18 -0700
Subject: [R] Using with() to avoid $ ?
In-Reply-To: <CAGxFJbRRqAftjDprpxe4bG8C8QZK794FwDTNadB47fP1SLrxnQ@mail.gmail.com>
References: <CAGxFJbSQEN98S5uu9Z4Gpd2ywi=CaaRN=wneyFT3oc0q2XJ+YQ@mail.gmail.com>
	<CAGxFJbRd=3d8asajk+dm4YGfigpd63cLbAUiG4e2zcSCYfN-zw@mail.gmail.com>
	<CAGxFJbRaiAhub8jDsGkGgS5WRhLdeLVZoAVZXRH2csL1k1bQqQ@mail.gmail.com>
	<CAGxFJbRQ75UVtFQGZucdAS=w1=G3ufn-sd4nLS0ASm6Tmg8tmQ@mail.gmail.com>
	<CAGxFJbQVCy_uNu3D5Aqsx7fAYTR-mO+KhVsGQNGDMFnqAGB34Q@mail.gmail.com>
	<CAGxFJbS1GaMinQW2fiDGy=4YwD1ZqjODOivC_2+AGfFXGTZi5w@mail.gmail.com>
	<CAGxFJbRK1Gy1q-1q0ggmCKO+N-t_VW6EX4htLh6C_+uHR08C_A@mail.gmail.com>
	<CAGxFJbRUwcZ26Wm_pebfH8wrEA6g2a1M7oibWP2enwH1S+km1g@mail.gmail.com>
	<CAGxFJbSNARhTjYQH01=FKCNLBpn4UiRZasky=_P5j=hmnOP7cg@mail.gmail.com>
	<CAGxFJbQ83tuAjFLrrwV-xLYP2Ev0SjSS=gJzTShULNOdB15NVA@mail.gmail.com>
	<CAGxFJbRhEX1=2EwezHgd8ssngTt=d47v8zZZr2hdiOeaLseZvA@mail.gmail.com>
	<CAGxFJbS9usiDSCacNATo6GOmowLbdrwP2QOCuA1BjDzDzU2DWg@mail.gmail.com>
	<CAGxFJbRxN1fgD4hTM1mF8BDqemPAJ5mu+oCw0Rq7tXwBwS_6WQ@mail.gmail.com>
	<CAGxFJbTR4RXKcitfvWpinqqS6B9gZF8KpfNKYE8x7rvm8hOxgw@mail.gmail.com>
	<CAGxFJbTScSie7WRd41-0wQXn7PkeDbBsJTmmgTVOvZ+=5k6OWw@mail.gmail.com>
	<CAGxFJbRfCAq60WeJ9gSkUf-govXCu7_ucAKxO-85jRAOdZ7Vrg@mail.gmail.com>
	<CAGxFJbRd=qdfnvdAv5hhDjAkqQLXPKWykSeMRm8UFsdQ4gL00Q@mail.gmail.com>
	<CAGxFJbS+CK79AyrWtr6L8iU9-8Vub-Z1Fm+MC9WOdiPW04LZOQ@mail.gmail.com>
	<CAGxFJbT1Ob3TsPWR=1by14h4f0tFjQvV9_UnFpKYdE8Tu1GJiA@mail.gmail.com>
	<CAGxFJbTZ-Z65nb-fKe-KRsc_sYGReSneifXWT=AORx0J4VL8Uw@mail.gmail.com>
	<CAGxFJbS6_AnN9Aype-yWCREHPw287siMjwe3jVN0cXe1Vh_RPA@mail.gmail.com>
	<CAGxFJbQD-Q=R1ikADh+eiRP8=5yTzdSasdS5sMEAOTYJP9Ah7Q@mail.gmail.com>
	<CAGxFJbQg8=9Zau3jEhn1SyOTuhfSjKf5hnwTeQ3nyR+VgnMDVg@mail.gmail.com>
	<CAGxFJbQS9Wq5iW-3k7fe5btO3cCg4DzgGVZmZBqqSjzfQT-Mtw@mail.gmail.com>
	<CAGxFJbQcSimmdOmKvckGU7O=4Xi1sWxP38MFLdg-RTu3ZMUwXA@mail.gmail.com>
	<CAGxFJbRRqAftjDprpxe4bG8C8QZK794FwDTNadB47fP1SLrxnQ@mail.gmail.com>
Message-ID: <CAF8bMcYwdL2=U-R9X_OpQg99JtmUmRdcTqP7dHu+O2EbvGnRPw@mail.gmail.com>

Here is a concrete example where with(data, fit(formula)) differs from
fit(formula, data):

> z1 <- function(myFormula, myData) lm(myFormula, data=myData)
> z2 <- function(myFormula, myData) with(myData, lm(myFormula))
> coef(z1(hp ~ wt, datasets::mtcars))
(Intercept)          wt
  -1.820922   46.160050
> coef(z2(hp ~ wt, datasets::mtcars))
Error in eval(expr, envir, enclos) : object 'hp' not found

You could fix this up by adding data=environment() to z2's call to lm,
but I suspect there are lots of other functions for which this would fail
to work correctly.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Oct 23, 2016 at 9:18 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> As has been noted oftimes on this list
> f( y ~ x1 + x2 + x3 + ... , data = foo,  ...)
>
> is much preferable to
> f( foo$y ~ foo$x1 + foo$x2 + foo$x3 + ...,  ...)
>
> (with no data argument), using nse = non-standard evaluation to set the
> environment for formula evaluation. However, as queries here recently
> demonstrate,  the formula variables (y, x1, x2, x3, ...) or other variables
> in foo are also sometimes needed as further arguments of f,  and these have
> to be explicitly and tediously given as foo$whatever or equivalent
> indexing.
>
> So my question is, can/should with() be used instead in the form
> with(foo, f( y ~ x1 + x2 + x3 + ... , data = foo,  ...))  with no explicit
> $ or indexing in ... variables?
>
> or even
> with(foo, f( y ~ x1 + x2 + x3 + ... ,  ...))
>
> with no data argument for nse or indexing, though this seems to me
> questionable in that it may affect the formula's  environment
> differently.(??)
>
> Please correct any misstatements of fact in the above as well as clarifying
> anything else I seem confused about.
>
> Many thanks.
>
> Bert
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nabiyogesh at gmail.com  Mon Oct 24 04:13:08 2016
From: nabiyogesh at gmail.com (Yogesh Gupta)
Date: Mon, 24 Oct 2016 11:13:08 +0900
Subject: [R] Error In DESeq installation
Message-ID: <CAJE2if3mmvXk9SSZ+3XL0PEi7QQJ6PDRzMPQOaAZiOOFc=RgbA@mail.gmail.com>

Dear All,

I am getting error in DESeq installation in R.

package ?DESeq? is not available (for R version 3.3.1)
> source("http://www.Bioconductor.org/biocLite.R")
Bioconductor version 3.4 (BiocInstaller 1.24.0), ?biocLite for help
> biocLite("BiocUpgrade")
Error: Bioconductor version 3.4 cannot be upgraded with R version 3.3.1

Can you suggest me I How I can resolve it.

Thanks
Yogesh


*Yogesh Gupta*
*Postdoctoral Researcher*
*Department of Biological Science*
*Seoul National University*
*Seoul, South Korea*
web) http://biosci.snu.ac.kr/jiyounglee
*Cell No. +82-10-6453-0716*

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Oct 24 08:22:31 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 23 Oct 2016 23:22:31 -0700
Subject: [R] Using with() to avoid $ ?
In-Reply-To: <CAF8bMcYwdL2=U-R9X_OpQg99JtmUmRdcTqP7dHu+O2EbvGnRPw@mail.gmail.com>
References: <CAGxFJbSQEN98S5uu9Z4Gpd2ywi=CaaRN=wneyFT3oc0q2XJ+YQ@mail.gmail.com>
	<CAGxFJbRd=3d8asajk+dm4YGfigpd63cLbAUiG4e2zcSCYfN-zw@mail.gmail.com>
	<CAGxFJbRaiAhub8jDsGkGgS5WRhLdeLVZoAVZXRH2csL1k1bQqQ@mail.gmail.com>
	<CAGxFJbRQ75UVtFQGZucdAS=w1=G3ufn-sd4nLS0ASm6Tmg8tmQ@mail.gmail.com>
	<CAGxFJbQVCy_uNu3D5Aqsx7fAYTR-mO+KhVsGQNGDMFnqAGB34Q@mail.gmail.com>
	<CAGxFJbS1GaMinQW2fiDGy=4YwD1ZqjODOivC_2+AGfFXGTZi5w@mail.gmail.com>
	<CAGxFJbRK1Gy1q-1q0ggmCKO+N-t_VW6EX4htLh6C_+uHR08C_A@mail.gmail.com>
	<CAGxFJbRUwcZ26Wm_pebfH8wrEA6g2a1M7oibWP2enwH1S+km1g@mail.gmail.com>
	<CAGxFJbSNARhTjYQH01=FKCNLBpn4UiRZasky=_P5j=hmnOP7cg@mail.gmail.com>
	<CAGxFJbQ83tuAjFLrrwV-xLYP2Ev0SjSS=gJzTShULNOdB15NVA@mail.gmail.com>
	<CAGxFJbRhEX1=2EwezHgd8ssngTt=d47v8zZZr2hdiOeaLseZvA@mail.gmail.com>
	<CAGxFJbS9usiDSCacNATo6GOmowLbdrwP2QOCuA1BjDzDzU2DWg@mail.gmail.com>
	<CAGxFJbRxN1fgD4hTM1mF8BDqemPAJ5mu+oCw0Rq7tXwBwS_6WQ@mail.gmail.com>
	<CAGxFJbTR4RXKcitfvWpinqqS6B9gZF8KpfNKYE8x7rvm8hOxgw@mail.gmail.com>
	<CAGxFJbTScSie7WRd41-0wQXn7PkeDbBsJTmmgTVOvZ+=5k6OWw@mail.gmail.com>
	<CAGxFJbRfCAq60WeJ9gSkUf-govXCu7_ucAKxO-85jRAOdZ7Vrg@mail.gmail.com>
	<CAGxFJbRd=qdfnvdAv5hhDjAkqQLXPKWykSeMRm8UFsdQ4gL00Q@mail.gmail.com>
	<CAGxFJbS+CK79AyrWtr6L8iU9-8Vub-Z1Fm+MC9WOdiPW04LZOQ@mail.gmail.com>
	<CAGxFJbT1Ob3TsPWR=1by14h4f0tFjQvV9_UnFpKYdE8Tu1GJiA@mail.gmail.com>
	<CAGxFJbTZ-Z65nb-fKe-KRsc_sYGReSneifXWT=AORx0J4VL8Uw@mail.gmail.com>
	<CAGxFJbS6_AnN9Aype-yWCREHPw287siMjwe3jVN0cXe1Vh_RPA@mail.gmail.com>
	<CAGxFJbQD-Q=R1ikADh+eiRP8=5yTzdSasdS5sMEAOTYJP9Ah7Q@mail.gmail.com>
	<CAGxFJbQg8=9Zau3jEhn1SyOTuhfSjKf5hnwTeQ3nyR+VgnMDVg@mail.gmail.com>
	<CAGxFJbQS9Wq5iW-3k7fe5btO3cCg4DzgGVZmZBqqSjzfQT-Mtw@mail.gmail.com>
	<CAGxFJbQcSimmdOmKvckGU7O=4Xi1sWxP38MFLdg-RTu3ZMUwXA@mail.gmail.com>
	<CAGxFJbRRqAftjDprpxe4bG8C8QZK794FwDTNadB47fP1SLrxnQ@mail.gmail.com>
	<CAF8bMcYwdL2=U-R9X_OpQg99JtmUmRdcTqP7dHu+O2EbvGnRPw@mail.gmail.com>
Message-ID: <CAGxFJbSHvscCqQmy9DRiAaw8=dVww2UThV0EjwKwYQPaNK_E2g@mail.gmail.com>

Bill et. al.

If I understand correctly, your example does not answer my query. I have
already acknowledged that the data argument is required for nse formula
evaluation. The question is: can with() also be used to evaluate other
arguments, some of which also might be in the formula's environment?. Both
Duncan and Jeff say this is asking for trouble. My query is: give me an
example of such trouble.

Bert

On Oct 24, 2016 12:50 AM, "William Dunlap" <wdunlap at tibco.com> wrote:

> Here is a concrete example where with(data, fit(formula)) differs from
> fit(formula, data):
>
> > z1 <- function(myFormula, myData) lm(myFormula, data=myData)
> > z2 <- function(myFormula, myData) with(myData, lm(myFormula))
> > coef(z1(hp ~ wt, datasets::mtcars))
> (Intercept)          wt
>   -1.820922   46.160050
> > coef(z2(hp ~ wt, datasets::mtcars))
> Error in eval(expr, envir, enclos) : object 'hp' not found
>
> You could fix this up by adding data=environment() to z2's call to lm,
> but I suspect there are lots of other functions for which this would fail
> to work correctly.
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Sun, Oct 23, 2016 at 9:18 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> As has been noted oftimes on this list
>> f( y ~ x1 + x2 + x3 + ... , data = foo,  ...)
>>
>> is much preferable to
>> f( foo$y ~ foo$x1 + foo$x2 + foo$x3 + ...,  ...)
>>
>> (with no data argument), using nse = non-standard evaluation to set the
>> environment for formula evaluation. However, as queries here recently
>> demonstrate,  the formula variables (y, x1, x2, x3, ...) or other
>> variables
>> in foo are also sometimes needed as further arguments of f,  and these
>> have
>> to be explicitly and tediously given as foo$whatever or equivalent
>> indexing.
>>
>> So my question is, can/should with() be used instead in the form
>> with(foo, f( y ~ x1 + x2 + x3 + ... , data = foo,  ...))  with no explicit
>> $ or indexing in ... variables?
>>
>> or even
>> with(foo, f( y ~ x1 + x2 + x3 + ... ,  ...))
>>
>> with no data argument for nse or indexing, though this seems to me
>> questionable in that it may affect the formula's  environment
>> differently.(??)
>>
>> Please correct any misstatements of fact in the above as well as
>> clarifying
>> anything else I seem confused about.
>>
>> Many thanks.
>>
>> Bert
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From martin.morgan at roswellpark.org  Mon Oct 24 12:21:48 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Mon, 24 Oct 2016 06:21:48 -0400
Subject: [R] Error In DESeq installation
In-Reply-To: <CAJE2if3mmvXk9SSZ+3XL0PEi7QQJ6PDRzMPQOaAZiOOFc=RgbA@mail.gmail.com>
References: <CAJE2if3mmvXk9SSZ+3XL0PEi7QQJ6PDRzMPQOaAZiOOFc=RgbA@mail.gmail.com>
Message-ID: <931b6e09-5e1d-cbfb-7f16-a7d591667c72@roswellpark.org>

On 10/23/2016 10:13 PM, Yogesh Gupta wrote:
> Dear All,
>
> I am getting error in DESeq installation in R.
>
> package ?DESeq? is not available (for R version 3.3.1)
>> source("http://www.Bioconductor.org/biocLite.R")
> Bioconductor version 3.4 (BiocInstaller 1.24.0), ?biocLite for help
>> biocLite("BiocUpgrade")
> Error: Bioconductor version 3.4 cannot be upgraded with R version 3.3.1
>
> Can you suggest me I How I can resolve it.

Ask questions about Bioconductor packages on the Bioconductor support forum

  https://support.bioconductor.org

DESeq was replaced by DESeq2, but is still available; provide (on the 
Bioconductor support site) the complete output of the installation 
attempt and sessionInfo().

'BiocUpgrade' is to update to a more recent version of Bioconductor. 
There is a 'devel' version that is m ore recent that 3.4, but it 
requires R-devel.

Martin

>
> Thanks
> Yogesh
>
>
> *Yogesh Gupta*
> *Postdoctoral Researcher*
> *Department of Biological Science*
> *Seoul National University*
> *Seoul, South Korea*
> web) http://biosci.snu.ac.kr/jiyounglee
> *Cell No. +82-10-6453-0716*
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or...{{dropped:2}}


From marc_grt at yahoo.fr  Mon Oct 24 13:08:32 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Mon, 24 Oct 2016 13:08:32 +0200
Subject: [R] Limit the y-axis line with ggplot2 (not the axis itself,
 but the line used at the left of the graph)
Message-ID: <e0cf9616-722d-c3f6-87d4-75c9edee3283@yahoo.fr>

Hello everybody,

Using ggplot2 package, is there a way to force to stop the y-axis line 
at a specified point ? (not using ylim because I want that some text 
written using annotate() at the top of the graph is still shown).

Bellow is a simple example to show what I would like do:

Thanks a lot

Marc





library("ggplot2")

g <- ggplot()+
   geom_point(aes(x=c(20, 29, 32), y=c(0, 0.4, 1)))+
   scale_y_continuous(breaks=c(0, 0.25, 0.5, 0.75, 1))+
   labs(x="Label for x axis")+
   labs(y="Label for y axis") +
   annotate("text", x = 25 , y=1.2, label="Text 1")+
   annotate("text", x = 22 , y=1.0, label="How to stop the y-axis line 
here !")+
   geom_segment(aes(x=25, xend=25, y=0, yend=1.1), linetype=2)+
   # This part is just to make it more nice
   theme(panel.background = element_rect(fill = 'white'),
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         plot.margin = unit(c(0.5, 1, 0.5, 0.5), "cm"),
         axis.text.x=element_text(size=14),
         axis.text.y=element_text(size=14),
         axis.title.x=element_text(size=18),
         axis.title.y=element_text(size=18),
         axis.ticks.length=unit(0.3,"cm"),
         panel.border = element_blank(),
         axis.line.x = element_line(),
         axis.line.y = element_line())
g


From pomchip at free.fr  Mon Oct 24 15:13:40 2016
From: pomchip at free.fr (=?UTF-8?Q?S=C3=A9bastien_Bihorel?=)
Date: Mon, 24 Oct 2016 09:13:40 -0400
Subject: [R] Lattice equivalent to ggplot function
Message-ID: <CABR8Zvr21rYuTa+3E1dpoBD-6EUZ96yUPObDmqpGvp76ExZ6LA@mail.gmail.com>

Hi,

The ggplot2 includes the very convenient stat_summary function to summarize
y variable data and plot this summary statistic in a y vs x graph. I need
to implement similar functionality in a lattice-based framework.
Googling this topic using keywords like lattice, equivalent, stat_summary,
did not provide anything helpful. So, before starting coding something
myself, I thought I would reach out to the R help list and ask if anybody
would be aware of a contributed package that would include a equivalent
function of set of functions to stat_summary.

Thank you in advance for you help

Sebastien

	[[alternative HTML version deleted]]


From cof at qualityexcellence.es  Mon Oct 24 15:45:48 2016
From: cof at qualityexcellence.es (Carlos Ortega)
Date: Mon, 24 Oct 2016 15:45:48 +0200
Subject: [R] Lattice equivalent to ggplot function
In-Reply-To: <CABR8Zvr21rYuTa+3E1dpoBD-6EUZ96yUPObDmqpGvp76ExZ6LA@mail.gmail.com>
References: <CABR8Zvr21rYuTa+3E1dpoBD-6EUZ96yUPObDmqpGvp76ExZ6LA@mail.gmail.com>
Message-ID: <CAOKbq8jxig3dqMVO+kQPNr46UUMpmM2__n8EtLvoSgcOP3LrFg@mail.gmail.com>

Hi,

Yes, it is available in "latticeExtra" package in function
"panel.smoother()".

Thanks,
Carlos Ortega
www.qualityexcellence.es

2016-10-24 15:13 GMT+02:00 S?bastien Bihorel <pomchip at free.fr>:

> Hi,
>
> The ggplot2 includes the very convenient stat_summary function to summarize
> y variable data and plot this summary statistic in a y vs x graph. I need
> to implement similar functionality in a lattice-based framework.
> Googling this topic using keywords like lattice, equivalent, stat_summary,
> did not provide anything helpful. So, before starting coding something
> myself, I thought I would reach out to the R help list and ask if anybody
> would be aware of a contributed package that would include a equivalent
> function of set of functions to stat_summary.
>
> Thank you in advance for you help
>
> Sebastien
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Saludos,
Carlos Ortega
www.qualityexcellence.es

	[[alternative HTML version deleted]]


From etienne.borocco at dauphine.fr  Mon Oct 24 15:49:09 2016
From: etienne.borocco at dauphine.fr (Etienne Borocco)
Date: Mon, 24 Oct 2016 15:49:09 +0200
Subject: [R] rsync: failed to connect to cran.r-project.org
 (137.208.57.37): No route to host (113)
In-Reply-To: <167ae4a6-65ac-7008-3865-c14a0f91a19d@gmail.com>
References: <6723df1a-1e10-90c3-2f9b-8ad9d60c7890@dauphine.fr>
	<167ae4a6-65ac-7008-3865-c14a0f91a19d@gmail.com>
Message-ID: <132b2027-fda8-b900-ce69-71068fac8137@dauphine.fr>

I still have the same problem today. Has the issue been fixed in Vienna?


Le 19/10/2016 ? 22:46, Duncan Murdoch a ?crit :
> On 19/10/2016 11:36 AM, Etienne Borocco wrote:
>> Hello,
>>
>> I folowed this tutorial here:
>> http://singmann.org/installing-r-devel-on-linux/
>>
>> I tried to install r-dev to compile gstoos that I can't manage to
>> compile now on my ubuntu 16.04 distribution.
>>
>> I get an error with rsync:
>>
>>  1. bash ./tools/rsync-recommended
>>
>> There is the output of the shell:
>>
>> rsync: failed to connect to cran.r-project.org (137.208.57.37): No route
>> to host (113)
>> rsync error: error in socket IO (code 10) at clientserver.c(128)
>> [Receiver=3.1.1]
>> *** rsync failed to update Recommended files ***
>>
>> I saw this old post from 2008 but it does not seem to adress my issue:
>> https://stat.ethz.ch/pipermail/r-devel/2008-October/050973.html
>
> Other people have been having trouble today getting through to some of
> the Vienna machines.  I've got no idea if it's a problem in Vienna or
> somewhere else, but it will probably be fixed pretty quickly. 
> However, it's now after office hours, so if the problem is actually in
> Vienna, it might not be fixed until tomorrow.
>
> Duncan Murdoch
>

-- 
Etienne Borocco
PhD Student in Economics - Paris Dauphine University


From Anusha.Indhira at controlsdata.com  Mon Oct 24 13:56:25 2016
From: Anusha.Indhira at controlsdata.com (Indhira, Anusha)
Date: Mon, 24 Oct 2016 11:56:25 +0000
Subject: [R] using nested ifelse when i want to process values from more
 than 3 columns of data frame
Message-ID: <CE1899A9C6A8D64099DFB344ECF0F754899D@DERCORCEXH02.ds-s.com>


Hi,

I would like to process each row of data frame having 8 columns of which I am interested in 4 columns for my analysis.I tried using apply function but I get syntax error,although I checked for missing syntaxes ,couldn't figure out the mistake.Can you also suggest me more efficient way to perform same action.

# creating target column from result
kdata$target <- apply(kdata,1,ifelse((kdata$H1 & kdata$H2 & kdata$H3 &
                                                         kdata$H8) == 1,"all-true",(ifelse(kdata$H1== 0 &
                                                                                                            kdata$H2 == 0 &
                                                                                                            kdata$H3 == 0 &
                                                                                                            kdata$H8 == 0) ,
                                                                                                   "all-false","other")))
Thanks.
Alily
This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.

	[[alternative HTML version deleted]]


From Anusha.Indhira at controlsdata.com  Mon Oct 24 14:06:23 2016
From: Anusha.Indhira at controlsdata.com (Indhira, Anusha)
Date: Mon, 24 Oct 2016 12:06:23 +0000
Subject: [R] using nested ifelse when i want to process values from more
 than 3 columns of data frame
Message-ID: <CE1899A9C6A8D64099DFB344ECF0F75489B5@DERCORCEXH02.ds-s.com>

Got past the syntax error,now I got  new error below

Error in match.fun(FUN) : c("'ifelse((kmeans.data$HBV51OpenDmd & kmeans.data$HBV52OpenDmd & ' is not a function, character or symbol", "' kmeans.data$HBV53OpenDmd & kmeans.data$HBV8OpenDmd) == 1, ' is not a function, character or symbol", "' \"all-true\", (ifelse((kmeans.data$HBV51OpenDmd == 0 & kmeans.data$HBV52OpenDmd == ' is not a function, character or symbol", "' 0 & kmeans.data$HBV53OpenDmd == 0 & kmeans.data$HBV8OpenDmd == ' is not a function, character or symbol", "' 0), \"all-false\", \"other\")))' is not a function, character or symbol" )


From: Indhira, Anusha
Sent: 24 October 2016 12:56
To: 'r-help at r-project.org'
Subject: using nested ifelse when i want to process values from more than 3 columns of data frame


Hi,

I would like to process each row of data frame having 8 columns of which I am interested in 4 columns for my analysis.I tried using apply function but I get syntax error,although I checked for missing syntaxes ,couldn't figure out the mistake.Can you also suggest me more efficient way to perform same action.

# creating target column from result
kdata$target <- apply(kdata,1,ifelse((kdata$H1 & kdata$H2 & kdata$H3 &
                                                         kdata$H8) == 1,"all-true",(ifelse(kdata$H1== 0 &
                                                                                                            kdata$H2 == 0 &
                                                                                                            kdata$H3 == 0 &
                                                                                                            kdata$H8 == 0) ,
                                                                                                   "all-false","other")))
Thanks.
Alily
This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.

	[[alternative HTML version deleted]]


From nabiyogesh at gmail.com  Mon Oct 24 09:05:30 2016
From: nabiyogesh at gmail.com (Yogesh Gupta)
Date: Mon, 24 Oct 2016 16:05:30 +0900
Subject: [R] Error in DESeq Installation
Message-ID: <CAJE2if1xqNb1anR+RgDqV4vNDFu09ePYzDVr3r41Frw_qCkrfw@mail.gmail.com>

Dear all


when I run this cammand to install DESeq it show somw error:

## try http:// if https:// URLs are not supported
source("https://bioconductor.org/biocLite.R")
biocLite("DESeq")


it shows this error:

> source("https://bioconductor.org/biocLite.R")
Bioconductor version 3.4 (BiocInstaller 1.24.0), ?biocLite for help
> biocLite("DESeq")
BioC_mirror: https://bioconductor.org
Using Bioconductor 3.4 (BiocInstaller 1.24.0), R 3.3.1 (2016-06-21).
Installing package(s) ?DESeq?
also installing the dependencies ?XML?, ?RCurl?, ?annotate?, ?genefilter?,
?geneplotter?

trying URL 'https://cran.rstudio.com/src/contrib/XML_3.98-1.4.tar.gz'
Content type 'unknown' length 1599214 bytes (1.5 MB)
==================================================
downloaded 1.5 MB

trying URL 'https://cran.rstudio.com/src/contrib/RCurl_1.95-4.8.tar.gz'
Content type 'unknown' length 916934 bytes (895 KB)
==================================================
downloaded 895 KB

trying URL 'https://bioconductor.org/packages/3.4/bioc/src/contrib/anno
tate_1.52.0.tar.gz'
Content type 'unknown' length 1861023 bytes (1.8 MB)
==================================================
downloaded 1.8 MB

trying URL 'https://bioconductor.org/packages/3.4/bioc/src/contrib/gene
filter_1.56.0.tar.gz'
Content type 'unknown' length 1407436 bytes (1.3 MB)
==================================================
downloaded 1.3 MB

trying URL 'https://bioconductor.org/packages/3.4/bioc/src/contrib/gene
plotter_1.52.0.tar.gz'
Content type 'unknown' length 1426298 bytes (1.4 MB)
==================================================
downloaded 1.4 MB

trying URL 'https://bioconductor.org/packages/3.4/bioc/src/contrib/DESe
q_1.26.0.tar.gz'
Content type 'unknown' length 1698987 bytes (1.6 MB)
==================================================
downloaded 1.6 MB

* installing *source* package ?XML? ...
** package ?XML? successfully unpacked and MD5 sums checked
checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking how to run the C preprocessor... gcc -E
checking for sed... /usr/bin/sed
checking for pkg-config... /usr/bin/pkg-config
checking for xml2-config... no
Cannot find xml2-config
ERROR: configuration failed for package ?XML?
* removing ?/usr/lib64/R/library/XML?
* installing *source* package ?RCurl? ...
** package ?RCurl? successfully unpacked and MD5 sums checked
checking for curl-config... no
Cannot find curl-config
ERROR: configuration failed for package ?RCurl?
* removing ?/usr/lib64/R/library/RCurl?
ERROR: dependencies ?XML?, ?RCurl? are not available for package ?annotate?
* removing ?/usr/lib64/R/library/annotate?
ERROR: dependency ?annotate? is not available for package ?genefilter?
* removing ?/usr/lib64/R/library/genefilter?
ERROR: dependency ?annotate? is not available for package ?geneplotter?
* removing ?/usr/lib64/R/library/geneplotter?
ERROR: dependencies ?genefilter?, ?geneplotter? are not available for
package ?DESeq?
* removing ?/usr/lib64/R/library/DESeq?

The downloaded source packages are in
        ?/tmp/RtmpsMJs05/downloaded_packages?
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
Warning messages:
1: In install.packages(pkgs = doing, lib = lib, ...) :
  installation of package ?XML? had non-zero exit status
2: In install.packages(pkgs = doing, lib = lib, ...) :
  installation of package ?RCurl? had non-zero exit status
3: In install.packages(pkgs = doing, lib = lib, ...) :
  installation of package ?annotate? had non-zero exit status
4: In install.packages(pkgs = doing, lib = lib, ...) :
  installation of package ?genefilter? had non-zero exit status
5: In install.packages(pkgs = doing, lib = lib, ...) :
  installation of package ?geneplotter? had non-zero exit status
6: In install.packages(pkgs = doing, lib = lib, ...) :
  installation of package ?DESeq? had non-zero exit status

Thanks
*Yogesh Gupta*
*Postdoctoral Researcher*
*Department of Biological Science*
*Seoul National University*
*Seoul, South Korea*
web) http://biosci.snu.ac.kr/jiyounglee
*Cell No. +82-10-6453-0716*

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Oct 24 17:23:52 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 24 Oct 2016 15:23:52 +0000
Subject: [R] using nested ifelse when i want to process values from more
 than 3 columns of data frame
In-Reply-To: <CE1899A9C6A8D64099DFB344ECF0F75489B5@DERCORCEXH02.ds-s.com>
References: <CE1899A9C6A8D64099DFB344ECF0F75489B5@DERCORCEXH02.ds-s.com>
Message-ID: <49995690ccf14cc194353212aa607891@exch-2p-mbx-w2.ads.tamu.edu>

You really need to provide more information. The error message without the command that generated it and the structure of the data sets you are using is a bare minimum. A reproducible example is often necessary to debug code such as this.

You can simplify your code substantially with something like this

> cols <- c("H1", "H2", "H3", "H8")
> RS <- rowSums(kdata[, cols])
> kdata$target <- ifelse(RS == length(cols), "all-true",
+       ifelse(RS == 0, "all-false", "other"))

David L. Carlson
Department of Anthropology
Texas A&M University


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Indhira, Anusha
Sent: Monday, October 24, 2016 7:06 AM
To: r-help at r-project.org
Subject: Re: [R] using nested ifelse when i want to process values from more than 3 columns of data frame

Got past the syntax error,now I got  new error below

Error in match.fun(FUN) : c("'ifelse((kmeans.data$HBV51OpenDmd & kmeans.data$HBV52OpenDmd & ' is not a function, character or symbol", "' kmeans.data$HBV53OpenDmd & kmeans.data$HBV8OpenDmd) == 1, ' is not a function, character or symbol", "' \"all-true\", (ifelse((kmeans.data$HBV51OpenDmd == 0 & kmeans.data$HBV52OpenDmd == ' is not a function, character or symbol", "' 0 & kmeans.data$HBV53OpenDmd == 0 & kmeans.data$HBV8OpenDmd == ' is not a function, character or symbol", "' 0), \"all-false\", \"other\")))' is not a function, character or symbol" )


From: Indhira, Anusha
Sent: 24 October 2016 12:56
To: 'r-help at r-project.org'
Subject: using nested ifelse when i want to process values from more than 3 columns of data frame


Hi,

I would like to process each row of data frame having 8 columns of which I am interested in 4 columns for my analysis.I tried using apply function but I get syntax error,although I checked for missing syntaxes ,couldn't figure out the mistake.Can you also suggest me more efficient way to perform same action.

# creating target column from result
kdata$target <- apply(kdata,1,ifelse((kdata$H1 & kdata$H2 & kdata$H3 &
                                                         kdata$H8) == 1,"all-true",(ifelse(kdata$H1== 0 &
                                                                                                            kdata$H2 == 0 &
                                                                                                            kdata$H3 == 0 &
                                                                                                            kdata$H8 == 0) ,
                                                                                                   "all-false","other")))
Thanks.
Alily
This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From msharp at txbiomed.org  Mon Oct 24 17:29:33 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Mon, 24 Oct 2016 15:29:33 +0000
Subject: [R] using nested ifelse when i want to process values from more
 than 3 columns of data frame
In-Reply-To: <CE1899A9C6A8D64099DFB344ECF0F75489B5@DERCORCEXH02.ds-s.com>
References: <CE1899A9C6A8D64099DFB344ECF0F75489B5@DERCORCEXH02.ds-s.com>
Message-ID: <DECDAC11-3B28-4E69-81B6-82A3D15CBA48@TxBiomed.org>

Indira,

I think you are wanting to define a new column (target) with "all_true", "all_false", or "other" based on columns H1, H2, H3, and H8 all being equal to 1, all being equal to 0, and other wise respectively. If so, then you do not need apply() or ifelse().

I believe this does what you were trying to do. I am not persuaded you are doing what you need to do.

kdata$target <- rep("other", nrow(kdata))
kdata$target[kdata$H1 == 0 &
             kdata$H2 == 0 &
             kdata$H3 == 0 &
             kdata$H8 == 0] <- "all_false"
kdata$target[kdata$H1 == 1 &
             kdata$H2 == 1 &
             kdata$H3 == 1 &
             kdata$H8 == 1] <- "all_true"

Mark

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org








> On Oct 24, 2016, at 7:06 AM, Indhira, Anusha <Anusha.Indhira at controlsdata.com> wrote:
>
> Got past the syntax error,now I got  new error below
>
> Error in match.fun(FUN) : c("'ifelse((kmeans.data$HBV51OpenDmd & kmeans.data$HBV52OpenDmd & ' is not a function, character or symbol", "' kmeans.data$HBV53OpenDmd & kmeans.data$HBV8OpenDmd) == 1, ' is not a function, character or symbol", "' \"all-true\", (ifelse((kmeans.data$HBV51OpenDmd == 0 & kmeans.data$HBV52OpenDmd == ' is not a function, character or symbol", "' 0 & kmeans.data$HBV53OpenDmd == 0 & kmeans.data$HBV8OpenDmd == ' is not a function, character or symbol", "' 0), \"all-false\", \"other\")))' is not a function, character or symbol" )
>
>
> From: Indhira, Anusha
> Sent: 24 October 2016 12:56
> To: 'r-help at r-project.org'
> Subject: using nested ifelse when i want to process values from more than 3 columns of data frame
>
>
> Hi,
>
> I would like to process each row of data frame having 8 columns of which I am interested in 4 columns for my analysis.I tried using apply function but I get syntax error,although I checked for missing syntaxes ,couldn't figure out the mistake.Can you also suggest me more efficient way to perform same action.
>
> # creating target column from result
> kdata$target <- apply(kdata,1,ifelse((kdata$H1 & kdata$H2 & kdata$H3 &
>                                                         kdata$H8) == 1,"all-true",(ifelse(kdata$H1== 0 &
>                                                                                                            kdata$H2 == 0 &
>                                                                                                            kdata$H3 == 0 &
>                                                                                                            kdata$H8 == 0) ,
>                                                                                                   "all-false","other")))
> Thanks.
> Alily
> This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From anmhuerfanoba at unal.edu.co  Mon Oct 24 17:54:00 2016
From: anmhuerfanoba at unal.edu.co (Andrea Marcela Huerfano Barbosa)
Date: Mon, 24 Oct 2016 10:54:00 -0500
Subject: [R] Error in a regression
Message-ID: <CAGTB1-y7LF=zybywHE-TnWjMf2rh1LvXAZL=jeq0PFhFHRvoNw@mail.gmail.com>

Hi guys,
When I try to do a linear regression into the console appears this warning
message:

>* attempting model selection on an essentially perfect fit is nonsense*

Some one could tell me what does it mean and maybe a way to solve it.

Thanks in advance,

Andrea Marcela

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Oct 24 18:49:49 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 24 Oct 2016 09:49:49 -0700
Subject: [R] Error in a regression
In-Reply-To: <CAGTB1-y7LF=zybywHE-TnWjMf2rh1LvXAZL=jeq0PFhFHRvoNw@mail.gmail.com>
References: <CAGTB1-y7LF=zybywHE-TnWjMf2rh1LvXAZL=jeq0PFhFHRvoNw@mail.gmail.com>
Message-ID: <CAGxFJbTpxMNKVkE+rhMc7Y+i7TDLKS2F_zFD3mCv6UpmmV+00g@mail.gmail.com>

Probably not. This is a statistics issue, not an R issue. But you need to
show us your code to make sure it's not a syntax error.  Assuming it's not,
you'll need to consult a local statistical expert for help.

Bert

	[[alternative HTML version deleted]]


From swbueno at gmail.com  Mon Oct 24 18:03:24 2016
From: swbueno at gmail.com (Santiago Bueno)
Date: Mon, 24 Oct 2016 12:03:24 -0400
Subject: [R] nlme
Message-ID: <CAGfmZu4Rrh-tOspOa5H1Nx=7Q8Zvk_JwogYx20XK8tENBKXBag@mail.gmail.com>

Dear people:


I am getting the following error when trying to run the piece of code
below. Any insights??



Error in nlme.formula(Btronc ~ a + b * dbh^2 * haut, data = cbind(dat,  :

  object 'a' not found



library(nlme)

start <- coef(lm(Btronc~I(dbh**2*haut),data=dat))

names(start) <- c("a","b")

summary(nlme(Btronc~a+b*dbh**2*haut, data=cbind(dat,g="a"), fixed=a+b_1,
start=start,

groups=~g, weights=varPower(form=~dbh)))


Best,


Santiago

	[[alternative HTML version deleted]]


From kkpdff at gmail.com  Mon Oct 24 20:05:31 2016
From: kkpdff at gmail.com (Klaus Krippendorff)
Date: Mon, 24 Oct 2016 14:05:31 -0400
Subject: [R]  Krippendorff's alpha bootstrapping implementation
Message-ID: <BC684B61-96E7-4FB9-BCB3-4E21F8A10213@gmail.com>

I noticed the 2014 discussion of bootstrapping Krippendorff's alpha referring to Andrew Hayes website. 
Whoever is interested in this algorithm:
One of Andrew Hayes' student discovered an oddity in the distribution obtained by this algorithm when data are very sparse. This has been corrected by a new 2016.10.10 version of the bootstrapping algorithm that avoids this oddity and is faster as well. You can find it by googling: boot.c-alpha. pdf. This algorithm is now implemented in Hayes' KALPHA. 
Should anyone have questions: klaus.krippendorff at asc.upenn.edu

Sent from my iPhone

From davef at otter-rsch.com  Mon Oct 24 19:49:30 2016
From: davef at otter-rsch.com (dave fournier)
Date: Mon, 24 Oct 2016 10:49:30 -0700
Subject: [R] Finding starting values for the parameters using nls() or
 nls2()
In-Reply-To: <013a01d2221f$40b46360$c21d2a20$@163.com>
References: <013a01d2221f$40b46360$c21d2a20$@163.com>
Message-ID: <08a8d1de-5e5d-a51e-c96d-9b5ce288d22e@otter-rsch.com>

I've spent quite a bit of time trying to convince people on various 
lists that the solution to these kinds of
problems lies in the stable parameterization of the model.  I write the 
solutions in AD Model Builder because it
is easy.  But R people are generally stuck in R (or mired) so the 
message somehow always gets lost.

  I thought I would bite the bullet and figure out how to do this in R. 
It turns out that one can fit this model
  with only 6 function evaluations using nls2.   I apologize in advance 
for my execrable R code. But it does do
the job.

The data were fit using 3 calls to nls2. For the first call only the 
parameter th was estimated. This converged
in 4 function evaluations. For the second call all three of the 
parameters were estimated
(but the other 2 parameters are different from b0, b1) .This converged 
to the solution in four function evaluations.

The final call to nls2 uses the converged values to calculate b0,b1 and 
theta and starts from there.
As you can see the model is already converged. This final call to nls2 
is used to get the standard error
estimates for the parameters.

 >  nls.m1
Nonlinear regression model
   model: Retention ~ expFct1(Area, y1, yn, th)
    data: structure(list(Area = c(521.5, 689.78, 1284.71, 2018.8, 
2560.46, 524.91, 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 
1432.5, 2144.74, 2629.2), Retention = c(95.3, 87.18, 44.94, 26.36, 
18.12, 84.68, 37.24, 33.04, 23.46, 9.72, 97.92, 71.44, 44.52, 24.44, 
15.26)), .Names = c("Area", "Retention"), row.names = c(NA, -15L), class 
= "data.frame")
     th
0.9862
  residual sum-of-squares: 730

Number of iterations to convergence: 2
Achieved convergence tolerance: 1.616e-06

 >  nls.m2
Nonlinear regression model
   model: Retention ~ expFct2(Area, y1, yn, c, d, th)
    data: structure(list(Area = c(521.5, 689.78, 1284.71, 2018.8, 
2560.46, 524.91, 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 
1432.5, 2144.74, 2629.2), Retention = c(95.3, 87.18, 44.94, 26.36, 
18.12, 84.68, 37.24, 33.04, 23.46, 9.72, 97.92, 71.44, 44.52, 24.44, 
15.26)), .Names = c("Area", "Retention"), row.names = c(NA, -15L), class 
= "data.frame")
      c      d     th
0.9716 1.1010 0.9118
  residual sum-of-squares: 686.8

Number of iterations to convergence: 4
Achieved convergence tolerance: 2.398e-06

 >  nls.m
Nonlinear regression model
   model: Retention ~ expFct(Area, b0, b1, th)
    data: structure(list(Area = c(521.5, 689.78, 1284.71, 2018.8, 
2560.46, 524.91, 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 
1432.5, 2144.74, 2629.2), Retention = c(95.3, 87.18, 44.94, 26.36, 
18.12, 84.68, 37.24, 33.04, 23.46, 9.72, 97.92, 71.44, 44.52, 24.44, 
15.26)), .Names = c("Area", "Retention"), row.names = c(NA, -15L), class 
= "data.frame")
         b0         b1         th
  5.2104452 -0.0004672  0.9118040
  residual sum-of-squares: 686.8

Number of iterations to convergence: 0
Achieved convergence tolerance: 1.384e-06

Parameters:
      Estimate Std. Error t value Pr(>|t|)
b0  5.2104452  0.4999594  10.422 2.29e-07 ***
b1 -0.0004672  0.0013527  -0.345   0.7358
th  0.9118040  0.3583575   2.544   0.0257 *

So what is the stable parameterization for this model.  To simplify let 
x be the independent variable and y be the
  dependent variable and write t instead of th  So the model is

             y = exp(b0*exp(b1*x^t) (1)

Now it would be nice to reorder the x's so that they are monotone 
increasing or decreasing, but in this case the
first x is almost the largest and the last x is almost the smallest 
(slight reach) so they will do. Call them x1 and xn.
The new parameters of the model are the predicted y's for x1 and xn.  
Call them y1 and yn.  Note that y1 and yn
are parameters, not observations.


The data were fit using 3 calls to nls2. For the first call only the 
parameter th was estimated. this converged
in 4 function evaluestions. for the second call all three of the 
parameters were estimated
(but the other 2 parameters are different from b0, b1) .This converged 
to the solution in four function evaluations.

The final call to nls2 uses the converged values to calculate b0,b1 and 
theta and starts from there.
as you can see the model is already converged. this final call to nls2 
is used to get the standard error
estimates for the parameters.

 >  nls.m1
Nonlinear regression model
   model: Retention ~ expFct1(Area, y1, yn, th)
    data: structure(list(Area = c(521.5, 689.78, 1284.71, 2018.8, 
2560.46, 524.91, 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 
1432.5, 2144.74, 2629.2), Retention = c(95.3, 87.18, 44.94, 26.36, 
18.12, 84.68, 37.24, 33.04, 23.46, 9.72, 97.92, 71.44, 44.52, 24.44, 
15.26)), .Names = c("Area", "Retention"), row.names = c(NA, -15L), class 
= "data.frame")
     th
0.9862
  residual sum-of-squares: 730

Number of iterations to convergence: 2
Achieved convergence tolerance: 1.616e-06

 >  nls.m2
Nonlinear regression model
   model: Retention ~ expFct2(Area, y1, yn, c, d, th)
    data: structure(list(Area = c(521.5, 689.78, 1284.71, 2018.8, 
2560.46, 524.91, 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 
1432.5, 2144.74, 2629.2), Retention = c(95.3, 87.18, 44.94, 26.36, 
18.12, 84.68, 37.24, 33.04, 23.46, 9.72, 97.92, 71.44, 44.52, 24.44, 
15.26)), .Names = c("Area", "Retention"), row.names = c(NA, -15L), class 
= "data.frame")
      c      d     th
0.9716 1.1010 0.9118
  residual sum-of-squares: 686.8

Number of iterations to convergence: 4
Achieved convergence tolerance: 2.398e-06

 >  nls.m
Nonlinear regression model
   model: Retention ~ expFct(Area, b0, b1, th)
    data: structure(list(Area = c(521.5, 689.78, 1284.71, 2018.8, 
2560.46, 524.91, 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 
1432.5, 2144.74, 2629.2), Retention = c(95.3, 87.18, 44.94, 26.36, 
18.12, 84.68, 37.24, 33.04, 23.46, 9.72, 97.92, 71.44, 44.52, 24.44, 
15.26)), .Names = c("Area", "Retention"), row.names = c(NA, -15L), class 
= "data.frame")
         b0         b1         th
  5.2104452 -0.0004672  0.9118040
  residual sum-of-squares: 686.8

Number of iterations to convergence: 0
Achieved convergence tolerance: 1.384e-06

Parameters:
      Estimate Std. Error t value Pr(>|t|)
b0  5.2104452  0.4999594  10.422 2.29e-07 ***
b1 -0.0004672  0.0013527  -0.345   0.7358
th  0.9118040  0.3583575   2.544   0.0257 *

So what is the stable parameterization for this model.  To simplify letx 
be the independent variable and y be the
  dependent variable and write t insted of th  So the model is

             y = exp(b0*exp(b1*x^t) (1)

Now it would be nice to reorder the x's so that they are monotone 
increasing or decreasing, but in this case the
first x is almost the largest and the last x is almost the smallest 
(slight reach) so they will do. Call them x1 and xn.
The new parameters of the model are the predicted y's for x1 and xn.  
Call them y1 and yn.  Note that y1 and yn
are parameters, not observations.

              y1 = exp(b0*exp(b1*x1^t)
(2)
              yn = exp(b0*exp(b1*xn^t)

One can solve for b1 and b0 in terms of y1 and yn.

             b1=log(log(y1)/log(yn))/(x1^t-xn^t);
(3)
             b0=log(y1)*exp(-b1*x1^t);


To use this  we do the fitting of the model in two stages. In the first 
stage we use the obvious
  estimates of y[1] for y1 and y[n] for yn and fix these values and 
estimate t using the obvious
starting value of 1 for t.

In the second stage we set

                y1=c*y[1]

                yn=d*y[n]

and estimate   c, d, and t using the obvious starting values of 1 for c 
and d.
That's it. this converges as stated in 6 function evaluations.  This 
technique works for
may curves such as 3,4,5 parameter logistic double exponential 
vonBertalanffy
(where Schnute and I first discovered it in the early 1980's before 
anyone was born).

One caveat  is that usually not all values of y1 and yn are 
permissible.  For example in this case if b>0
then y1 and yn are both >1. To make this routine bulletproof one needs 
to impose these kinds of
constraints.  But this was not needed here.

Here is my  R code for this model.

library("nls2")
cl=data.frame(Area=c(521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91, 
989.05,
1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 2629.2), 
Retention=c (95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 23.46,
9.72, 97.92, 71.44, 44.52, 24.44, 15.26) )

  y1 <<- cl$Retention[1];
  yn <<- cl$Retention[length(cl$Retention)]

  expFct1 <- function(x, y1, yn,th)
  {
   x1=x[1]
   xn=x[length(x)]
   b1=log(log(y1)/log(yn))/(x1^th-xn^th)
   b0=log(y1)*exp(-b1*x1^th)
   exp(b0*exp(b1*x^th));
  }

  expFct2 <- function(x, y_1,y_n,c,d,th)
  {
   x1=x[1]
   xn=x[length(x)]
   y1=c*y_1
   yn=d*y_n
   b1=log(log(y1)/log(yn))/(x1^th-xn^th)
   b0=log(y1)*exp(-b1*x1^th)
   exp(b0*exp(b1*x^th));
  }

  expFct <- function(x, b0, b1,th)
  {
    exp(b0*exp(b1*x^th))
  }


  nls.m1<- nls2(Retention ~ expFct1(Area, y1, yn, th), data = cl,
     start = list(th = 1))

  th_start=coef(nls.m1)


  nls.m2<- nls2(Retention ~ expFct2(Area, y1, yn, c, d,  th), data = cl,
     start = list(c=1, d=1, th = th_start))

  x=cl$Area
  x1=x[1]
  xn=x[length(x)]
  th_start=coef(nls.m2)[3]
  cy1=coef(nls.m2)[1]*y1

dyn=coef(nls.m2)[2]*yn
  b1_start=log(log(cy1)/log(dyn))/(x1^th_start-xn^th_start)
  b0_start=log(cy1)*exp(-b1_start*x1^th_start)

  th_start
  b1_start
  b0_start
  nls.m<- nls2(Retention ~ expFct(Area, b0, b1, th), data = cl,
     start = list(b0 = b0_start, b1 = b1_start, th = th_start))

  nls.m1
  nls.m2
  nls.m


From A.Robinson at ms.unimelb.edu.au  Mon Oct 24 21:50:15 2016
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 25 Oct 2016 06:50:15 +1100
Subject: [R] nlme
In-Reply-To: <CAGfmZu4Rrh-tOspOa5H1Nx=7Q8Zvk_JwogYx20XK8tENBKXBag@mail.gmail.com>
References: <CAGfmZu4Rrh-tOspOa5H1Nx=7Q8Zvk_JwogYx20XK8tENBKXBag@mail.gmail.com>
Message-ID: <CAHyGmd7VaTBYGy3CQj=yUYGso8LnLoFg2uCNyR-9Mr-z0EfixQ@mail.gmail.com>

Without access to the data, or commented, minimal, self-contained,
reproducible code, it's pretty hard to speculate.  I suggest that you
reframe your question so that we can see what you can see.

Andrew

On 25 October 2016 at 03:03, Santiago Bueno <swbueno at gmail.com> wrote:
> Dear people:
>
>
> I am getting the following error when trying to run the piece of code
> below. Any insights??
>
>
>
> Error in nlme.formula(Btronc ~ a + b * dbh^2 * haut, data = cbind(dat,  :
>
>   object 'a' not found
>
>
>
> library(nlme)
>
> start <- coef(lm(Btronc~I(dbh**2*haut),data=dat))
>
> names(start) <- c("a","b")
>
> summary(nlme(Btronc~a+b*dbh**2*haut, data=cbind(dat,g="a"), fixed=a+b_1,
> start=start,
>
> groups=~g, weights=varPower(form=~dbh)))
>
>
> Best,
>
>
> Santiago
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Andrew Robinson
Deputy Director, CEBRA, School of Biosciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au
Website: http://www.ms.unimelb.edu.au/~andrewpr

MSME: http://www.crcpress.com/product/isbn/9781439858028
FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
SPuR: http://www.ms.unimelb.edu.au/spuRs/


From wdunlap at tibco.com  Mon Oct 24 21:58:42 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 24 Oct 2016 12:58:42 -0700
Subject: [R] nlme
In-Reply-To: <CAGfmZu4Rrh-tOspOa5H1Nx=7Q8Zvk_JwogYx20XK8tENBKXBag@mail.gmail.com>
References: <CAGfmZu4Rrh-tOspOa5H1Nx=7Q8Zvk_JwogYx20XK8tENBKXBag@mail.gmail.com>
Message-ID: <CAF8bMcaZf6CprFj0k4SWqjRrgAGrzDhk4wi0X5kx9SJkEfBxrA@mail.gmail.com>

> summary(nlme(Btronc~a+b*dbh**2*haut, data=cbind(dat,g="a"), fixed=a+b_1,
> start=start,
>
> groups=~g, weights=varPower(form=~dbh)))

Shouldn't 'fixed' be a formula?  Perhaps a+b~1?


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Oct 24, 2016 at 9:03 AM, Santiago Bueno <swbueno at gmail.com> wrote:

> Dear people:
>
>
> I am getting the following error when trying to run the piece of code
> below. Any insights??
>
>
>
> Error in nlme.formula(Btronc ~ a + b * dbh^2 * haut, data = cbind(dat,  :
>
>   object 'a' not found
>
>
>
> library(nlme)
>
> start <- coef(lm(Btronc~I(dbh**2*haut),data=dat))
>
> names(start) <- c("a","b")
>
> summary(nlme(Btronc~a+b*dbh**2*haut, data=cbind(dat,g="a"), fixed=a+b_1,
> start=start,
>
> groups=~g, weights=varPower(form=~dbh)))
>
>
> Best,
>
>
> Santiago
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jan.kacaba at gmail.com  Mon Oct 24 22:14:53 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Mon, 24 Oct 2016 22:14:53 +0200
Subject: [R] function which returns number of occurrences of a pattern
	in string
In-Reply-To: <CAA-FpKUowYCRpEU+paqbU=95bdc06VABADt_Peaboatq9Ov_3Q@mail.gmail.com>
References: <CAHby=D02jVZX_b3YR0+eXFvLanQo2evr0z+RAeT-1BbgJSPSFw@mail.gmail.com>
	<CAA-FpKUowYCRpEU+paqbU=95bdc06VABADt_Peaboatq9Ov_3Q@mail.gmail.com>
Message-ID: <CAHby=D2=fp1F7sSik16ipQMe1L88A4D2AOavgTF_-uZp_-0aAg@mail.gmail.com>

Bob and Max, I thank you. It helped me much.

2016-10-21 3:47 GMT+02:00 Bob Rudis <bob at rud.is>:

> `stringi::stri_count()`
>
> I know that the `stringr` pkg saves some typing (it wraps the
> `stringi` pkg), but you should really just use the `stringi` package.
> It has many more very useful functions with not too much more typing.
>
> On Thu, Oct 20, 2016 at 5:47 PM, Jan Kacaba <jan.kacaba at gmail.com> wrote:
> > Hello dear R-help
> >
> > I tried to find function which returns number of occurrences of a pattern
> > in string. The closest match I've found is str_locate_all in stringr
> > package. I can use str_locate_all but write my function but I don't want
> > reinvent wheel.
> >
> > JK
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Oct 24 22:23:14 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 24 Oct 2016 15:23:14 -0500
Subject: [R] nlme
In-Reply-To: <CAF8bMcaZf6CprFj0k4SWqjRrgAGrzDhk4wi0X5kx9SJkEfBxrA@mail.gmail.com>
References: <CAGfmZu4Rrh-tOspOa5H1Nx=7Q8Zvk_JwogYx20XK8tENBKXBag@mail.gmail.com>
	<CAF8bMcaZf6CprFj0k4SWqjRrgAGrzDhk4wi0X5kx9SJkEfBxrA@mail.gmail.com>
Message-ID: <883DD081-FD87-4E1F-B578-6C21FA929852@dcn.davis.ca.us>

Wild guess: Santiago is putting a and b in his formula when they are the coefficients he wants to extract? 

If Mr S wants better answers he needs to read about reproducibility and avoid HTML format email. 
-- 
Sent from my phone. Please excuse my brevity.

On October 24, 2016 2:58:42 PM CDT, William Dunlap via R-help <r-help at r-project.org> wrote:
>> summary(nlme(Btronc~a+b*dbh**2*haut, data=cbind(dat,g="a"),
>fixed=a+b_1,
>> start=start,
>>
>> groups=~g, weights=varPower(form=~dbh)))
>
>Shouldn't 'fixed' be a formula?  Perhaps a+b~1?
>
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>On Mon, Oct 24, 2016 at 9:03 AM, Santiago Bueno <swbueno at gmail.com>
>wrote:
>
>> Dear people:
>>
>>
>> I am getting the following error when trying to run the piece of code
>> below. Any insights??
>>
>>
>>
>> Error in nlme.formula(Btronc ~ a + b * dbh^2 * haut, data =
>cbind(dat,  :
>>
>>   object 'a' not found
>>
>>
>>
>> library(nlme)
>>
>> start <- coef(lm(Btronc~I(dbh**2*haut),data=dat))
>>
>> names(start) <- c("a","b")
>>
>> summary(nlme(Btronc~a+b*dbh**2*haut, data=cbind(dat,g="a"),
>fixed=a+b_1,
>> start=start,
>>
>> groups=~g, weights=varPower(form=~dbh)))
>>
>>
>> Best,
>>
>>
>> Santiago
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From joeceradini at gmail.com  Mon Oct 24 23:33:20 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Mon, 24 Oct 2016 15:33:20 -0600
Subject: [R] Extract word from string based on pattern match
Message-ID: <CAKq2vL4nt5w0AoWs_C9OUsFppz4Jfg5=fOwPNrVfOryVJRNCBA@mail.gmail.com>

R Helpers,

I would like to extract the entire word beginning with "BT" (or "BT-")
and not any thing else in the string. Or, I would like to extract from
BT up until the next space.

test <- data.frame(x = c("abc", "Sample BT-1501-2E stuff", "Bt-1599-3E stuff"))
test

So, from test$x I would like to only extract "BT-1501-2E" and "Bt-1599-3E".

I started with straight grep but of course that is not what I need.
grep("BT", test$x, value = TRUE, ignore.case = TRUE)
"Sample BT-1501-2E stuff" "Bt-2134df stuff"

In a somewhat similar post, the solution involved boundaries or
anchors, but I haven't been able to adapt it to my needs, so I won't
even bother including my boundary attempts :)
http://stackoverflow.com/questions/7227976/using-grep-in-r-to-find-strings-as-whole-words-but-not-strings-as-part-of-words

If possible, it would also be helpful if something was returned, like
NA, for rows without a "BT" match. So, conceptually, test$x would
return:
NA, "BT-1501-2E", "Bt-1599-3E".

Thanks!
Joe


From joeceradini at gmail.com  Tue Oct 25 00:03:42 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Mon, 24 Oct 2016 16:03:42 -0600
Subject: [R] Extract word from string based on pattern match
In-Reply-To: <20161024214256.GV1108@albert.catwhisker.org>
References: <CAKq2vL4nt5w0AoWs_C9OUsFppz4Jfg5=fOwPNrVfOryVJRNCBA@mail.gmail.com>
	<20161024214256.GV1108@albert.catwhisker.org>
Message-ID: <CAKq2vL5-df8f3J41vXCoi1Sr5JaCZmb0xh3xToh+8KOUY5bCnw@mail.gmail.com>

Excellent - thanks David!
Regex syntax never fails to scare the crap out of me :)

David absolutely solved my problem (in record time, no less), so it
can be put to rest. However, if anyone knows how to accomplish the
same thing through non base packages, like stringr or stringi, I'd be
interested in seeing those solutions as well.

Thanks,
Joe


On Mon, Oct 24, 2016 at 3:42 PM, David Wolfskill <david at catwhisker.org> wrote:
>
> On Mon, Oct 24, 2016 at 03:33:20PM -0600, Joe Ceradini wrote:
> > R Helpers,
> >
> > I would like to extract the entire word beginning with "BT" (or "BT-")
> > and not any thing else in the string. Or, I would like to extract from
> > BT up until the next space.
> >
> > test <- data.frame(x = c("abc", "Sample BT-1501-2E stuff", "Bt-1599-3E stuff"))
> > test
> >
> > So, from test$x I would like to only extract "BT-1501-2E" and "Bt-1599-3E".
> >
> > I started with straight grep but of course that is not what I need.
> > grep("BT", test$x, value = TRUE, ignore.case = TRUE)
> > "Sample BT-1501-2E stuff" "Bt-2134df stuff"
> >
> > In a somewhat similar post, the solution involved boundaries or
> > anchors, but I haven't been able to adapt it to my needs, so I won't
> > even bother including my boundary attempts :)
> > http://stackoverflow.com/questions/7227976/using-grep-in-r-to-find-strings-as-whole-words-but-not-strings-as-part-of-words
> >
> > If possible, it would also be helpful if something was returned, like
> > NA, for rows without a "BT" match. So, conceptually, test$x would
> > return:
> > NA, "BT-1501-2E", "Bt-1599-3E".
> >
> > Thanks!
> > Joe
> > ....
>
> This is not exactly what you requested, as it returns the original
> unmodified string when there's no match; I expect you can come up with
> some code to test for that.  It does, however, meet the rest of your
> requirements -- or so I believe:
>
> > test
>                         x
> 1                     abc
> 2 Sample BT-1501-2E stuff
> 3        Bt-1599-3E stuff
> > sub("^.*(BT-?\\w*).*$", "\\1", test$x, ignore.case = TRUE, perl = TRUE)
> [1] "abc"     "BT-1501" "Bt-1599"
> >
>
> Peace,
> david
> --
> David H. Wolfskill                              david at catwhisker.org
> Those who would murder in the name of God or prophet are blasphemous cowards.
>
> See http://www.catwhisker.org/~david/publickey.gpg for my public key.


From istazahn at gmail.com  Tue Oct 25 01:35:05 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 24 Oct 2016 19:35:05 -0400
Subject: [R] Extract word from string based on pattern match
In-Reply-To: <CAKq2vL5-df8f3J41vXCoi1Sr5JaCZmb0xh3xToh+8KOUY5bCnw@mail.gmail.com>
References: <CAKq2vL4nt5w0AoWs_C9OUsFppz4Jfg5=fOwPNrVfOryVJRNCBA@mail.gmail.com>
	<20161024214256.GV1108@albert.catwhisker.org>
	<CAKq2vL5-df8f3J41vXCoi1Sr5JaCZmb0xh3xToh+8KOUY5bCnw@mail.gmail.com>
Message-ID: <CA+vqiLGvB=hXDzPf9X-ZyrrZKU0LOFzgP7UaZ-XcKDhGymU1Pw@mail.gmail.com>

On Oct 24, 2016 6:05 PM, "Joe Ceradini" <joeceradini at gmail.com> wrote:
>
> Excellent - thanks David!
> Regex syntax never fails to scare the crap out of me :)
>
> David absolutely solved my problem (in record time, no less), so it
> can be put to rest. However, if anyone knows how to accomplish the
> same thing through non base packages, like stringr or stringi, I'd be
> interested in seeing those solutions as well.

Try it, its easy. I would be very surprised if you can't figure it out. The
stringr vignette is a good place to start.

Best,
Ista

>
> Thanks,
> Joe
>
>
> On Mon, Oct 24, 2016 at 3:42 PM, David Wolfskill <david at catwhisker.org>
wrote:
> >
> > On Mon, Oct 24, 2016 at 03:33:20PM -0600, Joe Ceradini wrote:
> > > R Helpers,
> > >
> > > I would like to extract the entire word beginning with "BT" (or "BT-")
> > > and not any thing else in the string. Or, I would like to extract from
> > > BT up until the next space.
> > >
> > > test <- data.frame(x = c("abc", "Sample BT-1501-2E stuff",
"Bt-1599-3E stuff"))
> > > test
> > >
> > > So, from test$x I would like to only extract "BT-1501-2E" and
"Bt-1599-3E".
> > >
> > > I started with straight grep but of course that is not what I need.
> > > grep("BT", test$x, value = TRUE, ignore.case = TRUE)
> > > "Sample BT-1501-2E stuff" "Bt-2134df stuff"
> > >
> > > In a somewhat similar post, the solution involved boundaries or
> > > anchors, but I haven't been able to adapt it to my needs, so I won't
> > > even bother including my boundary attempts :)
> > >
http://stackoverflow.com/questions/7227976/using-grep-in-r-to-find-strings-as-whole-words-but-not-strings-as-part-of-words
> > >
> > > If possible, it would also be helpful if something was returned, like
> > > NA, for rows without a "BT" match. So, conceptually, test$x would
> > > return:
> > > NA, "BT-1501-2E", "Bt-1599-3E".
> > >
> > > Thanks!
> > > Joe
> > > ....
> >
> > This is not exactly what you requested, as it returns the original
> > unmodified string when there's no match; I expect you can come up with
> > some code to test for that.  It does, however, meet the rest of your
> > requirements -- or so I believe:
> >
> > > test
> >                         x
> > 1                     abc
> > 2 Sample BT-1501-2E stuff
> > 3        Bt-1599-3E stuff
> > > sub("^.*(BT-?\\w*).*$", "\\1", test$x, ignore.case = TRUE, perl =
TRUE)
> > [1] "abc"     "BT-1501" "Bt-1599"
> > >
> >
> > Peace,
> > david
> > --
> > David H. Wolfskill                              david at catwhisker.org
> > Those who would murder in the name of God or prophet are blasphemous
cowards.
> >
> > See http://www.catwhisker.org/~david/publickey.gpg for my public key.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bob at rud.is  Tue Oct 25 02:31:02 2016
From: bob at rud.is (Bob Rudis)
Date: Mon, 24 Oct 2016 20:31:02 -0400
Subject: [R] rsync: failed to connect to cran.r-project.org
 (137.208.57.37): No route to host (113)
In-Reply-To: <132b2027-fda8-b900-ce69-71068fac8137@dauphine.fr>
References: <6723df1a-1e10-90c3-2f9b-8ad9d60c7890@dauphine.fr>
	<167ae4a6-65ac-7008-3865-c14a0f91a19d@gmail.com>
	<132b2027-fda8-b900-ce69-71068fac8137@dauphine.fr>
Message-ID: <CAA-FpKVEjcCPVoYKGwc67g7LM7+_iLKbWf9KutZ9E_NHfmqq9Q@mail.gmail.com>

I ran traceroutes & BGP traces from Marseille & Paris routers to that
CRAN IPv4 address (it's 10hrs after your mail, tho) and there's no
network errors. You can use any CRAN mirror, though. You aren't
limited to that one.

On Mon, Oct 24, 2016 at 9:49 AM, Etienne Borocco
<etienne.borocco at dauphine.fr> wrote:
> I still have the same problem today. Has the issue been fixed in Vienna?
>
>
> Le 19/10/2016 ? 22:46, Duncan Murdoch a ?crit :
>> On 19/10/2016 11:36 AM, Etienne Borocco wrote:
>>> Hello,
>>>
>>> I folowed this tutorial here:
>>> http://singmann.org/installing-r-devel-on-linux/
>>>
>>> I tried to install r-dev to compile gstoos that I can't manage to
>>> compile now on my ubuntu 16.04 distribution.
>>>
>>> I get an error with rsync:
>>>
>>>  1. bash ./tools/rsync-recommended
>>>
>>> There is the output of the shell:
>>>
>>> rsync: failed to connect to cran.r-project.org (137.208.57.37): No route
>>> to host (113)
>>> rsync error: error in socket IO (code 10) at clientserver.c(128)
>>> [Receiver=3.1.1]
>>> *** rsync failed to update Recommended files ***
>>>
>>> I saw this old post from 2008 but it does not seem to adress my issue:
>>> https://stat.ethz.ch/pipermail/r-devel/2008-October/050973.html
>>
>> Other people have been having trouble today getting through to some of
>> the Vienna machines.  I've got no idea if it's a problem in Vienna or
>> somewhere else, but it will probably be fixed pretty quickly.
>> However, it's now after office hours, so if the problem is actually in
>> Vienna, it might not be fixed until tomorrow.
>>
>> Duncan Murdoch
>>
>
> --
> Etienne Borocco
> PhD Student in Economics - Paris Dauphine University
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Oct 25 04:44:01 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 25 Oct 2016 13:44:01 +1100
Subject: [R] Error in a regression
In-Reply-To: <CAGxFJbTpxMNKVkE+rhMc7Y+i7TDLKS2F_zFD3mCv6UpmmV+00g@mail.gmail.com>
References: <CAGTB1-y7LF=zybywHE-TnWjMf2rh1LvXAZL=jeq0PFhFHRvoNw@mail.gmail.com>
	<CAGxFJbTpxMNKVkE+rhMc7Y+i7TDLKS2F_zFD3mCv6UpmmV+00g@mail.gmail.com>
Message-ID: <CA+8X3fVpZ7=jJwEZdXJ=jsEJsJkWfMo2SdG04y1AWwNXgfALYQ@mail.gmail.com>

Hi Andrea,
Assuming that your model is something like:

lm(y~x,data=mydata)

See what:

cor(mydata$y,mydata$x)

returns. If it is very very close to 1 or -1, there lies your problem.
If one or more of your predictor variables is an almost perfect
predictor of the response, you don't have much room to select
different models.

Jim


From lists at dewey.myzen.co.uk  Tue Oct 25 10:15:34 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 25 Oct 2016 09:15:34 +0100
Subject: [R] Error in a regression
In-Reply-To: <CAGTB1-y7LF=zybywHE-TnWjMf2rh1LvXAZL=jeq0PFhFHRvoNw@mail.gmail.com>
References: <CAGTB1-y7LF=zybywHE-TnWjMf2rh1LvXAZL=jeq0PFhFHRvoNw@mail.gmail.com>
Message-ID: <e1c7af9e-60b4-2956-53c4-18e3a8d32bad@dewey.myzen.co.uk>

Dear Andrea

At a guess you are trying to add variables to your model in some 
automatic way but since your model is already perfect the unnamed 
function you are using is telling you that you gave it an impossible task.

On 24/10/2016 16:54, Andrea Marcela Huerfano Barbosa wrote:
> Hi guys,
> When I try to do a linear regression into the console appears this warning
> message:
>
>> * attempting model selection on an essentially perfect fit is nonsense*
>
> Some one could tell me what does it mean and maybe a way to solve it.
>
> Thanks in advance,
>
> Andrea Marcela
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From btupper at bigelow.org  Tue Oct 25 14:53:13 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 25 Oct 2016 08:53:13 -0400
Subject: [R] lattice: control panel extent on device
Message-ID: <5241D8A5-B794-4C41-9BF1-04BA08B1AB8D@bigelow.org>

Hello,

I am drawing a levelplot and an xyplot on a single device as shown in the runnable example below.  I would like the x axes to align - that is for them to cover the same extent left-to-right on the device. How do I go about doing that?

#######
# START
#######
library(lattice)

d <- dim(volcano)
xy <- data.frame(x = 1:d[1], y = volcano[,30] )

vol_p <- levelplot(volcano)
xy_p <- xyplot(y ~ x, data = xy)

print(vol_p, split = c(1, 2, 1, 2), more = TRUE)
print(xy_p,  split = c(1, 1, 1, 2), more = FALSE)
######
#END
######


Thanks!
Ben


> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.6 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lattice_0.20-33

loaded via a namespace (and not attached):
[1] tools_3.3.1 grid_3.3.1 



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From btupper at bigelow.org  Tue Oct 25 17:30:50 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 25 Oct 2016 11:30:50 -0400
Subject: [R] lattice: control panel extent on device
In-Reply-To: <CAGxFJbR1fd4pVeNkxd7mm5z7QwQmSd+M0QeeMuiz3wP9k0jbrQ@mail.gmail.com>
References: <5241D8A5-B794-4C41-9BF1-04BA08B1AB8D@bigelow.org>
	<CAGxFJbTTE7jshhNEVizVPJD7Nngbs0a26q+CG5AmCf+wX3EoxA@mail.gmail.com>
	<CAGxFJbSs2oRCwd30jnp0ZKaCeFyjK-PvR_1QLoH3NxQPOhNoSw@mail.gmail.com>
	<CAGxFJbR1fd4pVeNkxd7mm5z7QwQmSd+M0QeeMuiz3wP9k0jbrQ@mail.gmail.com>
Message-ID: <E9A9E28D-0264-4013-9CEA-9B4D25D27EAD@bigelow.org>

Thanks, Bert.

I have used latticeExtra for layering graphics.  I'm not sure how I would use it to align graphics rather superimposing them.

I shall look into the the custom panel plot but that is very new territory for me.

Ben

> On Oct 25, 2016, at 9:13 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Write a custom panel function for levelplot() that calls panel.xyplot after panel.levelplot. I believe this can also be done by the +  operator of the latticeExtra package.
> 
> You do *not* want to call xyplot after levelplot, as that completely redraws the plot.
> 
> Cheers,
> Bert
> 
> 
> On Oct 25, 2016 2:55 PM, "Ben Tupper" <btupper at bigelow.org <mailto:btupper at bigelow.org>> wrote:
> Hello,
> 
> I am drawing a levelplot and an xyplot on a single device as shown in the runnable example below.  I would like the x axes to align - that is for them to cover the same extent left-to-right on the device. How do I go about doing that?
> 
> #######
> # START
> #######
> library(lattice)
> 
> d <- dim(volcano)
> xy <- data.frame(x = 1:d[1], y = volcano[,30] )
> 
> vol_p <- levelplot(volcano)
> xy_p <- xyplot(y ~ x, data = xy)
> 
> print(vol_p, split = c(1, 2, 1, 2), more = TRUE)
> print(xy_p,  split = c(1, 1, 1, 2), more = FALSE)
> ######
> #END
> ######
> 
> 
> Thanks!
> Ben
> 
> 
> > sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.11.6 (El Capitan)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] lattice_0.20-33
> 
> loaded via a namespace (and not attached):
> [1] tools_3.3.1 grid_3.3.1
> 
> 
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org <http://www.bigelow.org/>
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org




	[[alternative HTML version deleted]]


From marc.girondot at u-psud.fr  Tue Oct 25 06:33:08 2016
From: marc.girondot at u-psud.fr (Marc Girondot)
Date: Tue, 25 Oct 2016 06:33:08 +0200
Subject: [R] Limit the y-axis line with ggplot2 (not the axis itself,
 but the line used at the left of the graph) [SOLVED]
In-Reply-To: <e0cf9616-722d-c3f6-87d4-75c9edee3283@yahoo.fr>
References: <e0cf9616-722d-c3f6-87d4-75c9edee3283@yahoo.fr>
Message-ID: <e39649ed-c0af-65ef-4c9e-96acebdc040c@u-psud.fr>

After many tries, here is a solution using grob.
I post here in case it could help someone.
Note that this solution is not 100% optimal as it uses a trick (limits = 
c(-0.05, 1.02)) to show fully the points.

Marc

library("ggplot2"); require("gtable"); require("grid")

p <- ggplot()+
   geom_point(aes(x=c(20, 29, 32), y=c(0, 0.4, 1)))+
   scale_y_continuous(breaks=c(0, 0.25, 0.5, 0.75, 1),
                      expand = c(0, 0), limits = c(-0.05, 1.02))+
   xlim(20, 32) +
   labs(x="Label for x axis")+
   labs(y="Label for y axis") +
   geom_segment(aes(x=25, xend=25, y=0, yend=1), linetype=2)+
   # This part is just to make it more nice
   theme(panel.background = element_rect(fill = 'white'),
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         plot.margin = unit(c(0.5, 1, 0.5, 0.5), "cm"),
         axis.text.x=element_text(size=14),
         axis.text.y=element_text(size=14),
         axis.title.x=element_text(size=18),
         axis.title.y=element_text(size=18),
         axis.ticks.length=unit(0.3,"cm"),
         panel.border = element_blank(),
         axis.line.x = element_line(),
         axis.line.y = element_line())


# I prepare the legend to be shown at the top
plegend <- ggplot() +
   geom_blank() +
   geom_segment(aes(x=25, xend=25, y=0, yend=0.4), linetype=2) +
   annotate("text", x = 25 , y=0.5, label="Text 1")+
   scale_y_continuous(expand=c(0,0), limits = c(0,1)) +
   scale_x_continuous(limits = c(20, 32)) +
   theme_minimal() + theme(line=element_blank(),
                           text=element_blank(),
                           panel.background=element_blank())

# extract the panel only
gl <- gtable_filter(ggplotGrob(plegend), "panel")

# And draw both
g <- ggplotGrob(p)
g <- gtable_add_rows(x = g, heights = unit(2, "cm"), pos = 0)
g <- gtable_add_grob(g, gl, t = 2, l=4, b=1, r=4)
grid.newpage()
grid.draw(g)



Le 24/10/2016 ? 13:08, Marc Girondot via R-help a ?crit :
> Hello everybody,
>
> Using ggplot2 package, is there a way to force to stop the y-axis line 
> at a specified point ? (not using ylim because I want that some text 
> written using annotate() at the top of the graph is still shown).
>
> Bellow is a simple example to show what I would like do:
>
> Thanks a lot
>
> Marc
>
>
>
>
>
> library("ggplot2")
>
> g <- ggplot()+
>   geom_point(aes(x=c(20, 29, 32), y=c(0, 0.4, 1)))+
>   scale_y_continuous(breaks=c(0, 0.25, 0.5, 0.75, 1))+
>   labs(x="Label for x axis")+
>   labs(y="Label for y axis") +
>   annotate("text", x = 25 , y=1.2, label="Text 1")+
>   annotate("text", x = 22 , y=1.0, label="How to stop the y-axis line 
> here !")+
>   geom_segment(aes(x=25, xend=25, y=0, yend=1.1), linetype=2)+
>   # This part is just to make it more nice
>   theme(panel.background = element_rect(fill = 'white'),
>         panel.grid.major = element_blank(),
>         panel.grid.minor = element_blank(),
>         plot.margin = unit(c(0.5, 1, 0.5, 0.5), "cm"),
>         axis.text.x=element_text(size=14),
>         axis.text.y=element_text(size=14),
>         axis.title.x=element_text(size=18),
>         axis.title.y=element_text(size=18),
>         axis.ticks.length=unit(0.3,"cm"),
>         panel.border = element_blank(),
>         axis.line.x = element_line(),
>         axis.line.y = element_line())
> g
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
__________________________________________________________
Marc Girondot, Pr

Laboratoire Ecologie, Syst?matique et Evolution
Equipe de Conservation des Populations et des Communaut?s
CNRS, AgroParisTech et Universit? Paris-Sud 11 , UMR 8079
B?timent 362
91405 Orsay Cedex, France

Tel:  33 1 (0)1.69.15.72.30   Fax: 33 1 (0)1.69.15.73.53
e-mail: marc.girondot at u-psud.fr
Web: http://www.ese.u-psud.fr/epc/conservation/Marc.html
Skype: girondot


From gaopinglei at 163.com  Tue Oct 25 17:01:21 2016
From: gaopinglei at 163.com (Pinglei Gao)
Date: Tue, 25 Oct 2016 23:01:21 +0800
Subject: [R] Finding starting values for the parameters using nls() or
	nls2()
Message-ID: <000201d22ed0$a84030a0$f8c091e0$@163.com>

Dear Dave
Thanks for your kindness help. I am sorry, I am on a filed survey these days. I did not check my email for a long time. Please forgive me for the misunderstanding brought to you. Your answer works well for the model: Retention = exp (b0*exp (b1*Area^th)). Could you find the starting values for the another model: Retention = (b0*Area^(th+1))^b with the same data for me. I also asked the same question on R-help list before.

Bests,

PG

-----????-----
???: dave fournier [mailto:davef at otter-rsch.com] 
????: 2016?10?20? 5:47
???: r-help at r-project.org; gaopinglei at 163.com
??: Re: [R] Finding starting values for the parameters using nls() or nls2()

Actually this converges very nicely if you use these starting values that I obtained with AD Model Builder

        th     9.1180e-01
        b0    5.2104e+00
        b1   -4.6725e-04

The R result looks like

nls.m2
Nonlinear regression model
   model: Retention ~ expFct(Area, b0, b1, th)
    data: structure(list(Area = c(521.5, 689.78, 1284.71, 2018.8, 2560.46, 524.91, 989.05, 1646.32, 2239.65, 2972.96, 478.54, 875.52, 1432.5, 2144.74, 2629.2), Retention = c(95.3, 87.18, 44.94, 26.36, 18.12, 84.68, 37.24, 33.04, 23.46, 9.72, 97.92, 71.44, 44.52, 24.44, 15.26)), .Names = c("Area", "Retention"), row.names = c(NA, -15L), class = "data.frame")
         b0         b1         th
  5.2104466 -0.0004672  0.9118029
  residual sum-of-squares: 686.8

Number of iterations to convergence: 1
Achieved convergence tolerance: 1.75e-06


From swbueno at gmail.com  Tue Oct 25 18:22:16 2016
From: swbueno at gmail.com (Santiago Bueno)
Date: Tue, 25 Oct 2016 12:22:16 -0400
Subject: [R] 100 fold cross validation in R
Message-ID: <CAGfmZu5JUzETEGzv2kD1SvBsBCrCojQ_LrGeVyiJ+nZQMCVwwA@mail.gmail.com>

Dear experts,

I have to carry a 100 fold cross-validation of non linear regression
models. Is it possible to find a way to do it in R.

Best regards,

Santiago Bueno

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Oct 25 18:34:19 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 25 Oct 2016 09:34:19 -0700
Subject: [R] 100 fold cross validation in R
In-Reply-To: <CAGfmZu5JUzETEGzv2kD1SvBsBCrCojQ_LrGeVyiJ+nZQMCVwwA@mail.gmail.com>
References: <CAGfmZu5JUzETEGzv2kD1SvBsBCrCojQ_LrGeVyiJ+nZQMCVwwA@mail.gmail.com>
Message-ID: <C59580C3-ECA9-4F95-9D7B-8058A5D9397D@comcast.net>


> On Oct 25, 2016, at 9:22 AM, Santiago Bueno <swbueno at gmail.com> wrote:
> 
> Dear experts,
> 
> I have to carry a 100 fold cross-validation of non linear regression
> models. Is it possible to find a way to do it in R.
> 

Show us your code for a single-fold validation.


> Best regards,
> 
> Santiago Bueno
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From davef at otter-rsch.com  Tue Oct 25 18:29:08 2016
From: davef at otter-rsch.com (dave fournier)
Date: Tue, 25 Oct 2016 09:29:08 -0700
Subject: [R] Finding starting values for the parameters using nls() or
 nls2()
In-Reply-To: <000201d22ed0$a84030a0$f8c091e0$@163.com>
References: <000201d22ed0$a84030a0$f8c091e0$@163.com>
Message-ID: <766701db-1f6b-c440-5753-07631ad37f86@otter-rsch.com>



  Unfortunately this problem does not appear to be well posed.

     Retention = (b0*Area^(th+1))^b

If b0, th, and b are the parameter only the product (th+1)*b is determined.

This comes from noting that powers satisfy



     (a^b)^c  =  a^(b*c)



So your model can be written as



           (b0^b) * Area^((th+1)*b)


From dwinsemius at comcast.net  Tue Oct 25 20:15:10 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 25 Oct 2016 11:15:10 -0700
Subject: [R] Finding starting values for the parameters using nls() or
	nls2()
In-Reply-To: <766701db-1f6b-c440-5753-07631ad37f86@otter-rsch.com>
References: <000201d22ed0$a84030a0$f8c091e0$@163.com>
	<766701db-1f6b-c440-5753-07631ad37f86@otter-rsch.com>
Message-ID: <CF336029-D3BC-44EF-B2C7-55C9B3E38B29@comcast.net>


> On Oct 25, 2016, at 9:29 AM, dave fournier <davef at otter-rsch.com> wrote:
> 
> 
> 
> Unfortunately this problem does not appear to be well posed.
> 
>    Retention = (b0*Area^(th+1))^b
> 
> If b0, th, and b are the parameter only the product (th+1)*b is determined.
> 
> This comes from noting that powers satisfy
> 
> 
> 
>    (a^b)^c  =  a^(b*c)
> 
> 
> 
> So your model can be written as
> 
> 
> 
>          (b0^b) * Area^((th+1)*b)
> 

... which nicely completes the thread since one model had:

th1   =  9.1180e-01
 b01=    5.2104e+00
 b11 =  -4.6725e-04
(th1+1)*b11
[1] -0.0008932885


 b0  = 5.2104466   ;    b1 =   -0.0004672   ;  th =  0.9118029
((th+1)*b1)
[1] -0.0008931943

So both the R's nls2 and AD_MOdel_Builder results yield that same predictions for any given data point at least up to four decimal places.

So perhaps there was some other physical interpretation of those parameters and there exists an underlying theory that would support adding some extra constraints? 

-- 
David Winsemius
Alameda, CA, USA


From paul at stat.auckland.ac.nz  Tue Oct 25 22:58:29 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 26 Oct 2016 09:58:29 +1300
Subject: [R] Limit the y-axis line with ggplot2 (not the axis itself,
 but the line used at the left of the graph) [SOLVED]
In-Reply-To: <e39649ed-c0af-65ef-4c9e-96acebdc040c@u-psud.fr>
References: <e0cf9616-722d-c3f6-87d4-75c9edee3283@yahoo.fr>
	<e39649ed-c0af-65ef-4c9e-96acebdc040c@u-psud.fr>
Message-ID: <f787d85f-ea28-811c-722d-bd930e303ef5@stat.auckland.ac.nz>

Hi

Here are some alternatives that involve messing about with the grobs and 
viewports after the plot has been drawn.  The percentage optimality of 
these solutions is up for debate ...

###############################################################################
# Edit the y-axis line after drawing
library("ggplot2"); library("grid")
g <- ggplot()+
   geom_point(aes(x=c(20, 29, 32), y=c(0, 0.4, 1)))+
   scale_y_continuous(breaks=c(0, 0.25, 0.5, 0.75, 1))+
   labs(x="Label for x axis")+
   labs(y="Label for y axis") +
   annotate("text", x = 25 , y=1.2, label="Text 1")+
   annotate("text", x = 22 , y=1.0, label="How to stop the y-axis line 
here !")+
   geom_segment(aes(x=25, xend=25, y=0, yend=1.1), linetype=2)+
   # This part is just to make it more nice
   theme(panel.background = element_rect(fill = 'white'),
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         plot.margin = unit(c(0.5, 1, 0.5, 0.5), "cm"),
         axis.text.x=element_text(size=14),
         axis.text.y=element_text(size=14),
         axis.title.x=element_text(size=18),
         axis.title.y=element_text(size=18),
         axis.ticks.length=unit(0.3,"cm"),
         panel.border = element_blank(),
         axis.line.x = element_line(),
         axis.line.y = element_line())
g
# Force creation of all grobs
grid.force()
# List all grobs
grid.ls()
# Get y-axis line y-locations
grid.get("axis.line.y..polyline", grep=TRUE)$y
# Edit y-axis line y-locations (trial-and-error to get 0.81)
grid.edit("axis.line.y..polyline", grep=TRUE, y=unit(c(0, 0.81), "npc"))

###############################################################################
# Insert marker to work off and edit the y-axis line after drawing
library("ggplot2"); library("grid")
g <- ggplot()+
   geom_point(aes(x=c(20, 29, 32), y=c(0, 0.4, 1)))+
   scale_y_continuous(breaks=c(0, 0.25, 0.5, 0.75, 1))+
   labs(x="Label for x axis")+
   labs(y="Label for y axis") +
   annotate("text", x = 25 , y=1.2, label="Text 1")+
   annotate("text", x = 22 , y=1.0, label="How to stop the y-axis line 
here !")+
   geom_segment(aes(x=25, xend=25, y=0, yend=1.1), linetype=2)+
   # This part is just to make it more nice
   theme(panel.background = element_rect(fill = 'white'),
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         plot.margin = unit(c(0.5, 1, 0.5, 0.5), "cm"),
         axis.text.x=element_text(size=14),
         axis.text.y=element_text(size=14),
         axis.title.x=element_text(size=18),
         axis.title.y=element_text(size=18),
         axis.ticks.length=unit(0.3,"cm"),
         panel.border = element_blank(),
         axis.line.x = element_line(),
         axis.line.y = element_line()) +
     # marker
     geom_point(aes(x=20, y=1), col="red")
g
# Force creation of all grobs
grid.force()
# List all grobs
grid.ls()
# Navigate to panel viewport
downViewport("panel.6-4-6-4")
# Get marker
marker <- grid.get("geom_point", grep=TRUE, global=TRUE)[[2]]
# Edit y-axis line y-locations (based on marker)
grid.edit("axis.line.y..polyline", grep=TRUE,
           y=convertY(unit(0:1, c("npc", "groby"), list(NULL, marker)), 
"npc"))
# grid.edit("axis.line.y..polyline", grep=TRUE,
#           y=unit(c(0, convertY(grobY(marker, 0), "npc", valueOnly=TRUE)),
#                  "npc"))
# Remove marker
grid.remove(marker$name)

###############################################################################
# Just draw the plot, with margin above, vertical dash line clipped
library("ggplot2"); library("grid")
g <- ggplot()+
   geom_point(aes(x=c(20, 29, 32), y=c(0, 0.4, 1)))+
   scale_y_continuous(breaks=c(0, 0.25, 0.5, 0.75, 1),
                      limits=c(-.05, 1), expand=c(0, 0),
                      oob=function(x, range) x)+
   labs(x="Label for x axis")+
   labs(y="Label for y axis") +
   annotate("text", x = 25 , y=1.2, label="Text 1")+
   annotate("text", x = 22 , y=1.0, label="How to stop the y-axis line 
here !")+
   geom_segment(aes(x=25, xend=25, y=0, yend=1.1), linetype=2)+
   # This part is just to make it more nice
   theme(panel.background = element_rect(fill = 'white'),
         panel.grid.major = element_blank(),
         panel.grid.minor = element_blank(),
         plot.margin = unit(c(3, 1, 0.5, 0.5), "cm"),
         axis.text.x=element_text(size=14),
         axis.text.y=element_text(size=14),
         axis.title.x=element_text(size=18),
         axis.title.y=element_text(size=18),
         axis.ticks.length=unit(0.3,"cm"),
         panel.border = element_blank(),
         axis.line.x = element_line(),
         axis.line.y = element_line())
g
# Force creation of all grobs
grid.force()
# List all grobs
grid.ls()
# Navigate to panel viewport
downViewport("panel.6-4-6-4")
# Get the line segment and label
seg <- grid.get("segments", grep=TRUE)
lab <- grid.get("text", grep=TRUE)
# Push new viewport with clipping off
pushViewport(viewport(clip="off"))
# Draw line segment and text
grid.draw(seg)
grid.draw(lab)
# Clean up
upViewport()

Paul

On 25/10/16 17:33, Marc Girondot wrote:
> After many tries, here is a solution using grob.
> I post here in case it could help someone.
> Note that this solution is not 100% optimal as it uses a trick (limits =
> c(-0.05, 1.02)) to show fully the points.
>
> Marc
>
> library("ggplot2"); require("gtable"); require("grid")
>
> p <- ggplot()+
>   geom_point(aes(x=c(20, 29, 32), y=c(0, 0.4, 1)))+
>   scale_y_continuous(breaks=c(0, 0.25, 0.5, 0.75, 1),
>                      expand = c(0, 0), limits = c(-0.05, 1.02))+
>   xlim(20, 32) +
>   labs(x="Label for x axis")+
>   labs(y="Label for y axis") +
>   geom_segment(aes(x=25, xend=25, y=0, yend=1), linetype=2)+
>   # This part is just to make it more nice
>   theme(panel.background = element_rect(fill = 'white'),
>         panel.grid.major = element_blank(),
>         panel.grid.minor = element_blank(),
>         plot.margin = unit(c(0.5, 1, 0.5, 0.5), "cm"),
>         axis.text.x=element_text(size=14),
>         axis.text.y=element_text(size=14),
>         axis.title.x=element_text(size=18),
>         axis.title.y=element_text(size=18),
>         axis.ticks.length=unit(0.3,"cm"),
>         panel.border = element_blank(),
>         axis.line.x = element_line(),
>         axis.line.y = element_line())
>
>
> # I prepare the legend to be shown at the top
> plegend <- ggplot() +
>   geom_blank() +
>   geom_segment(aes(x=25, xend=25, y=0, yend=0.4), linetype=2) +
>   annotate("text", x = 25 , y=0.5, label="Text 1")+
>   scale_y_continuous(expand=c(0,0), limits = c(0,1)) +
>   scale_x_continuous(limits = c(20, 32)) +
>   theme_minimal() + theme(line=element_blank(),
>                           text=element_blank(),
>                           panel.background=element_blank())
>
> # extract the panel only
> gl <- gtable_filter(ggplotGrob(plegend), "panel")
>
> # And draw both
> g <- ggplotGrob(p)
> g <- gtable_add_rows(x = g, heights = unit(2, "cm"), pos = 0)
> g <- gtable_add_grob(g, gl, t = 2, l=4, b=1, r=4)
> grid.newpage()
> grid.draw(g)
>
>
>
> Le 24/10/2016 ? 13:08, Marc Girondot via R-help a ?crit :
>> Hello everybody,
>>
>> Using ggplot2 package, is there a way to force to stop the y-axis line
>> at a specified point ? (not using ylim because I want that some text
>> written using annotate() at the top of the graph is still shown).
>>
>> Bellow is a simple example to show what I would like do:
>>
>> Thanks a lot
>>
>> Marc
>>
>>
>>
>>
>>
>> library("ggplot2")
>>
>> g <- ggplot()+
>>   geom_point(aes(x=c(20, 29, 32), y=c(0, 0.4, 1)))+
>>   scale_y_continuous(breaks=c(0, 0.25, 0.5, 0.75, 1))+
>>   labs(x="Label for x axis")+
>>   labs(y="Label for y axis") +
>>   annotate("text", x = 25 , y=1.2, label="Text 1")+
>>   annotate("text", x = 22 , y=1.0, label="How to stop the y-axis line
>> here !")+
>>   geom_segment(aes(x=25, xend=25, y=0, yend=1.1), linetype=2)+
>>   # This part is just to make it more nice
>>   theme(panel.background = element_rect(fill = 'white'),
>>         panel.grid.major = element_blank(),
>>         panel.grid.minor = element_blank(),
>>         plot.margin = unit(c(0.5, 1, 0.5, 0.5), "cm"),
>>         axis.text.x=element_text(size=14),
>>         axis.text.y=element_text(size=14),
>>         axis.title.x=element_text(size=18),
>>         axis.title.y=element_text(size=18),
>>         axis.ticks.length=unit(0.3,"cm"),
>>         panel.border = element_blank(),
>>         axis.line.x = element_line(),
>>         axis.line.y = element_line())
>> g
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From paul at stat.auckland.ac.nz  Tue Oct 25 23:14:16 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 26 Oct 2016 10:14:16 +1300
Subject: [R] [FORGED] Re:  lattice: control panel extent on device
In-Reply-To: <E9A9E28D-0264-4013-9CEA-9B4D25D27EAD@bigelow.org>
References: <5241D8A5-B794-4C41-9BF1-04BA08B1AB8D@bigelow.org>
	<CAGxFJbTTE7jshhNEVizVPJD7Nngbs0a26q+CG5AmCf+wX3EoxA@mail.gmail.com>
	<CAGxFJbSs2oRCwd30jnp0ZKaCeFyjK-PvR_1QLoH3NxQPOhNoSw@mail.gmail.com>
	<CAGxFJbR1fd4pVeNkxd7mm5z7QwQmSd+M0QeeMuiz3wP9k0jbrQ@mail.gmail.com>
	<E9A9E28D-0264-4013-9CEA-9B4D25D27EAD@bigelow.org>
Message-ID: <240b050e-d627-2f99-6384-500bf46f341a@stat.auckland.ac.nz>

Hi

Does this do what you want ?

library(latticeExtra)
c(vol_p, xy_p, x.same=TRUE)

Paul

On 26/10/16 04:30, Ben Tupper wrote:
> Thanks, Bert.
>
> I have used latticeExtra for layering graphics.  I'm not sure how I
> would use it to align graphics rather superimposing them.
>
> I shall look into the the custom panel plot but that is very new
> territory for me.
>
> Ben
>
>> On Oct 25, 2016, at 9:13 AM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>> Write a custom panel function for levelplot() that calls
>> panel.xyplot after panel.levelplot. I believe this can also be done
>> by the +  operator of the latticeExtra package.
>>
>> You do *not* want to call xyplot after levelplot, as that
>> completely redraws the plot.
>>
>> Cheers, Bert
>>
>>
>> On Oct 25, 2016 2:55 PM, "Ben Tupper" <btupper at bigelow.org
>> <mailto:btupper at bigelow.org>> wrote: Hello,
>>
>> I am drawing a levelplot and an xyplot on a single device as shown
>> in the runnable example below.  I would like the x axes to align -
>> that is for them to cover the same extent left-to-right on the
>> device. How do I go about doing that?
>>
>> ####### # START ####### library(lattice)
>>
>> d <- dim(volcano) xy <- data.frame(x = 1:d[1], y = volcano[,30] )
>>
>> vol_p <- levelplot(volcano) xy_p <- xyplot(y ~ x, data = xy)
>>
>> print(vol_p, split = c(1, 2, 1, 2), more = TRUE) print(xy_p,  split
>> = c(1, 1, 1, 2), more = FALSE) ###### #END ######
>>
>>
>> Thanks! Ben
>>
>>
>>> sessionInfo()
>> R version 3.3.1 (2016-06-21) Platform: x86_64-apple-darwin13.4.0
>> (64-bit) Running under: OS X 10.11.6 (El Capitan)
>>
>> locale: [1]
>> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages: [1] stats     graphics  grDevices utils
>> datasets  methods   base
>>
>> other attached packages: [1] lattice_0.20-33
>>
>> loaded via a namespace (and not attached): [1] tools_3.3.1
>> grid_3.3.1
>>
>>
>>
>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
>> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>> <http://www.bigelow.org/>
>>
>> ______________________________________________ R-help at r-project.org
>> <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
>> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>> <https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html> and provide
>> commented, minimal, self-contained, reproducible code.
>>
>
> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From chocold12 at gmail.com  Tue Oct 25 23:28:24 2016
From: chocold12 at gmail.com (lily li)
Date: Tue, 25 Oct 2016 15:28:24 -0600
Subject: [R] About converting files in R
Message-ID: <CAN5afy-UvGzV+Z4G07Qj8dqRcQvwBu7UV+=+qBpEuR6h_1auyg@mail.gmail.com>

Hi R users,

Do any of you have any experience about converting binary files to ascii or
txt files in R? Thanks a lot for your help.

	[[alternative HTML version deleted]]


From bob at rud.is  Tue Oct 25 23:40:45 2016
From: bob at rud.is (Bob Rudis)
Date: Tue, 25 Oct 2016 17:40:45 -0400
Subject: [R] About converting files in R
In-Reply-To: <CAN5afy-UvGzV+Z4G07Qj8dqRcQvwBu7UV+=+qBpEuR6h_1auyg@mail.gmail.com>
References: <CAN5afy-UvGzV+Z4G07Qj8dqRcQvwBu7UV+=+qBpEuR6h_1auyg@mail.gmail.com>
Message-ID: <CAA-FpKV51H9Pg=WpL77AGLkhj-G3n8TWpQXMNi+B3r=_1KwCzQ@mail.gmail.com>

I'm afraid we'll need more information that that since the answer from
many folks on the list to such a generic question is going to be a
generic "yes".

What's the source of the binary files? If you know the type, there may
even be an R package for it already.

On Tue, Oct 25, 2016 at 5:28 PM, lily li <chocold12 at gmail.com> wrote:
> Hi R users,
>
> Do any of you have any experience about converting binary files to ascii or
> txt files in R? Thanks a lot for your help.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msharp at txbiomed.org  Tue Oct 25 23:45:25 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 25 Oct 2016 21:45:25 +0000
Subject: [R] About converting files in R
In-Reply-To: <CAA-FpKV51H9Pg=WpL77AGLkhj-G3n8TWpQXMNi+B3r=_1KwCzQ@mail.gmail.com>
References: <CAN5afy-UvGzV+Z4G07Qj8dqRcQvwBu7UV+=+qBpEuR6h_1auyg@mail.gmail.com>
	<CAA-FpKV51H9Pg=WpL77AGLkhj-G3n8TWpQXMNi+B3r=_1KwCzQ@mail.gmail.com>
Message-ID: <9764EC8C-70E5-4516-801B-D1AEAE4703F4@TxBiomed.org>

Lily,

Bob's suggestion is the best. You can also look at readBin(). Enter ?readBin at the R prompt.

Mark
R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On Oct 25, 2016, at 4:40 PM, Bob Rudis <bob at rud.is> wrote:
>
> I'm afraid we'll need more information that that since the answer from
> many folks on the list to such a generic question is going to be a
> generic "yes".
>
> What's the source of the binary files? If you know the type, there may
> even be an R package for it already.
>
> On Tue, Oct 25, 2016 at 5:28 PM, lily li <chocold12 at gmail.com> wrote:
>> Hi R users,
>>
>> Do any of you have any experience about converting binary files to ascii or
>> txt files in R? Thanks a lot for your help.
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From btupper at bigelow.org  Tue Oct 25 23:50:26 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 25 Oct 2016 17:50:26 -0400
Subject: [R] [FORGED] Re:  lattice: control panel extent on device
In-Reply-To: <240b050e-d627-2f99-6384-500bf46f341a@stat.auckland.ac.nz>
References: <5241D8A5-B794-4C41-9BF1-04BA08B1AB8D@bigelow.org>
	<CAGxFJbTTE7jshhNEVizVPJD7Nngbs0a26q+CG5AmCf+wX3EoxA@mail.gmail.com>
	<CAGxFJbSs2oRCwd30jnp0ZKaCeFyjK-PvR_1QLoH3NxQPOhNoSw@mail.gmail.com>
	<CAGxFJbR1fd4pVeNkxd7mm5z7QwQmSd+M0QeeMuiz3wP9k0jbrQ@mail.gmail.com>
	<E9A9E28D-0264-4013-9CEA-9B4D25D27EAD@bigelow.org>
	<240b050e-d627-2f99-6384-500bf46f341a@stat.auckland.ac.nz>
Message-ID: <03FB6E15-9ED0-49D0-9C79-265F14176D37@bigelow.org>

Hi,

Almost but not quite.  It certainly moves the ball down the field, and, dang, that would be way too easy!  

I have been fiddling with the panel.widths to the lattice::plot method.  No joy yet.


Ben


> On Oct 25, 2016, at 5:14 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
> 
> Hi
> 
> Does this do what you want ?
> 
> library(latticeExtra)
> c(vol_p, xy_p, x.same=TRUE)
> 
> Paul
> 
> On 26/10/16 04:30, Ben Tupper wrote:
>> Thanks, Bert.
>> 
>> I have used latticeExtra for layering graphics.  I'm not sure how I
>> would use it to align graphics rather superimposing them.
>> 
>> I shall look into the the custom panel plot but that is very new
>> territory for me.
>> 
>> Ben
>> 
>>> On Oct 25, 2016, at 9:13 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>> 
>>> Write a custom panel function for levelplot() that calls
>>> panel.xyplot after panel.levelplot. I believe this can also be done
>>> by the +  operator of the latticeExtra package.
>>> 
>>> You do *not* want to call xyplot after levelplot, as that
>>> completely redraws the plot.
>>> 
>>> Cheers, Bert
>>> 
>>> 
>>> On Oct 25, 2016 2:55 PM, "Ben Tupper" <btupper at bigelow.org
>>> <mailto:btupper at bigelow.org>> wrote: Hello,
>>> 
>>> I am drawing a levelplot and an xyplot on a single device as shown
>>> in the runnable example below.  I would like the x axes to align -
>>> that is for them to cover the same extent left-to-right on the
>>> device. How do I go about doing that?
>>> 
>>> ####### # START ####### library(lattice)
>>> 
>>> d <- dim(volcano) xy <- data.frame(x = 1:d[1], y = volcano[,30] )
>>> 
>>> vol_p <- levelplot(volcano) xy_p <- xyplot(y ~ x, data = xy)
>>> 
>>> print(vol_p, split = c(1, 2, 1, 2), more = TRUE) print(xy_p,  split
>>> = c(1, 1, 1, 2), more = FALSE) ###### #END ######
>>> 
>>> 
>>> Thanks! Ben
>>> 
>>> 
>>>> sessionInfo()
>>> R version 3.3.1 (2016-06-21) Platform: x86_64-apple-darwin13.4.0
>>> (64-bit) Running under: OS X 10.11.6 (El Capitan)
>>> 
>>> locale: [1]
>>> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>> 
>>> attached base packages: [1] stats     graphics  grDevices utils
>>> datasets  methods   base
>>> 
>>> other attached packages: [1] lattice_0.20-33
>>> 
>>> loaded via a namespace (and not attached): [1] tools_3.3.1
>>> grid_3.3.1
>>> 
>>> 
>>> 
>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
>>> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>>> <http://www.bigelow.org/>
>>> 
>>> ______________________________________________ R-help at r-project.org
>>> <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
>>> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>>> <https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do read the
>>> posting guide http://www.R-project.org/posting-guide.html
>>> <http://www.r-project.org/posting-guide.html> and provide
>>> commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
>> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>> 
>> 
>> 
>> 
>> [[alternative HTML version deleted]]
>> 
>> ______________________________________________ R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and provide
>> commented, minimal, self-contained, reproducible code.
>> 
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From zpsimpso at gmail.com  Wed Oct 26 00:40:48 2016
From: zpsimpso at gmail.com (Zach Simpson)
Date: Tue, 25 Oct 2016 17:40:48 -0500
Subject: [R] Limit the y-axis line with ggplot2 (not the axis itself,
 but the line used at the left of the graph)
Message-ID: <CAJByKzo=4mfkjAU4QyXPnpOnvqPU-867O=U0qvWhKfEpTnWEvQ@mail.gmail.com>

> Hello everybody,
>
> Using ggplot2 package, is there a way to force to stop the y-axis line
> at a specified point ? (not using ylim because I want that some text
>                         written using annotate() at the top of the graph is still shown).
>
> Bellow is a simple example to show what I would like do:
>
>   Thanks a lot
>
> Marc
>
>
>
>
>
> library("ggplot2")
>
> g <- ggplot()+
>   geom_point(aes(x=c(20, 29, 32), y=c(0, 0.4, 1)))+
>   scale_y_continuous(breaks=c(0, 0.25, 0.5, 0.75, 1))+
>   labs(x="Label for x axis")+
>   labs(y="Label for y axis") +
>   annotate("text", x = 25 , y=1.2, label="Text 1")+
>   annotate("text", x = 22 , y=1.0, label="How to stop the y-axis line
>            here !")+
>   geom_segment(aes(x=25, xend=25, y=0, yend=1.1), linetype=2)+
>   > This part is just to make it more nice
>   theme(panel.background = element_rect(fill = 'white'),
>         panel.grid.major = element_blank(),
>         panel.grid.minor = element_blank(),
>         plot.margin = unit(c(0.5, 1, 0.5, 0.5), "cm"),
>         axis.text.x=element_text(size=14),
>         axis.text.y=element_text(size=14),
>         axis.title.x=element_text(size=18),
>         axis.title.y=element_text(size=18),
>         axis.ticks.length=unit(0.3,"cm"),
>         panel.border = element_blank(),
>         axis.line.x = element_line(),
>         axis.line.y = element_line())
> g

Hey Marc,

I feel there's a better solution out there, but I think I got what
you're after by replacing the y-axis with a
`annotate(geom="segment")`, which I could manipulate using the y and
yend arguments.

It took some other finagling of the other elements though.

#after already defining g per the OP
g + scale_x_continuous(limits = c(19,32.5), expand = c(0,0)) +
  scale_y_continuous(limits=c(-0.05,1.25), breaks=c(0, 0.25, 0.5,
0.75, 1), expand = c(0,0))+
  annotate(geom = "segment", x=19, xend = 19, y = -0.05, yend = 1)+
  theme(axis.line.y = element_blank())

Cheers,

Zach


From vd4mmind at gmail.com  Wed Oct 26 00:48:04 2016
From: vd4mmind at gmail.com (Vivek Das)
Date: Wed, 26 Oct 2016 00:48:04 +0200
Subject: [R] Can anyone help me with the below problem? I have tried
 stackoverflow but no help
Message-ID: <CAFkF=gGc74+5363gedOfS+op3Nx3KXdy4LP5fw1A0Ox3hxGd-Q@mail.gmail.com>

Dear Users,

I have a problem with installing a particular r-package in R -3.1.2 in my
work Debian. The problem is mentioned in the link below. I have tried to
seek help from stackoverflow but have not received any help. It would be
great if anyone can point out the problem and let me know how I can have a
workaround. I do not intend to install another version of R in our office
workspace. I already have latest in my personal office laptop but since I
handle large data files as well I try to use the R-3.1 in HPC cluster from
my /home/ directory in office debian. Now I want to install igraph in it bu
I having the problem. It would be kind if you can let me know how to fix
it. Thanks

http://stackoverflow.com/questions/40244946/error-with-installing-igraph-in-r-3-1-2-in-our-hpc-cluster-at-work
----------------------------------------------------------

Vivek Das

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Oct 26 01:46:54 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 25 Oct 2016 19:46:54 -0400
Subject: [R] Can anyone help me with the below problem? I have tried
 stackoverflow but no help
In-Reply-To: <CAFkF=gGc74+5363gedOfS+op3Nx3KXdy4LP5fw1A0Ox3hxGd-Q@mail.gmail.com>
References: <CAFkF=gGc74+5363gedOfS+op3Nx3KXdy4LP5fw1A0Ox3hxGd-Q@mail.gmail.com>
Message-ID: <CAM_vjuk=Oej-y6-_WkARSrRA1kOvcQkyaeLFq2c8phdT7FGN6w@mail.gmail.com>

I don't see your session info in the stackoverflow posting, but it
looks like you're using Debian 6, which hit its end of life in
February 2016. So the best way to get the current GLIBCXX is to
upgrade to a current version of Debian.

A google search on installing GLIBCXX_3.4.15 on Debian 6 turns up a
bunch of hits, so you may be able to find a work-around if necessary.
You might also be able to download the source for an older version of
igraph that works with your system.

Sarah

On Tue, Oct 25, 2016 at 6:48 PM, Vivek Das <vd4mmind at gmail.com> wrote:
> Dear Users,
>
> I have a problem with installing a particular r-package in R -3.1.2 in my
> work Debian. The problem is mentioned in the link below. I have tried to
> seek help from stackoverflow but have not received any help. It would be
> great if anyone can point out the problem and let me know how I can have a
> workaround. I do not intend to install another version of R in our office
> workspace. I already have latest in my personal office laptop but since I
> handle large data files as well I try to use the R-3.1 in HPC cluster from
> my /home/ directory in office debian. Now I want to install igraph in it bu
> I having the problem. It would be kind if you can let me know how to fix
> it. Thanks
>
> http://stackoverflow.com/questions/40244946/error-with-installing-igraph-in-r-3-1-2-in-our-hpc-cluster-at-work
> ----------------------------------------------------------
>


From jwd at surewest.net  Wed Oct 26 01:47:34 2016
From: jwd at surewest.net (John Dougherty)
Date: Tue, 25 Oct 2016 16:47:34 -0700
Subject: [R] Error in a regression
In-Reply-To: <CAGTB1-y7LF=zybywHE-TnWjMf2rh1LvXAZL=jeq0PFhFHRvoNw@mail.gmail.com>
References: <CAGTB1-y7LF=zybywHE-TnWjMf2rh1LvXAZL=jeq0PFhFHRvoNw@mail.gmail.com>
Message-ID: <20161025164734.7a556068@draco>

On Mon, 24 Oct 2016 10:54:00 -0500
Andrea Marcela Huerfano Barbosa <anmhuerfanoba at unal.edu.co> wrote:

> Hi guys,
> When I try to do a linear regression into the console appears this
> warning message:
> 
> >* attempting model selection on an essentially perfect fit is
> >nonsense*
> 
> Some one could tell me what does it mean and maybe a way to solve it.
> 
> Thanks in advance,
> 
> Andrea Marcela
> 
Andrea, there is far too little information in your post for us to help
you.  The standard lm() routine doesn't produce that message in any
model. You need to provide a sample the data and explain what routine
you are using to select the model.

-- 

John


From vd4mmind at gmail.com  Wed Oct 26 01:51:21 2016
From: vd4mmind at gmail.com (Vivek Das)
Date: Wed, 26 Oct 2016 01:51:21 +0200
Subject: [R] Can anyone help me with the below problem? I have tried
 stackoverflow but no help
In-Reply-To: <CAM_vjuk=Oej-y6-_WkARSrRA1kOvcQkyaeLFq2c8phdT7FGN6w@mail.gmail.com>
References: <CAFkF=gGc74+5363gedOfS+op3Nx3KXdy4LP5fw1A0Ox3hxGd-Q@mail.gmail.com>
	<CAM_vjuk=Oej-y6-_WkARSrRA1kOvcQkyaeLFq2c8phdT7FGN6w@mail.gmail.com>
Message-ID: <CAFkF=gGV1anYeC7yjY18EYOunoaFOM=cYgh9P5WHLRB34CFX-g@mail.gmail.com>

Dear Sarah,

Thank you for your reply. I cannot upgrade debian since it is an HPC and I
do not have root priviledges. I will try to install and older version that
is compatible and report. Thanks a lot.
Regards,

Vivek

On Oct 26, 2016 1:46 AM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:

> I don't see your session info in the stackoverflow posting, but it
> looks like you're using Debian 6, which hit its end of life in
> February 2016. So the best way to get the current GLIBCXX is to
> upgrade to a current version of Debian.
>
> A google search on installing GLIBCXX_3.4.15 on Debian 6 turns up a
> bunch of hits, so you may be able to find a work-around if necessary.
> You might also be able to download the source for an older version of
> igraph that works with your system.
>
> Sarah
>
> On Tue, Oct 25, 2016 at 6:48 PM, Vivek Das <vd4mmind at gmail.com> wrote:
> > Dear Users,
> >
> > I have a problem with installing a particular r-package in R -3.1.2 in my
> > work Debian. The problem is mentioned in the link below. I have tried to
> > seek help from stackoverflow but have not received any help. It would be
> > great if anyone can point out the problem and let me know how I can have
> a
> > workaround. I do not intend to install another version of R in our office
> > workspace. I already have latest in my personal office laptop but since I
> > handle large data files as well I try to use the R-3.1 in HPC cluster
> from
> > my /home/ directory in office debian. Now I want to install igraph in it
> bu
> > I having the problem. It would be kind if you can let me know how to fix
> > it. Thanks
> >
> > http://stackoverflow.com/questions/40244946/error-with-
> installing-igraph-in-r-3-1-2-in-our-hpc-cluster-at-work
> > ----------------------------------------------------------
> >
>

	[[alternative HTML version deleted]]


From paul at stat.auckland.ac.nz  Wed Oct 26 02:07:27 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 26 Oct 2016 13:07:27 +1300
Subject: [R] [FORGED] Re:  lattice: control panel extent on device
In-Reply-To: <03FB6E15-9ED0-49D0-9C79-265F14176D37@bigelow.org>
References: <5241D8A5-B794-4C41-9BF1-04BA08B1AB8D@bigelow.org>
	<CAGxFJbTTE7jshhNEVizVPJD7Nngbs0a26q+CG5AmCf+wX3EoxA@mail.gmail.com>
	<CAGxFJbSs2oRCwd30jnp0ZKaCeFyjK-PvR_1QLoH3NxQPOhNoSw@mail.gmail.com>
	<CAGxFJbR1fd4pVeNkxd7mm5z7QwQmSd+M0QeeMuiz3wP9k0jbrQ@mail.gmail.com>
	<E9A9E28D-0264-4013-9CEA-9B4D25D27EAD@bigelow.org>
	<240b050e-d627-2f99-6384-500bf46f341a@stat.auckland.ac.nz>
	<03FB6E15-9ED0-49D0-9C79-265F14176D37@bigelow.org>
Message-ID: <3e921eb1-0f0f-bbc4-119a-c3b54e1ae5c5@stat.auckland.ac.nz>

Hi

This might work, though it's a teensy bit more complicated and a bit 
manual (on the left axis labels) and it ignores heights and vertical 
whitespace ...

library(lattice)
d <- dim(volcano)
xy <- data.frame(x = 1:d[1], y = volcano[,30] )
library(grid)
grid.newpage()
pushViewport(viewport(y=0, height=.5, just="bottom"))
# Force identical widths where we can
layout.widths <- lattice.options("layout.widths")[[1]]
layout.widths$ylab <- list(x=1, units="cm", data=NULL)
layout.widths$panel <- list(x=1, units="null", data=NULL)
layout.widths$key.right <- list(x=1, units="cm", data=NULL)
lattice.options(layout.widths=layout.widths)
# Force (width of) left axis labels to be the same
vol_p <- levelplot(volcano, scales=list(y=list(at=seq(10, 60, 10),
                                                labels=rep(" ", 6))))
print(vol_p, newpage=FALSE, prefix="vol_p")
downViewport("vol_p.panel.1.1.off.vp")
# Draw proper left axis labels
grid.text(seq(10, 60, 10), x=unit(0, "npc") - unit(1, "lines"),
           y=unit(seq(10, 60, 10), "native"), just="right",
           gp=gpar(cex=.8))
# Determine width of levelplot panel
border <- grid.get("border", grep=TRUE)
width <- convertWidth(border$width, "in", valueOnly=TRUE)
xscale <- current.viewport()$xscale
upViewport(0)
pushViewport(viewport(y=.5, height=.5, just="bottom"))
# Force identical widths where we can
layout.widths$ylab <- list(x=1, units="cm", data=NULL)
layout.widths$panel <- list(x=width, units="in", data=NULL)
layout.widths$key.right <- list(x=1, units="cm", data=NULL)
lattice.options(layout.widths=layout.widths)
# Force (width of) left axis labels to be the same
xy_p <- xyplot(y ~ x, data = xy, xlim=xscale,
                scales=list(y=list(at=seq(100, 200, 20),
                                   labels=rep(" ", 11))))
print(xy_p, newpage=FALSE, prefix="xy_p")
downViewport("xy_p.panel.1.1.off.vp")
# Draw proper left axis labels
grid.text(seq(100, 200, 20), x=unit(0, "npc") - unit(1, "lines"),
           y=unit(seq(100, 200, 20), "native"), just="right",
           gp=gpar(cex=.8))
upViewport(0)

Paul

On 26/10/16 10:50, Ben Tupper wrote:
> Hi,
>
> Almost but not quite.  It certainly moves the ball down the field, and, dang, that would be way too easy!
>
> I have been fiddling with the panel.widths to the lattice::plot method.  No joy yet.
>
>
> Ben
>
>
>> On Oct 25, 2016, at 5:14 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
>>
>> Hi
>>
>> Does this do what you want ?
>>
>> library(latticeExtra)
>> c(vol_p, xy_p, x.same=TRUE)
>>
>> Paul
>>
>> On 26/10/16 04:30, Ben Tupper wrote:
>>> Thanks, Bert.
>>>
>>> I have used latticeExtra for layering graphics.  I'm not sure how I
>>> would use it to align graphics rather superimposing them.
>>>
>>> I shall look into the the custom panel plot but that is very new
>>> territory for me.
>>>
>>> Ben
>>>
>>>> On Oct 25, 2016, at 9:13 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>> wrote:
>>>>
>>>> Write a custom panel function for levelplot() that calls
>>>> panel.xyplot after panel.levelplot. I believe this can also be done
>>>> by the +  operator of the latticeExtra package.
>>>>
>>>> You do *not* want to call xyplot after levelplot, as that
>>>> completely redraws the plot.
>>>>
>>>> Cheers, Bert
>>>>
>>>>
>>>> On Oct 25, 2016 2:55 PM, "Ben Tupper" <btupper at bigelow.org
>>>> <mailto:btupper at bigelow.org>> wrote: Hello,
>>>>
>>>> I am drawing a levelplot and an xyplot on a single device as shown
>>>> in the runnable example below.  I would like the x axes to align -
>>>> that is for them to cover the same extent left-to-right on the
>>>> device. How do I go about doing that?
>>>>
>>>> ####### # START ####### library(lattice)
>>>>
>>>> d <- dim(volcano) xy <- data.frame(x = 1:d[1], y = volcano[,30] )
>>>>
>>>> vol_p <- levelplot(volcano) xy_p <- xyplot(y ~ x, data = xy)
>>>>
>>>> print(vol_p, split = c(1, 2, 1, 2), more = TRUE) print(xy_p,  split
>>>> = c(1, 1, 1, 2), more = FALSE) ###### #END ######
>>>>
>>>>
>>>> Thanks! Ben
>>>>
>>>>
>>>>> sessionInfo()
>>>> R version 3.3.1 (2016-06-21) Platform: x86_64-apple-darwin13.4.0
>>>> (64-bit) Running under: OS X 10.11.6 (El Capitan)
>>>>
>>>> locale: [1]
>>>> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>
>>>> attached base packages: [1] stats     graphics  grDevices utils
>>>> datasets  methods   base
>>>>
>>>> other attached packages: [1] lattice_0.20-33
>>>>
>>>> loaded via a namespace (and not attached): [1] tools_3.3.1
>>>> grid_3.3.1
>>>>
>>>>
>>>>
>>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
>>>> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>>>> <http://www.bigelow.org/>
>>>>
>>>> ______________________________________________ R-help at r-project.org
>>>> <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
>>>> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>>>> <https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do read the
>>>> posting guide http://www.R-project.org/posting-guide.html
>>>> <http://www.r-project.org/posting-guide.html> and provide
>>>> commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
>>> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>>>
>>>
>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________ R-help at r-project.org
>>> mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>>> posting guide http://www.R-project.org/posting-guide.html and provide
>>> commented, minimal, self-contained, reproducible code.
>>>
>>
>> --
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
>
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From dulcalma at bigpond.com  Wed Oct 26 02:56:10 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 26 Oct 2016 11:56:10 +1100
Subject: [R] lattice: control panel extent on device
In-Reply-To: <5241D8A5-B794-4C41-9BF1-04BA08B1AB8D@bigelow.org>
References: <5241D8A5-B794-4C41-9BF1-04BA08B1AB8D@bigelow.org>
Message-ID: <000601d22f23$be492070$3adb6150$@bigpond.com>

Hi Ben

A bit kludgy but it works. Further refinement by eye

print(vol_p, position = c(0,0,1,0.5), more = TRUE)
print(xy_p, position = c(0.14,0.5,0.86,1), more = FALSE)

I do not know if viewports will be  any better

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ben Tupper
Sent: Tuesday, 25 October 2016 23:53
To: r-help
Subject: [R] lattice: control panel extent on device

Hello,

I am drawing a levelplot and an xyplot on a single device as shown in the
runnable example below.  I would like the x axes to align - that is for them
to cover the same extent left-to-right on the device. How do I go about
doing that?

#######
# START
#######
library(lattice)

d <- dim(volcano)
xy <- data.frame(x = 1:d[1], y = volcano[,30] )

vol_p <- levelplot(volcano)
xy_p <- xyplot(y ~ x, data = xy)

print(vol_p, split = c(1, 2, 1, 2), more = TRUE)
print(xy_p,  split = c(1, 1, 1, 2), more = FALSE)
######
#END
######


Thanks!
Ben


> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.6 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lattice_0.20-33

loaded via a namespace (and not attached):
[1] tools_3.3.1 grid_3.3.1 



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bob at rud.is  Wed Oct 26 03:21:22 2016
From: bob at rud.is (Bob Rudis)
Date: Tue, 25 Oct 2016 21:21:22 -0400
Subject: [R] About converting files in R
In-Reply-To: <CAA-FpKV51H9Pg=WpL77AGLkhj-G3n8TWpQXMNi+B3r=_1KwCzQ@mail.gmail.com>
References: <CAN5afy-UvGzV+Z4G07Qj8dqRcQvwBu7UV+=+qBpEuR6h_1auyg@mail.gmail.com>
	<CAA-FpKV51H9Pg=WpL77AGLkhj-G3n8TWpQXMNi+B3r=_1KwCzQ@mail.gmail.com>
Message-ID: <CAA-FpKW-yN-Optk6UvCqs8bL=LukW+H_Gt51DxihE-gjDTqUaQ@mail.gmail.com>

Can you tell us where you got the file from and perhaps even send a
link to the file? I know of at least 11 types of files that use `.bin`
as an extension which are all different types of data with different
binary formats.

On Tue, Oct 25, 2016 at 5:40 PM, Bob Rudis <bob at rud.is> wrote:
> I'm afraid we'll need more information that that since the answer from
> many folks on the list to such a generic question is going to be a
> generic "yes".
>
> What's the source of the binary files? If you know the type, there may
> even be an R package for it already.
>
> On Tue, Oct 25, 2016 at 5:28 PM, lily li <chocold12 at gmail.com> wrote:
>> Hi R users,
>>
>> Do any of you have any experience about converting binary files to ascii or
>> txt files in R? Thanks a lot for your help.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From btupper at bigelow.org  Wed Oct 26 04:08:03 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 25 Oct 2016 22:08:03 -0400
Subject: [R] [FORGED]  lattice: control panel extent on device
In-Reply-To: <3e921eb1-0f0f-bbc4-119a-c3b54e1ae5c5@stat.auckland.ac.nz>
References: <5241D8A5-B794-4C41-9BF1-04BA08B1AB8D@bigelow.org>
	<CAGxFJbTTE7jshhNEVizVPJD7Nngbs0a26q+CG5AmCf+wX3EoxA@mail.gmail.com>
	<CAGxFJbSs2oRCwd30jnp0ZKaCeFyjK-PvR_1QLoH3NxQPOhNoSw@mail.gmail.com>
	<CAGxFJbR1fd4pVeNkxd7mm5z7QwQmSd+M0QeeMuiz3wP9k0jbrQ@mail.gmail.com>
	<E9A9E28D-0264-4013-9CEA-9B4D25D27EAD@bigelow.org>
	<240b050e-d627-2f99-6384-500bf46f341a@stat.auckland.ac.nz>
	<03FB6E15-9ED0-49D0-9C79-265F14176D37@bigelow.org>
	<3e921eb1-0f0f-bbc4-119a-c3b54e1ae5c5@stat.auckland.ac.nz>
Message-ID: <C4F7FC01-75F6-4983-9802-87AF2D333387@bigelow.org>

Wow!  That's exactly what I am looking for!

I have had both books* open in front of me all day to no avail, and, I was spinning round and round - I was waaay off in left field.

Thanks so much!
Ben


* https://www.r-project.org/doc/bib/R-books_bib.html#R:Sarkar:2008
  https://www.r-project.org/doc/bib/R-books_bib.html#R:Murrell:2011

> On Oct 25, 2016, at 8:07 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
> 
> Hi
> 
> This might work, though it's a teensy bit more complicated and a bit manual (on the left axis labels) and it ignores heights and vertical whitespace ...
> 
> library(lattice)
> d <- dim(volcano)
> xy <- data.frame(x = 1:d[1], y = volcano[,30] )
> library(grid)
> grid.newpage()
> pushViewport(viewport(y=0, height=.5, just="bottom"))
> # Force identical widths where we can
> layout.widths <- lattice.options("layout.widths")[[1]]
> layout.widths$ylab <- list(x=1, units="cm", data=NULL)
> layout.widths$panel <- list(x=1, units="null", data=NULL)
> layout.widths$key.right <- list(x=1, units="cm", data=NULL)
> lattice.options(layout.widths=layout.widths)
> # Force (width of) left axis labels to be the same
> vol_p <- levelplot(volcano, scales=list(y=list(at=seq(10, 60, 10),
>                                               labels=rep(" ", 6))))
> print(vol_p, newpage=FALSE, prefix="vol_p")
> downViewport("vol_p.panel.1.1.off.vp")
> # Draw proper left axis labels
> grid.text(seq(10, 60, 10), x=unit(0, "npc") - unit(1, "lines"),
>          y=unit(seq(10, 60, 10), "native"), just="right",
>          gp=gpar(cex=.8))
> # Determine width of levelplot panel
> border <- grid.get("border", grep=TRUE)
> width <- convertWidth(border$width, "in", valueOnly=TRUE)
> xscale <- current.viewport()$xscale
> upViewport(0)
> pushViewport(viewport(y=.5, height=.5, just="bottom"))
> # Force identical widths where we can
> layout.widths$ylab <- list(x=1, units="cm", data=NULL)
> layout.widths$panel <- list(x=width, units="in", data=NULL)
> layout.widths$key.right <- list(x=1, units="cm", data=NULL)
> lattice.options(layout.widths=layout.widths)
> # Force (width of) left axis labels to be the same
> xy_p <- xyplot(y ~ x, data = xy, xlim=xscale,
>               scales=list(y=list(at=seq(100, 200, 20),
>                                  labels=rep(" ", 11))))
> print(xy_p, newpage=FALSE, prefix="xy_p")
> downViewport("xy_p.panel.1.1.off.vp")
> # Draw proper left axis labels
> grid.text(seq(100, 200, 20), x=unit(0, "npc") - unit(1, "lines"),
>          y=unit(seq(100, 200, 20), "native"), just="right",
>          gp=gpar(cex=.8))
> upViewport(0)
> 
> Paul
> 
> On 26/10/16 10:50, Ben Tupper wrote:
>> Hi,
>> 
>> Almost but not quite.  It certainly moves the ball down the field, and, dang, that would be way too easy!
>> 
>> I have been fiddling with the panel.widths to the lattice::plot method.  No joy yet.
>> 
>> 
>> Ben
>> 
>> 
>>> On Oct 25, 2016, at 5:14 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
>>> 
>>> Hi
>>> 
>>> Does this do what you want ?
>>> 
>>> library(latticeExtra)
>>> c(vol_p, xy_p, x.same=TRUE)
>>> 
>>> Paul
>>> 
>>> On 26/10/16 04:30, Ben Tupper wrote:
>>>> Thanks, Bert.
>>>> 
>>>> I have used latticeExtra for layering graphics.  I'm not sure how I
>>>> would use it to align graphics rather superimposing them.
>>>> 
>>>> I shall look into the the custom panel plot but that is very new
>>>> territory for me.
>>>> 
>>>> Ben
>>>> 
>>>>> On Oct 25, 2016, at 9:13 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>> wrote:
>>>>> 
>>>>> Write a custom panel function for levelplot() that calls
>>>>> panel.xyplot after panel.levelplot. I believe this can also be done
>>>>> by the +  operator of the latticeExtra package.
>>>>> 
>>>>> You do *not* want to call xyplot after levelplot, as that
>>>>> completely redraws the plot.
>>>>> 
>>>>> Cheers, Bert
>>>>> 
>>>>> 
>>>>> On Oct 25, 2016 2:55 PM, "Ben Tupper" <btupper at bigelow.org
>>>>> <mailto:btupper at bigelow.org>> wrote: Hello,
>>>>> 
>>>>> I am drawing a levelplot and an xyplot on a single device as shown
>>>>> in the runnable example below.  I would like the x axes to align -
>>>>> that is for them to cover the same extent left-to-right on the
>>>>> device. How do I go about doing that?
>>>>> 
>>>>> ####### # START ####### library(lattice)
>>>>> 
>>>>> d <- dim(volcano) xy <- data.frame(x = 1:d[1], y = volcano[,30] )
>>>>> 
>>>>> vol_p <- levelplot(volcano) xy_p <- xyplot(y ~ x, data = xy)
>>>>> 
>>>>> print(vol_p, split = c(1, 2, 1, 2), more = TRUE) print(xy_p,  split
>>>>> = c(1, 1, 1, 2), more = FALSE) ###### #END ######
>>>>> 
>>>>> 
>>>>> Thanks! Ben
>>>>> 
>>>>> 
>>>>>> sessionInfo()
>>>>> R version 3.3.1 (2016-06-21) Platform: x86_64-apple-darwin13.4.0
>>>>> (64-bit) Running under: OS X 10.11.6 (El Capitan)
>>>>> 
>>>>> locale: [1]
>>>>> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>> 
>>>>> attached base packages: [1] stats     graphics  grDevices utils
>>>>> datasets  methods   base
>>>>> 
>>>>> other attached packages: [1] lattice_0.20-33
>>>>> 
>>>>> loaded via a namespace (and not attached): [1] tools_3.3.1
>>>>> grid_3.3.1
>>>>> 
>>>>> 
>>>>> 
>>>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
>>>>> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>>>>> <http://www.bigelow.org/>
>>>>> 
>>>>> ______________________________________________ R-help at r-project.org
>>>>> <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
>>>>> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do read the
>>>>> posting guide http://www.R-project.org/posting-guide.html
>>>>> <http://www.r-project.org/posting-guide.html> and provide
>>>>> commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
>>>> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>>>> 
>>>> 
>>>> 
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________ R-help at r-project.org
>>>> mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>>>> posting guide http://www.R-project.org/posting-guide.html and provide
>>>> commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> --
>>> Dr Paul Murrell
>>> Department of Statistics
>>> The University of Auckland
>>> Private Bag 92019
>>> Auckland
>>> New Zealand
>>> 64 9 3737599 x85392
>>> paul at stat.auckland.ac.nz
>>> http://www.stat.auckland.ac.nz/~paul/
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>> 
>> 
>> 
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From rmh at temple.edu  Wed Oct 26 05:21:23 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 25 Oct 2016 23:21:23 -0400
Subject: [R] [FORGED] lattice: control panel extent on device
In-Reply-To: <C4F7FC01-75F6-4983-9802-87AF2D333387@bigelow.org>
References: <5241D8A5-B794-4C41-9BF1-04BA08B1AB8D@bigelow.org>
	<CAGxFJbTTE7jshhNEVizVPJD7Nngbs0a26q+CG5AmCf+wX3EoxA@mail.gmail.com>
	<CAGxFJbSs2oRCwd30jnp0ZKaCeFyjK-PvR_1QLoH3NxQPOhNoSw@mail.gmail.com>
	<CAGxFJbR1fd4pVeNkxd7mm5z7QwQmSd+M0QeeMuiz3wP9k0jbrQ@mail.gmail.com>
	<E9A9E28D-0264-4013-9CEA-9B4D25D27EAD@bigelow.org>
	<240b050e-d627-2f99-6384-500bf46f341a@stat.auckland.ac.nz>
	<03FB6E15-9ED0-49D0-9C79-265F14176D37@bigelow.org>
	<3e921eb1-0f0f-bbc4-119a-c3b54e1ae5c5@stat.auckland.ac.nz>
	<C4F7FC01-75F6-4983-9802-87AF2D333387@bigelow.org>
Message-ID: <CAGx1TMCMMQ4aq4qVLUhygJ1wJD5iq4W8GYCOY8f5qHP9BAP5Kg@mail.gmail.com>

I think this is simpler.

vol_p2 <- vol_p
vol_p2$legend <- NULL
print(update(vol_p2, scales=list(y=list(labels=FALSE))), split = c(1,
2, 1, 2), more = TRUE)
draw.colorkey(vol_p$legend$right$args$key, draw=TRUE,
vp=viewport(y=.27, height=.26, x=.75))
print(update(xy_p, scales=list(y=list(labels=FALSE))),  split = c(1,
1, 1, 2), more = FALSE)

On Tue, Oct 25, 2016 at 10:08 PM, Ben Tupper <btupper at bigelow.org> wrote:
> Wow!  That's exactly what I am looking for!
>
> I have had both books* open in front of me all day to no avail, and, I was spinning round and round - I was waaay off in left field.
>
> Thanks so much!
> Ben
>
>
> * https://www.r-project.org/doc/bib/R-books_bib.html#R:Sarkar:2008
>   https://www.r-project.org/doc/bib/R-books_bib.html#R:Murrell:2011
>
>> On Oct 25, 2016, at 8:07 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
>>
>> Hi
>>
>> This might work, though it's a teensy bit more complicated and a bit manual (on the left axis labels) and it ignores heights and vertical whitespace ...
>>
>> library(lattice)
>> d <- dim(volcano)
>> xy <- data.frame(x = 1:d[1], y = volcano[,30] )
>> library(grid)
>> grid.newpage()
>> pushViewport(viewport(y=0, height=.5, just="bottom"))
>> # Force identical widths where we can
>> layout.widths <- lattice.options("layout.widths")[[1]]
>> layout.widths$ylab <- list(x=1, units="cm", data=NULL)
>> layout.widths$panel <- list(x=1, units="null", data=NULL)
>> layout.widths$key.right <- list(x=1, units="cm", data=NULL)
>> lattice.options(layout.widths=layout.widths)
>> # Force (width of) left axis labels to be the same
>> vol_p <- levelplot(volcano, scales=list(y=list(at=seq(10, 60, 10),
>>                                               labels=rep(" ", 6))))
>> print(vol_p, newpage=FALSE, prefix="vol_p")
>> downViewport("vol_p.panel.1.1.off.vp")
>> # Draw proper left axis labels
>> grid.text(seq(10, 60, 10), x=unit(0, "npc") - unit(1, "lines"),
>>          y=unit(seq(10, 60, 10), "native"), just="right",
>>          gp=gpar(cex=.8))
>> # Determine width of levelplot panel
>> border <- grid.get("border", grep=TRUE)
>> width <- convertWidth(border$width, "in", valueOnly=TRUE)
>> xscale <- current.viewport()$xscale
>> upViewport(0)
>> pushViewport(viewport(y=.5, height=.5, just="bottom"))
>> # Force identical widths where we can
>> layout.widths$ylab <- list(x=1, units="cm", data=NULL)
>> layout.widths$panel <- list(x=width, units="in", data=NULL)
>> layout.widths$key.right <- list(x=1, units="cm", data=NULL)
>> lattice.options(layout.widths=layout.widths)
>> # Force (width of) left axis labels to be the same
>> xy_p <- xyplot(y ~ x, data = xy, xlim=xscale,
>>               scales=list(y=list(at=seq(100, 200, 20),
>>                                  labels=rep(" ", 11))))
>> print(xy_p, newpage=FALSE, prefix="xy_p")
>> downViewport("xy_p.panel.1.1.off.vp")
>> # Draw proper left axis labels
>> grid.text(seq(100, 200, 20), x=unit(0, "npc") - unit(1, "lines"),
>>          y=unit(seq(100, 200, 20), "native"), just="right",
>>          gp=gpar(cex=.8))
>> upViewport(0)
>>
>> Paul
>>
>> On 26/10/16 10:50, Ben Tupper wrote:
>>> Hi,
>>>
>>> Almost but not quite.  It certainly moves the ball down the field, and, dang, that would be way too easy!
>>>
>>> I have been fiddling with the panel.widths to the lattice::plot method.  No joy yet.
>>>
>>>
>>> Ben
>>>
>>>
>>>> On Oct 25, 2016, at 5:14 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
>>>>
>>>> Hi
>>>>
>>>> Does this do what you want ?
>>>>
>>>> library(latticeExtra)
>>>> c(vol_p, xy_p, x.same=TRUE)
>>>>
>>>> Paul
>>>>
>>>> On 26/10/16 04:30, Ben Tupper wrote:
>>>>> Thanks, Bert.
>>>>>
>>>>> I have used latticeExtra for layering graphics.  I'm not sure how I
>>>>> would use it to align graphics rather superimposing them.
>>>>>
>>>>> I shall look into the the custom panel plot but that is very new
>>>>> territory for me.
>>>>>
>>>>> Ben
>>>>>
>>>>>> On Oct 25, 2016, at 9:13 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>> Write a custom panel function for levelplot() that calls
>>>>>> panel.xyplot after panel.levelplot. I believe this can also be done
>>>>>> by the +  operator of the latticeExtra package.
>>>>>>
>>>>>> You do *not* want to call xyplot after levelplot, as that
>>>>>> completely redraws the plot.
>>>>>>
>>>>>> Cheers, Bert
>>>>>>
>>>>>>
>>>>>> On Oct 25, 2016 2:55 PM, "Ben Tupper" <btupper at bigelow.org
>>>>>> <mailto:btupper at bigelow.org>> wrote: Hello,
>>>>>>
>>>>>> I am drawing a levelplot and an xyplot on a single device as shown
>>>>>> in the runnable example below.  I would like the x axes to align -
>>>>>> that is for them to cover the same extent left-to-right on the
>>>>>> device. How do I go about doing that?
>>>>>>
>>>>>> ####### # START ####### library(lattice)
>>>>>>
>>>>>> d <- dim(volcano) xy <- data.frame(x = 1:d[1], y = volcano[,30] )
>>>>>>
>>>>>> vol_p <- levelplot(volcano) xy_p <- xyplot(y ~ x, data = xy)
>>>>>>
>>>>>> print(vol_p, split = c(1, 2, 1, 2), more = TRUE) print(xy_p,  split
>>>>>> = c(1, 1, 1, 2), more = FALSE) ###### #END ######
>>>>>>
>>>>>>
>>>>>> Thanks! Ben
>>>>>>
>>>>>>
>>>>>>> sessionInfo()
>>>>>> R version 3.3.1 (2016-06-21) Platform: x86_64-apple-darwin13.4.0
>>>>>> (64-bit) Running under: OS X 10.11.6 (El Capitan)
>>>>>>
>>>>>> locale: [1]
>>>>>> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>>>
>>>>>> attached base packages: [1] stats     graphics  grDevices utils
>>>>>> datasets  methods   base
>>>>>>
>>>>>> other attached packages: [1] lattice_0.20-33
>>>>>>
>>>>>> loaded via a namespace (and not attached): [1] tools_3.3.1
>>>>>> grid_3.3.1
>>>>>>
>>>>>>
>>>>>>
>>>>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
>>>>>> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>>>>>> <http://www.bigelow.org/>
>>>>>>
>>>>>> ______________________________________________ R-help at r-project.org
>>>>>> <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
>>>>>> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do read the
>>>>>> posting guide http://www.R-project.org/posting-guide.html
>>>>>> <http://www.r-project.org/posting-guide.html> and provide
>>>>>> commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
>>>>> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________ R-help at r-project.org
>>>>> mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>>>>> posting guide http://www.R-project.org/posting-guide.html and provide
>>>>> commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>> --
>>>> Dr Paul Murrell
>>>> Department of Statistics
>>>> The University of Auckland
>>>> Private Bag 92019
>>>> Auckland
>>>> New Zealand
>>>> 64 9 3737599 x85392
>>>> paul at stat.auckland.ac.nz
>>>> http://www.stat.auckland.ac.nz/~paul/
>>>
>>> Ben Tupper
>>> Bigelow Laboratory for Ocean Sciences
>>> 60 Bigelow Drive, P.O. Box 380
>>> East Boothbay, Maine 04544
>>> http://www.bigelow.org
>>>
>>>
>>>
>>
>> --
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From es at enricoschumann.net  Mon Oct 24 20:44:36 2016
From: es at enricoschumann.net (Enrico Schumann)
Date: Mon, 24 Oct 2016 20:44:36 +0200
Subject: [R] [R-pkgs] NMOF 0.40-0 (Numerical Methods and Optimization in
	Finance)
Message-ID: <87a8dtd1t7.fsf@enricoschumann.net>

Dear all,

version 0.40-0 of package NMOF is on CRAN now, 5 years
(exactly) after its first release on CRAN.

'NMOF' stands for 'Numerical Methods and Optimization
in Finance'. The package accompanies the book with the
same name, written by Manfred Gilli, Dietmar Maringer
and Enrico Schumann, published by Elsevier/Academic
Press in 2011.

Since my last announcement on this list [1], many
things have been added to the package:

- all the R code examples from the book (?showExample)

- many new functions, e.g. for pricing financial
  instruments (?vanillaOptionEuropean, ?vanillaBond,
  ?callMerton, ?xtContractValue, ...), and utilities
  for Monte-Carlo simulation, for computing implied
  vol, yields, etc.

Many of these new functions are described, with
examples, in the Manual [2].

If you want to stay up-to-date: the latest version is
always available from my website [3]; there is a public
Git repository on GitHub [4].

In case of comments/corrections/remarks/suggestions --
which are very welcome -- please contact the maintainer
(me) directly.


Kind regards
    Enrico


[1] https://stat.ethz.ch/pipermail/r-packages/2011/001257.html
[2] http://enricoschumann.net/NMOF.htm#NMOFmanual
[3] http://enricoschumann.net/R/packages/NMOF/
[4] https://github.com/enricoschumann/NMOF

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From a.recktenwald at mx.uni-saarland.de  Tue Oct 25 13:58:18 2016
From: a.recktenwald at mx.uni-saarland.de (Andreas Recktenwald)
Date: Tue, 25 Oct 2016 13:58:18 +0200
Subject: [R] [R-pkgs] New Package: pinbasic - Fast and Stable Estimation of
 the Probability of Informed Trading (PIN)
Message-ID: <a262f7c2-63e8-7e84-c611-9ce55041a377@mx.uni-saarland.de>

Dear R-Users,

a new package, "pinbasic", is now available on CRAN. According to the 
DESCRIPTION:


Utilities for fast and stable estimation of the probability of informed 
trading (PIN) in the model introduced by Easley et al. (2002) 
<DOI:10.1111/1540-6261.00493> are implemented. Since the basic model 
developed  by Easley et al. (1996) 
<DOI:10.1111/j.1540-6261.1996.tb04074.x> is nested in the former due to 
equating the intensity of uninformed buys and sells, functionalities  
can also be applied to this simpler model structure, if needed.


A vignette will be added to the package in near future. However, the 
existing manual pages should be a good starting point.

Development version of the package is available at:

https://github.com/anre005/pinbasic

-- 
Diplom-Kaufmann Andreas Recktenwald
Statistik & ?konometrie
Rechts- und Wirtschaftswissenschaftliche Fakult?t
Universit?t des Saarlandes
Campus C3 1, Raum 2.06
66123 Saarbr?cken
Deutschland

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From btupper at bigelow.org  Wed Oct 26 17:21:52 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 26 Oct 2016 11:21:52 -0400
Subject: [R] [FORGED]  lattice: control panel extent on device
In-Reply-To: <3e921eb1-0f0f-bbc4-119a-c3b54e1ae5c5@stat.auckland.ac.nz>
References: <5241D8A5-B794-4C41-9BF1-04BA08B1AB8D@bigelow.org>
	<CAGxFJbTTE7jshhNEVizVPJD7Nngbs0a26q+CG5AmCf+wX3EoxA@mail.gmail.com>
	<CAGxFJbSs2oRCwd30jnp0ZKaCeFyjK-PvR_1QLoH3NxQPOhNoSw@mail.gmail.com>
	<CAGxFJbR1fd4pVeNkxd7mm5z7QwQmSd+M0QeeMuiz3wP9k0jbrQ@mail.gmail.com>
	<E9A9E28D-0264-4013-9CEA-9B4D25D27EAD@bigelow.org>
	<240b050e-d627-2f99-6384-500bf46f341a@stat.auckland.ac.nz>
	<03FB6E15-9ED0-49D0-9C79-265F14176D37@bigelow.org>
	<3e921eb1-0f0f-bbc4-119a-c3b54e1ae5c5@stat.auckland.ac.nz>
Message-ID: <0FDDD7DE-A200-41CA-8A41-A9AFCE0B0785@bigelow.org>

Hi,

The following encapsulates what I hoped for using Paul's method.  The function accepts one or more trellis class objects and aligns them vertically.  I think I have automated most of the manual fiddling.  Depending upon your graphics device you may need to fiddle with the aspect of the levelplot as I did below.  There remains a good deal of vertical white space but it is fine for my purposes as I only need two objects aligned where it looks OK.

I couldn't get Richard's simplified steps to work - I'm still noodling that out but the simplicity is very enticing.

Thanks again for the all the suggestions!
Ben

#### START
library(lattice)
library(grid)

#' Vertically align one or more trellis class objects.
#'
#' Objects are plotted in order from bottom up and all are restricted to the 
#' horizontal extent across the device and to the data range of that of the 
#' first object.
#'
#' @param x a list of one or more trellis class objects
valign_lattice <- function(x) {   
    
    if (inherits(x, "trellis")) x <- list(x)
    
    if (!all(sapply(x, inherits, 'trellis')))
        stop("all elements of x must inherit from trellis class")
    
    nx <- length(x)
    names(x) <- LETTERS[1:nx]
    h1 <- 1/nx
    y0 <- seq(from = 0, to = 1 - h1, length = nx)
    n <- 1
    grid.newpage()
    pushViewport(viewport(y=y0[n], height=h1, just="bottom"))
    # Force identical widths where we can
    layout.widths <- lattice.options("layout.widths")[[1]]
    layout.widths$ylab <- list(x=1, units="cm", data=NULL)
    layout.widths$panel <- list(x=1, units="null", data=NULL)
    layout.widths$key.right <- list(x=1, units="cm", data=NULL)
    lattice.options(layout.widths=layout.widths)
    # Force (width of) left axis labels to be the same
    prefix <- LETTERS[n]
    print(x[[n]], newpage=FALSE, prefix=prefix)
    downViewport(paste0(prefix,".panel.1.1.off.vp"))
    # Determine width of levelplot panel
    border <- grid.get("border", grep=TRUE)
    width <- convertWidth(border$width, "in", valueOnly=TRUE)
    xscale <- current.viewport()$xscale
    upViewport(0)
    
    if (nx > 1){
        for (n in 2:nx){
            pushViewport(viewport(y=y0[n], height=h1, just="bottom"))
            # Force identical widths where we can
            layout.widths$ylab <- list(x=1, units="cm", data=NULL)
            layout.widths$panel <- list(x=width, units="in", data=NULL)
            layout.widths$key.right <- list(x=1, units="cm", data=NULL)
            lattice.options(layout.widths=layout.widths)
            x[[n]] <- update(x[[n]], xlim = xscale)
            prefix <- LETTERS[n]                            
            print(x[[n]], newpage=FALSE, prefix=prefix)
            downViewport(paste0(prefix,".panel.1.1.off.vp"))
            upViewport(0)
        } #n-loop
    }
}

d <- dim(volcano)
xy <- data.frame(
    x = 1:d[1], 
    y1 = volcano[,30], 
    y2 = sqrt(volcano[,7]))

bottom <- levelplot(volcano, 
    main = 'boom', 
    ylab = 'foo', 
    xlab = 'bar',
    aspect = 0.5)
middle <- xyplot(y1 ~ x, data = xy,
    main = 'bam',
    xlab = '',
    ylab = 'elevation')
top <- xyplot(y2 ~ x, data = xy,
    main = 'bing',
    ylab = 'squished',
    xlab = '')
    
# just two
x <- list(bottom, top)
valign_lattice(x)    

bottom <- update(bottom, aspect = 0.2)
# three
x <- list(bottom, middle, top)          
valign_lattice(x)                                                                                                                                      
#### END



> On Oct 25, 2016, at 8:07 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
> 
> Hi
> 
> This might work, though it's a teensy bit more complicated and a bit manual (on the left axis labels) and it ignores heights and vertical whitespace ...
> 
> library(lattice)
> d <- dim(volcano)
> xy <- data.frame(x = 1:d[1], y = volcano[,30] )
> library(grid)
> grid.newpage()
> pushViewport(viewport(y=0, height=.5, just="bottom"))
> # Force identical widths where we can
> layout.widths <- lattice.options("layout.widths")[[1]]
> layout.widths$ylab <- list(x=1, units="cm", data=NULL)
> layout.widths$panel <- list(x=1, units="null", data=NULL)
> layout.widths$key.right <- list(x=1, units="cm", data=NULL)
> lattice.options(layout.widths=layout.widths)
> # Force (width of) left axis labels to be the same
> vol_p <- levelplot(volcano, scales=list(y=list(at=seq(10, 60, 10),
>                                               labels=rep(" ", 6))))
> print(vol_p, newpage=FALSE, prefix="vol_p")
> downViewport("vol_p.panel.1.1.off.vp")
> # Draw proper left axis labels
> grid.text(seq(10, 60, 10), x=unit(0, "npc") - unit(1, "lines"),
>          y=unit(seq(10, 60, 10), "native"), just="right",
>          gp=gpar(cex=.8))
> # Determine width of levelplot panel
> border <- grid.get("border", grep=TRUE)
> width <- convertWidth(border$width, "in", valueOnly=TRUE)
> xscale <- current.viewport()$xscale
> upViewport(0)
> pushViewport(viewport(y=.5, height=.5, just="bottom"))
> # Force identical widths where we can
> layout.widths$ylab <- list(x=1, units="cm", data=NULL)
> layout.widths$panel <- list(x=width, units="in", data=NULL)
> layout.widths$key.right <- list(x=1, units="cm", data=NULL)
> lattice.options(layout.widths=layout.widths)
> # Force (width of) left axis labels to be the same
> xy_p <- xyplot(y ~ x, data = xy, xlim=xscale,
>               scales=list(y=list(at=seq(100, 200, 20),
>                                  labels=rep(" ", 11))))
> print(xy_p, newpage=FALSE, prefix="xy_p")
> downViewport("xy_p.panel.1.1.off.vp")
> # Draw proper left axis labels
> grid.text(seq(100, 200, 20), x=unit(0, "npc") - unit(1, "lines"),
>          y=unit(seq(100, 200, 20), "native"), just="right",
>          gp=gpar(cex=.8))
> upViewport(0)
> 
> Paul
> 
> On 26/10/16 10:50, Ben Tupper wrote:
>> Hi,
>> 
>> Almost but not quite.  It certainly moves the ball down the field, and, dang, that would be way too easy!
>> 
>> I have been fiddling with the panel.widths to the lattice::plot method.  No joy yet.
>> 
>> 
>> Ben
>> 
>> 
>>> On Oct 25, 2016, at 5:14 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
>>> 
>>> Hi
>>> 
>>> Does this do what you want ?
>>> 
>>> library(latticeExtra)
>>> c(vol_p, xy_p, x.same=TRUE)
>>> 
>>> Paul
>>> 
>>> On 26/10/16 04:30, Ben Tupper wrote:
>>>> Thanks, Bert.
>>>> 
>>>> I have used latticeExtra for layering graphics.  I'm not sure how I
>>>> would use it to align graphics rather superimposing them.
>>>> 
>>>> I shall look into the the custom panel plot but that is very new
>>>> territory for me.
>>>> 
>>>> Ben
>>>> 
>>>>> On Oct 25, 2016, at 9:13 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>> wrote:
>>>>> 
>>>>> Write a custom panel function for levelplot() that calls
>>>>> panel.xyplot after panel.levelplot. I believe this can also be done
>>>>> by the +  operator of the latticeExtra package.
>>>>> 
>>>>> You do *not* want to call xyplot after levelplot, as that
>>>>> completely redraws the plot.
>>>>> 
>>>>> Cheers, Bert
>>>>> 
>>>>> 
>>>>> On Oct 25, 2016 2:55 PM, "Ben Tupper" <btupper at bigelow.org
>>>>> <mailto:btupper at bigelow.org>> wrote: Hello,
>>>>> 
>>>>> I am drawing a levelplot and an xyplot on a single device as shown
>>>>> in the runnable example below.  I would like the x axes to align -
>>>>> that is for them to cover the same extent left-to-right on the
>>>>> device. How do I go about doing that?
>>>>> 
>>>>> ####### # START ####### library(lattice)
>>>>> 
>>>>> d <- dim(volcano) xy <- data.frame(x = 1:d[1], y = volcano[,30] )
>>>>> 
>>>>> vol_p <- levelplot(volcano) xy_p <- xyplot(y ~ x, data = xy)
>>>>> 
>>>>> print(vol_p, split = c(1, 2, 1, 2), more = TRUE) print(xy_p,  split
>>>>> = c(1, 1, 1, 2), more = FALSE) ###### #END ######
>>>>> 
>>>>> 
>>>>> Thanks! Ben
>>>>> 
>>>>> 
>>>>>> sessionInfo()
>>>>> R version 3.3.1 (2016-06-21) Platform: x86_64-apple-darwin13.4.0
>>>>> (64-bit) Running under: OS X 10.11.6 (El Capitan)
>>>>> 
>>>>> locale: [1]
>>>>> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>> 
>>>>> attached base packages: [1] stats     graphics  grDevices utils
>>>>> datasets  methods   base
>>>>> 
>>>>> other attached packages: [1] lattice_0.20-33
>>>>> 
>>>>> loaded via a namespace (and not attached): [1] tools_3.3.1
>>>>> grid_3.3.1
>>>>> 
>>>>> 
>>>>> 
>>>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
>>>>> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>>>>> <http://www.bigelow.org/>
>>>>> 
>>>>> ______________________________________________ R-help at r-project.org
>>>>> <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and
>>>>> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do read the
>>>>> posting guide http://www.R-project.org/posting-guide.html
>>>>> <http://www.r-project.org/posting-guide.html> and provide
>>>>> commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
>>>> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>>>> 
>>>> 
>>>> 
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________ R-help at r-project.org
>>>> mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>>>> posting guide http://www.R-project.org/posting-guide.html and provide
>>>> commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> --
>>> Dr Paul Murrell
>>> Department of Statistics
>>> The University of Auckland
>>> Private Bag 92019
>>> Auckland
>>> New Zealand
>>> 64 9 3737599 x85392
>>> paul at stat.auckland.ac.nz
>>> http://www.stat.auckland.ac.nz/~paul/
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>> 
>> 
>> 
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From Anusha.Indhira at controlsdata.com  Wed Oct 26 11:46:21 2016
From: Anusha.Indhira at controlsdata.com (Indhira, Anusha)
Date: Wed, 26 Oct 2016 09:46:21 +0000
Subject: [R] interpretation of plot.svm graph
Message-ID: <CE1899A9C6A8D64099DFB344ECF0F7548A7F@DERCORCEXH02.ds-s.com>

Hi,

I am trying to understand graph generated by plot.svm command. when I use
model.svm <- svm(target.538 ~.,data = svm.data,type = "C-classification")
plot(model.svm,svm.data,T~P,xlab="",ylab = "")
I get attached graph.Can anyone let me know what red,bkack,green circle and cross points represent? Also why are not 1-1 class represented in the graph?

Thanks,
Alily
This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.

From julia.lienert at googlemail.com  Wed Oct 26 14:20:40 2016
From: julia.lienert at googlemail.com (Julia Lienert)
Date: Wed, 26 Oct 2016 14:20:40 +0200
Subject: [R] PROBLEM: correspondence analysis with vegan
Message-ID: <E2E487C8-8358-4188-9F77-1BBEFFAC7DB4@googlemail.com>

Hello All,

I?m Julia from Germany and I have a problem concerning the vegan package that I can?t solve on my own (after hours and hours spent searching for a solution). I was thrown into the topic of working with R by my professor and wasn?t really aware that this included working with higher statistics (since I studied pedagogy before and have not much basic statistical knowledge or knowledge of R).

I need to do a correspondence analysis on a dataset of vegetation samples and species as a comma-separated csv file. I have the species names as row names. The column names indicated zonation + land use and make up the first row of the matrix. I set the header = TRUE. 

If I tried doing a CA or DCA with this dataset the warning ?Error in rowSums(X): ?x? must be numeric? appeared. According to several forums, I then removed the first column and the CA worked and i could also apply the envfit function and plot it. 

Now here comes my problem and question:

when I plotted the arrows { plot(ef, p.max = 0.1) }, I got arrows labeled with species in my ordination plot. But instead I would need the column that indicates the zonation/land use (the first column) which I had to remove in order for the CA/ DCA to work. Is there any way that I can incorporate the zonation/ land use column as environmental vector after I did the whole CA/ DCA? Or is there any way for me to do a CA/ DCA without having to remove the first column?

I might be missing something but I just started working with R and haven?t got the time to really work my way in from the basics. I will do that after this project is done but for now I just hope that you can help me.

Greetings,
Julia


From dcarlson at tamu.edu  Wed Oct 26 20:05:07 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 26 Oct 2016 18:05:07 +0000
Subject: [R] PROBLEM: correspondence analysis with vegan
In-Reply-To: <E2E487C8-8358-4188-9F77-1BBEFFAC7DB4@googlemail.com>
References: <E2E487C8-8358-4188-9F77-1BBEFFAC7DB4@googlemail.com>
Message-ID: <efc59743a8144ed4b99f240c5920c886@exch-2p-mbx-w2.ads.tamu.edu>

The organization of your data is not clear from your description. You say you have species and samples and that the rows are the species, but the columns (which should be the samples) are "zonation + land use". I'm guessing that you mean the first column was zonation and land use and the remaining columns were samples? Your problem is not so much with R as with not knowing how to use the vegan package to do correspondence analysis. 

Fortunately, the vegan package comes with several documents describing how to use it called vignettes. You can see their names with the following command:

> vignette(package="vegan")

Then read the "intro-vegan" one:

> vignette("intro-vegan")

Also Jari Oksanen has a nice tutorial on his web page that you should read:

http://cc.oulu.fi/~jarioksa/opetus/metodi/vegantutor.pdf

I suspect you are trying to do constrained ordination, but I may be wrong since you did not show us any of your code. If so, you should also read the manual page for the cca() function and look at the examples.
 
> ?cca
> example("cca") # Will run them for you

Look at the examples carefully and display the data sets so that you know how they are organized using the str() function to study the structure of the data and View() to display it.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Julia Lienert via R-help
Sent: Wednesday, October 26, 2016 7:21 AM
To: r-help at stat.math.ethz.ch
Subject: [R] PROBLEM: correspondence analysis with vegan

Hello All,

I?m Julia from Germany and I have a problem concerning the vegan package that I can?t solve on my own (after hours and hours spent searching for a solution). I was thrown into the topic of working with R by my professor and wasn?t really aware that this included working with higher statistics (since I studied pedagogy before and have not much basic statistical knowledge or knowledge of R).

I need to do a correspondence analysis on a dataset of vegetation samples and species as a comma-separated csv file. I have the species names as row names. The column names indicated zonation + land use and make up the first row of the matrix. I set the header = TRUE. 

If I tried doing a CA or DCA with this dataset the warning ?Error in rowSums(X): ?x? must be numeric? appeared. According to several forums, I then removed the first column and the CA worked and i could also apply the envfit function and plot it. 

Now here comes my problem and question:

when I plotted the arrows { plot(ef, p.max = 0.1) }, I got arrows labeled with species in my ordination plot. But instead I would need the column that indicates the zonation/land use (the first column) which I had to remove in order for the CA/ DCA to work. Is there any way that I can incorporate the zonation/ land use column as environmental vector after I did the whole CA/ DCA? Or is there any way for me to do a CA/ DCA without having to remove the first column?

I might be missing something but I just started working with R and haven?t got the time to really work my way in from the basics. I will do that after this project is done but for now I just hope that you can help me.

Greetings,
Julia

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From paul at stat.auckland.ac.nz  Wed Oct 26 21:13:23 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Thu, 27 Oct 2016 08:13:23 +1300
Subject: [R] [FORGED] Re: [FORGED] lattice: control panel extent on
	device
In-Reply-To: <0FDDD7DE-A200-41CA-8A41-A9AFCE0B0785@bigelow.org>
References: <5241D8A5-B794-4C41-9BF1-04BA08B1AB8D@bigelow.org>
	<CAGxFJbTTE7jshhNEVizVPJD7Nngbs0a26q+CG5AmCf+wX3EoxA@mail.gmail.com>
	<CAGxFJbSs2oRCwd30jnp0ZKaCeFyjK-PvR_1QLoH3NxQPOhNoSw@mail.gmail.com>
	<CAGxFJbR1fd4pVeNkxd7mm5z7QwQmSd+M0QeeMuiz3wP9k0jbrQ@mail.gmail.com>
	<E9A9E28D-0264-4013-9CEA-9B4D25D27EAD@bigelow.org>
	<240b050e-d627-2f99-6384-500bf46f341a@stat.auckland.ac.nz>
	<03FB6E15-9ED0-49D0-9C79-265F14176D37@bigelow.org>
	<3e921eb1-0f0f-bbc4-119a-c3b54e1ae5c5@stat.auckland.ac.nz>
	<0FDDD7DE-A200-41CA-8A41-A9AFCE0B0785@bigelow.org>
Message-ID: <624402ca-9b4c-33ae-76ca-6d3a7f922721@stat.auckland.ac.nz>

Hi

I think your plots are not *quite* horizontally aligned (because of 
differences in the lengths of y-axis labels).  Here is a slight 
modification that messes with the labels (but at least not manually) to 
get things exact ...

valign_lattice <- function(x) {

     if (inherits(x, "trellis")) x <- list(x)

     if (!all(sapply(x, inherits, 'trellis')))
         stop("all elements of x must inherit from trellis class")

     nx <- length(x)
     names(x) <- LETTERS[1:nx]
     h1 <- 1/nx
     y0 <- seq(from = 0, to = 1 - h1, length = nx)
     n <- 1
     grid.newpage()
     pushViewport(viewport(y=y0[n], height=h1, just="bottom"))
     # Force identical widths where we can
     layout.widths <- lattice.options("layout.widths")[[1]]
     layout.widths$ylab <- list(x=1, units="cm", data=NULL)
     layout.widths$panel <- list(x=1, units="null", data=NULL)
     layout.widths$key.right <- list(x=1, units="cm", data=NULL)
     lattice.options(layout.widths=layout.widths)
     # Force (width of) left axis labels to be the same
     yrange <- x[[n]]$y.limits
     yticks <- axisTicks(yrange, FALSE)
     x[[n]] <- update(x[[n]],
                      scales=list(y=list(at=yticks,
                                         labels=rep(" ", length(yticks)))))
     prefix <- LETTERS[n]
     print(x[[n]], newpage=FALSE, prefix=prefix)
     downViewport(paste0(prefix,".panel.1.1.off.vp"))
     # Draw proper left axis labels
     grid.text(yticks, x=unit(0, "npc") - unit(1, "lines"),
               y=unit(yticks, "native"), just="right",
               gp=gpar(cex=.8))
     # Determine width of levelplot panel
     border <- grid.get("border", grep=TRUE)
     width <- convertWidth(border$width, "in", valueOnly=TRUE)
     xscale <- current.viewport()$xscale
     upViewport(0)

     if (nx > 1){
         for (n in 2:nx){
             pushViewport(viewport(y=y0[n], height=h1, just="bottom"))
             # Force identical widths where we can
             layout.widths$ylab <- list(x=1, units="cm", data=NULL)
             layout.widths$panel <- list(x=width, units="in", data=NULL)
             layout.widths$key.right <- list(x=1, units="cm", data=NULL)
             lattice.options(layout.widths=layout.widths)
             x[[n]] <- update(x[[n]], xlim = xscale)
             # Force (width of) left axis labels to be the same
             yrange <- x[[n]]$y.limits
             yticks <- axisTicks(yrange, FALSE)
             x[[n]] <- update(x[[n]],
                              scales=list(y=list(at=yticks,
                                                 labels=rep(" ",
 
length(yticks)))))
             prefix <- LETTERS[n]
             print(x[[n]], newpage=FALSE, prefix=prefix)
             downViewport(paste0(prefix,".panel.1.1.off.vp"))
             # Draw proper left axis labels
             grid.text(yticks, x=unit(0, "npc") - unit(1, "lines"),
                       y=unit(yticks, "native"), just="right",
                       gp=gpar(cex=.8))
             upViewport(0)
         } #n-loop
     }
}

Paul

On 27/10/16 04:21, Ben Tupper wrote:
> Hi,
>
> The following encapsulates what I hoped for using Paul's method.  The
> function accepts one or more trellis class objects and aligns them
> vertically.  I think I have automated most of the manual fiddling.
> Depending upon your graphics device you may need to fiddle with the
> aspect of the levelplot as I did below.  There remains a good deal of
> vertical white space but it is fine for my purposes as I only need
> two objects aligned where it looks OK.
>
> I couldn't get Richard's simplified steps to work - I'm still
> noodling that out but the simplicity is very enticing.
>
> Thanks again for the all the suggestions! Ben
>
> #### START library(lattice) library(grid)
>
> #' Vertically align one or more trellis class objects. #' #' Objects
> are plotted in order from bottom up and all are restricted to the #'
> horizontal extent across the device and to the data range of that of
> the #' first object. #' #' @param x a list of one or more trellis
> class objects valign_lattice <- function(x) {
>
> if (inherits(x, "trellis")) x <- list(x)
>
> if (!all(sapply(x, inherits, 'trellis'))) stop("all elements of x
> must inherit from trellis class")
>
> nx <- length(x) names(x) <- LETTERS[1:nx] h1 <- 1/nx y0 <- seq(from =
> 0, to = 1 - h1, length = nx) n <- 1 grid.newpage()
> pushViewport(viewport(y=y0[n], height=h1, just="bottom")) # Force
> identical widths where we can layout.widths <-
> lattice.options("layout.widths")[[1]] layout.widths$ylab <- list(x=1,
> units="cm", data=NULL) layout.widths$panel <- list(x=1, units="null",
> data=NULL) layout.widths$key.right <- list(x=1, units="cm",
> data=NULL) lattice.options(layout.widths=layout.widths) # Force
> (width of) left axis labels to be the same prefix <- LETTERS[n]
> print(x[[n]], newpage=FALSE, prefix=prefix)
> downViewport(paste0(prefix,".panel.1.1.off.vp")) # Determine width of
> levelplot panel border <- grid.get("border", grep=TRUE) width <-
> convertWidth(border$width, "in", valueOnly=TRUE) xscale <-
> current.viewport()$xscale upViewport(0)
>
> if (nx > 1){ for (n in 2:nx){ pushViewport(viewport(y=y0[n],
> height=h1, just="bottom")) # Force identical widths where we can
> layout.widths$ylab <- list(x=1, units="cm", data=NULL)
> layout.widths$panel <- list(x=width, units="in", data=NULL)
> layout.widths$key.right <- list(x=1, units="cm", data=NULL)
> lattice.options(layout.widths=layout.widths) x[[n]] <- update(x[[n]],
> xlim = xscale) prefix <- LETTERS[n] print(x[[n]], newpage=FALSE,
> prefix=prefix) downViewport(paste0(prefix,".panel.1.1.off.vp"))
> upViewport(0) } #n-loop } }
>
> d <- dim(volcano) xy <- data.frame( x = 1:d[1], y1 = volcano[,30], y2
> = sqrt(volcano[,7]))
>
> bottom <- levelplot(volcano, main = 'boom', ylab = 'foo', xlab =
> 'bar', aspect = 0.5) middle <- xyplot(y1 ~ x, data = xy, main =
> 'bam', xlab = '', ylab = 'elevation') top <- xyplot(y2 ~ x, data =
> xy, main = 'bing', ylab = 'squished', xlab = '')
>
> # just two x <- list(bottom, top) valign_lattice(x)
>
> bottom <- update(bottom, aspect = 0.2) # three x <- list(bottom,
> middle, top) valign_lattice(x)
>  #### END
>
>
>
>> On Oct 25, 2016, at 8:07 PM, Paul Murrell
>> <paul at stat.auckland.ac.nz> wrote:
>>
>> Hi
>>
>> This might work, though it's a teensy bit more complicated and a
>> bit manual (on the left axis labels) and it ignores heights and
>> vertical whitespace ...
>>
>> library(lattice) d <- dim(volcano) xy <- data.frame(x = 1:d[1], y =
>> volcano[,30] ) library(grid) grid.newpage()
>> pushViewport(viewport(y=0, height=.5, just="bottom")) # Force
>> identical widths where we can layout.widths <-
>> lattice.options("layout.widths")[[1]] layout.widths$ylab <-
>> list(x=1, units="cm", data=NULL) layout.widths$panel <- list(x=1,
>> units="null", data=NULL) layout.widths$key.right <- list(x=1,
>> units="cm", data=NULL)
>> lattice.options(layout.widths=layout.widths) # Force (width of)
>> left axis labels to be the same vol_p <- levelplot(volcano,
>> scales=list(y=list(at=seq(10, 60, 10), labels=rep(" ", 6))))
>> print(vol_p, newpage=FALSE, prefix="vol_p")
>> downViewport("vol_p.panel.1.1.off.vp") # Draw proper left axis
>> labels grid.text(seq(10, 60, 10), x=unit(0, "npc") - unit(1,
>> "lines"), y=unit(seq(10, 60, 10), "native"), just="right",
>> gp=gpar(cex=.8)) # Determine width of levelplot panel border <-
>> grid.get("border", grep=TRUE) width <- convertWidth(border$width,
>> "in", valueOnly=TRUE) xscale <- current.viewport()$xscale
>> upViewport(0) pushViewport(viewport(y=.5, height=.5,
>> just="bottom")) # Force identical widths where we can
>> layout.widths$ylab <- list(x=1, units="cm", data=NULL)
>> layout.widths$panel <- list(x=width, units="in", data=NULL)
>> layout.widths$key.right <- list(x=1, units="cm", data=NULL)
>> lattice.options(layout.widths=layout.widths) # Force (width of)
>> left axis labels to be the same xy_p <- xyplot(y ~ x, data = xy,
>> xlim=xscale, scales=list(y=list(at=seq(100, 200, 20), labels=rep("
>> ", 11)))) print(xy_p, newpage=FALSE, prefix="xy_p")
>> downViewport("xy_p.panel.1.1.off.vp") # Draw proper left axis
>> labels grid.text(seq(100, 200, 20), x=unit(0, "npc") - unit(1,
>> "lines"), y=unit(seq(100, 200, 20), "native"), just="right",
>> gp=gpar(cex=.8)) upViewport(0)
>>
>> Paul
>>
>> On 26/10/16 10:50, Ben Tupper wrote:
>>> Hi,
>>>
>>> Almost but not quite.  It certainly moves the ball down the
>>> field, and, dang, that would be way too easy!
>>>
>>> I have been fiddling with the panel.widths to the lattice::plot
>>> method.  No joy yet.
>>>
>>>
>>> Ben
>>>
>>>
>>>> On Oct 25, 2016, at 5:14 PM, Paul Murrell
>>>> <paul at stat.auckland.ac.nz> wrote:
>>>>
>>>> Hi
>>>>
>>>> Does this do what you want ?
>>>>
>>>> library(latticeExtra) c(vol_p, xy_p, x.same=TRUE)
>>>>
>>>> Paul
>>>>
>>>> On 26/10/16 04:30, Ben Tupper wrote:
>>>>> Thanks, Bert.
>>>>>
>>>>> I have used latticeExtra for layering graphics.  I'm not sure
>>>>> how I would use it to align graphics rather superimposing
>>>>> them.
>>>>>
>>>>> I shall look into the the custom panel plot but that is very
>>>>> new territory for me.
>>>>>
>>>>> Ben
>>>>>
>>>>>> On Oct 25, 2016, at 9:13 AM, Bert Gunter
>>>>>> <bgunter.4567 at gmail.com> wrote:
>>>>>>
>>>>>> Write a custom panel function for levelplot() that calls
>>>>>> panel.xyplot after panel.levelplot. I believe this can also
>>>>>> be done by the +  operator of the latticeExtra package.
>>>>>>
>>>>>> You do *not* want to call xyplot after levelplot, as that
>>>>>> completely redraws the plot.
>>>>>>
>>>>>> Cheers, Bert
>>>>>>
>>>>>>
>>>>>> On Oct 25, 2016 2:55 PM, "Ben Tupper" <btupper at bigelow.org
>>>>>> <mailto:btupper at bigelow.org>> wrote: Hello,
>>>>>>
>>>>>> I am drawing a levelplot and an xyplot on a single device
>>>>>> as shown in the runnable example below.  I would like the x
>>>>>> axes to align - that is for them to cover the same extent
>>>>>> left-to-right on the device. How do I go about doing that?
>>>>>>
>>>>>> ####### # START ####### library(lattice)
>>>>>>
>>>>>> d <- dim(volcano) xy <- data.frame(x = 1:d[1], y =
>>>>>> volcano[,30] )
>>>>>>
>>>>>> vol_p <- levelplot(volcano) xy_p <- xyplot(y ~ x, data =
>>>>>> xy)
>>>>>>
>>>>>> print(vol_p, split = c(1, 2, 1, 2), more = TRUE)
>>>>>> print(xy_p,  split = c(1, 1, 1, 2), more = FALSE) ######
>>>>>> #END ######
>>>>>>
>>>>>>
>>>>>> Thanks! Ben
>>>>>>
>>>>>>
>>>>>>> sessionInfo()
>>>>>> R version 3.3.1 (2016-06-21) Platform:
>>>>>> x86_64-apple-darwin13.4.0 (64-bit) Running under: OS X
>>>>>> 10.11.6 (El Capitan)
>>>>>>
>>>>>> locale: [1]
>>>>>> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>>>
>>>>>>
>>>>>>
attached base packages: [1] stats     graphics  grDevices utils
>>>>>> datasets  methods   base
>>>>>>
>>>>>> other attached packages: [1] lattice_0.20-33
>>>>>>
>>>>>> loaded via a namespace (and not attached): [1] tools_3.3.1
>>>>>> grid_3.3.1
>>>>>>
>>>>>>
>>>>>>
>>>>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow
>>>>>> Drive, P.O. Box 380 East Boothbay, Maine 04544
>>>>>> http://www.bigelow.org <http://www.bigelow.org/>
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>>>>> list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do
>>>>>> read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> <http://www.r-project.org/posting-guide.html> and provide
>>>>>> commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow
>>>>> Drive, P.O. Box 380 East Boothbay, Maine 04544
>>>>> http://www.bigelow.org
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>>>>> read the posting guide
>>>>> http://www.R-project.org/posting-guide.html and provide
>>>>> commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>> -- Dr Paul Murrell Department of Statistics The University of
>>>> Auckland Private Bag 92019 Auckland New Zealand 64 9 3737599
>>>> x85392 paul at stat.auckland.ac.nz
>>>> http://www.stat.auckland.ac.nz/~paul/
>>>
>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow
>>> Drive, P.O. Box 380 East Boothbay, Maine 04544
>>> http://www.bigelow.org
>>>
>>>
>>>
>>
>> -- Dr Paul Murrell Department of Statistics The University of
>> Auckland Private Bag 92019 Auckland New Zealand 64 9 3737599
>> x85392 paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>
> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From bgunter.4567 at gmail.com  Wed Oct 26 23:15:28 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 26 Oct 2016 14:15:28 -0700
Subject: [R] PROBLEM: correspondence analysis with vegan
In-Reply-To: <E2E487C8-8358-4188-9F77-1BBEFFAC7DB4@googlemail.com>
References: <E2E487C8-8358-4188-9F77-1BBEFFAC7DB4@googlemail.com>
Message-ID: <CAGxFJbRc=Hji30tdQc-_7Hc9Jcf-ApY7J5yw5Hj9yYadnBJEvg@mail.gmail.com>

Julia:

1. I appreciate your honesty.

2. What follows is just my opinion. Feel free to ignore.

3. I think you are in a near impossible situation. R is a computer language
for statistics and data analysis:  you need to know both the language and
statistics to use it properly. You know neither.  So from my perspective,
there is a mismatch between your education background and what your
professor seems to expect you to know.

4. There are many good R tutorials on the web, so it shouldn't take more
than a few weeks (or days) to get up and running with R, especially if you
have  prior programming experience.

5. However, the statistics is a different matter.  By your own admission,
your statistical background is minimal; but you are being asked to use a
fairly advanced procedure (corr analysis -- whose utility and validity can
be tricky, by the way).  I do not see how you can proceed without several
semesters of the necessary statistical background -- and that assumes you
have sufficient mathematical training to take those courses!

6. So I would suggest that you sit down with your professor to discuss what
he thinks you know and what you actually know, and what course of action
you need to take to resolve any discrepancy (perhaps even a different
professor).

7. If it makes you feel any better, you are far from alone in this regard.
Many students and their professors in a variety of disciplines are misusing
statistics because of inadequate statistical understanding. That is one
reason why we have a so-called "irreproducibility" crisis in Science.

8. Again, just my fallible opinion.

Good luck!

Bert

On Oct 26, 2016 7:21 PM, "Julia Lienert via R-help" <r-help at r-project.org>
wrote:
>
> Hello All,
>
> I?m Julia from Germany and I have a problem concerning the vegan package
that I can?t solve on my own (after hours and hours spent searching for a
solution). I was thrown into the topic of working with R by my professor
and wasn?t really aware that this included working with higher statistics
(since I studied pedagogy before and have not much basic statistical
knowledge or knowledge of R).
>
> I need to do a correspondence analysis on a dataset of vegetation samples
and species as a comma-separated csv file. I have the species names as row
names. The column names indicated zonation + land use and make up the first
row of the matrix. I set the header = TRUE.
>
> If I tried doing a CA or DCA with this dataset the warning ?Error in
rowSums(X): ?x? must be numeric? appeared. According to several forums, I
then removed the first column and the CA worked and i could also apply the
envfit function and plot it.
>
> Now here comes my problem and question:
>
> when I plotted the arrows { plot(ef, p.max = 0.1) }, I got arrows labeled
with species in my ordination plot. But instead I would need the column
that indicates the zonation/land use (the first column) which I had to
remove in order for the CA/ DCA to work. Is there any way that I can
incorporate the zonation/ land use column as environmental vector after I
did the whole CA/ DCA? Or is there any way for me to do a CA/ DCA without
having to remove the first column?
>
> I might be missing something but I just started working with R and
haven?t got the time to really work my way in from the basics. I will do
that after this project is done but for now I just hope that you can help
me.
>
> Greetings,
> Julia
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Oct 27 00:32:43 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 27 Oct 2016 09:32:43 +1100
Subject: [R] PROBLEM: correspondence analysis with vegan
In-Reply-To: <E2E487C8-8358-4188-9F77-1BBEFFAC7DB4@googlemail.com>
References: <E2E487C8-8358-4188-9F77-1BBEFFAC7DB4@googlemail.com>
Message-ID: <CA+8X3fXt3b5+Tp5ahV-kKfWkAyiNi0bdjV7Y4JbtsQryneVuwA@mail.gmail.com>

Hi Julia,
The error you got is usually due to data that should be numeric (1, 2,
3, ...) actually being a factor data type. This often happens when R
reads in a CSV file with the default option of converting character
variables (A, B, C,...) to factors. So your first column after input
may be a factor. Say your data frame (what you get after reading in
the CSV file) is named "mydf". Try this:

is.factor(mydf[,1])

If that is TRUE, you have identified the problem with the error
message.I don't have the vegan package installed here at work, but if
there is an argument that specifies the labels for the arrows (this
may be "display="), you may be able to pass the first column of your
data frame to that argument and pass:

mydf[,-1] as the "data" argument. This is very much a guess, but might
help you to understand what is happening in the process. Also look at
the stringsAsFactors= argument in the read.csv function.

Jim

On Wed, Oct 26, 2016 at 11:20 PM, Julia Lienert via R-help
<r-help at r-project.org> wrote:
> Hello All,
>
> I?m Julia from Germany and I have a problem concerning the vegan package that I can?t solve on my own (after hours and hours spent searching for a solution). I was thrown into the topic of working with R by my professor and wasn?t really aware that this included working with higher statistics (since I studied pedagogy before and have not much basic statistical knowledge or knowledge of R).
>
> I need to do a correspondence analysis on a dataset of vegetation samples and species as a comma-separated csv file. I have the species names as row names. The column names indicated zonation + land use and make up the first row of the matrix. I set the header = TRUE.
>
> If I tried doing a CA or DCA with this dataset the warning ?Error in rowSums(X): ?x? must be numeric? appeared. According to several forums, I then removed the first column and the CA worked and i could also apply the envfit function and plot it.
>
> Now here comes my problem and question:
>
> when I plotted the arrows { plot(ef, p.max = 0.1) }, I got arrows labeled with species in my ordination plot. But instead I would need the column that indicates the zonation/land use (the first column) which I had to remove in order for the CA/ DCA to work. Is there any way that I can incorporate the zonation/ land use column as environmental vector after I did the whole CA/ DCA? Or is there any way for me to do a CA/ DCA without having to remove the first column?
>
> I might be missing something but I just started working with R and haven?t got the time to really work my way in from the basics. I will do that after this project is done but for now I just hope that you can help me.
>
> Greetings,
> Julia
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Oct 27 00:37:07 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 27 Oct 2016 09:37:07 +1100
Subject: [R] interpretation of plot.svm graph
In-Reply-To: <CE1899A9C6A8D64099DFB344ECF0F7548A7F@DERCORCEXH02.ds-s.com>
References: <CE1899A9C6A8D64099DFB344ECF0F7548A7F@DERCORCEXH02.ds-s.com>
Message-ID: <CA+8X3fUB+xLbeOYfL1vA_PR3Uexrw4SZYdju2i0mnazj4HBbdA@mail.gmail.com>

Hi Alily,
Your image file didn't get through to the list. Try sending a PDF
image or perhaps providing a URL for an image stored on the internet.

Jim


On Wed, Oct 26, 2016 at 8:46 PM, Indhira, Anusha
<Anusha.Indhira at controlsdata.com> wrote:
> Hi,
>
> I am trying to understand graph generated by plot.svm command. when I use
> model.svm <- svm(target.538 ~.,data = svm.data,type = "C-classification")
> plot(model.svm,svm.data,T~P,xlab="",ylab = "")
> I get attached graph.Can anyone let me know what red,bkack,green circle and cross points represent? Also why are not 1-1 class represented in the graph?
>
> Thanks,
> Alily
> This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Oct 27 09:53:11 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 27 Oct 2016 07:53:11 +0000
Subject: [R] PROBLEM: correspondence analysis with vegan
In-Reply-To: <E2E487C8-8358-4188-9F77-1BBEFFAC7DB4@googlemail.com>
References: <E2E487C8-8358-4188-9F77-1BBEFFAC7DB4@googlemail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C504433C@SRVEXCHMBX.precheza.cz>

Hi Julia

Do not be too much distracted by Bert's comments. I also do not have formal statistical background but R usually keeps me on track as clever people designed its functions and made big effort in providing concise help. Together with this help list it can give you pretty good base for your analysis. However you should not expect to reach mastery overnight.

Beside what have been said, your questions to this help list should include:

- some toy data, preferably obtained by

dput(head(yourdata, 20))

result copied directly to your mail.

- the code you used for your analysis
- some description what you expected and did not obtained

However I agree with Bert that I you do not have any idea how to interpret results from analysis, you are asking for trouble.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Julia
> Lienert via R-help
> Sent: Wednesday, October 26, 2016 2:21 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] PROBLEM: correspondence analysis with vegan
>
> Hello All,
>
> I?m Julia from Germany and I have a problem concerning the vegan package
> that I can?t solve on my own (after hours and hours spent searching for a
> solution). I was thrown into the topic of working with R by my professor and
> wasn?t really aware that this included working with higher statistics (since I
> studied pedagogy before and have not much basic statistical knowledge or
> knowledge of R).
>
> I need to do a correspondence analysis on a dataset of vegetation samples
> and species as a comma-separated csv file. I have the species names as row
> names. The column names indicated zonation + land use and make up the
> first row of the matrix. I set the header = TRUE.
>
> If I tried doing a CA or DCA with this dataset the warning ?Error in
> rowSums(X): ?x? must be numeric? appeared. According to several forums, I
> then removed the first column and the CA worked and i could also apply the
> envfit function and plot it.
>
> Now here comes my problem and question:
>
> when I plotted the arrows { plot(ef, p.max = 0.1) }, I got arrows labeled with
> species in my ordination plot. But instead I would need the column that
> indicates the zonation/land use (the first column) which I had to remove in
> order for the CA/ DCA to work. Is there any way that I can incorporate the
> zonation/ land use column as environmental vector after I did the whole CA/
> DCA? Or is there any way for me to do a CA/ DCA without having to remove
> the first column?
>
> I might be missing something but I just started working with R and haven?t
> got the time to really work my way in from the basics. I will do that after this
> project is done but for now I just hope that you can help me.
>
> Greetings,
> Julia
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Anusha.Indhira at controlsdata.com  Thu Oct 27 12:42:19 2016
From: Anusha.Indhira at controlsdata.com (Indhira, Anusha)
Date: Thu, 27 Oct 2016 10:42:19 +0000
Subject: [R] interpretation of plot.svm graph
In-Reply-To: <CA+8X3fUB+xLbeOYfL1vA_PR3Uexrw4SZYdju2i0mnazj4HBbdA@mail.gmail.com>
References: <CE1899A9C6A8D64099DFB344ECF0F7548A7F@DERCORCEXH02.ds-s.com>
	<CA+8X3fUB+xLbeOYfL1vA_PR3Uexrw4SZYdju2i0mnazj4HBbdA@mail.gmail.com>
Message-ID: <CE1899A9C6A8D64099DFB344ECF0F7548D41@DERCORCEXH02.ds-s.com>

 Thanks for letting me know.Please find the image file in below link
https://github.com/anushar/bleed-analysis/blob/master/svm_classification_plot.jpeg

Thanks
-----Original Message-----
From: Jim Lemon [mailto:drjimlemon at gmail.com]
Sent: 26 October 2016 23:37
To: Indhira, Anusha
Cc: r-help at r-project.org
Subject: Re: [R] interpretation of plot.svm graph

Hi Alily,
Your image file didn't get through to the list. Try sending a PDF image or perhaps providing a URL for an image stored on the internet.

Jim


On Wed, Oct 26, 2016 at 8:46 PM, Indhira, Anusha <Anusha.Indhira at controlsdata.com> wrote:
> Hi,
>
> I am trying to understand graph generated by plot.svm command. when I
> use model.svm <- svm(target.538 ~.,data = svm.data,type =
> "C-classification") plot(model.svm,svm.data,T~P,xlab="",ylab = "") I
> get attached graph.Can anyone let me know what red,bkack,green circle and cross points represent? Also why are not 1-1 class represented in the graph?
>
> Thanks,
> Alily
> This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________________________________
This email has been scanned.
This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.

From jimmaasuk at gmail.com  Thu Oct 27 13:42:59 2016
From: jimmaasuk at gmail.com (Jim Maas)
Date: Thu, 27 Oct 2016 12:42:59 +0100
Subject: [R] age old problem with rJava
Message-ID: <CAGQ6_y-htUhGf6MB4Dk=LhtZbSKCJitf5+_cfZc3FWJ5JQVvLA@mail.gmail.com>

I've installed oracle java 8, at least think I have and tried many things
but still getting this error.  For some reason if I run R as sudo, then the
library rJava loads just fine, but not as user.  Any suggestions most
welcome.

Ubuntu 16.04 linux, R 3.3.1 64-bit

Thanks

J


> library(rJava)
Error : .onLoad failed in loadNamespace() for 'rJava', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object
'/usr/local/lib/R/site-library/rJava/libs/rJava.so':
  libjvm.so: cannot open shared object file: No such file or directory
Error: package or namespace load failed for ?rJava?


-- 
Jim Maas

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Oct 27 14:31:10 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 27 Oct 2016 07:31:10 -0500
Subject: [R] age old problem with rJava
In-Reply-To: <CAGQ6_y-htUhGf6MB4Dk=LhtZbSKCJitf5+_cfZc3FWJ5JQVvLA@mail.gmail.com>
References: <CAGQ6_y-htUhGf6MB4Dk=LhtZbSKCJitf5+_cfZc3FWJ5JQVvLA@mail.gmail.com>
Message-ID: <04A707A2-35C4-421F-A63A-4A55ABE70902@dcn.davis.ca.us>

The very act of using sudo for this kind of activity creates files that you can only access by using sudo (bad permissions), thereby perpetuating your difficulties. You should be able to limit yourself to only using sudo for installing OS packages (apt-get) which is designed to yield appropriate file permissions for normal use. 

Resolving such gordian knots in the operating system is off topic here, but I would recommend uninstalling R and your ~/R directory and the java runtime and then using the Ubuntu-specific instructions for setting up R that are posted on CRAN and avoid running R with sudo. Only use sudo with apt-get and use a local user-specific R library (~/R) so you don't have to use sudo to install R packages. If you need a system-wide installation then you need to get help in a more OS-specific forum... perhaps R-sig-debian.
-- 
Sent from my phone. Please excuse my brevity.

On October 27, 2016 6:42:59 AM CDT, Jim Maas <jimmaasuk at gmail.com> wrote:
>I've installed oracle java 8, at least think I have and tried many
>things
>but still getting this error.  For some reason if I run R as sudo, then
>the
>library rJava loads just fine, but not as user.  Any suggestions most
>welcome.
>
>Ubuntu 16.04 linux, R 3.3.1 64-bit
>
>Thanks
>
>J
>
>
>> library(rJava)
>Error : .onLoad failed in loadNamespace() for 'rJava', details:
>  call: dyn.load(file, DLLpath = DLLpath, ...)
>  error: unable to load shared object
>'/usr/local/lib/R/site-library/rJava/libs/rJava.so':
>  libjvm.so: cannot open shared object file: No such file or directory
>Error: package or namespace load failed for ?rJava?
>
>
>-- 
>Jim Maas
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From btupper at bigelow.org  Thu Oct 27 15:01:28 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Thu, 27 Oct 2016 09:01:28 -0400
Subject: [R] [FORGED]  [FORGED] lattice: control panel extent on device
In-Reply-To: <624402ca-9b4c-33ae-76ca-6d3a7f922721@stat.auckland.ac.nz>
References: <5241D8A5-B794-4C41-9BF1-04BA08B1AB8D@bigelow.org>
	<CAGxFJbTTE7jshhNEVizVPJD7Nngbs0a26q+CG5AmCf+wX3EoxA@mail.gmail.com>
	<CAGxFJbSs2oRCwd30jnp0ZKaCeFyjK-PvR_1QLoH3NxQPOhNoSw@mail.gmail.com>
	<CAGxFJbR1fd4pVeNkxd7mm5z7QwQmSd+M0QeeMuiz3wP9k0jbrQ@mail.gmail.com>
	<E9A9E28D-0264-4013-9CEA-9B4D25D27EAD@bigelow.org>
	<240b050e-d627-2f99-6384-500bf46f341a@stat.auckland.ac.nz>
	<03FB6E15-9ED0-49D0-9C79-265F14176D37@bigelow.org>
	<3e921eb1-0f0f-bbc4-119a-c3b54e1ae5c5@stat.auckland.ac.nz>
	<0FDDD7DE-A200-41CA-8A41-A9AFCE0B0785@bigelow.org>
	<624402ca-9b4c-33ae-76ca-6d3a7f922721@stat.auckland.ac.nz>
Message-ID: <CB002D36-1927-43A2-9173-02B6319E75B6@bigelow.org>

Hi,

I had not noticed the difference, but now that I can see them side-by-side it's obvious.  I see that I shouldn't have taken out those modifications you had originally set up.  They were sort of like extra those extra parts you find after assembling a new gizmo - "Nah, I don't need those things."  Oops!

I just realized that I was calling the alignment vertical (because the plots are over-under), but you referred to the alignment as horizontal which sounds 'righter'.  I should challenge myself to do the same for vertical alignment for side-by-side plots.  If I get to it I'll post the results.

Thanks, again, for your time and help.

Cheers,
Ben


> On Oct 26, 2016, at 3:13 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
> 
> Hi
> 
> I think your plots are not *quite* horizontally aligned (because of differences in the lengths of y-axis labels).  Here is a slight modification that messes with the labels (but at least not manually) to get things exact ...
> 
> valign_lattice <- function(x) {
> 
>    if (inherits(x, "trellis")) x <- list(x)
> 
>    if (!all(sapply(x, inherits, 'trellis')))
>        stop("all elements of x must inherit from trellis class")
> 
>    nx <- length(x)
>    names(x) <- LETTERS[1:nx]
>    h1 <- 1/nx
>    y0 <- seq(from = 0, to = 1 - h1, length = nx)
>    n <- 1
>    grid.newpage()
>    pushViewport(viewport(y=y0[n], height=h1, just="bottom"))
>    # Force identical widths where we can
>    layout.widths <- lattice.options("layout.widths")[[1]]
>    layout.widths$ylab <- list(x=1, units="cm", data=NULL)
>    layout.widths$panel <- list(x=1, units="null", data=NULL)
>    layout.widths$key.right <- list(x=1, units="cm", data=NULL)
>    lattice.options(layout.widths=layout.widths)
>    # Force (width of) left axis labels to be the same
>    yrange <- x[[n]]$y.limits
>    yticks <- axisTicks(yrange, FALSE)
>    x[[n]] <- update(x[[n]],
>                     scales=list(y=list(at=yticks,
>                                        labels=rep(" ", length(yticks)))))
>    prefix <- LETTERS[n]
>    print(x[[n]], newpage=FALSE, prefix=prefix)
>    downViewport(paste0(prefix,".panel.1.1.off.vp"))
>    # Draw proper left axis labels
>    grid.text(yticks, x=unit(0, "npc") - unit(1, "lines"),
>              y=unit(yticks, "native"), just="right",
>              gp=gpar(cex=.8))
>    # Determine width of levelplot panel
>    border <- grid.get("border", grep=TRUE)
>    width <- convertWidth(border$width, "in", valueOnly=TRUE)
>    xscale <- current.viewport()$xscale
>    upViewport(0)
> 
>    if (nx > 1){
>        for (n in 2:nx){
>            pushViewport(viewport(y=y0[n], height=h1, just="bottom"))
>            # Force identical widths where we can
>            layout.widths$ylab <- list(x=1, units="cm", data=NULL)
>            layout.widths$panel <- list(x=width, units="in", data=NULL)
>            layout.widths$key.right <- list(x=1, units="cm", data=NULL)
>            lattice.options(layout.widths=layout.widths)
>            x[[n]] <- update(x[[n]], xlim = xscale)
>            # Force (width of) left axis labels to be the same
>            yrange <- x[[n]]$y.limits
>            yticks <- axisTicks(yrange, FALSE)
>            x[[n]] <- update(x[[n]],
>                             scales=list(y=list(at=yticks,
>                                                labels=rep(" ",
> length(yticks)))))
>            prefix <- LETTERS[n]
>            print(x[[n]], newpage=FALSE, prefix=prefix)
>            downViewport(paste0(prefix,".panel.1.1.off.vp"))
>            # Draw proper left axis labels
>            grid.text(yticks, x=unit(0, "npc") - unit(1, "lines"),
>                      y=unit(yticks, "native"), just="right",
>                      gp=gpar(cex=.8))
>            upViewport(0)
>        } #n-loop
>    }
> }
> 
> Paul
> 
> On 27/10/16 04:21, Ben Tupper wrote:
>> Hi,
>> 
>> The following encapsulates what I hoped for using Paul's method.  The
>> function accepts one or more trellis class objects and aligns them
>> vertically.  I think I have automated most of the manual fiddling.
>> Depending upon your graphics device you may need to fiddle with the
>> aspect of the levelplot as I did below.  There remains a good deal of
>> vertical white space but it is fine for my purposes as I only need
>> two objects aligned where it looks OK.
>> 
>> I couldn't get Richard's simplified steps to work - I'm still
>> noodling that out but the simplicity is very enticing.
>> 
>> Thanks again for the all the suggestions! Ben
>> 
>> #### START library(lattice) library(grid)
>> 
>> #' Vertically align one or more trellis class objects. #' #' Objects
>> are plotted in order from bottom up and all are restricted to the #'
>> horizontal extent across the device and to the data range of that of
>> the #' first object. #' #' @param x a list of one or more trellis
>> class objects valign_lattice <- function(x) {
>> 
>> if (inherits(x, "trellis")) x <- list(x)
>> 
>> if (!all(sapply(x, inherits, 'trellis'))) stop("all elements of x
>> must inherit from trellis class")
>> 
>> nx <- length(x) names(x) <- LETTERS[1:nx] h1 <- 1/nx y0 <- seq(from =
>> 0, to = 1 - h1, length = nx) n <- 1 grid.newpage()
>> pushViewport(viewport(y=y0[n], height=h1, just="bottom")) # Force
>> identical widths where we can layout.widths <-
>> lattice.options("layout.widths")[[1]] layout.widths$ylab <- list(x=1,
>> units="cm", data=NULL) layout.widths$panel <- list(x=1, units="null",
>> data=NULL) layout.widths$key.right <- list(x=1, units="cm",
>> data=NULL) lattice.options(layout.widths=layout.widths) # Force
>> (width of) left axis labels to be the same prefix <- LETTERS[n]
>> print(x[[n]], newpage=FALSE, prefix=prefix)
>> downViewport(paste0(prefix,".panel.1.1.off.vp")) # Determine width of
>> levelplot panel border <- grid.get("border", grep=TRUE) width <-
>> convertWidth(border$width, "in", valueOnly=TRUE) xscale <-
>> current.viewport()$xscale upViewport(0)
>> 
>> if (nx > 1){ for (n in 2:nx){ pushViewport(viewport(y=y0[n],
>> height=h1, just="bottom")) # Force identical widths where we can
>> layout.widths$ylab <- list(x=1, units="cm", data=NULL)
>> layout.widths$panel <- list(x=width, units="in", data=NULL)
>> layout.widths$key.right <- list(x=1, units="cm", data=NULL)
>> lattice.options(layout.widths=layout.widths) x[[n]] <- update(x[[n]],
>> xlim = xscale) prefix <- LETTERS[n] print(x[[n]], newpage=FALSE,
>> prefix=prefix) downViewport(paste0(prefix,".panel.1.1.off.vp"))
>> upViewport(0) } #n-loop } }
>> 
>> d <- dim(volcano) xy <- data.frame( x = 1:d[1], y1 = volcano[,30], y2
>> = sqrt(volcano[,7]))
>> 
>> bottom <- levelplot(volcano, main = 'boom', ylab = 'foo', xlab =
>> 'bar', aspect = 0.5) middle <- xyplot(y1 ~ x, data = xy, main =
>> 'bam', xlab = '', ylab = 'elevation') top <- xyplot(y2 ~ x, data =
>> xy, main = 'bing', ylab = 'squished', xlab = '')
>> 
>> # just two x <- list(bottom, top) valign_lattice(x)
>> 
>> bottom <- update(bottom, aspect = 0.2) # three x <- list(bottom,
>> middle, top) valign_lattice(x)
>> #### END
>> 
>> 
>> 
>>> On Oct 25, 2016, at 8:07 PM, Paul Murrell
>>> <paul at stat.auckland.ac.nz> wrote:
>>> 
>>> Hi
>>> 
>>> This might work, though it's a teensy bit more complicated and a
>>> bit manual (on the left axis labels) and it ignores heights and
>>> vertical whitespace ...
>>> 
>>> library(lattice) d <- dim(volcano) xy <- data.frame(x = 1:d[1], y =
>>> volcano[,30] ) library(grid) grid.newpage()
>>> pushViewport(viewport(y=0, height=.5, just="bottom")) # Force
>>> identical widths where we can layout.widths <-
>>> lattice.options("layout.widths")[[1]] layout.widths$ylab <-
>>> list(x=1, units="cm", data=NULL) layout.widths$panel <- list(x=1,
>>> units="null", data=NULL) layout.widths$key.right <- list(x=1,
>>> units="cm", data=NULL)
>>> lattice.options(layout.widths=layout.widths) # Force (width of)
>>> left axis labels to be the same vol_p <- levelplot(volcano,
>>> scales=list(y=list(at=seq(10, 60, 10), labels=rep(" ", 6))))
>>> print(vol_p, newpage=FALSE, prefix="vol_p")
>>> downViewport("vol_p.panel.1.1.off.vp") # Draw proper left axis
>>> labels grid.text(seq(10, 60, 10), x=unit(0, "npc") - unit(1,
>>> "lines"), y=unit(seq(10, 60, 10), "native"), just="right",
>>> gp=gpar(cex=.8)) # Determine width of levelplot panel border <-
>>> grid.get("border", grep=TRUE) width <- convertWidth(border$width,
>>> "in", valueOnly=TRUE) xscale <- current.viewport()$xscale
>>> upViewport(0) pushViewport(viewport(y=.5, height=.5,
>>> just="bottom")) # Force identical widths where we can
>>> layout.widths$ylab <- list(x=1, units="cm", data=NULL)
>>> layout.widths$panel <- list(x=width, units="in", data=NULL)
>>> layout.widths$key.right <- list(x=1, units="cm", data=NULL)
>>> lattice.options(layout.widths=layout.widths) # Force (width of)
>>> left axis labels to be the same xy_p <- xyplot(y ~ x, data = xy,
>>> xlim=xscale, scales=list(y=list(at=seq(100, 200, 20), labels=rep("
>>> ", 11)))) print(xy_p, newpage=FALSE, prefix="xy_p")
>>> downViewport("xy_p.panel.1.1.off.vp") # Draw proper left axis
>>> labels grid.text(seq(100, 200, 20), x=unit(0, "npc") - unit(1,
>>> "lines"), y=unit(seq(100, 200, 20), "native"), just="right",
>>> gp=gpar(cex=.8)) upViewport(0)
>>> 
>>> Paul
>>> 
>>> On 26/10/16 10:50, Ben Tupper wrote:
>>>> Hi,
>>>> 
>>>> Almost but not quite.  It certainly moves the ball down the
>>>> field, and, dang, that would be way too easy!
>>>> 
>>>> I have been fiddling with the panel.widths to the lattice::plot
>>>> method.  No joy yet.
>>>> 
>>>> 
>>>> Ben
>>>> 
>>>> 
>>>>> On Oct 25, 2016, at 5:14 PM, Paul Murrell
>>>>> <paul at stat.auckland.ac.nz> wrote:
>>>>> 
>>>>> Hi
>>>>> 
>>>>> Does this do what you want ?
>>>>> 
>>>>> library(latticeExtra) c(vol_p, xy_p, x.same=TRUE)
>>>>> 
>>>>> Paul
>>>>> 
>>>>> On 26/10/16 04:30, Ben Tupper wrote:
>>>>>> Thanks, Bert.
>>>>>> 
>>>>>> I have used latticeExtra for layering graphics.  I'm not sure
>>>>>> how I would use it to align graphics rather superimposing
>>>>>> them.
>>>>>> 
>>>>>> I shall look into the the custom panel plot but that is very
>>>>>> new territory for me.
>>>>>> 
>>>>>> Ben
>>>>>> 
>>>>>>> On Oct 25, 2016, at 9:13 AM, Bert Gunter
>>>>>>> <bgunter.4567 at gmail.com> wrote:
>>>>>>> 
>>>>>>> Write a custom panel function for levelplot() that calls
>>>>>>> panel.xyplot after panel.levelplot. I believe this can also
>>>>>>> be done by the +  operator of the latticeExtra package.
>>>>>>> 
>>>>>>> You do *not* want to call xyplot after levelplot, as that
>>>>>>> completely redraws the plot.
>>>>>>> 
>>>>>>> Cheers, Bert
>>>>>>> 
>>>>>>> 
>>>>>>> On Oct 25, 2016 2:55 PM, "Ben Tupper" <btupper at bigelow.org
>>>>>>> <mailto:btupper at bigelow.org>> wrote: Hello,
>>>>>>> 
>>>>>>> I am drawing a levelplot and an xyplot on a single device
>>>>>>> as shown in the runnable example below.  I would like the x
>>>>>>> axes to align - that is for them to cover the same extent
>>>>>>> left-to-right on the device. How do I go about doing that?
>>>>>>> 
>>>>>>> ####### # START ####### library(lattice)
>>>>>>> 
>>>>>>> d <- dim(volcano) xy <- data.frame(x = 1:d[1], y =
>>>>>>> volcano[,30] )
>>>>>>> 
>>>>>>> vol_p <- levelplot(volcano) xy_p <- xyplot(y ~ x, data =
>>>>>>> xy)
>>>>>>> 
>>>>>>> print(vol_p, split = c(1, 2, 1, 2), more = TRUE)
>>>>>>> print(xy_p,  split = c(1, 1, 1, 2), more = FALSE) ######
>>>>>>> #END ######
>>>>>>> 
>>>>>>> 
>>>>>>> Thanks! Ben
>>>>>>> 
>>>>>>> 
>>>>>>>> sessionInfo()
>>>>>>> R version 3.3.1 (2016-06-21) Platform:
>>>>>>> x86_64-apple-darwin13.4.0 (64-bit) Running under: OS X
>>>>>>> 10.11.6 (El Capitan)
>>>>>>> 
>>>>>>> locale: [1]
>>>>>>> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>>>> 
>>>>>>> 
>>>>>>> 
> attached base packages: [1] stats     graphics  grDevices utils
>>>>>>> datasets  methods   base
>>>>>>> 
>>>>>>> other attached packages: [1] lattice_0.20-33
>>>>>>> 
>>>>>>> loaded via a namespace (and not attached): [1] tools_3.3.1
>>>>>>> grid_3.3.1
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow
>>>>>>> Drive, P.O. Box 380 East Boothbay, Maine 04544
>>>>>>> http://www.bigelow.org <http://www.bigelow.org/>
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>>>>>> list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> <https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do
>>>>>>> read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> <http://www.r-project.org/posting-guide.html> and provide
>>>>>>> commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>> 
>>>>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow
>>>>>> Drive, P.O. Box 380 East Boothbay, Maine 04544
>>>>>> http://www.bigelow.org
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>>>>>> read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html and provide
>>>>>> commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>> 
>>>>> -- Dr Paul Murrell Department of Statistics The University of
>>>>> Auckland Private Bag 92019 Auckland New Zealand 64 9 3737599
>>>>> x85392 paul at stat.auckland.ac.nz
>>>>> http://www.stat.auckland.ac.nz/~paul/
>>>> 
>>>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow
>>>> Drive, P.O. Box 380 East Boothbay, Maine 04544
>>>> http://www.bigelow.org
>>>> 
>>>> 
>>>> 
>>> 
>>> -- Dr Paul Murrell Department of Statistics The University of
>>> Auckland Private Bag 92019 Auckland New Zealand 64 9 3737599
>>> x85392 paul at stat.auckland.ac.nz
>>> http://www.stat.auckland.ac.nz/~paul/
>> 
>> Ben Tupper Bigelow Laboratory for Ocean Sciences 60 Bigelow Drive,
>> P.O. Box 380 East Boothbay, Maine 04544 http://www.bigelow.org
>> 
>> ______________________________________________ R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and provide
>> commented, minimal, self-contained, reproducible code.
>> 
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From bogaso.christofer at gmail.com  Thu Oct 27 17:05:54 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Thu, 27 Oct 2016 20:35:54 +0530
Subject: [R] How to put below code in Automator in iOS
Message-ID: <CA+dpOJn9eO0dgsMAWDMFrGVr2_omCSJubazmO79jh052uY-VOA@mail.gmail.com>

Hi,

I have a piece of code available here

http://mcu.edu.tw/~chenmh/teaching/project/r/reference/RTclTkExamples/radiobuttons.html

Now I put that code in a .R file and then created an .app file in Mac
using Automator as explained below

https://www.r-bloggers.com/how-to-source-an-r-script-automatically-on-a-mac-using-automator-and-ical/

Surprisingly what I see is that, when I put that R code in a .app
file, R fails to pop up the input window, which otherwise is fine when
I just copy paste that code in R window.

Could you please help if I need to have anything extra so that my .app
will be able to take the input.

Thanks for your time.


From S.Ellison at LGCGroup.com  Thu Oct 27 17:40:48 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 27 Oct 2016 16:40:48 +0100
Subject: [R] How to put below code in Automator in iOS
In-Reply-To: <CA+dpOJn9eO0dgsMAWDMFrGVr2_omCSJubazmO79jh052uY-VOA@mail.gmail.com>
References: <CA+dpOJn9eO0dgsMAWDMFrGVr2_omCSJubazmO79jh052uY-VOA@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672404009966C4@GBTEDVPEXCMB04.corp.lgc-group.com>

From 'An introduction to R' in the html help system:
"If you just want to run a file foo.R of R commands, the recommended way is to use R CMD BATCH foo.R. "
There is also a short section on 'Invoking R under OS X' in the 'Introduction to R'; it may help.

S Ellison


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Christofer
> Bogaso
> Sent: 27 October 2016 16:06
> To: r-help
> Subject: [R] How to put below code in Automator in iOS
> 
> Hi,
> 
> I have a piece of code available here
> 
> http://mcu.edu.tw/~chenmh/teaching/project/r/reference/RTclTkExamples
> /radiobuttons.html
> 
> Now I put that code in a .R file and then created an .app file in Mac using
> Automator as explained below
> 
> https://www.r-bloggers.com/how-to-source-an-r-script-automatically-on-a-
> mac-using-automator-and-ical/
> 
> Surprisingly what I see is that, when I put that R code in a .app file, R fails to
> pop up the input window, which otherwise is fine when I just copy paste that
> code in R window.
> 
> Could you please help if I need to have anything extra so that my .app will be
> able to take the input.
> 
> Thanks for your time.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From sarah.goslee at gmail.com  Thu Oct 27 18:00:30 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 27 Oct 2016 12:00:30 -0400
Subject: [R] How to put below code in Automator in iOS
In-Reply-To: <CA+dpOJn9eO0dgsMAWDMFrGVr2_omCSJubazmO79jh052uY-VOA@mail.gmail.com>
References: <CA+dpOJn9eO0dgsMAWDMFrGVr2_omCSJubazmO79jh052uY-VOA@mail.gmail.com>
Message-ID: <CAM_vjunfPhHvhOeTMYWikMWGzZbXGxeV7ar2q-aD2fmWHxtoCA@mail.gmail.com>

You should probably ask this on the Mac R-help list, since it's not a
general R question and that's where you are likely to find people who
know the answer:
https://stat.ethz.ch/mailman/listinfo/r-sig-mac

Sarah

On Thu, Oct 27, 2016 at 11:05 AM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hi,
>
> I have a piece of code available here
>
> http://mcu.edu.tw/~chenmh/teaching/project/r/reference/RTclTkExamples/radiobuttons.html
>
> Now I put that code in a .R file and then created an .app file in Mac
> using Automator as explained below
>
> https://www.r-bloggers.com/how-to-source-an-r-script-automatically-on-a-mac-using-automator-and-ical/
>
> Surprisingly what I see is that, when I put that R code in a .app
> file, R fails to pop up the input window, which otherwise is fine when
> I just copy paste that code in R window.
>
> Could you please help if I need to have anything extra so that my .app
> will be able to take the input.
>
> Thanks for your time.
>


From aloboaleu at gmail.com  Thu Oct 27 14:57:57 2016
From: aloboaleu at gmail.com (Agustin Lobo)
Date: Thu, 27 Oct 2016 14:57:57 +0200
Subject: [R] How to create a list of trellis objects for grid.arrange()
Message-ID: <CALPC6DPgXuMXYKEKc=yW_imraLGPMKcB9ix9U5h1VE72BXDQZQ@mail.gmail.com>

Given
require(raster)
require(sp)
require(gridExtra)

f <- system.file("external/test.grd", package="raster")
r <- raster(f)
p1 <- spplot(r)
p2 <- spplot(r)

I would like to plot the equivalent to

grid.arrange(p1,p2,ncol=1,nrow=2)

but keeping the trellis objects p1 and p2 within one single object (as
in practice I have many objects generated within a for() loop).

The following used to work:
ps <- c(p1,p2)
grid.arrange(ps,ncol=1,nrow=2)

but does not work any more.

How should I combine p1 and p2 into one single object that would be
accepted by grid.arrange?

Thanks
-- 
Agustin Lobo
aloboaleu at gmail.com


From arunkumar.govindaraju at hsbc.co.in  Thu Oct 27 16:12:51 2016
From: arunkumar.govindaraju at hsbc.co.in (arunkumar.govindaraju at hsbc.co.in)
Date: Thu, 27 Oct 2016 19:42:51 +0530
Subject: [R] Reg. Error: could not find function "lsei" in limSolve library
Message-ID: <OF6D5F422B.9DE72EBC-ON65258059.004D9D71-65258059.004E14C2@hsbc.asia>

Hi,

I tried to load package from local zip folder in R logic and it worked.

> utils:::menuInstallLocal()
package ?limSolve? successfully unpacked and MD5 sums checked

when tried to load.. it says,

> local({pkg <- select.list(sort(.packages(all.available = 
TRUE)),graphics=TRUE)
+ if(nchar(pkg)) library(pkg, character.only=TRUE)})
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck 
= vI[[j]]) : 
  there is no package called ?lpSolve?
In addition: Warning message:
package ?limSolve? was built under R version 3.2.5 
Error: package or namespace load failed for ?limSolve?

But my R version is 3.1.2, so can someone tell me, how to load the 
package? thx

Regards,
Arun


************************************************************
The Hongkong and Shanghai Banking Corporation Limited
whose registered address is 1 Queen's Road Central, Hong Kong
************************************************************



-----------------------------------------
*******************************************************************
This e-mail is confidential. It may also be legally privileged.
If you are not the addressee you may not copy, forward, disclose
or use any part of it. If you have received this message in error,
please delete it and all copies from your system and notify the
sender immediately by return e-mail.

Internet communications cannot be guaranteed to be timely,
secure, error or virus-free. The sender does not accept liability
for any errors or omissions.
*******************************************************************
"SAVE PAPER - THINK BEFORE YOU PRINT!"

	[[alternative HTML version deleted]]


From davef at otter-rsch.com  Thu Oct 27 17:48:39 2016
From: davef at otter-rsch.com (dave fournier)
Date: Thu, 27 Oct 2016 08:48:39 -0700
Subject: [R] Finding starting values for the parameters using nls() or
 nls2()
In-Reply-To: <CF336029-D3BC-44EF-B2C7-55C9B3E38B29@comcast.net>
References: <CF336029-D3BC-44EF-B2C7-55C9B3E38B29@comcast.net>
Message-ID: <9074fde3-748c-94fc-88cd-7e5f8e856182@otter-rsch.com>

 >
 >> On Oct 25, 2016, at 9:29 AM, dave fournier <davef at otter-rsch.com> 
wrote:
 >>
 >>
 >>
 >> Unfortunately this problem does not appear to be well posed.
 >>
 >>    Retention = (b0*Area^(th+1))^b
 >>
 >> If b0, th, and b are the parameter only the product (th+1)*b is 
determined.
 >>
 >> This comes from noting that powers satisfy
 >>
 >>
 >>
 >>    (a^b)^c  =  a^(b*c)
 >>
 >>
 >>
 >> So your model can be written as
 >>
 >>
 >>
 >>          (b0^b) * Area^((th+1)*b)
 >>
 >
 >... which nicely completes the thread since one model had:
 >
 >th1   =  9.1180e-01
 > b01=    5.2104e+00
 > b11 =  -4.6725e-04
 >(th1+1)*b11
 >[1] -0.0008932885
 >
 >
 > b0  = 5.2104466   ;    b1 =   -0.0004672   ;  th =  0.9118029
 >((th+1)*b1)
 >[1] -0.0008931943
 >
 >So both the R's nls2 and AD_MOdel_Builder results yield that same 
predictions for any given data point at least up to four decimal places.
 >
 >So perhaps there was some other physical interpretation of those 
parameters and there exists an underlying theory that would support 
adding some extra constraints?
 >
 >--
 >>David Winsemius
 >Alameda, CA, USA

I'm not really sure what your point is. The OP has two models. One is well
posed and the other is not. I was discussing solution of the former model
which is well posed.  The form of the model, using a, b, and t and x,y to
simplify the expression is

         y  = exp( a * exp(b * x^t) )

My point is that there are many models like this where the obvious
parameterization (something like the parameters the user is interested
in) leads to parameter estimates with highly correlated errors.
This does not necessarily mean that
the model is badly determined. The model exists independent of the
particular parameterization. To fix  the ideas assume there are n 
observations
(x_i,y_i)  and simplify by assuming that x_1<=x_2<=...<=x_n
(but not all equal lets hope)

A stable parameterization of the model can often be obtained by
picking as new parameters y1 and yn where y1 and yn are the predicted 
values for y_1 and y_n, that is

            y1  = exp( a * exp(b * x_1^t) )
            yn  = exp( a * exp(b * x_n^t) )

Then one solves for some of the original model parameters in terms of y1 
and yn.
The particular way this is done depends on the model. Often some has some
linear parameters and the procedure is easy. For this model as I showed
one can solve for a and b in terms of y1 and yn.
Then one can fit the model easily with AD Model Builder or
nls2 using this parameterization. nls2 provides the standard errors for
the parameter estimates.  The AD Model Builder solution provides the
estimated variance covariance matrix of the parameter estimates via the
standard maximum likelihood Hessian calculations. It also provides the
covariance for any desired dependent variable.  So one can fit the model
using y1,yn, and t and get the covariance matrix for a,b, and t
in one step. In nls2 one needs to fit the model using y1,yn and then
solve for a and b and run the model again from that point.  That is no big
deal, and I showed how to do it, but it is one more step for the user.

It is interesting to see the correlation matrix for the parameter estimates
and the dependent variables.
                     std dev          correlation
1  logt -9.233e-02 3.4026e-01  1.0000
2  c    9.7164e-01 3.7006e-02 -0.2690  1.0000
3  d    1.1010e+00 1.7852e-01 -0.7495  0.0325  1.000
4  t    9.1180e-01 3.1025e-01  1.0000 -0.2690 -0.749  1.0000
5  a    5.2104e+00 4.3404e-01 -0.9781  0.4191  0.621 -0.9781  1.000
6  b   -4.6725e-04 1.1714e-03  0.9994 -0.2836 -0.726  0.9994 -0.984 1.00

Here the independent variable are c, d, and logt
where y1=c*y_1  y2=d*y2
That is just an additional thing so that one can start with c=1 and d=1
Also logt is used where t=exp(logt) which makes sure t>0.
Notice that the correlation between c and d is 0.0325 which is small.


If  a and b were the parameters of the model

4   t    9.1180e-01 3.1025e-01   1.0000
5   a    5.2104e+00 4.3404e-01   -0.9781  1.000
6   b   -4.6725e-04 1.1714e-03    0.9994 -0.984  1.00

One can see how close to 1 and -1 the correlations are.

Notice that the parameter b is very badly determined.
So rather than saying the model is no good one sees that
the model is no good if one want to get information about
the parameter b. In contrast the parameter a is fairly well
determined and the parameter t is "kind of" determined.

   Because of this parameter confounding nls2 is extremely sensitive
   to the starting parameter values using this parameterization.
   If I change the parameters by about 15% or less as below

   #b0start=5.210445
   #b1_start=-0.0004672373
   #th_start=0.911804
   b0_start=5.7
   b1_start=-0.00055
   th_start=1.05

I get the dreaded

Error in (function (formula, data = parent.frame(), start, control = 
nls.control(),  :
   singular gradient

So there is nothing wrong with either the data or the model. The model
just needs to be given a stable parameterization.


From dwinsemius at comcast.net  Fri Oct 28 00:43:01 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 27 Oct 2016 15:43:01 -0700
Subject: [R] Reg. Error: could not find function "lsei" in limSolve
	library
In-Reply-To: <OF6D5F422B.9DE72EBC-ON65258059.004D9D71-65258059.004E14C2@hsbc.asia>
References: <OF6D5F422B.9DE72EBC-ON65258059.004D9D71-65258059.004E14C2@hsbc.asia>
Message-ID: <3B0E0C23-2AA9-4FBF-A807-C099A9FECBD6@comcast.net>


> On Oct 27, 2016, at 7:12 AM, arunkumar.govindaraju at hsbc.co.in wrote:
> 
> Hi,
> 
> I tried to load package from local zip folder in R logic and it worked.
> 
>> utils:::menuInstallLocal()
> package ?limSolve? successfully unpacked and MD5 sums checked
> 
> when tried to load.. it says,
> 
>> local({pkg <- select.list(sort(.packages(all.available = 
> TRUE)),graphics=TRUE)
> + if(nchar(pkg)) library(pkg, character.only=TRUE)})
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck 
> = vI[[j]]) : 
>  there is no package called ?lpSolve?
> In addition: Warning message:
> package ?limSolve? was built under R version 3.2.5 
> Error: package or namespace load failed for ?limSolve?

I do not see the error you are referencing about in your subject line.

The error message you are posting says that if you do not have the R package dependencies for a package in your library directories, it fails to install. (Read the error messages completely.)

And do read the Posting Guide.

> 
> But my R version is 3.1.2, so can someone tell me, how to load the 
> package? thx

If your desired package will not install or load after installation in an outdated version of R, then you need to install a copy from the Archives.

-- 
Best;
David.

> 
> Regards,
> Arun
> 
> 
> ************************************************************
> The Hongkong and Shanghai Banking Corporation Limited
> whose registered address is 1 Queen's Road Central, Hong Kong
> ************************************************************
> 
> 
> 
> -----------------------------------------
> *******************************************************************
> This e-mail is confidential. It may also be legally privileged.
> If you are not the addressee you may not copy, forward, disclose
> or use any part of it. If you have received this message in error,
> please delete it and all copies from your system and notify the
> sender immediately by return e-mail.
> 
> Internet communications cannot be guaranteed to be timely,
> secure, error or virus-free. The sender does not accept liability
> for any errors or omissions.
> *******************************************************************
> "SAVE PAPER - THINK BEFORE YOU PRINT!"
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From cbenjami at BTBOCES.ORG  Fri Oct 28 02:53:20 2016
From: cbenjami at BTBOCES.ORG (Courtney Benjamin)
Date: Fri, 28 Oct 2016 00:53:20 +0000
Subject: [R] Significance of Svyrepdesign Object Warning
In-Reply-To: <CAF8bMcaZqm=0ykGfEYkBOYObraxY2AGCQ9uMOi+WmE9wdTRV_g@mail.gmail.com>
References: <1477238188762.32714@BTBOCES.ORG>
	<CAOwvMDy-RPreSvxgU-Gbo6gXb4xBzOaTsig2Qt8vYjNX7f_=og@mail.gmail.com>,
	<CAF8bMcaZqm=0ykGfEYkBOYObraxY2AGCQ9uMOi+WmE9wdTRV_g@mail.gmail.com>
Message-ID: <1477615998988.4101@BTBOCES.ORG>

Hello Mr. Dunlap,

I have gone back and re-read the responses to my question.  I am interested in trying to apply your recommendation so I am doing things correctly; however I am not sure how to go about doing it within my code.  It appears that you are digging quite deeply into R where I am not yet familiar.  I am including a reproducible example; would you be willing to show an example of how it would be done?  I greatly appreciate your advisement and time.

Sincerely,

Courtney


library(RCurl)
library(survey)
data <- getURL("https://raw.githubusercontent.com/cbenjamin1821/careertech-ed/master/elsq1adj.csv")
elsq1ch <- read.csv(text = data)
#Specifying the svyrepdesign object which applies the BRR weights
elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights = elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type = "BRR")
elsq1ch_brr
#Logistic regression call which yields a warning regarding svyrepdesign object
allCC <-svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
summary(allCC)


?


Courtney Benjamin

Broome-Tioga BOCES

Automotive Technology II Teacher

Located at Gault Toyota

Doctoral Candidate-Educational Theory & Practice

State University of New York at Binghamton

cbenjami at btboces.org<mailto:cbenjami at btboces.org>

607-763-8633

________________________________
From: William Dunlap <wdunlap at tibco.com>
Sent: Sunday, October 23, 2016 2:24 PM
To: Anthony Damico
Cc: Courtney Benjamin; r-help at r-project.org; Thomas Lumley
Subject: Re: [R] Significance of Svyrepdesign Object Warning

The immediate problem could be solved by changing the following lines in survey:::summary.svrepglm from
    presid <- resid(object, "pearson")
    dispersion <- sum(object$survey.design$pweights * presid^2,
        na.rm = TRUE)/sum(object$survey.design$pweights)
to
    presid <- resid(object, "pearson")
    pweights <- naresid(object$na.action, object$survey.design$pweights)
    dispersion <- sum(pweights * presid^2, na.rm = TRUE)/sum(pweights,
        na.rm = TRUE)

'naresid' uses the information from na.exclude to match up the residuals
with the row in the data that they correspond to.  resid() calls it so it should
also be applied to pweights so they line up correctly.




Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Sun, Oct 23, 2016 at 11:17 AM, Anthony Damico <ajdamico at gmail.com<mailto:ajdamico at gmail.com>> wrote:
hi, great example.  i am ccing survey package author/maintainer dr.
lumley.  why do you have `na.action=na.exclude`?  if you remove it, things
work as expected--


    library(RCurl)
    library(survey)
    data <- getURL("
https://raw.githubusercontent.com/cbenjamin1821/careertech-ed/master/elsq1adj.csv
")
    elsq1ch <- read.csv(text = data)
    #Specifying the svyrepdesign object which applies the BRR weights
    elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights =
elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type =
"BRR")
    elsq1ch_brr
    #Logistic regression call which yields a warning regarding svyrepdesign
object

    # your warning
    a <-
svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
    summary(a)

    # works fine
    a <-
svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1)
    summary(a)



    the mismatch of vectors generating that warning happens inside

    debug(survey:::summary.svrepglm)

    [..snip..]

    Browse[2]> length(presid)
    [1] 12614
    Browse[2]> length(object$survey.design$pweights)
    [1] 8397


    and including vs excluding the na.action=na.exclude gives you a
slightly different dispersion parameter calculation

        (Dispersion parameter for binomial family taken to be 0.7756235)

        (Dispersion parameter for binomial family taken to be 0.7849244)


not sure if the two survey:::residuals.sv<http://residuals.sv>* methods should deal with the
na.action= parameter?


thanks

On Sun, Oct 23, 2016 at 11:56 AM, Courtney Benjamin <cbenjami at btboces.org<mailto:cbenjami at btboces.org>>
wrote:

> Hello R Users,
>
> I am using Lumley's Survey Package in R to analyze complex survey data
> that involves 200 balanced repeated replicate (BRR) weight variables.  I
> have ensured that my svyrepdesign object that specifies the application of
> the BRR weights to the data set is accurate and I have matched the
> published standard errors of the data set.
>
> When doing a logistic regression through the svyglm call, I receive the
> following warning:
>
> In object$survey.design$pweights * presid^2 :
>   longer object length is not a multiple of shorter object length?
> I have search around quite a bit online and have not been able to find any
> good interpretation of its meaning.  I want to be sure that I am not making
> some type of mistake that is causing this warning to be produced.  Any
> advisement is greatly appreciated.
> The following is an MRE that can be pasted into the R console:
> library(RCurl)
> library(survey)
> data <- getURL("https://raw.githubusercontent.com/
> cbenjamin1821/careertech-ed/master/elsq1adj.csv")
> elsq1ch <- read.csv(text = data)
> #Specifying the svyrepdesign object which applies the BRR weights
> elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights =
> elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type =
> "BRR")
> elsq1ch_brr
> #Logistic regression call which yields a warning regarding svyrepdesign
> object
> svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+
> F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=
> elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
> allCC <- summary(svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+
> F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",
> design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude))
> allCC
>
> #Session Info
> #R version 3.3.1 (2016-06-21)
> #Platform: x86_64-w64-mingw32/x64 (64-bit)
> #Running under: Windows >= 8 x64 (build 9200)
>
> #locale:
> #  [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
> #[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> #[5] LC_TIME=English_United States.1252
> #attached base packages:
> #  [1] grid      stats     graphics  grDevices utils     datasets
> methods   base
> #other attached packages:
> #[1] survey_3.31-2   survival_2.39-4 Matrix_1.2-6    RCurl_1.95-4.8
> bitops_1.0-6
> #loaded via a namespace (and not attached):
> #[1] tools_3.3.1     splines_3.3.1   knitr_1.14      lattice_0.20-33
>
>
> Courtney Benjamin
>
> Broome-Tioga BOCES
>
> Automotive Technology II Teacher
>
> Located at Gault Toyota
>
> Doctoral Candidate-Educational Theory & Practice
>
> State University of New York at Binghamton
>
> cbenjami at btboces.org<mailto:cbenjami at btboces.org><mailto:cbenjami at btboces.org<mailto:cbenjami at btboces.org>>
>
> 607-763-8633<tel:607-763-8633>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Oct 28 03:59:34 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 27 Oct 2016 18:59:34 -0700
Subject: [R] Significance of Svyrepdesign Object Warning
In-Reply-To: <1477615998988.4101@BTBOCES.ORG>
References: <1477238188762.32714@BTBOCES.ORG>
	<CAOwvMDy-RPreSvxgU-Gbo6gXb4xBzOaTsig2Qt8vYjNX7f_=og@mail.gmail.com>
	<CAF8bMcaZqm=0ykGfEYkBOYObraxY2AGCQ9uMOi+WmE9wdTRV_g@mail.gmail.com>
	<1477615998988.4101@BTBOCES.ORG>
Message-ID: <CAF8bMcZNfa1K=cJgbx8QgQN0xHZZAWaPd_Y+Aukcdr9zDM7=ww@mail.gmail.com>

For, now I would just use na.action=na.omit instead of na.exclude.  My
comments were mainly for the package author.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Oct 27, 2016 at 5:53 PM, Courtney Benjamin <cbenjami at btboces.org>
wrote:

> Hello Mr. Dunlap,
>
> I have gone back and re-read the responses to my question.  I am
> interested in trying to apply your recommendation so I am doing things
> correctly; however I am not sure how to go about doing it within my code.
> It appears that you are digging quite deeply into R where I am not yet
> familiar.  I am including a reproducible example; would you be willing to
> show an example of how it would be done?  I greatly appreciate your
> advisement and time.
>
> Sincerely,
>
> Courtney
>
>
> library(RCurl)
> library(survey)
> data <- getURL("https://raw.githubusercontent.com/
> cbenjamin1821/careertech-ed/master/elsq1adj.csv")
> elsq1ch <- read.csv(text = data)
> #Specifying the svyrepdesign object which applies the BRR weights
> elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights =
> elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type =
> "BRR")
> elsq1ch_brr
> #Logistic regression call which yields a warning regarding svyrepdesign
> object
> allCC <-svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+
> F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=
> elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
> summary(allCC)
>
>
> ?
>
>
> Courtney Benjamin
>
> Broome-Tioga BOCES
>
> Automotive Technology II Teacher
>
> Located at Gault Toyota
>
> Doctoral Candidate-Educational Theory & Practice
>
> State University of New York at Binghamton
>
> cbenjami at btboces.org
>
> 607-763-8633
> ------------------------------
> *From:* William Dunlap <wdunlap at tibco.com>
> *Sent:* Sunday, October 23, 2016 2:24 PM
> *To:* Anthony Damico
> *Cc:* Courtney Benjamin; r-help at r-project.org; Thomas Lumley
> *Subject:* Re: [R] Significance of Svyrepdesign Object Warning
>
> The immediate problem could be solved by changing the following lines in
> survey:::summary.svrepglm from
>     presid <- resid(object, "pearson")
>     dispersion <- sum(object$survey.design$pweights * presid^2,
>         na.rm = TRUE)/sum(object$survey.design$pweights)
> to
>     presid <- resid(object, "pearson")
>     pweights <- naresid(object$na.action, object$survey.design$pweights)
>     dispersion <- sum(pweights * presid^2, na.rm = TRUE)/sum(pweights,
>         na.rm = TRUE)
>
> 'naresid' uses the information from na.exclude to match up the residuals
> with the row in the data that they correspond to.  resid() calls it so it
> should
> also be applied to pweights so they line up correctly.
>
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Sun, Oct 23, 2016 at 11:17 AM, Anthony Damico <ajdamico at gmail.com>
> wrote:
>
>> hi, great example.  i am ccing survey package author/maintainer dr.
>> lumley.  why do you have `na.action=na.exclude`?  if you remove it, things
>> work as expected--
>>
>>
>>     library(RCurl)
>>     library(survey)
>>     data <- getURL("
>> https://raw.githubusercontent.com/cbenjamin1821/careertech-e
>> d/master/elsq1adj.csv
>> ")
>>     elsq1ch <- read.csv(text = data)
>>     #Specifying the svyrepdesign object which applies the BRR weights
>>     elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights =
>> elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type =
>> "BRR")
>>     elsq1ch_brr
>>     #Logistic regression call which yields a warning regarding
>> svyrepdesign
>> object
>>
>>     # your warning
>>     a <-
>> svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGP
>> P2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,
>> subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
>>     summary(a)
>>
>>     # works fine
>>     a <-
>> svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGP
>> P2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,
>> subset=BYSCTRL==1&G10COHRT==1)
>>     summary(a)
>>
>>
>>
>>     the mismatch of vectors generating that warning happens inside
>>
>>     debug(survey:::summary.svrepglm)
>>
>>     [..snip..]
>>
>>     Browse[2]> length(presid)
>>     [1] 12614
>>     Browse[2]> length(object$survey.design$pweights)
>>     [1] 8397
>>
>>
>>     and including vs excluding the na.action=na.exclude gives you a
>> slightly different dispersion parameter calculation
>>
>>         (Dispersion parameter for binomial family taken to be 0.7756235)
>>
>>         (Dispersion parameter for binomial family taken to be 0.7849244)
>>
>>
>> not sure if the two survey:::residuals.sv* methods should deal with the
>> na.action= parameter?
>>
>>
>> thanks
>>
>> On Sun, Oct 23, 2016 at 11:56 AM, Courtney Benjamin <cbenjami at btboces.org
>> >
>> wrote:
>>
>> > Hello R Users,
>> >
>> > I am using Lumley's Survey Package in R to analyze complex survey data
>> > that involves 200 balanced repeated replicate (BRR) weight variables.  I
>> > have ensured that my svyrepdesign object that specifies the application
>> of
>> > the BRR weights to the data set is accurate and I have matched the
>> > published standard errors of the data set.
>> >
>> > When doing a logistic regression through the svyglm call, I receive the
>> > following warning:
>> >
>> > In object$survey.design$pweights * presid^2 :
>> >   longer object length is not a multiple of shorter object length?
>> > I have search around quite a bit online and have not been able to find
>> any
>> > good interpretation of its meaning.  I want to be sure that I am not
>> making
>> > some type of mistake that is causing this warning to be produced.  Any
>> > advisement is greatly appreciated.
>> > The following is an MRE that can be pasted into the R console:
>> > library(RCurl)
>> > library(survey)
>> > data <- getURL("https://raw.githubusercontent.com/
>> > cbenjamin1821/careertech-ed/master/elsq1adj.csv")
>> > elsq1ch <- read.csv(text = data)
>> > #Specifying the svyrepdesign object which applies the BRR weights
>> > elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights =
>> > elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type
>> =
>> > "BRR")
>> > elsq1ch_brr
>> > #Logistic regression call which yields a warning regarding svyrepdesign
>> > object
>> > svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+
>> > F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=
>> > elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
>> > allCC <- summary(svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+
>> > F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",
>> > design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude))
>> > allCC
>> >
>> > #Session Info
>> > #R version 3.3.1 (2016-06-21)
>> > #Platform: x86_64-w64-mingw32/x64 (64-bit)
>> > #Running under: Windows >= 8 x64 (build 9200)
>> >
>> > #locale:
>> > #  [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> > States.1252
>> > #[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>> > #[5] LC_TIME=English_United States.1252
>> > #attached base packages:
>> > #  [1] grid      stats     graphics  grDevices utils     datasets
>> > methods   base
>> > #other attached packages:
>> > #[1] survey_3.31-2   survival_2.39-4 Matrix_1.2-6    RCurl_1.95-4.8
>> > bitops_1.0-6
>> > #loaded via a namespace (and not attached):
>> > #[1] tools_3.3.1     splines_3.3.1   knitr_1.14      lattice_0.20-33
>> >
>> >
>> > Courtney Benjamin
>> >
>> > Broome-Tioga BOCES
>> >
>> > Automotive Technology II Teacher
>> >
>> > Located at Gault Toyota
>> >
>> > Doctoral Candidate-Educational Theory & Practice
>> >
>> > State University of New York at Binghamton
>> >
>> > cbenjami at btboces.org<mailto:cbenjami at btboces.org>
>> >
>> > 607-763-8633
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From cbenjami at BTBOCES.ORG  Fri Oct 28 04:52:48 2016
From: cbenjami at BTBOCES.ORG (Courtney Benjamin)
Date: Fri, 28 Oct 2016 02:52:48 +0000
Subject: [R] Significance of Svyrepdesign Object Warning
In-Reply-To: <CAF8bMcZNfa1K=cJgbx8QgQN0xHZZAWaPd_Y+Aukcdr9zDM7=ww@mail.gmail.com>
References: <1477238188762.32714@BTBOCES.ORG>
	<CAOwvMDy-RPreSvxgU-Gbo6gXb4xBzOaTsig2Qt8vYjNX7f_=og@mail.gmail.com>
	<CAF8bMcaZqm=0ykGfEYkBOYObraxY2AGCQ9uMOi+WmE9wdTRV_g@mail.gmail.com>
	<1477615998988.4101@BTBOCES.ORG>,
	<CAF8bMcZNfa1K=cJgbx8QgQN0xHZZAWaPd_Y+Aukcdr9zDM7=ww@mail.gmail.com>
Message-ID: <1477623166388.53935@BTBOCES.ORG>

?Thank you; I will do so.


Courtney Benjamin

Broome-Tioga BOCES

Automotive Technology II Teacher

Located at Gault Toyota

Doctoral Candidate-Educational Theory & Practice

State University of New York at Binghamton

cbenjami at btboces.org<mailto:cbenjami at btboces.org>

607-763-8633

________________________________
From: William Dunlap <wdunlap at tibco.com>
Sent: Thursday, October 27, 2016 9:59 PM
To: Courtney Benjamin
Cc: Anthony Damico; r-help at r-project.org; Thomas Lumley
Subject: Re: [R] Significance of Svyrepdesign Object Warning

For, now I would just use na.action=na.omit instead of na.exclude.  My comments were mainly for the package author.

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Thu, Oct 27, 2016 at 5:53 PM, Courtney Benjamin <cbenjami at btboces.org<mailto:cbenjami at btboces.org>> wrote:

Hello Mr. Dunlap,

I have gone back and re-read the responses to my question.  I am interested in trying to apply your recommendation so I am doing things correctly; however I am not sure how to go about doing it within my code.  It appears that you are digging quite deeply into R where I am not yet familiar.  I am including a reproducible example; would you be willing to show an example of how it would be done?  I greatly appreciate your advisement and time.

Sincerely,

Courtney


library(RCurl)
library(survey)
data <- getURL("https://raw.githubusercontent.com/cbenjamin1821/careertech-ed/master/elsq1adj.csv")
elsq1ch <- read.csv(text = data)
#Specifying the svyrepdesign object which applies the BRR weights
elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights = elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type = "BRR")
elsq1ch_brr
#Logistic regression call which yields a warning regarding svyrepdesign object
allCC <-svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
summary(allCC)


?


Courtney Benjamin

Broome-Tioga BOCES

Automotive Technology II Teacher

Located at Gault Toyota

Doctoral Candidate-Educational Theory & Practice

State University of New York at Binghamton

cbenjami at btboces.org<mailto:cbenjami at btboces.org>

607-763-8633<tel:607-763-8633>

________________________________
From: William Dunlap <wdunlap at tibco.com<mailto:wdunlap at tibco.com>>
Sent: Sunday, October 23, 2016 2:24 PM
To: Anthony Damico
Cc: Courtney Benjamin; r-help at r-project.org<mailto:r-help at r-project.org>; Thomas Lumley
Subject: Re: [R] Significance of Svyrepdesign Object Warning

The immediate problem could be solved by changing the following lines in survey:::summary.svrepglm from
    presid <- resid(object, "pearson")
    dispersion <- sum(object$survey.design$pweights * presid^2,
        na.rm = TRUE)/sum(object$survey.design$pweights)
to
    presid <- resid(object, "pearson")
    pweights <- naresid(object$na.action, object$survey.design$pweights)
    dispersion <- sum(pweights * presid^2, na.rm = TRUE)/sum(pweights,
        na.rm = TRUE)

'naresid' uses the information from na.exclude to match up the residuals
with the row in the data that they correspond to.  resid() calls it so it should
also be applied to pweights so they line up correctly.




Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Sun, Oct 23, 2016 at 11:17 AM, Anthony Damico <ajdamico at gmail.com<mailto:ajdamico at gmail.com>> wrote:
hi, great example.  i am ccing survey package author/maintainer dr.
lumley.  why do you have `na.action=na.exclude`?  if you remove it, things
work as expected--


    library(RCurl)
    library(survey)
    data <- getURL("
https://raw.githubusercontent.com/cbenjamin1821/careertech-ed/master/elsq1adj.csv
")
    elsq1ch <- read.csv(text = data)
    #Specifying the svyrepdesign object which applies the BRR weights
    elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights =
elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type =
"BRR")
    elsq1ch_brr
    #Logistic regression call which yields a warning regarding svyrepdesign
object

    # your warning
    a <-
svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
    summary(a)

    # works fine
    a <-
svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1)
    summary(a)



    the mismatch of vectors generating that warning happens inside

    debug(survey:::summary.svrepglm)

    [..snip..]

    Browse[2]> length(presid)
    [1] 12614
    Browse[2]> length(object$survey.design$pweights)
    [1] 8397


    and including vs excluding the na.action=na.exclude gives you a
slightly different dispersion parameter calculation

        (Dispersion parameter for binomial family taken to be 0.7756235)

        (Dispersion parameter for binomial family taken to be 0.7849244)


not sure if the two survey:::residuals.sv<http://residuals.sv>* methods should deal with the
na.action= parameter?


thanks

On Sun, Oct 23, 2016 at 11:56 AM, Courtney Benjamin <cbenjami at btboces.org<mailto:cbenjami at btboces.org>>
wrote:

> Hello R Users,
>
> I am using Lumley's Survey Package in R to analyze complex survey data
> that involves 200 balanced repeated replicate (BRR) weight variables.  I
> have ensured that my svyrepdesign object that specifies the application of
> the BRR weights to the data set is accurate and I have matched the
> published standard errors of the data set.
>
> When doing a logistic regression through the svyglm call, I receive the
> following warning:
>
> In object$survey.design$pweights * presid^2 :
>   longer object length is not a multiple of shorter object length?
> I have search around quite a bit online and have not been able to find any
> good interpretation of its meaning.  I want to be sure that I am not making
> some type of mistake that is causing this warning to be produced.  Any
> advisement is greatly appreciated.
> The following is an MRE that can be pasted into the R console:
> library(RCurl)
> library(survey)
> data <- getURL("https://raw.githubusercontent.com/
> cbenjamin1821/careertech-ed/master/elsq1adj.csv")
> elsq1ch <- read.csv(text = data)
> #Specifying the svyrepdesign object which applies the BRR weights
> elsq1ch_brr<-svrepdesign(variables = elsq1ch[,1:16], repweights =
> elsq1ch[,18:217], weights = elsq1ch[,17], combined.weights = TRUE, type =
> "BRR")
> elsq1ch_brr
> #Logistic regression call which yields a warning regarding svyrepdesign
> object
> svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+F1RACE+F1SEX+
> F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",design=
> elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude)
> allCC <- summary(svyglm(formula=F3ATTAINB~F1PARED+BYINCOME+
> F1RACE+F1SEX+F1RGPP2+F1HIMATH+F1RTRCC,family="binomial",
> design=elsq1ch_brr,subset=BYSCTRL==1&G10COHRT==1,na.action=na.exclude))
> allCC
>
> #Session Info
> #R version 3.3.1 (2016-06-21)
> #Platform: x86_64-w64-mingw32/x64 (64-bit)
> #Running under: Windows >= 8 x64 (build 9200)
>
> #locale:
> #  [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
> #[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> #[5] LC_TIME=English_United States.1252
> #attached base packages:
> #  [1] grid      stats     graphics  grDevices utils     datasets
> methods   base
> #other attached packages:
> #[1] survey_3.31-2   survival_2.39-4 Matrix_1.2-6    RCurl_1.95-4.8
> bitops_1.0-6
> #loaded via a namespace (and not attached):
> #[1] tools_3.3.1     splines_3.3.1   knitr_1.14      lattice_0.20-33
>
>
> Courtney Benjamin
>
> Broome-Tioga BOCES
>
> Automotive Technology II Teacher
>
> Located at Gault Toyota
>
> Doctoral Candidate-Educational Theory & Practice
>
> State University of New York at Binghamton
>
> cbenjami at btboces.org<mailto:cbenjami at btboces.org><mailto:cbenjami at btboces.org<mailto:cbenjami at btboces.org>>
>
> 607-763-8633<tel:607-763-8633>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From sewashm at gmail.com  Fri Oct 28 06:20:15 2016
From: sewashm at gmail.com (Ashta)
Date: Thu, 27 Oct 2016 23:20:15 -0500
Subject: [R] difference
Message-ID: <CADDFq3185Ly7v7dn9z_811wKYu8DbaBtc8Q=HytPK6Nf6As7RA@mail.gmail.com>

Hi all,

I want to calculate the difference  between successive row values to
the first row value within year.
How do I get that?

 Here is    the sample of data
Year   Num
2001    25
2001    75
2001   150
2002    30
2002    85
2002    95

Desired output
Year   Num  diff
2001    25       0
2001    75      50
2001  150    125
2002    30        0
2002    85      55
2002    95      65

Thank you.


From philipt900 at iinet.net.au  Fri Oct 28 11:08:50 2016
From: philipt900 at iinet.net.au (P Tennant)
Date: Fri, 28 Oct 2016 20:08:50 +1100
Subject: [R] difference
In-Reply-To: <CADDFq3185Ly7v7dn9z_811wKYu8DbaBtc8Q=HytPK6Nf6As7RA@mail.gmail.com>
References: <CADDFq3185Ly7v7dn9z_811wKYu8DbaBtc8Q=HytPK6Nf6As7RA@mail.gmail.com>
Message-ID: <581315A2.8090506@iinet.net.au>

Hi,

You could use an anonymous function to operate on each `year-block' of 
your dataset, then assign the result as a new column:

d <- data.frame(year=c(rep(2001, 3), rep(2002, 3)),
                 num=c(25,75,150,30,85,95))

d$diff <- unlist(by(d$num, d$year, function(x) x - x[1]))
d

   year num diff
1 2001  25    0
2 2001  75   50
3 2001 150  125
4 2002  30    0
5 2002  85   55
6 2002  95   65


Philip

On 28/10/2016 3:20 PM, Ashta wrote:
> Hi all,
>
> I want to calculate the difference  between successive row values to
> the first row value within year.
> How do I get that?
>
>   Here is    the sample of data
> Year   Num
> 2001    25
> 2001    75
> 2001   150
> 2002    30
> 2002    85
> 2002    95
>
> Desired output
> Year   Num  diff
> 2001    25       0
> 2001    75      50
> 2001  150    125
> 2002    30        0
> 2002    85      55
> 2002    95      65
>
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From manu.reddy52 at gmail.com  Fri Oct 28 11:33:52 2016
From: manu.reddy52 at gmail.com (Manohar Reddy)
Date: Fri, 28 Oct 2016 15:03:52 +0530
Subject: [R] Reg : : How to plot the live streaming graph in R ?
In-Reply-To: <CAKVAULP=m2RNptb93HrftZTJvNTDpkqbgWr3dt=G0KMeiEQ34g@mail.gmail.com>
References: <CADG9u0CwFaumjAG7Ln+=E8dOqTTrcRF4UKZ+j71g-rZwKmkFEw@mail.gmail.com>
	<CAKVAULP=m2RNptb93HrftZTJvNTDpkqbgWr3dt=G0KMeiEQ34g@mail.gmail.com>
Message-ID: <CADG9u0Cp+ucEZLAb9ic2YgY0FgRJzyaJrTp3WZ1_nih+p3=djA@mail.gmail.com>

Thanks Ulrik,

  Using 'reactive timer ' i was partially reached to my
achievement/requirement as when ever reactive timer triggered my graph
getting blinking  (PFA for same) but real streaming graph should not be
like that though at this moment i'm okay with this blinking.Here i have one
more reqirement like whenever my graph hit/corss the thresold value like 80
% , i need to get the email alert saying that graph reached to 80 as well
as i need to show the graph in different color usually red color whenver
it's crossed to thresold value,is it possiable in R ?

Thanks in Advance !!!

Manu.

On Fri, Oct 21, 2016 at 12:32 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> Hi Manu,
>
> I'm by far no expert, but if you use Shiny I believe you can refresh using
> 'reactiveTimer' and just plot the last n points
>
> HTH
> Ulrik
>
> On Fri, 21 Oct 2016 at 08:53 Manohar Reddy <manu.reddy52 at gmail.com> wrote:
>
>> Hi,
>>
>>
>>
>>   I have a data which is stored in sql table and in every minute data
>> inserting to this table .Now my requirement is I need to plot the live
>> streaming  graph as per below link or PFA. Can anyone help out me how to
>> do
>> that in R ?
>>
>>   link : http://www.highcharts.com/studies/live-server.htm
>>
>>  Thanks in Advance !
>>
>> ?Note :
>>
>>   The graph will be keep on moving .?
>>
>> *Manu.*
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 


*Manu.*
-------------- next part --------------
A non-text attachment was scrubbed...
Name: live_Streaming_graph_alerts.PNG
Type: image/png
Size: 29026 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161028/70b78d8a/attachment.png>

From leebisu at gmail.com  Fri Oct 28 10:30:37 2016
From: leebisu at gmail.com (=?UTF-8?B?7J207ZiE7Je0?=)
Date: Fri, 28 Oct 2016 17:30:37 +0900
Subject: [R] fPortfolio group constraint problem
Message-ID: <CALp_pStW_O=Li1yJQ+H0rOSiOVj47xo-RBAQZ7qtgYKEK0te1w@mail.gmail.com>

recently, I bought Portfolio optimization with R/Rmetrics
and i have some problem doing it (fPortfolio Package)



*group.1 = c("minsumW[ sec1 ] = 0.215688 " ,  "maxsumW[ sec1 ] = 0.3126 "
)  groupConstraints = c(group.1)  portfolioConstraints(ret, mv,
groupConstraints)*

it works, but




*x = 0.215688group.1 = c("minsumW[ sec1 ] = x " ,  "maxsumW[ sec1 ] =
0.3126 " )  groupConstraints = c(group.1)  portfolioConstraints(ret, mv,
groupConstraints)*

then, if i check the constraint, the error


*Warning message:NAs introduced by coercion*

I guess, if group constraint is not a numeric number, it cannot work.

How can i deal with it?
because group constraint level is different for backtest time, not a
constant numeric.

-- 

*? ? ?(Hyun-Yul Lee )*

Web : http://henryquant.blogspot.kr/

Mobile : +82 10 3057 0072

Email : *leebisu at gmail.com <leebisu at gmail.com>*

	[[alternative HTML version deleted]]


From Anusha.Indhira at controlsdata.com  Fri Oct 28 12:21:08 2016
From: Anusha.Indhira at controlsdata.com (Indhira, Anusha)
Date: Fri, 28 Oct 2016 10:21:08 +0000
Subject: [R] cosine similarity tf-idf
Message-ID: <CE1899A9C6A8D64099DFB344ECF0F7548DB4@DERCORCEXH02.ds-s.com>

Hi,

To find similar documents in a Corpus using cosine similarity, Is it necessary to calculate tf-idf weights while creating term document matrix or just term frequency is fine? Can anyone let me know what are advantages and disadvantages for both ways?

Thanks,
Anusha

This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.

	[[alternative HTML version deleted]]


From Anusha.Indhira at controlsdata.com  Fri Oct 28 14:07:31 2016
From: Anusha.Indhira at controlsdata.com (Indhira, Anusha)
Date: Fri, 28 Oct 2016 12:07:31 +0000
Subject: [R] lsa-cosine subscript out of bounds error
Message-ID: <CE1899A9C6A8D64099DFB344ECF0F7548DC4@DERCORCEXH02.ds-s.com>

Hi,

I have created a document term matrix from corpus.I would like to apply Cosine similarity to find similar documents,when I apply cosine(w.mt) I get " Error in x[,i] : Subscript out of bounds"
Can anyone let me know how to overcome this error?

Thanks,
alily
This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Fri Oct 28 15:03:37 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Fri, 28 Oct 2016 13:03:37 +0000
Subject: [R] lsa-cosine subscript out of bounds error
In-Reply-To: <CE1899A9C6A8D64099DFB344ECF0F7548DC4@DERCORCEXH02.ds-s.com>
References: <CE1899A9C6A8D64099DFB344ECF0F7548DC4@DERCORCEXH02.ds-s.com>
Message-ID: <CFE1593A-DB28-4775-8A7A-F5D5590DD949@txbiomed.org>

Anusha,

You have written to r-help multiple times and are still using HTML and failing to provide a reproducible example of your problem. Please read and comply with the posting guide.

Mark
R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On Oct 28, 2016, at 7:07 AM, Indhira, Anusha <Anusha.Indhira at controlsdata.com> wrote:
>
> Hi,
>
> I have created a document term matrix from corpus.I would like to apply Cosine similarity to find similar documents,when I apply cosine(w.mt) I get " Error in x[,i] : Subscript out of bounds"
> Can anyone let me know how to overcome this error?
>
> Thanks,
> alily
> This e-mail (including attachments) contains contents owned by Rolls-Royce plc and its subsidiaries, affiliated companies or customers and covered by the laws of England and Wales, Brazil, US, or Canada (federal, state or provincial). The information is intended to be confidential and may be legally privileged. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution, interception or copying of this communication is strictly prohibited and may subject you to further legal action. Reply to the sender if you received this email by accident, and then delete the email and any attachments.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From S.Ellison at LGCGroup.com  Fri Oct 28 15:20:17 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 28 Oct 2016 14:20:17 +0100
Subject: [R] lsa-cosine subscript out of bounds error
In-Reply-To: <CE1899A9C6A8D64099DFB344ECF0F7548DC4@DERCORCEXH02.ds-s.com>
References: <CE1899A9C6A8D64099DFB344ECF0F7548DC4@DERCORCEXH02.ds-s.com>
Message-ID: <1A8C1289955EF649A09086A153E26724040099681F@GBTEDVPEXCMB04.corp.lgc-group.com>

> I have created a document term matrix from corpus.I would like to apply
> Cosine similarity to find similar documents,when I apply cosine(w.mt) I get "
> Error in x[,i] : Subscript out of bounds"
> Can anyone let me know how to overcome this error?

Not specifically, from the information you have given.
But in general, subscript errors in a function are often caused by the user (you) supplying the wrong object type or an object with incorrect dimensions. So you could start by making sure w.mt is what cosine() expects. 

class(w.mt)
dim(w.mt)
str(w.mt)

could all help.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jholtman at gmail.com  Fri Oct 28 19:32:40 2016
From: jholtman at gmail.com (jim holtman)
Date: Fri, 28 Oct 2016 13:32:40 -0400
Subject: [R] difference
In-Reply-To: <CADDFq3185Ly7v7dn9z_811wKYu8DbaBtc8Q=HytPK6Nf6As7RA@mail.gmail.com>
References: <CADDFq3185Ly7v7dn9z_811wKYu8DbaBtc8Q=HytPK6Nf6As7RA@mail.gmail.com>
Message-ID: <CAAxdm-6vRKHTfwD+BeSwn+D7h0hOAbAXVpt04TT42kMHxbQuHQ@mail.gmail.com>

Here are a couple of other ways using 'dplyr' and 'data.table'

> require(dplyr)
> input <- read.table(text = "Year   Num
+ 2001    25
+ 2001    75
+ 2001   150
+ 2002    30
+ 2002    85
+ 2002    95", header = TRUE)
>
> input %>%
+     group_by(Year) %>%
+     mutate(diff = c(0, diff(Num)))
Source: local data frame [6 x 3]
Groups: Year [2]

   Year   Num  diff
  <int> <int> <dbl>
1  2001    25     0
2  2001    75    50
3  2001   150    75
4  2002    30     0
5  2002    85    55
6  2002    95    10
>
> # use data.table
> require(data.table)
Loading required package: data.table
data.table 1.9.6  For help type ?data.table or
https://github.com/Rdatatable/data.table/wiki
The fastest way to learn (by data.table authors):
https://www.datacamp.com/courses/data-analysis-the-data-table-way
-------------------------------------------------------------------------------------------------------
data.table + dplyr code now lives in dtplyr.
Please library(dtplyr)!
-------------------------------------------------------------------------------------------------------

Attaching package: ?data.table?

The following objects are masked from ?package:dplyr?:

    between, last

> setDT(input)  # convert to data.table
> input[, diff := c(0, diff(Num)), by = Year][]  # print output
   Year Num diff
1: 2001  25    0
2: 2001  75   50
3: 2001 150   75
4: 2002  30    0
5: 2002  85   55
6: 2002  95   10
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Oct 28, 2016 at 12:20 AM, Ashta <sewashm at gmail.com> wrote:
> Hi all,
>
> I want to calculate the difference  between successive row values to
> the first row value within year.
> How do I get that?
>
>  Here is    the sample of data
> Year   Num
> 2001    25
> 2001    75
> 2001   150
> 2002    30
> 2002    85
> 2002    95
>
> Desired output
> Year   Num  diff
> 2001    25       0
> 2001    75      50
> 2001  150    125
> 2002    30        0
> 2002    85      55
> 2002    95      65
>
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Fri Oct 28 19:34:44 2016
From: jholtman at gmail.com (jim holtman)
Date: Fri, 28 Oct 2016 13:34:44 -0400
Subject: [R] difference
In-Reply-To: <CADDFq3185Ly7v7dn9z_811wKYu8DbaBtc8Q=HytPK6Nf6As7RA@mail.gmail.com>
References: <CADDFq3185Ly7v7dn9z_811wKYu8DbaBtc8Q=HytPK6Nf6As7RA@mail.gmail.com>
Message-ID: <CAAxdm-6AzGhsq--=teTf3BaW3+gF978ipC70LHOSMi85QdjjcQ@mail.gmail.com>

I read the problem incorrectly; I did not see that you wanted the
difference from the first entry; trying again:

> require(dplyr)
> input <- read.table(text = "Year   Num
+ 2001    25
+ 2001    75
+ 2001   150
+ 2002    30
+ 2002    85
+ 2002    95", header = TRUE)
>
> input %>%
+     group_by(Year) %>%
+     mutate(diff = Num - Num[1L])
Source: local data frame [6 x 3]
Groups: Year [2]

   Year   Num  diff
  <int> <int> <int>
1  2001    25     0
2  2001    75    50
3  2001   150   125
4  2002    30     0
5  2002    85    55
6  2002    95    65
>
> # use data.table
> require(data.table)
> setDT(input)  # convert to data.table
> input[, diff := Num - Num[1L], by = Year][]  # print output
   Year Num diff
1: 2001  25    0
2: 2001  75   50
3: 2001 150  125
4: 2002  30    0
5: 2002  85   55
6: 2002  95   65

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Oct 28, 2016 at 12:20 AM, Ashta <sewashm at gmail.com> wrote:
> Hi all,
>
> I want to calculate the difference  between successive row values to
> the first row value within year.
> How do I get that?
>
>  Here is    the sample of data
> Year   Num
> 2001    25
> 2001    75
> 2001   150
> 2002    30
> 2002    85
> 2002    95
>
> Desired output
> Year   Num  diff
> 2001    25       0
> 2001    75      50
> 2001  150    125
> 2002    30        0
> 2002    85      55
> 2002    95      65
>
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Oct 28 19:46:15 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 28 Oct 2016 10:46:15 -0700
Subject: [R] difference
In-Reply-To: <CADDFq3185Ly7v7dn9z_811wKYu8DbaBtc8Q=HytPK6Nf6As7RA@mail.gmail.com>
References: <CADDFq3185Ly7v7dn9z_811wKYu8DbaBtc8Q=HytPK6Nf6As7RA@mail.gmail.com>
Message-ID: <CAF8bMcY=3rscy_rJgxE3XZwfr8hiQMooVAV_8eOaW82FUstryw@mail.gmail.com>

You could use match() to find, for each row, the index of the first
row with the give row's year:

> d <- data.frame(year=c(rep(2001, 3), rep(2002, 3)),
                  num=c(25,75,150,30,85,95))
> indexOfFirstOfYear <- with(d, match(year, year))
> indexOfFirstOfYear
[1] 1 1 1 4 4 4
> d$diff <- d$num - d$num[indexOfFirstOfYear]
> d
  year num diff
1 2001  25    0
2 2001  75   50
3 2001 150  125
4 2002  30    0
5 2002  85   55
6 2002  95   65


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Oct 27, 2016 at 9:20 PM, Ashta <sewashm at gmail.com> wrote:

> Hi all,
>
> I want to calculate the difference  between successive row values to
> the first row value within year.
> How do I get that?
>
>  Here is    the sample of data
> Year   Num
> 2001    25
> 2001    75
> 2001   150
> 2002    30
> 2002    85
> 2002    95
>
> Desired output
> Year   Num  diff
> 2001    25       0
> 2001    75      50
> 2001  150    125
> 2002    30        0
> 2002    85      55
> 2002    95      65
>
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Fri Oct 28 20:06:25 2016
From: chocold12 at gmail.com (lily li)
Date: Fri, 28 Oct 2016 12:06:25 -0600
Subject: [R] How to calculate row means while ignore NAs
Message-ID: <CAN5afy9GRkw4ZKay-BQPhnFc7bOA=hH4mX0F9fKgfZGSBi95iQ@mail.gmail.com>

Hi R users,

I have the dataframe as below:

w=c(5,6,7,8)
x=c(1,2,3,4)
y=c(1,2,3)
length(y)=4
z=data.frame(w,x,y)

z$mean1 <- rowMeans(subset(z, select = c(x, y)), na.rm = T)
z$mean2 <- rowMeans(subset(z, select = c(x, y)), na.rm=F)

  w x  y mean1 mean2
1 5 1  1     1     1
2 6 2  2     2     2
3 7 3  3     3     3
4 8 4 NA     4    NA

How to calculate mean value for the three columns, while default removing
NAs.
For example, for the fourth row, the mean value should be (8+4)/2 = 6

Thanks for your help.

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Fri Oct 28 20:15:36 2016
From: chocold12 at gmail.com (lily li)
Date: Fri, 28 Oct 2016 12:15:36 -0600
Subject: [R] How to calculate row means while ignore NAs
In-Reply-To: <CAN5afy9GRkw4ZKay-BQPhnFc7bOA=hH4mX0F9fKgfZGSBi95iQ@mail.gmail.com>
References: <CAN5afy9GRkw4ZKay-BQPhnFc7bOA=hH4mX0F9fKgfZGSBi95iQ@mail.gmail.com>
Message-ID: <CAN5afy_8AcMf3Ggo4s4PS07kQ8JFxqD0r+kuf6UcqkEV4b90Vg@mail.gmail.com>

My apologize, it has been solved. Just include w inside of select, such as:
select = c(w, x, y)

On Fri, Oct 28, 2016 at 12:06 PM, lily li <chocold12 at gmail.com> wrote:

> Hi R users,
>
> I have the dataframe as below:
>
> w=c(5,6,7,8)
> x=c(1,2,3,4)
> y=c(1,2,3)
> length(y)=4
> z=data.frame(w,x,y)
>
> z$mean1 <- rowMeans(subset(z, select = c(x, y)), na.rm = T)
> z$mean2 <- rowMeans(subset(z, select = c(x, y)), na.rm=F)
>
>   w x  y mean1 mean2
> 1 5 1  1     1     1
> 2 6 2  2     2     2
> 3 7 3  3     3     3
> 4 8 4 NA     4    NA
>
> How to calculate mean value for the three columns, while default removing
> NAs.
> For example, for the fourth row, the mean value should be (8+4)/2 = 6
>
> Thanks for your help.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Oct 28 22:14:31 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 28 Oct 2016 15:14:31 -0500
Subject: [R] difference
In-Reply-To: <CAF8bMcY=3rscy_rJgxE3XZwfr8hiQMooVAV_8eOaW82FUstryw@mail.gmail.com>
References: <CADDFq3185Ly7v7dn9z_811wKYu8DbaBtc8Q=HytPK6Nf6As7RA@mail.gmail.com>
	<CAF8bMcY=3rscy_rJgxE3XZwfr8hiQMooVAV_8eOaW82FUstryw@mail.gmail.com>
Message-ID: <289BD6F0-5AA8-46FB-9A8F-6BE6A270F6D0@dcn.davis.ca.us>

Haven't seen a solution using ave...

d$diff <- ave( d$num, d$year, FUN = function( v ) { v - v[ 1 ] } )
-- 
Sent from my phone. Please excuse my brevity.

On October 28, 2016 12:46:15 PM CDT, William Dunlap via R-help <r-help at r-project.org> wrote:
>You could use match() to find, for each row, the index of the first
>row with the give row's year:
>
>> d <- data.frame(year=c(rep(2001, 3), rep(2002, 3)),
>                  num=c(25,75,150,30,85,95))
>> indexOfFirstOfYear <- with(d, match(year, year))
>> indexOfFirstOfYear
>[1] 1 1 1 4 4 4
>> d$diff <- d$num - d$num[indexOfFirstOfYear]
>> d
>  year num diff
>1 2001  25    0
>2 2001  75   50
>3 2001 150  125
>4 2002  30    0
>5 2002  85   55
>6 2002  95   65
>
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>On Thu, Oct 27, 2016 at 9:20 PM, Ashta <sewashm at gmail.com> wrote:
>
>> Hi all,
>>
>> I want to calculate the difference  between successive row values to
>> the first row value within year.
>> How do I get that?
>>
>>  Here is    the sample of data
>> Year   Num
>> 2001    25
>> 2001    75
>> 2001   150
>> 2002    30
>> 2002    85
>> 2002    95
>>
>> Desired output
>> Year   Num  diff
>> 2001    25       0
>> 2001    75      50
>> 2001  150    125
>> 2002    30        0
>> 2002    85      55
>> 2002    95      65
>>
>> Thank you.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sat Oct 29 04:28:44 2016
From: sewashm at gmail.com (Ashta)
Date: Fri, 28 Oct 2016 21:28:44 -0500
Subject: [R] difference
In-Reply-To: <581315A2.8090506@iinet.net.au>
References: <CADDFq3185Ly7v7dn9z_811wKYu8DbaBtc8Q=HytPK6Nf6As7RA@mail.gmail.com>
	<581315A2.8090506@iinet.net.au>
Message-ID: <CADDFq330ZwBL4Tskk5zzsrjedkgRvm=GWEDdG8_RMONczvbhvA@mail.gmail.com>

Hi all thank you very much for your help. Worked very well for that
data set. I just found out that one of the data sets have another
level and do the same thing, I want to calculate the difference
between successive row values (num)  to the first row value within
city and year.

city, year, num
1, 2001,    25
1, 2001,    75
1, 2001,    150
1, 2002,    35
1, 2002,    65
1, 2002,    120
2, 2001,    25
2, 2001,    95
2, 2001,    150
2, 2002,    35
2, 2002,    110
2, 2002,    120

The result will be

city,year,num,Diff
1, 2001,    25, 0
1, 2001,    75, 50
1, 2001,    150, 125
1, 2002,    35, 0
1, 2002,    65, 30
1, 2002,    120, 85
2, 2001,    25, 0
2, 2001,    95, 70
2, 2001,    150, 125
2, 2002,    35, 0
2, 2002,    110, 75
2, 2002,    120, 85

Thank you again


On Fri, Oct 28, 2016 at 4:08 AM, P Tennant <philipt900 at iinet.net.au> wrote:
> Hi,
>
> You could use an anonymous function to operate on each `year-block' of your
> dataset, then assign the result as a new column:
>
> d <- data.frame(year=c(rep(2001, 3), rep(2002, 3)),
>                 num=c(25,75,150,30,85,95))
>
> d$diff <- unlist(by(d$num, d$year, function(x) x - x[1]))
> d
>
>   year num diff
> 1 2001  25    0
> 2 2001  75   50
> 3 2001 150  125
> 4 2002  30    0
> 5 2002  85   55
> 6 2002  95   65
>
>
> Philip
>
>
> On 28/10/2016 3:20 PM, Ashta wrote:
>>
>> Hi all,
>>
>> I want to calculate the difference  between successive row values to
>> the first row value within year.
>> How do I get that?
>>
>>   Here is    the sample of data
>> Year   Num
>> 2001    25
>> 2001    75
>> 2001   150
>> 2002    30
>> 2002    85
>> 2002    95
>>
>> Desired output
>> Year   Num  diff
>> 2001    25       0
>> 2001    75      50
>> 2001  150    125
>> 2002    30        0
>> 2002    85      55
>> 2002    95      65
>>
>> Thank you.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From jdnewmil at dcn.davis.ca.us  Sat Oct 29 06:15:39 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 28 Oct 2016 21:15:39 -0700
Subject: [R] difference
In-Reply-To: <CADDFq330ZwBL4Tskk5zzsrjedkgRvm=GWEDdG8_RMONczvbhvA@mail.gmail.com>
References: <CADDFq3185Ly7v7dn9z_811wKYu8DbaBtc8Q=HytPK6Nf6As7RA@mail.gmail.com>
	<581315A2.8090506@iinet.net.au>
	<CADDFq330ZwBL4Tskk5zzsrjedkgRvm=GWEDdG8_RMONczvbhvA@mail.gmail.com>
Message-ID: <9B430DD3-9A0E-418C-AD64-37F10F0F6DAB@dcn.davis.ca.us>

Now would be an excellent time to read the help page for ?ave. You can specify multiple grouping variables. 
-- 
Sent from my phone. Please excuse my brevity.

On October 28, 2016 7:28:44 PM PDT, Ashta <sewashm at gmail.com> wrote:
>Hi all thank you very much for your help. Worked very well for that
>data set. I just found out that one of the data sets have another
>level and do the same thing, I want to calculate the difference
>between successive row values (num)  to the first row value within
>city and year.
>
>city, year, num
>1, 2001,    25
>1, 2001,    75
>1, 2001,    150
>1, 2002,    35
>1, 2002,    65
>1, 2002,    120
>2, 2001,    25
>2, 2001,    95
>2, 2001,    150
>2, 2002,    35
>2, 2002,    110
>2, 2002,    120
>
>The result will be
>
>city,year,num,Diff
>1, 2001,    25, 0
>1, 2001,    75, 50
>1, 2001,    150, 125
>1, 2002,    35, 0
>1, 2002,    65, 30
>1, 2002,    120, 85
>2, 2001,    25, 0
>2, 2001,    95, 70
>2, 2001,    150, 125
>2, 2002,    35, 0
>2, 2002,    110, 75
>2, 2002,    120, 85
>
>Thank you again
>
>
>On Fri, Oct 28, 2016 at 4:08 AM, P Tennant <philipt900 at iinet.net.au>
>wrote:
>> Hi,
>>
>> You could use an anonymous function to operate on each `year-block'
>of your
>> dataset, then assign the result as a new column:
>>
>> d <- data.frame(year=c(rep(2001, 3), rep(2002, 3)),
>>                 num=c(25,75,150,30,85,95))
>>
>> d$diff <- unlist(by(d$num, d$year, function(x) x - x[1]))
>> d
>>
>>   year num diff
>> 1 2001  25    0
>> 2 2001  75   50
>> 3 2001 150  125
>> 4 2002  30    0
>> 5 2002  85   55
>> 6 2002  95   65
>>
>>
>> Philip
>>
>>
>> On 28/10/2016 3:20 PM, Ashta wrote:
>>>
>>> Hi all,
>>>
>>> I want to calculate the difference  between successive row values to
>>> the first row value within year.
>>> How do I get that?
>>>
>>>   Here is    the sample of data
>>> Year   Num
>>> 2001    25
>>> 2001    75
>>> 2001   150
>>> 2002    30
>>> 2002    85
>>> 2002    95
>>>
>>> Desired output
>>> Year   Num  diff
>>> 2001    25       0
>>> 2001    75      50
>>> 2001  150    125
>>> 2002    30        0
>>> 2002    85      55
>>> 2002    95      65
>>>
>>> Thank you.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>


From residuo.solow at gmail.com  Sat Oct 29 21:47:03 2016
From: residuo.solow at gmail.com (residuo.solow at gmail.com)
Date: Sat, 29 Oct 2016 16:47:03 -0300
Subject: [R] Can not update
Message-ID: <5814fcbf.2f26c80a.d3359.a98b@mx.google.com>

Dear R-Users:

I have an R installed in a Windows 10 machine.

Update doesn?t work:

> update.packages(ask='graphics',checkBuilt=TRUE)
--- Please select a CRAN mirror for use in this session ---
Warning: package 'cluster' in library 'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
Warning: package 'codetools' in library 'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
Warning: package 'foreign' in library 'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
Warning: package 'lattice' in library 'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
Warning: package 'Matrix' in library 'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
Warning: package 'mgcv' in library 'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
Warning: package 'survival' in library 'C:/Users/Public/Documents/R-3.3.1/library' will not be updated

What can I do?

Bye,

Sebas.

Enviado desde Correo para Windows 10


	[[alternative HTML version deleted]]


From stefac88 at gmail.com  Fri Oct 28 13:14:50 2016
From: stefac88 at gmail.com (Claudio Stefanini)
Date: Fri, 28 Oct 2016 13:14:50 +0200
Subject: [R] Problem with creation of netcdf file
Message-ID: <8e2b6270-494c-dac0-b713-0640cb764bc1@gmail.com>

Hello everyone!
I have a weird problem with the netcdf format: I want to save part of 
the lon-lat matrix "radar_ok_final" as .nc file, so I select the first 
271 columns (corrensponding to the first 271 values in the longitude 
vector "Longvector") and I get this plot from the netcdf file that I create:

http://s15.postimg.org/tfzzg435n/271.png

But if I select only the first 270 columns (and of course I modify 
"Longvector" in Longvector = lon_new_mosaico[c(1:270)]) I get this 
strange plot, translated and distorted, instead of the same plot above 
without the last column of data. Why?

http://s15.postimg.org/fkx3jwjcr/270.png

here is my code: # data
radar_ok_final <- radarok_mosaico[,c(1:271)] # then I change to c(1:270)
# write the ncdf files
Longvector = lon_new_mosaico[c(1:271)] # then I change to c(1:270)
Latvector = lat_new_mosaico
# Define the dimensions
dimX = ncdim_def("Long", "degreesE", Longvector)
dimY = ncdim_def("Lat", "degreesN", Latvector)
# Define missing value
mv = NA
# Define the data
var2d = ncvar_def("dBZ", "units", list(dimX,dimY), mv, prec="double", 
compression=9)
# Create the NetCDF file
# If you want a NetCDF4 file, explicitly add force_v4=T
nc = nc_create(paste("/home/radarmeteo.com/data_archive/",year, month, 
day,"/Mosaico/Radar_mosaico_",year, month, day,"_",hour, minutes1,".nc", 
sep=""), list(var2d), force_v4=T)
# Write data to the NetCDF file
ncvar_put(nc, var2d, matrix(radar_ok_final, nrow=length(Latvector), 
ncol=length(Longvector)))
# Close your new file to finish writing
nc_close(nc)

Thank you very much for the help!


From bwater at outlook.com  Fri Oct 28 16:00:02 2016
From: bwater at outlook.com (Be Water)
Date: Fri, 28 Oct 2016 16:00:02 +0200
Subject: [R] Predict ARMA GARCH model with new data
Message-ID: <BAY406-EAS2639D69369A0A297065EFF7CBAD0@phx.gbl>

How to add newdata to be predicted in an ARMA GARCH model with the fGARCH package?

## R version 3.3.1 (2016-06-21)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows >= 8 x64 (build 9200)

library(fGarch)

## Data simulation
set.seed(345)
ar.sim <- arima.sim(model=list(ar=c(.9,-.2)), n=1000) 
tail(ar.sim) 
plot(ar.sim)

## Model fit 
model = garchFit( ~ arma(1, 2) + garch(1, 1), Data=ar.sim) 
print(model)
help(garchFit,package="fGarch")

##QUESTION 1: How to add newdata to be predicted?
newdata <- data.frame(x= -0.3)
newdata <- -0.3
predict(model, newdata = newdata, n.ahead=1)[1,1]

##QUESTION 2: If this is the correct way, why do I get the same result with different newdata?
predict(model, newdata= -1.035, n.ahead=1)
predict(model, newdata= 0.124, n.ahead=1)
help(predict, package="fGarch")




	[[alternative HTML version deleted]]


From justin.bem at outlook.fr  Sat Oct 29 10:19:30 2016
From: justin.bem at outlook.fr (Justin Bem)
Date: Sat, 29 Oct 2016 08:19:30 +0000
Subject: [R] Hmisc::latex and the use of \phantom
Message-ID: <VI1PR08MB0477BDF615CD1E0309F77396F2AC0@VI1PR08MB0477.eurprd08.prod.outlook.com>

Dear all,



Is it possible to avoid the use of \phantom with latex function ? when I run latex(latex=FALSE,?) I get an error message.



When I use Format(big.mark= ?? ??) the result appear correct in R console but not in Latex code. Is it a way to combine numprint with latex ? col.just= ?n{#}{#}? donc work



Sincerly.



Provenance : Courrier<http://go.microsoft.com/fwlink/?LinkId=550986> pour Windows 10

	[[alternative HTML version deleted]]


From elhamdallalbashi at gmail.com  Sat Oct 29 18:01:28 2016
From: elhamdallalbashi at gmail.com (Elham Dallalbashi)
Date: Sat, 29 Oct 2016 19:31:28 +0330
Subject: [R] Convert matrix
In-Reply-To: <CAJpR6yifOxS_xUtj=y8NpbS9XpZJweE0uGzL1FNthtHzTbqA7A@mail.gmail.com>
References: <CAJpR6yifOxS_xUtj=y8NpbS9XpZJweE0uGzL1FNthtHzTbqA7A@mail.gmail.com>
Message-ID: <CAJpR6ygNAPtTjaDdwuAF7kr4DGyAuHHt60+Q=jaXsUDQ3PkSAQ@mail.gmail.com>

> Dear Madam / Sir,
> I saw this function for "*Convert to matrix as it is that you wanted" *
>
> >* test2<-as.matrix(test1)
> *>* colnames(test2)<-NULL
> *>* genelist<-c("Fkh2","Swi5","Sic1")
> *>* rownames(test2)<-genelist
> *>* test2
> *>* #      [,1]  [,2]  [,3]
> *>* #Fkh2 0.141 0.242 0.342
> *>* #Swi5 0.224 0.342 0.334
> *>* #Sic1 0.652 0.682 0.182*
>
>
>
>
> what is function for large data?my data and genelist are 28031 rows,how
> can I convert? clear that I can not write 28031 genes like
> *genelist<-c("Fkh2","Swi5","Sic1")*
>
>
>
> Your attention would be really appreciated.
>
> Best Regards,
>
> Elham Dalalbshi Esfahani
>

	[[alternative HTML version deleted]]


From ed_isfahani at yahoo.com  Sat Oct 29 18:17:07 2016
From: ed_isfahani at yahoo.com (Elham -)
Date: Sat, 29 Oct 2016 16:17:07 +0000 (UTC)
Subject: [R] (no subject)
References: <454539698.342511.1477757827704.ref@mail.yahoo.com>
Message-ID: <454539698.342511.1477757827704@mail.yahoo.com>

Dear Madam / Sir,I saw this function for "Convert to matrix as it is that you wanted" > test2<-as.matrix(test1)
> colnames(test2)<-NULL
> genelist<-c("Fkh2","Swi5","Sic1")
> rownames(test2)<-genelist
> test2
> #????? [,1]? [,2]? [,3]
> #Fkh2 0.141 0.242 0.342
> #Swi5 0.224 0.342 0.334
> #Sic1 0.652 0.682 0.182


what is function for large data?my data and genelist are 28031 rows,how can I convert? clear that I can not write 28031 genes like?genelist<-c("Fkh2","Swi5","Sic1")


Your attention would be really appreciated.Best Regards,Elham Dalalbshi Esfahani
	[[alternative HTML version deleted]]


From ed_isfahani at yahoo.com  Sat Oct 29 18:19:58 2016
From: ed_isfahani at yahoo.com (Elham -)
Date: Sat, 29 Oct 2016 16:19:58 +0000 (UTC)
Subject: [R] convert matrix
References: <1568078179.330562.1477757998067.ref@mail.yahoo.com>
Message-ID: <1568078179.330562.1477757998067@mail.yahoo.com>

Dear Madam / Sir,I saw this function for "Convert to matrix as it is that you wanted" > test2<-as.matrix(test1)
> colnames(test2)<-NULL
> genelist<-c("Fkh2","Swi5","Sic1")
> rownames(test2)<-genelist
> test2
> #????? [,1]? [,2]? [,3]
> #Fkh2 0.141 0.242 0.342
> #Swi5 0.224 0.342 0.334
> #Sic1 0.652 0.682 0.182


what is function for large data?my data and genelist are 28031 rows,how can I convert? clear that I can not write 28031 genes like?genelist<-c("Fkh2","Swi5","Sic1")


Your attention would be really appreciated.Best Regards,Elham Dalalbshi Esfahani

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Oct 30 00:07:22 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 29 Oct 2016 15:07:22 -0700
Subject: [R] Can not update
In-Reply-To: <5814fcbf.2f26c80a.d3359.a98b@mx.google.com>
References: <5814fcbf.2f26c80a.d3359.a98b@mx.google.com>
Message-ID: <95187377-240D-4B87-87F3-F00D2A7846A6@dcn.davis.ca.us>

I suspect your difficulty arises because you have installed your library in the Public directory... but I don't use Windows 10 so I could be wrong. Have you tried uninstalling and installing with default configuration, not using Run As Administrator but letting Windows prompt you for your password as needed? 
-- 
Sent from my phone. Please excuse my brevity.

On October 29, 2016 12:47:03 PM PDT, residuo.solow at gmail.com wrote:
>Dear R-Users:
>
>I have an R installed in a Windows 10 machine.
>
>Update doesn?t work:
>
>> update.packages(ask='graphics',checkBuilt=TRUE)
>--- Please select a CRAN mirror for use in this session ---
>Warning: package 'cluster' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>Warning: package 'codetools' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>Warning: package 'foreign' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>Warning: package 'lattice' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>Warning: package 'Matrix' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>Warning: package 'mgcv' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>Warning: package 'survival' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>
>What can I do?
>
>Bye,
>
>Sebas.
>
>Enviado desde Correo para Windows 10
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From residuo.solow at gmail.com  Sun Oct 30 00:55:40 2016
From: residuo.solow at gmail.com (Sebastian)
Date: Sat, 29 Oct 2016 19:55:40 -0300
Subject: [R] Can not update
In-Reply-To: <95187377-240D-4B87-87F3-F00D2A7846A6@dcn.davis.ca.us>
References: <5814fcbf.2f26c80a.d3359.a98b@mx.google.com>
	<95187377-240D-4B87-87F3-F00D2A7846A6@dcn.davis.ca.us>
Message-ID: <5815290e.0d63370a.11102.da92@mx.google.com>

Finally I use RStudio to do it. 
I don't know what it was the problem.

Thanks,

Sebastian .

-----Mensaje original-----
De: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
Enviado el: ?29/?10/?2016 19:07
Para: "residuo.solow at gmail.com" <residuo.solow at gmail.com>; "R-help" <r-help at r-project.org>
Asunto: Re: [R] Can not update

I suspect your difficulty arises because you have installed your library in the Public directory... but I don't use Windows 10 so I could be wrong. Have you tried uninstalling and installing with default configuration, not using Run As Administrator but letting Windows prompt you for your password as needed? 
-- 
Sent from my phone. Please excuse my brevity.

On October 29, 2016 12:47:03 PM PDT, residuo.solow at gmail.com wrote:
>Dear R-Users:
>
>I have an R installed in a Windows 10 machine.
>
>Update doesn?t work:
>
>> update.packages(ask='graphics',checkBuilt=TRUE)
>--- Please select a CRAN mirror for use in this session ---
>Warning: package 'cluster' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>Warning: package 'codetools' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>Warning: package 'foreign' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>Warning: package 'lattice' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>Warning: package 'Matrix' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>Warning: package 'mgcv' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>Warning: package 'survival' in library
>'C:/Users/Public/Documents/R-3.3.1/library' will not be updated
>
>What can I do?
>
>Bye,
>
>Sebas.
>
>Enviado desde Correo para Windows 10
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From philipt900 at iinet.net.au  Sun Oct 30 02:57:06 2016
From: philipt900 at iinet.net.au (P Tennant)
Date: Sun, 30 Oct 2016 12:57:06 +1100
Subject: [R] difference
In-Reply-To: <9B430DD3-9A0E-418C-AD64-37F10F0F6DAB@dcn.davis.ca.us>
References: <CADDFq3185Ly7v7dn9z_811wKYu8DbaBtc8Q=HytPK6Nf6As7RA@mail.gmail.com>
	<581315A2.8090506@iinet.net.au>
	<CADDFq330ZwBL4Tskk5zzsrjedkgRvm=GWEDdG8_RMONczvbhvA@mail.gmail.com>
	<9B430DD3-9A0E-418C-AD64-37F10F0F6DAB@dcn.davis.ca.us>
Message-ID: <58155372.5060404@iinet.net.au>

Hi,

As Jeff said, more than one grouping variable can be supplied, and there 
is an example at the bottom of the help page for ave(). The same goes 
for by(), but the order that you supply the grouping variables becomes 
important. Whichever grouping variable is supplied first to by() will 
change its levels first in the output sequence. You can see from your 
dataset:

d2 <- data.frame(city=rep(1:2, ea=6),
     year=c(rep(2001, 3), rep(2002, 3), rep(2001, 3), rep(2002, 3)),
     num=c(25,75,150,35,65,120,25,95,150,35,110,120))

d2
    # city year num
# 1     1 2001  25
# 2     1 2001  75
# 3     1 2001 150
# 4     1 2002  35
# 5     1 2002  65
# 6     1 2002 120
# 7     2 2001  25
# 8     2 2001  95
# 9     2 2001 150
# 10    2 2002  35
# 11    2 2002 110
# 12    2 2002 120

that `year' changes its levels through the sequence down the table 
first, and then `city' changes. You want your new column to align with 
this sequence. If you put city first in the list of grouping variables 
for by(), rather than `year', you won't get the sequence reflected in 
your dataset:

by(d2$num, d2[c('city', 'year')], function(x) x - x[1])

# city: 1
# year: 2001
# [1]   0  50 125
# -----------------------------
# city: 2
# year: 2001
# [1]   0  70 125
# -----------------------------
# city: 1
# year: 2002
# [1]  0 30 85
# -----------------------------
# city: 2
# year: 2002
# [1]  0 75 85

In contrast to using by() as I've suggested, using match() to create 
indices that flag when a new `city/year' category is encountered seems a 
more explicit, secure way to do the calculation. Adapting an earlier 
solution provided in this thread:

year.city <- with(d2, interaction(year, city))
indexOfFirstYearCity <- match(year.city, year.city)
indexOfFirstYearCity
# [1]  1  1  1  4  4  4  7  7  7 10 10 10

d2$diff <- d2$num - d2$num[indexOfFirstYearCity]
d2

   city year num diff
1     1 2001  25    0
2     1 2001  75   50
3     1 2001 150  125
4     1 2002  35    0
5     1 2002  65   30
6     1 2002 120   85
7     2 2001  25    0
8     2 2001  95   70
9     2 2001 150  125
10    2 2002  35    0
11    2 2002 110   75
12    2 2002 120   85


Philip

On 29/10/2016 3:15 PM, Jeff Newmiller wrote:
> Now would be an excellent time to read the help page for ?ave. You can specify multiple grouping variables.


From dulcalma at bigpond.com  Sun Oct 30 05:26:10 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sun, 30 Oct 2016 15:26:10 +1100
Subject: [R] How to create a list of trellis objects for grid.arrange()
In-Reply-To: <CALPC6DPgXuMXYKEKc=yW_imraLGPMKcB9ix9U5h1VE72BXDQZQ@mail.gmail.com>
References: <CALPC6DPgXuMXYKEKc=yW_imraLGPMKcB9ix9U5h1VE72BXDQZQ@mail.gmail.com>
Message-ID: <000001d23265$be1be2f0$3a53a8d0$@bigpond.com>

Hi

I did not have a look at this when it was sent as I thought it dealt with
ggplot objects 

If you have trellis objects (check by str())or ?class) try printing them 

print(p2, position = (c(0,0,1,0.5), more =T)
print(p1, position = (c(0,0.5,1,1), more = F)

The only other way that I can think of is using viewports
 ? grid::viewports

If it is base graphics then ? layout  may fix it

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Agustin Lobo
Sent: Thursday, 27 October 2016 23:58
To: r-help at r-project.org
Subject: [R] How to create a list of trellis objects for grid.arrange()

Given
require(raster)
require(sp)
require(gridExtra)

f <- system.file("external/test.grd", package="raster")
r <- raster(f)
p1 <- spplot(r)
p2 <- spplot(r)

I would like to plot the equivalent to

grid.arrange(p1,p2,ncol=1,nrow=2)

but keeping the trellis objects p1 and p2 within one single object (as
in practice I have many objects generated within a for() loop).

The following used to work:
ps <- c(p1,p2)
grid.arrange(ps,ncol=1,nrow=2)

but does not work any more.

How should I combine p1 and p2 into one single object that would be
accepted by grid.arrange?

Thanks
-- 
Agustin Lobo
aloboaleu at gmail.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Oct 30 10:30:07 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 30 Oct 2016 20:30:07 +1100
Subject: [R] Convert matrix
In-Reply-To: <CAJpR6ygNAPtTjaDdwuAF7kr4DGyAuHHt60+Q=jaXsUDQ3PkSAQ@mail.gmail.com>
References: <CAJpR6yifOxS_xUtj=y8NpbS9XpZJweE0uGzL1FNthtHzTbqA7A@mail.gmail.com>
	<CAJpR6ygNAPtTjaDdwuAF7kr4DGyAuHHt60+Q=jaXsUDQ3PkSAQ@mail.gmail.com>
Message-ID: <CA+8X3fXep52qnddCiaQHSWHnXuxVQcYVoRPBJECNWrXkc+uX0Q@mail.gmail.com>

Hi Elham,
As you have asked this question a large number of times in quite a few
places, and have received reasonable answers, I assume that you
already know that the gene names and associated values are in another
format. What you probably want to do is to convert the first column of
the data that you have imported into rownames:

test2a<-(test2[,-1])
rownames(test2a)<-test2[,1]

Why do I guess this? Because the values in a matrix must all be of the
same data type and you probably have a data frame in which the first
column is the names. You want the numeric values in the subsequent
columns to become a matrix. Perhaps I have guessed correctly. Perhaps
not.

Jim


On Sun, Oct 30, 2016 at 3:01 AM, Elham Dallalbashi
<elhamdallalbashi at gmail.com> wrote:
>> Dear Madam / Sir,
>> I saw this function for "*Convert to matrix as it is that you wanted" *
>>
>> >* test2<-as.matrix(test1)
>> *>* colnames(test2)<-NULL
>> *>* genelist<-c("Fkh2","Swi5","Sic1")
>> *>* rownames(test2)<-genelist
>> *>* test2
>> *>* #      [,1]  [,2]  [,3]
>> *>* #Fkh2 0.141 0.242 0.342
>> *>* #Swi5 0.224 0.342 0.334
>> *>* #Sic1 0.652 0.682 0.182*
>>
>>
>>
>>
>> what is function for large data?my data and genelist are 28031 rows,how
>> can I convert? clear that I can not write 28031 genes like
>> *genelist<-c("Fkh2","Swi5","Sic1")*
>>
>>
>>
>> Your attention would be really appreciated.
>>
>> Best Regards,
>>
>> Elham Dalalbshi Esfahani
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From btupper at bigelow.org  Sun Oct 30 14:20:44 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Sun, 30 Oct 2016 09:20:44 -0400
Subject: [R] How to create a list of trellis objects for grid.arrange()
In-Reply-To: <000001d23265$be1be2f0$3a53a8d0$@bigpond.com>
References: <CALPC6DPgXuMXYKEKc=yW_imraLGPMKcB9ix9U5h1VE72BXDQZQ@mail.gmail.com>
	<000001d23265$be1be2f0$3a53a8d0$@bigpond.com>
Message-ID: <082C75EB-77EA-44D7-A41E-55A033A61558@bigelow.org>

Hi,

You might try gridExtra::marrangeGrob()

require(raster)
require(sp)
require(gridExtra)

f <- system.file("external/test.grd", package="raster")
r <- raster(f)
p1 <- spplot(r)
p2 <- spplot(r/2)

ps <- list(p1,p2)
mm <- marrangeGrob(ps, ncol=1, nrow=2, top = 'foo')

mm


The above generates the two plots arranged vertically.  Note that if I use ps <- c(p1,p2) instead of ps <- list(p1,p2) the marrangeGrob() function throws an error.  Unlike list(), c() coerces the components to a common type, which, in this case, I guess isn't 'trellis'.  Check out the values of str(c(p1, p2)) vs str(list(p1,p2)).   


> ps <- c(p1,p2)
> mm <- marrangeGrob(ps, ncol=1, nrow=2, top = 'foo')
Error in (function (..., grobs = list(...), layout_matrix, vp = NULL,  : 
  could not find function "levelplot"


Cheers,
Ben

> On Oct 30, 2016, at 12:26 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> 
> Hi
> 
> I did not have a look at this when it was sent as I thought it dealt with
> ggplot objects 
> 
> If you have trellis objects (check by str())or ?class) try printing them 
> 
> print(p2, position = (c(0,0,1,0.5), more =T)
> print(p1, position = (c(0,0.5,1,1), more = F)
> 
> The only other way that I can think of is using viewports
> ? grid::viewports
> 
> If it is base graphics then ? layout  may fix it
> 
> Regards
> 
> Duncan
> 
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Agustin Lobo
> Sent: Thursday, 27 October 2016 23:58
> To: r-help at r-project.org
> Subject: [R] How to create a list of trellis objects for grid.arrange()
> 
> Given
> require(raster)
> require(sp)
> require(gridExtra)
> 
> f <- system.file("external/test.grd", package="raster")
> r <- raster(f)
> p1 <- spplot(r)
> p2 <- spplot(r)
> 
> I would like to plot the equivalent to
> 
> grid.arrange(p1,p2,ncol=1,nrow=2)
> 
> but keeping the trellis objects p1 and p2 within one single object (as
> in practice I have many objects generated within a for() loop).
> 
> The following used to work:
> ps <- c(p1,p2)
> grid.arrange(ps,ncol=1,nrow=2)
> 
> but does not work any more.
> 
> How should I combine p1 and p2 into one single object that would be
> accepted by grid.arrange?
> 
> Thanks
> -- 
> Agustin Lobo
> aloboaleu at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From rbaer at atsu.edu  Sun Oct 30 16:20:27 2016
From: rbaer at atsu.edu (Robert Baer)
Date: Sun, 30 Oct 2016 10:20:27 -0500
Subject: [R] convert matrix
In-Reply-To: <1568078179.330562.1477757998067@mail.yahoo.com>
References: <1568078179.330562.1477757998067.ref@mail.yahoo.com>
	<1568078179.330562.1477757998067@mail.yahoo.com>
Message-ID: <f6aa59fd-7184-f85b-1c1b-17b5f7253b54@atsu.edu>



On 10/29/2016 11:19 AM, Elham - via R-help wrote:
> Dear Madam / Sir,I saw this function for "Convert to matrix as it is that you wanted" > test2<-as.matrix(test1)
>> colnames(test2)<-NULL
>> genelist<-c("Fkh2","Swi5","Sic1")
>> rownames(test2)<-genelist
>> test2
>> #      [,1]  [,2]  [,3]
>> #Fkh2 0.141 0.242 0.342
>> #Swi5 0.224 0.342 0.334
>> #Sic1 0.652 0.682 0.182
>
> what is function for large data?my data and genelist are 28031 rows,how can I convert? clear that I can not write 28031 genes like genelist<-c("Fkh2","Swi5","Sic1")
You can assign the names of your genes by any method convenient. The 
point is not necessarily to use the c() function.   If you have them in 
a .csv file somewhere, simply read them in to create the genelist vector.

If you do not know how to to this you should probably read, "An 
Introduction to R", 
https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf

?read.csv typed at the command prompt will give you some specifics

In the end, you will do something like:
genelist  <- read.csv("AfileOfMyGenes.csv", header = TRUE)

# assume your gene names are in the first column which is titled genename
genelist <- genelist$genename



>
> Your attention would be really appreciated.Best Regards,Elham Dalalbshi Esfahani
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Oct 30 19:43:26 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 30 Oct 2016 11:43:26 -0700
Subject: [R] Predict ARMA GARCH model with new data
In-Reply-To: <BAY406-EAS2639D69369A0A297065EFF7CBAD0@phx.gbl>
References: <BAY406-EAS2639D69369A0A297065EFF7CBAD0@phx.gbl>
Message-ID: <40725D57-4AAF-461C-9EE6-F6FC4B26AD22@comcast.net>


> On Oct 28, 2016, at 7:00 AM, Be Water <bwater at outlook.com> wrote:
> 
> How to add newdata to be predicted in an ARMA GARCH model with the fGARCH package?
> 
> ## R version 3.3.1 (2016-06-21)
> ## Platform: x86_64-w64-mingw32/x64 (64-bit)
> ## Running under: Windows >= 8 x64 (build 9200)
> 
> library(fGarch)
> 
> ## Data simulation
> set.seed(345)
> ar.sim <- arima.sim(model=list(ar=c(.9,-.2)), n=1000) 
> tail(ar.sim) 
> plot(ar.sim)
> 
> ## Model fit 
> model = garchFit( ~ arma(1, 2) + garch(1, 1), Data=ar.sim) 
> print(model)
> help(garchFit,package="fGarch")
> 
> ##QUESTION 1: How to add newdata to be predicted?
> newdata <- data.frame(x= -0.3)
> newdata <- -0.3
> predict(model, newdata = newdata, n.ahead=1)[1,1]
> 
> ##QUESTION 2: If this is the correct way, why do I get the same result with different newdata?
> predict(model, newdata= -1.035, n.ahead=1)
> predict(model, newdata= 0.124, n.ahead=1)
> help(predict, package="fGarch")
> 

Try this:

help('predict-methods', pac=fGarch)

Generally there is a fallback to the original data when the argument to `newdata` is malformed. I don't see any dependence on a varaible named either "x"  in the construction of `model`, nor do I even see an argument named `newdata` in the predict method for fGarch. Look at the examples on that help page. I think you are incorrectly generalizing expectations about model objects to this package.
> 
> 	[[alternative HTML version deleted]]
> 
And learn to use plain text.

-- 
David.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From betelguiese at gmail.com  Sun Oct 30 00:07:33 2016
From: betelguiese at gmail.com (betelguiese at gmail.com)
Date: Sat, 29 Oct 2016 17:07:33 -0500
Subject: [R] Error Message when executing wordcloud(bd_clean)
Message-ID: <CACNpEBkZOpR888uMexYHPX9EcTtQAa+Di54z5BbLgHh=X=OCVA@mail.gmail.com>

Hello everybody

I am using RStudio version 0.99.903, and recently installed and loaded the
package wordcloud.  My platform is Mac OS Sierra.

I came across the following error message when I execute the command line
wordcloud(bd_clean):

> wordcloud(bd_clean)
Error in if (min.freq > max(freq)) min.freq <- 0 :
missing value where TRUE/FALSE needed
In addition: Warning messages:
1: In mclapply(unname(content(x)), termFreq, control) :
scheduled cores 2 encountered errors in user code, all values of the jobs
will be affected
2: In simple_triplet_matrix(i = i, j = j, v = as.numeric(v), nrow =
length(allTerms), :
NAs introduced by coercion

I have a hunch it may have something to do with my RStudio working
directory and the wordcloud package installed.  I created this post to see
if anybody have come across similar error before?  If so, can someone help
to shed some light to what this error means, and what are the workarounds
available for this error.

Thank you in advance for your responses

Best regards


------------------------------------------
Khairil Anuar SULONG AHMAD

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Oct 31 08:07:23 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 31 Oct 2016 00:07:23 -0700
Subject: [R] Error Message when executing wordcloud(bd_clean)
In-Reply-To: <CACNpEBkZOpR888uMexYHPX9EcTtQAa+Di54z5BbLgHh=X=OCVA@mail.gmail.com>
References: <CACNpEBkZOpR888uMexYHPX9EcTtQAa+Di54z5BbLgHh=X=OCVA@mail.gmail.com>
Message-ID: <88810D78-7FA4-43CC-8CEC-5742F7BE65DD@dcn.davis.ca.us>

A) Please post in plain text so your code doesn't get mangled by HTML.

B) Please provide a reproducible example. [1] [2]

C) RStudio is probably not the problem, but if it is then this is the wrong place to ask about that (see the RStudio website for help with that software). Simply try your code directly in R to verify that RStudio is not the problem, and then leave it out of your questions asked here from now on. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html
-- 
Sent from my phone. Please excuse my brevity.

On October 29, 2016 3:07:33 PM PDT, betelguiese at gmail.com wrote:
>Hello everybody
>
>I am using RStudio version 0.99.903, and recently installed and loaded
>the
>package wordcloud.  My platform is Mac OS Sierra.
>
>I came across the following error message when I execute the command
>line
>wordcloud(bd_clean):
>
>> wordcloud(bd_clean)
>Error in if (min.freq > max(freq)) min.freq <- 0 :
>missing value where TRUE/FALSE needed
>In addition: Warning messages:
>1: In mclapply(unname(content(x)), termFreq, control) :
>scheduled cores 2 encountered errors in user code, all values of the
>jobs
>will be affected
>2: In simple_triplet_matrix(i = i, j = j, v = as.numeric(v), nrow =
>length(allTerms), :
>NAs introduced by coercion
>
>I have a hunch it may have something to do with my RStudio working
>directory and the wordcloud package installed.  I created this post to
>see
>if anybody have come across similar error before?  If so, can someone
>help
>to shed some light to what this error means, and what are the
>workarounds
>available for this error.
>
>Thank you in advance for your responses
>
>Best regards
>
>
>------------------------------------------
>Khairil Anuar SULONG AHMAD
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From chienpang.c at gmail.com  Mon Oct 31 10:17:48 2016
From: chienpang.c at gmail.com (Chien-Pang Chin)
Date: Mon, 31 Oct 2016 17:17:48 +0800
Subject: [R] Predicition and CI for lognormal model
Message-ID: <003101d23357$a7e80de0$f7b829a0$@gmail.com>

Hi, everyone

 

I have a model like.

 

cpue=catch*1000/Hook

glmmodel=glm(log(cpue)~yy+qq+cc+pp, family=gaussian)

 

and I want to estimate yy, qq, cc, pp effect and CI

 

A senior scientist suggested to use

        

        

        model <- cbind(yhat=predict.glm(glmmodel, se.fit=T), DATA)

yy_effect = with(model, tapply(fit, yy, mean))

yy_effect.se = with(model, tapply(se.fit, yy, mean))

STD_CPUE_yy = exp(yy_effect+yy_effect.se/2);

    

It's confusing me, because I don't understand 1). why calculate mean first
before exp, 2). why +se/2 and 3). How can I calculate CI for STD_CPUE_yy?

 

My previous code was.

 

        yhat = predict.glm(glmmodel, se.fit=T,interval = "predict")

pcpue =exp(yhat$fit)

   pcatch = pcpue*yftcpue$Hook/1000

model=cbind(yftcpue,pcatch,pcpue)

   

 #calculate mean predication for each yy

yypcatch= with(model, tapply(pcatch, yy, sum))

   yyhook= with(model, tapply(Hook, yy, sum))

    yypcatch/yyhook*1000

 

# calculate CI for each yy

        upp= model$fit+1.96*model$se.fit

        low= model$fit-1.96*model$se.fit

    

thanks for help

 

 


	[[alternative HTML version deleted]]


From pd.mes at cbs.dk  Mon Oct 31 11:22:44 2016
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Mon, 31 Oct 2016 10:22:44 +0000
Subject: [R]   R 3.3.2 is released
Message-ID: <21996647-C176-4770-8EBC-04DD17881E7D@cbs.dk>

The build system rolled up R-3.3.2.tar.gz (codename "Sincere Pumpkin Patch") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.3.2.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard


These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = eb97a5cd38acb1cfc6408988bffef765
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 342856fe28ac8af7c8d48db1f6dde8e2
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 3edf7e6a206a1303ed50979fb21d2ab7
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 8e2f4d1d5228663ae598a09bf1e2bc6b
MD5 (R-latest.tar.gz) = 2437014ef40641cdc9673e89c040b7a8
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = f80d02e7ba9729a927e1c9cf7b435b32
MD5 (VERSION-INFO.dcf) = c643e0eb5a8e98b034f76287c574be32
MD5 (R-3/R-3.3.2.tar.gz) = 2437014ef40641cdc9673e89c040b7a8



This is the relevant part of the NEWS file

CHANGES IN R 3.3.2:

  NEW FEATURES:

    * extSoftVersion() now reports the version (if any) of the readline
      library in use.

    * The version of LAPACK included in the sources has been updated to
      3.6.1, a bug-fix release including a speedup for the
      non-symmetric case of eigen().

    * Use options(deparse.max.lines=) to limit the number of lines
      recorded in .Traceback and other deparsing activities.

    * format(<AsIs>) looks more regular, also for non-character atomic
      matrices.

    * abbreviate() gains an option named = TRUE.

    * The online documentation for package methods is extensively
      rewritten.  The goals are to simplify documentation for basic
      use, to note old features not recommended and to correct
      out-of-date information.

    * Calls to setMethod() no longer print a message when creating a
      generic function in those cases where that is natural: S3
      generics and primitives.

  INSTALLATION and INCLUDED SOFTWARE:

    * Versions of the readline library >= 6.3 had been changed so that
      terminal window resizes were not signalled to readline: code has
      been added using a explicit signal handler to work around that
      (when R is compiled against readline >= 6.3).  (PR#16604)

    * configure works better with Oracle Developer Studio 12.5.

  UTILITIES:

    * R CMD check reports more dubious flags in files
      src/Makevars[.in], including -w and -g.

    * R CMD check has been set up to filter important warnings from
      recent versions of gfortran with -Wall -pedantic: this now
      reports non-portable GNU extensions such as out-of-order
      declarations.

    * R CMD config works better with paths containing spaces, even
      those of home directories (as reported by Ken Beath).

  DEPRECATED AND DEFUNCT:

    * Use of the C/C++ macro NO_C_HEADERS is deprecated (no C headers
      are included by R headers from C++ as from R 3.3.0, so it should
      no longer be needed).

  BUG FIXES:

    * The check for non-portable flags in R CMD check could be stymied
      by src/Makevars files which contained targets.

    * (Windows only) When using certain desktop themes in Windows 7 or
      higher, Alt-Tab could cause Rterm to stop accepting input.
      (PR#14406; patch submitted by Jan Gleixner.)

    * pretty(d, ..) behaves better for date-time d (PR#16923).

    * When an S4 class name matches multiple classes in the S4 cache,
      perform a dynamic search in order to obey namespace imports.
      This should eliminate annoying messages about multiple hits in
      the class cache.  Also, pass along the package from the
      ClassExtends object when looking up superclasses in the cache.

    * sample(NA_real_) now works.

    * Packages using non-ASCII encodings in their code did not install
      data properly on systems using different encodings.

    * merge(df1, df2) now also works for data frames with column names
      "na.last", "decreasing", or "method".  (PR#17119)

    * contour() caused a segfault if the labels argument had length
      zero.  (Reported by Bill Dunlap.)

    * unique(warnings()) works more correctly, thanks to a new
      duplicated.warnings() method.

    * findInterval(x, vec = numeric(), all.inside = TRUE) now returns
      0s as documented.  (Reported by Bill Dunlap.)

    * (Windows only) R CMD SHLIB failed when a symbol in the resulting
      library had the same name as a keyword in the .def file.
      (PR#17130)

    * pmax() and pmin() now work with (more ?)  classed objects, such
      as "Matrix" from the Matrix package, as documented for a long
      time.

    * axis(side, x = D) and hence Axis() and plot() now work correctly
      for "Date" and time objects D, even when "time goes backward",
      e.g., with decreasing xlim.  (Reported by William May.)

    * str(I(matrix(..))) now looks as always intended.

    * plot.ts(), the plot() method for time series, now respects cex,
      lwd and lty.  (Reported by Greg Werbin.)

    * parallel::mccollect() now returns a named list (as documented)
      when called with wait = FALSE.  (Reported by Michel Lang.)

    * If a package added a class to a class union in another package,
      loading the first package gave erroneous warnings about
      "undefined subclass".

    * c()'s argument use.names is documented now, as belonging to the
      (C internal) default method.  In "parallel", argument recursive
      is also moved from the generic to the default method, such that
      the formal argument list of base generic c() is just (...).

    * rbeta(4, NA) and similarly rgamma() and rnbinom() now return
      NaN's with a warning, as other r<dist>(), and as documented.
      (PR#17155)

    * Using options(checkPackageLicense = TRUE) no longer requires
      acceptance of the licence for non-default standard packages such
      as compiler.  (Reported by Mikko Korpela.)

    * split(<very_long>, *) now works even when the split off parts are
      long. (PR#17139)

    * min() and max() now also work correctly when the argument list
      starts with character(0).  (PR#17160)

    * Subsetting very large matrices (prod(dim(.)) >= 2^31) now works
      thanks to Michael Schubmehl's PR#17158.

    * bartlett.test() used residual sums of squares instead of
      variances, when the argument was a list of lm objects.  (Reported
      by Jens Ledet Jensen).

    * plot(<lm>, which = *) now correctly labels the contour lines for
      the standardized residuals for which = 6.  It also takes the
      correct p in case of singularities (also for which = 5).
      (PR#17161)

    * xtabs(~ exclude) no longer fails from wrong scope, thanks to
      Suharto Anggono's PR#17147.

    * Reference class calls to methods() did not re-analyse previously
      defined methods, meaning that calls to methods defined later
      would fail. (Reported by Charles Tilford).

    * findInterval(x, vec, left.open = TRUE) misbehaved in some cases.
      (Reported by Dmitriy Chernykh.)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From kristi.glover at hotmail.com  Mon Oct 31 13:59:21 2016
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Mon, 31 Oct 2016 12:59:21 +0000
Subject: [R] How to copy and paste a row at the end of each group of a table?
Message-ID: <CO2PR13MB0139D10F7DF0CBCB13ED826FFAAE0@CO2PR13MB0139.namprd13.prod.outlook.com>

Hi R Users,

I have a big table with many classes, I need to copy a fist row of each class and put at the end of each class.

I split the table but I wonder of copying and putting at the end of the class. Here is an example. I was trying to get the table from "dat" to "dat1". In "dat", there is a column with "day", has only 12 rows for each class. but I want to copy first row of each class and put on the bottom of the class (see table: "dat1"), the value of the column of "day" need to be "361" but the value of temp should be same as of row 1.


Thanks for your suggestions in advance.


Thanks,

dat<-structure(list(site = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), day = c(1, 31, 61, 91, 121,
151, 181, 211, 241, 271, 301, 331, 1, 31, 61, 91, 121, 151, 181,
211, 241, 271, 301, 331), temp = c(8.3, 10.3, 9.4, 6.1, 3, 1.3,
1, 0.8, 1, 1.4, 2.7, 5.1, 9, 11.2, 9.6, 5.7, 2, 0.8, 0.6, 0.4,
0.4, 0.6, 1.5, 4.5)), .Names = c("site", "day", "temp"), row.names = c(NA,
-24L), class = "data.frame")

dat1<-structure(list(site = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), day = c(1, 31, 61, 91,
121, 151, 181, 211, 241, 271, 301, 331, 361, 1, 31, 61, 91, 121,
151, 181, 211, 241, 271, 301, 331, 361), temp = c(8.3, 10.3,
9.4, 6.1, 3, 1.3, 1, 0.8, 1, 1.4, 2.7, 5.1, 8.3, 9, 11.2, 9.6,
5.7, 2, 0.8, 0.6, 0.4, 0.4, 0.6, 1.5, 4.5, 9)), .Names = c("site",
"day", "temp"), row.names = c(NA, -26L), class = "data.frame")



	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Oct 31 14:09:53 2016
From: jholtman at gmail.com (jim holtman)
Date: Mon, 31 Oct 2016 09:09:53 -0400
Subject: [R] How to copy and paste a row at the end of each group of a
	table?
In-Reply-To: <CO2PR13MB0139D10F7DF0CBCB13ED826FFAAE0@CO2PR13MB0139.namprd13.prod.outlook.com>
References: <CO2PR13MB0139D10F7DF0CBCB13ED826FFAAE0@CO2PR13MB0139.namprd13.prod.outlook.com>
Message-ID: <CAAxdm-6Mdc=BTE382SKHCZkSeHa6T=d-AST+qLVgH-eZ2306aA@mail.gmail.com>

try this:

> dat<-structure(list(site = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,
+ 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), day = c(1, 31, 61, 91, 121,
+ 151, 181, 211, 241, 271, 301, 331, 1, 31, 61, 91, 121, 151, 181,
+ 211, 241, 271, 301, 331), temp = c(8.3, 10.3, 9.4, 6.1, 3, 1.3,
+ 1, 0.8, 1, 1.4, 2.7, 5.1, 9, 11.2, 9.6, 5.7, 2, 0.8, 0.6, 0.4,
+ 0.4, 0.6, 1.5, 4.5)), .Names = c("site", "day", "temp"), row.names = c(NA,
+ -24L), class = "data.frame")
>
> # split the data, copy value of first row to end
> dat2 <- do.call(rbind, lapply(split(dat, dat$site), function(.site){
+     x <- rbind(.site, .site[1L, ])  # add first row to bottom
+     x$day[nrow(x)] <- 361
+     x  # return x
+ }))
> dat2
      site day temp
1.1      1   1  8.3
1.2      1  31 10.3
1.3      1  61  9.4
1.4      1  91  6.1
1.5      1 121  3.0
1.6      1 151  1.3
1.7      1 181  1.0
1.8      1 211  0.8
1.9      1 241  1.0
1.10     1 271  1.4
1.11     1 301  2.7
1.12     1 331  5.1
1.13     1 361  8.3
2.13     2   1  9.0
2.14     2  31 11.2
2.15     2  61  9.6
2.16     2  91  5.7
2.17     2 121  2.0
2.18     2 151  0.8
2.19     2 181  0.6
2.20     2 211  0.4
2.21     2 241  0.4
2.22     2 271  0.6
2.23     2 301  1.5
2.24     2 331  4.5
2.131    2 361  9.0

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Mon, Oct 31, 2016 at 8:59 AM, Kristi Glover
<kristi.glover at hotmail.com> wrote:
> Hi R Users,
>
> I have a big table with many classes, I need to copy a fist row of each class and put at the end of each class.
>
> I split the table but I wonder of copying and putting at the end of the class. Here is an example. I was trying to get the table from "dat" to "dat1". In "dat", there is a column with "day", has only 12 rows for each class. but I want to copy first row of each class and put on the bottom of the class (see table: "dat1"), the value of the column of "day" need to be "361" but the value of temp should be same as of row 1.
>
>
> Thanks for your suggestions in advance.
>
>
> Thanks,
>
> dat<-structure(list(site = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), day = c(1, 31, 61, 91, 121,
> 151, 181, 211, 241, 271, 301, 331, 1, 31, 61, 91, 121, 151, 181,
> 211, 241, 271, 301, 331), temp = c(8.3, 10.3, 9.4, 6.1, 3, 1.3,
> 1, 0.8, 1, 1.4, 2.7, 5.1, 9, 11.2, 9.6, 5.7, 2, 0.8, 0.6, 0.4,
> 0.4, 0.6, 1.5, 4.5)), .Names = c("site", "day", "temp"), row.names = c(NA,
> -24L), class = "data.frame")
>
> dat1<-structure(list(site = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), day = c(1, 31, 61, 91,
> 121, 151, 181, 211, 241, 271, 301, 331, 361, 1, 31, 61, 91, 121,
> 151, 181, 211, 241, 271, 301, 331, 361), temp = c(8.3, 10.3,
> 9.4, 6.1, 3, 1.3, 1, 0.8, 1, 1.4, 2.7, 5.1, 8.3, 9, 11.2, 9.6,
> 5.7, 2, 0.8, 0.6, 0.4, 0.4, 0.6, 1.5, 4.5, 9)), .Names = c("site",
> "day", "temp"), row.names = c(NA, -26L), class = "data.frame")
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Oct 31 14:42:07 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 31 Oct 2016 13:42:07 +0000
Subject: [R] How to copy and paste a row at the end of each group of
	a	table?
In-Reply-To: <CAAxdm-6Mdc=BTE382SKHCZkSeHa6T=d-AST+qLVgH-eZ2306aA@mail.gmail.com>
References: <CO2PR13MB0139D10F7DF0CBCB13ED826FFAAE0@CO2PR13MB0139.namprd13.prod.outlook.com>
	<CAAxdm-6Mdc=BTE382SKHCZkSeHa6T=d-AST+qLVgH-eZ2306aA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50448C3@SRVEXCHMBX.precheza.cz>

Hi

Another approach is to use function like following

fff<-function(x, ...) {
temp <- x[which(x[,"day"]==1),]
temp$day <- 361
x <- rbind(x, temp)
x[order(x$site, x$day),]
}

fff(dat)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of jim
> holtman
> Sent: Monday, October 31, 2016 2:10 PM
> To: Kristi Glover <kristi.glover at hotmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] How to copy and paste a row at the end of each group of a
> table?
>
> try this:
>
> > dat<-structure(list(site = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,
> + 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), day = c(1, 31, 61, 91, 121,
> + 151, 181, 211, 241, 271, 301, 331, 1, 31, 61, 91, 121, 151, 181,
> + 211, 241, 271, 301, 331), temp = c(8.3, 10.3, 9.4, 6.1, 3, 1.3,
> + 1, 0.8, 1, 1.4, 2.7, 5.1, 9, 11.2, 9.6, 5.7, 2, 0.8, 0.6, 0.4,
> + 0.4, 0.6, 1.5, 4.5)), .Names = c("site", "day", "temp"), row.names = c(NA,
> + -24L), class = "data.frame")
> >
> > # split the data, copy value of first row to end
> > dat2 <- do.call(rbind, lapply(split(dat, dat$site), function(.site){
> +     x <- rbind(.site, .site[1L, ])  # add first row to bottom
> +     x$day[nrow(x)] <- 361
> +     x  # return x
> + }))
> > dat2
>       site day temp
> 1.1      1   1  8.3
> 1.2      1  31 10.3
> 1.3      1  61  9.4
> 1.4      1  91  6.1
> 1.5      1 121  3.0
> 1.6      1 151  1.3
> 1.7      1 181  1.0
> 1.8      1 211  0.8
> 1.9      1 241  1.0
> 1.10     1 271  1.4
> 1.11     1 301  2.7
> 1.12     1 331  5.1
> 1.13     1 361  8.3
> 2.13     2   1  9.0
> 2.14     2  31 11.2
> 2.15     2  61  9.6
> 2.16     2  91  5.7
> 2.17     2 121  2.0
> 2.18     2 151  0.8
> 2.19     2 181  0.6
> 2.20     2 211  0.4
> 2.21     2 241  0.4
> 2.22     2 271  0.6
> 2.23     2 301  1.5
> 2.24     2 331  4.5
> 2.131    2 361  9.0
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Mon, Oct 31, 2016 at 8:59 AM, Kristi Glover
> <kristi.glover at hotmail.com> wrote:
> > Hi R Users,
> >
> > I have a big table with many classes, I need to copy a fist row of each class
> and put at the end of each class.
> >
> > I split the table but I wonder of copying and putting at the end of the class.
> Here is an example. I was trying to get the table from "dat" to "dat1". In
> "dat", there is a column with "day", has only 12 rows for each class. but I want
> to copy first row of each class and put on the bottom of the class (see table:
> "dat1"), the value of the column of "day" need to be "361" but the value of
> temp should be same as of row 1.
> >
> >
> > Thanks for your suggestions in advance.
> >
> >
> > Thanks,
> >
> > dat<-structure(list(site = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,
> > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), day = c(1, 31, 61, 91, 121,
> > 151, 181, 211, 241, 271, 301, 331, 1, 31, 61, 91, 121, 151, 181,
> > 211, 241, 271, 301, 331), temp = c(8.3, 10.3, 9.4, 6.1, 3, 1.3,
> > 1, 0.8, 1, 1.4, 2.7, 5.1, 9, 11.2, 9.6, 5.7, 2, 0.8, 0.6, 0.4,
> > 0.4, 0.6, 1.5, 4.5)), .Names = c("site", "day", "temp"), row.names = c(NA,
> > -24L), class = "data.frame")
> >
> > dat1<-structure(list(site = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), day = c(1, 31, 61, 91,
> > 121, 151, 181, 211, 241, 271, 301, 331, 361, 1, 31, 61, 91, 121,
> > 151, 181, 211, 241, 271, 301, 331, 361), temp = c(8.3, 10.3,
> > 9.4, 6.1, 3, 1.3, 1, 0.8, 1, 1.4, 2.7, 5.1, 8.3, 9, 11.2, 9.6,
> > 5.7, 2, 0.8, 0.6, 0.4, 0.4, 0.6, 1.5, 4.5, 9)), .Names = c("site",
> > "day", "temp"), row.names = c(NA, -26L), class = "data.frame")
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Thomas.Chesney at nottingham.ac.uk  Mon Oct 31 15:09:19 2016
From: Thomas.Chesney at nottingham.ac.uk (Thomas Chesney)
Date: Mon, 31 Oct 2016 14:09:19 +0000
Subject: [R] The equivalent of which() when accessing slots in an object
Message-ID: <205BB27F-C816-4F85-BA0C-BD290D45780B@exmail.nottingham.ac.uk>

I have the following object

setClass("buyer",
representation(
reqstock="numeric",
buyout="numeric"),
)

nBuy <- 5

#Set buyer parameters here
buylist <- list()
for (i in 1:nBuy){
buylist[[i]] <- new("buyer")
buylist[[i]]@reqstock <- sample(c(50:200),1)
}

and want to count the number of objects in buylist that have reqstock greater than 100. Something like this if it was a vector:

length(which(buylist[[]]@reqstock > 100))

How could I do this please and where could I find more information about manipulating slots? When I try to search for this I just keep finding info on ls() and similar functions.

Thank you

Thomas Chesney
http://www.nottingham.ac.uk/~liztc/Personal/index.html



This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please send it back to me, and immediately delete it. 

Please do not use, copy or disclose the information contained in this
message or in any attachment.  Any views or opinions expressed by the
author of this email do not necessarily reflect the views of the
University of Nottingham.

This message has been checked for viruses but the contents of an
attachment may still contain software viruses which could damage your
computer system, you are advised to perform your own checks. Email
communications with the University of Nottingham may be monitored as
permitted by UK legislation.


From bob at rud.is  Mon Oct 31 15:31:17 2016
From: bob at rud.is (Bob Rudis)
Date: Mon, 31 Oct 2016 10:31:17 -0400
Subject: [R] The equivalent of which() when accessing slots in an object
In-Reply-To: <205BB27F-C816-4F85-BA0C-BD290D45780B@exmail.nottingham.ac.uk>
References: <205BB27F-C816-4F85-BA0C-BD290D45780B@exmail.nottingham.ac.uk>
Message-ID: <CAA-FpKVZvTcjcNmabH8yBX9=R=HzZfx76UvVePucENVQZhpEhg@mail.gmail.com>

    which(purrr::map_dbl(buylist, slot, "reqstock") > 100)

or

    which(sapply(buylist, slot, "reqstock") > 100)

ought to do the trick.

On Mon, Oct 31, 2016 at 10:09 AM, Thomas Chesney
<Thomas.Chesney at nottingham.ac.uk> wrote:
> I have the following object
>
> setClass("buyer",
> representation(
> reqstock="numeric",
> buyout="numeric"),
> )
>
> nBuy <- 5
>
> #Set buyer parameters here
> buylist <- list()
> for (i in 1:nBuy){
> buylist[[i]] <- new("buyer")
> buylist[[i]]@reqstock <- sample(c(50:200),1)
> }
>
> and want to count the number of objects in buylist that have reqstock greater than 100. Something like this if it was a vector:
>
> length(which(buylist[[]]@reqstock > 100))
>
> How could I do this please and where could I find more information about manipulating slots? When I try to search for this I just keep finding info on ls() and similar functions.
>
> Thank you
>
> Thomas Chesney
> http://www.nottingham.ac.uk/~liztc/Personal/index.html
>
>
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please send it back to me, and immediately delete it.
>
> Please do not use, copy or disclose the information contained in this
> message or in any attachment.  Any views or opinions expressed by the
> author of this email do not necessarily reflect the views of the
> University of Nottingham.
>
> This message has been checked for viruses but the contents of an
> attachment may still contain software viruses which could damage your
> computer system, you are advised to perform your own checks. Email
> communications with the University of Nottingham may be monitored as
> permitted by UK legislation.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kristi.glover at hotmail.com  Mon Oct 31 17:08:14 2016
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Mon, 31 Oct 2016 16:08:14 +0000
Subject: [R] How to copy and paste a row at the end of each group of
	a	table?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50448C3@SRVEXCHMBX.precheza.cz>
References: <CO2PR13MB0139D10F7DF0CBCB13ED826FFAAE0@CO2PR13MB0139.namprd13.prod.outlook.com>
	<CAAxdm-6Mdc=BTE382SKHCZkSeHa6T=d-AST+qLVgH-eZ2306aA@mail.gmail.com>,
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50448C3@SRVEXCHMBX.precheza.cz>
Message-ID: <CO2PR13MB01398129C4341231D88FA690FAAE0@CO2PR13MB0139.namprd13.prod.outlook.com>

Hi Jim and Pikal,

thank you very much for the help. Both approach works fine. Thank you once again.


KG


________________________________
From: PIKAL Petr <petr.pikal at precheza.cz>
Sent: October 31, 2016 7:42 AM
To: Kristi Glover
Cc: r-help at r-project.org
Subject: RE: [R] How to copy and paste a row at the end of each group of a table?

Hi

Another approach is to use function like following

fff<-function(x, ...) {
temp <- x[which(x[,"day"]==1),]
temp$day <- 361
x <- rbind(x, temp)
x[order(x$site, x$day),]
}

fff(dat)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of jim
> holtman
> Sent: Monday, October 31, 2016 2:10 PM
> To: Kristi Glover <kristi.glover at hotmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] How to copy and paste a row at the end of each group of a
> table?
>
> try this:
>
> > dat<-structure(list(site = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,
> + 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), day = c(1, 31, 61, 91, 121,
> + 151, 181, 211, 241, 271, 301, 331, 1, 31, 61, 91, 121, 151, 181,
> + 211, 241, 271, 301, 331), temp = c(8.3, 10.3, 9.4, 6.1, 3, 1.3,
> + 1, 0.8, 1, 1.4, 2.7, 5.1, 9, 11.2, 9.6, 5.7, 2, 0.8, 0.6, 0.4,
> + 0.4, 0.6, 1.5, 4.5)), .Names = c("site", "day", "temp"), row.names = c(NA,
> + -24L), class = "data.frame")
> >
> > # split the data, copy value of first row to end
> > dat2 <- do.call(rbind, lapply(split(dat, dat$site), function(.site){
> +     x <- rbind(.site, .site[1L, ])  # add first row to bottom
> +     x$day[nrow(x)] <- 361
> +     x  # return x
> + }))
> > dat2
>       site day temp
> 1.1      1   1  8.3
> 1.2      1  31 10.3
> 1.3      1  61  9.4
> 1.4      1  91  6.1
> 1.5      1 121  3.0
> 1.6      1 151  1.3
> 1.7      1 181  1.0
> 1.8      1 211  0.8
> 1.9      1 241  1.0
> 1.10     1 271  1.4
> 1.11     1 301  2.7
> 1.12     1 331  5.1
> 1.13     1 361  8.3
> 2.13     2   1  9.0
> 2.14     2  31 11.2
> 2.15     2  61  9.6
> 2.16     2  91  5.7
> 2.17     2 121  2.0
> 2.18     2 151  0.8
> 2.19     2 181  0.6
> 2.20     2 211  0.4
> 2.21     2 241  0.4
> 2.22     2 271  0.6
> 2.23     2 301  1.5
> 2.24     2 331  4.5
> 2.131    2 361  9.0
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Mon, Oct 31, 2016 at 8:59 AM, Kristi Glover
> <kristi.glover at hotmail.com> wrote:
> > Hi R Users,
> >
> > I have a big table with many classes, I need to copy a fist row of each class
> and put at the end of each class.
> >
> > I split the table but I wonder of copying and putting at the end of the class.
> Here is an example. I was trying to get the table from "dat" to "dat1". In
> "dat", there is a column with "day", has only 12 rows for each class. but I want
> to copy first row of each class and put on the bottom of the class (see table:
> "dat1"), the value of the column of "day" need to be "361" but the value of
> temp should be same as of row 1.
> >
> >
> > Thanks for your suggestions in advance.
> >
> >
> > Thanks,
> >
> > dat<-structure(list(site = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,
> > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), day = c(1, 31, 61, 91, 121,
> > 151, 181, 211, 241, 271, 301, 331, 1, 31, 61, 91, 121, 151, 181,
> > 211, 241, 271, 301, 331), temp = c(8.3, 10.3, 9.4, 6.1, 3, 1.3,
> > 1, 0.8, 1, 1.4, 2.7, 5.1, 9, 11.2, 9.6, 5.7, 2, 0.8, 0.6, 0.4,
> > 0.4, 0.6, 1.5, 4.5)), .Names = c("site", "day", "temp"), row.names = c(NA,
> > -24L), class = "data.frame")
> >
> > dat1<-structure(list(site = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), day = c(1, 31, 61, 91,
> > 121, 151, 181, 211, 241, 271, 301, 331, 361, 1, 31, 61, 91, 121,
> > 151, 181, 211, 241, 271, 301, 331, 361), temp = c(8.3, 10.3,
> > 9.4, 6.1, 3, 1.3, 1, 0.8, 1, 1.4, 2.7, 5.1, 8.3, 9, 11.2, 9.6,
> > 5.7, 2, 0.8, 0.6, 0.4, 0.4, 0.6, 1.5, 4.5, 9)), .Names = c("site",
> > "day", "temp"), row.names = c(NA, -26L), class = "data.frame")
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k nemu pripojen? dokumenty jsou duvern? a jsou urceny pouze jeho adres?tum.
Jestlize jste obdrzel(a) tento e-mail omylem, informujte laskave neprodlene jeho odes?latele. Obsah tohoto emailu i s pr?lohami a jeho kopie vymazte ze sv?ho syst?mu.
Nejste-li zam?slen?m adres?tem tohoto emailu, nejste opr?vneni tento email jakkoliv uz?vat, rozsirovat, kop?rovat ci zverejnovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? skodu zpusobenou modifikacemi ci zpozden?m prenosu e-mailu.

V pr?pade, ze je tento e-mail souc?st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukoncit kdykoliv jedn?n? o uzavren? smlouvy, a to z jak?hokoliv duvodu i bez uveden? duvodu.
- a obsahuje-li nab?dku, je adres?t opr?vnen nab?dku bezodkladne prijmout; Odes?latel tohoto e-mailu (nab?dky) vylucuje prijet? nab?dky ze strany pr?jemce s dodatkem ci odchylkou.
- trv? odes?latel na tom, ze pr?slusn? smlouva je uzavrena teprve v?slovn?m dosazen?m shody na vsech jej?ch n?lezitostech.
- odes?latel tohoto emailu informuje, ze nen? opr?vnen uzav?rat za spolecnost z?dn? smlouvy s v?jimkou pr?padu, kdy k tomu byl p?semne zmocnen nebo p?semne poveren a takov? poveren? nebo pln? moc byly adres?tovi tohoto emailu pr?padne osobe, kterou adres?t zastupuje, predlozeny nebo jejich existence je adres?tovi ci osobe j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Oct 31 17:09:23 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 31 Oct 2016 09:09:23 -0700
Subject: [R] The equivalent of which() when accessing slots in an object
In-Reply-To: <CAA-FpKVZvTcjcNmabH8yBX9=R=HzZfx76UvVePucENVQZhpEhg@mail.gmail.com>
References: <205BB27F-C816-4F85-BA0C-BD290D45780B@exmail.nottingham.ac.uk>
	<CAA-FpKVZvTcjcNmabH8yBX9=R=HzZfx76UvVePucENVQZhpEhg@mail.gmail.com>
Message-ID: <CAGxFJbQywDZ63Ek0OxtZmb6YJm-39zzxJgyfE7=rsCGk71m=Tg@mail.gmail.com>

But if all the OP want is a count, wouldn't

sum(sapply(buylist, slot, "reqstock") > 100)

suffice?

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Oct 31, 2016 at 7:31 AM, Bob Rudis <bob at rud.is> wrote:
>     which(purrr::map_dbl(buylist, slot, "reqstock") > 100)
>
> or
>
>     which(sapply(buylist, slot, "reqstock") > 100)
>
> ought to do the trick.
>
> On Mon, Oct 31, 2016 at 10:09 AM, Thomas Chesney
> <Thomas.Chesney at nottingham.ac.uk> wrote:
>> I have the following object
>>
>> setClass("buyer",
>> representation(
>> reqstock="numeric",
>> buyout="numeric"),
>> )
>>
>> nBuy <- 5
>>
>> #Set buyer parameters here
>> buylist <- list()
>> for (i in 1:nBuy){
>> buylist[[i]] <- new("buyer")
>> buylist[[i]]@reqstock <- sample(c(50:200),1)
>> }
>>
>> and want to count the number of objects in buylist that have reqstock greater than 100. Something like this if it was a vector:
>>
>> length(which(buylist[[]]@reqstock > 100))
>>
>> How could I do this please and where could I find more information about manipulating slots? When I try to search for this I just keep finding info on ls() and similar functions.
>>
>> Thank you
>>
>> Thomas Chesney
>> http://www.nottingham.ac.uk/~liztc/Personal/index.html
>>
>>
>>
>> This message and any attachment are intended solely for the addressee
>> and may contain confidential information. If you have received this
>> message in error, please send it back to me, and immediately delete it.
>>
>> Please do not use, copy or disclose the information contained in this
>> message or in any attachment.  Any views or opinions expressed by the
>> author of this email do not necessarily reflect the views of the
>> University of Nottingham.
>>
>> This message has been checked for viruses but the contents of an
>> attachment may still contain software viruses which could damage your
>> computer system, you are advised to perform your own checks. Email
>> communications with the University of Nottingham may be monitored as
>> permitted by UK legislation.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Oct 31 17:29:47 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 31 Oct 2016 09:29:47 -0700
Subject: [R] The equivalent of which() when accessing slots in an object
In-Reply-To: <CAA-FpKVZvTcjcNmabH8yBX9=R=HzZfx76UvVePucENVQZhpEhg@mail.gmail.com>
References: <205BB27F-C816-4F85-BA0C-BD290D45780B@exmail.nottingham.ac.uk>
	<CAA-FpKVZvTcjcNmabH8yBX9=R=HzZfx76UvVePucENVQZhpEhg@mail.gmail.com>
Message-ID: <CAF8bMcaY=B0LNjGT3oETXSQxVy66oBcNggcFdCR84iQ2tphSTw@mail.gmail.com>

vapply(buylist, slot, "reqstock", FUN.VALUE=0.0)
is closer in spirit than sapply() to purrr::map_dbl() - FUN.VALUE
gives the expected type and size of f's output.  vapply() is usually
quicker than sapply(), uses less memory, gives the right results
when given a vector of length 0, and gives an error when FUN does
not return the specified sort of result.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Oct 31, 2016 at 7:31 AM, Bob Rudis <bob at rud.is> wrote:

>     which(purrr::map_dbl(buylist, slot, "reqstock") > 100)
>
> or
>
>     which(sapply(buylist, slot, "reqstock") > 100)
>
> ought to do the trick.
>
> On Mon, Oct 31, 2016 at 10:09 AM, Thomas Chesney
> <Thomas.Chesney at nottingham.ac.uk> wrote:
> > I have the following object
> >
> > setClass("buyer",
> > representation(
> > reqstock="numeric",
> > buyout="numeric"),
> > )
> >
> > nBuy <- 5
> >
> > #Set buyer parameters here
> > buylist <- list()
> > for (i in 1:nBuy){
> > buylist[[i]] <- new("buyer")
> > buylist[[i]]@reqstock <- sample(c(50:200),1)
> > }
> >
> > and want to count the number of objects in buylist that have reqstock
> greater than 100. Something like this if it was a vector:
> >
> > length(which(buylist[[]]@reqstock > 100))
> >
> > How could I do this please and where could I find more information about
> manipulating slots? When I try to search for this I just keep finding info
> on ls() and similar functions.
> >
> > Thank you
> >
> > Thomas Chesney
> > http://www.nottingham.ac.uk/~liztc/Personal/index.html
> >
> >
> >
> > This message and any attachment are intended solely for the addressee
> > and may contain confidential information. If you have received this
> > message in error, please send it back to me, and immediately delete it.
> >
> > Please do not use, copy or disclose the information contained in this
> > message or in any attachment.  Any views or opinions expressed by the
> > author of this email do not necessarily reflect the views of the
> > University of Nottingham.
> >
> > This message has been checked for viruses but the contents of an
> > attachment may still contain software viruses which could damage your
> > computer system, you are advised to perform your own checks. Email
> > communications with the University of Nottingham may be monitored as
> > permitted by UK legislation.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bob at rud.is  Mon Oct 31 18:08:43 2016
From: bob at rud.is (Bob Rudis)
Date: Mon, 31 Oct 2016 13:08:43 -0400
Subject: [R] The equivalent of which() when accessing slots in an object
In-Reply-To: <CAF8bMcaY=B0LNjGT3oETXSQxVy66oBcNggcFdCR84iQ2tphSTw@mail.gmail.com>
References: <205BB27F-C816-4F85-BA0C-BD290D45780B@exmail.nottingham.ac.uk>
	<CAA-FpKVZvTcjcNmabH8yBX9=R=HzZfx76UvVePucENVQZhpEhg@mail.gmail.com>
	<CAF8bMcaY=B0LNjGT3oETXSQxVy66oBcNggcFdCR84iQ2tphSTw@mail.gmail.com>
Message-ID: <CAA-FpKUU9cGP8D=75nGt-BFf2Bwav8ocA6XRL2Kg7fBWRiJXyQ@mail.gmail.com>

Aye, Bill. I figured others wld include a `vapply()` example (didn't
want to "hog" the answer :-).

I went with bland `sapply()` as an alternative since I made an
assumption Thomas (like the large % of R users I've come in contact
with - albeit a biased sample) aren't really familiar with `vapply()`.

On Mon, Oct 31, 2016 at 12:29 PM, William Dunlap <wdunlap at tibco.com> wrote:
> vapply(buylist, slot, "reqstock", FUN.VALUE=0.0)
> is closer in spirit than sapply() to purrr::map_dbl() - FUN.VALUE
> gives the expected type and size of f's output.  vapply() is usually
> quicker than sapply(), uses less memory, gives the right results
> when given a vector of length 0, and gives an error when FUN does
> not return the specified sort of result.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Oct 31, 2016 at 7:31 AM, Bob Rudis <bob at rud.is> wrote:
>>
>>     which(purrr::map_dbl(buylist, slot, "reqstock") > 100)
>>
>> or
>>
>>     which(sapply(buylist, slot, "reqstock") > 100)
>>
>> ought to do the trick.
>>
>> On Mon, Oct 31, 2016 at 10:09 AM, Thomas Chesney
>> <Thomas.Chesney at nottingham.ac.uk> wrote:
>> > I have the following object
>> >
>> > setClass("buyer",
>> > representation(
>> > reqstock="numeric",
>> > buyout="numeric"),
>> > )
>> >
>> > nBuy <- 5
>> >
>> > #Set buyer parameters here
>> > buylist <- list()
>> > for (i in 1:nBuy){
>> > buylist[[i]] <- new("buyer")
>> > buylist[[i]]@reqstock <- sample(c(50:200),1)
>> > }
>> >
>> > and want to count the number of objects in buylist that have reqstock
>> > greater than 100. Something like this if it was a vector:
>> >
>> > length(which(buylist[[]]@reqstock > 100))
>> >
>> > How could I do this please and where could I find more information about
>> > manipulating slots? When I try to search for this I just keep finding info
>> > on ls() and similar functions.
>> >
>> > Thank you
>> >
>> > Thomas Chesney
>> > http://www.nottingham.ac.uk/~liztc/Personal/index.html
>> >
>> >
>> >
>> > This message and any attachment are intended solely for the addressee
>> > and may contain confidential information. If you have received this
>> > message in error, please send it back to me, and immediately delete it.
>> >
>> > Please do not use, copy or disclose the information contained in this
>> > message or in any attachment.  Any views or opinions expressed by the
>> > author of this email do not necessarily reflect the views of the
>> > University of Nottingham.
>> >
>> > This message has been checked for viruses but the contents of an
>> > attachment may still contain software viruses which could damage your
>> > computer system, you are advised to perform your own checks. Email
>> > communications with the University of Nottingham may be monitored as
>> > permitted by UK legislation.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From larakiyahya at gmail.com  Mon Oct 31 15:44:37 2016
From: larakiyahya at gmail.com (Yahya Laraki)
Date: Mon, 31 Oct 2016 10:44:37 -0400
Subject: [R] Simple loop problem
Message-ID: <A2BC262C-E688-41DD-B88E-B03C8402DDF9@gmail.com>

Hi everybody,

I?m new to R and i?m trying to learn fundamentals. I?m facing a small problem for which i can?t find a solution online.

What i want to do: write a function to lower case for all the columns in my data.frame if they respect a condition (class = factor)

This code works, but for all my columns : change_lower = function(x) {data.frame(tolower(as.matrix(x)))}

I need more something like this, but it doesn?t work: function (x) { for (i in 1:length(x)) {
  if (class(i)=="factor") {
    data.frame(tolower(as.matrix(x))) 
  }
}}

Thank you 

Yahya

From luke.gaylor at live.com.au  Mon Oct 31 13:54:27 2016
From: luke.gaylor at live.com.au (Luke Gaylor)
Date: Mon, 31 Oct 2016 12:54:27 +0000
Subject: [R] Permutations in matched-pair study where combinations of pairs
	change
Message-ID: <BN6PR11MB1764D467976D8714D9F4AD3DAEAE0@BN6PR11MB1764.namprd11.prod.outlook.com>

Friends,


Matched pairs studies are well documented, but what happens if we were to alter the manner in which events were paired to one another. Say we change the order of our data and pair without replacement, so that event 1 may pair with event 23 in one instance, but also event 36 or 102 in other instances.

Matched pair study can then be used to determine the effectiveness of, for example a treatment program, on a given outcome. The outcome may be continuous or variable. Therefore, a conditional logistic regression model can output an odds ratio (and confidence intervals for the treatment coefficient). Or we may use a paired t-test to assess if the difference in means between the pairs differ.

I am more favored to the logistic regression and output of the odds ratio, however it changes for each permutation. As too does its confidence interval. So my question is how can we report on a string of given odds ratios - how can be arrive at a statistical sound conclusion? Or accounting for the study design, where we achieve different combinations of matched pairs, how can be comment on the effectiveness of a given treatment program?

Below I have attached a code, which simulates a 100-fold permutation.


Any advice would be greatly appreciated,
Luke


Set.seed(123)
# prepare the data for the simulation
#1.
library(Matching)
library(survival)
library(dplyr)
#2.
require(doParallel)
cl<-makeCluster(2)
registerDoParallel(cl)
#3.
clusterEvalQ(cl,library(Matching))
clusterEvalQ(cl,library(survival))
clusterEvalQ(cl,library(dplyr))

# number of permutations
m <- 100


Result = foreach(i=1:m,.combine=cbind) %do%{

  # taking from the example from the Matching package
  #attach the data
  data(lalonde)

  # we want to assess if treatment shows an influence on a given outcome of interest
  # lets create our hypothetical example
  lalonde$success <- with(lalonde, ifelse(re78 > 8125, 1, 0))

  # adjust the order of the data
  lalonde <- lalonde[sample(1:nrow(lalonde)), ]
  head(lalonde$age)


  # Define the covariates we want to match on
  Xmat = cbind(lalonde$age, lalonde$educ, lalonde$married, lalonde$nodegr)

  # define crude matching
  mgen1 <- Match(Y=NULL, Tr=lalonde$treat,
                 X=Xmat,
                 exact=c(0,1,1,1),
                 replace=FALSE, ties=F)

  summary(mgen1)

  # obtain initial pair-combinations
  matched <- rbind(lalonde[mgen1$index.treated,], lalonde[mgen1$index.control,])

  # generate a dummy variable for our each pair of people
  matched$Pair_ID <- rep(1:length(mgen1$index.treated),2)

  # crude filtering
  # set hard limits of age
  # must be within +-2 years
  Matched2 <- matched %>%
    group_by(Pair_ID) %>%
    filter(abs( age[treat == 1] - age[treat == 0]) <= 2)

  # summary table
  table(Matched2$treat, Matched2$success)

  # so now we have a cohort of similar events
  # each pair contains one treat and one non-treat event


  #######################################################
  #                                                     #
  #     H E R E   W E   A R E   T R Y I N G    T O      #
  #  A S S E S S   T H E    E F F E C T I V E N E S S   #
  #   O F   T R E A T M E N T   T O    A C H I E V E    #
  #               s U C C E S S                         #
  #                                                     #
  #######################################################


  # One could implement a parametric difference of means test
  # t-test - (as the outcome of interest is binary)
  # to assess if differences between pairs change

  diff_means<- t.test(Matched2$success[Matched2$treat==1], Matched2$success[Matched2$treat==0],
         paired = T, alternative = "two.sided", conf.level = 0.95)
  diff_means$p.value

  # output the series of p-values for each permutation

  # ===========================================
  # Or
  # ===========================================

  # obtain an estimated effectiveness value from a conditional logistic regression
  # namely, the Odds Ratio coefficient for 'treat'
  model_1 <- clogit(success ~ treat + strata(Pair_ID), matched)
  summary(model_1)

  OR_M1 <- exp(model_1$coefficients[1])

  # we can save the confidence intervals for the 'treat' effectiveness
  CI_U1 <- exp(confint(model_1))[1,2]
  CI_L1 <- exp(confint(model_1))[1,1]

  # then we could output any of the following
  #Result <- diff_means$p.value
  #Result <- OR_M1
  #Result <- rbind(OR_M1, CI_U1, CI_L1)

  Result <- OR_M1

}

summary(Result[1,])




	[[alternative HTML version deleted]]


From mkevelson at ets.org  Mon Oct 31 16:49:03 2016
From: mkevelson at ets.org (Kevelson, Marisol J)
Date: Mon, 31 Oct 2016 15:49:03 +0000
Subject: [R] Installing polycor package
Message-ID: <SN2PR07MB26393AFC36B14F11E450F91CA2AE0@SN2PR07MB2639.namprd07.prod.outlook.com>

I have been trying to install the R polycor package without any success. I want to install version 0.7-8 because it is supposed to work with R version 3.1.0, which I have to use to run an R plug-in for SPSS. But I get a message that polycor is not available for R version 3.1.0:

>  install.packages("polycor", repos="C:/Users/mkevelson/Documents/polycor_0.7-8 (1)/polycor/R")
Installing package into 'C:/Users/mkevelson/Documents/R/win-library/3.1'
(as 'lib' is unspecified)
Warning: unable to access index for repository C:/Users/mkevelson/Documents/polycor_0.7-8 (1)/polycor/R/bin/windows/contrib/3.1
Warning message:
package 'polycor' is not available (for R version 3.1.0)

I also tried installing the current version of polycor directly from R-Forge in R version 3.3.1, also without success:

> install.packages("polycor", repos="http://R-Forge.R-project.org")
Installing package into 'C:/Users/mkevelson/Documents/R/win-library/3.3'
(as 'lib' is unspecified)
also installing the dependency 'mvtnorm'

trying URL 'http://R-Forge.R-project.org/bin/windows/contrib/3.3/mvtnorm_1.0-5.zip'
Content type 'application/zip' length 408362 bytes (398 KB)
downloaded 292 KB

trying URL 'http://R-Forge.R-project.org/bin/windows/contrib/3.3/polycor_0.7-10.zip'
Content type 'application/zip' length 52183 bytes (50 KB)
downloaded 50 KB

Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
  cannot open the connection
In addition: Warning messages:
1: In download.file(url, destfile, method, mode = "wb", ...) :
  downloaded length 299008 != reported length 408362
2: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
  cannot open compressed file 'mvtnorm/DESCRIPTION', probable reason 'No such file or directory'

I would greatly appreciate any advice you have on how to successfully install the polycor package.

Thank you,

Marisol



________________________________

This e-mail and any files transmitted with it may contain privileged or confidential information. It is solely for use by the individual for whom it is intended, even if addressed incorrectly. If you received this e-mail in error, please notify the sender; do not disclose, copy, distribute, or take any action in reliance on the contents of this information; and delete it from your system. Any other use of this e-mail is prohibited.


Thank you for your compliance.

________________________________

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Oct 31 20:28:23 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 31 Oct 2016 19:28:23 +0000
Subject: [R] Simple loop problem
In-Reply-To: <A2BC262C-E688-41DD-B88E-B03C8402DDF9@gmail.com>
References: <A2BC262C-E688-41DD-B88E-B03C8402DDF9@gmail.com>
Message-ID: <4a1c0b7cde3f4bc1b334e4f4c7c268a0@exch-2p-mbx-w2.ads.tamu.edu>

This looks like homework and r-help has a policy of not providing answers for homework. But first you need to research what happens when you convert a data frame to a matrix. 

Also in your loop, i is a numeric value between 1 and the length of x:

What is x (what class)?
What is the length of an object of that class?
What is the value of class(i) regardless of the value of i?
What is the difference between class "character" and class "factor"?

If you can answer these questions, it will be obvious what is wrong with your code. They are all available online in basic introductions to R.
-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Yahya Laraki
Sent: Monday, October 31, 2016 9:45 AM
To: r-help at r-project.org
Subject: [R] Simple loop problem

Hi everybody,

I?m new to R and i?m trying to learn fundamentals. I?m facing a small problem for which i can?t find a solution online.

What i want to do: write a function to lower case for all the columns in my data.frame if they respect a condition (class = factor)

This code works, but for all my columns : change_lower = function(x) {data.frame(tolower(as.matrix(x)))}

I need more something like this, but it doesn?t work: function (x) { for (i in 1:length(x)) {
  if (class(i)=="factor") {
    data.frame(tolower(as.matrix(x))) 
  }
}}

Thank you 

Yahya
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From wdunlap at tibco.com  Mon Oct 31 20:28:51 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 31 Oct 2016 12:28:51 -0700
Subject: [R] Simple loop problem
In-Reply-To: <A2BC262C-E688-41DD-B88E-B03C8402DDF9@gmail.com>
References: <A2BC262C-E688-41DD-B88E-B03C8402DDF9@gmail.com>
Message-ID: <CAF8bMcZt9Yd2sz5_pZjD=AMx1ET76k4ieKK4wspd2aaGNXMeFw@mail.gmail.com>

Use tolower on the levels of the factor columns.  E.g.,

> d <- data.frame(Num=1:3, F1=c("One","Two","Three"), F2=c("A","B","a"))
> str(d)
'data.frame':   3 obs. of  3 variables:
 $ Num: int  1 2 3
 $ F1 : Factor w/ 3 levels "One","Three",..: 1 3 2
 $ F2 : Factor w/ 3 levels "a","A","B": 2 3 1
> for(n in names(d))
+    if (is.factor(d[[n]])) levels(d[[n]]) <- tolower(levels(d[[n]]))
> str(d)
'data.frame':   3 obs. of  3 variables:
 $ Num: int  1 2 3
 $ F1 : Factor w/ 3 levels "one","three",..: 1 3 2
 $ F2 : Factor w/ 2 levels "a","b": 1 2 1

Using data.frame(tolower(as.matrix(d))) may change your column names
and the data in your columns - don't do it.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Oct 31, 2016 at 7:44 AM, Yahya Laraki <larakiyahya at gmail.com> wrote:

> Hi everybody,
>
> I?m new to R and i?m trying to learn fundamentals. I?m facing a small
> problem for which i can?t find a solution online.
>
> What i want to do: write a function to lower case for all the columns in
> my data.frame if they respect a condition (class = factor)
>
> This code works, but for all my columns : change_lower = function(x)
> {data.frame(tolower(as.matrix(x)))}
>
> I need more something like this, but it doesn?t work: function (x) { for
> (i in 1:length(x)) {
>   if (class(i)=="factor") {
>     data.frame(tolower(as.matrix(x)))
>   }
> }}
>
> Thank you
>
> Yahya
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Oct 31 20:46:31 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 31 Oct 2016 12:46:31 -0700
Subject: [R] Simple loop problem
In-Reply-To: <B21ED616-B128-4B91-A11F-8ECA8A887501@gmail.com>
References: <A2BC262C-E688-41DD-B88E-B03C8402DDF9@gmail.com>
	<CAF8bMcZt9Yd2sz5_pZjD=AMx1ET76k4ieKK4wspd2aaGNXMeFw@mail.gmail.com>
	<B21ED616-B128-4B91-A11F-8ECA8A887501@gmail.com>
Message-ID: <CAF8bMcYUtaoA1sj0VA+YQnmZW6MLUdS43b7xKYJJnikMsCD8RQ@mail.gmail.com>

Did you mean 'tolower' instead of 'to lower' in your example?
Or is there a similarly named function that converts the levels
of a factor to lower case instead of converting the factor to
a character vector and then lower-casing that?

> d %>% dplyr::mutate_if(is.factor, tolower)
  Num    F1 F2
1   1   one  a
2   2   two  b
3   3 three  a
> str(.Last.value)
'data.frame':   3 obs. of  3 variables:
 $ Num: int  1 2 3
 $ F1 : chr  "one" "two" "three"
 $ F2 : chr  "a" "b" "a"


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Oct 31, 2016 at 12:39 PM, Yahya Laraki <larakiyahya at gmail.com>
wrote:

> Thank you for your help! I found this solution much simpler:
> d <- data.frame(Num=1:3, F1=c("One","Two","Three"), F2=c("A","B","a ?))
> d %>% mutate_if(is.factor, to lower)
>
> Thank you again for taking time to respond!!
>
> Yahya
>
> Le 31 oct. 2016 ? 15:28, William Dunlap <wdunlap at tibco.com> a ?crit :
>
> Use tolower on the levels of the factor columns.  E.g.,
>
> > d <- data.frame(Num=1:3, F1=c("One","Two","Three"), F2=c("A","B","a"))
> > str(d)
> 'data.frame':   3 obs. of  3 variables:
>  $ Num: int  1 2 3
>  $ F1 : Factor w/ 3 levels "One","Three",..: 1 3 2
>  $ F2 : Factor w/ 3 levels "a","A","B": 2 3 1
> > for(n in names(d))
> +    if (is.factor(d[[n]])) levels(d[[n]]) <- tolower(levels(d[[n]]))
> > str(d)
> 'data.frame':   3 obs. of  3 variables:
>  $ Num: int  1 2 3
>  $ F1 : Factor w/ 3 levels "one","three",..: 1 3 2
>  $ F2 : Factor w/ 2 levels "a","b": 1 2 1
>
> Using data.frame(tolower(as.matrix(d))) may change your column names
> and the data in your columns - don't do it.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Oct 31, 2016 at 7:44 AM, Yahya Laraki <larakiyahya at gmail.com>
> wrote:
>
>> Hi everybody,
>>
>> I?m new to R and i?m trying to learn fundamentals. I?m facing a small
>> problem for which i can?t find a solution online.
>>
>> What i want to do: write a function to lower case for all the columns in
>> my data.frame if they respect a condition (class = factor)
>>
>> This code works, but for all my columns : change_lower = function(x)
>> {data.frame(tolower(as.matrix(x)))}
>>
>> I need more something like this, but it doesn?t work: function (x) { for
>> (i in 1:length(x)) {
>>   if (class(i)=="factor") {
>>     data.frame(tolower(as.matrix(x)))
>>   }
>> }}
>>
>> Thank you
>>
>> Yahya
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Oct 31 22:02:30 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 31 Oct 2016 14:02:30 -0700
Subject: [R] Installing polycor package
In-Reply-To: <SN2PR07MB26393AFC36B14F11E450F91CA2AE0@SN2PR07MB2639.namprd07.prod.outlook.com>
References: <SN2PR07MB26393AFC36B14F11E450F91CA2AE0@SN2PR07MB2639.namprd07.prod.outlook.com>
Message-ID: <9C85347C-B734-4C12-9E76-ACD147A9A969@dcn.davis.ca.us>

"any advice" is to use the latest R and packages. Unfortunately the number of things that can go wrong trying to keep an old version of R working is too extensive for this list to support (per Posting Guide).

If you wish to proceed without support then by all means download any older versions of the packages that you need from the CRAN archives manually and install those files directly rather than trying to automatically download and install. Keep in mind that contributed package authors might have fixed bugs since then though so you may not have access to a fully-functional R analysis environment. While such authors might help you out if you get into a bind, don't be surprised if they won't... it can be enough of a headache to keep the current version of their package working without adding a whole separate historical version going too.
-- 
Sent from my phone. Please excuse my brevity.

On October 31, 2016 8:49:03 AM PDT, "Kevelson, Marisol J" <mkevelson at ets.org> wrote:
>I have been trying to install the R polycor package without any
>success. I want to install version 0.7-8 because it is supposed to work
>with R version 3.1.0, which I have to use to run an R plug-in for SPSS.
>But I get a message that polycor is not available for R version 3.1.0:
>
>>  install.packages("polycor",
>repos="C:/Users/mkevelson/Documents/polycor_0.7-8 (1)/polycor/R")
>Installing package into
>'C:/Users/mkevelson/Documents/R/win-library/3.1'
>(as 'lib' is unspecified)
>Warning: unable to access index for repository
>C:/Users/mkevelson/Documents/polycor_0.7-8
>(1)/polycor/R/bin/windows/contrib/3.1
>Warning message:
>package 'polycor' is not available (for R version 3.1.0)
>
>I also tried installing the current version of polycor directly from
>R-Forge in R version 3.3.1, also without success:
>
>> install.packages("polycor", repos="http://R-Forge.R-project.org")
>Installing package into
>'C:/Users/mkevelson/Documents/R/win-library/3.3'
>(as 'lib' is unspecified)
>also installing the dependency 'mvtnorm'
>
>trying URL
>'http://R-Forge.R-project.org/bin/windows/contrib/3.3/mvtnorm_1.0-5.zip'
>Content type 'application/zip' length 408362 bytes (398 KB)
>downloaded 292 KB
>
>trying URL
>'http://R-Forge.R-project.org/bin/windows/contrib/3.3/polycor_0.7-10.zip'
>Content type 'application/zip' length 52183 bytes (50 KB)
>downloaded 50 KB
>
>Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>"Type")) :
>  cannot open the connection
>In addition: Warning messages:
>1: In download.file(url, destfile, method, mode = "wb", ...) :
>  downloaded length 299008 != reported length 408362
>2: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
>file
>3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
>:
>cannot open compressed file 'mvtnorm/DESCRIPTION', probable reason 'No
>such file or directory'
>
>I would greatly appreciate any advice you have on how to successfully
>install the polycor package.
>
>Thank you,
>
>Marisol
>
>
>
>________________________________
>
>This e-mail and any files transmitted with it may contain privileged or
>confidential information. It is solely for use by the individual for
>whom it is intended, even if addressed incorrectly. If you received
>this e-mail in error, please notify the sender; do not disclose, copy,
>distribute, or take any action in reliance on the contents of this
>information; and delete it from your system. Any other use of this
>e-mail is prohibited.
>
>
>Thank you for your compliance.
>
>________________________________
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mkevelson at ets.org  Mon Oct 31 22:36:45 2016
From: mkevelson at ets.org (Kevelson, Marisol J)
Date: Mon, 31 Oct 2016 21:36:45 +0000
Subject: [R] Installing polycor package
In-Reply-To: <9C85347C-B734-4C12-9E76-ACD147A9A969@dcn.davis.ca.us>
References: <SN2PR07MB26393AFC36B14F11E450F91CA2AE0@SN2PR07MB2639.namprd07.prod.outlook.com>
	<9C85347C-B734-4C12-9E76-ACD147A9A969@dcn.davis.ca.us>
Message-ID: <SN2PR07MB2639B64BD97DFB837A533A5BA2AE0@SN2PR07MB2639.namprd07.prod.outlook.com>

Thank you. I understand that it's best to use the current versions of R packages. Neither the current version of polycor nor the current version of mvtnorm would install when I used the most recent version of R, 3.3.1:

> install.packages("polycor", repos="http://R-Forge.R-project.org")
Warning in install.packages("polycor", repos = "http://R-Forge.R-project.org") :
  'lib = "C:/Program Files/R/R-3.3.1/library"' is not writable
also installing the dependency ?mvtnorm?

trying URL 'http://R-Forge.R-project.org/bin/windows/contrib/3.3/mvtnorm_1.0-5.zip'
Content type 'application/zip' length 408362 bytes (398 KB)
downloaded 292 KB

trying URL 'http://R-Forge.R-project.org/bin/windows/contrib/3.3/polycor_0.7-10.zip'
Content type 'application/zip' length 52183 bytes (50 KB)
downloaded 50 KB

Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
  cannot open the connection
In addition: Warning messages:
1: In download.file(url, destfile, method, mode = "wb", ...) :
  downloaded length 299008 != reported length 408362
2: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
  cannot open compressed file 'mvtnorm/DESCRIPTION', probable reason 'No such file or directory'



-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
Sent: Monday, October 31, 2016 5:03 PM
To: Kevelson, Marisol J <mkevelson at ets.org>; r-help at r-project.org
Subject: Re: [R] Installing polycor package

"any advice" is to use the latest R and packages. Unfortunately the number of things that can go wrong trying to keep an old version of R working is too extensive for this list to support (per Posting Guide).

If you wish to proceed without support then by all means download any older versions of the packages that you need from the CRAN archives manually and install those files directly rather than trying to automatically download and install. Keep in mind that contributed package authors might have fixed bugs since then though so you may not have access to a fully-functional R analysis environment. While such authors might help you out if you get into a bind, don't be surprised if they won't... it can be enough of a headache to keep the current version of their package working without adding a whole separate historical version going too.
--
Sent from my phone. Please excuse my brevity.

On October 31, 2016 8:49:03 AM PDT, "Kevelson, Marisol J" <mkevelson at ets.org> wrote:
>I have been trying to install the R polycor package without any
>success. I want to install version 0.7-8 because it is supposed to work
>with R version 3.1.0, which I have to use to run an R plug-in for SPSS.
>But I get a message that polycor is not available for R version 3.1.0:
>
>>  install.packages("polycor",
>repos="C:/Users/mkevelson/Documents/polycor_0.7-8 (1)/polycor/R")
>Installing package into
>'C:/Users/mkevelson/Documents/R/win-library/3.1'
>(as 'lib' is unspecified)
>Warning: unable to access index for repository
>C:/Users/mkevelson/Documents/polycor_0.7-8
>(1)/polycor/R/bin/windows/contrib/3.1
>Warning message:
>package 'polycor' is not available (for R version 3.1.0)
>
>I also tried installing the current version of polycor directly from
>R-Forge in R version 3.3.1, also without success:
>
>> install.packages("polycor", repos="http://R-Forge.R-project.org")
>Installing package into
>'C:/Users/mkevelson/Documents/R/win-library/3.3'
>(as 'lib' is unspecified)
>also installing the dependency 'mvtnorm'
>
>trying URL
>'http://R-Forge.R-project.org/bin/windows/contrib/3.3/mvtnorm_1.0-5.zip'
>Content type 'application/zip' length 408362 bytes (398 KB) downloaded
>292 KB
>
>trying URL
>'http://R-Forge.R-project.org/bin/windows/contrib/3.3/polycor_0.7-10.zip'
>Content type 'application/zip' length 52183 bytes (50 KB) downloaded 50
>KB
>
>Error in read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package",
>"Type")) :
>  cannot open the connection
>In addition: Warning messages:
>1: In download.file(url, destfile, method, mode = "wb", ...) :
>  downloaded length 299008 != reported length 408362
>2: In unzip(zipname, exdir = dest) : error 1 in extracting from zip
>file
>3: In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type"))
>:
>cannot open compressed file 'mvtnorm/DESCRIPTION', probable reason 'No
>such file or directory'
>
>I would greatly appreciate any advice you have on how to successfully
>install the polycor package.
>
>Thank you,
>
>Marisol
>
>
>
>________________________________
>
>This e-mail and any files transmitted with it may contain privileged or
>confidential information. It is solely for use by the individual for
>whom it is intended, even if addressed incorrectly. If you received
>this e-mail in error, please notify the sender; do not disclose, copy,
>distribute, or take any action in reliance on the contents of this
>information; and delete it from your system. Any other use of this
>e-mail is prohibited.
>
>
>Thank you for your compliance.
>
>________________________________
>
>[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


________________________________

This e-mail and any files transmitted with it may contain privileged or confidential information. It is solely for use by the individual for whom it is intended, even if addressed incorrectly. If you received this e-mail in error, please notify the sender; do not disclose, copy, distribute, or take any action in reliance on the contents of this information; and delete it from your system. Any other use of this e-mail is prohibited.


Thank you for your compliance.

________________________________

From bgunter.4567 at gmail.com  Mon Oct 31 23:22:25 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 31 Oct 2016 15:22:25 -0700
Subject: [R] Permutations in matched-pair study where combinations of
 pairs change
In-Reply-To: <BN6PR11MB1764D467976D8714D9F4AD3DAEAE0@BN6PR11MB1764.namprd11.prod.outlook.com>
References: <BN6PR11MB1764D467976D8714D9F4AD3DAEAE0@BN6PR11MB1764.namprd11.prod.outlook.com>
Message-ID: <CAGxFJbRsu_wA1j3VkdGx_QZ=EutJ_xGCYns72=pCmKg2LGyqSw@mail.gmail.com>

You may get a reply here, but this post belongs on a statistics list
like stats.stackexchange.com, not r-help, which is concerned about R
programming issues rather than statistical methodology.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Oct 31, 2016 at 5:54 AM, Luke Gaylor <luke.gaylor at live.com.au> wrote:
> Friends,
>
>
> Matched pairs studies are well documented, but what happens if we were to alter the manner in which events were paired to one another. Say we change the order of our data and pair without replacement, so that event 1 may pair with event 23 in one instance, but also event 36 or 102 in other instances.
>
> Matched pair study can then be used to determine the effectiveness of, for example a treatment program, on a given outcome. The outcome may be continuous or variable. Therefore, a conditional logistic regression model can output an odds ratio (and confidence intervals for the treatment coefficient). Or we may use a paired t-test to assess if the difference in means between the pairs differ.
>
> I am more favored to the logistic regression and output of the odds ratio, however it changes for each permutation. As too does its confidence interval. So my question is how can we report on a string of given odds ratios - how can be arrive at a statistical sound conclusion? Or accounting for the study design, where we achieve different combinations of matched pairs, how can be comment on the effectiveness of a given treatment program?
>
> Below I have attached a code, which simulates a 100-fold permutation.
>
>
> Any advice would be greatly appreciated,
> Luke
>
>
> Set.seed(123)
> # prepare the data for the simulation
> #1.
> library(Matching)
> library(survival)
> library(dplyr)
> #2.
> require(doParallel)
> cl<-makeCluster(2)
> registerDoParallel(cl)
> #3.
> clusterEvalQ(cl,library(Matching))
> clusterEvalQ(cl,library(survival))
> clusterEvalQ(cl,library(dplyr))
>
> # number of permutations
> m <- 100
>
>
> Result = foreach(i=1:m,.combine=cbind) %do%{
>
>   # taking from the example from the Matching package
>   #attach the data
>   data(lalonde)
>
>   # we want to assess if treatment shows an influence on a given outcome of interest
>   # lets create our hypothetical example
>   lalonde$success <- with(lalonde, ifelse(re78 > 8125, 1, 0))
>
>   # adjust the order of the data
>   lalonde <- lalonde[sample(1:nrow(lalonde)), ]
>   head(lalonde$age)
>
>
>   # Define the covariates we want to match on
>   Xmat = cbind(lalonde$age, lalonde$educ, lalonde$married, lalonde$nodegr)
>
>   # define crude matching
>   mgen1 <- Match(Y=NULL, Tr=lalonde$treat,
>                  X=Xmat,
>                  exact=c(0,1,1,1),
>                  replace=FALSE, ties=F)
>
>   summary(mgen1)
>
>   # obtain initial pair-combinations
>   matched <- rbind(lalonde[mgen1$index.treated,], lalonde[mgen1$index.control,])
>
>   # generate a dummy variable for our each pair of people
>   matched$Pair_ID <- rep(1:length(mgen1$index.treated),2)
>
>   # crude filtering
>   # set hard limits of age
>   # must be within +-2 years
>   Matched2 <- matched %>%
>     group_by(Pair_ID) %>%
>     filter(abs( age[treat == 1] - age[treat == 0]) <= 2)
>
>   # summary table
>   table(Matched2$treat, Matched2$success)
>
>   # so now we have a cohort of similar events
>   # each pair contains one treat and one non-treat event
>
>
>   #######################################################
>   #                                                     #
>   #     H E R E   W E   A R E   T R Y I N G    T O      #
>   #  A S S E S S   T H E    E F F E C T I V E N E S S   #
>   #   O F   T R E A T M E N T   T O    A C H I E V E    #
>   #               s U C C E S S                         #
>   #                                                     #
>   #######################################################
>
>
>   # One could implement a parametric difference of means test
>   # t-test - (as the outcome of interest is binary)
>   # to assess if differences between pairs change
>
>   diff_means<- t.test(Matched2$success[Matched2$treat==1], Matched2$success[Matched2$treat==0],
>          paired = T, alternative = "two.sided", conf.level = 0.95)
>   diff_means$p.value
>
>   # output the series of p-values for each permutation
>
>   # ===========================================
>   # Or
>   # ===========================================
>
>   # obtain an estimated effectiveness value from a conditional logistic regression
>   # namely, the Odds Ratio coefficient for 'treat'
>   model_1 <- clogit(success ~ treat + strata(Pair_ID), matched)
>   summary(model_1)
>
>   OR_M1 <- exp(model_1$coefficients[1])
>
>   # we can save the confidence intervals for the 'treat' effectiveness
>   CI_U1 <- exp(confint(model_1))[1,2]
>   CI_L1 <- exp(confint(model_1))[1,1]
>
>   # then we could output any of the following
>   #Result <- diff_means$p.value
>   #Result <- OR_M1
>   #Result <- rbind(OR_M1, CI_U1, CI_L1)
>
>   Result <- OR_M1
>
> }
>
> summary(Result[1,])
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From NordlDJ at dshs.wa.gov  Mon Oct 31 23:29:01 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Mon, 31 Oct 2016 22:29:01 +0000
Subject: [R] function ave() with seq_along returning char sequence instead
 of numeric
Message-ID: <F7E6D18CC2877149AB5296CE54EA276635B9A7CC@WAXMXOLYMB025.WAX.wa.lcl>

Given  the following R statements

v <-  c('a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'c', 'c')
ave(v, list(v), FUN=seq_along)
 [1] "1" "2" "3" "1" "2" "3" "1" "2" "3" "4" 

I was expecting to get a numeric vector back.  I apparently have missed something in the documentation.  If vector v is character, then the numeric sequence is converted to character before returning.  I can work around by doing something like

ave(seq_along(v), list(v), FUN=seq_along)
 [1] 1 2 3 1 2 3 1 2 3 4 

Is the work around the best way to go, or have I missed an option in the documentation?


Thanks,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


From elhamdallalbashi at gmail.com  Mon Oct 31 21:36:52 2016
From: elhamdallalbashi at gmail.com (Elham Dallalbashi)
Date: Tue, 1 Nov 2016 00:06:52 +0330
Subject: [R] store result of meta analysis by Rstudio
Message-ID: <CAJpR6yjO+tP6p=jpdtrt=tjDAhZy+JJ+PTmh011QcWkY303Abg@mail.gmail.com>

hi everyone,
how can I store result of meta analysis by Rstudio,I can not save the
result of metaseq and metaDE package,I want to use sink to store the output
in a file.
in metaseq package there are several objects to store:(I copy example of
this package)

> head(F$Upper)

1/2-SBSRNA4 A1BG A1BG-AS1 A1CF A2LD1
0.3842542 0.5316118 0.5325544 NA 0.1358559
A2M
0.2252807

> head(F$Lower)

1/2-SBSRNA4 A1BG A1BG-AS1 A1CF A2LD1
0.8420357 0.6078896 0.4047202 NA 0.3661371
A2M
0.6197968
> F$Weight
Study 1 Study 2 Study 3 Study 4
5 2 8 3

> head(S$Upper)

1/2-SBSRNA4 A1BG A1BG-AS1 A1CF A2LD1
0.3709297 0.2663748 0.2711745 NA 0.2957139
A2M
0.2996707

> head(S$Lower)

1/2-SBSRNA4 A1BG A1BG-AS1 A1CF A2LD1
0.6290703 0.7336252 0.7288255 NA 0.7042861
A2M
0.7003293

> S$Weight

Study 1 Study 2 Study 3 Study 4
5 2 8 3



thanks for help.

	[[alternative HTML version deleted]]


