From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Sun Mar  2 15:56:29 2025
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Sun, 2 Mar 2025 14:56:29 +0000
Subject: [R] expression in lattice panel strip
Message-ID: <IA1P223MB04997BF88B4F3ECDFB5FA8ECFACE2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>

Is it possible to include expression in lattice panel strip?
Thanks,
Naresh

cs <- 2 * cos(2 * pi * (1:500) / 50 + 0.6 * pi)
w <- rnorm(500)
xyplot(ts(cbind(x1 = cs, x2 = cs + w)), screens = list(x1 = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi)), x2 = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi) + N(0, 1))), type = c("l", "g"), main = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi)))

# Greek letter pi is shown in main title, but not in panel strips

From bgunter@4567 @end|ng |rom gm@||@com  Mon Mar  3 02:07:51 2025
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 2 Mar 2025 17:07:51 -0800
Subject: [R] expression in lattice panel strip
In-Reply-To: <IA1P223MB04997BF88B4F3ECDFB5FA8ECFACE2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
References: <IA1P223MB04997BF88B4F3ECDFB5FA8ECFACE2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbRuXsPDPdhV7Ob3Fv_uxgxi71H1ubNjCRGf=1egf=wbiQ@mail.gmail.com>

Full disclosure: I have never plotted time series using this xyplot method.

However, ?xyplot.ts says:

"screens

factor (or coerced to factor) whose levels specify which panel each
series is to be plotted in. screens = c(1, 2, 1) would plot series 1,
2 and 3 in panels 1, 2 and 1. May also be a named list, see Details
below."

>From that I would infer the answer to your query in no: factors, know
nothing about plotmath notation, and as.factor() just coerces your
expressions to character strings that are the factor labels.
strip.default() then uses these character strings as the labels for
the strips, giving what you got.

As you only want to use a "pi" character, ?, in your math expression,
I tried using a UTF-8 symbol for it, \U1D6D1, in quoted strings as the
argument for the screens parameter. That is:

striplabs <- factor(c("2cos(2\U1D6D1t/50 + 0.6\U1D6D1)",
                      "2cos(2\U1D6D1t /50 + 0.6\U1D6D1) + N(0, 1)"))
xyplot(ts(cbind(x1 = cs, x2 = cs + w)),
       type = c("l", "g"),
       main = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi)),
       screens = striplabs
)

The RStudio graphics device was *not* able to interpret the UTF-8 in
the strip, but on my Mac, the Cairo_pdf() device (or just using the
export button to export the graphic as a pdf from RStudio) *did*
reproduce the characters nicely in the strip labels in the pdf.
Unfortunately, the main title expression symbol for pi (presumably
from the adobe font symbols) did not look nice. However, using the
quoted graphics string (the first level of the striplabs factor) does
fine, of course.

As I just sort of barely know what I'm doing here, there may be a much
better way to do this by using an appropriate font specification in a
strip = strip.custom(par.strip.text= ...) argument to xyplot, but that
exceeds my current abilities. Maybe you or one of the R cognescenti
can figure it  out.

Again, please note my full disclosure.

Cheers,
Bert

"An educated person is one who can entertain new ideas, entertain
others, and entertain herself."

"An educated person is one who can entertain new ideas, entertain
others, and entertain herself."



On Sun, Mar 2, 2025 at 6:56?AM Naresh Gurbuxani
<naresh_gurbuxani at hotmail.com> wrote:
>
> Is it possible to include expression in lattice panel strip?
> Thanks,
> Naresh
>
> cs <- 2 * cos(2 * pi * (1:500) / 50 + 0.6 * pi)
> w <- rnorm(500)
> xyplot(ts(cbind(x1 = cs, x2 = cs + w)), screens = list(x1 = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi)), x2 = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi) + N(0, 1))), type = c("l", "g"), main = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi)))
>
> # Greek letter pi is shown in main title, but not in panel strips
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Mon Mar  3 07:08:05 2025
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Mon, 3 Mar 2025 11:38:05 +0530
Subject: [R] expression in lattice panel strip
In-Reply-To: <CAGxFJbRuXsPDPdhV7Ob3Fv_uxgxi71H1ubNjCRGf=1egf=wbiQ@mail.gmail.com>
References: <IA1P223MB04997BF88B4F3ECDFB5FA8ECFACE2@IA1P223MB0499.NAMP223.PROD.OUTLOOK.COM>
 <CAGxFJbRuXsPDPdhV7Ob3Fv_uxgxi71H1ubNjCRGf=1egf=wbiQ@mail.gmail.com>
Message-ID: <CADfFDC6bxDOfsDbVPi=pCRE1pGHCqQOokYVg+KKgpbKLu--puQ@mail.gmail.com>

This is possible but a little cumbersome. Bert is on the right track with
strip.custom:

xyplot(ts(cbind(x1 = cs, x2 = cs + w)),
       strip = strip.custom(factor.levels =
                                expression(2 * cos(2 * pi * t / 50 + 0.6 *
pi),
                                           2 * cos(2 * pi * t / 50 + 0.6 *
pi) + N(0, 1))),
       type = c("l", "g"),
       main = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi)))

where (from the docs):

factor.levels: vector of character strings or expressions giving the
          levels of the conditioning variable currently being drawn.
          For more than one conditioning variable, this will vary with
          'which.given'.

This is relatively straightforward with only one conditioning variable. A
more general solution for multiple conditioning variables would be

estrip <- function(..., factor.levels)
{
    strip.default(..., factor.levels = parse(text = factor.levels))
}

xyplot(ts(cbind(x1 = cs, x2 = cs + w)),
       screens = list(x1 = "2 * cos(2 * pi * t / 50 + 0.6 * pi)",
                      x2 = "2 * cos(2 * pi * t / 50 + 0.6 * pi) + N(0, 1)"),
       strip = estrip,
       type = c("l", "g"),
       main = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi)))

Best,
-Deepayan

On Mon, 3 Mar 2025 at 06:38, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Full disclosure: I have never plotted time series using this xyplot method.
>
> However, ?xyplot.ts says:
>
> "screens
>
> factor (or coerced to factor) whose levels specify which panel each
> series is to be plotted in. screens = c(1, 2, 1) would plot series 1,
> 2 and 3 in panels 1, 2 and 1. May also be a named list, see Details
> below."
>
> From that I would infer the answer to your query in no: factors, know
> nothing about plotmath notation, and as.factor() just coerces your
> expressions to character strings that are the factor labels.
> strip.default() then uses these character strings as the labels for
> the strips, giving what you got.
>
> As you only want to use a "pi" character, ?, in your math expression,
> I tried using a UTF-8 symbol for it, \U1D6D1, in quoted strings as the
> argument for the screens parameter. That is:
>
> striplabs <- factor(c("2cos(2\U1D6D1t/50 + 0.6\U1D6D1)",
>                       "2cos(2\U1D6D1t /50 + 0.6\U1D6D1) + N(0, 1)"))
> xyplot(ts(cbind(x1 = cs, x2 = cs + w)),
>        type = c("l", "g"),
>        main = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi)),
>        screens = striplabs
> )
>
> The RStudio graphics device was *not* able to interpret the UTF-8 in
> the strip, but on my Mac, the Cairo_pdf() device (or just using the
> export button to export the graphic as a pdf from RStudio) *did*
> reproduce the characters nicely in the strip labels in the pdf.
> Unfortunately, the main title expression symbol for pi (presumably
> from the adobe font symbols) did not look nice. However, using the
> quoted graphics string (the first level of the striplabs factor) does
> fine, of course.
>
> As I just sort of barely know what I'm doing here, there may be a much
> better way to do this by using an appropriate font specification in a
> strip = strip.custom(par.strip.text= ...) argument to xyplot, but that
> exceeds my current abilities. Maybe you or one of the R cognescenti
> can figure it  out.
>
> Again, please note my full disclosure.
>
> Cheers,
> Bert
>
> "An educated person is one who can entertain new ideas, entertain
> others, and entertain herself."
>
> "An educated person is one who can entertain new ideas, entertain
> others, and entertain herself."
>
>
>
> On Sun, Mar 2, 2025 at 6:56?AM Naresh Gurbuxani
> <naresh_gurbuxani at hotmail.com> wrote:
> >
> > Is it possible to include expression in lattice panel strip?
> > Thanks,
> > Naresh
> >
> > cs <- 2 * cos(2 * pi * (1:500) / 50 + 0.6 * pi)
> > w <- rnorm(500)
> > xyplot(ts(cbind(x1 = cs, x2 = cs + w)), screens = list(x1 = expression(2
> * cos(2 * pi * t / 50 + 0.6 * pi)), x2 = expression(2 * cos(2 * pi * t / 50
> + 0.6 * pi) + N(0, 1))), type = c("l", "g"), main = expression(2 * cos(2 *
> pi * t / 50 + 0.6 * pi)))
> >
> > # Greek letter pi is shown in main title, but not in panel strips
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Mar  3 07:38:43 2025
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 3 Mar 2025 12:08:43 +0530
Subject: [R] Failed to convert data to numeric
Message-ID: <CA+dpOJmdNDT6Y2n5UDZgUj8c1E77TupPfT5MhgbRNZW5XSgjFg@mail.gmail.com>

Hi,

I have below data

dat2 = c("-24.437285333333300", "4.850695000000000", "-1.918495666666670",

"2.641818000000000", "6.777527666666670", "3.208084000000000",

"4.193287666666670", "0.378257666666667", "4.658955000000000",

"?-9.881474000000000")

Now when I try to convert this data to numeric, I got NA as below

> as.numeric(dat2)

 [1] -24.4372853   4.8506950  -1.9184957   2.6418180   6.7775277   3.2080840

 [7]   4.1932877   0.3782577   4.6589550          NA

Could you please help to understand why I get NA for the last value?

> sessionInfo()

R version 4.4.0 (2024-04-24)

Platform: aarch64-apple-darwin20

Running under: macOS 15.3.1


Matrix products: default

BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib

LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;
 LAPACK version 3.12.0


locale:

[1] C/UTF-8/C/C/C/C


time zone: Asia

tzcode source: internal


attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base


loaded via a namespace (and not attached):

[1] compiler_4.4.0


From |kry|ov @end|ng |rom d|@root@org  Mon Mar  3 07:48:37 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 3 Mar 2025 09:48:37 +0300
Subject: [R] Failed to convert data to numeric
In-Reply-To: <CA+dpOJmdNDT6Y2n5UDZgUj8c1E77TupPfT5MhgbRNZW5XSgjFg@mail.gmail.com>
References: <CA+dpOJmdNDT6Y2n5UDZgUj8c1E77TupPfT5MhgbRNZW5XSgjFg@mail.gmail.com>
Message-ID: <20250303094837.32820c87@Tarkus>

? Mon, 3 Mar 2025 12:08:43 +0530
Christofer Bogaso <bogaso.christofer at gmail.com> ?????:

> dat2 = c("-24.437285333333300", "4.850695000000000",
> "-1.918495666666670",
> 
> "2.641818000000000", "6.777527666666670", "3.208084000000000",
> 
> "4.193287666666670", "0.378257666666667", "4.658955000000000",
> 
> "?-9.881474000000000")
> 
> Now when I try to convert this data to numeric, I got NA as below
> 
> > as.numeric(dat2)  
> 
>  [1] -24.4372853   4.8506950  -1.9184957   2.6418180   6.7775277
> 3.2080840
> 
>  [7]   4.1932877   0.3782577   4.6589550          NA

There's an invisible Unicode character in there, U+FEFF ZERO WIDTH
NO-BREAK SPACE:

> dat2 |> tail(1) |> tools::showNonASCII()
1: <ef><bb><bf>-9.881474000000000

Try as.numeric(gsub('\ufeff', '', dat2)).

-- 
Best regards,
Ivan


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Mar  3 08:51:31 2025
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 3 Mar 2025 13:21:31 +0530
Subject: [R] Failed to convert data to numeric
In-Reply-To: <20250303094837.32820c87@Tarkus>
References: <CA+dpOJmdNDT6Y2n5UDZgUj8c1E77TupPfT5MhgbRNZW5XSgjFg@mail.gmail.com>
 <20250303094837.32820c87@Tarkus>
Message-ID: <CA+dpOJnHQOj+rbOJXhSNxHGerqNCaiAfARtkvo_=87jiD93OTw@mail.gmail.com>

Hi Ivan,

Thanks for your solution.

Is there any way to remove all possible "Unicode character" that may
be present in the array at once?

On Mon, Mar 3, 2025 at 12:18?PM Ivan Krylov <ikrylov at disroot.org> wrote:
>
> ? Mon, 3 Mar 2025 12:08:43 +0530
> Christofer Bogaso <bogaso.christofer at gmail.com> ?????:
>
> > dat2 = c("-24.437285333333300", "4.850695000000000",
> > "-1.918495666666670",
> >
> > "2.641818000000000", "6.777527666666670", "3.208084000000000",
> >
> > "4.193287666666670", "0.378257666666667", "4.658955000000000",
> >
> > "?-9.881474000000000")
> >
> > Now when I try to convert this data to numeric, I got NA as below
> >
> > > as.numeric(dat2)
> >
> >  [1] -24.4372853   4.8506950  -1.9184957   2.6418180   6.7775277
> > 3.2080840
> >
> >  [7]   4.1932877   0.3782577   4.6589550          NA
>
> There's an invisible Unicode character in there, U+FEFF ZERO WIDTH
> NO-BREAK SPACE:
>
> > dat2 |> tail(1) |> tools::showNonASCII()
> 1: <ef><bb><bf>-9.881474000000000
>
> Try as.numeric(gsub('\ufeff', '', dat2)).
>
> --
> Best regards,
> Ivan


From |kry|ov @end|ng |rom d|@root@org  Mon Mar  3 09:09:22 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 3 Mar 2025 11:09:22 +0300
Subject: [R] Failed to convert data to numeric
In-Reply-To: <CA+dpOJnHQOj+rbOJXhSNxHGerqNCaiAfARtkvo_=87jiD93OTw@mail.gmail.com>
References: <CA+dpOJmdNDT6Y2n5UDZgUj8c1E77TupPfT5MhgbRNZW5XSgjFg@mail.gmail.com>
 <20250303094837.32820c87@Tarkus>
 <CA+dpOJnHQOj+rbOJXhSNxHGerqNCaiAfARtkvo_=87jiD93OTw@mail.gmail.com>
Message-ID: <20250303110922.1e9ecb49@Tarkus>

? Mon, 3 Mar 2025 13:21:31 +0530
Christofer Bogaso <bogaso.christofer at gmail.com> ?????:

> Is there any way to remove all possible "Unicode character" that may
> be present in the array at once?

Define a range of characters you consider acceptable, and you'll be
able to use regular expressions to remove everything else. For example,
the following expression should remove everything except ASCII digits,
dots, and hyphen-minus:

gsub('[^0-9.-]+', '', dat2)

There is a brief introduction to regular expressions in ?regex and
various online resources such as <https://regex101.com/>.

-- 
Best regards,
Ivan


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Mar  3 09:33:40 2025
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 03 Mar 2025 00:33:40 -0800
Subject: [R] [Tagged]  Re:  Failed to convert data to numeric
In-Reply-To: <20250303110922.1e9ecb49@Tarkus>
References: <CA+dpOJmdNDT6Y2n5UDZgUj8c1E77TupPfT5MhgbRNZW5XSgjFg@mail.gmail.com>
 <20250303094837.32820c87@Tarkus>
 <CA+dpOJnHQOj+rbOJXhSNxHGerqNCaiAfARtkvo_=87jiD93OTw@mail.gmail.com>
 <20250303110922.1e9ecb49@Tarkus>
Message-ID: <E6FF9AA7-B4B2-43E1-94A3-EBE75CDF7E33@dcn.davis.ca.us>

?tools::showNonASCII

On March 3, 2025 12:09:22 AM PST, Ivan Krylov via R-help <r-help at r-project.org> wrote:
>? Mon, 3 Mar 2025 13:21:31 +0530
>Christofer Bogaso <bogaso.christofer at gmail.com> ?????:
>
>> Is there any way to remove all possible "Unicode character" that may
>> be present in the array at once?
>
>Define a range of characters you consider acceptable, and you'll be
>able to use regular expressions to remove everything else. For example,
>the following expression should remove everything except ASCII digits,
>dots, and hyphen-minus:
>
>gsub('[^0-9.-]+', '', dat2)
>
>There is a brief introduction to regular expressions in ?regex and
>various online resources such as <https://regex101.com/>.
>

-- 
Sent from my phone. Please excuse my brevity.


From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Mon Mar  3 11:54:37 2025
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Mon, 3 Mar 2025 10:54:37 +0000
Subject: [R] expression in lattice panel strip
In-Reply-To: <CADfFDC6bxDOfsDbVPi=pCRE1pGHCqQOokYVg+KKgpbKLu--puQ@mail.gmail.com>
References: <CADfFDC6bxDOfsDbVPi=pCRE1pGHCqQOokYVg+KKgpbKLu--puQ@mail.gmail.com>
Message-ID: <DM4P223MB0519AB58C5F791B2363181C1FAC92@DM4P223MB0519.NAMP223.PROD.OUTLOOK.COM>

Thanks all for your responses.  My problem is solved.

Sent from my iPhone

On Mar 3, 2025, at 1:08?AM, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:

?
This is possible but a little cumbersome. Bert is on the right track with strip.custom:

xyplot(ts(cbind(x1 = cs, x2 = cs + w)),
       strip = strip.custom(factor.levels =
                                expression(2 * cos(2 * pi * t / 50 + 0.6 * pi),
                                           2 * cos(2 * pi * t / 50 + 0.6 * pi) + N(0, 1))),
       type = c("l", "g"),
       main = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi)))

where (from the docs):

factor.levels: vector of character strings or expressions giving the
          levels of the conditioning variable currently being drawn.
          For more than one conditioning variable, this will vary with
          'which.given'.

This is relatively straightforward with only one conditioning variable. A more general solution for multiple conditioning variables would be

estrip <- function(..., factor.levels)
{
    strip.default(..., factor.levels = parse(text = factor.levels))
}

xyplot(ts(cbind(x1 = cs, x2 = cs + w)),
       screens = list(x1 = "2 * cos(2 * pi * t / 50 + 0.6 * pi)",
                      x2 = "2 * cos(2 * pi * t / 50 + 0.6 * pi) + N(0, 1)"),
       strip = estrip,
       type = c("l", "g"),
       main = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi)))

Best,
-Deepayan

On Mon, 3 Mar 2025 at 06:38, Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>> wrote:
Full disclosure: I have never plotted time series using this xyplot method.

However, ?xyplot.ts says:

"screens

factor (or coerced to factor) whose levels specify which panel each
series is to be plotted in. screens = c(1, 2, 1) would plot series 1,
2 and 3 in panels 1, 2 and 1. May also be a named list, see Details
below."

From that I would infer the answer to your query in no: factors, know
nothing about plotmath notation, and as.factor() just coerces your
expressions to character strings that are the factor labels.
strip.default() then uses these character strings as the labels for
the strips, giving what you got.

As you only want to use a "pi" character, ?, in your math expression,
I tried using a UTF-8 symbol for it, \U1D6D1, in quoted strings as the
argument for the screens parameter. That is:

striplabs <- factor(c("2cos(2\U1D6D1t/50 + 0.6\U1D6D1)",
                      "2cos(2\U1D6D1t /50 + 0.6\U1D6D1) + N(0, 1)"))
xyplot(ts(cbind(x1 = cs, x2 = cs + w)),
       type = c("l", "g"),
       main = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi)),
       screens = striplabs
)

The RStudio graphics device was *not* able to interpret the UTF-8 in
the strip, but on my Mac, the Cairo_pdf() device (or just using the
export button to export the graphic as a pdf from RStudio) *did*
reproduce the characters nicely in the strip labels in the pdf.
Unfortunately, the main title expression symbol for pi (presumably
from the adobe font symbols) did not look nice. However, using the
quoted graphics string (the first level of the striplabs factor) does
fine, of course.

As I just sort of barely know what I'm doing here, there may be a much
better way to do this by using an appropriate font specification in a
strip = strip.custom(par.strip.text= ...) argument to xyplot, but that
exceeds my current abilities. Maybe you or one of the R cognescenti
can figure it  out.

Again, please note my full disclosure.

Cheers,
Bert

"An educated person is one who can entertain new ideas, entertain
others, and entertain herself."

"An educated person is one who can entertain new ideas, entertain
others, and entertain herself."



On Sun, Mar 2, 2025 at 6:56?AM Naresh Gurbuxani
<naresh_gurbuxani at hotmail.com<mailto:naresh_gurbuxani at hotmail.com>> wrote:
>
> Is it possible to include expression in lattice panel strip?
> Thanks,
> Naresh
>
> cs <- 2 * cos(2 * pi * (1:500) / 50 + 0.6 * pi)
> w <- rnorm(500)
> xyplot(ts(cbind(x1 = cs, x2 = cs + w)), screens = list(x1 = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi)), x2 = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi) + N(0, 1))), type = c("l", "g"), main = expression(2 * cos(2 * pi * t / 50 + 0.6 * pi)))
>
> # Greek letter pi is shown in main title, but not in panel strips
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @vi@e@gross m@iii@g oii gm@ii@com  Mon Mar  3 18:19:02 2025
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Mon, 3 Mar 2025 12:19:02 -0500
Subject: [R] Failed to convert data to numeric
In-Reply-To: <20250303110922.1e9ecb49@Tarkus>
References: <CA+dpOJmdNDT6Y2n5UDZgUj8c1E77TupPfT5MhgbRNZW5XSgjFg@mail.gmail.com>
 <20250303094837.32820c87@Tarkus>
 <CA+dpOJnHQOj+rbOJXhSNxHGerqNCaiAfARtkvo_=87jiD93OTw@mail.gmail.com>
 <20250303110922.1e9ecb49@Tarkus>
Message-ID: <007801db8c60$5c6df260$1549d720$@gmail.com>

The second solution Ivan offers looks good, and a bit more general than his first that simply removes one non-visible character.

It begs the question of why the data has that anomaly at all. Did the data come from a text-processing environment where it was going to wrap there and was protected?

As Ivan points out, there is a question of what format you expect numbers in and what "as.numeric"  should do when it does not see an integer or floating point number. 

If you test it, you can see that as.numeric ignores leading and/or trailing blanks and tabs and even newlines sometimes and some other irrelevant ASCII characters. In that spirit, the UNICODE character being mentioned should be one that any UNICODE-aware version of as.numeric should ignore.

But UNICODE supports a much wider vision of numeric so that there are numeric-equivalent symbols in other languages and groupings and even something like the symbols for numerals in light or dark circles count as numbers. Those can likely safely be excluded in this context but perhaps not in a more general function.

But I note as.numeric seems to handle scientific notation as in:

as.numeric("1.23e8")
[1] 1.23e+08

So a single instance of the letters "e" and "E" must be supported if your numbers in string form may contain them. Further, the E cannot be the first or last letter. It cannot have adjacent whitespace. Still, if you are OK with getting an NA in such situations, it should be OK.

It gets worse. Hexadecimal is supported:

> as.numeric("0X12")
[1] 18

You now need to support the letters x and X. But only if preceded by a zero! 

It gets still worse as any characters from [0-9A-F] are supported:

> as.numeric("0xAE")
[1] 174

There may be other scenarios it handles. The filter applied might remove valid numbers so you may want to carefully document it if your program only handles a restricted set.

A possible idea might be to make two passes and only  evaluate any resulting NA from as.numeric() by doing a substitution like Ivan suggests to try to fix any broken ones. But note it may fix too much as "1.2 e 5" might become "1.2e5" as spaces are removed.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Ivan Krylov via R-help
Sent: Monday, March 3, 2025 3:09 AM
To: Christofer Bogaso <bogaso.christofer at gmail.com>
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] Failed to convert data to numeric

? Mon, 3 Mar 2025 13:21:31 +0530
Christofer Bogaso <bogaso.christofer at gmail.com> ?????:

> Is there any way to remove all possible "Unicode character" that may
> be present in the array at once?

Define a range of characters you consider acceptable, and you'll be
able to use regular expressions to remove everything else. For example,
the following expression should remove everything except ASCII digits,
dots, and hyphen-minus:

gsub('[^0-9.-]+', '', dat2)

There is a brief introduction to regular expressions in ?regex and
various online resources such as <https://regex101.com/>.

-- 
Best regards,
Ivan

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ro||turner @end|ng |rom po@teo@net  Mon Mar  3 22:45:14 2025
From: ro||turner @end|ng |rom po@teo@net (Rolf Turner)
Date: Mon,  3 Mar 2025 21:45:14 +0000
Subject: [R] Failed to convert data to numeric
In-Reply-To: <007801db8c60$5c6df260$1549d720$@gmail.com>
References: <CA+dpOJmdNDT6Y2n5UDZgUj8c1E77TupPfT5MhgbRNZW5XSgjFg@mail.gmail.com>
 <20250303094837.32820c87@Tarkus>
 <CA+dpOJnHQOj+rbOJXhSNxHGerqNCaiAfARtkvo_=87jiD93OTw@mail.gmail.com>
 <20250303110922.1e9ecb49@Tarkus>
 <007801db8c60$5c6df260$1549d720$@gmail.com>
Message-ID: <20250304104514.691929c1@new-hp>


This issue looks like grist for the R Inferno.

cheers,

Rolf


On Mon, 3 Mar 2025 12:19:02 -0500
<avi.e.gross at gmail.com> wrote:

> The second solution Ivan offers looks good, and a bit more general
> than his first that simply removes one non-visible character.
> 
> It begs the question of why the data has that anomaly at all. Did the
> data come from a text-processing environment where it was going to
> wrap there and was protected?
> 
> As Ivan points out, there is a question of what format you expect
> numbers in and what "as.numeric"  should do when it does not see an
> integer or floating point number. 
> 
> If you test it, you can see that as.numeric ignores leading and/or
> trailing blanks and tabs and even newlines sometimes and some other
> irrelevant ASCII characters. In that spirit, the UNICODE character
> being mentioned should be one that any UNICODE-aware version of
> as.numeric should ignore.
> 
> But UNICODE supports a much wider vision of numeric so that there are
> numeric-equivalent symbols in other languages and groupings and even
> something like the symbols for numerals in light or dark circles
> count as numbers. Those can likely safely be excluded in this context
> but perhaps not in a more general function.
> 
> But I note as.numeric seems to handle scientific notation as in:
> 
> as.numeric("1.23e8")
> [1] 1.23e+08
> 
> So a single instance of the letters "e" and "E" must be supported if
> your numbers in string form may contain them. Further, the E cannot
> be the first or last letter. It cannot have adjacent whitespace.
> Still, if you are OK with getting an NA in such situations, it should
> be OK.
> 
> It gets worse. Hexadecimal is supported:
> 
> > as.numeric("0X12")
> [1] 18
> 
> You now need to support the letters x and X. But only if preceded by
> a zero! 
> 
> It gets still worse as any characters from [0-9A-F] are supported:
> 
> > as.numeric("0xAE")
> [1] 174
> 
> There may be other scenarios it handles. The filter applied might
> remove valid numbers so you may want to carefully document it if your
> program only handles a restricted set.
> 
> A possible idea might be to make two passes and only  evaluate any
> resulting NA from as.numeric() by doing a substitution like Ivan
> suggests to try to fix any broken ones. But note it may fix too much
> as "1.2 e 5" might become "1.2e5" as spaces are removed.
> 
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ivan Krylov
> via R-help Sent: Monday, March 3, 2025 3:09 AM
> To: Christofer Bogaso <bogaso.christofer at gmail.com>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] Failed to convert data to numeric
> 
> ? Mon, 3 Mar 2025 13:21:31 +0530
> Christofer Bogaso <bogaso.christofer at gmail.com> ?????:
> 
> > Is there any way to remove all possible "Unicode character" that may
> > be present in the array at once?
> 
> Define a range of characters you consider acceptable, and you'll be
> able to use regular expressions to remove everything else. For
> example, the following expression should remove everything except
> ASCII digits, dots, and hyphen-minus:
> 
> gsub('[^0-9.-]+', '', dat2)
> 
> There is a brief introduction to regular expressions in ?regex and
> various online resources such as <https://regex101.com/>.
> 



-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Stats. Dep't. (secretaries) phone:
         +64-9-373-7599 ext. 89622
Home phone: +64-9-480-4619


From r@oknz @end|ng |rom gm@||@com  Mon Mar  3 23:33:51 2025
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 4 Mar 2025 11:33:51 +1300
Subject: [R] Failed to convert data to numeric
In-Reply-To: <007801db8c60$5c6df260$1549d720$@gmail.com>
References: <CA+dpOJmdNDT6Y2n5UDZgUj8c1E77TupPfT5MhgbRNZW5XSgjFg@mail.gmail.com>
 <20250303094837.32820c87@Tarkus>
 <CA+dpOJnHQOj+rbOJXhSNxHGerqNCaiAfARtkvo_=87jiD93OTw@mail.gmail.com>
 <20250303110922.1e9ecb49@Tarkus> <007801db8c60$5c6df260$1549d720$@gmail.com>
Message-ID: <CABcYAdKTKJaRcN9u-uU0FPPC79WJ48VkjmLszjjjA01TWqQoPA@mail.gmail.com>

The zero-width no-break space character is used as the Byte Order
Mark.  That is, an official function for it at the beginning of a
character sequence
is to indicate whether you have 2-byte or 4-byte big-endian or
little-endian encoding.  It was not intended for use in UTF-8, where
there is nothing for
it to tell you, but Microsoft jumped in with all six feet and said
"hey, we'll use this to indicate that it's Unicode in UTF-8 and not
one of the hundreds
of other 8-bit coded character sets."  I've lost count of the number
of programs that have choked because they were given a BOM where they
didn't expect one.

So there is no great mystery about why there is a BOM at the beginning
of this particular string.
The real mystery is why it was there and NOT at the beginning of all the others.

I suggest that it is a good idea to remove the BOM character from the
beginning of microsofted strings,
but a bad idea to remove any other character.  If you are given bad
data like "Bond-007" when you
expect a number, you want to know about it, and not mistake it for
-007.  Still less do you want a
phone number like "+61 3 555 1234 x77" to be mistaken for a plain
number "613555123477".

On Tue, 4 Mar 2025 at 06:24, <avi.e.gross at gmail.com> wrote:
>
> The second solution Ivan offers looks good, and a bit more general than his first that simply removes one non-visible character.
>
> It begs the question of why the data has that anomaly at all. Did the data come from a text-processing environment where it was going to wrap there and was protected?
>
> As Ivan points out, there is a question of what format you expect numbers in and what "as.numeric"  should do when it does not see an integer or floating point number.
>
> If you test it, you can see that as.numeric ignores leading and/or trailing blanks and tabs and even newlines sometimes and some other irrelevant ASCII characters. In that spirit, the UNICODE character being mentioned should be one that any UNICODE-aware version of as.numeric should ignore.
>
> But UNICODE supports a much wider vision of numeric so that there are numeric-equivalent symbols in other languages and groupings and even something like the symbols for numerals in light or dark circles count as numbers. Those can likely safely be excluded in this context but perhaps not in a more general function.
>
> But I note as.numeric seems to handle scientific notation as in:
>
> as.numeric("1.23e8")
> [1] 1.23e+08
>
> So a single instance of the letters "e" and "E" must be supported if your numbers in string form may contain them. Further, the E cannot be the first or last letter. It cannot have adjacent whitespace. Still, if you are OK with getting an NA in such situations, it should be OK.
>
> It gets worse. Hexadecimal is supported:
>
> > as.numeric("0X12")
> [1] 18
>
> You now need to support the letters x and X. But only if preceded by a zero!
>
> It gets still worse as any characters from [0-9A-F] are supported:
>
> > as.numeric("0xAE")
> [1] 174
>
> There may be other scenarios it handles. The filter applied might remove valid numbers so you may want to carefully document it if your program only handles a restricted set.
>
> A possible idea might be to make two passes and only  evaluate any resulting NA from as.numeric() by doing a substitution like Ivan suggests to try to fix any broken ones. But note it may fix too much as "1.2 e 5" might become "1.2e5" as spaces are removed.
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ivan Krylov via R-help
> Sent: Monday, March 3, 2025 3:09 AM
> To: Christofer Bogaso <bogaso.christofer at gmail.com>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] Failed to convert data to numeric
>
> ? Mon, 3 Mar 2025 13:21:31 +0530
> Christofer Bogaso <bogaso.christofer at gmail.com> ?????:
>
> > Is there any way to remove all possible "Unicode character" that may
> > be present in the array at once?
>
> Define a range of characters you consider acceptable, and you'll be
> able to use regular expressions to remove everything else. For example,
> the following expression should remove everything except ASCII digits,
> dots, and hyphen-minus:
>
> gsub('[^0-9.-]+', '', dat2)
>
> There is a brief introduction to regular expressions in ?regex and
> various online resources such as <https://regex101.com/>.
>
> --
> Best regards,
> Ivan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Mon Mar  3 23:42:30 2025
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 4 Mar 2025 11:42:30 +1300
Subject: [R] Failed to convert data to numeric
In-Reply-To: <20250304104514.691929c1@new-hp>
References: <CA+dpOJmdNDT6Y2n5UDZgUj8c1E77TupPfT5MhgbRNZW5XSgjFg@mail.gmail.com>
 <20250303094837.32820c87@Tarkus>
 <CA+dpOJnHQOj+rbOJXhSNxHGerqNCaiAfARtkvo_=87jiD93OTw@mail.gmail.com>
 <20250303110922.1e9ecb49@Tarkus> <007801db8c60$5c6df260$1549d720$@gmail.com>
 <20250304104514.691929c1@new-hp>
Message-ID: <CABcYAd+stZ5zbXV_svwGNVn8hddyPRU1aU41C70czL7cA3NsXw@mail.gmail.com>

This is not for the R inferno.
This is for the Microsoft interno, or perhaps the Unicode inferno.
The Byte Order Mark is supposed to appear at the beginning of UTF-32
or UTF-16 *external* data, like a file
or data coming over a socket.
In the Microsoft world, it also tends to appear at the beginning of
UTF-8 files, where strictly speaking, it shouldn't.
ONLY at the beginning does ZWNBSP have this function.

I use a lot of programming languages, and I don't know any that
routinely ignores ZWNBSP.


Hmm.  I wonder if the strings in this example are fields of a data
file but were originally in a different
order, with the last string first?

What *would* make sense would be an option, when opening a connection,
to skip a leading BOM.


On Tue, 4 Mar 2025 at 10:45, Rolf Turner <rolfturner at posteo.net> wrote:
>
>
> This issue looks like grist for the R Inferno.
>
> cheers,
>
> Rolf
>
>
> On Mon, 3 Mar 2025 12:19:02 -0500
> <avi.e.gross at gmail.com> wrote:
>
> > The second solution Ivan offers looks good, and a bit more general
> > than his first that simply removes one non-visible character.
> >
> > It begs the question of why the data has that anomaly at all. Did the
> > data come from a text-processing environment where it was going to
> > wrap there and was protected?
> >
> > As Ivan points out, there is a question of what format you expect
> > numbers in and what "as.numeric"  should do when it does not see an
> > integer or floating point number.
> >
> > If you test it, you can see that as.numeric ignores leading and/or
> > trailing blanks and tabs and even newlines sometimes and some other
> > irrelevant ASCII characters. In that spirit, the UNICODE character
> > being mentioned should be one that any UNICODE-aware version of
> > as.numeric should ignore.
> >
> > But UNICODE supports a much wider vision of numeric so that there are
> > numeric-equivalent symbols in other languages and groupings and even
> > something like the symbols for numerals in light or dark circles
> > count as numbers. Those can likely safely be excluded in this context
> > but perhaps not in a more general function.
> >
> > But I note as.numeric seems to handle scientific notation as in:
> >
> > as.numeric("1.23e8")
> > [1] 1.23e+08
> >
> > So a single instance of the letters "e" and "E" must be supported if
> > your numbers in string form may contain them. Further, the E cannot
> > be the first or last letter. It cannot have adjacent whitespace.
> > Still, if you are OK with getting an NA in such situations, it should
> > be OK.
> >
> > It gets worse. Hexadecimal is supported:
> >
> > > as.numeric("0X12")
> > [1] 18
> >
> > You now need to support the letters x and X. But only if preceded by
> > a zero!
> >
> > It gets still worse as any characters from [0-9A-F] are supported:
> >
> > > as.numeric("0xAE")
> > [1] 174
> >
> > There may be other scenarios it handles. The filter applied might
> > remove valid numbers so you may want to carefully document it if your
> > program only handles a restricted set.
> >
> > A possible idea might be to make two passes and only  evaluate any
> > resulting NA from as.numeric() by doing a substitution like Ivan
> > suggests to try to fix any broken ones. But note it may fix too much
> > as "1.2 e 5" might become "1.2e5" as spaces are removed.
> >
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Ivan Krylov
> > via R-help Sent: Monday, March 3, 2025 3:09 AM
> > To: Christofer Bogaso <bogaso.christofer at gmail.com>
> > Cc: r-help <r-help at r-project.org>
> > Subject: Re: [R] Failed to convert data to numeric
> >
> > ? Mon, 3 Mar 2025 13:21:31 +0530
> > Christofer Bogaso <bogaso.christofer at gmail.com> ?????:
> >
> > > Is there any way to remove all possible "Unicode character" that may
> > > be present in the array at once?
> >
> > Define a range of characters you consider acceptable, and you'll be
> > able to use regular expressions to remove everything else. For
> > example, the following expression should remove everything except
> > ASCII digits, dots, and hyphen-minus:
> >
> > gsub('[^0-9.-]+', '', dat2)
> >
> > There is a brief introduction to regular expressions in ?regex and
> > various online resources such as <https://regex101.com/>.
> >
>
>
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Stats. Dep't. (secretaries) phone:
>          +64-9-373-7599 ext. 89622
> Home phone: +64-9-480-4619
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @vi@e@gross m@iii@g oii gm@ii@com  Mon Mar  3 23:51:21 2025
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Mon, 3 Mar 2025 17:51:21 -0500
Subject: [R] Failed to convert data to numeric
In-Reply-To: <CABcYAdKTKJaRcN9u-uU0FPPC79WJ48VkjmLszjjjA01TWqQoPA@mail.gmail.com>
References: <CA+dpOJmdNDT6Y2n5UDZgUj8c1E77TupPfT5MhgbRNZW5XSgjFg@mail.gmail.com>
 <20250303094837.32820c87@Tarkus>
 <CA+dpOJnHQOj+rbOJXhSNxHGerqNCaiAfARtkvo_=87jiD93OTw@mail.gmail.com>
 <20250303110922.1e9ecb49@Tarkus> <007801db8c60$5c6df260$1549d720$@gmail.com>
 <CABcYAdKTKJaRcN9u-uU0FPPC79WJ48VkjmLszjjjA01TWqQoPA@mail.gmail.com>
Message-ID: <00aa01db8c8e$c9058b30$5b10a190$@gmail.com>

I like your examples, Richard, of strings that should not be considered as numbers. There are times you want to recognize something like "221B Baker Street" and extract the 221 or perhaps the 221B as a part of a full address and ignore the rest. But one goal of a function like as.numeric() is to handle fully-formed numbers ready to be converted to another storage format. 

People with special uses and needs generally need to roll their own. A Bank may want to be able to handle this:

as.currency("five hundred twenty eight dollars and thirty two cents")

And someone else may want to handle Roman numerals, or calculate the value of text in a form of numerology like:
gematria("???") generates 18.

But what you describe with ?soft is quite inconsiderate and I wonder if it should be automatically handled by an enhanced version of the as.numeric family. There is indeed a general problem with different character sets and how to know what you have. But breaking lots of software this way is not ...

-----Original Message-----
From: Richard O'Keefe <raoknz at gmail.com> 
Sent: Monday, March 3, 2025 5:34 PM
To: avi.e.gross at gmail.com
Cc: Ivan Krylov <ikrylov at disroot.org>; Christofer Bogaso <bogaso.christofer at gmail.com>; r-help <r-help at r-project.org>
Subject: Re: [R] Failed to convert data to numeric

The zero-width no-break space character is used as the Byte Order
Mark.  That is, an official function for it at the beginning of a
character sequence
is to indicate whether you have 2-byte or 4-byte big-endian or
little-endian encoding.  It was not intended for use in UTF-8, where
there is nothing for
it to tell you, but Microsoft jumped in with all six feet and said
"hey, we'll use this to indicate that it's Unicode in UTF-8 and not
one of the hundreds
of other 8-bit coded character sets."  I've lost count of the number
of programs that have choked because they were given a BOM where they
didn't expect one.

So there is no great mystery about why there is a BOM at the beginning
of this particular string.
The real mystery is why it was there and NOT at the beginning of all the others.

I suggest that it is a good idea to remove the BOM character from the
beginning of microsofted strings,
but a bad idea to remove any other character.  If you are given bad
data like "Bond-007" when you
expect a number, you want to know about it, and not mistake it for
-007.  Still less do you want a
phone number like "+61 3 555 1234 x77" to be mistaken for a plain
number "613555123477".

On Tue, 4 Mar 2025 at 06:24, <avi.e.gross at gmail.com> wrote:
>
> The second solution Ivan offers looks good, and a bit more general than his first that simply removes one non-visible character.
>
> It begs the question of why the data has that anomaly at all. Did the data come from a text-processing environment where it was going to wrap there and was protected?
>
> As Ivan points out, there is a question of what format you expect numbers in and what "as.numeric"  should do when it does not see an integer or floating point number.
>
> If you test it, you can see that as.numeric ignores leading and/or trailing blanks and tabs and even newlines sometimes and some other irrelevant ASCII characters. In that spirit, the UNICODE character being mentioned should be one that any UNICODE-aware version of as.numeric should ignore.
>
> But UNICODE supports a much wider vision of numeric so that there are numeric-equivalent symbols in other languages and groupings and even something like the symbols for numerals in light or dark circles count as numbers. Those can likely safely be excluded in this context but perhaps not in a more general function.
>
> But I note as.numeric seems to handle scientific notation as in:
>
> as.numeric("1.23e8")
> [1] 1.23e+08
>
> So a single instance of the letters "e" and "E" must be supported if your numbers in string form may contain them. Further, the E cannot be the first or last letter. It cannot have adjacent whitespace. Still, if you are OK with getting an NA in such situations, it should be OK.
>
> It gets worse. Hexadecimal is supported:
>
> > as.numeric("0X12")
> [1] 18
>
> You now need to support the letters x and X. But only if preceded by a zero!
>
> It gets still worse as any characters from [0-9A-F] are supported:
>
> > as.numeric("0xAE")
> [1] 174
>
> There may be other scenarios it handles. The filter applied might remove valid numbers so you may want to carefully document it if your program only handles a restricted set.
>
> A possible idea might be to make two passes and only  evaluate any resulting NA from as.numeric() by doing a substitution like Ivan suggests to try to fix any broken ones. But note it may fix too much as "1.2 e 5" might become "1.2e5" as spaces are removed.
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ivan Krylov via R-help
> Sent: Monday, March 3, 2025 3:09 AM
> To: Christofer Bogaso <bogaso.christofer at gmail.com>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] Failed to convert data to numeric
>
> ? Mon, 3 Mar 2025 13:21:31 +0530
> Christofer Bogaso <bogaso.christofer at gmail.com> ?????:
>
> > Is there any way to remove all possible "Unicode character" that may
> > be present in the array at once?
>
> Define a range of characters you consider acceptable, and you'll be
> able to use regular expressions to remove everything else. For example,
> the following expression should remove everything except ASCII digits,
> dots, and hyphen-minus:
>
> gsub('[^0-9.-]+', '', dat2)
>
> There is a brief introduction to regular expressions in ?regex and
> various online resources such as <https://regex101.com/>.
>
> --
> Best regards,
> Ivan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pro|jcn@@h @end|ng |rom gm@||@com  Fri Mar  7 16:45:59 2025
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Fri, 7 Mar 2025 10:45:59 -0500
Subject: [R] Issue with littler vs. R and source()
Message-ID: <b2f132fd-5fd0-4ec0-86fe-cb2548c365bc@gmail.com>

I want to use littler (i.e. "r -i ") to run an R script so I can
set up a clickable icon for a program which uses package staplr.
Actually to use staplr to consolidate two files and remove some unwanted
pages before printout.

A minimal example program is FailBill.R, which has the single line

   library("staplr")

staplr is installed, as is rJava. System is Linux Mint 22.1 Xia,
and I had to install default-jre and default-jdk to get rJava
installed. Same error came up in a virtual Linux Mint 22 Wilma,
as I thought recent upgrade to Mint might be the problem.

Starting R and then doing
  source("FailBill.R")
works fine.

But in a terminal

   r -i FailBill.R

gives

   Error: package or namespace load failed for ?staplr?:
   .onLoad failed in loadNamespace() for 'staplr', details:
     call: NULL
     error: .onLoad failed in loadNamespace() for 'rJava', details:
     call: dyn.load(file, DLLpath = DLLpath, ...)
     error: unable to load shared object '/home/john/R/x86_64-pc-linux-gnu-library/4.4/rJava/libs/rJava.so':
     libjvm.so: cannot open shared object file: No such file or directory

Almost certainly some setting/pointer is incorrect, but I've yet to find it, and see a
lot of posts about rJava, offering plenty of confusion.

Suggestions welcome. Note that the program is interactive, and RScript or similar
charge ahead and ignore the interactive dialogs that use package svDialogs in the
program I'm trying to develop. Since I can run in R or RStudio by starting them and
then source()ing, the situation is not critical, but it would be good to work out
what is failing.

John Nash


From m@rbert@ @end|ng |rom protonm@||@com  Sat Mar  8 05:02:10 2025
From: m@rbert@ @end|ng |rom protonm@||@com (Steve Martin)
Date: Sat, 08 Mar 2025 04:02:10 +0000
Subject: [R] Issue with littler vs. R and source()
In-Reply-To: <b2f132fd-5fd0-4ec0-86fe-cb2548c365bc@gmail.com>
References: <b2f132fd-5fd0-4ec0-86fe-cb2548c365bc@gmail.com>
Message-ID: <2Qw7UFaTb91XKTPAMQeIx1SUe3zV0KU31oz4HeoAnaWk688GFjon_jOAMETQcF2W4hBJw170oSp8nXKA2gHpfcDJypPlj8GYwpkDBseB84s=@protonmail.com>

Hi John,

Does it work if you run R CMD r -i FailBill.R?

Steve


-------- Original Message --------
On 3/7/25 10:45, J C Nash <profjcnash at gmail.com> wrote:

>  I want to use littler (i.e. "r -i ") to run an R script so I can
>  set up a clickable icon for a program which uses package staplr.
>  Actually to use staplr to consolidate two files and remove some unwanted
>  pages before printout.
>  
>  A minimal example program is FailBill.R, which has the single line
>  
>     library("staplr")
>  
>  staplr is installed, as is rJava. System is Linux Mint 22.1 Xia,
>  and I had to install default-jre and default-jdk to get rJava
>  installed. Same error came up in a virtual Linux Mint 22 Wilma,
>  as I thought recent upgrade to Mint might be the problem.
>  
>  Starting R and then doing
>    source("FailBill.R")
>  works fine.
>  
>  But in a terminal
>  
>     r -i FailBill.R
>  
>  gives
>  
>     Error: package or namespace load failed for ?staplr?:
>     .onLoad failed in loadNamespace() for 'staplr', details:
>       call: NULL
>       error: .onLoad failed in loadNamespace() for 'rJava', details:
>       call: dyn.load(file, DLLpath = DLLpath, ...)
>       error: unable to load shared object '/home/john/R/x86_64-pc-linux-gnu-library/4.4/rJava/libs/rJava.so':
>       libjvm.so: cannot open shared object file: No such file or directory
>  
>  Almost certainly some setting/pointer is incorrect, but I've yet to find it, and see a
>  lot of posts about rJava, offering plenty of confusion.
>  
>  Suggestions welcome. Note that the program is interactive, and RScript or similar
>  charge ahead and ignore the interactive dialogs that use package svDialogs in the
>  program I'm trying to develop. Since I can run in R or RStudio by starting them and
>  then source()ing, the situation is not critical, but it would be good to work out
>  what is failing.
>  
>  John Nash
>  
>  ______________________________________________
>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://stat.ethz.ch/mailman/listinfo/r-help
>  PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>  and provide commented, minimal, self-contained, reproducible code.
>


From pd@|gd @end|ng |rom gm@||@com  Sat Mar  8 11:15:10 2025
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sat, 8 Mar 2025 11:15:10 +0100
Subject: [R] Issue with littler vs. R and source()
In-Reply-To: <b2f132fd-5fd0-4ec0-86fe-cb2548c365bc@gmail.com>
References: <b2f132fd-5fd0-4ec0-86fe-cb2548c365bc@gmail.com>
Message-ID: <BB1EB94A-28F0-4085-89DB-6CAEA912F499@gmail.com>

Does Rscript work for you? Seems happy enough here:

Peters-MacBook-Air:~ pd$ Rscript -e 'library(stapler)'
Peters-MacBook-Air:~ pd$ cat > tmp/FailBill.R
library(stapler)
Peters-MacBook-Air:~ pd$ Rscript tmp/FailBill.R 

-pd

> On 7 Mar 2025, at 16.45, J C Nash <profjcnash at gmail.com> wrote:
> 
> I want to use littler (i.e. "r -i ") to run an R script so I can
> set up a clickable icon for a program which uses package staplr.
> Actually to use staplr to consolidate two files and remove some unwanted
> pages before printout.
> 
> A minimal example program is FailBill.R, which has the single line
> 
>  library("staplr")
> 
> staplr is installed, as is rJava. System is Linux Mint 22.1 Xia,
> and I had to install default-jre and default-jdk to get rJava
> installed. Same error came up in a virtual Linux Mint 22 Wilma,
> as I thought recent upgrade to Mint might be the problem.
> 
> Starting R and then doing
> source("FailBill.R")
> works fine.
> 
> But in a terminal
> 
>  r -i FailBill.R
> 
> gives
> 
>  Error: package or namespace load failed for ?staplr?:
>  .onLoad failed in loadNamespace() for 'staplr', details:
>    call: NULL
>    error: .onLoad failed in loadNamespace() for 'rJava', details:
>    call: dyn.load(file, DLLpath = DLLpath, ...)
>    error: unable to load shared object '/home/john/R/x86_64-pc-linux-gnu-library/4.4/rJava/libs/rJava.so':
>    libjvm.so: cannot open shared object file: No such file or directory
> 
> Almost certainly some setting/pointer is incorrect, but I've yet to find it, and see a
> lot of posts about rJava, offering plenty of confusion.
> 
> Suggestions welcome. Note that the program is interactive, and RScript or similar
> charge ahead and ignore the interactive dialogs that use package svDialogs in the
> program I'm trying to develop. Since I can run in R or RStudio by starting them and
> then source()ing, the situation is not critical, but it would be good to work out
> what is failing.
> 
> John Nash
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pro|jcn@@h @end|ng |rom gm@||@com  Sat Mar  8 13:24:07 2025
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Sat, 8 Mar 2025 07:24:07 -0500
Subject: [R] Issue with littler vs. R and source()
In-Reply-To: <2Qw7UFaTb91XKTPAMQeIx1SUe3zV0KU31oz4HeoAnaWk688GFjon_jOAMETQcF2W4hBJw170oSp8nXKA2gHpfcDJypPlj8GYwpkDBseB84s=@protonmail.com>
References: <b2f132fd-5fd0-4ec0-86fe-cb2548c365bc@gmail.com>
 <2Qw7UFaTb91XKTPAMQeIx1SUe3zV0KU31oz4HeoAnaWk688GFjon_jOAMETQcF2W4hBJw170oSp8nXKA2gHpfcDJypPlj8GYwpkDBseB84s=@protonmail.com>
Message-ID: <d5be48a2-daea-4a0e-b410-f2cea5121c43@gmail.com>

Thanks for responses.

R CMD r -i ./FailBill.R

And, better, the approach seems to allow the full program to run the
dialogs (from svDialogs package) I need for interaction. I'll have to
see how well I can make that work in a clickable icon.

Rscript ./FailBill.R

does avoid the "error" in not finding the java VM. However, and
unfortunately for me, Rscript on the full program ignores the dialogs, but
keeps going taking whatever is first option in the dialog call. I've not
sorted out why that is, but believe it is why littler was set up. Despite
quite a lot of R programming, I've not much experience in interactive programs
that go beyond simple 'readline' statements.

In any event, Steve's suggestion has got me moving forward. I suspect there'll
be other glitches to work around, especially as my intent was to obtain a
program that was cross platform. I had been using YAD in Linux, which is nice,
but leaves out Windows and Mac users.

Thanks again.

JN

On 2025-03-07 23:02, Steve Martin wrote:
> Hi John,
> 
> Does it work if you run R CMD r -i FailBill.R?
> 
> Steve
> 
> 
> -------- Original Message --------
> On 3/7/25 10:45, J C Nash <profjcnash at gmail.com> wrote:
> 
>>   I want to use littler (i.e. "r -i ") to run an R script so I can
>>   set up a clickable icon for a program which uses package staplr.
>>   Actually to use staplr to consolidate two files and remove some unwanted
>>   pages before printout.
>>   
>>   A minimal example program is FailBill.R, which has the single line
>>   
>>      library("staplr")
>>   
>>   staplr is installed, as is rJava. System is Linux Mint 22.1 Xia,
>>   and I had to install default-jre and default-jdk to get rJava
>>   installed. Same error came up in a virtual Linux Mint 22 Wilma,
>>   as I thought recent upgrade to Mint might be the problem.
>>   
>>   Starting R and then doing
>>     source("FailBill.R")
>>   works fine.
>>   
>>   But in a terminal
>>   
>>      r -i FailBill.R
>>   
>>   gives
>>   
>>      Error: package or namespace load failed for ?staplr?:
>>      .onLoad failed in loadNamespace() for 'staplr', details:
>>        call: NULL
>>        error: .onLoad failed in loadNamespace() for 'rJava', details:
>>        call: dyn.load(file, DLLpath = DLLpath, ...)
>>        error: unable to load shared object '/home/john/R/x86_64-pc-linux-gnu-library/4.4/rJava/libs/rJava.so':
>>        libjvm.so: cannot open shared object file: No such file or directory
>>   
>>   Almost certainly some setting/pointer is incorrect, but I've yet to find it, and see a
>>   lot of posts about rJava, offering plenty of confusion.
>>   
>>   Suggestions welcome. Note that the program is interactive, and RScript or similar
>>   charge ahead and ignore the interactive dialogs that use package svDialogs in the
>>   program I'm trying to develop. Since I can run in R or RStudio by starting them and
>>   then source()ing, the situation is not critical, but it would be good to work out
>>   what is failing.
>>   
>>   John Nash
>>   
>>   ______________________________________________
>>   R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>   https://stat.ethz.ch/mailman/listinfo/r-help
>>   PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>>   and provide commented, minimal, self-contained, reproducible code.
>>


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sun Mar  9 18:12:47 2025
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Sun, 9 Mar 2025 22:42:47 +0530
Subject: [R] Number changed weirdly when converting to numeric
Message-ID: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>

Hi,

I have below simple conversion

> sprintf("%0.15f", as.numeric("-177253333.333333343267441"))

[1] "-177253333.333333373069763"

I could not figure out why the input and output is different?

Clearly this conversion is incorrect. Is there any way to convert to
numerical properly?

> sessionInfo()

R version 4.4.0 (2024-04-24)

Platform: aarch64-apple-darwin20

Running under: macOS 15.3.1


Matrix products: default

BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib

LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;
 LAPACK version 3.12.0


locale:

[1] C/UTF-8/C/C/C/C


time zone: Asia

tzcode source: internal


attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base


loaded via a namespace (and not attached):

[1] compiler_4.4.0


From bbo|ker @end|ng |rom gm@||@com  Sun Mar  9 18:44:48 2025
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 9 Mar 2025 13:44:48 -0400
Subject: [R] Number changed weirdly when converting to numeric
In-Reply-To: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
References: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
Message-ID: <0f1a538b-135d-434c-81bd-15fde9338575@gmail.com>

   I can't reproduce this locally.


sprintf("%0.15f", as.numeric("-177253333.333333343267441"))
[1] "-177253333.333333343267441"

R Under development (unstable) (2025-03-08 r87909)
Platform: x86_64-pc-linux-gnu
Running under: Ubuntu 24.04.2 LTS


On 3/9/25 13:12, Christofer Bogaso wrote:
> Hi,
> 
> I have below simple conversion
> 
>> sprintf("%0.15f", as.numeric("-177253333.333333343267441"))
> 
> [1] "-177253333.333333373069763"
> 
> I could not figure out why the input and output is different?
> 
> Clearly this conversion is incorrect. Is there any way to convert to
> numerical properly?
> 
>> sessionInfo()
> 
> R version 4.4.0 (2024-04-24)
> 
> Platform: aarch64-apple-darwin20
> 
> Running under: macOS 15.3.1
> 
> 
> Matrix products: default
> 
> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib
> 
> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;
>   LAPACK version 3.12.0
> 
> 
> locale:
> 
> [1] C/UTF-8/C/C/C/C
> 
> 
> time zone: Asia
> 
> tzcode source: internal
> 
> 
> attached base packages:
> 
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 
> loaded via a namespace (and not attached):
> 
> [1] compiler_4.4.0
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Mar  9 18:46:25 2025
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 09 Mar 2025 10:46:25 -0700
Subject: [R] Number changed weirdly when converting to numeric
In-Reply-To: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
References: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
Message-ID: <4908AE38-EA36-41F1-B899-FBA17569E2B5@dcn.davis.ca.us>

https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

https://0.30000000000000004.com/

On March 9, 2025 10:12:47 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>Hi,
>
>I have below simple conversion
>
>> sprintf("%0.15f", as.numeric("-177253333.333333343267441"))
>
>[1] "-177253333.333333373069763"
>
>I could not figure out why the input and output is different?
>
>Clearly this conversion is incorrect. Is there any way to convert to
>numerical properly?
>
>> sessionInfo()
>
>R version 4.4.0 (2024-04-24)
>
>Platform: aarch64-apple-darwin20
>
>Running under: macOS 15.3.1
>
>
>Matrix products: default
>
>BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib
>
>LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;
> LAPACK version 3.12.0
>
>
>locale:
>
>[1] C/UTF-8/C/C/C/C
>
>
>time zone: Asia
>
>tzcode source: internal
>
>
>attached base packages:
>
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>loaded via a namespace (and not attached):
>
>[1] compiler_4.4.0
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @te|@nML @end|ng |rom co||oc@t|on@@de  Sun Mar  9 19:06:17 2025
From: @te|@nML @end|ng |rom co||oc@t|on@@de (Stephanie Evert)
Date: Sun, 9 Mar 2025 19:06:17 +0100
Subject: [R] Number changed weirdly when converting to numeric
In-Reply-To: <4908AE38-EA36-41F1-B899-FBA17569E2B5@dcn.davis.ca.us>
References: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
 <4908AE38-EA36-41F1-B899-FBA17569E2B5@dcn.davis.ca.us>
Message-ID: <A16FBCC8-9FFD-41EE-ACE7-B6DE9B62B988@collocations.de>

For once, that doesn't seem to be the issue here. The bug only seems to happen on arm64 and doesn't reproduce on x86_64 hardware.

> x <- as.numeric("-177253333.333333343267441")
> sprintf("%.15f", x)
[1] "-177253333.333333373069763"

This is the number adjacent to -177253333.333333343267441 in IEEE 754.

> writeBin(x, raw(8))
[1] ac aa aa aa 57 21 a5 c1

If you look at the hexadecimal representation, the least significant bit appears to be off by one: the first byte should be 0xAB rather than 0xAC (according to online calculators such as https://numeral-systems.com/ieee-754-converter/).

Seems that decimal-to-float conversion has a bug on arm64. Note that I get the same result with 

> x <- -177253333.333333343267441

so it's not specific to as.numeric().

Best,
Stephanie




> On 9 Mar 2025, at 18:46, Jeff Newmiller via R-help <r-help at r-project.org> wrote:
> 
> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
> 
> https://0.30000000000000004.com/
> 
> On March 9, 2025 10:12:47 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>> Hi,
>> 
>> I have below simple conversion
>> 
>>> sprintf("%0.15f", as.numeric("-177253333.333333343267441"))
>> 
>> [1] "-177253333.333333373069763"
>> 
>> I could not figure out why the input and output is different?
>> 
>> Clearly this conversion is incorrect. Is there any way to convert to
>> numerical properly?
>> 
>>> sessionInfo()
>> 
>> R version 4.4.0 (2024-04-24)
>> 
>> Platform: aarch64-apple-darwin20
>> 
>> Running under: macOS 15.3.1
>> 
>> 
>> Matrix products: default
>> 
>> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib
>> 
>> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;
>> LAPACK version 3.12.0
>> 
>> 
>> locale:
>> 
>> [1] C/UTF-8/C/C/C/C
>> 
>> 
>> time zone: Asia
>> 
>> tzcode source: internal
>> 
>> 
>> attached base packages:
>> 
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> 
>> loaded via a namespace (and not attached):
>> 
>> [1] compiler_4.4.0
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Sun Mar  9 19:19:00 2025
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Sun, 9 Mar 2025 14:19:00 -0400
Subject: [R] Number changed weirdly when converting to numeric
In-Reply-To: <A16FBCC8-9FFD-41EE-ACE7-B6DE9B62B988@collocations.de>
References: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
 <4908AE38-EA36-41F1-B899-FBA17569E2B5@dcn.davis.ca.us>
 <A16FBCC8-9FFD-41EE-ACE7-B6DE9B62B988@collocations.de>
Message-ID: <d15df42b-ccff-4d9f-a650-1c5920cff105@gmail.com>

This may be way off the mark, but is it possible that the ARM machine is using
the "new" IEEE-754 arithmetic that does not have 80 bit extended? The standard
was changed (in ways to allow non-compliant systems to be compliant) because
ARM does not have the hardware registers. There are reasons why this might be
sensible, but we need more awareness of the consequences to avoid some of the
resulting changes in results. I've had to "fix" things that weren't broken because
M1 and later Macs gave different outputs, actually not in my code but in vignettes
where I compared to other packages.

Cheers,

John Nash
(who actually was part of 1985 IEEE 754 committee, though a VERY minor player)

On 2025-03-09 14:06, Stephanie Evert wrote:
> For once, that doesn't seem to be the issue here. The bug only seems to happen on arm64 and doesn't reproduce on x86_64 hardware.
> 
>> x <- as.numeric("-177253333.333333343267441")
>> sprintf("%.15f", x)
> [1] "-177253333.333333373069763"
> 
> This is the number adjacent to -177253333.333333343267441 in IEEE 754.
> 
>> writeBin(x, raw(8))
> [1] ac aa aa aa 57 21 a5 c1
> 
> If you look at the hexadecimal representation, the least significant bit appears to be off by one: the first byte should be 0xAB rather than 0xAC (according to online calculators such as https://numeral-systems.com/ieee-754-converter/).
> 
> Seems that decimal-to-float conversion has a bug on arm64. Note that I get the same result with
> 
>> x <- -177253333.333333343267441
> 
> so it's not specific to as.numeric().
> 
> Best,
> Stephanie
> 
> 
> 
> 
>> On 9 Mar 2025, at 18:46, Jeff Newmiller via R-help <r-help at r-project.org> wrote:
>>
>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
>>
>> https://0.30000000000000004.com/
>>
>> On March 9, 2025 10:12:47 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>> Hi,
>>>
>>> I have below simple conversion
>>>
>>>> sprintf("%0.15f", as.numeric("-177253333.333333343267441"))
>>>
>>> [1] "-177253333.333333373069763"
>>>
>>> I could not figure out why the input and output is different?
>>>
>>> Clearly this conversion is incorrect. Is there any way to convert to
>>> numerical properly?
>>>
>>>> sessionInfo()
>>>
>>> R version 4.4.0 (2024-04-24)
>>>
>>> Platform: aarch64-apple-darwin20
>>>
>>> Running under: macOS 15.3.1
>>>
>>>
>>> Matrix products: default
>>>
>>> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib
>>>
>>> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;
>>> LAPACK version 3.12.0
>>>
>>>
>>> locale:
>>>
>>> [1] C/UTF-8/C/C/C/C
>>>
>>>
>>> time zone: Asia
>>>
>>> tzcode source: internal
>>>
>>>
>>> attached base packages:
>>>
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>>
>>> loaded via a namespace (and not attached):
>>>
>>> [1] compiler_4.4.0
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> -- 
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbo|ker @end|ng |rom gm@||@com  Sun Mar  9 19:24:33 2025
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 9 Mar 2025 14:24:33 -0400
Subject: [R] Number changed weirdly when converting to numeric
In-Reply-To: <A16FBCC8-9FFD-41EE-ACE7-B6DE9B62B988@collocations.de>
References: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
 <4908AE38-EA36-41F1-B899-FBA17569E2B5@dcn.davis.ca.us>
 <A16FBCC8-9FFD-41EE-ACE7-B6DE9B62B988@collocations.de>
Message-ID: <d565b28e-a601-49d4-be24-1aba2e0646be@gmail.com>

    Out of curiosity, what does atof() do on that platform? What does 
the following C program do on arm64? (I don't know exactly what R does 
to coerce character to double, but this is what I would guess ...)

#include <stdio.h>
#include <stdlib.h>
int main(void) {
   const char *str = "-177253333.333333343267441";
   double x = atof(str);
   printf("%0.15f\n", x);
   return 0;
}

   To my surprise, apparently R doesn't use stdlib to convert.

 From 
https://github.com/r-devel/r-svn/blob/bb64b28d8cc2e2863eb664e7f83b0a7206b4b1d4/src/main/util.c#L2087C1-L2107:

/* ...

        use our own strtod/atof to mitigate effects of setting LC_NUMERIC

    Also allows complete control of which non-numeric strings are
    accepted; e.g. glibc allows NANxxxx, macOS NAN(s), this accepts "NA".

... */

   Should this be escalated to r-devel (or r-bugzilla)?  Nothing pops 
out at me from the recent NEWS ...

   Ben Bolker

On 3/9/25 14:06, Stephanie Evert wrote:
> For once, that doesn't seem to be the issue here. The bug only seems to happen on arm64 and doesn't reproduce on x86_64 hardware.
> 
>> x <- as.numeric("-177253333.333333343267441")
>> sprintf("%.15f", x)
> [1] "-177253333.333333373069763"
> 
> This is the number adjacent to -177253333.333333343267441 in IEEE 754.
> 
>> writeBin(x, raw(8))
> [1] ac aa aa aa 57 21 a5 c1
> 
> If you look at the hexadecimal representation, the least significant bit appears to be off by one: the first byte should be 0xAB rather than 0xAC (according to online calculators such as https://numeral-systems.com/ieee-754-converter/).
> 
> Seems that decimal-to-float conversion has a bug on arm64. Note that I get the same result with
> 
>> x <- -177253333.333333343267441
> 
> so it's not specific to as.numeric().
> 
> Best,
> Stephanie
> 
> 
> 
> 
>> On 9 Mar 2025, at 18:46, Jeff Newmiller via R-help <r-help at r-project.org> wrote:
>>
>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
>>
>> https://0.30000000000000004.com/
>>
>> On March 9, 2025 10:12:47 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>> Hi,
>>>
>>> I have below simple conversion
>>>
>>>> sprintf("%0.15f", as.numeric("-177253333.333333343267441"))
>>>
>>> [1] "-177253333.333333373069763"
>>>
>>> I could not figure out why the input and output is different?
>>>
>>> Clearly this conversion is incorrect. Is there any way to convert to
>>> numerical properly?
>>>
>>>> sessionInfo()
>>>
>>> R version 4.4.0 (2024-04-24)
>>>
>>> Platform: aarch64-apple-darwin20
>>>
>>> Running under: macOS 15.3.1
>>>
>>>
>>> Matrix products: default
>>>
>>> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib
>>>
>>> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;
>>> LAPACK version 3.12.0
>>>
>>>
>>> locale:
>>>
>>> [1] C/UTF-8/C/C/C/C
>>>
>>>
>>> time zone: Asia
>>>
>>> tzcode source: internal
>>>
>>>
>>> attached base packages:
>>>
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>>
>>> loaded via a namespace (and not attached):
>>>
>>> [1] compiler_4.4.0
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> -- 
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Mar  9 20:31:56 2025
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 09 Mar 2025 12:31:56 -0700
Subject: [R] Number changed weirdly when converting to numeric
In-Reply-To: <A16FBCC8-9FFD-41EE-ACE7-B6DE9B62B988@collocations.de>
References: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
 <4908AE38-EA36-41F1-B899-FBA17569E2B5@dcn.davis.ca.us>
 <A16FBCC8-9FFD-41EE-ACE7-B6DE9B62B988@collocations.de>
Message-ID: <F1E7054C-5ADC-40C8-8921-6CC6E04E97C3@dcn.davis.ca.us>

I now see more clearly what the complaint is.

That said, you should ALWAYS be prepared for the round trip between binary and string forms of floating point to accrue rounding error because floating point is intrinsically approximate. While there are examples of floating point numbers that can reliably do that round trip exactly (e.g. integers shorter than the mantissa), in general you should be prepared for such "inexact" results.

John Nash's point that IEEE754 has been relaxed is reinforcement that they want users to be prepared for differences around the least significant bits... but the principle is mathematically intrinsic to the scope of floating point numbers whether the standard says so or not.

On March 9, 2025 11:06:17 AM PDT, Stephanie Evert <stefanML at collocations.de> wrote:
>For once, that doesn't seem to be the issue here. The bug only seems to happen on arm64 and doesn't reproduce on x86_64 hardware.
>
>> x <- as.numeric("-177253333.333333343267441")
>> sprintf("%.15f", x)
>[1] "-177253333.333333373069763"
>
>This is the number adjacent to -177253333.333333343267441 in IEEE 754.
>
>> writeBin(x, raw(8))
>[1] ac aa aa aa 57 21 a5 c1
>
>If you look at the hexadecimal representation, the least significant bit appears to be off by one: the first byte should be 0xAB rather than 0xAC (according to online calculators such as https://numeral-systems.com/ieee-754-converter/).
>
>Seems that decimal-to-float conversion has a bug on arm64. Note that I get the same result with 
>
>> x <- -177253333.333333343267441
>
>so it's not specific to as.numeric().
>
>Best,
>Stephanie
>
>
>
>
>> On 9 Mar 2025, at 18:46, Jeff Newmiller via R-help <r-help at r-project.org> wrote:
>> 
>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
>> 
>> https://0.30000000000000004.com/
>> 
>> On March 9, 2025 10:12:47 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>> Hi,
>>> 
>>> I have below simple conversion
>>> 
>>>> sprintf("%0.15f", as.numeric("-177253333.333333343267441"))
>>> 
>>> [1] "-177253333.333333373069763"
>>> 
>>> I could not figure out why the input and output is different?
>>> 
>>> Clearly this conversion is incorrect. Is there any way to convert to
>>> numerical properly?
>>> 
>>>> sessionInfo()
>>> 
>>> R version 4.4.0 (2024-04-24)
>>> 
>>> Platform: aarch64-apple-darwin20
>>> 
>>> Running under: macOS 15.3.1
>>> 
>>> 
>>> Matrix products: default
>>> 
>>> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib
>>> 
>>> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;
>>> LAPACK version 3.12.0
>>> 
>>> 
>>> locale:
>>> 
>>> [1] C/UTF-8/C/C/C/C
>>> 
>>> 
>>> time zone: Asia
>>> 
>>> tzcode source: internal
>>> 
>>> 
>>> attached base packages:
>>> 
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> 
>>> loaded via a namespace (and not attached):
>>> 
>>> [1] compiler_4.4.0
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> -- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Sent from my phone. Please excuse my brevity.


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sun Mar  9 22:55:42 2025
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 10 Mar 2025 03:25:42 +0530
Subject: [R] Number changed weirdly when converting to numeric
In-Reply-To: <F1E7054C-5ADC-40C8-8921-6CC6E04E97C3@dcn.davis.ca.us>
References: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
 <4908AE38-EA36-41F1-B899-FBA17569E2B5@dcn.davis.ca.us>
 <A16FBCC8-9FFD-41EE-ACE7-B6DE9B62B988@collocations.de>
 <F1E7054C-5ADC-40C8-8921-6CC6E04E97C3@dcn.davis.ca.us>
Message-ID: <CA+dpOJmGGqYgAzrG0qye5_=fg7A0gR2dWTk2z3iiymz-xC9A2Q@mail.gmail.com>

So, based on the discussion points from the experts here, I understand
that this is an ARM specific problem.

However, what should I do for a solution?

I use ARM+R in my office workstation, so it may not be prudent to me
to just say ignore this problem and let Apple's Tim Cook take care of
it...

On Mon, Mar 10, 2025 at 1:01?AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> I now see more clearly what the complaint is.
>
> That said, you should ALWAYS be prepared for the round trip between binary and string forms of floating point to accrue rounding error because floating point is intrinsically approximate. While there are examples of floating point numbers that can reliably do that round trip exactly (e.g. integers shorter than the mantissa), in general you should be prepared for such "inexact" results.
>
> John Nash's point that IEEE754 has been relaxed is reinforcement that they want users to be prepared for differences around the least significant bits... but the principle is mathematically intrinsic to the scope of floating point numbers whether the standard says so or not.
>
> On March 9, 2025 11:06:17 AM PDT, Stephanie Evert <stefanML at collocations.de> wrote:
> >For once, that doesn't seem to be the issue here. The bug only seems to happen on arm64 and doesn't reproduce on x86_64 hardware.
> >
> >> x <- as.numeric("-177253333.333333343267441")
> >> sprintf("%.15f", x)
> >[1] "-177253333.333333373069763"
> >
> >This is the number adjacent to -177253333.333333343267441 in IEEE 754.
> >
> >> writeBin(x, raw(8))
> >[1] ac aa aa aa 57 21 a5 c1
> >
> >If you look at the hexadecimal representation, the least significant bit appears to be off by one: the first byte should be 0xAB rather than 0xAC (according to online calculators such as https://numeral-systems.com/ieee-754-converter/).
> >
> >Seems that decimal-to-float conversion has a bug on arm64. Note that I get the same result with
> >
> >> x <- -177253333.333333343267441
> >
> >so it's not specific to as.numeric().
> >
> >Best,
> >Stephanie
> >
> >
> >
> >
> >> On 9 Mar 2025, at 18:46, Jeff Newmiller via R-help <r-help at r-project.org> wrote:
> >>
> >> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
> >>
> >> https://0.30000000000000004.com/
> >>
> >> On March 9, 2025 10:12:47 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
> >>> Hi,
> >>>
> >>> I have below simple conversion
> >>>
> >>>> sprintf("%0.15f", as.numeric("-177253333.333333343267441"))
> >>>
> >>> [1] "-177253333.333333373069763"
> >>>
> >>> I could not figure out why the input and output is different?
> >>>
> >>> Clearly this conversion is incorrect. Is there any way to convert to
> >>> numerical properly?
> >>>
> >>>> sessionInfo()
> >>>
> >>> R version 4.4.0 (2024-04-24)
> >>>
> >>> Platform: aarch64-apple-darwin20
> >>>
> >>> Running under: macOS 15.3.1
> >>>
> >>>
> >>> Matrix products: default
> >>>
> >>> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib
> >>>
> >>> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;
> >>> LAPACK version 3.12.0
> >>>
> >>>
> >>> locale:
> >>>
> >>> [1] C/UTF-8/C/C/C/C
> >>>
> >>>
> >>> time zone: Asia
> >>>
> >>> tzcode source: internal
> >>>
> >>>
> >>> attached base packages:
> >>>
> >>> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>>
> >>>
> >>> loaded via a namespace (and not attached):
> >>>
> >>> [1] compiler_4.4.0
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Mar  9 23:31:25 2025
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 9 Mar 2025 18:31:25 -0400
Subject: [R] Number changed weirdly when converting to numeric
In-Reply-To: <CA+dpOJmGGqYgAzrG0qye5_=fg7A0gR2dWTk2z3iiymz-xC9A2Q@mail.gmail.com>
References: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
 <4908AE38-EA36-41F1-B899-FBA17569E2B5@dcn.davis.ca.us>
 <A16FBCC8-9FFD-41EE-ACE7-B6DE9B62B988@collocations.de>
 <F1E7054C-5ADC-40C8-8921-6CC6E04E97C3@dcn.davis.ca.us>
 <CA+dpOJmGGqYgAzrG0qye5_=fg7A0gR2dWTk2z3iiymz-xC9A2Q@mail.gmail.com>
Message-ID: <755f7612-6e0f-462f-aaf7-f13e272eaa28@gmail.com>

On 2025-03-09 5:55 p.m., Christofer Bogaso wrote:
> So, based on the discussion points from the experts here, I understand
> that this is an ARM specific problem.
> 
> However, what should I do for a solution?
> 
> I use ARM+R in my office workstation, so it may not be prudent to me
> to just say ignore this problem and let Apple's Tim Cook take care of
> it...

No, the problem is much deeper than that.  If your work depends on 
things that are way out in the limit of floating point precision, then 
your work is unavoidably unstable already.  The easiest way to fix this 
is to avoid doing anything that depends on the 15th or 16th or higher 
significant digit of what you are working with.

If you really need 20 or 30 digit precision, then you can do it in R, 
but you need to be extra careful with every single calculation you're 
doing.  Base R calculations won't be good enough.

Duncan Murdoch

> 
> On Mon, Mar 10, 2025 at 1:01?AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> I now see more clearly what the complaint is.
>>
>> That said, you should ALWAYS be prepared for the round trip between binary and string forms of floating point to accrue rounding error because floating point is intrinsically approximate. While there are examples of floating point numbers that can reliably do that round trip exactly (e.g. integers shorter than the mantissa), in general you should be prepared for such "inexact" results.
>>
>> John Nash's point that IEEE754 has been relaxed is reinforcement that they want users to be prepared for differences around the least significant bits... but the principle is mathematically intrinsic to the scope of floating point numbers whether the standard says so or not.
>>
>> On March 9, 2025 11:06:17 AM PDT, Stephanie Evert <stefanML at collocations.de> wrote:
>>> For once, that doesn't seem to be the issue here. The bug only seems to happen on arm64 and doesn't reproduce on x86_64 hardware.
>>>
>>>> x <- as.numeric("-177253333.333333343267441")
>>>> sprintf("%.15f", x)
>>> [1] "-177253333.333333373069763"
>>>
>>> This is the number adjacent to -177253333.333333343267441 in IEEE 754.
>>>
>>>> writeBin(x, raw(8))
>>> [1] ac aa aa aa 57 21 a5 c1
>>>
>>> If you look at the hexadecimal representation, the least significant bit appears to be off by one: the first byte should be 0xAB rather than 0xAC (according to online calculators such as https://numeral-systems.com/ieee-754-converter/).
>>>
>>> Seems that decimal-to-float conversion has a bug on arm64. Note that I get the same result with
>>>
>>>> x <- -177253333.333333343267441
>>>
>>> so it's not specific to as.numeric().
>>>
>>> Best,
>>> Stephanie
>>>
>>>
>>>
>>>
>>>> On 9 Mar 2025, at 18:46, Jeff Newmiller via R-help <r-help at r-project.org> wrote:
>>>>
>>>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
>>>>
>>>> https://0.30000000000000004.com/
>>>>
>>>> On March 9, 2025 10:12:47 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>>>> Hi,
>>>>>
>>>>> I have below simple conversion
>>>>>
>>>>>> sprintf("%0.15f", as.numeric("-177253333.333333343267441"))
>>>>>
>>>>> [1] "-177253333.333333373069763"
>>>>>
>>>>> I could not figure out why the input and output is different?
>>>>>
>>>>> Clearly this conversion is incorrect. Is there any way to convert to
>>>>> numerical properly?
>>>>>
>>>>>> sessionInfo()
>>>>>
>>>>> R version 4.4.0 (2024-04-24)
>>>>>
>>>>> Platform: aarch64-apple-darwin20
>>>>>
>>>>> Running under: macOS 15.3.1
>>>>>
>>>>>
>>>>> Matrix products: default
>>>>>
>>>>> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib
>>>>>
>>>>> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;
>>>>> LAPACK version 3.12.0
>>>>>
>>>>>
>>>>> locale:
>>>>>
>>>>> [1] C/UTF-8/C/C/C/C
>>>>>
>>>>>
>>>>> time zone: Asia
>>>>>
>>>>> tzcode source: internal
>>>>>
>>>>>
>>>>> attached base packages:
>>>>>
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>>
>>>>> [1] compiler_4.4.0
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> --
>> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Mar 10 00:15:52 2025
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 9 Mar 2025 16:15:52 -0700
Subject: [R] Number changed weirdly when converting to numeric
In-Reply-To: <755f7612-6e0f-462f-aaf7-f13e272eaa28@gmail.com>
References: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
 <4908AE38-EA36-41F1-B899-FBA17569E2B5@dcn.davis.ca.us>
 <A16FBCC8-9FFD-41EE-ACE7-B6DE9B62B988@collocations.de>
 <F1E7054C-5ADC-40C8-8921-6CC6E04E97C3@dcn.davis.ca.us>
 <CA+dpOJmGGqYgAzrG0qye5_=fg7A0gR2dWTk2z3iiymz-xC9A2Q@mail.gmail.com>
 <755f7612-6e0f-462f-aaf7-f13e272eaa28@gmail.com>
Message-ID: <CAGxFJbQSnVTEikcTTF9_1oVuEfoawr3UtyBwkDoQrYfiXttpxw@mail.gmail.com>

As has now been explained, there is a lot going on under the hood
here. I would just note that the Rmpfr package can do arbitrary
precision arithmetic; and so can the Ryacas package, which extends
these capabilities to e.g. arbitrary precision linear algebra.

(I am just parroting what I found via search and know nothing about
details or use cases.)

Cheers,
Bert

"An educated person is one who can entertain new ideas, entertain
others, and entertain herself."

"An educated person is one who can entertain new ideas, entertain
others, and entertain herself."



On Sun, Mar 9, 2025 at 3:31?PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 2025-03-09 5:55 p.m., Christofer Bogaso wrote:
> > So, based on the discussion points from the experts here, I understand
> > that this is an ARM specific problem.
> >
> > However, what should I do for a solution?
> >
> > I use ARM+R in my office workstation, so it may not be prudent to me
> > to just say ignore this problem and let Apple's Tim Cook take care of
> > it...
>
> No, the problem is much deeper than that.  If your work depends on
> things that are way out in the limit of floating point precision, then
> your work is unavoidably unstable already.  The easiest way to fix this
> is to avoid doing anything that depends on the 15th or 16th or higher
> significant digit of what you are working with.
>
> If you really need 20 or 30 digit precision, then you can do it in R,
> but you need to be extra careful with every single calculation you're
> doing.  Base R calculations won't be good enough.
>
> Duncan Murdoch
>
> >
> > On Mon, Mar 10, 2025 at 1:01?AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> >>
> >> I now see more clearly what the complaint is.
> >>
> >> That said, you should ALWAYS be prepared for the round trip between binary and string forms of floating point to accrue rounding error because floating point is intrinsically approximate. While there are examples of floating point numbers that can reliably do that round trip exactly (e.g. integers shorter than the mantissa), in general you should be prepared for such "inexact" results.
> >>
> >> John Nash's point that IEEE754 has been relaxed is reinforcement that they want users to be prepared for differences around the least significant bits... but the principle is mathematically intrinsic to the scope of floating point numbers whether the standard says so or not.
> >>
> >> On March 9, 2025 11:06:17 AM PDT, Stephanie Evert <stefanML at collocations.de> wrote:
> >>> For once, that doesn't seem to be the issue here. The bug only seems to happen on arm64 and doesn't reproduce on x86_64 hardware.
> >>>
> >>>> x <- as.numeric("-177253333.333333343267441")
> >>>> sprintf("%.15f", x)
> >>> [1] "-177253333.333333373069763"
> >>>
> >>> This is the number adjacent to -177253333.333333343267441 in IEEE 754.
> >>>
> >>>> writeBin(x, raw(8))
> >>> [1] ac aa aa aa 57 21 a5 c1
> >>>
> >>> If you look at the hexadecimal representation, the least significant bit appears to be off by one: the first byte should be 0xAB rather than 0xAC (according to online calculators such as https://numeral-systems.com/ieee-754-converter/).
> >>>
> >>> Seems that decimal-to-float conversion has a bug on arm64. Note that I get the same result with
> >>>
> >>>> x <- -177253333.333333343267441
> >>>
> >>> so it's not specific to as.numeric().
> >>>
> >>> Best,
> >>> Stephanie
> >>>
> >>>
> >>>
> >>>
> >>>> On 9 Mar 2025, at 18:46, Jeff Newmiller via R-help <r-help at r-project.org> wrote:
> >>>>
> >>>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
> >>>>
> >>>> https://0.30000000000000004.com/
> >>>>
> >>>> On March 9, 2025 10:12:47 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
> >>>>> Hi,
> >>>>>
> >>>>> I have below simple conversion
> >>>>>
> >>>>>> sprintf("%0.15f", as.numeric("-177253333.333333343267441"))
> >>>>>
> >>>>> [1] "-177253333.333333373069763"
> >>>>>
> >>>>> I could not figure out why the input and output is different?
> >>>>>
> >>>>> Clearly this conversion is incorrect. Is there any way to convert to
> >>>>> numerical properly?
> >>>>>
> >>>>>> sessionInfo()
> >>>>>
> >>>>> R version 4.4.0 (2024-04-24)
> >>>>>
> >>>>> Platform: aarch64-apple-darwin20
> >>>>>
> >>>>> Running under: macOS 15.3.1
> >>>>>
> >>>>>
> >>>>> Matrix products: default
> >>>>>
> >>>>> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib
> >>>>>
> >>>>> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;
> >>>>> LAPACK version 3.12.0
> >>>>>
> >>>>>
> >>>>> locale:
> >>>>>
> >>>>> [1] C/UTF-8/C/C/C/C
> >>>>>
> >>>>>
> >>>>> time zone: Asia
> >>>>>
> >>>>> tzcode source: internal
> >>>>>
> >>>>>
> >>>>> attached base packages:
> >>>>>
> >>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>>>>
> >>>>>
> >>>>> loaded via a namespace (and not attached):
> >>>>>
> >>>>> [1] compiler_4.4.0
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>> --
> >>>> Sent from my phone. Please excuse my brevity.
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbo|ker @end|ng |rom gm@||@com  Mon Mar 10 00:31:41 2025
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 9 Mar 2025 19:31:41 -0400
Subject: [R] Number changed weirdly when converting to numeric
In-Reply-To: <755f7612-6e0f-462f-aaf7-f13e272eaa28@gmail.com>
References: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
 <4908AE38-EA36-41F1-B899-FBA17569E2B5@dcn.davis.ca.us>
 <A16FBCC8-9FFD-41EE-ACE7-B6DE9B62B988@collocations.de>
 <F1E7054C-5ADC-40C8-8921-6CC6E04E97C3@dcn.davis.ca.us>
 <CA+dpOJmGGqYgAzrG0qye5_=fg7A0gR2dWTk2z3iiymz-xC9A2Q@mail.gmail.com>
 <755f7612-6e0f-462f-aaf7-f13e272eaa28@gmail.com>
Message-ID: <3806ed31-a284-4746-aeea-94667c82fd28@gmail.com>

   I agree with Duncan.  From an abstract point of view it would be 
interesting, and possibly useful, to analyze exactly what is going 
'wrong' (in some sense) with R's built-in string-to-double function in 
this case, and might lead to some marginal improvements.  But if you are 
doing anything but the simplest floating-point operations you will see 
many other unavoidable differences of similar magnitudes across platforms.

    If you feel like taking a deep dive, this is the classic article 
from 1991: https://www.itu.dk/~sestoft/bachelor/IEEE754_article.pdf (and 
the corresponding R-centric Stack Overflow post 
https://stackoverflow.com/questions/9508518/why-are-these-numbers-not-equal/ 
)

On 3/9/25 18:31, Duncan Murdoch wrote:
> On 2025-03-09 5:55 p.m., Christofer Bogaso wrote:
>> So, based on the discussion points from the experts here, I understand
>> that this is an ARM specific problem.
>>
>> However, what should I do for a solution?
>>
>> I use ARM+R in my office workstation, so it may not be prudent to me
>> to just say ignore this problem and let Apple's Tim Cook take care of
>> it...
> 
> No, the problem is much deeper than that.? If your work depends on 
> things that are way out in the limit of floating point precision, then 
> your work is unavoidably unstable already.? The easiest way to fix this 
> is to avoid doing anything that depends on the 15th or 16th or higher 
> significant digit of what you are working with.
> 
> If you really need 20 or 30 digit precision, then you can do it in R, 
> but you need to be extra careful with every single calculation you're 
> doing.? Base R calculations won't be good enough.
> 
> Duncan Murdoch
> 
>>
>> On Mon, Mar 10, 2025 at 1:01?AM Jeff Newmiller 
>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>
>>> I now see more clearly what the complaint is.
>>>
>>> That said, you should ALWAYS be prepared for the round trip between 
>>> binary and string forms of floating point to accrue rounding error 
>>> because floating point is intrinsically approximate. While there are 
>>> examples of floating point numbers that can reliably do that round 
>>> trip exactly (e.g. integers shorter than the mantissa), in general 
>>> you should be prepared for such "inexact" results.
>>>
>>> John Nash's point that IEEE754 has been relaxed is reinforcement that 
>>> they want users to be prepared for differences around the least 
>>> significant bits... but the principle is mathematically intrinsic to 
>>> the scope of floating point numbers whether the standard says so or not.
>>>
>>> On March 9, 2025 11:06:17 AM PDT, Stephanie Evert 
>>> <stefanML at collocations.de> wrote:
>>>> For once, that doesn't seem to be the issue here. The bug only seems 
>>>> to happen on arm64 and doesn't reproduce on x86_64 hardware.
>>>>
>>>>> x <- as.numeric("-177253333.333333343267441")
>>>>> sprintf("%.15f", x)
>>>> [1] "-177253333.333333373069763"
>>>>
>>>> This is the number adjacent to -177253333.333333343267441 in IEEE 754.
>>>>
>>>>> writeBin(x, raw(8))
>>>> [1] ac aa aa aa 57 21 a5 c1
>>>>
>>>> If you look at the hexadecimal representation, the least significant 
>>>> bit appears to be off by one: the first byte should be 0xAB rather 
>>>> than 0xAC (according to online calculators such as https://numeral- 
>>>> systems.com/ieee-754-converter/).
>>>>
>>>> Seems that decimal-to-float conversion has a bug on arm64. Note that 
>>>> I get the same result with
>>>>
>>>>> x <- -177253333.333333343267441
>>>>
>>>> so it's not specific to as.numeric().
>>>>
>>>> Best,
>>>> Stephanie
>>>>
>>>>
>>>>
>>>>
>>>>> On 9 Mar 2025, at 18:46, Jeff Newmiller via R-help <r-help at r- 
>>>>> project.org> wrote:
>>>>>
>>>>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R- 
>>>>> think-these-numbers-are-equal_003f
>>>>>
>>>>> https://0.30000000000000004.com/
>>>>>
>>>>> On March 9, 2025 10:12:47 AM PDT, Christofer Bogaso 
>>>>> <bogaso.christofer at gmail.com> wrote:
>>>>>> Hi,
>>>>>>
>>>>>> I have below simple conversion
>>>>>>
>>>>>>> sprintf("%0.15f", as.numeric("-177253333.333333343267441"))
>>>>>>
>>>>>> [1] "-177253333.333333373069763"
>>>>>>
>>>>>> I could not figure out why the input and output is different?
>>>>>>
>>>>>> Clearly this conversion is incorrect. Is there any way to convert to
>>>>>> numerical properly?
>>>>>>
>>>>>>> sessionInfo()
>>>>>>
>>>>>> R version 4.4.0 (2024-04-24)
>>>>>>
>>>>>> Platform: aarch64-apple-darwin20
>>>>>>
>>>>>> Running under: macOS 15.3.1
>>>>>>
>>>>>>
>>>>>> Matrix products: default
>>>>>>
>>>>>> BLAS:?? /Library/Frameworks/R.framework/Versions/4.4-arm64/ 
>>>>>> Resources/lib/libRblas.0.dylib
>>>>>>
>>>>>> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/ 
>>>>>> Resources/lib/libRlapack.dylib;
>>>>>> LAPACK version 3.12.0
>>>>>>
>>>>>>
>>>>>> locale:
>>>>>>
>>>>>> [1] C/UTF-8/C/C/C/C
>>>>>>
>>>>>>
>>>>>> time zone: Asia
>>>>>>
>>>>>> tzcode source: internal
>>>>>>
>>>>>>
>>>>>> attached base packages:
>>>>>>
>>>>>> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
>>>>>>
>>>>>>
>>>>>> loaded via a namespace (and not attached):
>>>>>>
>>>>>> [1] compiler_4.4.0
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide https://www.R-project.org/ 
>>>>>> posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>> -- 
>>>>> Sent from my phone. Please excuse my brevity.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide https://www.R-project.org/posting- 
>>>>> guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> -- 
>>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
* E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From tebert @end|ng |rom u||@edu  Mon Mar 10 03:24:05 2025
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Mon, 10 Mar 2025 02:24:05 +0000
Subject: [R] Number changed weirdly when converting to numeric
In-Reply-To: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
References: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
Message-ID: <CH3PR22MB4514D7C6FD5AE27B34B3850ACFD62@CH3PR22MB4514.namprd22.prod.outlook.com>

This is a general problem across all software. A computer has finite memory but a floating-point value can have an infinite number of digits. Consider trying to store the exact value of pi. All computer software has a limit to available precision, and that value is specific to each piece of software. You can play games to find that limit. Ask the computer what is 1 + 0.1?
Then keep going
1 + 0.01
1 + 0.001
And so forth, until the answer is 1. In this game be careful in what the computer displays (as a default) and what it calculates. My version of Excel will display a result of 1 after 1 + 0.0000001. However by changing the display you can see that Excel continues out to 1E-15 before everything equals 1. Keep in mind that this is significant digits. So if I change the problem to 1000 + 0.1 then Excel will display everything equals 1000 after 1000.001, and keep calculating until 1E-11.

You can correctly process the string. This is one solution:

install.packages("Rmpfr")
library(Rmpfr)

x <- "-177253333.333333343267441"
mpfr_x <- mpfr(x, precBits = 128)  # Increase precision

sprintf("%0.15f", as.numeric(mpfr_x))

Mathematical operations on mpfr_x give an answer -354506666.6666666865348819999999999999992 if I multiply by 2.

If I increase precBits=256 then I get -354506666.666666686534882

This approach will let you read the numbers in correctly. You will need to revisit this issue if you use these numbers in data analyses or even simple calculations. Also consider how much memory is being consumed by the increase in precision versus the available memory. This will become more problematic in using these values in matrix algebra necessary in many data analyses.


Tim


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Christofer Bogaso
Sent: Sunday, March 9, 2025 1:13 PM
To: r-help <r-help at r-project.org>
Subject: [R] Number changed weirdly when converting to numeric

[External Email]

Hi,

I have below simple conversion

> sprintf("%0.15f", as.numeric("-177253333.333333343267441"))

[1] "-177253333.333333373069763"

I could not figure out why the input and output is different?

Clearly this conversion is incorrect. Is there any way to convert to numerical properly?

> sessionInfo()

R version 4.4.0 (2024-04-24)

Platform: aarch64-apple-darwin20

Running under: macOS 15.3.1


Matrix products: default

BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib

LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;
 LAPACK version 3.12.0


locale:

[1] C/UTF-8/C/C/C/C


time zone: Asia

tzcode source: internal


attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base


loaded via a namespace (and not attached):

[1] compiler_4.4.0

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Mar 10 11:27:31 2025
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 10 Mar 2025 11:27:31 +0100
Subject: [R] Number changed weirdly when converting to numeric
In-Reply-To: <d15df42b-ccff-4d9f-a650-1c5920cff105@gmail.com>
References: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
 <4908AE38-EA36-41F1-B899-FBA17569E2B5@dcn.davis.ca.us>
 <A16FBCC8-9FFD-41EE-ACE7-B6DE9B62B988@collocations.de>
 <d15df42b-ccff-4d9f-a650-1c5920cff105@gmail.com>
Message-ID: <26574.48787.187485.773401@stat.math.ethz.ch>

>>>>> J C Nash 
>>>>>     on Sun, 9 Mar 2025 14:19:00 -0400 writes:

    > This may be way off the mark, but is it possible that the ARM machine is using
    > the "new" IEEE-754 arithmetic that does not have 80 bit extended? The standard
    > was changed (in ways to allow non-compliant systems to be compliant) because
    > ARM does not have the hardware registers. There are reasons why this might be
    > sensible, but we need more awareness of the consequences to avoid some of the
    > resulting changes in results. I've had to "fix" things that weren't broken because
    > M1 and later Macs gave different outputs, actually not in my code but in vignettes
    > where I compared to other packages.

Yes, indeed; very much the same here, thank you, John.
and yes, the consequences I've seen (in the R world) have been
considerably larger than many would have expected.

OTOH, I agree (with people saying) that I (and others) had
become too much dependent on assuming quite specific floating
point arithmetic behavior (basically something like "x86_64 everywhere")
which has not been a good long term behaviour.

and "yes" (nr. 3): I tell everybody that indeed, the speed of
the M{1,2,3,4,..} chips is amazing and beating all competition
at the moment, *BUT* the cost is decreased accuracy in amazingly
many situations.

Martin

    > Cheers,

    > John Nash
    > (who actually was part of 1985 IEEE 754 committee, though a VERY minor player)

    > On 2025-03-09 14:06, Stephanie Evert wrote:
    >> For once, that doesn't seem to be the issue here. The bug only seems to happen on arm64 and doesn't reproduce on x86_64 hardware.
    >> 
    >>> x <- as.numeric("-177253333.333333343267441")
    >>> sprintf("%.15f", x)
    >> [1] "-177253333.333333373069763"
    >> 
    >> This is the number adjacent to -177253333.333333343267441 in IEEE 754.
    >> 
    >>> writeBin(x, raw(8))
    >> [1] ac aa aa aa 57 21 a5 c1
    >> 
    >> If you look at the hexadecimal representation, the least significant bit appears to be off by one: the first byte should be 0xAB rather than 0xAC (according to online calculators such as https://numeral-systems.com/ieee-754-converter/).
    >> 
    >> Seems that decimal-to-float conversion has a bug on arm64. Note that I get the same result with
    >> 
    >>> x <- -177253333.333333343267441
    >> 
    >> so it's not specific to as.numeric().
    >> 
    >> Best,
    >> Stephanie
    >> 
    >> 
    >> 
    >> 
    >>> On 9 Mar 2025, at 18:46, Jeff Newmiller via R-help <r-help at r-project.org> wrote:
    >>> 
    >>> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
    >>> 
    >>> https://0.30000000000000004.com/
    >>> 
    >>> On March 9, 2025 10:12:47 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
    >>>> Hi,
    >>>> 
    >>>> I have below simple conversion
    >>>> 
    >>>>> sprintf("%0.15f", as.numeric("-177253333.333333343267441"))
    >>>> 
    >>>> [1] "-177253333.333333373069763"
    >>>> 
    >>>> I could not figure out why the input and output is different?
    >>>> 
    >>>> Clearly this conversion is incorrect. Is there any way to convert to
    >>>> numerical properly?
    >>>> 
    >>>>> sessionInfo()
    >>>> 
    >>>> R version 4.4.0 (2024-04-24)
    >>>> 
    >>>> Platform: aarch64-apple-darwin20
    >>>> 
    >>>> Running under: macOS 15.3.1
    >>>> 
    >>>> 
    >>>> Matrix products: default
    >>>> 
    >>>> BLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib
    >>>> 
    >>>> LAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;
    >>>> LAPACK version 3.12.0
    >>>> 
    >>>> 
    >>>> locale:
    >>>> 
    >>>> [1] C/UTF-8/C/C/C/C
    >>>> 
    >>>> 
    >>>> time zone: Asia
    >>>> 
    >>>> tzcode source: internal
    >>>> 
    >>>> 
    >>>> attached base packages:
    >>>> 
    >>>> [1] stats     graphics  grDevices utils     datasets  methods   base
    >>>> 
    >>>> 
    >>>> loaded via a namespace (and not attached):
    >>>> 
    >>>> [1] compiler_4.4.0
    >>>> 
    >>>> ______________________________________________
    >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>>> https://stat.ethz.ch/mailman/listinfo/r-help
    >>>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
    >>>> and provide commented, minimal, self-contained, reproducible code.
    >>> 
    >>> -- 
    >>> Sent from my phone. Please excuse my brevity.
    >>> 
    >>> ______________________________________________
    >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>> https://stat.ethz.ch/mailman/listinfo/r-help
    >>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
    >>> and provide commented, minimal, self-contained, reproducible code.
    >> 
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From @te|@nML @end|ng |rom co||oc@t|on@@de  Mon Mar 10 13:51:02 2025
From: @te|@nML @end|ng |rom co||oc@t|on@@de (Stephanie Evert)
Date: Mon, 10 Mar 2025 13:51:02 +0100
Subject: [R] Number changed weirdly when converting to numeric
In-Reply-To: <d565b28e-a601-49d4-be24-1aba2e0646be@gmail.com>
References: <CA+dpOJm_biYUo80HF3UG=tu2LggK9pidk2nBUD2NbKsskE9ujA@mail.gmail.com>
 <4908AE38-EA36-41F1-B899-FBA17569E2B5@dcn.davis.ca.us>
 <A16FBCC8-9FFD-41EE-ACE7-B6DE9B62B988@collocations.de>
 <d565b28e-a601-49d4-be24-1aba2e0646be@gmail.com>
Message-ID: <0DE187BC-F252-42F9-9ED8-19C3CF0F2597@collocations.de>

Both atof() and strtod() give the correct result on my M1 MacBook. So it looks to me like a bug in R_strtod5(), possibly something that requires extended 80-bit precision to get the conversion right.

Doesn't seem to be the fault of the ARM chip, so I'd say it warrants a bug report.

Perhaps we can learn from SQLite, which has recently put some work into making decimal / double conversion more reliable IIRC (possibly even triggered by similar problems on arm64).

	https://github.com/sqlite/sqlite/blob/eed4e1d2df599952f191182cf51646de11b110a6/src/util.c#L577

A key difference seems to be that SQLite accumulates the significand in an uint64_t in order to get 18 or 19 digits of precision before conversion to double.

Best,
Stephanie


> On 9 Mar 2025, at 19:24, Ben Bolker <bbolker at gmail.com> wrote:
> 
>   Out of curiosity, what does atof() do on that platform? What does the following C program do on arm64? (I don't know exactly what R does to coerce character to double, but this is what I would guess ...)
> 
> #include <stdio.h>
> #include <stdlib.h>
> int main(void) {
>  const char *str = "-177253333.333333343267441";
>  double x = atof(str);
>  printf("%0.15f\n", x);
>  return 0;
> }
> 
>  To my surprise, apparently R doesn't use stdlib to convert.
> 
> From https://github.com/r-devel/r-svn/blob/bb64b28d8cc2e2863eb664e7f83b0a7206b4b1d4/src/main/util.c#L2087C1-L2107:
> 
> /* ...
> 
>       use our own strtod/atof to mitigate effects of setting LC_NUMERIC
> 
>   Also allows complete control of which non-numeric strings are
>   accepted; e.g. glibc allows NANxxxx, macOS NAN(s), this accepts "NA".
> 
> ... */
> 
>  Should this be escalated to r-devel (or r-bugzilla)?  Nothing pops out at me from the recent NEWS ...
> 


	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Mon Mar 10 14:19:50 2025
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 10 Mar 2025 14:19:50 +0100
Subject: [R] [Rd] R 4.5.0 scheduled for April 11
Message-ID: <983AEC97-BB06-46E4-8691-4C0F90F76F7B@gmail.com>

Full schedule is available on developer.r-project.org (pending update from SVN).

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From or@@ge m@iii@g oii qu@@tbo@com  Mon Mar 10 11:04:52 2025
From: or@@ge m@iii@g oii qu@@tbo@com (or@@ge m@iii@g oii qu@@tbo@com)
Date: Mon, 10 Mar 2025 17:04:52 +0700
Subject: [R] R GUI randomly resizes. Is this a known bug?
Message-ID: <7520846d-ef0e-4bed-b7b6-bb690dfc2dce@app.fastmail.com>

Setup:

R-4.4.2patched-win.exe
Windows 11

I always run the R GUI maximized. From time to time when I run a lengthy program the GUI will spontaneously shrink to about 2/3 of its size, with the fonts also shrunk, then jump back to full size. Back and forth, back and forth.

I've been using R for many years and I've never experienced this behavior before this version of R. Have other people observed it? Is it a known bug? Is someone working on fixing it?

I cannot provide a use-case because it happens in an entirely unpredictable way.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Mar 12 11:35:24 2025
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 12 Mar 2025 11:35:24 +0100
Subject: [R] How to customize legend labels in ggplot2?
Message-ID: <CAMk+s2THV8tML6ZzdbEdtPCtDhfzy9J0q7i6+faEM-HF+-h9qg@mail.gmail.com>

I have a data frame with measurements in different conditions. I set
the conditions as a factor using a notation for ease of use. I now
want to plot the data and assign meaningful labels to the factors. I
am using ggplot2; for the x axis I would like to keep the factors but
in the legend I would like to use custom values.
I tried different combinations but none worked.
What is the correct way to assign
custom labels to legends in ggplot2?
Thank you

EXAMPLE:
```
df = data.frame(Target = 1:4,
                Rate = c(0.02078663, 0.03685543, 0.02238002, 0.05033979),
                SD = c(0.003043398, 0.001447410, 0.002998729, 0.002171813))
df$Target = factor(df$Target)
ggplot(df, aes(x=Target, y=Rate, colour=Target, group=Target)) +
  geom_point(size=8) +
  geom_errorbar(aes(ymin=Rate-SD, ymax=Rate+SD), width=.1) +
  scale_colour_manual(values = COLS) +
  xlab(expression(bold("Class"))) +
  ylab(expression(bold("Value"))) +
  theme_classic(base_size = 15)
```
NOTE: if using
```
...
  theme_classic(base_size = 15, labels = c("Condition 1", "Condition 2",
                                           "Condition 3", "Control"))
```
I get the error:

Error in theme_classic(base_size = 15, labels = c("Condition 1",
"Condition 2",  :
  unused argument (labels = c("Condition 1", "Condition 2", "Condition
3", "Control"))


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Mar 12 12:19:12 2025
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 12 Mar 2025 12:19:12 +0100
Subject: [R] How to customize legend labels in ggplot2?
In-Reply-To: <CAMk+s2THV8tML6ZzdbEdtPCtDhfzy9J0q7i6+faEM-HF+-h9qg@mail.gmail.com>
References: <CAMk+s2THV8tML6ZzdbEdtPCtDhfzy9J0q7i6+faEM-HF+-h9qg@mail.gmail.com>
Message-ID: <CAJuCY5xbQyHhiOe2zhykZVXiXuzZjRTRTK3BWVE0gce_L_wfqA@mail.gmail.com>

Dear Luigi,

ggplot2 will use the factor levels as default values for the legend labels.
Setting the factor labels of your target values fixes your problem.

Best regards,



ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
*Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
*Poststukken die naar dit adres worden gestuurd, worden ingescand en
digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
dossiers volledig digitaal behandelen. Poststukken met de vermelding
?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
bezorgd.*
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 12 mrt 2025 om 11:36 schreef Luigi Marongiu <marongiu.luigi at gmail.com
>:

> I have a data frame with measurements in different conditions. I set
> the conditions as a factor using a notation for ease of use. I now
> want to plot the data and assign meaningful labels to the factors. I
> am using ggplot2; for the x axis I would like to keep the factors but
> in the legend I would like to use custom values.
> I tried different combinations but none worked.
> What is the correct way to assign
> custom labels to legends in ggplot2?
> Thank you
>
> EXAMPLE:
> ```
> df = data.frame(Target = 1:4,
>                 Rate = c(0.02078663, 0.03685543, 0.02238002, 0.05033979),
>                 SD = c(0.003043398, 0.001447410, 0.002998729, 0.002171813))
> df$Target = factor(df$Target)
> ggplot(df, aes(x=Target, y=Rate, colour=Target, group=Target)) +
>   geom_point(size=8) +
>   geom_errorbar(aes(ymin=Rate-SD, ymax=Rate+SD), width=.1) +
>   scale_colour_manual(values = COLS) +
>   xlab(expression(bold("Class"))) +
>   ylab(expression(bold("Value"))) +
>   theme_classic(base_size = 15)
> ```
> NOTE: if using
> ```
> ...
>   theme_classic(base_size = 15, labels = c("Condition 1", "Condition 2",
>                                            "Condition 3", "Control"))
> ```
> I get the error:
>
> Error in theme_classic(base_size = 15, labels = c("Condition 1",
> "Condition 2",  :
>   unused argument (labels = c("Condition 1", "Condition 2", "Condition
> 3", "Control"))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Mar 12 12:47:39 2025
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 12 Mar 2025 11:47:39 +0000
Subject: [R] How to customize legend labels in ggplot2?
In-Reply-To: <CAMk+s2THV8tML6ZzdbEdtPCtDhfzy9J0q7i6+faEM-HF+-h9qg@mail.gmail.com>
References: <CAMk+s2THV8tML6ZzdbEdtPCtDhfzy9J0q7i6+faEM-HF+-h9qg@mail.gmail.com>
Message-ID: <e13760c0-bb89-4a5e-b93d-209ce4ca2889@sapo.pt>

?s 10:35 de 12/03/2025, Luigi Marongiu escreveu:
> I have a data frame with measurements in different conditions. I set
> the conditions as a factor using a notation for ease of use. I now
> want to plot the data and assign meaningful labels to the factors. I
> am using ggplot2; for the x axis I would like to keep the factors but
> in the legend I would like to use custom values.
> I tried different combinations but none worked.
> What is the correct way to assign
> custom labels to legends in ggplot2?
> Thank you
> 
> EXAMPLE:
> ```
> df = data.frame(Target = 1:4,
>                  Rate = c(0.02078663, 0.03685543, 0.02238002, 0.05033979),
>                  SD = c(0.003043398, 0.001447410, 0.002998729, 0.002171813))
> df$Target = factor(df$Target)
> ggplot(df, aes(x=Target, y=Rate, colour=Target, group=Target)) +
>    geom_point(size=8) +
>    geom_errorbar(aes(ymin=Rate-SD, ymax=Rate+SD), width=.1) +
>    scale_colour_manual(values = COLS) +
>    xlab(expression(bold("Class"))) +
>    ylab(expression(bold("Value"))) +
>    theme_classic(base_size = 15)
> ```
> NOTE: if using
> ```
> ...
>    theme_classic(base_size = 15, labels = c("Condition 1", "Condition 2",
>                                             "Condition 3", "Control"))
> ```
> I get the error:
> 
> Error in theme_classic(base_size = 15, labels = c("Condition 1",
> "Condition 2",  :
>    unused argument (labels = c("Condition 1", "Condition 2", "Condition
> 3", "Control"))
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

The colors COLS are missing from the question.
As for the labels, use


lbls <- c("Condition 1", "Condition 2", "Condition 3", "Control")

and then

scale_colour_manual(values = COLS, labels = lbls)


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Mar 13 06:19:16 2025
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 13 Mar 2025 06:19:16 +0100
Subject: [R] How to customize legend labels in ggplot2?
In-Reply-To: <e13760c0-bb89-4a5e-b93d-209ce4ca2889@sapo.pt>
References: <CAMk+s2THV8tML6ZzdbEdtPCtDhfzy9J0q7i6+faEM-HF+-h9qg@mail.gmail.com>
 <e13760c0-bb89-4a5e-b93d-209ce4ca2889@sapo.pt>
Message-ID: <CAMk+s2Q8==-cdU+A+oOdme7XRrr9+rOm8xWm+zRUQ=yM28tn2A@mail.gmail.com>

Thank you, but then I will have long labels also on the axis, making the
plot too crowded. I would like instead to force the long labels only on the
legend...

On Wed, 12 Mar 2025, 12:47 Rui Barradas, <ruipbarradas at sapo.pt> wrote:

> ?s 10:35 de 12/03/2025, Luigi Marongiu escreveu:
> > I have a data frame with measurements in different conditions. I set
> > the conditions as a factor using a notation for ease of use. I now
> > want to plot the data and assign meaningful labels to the factors. I
> > am using ggplot2; for the x axis I would like to keep the factors but
> > in the legend I would like to use custom values.
> > I tried different combinations but none worked.
> > What is the correct way to assign
> > custom labels to legends in ggplot2?
> > Thank you
> >
> > EXAMPLE:
> > ```
> > df = data.frame(Target = 1:4,
> >                  Rate = c(0.02078663, 0.03685543, 0.02238002,
> 0.05033979),
> >                  SD = c(0.003043398, 0.001447410, 0.002998729,
> 0.002171813))
> > df$Target = factor(df$Target)
> > ggplot(df, aes(x=Target, y=Rate, colour=Target, group=Target)) +
> >    geom_point(size=8) +
> >    geom_errorbar(aes(ymin=Rate-SD, ymax=Rate+SD), width=.1) +
> >    scale_colour_manual(values = COLS) +
> >    xlab(expression(bold("Class"))) +
> >    ylab(expression(bold("Value"))) +
> >    theme_classic(base_size = 15)
> > ```
> > NOTE: if using
> > ```
> > ...
> >    theme_classic(base_size = 15, labels = c("Condition 1", "Condition 2",
> >                                             "Condition 3", "Control"))
> > ```
> > I get the error:
> >
> > Error in theme_classic(base_size = 15, labels = c("Condition 1",
> > "Condition 2",  :
> >    unused argument (labels = c("Condition 1", "Condition 2", "Condition
> > 3", "Control"))
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Hello,
>
> The colors COLS are missing from the question.
> As for the labels, use
>
>
> lbls <- c("Condition 1", "Condition 2", "Condition 3", "Control")
>
> and then
>
> scale_colour_manual(values = COLS, labels = lbls)
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> presen?a de v?rus.
> www.avg.com
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Mar 13 08:16:09 2025
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 13 Mar 2025 07:16:09 +0000
Subject: [R] How to customize legend labels in ggplot2?
In-Reply-To: <CAMk+s2Q8==-cdU+A+oOdme7XRrr9+rOm8xWm+zRUQ=yM28tn2A@mail.gmail.com>
References: <CAMk+s2THV8tML6ZzdbEdtPCtDhfzy9J0q7i6+faEM-HF+-h9qg@mail.gmail.com>
 <e13760c0-bb89-4a5e-b93d-209ce4ca2889@sapo.pt>
 <CAMk+s2Q8==-cdU+A+oOdme7XRrr9+rOm8xWm+zRUQ=yM28tn2A@mail.gmail.com>
Message-ID: <9f0b2b1e-4daa-41ee-b62b-8aec72ad1bf5@sapo.pt>

Hello,

Inline.

?s 05:19 de 13/03/2025, Luigi Marongiu escreveu:
> Thank you, but then I will have long labels also on the axis, 


I am not getting the same legend labels and axis labels, only the legend 
is labelled as variable lbls, the axis labels are numeric.
I am running the following reproducible example.


library(ggplot2)

lbls <- c("Condition 1", "Condition 2", "Condition 3", "Control")
COLS <- 1:4

df = data.frame(Target = 1:4,
                 Rate = c(0.02078663, 0.03685543, 0.02238002, 0.05033979),
                 SD = c(0.003043398, 0.001447410, 0.002998729, 0.002171813))

df$Target = factor(df$Target)

ggplot(df, aes(x = Target, y = Rate, colour = Target, group = Target)) +
   geom_point(size = 8) +
   geom_errorbar(aes(ymin = Rate - SD, ymax = Rate + SD), width = 0.1) +
   # this is the only thing different from your original code
   scale_colour_manual(values = COLS, labels = lbls) +
   xlab(expression(bold("Class"))) +
   ylab(expression(bold("Value"))) +
   theme_classic(base_size = 15)


What code are you running? The OP code?

Hope this helps,

Rui Barradas

making the
> plot too crowded. I would like instead to force the long labels only on the
> legend...
> 
> On Wed, 12 Mar 2025, 12:47 Rui Barradas, <ruipbarradas at sapo.pt> wrote:
> 
>> ?s 10:35 de 12/03/2025, Luigi Marongiu escreveu:
>>> I have a data frame with measurements in different conditions. I set
>>> the conditions as a factor using a notation for ease of use. I now
>>> want to plot the data and assign meaningful labels to the factors. I
>>> am using ggplot2; for the x axis I would like to keep the factors but
>>> in the legend I would like to use custom values.
>>> I tried different combinations but none worked.
>>> What is the correct way to assign
>>> custom labels to legends in ggplot2?
>>> Thank you
>>>
>>> EXAMPLE:
>>> ```
>>> df = data.frame(Target = 1:4,
>>>                   Rate = c(0.02078663, 0.03685543, 0.02238002,
>> 0.05033979),
>>>                   SD = c(0.003043398, 0.001447410, 0.002998729,
>> 0.002171813))
>>> df$Target = factor(df$Target)
>>> ggplot(df, aes(x=Target, y=Rate, colour=Target, group=Target)) +
>>>     geom_point(size=8) +
>>>     geom_errorbar(aes(ymin=Rate-SD, ymax=Rate+SD), width=.1) +
>>>     scale_colour_manual(values = COLS) +
>>>     xlab(expression(bold("Class"))) +
>>>     ylab(expression(bold("Value"))) +
>>>     theme_classic(base_size = 15)
>>> ```
>>> NOTE: if using
>>> ```
>>> ...
>>>     theme_classic(base_size = 15, labels = c("Condition 1", "Condition 2",
>>>                                              "Condition 3", "Control"))
>>> ```
>>> I get the error:
>>>
>>> Error in theme_classic(base_size = 15, labels = c("Condition 1",
>>> "Condition 2",  :
>>>     unused argument (labels = c("Condition 1", "Condition 2", "Condition
>>> 3", "Control"))
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> https://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> Hello,
>>
>> The colors COLS are missing from the question.
>> As for the labels, use
>>
>>
>> lbls <- c("Condition 1", "Condition 2", "Condition 3", "Control")
>>
>> and then
>>
>> scale_colour_manual(values = COLS, labels = lbls)
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> --
>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>> presen?a de v?rus.
>> www.avg.com
>>
> 


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Mar 13 09:20:05 2025
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 13 Mar 2025 09:20:05 +0100
Subject: [R] How to customize legend labels in ggplot2?
In-Reply-To: <9f0b2b1e-4daa-41ee-b62b-8aec72ad1bf5@sapo.pt>
References: <CAMk+s2THV8tML6ZzdbEdtPCtDhfzy9J0q7i6+faEM-HF+-h9qg@mail.gmail.com>
 <e13760c0-bb89-4a5e-b93d-209ce4ca2889@sapo.pt>
 <CAMk+s2Q8==-cdU+A+oOdme7XRrr9+rOm8xWm+zRUQ=yM28tn2A@mail.gmail.com>
 <9f0b2b1e-4daa-41ee-b62b-8aec72ad1bf5@sapo.pt>
Message-ID: <CAMk+s2TmZSpK1_VQPe3=v96dEr-B5GZbyAKxX9VaRt+3jnPkXw@mail.gmail.com>

Thank you, that is exactly was I was looking for.

On Thu, Mar 13, 2025 at 8:16?AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Inline.
>
> ?s 05:19 de 13/03/2025, Luigi Marongiu escreveu:
> > Thank you, but then I will have long labels also on the axis,
>
>
> I am not getting the same legend labels and axis labels, only the legend
> is labelled as variable lbls, the axis labels are numeric.
> I am running the following reproducible example.
>
>
> library(ggplot2)
>
> lbls <- c("Condition 1", "Condition 2", "Condition 3", "Control")
> COLS <- 1:4
>
> df = data.frame(Target = 1:4,
>                  Rate = c(0.02078663, 0.03685543, 0.02238002, 0.05033979),
>                  SD = c(0.003043398, 0.001447410, 0.002998729, 0.002171813))
>
> df$Target = factor(df$Target)
>
> ggplot(df, aes(x = Target, y = Rate, colour = Target, group = Target)) +
>    geom_point(size = 8) +
>    geom_errorbar(aes(ymin = Rate - SD, ymax = Rate + SD), width = 0.1) +
>    # this is the only thing different from your original code
>    scale_colour_manual(values = COLS, labels = lbls) +
>    xlab(expression(bold("Class"))) +
>    ylab(expression(bold("Value"))) +
>    theme_classic(base_size = 15)
>
>
> What code are you running? The OP code?
>
> Hope this helps,
>
> Rui Barradas
>
> making the
> > plot too crowded. I would like instead to force the long labels only on the
> > legend...
> >
> > On Wed, 12 Mar 2025, 12:47 Rui Barradas, <ruipbarradas at sapo.pt> wrote:
> >
> >> ?s 10:35 de 12/03/2025, Luigi Marongiu escreveu:
> >>> I have a data frame with measurements in different conditions. I set
> >>> the conditions as a factor using a notation for ease of use. I now
> >>> want to plot the data and assign meaningful labels to the factors. I
> >>> am using ggplot2; for the x axis I would like to keep the factors but
> >>> in the legend I would like to use custom values.
> >>> I tried different combinations but none worked.
> >>> What is the correct way to assign
> >>> custom labels to legends in ggplot2?
> >>> Thank you
> >>>
> >>> EXAMPLE:
> >>> ```
> >>> df = data.frame(Target = 1:4,
> >>>                   Rate = c(0.02078663, 0.03685543, 0.02238002,
> >> 0.05033979),
> >>>                   SD = c(0.003043398, 0.001447410, 0.002998729,
> >> 0.002171813))
> >>> df$Target = factor(df$Target)
> >>> ggplot(df, aes(x=Target, y=Rate, colour=Target, group=Target)) +
> >>>     geom_point(size=8) +
> >>>     geom_errorbar(aes(ymin=Rate-SD, ymax=Rate+SD), width=.1) +
> >>>     scale_colour_manual(values = COLS) +
> >>>     xlab(expression(bold("Class"))) +
> >>>     ylab(expression(bold("Value"))) +
> >>>     theme_classic(base_size = 15)
> >>> ```
> >>> NOTE: if using
> >>> ```
> >>> ...
> >>>     theme_classic(base_size = 15, labels = c("Condition 1", "Condition 2",
> >>>                                              "Condition 3", "Control"))
> >>> ```
> >>> I get the error:
> >>>
> >>> Error in theme_classic(base_size = 15, labels = c("Condition 1",
> >>> "Condition 2",  :
> >>>     unused argument (labels = c("Condition 1", "Condition 2", "Condition
> >>> 3", "Control"))
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> https://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >> Hello,
> >>
> >> The colors COLS are missing from the question.
> >> As for the labels, use
> >>
> >>
> >> lbls <- c("Condition 1", "Condition 2", "Condition 3", "Control")
> >>
> >> and then
> >>
> >> scale_colour_manual(values = COLS, labels = lbls)
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>
> >> --
> >> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> >> presen?a de v?rus.
> >> www.avg.com
> >>
> >
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
> www.avg.com



-- 
Best regards,
Luigi


From |kry|ov @end|ng |rom d|@root@org  Thu Mar 13 21:03:20 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Thu, 13 Mar 2025 23:03:20 +0300
Subject: [R] R GUI randomly resizes. Is this a known bug?
In-Reply-To: <7520846d-ef0e-4bed-b7b6-bb690dfc2dce@app.fastmail.com>
References: <7520846d-ef0e-4bed-b7b6-bb690dfc2dce@app.fastmail.com>
Message-ID: <20250313230320.44518732@Tarkus>

? Mon, 10 Mar 2025 17:04:52 +0700
orange at quantbo.com ?????:

> From time to time when I run a lengthy program the GUI will
> spontaneously shrink to about 2/3 of its size, with the fonts also
> shrunk, then jump back to full size. Back and forth, back and forth.

It looks like the kind of resizing that happens when the system scaling
factor is changed, or when the window is dragged between two monitors
with different resolution scaling factors (e.g. 96 pixels per inch vs.
150 pixels per inch). I think that Rgui.exe currently does not perform
any resolution scaling on its own; it seems to rely on the bitmap
scaling provided by Windows for "non-DPI-aware" applications.

How many monitors do you have and what are their resolutions? Are their
connections reliable? It could also be something having updated in
Windows 11 itself.

-- 
Best regards,
Ivan


From kev|n @end|ng |rom zembower@org  Thu Mar 13 22:00:26 2025
From: kev|n @end|ng |rom zembower@org (=?UTF-8?Q?Kevin_Zembower?=)
Date: Thu, 13 Mar 2025 21:00:26 +0000
Subject: [R] What don't I understand about sample()?
References: <4aafb881ce10fff0caa3cee0096d99fa285501b1.camel@zembower.org>
Message-ID: <01000195914ef9c4-7adadf5d-0069-4794-af09-454452b71c3d-000000@email.amazonses.com>

Hello, all,

I'm learning to do randomized distributions in my Stats 101 class*. I
thought I could do it with a call to sample() inside a matrix(), like:

> matrix(sample(1:10, replace=TRUE), 5, 10, byrow=TRUE)
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]    8    2    3    1    8    2    8    8    9     8
[2,]    8    2    3    1    8    2    8    8    9     8
[3,]    8    2    3    1    8    2    8    8    9     8
[4,]    8    2    3    1    8    2    8    8    9     8
[5,]    8    2    3    1    8    2    8    8    9     8
>

Imagine my surprise to learn that all the rows were the same
permutation. I thought each time sample() was called inside the matrix,
it would generate a different permutation. 

I modeled this after the bootstrap sample techniques in
https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf. I don't
understand why it works in bootstrap samples (with replace=TRUE), but
not in randomized distributions (with replace=FALSE).

Thanks for any insight you can share with me, and any suggestions for
getting rows in a matrix with different permutations.

-Kevin

*No, this isn't a homework problem. We're using Lock5 as the text in
class, along with its StatKey web application. I'm just trying to get
more out of the class by also solving our problems using R, for which
I'm not receiving any class credit.


From 538280 @end|ng |rom gm@||@com  Thu Mar 13 22:28:43 2025
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Thu, 13 Mar 2025 15:28:43 -0600
Subject: [R] What don't I understand about sample()?
In-Reply-To: <01000195914ef9c4-7adadf5d-0069-4794-af09-454452b71c3d-000000@email.amazonses.com>
References: <4aafb881ce10fff0caa3cee0096d99fa285501b1.camel@zembower.org>
 <01000195914ef9c4-7adadf5d-0069-4794-af09-454452b71c3d-000000@email.amazonses.com>
Message-ID: <CAFEqCdyxd_H7=Q2LYNw3tvheaGiXR+3fCaF5dmK5Yk7bhmw-mg@mail.gmail.com>

Your call to `sample` does not specify the `size` or the number of
values to return, so it defaults to the same number in `x`, in this
case 10.  The `matrix` function then repeats the vector of 10 enough
times to fill in the matrix.

To do what you want you just need to specify the `size` as the total
number of values you want sampled, 50 or 5*10 for your case.

So the following should do what you want:

matrix(sample(1:10, 5*10, replace=TRUE), 5, 10, byrow=TRUE)

In this case the `byrow` does not really matter much since you are
just filling in random values.

Hope this helps,

On Thu, Mar 13, 2025 at 3:23?PM Kevin Zembower via R-help
<r-help at r-project.org> wrote:
>
> Hello, all,
>
> I'm learning to do randomized distributions in my Stats 101 class*. I
> thought I could do it with a call to sample() inside a matrix(), like:
>
> > matrix(sample(1:10, replace=TRUE), 5, 10, byrow=TRUE)
>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
> [1,]    8    2    3    1    8    2    8    8    9     8
> [2,]    8    2    3    1    8    2    8    8    9     8
> [3,]    8    2    3    1    8    2    8    8    9     8
> [4,]    8    2    3    1    8    2    8    8    9     8
> [5,]    8    2    3    1    8    2    8    8    9     8
> >
>
> Imagine my surprise to learn that all the rows were the same
> permutation. I thought each time sample() was called inside the matrix,
> it would generate a different permutation.
>
> I modeled this after the bootstrap sample techniques in
> https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf. I don't
> understand why it works in bootstrap samples (with replace=TRUE), but
> not in randomized distributions (with replace=FALSE).
>
> Thanks for any insight you can share with me, and any suggestions for
> getting rows in a matrix with different permutations.
>
> -Kevin
>
> *No, this isn't a homework problem. We're using Lock5 as the text in
> class, along with its StatKey web application. I'm just trying to get
> more out of the class by also solving our problems using R, for which
> I'm not receiving any class credit.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From |kw@|mmo @end|ng |rom gm@||@com  Thu Mar 13 22:29:17 2025
From: |kw@|mmo @end|ng |rom gm@||@com (Iris Simmons)
Date: Thu, 13 Mar 2025 17:29:17 -0400
Subject: [R] What don't I understand about sample()?
In-Reply-To: <01000195914ef9c4-7adadf5d-0069-4794-af09-454452b71c3d-000000@email.amazonses.com>
References: <4aafb881ce10fff0caa3cee0096d99fa285501b1.camel@zembower.org>
 <01000195914ef9c4-7adadf5d-0069-4794-af09-454452b71c3d-000000@email.amazonses.com>
Message-ID: <CADNULg_gd_=O-dENdpfxpk==0MSyxfusX6PdZP7pCuHPgGnqDA@mail.gmail.com>

The textbook uses an extra argument 'size'. If you do the same, it should
work.

matrix(sample(1:10, size = 5 * 10, replace=TRUE), 5, 10, byrow=TRUE)

On Thu, Mar 13, 2025, 17:23 Kevin Zembower via R-help <r-help at r-project.org>
wrote:

> Hello, all,
>
> I'm learning to do randomized distributions in my Stats 101 class*. I
> thought I could do it with a call to sample() inside a matrix(), like:
>
> > matrix(sample(1:10, replace=TRUE), 5, 10, byrow=TRUE)
>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
> [1,]    8    2    3    1    8    2    8    8    9     8
> [2,]    8    2    3    1    8    2    8    8    9     8
> [3,]    8    2    3    1    8    2    8    8    9     8
> [4,]    8    2    3    1    8    2    8    8    9     8
> [5,]    8    2    3    1    8    2    8    8    9     8
> >
>
> Imagine my surprise to learn that all the rows were the same
> permutation. I thought each time sample() was called inside the matrix,
> it would generate a different permutation.
>
> I modeled this after the bootstrap sample techniques in
> https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf. I don't
> understand why it works in bootstrap samples (with replace=TRUE), but
> not in randomized distributions (with replace=FALSE).
>
> Thanks for any insight you can share with me, and any suggestions for
> getting rows in a matrix with different permutations.
>
> -Kevin
>
> *No, this isn't a homework problem. We're using Lock5 as the text in
> class, along with its StatKey web application. I'm just trying to get
> more out of the class by also solving our problems using R, for which
> I'm not receiving any class credit.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @vi@e@gross m@iii@g oii gm@ii@com  Thu Mar 13 22:37:37 2025
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Thu, 13 Mar 2025 17:37:37 -0400
Subject: [R] What don't I understand about sample()?
In-Reply-To: <01000195914ef9c4-7adadf5d-0069-4794-af09-454452b71c3d-000000@email.amazonses.com>
References: <4aafb881ce10fff0caa3cee0096d99fa285501b1.camel@zembower.org>
 <01000195914ef9c4-7adadf5d-0069-4794-af09-454452b71c3d-000000@email.amazonses.com>
Message-ID: <006a01db9460$23ca66c0$6b5f3440$@gmail.com>

Kevin,

It is simple. Your matrix has fifty entries and you supplied just 10. R
tends to quietly assume you want the sample repeated as often as needed as
long as it can be used in whole amounts. So, you get five copies. If you
interchanged rows and columns with byrow=FALSE then every two rows would
repeat.

Ask for 50!

matrix(sample(1:50, replace=TRUE), 5, 10, byrow=TRUE)

But decide what you want. You are getting numbers in the range of 10. Asking
for 50 as I showed will get you  something like this:

matrix(sample(1:50, replace=TRUE), 5, 10, byrow=TRUE)
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]   15   32   20    4   44   20   34    2   30    14
[2,]   20    8   42    8   46   45   10   27   27     9
[3,]   26   12   15   26    8   47   25   31   38    31
[4,]   47    5    2   28   13   33   19    3    3    49
[5,]   12    1   11    3   12   21    1   19   30    31

What you may want is this with size=5*10

matrix(sample(x=1:10, size=5*10, replace=TRUE), 5, 10, byrow=TRUE)
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]    2    1    9    9    3    5    7    4    4    10
[2,]    4    1    8    7    1    1    5    1    6    10
[3,]    4    3    6    2    4    4   10   10    8     8
[4,]   10    6    3    2    8   10   10    2    7     9
[5,]    2    4    2    5    5   10   10   10    8     1

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Zembower via
R-help
Sent: Thursday, March 13, 2025 5:00 PM
To: r-help at r-project.org
Subject: [R] What don't I understand about sample()?

Hello, all,

I'm learning to do randomized distributions in my Stats 101 class*. I
thought I could do it with a call to sample() inside a matrix(), like:

> matrix(sample(1:10, replace=TRUE), 5, 10, byrow=TRUE)
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]    8    2    3    1    8    2    8    8    9     8
[2,]    8    2    3    1    8    2    8    8    9     8
[3,]    8    2    3    1    8    2    8    8    9     8
[4,]    8    2    3    1    8    2    8    8    9     8
[5,]    8    2    3    1    8    2    8    8    9     8
>

Imagine my surprise to learn that all the rows were the same
permutation. I thought each time sample() was called inside the matrix,
it would generate a different permutation. 

I modeled this after the bootstrap sample techniques in
https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf. I don't
understand why it works in bootstrap samples (with replace=TRUE), but
not in randomized distributions (with replace=FALSE).

Thanks for any insight you can share with me, and any suggestions for
getting rows in a matrix with different permutations.

-Kevin

*No, this isn't a homework problem. We're using Lock5 as the text in
class, along with its StatKey web application. I'm just trying to get
more out of the class by also solving our problems using R, for which
I'm not receiving any class credit.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Thu Mar 13 22:33:40 2025
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Mar 2025 14:33:40 -0700
Subject: [R] What don't I understand about sample()?
In-Reply-To: <01000195914ef9c4-7adadf5d-0069-4794-af09-454452b71c3d-000000@email.amazonses.com>
References: <4aafb881ce10fff0caa3cee0096d99fa285501b1.camel@zembower.org>
 <01000195914ef9c4-7adadf5d-0069-4794-af09-454452b71c3d-000000@email.amazonses.com>
Message-ID: <CAGxFJbTKagSSs=t7VnhdjSj+RtDTkkud8e5q2F1chWJC_f9YfA@mail.gmail.com>

Bravo for your unrequired R efforts.

You misunderstand the nested call. sample() is called only once,
producing 1 sample of 10 with replacement. Since your matrix call
needs 50 values, ?matrix tells you (in details):
"If there are too few elements in data to fill the matrix, then the
elements in data are recycled. If data has length zero, NA of an
appropriate type is used for atomic vectors (0 for raw vectors) and
NULL for lists.

This sort of "recycling" is quite standard in R. Though not universal.

Cheers,
Bert

"An educated person is one who can entertain new ideas, entertain
others, and entertain herself."

On Thu, Mar 13, 2025 at 2:23?PM Kevin Zembower via R-help
<r-help at r-project.org> wrote:
>
> Hello, all,
>
> I'm learning to do randomized distributions in my Stats 101 class*. I
> thought I could do it with a call to sample() inside a matrix(), like:
>
> > matrix(sample(1:10, replace=TRUE), 5, 10, byrow=TRUE)
>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
> [1,]    8    2    3    1    8    2    8    8    9     8
> [2,]    8    2    3    1    8    2    8    8    9     8
> [3,]    8    2    3    1    8    2    8    8    9     8
> [4,]    8    2    3    1    8    2    8    8    9     8
> [5,]    8    2    3    1    8    2    8    8    9     8
> >
>
> Imagine my surprise to learn that all the rows were the same
> permutation. I thought each time sample() was called inside the matrix,
> it would generate a different permutation.
>
> I modeled this after the bootstrap sample techniques in
> https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf. I don't
> understand why it works in bootstrap samples (with replace=TRUE), but
> not in randomized distributions (with replace=FALSE).
>
> Thanks for any insight you can share with me, and any suggestions for
> getting rows in a matrix with different permutations.
>
> -Kevin
>
> *No, this isn't a homework problem. We're using Lock5 as the text in
> class, along with its StatKey web application. I'm just trying to get
> more out of the class by also solving our problems using R, for which
> I'm not receiving any class credit.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Thu Mar 13 23:06:48 2025
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 13 Mar 2025 23:06:48 +0100
Subject: [R] What don't I understand about sample()?
In-Reply-To: <CAGxFJbTKagSSs=t7VnhdjSj+RtDTkkud8e5q2F1chWJC_f9YfA@mail.gmail.com>
References: <4aafb881ce10fff0caa3cee0096d99fa285501b1.camel@zembower.org>
 <01000195914ef9c4-7adadf5d-0069-4794-af09-454452b71c3d-000000@email.amazonses.com>
 <CAGxFJbTKagSSs=t7VnhdjSj+RtDTkkud8e5q2F1chWJC_f9YfA@mail.gmail.com>
Message-ID: <83A9046F-D8B8-445E-9C28-249183E7A134@gmail.com>

Yes. If you want repeated calls to sample() you need to call it several times.

Try, for instance replicate(5, sample(1:10)) which is nearly the structure you expected, except transposed.

-pd

> On 13 Mar 2025, at 22.33, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Bravo for your unrequired R efforts.
> 
> You misunderstand the nested call. sample() is called only once,
> producing 1 sample of 10 with replacement. Since your matrix call
> needs 50 values, ?matrix tells you (in details):
> "If there are too few elements in data to fill the matrix, then the
> elements in data are recycled. If data has length zero, NA of an
> appropriate type is used for atomic vectors (0 for raw vectors) and
> NULL for lists.
> 
> This sort of "recycling" is quite standard in R. Though not universal.
> 
> Cheers,
> Bert
> 
> "An educated person is one who can entertain new ideas, entertain
> others, and entertain herself."
> 
> On Thu, Mar 13, 2025 at 2:23?PM Kevin Zembower via R-help
> <r-help at r-project.org> wrote:
>> 
>> Hello, all,
>> 
>> I'm learning to do randomized distributions in my Stats 101 class*. I
>> thought I could do it with a call to sample() inside a matrix(), like:
>> 
>>> matrix(sample(1:10, replace=TRUE), 5, 10, byrow=TRUE)
>>     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
>> [1,]    8    2    3    1    8    2    8    8    9     8
>> [2,]    8    2    3    1    8    2    8    8    9     8
>> [3,]    8    2    3    1    8    2    8    8    9     8
>> [4,]    8    2    3    1    8    2    8    8    9     8
>> [5,]    8    2    3    1    8    2    8    8    9     8
>>> 
>> 
>> Imagine my surprise to learn that all the rows were the same
>> permutation. I thought each time sample() was called inside the matrix,
>> it would generate a different permutation.
>> 
>> I modeled this after the bootstrap sample techniques in
>> https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf. I don't
>> understand why it works in bootstrap samples (with replace=TRUE), but
>> not in randomized distributions (with replace=FALSE).
>> 
>> Thanks for any insight you can share with me, and any suggestions for
>> getting rows in a matrix with different permutations.
>> 
>> -Kevin
>> 
>> *No, this isn't a homework problem. We're using Lock5 as the text in
>> class, along with its StatKey web application. I'm just trying to get
>> more out of the class by also solving our problems using R, for which
>> I'm not receiving any class credit.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business SchoolSolbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tebert @end|ng |rom u||@edu  Fri Mar 14 05:19:10 2025
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Fri, 14 Mar 2025 04:19:10 +0000
Subject: [R] What don't I understand about sample()?
In-Reply-To: <01000195914ef9c4-7adadf5d-0069-4794-af09-454452b71c3d-000000@email.amazonses.com>
References: <4aafb881ce10fff0caa3cee0096d99fa285501b1.camel@zembower.org>
 <01000195914ef9c4-7adadf5d-0069-4794-af09-454452b71c3d-000000@email.amazonses.com>
Message-ID: <CH3PR22MB451421391403B0A75E37F98ACFD22@CH3PR22MB4514.namprd22.prod.outlook.com>

This is fun.
In a stats class you are trying to deal with data. There is the underlying distribution. This is the random number generator. I have a population that is following the underlying distribution. In this case my population is 10,000 individuals with a true population mean of 40 and a standard deviation of 6.
Population1 <- round(rnorm(10000, 40, 6), 2)  ### rounds numbers to 2 decimal places
However, Population1 can be any vector of any size, and the code will work.
Population1 <- 1:10
Population1 <- c("a", "b", "C", "D", "e", "f")
Population1 <- letters[1:13]   ### note square brackets here. Round ones do not work.
Population1 <- c(letters[1:13], LETTERS[8:21])

I cannot test every individual in the population of 10,000. My experiment must sample the population. I hope to get away with a sample size of five, but I want to understand the variability in my outcomes. I will take ten sets of five values (just as you have in your example)

Matrix1 <- matrix(sample(Population1, size = length(Matrix1), replace = TRUE), nrow = 5, ncol = 10)
print(Matrix1)

In some cases, I find it easier to understand if I use loops instead. This is just a different way to solve the same problem.
# Fill the matrix using for loops
Matrix1 <- matrix(0,5,10)   ### create and initialize the matrix
for (i in 1:nrow(Matrix1)) {
  for (j in 1:ncol(Matrix1)) {
    Matrix1[i, j] <- sample(Population1, 1)  # Pick a random value from Population1
  }
}
print(Matrix1)

If you want every row to have every value in Population1 (in the case where Population1 <- 1:10) then change replace=TRUE to replace=FALSE in
Matrix1 <- matrix(sample(Population1, size = length(Matrix1), replace = TRUE), nrow = 5, ncol = 10)
. If you want to make this more generic, a simple improvement would be to set the number of columns to be the length of Population1.
Matrix1 <- matrix(sample(Population1, size = length(Matrix1), replace = FALSE), nrow = 5, ncol = length(Population1))


In your example you told R to take a random sample of ten values (from the integers 1 to 10) and then R made five copies to fill the matrix. To make that approach work as planned you could make a hybrid approach like this where I take a random sample of ten values and then loop through that for each row in the matrix.

Matrix1 <- matrix(0, 5, 10)
# Fill the matrix row-wise using a single loop
for (i in 1:nrow(Matrix1)) {
  sample1 <- sample(Population1, 10, replace = TRUE)  # Sample 10 values for the row
  Matrix1[i, ] <- sample1  # Directly assign the entire row
}
# Print the filled matrix
print(Matrix1)

You can also make and use your own variables.
matrix_rows <- 5
matrix_columns <- 10
values <- matrix_rows * matrix_columns
pop_min <- 1
pop_max <- 10
Population1 <- pop_min : pop_max
Matrix1 <- matrix(sample(Population1, size = values, replace = TRUE), nrow = matrix_rows, ncol = matrix_columns)
print(Matrix1)

You can look at the effect of sample size by changing matrix_rows at the top of the program.


Tim


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Zembower via R-help
Sent: Thursday, March 13, 2025 5:00 PM
To: r-help at r-project.org
Subject: [R] What don't I understand about sample()?

[External Email]

Hello, all,

I'm learning to do randomized distributions in my Stats 101 class*. I thought I could do it with a call to sample() inside a matrix(), like:

> matrix(sample(1:10, replace=TRUE), 5, 10, byrow=TRUE)
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]    8    2    3    1    8    2    8    8    9     8
[2,]    8    2    3    1    8    2    8    8    9     8
[3,]    8    2    3    1    8    2    8    8    9     8
[4,]    8    2    3    1    8    2    8    8    9     8
[5,]    8    2    3    1    8    2    8    8    9     8
>

Imagine my surprise to learn that all the rows were the same permutation. I thought each time sample() was called inside the matrix, it would generate a different permutation.

I modeled this after the bootstrap sample techniques in https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf. I don't understand why it works in bootstrap samples (with replace=TRUE), but not in randomized distributions (with replace=FALSE).

Thanks for any insight you can share with me, and any suggestions for getting rows in a matrix with different permutations.

-Kevin

*No, this isn't a homework problem. We're using Lock5 as the text in class, along with its StatKey web application. I'm just trying to get more out of the class by also solving our problems using R, for which I'm not receiving any class credit.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From JH@rm@e @end|ng |rom roku@com  Fri Mar 14 17:31:14 2025
From: JH@rm@e @end|ng |rom roku@com (Jorgen Harmse)
Date: Fri, 14 Mar 2025 16:31:14 +0000
Subject: [R] What don't I understand about sample()?
In-Reply-To: <mailman.372643.1.1741950002.23055.r-help@r-project.org>
References: <mailman.372643.1.1741950002.23055.r-help@r-project.org>
Message-ID: <BL0PR01MB4434D497024B555F20543197DCD22@BL0PR01MB4434.prod.exchangelabs.com>

I agree with the other answers. In particular, Bert Gunter points out that each argument to a function is evaluated at most once. Default arguments can use information in the callee's frame (and order of evaluation may matter), but arguments provided by the caller are evaluated in the caller's environment (or an ancestor in the call-stack hierarchy), so there is no way for sample to know that matrix prefers to see 50 values. If you are determined to have repeated evaluation (instead of simply telling sample what size you want) then you need a function that accepts an expression as input.

Regards,
Jorgen Harmse.

> arrayE <- function(E, dim)

+ { N <- prod(dim)

+   x <- numeric(0L)

+   while (length(x)<N)

+     x <- c(x, eval(E, parent.frame()))

+   array(x[1:N], dim=dim)

+ }

> arrayE(parse(text='sample(1:10, replace=TRUE)'), c(5,10))

     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]

[1,]   10    7   10    8    6    5    6    9    1     9

[2,]    6    3    3    1    8    1    2    9    8     5

[3,]    4    2    1    3    9    5    7   10    1     2

[4,]    1    7    1    6    7    3    3    6    1     2

[5,]    9    6    8    5    3    5    3    4    5     1


------------------------------

Message: 2
Date: Thu, 13 Mar 2025 21:00:26 +0000
From: Kevin Zembower <kevin at zembower.org>
To: r-help at r-project.org <r-help at r-project.org>
Subject: [R] What don't I understand about sample()?
Message-ID:
        <01000195914ef9c4-7adadf5d-0069-4794-af09-454452b71c3d-000000 at email.amazonses.com>

Content-Type: text/plain; charset="utf-8"

Hello, all,

I'm learning to do randomized distributions in my Stats 101 class*. I
thought I could do it with a call to sample() inside a matrix(), like:

> matrix(sample(1:10, replace=TRUE), 5, 10, byrow=TRUE)
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]    8    2    3    1    8    2    8    8    9     8
[2,]    8    2    3    1    8    2    8    8    9     8
[3,]    8    2    3    1    8    2    8    8    9     8
[4,]    8    2    3    1    8    2    8    8    9     8
[5,]    8    2    3    1    8    2    8    8    9     8
>

Imagine my surprise to learn that all the rows were the same
permutation. I thought each time sample() was called inside the matrix,
it would generate a different permutation.

I modeled this after the bootstrap sample techniques in
https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf. I don't
understand why it works in bootstrap samples (with replace=TRUE), but
not in randomized distributions (with replace=FALSE).

Thanks for any insight you can share with me, and any suggestions for
getting rows in a matrix with different permutations.

-Kevin

*No, this isn't a homework problem. We're using Lock5 as the text in
class, along with its StatKey web application. I'm just trying to get
more out of the class by also solving our problems using R, for which
I'm not receiving any class credit.


------------------------------

Message: 5
Date: Thu, 13 Mar 2025 14:33:40 -0700
From: Bert Gunter <bgunter.4567 at gmail.com>
To: Kevin Zembower <kevin at zembower.org>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Subject: Re: [R] What don't I understand about sample()?
Message-ID:
        <CAGxFJbTKagSSs=t7VnhdjSj+RtDTkkud8e5q2F1chWJC_f9YfA at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Bravo for your unrequired R efforts.

You misunderstand the nested call. sample() is called only once,
producing 1 sample of 10 with replacement. Since your matrix call
needs 50 values, ?matrix tells you (in details):
"If there are too few elements in data to fill the matrix, then the
elements in data are recycled. If data has length zero, NA of an
appropriate type is used for atomic vectors (0 for raw vectors) and
NULL for lists.

This sort of "recycling" is quite standard in R. Though not universal.

Cheers,
Bert

"An educated person is one who can entertain new ideas, entertain
others, and entertain herself."

On Thu, Mar 13, 2025 at 2:23?PM Kevin Zembower via R-help
<r-help at r-project.org> wrote:
>
> Hello, all,
>
> I'm learning to do randomized distributions in my Stats 101 class*. I
> thought I could do it with a call to sample() inside a matrix(), like:
>
> > matrix(sample(1:10, replace=TRUE), 5, 10, byrow=TRUE)
>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
> [1,]    8    2    3    1    8    2    8    8    9     8
> [2,]    8    2    3    1    8    2    8    8    9     8
> [3,]    8    2    3    1    8    2    8    8    9     8
> [4,]    8    2    3    1    8    2    8    8    9     8
> [5,]    8    2    3    1    8    2    8    8    9     8
> >
>
> Imagine my surprise to learn that all the rows were the same
> permutation. I thought each time sample() was called inside the matrix,
> it would generate a different permutation.
>
> I modeled this after the bootstrap sample techniques in
> https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf. I don't
> understand why it works in bootstrap samples (with replace=TRUE), but
> not in randomized distributions (with replace=FALSE).
>
> Thanks for any insight you can share with me, and any suggestions for
> getting rows in a matrix with different permutations.
>
> -Kevin
>
> *No, this isn't a homework problem. We're using Lock5 as the text in
> class, along with its StatKey web application. I'm just trying to get
> more out of the class by also solving our problems using R, for which
> I'm not receiving any class credit.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




	[[alternative HTML version deleted]]


From kev|n @end|ng |rom zembower@org  Fri Mar 14 19:51:55 2025
From: kev|n @end|ng |rom zembower@org (=?UTF-8?Q?Kevin_Zembower?=)
Date: Fri, 14 Mar 2025 18:51:55 +0000
Subject: [R] What don't I understand about sample()?
In-Reply-To: <4aafb881ce10fff0caa3cee0096d99fa285501b1.camel@zembower.org>
References: <4aafb881ce10fff0caa3cee0096d99fa285501b1.camel@zembower.org> 
 <d5fce1d0fd242f05c6bdafc94779662c6e06809b.camel@zembower.org>
Message-ID: <0100019595ffab79-081b554a-5ceb-426d-8f67-af62ed03b770-000000@email.amazonses.com>

Thank you all, very much, for your kind and detailed explanations. I
didn't understand, mainly, that the matrix() call only called its
parameters once. I was certain that this was a bug with sample()
getting seeded with a constant value, and giving the same permutation.

I think I need to make my MWE a little less minimal to continue
learning. If you're familiar with the Lock5 statistics textbook, I'm
working on the Light and Dark mice example, where groups of mice were
exposed or not to light at night, then measured for weight gain. The
statistic is mean difference in weight gain between the two groups.

My understanding of how I'm supposed to construct a randomized
distribution is to join the weight gains of the 10 mice exposed to
light at night to the 8 mice not exposed to light at night. After
shuffling this data, I arbitrarily group the first 10 values into the
'light' group, and the last 8 into the 'dark' group, and find the
difference in their means.

I think I can do this correctly with:
===================
## Less-minimal working example
library(tidyverse)

library(Lock5Data)
data(LightatNight)
str(LightatNight)

## Or, if you don't have the Lock5Data library:
(d <-
read_csv("https://www.lock5stat.com/datasets3e/LigthtatNight.csv"))

(lt <- d$BMGain[d$Group == "Light"])
(dk <- d$BMGain[d$Group == "Dark"])
(n_lt <- length(lt))
(n_dk <- length(dk))

(data <- c(lt, dk))

B <- 10 #Will be 1000
n <- length(data)

random.samples <- matrix(NA, B, n)
random.statistics <- rep(NA, B)

for(i in 1:B) {
    random.samples[i,] <- sample(data)
    random.statistics[i] <- mean(random.samples[i, 1:n_lt]) -
        mean(random.samples[i, (n_lt + 1):(n_lt + n_dk)])
}
random.samples
random.statistics

## Trying to do it without a for(), using Peter's suggestion:
(random.samples <- matrix(replicate(B, sample(data)), B, n,
byrow=TRUE))
compute.diff.means <- function(x) {
    return(mean(x[1:n_lt]) - mean(x[(n_lt+1):(n_lt+n_dk)]))
}
(random.statistics <- apply(random.samples, 1, compute.diff.means))
=======================

I think both of these methods give me the data I'm trying for. Any
suggestions on my R coding techniques are welcome.

Thank you all, again, for taking the time and effort to help me. Your
help is greatly appreciated.

-Kevin

On Thu, 2025-03-13 at 17:00 -0400, Kevin Zembower wrote:
> Hello, all,
> 
> I'm learning to do randomized distributions in my Stats 101 class*. I
> thought I could do it with a call to sample() inside a matrix(),
> like:
> 
> > matrix(sample(1:10, replace=TRUE), 5, 10, byrow=TRUE)
> ???? [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
> [1,]??? 8??? 2??? 3??? 1??? 8??? 2??? 8??? 8??? 9???? 8
> [2,]??? 8??? 2??? 3??? 1??? 8??? 2??? 8??? 8??? 9???? 8
> [3,]??? 8??? 2??? 3??? 1??? 8??? 2??? 8??? 8??? 9???? 8
> [4,]??? 8??? 2??? 3??? 1??? 8??? 2??? 8??? 8??? 9???? 8
> [5,]??? 8??? 2??? 3??? 1??? 8??? 2??? 8??? 8??? 9???? 8
> > 
> 
> Imagine my surprise to learn that all the rows were the same
> permutation. I thought each time sample() was called inside the
> matrix,
> it would generate a different permutation. 
> 
> I modeled this after the bootstrap sample techniques in
> https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf. I don't
> understand why it works in bootstrap samples (with replace=TRUE), but
> not in randomized distributions (with replace=FALSE).
> 
> Thanks for any insight you can share with me, and any suggestions for
> getting rows in a matrix with different permutations.
> 
> -Kevin
> 
> *No, this isn't a homework problem. We're using Lock5 as the text in
> class, along with its StatKey web application. I'm just trying to get
> more out of the class by also solving our problems using R, for which
> I'm not receiving any class credit.




From @vi@e@gross m@iii@g oii gm@ii@com  Fri Mar 14 23:19:25 2025
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Fri, 14 Mar 2025 18:19:25 -0400
Subject: [R] What don't I understand about sample()?
In-Reply-To: <0100019595ffab79-081b554a-5ceb-426d-8f67-af62ed03b770-000000@email.amazonses.com>
References: <4aafb881ce10fff0caa3cee0096d99fa285501b1.camel@zembower.org>
 <d5fce1d0fd242f05c6bdafc94779662c6e06809b.camel@zembower.org>
 <0100019595ffab79-081b554a-5ceb-426d-8f67-af62ed03b770-000000@email.amazonses.com>
Message-ID: <010901db952f$25099c70$6f1cd550$@gmail.com>

Kevin,

I was amused by the use of the parentheses wrapping to get the REPL to show the effects of an assignment but would remove that in any final program if the output is not needed. 

I am not saying this is wrong, nor what I describe below, but just a discussion of how others might do it.

I do somewhat wonder  about the way you define the function below:

compute.diff.means <- function(x) {
    return(mean(x[1:n_lt]) - mean(x[(n_lt+1):(n_lt+n_dk)]))
}

It is a function of x which you pass in but makes use of an external variable that it needs to find in the environment several times, n_lt, as well as n_dk. But these assignments happen just once in your code:

(n_lt <- length(lt))
(n_dk <- length(dk))

Some people would write the function to include the variables as in:

compute.diff.means <- function(x, n_lt, n_dk) {
    return(mean(x[1:n_lt]) - mean(x[(n_lt+1):(n_lt+n_dk)]))
}

The names of the variables can be the same or new ones.

The reason you do this seems to be that you are using "apply" as shown below and may not know it can accommodate additional argument.

(random.statistics <- apply(random.samples, 1, compute.diff.means))

The above is an implicit loop that calls compute.diff.means() repeatedly over each row of your matrix. It passes the specific row as a vector as the first and only argument.

If you ask "?apply" to document what the apply function does, you may note that like some other such functions, there is a "..." that actually means anything else you supply as extra arguments are passed along to the function. So, since your variables are not changing, then code like this:

(random.statistics <- apply(random.samples, 1, compute.diff.means, n_lt, n_dk))

Will call a function with a row vector and then the additional two arguments so each call will be to:

compute.diff.means(ROW, n_lt, n_dk)

Arguably, this approach may be no better but in some sense makes your function more portable and cleaner. If your code continued and did additional analyses like this, the function might be more easily re-usable.




-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Zembower via R-help
Sent: Friday, March 14, 2025 2:52 PM
To: r-help at r-project.org
Subject: Re: [R] What don't I understand about sample()?

Thank you all, very much, for your kind and detailed explanations. I
didn't understand, mainly, that the matrix() call only called its
parameters once. I was certain that this was a bug with sample()
getting seeded with a constant value, and giving the same permutation.

I think I need to make my MWE a little less minimal to continue
learning. If you're familiar with the Lock5 statistics textbook, I'm
working on the Light and Dark mice example, where groups of mice were
exposed or not to light at night, then measured for weight gain. The
statistic is mean difference in weight gain between the two groups.

My understanding of how I'm supposed to construct a randomized
distribution is to join the weight gains of the 10 mice exposed to
light at night to the 8 mice not exposed to light at night. After
shuffling this data, I arbitrarily group the first 10 values into the
'light' group, and the last 8 into the 'dark' group, and find the
difference in their means.

I think I can do this correctly with:
===================
## Less-minimal working example
library(tidyverse)

library(Lock5Data)
data(LightatNight)
str(LightatNight)

## Or, if you don't have the Lock5Data library:
(d <-
read_csv("https://www.lock5stat.com/datasets3e/LigthtatNight.csv"))

(lt <- d$BMGain[d$Group == "Light"])
(dk <- d$BMGain[d$Group == "Dark"])
(n_lt <- length(lt))
(n_dk <- length(dk))

(data <- c(lt, dk))

B <- 10 #Will be 1000
n <- length(data)

random.samples <- matrix(NA, B, n)
random.statistics <- rep(NA, B)

for(i in 1:B) {
    random.samples[i,] <- sample(data)
    random.statistics[i] <- mean(random.samples[i, 1:n_lt]) -
        mean(random.samples[i, (n_lt + 1):(n_lt + n_dk)])
}
random.samples
random.statistics

## Trying to do it without a for(), using Peter's suggestion:
(random.samples <- matrix(replicate(B, sample(data)), B, n,
byrow=TRUE))
compute.diff.means <- function(x) {
    return(mean(x[1:n_lt]) - mean(x[(n_lt+1):(n_lt+n_dk)]))
}
(random.statistics <- apply(random.samples, 1, compute.diff.means))
=======================

I think both of these methods give me the data I'm trying for. Any
suggestions on my R coding techniques are welcome.

Thank you all, again, for taking the time and effort to help me. Your
help is greatly appreciated.

-Kevin

On Thu, 2025-03-13 at 17:00 -0400, Kevin Zembower wrote:
> Hello, all,
> 
> I'm learning to do randomized distributions in my Stats 101 class*. I
> thought I could do it with a call to sample() inside a matrix(),
> like:
> 
> > matrix(sample(1:10, replace=TRUE), 5, 10, byrow=TRUE)
>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
> [1,]    8    2    3    1    8    2    8    8    9     8
> [2,]    8    2    3    1    8    2    8    8    9     8
> [3,]    8    2    3    1    8    2    8    8    9     8
> [4,]    8    2    3    1    8    2    8    8    9     8
> [5,]    8    2    3    1    8    2    8    8    9     8
> > 
> 
> Imagine my surprise to learn that all the rows were the same
> permutation. I thought each time sample() was called inside the
> matrix,
> it would generate a different permutation. 
> 
> I modeled this after the bootstrap sample techniques in
> https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf. I don't
> understand why it works in bootstrap samples (with replace=TRUE), but
> not in randomized distributions (with replace=FALSE).
> 
> Thanks for any insight you can share with me, and any suggestions for
> getting rows in a matrix with different permutations.
> 
> -Kevin
> 
> *No, this isn't a homework problem. We're using Lock5 as the text in
> class, along with its StatKey web application. I'm just trying to get
> more out of the class by also solving our problems using R, for which
> I'm not receiving any class credit.



______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Sat Mar 15 09:27:24 2025
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 15 Mar 2025 21:27:24 +1300
Subject: [R] What don't I understand about sample()?
In-Reply-To: <0100019595ffab79-081b554a-5ceb-426d-8f67-af62ed03b770-000000@email.amazonses.com>
References: <d5fce1d0fd242f05c6bdafc94779662c6e06809b.camel@zembower.org>
 <4aafb881ce10fff0caa3cee0096d99fa285501b1.camel@zembower.org>
 <0100019595ffab79-081b554a-5ceb-426d-8f67-af62ed03b770-000000@email.amazonses.com>
Message-ID: <CABcYAdJjtg_Lzqy1Z6MDFinJ6JamN-5FV-xg1g0N5kWXFCqerQ@mail.gmail.com>

Not having the book (and which of the three editions are you using?),
I downloaded the data and played with it for a bit.
dotchart() showed the Dark and Light conditions looked quite
different, but also showed that there are not very many cases.
After trying t.test, it occurred to me that I did not know whether
"BMGain" means gain in *grams* or gain in *percent*.
Reflection told me that for a growth experiment, percent made more
sense, which reminded my of one of my first
student advising experiences, where I said "never give the computer
percentages; let IT calculate the percentages
from the baseline and outcome, because once you've thrown away
information, the computer can't magically get it back."
In particular, in the real world I'd be worried about the possibility
that there was some confounding going on, so I would
much rather have initial weight and final weight as variables.
If BMGain is an absolute measure, the p value for a t test is teeny tiny.
If BMGain is a percentage, the p value for a sensible t test is about 0.03.

A permutation test went like this.
is.light <- d$Group == "Light"
is.dark <- d$Group == "Dark"
score <- function (g) mean(g[is.light]) - mean(g[is.dark])
base.score <- score(d$BMGain)
perm.scores <- sapply(1:997, function (i) score(sample(d$BMGain)))
sum(perm.scores >= base.score) / length(perm.scores)

I don't actually see where matrix() comes into it, still less anything
in the tidyverse.


On Sat, 15 Mar 2025 at 07:52, Kevin Zembower via R-help
<r-help at r-project.org> wrote:
>
> Thank you all, very much, for your kind and detailed explanations. I
> didn't understand, mainly, that the matrix() call only called its
> parameters once. I was certain that this was a bug with sample()
> getting seeded with a constant value, and giving the same permutation.
>
> I think I need to make my MWE a little less minimal to continue
> learning. If you're familiar with the Lock5 statistics textbook, I'm
> working on the Light and Dark mice example, where groups of mice were
> exposed or not to light at night, then measured for weight gain. The
> statistic is mean difference in weight gain between the two groups.
>
> My understanding of how I'm supposed to construct a randomized
> distribution is to join the weight gains of the 10 mice exposed to
> light at night to the 8 mice not exposed to light at night. After
> shuffling this data, I arbitrarily group the first 10 values into the
> 'light' group, and the last 8 into the 'dark' group, and find the
> difference in their means.
>
> I think I can do this correctly with:
> ===================
> ## Less-minimal working example
> library(tidyverse)
>
> library(Lock5Data)
> data(LightatNight)
> str(LightatNight)
>
> ## Or, if you don't have the Lock5Data library:
> (d <-
> read_csv("https://www.lock5stat.com/datasets3e/LigthtatNight.csv"))
>
> (lt <- d$BMGain[d$Group == "Light"])
> (dk <- d$BMGain[d$Group == "Dark"])
> (n_lt <- length(lt))
> (n_dk <- length(dk))
>
> (data <- c(lt, dk))
>
> B <- 10 #Will be 1000
> n <- length(data)
>
> random.samples <- matrix(NA, B, n)
> random.statistics <- rep(NA, B)
>
> for(i in 1:B) {
>     random.samples[i,] <- sample(data)
>     random.statistics[i] <- mean(random.samples[i, 1:n_lt]) -
>         mean(random.samples[i, (n_lt + 1):(n_lt + n_dk)])
> }
> random.samples
> random.statistics
>
> ## Trying to do it without a for(), using Peter's suggestion:
> (random.samples <- matrix(replicate(B, sample(data)), B, n,
> byrow=TRUE))
> compute.diff.means <- function(x) {
>     return(mean(x[1:n_lt]) - mean(x[(n_lt+1):(n_lt+n_dk)]))
> }
> (random.statistics <- apply(random.samples, 1, compute.diff.means))
> =======================
>
> I think both of these methods give me the data I'm trying for. Any
> suggestions on my R coding techniques are welcome.
>
> Thank you all, again, for taking the time and effort to help me. Your
> help is greatly appreciated.
>
> -Kevin
>
> On Thu, 2025-03-13 at 17:00 -0400, Kevin Zembower wrote:
> > Hello, all,
> >
> > I'm learning to do randomized distributions in my Stats 101 class*. I
> > thought I could do it with a call to sample() inside a matrix(),
> > like:
> >
> > > matrix(sample(1:10, replace=TRUE), 5, 10, byrow=TRUE)
> >      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
> > [1,]    8    2    3    1    8    2    8    8    9     8
> > [2,]    8    2    3    1    8    2    8    8    9     8
> > [3,]    8    2    3    1    8    2    8    8    9     8
> > [4,]    8    2    3    1    8    2    8    8    9     8
> > [5,]    8    2    3    1    8    2    8    8    9     8
> > >
> >
> > Imagine my surprise to learn that all the rows were the same
> > permutation. I thought each time sample() was called inside the
> > matrix,
> > it would generate a different permutation.
> >
> > I modeled this after the bootstrap sample techniques in
> > https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf. I don't
> > understand why it works in bootstrap samples (with replace=TRUE), but
> > not in randomized distributions (with replace=FALSE).
> >
> > Thanks for any insight you can share with me, and any suggestions for
> > getting rows in a matrix with different permutations.
> >
> > -Kevin
> >
> > *No, this isn't a homework problem. We're using Lock5 as the text in
> > class, along with its StatKey web application. I'm just trying to get
> > more out of the class by also solving our problems using R, for which
> > I'm not receiving any class credit.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kev|n @end|ng |rom zembower@org  Sat Mar 15 18:03:48 2025
From: kev|n @end|ng |rom zembower@org (=?UTF-8?Q?Kevin_Zembower?=)
Date: Sat, 15 Mar 2025 17:03:48 +0000
Subject: [R] [SPAM | WERBUNG] Re:  What don't I understand about sample()?
In-Reply-To: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org> 
 <4ee3bcfe192808ce7a7a2a0b56ac8dc923634802.camel@zembower.org>
Message-ID: <010001959ac30aa1-b06b10f1-9351-45c1-bd55-63acb07377dc-000000@email.amazonses.com>

Avi, hi, thanks for your reply. I was vaguely aware of the '...'
construct, but hadn't ever worked out how to actually use it. Thank you
so much for teaching me that. I agree that I should use it in my
function.

Yeah, I just used the parentheses around some of my assignments to
avoid the trouble of typing the variable into R to verify the contents.
My work is all contained in a Rmarkdown file, that I finally export and
file with my notes from class to help me study for exams.

Thank you, again, for your generous help for me.

-Kevin

On Sat, 2025-03-15 at 12:00 +0100, r-help-request at r-project.org wrote:
> Kevin,
> 
> I was amused by the use of the parentheses wrapping to get the REPL
> to show the effects of an assignment but would remove that in any
> final program if the output is not needed. 
> 
> I am not saying this is wrong, nor what I describe below, but just a
> discussion of how others might do it.
> 
> I do somewhat wonder? about the way you define the function below:
> 
> compute.diff.means <- function(x) {
> ??? return(mean(x[1:n_lt]) - mean(x[(n_lt+1):(n_lt+n_dk)]))
> }
> 
> It is a function of x which you pass in but makes use of an external
> variable that it needs to find in the environment several times,
> n_lt, as well as n_dk. But these assignments happen just once in your
> code:
> 
> (n_lt <- length(lt))
> (n_dk <- length(dk))
> 
> Some people would write the function to include the variables as in:
> 
> compute.diff.means <- function(x, n_lt, n_dk) {
> ??? return(mean(x[1:n_lt]) - mean(x[(n_lt+1):(n_lt+n_dk)]))
> }
> 
> The names of the variables can be the same or new ones.
> 
> The reason you do this seems to be that you are using "apply" as
> shown below and may not know it can accommodate additional argument.
> 
> (random.statistics <- apply(random.samples, 1, compute.diff.means))
> 
> The above is an implicit loop that calls compute.diff.means()
> repeatedly over each row of your matrix. It passes the specific row
> as a vector as the first and only argument.
> 
> If you ask "?apply" to document what the apply function does, you may
> note that like some other such functions, there is a "..." that
> actually means anything else you supply as extra arguments are passed
> along to the function. So, since your variables are not changing,
> then code like this:
> 
> (random.statistics <- apply(random.samples, 1, compute.diff.means,
> n_lt, n_dk))
> 
> Will call a function with a row vector and then the additional two
> arguments so each call will be to:
> 
> compute.diff.means(ROW, n_lt, n_dk)
> 
> Arguably, this approach may be no better but in some sense makes your
> function more portable and cleaner. If your code continued and did
> additional analyses like this, the function might be more easily re-
> usable.
> 
> 




From kev|n @end|ng |rom zembower@org  Sat Mar 15 18:28:42 2025
From: kev|n @end|ng |rom zembower@org (=?UTF-8?Q?Kevin_Zembower?=)
Date: Sat, 15 Mar 2025 17:28:42 +0000
Subject: [R] What don't I understand about sample()?
In-Reply-To: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org> 
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org>
Message-ID: <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>

Hi, Richard, thanks for replying. I should have mentioned the third
edition, which we're using. The data file didn't change between the
second and third editions, and the data on Body Mass Gain was the same
as in the first edition, although the first edition data file contained
additional variables.

According to my text, the BMGain was measured in grams. Thanks for
pointing out that my statement of the problem lacked crucial
information.

The matrix in my example comes from an example in
https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf, where the author
created a bootstrap example with a matrix that consisted of one row for
every sample in the bootstrap, and one column for each mean in the
original data. This allowed him to find the mean for each row to create
the bootstrap statistics.

The only need for the tidyverse is to use the read_csv() function. I'm
regrettably lazy in not determining which of the multiple functions in
the tidyverse library loads read_csv(), and just using that one.

Thanks, again, for helping me to further understand R and this problem.

-Kevin

On Sat, 2025-03-15 at 12:00 +0100, r-help-request at r-project.org wrote:
> Not having the book (and which of the three editions are you using?),
> I downloaded the data and played with it for a bit.
> dotchart() showed the Dark and Light conditions looked quite
> different, but also showed that there are not very many cases.
> After trying t.test, it occurred to me that I did not know whether
> "BMGain" means gain in *grams* or gain in *percent*.
> Reflection told me that for a growth experiment, percent made more
> sense, which reminded my of one of my first
> student advising experiences, where I said "never give the computer
> percentages; let IT calculate the percentages
> from the baseline and outcome, because once you've thrown away
> information, the computer can't magically get it back."
> In particular, in the real world I'd be worried about the possibility
> that there was some confounding going on, so I would
> much rather have initial weight and final weight as variables.
> If BMGain is an absolute measure, the p value for a t test is teeny
> tiny.
> If BMGain is a percentage, the p value for a sensible t test is about
> 0.03.
> 
> A permutation test went like this.
> is.light <- d$Group == "Light"
> is.dark <- d$Group == "Dark"
> score <- function (g) mean(g[is.light]) - mean(g[is.dark])
> base.score <- score(d$BMGain)
> perm.scores <- sapply(1:997, function (i) score(sample(d$BMGain)))
> sum(perm.scores >= base.score) / length(perm.scores)
> 
> I don't actually see where matrix() comes into it, still less
> anything
> in the tidyverse.
>


From @vi@e@gross m@iii@g oii gm@ii@com  Sat Mar 15 18:55:04 2025
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sat, 15 Mar 2025 13:55:04 -0400
Subject: [R] What don't I understand about sample()?
In-Reply-To: <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org>
 <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
Message-ID: <003d01db95d3$6189cae0$249d60a0$@gmail.com>

Kevin & Richard, and of course everyone,

As the main topic here is not the tidyverse, I will mention the perils of loading in more than needed in general.

If you want to use one or a very few functions, it can be more efficient and safe to load exactly what is needed. In the case of wanting to use read_csv(), I think this suffices:

library(readr)

If you instead use:

library(tidyverse)

You load a varying number of packages (it may change) including some like lubridate or forcats or ggplot2 that you may not be even thinking of using or never heard of.

The bigger problem is shadowing that happens. For example, you may be getting warning messages like:

? dplyr::filter() masks stats::filter()
? dplyr::lag()    masks stats::lag()

This can interfere with some other package you had already loaded unless it uses a notation like mypackage::filter(...) in their code to avoid being easily replaced but even then, if you yourself called what you though was filter() from base R or some package, you have a problem unless you invoke it like base::filter(...)

The order packages like this load can matter as well as when you define a function of your own. So, it may be worth some effort to zoom in and call exactly what you need and only when you need it. I have seen code that only needs a package in rare conditions and only loads the package in one branch of an IF statement right before using in.
.
Packages can also be unloaded after use.

>From what you describe, none of this is crucially important as you are using R for your own purposes in your own RMarkDown file that you may not be distributing. And, when I write programs where I keep adjusting and adding things from the tidyverse, it is indeed much easier to just get the grouping on top and forget about it. That is, until I decide to do something with functional programming that uses reduce/filter/map... and have an odd error!


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Zembower via R-help
Sent: Saturday, March 15, 2025 1:29 PM
To: r-help at r-project.org
Subject: Re: [R] What don't I understand about sample()?

Hi, Richard, thanks for replying. I should have mentioned the third
edition, which we're using. The data file didn't change between the
second and third editions, and the data on Body Mass Gain was the same
as in the first edition, although the first edition data file contained
additional variables.

According to my text, the BMGain was measured in grams. Thanks for
pointing out that my statement of the problem lacked crucial
information.

The matrix in my example comes from an example in
https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf, where the author
created a bootstrap example with a matrix that consisted of one row for
every sample in the bootstrap, and one column for each mean in the
original data. This allowed him to find the mean for each row to create
the bootstrap statistics.

The only need for the tidyverse is to use the read_csv() function. I'm
regrettably lazy in not determining which of the multiple functions in
the tidyverse library loads read_csv(), and just using that one.

Thanks, again, for helping me to further understand R and this problem.

-Kevin

On Sat, 2025-03-15 at 12:00 +0100, r-help-request at r-project.org wrote:
> Not having the book (and which of the three editions are you using?),
> I downloaded the data and played with it for a bit.
> dotchart() showed the Dark and Light conditions looked quite
> different, but also showed that there are not very many cases.
> After trying t.test, it occurred to me that I did not know whether
> "BMGain" means gain in *grams* or gain in *percent*.
> Reflection told me that for a growth experiment, percent made more
> sense, which reminded my of one of my first
> student advising experiences, where I said "never give the computer
> percentages; let IT calculate the percentages
> from the baseline and outcome, because once you've thrown away
> information, the computer can't magically get it back."
> In particular, in the real world I'd be worried about the possibility
> that there was some confounding going on, so I would
> much rather have initial weight and final weight as variables.
> If BMGain is an absolute measure, the p value for a t test is teeny
> tiny.
> If BMGain is a percentage, the p value for a sensible t test is about
> 0.03.
> 
> A permutation test went like this.
> is.light <- d$Group == "Light"
> is.dark <- d$Group == "Dark"
> score <- function (g) mean(g[is.light]) - mean(g[is.dark])
> base.score <- score(d$BMGain)
> perm.scores <- sapply(1:997, function (i) score(sample(d$BMGain)))
> sum(perm.scores >= base.score) / length(perm.scores)
> 
> I don't actually see where matrix() comes into it, still less
> anything
> in the tidyverse.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tebert @end|ng |rom u||@edu  Sat Mar 15 20:51:19 2025
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Sat, 15 Mar 2025 19:51:19 +0000
Subject: [R] What don't I understand about sample()?
In-Reply-To: <CABcYAdJjtg_Lzqy1Z6MDFinJ6JamN-5FV-xg1g0N5kWXFCqerQ@mail.gmail.com>
References: <d5fce1d0fd242f05c6bdafc94779662c6e06809b.camel@zembower.org>
 <4aafb881ce10fff0caa3cee0096d99fa285501b1.camel@zembower.org>
 <0100019595ffab79-081b554a-5ceb-426d-8f67-af62ed03b770-000000@email.amazonses.com>
 <CABcYAdJjtg_Lzqy1Z6MDFinJ6JamN-5FV-xg1g0N5kWXFCqerQ@mail.gmail.com>
Message-ID: <CH3PR22MB4514D1886A0CDC2933C5E963CFDD2@CH3PR22MB4514.namprd22.prod.outlook.com>

Brian Manly wrote a nice book about computer intensive methods in data analysis: https://www.amazon.com/Randomization-Bootstrap-Methods-Biology-Statistical/dp/1584885416. Therein there is a distinction between permutation tests and randomization tests. A permutation test uses every permutation while a randomization test uses a random selection of all permutations. In this case there are exactly 18 choose 2 possible permutations, or 18!/(10!*8!) = 43758. With such a small number, a permutation test is better. The permutation test is exact while the randomization test is approximate (you get a different quantitative answer each time you run the test). At around one million permutations is where I switch from permutation test to randomization test. A bootstrap test takes a random sample of the available data with replacement. The same observation can appear multiple times in each sample. This reduces the influence of rare events.

My guess is that the variable BMGain is body mass gain, and the units should be grams.

There are many ways to program this. A matrix is one approach. The matrix is filled with possible orderings of the data and two groups are formed by splitting the matrix. There are many ways to do this if you just want a number, but plotting the distribution of possible answers lets you see some of the mechanics of this process.
df <- read_csv("https://www.lock5stat.com/datasets3e/LightatNight.csv")

# Generate unique group assignments
unique_partitions <- t(combn(18, 10))

# Compute mean differences for unique partitions
diffs <- apply(unique_partitions, 1, function(idx) {
  group_A <- df$BMGain[idx]        # Values assigned to group A
  group_B <- df$BMGain[-idx]       # Remaining values assigned to group B
  abs(mean(group_A) - mean(group_B))  # Difference in means
})

# Convert to data frame for plotting
diff_df <- data.frame(Difference = diffs)

# Calculate observed difference in original data
obs_diff <- abs(mean(df$BMGain[df$Group == "Light"]) - mean(df$BMGain[df$Group == "Dark"]))

num_below <- sum(diff_df$Difference <= obs_diff)
num_above <- sum(diff_df$Difference > obs_diff)

# Compute p-value (proportion of random diffs as extreme as observed)
p_value <- mean(abs(diffs) >= abs(obs_diff))

# Plot histogram with vline for observed difference
p <- ggplot(diff_df, aes(x = Difference)) +
  geom_histogram(binwidth = 0.05, fill = "blue", alpha = 0.5, color = "black") +
  geom_vline(xintercept = obs_diff, color = "red", linetype = "dashed", size = 1) +
  theme_minimal() +
  ggtitle("Distribution of Mean Differences") +
  xlab("Mean Difference") +
  ylab("Frequency")

# Extract histogram bin data
hist_data <- ggplot_build(p)$data[[1]]
max_y <- max(hist_data$count)  # Get the max count from the histogram

# Add annotation with dynamic max_y
p +
  annotate("text", x = obs_diff - 0.1, y = max_y -(max_y*.17),
           label = paste("Below:", num_below),
           hjust = 1, color = "blue", fontface = "bold") +
  annotate("text", x = obs_diff + 0.1, y = max_y -(max_y*.17),
           label = paste("Above:", num_above),
           hjust = 0, color = "blue", fontface = "bold") +
  annotate("text", x = obs_diff, y = max_y -(max_y*.1),
           label = paste("Observed Diff =", round(obs_diff, 2)),
           vjust = 0, color = "red", fontface = "bold")
# Print observed difference and p-value
cat("Observed Difference:", obs_diff, "\n")
cat("P-value:", p_value, "\n")


Note that unique_partitions can easily exceed the memory capacity of your computer. In that case a randomization test will be more useful. Note that the set seed part is commented out, and each run of the program will give a slightly different outcome.
library(ggplot2)

# Set number of randomizations
rand_number <- 1000  # Adjust as needed

# Create dataset
df <- read_csv("https://www.lock5stat.com/datasets3e/LightatNight.csv")

# Compute observed difference in original data
obs_diff <- abs(mean(df$BMGain[df$Group == "Light"]) - mean(df$BMGain[df$Group == "Dark"]))

# Perform randomization test
#set.seed(123)  # For reproducibility in coding, Do Not Use in analyses
rand_diffs <- numeric(rand_number)

for (i in 1:rand_number) {
  shuffled <- sample(df$BMGain)  # Shuffle values
  group_A <- shuffled[1:10]  # First 10 as Light group
  group_B <- shuffled[11:18]  # Remaining 8 as Dark group
  rand_diffs[i] <- abs(mean(group_A) - mean(group_B))
}

# Convert to data frame for plotting
diff_df <- data.frame(Difference = rand_diffs)

# Count how many are above/below observed difference
num_below <- sum(rand_diffs <= obs_diff)
num_above <- sum(rand_diffs > obs_diff)

# Compute p-value (proportion as extreme as observed)
p_value <- mean(abs(rand_diffs) >= abs(obs_diff))

# Create the base plot
p <- ggplot(diff_df, aes(x = Difference)) +
  geom_histogram(binwidth = 0.05, fill = "blue", alpha = 0.5, color = "black") +
  geom_vline(xintercept = obs_diff, color = "red", linetype = "dashed", size = 1) +
  theme_minimal() +
  ggtitle("Randomization Test: Distribution of Mean Differences") +
  xlab("Mean Difference") +
  ylab("Frequency")

# Extract histogram data for dynamic text placement
hist_data <- ggplot_build(p)$data[[1]]
max_y <- max(hist_data$count)  # Highest bar in the histogram

# Annotate counts on either side of vline
p +
  annotate("text", x = obs_diff - 0.1, y = max_y * 0.8,
           label = paste("Below:", num_below),
           hjust = 1, color = "blue", fontface = "bold") +
  annotate("text", x = obs_diff + 0.1, y = max_y * 0.8,
           label = paste("Above:", num_above),
           hjust = 0, color = "blue", fontface = "bold") +
  annotate("text", x = obs_diff, y = max_y * 0.9,
           label = paste("Observed Diff =", round(obs_diff, 2)),
           vjust = 0, color = "red", fontface = "bold")

# Print observed difference and p-value
cat("Observed Difference:", obs_diff, "\n")
cat("P-value:", p_value, "\n")


Regards,
Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard O'Keefe
Sent: Saturday, March 15, 2025 4:27 AM
To: Kevin Zembower <kevin at zembower.org>
Cc: r-help at r-project.org
Subject: Re: [R] What don't I understand about sample()?

[External Email]

Not having the book (and which of the three editions are you using?), I downloaded the data and played with it for a bit.
dotchart() showed the Dark and Light conditions looked quite different, but also showed that there are not very many cases.
After trying t.test, it occurred to me that I did not know whether "BMGain" means gain in *grams* or gain in *percent*.
Reflection told me that for a growth experiment, percent made more sense, which reminded my of one of my first student advising experiences, where I said "never give the computer percentages; let IT calculate the percentages from the baseline and outcome, because once you've thrown away information, the computer can't magically get it back."
In particular, in the real world I'd be worried about the possibility that there was some confounding going on, so I would much rather have initial weight and final weight as variables.
If BMGain is an absolute measure, the p value for a t test is teeny tiny.
If BMGain is a percentage, the p value for a sensible t test is about 0.03.

A permutation test went like this.
is.light <- d$Group == "Light"
is.dark <- d$Group == "Dark"
score <- function (g) mean(g[is.light]) - mean(g[is.dark]) base.score <- score(d$BMGain) perm.scores <- sapply(1:997, function (i) score(sample(d$BMGain))) sum(perm.scores >= base.score) / length(perm.scores)

I don't actually see where matrix() comes into it, still less anything in the tidyverse.


On Sat, 15 Mar 2025 at 07:52, Kevin Zembower via R-help <r-help at r-project.org> wrote:
>
> Thank you all, very much, for your kind and detailed explanations. I
> didn't understand, mainly, that the matrix() call only called its
> parameters once. I was certain that this was a bug with sample()
> getting seeded with a constant value, and giving the same permutation.
>
> I think I need to make my MWE a little less minimal to continue
> learning. If you're familiar with the Lock5 statistics textbook, I'm
> working on the Light and Dark mice example, where groups of mice were
> exposed or not to light at night, then measured for weight gain. The
> statistic is mean difference in weight gain between the two groups.
>
> My understanding of how I'm supposed to construct a randomized
> distribution is to join the weight gains of the 10 mice exposed to
> light at night to the 8 mice not exposed to light at night. After
> shuffling this data, I arbitrarily group the first 10 values into the
> 'light' group, and the last 8 into the 'dark' group, and find the
> difference in their means.
>
> I think I can do this correctly with:
> ===================
> ## Less-minimal working example
> library(tidyverse)
>
> library(Lock5Data)
> data(LightatNight)
> str(LightatNight)
>
> ## Or, if you don't have the Lock5Data library:
> (d <-
> read_csv("https://nam10.safelinks.protection.outlook.com/?url=https%3A
> %2F%2Fwww.lock5stat.com%2Fdatasets3e%2FLigthtatNight.csv&data=05%7C02%
> 7Ctebert%40ufl.edu%7Cd58e9cb0dd1d493dfd3708dd639b4e26%7C0d4da0f84a314d
> 76ace60a62331e1b84%7C0%7C0%7C638776241003988479%7CUnknown%7CTWFpbGZsb3
> d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoi
> TWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=xICk3ewMwgDmCgvFq52yCaplry
> 5qZseKtrp2yBgIO%2FY%3D&reserved=0"))
>
> (lt <- d$BMGain[d$Group == "Light"])
> (dk <- d$BMGain[d$Group == "Dark"])
> (n_lt <- length(lt))
> (n_dk <- length(dk))
>
> (data <- c(lt, dk))
>
> B <- 10 #Will be 1000
> n <- length(data)
>
> random.samples <- matrix(NA, B, n)
> random.statistics <- rep(NA, B)
>
> for(i in 1:B) {
>     random.samples[i,] <- sample(data)
>     random.statistics[i] <- mean(random.samples[i, 1:n_lt]) -
>         mean(random.samples[i, (n_lt + 1):(n_lt + n_dk)]) }
> random.samples random.statistics
>
> ## Trying to do it without a for(), using Peter's suggestion:
> (random.samples <- matrix(replicate(B, sample(data)), B, n,
> byrow=TRUE))
> compute.diff.means <- function(x) {
>     return(mean(x[1:n_lt]) - mean(x[(n_lt+1):(n_lt+n_dk)])) }
> (random.statistics <- apply(random.samples, 1, compute.diff.means))
> =======================
>
> I think both of these methods give me the data I'm trying for. Any
> suggestions on my R coding techniques are welcome.
>
> Thank you all, again, for taking the time and effort to help me. Your
> help is greatly appreciated.
>
> -Kevin
>
> On Thu, 2025-03-13 at 17:00 -0400, Kevin Zembower wrote:
> > Hello, all,
> >
> > I'm learning to do randomized distributions in my Stats 101 class*.
> > I thought I could do it with a call to sample() inside a matrix(),
> > like:
> >
> > > matrix(sample(1:10, replace=TRUE), 5, 10, byrow=TRUE)
> >      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
> > [1,]    8    2    3    1    8    2    8    8    9     8
> > [2,]    8    2    3    1    8    2    8    8    9     8
> > [3,]    8    2    3    1    8    2    8    8    9     8
> > [4,]    8    2    3    1    8    2    8    8    9     8
> > [5,]    8    2    3    1    8    2    8    8    9     8
> > >
> >
> > Imagine my surprise to learn that all the rows were the same
> > permutation. I thought each time sample() was called inside the
> > matrix, it would generate a different permutation.
> >
> > I modeled this after the bootstrap sample techniques in
> > https://pa/
> > ges.stat.wisc.edu%2F~larget%2Fstat302%2Fchap3.pdf&data=05%7C02%7Cteb
> > ert%40ufl.edu%7Cd58e9cb0dd1d493dfd3708dd639b4e26%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638776241004291461%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=mTfoalDp1qnXCWjy4EaThFXMRC7b2HyhGV75nrI01sw%3D&reserved=0. I don't understand why it works in bootstrap samples (with replace=TRUE), but not in randomized distributions (with replace=FALSE).
> >
> > Thanks for any insight you can share with me, and any suggestions
> > for getting rows in a matrix with different permutations.
> >
> > -Kevin
> >
> > *No, this isn't a homework problem. We're using Lock5 as the text in
> > class, along with its StatKey web application. I'm just trying to
> > get more out of the class by also solving our problems using R, for
> > which I'm not receiving any class credit.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat/
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu
> %7Cd58e9cb0dd1d493dfd3708dd639b4e26%7C0d4da0f84a314d76ace60a62331e1b84
> %7C0%7C0%7C638776241004299940%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGki
> OnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ
> %3D%3D%7C0%7C%7C%7C&sdata=8U3Tea5HC8uDM4G%2FAKsE%2BStdoeMB7Kd%2BCgM3v6
> DG5XI%3D&reserved=0 PLEASE do read the posting guide
> https://www/.
> r-project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%7Cd
> 58e9cb0dd1d493dfd3708dd639b4e26%7C0d4da0f84a314d76ace60a62331e1b84%7C0
> %7C0%7C638776241004308034%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRy
> dWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%
> 3D%7C0%7C%7C%7C&sdata=yeQqG29qVGgeTEEmxIG6e879bRn0sBMJjLEFwfYWOxk%3D&r
> eserved=0 and provide commented, minimal, self-contained, reproducible
> code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Mar 15 22:27:56 2025
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 15 Mar 2025 21:27:56 +0000
Subject: [R] What don't I understand about sample()?
In-Reply-To: <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org>
 <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
Message-ID: <3014e1fb-3c66-4756-98ef-0995bd0b45a9@sapo.pt>

Hello,

I have been following this thread and though answers have been given, 
some of them address R coding in general, not necessarily the sample() 
function. Here are some random notes I think the OP could use, prompted 
by the text linked to, chap3.pdf.

1.
Throughout the text, assignments use the equal sign instead of the left 
arrow. The left arrow is generally considered more idiomatic and there 
is an important diference beteewn he wo, see help("assignOps").


time.mean = with(CommuteAtlanta, mean(Time))
B = 1000
n = nrow(CommuteAtlanta)

# This should be used, not the above.
time.mean <- with(CommuteAtlanta, mean(Time))
B <- 1000
n <- nrow(CommuteAtlanta)


2.
Systematic use of apply(., 1, mean).
rowMeans (and colMeans) are much faster.


boot.statistics <- apply(boot.samples, 1, mean)
boot.statistics <- rowMeans(boot.samples)


3.
The first confidence interval computation seems awkward. I had never 
seen this way of computing a CI95.
Moreover, it's plain common sense to keep the results with the returned 
decimals and round for display purposes only.
And the normal intervals are computed in a more usual way later in the 
text, see sections 1.2 and 1.3.


me <- ceiling(10 * 2 * time.se)/10
round(time.mean, 1) + c(-1, 1) * me

# Straightforward.
normal_ci95 <- time.mean + c(-1, 1) * 2 * time.se
normal_ci95
round(normal_ci95, 1)

# section 1.2 , function boot.mean
interval = mean(x) + c(-1,1)*2*se

# section 1.3
with(students, mean(Height) + c(-1, 1) * 2 * sd(result))



4.
In section 1.2 there is a bootstrap function boot.mean().
The function could be improved to let users pass a conf.level of their 
choice.
And why force the function user to always have the plot displayed? Base 
functions hist() and barplot() have na argument 'plot' with default TRUE 
allowing the user to choose.

The following seems more user friendly.


boot.mean <- function(x, B, binwidth = NULL, conf.level = 0.95, plot = 
TRUE) {
   require(ggplot2)
   n <- length(x)
   boot.samples <- matrix( sample(x, size = n*B, replace = TRUE), B, n)
   boot.statistics <- rowMeans(boot.samples)
   se <- sd(boot.statistics)
   if ( is.null(binwidth) )
     binwidth <- diff(range(boot.statistics))/30

   p <- ggplot(data.frame(x = boot.statistics), aes(x = x)) +
     geom_histogram(aes(y = ..density..),binwidth = binwidth) +
     geom_density(color = "red")

   alpha <- 1 - (1 - conf.level)/2
   interval <- mean(x) + c(-1, 1) * qnorm(alpha) * se

   if(plot) {
     plot(p)
   }

   list(boot.statistics = boot.statistics, interval = interval, se = se, 
plot = p)
}


Hope this helps,

Rui Barradas



?s 17:28 de 15/03/2025, Kevin Zembower via R-help escreveu:
> Hi, Richard, thanks for replying. I should have mentioned the third
> edition, which we're using. The data file didn't change between the
> second and third editions, and the data on Body Mass Gain was the same
> as in the first edition, although the first edition data file contained
> additional variables.
> 
> According to my text, the BMGain was measured in grams. Thanks for
> pointing out that my statement of the problem lacked crucial
> information.
> 
> The matrix in my example comes from an example in
> https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf, where the author
> created a bootstrap example with a matrix that consisted of one row for
> every sample in the bootstrap, and one column for each mean in the
> original data. This allowed him to find the mean for each row to create
> the bootstrap statistics.
> 
> The only need for the tidyverse is to use the read_csv() function. I'm
> regrettably lazy in not determining which of the multiple functions in
> the tidyverse library loads read_csv(), and just using that one.
> 
> Thanks, again, for helping me to further understand R and this problem.
> 
> -Kevin
> 
> On Sat, 2025-03-15 at 12:00 +0100, r-help-request at r-project.org wrote:
>> Not having the book (and which of the three editions are you using?),
>> I downloaded the data and played with it for a bit.
>> dotchart() showed the Dark and Light conditions looked quite
>> different, but also showed that there are not very many cases.
>> After trying t.test, it occurred to me that I did not know whether
>> "BMGain" means gain in *grams* or gain in *percent*.
>> Reflection told me that for a growth experiment, percent made more
>> sense, which reminded my of one of my first
>> student advising experiences, where I said "never give the computer
>> percentages; let IT calculate the percentages
>> from the baseline and outcome, because once you've thrown away
>> information, the computer can't magically get it back."
>> In particular, in the real world I'd be worried about the possibility
>> that there was some confounding going on, so I would
>> much rather have initial weight and final weight as variables.
>> If BMGain is an absolute measure, the p value for a t test is teeny
>> tiny.
>> If BMGain is a percentage, the p value for a sensible t test is about
>> 0.03.
>>
>> A permutation test went like this.
>> is.light <- d$Group == "Light"
>> is.dark <- d$Group == "Dark"
>> score <- function (g) mean(g[is.light]) - mean(g[is.dark])
>> base.score <- score(d$BMGain)
>> perm.scores <- sapply(1:997, function (i) score(sample(d$BMGain)))
>> sum(perm.scores >= base.score) / length(perm.scores)
>>
>> I don't actually see where matrix() comes into it, still less
>> anything
>> in the tidyverse.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From @vi@e@gross m@iii@g oii gm@ii@com  Sun Mar 16 02:31:45 2025
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sat, 15 Mar 2025 21:31:45 -0400
Subject: [R] What don't I understand about sample()?
In-Reply-To: <3014e1fb-3c66-4756-98ef-0995bd0b45a9@sapo.pt>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org>
 <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
 <3014e1fb-3c66-4756-98ef-0995bd0b45a9@sapo.pt>
Message-ID: <005e01db9613$2e439e50$8acadaf0$@gmail.com>

Rui,

I just want to discuss this point you made for now:

	2.
	Systematic use of apply(., 1, mean).
	rowMeans (and colMeans) are much faster.

You are, of course, technically correct. I consider an alternative aspect in which you are teaching a programming language as a small set of "commands" that can do quite a bit in various legal combinations. These are often reserved words and primitives like "if" or operators like "<-" and so on.

You then can discuss various built-in functionality that extends your abilities such as an array of built in functions commonly used. I see these in several categories. Some, can be examined in R at the prompt to see what R code produces it. You can learn how it works and perhaps cannibalize from it to make your own code that uses helpful parts and perhaps avoids functionality you do not need.

The other kinds are relatively hidden as .Internal or a function that after someprocessing then calls .Internal(...) and can be code written in various (perhaps usually compiled) languages such as a version of C,  or perhaps pulled from libraries such as FORTRAN mathematical functions. These are sometimes faster partially because they are not being read and interpreted, or perhaps use cute programming tricks.

So, as I see it, whatever teacher or book or course is being used by the OP, they are supposedly learning ways to approach problems from some level in which they want them to learn about ideas. The goal is not just learning how to do one problem, but to add to your tool bag for additional problems. And, in R, some of those ideas revolve in how to do implicit loops and in some sense do vectorized operations. 

So, if I understood it, the assignment included getting some number of equal-sized vectors and instead of working on them one at a time, assemble them into a collection of vectors. Besides generalized lists, R supports dataframes as a list of vectors (or actually other things) and matrices implemented as vectors with attributes and some other structures.

The assignment seems to ask them to assemble the vectors into rows of a matrix object and then use something that operates on one row at a time, as already discussed. Clearly, someone has already made implementations that allow you to avoid directly using apply() and get the same, faster result, using rowMeans. But note that although there are perhaps additional rowwise operations available this way, such as rowSums, in the general case, there are many possible functions not already supplied.

If I want something like a rowMinMax, or something exotic where I consider the row to contain the coefficients of a polynomial to evaluate for some given value for X, then a less efficient solution can easily be put together using something like apply, or if using other data structures, using cousins like lapply/sapply/vapply and quite a few other methods in packages including functions like pmap and interesting methods in dplyr such as rowwise that allow per row calculations easily.

There are usually many ways you can do something in R, as in many languages, and sometimes a highly efficient solution for some situations is not the best or most efficient. An example might be how some forms of looping are better suited when the number of items is not known in advance. Often a compiled language will optimize away a loop over a fixed small number of items like asking for index going from 1 to 2 to calculate the squares of the index and storing them in an array of two. It may get replaced without a loop and calling a function twice, or even doing the calculation at compile them and inserting a data structure with the results and not doing anything major at run time.

In this case, the OP may actually have a small fixed number of such results and possibly there are faster ways to do the calculation. But, if the point is to learn how to do arbitrary calculations when the magnitude of the parts may vary, then this is reasonable. Of course, if the samples being used are not all the same length, this method can fail badly while other methods may still work well.

I note relatedly, that one of us here has expressed a wish to do some of their code as near to using base R as possible rather than jump right away into the tidyverse. I can respect that even as, I, personally, prefer using whatever works for me faster and easier. At least, that is true when I am prototyping or doing something one-off. If the code turns out to be used a lot and is slow, I might reconsider. But, having said that, I suspect some packages may allow faster code than the basics. Of course, things like the built-in native pipe |> can change things so an altered package using a slower pipe may no longer ...

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
Sent: Saturday, March 15, 2025 5:28 PM
To: Kevin Zembower <kevin at zembower.org>; r-help at r-project.org
Subject: Re: [R] What don't I understand about sample()?

Hello,

I have been following this thread and though answers have been given, 
some of them address R coding in general, not necessarily the sample() 
function. Here are some random notes I think the OP could use, prompted 
by the text linked to, chap3.pdf.

1.
Throughout the text, assignments use the equal sign instead of the left 
arrow. The left arrow is generally considered more idiomatic and there 
is an important diference beteewn he wo, see help("assignOps").


time.mean = with(CommuteAtlanta, mean(Time))
B = 1000
n = nrow(CommuteAtlanta)

# This should be used, not the above.
time.mean <- with(CommuteAtlanta, mean(Time))
B <- 1000
n <- nrow(CommuteAtlanta)


2.
Systematic use of apply(., 1, mean).
rowMeans (and colMeans) are much faster.


boot.statistics <- apply(boot.samples, 1, mean)
boot.statistics <- rowMeans(boot.samples)


3.
The first confidence interval computation seems awkward. I had never 
seen this way of computing a CI95.
Moreover, it's plain common sense to keep the results with the returned 
decimals and round for display purposes only.
And the normal intervals are computed in a more usual way later in the 
text, see sections 1.2 and 1.3.


me <- ceiling(10 * 2 * time.se)/10
round(time.mean, 1) + c(-1, 1) * me

# Straightforward.
normal_ci95 <- time.mean + c(-1, 1) * 2 * time.se
normal_ci95
round(normal_ci95, 1)

# section 1.2 , function boot.mean
interval = mean(x) + c(-1,1)*2*se

# section 1.3
with(students, mean(Height) + c(-1, 1) * 2 * sd(result))



4.
In section 1.2 there is a bootstrap function boot.mean().
The function could be improved to let users pass a conf.level of their 
choice.
And why force the function user to always have the plot displayed? Base 
functions hist() and barplot() have na argument 'plot' with default TRUE 
allowing the user to choose.

The following seems more user friendly.


boot.mean <- function(x, B, binwidth = NULL, conf.level = 0.95, plot = 
TRUE) {
   require(ggplot2)
   n <- length(x)
   boot.samples <- matrix( sample(x, size = n*B, replace = TRUE), B, n)
   boot.statistics <- rowMeans(boot.samples)
   se <- sd(boot.statistics)
   if ( is.null(binwidth) )
     binwidth <- diff(range(boot.statistics))/30

   p <- ggplot(data.frame(x = boot.statistics), aes(x = x)) +
     geom_histogram(aes(y = ..density..),binwidth = binwidth) +
     geom_density(color = "red")

   alpha <- 1 - (1 - conf.level)/2
   interval <- mean(x) + c(-1, 1) * qnorm(alpha) * se

   if(plot) {
     plot(p)
   }

   list(boot.statistics = boot.statistics, interval = interval, se = se, 
plot = p)
}


Hope this helps,

Rui Barradas



?s 17:28 de 15/03/2025, Kevin Zembower via R-help escreveu:
> Hi, Richard, thanks for replying. I should have mentioned the third
> edition, which we're using. The data file didn't change between the
> second and third editions, and the data on Body Mass Gain was the same
> as in the first edition, although the first edition data file contained
> additional variables.
> 
> According to my text, the BMGain was measured in grams. Thanks for
> pointing out that my statement of the problem lacked crucial
> information.
> 
> The matrix in my example comes from an example in
> https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf, where the author
> created a bootstrap example with a matrix that consisted of one row for
> every sample in the bootstrap, and one column for each mean in the
> original data. This allowed him to find the mean for each row to create
> the bootstrap statistics.
> 
> The only need for the tidyverse is to use the read_csv() function. I'm
> regrettably lazy in not determining which of the multiple functions in
> the tidyverse library loads read_csv(), and just using that one.
> 
> Thanks, again, for helping me to further understand R and this problem.
> 
> -Kevin
> 
> On Sat, 2025-03-15 at 12:00 +0100, r-help-request at r-project.org wrote:
>> Not having the book (and which of the three editions are you using?),
>> I downloaded the data and played with it for a bit.
>> dotchart() showed the Dark and Light conditions looked quite
>> different, but also showed that there are not very many cases.
>> After trying t.test, it occurred to me that I did not know whether
>> "BMGain" means gain in *grams* or gain in *percent*.
>> Reflection told me that for a growth experiment, percent made more
>> sense, which reminded my of one of my first
>> student advising experiences, where I said "never give the computer
>> percentages; let IT calculate the percentages
>> from the baseline and outcome, because once you've thrown away
>> information, the computer can't magically get it back."
>> In particular, in the real world I'd be worried about the possibility
>> that there was some confounding going on, so I would
>> much rather have initial weight and final weight as variables.
>> If BMGain is an absolute measure, the p value for a t test is teeny
>> tiny.
>> If BMGain is a percentage, the p value for a sensible t test is about
>> 0.03.
>>
>> A permutation test went like this.
>> is.light <- d$Group == "Light"
>> is.dark <- d$Group == "Dark"
>> score <- function (g) mean(g[is.light]) - mean(g[is.dark])
>> base.score <- score(d$BMGain)
>> perm.scores <- sapply(1:997, function (i) score(sample(d$BMGain)))
>> sum(perm.scores >= base.score) / length(perm.scores)
>>
>> I don't actually see where matrix() comes into it, still less
>> anything
>> in the tidyverse.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Sun Mar 16 05:32:09 2025
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sun, 16 Mar 2025 17:32:09 +1300
Subject: [R] What don't I understand about sample()?
In-Reply-To: <003d01db95d3$6189cae0$249d60a0$@gmail.com>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org>
 <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
 <003d01db95d3$6189cae0$249d60a0$@gmail.com>
Message-ID: <CABcYAdKC9uKyBfGDRKWU7JozTA9i1=2sdePwABVmhNY=3WnRpQ@mail.gmail.com>

Rgui 4.4.3 on Windows.  When I start it up, read.csv is just *there*.
I don't need to load any package to get it.

I have three reasons for being very sparing in the packages I use.
1. It took me long enough to get my head around R.  More packages =
more things to learn.  I *still* have major trouble grasping
tidyverse, and as far as I can see it doesn't solve any problem that
*I* have.  I install a package only when I have a specific need for
something it does, like spatial statistics.  (And yet I have hundreds
of packages installed, because packages depend on other packages.)
2. Everything changes, and they don't all change coherently.  A
package I've used for years may not be available in the next release.
This is not a theoretical possibility; it has happened to me often.
"If I don't use it I can't lose it."  Sometimes things break because
something else on the system (tcl/tk, or the C or Fortran compiler)
has changed.  I'm tired of things breaking because the C or Fortran compiler
is now stricter.
3. The universe of R packages is vast and constantly expanding.  This
makes it *impossible* for anyone to test every possible combination.  I
used to teach software engineering, and we had a slogan "if it isn't
tested it doesn't work".  Base R plus package X?  Probably tested.
Base R plus package Y?  Probably tested.  Base R plus X plus Y?
Not unless X requires Y or Y requires X.

There is also the didactic point that the more you work with base R
the better you will understand it, which you will need to understand
other things like tidyverse.  It's like mastering the alphabet before you
learn shorthand.


On Sun, 16 Mar 2025 at 06:55, <avi.e.gross at gmail.com> wrote:
>
> Kevin & Richard, and of course everyone,
>
> As the main topic here is not the tidyverse, I will mention the perils of loading in more than needed in general.
>
> If you want to use one or a very few functions, it can be more efficient and safe to load exactly what is needed. In the case of wanting to use read_csv(), I think this suffices:
>
> library(readr)
>
> If you instead use:
>
> library(tidyverse)
>
> You load a varying number of packages (it may change) including some like lubridate or forcats or ggplot2 that you may not be even thinking of using or never heard of.
>
> The bigger problem is shadowing that happens. For example, you may be getting warning messages like:
>
> ? dplyr::filter() masks stats::filter()
> ? dplyr::lag()    masks stats::lag()
>
> This can interfere with some other package you had already loaded unless it uses a notation like mypackage::filter(...) in their code to avoid being easily replaced but even then, if you yourself called what you though was filter() from base R or some package, you have a problem unless you invoke it like base::filter(...)
>
> The order packages like this load can matter as well as when you define a function of your own. So, it may be worth some effort to zoom in and call exactly what you need and only when you need it. I have seen code that only needs a package in rare conditions and only loads the package in one branch of an IF statement right before using in.
> .
> Packages can also be unloaded after use.
>
> From what you describe, none of this is crucially important as you are using R for your own purposes in your own RMarkDown file that you may not be distributing. And, when I write programs where I keep adjusting and adding things from the tidyverse, it is indeed much easier to just get the grouping on top and forget about it. That is, until I decide to do something with functional programming that uses reduce/filter/map... and have an odd error!
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Zembower via R-help
> Sent: Saturday, March 15, 2025 1:29 PM
> To: r-help at r-project.org
> Subject: Re: [R] What don't I understand about sample()?
>
> Hi, Richard, thanks for replying. I should have mentioned the third
> edition, which we're using. The data file didn't change between the
> second and third editions, and the data on Body Mass Gain was the same
> as in the first edition, although the first edition data file contained
> additional variables.
>
> According to my text, the BMGain was measured in grams. Thanks for
> pointing out that my statement of the problem lacked crucial
> information.
>
> The matrix in my example comes from an example in
> https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf, where the author
> created a bootstrap example with a matrix that consisted of one row for
> every sample in the bootstrap, and one column for each mean in the
> original data. This allowed him to find the mean for each row to create
> the bootstrap statistics.
>
> The only need for the tidyverse is to use the read_csv() function. I'm
> regrettably lazy in not determining which of the multiple functions in
> the tidyverse library loads read_csv(), and just using that one.
>
> Thanks, again, for helping me to further understand R and this problem.
>
> -Kevin
>
> On Sat, 2025-03-15 at 12:00 +0100, r-help-request at r-project.org wrote:
> > Not having the book (and which of the three editions are you using?),
> > I downloaded the data and played with it for a bit.
> > dotchart() showed the Dark and Light conditions looked quite
> > different, but also showed that there are not very many cases.
> > After trying t.test, it occurred to me that I did not know whether
> > "BMGain" means gain in *grams* or gain in *percent*.
> > Reflection told me that for a growth experiment, percent made more
> > sense, which reminded my of one of my first
> > student advising experiences, where I said "never give the computer
> > percentages; let IT calculate the percentages
> > from the baseline and outcome, because once you've thrown away
> > information, the computer can't magically get it back."
> > In particular, in the real world I'd be worried about the possibility
> > that there was some confounding going on, so I would
> > much rather have initial weight and final weight as variables.
> > If BMGain is an absolute measure, the p value for a t test is teeny
> > tiny.
> > If BMGain is a percentage, the p value for a sensible t test is about
> > 0.03.
> >
> > A permutation test went like this.
> > is.light <- d$Group == "Light"
> > is.dark <- d$Group == "Dark"
> > score <- function (g) mean(g[is.light]) - mean(g[is.dark])
> > base.score <- score(d$BMGain)
> > perm.scores <- sapply(1:997, function (i) score(sample(d$BMGain)))
> > sum(perm.scores >= base.score) / length(perm.scores)
> >
> > I don't actually see where matrix() comes into it, still less
> > anything
> > in the tidyverse.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @vi@e@gross m@iii@g oii gm@ii@com  Sun Mar 16 05:51:24 2025
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sun, 16 Mar 2025 00:51:24 -0400
Subject: [R] What don't I understand about sample()?
In-Reply-To: <CABcYAdKC9uKyBfGDRKWU7JozTA9i1=2sdePwABVmhNY=3WnRpQ@mail.gmail.com>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org>
 <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
 <003d01db95d3$6189cae0$249d60a0$@gmail.com>
 <CABcYAdKC9uKyBfGDRKWU7JozTA9i1=2sdePwABVmhNY=3WnRpQ@mail.gmail.com>
Message-ID: <012401db962f$12376090$36a621b0$@gmail.com>

Richard,

The function with a period as a separator that you cite, read.csv, is part of normal base R.

We have been discussing a different function named just a tad different that uses an underscore as a separator, read_csv that is similar but has some changes in how it works and the options supported and is considered part of the tidyverse grouping of packages and can also be gotten more compactly by importing package "readr" ...

The OP, for reasons of their own, wanted to use read_csv and did not want or need anything else in the related packages.

Of course, nobody is required to use other packages, albeit, as you noted, many packages you may choose to use have some dependencies on others you don't.

Like many good things, added functionality available to you does add complexity and room for failures. But when a package is useful enough to be very useful, it can develop enough momentum that some functionality might well be a good idea to move into base R. As an example I already mentioned, of the various pipe implementations, a version has been added to base R and I suspect many older packages, including in the tidyverse, can adjust their code in new releases to use it but with CARE. Anyone still using older versions of R will experience failures in such a scenario. 

Luckily, many uses within a package are likely to be safe if done properly. Can anyone share if any such methods are in use?

I mean, as an example, could a package early on check if the R version being used is later than the introduction, or some other way to check if a |> operation is supported? Could they then somehow introduce an operator that is either bound to |> or perhaps %>% and use that in any places in the code where both work the same, and only use the magrittr pipe when doing something it does differently such as needing to use a period to specify which argument in a function is receiving the pipelined data.

There are programs people want to keep frozen so they only use the versions of R and packages that existed at some moment so you avoid some inevitable conflicts. So, I despair that older versions of R may stick around way too long and break with any newer packages.

But languages cannot remain totally static or chances are people will move on to newer languages that offer things they want. Then again, there seem to still be COBOL programs out there.

-----Original Message-----
From: Richard O'Keefe <raoknz at gmail.com> 
Sent: Sunday, March 16, 2025 12:32 AM
To: avi.e.gross at gmail.com
Cc: Kevin Zembower <kevin at zembower.org>; r-help at r-project.org
Subject: Re: [R] What don't I understand about sample()?

Rgui 4.4.3 on Windows.  When I start it up, read.csv is just *there*.
I don't need to load any package to get it.

I have three reasons for being very sparing in the packages I use.
1. It took me long enough to get my head around R.  More packages =
more things to learn.  I *still* have major trouble grasping
tidyverse, and as far as I can see it doesn't solve any problem that
*I* have.  I install a package only when I have a specific need for
something it does, like spatial statistics.  (And yet I have hundreds
of packages installed, because packages depend on other packages.)
2. Everything changes, and they don't all change coherently.  A
package I've used for years may not be available in the next release.
This is not a theoretical possibility; it has happened to me often.
"If I don't use it I can't lose it."  Sometimes things break because
something else on the system (tcl/tk, or the C or Fortran compiler)
has changed.  I'm tired of things breaking because the C or Fortran compiler
is now stricter.
3. The universe of R packages is vast and constantly expanding.  This
makes it *impossible* for anyone to test every possible combination.  I
used to teach software engineering, and we had a slogan "if it isn't
tested it doesn't work".  Base R plus package X?  Probably tested.
Base R plus package Y?  Probably tested.  Base R plus X plus Y?
Not unless X requires Y or Y requires X.

There is also the didactic point that the more you work with base R
the better you will understand it, which you will need to understand
other things like tidyverse.  It's like mastering the alphabet before you
learn shorthand.


On Sun, 16 Mar 2025 at 06:55, <avi.e.gross at gmail.com> wrote:
>
> Kevin & Richard, and of course everyone,
>
> As the main topic here is not the tidyverse, I will mention the perils of loading in more than needed in general.
>
> If you want to use one or a very few functions, it can be more efficient and safe to load exactly what is needed. In the case of wanting to use read_csv(), I think this suffices:
>
> library(readr)
>
> If you instead use:
>
> library(tidyverse)
>
> You load a varying number of packages (it may change) including some like lubridate or forcats or ggplot2 that you may not be even thinking of using or never heard of.
>
> The bigger problem is shadowing that happens. For example, you may be getting warning messages like:
>
> ? dplyr::filter() masks stats::filter()
> ? dplyr::lag()    masks stats::lag()
>
> This can interfere with some other package you had already loaded unless it uses a notation like mypackage::filter(...) in their code to avoid being easily replaced but even then, if you yourself called what you though was filter() from base R or some package, you have a problem unless you invoke it like base::filter(...)
>
> The order packages like this load can matter as well as when you define a function of your own. So, it may be worth some effort to zoom in and call exactly what you need and only when you need it. I have seen code that only needs a package in rare conditions and only loads the package in one branch of an IF statement right before using in.
> .
> Packages can also be unloaded after use.
>
> From what you describe, none of this is crucially important as you are using R for your own purposes in your own RMarkDown file that you may not be distributing. And, when I write programs where I keep adjusting and adding things from the tidyverse, it is indeed much easier to just get the grouping on top and forget about it. That is, until I decide to do something with functional programming that uses reduce/filter/map... and have an odd error!
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Zembower via R-help
> Sent: Saturday, March 15, 2025 1:29 PM
> To: r-help at r-project.org
> Subject: Re: [R] What don't I understand about sample()?
>
> Hi, Richard, thanks for replying. I should have mentioned the third
> edition, which we're using. The data file didn't change between the
> second and third editions, and the data on Body Mass Gain was the same
> as in the first edition, although the first edition data file contained
> additional variables.
>
> According to my text, the BMGain was measured in grams. Thanks for
> pointing out that my statement of the problem lacked crucial
> information.
>
> The matrix in my example comes from an example in
> https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf, where the author
> created a bootstrap example with a matrix that consisted of one row for
> every sample in the bootstrap, and one column for each mean in the
> original data. This allowed him to find the mean for each row to create
> the bootstrap statistics.
>
> The only need for the tidyverse is to use the read_csv() function. I'm
> regrettably lazy in not determining which of the multiple functions in
> the tidyverse library loads read_csv(), and just using that one.
>
> Thanks, again, for helping me to further understand R and this problem.
>
> -Kevin
>
> On Sat, 2025-03-15 at 12:00 +0100, r-help-request at r-project.org wrote:
> > Not having the book (and which of the three editions are you using?),
> > I downloaded the data and played with it for a bit.
> > dotchart() showed the Dark and Light conditions looked quite
> > different, but also showed that there are not very many cases.
> > After trying t.test, it occurred to me that I did not know whether
> > "BMGain" means gain in *grams* or gain in *percent*.
> > Reflection told me that for a growth experiment, percent made more
> > sense, which reminded my of one of my first
> > student advising experiences, where I said "never give the computer
> > percentages; let IT calculate the percentages
> > from the baseline and outcome, because once you've thrown away
> > information, the computer can't magically get it back."
> > In particular, in the real world I'd be worried about the possibility
> > that there was some confounding going on, so I would
> > much rather have initial weight and final weight as variables.
> > If BMGain is an absolute measure, the p value for a t test is teeny
> > tiny.
> > If BMGain is a percentage, the p value for a sensible t test is about
> > 0.03.
> >
> > A permutation test went like this.
> > is.light <- d$Group == "Light"
> > is.dark <- d$Group == "Dark"
> > score <- function (g) mean(g[is.light]) - mean(g[is.dark])
> > base.score <- score(d$BMGain)
> > perm.scores <- sapply(1:997, function (i) score(sample(d$BMGain)))
> > sum(perm.scores >= base.score) / length(perm.scores)
> >
> > I don't actually see where matrix() comes into it, still less
> > anything
> > in the tidyverse.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @vi@e@gross m@iii@g oii gm@ii@com  Sun Mar 16 06:12:00 2025
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sun, 16 Mar 2025 01:12:00 -0400
Subject: [R] What don't I understand about sample()?
In-Reply-To: <CABcYAdKC9uKyBfGDRKWU7JozTA9i1=2sdePwABVmhNY=3WnRpQ@mail.gmail.com>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org>
 <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
 <003d01db95d3$6189cae0$249d60a0$@gmail.com>
 <CABcYAdKC9uKyBfGDRKWU7JozTA9i1=2sdePwABVmhNY=3WnRpQ@mail.gmail.com>
Message-ID: <012601db9631$f2e269d0$d8a73d70$@gmail.com>

Richard,

After some thinking, I conclude that founders of things, including ancient religious figures as well as people who have developed programming languages, may not recognize what follows later. As an example, you have customs in some religions revolving around trees and snow or around potato pancakes when the early version took place in warmer climes and long before potatoes had been introduced to Eurasia.

In the same way, many people would NOT build the language the same way if they were doing it now. They would not be stuck with some early, and sometimes arbitrary, decisions.

I am not defending the tidyverse nor attacking it. Some parts of it have kept changing with others being deprecated and if built anew, it might be a bit different. But, yes, in one sense it is a language of it's own tacked on top of base R which is tacked on top of a sparser underlying part of R. I happen to like quite a bit of it as having a certain consistence and approach and functionality that is better thought out than early pure R. Not everything, but some things. And, the two largely inter-operate so it is possible to do tasks alternating between the two as well as incorporating other packages.

There are parts of R that I, as an opinion, feel were badly designed and built in the sense that it seems complex and easy to do things wrong in. Others disagree. In a similar vein, there are parts of the tidyverse that don't feel right to me and some of what has been deprecated feels more right. As time went on, some simpler functionality has been made so damn general and flexible that the simpler and more common cases feel almost hidden and hard to do.

A new approach to build an R-like language might, as one example, move directly to one major way of being object-oriented rather than so many available now. Attempts to create a sort of overarching way may work but are perhaps more kludge than had they been built directly with no S3 or S4 or ...

But it is in a sense too late to change and also too early. A new R might be so incompatible that many or most programs would stop working right, or at all. Python is an example where they bit the bullet and version 3.X is different enough from 2.X so that many programs need a serious rewrite. Too bad the original could not have started out like it, but who knew what the future might bring.

But I find a reasonable compromise reasonable if you allow a language to layer mini-languages within or above it. An obvious example is how regular expressions can extend a language. Some languages like SCALA allow fairly serious ways to extend the language almost seamlessly as you can create what looks like all kinds of new keywords and operators that just work. When working with a region of code using objects and associated methods that appear inline between objects, you might wonder if you are using some other language entirely. Move to a different part of the code, and it may look like yet another universe. 

R is not designed with all concepts but packages often can extend it nicely and I suggest that is as good a way to extend the language as many others, albeit things can break.


-----Original Message-----
From: Richard O'Keefe <raoknz at gmail.com> 
Sent: Sunday, March 16, 2025 12:32 AM
To: avi.e.gross at gmail.com
Cc: Kevin Zembower <kevin at zembower.org>; r-help at r-project.org
Subject: Re: [R] What don't I understand about sample()?

Rgui 4.4.3 on Windows.  When I start it up, read.csv is just *there*.
I don't need to load any package to get it.

I have three reasons for being very sparing in the packages I use.
1. It took me long enough to get my head around R.  More packages =
more things to learn.  I *still* have major trouble grasping
tidyverse, and as far as I can see it doesn't solve any problem that
*I* have.  I install a package only when I have a specific need for
something it does, like spatial statistics.  (And yet I have hundreds
of packages installed, because packages depend on other packages.)
2. Everything changes, and they don't all change coherently.  A
package I've used for years may not be available in the next release.
This is not a theoretical possibility; it has happened to me often.
"If I don't use it I can't lose it."  Sometimes things break because
something else on the system (tcl/tk, or the C or Fortran compiler)
has changed.  I'm tired of things breaking because the C or Fortran compiler
is now stricter.
3. The universe of R packages is vast and constantly expanding.  This
makes it *impossible* for anyone to test every possible combination.  I
used to teach software engineering, and we had a slogan "if it isn't
tested it doesn't work".  Base R plus package X?  Probably tested.
Base R plus package Y?  Probably tested.  Base R plus X plus Y?
Not unless X requires Y or Y requires X.

There is also the didactic point that the more you work with base R
the better you will understand it, which you will need to understand
other things like tidyverse.  It's like mastering the alphabet before you
learn shorthand.


On Sun, 16 Mar 2025 at 06:55, <avi.e.gross at gmail.com> wrote:
>
> Kevin & Richard, and of course everyone,
>
> As the main topic here is not the tidyverse, I will mention the perils of loading in more than needed in general.
>
> If you want to use one or a very few functions, it can be more efficient and safe to load exactly what is needed. In the case of wanting to use read_csv(), I think this suffices:
>
> library(readr)
>
> If you instead use:
>
> library(tidyverse)
>
> You load a varying number of packages (it may change) including some like lubridate or forcats or ggplot2 that you may not be even thinking of using or never heard of.
>
> The bigger problem is shadowing that happens. For example, you may be getting warning messages like:
>
> ? dplyr::filter() masks stats::filter()
> ? dplyr::lag()    masks stats::lag()
>
> This can interfere with some other package you had already loaded unless it uses a notation like mypackage::filter(...) in their code to avoid being easily replaced but even then, if you yourself called what you though was filter() from base R or some package, you have a problem unless you invoke it like base::filter(...)
>
> The order packages like this load can matter as well as when you define a function of your own. So, it may be worth some effort to zoom in and call exactly what you need and only when you need it. I have seen code that only needs a package in rare conditions and only loads the package in one branch of an IF statement right before using in.
> .
> Packages can also be unloaded after use.
>
> From what you describe, none of this is crucially important as you are using R for your own purposes in your own RMarkDown file that you may not be distributing. And, when I write programs where I keep adjusting and adding things from the tidyverse, it is indeed much easier to just get the grouping on top and forget about it. That is, until I decide to do something with functional programming that uses reduce/filter/map... and have an odd error!
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Zembower via R-help
> Sent: Saturday, March 15, 2025 1:29 PM
> To: r-help at r-project.org
> Subject: Re: [R] What don't I understand about sample()?
>
> Hi, Richard, thanks for replying. I should have mentioned the third
> edition, which we're using. The data file didn't change between the
> second and third editions, and the data on Body Mass Gain was the same
> as in the first edition, although the first edition data file contained
> additional variables.
>
> According to my text, the BMGain was measured in grams. Thanks for
> pointing out that my statement of the problem lacked crucial
> information.
>
> The matrix in my example comes from an example in
> https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf, where the author
> created a bootstrap example with a matrix that consisted of one row for
> every sample in the bootstrap, and one column for each mean in the
> original data. This allowed him to find the mean for each row to create
> the bootstrap statistics.
>
> The only need for the tidyverse is to use the read_csv() function. I'm
> regrettably lazy in not determining which of the multiple functions in
> the tidyverse library loads read_csv(), and just using that one.
>
> Thanks, again, for helping me to further understand R and this problem.
>
> -Kevin
>
> On Sat, 2025-03-15 at 12:00 +0100, r-help-request at r-project.org wrote:
> > Not having the book (and which of the three editions are you using?),
> > I downloaded the data and played with it for a bit.
> > dotchart() showed the Dark and Light conditions looked quite
> > different, but also showed that there are not very many cases.
> > After trying t.test, it occurred to me that I did not know whether
> > "BMGain" means gain in *grams* or gain in *percent*.
> > Reflection told me that for a growth experiment, percent made more
> > sense, which reminded my of one of my first
> > student advising experiences, where I said "never give the computer
> > percentages; let IT calculate the percentages
> > from the baseline and outcome, because once you've thrown away
> > information, the computer can't magically get it back."
> > In particular, in the real world I'd be worried about the possibility
> > that there was some confounding going on, so I would
> > much rather have initial weight and final weight as variables.
> > If BMGain is an absolute measure, the p value for a t test is teeny
> > tiny.
> > If BMGain is a percentage, the p value for a sensible t test is about
> > 0.03.
> >
> > A permutation test went like this.
> > is.light <- d$Group == "Light"
> > is.dark <- d$Group == "Dark"
> > score <- function (g) mean(g[is.light]) - mean(g[is.dark])
> > base.score <- score(d$BMGain)
> > perm.scores <- sapply(1:997, function (i) score(sample(d$BMGain)))
> > sum(perm.scores >= base.score) / length(perm.scores)
> >
> > I don't actually see where matrix() comes into it, still less
> > anything
> > in the tidyverse.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Mar 16 10:05:29 2025
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 16 Mar 2025 09:05:29 +0000
Subject: [R] What don't I understand about sample()?
In-Reply-To: <005e01db9613$2e439e50$8acadaf0$@gmail.com>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org>
 <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
 <3014e1fb-3c66-4756-98ef-0995bd0b45a9@sapo.pt>
 <005e01db9613$2e439e50$8acadaf0$@gmail.com>
Message-ID: <fb33c158-3cea-4418-b63b-402e56ba1b8a@sapo.pt>

Hello,

Inline.

?s 01:31 de 16/03/2025, avi.e.gross at gmail.com escreveu:
> Rui,
> 
> I just want to discuss this point you made for now:
> 
> 	2.
> 	Systematic use of apply(., 1, mean).
> 	rowMeans (and colMeans) are much faster.
> 
> You are, of course, technically correct. I consider an alternative aspect in which you are teaching a programming language as a small set of "commands" that can do quite a bit in various legal combinations. These are often reserved words and primitives like "if" or operators like "<-" and so on.
> 
> You then can discuss various built-in functionality that extends your abilities such as an array of built in functions commonly used. I see these in several categories. Some, can be examined in R at the prompt to see what R code produces it. You can learn how it works and perhaps cannibalize from it to make your own code that uses helpful parts and perhaps avoids functionality you do not need.
> 
> The other kinds are relatively hidden as .Internal or a function that after someprocessing then calls .Internal(...) and can be code written in various (perhaps usually compiled) languages such as a version of C,  or perhaps pulled from libraries such as FORTRAN mathematical functions. These are sometimes faster partially because they are not being read and interpreted, or perhaps use cute programming tricks.
> 
> So, as I see it, whatever teacher or book or course is being used by the OP, they are supposedly learning ways to approach problems from some level in which they want them to learn about ideas. The goal is not just learning how to do one problem, but to add to your tool bag for additional problems. And, in R, some of those ideas revolve in how to do implicit loops and in some sense do vectorized operations.
> 
> So, if I understood it, the assignment included getting some number of equal-sized vectors and instead of working on them one at a time, assemble them into a collection of vectors. Besides generalized lists, R supports dataframes as a list of vectors (or actually other things) and matrices implemented as vectors with attributes and some other structures.
> 
> The assignment seems to ask them to assemble the vectors into rows of a matrix object and then use something that operates on one row at a time, as already discussed. Clearly, someone has already made implementations that allow you to avoid directly using apply() and get the same, faster result, using rowMeans. But note that although there are perhaps additional rowwise operations available this way, such as rowSums, in the general case, there are many possible functions not already supplied.
> 
> If I want something like a rowMinMax, or something exotic where I consider the row to contain the coefficients of a polynomial to evaluate for some given value for X, then a less efficient solution can easily be put together using something like apply, or if using other data structures, using cousins like lapply/sapply/vapply and quite a few other methods in packages including functions like pmap and interesting methods in dplyr such as rowwise that allow per row calculations easily.

I couldn't agree more. My comment applies to the use of apply(., 1, 
mean), not to the use of apply() in general. In the text, mean() is the 
only function apply'ed, that's why my comment.
I have read several times that when R users learn how to effectively use 
apply/lapply then they've made it through R's [steep] learning curve. I 
know I felt that way when I learned those functions.

> 
> There are usually many ways you can do something in R, as in many languages, and sometimes a highly efficient solution for some situations is not the best or most efficient. An example might be how some forms of looping are better suited when the number of items is not known in advance. Often a compiled language will optimize away a loop over a fixed small number of items like asking for index going from 1 to 2 to calculate the squares of the index and storing them in an array of two. It may get replaced without a loop and calling a function twice, or even doing the calculation at compile them and inserting a data structure with the results and not doing anything major at run time.
> 
> In this case, the OP may actually have a small fixed number of such results and possibly there are faster ways to do the calculation. But, if the point is to learn how to do arbitrary calculations when the magnitude of the parts may vary, then this is reasonable. Of course, if the samples being used are not all the same length, this method can fail badly while other methods may still work well.
> 
> I note relatedly, that one of us here has expressed a wish to do some of their code as near to using base R as possible rather than jump right away into the tidyverse. 

Just to use read_csv when base R has read.csv. The OP is reading data 
from the internet so read.csv is all that's needed.

And, related, it is not necessary to load a package to have access to 
its data sets. For instance,


data(CommuteAtlanta, package = "Lock5Data")


will load the data used for the example of section 1.1.

I can respect that even as, I, personally, prefer using whatever works 
for me faster and easier. At least, that is true when I am prototyping 
or doing something one-off. If the code turns out to be used a lot and 
is slow, I might reconsider. But, having said that, I suspect some 
packages may allow faster code than the basics. Of course, things like 
the built-in native pipe |> can change things so an altered package 
using a slower pipe may no longer ...

Thanks for the notes, they are always welcome.
> 
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
> Sent: Saturday, March 15, 2025 5:28 PM
> To: Kevin Zembower <kevin at zembower.org>; r-help at r-project.org
> Subject: Re: [R] What don't I understand about sample()?
> 
> Hello,
> 
> I have been following this thread and though answers have been given,
> some of them address R coding in general, not necessarily the sample()
> function. Here are some random notes I think the OP could use, prompted
> by the text linked to, chap3.pdf.
> 
> 1.
> Throughout the text, assignments use the equal sign instead of the left
> arrow. The left arrow is generally considered more idiomatic and there
> is an important diference beteewn he wo, see help("assignOps").
> 
> 
> time.mean = with(CommuteAtlanta, mean(Time))
> B = 1000
> n = nrow(CommuteAtlanta)
> 
> # This should be used, not the above.
> time.mean <- with(CommuteAtlanta, mean(Time))
> B <- 1000
> n <- nrow(CommuteAtlanta)
> 
> 
> 2.
> Systematic use of apply(., 1, mean).
> rowMeans (and colMeans) are much faster.
> 
> 
> boot.statistics <- apply(boot.samples, 1, mean)
> boot.statistics <- rowMeans(boot.samples)
> 
> 
> 3.
> The first confidence interval computation seems awkward. I had never
> seen this way of computing a CI95.
> Moreover, it's plain common sense to keep the results with the returned
> decimals and round for display purposes only.
> And the normal intervals are computed in a more usual way later in the
> text, see sections 1.2 and 1.3.
> 
> 
> me <- ceiling(10 * 2 * time.se)/10
> round(time.mean, 1) + c(-1, 1) * me
> 
> # Straightforward.
> normal_ci95 <- time.mean + c(-1, 1) * 2 * time.se
> normal_ci95
> round(normal_ci95, 1)
> 
> # section 1.2 , function boot.mean
> interval = mean(x) + c(-1,1)*2*se
> 
> # section 1.3
> with(students, mean(Height) + c(-1, 1) * 2 * sd(result))
> 
> 
> 
> 4.
> In section 1.2 there is a bootstrap function boot.mean().
> The function could be improved to let users pass a conf.level of their
> choice.
> And why force the function user to always have the plot displayed? Base
> functions hist() and barplot() have na argument 'plot' with default TRUE
> allowing the user to choose.
> 
> The following seems more user friendly.
> 
> 
> boot.mean <- function(x, B, binwidth = NULL, conf.level = 0.95, plot =
> TRUE) {
>     require(ggplot2)
>     n <- length(x)
>     boot.samples <- matrix( sample(x, size = n*B, replace = TRUE), B, n)
>     boot.statistics <- rowMeans(boot.samples)
>     se <- sd(boot.statistics)
>     if ( is.null(binwidth) )
>       binwidth <- diff(range(boot.statistics))/30
> 
>     p <- ggplot(data.frame(x = boot.statistics), aes(x = x)) +
>       geom_histogram(aes(y = ..density..),binwidth = binwidth) +
>       geom_density(color = "red")
> 
>     alpha <- 1 - (1 - conf.level)/2
>     interval <- mean(x) + c(-1, 1) * qnorm(alpha) * se
> 
>     if(plot) {
>       plot(p)
>     }
> 
>     list(boot.statistics = boot.statistics, interval = interval, se = se,
> plot = p)
> }
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> 
> ?s 17:28 de 15/03/2025, Kevin Zembower via R-help escreveu:
>> Hi, Richard, thanks for replying. I should have mentioned the third
>> edition, which we're using. The data file didn't change between the
>> second and third editions, and the data on Body Mass Gain was the same
>> as in the first edition, although the first edition data file contained
>> additional variables.
>>
>> According to my text, the BMGain was measured in grams. Thanks for
>> pointing out that my statement of the problem lacked crucial
>> information.
>>
>> The matrix in my example comes from an example in
>> https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf, where the author
>> created a bootstrap example with a matrix that consisted of one row for
>> every sample in the bootstrap, and one column for each mean in the
>> original data. This allowed him to find the mean for each row to create
>> the bootstrap statistics.
>>
>> The only need for the tidyverse is to use the read_csv() function. I'm
>> regrettably lazy in not determining which of the multiple functions in
>> the tidyverse library loads read_csv(), and just using that one.
>>
>> Thanks, again, for helping me to further understand R and this problem.
>>
>> -Kevin
>>
>> On Sat, 2025-03-15 at 12:00 +0100, r-help-request at r-project.org wrote:
>>> Not having the book (and which of the three editions are you using?),
>>> I downloaded the data and played with it for a bit.
>>> dotchart() showed the Dark and Light conditions looked quite
>>> different, but also showed that there are not very many cases.
>>> After trying t.test, it occurred to me that I did not know whether
>>> "BMGain" means gain in *grams* or gain in *percent*.
>>> Reflection told me that for a growth experiment, percent made more
>>> sense, which reminded my of one of my first
>>> student advising experiences, where I said "never give the computer
>>> percentages; let IT calculate the percentages
>>> from the baseline and outcome, because once you've thrown away
>>> information, the computer can't magically get it back."
>>> In particular, in the real world I'd be worried about the possibility
>>> that there was some confounding going on, so I would
>>> much rather have initial weight and final weight as variables.
>>> If BMGain is an absolute measure, the p value for a t test is teeny
>>> tiny.
>>> If BMGain is a percentage, the p value for a sensible t test is about
>>> 0.03.
>>>
>>> A permutation test went like this.
>>> is.light <- d$Group == "Light"
>>> is.dark <- d$Group == "Dark"
>>> score <- function (g) mean(g[is.light]) - mean(g[is.dark])
>>> base.score <- score(d$BMGain)
>>> perm.scores <- sapply(1:997, function (i) score(sample(d$BMGain)))
>>> sum(perm.scores >= base.score) / length(perm.scores)
>>>
>>> I don't actually see where matrix() comes into it, still less
>>> anything
>>> in the tidyverse.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From r@oknz @end|ng |rom gm@||@com  Sun Mar 16 12:52:46 2025
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 17 Mar 2025 00:52:46 +1300
Subject: [R] What don't I understand about sample()?
In-Reply-To: <012401db962f$12376090$36a621b0$@gmail.com>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org>
 <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
 <003d01db95d3$6189cae0$249d60a0$@gmail.com>
 <CABcYAdKC9uKyBfGDRKWU7JozTA9i1=2sdePwABVmhNY=3WnRpQ@mail.gmail.com>
 <012401db962f$12376090$36a621b0$@gmail.com>
Message-ID: <CABcYAdKXv9CZV-JK1--7=Ckskfu9F+2Bs58o-gv9J3gdOTrbtA@mail.gmail.com>

I think you think I mistook read_csv for read.csv.  Not so.  The point
was that base R with no additional packages loaded already contains a
CSV reader which is entirely adequate for the task at hand.  When you
are already struggling with the basics of a system (like how often and
when arguments are evaluated), I think it's wisests to stick with
basic tools.  When they taught me carpentry at school, they had me on
chisels before getting to lathes (and in fact never did get to lathes
at my school).

Sure, R isn't perfect.  But whenever I open the SAS manuals I remember
that things could be much worse.

On Sun, 16 Mar 2025 at 17:51, <avi.e.gross at gmail.com> wrote:
>
> Richard,
>
> The function with a period as a separator that you cite, read.csv, is part of normal base R.
>
> We have been discussing a different function named just a tad different that uses an underscore as a separator, read_csv that is similar but has some changes in how it works and the options supported and is considered part of the tidyverse grouping of packages and can also be gotten more compactly by importing package "readr" ...
>
> The OP, for reasons of their own, wanted to use read_csv and did not want or need anything else in the related packages.
>
> Of course, nobody is required to use other packages, albeit, as you noted, many packages you may choose to use have some dependencies on others you don't.
>
> Like many good things, added functionality available to you does add complexity and room for failures. But when a package is useful enough to be very useful, it can develop enough momentum that some functionality might well be a good idea to move into base R. As an example I already mentioned, of the various pipe implementations, a version has been added to base R and I suspect many older packages, including in the tidyverse, can adjust their code in new releases to use it but with CARE. Anyone still using older versions of R will experience failures in such a scenario.
>
> Luckily, many uses within a package are likely to be safe if done properly. Can anyone share if any such methods are in use?
>
> I mean, as an example, could a package early on check if the R version being used is later than the introduction, or some other way to check if a |> operation is supported? Could they then somehow introduce an operator that is either bound to |> or perhaps %>% and use that in any places in the code where both work the same, and only use the magrittr pipe when doing something it does differently such as needing to use a period to specify which argument in a function is receiving the pipelined data.
>
> There are programs people want to keep frozen so they only use the versions of R and packages that existed at some moment so you avoid some inevitable conflicts. So, I despair that older versions of R may stick around way too long and break with any newer packages.
>
> But languages cannot remain totally static or chances are people will move on to newer languages that offer things they want. Then again, there seem to still be COBOL programs out there.
>
> -----Original Message-----
> From: Richard O'Keefe <raoknz at gmail.com>
> Sent: Sunday, March 16, 2025 12:32 AM
> To: avi.e.gross at gmail.com
> Cc: Kevin Zembower <kevin at zembower.org>; r-help at r-project.org
> Subject: Re: [R] What don't I understand about sample()?
>
> Rgui 4.4.3 on Windows.  When I start it up, read.csv is just *there*.
> I don't need to load any package to get it.
>
> I have three reasons for being very sparing in the packages I use.
> 1. It took me long enough to get my head around R.  More packages =
> more things to learn.  I *still* have major trouble grasping
> tidyverse, and as far as I can see it doesn't solve any problem that
> *I* have.  I install a package only when I have a specific need for
> something it does, like spatial statistics.  (And yet I have hundreds
> of packages installed, because packages depend on other packages.)
> 2. Everything changes, and they don't all change coherently.  A
> package I've used for years may not be available in the next release.
> This is not a theoretical possibility; it has happened to me often.
> "If I don't use it I can't lose it."  Sometimes things break because
> something else on the system (tcl/tk, or the C or Fortran compiler)
> has changed.  I'm tired of things breaking because the C or Fortran compiler
> is now stricter.
> 3. The universe of R packages is vast and constantly expanding.  This
> makes it *impossible* for anyone to test every possible combination.  I
> used to teach software engineering, and we had a slogan "if it isn't
> tested it doesn't work".  Base R plus package X?  Probably tested.
> Base R plus package Y?  Probably tested.  Base R plus X plus Y?
> Not unless X requires Y or Y requires X.
>
> There is also the didactic point that the more you work with base R
> the better you will understand it, which you will need to understand
> other things like tidyverse.  It's like mastering the alphabet before you
> learn shorthand.
>
>
> On Sun, 16 Mar 2025 at 06:55, <avi.e.gross at gmail.com> wrote:
> >
> > Kevin & Richard, and of course everyone,
> >
> > As the main topic here is not the tidyverse, I will mention the perils of loading in more than needed in general.
> >
> > If you want to use one or a very few functions, it can be more efficient and safe to load exactly what is needed. In the case of wanting to use read_csv(), I think this suffices:
> >
> > library(readr)
> >
> > If you instead use:
> >
> > library(tidyverse)
> >
> > You load a varying number of packages (it may change) including some like lubridate or forcats or ggplot2 that you may not be even thinking of using or never heard of.
> >
> > The bigger problem is shadowing that happens. For example, you may be getting warning messages like:
> >
> > ? dplyr::filter() masks stats::filter()
> > ? dplyr::lag()    masks stats::lag()
> >
> > This can interfere with some other package you had already loaded unless it uses a notation like mypackage::filter(...) in their code to avoid being easily replaced but even then, if you yourself called what you though was filter() from base R or some package, you have a problem unless you invoke it like base::filter(...)
> >
> > The order packages like this load can matter as well as when you define a function of your own. So, it may be worth some effort to zoom in and call exactly what you need and only when you need it. I have seen code that only needs a package in rare conditions and only loads the package in one branch of an IF statement right before using in.
> > .
> > Packages can also be unloaded after use.
> >
> > From what you describe, none of this is crucially important as you are using R for your own purposes in your own RMarkDown file that you may not be distributing. And, when I write programs where I keep adjusting and adding things from the tidyverse, it is indeed much easier to just get the grouping on top and forget about it. That is, until I decide to do something with functional programming that uses reduce/filter/map... and have an odd error!
> >
> >
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Zembower via R-help
> > Sent: Saturday, March 15, 2025 1:29 PM
> > To: r-help at r-project.org
> > Subject: Re: [R] What don't I understand about sample()?
> >
> > Hi, Richard, thanks for replying. I should have mentioned the third
> > edition, which we're using. The data file didn't change between the
> > second and third editions, and the data on Body Mass Gain was the same
> > as in the first edition, although the first edition data file contained
> > additional variables.
> >
> > According to my text, the BMGain was measured in grams. Thanks for
> > pointing out that my statement of the problem lacked crucial
> > information.
> >
> > The matrix in my example comes from an example in
> > https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf, where the author
> > created a bootstrap example with a matrix that consisted of one row for
> > every sample in the bootstrap, and one column for each mean in the
> > original data. This allowed him to find the mean for each row to create
> > the bootstrap statistics.
> >
> > The only need for the tidyverse is to use the read_csv() function. I'm
> > regrettably lazy in not determining which of the multiple functions in
> > the tidyverse library loads read_csv(), and just using that one.
> >
> > Thanks, again, for helping me to further understand R and this problem.
> >
> > -Kevin
> >
> > On Sat, 2025-03-15 at 12:00 +0100, r-help-request at r-project.org wrote:
> > > Not having the book (and which of the three editions are you using?),
> > > I downloaded the data and played with it for a bit.
> > > dotchart() showed the Dark and Light conditions looked quite
> > > different, but also showed that there are not very many cases.
> > > After trying t.test, it occurred to me that I did not know whether
> > > "BMGain" means gain in *grams* or gain in *percent*.
> > > Reflection told me that for a growth experiment, percent made more
> > > sense, which reminded my of one of my first
> > > student advising experiences, where I said "never give the computer
> > > percentages; let IT calculate the percentages
> > > from the baseline and outcome, because once you've thrown away
> > > information, the computer can't magically get it back."
> > > In particular, in the real world I'd be worried about the possibility
> > > that there was some confounding going on, so I would
> > > much rather have initial weight and final weight as variables.
> > > If BMGain is an absolute measure, the p value for a t test is teeny
> > > tiny.
> > > If BMGain is a percentage, the p value for a sensible t test is about
> > > 0.03.
> > >
> > > A permutation test went like this.
> > > is.light <- d$Group == "Light"
> > > is.dark <- d$Group == "Dark"
> > > score <- function (g) mean(g[is.light]) - mean(g[is.dark])
> > > base.score <- score(d$BMGain)
> > > perm.scores <- sapply(1:997, function (i) score(sample(d$BMGain)))
> > > sum(perm.scores >= base.score) / length(perm.scores)
> > >
> > > I don't actually see where matrix() comes into it, still less
> > > anything
> > > in the tidyverse.
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From @vi@e@gross m@iii@g oii gm@ii@com  Sun Mar 16 20:52:07 2025
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sun, 16 Mar 2025 15:52:07 -0400
Subject: [R] What don't I understand about sample()?
In-Reply-To: <CABcYAdKXv9CZV-JK1--7=Ckskfu9F+2Bs58o-gv9J3gdOTrbtA@mail.gmail.com>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org>
 <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
 <003d01db95d3$6189cae0$249d60a0$@gmail.com>
 <CABcYAdKC9uKyBfGDRKWU7JozTA9i1=2sdePwABVmhNY=3WnRpQ@mail.gmail.com>
 <012401db962f$12376090$36a621b0$@gmail.com>
 <CABcYAdKXv9CZV-JK1--7=Ckskfu9F+2Bs58o-gv9J3gdOTrbtA@mail.gmail.com>
Message-ID: <004401db96ac$e62c3600$b284a200$@gmail.com>

Thanks for the clarification, Richard, as I clearly made the wrong guess of what you meant.

Your idea or objection was that you see the included read.csv function as adequate and see no incentive to use read_csv, and especially not if that is the only function being used. I only partially agree.

As usual, I look at things from multiple overlapping perspectives.

There are actually more ways to read in a CSV or other such data files including fread from data.table and another called feather and other base functions. Some people choose ONE and use it whenever possible and your choice might be the base version and mine would not be. 

So, one perspective is that the base version is in some sense pre-loaded and any other must be pre-downloaded and added with a library statement. I am not sure how much that costs or if the base version is also only partially preloaded and gotten only as needed. But it can be a valid concern, especially as some people write defensive code so that if it is not already installed, they first fetch it.

Another perspective, especially for larger files, is speed. One article I have suggests the base version is quite SLOW. 

https://www.r-bloggers.com/2017/04/fast-data-loading-from-files-to-r/

But that was in 2017, and using such concerns, you may be better off with data.table ...

Another issue is that some people have found it handy to deal with tibbles rather than unenhanced data.frames and if you read it in using the base, you may end up converting it later so the underscore version saves a small step. The OP clearly does not need this as no other tidyverse functions are used. Others may care.

But related to this are things like not converting strings to factors by default or play around with column names. It can be time consuming to read in data and then use multiple commands to change it to the way you want it, such as undoing the factors (albeit you can just set the default in the base too) or converting a column it guessed was integer to Boolean and so on.

And I note I have used other features that I like and base does not support. But, again, if the OP does not have any plans on using any such features or defaults and is reading fairly small amounts of data and running it once, there is no special reason to make it worth leaving the base. If they may later want to use additional tidyverse functionality, switching to use this by default may be wise. 

My philosophy is to keep thing as simple as reasonable but no simpler than reasonable. In programming languages, it is to use a simple consistent set of tools that gets me what I want with accuracy and thus it can be simpler to use the tidyverse a lot as my default. To each their own.

-----Original Message-----
From: Richard O'Keefe <raoknz at gmail.com> 
Sent: Sunday, March 16, 2025 7:53 AM
To: avi.e.gross at gmail.com
Cc: Kevin Zembower <kevin at zembower.org>; r-help at r-project.org
Subject: Re: [R] What don't I understand about sample()?

I think you think I mistook read_csv for read.csv.  Not so.  The point
was that base R with no additional packages loaded already contains a
CSV reader which is entirely adequate for the task at hand.  When you
are already struggling with the basics of a system (like how often and
when arguments are evaluated), I think it's wisests to stick with
basic tools.  When they taught me carpentry at school, they had me on
chisels before getting to lathes (and in fact never did get to lathes
at my school).

Sure, R isn't perfect.  But whenever I open the SAS manuals I remember
that things could be much worse.

On Sun, 16 Mar 2025 at 17:51, <avi.e.gross at gmail.com> wrote:
>
> Richard,
>
> The function with a period as a separator that you cite, read.csv, is part of normal base R.
>
> We have been discussing a different function named just a tad different that uses an underscore as a separator, read_csv that is similar but has some changes in how it works and the options supported and is considered part of the tidyverse grouping of packages and can also be gotten more compactly by importing package "readr" ...
>
> The OP, for reasons of their own, wanted to use read_csv and did not want or need anything else in the related packages.
>
> Of course, nobody is required to use other packages, albeit, as you noted, many packages you may choose to use have some dependencies on others you don't.
>
> Like many good things, added functionality available to you does add complexity and room for failures. But when a package is useful enough to be very useful, it can develop enough momentum that some functionality might well be a good idea to move into base R. As an example I already mentioned, of the various pipe implementations, a version has been added to base R and I suspect many older packages, including in the tidyverse, can adjust their code in new releases to use it but with CARE. Anyone still using older versions of R will experience failures in such a scenario.
>
> Luckily, many uses within a package are likely to be safe if done properly. Can anyone share if any such methods are in use?
>
> I mean, as an example, could a package early on check if the R version being used is later than the introduction, or some other way to check if a |> operation is supported? Could they then somehow introduce an operator that is either bound to |> or perhaps %>% and use that in any places in the code where both work the same, and only use the magrittr pipe when doing something it does differently such as needing to use a period to specify which argument in a function is receiving the pipelined data.
>
> There are programs people want to keep frozen so they only use the versions of R and packages that existed at some moment so you avoid some inevitable conflicts. So, I despair that older versions of R may stick around way too long and break with any newer packages.
>
> But languages cannot remain totally static or chances are people will move on to newer languages that offer things they want. Then again, there seem to still be COBOL programs out there.
>
> -----Original Message-----
> From: Richard O'Keefe <raoknz at gmail.com>
> Sent: Sunday, March 16, 2025 12:32 AM
> To: avi.e.gross at gmail.com
> Cc: Kevin Zembower <kevin at zembower.org>; r-help at r-project.org
> Subject: Re: [R] What don't I understand about sample()?
>
> Rgui 4.4.3 on Windows.  When I start it up, read.csv is just *there*.
> I don't need to load any package to get it.
>
> I have three reasons for being very sparing in the packages I use.
> 1. It took me long enough to get my head around R.  More packages =
> more things to learn.  I *still* have major trouble grasping
> tidyverse, and as far as I can see it doesn't solve any problem that
> *I* have.  I install a package only when I have a specific need for
> something it does, like spatial statistics.  (And yet I have hundreds
> of packages installed, because packages depend on other packages.)
> 2. Everything changes, and they don't all change coherently.  A
> package I've used for years may not be available in the next release.
> This is not a theoretical possibility; it has happened to me often.
> "If I don't use it I can't lose it."  Sometimes things break because
> something else on the system (tcl/tk, or the C or Fortran compiler)
> has changed.  I'm tired of things breaking because the C or Fortran compiler
> is now stricter.
> 3. The universe of R packages is vast and constantly expanding.  This
> makes it *impossible* for anyone to test every possible combination.  I
> used to teach software engineering, and we had a slogan "if it isn't
> tested it doesn't work".  Base R plus package X?  Probably tested.
> Base R plus package Y?  Probably tested.  Base R plus X plus Y?
> Not unless X requires Y or Y requires X.
>
> There is also the didactic point that the more you work with base R
> the better you will understand it, which you will need to understand
> other things like tidyverse.  It's like mastering the alphabet before you
> learn shorthand.
>
>
> On Sun, 16 Mar 2025 at 06:55, <avi.e.gross at gmail.com> wrote:
> >
> > Kevin & Richard, and of course everyone,
> >
> > As the main topic here is not the tidyverse, I will mention the perils of loading in more than needed in general.
> >
> > If you want to use one or a very few functions, it can be more efficient and safe to load exactly what is needed. In the case of wanting to use read_csv(), I think this suffices:
> >
> > library(readr)
> >
> > If you instead use:
> >
> > library(tidyverse)
> >
> > You load a varying number of packages (it may change) including some like lubridate or forcats or ggplot2 that you may not be even thinking of using or never heard of.
> >
> > The bigger problem is shadowing that happens. For example, you may be getting warning messages like:
> >
> > ? dplyr::filter() masks stats::filter()
> > ? dplyr::lag()    masks stats::lag()
> >
> > This can interfere with some other package you had already loaded unless it uses a notation like mypackage::filter(...) in their code to avoid being easily replaced but even then, if you yourself called what you though was filter() from base R or some package, you have a problem unless you invoke it like base::filter(...)
> >
> > The order packages like this load can matter as well as when you define a function of your own. So, it may be worth some effort to zoom in and call exactly what you need and only when you need it. I have seen code that only needs a package in rare conditions and only loads the package in one branch of an IF statement right before using in.
> > .
> > Packages can also be unloaded after use.
> >
> > From what you describe, none of this is crucially important as you are using R for your own purposes in your own RMarkDown file that you may not be distributing. And, when I write programs where I keep adjusting and adding things from the tidyverse, it is indeed much easier to just get the grouping on top and forget about it. That is, until I decide to do something with functional programming that uses reduce/filter/map... and have an odd error!
> >
> >
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Zembower via R-help
> > Sent: Saturday, March 15, 2025 1:29 PM
> > To: r-help at r-project.org
> > Subject: Re: [R] What don't I understand about sample()?
> >
> > Hi, Richard, thanks for replying. I should have mentioned the third
> > edition, which we're using. The data file didn't change between the
> > second and third editions, and the data on Body Mass Gain was the same
> > as in the first edition, although the first edition data file contained
> > additional variables.
> >
> > According to my text, the BMGain was measured in grams. Thanks for
> > pointing out that my statement of the problem lacked crucial
> > information.
> >
> > The matrix in my example comes from an example in
> > https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf, where the author
> > created a bootstrap example with a matrix that consisted of one row for
> > every sample in the bootstrap, and one column for each mean in the
> > original data. This allowed him to find the mean for each row to create
> > the bootstrap statistics.
> >
> > The only need for the tidyverse is to use the read_csv() function. I'm
> > regrettably lazy in not determining which of the multiple functions in
> > the tidyverse library loads read_csv(), and just using that one.
> >
> > Thanks, again, for helping me to further understand R and this problem.
> >
> > -Kevin
> >
> > On Sat, 2025-03-15 at 12:00 +0100, r-help-request at r-project.org wrote:
> > > Not having the book (and which of the three editions are you using?),
> > > I downloaded the data and played with it for a bit.
> > > dotchart() showed the Dark and Light conditions looked quite
> > > different, but also showed that there are not very many cases.
> > > After trying t.test, it occurred to me that I did not know whether
> > > "BMGain" means gain in *grams* or gain in *percent*.
> > > Reflection told me that for a growth experiment, percent made more
> > > sense, which reminded my of one of my first
> > > student advising experiences, where I said "never give the computer
> > > percentages; let IT calculate the percentages
> > > from the baseline and outcome, because once you've thrown away
> > > information, the computer can't magically get it back."
> > > In particular, in the real world I'd be worried about the possibility
> > > that there was some confounding going on, so I would
> > > much rather have initial weight and final weight as variables.
> > > If BMGain is an absolute measure, the p value for a t test is teeny
> > > tiny.
> > > If BMGain is a percentage, the p value for a sensible t test is about
> > > 0.03.
> > >
> > > A permutation test went like this.
> > > is.light <- d$Group == "Light"
> > > is.dark <- d$Group == "Dark"
> > > score <- function (g) mean(g[is.light]) - mean(g[is.dark])
> > > base.score <- score(d$BMGain)
> > > perm.scores <- sapply(1:997, function (i) score(sample(d$BMGain)))
> > > sum(perm.scores >= base.score) / length(perm.scores)
> > >
> > > I don't actually see where matrix() comes into it, still less
> > > anything
> > > in the tidyverse.
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From ro||turner @end|ng |rom po@teo@net  Sun Mar 16 20:58:00 2025
From: ro||turner @end|ng |rom po@teo@net (Rolf Turner)
Date: Sun, 16 Mar 2025 19:58:00 +0000
Subject: [R] What don't I understand about sample()?
In-Reply-To: <CABcYAdKXv9CZV-JK1--7=Ckskfu9F+2Bs58o-gv9J3gdOTrbtA@mail.gmail.com>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org>
 <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
 <003d01db95d3$6189cae0$249d60a0$@gmail.com>
 <CABcYAdKC9uKyBfGDRKWU7JozTA9i1=2sdePwABVmhNY=3WnRpQ@mail.gmail.com>
 <012401db962f$12376090$36a621b0$@gmail.com>
 <CABcYAdKXv9CZV-JK1--7=Ckskfu9F+2Bs58o-gv9J3gdOTrbtA@mail.gmail.com>
Message-ID: <20250317085800.3953f27c@new-hp>


On Mon, 17 Mar 2025 00:52:46 +1300
"Richard O'Keefe" <raoknz at gmail.com> wrote:

<SNIP>

> Sure, R isn't perfect.  But whenever I open the SAS manuals I remember
> that things could be much worse.

<SNIP>

Fortune nomination!

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Stats. Dep't. (secretaries) phone:
         +64-9-373-7599 ext. 89622
Home phone: +64-9-480-4619


From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Sun Mar 16 21:28:49 2025
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Sun, 16 Mar 2025 20:28:49 +0000
Subject: [R] MacPorts install of data.table lacks openmp support
Message-ID: <99D4F0C8-BF67-4B2E-B9F3-903149CB4151@hotmail.com>


In the past I have been able to install data.table with openmp support.
Recently I upgraded to Sequoia and needed to reinstall R and various
packages.  My new install of data.table lacks openmp support.  Has
anyone been able to use MacPorts to install data.table with openmp
support?

I have an Intel mac mini with Sequoia 15.3.2
I installed gfortran 14.2 using package available at
https://mac.r-project.org.  Then I installed openmp support (17.0.6) using
package available at https://mac.r-project.org/openmp/.  liblzma, pcre2,
and bzip2 were installed by MacPorts. I do not have a Makevars file.
Without Makevars file, in the past I had successfully installed
data.table with openmp support.   

Thanks,
Naresh

~ $ which gfortran 
/usr/local/bin/gfortran
~ $ gfortran --version
GNU Fortran (GCC) 14.2.0
~ $ clang --version
Apple clang version 16.0.0 (clang-1600.0.26.6)
Target: x86_64-apple-darwin24.3.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin
~ $ which clang 
/usr/bin/clang
~ $ ls /usr/local/lib/libomp.dylib 
/usr/local/lib/libomp.dylib
~ $ ls /usr/local/include/omp-tools.h 
/usr/local/include/omp-tools.h
~ $ ls /usr/local/include/omp.h 
/usr/local/include/omp.h
~ $ ls /usr/local/include/ompt.h 
/usr/local/include/ompt.h
~ $ port installed xz*
The following ports are currently installed:
  xz @5.6.4_0 (active)
  xz-bootstrap @5.6.4_0 (active)
~ $ port installed pcre2 bzip2
The following ports are currently installed:
  bzip2 @1.0.8_0 (active)
  pcre2 @10.45_0 (active)
~ $ export $LDFLAGS
declare -x CLICOLOR="1"
declare -x COLUMNS="92"
declare -x DISPLAY="Macmini.fios-router.home"
declare -x EDITOR="/Applications/MacPorts/Emacs.app/Contents/MacOS/Emacs"
declare -x EMAIL="naresh_gurbuxani at hotmail.com"
declare -x HOME="/Users/nareshgurbuxani"
declare -x INFOPATH=":/usr/local/texlive/2024/texmf-dist/doc/info"
declare -x INSIDE_EMACS="29.4,comint"
declare -x LANG="en_US.UTF-8"
declare -x LOGNAME="nareshgurbuxani"
declare -x LSCOLORS="GxFxCxDxBxegedabagaced"
declare -x MANPATH=":/usr/local/texlive/2024/texmf-dist/doc/man"
declare -x NAME="Naresh Gurbuxani"
declare -x OLDPWD
declare -x PATH="/usr/local/texlive/2024/bin/universal-darwin:/opt/local/libexec/gnubin:/opt/local/bin:/opt/local/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/usr/local/texlive/2024/bin/universal-darwin"
declare -x PS1="\\W \$ "
declare -x PWD="/Users/nareshgurbuxani"
declare -x SHELL="/bin/bash"
declare -x SHLVL="2"
declare -x SSH_AUTH_SOCK="/private/tmp/com.apple.launchd.Wok8stg6Ex/Listeners"
declare -x TERM="dumb"
declare -x TERMCAP=""
declare -x TERM_PROGRAM="Apple_Terminal"
declare -x TERM_PROGRAM_VERSION="455"
declare -x TERM_SESSION_ID="32510F68-CEC8-48D1-9C02-4A8B7B6F18D2"
declare -x TMPDIR="/var/folders/nb/2vppcjgd19l_h9brvzgdjcm40000gn/T/"
declare -x USER="nareshgurbuxani"
declare -x XPC_FLAGS="0x0"
declare -x XPC_SERVICE_NAME="0"
declare -x __CFBundleIdentifier="com.apple.Terminal"
declare -x __CF_USER_TEXT_ENCODING="0x1F5:0x0:0x0"
~ $ xcode-select --version
xcode-select version 2409.
~ $ port installed R
The following ports are currently installed:
  R @4.4.3_0+aqua+builtin_lapack+cairo+gcc14+openmp+tcltk+x11 (active)
~ $ Rscript -e 'sessionInfo()'
R version 4.4.3 (2025-02-28)
Platform: x86_64-apple-darwin24.3.0
Running under: macOS Sequoia 15.3.2

Matrix products: default
BLAS:   /opt/local/Library/Frameworks/R.framework/Versions/4.4/Resources/lib/libRblas.dylib 
LAPACK: /opt/local/Library/Frameworks/R.framework/Versions/4.4/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: America/New_York
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_4.4.3
~ $


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Mar 17 00:04:10 2025
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 16 Mar 2025 16:04:10 -0700
Subject: [R] What don't I understand about sample()?
In-Reply-To: <004401db96ac$e62c3600$b284a200$@gmail.com>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org>
 <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
 <003d01db95d3$6189cae0$249d60a0$@gmail.com>
 <CABcYAdKC9uKyBfGDRKWU7JozTA9i1=2sdePwABVmhNY=3WnRpQ@mail.gmail.com>
 <012401db962f$12376090$36a621b0$@gmail.com>
 <CABcYAdKXv9CZV-JK1--7=Ckskfu9F+2Bs58o-gv9J3gdOTrbtA@mail.gmail.com>
 <004401db96ac$e62c3600$b284a200$@gmail.com>
Message-ID: <9FE006C1-C7D4-4FFC-94EF-7DB0818737DF@dcn.davis.ca.us>

The original question was about sample, a base R function. Dragging in tidyverse along the way could be regarded as complicating the question unnecessarily, but in some cases there can be undesirable or simply unexpected interactions between functions drawn from different packages. Such complications can turn out to be intrinsic to the question being posed, in which case it will be necessary to have things in their example just as they are in the original environment. In this case that does not seem to be the case... and OP may get fewer responses to their question because some people don't keep tidyverse installed and may not want to add it just to answer a question... leading to fewer responses. In some cases no one may respond, and OP would be left with no help.

In this case it all turned out fine.. so this debate is getting stale, and there are reasons why including or excluding tidyverse might have been better. But in general, building a true Minimum Reproducible Example (MRE) will help communicate most clearly (consider using the reprex package to verify the example) and minimizing unnecessary packages (reprex can help paring things down) may avoid the dreaded "crickets" on the mailing list in the future. And sometimes building an MRE will help OP answer their own question.

On March 16, 2025 12:52:07 PM PDT, avi.e.gross at gmail.com wrote:
>Thanks for the clarification, Richard, as I clearly made the wrong guess of what you meant.
>
>Your idea or objection was that you see the included read.csv function as adequate and see no incentive to use read_csv, and especially not if that is the only function being used. I only partially agree.
>
>As usual, I look at things from multiple overlapping perspectives.
>
>There are actually more ways to read in a CSV or other such data files including fread from data.table and another called feather and other base functions. Some people choose ONE and use it whenever possible and your choice might be the base version and mine would not be. 
>
>So, one perspective is that the base version is in some sense pre-loaded and any other must be pre-downloaded and added with a library statement. I am not sure how much that costs or if the base version is also only partially preloaded and gotten only as needed. But it can be a valid concern, especially as some people write defensive code so that if it is not already installed, they first fetch it.
>
>Another perspective, especially for larger files, is speed. One article I have suggests the base version is quite SLOW. 
>
>https://www.r-bloggers.com/2017/04/fast-data-loading-from-files-to-r/
>
>But that was in 2017, and using such concerns, you may be better off with data.table ...
>
>Another issue is that some people have found it handy to deal with tibbles rather than unenhanced data.frames and if you read it in using the base, you may end up converting it later so the underscore version saves a small step. The OP clearly does not need this as no other tidyverse functions are used. Others may care.
>
>But related to this are things like not converting strings to factors by default or play around with column names. It can be time consuming to read in data and then use multiple commands to change it to the way you want it, such as undoing the factors (albeit you can just set the default in the base too) or converting a column it guessed was integer to Boolean and so on.
>
>And I note I have used other features that I like and base does not support. But, again, if the OP does not have any plans on using any such features or defaults and is reading fairly small amounts of data and running it once, there is no special reason to make it worth leaving the base. If they may later want to use additional tidyverse functionality, switching to use this by default may be wise. 
>
>My philosophy is to keep thing as simple as reasonable but no simpler than reasonable. In programming languages, it is to use a simple consistent set of tools that gets me what I want with accuracy and thus it can be simpler to use the tidyverse a lot as my default. To each their own.
>
>-----Original Message-----
>From: Richard O'Keefe <raoknz at gmail.com> 
>Sent: Sunday, March 16, 2025 7:53 AM
>To: avi.e.gross at gmail.com
>Cc: Kevin Zembower <kevin at zembower.org>; r-help at r-project.org
>Subject: Re: [R] What don't I understand about sample()?
>
>I think you think I mistook read_csv for read.csv.  Not so.  The point
>was that base R with no additional packages loaded already contains a
>CSV reader which is entirely adequate for the task at hand.  When you
>are already struggling with the basics of a system (like how often and
>when arguments are evaluated), I think it's wisests to stick with
>basic tools.  When they taught me carpentry at school, they had me on
>chisels before getting to lathes (and in fact never did get to lathes
>at my school).
>
>Sure, R isn't perfect.  But whenever I open the SAS manuals I remember
>that things could be much worse.
>
>On Sun, 16 Mar 2025 at 17:51, <avi.e.gross at gmail.com> wrote:
>>
>> Richard,
>>
>> The function with a period as a separator that you cite, read.csv, is part of normal base R.
>>
>> We have been discussing a different function named just a tad different that uses an underscore as a separator, read_csv that is similar but has some changes in how it works and the options supported and is considered part of the tidyverse grouping of packages and can also be gotten more compactly by importing package "readr" ...
>>
>> The OP, for reasons of their own, wanted to use read_csv and did not want or need anything else in the related packages.
>>
>> Of course, nobody is required to use other packages, albeit, as you noted, many packages you may choose to use have some dependencies on others you don't.
>>
>> Like many good things, added functionality available to you does add complexity and room for failures. But when a package is useful enough to be very useful, it can develop enough momentum that some functionality might well be a good idea to move into base R. As an example I already mentioned, of the various pipe implementations, a version has been added to base R and I suspect many older packages, including in the tidyverse, can adjust their code in new releases to use it but with CARE. Anyone still using older versions of R will experience failures in such a scenario.
>>
>> Luckily, many uses within a package are likely to be safe if done properly. Can anyone share if any such methods are in use?
>>
>> I mean, as an example, could a package early on check if the R version being used is later than the introduction, or some other way to check if a |> operation is supported? Could they then somehow introduce an operator that is either bound to |> or perhaps %>% and use that in any places in the code where both work the same, and only use the magrittr pipe when doing something it does differently such as needing to use a period to specify which argument in a function is receiving the pipelined data.
>>
>> There are programs people want to keep frozen so they only use the versions of R and packages that existed at some moment so you avoid some inevitable conflicts. So, I despair that older versions of R may stick around way too long and break with any newer packages.
>>
>> But languages cannot remain totally static or chances are people will move on to newer languages that offer things they want. Then again, there seem to still be COBOL programs out there.
>>
>> -----Original Message-----
>> From: Richard O'Keefe <raoknz at gmail.com>
>> Sent: Sunday, March 16, 2025 12:32 AM
>> To: avi.e.gross at gmail.com
>> Cc: Kevin Zembower <kevin at zembower.org>; r-help at r-project.org
>> Subject: Re: [R] What don't I understand about sample()?
>>
>> Rgui 4.4.3 on Windows.  When I start it up, read.csv is just *there*.
>> I don't need to load any package to get it.
>>
>> I have three reasons for being very sparing in the packages I use.
>> 1. It took me long enough to get my head around R.  More packages =
>> more things to learn.  I *still* have major trouble grasping
>> tidyverse, and as far as I can see it doesn't solve any problem that
>> *I* have.  I install a package only when I have a specific need for
>> something it does, like spatial statistics.  (And yet I have hundreds
>> of packages installed, because packages depend on other packages.)
>> 2. Everything changes, and they don't all change coherently.  A
>> package I've used for years may not be available in the next release.
>> This is not a theoretical possibility; it has happened to me often.
>> "If I don't use it I can't lose it."  Sometimes things break because
>> something else on the system (tcl/tk, or the C or Fortran compiler)
>> has changed.  I'm tired of things breaking because the C or Fortran compiler
>> is now stricter.
>> 3. The universe of R packages is vast and constantly expanding.  This
>> makes it *impossible* for anyone to test every possible combination.  I
>> used to teach software engineering, and we had a slogan "if it isn't
>> tested it doesn't work".  Base R plus package X?  Probably tested.
>> Base R plus package Y?  Probably tested.  Base R plus X plus Y?
>> Not unless X requires Y or Y requires X.
>>
>> There is also the didactic point that the more you work with base R
>> the better you will understand it, which you will need to understand
>> other things like tidyverse.  It's like mastering the alphabet before you
>> learn shorthand.
>>
>>
>> On Sun, 16 Mar 2025 at 06:55, <avi.e.gross at gmail.com> wrote:
>> >
>> > Kevin & Richard, and of course everyone,
>> >
>> > As the main topic here is not the tidyverse, I will mention the perils of loading in more than needed in general.
>> >
>> > If you want to use one or a very few functions, it can be more efficient and safe to load exactly what is needed. In the case of wanting to use read_csv(), I think this suffices:
>> >
>> > library(readr)
>> >
>> > If you instead use:
>> >
>> > library(tidyverse)
>> >
>> > You load a varying number of packages (it may change) including some like lubridate or forcats or ggplot2 that you may not be even thinking of using or never heard of.
>> >
>> > The bigger problem is shadowing that happens. For example, you may be getting warning messages like:
>> >
>> > ? dplyr::filter() masks stats::filter()
>> > ? dplyr::lag()    masks stats::lag()
>> >
>> > This can interfere with some other package you had already loaded unless it uses a notation like mypackage::filter(...) in their code to avoid being easily replaced but even then, if you yourself called what you though was filter() from base R or some package, you have a problem unless you invoke it like base::filter(...)
>> >
>> > The order packages like this load can matter as well as when you define a function of your own. So, it may be worth some effort to zoom in and call exactly what you need and only when you need it. I have seen code that only needs a package in rare conditions and only loads the package in one branch of an IF statement right before using in.
>> > .
>> > Packages can also be unloaded after use.
>> >
>> > From what you describe, none of this is crucially important as you are using R for your own purposes in your own RMarkDown file that you may not be distributing. And, when I write programs where I keep adjusting and adding things from the tidyverse, it is indeed much easier to just get the grouping on top and forget about it. That is, until I decide to do something with functional programming that uses reduce/filter/map... and have an odd error!
>> >
>> >
>> > -----Original Message-----
>> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Zembower via R-help
>> > Sent: Saturday, March 15, 2025 1:29 PM
>> > To: r-help at r-project.org
>> > Subject: Re: [R] What don't I understand about sample()?
>> >
>> > Hi, Richard, thanks for replying. I should have mentioned the third
>> > edition, which we're using. The data file didn't change between the
>> > second and third editions, and the data on Body Mass Gain was the same
>> > as in the first edition, although the first edition data file contained
>> > additional variables.
>> >
>> > According to my text, the BMGain was measured in grams. Thanks for
>> > pointing out that my statement of the problem lacked crucial
>> > information.
>> >
>> > The matrix in my example comes from an example in
>> > https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf, where the author
>> > created a bootstrap example with a matrix that consisted of one row for
>> > every sample in the bootstrap, and one column for each mean in the
>> > original data. This allowed him to find the mean for each row to create
>> > the bootstrap statistics.
>> >
>> > The only need for the tidyverse is to use the read_csv() function. I'm
>> > regrettably lazy in not determining which of the multiple functions in
>> > the tidyverse library loads read_csv(), and just using that one.
>> >
>> > Thanks, again, for helping me to further understand R and this problem.
>> >
>> > -Kevin
>> >
>> > On Sat, 2025-03-15 at 12:00 +0100, r-help-request at r-project.org wrote:
>> > > Not having the book (and which of the three editions are you using?),
>> > > I downloaded the data and played with it for a bit.
>> > > dotchart() showed the Dark and Light conditions looked quite
>> > > different, but also showed that there are not very many cases.
>> > > After trying t.test, it occurred to me that I did not know whether
>> > > "BMGain" means gain in *grams* or gain in *percent*.
>> > > Reflection told me that for a growth experiment, percent made more
>> > > sense, which reminded my of one of my first
>> > > student advising experiences, where I said "never give the computer
>> > > percentages; let IT calculate the percentages
>> > > from the baseline and outcome, because once you've thrown away
>> > > information, the computer can't magically get it back."
>> > > In particular, in the real world I'd be worried about the possibility
>> > > that there was some confounding going on, so I would
>> > > much rather have initial weight and final weight as variables.
>> > > If BMGain is an absolute measure, the p value for a t test is teeny
>> > > tiny.
>> > > If BMGain is a percentage, the p value for a sensible t test is about
>> > > 0.03.
>> > >
>> > > A permutation test went like this.
>> > > is.light <- d$Group == "Light"
>> > > is.dark <- d$Group == "Dark"
>> > > score <- function (g) mean(g[is.light]) - mean(g[is.dark])
>> > > base.score <- score(d$BMGain)
>> > > perm.scores <- sapply(1:997, function (i) score(sample(d$BMGain)))
>> > > sum(perm.scores >= base.score) / length(perm.scores)
>> > >
>> > > I don't actually see where matrix() comes into it, still less
>> > > anything
>> > > in the tidyverse.
>> > >
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide https://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From |kry|ov @end|ng |rom d|@root@org  Mon Mar 17 10:37:53 2025
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 17 Mar 2025 12:37:53 +0300
Subject: [R] MacPorts install of data.table lacks openmp support
In-Reply-To: <99D4F0C8-BF67-4B2E-B9F3-903149CB4151@hotmail.com>
References: <99D4F0C8-BF67-4B2E-B9F3-903149CB4151@hotmail.com>
Message-ID: <20250317123753.02b1b282@arachnoid>

Hello Naresh,

If you don't get a good answer here, consider asking later at
R-SIG-Mac at R-project.org.

? Sun, 16 Mar 2025 20:28:49 +0000
Naresh Gurbuxani <naresh_gurbuxani at hotmail.com> ?????:

> I installed gfortran 14.2 using package available at
> https://mac.r-project.org.  Then I installed openmp support (17.0.6)
> using package available at https://mac.r-project.org/openmp/.

These are needed to build source packages for the CRAN build of R using
the Apple toolchain. Although if you install the CRAN build of R, it
should be possible to install the pre-built packages, including
data.table, with OpenMP support. (CRAN builds of R for macOS include
their own copy of OpenMP runtime starting with R-4.3.)

> ~ $ which gfortran 
> /usr/local/bin/gfortran
> ~ $ gfortran --version
> GNU Fortran (GCC) 14.2.0
> ~ $ clang --version
> Apple clang version 16.0.0 (clang-1600.0.26.6)
> Target: x86_64-apple-darwin24.3.0
> Thread model: posix
> InstalledDir: /Library/Developer/CommandLineTools/usr/bin

Doesn't the MacPorts build of R use its own toolchain?
https://github.com/macports/macports-ports/blob/bc07a46df685778bc33530c2dd09050be07a6a41/math/R/Portfile#L40-L41

Check the output of R CMD config CC (is it /opt/local/bin/clang-mp-18?)
and try to find out how to enable OpenMP support for that compiler.
Does it need a separate installation of the libomp port?

-- 
Best regards,
Ivan


From kev|n @end|ng |rom zembower@org  Mon Mar 17 15:39:28 2025
From: kev|n @end|ng |rom zembower@org (=?UTF-8?Q?Kevin_Zembower?=)
Date: Mon, 17 Mar 2025 14:39:28 +0000
Subject: [R] Why I wrote my MWE the way I did. [WAS:] Re: What don't I
 understand about sample()?
In-Reply-To: <9FE006C1-C7D4-4FFC-94EF-7DB0818737DF@dcn.davis.ca.us>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org> 
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org> 
 <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
 <003d01db95d3$6189cae0$249d60a0$@gmail.com> 
 <CABcYAdKC9uKyBfGDRKWU7JozTA9i1=2sdePwABVmhNY=3WnRpQ@mail.gmail.com> 
 <012401db962f$12376090$36a621b0$@gmail.com> 
 <CABcYAdKXv9CZV-JK1--7=Ckskfu9F+2Bs58o-gv9J3gdOTrbtA@mail.gmail.com> 
 <004401db96ac$e62c3600$b284a200$@gmail.com> 
 <9FE006C1-C7D4-4FFC-94EF-7DB0818737DF@dcn.davis.ca.us> 
 <0a7415f95666485c187c5edab6c799965952b528.camel@zembower.org>
Message-ID: <01000195a48b9f2c-f448db2e-b928-458f-8fca-e962b9ee9788-000000@email.amazonses.com>

Hello, all, thanks, again for the detailed comments and suggestions.
This is one reason I really enjoy this group: the lively and
knowledgeable discussions that questions generate. I'm a little
hesitant that a future reader, just skimming the subject lines, will
miss the true breath of this discussion.

I'd like to clarify my use of the tidyverse library. I used it so that
I could use read_csv(). I was under the mistaken understanding that
read.csv() would not fetch a file from the internet, using a
'https://...' URL, that only read_csv() would do that. I'm pretty sure
that at some point in the 15 years that I've been aware of and using R,
read.csv() would not do that. I didn't do a lot with R during the time
that the tidyverse was developed and became popular; I had to learn it
fresh just a few years ago, when I kind of came back to R. 

In this project, I was doing a 'data exploration' of sorts. I wasn't
concerned with optimizing anything but getting a correct answer. I
didn't explore whether other functions would also fetch internet files,
I didn't compare the execution speeds of apply() versus rowMeans()
(although, since I didn't know about rowMeans(), I'm glad Tim mentioned
it; I'll be sure to file this away for the next time it comes up).

Almost all respondents to my original question about sample() pointed
out my example didn't use the 'size=' parameter. I constructed my first
MWE (beyond the first one-line snippet I originally posted) to explain
how I couldn't just use 'size' to fill a matrix, like the bootstart
model I was working from, because I needed permutations of the original
dataset. (I had never heard of a permutation test. I think that's
beyond the scope of Stats101.) I wanted to make sure that anyone who
wished to participate in this discussion could do it in the easiest way
possible, without loading a library that they would otherwise have no
use for.

I asked for any suggestions for my R coding style, and I appreciate all
the respondents who went way above the call and researched the sources
I was working from and made suggestions and improvements. I'm still
reading through these to fully understand them, but I'm very grateful
that you took the time to try to help me.

Thank you all, again, for your efforts, and sharing your knowledge and
experience with all of us on this list.

-Kevin

On Sun, 2025-03-16 at 16:04 -0700, Jeff Newmiller wrote:
> The original question was about sample, a base R function. Dragging
> in tidyverse along the way could be regarded as complicating the
> question unnecessarily, but in some cases there can be undesirable or
> simply unexpected interactions between functions drawn from different
> packages. Such complications can turn out to be intrinsic to the
> question being posed, in which case it will be necessary to have
> things in their example just as they are in the original environment.
> In this case that does not seem to be the case... and OP may get
> fewer responses to their question because some people don't keep
> tidyverse installed and may not want to add it just to answer a
> question... leading to fewer responses. In some cases no one may
> respond, and OP would be left with no help.
> 
> In this case it all turned out fine.. so this debate is getting
> stale, and there are reasons why including or excluding tidyverse
> might have been better. But in general, building a true Minimum
> Reproducible Example (MRE) will help communicate most clearly
> (consider using the reprex package to verify the example) and
> minimizing unnecessary packages (reprex can help paring things down)
> may avoid the dreaded "crickets" on the mailing list in the future.
> And sometimes building an MRE will help OP answer their own question.
> 
> On March 16, 2025 12:52:07 PM PDT, avi.e.gross at gmail.com?wrote:
> > Thanks for the clarification, Richard, as I clearly made the wrong
> > guess of what you meant.
> > 
> > Your idea or objection was that you see the included read.csv
> > function as adequate and see no incentive to use read_csv, and
> > especially not if that is the only function being used. I only
> > partially agree.
> > 
> > As usual, I look at things from multiple overlapping perspectives.
> > 
> > There are actually more ways to read in a CSV or other such data
> > files including fread from data.table and another called feather
> > and other base functions. Some people choose ONE and use it
> > whenever possible and your choice might be the base version and
> > mine would not be. 
> > 
> > So, one perspective is that the base version is in some sense pre-
> > loaded and any other must be pre-downloaded and added with a
> > library statement. I am not sure how much that costs or if the base
> > version is also only partially preloaded and gotten only as needed.
> > But it can be a valid concern, especially as some people write
> > defensive code so that if it is not already installed, they first
> > fetch it.
> > 
> > Another perspective, especially for larger files, is speed. One
> > article I have suggests the base version is quite SLOW. 
> > 
> > https://www.r-bloggers.com/2017/04/fast-data-loading-from-files-to-r/
> > 
> > But that was in 2017, and using such concerns, you may be better
> > off with data.table ...
> > 
> > Another issue is that some people have found it handy to deal with
> > tibbles rather than unenhanced data.frames and if you read it in
> > using the base, you may end up converting it later so the
> > underscore version saves a small step. The OP clearly does not need
> > this as no other tidyverse functions are used. Others may care.
> > 
> > But related to this are things like not converting strings to
> > factors by default or play around with column names. It can be time
> > consuming to read in data and then use multiple commands to change
> > it to the way you want it, such as undoing the factors (albeit you
> > can just set the default in the base too) or converting a column it
> > guessed was integer to Boolean and so on.
> > 
> > And I note I have used other features that I like and base does not
> > support. But, again, if the OP does not have any plans on using any
> > such features or defaults and is reading fairly small amounts of
> > data and running it once, there is no special reason to make it
> > worth leaving the base. If they may later want to use additional
> > tidyverse functionality, switching to use this by default may be
> > wise. 
> > 
> > My philosophy is to keep thing as simple as reasonable but no
> > simpler than reasonable. In programming languages, it is to use a
> > simple consistent set of tools that gets me what I want with
> > accuracy and thus it can be simpler to use the tidyverse a lot as
> > my default. To each their own.
> > 
> > -----Original Message-----
> > From: Richard O'Keefe <raoknz at gmail.com> 
> > Sent: Sunday, March 16, 2025 7:53 AM
> > To: avi.e.gross at gmail.com
> > Cc: Kevin Zembower <kevin at zembower.org>; r-help at r-project.org
> > Subject: Re: [R] What don't I understand about sample()?
> > 
> > I think you think I mistook read_csv for read.csv.? Not so.? The
> > point
> > was that base R with no additional packages loaded already contains
> > a
> > CSV reader which is entirely adequate for the task at hand.? When
> > you
> > are already struggling with the basics of a system (like how often
> > and
> > when arguments are evaluated), I think it's wisests to stick with
> > basic tools.? When they taught me carpentry at school, they had me
> > on
> > chisels before getting to lathes (and in fact never did get to
> > lathes
> > at my school).
> > 
> > Sure, R isn't perfect.? But whenever I open the SAS manuals I
> > remember
> > that things could be much worse.
> > 
> > On Sun, 16 Mar 2025 at 17:51, <avi.e.gross at gmail.com> wrote:
> > > 
> > > Richard,
> > > 
> > > The function with a period as a separator that you cite,
> > > read.csv, is part of normal base R.
> > > 
> > > We have been discussing a different function named just a tad
> > > different that uses an underscore as a separator, read_csv that
> > > is similar but has some changes in how it works and the options
> > > supported and is considered part of the tidyverse grouping of
> > > packages and can also be gotten more compactly by importing
> > > package "readr" ...
> > > 
> > > The OP, for reasons of their own, wanted to use read_csv and did
> > > not want or need anything else in the related packages.
> > > 
> > > Of course, nobody is required to use other packages, albeit, as
> > > you noted, many packages you may choose to use have some
> > > dependencies on others you don't.
> > > 
> > > Like many good things, added functionality available to you does
> > > add complexity and room for failures. But when a package is
> > > useful enough to be very useful, it can develop enough momentum
> > > that some functionality might well be a good idea to move into
> > > base R. As an example I already mentioned, of the various pipe
> > > implementations, a version has been added to base R and I suspect
> > > many older packages, including in the tidyverse, can adjust their
> > > code in new releases to use it but with CARE. Anyone still using
> > > older versions of R will experience failures in such a scenario.
> > > 
> > > Luckily, many uses within a package are likely to be safe if done
> > > properly. Can anyone share if any such methods are in use?
> > > 
> > > I mean, as an example, could a package early on check if the R
> > > version being used is later than the introduction, or some other
> > > way to check if a |> operation is supported? Could they then
> > > somehow introduce an operator that is either bound to |> or
> > > perhaps %>% and use that in any places in the code where both
> > > work the same, and only use the magrittr pipe when doing
> > > something it does differently such as needing to use a period to
> > > specify which argument in a function is receiving the pipelined
> > > data.
> > > 
> > > There are programs people want to keep frozen so they only use
> > > the versions of R and packages that existed at some moment so you
> > > avoid some inevitable conflicts. So, I despair that older
> > > versions of R may stick around way too long and break with any
> > > newer packages.
> > > 
> > > But languages cannot remain totally static or chances are people
> > > will move on to newer languages that offer things they want. Then
> > > again, there seem to still be COBOL programs out there.
> > > 
> > > -----Original Message-----
> > > From: Richard O'Keefe <raoknz at gmail.com>
> > > Sent: Sunday, March 16, 2025 12:32 AM
> > > To: avi.e.gross at gmail.com
> > > Cc: Kevin Zembower <kevin at zembower.org>; r-help at r-project.org
> > > Subject: Re: [R] What don't I understand about sample()?
> > > 
> > > Rgui 4.4.3 on Windows.? When I start it up, read.csv is just
> > > *there*.
> > > I don't need to load any package to get it.
> > > 
> > > I have three reasons for being very sparing in the packages I
> > > use.
> > > 1. It took me long enough to get my head around R.? More packages
> > > =
> > > more things to learn.? I *still* have major trouble grasping
> > > tidyverse, and as far as I can see it doesn't solve any problem
> > > that
> > > *I* have.? I install a package only when I have a specific need
> > > for
> > > something it does, like spatial statistics.? (And yet I have
> > > hundreds
> > > of packages installed, because packages depend on other
> > > packages.)
> > > 2. Everything changes, and they don't all change coherently.? A
> > > package I've used for years may not be available in the next
> > > release.
> > > This is not a theoretical possibility; it has happened to me
> > > often.
> > > "If I don't use it I can't lose it."? Sometimes things break
> > > because
> > > something else on the system (tcl/tk, or the C or Fortran
> > > compiler)
> > > has changed.? I'm tired of things breaking because the C or
> > > Fortran compiler
> > > is now stricter.
> > > 3. The universe of R packages is vast and constantly expanding.?
> > > This
> > > makes it *impossible* for anyone to test every possible
> > > combination.? I
> > > used to teach software engineering, and we had a slogan "if it
> > > isn't
> > > tested it doesn't work".? Base R plus package X?? Probably
> > > tested.
> > > Base R plus package Y?? Probably tested.? Base R plus X plus Y?
> > > Not unless X requires Y or Y requires X.
> > > 
> > > There is also the didactic point that the more you work with base
> > > R
> > > the better you will understand it, which you will need to
> > > understand
> > > other things like tidyverse.? It's like mastering the alphabet
> > > before you
> > > learn shorthand.
> > > 
> > > 
> > > On Sun, 16 Mar 2025 at 06:55, <avi.e.gross at gmail.com> wrote:
> > > > 
> > > > Kevin & Richard, and of course everyone,
> > > > 
> > > > As the main topic here is not the tidyverse, I will mention the
> > > > perils of loading in more than needed in general.
> > > > 
> > > > If you want to use one or a very few functions, it can be more
> > > > efficient and safe to load exactly what is needed. In the case
> > > > of wanting to use read_csv(), I think this suffices:
> > > > 
> > > > library(readr)
> > > > 
> > > > If you instead use:
> > > > 
> > > > library(tidyverse)
> > > > 
> > > > You load a varying number of packages (it may change) including
> > > > some like lubridate or forcats or ggplot2 that you may not be
> > > > even thinking of using or never heard of.
> > > > 
> > > > The bigger problem is shadowing that happens. For example, you
> > > > may be getting warning messages like:
> > > > 
> > > > ? dplyr::filter() masks stats::filter()
> > > > ? dplyr::lag()??? masks stats::lag()
> > > > 
> > > > This can interfere with some other package you had already
> > > > loaded unless it uses a notation like mypackage::filter(...) in
> > > > their code to avoid being easily replaced but even then, if you
> > > > yourself called what you though was filter() from base R or
> > > > some package, you have a problem unless you invoke it like
> > > > base::filter(...)
> > > > 
> > > > The order packages like this load can matter as well as when
> > > > you define a function of your own. So, it may be worth some
> > > > effort to zoom in and call exactly what you need and only when
> > > > you need it. I have seen code that only needs a package in rare
> > > > conditions and only loads the package in one branch of an IF
> > > > statement right before using in.
> > > > .
> > > > Packages can also be unloaded after use.
> > > > 
> > > > From what you describe, none of this is crucially important as
> > > > you are using R for your own purposes in your own RMarkDown
> > > > file that you may not be distributing. And, when I write
> > > > programs where I keep adjusting and adding things from the
> > > > tidyverse, it is indeed much easier to just get the grouping on
> > > > top and forget about it. That is, until I decide to do
> > > > something with functional programming that uses
> > > > reduce/filter/map... and have an odd error!
> > > > 
> > > > 
> > > > -----Original Message-----
> > > > From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin
> > > > Zembower via R-help
> > > > Sent: Saturday, March 15, 2025 1:29 PM
> > > > To: r-help at r-project.org
> > > > Subject: Re: [R] What don't I understand about sample()?
> > > > 
> > > > Hi, Richard, thanks for replying. I should have mentioned the
> > > > third
> > > > edition, which we're using. The data file didn't change between
> > > > the
> > > > second and third editions, and the data on Body Mass Gain was
> > > > the same
> > > > as in the first edition, although the first edition data file
> > > > contained
> > > > additional variables.
> > > > 
> > > > According to my text, the BMGain was measured in grams. Thanks
> > > > for
> > > > pointing out that my statement of the problem lacked crucial
> > > > information.
> > > > 
> > > > The matrix in my example comes from an example in
> > > > https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf, where
> > > > the author
> > > > created a bootstrap example with a matrix that consisted of one
> > > > row for
> > > > every sample in the bootstrap, and one column for each mean in
> > > > the
> > > > original data. This allowed him to find the mean for each row
> > > > to create
> > > > the bootstrap statistics.
> > > > 
> > > > The only need for the tidyverse is to use the read_csv()
> > > > function. I'm
> > > > regrettably lazy in not determining which of the multiple
> > > > functions in
> > > > the tidyverse library loads read_csv(), and just using that
> > > > one.
> > > > 
> > > > Thanks, again, for helping me to further understand R and this
> > > > problem.
> > > > 
> > > > -Kevin
> > > > 
> > > > On Sat, 2025-03-15 at 12:00 +0100,
> > > > r-help-request at r-project.org?wrote:
> > > > > Not having the book (and which of the three editions are you
> > > > > using?),
> > > > > I downloaded the data and played with it for a bit.
> > > > > dotchart() showed the Dark and Light conditions looked quite
> > > > > different, but also showed that there are not very many
> > > > > cases.
> > > > > After trying t.test, it occurred to me that I did not know
> > > > > whether
> > > > > "BMGain" means gain in *grams* or gain in *percent*.
> > > > > Reflection told me that for a growth experiment, percent made
> > > > > more
> > > > > sense, which reminded my of one of my first
> > > > > student advising experiences, where I said "never give the
> > > > > computer
> > > > > percentages; let IT calculate the percentages
> > > > > from the baseline and outcome, because once you've thrown
> > > > > away
> > > > > information, the computer can't magically get it back."
> > > > > In particular, in the real world I'd be worried about the
> > > > > possibility
> > > > > that there was some confounding going on, so I would
> > > > > much rather have initial weight and final weight as
> > > > > variables.
> > > > > If BMGain is an absolute measure, the p value for a t test is
> > > > > teeny
> > > > > tiny.
> > > > > If BMGain is a percentage, the p value for a sensible t test
> > > > > is about
> > > > > 0.03.
> > > > > 
> > > > > A permutation test went like this.
> > > > > is.light <- d$Group == "Light"
> > > > > is.dark <- d$Group == "Dark"
> > > > > score <- function (g) mean(g[is.light]) - mean(g[is.dark])
> > > > > base.score <- score(d$BMGain)
> > > > > perm.scores <- sapply(1:997, function (i)
> > > > > score(sample(d$BMGain)))
> > > > > sum(perm.scores >= base.score) / length(perm.scores)
> > > > > 
> > > > > I don't actually see where matrix() comes into it, still less
> > > > > anything
> > > > > in the tidyverse.
> > > > > 
> > > > 
> > > > ______________________________________________
> > > > R-help at r-project.org?mailing list -- To UNSUBSCRIBE and more,
> > > > see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > https://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible
> > > > code.
> > > > 
> > > > ______________________________________________
> > > > R-help at r-project.org?mailing list -- To UNSUBSCRIBE and more,
> > > > see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > https://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible
> > > > code.
> > > 
> > 
> > ______________________________________________
> > R-help at r-project.org?mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > https://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 




From r@oknz @end|ng |rom gm@||@com  Tue Mar 18 01:56:06 2025
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 18 Mar 2025 13:56:06 +1300
Subject: [R] Why I wrote my MWE the way I did. [WAS:] Re: What don't I
 understand about sample()?
In-Reply-To: <01000195a48b9f2c-f448db2e-b928-458f-8fca-e962b9ee9788-000000@email.amazonses.com>
References: <mailman.372647.0.1742036401.60374.r-help@r-project.org>
 <4c982e51255c5b83097fba1d7cf12341988eeb4e.camel@zembower.org>
 <010001959ad9d794-3dea3f0a-037e-4cb9-bf19-28979a0d147b-000000@email.amazonses.com>
 <003d01db95d3$6189cae0$249d60a0$@gmail.com>
 <CABcYAdKC9uKyBfGDRKWU7JozTA9i1=2sdePwABVmhNY=3WnRpQ@mail.gmail.com>
 <012401db962f$12376090$36a621b0$@gmail.com>
 <CABcYAdKXv9CZV-JK1--7=Ckskfu9F+2Bs58o-gv9J3gdOTrbtA@mail.gmail.com>
 <004401db96ac$e62c3600$b284a200$@gmail.com>
 <0a7415f95666485c187c5edab6c799965952b528.camel@zembower.org>
 <9FE006C1-C7D4-4FFC-94EF-7DB0818737DF@dcn.davis.ca.us>
 <01000195a48b9f2c-f448db2e-b928-458f-8fca-e962b9ee9788-000000@email.amazonses.com>
Message-ID: <CABcYAdL2oXbr2OPWf6QCsaKJaaAx9zW-kFFWpyZCU+Cv5doqWw@mail.gmail.com>

?read.csv
leads to the help page for read.table, of which read.csv is a special case.
In the description, the first argument is called 'file', which
suggests to the unwary reader that
it can only name a file.
But if you persist and read the description of the arguments, you learn that
"file can be a readable text-mode connection" and in the next paragraph
"file can also be a complete URL."

Chances are, I'm going to make mistakes.  I'm going to want to fix my
script and try again.
And again.  And again.  If I download a file, all these attempts are
going to my local SSD.
If I use a URL, all these attempts are going to reach out over the
network, and if my connection
goes down (I've had a pile of washing fall on my modem, which then
overheated and shut down)
I can't continue.

When is it a good idea to use read.table or any of its wrappers with a
URL as first argument?


On Tue, 18 Mar 2025 at 03:39, Kevin Zembower <kevin at zembower.org> wrote:
>
> Hello, all, thanks, again for the detailed comments and suggestions.
> This is one reason I really enjoy this group: the lively and
> knowledgeable discussions that questions generate. I'm a little
> hesitant that a future reader, just skimming the subject lines, will
> miss the true breath of this discussion.
>
> I'd like to clarify my use of the tidyverse library. I used it so that
> I could use read_csv(). I was under the mistaken understanding that
> read.csv() would not fetch a file from the internet, using a
> 'https://...' URL, that only read_csv() would do that. I'm pretty sure
> that at some point in the 15 years that I've been aware of and using R,
> read.csv() would not do that. I didn't do a lot with R during the time
> that the tidyverse was developed and became popular; I had to learn it
> fresh just a few years ago, when I kind of came back to R.
>
> In this project, I was doing a 'data exploration' of sorts. I wasn't
> concerned with optimizing anything but getting a correct answer. I
> didn't explore whether other functions would also fetch internet files,
> I didn't compare the execution speeds of apply() versus rowMeans()
> (although, since I didn't know about rowMeans(), I'm glad Tim mentioned
> it; I'll be sure to file this away for the next time it comes up).
>
> Almost all respondents to my original question about sample() pointed
> out my example didn't use the 'size=' parameter. I constructed my first
> MWE (beyond the first one-line snippet I originally posted) to explain
> how I couldn't just use 'size' to fill a matrix, like the bootstart
> model I was working from, because I needed permutations of the original
> dataset. (I had never heard of a permutation test. I think that's
> beyond the scope of Stats101.) I wanted to make sure that anyone who
> wished to participate in this discussion could do it in the easiest way
> possible, without loading a library that they would otherwise have no
> use for.
>
> I asked for any suggestions for my R coding style, and I appreciate all
> the respondents who went way above the call and researched the sources
> I was working from and made suggestions and improvements. I'm still
> reading through these to fully understand them, but I'm very grateful
> that you took the time to try to help me.
>
> Thank you all, again, for your efforts, and sharing your knowledge and
> experience with all of us on this list.
>
> -Kevin
>
> On Sun, 2025-03-16 at 16:04 -0700, Jeff Newmiller wrote:
> > The original question was about sample, a base R function. Dragging
> > in tidyverse along the way could be regarded as complicating the
> > question unnecessarily, but in some cases there can be undesirable or
> > simply unexpected interactions between functions drawn from different
> > packages. Such complications can turn out to be intrinsic to the
> > question being posed, in which case it will be necessary to have
> > things in their example just as they are in the original environment.
> > In this case that does not seem to be the case... and OP may get
> > fewer responses to their question because some people don't keep
> > tidyverse installed and may not want to add it just to answer a
> > question... leading to fewer responses. In some cases no one may
> > respond, and OP would be left with no help.
> >
> > In this case it all turned out fine.. so this debate is getting
> > stale, and there are reasons why including or excluding tidyverse
> > might have been better. But in general, building a true Minimum
> > Reproducible Example (MRE) will help communicate most clearly
> > (consider using the reprex package to verify the example) and
> > minimizing unnecessary packages (reprex can help paring things down)
> > may avoid the dreaded "crickets" on the mailing list in the future.
> > And sometimes building an MRE will help OP answer their own question.
> >
> > On March 16, 2025 12:52:07 PM PDT, avi.e.gross at gmail.com wrote:
> > > Thanks for the clarification, Richard, as I clearly made the wrong
> > > guess of what you meant.
> > >
> > > Your idea or objection was that you see the included read.csv
> > > function as adequate and see no incentive to use read_csv, and
> > > especially not if that is the only function being used. I only
> > > partially agree.
> > >
> > > As usual, I look at things from multiple overlapping perspectives.
> > >
> > > There are actually more ways to read in a CSV or other such data
> > > files including fread from data.table and another called feather
> > > and other base functions. Some people choose ONE and use it
> > > whenever possible and your choice might be the base version and
> > > mine would not be.
> > >
> > > So, one perspective is that the base version is in some sense pre-
> > > loaded and any other must be pre-downloaded and added with a
> > > library statement. I am not sure how much that costs or if the base
> > > version is also only partially preloaded and gotten only as needed.
> > > But it can be a valid concern, especially as some people write
> > > defensive code so that if it is not already installed, they first
> > > fetch it.
> > >
> > > Another perspective, especially for larger files, is speed. One
> > > article I have suggests the base version is quite SLOW.
> > >
> > > https://www.r-bloggers.com/2017/04/fast-data-loading-from-files-to-r/
> > >
> > > But that was in 2017, and using such concerns, you may be better
> > > off with data.table ...
> > >
> > > Another issue is that some people have found it handy to deal with
> > > tibbles rather than unenhanced data.frames and if you read it in
> > > using the base, you may end up converting it later so the
> > > underscore version saves a small step. The OP clearly does not need
> > > this as no other tidyverse functions are used. Others may care.
> > >
> > > But related to this are things like not converting strings to
> > > factors by default or play around with column names. It can be time
> > > consuming to read in data and then use multiple commands to change
> > > it to the way you want it, such as undoing the factors (albeit you
> > > can just set the default in the base too) or converting a column it
> > > guessed was integer to Boolean and so on.
> > >
> > > And I note I have used other features that I like and base does not
> > > support. But, again, if the OP does not have any plans on using any
> > > such features or defaults and is reading fairly small amounts of
> > > data and running it once, there is no special reason to make it
> > > worth leaving the base. If they may later want to use additional
> > > tidyverse functionality, switching to use this by default may be
> > > wise.
> > >
> > > My philosophy is to keep thing as simple as reasonable but no
> > > simpler than reasonable. In programming languages, it is to use a
> > > simple consistent set of tools that gets me what I want with
> > > accuracy and thus it can be simpler to use the tidyverse a lot as
> > > my default. To each their own.
> > >
> > > -----Original Message-----
> > > From: Richard O'Keefe <raoknz at gmail.com>
> > > Sent: Sunday, March 16, 2025 7:53 AM
> > > To: avi.e.gross at gmail.com
> > > Cc: Kevin Zembower <kevin at zembower.org>; r-help at r-project.org
> > > Subject: Re: [R] What don't I understand about sample()?
> > >
> > > I think you think I mistook read_csv for read.csv.  Not so.  The
> > > point
> > > was that base R with no additional packages loaded already contains
> > > a
> > > CSV reader which is entirely adequate for the task at hand.  When
> > > you
> > > are already struggling with the basics of a system (like how often
> > > and
> > > when arguments are evaluated), I think it's wisests to stick with
> > > basic tools.  When they taught me carpentry at school, they had me
> > > on
> > > chisels before getting to lathes (and in fact never did get to
> > > lathes
> > > at my school).
> > >
> > > Sure, R isn't perfect.  But whenever I open the SAS manuals I
> > > remember
> > > that things could be much worse.
> > >
> > > On Sun, 16 Mar 2025 at 17:51, <avi.e.gross at gmail.com> wrote:
> > > >
> > > > Richard,
> > > >
> > > > The function with a period as a separator that you cite,
> > > > read.csv, is part of normal base R.
> > > >
> > > > We have been discussing a different function named just a tad
> > > > different that uses an underscore as a separator, read_csv that
> > > > is similar but has some changes in how it works and the options
> > > > supported and is considered part of the tidyverse grouping of
> > > > packages and can also be gotten more compactly by importing
> > > > package "readr" ...
> > > >
> > > > The OP, for reasons of their own, wanted to use read_csv and did
> > > > not want or need anything else in the related packages.
> > > >
> > > > Of course, nobody is required to use other packages, albeit, as
> > > > you noted, many packages you may choose to use have some
> > > > dependencies on others you don't.
> > > >
> > > > Like many good things, added functionality available to you does
> > > > add complexity and room for failures. But when a package is
> > > > useful enough to be very useful, it can develop enough momentum
> > > > that some functionality might well be a good idea to move into
> > > > base R. As an example I already mentioned, of the various pipe
> > > > implementations, a version has been added to base R and I suspect
> > > > many older packages, including in the tidyverse, can adjust their
> > > > code in new releases to use it but with CARE. Anyone still using
> > > > older versions of R will experience failures in such a scenario.
> > > >
> > > > Luckily, many uses within a package are likely to be safe if done
> > > > properly. Can anyone share if any such methods are in use?
> > > >
> > > > I mean, as an example, could a package early on check if the R
> > > > version being used is later than the introduction, or some other
> > > > way to check if a |> operation is supported? Could they then
> > > > somehow introduce an operator that is either bound to |> or
> > > > perhaps %>% and use that in any places in the code where both
> > > > work the same, and only use the magrittr pipe when doing
> > > > something it does differently such as needing to use a period to
> > > > specify which argument in a function is receiving the pipelined
> > > > data.
> > > >
> > > > There are programs people want to keep frozen so they only use
> > > > the versions of R and packages that existed at some moment so you
> > > > avoid some inevitable conflicts. So, I despair that older
> > > > versions of R may stick around way too long and break with any
> > > > newer packages.
> > > >
> > > > But languages cannot remain totally static or chances are people
> > > > will move on to newer languages that offer things they want. Then
> > > > again, there seem to still be COBOL programs out there.
> > > >
> > > > -----Original Message-----
> > > > From: Richard O'Keefe <raoknz at gmail.com>
> > > > Sent: Sunday, March 16, 2025 12:32 AM
> > > > To: avi.e.gross at gmail.com
> > > > Cc: Kevin Zembower <kevin at zembower.org>; r-help at r-project.org
> > > > Subject: Re: [R] What don't I understand about sample()?
> > > >
> > > > Rgui 4.4.3 on Windows.  When I start it up, read.csv is just
> > > > *there*.
> > > > I don't need to load any package to get it.
> > > >
> > > > I have three reasons for being very sparing in the packages I
> > > > use.
> > > > 1. It took me long enough to get my head around R.  More packages
> > > > =
> > > > more things to learn.  I *still* have major trouble grasping
> > > > tidyverse, and as far as I can see it doesn't solve any problem
> > > > that
> > > > *I* have.  I install a package only when I have a specific need
> > > > for
> > > > something it does, like spatial statistics.  (And yet I have
> > > > hundreds
> > > > of packages installed, because packages depend on other
> > > > packages.)
> > > > 2. Everything changes, and they don't all change coherently.  A
> > > > package I've used for years may not be available in the next
> > > > release.
> > > > This is not a theoretical possibility; it has happened to me
> > > > often.
> > > > "If I don't use it I can't lose it."  Sometimes things break
> > > > because
> > > > something else on the system (tcl/tk, or the C or Fortran
> > > > compiler)
> > > > has changed.  I'm tired of things breaking because the C or
> > > > Fortran compiler
> > > > is now stricter.
> > > > 3. The universe of R packages is vast and constantly expanding.
> > > > This
> > > > makes it *impossible* for anyone to test every possible
> > > > combination.  I
> > > > used to teach software engineering, and we had a slogan "if it
> > > > isn't
> > > > tested it doesn't work".  Base R plus package X?  Probably
> > > > tested.
> > > > Base R plus package Y?  Probably tested.  Base R plus X plus Y?
> > > > Not unless X requires Y or Y requires X.
> > > >
> > > > There is also the didactic point that the more you work with base
> > > > R
> > > > the better you will understand it, which you will need to
> > > > understand
> > > > other things like tidyverse.  It's like mastering the alphabet
> > > > before you
> > > > learn shorthand.
> > > >
> > > >
> > > > On Sun, 16 Mar 2025 at 06:55, <avi.e.gross at gmail.com> wrote:
> > > > >
> > > > > Kevin & Richard, and of course everyone,
> > > > >
> > > > > As the main topic here is not the tidyverse, I will mention the
> > > > > perils of loading in more than needed in general.
> > > > >
> > > > > If you want to use one or a very few functions, it can be more
> > > > > efficient and safe to load exactly what is needed. In the case
> > > > > of wanting to use read_csv(), I think this suffices:
> > > > >
> > > > > library(readr)
> > > > >
> > > > > If you instead use:
> > > > >
> > > > > library(tidyverse)
> > > > >
> > > > > You load a varying number of packages (it may change) including
> > > > > some like lubridate or forcats or ggplot2 that you may not be
> > > > > even thinking of using or never heard of.
> > > > >
> > > > > The bigger problem is shadowing that happens. For example, you
> > > > > may be getting warning messages like:
> > > > >
> > > > > ? dplyr::filter() masks stats::filter()
> > > > > ? dplyr::lag()    masks stats::lag()
> > > > >
> > > > > This can interfere with some other package you had already
> > > > > loaded unless it uses a notation like mypackage::filter(...) in
> > > > > their code to avoid being easily replaced but even then, if you
> > > > > yourself called what you though was filter() from base R or
> > > > > some package, you have a problem unless you invoke it like
> > > > > base::filter(...)
> > > > >
> > > > > The order packages like this load can matter as well as when
> > > > > you define a function of your own. So, it may be worth some
> > > > > effort to zoom in and call exactly what you need and only when
> > > > > you need it. I have seen code that only needs a package in rare
> > > > > conditions and only loads the package in one branch of an IF
> > > > > statement right before using in.
> > > > > .
> > > > > Packages can also be unloaded after use.
> > > > >
> > > > > From what you describe, none of this is crucially important as
> > > > > you are using R for your own purposes in your own RMarkDown
> > > > > file that you may not be distributing. And, when I write
> > > > > programs where I keep adjusting and adding things from the
> > > > > tidyverse, it is indeed much easier to just get the grouping on
> > > > > top and forget about it. That is, until I decide to do
> > > > > something with functional programming that uses
> > > > > reduce/filter/map... and have an odd error!
> > > > >
> > > > >
> > > > > -----Original Message-----
> > > > > From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin
> > > > > Zembower via R-help
> > > > > Sent: Saturday, March 15, 2025 1:29 PM
> > > > > To: r-help at r-project.org
> > > > > Subject: Re: [R] What don't I understand about sample()?
> > > > >
> > > > > Hi, Richard, thanks for replying. I should have mentioned the
> > > > > third
> > > > > edition, which we're using. The data file didn't change between
> > > > > the
> > > > > second and third editions, and the data on Body Mass Gain was
> > > > > the same
> > > > > as in the first edition, although the first edition data file
> > > > > contained
> > > > > additional variables.
> > > > >
> > > > > According to my text, the BMGain was measured in grams. Thanks
> > > > > for
> > > > > pointing out that my statement of the problem lacked crucial
> > > > > information.
> > > > >
> > > > > The matrix in my example comes from an example in
> > > > > https://pages.stat.wisc.edu/~larget/stat302/chap3.pdf, where
> > > > > the author
> > > > > created a bootstrap example with a matrix that consisted of one
> > > > > row for
> > > > > every sample in the bootstrap, and one column for each mean in
> > > > > the
> > > > > original data. This allowed him to find the mean for each row
> > > > > to create
> > > > > the bootstrap statistics.
> > > > >
> > > > > The only need for the tidyverse is to use the read_csv()
> > > > > function. I'm
> > > > > regrettably lazy in not determining which of the multiple
> > > > > functions in
> > > > > the tidyverse library loads read_csv(), and just using that
> > > > > one.
> > > > >
> > > > > Thanks, again, for helping me to further understand R and this
> > > > > problem.
> > > > >
> > > > > -Kevin
> > > > >
> > > > > On Sat, 2025-03-15 at 12:00 +0100,
> > > > > r-help-request at r-project.org wrote:
> > > > > > Not having the book (and which of the three editions are you
> > > > > > using?),
> > > > > > I downloaded the data and played with it for a bit.
> > > > > > dotchart() showed the Dark and Light conditions looked quite
> > > > > > different, but also showed that there are not very many
> > > > > > cases.
> > > > > > After trying t.test, it occurred to me that I did not know
> > > > > > whether
> > > > > > "BMGain" means gain in *grams* or gain in *percent*.
> > > > > > Reflection told me that for a growth experiment, percent made
> > > > > > more
> > > > > > sense, which reminded my of one of my first
> > > > > > student advising experiences, where I said "never give the
> > > > > > computer
> > > > > > percentages; let IT calculate the percentages
> > > > > > from the baseline and outcome, because once you've thrown
> > > > > > away
> > > > > > information, the computer can't magically get it back."
> > > > > > In particular, in the real world I'd be worried about the
> > > > > > possibility
> > > > > > that there was some confounding going on, so I would
> > > > > > much rather have initial weight and final weight as
> > > > > > variables.
> > > > > > If BMGain is an absolute measure, the p value for a t test is
> > > > > > teeny
> > > > > > tiny.
> > > > > > If BMGain is a percentage, the p value for a sensible t test
> > > > > > is about
> > > > > > 0.03.
> > > > > >
> > > > > > A permutation test went like this.
> > > > > > is.light <- d$Group == "Light"
> > > > > > is.dark <- d$Group == "Dark"
> > > > > > score <- function (g) mean(g[is.light]) - mean(g[is.dark])
> > > > > > base.score <- score(d$BMGain)
> > > > > > perm.scores <- sapply(1:997, function (i)
> > > > > > score(sample(d$BMGain)))
> > > > > > sum(perm.scores >= base.score) / length(perm.scores)
> > > > > >
> > > > > > I don't actually see where matrix() comes into it, still less
> > > > > > anything
> > > > > > in the tidyverse.
> > > > > >
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > > see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide
> > > > > https://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible
> > > > > code.
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > > see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide
> > > > > https://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible
> > > > > code.
> > > >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > https://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>


