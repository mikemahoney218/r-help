From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep  1 01:51:09 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 31 Aug 2021 16:51:09 -0700
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108311402330.6620@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>
 <alpine.LNX.2.20.2108311402330.6620@salmo.appl-ecosys.com>
Message-ID: <7013D663-1266-4422-A405-537DA425F676@dcn.davis.ca.us>

Never use stringsAsFactors on uncleaned data. For one thing you give a factor to as.Date and it tries to make sense of the integer representation, not the character representation.

library(dplyr)
dta <- read.csv( text =
"sampdate,samptime,cfs
2020-08-26,09:30,136000
2020-08-26,09:35,126000
2020-08-26,09:40,130000
2020-08-26,09:45,128000
2020-08-26,09:50,126000
2020-08-26,09:55,125000
2020-08-26,10:00,121000
2020-08-26,10:05,117000
2020-08-26,10:10,120000
", stringsAsFactors = FALSE)
dtad <- (   dta
        %>% group_by( sampdate )
        %>% summarise( exp_value = mean(cfs, na.rm = TRUE)
                     , Count = n()
                     )
        )

On August 31, 2021 2:11:05 PM PDT, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>On Sun, 29 Aug 2021, Jeff Newmiller wrote:
>
>> The general idea is to create a "grouping" column with repeated values for
>> each day, and then to use aggregate to compute your combined results. The
>> dplyr package's group_by/summarise functions can also do this, and there
>> are also proponents of the data.table package which is high performance
>> but tends to depend on altering data in-place unlike most other R data
>> handling functions.
>
>Jeff,
>
>I've read a number of docs discussing dplyr's summerize and group_by
>functions (including that section of Hadley's 'R for Data Science' book, yet
>I'm missing something; I think that I need to separate the single sampdate
>column into colums for year, month, and day and group_by year/month
>summarizing within those groups.
>
>The data are of this format:
>sampdate,samptime,cfs
>2020-08-26,09:30,136000
>2020-08-26,09:35,126000
>2020-08-26,09:40,130000
>2020-08-26,09:45,128000
>2020-08-26,09:50,126000
>2020-08-26,09:55,125000
>2020-08-26,10:00,121000
>2020-08-26,10:05,117000
>2020-08-26,10:10,120000
>
>My curent script is:
>
>-------8<--------------
>library('tidyverse')
>
>discharge <- read.table('../data/discharge.dat', header = TRUE, sep = ',', stringsAsFactors = TRUE)
>discharge$sampdate <- as.Date(discharge$sampdate)
>discharge$cfs <- as.numeric(discharge$cfs, length = 6)
>
># use dplyr.summarize grouped by date
>
># need to separate sampdate into %Y-%M-%D in order to group_by the month?
>by_month <- discharge %>%
>   group_by(sampdate ...
>summarize(by_month, exp_value = mean(cfs, na.rm = TRUE), sd(cfs))
>---------------->8--------
>
>and the results are:
>
>> str(discharge)
>'data.frame':	93254 obs. of  3 variables:
>  $ sampdate: Date, format: "2020-08-26" "2020-08-26" ...
>  $ samptime: Factor w/ 728 levels "00:00","00:05",..: 115 116 117 118 123 128 133 138 143 148 ...
>  $ cfs     : num  176 156 165 161 156 154 144 137 142 142 ...
>> ls()
>[1] "by_month"  "discharge"
>> by_month
># A tibble: 93,254 ? 3
># Groups:   sampdate [322]
>    sampdate   samptime   cfs
>    <date>     <fct>    <dbl>
>  1 2020-08-26 09:30      176
>  2 2020-08-26 09:35      156
>  3 2020-08-26 09:40      165
>  4 2020-08-26 09:45      161
>  5 2020-08-26 09:50      156
>  6 2020-08-26 09:55      154
>  7 2020-08-26 10:00      144
>  8 2020-08-26 10:05      137
>  9 2020-08-26 10:10      142
>10 2020-08-26 10:15      142
># ? with 93,244 more rows
>
>I don't know why the discharge values are truncated to 3 digits when they're
>6 digits in the input data.
>
>Suggested readings appreciated,
>
>Rich
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Sep  1 05:59:04 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 1 Sep 2021 15:59:04 +1200
Subject: [R] What if there's nothing to dispatch on?
Message-ID: <20210901155904.33a8f6e0@rolf-Latitude-E7470>


I'm trying to build a pair of (S3) methods, a "formula" method and a
"default" method.  The methods have a "data" argument.  If the variables
in question cannot be found in "data" then they should be sought in
the global environment.

My problem is that the generic dispatches on its first argument, which
may be a formula (in which case it of course dispatches to the formula
method) or the first of the variables.  If this variable exists in
the global environment then all is well.  But if it doesn't exist there,
then the generic falls over with an error of the form "object 'x' not
found" --- because there isn't anything to dispatch on.

I'd *like* to be able to tell the generic that if "x" is not found then
it should dispatch to the default method (which will, if the call is
sensible, find "x" in "data").

Is there any way to tell the generic to do this?

Or is there any other way out of this dilemma? (Other than "Give up and
go to the pub", which I cannot currently do since Auckland is in Level 4
lockdown. :-) )

Thanks for any enlightenment.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@oknz @end|ng |rom gm@||@com  Wed Sep  1 06:05:30 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Wed, 1 Sep 2021 16:05:30 +1200
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108310525150.6620@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2108300538250.15422@salmo.appl-ecosys.com>
 <CABcYAdKHKXZy9yzGcvP3K9=K5bQrVCBX7mN9iCPSqiV=TGJN9w@mail.gmail.com>
 <alpine.LNX.2.20.2108301630260.15422@salmo.appl-ecosys.com>
 <CABcYAdLtdFOR6FJps1cXGTmEEYWZ6ZArn+fnnhyWKEgY0_rYMw@mail.gmail.com>
 <alpine.LNX.2.20.2108310525150.6620@salmo.appl-ecosys.com>
Message-ID: <CABcYAdKnPTLfNHjJ9WZvEGWQ07yEE-g4ceeiSM+1sfd1EkkjaA@mail.gmail.com>

I wrote:
> > By the time you get the data from the USGS, you are already far past the point
> > where what the instruments can write is important.
Rich Shepard replied:
> The data are important because they show what's happened in that period of
> record. Don't physicians take a medical history from patients even though
> those data are far past the point they occurred?

You have missed the point.  The issue is not the temporal distance, but the
fact that the data you have are NOT the raw instrumental data and are NOT
subject to the limitations of the recording instruments.  The data you get from
the USGS is not the raw instrumental value, and there is no longer any good
reason for there to be any gaps in it.  Indeed, the Rogue River data I looked
at explicitly includes some flows labelled "Ae" meaning that they are NOT the
instrumental data at all, but estimated.

> And I use emacs to replace the space between columns with commas so the date
> and the time are separate.

There does not seem to be any good reason for this.
As I demonstrated, it is easy to convert these timestamps to
POSIXct form, which is good for calculating with.
If you want to extract year, month, day, &c, by far the easiest
way is to convert to POSIXlt form (so keeping the timestamp as a
single field) and then use $<whatever> to extract the field.
> n <- as.POSIXlt("2003.04.05 06:07", format="%Y.%m.%d %H:%M", tz="UTC")
> n
[1] "2003-04-05 06:07:00 UTC"
> c(n$year+1900, n$mon+1, n$mday, n$hour, $min)
[1] 2003    4    5    6    7

> > The flow is dominated by a series of "bursts" with a fast onset to a peak
> > and a slow decay, coming in a range of sizes from quite small to rather
> > large, separated by gaps of 4 to 45 days.
>
> And when discharge is controlled by flows through a hydroelectric dam there
> is a lot of variability. The pattern is important to fish as well as
> regulators.

And what is important to fish is NOT captured by daily means and standard
deviations.  For what it's worth, my understanding is that most of the dams on
the Rogue River have been removed, leaving only the Lost Creek Lake one,
and that this has been good for the fish.

Suppose you have a day when there are 16 hours with no water at all flowing,
then 8 hours with 12 cumecs because a dam upstream is discharging.  Then
the daily mean is 4 cumecs, which might look good for fish, but it wasn't.
"Number of minutes below minimum safe level" might be more interesting
for the fish.

>From the data we have alone, we cannot tell which bursts are due to
releases from dams and which have other causes.  Dam releases are under
human control, storms are not.

Looking at the Rogue River data, plotting daily means
- lowers the peaks
- moves them right
- changes the overall shape
Not severely, mind you, but enough to avoid if you don't have to.

By the way, by far the easiest way to do day-wise summaries,
if you really feel you must, is to start with a POSIXct or POSIXlt
column, let's call it r$when, then
  d <- trunc(difftime(r$when, min(r$when), units="days)) + 1
  m <- aggregate(r$flow, by=list(d), FUN=mean)
  plot(m, type="l")
You can plug in other summary functions, not just mean.

Remember:
  for all calculations involving dates and times,
  prefer using the built in date and time classes to
  hacking around the problem

  aggregate() is a good way to compute oddball summaries.


> > - how do I *detect* these bursts? (detecting a peak isn't too hard,
> >   but the peak is not the onset)
> > - how do I *characterise* these bursts?
> >   (and is the onset rate related to the peak size?)
> > - what's left after taking the bursts out?
> > - can I relate these bursts to something going on upstream?
>
> Well, those questions could be appropriate depending on what questions you
> need the data to answer.
>
> Environmental data are quite different from experimental, economic,
> financial, and public data (e.g., unemployment, housing costs).
>
> There are always multiple ways to address an analytical need. Thank you for
> your contributions.
>
> Stay well,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e@ @end|ng |rom enr|co@chum@nn@net  Wed Sep  1 07:25:52 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Wed, 01 Sep 2021 07:25:52 +0200
Subject: [R] Converting characters back to Date and Time
In-Reply-To: <AS8P194MB099979E9FD39C8A3705261579ACC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 (Eliza Botto's message of "Tue, 31 Aug 2021 20:26:01 +0000")
References: <AS8P194MB099979E9FD39C8A3705261579ACC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <87y28g50kf.fsf@enricoschumann.net>

On Tue, 31 Aug 2021, Eliza Botto writes:

> DeaR useR,
>
> I read an excel column in R having Date and time (written in the same cell) as follow,
>
> 06/18/18 10:00
>
> 06/18/18 11:00
>
> 06/18/18 12:00
>
> In R environment, they are read as
>
> 43269.42
>
> 43269.46
>
> 43269.50
>
> Is there a way to covert these characters back to the original format?
>
> Thank-you very much in advance.
>
>
> Eliza Botto
>

If using a package is an option:

  library("datetimeutils")
  convert_date(c(43269.42, 43269.46, 43269.50), "excel")
  ## [1] "2018-06-18" "2018-06-18" "2018-06-18"

  convert_date(c(43269.42, 43269.46, 43269.50), "excel", fraction = TRUE)
  ## [1] "2018-06-18 10:04:48 CEST" "2018-06-18 11:02:24 CEST"
  ## [3] "2018-06-18 12:00:00 CEST"

Note that the times differ: the numbers are probably
not /displayed/ to full precision in R.

You may also want to search the archives of this list,
as this question has been discussed before.


-- 
Enrico Schumann (maintainer of package datetimeutils)
Lucerne, Switzerland
http://enricoschumann.net


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep  1 11:35:03 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 1 Sep 2021 05:35:03 -0400
Subject: [R] What if there's nothing to dispatch on?
In-Reply-To: <20210901155904.33a8f6e0@rolf-Latitude-E7470>
References: <20210901155904.33a8f6e0@rolf-Latitude-E7470>
Message-ID: <c46921e2-4d2a-09f6-110d-376eb188e327@gmail.com>

On 31/08/2021 11:59 p.m., Rolf Turner wrote:
> 
> I'm trying to build a pair of (S3) methods, a "formula" method and a
> "default" method.  The methods have a "data" argument.  If the variables
> in question cannot be found in "data" then they should be sought in
> the global environment.
> 
> My problem is that the generic dispatches on its first argument, which
> may be a formula (in which case it of course dispatches to the formula
> method) or the first of the variables.  If this variable exists in
> the global environment then all is well.  But if it doesn't exist there,
> then the generic falls over with an error of the form "object 'x' not
> found" --- because there isn't anything to dispatch on.
> 
> I'd *like* to be able to tell the generic that if "x" is not found then
> it should dispatch to the default method (which will, if the call is
> sensible, find "x" in "data").
> 
> Is there any way to tell the generic to do this?
> 
> Or is there any other way out of this dilemma? (Other than "Give up and
> go to the pub", which I cannot currently do since Auckland is in Level 4
> lockdown. :-) )
> 

That design is probably not a good idea:  what if one of the variables 
in data matches the name of some other object in the global environment? 
  Then it would dispatch on that other object, and things won't go well.

But here's a way to shoot yourself in the foot:

function(x) {
   x1 <- try(x, silent = TRUE)
   if (inherits(x1, "try-error"))
     foo.default(x)
   else
     UseMethod("foo", x)
}

Happy shooting!

Duncan


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Sep  1 14:27:21 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 1 Sep 2021 12:27:21 +0000
Subject: [R] Converting characters back to Date and Time
In-Reply-To: <AS8P194MB099979E9FD39C8A3705261579ACC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099979E9FD39C8A3705261579ACC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <ca44b3d71ab74492b660c4c8df343d9f@SRVEXCHCM1302.precheza.cz>

Hi

You can use as.POSIXct function
https://stackoverflow.com/questions/19172632/converting-excel-datetime-seria
l-number-to-r-datetime

But you should preferably try to read the date as character vector and then
convert it to date and time.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Eliza Botto
> Sent: Tuesday, August 31, 2021 10:26 PM
> To: r-help at r-project.org
> Subject: [R] Converting characters back to Date and Time
> 
> DeaR useR,
> 
> I read an excel column in R having Date and time (written in the same
cell) as
> follow,
> 
> 06/18/18 10:00
> 
> 06/18/18 11:00
> 
> 06/18/18 12:00
> 
> In R environment, they are read as
> 
> 43269.42
> 
> 43269.46
> 
> 43269.50
> 
> Is there a way to covert these characters back to the original format?
> 
> Thank-you very much in advance.
> 
> 
> Eliza Botto
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep  1 15:15:34 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 1 Sep 2021 06:15:34 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CABcYAdKnPTLfNHjJ9WZvEGWQ07yEE-g4ceeiSM+1sfd1EkkjaA@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2108300538250.15422@salmo.appl-ecosys.com>
 <CABcYAdKHKXZy9yzGcvP3K9=K5bQrVCBX7mN9iCPSqiV=TGJN9w@mail.gmail.com>
 <alpine.LNX.2.20.2108301630260.15422@salmo.appl-ecosys.com>
 <CABcYAdLtdFOR6FJps1cXGTmEEYWZ6ZArn+fnnhyWKEgY0_rYMw@mail.gmail.com>
 <alpine.LNX.2.20.2108310525150.6620@salmo.appl-ecosys.com>
 <CABcYAdKnPTLfNHjJ9WZvEGWQ07yEE-g4ceeiSM+1sfd1EkkjaA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109010615040.29114@salmo.appl-ecosys.com>

On Wed, 1 Sep 2021, Richard O'Keefe wrote:

> You have missed the point. The issue is not the temporal distance, but the
> fact that the data you have are NOT the raw instrumental data and are NOT
> subject to the limitations of the recording instruments. The data you get
> from the USGS is not the raw instrumental value, and there is no longer
> any good reason for there to be any gaps in it. Indeed, the Rogue River
> data I looked at explicitly includes some flows labelled "Ae" meaning that
> they are NOT the instrumental data at all, but estimated.

Richard,

Thanks for your comments.

Regards,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep  1 16:30:44 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 1 Sep 2021 07:30:44 -0700 (PDT)
Subject: [R] 
 Calculate daily means from 5-minute interval data [RESOLVED]
In-Reply-To: <7013D663-1266-4422-A405-537DA425F676@dcn.davis.ca.us>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>
 <alpine.LNX.2.20.2108311402330.6620@salmo.appl-ecosys.com>
 <7013D663-1266-4422-A405-537DA425F676@dcn.davis.ca.us>
Message-ID: <alpine.LNX.2.20.2109010724410.29114@salmo.appl-ecosys.com>

On Tue, 31 Aug 2021, Jeff Newmiller wrote:

> Never use stringsAsFactors on uncleaned data. For one thing you give a
> factor to as.Date and it tries to make sense of the integer
> representation, not the character representation.

Jeff,

Oops! I had changed it in a previous version of the script and for got to
change it back again. Fixed

> dtad <- (   dta
>        %>% group_by( sampdate )
>        %>% summarise( exp_value = mean(cfs, na.rm = TRUE)
>                     , Count = n()
>                     )
>        )

Thank you. Now I understand how to use dplyr's summarize().

Best regards,

Rich


From c@ghpm m@iii@g oii gm@ii@com  Wed Sep  1 16:34:07 2021
From: c@ghpm m@iii@g oii gm@ii@com (c@ghpm m@iii@g oii gm@ii@com)
Date: Wed, 1 Sep 2021 11:34:07 -0300
Subject: [R] how to install npsm package
Message-ID: <012701d79f3e$79cb6300$6d622900$@gmail.com>

I need to install the package "npsm" to follow Kloke & McKean book. However,
npsm is no longer on CRAN. So, please let me know in detail how to proceed
to install it.

 

Thanks.

 

Carlos Gonzalez


	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Sep  1 17:31:15 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 1 Sep 2021 18:31:15 +0300
Subject: [R] how to install npsm package
In-Reply-To: <012701d79f3e$79cb6300$6d622900$@gmail.com>
References: <012701d79f3e$79cb6300$6d622900$@gmail.com>
Message-ID: <CAGgJW76wD-ai58K=QkUrH0yWaG9-6XTR5D8r7J8DuYLL3Pid-g@mail.gmail.com>

Instructions can be found at https://github.com/kloke/npsm


On Wed, Sep 1, 2021 at 6:27 PM <caghpm at gmail.com> wrote:

> I need to install the package "npsm" to follow Kloke & McKean book.
> However,
> npsm is no longer on CRAN. So, please let me know in detail how to proceed
> to install it.
>
>
>
> Thanks.
>
>
>
> Carlos Gonzalez
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrg @end|ng |rom |oe@|@u@  Wed Sep  1 17:32:08 2021
From: jrg @end|ng |rom |oe@|@u@ (JRG)
Date: Wed, 1 Sep 2021 11:32:08 -0400
Subject: [R] how to install npsm package
In-Reply-To: <012701d79f3e$79cb6300$6d622900$@gmail.com>
References: <012701d79f3e$79cb6300$6d622900$@gmail.com>
Message-ID: <7e1ae8e5-08d7-d704-2d2f-0c9460d88861@loesl.us>

Does  this link help?

> https://rdrr.io/cran/npsm/



---JRG



On 9/1/21 10:34 AM, caghpm at gmail.com wrote:
> I need to install the package "npsm" to follow Kloke & McKean book. However,
> npsm is no longer on CRAN. So, please let me know in detail how to proceed
> to install it.
> 
>  
> 
> Thanks.
> 
>  
> 
> Carlos Gonzalez
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Wed Sep  1 18:06:02 2021
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Wed, 1 Sep 2021 09:06:02 -0700
Subject: [R] how to install npsm package
In-Reply-To: <012701d79f3e$79cb6300$6d622900$@gmail.com>
References: <012701d79f3e$79cb6300$6d622900$@gmail.com>
Message-ID: <CAA99HCzr_mvpRbT3+3+cP+Q22uRvevhHQcRP8Pq33GoqmfLF6A@mail.gmail.com>

Hi,

I found package "npsm" at the links below:

https://mran.microsoft.com/snapshot/2017-02-04/web/packages/npsm/index.html
https://cran.r-project.org/src/contrib/Archive/npsm/

HTH, Bill.

W. Michels, Ph.D.


On Wed, Sep 1, 2021 at 8:27 AM <caghpm at gmail.com> wrote:
>
> I need to install the package "npsm" to follow Kloke & McKean book. However,
> npsm is no longer on CRAN. So, please let me know in detail how to proceed
> to install it.
>
>
>
> Thanks.
>
>
>
> Carlos Gonzalez
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e||z@_botto @end|ng |rom out|ook@com  Wed Sep  1 22:59:42 2021
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Wed, 1 Sep 2021 20:59:42 +0000
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
Message-ID: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

deaR useRs,

I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a way of doing it?

> dput(A)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
NA, NA, NA, NA, NA), .Dim = c(9L, 2L))

> dput(B)

structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
11, 12, 13, 14), .Dim = c(9L, 2L))

> dput(C)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
10, 11, 12, 13, 14), .Dim = c(9L, 2L))

Precisely, I want to replace the elements of 2nd column of A with those of B provided the elements of 1st column match. Is there a single line loop or code for that?


Thanks in advance,

Eliza Botto

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Wed Sep  1 23:12:11 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Wed, 1 Sep 2021 21:12:11 +0000
Subject: [R] 
 [External] conditional replacement of elements of matrix with
 another matrix column
In-Reply-To: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <07000564-9D6B-4773-B7EE-079ABFBD4C95@temple.edu>

> A
      [,1] [,2]
 [1,]   12   NA
 [2,]   12   NA
 [3,]   12   NA
 [4,]   13   NA
 [5,]   13   NA
 [6,]   13   NA
 [7,]   14   NA
 [8,]   14   NA
 [9,]   14   NA
> B
      [,1] [,2]
 [1,]   11    6
 [2,]   11    7
 [3,]   11    8
 [4,]   13    9
 [5,]   13   10
 [6,]   13   11
 [7,]   14   12
 [8,]   14   13
 [9,]   14   14
> C
      [,1] [,2]
 [1,]   12   NA
 [2,]   12   NA
 [3,]   12   NA
 [4,]   13    9
 [5,]   13   10
 [6,]   13   11
 [7,]   14   12
 [8,]   14   13
 [9,]   14   14
> same <- A[,1] == B[,1]
> same
[1] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE

> A[same,2] <- B[same,2]
> A
      [,1] [,2]
 [1,]   12   NA
 [2,]   12   NA
 [3,]   12   NA
 [4,]   13    9
 [5,]   13   10
 [6,]   13   11
 [7,]   14   12
 [8,]   14   13
 [9,]   14   14
> 

> On Sep 01, 2021, at 16:59, Eliza Botto <eliza_botto at outlook.com> wrote:
> 
>> dput(A)
> 
> structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
> NA, NA, NA, NA, NA), .Dim = c(9L, 2L))
> 
>> dput(B)
> 
> structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
> 11, 12, 13, 14), .Dim = c(9L, 2L))
> 
>> dput(C)
> 
> structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
> 10, 11, 12, 13, 14), .Dim = c(9L, 2L))


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Sep  1 23:34:25 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 1 Sep 2021 17:34:25 -0400
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
In-Reply-To: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <04b701d79f79$23534d40$69f9e7c0$@verizon.net>

Seems trivial enough Elizabeth, either using a matrix or data.frame.

R is vectorized mostly so A[,1] notation selects a column all at once. Your
condition is thus:

A[,1] == B[,1]

After using your sample data to initialize an A and a B, I get this:

> A[,1] == B[,1]
[1] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE

That Boolean vector can be used to index either of your matrices or any that
have the same number of rows:

Here is one solution using the vectorized ifelse() function:

using <- A[,1] == B[,1]

C <- A

C[, 2 ] <- ifelse(using, B[, 2], A[, 2])

I show the results below and you can tell us if that matches your need on
this sample data:

> A
[,1] [,2]
[1,]   12   NA
[2,]   12   NA
[3,]   12   NA
[4,]   13   NA
[5,]   13   NA
[6,]   13   NA
[7,]   14   NA
[8,]   14   NA
[9,]   14   NA
> B
[,1] [,2]
[1,]   11    6
[2,]   11    7
[3,]   11    8
[4,]   13    9
[5,]   13   10
[6,]   13   11
[7,]   14   12
[8,]   14   13
[9,]   14   14
> C
[,1] [,2]
[1,]   12   NA
[2,]   12   NA
[3,]   12   NA
[4,]   13    9
[5,]   13   10
[6,]   13   11
[7,]   14   12
[8,]   14   13
[9,]   14   14

Of course, the above can be done in fewer steps or many other ways.




-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Eliza Botto
Sent: Wednesday, September 1, 2021 5:00 PM
To: r-help at r-project.org
Subject: [R] conditional replacement of elements of matrix with another
matrix column

deaR useRs,

I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a
way of doing it?

> dput(A)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA, NA, NA, NA,
NA, NA), .Dim = c(9L, 2L))

> dput(B)

structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10, 11, 12, 13,
14), .Dim = c(9L, 2L))

> dput(C)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9, 10, 11, 12,
13, 14), .Dim = c(9L, 2L))

Precisely, I want to replace the elements of 2nd column of A with those of B
provided the elements of 1st column match. Is there a single line loop or
code for that?


Thanks in advance,

Eliza Botto

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@@hr@ng@ @end|ng |rom y@hoo@com  Wed Sep  1 23:48:26 2021
From: m@@hr@ng@ @end|ng |rom y@hoo@com (Mohammad Tanvir Ahamed)
Date: Wed, 1 Sep 2021 21:48:26 +0000 (UTC)
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
In-Reply-To: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <1424132412.2013968.1630532906443@mail.yahoo.com>

C1 <- A
C1[,2][which(B[,1]%in%A[,1])] <- B[,2][which(B[,1]%in%A[,1])]


Regards.............
Tanvir Ahamed 






On Wednesday, 1 September 2021, 11:00:16 pm GMT+2, Eliza Botto <eliza_botto at outlook.com> wrote: 





deaR useRs,

I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a way of doing it?

> dput(A)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
NA, NA, NA, NA, NA), .Dim = c(9L, 2L))

> dput(B)

structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
11, 12, 13, 14), .Dim = c(9L, 2L))

> dput(C)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
10, 11, 12, 13, 14), .Dim = c(9L, 2L))

Precisely, I want to replace the elements of 2nd column of A with those of B provided the elements of 1st column match. Is there a single line loop or code for that?


Thanks in advance,

Eliza Botto

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From e||z@_botto @end|ng |rom out|ook@com  Thu Sep  2 00:00:22 2021
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Wed, 1 Sep 2021 22:00:22 +0000
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
In-Reply-To: <1424132412.2013968.1630532906443@mail.yahoo.com>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <1424132412.2013968.1630532906443@mail.yahoo.com>
Message-ID: <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

I thank you all. But the code doesn't work on my different dataset where A and B have different column lengths. For example,

> dput(A)
structure(c(17897, 17897, 17897, 17897, 17897, 17897, 17897,
17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897,
17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17898,
17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898,
17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898,
17898, 17898, 17898, 17898, 17898, 17899, 17899, 17899, 17899,
17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899,
17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899,
17899, 17899, 17900, 17900, 17900, 17900, 17900, 17900, 17900,
17900, 17900, 17900, 17900, 17900, 17900, 17900, 17900, 17900,
17900, 17900, 17900, 17900, 17900, 17900, 17900, 17900, 17901,
17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901,
17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901,
17901, 17901, 17901, 17901, 17901, 17902, 17902, 17902, 17902,
17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902,
17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902,
17902, 17902, 17903, 17903, 17903, 17903, 17903, 17903, 17903,
17903, 17903, 17903, 17903, 17903, 17903, 17903, 17903, 17903,
17903, 17903, 17903, 17903, 17903, 17903, 17903, 17903, 17904,
17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904,
17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904,
17904, 17904, 17904, 17904, 17904, 17905, 17905, 17905, 17905,
17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905,
17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905,
17905, 17905, 17906, 17906, 17906, 17906, 17906, 17906, 17906,
17906, 17906, 17906, 17906, 17906, 17906, 17906, 17906, 17906,
17906, 17906, 17906, 17906, 17906, 17906, 17906, 17906, 17907,
17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907,
17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907,
17907, 17907, 17907, 17907, 17907, 17908, 17908, 17908, 17908,
17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908,
17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908,
17908, 17908, 17909, 17909, 17909, 17909, 17909, 17909, 17909,
17909, 17909, 17909, 17909, 17909, 17909, 17909, 17909, 17909,
17909, 17909, 17909, 17909, 17909, 17909, 17909, 17909, 17910,
17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910,
17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910,
17910, 17910, 17910, 17910, 17910, 17911, 17911, 17911, 17911,
17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911,
17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911,
17911, 17911, 17912, 17912, 17912, 17912, 17912, 17912, 17912,
17912, 17912, 17912, 17912, 17912, 17912, 17912, 17912, 17912,
17912, 17912, 17912, 17912, 17912, 17912, 17912, 17912, 17913,
17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913,
17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913,
17913, 17913, 17913, 17913, 17913, 17914, 17914, 17914, 17914,
17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914,
17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914,
17914, 17914, 17915, 17915, 17915, 17915, 17915, 17915, 17915,
17915, 17915, 17915, 17915, 17915, 17915, 17915, 17915, 17915,
17915, 17915, 17915, 17915, 17915, 17915, 17915, 17915, 17916,
17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916,
17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916,
17916, 17916, 17916, 17916, 17916, 17917, 17917, 17917, 17917,
17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917,
17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917,
17917, 17917, 17918, 17918, 17918, 17918, 17918, 17918, 17918,
17918, 17918, 17918, 17918, 17918, 17918, 17918, 17918, 17918,
17918, 17918, 17918, 17918, 17918, 17918, 17918, 17918, 17919,
17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919,
17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919,
17919, 17919, 17919, 17919, 17919, 17920, 17920, 17920, 17920,
17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920,
17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920,
17920, 17920, 17921, 17921, 17921, 17921, 17921, 17921, 17921,
17921, 17921, 17921, 17921, 17921, 17921, 17921, 17921, 17921,
17921, 17921, 17921, 17921, 17921, 17921, 17921, 17921, 17922,
17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922,
17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922,
17922, 17922, 17922, 17922, 17922, 17923, 17923, 17923, 17923,
17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923,
17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923,
17923, 17923, 17924, 17924, 17924, 17924, 17924, 17924, 17924,
17924, 17924, 17924, 17924, 17924, 17924, 17924, 17924, 17924,
17924, 17924, 17924, 17924, 17924, 17924, 17924, 17924, 17925,
17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925,
17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925,
17925, 17925, 17925, 17925, 17925, 17926, 17926, 17926, 17926,
17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926,
17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926,
17926, 17926, 17927, 17927, 17927, 17927, 17927, 17927, 17927,
17927, 17927, 17927, 17927, 17927, 17927, 17927, 17927, 17927,
17927, 17927, 17927, 17927, 17927, 17927, 17927, 17927, 17928,
17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928,
17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928,
17928, 17928, 17928, 17928, 17928, 17929, 17929, 17929, 17929,
17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929,
17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929,
17929, 17929, 17930, 17930, 17930, 17930, 17930, 17930, 17930,
17930, 17930, 17930, 17930, 17930, 17930, 17930, 17930, 17930,
17930, 17930, 17930, 17930, 17930, 17930, 17930, 17930, 17931,
17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931,
17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931,
17931, 17931, 17931, 17931, 17931, 17932, 17932, 17932, 17932,
17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932,
17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932,
17932, 17932, 17933, 17933, 17933, 17933, 17933, 17933, 17933,
17933, 17933, 17933, 17933, 17933, 17933, 17933, 17933, 17933,
17933, 17933, 17933, 17933, 17933, 17933, 17933, 17933, 17934,
17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934,
17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934,
17934, 17934, 17934, 17934, 17934, 17935, 17935, 17935, 17935,
17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935,
17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935,
17935, 17935, 17936, 17936, 17936, 17936, 17936, 17936, 17936,
17936, 17936, 17936, 17936, 17936, 17936, 17936, 17936, 17936,
17936, 17936, 17936, 17936, 17936, 17936, 17936, 17936, 17937,
17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937,
17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937,
17937, 17937, 17937, 17937, 17937, 17938, 17938, 17938, 17938,
17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938,
17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938,
17938, 17938, 17939, 17939, 17939, 17939, 17939, 17939, 17939,
17939, 17939, 17939, 17939, 17939, 17939, 17939, 17939, 17939,
17939, 17939, 17939, 17939, 17939, 17939, 17939, 17939, 17940,
17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940,
17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940,
17940, 17940, 17940, 17940, 17940, 17941, 17941, 17941, 17941,
17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941,
17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941,
17941, 17941, 17942, 17942, 17942, 17942, 17942, 17942, 17942,
17942, 17942, 17942, 17942, 17942, 17942, 17942, 17942, 17942,
17942, 17942, 17942, 17942, 17942, 17942, 17942, 17942, 17943,
17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943,
17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943,
17943, 17943, 17943, 17943, 17943, 17944, 17944, 17944, 17944,
17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944,
17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944,
17944, 17944, 17945, 17945, 17945, 17945, 17945, 17945, 17945,
17945, 17945, 17945, 17945, 17945, 17945, 17945, 17945, 17945,
17945, 17945, 17945, 17945, 17945, 17945, 17945, 17945, 17946,
17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946,
17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946,
17946, 17946, 17946, 17946, 17946, 17947, 17947, 17947, 17947,
17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947,
17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947,
17947, 17947, 17948, 17948, 17948, 17948, 17948, 17948, 17948,
17948, 17948, 17948, 17948, 17948, 17948, 17948, 17948, 17948,
17948, 17948, 17948, 17948, 17948, 17948, 17948, 17948, 17949,
17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949,
17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949,
17949, 17949, 17949, 17949, 17949, 17950, 17950, 17950, 17950,
17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950,
17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950,
17950, 17950, 17951, 17951, 17951, 17951, 17951, 17951, 17951,
17951, 17951, 17951, 17951, 17951, 17951, 17951, 17951, 17951,
17951, 17951, 17951, 17951, 17951, 17951, 17951, 17951, 17952,
17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952,
17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952,
17952, 17952, 17952, 17952, 17952, 17953, 17953, 17953, 17953,
17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953,
17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953,
17953, 17953, 17954, 17954, 17954, 17954, 17954, 17954, 17954,
17954, 17954, 17954, 17954, 17954, 17954, 17954, 17954, 17954,
17954, 17954, 17954, 17954, 17954, 17954, 17954, 17954, 17955,
17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955,
17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955,
17955, 17955, 17955, 17955, 17955, 17956, 17956, 17956, 17956,
17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956,
17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956,
17956, 17956, 17957, 17957, 17957, 17957, 17957, 17957, 17957,
17957, 17957, 17957, 17957, 17957, 17957, 17957, 17957, 17957,
17957, 17957, 17957, 17957, 17957, 17957, 17957, 17957, 17958,
17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958,
17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958,
17958, 17958, 17958, 17958, 17958, 17959, 17959, 17959, 17959,
17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959,
17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959,
17959, 17959, 17960, 17960, 17960, 17960, 17960, 17960, 17960,
17960, 17960, 17960, 17960, 17960, 17960, 17960, 17960, 17960,
17960, 17960, 17960, 17960, 17960, 17960, 17960, 17960, 17961,
17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961,
17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961,
17961, 17961, 17961, 17961, 17961, 17962, 17962, 17962, 17962,
17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962,
17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962,
17962, 17962, 17963, 17963, 17963, 17963, 17963, 17963, 17963,
17963, 17963, 17963, 17963, 17963, 17963, 17963, 17963, 17963,
17963, 17963, 17963, 17963, 17963, 17963, 17963, 17963, 17964,
17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964,
17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964,
17964, 17964, 17964, 17964, 17964, 17965, 17965, 17965, 17965,
17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965,
17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965,
17965, 17965, 17966, 17966, 17966, 17966, 17966, 17966, 17966,
17966, 17966, 17966, 17966, 17966, 17966, 17966, 17966, 17966,
17966, 17966, 17966, 17966, 17966, 17966, 17966, 17966, 17967,
17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967,
17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967,
17967, 17967, 17967, 17967, 17967, 17968, 17968, 17968, 17968,
17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968,
17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968,
17968, 17968, 17969, 17969, 17969, 17969, 17969, 17969, 17969,
17969, 17969, 17969, 17969, 17969, 17969, 17969, 17969, 17969,
17969, 17969, 17969, 17969, 17969, 17969, 17969, 17969, 17970,
17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970,
17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970,
17970, 17970, 17970, 17970, 17970, 17971, 17971, 17971, 17971,
17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971,
17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971,
17971, 17971, 17972, 17972, 17972, 17972, 17972, 17972, 17972,
17972, 17972, 17972, 17972, 17972, 17972, 17972, 17972, 17972,
17972, 17972, 17972, 17972, 17972, 17972, 17972, 17972, 17973,
17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973,
17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973,
17973, 17973, 17973, 17973, 17973, 17974, 17974, 17974, 17974,
17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974,
17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974,
17974, 17974, 17975, 17975, 17975, 17975, 17975, 17975, 17975,
17975, 17975, 17975, 17975, 17975, 17975, 17975, 17975, 17975,
17975, 17975, 17975, 17975, 17975, 17975, 17975, 17975, 17976,
17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976,
17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976,
17976, 17976, 17976, 17976, 17976, 17977, 17977, 17977, 17977,
17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977,
17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977,
17977, 17977, 17978, 17978, 17978, 17978, 17978, 17978, 17978,
17978, 17978, 17978, 17978, 17978, 17978, 17978, 17978, 17978,
17978, 17978, 17978, 17978, 17978, 17978, 17978, 17978, 17979,
17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979,
17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979,
17979, 17979, 17979, 17979, 17979, 17980, 17980, 17980, 17980,
17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980,
17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980,
17980, 17980, 17981, 17981, 17981, 17981, 17981, 17981, 17981,
17981, 17981, 17981, 17981, 17981, 17981, 17981, 17981, 17981,
17981, 17981, 17981, 17981, 17981, 17981, 17981, 17981, 17982,
17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982,
17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982,
17982, 17982, 17982, 17982, 17982, 17983, 17983, 17983, 17983,
17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983,
17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983,
17983, 17983, 17984, 17984, 17984, 17984, 17984, 17984, 17984,
17984, 17984, 17984, 17984, 17984, 17984, 17984, 17984, 17984,
17984, 17984, 17984, 17984, 17984, 17984, 17984, 17984, 17985,
17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985,
17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985,
17985, 17985, 17985, 17985, 17985, 17986, 17986, 17986, 17986,
17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986,
17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986,
17986, 17986, 17987, 17987, 17987, 17987, 17987, 17987, 17987,
17987, 17987, 17987, 17987, 17987, 17987, 17987, 17987, 17987,
17987, 17987, 17987, 17987, 17987, 17987, 17987, 17987, 17988,
17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988,
17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988,
17988, 17988, 17988, 17988, 17988, 17989, 17989, 17989, 17989,
17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989,
17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989,
17989, 17989, 17990, 17990, 17990, 17990, 17990, 17990, 17990,
17990, 17990, 17990, 17990, 17990, 17990, 17990, 17990, 17990,
17990, 17990, 17990, 17990, 17990, 17990, 17990, 17990, 17991,
17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991,
17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991,
17991, 17991, 17991, 17991, 17991, 17992, 17992, 17992, 17992,
17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992,
17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992,
17992, 17992, 17993, 17993, 17993, 17993, 17993, 17993, 17993,
17993, 17993, 17993, 17993, 17993, 17993, 17993, 17993, 17993,
17993, 17993, 17993, 17993, 17993, 17993, 17993, 17993, 17994,
17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994,
17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994,
17994, 17994, 17994, 17994, 17994, 17995, 17995, 17995, 17995,
17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995,
17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995,
17995, 17995, 17996, 17996, 17996, 17996, 17996, 17996, 17996,
17996, 17996, 17996, 17996, 17996, 17996, 17996, 17996, 17996,
17996, 17996, 17996, 17996, 17996, 17996, 17996, 17996, 17997,
17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997,
17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997,
17997, 17997, 17997, 17997, 17997, 17998, 17998, 17998, 17998,
17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998,
17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998,
17998, 17998, 17999, 17999, 17999, 17999, 17999, 17999, 17999,
17999, 17999, 17999, 17999, 17999, 17999, 17999, 17999, 17999,
17999, 17999, 17999, 17999, 17999, 17999, 17999, 17999, 18000,
18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000,
18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000,
18000, 18000, 18000, 18000, 18000, 18001, 18001, 18001, 18001,
18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001,
18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001,
18001, 18001, 18002, 18002, 18002, 18002, 18002, 18002, 18002,
18002, 18002, 18002, 18002, 18002, 18002, 18002, 18002, 18002,
18002, 18002, 18002, 18002, 18002, 18002, 18002, 18002, 18003,
18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003,
18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003,
18003, 18003, 18003, 18003, 18003, 18004, 18004, 18004, 18004,
18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004,
18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004,
18004, 18004, 18005, 18005, 18005, 18005, 18005, 18005, 18005,
18005, 18005, 18005, 18005, 18005, 18005, 18005, 18005, 18005,
18005, 18005, 18005, 18005, 18005, 18005, 18005, 18005, 18006,
18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006,
18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006,
18006, 18006, 18006, 18006, 18006, 18007, 18007, 18007, 18007,
18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007,
18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007,
18007, 18007, 18008, 18008, 18008, 18008, 18008, 18008, 18008,
18008, 18008, 18008, 18008, 18008, 18008, 18008, 18008, 18008,
18008, 18008, 18008, 18008, 18008, 18008, 18008, 18008, 18009,
18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009,
18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009,
18009, 18009, 18009, 18009, 18009, 18010, 18010, 18010, 18010,
18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010,
18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010,
18010, 18010, 18011, 18011, 18011, 18011, 18011, 18011, 18011,
18011, 18011, 18011, 18011, 18011, 18011, 18011, 18011, 18011,
18011, 18011, 18011, 18011, 18011, 18011, 18011, 18011, 18012,
18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012,
18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012,
18012, 18012, 18012, 18012, 18012, 18013, 18013, 18013, 18013,
18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013,
18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013,
18013, 18013, 18014, 18014, 18014, 18014, 18014, 18014, 18014,
18014, 18014, 18014, 18014, 18014, 18014, 18014, 18014, 18014,
18014, 18014, 18014, 18014, 18014, 18014, 18014, 18014, 18015,
18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015,
18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015,
18015, 18015, 18015, 18015, 18015, 18016, 18016, 18016, 18016,
18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016,
18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016,
18016, 18016, 18017, 18017, 18017, 18017, 18017, 18017, 18017,
18017, 18017, 18017, 18017, 18017, 18017, 18017, 18017, 18017,
18017, 18017, 18017, 18017, 18017, 18017, 18017, 18017, 18018,
18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018,
18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018,
18018, 18018, 18018, 18018, 18018, 18019, 18019, 18019, 18019,
18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019,
18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019,
18019, 18019, 18020, 18020, 18020, 18020, 18020, 18020, 18020,
18020, 18020, 18020, 18020, 18020, 18020, 18020, 18020, 18020,
18020, 18020, 18020, 18020, 18020, 18020, 18020, 18020, 18021,
18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021,
18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021,
18021, 18021, 18021, 18021, 18021, 18022, 18022, 18022, 18022,
18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022,
18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022,
18022, 18022, 18023, 18023, 18023, 18023, 18023, 18023, 18023,
18023, 18023, 18023, 18023, 18023, 18023, 18023, 18023, 18023,
18023, 18023, 18023, 18023, 18023, 18023, 18023, 18023, 18024,
18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024,
18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024,
18024, 18024, 18024, 18024, 18024, 18025, 18025, 18025, 18025,
18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025,
18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025,
18025, 18025, 18026, 18026, 18026, 18026, 18026, 18026, 18026,
18026, 18026, 18026, 18026, 18026, 18026, 18026, 18026, 18026,
18026, 18026, 18026, 18026, 18026, 18026, 18026, 18026, 18027,
18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027,
18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027,
18027, 18027, 18027, 18027, 18027, 18028, 18028, 18028, 18028,
18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028,
18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028,
18028, 18028, 18029, 18029, 18029, 18029, 18029, 18029, 18029,
18029, 18029, 18029, 18029, 18029, 18029, 18029, 18029, 18029,
18029, 18029, 18029, 18029, 18029, 18029, 18029, 18029, 18030,
18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030,
18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030,
18030, 18030, 18030, 18030, 18030, 18031, 18031, 18031, 18031,
18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031,
18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031,
18031, 18031, 18032, 18032, 18032, 18032, 18032, 18032, 18032,
18032, 18032, 18032, 18032, 18032, 18032, 18032, 18032, 18032,
18032, 18032, 18032, 18032, 18032, 18032, 18032, 18032, 18033,
18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033,
18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033,
18033, 18033, 18033, 18033, 18033, 18034, 18034, 18034, 18034,
18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034,
18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034,
18034, 18034, 18035, 18035, 18035, 18035, 18035, 18035, 18035,
18035, 18035, 18035, 18035, 18035, 18035, 18035, 18035, 18035,
18035, 18035, 18035, 18035, 18035, 18035, 18035, 18035, 18036,
18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036,
18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036,
18036, 18036, 18036, 18036, 18036, 18037, 18037, 18037, 18037,
18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037,
18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037,
18037, 18037, 18038, 18038, 18038, 18038, 18038, 18038, 18038,
18038, 18038, 18038, 18038, 18038, 18038, 18038, 18038, 18038,
18038, 18038, 18038, 18038, 18038, 18038, 18038, 18038, 18039,
18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039,
18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039,
18039, 18039, 18039, 18039, 18039, 18040, 18040, 18040, 18040,
18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040,
18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040,
18040, 18040, 18041, 18041, 18041, 18041, 18041, 18041, 18041,
18041, 18041, 18041, 18041, 18041, 18041, 18041, 18041, 18041,
18041, 18041, 18041, 18041, 18041, 18041, 18041, 18041, 18042,
18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042,
18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042,
18042, 18042, 18042, 18042, 18042, 18043, 18043, 18043, 18043,
18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043,
18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043,
18043, 18043, 18044, 18044, 18044, 18044, 18044, 18044, 18044,
18044, 18044, 18044, 18044, 18044, 18044, 18044, 18044, 18044,
18044, 18044, 18044, 18044, 18044, 18044, 18044, 18044, 18045,
18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045,
18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045,
18045, 18045, 18045, 18045, 18045, 18046, 18046, 18046, 18046,
18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046,
18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046,
18046, 18046, 18047, 18047, 18047, 18047, 18047, 18047, 18047,
18047, 18047, 18047, 18047, 18047, 18047, 18047, 18047, 18047,
18047, 18047, 18047, 18047, 18047, 18047, 18047, 18047, 18048,
18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048,
18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048,
18048, 18048, 18048, 18048, 18048, 18049, 18049, 18049, 18049,
18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049,
18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049,
18049, 18049, 18050, 18050, 18050, 18050, 18050, 18050, 18050,
18050, 18050, 18050, 18050, 18050, 18050, 18050, 18050, 18050,
18050, 18050, 18050, 18050, 18050, 18050, 18050, 18050, 18051,
18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051,
18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051,
18051, 18051, 18051, 18051, 18051, 18052, 18052, 18052, 18052,
18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052,
18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052,
18052, 18052, 18053, 18053, 18053, 18053, 18053, 18053, 18053,
18053, 18053, 18053, 18053, 18053, 18053, 18053, 18053, 18053,
18053, 18053, 18053, 18053, 18053, 18053, 18053, 18053, 18054,
18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054,
18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054,
18054, 18054, 18054, 18054, 18054, 18055, 18055, 18055, 18055,
18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055,
18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055,
18055, 18055, 18056, 18056, 18056, 18056, 18056, 18056, 18056,
18056, 18056, 18056, 18056, 18056, 18056, 18056, 18056, 18056,
18056, 18056, 18056, 18056, 18056, 18056, 18056, 18056, 18057,
18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057,
18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057,
18057, 18057, 18057, 18057, 18057, 18058, 18058, 18058, 18058,
18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058,
18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058,
18058, 18058, 18059, 18059, 18059, 18059, 18059, 18059, 18059,
18059, 18059, 18059, 18059, 18059, 18059, 18059, 18059, 18059,
18059, 18059, 18059, 18059, 18059, 18059, 18059, 18059, 18060,
18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060,
18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060,
18060, 18060, 18060, 18060, 18060, 18061, 18061, 18061, 18061,
18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061,
18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061,
18061, 18061, 18062, 18062, 18062, 18062, 18062, 18062, 18062,
18062, 18062, 18062, 18062, 18062, 18062, 18062, 18062, 18062,
18062, 18062, 18062, 18062, 18062, 18062, 18062, 18062, 18063,
18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063,
18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063,
18063, 18063, 18063, 18063, 18063, 18064, 18064, 18064, 18064,
18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064,
18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064,
18064, 18064, 18065, 18065, 18065, 18065, 18065, 18065, 18065,
18065, 18065, 18065, 18065, 18065, 18065, 18065, 18065, 18065,
18065, 18065, 18065, 18065, 18065, 18065, 18065, 18065, 18066,
18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066,
18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066,
18066, 18066, 18066, 18066, 18066, 18067, 18067, 18067, 18067,
18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067,
18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067,
18067, 18067, 18068, 18068, 18068, 18068, 18068, 18068, 18068,
18068, 18068, 18068, 18068, 18068, 18068, 18068, 18068, 18068,
18068, 18068, 18068, 18068, 18068, 18068, 18068, 18068, 18069,
18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069,
18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069,
18069, 18069, 18069, 18069, 18069, 18070, 18070, 18070, 18070,
18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070,
18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070,
18070, 18070, 18071, 18071, 18071, 18071, 18071, 18071, 18071,
18071, 18071, 18071, 18071, 18071, 18071, 18071, 18071, 18071,
18071, 18071, 18071, 18071, 18071, 18071, 18071, 18071, 18072,
18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072,
18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072,
18072, 18072, 18072, 18072, 18072, 18073, 18073, 18073, 18073,
18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073,
18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073,
18073, 18073, 18074, 18074, 18074, 18074, 18074, 18074, 18074,
18074, 18074, 18074, 18074, 18074, 18074, 18074, 18074, 18074,
18074, 18074, 18074, 18074, 18074, 18074, 18074, 18074, 18075,
18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075,
18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075,
18075, 18075, 18075, 18075, 18075, 18076, 18076, 18076, 18076,
18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076,
18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076,
18076, 18076, 18077, 18077, 18077, 18077, 18077, 18077, 18077,
18077, 18077, 18077, 18077, 18077, 18077, 18077, 18077, 18077,
18077, 18077, 18077, 18077, 18077, 18077, 18077, 18077, 18078,
18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078,
18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078,
18078, 18078, 18078, 18078, 18078, 18079, 18079, 18079, 18079,
18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079,
18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079,
18079, 18079, 18080, 18080, 18080, 18080, 18080, 18080, 18080,
18080, 18080, 18080, 18080, 18080, 18080, 18080, 18080, 18080,
18080, 18080, 18080, 18080, 18080, 18080, 18080, 18080, 18081,
18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081,
18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081,
18081, 18081, 18081, 18081, 18081, 18082, 18082, 18082, 18082,
18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082,
18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082,
18082, 18082, 18083, 18083, 18083, 18083, 18083, 18083, 18083,
18083, 18083, 18083, 18083, 18083, 18083, 18083, 18083, 18083,
18083, 18083, 18083, 18083, 18083, 18083, 18083, 18083, 18084,
18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084,
18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084,
18084, 18084, 18084, 18084, 18084, 18085, 18085, 18085, 18085,
18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085,
18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085,
18085, 18085, 18086, 18086, 18086, 18086, 18086, 18086, 18086,
18086, 18086, 18086, 18086, 18086, 18086, 18086, 18086, 18086,
18086, 18086, 18086, 18086, 18086, 18086, 18086, 18086, 18087,
18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087,
18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087,
18087, 18087, 18087, 18087, 18087, 18088, 18088, 18088, 18088,
18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088,
18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088,
18088, 18088, 18089, 18089, 18089, 18089, 18089, 18089, 18089,
18089, 18089, 18089, 18089, 18089, 18089, 18089, 18089, 18089,
18089, 18089, 18089, 18089, 18089, 18089, 18089, 18089, 18090,
18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090,
18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090,
18090, 18090, 18090, 18090, 18090, 18091, 18091, 18091, 18091,
18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091,
18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091,
18091, 18091, 18092, 18092, 18092, 18092, 18092, 18092, 18092,
18092, 18092, 18092, 18092, 18092, 18092, 18092, 18092, 18092,
18092, 18092, 18092, 18092, 18092, 18092, 18092, 18092, 18093,
18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093,
18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093,
18093, 18093, 18093, 18093, 18093, 18094, 18094, 18094, 18094,
18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094,
18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094,
18094, 18094, 18095, 18095, 18095, 18095, 18095, 18095, 18095,
18095, 18095, 18095, 18095, 18095, 18095, 18095, 18095, 18095,
18095, 18095, 18095, 18095, 18095, 18095, 18095, 18095, 18096,
18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096,
18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096,
18096, 18096, 18096, 18096, 18096, 18097, 18097, 18097, 18097,
18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097,
18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097,
18097, 18097, 18098, 18098, 18098, 18098, 18098, 18098, 18098,
18098, 18098, 18098, 18098, 18098, 18098, 18098, 18098, 18098,
18098, 18098, 18098, 18098, 18098, 18098, 18098, 18098, 18099,
18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099,
18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099,
18099, 18099, 18099, 18099, 18099, 18100, 18100, 18100, 18100,
18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100,
18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100,
18100, 18100, 18101, 18101, 18101, 18101, 18101, 18101, 18101,
18101, 18101, 18101, 18101, 18101, 18101, 18101, 18101, 18101,
18101, 18101, 18101, 18101, 18101, 18101, 18101, 18101, 18102,
18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102,
18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102,
18102, 18102, 18102, 18102, 18102, 18103, 18103, 18103, 18103,
18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103,
18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103,
18103, 18103, 18104, 18104, 18104, 18104, 18104, 18104, 18104,
18104, 18104, 18104, 18104, 18104, 18104, 18104, 18104, 18104,
18104, 18104, 18104, 18104, 18104, 18104, 18104, 18104, 18105,
18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105,
18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105,
18105, 18105, 18105, 18105, 18105, 18106, 18106, 18106, 18106,
18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106,
18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106,
18106, 18106, 18107, 18107, 18107, 18107, 18107, 18107, 18107,
18107, 18107, 18107, 18107, 18107, 18107, 18107, 18107, 18107,
18107, 18107, 18107, 18107, 18107, 18107, 18107, 18107, 18108,
18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108,
18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108,
18108, 18108, 18108, 18108, 18108, 18109, 18109, 18109, 18109,
18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109,
18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109,
18109, 18109, 18110, 18110, 18110, 18110, 18110, 18110, 18110,
18110, 18110, 18110, 18110, 18110, 18110, 18110, 18110, 18110,
18110, 18110, 18110, 18110, 18110, 18110, 18110, 18110, 18111,
18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111,
18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111,
18111, 18111, 18111, 18111, 18111, 18112, 18112, 18112, 18112,
18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112,
18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112,
18112, 18112, 18113, 18113, 18113, 18113, 18113, 18113, 18113,
18113, 18113, 18113, 18113, 18113, 18113, 18113, 18113, 18113,
18113, 18113, 18113, 18113, 18113, 18113, 18113, 18113, 18114,
18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114,
18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114,
18114, 18114, 18114, 18114, 18114, 18115, 18115, 18115, 18115,
18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115,
18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115,
18115, 18115, 18116, 18116, 18116, 18116, 18116, 18116, 18116,
18116, 18116, 18116, 18116, 18116, 18116, 18116, 18116, 18116,
18116, 18116, 18116, 18116, 18116, 18116, 18116, 18116, 18117,
18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117,
18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117,
18117, 18117, 18117, 18117, 18117, 18118, 18118, 18118, 18118,
18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118,
18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118,
18118, 18118, 18119, 18119, 18119, 18119, 18119, 18119, 18119,
18119, 18119, 18119, 18119, 18119, 18119, 18119, 18119, 18119,
18119, 18119, 18119, 18119, 18119, 18119, 18119, 18119, 18120,
18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120,
18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120,
18120, 18120, 18120, 18120, 18120, 18121, 18121, 18121, 18121,
18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121,
18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121,
18121, 18121, 18122, 18122, 18122, 18122, 18122, 18122, 18122,
18122, 18122, 18122, 18122, 18122, 18122, 18122, 18122, 18122,
18122, 18122, 18122, 18122, 18122, 18122, 18122, 18122, 18123,
18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123,
18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123,
18123, 18123, 18123, 18123, 18123, 18124, 18124, 18124, 18124,
18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124,
18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124,
18124, 18124, 18125, 18125, 18125, 18125, 18125, 18125, 18125,
18125, 18125, 18125, 18125, 18125, 18125, 18125, 18125, 18125,
18125, 18125, 18125, 18125, 18125, 18125, 18125, 18125, 18126,
18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126,
18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126,
18126, 18126, 18126, 18126, 18126, 18127, 18127, 18127, 18127,
18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127,
18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127,
18127, 18127, 18128, 18128, 18128, 18128, 18128, 18128, 18128,
18128, 18128, 18128, 18128, 18128, 18128, 18128, 18128, 18128,
18128, 18128, 18128, 18128, 18128, 18128, 18128, 18128, 18129,
18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129,
18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129,
18129, 18129, 18129, 18129, 18129, 18130, 18130, 18130, 18130,
18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130,
18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130,
18130, 18130, 18131, 18131, 18131, 18131, 18131, 18131, 18131,
18131, 18131, 18131, 18131, 18131, 18131, 18131, 18131, 18131,
18131, 18131, 18131, 18131, 18131, 18131, 18131, 18131, 18132,
18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132,
18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132,
18132, 18132, 18132, 18132, 18132, 18133, 18133, 18133, 18133,
18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133,
18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133,
18133, 18133, 18134, 18134, 18134, 18134, 18134, 18134, 18134,
18134, 18134, 18134, 18134, 18134, 18134, 18134, 18134, 18134,
18134, 18134, 18134, 18134, 18134, 18134, 18134, 18134, 18135,
18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135,
18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135,
18135, 18135, 18135, 18135, 18135, 18136, 18136, 18136, 18136,
18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136,
18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136,
18136, 18136, 18137, 18137, 18137, 18137, 18137, 18137, 18137,
18137, 18137, 18137, 18137, 18137, 18137, 18137, 18137, 18137,
18137, 18137, 18137, 18137, 18137, 18137, 18137, 18137, 18138,
18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138,
18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138,
18138, 18138, 18138, 18138, 18138, 18139, 18139, 18139, 18139,
18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139,
18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139,
18139, 18139, 18140, 18140, 18140, 18140, 18140, 18140, 18140,
18140, 18140, 18140, 18140, 18140, 18140, 18140, 18140, 18140,
18140, 18140, 18140, 18140, 18140, 18140, 18140, 18140, 18141,
18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141,
18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141,
18141, 18141, 18141, 18141, 18141, 18142, 18142, 18142, 18142,
18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142,
18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142,
18142, 18142, 18143, 18143, 18143, 18143, 18143, 18143, 18143,
18143, 18143, 18143, 18143, 18143, 18143, 18143, 18143, 18143,
18143, 18143, 18143, 18143, 18143, 18143, 18143, 18143, 18144,
18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144,
18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144,
18144, 18144, 18144, 18144, 18144, 18145, 18145, 18145, 18145,
18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145,
18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145,
18145, 18145, 18146, 18146, 18146, 18146, 18146, 18146, 18146,
18146, 18146, 18146, 18146, 18146, 18146, 18146, 18146, 18146,
18146, 18146, 18146, 18146, 18146, 18146, 18146, 18146, 18147,
18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147,
18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147,
18147, 18147, 18147, 18147, 18147, 18148, 18148, 18148, 18148,
18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148,
18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148,
18148, 18148, 18149, 18149, 18149, 18149, 18149, 18149, 18149,
18149, 18149, 18149, 18149, 18149, 18149, 18149, 18149, 18149,
18149, 18149, 18149, 18149, 18149, 18149, 18149, 18149, 18150,
18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150,
18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150,
18150, 18150, 18150, 18150, 18150, 18151, 18151, 18151, 18151,
18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151,
18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151,
18151, 18151, 18152, 18152, 18152, 18152, 18152, 18152, 18152,
18152, 18152, 18152, 18152, 18152, 18152, 18152, 18152, 18152,
18152, 18152, 18152, 18152, 18152, 18152, 18152, 18152, 18153,
18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153,
18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153,
18153, 18153, 18153, 18153, 18153, 18154, 18154, 18154, 18154,
18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154,
18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154,
18154, 18154, 18155, 18155, 18155, 18155, 18155, 18155, 18155,
18155, 18155, 18155, 18155, 18155, 18155, 18155, 18155, 18155,
18155, 18155, 18155, 18155, 18155, 18155, 18155, 18155, 18156,
18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156,
18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156,
18156, 18156, 18156, 18156, 18156, 18157, 18157, 18157, 18157,
18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157,
18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157,
18157, 18157, 18158, 18158, 18158, 18158, 18158, 18158, 18158,
18158, 18158, 18158, 18158, 18158, 18158, 18158, 18158, 18158,
18158, 18158, 18158, 18158, 18158, 18158, 18158, 18158, 18159,
18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159,
18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159,
18159, 18159, 18159, 18159, 18159, 18160, 18160, 18160, 18160,
18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160,
18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160,
18160, 18160, 18161, 18161, 18161, 18161, 18161, 18161, 18161,
18161, 18161, 18161, 18161, 18161, 18161, 18161, 18161, 18161,
18161, 18161, 18161, 18161, 18161, 18161, 18161, 18161, 18162,
18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162,
18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162,
18162, 18162, 18162, 18162, 18162, 18163, 18163, 18163, 18163,
18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163,
18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163,
18163, 18163, 18164, 18164, 18164, 18164, 18164, 18164, 18164,
18164, 18164, 18164, 18164, 18164, 18164, 18164, 18164, 18164,
18164, 18164, 18164, 18164, 18164, 18164, 18164, 18164, 18165,
18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165,
18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165,
18165, 18165, 18165, 18165, 18165, 18166, 18166, 18166, 18166,
18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166,
18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166,
18166, 18166, 18167, 18167, 18167, 18167, 18167, 18167, 18167,
18167, 18167, 18167, 18167, 18167, 18167, 18167, 18167, 18167,
18167, 18167, 18167, 18167, 18167, 18167, 18167, 18167, 18168,
18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168,
18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168,
18168, 18168, 18168, 18168, 18168, 18169, 18169, 18169, 18169,
18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169,
18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169,
18169, 18169, 18170, 18170, 18170, 18170, 18170, 18170, 18170,
18170, 18170, 18170, 18170, 18170, 18170, 18170, 18170, 18170,
18170, 18170, 18170, 18170, 18170, 18170, 18170, 18170, 18171,
18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171,
18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171,
18171, 18171, 18171, 18171, 18171, 18172, 18172, 18172, 18172,
18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172,
18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172,
18172, 18172, 18173, 18173, 18173, 18173, 18173, 18173, 18173,
18173, 18173, 18173, 18173, 18173, 18173, 18173, 18173, 18173,
18173, 18173, 18173, 18173, 18173, 18173, 18173, 18173, 18174,
18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174,
18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174,
18174, 18174, 18174, 18174, 18174, 18175, 18175, 18175, 18175,
18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175,
18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175,
18175, 18175, 18176, 18176, 18176, 18176, 18176, 18176, 18176,
18176, 18176, 18176, 18176, 18176, 18176, 18176, 18176, 18176,
18176, 18176, 18176, 18176, 18176, 18176, 18176, 18176, 18177,
18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177,
18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177,
18177, 18177, 18177, 18177, 18177, 18178, 18178, 18178, 18178,
18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178,
18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178,
18178, 18178, 18179, 18179, 18179, 18179, 18179, 18179, 18179,
18179, 18179, 18179, 18179, 18179, 18179, 18179, 18179, 18179,
18179, 18179, 18179, 18179, 18179, 18179, 18179, 18179, 18180,
18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180,
18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180,
18180, 18180, 18180, 18180, 18180, 18181, 18181, 18181, 18181,
18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181,
18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181,
18181, 18181, 18182, 18182, 18182, 18182, 18182, 18182, 18182,
18182, 18182, 18182, 18182, 18182, 18182, 18182, 18182, 18182,
18182, 18182, 18182, 18182, 18182, 18182, 18182, 18182, 18183,
18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183,
18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183,
18183, 18183, 18183, 18183, 18183, 18184, 18184, 18184, 18184,
18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184,
18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184,
18184, 18184, 18185, 18185, 18185, 18185, 18185, 18185, 18185,
18185, 18185, 18185, 18185, 18185, 18185, 18185, 18185, 18185,
18185, 18185, 18185, 18185, 18185, 18185, 18185, 18185, 18186,
18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186,
18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186,
18186, 18186, 18186, 18186, 18186, 18187, 18187, 18187, 18187,
18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187,
18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187,
18187, 18187, 18188, 18188, 18188, 18188, 18188, 18188, 18188,
18188, 18188, 18188, 18188, 18188, 18188, 18188, 18188, 18188,
18188, 18188, 18188, 18188, 18188, 18188, 18188, 18188, 18189,
18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189,
18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189,
18189, 18189, 18189, 18189, 18189, 18190, 18190, 18190, 18190,
18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190,
18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190,
18190, 18190, 18191, 18191, 18191, 18191, 18191, 18191, 18191,
18191, 18191, 18191, 18191, 18191, 18191, 18191, 18191, 18191,
18191, 18191, 18191, 18191, 18191, 18191, 18191, 18191, 18192,
18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192,
18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192,
18192, 18192, 18192, 18192, 18192, 18193, 18193, 18193, 18193,
18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193,
18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193,
18193, 18193, 18194, 18194, 18194, 18194, 18194, 18194, 18194,
18194, 18194, 18194, 18194, 18194, 18194, 18194, 18194, 18194,
18194, 18194, 18194, 18194, 18194, 18194, 18194, 18194, 18195,
18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195,
18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195,
18195, 18195, 18195, 18195, 18195, 18196, 18196, 18196, 18196,
18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196,
18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196,
18196, 18196, 18197, 18197, 18197, 18197, 18197, 18197, 18197,
18197, 18197, 18197, 18197, 18197, 18197, 18197, 18197, 18197,
18197, 18197, 18197, 18197, 18197, 18197, 18197, 18197, 18198,
18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198,
18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198,
18198, 18198, 18198, 18198, 18198, 18199, 18199, 18199, 18199,
18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199,
18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199,
18199, 18199, 18200, 18200, 18200, 18200, 18200, 18200, 18200,
18200, 18200, 18200, 18200, 18200, 18200, 18200, 18200, 18200,
18200, 18200, 18200, 18200, 18200, 18200, 18200, 18200, 18201,
18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201,
18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201,
18201, 18201, 18201, 18201, 18201, 18202, 18202, 18202, 18202,
18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202,
18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202,
18202, 18202, 18203, 18203, 18203, 18203, 18203, 18203, 18203,
18203, 18203, 18203, 18203, 18203, 18203, 18203, 18203, 18203,
18203, 18203, 18203, 18203, 18203, 18203, 18203, 18203, 18204,
18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204,
18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204,
18204, 18204, 18204, 18204, 18204, 18205, 18205, 18205, 18205,
18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205,
18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205,
18205, 18205, 18206, 18206, 18206, 18206, 18206, 18206, 18206,
18206, 18206, 18206, 18206, 18206, 18206, 18206, 18206, 18206,
18206, 18206, 18206, 18206, 18206, 18206, 18206, 18206, 18207,
18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207,
18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207,
18207, 18207, 18207, 18207, 18207, 18208, 18208, 18208, 18208,
18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208,
18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208,
18208, 18208, 18209, 18209, 18209, 18209, 18209, 18209, 18209,
18209, 18209, 18209, 18209, 18209, 18209, 18209, 18209, 18209,
18209, 18209, 18209, 18209, 18209, 18209, 18209, 18209, 18210,
18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210,
18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210,
18210, 18210, 18210, 18210, 18210, 18211, 18211, 18211, 18211,
18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211,
18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211,
18211, 18211, 18212, 18212, 18212, 18212, 18212, 18212, 18212,
18212, 18212, 18212, 18212, 18212, 18212, 18212, 18212, 18212,
18212, 18212, 18212, 18212, 18212, 18212, 18212, 18212, 18213,
18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213,
18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213,
18213, 18213, 18213, 18213, 18213, 18214, 18214, 18214, 18214,
18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214,
18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214,
18214, 18214, 18215, 18215, 18215, 18215, 18215, 18215, 18215,
18215, 18215, 18215, 18215, 18215, 18215, 18215, 18215, 18215,
18215, 18215, 18215, 18215, 18215, 18215, 18215, 18215, 18216,
18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216,
18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216,
18216, 18216, 18216, 18216, 18216, 18217, 18217, 18217, 18217,
18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217,
18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217,
18217, 18217, 18218, 18218, 18218, 18218, 18218, 18218, 18218,
18218, 18218, 18218, 18218, 18218, 18218, 18218, 18218, 18218,
18218, 18218, 18218, 18218, 18218, 18218, 18218, 18218, 18219,
18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219,
18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219,
18219, 18219, 18219, 18219, 18219, 18220, 18220, 18220, 18220,
18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220,
18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220,
18220, 18220, 18221, 18221, 18221, 18221, 18221, 18221, 18221,
18221, 18221, 18221, 18221, 18221, 18221, 18221, 18221, 18221,
18221, 18221, 18221, 18221, 18221, 18221, 18221, 18221, 18222,
18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222,
18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222,
18222, 18222, 18222, 18222, 18222, 18223, 18223, 18223, 18223,
18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223,
18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223,
18223, 18223, 18224, 18224, 18224, 18224, 18224, 18224, 18224,
18224, 18224, 18224, 18224, 18224, 18224, 18224, 18224, 18224,
18224, 18224, 18224, 18224, 18224, 18224, 18224, 18224, 18225,
18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225,
18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225,
18225, 18225, 18225, 18225, 18225, 18226, 18226, 18226, 18226,
18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226,
18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226,
18226, 18226, 18227, 18227, 18227, 18227, 18227, 18227, 18227,
18227, 18227, 18227, 18227, 18227, 18227, 18227, 18227, 18227,
18227, 18227, 18227, 18227, 18227, 18227, 18227, 18227, 18228,
18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228,
18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228,
18228, 18228, 18228, 18228, 18228, 18229, 18229, 18229, 18229,
18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229,
18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229,
18229, 18229, 18230, 18230, 18230, 18230, 18230, 18230, 18230,
18230, 18230, 18230, 18230, 18230, 18230, 18230, 18230, 18230,
18230, 18230, 18230, 18230, 18230, 18230, 18230, 18230, 18231,
18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231,
18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231,
18231, 18231, 18231, 18231, 18231, 18232, 18232, 18232, 18232,
18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232,
18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232,
18232, 18232, 18233, 18233, 18233, 18233, 18233, 18233, 18233,
18233, 18233, 18233, 18233, 18233, 18233, 18233, 18233, 18233,
18233, 18233, 18233, 18233, 18233, 18233, 18233, 18233, 18234,
18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234,
18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234,
18234, 18234, 18234, 18234, 18234, 18235, 18235, 18235, 18235,
18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235,
18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235,
18235, 18235, 18236, 18236, 18236, 18236, 18236, 18236, 18236,
18236, 18236, 18236, 18236, 18236, 18236, 18236, 18236, 18236,
18236, 18236, 18236, 18236, 18236, 18236, 18236, 18236, 18237,
18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237,
18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237,
18237, 18237, 18237, 18237, 18237, 18238, 18238, 18238, 18238,
18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238,
18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238,
18238, 18238, 18239, 18239, 18239, 18239, 18239, 18239, 18239,
18239, 18239, 18239, 18239, 18239, 18239, 18239, 18239, 18239,
18239, 18239, 18239, 18239, 18239, 18239, 18239, 18239, 18240,
18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240,
18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240,
18240, 18240, 18240, 18240, 18240, 18241, 18241, 18241, 18241,
18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241,
18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241,
18241, 18241, 18242, 18242, 18242, 18242, 18242, 18242, 18242,
18242, 18242, 18242, 18242, 18242, 18242, 18242, 18242, 18242,
18242, 18242, 18242, 18242, 18242, 18242, 18242, 18242, 18243,
18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243,
18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243,
18243, 18243, 18243, 18243, 18243, 18244, 18244, 18244, 18244,
18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244,
18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244,
18244, 18244, 18245, 18245, 18245, 18245, 18245, 18245, 18245,
18245, 18245, 18245, 18245, 18245, 18245, 18245, 18245, 18245,
18245, 18245, 18245, 18245, 18245, 18245, 18245, 18245, 18246,
18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246,
18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246,
18246, 18246, 18246, 18246, 18246, 18247, 18247, 18247, 18247,
18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247,
18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247,
18247, 18247, 18248, 18248, 18248, 18248, 18248, 18248, 18248,
18248, 18248, 18248, 18248, 18248, 18248, 18248, 18248, 18248,
18248, 18248, 18248, 18248, 18248, 18248, 18248, 18248, 18249,
18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249,
18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249,
18249, 18249, 18249, 18249, 18249, 18250, 18250, 18250, 18250,
18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250,
18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250,
18250, 18250, 18251, 18251, 18251, 18251, 18251, 18251, 18251,
18251, 18251, 18251, 18251, 18251, 18251, 18251, 18251, 18251,
18251, 18251, 18251, 18251, 18251, 18251, 18251, 18251, 18252,
18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252,
18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252,
18252, 18252, 18252, 18252, 18252, 18253, 18253, 18253, 18253,
18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253,
18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253,
18253, 18253, 18254, 18254, 18254, 18254, 18254, 18254, 18254,
18254, 18254, 18254, 18254, 18254, 18254, 18254, 18254, 18254,
18254, 18254, 18254, 18254, 18254, 18254, 18254, 18254, 18255,
18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255,
18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255,
18255, 18255, 18255, 18255, 18255, 18256, 18256, 18256, 18256,
18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256,
18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256,
18256, 18256, 18257, 18257, 18257, 18257, 18257, 18257, 18257,
18257, 18257, 18257, 18257, 18257, 18257, 18257, 18257, 18257,
18257, 18257, 18257, 18257, 18257, 18257, 18257, 18257, 18258,
18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258,
18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258,
18258, 18258, 18258, 18258, 18258, 18259, 18259, 18259, 18259,
18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259,
18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259,
18259, 18259, 18260, 18260, 18260, 18260, 18260, 18260, 18260,
18260, 18260, 18260, 18260, 18260, 18260, 18260, 18260, 18260,
18260, 18260, 18260, 18260, 18260, 18260, 18260, 18260, 18261,
18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261,
18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261,
18261, 18261, 18261, 18261, 18261, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA), .Dim = c(8760L, 2L))


> dput(B)
structure(c(13634, 13635, 13637, 13638, 13639, 13640, 13641,
13642, 13643, 13645, 13646, 13647, 13648, 13649, 13650, 13651,
13652, 13653, 13654, 13655, 13656, 13657, 13658, 13659, 13660,
13661, 13662, 13663, 13664, 13665, 13666, 13667, 13677, 13678,
13680, 13681, 13682, 13684, 13685, 13686, 13687, 13689, 13690,
13691, 13695, 13696, 13697, 13698, 13701, 13702, 13703, 13705,
13706, 13710, 13711, 13712, 13713, 13714, 13715, 13716, 13717,
13718, 13719, 13720, 13721, 13722, 13723, 13724, 13725, 13726,
13727, 13728, 13729, 13730, 13731, 13732, 13733, 13734, 13735,
13736, 13737, 13738, 13739, 13740, 13741, 13742, 13743, 13748,
13749, 13750, 13751, 13752, 13753, 13754, 13755, 14008, 14009,
14010, 14011, 14012, 14013, 14014, 14015, 14016, 14017, 14018,
14019, 14020, 14021, 14022, 14023, 14024, 14025, 14026, 14027,
14028, 14029, 14030, 14031, 14035, 14036, 14037, 14038, 14039,
14040, 14041, 14042, 14043, 14044, 14045, 14046, 14047, 14048,
14049, 14050, 14051, 14052, 14053, 14054, 14055, 14056, 14057,
14058, 14059, 14060, 14061, 14062, 14063, 14064, 14065, 14066,
14067, 14068, 14069, 14070, 14071, 14072, 14073, 14074, 14075,
14076, 14077, 14078, 14079, 14080, 14081, 14082, 14083, 14084,
14085, 14086, 14087, 14088, 14089, 14090, 14091, 14092, 14093,
14094, 14095, 14096, 14097, 14098, 14102, 14103, 14104, 14105,
14106, 14107, 14108, 14109, 14112, 14113, 14114, 14115, 14116,
14117, 14118, 14119, 14120, 14121, 14122, 14371, 14372, 14373,
14375, 14376, 14377, 14378, 14379, 14380, 14381, 14382, 14383,
14384, 14385, 14386, 14387, 14388, 14389, 14390, 14391, 14392,
14393, 14394, 14395, 14396, 14397, 14398, 14399, 14403, 14404,
14405, 14406, 14407, 14408, 14409, 14410, 14411, 14413, 14414,
14415, 14416, 14417, 14418, 14419, 14420, 14421, 14422, 14423,
14424, 14425, 14426, 14427, 14428, 14429, 14430, 14431, 14432,
14433, 14434, 14435, 14436, 14437, 14438, 14439, 14440, 14441,
14442, 14443, 14444, 14445, 14446, 14447, 14448, 14449, 14450,
14451, 14452, 14453, 14455, 14459, 14460, 14461, 14466, 14467,
14468, 14469, 14470, 14471, 14472, 14473, 14474, 14475, 14476,
14477, 14478, 14479, 14480, 14481, 14482, 14483, 14484, 14485,
14486, 14487, 14742, 14746, 14749, 14756, 14767, 14770, 14774,
14776, 14781, 14784, 14788, 14795, 14798, 14802, 14805, 14809,
14812, 14816, 14819, 14826, 14830, 14833, 14837, 14840, 14844,
14847, 14851, 15461, 15462, 15463, 15464, 15465, 15466, 15467,
15468, 15469, 15470, 15471, 15472, 15473, 15474, 15475, 15476,
15477, 15478, 15479, 15480, 15481, 15482, 15483, 15484, 15485,
15486, 15487, 15488, 15489, 15490, 15491, 15492, 15493, 15494,
15495, 15496, 15497, 15498, 15499, 15500, 15501, 15502, 15503,
15504, 15505, 15506, 15507, 15508, 15509, 15510, 15511, 15512,
15513, 15514, 15515, 15516, 15517, 15518, 15519, 15520, 15521,
15522, 15523, 15524, 15525, 15526, 15527, 15528, 15529, 15530,
15531, 15532, 15533, 15534, 15535, 15536, 15537, 15538, 15539,
15540, 15541, 15542, 15543, 15544, 15545, 15546, 15547, 15548,
15549, 15550, 15551, 15552, 15553, 15554, 15555, 15556, 15557,
15558, 15559, 15560, 15561, 15562, 15563, 15564, 15565, 15566,
15567, 15568, 15569, 15570, 15571, 15572, 15573, 15574, 15575,
15576, 15577, 15578, 15579, 15580, 15581, 15582, 15583, 15584,
15585, 15586, 15587, 15825, 15826, 15827, 15828, 15831, 15832,
15833, 15834, 15835, 15836, 15837, 15838, 15839, 15840, 15841,
15848, 15849, 15850, 15851, 15852, 15853, 15854, 15855, 15856,
15857, 15858, 15859, 15862, 15863, 15864, 15865, 15866, 15867,
15868, 15869, 15870, 15871, 15872, 15873, 15874, 15875, 15889,
15890, 15891, 15892, 15893, 15894, 15895, 15896, 15897, 15898,
15899, 15900, 15901, 15902, 15903, 15904, 15905, 15906, 15907,
15908, 15909, 15910, 15911, 15912, 15913, 15914, 15918, 15919,
15920, 15921, 15922, 15923, 15924, 15925, 15926, 15927, 15928,
15929, 15930, 15931, 15932, 15933, 15934, 15935, 15936, 15937,
15938, 15939, 15940, 15941, 15942, 15943, 15944, 15945, 15946,
15947, 15948, 15949, 15950, 15951, 16192, 16193, 16194, 16195,
16196, 16197, 16198, 16199, 16200, 16202, 16203, 16204, 16205,
16206, 16207, 16208, 16209, 16212, 16213, 16214, 16215, 16216,
16217, 16226, 16227, 16228, 16229, 16230, 16231, 16232, 16233,
16238, 16239, 16240, 16241, 16244, 16245, 16246, 16247, 16248,
16249, 16250, 16251, 16252, 16253, 16254, 16255, 16256, 16257,
16258, 16259, 16260, 16261, 16262, 16263, 16264, 16265, 16266,
16267, 16268, 16269, 16270, 16271, 16275, 16276, 16277, 16278,
16279, 16280, 16281, 16282, 16285, 16293, 16294, 16295, 16296,
16297, 16298, 16299, 16300, 16301, 16302, 16303, 16304, 16305,
16306, 16307, 16308, 16309, 16310, 16589, 16603, 16607, 16616,
16632, 16651, 16662, 16971, 16986, 17007, 17023, 17180, 17184,
17189, 17218, 17231, 17239, 17245, 17269, 17273, 17301, 17304,
17315, 17326, 17343, 17367, 17387, 17392, 17393, 17393, 17399,
17416, 17422, 17423, 17427, 17431, 17442, 17455, 17469, 17483,
17494, 17498, 17511, 17528, 17539, 17550, 17553, 17583, 17595,
17603, 17605, 17610, 17611, 17612, 17618, 17619, 17623, 17637,
17651, 17665, 17679, 17682, 17696, 17707, 17721, 17722, 17731,
17735, 17736, 17738, 17751, 17763, 17778, 17791, 18033, 18037,
18053, 18063, 18066, 18114, 18130, 18133, 18148, 3, 32, 88, 126,
8, 2, 2, 4, 5, 5, 60, 1, 1, 1.5, 1.5, 2, 2, 330, 7, 1, 40, 52,
15, 4, 3, 2, 1, 5, 3, 1, 5, 1234, 5, 6, 34, 107, 12, 6, 6, 1,
1, 189, 9, 4, 1, 1, 5, 5, 3, 5, 4, 14, 3, 15, 3.5, 9, 2, 1, 1,
1, 10, 133, 109, 8, 1, 2, 1, 13, 1, 1, 2, 4, 60, 4, 2, 2, 226,
111, 23, 2, 1, 2, 2, 2, 2, 3, 1, 15, 2, 1, 111, 93, 6, 5, 1,
42, 9, 3, 2, 1, 1, 0.75, 1, 0.5, 0.5, 1, 5, 235, 129, 120, 102,
41, 63, 11, 5, 0.75, 257, 45, 7, 164, 161, 223, 111, 175, 158,
76, 39, 39, 22, 5, 4, 3, 4, 3, 6, 4, 13, 2, 137, 5, 3, 2, 2,
1, 47, 1, 1, 1, 256, 29, 51, 427, 54, 15, 131, 52, 6, 329, 111,
43, 9, 2, 87, 11, 3, 5, 6, 12, 17, 3, 5, 306, 28, 5, 3, 0.5,
1, 0.5, 0.5, 4, 1.5, 3, 2, 3, 2, 3, 2, 2, 2, 507, 10, 70, 12,
1, 3, 1, 49, 2, 3, 1, 189, 39, 39, 122, 63, 5, 184, 37, 78, 22,
7, 4, 47, 12, 65, 6, 9, 2, 3, 42, 7, 3, 3, 2, 2, 18, 2, 1, 2,
2, 9, 10, 3, 3, 3, 32, 13, 5, 98, 442, 51, 6, 101, 5, 2, 2, 6,
5, 3, 2, 3, 6, 17, 125, 6, 70, 11, 171, 24.5, 87, 11, 11, 2,
2, 137, 16, 35, 5, 2, 2, 3, 2, 3, 3, 3, 2, 1, 8, 2, 3, 61, 119,
62, 22, 8, 25, 3, 159, 38, 42, 9, 3, 93, 36, 4, 5, 4, 4, 5, 4,
5, 4, 3, 332, 20, 6, 2.5, 7.5, 3, 331, 149.5, 44, 36.5, 311,
427, 3, 43.5, 7, 140, 594, 46, 23, 11, 46, 436, 82.5, 600, 53,
1.5, 9, 4, 40, 8, 6, 6, 6, 13, 141, 11, 4, 2, 4, 1, 1, 1, 1,
1, 1, 1, 21, 6, 4, 1, 1, 553, 93, 41, 40, 4, 2, 2, 4, 1, 3, 2,
17, 3, 5, 951, 138, 6, 67, 24, 66, 3, 4, 167, 259, 32, 4, 8,
143, 64, 4, 3, 25, 68, 119, 8, 57, 61, 2, 2, 4, 3, 2, 3, 2, 12.61666667,
51, 7, 5.916666667, 2, 6, 1, 5, 3, 3, 4.083333333, 8, 7, 1, 1,
17, 4, 3, 12, 1, 1, 1, 2, 3, 3, 1, 1, 19, 18, 3, 1, 1, 1, 1,
1, 4, 4, 3, 121, 94, 13, 4, 4, 1, 2, 1, 1, 1, 1, 1, 83, 4, 1,
4, 2, 1, 1, 2, 5, 3, 1, 1, 23, 6, 12, 28, 12, 4, 4, 4, 3, 10,
5, 6, 36, 5, 8, 386, 177.5, 23, 3, 9, 174, 248, 116, 29, 5, 88,
56, 4, 11, 30, 9, 8, 14, 6, 28, 139.5, 64, 4, 18, 64, 67, 39,
144, 102, 10, 4, 252, 4, 4, 4, 4, 19, 1, 4, 3, 3, 9, 2, 1, 1,
314, 44, 12, 87, 7, 132, 26, 14, 16, 7, 10, 8, 107, 40, 33, 18,
5, 5, 6, 4, 3, 2, 6, 6, 5, 4, 5, 7, 5, 6, 8, 6, 29, 7, 4, 77,
3, 3, 4, 17, 3, 154, 60, 45, 7, 18.5, 8, 5, 118, 56, 6.5, 2,
1, 4, 4, 4, 34, 16, 14, 7, 6, 6, 44, 6, 8.5, 2, 1, 1, 9, 1, 16,
4, 50, 98, 57, 45, 10, 142, 170, 6, 60, 605, 25, 30, 18.5, 19,
9.5, 1, 1, 993.5, 57, 4, 2, 30, 4, 4, 2, 2, 1, 9, 53, 4, 3, 580.75,
60, 45, 21, 25, 44, 18, 10, 27, 534.3333333, 4, 10, 2, 63, 14,
4, 4, 8, 15, 408, 46, 18, 8, 3, 6, 4, 9, 137.5, 428.49, 78.8,
30.49, 9.97, 229.77, 550.175, 167.17, 186.17, 224.855, 609.835,
1180, 130.7077449, 229.6460144, 3, 4, 20, 409.1286324, 18, 452,
4, 4, 107, 8, 487, 2, 9, 1, 159, 329, 324, 2, 10, 174, 67, 1,
42, 43, 4, 3, 3, 104, 9, 1, 1, 4, 32, 1, 1, 2, 238, 237, 190,
214, 156, 240, 29, 2, 374, 36, 4, 18, 419, 2, 5, 3, 277, 340,
1, 216, 93, 1, 4, 2, 3, 42, 78, 190, 40, 808, 80, 266, 66, 42
), .Dim = c(734L, 2L))

Can you please guide me how to implement the given code on this dataset?
I thanyou in advance
________________________________
From: Mohammad Tanvir Ahamed <mashranga at yahoo.com>
Sent: Wednesday 1 September 2021 21:48
To: r-help at r-project.org <r-help at r-project.org>; Eliza Botto <eliza_botto at outlook.com>
Subject: Re: [R] conditional replacement of elements of matrix with another matrix column

C1 <- A
C1[,2][which(B[,1]%in%A[,1])] <- B[,2][which(B[,1]%in%A[,1])]


Regards.............
Tanvir Ahamed






On Wednesday, 1 September 2021, 11:00:16 pm GMT+2, Eliza Botto <eliza_botto at outlook.com> wrote:





deaR useRs,

I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a way of doing it?

> dput(A)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
NA, NA, NA, NA, NA), .Dim = c(9L, 2L))

> dput(B)

structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
11, 12, 13, 14), .Dim = c(9L, 2L))

> dput(C)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
10, 11, 12, 13, 14), .Dim = c(9L, 2L))

Precisely, I want to replace the elements of 2nd column of A with those of B provided the elements of 1st column match. Is there a single line loop or code for that?


Thanks in advance,

Eliza Botto

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Sep  2 00:06:22 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 1 Sep 2021 18:06:22 -0400
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
In-Reply-To: <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <1424132412.2013968.1630532906443@mail.yahoo.com>
 <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <053c01d79f7d$99744020$cc5cc060$@verizon.net>

Why would you ask your question without mentioning that the two vectors may
be of unequal length when your abbreviated example was not like that!

 

You have two CASES here. In one A is longer and in one B is longer. When
they are the same, it does not matter.

 

So in your scenario, consider looking at length(A) and length(B) and
adjusting whatever method you use carefully. You now might need to use 1:N
notation to limit what you are doing so you do not access values out of
bounds.

 

Not going to do it for you. I see others have also supplied variants and .

 

From: Eliza Botto <eliza_botto at outlook.com> 
Sent: Wednesday, September 1, 2021 6:00 PM
To: r-help at r-project.org; Mohammad Tanvir Ahamed <mashranga at yahoo.com>; Avi
Gross <avigross at verizon.net>; Richard M. Heiberger <rmh at temple.edu>
Subject: Re: [R] conditional replacement of elements of matrix with another
matrix column

 

I thank you all. But the code doesn't work on my different dataset where A
and B have different column lengths. For example,

 

> dput(A) 

structure(c(17897, 17897, 17897, 17897, 17897, 17897, 17897, 

17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 

SNIP

 

 

Can you please guide me how to implement the given code on this dataset?

I thanyou in advance

  _____  

From: Mohammad Tanvir Ahamed <mashranga at yahoo.com>
Sent: Wednesday 1 September 2021 21:48
To: r-help at r-project.org <r-help at r-project.org>; Eliza Botto
<eliza_botto at outlook.com>
Subject: Re: [R] conditional replacement of elements of matrix with another
matrix column 

 

C1 <- A
C1[,2][which(B[,1]%in%A[,1])] <- B[,2][which(B[,1]%in%A[,1])]


Regards.............
Tanvir Ahamed 






On Wednesday, 1 September 2021, 11:00:16 pm GMT+2, Eliza Botto
<eliza_botto at outlook.com> wrote: 





deaR useRs,

I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a
way of doing it?

> dput(A)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
NA, NA, NA, NA, NA), .Dim = c(9L, 2L))

> dput(B)

structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
11, 12, 13, 14), .Dim = c(9L, 2L))

> dput(C)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
10, 11, 12, 13, 14), .Dim = c(9L, 2L))

Precisely, I want to replace the elements of 2nd column of A with those of B
provided the elements of 1st column match. Is there a single line loop or
code for that?


Thanks in advance,

Eliza Botto

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Sep  2 00:29:50 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 2 Sep 2021 10:29:50 +1200
Subject: [R] What if there's nothing to dispatch on?
In-Reply-To: <c46921e2-4d2a-09f6-110d-376eb188e327@gmail.com>
References: <20210901155904.33a8f6e0@rolf-Latitude-E7470>
 <c46921e2-4d2a-09f6-110d-376eb188e327@gmail.com>
Message-ID: <20210902102950.0e873a42@rolf-Latitude-E7470>


On Wed, 1 Sep 2021 05:35:03 -0400
Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 31/08/2021 11:59 p.m., Rolf Turner wrote:
> > 
> > I'm trying to build a pair of (S3) methods, a "formula" method and a
> > "default" method.  The methods have a "data" argument.  If the
> > variables in question cannot be found in "data" then they should be
> > sought in the global environment.
> > 
> > My problem is that the generic dispatches on its first argument,
> > which may be a formula (in which case it of course dispatches to
> > the formula method) or the first of the variables.  If this
> > variable exists in the global environment then all is well.  But if
> > it doesn't exist there, then the generic falls over with an error
> > of the form "object 'x' not found" --- because there isn't anything
> > to dispatch on.
> > 
> > I'd *like* to be able to tell the generic that if "x" is not found
> > then it should dispatch to the default method (which will, if the
> > call is sensible, find "x" in "data").
> > 
> > Is there any way to tell the generic to do this?
> > 
> > Or is there any other way out of this dilemma? (Other than "Give up
> > and go to the pub", which I cannot currently do since Auckland is
> > in Level 4 lockdown. :-) )
> > 
> 
> That design is probably not a good idea:  what if one of the
> variables in data matches the name of some other object in the global
> environment? Then it would dispatch on that other object, and things
> won't go well.
> 
> But here's a way to shoot yourself in the foot:
> 
> function(x) {
>    x1 <- try(x, silent = TRUE)
>    if (inherits(x1, "try-error"))
>      foo.default(x)
>    else
>      UseMethod("foo", x)
> }
> 
> Happy shooting!

Thanks Duncan. I don't understand your warning, but.

If I call foo(y ~ x,data=xxx) I want the generic to dispatch to the
formula method.  That method will then look for y and x first in xxx,
and if it can't find them there it then will look for them in the global
environment.

If I call foo(x,y,data=xxx) I want the generic to dispatch to the
default method, irrespective of whether x exists in the global
environment.  I can't figure out how to arrange this.  As before
(if I could arrange for the dispatch to happen as desired) I would want
the method to look for y and x first in xxx, and if it can't find them
there it then will look for them in the global environment.

It doesn't matter there is an "x" in both xxx and in the global
environment; the methods will/should use the "x" from xxx.

I don't see a problem with respect to this issue.

Whatever.  I can't get your shoot-in-the-foot solution to work anyway.

If I set

    xxx <- data.frame(u=1:10,v=rnorm(10))

and do

    foo(x=u,y=v,data=xxx)

I get

> Error in foo.default(x, y, data) : Cannot find x.

The argument names need to match up.  Note that calling foo.default()
directly works:

    foo.default(x=u,y=v,data=xxx)

runs just fine.

I think I'm going to have to give up on the classes-and-methods
approach.  I *think* I can see a way through with a using a single
function and if-statements based on your "try" idea.

Thanks!!!

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From no@p@m @end|ng |rom ||@@e@NA  Thu Sep  2 00:32:30 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Thu, 2 Sep 2021 00:32:30 +0200
Subject: [R] ISO Code for Namibia ('NA')
Message-ID: <sgov20$3kl$1@ciao.gmane.io>

Hi,

how can I look for the ISO code for Namibia 'NA' in a list of ISO codes
which looks something like

	# A tibble: 10 ? 1
	   location_code
	   <chr>
	 1 NC
[...]
	10 NZ

but should look like

	# A tibble: 10 ? 1
	   location_code
	   <chr>
	 1 NA
	 2 NC
[...]
	11 NZ

In other words 'NA' is taken for the missing value NA.

greetings, el


From w||||@mwdun|@p @end|ng |rom gm@||@com  Thu Sep  2 00:41:16 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Wed, 1 Sep 2021 15:41:16 -0700
Subject: [R] ISO Code for Namibia ('NA')
In-Reply-To: <sgov20$3kl$1@ciao.gmane.io>
References: <sgov20$3kl$1@ciao.gmane.io>
Message-ID: <CAHqSRuRx2PQz_RTZfMFaFFZb8XmJnx8w4ztxNp2pLaciOD81ew@mail.gmail.com>

> z <- tibble(Code=c("NA","NZ",NA), Name=c("Namibia","New Zealand","?"))
> z
# A tibble: 3 x 2
  Code  Name
  <chr> <chr>
1 NA    Namibia
2 NZ    New Zealand
3 <NA>  ?
> subset(z, Code=="NA")
# A tibble: 1 x 2
  Code  Name
  <chr> <chr>
1 NA    Namibia
> subset(z, is.na(Code))
# A tibble: 1 x 2
  Code  Name
  <chr> <chr>
1 <NA>  ?
> subset(z, Code==NA_character_)
# A tibble: 0 x 2
# ... with 2 variables: Code <chr>, Name <chr>

On Wed, Sep 1, 2021 at 3:33 PM Dr Eberhard Lisse <nospam at lisse.na> wrote:

> Hi,
>
> how can I look for the ISO code for Namibia 'NA' in a list of ISO codes
> which looks something like
>
>         # A tibble: 10 ? 1
>            location_code
>            <chr>
>          1 NC
> [...]
>         10 NZ
>
> but should look like
>
>         # A tibble: 10 ? 1
>            location_code
>            <chr>
>          1 NA
>          2 NC
> [...]
>         11 NZ
>
> In other words 'NA' is taken for the missing value NA.
>
> greetings, el
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Thu Sep  2 00:57:27 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Wed, 1 Sep 2021 15:57:27 -0700
Subject: [R] What if there's nothing to dispatch on?
In-Reply-To: <20210902102950.0e873a42@rolf-Latitude-E7470>
References: <20210901155904.33a8f6e0@rolf-Latitude-E7470>
 <c46921e2-4d2a-09f6-110d-376eb188e327@gmail.com>
 <20210902102950.0e873a42@rolf-Latitude-E7470>
Message-ID: <CAHqSRuR7JFwPsULje+p+jBjywTC2OpWrvSirjXg+wFryNwor1w@mail.gmail.com>

Is this the kind of thing you are looking for?  It separates the scoping
issue from the method dispatch by defining another S3-generic function,
".foo".

> foo <- function(x, ..., data=NULL) with(data, .foo(x, ...))
> .foo <- function(x, ...) UseMethod(".foo")
> .foo.default <- function(x, ...) cat("default method\n")
> .foo.integer <- function(x, ...) cat("integer method\n")
> .foo.formula <- function(x, ...) cat("formula method\n")
>
> rm(x)
Warning message:
In rm(x) : object 'x' not found
> foo(32L)
integer method
> foo(y~x)
formula method
> foo(x, data=list(x=2.7))
default method
> x <- 45L ; foo(x)
integer method
> x <- 45L ; foo(x, data=list(x=3.4))
default method
> x <- 45L ; foo(x, data=list(x=Y~X1+X2))
formula method

On Wed, Sep 1, 2021 at 3:30 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> On Wed, 1 Sep 2021 05:35:03 -0400
> Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> > On 31/08/2021 11:59 p.m., Rolf Turner wrote:
> > >
> > > I'm trying to build a pair of (S3) methods, a "formula" method and a
> > > "default" method.  The methods have a "data" argument.  If the
> > > variables in question cannot be found in "data" then they should be
> > > sought in the global environment.
> > >
> > > My problem is that the generic dispatches on its first argument,
> > > which may be a formula (in which case it of course dispatches to
> > > the formula method) or the first of the variables.  If this
> > > variable exists in the global environment then all is well.  But if
> > > it doesn't exist there, then the generic falls over with an error
> > > of the form "object 'x' not found" --- because there isn't anything
> > > to dispatch on.
> > >
> > > I'd *like* to be able to tell the generic that if "x" is not found
> > > then it should dispatch to the default method (which will, if the
> > > call is sensible, find "x" in "data").
> > >
> > > Is there any way to tell the generic to do this?
> > >
> > > Or is there any other way out of this dilemma? (Other than "Give up
> > > and go to the pub", which I cannot currently do since Auckland is
> > > in Level 4 lockdown. :-) )
> > >
> >
> > That design is probably not a good idea:  what if one of the
> > variables in data matches the name of some other object in the global
> > environment? Then it would dispatch on that other object, and things
> > won't go well.
> >
> > But here's a way to shoot yourself in the foot:
> >
> > function(x) {
> >    x1 <- try(x, silent = TRUE)
> >    if (inherits(x1, "try-error"))
> >      foo.default(x)
> >    else
> >      UseMethod("foo", x)
> > }
> >
> > Happy shooting!
>
> Thanks Duncan. I don't understand your warning, but.
>
> If I call foo(y ~ x,data=xxx) I want the generic to dispatch to the
> formula method.  That method will then look for y and x first in xxx,
> and if it can't find them there it then will look for them in the global
> environment.
>
> If I call foo(x,y,data=xxx) I want the generic to dispatch to the
> default method, irrespective of whether x exists in the global
> environment.  I can't figure out how to arrange this.  As before
> (if I could arrange for the dispatch to happen as desired) I would want
> the method to look for y and x first in xxx, and if it can't find them
> there it then will look for them in the global environment.
>
> It doesn't matter there is an "x" in both xxx and in the global
> environment; the methods will/should use the "x" from xxx.
>
> I don't see a problem with respect to this issue.
>
> Whatever.  I can't get your shoot-in-the-foot solution to work anyway.
>
> If I set
>
>     xxx <- data.frame(u=1:10,v=rnorm(10))
>
> and do
>
>     foo(x=u,y=v,data=xxx)
>
> I get
>
> > Error in foo.default(x, y, data) : Cannot find x.
>
> The argument names need to match up.  Note that calling foo.default()
> directly works:
>
>     foo.default(x=u,y=v,data=xxx)
>
> runs just fine.
>
> I think I'm going to have to give up on the classes-and-methods
> approach.  I *think* I can see a way through with a using a single
> function and if-statements based on your "try" idea.
>
> Thanks!!!
>
> cheers,
>
> Rolf
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep  2 01:29:32 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 1 Sep 2021 19:29:32 -0400
Subject: [R] What if there's nothing to dispatch on?
In-Reply-To: <20210902102950.0e873a42@rolf-Latitude-E7470>
References: <20210901155904.33a8f6e0@rolf-Latitude-E7470>
 <c46921e2-4d2a-09f6-110d-376eb188e327@gmail.com>
 <20210902102950.0e873a42@rolf-Latitude-E7470>
Message-ID: <6a6ca852-2a8b-7f20-b85f-fadd2c6af769@gmail.com>

On 01/09/2021 6:29 p.m., Rolf Turner wrote:
> 
> On Wed, 1 Sep 2021 05:35:03 -0400
> Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>> On 31/08/2021 11:59 p.m., Rolf Turner wrote:
>>>
>>> I'm trying to build a pair of (S3) methods, a "formula" method and a
>>> "default" method.  The methods have a "data" argument.  If the
>>> variables in question cannot be found in "data" then they should be
>>> sought in the global environment.
>>>
>>> My problem is that the generic dispatches on its first argument,
>>> which may be a formula (in which case it of course dispatches to
>>> the formula method) or the first of the variables.  If this
>>> variable exists in the global environment then all is well.  But if
>>> it doesn't exist there, then the generic falls over with an error
>>> of the form "object 'x' not found" --- because there isn't anything
>>> to dispatch on.
>>>
>>> I'd *like* to be able to tell the generic that if "x" is not found
>>> then it should dispatch to the default method (which will, if the
>>> call is sensible, find "x" in "data").
>>>
>>> Is there any way to tell the generic to do this?
>>>
>>> Or is there any other way out of this dilemma? (Other than "Give up
>>> and go to the pub", which I cannot currently do since Auckland is
>>> in Level 4 lockdown. :-) )
>>>
>>
>> That design is probably not a good idea:  what if one of the
>> variables in data matches the name of some other object in the global
>> environment? Then it would dispatch on that other object, and things
>> won't go well.
>>
>> But here's a way to shoot yourself in the foot:
>>
>> function(x) {
>>     x1 <- try(x, silent = TRUE)
>>     if (inherits(x1, "try-error"))
>>       foo.default(x)
>>     else
>>       UseMethod("foo", x)
>> }
>>
>> Happy shooting!
> 
> Thanks Duncan. I don't understand your warning, but.
> 
> If I call foo(y ~ x,data=xxx) I want the generic to dispatch to the
> formula method.  That method will then look for y and x first in xxx,
> and if it can't find them there it then will look for them in the global
> environment.
> 
> If I call foo(x,y,data=xxx) I want the generic to dispatch to the
> default method, irrespective of whether x exists in the global
> environment.  I can't figure out how to arrange this.  As before
> (if I could arrange for the dispatch to happen as desired) I would want
> the method to look for y and x first in xxx, and if it can't find them
> there it then will look for them in the global environment.
> 
> It doesn't matter there is an "x" in both xxx and in the global
> environment; the methods will/should use the "x" from xxx.
> 
> I don't see a problem with respect to this issue.
> 
> Whatever.  I can't get your shoot-in-the-foot solution to work anyway.
> 
> If I set
> 
>      xxx <- data.frame(u=1:10,v=rnorm(10))
> 
> and do
> 
>      foo(x=u,y=v,data=xxx)
> 
> I get
> 
>> Error in foo.default(x, y, data) : Cannot find x.
> 
> The argument names need to match up.  Note that calling foo.default()
> directly works:
> 
>      foo.default(x=u,y=v,data=xxx)
> 
> runs just fine.
> 
> I think I'm going to have to give up on the classes-and-methods
> approach.  I *think* I can see a way through with a using a single
> function and if-statements based on your "try" idea.
> 

I don't know the header of your foo() method, but let's suppose foo() is

   foo <- function(x, data, ...) {
     UseMethod("foo")
   }

with

   foo.formula <- function(x, data, ...) {
     # do something with the formula x
   }

   foo.default <- function(x, data, ...) {
     # do the default thing.
   }

Now you have

   xxx <- data.frame(u = 1:10, v = rnorm(10))
   foo(x = u, y = v, data = xxx)

You want this to dispatch to the default method, because u is not a 
formula, it's a column in xxx.  But how do you know that?  Maybe in some 
other part of your code you have

   u <- someresponse ~ somepredictor

So now u *is* a formula, and this will dispatch to the formula method, 
causing havoc.

I think Bill's suggestion doesn't help here.  To do what you want to do 
doesn't really match what S3 is designed to do.

Duncan


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Sep  2 04:15:38 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 1 Sep 2021 22:15:38 -0400
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
In-Reply-To: <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <1424132412.2013968.1630532906443@mail.yahoo.com>
 <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <009401d79fa0$6c33b230$449b1690$@verizon.net>

Just for the hell of is I looked at the huge amount of data to see the
lengths:

 

> nrow(A)

[1] 8760

> nrow(B)

[1] 734

> sum(is.na(A[, 2]))

[1] 8760

> sum(is.na(B[, 2]))

[1] 0

 

So it seems your first huge matrix has 8,760 rows where the second entry is
always NA.

 

B seems to have 733 unique values out of 734 entries. For what I call a key
and 192 different values mapped into by the keys.

 

> length(unique(B[,1]))

[1] 733

> length(unique(B[,2]))

[1] 192

 

I now conclude the question was badly phrased, as often happens when English
is not the main language used, or the person asking may have provided an
incomplete request, perhaps based on their misunderstanding.

 

First, matrix A has NOTHING anywhere in the second column other than an NA
placeholder. It has umpteen copies of the same number followed by umpteen of
the next and so on. And specifically exactly 24 copies of each!

 

> table(A[,1])

 

17897 17898 17899 17900 17901 17902 17903 17904 17905 17906 17907 17908
17909 17910 17911 17912 

24    24    24    24    24    24    24    24    24    24    24    24    24
24    24    24 

<<SNIP>>

  18249 18250 18251 18252 18253 18254 18255 18256 18257 18258 18259 18260
18261 

24    24    24    24    24    24    24    24    24    24    24    24    24

 

I have no interest in why any of that is but the problem now strikes me as
different. It is not about what to do when A and B have the same value in
column one at all, especially as they are not at all similar. It is about
table lookup, I think.

 

As such, the request is to do something so that you replace the NA in table
A (probably no need to make a C, albeit that works too) by using column2 in
B for whichever one table A in column one matches, using the corresponding
column two.

 

Such a request can be handled quite a few ways BEFORE or after. I mean
instead of making 24 copies in A, you could just make 24 copies of B, and if
needed sort them.  But more generally, there are many R function in base R
that do all kinds of joins such as merge() or in the dplyr/tidyverse package
albeit some of these may be done on data.frames rather than matrices, albeit
they can easily be converted.

 

And of course many alternatives, some painful, involve iterating over one
matrix while searching the other for a match, or setting up B as a
searchable object that simulates a hash or dictionary in other languages,
such as a named structure.

 

For example, make a named vector containing column two with the names of
column 1:

 

You can now look up items in B_vech using the character representation:

 

Here is the first few lines of B:

 

> head(B)

[,1] [,2]

[1,] 13634    3

[2,] 13635   32

[3,] 13637   88

[4,] 13638  126

[5,] 13639    8

[6,] 13640    2

 

Searching for 13635 works fine:

 

> B_vec[as.character(13635)]

13635 

32 

> B_vec[as.character(13636)]

<NA> 

  NA 

> B_vec[as.character(13637)]

13637 

88

 

But since 13636 is not in the vector, it fails.

 

So to convert A (or a copy called C) becomes fairly simple IFF the set of
numbers in A and B are properly set up.

 

A[,2] <- B_vec[as.character(A[,1])]

 

But are they?

 

> range(A[,1])

[1] 17897 18261

> range(B[,1])

[1] 13634 18148

 

But I think I have wasted enough of my time and of everyone who read this
far on a problem that was not explained and may well still not be what I am
guessing. As noted, probably easiest to solve using a merge.

 

 

 

 

From: Eliza Botto <eliza_botto at outlook.com> 
Sent: Wednesday, September 1, 2021 6:00 PM
To: r-help at r-project.org; Mohammad Tanvir Ahamed <mashranga at yahoo.com>; Avi
Gross <avigross at verizon.net>; Richard M. Heiberger <rmh at temple.edu>
Subject: Re: [R] conditional replacement of elements of matrix with another
matrix column

 

I thank you all. But the code doesn't work on my different dataset where A
and B have different column lengths. For example,

 

> dput(A) 

structure(c(17897, 17897, 17897, 17897, 17897, 17897, 17897, 

17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 

<<SNIP>>

NA), .Dim = c(8760L, 2L))

 

 

> dput(B) 

structure(c(13634, 13635, 13637, 13638, 13639, 13640, 13641, 

13642, 13643, 13645, 13646, 13647, 13648, 13649, 13650, 13651, 

<<SNIP>>

214, 156, 240, 29, 2, 374, 36, 4, 18, 419, 2, 5, 3, 277, 340, 

1, 216, 93, 1, 4, 2, 3, 42, 78, 190, 40, 808, 80, 266, 66, 42

), .Dim = c(734L, 2L))

 

Can you please guide me how to implement the given code on this dataset?

I thanyou in advance

  _____  

From: Mohammad Tanvir Ahamed <mashranga at yahoo.com>
Sent: Wednesday 1 September 2021 21:48
To: r-help at r-project.org <r-help at r-project.org>; Eliza Botto
<eliza_botto at outlook.com>
Subject: Re: [R] conditional replacement of elements of matrix with another
matrix column 

 

C1 <- A
C1[,2][which(B[,1]%in%A[,1])] <- B[,2][which(B[,1]%in%A[,1])]


Regards.............
Tanvir Ahamed 






On Wednesday, 1 September 2021, 11:00:16 pm GMT+2, Eliza Botto
<eliza_botto at outlook.com> wrote: 





deaR useRs,

I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a
way of doing it?

> dput(A)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
NA, NA, NA, NA, NA), .Dim = c(9L, 2L))

> dput(B)

structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
11, 12, 13, 14), .Dim = c(9L, 2L))

> dput(C)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
10, 11, 12, 13, 14), .Dim = c(9L, 2L))

Precisely, I want to replace the elements of 2nd column of A with those of B
provided the elements of 1st column match. Is there a single line loop or
code for that?


Thanks in advance,

Eliza Botto

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From no@p@m @end|ng |rom ||@@e@NA  Thu Sep  2 09:03:55 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Thu, 2 Sep 2021 09:03:55 +0200
Subject: [R] ISO Code for Namibia ('NA')
In-Reply-To: <CAHqSRuRx2PQz_RTZfMFaFFZb8XmJnx8w4ztxNp2pLaciOD81ew@mail.gmail.com>
References: <sgov20$3kl$1@ciao.gmane.io>
 <CAHqSRuRx2PQz_RTZfMFaFFZb8XmJnx8w4ztxNp2pLaciOD81ew@mail.gmail.com>
Message-ID: <00c8e252-067b-608b-6b4a-d34d684ca8d6@lisse.NA>

Thank you.

el


On 02/09/2021 00:41, Bill Dunlap wrote:
>> z <- tibble(Code=c("NA","NZ",NA), Name=c("Namibia","New Zealand","?"))
>> z
> # A tibble: 3 x 2
>    Code  Name
>    <chr> <chr>
> 1 NA    Namibia
> 2 NZ    New Zealand
> 3 <NA>  ?
>> subset(z, Code=="NA")
> # A tibble: 1 x 2
>    Code  Name
>    <chr> <chr>
> 1 NA    Namibia
>> subset(z, is.na(Code))
> # A tibble: 1 x 2
>    Code  Name
>    <chr> <chr>
> 1 <NA>  ?
>> subset(z, Code==NA_character_)
> # A tibble: 0 x 2
> # ... with 2 variables: Code <chr>, Name <chr>
> 
> On Wed, Sep 1, 2021 at 3:33 PM Dr Eberhard Lisse <nospam at lisse.na> wrote:
> 
>> Hi,
>>
>> how can I look for the ISO code for Namibia 'NA' in a list of ISO codes
>> which looks something like
>>
>>          # A tibble: 10 ? 1
>>             location_code
>>             <chr>
>>           1 NC
>> [...]
>>          10 NZ
>>
>> but should look like
>>
>>          # A tibble: 10 ? 1
>>             location_code
>>             <chr>
>>           1 NA
>>           2 NC
>> [...]
>>          11 NZ
>>
>> In other words 'NA' is taken for the missing value NA.
>>
>> greetings, el
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 


-- 
To email me replace 'nospam' with 'el'


From no@p@m @end|ng |rom ||@@e@NA  Thu Sep  2 09:03:55 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Thu, 2 Sep 2021 09:03:55 +0200
Subject: [R] ISO Code for Namibia ('NA')
In-Reply-To: <CAHqSRuRx2PQz_RTZfMFaFFZb8XmJnx8w4ztxNp2pLaciOD81ew@mail.gmail.com>
References: <sgov20$3kl$1@ciao.gmane.io>
 <CAHqSRuRx2PQz_RTZfMFaFFZb8XmJnx8w4ztxNp2pLaciOD81ew@mail.gmail.com>
Message-ID: <00c8e252-067b-608b-6b4a-d34d684ca8d6@lisse.NA>

Thank you.

el


On 02/09/2021 00:41, Bill Dunlap wrote:
>> z <- tibble(Code=c("NA","NZ",NA), Name=c("Namibia","New Zealand","?"))
>> z
> # A tibble: 3 x 2
>    Code  Name
>    <chr> <chr>
> 1 NA    Namibia
> 2 NZ    New Zealand
> 3 <NA>  ?
>> subset(z, Code=="NA")
> # A tibble: 1 x 2
>    Code  Name
>    <chr> <chr>
> 1 NA    Namibia
>> subset(z, is.na(Code))
> # A tibble: 1 x 2
>    Code  Name
>    <chr> <chr>
> 1 <NA>  ?
>> subset(z, Code==NA_character_)
> # A tibble: 0 x 2
> # ... with 2 variables: Code <chr>, Name <chr>
> 
> On Wed, Sep 1, 2021 at 3:33 PM Dr Eberhard Lisse <nospam at lisse.na> wrote:
> 
>> Hi,
>>
>> how can I look for the ISO code for Namibia 'NA' in a list of ISO codes
>> which looks something like
>>
>>          # A tibble: 10 ? 1
>>             location_code
>>             <chr>
>>           1 NC
>> [...]
>>          10 NZ
>>
>> but should look like
>>
>>          # A tibble: 10 ? 1
>>             location_code
>>             <chr>
>>           1 NA
>>           2 NC
>> [...]
>>          11 NZ
>>
>> In other words 'NA' is taken for the missing value NA.
>>
>> greetings, el
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 


-- 
To email me replace 'nospam' with 'el'


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Sep  2 10:54:42 2021
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 2 Sep 2021 10:54:42 +0200
Subject: [R] combining geom_boxplot and geom_point with jitter
Message-ID: <29e2f7e6-b2a7-9b4f-83d3-44bc197f0cac@rgzm.de>

Dear useRs,

I'm having a problem to combine geom_boxplot and geom_point with jitter. 
It is difficult to explain but the code and result should make it clear 
(the example dataset is long so I copy it at the end of the email):

p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
p <- p + geom_boxplot(outlier.shape = NA)
p <- p + geom_point(mapping = aes(shape = NMP_cat), position = 
position_jitterdodge())
print(p)

As you can see in the resulting plot, the points with different shapes 
are dodged across the boxplot categories (colors). I'd like the three 
shapes per color to be restricted in one boxplot color, with jitter of 
course to better visualize the points.

Does that make sense?

I have played with the arguments of position_jitterdodge(), but it seems 
to me that the problem is that the shape aesthetic is not in the 
geom_boxplot() call (but I don't want it there, see below).

For background information, the column used for shape gives some sort of 
"quality" to the points; that's why I want to show the points 
differently, so that it can easily be seen whether "good" points plot in 
the same area as the "bad" points.
Because I'm doing facet plots with other variables, I do not want to 
separate these categories in the boxplots - the resulting plots would be 
overcrowded.

Thank you for the help.
Ivan

---

my_data <- structure(list(Diet = c("Dry lucerne", "Dry lucerne", "Dry 
lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
"Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
"Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
"Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
"Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne",
"Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
"Dry lucerne", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
"Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
"Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
"Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
"Dry grass", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo",
"Dry bamboo", "Dry bamboo"), Software = c("ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax"), NMP_cat = structure(c(1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 
3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 2L, 
2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L), .Label = c("0-5%", "5-10%", 
"10-20%", "20-100%"), class = c("ordered", "factor")), name = 
structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), 
.Label = c("Asfc", "Smfc", "HAsfc9", "HAsfc81", "epLsar", "NewEplsar"), 
class = "factor"), value = c(16.00716636, 12.925787, 14.05932485, 
11.999816, 15.12321532, 12.711474, 12.79565826, 10.900949, 15.90481161, 
12.836045, 16.22778102, 13.565995, 14.71354945, 12.384152, 16.61354777, 
13.714165, 15.91399496, 12.983796, 19.44739619, 15.173215, 16.13761798, 
12.932798, 14.7332952, 12.10277, 10.78710961, 8.762726, 10.16027362, 
8.040399, 14.53444662, 11.527896, 17.38120685, 13.78922, 11.26840546, 
9.426558, 24.01797992, 18.398553, 13.7435699, 11.44385, 14.391873, 
10.757141, 22.39390393, 18.176262, 11.60322022, 9.969118, 11.6099975, 
10.059618, 11.86282935, 10.280864, 16.22473644, 13.562839, 12.46350165, 
10.629406, 23.9347534, 19.062174, 19.58121507, 15.910959, 13.99145447, 
11.352648, 14.38942328, 11.821431, 23.4733371, 18.549503, 13.08142223, 
10.735494, 17.09293046, 13.012834, 28.80020878, 22.447105, 25.74460885, 
19.76834, 14.29106582, 12.233774, 12.03005024, 10.364224, 12.58953574, 
10.30257, 18.07111578, 14.416143, 20.85562751, 16.524047, 21.06132234, 
15.744758, 15.24052683, 11.891487, 11.62446752, 9.14325, 11.75704705, 
10.358542, 13.65568703, 11.766129, 16.98137759, 12.594787, 11.6560954, 
10.32073, 15.46708251, 13.199232, 13.20110131, 11.060226, 16.13986173, 
13.564802, 25.45656859, 20.071231, 24.84006178, 19.335892, 14.4723856, 
11.994841, 12.07940958, 9.470493, 13.93630412, 11.489685, 21.84464295, 
17.806018, 17.4383111, 14.478338, 20.55074297, 16.254467, 30.15238714, 
24.193768, 32.8541897, 25.769585, 32.06966759, 24.507185, 20.53975772, 
15.951186, 11.54494952, 9.676342, 13.56490524, 11.456356, 13.58242208, 
10.919419, 13.55260161, 11.356056, 38.58113502, 31.087536, 23.6753536, 
18.749955, 26.38707155, 20.877856, 26.18252748, 20.758242)), row.names = 
c(NA, -140L), class = c("tbl_df", "tbl", "data.frame"))

-- 
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From c@ghpm m@iii@g oii gm@ii@com  Wed Sep  1 22:50:27 2021
From: c@ghpm m@iii@g oii gm@ii@com (c@ghpm m@iii@g oii gm@ii@com)
Date: Wed, 1 Sep 2021 17:50:27 -0300
Subject: [R] how to install npsm package
In-Reply-To: <CAGgJW76wD-ai58K=QkUrH0yWaG9-6XTR5D8r7J8DuYLL3Pid-g@mail.gmail.com>
References: <012701d79f3e$79cb6300$6d622900$@gmail.com>
 <CAGgJW76wD-ai58K=QkUrH0yWaG9-6XTR5D8r7J8DuYLL3Pid-g@mail.gmail.com>
Message-ID: <017101d79f73$0c73a580$255af080$@gmail.com>

Thank you, Eric. Very useful. 

 

From: Eric Berger <ericjberger at gmail.com> 
Sent: Wednesday, September 1, 2021 12:31 PM
To: caghpm at gmail.com
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] how to install npsm package

 

Instructions can be found at https://github.com/kloke/npsm

 

 

On Wed, Sep 1, 2021 at 6:27 PM <caghpm at gmail.com <mailto:caghpm at gmail.com> > wrote:

I need to install the package "npsm" to follow Kloke & McKean book. However,
npsm is no longer on CRAN. So, please let me know in detail how to proceed
to install it.



Thanks.



Carlos Gonzalez


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep  2 11:28:01 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Sep 2021 10:28:01 +0100
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
In-Reply-To: <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <1424132412.2013968.1630532906443@mail.yahoo.com>
 <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <9ffc93df-e6d1-c123-c6af-c0a774a91e4a@sapo.pt>

Hello,

With the new data, here are two ways.
The first with a for loop. I find it simple and readable.


for(b in unique(B[,1])){
   A[which(A[,1] == b), 2] <- B[which(B[,1] == b), 2]
}
na <- is.na(A[,2])
A[!na, 2]

sum(!na)               # [1] 216
sum(A[,1] %in% B[,1])  # [1] 216

# Another way, with merge
mrg <- merge(as.data.frame(A), as.data.frame(B), by = "V1", all.x = 
TRUE)[c(1, 3)]
sum(!is.na(mrg[[2]]))  # [1] 216

identical(A[,2], mrg[[2]])  # [1] TRUE


Note that mrg is a data.frame, you can coerce back to matrix


A <- as.matrix(mrg)


Hope this helps,

Rui Barradas


?s 23:00 de 01/09/21, Eliza Botto escreveu:
> I thank you all. But the code doesn't work on my different dataset where A and B have different column lengths. For example,
> 
>> dput(A)
> structure(c(17897, 17897, 17897, 17897, 17897, 17897, 17897,
> 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897,
> 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17898,
> 17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898,
> 17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898,
> 17898, 17898, 17898, 17898, 17898, 17899, 17899, 17899, 17899,
> 17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899,
> 17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899,
> 17899, 17899, 17900, 17900, 17900, 17900, 17900, 17900, 17900,
> 17900, 17900, 17900, 17900, 17900, 17900, 17900, 17900, 17900,
> 17900, 17900, 17900, 17900, 17900, 17900, 17900, 17900, 17901,
> 17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901,
> 17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901,
> 17901, 17901, 17901, 17901, 17901, 17902, 17902, 17902, 17902,
> 17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902,
> 17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902,
> 17902, 17902, 17903, 17903, 17903, 17903, 17903, 17903, 17903,
> 17903, 17903, 17903, 17903, 17903, 17903, 17903, 17903, 17903,
> 17903, 17903, 17903, 17903, 17903, 17903, 17903, 17903, 17904,
> 17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904,
> 17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904,
> 17904, 17904, 17904, 17904, 17904, 17905, 17905, 17905, 17905,
> 17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905,
> 17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905,
> 17905, 17905, 17906, 17906, 17906, 17906, 17906, 17906, 17906,
> 17906, 17906, 17906, 17906, 17906, 17906, 17906, 17906, 17906,
> 17906, 17906, 17906, 17906, 17906, 17906, 17906, 17906, 17907,
> 17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907,
> 17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907,
> 17907, 17907, 17907, 17907, 17907, 17908, 17908, 17908, 17908,
> 17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908,
> 17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908,
> 17908, 17908, 17909, 17909, 17909, 17909, 17909, 17909, 17909,
> 17909, 17909, 17909, 17909, 17909, 17909, 17909, 17909, 17909,
> 17909, 17909, 17909, 17909, 17909, 17909, 17909, 17909, 17910,
> 17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910,
> 17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910,
> 17910, 17910, 17910, 17910, 17910, 17911, 17911, 17911, 17911,
> 17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911,
> 17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911,
> 17911, 17911, 17912, 17912, 17912, 17912, 17912, 17912, 17912,
> 17912, 17912, 17912, 17912, 17912, 17912, 17912, 17912, 17912,
> 17912, 17912, 17912, 17912, 17912, 17912, 17912, 17912, 17913,
> 17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913,
> 17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913,
> 17913, 17913, 17913, 17913, 17913, 17914, 17914, 17914, 17914,
> 17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914,
> 17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914,
> 17914, 17914, 17915, 17915, 17915, 17915, 17915, 17915, 17915,
> 17915, 17915, 17915, 17915, 17915, 17915, 17915, 17915, 17915,
> 17915, 17915, 17915, 17915, 17915, 17915, 17915, 17915, 17916,
> 17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916,
> 17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916,
> 17916, 17916, 17916, 17916, 17916, 17917, 17917, 17917, 17917,
> 17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917,
> 17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917,
> 17917, 17917, 17918, 17918, 17918, 17918, 17918, 17918, 17918,
> 17918, 17918, 17918, 17918, 17918, 17918, 17918, 17918, 17918,
> 17918, 17918, 17918, 17918, 17918, 17918, 17918, 17918, 17919,
> 17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919,
> 17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919,
> 17919, 17919, 17919, 17919, 17919, 17920, 17920, 17920, 17920,
> 17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920,
> 17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920,
> 17920, 17920, 17921, 17921, 17921, 17921, 17921, 17921, 17921,
> 17921, 17921, 17921, 17921, 17921, 17921, 17921, 17921, 17921,
> 17921, 17921, 17921, 17921, 17921, 17921, 17921, 17921, 17922,
> 17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922,
> 17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922,
> 17922, 17922, 17922, 17922, 17922, 17923, 17923, 17923, 17923,
> 17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923,
> 17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923,
> 17923, 17923, 17924, 17924, 17924, 17924, 17924, 17924, 17924,
> 17924, 17924, 17924, 17924, 17924, 17924, 17924, 17924, 17924,
> 17924, 17924, 17924, 17924, 17924, 17924, 17924, 17924, 17925,
> 17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925,
> 17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925,
> 17925, 17925, 17925, 17925, 17925, 17926, 17926, 17926, 17926,
> 17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926,
> 17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926,
> 17926, 17926, 17927, 17927, 17927, 17927, 17927, 17927, 17927,
> 17927, 17927, 17927, 17927, 17927, 17927, 17927, 17927, 17927,
> 17927, 17927, 17927, 17927, 17927, 17927, 17927, 17927, 17928,
> 17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928,
> 17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928,
> 17928, 17928, 17928, 17928, 17928, 17929, 17929, 17929, 17929,
> 17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929,
> 17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929,
> 17929, 17929, 17930, 17930, 17930, 17930, 17930, 17930, 17930,
> 17930, 17930, 17930, 17930, 17930, 17930, 17930, 17930, 17930,
> 17930, 17930, 17930, 17930, 17930, 17930, 17930, 17930, 17931,
> 17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931,
> 17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931,
> 17931, 17931, 17931, 17931, 17931, 17932, 17932, 17932, 17932,
> 17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932,
> 17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932,
> 17932, 17932, 17933, 17933, 17933, 17933, 17933, 17933, 17933,
> 17933, 17933, 17933, 17933, 17933, 17933, 17933, 17933, 17933,
> 17933, 17933, 17933, 17933, 17933, 17933, 17933, 17933, 17934,
> 17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934,
> 17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934,
> 17934, 17934, 17934, 17934, 17934, 17935, 17935, 17935, 17935,
> 17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935,
> 17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935,
> 17935, 17935, 17936, 17936, 17936, 17936, 17936, 17936, 17936,
> 17936, 17936, 17936, 17936, 17936, 17936, 17936, 17936, 17936,
> 17936, 17936, 17936, 17936, 17936, 17936, 17936, 17936, 17937,
> 17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937,
> 17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937,
> 17937, 17937, 17937, 17937, 17937, 17938, 17938, 17938, 17938,
> 17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938,
> 17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938,
> 17938, 17938, 17939, 17939, 17939, 17939, 17939, 17939, 17939,
> 17939, 17939, 17939, 17939, 17939, 17939, 17939, 17939, 17939,
> 17939, 17939, 17939, 17939, 17939, 17939, 17939, 17939, 17940,
> 17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940,
> 17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940,
> 17940, 17940, 17940, 17940, 17940, 17941, 17941, 17941, 17941,
> 17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941,
> 17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941,
> 17941, 17941, 17942, 17942, 17942, 17942, 17942, 17942, 17942,
> 17942, 17942, 17942, 17942, 17942, 17942, 17942, 17942, 17942,
> 17942, 17942, 17942, 17942, 17942, 17942, 17942, 17942, 17943,
> 17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943,
> 17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943,
> 17943, 17943, 17943, 17943, 17943, 17944, 17944, 17944, 17944,
> 17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944,
> 17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944,
> 17944, 17944, 17945, 17945, 17945, 17945, 17945, 17945, 17945,
> 17945, 17945, 17945, 17945, 17945, 17945, 17945, 17945, 17945,
> 17945, 17945, 17945, 17945, 17945, 17945, 17945, 17945, 17946,
> 17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946,
> 17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946,
> 17946, 17946, 17946, 17946, 17946, 17947, 17947, 17947, 17947,
> 17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947,
> 17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947,
> 17947, 17947, 17948, 17948, 17948, 17948, 17948, 17948, 17948,
> 17948, 17948, 17948, 17948, 17948, 17948, 17948, 17948, 17948,
> 17948, 17948, 17948, 17948, 17948, 17948, 17948, 17948, 17949,
> 17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949,
> 17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949,
> 17949, 17949, 17949, 17949, 17949, 17950, 17950, 17950, 17950,
> 17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950,
> 17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950,
> 17950, 17950, 17951, 17951, 17951, 17951, 17951, 17951, 17951,
> 17951, 17951, 17951, 17951, 17951, 17951, 17951, 17951, 17951,
> 17951, 17951, 17951, 17951, 17951, 17951, 17951, 17951, 17952,
> 17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952,
> 17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952,
> 17952, 17952, 17952, 17952, 17952, 17953, 17953, 17953, 17953,
> 17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953,
> 17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953,
> 17953, 17953, 17954, 17954, 17954, 17954, 17954, 17954, 17954,
> 17954, 17954, 17954, 17954, 17954, 17954, 17954, 17954, 17954,
> 17954, 17954, 17954, 17954, 17954, 17954, 17954, 17954, 17955,
> 17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955,
> 17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955,
> 17955, 17955, 17955, 17955, 17955, 17956, 17956, 17956, 17956,
> 17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956,
> 17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956,
> 17956, 17956, 17957, 17957, 17957, 17957, 17957, 17957, 17957,
> 17957, 17957, 17957, 17957, 17957, 17957, 17957, 17957, 17957,
> 17957, 17957, 17957, 17957, 17957, 17957, 17957, 17957, 17958,
> 17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958,
> 17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958,
> 17958, 17958, 17958, 17958, 17958, 17959, 17959, 17959, 17959,
> 17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959,
> 17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959,
> 17959, 17959, 17960, 17960, 17960, 17960, 17960, 17960, 17960,
> 17960, 17960, 17960, 17960, 17960, 17960, 17960, 17960, 17960,
> 17960, 17960, 17960, 17960, 17960, 17960, 17960, 17960, 17961,
> 17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961,
> 17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961,
> 17961, 17961, 17961, 17961, 17961, 17962, 17962, 17962, 17962,
> 17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962,
> 17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962,
> 17962, 17962, 17963, 17963, 17963, 17963, 17963, 17963, 17963,
> 17963, 17963, 17963, 17963, 17963, 17963, 17963, 17963, 17963,
> 17963, 17963, 17963, 17963, 17963, 17963, 17963, 17963, 17964,
> 17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964,
> 17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964,
> 17964, 17964, 17964, 17964, 17964, 17965, 17965, 17965, 17965,
> 17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965,
> 17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965,
> 17965, 17965, 17966, 17966, 17966, 17966, 17966, 17966, 17966,
> 17966, 17966, 17966, 17966, 17966, 17966, 17966, 17966, 17966,
> 17966, 17966, 17966, 17966, 17966, 17966, 17966, 17966, 17967,
> 17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967,
> 17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967,
> 17967, 17967, 17967, 17967, 17967, 17968, 17968, 17968, 17968,
> 17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968,
> 17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968,
> 17968, 17968, 17969, 17969, 17969, 17969, 17969, 17969, 17969,
> 17969, 17969, 17969, 17969, 17969, 17969, 17969, 17969, 17969,
> 17969, 17969, 17969, 17969, 17969, 17969, 17969, 17969, 17970,
> 17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970,
> 17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970,
> 17970, 17970, 17970, 17970, 17970, 17971, 17971, 17971, 17971,
> 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971,
> 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971,
> 17971, 17971, 17972, 17972, 17972, 17972, 17972, 17972, 17972,
> 17972, 17972, 17972, 17972, 17972, 17972, 17972, 17972, 17972,
> 17972, 17972, 17972, 17972, 17972, 17972, 17972, 17972, 17973,
> 17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973,
> 17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973,
> 17973, 17973, 17973, 17973, 17973, 17974, 17974, 17974, 17974,
> 17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974,
> 17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974,
> 17974, 17974, 17975, 17975, 17975, 17975, 17975, 17975, 17975,
> 17975, 17975, 17975, 17975, 17975, 17975, 17975, 17975, 17975,
> 17975, 17975, 17975, 17975, 17975, 17975, 17975, 17975, 17976,
> 17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976,
> 17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976,
> 17976, 17976, 17976, 17976, 17976, 17977, 17977, 17977, 17977,
> 17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977,
> 17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977,
> 17977, 17977, 17978, 17978, 17978, 17978, 17978, 17978, 17978,
> 17978, 17978, 17978, 17978, 17978, 17978, 17978, 17978, 17978,
> 17978, 17978, 17978, 17978, 17978, 17978, 17978, 17978, 17979,
> 17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979,
> 17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979,
> 17979, 17979, 17979, 17979, 17979, 17980, 17980, 17980, 17980,
> 17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980,
> 17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980,
> 17980, 17980, 17981, 17981, 17981, 17981, 17981, 17981, 17981,
> 17981, 17981, 17981, 17981, 17981, 17981, 17981, 17981, 17981,
> 17981, 17981, 17981, 17981, 17981, 17981, 17981, 17981, 17982,
> 17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982,
> 17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982,
> 17982, 17982, 17982, 17982, 17982, 17983, 17983, 17983, 17983,
> 17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983,
> 17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983,
> 17983, 17983, 17984, 17984, 17984, 17984, 17984, 17984, 17984,
> 17984, 17984, 17984, 17984, 17984, 17984, 17984, 17984, 17984,
> 17984, 17984, 17984, 17984, 17984, 17984, 17984, 17984, 17985,
> 17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985,
> 17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985,
> 17985, 17985, 17985, 17985, 17985, 17986, 17986, 17986, 17986,
> 17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986,
> 17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986,
> 17986, 17986, 17987, 17987, 17987, 17987, 17987, 17987, 17987,
> 17987, 17987, 17987, 17987, 17987, 17987, 17987, 17987, 17987,
> 17987, 17987, 17987, 17987, 17987, 17987, 17987, 17987, 17988,
> 17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988,
> 17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988,
> 17988, 17988, 17988, 17988, 17988, 17989, 17989, 17989, 17989,
> 17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989,
> 17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989,
> 17989, 17989, 17990, 17990, 17990, 17990, 17990, 17990, 17990,
> 17990, 17990, 17990, 17990, 17990, 17990, 17990, 17990, 17990,
> 17990, 17990, 17990, 17990, 17990, 17990, 17990, 17990, 17991,
> 17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991,
> 17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991,
> 17991, 17991, 17991, 17991, 17991, 17992, 17992, 17992, 17992,
> 17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992,
> 17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992,
> 17992, 17992, 17993, 17993, 17993, 17993, 17993, 17993, 17993,
> 17993, 17993, 17993, 17993, 17993, 17993, 17993, 17993, 17993,
> 17993, 17993, 17993, 17993, 17993, 17993, 17993, 17993, 17994,
> 17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994,
> 17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994,
> 17994, 17994, 17994, 17994, 17994, 17995, 17995, 17995, 17995,
> 17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995,
> 17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995,
> 17995, 17995, 17996, 17996, 17996, 17996, 17996, 17996, 17996,
> 17996, 17996, 17996, 17996, 17996, 17996, 17996, 17996, 17996,
> 17996, 17996, 17996, 17996, 17996, 17996, 17996, 17996, 17997,
> 17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997,
> 17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997,
> 17997, 17997, 17997, 17997, 17997, 17998, 17998, 17998, 17998,
> 17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998,
> 17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998,
> 17998, 17998, 17999, 17999, 17999, 17999, 17999, 17999, 17999,
> 17999, 17999, 17999, 17999, 17999, 17999, 17999, 17999, 17999,
> 17999, 17999, 17999, 17999, 17999, 17999, 17999, 17999, 18000,
> 18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000,
> 18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000,
> 18000, 18000, 18000, 18000, 18000, 18001, 18001, 18001, 18001,
> 18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001,
> 18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001,
> 18001, 18001, 18002, 18002, 18002, 18002, 18002, 18002, 18002,
> 18002, 18002, 18002, 18002, 18002, 18002, 18002, 18002, 18002,
> 18002, 18002, 18002, 18002, 18002, 18002, 18002, 18002, 18003,
> 18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003,
> 18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003,
> 18003, 18003, 18003, 18003, 18003, 18004, 18004, 18004, 18004,
> 18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004,
> 18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004,
> 18004, 18004, 18005, 18005, 18005, 18005, 18005, 18005, 18005,
> 18005, 18005, 18005, 18005, 18005, 18005, 18005, 18005, 18005,
> 18005, 18005, 18005, 18005, 18005, 18005, 18005, 18005, 18006,
> 18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006,
> 18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006,
> 18006, 18006, 18006, 18006, 18006, 18007, 18007, 18007, 18007,
> 18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007,
> 18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007,
> 18007, 18007, 18008, 18008, 18008, 18008, 18008, 18008, 18008,
> 18008, 18008, 18008, 18008, 18008, 18008, 18008, 18008, 18008,
> 18008, 18008, 18008, 18008, 18008, 18008, 18008, 18008, 18009,
> 18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009,
> 18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009,
> 18009, 18009, 18009, 18009, 18009, 18010, 18010, 18010, 18010,
> 18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010,
> 18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010,
> 18010, 18010, 18011, 18011, 18011, 18011, 18011, 18011, 18011,
> 18011, 18011, 18011, 18011, 18011, 18011, 18011, 18011, 18011,
> 18011, 18011, 18011, 18011, 18011, 18011, 18011, 18011, 18012,
> 18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012,
> 18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012,
> 18012, 18012, 18012, 18012, 18012, 18013, 18013, 18013, 18013,
> 18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013,
> 18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013,
> 18013, 18013, 18014, 18014, 18014, 18014, 18014, 18014, 18014,
> 18014, 18014, 18014, 18014, 18014, 18014, 18014, 18014, 18014,
> 18014, 18014, 18014, 18014, 18014, 18014, 18014, 18014, 18015,
> 18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015,
> 18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015,
> 18015, 18015, 18015, 18015, 18015, 18016, 18016, 18016, 18016,
> 18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016,
> 18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016,
> 18016, 18016, 18017, 18017, 18017, 18017, 18017, 18017, 18017,
> 18017, 18017, 18017, 18017, 18017, 18017, 18017, 18017, 18017,
> 18017, 18017, 18017, 18017, 18017, 18017, 18017, 18017, 18018,
> 18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018,
> 18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018,
> 18018, 18018, 18018, 18018, 18018, 18019, 18019, 18019, 18019,
> 18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019,
> 18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019,
> 18019, 18019, 18020, 18020, 18020, 18020, 18020, 18020, 18020,
> 18020, 18020, 18020, 18020, 18020, 18020, 18020, 18020, 18020,
> 18020, 18020, 18020, 18020, 18020, 18020, 18020, 18020, 18021,
> 18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021,
> 18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021,
> 18021, 18021, 18021, 18021, 18021, 18022, 18022, 18022, 18022,
> 18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022,
> 18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022,
> 18022, 18022, 18023, 18023, 18023, 18023, 18023, 18023, 18023,
> 18023, 18023, 18023, 18023, 18023, 18023, 18023, 18023, 18023,
> 18023, 18023, 18023, 18023, 18023, 18023, 18023, 18023, 18024,
> 18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024,
> 18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024,
> 18024, 18024, 18024, 18024, 18024, 18025, 18025, 18025, 18025,
> 18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025,
> 18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025,
> 18025, 18025, 18026, 18026, 18026, 18026, 18026, 18026, 18026,
> 18026, 18026, 18026, 18026, 18026, 18026, 18026, 18026, 18026,
> 18026, 18026, 18026, 18026, 18026, 18026, 18026, 18026, 18027,
> 18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027,
> 18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027,
> 18027, 18027, 18027, 18027, 18027, 18028, 18028, 18028, 18028,
> 18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028,
> 18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028,
> 18028, 18028, 18029, 18029, 18029, 18029, 18029, 18029, 18029,
> 18029, 18029, 18029, 18029, 18029, 18029, 18029, 18029, 18029,
> 18029, 18029, 18029, 18029, 18029, 18029, 18029, 18029, 18030,
> 18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030,
> 18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030,
> 18030, 18030, 18030, 18030, 18030, 18031, 18031, 18031, 18031,
> 18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031,
> 18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031,
> 18031, 18031, 18032, 18032, 18032, 18032, 18032, 18032, 18032,
> 18032, 18032, 18032, 18032, 18032, 18032, 18032, 18032, 18032,
> 18032, 18032, 18032, 18032, 18032, 18032, 18032, 18032, 18033,
> 18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033,
> 18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033,
> 18033, 18033, 18033, 18033, 18033, 18034, 18034, 18034, 18034,
> 18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034,
> 18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034,
> 18034, 18034, 18035, 18035, 18035, 18035, 18035, 18035, 18035,
> 18035, 18035, 18035, 18035, 18035, 18035, 18035, 18035, 18035,
> 18035, 18035, 18035, 18035, 18035, 18035, 18035, 18035, 18036,
> 18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036,
> 18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036,
> 18036, 18036, 18036, 18036, 18036, 18037, 18037, 18037, 18037,
> 18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037,
> 18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037,
> 18037, 18037, 18038, 18038, 18038, 18038, 18038, 18038, 18038,
> 18038, 18038, 18038, 18038, 18038, 18038, 18038, 18038, 18038,
> 18038, 18038, 18038, 18038, 18038, 18038, 18038, 18038, 18039,
> 18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039,
> 18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039,
> 18039, 18039, 18039, 18039, 18039, 18040, 18040, 18040, 18040,
> 18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040,
> 18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040,
> 18040, 18040, 18041, 18041, 18041, 18041, 18041, 18041, 18041,
> 18041, 18041, 18041, 18041, 18041, 18041, 18041, 18041, 18041,
> 18041, 18041, 18041, 18041, 18041, 18041, 18041, 18041, 18042,
> 18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042,
> 18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042,
> 18042, 18042, 18042, 18042, 18042, 18043, 18043, 18043, 18043,
> 18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043,
> 18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043,
> 18043, 18043, 18044, 18044, 18044, 18044, 18044, 18044, 18044,
> 18044, 18044, 18044, 18044, 18044, 18044, 18044, 18044, 18044,
> 18044, 18044, 18044, 18044, 18044, 18044, 18044, 18044, 18045,
> 18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045,
> 18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045,
> 18045, 18045, 18045, 18045, 18045, 18046, 18046, 18046, 18046,
> 18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046,
> 18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046,
> 18046, 18046, 18047, 18047, 18047, 18047, 18047, 18047, 18047,
> 18047, 18047, 18047, 18047, 18047, 18047, 18047, 18047, 18047,
> 18047, 18047, 18047, 18047, 18047, 18047, 18047, 18047, 18048,
> 18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048,
> 18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048,
> 18048, 18048, 18048, 18048, 18048, 18049, 18049, 18049, 18049,
> 18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049,
> 18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049,
> 18049, 18049, 18050, 18050, 18050, 18050, 18050, 18050, 18050,
> 18050, 18050, 18050, 18050, 18050, 18050, 18050, 18050, 18050,
> 18050, 18050, 18050, 18050, 18050, 18050, 18050, 18050, 18051,
> 18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051,
> 18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051,
> 18051, 18051, 18051, 18051, 18051, 18052, 18052, 18052, 18052,
> 18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052,
> 18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052,
> 18052, 18052, 18053, 18053, 18053, 18053, 18053, 18053, 18053,
> 18053, 18053, 18053, 18053, 18053, 18053, 18053, 18053, 18053,
> 18053, 18053, 18053, 18053, 18053, 18053, 18053, 18053, 18054,
> 18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054,
> 18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054,
> 18054, 18054, 18054, 18054, 18054, 18055, 18055, 18055, 18055,
> 18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055,
> 18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055,
> 18055, 18055, 18056, 18056, 18056, 18056, 18056, 18056, 18056,
> 18056, 18056, 18056, 18056, 18056, 18056, 18056, 18056, 18056,
> 18056, 18056, 18056, 18056, 18056, 18056, 18056, 18056, 18057,
> 18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057,
> 18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057,
> 18057, 18057, 18057, 18057, 18057, 18058, 18058, 18058, 18058,
> 18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058,
> 18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058,
> 18058, 18058, 18059, 18059, 18059, 18059, 18059, 18059, 18059,
> 18059, 18059, 18059, 18059, 18059, 18059, 18059, 18059, 18059,
> 18059, 18059, 18059, 18059, 18059, 18059, 18059, 18059, 18060,
> 18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060,
> 18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060,
> 18060, 18060, 18060, 18060, 18060, 18061, 18061, 18061, 18061,
> 18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061,
> 18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061,
> 18061, 18061, 18062, 18062, 18062, 18062, 18062, 18062, 18062,
> 18062, 18062, 18062, 18062, 18062, 18062, 18062, 18062, 18062,
> 18062, 18062, 18062, 18062, 18062, 18062, 18062, 18062, 18063,
> 18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063,
> 18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063,
> 18063, 18063, 18063, 18063, 18063, 18064, 18064, 18064, 18064,
> 18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064,
> 18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064,
> 18064, 18064, 18065, 18065, 18065, 18065, 18065, 18065, 18065,
> 18065, 18065, 18065, 18065, 18065, 18065, 18065, 18065, 18065,
> 18065, 18065, 18065, 18065, 18065, 18065, 18065, 18065, 18066,
> 18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066,
> 18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066,
> 18066, 18066, 18066, 18066, 18066, 18067, 18067, 18067, 18067,
> 18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067,
> 18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067,
> 18067, 18067, 18068, 18068, 18068, 18068, 18068, 18068, 18068,
> 18068, 18068, 18068, 18068, 18068, 18068, 18068, 18068, 18068,
> 18068, 18068, 18068, 18068, 18068, 18068, 18068, 18068, 18069,
> 18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069,
> 18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069,
> 18069, 18069, 18069, 18069, 18069, 18070, 18070, 18070, 18070,
> 18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070,
> 18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070,
> 18070, 18070, 18071, 18071, 18071, 18071, 18071, 18071, 18071,
> 18071, 18071, 18071, 18071, 18071, 18071, 18071, 18071, 18071,
> 18071, 18071, 18071, 18071, 18071, 18071, 18071, 18071, 18072,
> 18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072,
> 18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072,
> 18072, 18072, 18072, 18072, 18072, 18073, 18073, 18073, 18073,
> 18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073,
> 18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073,
> 18073, 18073, 18074, 18074, 18074, 18074, 18074, 18074, 18074,
> 18074, 18074, 18074, 18074, 18074, 18074, 18074, 18074, 18074,
> 18074, 18074, 18074, 18074, 18074, 18074, 18074, 18074, 18075,
> 18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075,
> 18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075,
> 18075, 18075, 18075, 18075, 18075, 18076, 18076, 18076, 18076,
> 18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076,
> 18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076,
> 18076, 18076, 18077, 18077, 18077, 18077, 18077, 18077, 18077,
> 18077, 18077, 18077, 18077, 18077, 18077, 18077, 18077, 18077,
> 18077, 18077, 18077, 18077, 18077, 18077, 18077, 18077, 18078,
> 18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078,
> 18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078,
> 18078, 18078, 18078, 18078, 18078, 18079, 18079, 18079, 18079,
> 18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079,
> 18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079,
> 18079, 18079, 18080, 18080, 18080, 18080, 18080, 18080, 18080,
> 18080, 18080, 18080, 18080, 18080, 18080, 18080, 18080, 18080,
> 18080, 18080, 18080, 18080, 18080, 18080, 18080, 18080, 18081,
> 18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081,
> 18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081,
> 18081, 18081, 18081, 18081, 18081, 18082, 18082, 18082, 18082,
> 18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082,
> 18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082,
> 18082, 18082, 18083, 18083, 18083, 18083, 18083, 18083, 18083,
> 18083, 18083, 18083, 18083, 18083, 18083, 18083, 18083, 18083,
> 18083, 18083, 18083, 18083, 18083, 18083, 18083, 18083, 18084,
> 18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084,
> 18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084,
> 18084, 18084, 18084, 18084, 18084, 18085, 18085, 18085, 18085,
> 18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085,
> 18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085,
> 18085, 18085, 18086, 18086, 18086, 18086, 18086, 18086, 18086,
> 18086, 18086, 18086, 18086, 18086, 18086, 18086, 18086, 18086,
> 18086, 18086, 18086, 18086, 18086, 18086, 18086, 18086, 18087,
> 18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087,
> 18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087,
> 18087, 18087, 18087, 18087, 18087, 18088, 18088, 18088, 18088,
> 18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088,
> 18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088,
> 18088, 18088, 18089, 18089, 18089, 18089, 18089, 18089, 18089,
> 18089, 18089, 18089, 18089, 18089, 18089, 18089, 18089, 18089,
> 18089, 18089, 18089, 18089, 18089, 18089, 18089, 18089, 18090,
> 18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090,
> 18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090,
> 18090, 18090, 18090, 18090, 18090, 18091, 18091, 18091, 18091,
> 18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091,
> 18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091,
> 18091, 18091, 18092, 18092, 18092, 18092, 18092, 18092, 18092,
> 18092, 18092, 18092, 18092, 18092, 18092, 18092, 18092, 18092,
> 18092, 18092, 18092, 18092, 18092, 18092, 18092, 18092, 18093,
> 18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093,
> 18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093,
> 18093, 18093, 18093, 18093, 18093, 18094, 18094, 18094, 18094,
> 18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094,
> 18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094,
> 18094, 18094, 18095, 18095, 18095, 18095, 18095, 18095, 18095,
> 18095, 18095, 18095, 18095, 18095, 18095, 18095, 18095, 18095,
> 18095, 18095, 18095, 18095, 18095, 18095, 18095, 18095, 18096,
> 18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096,
> 18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096,
> 18096, 18096, 18096, 18096, 18096, 18097, 18097, 18097, 18097,
> 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097,
> 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097,
> 18097, 18097, 18098, 18098, 18098, 18098, 18098, 18098, 18098,
> 18098, 18098, 18098, 18098, 18098, 18098, 18098, 18098, 18098,
> 18098, 18098, 18098, 18098, 18098, 18098, 18098, 18098, 18099,
> 18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099,
> 18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099,
> 18099, 18099, 18099, 18099, 18099, 18100, 18100, 18100, 18100,
> 18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100,
> 18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100,
> 18100, 18100, 18101, 18101, 18101, 18101, 18101, 18101, 18101,
> 18101, 18101, 18101, 18101, 18101, 18101, 18101, 18101, 18101,
> 18101, 18101, 18101, 18101, 18101, 18101, 18101, 18101, 18102,
> 18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102,
> 18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102,
> 18102, 18102, 18102, 18102, 18102, 18103, 18103, 18103, 18103,
> 18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103,
> 18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103,
> 18103, 18103, 18104, 18104, 18104, 18104, 18104, 18104, 18104,
> 18104, 18104, 18104, 18104, 18104, 18104, 18104, 18104, 18104,
> 18104, 18104, 18104, 18104, 18104, 18104, 18104, 18104, 18105,
> 18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105,
> 18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105,
> 18105, 18105, 18105, 18105, 18105, 18106, 18106, 18106, 18106,
> 18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106,
> 18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106,
> 18106, 18106, 18107, 18107, 18107, 18107, 18107, 18107, 18107,
> 18107, 18107, 18107, 18107, 18107, 18107, 18107, 18107, 18107,
> 18107, 18107, 18107, 18107, 18107, 18107, 18107, 18107, 18108,
> 18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108,
> 18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108,
> 18108, 18108, 18108, 18108, 18108, 18109, 18109, 18109, 18109,
> 18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109,
> 18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109,
> 18109, 18109, 18110, 18110, 18110, 18110, 18110, 18110, 18110,
> 18110, 18110, 18110, 18110, 18110, 18110, 18110, 18110, 18110,
> 18110, 18110, 18110, 18110, 18110, 18110, 18110, 18110, 18111,
> 18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111,
> 18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111,
> 18111, 18111, 18111, 18111, 18111, 18112, 18112, 18112, 18112,
> 18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112,
> 18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112,
> 18112, 18112, 18113, 18113, 18113, 18113, 18113, 18113, 18113,
> 18113, 18113, 18113, 18113, 18113, 18113, 18113, 18113, 18113,
> 18113, 18113, 18113, 18113, 18113, 18113, 18113, 18113, 18114,
> 18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114,
> 18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114,
> 18114, 18114, 18114, 18114, 18114, 18115, 18115, 18115, 18115,
> 18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115,
> 18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115,
> 18115, 18115, 18116, 18116, 18116, 18116, 18116, 18116, 18116,
> 18116, 18116, 18116, 18116, 18116, 18116, 18116, 18116, 18116,
> 18116, 18116, 18116, 18116, 18116, 18116, 18116, 18116, 18117,
> 18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117,
> 18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117,
> 18117, 18117, 18117, 18117, 18117, 18118, 18118, 18118, 18118,
> 18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118,
> 18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118,
> 18118, 18118, 18119, 18119, 18119, 18119, 18119, 18119, 18119,
> 18119, 18119, 18119, 18119, 18119, 18119, 18119, 18119, 18119,
> 18119, 18119, 18119, 18119, 18119, 18119, 18119, 18119, 18120,
> 18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120,
> 18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120,
> 18120, 18120, 18120, 18120, 18120, 18121, 18121, 18121, 18121,
> 18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121,
> 18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121,
> 18121, 18121, 18122, 18122, 18122, 18122, 18122, 18122, 18122,
> 18122, 18122, 18122, 18122, 18122, 18122, 18122, 18122, 18122,
> 18122, 18122, 18122, 18122, 18122, 18122, 18122, 18122, 18123,
> 18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123,
> 18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123,
> 18123, 18123, 18123, 18123, 18123, 18124, 18124, 18124, 18124,
> 18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124,
> 18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124,
> 18124, 18124, 18125, 18125, 18125, 18125, 18125, 18125, 18125,
> 18125, 18125, 18125, 18125, 18125, 18125, 18125, 18125, 18125,
> 18125, 18125, 18125, 18125, 18125, 18125, 18125, 18125, 18126,
> 18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126,
> 18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126,
> 18126, 18126, 18126, 18126, 18126, 18127, 18127, 18127, 18127,
> 18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127,
> 18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127,
> 18127, 18127, 18128, 18128, 18128, 18128, 18128, 18128, 18128,
> 18128, 18128, 18128, 18128, 18128, 18128, 18128, 18128, 18128,
> 18128, 18128, 18128, 18128, 18128, 18128, 18128, 18128, 18129,
> 18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129,
> 18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129,
> 18129, 18129, 18129, 18129, 18129, 18130, 18130, 18130, 18130,
> 18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130,
> 18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130,
> 18130, 18130, 18131, 18131, 18131, 18131, 18131, 18131, 18131,
> 18131, 18131, 18131, 18131, 18131, 18131, 18131, 18131, 18131,
> 18131, 18131, 18131, 18131, 18131, 18131, 18131, 18131, 18132,
> 18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132,
> 18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132,
> 18132, 18132, 18132, 18132, 18132, 18133, 18133, 18133, 18133,
> 18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133,
> 18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133,
> 18133, 18133, 18134, 18134, 18134, 18134, 18134, 18134, 18134,
> 18134, 18134, 18134, 18134, 18134, 18134, 18134, 18134, 18134,
> 18134, 18134, 18134, 18134, 18134, 18134, 18134, 18134, 18135,
> 18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135,
> 18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135,
> 18135, 18135, 18135, 18135, 18135, 18136, 18136, 18136, 18136,
> 18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136,
> 18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136,
> 18136, 18136, 18137, 18137, 18137, 18137, 18137, 18137, 18137,
> 18137, 18137, 18137, 18137, 18137, 18137, 18137, 18137, 18137,
> 18137, 18137, 18137, 18137, 18137, 18137, 18137, 18137, 18138,
> 18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138,
> 18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138,
> 18138, 18138, 18138, 18138, 18138, 18139, 18139, 18139, 18139,
> 18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139,
> 18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139,
> 18139, 18139, 18140, 18140, 18140, 18140, 18140, 18140, 18140,
> 18140, 18140, 18140, 18140, 18140, 18140, 18140, 18140, 18140,
> 18140, 18140, 18140, 18140, 18140, 18140, 18140, 18140, 18141,
> 18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141,
> 18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141,
> 18141, 18141, 18141, 18141, 18141, 18142, 18142, 18142, 18142,
> 18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142,
> 18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142,
> 18142, 18142, 18143, 18143, 18143, 18143, 18143, 18143, 18143,
> 18143, 18143, 18143, 18143, 18143, 18143, 18143, 18143, 18143,
> 18143, 18143, 18143, 18143, 18143, 18143, 18143, 18143, 18144,
> 18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144,
> 18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144,
> 18144, 18144, 18144, 18144, 18144, 18145, 18145, 18145, 18145,
> 18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145,
> 18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145,
> 18145, 18145, 18146, 18146, 18146, 18146, 18146, 18146, 18146,
> 18146, 18146, 18146, 18146, 18146, 18146, 18146, 18146, 18146,
> 18146, 18146, 18146, 18146, 18146, 18146, 18146, 18146, 18147,
> 18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147,
> 18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147,
> 18147, 18147, 18147, 18147, 18147, 18148, 18148, 18148, 18148,
> 18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148,
> 18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148,
> 18148, 18148, 18149, 18149, 18149, 18149, 18149, 18149, 18149,
> 18149, 18149, 18149, 18149, 18149, 18149, 18149, 18149, 18149,
> 18149, 18149, 18149, 18149, 18149, 18149, 18149, 18149, 18150,
> 18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150,
> 18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150,
> 18150, 18150, 18150, 18150, 18150, 18151, 18151, 18151, 18151,
> 18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151,
> 18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151,
> 18151, 18151, 18152, 18152, 18152, 18152, 18152, 18152, 18152,
> 18152, 18152, 18152, 18152, 18152, 18152, 18152, 18152, 18152,
> 18152, 18152, 18152, 18152, 18152, 18152, 18152, 18152, 18153,
> 18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153,
> 18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153,
> 18153, 18153, 18153, 18153, 18153, 18154, 18154, 18154, 18154,
> 18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154,
> 18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154,
> 18154, 18154, 18155, 18155, 18155, 18155, 18155, 18155, 18155,
> 18155, 18155, 18155, 18155, 18155, 18155, 18155, 18155, 18155,
> 18155, 18155, 18155, 18155, 18155, 18155, 18155, 18155, 18156,
> 18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156,
> 18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156,
> 18156, 18156, 18156, 18156, 18156, 18157, 18157, 18157, 18157,
> 18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157,
> 18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157,
> 18157, 18157, 18158, 18158, 18158, 18158, 18158, 18158, 18158,
> 18158, 18158, 18158, 18158, 18158, 18158, 18158, 18158, 18158,
> 18158, 18158, 18158, 18158, 18158, 18158, 18158, 18158, 18159,
> 18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159,
> 18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159,
> 18159, 18159, 18159, 18159, 18159, 18160, 18160, 18160, 18160,
> 18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160,
> 18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160,
> 18160, 18160, 18161, 18161, 18161, 18161, 18161, 18161, 18161,
> 18161, 18161, 18161, 18161, 18161, 18161, 18161, 18161, 18161,
> 18161, 18161, 18161, 18161, 18161, 18161, 18161, 18161, 18162,
> 18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162,
> 18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162,
> 18162, 18162, 18162, 18162, 18162, 18163, 18163, 18163, 18163,
> 18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163,
> 18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163,
> 18163, 18163, 18164, 18164, 18164, 18164, 18164, 18164, 18164,
> 18164, 18164, 18164, 18164, 18164, 18164, 18164, 18164, 18164,
> 18164, 18164, 18164, 18164, 18164, 18164, 18164, 18164, 18165,
> 18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165,
> 18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165,
> 18165, 18165, 18165, 18165, 18165, 18166, 18166, 18166, 18166,
> 18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166,
> 18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166,
> 18166, 18166, 18167, 18167, 18167, 18167, 18167, 18167, 18167,
> 18167, 18167, 18167, 18167, 18167, 18167, 18167, 18167, 18167,
> 18167, 18167, 18167, 18167, 18167, 18167, 18167, 18167, 18168,
> 18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168,
> 18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168,
> 18168, 18168, 18168, 18168, 18168, 18169, 18169, 18169, 18169,
> 18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169,
> 18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169,
> 18169, 18169, 18170, 18170, 18170, 18170, 18170, 18170, 18170,
> 18170, 18170, 18170, 18170, 18170, 18170, 18170, 18170, 18170,
> 18170, 18170, 18170, 18170, 18170, 18170, 18170, 18170, 18171,
> 18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171,
> 18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171,
> 18171, 18171, 18171, 18171, 18171, 18172, 18172, 18172, 18172,
> 18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172,
> 18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172,
> 18172, 18172, 18173, 18173, 18173, 18173, 18173, 18173, 18173,
> 18173, 18173, 18173, 18173, 18173, 18173, 18173, 18173, 18173,
> 18173, 18173, 18173, 18173, 18173, 18173, 18173, 18173, 18174,
> 18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174,
> 18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174,
> 18174, 18174, 18174, 18174, 18174, 18175, 18175, 18175, 18175,
> 18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175,
> 18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175,
> 18175, 18175, 18176, 18176, 18176, 18176, 18176, 18176, 18176,
> 18176, 18176, 18176, 18176, 18176, 18176, 18176, 18176, 18176,
> 18176, 18176, 18176, 18176, 18176, 18176, 18176, 18176, 18177,
> 18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177,
> 18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177,
> 18177, 18177, 18177, 18177, 18177, 18178, 18178, 18178, 18178,
> 18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178,
> 18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178,
> 18178, 18178, 18179, 18179, 18179, 18179, 18179, 18179, 18179,
> 18179, 18179, 18179, 18179, 18179, 18179, 18179, 18179, 18179,
> 18179, 18179, 18179, 18179, 18179, 18179, 18179, 18179, 18180,
> 18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180,
> 18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180,
> 18180, 18180, 18180, 18180, 18180, 18181, 18181, 18181, 18181,
> 18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181,
> 18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181,
> 18181, 18181, 18182, 18182, 18182, 18182, 18182, 18182, 18182,
> 18182, 18182, 18182, 18182, 18182, 18182, 18182, 18182, 18182,
> 18182, 18182, 18182, 18182, 18182, 18182, 18182, 18182, 18183,
> 18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183,
> 18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183,
> 18183, 18183, 18183, 18183, 18183, 18184, 18184, 18184, 18184,
> 18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184,
> 18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184,
> 18184, 18184, 18185, 18185, 18185, 18185, 18185, 18185, 18185,
> 18185, 18185, 18185, 18185, 18185, 18185, 18185, 18185, 18185,
> 18185, 18185, 18185, 18185, 18185, 18185, 18185, 18185, 18186,
> 18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186,
> 18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186,
> 18186, 18186, 18186, 18186, 18186, 18187, 18187, 18187, 18187,
> 18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187,
> 18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187,
> 18187, 18187, 18188, 18188, 18188, 18188, 18188, 18188, 18188,
> 18188, 18188, 18188, 18188, 18188, 18188, 18188, 18188, 18188,
> 18188, 18188, 18188, 18188, 18188, 18188, 18188, 18188, 18189,
> 18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189,
> 18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189,
> 18189, 18189, 18189, 18189, 18189, 18190, 18190, 18190, 18190,
> 18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190,
> 18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190,
> 18190, 18190, 18191, 18191, 18191, 18191, 18191, 18191, 18191,
> 18191, 18191, 18191, 18191, 18191, 18191, 18191, 18191, 18191,
> 18191, 18191, 18191, 18191, 18191, 18191, 18191, 18191, 18192,
> 18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192,
> 18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192,
> 18192, 18192, 18192, 18192, 18192, 18193, 18193, 18193, 18193,
> 18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193,
> 18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193,
> 18193, 18193, 18194, 18194, 18194, 18194, 18194, 18194, 18194,
> 18194, 18194, 18194, 18194, 18194, 18194, 18194, 18194, 18194,
> 18194, 18194, 18194, 18194, 18194, 18194, 18194, 18194, 18195,
> 18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195,
> 18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195,
> 18195, 18195, 18195, 18195, 18195, 18196, 18196, 18196, 18196,
> 18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196,
> 18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196,
> 18196, 18196, 18197, 18197, 18197, 18197, 18197, 18197, 18197,
> 18197, 18197, 18197, 18197, 18197, 18197, 18197, 18197, 18197,
> 18197, 18197, 18197, 18197, 18197, 18197, 18197, 18197, 18198,
> 18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198,
> 18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198,
> 18198, 18198, 18198, 18198, 18198, 18199, 18199, 18199, 18199,
> 18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199,
> 18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199,
> 18199, 18199, 18200, 18200, 18200, 18200, 18200, 18200, 18200,
> 18200, 18200, 18200, 18200, 18200, 18200, 18200, 18200, 18200,
> 18200, 18200, 18200, 18200, 18200, 18200, 18200, 18200, 18201,
> 18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201,
> 18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201,
> 18201, 18201, 18201, 18201, 18201, 18202, 18202, 18202, 18202,
> 18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202,
> 18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202,
> 18202, 18202, 18203, 18203, 18203, 18203, 18203, 18203, 18203,
> 18203, 18203, 18203, 18203, 18203, 18203, 18203, 18203, 18203,
> 18203, 18203, 18203, 18203, 18203, 18203, 18203, 18203, 18204,
> 18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204,
> 18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204,
> 18204, 18204, 18204, 18204, 18204, 18205, 18205, 18205, 18205,
> 18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205,
> 18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205,
> 18205, 18205, 18206, 18206, 18206, 18206, 18206, 18206, 18206,
> 18206, 18206, 18206, 18206, 18206, 18206, 18206, 18206, 18206,
> 18206, 18206, 18206, 18206, 18206, 18206, 18206, 18206, 18207,
> 18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207,
> 18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207,
> 18207, 18207, 18207, 18207, 18207, 18208, 18208, 18208, 18208,
> 18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208,
> 18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208,
> 18208, 18208, 18209, 18209, 18209, 18209, 18209, 18209, 18209,
> 18209, 18209, 18209, 18209, 18209, 18209, 18209, 18209, 18209,
> 18209, 18209, 18209, 18209, 18209, 18209, 18209, 18209, 18210,
> 18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210,
> 18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210,
> 18210, 18210, 18210, 18210, 18210, 18211, 18211, 18211, 18211,
> 18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211,
> 18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211,
> 18211, 18211, 18212, 18212, 18212, 18212, 18212, 18212, 18212,
> 18212, 18212, 18212, 18212, 18212, 18212, 18212, 18212, 18212,
> 18212, 18212, 18212, 18212, 18212, 18212, 18212, 18212, 18213,
> 18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213,
> 18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213,
> 18213, 18213, 18213, 18213, 18213, 18214, 18214, 18214, 18214,
> 18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214,
> 18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214,
> 18214, 18214, 18215, 18215, 18215, 18215, 18215, 18215, 18215,
> 18215, 18215, 18215, 18215, 18215, 18215, 18215, 18215, 18215,
> 18215, 18215, 18215, 18215, 18215, 18215, 18215, 18215, 18216,
> 18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216,
> 18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216,
> 18216, 18216, 18216, 18216, 18216, 18217, 18217, 18217, 18217,
> 18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217,
> 18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217,
> 18217, 18217, 18218, 18218, 18218, 18218, 18218, 18218, 18218,
> 18218, 18218, 18218, 18218, 18218, 18218, 18218, 18218, 18218,
> 18218, 18218, 18218, 18218, 18218, 18218, 18218, 18218, 18219,
> 18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219,
> 18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219,
> 18219, 18219, 18219, 18219, 18219, 18220, 18220, 18220, 18220,
> 18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220,
> 18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220,
> 18220, 18220, 18221, 18221, 18221, 18221, 18221, 18221, 18221,
> 18221, 18221, 18221, 18221, 18221, 18221, 18221, 18221, 18221,
> 18221, 18221, 18221, 18221, 18221, 18221, 18221, 18221, 18222,
> 18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222,
> 18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222,
> 18222, 18222, 18222, 18222, 18222, 18223, 18223, 18223, 18223,
> 18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223,
> 18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223,
> 18223, 18223, 18224, 18224, 18224, 18224, 18224, 18224, 18224,
> 18224, 18224, 18224, 18224, 18224, 18224, 18224, 18224, 18224,
> 18224, 18224, 18224, 18224, 18224, 18224, 18224, 18224, 18225,
> 18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225,
> 18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225,
> 18225, 18225, 18225, 18225, 18225, 18226, 18226, 18226, 18226,
> 18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226,
> 18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226,
> 18226, 18226, 18227, 18227, 18227, 18227, 18227, 18227, 18227,
> 18227, 18227, 18227, 18227, 18227, 18227, 18227, 18227, 18227,
> 18227, 18227, 18227, 18227, 18227, 18227, 18227, 18227, 18228,
> 18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228,
> 18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228,
> 18228, 18228, 18228, 18228, 18228, 18229, 18229, 18229, 18229,
> 18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229,
> 18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229,
> 18229, 18229, 18230, 18230, 18230, 18230, 18230, 18230, 18230,
> 18230, 18230, 18230, 18230, 18230, 18230, 18230, 18230, 18230,
> 18230, 18230, 18230, 18230, 18230, 18230, 18230, 18230, 18231,
> 18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231,
> 18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231,
> 18231, 18231, 18231, 18231, 18231, 18232, 18232, 18232, 18232,
> 18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232,
> 18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232,
> 18232, 18232, 18233, 18233, 18233, 18233, 18233, 18233, 18233,
> 18233, 18233, 18233, 18233, 18233, 18233, 18233, 18233, 18233,
> 18233, 18233, 18233, 18233, 18233, 18233, 18233, 18233, 18234,
> 18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234,
> 18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234,
> 18234, 18234, 18234, 18234, 18234, 18235, 18235, 18235, 18235,
> 18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235,
> 18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235,
> 18235, 18235, 18236, 18236, 18236, 18236, 18236, 18236, 18236,
> 18236, 18236, 18236, 18236, 18236, 18236, 18236, 18236, 18236,
> 18236, 18236, 18236, 18236, 18236, 18236, 18236, 18236, 18237,
> 18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237,
> 18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237,
> 18237, 18237, 18237, 18237, 18237, 18238, 18238, 18238, 18238,
> 18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238,
> 18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238,
> 18238, 18238, 18239, 18239, 18239, 18239, 18239, 18239, 18239,
> 18239, 18239, 18239, 18239, 18239, 18239, 18239, 18239, 18239,
> 18239, 18239, 18239, 18239, 18239, 18239, 18239, 18239, 18240,
> 18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240,
> 18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240,
> 18240, 18240, 18240, 18240, 18240, 18241, 18241, 18241, 18241,
> 18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241,
> 18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241,
> 18241, 18241, 18242, 18242, 18242, 18242, 18242, 18242, 18242,
> 18242, 18242, 18242, 18242, 18242, 18242, 18242, 18242, 18242,
> 18242, 18242, 18242, 18242, 18242, 18242, 18242, 18242, 18243,
> 18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243,
> 18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243,
> 18243, 18243, 18243, 18243, 18243, 18244, 18244, 18244, 18244,
> 18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244,
> 18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244,
> 18244, 18244, 18245, 18245, 18245, 18245, 18245, 18245, 18245,
> 18245, 18245, 18245, 18245, 18245, 18245, 18245, 18245, 18245,
> 18245, 18245, 18245, 18245, 18245, 18245, 18245, 18245, 18246,
> 18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246,
> 18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246,
> 18246, 18246, 18246, 18246, 18246, 18247, 18247, 18247, 18247,
> 18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247,
> 18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247,
> 18247, 18247, 18248, 18248, 18248, 18248, 18248, 18248, 18248,
> 18248, 18248, 18248, 18248, 18248, 18248, 18248, 18248, 18248,
> 18248, 18248, 18248, 18248, 18248, 18248, 18248, 18248, 18249,
> 18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249,
> 18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249,
> 18249, 18249, 18249, 18249, 18249, 18250, 18250, 18250, 18250,
> 18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250,
> 18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250,
> 18250, 18250, 18251, 18251, 18251, 18251, 18251, 18251, 18251,
> 18251, 18251, 18251, 18251, 18251, 18251, 18251, 18251, 18251,
> 18251, 18251, 18251, 18251, 18251, 18251, 18251, 18251, 18252,
> 18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252,
> 18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252,
> 18252, 18252, 18252, 18252, 18252, 18253, 18253, 18253, 18253,
> 18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253,
> 18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253,
> 18253, 18253, 18254, 18254, 18254, 18254, 18254, 18254, 18254,
> 18254, 18254, 18254, 18254, 18254, 18254, 18254, 18254, 18254,
> 18254, 18254, 18254, 18254, 18254, 18254, 18254, 18254, 18255,
> 18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255,
> 18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255,
> 18255, 18255, 18255, 18255, 18255, 18256, 18256, 18256, 18256,
> 18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256,
> 18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256,
> 18256, 18256, 18257, 18257, 18257, 18257, 18257, 18257, 18257,
> 18257, 18257, 18257, 18257, 18257, 18257, 18257, 18257, 18257,
> 18257, 18257, 18257, 18257, 18257, 18257, 18257, 18257, 18258,
> 18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258,
> 18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258,
> 18258, 18258, 18258, 18258, 18258, 18259, 18259, 18259, 18259,
> 18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259,
> 18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259,
> 18259, 18259, 18260, 18260, 18260, 18260, 18260, 18260, 18260,
> 18260, 18260, 18260, 18260, 18260, 18260, 18260, 18260, 18260,
> 18260, 18260, 18260, 18260, 18260, 18260, 18260, 18260, 18261,
> 18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261,
> 18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261,
> 18261, 18261, 18261, 18261, 18261, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA), .Dim = c(8760L, 2L))
> 
> 
>> dput(B)
> structure(c(13634, 13635, 13637, 13638, 13639, 13640, 13641,
> 13642, 13643, 13645, 13646, 13647, 13648, 13649, 13650, 13651,
> 13652, 13653, 13654, 13655, 13656, 13657, 13658, 13659, 13660,
> 13661, 13662, 13663, 13664, 13665, 13666, 13667, 13677, 13678,
> 13680, 13681, 13682, 13684, 13685, 13686, 13687, 13689, 13690,
> 13691, 13695, 13696, 13697, 13698, 13701, 13702, 13703, 13705,
> 13706, 13710, 13711, 13712, 13713, 13714, 13715, 13716, 13717,
> 13718, 13719, 13720, 13721, 13722, 13723, 13724, 13725, 13726,
> 13727, 13728, 13729, 13730, 13731, 13732, 13733, 13734, 13735,
> 13736, 13737, 13738, 13739, 13740, 13741, 13742, 13743, 13748,
> 13749, 13750, 13751, 13752, 13753, 13754, 13755, 14008, 14009,
> 14010, 14011, 14012, 14013, 14014, 14015, 14016, 14017, 14018,
> 14019, 14020, 14021, 14022, 14023, 14024, 14025, 14026, 14027,
> 14028, 14029, 14030, 14031, 14035, 14036, 14037, 14038, 14039,
> 14040, 14041, 14042, 14043, 14044, 14045, 14046, 14047, 14048,
> 14049, 14050, 14051, 14052, 14053, 14054, 14055, 14056, 14057,
> 14058, 14059, 14060, 14061, 14062, 14063, 14064, 14065, 14066,
> 14067, 14068, 14069, 14070, 14071, 14072, 14073, 14074, 14075,
> 14076, 14077, 14078, 14079, 14080, 14081, 14082, 14083, 14084,
> 14085, 14086, 14087, 14088, 14089, 14090, 14091, 14092, 14093,
> 14094, 14095, 14096, 14097, 14098, 14102, 14103, 14104, 14105,
> 14106, 14107, 14108, 14109, 14112, 14113, 14114, 14115, 14116,
> 14117, 14118, 14119, 14120, 14121, 14122, 14371, 14372, 14373,
> 14375, 14376, 14377, 14378, 14379, 14380, 14381, 14382, 14383,
> 14384, 14385, 14386, 14387, 14388, 14389, 14390, 14391, 14392,
> 14393, 14394, 14395, 14396, 14397, 14398, 14399, 14403, 14404,
> 14405, 14406, 14407, 14408, 14409, 14410, 14411, 14413, 14414,
> 14415, 14416, 14417, 14418, 14419, 14420, 14421, 14422, 14423,
> 14424, 14425, 14426, 14427, 14428, 14429, 14430, 14431, 14432,
> 14433, 14434, 14435, 14436, 14437, 14438, 14439, 14440, 14441,
> 14442, 14443, 14444, 14445, 14446, 14447, 14448, 14449, 14450,
> 14451, 14452, 14453, 14455, 14459, 14460, 14461, 14466, 14467,
> 14468, 14469, 14470, 14471, 14472, 14473, 14474, 14475, 14476,
> 14477, 14478, 14479, 14480, 14481, 14482, 14483, 14484, 14485,
> 14486, 14487, 14742, 14746, 14749, 14756, 14767, 14770, 14774,
> 14776, 14781, 14784, 14788, 14795, 14798, 14802, 14805, 14809,
> 14812, 14816, 14819, 14826, 14830, 14833, 14837, 14840, 14844,
> 14847, 14851, 15461, 15462, 15463, 15464, 15465, 15466, 15467,
> 15468, 15469, 15470, 15471, 15472, 15473, 15474, 15475, 15476,
> 15477, 15478, 15479, 15480, 15481, 15482, 15483, 15484, 15485,
> 15486, 15487, 15488, 15489, 15490, 15491, 15492, 15493, 15494,
> 15495, 15496, 15497, 15498, 15499, 15500, 15501, 15502, 15503,
> 15504, 15505, 15506, 15507, 15508, 15509, 15510, 15511, 15512,
> 15513, 15514, 15515, 15516, 15517, 15518, 15519, 15520, 15521,
> 15522, 15523, 15524, 15525, 15526, 15527, 15528, 15529, 15530,
> 15531, 15532, 15533, 15534, 15535, 15536, 15537, 15538, 15539,
> 15540, 15541, 15542, 15543, 15544, 15545, 15546, 15547, 15548,
> 15549, 15550, 15551, 15552, 15553, 15554, 15555, 15556, 15557,
> 15558, 15559, 15560, 15561, 15562, 15563, 15564, 15565, 15566,
> 15567, 15568, 15569, 15570, 15571, 15572, 15573, 15574, 15575,
> 15576, 15577, 15578, 15579, 15580, 15581, 15582, 15583, 15584,
> 15585, 15586, 15587, 15825, 15826, 15827, 15828, 15831, 15832,
> 15833, 15834, 15835, 15836, 15837, 15838, 15839, 15840, 15841,
> 15848, 15849, 15850, 15851, 15852, 15853, 15854, 15855, 15856,
> 15857, 15858, 15859, 15862, 15863, 15864, 15865, 15866, 15867,
> 15868, 15869, 15870, 15871, 15872, 15873, 15874, 15875, 15889,
> 15890, 15891, 15892, 15893, 15894, 15895, 15896, 15897, 15898,
> 15899, 15900, 15901, 15902, 15903, 15904, 15905, 15906, 15907,
> 15908, 15909, 15910, 15911, 15912, 15913, 15914, 15918, 15919,
> 15920, 15921, 15922, 15923, 15924, 15925, 15926, 15927, 15928,
> 15929, 15930, 15931, 15932, 15933, 15934, 15935, 15936, 15937,
> 15938, 15939, 15940, 15941, 15942, 15943, 15944, 15945, 15946,
> 15947, 15948, 15949, 15950, 15951, 16192, 16193, 16194, 16195,
> 16196, 16197, 16198, 16199, 16200, 16202, 16203, 16204, 16205,
> 16206, 16207, 16208, 16209, 16212, 16213, 16214, 16215, 16216,
> 16217, 16226, 16227, 16228, 16229, 16230, 16231, 16232, 16233,
> 16238, 16239, 16240, 16241, 16244, 16245, 16246, 16247, 16248,
> 16249, 16250, 16251, 16252, 16253, 16254, 16255, 16256, 16257,
> 16258, 16259, 16260, 16261, 16262, 16263, 16264, 16265, 16266,
> 16267, 16268, 16269, 16270, 16271, 16275, 16276, 16277, 16278,
> 16279, 16280, 16281, 16282, 16285, 16293, 16294, 16295, 16296,
> 16297, 16298, 16299, 16300, 16301, 16302, 16303, 16304, 16305,
> 16306, 16307, 16308, 16309, 16310, 16589, 16603, 16607, 16616,
> 16632, 16651, 16662, 16971, 16986, 17007, 17023, 17180, 17184,
> 17189, 17218, 17231, 17239, 17245, 17269, 17273, 17301, 17304,
> 17315, 17326, 17343, 17367, 17387, 17392, 17393, 17393, 17399,
> 17416, 17422, 17423, 17427, 17431, 17442, 17455, 17469, 17483,
> 17494, 17498, 17511, 17528, 17539, 17550, 17553, 17583, 17595,
> 17603, 17605, 17610, 17611, 17612, 17618, 17619, 17623, 17637,
> 17651, 17665, 17679, 17682, 17696, 17707, 17721, 17722, 17731,
> 17735, 17736, 17738, 17751, 17763, 17778, 17791, 18033, 18037,
> 18053, 18063, 18066, 18114, 18130, 18133, 18148, 3, 32, 88, 126,
> 8, 2, 2, 4, 5, 5, 60, 1, 1, 1.5, 1.5, 2, 2, 330, 7, 1, 40, 52,
> 15, 4, 3, 2, 1, 5, 3, 1, 5, 1234, 5, 6, 34, 107, 12, 6, 6, 1,
> 1, 189, 9, 4, 1, 1, 5, 5, 3, 5, 4, 14, 3, 15, 3.5, 9, 2, 1, 1,
> 1, 10, 133, 109, 8, 1, 2, 1, 13, 1, 1, 2, 4, 60, 4, 2, 2, 226,
> 111, 23, 2, 1, 2, 2, 2, 2, 3, 1, 15, 2, 1, 111, 93, 6, 5, 1,
> 42, 9, 3, 2, 1, 1, 0.75, 1, 0.5, 0.5, 1, 5, 235, 129, 120, 102,
> 41, 63, 11, 5, 0.75, 257, 45, 7, 164, 161, 223, 111, 175, 158,
> 76, 39, 39, 22, 5, 4, 3, 4, 3, 6, 4, 13, 2, 137, 5, 3, 2, 2,
> 1, 47, 1, 1, 1, 256, 29, 51, 427, 54, 15, 131, 52, 6, 329, 111,
> 43, 9, 2, 87, 11, 3, 5, 6, 12, 17, 3, 5, 306, 28, 5, 3, 0.5,
> 1, 0.5, 0.5, 4, 1.5, 3, 2, 3, 2, 3, 2, 2, 2, 507, 10, 70, 12,
> 1, 3, 1, 49, 2, 3, 1, 189, 39, 39, 122, 63, 5, 184, 37, 78, 22,
> 7, 4, 47, 12, 65, 6, 9, 2, 3, 42, 7, 3, 3, 2, 2, 18, 2, 1, 2,
> 2, 9, 10, 3, 3, 3, 32, 13, 5, 98, 442, 51, 6, 101, 5, 2, 2, 6,
> 5, 3, 2, 3, 6, 17, 125, 6, 70, 11, 171, 24.5, 87, 11, 11, 2,
> 2, 137, 16, 35, 5, 2, 2, 3, 2, 3, 3, 3, 2, 1, 8, 2, 3, 61, 119,
> 62, 22, 8, 25, 3, 159, 38, 42, 9, 3, 93, 36, 4, 5, 4, 4, 5, 4,
> 5, 4, 3, 332, 20, 6, 2.5, 7.5, 3, 331, 149.5, 44, 36.5, 311,
> 427, 3, 43.5, 7, 140, 594, 46, 23, 11, 46, 436, 82.5, 600, 53,
> 1.5, 9, 4, 40, 8, 6, 6, 6, 13, 141, 11, 4, 2, 4, 1, 1, 1, 1,
> 1, 1, 1, 21, 6, 4, 1, 1, 553, 93, 41, 40, 4, 2, 2, 4, 1, 3, 2,
> 17, 3, 5, 951, 138, 6, 67, 24, 66, 3, 4, 167, 259, 32, 4, 8,
> 143, 64, 4, 3, 25, 68, 119, 8, 57, 61, 2, 2, 4, 3, 2, 3, 2, 12.61666667,
> 51, 7, 5.916666667, 2, 6, 1, 5, 3, 3, 4.083333333, 8, 7, 1, 1,
> 17, 4, 3, 12, 1, 1, 1, 2, 3, 3, 1, 1, 19, 18, 3, 1, 1, 1, 1,
> 1, 4, 4, 3, 121, 94, 13, 4, 4, 1, 2, 1, 1, 1, 1, 1, 83, 4, 1,
> 4, 2, 1, 1, 2, 5, 3, 1, 1, 23, 6, 12, 28, 12, 4, 4, 4, 3, 10,
> 5, 6, 36, 5, 8, 386, 177.5, 23, 3, 9, 174, 248, 116, 29, 5, 88,
> 56, 4, 11, 30, 9, 8, 14, 6, 28, 139.5, 64, 4, 18, 64, 67, 39,
> 144, 102, 10, 4, 252, 4, 4, 4, 4, 19, 1, 4, 3, 3, 9, 2, 1, 1,
> 314, 44, 12, 87, 7, 132, 26, 14, 16, 7, 10, 8, 107, 40, 33, 18,
> 5, 5, 6, 4, 3, 2, 6, 6, 5, 4, 5, 7, 5, 6, 8, 6, 29, 7, 4, 77,
> 3, 3, 4, 17, 3, 154, 60, 45, 7, 18.5, 8, 5, 118, 56, 6.5, 2,
> 1, 4, 4, 4, 34, 16, 14, 7, 6, 6, 44, 6, 8.5, 2, 1, 1, 9, 1, 16,
> 4, 50, 98, 57, 45, 10, 142, 170, 6, 60, 605, 25, 30, 18.5, 19,
> 9.5, 1, 1, 993.5, 57, 4, 2, 30, 4, 4, 2, 2, 1, 9, 53, 4, 3, 580.75,
> 60, 45, 21, 25, 44, 18, 10, 27, 534.3333333, 4, 10, 2, 63, 14,
> 4, 4, 8, 15, 408, 46, 18, 8, 3, 6, 4, 9, 137.5, 428.49, 78.8,
> 30.49, 9.97, 229.77, 550.175, 167.17, 186.17, 224.855, 609.835,
> 1180, 130.7077449, 229.6460144, 3, 4, 20, 409.1286324, 18, 452,
> 4, 4, 107, 8, 487, 2, 9, 1, 159, 329, 324, 2, 10, 174, 67, 1,
> 42, 43, 4, 3, 3, 104, 9, 1, 1, 4, 32, 1, 1, 2, 238, 237, 190,
> 214, 156, 240, 29, 2, 374, 36, 4, 18, 419, 2, 5, 3, 277, 340,
> 1, 216, 93, 1, 4, 2, 3, 42, 78, 190, 40, 808, 80, 266, 66, 42
> ), .Dim = c(734L, 2L))
> 
> Can you please guide me how to implement the given code on this dataset?
> I thanyou in advance
> ________________________________
> From: Mohammad Tanvir Ahamed <mashranga at yahoo.com>
> Sent: Wednesday 1 September 2021 21:48
> To: r-help at r-project.org <r-help at r-project.org>; Eliza Botto <eliza_botto at outlook.com>
> Subject: Re: [R] conditional replacement of elements of matrix with another matrix column
> 
> C1 <- A
> C1[,2][which(B[,1]%in%A[,1])] <- B[,2][which(B[,1]%in%A[,1])]
> 
> 
> Regards.............
> Tanvir Ahamed
> 
> 
> 
> 
> 
> 
> On Wednesday, 1 September 2021, 11:00:16 pm GMT+2, Eliza Botto <eliza_botto at outlook.com> wrote:
> 
> 
> 
> 
> 
> deaR useRs,
> 
> I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a way of doing it?
> 
>> dput(A)
> 
> structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
> NA, NA, NA, NA, NA), .Dim = c(9L, 2L))
> 
>> dput(B)
> 
> structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
> 11, 12, 13, 14), .Dim = c(9L, 2L))
> 
>> dput(C)
> 
> structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
> 10, 11, 12, 13, 14), .Dim = c(9L, 2L))
> 
> Precisely, I want to replace the elements of 2nd column of A with those of B provided the elements of 1st column match. Is there a single line loop or code for that?
> 
> 
> Thanks in advance,
> 
> Eliza Botto
> 
>      [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Sep  2 12:21:30 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 2 Sep 2021 22:21:30 +1200
Subject: [R] What if there's nothing to dispatch on?
In-Reply-To: <6a6ca852-2a8b-7f20-b85f-fadd2c6af769@gmail.com>
References: <20210901155904.33a8f6e0@rolf-Latitude-E7470>
 <c46921e2-4d2a-09f6-110d-376eb188e327@gmail.com>
 <20210902102950.0e873a42@rolf-Latitude-E7470>
 <6a6ca852-2a8b-7f20-b85f-fadd2c6af769@gmail.com>
Message-ID: <20210902222130.6e98bd7f@rolf-Latitude-E7470>


On Wed, 1 Sep 2021 19:29:32 -0400
Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

<SNIP>

> I don't know the header of your foo() method, but let's suppose foo()
> is
> 
>    foo <- function(x, data, ...) {
>      UseMethod("foo")
>    }
> 
> with
> 
>    foo.formula <- function(x, data, ...) {
>      # do something with the formula x
>    }
> 
>    foo.default <- function(x, data, ...) {
>      # do the default thing.
>    }
> 
> Now you have
> 
>    xxx <- data.frame(u = 1:10, v = rnorm(10))
>    foo(x = u, y = v, data = xxx)
> 
> You want this to dispatch to the default method, because u is not a 
> formula, it's a column in xxx.  But how do you know that?  Maybe in
> some other part of your code you have
> 
>    u <- someresponse ~ somepredictor

Well I *don't* have such code anywhere, but a user could have such a
formula saved in the global environment.

> So now u *is* a formula, and this will dispatch to the formula
> method, causing havoc.
> 
> I think Bill's suggestion doesn't help here.  To do what you want to
> do doesn't really match what S3 is designed to do.

Yes.  I have come to realise that and have moved away from the S3
classes and method approach. I now have a solution with which I am
basically satisfied.  But I now understand the problem that you raised.
(Sorry to be so slow!  And thank you for the explanation.)

We need to guard against the possibility that a user may invoke the
"non-formula" syntax, foo(x,y,data)  where x is the predictor and y is
the response, and inadvertently trigger the formula syntax because
there is a pre-constructed formula, with the same name as x, hanging
about.

Not really very likely, but certainly not impossible.

I think that the following works:  suppose that x turns out (using
your handy-dandy try() trick) to be a formula.

    x1 <-try(x,silent=TRUE)

If inherits(x1,"formula") firstly check whether this formula exists in
the global environment:

    nmx <- deparse(substitute(x))
    if(exists(nmx,envir=.GlobalEnv)) {
        (throw an error)
    }

I have also added an argument forceFormula=FALSE, which if set to TRUE
prevents the error from being thrown.   Just in case using the formula
named by x *really is* what the user wants to do!

I've tested this out a bit (in my real application) and it seems to
work.  I'm sure that there are other pitfalls and Traps for Young
Players.  E.g. someone might call my function from inside
another function in which the offending formula is constructed.
So the offending formula *won't* be found in the global environment and
the error won't be triggered.  Psigh! Somebody will always be able to
find a way to break things. See fortunes::fortune(15).

However I think the code that I have written is reasonably robust, and
does what I want.  (BTW I want the function to accommodate the
"non-formula" syntax, as well as the formula syntax, to maintain some
semblance of backwards-compatibility.)

Thanks again for (a) the try() trick, and (b) pointing out the lurking
danger.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 13:02:05 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 13:02:05 +0200
Subject: [R] Show only header of str() function
Message-ID: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>

Hello, is it possible to show only the header (that is: `'data.frame':
x obs. of  y variables:` part) of the str function?
Thank you

-- 
Best regards,
Luigi


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep  2 13:31:17 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Sep 2021 12:31:17 +0100
Subject: [R] Show only header of str() function
In-Reply-To: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
Message-ID: <ca4ddb3d-110d-fe3f-240c-b8ba0217a146@sapo.pt>

Hello,

Not perfect but works for data.frames:


header_str <- function(x){
   capture.output(str(x))[[1]]
}
header_str(iris)
header_str(AirPassengers)
header_str(1:10)


Hope this helps,

Rui Barradas

?s 12:02 de 02/09/21, Luigi Marongiu escreveu:
> Hello, is it possible to show only the header (that is: `'data.frame':
> x obs. of  y variables:` part) of the str function?
> Thank you
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 14:47:21 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 14:47:21 +0200
Subject: [R] Show only header of str() function
In-Reply-To: <ca4ddb3d-110d-fe3f-240c-b8ba0217a146@sapo.pt>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
 <ca4ddb3d-110d-fe3f-240c-b8ba0217a146@sapo.pt>
Message-ID: <CAMk+s2T2cpXGJw87eb_DbAEshsTWH1UUNUt1F5EGwQnNtoo6WQ@mail.gmail.com>

Thank you! better than dim() anyway.
Best regards
Luigi

On Thu, Sep 2, 2021 at 1:31 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Not perfect but works for data.frames:
>
>
> header_str <- function(x){
>    capture.output(str(x))[[1]]
> }
> header_str(iris)
> header_str(AirPassengers)
> header_str(1:10)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 12:02 de 02/09/21, Luigi Marongiu escreveu:
> > Hello, is it possible to show only the header (that is: `'data.frame':
> > x obs. of  y variables:` part) of the str function?
> > Thank you
> >



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 15:18:13 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 15:18:13 +0200
Subject: [R] How to globally convert NaN to NA in dataframe?
Message-ID: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>

Hello,
I have some NaN values in some elements of a dataframe that I would
like to convert to NA.
The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
Is there an alternative for the global modification at once of all
instances?
I have seen from
https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
that once could use:
```

is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))

data123[is.nan(data123)] <- 0
```
replacing o with NA, but I got
```
str(df)
> logi NA
```
when modifying my dataframe df.
What would be the correct syntax?
Thank you



-- 
Best regards,
Luigi


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep  2 15:29:24 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 2 Sep 2021 13:29:24 +0000
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
Message-ID: <5d3f9164ac3f4edbbd537226caa3cb7f@SRVEXCHCM1302.precheza.cz>

Hi

what about

data[sapply(data, is.nan)] <- NA

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> Sent: Thursday, September 2, 2021 3:18 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] How to globally convert NaN to NA in dataframe?
> 
> Hello,
> I have some NaN values in some elements of a dataframe that I would like
to
> convert to NA.
> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
> Is there an alternative for the global modification at once of all
instances?
> I have seen from
> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-
> with-zero-in-a-huge-data-frame/18143097#18143097
> that once could use:
> ```
> 
> is.nan.data.frame <- function(x)
> do.call(cbind, lapply(x, is.nan))
> 
> data123[is.nan(data123)] <- 0
> ```
> replacing o with NA, but I got
> ```
> str(df)
> > logi NA
> ```
> when modifying my dataframe df.
> What would be the correct syntax?
> Thank you
> 
> 
> 
> --
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From @kw@|mmo @end|ng |rom gm@||@com  Thu Sep  2 15:29:54 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 2 Sep 2021 09:29:54 -0400
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
Message-ID: <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>

Hello,


I would use something like:


x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |>
as.data.frame()
x[] <- lapply(x, function(xx) {
    xx[is.nan(xx)] <- NA_real_
    xx
})


This prevents attributes from being changed in 'x', but accomplishes the
same thing as you have above, I hope this helps!

On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Hello,
> I have some NaN values in some elements of a dataframe that I would
> like to convert to NA.
> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
> Is there an alternative for the global modification at once of all
> instances?
> I have seen from
>
> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
> that once could use:
> ```
>
> is.nan.data.frame <- function(x)
> do.call(cbind, lapply(x, is.nan))
>
> data123[is.nan(data123)] <- 0
> ```
> replacing o with NA, but I got
> ```
> str(df)
> > logi NA
> ```
> when modifying my dataframe df.
> What would be the correct syntax?
> Thank you
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 15:35:24 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 15:35:24 +0200
Subject: [R] Loop over columns of dataframe and change values condtionally
Message-ID: <CAMk+s2T0TaPuYZDywiOH7YOZgr8WUjusN=mDpxP4mMyQ=nW=Uw@mail.gmail.com>

Hello,
it is possible to select the columns of a dataframe in sequence with:
```
for(i in 1:ncol(df)) {
  df[ , i]
}
# or
for(i in 1:ncol(df)) {
  df[ i]
}
```
And change all values with, for instance:
```
for(i in 1:ncol(df)) {
  df[ , i] <- df[ , i] + 10
}
```
Is it possible to apply a condition? What would be the syntax?
For instance, to change all 0s in a column to NA would `df[i][df[i ==
0] = NA` be right?
Thank you


-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 15:45:33 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 15:45:33 +0200
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
Message-ID: <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>

`data[sapply(data, is.nan)] <- NA` is a nice compact command, but I
still get NaN when using the summary function, for instance one of the
columns give:
```
Min.   : NA
1st Qu.: NA
Median : NA
Mean   :NaN
3rd Qu.: NA
Max.   : NA
NA's   :110
```
I tried to implement the second solution but:
```
df <- lapply(x, function(xx) {
  xx[is.nan(xx)] <- NA
})
> str(df)
List of 1
 $ sd_ef_rash_loc___palm: logi NA
```
What am I getting wrong?
Thanks

On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>
> Hello,
>
>
> I would use something like:
>
>
> x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |> as.data.frame()
> x[] <- lapply(x, function(xx) {
>     xx[is.nan(xx)] <- NA_real_
>     xx
> })
>
>
> This prevents attributes from being changed in 'x', but accomplishes the same thing as you have above, I hope this helps!
>
> On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Hello,
>> I have some NaN values in some elements of a dataframe that I would
>> like to convert to NA.
>> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
>> Is there an alternative for the global modification at once of all
>> instances?
>> I have seen from
>> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
>> that once could use:
>> ```
>>
>> is.nan.data.frame <- function(x)
>> do.call(cbind, lapply(x, is.nan))
>>
>> data123[is.nan(data123)] <- 0
>> ```
>> replacing o with NA, but I got
>> ```
>> str(df)
>> > logi NA
>> ```
>> when modifying my dataframe df.
>> What would be the correct syntax?
>> Thank you
>>
>>
>>
>> --
>> Best regards,
>> Luigi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From @kw@|mmo @end|ng |rom gm@||@com  Thu Sep  2 15:47:06 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 2 Sep 2021 09:47:06 -0400
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
Message-ID: <CAPcHnpTEsoWGcndBzUWtfNj4QJXr5T=_6fsHeKt7MthO36pgkw@mail.gmail.com>

You removed the second line 'xx' from the function, put it back and it
should work

On Thu, Sep 2, 2021, 09:45 Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I
> still get NaN when using the summary function, for instance one of the
> columns give:
> ```
> Min.   : NA
> 1st Qu.: NA
> Median : NA
> Mean   :NaN
> 3rd Qu.: NA
> Max.   : NA
> NA's   :110
> ```
> I tried to implement the second solution but:
> ```
> df <- lapply(x, function(xx) {
>   xx[is.nan(xx)] <- NA
> })
> > str(df)
> List of 1
>  $ sd_ef_rash_loc___palm: logi NA
> ```
> What am I getting wrong?
> Thanks
>
> On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
> >
> > Hello,
> >
> >
> > I would use something like:
> >
> >
> > x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |>
> as.data.frame()
> > x[] <- lapply(x, function(xx) {
> >     xx[is.nan(xx)] <- NA_real_
> >     xx
> > })
> >
> >
> > This prevents attributes from being changed in 'x', but accomplishes the
> same thing as you have above, I hope this helps!
> >
> > On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> >>
> >> Hello,
> >> I have some NaN values in some elements of a dataframe that I would
> >> like to convert to NA.
> >> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
> >> Is there an alternative for the global modification at once of all
> >> instances?
> >> I have seen from
> >>
> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
> >> that once could use:
> >> ```
> >>
> >> is.nan.data.frame <- function(x)
> >> do.call(cbind, lapply(x, is.nan))
> >>
> >> data123[is.nan(data123)] <- 0
> >> ```
> >> replacing o with NA, but I got
> >> ```
> >> str(df)
> >> > logi NA
> >> ```
> >> when modifying my dataframe df.
> >> What would be the correct syntax?
> >> Thank you
> >>
> >>
> >>
> >> --
> >> Best regards,
> >> Luigi
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep  2 15:51:00 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 2 Sep 2021 13:51:00 +0000
Subject: [R] 
 Loop over columns of dataframe and change values condtionally
In-Reply-To: <CAMk+s2T0TaPuYZDywiOH7YOZgr8WUjusN=mDpxP4mMyQ=nW=Uw@mail.gmail.com>
References: <CAMk+s2T0TaPuYZDywiOH7YOZgr8WUjusN=mDpxP4mMyQ=nW=Uw@mail.gmail.com>
Message-ID: <83fe857d702049c3b6a4468959cec5f1@SRVEXCHCM1302.precheza.cz>

Hi

you could operate with whole data frame (sometimes)
head(iris)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
2          4.9         3.0          1.4         0.2  setosa
3          4.7         3.2          1.3         0.2  setosa
4          4.6         3.1          1.5         0.2  setosa
5          5.0         3.6          1.4         0.2  setosa
6          5.4         3.9          1.7         0.4  setosa

chenge all

> head(iris[,1:4]+10) 
  Sepal.Length Sepal.Width Petal.Length Petal.Width
1         15.1        13.5         11.4        10.2
2         14.9        13.0         11.4        10.2
3         14.7        13.2         11.3        10.2
4         14.6        13.1         11.5        10.2
5         15.0        13.6         11.4        10.2
6         15.4        13.9         11.7        10.4

change only some
> iris[,1:4][iris[,1:4]<2] <- iris[,1:4][iris[,1:4]<2]+10
> head(iris)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5         11.4        10.2  setosa
2          4.9         3.0         11.4        10.2  setosa
3          4.7         3.2         11.3        10.2  setosa
4          4.6         3.1         11.5        10.2  setosa
5          5.0         3.6         11.4        10.2  setosa
6          5.4         3.9         11.7        10.4  setosa


Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> Sent: Thursday, September 2, 2021 3:35 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] Loop over columns of dataframe and change values condtionally
> 
> Hello,
> it is possible to select the columns of a dataframe in sequence with:
> ```
> for(i in 1:ncol(df)) {
>   df[ , i]
> }
> # or
> for(i in 1:ncol(df)) {
>   df[ i]
> }
> ```
> And change all values with, for instance:
> ```
> for(i in 1:ncol(df)) {
>   df[ , i] <- df[ , i] + 10
> }
> ```
> Is it possible to apply a condition? What would be the syntax?
> For instance, to change all 0s in a column to NA would `df[i][df[i == 0] =
NA`
> be right?
> Thank you
> 
> 
> --
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep  2 16:01:17 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Sep 2021 15:01:17 +0100
Subject: [R] 
 Loop over columns of dataframe and change values condtionally
In-Reply-To: <CAMk+s2T0TaPuYZDywiOH7YOZgr8WUjusN=mDpxP4mMyQ=nW=Uw@mail.gmail.com>
References: <CAMk+s2T0TaPuYZDywiOH7YOZgr8WUjusN=mDpxP4mMyQ=nW=Uw@mail.gmail.com>
Message-ID: <3916e2d9-a21e-635b-5b48-65494c4d0e15@sapo.pt>

Hello,

In the particular case you have, to change to NA based on condition, use 
`is.na<-`.

Here is some test data, 3 times the same df.


set.seed(2021)
df3 <- df2 <- df1 <- data.frame(
   x = c(0, 0, 1, 2, 3),
   y = c(1, 2, 3, 0, 0),
   z = rbinom(5, 1, prob = c(0.25, 0.75)),
   a = letters[1:5]
)


# change all columns
is.na(df1) <- df1 == 0
df1

# only one column
is.na(df2[, 2]) <- df2[, 2] == 0
df2

# change several columns given by an index
is.na(df3[c(1, 3)]) <- df3[c(1, 3)] == 0
df3


Hope this helps,

Rui Barradas


?s 14:35 de 02/09/21, Luigi Marongiu escreveu:
> Hello,
> it is possible to select the columns of a dataframe in sequence with:
> ```
> for(i in 1:ncol(df)) {
>    df[ , i]
> }
> # or
> for(i in 1:ncol(df)) {
>    df[ i]
> }
> ```
> And change all values with, for instance:
> ```
> for(i in 1:ncol(df)) {
>    df[ , i] <- df[ , i] + 10
> }
> ```
> Is it possible to apply a condition? What would be the syntax?
> For instance, to change all 0s in a column to NA would `df[i][df[i ==
> 0] = NA` be right?
> Thank you
> 
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 16:01:39 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 16:01:39 +0200
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAPcHnpTEsoWGcndBzUWtfNj4QJXr5T=_6fsHeKt7MthO36pgkw@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
 <CAPcHnpTEsoWGcndBzUWtfNj4QJXr5T=_6fsHeKt7MthO36pgkw@mail.gmail.com>
Message-ID: <CAMk+s2TqNXTj1Ys7QPD3=-F_97+XBgkshZPaLgaLZsHjtqQ+=g@mail.gmail.com>

Sorry,
still I don't get it:
```
> dim(df)
[1] 302 626
> # clean
> df <- lapply(x, function(xx) {
+   xx[is.nan(xx)] <- NA
+   xx
+ })
> dim(df)
NULL
```

On Thu, Sep 2, 2021 at 3:47 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>
> You removed the second line 'xx' from the function, put it back and it should work
>
> On Thu, Sep 2, 2021, 09:45 Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I
>> still get NaN when using the summary function, for instance one of the
>> columns give:
>> ```
>> Min.   : NA
>> 1st Qu.: NA
>> Median : NA
>> Mean   :NaN
>> 3rd Qu.: NA
>> Max.   : NA
>> NA's   :110
>> ```
>> I tried to implement the second solution but:
>> ```
>> df <- lapply(x, function(xx) {
>>   xx[is.nan(xx)] <- NA
>> })
>> > str(df)
>> List of 1
>>  $ sd_ef_rash_loc___palm: logi NA
>> ```
>> What am I getting wrong?
>> Thanks
>>
>> On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>> >
>> > Hello,
>> >
>> >
>> > I would use something like:
>> >
>> >
>> > x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |> as.data.frame()
>> > x[] <- lapply(x, function(xx) {
>> >     xx[is.nan(xx)] <- NA_real_
>> >     xx
>> > })
>> >
>> >
>> > This prevents attributes from being changed in 'x', but accomplishes the same thing as you have above, I hope this helps!
>> >
>> > On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> >>
>> >> Hello,
>> >> I have some NaN values in some elements of a dataframe that I would
>> >> like to convert to NA.
>> >> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
>> >> Is there an alternative for the global modification at once of all
>> >> instances?
>> >> I have seen from
>> >> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
>> >> that once could use:
>> >> ```
>> >>
>> >> is.nan.data.frame <- function(x)
>> >> do.call(cbind, lapply(x, is.nan))
>> >>
>> >> data123[is.nan(data123)] <- 0
>> >> ```
>> >> replacing o with NA, but I got
>> >> ```
>> >> str(df)
>> >> > logi NA
>> >> ```
>> >> when modifying my dataframe df.
>> >> What would be the correct syntax?
>> >> Thank you
>> >>
>> >>
>> >>
>> >> --
>> >> Best regards,
>> >> Luigi
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Best regards,
>> Luigi



-- 
Best regards,
Luigi


From @kw@|mmo @end|ng |rom gm@||@com  Thu Sep  2 16:17:31 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 2 Sep 2021 10:17:31 -0400
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAMk+s2TqNXTj1Ys7QPD3=-F_97+XBgkshZPaLgaLZsHjtqQ+=g@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
 <CAPcHnpTEsoWGcndBzUWtfNj4QJXr5T=_6fsHeKt7MthO36pgkw@mail.gmail.com>
 <CAMk+s2TqNXTj1Ys7QPD3=-F_97+XBgkshZPaLgaLZsHjtqQ+=g@mail.gmail.com>
Message-ID: <CAPcHnpTtapJMLwv0Q-W1w8zzynthrC+myJO1zWiARAo8gbiyKw@mail.gmail.com>

It seems like you might've missed one more thing, you need the brackets
next to 'x' to get it to work.


x[] <- lapply(x, function(xx) {
    xx[is.nan(xx)] <- NA_real_
    xx
})

is different from

x <- lapply(x, function(xx) {
    xx[is.nan(xx)] <- NA_real_
    xx
})

Also, if all of your data is numeric, it might be better to convert to a
matrix before doing your calculations. For example:

x <- as.matrix(x)
x[is.nan(x)] <- NA_real_

I'd also suggest this same solution for the other question you posted,

x[x == 0] <- NA

On Thu, Sep 2, 2021 at 10:01 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Sorry,
> still I don't get it:
> ```
> > dim(df)
> [1] 302 626
> > # clean
> > df <- lapply(x, function(xx) {
> +   xx[is.nan(xx)] <- NA
> +   xx
> + })
> > dim(df)
> NULL
> ```
>
> On Thu, Sep 2, 2021 at 3:47 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
> >
> > You removed the second line 'xx' from the function, put it back and it
> should work
> >
> > On Thu, Sep 2, 2021, 09:45 Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> >>
> >> `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I
> >> still get NaN when using the summary function, for instance one of the
> >> columns give:
> >> ```
> >> Min.   : NA
> >> 1st Qu.: NA
> >> Median : NA
> >> Mean   :NaN
> >> 3rd Qu.: NA
> >> Max.   : NA
> >> NA's   :110
> >> ```
> >> I tried to implement the second solution but:
> >> ```
> >> df <- lapply(x, function(xx) {
> >>   xx[is.nan(xx)] <- NA
> >> })
> >> > str(df)
> >> List of 1
> >>  $ sd_ef_rash_loc___palm: logi NA
> >> ```
> >> What am I getting wrong?
> >> Thanks
> >>
> >> On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com>
> wrote:
> >> >
> >> > Hello,
> >> >
> >> >
> >> > I would use something like:
> >> >
> >> >
> >> > x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |>
> as.data.frame()
> >> > x[] <- lapply(x, function(xx) {
> >> >     xx[is.nan(xx)] <- NA_real_
> >> >     xx
> >> > })
> >> >
> >> >
> >> > This prevents attributes from being changed in 'x', but accomplishes
> the same thing as you have above, I hope this helps!
> >> >
> >> > On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <
> marongiu.luigi at gmail.com> wrote:
> >> >>
> >> >> Hello,
> >> >> I have some NaN values in some elements of a dataframe that I would
> >> >> like to convert to NA.
> >> >> The command `df1$col[is.nan(df1$col)]<-NA` allows to work
> column-wise.
> >> >> Is there an alternative for the global modification at once of all
> >> >> instances?
> >> >> I have seen from
> >> >>
> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
> >> >> that once could use:
> >> >> ```
> >> >>
> >> >> is.nan.data.frame <- function(x)
> >> >> do.call(cbind, lapply(x, is.nan))
> >> >>
> >> >> data123[is.nan(data123)] <- 0
> >> >> ```
> >> >> replacing o with NA, but I got
> >> >> ```
> >> >> str(df)
> >> >> > logi NA
> >> >> ```
> >> >> when modifying my dataframe df.
> >> >> What would be the correct syntax?
> >> >> Thank you
> >> >>
> >> >>
> >> >>
> >> >> --
> >> >> Best regards,
> >> >> Luigi
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >> --
> >> Best regards,
> >> Luigi
>
>
>
> --
> Best regards,
> Luigi
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 16:29:47 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 16:29:47 +0200
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAPcHnpTtapJMLwv0Q-W1w8zzynthrC+myJO1zWiARAo8gbiyKw@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
 <CAPcHnpTEsoWGcndBzUWtfNj4QJXr5T=_6fsHeKt7MthO36pgkw@mail.gmail.com>
 <CAMk+s2TqNXTj1Ys7QPD3=-F_97+XBgkshZPaLgaLZsHjtqQ+=g@mail.gmail.com>
 <CAPcHnpTtapJMLwv0Q-W1w8zzynthrC+myJO1zWiARAo8gbiyKw@mail.gmail.com>
Message-ID: <CAMk+s2RNk3bhB___0Lu+qQPqxFgeU3wcVvyzQu0fAhV-LCqssw@mail.gmail.com>

Thank you!

On Thu, Sep 2, 2021 at 4:17 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>
> It seems like you might've missed one more thing, you need the brackets next to 'x' to get it to work.
>
>
> x[] <- lapply(x, function(xx) {
>     xx[is.nan(xx)] <- NA_real_
>     xx
> })
>
> is different from
>
> x <- lapply(x, function(xx) {
>     xx[is.nan(xx)] <- NA_real_
>     xx
> })
>
> Also, if all of your data is numeric, it might be better to convert to a matrix before doing your calculations. For example:
>
> x <- as.matrix(x)
> x[is.nan(x)] <- NA_real_
>
> I'd also suggest this same solution for the other question you posted,
>
> x[x == 0] <- NA
>
> On Thu, Sep 2, 2021 at 10:01 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Sorry,
>> still I don't get it:
>> ```
>> > dim(df)
>> [1] 302 626
>> > # clean
>> > df <- lapply(x, function(xx) {
>> +   xx[is.nan(xx)] <- NA
>> +   xx
>> + })
>> > dim(df)
>> NULL
>> ```
>>
>> On Thu, Sep 2, 2021 at 3:47 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>> >
>> > You removed the second line 'xx' from the function, put it back and it should work
>> >
>> > On Thu, Sep 2, 2021, 09:45 Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> >>
>> >> `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I
>> >> still get NaN when using the summary function, for instance one of the
>> >> columns give:
>> >> ```
>> >> Min.   : NA
>> >> 1st Qu.: NA
>> >> Median : NA
>> >> Mean   :NaN
>> >> 3rd Qu.: NA
>> >> Max.   : NA
>> >> NA's   :110
>> >> ```
>> >> I tried to implement the second solution but:
>> >> ```
>> >> df <- lapply(x, function(xx) {
>> >>   xx[is.nan(xx)] <- NA
>> >> })
>> >> > str(df)
>> >> List of 1
>> >>  $ sd_ef_rash_loc___palm: logi NA
>> >> ```
>> >> What am I getting wrong?
>> >> Thanks
>> >>
>> >> On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>> >> >
>> >> > Hello,
>> >> >
>> >> >
>> >> > I would use something like:
>> >> >
>> >> >
>> >> > x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |> as.data.frame()
>> >> > x[] <- lapply(x, function(xx) {
>> >> >     xx[is.nan(xx)] <- NA_real_
>> >> >     xx
>> >> > })
>> >> >
>> >> >
>> >> > This prevents attributes from being changed in 'x', but accomplishes the same thing as you have above, I hope this helps!
>> >> >
>> >> > On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> >> >>
>> >> >> Hello,
>> >> >> I have some NaN values in some elements of a dataframe that I would
>> >> >> like to convert to NA.
>> >> >> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
>> >> >> Is there an alternative for the global modification at once of all
>> >> >> instances?
>> >> >> I have seen from
>> >> >> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
>> >> >> that once could use:
>> >> >> ```
>> >> >>
>> >> >> is.nan.data.frame <- function(x)
>> >> >> do.call(cbind, lapply(x, is.nan))
>> >> >>
>> >> >> data123[is.nan(data123)] <- 0
>> >> >> ```
>> >> >> replacing o with NA, but I got
>> >> >> ```
>> >> >> str(df)
>> >> >> > logi NA
>> >> >> ```
>> >> >> when modifying my dataframe df.
>> >> >> What would be the correct syntax?
>> >> >> Thank you
>> >> >>
>> >> >>
>> >> >>
>> >> >> --
>> >> >> Best regards,
>> >> >> Luigi
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>> >>
>> >> --
>> >> Best regards,
>> >> Luigi
>>
>>
>>
>> --
>> Best regards,
>> Luigi



-- 
Best regards,
Luigi


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Sep  2 17:45:50 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 2 Sep 2021 11:45:50 -0400
Subject: [R] Show only header of str() function
In-Reply-To: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
Message-ID: <010801d7a011$9b36ff80$d1a4fe80$@verizon.net>

Luigi,

If you are sure you are looking at something like a data.frame, and all you
want o know is how many rows and how many columns are in it, then str() is
perhaps too detailed a tool.

The functions nrow() and ncol() tell you what you want and you can get both
together with dim(). You can, of course, print out whatever message you want
using the numbers supplied by throwing together some function like this:

sstr <- function(x) {
  cat(nrow(x), "obs. of ", ncol(x), " variables\n")
}

Calling that instead of str may meet your needs.  Of course, unlike str, it
will not work on arbitrary data structures.

Note the output of str()goes straight to the screen, similar to what cat
does. Capturing the output to say chop out just the first line is not
therefore a simple option. 


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
Sent: Thursday, September 2, 2021 7:02 AM
To: r-help <r-help at r-project.org>
Subject: [R] Show only header of str() function

Hello, is it possible to show only the header (that is: `'data.frame':
x obs. of  y variables:` part) of the str function?
Thank you

--
Best regards,
Luigi

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From e@ @end|ng |rom enr|co@chum@nn@net  Thu Sep  2 17:56:28 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 02 Sep 2021 17:56:28 +0200
Subject: [R] Show only header of str() function
In-Reply-To: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
 (Luigi Marongiu's message of "Thu, 2 Sep 2021 13:02:05 +0200")
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
Message-ID: <87y28fynrn.fsf@enricoschumann.net>

On Thu, 02 Sep 2021, Luigi Marongiu writes:

> Hello, is it possible to show only the header (that is: `'data.frame':
> x obs. of  y variables:` part) of the str function?
> Thank you

Perhaps one more solution. You could limit the number
of list components to be printed, though it will leave
a "truncated" message.

    str(iris, list.len = 0)
    ## 'data.frame':    150 obs. of  5 variables:
    ##   [list output truncated]

Since 'str' is a generic function, you could also
define a new 'str' method. Perhaps something among
those lines:

    str.data.frame.oneline <- function (object, ...) {
        cat("'data.frame':\t", nrow(object), " obs. of  ",
            (p <- length(object)), 
            " variable", if (p != 1) "s", "\n", sep = "")
        invisible(NULL)
    }

(which is essentially taken from 'str.data.frame').

Then:

    class(iris) <- c("data.frame.oneline", class(iris))

    str(iris)
    ## 'data.frame':  150 obs. of  5 variables
    
    str(list(a = 1,
             list(b = 2,
                  c = iris)))
    ## List of 2
    ##  $ a: num 1
    ##  $  :List of 2
    ##   ..$ b: num 2
    ##   ..$ c:'data.frame':   150 obs. of  5 variables




-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Sep  2 18:32:24 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 2 Sep 2021 09:32:24 -0700 (PDT)
Subject: [R] read.csv() error
Message-ID: <alpine.LNX.2.20.2109020931350.18288@salmo.appl-ecosys.com>

The first three commands in the script are:
stage <- read.csv('../data/water/gauge-ht.dat', header = TRUE, sep = ',', 
stringsAsFactors = FALSE)
stage$sampdate <- as.Date(stage$sampdate)
stage$ht <- as.numeric(stage$ht, length = 6)

Running the script produces this error:
> source('stage.R')
Error in `$<-.data.frame`(`*tmp*`, ht, value = numeric(0)) :
   replacement has 0 rows, data has 486336

Sample lines from the data file:
sampdate,samptime,elev
2007-10-01,01:00,2.80
2007-10-01,01:15,2.71
2007-10-01,01:30,2.63
2007-10-01,01:45,2.53
2007-10-01,02:00,2.45
2007-10-01,02:15,2.36
2007-10-01,02:30,2.27
2007-10-01,02:45,2.17
2007-10-01,03:00,2.07

Maximum value for elev is about 11.00, 5 digits.

I don't understand this error because the equivalent commands for another
data source file completes without error.

What is that error message telling me?

TIA,

Rich


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Sep  2 18:32:56 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 2 Sep 2021 12:32:56 -0400
Subject: [R] Show only header of str() function
In-Reply-To: <ca4ddb3d-110d-fe3f-240c-b8ba0217a146@sapo.pt>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
 <ca4ddb3d-110d-fe3f-240c-b8ba0217a146@sapo.pt>
Message-ID: <013401d7a018$2f6c6090$8e4521b0$@verizon.net>

Thanks for the interesting method Rui. So that is a way to do a redirect of output not to a sinkfile but to an in-memory variable as a textConnection.

Of course, one has to wonder why the makers of str thought it would be too inefficient to have an option that returns the output in a form that can be captured directly, not just to the screen. 

I have in the past done odd things such as using sink() to capture the output of a program that wrote another program dynamically in a loop. The saved file could then be used with source(). So a similar technique can capture the output from str() or cat() or whatever normally only writes to the screen and then the file can be read in to get the first line or whatever you need. I have had to play games to get the right output from some statistical programs too as it was assumed the user would read it, and sometimes had to cherry pick what I needed directly from withing the underlying object.

I suspect one reason R has so many packages including the tidyverse I like to use, is because the original R was designed in another time and in many places is not very consistent. I wonder how hard it would be to change some programs to simply accept an additional argument like sink() has where you can say split=TRUE and get a copy of what is being diverted to also come to the screen. I find cat() to be a very useful way to put more complicated output together than say print() but since it does not allow capture of the text into variables, I end up having to use other methods such as the glue() function or something like print(sprint("Hello %s, I have %d left.\n", "Brian", 5))

But you work with what you have. Your solution works albeit having read the function definition, is quite a bit of overkill when I read the code as it does things not needed. But as noted, if efficiency matters and you are only looking at data.frame style objects, there are cheaper solutions.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
Sent: Thursday, September 2, 2021 7:31 AM
To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help <r-help at r-project.org>
Subject: Re: [R] Show only header of str() function

Hello,

Not perfect but works for data.frames:


header_str <- function(x){
   capture.output(str(x))[[1]]
}
header_str(iris)
header_str(AirPassengers)
header_str(1:10)


Hope this helps,

Rui Barradas

?s 12:02 de 02/09/21, Luigi Marongiu escreveu:
> Hello, is it possible to show only the header (that is: `'data.frame':
> x obs. of  y variables:` part) of the str function?
> Thank you
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From e@ @end|ng |rom enr|co@chum@nn@net  Thu Sep  2 18:43:22 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 02 Sep 2021 18:43:22 +0200
Subject: [R] read.csv() error
In-Reply-To: <alpine.LNX.2.20.2109020931350.18288@salmo.appl-ecosys.com> (Rich
 Shepard's message of "Thu, 2 Sep 2021 09:32:24 -0700 (PDT)")
References: <alpine.LNX.2.20.2109020931350.18288@salmo.appl-ecosys.com>
Message-ID: <87sfynyllh.fsf@enricoschumann.net>

On Thu, 02 Sep 2021, Rich Shepard writes:

> The first three commands in the script are:
> stage <- read.csv('../data/water/gauge-ht.dat', header
> = TRUE, sep = ',', stringsAsFactors = FALSE)
> stage$sampdate <- as.Date(stage$sampdate)
> stage$ht <- as.numeric(stage$ht, length = 6)
>
> Running the script produces this error:
>> source('stage.R')
> Error in `$<-.data.frame`(`*tmp*`, ht, value = numeric(0)) :
>   replacement has 0 rows, data has 486336
>
> Sample lines from the data file:
> sampdate,samptime,elev
> 2007-10-01,01:00,2.80
> 2007-10-01,01:15,2.71
> 2007-10-01,01:30,2.63
> 2007-10-01,01:45,2.53
> 2007-10-01,02:00,2.45
> 2007-10-01,02:15,2.36
> 2007-10-01,02:30,2.27
> 2007-10-01,02:45,2.17
> 2007-10-01,03:00,2.07
>
> Maximum value for elev is about 11.00, 5 digits.
>
> I don't understand this error because the equivalent commands for another
> data source file completes without error.
>
> What is that error message telling me?
>
> TIA,
>
> Rich
>

There is no column 'ht'.

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From e@ @end|ng |rom enr|co@chum@nn@net  Thu Sep  2 18:43:22 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 02 Sep 2021 18:43:22 +0200
Subject: [R] read.csv() error
In-Reply-To: <alpine.LNX.2.20.2109020931350.18288@salmo.appl-ecosys.com> (Rich
 Shepard's message of "Thu, 2 Sep 2021 09:32:24 -0700 (PDT)")
References: <alpine.LNX.2.20.2109020931350.18288@salmo.appl-ecosys.com>
Message-ID: <87lf4ezzua.fsf@enricoschumann.net>

On Thu, 02 Sep 2021, Rich Shepard writes:

> The first three commands in the script are:
> stage <- read.csv('../data/water/gauge-ht.dat', header
> = TRUE, sep = ',', stringsAsFactors = FALSE)
> stage$sampdate <- as.Date(stage$sampdate)
> stage$ht <- as.numeric(stage$ht, length = 6)
>
> Running the script produces this error:
>> source('stage.R')
> Error in `$<-.data.frame`(`*tmp*`, ht, value = numeric(0)) :
>   replacement has 0 rows, data has 486336
>
> Sample lines from the data file:
> sampdate,samptime,elev
> 2007-10-01,01:00,2.80
> 2007-10-01,01:15,2.71
> 2007-10-01,01:30,2.63
> 2007-10-01,01:45,2.53
> 2007-10-01,02:00,2.45
> 2007-10-01,02:15,2.36
> 2007-10-01,02:30,2.27
> 2007-10-01,02:45,2.17
> 2007-10-01,03:00,2.07
>
> Maximum value for elev is about 11.00, 5 digits.
>
> I don't understand this error because the equivalent commands for another
> data source file completes without error.
>
> What is that error message telling me?
>
> TIA,
>
> Rich
>

(Sorry, sent too early.)

There is no column 'ht'.

    df <- data.frame(a = 1:5)
    df$b <- as.numeric(df$b)
    ## Error in `$<-.data.frame`(`*tmp*`, b, value = numeric(0)) : 
    ##   replacement has 0 rows, data has 5

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Thu Sep  2 19:02:34 2021
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Thu, 2 Sep 2021 22:32:34 +0530
Subject: [R] Show only header of str() function
In-Reply-To: <87y28fynrn.fsf@enricoschumann.net>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
 <87y28fynrn.fsf@enricoschumann.net>
Message-ID: <CADfFDC4i_jDyDRJ44i64+MX=E_xEpKf9+Z5Wq03jOqwWRTO0-A@mail.gmail.com>

On Thu, Sep 2, 2021 at 9:26 PM Enrico Schumann <es at enricoschumann.net> wrote:
>
> On Thu, 02 Sep 2021, Luigi Marongiu writes:
>
> > Hello, is it possible to show only the header (that is: `'data.frame':
> > x obs. of  y variables:` part) of the str function?
> > Thank you
>
> Perhaps one more solution. You could limit the number
> of list components to be printed, though it will leave
> a "truncated" message.
>
>     str(iris, list.len = 0)
>     ## 'data.frame':    150 obs. of  5 variables:
>     ##   [list output truncated]

Or use 'max.level', which is also generally useful for nested lists:

str(iris, max.level=0)
## 'data.frame':    150 obs. of  5 variables:

Best,
-Deepayan

> Since 'str' is a generic function, you could also
> define a new 'str' method. Perhaps something among
> those lines:
>
>     str.data.frame.oneline <- function (object, ...) {
>         cat("'data.frame':\t", nrow(object), " obs. of  ",
>             (p <- length(object)),
>             " variable", if (p != 1) "s", "\n", sep = "")
>         invisible(NULL)
>     }
>
> (which is essentially taken from 'str.data.frame').
>
> Then:
>
>     class(iris) <- c("data.frame.oneline", class(iris))
>
>     str(iris)
>     ## 'data.frame':  150 obs. of  5 variables
>
>     str(list(a = 1,
>              list(b = 2,
>                   c = iris)))
>     ## List of 2
>     ##  $ a: num 1
>     ##  $  :List of 2
>     ##   ..$ b: num 2
>     ##   ..$ c:'data.frame':   150 obs. of  5 variables
>
>
>
>
> --
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Sep  2 19:05:46 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 2 Sep 2021 10:05:46 -0700 (PDT)
Subject: [R] read.csv() error
In-Reply-To: <87sfynyllh.fsf@enricoschumann.net>
References: <alpine.LNX.2.20.2109020931350.18288@salmo.appl-ecosys.com>
 <87sfynyllh.fsf@enricoschumann.net>
Message-ID: <alpine.LNX.2.20.2109021005000.18288@salmo.appl-ecosys.com>

On Thu, 2 Sep 2021, Enrico Schumann wrote:

> There is no column 'ht'.

Enrico,

New eyeballs caught my change in variable name that I kept missing.

Thanks very much,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Sep  2 20:16:16 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 2 Sep 2021 11:16:16 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>

On Mon, 30 Aug 2021, Richard O'Keefe wrote:

>> x <- rnorm(samples.per.day * 365)
>> length(x)
> [1] 105120
>
> Reshape the fake data into a matrix where each row represents one
> 24-hour period.
>
>> m <- matrix(x, ncol=samples.per.day, byrow=TRUE)

Richard,

Now I understand the need to keep the date and time as a single datetime
column; separately dplyr's sumamrize() provides daily means (too many data
points to plot over 3-5 years). I reformatted the data to provide a
sampledatetime column and a values column.

If I correctly understand the output of as.POSIXlt each date and time
element is separate, so input such as 2016-03-03 12:00 would now be 2016 03
03 12 00 (I've not read how the elements are separated). (The TZ is not
important because all data are either PST or PDT.)

> Now we can summarise the rows any way we want.
> The basic tool here is ?apply.
> ?rowMeans is said to be faster than using apply to calculate means,
> so we'll use that.  There is no *rowSds so we have to use apply
> for the standard deviation.  I use ?head because I don't want to
> post tens of thousands of meaningless numbers.

If I create a matrix using the above syntax the resulting rows contain all
recorded values for a specific day. What would be the syntax to collect all
values for each month?

This would result in 12 rows per year; the periods of record for the five
variables availble from that gauge station vary in length.

Regards,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Sep  2 20:42:41 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 2 Sep 2021 11:42:41 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>

On Thu, 2 Sep 2021, Rich Shepard wrote:

> If I correctly understand the output of as.POSIXlt each date and time
> element is separate, so input such as 2016-03-03 12:00 would now be 2016 03
> 03 12 00 (I've not read how the elements are separated). (The TZ is not
> important because all data are either PST or PDT.)

Using this script:
discharge <- read.csv('../data/water/discharge.dat', header = TRUE, sep = ',', stringsAsFactors = FALSE)
discharge$sampdate <- as.POSIXlt(discharge$sampdate, tz = "",
                                  format = '%Y-%m-%d %H:%M',
                                  optional = 'logical')
discharge$cfs <- as.numeric(discharge$cfs, length = 6)

I get this result:
> head(discharge)
              sampdate    cfs
1 2016-03-03 12:00:00 149000
2 2016-03-03 12:10:00 150000
3 2016-03-03 12:20:00 151000
4 2016-03-03 12:30:00 156000
5 2016-03-03 12:40:00 154000
6 2016-03-03 12:50:00 150000

I'm completely open to suggestions on using this output to calculate monthly
means and sds.

If dplyr:summarize() will do so please show me how to modify this command:
disc_monthly <- ( discharge
         %>% group_by(sampdate)
         %>% summarize(exp_value = mean(cfs, na.rm = TRUE))
because it produces daily means, not monthly means.

TIA,

Rich


From @kw@|mmo @end|ng |rom gm@||@com  Thu Sep  2 21:10:15 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 2 Sep 2021 15:10:15 -0400
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
Message-ID: <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>

You could use 'split' to create a list of data frames, and then apply a
function to each to get the means and sds.


cols <- "cfs"  # add more as necessary
S <- split(discharge[cols], format(discharge$sampdate, format = "%Y-%m"))
means <- do.call("rbind", lapply(S, colMeans, na.rm = TRUE))
sds   <- do.call("rbind", lapply(S, function(xx) sapply(xx, sd, na.rm =
TRUE)))

On Thu, Sep 2, 2021 at 3:01 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Thu, 2 Sep 2021, Rich Shepard wrote:
>
> > If I correctly understand the output of as.POSIXlt each date and time
> > element is separate, so input such as 2016-03-03 12:00 would now be 2016
> 03
> > 03 12 00 (I've not read how the elements are separated). (The TZ is not
> > important because all data are either PST or PDT.)
>
> Using this script:
> discharge <- read.csv('../data/water/discharge.dat', header = TRUE, sep =
> ',', stringsAsFactors = FALSE)
> discharge$sampdate <- as.POSIXlt(discharge$sampdate, tz = "",
>                                   format = '%Y-%m-%d %H:%M',
>                                   optional = 'logical')
> discharge$cfs <- as.numeric(discharge$cfs, length = 6)
>
> I get this result:
> > head(discharge)
>               sampdate    cfs
> 1 2016-03-03 12:00:00 149000
> 2 2016-03-03 12:10:00 150000
> 3 2016-03-03 12:20:00 151000
> 4 2016-03-03 12:30:00 156000
> 5 2016-03-03 12:40:00 154000
> 6 2016-03-03 12:50:00 150000
>
> I'm completely open to suggestions on using this output to calculate
> monthly
> means and sds.
>
> If dplyr:summarize() will do so please show me how to modify this command:
> disc_monthly <- ( discharge
>          %>% group_by(sampdate)
>          %>% summarize(exp_value = mean(cfs, na.rm = TRUE))
> because it produces daily means, not monthly means.
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m|n@h@|| @end|ng |rom um|ch@edu  Thu Sep  2 21:20:56 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Thu, 02 Sep 2021 22:20:56 +0300
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: Your message of "Thu, 02 Sep 2021 10:17:31 -0400."
 <CAPcHnpTtapJMLwv0Q-W1w8zzynthrC+myJO1zWiARAo8gbiyKw@mail.gmail.com>
Message-ID: <1021538.1630610456@apollo2.minshall.org>

Andrew,

> x[] <- lapply(x, function(xx) {
>     xx[is.nan(xx)] <- NA_real_
>     xx
> })
> 
> is different from
> 
> x <- lapply(x, function(xx) {
>     xx[is.nan(xx)] <- NA_real_
>     xx
> })

indeed, the two are different -- but some ignorance of mine is exposed.
i wonder, can you explain why the two are different?

is it because of (or, "is the clue...") this in the "Value:" section of
: ?"[<-.data.frame"
----
     For '[<-', '[[<-' and '$<-', a data frame.
----
?

cheers, Greg


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Sep  2 21:31:40 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 2 Sep 2021 12:31:40 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
 <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109021230300.18288@salmo.appl-ecosys.com>

On Thu, 2 Sep 2021, Andrew Simmons wrote:

> You could use 'split' to create a list of data frames, and then apply a
> function to each to get the means and sds.
>
> cols <- "cfs"  # add more as necessary
> S <- split(discharge[cols], format(discharge$sampdate, format = "%Y-%m"))
> means <- do.call("rbind", lapply(S, colMeans, na.rm = TRUE))
> sds   <- do.call("rbind", lapply(S, function(xx) sapply(xx, sd, na.rm =
> TRUE)))

Andrew,

Thank you for the valuable lesson. This is new to me and I know I'll have
use for it in the future, too.

Much appreciated!

Stay well,

Rich


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep  2 21:40:46 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 02 Sep 2021 12:40:46 -0700
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
 <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
Message-ID: <219F64F7-55D9-4D5B-9666-2C2DF6EC7AF4@dcn.davis.ca.us>

Regardless of whether you use the lower-level split function, or the higher-level aggregate function, or the tidyverse group_by function, the key is learning how to create the column that is the same for all records corresponding to the time interval of interest.

If you convert the sampdate to POSIXct, the tz IS important, because most of us use local timezones that respect daylight savings time, and a naive conversion of standard time will run into trouble if R is assuming daylight savings time applies. The lubridate package gets around this by always assuming UTC and giving you a function to "fix" the timezone after the conversion. I prefer to always be specific about timezones, at least by using so something like

    Sys.setenv( TZ = "Etc/GMT+8" )

which does not respect daylight savings.

Regarding using character data for identifying the month, in order to have clean plots of the data I prefer to use the trunc function but it returns a POSIXlt so I convert it to POSIXct:

    discharge$sampmonthbegin <- as.POSIXct( trunc( discharge$sampdate, units = "months" ) )

Then any of various ways can be used to aggregate the records by that column.

On September 2, 2021 12:10:15 PM PDT, Andrew Simmons <akwsimmo at gmail.com> wrote:
>You could use 'split' to create a list of data frames, and then apply a
>function to each to get the means and sds.
>
>
>cols <- "cfs"  # add more as necessary
>S <- split(discharge[cols], format(discharge$sampdate, format = "%Y-%m"))
>means <- do.call("rbind", lapply(S, colMeans, na.rm = TRUE))
>sds   <- do.call("rbind", lapply(S, function(xx) sapply(xx, sd, na.rm =
>TRUE)))
>
>On Thu, Sep 2, 2021 at 3:01 PM Rich Shepard <rshepard at appl-ecosys.com>
>wrote:
>
>> On Thu, 2 Sep 2021, Rich Shepard wrote:
>>
>> > If I correctly understand the output of as.POSIXlt each date and time
>> > element is separate, so input such as 2016-03-03 12:00 would now be 2016
>> 03
>> > 03 12 00 (I've not read how the elements are separated). (The TZ is not
>> > important because all data are either PST or PDT.)
>>
>> Using this script:
>> discharge <- read.csv('../data/water/discharge.dat', header = TRUE, sep =
>> ',', stringsAsFactors = FALSE)
>> discharge$sampdate <- as.POSIXlt(discharge$sampdate, tz = "",
>>                                   format = '%Y-%m-%d %H:%M',
>>                                   optional = 'logical')
>> discharge$cfs <- as.numeric(discharge$cfs, length = 6)
>>
>> I get this result:
>> > head(discharge)
>>               sampdate    cfs
>> 1 2016-03-03 12:00:00 149000
>> 2 2016-03-03 12:10:00 150000
>> 3 2016-03-03 12:20:00 151000
>> 4 2016-03-03 12:30:00 156000
>> 5 2016-03-03 12:40:00 154000
>> 6 2016-03-03 12:50:00 150000
>>
>> I'm completely open to suggestions on using this output to calculate
>> monthly
>> means and sds.
>>
>> If dplyr:summarize() will do so please show me how to modify this command:
>> disc_monthly <- ( discharge
>>          %>% group_by(sampdate)
>>          %>% summarize(exp_value = mean(cfs, na.rm = TRUE))
>> because it produces daily means, not monthly means.
>>
>> TIA,
>>
>> Rich
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep  2 21:44:07 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 2 Sep 2021 15:44:07 -0400
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <1021538.1630610456@apollo2.minshall.org>
References: <1021538.1630610456@apollo2.minshall.org>
Message-ID: <9df5d40e-f922-1282-025f-2b6b0b09e2e6@gmail.com>

On 02/09/2021 3:20 p.m., Greg Minshall wrote:
> Andrew,
> 
>> x[] <- lapply(x, function(xx) {
>>      xx[is.nan(xx)] <- NA_real_
>>      xx
>> })
>>
>> is different from
>>
>> x <- lapply(x, function(xx) {
>>      xx[is.nan(xx)] <- NA_real_
>>      xx
>> })
> 
> indeed, the two are different -- but some ignorance of mine is exposed.
> i wonder, can you explain why the two are different?

x <- lapply(...) says "set x to the list on the RHS", so x becomes a 
list, not a dataframe.

x[] <- lapply(...) says "set the values in x to the values in the list 
on the RHS", so x retains its class.

Duncan Murdoch


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep  2 22:04:31 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Sep 2021 21:04:31 +0100
Subject: [R] Show only header of str() function
In-Reply-To: <013401d7a018$2f6c6090$8e4521b0$@verizon.net>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
 <ca4ddb3d-110d-fe3f-240c-b8ba0217a146@sapo.pt>
 <013401d7a018$2f6c6090$8e4521b0$@verizon.net>
Message-ID: <fc87a627-f9b7-6c81-afb1-ad74c340c149@sapo.pt>

Hello,

I believe but do not have references that str was meant for interactive 
use, not for use in a script or package. If this is the case, then it 
should be rare to have to output to an object such as a character vector.

As for my solution, it is far from perfect, I try to avoid 
capture.output and, once again, limit its use to interactive R. It is 
overkill but I use it so few times that performance issues probably do 
not matter. It is sometimes a convenient way of solving an immediate 
problem and once done, move on.

As for the OP, Enrico's solution seems better, even with the 2nd printed 
line. Unless the 1st line is to be processed (?).

Hope this helps,

Rui Barradas

?s 17:32 de 02/09/21, Avi Gross via R-help escreveu:
> Thanks for the interesting method Rui. So that is a way to do a redirect of output not to a sinkfile but to an in-memory variable as a textConnection.
> 
> Of course, one has to wonder why the makers of str thought it would be too inefficient to have an option that returns the output in a form that can be captured directly, not just to the screen.
> 
> I have in the past done odd things such as using sink() to capture the output of a program that wrote another program dynamically in a loop. The saved file could then be used with source(). So a similar technique can capture the output from str() or cat() or whatever normally only writes to the screen and then the file can be read in to get the first line or whatever you need. I have had to play games to get the right output from some statistical programs too as it was assumed the user would read it, and sometimes had to cherry pick what I needed directly from withing the underlying object.
> 
> I suspect one reason R has so many packages including the tidyverse I like to use, is because the original R was designed in another time and in many places is not very consistent. I wonder how hard it would be to change some programs to simply accept an additional argument like sink() has where you can say split=TRUE and get a copy of what is being diverted to also come to the screen. I find cat() to be a very useful way to put more complicated output together than say print() but since it does not allow capture of the text into variables, I end up having to use other methods such as the glue() function or something like print(sprint("Hello %s, I have %d left.\n", "Brian", 5))
> 
> But you work with what you have. Your solution works albeit having read the function definition, is quite a bit of overkill when I read the code as it does things not needed. But as noted, if efficiency matters and you are only looking at data.frame style objects, there are cheaper solutions.
> 
> 
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
> Sent: Thursday, September 2, 2021 7:31 AM
> To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help <r-help at r-project.org>
> Subject: Re: [R] Show only header of str() function
> 
> Hello,
> 
> Not perfect but works for data.frames:
> 
> 
> header_str <- function(x){
>     capture.output(str(x))[[1]]
> }
> header_str(iris)
> header_str(AirPassengers)
> header_str(1:10)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 12:02 de 02/09/21, Luigi Marongiu escreveu:
>> Hello, is it possible to show only the header (that is: `'data.frame':
>> x obs. of  y variables:` part) of the str function?
>> Thank you
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 22:25:25 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 22:25:25 +0200
Subject: [R] Show only header of str() function
In-Reply-To: <CADfFDC4i_jDyDRJ44i64+MX=E_xEpKf9+Z5Wq03jOqwWRTO0-A@mail.gmail.com>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
 <87y28fynrn.fsf@enricoschumann.net>
 <CADfFDC4i_jDyDRJ44i64+MX=E_xEpKf9+Z5Wq03jOqwWRTO0-A@mail.gmail.com>
Message-ID: <CAMk+s2T3zgvd69nAij2dMz2xYgGe2XwmN+5KmCRMfKdX6MYMyg@mail.gmail.com>

Thanks, that is perfect!

On Thu, Sep 2, 2021 at 7:02 PM Deepayan Sarkar
<deepayan.sarkar at gmail.com> wrote:
>
> On Thu, Sep 2, 2021 at 9:26 PM Enrico Schumann <es at enricoschumann.net> wrote:
> >
> > On Thu, 02 Sep 2021, Luigi Marongiu writes:
> >
> > > Hello, is it possible to show only the header (that is: `'data.frame':
> > > x obs. of  y variables:` part) of the str function?
> > > Thank you
> >
> > Perhaps one more solution. You could limit the number
> > of list components to be printed, though it will leave
> > a "truncated" message.
> >
> >     str(iris, list.len = 0)
> >     ## 'data.frame':    150 obs. of  5 variables:
> >     ##   [list output truncated]
>
> Or use 'max.level', which is also generally useful for nested lists:
>
> str(iris, max.level=0)
> ## 'data.frame':    150 obs. of  5 variables:
>
> Best,
> -Deepayan
>
> > Since 'str' is a generic function, you could also
> > define a new 'str' method. Perhaps something among
> > those lines:
> >
> >     str.data.frame.oneline <- function (object, ...) {
> >         cat("'data.frame':\t", nrow(object), " obs. of  ",
> >             (p <- length(object)),
> >             " variable", if (p != 1) "s", "\n", sep = "")
> >         invisible(NULL)
> >     }
> >
> > (which is essentially taken from 'str.data.frame').
> >
> > Then:
> >
> >     class(iris) <- c("data.frame.oneline", class(iris))
> >
> >     str(iris)
> >     ## 'data.frame':  150 obs. of  5 variables
> >
> >     str(list(a = 1,
> >              list(b = 2,
> >                   c = iris)))
> >     ## List of 2
> >     ##  $ a: num 1
> >     ##  $  :List of 2
> >     ##   ..$ b: num 2
> >     ##   ..$ c:'data.frame':   150 obs. of  5 variables
> >
> >
> >
> >
> > --
> > Enrico Schumann
> > Lucerne, Switzerland
> > http://enricoschumann.net
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From e||z@_botto @end|ng |rom out|ook@com  Fri Sep  3 00:44:10 2021
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Thu, 2 Sep 2021 22:44:10 +0000
Subject: [R] plotting some rows in different color
Message-ID: <AS8P194MB099914EF5653553F8FC81E879ACE9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

Dear useRs,

For the following dataset,

dput(BFA3)

structure(c(17532, 17533, 17534, 17535, 17536, 17537, 17538,
17539, 17540, 17541, 17542, 17543, 17544, 17545, 17546, 17547,
17548, 17549, 17550, 17551, 17552, 17553, 17554, 17555, 17556,
17557, 17558, 17559, 17560, 17561, 17562, 17563, 17564, 17565,
17566, 17567, 17568, 17569, 17570, 17571, 17572, 17573, 17574,
17575, 17576, 17577, 17578, 17579, 17580, 17581, 17582, 17583,
17584, 17585, 17586, 17587, 17588, 17589, 17590, 17591, 17592,
17593, 17594, 17595, 17596, 17597, 17598, 17599, 17600, 17601,
17602, 17603, 17604, 17605, 17606, 17607, 17608, 17609, 17610,
17611, 17612, 17613, 17614, 17615, 17616, 17617, 17618, 17619,
17620, 17621, 17622, 17623, 17624, 17625, 17626, 17627, 17628,
17629, 17630, 17631, 17632, 17633, 17634, 17635, 17636, 17637,
17638, 17639, 17640, 17641, 17642, 17643, 17644, 17645, 17646,
17647, 17648, 17649, 17650, 17651, 17652, 17653, 17654, 17655,
17656, 17657, 17658, 17659, 17660, 17661, 17662, 17663, 17664,
17665, 17666, 17667, 17668, 17669, 17670, 17671, 17672, 17673,
17674, 17675, 17676, 17677, 17678, 17679, 17680, 17681, 17682,
17683, 17684, 17685, 17686, 17687, 17688, 17689, 17690, 17691,
17692, 17693, 17694, 17695, 17696, 17697, 17698, 17699, 17700,
17701, 17702, 17703, 17704, 17705, 17706, 17707, 17708, 17709,
17710, 17711, 17712, 17713, 17714, 17715, 17716, 17717, 17718,
17719, 17720, 17721, 17722, 17723, 17724, 17725, 17726, 17727,
17728, 17729, 17730, 17731, 17732, 17733, 17734, 17735, 17736,
17737, 17738, 17739, 17740, 17741, 17742, 17743, 17744, 17745,
17746, 17747, 17748, 17749, 17750, 17751, 17752, 17753, 17754,
17755, 17756, 17757, 17758, 17759, 17760, 17761, 17762, 17763,
17764, 17765, 17766, 17767, 17768, 17769, 17770, 17771, 17772,
17773, 17774, 17775, 17776, 17777, 17778, 17779, 17780, 17781,
17782, 17783, 17784, 17785, 17786, 17787, 17788, 17789, 17790,
17791, 17792, 17793, 17794, 17795, 17796, 17797, 17798, 17799,
17800, 17801, 17802, 17803, 17804, 17805, 17806, 17807, 17808,
17809, 17810, 17811, 17812, 17813, 17814, 17815, 17816, 17817,
17818, 17819, 17820, 17821, 17822, 17823, 17824, 17825, 17826,
17827, 17828, 17829, 17830, 17831, 17832, 17833, 17834, 17835,
17836, 17837, 17838, 17839, 17840, 17841, 17842, 17843, 17844,
17845, 17846, 17847, 17848, 17849, 17850, 17851, 17852, 17853,
17854, 17855, 17856, 17857, 17858, 17859, 17860, 17861, 17862,
17863, 17864, 17865, 17866, 17867, 17868, 17869, 17870, 17871,
17872, 17873, 17874, 17875, 17876, 17877, 17878, 17879, 17880,
17881, 17882, 17883, 17884, 17885, 17886, 17887, 17888, 17889,
17890, 17891, 17892, 17893, 17894, 17895, 17896, 8.36875, 15.12875,
14.2825, 12.355, 13.1825, 88.58375, 47.52125, 26.53375, 22.85875,
12.4925, 9.86875, 13.125, 14.055, 14.0175, 14.70625, 15.46125,
11.8725, 17.505, 19.8575, 74.875445, 62.018935, 23.9481046910236,
9.68, 9.6175, 9.78, 9.8875, 9.5125, 9.885, 9.99, 14.16625, 11.99375,
10.7875, 9.85625, 12.17125, 11.76625, 11.0425, 9.28875, 9.425,
23.29375, 12.66875, 9.6, 10.06875, 10.055, 30.89625, 36.69375,
16.63875, 11.84625, 12.825, 14.94, 11.495, 10.795, 9.14625, 10.17875,
11.0525, 10.0175, 10.67625, 10.4325, 12.5175, 13.93, 14.1675,
17.3175, 18.3875, 12.06, 10.3125, 9.94125, 10.8575, 11.2425,
13.28875, 43.885, 76.225, 125.277272727273, 198.285, 181.40125,
113.38875, 89.7925, 108.27875, 100.24375, 103.57, 189.015, 190.8925,
113.76875, 109.055, 96.4925, 99.04625, 127.47125, 300.86, 250.0725,
108.72125, 54.61, 39.76625, 30.11875, 31.46875, 40.73, 40.63,
27.48125, 24.9125, 24.105, 53.65625, 209.77125, 281.53125, 460.90875,
296.4225, 349.58375, 494.825, 404.4475, 510.68125, 681.65625,
637.78125, 838.40125, 740.0875, 601.81375, 246.75625, 127.1725,
92.36875, 78.11875, 73.61625, 62.77875, 59.87, 106.36, 115.31125,
64.025, 96.30125, 97.50625, 92.875, 92.49875, 89.295, 84.46375,
80.05625, 80.745, 114.13, 91.3225, 79.72125, 70.555, 30.8975,
14.28625, 13.02875, 93.59125, 246.7875, 54.37125, 29.45375, 16.2725,
15.175, 15.1475, 16.27875, 15.0575, 14.0425, 11.675, 12.9275,
11.26, 12.56, 183.555, 413.2025, 111.46375, 43.01375, 27.66125,
17.55875, 15.28, 14.88875, 14.60875, 14.44625, 281.95125, 85.16875,
24.6675, 14.88875, 15.02, 23.35125, 65.385, 83.95, 37.675, 22.31375,
15.1075, 15.02625, 96.39, 1856.72375, 612.275, 97.04875, 46.065,
28.62125, 23.22875, 234.78375, 58.21375, 33.29, 55.595, 66.57375,
81.39875, 42.84625, 26.945, 20.00375, 14.26875, 14.87625, 82.975,
85.12125, 35.7575, 26.875, 40.36375, 28.63875, 15.68, 13.70125,
29.42625, 51.81125, 26.6125, 15.56375, 13.725, 191.72625, 376.08625,
66.27875, 72.0275, 47.50375, 26.555, 16.58625, 16.9275, 15.26875,
33.3125, 64.98625, 66.93875, 194.75875, 65.15, 29.03375, 15.545,
14.83625, 14.89, 15.08875, 14.71, 146.1525, 112.855, 34.10625,
16.46625, 15.0175, 15.06125, 13.94625, 12.1075, 14.265, 14.30125,
13.77125, 12.51, 181.65625, 82.07875, 59.46125, 209.9875, 42.5525,
22.19, 32.95, 19.89875, 37.7175, 29.62875, 41.705, 34.1225, 23.7275,
20.565, 17.61125, 16.53125, 15.75125, 119.1025, 79.8675, 27.6375,
15.6675, 13.955, 16.54875, 24.2075, 21.97875, 17.3525, 19.9875,
18.2275, 109.57875, 73.06625, 47.2775, 50.1475, 28.66875, 17.8,
373.38375, 96.49875, 62.55125, 24.56375, 26.7675, 109.57375,
265.26125, 161.6575, 86.80375, 67.98, 62.88125, 64.88625, 97.665,
77.29125, 52.015, 81.7925, 75.305, 45.81875, 39.425, 37.78625,
35.40125, 32.1275, 31.89875, 31.77125, 30.1575, 28.62875, 28.065,
29.6875, 28.47125, 25.525, 25.2125, 22.68125, 22.81625, 20.165,
18.03125, 18.0425, 18.945, 19.88125, 24.6225, 25.6025, 24.65125,
31.76375, 27.41375, 22.8075, 28.64, 25.06875, 26.36125, 29.74625,
23.1, 19.67, 30.01625, 27.285, 43.90125, 50.1425, 33.45375, 23.2225,
19.91625, 27.22875, 46.14125, 33.70375, 38.7525, 178.45625, 85.08,
37.93875, 22.4225, 23.45125, 34.1375, 22.3325, 18.7125, 17.5375,
16.07625, 15.07375, 15.035, 15.16875, 15.6225, 15.9125, 15.3325,
15.09, 14.91125, 14.94125, 14.8325, 14.86375, 14.9675, 14.895,
14.81, 14.77125, 13.66625, 13.135, 13.00875, 12.86375, 12.9525,
13.0675, 12.97, 13.02, 13.10375, 12.96, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, 9.86875, 9.84942307692308, 9.83009615384615,
9.81076923076923, 9.79144230769231, 9.77211538461539, 9.75278846153846,
9.73346153846154, 9.71413461538462, 9.69480769230769, 9.67548076923077,
9.65615384615385, 9.63682692307692, 9.6175, 9.5825, 9.5475, 9.5125,
9.56979166666667, 9.62708333333333, 9.684375, 9.74166666666667,
9.79895833333333, 9.85625, 9.714375, 9.5725, 9.430625, 9.28875,
9.3665625, 9.444375, 9.5221875, 9.6, 9.55875, 9.5175, 9.47625,
9.435, 9.39375, 9.3525, 9.31125, 9.27, 9.22875, 9.1875, 9.14625,
9.20740384615385, 9.26855769230769, 9.32971153846154, 9.39086538461538,
9.45201923076923, 9.51317307692308, 9.57432692307692, 9.63548076923077,
9.69663461538462, 9.75778846153846, 9.81894230769231, 9.88009615384615,
9.94125, 10.8575, 11.2425, 11.7121774193548, 12.1395161290323,
12.5668548387097, 12.9941935483871, 13.4215322580645, 13.8488709677419,
14.2762096774194, 14.7035483870968, 15.1308870967742, 15.5582258064516,
15.985564516129, 16.4129032258065, 16.8402419354839, 17.2675806451613,
17.6949193548387, 18.1222580645161, 18.5495967741935, 18.976935483871,
19.4042741935484, 19.8316129032258, 20.2589516129032, 20.6862903225806,
21.1136290322581, 21.5409677419355, 21.9683064516129, 22.3956451612903,
22.8229838709677, 23.2503225806452, 23.6776612903226, 24.105,
25.8080952380952, 27.5111904761905, 29.2142857142857, 30.917380952381,
32.6204761904762, 34.3235714285714, 36.0266666666667, 37.7297619047619,
39.4328571428571, 41.1359523809524, 42.8390476190476, 44.5421428571429,
46.2452380952381, 47.9483333333333, 49.6514285714286, 51.3545238095238,
53.057619047619, 54.7607142857143, 56.4638095238095, 58.1669047619048,
59.87, 61.255, 62.64, 64.025, 60.4722321428572, 56.9194642857143,
53.3666964285714, 49.8139285714286, 46.2611607142857, 42.7083928571429,
39.155625, 35.6028571428571, 32.0500892857143, 28.4973214285714,
24.9445535714286, 21.3917857142857, 17.8390178571429, 14.28625,
13.02875, 12.8926923076923, 12.7566346153846, 12.6205769230769,
12.4845192307692, 12.3484615384615, 12.2124038461538, 12.0763461538462,
11.9402884615385, 11.8042307692308, 11.6681730769231, 11.5321153846154,
11.3960576923077, 11.26, 11.5496590909091, 11.8393181818182,
12.1289772727273, 12.4186363636364, 12.7082954545455, 12.9979545454545,
13.2876136363636, 13.5772727272727, 13.8669318181818, 14.1565909090909,
14.44625, 14.556875, 14.6675, 14.778125, 14.88875, 14.9059375,
14.923125, 14.9403125, 14.9575, 14.9746875, 14.991875, 15.0090625,
15.02625, 14.9816911764706, 14.9371323529412, 14.8925735294118,
14.8480147058824, 14.8034558823529, 14.7588970588235, 14.7143382352941,
14.6697794117647, 14.6252205882353, 14.5806617647059, 14.5361029411765,
14.4915441176471, 14.4469852941176, 14.4024264705882, 14.3578676470588,
14.3133088235294, 14.26875, 14.2056944444444, 14.1426388888889,
14.0795833333333, 14.0165277777778, 13.9534722222222, 13.8904166666667,
13.8273611111111, 13.7643055555556, 13.70125, 13.706, 13.71075,
13.7155, 13.72025, 13.725, 13.8965277777778, 14.0680555555556,
14.2395833333333, 14.4111111111111, 14.5826388888889, 14.7541666666667,
14.9256944444444, 15.0972222222222, 15.26875, 15.2146875, 15.160625,
15.1065625, 15.0525, 14.9984375, 14.944375, 14.8903125, 14.83625,
14.7941666666667, 14.7520833333333, 14.71, 14.3846875, 14.059375,
13.7340625, 13.40875, 13.0834375, 12.758125, 12.4328125, 12.1075,
12.1785576923077, 12.2496153846154, 12.3206730769231, 12.3917307692308,
12.4627884615385, 12.5338461538462, 12.6049038461538, 12.6759615384615,
12.7470192307692, 12.8180769230769, 12.8891346153846, 12.9601923076923,
13.03125, 13.1023076923077, 13.1733653846154, 13.2444230769231,
13.3154807692308, 13.3865384615385, 13.4575961538462, 13.5286538461538,
13.5997115384615, 13.6707692307692, 13.7418269230769, 13.8128846153846,
13.8839423076923, 13.955, 14.2754166666667, 14.5958333333333,
14.91625, 15.2366666666667, 15.5570833333333, 15.8775, 16.1979166666667,
16.5183333333333, 16.83875, 17.1591666666667, 17.4795833333333,
17.8, 17.8066071428571, 17.8132142857143, 17.8198214285714, 17.8264285714286,
17.8330357142857, 17.8396428571429, 17.84625, 17.8528571428571,
17.8594642857143, 17.8660714285714, 17.8726785714286, 17.8792857142857,
17.8858928571429, 17.8925, 17.8991071428571, 17.9057142857143,
17.9123214285714, 17.9189285714286, 17.9255357142857, 17.9321428571429,
17.93875, 17.9453571428571, 17.9519642857143, 17.9585714285714,
17.9651785714286, 17.9717857142857, 17.9783928571429, 17.985,
17.9916071428571, 17.9982142857143, 18.0048214285714, 18.0114285714286,
18.0180357142857, 18.0246428571429, 18.03125, 18.0425, 18.945,
19.0007692307692, 19.0565384615385, 19.1123076923077, 19.1680769230769,
19.2238461538462, 19.2796153846154, 19.3353846153846, 19.3911538461538,
19.4469230769231, 19.5026923076923, 19.5584615384615, 19.6142307692308,
19.67, 19.7051785714286, 19.7403571428571, 19.7755357142857,
19.8107142857143, 19.8458928571429, 19.8810714285714, 19.91625,
19.6419642857143, 19.3676785714286, 19.0933928571429, 18.8191071428571,
18.5448214285714, 18.2705357142857, 17.99625, 17.7219642857143,
17.4476785714286, 17.1733928571429, 16.8991071428571, 16.6248214285714,
16.3505357142857, 16.07625, 15.07375, 15.035, 15.0096875, 14.984375,
14.9590625, 14.93375, 14.9084375, 14.883125, 14.8578125, 14.8325,
14.61375, 14.395, 14.17625, 13.9575, 13.73875, 13.52, 13.135,
13.00875, 12.86375, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, 2, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, 4, NA,
3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
NA, NA, NA, NA, NA, NA, 1, 4, NA, NA, NA, NA, NA, NA, 2, NA,
NA, NA, NA, NA, 4, 9, NA, NA, NA, NA, 16, NA, NA, NA, NA, NA,
18, 12, 22, 22, 40, NA, NA, NA, NA, 19.5, 14, 17, NA, NA, NA,
NA, 21, 6, 11, NA, NA, NA, 8, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, 11, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, 5, 10, 6, NA, NA, NA, NA, NA, NA, NA, 4, 2, NA, NA,
9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 8, NA,
NA, 8, 1, NA, NA, NA, NA, NA, NA, NA, NA, 2, 4, 5, NA, 6, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, 6, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, 2, NA, 2, 5, 12, NA, NA, NA, NA,
NA, NA, NA, NA, NA, 19, 13, 19, 23, NA, NA, NA, NA, NA, NA, NA,
19, NA, NA, NA, NA, 17, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, 9, NA, NA, NA, 8, 4, 9, NA, NA, NA, NA, NA, NA, NA, NA, 3,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA), .Dim = c(365L, 4L), .Dimnames = list(
    c("17532", "17533", "17534", "17535", "17536", "17537", "17538",
    "17539", "17540", "17541", "17542", "17543", "17544", "17545",
    "17546", "17547", "17548", "17549", "17550", "17551", "17552",
    "17553", "17554", "17555", "17556", "17557", "17558", "17559",
    "17560", "17561", "17562", "17563", "17564", "17565", "17566",
    "17567", "17568", "17569", "17570", "17571", "17572", "17573",
    "17574", "17575", "17576", "17577", "17578", "17579", "17580",
    "17581", "17582", "17583", "17584", "17585", "17586", "17587",
    "17588", "17589", "17590", "17591", "17592", "17593", "17594",
    "17595", "17596", "17597", "17598", "17599", "17600", "17601",
    "17602", "17603", "17604", "17605", "17606", "17607", "17608",
    "17609", "17610", "17611", "17612", "17613", "17614", "17615",
    "17616", "17617", "17618", "17619", "17620", "17621", "17622",
    "17623", "17624", "17625", "17626", "17627", "17628", "17629",
    "17630", "17631", "17632", "17633", "17634", "17635", "17636",
    "17637", "17638", "17639", "17640", "17641", "17642", "17643",
    "17644", "17645", "17646", "17647", "17648", "17649", "17650",
    "17651", "17652", "17653", "17654", "17655", "17656", "17657",
    "17658", "17659", "17660", "17661", "17662", "17663", "17664",
    "17665", "17666", "17667", "17668", "17669", "17670", "17671",
    "17672", "17673", "17674", "17675", "17676", "17677", "17678",
    "17679", "17680", "17681", "17682", "17683", "17684", "17685",
    "17686", "17687", "17688", "17689", "17690", "17691", "17692",
    "17693", "17694", "17695", "17696", "17697", "17698", "17699",
    "17700", "17701", "17702", "17703", "17704", "17705", "17706",
    "17707", "17708", "17709", "17710", "17711", "17712", "17713",
    "17714", "17715", "17716", "17717", "17718", "17719", "17720",
    "17721", "17722", "17723", "17724", "17725", "17726", "17727",
    "17728", "17729", "17730", "17731", "17732", "17733", "17734",
    "17735", "17736", "17737", "17738", "17739", "17740", "17741",
    "17742", "17743", "17744", "17745", "17746", "17747", "17748",
    "17749", "17750", "17751", "17752", "17753", "17754", "17755",
    "17756", "17757", "17758", "17759", "17760", "17761", "17762",
    "17763", "17764", "17765", "17766", "17767", "17768", "17769",
    "17770", "17771", "17772", "17773", "17774", "17775", "17776",
    "17777", "17778", "17779", "17780", "17781", "17782", "17783",
    "17784", "17785", "17786", "17787", "17788", "17789", "17790",
    "17791", "17792", "17793", "17794", "17795", "17796", "17797",
    "17798", "17799", "17800", "17801", "17802", "17803", "17804",
    "17805", "17806", "17807", "17808", "17809", "17810", "17811",
    "17812", "17813", "17814", "17815", "17816", "17817", "17818",
    "17819", "17820", "17821", "17822", "17823", "17824", "17825",
    "17826", "17827", "17828", "17829", "17830", "17831", "17832",
    "17833", "17834", "17835", "17836", "17837", "17838", "17839",
    "17840", "17841", "17842", "17843", "17844", "17845", "17846",
    "17847", "17848", "17849", "17850", "17851", "17852", "17853",
    "17854", "17855", "17856", "17857", "17858", "17859", "17860",
    "17861", "17862", "17863", "17864", "17865", "17866", "17867",
    "17868", "17869", "17870", "17871", "17872", "17873", "17874",
    "17875", "17876", "17877", "17878", "17879", "17880", "17881",
    "17882", "17883", "17884", "17885", "17886", "17887", "17888",
    "17889", "17890", "17891", "17892", "17893", "17894", "17895",
    "17896"), c("DAT", "Q", "BF", "")))

The following command gives the values of 1st column for which the values in 2nd and 3rd columns are similar

val<-BFA3[,1][which(BFA3[,2]-BFA3[,3]==0)]

dput(val)
c(`17542` = 17542, `17555` = 17555, `17558` = 17558, `17564` = 17564,
`17568` = 17568, `17572` = 17572, `17583` = 17583, `17596` = 17596,
`17597` = 17597, `17598` = 17598, `17628` = 17628, `17649` = 17649,
`17652` = 17652, `17666` = 17666, `17667` = 17667, `17680` = 17680,
`17691` = 17691, `17695` = 17695, `17703` = 17703, `17720` = 17720,
`17729` = 17729, `17734` = 17734, `17743` = 17743, `17751` = 17751,
`17754` = 17754, `17762` = 17762, `17788` = 17788, `17800` = 17800,
`17835` = 17835, `17836` = 17836, `17837` = 17837, `17850` = 17850,
`17857` = 17857, `17871` = 17871, `17872` = 17872, `17873` = 17873,
`17881` = 17881, `17888` = 17888, `17889` = 17889, `17890` = 17890
)


Now for these values of "val" I want the values of 4th column to be plotted in "green" while all other in "red". I have tried the following command but to no avail

plot(as.numeric(as.Date(BFA3[,1])), BFA3[,4], pch=16, xlab = "", ylab = "",col= ifelse(BFA3[,1]==BFA3[,1][which(BFA3[,2]-BFA3[,3]==0)], "green","red"),axes=F)

Is there a way around it?
I thankyou in advance

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep  3 02:18:42 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 3 Sep 2021 10:18:42 +1000
Subject: [R] plotting some rows in different color
In-Reply-To: <AS8P194MB099914EF5653553F8FC81E879ACE9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099914EF5653553F8FC81E879ACE9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fWP8h509H7udmKMPB4Zm4jxNAiT1-t1gBia+ckgwqFcNw@mail.gmail.com>

Hi Eliza
This seems to work:

plot(BFA3[,1],BFA3[,4],
 pch=16, xlab = "", ylab = "",col=(BFA3[,2]==BFA3[,3])+2,axes=FALSE)

but I have no idea what you are trying to do with the

as.numeric(as.Date(...))

business.

Jim

On Fri, Sep 3, 2021 at 8:44 AM Eliza Botto <eliza_botto at outlook.com> wrote:
>
> Dear useRs,
>
> For the following dataset,
>
> dput(BFA3)
>
> structure(c(17532, 17533, 17534, 17535, 17536, 17537, 17538,
> 17539, 17540, 17541, 17542, 17543, 17544, 17545, 17546, 17547,
> 17548, 17549, 17550, 17551, 17552, 17553, 17554, 17555, 17556,
> 17557, 17558, 17559, 17560, 17561, 17562, 17563, 17564, 17565,
> 17566, 17567, 17568, 17569, 17570, 17571, 17572, 17573, 17574,
> 17575, 17576, 17577, 17578, 17579, 17580, 17581, 17582, 17583,
> 17584, 17585, 17586, 17587, 17588, 17589, 17590, 17591, 17592,
> 17593, 17594, 17595, 17596, 17597, 17598, 17599, 17600, 17601,
> 17602, 17603, 17604, 17605, 17606, 17607, 17608, 17609, 17610,
> 17611, 17612, 17613, 17614, 17615, 17616, 17617, 17618, 17619,
> 17620, 17621, 17622, 17623, 17624, 17625, 17626, 17627, 17628,
> 17629, 17630, 17631, 17632, 17633, 17634, 17635, 17636, 17637,
> 17638, 17639, 17640, 17641, 17642, 17643, 17644, 17645, 17646,
> 17647, 17648, 17649, 17650, 17651, 17652, 17653, 17654, 17655,
> 17656, 17657, 17658, 17659, 17660, 17661, 17662, 17663, 17664,
> 17665, 17666, 17667, 17668, 17669, 17670, 17671, 17672, 17673,
> 17674, 17675, 17676, 17677, 17678, 17679, 17680, 17681, 17682,
> 17683, 17684, 17685, 17686, 17687, 17688, 17689, 17690, 17691,
> 17692, 17693, 17694, 17695, 17696, 17697, 17698, 17699, 17700,
> 17701, 17702, 17703, 17704, 17705, 17706, 17707, 17708, 17709,
> 17710, 17711, 17712, 17713, 17714, 17715, 17716, 17717, 17718,
> 17719, 17720, 17721, 17722, 17723, 17724, 17725, 17726, 17727,
> 17728, 17729, 17730, 17731, 17732, 17733, 17734, 17735, 17736,
> 17737, 17738, 17739, 17740, 17741, 17742, 17743, 17744, 17745,
> 17746, 17747, 17748, 17749, 17750, 17751, 17752, 17753, 17754,
> 17755, 17756, 17757, 17758, 17759, 17760, 17761, 17762, 17763,
> 17764, 17765, 17766, 17767, 17768, 17769, 17770, 17771, 17772,
> 17773, 17774, 17775, 17776, 17777, 17778, 17779, 17780, 17781,
> 17782, 17783, 17784, 17785, 17786, 17787, 17788, 17789, 17790,
> 17791, 17792, 17793, 17794, 17795, 17796, 17797, 17798, 17799,
> 17800, 17801, 17802, 17803, 17804, 17805, 17806, 17807, 17808,
> 17809, 17810, 17811, 17812, 17813, 17814, 17815, 17816, 17817,
> 17818, 17819, 17820, 17821, 17822, 17823, 17824, 17825, 17826,
> 17827, 17828, 17829, 17830, 17831, 17832, 17833, 17834, 17835,
> 17836, 17837, 17838, 17839, 17840, 17841, 17842, 17843, 17844,
> 17845, 17846, 17847, 17848, 17849, 17850, 17851, 17852, 17853,
> 17854, 17855, 17856, 17857, 17858, 17859, 17860, 17861, 17862,
> 17863, 17864, 17865, 17866, 17867, 17868, 17869, 17870, 17871,
> 17872, 17873, 17874, 17875, 17876, 17877, 17878, 17879, 17880,
> 17881, 17882, 17883, 17884, 17885, 17886, 17887, 17888, 17889,
> 17890, 17891, 17892, 17893, 17894, 17895, 17896, 8.36875, 15.12875,
> 14.2825, 12.355, 13.1825, 88.58375, 47.52125, 26.53375, 22.85875,
> 12.4925, 9.86875, 13.125, 14.055, 14.0175, 14.70625, 15.46125,
> 11.8725, 17.505, 19.8575, 74.875445, 62.018935, 23.9481046910236,
> 9.68, 9.6175, 9.78, 9.8875, 9.5125, 9.885, 9.99, 14.16625, 11.99375,
> 10.7875, 9.85625, 12.17125, 11.76625, 11.0425, 9.28875, 9.425,
> 23.29375, 12.66875, 9.6, 10.06875, 10.055, 30.89625, 36.69375,
> 16.63875, 11.84625, 12.825, 14.94, 11.495, 10.795, 9.14625, 10.17875,
> 11.0525, 10.0175, 10.67625, 10.4325, 12.5175, 13.93, 14.1675,
> 17.3175, 18.3875, 12.06, 10.3125, 9.94125, 10.8575, 11.2425,
> 13.28875, 43.885, 76.225, 125.277272727273, 198.285, 181.40125,
> 113.38875, 89.7925, 108.27875, 100.24375, 103.57, 189.015, 190.8925,
> 113.76875, 109.055, 96.4925, 99.04625, 127.47125, 300.86, 250.0725,
> 108.72125, 54.61, 39.76625, 30.11875, 31.46875, 40.73, 40.63,
> 27.48125, 24.9125, 24.105, 53.65625, 209.77125, 281.53125, 460.90875,
> 296.4225, 349.58375, 494.825, 404.4475, 510.68125, 681.65625,
> 637.78125, 838.40125, 740.0875, 601.81375, 246.75625, 127.1725,
> 92.36875, 78.11875, 73.61625, 62.77875, 59.87, 106.36, 115.31125,
> 64.025, 96.30125, 97.50625, 92.875, 92.49875, 89.295, 84.46375,
> 80.05625, 80.745, 114.13, 91.3225, 79.72125, 70.555, 30.8975,
> 14.28625, 13.02875, 93.59125, 246.7875, 54.37125, 29.45375, 16.2725,
> 15.175, 15.1475, 16.27875, 15.0575, 14.0425, 11.675, 12.9275,
> 11.26, 12.56, 183.555, 413.2025, 111.46375, 43.01375, 27.66125,
> 17.55875, 15.28, 14.88875, 14.60875, 14.44625, 281.95125, 85.16875,
> 24.6675, 14.88875, 15.02, 23.35125, 65.385, 83.95, 37.675, 22.31375,
> 15.1075, 15.02625, 96.39, 1856.72375, 612.275, 97.04875, 46.065,
> 28.62125, 23.22875, 234.78375, 58.21375, 33.29, 55.595, 66.57375,
> 81.39875, 42.84625, 26.945, 20.00375, 14.26875, 14.87625, 82.975,
> 85.12125, 35.7575, 26.875, 40.36375, 28.63875, 15.68, 13.70125,
> 29.42625, 51.81125, 26.6125, 15.56375, 13.725, 191.72625, 376.08625,
> 66.27875, 72.0275, 47.50375, 26.555, 16.58625, 16.9275, 15.26875,
> 33.3125, 64.98625, 66.93875, 194.75875, 65.15, 29.03375, 15.545,
> 14.83625, 14.89, 15.08875, 14.71, 146.1525, 112.855, 34.10625,
> 16.46625, 15.0175, 15.06125, 13.94625, 12.1075, 14.265, 14.30125,
> 13.77125, 12.51, 181.65625, 82.07875, 59.46125, 209.9875, 42.5525,
> 22.19, 32.95, 19.89875, 37.7175, 29.62875, 41.705, 34.1225, 23.7275,
> 20.565, 17.61125, 16.53125, 15.75125, 119.1025, 79.8675, 27.6375,
> 15.6675, 13.955, 16.54875, 24.2075, 21.97875, 17.3525, 19.9875,
> 18.2275, 109.57875, 73.06625, 47.2775, 50.1475, 28.66875, 17.8,
> 373.38375, 96.49875, 62.55125, 24.56375, 26.7675, 109.57375,
> 265.26125, 161.6575, 86.80375, 67.98, 62.88125, 64.88625, 97.665,
> 77.29125, 52.015, 81.7925, 75.305, 45.81875, 39.425, 37.78625,
> 35.40125, 32.1275, 31.89875, 31.77125, 30.1575, 28.62875, 28.065,
> 29.6875, 28.47125, 25.525, 25.2125, 22.68125, 22.81625, 20.165,
> 18.03125, 18.0425, 18.945, 19.88125, 24.6225, 25.6025, 24.65125,
> 31.76375, 27.41375, 22.8075, 28.64, 25.06875, 26.36125, 29.74625,
> 23.1, 19.67, 30.01625, 27.285, 43.90125, 50.1425, 33.45375, 23.2225,
> 19.91625, 27.22875, 46.14125, 33.70375, 38.7525, 178.45625, 85.08,
> 37.93875, 22.4225, 23.45125, 34.1375, 22.3325, 18.7125, 17.5375,
> 16.07625, 15.07375, 15.035, 15.16875, 15.6225, 15.9125, 15.3325,
> 15.09, 14.91125, 14.94125, 14.8325, 14.86375, 14.9675, 14.895,
> 14.81, 14.77125, 13.66625, 13.135, 13.00875, 12.86375, 12.9525,
> 13.0675, 12.97, 13.02, 13.10375, 12.96, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, 9.86875, 9.84942307692308, 9.83009615384615,
> 9.81076923076923, 9.79144230769231, 9.77211538461539, 9.75278846153846,
> 9.73346153846154, 9.71413461538462, 9.69480769230769, 9.67548076923077,
> 9.65615384615385, 9.63682692307692, 9.6175, 9.5825, 9.5475, 9.5125,
> 9.56979166666667, 9.62708333333333, 9.684375, 9.74166666666667,
> 9.79895833333333, 9.85625, 9.714375, 9.5725, 9.430625, 9.28875,
> 9.3665625, 9.444375, 9.5221875, 9.6, 9.55875, 9.5175, 9.47625,
> 9.435, 9.39375, 9.3525, 9.31125, 9.27, 9.22875, 9.1875, 9.14625,
> 9.20740384615385, 9.26855769230769, 9.32971153846154, 9.39086538461538,
> 9.45201923076923, 9.51317307692308, 9.57432692307692, 9.63548076923077,
> 9.69663461538462, 9.75778846153846, 9.81894230769231, 9.88009615384615,
> 9.94125, 10.8575, 11.2425, 11.7121774193548, 12.1395161290323,
> 12.5668548387097, 12.9941935483871, 13.4215322580645, 13.8488709677419,
> 14.2762096774194, 14.7035483870968, 15.1308870967742, 15.5582258064516,
> 15.985564516129, 16.4129032258065, 16.8402419354839, 17.2675806451613,
> 17.6949193548387, 18.1222580645161, 18.5495967741935, 18.976935483871,
> 19.4042741935484, 19.8316129032258, 20.2589516129032, 20.6862903225806,
> 21.1136290322581, 21.5409677419355, 21.9683064516129, 22.3956451612903,
> 22.8229838709677, 23.2503225806452, 23.6776612903226, 24.105,
> 25.8080952380952, 27.5111904761905, 29.2142857142857, 30.917380952381,
> 32.6204761904762, 34.3235714285714, 36.0266666666667, 37.7297619047619,
> 39.4328571428571, 41.1359523809524, 42.8390476190476, 44.5421428571429,
> 46.2452380952381, 47.9483333333333, 49.6514285714286, 51.3545238095238,
> 53.057619047619, 54.7607142857143, 56.4638095238095, 58.1669047619048,
> 59.87, 61.255, 62.64, 64.025, 60.4722321428572, 56.9194642857143,
> 53.3666964285714, 49.8139285714286, 46.2611607142857, 42.7083928571429,
> 39.155625, 35.6028571428571, 32.0500892857143, 28.4973214285714,
> 24.9445535714286, 21.3917857142857, 17.8390178571429, 14.28625,
> 13.02875, 12.8926923076923, 12.7566346153846, 12.6205769230769,
> 12.4845192307692, 12.3484615384615, 12.2124038461538, 12.0763461538462,
> 11.9402884615385, 11.8042307692308, 11.6681730769231, 11.5321153846154,
> 11.3960576923077, 11.26, 11.5496590909091, 11.8393181818182,
> 12.1289772727273, 12.4186363636364, 12.7082954545455, 12.9979545454545,
> 13.2876136363636, 13.5772727272727, 13.8669318181818, 14.1565909090909,
> 14.44625, 14.556875, 14.6675, 14.778125, 14.88875, 14.9059375,
> 14.923125, 14.9403125, 14.9575, 14.9746875, 14.991875, 15.0090625,
> 15.02625, 14.9816911764706, 14.9371323529412, 14.8925735294118,
> 14.8480147058824, 14.8034558823529, 14.7588970588235, 14.7143382352941,
> 14.6697794117647, 14.6252205882353, 14.5806617647059, 14.5361029411765,
> 14.4915441176471, 14.4469852941176, 14.4024264705882, 14.3578676470588,
> 14.3133088235294, 14.26875, 14.2056944444444, 14.1426388888889,
> 14.0795833333333, 14.0165277777778, 13.9534722222222, 13.8904166666667,
> 13.8273611111111, 13.7643055555556, 13.70125, 13.706, 13.71075,
> 13.7155, 13.72025, 13.725, 13.8965277777778, 14.0680555555556,
> 14.2395833333333, 14.4111111111111, 14.5826388888889, 14.7541666666667,
> 14.9256944444444, 15.0972222222222, 15.26875, 15.2146875, 15.160625,
> 15.1065625, 15.0525, 14.9984375, 14.944375, 14.8903125, 14.83625,
> 14.7941666666667, 14.7520833333333, 14.71, 14.3846875, 14.059375,
> 13.7340625, 13.40875, 13.0834375, 12.758125, 12.4328125, 12.1075,
> 12.1785576923077, 12.2496153846154, 12.3206730769231, 12.3917307692308,
> 12.4627884615385, 12.5338461538462, 12.6049038461538, 12.6759615384615,
> 12.7470192307692, 12.8180769230769, 12.8891346153846, 12.9601923076923,
> 13.03125, 13.1023076923077, 13.1733653846154, 13.2444230769231,
> 13.3154807692308, 13.3865384615385, 13.4575961538462, 13.5286538461538,
> 13.5997115384615, 13.6707692307692, 13.7418269230769, 13.8128846153846,
> 13.8839423076923, 13.955, 14.2754166666667, 14.5958333333333,
> 14.91625, 15.2366666666667, 15.5570833333333, 15.8775, 16.1979166666667,
> 16.5183333333333, 16.83875, 17.1591666666667, 17.4795833333333,
> 17.8, 17.8066071428571, 17.8132142857143, 17.8198214285714, 17.8264285714286,
> 17.8330357142857, 17.8396428571429, 17.84625, 17.8528571428571,
> 17.8594642857143, 17.8660714285714, 17.8726785714286, 17.8792857142857,
> 17.8858928571429, 17.8925, 17.8991071428571, 17.9057142857143,
> 17.9123214285714, 17.9189285714286, 17.9255357142857, 17.9321428571429,
> 17.93875, 17.9453571428571, 17.9519642857143, 17.9585714285714,
> 17.9651785714286, 17.9717857142857, 17.9783928571429, 17.985,
> 17.9916071428571, 17.9982142857143, 18.0048214285714, 18.0114285714286,
> 18.0180357142857, 18.0246428571429, 18.03125, 18.0425, 18.945,
> 19.0007692307692, 19.0565384615385, 19.1123076923077, 19.1680769230769,
> 19.2238461538462, 19.2796153846154, 19.3353846153846, 19.3911538461538,
> 19.4469230769231, 19.5026923076923, 19.5584615384615, 19.6142307692308,
> 19.67, 19.7051785714286, 19.7403571428571, 19.7755357142857,
> 19.8107142857143, 19.8458928571429, 19.8810714285714, 19.91625,
> 19.6419642857143, 19.3676785714286, 19.0933928571429, 18.8191071428571,
> 18.5448214285714, 18.2705357142857, 17.99625, 17.7219642857143,
> 17.4476785714286, 17.1733928571429, 16.8991071428571, 16.6248214285714,
> 16.3505357142857, 16.07625, 15.07375, 15.035, 15.0096875, 14.984375,
> 14.9590625, 14.93375, 14.9084375, 14.883125, 14.8578125, 14.8325,
> 14.61375, 14.395, 14.17625, 13.9575, 13.73875, 13.52, 13.135,
> 13.00875, 12.86375, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, 2, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, 4, NA,
> 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
> NA, NA, NA, NA, NA, NA, 1, 4, NA, NA, NA, NA, NA, NA, 2, NA,
> NA, NA, NA, NA, 4, 9, NA, NA, NA, NA, 16, NA, NA, NA, NA, NA,
> 18, 12, 22, 22, 40, NA, NA, NA, NA, 19.5, 14, 17, NA, NA, NA,
> NA, 21, 6, 11, NA, NA, NA, 8, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, 11, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, 5, 10, 6, NA, NA, NA, NA, NA, NA, NA, 4, 2, NA, NA,
> 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 8, NA,
> NA, 8, 1, NA, NA, NA, NA, NA, NA, NA, NA, 2, 4, 5, NA, 6, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, 6, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, 2, NA, 2, 5, 12, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, 19, 13, 19, 23, NA, NA, NA, NA, NA, NA, NA,
> 19, NA, NA, NA, NA, 17, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, 9, NA, NA, NA, 8, 4, 9, NA, NA, NA, NA, NA, NA, NA, NA, 3,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA), .Dim = c(365L, 4L), .Dimnames = list(
>     c("17532", "17533", "17534", "17535", "17536", "17537", "17538",
>     "17539", "17540", "17541", "17542", "17543", "17544", "17545",
>     "17546", "17547", "17548", "17549", "17550", "17551", "17552",
>     "17553", "17554", "17555", "17556", "17557", "17558", "17559",
>     "17560", "17561", "17562", "17563", "17564", "17565", "17566",
>     "17567", "17568", "17569", "17570", "17571", "17572", "17573",
>     "17574", "17575", "17576", "17577", "17578", "17579", "17580",
>     "17581", "17582", "17583", "17584", "17585", "17586", "17587",
>     "17588", "17589", "17590", "17591", "17592", "17593", "17594",
>     "17595", "17596", "17597", "17598", "17599", "17600", "17601",
>     "17602", "17603", "17604", "17605", "17606", "17607", "17608",
>     "17609", "17610", "17611", "17612", "17613", "17614", "17615",
>     "17616", "17617", "17618", "17619", "17620", "17621", "17622",
>     "17623", "17624", "17625", "17626", "17627", "17628", "17629",
>     "17630", "17631", "17632", "17633", "17634", "17635", "17636",
>     "17637", "17638", "17639", "17640", "17641", "17642", "17643",
>     "17644", "17645", "17646", "17647", "17648", "17649", "17650",
>     "17651", "17652", "17653", "17654", "17655", "17656", "17657",
>     "17658", "17659", "17660", "17661", "17662", "17663", "17664",
>     "17665", "17666", "17667", "17668", "17669", "17670", "17671",
>     "17672", "17673", "17674", "17675", "17676", "17677", "17678",
>     "17679", "17680", "17681", "17682", "17683", "17684", "17685",
>     "17686", "17687", "17688", "17689", "17690", "17691", "17692",
>     "17693", "17694", "17695", "17696", "17697", "17698", "17699",
>     "17700", "17701", "17702", "17703", "17704", "17705", "17706",
>     "17707", "17708", "17709", "17710", "17711", "17712", "17713",
>     "17714", "17715", "17716", "17717", "17718", "17719", "17720",
>     "17721", "17722", "17723", "17724", "17725", "17726", "17727",
>     "17728", "17729", "17730", "17731", "17732", "17733", "17734",
>     "17735", "17736", "17737", "17738", "17739", "17740", "17741",
>     "17742", "17743", "17744", "17745", "17746", "17747", "17748",
>     "17749", "17750", "17751", "17752", "17753", "17754", "17755",
>     "17756", "17757", "17758", "17759", "17760", "17761", "17762",
>     "17763", "17764", "17765", "17766", "17767", "17768", "17769",
>     "17770", "17771", "17772", "17773", "17774", "17775", "17776",
>     "17777", "17778", "17779", "17780", "17781", "17782", "17783",
>     "17784", "17785", "17786", "17787", "17788", "17789", "17790",
>     "17791", "17792", "17793", "17794", "17795", "17796", "17797",
>     "17798", "17799", "17800", "17801", "17802", "17803", "17804",
>     "17805", "17806", "17807", "17808", "17809", "17810", "17811",
>     "17812", "17813", "17814", "17815", "17816", "17817", "17818",
>     "17819", "17820", "17821", "17822", "17823", "17824", "17825",
>     "17826", "17827", "17828", "17829", "17830", "17831", "17832",
>     "17833", "17834", "17835", "17836", "17837", "17838", "17839",
>     "17840", "17841", "17842", "17843", "17844", "17845", "17846",
>     "17847", "17848", "17849", "17850", "17851", "17852", "17853",
>     "17854", "17855", "17856", "17857", "17858", "17859", "17860",
>     "17861", "17862", "17863", "17864", "17865", "17866", "17867",
>     "17868", "17869", "17870", "17871", "17872", "17873", "17874",
>     "17875", "17876", "17877", "17878", "17879", "17880", "17881",
>     "17882", "17883", "17884", "17885", "17886", "17887", "17888",
>     "17889", "17890", "17891", "17892", "17893", "17894", "17895",
>     "17896"), c("DAT", "Q", "BF", "")))
>
> The following command gives the values of 1st column for which the values in 2nd and 3rd columns are similar
>
> val<-BFA3[,1][which(BFA3[,2]-BFA3[,3]==0)]
>
> dput(val)
> c(`17542` = 17542, `17555` = 17555, `17558` = 17558, `17564` = 17564,
> `17568` = 17568, `17572` = 17572, `17583` = 17583, `17596` = 17596,
> `17597` = 17597, `17598` = 17598, `17628` = 17628, `17649` = 17649,
> `17652` = 17652, `17666` = 17666, `17667` = 17667, `17680` = 17680,
> `17691` = 17691, `17695` = 17695, `17703` = 17703, `17720` = 17720,
> `17729` = 17729, `17734` = 17734, `17743` = 17743, `17751` = 17751,
> `17754` = 17754, `17762` = 17762, `17788` = 17788, `17800` = 17800,
> `17835` = 17835, `17836` = 17836, `17837` = 17837, `17850` = 17850,
> `17857` = 17857, `17871` = 17871, `17872` = 17872, `17873` = 17873,
> `17881` = 17881, `17888` = 17888, `17889` = 17889, `17890` = 17890
> )
>
>
> Now for these values of "val" I want the values of 4th column to be plotted in "green" while all other in "red". I have tried the following command but to no avail
>
> plot(as.numeric(as.Date(BFA3[,1])), BFA3[,4], pch=16, xlab = "", ylab = "",col= ifelse(BFA3[,1]==BFA3[,1][which(BFA3[,2]-BFA3[,3]==0)], "green","red"),axes=F)
>
> Is there a way around it?
> I thankyou in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Sep  3 03:30:28 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Thu, 2 Sep 2021 21:30:28 -0400
Subject: [R] Splitting a data column randomly into 3 groups
Message-ID: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>

Dear All:

How to split a column data *randomly* into three groups. Please see the
attached data. I need to split column #2 titled "Data"

with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: data_example.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210902/064b4219/attachment.txt>

From @v|gro@@ @end|ng |rom ver|zon@net  Fri Sep  3 03:42:06 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 2 Sep 2021 21:42:06 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
Message-ID: <00e501d7a064$e7113f80$b533be80$@verizon.net>

What is stopping you Abou?

Some of us here start wondering if we have better things to do than homework for others. Help is supposed to be after they try and encounter issues that we may help with.

So think about your problem. You supplied data in a file that is NOT in CSV format but is in Tab separated format.

You need to get it in to your program and store it in something. It looks like you have 204 items so 1/3 of those would be exactly 68.

So if your data is in an object like a vector or data.frame, you want to choose random number between 1 and 204. How do you do that? You need 1/3 of the length of the object items, in your case 68.

Now extract the items with  those indices into say A1. Extract all the rest into a temporary item.

Make another 68 random indices, with no overlap, and copy those items into A2 and the ones that do not have those into A3 and you are sort of done, other than some cleanup or whatever.

There are many ways to do the above and I am sure packages too.

But since you have made no visible effort, I personally am not going to pick anything in particular.

Had you shown some text and code along the lines of the above and just wanted to know how to copy just the ones that were not selected, we could easily ...


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of AbouEl-Makarim Aboueissa
Sent: Thursday, September 2, 2021 9:30 PM
To: R mailing list <r-help at r-project.org>
Subject: [R] Splitting a data column randomly into 3 groups

Dear All:

How to split a column data *randomly* into three groups. Please see the attached data. I need to split column #2 titled "Data"

with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science* *Graduate Coordinator*

*Department of Mathematics and Statistics* *University of Southern Maine*


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep  3 03:46:04 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 3 Sep 2021 11:46:04 +1000
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
Message-ID: <CA+8X3fUn-XTqM3dUgdDu7+vnBTZPKw=-kh7W=cQmWFDz6EX+mQ@mail.gmail.com>

Hi Abou,
One way is to shuffle the original data frame using sample(). and
split up the result into three equal parts.
I was going to provide example code, but Avi's response popped up and
I kind of agree with him.

Jim

On Fri, Sep 3, 2021 at 11:31 AM AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> Dear All:
>
> How to split a column data *randomly* into three groups. Please see the
> attached data. I need to split column #2 titled "Data"
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Sep  3 03:51:20 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Thu, 2 Sep 2021 21:51:20 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <00e501d7a064$e7113f80$b533be80$@verizon.net>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
 <00e501d7a064$e7113f80$b533be80$@verizon.net>
Message-ID: <CAE9stmdgQRWkJZOKqy7PYFTiSgC+v0oc1qkKEsFGbfzNo03HEg@mail.gmail.com>

Sorry, please forget about it. I believe that I am very serious when I
posted my question.

with thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Thu, Sep 2, 2021 at 9:42 PM Avi Gross via R-help <r-help at r-project.org>
wrote:

> What is stopping you Abou?
>
> Some of us here start wondering if we have better things to do than
> homework for others. Help is supposed to be after they try and encounter
> issues that we may help with.
>
> So think about your problem. You supplied data in a file that is NOT in
> CSV format but is in Tab separated format.
>
> You need to get it in to your program and store it in something. It looks
> like you have 204 items so 1/3 of those would be exactly 68.
>
> So if your data is in an object like a vector or data.frame, you want to
> choose random number between 1 and 204. How do you do that? You need 1/3 of
> the length of the object items, in your case 68.
>
> Now extract the items with  those indices into say A1. Extract all the
> rest into a temporary item.
>
> Make another 68 random indices, with no overlap, and copy those items into
> A2 and the ones that do not have those into A3 and you are sort of done,
> other than some cleanup or whatever.
>
> There are many ways to do the above and I am sure packages too.
>
> But since you have made no visible effort, I personally am not going to
> pick anything in particular.
>
> Had you shown some text and code along the lines of the above and just
> wanted to know how to copy just the ones that were not selected, we could
> easily ...
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of AbouEl-Makarim
> Aboueissa
> Sent: Thursday, September 2, 2021 9:30 PM
> To: R mailing list <r-help at r-project.org>
> Subject: [R] Splitting a data column randomly into 3 groups
>
> Dear All:
>
> How to split a column data *randomly* into three groups. Please see the
> attached data. I need to split column #2 titled "Data"
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science* *Graduate Coordinator*
>
> *Department of Mathematics and Statistics* *University of Southern Maine*
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Fri Sep  3 04:42:18 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 2 Sep 2021 22:42:18 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAE9stmdgQRWkJZOKqy7PYFTiSgC+v0oc1qkKEsFGbfzNo03HEg@mail.gmail.com>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
 <00e501d7a064$e7113f80$b533be80$@verizon.net>
 <CAE9stmdgQRWkJZOKqy7PYFTiSgC+v0oc1qkKEsFGbfzNo03HEg@mail.gmail.com>
Message-ID: <012901d7a06d$50067980$f0136c80$@verizon.net>

Abou,

 

I am not trying to be negative. Assuming you are a professor of Statistics, your request seems odd as what you are asking about is very routine in much of statistical work where you want to make a model or something using just part of your data and need to reserve some to check if you perhaps trained an algorithm too much for the original data used.

 

A simple online search before asking questions here is appreciated. I did a quick search for something like ?R split data into three parts? and see several applicable answers.

 

There are people on this forum who actually get paid to do nontrivial tasks and do not mind help in spots but feel sort of used if expected to write a serious amount of code and perhaps then be asked to redo it with more bells and whistles added. A recent badly phrased request comes to mind where several of us provided and answer only to find out it was for a different scenario, ?

 

So let me continue with a serious answer. May we assume you KNOW how to read the data in to something like a data.frame? If so, and if you see no need or value in doing this the hard way, then your question could have been to ask if there is an R built-in function or perhaps a pacjkage already set to solve it quickly. Again, a simple online search can do wonders.  Here, for example is a package called caret and this page discusses spliutting data multiple ways:

 

https://topepo.github.io/caret/data-splitting.html

 

There are other such pages suggesting how to do it using base R.

 

Here is one that gives an example on how to make  three unequal partitions:

 

inds <- partition(iris$Sepal.Length, p = c(train = 0.6, valid = 0.2, test = 0.2))

 

 

There is more to do below but in the above, you would use whatever names you want instead of train/valid/test and set all three to 0.33 and so on.

 

I repeat, that what you want to do strikes some of us as a fairly routine thing to do and lots of people have written how they have done it and you can pick and choose, or redo it on your own. If what you have is a homework assignment, the appropriate thing is to have you learn to use some technique yourself and perhaps get minor help when it fails. But if you will be doing this regularly, use of some packages is highly valuable.

 

Good Luck.

 

 

 

 

 

From: AbouEl-Makarim Aboueissa <abouelmakarim1962 at gmail.com> 
Sent: Thursday, September 2, 2021 9:51 PM
To: Avi Gross <avigross at verizon.net>
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] Splitting a data column randomly into 3 groups

 

Sorry, please forget about it. I believe that I am very serious when I posted my question.

 

with thanks

abou


______________________

AbouEl-Makarim Aboueissa, PhD

 

Professor, Statistics and Data Science

Graduate Coordinator

Department of Mathematics and Statistics

University of Southern Maine

 

 

 

On Thu, Sep 2, 2021 at 9:42 PM Avi Gross via R-help <r-help at r-project.org <mailto:r-help at r-project.org> > wrote:

What is stopping you Abou?

Some of us here start wondering if we have better things to do than homework for others. Help is supposed to be after they try and encounter issues that we may help with.

So think about your problem. You supplied data in a file that is NOT in CSV format but is in Tab separated format.

You need to get it in to your program and store it in something. It looks like you have 204 items so 1/3 of those would be exactly 68.

So if your data is in an object like a vector or data.frame, you want to choose random number between 1 and 204. How do you do that? You need 1/3 of the length of the object items, in your case 68.

Now extract the items with  those indices into say A1. Extract all the rest into a temporary item.

Make another 68 random indices, with no overlap, and copy those items into A2 and the ones that do not have those into A3 and you are sort of done, other than some cleanup or whatever.

There are many ways to do the above and I am sure packages too.

But since you have made no visible effort, I personally am not going to pick anything in particular.

Had you shown some text and code along the lines of the above and just wanted to know how to copy just the ones that were not selected, we could easily ...


-----Original Message-----
From: R-help <r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org> > On Behalf Of AbouEl-Makarim Aboueissa
Sent: Thursday, September 2, 2021 9:30 PM
To: R mailing list <r-help at r-project.org <mailto:r-help at r-project.org> >
Subject: [R] Splitting a data column randomly into 3 groups

Dear All:

How to split a column data *randomly* into three groups. Please see the attached data. I need to split column #2 titled "Data"

with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science* *Graduate Coordinator*

*Department of Mathematics and Statistics* *University of Southern Maine*

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Sep  3 08:26:49 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 3 Sep 2021 06:26:49 +0000
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
Message-ID: <8252a0fe9c2b42e1b855cfd24015e622@SRVEXCHCM1302.precheza.cz>

Hi Luigi.

Weird. But maybe it is the desired behaviour of summary when calculating
mean of numeric column full of NAs.

See example

dat <- data.frame(x=rep(NA, 110), y=rep(1, 110), z= rnorm(110))

# change all values in second column to NA
dat[,2] <- NA
# change some of them to NAN
dat[5:6, 2:3] <- 0/0

# see summary
summary(dat)
    x                 y             z          
 Mode:logical   Min.   : NA   Min.   :-1.9798  
 NA's:110       1st Qu.: NA   1st Qu.:-0.4729  
                Median : NA   Median : 0.1745  
                Mean   :NaN   Mean   : 0.1856  
                3rd Qu.: NA   3rd Qu.: 0.8017  
                Max.   : NA   Max.   : 2.5075  
                NA's   :110   NA's   :2        

# change NAN values to NA
dat[sapply(dat, is.nan)] <- NA
*************************

#summary is same
summary(dat)
    x                 y             z          
 Mode:logical   Min.   : NA   Min.   :-1.9798  
 NA's:110       1st Qu.: NA   1st Qu.:-0.4729  
                Median : NA   Median : 0.1745  
                Mean   :NaN   Mean   : 0.1856  
                3rd Qu.: NA   3rd Qu.: 0.8017  
                Max.   : NA   Max.   : 2.5075  
                NA's   :110   NA's   :2        

# but no NAN value in data
dat[1:10,]
    x  y          z
1  NA NA -0.9148696
2  NA NA  0.7110570
3  NA NA -0.1901676
4  NA NA  0.5900650
5  NA NA         NA
6  NA NA         NA
7  NA NA  0.7987658
8  NA NA -0.5225229
9  NA NA  0.7673103
10 NA NA -0.5263897

So my "nice compact command"
dat[sapply(dat, is.nan)] <- NA

works as expected, but summary gives as mean NAN.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> Sent: Thursday, September 2, 2021 3:46 PM
> To: Andrew Simmons <akwsimmo at gmail.com>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] How to globally convert NaN to NA in dataframe?
> 
> `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I still
get
> NaN when using the summary function, for instance one of the columns give:
> ```
> Min.   : NA
> 1st Qu.: NA
> Median : NA
> Mean   :NaN
> 3rd Qu.: NA
> Max.   : NA
> NA's   :110
> ```
> I tried to implement the second solution but:
> ```
> df <- lapply(x, function(xx) {
>   xx[is.nan(xx)] <- NA
> })
> > str(df)
> List of 1
>  $ sd_ef_rash_loc___palm: logi NA
> ```
> What am I getting wrong?
> Thanks
> 
> On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com>
> wrote:
> >
> > Hello,
> >
> >
> > I would use something like:
> >
> >
> > x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |>
> > as.data.frame() x[] <- lapply(x, function(xx) {
> >     xx[is.nan(xx)] <- NA_real_
> >     xx
> > })
> >
> >
> > This prevents attributes from being changed in 'x', but accomplishes the
> same thing as you have above, I hope this helps!
> >
> > On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> >>
> >> Hello,
> >> I have some NaN values in some elements of a dataframe that I would
> >> like to convert to NA.
> >> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
> >> Is there an alternative for the global modification at once of all
> >> instances?
> >> I have seen from
> >> https://stackoverflow.com/questions/18142117/how-to-replace-nan-
> value
> >> -with-zero-in-a-huge-data-frame/18143097#18143097
> >> that once could use:
> >> ```
> >>
> >> is.nan.data.frame <- function(x)
> >> do.call(cbind, lapply(x, is.nan))
> >>
> >> data123[is.nan(data123)] <- 0
> >> ```
> >> replacing o with NA, but I got
> >> ```
> >> str(df)
> >> > logi NA
> >> ```
> >> when modifying my dataframe df.
> >> What would be the correct syntax?
> >> Thank you
> >>
> >>
> >>
> >> --
> >> Best regards,
> >> Luigi
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Sep  3 09:59:12 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 3 Sep 2021 09:59:12 +0200
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <8252a0fe9c2b42e1b855cfd24015e622@SRVEXCHCM1302.precheza.cz>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
 <8252a0fe9c2b42e1b855cfd24015e622@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAMk+s2TurkxmAEqqB513h4XjbeT-MaFGVUPKype0JMKWPKNS-w@mail.gmail.com>

Fair enough, I'll check the actual data to see if there are indeed any
NaN (which should not, since the data are categories, not generated by
math).
Thanks!

On Fri, Sep 3, 2021 at 8:26 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi Luigi.
>
> Weird. But maybe it is the desired behaviour of summary when calculating
> mean of numeric column full of NAs.
>
> See example
>
> dat <- data.frame(x=rep(NA, 110), y=rep(1, 110), z= rnorm(110))
>
> # change all values in second column to NA
> dat[,2] <- NA
> # change some of them to NAN
> dat[5:6, 2:3] <- 0/0
>
> # see summary
> summary(dat)
>     x                 y             z
>  Mode:logical   Min.   : NA   Min.   :-1.9798
>  NA's:110       1st Qu.: NA   1st Qu.:-0.4729
>                 Median : NA   Median : 0.1745
>                 Mean   :NaN   Mean   : 0.1856
>                 3rd Qu.: NA   3rd Qu.: 0.8017
>                 Max.   : NA   Max.   : 2.5075
>                 NA's   :110   NA's   :2
>
> # change NAN values to NA
> dat[sapply(dat, is.nan)] <- NA
> *************************
>
> #summary is same
> summary(dat)
>     x                 y             z
>  Mode:logical   Min.   : NA   Min.   :-1.9798
>  NA's:110       1st Qu.: NA   1st Qu.:-0.4729
>                 Median : NA   Median : 0.1745
>                 Mean   :NaN   Mean   : 0.1856
>                 3rd Qu.: NA   3rd Qu.: 0.8017
>                 Max.   : NA   Max.   : 2.5075
>                 NA's   :110   NA's   :2
>
> # but no NAN value in data
> dat[1:10,]
>     x  y          z
> 1  NA NA -0.9148696
> 2  NA NA  0.7110570
> 3  NA NA -0.1901676
> 4  NA NA  0.5900650
> 5  NA NA         NA
> 6  NA NA         NA
> 7  NA NA  0.7987658
> 8  NA NA -0.5225229
> 9  NA NA  0.7673103
> 10 NA NA -0.5263897
>
> So my "nice compact command"
> dat[sapply(dat, is.nan)] <- NA
>
> works as expected, but summary gives as mean NAN.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> > Sent: Thursday, September 2, 2021 3:46 PM
> > To: Andrew Simmons <akwsimmo at gmail.com>
> > Cc: r-help <r-help at r-project.org>
> > Subject: Re: [R] How to globally convert NaN to NA in dataframe?
> >
> > `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I still
> get
> > NaN when using the summary function, for instance one of the columns give:
> > ```
> > Min.   : NA
> > 1st Qu.: NA
> > Median : NA
> > Mean   :NaN
> > 3rd Qu.: NA
> > Max.   : NA
> > NA's   :110
> > ```
> > I tried to implement the second solution but:
> > ```
> > df <- lapply(x, function(xx) {
> >   xx[is.nan(xx)] <- NA
> > })
> > > str(df)
> > List of 1
> >  $ sd_ef_rash_loc___palm: logi NA
> > ```
> > What am I getting wrong?
> > Thanks
> >
> > On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com>
> > wrote:
> > >
> > > Hello,
> > >
> > >
> > > I would use something like:
> > >
> > >
> > > x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |>
> > > as.data.frame() x[] <- lapply(x, function(xx) {
> > >     xx[is.nan(xx)] <- NA_real_
> > >     xx
> > > })
> > >
> > >
> > > This prevents attributes from being changed in 'x', but accomplishes the
> > same thing as you have above, I hope this helps!
> > >
> > > On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com>
> > wrote:
> > >>
> > >> Hello,
> > >> I have some NaN values in some elements of a dataframe that I would
> > >> like to convert to NA.
> > >> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
> > >> Is there an alternative for the global modification at once of all
> > >> instances?
> > >> I have seen from
> > >> https://stackoverflow.com/questions/18142117/how-to-replace-nan-
> > value
> > >> -with-zero-in-a-huge-data-frame/18143097#18143097
> > >> that once could use:
> > >> ```
> > >>
> > >> is.nan.data.frame <- function(x)
> > >> do.call(cbind, lapply(x, is.nan))
> > >>
> > >> data123[is.nan(data123)] <- 0
> > >> ```
> > >> replacing o with NA, but I got
> > >> ```
> > >> str(df)
> > >> > logi NA
> > >> ```
> > >> when modifying my dataframe df.
> > >> What would be the correct syntax?
> > >> Thank you
> > >>
> > >>
> > >>
> > >> --
> > >> Best regards,
> > >> Luigi
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From pd@|gd @end|ng |rom gm@||@com  Fri Sep  3 11:51:55 2021
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 3 Sep 2021 11:51:55 +0200
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAMk+s2TurkxmAEqqB513h4XjbeT-MaFGVUPKype0JMKWPKNS-w@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
 <8252a0fe9c2b42e1b855cfd24015e622@SRVEXCHCM1302.precheza.cz>
 <CAMk+s2TurkxmAEqqB513h4XjbeT-MaFGVUPKype0JMKWPKNS-w@mail.gmail.com>
Message-ID: <B1EF7DC1-39A1-4642-9F9E-924300032E09@gmail.com>

Yes, even

> summary(NA_real_)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
     NA      NA      NA     NaN      NA      NA       1 

which is presumably because the mean is an empty sum (= 0) divided by a zero count, and 0/0 = NaN.

Notice also the differenc between

> mean(NA_real_)
[1] NA
> mean(NA_real_, na.rm=TRUE)
[1] NaN


> On 3 Sep 2021, at 09:59 , Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> Fair enough, I'll check the actual data to see if there are indeed any
> NaN (which should not, since the data are categories, not generated by
> math).
> Thanks!
> 
> On Fri, Sep 3, 2021 at 8:26 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>> 
>> Hi Luigi.
>> 
>> Weird. But maybe it is the desired behaviour of summary when calculating
>> mean of numeric column full of NAs.
>> 
>> See example
>> 
>> dat <- data.frame(x=rep(NA, 110), y=rep(1, 110), z= rnorm(110))
>> 
>> # change all values in second column to NA
>> dat[,2] <- NA
>> # change some of them to NAN
>> dat[5:6, 2:3] <- 0/0
>> 
>> # see summary
>> summary(dat)
>>    x                 y             z
>> Mode:logical   Min.   : NA   Min.   :-1.9798
>> NA's:110       1st Qu.: NA   1st Qu.:-0.4729
>>                Median : NA   Median : 0.1745
>>                Mean   :NaN   Mean   : 0.1856
>>                3rd Qu.: NA   3rd Qu.: 0.8017
>>                Max.   : NA   Max.   : 2.5075
>>                NA's   :110   NA's   :2
>> 
>> # change NAN values to NA
>> dat[sapply(dat, is.nan)] <- NA
>> *************************
>> 
>> #summary is same
>> summary(dat)
>>    x                 y             z
>> Mode:logical   Min.   : NA   Min.   :-1.9798
>> NA's:110       1st Qu.: NA   1st Qu.:-0.4729
>>                Median : NA   Median : 0.1745
>>                Mean   :NaN   Mean   : 0.1856
>>                3rd Qu.: NA   3rd Qu.: 0.8017
>>                Max.   : NA   Max.   : 2.5075
>>                NA's   :110   NA's   :2
>> 
>> # but no NAN value in data
>> dat[1:10,]
>>    x  y          z
>> 1  NA NA -0.9148696
>> 2  NA NA  0.7110570
>> 3  NA NA -0.1901676
>> 4  NA NA  0.5900650
>> 5  NA NA         NA
>> 6  NA NA         NA
>> 7  NA NA  0.7987658
>> 8  NA NA -0.5225229
>> 9  NA NA  0.7673103
>> 10 NA NA -0.5263897
>> 
>> So my "nice compact command"
>> dat[sapply(dat, is.nan)] <- NA
>> 
>> works as expected, but summary gives as mean NAN.
>> 
>> Cheers
>> Petr
>> 
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
>>> Sent: Thursday, September 2, 2021 3:46 PM
>>> To: Andrew Simmons <akwsimmo at gmail.com>
>>> Cc: r-help <r-help at r-project.org>
>>> Subject: Re: [R] How to globally convert NaN to NA in dataframe?
>>> 
>>> `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I still
>> get
>>> NaN when using the summary function, for instance one of the columns give:
>>> ```
>>> Min.   : NA
>>> 1st Qu.: NA
>>> Median : NA
>>> Mean   :NaN
>>> 3rd Qu.: NA
>>> Max.   : NA
>>> NA's   :110
>>> ```
>>> I tried to implement the second solution but:
>>> ```
>>> df <- lapply(x, function(xx) {
>>>  xx[is.nan(xx)] <- NA
>>> })
>>>> str(df)
>>> List of 1
>>> $ sd_ef_rash_loc___palm: logi NA
>>> ```
>>> What am I getting wrong?
>>> Thanks
>>> 
>>> On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com>
>>> wrote:
>>>> 
>>>> Hello,
>>>> 
>>>> 
>>>> I would use something like:
>>>> 
>>>> 
>>>> x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |>
>>>> as.data.frame() x[] <- lapply(x, function(xx) {
>>>>    xx[is.nan(xx)] <- NA_real_
>>>>    xx
>>>> })
>>>> 
>>>> 
>>>> This prevents attributes from being changed in 'x', but accomplishes the
>>> same thing as you have above, I hope this helps!
>>>> 
>>>> On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com>
>>> wrote:
>>>>> 
>>>>> Hello,
>>>>> I have some NaN values in some elements of a dataframe that I would
>>>>> like to convert to NA.
>>>>> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
>>>>> Is there an alternative for the global modification at once of all
>>>>> instances?
>>>>> I have seen from
>>>>> https://stackoverflow.com/questions/18142117/how-to-replace-nan-
>>> value
>>>>> -with-zero-in-a-huge-data-frame/18143097#18143097
>>>>> that once could use:
>>>>> ```
>>>>> 
>>>>> is.nan.data.frame <- function(x)
>>>>> do.call(cbind, lapply(x, is.nan))
>>>>> 
>>>>> data123[is.nan(data123)] <- 0
>>>>> ```
>>>>> replacing o with NA, but I got
>>>>> ```
>>>>> str(df)
>>>>>> logi NA
>>>>> ```
>>>>> when modifying my dataframe df.
>>>>> What would be the correct syntax?
>>>>> Thank you
>>>>> 
>>>>> 
>>>>> 
>>>>> --
>>>>> Best regards,
>>>>> Luigi
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> --
>>> Best regards,
>>> Luigi
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From r@oknz @end|ng |rom gm@||@com  Fri Sep  3 16:24:57 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 4 Sep 2021 02:24:57 +1200
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
Message-ID: <CABcYAdKHY7vrjGsicgNxB7ggRnYYqe23=onWNd0TpOJ6J2e4gQ@mail.gmail.com>

Your question is ambiguous.
One reading is
  n <- length(table$Data)
  m <- n %/% 3
  s <- sample(1:n, n)
  X <- table$Data[s[1:m]]
  Y <- table$Data[s[(m+1):(2*m)]]
  Z <- table$Data[s[(m*2+1):(3*m)]]




On Fri, 3 Sept 2021 at 13:31, AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> Dear All:
>
> How to split a column data *randomly* into three groups. Please see the
> attached data. I need to split column #2 titled "Data"
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Sep  3 16:27:45 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Fri, 3 Sep 2021 10:27:45 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <012901d7a06d$50067980$f0136c80$@verizon.net>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
 <00e501d7a064$e7113f80$b533be80$@verizon.net>
 <CAE9stmdgQRWkJZOKqy7PYFTiSgC+v0oc1qkKEsFGbfzNo03HEg@mail.gmail.com>
 <012901d7a06d$50067980$f0136c80$@verizon.net>
Message-ID: <CAE9stmfRFtgQLxBWASnir7kdwY+2uMVp4C82ta4ie1XvasNgzg@mail.gmail.com>

Hi Avi: good morning

Again, many thanks to all of you. I appreciate all what you are doing. You
are good. I did it in Minitab. It cost me a little bit more time, but it is
okay.

It was a little bit confusing for me to do it in R. Because in *Step 1: *I
have to select a random sample of size n=204 (say) out of N=700 (say). Then
in Step 2: I have to allocate the 204 randomly selected obs. into three
groups of equal sample sizes.

Again, thank you very much, and sorry if I bothered you.


with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Thu, Sep 2, 2021 at 10:42 PM Avi Gross via R-help <r-help at r-project.org>
wrote:

> Abou,
>
>
>
> I am not trying to be negative. Assuming you are a professor of
> Statistics, your request seems odd as what you are asking about is very
> routine in much of statistical work where you want to make a model or
> something using just part of your data and need to reserve some to check if
> you perhaps trained an algorithm too much for the original data used.
>
>
>
> A simple online search before asking questions here is appreciated. I did
> a quick search for something like ?R split data into three parts? and see
> several applicable answers.
>
>
>
> There are people on this forum who actually get paid to do nontrivial
> tasks and do not mind help in spots but feel sort of used if expected to
> write a serious amount of code and perhaps then be asked to redo it with
> more bells and whistles added. A recent badly phrased request comes to mind
> where several of us provided and answer only to find out it was for a
> different scenario, ?
>
>
>
> So let me continue with a serious answer. May we assume you KNOW how to
> read the data in to something like a data.frame? If so, and if you see no
> need or value in doing this the hard way, then your question could have
> been to ask if there is an R built-in function or perhaps a pacjkage
> already set to solve it quickly. Again, a simple online search can do
> wonders.  Here, for example is a package called caret and this page
> discusses spliutting data multiple ways:
>
>
>
> https://topepo.github.io/caret/data-splitting.html
>
>
>
> There are other such pages suggesting how to do it using base R.
>
>
>
> Here is one that gives an example on how to make  three unequal partitions:
>
>
>
> inds <- partition(iris$Sepal.Length, p = c(train = 0.6, valid = 0.2, test
> = 0.2))
>
>
>
>
>
> There is more to do below but in the above, you would use whatever names
> you want instead of train/valid/test and set all three to 0.33 and so on.
>
>
>
> I repeat, that what you want to do strikes some of us as a fairly routine
> thing to do and lots of people have written how they have done it and you
> can pick and choose, or redo it on your own. If what you have is a homework
> assignment, the appropriate thing is to have you learn to use some
> technique yourself and perhaps get minor help when it fails. But if you
> will be doing this regularly, use of some packages is highly valuable.
>
>
>
> Good Luck.
>
>
>
>
>
>
>
>
>
>
>
> From: AbouEl-Makarim Aboueissa <abouelmakarim1962 at gmail.com>
> Sent: Thursday, September 2, 2021 9:51 PM
> To: Avi Gross <avigross at verizon.net>
> Cc: R mailing list <r-help at r-project.org>
> Subject: Re: [R] Splitting a data column randomly into 3 groups
>
>
>
> Sorry, please forget about it. I believe that I am very serious when I
> posted my question.
>
>
>
> with thanks
>
> abou
>
>
> ______________________
>
> AbouEl-Makarim Aboueissa, PhD
>
>
>
> Professor, Statistics and Data Science
>
> Graduate Coordinator
>
> Department of Mathematics and Statistics
>
> University of Southern Maine
>
>
>
>
>
>
>
> On Thu, Sep 2, 2021 at 9:42 PM Avi Gross via R-help <r-help at r-project.org
> <mailto:r-help at r-project.org> > wrote:
>
> What is stopping you Abou?
>
> Some of us here start wondering if we have better things to do than
> homework for others. Help is supposed to be after they try and encounter
> issues that we may help with.
>
> So think about your problem. You supplied data in a file that is NOT in
> CSV format but is in Tab separated format.
>
> You need to get it in to your program and store it in something. It looks
> like you have 204 items so 1/3 of those would be exactly 68.
>
> So if your data is in an object like a vector or data.frame, you want to
> choose random number between 1 and 204. How do you do that? You need 1/3 of
> the length of the object items, in your case 68.
>
> Now extract the items with  those indices into say A1. Extract all the
> rest into a temporary item.
>
> Make another 68 random indices, with no overlap, and copy those items into
> A2 and the ones that do not have those into A3 and you are sort of done,
> other than some cleanup or whatever.
>
> There are many ways to do the above and I am sure packages too.
>
> But since you have made no visible effort, I personally am not going to
> pick anything in particular.
>
> Had you shown some text and code along the lines of the above and just
> wanted to know how to copy just the ones that were not selected, we could
> easily ...
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org <mailto:
> r-help-bounces at r-project.org> > On Behalf Of AbouEl-Makarim Aboueissa
> Sent: Thursday, September 2, 2021 9:30 PM
> To: R mailing list <r-help at r-project.org <mailto:r-help at r-project.org> >
> Subject: [R] Splitting a data column randomly into 3 groups
>
> Dear All:
>
> How to split a column data *randomly* into three groups. Please see the
> attached data. I need to split column #2 titled "Data"
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science* *Graduate Coordinator*
>
> *Department of Mathematics and Statistics* *University of Southern Maine*
>
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Sep  3 16:29:07 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Fri, 3 Sep 2021 10:29:07 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CABcYAdKHY7vrjGsicgNxB7ggRnYYqe23=onWNd0TpOJ6J2e4gQ@mail.gmail.com>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
 <CABcYAdKHY7vrjGsicgNxB7ggRnYYqe23=onWNd0TpOJ6J2e4gQ@mail.gmail.com>
Message-ID: <CAE9stmd6qWnzcqyna9=kUXWKXrEzGhwz=k0h2s2Q4iS4rHyuhg@mail.gmail.com>

Hi Richard:

Thank you very much for your help in this matter.

with thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Fri, Sep 3, 2021 at 10:25 AM Richard O'Keefe <raoknz at gmail.com> wrote:

> Your question is ambiguous.
> One reading is
>   n <- length(table$Data)
>   m <- n %/% 3
>   s <- sample(1:n, n)
>   X <- table$Data[s[1:m]]
>   Y <- table$Data[s[(m+1):(2*m)]]
>   Z <- table$Data[s[(m*2+1):(3*m)]]
>
>
>
>
> On Fri, 3 Sept 2021 at 13:31, AbouEl-Makarim Aboueissa
> <abouelmakarim1962 at gmail.com> wrote:
> >
> > Dear All:
> >
> > How to split a column data *randomly* into three groups. Please see the
> > attached data. I need to split column #2 titled "Data"
> >
> > with many thanks
> > abou
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor, Statistics and Data Science*
> > *Graduate Coordinator*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep  3 17:37:13 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 3 Sep 2021 08:37:13 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <219F64F7-55D9-4D5B-9666-2C2DF6EC7AF4@dcn.davis.ca.us>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
 <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
 <219F64F7-55D9-4D5B-9666-2C2DF6EC7AF4@dcn.davis.ca.us>
Message-ID: <alpine.LNX.2.20.2109030833500.10519@salmo.appl-ecosys.com>

On Thu, 2 Sep 2021, Jeff Newmiller wrote:

> Regardless of whether you use the lower-level split function, or the
> higher-level aggregate function, or the tidyverse group_by function, the
> key is learning how to create the column that is the same for all records
> corresponding to the time interval of interest.

Jeff,

I tried responding to only you but my message bounced:

<jdnewmil at dcn.davis.ca.us>: host
     d9300a.ess.barracudanetworks.com[209.222.82.252] said: 550 permanent
     failure for one or more recipients (jdnewmil at dcn.davis.ca.us:blocked) (in
     reply to end of DATA command)

My response was not pertininet to the entire list, IMO, so I sent it to your
address.

Rich


From Stephen@Bond @end|ng |rom c|bc@com  Fri Sep  3 18:01:35 2021
From: Stephen@Bond @end|ng |rom c|bc@com (Bond, Stephen)
Date: Fri, 3 Sep 2021 16:01:35 +0000
Subject: [R] coxph means not equal to means of model matrix
Message-ID: <YT3PR01MB502649419C3D4D226D854524E6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>

Hi,

Please, help me understand what is happening with the means of a Cox model?
I have:
R version 4.0.2 (2020-06-22) -- "Taking Off Again"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

getOption("contrasts")
        unordered           ordered
"contr.treatment"      "contr.poly"

According to the help  coxph.object has a component holding the means of the X (model.matrix). This does not hold any more.
```
library(survival)
test1 <- list(time=c(4,3,1,1,2,2,3),
                   status=c(1,1,1,0,1,1,0),
                   x=c(0,2,1,1,1,0,0),
                   sex=factor(c(0,0,0,0,1,1,1)))
m1 <- coxph(Surv(time, status) ~ x + sex, test1)
m1$means
##        x      sex1
## 0.7142857 0.0000000
colMeans(model.matrix(m1))
##         x      sex1
## 0.7142857 0.4285714

```
Will new observations be scored using the zero mean from the object?? Is this just a reporting change where $means shows the reference level and no longer the mean of the model matrix??

Thanks everybody



	[[alternative HTML version deleted]]


From therne@u @end|ng |rom m@yo@edu  Fri Sep  3 18:37:24 2021
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Fri, 03 Sep 2021 11:37:24 -0500
Subject: [R] coxph means not equal to means of model matrix
In-Reply-To: <YT3PR01MB502649419C3D4D226D854524E6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>
References: <YT3PR01MB502649419C3D4D226D854524E6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <2e47ad$giu8ae@ironport10.mayo.edu>

See ?coxph, in particular the new "nocenter" option.

Basically, the "mean" component is used to center later computations.? This can be 
critical for continuous variables, avoiding overflow in the exp function, but is not 
necessary for 0/1 covariates.?? The fact that the default survival curve would be for a 
sex of .453, say, was off-putting to many.

Terry T.


On 9/3/21 11:01 AM, Bond, Stephen wrote:
>
> Hi,
>
> Please, help me understand what is happening with the means of a Cox model?
>
> I have:
>
> R version 4.0.2 (2020-06-22) -- "Taking Off Again"
>
> Copyright (C) 2020 The R Foundation for Statistical Computing
>
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> getOption("contrasts")
>
> ??????? unordered?????????? ordered
>
> "contr.treatment"????? "contr.poly"
>
> According to the help ?coxph.object has a component holding the means of the X 
> (model.matrix). This does not hold any more.
>
> ```
>
> library(survival)
>
> test1 <- list(time=c(4,3,1,1,2,2,3),
>
> ???????????????????status=c(1,1,1,0,1,1,0),
>
> ???????????????????x=c(0,2,1,1,1,0,0),
>
> ???????????????????sex=factor(c(0,0,0,0,1,1,1)))
>
> m1 <- coxph(Surv(time, status) ~ x + sex, test1)
>
> m1$means
>
> ##??????? x????? sex1
>
> ## 0.7142857 0.0000000
>
> colMeans(model.matrix(m1))
>
> ##???????? x????? sex1
>
> ## 0.7142857 0.4285714
>
> ```
>
> Will new observations be scored using the zero mean from the object?? Is this just a 
> reporting change where $means shows the reference level and no longer the mean of the 
> model matrix??
>
> Thanks everybody
>


	[[alternative HTML version deleted]]


From Stephen@Bond @end|ng |rom c|bc@com  Fri Sep  3 19:59:37 2021
From: Stephen@Bond @end|ng |rom c|bc@com (Bond, Stephen)
Date: Fri, 3 Sep 2021 17:59:37 +0000
Subject: [R] coxph means not equal to means of model matrix
In-Reply-To: <2e47ad$giu8af@ironport10.mayo.edu>
References: <YT3PR01MB502649419C3D4D226D854524E6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>
 <2e47ad$giu8af@ironport10.mayo.edu>
Message-ID: <YT3PR01MB5026E0FB5440DC99B1D82DBBE6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>

I looked at the nocenter and it says (-1,0,1) values but it seems that any three-level factor is included in that (represented as 1,2,3 in R) .
Also, is the baseline curve now showing the reference level and not the fictional .428 sex? If I predict the risk for a new row, should I multiply the coefficient shown in the output by 1 for a sex=1? It used to be (1-.428)*coef.
Thanks for clarifying.
SB

From: Therneau, Terry M., Ph.D. <therneau at mayo.edu>
Sent: Friday, 3 September, 2021 12:37
To: Bond, Stephen <Stephen.Bond at cibc.com>
Cc: R-help <r-help at R-project.org>
Subject: Re: coxph means not equal to means of model matrix

[EXTERNAL]
________________________________
See ?coxph, in particular the new "nocenter" option.

Basically, the "mean" component is used to center later computations.  This can be critical for continuous variables, avoiding overflow in the exp function, but is not necessary for 0/1 covariates.   The fact that the default survival curve would be for a sex of .453, say, was off-putting to many.

Terry T.

On 9/3/21 11:01 AM, Bond, Stephen wrote:
Hi,

Please, help me understand what is happening with the means of a Cox model?
I have:
R version 4.0.2 (2020-06-22) -- "Taking Off Again"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

getOption("contrasts")
        unordered           ordered
"contr.treatment"      "contr.poly"

According to the help  coxph.object has a component holding the means of the X (model.matrix). This does not hold any more.
```
library(survival)
test1 <- list(time=c(4,3,1,1,2,2,3),
                   status=c(1,1,1,0,1,1,0),
                   x=c(0,2,1,1,1,0,0),
                   sex=factor(c(0,0,0,0,1,1,1)))
m1 <- coxph(Surv(time, status) ~ x + sex, test1)
m1$means
##        x      sex1
## 0.7142857 0.0000000
colMeans(model.matrix(m1))
##         x      sex1
## 0.7142857 0.4285714

```
Will new observations be scored using the zero mean from the object?? Is this just a reporting change where $means shows the reference level and no longer the mean of the model matrix??

Thanks everybody



ATTENTION : This email originated outside your organization. Exercise caution before clicking links, opening attachments, or responding with personal information.
________________________________

	[[alternative HTML version deleted]]


From therne@u @end|ng |rom m@yo@edu  Fri Sep  3 21:10:00 2021
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Fri, 03 Sep 2021 14:10:00 -0500
Subject: [R] coxph means not equal to means of model matrix
In-Reply-To: <YT3PR01MB5026E0FB5440DC99B1D82DBBE6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>
References: <YT3PR01MB502649419C3D4D226D854524E6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>
 <2e47ad$giu8af@ironport10.mayo.edu>
 <YT3PR01MB5026E0FB5440DC99B1D82DBBE6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <2e47ad$givhj1@ironport10.mayo.edu>



On 9/3/21 12:59 PM, Bond, Stephen wrote:
>
> I looked at the nocenter and it says (-1,0,1) values but it seems that any three-level 
> factor is included in that (represented as 1,2,3 in R) .
>
A factor is turned into a set of 0/1 dummy variable, so the nocenter applies.? I will add 
more clarification to the documentation.

> Also, is the baseline curve now showing the reference level and not the fictional .428 
> sex? If I predict the risk for a new row, should I multiply the coefficient shown in the 
> output by 1 for a sex=1? It used to be (1-.428)*coef.
>
Yes, the "mean" component is the reference level for predict and survfit.? If I could go 
back in time it would be labeled as "reference" instead of "mean".?? Another opportunity 
for me to make the documentation clearer.

Good questions,
 ? Terry T

> Thanks for clarifying.
>
> SB
>
> *From:* Therneau, Terry M., Ph.D. <therneau at mayo.edu>
> *Sent:* Friday, 3 September, 2021 12:37
> *To:* Bond, Stephen <Stephen.Bond at cibc.com>
> *Cc:* R-help <r-help at R-project.org>
> *Subject:* Re: coxph means not equal to means of model matrix
>
> [EXTERNAL]
>
> ------------------------------------------------------------------------------------------
>
> See ?coxph, in particular the new "nocenter" option.
>
> Basically, the "mean" component is used to center later computations.? This can be 
> critical for continuous variables, avoiding overflow in the exp function, but is not 
> necessary for 0/1 covariates.?? The fact that the default survival curve would be for a 
> sex of .453, say, was off-putting to many.
>
> Terry T.
>
> On 9/3/21 11:01 AM, Bond, Stephen wrote:
>
>     Hi,
>
>     Please, help me understand what is happening with the means of a Cox model?
>
>     I have:
>
>     R version 4.0.2 (2020-06-22) -- "Taking Off Again"
>
>     Copyright (C) 2020 The R Foundation for Statistical Computing
>
>     Platform: x86_64-w64-mingw32/x64 (64-bit)
>
>     getOption("contrasts")
>
>     ??????? unordered ordered
>
>     "contr.treatment" "contr.poly"
>
>     According to the help ?coxph.object has a component holding the means of the X
>     (model.matrix). This does not hold any more.
>
>     ```
>
>     library(survival)
>
>     test1 <- list(time=c(4,3,1,1,2,2,3),
>
>     ???????????????????status=c(1,1,1,0,1,1,0),
>
>     ???????????????????x=c(0,2,1,1,1,0,0),
>
>     ???????????????????sex=factor(c(0,0,0,0,1,1,1)))
>
>     m1 <- coxph(Surv(time, status) ~ x + sex, test1)
>
>     m1$means
>
>     ##??????? x????? sex1
>
>     ## 0.7142857 0.0000000
>
>     colMeans(model.matrix(m1))
>
>     ##???????? x????? sex1
>
>     ## 0.7142857 0.4285714
>
>     ```
>
>     Will new observations be scored using the zero mean from the object?? Is this just a
>     reporting change where $means shows the reference level and no longer the mean of
>     the model matrix??
>
>     Thanks everybody
>
> ATTENTION : This email originated outside your organization. Exercise caution before 
> clicking links, opening attachments, or responding with personal information.
>
> ------------------------------------------------------------------------------------------


	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep  3 21:17:53 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 3 Sep 2021 12:17:53 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
Message-ID: <alpine.LNX.2.20.2109031217230.10519@salmo.appl-ecosys.com>

On Thu, 2 Sep 2021, Jeff Newmiller wrote:

> Regardless of whether you use the lower-level split function, or the
> higher-level aggregate function, or the tidyverse group_by function, the
> key is learning how to create the column that is the same for all records
> corresponding to the time interval of interest.

Jeff,

I definitely agree with the above

> If you convert the sampdate to POSIXct, the tz IS important, because most
> of us use local timezones that respect daylight savings time, and a naive
> conversion of standard time will run into trouble if R is assuming
> daylight savings time applies. The lubridate package gets around this by
> always assuming UTC and giving you a function to "fix" the timezone after
> the conversion. I prefer to always be specific about timezones, at least
> by using so something like
>    Sys.setenv( TZ = "Etc/GMT+8" )
> which does not respect daylight savings.

I'm not following you here. All my projects have always been in a single
time zone and the data might be recorded at June 19th or November 4th but do
not depend on whether the time is PDT or PST. My hosts all set the hardware
clock to local time, not UTC.

As the location(s) at which data are collected remain fixed geographically I
don't understand why daylight savings time, or non-daylight savings time is
important.

> Regarding using character data for identifying the month, in order to have
> clean plots of the data I prefer to use the trunc function but it returns
> a POSIXlt so I convert it to POSIXct:

I don't use character data for months, as far as I know. If a sample data
is, for example, 2021-09-03 then monthly summaries are based on '09', not
'September.'

I've always valued your inputs to help me understand what I don't. In this
case I'm really lost in understanding your position.

Have a good Labor Day weekend,

Rich


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Sep  4 08:30:26 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 3 Sep 2021 23:30:26 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2109031217230.10519@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109031217230.10519@salmo.appl-ecosys.com>
Message-ID: <alpine.BSF.2.00.2109032251260.3401@pedal.dcn.davis.ca.us>

On Fri, 3 Sep 2021, Rich Shepard wrote:

> On Thu, 2 Sep 2021, Jeff Newmiller wrote:
>
>> Regardless of whether you use the lower-level split function, or the
>> higher-level aggregate function, or the tidyverse group_by function, the
>> key is learning how to create the column that is the same for all records
>> corresponding to the time interval of interest.
>
> Jeff,
>
> I definitely agree with the above
>
>> If you convert the sampdate to POSIXct, the tz IS important, because most
>> of us use local timezones that respect daylight savings time, and a naive
>> conversion of standard time will run into trouble if R is assuming
>> daylight savings time applies. The lubridate package gets around this by
>> always assuming UTC and giving you a function to "fix" the timezone after
>> the conversion. I prefer to always be specific about timezones, at least
>> by using so something like
>>    Sys.setenv( TZ = "Etc/GMT+8" )
>> which does not respect daylight savings.
>
> I'm not following you here. All my projects have always been in a single
> time zone and the data might be recorded at June 19th or November 4th but do
> not depend on whether the time is PDT or PST. My hosts all set the hardware
> clock to local time, not UTC.

The fact that your projects are in a single time zone is irrelevant. I am 
not sure how you can be so confident in saying it does not matter whether 
the data were recorded in PDT or PST, since if it were recorded in PDT 
then there would be a day in March with 23 hours and another day in 
November with 25 hours, but if it were recorded in PST then there would 
always be 24 hours in every day, and R almost always assumes daylight 
savings if you don't tell it otherwise!

I am also normally working with automated collection devices that record 
data in standard time year round. But if you fail to tell R that this is 
the case, then it will almost always assume your data are stored with 
daylight savings time and screw up the conversion to computable time 
format. This screw up may include NA values in spring time when standard 
time has perfectly valid times between 1am and 2am on the changeover day, 
but in daylight time those timestamps would be invalid and will end up as 
NA values in your timestamp column.

> As the location(s) at which data are collected remain fixed geographically I
> don't understand why daylight savings time, or non-daylight savings time is
> important.

I am telling you that it is important _TO R_ if you use POSIXt times. 
Acknowledge this and move on with life, or avoid POSIXt data. As I said, 
one way to acknowledge this while limiting the amount of attention you 
have to give to the problem is to use UTC/GMT everywhere... but this can 
lead to weird time of day problems as I pointed out in my timestamp 
cleaning slides: 
https://jdnewmil.github.io/time-2018-10/TimestampCleaning.html

If you want to use GMT everywhere... then you have to use GMT explicitly 
because the default timezone in R is practically never GMT for most 
people. You. Need. To. Be. Explicit. Don't fight it. Just do it. It isn't 
hard.

>> Regarding using character data for identifying the month, in order to have
>> clean plots of the data I prefer to use the trunc function but it returns
>> a POSIXlt so I convert it to POSIXct:
>
> I don't use character data for months, as far as I know. If a sample data
> is, for example, 2021-09-03 then monthly summaries are based on '09', not
> 'September.'

You are taking this out of context and complaining that it has no context. 
This was a reply to a response by Andrew Simmons in which he used the 
"format" function to create unique year/month strings to act as group-by 
data. Earlier, when I originally responded to clarify how you could use 
the dplyr group_by function, I used your character date column without 
combining it with time or convertint to Date at all. If you studied these 
responses more carefully you would indeed have been using character data 
for grouping in some cases, and my only point was that doing so can indeed 
be a shortcut to the immediate answer while being troublesome later in the 
analysis. Accusing you of mishandling data was not my intention.

> I've always valued your inputs to help me understand what I don't. In this
> case I'm really lost in understanding your position.

I hope my comments are clear enough now.

> Have a good Labor Day weekend,

Thanks! (Not relevant to many on this list.)

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sat Sep  4 14:42:51 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sat, 4 Sep 2021 05:42:51 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.BSF.2.00.2109032251260.3401@pedal.dcn.davis.ca.us>
References: <alpine.LNX.2.20.2109031217230.10519@salmo.appl-ecosys.com>
 <alpine.BSF.2.00.2109032251260.3401@pedal.dcn.davis.ca.us>
Message-ID: <alpine.LNX.2.20.2109040541470.29254@salmo.appl-ecosys.com>

On Fri, 3 Sep 2021, Jeff Newmiller wrote:

> The fact that your projects are in a single time zone is irrelevant. I am
> not sure how you can be so confident in saying it does not matter whether
> the data were recorded in PDT or PST, since if it were recorded in PDT
> then there would be a day in March with 23 hours and another day in
> November with 25 hours, but if it were recorded in PST then there would
> always be 24 hours in every day, and R almost always assumes daylight
> savings if you don't tell it otherwise!

Got it, Jeff. Thanks very much.

Regards,

Rich


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Sat Sep  4 18:06:57 2021
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Sat, 4 Sep 2021 16:06:57 +0000
Subject: [R] Managing NA values in aggregate
Message-ID: <8B435C9568170B469AE31E8891E8CC4F011E6DE4FF@ESINO.regionemarche.intra>

Dear R-list users,
I encountered a silly problem using aggregate, but I am not able to get rid of it.
I read the manual quite carefully, probaby not enough.
Suppose I have the following data frame:

mydf <- data.frame(year_month=rep(c("2003-12", "2004-12", "2005-12"), 3), station_number=c(rep(1818,3), rep(1819,3), rep(1820,3)), value=c(NA, NA, 20, NA, NA, 40, NA, 15, 50))

I want aggregate the column value by the column year_month, but I need to preserve rows with NA when all data are NA:

aggregate(mydf$value, list(mydf$year_month), sum) gives
1 2003-12  NA
2 2004-12  NA
3 2005-12 110

aggregate(mydf$value, list(mydf$year_month), sum, na.rm=TRUE) gives
1 2003-12   0
2 2004-12  15
3 2005-12 110

but I need
1 2003-12   NA
2 2004-12  15
3 2005-12 110

How can I get it?
Thank you for your attention and your help
Stefano


         (oo)
--oOO--( )--OOo--------------------------------------
Stefano Sofia PhD
Civil Protection - Marche Region - Italy
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona (AN)
Uff: +39 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------------------------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
This message was scanned by Libraesva ESG and is believed to be clean.


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Sep  4 18:21:38 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 04 Sep 2021 09:21:38 -0700
Subject: [R] Managing NA values in aggregate
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F011E6DE4FF@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F011E6DE4FF@ESINO.regionemarche.intra>
Message-ID: <92AF0B15-0F5E-4EDD-A59A-68A850FBAC9C@dcn.davis.ca.us>

Literal translation...

aggregate( mydf$value
         , mydf[ , "year_month", drop=FALSE ]
         , function( x ) if ( all( is.na( x ) ) ) NA else sum( x, na.rm = TRUE )
         )

On September 4, 2021 9:06:57 AM PDT, Stefano Sofia <stefano.sofia at regione.marche.it> wrote:
>Dear R-list users,
>I encountered a silly problem using aggregate, but I am not able to get rid of it.
>I read the manual quite carefully, probaby not enough.
>Suppose I have the following data frame:
>
>mydf <- data.frame(year_month=rep(c("2003-12", "2004-12", "2005-12"), 3), station_number=c(rep(1818,3), rep(1819,3), rep(1820,3)), value=c(NA, NA, 20, NA, NA, 40, NA, 15, 50))
>
>I want aggregate the column value by the column year_month, but I need to preserve rows with NA when all data are NA:
>
>aggregate(mydf$value, list(mydf$year_month), sum) gives
>1 2003-12  NA
>2 2004-12  NA
>3 2005-12 110
>
>aggregate(mydf$value, list(mydf$year_month), sum, na.rm=TRUE) gives
>1 2003-12   0
>2 2004-12  15
>3 2005-12 110
>
>but I need
>1 2003-12   NA
>2 2004-12  15
>3 2005-12 110
>
>How can I get it?
>Thank you for your attention and your help
>Stefano
>
>
>         (oo)
>--oOO--( )--OOo--------------------------------------
>Stefano Sofia PhD
>Civil Protection - Marche Region - Italy
>Meteo Section
>Snow Section
>Via del Colle Ameno 5
>60126 Torrette di Ancona, Ancona (AN)
>Uff: +39 071 806 7743
>E-mail: stefano.sofia at regione.marche.it
>---Oo---------oO----------------------------------------
>
>________________________________
>
>AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
>IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
>--
>Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
>This message was scanned by Libraesva ESG and is believed to be clean.
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Sep  4 18:22:14 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 4 Sep 2021 17:22:14 +0100
Subject: [R] combining geom_boxplot and geom_point with jitter
In-Reply-To: <29e2f7e6-b2a7-9b4f-83d3-44bc197f0cac@rgzm.de>
References: <29e2f7e6-b2a7-9b4f-83d3-44bc197f0cac@rgzm.de>
Message-ID: <de5962ba-7d8c-9dbe-c0bf-898fa245380f@sapo.pt>

Hello,

The problem is that you have two grouping aesthetics, color and shape.
In geom_point make the group explicit:


p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
p <- p + geom_boxplot(outlier.shape = NA)

p + geom_point(
   mapping = aes(shape = NMP_cat, group = Software),
   position = position_jitterdodge()
)


Hope this helps,

Rui Barradas

?s 09:54 de 02/09/21, Ivan Calandra escreveu:
> Dear useRs,
> 
> I'm having a problem to combine geom_boxplot and geom_point with jitter. 
> It is difficult to explain but the code and result should make it clear 
> (the example dataset is long so I copy it at the end of the email):
> 
> p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
> p <- p + geom_boxplot(outlier.shape = NA)
> p <- p + geom_point(mapping = aes(shape = NMP_cat), position = 
> position_jitterdodge())
> print(p)
> 
> As you can see in the resulting plot, the points with different shapes 
> are dodged across the boxplot categories (colors). I'd like the three 
> shapes per color to be restricted in one boxplot color, with jitter of 
> course to better visualize the points.
> 
> Does that make sense?
> 
> I have played with the arguments of position_jitterdodge(), but it seems 
> to me that the problem is that the shape aesthetic is not in the 
> geom_boxplot() call (but I don't want it there, see below).
> 
> For background information, the column used for shape gives some sort of 
> "quality" to the points; that's why I want to show the points 
> differently, so that it can easily be seen whether "good" points plot in 
> the same area as the "bad" points.
> Because I'm doing facet plots with other variables, I do not want to 
> separate these categories in the boxplots - the resulting plots would be 
> overcrowded.
> 
> Thank you for the help.
> Ivan
> 
> ---
> 
> my_data <- structure(list(Diet = c("Dry lucerne", "Dry lucerne", "Dry 
> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne",
> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
> "Dry lucerne", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
> "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
> "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
> "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
> "Dry grass", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo",
> "Dry bamboo", "Dry bamboo"), Software = c("ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax"), NMP_cat = structure(c(1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
> 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 
> 3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 2L, 
> 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L), .Label = c("0-5%", "5-10%", 
> "10-20%", "20-100%"), class = c("ordered", "factor")), name = 
> structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), 
> .Label = c("Asfc", "Smfc", "HAsfc9", "HAsfc81", "epLsar", "NewEplsar"), 
> class = "factor"), value = c(16.00716636, 12.925787, 14.05932485, 
> 11.999816, 15.12321532, 12.711474, 12.79565826, 10.900949, 15.90481161, 
> 12.836045, 16.22778102, 13.565995, 14.71354945, 12.384152, 16.61354777, 
> 13.714165, 15.91399496, 12.983796, 19.44739619, 15.173215, 16.13761798, 
> 12.932798, 14.7332952, 12.10277, 10.78710961, 8.762726, 10.16027362, 
> 8.040399, 14.53444662, 11.527896, 17.38120685, 13.78922, 11.26840546, 
> 9.426558, 24.01797992, 18.398553, 13.7435699, 11.44385, 14.391873, 
> 10.757141, 22.39390393, 18.176262, 11.60322022, 9.969118, 11.6099975, 
> 10.059618, 11.86282935, 10.280864, 16.22473644, 13.562839, 12.46350165, 
> 10.629406, 23.9347534, 19.062174, 19.58121507, 15.910959, 13.99145447, 
> 11.352648, 14.38942328, 11.821431, 23.4733371, 18.549503, 13.08142223, 
> 10.735494, 17.09293046, 13.012834, 28.80020878, 22.447105, 25.74460885, 
> 19.76834, 14.29106582, 12.233774, 12.03005024, 10.364224, 12.58953574, 
> 10.30257, 18.07111578, 14.416143, 20.85562751, 16.524047, 21.06132234, 
> 15.744758, 15.24052683, 11.891487, 11.62446752, 9.14325, 11.75704705, 
> 10.358542, 13.65568703, 11.766129, 16.98137759, 12.594787, 11.6560954, 
> 10.32073, 15.46708251, 13.199232, 13.20110131, 11.060226, 16.13986173, 
> 13.564802, 25.45656859, 20.071231, 24.84006178, 19.335892, 14.4723856, 
> 11.994841, 12.07940958, 9.470493, 13.93630412, 11.489685, 21.84464295, 
> 17.806018, 17.4383111, 14.478338, 20.55074297, 16.254467, 30.15238714, 
> 24.193768, 32.8541897, 25.769585, 32.06966759, 24.507185, 20.53975772, 
> 15.951186, 11.54494952, 9.676342, 13.56490524, 11.456356, 13.58242208, 
> 10.919419, 13.55260161, 11.356056, 38.58113502, 31.087536, 23.6753536, 
> 18.749955, 26.38707155, 20.877856, 26.18252748, 20.758242)), row.names = 
> c(NA, -140L), class = c("tbl_df", "tbl", "data.frame"))
>


From tg@77m @end|ng |rom y@hoo@com  Sat Sep  4 18:25:40 2021
From: tg@77m @end|ng |rom y@hoo@com (Thomas Subia)
Date: Sat, 4 Sep 2021 09:25:40 -0700
Subject: [R] . Re: Splitting a data column randomly into 3 groups
References: <006c01d7a1a9$80cca840$8265f8c0$.ref@yahoo.com>
Message-ID: <006c01d7a1a9$80cca840$8265f8c0$@yahoo.com>

I was wondering if this is a good alternative method to split a data column
into distinct groups.
Let's say I want my first group to have 4 elements selected randomly

mydata <- LETTERS[1:11] 
 random_grp <- sample(mydata,4,replace=FALSE)

Now random_grp is:
> random_grp
[1] "H" "E" "A" "D"
# How's that for a random selection!

Now my choices for another group of random data now becomes:
 data_wo_random <- setdiff(mydata,random_grp)

> data_wo_random
[1] "B" "C" "F" "G" "I" "J" "K"

Now from this reduced dataset, I can generate another random selection with
any size I choose.

One problem with this is that this is cumbersome when ones original dataset
is large or when one wants to subgroup the original dataset into many
different subgroup sizes.

Nevertheless, it's an intuitive method which is relatively easy to
understand

Hope this helps!

Thomas Subia
Statistician


From m|n@h@|| @end|ng |rom um|ch@edu  Sat Sep  4 18:31:04 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Sat, 04 Sep 2021 19:31:04 +0300
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: Your message of "Thu, 02 Sep 2021 15:44:07 -0400."
 <9df5d40e-f922-1282-025f-2b6b0b09e2e6@gmail.com>
Message-ID: <1314604.1630773064@apollo2.minshall.org>

Duncan,

> x[] <- lapply(...) says "set the values in x to the values in the list
> on the RHS", so x retains its class.

thanks!

cheers, Greg


From @v|gro@@ @end|ng |rom ver|zon@net  Sat Sep  4 19:58:18 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sat, 4 Sep 2021 13:58:18 -0400
Subject: [R] . Re: Splitting a data column randomly into 3 groups
In-Reply-To: <006c01d7a1a9$80cca840$8265f8c0$@yahoo.com>
References: <006c01d7a1a9$80cca840$8265f8c0$.ref@yahoo.com>
 <006c01d7a1a9$80cca840$8265f8c0$@yahoo.com>
Message-ID: <00f601d7a1b6$7193a420$54baec60$@verizon.net>

Thomas,

There are many approaches tried over the years to do partitioning along the
lines you mentioned and others. R already has many built-in or in packages
including some that are quite optimized. So anyone doing serious work can
often avoid doing this the hard way and build on earlier work.

Now, obviously, some people learning may take on such challenges or have
them assigned as homework. And if you want to tweak the efficiency, you may
be able to do things like knowing the conditions needed by sample() are met,
you can directly call sample.int() and so on.

But fundamentally, a large subset of all these kinds of sampling can often
be done by just playing with indices. It does not matter whether your data
is in the form of a list or other kind of vector or a data.frame or matrix.
Anything you can subset with integers will do.

So an algorithm could determine how many subsets of the indices you want and
calculate how many you want in each bucket and it can be done fairly simply.
One approach might be to scramble the indices in some form, and that can be
a vector of them or something more like an unordered set. You then take the
first number of them as needed for the first partition then the next ones
for the additional partitions. Finally, you apply the selected ones to
subset the original data into multiple smaller data collections.

Obviously you can instead work in stages, if you prefer. Your algorithm
seems to be along those lines. Start with your full data and pull out what
you want for the first partition. Then with what is left, repeat for the
second partition and so on, till what is left is used for the final
partition. Arguably this may in some ways be more work, especially for
larger amounts of data.

I do note many statistical processes, such as bootstrapping, may include
allowing various kinds of overlap in which the same items are allowed to be
used repeatedly, sometimes even within a single random sample. In those
cases, the algorithm has to include replacement and that is a somewhat
different discussion.

What I am finding here is that many problems posed are not explained in the
way they turn out to be needed in the end. So answering a question before we
know what it is can be a tad premature and waste time all around. But in
reality, some people new to R or computing in general, may be stuck
precisely on understanding the question they are trying to solve or may not
realize their use of language (especially when English is not one of their
stronger languages) can be a problem as their listeners/readers assume they
mean something else.

Your suggestion of how to do some things is reasonable and you note a
question about larger amounts of data. Many languages, for example Python,
will often have higher-level abilities arguable better designed for some
problems. R was built with vectorization in mind and most things are
ultimately vectors in a sense. For some purposes, it would be nice to have
an implementation of primitives along the lines of sets and bags and
hashes/dictionaries and so on. People have added some things along these
lines but if you look at the implementation of your use of setdiff(), it
just calls unique on two arguments coerced into vector format!

So consider what happens if you instead start in a language where you can
use a native construct called a set where sets are implemented efficiently.
To make N groupings that are distinct, you might start by adding all the
indices, or even complete entities, into the set. You can then ask to get a
random element from the set (perhaps also with deletion) until you have
reached your N items. You can then ask for the next group of N' and then N''
till you have what you need and perhaps the set is empty. An implementation
that uses some form of hashing to store and access set items can make
finding things take the same amount of time no matter the size. There is no
endless copying of parts of data. There may be no need for a setdiff() step
or if used, a more efficient way it is done. 

And, of course, if your data can have things like redundant elements or
rows, some kind of bag primitive may be useful and you can do your
scrambling and partitioning without using obvious indices.

R has been used extensively for a long time and most people use what is
already there. Some create new object types or packages, of course.

I have sometimes taken a hybrid approach and one interesting one is to use a
hybrid environment. I have, for example, done things like the above by
writing a program that has a package that allows both an R and a Python
interpreter to work together on data they sort of share and at times
interconvert. In an example where you have lots of statistical routines you
trust in R but want some of the preparation and arrangement or further
analysis, to be done with functionality you have in Python, you can sort of
combine the best of both worlds into a single program. Heck, the same
environment may also be creating a document in a markup language where the
above language codes are embedded and selectively output results including
graphics and result in something like a PDF or other document form.

I know the current discussion was, sort of, about dividing a set of data
into three groups. Efficiency may not be a major consideration, especially
as what is done with the groups may be the dominant user of resources. But
many newer techniques, such as Random Forest, may involve taking the same
data and repeatedly partitioning it and running an analysis and repeating
many thousands of times and then in some way combining the results. Some
break it down over multiple stages till they have just a few items. Some
will allow strange things like making small groups that could in theory
consist of the same original item repeated several times even if in the real
world that makes no sense as it may improve the results. So the partitioning
part may well best be done well.





-----Original Message-----
From: Thomas Subia <tgs77m at yahoo.com> 
Sent: Saturday, September 4, 2021 12:26 PM
To: r-help at r-project.org
Cc: avigross at verizon.net; abouelmakarim1962 at gmail.com
Subject: . Re: Splitting a data column randomly into 3 groups

I was wondering if this is a good alternative method to split a data column
into distinct groups.
Let's say I want my first group to have 4 elements selected randomly

mydata <- LETTERS[1:11]
 random_grp <- sample(mydata,4,replace=FALSE)

Now random_grp is:
> random_grp
[1] "H" "E" "A" "D"
# How's that for a random selection!

Now my choices for another group of random data now becomes:
 data_wo_random <- setdiff(mydata,random_grp)

> data_wo_random
[1] "B" "C" "F" "G" "I" "J" "K"

Now from this reduced dataset, I can generate another random selection with
any size I choose.

One problem with this is that this is cumbersome when ones original dataset
is large or when one wants to subgroup the original dataset into many
different subgroup sizes.

Nevertheless, it's an intuitive method which is relatively easy to
understand

Hope this helps!

Thomas Subia
Statistician


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Sat Sep  4 23:12:43 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Sat, 4 Sep 2021 17:12:43 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <005601d7a1a5$11da6480$358f2d80$@yahoo.com>
References: <005601d7a1a5$11da6480$358f2d80$.ref@yahoo.com>
 <005601d7a1a5$11da6480$358f2d80$@yahoo.com>
Message-ID: <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>

Dear Thomas:


Thank you very much for your input in this matter.


The core part of this R code(s) (please see below) was written by *Richard
O'Keefe*. I had three examples with different sample sizes.



*First sample of size n1 = 204* divided randomly into three groups of sizes
68. *No problems with this one*.



*The second sample of size n2 = 112* divided randomly into three groups of
sizes 37, 37, and 38. BUT this R code generated three groups of equal sizes
(37, 37, and 37). *How to fix the code to make sure that the output will be
three groups of sizes 37, 37, and 38*.



*The third sample of size n3 = 284* divided randomly into three groups of
sizes 94, 95, and 95. BUT this R code generated three groups of equal sizes
(94, 94, and 94). *Again*, h*ow to fix the code to make sure that the
output will be three groups of sizes 94, 95, and 95*.


With many thanks

abou


###########  ------------------------   #############


N1 <- 485
population1.IDs <- seq(1, N1, by = 1)
#### population1.IDs

n1<-204                                        ##### in this case the size
of each group of the three groups = 68
sample1.IDs <- sample(population1.IDs,n1)
#### sample1.IDs

####  n1 <- length(sample1.IDs)

  m1 <- n1 %/% 3
  s1 <- sample(1:n1, n1)
  group1.IDs <- sample1.IDs[s1[1:m1]]
  group2.IDs <- sample1.IDs[s1[(m1+1):(2*m1)]]
  group3.IDs <- sample1.IDs[s1[(m1*2+1):(3*m1)]]

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs


####### --------------------------


N2 <- 266
population2.IDs <- seq(1, N2, by = 1)
#### population2.IDs

n2<-112                           ##### in this case the sizes of the three
groups are(37, 37, and 38)
                                          ##### BUT this codes generate
three groups of equal sizes (37, 37, and 37)
sample2.IDs <- sample(population2.IDs,n2)
#### sample2.IDs

####  n2 <- length(sample2.IDs)

  m2 <- n2 %/% 3
  s2 <- sample(1:n2, n2)
  group1.IDs <- sample2.IDs[s2[1:m2]]
  group2.IDs <- sample2.IDs[s2[(m2+1):(2*m2)]]
  group3.IDs <- sample2.IDs[s2[(m2*2+1):(3*m2)]]

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs


####### --------------------------



N3 <- 674
population3.IDs <- seq(1, N3, by = 1)
#### population3.IDs

n3<-284                           ##### in this case the sizes of the three
groups are(94, 95, and 95)
                                          ##### BUT this codes generate
three groups of equal sizes (94, 94, and 94)
sample2.IDs <- sample(population2.IDs,n2)
sample3.IDs <- sample(population3.IDs,n3)
#### sample3.IDs

####  n3 <- length(sample2.IDs)

  m3 <- n3 %/% 3
  s3 <- sample(1:n3, n3)
  group1.IDs <- sample3.IDs[s3[1:m3]]
  group2.IDs <- sample3.IDs[s3[(m3+1):(2*m3)]]
  group3.IDs <- sample3.IDs[s3[(m3*2+1):(3*m3)]]

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs

______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Sat, Sep 4, 2021 at 11:54 AM Thomas Subia <tgs77m at yahoo.com> wrote:

> Abou,
>
>
>
> I?ve been following your question on how to split a data column randomly
> into 3 groups using R.
>
>
>
> My method may not be amenable for a large set of data but it surely worth
> considering since it makes sense intuitively.
>
>
>
> mydata <- LETTERS[1:11]
>
> > mydata
>
> [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K"
>
>
>
> # Let?s choose a random sample of size 4 from mydata
>
> > random_grp1
>
> [1] "J" "H" "D" "A"
>
>
>
> Now my next random selection of data is defined by
>
> data_wo_random <- setdiff(mydata,random_grp1)
>
> # this makes sense because I need to choose random data from a set which
> is defined by the difference of the sets mydata and random_grp1
>
>
>
> > data_wo_random
>
> [1] "B" "C" "E" "F" "G" "I" "K"
>
>
>
> This is great! So now I can randomly select data of any size from this set.
>
> Repeating this process can easily generate subgroups of your original
> dataset of any size you want.
>
>
>
> Surely this method could be improved so that this could be done
> automatically.
>
> Nevertheless, this is an intuitive method which I believe is easier to
> understand than some of the other methods posted.
>
>
>
> Hope this helps!
>
>
>
> Thomas Subia
>
> Statistician
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Sep  5 00:02:08 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 4 Sep 2021 23:02:08 +0100
Subject: [R] combining geom_boxplot and geom_point with jitter
In-Reply-To: <de5962ba-7d8c-9dbe-c0bf-898fa245380f@sapo.pt>
References: <29e2f7e6-b2a7-9b4f-83d3-44bc197f0cac@rgzm.de>
 <de5962ba-7d8c-9dbe-c0bf-898fa245380f@sapo.pt>
Message-ID: <6af06d92-0c68-873f-d08b-a24d0d415f3b@sapo.pt>

Hello,

And another way, with geom_jitter


p + geom_jitter(
   mapping = aes(shape = NMP_cat, group = Software),
   position = position_dodge2(width = 1)
)


Hope this helps,

Rui Barradas

?s 17:22 de 04/09/21, Rui Barradas escreveu:
> Hello,
> 
> The problem is that you have two grouping aesthetics, color and shape.
> In geom_point make the group explicit:
> 
> 
> p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
> p <- p + geom_boxplot(outlier.shape = NA)
> 
> p + geom_point(
>  ? mapping = aes(shape = NMP_cat, group = Software),
>  ? position = position_jitterdodge()
> )
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 09:54 de 02/09/21, Ivan Calandra escreveu:
>> Dear useRs,
>>
>> I'm having a problem to combine geom_boxplot and geom_point with 
>> jitter. It is difficult to explain but the code and result should make 
>> it clear (the example dataset is long so I copy it at the end of the 
>> email):
>>
>> p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
>> p <- p + geom_boxplot(outlier.shape = NA)
>> p <- p + geom_point(mapping = aes(shape = NMP_cat), position = 
>> position_jitterdodge())
>> print(p)
>>
>> As you can see in the resulting plot, the points with different shapes 
>> are dodged across the boxplot categories (colors). I'd like the three 
>> shapes per color to be restricted in one boxplot color, with jitter of 
>> course to better visualize the points.
>>
>> Does that make sense?
>>
>> I have played with the arguments of position_jitterdodge(), but it 
>> seems to me that the problem is that the shape aesthetic is not in the 
>> geom_boxplot() call (but I don't want it there, see below).
>>
>> For background information, the column used for shape gives some sort 
>> of "quality" to the points; that's why I want to show the points 
>> differently, so that it can easily be seen whether "good" points plot 
>> in the same area as the "bad" points.
>> Because I'm doing facet plots with other variables, I do not want to 
>> separate these categories in the boxplots - the resulting plots would 
>> be overcrowded.
>>
>> Thank you for the help.
>> Ivan
>>
>> ---
>>
>> my_data <- structure(list(Diet = c("Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne",
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
>> "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo",
>> "Dry bamboo", "Dry bamboo"), Software = c("ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax"), NMP_cat = structure(c(1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 
>> 2L, 2L, 2L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
>> 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 
>> 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 
>> 2L, 2L), .Label = c("0-5%", "5-10%", "10-20%", "20-100%"), class = 
>> c("ordered", "factor")), name = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = 
>> c("Asfc", "Smfc", "HAsfc9", "HAsfc81", "epLsar", "NewEplsar"), class = 
>> "factor"), value = c(16.00716636, 12.925787, 14.05932485, 11.999816, 
>> 15.12321532, 12.711474, 12.79565826, 10.900949, 15.90481161, 
>> 12.836045, 16.22778102, 13.565995, 14.71354945, 12.384152, 
>> 16.61354777, 13.714165, 15.91399496, 12.983796, 19.44739619, 
>> 15.173215, 16.13761798, 12.932798, 14.7332952, 12.10277, 10.78710961, 
>> 8.762726, 10.16027362, 8.040399, 14.53444662, 11.527896, 17.38120685, 
>> 13.78922, 11.26840546, 9.426558, 24.01797992, 18.398553, 13.7435699, 
>> 11.44385, 14.391873, 10.757141, 22.39390393, 18.176262, 11.60322022, 
>> 9.969118, 11.6099975, 10.059618, 11.86282935, 10.280864, 16.22473644, 
>> 13.562839, 12.46350165, 10.629406, 23.9347534, 19.062174, 19.58121507, 
>> 15.910959, 13.99145447, 11.352648, 14.38942328, 11.821431, 23.4733371, 
>> 18.549503, 13.08142223, 10.735494, 17.09293046, 13.012834, 
>> 28.80020878, 22.447105, 25.74460885, 19.76834, 14.29106582, 12.233774, 
>> 12.03005024, 10.364224, 12.58953574, 10.30257, 18.07111578, 14.416143, 
>> 20.85562751, 16.524047, 21.06132234, 15.744758, 15.24052683, 
>> 11.891487, 11.62446752, 9.14325, 11.75704705, 10.358542, 13.65568703, 
>> 11.766129, 16.98137759, 12.594787, 11.6560954, 10.32073, 15.46708251, 
>> 13.199232, 13.20110131, 11.060226, 16.13986173, 13.564802, 
>> 25.45656859, 20.071231, 24.84006178, 19.335892, 14.4723856, 11.994841, 
>> 12.07940958, 9.470493, 13.93630412, 11.489685, 21.84464295, 17.806018, 
>> 17.4383111, 14.478338, 20.55074297, 16.254467, 30.15238714, 24.193768, 
>> 32.8541897, 25.769585, 32.06966759, 24.507185, 20.53975772, 15.951186, 
>> 11.54494952, 9.676342, 13.56490524, 11.456356, 13.58242208, 10.919419, 
>> 13.55260161, 11.356056, 38.58113502, 31.087536, 23.6753536, 18.749955, 
>> 26.38707155, 20.877856, 26.18252748, 20.758242)), row.names = c(NA, 
>> -140L), class = c("tbl_df", "tbl", "data.frame"))
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Sep  5 00:34:41 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 4 Sep 2021 15:34:41 -0700
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>
References: <005601d7a1a5$11da6480$358f2d80$.ref@yahoo.com>
 <005601d7a1a5$11da6480$358f2d80$@yahoo.com>
 <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>
Message-ID: <CAGxFJbQ+=0j4=7g4LUS2HvnXJw4KFVe0FLzBrGDuDLcURcedqA@mail.gmail.com>

I have a more general problem for you.

Given n items and 2 <=g <<n , how do you divide the n items into g
groups that are as "equal as possible."

First, operationally define "as equal as possible."
Second, define the algorithm to carry out the definition. Hint: Note
that sum{m[i]} for i <=g must sum to n, where m[i] is the number of
items in the ith group.
Third, write R code for the algorithm. Exercise for the reader.

I may be wrong, but I think numerical analysts might also have a
little fun here.

Randomization, of course, is trivial.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Sep 4, 2021 at 2:13 PM AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> Dear Thomas:
>
>
> Thank you very much for your input in this matter.
>
>
> The core part of this R code(s) (please see below) was written by *Richard
> O'Keefe*. I had three examples with different sample sizes.
>
>
>
> *First sample of size n1 = 204* divided randomly into three groups of sizes
> 68. *No problems with this one*.
>
>
>
> *The second sample of size n2 = 112* divided randomly into three groups of
> sizes 37, 37, and 38. BUT this R code generated three groups of equal sizes
> (37, 37, and 37). *How to fix the code to make sure that the output will be
> three groups of sizes 37, 37, and 38*.
>
>
>
> *The third sample of size n3 = 284* divided randomly into three groups of
> sizes 94, 95, and 95. BUT this R code generated three groups of equal sizes
> (94, 94, and 94). *Again*, h*ow to fix the code to make sure that the
> output will be three groups of sizes 94, 95, and 95*.
>
>
> With many thanks
>
> abou
>
>
> ###########  ------------------------   #############
>
>
> N1 <- 485
> population1.IDs <- seq(1, N1, by = 1)
> #### population1.IDs
>
> n1<-204                                        ##### in this case the size
> of each group of the three groups = 68
> sample1.IDs <- sample(population1.IDs,n1)
> #### sample1.IDs
>
> ####  n1 <- length(sample1.IDs)
>
>   m1 <- n1 %/% 3
>   s1 <- sample(1:n1, n1)
>   group1.IDs <- sample1.IDs[s1[1:m1]]
>   group2.IDs <- sample1.IDs[s1[(m1+1):(2*m1)]]
>   group3.IDs <- sample1.IDs[s1[(m1*2+1):(3*m1)]]
>
> groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
>
> groups.IDs
>
>
> ####### --------------------------
>
>
> N2 <- 266
> population2.IDs <- seq(1, N2, by = 1)
> #### population2.IDs
>
> n2<-112                           ##### in this case the sizes of the three
> groups are(37, 37, and 38)
>                                           ##### BUT this codes generate
> three groups of equal sizes (37, 37, and 37)
> sample2.IDs <- sample(population2.IDs,n2)
> #### sample2.IDs
>
> ####  n2 <- length(sample2.IDs)
>
>   m2 <- n2 %/% 3
>   s2 <- sample(1:n2, n2)
>   group1.IDs <- sample2.IDs[s2[1:m2]]
>   group2.IDs <- sample2.IDs[s2[(m2+1):(2*m2)]]
>   group3.IDs <- sample2.IDs[s2[(m2*2+1):(3*m2)]]
>
> groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
>
> groups.IDs
>
>
> ####### --------------------------
>
>
>
> N3 <- 674
> population3.IDs <- seq(1, N3, by = 1)
> #### population3.IDs
>
> n3<-284                           ##### in this case the sizes of the three
> groups are(94, 95, and 95)
>                                           ##### BUT this codes generate
> three groups of equal sizes (94, 94, and 94)
> sample2.IDs <- sample(population2.IDs,n2)
> sample3.IDs <- sample(population3.IDs,n3)
> #### sample3.IDs
>
> ####  n3 <- length(sample2.IDs)
>
>   m3 <- n3 %/% 3
>   s3 <- sample(1:n3, n3)
>   group1.IDs <- sample3.IDs[s3[1:m3]]
>   group2.IDs <- sample3.IDs[s3[(m3+1):(2*m3)]]
>   group3.IDs <- sample3.IDs[s3[(m3*2+1):(3*m3)]]
>
> groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
>
> groups.IDs
>
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>
>
> On Sat, Sep 4, 2021 at 11:54 AM Thomas Subia <tgs77m at yahoo.com> wrote:
>
> > Abou,
> >
> >
> >
> > I?ve been following your question on how to split a data column randomly
> > into 3 groups using R.
> >
> >
> >
> > My method may not be amenable for a large set of data but it surely worth
> > considering since it makes sense intuitively.
> >
> >
> >
> > mydata <- LETTERS[1:11]
> >
> > > mydata
> >
> > [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K"
> >
> >
> >
> > # Let?s choose a random sample of size 4 from mydata
> >
> > > random_grp1
> >
> > [1] "J" "H" "D" "A"
> >
> >
> >
> > Now my next random selection of data is defined by
> >
> > data_wo_random <- setdiff(mydata,random_grp1)
> >
> > # this makes sense because I need to choose random data from a set which
> > is defined by the difference of the sets mydata and random_grp1
> >
> >
> >
> > > data_wo_random
> >
> > [1] "B" "C" "E" "F" "G" "I" "K"
> >
> >
> >
> > This is great! So now I can randomly select data of any size from this set.
> >
> > Repeating this process can easily generate subgroups of your original
> > dataset of any size you want.
> >
> >
> >
> > Surely this method could be improved so that this could be done
> > automatically.
> >
> > Nevertheless, this is an intuitive method which I believe is easier to
> > understand than some of the other methods posted.
> >
> >
> >
> > Hope this helps!
> >
> >
> >
> > Thomas Subia
> >
> > Statistician
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Sun Sep  5 01:58:53 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sat, 4 Sep 2021 19:58:53 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>
References: <005601d7a1a5$11da6480$358f2d80$.ref@yahoo.com>
 <005601d7a1a5$11da6480$358f2d80$@yahoo.com>
 <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>
Message-ID: <016501d7a1e8$d098d300$71ca7900$@verizon.net>

Abou,

I believe I addressed this issue in a private message the other day.

As a general rule, truncating can leave a remainder. If 
	M  = length(whatever)/3 

Then M is no longer an integer. It can be a number ending in .333... or .666... as well as 0.

Now R may silently truncate something like 100/3 which you see to use and make it be as if you typed 33. Same for 2*M. In your code, you used integer division and that is a truncation too!

  m1 <- n1 %/% 3
  s1 <- sample(1:n1, n1)
  group1.IDs <- sample1.IDs[s1[1:m1]]
  group2.IDs <- sample1.IDs[s1[(m1+1):(2*m1)]]
  group3.IDs <- sample1.IDs[s1[(m1*2+1):(3*m1)]]

A proper solution accounts for any leftover items. One method is to leave all extra items till the end and have:

MAX <- length(original or whatever)
group3.IDs <- sample1.IDs[s1[(m1*2+1):MAX]]


The last group then might have one or two extra items. Another is to go for  a second sweep and take any leftover items and move one each into whatever groups you wish for some balance.

Or, as discussed, there are packages available that let you specify percentages you want and handle these edge cases too.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of AbouEl-Makarim Aboueissa
Sent: Saturday, September 4, 2021 5:13 PM
To: Thomas Subia <tgs77m at yahoo.com>
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] Splitting a data column randomly into 3 groups

Dear Thomas:


Thank you very much for your input in this matter.


The core part of this R code(s) (please see below) was written by *Richard O'Keefe*. I had three examples with different sample sizes.



*First sample of size n1 = 204* divided randomly into three groups of sizes 68. *No problems with this one*.



*The second sample of size n2 = 112* divided randomly into three groups of sizes 37, 37, and 38. BUT this R code generated three groups of equal sizes (37, 37, and 37). *How to fix the code to make sure that the output will be three groups of sizes 37, 37, and 38*.



*The third sample of size n3 = 284* divided randomly into three groups of sizes 94, 95, and 95. BUT this R code generated three groups of equal sizes (94, 94, and 94). *Again*, h*ow to fix the code to make sure that the output will be three groups of sizes 94, 95, and 95*.


With many thanks

abou


###########  ------------------------   #############


N1 <- 485
population1.IDs <- seq(1, N1, by = 1)
#### population1.IDs

n1<-204                                        ##### in this case the size
of each group of the three groups = 68
sample1.IDs <- sample(population1.IDs,n1) #### sample1.IDs

####  n1 <- length(sample1.IDs)

  m1 <- n1 %/% 3
  s1 <- sample(1:n1, n1)
  group1.IDs <- sample1.IDs[s1[1:m1]]
  group2.IDs <- sample1.IDs[s1[(m1+1):(2*m1)]]
  group3.IDs <- sample1.IDs[s1[(m1*2+1):(3*m1)]]

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs


####### --------------------------


N2 <- 266
population2.IDs <- seq(1, N2, by = 1)
#### population2.IDs

n2<-112                           ##### in this case the sizes of the three
groups are(37, 37, and 38)
                                          ##### BUT this codes generate three groups of equal sizes (37, 37, and 37) sample2.IDs <- sample(population2.IDs,n2) #### sample2.IDs

####  n2 <- length(sample2.IDs)

  m2 <- n2 %/% 3
  s2 <- sample(1:n2, n2)
  group1.IDs <- sample2.IDs[s2[1:m2]]
  group2.IDs <- sample2.IDs[s2[(m2+1):(2*m2)]]
  group3.IDs <- sample2.IDs[s2[(m2*2+1):(3*m2)]]

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs


####### --------------------------



N3 <- 674
population3.IDs <- seq(1, N3, by = 1)
#### population3.IDs

n3<-284                           ##### in this case the sizes of the three
groups are(94, 95, and 95)
                                          ##### BUT this codes generate three groups of equal sizes (94, 94, and 94) sample2.IDs <- sample(population2.IDs,n2) sample3.IDs <- sample(population3.IDs,n3) #### sample3.IDs

####  n3 <- length(sample2.IDs)

  m3 <- n3 %/% 3
  s3 <- sample(1:n3, n3)
  group1.IDs <- sample3.IDs[s3[1:m3]]
  group2.IDs <- sample3.IDs[s3[(m3+1):(2*m3)]]
  group3.IDs <- sample3.IDs[s3[(m3*2+1):(3*m3)]]

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs

______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science* *Graduate Coordinator*

*Department of Mathematics and Statistics* *University of Southern Maine*



On Sat, Sep 4, 2021 at 11:54 AM Thomas Subia <tgs77m at yahoo.com> wrote:

> Abou,
>
>
>
> I?ve been following your question on how to split a data column 
> randomly into 3 groups using R.
>
>
>
> My method may not be amenable for a large set of data but it surely 
> worth considering since it makes sense intuitively.
>
>
>
> mydata <- LETTERS[1:11]
>
> > mydata
>
> [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K"
>
>
>
> # Let?s choose a random sample of size 4 from mydata
>
> > random_grp1
>
> [1] "J" "H" "D" "A"
>
>
>
> Now my next random selection of data is defined by
>
> data_wo_random <- setdiff(mydata,random_grp1)
>
> # this makes sense because I need to choose random data from a set 
> which is defined by the difference of the sets mydata and random_grp1
>
>
>
> > data_wo_random
>
> [1] "B" "C" "E" "F" "G" "I" "K"
>
>
>
> This is great! So now I can randomly select data of any size from this set.
>
> Repeating this process can easily generate subgroups of your original 
> dataset of any size you want.
>
>
>
> Surely this method could be improved so that this could be done 
> automatically.
>
> Nevertheless, this is an intuitive method which I believe is easier to 
> understand than some of the other methods posted.
>
>
>
> Hope this helps!
>
>
>
> Thomas Subia
>
> Statistician
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From brunoju||@tt| @end|ng |rom gm@||@com  Sat Sep  4 16:13:57 2021
From: brunoju||@tt| @end|ng |rom gm@||@com (=?UTF-8?Q?Bruno_C=C3=A9sar_Juliatti?=)
Date: Sat, 4 Sep 2021 11:13:57 -0300
Subject: [R] Help with bibliometrix and biblioshiny
Message-ID: <CADUw8q5jbvGu5y6mVfoH+ihZsGWYun3Fn7krKT0Kdxu6Hkd5Xw@mail.gmail.com>

Hi, everyone. I'm new in this R language universe. I want to use
bibliometric as a research in m Master's program. I run the code in R
studio and works just fine. But, in the web-interface (biblioshiny), I load
the table in .csv and keeps showing this message: Error: object 'M' not
found
PS: I already exported the searches in Web of Science and Scopus.

This is the code and below the console's messages.

*install.packages("bibliometrix")* # Baixar o pacote. S? precisa fazer isso
uma #vez! E demora muito, por vezes muitos minutos!

#library(bibliometrix)  # carregar o pacote na mem?ria para utiliz?-lo
agora.

# D?vidas de uso do Bibliometrix, execute  o comando que segue:
help(bibliometrix)

#Artigo: CAPACIDADE ESTATAL
#AUTORES: PATR? CIA ROSVADOSKI-DA-SILVA, WELLES ABREU
#OBJETIVO -> Caracterizar e clusterizar os trabalhos de capacidade estatal


#######COLETA DOS DADOS ##############

#WEB OF SCIENCE
#Pesquisa B??sica
# vari??veis da pesquisa: BOLEADORES -> AND, OR , NOT
############ ATEN????O: ASPAS (") E *
# configura????es
#Filtros ##########ATEN????O: ANOTAR TODOS OS PASSOS
# EXPORTAR -> Outros formatos de arquivo
# Registro completo de refer??ncias citadas (m??ximo de 500)
# bibtex. OBS-> Salvar arquivo: ser?? gerado um arquivo #???savedrecs.bib??
na ??rea de downloads

#SCOPUS
#PESQUISA
#CAMPOS
#  FILTROS -> Data range, document type, Access type
#FILTROS
#EXPORT -> Bibtex (citation information, Bibliographical information,
Abstract & keywords, Funding details, Other information -> Export)
#limite de 2000 artigos, Salvar arquivo: ser?? gerado um arquivo
#???scopus.bib?? na ??rea de downloads








############### ETAPA 1 - CARREGAMENTO E CONVERS?O DOS DADOS ###############

# WEB OF SCIENCE (ISI): Converter os dados para o padr?o do bibliometrix

*W <- convert2df("C:/Users/bruno/Desktop/Bibliometria/wos_scielo.bib",
dbsource = "isi", format = "bibtex")*
#W1 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/WOS/savedrecs (12).bib", dbsource = "isi", format
= "bibtex")
#W2 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/WOS/savedrecs (13).bib", dbsource = "isi", format
= "bibtex")
#W3 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/WOS/savedrecs (14).bib", dbsource = "isi", format
= "bibtex")
#W4 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/WOS/savedrecs (15).bib", dbsource = "isi", format
= "bibtex")




#W <- mergeDbSources(W1, W2, W3, W4)




# SCOPUS: Converter os dados   para o padr?o do bibliometrix

*S <-convert2df("C:/Users/bruno/Desktop/Bibliometria/scopus_elsevier.bib",
dbsource = "scopus", format = "bibtex")*
#S2 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (2).bib", dbsource = "scopus",
format = "bibtex")
#S3 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (4).bib", dbsource = "scopus",
format = "bibtex")
#S4 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (5).bib", dbsource = "scopus",
format = "bibtex")
#S5 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (6).bib", dbsource = "scopus",
format = "bibtex")
#S6 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (7).bib", dbsource = "scopus",
format = "bibtex")
#S7 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (8).bib", dbsource = "scopus",
format = "bibtex")
#S8 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (9).bib", dbsource = "scopus",
format = "bibtex")
#S9 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (10).bib", dbsource = "scopus",
format = "bibtex")
#S10 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
#andamento/Cooperativismo/Scopus/scopus (11).bib", dbsource = "scopus",
#format = "bibtex")


#S <- mergeDbSources(S1, S2, S3, S4, S5, S6, S7, S8, S9, S10)

# PUBMED: Se desejar caregar dado, execute o script do PubMed, gerando o
#arquivo de dados "C"

# COCHRANE: Se desejar carregar dados  execute a linha que segue, gerando
#o arquivo de dados "D"
# D <- convert2df("c:/bib/citation-export.bib", dbsource = "isi", format =
"bibtex")

#### Juntar bases WEB OF SCIENCE (ISI), SCOPUS, PUBMED e #COCHRANE
*M <- mergeDbSources(W, S, remove.duplicated = TRUE)*

# se precisar juntar dados do Pubmed e Cochrane, execute linha que segue
# M <- mergeDbSources(A, B, C, D, remove.duplicated = TRUE)

#### Cria um arquivo.csv para importar para o Excel
*P<- M[,c("AU","TI","SO","AB","DE", "ID", "DI","LA","DT","TC","PY")] * #
#Cria lista na ordem desejada
*write.table(P, "C:/Users/bruno/Desktop/Bibliometria/opa.csv", sep=";",
row.names=FALSE)* # para gerar com separador ";", sem necessidade de
#ajustar o CSV, quanto ? primeira coluna

#### BiblioAnalysis - Processamento dos dados
*resultados <- biblioAnalysis(M)*




############### ETAPA 2 - AN?LISE e VISUALIZA??O DOS DADOS ###############

#### 2.1 - Resumo dos resultados na console do RStudio


*Resumo <- summary(object = resultados, k = 10)Resumoplot(resultados, k=10)*
  # Gr?ficos com dados bibliom?tricos b?sicos
*plot*


# Para visualizar os resultados via web-interface (browser)
*biblioshiny()*

#### Para mais informa??es, tutoriais e v?deos, acessar
www.bibliometrix.org/

This is the console's message about the error:













*Warning: Error in eventReactiveValueFunc: object 'M' not found  149:
eventReactiveValueFunc
[C:\Users\bruno\OneDrive\Documentos\R\win-library\4.1\bibliometrix\biblioshiny/server.R#321]
105: DATAloading  104: exprFunc
[C:\Users\bruno\OneDrive\Documentos\R\win-library\4.1\bibliometrix\biblioshiny/server.R#330]
103: widgetFunc  102: htmlwidgets::shinyRenderWidget  101: func   88:
renderFunc   87: renderFunc   83: renderFunc   82: output$contents    2:
runApp*
*    1: biblioshiny *

	[[alternative HTML version deleted]]


From |euk@m|r@nk||n18 @end|ng |rom y@hoo@com  Sun Sep  5 12:43:21 2021
From: |euk@m|r@nk||n18 @end|ng |rom y@hoo@com (Franklin Feukam)
Date: Sun, 5 Sep 2021 12:43:21 +0200
Subject: [R] Multivariate tobit regression
Message-ID: <mailman.364135.5.1630856431.1337.r-help@r-project.org>

Please can I have the package of Multivariate Tobit regression??

I am a student at Ecole Nationale de la Statistique et de l?Administration Economique of Paris.

Thanks?!

Envoy? ? partir de Courrier pour Windows


	[[alternative HTML version deleted]]


From jrg @end|ng |rom |oe@|@u@  Sun Sep  5 17:26:05 2021
From: jrg @end|ng |rom |oe@|@u@ (JRG)
Date: Sun, 5 Sep 2021 11:26:05 -0400
Subject: [R] Multivariate tobit regression
In-Reply-To: <20210905152032.397D412E8@hypatia.math.ethz.ch>
References: <20210905152032.397D412E8@hypatia.math.ethz.ch>
Message-ID: <a919c6e5-43a3-1e9d-2820-cb1143d553c5@loesl.us>

Have you tried

RSiteSearch("tobit")

??

---JRG



On 9/5/21 6:43 AM, Franklin Feukam via R-help wrote:
> Multivariate Tobit regression


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep  5 17:50:29 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 05 Sep 2021 08:50:29 -0700
Subject: [R] Multivariate tobit regression
In-Reply-To: <20210905152032.397D412E8@hypatia.math.ethz.ch>
References: <20210905152032.397D412E8@hypatia.math.ethz.ch>
Message-ID: <58CC285F-3F6D-4182-AAA9-64B3E8D629A8@dcn.davis.ca.us>

Quite probably, but not via this mailing list. Do read the Posting Guide mentioned in the footer. http://cran.nexr.com/web/views/Econometrics.html may suggest options.

On September 5, 2021 3:43:21 AM PDT, Franklin Feukam via R-help <r-help at r-project.org> wrote:
>Please can I have the package of Multivariate Tobit regression??
>
>I am a student at Ecole Nationale de la Statistique et de l?Administration Economique of Paris.
>
>Thanks?!
>
>Envoy? ? partir de Courrier pour Windows
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Sep  5 18:02:05 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 5 Sep 2021 09:02:05 -0700
Subject: [R] Help with bibliometrix and biblioshiny
In-Reply-To: <CADUw8q5jbvGu5y6mVfoH+ihZsGWYun3Fn7krKT0Kdxu6Hkd5Xw@mail.gmail.com>
References: <CADUw8q5jbvGu5y6mVfoH+ihZsGWYun3Fn7krKT0Kdxu6Hkd5Xw@mail.gmail.com>
Message-ID: <CAGxFJbR3nD1tNj5yYjS5+OcR=U24Dsnnp9T1Ojn9LMpVxor7mA@mail.gmail.com>

Please read and follow the posting guide, which says:

"For questions about functions in standard packages distributed with R
(see the FAQ Add-on packages in R), ask questions on R-help.
If the question relates to a contributed package , e.g., one
downloaded from CRAN, try contacting the package maintainer first. You
can also use find("functionname") and
packageDescription("packagename") to find this information. Only send
such questions to R-help or R-devel if you get no reply or need
further assistance. "

So for a specialized package like bibliometrix, though you might get
lucky here, you should probably contact the maintainers. I also noted
that the package has its own web page with a FAQ and other resources.
Have you consulted them yet?  There might also be a user community
that could help, but I did not see it in my brief look around.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Sep 5, 2021 at 8:20 AM Bruno C?sar Juliatti
<brunojuliatti at gmail.com> wrote:
>
> Hi, everyone. I'm new in this R language universe. I want to use
> bibliometric as a research in m Master's program. I run the code in R
> studio and works just fine. But, in the web-interface (biblioshiny), I load
> the table in .csv and keeps showing this message: Error: object 'M' not
> found
> PS: I already exported the searches in Web of Science and Scopus.
>
> This is the code and below the console's messages.
>
> *install.packages("bibliometrix")* # Baixar o pacote. S? precisa fazer isso
> uma #vez! E demora muito, por vezes muitos minutos!
>
> #library(bibliometrix)  # carregar o pacote na mem?ria para utiliz?-lo
> agora.
>
> # D?vidas de uso do Bibliometrix, execute  o comando que segue:
> help(bibliometrix)
>
> #Artigo: CAPACIDADE ESTATAL
> #AUTORES: PATR? CIA ROSVADOSKI-DA-SILVA, WELLES ABREU
> #OBJETIVO -> Caracterizar e clusterizar os trabalhos de capacidade estatal
>
>
> #######COLETA DOS DADOS ##############
>
> #WEB OF SCIENCE
> #Pesquisa B??sica
> # vari??veis da pesquisa: BOLEADORES -> AND, OR , NOT
> ############ ATEN????O: ASPAS (") E *
> # configura????es
> #Filtros ##########ATEN????O: ANOTAR TODOS OS PASSOS
> # EXPORTAR -> Outros formatos de arquivo
> # Registro completo de refer??ncias citadas (m??ximo de 500)
> # bibtex. OBS-> Salvar arquivo: ser?? gerado um arquivo #???savedrecs.bib??
> na ??rea de downloads
>
> #SCOPUS
> #PESQUISA
> #CAMPOS
> #  FILTROS -> Data range, document type, Access type
> #FILTROS
> #EXPORT -> Bibtex (citation information, Bibliographical information,
> Abstract & keywords, Funding details, Other information -> Export)
> #limite de 2000 artigos, Salvar arquivo: ser?? gerado um arquivo
> #???scopus.bib?? na ??rea de downloads
>
>
>
>
>
>
>
>
> ############### ETAPA 1 - CARREGAMENTO E CONVERS?O DOS DADOS ###############
>
> # WEB OF SCIENCE (ISI): Converter os dados para o padr?o do bibliometrix
>
> *W <- convert2df("C:/Users/bruno/Desktop/Bibliometria/wos_scielo.bib",
> dbsource = "isi", format = "bibtex")*
> #W1 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/WOS/savedrecs (12).bib", dbsource = "isi", format
> = "bibtex")
> #W2 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/WOS/savedrecs (13).bib", dbsource = "isi", format
> = "bibtex")
> #W3 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/WOS/savedrecs (14).bib", dbsource = "isi", format
> = "bibtex")
> #W4 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/WOS/savedrecs (15).bib", dbsource = "isi", format
> = "bibtex")
>
>
>
>
> #W <- mergeDbSources(W1, W2, W3, W4)
>
>
>
>
> # SCOPUS: Converter os dados   para o padr?o do bibliometrix
>
> *S <-convert2df("C:/Users/bruno/Desktop/Bibliometria/scopus_elsevier.bib",
> dbsource = "scopus", format = "bibtex")*
> #S2 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (2).bib", dbsource = "scopus",
> format = "bibtex")
> #S3 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (4).bib", dbsource = "scopus",
> format = "bibtex")
> #S4 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (5).bib", dbsource = "scopus",
> format = "bibtex")
> #S5 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (6).bib", dbsource = "scopus",
> format = "bibtex")
> #S6 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (7).bib", dbsource = "scopus",
> format = "bibtex")
> #S7 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (8).bib", dbsource = "scopus",
> format = "bibtex")
> #S8 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (9).bib", dbsource = "scopus",
> format = "bibtex")
> #S9 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (10).bib", dbsource = "scopus",
> format = "bibtex")
> #S10 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> #andamento/Cooperativismo/Scopus/scopus (11).bib", dbsource = "scopus",
> #format = "bibtex")
>
>
> #S <- mergeDbSources(S1, S2, S3, S4, S5, S6, S7, S8, S9, S10)
>
> # PUBMED: Se desejar caregar dado, execute o script do PubMed, gerando o
> #arquivo de dados "C"
>
> # COCHRANE: Se desejar carregar dados  execute a linha que segue, gerando
> #o arquivo de dados "D"
> # D <- convert2df("c:/bib/citation-export.bib", dbsource = "isi", format =
> "bibtex")
>
> #### Juntar bases WEB OF SCIENCE (ISI), SCOPUS, PUBMED e #COCHRANE
> *M <- mergeDbSources(W, S, remove.duplicated = TRUE)*
>
> # se precisar juntar dados do Pubmed e Cochrane, execute linha que segue
> # M <- mergeDbSources(A, B, C, D, remove.duplicated = TRUE)
>
> #### Cria um arquivo.csv para importar para o Excel
> *P<- M[,c("AU","TI","SO","AB","DE", "ID", "DI","LA","DT","TC","PY")] * #
> #Cria lista na ordem desejada
> *write.table(P, "C:/Users/bruno/Desktop/Bibliometria/opa.csv", sep=";",
> row.names=FALSE)* # para gerar com separador ";", sem necessidade de
> #ajustar o CSV, quanto ? primeira coluna
>
> #### BiblioAnalysis - Processamento dos dados
> *resultados <- biblioAnalysis(M)*
>
>
>
>
> ############### ETAPA 2 - AN?LISE e VISUALIZA??O DOS DADOS ###############
>
> #### 2.1 - Resumo dos resultados na console do RStudio
>
>
> *Resumo <- summary(object = resultados, k = 10)Resumoplot(resultados, k=10)*
>   # Gr?ficos com dados bibliom?tricos b?sicos
> *plot*
>
>
> # Para visualizar os resultados via web-interface (browser)
> *biblioshiny()*
>
> #### Para mais informa??es, tutoriais e v?deos, acessar
> www.bibliometrix.org/
>
> This is the console's message about the error:
>
>
>
>
>
>
>
>
>
>
>
>
>
> *Warning: Error in eventReactiveValueFunc: object 'M' not found  149:
> eventReactiveValueFunc
> [C:\Users\bruno\OneDrive\Documentos\R\win-library\4.1\bibliometrix\biblioshiny/server.R#321]
> 105: DATAloading  104: exprFunc
> [C:\Users\bruno\OneDrive\Documentos\R\win-library\4.1\bibliometrix\biblioshiny/server.R#330]
> 103: widgetFunc  102: htmlwidgets::shinyRenderWidget  101: func   88:
> renderFunc   87: renderFunc   83: renderFunc   82: output$contents    2:
> runApp*
> *    1: biblioshiny *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From w||||@mwdun|@p @end|ng |rom gm@||@com  Sun Sep  5 19:18:48 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Sun, 5 Sep 2021 10:18:48 -0700
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <219F64F7-55D9-4D5B-9666-2C2DF6EC7AF4@dcn.davis.ca.us>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
 <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
 <219F64F7-55D9-4D5B-9666-2C2DF6EC7AF4@dcn.davis.ca.us>
Message-ID: <CAHqSRuTmg0+RXa5gxFCETx2bfYL5e7n-bpwnX2R92JDxqzV0Dw@mail.gmail.com>

What is the best way to read (from a text file) timestamps from the fall
time change, where there are two 1:15am's?  E.g., here is an extract from a
US Geological Survey web site giving data on the river through our county
on 2020-11-01, when we changed from PDT to PST,
https://nwis.waterdata.usgs.gov/wa/nwis/uv/?cb_00010=on&cb_00060=on&cb_00065=on&format=rdb&site_no=12200500&period=&begin_date=2020-11-01&end_date=2020-11-05
.

The timestamps include the date and time as well as PDT or PST.

river <-
c("datetime,tz,discharge,height,temp",
  "2020-11-01 00:00,PDT,20500,16.44,9.3",
  "2020-11-01 00:15,PDT,20500,16.44,9.3",
  "2020-11-01 00:30,PDT,20500,16.43,9.3",
  "2020-11-01 00:45,PDT,20400,16.40,9.3",
  "2020-11-01 01:00,PDT,20400,16.40,9.3",
  "2020-11-01 01:00,PST,20200,16.34,9.2",
  "2020-11-01 01:15,PDT,20400,16.39,9.3",
  "2020-11-01 01:15,PST,20200,16.34,9.2",
  "2020-11-01 01:30,PDT,20300,16.37,9.2",
  "2020-11-01 01:30,PST,20100,16.31,9.2",
  "2020-11-01 01:45,PDT,20300,16.35,9.2",
  "2020-11-01 01:45,PST,20100,16.29,9.2",
  "2020-11-01 02:00,PST,20100,16.29,9.2",
  "2020-11-01 02:15,PST,20000,16.27,9.1",
  "2020-11-01 02:30,PST,20000,16.26,9.1"
  )
d <- read.table(text=river, sep=",",header=TRUE)

The entries are obviously not in time order.

Is there a simple way to read the timedate and tz columns together?  One
way is to use d$tz to construct an offset that can be read with
strptime's "%z".

> d$POSIXct <-
as.POSIXct(paste(d$datetime,ifelse(d$tz=="PDT","-0700","-0800")),
format="%Y-%m-%d %H:%M %z")
> d
           datetime  tz discharge height temp             POSIXct
1  2020-11-01 00:00 PDT     20500  16.44  9.3 2020-11-01 00:00:00
2  2020-11-01 00:15 PDT     20500  16.44  9.3 2020-11-01 00:15:00
3  2020-11-01 00:30 PDT     20500  16.43  9.3 2020-11-01 00:30:00
4  2020-11-01 00:45 PDT     20400  16.40  9.3 2020-11-01 00:45:00
5  2020-11-01 01:00 PDT     20400  16.40  9.3 2020-11-01 01:00:00
6  2020-11-01 01:00 PST     20200  16.34  9.2 2020-11-01 01:00:00
7  2020-11-01 01:15 PDT     20400  16.39  9.3 2020-11-01 01:15:00
8  2020-11-01 01:15 PST     20200  16.34  9.2 2020-11-01 01:15:00
9  2020-11-01 01:30 PDT     20300  16.37  9.2 2020-11-01 01:30:00
10 2020-11-01 01:30 PST     20100  16.31  9.2 2020-11-01 01:30:00
11 2020-11-01 01:45 PDT     20300  16.35  9.2 2020-11-01 01:45:00
12 2020-11-01 01:45 PST     20100  16.29  9.2 2020-11-01 01:45:00
13 2020-11-01 02:00 PST     20100  16.29  9.2 2020-11-01 02:00:00
14 2020-11-01 02:15 PST     20000  16.27  9.1 2020-11-01 02:15:00
15 2020-11-01 02:30 PST     20000  16.26  9.1 2020-11-01 02:30:00
> with(d[order(d$POSIXct),], plot(temp)) # monotonic temperature

-Bill


On Thu, Sep 2, 2021 at 12:41 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Regardless of whether you use the lower-level split function, or the
> higher-level aggregate function, or the tidyverse group_by function, the
> key is learning how to create the column that is the same for all records
> corresponding to the time interval of interest.
>
> If you convert the sampdate to POSIXct, the tz IS important, because most
> of us use local timezones that respect daylight savings time, and a naive
> conversion of standard time will run into trouble if R is assuming daylight
> savings time applies. The lubridate package gets around this by always
> assuming UTC and giving you a function to "fix" the timezone after the
> conversion. I prefer to always be specific about timezones, at least by
> using so something like
>
>     Sys.setenv( TZ = "Etc/GMT+8" )
>
> which does not respect daylight savings.
>
> Regarding using character data for identifying the month, in order to have
> clean plots of the data I prefer to use the trunc function but it returns a
> POSIXlt so I convert it to POSIXct:
>
>     discharge$sampmonthbegin <- as.POSIXct( trunc( discharge$sampdate,
> units = "months" ) )
>
> Then any of various ways can be used to aggregate the records by that
> column.
>
> On September 2, 2021 12:10:15 PM PDT, Andrew Simmons <akwsimmo at gmail.com>
> wrote:
> >You could use 'split' to create a list of data frames, and then apply a
> >function to each to get the means and sds.
> >
> >
> >cols <- "cfs"  # add more as necessary
> >S <- split(discharge[cols], format(discharge$sampdate, format = "%Y-%m"))
> >means <- do.call("rbind", lapply(S, colMeans, na.rm = TRUE))
> >sds   <- do.call("rbind", lapply(S, function(xx) sapply(xx, sd, na.rm =
> >TRUE)))
> >
> >On Thu, Sep 2, 2021 at 3:01 PM Rich Shepard <rshepard at appl-ecosys.com>
> >wrote:
> >
> >> On Thu, 2 Sep 2021, Rich Shepard wrote:
> >>
> >> > If I correctly understand the output of as.POSIXlt each date and time
> >> > element is separate, so input such as 2016-03-03 12:00 would now be
> 2016
> >> 03
> >> > 03 12 00 (I've not read how the elements are separated). (The TZ is
> not
> >> > important because all data are either PST or PDT.)
> >>
> >> Using this script:
> >> discharge <- read.csv('../data/water/discharge.dat', header = TRUE, sep
> =
> >> ',', stringsAsFactors = FALSE)
> >> discharge$sampdate <- as.POSIXlt(discharge$sampdate, tz = "",
> >>                                   format = '%Y-%m-%d %H:%M',
> >>                                   optional = 'logical')
> >> discharge$cfs <- as.numeric(discharge$cfs, length = 6)
> >>
> >> I get this result:
> >> > head(discharge)
> >>               sampdate    cfs
> >> 1 2016-03-03 12:00:00 149000
> >> 2 2016-03-03 12:10:00 150000
> >> 3 2016-03-03 12:20:00 151000
> >> 4 2016-03-03 12:30:00 156000
> >> 5 2016-03-03 12:40:00 154000
> >> 6 2016-03-03 12:50:00 150000
> >>
> >> I'm completely open to suggestions on using this output to calculate
> >> monthly
> >> means and sds.
> >>
> >> If dplyr:summarize() will do so please show me how to modify this
> command:
> >> disc_monthly <- ( discharge
> >>          %>% group_by(sampdate)
> >>          %>% summarize(exp_value = mean(cfs, na.rm = TRUE))
> >> because it produces daily means, not monthly means.
> >>
> >> TIA,
> >>
> >> Rich
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep  5 20:04:43 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 05 Sep 2021 11:04:43 -0700
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CAHqSRuTmg0+RXa5gxFCETx2bfYL5e7n-bpwnX2R92JDxqzV0Dw@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
 <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
 <219F64F7-55D9-4D5B-9666-2C2DF6EC7AF4@dcn.davis.ca.us>
 <CAHqSRuTmg0+RXa5gxFCETx2bfYL5e7n-bpwnX2R92JDxqzV0Dw@mail.gmail.com>
Message-ID: <8F130A55-5394-4EFB-9BBB-5E9511624356@dcn.davis.ca.us>

This problem nearly always boils down to using meta knowledge about the file. Having informal TZ info in the file is very helpful, but PST is not necessarily a uniquely-defined time zone specification so you have to draw on information outside of the file to know that these codes correspond to -0800 etc. (e.g. CST could be China Standard Time or US Central Standard Time.) Thus, it is tough to make this into a broadly-useful function.

You can also construct the timezone column from knowledge about the location of interest and the monotonicity of the time data. https://jdnewmil.github.io/eci298sp2016/QuickHowtos1.html#handling-time-data ... but the answer to "easy" seems firmly in the eyes of the beholder.

On September 5, 2021 10:18:48 AM PDT, Bill Dunlap <williamwdunlap at gmail.com> wrote:
>What is the best way to read (from a text file) timestamps from the fall
>time change, where there are two 1:15am's?  E.g., here is an extract from a
>US Geological Survey web site giving data on the river through our county
>on 2020-11-01, when we changed from PDT to PST,
>https://nwis.waterdata.usgs.gov/wa/nwis/uv/?cb_00010=on&cb_00060=on&cb_00065=on&format=rdb&site_no=12200500&period=&begin_date=2020-11-01&end_date=2020-11-05
>.
>
>The timestamps include the date and time as well as PDT or PST.
>
>river <-
>c("datetime,tz,discharge,height,temp",
>  "2020-11-01 00:00,PDT,20500,16.44,9.3",
>  "2020-11-01 00:15,PDT,20500,16.44,9.3",
>  "2020-11-01 00:30,PDT,20500,16.43,9.3",
>  "2020-11-01 00:45,PDT,20400,16.40,9.3",
>  "2020-11-01 01:00,PDT,20400,16.40,9.3",
>  "2020-11-01 01:00,PST,20200,16.34,9.2",
>  "2020-11-01 01:15,PDT,20400,16.39,9.3",
>  "2020-11-01 01:15,PST,20200,16.34,9.2",
>  "2020-11-01 01:30,PDT,20300,16.37,9.2",
>  "2020-11-01 01:30,PST,20100,16.31,9.2",
>  "2020-11-01 01:45,PDT,20300,16.35,9.2",
>  "2020-11-01 01:45,PST,20100,16.29,9.2",
>  "2020-11-01 02:00,PST,20100,16.29,9.2",
>  "2020-11-01 02:15,PST,20000,16.27,9.1",
>  "2020-11-01 02:30,PST,20000,16.26,9.1"
>  )
>d <- read.table(text=river, sep=",",header=TRUE)
>
>The entries are obviously not in time order.
>
>Is there a simple way to read the timedate and tz columns together?  One
>way is to use d$tz to construct an offset that can be read with
>strptime's "%z".
>
>> d$POSIXct <-
>as.POSIXct(paste(d$datetime,ifelse(d$tz=="PDT","-0700","-0800")),
>format="%Y-%m-%d %H:%M %z")
>> d
>           datetime  tz discharge height temp             POSIXct
>1  2020-11-01 00:00 PDT     20500  16.44  9.3 2020-11-01 00:00:00
>2  2020-11-01 00:15 PDT     20500  16.44  9.3 2020-11-01 00:15:00
>3  2020-11-01 00:30 PDT     20500  16.43  9.3 2020-11-01 00:30:00
>4  2020-11-01 00:45 PDT     20400  16.40  9.3 2020-11-01 00:45:00
>5  2020-11-01 01:00 PDT     20400  16.40  9.3 2020-11-01 01:00:00
>6  2020-11-01 01:00 PST     20200  16.34  9.2 2020-11-01 01:00:00
>7  2020-11-01 01:15 PDT     20400  16.39  9.3 2020-11-01 01:15:00
>8  2020-11-01 01:15 PST     20200  16.34  9.2 2020-11-01 01:15:00
>9  2020-11-01 01:30 PDT     20300  16.37  9.2 2020-11-01 01:30:00
>10 2020-11-01 01:30 PST     20100  16.31  9.2 2020-11-01 01:30:00
>11 2020-11-01 01:45 PDT     20300  16.35  9.2 2020-11-01 01:45:00
>12 2020-11-01 01:45 PST     20100  16.29  9.2 2020-11-01 01:45:00
>13 2020-11-01 02:00 PST     20100  16.29  9.2 2020-11-01 02:00:00
>14 2020-11-01 02:15 PST     20000  16.27  9.1 2020-11-01 02:15:00
>15 2020-11-01 02:30 PST     20000  16.26  9.1 2020-11-01 02:30:00
>> with(d[order(d$POSIXct),], plot(temp)) # monotonic temperature
>
>-Bill
>
>
>On Thu, Sep 2, 2021 at 12:41 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Regardless of whether you use the lower-level split function, or the
>> higher-level aggregate function, or the tidyverse group_by function, the
>> key is learning how to create the column that is the same for all records
>> corresponding to the time interval of interest.
>>
>> If you convert the sampdate to POSIXct, the tz IS important, because most
>> of us use local timezones that respect daylight savings time, and a naive
>> conversion of standard time will run into trouble if R is assuming daylight
>> savings time applies. The lubridate package gets around this by always
>> assuming UTC and giving you a function to "fix" the timezone after the
>> conversion. I prefer to always be specific about timezones, at least by
>> using so something like
>>
>>     Sys.setenv( TZ = "Etc/GMT+8" )
>>
>> which does not respect daylight savings.
>>
>> Regarding using character data for identifying the month, in order to have
>> clean plots of the data I prefer to use the trunc function but it returns a
>> POSIXlt so I convert it to POSIXct:
>>
>>     discharge$sampmonthbegin <- as.POSIXct( trunc( discharge$sampdate,
>> units = "months" ) )
>>
>> Then any of various ways can be used to aggregate the records by that
>> column.
>>
>> On September 2, 2021 12:10:15 PM PDT, Andrew Simmons <akwsimmo at gmail.com>
>> wrote:
>> >You could use 'split' to create a list of data frames, and then apply a
>> >function to each to get the means and sds.
>> >
>> >
>> >cols <- "cfs"  # add more as necessary
>> >S <- split(discharge[cols], format(discharge$sampdate, format = "%Y-%m"))
>> >means <- do.call("rbind", lapply(S, colMeans, na.rm = TRUE))
>> >sds   <- do.call("rbind", lapply(S, function(xx) sapply(xx, sd, na.rm =
>> >TRUE)))
>> >
>> >On Thu, Sep 2, 2021 at 3:01 PM Rich Shepard <rshepard at appl-ecosys.com>
>> >wrote:
>> >
>> >> On Thu, 2 Sep 2021, Rich Shepard wrote:
>> >>
>> >> > If I correctly understand the output of as.POSIXlt each date and time
>> >> > element is separate, so input such as 2016-03-03 12:00 would now be
>> 2016
>> >> 03
>> >> > 03 12 00 (I've not read how the elements are separated). (The TZ is
>> not
>> >> > important because all data are either PST or PDT.)
>> >>
>> >> Using this script:
>> >> discharge <- read.csv('../data/water/discharge.dat', header = TRUE, sep
>> =
>> >> ',', stringsAsFactors = FALSE)
>> >> discharge$sampdate <- as.POSIXlt(discharge$sampdate, tz = "",
>> >>                                   format = '%Y-%m-%d %H:%M',
>> >>                                   optional = 'logical')
>> >> discharge$cfs <- as.numeric(discharge$cfs, length = 6)
>> >>
>> >> I get this result:
>> >> > head(discharge)
>> >>               sampdate    cfs
>> >> 1 2016-03-03 12:00:00 149000
>> >> 2 2016-03-03 12:10:00 150000
>> >> 3 2016-03-03 12:20:00 151000
>> >> 4 2016-03-03 12:30:00 156000
>> >> 5 2016-03-03 12:40:00 154000
>> >> 6 2016-03-03 12:50:00 150000
>> >>
>> >> I'm completely open to suggestions on using this output to calculate
>> >> monthly
>> >> means and sds.
>> >>
>> >> If dplyr:summarize() will do so please show me how to modify this
>> command:
>> >> disc_monthly <- ( discharge
>> >>          %>% group_by(sampdate)
>> >>          %>% summarize(exp_value = mean(cfs, na.rm = TRUE))
>> >> because it produces daily means, not monthly means.
>> >>
>> >> TIA,
>> >>
>> >> Rich
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep  6 00:50:41 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 5 Sep 2021 15:50:41 -0700
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAGxFJbQ+=0j4=7g4LUS2HvnXJw4KFVe0FLzBrGDuDLcURcedqA@mail.gmail.com>
References: <005601d7a1a5$11da6480$358f2d80$.ref@yahoo.com>
 <005601d7a1a5$11da6480$358f2d80$@yahoo.com>
 <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>
 <CAGxFJbQ+=0j4=7g4LUS2HvnXJw4KFVe0FLzBrGDuDLcURcedqA@mail.gmail.com>
Message-ID: <CAGxFJbQPFXdB79EJXTpgEqg0G5JzZwgDnb_fGm8UN+r_Y68mHA@mail.gmail.com>

In case anyone is still interested in my query, note that if there are
n total items to be split into g groups as evenly as possible, if we
define this as at most two different size groups whose size differs by
1, then:

if n = k*g + r, where 0 <= r < g,
then n = k*(g - r) + (k + 1)*r  .
i.e. g-r groups of size k and r groups of size k+1

So using R's modular arithmetic operators, which are handy to know
about, we have:

r = n %% g and k = n %/% g .

(and note that you should disregard my previous stupid remark about
numerical analysis).

Cheers,
Bert


On Sat, Sep 4, 2021 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> I have a more general problem for you.
>
> Given n items and 2 <=g <<n , how do you divide the n items into g
> groups that are as "equal as possible."
>
> First, operationally define "as equal as possible."
> Second, define the algorithm to carry out the definition. Hint: Note
> that sum{m[i]} for i <=g must sum to n, where m[i] is the number of
> items in the ith group.
> Third, write R code for the algorithm. Exercise for the reader.
>
> I may be wrong, but I think numerical analysts might also have a
> little fun here.
>
> Randomization, of course, is trivial.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sat, Sep 4, 2021 at 2:13 PM AbouEl-Makarim Aboueissa
> <abouelmakarim1962 at gmail.com> wrote:
> >
> > Dear Thomas:
> >
> >
> > Thank you very much for your input in this matter.
> >
> >
> > The core part of this R code(s) (please see below) was written by *Richard
> > O'Keefe*. I had three examples with different sample sizes.
> >
> >
> >
> > *First sample of size n1 = 204* divided randomly into three groups of sizes
> > 68. *No problems with this one*.
> >
> >
> >
> > *The second sample of size n2 = 112* divided randomly into three groups of
> > sizes 37, 37, and 38. BUT this R code generated three groups of equal sizes
> > (37, 37, and 37). *How to fix the code to make sure that the output will be
> > three groups of sizes 37, 37, and 38*.
> >
> >
> >
> > *The third sample of size n3 = 284* divided randomly into three groups of
> > sizes 94, 95, and 95. BUT this R code generated three groups of equal sizes
> > (94, 94, and 94). *Again*, h*ow to fix the code to make sure that the
> > output will be three groups of sizes 94, 95, and 95*.
> >
> >
> > With many thanks
> >
> > abou
> >
> >
> > ###########  ------------------------   #############
> >
> >
> > N1 <- 485
> > population1.IDs <- seq(1, N1, by = 1)
> > #### population1.IDs
> >
> > n1<-204                                        ##### in this case the size
> > of each group of the three groups = 68
> > sample1.IDs <- sample(population1.IDs,n1)
> > #### sample1.IDs
> >
> > ####  n1 <- length(sample1.IDs)
> >
> >   m1 <- n1 %/% 3
> >   s1 <- sample(1:n1, n1)
> >   group1.IDs <- sample1.IDs[s1[1:m1]]
> >   group2.IDs <- sample1.IDs[s1[(m1+1):(2*m1)]]
> >   group3.IDs <- sample1.IDs[s1[(m1*2+1):(3*m1)]]
> >
> > groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
> >
> > groups.IDs
> >
> >
> > ####### --------------------------
> >
> >
> > N2 <- 266
> > population2.IDs <- seq(1, N2, by = 1)
> > #### population2.IDs
> >
> > n2<-112                           ##### in this case the sizes of the three
> > groups are(37, 37, and 38)
> >                                           ##### BUT this codes generate
> > three groups of equal sizes (37, 37, and 37)
> > sample2.IDs <- sample(population2.IDs,n2)
> > #### sample2.IDs
> >
> > ####  n2 <- length(sample2.IDs)
> >
> >   m2 <- n2 %/% 3
> >   s2 <- sample(1:n2, n2)
> >   group1.IDs <- sample2.IDs[s2[1:m2]]
> >   group2.IDs <- sample2.IDs[s2[(m2+1):(2*m2)]]
> >   group3.IDs <- sample2.IDs[s2[(m2*2+1):(3*m2)]]
> >
> > groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
> >
> > groups.IDs
> >
> >
> > ####### --------------------------
> >
> >
> >
> > N3 <- 674
> > population3.IDs <- seq(1, N3, by = 1)
> > #### population3.IDs
> >
> > n3<-284                           ##### in this case the sizes of the three
> > groups are(94, 95, and 95)
> >                                           ##### BUT this codes generate
> > three groups of equal sizes (94, 94, and 94)
> > sample2.IDs <- sample(population2.IDs,n2)
> > sample3.IDs <- sample(population3.IDs,n3)
> > #### sample3.IDs
> >
> > ####  n3 <- length(sample2.IDs)
> >
> >   m3 <- n3 %/% 3
> >   s3 <- sample(1:n3, n3)
> >   group1.IDs <- sample3.IDs[s3[1:m3]]
> >   group2.IDs <- sample3.IDs[s3[(m3+1):(2*m3)]]
> >   group3.IDs <- sample3.IDs[s3[(m3*2+1):(3*m3)]]
> >
> > groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
> >
> > groups.IDs
> >
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor, Statistics and Data Science*
> > *Graduate Coordinator*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> >
> >
> >
> > On Sat, Sep 4, 2021 at 11:54 AM Thomas Subia <tgs77m at yahoo.com> wrote:
> >
> > > Abou,
> > >
> > >
> > >
> > > I?ve been following your question on how to split a data column randomly
> > > into 3 groups using R.
> > >
> > >
> > >
> > > My method may not be amenable for a large set of data but it surely worth
> > > considering since it makes sense intuitively.
> > >
> > >
> > >
> > > mydata <- LETTERS[1:11]
> > >
> > > > mydata
> > >
> > > [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K"
> > >
> > >
> > >
> > > # Let?s choose a random sample of size 4 from mydata
> > >
> > > > random_grp1
> > >
> > > [1] "J" "H" "D" "A"
> > >
> > >
> > >
> > > Now my next random selection of data is defined by
> > >
> > > data_wo_random <- setdiff(mydata,random_grp1)
> > >
> > > # this makes sense because I need to choose random data from a set which
> > > is defined by the difference of the sets mydata and random_grp1
> > >
> > >
> > >
> > > > data_wo_random
> > >
> > > [1] "B" "C" "E" "F" "G" "I" "K"
> > >
> > >
> > >
> > > This is great! So now I can randomly select data of any size from this set.
> > >
> > > Repeating this process can easily generate subgroups of your original
> > > dataset of any size you want.
> > >
> > >
> > >
> > > Surely this method could be improved so that this could be done
> > > automatically.
> > >
> > > Nevertheless, this is an intuitive method which I believe is easier to
> > > understand than some of the other methods posted.
> > >
> > >
> > >
> > > Hope this helps!
> > >
> > >
> > >
> > > Thomas Subia
> > >
> > > Statistician
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From g@@@uu| @end|ng |rom gm@||@com  Mon Sep  6 08:37:07 2021
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Mon, 6 Sep 2021 15:37:07 +0900
Subject: [R] field significance test
Message-ID: <CAHXS41xewf=m01MSh9DdYwwyL_iLJupADLJkedQRLwOqMJePPg@mail.gmail.com>

Dear r-list member,

I want to plot a histogram that shows a number of station that have a
significant statistic (positive or negative) based on the value itself
and its p-value. df3 shows the test statistic value (column shows the
station and rows show the result from the resample matrix
(repetition/bootstrap)) and df4 shows the p-value.

#the value
dput(head(df3,10))
structure(c(0.569535339474781, 1.02925697755861, 1.08125714350978,
0.50589479161552, -0.695827095264809, 0.455608022735733, 1.2552019505074,
0.981335144120386, 1.63020923423253, -0.424613279862939, 0.429207234903993,
1.99059339634301, -1.25731480224036, 0.64293796635093, 0.0189774621961392,
0.1163965630274, -1.41756397958877, 1.58945674395921, -1.2551489541395,
-2.84122761058959, -0.72446669544026, -0.719331298629362, -0.164045813998067,
0.444120153507258, -0.0845757313567553, -0.27732982718919, -0.166982066770785,
-0.193859909749249, 0.277426534878283, -0.0430460496295642, -0.0741475736028902,
-0.017026178205196, 0.732589091697401, 0.332813962514037, -0.0860983232517636,
0.155930932436498, -0.438635444604027, 0.046881008364722, -0.704876076807635,
-0.945506782070735, 0.662399207637722, -0.860903464600488, 1.06638547921749,
-0.462184163508299, 0.442447468362937, 0.145655792120232, 0.696309974316211,
1.84692085953474, 0.00841868461519582, -1.04408256815264, -0.548599461573869,
1.22352273108675, 0.0191993545723452, 1.26090162037733, 0.192106046362172,
-1.02864978106213, -0.0712068006002629, -0.674610175422543, -0.658383381010154,
-1.52779151484935, 0.479809528798632, -0.112078644619679, -0.19482661081522,
-0.192179943664117, -0.246553759113406, -0.563554156777087, -1.0236492805268,
0.0289772842372375, -0.274878506644853, 0.95578159001869, -0.27550722692588,
-0.66586322268903, 1.24703690613745, -0.00368775734780707, -0.0766884108214613,
-1.41610325144406, 0.518897523428314, -2.12289477996499, 0.968369305561191,
0.0766656793804207, 0.470712743077857, 0.241711948576043, 0.0636131491007723,
-1.13735866614159, 0.625015831730259, -0.234696421716696, 0.358555918256736,
-0.651761882852838, -0.236796663592383, 0.0421395303375618, 0.574747610964774,
-0.730646230622174, -0.20839489662388, -1.4832025994155, -0.366841536561336,
0.621868015281511, 0.945609952617796, 0.297055307072896, 0.737974050847397,
1.49862070675738), .Dim = c(10L, 10L))

#the p-value
dput(head(df4,10))
structure(c(0.560903574193679, 0.358019718822816, 0.320136568444488,
0.721538652049639, 0.419898899237915, 0.511481779449553, 0.208829636238898,
0.535905791761543, 0.252523383923989, 0.721538652049639, 0.487651926831611,
0.0281856103410957, 0.138370395238992, 0.639104270712721, 0.98503410973661,
0.955123383216192, 0.358019718822816, 0.138370395238992, 0.252523383923989,
0.0373292396736942, 0.302215769747998, 0.302215769747998, 0.807343273858921,
0.560903574193679, 0.955123383216192, 0.836526366120417, 0.807343273858921,
0.807343273858921, 0.693640621783759, 0.895532903167044, 0.895532903167044,
0.98503410973661, 0.159470497055087, 0.560903574193679, 0.925275729900227,
0.865936215436343, 0.441845502530452, 0.98503410973661, 0.358019718822816,
0.170893484254114, 0.586452625432322, 0.268412562734209, 0.102689728987727,
0.511481779449553, 0.666151798537229, 0.925275729900227, 0.358019718822816,
0.0581501553999165, 0.98503410973661, 0.170893484254114, 0.586452625432322,
0.464434476654839, 0.98503410973661, 0.252523383923989, 0.925275729900227,
0.377977518007105, 0.98503410973661, 0.586452625432322,
0.666151798537229, 0.284975267823252, 0.560903574193679,
0.721538652049639, 0.778425914188847,
0.836526366120417, 0.778425914188847, 0.511481779449553, 0.087825095630195,
0.98503410973661, 0.693640621783759, 0.208829636238898, 0.807343273858921,
0.222740206090239, 0.222740206090239, 0.98503410973661, 0.925275729900227,
0.0373292396736942, 0.586452625432322, 0.00322938266821475, 0.222740206090239,
0.865936215436343, 0.338738311334395, 0.639104270712721, 0.895532903167044,
0.0533495868962313, 0.268412562734209, 0.721538652049639, 0.721538652049639,
0.195559652706897, 0.778425914188847, 0.880692897134707, 0.398606385377039,
0.398606385377039, 0.693640621783759, 0.102689728987727, 0.666151798537229,
0.252523383923989, 0.358019718822816, 0.778425914188847, 0.284975267823252,
0.0633043080023749), .Dim = c(10L, 10L))

#find the positive significant station
df5<-df3
df5[df4>0.05|df5<0]<-NA
df5[df5>0]<-1
pos<-as.numeric(rowSums(df5, na.rm=T))
hist(pos)

#find the negative significant station
df6<-df3
df6[df4>0.05|df5>0]<-NA
df6[df6<0]<-1
neg<-as.numeric(rowSums(df6, na.rm=T))
hist(neg)

but above code is not correct because the 0 station (row when there is
no significant station detected) should be the same. The problem is
when the row produces significant positive and negative at the same
time. Is there any way to combine positive and negative significant
value and plot the histogram? or we can calculate the 0 station first
separately?

Any lead is really appreciated. Thank you.

Ani Jaya


From c@|@ndr@ @end|ng |rom rgzm@de  Mon Sep  6 08:52:07 2021
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 6 Sep 2021 08:52:07 +0200
Subject: [R] combining geom_boxplot and geom_point with jitter
In-Reply-To: <de5962ba-7d8c-9dbe-c0bf-898fa245380f@sapo.pt>
References: <29e2f7e6-b2a7-9b4f-83d3-44bc197f0cac@rgzm.de>
 <de5962ba-7d8c-9dbe-c0bf-898fa245380f@sapo.pt>
Message-ID: <a0a547ec-92ae-d75d-7a16-471fc333fcb3@rgzm.de>

Thank you very much Rui!

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 04/09/2021 18:22, Rui Barradas wrote:
> Hello,
>
> The problem is that you have two grouping aesthetics, color and shape.
> In geom_point make the group explicit:
>
>
> p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
> p <- p + geom_boxplot(outlier.shape = NA)
>
> p + geom_point(
> ? mapping = aes(shape = NMP_cat, group = Software),
> ? position = position_jitterdodge()
> )
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 09:54 de 02/09/21, Ivan Calandra escreveu:
>> Dear useRs,
>>
>> I'm having a problem to combine geom_boxplot and geom_point with 
>> jitter. It is difficult to explain but the code and result should 
>> make it clear (the example dataset is long so I copy it at the end of 
>> the email):
>>
>> p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
>> p <- p + geom_boxplot(outlier.shape = NA)
>> p <- p + geom_point(mapping = aes(shape = NMP_cat), position = 
>> position_jitterdodge())
>> print(p)
>>
>> As you can see in the resulting plot, the points with different 
>> shapes are dodged across the boxplot categories (colors). I'd like 
>> the three shapes per color to be restricted in one boxplot color, 
>> with jitter of course to better visualize the points.
>>
>> Does that make sense?
>>
>> I have played with the arguments of position_jitterdodge(), but it 
>> seems to me that the problem is that the shape aesthetic is not in 
>> the geom_boxplot() call (but I don't want it there, see below).
>>
>> For background information, the column used for shape gives some sort 
>> of "quality" to the points; that's why I want to show the points 
>> differently, so that it can easily be seen whether "good" points plot 
>> in the same area as the "bad" points.
>> Because I'm doing facet plots with other variables, I do not want to 
>> separate these categories in the boxplots - the resulting plots would 
>> be overcrowded.
>>
>> Thank you for the help.
>> Ivan
>>
>> ---
>>
>> my_data <- structure(list(Diet = c("Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne",
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
>> "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo",
>> "Dry bamboo", "Dry bamboo"), Software = c("ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax"), NMP_cat = structure(c(1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 
>> 2L, 2L, 2L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
>> 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 
>> 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 
>> 2L, 2L), .Label = c("0-5%", "5-10%", "10-20%", "20-100%"), class = 
>> c("ordered", "factor")), name = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = 
>> c("Asfc", "Smfc", "HAsfc9", "HAsfc81", "epLsar", "NewEplsar"), class 
>> = "factor"), value = c(16.00716636, 12.925787, 14.05932485, 
>> 11.999816, 15.12321532, 12.711474, 12.79565826, 10.900949, 
>> 15.90481161, 12.836045, 16.22778102, 13.565995, 14.71354945, 
>> 12.384152, 16.61354777, 13.714165, 15.91399496, 12.983796, 
>> 19.44739619, 15.173215, 16.13761798, 12.932798, 14.7332952, 12.10277, 
>> 10.78710961, 8.762726, 10.16027362, 8.040399, 14.53444662, 11.527896, 
>> 17.38120685, 13.78922, 11.26840546, 9.426558, 24.01797992, 18.398553, 
>> 13.7435699, 11.44385, 14.391873, 10.757141, 22.39390393, 18.176262, 
>> 11.60322022, 9.969118, 11.6099975, 10.059618, 11.86282935, 10.280864, 
>> 16.22473644, 13.562839, 12.46350165, 10.629406, 23.9347534, 
>> 19.062174, 19.58121507, 15.910959, 13.99145447, 11.352648, 
>> 14.38942328, 11.821431, 23.4733371, 18.549503, 13.08142223, 
>> 10.735494, 17.09293046, 13.012834, 28.80020878, 22.447105, 
>> 25.74460885, 19.76834, 14.29106582, 12.233774, 12.03005024, 
>> 10.364224, 12.58953574, 10.30257, 18.07111578, 14.416143, 
>> 20.85562751, 16.524047, 21.06132234, 15.744758, 15.24052683, 
>> 11.891487, 11.62446752, 9.14325, 11.75704705, 10.358542, 13.65568703, 
>> 11.766129, 16.98137759, 12.594787, 11.6560954, 10.32073, 15.46708251, 
>> 13.199232, 13.20110131, 11.060226, 16.13986173, 13.564802, 
>> 25.45656859, 20.071231, 24.84006178, 19.335892, 14.4723856, 
>> 11.994841, 12.07940958, 9.470493, 13.93630412, 11.489685, 
>> 21.84464295, 17.806018, 17.4383111, 14.478338, 20.55074297, 
>> 16.254467, 30.15238714, 24.193768, 32.8541897, 25.769585, 
>> 32.06966759, 24.507185, 20.53975772, 15.951186, 11.54494952, 
>> 9.676342, 13.56490524, 11.456356, 13.58242208, 10.919419, 
>> 13.55260161, 11.356056, 38.58113502, 31.087536, 23.6753536, 
>> 18.749955, 26.38707155, 20.877856, 26.18252748, 20.758242)), 
>> row.names = c(NA, -140L), class = c("tbl_df", "tbl", "data.frame"))
>>
>


From drj|m|emon @end|ng |rom gm@||@com  Mon Sep  6 10:41:43 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 6 Sep 2021 18:41:43 +1000
Subject: [R] field significance test
In-Reply-To: <CAHXS41xewf=m01MSh9DdYwwyL_iLJupADLJkedQRLwOqMJePPg@mail.gmail.com>
References: <CAHXS41xewf=m01MSh9DdYwwyL_iLJupADLJkedQRLwOqMJePPg@mail.gmail.com>
Message-ID: <CA+8X3fVbxs=GAAsGKnM6RAAArJ9OL3vap4q-ZPZEUb9=58EDJA@mail.gmail.com>

HI Ani,
I would create these two matrices:

# matrix of logicals for positive stat values
posvalue<-df3 > 0
# matrix of logicals for significance
sigstat<-df4 < 0.05

Then you can identify the positive/negative and significant values:

which(posvalue & sigstat)
[1] 12
which(!posvalue & sigstat)
[1] 20 76 78

and as you note, column 2 has 2 significant results, one statistical
value positive and the other negative.
I'm not sure what sort of histogram you want, perhaps all ten columns
with groups of ten bars for each column (very messy and sparse). Maybe
a bit more info will enlighten me.

Jim

On Mon, Sep 6, 2021 at 4:37 PM ani jaya <gaaauul at gmail.com> wrote:
>
> Dear r-list member,
>
> I want to plot a histogram that shows a number of station that have a
> significant statistic (positive or negative) based on the value itself
> and its p-value. df3 shows the test statistic value (column shows the
> station and rows show the result from the resample matrix
> (repetition/bootstrap)) and df4 shows the p-value.
>
> #the value
> dput(head(df3,10))
> structure(c(0.569535339474781, 1.02925697755861, 1.08125714350978,
> 0.50589479161552, -0.695827095264809, 0.455608022735733, 1.2552019505074,
> 0.981335144120386, 1.63020923423253, -0.424613279862939, 0.429207234903993,
> 1.99059339634301, -1.25731480224036, 0.64293796635093, 0.0189774621961392,
> 0.1163965630274, -1.41756397958877, 1.58945674395921, -1.2551489541395,
> -2.84122761058959, -0.72446669544026, -0.719331298629362, -0.164045813998067,
> 0.444120153507258, -0.0845757313567553, -0.27732982718919, -0.166982066770785,
> -0.193859909749249, 0.277426534878283, -0.0430460496295642, -0.0741475736028902,
> -0.017026178205196, 0.732589091697401, 0.332813962514037, -0.0860983232517636,
> 0.155930932436498, -0.438635444604027, 0.046881008364722, -0.704876076807635,
> -0.945506782070735, 0.662399207637722, -0.860903464600488, 1.06638547921749,
> -0.462184163508299, 0.442447468362937, 0.145655792120232, 0.696309974316211,
> 1.84692085953474, 0.00841868461519582, -1.04408256815264, -0.548599461573869,
> 1.22352273108675, 0.0191993545723452, 1.26090162037733, 0.192106046362172,
> -1.02864978106213, -0.0712068006002629, -0.674610175422543, -0.658383381010154,
> -1.52779151484935, 0.479809528798632, -0.112078644619679, -0.19482661081522,
> -0.192179943664117, -0.246553759113406, -0.563554156777087, -1.0236492805268,
> 0.0289772842372375, -0.274878506644853, 0.95578159001869, -0.27550722692588,
> -0.66586322268903, 1.24703690613745, -0.00368775734780707, -0.0766884108214613,
> -1.41610325144406, 0.518897523428314, -2.12289477996499, 0.968369305561191,
> 0.0766656793804207, 0.470712743077857, 0.241711948576043, 0.0636131491007723,
> -1.13735866614159, 0.625015831730259, -0.234696421716696, 0.358555918256736,
> -0.651761882852838, -0.236796663592383, 0.0421395303375618, 0.574747610964774,
> -0.730646230622174, -0.20839489662388, -1.4832025994155, -0.366841536561336,
> 0.621868015281511, 0.945609952617796, 0.297055307072896, 0.737974050847397,
> 1.49862070675738), .Dim = c(10L, 10L))
>
> #the p-value
> dput(head(df4,10))
> structure(c(0.560903574193679, 0.358019718822816, 0.320136568444488,
> 0.721538652049639, 0.419898899237915, 0.511481779449553, 0.208829636238898,
> 0.535905791761543, 0.252523383923989, 0.721538652049639, 0.487651926831611,
> 0.0281856103410957, 0.138370395238992, 0.639104270712721, 0.98503410973661,
> 0.955123383216192, 0.358019718822816, 0.138370395238992, 0.252523383923989,
> 0.0373292396736942, 0.302215769747998, 0.302215769747998, 0.807343273858921,
> 0.560903574193679, 0.955123383216192, 0.836526366120417, 0.807343273858921,
> 0.807343273858921, 0.693640621783759, 0.895532903167044, 0.895532903167044,
> 0.98503410973661, 0.159470497055087, 0.560903574193679, 0.925275729900227,
> 0.865936215436343, 0.441845502530452, 0.98503410973661, 0.358019718822816,
> 0.170893484254114, 0.586452625432322, 0.268412562734209, 0.102689728987727,
> 0.511481779449553, 0.666151798537229, 0.925275729900227, 0.358019718822816,
> 0.0581501553999165, 0.98503410973661, 0.170893484254114, 0.586452625432322,
> 0.464434476654839, 0.98503410973661, 0.252523383923989, 0.925275729900227,
> 0.377977518007105, 0.98503410973661, 0.586452625432322,
> 0.666151798537229, 0.284975267823252, 0.560903574193679,
> 0.721538652049639, 0.778425914188847,
> 0.836526366120417, 0.778425914188847, 0.511481779449553, 0.087825095630195,
> 0.98503410973661, 0.693640621783759, 0.208829636238898, 0.807343273858921,
> 0.222740206090239, 0.222740206090239, 0.98503410973661, 0.925275729900227,
> 0.0373292396736942, 0.586452625432322, 0.00322938266821475, 0.222740206090239,
> 0.865936215436343, 0.338738311334395, 0.639104270712721, 0.895532903167044,
> 0.0533495868962313, 0.268412562734209, 0.721538652049639, 0.721538652049639,
> 0.195559652706897, 0.778425914188847, 0.880692897134707, 0.398606385377039,
> 0.398606385377039, 0.693640621783759, 0.102689728987727, 0.666151798537229,
> 0.252523383923989, 0.358019718822816, 0.778425914188847, 0.284975267823252,
> 0.0633043080023749), .Dim = c(10L, 10L))
>
> #find the positive significant station
> df5<-df3
> df5[df4>0.05|df5<0]<-NA
> df5[df5>0]<-1
> pos<-as.numeric(rowSums(df5, na.rm=T))
> hist(pos)
>
> #find the negative significant station
> df6<-df3
> df6[df4>0.05|df5>0]<-NA
> df6[df6<0]<-1
> neg<-as.numeric(rowSums(df6, na.rm=T))
> hist(neg)
>
> but above code is not correct because the 0 station (row when there is
> no significant station detected) should be the same. The problem is
> when the row produces significant positive and negative at the same
> time. Is there any way to combine positive and negative significant
> value and plot the histogram? or we can calculate the 0 station first
> separately?
>
> Any lead is really appreciated. Thank you.
>
> Ani Jaya
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Mon Sep  6 12:16:08 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Mon, 6 Sep 2021 06:16:08 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAGxFJbQPFXdB79EJXTpgEqg0G5JzZwgDnb_fGm8UN+r_Y68mHA@mail.gmail.com>
References: <005601d7a1a5$11da6480$358f2d80$.ref@yahoo.com>
 <005601d7a1a5$11da6480$358f2d80$@yahoo.com>
 <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>
 <CAGxFJbQ+=0j4=7g4LUS2HvnXJw4KFVe0FLzBrGDuDLcURcedqA@mail.gmail.com>
 <CAGxFJbQPFXdB79EJXTpgEqg0G5JzZwgDnb_fGm8UN+r_Y68mHA@mail.gmail.com>
Message-ID: <CAE9stmcGBVvoMGWuo2pUq6M3OFjsz-VRm57K9eNLf7VRZO7ObQ@mail.gmail.com>

Hi Bert and All: good morning

I promise this would be the last time to write about this topic.

I come up with this R function (please see below), for sure with your help.
It works for all sample sizes. I also provided three different simple
examples.

with many thanks
abou

##################    Here it is    ###############

Random.Sample.IDs <- function (N,n, ngroups){    #### N = population size,
and n = sample size, ngroups = number of groups

population.IDs <- seq(1, N, by = 1)
sample.IDs <- sample(population.IDs,n)

##### to print sample.IDs in a column format
##### --------------------------------------------------
sample.IDs.in.column<-data.frame(sample.IDs)
print(sample.IDs.in.column)

reminder.n<-n%%ngroups
reminder.n

n.final<-n-reminder.n
n.final

  m <- n %/% 3
  m
  s <- sample(1:n, n)

if (reminder.n == 0) {

  group1.IDs <- sample.IDs[s[1:m]]
  group2.IDs <- sample.IDs[s[(m+1):(2*m)]]
  group3.IDs <- sample.IDs[s[(m*2+1):(3*m)]]

} else if(reminder.n == 1){

  group1.IDs <- sample.IDs[s[1:(m+1)]]
  group2.IDs <- sample.IDs[s[(m+2):(2*m+1)]]
  group3.IDs <- sample.IDs[s[(m*2+2):(3*m+1)]]

} else if(reminder.n == 2){

  group1.IDs <- sample.IDs[s[1:(m+1)]]
  group2.IDs <- sample.IDs[s[(m+2):(2*m+2)]]
  group3.IDs <- sample.IDs[s[(m*2+3):(3*m+2)]]
}
nn<-max(length(group1.IDs),length(group2.IDs),length(group3.IDs))
nn
length(group1.IDs) <- nn
length(group2.IDs) <- nn
length(group3.IDs) <- nn

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs

}


#####  Examples
#####  --------

Random.Sample.IDs (100,12,3)    #### group sizes are equal (n1=n2=n3=4)

Random.Sample.IDs (100,13,3)    #### group sizes are NOT equal (n1=5, n2=4,
n3=4)

Random.Sample.IDs (100,17,3)    #### group sizes are NOT equal (n1=6, n2=6,
n3=5)


______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Sun, Sep 5, 2021 at 6:50 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> In case anyone is still interested in my query, note that if there are
> n total items to be split into g groups as evenly as possible, if we
> define this as at most two different size groups whose size differs by
> 1, then:
>
> if n = k*g + r, where 0 <= r < g,
> then n = k*(g - r) + (k + 1)*r  .
> i.e. g-r groups of size k and r groups of size k+1
>
> So using R's modular arithmetic operators, which are handy to know
> about, we have:
>
> r = n %% g and k = n %/% g .
>
> (and note that you should disregard my previous stupid remark about
> numerical analysis).
>
> Cheers,
> Bert
>
>
> On Sat, Sep 4, 2021 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > I have a more general problem for you.
> >
> > Given n items and 2 <=g <<n , how do you divide the n items into g
> > groups that are as "equal as possible."
> >
> > First, operationally define "as equal as possible."
> > Second, define the algorithm to carry out the definition. Hint: Note
> > that sum{m[i]} for i <=g must sum to n, where m[i] is the number of
> > items in the ith group.
> > Third, write R code for the algorithm. Exercise for the reader.
> >
> > I may be wrong, but I think numerical analysts might also have a
> > little fun here.
> >
> > Randomization, of course, is trivial.
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Sat, Sep 4, 2021 at 2:13 PM AbouEl-Makarim Aboueissa
> > <abouelmakarim1962 at gmail.com> wrote:
> > >
> > > Dear Thomas:
> > >
> > >
> > > Thank you very much for your input in this matter.
> > >
> > >
> > > The core part of this R code(s) (please see below) was written by
> *Richard
> > > O'Keefe*. I had three examples with different sample sizes.
> > >
> > >
> > >
> > > *First sample of size n1 = 204* divided randomly into three groups of
> sizes
> > > 68. *No problems with this one*.
> > >
> > >
> > >
> > > *The second sample of size n2 = 112* divided randomly into three
> groups of
> > > sizes 37, 37, and 38. BUT this R code generated three groups of equal
> sizes
> > > (37, 37, and 37). *How to fix the code to make sure that the output
> will be
> > > three groups of sizes 37, 37, and 38*.
> > >
> > >
> > >
> > > *The third sample of size n3 = 284* divided randomly into three groups
> of
> > > sizes 94, 95, and 95. BUT this R code generated three groups of equal
> sizes
> > > (94, 94, and 94). *Again*, h*ow to fix the code to make sure that the
> > > output will be three groups of sizes 94, 95, and 95*.
> > >
> > >
> > > With many thanks
> > >
> > > abou
> > >
> > >
> > > ###########  ------------------------   #############
> > >
> > >
> > > N1 <- 485
> > > population1.IDs <- seq(1, N1, by = 1)
> > > #### population1.IDs
> > >
> > > n1<-204                                        ##### in this case the
> size
> > > of each group of the three groups = 68
> > > sample1.IDs <- sample(population1.IDs,n1)
> > > #### sample1.IDs
> > >
> > > ####  n1 <- length(sample1.IDs)
> > >
> > >   m1 <- n1 %/% 3
> > >   s1 <- sample(1:n1, n1)
> > >   group1.IDs <- sample1.IDs[s1[1:m1]]
> > >   group2.IDs <- sample1.IDs[s1[(m1+1):(2*m1)]]
> > >   group3.IDs <- sample1.IDs[s1[(m1*2+1):(3*m1)]]
> > >
> > > groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
> > >
> > > groups.IDs
> > >
> > >
> > > ####### --------------------------
> > >
> > >
> > > N2 <- 266
> > > population2.IDs <- seq(1, N2, by = 1)
> > > #### population2.IDs
> > >
> > > n2<-112                           ##### in this case the sizes of the
> three
> > > groups are(37, 37, and 38)
> > >                                           ##### BUT this codes generate
> > > three groups of equal sizes (37, 37, and 37)
> > > sample2.IDs <- sample(population2.IDs,n2)
> > > #### sample2.IDs
> > >
> > > ####  n2 <- length(sample2.IDs)
> > >
> > >   m2 <- n2 %/% 3
> > >   s2 <- sample(1:n2, n2)
> > >   group1.IDs <- sample2.IDs[s2[1:m2]]
> > >   group2.IDs <- sample2.IDs[s2[(m2+1):(2*m2)]]
> > >   group3.IDs <- sample2.IDs[s2[(m2*2+1):(3*m2)]]
> > >
> > > groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
> > >
> > > groups.IDs
> > >
> > >
> > > ####### --------------------------
> > >
> > >
> > >
> > > N3 <- 674
> > > population3.IDs <- seq(1, N3, by = 1)
> > > #### population3.IDs
> > >
> > > n3<-284                           ##### in this case the sizes of the
> three
> > > groups are(94, 95, and 95)
> > >                                           ##### BUT this codes generate
> > > three groups of equal sizes (94, 94, and 94)
> > > sample2.IDs <- sample(population2.IDs,n2)
> > > sample3.IDs <- sample(population3.IDs,n3)
> > > #### sample3.IDs
> > >
> > > ####  n3 <- length(sample2.IDs)
> > >
> > >   m3 <- n3 %/% 3
> > >   s3 <- sample(1:n3, n3)
> > >   group1.IDs <- sample3.IDs[s3[1:m3]]
> > >   group2.IDs <- sample3.IDs[s3[(m3+1):(2*m3)]]
> > >   group3.IDs <- sample3.IDs[s3[(m3*2+1):(3*m3)]]
> > >
> > > groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
> > >
> > > groups.IDs
> > >
> > > ______________________
> > >
> > >
> > > *AbouEl-Makarim Aboueissa, PhD*
> > >
> > > *Professor, Statistics and Data Science*
> > > *Graduate Coordinator*
> > >
> > > *Department of Mathematics and Statistics*
> > > *University of Southern Maine*
> > >
> > >
> > >
> > > On Sat, Sep 4, 2021 at 11:54 AM Thomas Subia <tgs77m at yahoo.com> wrote:
> > >
> > > > Abou,
> > > >
> > > >
> > > >
> > > > I?ve been following your question on how to split a data column
> randomly
> > > > into 3 groups using R.
> > > >
> > > >
> > > >
> > > > My method may not be amenable for a large set of data but it surely
> worth
> > > > considering since it makes sense intuitively.
> > > >
> > > >
> > > >
> > > > mydata <- LETTERS[1:11]
> > > >
> > > > > mydata
> > > >
> > > > [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K"
> > > >
> > > >
> > > >
> > > > # Let?s choose a random sample of size 4 from mydata
> > > >
> > > > > random_grp1
> > > >
> > > > [1] "J" "H" "D" "A"
> > > >
> > > >
> > > >
> > > > Now my next random selection of data is defined by
> > > >
> > > > data_wo_random <- setdiff(mydata,random_grp1)
> > > >
> > > > # this makes sense because I need to choose random data from a set
> which
> > > > is defined by the difference of the sets mydata and random_grp1
> > > >
> > > >
> > > >
> > > > > data_wo_random
> > > >
> > > > [1] "B" "C" "E" "F" "G" "I" "K"
> > > >
> > > >
> > > >
> > > > This is great! So now I can randomly select data of any size from
> this set.
> > > >
> > > > Repeating this process can easily generate subgroups of your original
> > > > dataset of any size you want.
> > > >
> > > >
> > > >
> > > > Surely this method could be improved so that this could be done
> > > > automatically.
> > > >
> > > > Nevertheless, this is an intuitive method which I believe is easier
> to
> > > > understand than some of the other methods posted.
> > > >
> > > >
> > > >
> > > > Hope this helps!
> > > >
> > > >
> > > >
> > > > Thomas Subia
> > > >
> > > > Statistician
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Mon Sep  6 16:03:46 2021
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 6 Sep 2021 16:03:46 +0200
Subject: [R] ggsave() with width only
Message-ID: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>

Dear useRs,

I produce several independent ggplot2 plots and I would like to save 
them to a fixed width (for publications), but the height (and therefore 
aspect ratio) is different from plot to plot.

How can I save my plots with ggsave() supplying only a fixed width but 
without knowing the height nor the aspect ratio? If I specify the width 
only, the plots are truncated in width because the aspect ratio is not 
correct.

Thank you for the tip!
Ivan

-- 

Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Sep  6 16:24:35 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 06 Sep 2021 07:24:35 -0700
Subject: [R] ggsave() with width only
In-Reply-To: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
Message-ID: <CC6FE349-3CA9-48A7-9532-F15C2EE1F692@dcn.davis.ca.us>

I use an rmarkdown file to generate consistent output figures and tables for html or Word. I just use Rnw files directly if I am generating LaTeX. I do not use R files for building output... and I never use ggsave. So you might consider altering your approach to bypass the question entirely.

On September 6, 2021 7:03:46 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>Dear useRs,
>
>I produce several independent ggplot2 plots and I would like to save 
>them to a fixed width (for publications), but the height (and therefore 
>aspect ratio) is different from plot to plot.
>
>How can I save my plots with ggsave() supplying only a fixed width but 
>without knowing the height nor the aspect ratio? If I specify the width 
>only, the plots are truncated in width because the aspect ratio is not 
>correct.
>
>Thank you for the tip!
>Ivan
>

-- 
Sent from my phone. Please excuse my brevity.


From c@|@ndr@ @end|ng |rom rgzm@de  Mon Sep  6 16:29:34 2021
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 6 Sep 2021 16:29:34 +0200
Subject: [R] ggsave() with width only
In-Reply-To: <CC6FE349-3CA9-48A7-9532-F15C2EE1F692@dcn.davis.ca.us>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
 <CC6FE349-3CA9-48A7-9532-F15C2EE1F692@dcn.davis.ca.us>
Message-ID: <5a218981-c1f2-ea50-d6b1-ba5b8d0a827e@rgzm.de>

Thank you Jeff for your answer.

I do use rmarkdown but I do not write papers completely with it. I do 
output a report in HTML but I also like to export the plots as PDF so 
that I can edit them (using Inkscape or similar) if and as needed.
And because I like to have both the HTML report including plots and 
extra plots as PDF, I cannot use pdf(). That's why I use ggsave().

Or am I missing something?

Ivan

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 06/09/2021 16:24, Jeff Newmiller wrote:
> I use an rmarkdown file to generate consistent output figures and tables for html or Word. I just use Rnw files directly if I am generating LaTeX. I do not use R files for building output... and I never use ggsave. So you might consider altering your approach to bypass the question entirely.
>
> On September 6, 2021 7:03:46 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>> Dear useRs,
>>
>> I produce several independent ggplot2 plots and I would like to save
>> them to a fixed width (for publications), but the height (and therefore
>> aspect ratio) is different from plot to plot.
>>
>> How can I save my plots with ggsave() supplying only a fixed width but
>> without knowing the height nor the aspect ratio? If I specify the width
>> only, the plots are truncated in width because the aspect ratio is not
>> correct.
>>
>> Thank you for the tip!
>> Ivan
>>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Sep  6 16:44:25 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 06 Sep 2021 07:44:25 -0700
Subject: [R] ggsave() with width only
In-Reply-To: <5a218981-c1f2-ea50-d6b1-ba5b8d0a827e@rgzm.de>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
 <CC6FE349-3CA9-48A7-9532-F15C2EE1F692@dcn.davis.ca.us>
 <5a218981-c1f2-ea50-d6b1-ba5b8d0a827e@rgzm.de>
Message-ID: <1F817A73-D4A1-4B0B-8625-F8E7975B7169@dcn.davis.ca.us>

I don't always use rmarkdown to write papers either, but you can capture figures from it. I avoid hand editing figures like the plague of irreproducibility. But sometimes you get stuck in an approach... I cannot answer your original post, but wanted to point out that it may not actually be necessary to answer it if you change your approach.

On September 6, 2021 7:29:34 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>Thank you Jeff for your answer.
>
>I do use rmarkdown but I do not write papers completely with it. I do 
>output a report in HTML but I also like to export the plots as PDF so 
>that I can edit them (using Inkscape or similar) if and as needed.
>And because I like to have both the HTML report including plots and 
>extra plots as PDF, I cannot use pdf(). That's why I use ggsave().
>
>Or am I missing something?
>
>Ivan
>
>--
>Dr. Ivan Calandra
>Imaging lab
>RGZM - MONREPOS Archaeological Research Centre
>Schloss Monrepos
>56567 Neuwied, Germany
>+49 (0) 2631 9772-243
>https://www.researchgate.net/profile/Ivan_Calandra
>
>On 06/09/2021 16:24, Jeff Newmiller wrote:
>> I use an rmarkdown file to generate consistent output figures and tables for html or Word. I just use Rnw files directly if I am generating LaTeX. I do not use R files for building output... and I never use ggsave. So you might consider altering your approach to bypass the question entirely.
>>
>> On September 6, 2021 7:03:46 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>>> Dear useRs,
>>>
>>> I produce several independent ggplot2 plots and I would like to save
>>> them to a fixed width (for publications), but the height (and therefore
>>> aspect ratio) is different from plot to plot.
>>>
>>> How can I save my plots with ggsave() supplying only a fixed width but
>>> without knowing the height nor the aspect ratio? If I specify the width
>>> only, the plots are truncated in width because the aspect ratio is not
>>> correct.
>>>
>>> Thank you for the tip!
>>> Ivan
>>>

-- 
Sent from my phone. Please excuse my brevity.


From c@|@ndr@ @end|ng |rom rgzm@de  Mon Sep  6 17:06:15 2021
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 6 Sep 2021 17:06:15 +0200
Subject: [R] ggsave() with width only
In-Reply-To: <1F817A73-D4A1-4B0B-8625-F8E7975B7169@dcn.davis.ca.us>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
 <CC6FE349-3CA9-48A7-9532-F15C2EE1F692@dcn.davis.ca.us>
 <5a218981-c1f2-ea50-d6b1-ba5b8d0a827e@rgzm.de>
 <1F817A73-D4A1-4B0B-8625-F8E7975B7169@dcn.davis.ca.us>
Message-ID: <1388dab2-31c9-ebe3-f496-385ee9d0d49d@rgzm.de>

Yes Jeff, you are right. I hate manually editing figures too, but 
sometimes I find it's still the easiest way (e.g. when you submit your 
paper several times when journals have differing guidelines, or when you 
build figures from several (sub)plots + other images, or when you 
combine plots that a colleague has done in Python with your R plots). I 
have the impression that at some point, there is always something to 
edit by hand, no matter how much you've adjusted the graphical 
parameters and even if you use all possible tools available for ggplot2...

I have thought a lot about it and, as it is, I am not sure it would be 
worth the effort. I might be missing some arguments for it, but I would 
actually like someone to show me how it could look like - this might 
just be what I need to be convinced!

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 06/09/2021 16:44, Jeff Newmiller wrote:
> I don't always use rmarkdown to write papers either, but you can capture figures from it. I avoid hand editing figures like the plague of irreproducibility. But sometimes you get stuck in an approach... I cannot answer your original post, but wanted to point out that it may not actually be necessary to answer it if you change your approach.
>
> On September 6, 2021 7:29:34 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>> Thank you Jeff for your answer.
>>
>> I do use rmarkdown but I do not write papers completely with it. I do
>> output a report in HTML but I also like to export the plots as PDF so
>> that I can edit them (using Inkscape or similar) if and as needed.
>> And because I like to have both the HTML report including plots and
>> extra plots as PDF, I cannot use pdf(). That's why I use ggsave().
>>
>> Or am I missing something?
>>
>> Ivan
>>
>> --
>> Dr. Ivan Calandra
>> Imaging lab
>> RGZM - MONREPOS Archaeological Research Centre
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> On 06/09/2021 16:24, Jeff Newmiller wrote:
>>> I use an rmarkdown file to generate consistent output figures and tables for html or Word. I just use Rnw files directly if I am generating LaTeX. I do not use R files for building output... and I never use ggsave. So you might consider altering your approach to bypass the question entirely.
>>>
>>> On September 6, 2021 7:03:46 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>>>> Dear useRs,
>>>>
>>>> I produce several independent ggplot2 plots and I would like to save
>>>> them to a fixed width (for publications), but the height (and therefore
>>>> aspect ratio) is different from plot to plot.
>>>>
>>>> How can I save my plots with ggsave() supplying only a fixed width but
>>>> without knowing the height nor the aspect ratio? If I specify the width
>>>> only, the plots are truncated in width because the aspect ratio is not
>>>> correct.
>>>>
>>>> Thank you for the tip!
>>>> Ivan
>>>>


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep  6 17:53:23 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 6 Sep 2021 11:53:23 -0400
Subject: [R] ggsave() with width only
In-Reply-To: <1388dab2-31c9-ebe3-f496-385ee9d0d49d@rgzm.de>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
 <CC6FE349-3CA9-48A7-9532-F15C2EE1F692@dcn.davis.ca.us>
 <5a218981-c1f2-ea50-d6b1-ba5b8d0a827e@rgzm.de>
 <1F817A73-D4A1-4B0B-8625-F8E7975B7169@dcn.davis.ca.us>
 <1388dab2-31c9-ebe3-f496-385ee9d0d49d@rgzm.de>
Message-ID: <7b49ca23-3661-a341-86c0-d265f75a4fff@gmail.com>

On 06/09/2021 11:06 a.m., Ivan Calandra wrote:
> Yes Jeff, you are right. I hate manually editing figures too, but
> sometimes I find it's still the easiest way (e.g. when you submit your
> paper several times when journals have differing guidelines, or when you
> build figures from several (sub)plots + other images, or when you
> combine plots that a colleague has done in Python with your R plots). I
> have the impression that at some point, there is always something to
> edit by hand, no matter how much you've adjusted the graphical
> parameters and even if you use all possible tools available for ggplot2...
> 
> I have thought a lot about it and, as it is, I am not sure it would be
> worth the effort. I might be missing some arguments for it, but I would
> actually like someone to show me how it could look like - this might
> just be what I need to be convinced!

It's not much effort.  For example, the document below produces two PDF 
figures with different heights but the same width.    I called the 
document Untitled.Rmd, so the figures show up in 
Untitled_figures/figure-latex/fig1-1.pdf and 
Untitled_figures/figure-latex/fig2-1.pdf.

   ---
   title: "Untitled"
   author: "Duncan Murdoch"
   date: "06/09/2021"
   output:
     pdf_document:
       keep_tex: true
   ---

   ```{r setup, include=FALSE}
   knitr::opts_chunk$set(echo = TRUE)
   ```

   ```{r fig1, fig.width=2, echo=FALSE}
   library(ggplot2)
   ggplot(mtcars, aes(carb, gear)) +
     geom_point()
   ```

   ```{r fig2, fig.width=2, echo=FALSE}
   ggplot(mtcars, aes(carb, gear)) +
     geom_point() +
     coord_fixed()
   ```


From John@Tu||y @end|ng |rom nott|ngh@m@@c@uk  Mon Sep  6 16:16:10 2021
From: John@Tu||y @end|ng |rom nott|ngh@m@@c@uk (John Tully)
Date: Mon, 6 Sep 2021 14:16:10 +0000
Subject: [R] 'Double to logical' error
Message-ID: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>

Dear colleagues
>
> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>
> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the error occurred.
>
> This follows the commands
>
> for (region in regions){
>    for (study in unique(df$studyid)){
>      single_study_df <- df %>% filter(studyid==study)
>      if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l', region)])){
>        df <- calc_bilat(study, region, r, df)
>      }
>    }
> }
>
>
> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>
> I would greatly value your input on this matter
>
> Kind regards
>
> John Tully
>
>
>
>




This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment. 

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored 
where permitted by law.





	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep  6 18:34:03 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 6 Sep 2021 12:34:03 -0400
Subject: [R] 'Double to logical' error
In-Reply-To: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
Message-ID: <7fd99717-b3dc-747e-5819-7e21493f405b@gmail.com>

On 06/09/2021 10:16 a.m., John Tully wrote:
> Dear colleagues
>>
>> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>>
>> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the error occurred.

That certainly looks like a tidyverse error, specifically from the 
tibble package.

Duncan Murdoch

>>
>> This follows the commands
>>
>> for (region in regions){
>>     for (study in unique(df$studyid)){
>>       single_study_df <- df %>% filter(studyid==study)
>>       if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l', region)])){
>>         df <- calc_bilat(study, region, r, df)
>>       }
>>     }
>> }
>>
>>
>> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>>
>> I would greatly value your input on this matter
>>
>> Kind regards
>>
>> John Tully
>>
>>
>>
>>
> 
> 
> 
> 
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please contact the sender and delete the email and
> attachment.
> 
> Any views or opinions expressed by the author of this email do not
> necessarily reflect the views of the University of Nottingham. Email
> communications with the University of Nottingham may be monitored
> where permitted by law.
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From w||||@mwdun|@p @end|ng |rom gm@||@com  Mon Sep  6 18:36:59 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Mon, 6 Sep 2021 09:36:59 -0700
Subject: [R] 'Double to logical' error
In-Reply-To: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
Message-ID: <CAHqSRuR4tONhT9-vFm-wVSQBU-aimD001xG5BOyEMQr8F9U=qw@mail.gmail.com>

>  Run `rlang::last_error()` to see where the error occurred

What did rlang::last_error() show?

-Bill


On Mon, Sep 6, 2021 at 9:19 AM John Tully <John.Tully at nottingham.ac.uk>
wrote:

> Dear colleagues
> >
> > in conducting a meta-analysis (of MRI data) I am running into the
> repeated issue:
> >
> > Error: Assigned data `single_study_df` must be compatible with existing
> data. ? Error occurred for column `accumbens_sd`. x Can't convert from
> <double> to <logical> due to loss of precision. * Locations: 1, 2. Run
> `rlang::last_error()` to see where the error occurred.
> >
> > This follows the commands
> >
> > for (region in regions){
> >    for (study in unique(df$studyid)){
> >      single_study_df <- df %>% filter(studyid==study)
> >      if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l',
> region)])){
> >        df <- calc_bilat(study, region, r, df)
> >      }
> >    }
> > }
> >
> >
> > My colleague (cc'd) believed it may be an issue with tidyverse version,
> however using an older version (1.2.1), the issue persists. note
> 'accumbens' is the first of many columns so I suspect this is why it flags
> this up.
> >
> > I would greatly value your input on this matter
> >
> > Kind regards
> >
> > John Tully
> >
> >
> >
> >
>
>
>
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please contact the sender and delete the email and
> attachment.
>
> Any views or opinions expressed by the author of this email do not
> necessarily reflect the views of the University of Nottingham. Email
> communications with the University of Nottingham may be monitored
> where permitted by law.
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep  6 18:49:26 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 6 Sep 2021 12:49:26 -0400
Subject: [R] 'Double to logical' error
In-Reply-To: <7fd99717-b3dc-747e-5819-7e21493f405b@gmail.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <7fd99717-b3dc-747e-5819-7e21493f405b@gmail.com>
Message-ID: <8e5dd1a0-2a21-63cb-eb20-25226aebe847@gmail.com>

You get this error from this kind of operation on tibbles:

library(tibble)
t1 <- tibble(x = c(TRUE, FALSE))
t2 <- tibble(x = c(1.2, 1.3))
t1[1,] <- t2[1,]
#> Error: Assigned data `t2[1, ]` must be compatible with existing data.
#> ? Error occurred for column `x`.
#> x Can't convert from <double> to <logical> due to loss of precision.
#> * Locations: 1.

If t1 had been a data.frame instead of a tibble, this would convert t1$x 
to type double.  So it is possible some code you are using assumes 
things inheriting from class "data.frame" act like dataframes.  Or maybe 
they were just sloppy.  In any case, you might be able to fix it by 
changing single_study_df to a dataframe using

   single_study_df <- as.data.frame(single_study_df)

Duncan Murdoch


On 06/09/2021 12:34 p.m., Duncan Murdoch wrote:
> On 06/09/2021 10:16 a.m., John Tully wrote:
>> Dear colleagues
>>>
>>> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>>>
>>> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the error occurred.
> 
> That certainly looks like a tidyverse error, specifically from the
> tibble package.
> 
> Duncan Murdoch
> 
>>>
>>> This follows the commands
>>>
>>> for (region in regions){
>>>      for (study in unique(df$studyid)){
>>>        single_study_df <- df %>% filter(studyid==study)
>>>        if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l', region)])){
>>>          df <- calc_bilat(study, region, r, df)
>>>        }
>>>      }
>>> }
>>>
>>>
>>> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>>>
>>> I would greatly value your input on this matter
>>>
>>> Kind regards
>>>
>>> John Tully
>>>
>>>
>>>
>>>
>>
>>
>>
>>
>> This message and any attachment are intended solely for the addressee
>> and may contain confidential information. If you have received this
>> message in error, please contact the sender and delete the email and
>> attachment.
>>
>> Any views or opinions expressed by the author of this email do not
>> necessarily reflect the views of the University of Nottingham. Email
>> communications with the University of Nottingham may be monitored
>> where permitted by law.
>>
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From j|n||68 @end|ng |rom gm@||@com  Tue Sep  7 01:46:34 2021
From: j|n||68 @end|ng |rom gm@||@com (Jin Li)
Date: Tue, 7 Sep 2021 09:46:34 +1000
Subject: [R] spm package is available on CRAN again
Message-ID: <CAGu_3ZKf=6txLZ5VQNCJzKPTuJw7Fev1XDVuG9pbyVx0p3UMpA@mail.gmail.com>

Dear spm users and all,

I am glad to inform you that the spm package is available on CRAN again. It
is an updated version with a few bugs fixed. Please note that some
functions in the package are not only for spatial predictive modelling but
also for general predictive modeling.

Please feel free to contact me if you have any questions regarding the spm
package.

Best regards,
-- 
Jin
------------------------------------------
Jin Li, PhD
Founder, Data2action, Australia
https://www.researchgate.net/profile/Jin_Li32
https://scholar.google.com/citations?user=Jeot53EAAAAJ&hl=en

	[[alternative HTML version deleted]]


From g@@@uu| @end|ng |rom gm@||@com  Tue Sep  7 02:38:44 2021
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Tue, 7 Sep 2021 09:38:44 +0900
Subject: [R] field significance test
In-Reply-To: <CA+8X3fVbxs=GAAsGKnM6RAAArJ9OL3vap4q-ZPZEUb9=58EDJA@mail.gmail.com>
References: <CAHXS41xewf=m01MSh9DdYwwyL_iLJupADLJkedQRLwOqMJePPg@mail.gmail.com>
 <CA+8X3fVbxs=GAAsGKnM6RAAArJ9OL3vap4q-ZPZEUb9=58EDJA@mail.gmail.com>
Message-ID: <CAHXS41w_5PM0mbgHTXMqG8SogX2a_MCyP0tbcZukNi7cV2FD6Q@mail.gmail.com>

Hello Jim, thank you for your response. What I am trying to achieve is
like this:

#calculate the positive significant station for every row based on p-value
df5<-df3
df5[df4>0.05|df5<0]<-NA
      #remove the insignificant one or negative statistic value
df5[df5>0]<-1
            #change the positive value to be +1 so I can row sum later
pos<-as.data.frame(rowSums(df5, na.rm=T))                         #row
sum to see the total significant station (column) for each row
poss<-as.data.frame(table(pos))
   #get the frequency of each significant number (row that have only
1,2,3,.. significant station)
posss<-as.numeric(rep(poss$pos[-1],poss$Freq[-1]))-1          #create
the series based on frequency

#calculate the negative significant station for every row based on p-value
df6<-df3
df6[df4>0.05|df5>0]<-NA
df6[df6<0]<-1
neg<-as.data.frame(rowSums(df6, na.rm=T))
negg<-as.data.frame(table(neg))
neggg<-(as.numeric(rep(negg$neg[-1],negg$Freq[-1]))-1)*-1

ne<-sum(pos==0&neg==0)
#to see the 0 significant station, row that have no significant
station



after that I want to combine posss, neggg, and ne to be 1 column data
frame but not success yet. After that, I want to plot the histogram to
see the distribution of significant stations.
Any lead is appreciate. Thank you
Ani Jaya


From g@@@uu| @end|ng |rom gm@||@com  Tue Sep  7 02:50:52 2021
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Tue, 7 Sep 2021 09:50:52 +0900
Subject: [R] field significance test
In-Reply-To: <CAHXS41w_5PM0mbgHTXMqG8SogX2a_MCyP0tbcZukNi7cV2FD6Q@mail.gmail.com>
References: <CAHXS41xewf=m01MSh9DdYwwyL_iLJupADLJkedQRLwOqMJePPg@mail.gmail.com>
 <CA+8X3fVbxs=GAAsGKnM6RAAArJ9OL3vap4q-ZPZEUb9=58EDJA@mail.gmail.com>
 <CAHXS41w_5PM0mbgHTXMqG8SogX2a_MCyP0tbcZukNi7cV2FD6Q@mail.gmail.com>
Message-ID: <CAHXS41z0MFVKF10oS-emL-LsGHQsQp=V_F6XAZiW8EOjhhzazg@mail.gmail.com>

and yes I can sleep well now. Thank you, Jim.

ne<-rep(0,ne)
total<-c(neggg,posss,ne)
hist(total)

Best,
Ani Jaya

On Tue, Sep 7, 2021 at 9:38 AM ani jaya <gaaauul at gmail.com> wrote:
>
> Hello Jim, thank you for your response. What I am trying to achieve is
> like this:
>
> #calculate the positive significant station for every row based on p-value
> df5<-df3
> df5[df4>0.05|df5<0]<-NA
>       #remove the insignificant one or negative statistic value
> df5[df5>0]<-1
>             #change the positive value to be +1 so I can row sum later
> pos<-as.data.frame(rowSums(df5, na.rm=T))                         #row
> sum to see the total significant station (column) for each row
> poss<-as.data.frame(table(pos))
>    #get the frequency of each significant number (row that have only
> 1,2,3,.. significant station)
> posss<-as.numeric(rep(poss$pos[-1],poss$Freq[-1]))-1          #create
> the series based on frequency
>
> #calculate the negative significant station for every row based on p-value
> df6<-df3
> df6[df4>0.05|df5>0]<-NA
> df6[df6<0]<-1
> neg<-as.data.frame(rowSums(df6, na.rm=T))
> negg<-as.data.frame(table(neg))
> neggg<-(as.numeric(rep(negg$neg[-1],negg$Freq[-1]))-1)*-1
>
> ne<-sum(pos==0&neg==0)
> #to see the 0 significant station, row that have no significant
> station
>
>
>
> after that I want to combine posss, neggg, and ne to be 1 column data
> frame but not success yet. After that, I want to plot the histogram to
> see the distribution of significant stations.
> Any lead is appreciate. Thank you
> Ani Jaya


From John@Tu||y @end|ng |rom nott|ngh@m@@c@uk  Tue Sep  7 12:37:41 2021
From: John@Tu||y @end|ng |rom nott|ngh@m@@c@uk (John Tully)
Date: Tue, 7 Sep 2021 10:37:41 +0000
Subject: [R] 'Double to logical' error
In-Reply-To: <CAHqSRuR4tONhT9-vFm-wVSQBU-aimD001xG5BOyEMQr8F9U=qw@mail.gmail.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <CAHqSRuR4tONhT9-vFm-wVSQBU-aimD001xG5BOyEMQr8F9U=qw@mail.gmail.com>
Message-ID: <AS8PR06MB76408F9128B6863223D95E3B92D39@AS8PR06MB7640.eurprd06.prod.outlook.com>

Thank you

I ran:

```{r}
rlang::last_error()
```

Here is the output:

<error/tibble_error_assign_incompatible_type>
Assigned data `single_study_df` must be compatible with existing data.
? Error occurred for column `third_ventricle_mn`.
x Can't convert from <double> to <logical> due to loss of precision.
* Locations: 1, 2.
Backtrace:
Run `rlang::last_trace()` to see the full context.




________________________________
From: Bill Dunlap <williamwdunlap at gmail.com>
Sent: Monday, September 6, 2021 5:36 PM
To: John Tully <mszjt1 at exmail.nottingham.ac.uk>
Cc: r-help at R-project.org <r-help at r-project.org>; McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk>
Subject: Re: [R] 'Double to logical' error

>  Run `rlang::last_error()` to see where the error occurred

What did rlang::last_error() show?

-Bill


On Mon, Sep 6, 2021 at 9:19 AM John Tully <John.Tully at nottingham.ac.uk<mailto:John.Tully at nottingham.ac.uk>> wrote:
Dear colleagues
>
> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>
> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the error occurred.
>
> This follows the commands
>
> for (region in regions){
>    for (study in unique(df$studyid)){
>      single_study_df <- df %>% filter(studyid==study)
>      if (is.na<http://is.na>(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na<http://is.na>(single_study_df[sprintf('%s_mn_l', region)])){
>        df <- calc_bilat(study, region, r, df)
>      }
>    }
> }
>
>
> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>
> I would greatly value your input on this matter
>
> Kind regards
>
> John Tully
>
>
>
>




This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment.

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored
where permitted by law.





        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment. 

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored 
where permitted by law.





	[[alternative HTML version deleted]]


From nmw2000 @end|ng |rom hw@@c@uk  Tue Sep  7 13:00:21 2021
From: nmw2000 @end|ng |rom hw@@c@uk (Wray, Nicholas M)
Date: Tue, 7 Sep 2021 11:00:21 +0000
Subject: [R] SWATplusR package problems
Message-ID: <LO0P265MB3082361D120234F96AAC21BB8FD39@LO0P265MB3082.GBRP265.PROD.OUTLOOK.COM>

I am trying to get to grips with the SWAT+ hydrological model and with the package SWATplusR which is meant instantiate SWAT+ into R. I have going through the code supplied on this website https://github.com/chrisschuerz/SWATplusR/blob/master/vignettes/SWATplusR.Rmd

I can get so far, as shown beneath but then I get the error message also shown. I cannot see how to get any further


library(SWATdata)
library(SWATplusR)
demo_path<-"C:Documents"
demo_path
######
path_plus <- load_demo(dataset = "project",
                       version = "plus",
                       path = demo_path,
                       revision = 57)


q_obs <- load_demo(dataset = "observation")
q_obs
plot(q_obs, type = "l")####### Path to the subbasin shape file
sub_path <- load_demo(dataset = "subbasin", version = "plus")# Path to the subbasin shape file
riv_path <- load_demo(dataset = "river", version = "plus")
sub_path
riv_path
library(sf)
library(ggplot2)
sub <- read_sf(sub_path)
riv <- read_sf(riv_path)
ggplot() +
  geom_sf(data = sub) +
  geom_sf(data = riv, col = "royalblue", lwd = 0.75) +
  geom_sf_label(data = riv, aes(label = Channel)) +
  theme_bw()
q_sim_plus <- run_swatplus(project_path = path_plus,
                           output = define_output(file = "channel",
                                                  variable = "flo_out",
                                                  unit = 1))

The ggplot gives me a map but for the next line I get this error message:


Error: 'C:/swat_demo/swatplus_rev57_demo/time.sim' does not exist.

Where might this file be? I've tried searching for sources but cannot find anything. Thanks Nick Wray


________________________________

Founded in 1821, Heriot-Watt is a leader in ideas and solutions. With campuses and students across the entire globe we span the world, delivering innovation and educational excellence in business, engineering, design and the physical, social and life sciences. This email is generated from the Heriot-Watt University Group, which includes:

  1.  Heriot-Watt University, a Scottish charity registered under number SC000278
  2.  Heriot- Watt Services Limited (Oriam), Scotland's national performance centre for sport. Heriot-Watt Services Limited is a private limited company registered is Scotland with registered number SC271030 and registered office at Research & Enterprise Services Heriot-Watt University, Riccarton, Edinburgh, EH14 4AS.

The contents (including any attachments) are confidential. If you are not the intended recipient of this e-mail, any disclosure, copying, distribution or use of its contents is strictly prohibited, and you should please notify the sender immediately and then delete it (including any attachments) from your system.

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Sep  7 14:51:12 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 7 Sep 2021 08:51:12 -0400
Subject: [R] SWATplusR package problems
In-Reply-To: <LO0P265MB3082361D120234F96AAC21BB8FD39@LO0P265MB3082.GBRP265.PROD.OUTLOOK.COM>
References: <LO0P265MB3082361D120234F96AAC21BB8FD39@LO0P265MB3082.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <582e3bc7-72b1-e7e3-38bf-36b7d73b93a9@gmail.com>

On 07/09/2021 7:00 a.m., Wray, Nicholas M via R-help wrote:
> I am trying to get to grips with the SWAT+ hydrological model and with the package SWATplusR which is meant instantiate SWAT+ into R. I have going through the code supplied on this website https://github.com/chrisschuerz/SWATplusR/blob/master/vignettes/SWATplusR.Rmd
> 

I think you'll need to raise this as an "Issue" on that Github site; 
it's not really something we're likely to be able to help with (and is 
formally off-topic here, being a contributed package).

Duncan Murdoch

> I can get so far, as shown beneath but then I get the error message also shown. I cannot see how to get any further
> 
> 
> library(SWATdata)
> library(SWATplusR)
> demo_path<-"C:Documents"
> demo_path
> ######
> path_plus <- load_demo(dataset = "project",
>                         version = "plus",
>                         path = demo_path,
>                         revision = 57)
> 
> 
> q_obs <- load_demo(dataset = "observation")
> q_obs
> plot(q_obs, type = "l")####### Path to the subbasin shape file
> sub_path <- load_demo(dataset = "subbasin", version = "plus")# Path to the subbasin shape file
> riv_path <- load_demo(dataset = "river", version = "plus")
> sub_path
> riv_path
> library(sf)
> library(ggplot2)
> sub <- read_sf(sub_path)
> riv <- read_sf(riv_path)
> ggplot() +
>    geom_sf(data = sub) +
>    geom_sf(data = riv, col = "royalblue", lwd = 0.75) +
>    geom_sf_label(data = riv, aes(label = Channel)) +
>    theme_bw()
> q_sim_plus <- run_swatplus(project_path = path_plus,
>                             output = define_output(file = "channel",
>                                                    variable = "flo_out",
>                                                    unit = 1))
> 
> The ggplot gives me a map but for the next line I get this error message:
> 
> 
> Error: 'C:/swat_demo/swatplus_rev57_demo/time.sim' does not exist.
> 
> Where might this file be? I've tried searching for sources but cannot find anything. Thanks Nick Wray
> 
> 
> ________________________________
> 
> Founded in 1821, Heriot-Watt is a leader in ideas and solutions. With campuses and students across the entire globe we span the world, delivering innovation and educational excellence in business, engineering, design and the physical, social and life sciences. This email is generated from the Heriot-Watt University Group, which includes:
> 
>    1.  Heriot-Watt University, a Scottish charity registered under number SC000278
>    2.  Heriot- Watt Services Limited (Oriam), Scotland's national performance centre for sport. Heriot-Watt Services Limited is a private limited company registered is Scotland with registered number SC271030 and registered office at Research & Enterprise Services Heriot-Watt University, Riccarton, Edinburgh, EH14 4AS.
> 
> The contents (including any attachments) are confidential. If you are not the intended recipient of this e-mail, any disclosure, copying, distribution or use of its contents is strictly prohibited, and you should please notify the sender immediately and then delete it (including any attachments) from your system.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Sep  7 15:27:55 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 7 Sep 2021 09:27:55 -0400
Subject: [R] 'Double to logical' error
In-Reply-To: <AS8PR06MB76404B55C21D5E24CF55633392D39@AS8PR06MB7640.eurprd06.prod.outlook.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <7fd99717-b3dc-747e-5819-7e21493f405b@gmail.com>
 <8e5dd1a0-2a21-63cb-eb20-25226aebe847@gmail.com>
 <AS8PR06MB76404B55C21D5E24CF55633392D39@AS8PR06MB7640.eurprd06.prod.outlook.com>
Message-ID: <380f96fa-8b35-c2da-4f0e-efe0e39f7a6b@gmail.com>

And what is in the string that triggers the issue?

On 07/09/2021 9:23 a.m., John Tully wrote:
> Thank you Duncan
> 
> we now resolved this
> 
> However I have run into another problem with the section of script 
> below- I am getting in reply
> 
> Error in nchar(a) : invalid multibyte string, element 1
> 
> Thanks
> 
> 
> 
> 
> SCRIPT SECTION:
> 
> **
> 
> **
> 
> # fill data frame with meta results
> j=1
> for (indiv_meta in to_include){
>  ? graph_results$estimate[j]=results_list[[indiv_meta]]$b
>  ? graph_results$lb[j]=results_list[[indiv_meta]]$ci.lb
>  ? graph_results$ub[j]=results_list[[indiv_meta]]$ci.ub
>  ? graph_results$p[j]=results_list[[indiv_meta]]$pval
>  ? a <- as.character(results_list[[indiv_meta]]$slab)
>  ? #this reduces the 'k' printed on the graph for instancews where 
> sibsamples counted as sepearte studies
>  ? b <- substr( a, start = nchar(a) - 1 , stop = nchar(a)-1)
>  ? num_dups = sum(b==".")/2
>  ? graph_results$k[j]=as.integer(results_list[[indiv_meta]]$k)-num_dups
>  ? j=j+1
> }
> 
> 
> 
> 
> ------------------------------------------------------------------------
> *From:* Duncan Murdoch <murdoch.duncan at gmail.com>
> *Sent:* Monday, September 6, 2021 5:49 PM
> *To:* John Tully <mszjt1 at exmail.nottingham.ac.uk>; r-help at R-project.org 
> <r-help at R-project.org>
> *Cc:* McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk>
> *Subject:* Re: [R] 'Double to logical' error
> You get this error from this kind of operation on tibbles:
> 
> library(tibble)
> t1 <- tibble(x = c(TRUE, FALSE))
> t2 <- tibble(x = c(1.2, 1.3))
> t1[1,] <- t2[1,]
> #> Error: Assigned data `t2[1, ]` must be compatible with existing data.
> #> ? Error occurred for column `x`.
> #> x Can't convert from <double> to <logical> due to loss of precision.
> #> * Locations: 1.
> 
> If t1 had been a data.frame instead of a tibble, this would convert t1$x
> to type double.? So it is possible some code you are using assumes
> things inheriting from class "data.frame" act like dataframes.? Or maybe
> they were just sloppy.? In any case, you might be able to fix it by
> changing single_study_df to a dataframe using
> 
>  ?? single_study_df <- as.data.frame(single_study_df)
> 
> Duncan Murdoch
> 
> 
> On 06/09/2021 12:34 p.m., Duncan Murdoch wrote:
>> On 06/09/2021 10:16 a.m., John Tully wrote:
>>> Dear colleagues
>>>>
>>>> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>>>>
>>>> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the  error occurred.
>> 
>> That certainly looks like a tidyverse error, specifically from the
>> tibble package.
>> 
>> Duncan Murdoch
>> 
>>>>
>>>> This follows the commands
>>>>
>>>> for (region in regions){
>>>>????? for (study in unique(df$studyid)){
>>>>??????? single_study_df <- df %>% filter(studyid==study)
>>>>??????? if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l', region)])){
>>>>????????? df <- calc_bilat(study, region, r, df)
>>>>??????? }
>>>>????? }
>>>> }
>>>>
>>>>
>>>> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>>>>
>>>> I would greatly value your input on this matter
>>>>
>>>> Kind regards
>>>>
>>>> John Tully
>>>>
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>>
>>> This message and any attachment are intended solely for the addressee
>>> and may contain confidential information. If you have received this
>>> message in error, please contact the sender and delete the email and
>>> attachment.
>>>
>>> Any views or opinions expressed by the author of this email do not
>>> necessarily reflect the views of the University of Nottingham. Email
>>> communications with the University of Nottingham may be monitored
>>> where permitted by law.
>>>
>>>
>>>
>>>
>>>
>>>?????? [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> 
> 
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please contact the sender and delete the email and
> attachment.
> 
> Any views or opinions expressed by the author of this email do not
> necessarily reflect the views of the University of Nottingham. Email
> communications with the University of Nottingham may be monitored
> where permitted by law.
> 
> 
>


From w||||@mwdun|@p @end|ng |rom gm@||@com  Tue Sep  7 17:06:03 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Tue, 7 Sep 2021 08:06:03 -0700
Subject: [R] 'Double to logical' error
In-Reply-To: <AS8PR06MB76408F9128B6863223D95E3B92D39@AS8PR06MB7640.eurprd06.prod.outlook.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <CAHqSRuR4tONhT9-vFm-wVSQBU-aimD001xG5BOyEMQr8F9U=qw@mail.gmail.com>
 <AS8PR06MB76408F9128B6863223D95E3B92D39@AS8PR06MB7640.eurprd06.prod.outlook.com>
Message-ID: <CAHqSRuRLH0a_ibiZ1YUN-qRbM5oTePDFaVVpp-s_YefDfUd_kQ@mail.gmail.com>

Thanks.  If you can still reproduce the problem, what did
    rlang::last_trace()
report?

-Bill

On Tue, Sep 7, 2021 at 3:37 AM John Tully <John.Tully at nottingham.ac.uk>
wrote:

> Thank you
>
> I ran:
>
> ```{r}
> rlang::last_error()
> ```
>
> Here is the output:
>
> <error/tibble_error_assign_incompatible_type>
> Assigned data `single_study_df` must be compatible with existing data.
> ? Error occurred for column `third_ventricle_mn`.
> x Can't convert from <double> to <logical> due to loss of precision.
> * Locations: 1, 2.
> Backtrace:
> Run `rlang::last_trace()` to see the full context.
>
>
>
>
> ------------------------------
> *From:* Bill Dunlap <williamwdunlap at gmail.com>
> *Sent:* Monday, September 6, 2021 5:36 PM
> *To:* John Tully <mszjt1 at exmail.nottingham.ac.uk>
> *Cc:* r-help at R-project.org <r-help at r-project.org>; McCutcheon, Robert <
> robert.mccutcheon at kcl.ac.uk>
> *Subject:* Re: [R] 'Double to logical' error
>
> >  Run `rlang::last_error()` to see where the error occurred
>
> What did rlang::last_error() show?
>
> -Bill
>
>
> On Mon, Sep 6, 2021 at 9:19 AM John Tully <John.Tully at nottingham.ac.uk>
> wrote:
>
> Dear colleagues
> >
> > in conducting a meta-analysis (of MRI data) I am running into the
> repeated issue:
> >
> > Error: Assigned data `single_study_df` must be compatible with existing
> data. ? Error occurred for column `accumbens_sd`. x Can't convert from
> <double> to <logical> due to loss of precision. * Locations: 1, 2. Run
> `rlang::last_error()` to see where the error occurred.
> >
> > This follows the commands
> >
> > for (region in regions){
> >    for (study in unique(df$studyid)){
> >      single_study_df <- df %>% filter(studyid==study)
> >      if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l',
> region)])){
> >        df <- calc_bilat(study, region, r, df)
> >      }
> >    }
> > }
> >
> >
> > My colleague (cc'd) believed it may be an issue with tidyverse version,
> however using an older version (1.2.1), the issue persists. note
> 'accumbens' is the first of many columns so I suspect this is why it flags
> this up.
> >
> > I would greatly value your input on this matter
> >
> > Kind regards
> >
> > John Tully
> >
> >
> >
> >
>
>
>
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please contact the sender and delete the email and
> attachment.
>
> Any views or opinions expressed by the author of this email do not
> necessarily reflect the views of the University of Nottingham. Email
> communications with the University of Nottingham may be monitored
> where permitted by law.
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please contact the sender and delete the email and
> attachment.
>
> Any views or opinions expressed by the author of this email do not
> necessarily reflect the views of the University of Nottingham. Email
> communications with the University of Nottingham may be monitored
> where permitted by law.
>
>
>
>
>

	[[alternative HTML version deleted]]


From John@Tu||y @end|ng |rom nott|ngh@m@@c@uk  Tue Sep  7 15:23:50 2021
From: John@Tu||y @end|ng |rom nott|ngh@m@@c@uk (John Tully)
Date: Tue, 7 Sep 2021 13:23:50 +0000
Subject: [R] 'Double to logical' error
In-Reply-To: <8e5dd1a0-2a21-63cb-eb20-25226aebe847@gmail.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <7fd99717-b3dc-747e-5819-7e21493f405b@gmail.com>
 <8e5dd1a0-2a21-63cb-eb20-25226aebe847@gmail.com>
Message-ID: <AS8PR06MB76404B55C21D5E24CF55633392D39@AS8PR06MB7640.eurprd06.prod.outlook.com>

Thank you Duncan

we now resolved this

However I have run into another problem with the section of script below- I am getting in reply

Error in nchar(a) : invalid multibyte string, element 1

Thanks




SCRIPT SECTION:


# fill data frame with meta results
j=1
for (indiv_meta in to_include){
  graph_results$estimate[j]=results_list[[indiv_meta]]$b
  graph_results$lb[j]=results_list[[indiv_meta]]$ci.lb
  graph_results$ub[j]=results_list[[indiv_meta]]$ci.ub
  graph_results$p[j]=results_list[[indiv_meta]]$pval
  a <- as.character(results_list[[indiv_meta]]$slab)
  #this reduces the 'k' printed on the graph for instancews where sibsamples counted as sepearte studies
  b <- substr( a, start = nchar(a) - 1 , stop = nchar(a)-1)
  num_dups = sum(b==".")/2
  graph_results$k[j]=as.integer(results_list[[indiv_meta]]$k)-num_dups
  j=j+1
}




________________________________
From: Duncan Murdoch <murdoch.duncan at gmail.com>
Sent: Monday, September 6, 2021 5:49 PM
To: John Tully <mszjt1 at exmail.nottingham.ac.uk>; r-help at R-project.org <r-help at R-project.org>
Cc: McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk>
Subject: Re: [R] 'Double to logical' error

You get this error from this kind of operation on tibbles:

library(tibble)
t1 <- tibble(x = c(TRUE, FALSE))
t2 <- tibble(x = c(1.2, 1.3))
t1[1,] <- t2[1,]
#> Error: Assigned data `t2[1, ]` must be compatible with existing data.
#> ? Error occurred for column `x`.
#> x Can't convert from <double> to <logical> due to loss of precision.
#> * Locations: 1.

If t1 had been a data.frame instead of a tibble, this would convert t1$x
to type double.  So it is possible some code you are using assumes
things inheriting from class "data.frame" act like dataframes.  Or maybe
they were just sloppy.  In any case, you might be able to fix it by
changing single_study_df to a dataframe using

   single_study_df <- as.data.frame(single_study_df)

Duncan Murdoch


On 06/09/2021 12:34 p.m., Duncan Murdoch wrote:
> On 06/09/2021 10:16 a.m., John Tully wrote:
>> Dear colleagues
>>>
>>> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>>>
>>> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the error occurred.
>
> That certainly looks like a tidyverse error, specifically from the
> tibble package.
>
> Duncan Murdoch
>
>>>
>>> This follows the commands
>>>
>>> for (region in regions){
>>>      for (study in unique(df$studyid)){
>>>        single_study_df <- df %>% filter(studyid==study)
>>>        if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l', region)])){
>>>          df <- calc_bilat(study, region, r, df)
>>>        }
>>>      }
>>> }
>>>
>>>
>>> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>>>
>>> I would greatly value your input on this matter
>>>
>>> Kind regards
>>>
>>> John Tully
>>>
>>>
>>>
>>>
>>
>>
>>
>>
>> This message and any attachment are intended solely for the addressee
>> and may contain confidential information. If you have received this
>> message in error, please contact the sender and delete the email and
>> attachment.
>>
>> Any views or opinions expressed by the author of this email do not
>> necessarily reflect the views of the University of Nottingham. Email
>> communications with the University of Nottingham may be monitored
>> where permitted by law.
>>
>>
>>
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>




This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment. 

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored 
where permitted by law.





	[[alternative HTML version deleted]]


From John@Tu||y @end|ng |rom nott|ngh@m@@c@uk  Tue Sep  7 16:01:29 2021
From: John@Tu||y @end|ng |rom nott|ngh@m@@c@uk (John Tully)
Date: Tue, 7 Sep 2021 14:01:29 +0000
Subject: [R] 'Double to logical' error
In-Reply-To: <380f96fa-8b35-c2da-4f0e-efe0e39f7a6b@gmail.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <7fd99717-b3dc-747e-5819-7e21493f405b@gmail.com>
 <8e5dd1a0-2a21-63cb-eb20-25226aebe847@gmail.com>
 <AS8PR06MB76404B55C21D5E24CF55633392D39@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <380f96fa-8b35-c2da-4f0e-efe0e39f7a6b@gmail.com>
Message-ID: <AS8PR06MB76400A66C58E07BDE7C3DE1E92D39@AS8PR06MB7640.eurprd06.prod.outlook.com>

I?m afraid I don?t know this. I ran rlang to no avail. Any other suggestion?

Get Outlook for iOS<https://aka.ms/o0ukef>
________________________________
From: Duncan Murdoch <murdoch.duncan at gmail.com>
Sent: Tuesday, September 7, 2021 2:27:55 PM
To: John Tully <mszjt1 at exmail.nottingham.ac.uk>; r-help at R-project.org <r-help at R-project.org>
Cc: McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk>
Subject: Re: [R] 'Double to logical' error

And what is in the string that triggers the issue?

On 07/09/2021 9:23 a.m., John Tully wrote:
> Thank you Duncan
>
> we now resolved this
>
> However I have run into another problem with the section of script
> below- I am getting in reply
>
> Error in nchar(a) : invalid multibyte string, element 1
>
> Thanks
>
>
>
>
> SCRIPT SECTION:
>
> **
>
> **
>
> # fill data frame with meta results
> j=1
> for (indiv_meta in to_include){
>    graph_results$estimate[j]=results_list[[indiv_meta]]$b
>    graph_results$lb[j]=results_list[[indiv_meta]]$ci.lb
>    graph_results$ub[j]=results_list[[indiv_meta]]$ci.ub
>    graph_results$p[j]=results_list[[indiv_meta]]$pval
>    a <- as.character(results_list[[indiv_meta]]$slab)
>    #this reduces the 'k' printed on the graph for instancews where
> sibsamples counted as sepearte studies
>    b <- substr( a, start = nchar(a) - 1 , stop = nchar(a)-1)
>    num_dups = sum(b==".")/2
>    graph_results$k[j]=as.integer(results_list[[indiv_meta]]$k)-num_dups
>    j=j+1
> }
>
>
>
>
> ------------------------------------------------------------------------
> *From:* Duncan Murdoch <murdoch.duncan at gmail.com>
> *Sent:* Monday, September 6, 2021 5:49 PM
> *To:* John Tully <mszjt1 at exmail.nottingham.ac.uk>; r-help at R-project.org
> <r-help at R-project.org>
> *Cc:* McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk>
> *Subject:* Re: [R] 'Double to logical' error
> You get this error from this kind of operation on tibbles:
>
> library(tibble)
> t1 <- tibble(x = c(TRUE, FALSE))
> t2 <- tibble(x = c(1.2, 1.3))
> t1[1,] <- t2[1,]
> #> Error: Assigned data `t2[1, ]` must be compatible with existing data.
> #> ? Error occurred for column `x`.
> #> x Can't convert from <double> to <logical> due to loss of precision.
> #> * Locations: 1.
>
> If t1 had been a data.frame instead of a tibble, this would convert t1$x
> to type double.  So it is possible some code you are using assumes
> things inheriting from class "data.frame" act like dataframes.  Or maybe
> they were just sloppy.  In any case, you might be able to fix it by
> changing single_study_df to a dataframe using
>
>     single_study_df <- as.data.frame(single_study_df)
>
> Duncan Murdoch
>
>
> On 06/09/2021 12:34 p.m., Duncan Murdoch wrote:
>> On 06/09/2021 10:16 a.m., John Tully wrote:
>>> Dear colleagues
>>>>
>>>> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>>>>
>>>> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the  error occurred.
>>
>> That certainly looks like a tidyverse error, specifically from the
>> tibble package.
>>
>> Duncan Murdoch
>>
>>>>
>>>> This follows the commands
>>>>
>>>> for (region in regions){
>>>>      for (study in unique(df$studyid)){
>>>>        single_study_df <- df %>% filter(studyid==study)
>>>>        if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l', region)])){
>>>>          df <- calc_bilat(study, region, r, df)
>>>>        }
>>>>      }
>>>> }
>>>>
>>>>
>>>> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>>>>
>>>> I would greatly value your input on this matter
>>>>
>>>> Kind regards
>>>>
>>>> John Tully
>>>>
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>>
>>> This message and any attachment are intended solely for the addressee
>>> and may contain confidential information. If you have received this
>>> message in error, please contact the sender and delete the email and
>>> attachment.
>>>
>>> Any views or opinions expressed by the author of this email do not
>>> necessarily reflect the views of the University of Nottingham. Email
>>> communications with the University of Nottingham may be monitored
>>> where permitted by law.
>>>
>>>
>>>
>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
> <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please contact the sender and delete the email and
> attachment.
>
> Any views or opinions expressed by the author of this email do not
> necessarily reflect the views of the University of Nottingham. Email
> communications with the University of Nottingham may be monitored
> where permitted by law.
>
>
>




This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment. 

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored 
where permitted by law.





	[[alternative HTML version deleted]]


From John@Tu||y @end|ng |rom nott|ngh@m@@c@uk  Tue Sep  7 17:42:17 2021
From: John@Tu||y @end|ng |rom nott|ngh@m@@c@uk (John Tully)
Date: Tue, 7 Sep 2021 15:42:17 +0000
Subject: [R] 'Double to logical' error
In-Reply-To: <CAHqSRuRLH0a_ibiZ1YUN-qRbM5oTePDFaVVpp-s_YefDfUd_kQ@mail.gmail.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <CAHqSRuR4tONhT9-vFm-wVSQBU-aimD001xG5BOyEMQr8F9U=qw@mail.gmail.com>
 <AS8PR06MB76408F9128B6863223D95E3B92D39@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <CAHqSRuRLH0a_ibiZ1YUN-qRbM5oTePDFaVVpp-s_YefDfUd_kQ@mail.gmail.com>
Message-ID: <AS8PR06MB76403D1DE539F715ACA67D4992D39@AS8PR06MB7640.eurprd06.prod.outlook.com>

thanks

i get a red bar to the left of all of this

for (indiv_meta in to_include){
  graph_results$estimate[j]=results_list[[indiv_meta]]$b
  graph_results$lb[j]=results_list[[indiv_meta]]$ci.lb
  graph_results$ub[j]=results_list[[indiv_meta]]$ci.ub
  graph_results$p[j]=results_list[[indiv_meta]]$pval
  a <- as.character(results_list[[indiv_meta]]$slab)
  #this reduces the 'k' printed on the graph for instancews where sibsamples counted as sepearte studies
  b <- substr( a, start = nchar(a) - 1 , stop = nchar(a)-1)
  num_dups = sum(b==".")/2
  graph_results$k[j]=as.integer(results_list[[indiv_meta]]$k)-num_dups
  j=j+1
}






rlang last trace gives this

<error/tibble_error_assign_incompatible_type>
Assigned data `single_study_df` must be compatible with existing data.
? Error occurred for column `third_ventricle_mn`.
x Can't convert from <double> to <logical> due to loss of precision.
* Locations: 1, 2.
Backtrace:
     ?
  1. ??global::calc_bilat(study, region, r, df)
  2. ? ??base::`[<-`(...) aspd_funcs.r:11:2
  3. ? ??tibble:::`[<-.tbl_df`(...) aspd_funcs.r:11:2
  4. ?   ??tibble:::tbl_subassign(x, i, j, value, i_arg, j_arg, substitute(value))
  5. ?     ??tibble:::tbl_subassign_row(x, i, value, value_arg)
  6. ?       ??base::withCallingHandlers(...)
  7. ?       ??vctrs::`vec_slice<-`(`*tmp*`, i, value = value[[j]])
  8. ?         ??(function () ...
  9. ?           ??vctrs:::vec_cast.logical.double(...)
 10. ?             ??vctrs::maybe_lossy_cast(out, x, to, lossy, x_arg = x_arg, to_arg = to_arg)
 11. ?               ??base::withRestarts(...)
 12. ?               ? ??base:::withOneRestart(expr, restarts[[1L]])
 13. ?               ?   ??base:::doWithOneRestart(return(expr), restart)
 14. ?               ??vctrs:::stop_lossy_cast(...)
 15. ?                 ??vctrs:::stop_vctrs(...)
 16. ?                   ??rlang::abort(message, class = c(class, "vctrs_error"), ...)
 17. ?                     ??rlang:::signal_abort(cnd)
 18. ?                       ??base::signalCondition(cnd)
 19. ??(function (cnd) ...


?


________________________________
From: Bill Dunlap <williamwdunlap at gmail.com>
Sent: Tuesday, September 7, 2021 4:06 PM
To: John Tully <mszjt1 at exmail.nottingham.ac.uk>
Cc: r-help at R-project.org <r-help at r-project.org>; McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk>
Subject: Re: [R] 'Double to logical' error

Thanks.  If you can still reproduce the problem, what did
    rlang::last_trace()
report?

-Bill

On Tue, Sep 7, 2021 at 3:37 AM John Tully <John.Tully at nottingham.ac.uk<mailto:John.Tully at nottingham.ac.uk>> wrote:
Thank you

I ran:

```{r}
rlang::last_error()
```

Here is the output:

<error/tibble_error_assign_incompatible_type>
Assigned data `single_study_df` must be compatible with existing data.
? Error occurred for column `third_ventricle_mn`.
x Can't convert from <double> to <logical> due to loss of precision.
* Locations: 1, 2.
Backtrace:
Run `rlang::last_trace()` to see the full context.




________________________________
From: Bill Dunlap <williamwdunlap at gmail.com<mailto:williamwdunlap at gmail.com>>
Sent: Monday, September 6, 2021 5:36 PM
To: John Tully <mszjt1 at exmail.nottingham.ac.uk<mailto:mszjt1 at exmail.nottingham.ac.uk>>
Cc: r-help at R-project.org <r-help at r-project.org<mailto:r-help at r-project.org>>; McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk<mailto:robert.mccutcheon at kcl.ac.uk>>
Subject: Re: [R] 'Double to logical' error

>  Run `rlang::last_error()` to see where the error occurred

What did rlang::last_error() show?

-Bill


On Mon, Sep 6, 2021 at 9:19 AM John Tully <John.Tully at nottingham.ac.uk<mailto:John.Tully at nottingham.ac.uk>> wrote:
Dear colleagues
>
> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>
> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the error occurred.
>
> This follows the commands
>
> for (region in regions){
>    for (study in unique(df$studyid)){
>      single_study_df <- df %>% filter(studyid==study)
>      if (is.na<http://is.na>(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na<http://is.na>(single_study_df[sprintf('%s_mn_l', region)])){
>        df <- calc_bilat(study, region, r, df)
>      }
>    }
> }
>
>
> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>
> I would greatly value your input on this matter
>
> Kind regards
>
> John Tully
>
>
>
>




This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment.

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored
where permitted by law.





        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment.

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored
where permitted by law.







This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment. 

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored 
where permitted by law.





	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Sep  8 01:30:04 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 8 Sep 2021 09:30:04 +1000
Subject: [R] field significance test
In-Reply-To: <CAHXS41z0MFVKF10oS-emL-LsGHQsQp=V_F6XAZiW8EOjhhzazg@mail.gmail.com>
References: <CAHXS41xewf=m01MSh9DdYwwyL_iLJupADLJkedQRLwOqMJePPg@mail.gmail.com>
 <CA+8X3fVbxs=GAAsGKnM6RAAArJ9OL3vap4q-ZPZEUb9=58EDJA@mail.gmail.com>
 <CAHXS41w_5PM0mbgHTXMqG8SogX2a_MCyP0tbcZukNi7cV2FD6Q@mail.gmail.com>
 <CAHXS41z0MFVKF10oS-emL-LsGHQsQp=V_F6XAZiW8EOjhhzazg@mail.gmail.com>
Message-ID: <CA+8X3fWW2YOnw_1mJZy2zco7xVdvUkKynrTCexc6mw0TmAbRfg@mail.gmail.com>

HIi Ani,
 I think you are going to a lot of trouble to get a fairly simple result.

# matrix of logicals for positive stat values
possig<-df3 > 0 & df4 < 0.05
# now negative stat values
negsig<-df3 < 0 & df4 < 0.05
# very clunky plots of column counts
barplot(colSums(possig),
 names.arg=paste0("S",1:10),
 main="Positive significant")
barplot(colSums(negsig))
 names.arg=paste0("S",1:10),
 main="Negative significant")

You said something about displaying the values of the statistics. As
the positive and negative values are mutually exclusive, you may want
to do something like this:

allsig<-possig | negsig
allsig[!allsig]<-NA
plot(1:10,1:10,type="n",xlab="Station",ylab="Rep",
 main="Significant statistical values")
text(rep(1:10,each=10),rep(10:1,10),round(df3*allsig,2))

giving you a matrix-like plot of the stat values. You could also add
the p-values.

Jim

On Tue, Sep 7, 2021 at 10:51 AM ani jaya <gaaauul at gmail.com> wrote:
>
> and yes I can sleep well now. Thank you, Jim.
>
> ne<-rep(0,ne)
> total<-c(neggg,posss,ne)
> hist(total)
>
> Best,
> Ani Jaya
>
> On Tue, Sep 7, 2021 at 9:38 AM ani jaya <gaaauul at gmail.com> wrote:
> >
> > Hello Jim, thank you for your response. What I am trying to achieve is
> > like this:
> >
> > #calculate the positive significant station for every row based on p-value
> > df5<-df3
> > df5[df4>0.05|df5<0]<-NA
> >       #remove the insignificant one or negative statistic value
> > df5[df5>0]<-1
> >             #change the positive value to be +1 so I can row sum later
> > pos<-as.data.frame(rowSums(df5, na.rm=T))                         #row
> > sum to see the total significant station (column) for each row
> > poss<-as.data.frame(table(pos))
> >    #get the frequency of each significant number (row that have only
> > 1,2,3,.. significant station)
> > posss<-as.numeric(rep(poss$pos[-1],poss$Freq[-1]))-1          #create
> > the series based on frequency
> >
> > #calculate the negative significant station for every row based on p-value
> > df6<-df3
> > df6[df4>0.05|df5>0]<-NA
> > df6[df6<0]<-1
> > neg<-as.data.frame(rowSums(df6, na.rm=T))
> > negg<-as.data.frame(table(neg))
> > neggg<-(as.numeric(rep(negg$neg[-1],negg$Freq[-1]))-1)*-1
> >
> > ne<-sum(pos==0&neg==0)
> > #to see the 0 significant station, row that have no significant
> > station
> >
> >
> >
> > after that I want to combine posss, neggg, and ne to be 1 column data
> > frame but not success yet. After that, I want to plot the histogram to
> > see the distribution of significant stations.
> > Any lead is appreciate. Thank you
> > Ani Jaya


From j|n||68 @end|ng |rom gm@||@com  Wed Sep  8 06:46:58 2021
From: j|n||68 @end|ng |rom gm@||@com (Jin Li)
Date: Wed, 8 Sep 2021 14:46:58 +1000
Subject: [R] Spm package is updated and available on CRAN again
Message-ID: <CAGu_3ZK4v3=NZBhfErJUecoB_Nx11NjtkQ58TN_giJ7U0DWC=Q@mail.gmail.com>

Dear spm users and all,

I am glad to inform you that the spm package is available on CRAN again. It
is an updated version with a few bugs fixed. Please note that some
functions in the package are not only for spatial predictive modelling but
also for predictive modeling in general.

Please feel free to contact me if you have any questions regarding the spm
package.

Best regards,

-- 
Jin

	[[alternative HTML version deleted]]


From grjon|80 @end|ng |rom gm@||@com  Wed Sep  8 12:13:03 2021
From: grjon|80 @end|ng |rom gm@||@com (=?UTF-8?Q?Sigurj=C3=B3n_=C3=9Eorsteinsson?=)
Date: Wed, 8 Sep 2021 10:13:03 +0000
Subject: [R] R: Many package imports have issues related to 'pillar'
Message-ID: <CAG-konykcgVq=KW9EAf0qyhtXg+y4+W=nstWgzpPoGyLmZ7r1g@mail.gmail.com>

Hi

I am looking for a solution to this problem
> library(geepack)
Error: package or namespace load failed for ?geepack?:
 .onLoad failed in loadNamespace() for 'pillar', details:
  call: readRDS(nsInfoFilePath)
  error: unknown input format

More information:
https://stackoverflow.com/questions/69073165/r-many-package-imports-have-issues-related-to-pillar

Thanks for helping
Sigurjon


From R@H@un@ch||d @end|ng |rom |k|@mpg@de  Wed Sep  8 16:52:08 2021
From: R@H@un@ch||d @end|ng |rom |k|@mpg@de (Dr. Robin Haunschild)
Date: Wed, 8 Sep 2021 16:52:08 +0200
Subject: [R] Interpretation of download counts of r packages using
 cranlogs::cran_downloads
Message-ID: <e2530d3a-f87e-6594-5c44-a20cdd1fd181@fkf.mpg.de>

Hi,

I looked at the download counts retrieved via the function
cran_downloads in the package cranlogs. According to the documentation,
download counts from the RStudio CRAN mirror are retrieved.

Are requests from other mirrors included, or can each download count be
interpreted as a download from a real user?


Best regards,

Robin
-- 
Dr. Robin Haunschild
Max Planck Institute for Solid State Research
Heisenbergstr. 1
D-70569 Stuttgart (Germany)
phone: +49 (0) 711-689-1285
fax:   +49 (0) 711-689-1292
email: R.Haunschild at fkf.mpg.de
http://www.fkf.mpg.de/ivs
Publons: https://publons.com/researcher/1421847/robin-haunschild/
GS: https://scholar.google.de/citations?user=kDfateQAAAAJ&hl=de&oi=ao


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep  8 17:08:12 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 8 Sep 2021 11:08:12 -0400
Subject: [R] R: Many package imports have issues related to 'pillar'
In-Reply-To: <CAG-konykcgVq=KW9EAf0qyhtXg+y4+W=nstWgzpPoGyLmZ7r1g@mail.gmail.com>
References: <CAG-konykcgVq=KW9EAf0qyhtXg+y4+W=nstWgzpPoGyLmZ7r1g@mail.gmail.com>
Message-ID: <a6da4923-c8dc-d48d-133e-ebd48c921f16@gmail.com>

On 08/09/2021 6:13 a.m., Sigurj?n ?orsteinsson wrote:
> Hi
> 
> I am looking for a solution to this problem
>> library(geepack)
> Error: package or namespace load failed for ?geepack?:
>   .onLoad failed in loadNamespace() for 'pillar', details:
>    call: readRDS(nsInfoFilePath)
>    error: unknown input format
> 
> More information:
> https://stackoverflow.com/questions/69073165/r-many-package-imports-have-issues-related-to-pillar

What does "library(pillar)" show?

Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep  8 17:09:45 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 8 Sep 2021 11:09:45 -0400
Subject: [R] Interpretation of download counts of r packages using
 cranlogs::cran_downloads
In-Reply-To: <e2530d3a-f87e-6594-5c44-a20cdd1fd181@fkf.mpg.de>
References: <e2530d3a-f87e-6594-5c44-a20cdd1fd181@fkf.mpg.de>
Message-ID: <d9e23bcc-52f9-1149-38ce-740783283715@gmail.com>

On 08/09/2021 10:52 a.m., Dr. Robin Haunschild wrote:
> Hi,
> 
> I looked at the download counts retrieved via the function
> cran_downloads in the package cranlogs. According to the documentation,
> download counts from the RStudio CRAN mirror are retrieved.
> 
> Are requests from other mirrors included, or can each download count be
> interpreted as a download from a real user?

I think the answer to both questions is "no".  RStudio doesn't know what 
happens on other mirrors, and lots of automatic tests would download 
from RStudio's mirrors.

Duncan Murdoch


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Sep  8 17:09:36 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 8 Sep 2021 08:09:36 -0700
Subject: [R] R: Many package imports have issues related to 'pillar'
In-Reply-To: <CAG-konykcgVq=KW9EAf0qyhtXg+y4+W=nstWgzpPoGyLmZ7r1g@mail.gmail.com>
References: <CAG-konykcgVq=KW9EAf0qyhtXg+y4+W=nstWgzpPoGyLmZ7r1g@mail.gmail.com>
Message-ID: <3d6a91a3-6c26-32e5-c9b4-778f14e08494@comcast.net>


On 9/8/21 3:13 AM, Sigurj?n ?orsteinsson wrote:
> Hi
>
> I am looking for a solution to this problem
>> library(geepack)
> Error: package or namespace load failed for ?geepack?:
>   .onLoad failed in loadNamespace() for 'pillar', details:
>    call: readRDS(nsInfoFilePath)
>    error: unknown input format
>
> More information:
> https://stackoverflow.com/questions/69073165/r-many-package-imports-have-issues-related-to-pillar


If you search on SO you find that the error typically lies in failing to 
properly update R package libraries when you upgrade to a new 
installation of R. So it may not have anything to to do with the pillar 
package specifically.? My understanding (not an expert understanding) is 
that this arises because the serialization protocol of rds files may 
differ from version to version.


https://stackoverflow.com/questions/6473831/readrdsfile-in-r

You might first follow the usual path of removing any .Rdata and 
.Rhistory files

Then an R console command to try might be:


update.packages(checkBuilt=TRUE, ask=FALSE) # may take a long time


-- 

David.

>
> Thanks for helping
> Sigurjon
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Adr|@n@Bowm@n @end|ng |rom g|@@gow@@c@uk  Wed Sep  8 12:15:45 2021
From: Adr|@n@Bowm@n @end|ng |rom g|@@gow@@c@uk (Adrian Bowman)
Date: Wed, 8 Sep 2021 10:15:45 +0000
Subject: [R] [R-pkgs] rpanel package update
Message-ID: <230AB4F1-4D98-4F1B-9E1D-7215A4267693@glasgow.ac.uk>


The rpanel package provides a set of tools to build simple GUI controls for R functions, using the tcltk R package and the Tcl/Tk system. Some ?cartoons? which use interaction and animation to communicate statistical concepts are also included.  There have been some difficulties in installing rpanel on some systems (notably Mac computers) due to the reference to a Tcl/Tk module known as BWidget.  This has now been resolved.  If BWidget is not available the rpanel package can still be installed but two facilities, namely the ?combobox? (R function rp.combo) and ?notebook? (R functions rp.notebook and rp.notebook.raise) are disabled.

Adrian Bowman

Prof. Adrian Bowman
BSc (Hons) Dip.Math.Stat PhD FRSE
Emeritus Professor of Statistics
University of Glasgow

E: adrian.bowman at glasgow.ac.uk<mailto:adrian.bowman at glasgow.ac.uk>
W: www.stats.gla.ac.uk/~adrian<http://www.stats.gla.ac.uk/~adrian>

School of Mathematics and Statistics
University of Glasgow
Glasgow G12 8QQ

The University of Glasgow, charity number SC004401



	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From m@rio@corr@do m@iii@g oii cro@iii@@ce@com  Thu Sep  9 17:55:53 2021
From: m@rio@corr@do m@iii@g oii cro@iii@@ce@com (m@rio@corr@do m@iii@g oii cro@iii@@ce@com)
Date: Thu, 9 Sep 2021 17:55:53 +0200
Subject: [R] Windows installation failed testing
Message-ID: <00e001d7a593$2c785c60$85691520$@croalliance.com>

Dear all

Our IT has installed R on a Windows PC following the manual instruction.
The installation was validated as in manual ?3.3. "Testing an installation", by using the commands

Sys.setenv(LC_COLLATE = "C", LANGUAGE = "en")
library("tools")
testInstalledBasic("both")
testInstalledPackages(scope = "base", errorsAreFatal = FALSE)
testInstalledPackages(scope = "recommended", errorsAreFatal = FALSE)

All tests passed with the exception of this:

Testing examples for package 'utils'
Running specific tests for package 'utils'
  Running 'charclass.R'
  Running 'completion.R'
  Running 'download.file.R'
  Running 'Sweave-tst.R'
Warning: testing 'utils' failed

What can we do to track the reason of the failure?
Is this expected?
Any hint?

Thanks

Mario


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep  9 19:13:15 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 9 Sep 2021 13:13:15 -0400
Subject: [R] Windows installation failed testing
In-Reply-To: <00e001d7a593$2c785c60$85691520$@croalliance.com>
References: <00e001d7a593$2c785c60$85691520$@croalliance.com>
Message-ID: <09c447e1-c084-f2f2-df2e-daa0f9abe317@gmail.com>

On 09/09/2021 11:55 a.m., mario.corrado at croalliance.com wrote:
> Dear all
> 
> Our IT has installed R on a Windows PC following the manual instruction.
> The installation was validated as in manual ?3.3. "Testing an installation", by using the commands
> 
> Sys.setenv(LC_COLLATE = "C", LANGUAGE = "en")
> library("tools")
> testInstalledBasic("both")
> testInstalledPackages(scope = "base", errorsAreFatal = FALSE)
> testInstalledPackages(scope = "recommended", errorsAreFatal = FALSE)
> 
> All tests passed with the exception of this:
> 
> Testing examples for package 'utils'
> Running specific tests for package 'utils'
>    Running 'charclass.R'
>    Running 'completion.R'
>    Running 'download.file.R'
>    Running 'Sweave-tst.R'
> Warning: testing 'utils' failed
> 
> What can we do to track the reason of the failure?

The current working directory is the default output directory.  You will 
see a directory produced there containing the results of the tests. 
Look in it for filenames like "*.fail".

I just ran the tests just for utils, and it failed on the Sweave test, 
because it couldn't find pdflatex.  If that's the only failure you get, 
don't worry about it, just make sure that pdflatex can be found on the 
PATH when you actually need it.

Duncan Murdoch


From y@ngk@|9999 @end|ng |rom y@hoo@com  Thu Sep  9 21:00:15 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Thu, 9 Sep 2021 19:00:15 +0000 (UTC)
Subject: [R] how to find "first" or "last" record after sort in R
References: <1763582423.2148373.1631214015039.ref@mail.yahoo.com>
Message-ID: <1763582423.2148373.1631214015039@mail.yahoo.com>

Hello List,
Please look at the sample data frame below:

ID? ? ? ? ?date1? ? ? ? ? ? ? date2? ? ? ? ? ? ?date3
1? ? 2015-10-08? ? 2015-12-17? ? 2015-07-23

2? ? 2016-01-16? ? NA? ? ? ? ? ? ? ? ?2015-10-08
3? ? 2016-08-01? ? NA? ? ? ? ? ? ? ? ?2017-01-10
3? ? 2017-01-10? ? NA? ? ? ? ? ? ? ? ?2016-01-16
4? ? 2016-01-19? ? 2016-02-24? ?2016-08-01
5? ? 2016-03-01? ? 2016-03-10? ?2016-01-19
This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5?has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.

the question is, how can I identify the "last" record and set it as NA in date3 column.
Thank you,
Kai
	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep  9 21:20:56 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 9 Sep 2021 12:20:56 -0700
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <1763582423.2148373.1631214015039@mail.yahoo.com>
References: <1763582423.2148373.1631214015039.ref@mail.yahoo.com>
 <1763582423.2148373.1631214015039@mail.yahoo.com>
Message-ID: <CAGxFJbSbFaSgzf8iV9ZS_KWXATCw1-ZZBs0YepSOhvCWQ2uGjQ@mail.gmail.com>

Many ways to do this, of course, but if I understand correctly ?rle
may be the simplest, because you already have the data sorted by ID.

The following little example should give you the idea. It gets the
index of the last row in each id,, which you can then use to assign
NA's or whatever:

> id <- c(1,2,2,2,3,4,5,5)
> last.index <- cumsum(rle(test)$lengths)
> last.index
[1] 1 4 5 6 8

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 9, 2021 at 12:00 PM Kai Yang via R-help
<r-help at r-project.org> wrote:
>
> Hello List,
> Please look at the sample data frame below:
>
> ID         date1              date2             date3
> 1    2015-10-08    2015-12-17    2015-07-23
>
> 2    2016-01-16    NA                 2015-10-08
> 3    2016-08-01    NA                 2017-01-10
> 3    2017-01-10    NA                 2016-01-16
> 4    2016-01-19    2016-02-24   2016-08-01
> 5    2016-03-01    2016-03-10   2016-01-19
> This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5 has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.
>
> the question is, how can I identify the "last" record and set it as NA in date3 column.
> Thank you,
> Kai
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep  9 21:35:12 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 9 Sep 2021 12:35:12 -0700
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <CAGxFJbSbFaSgzf8iV9ZS_KWXATCw1-ZZBs0YepSOhvCWQ2uGjQ@mail.gmail.com>
References: <1763582423.2148373.1631214015039.ref@mail.yahoo.com>
 <1763582423.2148373.1631214015039@mail.yahoo.com>
 <CAGxFJbSbFaSgzf8iV9ZS_KWXATCw1-ZZBs0YepSOhvCWQ2uGjQ@mail.gmail.com>
Message-ID: <CAGxFJbQaDpqeLva7cVvfO2q1PxFbr23Wtx_0AhaGkz9Lr6A59A@mail.gmail.com>

Sorry, that should be

> id <- c(1,2,2,2,3,4,5,5)
> last.index <- cumsum(rle(id)$lengths)
> last.index
[1] 1 4 5 6 8

of course.

Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 9, 2021 at 12:20 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Many ways to do this, of course, but if I understand correctly ?rle
> may be the simplest, because you already have the data sorted by ID.
>
> The following little example should give you the idea. It gets the
> index of the last row in each id,, which you can then use to assign
> NA's or whatever:
>
> > id <- c(1,2,2,2,3,4,5,5)
> > last.index <- cumsum(rle(test)$lengths)
> > last.index
> [1] 1 4 5 6 8
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Sep 9, 2021 at 12:00 PM Kai Yang via R-help
> <r-help at r-project.org> wrote:
> >
> > Hello List,
> > Please look at the sample data frame below:
> >
> > ID         date1              date2             date3
> > 1    2015-10-08    2015-12-17    2015-07-23
> >
> > 2    2016-01-16    NA                 2015-10-08
> > 3    2016-08-01    NA                 2017-01-10
> > 3    2017-01-10    NA                 2016-01-16
> > 4    2016-01-19    2016-02-24   2016-08-01
> > 5    2016-03-01    2016-03-10   2016-01-19
> > This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5 has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.
> >
> > the question is, how can I identify the "last" record and set it as NA in date3 column.
> > Thank you,
> > Kai
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Sep  9 21:43:21 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 9 Sep 2021 15:43:21 -0400
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <1763582423.2148373.1631214015039@mail.yahoo.com>
References: <1763582423.2148373.1631214015039.ref@mail.yahoo.com>
 <1763582423.2148373.1631214015039@mail.yahoo.com>
Message-ID: <00b501d7a5b2$f25a87e0$d70f97a0$@verizon.net>

I am sure there are many good ways to do the task including taking the data.frame out into a list of data.frames and making the change to each by taking the nth row that matches nrow(it) and changing it and then recombining.

What follows are several attempts leading up to one at the end I find is probably the best choice.

I did the following sample demo using the dplyr package in the tidyverse but want to explain. My data was three small groups of 1 then 2 then 3. The second column in each had the same number as the group and it was unique for that group. If the last item can be a duplicate of another item, this method changes too much:

library(dplyr)

mydf <-
  tribble(
    ~grouper, ~val,
    1, 1,
    2, 1,
    2, 2,
    3, 1,
    3, 2,
    3, 3,
  )

mydf %>% group_by(grouper) %>% mutate(val2 = last(val), val=ifelse(val==val2,0,val))

The result is this:

> mydf %>% group_by(grouper) %>% mutate(val2 = last(val), val=ifelse(val==val2,0,val))
# A tibble: 6 x 3
# Groups:   grouper [3]
grouper   val  val2
<dbl> <dbl> <dbl>
  1       1     0     1
2       2     1     2
3       2     0     2
4       3     1     3
5       3     2     3
6       3     0     3

Now obviously this introduced an extra temporary row called val2, which is easily removed by many methods like piping to select(-val2) ...

But that is not needed as a shorter and more direct method is this:

mydf %>% 
  group_by(grouper) %>% 
  mutate(val = ifelse(val==last(val), 
                      0, 
                      val))

But some more research shows the helper functions that make this trivial.

Recall you wanted the last row in each group altered, I think to have an NA in column. I used 0 above but can use NA just as easily or any constant. The functions are:

n() gives the number of rows in the group.
row_number() gives the number of the current row as the functionality is being applied, within that group. The condition being offered is that n() == row_number() so this version surgically changes just the last rows no matter what other rows contain.

mydf %>% 
  group_by(grouper) %>% 
  mutate(val = ifelse(row_number() == n(), 
                      0, 
                      val))

If you have no interest in using a package like this, someone else will likely point you to a way. I suspect using something like split() to make a list of data.frames then applying some functionality to each smaller data.frame to get the result then recombining it back.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Kai Yang via R-help
Sent: Thursday, September 9, 2021 3:00 PM
To: R-help Mailing List <r-help at r-project.org>
Subject: [R] how to find "first" or "last" record after sort in R

Hello List,
Please look at the sample data frame below:

ID         date1              date2             date3
1    2015-10-08    2015-12-17    2015-07-23

2    2016-01-16    NA                 2015-10-08
3    2016-08-01    NA                 2017-01-10
3    2017-01-10    NA                 2016-01-16
4    2016-01-19    2016-02-24   2016-08-01
5    2016-03-01    2016-03-10   2016-01-19 This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5 has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.

the question is, how can I identify the "last" record and set it as NA in date3 column.
Thank you,
Kai
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From therne@u @end|ng |rom m@yo@edu  Fri Sep 10 14:13:45 2021
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Fri, 10 Sep 2021 07:13:45 -0500
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <mailman.364180.1.1631268001.4139.r-help@r-project.org>
References: <mailman.364180.1.1631268001.4139.r-help@r-project.org>
Message-ID: <6315bd$gjsu9b@ironport10.mayo.edu>

I prefer the duplicated() function, since the final code will be clear to a future reader. 
  (Particularly when I am that future reader).

last <- !duplicated(mydata$ID, fromLast=TRUE)  # point to the last ID for each subject
mydata$data3[last] <- NA

Terry T.

(I read the list once a day in digest form, so am always a late reply.)

On 9/10/21 5:00 AM, r-help-request at r-project.org wrote:
> Hello List,
> Please look at the sample data frame below:
> 
> ID? ? ? ? ?date1? ? ? ? ? ? ? date2? ? ? ? ? ? ?date3
> 1? ? 2015-10-08? ? 2015-12-17? ? 2015-07-23
> 
> 2? ? 2016-01-16? ? NA? ? ? ? ? ? ? ? ?2015-10-08
> 3? ? 2016-08-01? ? NA? ? ? ? ? ? ? ? ?2017-01-10
> 3? ? 2017-01-10? ? NA? ? ? ? ? ? ? ? ?2016-01-16
> 4? ? 2016-01-19? ? 2016-02-24? ?2016-08-01
> 5? ? 2016-03-01? ? 2016-03-10? ?2016-01-19
> This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5?has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.
> 
> the question is, how can I identify the "last" record and set it as NA in date3 column.
> Thank you,
> Kai
> 	[[alternative HTML version deleted]]
>


From m@rio@corr@do m@iii@g oii cro@iii@@ce@com  Fri Sep 10 15:51:29 2021
From: m@rio@corr@do m@iii@g oii cro@iii@@ce@com (m@rio@corr@do m@iii@g oii cro@iii@@ce@com)
Date: Fri, 10 Sep 2021 15:51:29 +0200
Subject: [R] Windows installation failed testing
In-Reply-To: <09c447e1-c084-f2f2-df2e-daa0f9abe317@gmail.com>
References: <00e001d7a593$2c785c60$85691520$@croalliance.com>
 <09c447e1-c084-f2f2-df2e-daa0f9abe317@gmail.com>
Message-ID: <020c01d7a64a$f62883c0$e2798b40$@croalliance.com>

Thanks

Unfortunately we checked the PATH and is correctly set
Any other suggestion?
Other Windows users experiment the same problem?
Mario

-----Original Message-----
[cut]

The current working directory is the default output directory.  You will see a directory produced there containing the results of the tests. 
Look in it for filenames like "*.fail".

I just ran the tests just for utils, and it failed on the Sweave test, because it couldn't find pdflatex.  If that's the only failure you get, don't worry about it, just make sure that pdflatex can be found on the PATH when you actually need it.

Duncan Murdoch


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Sep 10 16:43:18 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 10 Sep 2021 16:43:18 +0200
Subject: [R] Handling interrupts in long-running R functions
Message-ID: <20210910164318.65b75378@trisector>

Hello everyone,

I'm writing an R function that may be running for "long" periods of
time (think tens of minutes), and I would like to be able to tell it:
"please stop what you're doing and return the not-yet converged results
as they are for inspection".

The behaviour I'm striving for is

1) User presses interrupt
2) Function handles the interrupt and returns as if the convergence
   test passed
3) By some black magic, the interrupt condition is raised on the
   previous function call level (to avoid the situation where my
   function is called in a loop by some other function and the user
   wants to interrupt the whole process, not just my function).

Is this a good idea? Is (3) even possible? (I guess I could check the
length of sys.parents() and avoid recovering from the interrupt if
called from some other function, but that feels dirty.) Could something
similar be achieved with options(error = recover) and R restarts? Are
there other ways of, well, interrupting the execution of R functions
without changing the semantics of interrupts in R?

I've been working with MATLAB lately (when in Rome, do as Romans
do...), and their idiom for my desired behaviour is "create a plot
window and return when that window is closed", but that doesn't
translate well to R.

-- 
Best regards,
Ivan


From iuke-tier@ey m@iii@g oii uiow@@edu  Fri Sep 10 17:02:27 2021
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Fri, 10 Sep 2021 10:02:27 -0500 (CDT)
Subject: [R] [External]  Handling interrupts in long-running R functions
In-Reply-To: <20210910164318.65b75378@trisector>
References: <20210910164318.65b75378@trisector>
Message-ID: <alpine.DEB.2.22.394.2109100957200.2943@luke-Latitude-7480>

Some variation of this might do it:

     tryCatch(for (i in seq_len(1000000)) Sys.sleep(1),
              interrupt = function(e) i)

If you want the option to inspect and continue you would need to use
withCallingHandlers and invoke a 'resume' restart.

Best,

luke

On Fri, 10 Sep 2021, Ivan Krylov wrote:

> Hello everyone,
>
> I'm writing an R function that may be running for "long" periods of
> time (think tens of minutes), and I would like to be able to tell it:
> "please stop what you're doing and return the not-yet converged results
> as they are for inspection".
>
> The behaviour I'm striving for is
>
> 1) User presses interrupt
> 2) Function handles the interrupt and returns as if the convergence
>   test passed
> 3) By some black magic, the interrupt condition is raised on the
>   previous function call level (to avoid the situation where my
>   function is called in a loop by some other function and the user
>   wants to interrupt the whole process, not just my function).
>
> Is this a good idea? Is (3) even possible? (I guess I could check the
> length of sys.parents() and avoid recovering from the interrupt if
> called from some other function, but that feels dirty.) Could something
> similar be achieved with options(error = recover) and R restarts? Are
> there other ways of, well, interrupting the execution of R functions
> without changing the semantics of interrupts in R?
>
> I've been working with MATLAB lately (when in Rome, do as Romans
> do...), and their idiom for my desired behaviour is "create a plot
> window and return when that window is closed", but that doesn't
> translate well to R.
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From y@ngk@|9999 @end|ng |rom y@hoo@com  Fri Sep 10 17:51:39 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Fri, 10 Sep 2021 15:51:39 +0000 (UTC)
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <6315bd$gjsu9c@ironport10.mayo.edu>
References: <mailman.364180.1.1631268001.4139.r-help@r-project.org>
 <6315bd$gjsu9c@ironport10.mayo.edu>
Message-ID: <1140284697.2617467.1631289099919@mail.yahoo.com>

 Thanks Therneau,?duplicated() function works well. --- Kai
    On Friday, September 10, 2021, 05:13:47 AM PDT, Therneau, Terry M., Ph.D. <therneau at mayo.edu> wrote:  
 
 I prefer the duplicated() function, since the final code will be clear to a future reader. 
? (Particularly when I am that future reader).

last <- !duplicated(mydata$ID, fromLast=TRUE)? # point to the last ID for each subject
mydata$data3[last] <- NA

Terry T.

(I read the list once a day in digest form, so am always a late reply.)

On 9/10/21 5:00 AM, r-help-request at r-project.org wrote:
> Hello List,
> Please look at the sample data frame below:
> 
> ID? ? ? ? ?date1? ? ? ? ? ? ? date2? ? ? ? ? ? ?date3
> 1? ? 2015-10-08? ? 2015-12-17? ? 2015-07-23
> 
> 2? ? 2016-01-16? ? NA? ? ? ? ? ? ? ? ?2015-10-08
> 3? ? 2016-08-01? ? NA? ? ? ? ? ? ? ? ?2017-01-10
> 3? ? 2017-01-10? ? NA? ? ? ? ? ? ? ? ?2016-01-16
> 4? ? 2016-01-19? ? 2016-02-24? ?2016-08-01
> 5? ? 2016-03-01? ? 2016-03-10? ?2016-01-19
> This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5?has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.
> 
> the question is, how can I identify the "last" record and set it as NA in date3 column.
> Thank you,
> Kai
> ??? [[alternative HTML version deleted]]
> 
  
	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Sep 10 18:12:47 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 10 Sep 2021 12:12:47 -0400
Subject: [R] Windows installation failed testing
In-Reply-To: <020c01d7a64a$f62883c0$e2798b40$@croalliance.com>
References: <00e001d7a593$2c785c60$85691520$@croalliance.com>
 <09c447e1-c084-f2f2-df2e-daa0f9abe317@gmail.com>
 <020c01d7a64a$f62883c0$e2798b40$@croalliance.com>
Message-ID: <446a33b9-da95-8dfb-1f81-ae4978c75fec@gmail.com>

On 10/09/2021 9:51 a.m., mario.corrado at croalliance.com wrote:
> Thanks
> 
> Unfortunately we checked the PATH and is correctly set
> Any other suggestion?
> Other Windows users experiment the same problem?

What error did you see in the output dir?

Duncan Murdoch

> Mario
> 
> -----Original Message-----
> [cut]
> 
> The current working directory is the default output directory.  You will see a directory produced there containing the results of the tests.
> Look in it for filenames like "*.fail".
> 
> I just ran the tests just for utils, and it failed on the Sweave test, because it couldn't find pdflatex.  If that's the only failure you get, don't worry about it, just make sure that pdflatex can be found on the PATH when you actually need it.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @v|gro@@ @end|ng |rom ver|zon@net  Fri Sep 10 20:45:32 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Fri, 10 Sep 2021 14:45:32 -0400
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <6315bd$gjsu9b@ironport10.mayo.edu>
References: <mailman.364180.1.1631268001.4139.r-help@r-project.org>
 <6315bd$gjsu9b@ironport10.mayo.edu>
Message-ID: <009f01d7a674$093340d0$1b99c270$@verizon.net>

Excellent function to use, Terry.

 

I note when I used it on a vector (in this case the  first column of a data.frame, it accepted last=TRUE as well a fromlast=TRUE, which I did not see documented. Used on a data.frame, that change fails as function duplicated.data.frame only passes along the fromlast keyword value. ?

 

When given a problem, we sometimes use a hammer when existing functions are already there to help.

 

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Therneau, Terry M., Ph.D. via R-help
Sent: Friday, September 10, 2021 8:14 AM
To: yangkai9999 at yahoo.com; R-help <r-help at R-project.org>
Subject: Re: [R] how to find "first" or "last" record after sort in R

 

I prefer the duplicated() function, since the final code will be clear to a future reader. 

  (Particularly when I am that future reader).

 

last <- !duplicated(mydata$ID, fromLast=TRUE)  # point to the last ID for each subject mydata$data3[last] <- NA

 

Terry T.

 

(I read the list once a day in digest form, so am always a late reply.)

 

On 9/10/21 5:00 AM,  <mailto:r-help-request at r-project.org> r-help-request at r-project.org wrote:

> Hello List,

> Please look at the sample data frame below:

> 

> ID         date1              date2             date3

> 1    2015-10-08    2015-12-17    2015-07-23

> 

> 2    2016-01-16    NA                 2015-10-08

> 3    2016-08-01    NA                 2017-01-10

> 3    2017-01-10    NA                 2016-01-16

> 4    2016-01-19    2016-02-24   2016-08-01

> 5    2016-03-01    2016-03-10   2016-01-19 This data frame was sorted 

> by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5 has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.

> 

> the question is, how can I identify the "last" record and set it as NA in date3 column.

> Thank you,

> Kai

>             [[alternative HTML version deleted]]

> 

 

______________________________________________

 <mailto:R-help at r-project.org> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see  <https://stat.ethz.ch/mailman/listinfo/r-help> https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide  <http://www.R-project.org/posting-guide.html> http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Sat Sep 11 03:20:28 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 11 Sep 2021 13:20:28 +1200
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <1763582423.2148373.1631214015039@mail.yahoo.com>
References: <1763582423.2148373.1631214015039.ref@mail.yahoo.com>
 <1763582423.2148373.1631214015039@mail.yahoo.com>
Message-ID: <CABcYAd+5CXee0fB4r6VFuHd9WLTY2sL5H4-0YchP5O_-AtQuFw@mail.gmail.com>

Let's simplify this to consider a single vector, such as
x <- c(1,1,1,2,2,3,3,3,3,4,5,5,5)
in which equal elements are in contiguous blocks.
> diff(x)
 [1] 0 0 1 0 1 0 0 0 1 1 0 0
Of course, there could be gaps, or the sequence might be descending
instead of ascending.  So
> diff(x) != 0
We are nearly there, but there is a problem.
The last element of the vector is always the last element of a group,
but it will never be reported, because there is no following element
to compare it with.  So
> c(diff(x) != 0, TRUE)
That gives us a logical vector which we can use in indexing.
> w <- c(diff(x) != 0, TRUE)
> x[w] <- NA
> x
 [1]  1  1 NA  2 NA  3  3  3 NA NA  5  5 NA

On Fri, 10 Sept 2021 at 07:00, Kai Yang via R-help <r-help at r-project.org> wrote:
>
> Hello List,
> Please look at the sample data frame below:
>
> ID         date1              date2             date3
> 1    2015-10-08    2015-12-17    2015-07-23
>
> 2    2016-01-16    NA                 2015-10-08
> 3    2016-08-01    NA                 2017-01-10
> 3    2017-01-10    NA                 2016-01-16
> 4    2016-01-19    2016-02-24   2016-08-01
> 5    2016-03-01    2016-03-10   2016-01-19
> This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5 has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.
>
> the question is, how can I identify the "last" record and set it as NA in date3 column.
> Thank you,
> Kai
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sun Sep 12 16:33:25 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sun, 12 Sep 2021 17:33:25 +0300
Subject: [R] Evaluating lazily 'f<-' ?
Message-ID: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>

How can I avoid evaluation?

right = function(x, val) {print("Right");};
padding = function(x) {print("Padding");};
df = data.frame(x=1:5, y = sample(1:5, 5));

### OK
'%=%' = function(x, val) {
 ??? x = substitute(x);
}
right(padding(df)) %=% 1; # but ugly

### Does NOT work
'right<-' = function(x, val) {
 ??? print("Already evaluated and also does not use 'val'");
 ??? x = substitute(x); # is evaluated before
}

right(padding(df)) = 1


Sincerely,


Leonard


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep 13 15:11:01 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 13 Sep 2021 09:11:01 -0400
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
Message-ID: <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>

On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
> How can I avoid evaluation?
> 
> right = function(x, val) {print("Right");};
> padding = function(x) {print("Padding");};
> df = data.frame(x=1:5, y = sample(1:5, 5));
> 
> ### OK
> '%=%' = function(x, val) {
>   ??? x = substitute(x);
> }
> right(padding(df)) %=% 1; # but ugly
> 
> ### Does NOT work
> 'right<-' = function(x, val) {
>   ??? print("Already evaluated and also does not use 'val'");
>   ??? x = substitute(x); # is evaluated before
> }
> 
> right(padding(df)) = 1

That doesn't make sense.  You don't have a `padding<-` function, and yet 
you are trying to call right<- to assign something to padding(df).

I'm not sure about your real intention, but assignment functions by 
their nature need to evaluate the thing they are assigning to, since 
they are designed to modify objects, not create new ones.

To create a new object, just use regular assignment.

Duncan Murdoch


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 13 15:38:00 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 13 Sep 2021 16:38:00 +0300
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
Message-ID: <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>

Hello,


I can include code for "padding<-"as well, but the error is before that, 
namely in 'right<-':

right = function(x, val) {print("Right");};
# more options:
padding = function(x, right, left, top, bottom) {print("Padding");};
'padding<-' = function(x, ...) {print("Padding = ");};
df = data.frame(x=1:5, y = sample(1:5, 5));


### Does NOT work
'right<-' = function(x, val) {
 ? ??? print("Already evaluated and also does not use 'val'");
 ? ??? x = substitute(x); # x was evaluated before
}

right(padding(df)) = 1;


I want to capture the assignment event inside "right<-" and then call 
the function padding() properly.

I haven't thought yet if I should use:

padding(x, right, left, ... other parameters);

or

padding(x, parameter) <- value;


It also depends if I can properly capture the unevaluated expression 
inside "right<-":

'right<-' = function(x, val) {

# x is automatically evaluated when using 'f<-'!

# but not when implementing as '%f%' = function(x, y);

}


Many thanks,


Leonard


On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>> How can I avoid evaluation?
>>
>> right = function(x, val) {print("Right");};
>> padding = function(x) {print("Padding");};
>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>
>> ### OK
>> '%=%' = function(x, val) {
>> ? ??? x = substitute(x);
>> }
>> right(padding(df)) %=% 1; # but ugly
>>
>> ### Does NOT work
>> 'right<-' = function(x, val) {
>> ? ??? print("Already evaluated and also does not use 'val'");
>> ? ??? x = substitute(x); # is evaluated before
>> }
>>
>> right(padding(df)) = 1
>
> That doesn't make sense.? You don't have a `padding<-` function, and 
> yet you are trying to call right<- to assign something to padding(df).
>
> I'm not sure about your real intention, but assignment functions by 
> their nature need to evaluate the thing they are assigning to, since 
> they are designed to modify objects, not create new ones.
>
> To create a new object, just use regular assignment.
>
> Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep 13 15:45:12 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 13 Sep 2021 09:45:12 -0400
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
Message-ID: <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>

On 13/09/2021 9:38 a.m., Leonard Mada wrote:
> Hello,
> 
> 
> I can include code for "padding<-"as well, but the error is before that,
> namely in 'right<-':
> 
> right = function(x, val) {print("Right");};
> # more options:
> padding = function(x, right, left, top, bottom) {print("Padding");};
> 'padding<-' = function(x, ...) {print("Padding = ");};
> df = data.frame(x=1:5, y = sample(1:5, 5));
> 
> 
> ### Does NOT work
> 'right<-' = function(x, val) {
>   ? ??? print("Already evaluated and also does not use 'val'");
>   ? ??? x = substitute(x); # x was evaluated before
> }
> 
> right(padding(df)) = 1;

It "works" (i.e. doesn't generate an error) for me, when I correct your 
typo:  the second argument to `right<-` should be `value`, not `val`.

I'm still not clear whether it does what you want with that fix, because 
I don't really understand what you want.

Duncan Murdoch

> 
> 
> I want to capture the assignment event inside "right<-" and then call
> the function padding() properly.
> 
> I haven't thought yet if I should use:
> 
> padding(x, right, left, ... other parameters);
> 
> or
> 
> padding(x, parameter) <- value;
> 
> 
> It also depends if I can properly capture the unevaluated expression
> inside "right<-":
> 
> 'right<-' = function(x, val) {
> 
> # x is automatically evaluated when using 'f<-'!
> 
> # but not when implementing as '%f%' = function(x, y);
> 
> }
> 
> 
> Many thanks,
> 
> 
> Leonard
> 
> 
> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>>> How can I avoid evaluation?
>>>
>>> right = function(x, val) {print("Right");};
>>> padding = function(x) {print("Padding");};
>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>
>>> ### OK
>>> '%=%' = function(x, val) {
>>>  ? ??? x = substitute(x);
>>> }
>>> right(padding(df)) %=% 1; # but ugly
>>>
>>> ### Does NOT work
>>> 'right<-' = function(x, val) {
>>>  ? ??? print("Already evaluated and also does not use 'val'");
>>>  ? ??? x = substitute(x); # is evaluated before
>>> }
>>>
>>> right(padding(df)) = 1
>>
>> That doesn't make sense.? You don't have a `padding<-` function, and
>> yet you are trying to call right<- to assign something to padding(df).
>>
>> I'm not sure about your real intention, but assignment functions by
>> their nature need to evaluate the thing they are assigning to, since
>> they are designed to modify objects, not create new ones.
>>
>> To create a new object, just use regular assignment.
>>
>> Duncan Murdoch


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 13 17:28:09 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 13 Sep 2021 18:28:09 +0300
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
Message-ID: <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>

I try to clarify the code:


###
right = function(x, val) {print("Right");};
padding = function(x, right, left, top, bottom) {print("Padding");};
'padding<-' = function(x, ...) {print("Padding = ");};
df = data.frame(x=1:5, y = sample(1:5, 5)); # anything

### Does NOT work as expected
'right<-' = function(x, value) {
 ??? print("This line should be the first printed!")
 ??? print("But ERROR: x was already evaluated, which printed \"Padding\"");
 ??? x = substitute(x); # x was already evaluated before substitute();
 ??? return("Nothing"); # do not now what the behaviour should be?
}

right(padding(df)) = 1;

### Output:

[1] "Padding"
[1] "This line should be the first printed!"
[1] "But ERROR: x was already evaluated, which printed \"Padding\""
[1] "Padding = " # How did this happen ???


### Problems:

1.) substitute(x): did not capture the expression;
- the first parameter of 'right<-' was already evaluated, which is not 
the case with '%f%';
Can I avoid evaluating this parameter?
How can I avoid to evaluate it and capture the expression: "right(...)"?


2.) Unexpected
'padding<-' was also called!
I did not know this. Is it feature or bug?
R 4.0.4


Sincerely,


Leonard


On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
> On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>> Hello,
>>
>>
>> I can include code for "padding<-"as well, but the error is before that,
>> namely in 'right<-':
>>
>> right = function(x, val) {print("Right");};
>> # more options:
>> padding = function(x, right, left, top, bottom) {print("Padding");};
>> 'padding<-' = function(x, ...) {print("Padding = ");};
>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>
>>
>> ### Does NOT work
>> 'right<-' = function(x, val) {
>> ? ? ??? print("Already evaluated and also does not use 'val'");
>> ? ? ??? x = substitute(x); # x was evaluated before
>> }
>>
>> right(padding(df)) = 1;
>
> It "works" (i.e. doesn't generate an error) for me, when I correct 
> your typo:? the second argument to `right<-` should be `value`, not 
> `val`.
>
> I'm still not clear whether it does what you want with that fix, 
> because I don't really understand what you want.
>
> Duncan Murdoch
>
>>
>>
>> I want to capture the assignment event inside "right<-" and then call
>> the function padding() properly.
>>
>> I haven't thought yet if I should use:
>>
>> padding(x, right, left, ... other parameters);
>>
>> or
>>
>> padding(x, parameter) <- value;
>>
>>
>> It also depends if I can properly capture the unevaluated expression
>> inside "right<-":
>>
>> 'right<-' = function(x, val) {
>>
>> # x is automatically evaluated when using 'f<-'!
>>
>> # but not when implementing as '%f%' = function(x, y);
>>
>> }
>>
>>
>> Many thanks,
>>
>>
>> Leonard
>>
>>
>> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>>>> How can I avoid evaluation?
>>>>
>>>> right = function(x, val) {print("Right");};
>>>> padding = function(x) {print("Padding");};
>>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>>
>>>> ### OK
>>>> '%=%' = function(x, val) {
>>>> ?? ??? x = substitute(x);
>>>> }
>>>> right(padding(df)) %=% 1; # but ugly
>>>>
>>>> ### Does NOT work
>>>> 'right<-' = function(x, val) {
>>>> ?? ??? print("Already evaluated and also does not use 'val'");
>>>> ?? ??? x = substitute(x); # is evaluated before
>>>> }
>>>>
>>>> right(padding(df)) = 1
>>>
>>> That doesn't make sense.? You don't have a `padding<-` function, and
>>> yet you are trying to call right<- to assign something to padding(df).
>>>
>>> I'm not sure about your real intention, but assignment functions by
>>> their nature need to evaluate the thing they are assigning to, since
>>> they are designed to modify objects, not create new ones.
>>>
>>> To create a new object, just use regular assignment.
>>>
>>> Duncan Murdoch
>


From @kw@|mmo @end|ng |rom gm@||@com  Mon Sep 13 17:45:54 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Mon, 13 Sep 2021 11:45:54 -0400
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
Message-ID: <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>

I think you're trying to do something like:

`padding<-` <- function (x, which, value)
{
    which <- match.arg(which, c("bottom", "left", "top", "right"),
several.ok = TRUE)
    # code to pad to each side here
}

Then you could use it like

df <- data.frame(x=1:5, y = sample(1:5, 5))
padding(df, "right") <- 1

Does that work as expected for you?

On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help <r-help at r-project.org>
wrote:

> I try to clarify the code:
>
>
> ###
> right = function(x, val) {print("Right");};
> padding = function(x, right, left, top, bottom) {print("Padding");};
> 'padding<-' = function(x, ...) {print("Padding = ");};
> df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>
> ### Does NOT work as expected
> 'right<-' = function(x, value) {
>      print("This line should be the first printed!")
>      print("But ERROR: x was already evaluated, which printed
> \"Padding\"");
>      x = substitute(x); # x was already evaluated before substitute();
>      return("Nothing"); # do not now what the behaviour should be?
> }
>
> right(padding(df)) = 1;
>
> ### Output:
>
> [1] "Padding"
> [1] "This line should be the first printed!"
> [1] "But ERROR: x was already evaluated, which printed \"Padding\""
> [1] "Padding = " # How did this happen ???
>
>
> ### Problems:
>
> 1.) substitute(x): did not capture the expression;
> - the first parameter of 'right<-' was already evaluated, which is not
> the case with '%f%';
> Can I avoid evaluating this parameter?
> How can I avoid to evaluate it and capture the expression: "right(...)"?
>
>
> 2.) Unexpected
> 'padding<-' was also called!
> I did not know this. Is it feature or bug?
> R 4.0.4
>
>
> Sincerely,
>
>
> Leonard
>
>
> On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
> > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
> >> Hello,
> >>
> >>
> >> I can include code for "padding<-"as well, but the error is before that,
> >> namely in 'right<-':
> >>
> >> right = function(x, val) {print("Right");};
> >> # more options:
> >> padding = function(x, right, left, top, bottom) {print("Padding");};
> >> 'padding<-' = function(x, ...) {print("Padding = ");};
> >> df = data.frame(x=1:5, y = sample(1:5, 5));
> >>
> >>
> >> ### Does NOT work
> >> 'right<-' = function(x, val) {
> >>         print("Already evaluated and also does not use 'val'");
> >>         x = substitute(x); # x was evaluated before
> >> }
> >>
> >> right(padding(df)) = 1;
> >
> > It "works" (i.e. doesn't generate an error) for me, when I correct
> > your typo:  the second argument to `right<-` should be `value`, not
> > `val`.
> >
> > I'm still not clear whether it does what you want with that fix,
> > because I don't really understand what you want.
> >
> > Duncan Murdoch
> >
> >>
> >>
> >> I want to capture the assignment event inside "right<-" and then call
> >> the function padding() properly.
> >>
> >> I haven't thought yet if I should use:
> >>
> >> padding(x, right, left, ... other parameters);
> >>
> >> or
> >>
> >> padding(x, parameter) <- value;
> >>
> >>
> >> It also depends if I can properly capture the unevaluated expression
> >> inside "right<-":
> >>
> >> 'right<-' = function(x, val) {
> >>
> >> # x is automatically evaluated when using 'f<-'!
> >>
> >> # but not when implementing as '%f%' = function(x, y);
> >>
> >> }
> >>
> >>
> >> Many thanks,
> >>
> >>
> >> Leonard
> >>
> >>
> >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
> >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
> >>>> How can I avoid evaluation?
> >>>>
> >>>> right = function(x, val) {print("Right");};
> >>>> padding = function(x) {print("Padding");};
> >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
> >>>>
> >>>> ### OK
> >>>> '%=%' = function(x, val) {
> >>>>        x = substitute(x);
> >>>> }
> >>>> right(padding(df)) %=% 1; # but ugly
> >>>>
> >>>> ### Does NOT work
> >>>> 'right<-' = function(x, val) {
> >>>>        print("Already evaluated and also does not use 'val'");
> >>>>        x = substitute(x); # is evaluated before
> >>>> }
> >>>>
> >>>> right(padding(df)) = 1
> >>>
> >>> That doesn't make sense.  You don't have a `padding<-` function, and
> >>> yet you are trying to call right<- to assign something to padding(df).
> >>>
> >>> I'm not sure about your real intention, but assignment functions by
> >>> their nature need to evaluate the thing they are assigning to, since
> >>> they are designed to modify objects, not create new ones.
> >>>
> >>> To create a new object, just use regular assignment.
> >>>
> >>> Duncan Murdoch
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 13 18:17:18 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 13 Sep 2021 19:17:18 +0300
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
Message-ID: <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>

Hello Andrew,


this could work. I will think about it.


But I was thinking more generically. Suppose we have a series of functions:
padding(), border(), some_other_style();
Each of these functions has the parameter "right" (or the group of 
parameters c("right", ...)).


Then I could design a function right(FUN) that assigns the value to this 
parameter and evaluates the function FUN().


There are a few ways to do this:

1.) Other parameters as ...
right(FUN, value, ...) = value; and then pass "..." to FUN.
right(value, FUN, ...) = value; # or is this the syntax? (TODO: explore)

2.) Another way:
right(FUN(...other parameters already specified...)) = value;
I wanted to explore this 2nd option: but avoid evaluating FUN, unless 
the parameter "right" is injected into the call.

3.) Option 3:
The option you mentioned.


Independent of the method: there are still weird/unexplained behaviours 
when I try the initial code (see the latest mail with the improved code).


Sincerely,


Leonard


On 9/13/2021 6:45 PM, Andrew Simmons wrote:
> I think you're trying to do something like:
>
> `padding<-` <- function (x, which, value)
> {
> ? ? which <- match.arg(which, c("bottom", "left", "top", "right"), 
> several.ok = TRUE)
> ? ? # code to pad to each side here
> }
>
> Then you could use it like
>
> df <- data.frame(x=1:5, y = sample(1:5, 5))
> padding(df, "right") <- 1
>
> Does that work as expected for you?
>
> On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help 
> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>
>     I try to clarify the code:
>
>
>     ###
>     right = function(x, val) {print("Right");};
>     padding = function(x, right, left, top, bottom) {print("Padding");};
>     'padding<-' = function(x, ...) {print("Padding = ");};
>     df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>
>     ### Does NOT work as expected
>     'right<-' = function(x, value) {
>     ???? print("This line should be the first printed!")
>     ???? print("But ERROR: x was already evaluated, which printed
>     \"Padding\"");
>     ???? x = substitute(x); # x was already evaluated before substitute();
>     ???? return("Nothing"); # do not now what the behaviour should be?
>     }
>
>     right(padding(df)) = 1;
>
>     ### Output:
>
>     [1] "Padding"
>     [1] "This line should be the first printed!"
>     [1] "But ERROR: x was already evaluated, which printed \"Padding\""
>     [1] "Padding = " # How did this happen ???
>
>
>     ### Problems:
>
>     1.) substitute(x): did not capture the expression;
>     - the first parameter of 'right<-' was already evaluated, which is
>     not
>     the case with '%f%';
>     Can I avoid evaluating this parameter?
>     How can I avoid to evaluate it and capture the expression:
>     "right(...)"?
>
>
>     2.) Unexpected
>     'padding<-' was also called!
>     I did not know this. Is it feature or bug?
>     R 4.0.4
>
>
>     Sincerely,
>
>
>     Leonard
>
>
>     On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>     > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>     >> Hello,
>     >>
>     >>
>     >> I can include code for "padding<-"as well, but the error is
>     before that,
>     >> namely in 'right<-':
>     >>
>     >> right = function(x, val) {print("Right");};
>     >> # more options:
>     >> padding = function(x, right, left, top, bottom)
>     {print("Padding");};
>     >> 'padding<-' = function(x, ...) {print("Padding = ");};
>     >> df = data.frame(x=1:5, y = sample(1:5, 5));
>     >>
>     >>
>     >> ### Does NOT work
>     >> 'right<-' = function(x, val) {
>     >> ? ? ??? print("Already evaluated and also does not use 'val'");
>     >> ? ? ??? x = substitute(x); # x was evaluated before
>     >> }
>     >>
>     >> right(padding(df)) = 1;
>     >
>     > It "works" (i.e. doesn't generate an error) for me, when I correct
>     > your typo:? the second argument to `right<-` should be `value`, not
>     > `val`.
>     >
>     > I'm still not clear whether it does what you want with that fix,
>     > because I don't really understand what you want.
>     >
>     > Duncan Murdoch
>     >
>     >>
>     >>
>     >> I want to capture the assignment event inside "right<-" and
>     then call
>     >> the function padding() properly.
>     >>
>     >> I haven't thought yet if I should use:
>     >>
>     >> padding(x, right, left, ... other parameters);
>     >>
>     >> or
>     >>
>     >> padding(x, parameter) <- value;
>     >>
>     >>
>     >> It also depends if I can properly capture the unevaluated
>     expression
>     >> inside "right<-":
>     >>
>     >> 'right<-' = function(x, val) {
>     >>
>     >> # x is automatically evaluated when using 'f<-'!
>     >>
>     >> # but not when implementing as '%f%' = function(x, y);
>     >>
>     >> }
>     >>
>     >>
>     >> Many thanks,
>     >>
>     >>
>     >> Leonard
>     >>
>     >>
>     >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>     >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>     >>>> How can I avoid evaluation?
>     >>>>
>     >>>> right = function(x, val) {print("Right");};
>     >>>> padding = function(x) {print("Padding");};
>     >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>     >>>>
>     >>>> ### OK
>     >>>> '%=%' = function(x, val) {
>     >>>> ?? ??? x = substitute(x);
>     >>>> }
>     >>>> right(padding(df)) %=% 1; # but ugly
>     >>>>
>     >>>> ### Does NOT work
>     >>>> 'right<-' = function(x, val) {
>     >>>> ?? ??? print("Already evaluated and also does not use 'val'");
>     >>>> ?? ??? x = substitute(x); # is evaluated before
>     >>>> }
>     >>>>
>     >>>> right(padding(df)) = 1
>     >>>
>     >>> That doesn't make sense.? You don't have a `padding<-`
>     function, and
>     >>> yet you are trying to call right<- to assign something to
>     padding(df).
>     >>>
>     >>> I'm not sure about your real intention, but assignment
>     functions by
>     >>> their nature need to evaluate the thing they are assigning to,
>     since
>     >>> they are designed to modify objects, not create new ones.
>     >>>
>     >>> To create a new object, just use regular assignment.
>     >>>
>     >>> Duncan Murdoch
>     >
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Mon Sep 13 20:15:17 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Mon, 13 Sep 2021 14:15:17 -0400
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
Message-ID: <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>

R's parser doesn't work the way you're expecting it to. When doing an
assignment like:


padding(right(df)) <- 1


it is broken into small stages. The guide "R Language Definition" claims
that the above would be equivalent to:


`<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))


but that is not correct, and you can tell by using `substitute` as you were
above. There isn't a way to do what you want with the syntax you provided,
you'll have to do something different. You could add a `which` argument to
each style function, and maybe put the code for `match.arg` in a separate
function:


match.which <- function (which)
match.arg(which, c("bottom", "left", "top", "right"), several.ok = TRUE)


padding <- function (x, which)
{
    which <- match.which(which)
    # more code
}


border <- function (x, which)
{
    which <- match.which(which)
    # more code
}


some_other_style <- function (x, which)
{
    which <- match.which(which)
    # more code
}


I hope this helps.

On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada <leo.mada at syonic.eu> wrote:

> Hello Andrew,
>
>
> this could work. I will think about it.
>
> But I was thinking more generically. Suppose we have a series of functions:
> padding(), border(), some_other_style();
> Each of these functions has the parameter "right" (or the group of
> parameters c("right", ...)).
>
>
> Then I could design a function right(FUN) that assigns the value to this
> parameter and evaluates the function FUN().
>
>
> There are a few ways to do this:
> 1.) Other parameters as ...
> right(FUN, value, ...) = value; and then pass "..." to FUN.
> right(value, FUN, ...) = value; # or is this the syntax? (TODO: explore)
>
> 2.) Another way:
> right(FUN(...other parameters already specified...)) = value;
> I wanted to explore this 2nd option: but avoid evaluating FUN, unless the
> parameter "right" is injected into the call.
>
> 3.) Option 3:
> The option you mentioned.
>
>
> Independent of the method: there are still weird/unexplained behaviours
> when I try the initial code (see the latest mail with the improved code).
>
>
> Sincerely,
>
>
> Leonard
>
>
> On 9/13/2021 6:45 PM, Andrew Simmons wrote:
>
> I think you're trying to do something like:
>
> `padding<-` <- function (x, which, value)
> {
>     which <- match.arg(which, c("bottom", "left", "top", "right"),
> several.ok = TRUE)
>     # code to pad to each side here
> }
>
> Then you could use it like
>
> df <- data.frame(x=1:5, y = sample(1:5, 5))
> padding(df, "right") <- 1
>
> Does that work as expected for you?
>
> On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help <r-help at r-project.org>
> wrote:
>
>> I try to clarify the code:
>>
>>
>> ###
>> right = function(x, val) {print("Right");};
>> padding = function(x, right, left, top, bottom) {print("Padding");};
>> 'padding<-' = function(x, ...) {print("Padding = ");};
>> df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>>
>> ### Does NOT work as expected
>> 'right<-' = function(x, value) {
>>      print("This line should be the first printed!")
>>      print("But ERROR: x was already evaluated, which printed
>> \"Padding\"");
>>      x = substitute(x); # x was already evaluated before substitute();
>>      return("Nothing"); # do not now what the behaviour should be?
>> }
>>
>> right(padding(df)) = 1;
>>
>> ### Output:
>>
>> [1] "Padding"
>> [1] "This line should be the first printed!"
>> [1] "But ERROR: x was already evaluated, which printed \"Padding\""
>> [1] "Padding = " # How did this happen ???
>>
>>
>> ### Problems:
>>
>> 1.) substitute(x): did not capture the expression;
>> - the first parameter of 'right<-' was already evaluated, which is not
>> the case with '%f%';
>> Can I avoid evaluating this parameter?
>> How can I avoid to evaluate it and capture the expression: "right(...)"?
>>
>>
>> 2.) Unexpected
>> 'padding<-' was also called!
>> I did not know this. Is it feature or bug?
>> R 4.0.4
>>
>>
>> Sincerely,
>>
>>
>> Leonard
>>
>>
>> On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>> > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>> >> Hello,
>> >>
>> >>
>> >> I can include code for "padding<-"as well, but the error is before
>> that,
>> >> namely in 'right<-':
>> >>
>> >> right = function(x, val) {print("Right");};
>> >> # more options:
>> >> padding = function(x, right, left, top, bottom) {print("Padding");};
>> >> 'padding<-' = function(x, ...) {print("Padding = ");};
>> >> df = data.frame(x=1:5, y = sample(1:5, 5));
>> >>
>> >>
>> >> ### Does NOT work
>> >> 'right<-' = function(x, val) {
>> >>         print("Already evaluated and also does not use 'val'");
>> >>         x = substitute(x); # x was evaluated before
>> >> }
>> >>
>> >> right(padding(df)) = 1;
>> >
>> > It "works" (i.e. doesn't generate an error) for me, when I correct
>> > your typo:  the second argument to `right<-` should be `value`, not
>> > `val`.
>> >
>> > I'm still not clear whether it does what you want with that fix,
>> > because I don't really understand what you want.
>> >
>> > Duncan Murdoch
>> >
>> >>
>> >>
>> >> I want to capture the assignment event inside "right<-" and then call
>> >> the function padding() properly.
>> >>
>> >> I haven't thought yet if I should use:
>> >>
>> >> padding(x, right, left, ... other parameters);
>> >>
>> >> or
>> >>
>> >> padding(x, parameter) <- value;
>> >>
>> >>
>> >> It also depends if I can properly capture the unevaluated expression
>> >> inside "right<-":
>> >>
>> >> 'right<-' = function(x, val) {
>> >>
>> >> # x is automatically evaluated when using 'f<-'!
>> >>
>> >> # but not when implementing as '%f%' = function(x, y);
>> >>
>> >> }
>> >>
>> >>
>> >> Many thanks,
>> >>
>> >>
>> >> Leonard
>> >>
>> >>
>> >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>> >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>> >>>> How can I avoid evaluation?
>> >>>>
>> >>>> right = function(x, val) {print("Right");};
>> >>>> padding = function(x) {print("Padding");};
>> >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>> >>>>
>> >>>> ### OK
>> >>>> '%=%' = function(x, val) {
>> >>>>        x = substitute(x);
>> >>>> }
>> >>>> right(padding(df)) %=% 1; # but ugly
>> >>>>
>> >>>> ### Does NOT work
>> >>>> 'right<-' = function(x, val) {
>> >>>>        print("Already evaluated and also does not use 'val'");
>> >>>>        x = substitute(x); # is evaluated before
>> >>>> }
>> >>>>
>> >>>> right(padding(df)) = 1
>> >>>
>> >>> That doesn't make sense.  You don't have a `padding<-` function, and
>> >>> yet you are trying to call right<- to assign something to padding(df).
>> >>>
>> >>> I'm not sure about your real intention, but assignment functions by
>> >>> their nature need to evaluate the thing they are assigning to, since
>> >>> they are designed to modify objects, not create new ones.
>> >>>
>> >>> To create a new object, just use regular assignment.
>> >>>
>> >>> Duncan Murdoch
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 13 20:42:56 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 13 Sep 2021 21:42:56 +0300
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
 <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
Message-ID: <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>

Hello Andrew,


I try now to understand the evaluation of the expression:

e = expression(r(x) <- 1)

# parameter named "value" seems to be required;
'r<-' = function(x, value) {print("R");}
eval(e, list(x=2))
# [1] "R"

# both versions work
'r<-' = function(value, x) {print("R");}
eval(e, list(x=2))
# [1] "R"


### the Expression
e[[1]][[1]] # "<-", not "r<-"
e[[1]][[2]] # "r(x)"


The evaluation of "e" somehow calls "r<-", but evaluates also the 
argument of r(...). I am still investigating what is actually happening.


Sincerely,


Leonard


On 9/13/2021 9:15 PM, Andrew Simmons wrote:
> R's parser doesn't work the way you're expecting it to. When doing an 
> assignment like:
>
>
> padding(right(df)) <- 1
>
>
> it is broken into small stages. The guide "R Language Definition" 
> claims that the above would be equivalent to:
>
>
> `<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))
>
>
> but that is not correct, and you can tell by using `substitute` as you 
> were above. There isn't a way to do what you want with the syntax you 
> provided, you'll have to do something different. You could add a 
> `which` argument to each style function, and maybe put the code for 
> `match.arg` in a separate function:
>
>
> match.which <- function (which)
> match.arg(which, c("bottom", "left", "top", "right"), several.ok = TRUE)
>
>
> padding <- function (x, which)
> {
> ? ? which <- match.which(which)
> ? ? # more code
> }
>
>
> border <- function (x, which)
> {
> ? ? which <- match.which(which)
> ? ? # more code
> }
>
>
> some_other_style <- function (x, which)
> {
> ? ? which <- match.which(which)
> ? ? # more code
> }
>
>
> I hope this helps.
>
> On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada <leo.mada at syonic.eu 
> <mailto:leo.mada at syonic.eu>> wrote:
>
>     Hello Andrew,
>
>
>     this could work. I will think about it.
>
>
>     But I was thinking more generically. Suppose we have a series of
>     functions:
>     padding(), border(), some_other_style();
>     Each of these functions has the parameter "right" (or the group of
>     parameters c("right", ...)).
>
>
>     Then I could design a function right(FUN) that assigns the value
>     to this parameter and evaluates the function FUN().
>
>
>     There are a few ways to do this:
>
>     1.) Other parameters as ...
>     right(FUN, value, ...) = value; and then pass "..." to FUN.
>     right(value, FUN, ...) = value; # or is this the syntax? (TODO:
>     explore)
>
>     2.) Another way:
>     right(FUN(...other parameters already specified...)) = value;
>     I wanted to explore this 2nd option: but avoid evaluating FUN,
>     unless the parameter "right" is injected into the call.
>
>     3.) Option 3:
>     The option you mentioned.
>
>
>     Independent of the method: there are still weird/unexplained
>     behaviours when I try the initial code (see the latest mail with
>     the improved code).
>
>
>     Sincerely,
>
>
>     Leonard
>
>
>     On 9/13/2021 6:45 PM, Andrew Simmons wrote:
>>     I think you're trying to do something like:
>>
>>     `padding<-` <- function (x, which, value)
>>     {
>>     ? ? which <- match.arg(which, c("bottom", "left", "top",
>>     "right"), several.ok = TRUE)
>>     ? ? # code to pad to each side here
>>     }
>>
>>     Then you could use it like
>>
>>     df <- data.frame(x=1:5, y = sample(1:5, 5))
>>     padding(df, "right") <- 1
>>
>>     Does that work as expected for you?
>>
>>     On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help
>>     <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>
>>         I try to clarify the code:
>>
>>
>>         ###
>>         right = function(x, val) {print("Right");};
>>         padding = function(x, right, left, top, bottom)
>>         {print("Padding");};
>>         'padding<-' = function(x, ...) {print("Padding = ");};
>>         df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>>
>>         ### Does NOT work as expected
>>         'right<-' = function(x, value) {
>>         ???? print("This line should be the first printed!")
>>         ???? print("But ERROR: x was already evaluated, which printed
>>         \"Padding\"");
>>         ???? x = substitute(x); # x was already evaluated before
>>         substitute();
>>         ???? return("Nothing"); # do not now what the behaviour
>>         should be?
>>         }
>>
>>         right(padding(df)) = 1;
>>
>>         ### Output:
>>
>>         [1] "Padding"
>>         [1] "This line should be the first printed!"
>>         [1] "But ERROR: x was already evaluated, which printed
>>         \"Padding\""
>>         [1] "Padding = " # How did this happen ???
>>
>>
>>         ### Problems:
>>
>>         1.) substitute(x): did not capture the expression;
>>         - the first parameter of 'right<-' was already evaluated,
>>         which is not
>>         the case with '%f%';
>>         Can I avoid evaluating this parameter?
>>         How can I avoid to evaluate it and capture the expression:
>>         "right(...)"?
>>
>>
>>         2.) Unexpected
>>         'padding<-' was also called!
>>         I did not know this. Is it feature or bug?
>>         R 4.0.4
>>
>>
>>         Sincerely,
>>
>>
>>         Leonard
>>
>>
>>         On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>>         > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>>         >> Hello,
>>         >>
>>         >>
>>         >> I can include code for "padding<-"as well, but the error
>>         is before that,
>>         >> namely in 'right<-':
>>         >>
>>         >> right = function(x, val) {print("Right");};
>>         >> # more options:
>>         >> padding = function(x, right, left, top, bottom)
>>         {print("Padding");};
>>         >> 'padding<-' = function(x, ...) {print("Padding = ");};
>>         >> df = data.frame(x=1:5, y = sample(1:5, 5));
>>         >>
>>         >>
>>         >> ### Does NOT work
>>         >> 'right<-' = function(x, val) {
>>         >> ? ? ??? print("Already evaluated and also does not use
>>         'val'");
>>         >> ? ? ??? x = substitute(x); # x was evaluated before
>>         >> }
>>         >>
>>         >> right(padding(df)) = 1;
>>         >
>>         > It "works" (i.e. doesn't generate an error) for me, when I
>>         correct
>>         > your typo:? the second argument to `right<-` should be
>>         `value`, not
>>         > `val`.
>>         >
>>         > I'm still not clear whether it does what you want with that
>>         fix,
>>         > because I don't really understand what you want.
>>         >
>>         > Duncan Murdoch
>>         >
>>         >>
>>         >>
>>         >> I want to capture the assignment event inside "right<-"
>>         and then call
>>         >> the function padding() properly.
>>         >>
>>         >> I haven't thought yet if I should use:
>>         >>
>>         >> padding(x, right, left, ... other parameters);
>>         >>
>>         >> or
>>         >>
>>         >> padding(x, parameter) <- value;
>>         >>
>>         >>
>>         >> It also depends if I can properly capture the unevaluated
>>         expression
>>         >> inside "right<-":
>>         >>
>>         >> 'right<-' = function(x, val) {
>>         >>
>>         >> # x is automatically evaluated when using 'f<-'!
>>         >>
>>         >> # but not when implementing as '%f%' = function(x, y);
>>         >>
>>         >> }
>>         >>
>>         >>
>>         >> Many thanks,
>>         >>
>>         >>
>>         >> Leonard
>>         >>
>>         >>
>>         >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>>         >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>>         >>>> How can I avoid evaluation?
>>         >>>>
>>         >>>> right = function(x, val) {print("Right");};
>>         >>>> padding = function(x) {print("Padding");};
>>         >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>         >>>>
>>         >>>> ### OK
>>         >>>> '%=%' = function(x, val) {
>>         >>>> ?? ??? x = substitute(x);
>>         >>>> }
>>         >>>> right(padding(df)) %=% 1; # but ugly
>>         >>>>
>>         >>>> ### Does NOT work
>>         >>>> 'right<-' = function(x, val) {
>>         >>>> ?? ??? print("Already evaluated and also does not use
>>         'val'");
>>         >>>> ?? ??? x = substitute(x); # is evaluated before
>>         >>>> }
>>         >>>>
>>         >>>> right(padding(df)) = 1
>>         >>>
>>         >>> That doesn't make sense.? You don't have a `padding<-`
>>         function, and
>>         >>> yet you are trying to call right<- to assign something to
>>         padding(df).
>>         >>>
>>         >>> I'm not sure about your real intention, but assignment
>>         functions by
>>         >>> their nature need to evaluate the thing they are
>>         assigning to, since
>>         >>> they are designed to modify objects, not create new ones.
>>         >>>
>>         >>> To create a new object, just use regular assignment.
>>         >>>
>>         >>> Duncan Murdoch
>>         >
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>         list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         and provide commented, minimal, self-contained, reproducible
>>         code.
>>

	[[alternative HTML version deleted]]


From y@ngk@|9999 @end|ng |rom y@hoo@com  Mon Sep 13 20:44:31 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Mon, 13 Sep 2021 18:44:31 +0000 (UTC)
Subject: [R] dbWriteTable does not append rows in database
References: <653155647.2729013.1631558671249.ref@mail.yahoo.com>
Message-ID: <653155647.2729013.1631558671249@mail.yahoo.com>

Hi List,
I want to append some rows from R into sql server. So, I submitted the code below. there is not any error message:
dbWriteTable(conn = con,?name = "PMDB._Alias_A", value = try1, overwrite=FALSE, append=TRUE, row.names = FALSE)
But when I try to query the data from the Sql server, I can not find the records were appended. Did I miss something in the code?
Thank you,
Kai

	[[alternative HTML version deleted]]


From ||809 @end|ng |rom nc|@c@  Mon Sep 13 15:33:26 2021
From: ||809 @end|ng |rom nc|@c@ (Brian Lunergan)
Date: Mon, 13 Sep 2021 09:33:26 -0400
Subject: [R] Error msg trying to load R Commander with an older R edition...
Message-ID: <32f8ac2a-a9f0-7379-f499-2fa357b9a723@ncf.ca>

Hi folks:

I'm running Linux Mint 19.3 on my machine. Tried to install a more
recent edition of R but I couldn't seem to get it working so I pulled it
off and went with a good, basic install of the edition available through
the software manager. So... I'm running version 3.4.4.

Mucking about with the attempt at a newer edition seems to have left
some excess baggage behind. When I loaded R Commander and attempted to
run it I received the following error message.

Error: package or namespace load failed for ?car? in readRDS(pfile):
 cannot read workspace version 3 written by R 3.6.2; need R 3.5.0 or newer
During startup - Warning message:
package ?Rcmdr? in options("defaultPackages") was not found

I get a similar message in Rkward when I try to load any more packages.

Is there any solution for this? Any "leftovers" I can track down and
delete? Any assistance would be greatly appreciated.

Kind regards...
-- 
Brian Lunergan
Pavillon Marionville
Russell, Ontario
Canada




-------------- next part --------------
A non-text attachment was scrubbed...
Name: OpenPGP_signature
Type: application/pgp-signature
Size: 665 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210913/e4afd0f5/attachment.sig>

From @d@m@wy@ok|n@k| @end|ng |rom e@em@||  Mon Sep 13 15:40:11 2021
From: @d@m@wy@ok|n@k| @end|ng |rom e@em@|| (=?UTF-8?Q?Adam_Wysoki=c5=84ski?=)
Date: Mon, 13 Sep 2021 15:40:11 +0200
Subject: [R] ggsave() with width only
In-Reply-To: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
Message-ID: <a6477734-fefa-9cba-b7c1-b214858edd83@e.email>

Hi,
Instead of ggsave(), use save_plot() from the "cowplot" package:

library(ggplot2)
library(cowplot)
x <- 1:10
y <- x^2
df <- data.frame(x, y)
p <- ggplot(df, aes(x, y)) + geom_point()
save_plot("/tmp/plot.png", p, base_aspect_ratio = 1, base_width = 5, 
base_height = NULL)

-- 
Regards,
Adam Wysoki?ski

On 9/6/21 16:03, Ivan Calandra wrote:
> Dear useRs,
> 
> I produce several independent ggplot2 plots and I would like to save 
> them to a fixed width (for publications), but the height (and therefore 
> aspect ratio) is different from plot to plot.
> 
> How can I save my plots with ggsave() supplying only a fixed width but 
> without knowing the height nor the aspect ratio? If I specify the width 
> only, the plots are truncated in width because the aspect ratio is not 
> correct.
> 
> Thank you for the tip!
> Ivan
>


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 13 22:09:47 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 13 Sep 2021 13:09:47 -0700
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
 <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
 <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
Message-ID: <CAGxFJbTxVKVQ7zPsY0J-qnLYAHD4V1NRnKJYbasMc3i2p6csOQ@mail.gmail.com>

e = expression(r(x) <- 1)

lapply(e, as.list)
[[1]]
[[1]][[1]]
`<-`

[[1]][[2]]
r(x)

[[1]][[3]]
[1] 1
#######################

lapply(e[[1]], as.list)
[[1]]
[[1]][[1]]
`<-`


[[2]]
[[2]][[1]]
r

[[2]][[2]]
x


[[3]]
[[3]][[1]]
[1] 1

However, I would urge you not to go down this rabbit hole unless you
are comfortable with recursion and have good reason to compute on the
language.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 13, 2021 at 11:43 AM Leonard Mada via R-help
<r-help at r-project.org> wrote:
>
> Hello Andrew,
>
>
> I try now to understand the evaluation of the expression:
>
> e = expression(r(x) <- 1)
>
> # parameter named "value" seems to be required;
> 'r<-' = function(x, value) {print("R");}
> eval(e, list(x=2))
> # [1] "R"
>
> # both versions work
> 'r<-' = function(value, x) {print("R");}
> eval(e, list(x=2))
> # [1] "R"
>
>
> ### the Expression
> e[[1]][[1]] # "<-", not "r<-"
> e[[1]][[2]] # "r(x)"
>
>
> The evaluation of "e" somehow calls "r<-", but evaluates also the
> argument of r(...). I am still investigating what is actually happening.
>
>
> Sincerely,
>
>
> Leonard
>
>
> On 9/13/2021 9:15 PM, Andrew Simmons wrote:
> > R's parser doesn't work the way you're expecting it to. When doing an
> > assignment like:
> >
> >
> > padding(right(df)) <- 1
> >
> >
> > it is broken into small stages. The guide "R Language Definition"
> > claims that the above would be equivalent to:
> >
> >
> > `<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))
> >
> >
> > but that is not correct, and you can tell by using `substitute` as you
> > were above. There isn't a way to do what you want with the syntax you
> > provided, you'll have to do something different. You could add a
> > `which` argument to each style function, and maybe put the code for
> > `match.arg` in a separate function:
> >
> >
> > match.which <- function (which)
> > match.arg(which, c("bottom", "left", "top", "right"), several.ok = TRUE)
> >
> >
> > padding <- function (x, which)
> > {
> >     which <- match.which(which)
> >     # more code
> > }
> >
> >
> > border <- function (x, which)
> > {
> >     which <- match.which(which)
> >     # more code
> > }
> >
> >
> > some_other_style <- function (x, which)
> > {
> >     which <- match.which(which)
> >     # more code
> > }
> >
> >
> > I hope this helps.
> >
> > On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada <leo.mada at syonic.eu
> > <mailto:leo.mada at syonic.eu>> wrote:
> >
> >     Hello Andrew,
> >
> >
> >     this could work. I will think about it.
> >
> >
> >     But I was thinking more generically. Suppose we have a series of
> >     functions:
> >     padding(), border(), some_other_style();
> >     Each of these functions has the parameter "right" (or the group of
> >     parameters c("right", ...)).
> >
> >
> >     Then I could design a function right(FUN) that assigns the value
> >     to this parameter and evaluates the function FUN().
> >
> >
> >     There are a few ways to do this:
> >
> >     1.) Other parameters as ...
> >     right(FUN, value, ...) = value; and then pass "..." to FUN.
> >     right(value, FUN, ...) = value; # or is this the syntax? (TODO:
> >     explore)
> >
> >     2.) Another way:
> >     right(FUN(...other parameters already specified...)) = value;
> >     I wanted to explore this 2nd option: but avoid evaluating FUN,
> >     unless the parameter "right" is injected into the call.
> >
> >     3.) Option 3:
> >     The option you mentioned.
> >
> >
> >     Independent of the method: there are still weird/unexplained
> >     behaviours when I try the initial code (see the latest mail with
> >     the improved code).
> >
> >
> >     Sincerely,
> >
> >
> >     Leonard
> >
> >
> >     On 9/13/2021 6:45 PM, Andrew Simmons wrote:
> >>     I think you're trying to do something like:
> >>
> >>     `padding<-` <- function (x, which, value)
> >>     {
> >>         which <- match.arg(which, c("bottom", "left", "top",
> >>     "right"), several.ok = TRUE)
> >>         # code to pad to each side here
> >>     }
> >>
> >>     Then you could use it like
> >>
> >>     df <- data.frame(x=1:5, y = sample(1:5, 5))
> >>     padding(df, "right") <- 1
> >>
> >>     Does that work as expected for you?
> >>
> >>     On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help
> >>     <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
> >>
> >>         I try to clarify the code:
> >>
> >>
> >>         ###
> >>         right = function(x, val) {print("Right");};
> >>         padding = function(x, right, left, top, bottom)
> >>         {print("Padding");};
> >>         'padding<-' = function(x, ...) {print("Padding = ");};
> >>         df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
> >>
> >>         ### Does NOT work as expected
> >>         'right<-' = function(x, value) {
> >>              print("This line should be the first printed!")
> >>              print("But ERROR: x was already evaluated, which printed
> >>         \"Padding\"");
> >>              x = substitute(x); # x was already evaluated before
> >>         substitute();
> >>              return("Nothing"); # do not now what the behaviour
> >>         should be?
> >>         }
> >>
> >>         right(padding(df)) = 1;
> >>
> >>         ### Output:
> >>
> >>         [1] "Padding"
> >>         [1] "This line should be the first printed!"
> >>         [1] "But ERROR: x was already evaluated, which printed
> >>         \"Padding\""
> >>         [1] "Padding = " # How did this happen ???
> >>
> >>
> >>         ### Problems:
> >>
> >>         1.) substitute(x): did not capture the expression;
> >>         - the first parameter of 'right<-' was already evaluated,
> >>         which is not
> >>         the case with '%f%';
> >>         Can I avoid evaluating this parameter?
> >>         How can I avoid to evaluate it and capture the expression:
> >>         "right(...)"?
> >>
> >>
> >>         2.) Unexpected
> >>         'padding<-' was also called!
> >>         I did not know this. Is it feature or bug?
> >>         R 4.0.4
> >>
> >>
> >>         Sincerely,
> >>
> >>
> >>         Leonard
> >>
> >>
> >>         On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
> >>         > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
> >>         >> Hello,
> >>         >>
> >>         >>
> >>         >> I can include code for "padding<-"as well, but the error
> >>         is before that,
> >>         >> namely in 'right<-':
> >>         >>
> >>         >> right = function(x, val) {print("Right");};
> >>         >> # more options:
> >>         >> padding = function(x, right, left, top, bottom)
> >>         {print("Padding");};
> >>         >> 'padding<-' = function(x, ...) {print("Padding = ");};
> >>         >> df = data.frame(x=1:5, y = sample(1:5, 5));
> >>         >>
> >>         >>
> >>         >> ### Does NOT work
> >>         >> 'right<-' = function(x, val) {
> >>         >>         print("Already evaluated and also does not use
> >>         'val'");
> >>         >>         x = substitute(x); # x was evaluated before
> >>         >> }
> >>         >>
> >>         >> right(padding(df)) = 1;
> >>         >
> >>         > It "works" (i.e. doesn't generate an error) for me, when I
> >>         correct
> >>         > your typo:  the second argument to `right<-` should be
> >>         `value`, not
> >>         > `val`.
> >>         >
> >>         > I'm still not clear whether it does what you want with that
> >>         fix,
> >>         > because I don't really understand what you want.
> >>         >
> >>         > Duncan Murdoch
> >>         >
> >>         >>
> >>         >>
> >>         >> I want to capture the assignment event inside "right<-"
> >>         and then call
> >>         >> the function padding() properly.
> >>         >>
> >>         >> I haven't thought yet if I should use:
> >>         >>
> >>         >> padding(x, right, left, ... other parameters);
> >>         >>
> >>         >> or
> >>         >>
> >>         >> padding(x, parameter) <- value;
> >>         >>
> >>         >>
> >>         >> It also depends if I can properly capture the unevaluated
> >>         expression
> >>         >> inside "right<-":
> >>         >>
> >>         >> 'right<-' = function(x, val) {
> >>         >>
> >>         >> # x is automatically evaluated when using 'f<-'!
> >>         >>
> >>         >> # but not when implementing as '%f%' = function(x, y);
> >>         >>
> >>         >> }
> >>         >>
> >>         >>
> >>         >> Many thanks,
> >>         >>
> >>         >>
> >>         >> Leonard
> >>         >>
> >>         >>
> >>         >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
> >>         >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
> >>         >>>> How can I avoid evaluation?
> >>         >>>>
> >>         >>>> right = function(x, val) {print("Right");};
> >>         >>>> padding = function(x) {print("Padding");};
> >>         >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
> >>         >>>>
> >>         >>>> ### OK
> >>         >>>> '%=%' = function(x, val) {
> >>         >>>>        x = substitute(x);
> >>         >>>> }
> >>         >>>> right(padding(df)) %=% 1; # but ugly
> >>         >>>>
> >>         >>>> ### Does NOT work
> >>         >>>> 'right<-' = function(x, val) {
> >>         >>>>        print("Already evaluated and also does not use
> >>         'val'");
> >>         >>>>        x = substitute(x); # is evaluated before
> >>         >>>> }
> >>         >>>>
> >>         >>>> right(padding(df)) = 1
> >>         >>>
> >>         >>> That doesn't make sense.  You don't have a `padding<-`
> >>         function, and
> >>         >>> yet you are trying to call right<- to assign something to
> >>         padding(df).
> >>         >>>
> >>         >>> I'm not sure about your real intention, but assignment
> >>         functions by
> >>         >>> their nature need to evaluate the thing they are
> >>         assigning to, since
> >>         >>> they are designed to modify objects, not create new ones.
> >>         >>>
> >>         >>> To create a new object, just use regular assignment.
> >>         >>>
> >>         >>> Duncan Murdoch
> >>         >
> >>
> >>         ______________________________________________
> >>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
> >>         list -- To UNSUBSCRIBE and more, see
> >>         https://stat.ethz.ch/mailman/listinfo/r-help
> >>         <https://stat.ethz.ch/mailman/listinfo/r-help>
> >>         PLEASE do read the posting guide
> >>         http://www.R-project.org/posting-guide.html
> >>         <http://www.R-project.org/posting-guide.html>
> >>         and provide commented, minimal, self-contained, reproducible
> >>         code.
> >>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep 13 22:12:21 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 13 Sep 2021 16:12:21 -0400
Subject: [R] 
 Error msg trying to load R Commander with an older R edition...
In-Reply-To: <32f8ac2a-a9f0-7379-f499-2fa357b9a723@ncf.ca>
References: <32f8ac2a-a9f0-7379-f499-2fa357b9a723@ncf.ca>
Message-ID: <4d596d9a-ca18-bdb4-4799-d710f38858f7@gmail.com>

On 13/09/2021 9:33 a.m., Brian Lunergan wrote:
> Hi folks:
> 
> I'm running Linux Mint 19.3 on my machine. Tried to install a more
> recent edition of R but I couldn't seem to get it working so I pulled it
> off and went with a good, basic install of the edition available through
> the software manager. So... I'm running version 3.4.4.
> 
> Mucking about with the attempt at a newer edition seems to have left
> some excess baggage behind. When I loaded R Commander and attempted to
> run it I received the following error message.
> 
> Error: package or namespace load failed for ?car? in readRDS(pfile):
>   cannot read workspace version 3 written by R 3.6.2; need R 3.5.0 or newer
> During startup - Warning message:
> package ?Rcmdr? in options("defaultPackages") was not found

That likely means you still have some files from the newer R in your 
package library.  To find where your library is stored, run .libPaths(). 
  Then look in that directory and remove the "car" directory.  You might 
want to also remove anything else that was installed before you 
installed R 3.4.4, because all the old dirs in there will cause you trouble.

Duncan Murdoch

> 
> I get a similar message in Rkward when I try to load any more packages.
> 
> Is there any solution for this? Any "leftovers" I can track down and
> delete? Any assistance would be greatly appreciated.
> 
> Kind regards...
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 13 22:18:16 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 13 Sep 2021 23:18:16 +0300
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
 <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
 <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
Message-ID: <250d355b-072e-67cb-8bd5-bb012aed20a2@syonic.eu>

Hello,


I have found the evaluation: it is described in the section on 
subsetting. The forced evaluation makes sense for subsetting.


On 9/13/2021 9:42 PM, Leonard Mada wrote:
>
> Hello Andrew,
>
>
> I try now to understand the evaluation of the expression:
>
> e = expression(r(x) <- 1)
>
> # parameter named "value" seems to be required;
> 'r<-' = function(x, value) {print("R");}
> eval(e, list(x=2))
> # [1] "R"
>
> # both versions work
> 'r<-' = function(value, x) {print("R");}
> eval(e, list(x=2))
> # [1] "R"
>
>
> ### the Expression
> e[[1]][[1]] # "<-", not "r<-"
> e[[1]][[2]] # "r(x)"
>
>
> The evaluation of "e" somehow calls "r<-", but evaluates also the 
> argument of r(...). I am still investigating what is actually happening.
>

The forced evaluation is relevant for subsetting, e.g.:
expression(r(x)[3] <- 1)
expression(r(x)[3] <- 1)[[1]][[2]]
# r(x)[3] # the evaluation details are NOT visible in the expression per se;
# Note: indeed, it makes sens to first evaluate r(x) and then to perform 
the subsetting;


However, in the case of a non-subsetted expression:
r(x) <- 1;
It would make sense to evaluate lazily r(x) if no subsetting is involved 
(more precisely "r<-"(x, value) ).

Would this have any impact on the current code?


Sincerely,


Leonard


>
> Sincerely,
>
>
> Leonard
>
>
> On 9/13/2021 9:15 PM, Andrew Simmons wrote:
>> R's parser doesn't work the way you're expecting it to. When doing an 
>> assignment like:
>>
>>
>> padding(right(df)) <- 1
>>
>>
>> it is broken into small stages. The guide "R Language Definition" 
>> claims that the above would be equivalent to:
>>
>>
>> `<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))
>>
>>
>> but that is not correct, and you can tell by using `substitute` as 
>> you were above. There isn't a way to do what you want with the syntax 
>> you provided, you'll have to do something different. You could add a 
>> `which` argument to each style function, and maybe put the code for 
>> `match.arg` in a separate function:
>>
>>
>> match.which <- function (which)
>> match.arg(which, c("bottom", "left", "top", "right"), several.ok = TRUE)
>>
>>
>> padding <- function (x, which)
>> {
>> ? ? which <- match.which(which)
>> ? ? # more code
>> }
>>
>>
>> border <- function (x, which)
>> {
>> ? ? which <- match.which(which)
>> ? ? # more code
>> }
>>
>>
>> some_other_style <- function (x, which)
>> {
>> ? ? which <- match.which(which)
>> ? ? # more code
>> }
>>
>>
>> I hope this helps.
>>
>> On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada <leo.mada at syonic.eu 
>> <mailto:leo.mada at syonic.eu>> wrote:
>>
>>     Hello Andrew,
>>
>>
>>     this could work. I will think about it.
>>
>>
>>     But I was thinking more generically. Suppose we have a series of
>>     functions:
>>     padding(), border(), some_other_style();
>>     Each of these functions has the parameter "right" (or the group
>>     of parameters c("right", ...)).
>>
>>
>>     Then I could design a function right(FUN) that assigns the value
>>     to this parameter and evaluates the function FUN().
>>
>>
>>     There are a few ways to do this:
>>
>>     1.) Other parameters as ...
>>     right(FUN, value, ...) = value; and then pass "..." to FUN.
>>     right(value, FUN, ...) = value; # or is this the syntax? (TODO:
>>     explore)
>>
>>     2.) Another way:
>>     right(FUN(...other parameters already specified...)) = value;
>>     I wanted to explore this 2nd option: but avoid evaluating FUN,
>>     unless the parameter "right" is injected into the call.
>>
>>     3.) Option 3:
>>     The option you mentioned.
>>
>>
>>     Independent of the method: there are still weird/unexplained
>>     behaviours when I try the initial code (see the latest mail with
>>     the improved code).
>>
>>
>>     Sincerely,
>>
>>
>>     Leonard
>>
>>
>>     On 9/13/2021 6:45 PM, Andrew Simmons wrote:
>>>     I think you're trying to do something like:
>>>
>>>     `padding<-` <- function (x, which, value)
>>>     {
>>>     ? ? which <- match.arg(which, c("bottom", "left", "top",
>>>     "right"), several.ok = TRUE)
>>>     ? ? # code to pad to each side here
>>>     }
>>>
>>>     Then you could use it like
>>>
>>>     df <- data.frame(x=1:5, y = sample(1:5, 5))
>>>     padding(df, "right") <- 1
>>>
>>>     Does that work as expected for you?
>>>
>>>     On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help
>>>     <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>>
>>>         I try to clarify the code:
>>>
>>>
>>>         ###
>>>         right = function(x, val) {print("Right");};
>>>         padding = function(x, right, left, top, bottom)
>>>         {print("Padding");};
>>>         'padding<-' = function(x, ...) {print("Padding = ");};
>>>         df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>>>
>>>         ### Does NOT work as expected
>>>         'right<-' = function(x, value) {
>>>         ???? print("This line should be the first printed!")
>>>         ???? print("But ERROR: x was already evaluated, which
>>>         printed \"Padding\"");
>>>         ???? x = substitute(x); # x was already evaluated before
>>>         substitute();
>>>         ???? return("Nothing"); # do not now what the behaviour
>>>         should be?
>>>         }
>>>
>>>         right(padding(df)) = 1;
>>>
>>>         ### Output:
>>>
>>>         [1] "Padding"
>>>         [1] "This line should be the first printed!"
>>>         [1] "But ERROR: x was already evaluated, which printed
>>>         \"Padding\""
>>>         [1] "Padding = " # How did this happen ???
>>>
>>>
>>>         ### Problems:
>>>
>>>         1.) substitute(x): did not capture the expression;
>>>         - the first parameter of 'right<-' was already evaluated,
>>>         which is not
>>>         the case with '%f%';
>>>         Can I avoid evaluating this parameter?
>>>         How can I avoid to evaluate it and capture the expression:
>>>         "right(...)"?
>>>
>>>
>>>         2.) Unexpected
>>>         'padding<-' was also called!
>>>         I did not know this. Is it feature or bug?
>>>         R 4.0.4
>>>
>>>
>>>         Sincerely,
>>>
>>>
>>>         Leonard
>>>
>>>
>>>         On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>>>         > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>>>         >> Hello,
>>>         >>
>>>         >>
>>>         >> I can include code for "padding<-"as well, but the error
>>>         is before that,
>>>         >> namely in 'right<-':
>>>         >>
>>>         >> right = function(x, val) {print("Right");};
>>>         >> # more options:
>>>         >> padding = function(x, right, left, top, bottom)
>>>         {print("Padding");};
>>>         >> 'padding<-' = function(x, ...) {print("Padding = ");};
>>>         >> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>         >>
>>>         >>
>>>         >> ### Does NOT work
>>>         >> 'right<-' = function(x, val) {
>>>         >> ? ? ??? print("Already evaluated and also does not use
>>>         'val'");
>>>         >> ? ? ??? x = substitute(x); # x was evaluated before
>>>         >> }
>>>         >>
>>>         >> right(padding(df)) = 1;
>>>         >
>>>         > It "works" (i.e. doesn't generate an error) for me, when I
>>>         correct
>>>         > your typo:? the second argument to `right<-` should be
>>>         `value`, not
>>>         > `val`.
>>>         >
>>>         > I'm still not clear whether it does what you want with
>>>         that fix,
>>>         > because I don't really understand what you want.
>>>         >
>>>         > Duncan Murdoch
>>>         >
>>>         >>
>>>         >>
>>>         >> I want to capture the assignment event inside "right<-"
>>>         and then call
>>>         >> the function padding() properly.
>>>         >>
>>>         >> I haven't thought yet if I should use:
>>>         >>
>>>         >> padding(x, right, left, ... other parameters);
>>>         >>
>>>         >> or
>>>         >>
>>>         >> padding(x, parameter) <- value;
>>>         >>
>>>         >>
>>>         >> It also depends if I can properly capture the unevaluated
>>>         expression
>>>         >> inside "right<-":
>>>         >>
>>>         >> 'right<-' = function(x, val) {
>>>         >>
>>>         >> # x is automatically evaluated when using 'f<-'!
>>>         >>
>>>         >> # but not when implementing as '%f%' = function(x, y);
>>>         >>
>>>         >> }
>>>         >>
>>>         >>
>>>         >> Many thanks,
>>>         >>
>>>         >>
>>>         >> Leonard
>>>         >>
>>>         >>
>>>         >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>>>         >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>>>         >>>> How can I avoid evaluation?
>>>         >>>>
>>>         >>>> right = function(x, val) {print("Right");};
>>>         >>>> padding = function(x) {print("Padding");};
>>>         >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>         >>>>
>>>         >>>> ### OK
>>>         >>>> '%=%' = function(x, val) {
>>>         >>>> ?? ??? x = substitute(x);
>>>         >>>> }
>>>         >>>> right(padding(df)) %=% 1; # but ugly
>>>         >>>>
>>>         >>>> ### Does NOT work
>>>         >>>> 'right<-' = function(x, val) {
>>>         >>>> ?? ??? print("Already evaluated and also does not use
>>>         'val'");
>>>         >>>> ?? ??? x = substitute(x); # is evaluated before
>>>         >>>> }
>>>         >>>>
>>>         >>>> right(padding(df)) = 1
>>>         >>>
>>>         >>> That doesn't make sense.? You don't have a `padding<-`
>>>         function, and
>>>         >>> yet you are trying to call right<- to assign something
>>>         to padding(df).
>>>         >>>
>>>         >>> I'm not sure about your real intention, but assignment
>>>         functions by
>>>         >>> their nature need to evaluate the thing they are
>>>         assigning to, since
>>>         >>> they are designed to modify objects, not create new ones.
>>>         >>>
>>>         >>> To create a new object, just use regular assignment.
>>>         >>>
>>>         >>> Duncan Murdoch
>>>         >
>>>
>>>         ______________________________________________
>>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>>         list -- To UNSUBSCRIBE and more, see
>>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>         PLEASE do read the posting guide
>>>         http://www.R-project.org/posting-guide.html
>>>         <http://www.R-project.org/posting-guide.html>
>>>         and provide commented, minimal, self-contained, reproducible
>>>         code.
>>>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Mon Sep 13 22:28:55 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Mon, 13 Sep 2021 16:28:55 -0400
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <250d355b-072e-67cb-8bd5-bb012aed20a2@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
 <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
 <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
 <250d355b-072e-67cb-8bd5-bb012aed20a2@syonic.eu>
Message-ID: <CAPcHnpSR=ZtCk=bX=NkFWO8wNc4hks07x+eGJU+Z4QA0+cJcjg@mail.gmail.com>

In the example you gave : r(x) <- 1
r(x) is never evaluated, the above calls `r<-`,
in fact r does not even have to be an existing function.

On Mon, Sep 13, 2021, 16:18 Leonard Mada <leo.mada at syonic.eu> wrote:

> Hello,
>
>
> I have found the evaluation: it is described in the section on subsetting.
> The forced evaluation makes sense for subsetting.
>
>
> On 9/13/2021 9:42 PM, Leonard Mada wrote:
>
> Hello Andrew,
>
>
> I try now to understand the evaluation of the expression:
>
> e = expression(r(x) <- 1)
>
> # parameter named "value" seems to be required;
> 'r<-' = function(x, value) {print("R");}
> eval(e, list(x=2))
> # [1] "R"
>
> # both versions work
> 'r<-' = function(value, x) {print("R");}
> eval(e, list(x=2))
> # [1] "R"
>
>
> ### the Expression
> e[[1]][[1]] # "<-", not "r<-"
> e[[1]][[2]] # "r(x)"
>
>
> The evaluation of "e" somehow calls "r<-", but evaluates also the argument
> of r(...). I am still investigating what is actually happening.
>
>
> The forced evaluation is relevant for subsetting, e.g.:
> expression(r(x)[3] <- 1)
> expression(r(x)[3] <- 1)[[1]][[2]]
> # r(x)[3] # the evaluation details are NOT visible in the expression per
> se;
> # Note: indeed, it makes sens to first evaluate r(x) and then to perform
> the subsetting;
>
>
> However, in the case of a non-subsetted expression:
> r(x) <- 1;
> It would make sense to evaluate lazily r(x) if no subsetting is involved
> (more precisely "r<-"(x, value) ).
>
> Would this have any impact on the current code?
>
>
> Sincerely,
>
>
> Leonard
>
>
>
> Sincerely,
>
>
> Leonard
>
>
> On 9/13/2021 9:15 PM, Andrew Simmons wrote:
>
> R's parser doesn't work the way you're expecting it to. When doing an
> assignment like:
>
>
> padding(right(df)) <- 1
>
>
> it is broken into small stages. The guide "R Language Definition" claims
> that the above would be equivalent to:
>
>
> `<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))
>
>
> but that is not correct, and you can tell by using `substitute` as you
> were above. There isn't a way to do what you want with the syntax you
> provided, you'll have to do something different. You could add a `which`
> argument to each style function, and maybe put the code for `match.arg` in
> a separate function:
>
>
> match.which <- function (which)
> match.arg(which, c("bottom", "left", "top", "right"), several.ok = TRUE)
>
>
> padding <- function (x, which)
> {
>     which <- match.which(which)
>     # more code
> }
>
>
> border <- function (x, which)
> {
>     which <- match.which(which)
>     # more code
> }
>
>
> some_other_style <- function (x, which)
> {
>     which <- match.which(which)
>     # more code
> }
>
>
> I hope this helps.
>
> On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada <leo.mada at syonic.eu> wrote:
>
>> Hello Andrew,
>>
>>
>> this could work. I will think about it.
>>
>> But I was thinking more generically. Suppose we have a series of
>> functions:
>> padding(), border(), some_other_style();
>> Each of these functions has the parameter "right" (or the group of
>> parameters c("right", ...)).
>>
>>
>> Then I could design a function right(FUN) that assigns the value to this
>> parameter and evaluates the function FUN().
>>
>>
>> There are a few ways to do this:
>> 1.) Other parameters as ...
>> right(FUN, value, ...) = value; and then pass "..." to FUN.
>> right(value, FUN, ...) = value; # or is this the syntax? (TODO: explore)
>>
>> 2.) Another way:
>> right(FUN(...other parameters already specified...)) = value;
>> I wanted to explore this 2nd option: but avoid evaluating FUN, unless the
>> parameter "right" is injected into the call.
>>
>> 3.) Option 3:
>> The option you mentioned.
>>
>>
>> Independent of the method: there are still weird/unexplained behaviours
>> when I try the initial code (see the latest mail with the improved code).
>>
>>
>> Sincerely,
>>
>>
>> Leonard
>>
>>
>> On 9/13/2021 6:45 PM, Andrew Simmons wrote:
>>
>> I think you're trying to do something like:
>>
>> `padding<-` <- function (x, which, value)
>> {
>>     which <- match.arg(which, c("bottom", "left", "top", "right"),
>> several.ok = TRUE)
>>     # code to pad to each side here
>> }
>>
>> Then you could use it like
>>
>> df <- data.frame(x=1:5, y = sample(1:5, 5))
>> padding(df, "right") <- 1
>>
>> Does that work as expected for you?
>>
>> On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help <r-help at r-project.org>
>> wrote:
>>
>>> I try to clarify the code:
>>>
>>>
>>> ###
>>> right = function(x, val) {print("Right");};
>>> padding = function(x, right, left, top, bottom) {print("Padding");};
>>> 'padding<-' = function(x, ...) {print("Padding = ");};
>>> df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>>>
>>> ### Does NOT work as expected
>>> 'right<-' = function(x, value) {
>>>      print("This line should be the first printed!")
>>>      print("But ERROR: x was already evaluated, which printed
>>> \"Padding\"");
>>>      x = substitute(x); # x was already evaluated before substitute();
>>>      return("Nothing"); # do not now what the behaviour should be?
>>> }
>>>
>>> right(padding(df)) = 1;
>>>
>>> ### Output:
>>>
>>> [1] "Padding"
>>> [1] "This line should be the first printed!"
>>> [1] "But ERROR: x was already evaluated, which printed \"Padding\""
>>> [1] "Padding = " # How did this happen ???
>>>
>>>
>>> ### Problems:
>>>
>>> 1.) substitute(x): did not capture the expression;
>>> - the first parameter of 'right<-' was already evaluated, which is not
>>> the case with '%f%';
>>> Can I avoid evaluating this parameter?
>>> How can I avoid to evaluate it and capture the expression: "right(...)"?
>>>
>>>
>>> 2.) Unexpected
>>> 'padding<-' was also called!
>>> I did not know this. Is it feature or bug?
>>> R 4.0.4
>>>
>>>
>>> Sincerely,
>>>
>>>
>>> Leonard
>>>
>>>
>>> On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>>> > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>>> >> Hello,
>>> >>
>>> >>
>>> >> I can include code for "padding<-"as well, but the error is before
>>> that,
>>> >> namely in 'right<-':
>>> >>
>>> >> right = function(x, val) {print("Right");};
>>> >> # more options:
>>> >> padding = function(x, right, left, top, bottom) {print("Padding");};
>>> >> 'padding<-' = function(x, ...) {print("Padding = ");};
>>> >> df = data.frame(x=1:5, y = sample(1:5, 5));
>>> >>
>>> >>
>>> >> ### Does NOT work
>>> >> 'right<-' = function(x, val) {
>>> >>         print("Already evaluated and also does not use 'val'");
>>> >>         x = substitute(x); # x was evaluated before
>>> >> }
>>> >>
>>> >> right(padding(df)) = 1;
>>> >
>>> > It "works" (i.e. doesn't generate an error) for me, when I correct
>>> > your typo:  the second argument to `right<-` should be `value`, not
>>> > `val`.
>>> >
>>> > I'm still not clear whether it does what you want with that fix,
>>> > because I don't really understand what you want.
>>> >
>>> > Duncan Murdoch
>>> >
>>> >>
>>> >>
>>> >> I want to capture the assignment event inside "right<-" and then call
>>> >> the function padding() properly.
>>> >>
>>> >> I haven't thought yet if I should use:
>>> >>
>>> >> padding(x, right, left, ... other parameters);
>>> >>
>>> >> or
>>> >>
>>> >> padding(x, parameter) <- value;
>>> >>
>>> >>
>>> >> It also depends if I can properly capture the unevaluated expression
>>> >> inside "right<-":
>>> >>
>>> >> 'right<-' = function(x, val) {
>>> >>
>>> >> # x is automatically evaluated when using 'f<-'!
>>> >>
>>> >> # but not when implementing as '%f%' = function(x, y);
>>> >>
>>> >> }
>>> >>
>>> >>
>>> >> Many thanks,
>>> >>
>>> >>
>>> >> Leonard
>>> >>
>>> >>
>>> >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>>> >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>>> >>>> How can I avoid evaluation?
>>> >>>>
>>> >>>> right = function(x, val) {print("Right");};
>>> >>>> padding = function(x) {print("Padding");};
>>> >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>> >>>>
>>> >>>> ### OK
>>> >>>> '%=%' = function(x, val) {
>>> >>>>        x = substitute(x);
>>> >>>> }
>>> >>>> right(padding(df)) %=% 1; # but ugly
>>> >>>>
>>> >>>> ### Does NOT work
>>> >>>> 'right<-' = function(x, val) {
>>> >>>>        print("Already evaluated and also does not use 'val'");
>>> >>>>        x = substitute(x); # is evaluated before
>>> >>>> }
>>> >>>>
>>> >>>> right(padding(df)) = 1
>>> >>>
>>> >>> That doesn't make sense.  You don't have a `padding<-` function, and
>>> >>> yet you are trying to call right<- to assign something to
>>> padding(df).
>>> >>>
>>> >>> I'm not sure about your real intention, but assignment functions by
>>> >>> their nature need to evaluate the thing they are assigning to, since
>>> >>> they are designed to modify objects, not create new ones.
>>> >>>
>>> >>> To create a new object, just use regular assignment.
>>> >>>
>>> >>> Duncan Murdoch
>>> >
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 13 22:33:19 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 13 Sep 2021 23:33:19 +0300
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <CAPcHnpSR=ZtCk=bX=NkFWO8wNc4hks07x+eGJU+Z4QA0+cJcjg@mail.gmail.com>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
 <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
 <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
 <250d355b-072e-67cb-8bd5-bb012aed20a2@syonic.eu>
 <CAPcHnpSR=ZtCk=bX=NkFWO8wNc4hks07x+eGJU+Z4QA0+cJcjg@mail.gmail.com>
Message-ID: <12584b25-8150-4002-4eee-b4bc21525996@syonic.eu>


On 9/13/2021 11:28 PM, Andrew Simmons wrote:
> In the example you gave : r(x) <- 1
> r(x) is never evaluated, the above calls `r<-`,
> in fact r does not even have to be an existing function.


I meant:

'*tmp*' <- x; # "x" is evaluated here;

'r<-' is called after this step, which makes sense in the case of 
subsetting;


But I am wondering if changing this behaviour, when NO subsetting is 
performed, would have any impact.

e.g. names(x) = c("some names");

# would it have any impact to skip the evaluation of "x" and call directly:

'names<-'(x, value);


Leonard


>
> On Mon, Sep 13, 2021, 16:18 Leonard Mada <leo.mada at syonic.eu 
> <mailto:leo.mada at syonic.eu>> wrote:
>
>     Hello,
>
>
>     I have found the evaluation: it is described in the section on
>     subsetting. The forced evaluation makes sense for subsetting.
>
>
>     On 9/13/2021 9:42 PM, Leonard Mada wrote:
>>
>>     Hello Andrew,
>>
>>
>>     I try now to understand the evaluation of the expression:
>>
>>     e = expression(r(x) <- 1)
>>
>>     # parameter named "value" seems to be required;
>>     'r<-' = function(x, value) {print("R");}
>>     eval(e, list(x=2))
>>     # [1] "R"
>>
>>     # both versions work
>>     'r<-' = function(value, x) {print("R");}
>>     eval(e, list(x=2))
>>     # [1] "R"
>>
>>
>>     ### the Expression
>>     e[[1]][[1]] # "<-", not "r<-"
>>     e[[1]][[2]] # "r(x)"
>>
>>
>>     The evaluation of "e" somehow calls "r<-", but evaluates also the
>>     argument of r(...). I am still investigating what is actually
>>     happening.
>>
>
>     The forced evaluation is relevant for subsetting, e.g.:
>     expression(r(x)[3] <- 1)
>     expression(r(x)[3] <- 1)[[1]][[2]]
>     # r(x)[3] # the evaluation details are NOT visible in the
>     expression per se;
>     # Note: indeed, it makes sens to first evaluate r(x) and then to
>     perform the subsetting;
>
>
>     However, in the case of a non-subsetted expression:
>     r(x) <- 1;
>     It would make sense to evaluate lazily r(x) if no subsetting is
>     involved (more precisely "r<-"(x, value) ).
>
>     Would this have any impact on the current code?
>
>
>     Sincerely,
>
>
>     Leonard
>
>
>>
>>     Sincerely,
>>
>>
>>     Leonard
>>
>>
>>     On 9/13/2021 9:15 PM, Andrew Simmons wrote:
>>>     R's parser doesn't work the way you're expecting it to. When
>>>     doing an assignment like:
>>>
>>>
>>>     padding(right(df)) <- 1
>>>
>>>
>>>     it is broken into small stages. The guide "R Language
>>>     Definition" claims that the above would be equivalent to:
>>>
>>>
>>>     `<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))
>>>
>>>
>>>     but that is not correct, and you can tell by using `substitute`
>>>     as you were above. There isn't a way to do what you want with
>>>     the syntax you provided, you'll have to do something different.
>>>     You could add a `which` argument to each style function, and
>>>     maybe put the code for `match.arg` in a separate function:
>>>
>>>
>>>     match.which <- function (which)
>>>     match.arg(which, c("bottom", "left", "top", "right"), several.ok
>>>     = TRUE)
>>>
>>>
>>>     padding <- function (x, which)
>>>     {
>>>     ? ? which <- match.which(which)
>>>     ? ? # more code
>>>     }
>>>
>>>
>>>     border <- function (x, which)
>>>     {
>>>     ? ? which <- match.which(which)
>>>     ? ? # more code
>>>     }
>>>
>>>
>>>     some_other_style <- function (x, which)
>>>     {
>>>     ? ? which <- match.which(which)
>>>     ? ? # more code
>>>     }
>>>
>>>
>>>     I hope this helps.
>>>
>>>     On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada
>>>     <leo.mada at syonic.eu <mailto:leo.mada at syonic.eu>> wrote:
>>>
>>>         Hello Andrew,
>>>
>>>
>>>         this could work. I will think about it.
>>>
>>>
>>>         But I was thinking more generically. Suppose we have a
>>>         series of functions:
>>>         padding(), border(), some_other_style();
>>>         Each of these functions has the parameter "right" (or the
>>>         group of parameters c("right", ...)).
>>>
>>>
>>>         Then I could design a function right(FUN) that assigns the
>>>         value to this parameter and evaluates the function FUN().
>>>
>>>
>>>         There are a few ways to do this:
>>>
>>>         1.) Other parameters as ...
>>>         right(FUN, value, ...) = value; and then pass "..." to FUN.
>>>         right(value, FUN, ...) = value; # or is this the syntax?
>>>         (TODO: explore)
>>>
>>>         2.) Another way:
>>>         right(FUN(...other parameters already specified...)) = value;
>>>         I wanted to explore this 2nd option: but avoid evaluating
>>>         FUN, unless the parameter "right" is injected into the call.
>>>
>>>         3.) Option 3:
>>>         The option you mentioned.
>>>
>>>
>>>         Independent of the method: there are still weird/unexplained
>>>         behaviours when I try the initial code (see the latest mail
>>>         with the improved code).
>>>
>>>
>>>         Sincerely,
>>>
>>>
>>>         Leonard
>>>
>>>
>>>         On 9/13/2021 6:45 PM, Andrew Simmons wrote:
>>>>         I think you're trying to do something like:
>>>>
>>>>         `padding<-` <- function (x, which, value)
>>>>         {
>>>>         ? ? which <- match.arg(which, c("bottom", "left", "top",
>>>>         "right"), several.ok = TRUE)
>>>>         ? ? # code to pad to each side here
>>>>         }
>>>>
>>>>         Then you could use it like
>>>>
>>>>         df <- data.frame(x=1:5, y = sample(1:5, 5))
>>>>         padding(df, "right") <- 1
>>>>
>>>>         Does that work as expected for you?
>>>>
>>>>         On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help
>>>>         <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>>>
>>>>             I try to clarify the code:
>>>>
>>>>
>>>>             ###
>>>>             right = function(x, val) {print("Right");};
>>>>             padding = function(x, right, left, top, bottom)
>>>>             {print("Padding");};
>>>>             'padding<-' = function(x, ...) {print("Padding = ");};
>>>>             df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>>>>
>>>>             ### Does NOT work as expected
>>>>             'right<-' = function(x, value) {
>>>>             ???? print("This line should be the first printed!")
>>>>             ???? print("But ERROR: x was already evaluated, which
>>>>             printed \"Padding\"");
>>>>             ???? x = substitute(x); # x was already evaluated
>>>>             before substitute();
>>>>             ???? return("Nothing"); # do not now what the behaviour
>>>>             should be?
>>>>             }
>>>>
>>>>             right(padding(df)) = 1;
>>>>
>>>>             ### Output:
>>>>
>>>>             [1] "Padding"
>>>>             [1] "This line should be the first printed!"
>>>>             [1] "But ERROR: x was already evaluated, which printed
>>>>             \"Padding\""
>>>>             [1] "Padding = " # How did this happen ???
>>>>
>>>>
>>>>             ### Problems:
>>>>
>>>>             1.) substitute(x): did not capture the expression;
>>>>             - the first parameter of 'right<-' was already
>>>>             evaluated, which is not
>>>>             the case with '%f%';
>>>>             Can I avoid evaluating this parameter?
>>>>             How can I avoid to evaluate it and capture the
>>>>             expression: "right(...)"?
>>>>
>>>>
>>>>             2.) Unexpected
>>>>             'padding<-' was also called!
>>>>             I did not know this. Is it feature or bug?
>>>>             R 4.0.4
>>>>
>>>>
>>>>             Sincerely,
>>>>
>>>>
>>>>             Leonard
>>>>
>>>>
>>>>             On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>>>>             > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>>>>             >> Hello,
>>>>             >>
>>>>             >>
>>>>             >> I can include code for "padding<-"as well, but the
>>>>             error is before that,
>>>>             >> namely in 'right<-':
>>>>             >>
>>>>             >> right = function(x, val) {print("Right");};
>>>>             >> # more options:
>>>>             >> padding = function(x, right, left, top, bottom)
>>>>             {print("Padding");};
>>>>             >> 'padding<-' = function(x, ...) {print("Padding = ");};
>>>>             >> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>>             >>
>>>>             >>
>>>>             >> ### Does NOT work
>>>>             >> 'right<-' = function(x, val) {
>>>>             >> ? ? ??? print("Already evaluated and also does not
>>>>             use 'val'");
>>>>             >> ? ? ??? x = substitute(x); # x was evaluated before
>>>>             >> }
>>>>             >>
>>>>             >> right(padding(df)) = 1;
>>>>             >
>>>>             > It "works" (i.e. doesn't generate an error) for me,
>>>>             when I correct
>>>>             > your typo:? the second argument to `right<-` should
>>>>             be `value`, not
>>>>             > `val`.
>>>>             >
>>>>             > I'm still not clear whether it does what you want
>>>>             with that fix,
>>>>             > because I don't really understand what you want.
>>>>             >
>>>>             > Duncan Murdoch
>>>>             >
>>>>             >>
>>>>             >>
>>>>             >> I want to capture the assignment event inside
>>>>             "right<-" and then call
>>>>             >> the function padding() properly.
>>>>             >>
>>>>             >> I haven't thought yet if I should use:
>>>>             >>
>>>>             >> padding(x, right, left, ... other parameters);
>>>>             >>
>>>>             >> or
>>>>             >>
>>>>             >> padding(x, parameter) <- value;
>>>>             >>
>>>>             >>
>>>>             >> It also depends if I can properly capture the
>>>>             unevaluated expression
>>>>             >> inside "right<-":
>>>>             >>
>>>>             >> 'right<-' = function(x, val) {
>>>>             >>
>>>>             >> # x is automatically evaluated when using 'f<-'!
>>>>             >>
>>>>             >> # but not when implementing as '%f%' = function(x, y);
>>>>             >>
>>>>             >> }
>>>>             >>
>>>>             >>
>>>>             >> Many thanks,
>>>>             >>
>>>>             >>
>>>>             >> Leonard
>>>>             >>
>>>>             >>
>>>>             >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>>>>             >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help
>>>>             wrote:
>>>>             >>>> How can I avoid evaluation?
>>>>             >>>>
>>>>             >>>> right = function(x, val) {print("Right");};
>>>>             >>>> padding = function(x) {print("Padding");};
>>>>             >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>>             >>>>
>>>>             >>>> ### OK
>>>>             >>>> '%=%' = function(x, val) {
>>>>             >>>> ?? ??? x = substitute(x);
>>>>             >>>> }
>>>>             >>>> right(padding(df)) %=% 1; # but ugly
>>>>             >>>>
>>>>             >>>> ### Does NOT work
>>>>             >>>> 'right<-' = function(x, val) {
>>>>             >>>> ?? ??? print("Already evaluated and also does not
>>>>             use 'val'");
>>>>             >>>> ?? ??? x = substitute(x); # is evaluated before
>>>>             >>>> }
>>>>             >>>>
>>>>             >>>> right(padding(df)) = 1
>>>>             >>>
>>>>             >>> That doesn't make sense.? You don't have a
>>>>             `padding<-` function, and
>>>>             >>> yet you are trying to call right<- to assign
>>>>             something to padding(df).
>>>>             >>>
>>>>             >>> I'm not sure about your real intention, but
>>>>             assignment functions by
>>>>             >>> their nature need to evaluate the thing they are
>>>>             assigning to, since
>>>>             >>> they are designed to modify objects, not create new
>>>>             ones.
>>>>             >>>
>>>>             >>> To create a new object, just use regular assignment.
>>>>             >>>
>>>>             >>> Duncan Murdoch
>>>>             >
>>>>
>>>>             ______________________________________________
>>>>             R-help at r-project.org <mailto:R-help at r-project.org>
>>>>             mailing list -- To UNSUBSCRIBE and more, see
>>>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>             PLEASE do read the posting guide
>>>>             http://www.R-project.org/posting-guide.html
>>>>             <http://www.R-project.org/posting-guide.html>
>>>>             and provide commented, minimal, self-contained,
>>>>             reproducible code.
>>>>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep 13 22:52:42 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 13 Sep 2021 13:52:42 -0700 (PDT)
Subject: [R] tidyverse: grouped summaries (with summerize)
Message-ID: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>

I changed the data files so the date-times are in five separate columns:
year, month, day, hour, and minute; for example,
year,month,day,hour,min,cfs
2016,03,03,12,00,149000
2016,03,03,12,10,150000
2016,03,03,12,20,151000
2016,03,03,12,30,156000
2016,03,03,12,40,154000
2016,03,03,12,50,150000
2016,03,03,13,00,153000
2016,03,03,13,10,156000
2016,03,03,13,20,154000

The script is based on the example (on page 59 of 'R for Data Science'):
library('tidyverse')
disc <- read.csv('../data/water/disc.dat', header = TRUE, sep = ',', stringsAsFactors = FALSE)
disc$year <- as.integer(disc$year)
disc$month <- as.integer(disc$month)
disc$day <- as.integer(disc$day)
disc$hour <- as.integer(disc$hour)
disc$min <- as.integer(disc$min)
disc$cfs <- as.double(disc$cfs, length = 6)

# use dplyr to filter() by year, month, day; summarize() to get monthly
# means, sds
disc_by_month <- group_by(disc, year, month)
summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

but my syntax is off because the results are:
> source('disc.R')
`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.
Warning messages:
1: In eval(ei, envir) : NAs introduced by coercion
2: In eval(ei, envir) : NAs introduced by coercion
> ls()
[1] "disc"          "disc_by_month"
> disc_by_month
# A tibble: 590,940 ? 6
# Groups:   year, month [66]
     year month   day  hour   min    cfs
    <int> <int> <int> <int> <int>  <dbl>
  1  2016     3     3    12     0 149000
  2  2016     3     3    12    10 150000
  3  2016     3     3    12    20 151000
  4  2016     3     3    12    30 156000
  5  2016     3     3    12    40 154000
  6  2016     3     3    12    50 150000
  7  2016     3     3    13     0 153000
  8  2016     3     3    13    10 156000
  9  2016     3     3    13    20 154000
10  2016     3     3    13    30 155000
# ? with 590,930 more rows

I have the same results if I use as.numeric rather than as.integer and
as.double. What am I doing incorrectly?

TIA,

Rich


From @v|gro@@ @end|ng |rom ver|zon@net  Mon Sep 13 23:10:12 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 13 Sep 2021 17:10:12 -0400
Subject: [R] tidyverse: grouped summaries (with summerize)
In-Reply-To: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
Message-ID: <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>

Rich,

Did I miss something? The summarise() command is telling you that  you had not implicitly grouped the data and it made a guess. The canonical way is:

... %>% group_by(year, month, day, hour) %>% summarise(...)


You decide which fields to group by, sometimes including others so they are in the output. 

Avi

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rich Shepard
Sent: Monday, September 13, 2021 4:53 PM
To: r-help at r-project.org
Subject: [R] tidyverse: grouped summaries (with summerize)

I changed the data files so the date-times are in five separate columns:
year, month, day, hour, and minute; for example, year,month,day,hour,min,cfs
2016,03,03,12,00,149000
2016,03,03,12,10,150000
2016,03,03,12,20,151000
2016,03,03,12,30,156000
2016,03,03,12,40,154000
2016,03,03,12,50,150000
2016,03,03,13,00,153000
2016,03,03,13,10,156000
2016,03,03,13,20,154000

The script is based on the example (on page 59 of 'R for Data Science'):
library('tidyverse')
disc <- read.csv('../data/water/disc.dat', header = TRUE, sep = ',', stringsAsFactors = FALSE) disc$year <- as.integer(disc$year) disc$month <- as.integer(disc$month) disc$day <- as.integer(disc$day) disc$hour <- as.integer(disc$hour) disc$min <- as.integer(disc$min) disc$cfs <- as.double(disc$cfs, length = 6)

# use dplyr to filter() by year, month, day; summarize() to get monthly # means, sds disc_by_month <- group_by(disc, year, month) summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

but my syntax is off because the results are:
> source('disc.R')
`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.
Warning messages:
1: In eval(ei, envir) : NAs introduced by coercion
2: In eval(ei, envir) : NAs introduced by coercion
> ls()
[1] "disc"          "disc_by_month"
> disc_by_month
# A tibble: 590,940 ? 6
# Groups:   year, month [66]
     year month   day  hour   min    cfs
    <int> <int> <int> <int> <int>  <dbl>
  1  2016     3     3    12     0 149000
  2  2016     3     3    12    10 150000
  3  2016     3     3    12    20 151000
  4  2016     3     3    12    30 156000
  5  2016     3     3    12    40 154000
  6  2016     3     3    12    50 150000
  7  2016     3     3    13     0 153000
  8  2016     3     3    13    10 156000
  9  2016     3     3    13    20 154000
10  2016     3     3    13    30 155000
# ? with 590,930 more rows

I have the same results if I use as.numeric rather than as.integer and as.double. What am I doing incorrectly?

TIA,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep 13 23:22:09 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 13 Sep 2021 14:22:09 -0700 (PDT)
Subject: [R] tidyverse: grouped summaries (with summerize)
In-Reply-To: <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
Message-ID: <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>

On Mon, 13 Sep 2021, Avi Gross via R-help wrote:

> Did I miss something?

Avi,

Probably not.

> The summarise() command is telling you that  you had not implicitly
> grouped the data and it made a guess. The canonical way is:
> ... %>% group_by(year, month, day, hour) %>% summarise(...)

After sending the message I saw the example using %>% and didn't realize
that it made a difference from the previous example.

> You decide which fields to group by, sometimes including others so they
> are in the output.

That's what I thought I did. I'll rewrite the script and work toward the
output I need.

Thanks,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep 13 23:50:38 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 13 Sep 2021 14:50:38 -0700 (PDT)
Subject: [R] tidyverse: grouped summaries (with summerize)
In-Reply-To: <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>

On Mon, 13 Sep 2021, Rich Shepard wrote:

> That's what I thought I did. I'll rewrite the script and work toward the
> output I need.

Still not the correct syntax. Command is now:
disc_by_month %>%
     group_by(year, month) %>%
     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

and results are:
> source('disc.R')
`summarise()` has grouped output by 'year', 'month'. You can override using the `.groups` argument.

> disc_by_month
# A tibble: 590,940 ? 6
# Groups:   year, month [66]
     year month   day  hour   min    cfs
    <int> <int> <int> <int> <int>  <dbl>
  1  2016     3     3    12     0 149000
  2  2016     3     3    12    10 150000
  3  2016     3     3    12    20 151000
  4  2016     3     3    12    30 156000
  5  2016     3     3    12    40 154000
  6  2016     3     3    12    50 150000
  7  2016     3     3    13     0 153000
  8  2016     3     3    13    10 156000
  9  2016     3     3    13    20 154000
10  2016     3     3    13    30 155000
# ? with 590,930 more rows

The grouping is still not right. I expected to see a mean value for each
month of each year in the data set, not for each minute.

Rich


From er|cjberger @end|ng |rom gm@||@com  Mon Sep 13 23:56:16 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 14 Sep 2021 00:56:16 +0300
Subject: [R] tidyverse: grouped summaries (with summerize)
In-Reply-To: <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
Message-ID: <CAGgJW763+eH8c15Vek2OUHGYU8aO8oAG6jE2e51YdhOw_R40Ag@mail.gmail.com>

This code is not correct:
disc_by_month %>%
     group_by(year, month) %>%
     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

It should be:

disc %>% group_by(year,month) %>% summarize(vol=mean(cfs,na.rm=TRUE)





On Tue, Sep 14, 2021 at 12:51 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Mon, 13 Sep 2021, Rich Shepard wrote:
>
> > That's what I thought I did. I'll rewrite the script and work toward the
> > output I need.
>
> Still not the correct syntax. Command is now:
> disc_by_month %>%
>      group_by(year, month) %>%
>      summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))
>
> and results are:
> > source('disc.R')
> `summarise()` has grouped output by 'year', 'month'. You can override
> using the `.groups` argument.
>
> > disc_by_month
> # A tibble: 590,940 ? 6
> # Groups:   year, month [66]
>      year month   day  hour   min    cfs
>     <int> <int> <int> <int> <int>  <dbl>
>   1  2016     3     3    12     0 149000
>   2  2016     3     3    12    10 150000
>   3  2016     3     3    12    20 151000
>   4  2016     3     3    12    30 156000
>   5  2016     3     3    12    40 154000
>   6  2016     3     3    12    50 150000
>   7  2016     3     3    13     0 153000
>   8  2016     3     3    13    10 156000
>   9  2016     3     3    13    20 154000
> 10  2016     3     3    13    30 155000
> # ? with 590,930 more rows
>
> The grouping is still not right. I expected to see a mean value for each
> month of each year in the data set, not for each minute.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 00:31:33 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 13 Sep 2021 15:31:33 -0700 (PDT)
Subject: [R] tidyverse: grouped summaries (with summerize)
In-Reply-To: <CAGgJW763+eH8c15Vek2OUHGYU8aO8oAG6jE2e51YdhOw_R40Ag@mail.gmail.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
 <CAGgJW763+eH8c15Vek2OUHGYU8aO8oAG6jE2e51YdhOw_R40Ag@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109131524400.10716@salmo.appl-ecosys.com>

On Tue, 14 Sep 2021, Eric Berger wrote:

> This code is not correct:
> disc_by_month %>%
>     group_by(year, month) %>%
>     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))
> It should be:
> disc %>% group_by(year,month) %>% summarize(vol=mean(cfs,na.rm=TRUE)

Eric/Avi:

That makes no difference:
> disc_by_month
# A tibble: 590,940 ? 6
# Groups:   year, month [66]
     year month   day  hour   min    cfs
    <int> <int> <int> <int> <int>  <dbl>
  1  2016     3     3    12     0 149000
  2  2016     3     3    12    10 150000
  3  2016     3     3    12    20 151000
  4  2016     3     3    12    30 156000
  5  2016     3     3    12    40 154000
  6  2016     3     3    12    50 150000
  7  2016     3     3    13     0 153000
  8  2016     3     3    13    10 156000
  9  2016     3     3    13    20 154000
10  2016     3     3    13    30 155000
# ? with 590,930 more rows

I wondered if I need to group first by hour, then day, then year-month.
This, too, produces the same output:

disc %>%
     group_by(hour) %>%
     group_by(day) %>%
     group_by(year, month) %>%
     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

And disc shows the read dataframe.

I don't understand why the columns are not grouping.

Thanks,

Rich


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Sep 14 00:36:06 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 13 Sep 2021 18:36:06 -0400
Subject: [R] tidyverse: grouped summaries (with summerize)
In-Reply-To: <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
Message-ID: <03e801d7a8ef$be336b90$3a9a42b0$@verizon.net>

As Eric has pointed out, perhaps Rich is not thinking pipelined. Summarize() takes a first argument as:
	summarise(.data=whatever, ...)

But in a pipeline, you OMIT the first argument and let the pipeline supply an argument silently.

What I think summarize saw was something like:

summarize(. , disc_by_month, vol = mean(cfs, na.rm = TRUE))

There is now a superfluous SECOND argument in a place it expected not a data.frame type of variable but the name of a column in the hidden data.frame-like object it was passed. You do not have a column called disc_by_month and presumably some weird logic made it suggest it was replacing that by the first column or something.

I hope this makes sense. You do not cobble a pipeline together from parts without carefully making sure all first arguments otherwise used are NOT used.

And, just FYI, the subject line should not use a word that some see as the opposite companion of "winterize" ...

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rich Shepard
Sent: Monday, September 13, 2021 5:51 PM
To: r-help at r-project.org
Subject: Re: [R] tidyverse: grouped summaries (with summerize)

On Mon, 13 Sep 2021, Rich Shepard wrote:

> That's what I thought I did. I'll rewrite the script and work toward 
> the output I need.

Still not the correct syntax. Command is now:
disc_by_month %>%
     group_by(year, month) %>%
     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

and results are:
> source('disc.R')
`summarise()` has grouped output by 'year', 'month'. You can override using the `.groups` argument.

> disc_by_month
# A tibble: 590,940 ? 6
# Groups:   year, month [66]
     year month   day  hour   min    cfs
    <int> <int> <int> <int> <int>  <dbl>
  1  2016     3     3    12     0 149000
  2  2016     3     3    12    10 150000
  3  2016     3     3    12    20 151000
  4  2016     3     3    12    30 156000
  5  2016     3     3    12    40 154000
  6  2016     3     3    12    50 150000
  7  2016     3     3    13     0 153000
  8  2016     3     3    13    10 156000
  9  2016     3     3    13    20 154000
10  2016     3     3    13    30 155000
# ? with 590,930 more rows

The grouping is still not right. I expected to see a mean value for each month of each year in the data set, not for each minute.

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Sep 14 00:43:03 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 13 Sep 2021 18:43:03 -0400
Subject: [R] tidyverse: grouped summaries (with summArize)
References: <03ed01d7a8f0$b6a20d90$23e628b0$.ref@verizon.net>
Message-ID: <03ed01d7a8f0$b6a20d90$23e628b0$@verizon.net>

I think we wandered away into a package rather than base R, but the request seems easy enough.

Just FYI, Rich, as you seem not to have incorporated the advice we gave yet about the first argument, your use of group_by() is a tad odd.

disc %>%
     group_by(hour) %>%
     group_by(day) %>%
     group_by(year, month) %>%
     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

Not sure why you use disc once and disc_by_month the second superfluous time but if you read the manual page for group_by() https://dplyr.tidyverse.org/reference/group_by.html you may note it tends to be called ONCE with multiple arguments in sequence that specify what columns in the data.frame to group by sequentially.

disc %>%
     group_by(hour, day, year, month) %>%
     summarize(vol = mean(cfs, na.rm = TRUE))

Not sure most people would group that way as the above sorts by hours first. Many might reverse that sequence.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rich Shepard
Sent: Monday, September 13, 2021 6:32 PM
To: R mailing list <r-help at r-project.org>
Subject: Re: [R] tidyverse: grouped summaries (with summerize)

On Tue, 14 Sep 2021, Eric Berger wrote:

> This code is not correct:
> disc_by_month %>%
>     group_by(year, month) %>%
>     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE)) It should 
> be:
> disc %>% group_by(year,month) %>% summarize(vol=mean(cfs,na.rm=TRUE)

Eric/Avi:

That makes no difference:
> disc_by_month
# A tibble: 590,940 ? 6
# Groups:   year, month [66]
     year month   day  hour   min    cfs
    <int> <int> <int> <int> <int>  <dbl>
  1  2016     3     3    12     0 149000
  2  2016     3     3    12    10 150000
  3  2016     3     3    12    20 151000
  4  2016     3     3    12    30 156000
  5  2016     3     3    12    40 154000
  6  2016     3     3    12    50 150000
  7  2016     3     3    13     0 153000
  8  2016     3     3    13    10 156000
  9  2016     3     3    13    20 154000
10  2016     3     3    13    30 155000
# ? with 590,930 more rows

I wondered if I need to group first by hour, then day, then year-month.
This, too, produces the same output:

disc %>%
     group_by(hour) %>%
     group_by(day) %>%
     group_by(year, month) %>%
     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

And disc shows the read dataframe.

I don't understand why the columns are not grouping.

Thanks,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Tue Sep 14 00:46:09 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 13 Sep 2021 18:46:09 -0400
Subject: [R] 
 Error msg trying to load R Commander with an older R edition...
In-Reply-To: <18272_1631562598_18DJnvtf022235_32f8ac2a-a9f0-7379-f499-2fa357b9a723@ncf.ca>
References: <18272_1631562598_18DJnvtf022235_32f8ac2a-a9f0-7379-f499-2fa357b9a723@ncf.ca>
Message-ID: <d18ca8cc-551e-7a04-437f-7858da7ff4a0@mcmaster.ca>

Dear Brian,

On 2021-09-13 9:33 a.m., Brian Lunergan wrote:
> Hi folks:
> 
> I'm running Linux Mint 19.3 on my machine. Tried to install a more
> recent edition of R but I couldn't seem to get it working so I pulled it
> off and went with a good, basic install of the edition available through
> the software manager. So... I'm running version 3.4.4.
> 
> Mucking about with the attempt at a newer edition seems to have left
> some excess baggage behind. When I loaded R Commander and attempted to
> run it I received the following error message.
> 
> Error: package or namespace load failed for ?car? in readRDS(pfile):
>   cannot read workspace version 3 written by R 3.6.2; need R 3.5.0 or newer
> During startup - Warning message:
> package ?Rcmdr? in options("defaultPackages") was not found
> 
> I get a similar message in Rkward when I try to load any more packages.
> 
> Is there any solution for this? Any "leftovers" I can track down and
> delete? Any assistance would be greatly appreciated.

It's hard to know exactly how many things are wrong here, but one 
problem seems to be that you saved the R workspace in the newer version 
of R, and that the older version is trying to load the saved workspace, 
which is an incompatible format.

The workspace is probably saved in the file .RData in your R home 
directory. If that's the case, then you should see a message to this 
effect when R starts up. I'd begin by simply deleting this file.

Then, if the Rcmdr package fails to load with an error indicating that 
car or another package is missing, I'd try installing the missing 
package(s).

Finally, you might be better off persevering in your attempt to install 
the current version of R rather than the quite old version that you're 
trying get working.

I hope this helps,
  John

> 
> Kind regards...
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 01:04:28 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 13 Sep 2021 16:04:28 -0700 (PDT)
Subject: [R] tidyverse: grouped summaries (with summarize) [RESOLVED]
In-Reply-To: <03e801d7a8ef$be336b90$3a9a42b0$@verizon.net>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
 <03e801d7a8ef$be336b90$3a9a42b0$@verizon.net>
Message-ID: <alpine.LNX.2.20.2109131600180.10716@salmo.appl-ecosys.com>

On Mon, 13 Sep 2021, Avi Gross via R-help wrote:

> As Eric has pointed out, perhaps Rich is not thinking pipelined. Summarize() takes a first argument as:
> 	summarise(.data=whatever, ...)
>
> But in a pipeline, you OMIT the first argument and let the pipeline supply an argument silently.

Avi,

Thank you. I read your message carefully and re-read the example on the
bottom of page 60 and top of page 61. Then changed the command to:
disc_by_month = disc %>%
     group_by(year, month) %>%
     summarize(vol = mean(cfs, na.rm = TRUE))

And, the script now returns what I need:
> disc_by_month
# A tibble: 66 ? 3
# Groups:   year [7]
     year month     vol
    <int> <int>   <dbl>
  1  2016     3 221840.
  2  2016     4 288589.
  3  2016     5 255164.
  4  2016     6 205371.
  5  2016     7 167252.
  6  2016     8 140465.
  7  2016     9  97779.
  8  2016    10 135482.
  9  2016    11 166808.
10  2016    12 165787.

I missed the beginning of the command where the resulting dataframe needs to
be named first.

This clarifies my understanding and I appreciate your and Eric's help.

Regards,

Rich


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Sep 14 01:44:14 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 13 Sep 2021 19:44:14 -0400
Subject: [R] tidyverse: grouped summaries (with summarize) [RESOLVED]
In-Reply-To: <alpine.LNX.2.20.2109131600180.10716@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
 <03e801d7a8ef$be336b90$3a9a42b0$@verizon.net>
 <alpine.LNX.2.20.2109131600180.10716@salmo.appl-ecosys.com>
Message-ID: <043401d7a8f9$42a34b80$c7e9e280$@verizon.net>

Just FYI, Rich, the way the idiom with pipeline works does allow but not require the method you used:

Yours was
  RESULT <-
    DATAFRAME %>%
    FN1(args) %>%
    ...
    FNn(args)
    
But equally valid are forms that assign the result at the end:

    DATAFRAME %>%
    FN1(args) %>%
    ...
    FNn(args) -> RESULT

Or that supply the first argument to just the first function:

    FN1(DATAFRAME, args) %>%
    ...
    FNn(args) -> RESULT

And if you read some tutorials, there are many other things you can do including variants on the pipe symbol to do other things but also how to put the variable returned into a different part (not the first position) of the argument that follows and lots more. Some people spend most of the programming time relatively purely in the tidyverse functions without looking much at base R.

I am not saying that is a good thing.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rich Shepard
Sent: Monday, September 13, 2021 7:04 PM
To: r-help at r-project.org
Subject: Re: [R] tidyverse: grouped summaries (with summarize) [RESOLVED]

On Mon, 13 Sep 2021, Avi Gross via R-help wrote:

> As Eric has pointed out, perhaps Rich is not thinking pipelined. Summarize() takes a first argument as:
> 	summarise(.data=whatever, ...)
>
> But in a pipeline, you OMIT the first argument and let the pipeline supply an argument silently.

Avi,

Thank you. I read your message carefully and re-read the example on the bottom of page 60 and top of page 61. Then changed the command to:
disc_by_month = disc %>%
     group_by(year, month) %>%
     summarize(vol = mean(cfs, na.rm = TRUE))

And, the script now returns what I need:
> disc_by_month
# A tibble: 66 ? 3
# Groups:   year [7]
     year month     vol
    <int> <int>   <dbl>
  1  2016     3 221840.
  2  2016     4 288589.
  3  2016     5 255164.
  4  2016     6 205371.
  5  2016     7 167252.
  6  2016     8 140465.
  7  2016     9  97779.
  8  2016    10 135482.
  9  2016    11 166808.
10  2016    12 165787.

I missed the beginning of the command where the resulting dataframe needs to be named first.

This clarifies my understanding and I appreciate your and Eric's help.

Regards,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 02:15:06 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 13 Sep 2021 17:15:06 -0700 (PDT)
Subject: [R] tidyverse: grouped summaries (with summarize) [RESOLVED]
In-Reply-To: <043401d7a8f9$42a34b80$c7e9e280$@verizon.net>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
 <03e801d7a8ef$be336b90$3a9a42b0$@verizon.net>
 <alpine.LNX.2.20.2109131600180.10716@salmo.appl-ecosys.com>
 <043401d7a8f9$42a34b80$c7e9e280$@verizon.net>
Message-ID: <alpine.LNX.2.20.2109131712150.10716@salmo.appl-ecosys.com>

On Mon, 13 Sep 2021, Avi Gross via R-help wrote:

> Just FYI, Rich, the way the idiom with pipeline works does allow but not
> require the method you used:
   ...
> But equally valid are forms that assign the result at the end:

Avi,

I'll read more about tidyverse and summarize() in R and not just in the
book.

Most of what I've done has been in base R, but I've not before grouped
hydraulic values before plotting them. Seasonal patterns are more
informative than daily ones.

Thanks again,

Rich


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 14 03:10:33 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 13 Sep 2021 18:10:33 -0700
Subject: [R] tidyverse: grouped summaries (with summarize) [RESOLVED]
In-Reply-To: <alpine.LNX.2.20.2109131712150.10716@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
 <03e801d7a8ef$be336b90$3a9a42b0$@verizon.net>
 <alpine.LNX.2.20.2109131600180.10716@salmo.appl-ecosys.com>
 <043401d7a8f9$42a34b80$c7e9e280$@verizon.net>
 <alpine.LNX.2.20.2109131712150.10716@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbSGw=PUkc+EJEJUZsxaFw759b5egZ3UJcQKUy2WcofrfQ@mail.gmail.com>

If you are interested in extracting seasonal patterns from time
series, you might wish to check out ?stl (in the stats package). Of
course, there are all sorts of ways in many packages to fit
seasonality in time series that are more sophisticated, but probably
also more complicated, than your manual summarization and plotting.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 13, 2021 at 5:15 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Mon, 13 Sep 2021, Avi Gross via R-help wrote:
>
> > Just FYI, Rich, the way the idiom with pipeline works does allow but not
> > require the method you used:
>    ...
> > But equally valid are forms that assign the result at the end:
>
> Avi,
>
> I'll read more about tidyverse and summarize() in R and not just in the
> book.
>
> Most of what I've done has been in base R, but I've not before grouped
> hydraulic values before plotting them. Seasonal patterns are more
> informative than daily ones.
>
> Thanks again,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 03:36:30 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 13 Sep 2021 18:36:30 -0700 (PDT)
Subject: [R] tidyverse: grouped summaries (with summarize) [RESOLVED]
In-Reply-To: <CAGxFJbSGw=PUkc+EJEJUZsxaFw759b5egZ3UJcQKUy2WcofrfQ@mail.gmail.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
 <03e801d7a8ef$be336b90$3a9a42b0$@verizon.net>
 <alpine.LNX.2.20.2109131600180.10716@salmo.appl-ecosys.com>
 <043401d7a8f9$42a34b80$c7e9e280$@verizon.net>
 <alpine.LNX.2.20.2109131712150.10716@salmo.appl-ecosys.com>
 <CAGxFJbSGw=PUkc+EJEJUZsxaFw759b5egZ3UJcQKUy2WcofrfQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109131836070.28442@salmo.appl-ecosys.com>

On Mon, 13 Sep 2021, Bert Gunter wrote:

> If you are interested in extracting seasonal patterns from time series,
> you might wish to check out ?stl (in the stats package). Of course, there
> are all sorts of ways in many packages to fit seasonality in time series
> that are more sophisticated, but probably also more complicated, than your
> manual summarization and plotting.

Bert,

Thanks for the suggestions.

Regards,

Rich


From nev||@@mo@ @end|ng |rom gm@||@com  Tue Sep 14 08:48:48 2021
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Tue, 14 Sep 2021 16:48:48 +1000
Subject: [R] Fastest way to extract rows of smaller matrix many times by
 index to make larger matrix? and multiply columsn of matrix by vector
Message-ID: <CAN9eD7k2R1TdmAQuUNi-ucq7aPpNh5W+X1R5ztzDhVMs1f3t=g@mail.gmail.com>

Hi is there a faster way to "extract" rows of a matrix many times to for a
longer matrix based in a vector or for indices than M[ V, ]

I need to "expand" ( rather than subset)  a matrix M of 10-100,000 rows x
~50 columns to produce a matrix with a greater number (10^6-10^8) of rows
using a vector V containing the 10^6 -10^8 values that are the indices of
the rows of M. the output matrix M2 is then multiplied by another vector V2
With the same length as V.

Is there a faster way to achieve these calculations (which are by far the
slowest portion of a function looped 1000s of times? than the standard  M2
<- M[ V, ] and  M3<-M2*V2, the two calculations are taking a similar time,
Matrix M also changes for each loop.


M<-matrix(runif(50*10000,0,100),nrow=10000,ncol=50)
x = 10^7
V<-sample(1:10000,x,replace=T)
V2<-(sample(c(1,NA),x,replace=T))
print<-(microbenchmark(
M2<-M[V,],
M3<-M2*V2,
times=5,unit = "ms"))



thanks for any suggestions

Nevil Amos

	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Tue Sep 14 09:17:37 2021
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Tue, 14 Sep 2021 09:17:37 +0200
Subject: [R] ggsave() with width only
In-Reply-To: <a6477734-fefa-9cba-b7c1-b214858edd83@e.email>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
 <a6477734-fefa-9cba-b7c1-b214858edd83@e.email>
Message-ID: <9e4dcd06-68b7-5bf5-b4d0-85f2b549abd4@rgzm.de>

Thank you Adam!

I'm a bit surprised that an extra package is needed for this, but why not!

Best,
Ivan

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 13/09/2021 15:40, Adam Wysoki?ski wrote:
> Hi,
> Instead of ggsave(), use save_plot() from the "cowplot" package:
>
> library(ggplot2)
> library(cowplot)
> x <- 1:10
> y <- x^2
> df <- data.frame(x, y)
> p <- ggplot(df, aes(x, y)) + geom_point()
> save_plot("/tmp/plot.png", p, base_aspect_ratio = 1, base_width = 5, 
> base_height = NULL)
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Sep 14 09:49:00 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 14 Sep 2021 00:49:00 -0700
Subject: [R] Fastest way to extract rows of smaller matrix many times by
 index to make larger matrix? and multiply columsn of matrix by vector
In-Reply-To: <CAN9eD7k2R1TdmAQuUNi-ucq7aPpNh5W+X1R5ztzDhVMs1f3t=g@mail.gmail.com>
References: <CAN9eD7k2R1TdmAQuUNi-ucq7aPpNh5W+X1R5ztzDhVMs1f3t=g@mail.gmail.com>
Message-ID: <13967D0F-5487-4D45-991F-DD0A060FA2FD@dcn.davis.ca.us>

That is about as fast as it can be done. However you may be able to avoid doing it at all if you fold V2 into a matrix instead. Did you mean to use matrix multiplication in your calculation of M3?

On September 13, 2021 11:48:48 PM PDT, nevil amos <nevil.amos at gmail.com> wrote:
>Hi is there a faster way to "extract" rows of a matrix many times to for a
>longer matrix based in a vector or for indices than M[ V, ]
>
>I need to "expand" ( rather than subset)  a matrix M of 10-100,000 rows x
>~50 columns to produce a matrix with a greater number (10^6-10^8) of rows
>using a vector V containing the 10^6 -10^8 values that are the indices of
>the rows of M. the output matrix M2 is then multiplied by another vector V2
>With the same length as V.
>
>Is there a faster way to achieve these calculations (which are by far the
>slowest portion of a function looped 1000s of times? than the standard  M2
><- M[ V, ] and  M3<-M2*V2, the two calculations are taking a similar time,
>Matrix M also changes for each loop.
>
>
>M<-matrix(runif(50*10000,0,100),nrow=10000,ncol=50)
>x = 10^7
>V<-sample(1:10000,x,replace=T)
>V2<-(sample(c(1,NA),x,replace=T))
>print<-(microbenchmark(
>M2<-M[V,],
>M3<-M2*V2,
>times=5,unit = "ms"))
>
>
>
>thanks for any suggestions
>
>Nevil Amos
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From nev||@@mo@ @end|ng |rom gm@||@com  Tue Sep 14 11:10:46 2021
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Tue, 14 Sep 2021 19:10:46 +1000
Subject: [R] Fastest way to extract rows of smaller matrix many times by
 index to make larger matrix? and multiply columsn of matrix by vector
In-Reply-To: <13967D0F-5487-4D45-991F-DD0A060FA2FD@dcn.davis.ca.us>
References: <CAN9eD7k2R1TdmAQuUNi-ucq7aPpNh5W+X1R5ztzDhVMs1f3t=g@mail.gmail.com>
 <13967D0F-5487-4D45-991F-DD0A060FA2FD@dcn.davis.ca.us>
Message-ID: <CAN9eD7ncKdJA8DX=CyGNDZvCBbWV8g1jt1C6XxLA0QCXQ9hQwA@mail.gmail.com>

OK thanks, I thought it probably was, but always worth asking. the
multiplication of the columns of M2 by V2 is as intended - not matrix
multiplication.



On Tue, 14 Sept 2021 at 17:49, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> That is about as fast as it can be done. However you may be able to avoid
> doing it at all if you fold V2 into a matrix instead. Did you mean to use
> matrix multiplication in your calculation of M3?
>
> On September 13, 2021 11:48:48 PM PDT, nevil amos <nevil.amos at gmail.com>
> wrote:
> >Hi is there a faster way to "extract" rows of a matrix many times to for a
> >longer matrix based in a vector or for indices than M[ V, ]
> >
> >I need to "expand" ( rather than subset)  a matrix M of 10-100,000 rows x
> >~50 columns to produce a matrix with a greater number (10^6-10^8) of rows
> >using a vector V containing the 10^6 -10^8 values that are the indices of
> >the rows of M. the output matrix M2 is then multiplied by another vector
> V2
> >With the same length as V.
> >
> >Is there a faster way to achieve these calculations (which are by far the
> >slowest portion of a function looped 1000s of times? than the standard  M2
> ><- M[ V, ] and  M3<-M2*V2, the two calculations are taking a similar time,
> >Matrix M also changes for each loop.
> >
> >
> >M<-matrix(runif(50*10000,0,100),nrow=10000,ncol=50)
> >x = 10^7
> >V<-sample(1:10000,x,replace=T)
> >V2<-(sample(c(1,NA),x,replace=T))
> >print<-(microbenchmark(
> >M2<-M[V,],
> >M3<-M2*V2,
> >times=5,unit = "ms"))
> >
> >
> >
> >thanks for any suggestions
> >
> >Nevil Amos
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Tue Sep 14 15:46:46 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Tue, 14 Sep 2021 16:46:46 +0300
Subject: [R] Fastest way to extract rows of smaller matrix many times by
 index to make larger matrix? and multiply columsn of matrix by vector
Message-ID: <48426bb5-aa2f-30d3-9ef3-4aab41be5af5@syonic.eu>

Hello Nevil,


you could test something like:


# the Matrix
m = matrix(1:1000, ncol=10)
m = t(m)

# Extract Data
idcol = sample(seq(100), 100, TRUE); # now columns
for(i in 1:100) {
 ??? m2 = m[ , idcol];
}
m2 = t(m2); # transpose back


It may be faster, although I did not benchmark it.


There may be more complex variants. Maybe it is warranted to try for 
10^7 extractions:

- e.g. extracting one row and replacing all occurrences of that row;


Sincerely,


Leonard


========


It seems I cannot extract digested mail anymore. I hope though that the 
message is processed properly.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 17:21:12 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 14 Sep 2021 08:21:12 -0700 (PDT)
Subject: [R] Need fresh eyes to see what I'm missing
Message-ID: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>

The data file begins this way:
year,month,day,hour,min,fps
2016,03,03,12,00,1.74
2016,03,03,12,10,1.75
2016,03,03,12,20,1.76
2016,03,03,12,30,1.81
2016,03,03,12,40,1.79
2016,03,03,12,50,1.75
2016,03,03,13,00,1.78
2016,03,03,13,10,1.81

The script to process it:
library('tidyverse')
vel <- read.csv('../data/water/vel.dat', header = TRUE, sep = ',', stringsAsFactors = FALSE)
vel$year <- as.integer(vel$year)
vel$month <- as.integer(vel$month)
vel$day <- as.integer(vel$day)
vel$hour <- as.integer(vel$hour)
vel$min <- as.integer(vel$min)
vel$fps <- as.double(vel$fps, length = 6)

# use dplyr to filter() by year, month, day; summarize() to get monthly
# means
vel_by_month = vel %>%
     group_by(year, month) %>%
     summarize(flow = mean(fps, na.rm = TRUE))

R's display after running the script:
> source('vel.R')
`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.
Warning messages:
1: In eval(ei, envir) : NAs introduced by coercion
2: In eval(ei, envir) : NAs introduced by coercion
3: In eval(ei, envir) : NAs introduced by coercion

The dataframe created by the read.csv() command:
> head(vel)
   year month day hour min  fps
1 2016     3   3   12   0 1.74
2 2016     3   3   12  10 1.75
3 2016     3   3   12  20 1.76
4 2016     3   3   12  30 1.81
5 2016     3   3   12  40 1.79
6 2016     3   3   12  50 1.75

and the resulting grouping:
> vel_by_month
# A tibble: 67 ? 3
# Groups:   year [8]
     year month   flow
    <int> <int>  <dbl>
  1     0    NA NaN
  2  2016     3   2.40
  3  2016     4   3.00
  4  2016     5   2.86
  5  2016     6   2.51
  6  2016     7   2.18
  7  2016     8   1.89
  8  2016     9   1.38
  9  2016    10   1.73
10  2016    11   2.01
# ? with 57 more rows

I cannot find why line 1 is there. Other data sets don't produce this
result.

TIA,

Rich


From er|cjberger @end|ng |rom gm@||@com  Tue Sep 14 17:29:50 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 14 Sep 2021 18:29:50 +0300
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
Message-ID: <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>

Before you create vel_by_month you can check vel for NAs and NaNs by

sum(is.na(vel))
sum(unlist(lapply(vel,is.nan)))

HTH,
Eric


On Tue, Sep 14, 2021 at 6:21 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> The data file begins this way:
> year,month,day,hour,min,fps
> 2016,03,03,12,00,1.74
> 2016,03,03,12,10,1.75
> 2016,03,03,12,20,1.76
> 2016,03,03,12,30,1.81
> 2016,03,03,12,40,1.79
> 2016,03,03,12,50,1.75
> 2016,03,03,13,00,1.78
> 2016,03,03,13,10,1.81
>
> The script to process it:
> library('tidyverse')
> vel <- read.csv('../data/water/vel.dat', header = TRUE, sep = ',',
> stringsAsFactors = FALSE)
> vel$year <- as.integer(vel$year)
> vel$month <- as.integer(vel$month)
> vel$day <- as.integer(vel$day)
> vel$hour <- as.integer(vel$hour)
> vel$min <- as.integer(vel$min)
> vel$fps <- as.double(vel$fps, length = 6)
>
> # use dplyr to filter() by year, month, day; summarize() to get monthly
> # means
> vel_by_month = vel %>%
>      group_by(year, month) %>%
>      summarize(flow = mean(fps, na.rm = TRUE))
>
> R's display after running the script:
> > source('vel.R')
> `summarise()` has grouped output by 'year'. You can override using the
> `.groups` argument.
> Warning messages:
> 1: In eval(ei, envir) : NAs introduced by coercion
> 2: In eval(ei, envir) : NAs introduced by coercion
> 3: In eval(ei, envir) : NAs introduced by coercion
>
> The dataframe created by the read.csv() command:
> > head(vel)
>    year month day hour min  fps
> 1 2016     3   3   12   0 1.74
> 2 2016     3   3   12  10 1.75
> 3 2016     3   3   12  20 1.76
> 4 2016     3   3   12  30 1.81
> 5 2016     3   3   12  40 1.79
> 6 2016     3   3   12  50 1.75
>
> and the resulting grouping:
> > vel_by_month
> # A tibble: 67 ? 3
> # Groups:   year [8]
>      year month   flow
>     <int> <int>  <dbl>
>   1     0    NA NaN
>   2  2016     3   2.40
>   3  2016     4   3.00
>   4  2016     5   2.86
>   5  2016     6   2.51
>   6  2016     7   2.18
>   7  2016     8   1.89
>   8  2016     9   1.38
>   9  2016    10   1.73
> 10  2016    11   2.01
> # ? with 57 more rows
>
> I cannot find why line 1 is there. Other data sets don't produce this
> result.
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 14 17:38:45 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 14 Sep 2021 08:38:45 -0700
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
 <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
Message-ID: <CAGxFJbRm3uvcCYHC3HP4oEMfggBo_H_yDkKL6igqrhqoDW6YNQ@mail.gmail.com>

Remove all your as.integer() and as.double() coercions. They are
unnecessary (unless you are preparing input for C code; also, all R
non-integers are double precision) and may be the source of your
problems.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Sep 14, 2021 at 8:31 AM Eric Berger <ericjberger at gmail.com> wrote:
>
> Before you create vel_by_month you can check vel for NAs and NaNs by
>
> sum(is.na(vel))
> sum(unlist(lapply(vel,is.nan)))
>
> HTH,
> Eric
>
>
> On Tue, Sep 14, 2021 at 6:21 PM Rich Shepard <rshepard at appl-ecosys.com>
> wrote:
>
> > The data file begins this way:
> > year,month,day,hour,min,fps
> > 2016,03,03,12,00,1.74
> > 2016,03,03,12,10,1.75
> > 2016,03,03,12,20,1.76
> > 2016,03,03,12,30,1.81
> > 2016,03,03,12,40,1.79
> > 2016,03,03,12,50,1.75
> > 2016,03,03,13,00,1.78
> > 2016,03,03,13,10,1.81
> >
> > The script to process it:
> > library('tidyverse')
> > vel <- read.csv('../data/water/vel.dat', header = TRUE, sep = ',',
> > stringsAsFactors = FALSE)
> > vel$year <- as.integer(vel$year)
> > vel$month <- as.integer(vel$month)
> > vel$day <- as.integer(vel$day)
> > vel$hour <- as.integer(vel$hour)
> > vel$min <- as.integer(vel$min)
> > vel$fps <- as.double(vel$fps, length = 6)
> >
> > # use dplyr to filter() by year, month, day; summarize() to get monthly
> > # means
> > vel_by_month = vel %>%
> >      group_by(year, month) %>%
> >      summarize(flow = mean(fps, na.rm = TRUE))
> >
> > R's display after running the script:
> > > source('vel.R')
> > `summarise()` has grouped output by 'year'. You can override using the
> > `.groups` argument.
> > Warning messages:
> > 1: In eval(ei, envir) : NAs introduced by coercion
> > 2: In eval(ei, envir) : NAs introduced by coercion
> > 3: In eval(ei, envir) : NAs introduced by coercion
> >
> > The dataframe created by the read.csv() command:
> > > head(vel)
> >    year month day hour min  fps
> > 1 2016     3   3   12   0 1.74
> > 2 2016     3   3   12  10 1.75
> > 3 2016     3   3   12  20 1.76
> > 4 2016     3   3   12  30 1.81
> > 5 2016     3   3   12  40 1.79
> > 6 2016     3   3   12  50 1.75
> >
> > and the resulting grouping:
> > > vel_by_month
> > # A tibble: 67 ? 3
> > # Groups:   year [8]
> >      year month   flow
> >     <int> <int>  <dbl>
> >   1     0    NA NaN
> >   2  2016     3   2.40
> >   3  2016     4   3.00
> >   4  2016     5   2.86
> >   5  2016     6   2.51
> >   6  2016     7   2.18
> >   7  2016     8   1.89
> >   8  2016     9   1.38
> >   9  2016    10   1.73
> > 10  2016    11   2.01
> > # ? with 57 more rows
> >
> > I cannot find why line 1 is there. Other data sets don't produce this
> > result.
> >
> > TIA,
> >
> > Rich
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 17:41:15 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 14 Sep 2021 08:41:15 -0700 (PDT)
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
 <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109140836560.306@salmo.appl-ecosys.com>

On Tue, 14 Sep 2021, Eric Berger wrote:

> Before you create vel_by_month you can check vel for NAs and NaNs by
>
> sum(is.na(vel))
> sum(unlist(lapply(vel,is.nan)))

Eric,

There should not be any missing values in the data file. Regardless, I added
those lines to the script and it made no difference.

Running those commands on the R command line showed these results:
> sum(is.na(vel))
[1] 2321
> sum(unlist(lapply(vel,is.nan)))
[1] 0

Yet the monthly summaries retain the initial line:
> vel_by_month
# A tibble: 67 ? 3
# Groups:   year [8]
     year month   flow
    <int> <int>  <dbl>
  1     0    NA NaN

I've another data set with the same issue (that's 2 out of 5) and I assume
the source of the problem is the same with both.

The data sets have no NAs or missing values at the end of a line.

Thanks for the ideas,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 17:48:45 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 14 Sep 2021 08:48:45 -0700 (PDT)
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <CAGxFJbRm3uvcCYHC3HP4oEMfggBo_H_yDkKL6igqrhqoDW6YNQ@mail.gmail.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
 <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
 <CAGxFJbRm3uvcCYHC3HP4oEMfggBo_H_yDkKL6igqrhqoDW6YNQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109140843390.306@salmo.appl-ecosys.com>

On Tue, 14 Sep 2021, Bert Gunter wrote:

> Remove all your as.integer() and as.double() coercions. They are
> unnecessary (unless you are preparing input for C code; also, all R
> non-integers are double precision) and may be the source of your problems.

Bert,

When I remove coercions the script produces warnings like this:
1: In mean.default(fps, na.rm = TRUE) :
   argument is not numeric or logical: returning NA

and str(vel) displays this:
'data.frame':	565675 obs. of  6 variables:
  $ year : chr  "2016" "2016" "2016" "2016" ...
  $ month: int  3 3 3 3 3 3 3 3 3 3 ...
  $ day  : int  3 3 3 3 3 3 3 3 3 3 ...
  $ hour : chr  "12" "12" "12" "12" ...
  $ min  : int  0 10 20 30 40 50 0 10 20 30 ...
  $ fps  : chr  "1.74" "1.75" "1.76" "1.81" ...

so month, day, and min are recognized as integers but year, hour, and fps
are seen as characters. I don't understand why.

Regards,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 17:51:47 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 14 Sep 2021 08:51:47 -0700 (PDT)
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <CAGxFJbRm3uvcCYHC3HP4oEMfggBo_H_yDkKL6igqrhqoDW6YNQ@mail.gmail.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
 <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
 <CAGxFJbRm3uvcCYHC3HP4oEMfggBo_H_yDkKL6igqrhqoDW6YNQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109140850391.306@salmo.appl-ecosys.com>

On Tue, 14 Sep 2021, Bert Gunter wrote:

> Remove all your as.integer() and as.double() coercions. They are
> unnecessary (unless you are preparing input for C code; also, all R
> non-integers are double precision) and may be the source of your
> problems.

Bert,

Are all columns but the fps factors?

Rich


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Sep 14 18:16:45 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 14 Sep 2021 12:16:45 -0400
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
Message-ID: <021401d7a983$e9c5e730$bd51b590$@verizon.net>

Rich,

I reproduced your problem on my re-arranging the code the mailer mangled. I tried variations like not using pipes or changing what it is grouped by and they all show your results on the abbreviated data with the error:

`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.

I think I fixed summarise()  but it makes me wonder if there is an inconsistency introduced along the way as what you used is supposed to work and has worked for me in the past.

I note the man page for summarise() mentions that the .groups="..." is experimental and a tad confusing:

I changed your code to this by telling it to keep the grouping in the output the same:

vel_by_month = vel %>%
  group_by(year, month) %>%
  summarise(flow = mean(fps, na.rm = TRUE), .groups="keep")

The change from your code is the addition at the very end of the .groups="keep" argument.

Since I used your limited data, this is all I get:

> vel_by_month
# A tibble: 1 x 3
# Groups:   year, month [1]
year month  flow
<int> <int> <dbl>
  1  2016     3  1.77

For now, all I did was shut summarise() up.

Not having the rest of your data, the question is where your NA and Nan are introduced. If the change I made above does not resolve it, then as others suggested, you begin by looking at your data more carefully perhaps starting with the .CSV file and then the data structures in R, along the lines of what you were shown. I find the table() function useful for categorical data with limited choices as it would spit out the anomaly as happening once.

I see your point about needing fresh eyes. My eyes do not see what you did wrong but am just following clues you may be ignoring.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rich Shepard
Sent: Tuesday, September 14, 2021 11:21 AM
To: r-help at r-project.org
Subject: [R] Need fresh eyes to see what I'm missing

The data file begins this way:
year,month,day,hour,min,fps
2016,03,03,12,00,1.74
2016,03,03,12,10,1.75
2016,03,03,12,20,1.76
2016,03,03,12,30,1.81
2016,03,03,12,40,1.79
2016,03,03,12,50,1.75
2016,03,03,13,00,1.78
2016,03,03,13,10,1.81

The script to process it:
library('tidyverse')
vel <- read.csv('../data/water/vel.dat', header = TRUE, sep = ',', stringsAsFactors = FALSE) vel$year <- as.integer(vel$year) vel$month <- as.integer(vel$month) vel$day <- as.integer(vel$day) vel$hour <- as.integer(vel$hour) vel$min <- as.integer(vel$min) vel$fps <- as.double(vel$fps, length = 6)

# use dplyr to filter() by year, month, day; summarize() to get monthly # means vel_by_month = vel %>%
     group_by(year, month) %>%
     summarize(flow = mean(fps, na.rm = TRUE))

R's display after running the script:
> source('vel.R')
`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.
Warning messages:
1: In eval(ei, envir) : NAs introduced by coercion
2: In eval(ei, envir) : NAs introduced by coercion
3: In eval(ei, envir) : NAs introduced by coercion

The dataframe created by the read.csv() command:
> head(vel)
   year month day hour min  fps
1 2016     3   3   12   0 1.74
2 2016     3   3   12  10 1.75
3 2016     3   3   12  20 1.76
4 2016     3   3   12  30 1.81
5 2016     3   3   12  40 1.79
6 2016     3   3   12  50 1.75

and the resulting grouping:
> vel_by_month
# A tibble: 67 ? 3
# Groups:   year [8]
     year month   flow
    <int> <int>  <dbl>
  1     0    NA NaN
  2  2016     3   2.40
  3  2016     4   3.00
  4  2016     5   2.86
  5  2016     6   2.51
  6  2016     7   2.18
  7  2016     8   1.89
  8  2016     9   1.38
  9  2016    10   1.73
10  2016    11   2.01
# ? with 57 more rows

I cannot find why line 1 is there. Other data sets don't produce this result.

TIA,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Sep 14 18:41:38 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 14 Sep 2021 12:41:38 -0400
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <alpine.LNX.2.20.2109140843390.306@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
 <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
 <CAGxFJbRm3uvcCYHC3HP4oEMfggBo_H_yDkKL6igqrhqoDW6YNQ@mail.gmail.com>
 <alpine.LNX.2.20.2109140843390.306@salmo.appl-ecosys.com>
Message-ID: <024101d7a987$63e6fb00$2bb4f100$@verizon.net>

Rich,

I have to wonder about how your data was placed in the CSV file based on
what you report.

functions like read.table() (which is called by read.csv()) ultimately make
guesses about what number of columns to expect and what the contents are
likely to be. They may just examine the first N entries and make the most
compatible choice. The fact that it shows this:

'data.frame':	565675 obs. of  6 variables:
  $ year : chr  "2016" "2016" "2016" "2016" ...
  $ month: int  3 3 3 3 3 3 3 3 3 3 ...
  $ day  : int  3 3 3 3 3 3 3 3 3 3 ...
  $ hour : chr  "12" "12" "12" "12" ...
  $ min  : int  0 10 20 30 40 50 0 10 20 30 ...
  $ fps  : chr  "1.74" "1.75" "1.76" "1.81" ...

is odd. It suggests somewhere early in the data, it did not say 2016 or some
other entry  as an integer but as "2016" or a word like `missing` and not in
quotes.

Something similar seems to have happened with hour and fps but not the rest.

Nonetheless, you did convert back to what you wanted BUT if a single
anomalous entry remains then as.integer("missing") would return an NA and
as.double("missing") also an NA. So it is wise to check for any unexpected
numbers. If the source cannot be changed, then the R program can filter out
such cases from your data.frame in various ways.

Your way of reading the CSV in was this:

vel <- read.csv('../data/water/vel.dat', header = TRUE, sep = ',',
stringsAsFactors = FALSE)

The default is the options you added for header=TRUE and sep="," so that is
harmless. The default now is not to read in strings as Factors. But what you
did not include may be something you can look at given your data may be a
bit off. 

Without the underlying file, we can not trivially diagnose what may be wrong
in it. Do you get any error messages when reading in the file?  You can
specify additional arguments to read.csv() about what, if any, quoting
characters are used, what sequences should be recognized as an NA,
suggestions of what type each column should be assumed to be, what to do
with blank lines, what a comment looks like  and so on. 

One thing I sometimes have had to do is open the original CSV file in EXCEL
and examine it in various ways or even change it and save it again. That is
beyond the scope of this mailing list so if needed, ask me in private. You
have been working on this kind of stuff, but I assume often using other
tools outside R and dplyr.






-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rich Shepard
Sent: Tuesday, September 14, 2021 11:49 AM
To: R mailing list <r-help at r-project.org>
Subject: Re: [R] Need fresh eyes to see what I'm missing

On Tue, 14 Sep 2021, Bert Gunter wrote:

> Remove all your as.integer() and as.double() coercions. They are 
> unnecessary (unless you are preparing input for C code; also, all R 
> non-integers are double precision) and may be the source of your problems.

Bert,

When I remove coercions the script produces warnings like this:
1: In mean.default(fps, na.rm = TRUE) :
   argument is not numeric or logical: returning NA

and str(vel) displays this:
'data.frame':	565675 obs. of  6 variables:
  $ year : chr  "2016" "2016" "2016" "2016" ...
  $ month: int  3 3 3 3 3 3 3 3 3 3 ...
  $ day  : int  3 3 3 3 3 3 3 3 3 3 ...
  $ hour : chr  "12" "12" "12" "12" ...
  $ min  : int  0 10 20 30 40 50 0 10 20 30 ...
  $ fps  : chr  "1.74" "1.75" "1.76" "1.81" ...

so month, day, and min are recognized as integers but year, hour, and fps
are seen as characters. I don't understand why.

Regards,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 14 18:59:58 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 14 Sep 2021 09:59:58 -0700
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <alpine.LNX.2.20.2109140843390.306@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
 <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
 <CAGxFJbRm3uvcCYHC3HP4oEMfggBo_H_yDkKL6igqrhqoDW6YNQ@mail.gmail.com>
 <alpine.LNX.2.20.2109140843390.306@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbQCmyoHZGgxRNegJ-d6H_TL+LOkQCA595J0jDuCbVjJXQ@mail.gmail.com>

Input problems of this sort are often caused by stray or extra
characters (commas, dashes, etc.) in the input files, which then can
trigger automatic conversion to character. Excel files are somewhat
notorious for this.

A couple of comments, and then I'll quit, as others should have
greater insight (and may correct any of my errors).

1.
> as.numeric("1,")
[1] NA
Warning message:
NAs introduced by coercion

So if a stray character caused your "numeric" input to be read in as
character, then you converted it with as.numeric() (do not use
as.integer or as.double), you get that error.

2. So I would say that you need to check those columns in your data
frame that were read in as character instead of numeric.  I'd also
check the others with unique() or some such just to make sure they
have the handful of right values.

One way of doing this would be to look for NA's in as.numeric, as
above. But I thought you said you did
this already and found none, so I don't get it. Other approaches would
be to examine your .csv file with ?count.fields or try reading it with
?read.delim. Any discrepancies or errors you get from these may help
you to pinpoint problems like stray characters, to many fields in a
line, etc.

3. As for your "fps as factors" question, note that:
> as.numeric(factor("3"))
[1] 1

So it depends on how you read stuff in. The answer should be "no" with
read.csv(..., stringsAsFactors = FALSE), but I'm not sure what all you
did or what kind of junk in your .csv file may be causing R to misread
the numeric data as character.

As I said, others may be wiser and correct any errors in my "advice."
This is as far as I can go -- and it may already be too far.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )



On Tue, Sep 14, 2021 at 9:01 AM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Tue, 14 Sep 2021, Bert Gunter wrote:
>
> > Remove all your as.integer() and as.double() coercions. They are
> > unnecessary (unless you are preparing input for C code; also, all R
> > non-integers are double precision) and may be the source of your problems.
>
> Bert,
>
> When I remove coercions the script produces warnings like this:
> 1: In mean.default(fps, na.rm = TRUE) :
>    argument is not numeric or logical: returning NA
>
> and str(vel) displays this:
> 'data.frame':   565675 obs. of  6 variables:
>   $ year : chr  "2016" "2016" "2016" "2016" ...
>   $ month: int  3 3 3 3 3 3 3 3 3 3 ...
>   $ day  : int  3 3 3 3 3 3 3 3 3 3 ...
>   $ hour : chr  "12" "12" "12" "12" ...
>   $ min  : int  0 10 20 30 40 50 0 10 20 30 ...
>   $ fps  : chr  "1.74" "1.75" "1.76" "1.81" ...
>
> so month, day, and min are recognized as integers but year, hour, and fps
> are seen as characters. I don't understand why.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 19:12:52 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 14 Sep 2021 10:12:52 -0700 (PDT)
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <CAGxFJbQCmyoHZGgxRNegJ-d6H_TL+LOkQCA595J0jDuCbVjJXQ@mail.gmail.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
 <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
 <CAGxFJbRm3uvcCYHC3HP4oEMfggBo_H_yDkKL6igqrhqoDW6YNQ@mail.gmail.com>
 <alpine.LNX.2.20.2109140843390.306@salmo.appl-ecosys.com>
 <CAGxFJbQCmyoHZGgxRNegJ-d6H_TL+LOkQCA595J0jDuCbVjJXQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109141011300.306@salmo.appl-ecosys.com>

On Tue, 14 Sep 2021, Bert Gunter wrote:

> Input problems of this sort are often caused by stray or extra characters
> (commas, dashes, etc.) in the input files, which then can trigger
> automatic conversion to character. Excel files are somewhat notorious for
> this.

Bert,

Yes, I'm going to closely review the original data file and work forward
from there. Thanks for your comments; I do appreciate them.

Back when I have more information ... perhaps even a fix.

Best regards,

Rich


From |eo@m@d@ @end|ng |rom @yon|c@eu  Tue Sep 14 19:18:47 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Tue, 14 Sep 2021 20:18:47 +0300
Subject: [R] [R Code] Split long names in format.ftable
Message-ID: <7876cd2d-2855-fee4-2839-2821361fa85d@syonic.eu>

Dear List members,


I wrote some code to split long names in format.ftable. I hope it will 
be useful to others as well.


Ideally, this code should be implemented natively in R. I will provide 
in the 2nd part of the mail a concept how to actually implement the code 
in R. This may be interesting to R-devel as well.


### Helper function

# Split the actual names

split.names = function(names, extend=0, justify="Right", blank.rm=FALSE, 
split.ch = "\n", detailed=TRUE) {
 ??? justify = if(is.null(justify)) 0 else pmatch(justify, c("Left", 
"Right"));
 ??? str = strsplit(names, split.ch);
 ??? if(blank.rm) str = lapply(str, function(s) s[nchar(s) > 0]);
 ??? nr? = max(sapply(str, function(s) length(s)));
 ??? nch = lapply(str, function(s) max(nchar(s)));
 ??? chf = function(nch) paste0(rep(" ", nch), collapse="");
 ??? ch0 = sapply(nch, chf);
 ??? mx? = matrix(rep(ch0, each=nr), nrow=nr, ncol=length(names));
 ??? for(nc in seq(length(names))) {
 ??? ??? n = length(str[[nc]]);
 ??? ??? # Justifying
 ??? ??? s = sapply(seq(n), function(nr) paste0(rep(" ", nch[[nc]] - 
nchar(str[[nc]][nr])), collapse=""));
 ??? ??? s = if(justify == 2) paste0(s, str[[nc]]) else 
paste0(str[[nc]], s);
 ??? ??? mx[seq(nr + 1 - length(str[[nc]]), nr) , nc] = s;
 ??? }
 ??? if(extend > 0) {
 ??? ??? mx = cbind(mx, matrix("", nr=nr, ncol=extend));
 ??? }
 ??? if(detailed) attr(mx, "nchar") = unlist(nch);
 ??? return(mx);
}

### ftable with name splitting
# - this code should be ideally integrated inside format.ftable;
ftable2 = function(ftbl, print=TRUE, quote=FALSE, ...) {
 ??? ftbl2 = format(ftbl, quote=quote, ...);
 ??? row.vars = names(attr(ftbl, "row.vars"))
 ??? nr = length(row.vars);
 ??? nms = split.names(row.vars, extend = ncol(ftbl2) - nr);
 ??? ftbl2 = rbind(ftbl2[1,], nms, ftbl2[-c(1,2),]);
 ??? # TODO: update width of factor labels;
 ??? # - new width available in attr(nms, "nchar");
 ??? if(print) {
 ??? ??? cat(t(ftbl2), sep = c(rep(" ", ncol(ftbl2) - 1), "\n"))
 ??? }
 ??? invisible(ftbl2);
}

I have uploaded this code also on Github:

https://github.com/discoleo/R/blob/master/Stat/Tools.Data.R


B.) Detailed Concept
# - I am ignoring any variants;
# - the splitting is actually done in format.ftable;
# - we set only an attribute in ftable;
ftable = function(..., split.ch="\n") {
 ?? [...]
 ?? attr(ftbl, "split.ch") = split.ch; # set an attribute "split.ch"
 ?? return(ftbl);
}

format.ftable(ftbl, ..., split.ch) {
if(is.missing(split.ch)) {
 ?? # check if the split.ch attribute is set and use it;
} else {
 ?? # use the explicitly provided split.ch: if( ! is.null(split.ch))
}
 ?? [...]
}


C.) split.names Function

This function may be useful in other locations as well, particularly to 
split names/labels used in axes and legends in various plots. But I do 
not have much knowledge of the graphics engine in R.


Sincerely,


Leonard


From er|cjberger @end|ng |rom gm@||@com  Tue Sep 14 19:27:07 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 14 Sep 2021 20:27:07 +0300
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <alpine.LNX.2.20.2109140836560.306@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
 <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
 <alpine.LNX.2.20.2109140836560.306@salmo.appl-ecosys.com>
Message-ID: <CAGgJW76RHNyh949Kfy1Me5-HZkLr0SgfLmMAUGwGWJbH1+3-1w@mail.gmail.com>

Hi Rich,
My suggestion was not 'to make a difference'. It was to determine
whether the NAs or NaNs appear before the dplyr commands. You
confirmed that they do. There are 2321 NAs in vel. Bert suggested some
ways that an NA might appear.

Best,
Eric

On Tue, Sep 14, 2021 at 6:42 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Tue, 14 Sep 2021, Eric Berger wrote:
>
> > Before you create vel_by_month you can check vel for NAs and NaNs by
> >
> > sum(is.na(vel))
> > sum(unlist(lapply(vel,is.nan)))
>
> Eric,
>
> There should not be any missing values in the data file. Regardless, I added
> those lines to the script and it made no difference.
>
> Running those commands on the R command line showed these results:
> > sum(is.na(vel))
> [1] 2321
> > sum(unlist(lapply(vel,is.nan)))
> [1] 0
>
> Yet the monthly summaries retain the initial line:
> > vel_by_month
> # A tibble: 67 ? 3
> # Groups:   year [8]
>      year month   flow
>     <int> <int>  <dbl>
>   1     0    NA NaN
>
> I've another data set with the same issue (that's 2 out of 5) and I assume
> the source of the problem is the same with both.
>
> The data sets have no NAs or missing values at the end of a line.
>
> Thanks for the ideas,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 19:33:06 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 14 Sep 2021 10:33:06 -0700 (PDT)
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <CAGgJW76RHNyh949Kfy1Me5-HZkLr0SgfLmMAUGwGWJbH1+3-1w@mail.gmail.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
 <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
 <alpine.LNX.2.20.2109140836560.306@salmo.appl-ecosys.com>
 <CAGgJW76RHNyh949Kfy1Me5-HZkLr0SgfLmMAUGwGWJbH1+3-1w@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109141031420.306@salmo.appl-ecosys.com>

On Tue, 14 Sep 2021, Eric Berger wrote:

> My suggestion was not 'to make a difference'. It was to determine whether
> the NAs or NaNs appear before the dplyr commands. You confirmed that they
> do. There are 2321 NAs in vel. Bert suggested some ways that an NA might
> appear.

Eric,

Yes, you're all correct. I've just downloaded the raw data again for mean
velocieties and suspended sediments. I'll go through them line-by-line and
look for discrepancies.

Thanks again,

Rich


From j|hen@on1 @end|ng |rom gm@||@com  Tue Sep 14 19:49:32 2021
From: j|hen@on1 @end|ng |rom gm@||@com (James Henson)
Date: Tue, 14 Sep 2021 12:49:32 -0500
Subject: [R] pseudoreplication
Message-ID: <CABPq8JNTwDFg4XeUhSe=uypzxOGnnyKahPt62_M5KzkyGevDkw@mail.gmail.com>

Greetings R Community
The ASReml-R package will analyze data from experiments with
pseudoreplications.

Dealing with Pseudo-Replication in Linear Mixed Models
https://www.vsni.co.uk/case-studies/dealing-with-pseudo-replication-in-linear-mixed-models

Will the ?lme4? package return an equivalent analysis of data from
experiments with pseudoreplications?
Thank you for your assistance.

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 19:49:37 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 14 Sep 2021 10:49:37 -0700 (PDT)
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <CAGxFJbQCmyoHZGgxRNegJ-d6H_TL+LOkQCA595J0jDuCbVjJXQ@mail.gmail.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
 <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
 <CAGxFJbRm3uvcCYHC3HP4oEMfggBo_H_yDkKL6igqrhqoDW6YNQ@mail.gmail.com>
 <alpine.LNX.2.20.2109140843390.306@salmo.appl-ecosys.com>
 <CAGxFJbQCmyoHZGgxRNegJ-d6H_TL+LOkQCA595J0jDuCbVjJXQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109141047560.306@salmo.appl-ecosys.com>

On Tue, 14 Sep 2021, Bert Gunter wrote:

> Input problems of this sort are often caused by stray or extra characters
> (commas, dashes, etc.) in the input files, which then can trigger
> automatic conversion to character. Excel files are somewhat notorious for
> this.

Bert,

Large volume of missing data at the end of last year. See attached plot.

I'll go through the raw data file to see how those missing data are
presented.

Regards,

Rich
-------------- next part --------------
A non-text attachment was scrubbed...
Name: col-riv-velocities.png
Type: image/png
Size: 18887 bytes
Desc: 
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210914/c1d848db/attachment.png>

From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 14 19:54:58 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 14 Sep 2021 10:54:58 -0700
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <alpine.LNX.2.20.2109141031420.306@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
 <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
 <alpine.LNX.2.20.2109140836560.306@salmo.appl-ecosys.com>
 <CAGgJW76RHNyh949Kfy1Me5-HZkLr0SgfLmMAUGwGWJbH1+3-1w@mail.gmail.com>
 <alpine.LNX.2.20.2109141031420.306@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbSzxDbbExKzqe5q4-F5_4KHfKiknk4P4OweOnjo7UPAvg@mail.gmail.com>

Inline.


On Tue, Sep 14, 2021 at 10:42 AM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Tue, 14 Sep 2021, Eric Berger wrote:
>
> > My suggestion was not 'to make a difference'. It was to determine whether
> > the NAs or NaNs appear before the dplyr commands. You confirmed that they
> > do. There are 2321 NAs in vel. Bert suggested some ways that an NA might
> > appear.
>
> Eric,
>
> Yes, you're all correct. I've just downloaded the raw data again for mean
> velocieties and suspended sediments. I'll go through them line-by-line and
> look for discrepancies.

**Don't do this.*** You will make errors. Use fit-for-purpose tools.
That's what R is for. Also, be careful **how** you "download", as that
already may bake in problems.

-- Bert
>
> Thanks again,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 19:59:22 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 14 Sep 2021 10:59:22 -0700 (PDT)
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <CAGxFJbSzxDbbExKzqe5q4-F5_4KHfKiknk4P4OweOnjo7UPAvg@mail.gmail.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
 <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
 <alpine.LNX.2.20.2109140836560.306@salmo.appl-ecosys.com>
 <CAGgJW76RHNyh949Kfy1Me5-HZkLr0SgfLmMAUGwGWJbH1+3-1w@mail.gmail.com>
 <alpine.LNX.2.20.2109141031420.306@salmo.appl-ecosys.com>
 <CAGxFJbSzxDbbExKzqe5q4-F5_4KHfKiknk4P4OweOnjo7UPAvg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109141056100.306@salmo.appl-ecosys.com>

On Tue, 14 Sep 2021, Bert Gunter wrote:

> **Don't do this.*** You will make errors. Use fit-for-purpose tools.
> That's what R is for. Also, be careful **how** you "download", as that
> already may bake in problems.

Bert,

Haven't had downloading errors saving displayed files.

The problem with the velocities data is shown here:
2020-11-24 11:00	PST	Eqp 
2020-11-24 11:05	PST	Eqp 
2020-11-24 11:10	PST	Eqp 
2020-11-24 11:15	PST	Eqp 
2020-11-24 11:20	PST	Eqp 
2020-11-24 11:25	PST	Eqp 
2020-11-24 11:30	PST	Eqp 
2020-11-24 11:35	PST	Eqp 
2020-11-24 11:40	PST	Eqp 
2020-11-24 11:45	PST	Eqp 
2020-11-24 11:50	PST	Eqp 
2021-01-08 16:26	PST	Eqp

Equipment failure during the period shown.

What's the best way to replace these lines? Just remove them or change them
to NA?

Regards,

Rich


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Sep 14 20:45:29 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 14 Sep 2021 14:45:29 -0400
Subject: [R] Need fresh eyes to see what I'm missing
In-Reply-To: <alpine.LNX.2.20.2109141056100.306@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109140815450.306@salmo.appl-ecosys.com>
 <CAGgJW77k1bhrArSuosOaVi4cfXqM=xPZiAD_Fg7xEKpBWxHLiQ@mail.gmail.com>
 <alpine.LNX.2.20.2109140836560.306@salmo.appl-ecosys.com>
 <CAGgJW76RHNyh949Kfy1Me5-HZkLr0SgfLmMAUGwGWJbH1+3-1w@mail.gmail.com>
 <alpine.LNX.2.20.2109141031420.306@salmo.appl-ecosys.com>
 <CAGxFJbSzxDbbExKzqe5q4-F5_4KHfKiknk4P4OweOnjo7UPAvg@mail.gmail.com>
 <alpine.LNX.2.20.2109141056100.306@salmo.appl-ecosys.com>
Message-ID: <02f001d7a998$b10bc260$13234720$@verizon.net>

Rich,

You have helped us understand and at this point, suppose we now are sure
about the way missing info is supplied. What you show is not the same as the
CSV sample earlier but assuming you know that "Eqp" is the one and only way
they signaled bad data.

One choice is to fix the original data before reading into R. Chances are
placing exactly NA in those places, perhaps using a global substitute of
some sort, might do it.

But as Bert noted, R is a very powerful environment and you can use it.

One argument you can use with read.csv() is to tell it "Eqp" is to be
treated as an NA. The substitution may then be made as it is read in AND you
might then notice it is properly read in as a column of doubles.

Suppose you read in this data and make sure the column involved is read as
character strings, instead. You can use any number of tools in base R or
dplyr to replace Eqp with NA such as in a pipeline ... %>%
mutate(fps=ifelse(fps=="Eqp", NA, fps)) %>% ...

The above is one of many ways and of course afterward, you may want to
reconvert the character column back to floating point. I note dplyr can do
both in the same function as it applies them in order:

	mutate(fps=ifelse(fps=="Eqp", NA, fps), fps=as.double(fps))

The point is that in many cases, the data must be carefully examined and
cleaned and set up. In some cases, it may also be useful to treat some as
factors as in the hours and minutes. If you continue on your road and hit
ggplot() to make graphs, factors may be useful in various kinds of fine
tuning.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rich Shepard
Sent: Tuesday, September 14, 2021 1:59 PM
To: r-help at r-project.org
Subject: Re: [R] Need fresh eyes to see what I'm missing

On Tue, 14 Sep 2021, Bert Gunter wrote:

> **Don't do this.*** You will make errors. Use fit-for-purpose tools.
> That's what R is for. Also, be careful **how** you "download", as that 
> already may bake in problems.

Bert,

Haven't had downloading errors saving displayed files.

The problem with the velocities data is shown here:
2020-11-24 11:00	PST	Eqp 
2020-11-24 11:05	PST	Eqp 
2020-11-24 11:10	PST	Eqp 
2020-11-24 11:15	PST	Eqp 
2020-11-24 11:20	PST	Eqp 
2020-11-24 11:25	PST	Eqp 
2020-11-24 11:30	PST	Eqp 
2020-11-24 11:35	PST	Eqp 
2020-11-24 11:40	PST	Eqp 
2020-11-24 11:45	PST	Eqp 
2020-11-24 11:50	PST	Eqp 
2021-01-08 16:26	PST	Eqp

Equipment failure during the period shown.

What's the best way to replace these lines? Just remove them or change them
to NA?

Regards,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 14 22:40:39 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 14 Sep 2021 13:40:39 -0700
Subject: [R] pseudoreplication
In-Reply-To: <CABPq8JNTwDFg4XeUhSe=uypzxOGnnyKahPt62_M5KzkyGevDkw@mail.gmail.com>
References: <CABPq8JNTwDFg4XeUhSe=uypzxOGnnyKahPt62_M5KzkyGevDkw@mail.gmail.com>
Message-ID: <CAGxFJbSoAiD3fArjJhgjAZmpObmUP-jd1WFAwV9Ri1ObaXg+5g@mail.gmail.com>

This should be posted on r-sig-mixed-models, not here. But you should
realize that "equivalent analysis" presumes knowledge of what ASReml
does, so that perhaps the best target of your query is the package
maintainer, not a list concerned with other methods.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Sep 14, 2021 at 10:52 AM James Henson <jfhenson1 at gmail.com> wrote:
>
> Greetings R Community
> The ASReml-R package will analyze data from experiments with
> pseudoreplications.
>
> Dealing with Pseudo-Replication in Linear Mixed Models
> https://www.vsni.co.uk/case-studies/dealing-with-pseudo-replication-in-linear-mixed-models
>
> Will the ?lme4? package return an equivalent analysis of data from
> experiments with pseudoreplications?
> Thank you for your assistance.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From g@@@powe|| @end|ng |rom protonm@||@com  Wed Sep 15 04:01:53 2021
From: g@@@powe|| @end|ng |rom protonm@||@com (Gregg Powell)
Date: Wed, 15 Sep 2021 02:01:53 +0000
Subject: [R] How to remove all rows that have a numeric in the first (or
 any) column
In-Reply-To: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
References: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
Message-ID: <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>




> Stuck on this problem - How does one remove all rows in a dataframe that have a numeric in the first (or any) column?
> 

> Seems straight forward - but I'm having trouble.
> 


I've attempted to used:

VPN_Sheet1 <- VPN_Sheet1[!is.numeric(VPN_Sheet1$HVA),]

and

VPN_Sheet1 <- VPN_Sheet1[!is.integer(VPN_Sheet1$HVA),]

Neither work - Neither throw an error.

class(VPN_Sheet1$HVA)  returns:
[1] "list"

So, the HVA column returns a list.

>
> Data looks like the attached screen grab -
> 

> The ONLY rows I need to delete are the rows where there is a numeric in the HVA column.
> 

> There are some 5000+ rows in the actual data.
> 

> Would be grateful for a solution to this problem.

How to get R to detect whether the value in column 1 is a number so the rows with the number values can be deleted?
> 

> Thanks in advance to any and all willing to help on this problem.
> 

> Gregg Powell
> 

> Sierra Vista, AZ
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 509 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210915/f0da5667/attachment.sig>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep 15 05:32:02 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 14 Sep 2021 20:32:02 -0700
Subject: [R] How to remove all rows that have a numeric in the first (or
 any) column
In-Reply-To: <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
References: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
 <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
Message-ID: <68A11171-83D4-4EDB-B98A-154BBDDF447D@dcn.davis.ca.us>

An atomic column of data by design has exactly one mode, so if _any_ values are non-numeric then the entire column will be non-numeric. What does

str(VPN_Sheet1$HVA)

tell you? It is likely either a factor or character data.

On September 14, 2021 7:01:53 PM PDT, Gregg Powell via R-help <r-help at r-project.org> wrote:
>
>
>
>> Stuck on this problem - How does one remove all rows in a dataframe that have a numeric in the first (or any) column?
>> 
>
>> Seems straight forward - but I'm having trouble.
>> 
>
>
>I've attempted to used:
>
>VPN_Sheet1 <- VPN_Sheet1[!is.numeric(VPN_Sheet1$HVA),]
>
>and
>
>VPN_Sheet1 <- VPN_Sheet1[!is.integer(VPN_Sheet1$HVA),]
>
>Neither work - Neither throw an error.
>
>class(VPN_Sheet1$HVA)  returns:
>[1] "list"
>
>So, the HVA column returns a list.
>
>>
>> Data looks like the attached screen grab -
>> 
>
>> The ONLY rows I need to delete are the rows where there is a numeric in the HVA column.
>> 
>
>> There are some 5000+ rows in the actual data.
>> 
>
>> Would be grateful for a solution to this problem.
>
>How to get R to detect whether the value in column 1 is a number so the rows with the number values can be deleted?
>> 
>
>> Thanks in advance to any and all willing to help on this problem.
>> 
>
>> Gregg Powell
>> 
>
>> Sierra Vista, AZ
-- 
Sent from my phone. Please excuse my brevity.


From g@@@powe|| @end|ng |rom protonm@||@com  Wed Sep 15 05:38:35 2021
From: g@@@powe|| @end|ng |rom protonm@||@com (Gregg Powell)
Date: Wed, 15 Sep 2021 03:38:35 +0000
Subject: [R] How to remove all rows that have a numeric in the first (or
 any) column
In-Reply-To: <68A11171-83D4-4EDB-B98A-154BBDDF447D@dcn.davis.ca.us>
References: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
 <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
 <68A11171-83D4-4EDB-B98A-154BBDDF447D@dcn.davis.ca.us>
Message-ID: <sE0QX_gzL2sYKaWmX7FuESeIEt_y4VDdE3PHJ1yPNe8Mlm8kQ3Wd8NYLzU9lQCA7iHUNSIqKNcO0M2_nzFq1JdMN26OCj2rZNw7lf-wyE5o=@protonmail.com>

Here is the output:

> str(VPN_Sheet1$HVA)
List of 2174
 $ : chr "Email: fffd at fffffffffff.com"
 $ : num 1
 $ : chr "Eloisa Libas"
 $ : chr "Percival Esquejo"
 $ : chr "Louchelle Singh"
 $ : num 2
 $ : chr "Charisse Anne Tabarno, RN"
 $ : chr "Sol Amor Mucoy"
 $ : chr "Josan Moira Paler"
 $ : num 3
 $ : chr "Anna Katrina V. Alberto"
 $ : chr "Nenita Velarde"
 $ : chr "Eunice Arrances"
 $ : num 4
 $ : chr "Catherine Henson"
 $ : chr "Maria Carla Daya"
 $ : chr "Renee Ireine Alit"
 $ : num 5
 $ : chr "Marol Joseph Domingo - PS"
 $ : chr "Kissy Andrea Arriesgado"
 $ : chr "Pia B Baluyut, RN"
 $ : num 6
 $ : chr "Gladys Joy Tan"
 $ : chr "Frances Zarzua"
 $ : chr "Fairy Jane Nery"
 $ : num 7
 $ : chr "Gladys Tijam, RMT"
 $ : chr "Sarah Jane Aramburo"
 $ : chr "Eve Mendoza"
 $ : num 8
 $ : chr "Gloria Padolino"
 $ : chr "Joyce Pearl Javier"
 $ : chr "Ayza Padilla"
 $ : num 9
 $ : chr "Walfredson Calderon"
 $ : chr "Stephanie Anne Militante"
 $ : chr "Rennua Oquilan"
 $ : num 10
 $ : chr "Neil John Nery"
 $ : chr "Maria Reyna Reyes"
 $ : chr "Rowella Villegas"
 $ : num 11
 $ : chr "Katelyn Mendiola"
 $ : chr "Maria Riza Mariano"
 $ : chr "Marie Vallianne Carantes"
 $ : num 12

??????? Original Message ???????

On Tuesday, September 14th, 2021 at 8:32 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> An atomic column of data by design has exactly one mode, so if any values are non-numeric then the entire column will be non-numeric. What does
> 

> str(VPN_Sheet1$HVA)
> 

> tell you? It is likely either a factor or character data.
> 

> On September 14, 2021 7:01:53 PM PDT, Gregg Powell via R-help r-help at r-project.org wrote:
> 

> > > Stuck on this problem - How does one remove all rows in a dataframe that have a numeric in the first (or any) column?
> > 

> > > Seems straight forward - but I'm having trouble.
> > 

> > I've attempted to used:
> > 

> > VPN_Sheet1 <- VPN_Sheet1[!is.numeric(VPN_Sheet1$HVA),]
> > 

> > and
> > 

> > VPN_Sheet1 <- VPN_Sheet1[!is.integer(VPN_Sheet1$HVA),]
> > 

> > Neither work - Neither throw an error.
> > 

> > class(VPN_Sheet1$HVA) returns:
> > 

> > [1] "list"
> > 

> > So, the HVA column returns a list.
> > 

> > > Data looks like the attached screen grab -
> > 

> > > The ONLY rows I need to delete are the rows where there is a numeric in the HVA column.
> > 

> > > There are some 5000+ rows in the actual data.
> > 

> > > Would be grateful for a solution to this problem.
> > 

> > How to get R to detect whether the value in column 1 is a number so the rows with the number values can be deleted?
> > 

> > > Thanks in advance to any and all willing to help on this problem.
> > 

> > > Gregg Powell
> > 

> > > Sierra Vista, AZ
> 

> --
> 

> Sent from my phone. Please excuse my brevity.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 509 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210915/678b14a1/attachment.sig>

From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Sep 15 05:47:32 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 15 Sep 2021 15:47:32 +1200
Subject: [R] How to remove all rows that have a numeric in the first (or
 any) column
In-Reply-To: <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
References: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
 <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
Message-ID: <20210915154124.5cb9eac2@rolf-Latitude-E7470>


On Wed, 15 Sep 2021 02:01:53 +0000
Gregg Powell via R-help <r-help at r-project.org> wrote:

> > Stuck on this problem - How does one remove all rows in a dataframe
> > that have a numeric in the first (or any) column?
> > 
> 
> > Seems straight forward - but I'm having trouble.
> > 
> 
> 
> I've attempted to used:
> 
> VPN_Sheet1 <- VPN_Sheet1[!is.numeric(VPN_Sheet1$HVA),]
> 
> and
> 
> VPN_Sheet1 <- VPN_Sheet1[!is.integer(VPN_Sheet1$HVA),]
> 
> Neither work - Neither throw an error.
> 
> class(VPN_Sheet1$HVA)  returns:
> [1] "list"
> 
> So, the HVA column returns a list.

Do you mean that the HVA column *is* a list? It probably shouldn't be.
It seems very likely that your data are all screwed up.  The first
thing to do is get your data properly organised.  That could be
difficult since you have apparently read them in from an Excel file,
and Excel is a recipe for disaster.

> 
> >
> > Data looks like the attached screen grab -

No attachment came through.  Do read the posting guide.  Most
attachments are stripped by the mail handler.

> > The ONLY rows I need to delete are the rows where there is a
> > numeric in the HVA column.
> > 
> 
> > There are some 5000+ rows in the actual data.
> > 
> 
> > Would be grateful for a solution to this problem.
> 
> How to get R to detect whether the value in column 1 is a number so
> the rows with the number values can be deleted?
> > 
> 
> > Thanks in advance to any and all willing to help on this problem.
> > 
> 
> > Gregg Powell
> > 
> 
> > Sierra Vista, AZ

If there are any non-numeric entries in a column then they *all* have
to be non-numeric.  Some of them *may* be interpretable as being
numeric.

If you apply as.numeric() to a column you'll get NA's for all entries
that *cannot* be interpreted as numeric. So you may want to do something
like (untested, of course):

ok <- is.na(as.numeric(X[,"HVA"]))
X  <- X[ok,]

where "X" is the data frame that you are dealing with.

Good luck.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @kw@|mmo @end|ng |rom gm@||@com  Wed Sep 15 05:48:21 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Tue, 14 Sep 2021 23:48:21 -0400
Subject: [R] How to remove all rows that have a numeric in the first (or
 any) column
In-Reply-To: <sE0QX_gzL2sYKaWmX7FuESeIEt_y4VDdE3PHJ1yPNe8Mlm8kQ3Wd8NYLzU9lQCA7iHUNSIqKNcO0M2_nzFq1JdMN26OCj2rZNw7lf-wyE5o=@protonmail.com>
References: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
 <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
 <68A11171-83D4-4EDB-B98A-154BBDDF447D@dcn.davis.ca.us>
 <sE0QX_gzL2sYKaWmX7FuESeIEt_y4VDdE3PHJ1yPNe8Mlm8kQ3Wd8NYLzU9lQCA7iHUNSIqKNcO0M2_nzFq1JdMN26OCj2rZNw7lf-wyE5o=@protonmail.com>
Message-ID: <CAPcHnpQFPY8eJOo5DKG=UaLyS48E9O0B43PGGeKGeorFwf0_EQ@mail.gmail.com>

'is.numeric' is a function that returns whether its input is a numeric
vector. It looks like what you want to do is

VPN_Sheet1 <- VPN_Sheet1[!vapply(VPN_Sheet1$HVA, "is.numeric", NA), ]

instead of

VPN_Sheet1 <- VPN_Sheet1[!is.numeric(VPN_Sheet1$HVA), ]

I hope this helps, and see ?vapply if necessary.

On Tue, Sep 14, 2021 at 11:42 PM Gregg Powell via R-help <
r-help at r-project.org> wrote:

> Here is the output:
>
> > str(VPN_Sheet1$HVA)
> List of 2174
>  $ : chr "Email: fffd at fffffffffff.com"
>  $ : num 1
>  $ : chr "Eloisa Libas"
>  $ : chr "Percival Esquejo"
>  $ : chr "Louchelle Singh"
>  $ : num 2
>  $ : chr "Charisse Anne Tabarno, RN"
>  $ : chr "Sol Amor Mucoy"
>  $ : chr "Josan Moira Paler"
>  $ : num 3
>  $ : chr "Anna Katrina V. Alberto"
>  $ : chr "Nenita Velarde"
>  $ : chr "Eunice Arrances"
>  $ : num 4
>  $ : chr "Catherine Henson"
>  $ : chr "Maria Carla Daya"
>  $ : chr "Renee Ireine Alit"
>  $ : num 5
>  $ : chr "Marol Joseph Domingo - PS"
>  $ : chr "Kissy Andrea Arriesgado"
>  $ : chr "Pia B Baluyut, RN"
>  $ : num 6
>  $ : chr "Gladys Joy Tan"
>  $ : chr "Frances Zarzua"
>  $ : chr "Fairy Jane Nery"
>  $ : num 7
>  $ : chr "Gladys Tijam, RMT"
>  $ : chr "Sarah Jane Aramburo"
>  $ : chr "Eve Mendoza"
>  $ : num 8
>  $ : chr "Gloria Padolino"
>  $ : chr "Joyce Pearl Javier"
>  $ : chr "Ayza Padilla"
>  $ : num 9
>  $ : chr "Walfredson Calderon"
>  $ : chr "Stephanie Anne Militante"
>  $ : chr "Rennua Oquilan"
>  $ : num 10
>  $ : chr "Neil John Nery"
>  $ : chr "Maria Reyna Reyes"
>  $ : chr "Rowella Villegas"
>  $ : num 11
>  $ : chr "Katelyn Mendiola"
>  $ : chr "Maria Riza Mariano"
>  $ : chr "Marie Vallianne Carantes"
>  $ : num 12
>
> ??????? Original Message ???????
>
> On Tuesday, September 14th, 2021 at 8:32 PM, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us> wrote:
>
> > An atomic column of data by design has exactly one mode, so if any
> values are non-numeric then the entire column will be non-numeric. What does
> >
>
> > str(VPN_Sheet1$HVA)
> >
>
> > tell you? It is likely either a factor or character data.
> >
>
> > On September 14, 2021 7:01:53 PM PDT, Gregg Powell via R-help
> r-help at r-project.org wrote:
> >
>
> > > > Stuck on this problem - How does one remove all rows in a dataframe
> that have a numeric in the first (or any) column?
> > >
>
> > > > Seems straight forward - but I'm having trouble.
> > >
>
> > > I've attempted to used:
> > >
>
> > > VPN_Sheet1 <- VPN_Sheet1[!is.numeric(VPN_Sheet1$HVA),]
> > >
>
> > > and
> > >
>
> > > VPN_Sheet1 <- VPN_Sheet1[!is.integer(VPN_Sheet1$HVA),]
> > >
>
> > > Neither work - Neither throw an error.
> > >
>
> > > class(VPN_Sheet1$HVA) returns:
> > >
>
> > > [1] "list"
> > >
>
> > > So, the HVA column returns a list.
> > >
>
> > > > Data looks like the attached screen grab -
> > >
>
> > > > The ONLY rows I need to delete are the rows where there is a numeric
> in the HVA column.
> > >
>
> > > > There are some 5000+ rows in the actual data.
> > >
>
> > > > Would be grateful for a solution to this problem.
> > >
>
> > > How to get R to detect whether the value in column 1 is a number so
> the rows with the number values can be deleted?
> > >
>
> > > > Thanks in advance to any and all willing to help on this problem.
> > >
>
> > > > Gregg Powell
> > >
>
> > > > Sierra Vista, AZ
> >
>
> > --
> >
>
> > Sent from my phone. Please excuse my
> brevity.______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Wed Sep 15 05:53:33 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Tue, 14 Sep 2021 23:53:33 -0400
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <12584b25-8150-4002-4eee-b4bc21525996@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
 <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
 <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
 <250d355b-072e-67cb-8bd5-bb012aed20a2@syonic.eu>
 <CAPcHnpSR=ZtCk=bX=NkFWO8wNc4hks07x+eGJU+Z4QA0+cJcjg@mail.gmail.com>
 <12584b25-8150-4002-4eee-b4bc21525996@syonic.eu>
Message-ID: <CAPcHnpRMj=mDqhZ7C-+VvYCj9r0trS=3iOuu4NsouCG8xB2Dtw@mail.gmail.com>

names(x) <- c("some names")

if different from

`names<-`(x, value = c("some names"))

because the second piece of code does not ever call `<-`. The first piece
of code is (approximately) equivalent to

`*tmp*` <- x
`*tmp*` <- `names<-`(`*tmp*`, value = c("some names"))
x <- `*tmp*`

Another example,

y <- `names<-`(x, value = c("some names"))

now y will be equivalent to x if we did

names(x) <- c("some names")

except that the first will not update x, it will still have its old names.

On Mon, Sep 13, 2021 at 4:33 PM Leonard Mada <leo.mada at syonic.eu> wrote:

>
> On 9/13/2021 11:28 PM, Andrew Simmons wrote:
>
> In the example you gave : r(x) <- 1
> r(x) is never evaluated, the above calls `r<-`,
> in fact r does not even have to be an existing function.
>
>
> I meant:
>
> '*tmp*' <- x; # "x" is evaluated here;
>
> 'r<-' is called after this step, which makes sense in the case of
> subsetting;
>
>
> But I am wondering if changing this behaviour, when NO subsetting is
> performed, would have any impact.
>
> e.g. names(x) = c("some names");
>
> # would it have any impact to skip the evaluation of "x" and call directly:
>
> 'names<-'(x, value);
>
>
> Leonard
>
>
>
> On Mon, Sep 13, 2021, 16:18 Leonard Mada <leo.mada at syonic.eu> wrote:
>
>> Hello,
>>
>>
>> I have found the evaluation: it is described in the section on
>> subsetting. The forced evaluation makes sense for subsetting.
>>
>>
>> On 9/13/2021 9:42 PM, Leonard Mada wrote:
>>
>> Hello Andrew,
>>
>>
>> I try now to understand the evaluation of the expression:
>>
>> e = expression(r(x) <- 1)
>>
>> # parameter named "value" seems to be required;
>> 'r<-' = function(x, value) {print("R");}
>> eval(e, list(x=2))
>> # [1] "R"
>>
>> # both versions work
>> 'r<-' = function(value, x) {print("R");}
>> eval(e, list(x=2))
>> # [1] "R"
>>
>>
>> ### the Expression
>> e[[1]][[1]] # "<-", not "r<-"
>> e[[1]][[2]] # "r(x)"
>>
>>
>> The evaluation of "e" somehow calls "r<-", but evaluates also the
>> argument of r(...). I am still investigating what is actually happening.
>>
>>
>> The forced evaluation is relevant for subsetting, e.g.:
>> expression(r(x)[3] <- 1)
>> expression(r(x)[3] <- 1)[[1]][[2]]
>> # r(x)[3] # the evaluation details are NOT visible in the expression per
>> se;
>> # Note: indeed, it makes sens to first evaluate r(x) and then to perform
>> the subsetting;
>>
>>
>> However, in the case of a non-subsetted expression:
>> r(x) <- 1;
>> It would make sense to evaluate lazily r(x) if no subsetting is involved
>> (more precisely "r<-"(x, value) ).
>>
>> Would this have any impact on the current code?
>>
>>
>> Sincerely,
>>
>>
>> Leonard
>>
>>
>>
>> Sincerely,
>>
>>
>> Leonard
>>
>>
>> On 9/13/2021 9:15 PM, Andrew Simmons wrote:
>>
>> R's parser doesn't work the way you're expecting it to. When doing an
>> assignment like:
>>
>>
>> padding(right(df)) <- 1
>>
>>
>> it is broken into small stages. The guide "R Language Definition" claims
>> that the above would be equivalent to:
>>
>>
>> `<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))
>>
>>
>> but that is not correct, and you can tell by using `substitute` as you
>> were above. There isn't a way to do what you want with the syntax you
>> provided, you'll have to do something different. You could add a `which`
>> argument to each style function, and maybe put the code for `match.arg` in
>> a separate function:
>>
>>
>> match.which <- function (which)
>> match.arg(which, c("bottom", "left", "top", "right"), several.ok = TRUE)
>>
>>
>> padding <- function (x, which)
>> {
>>     which <- match.which(which)
>>     # more code
>> }
>>
>>
>> border <- function (x, which)
>> {
>>     which <- match.which(which)
>>     # more code
>> }
>>
>>
>> some_other_style <- function (x, which)
>> {
>>     which <- match.which(which)
>>     # more code
>> }
>>
>>
>> I hope this helps.
>>
>> On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada <leo.mada at syonic.eu> wrote:
>>
>>> Hello Andrew,
>>>
>>>
>>> this could work. I will think about it.
>>>
>>> But I was thinking more generically. Suppose we have a series of
>>> functions:
>>> padding(), border(), some_other_style();
>>> Each of these functions has the parameter "right" (or the group of
>>> parameters c("right", ...)).
>>>
>>>
>>> Then I could design a function right(FUN) that assigns the value to this
>>> parameter and evaluates the function FUN().
>>>
>>>
>>> There are a few ways to do this:
>>> 1.) Other parameters as ...
>>> right(FUN, value, ...) = value; and then pass "..." to FUN.
>>> right(value, FUN, ...) = value; # or is this the syntax? (TODO: explore)
>>>
>>> 2.) Another way:
>>> right(FUN(...other parameters already specified...)) = value;
>>> I wanted to explore this 2nd option: but avoid evaluating FUN, unless
>>> the parameter "right" is injected into the call.
>>>
>>> 3.) Option 3:
>>> The option you mentioned.
>>>
>>>
>>> Independent of the method: there are still weird/unexplained behaviours
>>> when I try the initial code (see the latest mail with the improved code).
>>>
>>>
>>> Sincerely,
>>>
>>>
>>> Leonard
>>>
>>>
>>> On 9/13/2021 6:45 PM, Andrew Simmons wrote:
>>>
>>> I think you're trying to do something like:
>>>
>>> `padding<-` <- function (x, which, value)
>>> {
>>>     which <- match.arg(which, c("bottom", "left", "top", "right"),
>>> several.ok = TRUE)
>>>     # code to pad to each side here
>>> }
>>>
>>> Then you could use it like
>>>
>>> df <- data.frame(x=1:5, y = sample(1:5, 5))
>>> padding(df, "right") <- 1
>>>
>>> Does that work as expected for you?
>>>
>>> On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help <
>>> r-help at r-project.org> wrote:
>>>
>>>> I try to clarify the code:
>>>>
>>>>
>>>> ###
>>>> right = function(x, val) {print("Right");};
>>>> padding = function(x, right, left, top, bottom) {print("Padding");};
>>>> 'padding<-' = function(x, ...) {print("Padding = ");};
>>>> df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>>>>
>>>> ### Does NOT work as expected
>>>> 'right<-' = function(x, value) {
>>>>      print("This line should be the first printed!")
>>>>      print("But ERROR: x was already evaluated, which printed
>>>> \"Padding\"");
>>>>      x = substitute(x); # x was already evaluated before substitute();
>>>>      return("Nothing"); # do not now what the behaviour should be?
>>>> }
>>>>
>>>> right(padding(df)) = 1;
>>>>
>>>> ### Output:
>>>>
>>>> [1] "Padding"
>>>> [1] "This line should be the first printed!"
>>>> [1] "But ERROR: x was already evaluated, which printed \"Padding\""
>>>> [1] "Padding = " # How did this happen ???
>>>>
>>>>
>>>> ### Problems:
>>>>
>>>> 1.) substitute(x): did not capture the expression;
>>>> - the first parameter of 'right<-' was already evaluated, which is not
>>>> the case with '%f%';
>>>> Can I avoid evaluating this parameter?
>>>> How can I avoid to evaluate it and capture the expression: "right(...)"?
>>>>
>>>>
>>>> 2.) Unexpected
>>>> 'padding<-' was also called!
>>>> I did not know this. Is it feature or bug?
>>>> R 4.0.4
>>>>
>>>>
>>>> Sincerely,
>>>>
>>>>
>>>> Leonard
>>>>
>>>>
>>>> On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>>>> > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>>>> >> Hello,
>>>> >>
>>>> >>
>>>> >> I can include code for "padding<-"as well, but the error is before
>>>> that,
>>>> >> namely in 'right<-':
>>>> >>
>>>> >> right = function(x, val) {print("Right");};
>>>> >> # more options:
>>>> >> padding = function(x, right, left, top, bottom) {print("Padding");};
>>>> >> 'padding<-' = function(x, ...) {print("Padding = ");};
>>>> >> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>> >>
>>>> >>
>>>> >> ### Does NOT work
>>>> >> 'right<-' = function(x, val) {
>>>> >>         print("Already evaluated and also does not use 'val'");
>>>> >>         x = substitute(x); # x was evaluated before
>>>> >> }
>>>> >>
>>>> >> right(padding(df)) = 1;
>>>> >
>>>> > It "works" (i.e. doesn't generate an error) for me, when I correct
>>>> > your typo:  the second argument to `right<-` should be `value`, not
>>>> > `val`.
>>>> >
>>>> > I'm still not clear whether it does what you want with that fix,
>>>> > because I don't really understand what you want.
>>>> >
>>>> > Duncan Murdoch
>>>> >
>>>> >>
>>>> >>
>>>> >> I want to capture the assignment event inside "right<-" and then call
>>>> >> the function padding() properly.
>>>> >>
>>>> >> I haven't thought yet if I should use:
>>>> >>
>>>> >> padding(x, right, left, ... other parameters);
>>>> >>
>>>> >> or
>>>> >>
>>>> >> padding(x, parameter) <- value;
>>>> >>
>>>> >>
>>>> >> It also depends if I can properly capture the unevaluated expression
>>>> >> inside "right<-":
>>>> >>
>>>> >> 'right<-' = function(x, val) {
>>>> >>
>>>> >> # x is automatically evaluated when using 'f<-'!
>>>> >>
>>>> >> # but not when implementing as '%f%' = function(x, y);
>>>> >>
>>>> >> }
>>>> >>
>>>> >>
>>>> >> Many thanks,
>>>> >>
>>>> >>
>>>> >> Leonard
>>>> >>
>>>> >>
>>>> >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>>>> >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>>>> >>>> How can I avoid evaluation?
>>>> >>>>
>>>> >>>> right = function(x, val) {print("Right");};
>>>> >>>> padding = function(x) {print("Padding");};
>>>> >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>> >>>>
>>>> >>>> ### OK
>>>> >>>> '%=%' = function(x, val) {
>>>> >>>>        x = substitute(x);
>>>> >>>> }
>>>> >>>> right(padding(df)) %=% 1; # but ugly
>>>> >>>>
>>>> >>>> ### Does NOT work
>>>> >>>> 'right<-' = function(x, val) {
>>>> >>>>        print("Already evaluated and also does not use 'val'");
>>>> >>>>        x = substitute(x); # is evaluated before
>>>> >>>> }
>>>> >>>>
>>>> >>>> right(padding(df)) = 1
>>>> >>>
>>>> >>> That doesn't make sense.  You don't have a `padding<-` function, and
>>>> >>> yet you are trying to call right<- to assign something to
>>>> padding(df).
>>>> >>>
>>>> >>> I'm not sure about your real intention, but assignment functions by
>>>> >>> their nature need to evaluate the thing they are assigning to, since
>>>> >>> they are designed to modify objects, not create new ones.
>>>> >>>
>>>> >>> To create a new object, just use regular assignment.
>>>> >>>
>>>> >>> Duncan Murdoch
>>>> >
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep 15 05:54:12 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 14 Sep 2021 20:54:12 -0700
Subject: [R] How to remove all rows that have a numeric in the first (or
 any) column
In-Reply-To: <sE0QX_gzL2sYKaWmX7FuESeIEt_y4VDdE3PHJ1yPNe8Mlm8kQ3Wd8NYLzU9lQCA7iHUNSIqKNcO0M2_nzFq1JdMN26OCj2rZNw7lf-wyE5o=@protonmail.com>
References: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
 <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
 <68A11171-83D4-4EDB-B98A-154BBDDF447D@dcn.davis.ca.us>
 <sE0QX_gzL2sYKaWmX7FuESeIEt_y4VDdE3PHJ1yPNe8Mlm8kQ3Wd8NYLzU9lQCA7iHUNSIqKNcO0M2_nzFq1JdMN26OCj2rZNw7lf-wyE5o=@protonmail.com>
Message-ID: <5F88E791-CEC3-4B77-BF54-47D4D03094FB@dcn.davis.ca.us>

You cannot apply vectorized operators to list columns... you have to use a map function like sapply or purrr::map_lgl to obtain a logical vector by running the function once for each list element:

sapply( VPN_Sheet1$HVA, is.numeric )

On September 14, 2021 8:38:35 PM PDT, Gregg Powell <g.a.powell at protonmail.com> wrote:
>Here is the output:
>
>> str(VPN_Sheet1$HVA)
>List of 2174
> $ : chr "Email: fffd at fffffffffff.com"
> $ : num 1
> $ : chr "Eloisa Libas"
> $ : chr "Percival Esquejo"
> $ : chr "Louchelle Singh"
> $ : num 2
> $ : chr "Charisse Anne Tabarno, RN"
> $ : chr "Sol Amor Mucoy"
> $ : chr "Josan Moira Paler"
> $ : num 3
> $ : chr "Anna Katrina V. Alberto"
> $ : chr "Nenita Velarde"
> $ : chr "Eunice Arrances"
> $ : num 4
> $ : chr "Catherine Henson"
> $ : chr "Maria Carla Daya"
> $ : chr "Renee Ireine Alit"
> $ : num 5
> $ : chr "Marol Joseph Domingo - PS"
> $ : chr "Kissy Andrea Arriesgado"
> $ : chr "Pia B Baluyut, RN"
> $ : num 6
> $ : chr "Gladys Joy Tan"
> $ : chr "Frances Zarzua"
> $ : chr "Fairy Jane Nery"
> $ : num 7
> $ : chr "Gladys Tijam, RMT"
> $ : chr "Sarah Jane Aramburo"
> $ : chr "Eve Mendoza"
> $ : num 8
> $ : chr "Gloria Padolino"
> $ : chr "Joyce Pearl Javier"
> $ : chr "Ayza Padilla"
> $ : num 9
> $ : chr "Walfredson Calderon"
> $ : chr "Stephanie Anne Militante"
> $ : chr "Rennua Oquilan"
> $ : num 10
> $ : chr "Neil John Nery"
> $ : chr "Maria Reyna Reyes"
> $ : chr "Rowella Villegas"
> $ : num 11
> $ : chr "Katelyn Mendiola"
> $ : chr "Maria Riza Mariano"
> $ : chr "Marie Vallianne Carantes"
> $ : num 12
>
>??????? Original Message ???????
>
>On Tuesday, September 14th, 2021 at 8:32 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
>> An atomic column of data by design has exactly one mode, so if any values are non-numeric then the entire column will be non-numeric. What does
>> 
>
>> str(VPN_Sheet1$HVA)
>> 
>
>> tell you? It is likely either a factor or character data.
>> 
>
>> On September 14, 2021 7:01:53 PM PDT, Gregg Powell via R-help r-help at r-project.org wrote:
>> 
>
>> > > Stuck on this problem - How does one remove all rows in a dataframe that have a numeric in the first (or any) column?
>> > 
>
>> > > Seems straight forward - but I'm having trouble.
>> > 
>
>> > I've attempted to used:
>> > 
>
>> > VPN_Sheet1 <- VPN_Sheet1[!is.numeric(VPN_Sheet1$HVA),]
>> > 
>
>> > and
>> > 
>
>> > VPN_Sheet1 <- VPN_Sheet1[!is.integer(VPN_Sheet1$HVA),]
>> > 
>
>> > Neither work - Neither throw an error.
>> > 
>
>> > class(VPN_Sheet1$HVA) returns:
>> > 
>
>> > [1] "list"
>> > 
>
>> > So, the HVA column returns a list.
>> > 
>
>> > > Data looks like the attached screen grab -
>> > 
>
>> > > The ONLY rows I need to delete are the rows where there is a numeric in the HVA column.
>> > 
>
>> > > There are some 5000+ rows in the actual data.
>> > 
>
>> > > Would be grateful for a solution to this problem.
>> > 
>
>> > How to get R to detect whether the value in column 1 is a number so the rows with the number values can be deleted?
>> > 
>
>> > > Thanks in advance to any and all willing to help on this problem.
>> > 
>
>> > > Gregg Powell
>> > 
>
>> > > Sierra Vista, AZ
>> 
>
>> --
>> 
>
>> Sent from my phone. Please excuse my brevity.
-- 
Sent from my phone. Please excuse my brevity.


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Sep 15 06:39:55 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 15 Sep 2021 00:39:55 -0400
Subject: [R] How to remove all rows that have a numeric in the first (or
 any) column
In-Reply-To: <5F88E791-CEC3-4B77-BF54-47D4D03094FB@dcn.davis.ca.us>
References: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
 <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
 <68A11171-83D4-4EDB-B98A-154BBDDF447D@dcn.davis.ca.us>
 <sE0QX_gzL2sYKaWmX7FuESeIEt_y4VDdE3PHJ1yPNe8Mlm8kQ3Wd8NYLzU9lQCA7iHUNSIqKNcO0M2_nzFq1JdMN26OCj2rZNw7lf-wyE5o=@protonmail.com>
 <5F88E791-CEC3-4B77-BF54-47D4D03094FB@dcn.davis.ca.us>
Message-ID: <03f801d7a9eb$bba80b40$32f821c0$@verizon.net>

Calling something a data.frame does not make it a data.frame.

The abbreviated object shown below is a list of singletons. If it is a column in a larger object that is a data.frame, then it is a list column which is valid but can be ticklish to handle within base R but less so in the tidyverse.

For example, if I try to make a data.frame the normal way, the list gets made into multiple columns and copied to each row. Not what was expected. I think some tidyverse functionality does better.

Like this:

library(tidyverse)
temp=list("Hello", 1, 1.1, "bye")

Now making a data.frame has an odd result:

> mydf=data.frame(alpha=1:4, beta=temp)
> mydf
alpha beta..Hello. beta.1 beta.1.1 beta..bye.
1     1        Hello      1      1.1        bye
2     2        Hello      1      1.1        bye
3     3        Hello      1      1.1        bye
4     4        Hello      1      1.1        bye

But a tibble handles it:

> mydf=tibble(alpha=1:4, beta=temp)
> mydf
# A tibble: 4 x 2
alpha beta     
<int> <list>   
  1     1 <chr [1]>
  2     2 <dbl [1]>
  3     3 <dbl [1]>
  4     4 <chr [1]>

So if the data does look like this, with a list column, but access can be tricky as subsetting a list with [] returns a list and you need [[]].

I found a somehwhat odd solution like this:

mydf %>%
   filter(!map_lgl(beta, is.numeric)) -> mydf2
# A tibble: 2 x 2
alpha beta     
<int> <list>   
  1     1 <chr [1]>
  2     4 <chr [1]>

When I saved that result into mydf2, I got this.

Original:
  
  > str(mydf)
tibble [4 x 2] (S3: tbl_df/tbl/data.frame)
$ alpha: int [1:4] 1 2 3 4
$ beta :List of 4
..$ : chr "Hello"
..$ : num 1
..$ : num 1.1
..$ : chr "bye"

Output when any row with a numeric is removed:

> str(mydf2)
tibble [2 x 2] (S3: tbl_df/tbl/data.frame)
$ alpha: int [1:2] 1 4
$ beta :List of 2
..$ : chr "Hello"
..$ : chr "bye"

So if you try variations on your code motivated by what I show, good luck. I am sure there are many better ways but I repeat, it can be tricky.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
Sent: Tuesday, September 14, 2021 11:54 PM
To: Gregg Powell <g.a.powell at protonmail.com>
Cc: Gregg Powell via R-help <r-help at r-project.org>
Subject: Re: [R] How to remove all rows that have a numeric in the first (or any) column

You cannot apply vectorized operators to list columns... you have to use a map function like sapply or purrr::map_lgl to obtain a logical vector by running the function once for each list element:

sapply( VPN_Sheet1$HVA, is.numeric )

On September 14, 2021 8:38:35 PM PDT, Gregg Powell <g.a.powell at protonmail.com> wrote:
>Here is the output:
>
>> str(VPN_Sheet1$HVA)
>List of 2174
> $ : chr "Email: fffd at fffffffffff.com"
> $ : num 1
> $ : chr "Eloisa Libas"
> $ : chr "Percival Esquejo"
> $ : chr "Louchelle Singh"
> $ : num 2
> $ : chr "Charisse Anne Tabarno, RN"
> $ : chr "Sol Amor Mucoy"
> $ : chr "Josan Moira Paler"
> $ : num 3
> $ : chr "Anna Katrina V. Alberto"
> $ : chr "Nenita Velarde"
> $ : chr "Eunice Arrances"
> $ : num 4
> $ : chr "Catherine Henson"
> $ : chr "Maria Carla Daya"
> $ : chr "Renee Ireine Alit"
> $ : num 5
> $ : chr "Marol Joseph Domingo - PS"
> $ : chr "Kissy Andrea Arriesgado"
> $ : chr "Pia B Baluyut, RN"
> $ : num 6
> $ : chr "Gladys Joy Tan"
> $ : chr "Frances Zarzua"
> $ : chr "Fairy Jane Nery"
> $ : num 7
> $ : chr "Gladys Tijam, RMT"
> $ : chr "Sarah Jane Aramburo"
> $ : chr "Eve Mendoza"
> $ : num 8
> $ : chr "Gloria Padolino"
> $ : chr "Joyce Pearl Javier"
> $ : chr "Ayza Padilla"
> $ : num 9
> $ : chr "Walfredson Calderon"
> $ : chr "Stephanie Anne Militante"
> $ : chr "Rennua Oquilan"
> $ : num 10
> $ : chr "Neil John Nery"
> $ : chr "Maria Reyna Reyes"
> $ : chr "Rowella Villegas"
> $ : num 11
> $ : chr "Katelyn Mendiola"
> $ : chr "Maria Riza Mariano"
> $ : chr "Marie Vallianne Carantes"
> $ : num 12
>
>??????? Original Message ???????
>
>On Tuesday, September 14th, 2021 at 8:32 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
>> An atomic column of data by design has exactly one mode, so if any 
>> values are non-numeric then the entire column will be non-numeric. 
>> What does
>> 
>
>> str(VPN_Sheet1$HVA)
>> 
>
>> tell you? It is likely either a factor or character data.
>> 
>
>> On September 14, 2021 7:01:53 PM PDT, Gregg Powell via R-help r-help at r-project.org wrote:
>> 
>
>> > > Stuck on this problem - How does one remove all rows in a dataframe that have a numeric in the first (or any) column?
>> > 
>
>> > > Seems straight forward - but I'm having trouble.
>> > 
>
>> > I've attempted to used:
>> > 
>
>> > VPN_Sheet1 <- VPN_Sheet1[!is.numeric(VPN_Sheet1$HVA),]
>> > 
>
>> > and
>> > 
>
>> > VPN_Sheet1 <- VPN_Sheet1[!is.integer(VPN_Sheet1$HVA),]
>> > 
>
>> > Neither work - Neither throw an error.
>> > 
>
>> > class(VPN_Sheet1$HVA) returns:
>> > 
>
>> > [1] "list"
>> > 
>
>> > So, the HVA column returns a list.
>> > 
>
>> > > Data looks like the attached screen grab -
>> > 
>
>> > > The ONLY rows I need to delete are the rows where there is a numeric in the HVA column.
>> > 
>
>> > > There are some 5000+ rows in the actual data.
>> > 
>
>> > > Would be grateful for a solution to this problem.
>> > 
>
>> > How to get R to detect whether the value in column 1 is a number so the rows with the number values can be deleted?
>> > 
>
>> > > Thanks in advance to any and all willing to help on this problem.
>> > 
>
>> > > Gregg Powell
>> > 
>
>> > > Sierra Vista, AZ
>> 
>
>> --
>> 
>
>> Sent from my phone. Please excuse my brevity.
--
Sent from my phone. Please excuse my brevity.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Sep 15 06:41:38 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 15 Sep 2021 00:41:38 -0400
Subject: [R] How to remove all rows that have a numeric in the first (or
 any) column
References: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
 <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
 <68A11171-83D4-4EDB-B98A-154BBDDF447D@dcn.davis.ca.us>
 <sE0QX_gzL2sYKaWmX7FuESeIEt_y4VDdE3PHJ1yPNe8Mlm8kQ3Wd8NYLzU9lQCA7iHUNSIqKNcO0M2_nzFq1JdMN26OCj2rZNw7lf-wyE5o=@protonmail.com>
 <5F88E791-CEC3-4B77-BF54-47D4D03094FB@dcn.davis.ca.us> 
Message-ID: <042b01d7a9eb$f8e7d2b0$eab77810$@verizon.net>


Calling something a data.frame does not make it a data.frame.

The abbreviated object shown below is a list of singletons. If it is a column in a larger object that is a data.frame, then it is a list column which is valid but can be ticklish to handle within base R but less so in the tidyverse.

For example, if I try to make a data.frame the normal way, the list gets made into multiple columns and copied to each row. Not what was expected. I think some tidyverse functionality does better.

Like this:

library(tidyverse)
temp=list("Hello", 1, 1.1, "bye")

Now making a data.frame has an odd result:

> mydf=data.frame(alpha=1:4, beta=temp)
> mydf
alpha beta..Hello. beta.1 beta.1.1 beta..bye.
1     1        Hello      1      1.1        bye
2     2        Hello      1      1.1        bye
3     3        Hello      1      1.1        bye
4     4        Hello      1      1.1        bye

But a tibble handles it:

> mydf=tibble(alpha=1:4, beta=temp)
> mydf
# A tibble: 4 x 2
alpha beta     
<int> <list>   
  1     1 <chr [1]>
  2     2 <dbl [1]>
  3     3 <dbl [1]>
  4     4 <chr [1]>

So if the data does look like this, with a list column, but access can be tricky as subsetting a list with [] returns a list and you need [[]].

I found a somehwhat odd solution like this:

mydf %>%
   filter(!map_lgl(beta, is.numeric)) -> mydf2 # A tibble: 2 x 2
alpha beta     
<int> <list>   
  1     1 <chr [1]>
  2     4 <chr [1]>

When I saved that result into mydf2, I got this.

Original:
  
  > str(mydf)
tibble [4 x 2] (S3: tbl_df/tbl/data.frame) $ alpha: int [1:4] 1 2 3 4 $ beta :List of 4 ..$ : chr "Hello"
..$ : num 1
..$ : num 1.1
..$ : chr "bye"

Output when any row with a numeric is removed:

> str(mydf2)
tibble [2 x 2] (S3: tbl_df/tbl/data.frame) $ alpha: int [1:2] 1 4 $ beta :List of 2 ..$ : chr "Hello"
..$ : chr "bye"

So if you try variations on your code motivated by what I show, good luck. I am sure there are many better ways but I repeat, it can be tricky.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
Sent: Tuesday, September 14, 2021 11:54 PM
To: Gregg Powell <g.a.powell at protonmail.com>
Cc: Gregg Powell via R-help <r-help at r-project.org>
Subject: Re: [R] How to remove all rows that have a numeric in the first (or any) column

You cannot apply vectorized operators to list columns... you have to use a map function like sapply or purrr::map_lgl to obtain a logical vector by running the function once for each list element:

sapply( VPN_Sheet1$HVA, is.numeric )

On September 14, 2021 8:38:35 PM PDT, Gregg Powell <g.a.powell at protonmail.com> wrote:
>Here is the output:
>
>> str(VPN_Sheet1$HVA)
>List of 2174
> $ : chr "Email: fffd at fffffffffff.com"
> $ : num 1
> $ : chr "Eloisa Libas"
> $ : chr "Percival Esquejo"
> $ : chr "Louchelle Singh"
> $ : num 2
> $ : chr "Charisse Anne Tabarno, RN"
> $ : chr "Sol Amor Mucoy"
> $ : chr "Josan Moira Paler"
> $ : num 3
> $ : chr "Anna Katrina V. Alberto"
> $ : chr "Nenita Velarde"
> $ : chr "Eunice Arrances"
> $ : num 4
> $ : chr "Catherine Henson"
> $ : chr "Maria Carla Daya"
> $ : chr "Renee Ireine Alit"
> $ : num 5
> $ : chr "Marol Joseph Domingo - PS"
> $ : chr "Kissy Andrea Arriesgado"
> $ : chr "Pia B Baluyut, RN"
> $ : num 6
> $ : chr "Gladys Joy Tan"
> $ : chr "Frances Zarzua"
> $ : chr "Fairy Jane Nery"
> $ : num 7
> $ : chr "Gladys Tijam, RMT"
> $ : chr "Sarah Jane Aramburo"
> $ : chr "Eve Mendoza"
> $ : num 8
> $ : chr "Gloria Padolino"
> $ : chr "Joyce Pearl Javier"
> $ : chr "Ayza Padilla"
> $ : num 9
> $ : chr "Walfredson Calderon"
> $ : chr "Stephanie Anne Militante"
> $ : chr "Rennua Oquilan"
> $ : num 10
> $ : chr "Neil John Nery"
> $ : chr "Maria Reyna Reyes"
> $ : chr "Rowella Villegas"
> $ : num 11
> $ : chr "Katelyn Mendiola"
> $ : chr "Maria Riza Mariano"
> $ : chr "Marie Vallianne Carantes"
> $ : num 12
>
>??????? Original Message ???????
>
>On Tuesday, September 14th, 2021 at 8:32 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
>> An atomic column of data by design has exactly one mode, so if any 
>> values are non-numeric then the entire column will be non-numeric.
>> What does
>> 
>
>> str(VPN_Sheet1$HVA)
>> 
>
>> tell you? It is likely either a factor or character data.
>> 
>
>> On September 14, 2021 7:01:53 PM PDT, Gregg Powell via R-help r-help at r-project.org wrote:
>> 
>
>> > > Stuck on this problem - How does one remove all rows in a dataframe that have a numeric in the first (or any) column?
>> > 
>
>> > > Seems straight forward - but I'm having trouble.
>> > 
>
>> > I've attempted to used:
>> > 
>
>> > VPN_Sheet1 <- VPN_Sheet1[!is.numeric(VPN_Sheet1$HVA),]
>> > 
>
>> > and
>> > 
>
>> > VPN_Sheet1 <- VPN_Sheet1[!is.integer(VPN_Sheet1$HVA),]
>> > 
>
>> > Neither work - Neither throw an error.
>> > 
>
>> > class(VPN_Sheet1$HVA) returns:
>> > 
>
>> > [1] "list"
>> > 
>
>> > So, the HVA column returns a list.
>> > 
>
>> > > Data looks like the attached screen grab -
>> > 
>
>> > > The ONLY rows I need to delete are the rows where there is a numeric in the HVA column.
>> > 
>
>> > > There are some 5000+ rows in the actual data.
>> > 
>
>> > > Would be grateful for a solution to this problem.
>> > 
>
>> > How to get R to detect whether the value in column 1 is a number so the rows with the number values can be deleted?
>> > 
>
>> > > Thanks in advance to any and all willing to help on this problem.
>> > 
>
>> > > Gregg Powell
>> > 
>
>> > > Sierra Vista, AZ
>> 
>
>> --
>> 
>
>> Sent from my phone. Please excuse my brevity.
--
Sent from my phone. Please excuse my brevity.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @kw@|mmo @end|ng |rom gm@||@com  Wed Sep 15 06:44:12 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Wed, 15 Sep 2021 00:44:12 -0400
Subject: [R] How to remove all rows that have a numeric in the first (or
 any) column
In-Reply-To: <03f801d7a9eb$bba80b40$32f821c0$@verizon.net>
References: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
 <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
 <68A11171-83D4-4EDB-B98A-154BBDDF447D@dcn.davis.ca.us>
 <sE0QX_gzL2sYKaWmX7FuESeIEt_y4VDdE3PHJ1yPNe8Mlm8kQ3Wd8NYLzU9lQCA7iHUNSIqKNcO0M2_nzFq1JdMN26OCj2rZNw7lf-wyE5o=@protonmail.com>
 <5F88E791-CEC3-4B77-BF54-47D4D03094FB@dcn.davis.ca.us>
 <03f801d7a9eb$bba80b40$32f821c0$@verizon.net>
Message-ID: <CAPcHnpRgC=t_9s3T9d7qbMH2_ShN23HTEkx3AuNXaBviYv1yzA@mail.gmail.com>

I'd like to point out that base R can handle a list as a data frame column,
it's just that you have to make the list of class "AsIs". So in your example

temp <- list("Hello", 1, 1.1, "bye")

data.frame(alpha = 1:4, beta = I(temp))

means that column "beta" will still be a list.



On Wed, Sep 15, 2021, 00:40 Avi Gross via R-help <r-help at r-project.org>
wrote:

> Calling something a data.frame does not make it a data.frame.
>
> The abbreviated object shown below is a list of singletons. If it is a
> column in a larger object that is a data.frame, then it is a list column
> which is valid but can be ticklish to handle within base R but less so in
> the tidyverse.
>
> For example, if I try to make a data.frame the normal way, the list gets
> made into multiple columns and copied to each row. Not what was expected. I
> think some tidyverse functionality does better.
>
> Like this:
>
> library(tidyverse)
> temp=list("Hello", 1, 1.1, "bye")
>
> Now making a data.frame has an odd result:
>
> > mydf=data.frame(alpha=1:4, beta=temp)
> > mydf
> alpha beta..Hello. beta.1 beta.1.1 beta..bye.
> 1     1        Hello      1      1.1        bye
> 2     2        Hello      1      1.1        bye
> 3     3        Hello      1      1.1        bye
> 4     4        Hello      1      1.1        bye
>
> But a tibble handles it:
>
> > mydf=tibble(alpha=1:4, beta=temp)
> > mydf
> # A tibble: 4 x 2
> alpha beta
> <int> <list>
>   1     1 <chr [1]>
>   2     2 <dbl [1]>
>   3     3 <dbl [1]>
>   4     4 <chr [1]>
>
> So if the data does look like this, with a list column, but access can be
> tricky as subsetting a list with [] returns a list and you need [[]].
>
> I found a somehwhat odd solution like this:
>
> mydf %>%
>    filter(!map_lgl(beta, is.numeric)) -> mydf2
> # A tibble: 2 x 2
> alpha beta
> <int> <list>
>   1     1 <chr [1]>
>   2     4 <chr [1]>
>
> When I saved that result into mydf2, I got this.
>
> Original:
>
>   > str(mydf)
> tibble [4 x 2] (S3: tbl_df/tbl/data.frame)
> $ alpha: int [1:4] 1 2 3 4
> $ beta :List of 4
> ..$ : chr "Hello"
> ..$ : num 1
> ..$ : num 1.1
> ..$ : chr "bye"
>
> Output when any row with a numeric is removed:
>
> > str(mydf2)
> tibble [2 x 2] (S3: tbl_df/tbl/data.frame)
> $ alpha: int [1:2] 1 4
> $ beta :List of 2
> ..$ : chr "Hello"
> ..$ : chr "bye"
>
> So if you try variations on your code motivated by what I show, good luck.
> I am sure there are many better ways but I repeat, it can be tricky.
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller
> Sent: Tuesday, September 14, 2021 11:54 PM
> To: Gregg Powell <g.a.powell at protonmail.com>
> Cc: Gregg Powell via R-help <r-help at r-project.org>
> Subject: Re: [R] How to remove all rows that have a numeric in the first
> (or any) column
>
> You cannot apply vectorized operators to list columns... you have to use a
> map function like sapply or purrr::map_lgl to obtain a logical vector by
> running the function once for each list element:
>
> sapply( VPN_Sheet1$HVA, is.numeric )
>
> On September 14, 2021 8:38:35 PM PDT, Gregg Powell <
> g.a.powell at protonmail.com> wrote:
> >Here is the output:
> >
> >> str(VPN_Sheet1$HVA)
> >List of 2174
> > $ : chr "Email: fffd at fffffffffff.com"
> > $ : num 1
> > $ : chr "Eloisa Libas"
> > $ : chr "Percival Esquejo"
> > $ : chr "Louchelle Singh"
> > $ : num 2
> > $ : chr "Charisse Anne Tabarno, RN"
> > $ : chr "Sol Amor Mucoy"
> > $ : chr "Josan Moira Paler"
> > $ : num 3
> > $ : chr "Anna Katrina V. Alberto"
> > $ : chr "Nenita Velarde"
> > $ : chr "Eunice Arrances"
> > $ : num 4
> > $ : chr "Catherine Henson"
> > $ : chr "Maria Carla Daya"
> > $ : chr "Renee Ireine Alit"
> > $ : num 5
> > $ : chr "Marol Joseph Domingo - PS"
> > $ : chr "Kissy Andrea Arriesgado"
> > $ : chr "Pia B Baluyut, RN"
> > $ : num 6
> > $ : chr "Gladys Joy Tan"
> > $ : chr "Frances Zarzua"
> > $ : chr "Fairy Jane Nery"
> > $ : num 7
> > $ : chr "Gladys Tijam, RMT"
> > $ : chr "Sarah Jane Aramburo"
> > $ : chr "Eve Mendoza"
> > $ : num 8
> > $ : chr "Gloria Padolino"
> > $ : chr "Joyce Pearl Javier"
> > $ : chr "Ayza Padilla"
> > $ : num 9
> > $ : chr "Walfredson Calderon"
> > $ : chr "Stephanie Anne Militante"
> > $ : chr "Rennua Oquilan"
> > $ : num 10
> > $ : chr "Neil John Nery"
> > $ : chr "Maria Reyna Reyes"
> > $ : chr "Rowella Villegas"
> > $ : num 11
> > $ : chr "Katelyn Mendiola"
> > $ : chr "Maria Riza Mariano"
> > $ : chr "Marie Vallianne Carantes"
> > $ : num 12
> >
> >??????? Original Message ???????
> >
> >On Tuesday, September 14th, 2021 at 8:32 PM, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us> wrote:
> >
> >> An atomic column of data by design has exactly one mode, so if any
> >> values are non-numeric then the entire column will be non-numeric.
> >> What does
> >>
> >
> >> str(VPN_Sheet1$HVA)
> >>
> >
> >> tell you? It is likely either a factor or character data.
> >>
> >
> >> On September 14, 2021 7:01:53 PM PDT, Gregg Powell via R-help
> r-help at r-project.org wrote:
> >>
> >
> >> > > Stuck on this problem - How does one remove all rows in a dataframe
> that have a numeric in the first (or any) column?
> >> >
> >
> >> > > Seems straight forward - but I'm having trouble.
> >> >
> >
> >> > I've attempted to used:
> >> >
> >
> >> > VPN_Sheet1 <- VPN_Sheet1[!is.numeric(VPN_Sheet1$HVA),]
> >> >
> >
> >> > and
> >> >
> >
> >> > VPN_Sheet1 <- VPN_Sheet1[!is.integer(VPN_Sheet1$HVA),]
> >> >
> >
> >> > Neither work - Neither throw an error.
> >> >
> >
> >> > class(VPN_Sheet1$HVA) returns:
> >> >
> >
> >> > [1] "list"
> >> >
> >
> >> > So, the HVA column returns a list.
> >> >
> >
> >> > > Data looks like the attached screen grab -
> >> >
> >
> >> > > The ONLY rows I need to delete are the rows where there is a
> numeric in the HVA column.
> >> >
> >
> >> > > There are some 5000+ rows in the actual data.
> >> >
> >
> >> > > Would be grateful for a solution to this problem.
> >> >
> >
> >> > How to get R to detect whether the value in column 1 is a number so
> the rows with the number values can be deleted?
> >> >
> >
> >> > > Thanks in advance to any and all willing to help on this problem.
> >> >
> >
> >> > > Gregg Powell
> >> >
> >
> >> > > Sierra Vista, AZ
> >>
> >
> >> --
> >>
> >
> >> Sent from my phone. Please excuse my brevity.
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Sep 15 07:22:56 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 15 Sep 2021 01:22:56 -0400
Subject: [R] How to remove all rows that have a numeric in the first (or
 any) column
In-Reply-To: <CAPcHnpRgC=t_9s3T9d7qbMH2_ShN23HTEkx3AuNXaBviYv1yzA@mail.gmail.com>
References: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
 <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
 <68A11171-83D4-4EDB-B98A-154BBDDF447D@dcn.davis.ca.us>
 <sE0QX_gzL2sYKaWmX7FuESeIEt_y4VDdE3PHJ1yPNe8Mlm8kQ3Wd8NYLzU9lQCA7iHUNSIqKNcO0M2_nzFq1JdMN26OCj2rZNw7lf-wyE5o=@protonmail.com>
 <5F88E791-CEC3-4B77-BF54-47D4D03094FB@dcn.davis.ca.us>
 <03f801d7a9eb$bba80b40$32f821c0$@verizon.net>
 <CAPcHnpRgC=t_9s3T9d7qbMH2_ShN23HTEkx3AuNXaBviYv1yzA@mail.gmail.com>
Message-ID: <045d01d7a9f1$be389270$3aa9b750$@verizon.net>

You are correct, Gregg, I am aware of that trick of asking something to not be evaluated in certain ways.

 

And you can indeed use base R to play with contents of beta as defined above.  Here is a sort of incremental demo:

 

> sapply(mydf$beta, is.numeric)

[1] FALSE  TRUE  TRUE FALSE

> !sapply(mydf$beta, is.numeric)

[1]  TRUE FALSE FALSE  TRUE

> keeping <- !sapply(mydf$beta, is.numeric)

> mydf[keeping, ]

# A tibble: 2 x 2

alpha beta     

<int> <list>   

  1     1 <chr [1]>

  2     4 <chr [1]>

  > str(mydf[keeping, ])

tibble [2 x 2] (S3: tbl_df/tbl/data.frame)

$ alpha: int [1:2] 1 4

$ beta :List of 2

..$ : chr "Hello"

..$ : chr "bye"

 

Now for the bad news. The original request was for ANY column. But presumably one way to do it, neither efficiently nor the best, would be to loop on the names of all the columns and starting with the original data.frame, whittle away at it column by column and adjust which column you search each time until what is left had nothing numeric anywhere. 

 

Now if I was using dplyr, I wonder if there is a nice way to use rowwise() to evaluate across a row.

 

Using your technique I made the following data.frame:

 

mydf <- data.frame(alpha=I(list("first", 2, 3.3, "Last")), 

                   beta=I(list(1, "second", 3.3, "Lasting")))

 

> mydf

alpha    beta

1 first       1

2     2  second

3   3.3     3.3

4  Last Lasting

 

Do we agree only the fourth row should be kept as the others have one or two numeric values?

 

Here is some code I cobbled together that seems to work:

 

 

rowwise(mydf) %>% 

  mutate(alphazoid=!is.numeric(unlist(alpha)), 

         betazoid=!is.numeric(unlist(beta))) %>%

  filter(alphazoid & betazoid) -> result

 

str(result)  

print(result)

result[[1,1]]

result[[1,2]]

 

as.data.frame(result)

 

The results are shown below that only the fourth row was kept:

 

> rowwise(mydf) %>% 

  +   mutate(alphazoid=!is.numeric(unlist(alpha)), 

             +          betazoid=!is.numeric(unlist(beta))) %>%

  +   filter(alphazoid & betazoid) -> result

> 

  > str(result)  

rowwise_df [1 x 4] (S3: rowwise_df/tbl_df/tbl/data.frame)

$ alpha    :List of 1

..$ : chr "Last"

..- attr(*, "class")= chr "AsIs"

$ beta     :List of 1

..$ : chr "Lasting"

..- attr(*, "class")= chr "AsIs"

$ alphazoid: logi TRUE

$ betazoid : logi TRUE

- attr(*, "groups")= tibble [1 x 1] (S3: tbl_df/tbl/data.frame)

..$ .rows: list<int> [1:1] 

.. ..$ : int 1

.. ..@ ptype: int(0) 

> print(result)

# A tibble: 1 x 4

# Rowwise: 

alpha     beta      alphazoid betazoid

<I<list>> <I<list>> <lgl>     <lgl>   

  1 <chr [1]> <chr [1]> TRUE      TRUE    

> result[[1,1]]

[[1]]

[1] "Last"

 

> result[[1,2]]

[[1]]

[1] "Lasting"

 

> as.data.frame(result)

alpha    beta alphazoid betazoid

1  Last Lasting      TRUE     TRUE

 

Of course, the temporary columns for alphazoid and betazoid can trivially be removed.

 

 

 

 

From: Andrew Simmons <akwsimmo at gmail.com> 
Sent: Wednesday, September 15, 2021 12:44 AM
To: Avi Gross <avigross at verizon.net>
Cc: Gregg Powell via R-help <r-help at r-project.org>
Subject: Re: [R] How to remove all rows that have a numeric in the first (or any) column

 

I'd like to point out that base R can handle a list as a data frame column, it's just that you have to make the list of class "AsIs". So in your example

 

temp <- list("Hello", 1, 1.1, "bye")

 

data.frame(alpha = 1:4, beta = I(temp)) 

 

means that column "beta" will still be a list.

 

 

On Wed, Sep 15, 2021, 00:40 Avi Gross via R-help <r-help at r-project.org <mailto:r-help at r-project.org> > wrote:

Calling something a data.frame does not make it a data.frame.

The abbreviated object shown below is a list of singletons. If it is a column in a larger object that is a data.frame, then it is a list column which is valid but can be ticklish to handle within base R but less so in the tidyverse.

For example, if I try to make a data.frame the normal way, the list gets made into multiple columns and copied to each row. Not what was expected. I think some tidyverse functionality does better.

Like this:

library(tidyverse)
temp=list("Hello", 1, 1.1, "bye")

Now making a data.frame has an odd result:

> mydf=data.frame(alpha=1:4, beta=temp)
> mydf
alpha beta..Hello. beta.1 beta.1.1 beta..bye.
1     1        Hello      1      1.1        bye
2     2        Hello      1      1.1        bye
3     3        Hello      1      1.1        bye
4     4        Hello      1      1.1        bye

But a tibble handles it:

> mydf=tibble(alpha=1:4, beta=temp)
> mydf
# A tibble: 4 x 2
alpha beta     
<int> <list>   
  1     1 <chr [1]>
  2     2 <dbl [1]>
  3     3 <dbl [1]>
  4     4 <chr [1]>

So if the data does look like this, with a list column, but access can be tricky as subsetting a list with [] returns a list and you need [[]].

I found a somehwhat odd solution like this:

mydf %>%
   filter(!map_lgl(beta, is.numeric)) -> mydf2
# A tibble: 2 x 2
alpha beta     
<int> <list>   
  1     1 <chr [1]>
  2     4 <chr [1]>

When I saved that result into mydf2, I got this.

Original:

  > str(mydf)
tibble [4 x 2] (S3: tbl_df/tbl/data.frame)
$ alpha: int [1:4] 1 2 3 4
$ beta :List of 4
..$ : chr "Hello"
..$ : num 1
..$ : num 1.1
..$ : chr "bye"

Output when any row with a numeric is removed:

> str(mydf2)
tibble [2 x 2] (S3: tbl_df/tbl/data.frame)
$ alpha: int [1:2] 1 4
$ beta :List of 2
..$ : chr "Hello"
..$ : chr "bye"

So if you try variations on your code motivated by what I show, good luck. I am sure there are many better ways but I repeat, it can be tricky.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org> > On Behalf Of Jeff Newmiller
Sent: Tuesday, September 14, 2021 11:54 PM
To: Gregg Powell <g.a.powell at protonmail.com <mailto:g.a.powell at protonmail.com> >
Cc: Gregg Powell via R-help <r-help at r-project.org <mailto:r-help at r-project.org> >
Subject: Re: [R] How to remove all rows that have a numeric in the first (or any) column

You cannot apply vectorized operators to list columns... you have to use a map function like sapply or purrr::map_lgl to obtain a logical vector by running the function once for each list element:

sapply( VPN_Sheet1$HVA, is.numeric )

On September 14, 2021 8:38:35 PM PDT, Gregg Powell <g.a.powell at protonmail.com <mailto:g.a.powell at protonmail.com> > wrote:
>Here is the output:
>
>> str(VPN_Sheet1$HVA)
>List of 2174
> $ : chr "Email: fffd at fffffffffff.com <mailto:fffd at fffffffffff.com> "
> $ : num 1
> $ : chr "Eloisa Libas"
> $ : chr "Percival Esquejo"
> $ : chr "Louchelle Singh"
> $ : num 2
> $ : chr "Charisse Anne Tabarno, RN"
> $ : chr "Sol Amor Mucoy"
> $ : chr "Josan Moira Paler"
> $ : num 3
> $ : chr "Anna Katrina V. Alberto"
> $ : chr "Nenita Velarde"
> $ : chr "Eunice Arrances"
> $ : num 4
> $ : chr "Catherine Henson"
> $ : chr "Maria Carla Daya"
> $ : chr "Renee Ireine Alit"
> $ : num 5
> $ : chr "Marol Joseph Domingo - PS"
> $ : chr "Kissy Andrea Arriesgado"
> $ : chr "Pia B Baluyut, RN"
> $ : num 6
> $ : chr "Gladys Joy Tan"
> $ : chr "Frances Zarzua"
> $ : chr "Fairy Jane Nery"
> $ : num 7
> $ : chr "Gladys Tijam, RMT"
> $ : chr "Sarah Jane Aramburo"
> $ : chr "Eve Mendoza"
> $ : num 8
> $ : chr "Gloria Padolino"
> $ : chr "Joyce Pearl Javier"
> $ : chr "Ayza Padilla"
> $ : num 9
> $ : chr "Walfredson Calderon"
> $ : chr "Stephanie Anne Militante"
> $ : chr "Rennua Oquilan"
> $ : num 10
> $ : chr "Neil John Nery"
> $ : chr "Maria Reyna Reyes"
> $ : chr "Rowella Villegas"
> $ : num 11
> $ : chr "Katelyn Mendiola"
> $ : chr "Maria Riza Mariano"
> $ : chr "Marie Vallianne Carantes"
> $ : num 12
>
>??????? Original Message ???????
>
>On Tuesday, September 14th, 2021 at 8:32 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us> > wrote:
>
>> An atomic column of data by design has exactly one mode, so if any 
>> values are non-numeric then the entire column will be non-numeric. 
>> What does
>> 
>
>> str(VPN_Sheet1$HVA)
>> 
>
>> tell you? It is likely either a factor or character data.
>> 
>
>> On September 14, 2021 7:01:53 PM PDT, Gregg Powell via R-help r-help at r-project.org <mailto:r-help at r-project.org>  wrote:
>> 
>
>> > > Stuck on this problem - How does one remove all rows in a dataframe that have a numeric in the first (or any) column?
>> > 
>
>> > > Seems straight forward - but I'm having trouble.
>> > 
>
>> > I've attempted to used:
>> > 
>
>> > VPN_Sheet1 <- VPN_Sheet1[!is.numeric(VPN_Sheet1$HVA),]
>> > 
>
>> > and
>> > 
>
>> > VPN_Sheet1 <- VPN_Sheet1[!is.integer(VPN_Sheet1$HVA),]
>> > 
>
>> > Neither work - Neither throw an error.
>> > 
>
>> > class(VPN_Sheet1$HVA) returns:
>> > 
>
>> > [1] "list"
>> > 
>
>> > So, the HVA column returns a list.
>> > 
>
>> > > Data looks like the attached screen grab -
>> > 
>
>> > > The ONLY rows I need to delete are the rows where there is a numeric in the HVA column.
>> > 
>
>> > > There are some 5000+ rows in the actual data.
>> > 
>
>> > > Would be grateful for a solution to this problem.
>> > 
>
>> > How to get R to detect whether the value in column 1 is a number so the rows with the number values can be deleted?
>> > 
>
>> > > Thanks in advance to any and all willing to help on this problem.
>> > 
>
>> > > Gregg Powell
>> > 
>
>> > > Sierra Vista, AZ
>> 
>
>> --
>> 
>
>> Sent from my phone. Please excuse my brevity.
--
Sent from my phone. Please excuse my brevity.

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Sep 15 07:25:54 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 15 Sep 2021 01:25:54 -0400
Subject: [R] How to remove all rows that have a numeric in the first (or
 any) column
In-Reply-To: <045d01d7a9f1$be389270$3aa9b750$@verizon.net>
References: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
 <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
 <68A11171-83D4-4EDB-B98A-154BBDDF447D@dcn.davis.ca.us>
 <sE0QX_gzL2sYKaWmX7FuESeIEt_y4VDdE3PHJ1yPNe8Mlm8kQ3Wd8NYLzU9lQCA7iHUNSIqKNcO0M2_nzFq1JdMN26OCj2rZNw7lf-wyE5o=@protonmail.com>
 <5F88E791-CEC3-4B77-BF54-47D4D03094FB@dcn.davis.ca.us>
 <03f801d7a9eb$bba80b40$32f821c0$@verizon.net>
 <CAPcHnpRgC=t_9s3T9d7qbMH2_ShN23HTEkx3AuNXaBviYv1yzA@mail.gmail.com>
 <045d01d7a9f1$be389270$3aa9b750$@verizon.net>
Message-ID: <047801d7a9f2$2843f100$78cbd300$@verizon.net>

My apologies. My reply was to Andrew, not Gregg.

Enough damage for one night. Here is hoping we finally understood a question that could have been better phrased. list columns are not normally considered common data structures but quite possibly will be more as time goes on and the tools to handle them become better or at least better understood.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Avi Gross via R-help
Sent: Wednesday, September 15, 2021 1:23 AM
To: R-help at r-project.org
Subject: Re: [R] How to remove all rows that have a numeric in the first (or any) column

You are correct, Gregg, I am aware of that trick of asking something to not be evaluated in certain ways.

 

And you can indeed use base R to play with contents of beta as defined above.  Here is a sort of incremental demo:

 

> sapply(mydf$beta, is.numeric)

[1] FALSE  TRUE  TRUE FALSE

> !sapply(mydf$beta, is.numeric)

[1]  TRUE FALSE FALSE  TRUE

> keeping <- !sapply(mydf$beta, is.numeric)

> mydf[keeping, ]

# A tibble: 2 x 2

alpha beta     

<int> <list>   

  1     1 <chr [1]>

  2     4 <chr [1]>

  > str(mydf[keeping, ])

tibble [2 x 2] (S3: tbl_df/tbl/data.frame)

$ alpha: int [1:2] 1 4

$ beta :List of 2

..$ : chr "Hello"

..$ : chr "bye"

 

Now for the bad news. The original request was for ANY column. But presumably one way to do it, neither efficiently nor the best, would be to loop on the names of all the columns and starting with the original data.frame, whittle away at it column by column and adjust which column you search each time until what is left had nothing numeric anywhere. 

 

Now if I was using dplyr, I wonder if there is a nice way to use rowwise() to evaluate across a row.

 

Using your technique I made the following data.frame:

 

mydf <- data.frame(alpha=I(list("first", 2, 3.3, "Last")), 

                   beta=I(list(1, "second", 3.3, "Lasting")))

 

> mydf

alpha    beta

1 first       1

2     2  second

3   3.3     3.3

4  Last Lasting

 

Do we agree only the fourth row should be kept as the others have one or two numeric values?

 

Here is some code I cobbled together that seems to work:

 

 

rowwise(mydf) %>% 

  mutate(alphazoid=!is.numeric(unlist(alpha)), 

         betazoid=!is.numeric(unlist(beta))) %>%

  filter(alphazoid & betazoid) -> result

 

str(result)  

print(result)

result[[1,1]]

result[[1,2]]

 

as.data.frame(result)

 

The results are shown below that only the fourth row was kept:

 

> rowwise(mydf) %>%

  +   mutate(alphazoid=!is.numeric(unlist(alpha)), 

             +          betazoid=!is.numeric(unlist(beta))) %>%

  +   filter(alphazoid & betazoid) -> result

> 

  > str(result)  

rowwise_df [1 x 4] (S3: rowwise_df/tbl_df/tbl/data.frame)

$ alpha    :List of 1

..$ : chr "Last"

..- attr(*, "class")= chr "AsIs"

$ beta     :List of 1

..$ : chr "Lasting"

..- attr(*, "class")= chr "AsIs"

$ alphazoid: logi TRUE

$ betazoid : logi TRUE

- attr(*, "groups")= tibble [1 x 1] (S3: tbl_df/tbl/data.frame)

..$ .rows: list<int> [1:1] 

.. ..$ : int 1

.. ..@ ptype: int(0) 

> print(result)

# A tibble: 1 x 4

# Rowwise: 

alpha     beta      alphazoid betazoid

<I<list>> <I<list>> <lgl>     <lgl>   

  1 <chr [1]> <chr [1]> TRUE      TRUE    

> result[[1,1]]

[[1]]

[1] "Last"

 

> result[[1,2]]

[[1]]

[1] "Lasting"

 

> as.data.frame(result)

alpha    beta alphazoid betazoid

1  Last Lasting      TRUE     TRUE

 

Of course, the temporary columns for alphazoid and betazoid can trivially be removed.

 

 

 

 

From: Andrew Simmons <akwsimmo at gmail.com>
Sent: Wednesday, September 15, 2021 12:44 AM
To: Avi Gross <avigross at verizon.net>
Cc: Gregg Powell via R-help <r-help at r-project.org>
Subject: Re: [R] How to remove all rows that have a numeric in the first (or any) column

 

I'd like to point out that base R can handle a list as a data frame column, it's just that you have to make the list of class "AsIs". So in your example

 

temp <- list("Hello", 1, 1.1, "bye")

 

data.frame(alpha = 1:4, beta = I(temp)) 

 

means that column "beta" will still be a list.

 

 

On Wed, Sep 15, 2021, 00:40 Avi Gross via R-help <r-help at r-project.org <mailto:r-help at r-project.org> > wrote:

Calling something a data.frame does not make it a data.frame.

The abbreviated object shown below is a list of singletons. If it is a column in a larger object that is a data.frame, then it is a list column which is valid but can be ticklish to handle within base R but less so in the tidyverse.

For example, if I try to make a data.frame the normal way, the list gets made into multiple columns and copied to each row. Not what was expected. I think some tidyverse functionality does better.

Like this:

library(tidyverse)
temp=list("Hello", 1, 1.1, "bye")

Now making a data.frame has an odd result:

> mydf=data.frame(alpha=1:4, beta=temp)
> mydf
alpha beta..Hello. beta.1 beta.1.1 beta..bye.
1     1        Hello      1      1.1        bye
2     2        Hello      1      1.1        bye
3     3        Hello      1      1.1        bye
4     4        Hello      1      1.1        bye

But a tibble handles it:

> mydf=tibble(alpha=1:4, beta=temp)
> mydf
# A tibble: 4 x 2
alpha beta     
<int> <list>   
  1     1 <chr [1]>
  2     2 <dbl [1]>
  3     3 <dbl [1]>
  4     4 <chr [1]>

So if the data does look like this, with a list column, but access can be tricky as subsetting a list with [] returns a list and you need [[]].

I found a somehwhat odd solution like this:

mydf %>%
   filter(!map_lgl(beta, is.numeric)) -> mydf2 # A tibble: 2 x 2
alpha beta     
<int> <list>   
  1     1 <chr [1]>
  2     4 <chr [1]>

When I saved that result into mydf2, I got this.

Original:

  > str(mydf)
tibble [4 x 2] (S3: tbl_df/tbl/data.frame) $ alpha: int [1:4] 1 2 3 4 $ beta :List of 4 ..$ : chr "Hello"
..$ : num 1
..$ : num 1.1
..$ : chr "bye"

Output when any row with a numeric is removed:

> str(mydf2)
tibble [2 x 2] (S3: tbl_df/tbl/data.frame) $ alpha: int [1:2] 1 4 $ beta :List of 2 ..$ : chr "Hello"
..$ : chr "bye"

So if you try variations on your code motivated by what I show, good luck. I am sure there are many better ways but I repeat, it can be tricky.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org> > On Behalf Of Jeff Newmiller
Sent: Tuesday, September 14, 2021 11:54 PM
To: Gregg Powell <g.a.powell at protonmail.com <mailto:g.a.powell at protonmail.com> >
Cc: Gregg Powell via R-help <r-help at r-project.org <mailto:r-help at r-project.org> >
Subject: Re: [R] How to remove all rows that have a numeric in the first (or any) column

You cannot apply vectorized operators to list columns... you have to use a map function like sapply or purrr::map_lgl to obtain a logical vector by running the function once for each list element:

sapply( VPN_Sheet1$HVA, is.numeric )

On September 14, 2021 8:38:35 PM PDT, Gregg Powell <g.a.powell at protonmail.com <mailto:g.a.powell at protonmail.com> > wrote:
>Here is the output:
>
>> str(VPN_Sheet1$HVA)
>List of 2174
> $ : chr "Email: fffd at fffffffffff.com <mailto:fffd at fffffffffff.com> "
> $ : num 1
> $ : chr "Eloisa Libas"
> $ : chr "Percival Esquejo"
> $ : chr "Louchelle Singh"
> $ : num 2
> $ : chr "Charisse Anne Tabarno, RN"
> $ : chr "Sol Amor Mucoy"
> $ : chr "Josan Moira Paler"
> $ : num 3
> $ : chr "Anna Katrina V. Alberto"
> $ : chr "Nenita Velarde"
> $ : chr "Eunice Arrances"
> $ : num 4
> $ : chr "Catherine Henson"
> $ : chr "Maria Carla Daya"
> $ : chr "Renee Ireine Alit"
> $ : num 5
> $ : chr "Marol Joseph Domingo - PS"
> $ : chr "Kissy Andrea Arriesgado"
> $ : chr "Pia B Baluyut, RN"
> $ : num 6
> $ : chr "Gladys Joy Tan"
> $ : chr "Frances Zarzua"
> $ : chr "Fairy Jane Nery"
> $ : num 7
> $ : chr "Gladys Tijam, RMT"
> $ : chr "Sarah Jane Aramburo"
> $ : chr "Eve Mendoza"
> $ : num 8
> $ : chr "Gloria Padolino"
> $ : chr "Joyce Pearl Javier"
> $ : chr "Ayza Padilla"
> $ : num 9
> $ : chr "Walfredson Calderon"
> $ : chr "Stephanie Anne Militante"
> $ : chr "Rennua Oquilan"
> $ : num 10
> $ : chr "Neil John Nery"
> $ : chr "Maria Reyna Reyes"
> $ : chr "Rowella Villegas"
> $ : num 11
> $ : chr "Katelyn Mendiola"
> $ : chr "Maria Riza Mariano"
> $ : chr "Marie Vallianne Carantes"
> $ : num 12
>
>??????? Original Message ???????
>
>On Tuesday, September 14th, 2021 at 8:32 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us> > wrote:
>
>> An atomic column of data by design has exactly one mode, so if any 
>> values are non-numeric then the entire column will be non-numeric.
>> What does
>> 
>
>> str(VPN_Sheet1$HVA)
>> 
>
>> tell you? It is likely either a factor or character data.
>> 
>
>> On September 14, 2021 7:01:53 PM PDT, Gregg Powell via R-help r-help at r-project.org <mailto:r-help at r-project.org>  wrote:
>> 
>
>> > > Stuck on this problem - How does one remove all rows in a dataframe that have a numeric in the first (or any) column?
>> > 
>
>> > > Seems straight forward - but I'm having trouble.
>> > 
>
>> > I've attempted to used:
>> > 
>
>> > VPN_Sheet1 <- VPN_Sheet1[!is.numeric(VPN_Sheet1$HVA),]
>> > 
>
>> > and
>> > 
>
>> > VPN_Sheet1 <- VPN_Sheet1[!is.integer(VPN_Sheet1$HVA),]
>> > 
>
>> > Neither work - Neither throw an error.
>> > 
>
>> > class(VPN_Sheet1$HVA) returns:
>> > 
>
>> > [1] "list"
>> > 
>
>> > So, the HVA column returns a list.
>> > 
>
>> > > Data looks like the attached screen grab -
>> > 
>
>> > > The ONLY rows I need to delete are the rows where there is a numeric in the HVA column.
>> > 
>
>> > > There are some 5000+ rows in the actual data.
>> > 
>
>> > > Would be grateful for a solution to this problem.
>> > 
>
>> > How to get R to detect whether the value in column 1 is a number so the rows with the number values can be deleted?
>> > 
>
>> > > Thanks in advance to any and all willing to help on this problem.
>> > 
>
>> > > Gregg Powell
>> > 
>
>> > > Sierra Vista, AZ
>> 
>
>> --
>> 
>
>> Sent from my phone. Please excuse my brevity.
--
Sent from my phone. Please excuse my brevity.

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep 15 07:43:48 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 14 Sep 2021 22:43:48 -0700
Subject: [R] How to remove all rows that have a numeric in the first (or
 any) column
In-Reply-To: <047801d7a9f2$2843f100$78cbd300$@verizon.net>
References: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
 <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
 <68A11171-83D4-4EDB-B98A-154BBDDF447D@dcn.davis.ca.us>
 <sE0QX_gzL2sYKaWmX7FuESeIEt_y4VDdE3PHJ1yPNe8Mlm8kQ3Wd8NYLzU9lQCA7iHUNSIqKNcO0M2_nzFq1JdMN26OCj2rZNw7lf-wyE5o=@protonmail.com>
 <5F88E791-CEC3-4B77-BF54-47D4D03094FB@dcn.davis.ca.us>
 <03f801d7a9eb$bba80b40$32f821c0$@verizon.net>
 <CAPcHnpRgC=t_9s3T9d7qbMH2_ShN23HTEkx3AuNXaBviYv1yzA@mail.gmail.com>
 <045d01d7a9f1$be389270$3aa9b750$@verizon.net>
 <047801d7a9f2$2843f100$78cbd300$@verizon.net>
Message-ID: <082EC7F4-3BDB-40F0-894E-14131660FADB@dcn.davis.ca.us>

FWIW I use them quite frequently, but not for the purpose of storing heterogeneous data... rather for holding complex objects of the same class.

On September 14, 2021 10:25:54 PM PDT, Avi Gross via R-help <r-help at r-project.org> wrote:
>My apologies. My reply was to Andrew, not Gregg.
>
>Enough damage for one night. Here is hoping we finally understood a question that could have been better phrased. list columns are not normally considered common data structures but quite possibly will be more as time goes on and the tools to handle them become better or at least better understood.
>
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of Avi Gross via R-help
>Sent: Wednesday, September 15, 2021 1:23 AM
>To: R-help at r-project.org
>Subject: Re: [R] How to remove all rows that have a numeric in the first (or any) column
>
>You are correct, Gregg, I am aware of that trick of asking something to not be evaluated in certain ways.
>
> 
>
>And you can indeed use base R to play with contents of beta as defined above.  Here is a sort of incremental demo:
>
> 
>
>> sapply(mydf$beta, is.numeric)
>
>[1] FALSE  TRUE  TRUE FALSE
>
>> !sapply(mydf$beta, is.numeric)
>
>[1]  TRUE FALSE FALSE  TRUE
>
>> keeping <- !sapply(mydf$beta, is.numeric)
>
>> mydf[keeping, ]
>
># A tibble: 2 x 2
>
>alpha beta     
>
><int> <list>   
>
>  1     1 <chr [1]>
>
>  2     4 <chr [1]>
>
>  > str(mydf[keeping, ])
>
>tibble [2 x 2] (S3: tbl_df/tbl/data.frame)
>
>$ alpha: int [1:2] 1 4
>
>$ beta :List of 2
>
>..$ : chr "Hello"
>
>..$ : chr "bye"
>
> 
>
>Now for the bad news. The original request was for ANY column. But presumably one way to do it, neither efficiently nor the best, would be to loop on the names of all the columns and starting with the original data.frame, whittle away at it column by column and adjust which column you search each time until what is left had nothing numeric anywhere. 
>
> 
>
>Now if I was using dplyr, I wonder if there is a nice way to use rowwise() to evaluate across a row.
>
> 
>
>Using your technique I made the following data.frame:
>
> 
>
>mydf <- data.frame(alpha=I(list("first", 2, 3.3, "Last")), 
>
>                   beta=I(list(1, "second", 3.3, "Lasting")))
>
> 
>
>> mydf
>
>alpha    beta
>
>1 first       1
>
>2     2  second
>
>3   3.3     3.3
>
>4  Last Lasting
>
> 
>
>Do we agree only the fourth row should be kept as the others have one or two numeric values?
>
> 
>
>Here is some code I cobbled together that seems to work:
>
> 
>
> 
>
>rowwise(mydf) %>% 
>
>  mutate(alphazoid=!is.numeric(unlist(alpha)), 
>
>         betazoid=!is.numeric(unlist(beta))) %>%
>
>  filter(alphazoid & betazoid) -> result
>
> 
>
>str(result)  
>
>print(result)
>
>result[[1,1]]
>
>result[[1,2]]
>
> 
>
>as.data.frame(result)
>
> 
>
>The results are shown below that only the fourth row was kept:
>
> 
>
>> rowwise(mydf) %>%
>
>  +   mutate(alphazoid=!is.numeric(unlist(alpha)), 
>
>             +          betazoid=!is.numeric(unlist(beta))) %>%
>
>  +   filter(alphazoid & betazoid) -> result
>
>> 
>
>  > str(result)  
>
>rowwise_df [1 x 4] (S3: rowwise_df/tbl_df/tbl/data.frame)
>
>$ alpha    :List of 1
>
>..$ : chr "Last"
>
>..- attr(*, "class")= chr "AsIs"
>
>$ beta     :List of 1
>
>..$ : chr "Lasting"
>
>..- attr(*, "class")= chr "AsIs"
>
>$ alphazoid: logi TRUE
>
>$ betazoid : logi TRUE
>
>- attr(*, "groups")= tibble [1 x 1] (S3: tbl_df/tbl/data.frame)
>
>..$ .rows: list<int> [1:1] 
>
>.. ..$ : int 1
>
>.. ..@ ptype: int(0) 
>
>> print(result)
>
># A tibble: 1 x 4
>
># Rowwise: 
>
>alpha     beta      alphazoid betazoid
>
><I<list>> <I<list>> <lgl>     <lgl>   
>
>  1 <chr [1]> <chr [1]> TRUE      TRUE    
>
>> result[[1,1]]
>
>[[1]]
>
>[1] "Last"
>
> 
>
>> result[[1,2]]
>
>[[1]]
>
>[1] "Lasting"
>
> 
>
>> as.data.frame(result)
>
>alpha    beta alphazoid betazoid
>
>1  Last Lasting      TRUE     TRUE
>
> 
>
>Of course, the temporary columns for alphazoid and betazoid can trivially be removed.
>
> 
>
> 
>
> 
>
> 
>
>From: Andrew Simmons <akwsimmo at gmail.com>
>Sent: Wednesday, September 15, 2021 12:44 AM
>To: Avi Gross <avigross at verizon.net>
>Cc: Gregg Powell via R-help <r-help at r-project.org>
>Subject: Re: [R] How to remove all rows that have a numeric in the first (or any) column
>
> 
>
>I'd like to point out that base R can handle a list as a data frame column, it's just that you have to make the list of class "AsIs". So in your example
>
> 
>
>temp <- list("Hello", 1, 1.1, "bye")
>
> 
>
>data.frame(alpha = 1:4, beta = I(temp)) 
>
> 
>
>means that column "beta" will still be a list.
>
> 
>
> 
>
>On Wed, Sep 15, 2021, 00:40 Avi Gross via R-help <r-help at r-project.org <mailto:r-help at r-project.org> > wrote:
>
>Calling something a data.frame does not make it a data.frame.
>
>The abbreviated object shown below is a list of singletons. If it is a column in a larger object that is a data.frame, then it is a list column which is valid but can be ticklish to handle within base R but less so in the tidyverse.
>
>For example, if I try to make a data.frame the normal way, the list gets made into multiple columns and copied to each row. Not what was expected. I think some tidyverse functionality does better.
>
>Like this:
>
>library(tidyverse)
>temp=list("Hello", 1, 1.1, "bye")
>
>Now making a data.frame has an odd result:
>
>> mydf=data.frame(alpha=1:4, beta=temp)
>> mydf
>alpha beta..Hello. beta.1 beta.1.1 beta..bye.
>1     1        Hello      1      1.1        bye
>2     2        Hello      1      1.1        bye
>3     3        Hello      1      1.1        bye
>4     4        Hello      1      1.1        bye
>
>But a tibble handles it:
>
>> mydf=tibble(alpha=1:4, beta=temp)
>> mydf
># A tibble: 4 x 2
>alpha beta     
><int> <list>   
>  1     1 <chr [1]>
>  2     2 <dbl [1]>
>  3     3 <dbl [1]>
>  4     4 <chr [1]>
>
>So if the data does look like this, with a list column, but access can be tricky as subsetting a list with [] returns a list and you need [[]].
>
>I found a somehwhat odd solution like this:
>
>mydf %>%
>   filter(!map_lgl(beta, is.numeric)) -> mydf2 # A tibble: 2 x 2
>alpha beta     
><int> <list>   
>  1     1 <chr [1]>
>  2     4 <chr [1]>
>
>When I saved that result into mydf2, I got this.
>
>Original:
>
>  > str(mydf)
>tibble [4 x 2] (S3: tbl_df/tbl/data.frame) $ alpha: int [1:4] 1 2 3 4 $ beta :List of 4 ..$ : chr "Hello"
>..$ : num 1
>..$ : num 1.1
>..$ : chr "bye"
>
>Output when any row with a numeric is removed:
>
>> str(mydf2)
>tibble [2 x 2] (S3: tbl_df/tbl/data.frame) $ alpha: int [1:2] 1 4 $ beta :List of 2 ..$ : chr "Hello"
>..$ : chr "bye"
>
>So if you try variations on your code motivated by what I show, good luck. I am sure there are many better ways but I repeat, it can be tricky.
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org> > On Behalf Of Jeff Newmiller
>Sent: Tuesday, September 14, 2021 11:54 PM
>To: Gregg Powell <g.a.powell at protonmail.com <mailto:g.a.powell at protonmail.com> >
>Cc: Gregg Powell via R-help <r-help at r-project.org <mailto:r-help at r-project.org> >
>Subject: Re: [R] How to remove all rows that have a numeric in the first (or any) column
>
>You cannot apply vectorized operators to list columns... you have to use a map function like sapply or purrr::map_lgl to obtain a logical vector by running the function once for each list element:
>
>sapply( VPN_Sheet1$HVA, is.numeric )
>
>On September 14, 2021 8:38:35 PM PDT, Gregg Powell <g.a.powell at protonmail.com <mailto:g.a.powell at protonmail.com> > wrote:
>>Here is the output:
>>
>>> str(VPN_Sheet1$HVA)
>>List of 2174
>> $ : chr "Email: fffd at fffffffffff.com <mailto:fffd at fffffffffff.com> "
>> $ : num 1
>> $ : chr "Eloisa Libas"
>> $ : chr "Percival Esquejo"
>> $ : chr "Louchelle Singh"
>> $ : num 2
>> $ : chr "Charisse Anne Tabarno, RN"
>> $ : chr "Sol Amor Mucoy"
>> $ : chr "Josan Moira Paler"
>> $ : num 3
>> $ : chr "Anna Katrina V. Alberto"
>> $ : chr "Nenita Velarde"
>> $ : chr "Eunice Arrances"
>> $ : num 4
>> $ : chr "Catherine Henson"
>> $ : chr "Maria Carla Daya"
>> $ : chr "Renee Ireine Alit"
>> $ : num 5
>> $ : chr "Marol Joseph Domingo - PS"
>> $ : chr "Kissy Andrea Arriesgado"
>> $ : chr "Pia B Baluyut, RN"
>> $ : num 6
>> $ : chr "Gladys Joy Tan"
>> $ : chr "Frances Zarzua"
>> $ : chr "Fairy Jane Nery"
>> $ : num 7
>> $ : chr "Gladys Tijam, RMT"
>> $ : chr "Sarah Jane Aramburo"
>> $ : chr "Eve Mendoza"
>> $ : num 8
>> $ : chr "Gloria Padolino"
>> $ : chr "Joyce Pearl Javier"
>> $ : chr "Ayza Padilla"
>> $ : num 9
>> $ : chr "Walfredson Calderon"
>> $ : chr "Stephanie Anne Militante"
>> $ : chr "Rennua Oquilan"
>> $ : num 10
>> $ : chr "Neil John Nery"
>> $ : chr "Maria Reyna Reyes"
>> $ : chr "Rowella Villegas"
>> $ : num 11
>> $ : chr "Katelyn Mendiola"
>> $ : chr "Maria Riza Mariano"
>> $ : chr "Marie Vallianne Carantes"
>> $ : num 12
>>
>>??????? Original Message ???????
>>
>>On Tuesday, September 14th, 2021 at 8:32 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us> > wrote:
>>
>>> An atomic column of data by design has exactly one mode, so if any 
>>> values are non-numeric then the entire column will be non-numeric.
>>> What does
>>> 
>>
>>> str(VPN_Sheet1$HVA)
>>> 
>>
>>> tell you? It is likely either a factor or character data.
>>> 
>>
>>> On September 14, 2021 7:01:53 PM PDT, Gregg Powell via R-help r-help at r-project.org <mailto:r-help at r-project.org>  wrote:
>>> 
>>
>>> > > Stuck on this problem - How does one remove all rows in a dataframe that have a numeric in the first (or any) column?
>>> > 
>>
>>> > > Seems straight forward - but I'm having trouble.
>>> > 
>>
>>> > I've attempted to used:
>>> > 
>>
>>> > VPN_Sheet1 <- VPN_Sheet1[!is.numeric(VPN_Sheet1$HVA),]
>>> > 
>>
>>> > and
>>> > 
>>
>>> > VPN_Sheet1 <- VPN_Sheet1[!is.integer(VPN_Sheet1$HVA),]
>>> > 
>>
>>> > Neither work - Neither throw an error.
>>> > 
>>
>>> > class(VPN_Sheet1$HVA) returns:
>>> > 
>>
>>> > [1] "list"
>>> > 
>>
>>> > So, the HVA column returns a list.
>>> > 
>>
>>> > > Data looks like the attached screen grab -
>>> > 
>>
>>> > > The ONLY rows I need to delete are the rows where there is a numeric in the HVA column.
>>> > 
>>
>>> > > There are some 5000+ rows in the actual data.
>>> > 
>>
>>> > > Would be grateful for a solution to this problem.
>>> > 
>>
>>> > How to get R to detect whether the value in column 1 is a number so the rows with the number values can be deleted?
>>> > 
>>
>>> > > Thanks in advance to any and all willing to help on this problem.
>>> > 
>>
>>> > > Gregg Powell
>>> > 
>>
>>> > > Sierra Vista, AZ
>>> 
>>
>>> --
>>> 
>>
>>> Sent from my phone. Please excuse my brevity.
>--
>Sent from my phone. Please excuse my brevity.
>
>______________________________________________
>R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Wed Sep 15 08:26:31 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Wed, 15 Sep 2021 09:26:31 +0300
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <CAPcHnpRMj=mDqhZ7C-+VvYCj9r0trS=3iOuu4NsouCG8xB2Dtw@mail.gmail.com>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
 <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
 <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
 <250d355b-072e-67cb-8bd5-bb012aed20a2@syonic.eu>
 <CAPcHnpSR=ZtCk=bX=NkFWO8wNc4hks07x+eGJU+Z4QA0+cJcjg@mail.gmail.com>
 <12584b25-8150-4002-4eee-b4bc21525996@syonic.eu>
 <CAPcHnpRMj=mDqhZ7C-+VvYCj9r0trS=3iOuu4NsouCG8xB2Dtw@mail.gmail.com>
Message-ID: <b406b3e1-28ff-d974-3a26-3c4f8003b672@syonic.eu>

Hello Andrew,


On 9/15/2021 6:53 AM, Andrew Simmons wrote:
> names(x) <- c("some names")
>
> if different from
>
> `names<-`(x, value = c("some names"))
>
> because the second piece of code does not ever call `<-`. The first 
> piece of code is (approximately) equivalent to
>
> `*tmp*` <- x
> `*tmp*` <- `names<-`(`*tmp*`, value = c("some names"))
> x <- `*tmp*`


This is my question:

Would there be any negative impact if the code is changed to:

x <- 'names<-'(x, value=...);

The "x" will be evaluated inside 'names<-' and this function outputs & 
assigns "x". The "creation" of "x" in the current environment is done 
only after the call to 'names<-' (if it did not exist before).


Leonard


>
> Another example,
>
> y <- `names<-`(x, value = c("some names"))
>
> now y will be equivalent to x if we did
>
> names(x) <- c("some names")
>
> except that the first will not update x, it will still have its old names.
>
> On Mon, Sep 13, 2021 at 4:33 PM Leonard Mada <leo.mada at syonic.eu 
> <mailto:leo.mada at syonic.eu>> wrote:
>
>
>     On 9/13/2021 11:28 PM, Andrew Simmons wrote:
>>     In the example you gave : r(x) <- 1
>>     r(x) is never evaluated, the above calls `r<-`,
>>     in fact r does not even have to be an existing function.
>
>
>     I meant:
>
>     '*tmp*' <- x; # "x" is evaluated here;
>
>     'r<-' is called after this step, which makes sense in the case of
>     subsetting;
>
>
>     But I am wondering if changing this behaviour, when NO subsetting
>     is performed, would have any impact.
>
>     e.g. names(x) = c("some names");
>
>     # would it have any impact to skip the evaluation of "x" and call
>     directly:
>
>     'names<-'(x, value);
>
>
>     Leonard
>
>
>>
>>     On Mon, Sep 13, 2021, 16:18 Leonard Mada <leo.mada at syonic.eu
>>     <mailto:leo.mada at syonic.eu>> wrote:
>>
>>         Hello,
>>
>>
>>         I have found the evaluation: it is described in the section
>>         on subsetting. The forced evaluation makes sense for subsetting.
>>
>>
>>         On 9/13/2021 9:42 PM, Leonard Mada wrote:
>>>
>>>         Hello Andrew,
>>>
>>>
>>>         I try now to understand the evaluation of the expression:
>>>
>>>         e = expression(r(x) <- 1)
>>>
>>>         # parameter named "value" seems to be required;
>>>         'r<-' = function(x, value) {print("R");}
>>>         eval(e, list(x=2))
>>>         # [1] "R"
>>>
>>>         # both versions work
>>>         'r<-' = function(value, x) {print("R");}
>>>         eval(e, list(x=2))
>>>         # [1] "R"
>>>
>>>
>>>         ### the Expression
>>>         e[[1]][[1]] # "<-", not "r<-"
>>>         e[[1]][[2]] # "r(x)"
>>>
>>>
>>>         The evaluation of "e" somehow calls "r<-", but evaluates
>>>         also the argument of r(...). I am still investigating what
>>>         is actually happening.
>>>
>>
>>         The forced evaluation is relevant for subsetting, e.g.:
>>         expression(r(x)[3] <- 1)
>>         expression(r(x)[3] <- 1)[[1]][[2]]
>>         # r(x)[3] # the evaluation details are NOT visible in the
>>         expression per se;
>>         # Note: indeed, it makes sens to first evaluate r(x) and then
>>         to perform the subsetting;
>>
>>
>>         However, in the case of a non-subsetted expression:
>>         r(x) <- 1;
>>         It would make sense to evaluate lazily r(x) if no subsetting
>>         is involved (more precisely "r<-"(x, value) ).
>>
>>         Would this have any impact on the current code?
>>
>>
>>         Sincerely,
>>
>>
>>         Leonard
>>
>>
>>>
>>>         Sincerely,
>>>
>>>
>>>         Leonard
>>>
>>>
>>>         On 9/13/2021 9:15 PM, Andrew Simmons wrote:
>>>>         R's parser doesn't work the way you're expecting it to.
>>>>         When doing an assignment like:
>>>>
>>>>
>>>>         padding(right(df)) <- 1
>>>>
>>>>
>>>>         it is broken into small stages. The guide "R Language
>>>>         Definition" claims that the above would be equivalent to:
>>>>
>>>>
>>>>         `<-`(df, `padding<-`(df, value = `right<-`(padding(df),
>>>>         value = 1)))
>>>>
>>>>
>>>>         but that is not correct, and you can tell by using
>>>>         `substitute` as you were above. There isn't a way to do
>>>>         what you want with the syntax you provided, you'll have to
>>>>         do something different. You could add a `which` argument to
>>>>         each style function, and maybe put the code for `match.arg`
>>>>         in a separate function:
>>>>
>>>>
>>>>         match.which <- function (which)
>>>>         match.arg(which, c("bottom", "left", "top", "right"),
>>>>         several.ok = TRUE)
>>>>
>>>>
>>>>         padding <- function (x, which)
>>>>         {
>>>>         ? ? which <- match.which(which)
>>>>         ? ? # more code
>>>>         }
>>>>
>>>>
>>>>         border <- function (x, which)
>>>>         {
>>>>         ? ? which <- match.which(which)
>>>>         ? ? # more code
>>>>         }
>>>>
>>>>
>>>>         some_other_style <- function (x, which)
>>>>         {
>>>>         ? ? which <- match.which(which)
>>>>         ? ? # more code
>>>>         }
>>>>
>>>>
>>>>         I hope this helps.
>>>>
>>>>         On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada
>>>>         <leo.mada at syonic.eu <mailto:leo.mada at syonic.eu>> wrote:
>>>>
>>>>             Hello Andrew,
>>>>
>>>>
>>>>             this could work. I will think about it.
>>>>
>>>>
>>>>             But I was thinking more generically. Suppose we have a
>>>>             series of functions:
>>>>             padding(), border(), some_other_style();
>>>>             Each of these functions has the parameter "right" (or
>>>>             the group of parameters c("right", ...)).
>>>>
>>>>
>>>>             Then I could design a function right(FUN) that assigns
>>>>             the value to this parameter and evaluates the function
>>>>             FUN().
>>>>
>>>>
>>>>             There are a few ways to do this:
>>>>
>>>>             1.) Other parameters as ...
>>>>             right(FUN, value, ...) = value; and then pass "..." to FUN.
>>>>             right(value, FUN, ...) = value; # or is this the
>>>>             syntax? (TODO: explore)
>>>>
>>>>             2.) Another way:
>>>>             right(FUN(...other parameters already specified...)) =
>>>>             value;
>>>>             I wanted to explore this 2nd option: but avoid
>>>>             evaluating FUN, unless the parameter "right" is
>>>>             injected into the call.
>>>>
>>>>             3.) Option 3:
>>>>             The option you mentioned.
>>>>
>>>>
>>>>             Independent of the method: there are still
>>>>             weird/unexplained behaviours when I try the initial
>>>>             code (see the latest mail with the improved code).
>>>>
>>>>
>>>>             Sincerely,
>>>>
>>>>
>>>>             Leonard
>>>>
>>>>
>>>>             On 9/13/2021 6:45 PM, Andrew Simmons wrote:
>>>>>             I think you're trying to do something like:
>>>>>
>>>>>             `padding<-` <- function (x, which, value)
>>>>>             {
>>>>>             ? ? which <- match.arg(which, c("bottom", "left",
>>>>>             "top", "right"), several.ok = TRUE)
>>>>>             ? ? # code to pad to each side here
>>>>>             }
>>>>>
>>>>>             Then you could use it like
>>>>>
>>>>>             df <- data.frame(x=1:5, y = sample(1:5, 5))
>>>>>             padding(df, "right") <- 1
>>>>>
>>>>>             Does that work as expected for you?
>>>>>
>>>>>             On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help
>>>>>             <r-help at r-project.org <mailto:r-help at r-project.org>>
>>>>>             wrote:
>>>>>
>>>>>                 I try to clarify the code:
>>>>>
>>>>>
>>>>>                 ###
>>>>>                 right = function(x, val) {print("Right");};
>>>>>                 padding = function(x, right, left, top, bottom)
>>>>>                 {print("Padding");};
>>>>>                 'padding<-' = function(x, ...) {print("Padding = ");};
>>>>>                 df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>>>>>
>>>>>                 ### Does NOT work as expected
>>>>>                 'right<-' = function(x, value) {
>>>>>                 ???? print("This line should be the first printed!")
>>>>>                 ???? print("But ERROR: x was already evaluated,
>>>>>                 which printed \"Padding\"");
>>>>>                 ???? x = substitute(x); # x was already evaluated
>>>>>                 before substitute();
>>>>>                 ???? return("Nothing"); # do not now what the
>>>>>                 behaviour should be?
>>>>>                 }
>>>>>
>>>>>                 right(padding(df)) = 1;
>>>>>
>>>>>                 ### Output:
>>>>>
>>>>>                 [1] "Padding"
>>>>>                 [1] "This line should be the first printed!"
>>>>>                 [1] "But ERROR: x was already evaluated, which
>>>>>                 printed \"Padding\""
>>>>>                 [1] "Padding = " # How did this happen ???
>>>>>
>>>>>
>>>>>                 ### Problems:
>>>>>
>>>>>                 1.) substitute(x): did not capture the expression;
>>>>>                 - the first parameter of 'right<-' was already
>>>>>                 evaluated, which is not
>>>>>                 the case with '%f%';
>>>>>                 Can I avoid evaluating this parameter?
>>>>>                 How can I avoid to evaluate it and capture the
>>>>>                 expression: "right(...)"?
>>>>>
>>>>>
>>>>>                 2.) Unexpected
>>>>>                 'padding<-' was also called!
>>>>>                 I did not know this. Is it feature or bug?
>>>>>                 R 4.0.4
>>>>>
>>>>>
>>>>>                 Sincerely,
>>>>>
>>>>>
>>>>>                 Leonard
>>>>>
>>>>>
>>>>>                 On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>>>>>                 > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>>>>>                 >> Hello,
>>>>>                 >>
>>>>>                 >>
>>>>>                 >> I can include code for "padding<-"as well, but
>>>>>                 the error is before that,
>>>>>                 >> namely in 'right<-':
>>>>>                 >>
>>>>>                 >> right = function(x, val) {print("Right");};
>>>>>                 >> # more options:
>>>>>                 >> padding = function(x, right, left, top, bottom)
>>>>>                 {print("Padding");};
>>>>>                 >> 'padding<-' = function(x, ...) {print("Padding
>>>>>                 = ");};
>>>>>                 >> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>>>                 >>
>>>>>                 >>
>>>>>                 >> ### Does NOT work
>>>>>                 >> 'right<-' = function(x, val) {
>>>>>                 >> ? ? ??? print("Already evaluated and also does
>>>>>                 not use 'val'");
>>>>>                 >> ? ? ??? x = substitute(x); # x was evaluated before
>>>>>                 >> }
>>>>>                 >>
>>>>>                 >> right(padding(df)) = 1;
>>>>>                 >
>>>>>                 > It "works" (i.e. doesn't generate an error) for
>>>>>                 me, when I correct
>>>>>                 > your typo:? the second argument to `right<-`
>>>>>                 should be `value`, not
>>>>>                 > `val`.
>>>>>                 >
>>>>>                 > I'm still not clear whether it does what you
>>>>>                 want with that fix,
>>>>>                 > because I don't really understand what you want.
>>>>>                 >
>>>>>                 > Duncan Murdoch
>>>>>                 >
>>>>>                 >>
>>>>>                 >>
>>>>>                 >> I want to capture the assignment event inside
>>>>>                 "right<-" and then call
>>>>>                 >> the function padding() properly.
>>>>>                 >>
>>>>>                 >> I haven't thought yet if I should use:
>>>>>                 >>
>>>>>                 >> padding(x, right, left, ... other parameters);
>>>>>                 >>
>>>>>                 >> or
>>>>>                 >>
>>>>>                 >> padding(x, parameter) <- value;
>>>>>                 >>
>>>>>                 >>
>>>>>                 >> It also depends if I can properly capture the
>>>>>                 unevaluated expression
>>>>>                 >> inside "right<-":
>>>>>                 >>
>>>>>                 >> 'right<-' = function(x, val) {
>>>>>                 >>
>>>>>                 >> # x is automatically evaluated when using 'f<-'!
>>>>>                 >>
>>>>>                 >> # but not when implementing as '%f%' =
>>>>>                 function(x, y);
>>>>>                 >>
>>>>>                 >> }
>>>>>                 >>
>>>>>                 >>
>>>>>                 >> Many thanks,
>>>>>                 >>
>>>>>                 >>
>>>>>                 >> Leonard
>>>>>                 >>
>>>>>                 >>
>>>>>                 >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>>>>>                 >>> On 12/09/2021 10:33 a.m., Leonard Mada via
>>>>>                 R-help wrote:
>>>>>                 >>>> How can I avoid evaluation?
>>>>>                 >>>>
>>>>>                 >>>> right = function(x, val) {print("Right");};
>>>>>                 >>>> padding = function(x) {print("Padding");};
>>>>>                 >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>>>                 >>>>
>>>>>                 >>>> ### OK
>>>>>                 >>>> '%=%' = function(x, val) {
>>>>>                 >>>> ?? ??? x = substitute(x);
>>>>>                 >>>> }
>>>>>                 >>>> right(padding(df)) %=% 1; # but ugly
>>>>>                 >>>>
>>>>>                 >>>> ### Does NOT work
>>>>>                 >>>> 'right<-' = function(x, val) {
>>>>>                 >>>> print("Already evaluated and also does not
>>>>>                 use 'val'");
>>>>>                 >>>> ?? ??? x = substitute(x); # is evaluated before
>>>>>                 >>>> }
>>>>>                 >>>>
>>>>>                 >>>> right(padding(df)) = 1
>>>>>                 >>>
>>>>>                 >>> That doesn't make sense.? You don't have a
>>>>>                 `padding<-` function, and
>>>>>                 >>> yet you are trying to call right<- to assign
>>>>>                 something to padding(df).
>>>>>                 >>>
>>>>>                 >>> I'm not sure about your real intention, but
>>>>>                 assignment functions by
>>>>>                 >>> their nature need to evaluate the thing they
>>>>>                 are assigning to, since
>>>>>                 >>> they are designed to modify objects, not
>>>>>                 create new ones.
>>>>>                 >>>
>>>>>                 >>> To create a new object, just use regular
>>>>>                 assignment.
>>>>>                 >>>
>>>>>                 >>> Duncan Murdoch
>>>>>                 >
>>>>>
>>>>>                 ______________________________________________
>>>>>                 R-help at r-project.org <mailto:R-help at r-project.org>
>>>>>                 mailing list -- To UNSUBSCRIBE and more, see
>>>>>                 https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>                 <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>                 PLEASE do read the posting guide
>>>>>                 http://www.R-project.org/posting-guide.html
>>>>>                 <http://www.R-project.org/posting-guide.html>
>>>>>                 and provide commented, minimal, self-contained,
>>>>>                 reproducible code.
>>>>>

	[[alternative HTML version deleted]]


From bret@chr @end|ng |rom x@4@||@n|  Wed Sep 15 09:05:46 2021
From: bret@chr @end|ng |rom x@4@||@n| (bretschr)
Date: Wed, 15 Sep 2021 09:05:46 +0200
Subject: [R] Handling interrupts in long-running R functions
In-Reply-To: <20210910164318.65b75378@trisector>
References: <20210910164318.65b75378@trisector>
Message-ID: <5D80E4AD-EDF5-451F-8078-712FACC412FC@xs4all.nl>

Dear Ivan Krylov,


Re:

> On 10 Sep 2021, at 16:43, Ivan Krylov <krylov.r00t at gmail.com> wrote:
> 
> Hello everyone,
> 
> I'm writing an R function that may be running for "long" periods of
> time (think tens of minutes), and I would like to be able to tell it:
> "please stop what you're doing and return the not-yet converged results
> as they are for inspection".
> 
> The behaviour I'm striving for is
> 
> 1) User presses interrupt
> 2) Function handles the interrupt and returns as if the convergence
>   test passed
> 3) By some black magic, the interrupt condition is raised on the
>   previous function call level (to avoid the situation where my
>   function is called in a loop by some other function and the user
>   wants to interrupt the whole process, not just my function).
> 
> Is this a good idea? Is (3) even possible? (I guess I could check the
> length of sys.parents() and avoid recovering from the interrupt if
> called from some other function, but that feels dirty.) Could something
> similar be achieved with options(error = recover) and R restarts? Are
> there other ways of, well, interrupting the execution of R functions
> without changing the semantics of interrupts in R?
> 
> I've been working with MATLAB lately (when in Rome, do as Romans
> do...), and their idiom for my desired behaviour is "create a plot
> window and return when that window is closed", but that doesn't
> translate well to R.
> 
> -- 
> Best regards,
> Ivan



Just a crazy idea: the sound input of a Mac/PC might serve as an interrupt.
Record a short bit and assess the amplitude: moderate = signal, loud = break.
See my source code below. This works on my MacBook Air with Mojave.
When I snap my fingers, the amplitude is moderate (3 through 10), when tapping 
or scratching the microphone, amplitude is over 20.

Hoping this might help,
With best regards,


Franklin
------


R source code:


#  sound as interrupt.R
#  with package audio
#  15-09-2021
#  ====================
#  NB First switch audio input to the wanted device
#     (microphone, sound input or 3rd party device)
#  flick your fingers = signal (m about 3 through 10)
#  tap the microphone -> stop  (m > 20)
library(audio)
samp.rate = 44100
rectime = 1  #  second
nsamples = samp.rate * rectime
repeat {
	sample <- record(2*nsamples, rate=44100, channels=2)
	wait(sample) # wait for the recording to finish
	sound <- sample$data # get the result
	m = max(sound)
	print(m)
	if (m > 0.5) alarm()  #  or the desired routine
	if (m > 20) {save.wave(sound, "sound from audio input.wav"); break}   # stop program
	}
#  end




Franklin Bretschneider
Dept of Biology
Utrecht University
f.bretschneider at uu.nl


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Sep 15 16:53:17 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 15 Sep 2021 16:53:17 +0200
Subject: [R] show structure of selected columns of dataframe
Message-ID: <CAMk+s2S6F07wQpVRmX4r=hNW+1y9t3ACxWQeRKaMk2PknTq0ow@mail.gmail.com>

Hello,
I have a dataframe and I would like to browse the information of its
structure only for a subset of columns (since there are hundreds of
them).
For instance, I tried with grepping some columns as in:
```
df <- data.frame(var_a1 = c(letters[1:3], letters[1:4]),
                 var2 = c(LETTERS[1:7]),
                 var_a2 = c(letters[1:3], letters[1:4]),
                 var4 = (1:7)^2,
                 var_a3 = c("light", "light", "heavy", "heavy", "heavy",
                          "light", "heavy"),
                 stringsAsFactors = FALSE)
> grep("*._a*.", names(df))
[1] 1 3 5
```
This tells me that the pattern v_1 is present in the name of columns 1 3 5.
Would it be possible to get a str() of just these columns?

```
> str(df)
'data.frame': 7 obs. of  5 variables:
 $ var_a1: chr  "a" "b" "c" "a" ...
 $ var2  : chr  "A" "B" "C" "D" ...
 $ var_a2: chr  "a" "b" "c" "a" ...
 $ var4  : num  1 4 9 16 25 36 49
 $ var_a3: chr  "light" "light" "heavy" "heavy" ...
```

Thank you

-- 
Best regards,
Luigi


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep 15 17:12:39 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 15 Sep 2021 08:12:39 -0700
Subject: [R] show structure of selected columns of dataframe
In-Reply-To: <CAMk+s2S6F07wQpVRmX4r=hNW+1y9t3ACxWQeRKaMk2PknTq0ow@mail.gmail.com>
References: <CAMk+s2S6F07wQpVRmX4r=hNW+1y9t3ACxWQeRKaMk2PknTq0ow@mail.gmail.com>
Message-ID: <69C693BA-4723-4FAD-A441-639A4BE28AE7@dcn.davis.ca.us>

Really?

str( df[ , grep(".*_a*.", names(df)) ] )


On September 15, 2021 7:53:17 AM PDT, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>Hello,
>I have a dataframe and I would like to browse the information of its
>structure only for a subset of columns (since there are hundreds of
>them).
>For instance, I tried with grepping some columns as in:
>```
>df <- data.frame(var_a1 = c(letters[1:3], letters[1:4]),
>                 var2 = c(LETTERS[1:7]),
>                 var_a2 = c(letters[1:3], letters[1:4]),
>                 var4 = (1:7)^2,
>                 var_a3 = c("light", "light", "heavy", "heavy", "heavy",
>                          "light", "heavy"),
>                 stringsAsFactors = FALSE)
>> grep("*._a*.", names(df))
>[1] 1 3 5
>```
>This tells me that the pattern v_1 is present in the name of columns 1 3 5.
>Would it be possible to get a str() of just these columns?
>
>```
>> str(df)
>'data.frame': 7 obs. of  5 variables:
> $ var_a1: chr  "a" "b" "c" "a" ...
> $ var2  : chr  "A" "B" "C" "D" ...
> $ var_a2: chr  "a" "b" "c" "a" ...
> $ var4  : num  1 4 9 16 25 36 49
> $ var_a3: chr  "light" "light" "heavy" "heavy" ...
>```
>
>Thank you
>

-- 
Sent from my phone. Please excuse my brevity.


From g@@@powe|| @end|ng |rom protonm@||@com  Wed Sep 15 17:38:11 2021
From: g@@@powe|| @end|ng |rom protonm@||@com (Gregg Powell)
Date: Wed, 15 Sep 2021 15:38:11 +0000
Subject: [R] How to remove all rows that have a numeric in the first (or
 any) column
In-Reply-To: <082EC7F4-3BDB-40F0-894E-14131660FADB@dcn.davis.ca.us>
References: <l6aXtyR0rWXlRJKphEzXZy4rAsQF2J_oEg2KHN9sXl5jmhFrGETIIVeNPmCv9yTN79IvJNrojQpmELxzzSXZ0cJX7VKmfPyO-wb6gIJTuZg=@protonmail.com>
 <BKIgN44too4juT0O9jtdnxR_OTD1Lv28B0FB_2h8hR-ZmvAKtDa_s-U_mjfZeJzfAiQw5Er24aLme_rdK2Vf5xGdEwrXyD7mRrpGT66_okM=@protonmail.com>
 <68A11171-83D4-4EDB-B98A-154BBDDF447D@dcn.davis.ca.us>
 <sE0QX_gzL2sYKaWmX7FuESeIEt_y4VDdE3PHJ1yPNe8Mlm8kQ3Wd8NYLzU9lQCA7iHUNSIqKNcO0M2_nzFq1JdMN26OCj2rZNw7lf-wyE5o=@protonmail.com>
 <5F88E791-CEC3-4B77-BF54-47D4D03094FB@dcn.davis.ca.us>
 <03f801d7a9eb$bba80b40$32f821c0$@verizon.net>
 <CAPcHnpRgC=t_9s3T9d7qbMH2_ShN23HTEkx3AuNXaBviYv1yzA@mail.gmail.com>
 <045d01d7a9f1$be389270$3aa9b750$@verizon.net>
 <047801d7a9f2$2843f100$78cbd300$@verizon.net>
 <082EC7F4-3BDB-40F0-894E-14131660FADB@dcn.davis.ca.us>
Message-ID: <Q8hM32kVTaq9SprB6lsppIrhdajrxE92efbZTvwPD4PCS1Rz_En09y4cyllFobKW-ZpUA-eR6eYkgEfED_qho5ZktHLd5_gXwZJZsDt9tyg=@protonmail.com>

Lots of feedback on this. Will have to take some time after work today to digest some of the more complex answers. Just wanted to say thank you though, to all who took time to provide feedback. I'm very grateful.

I'll likely be back with a few additional questions.

Regards

Gregg
Sierra Vista, AZ


Sent from ProtonMail mobile



\-------- Original Message --------
On Sep 14, 2021, 22:43, Jeff Newmiller < jdnewmil at dcn.davis.ca.us> wrote:

>
>
>
> FWIW I use them quite frequently, but not for the purpose of storing heterogeneous data... rather for holding complex objects of the same class.
>
> On September 14, 2021 10:25:54 PM PDT, Avi Gross via R-help <r-help at r-project.org> wrote:
> >My apologies. My reply was to Andrew, not Gregg.
> >
> >Enough damage for one night. Here is hoping we finally understood a question that could have been better phrased. list columns are not normally considered common data structures but quite possibly will be more as time goes on and the tools to handle them become better or at least better understood.
> >
> >
> >-----Original Message-----
> >From: R-help <r-help-bounces at r-project.org> On Behalf Of Avi Gross via R-help
> >Sent: Wednesday, September 15, 2021 1:23 AM
> >To: R-help at r-project.org
> >Subject: Re: \[R\] How to remove all rows that have a numeric in the first (or any) column
> >
> >You are correct, Gregg, I am aware of that trick of asking something to not be evaluated in certain ways.
> >
> >
> >
> >And you can indeed use base R to play with contents of beta as defined above. Here is a sort of incremental demo:
> >
> >
> >
> >> sapply(mydf$beta, is.numeric)
> >
> >\[1\] FALSE TRUE TRUE FALSE
> >
> >> !sapply(mydf$beta, is.numeric)
> >
> >\[1\] TRUE FALSE FALSE TRUE
> >
> >> keeping <- !sapply(mydf$beta, is.numeric)
> >
> >> mydf\[keeping, \]
> >
> >\# A tibble: 2 x 2
> >
> >alpha beta
> >
> ><int> <list>
> >
> > 1 1 <chr \[1\]>
> >
> > 2 4 <chr \[1\]>
> >
> > > str(mydf\[keeping, \])
> >
> >tibble \[2 x 2\] (S3: tbl\_df/tbl/data.frame)
> >
> >$ alpha: int \[1:2\] 1 4
> >
> >$ beta :List of 2
> >
> >..$ : chr "Hello"
> >
> >..$ : chr "bye"
> >
> >
> >
> >Now for the bad news. The original request was for ANY column. But presumably one way to do it, neither efficiently nor the best, would be to loop on the names of all the columns and starting with the original data.frame, whittle away at it column by column and adjust which column you search each time until what is left had nothing numeric anywhere.
> >
> >
> >
> >Now if I was using dplyr, I wonder if there is a nice way to use rowwise() to evaluate across a row.
> >
> >
> >
> >Using your technique I made the following data.frame:
> >
> >
> >
> >mydf <- data.frame(alpha=I(list("first", 2, 3.3, "Last")),
> >
> > beta=I(list(1, "second", 3.3, "Lasting")))
> >
> >
> >
> >> mydf
> >
> >alpha beta
> >
> >1 first 1
> >
> >2 2 second
> >
> >3 3.3 3.3
> >
> >4 Last Lasting
> >
> >
> >
> >Do we agree only the fourth row should be kept as the others have one or two numeric values?
> >
> >
> >
> >Here is some code I cobbled together that seems to work:
> >
> >
> >
> >
> >
> >rowwise(mydf) %>%
> >
> > mutate(alphazoid=!is.numeric(unlist(alpha)),
> >
> > betazoid=!is.numeric(unlist(beta))) %>%
> >
> > filter(alphazoid & betazoid) -> result
> >
> >
> >
> >str(result)
> >
> >print(result)
> >
> >result\[\[1,1\]\]
> >
> >result\[\[1,2\]\]
> >
> >
> >
> >as.data.frame(result)
> >
> >
> >
> >The results are shown below that only the fourth row was kept:
> >
> >
> >
> >> rowwise(mydf) %>%
> >
> > + mutate(alphazoid=!is.numeric(unlist(alpha)),
> >
> > + betazoid=!is.numeric(unlist(beta))) %>%
> >
> > + filter(alphazoid & betazoid) -> result
> >
> >>
> >
> > > str(result)
> >
> >rowwise\_df \[1 x 4\] (S3: rowwise\_df/tbl\_df/tbl/data.frame)
> >
> >$ alpha :List of 1
> >
> >..$ : chr "Last"
> >
> >..- attr(\*, "class")= chr "AsIs"
> >
> >$ beta :List of 1
> >
> >..$ : chr "Lasting"
> >
> >..- attr(\*, "class")= chr "AsIs"
> >
> >$ alphazoid: logi TRUE
> >
> >$ betazoid : logi TRUE
> >
> >- attr(\*, "groups")= tibble \[1 x 1\] (S3: tbl\_df/tbl/data.frame)
> >
> >..$ .rows: list<int> \[1:1\]
> >
> >.. ..$ : int 1
> >
> >.. ..@ ptype: int(0)
> >
> >> print(result)
> >
> >\# A tibble: 1 x 4
> >
> >\# Rowwise:
> >
> >alpha beta alphazoid betazoid
> >
> ><I<list>> <I<list>> <lgl> <lgl>
> >
> > 1 <chr \[1\]> <chr \[1\]> TRUE TRUE
> >
> >> result\[\[1,1\]\]
> >
> >\[\[1\]\]
> >
> >\[1\] "Last"
> >
> >
> >
> >> result\[\[1,2\]\]
> >
> >\[\[1\]\]
> >
> >\[1\] "Lasting"
> >
> >
> >
> >> as.data.frame(result)
> >
> >alpha beta alphazoid betazoid
> >
> >1 Last Lasting TRUE TRUE
> >
> >
> >
> >Of course, the temporary columns for alphazoid and betazoid can trivially be removed.
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >From: Andrew Simmons <akwsimmo at gmail.com>
> >Sent: Wednesday, September 15, 2021 12:44 AM
> >To: Avi Gross <avigross at verizon.net>
> >Cc: Gregg Powell via R-help <r-help at r-project.org>
> >Subject: Re: \[R\] How to remove all rows that have a numeric in the first (or any) column
> >
> >
> >
> >I'd like to point out that base R can handle a list as a data frame column, it's just that you have to make the list of class "AsIs". So in your example
> >
> >
> >
> >temp <- list("Hello", 1, 1.1, "bye")
> >
> >
> >
> >data.frame(alpha = 1:4, beta = I(temp))
> >
> >
> >
> >means that column "beta" will still be a list.
> >
> >
> >
> >
> >
> >On Wed, Sep 15, 2021, 00:40 Avi Gross via R-help <r-help at r-project.org <mailto:r-help at r-project.org> > wrote:
> >
> >Calling something a data.frame does not make it a data.frame.
> >
> >The abbreviated object shown below is a list of singletons. If it is a column in a larger object that is a data.frame, then it is a list column which is valid but can be ticklish to handle within base R but less so in the tidyverse.
> >
> >For example, if I try to make a data.frame the normal way, the list gets made into multiple columns and copied to each row. Not what was expected. I think some tidyverse functionality does better.
> >
> >Like this:
> >
> >library(tidyverse)
> >temp=list("Hello", 1, 1.1, "bye")
> >
> >Now making a data.frame has an odd result:
> >
> >> mydf=data.frame(alpha=1:4, beta=temp)
> >> mydf
> >alpha beta..Hello. beta.1 beta.1.1 beta..bye.
> >1 1 Hello 1 1.1 bye
> >2 2 Hello 1 1.1 bye
> >3 3 Hello 1 1.1 bye
> >4 4 Hello 1 1.1 bye
> >
> >But a tibble handles it:
> >
> >> mydf=tibble(alpha=1:4, beta=temp)
> >> mydf
> >\# A tibble: 4 x 2
> >alpha beta
> ><int> <list>
> > 1 1 <chr \[1\]>
> > 2 2 <dbl \[1\]>
> > 3 3 <dbl \[1\]>
> > 4 4 <chr \[1\]>
> >
> >So if the data does look like this, with a list column, but access can be tricky as subsetting a list with \[\] returns a list and you need \[\[\]\].
> >
> >I found a somehwhat odd solution like this:
> >
> >mydf %>%
> > filter(!map\_lgl(beta, is.numeric)) -> mydf2 \# A tibble: 2 x 2
> >alpha beta
> ><int> <list>
> > 1 1 <chr \[1\]>
> > 2 4 <chr \[1\]>
> >
> >When I saved that result into mydf2, I got this.
> >
> >Original:
> >
> > > str(mydf)
> >tibble \[4 x 2\] (S3: tbl\_df/tbl/data.frame) $ alpha: int \[1:4\] 1 2 3 4 $ beta :List of 4 ..$ : chr "Hello"
> >..$ : num 1
> >..$ : num 1.1
> >..$ : chr "bye"
> >
> >Output when any row with a numeric is removed:
> >
> >> str(mydf2)
> >tibble \[2 x 2\] (S3: tbl\_df/tbl/data.frame) $ alpha: int \[1:2\] 1 4 $ beta :List of 2 ..$ : chr "Hello"
> >..$ : chr "bye"
> >
> >So if you try variations on your code motivated by what I show, good luck. I am sure there are many better ways but I repeat, it can be tricky.
> >
> >-----Original Message-----
> >From: R-help <r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org> > On Behalf Of Jeff Newmiller
> >Sent: Tuesday, September 14, 2021 11:54 PM
> >To: Gregg Powell <g.a.powell at protonmail.com <mailto:g.a.powell at protonmail.com> >
> >Cc: Gregg Powell via R-help <r-help at r-project.org <mailto:r-help at r-project.org> >
> >Subject: Re: \[R\] How to remove all rows that have a numeric in the first (or any) column
> >
> >You cannot apply vectorized operators to list columns... you have to use a map function like sapply or purrr::map\_lgl to obtain a logical vector by running the function once for each list element:
> >
> >sapply( VPN\_Sheet1$HVA, is.numeric )
> >
> >On September 14, 2021 8:38:35 PM PDT, Gregg Powell <g.a.powell at protonmail.com <mailto:g.a.powell at protonmail.com> > wrote:
> >>Here is the output:
> >>
> >>> str(VPN\_Sheet1$HVA)
> >>List of 2174
> >> $ : chr "Email: fffd at fffffffffff.com <mailto:fffd at fffffffffff.com> "
> >> $ : num 1
> >> $ : chr "Eloisa Libas"
> >> $ : chr "Percival Esquejo"
> >> $ : chr "Louchelle Singh"
> >> $ : num 2
> >> $ : chr "Charisse Anne Tabarno, RN"
> >> $ : chr "Sol Amor Mucoy"
> >> $ : chr "Josan Moira Paler"
> >> $ : num 3
> >> $ : chr "Anna Katrina V. Alberto"
> >> $ : chr "Nenita Velarde"
> >> $ : chr "Eunice Arrances"
> >> $ : num 4
> >> $ : chr "Catherine Henson"
> >> $ : chr "Maria Carla Daya"
> >> $ : chr "Renee Ireine Alit"
> >> $ : num 5
> >> $ : chr "Marol Joseph Domingo - PS"
> >> $ : chr "Kissy Andrea Arriesgado"
> >> $ : chr "Pia B Baluyut, RN"
> >> $ : num 6
> >> $ : chr "Gladys Joy Tan"
> >> $ : chr "Frances Zarzua"
> >> $ : chr "Fairy Jane Nery"
> >> $ : num 7
> >> $ : chr "Gladys Tijam, RMT"
> >> $ : chr "Sarah Jane Aramburo"
> >> $ : chr "Eve Mendoza"
> >> $ : num 8
> >> $ : chr "Gloria Padolino"
> >> $ : chr "Joyce Pearl Javier"
> >> $ : chr "Ayza Padilla"
> >> $ : num 9
> >> $ : chr "Walfredson Calderon"
> >> $ : chr "Stephanie Anne Militante"
> >> $ : chr "Rennua Oquilan"
> >> $ : num 10
> >> $ : chr "Neil John Nery"
> >> $ : chr "Maria Reyna Reyes"
> >> $ : chr "Rowella Villegas"
> >> $ : num 11
> >> $ : chr "Katelyn Mendiola"
> >> $ : chr "Maria Riza Mariano"
> >> $ : chr "Marie Vallianne Carantes"
> >> $ : num 12
> >>
> >>??????? Original Message ???????
> >>
> >>On Tuesday, September 14th, 2021 at 8:32 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us> > wrote:
> >>
> >>> An atomic column of data by design has exactly one mode, so if any
> >>> values are non-numeric then the entire column will be non-numeric.
> >>> What does
> >>>
> >>
> >>> str(VPN\_Sheet1$HVA)
> >>>
> >>
> >>> tell you? It is likely either a factor or character data.
> >>>
> >>
> >>> On September 14, 2021 7:01:53 PM PDT, Gregg Powell via R-help r-help at r-project.org <mailto:r-help at r-project.org> wrote:
> >>>
> >>
> >>> > > Stuck on this problem - How does one remove all rows in a dataframe that have a numeric in the first (or any) column?
> >>> >
> >>
> >>> > > Seems straight forward - but I'm having trouble.
> >>> >
> >>
> >>> > I've attempted to used:
> >>> >
> >>
> >>> > VPN\_Sheet1 <- VPN\_Sheet1\[!is.numeric(VPN\_Sheet1$HVA),\]
> >>> >
> >>
> >>> > and
> >>> >
> >>
> >>> > VPN\_Sheet1 <- VPN\_Sheet1\[!is.integer(VPN\_Sheet1$HVA),\]
> >>> >
> >>
> >>> > Neither work - Neither throw an error.
> >>> >
> >>
> >>> > class(VPN\_Sheet1$HVA) returns:
> >>> >
> >>
> >>> > \[1\] "list"
> >>> >
> >>
> >>> > So, the HVA column returns a list.
> >>> >
> >>
> >>> > > Data looks like the attached screen grab -
> >>> >
> >>
> >>> > > The ONLY rows I need to delete are the rows where there is a numeric in the HVA column.
> >>> >
> >>
> >>> > > There are some 5000+ rows in the actual data.
> >>> >
> >>
> >>> > > Would be grateful for a solution to this problem.
> >>> >
> >>
> >>> > How to get R to detect whether the value in column 1 is a number so the rows with the number values can be deleted?
> >>> >
> >>
> >>> > > Thanks in advance to any and all willing to help on this problem.
> >>> >
> >>
> >>> > > Gregg Powell
> >>> >
> >>
> >>> > > Sierra Vista, AZ
> >>>
> >>
> >>> --
> >>>
> >>
> >>> Sent from my phone. Please excuse my brevity.
> >--
> >Sent from my phone. Please excuse my brevity.
> >
> >\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
> >R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
> >R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > \[\[alternative HTML version deleted\]\]
> >
> >\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> \--
> Sent from my phone. Please excuse my brevity.
>
> \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 509 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210915/e6825333/attachment.sig>

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Sep 15 18:47:16 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 15 Sep 2021 18:47:16 +0200
Subject: [R] show structure of selected columns of dataframe
In-Reply-To: <69C693BA-4723-4FAD-A441-639A4BE28AE7@dcn.davis.ca.us>
References: <CAMk+s2S6F07wQpVRmX4r=hNW+1y9t3ACxWQeRKaMk2PknTq0ow@mail.gmail.com>
 <69C693BA-4723-4FAD-A441-639A4BE28AE7@dcn.davis.ca.us>
Message-ID: <CAMk+s2Q6Sv6otodK_H8fF+pYj5C=e9wpiOyQPbBv-k=d01wPEQ@mail.gmail.com>

Thanks

On Wed, Sep 15, 2021 at 5:12 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Really?
>
> str( df[ , grep(".*_a*.", names(df)) ] )
>
>
> On September 15, 2021 7:53:17 AM PDT, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >Hello,
> >I have a dataframe and I would like to browse the information of its
> >structure only for a subset of columns (since there are hundreds of
> >them).
> >For instance, I tried with grepping some columns as in:
> >```
> >df <- data.frame(var_a1 = c(letters[1:3], letters[1:4]),
> >                 var2 = c(LETTERS[1:7]),
> >                 var_a2 = c(letters[1:3], letters[1:4]),
> >                 var4 = (1:7)^2,
> >                 var_a3 = c("light", "light", "heavy", "heavy", "heavy",
> >                          "light", "heavy"),
> >                 stringsAsFactors = FALSE)
> >> grep("*._a*.", names(df))
> >[1] 1 3 5
> >```
> >This tells me that the pattern v_1 is present in the name of columns 1 3 5.
> >Would it be possible to get a str() of just these columns?
> >
> >```
> >> str(df)
> >'data.frame': 7 obs. of  5 variables:
> > $ var_a1: chr  "a" "b" "c" "a" ...
> > $ var2  : chr  "A" "B" "C" "D" ...
> > $ var_a2: chr  "a" "b" "c" "a" ...
> > $ var4  : num  1 4 9 16 25 36 49
> > $ var_a3: chr  "light" "light" "heavy" "heavy" ...
> >```
> >
> >Thank you
> >
>
> --
> Sent from my phone. Please excuse my brevity.



-- 
Best regards,
Luigi


From y@ngk@|9999 @end|ng |rom y@hoo@com  Wed Sep 15 19:49:54 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Wed, 15 Sep 2021 17:49:54 +0000 (UTC)
Subject: [R] ggplot question
References: <1974309718.233001.1631728194672.ref@mail.yahoo.com>
Message-ID: <1974309718.233001.1631728194672@mail.yahoo.com>

Hello List,
I use ggplot to draw a stack bar chart. but I error message. please look it below:

> ggplot(s8_plot, aes(fill=GTresult, y=cases, x=gc_label) + 
+   geom_bar(position="stack", stat="identity"))

Error: Mapping should be created with `aes()` or `aes_()`.

GTresult and gc_label are character variables, cases is numeric variable. How to fix the problem?
Thank you
Kai

	[[alternative HTML version deleted]]


From g@@mo||n@k|1 @end|ng |rom gm@||@com  Wed Sep 15 19:54:39 2021
From: g@@mo||n@k|1 @end|ng |rom gm@||@com (=?UTF-8?Q?Grzegorz_Smoli=C5=84ski?=)
Date: Wed, 15 Sep 2021 19:54:39 +0200
Subject: [R] ODP:  ggplot question
In-Reply-To: <1974309718.233001.1631728194672@mail.yahoo.com>
References: <1974309718.233001.1631728194672.ref@mail.yahoo.com>
 <1974309718.233001.1631728194672@mail.yahoo.com>
Message-ID: <CABxpnnmTkS3sgvt_N9P4U=SKUDUpCR1DTeCDxP80gZZKWGKeBQ@mail.gmail.com>

Hi,

Isn?t a bracket missing after gc_label?

So it should be:

> ggplot(s8_plot, aes(fill=GTresult, y=cases, x=gc_label)) +

+   geom_bar(position="stack", stat="identity"))

Best,

Grzegorz

Od: Kai Yang via R-help
Wys?ano: ?roda, 15 wrze?nia 2021 19:50
Do: R-help Mailing List
Temat: [R] ggplot question



Hello List,

I use ggplot to draw a stack bar chart. but I error message. please
look it below:



> ggplot(s8_plot, aes(fill=GTresult, y=cases, x=gc_label) +

+   geom_bar(position="stack", stat="identity"))



Error: Mapping should be created with `aes()` or `aes_()`.



GTresult and gc_label are character variables, cases is numeric
variable. How to fix the problem?

Thank you

Kai



           [[alternative HTML version deleted]]



______________________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.


From @|e@@|@c|r @end|ng |rom hotm@||@|t  Wed Sep 15 14:15:36 2021
From: @|e@@|@c|r @end|ng |rom hotm@||@|t (alessia ciraolo)
Date: Wed, 15 Sep 2021 12:15:36 +0000
Subject: [R] error with dbFD function in FD library
Message-ID: <DB6PR07MB43412251F2D827836FD2090AABDB9@DB6PR07MB4341.eurprd07.prod.outlook.com>

Hi everyone,
I have a question about FD package. I?m trying to calculate functional

diversity indices on my marine organisms data. My trait data includes mobility, feeding type and reworking sediment type. I allowed more than one functional trait for a given taxon for each category, and scored from 0 to 1 based on the extent to which they displayed each trait. If two traits were shared by one taxa, I gave it 0.5 and 0.5 per trait.



ex1<-dbFD(fi,abund,calc.FRic = F/T, corr="cailliez",

          w.abun = T, CWM.type = "all" )



However, when I set ?calc.Frich=T?, I got the Feve, Fdis, RaoQ and CWM values

for my data, BUT when I set ?calc.Frich=T? I receive the following error:

Error in convhulln(tr.FRic, "FA") :

  Received error code 2 from qhull. Qhull error:

qhull precision warning:

The initial hull is narrow (cosine of min. angle is 1.0000000000000000).

Is the input lower dimensional (e.g., on a plane in 3-d)?  Qhull may

produce a wide facet.  Options 'QbB' (scale to unit box) or 'Qbb' (scale

last coordinate) may remove this warning.  Use 'Pp' to skip this warning.

See 'Limitations' in qh-impre.htm.

QH6114 qhull precision error: initial simplex is not convex. Distance=-2.5e-015



While executing:  | qhull FA  Qt

Options selected for Qhull 2015.2.r 2016/01/18:

  run-id 748402268  FArea-total  Qtriangulate  Qxact_merge  _zero-centrum

  Q3-no-merge-vertices-dim-high  _max-width 5.4  Error-roundoff 2.2e-014

  _one-merge 3.7e-013  _near-inside 1.8e-012  Visible-distance 1.3e-013

  U-coplanar-distance 1.3e-013  Width-outside 2.6e-013  _wide-facet 7.8e-013

  _narrow-hull  0



precision problems (corrected unless 'Q0' or an error)

      1 flipped facets

      7 nearly singular or axis-parall



Could you please tell me how can I fix this problem and have the FRic value

for my data?




If you can hel me with that, it would be very appreciated.

Regards,
Alessia

Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows


	[[alternative HTML version deleted]]


From y@ngk@|9999 @end|ng |rom y@hoo@com  Wed Sep 15 21:03:20 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Wed, 15 Sep 2021 19:03:20 +0000 (UTC)
Subject: [R] ODP:  ggplot question
In-Reply-To: <CABxpnnmTkS3sgvt_N9P4U=SKUDUpCR1DTeCDxP80gZZKWGKeBQ@mail.gmail.com>
References: <1974309718.233001.1631728194672.ref@mail.yahoo.com>
 <1974309718.233001.1631728194672@mail.yahoo.com>
 <CABxpnnmTkS3sgvt_N9P4U=SKUDUpCR1DTeCDxP80gZZKWGKeBQ@mail.gmail.com>
Message-ID: <84480730.282429.1631732600803@mail.yahoo.com>

 Hi Grzegorz,
You are correct. it works now.
One more question: can I turn gc_label 90 degree in plot?
Thank you
Kai
    On Wednesday, September 15, 2021, 10:54:52 AM PDT, Grzegorz Smoli?ski <g.smolinski1 at gmail.com> wrote:  
 
 Hi,

Isn?t a bracket missing after gc_label?

So it should be:

> ggplot(s8_plot, aes(fill=GTresult, y=cases, x=gc_label)) +

+? geom_bar(position="stack", stat="identity"))

Best,

Grzegorz

Od: Kai Yang via R-help
Wys?ano: ?roda, 15 wrze?nia 2021 19:50
Do: R-help Mailing List
Temat: [R] ggplot question



Hello List,

I use ggplot to draw a stack bar chart. but I error message. please
look it below:



> ggplot(s8_plot, aes(fill=GTresult, y=cases, x=gc_label) +

+? geom_bar(position="stack", stat="identity"))



Error: Mapping should be created with `aes()` or `aes_()`.



GTresult and gc_label are character variables, cases is numeric
variable. How to fix the problem?

Thank you

Kai



? ? ? ? ? [[alternative HTML version deleted]]



______________________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Wed Sep 15 22:14:37 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Wed, 15 Sep 2021 23:14:37 +0300
Subject: [R] [R Code] Split long names in format.ftable
In-Reply-To: <7876cd2d-2855-fee4-2839-2821361fa85d@syonic.eu>
References: <7876cd2d-2855-fee4-2839-2821361fa85d@syonic.eu>
Message-ID: <1b3a8922-0557-256f-d707-4726e746b0d7@syonic.eu>

Dear List members,


I have uploaded an improved version on Github:
- new option: align top vs bottom;

Functions:
split.names: splits and aligns the names;
merge.align: aligns 2 string matrices;
ftable2: enhanced version of format.ftable (proof of concept);
see:
https://github.com/discoleo/R/blob/master/Stat/Tools.Data.R


It makes sense to have such functionality in base R as well: it may be 
useful in various locations to format character output.


Sincerely,


Leonard


On 9/14/2021 8:18 PM, Leonard Mada wrote:
> Dear List members,
>
>
> I wrote some code to split long names in format.ftable. I hope it will 
> be useful to others as well.
>
>
> Ideally, this code should be implemented natively in R. I will provide 
> in the 2nd part of the mail a concept how to actually implement the 
> code in R. This may be interesting to R-devel as well.
>
>
> ### Helper function
>
> # Split the actual names
>
> split.names = function(names, extend=0, justify="Right", 
> blank.rm=FALSE, split.ch = "\n", detailed=TRUE) {
> ??? justify = if(is.null(justify)) 0 else pmatch(justify, c("Left", 
> "Right"));
> ??? str = strsplit(names, split.ch);
> ??? if(blank.rm) str = lapply(str, function(s) s[nchar(s) > 0]);
> ??? nr? = max(sapply(str, function(s) length(s)));
> ??? nch = lapply(str, function(s) max(nchar(s)));
> ??? chf = function(nch) paste0(rep(" ", nch), collapse="");
> ??? ch0 = sapply(nch, chf);
> ??? mx? = matrix(rep(ch0, each=nr), nrow=nr, ncol=length(names));
> ??? for(nc in seq(length(names))) {
> ??? ??? n = length(str[[nc]]);
> ??? ??? # Justifying
> ??? ??? s = sapply(seq(n), function(nr) paste0(rep(" ", nch[[nc]] - 
> nchar(str[[nc]][nr])), collapse=""));
> ??? ??? s = if(justify == 2) paste0(s, str[[nc]]) else 
> paste0(str[[nc]], s);
> ??? ??? mx[seq(nr + 1 - length(str[[nc]]), nr) , nc] = s;
> ??? }
> ??? if(extend > 0) {
> ??? ??? mx = cbind(mx, matrix("", nr=nr, ncol=extend));
> ??? }
> ??? if(detailed) attr(mx, "nchar") = unlist(nch);
> ??? return(mx);
> }
>
> ### ftable with name splitting
> # - this code should be ideally integrated inside format.ftable;
> ftable2 = function(ftbl, print=TRUE, quote=FALSE, ...) {
> ??? ftbl2 = format(ftbl, quote=quote, ...);
> ??? row.vars = names(attr(ftbl, "row.vars"))
> ??? nr = length(row.vars);
> ??? nms = split.names(row.vars, extend = ncol(ftbl2) - nr);
> ??? ftbl2 = rbind(ftbl2[1,], nms, ftbl2[-c(1,2),]);
> ??? # TODO: update width of factor labels;
> ??? # - new width available in attr(nms, "nchar");
> ??? if(print) {
> ??? ??? cat(t(ftbl2), sep = c(rep(" ", ncol(ftbl2) - 1), "\n"))
> ??? }
> ??? invisible(ftbl2);
> }
>
> I have uploaded this code also on Github:
>
> https://github.com/discoleo/R/blob/master/Stat/Tools.Data.R
>
>
> B.) Detailed Concept
> # - I am ignoring any variants;
> # - the splitting is actually done in format.ftable;
> # - we set only an attribute in ftable;
> ftable = function(..., split.ch="\n") {
> ?? [...]
> ?? attr(ftbl, "split.ch") = split.ch; # set an attribute "split.ch"
> ?? return(ftbl);
> }
>
> format.ftable(ftbl, ..., split.ch) {
> if(is.missing(split.ch)) {
> ?? # check if the split.ch attribute is set and use it;
> } else {
> ?? # use the explicitly provided split.ch: if( ! is.null(split.ch))
> }
> ?? [...]
> }
>
>
> C.) split.names Function
>
> This function may be useful in other locations as well, particularly 
> to split names/labels used in axes and legends in various plots. But I 
> do not have much knowledge of the graphics engine in R.
>
>
> Sincerely,
>
>
> Leonard
>
>


From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 15 22:28:36 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 15 Sep 2021 13:28:36 -0700
Subject: [R] error with dbFD function in FD library
In-Reply-To: <DB6PR07MB43412251F2D827836FD2090AABDB9@DB6PR07MB4341.eurprd07.prod.outlook.com>
References: <DB6PR07MB43412251F2D827836FD2090AABDB9@DB6PR07MB4341.eurprd07.prod.outlook.com>
Message-ID: <CAGxFJbSUEZwOcsVYdMhACYuwJLO4ngbSyGbSLLxt11k1FVhEYg@mail.gmail.com>

The posting guide, linked below (please read it!), says:

"For questions about functions in standard packages distributed with R
(see the FAQ Add-on packages in R), ask questions on R-help.
If the question relates to a contributed package , e.g., one
downloaded from CRAN, try contacting the package maintainer first. You
can also use find("functionname") and
packageDescription("packagename") to find this information. Only send
such questions to R-help or R-devel if you get no reply or need
further assistance. This applies to both requests for help and to bug
reports."

So your query is inappropriate here. I think you should try the
r-sig-ecology list -- or the maintainer -- instead.

However, I will make a totally ignorant guess (so feel free to
ignore): your data have linear dependencies which reduce its effective
dimensionality. If this is (approximately?) correct, your data cannot
support the analyses that you are trying to do.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Sep 15, 2021 at 11:44 AM alessia ciraolo <alessiacir at hotmail.it> wrote:
>
> Hi everyone,
> I have a question about FD package. I?m trying to calculate functional
>
> diversity indices on my marine organisms data. My trait data includes mobility, feeding type and reworking sediment type. I allowed more than one functional trait for a given taxon for each category, and scored from 0 to 1 based on the extent to which they displayed each trait. If two traits were shared by one taxa, I gave it 0.5 and 0.5 per trait.
>
>
>
> ex1<-dbFD(fi,abund,calc.FRic = F/T, corr="cailliez",
>
>           w.abun = T, CWM.type = "all" )
>
>
>
> However, when I set ?calc.Frich=T?, I got the Feve, Fdis, RaoQ and CWM values
>
> for my data, BUT when I set ?calc.Frich=T? I receive the following error:
>
> Error in convhulln(tr.FRic, "FA") :
>
>   Received error code 2 from qhull. Qhull error:
>
> qhull precision warning:
>
> The initial hull is narrow (cosine of min. angle is 1.0000000000000000).
>
> Is the input lower dimensional (e.g., on a plane in 3-d)?  Qhull may
>
> produce a wide facet.  Options 'QbB' (scale to unit box) or 'Qbb' (scale
>
> last coordinate) may remove this warning.  Use 'Pp' to skip this warning.
>
> See 'Limitations' in qh-impre.htm.
>
> QH6114 qhull precision error: initial simplex is not convex. Distance=-2.5e-015
>
>
>
> While executing:  | qhull FA  Qt
>
> Options selected for Qhull 2015.2.r 2016/01/18:
>
>   run-id 748402268  FArea-total  Qtriangulate  Qxact_merge  _zero-centrum
>
>   Q3-no-merge-vertices-dim-high  _max-width 5.4  Error-roundoff 2.2e-014
>
>   _one-merge 3.7e-013  _near-inside 1.8e-012  Visible-distance 1.3e-013
>
>   U-coplanar-distance 1.3e-013  Width-outside 2.6e-013  _wide-facet 7.8e-013
>
>   _narrow-hull  0
>
>
>
> precision problems (corrected unless 'Q0' or an error)
>
>       1 flipped facets
>
>       7 nearly singular or axis-parall
>
>
>
> Could you please tell me how can I fix this problem and have the FRic value
>
> for my data?
>
>
>
>
> If you can hel me with that, it would be very appreciated.
>
> Regards,
> Alessia
>
> Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @gent@ @end|ng |rom medd@t@|nc@com  Thu Sep 16 02:40:10 2021
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Wed, 15 Sep 2021 20:40:10 -0400
Subject: [R] Problem with plotmat package
Message-ID: <ca81fc55-3dc0-0f91-75f5-315c74cb2bf4@meddatainc.com>

I am using plotmat 1.6.5 (part of the diagram package) in R 3.6 to plot Markov transition charts but have run into an issue that I was hoping someone could shed light on here. I did e-mail the maintainer over a month ago but have not received a reply.

The issue is that the directional arrows point in the wrong direction. A brief example:

stateNames <- c("Rain", "Nice")
Oz <- matrix(c(0.25, 0.75, 0.6, 0.4), nrow = 2, byrow = TRUE)
rownames(Oz) <- stateNames; colnames(Oz) <- stateNames
plotmat(Oz, pos = c(1, 1), lwd = 1, box.lwd = 2, cex.txt = 0.8, box.size = 0.1, box.type = "circle", box.prop = 0.5, box.col = "light yellow", arr.length = 0.2, arr.width = 0.2, self.cex = 0.4, self.shifty = 0.01, self.shiftx = 0.13, main = "")

In the above example both arrows seem to point in the direction opposite to what I expect. Has anyone encountered this and know how to fix it?

Thanks.


From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 16 03:39:03 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 16 Sep 2021 11:39:03 +1000
Subject: [R] Problem with plotmat package
In-Reply-To: <ca81fc55-3dc0-0f91-75f5-315c74cb2bf4@meddatainc.com>
References: <ca81fc55-3dc0-0f91-75f5-315c74cb2bf4@meddatainc.com>
Message-ID: <CA+8X3fUXk4XseYENCEnEKx=yFmNyTGJnafbO0fZ=qsNkrUEwTA@mail.gmail.com>

Hi H,
Looking at your example and the help page, it looks to me as though
the plot is consistent with the "A" matrix:

 Oz
    Rain Nice
Rain 0.25 0.75
Nice 0.60 0.40

# help page
A  - square coefficient matrix, specifying the links (rows=to, cols=from).

In your plot (attached):
Rain (col) goes to Rain (row) 0.25
Rain (col) goes to Nice (row) 0.6
Nice (col) goes to Nice (row) 0.4
Nice (col) goes to Rain (row) 0.75

This is a bit confusing, but it seems to do what it says it does.

Jim

On Thu, Sep 16, 2021 at 10:40 AM H <agents at meddatainc.com> wrote:
>
> I am using plotmat 1.6.5 (part of the diagram package) in R 3.6 to plot Markov transition charts but have run into an issue that I was hoping someone could shed light on here. I did e-mail the maintainer over a month ago but have not received a reply.
>
> The issue is that the directional arrows point in the wrong direction. A brief example:
>
> stateNames <- c("Rain", "Nice")
> Oz <- matrix(c(0.25, 0.75, 0.6, 0.4), nrow = 2, byrow = TRUE)
> rownames(Oz) <- stateNames; colnames(Oz) <- stateNames
> plotmat(Oz, pos = c(1, 1), lwd = 1, box.lwd = 2, cex.txt = 0.8, box.size = 0.1, box.type = "circle", box.prop = 0.5, box.col = "light yellow", arr.length = 0.2, arr.width = 0.2, self.cex = 0.4, self.shifty = 0.01, self.shiftx = 0.13, main = "")
>
> In the above example both arrows seem to point in the direction opposite to what I expect. Has anyone encountered this and know how to fix it?
>
> Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 16 03:40:15 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 16 Sep 2021 11:40:15 +1000
Subject: [R] Problem with plotmat package
In-Reply-To: <CA+8X3fUXk4XseYENCEnEKx=yFmNyTGJnafbO0fZ=qsNkrUEwTA@mail.gmail.com>
References: <ca81fc55-3dc0-0f91-75f5-315c74cb2bf4@meddatainc.com>
 <CA+8X3fUXk4XseYENCEnEKx=yFmNyTGJnafbO0fZ=qsNkrUEwTA@mail.gmail.com>
Message-ID: <CA+8X3fW4brPdznLbM+MFBju2znSFJ-4Ag1uzAkUsVsRiv7Ov+A@mail.gmail.com>

Oops, your plot

On Thu, Sep 16, 2021 at 11:39 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi H,
> Looking at your example and the help page, it looks to me as though
> the plot is consistent with the "A" matrix:
>
>  Oz
>     Rain Nice
> Rain 0.25 0.75
> Nice 0.60 0.40
>
> # help page
> A  - square coefficient matrix, specifying the links (rows=to, cols=from).
>
> In your plot (attached):
> Rain (col) goes to Rain (row) 0.25
> Rain (col) goes to Nice (row) 0.6
> Nice (col) goes to Nice (row) 0.4
> Nice (col) goes to Rain (row) 0.75
>
> This is a bit confusing, but it seems to do what it says it does.
>
> Jim
>
> On Thu, Sep 16, 2021 at 10:40 AM H <agents at meddatainc.com> wrote:
> >
> > I am using plotmat 1.6.5 (part of the diagram package) in R 3.6 to plot Markov transition charts but have run into an issue that I was hoping someone could shed light on here. I did e-mail the maintainer over a month ago but have not received a reply.
> >
> > The issue is that the directional arrows point in the wrong direction. A brief example:
> >
> > stateNames <- c("Rain", "Nice")
> > Oz <- matrix(c(0.25, 0.75, 0.6, 0.4), nrow = 2, byrow = TRUE)
> > rownames(Oz) <- stateNames; colnames(Oz) <- stateNames
> > plotmat(Oz, pos = c(1, 1), lwd = 1, box.lwd = 2, cex.txt = 0.8, box.size = 0.1, box.type = "circle", box.prop = 0.5, box.col = "light yellow", arr.length = 0.2, arr.width = 0.2, self.cex = 0.4, self.shifty = 0.01, self.shiftx = 0.13, main = "")
> >
> > In the above example both arrows seem to point in the direction opposite to what I expect. Has anyone encountered this and know how to fix it?
> >
> > Thanks.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: plotmat_H.png
Type: image/png
Size: 2665 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210916/3be63027/attachment.png>

From g@@mo||n@k|1 @end|ng |rom gm@||@com  Thu Sep 16 08:09:08 2021
From: g@@mo||n@k|1 @end|ng |rom gm@||@com (=?UTF-8?Q?Grzegorz_Smoli=C5=84ski?=)
Date: Thu, 16 Sep 2021 08:09:08 +0200
Subject: [R] ODP:  ggplot question
In-Reply-To: <84480730.282429.1631732600803@mail.yahoo.com>
References: <1974309718.233001.1631728194672.ref@mail.yahoo.com>
 <1974309718.233001.1631728194672@mail.yahoo.com>
 <CABxpnnmTkS3sgvt_N9P4U=SKUDUpCR1DTeCDxP80gZZKWGKeBQ@mail.gmail.com>
 <84480730.282429.1631732600803@mail.yahoo.com>
Message-ID: <CABxpnnkmzi0-QPcONH0AuFAWzbc2kJUBscDWgyt9msj5kzcyBA@mail.gmail.com>

Hi,

of course you can. This should work:

ggplot(s8_plot, aes(fill=GTresult, y=cases, x=gc_label)) +
geom_bar(position="stack", stat="identity")) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))

By "hjust" you make sure that labels do not overlap on plot.

Best regards,

Grzegorz

?r., 15 wrz 2021 o 21:03 Kai Yang <yangkai9999 at yahoo.com> napisa?(a):
>
> Hi Grzegorz,
>
> You are correct. it works now.
>
> One more question: can I turn gc_label 90 degree in plot?
>
> Thank you
>
> Kai
>
> On Wednesday, September 15, 2021, 10:54:52 AM PDT, Grzegorz Smoli?ski <g.smolinski1 at gmail.com> wrote:
>
>
> Hi,
>
> Isn?t a bracket missing after gc_label?
>
> So it should be:
>
> > ggplot(s8_plot, aes(fill=GTresult, y=cases, x=gc_label)) +
>
> +  geom_bar(position="stack", stat="identity"))
>
> Best,
>
> Grzegorz
>
> Od: Kai Yang via R-help
> Wys?ano: ?roda, 15 wrze?nia 2021 19:50
> Do: R-help Mailing List
> Temat: [R] ggplot question
>
>
>
> Hello List,
>
> I use ggplot to draw a stack bar chart. but I error message. please
> look it below:
>
>
>
> > ggplot(s8_plot, aes(fill=GTresult, y=cases, x=gc_label) +
>
> +  geom_bar(position="stack", stat="identity"))
>
>
>
> Error: Mapping should be created with `aes()` or `aes_()`.
>
>
>
> GTresult and gc_label are character variables, cases is numeric
> variable. How to fix the problem?
>
> Thank you
>
> Kai
>
>
>
>           [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
>
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://stat.ethz.ch/mailman/listinfo/r-help
>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Sep 16 16:12:05 2021
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 16 Sep 2021 09:12:05 -0500
Subject: [R] unable to remove NAs from a data frame
Message-ID: <CAF9-5jMgcj+W4zUN52s3HUrK+qS2=dSOMkYCngrRspvH9=QKTQ@mail.gmail.com>

Hi All,

I have lines in file that look like this:

> df[14509227,]
    SNP   A1   A2 freq  b se  p  N
1: <NA> <NA> <NA>   NA NA NA NA NA

data looks like this:
> head(df)
           SNP A1 A2      freq       b     se      p      N
1:  rs74337086  G  A 0.0024460  0.1627 0.1231 0.1865 218792
2:  rs76388980  G  A 0.0034150  0.1451 0.1047 0.1660 218792
...
> sapply(df,class)
        SNP          A1          A2        freq           b          se
"character" "character" "character"   "numeric"   "numeric"   "numeric"
          p           N
  "numeric"   "integer"

> dim(df)
[1] 14509225        8

Tried:
> df=na.omit(df)
> dim(df)
[1] 14509225        8

and:
> library(tidyr)
> d=df %>% drop_na()
> dim(d)
[1] 14509225        8


Please advise,

Thanks
Ana


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep 16 16:12:32 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 16 Sep 2021 14:12:32 +0000
Subject: [R] adding results to plot
Message-ID: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>

Dear all

I know I have seen the answer somewhere but I am not able to find it. Please
help

> plot(1,1)
> res <- shapiro.test(rnorm(100))
> res

        Shapiro-Wilk normality test

data:  rnorm(100)
W = 0.98861, p-value = 0.5544

I would like to add whole res object to the plot.

I can do it one by one
> text(locator(1), res$method)
> text(locator(1), as.character(res$p.value))
...
But it is quite inconvenient

I could find some way in ggplot world but not in plain plot world.

Best regards
Petr

From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep 16 16:24:26 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 16 Sep 2021 14:24:26 +0000
Subject: [R] unable to remove NAs from a data frame
In-Reply-To: <CAF9-5jMgcj+W4zUN52s3HUrK+qS2=dSOMkYCngrRspvH9=QKTQ@mail.gmail.com>
References: <CAF9-5jMgcj+W4zUN52s3HUrK+qS2=dSOMkYCngrRspvH9=QKTQ@mail.gmail.com>
Message-ID: <3a0625af698d436d92f36fecd5cb0d15@SRVEXCHCM1302.precheza.cz>

Hi

You should consult either complete.cases function or to remove only rows in
which are only NAs you could use something like (untested)

df[!(colSums(is.na(df))==8),]

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ana Marija
> Sent: Thursday, September 16, 2021 4:12 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] unable to remove NAs from a data frame
> 
> Hi All,
> 
> I have lines in file that look like this:
> 
> > df[14509227,]
>     SNP   A1   A2 freq  b se  p  N
> 1: <NA> <NA> <NA>   NA NA NA NA NA
> 
> data looks like this:
> > head(df)
>            SNP A1 A2      freq       b     se      p      N
> 1:  rs74337086  G  A 0.0024460  0.1627 0.1231 0.1865 218792
> 2:  rs76388980  G  A 0.0034150  0.1451 0.1047 0.1660 218792 ...
> > sapply(df,class)
>         SNP          A1          A2        freq           b          se
> "character" "character" "character"   "numeric"   "numeric"   "numeric"
>           p           N
>   "numeric"   "integer"
> 
> > dim(df)
> [1] 14509225        8
> 
> Tried:
> > df=na.omit(df)
> > dim(df)
> [1] 14509225        8
> 
> and:
> > library(tidyr)
> > d=df %>% drop_na()
> > dim(d)
> [1] 14509225        8
> 
> 
> Please advise,
> 
> Thanks
> Ana
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From er|cjberger @end|ng |rom gm@||@com  Thu Sep 16 16:30:40 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 16 Sep 2021 17:30:40 +0300
Subject: [R] unable to remove NAs from a data frame
In-Reply-To: <CAF9-5jMgcj+W4zUN52s3HUrK+qS2=dSOMkYCngrRspvH9=QKTQ@mail.gmail.com>
References: <CAF9-5jMgcj+W4zUN52s3HUrK+qS2=dSOMkYCngrRspvH9=QKTQ@mail.gmail.com>
Message-ID: <CAGgJW74y8tuw3bK=zX5D1P725JazoyfSiVHqSKwhwDbGqmE1Kg@mail.gmail.com>

You are getting this because you asked for the contents of a row that
is beyond the number of rows in your data frame.

On Thu, Sep 16, 2021 at 5:12 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi All,
>
> I have lines in file that look like this:
>
> > df[14509227,]
>     SNP   A1   A2 freq  b se  p  N
> 1: <NA> <NA> <NA>   NA NA NA NA NA
>
> data looks like this:
> > head(df)
>            SNP A1 A2      freq       b     se      p      N
> 1:  rs74337086  G  A 0.0024460  0.1627 0.1231 0.1865 218792
> 2:  rs76388980  G  A 0.0034150  0.1451 0.1047 0.1660 218792
> ...
> > sapply(df,class)
>         SNP          A1          A2        freq           b          se
> "character" "character" "character"   "numeric"   "numeric"   "numeric"
>           p           N
>   "numeric"   "integer"
>
> > dim(df)
> [1] 14509225        8
>
> Tried:
> > df=na.omit(df)
> > dim(df)
> [1] 14509225        8
>
> and:
> > library(tidyr)
> > d=df %>% drop_na()
> > dim(d)
> [1] 14509225        8
>
>
> Please advise,
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep 16 16:44:48 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 16 Sep 2021 07:44:48 -0700
Subject: [R] adding results to plot
In-Reply-To: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
References: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGxFJbTGckG1xFRDPSc=K1gc7Bah3jycR+A_7TegutH_7UQMQw@mail.gmail.com>

res is a list of class "htest" . You can only add text strings  to a
plot via text(). I don't know what ggplot does.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 16, 2021 at 7:22 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Dear all
>
> I know I have seen the answer somewhere but I am not able to find it. Please
> help
>
> > plot(1,1)
> > res <- shapiro.test(rnorm(100))
> > res
>
>         Shapiro-Wilk normality test
>
> data:  rnorm(100)
> W = 0.98861, p-value = 0.5544
>
> I would like to add whole res object to the plot.
>
> I can do it one by one
> > text(locator(1), res$method)
> > text(locator(1), as.character(res$p.value))
> ...
> But it is quite inconvenient
>
> I could find some way in ggplot world but not in plain plot world.
>
> Best regards
> Petr
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From k|mmo@e|o @end|ng |rom utu@||  Thu Sep 16 16:45:03 2021
From: k|mmo@e|o @end|ng |rom utu@|| (Kimmo Elo)
Date: Thu, 16 Sep 2021 14:45:03 +0000
Subject: [R] adding results to plot
In-Reply-To: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
References: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
Message-ID: <ae0c7c1973a8d03398f5534df6b6ec8abaed3342.camel@utu.fi>

Hi!

Maybe with this:

text(x=0.6, y=1.2, paste0(capture.output(res), collapse="\n"), adj=0)

HTH,

Kimmo

to, 2021-09-16 kello 14:12 +0000, PIKAL Petr kirjoitti:
> 	Virhe vahvistaessa allekirjoitusta: Virhe tulkittaessa
> Dear all
> 
> I know I have seen the answer somewhere but I am not able to find it.
> Please
> help
> 
> > plot(1,1)
> > res <- shapiro.test(rnorm(100))
> > res
> 
>         Shapiro-Wilk normality test
> 
> data:  rnorm(100)
> W = 0.98861, p-value = 0.5544
> 
> I would like to add whole res object to the plot.
> 
> I can do it one by one
> > text(locator(1), res$method)
> > text(locator(1), as.character(res$p.value))
> ...
> But it is quite inconvenient
> 
> I could find some way in ggplot world but not in plain plot world.
> 
> Best regards
> Petr
> 
> ------=_NextPart_000_00C9_01D7AB15.A6E04EE0--
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From y@ngk@|9999 @end|ng |rom y@hoo@com  Thu Sep 16 16:59:27 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Thu, 16 Sep 2021 14:59:27 +0000 (UTC)
Subject: [R] ODP:  ggplot question
In-Reply-To: <CABxpnnkmzi0-QPcONH0AuFAWzbc2kJUBscDWgyt9msj5kzcyBA@mail.gmail.com>
References: <1974309718.233001.1631728194672.ref@mail.yahoo.com>
 <1974309718.233001.1631728194672@mail.yahoo.com>
 <CABxpnnmTkS3sgvt_N9P4U=SKUDUpCR1DTeCDxP80gZZKWGKeBQ@mail.gmail.com>
 <84480730.282429.1631732600803@mail.yahoo.com>
 <CABxpnnkmzi0-QPcONH0AuFAWzbc2kJUBscDWgyt9msj5kzcyBA@mail.gmail.com>
Message-ID: <780273911.483380.1631804367026@mail.yahoo.com>

 Hi Grzegorz,
this is great! it works for me.
Thank you,
Kai
    On Wednesday, September 15, 2021, 11:09:20 PM PDT, Grzegorz Smoli?ski <g.smolinski1 at gmail.com> wrote:  
 
 Hi,

of course you can. This should work:

ggplot(s8_plot, aes(fill=GTresult, y=cases, x=gc_label)) +
geom_bar(position="stack", stat="identity")) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))

By "hjust" you make sure that labels do not overlap on plot.

Best regards,

Grzegorz

?r., 15 wrz 2021 o 21:03 Kai Yang <yangkai9999 at yahoo.com> napisa?(a):
>
> Hi Grzegorz,
>
> You are correct. it works now.
>
> One more question: can I turn gc_label 90 degree in plot?
>
> Thank you
>
> Kai
>
> On Wednesday, September 15, 2021, 10:54:52 AM PDT, Grzegorz Smoli?ski <g.smolinski1 at gmail.com> wrote:
>
>
> Hi,
>
> Isn?t a bracket missing after gc_label?
>
> So it should be:
>
> > ggplot(s8_plot, aes(fill=GTresult, y=cases, x=gc_label)) +
>
> +? geom_bar(position="stack", stat="identity"))
>
> Best,
>
> Grzegorz
>
> Od: Kai Yang via R-help
> Wys?ano: ?roda, 15 wrze?nia 2021 19:50
> Do: R-help Mailing List
> Temat: [R] ggplot question
>
>
>
> Hello List,
>
> I use ggplot to draw a stack bar chart. but I error message. please
> look it below:
>
>
>
> > ggplot(s8_plot, aes(fill=GTresult, y=cases, x=gc_label) +
>
> +? geom_bar(position="stack", stat="identity"))
>
>
>
> Error: Mapping should be created with `aes()` or `aes_()`.
>
>
>
> GTresult and gc_label are character variables, cases is numeric
> variable. How to fix the problem?
>
> Thank you
>
> Kai
>
>
>
>? ? ? ? ? [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
>
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://stat.ethz.ch/mailman/listinfo/r-help
>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>
> and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep 16 16:59:32 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 16 Sep 2021 07:59:32 -0700
Subject: [R] adding results to plot
In-Reply-To: <CAGxFJbTGckG1xFRDPSc=K1gc7Bah3jycR+A_7TegutH_7UQMQw@mail.gmail.com>
References: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
 <CAGxFJbTGckG1xFRDPSc=K1gc7Bah3jycR+A_7TegutH_7UQMQw@mail.gmail.com>
Message-ID: <CAGxFJbSTA4CLMpCgWBSRRnUSoQg0TQy6pNAzzxvexYRQ7d7tvA@mail.gmail.com>

I was wrong. text() will attempt to coerce to character. This may be
informative:

> as.character(res)
[1] "c(W = 0.992709285275917)"    "0.869917232073854"
[3] "Shapiro-Wilk normality test" "rnorm(100)"

plot(0:1, 0:1); text(0,seq(.1,.9,.2), labels = res, pos = 4)

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 16, 2021 at 7:44 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> res is a list of class "htest" . You can only add text strings  to a
> plot via text(). I don't know what ggplot does.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Sep 16, 2021 at 7:22 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> > Dear all
> >
> > I know I have seen the answer somewhere but I am not able to find it. Please
> > help
> >
> > > plot(1,1)
> > > res <- shapiro.test(rnorm(100))
> > > res
> >
> >         Shapiro-Wilk normality test
> >
> > data:  rnorm(100)
> > W = 0.98861, p-value = 0.5544
> >
> > I would like to add whole res object to the plot.
> >
> > I can do it one by one
> > > text(locator(1), res$method)
> > > text(locator(1), as.character(res$p.value))
> > ...
> > But it is quite inconvenient
> >
> > I could find some way in ggplot world but not in plain plot world.
> >
> > Best regards
> > Petr
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep 16 17:16:04 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 16 Sep 2021 15:16:04 +0000
Subject: [R] adding results to plot
In-Reply-To: <ae0c7c1973a8d03398f5534df6b6ec8abaed3342.camel@utu.fi>
References: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
 <ae0c7c1973a8d03398f5534df6b6ec8abaed3342.camel@utu.fi>
Message-ID: <dfa0ba2c5e5542f5ba608969eecfd91b@SRVEXCHCM1302.precheza.cz>

Thanks, 
I will try to elaborate on it.

Best regards.
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Kimmo Elo
> Sent: Thursday, September 16, 2021 4:45 PM
> To: r-help at r-project.org
> Subject: Re: [R] adding results to plot
> 
> Hi!
> 
> Maybe with this:
> 
> text(x=0.6, y=1.2, paste0(capture.output(res), collapse="\n"), adj=0)
> 
> HTH,
> 
> Kimmo
> 
> to, 2021-09-16 kello 14:12 +0000, PIKAL Petr kirjoitti:
> > 	Virhe vahvistaessa allekirjoitusta: Virhe tulkittaessa Dear all
> >
> > I know I have seen the answer somewhere but I am not able to find it.
> > Please
> > help
> >
> > > plot(1,1)
> > > res <- shapiro.test(rnorm(100))
> > > res
> >
> >         Shapiro-Wilk normality test
> >
> > data:  rnorm(100)
> > W = 0.98861, p-value = 0.5544
> >
> > I would like to add whole res object to the plot.
> >
> > I can do it one by one
> > > text(locator(1), res$method)
> > > text(locator(1), as.character(res$p.value))
> > ...
> > But it is quite inconvenient
> >
> > I could find some way in ggplot world but not in plain plot world.
> >
> > Best regards
> > Petr
> >
> > ------=_NextPart_000_00C9_01D7AB15.A6E04EE0--
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep 16 17:17:15 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 16 Sep 2021 15:17:15 +0000
Subject: [R] adding results to plot
In-Reply-To: <CAGxFJbSTA4CLMpCgWBSRRnUSoQg0TQy6pNAzzxvexYRQ7d7tvA@mail.gmail.com>
References: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
 <CAGxFJbTGckG1xFRDPSc=K1gc7Bah3jycR+A_7TegutH_7UQMQw@mail.gmail.com>
 <CAGxFJbSTA4CLMpCgWBSRRnUSoQg0TQy6pNAzzxvexYRQ7d7tvA@mail.gmail.com>
Message-ID: <5562a820a8fe4cc8a349aca74dcf305c@SRVEXCHCM1302.precheza.cz>

Hallo

Thanks, I will try wat option is better if yours or Kimmo's

Best regards
Petr

> -----Original Message-----
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: Thursday, September 16, 2021 5:00 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] adding results to plot
> 
> I was wrong. text() will attempt to coerce to character. This may be
> informative:
> 
> > as.character(res)
> [1] "c(W = 0.992709285275917)"    "0.869917232073854"
> [3] "Shapiro-Wilk normality test" "rnorm(100)"
> 
> plot(0:1, 0:1); text(0,seq(.1,.9,.2), labels = res, pos = 4)
> 
> Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Thu, Sep 16, 2021 at 7:44 AM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> > res is a list of class "htest" . You can only add text strings  to a
> > plot via text(). I don't know what ggplot does.
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Thu, Sep 16, 2021 at 7:22 AM PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > >
> > > Dear all
> > >
> > > I know I have seen the answer somewhere but I am not able to find
> > > it. Please help
> > >
> > > > plot(1,1)
> > > > res <- shapiro.test(rnorm(100))
> > > > res
> > >
> > >         Shapiro-Wilk normality test
> > >
> > > data:  rnorm(100)
> > > W = 0.98861, p-value = 0.5544
> > >
> > > I would like to add whole res object to the plot.
> > >
> > > I can do it one by one
> > > > text(locator(1), res$method)
> > > > text(locator(1), as.character(res$p.value))
> > > ...
> > > But it is quite inconvenient
> > >
> > > I could find some way in ggplot world but not in plain plot world.
> > >
> > > Best regards
> > > Petr
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.

From d@v|d@@teven@ @end|ng |rom u@u@edu  Thu Sep 16 17:51:23 2021
From: d@v|d@@teven@ @end|ng |rom u@u@edu (David K Stevens)
Date: Thu, 16 Sep 2021 09:51:23 -0600
Subject: [R] [EXT] Re:  adding results to plot
In-Reply-To: <CAGxFJbTGckG1xFRDPSc=K1gc7Bah3jycR+A_7TegutH_7UQMQw@mail.gmail.com>
References: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
 <CAGxFJbTGckG1xFRDPSc=K1gc7Bah3jycR+A_7TegutH_7UQMQw@mail.gmail.com>
Message-ID: <b7291453-b1f0-1ca2-6b54-c9ff9d72c4a6@usu.edu>

This is pretty kludgy but ...

res.p <-capture.output(x.t)
res.pl <- ''
res.nul <- sapply(res.p,function(x.c) res.pl <<- 
paste(res.pl,res.c,sep='\n'))
text(x,y,rel.pl,pos=4,cex=mycex)

This will replicate the print object for the t.test that goes to the 
screen so you can add it to a plot. One note, the output of several 
lines will be left justified at the x-location but centered vertically 
on the y-location. Experimental with the cex setting to fit it on your 
plot. It will also put two blank lines above and one below so you might 
strip those out for better positioning

David Stevens

On 9/16/2021 8:44 AM, Bert Gunter wrote:
> res is a list of class "htest" . You can only add text strings  to a
> plot via text(). I don't know what ggplot does.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Sep 16, 2021 at 7:22 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>> Dear all
>>
>> I know I have seen the answer somewhere but I am not able to find it. Please
>> help
>>
>>> plot(1,1)
>>> res <- shapiro.test(rnorm(100))
>>> res
>>          Shapiro-Wilk normality test
>>
>> data:  rnorm(100)
>> W = 0.98861, p-value = 0.5544
>>
>> I would like to add whole res object to the plot.
>>
>> I can do it one by one
>>> text(locator(1), res$method)
>>> text(locator(1), as.character(res$p.value))
>> ...
>> But it is quite inconvenient
>>
>> I could find some way in ggplot world but not in plain plot world.
>>
>> Best regards
>> Petr
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> CAUTION: This email originated from outside of USU. If this appears to be a USU employee, beware of impersonators. Do not click links, reply, download images, or open attachments unless you verify the sender?s identity and know the content is safe.
>
-- 
David K Stevens, PhD,PE
Professor
Civil and Environmental Engineering
Utah State University
Logan, UT 84322-8200
david.stevens at usu.edu
014357973229


From d@v|d@@teven@ @end|ng |rom u@u@edu  Thu Sep 16 17:57:53 2021
From: d@v|d@@teven@ @end|ng |rom u@u@edu (David K Stevens)
Date: Thu, 16 Sep 2021 09:57:53 -0600
Subject: [R] [EXT] Re:  adding results to plot
In-Reply-To: <CAGxFJbSTA4CLMpCgWBSRRnUSoQg0TQy6pNAzzxvexYRQ7d7tvA@mail.gmail.com>
References: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
 <CAGxFJbTGckG1xFRDPSc=K1gc7Bah3jycR+A_7TegutH_7UQMQw@mail.gmail.com>
 <CAGxFJbSTA4CLMpCgWBSRRnUSoQg0TQy6pNAzzxvexYRQ7d7tvA@mail.gmail.com>
Message-ID: <f8cb3112-44e4-be25-2d7f-e7cc107804e7@usu.edu>

This is pretty kludgy but ...

res.p <- capture.output(res) ? # creates a list of what goes to the screen
res.pl <- '' "?? # initialize res.pl
res.nul <- sapply(res.p,function(x.c) res.pl <<- 
paste(res.pl,res.c,sep='\n'))? # adds the list items separated by a line 
feed
text(x, y, res.pl, pos=4, cex=mycex)

This will replicate the print object for the t.test that goes to the 
screen so you can add it to a plot. One note, the output of several 
lines will be left justified at the x-location but centered vertically 
on the y-location. Experimental with the cex setting to fit it on your 
plot. It will also put two blank lines above and one below so you might 
strip those out for better positioning

Best regards

David Stevens

On 9/16/2021 8:59 AM, Bert Gunter wrote:
> I was wrong. text() will attempt to coerce to character. This may be
> informative:
>
>> as.character(res)
> [1] "c(W = 0.992709285275917)"    "0.869917232073854"
> [3] "Shapiro-Wilk normality test" "rnorm(100)"
>
> plot(0:1, 0:1); text(0,seq(.1,.9,.2), labels = res, pos = 4)
>
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Sep 16, 2021 at 7:44 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> res is a list of class "htest" . You can only add text strings  to a
>> plot via text(). I don't know what ggplot does.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Thu, Sep 16, 2021 at 7:22 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>> Dear all
>>>
>>> I know I have seen the answer somewhere but I am not able to find it. Please
>>> help
>>>
>>>> plot(1,1)
>>>> res <- shapiro.test(rnorm(100))
>>>> res
>>>          Shapiro-Wilk normality test
>>>
>>> data:  rnorm(100)
>>> W = 0.98861, p-value = 0.5544
>>>
>>> I would like to add whole res object to the plot.
>>>
>>> I can do it one by one
>>>> text(locator(1), res$method)
>>>> text(locator(1), as.character(res$p.value))
>>> ...
>>> But it is quite inconvenient
>>>
>>> I could find some way in ggplot world but not in plain plot world.
>>>
>>> Best regards
>>> Petr
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> CAUTION: This email originated from outside of USU. If this appears to be a USU employee, beware of impersonators. Do not click links, reply, download images, or open attachments unless you verify the sender?s identity and know the content is safe.
>
-- 
David K Stevens, PhD,PE
Professor
Civil and Environmental Engineering
Utah State University
Logan, UT 84322-8200
david.stevens at usu.edu
014357973229


From m@rc_grt @end|ng |rom y@hoo@|r  Thu Sep 16 18:05:43 2021
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Thu, 16 Sep 2021 18:05:43 +0200
Subject: [R] Good practice for database with utf-8 string in package
References: <a7ab82d4-054d-616b-ee09-9f19c7edd0b2.ref@yahoo.fr>
Message-ID: <a7ab82d4-054d-616b-ee09-9f19c7edd0b2@yahoo.fr>

Hello everyone,

I am a little bit stucked on the problem to include a database with 
utf-8 string in a package. When I submit it to CRAN, it reports NOTES 
for several Unix system and I try to find a solution (if it exists) to 
not have these NOTES.

The database has references and some names have non ASCII characters.

* First I don't agree at all with the solution proposed here:

https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Encoding-issues

"First, consider carefully if you really need non-ASCIItext."

If a language has non ASCII characters, it is not just to make the 
writting nicer of more complex, it is because it changes the prononciation.

* Then I try to find solution to not have these NOTES.

For example, here is a reference with utf-8 characters

> DatabaseTSD$Reference[211]
[1] Hern?ndez-Montoya, V., P?ez, V.P. & Ceballos, C.P. (2017) Effects of 
temperature on sex determination and embryonic development in the 
red-footed tortoise, Chelonoidis carbonarius. Chelonian Conservation and 
Biology 16, 164-171.

When I convert the characters into unicode, I get indeed only ASCII 
characters. Perfect.

>  iconv(DatabaseTSD$Reference[211], "UTF-8", "ASCII", "Unicode")
[1] "Hern<U+00E1>ndez-Montoya, V., P<U+00E1>ez, V.P. & Ceballos, C.P. 
(2017) Effects of temperature on sex determination and embryonic 
development in the red-footed tortoise, Chelonoidis carbonarius. 
Chelonian Conservation and Biology 16, 164-171."

Then I have no NOTES when I checked the package with database in UNIX... 
but how can I print the reference back with original characters ?

Thanks a lot to point me to best practices to include databases with 
non-ASCII characters and not have NOTES while submitted package to CRAN.

Marc


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep 16 18:17:05 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 16 Sep 2021 09:17:05 -0700
Subject: [R] Good practice for database with utf-8 string in package
In-Reply-To: <a7ab82d4-054d-616b-ee09-9f19c7edd0b2@yahoo.fr>
References: <a7ab82d4-054d-616b-ee09-9f19c7edd0b2.ref@yahoo.fr>
 <a7ab82d4-054d-616b-ee09-9f19c7edd0b2@yahoo.fr>
Message-ID: <CAGxFJbRX5K_7M3uo3K2kfxHUDjXZ3BU6qKeN4RidhGgunFwgug@mail.gmail.com>

This should not be posted here. Post on the R-package-devel list instead.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 16, 2021 at 9:13 AM Marc Girondot via R-help
<r-help at r-project.org> wrote:
>
> Hello everyone,
>
> I am a little bit stucked on the problem to include a database with
> utf-8 string in a package. When I submit it to CRAN, it reports NOTES
> for several Unix system and I try to find a solution (if it exists) to
> not have these NOTES.
>
> The database has references and some names have non ASCII characters.
>
> * First I don't agree at all with the solution proposed here:
>
> https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Encoding-issues
>
> "First, consider carefully if you really need non-ASCIItext."
>
> If a language has non ASCII characters, it is not just to make the
> writting nicer of more complex, it is because it changes the prononciation.
>
> * Then I try to find solution to not have these NOTES.
>
> For example, here is a reference with utf-8 characters
>
> > DatabaseTSD$Reference[211]
> [1] Hern?ndez-Montoya, V., P?ez, V.P. & Ceballos, C.P. (2017) Effects of
> temperature on sex determination and embryonic development in the
> red-footed tortoise, Chelonoidis carbonarius. Chelonian Conservation and
> Biology 16, 164-171.
>
> When I convert the characters into unicode, I get indeed only ASCII
> characters. Perfect.
>
> >  iconv(DatabaseTSD$Reference[211], "UTF-8", "ASCII", "Unicode")
> [1] "Hern<U+00E1>ndez-Montoya, V., P<U+00E1>ez, V.P. & Ceballos, C.P.
> (2017) Effects of temperature on sex determination and embryonic
> development in the red-footed tortoise, Chelonoidis carbonarius.
> Chelonian Conservation and Biology 16, 164-171."
>
> Then I have no NOTES when I checked the package with database in UNIX...
> but how can I print the reference back with original characters ?
>
> Thanks a lot to point me to best practices to include databases with
> non-ASCII characters and not have NOTES while submitted package to CRAN.
>
> Marc
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep 16 18:40:37 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 16 Sep 2021 09:40:37 -0700
Subject: [R] Good practice for database with utf-8 string in package
In-Reply-To: <CAGxFJbRX5K_7M3uo3K2kfxHUDjXZ3BU6qKeN4RidhGgunFwgug@mail.gmail.com>
References: <a7ab82d4-054d-616b-ee09-9f19c7edd0b2.ref@yahoo.fr>
 <a7ab82d4-054d-616b-ee09-9f19c7edd0b2@yahoo.fr>
 <CAGxFJbRX5K_7M3uo3K2kfxHUDjXZ3BU6qKeN4RidhGgunFwgug@mail.gmail.com>
Message-ID: <01CB21DC-0199-48AD-B306-6B9E406940BF@dcn.davis.ca.us>

Agree with Bert per your stated problem, but want to point out that you don't have control over the locale in which your users will be trying to display the encoded strings in your data. I am no expert in this, but you will need to become one in order to understand your own problem and any solutions you are given in r-package-devel. You will likely benefit from reading Kevin Ushey's writeup: https://kevinushey.github.io/blog/2018/02/21/string-encoding-and-r/

On September 16, 2021 9:17:05 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>This should not be posted here. Post on the R-package-devel list instead.
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Thu, Sep 16, 2021 at 9:13 AM Marc Girondot via R-help
><r-help at r-project.org> wrote:
>>
>> Hello everyone,
>>
>> I am a little bit stucked on the problem to include a database with
>> utf-8 string in a package. When I submit it to CRAN, it reports NOTES
>> for several Unix system and I try to find a solution (if it exists) to
>> not have these NOTES.
>>
>> The database has references and some names have non ASCII characters.
>>
>> * First I don't agree at all with the solution proposed here:
>>
>> https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Encoding-issues
>>
>> "First, consider carefully if you really need non-ASCIItext."
>>
>> If a language has non ASCII characters, it is not just to make the
>> writting nicer of more complex, it is because it changes the prononciation.
>>
>> * Then I try to find solution to not have these NOTES.
>>
>> For example, here is a reference with utf-8 characters
>>
>> > DatabaseTSD$Reference[211]
>> [1] Hern?ndez-Montoya, V., P?ez, V.P. & Ceballos, C.P. (2017) Effects of
>> temperature on sex determination and embryonic development in the
>> red-footed tortoise, Chelonoidis carbonarius. Chelonian Conservation and
>> Biology 16, 164-171.
>>
>> When I convert the characters into unicode, I get indeed only ASCII
>> characters. Perfect.
>>
>> >  iconv(DatabaseTSD$Reference[211], "UTF-8", "ASCII", "Unicode")
>> [1] "Hern<U+00E1>ndez-Montoya, V., P<U+00E1>ez, V.P. & Ceballos, C.P.
>> (2017) Effects of temperature on sex determination and embryonic
>> development in the red-footed tortoise, Chelonoidis carbonarius.
>> Chelonian Conservation and Biology 16, 164-171."
>>
>> Then I have no NOTES when I checked the package with database in UNIX...
>> but how can I print the reference back with original characters ?
>>
>> Thanks a lot to point me to best practices to include databases with
>> non-ASCII characters and not have NOTES while submitted package to CRAN.
>>
>> Marc
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep 16 19:37:46 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 16 Sep 2021 18:37:46 +0100
Subject: [R] unable to remove NAs from a data frame
In-Reply-To: <CAF9-5jMgcj+W4zUN52s3HUrK+qS2=dSOMkYCngrRspvH9=QKTQ@mail.gmail.com>
References: <CAF9-5jMgcj+W4zUN52s3HUrK+qS2=dSOMkYCngrRspvH9=QKTQ@mail.gmail.com>
Message-ID: <e7ad850b-45b9-4660-491b-d6b96c76c177@sapo.pt>

Hello,

You are trying to access elements that do not exist, see the example below:


x <- 1:3
x[5]      # beyond the last element
#[1] NA

dim(df)
#[1] 14509225        8

df[14509227,] # beyond nrow(df) by 2


Hope this helps,

Rui Barradas


?s 15:12 de 16/09/21, Ana Marija escreveu:
> Hi All,
> 
> I have lines in file that look like this:
> 
>> df[14509227,]
>      SNP   A1   A2 freq  b se  p  N
> 1: <NA> <NA> <NA>   NA NA NA NA NA
> 
> data looks like this:
>> head(df)
>             SNP A1 A2      freq       b     se      p      N
> 1:  rs74337086  G  A 0.0024460  0.1627 0.1231 0.1865 218792
> 2:  rs76388980  G  A 0.0034150  0.1451 0.1047 0.1660 218792
> ...
>> sapply(df,class)
>          SNP          A1          A2        freq           b          se
> "character" "character" "character"   "numeric"   "numeric"   "numeric"
>            p           N
>    "numeric"   "integer"
> 
>> dim(df)
> [1] 14509225        8
> 
> Tried:
>> df=na.omit(df)
>> dim(df)
> [1] 14509225        8
> 
> and:
>> library(tidyr)
>> d=df %>% drop_na()
>> dim(d)
> [1] 14509225        8
> 
> 
> Please advise,
> 
> Thanks
> Ana
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Sep 16 19:39:53 2021
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 16 Sep 2021 12:39:53 -0500
Subject: [R] unable to remove NAs from a data frame
In-Reply-To: <e7ad850b-45b9-4660-491b-d6b96c76c177@sapo.pt>
References: <CAF9-5jMgcj+W4zUN52s3HUrK+qS2=dSOMkYCngrRspvH9=QKTQ@mail.gmail.com>
 <e7ad850b-45b9-4660-491b-d6b96c76c177@sapo.pt>
Message-ID: <CAF9-5jOtG+U+p7zHcS6k4vQP96BAwXak_5ZjtiXQ3hw-P8LUBw@mail.gmail.com>

Completely true. Thank you for your help

On Thu, Sep 16, 2021 at 12:37 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> You are trying to access elements that do not exist, see the example below:
>
>
> x <- 1:3
> x[5]      # beyond the last element
> #[1] NA
>
> dim(df)
> #[1] 14509225        8
>
> df[14509227,] # beyond nrow(df) by 2
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 15:12 de 16/09/21, Ana Marija escreveu:
> > Hi All,
> >
> > I have lines in file that look like this:
> >
> >> df[14509227,]
> >      SNP   A1   A2 freq  b se  p  N
> > 1: <NA> <NA> <NA>   NA NA NA NA NA
> >
> > data looks like this:
> >> head(df)
> >             SNP A1 A2      freq       b     se      p      N
> > 1:  rs74337086  G  A 0.0024460  0.1627 0.1231 0.1865 218792
> > 2:  rs76388980  G  A 0.0034150  0.1451 0.1047 0.1660 218792
> > ...
> >> sapply(df,class)
> >          SNP          A1          A2        freq           b          se
> > "character" "character" "character"   "numeric"   "numeric"   "numeric"
> >            p           N
> >    "numeric"   "integer"
> >
> >> dim(df)
> > [1] 14509225        8
> >
> > Tried:
> >> df=na.omit(df)
> >> dim(df)
> > [1] 14509225        8
> >
> > and:
> >> library(tidyr)
> >> d=df %>% drop_na()
> >> dim(d)
> > [1] 14509225        8
> >
> >
> > Please advise,
> >
> > Thanks
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From y@ngk@|9999 @end|ng |rom y@hoo@com  Thu Sep 16 19:58:15 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Thu, 16 Sep 2021 17:58:15 +0000 (UTC)
Subject: [R] order stacked bar plot from total frequency
References: <2037997804.528646.1631815095291.ref@mail.yahoo.com>
Message-ID: <2037997804.528646.1631815095291@mail.yahoo.com>

Hello List,
I can order the general bar chart based on frequency, using ggplot2 with the code :?aes((reorder(Var1, Freq)),?Freq))?
I don't know how to?order stacked bar plot by total frequency
Can you give me some of example?
Thank you
Kai

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 16 23:33:32 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 17 Sep 2021 07:33:32 +1000
Subject: [R] order stacked bar plot from total frequency
In-Reply-To: <2037997804.528646.1631815095291@mail.yahoo.com>
References: <2037997804.528646.1631815095291.ref@mail.yahoo.com>
 <2037997804.528646.1631815095291@mail.yahoo.com>
Message-ID: <CA+8X3fVBByLctCJfwNdbF=1zX7aCM-Q4awJXPUNo-CSQyr722g@mail.gmail.com>

Hi Kai,
I don't know about ggplot, but it may be easier to do it before plotting:

set.seed(753)
testdat<-matrix(sample(1:10,9),nrow=3)
# first plot the raw matrix
barplot(testdat)
# then plot the matrix ordered by column sums
barplot(testdat[,order(colSums(testdat))])

Jim

On Fri, Sep 17, 2021 at 4:01 AM Kai Yang via R-help
<r-help at r-project.org> wrote:
>
> Hello List,
> I can order the general bar chart based on frequency, using ggplot2 with the code : aes((reorder(Var1, Freq)), Freq))
> I don't know how to order stacked bar plot by total frequency
> Can you give me some of example?
> Thank you
> Kai
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ycd|ng @end|ng |rom coh@org  Fri Sep 17 00:40:50 2021
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Thu, 16 Sep 2021 22:40:50 +0000
Subject: [R] boxplots and dotplots by color group 1 and shape group2
Message-ID: <SJ0PR02MB764590391FFFF538441C6043D4DC9@SJ0PR02MB7645.namprd02.prod.outlook.com>

Dear R users,

I generated a boxplots in combination of dotplots using the R code below for the attached test file.
boxplot(value~score, data = test, outpch = NA, xlab="",ylab="",xaxt='n',
        cex.lab=1.2, cex.axis=1.2, main="Correlation of SCNV score and SCNV value ")
mtext(side=2, "SCNV value", line=2.3, cex = 1.3 )
stripchart(value~score, data = test,
           vertical = TRUE, method = "jitter",
           pch = 16, col = c("green", "brown4","black", "red"),
           add = TRUE)

now I hope to add a second group variable purity_cat in the test file, labeling it by four different shape, pch=c(3,4,16,8).

Is it possible to do add the second group variable?

Thank you,

Ding

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
------------------------------------------------------------

From drj|m|emon @end|ng |rom gm@||@com  Fri Sep 17 02:31:27 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 17 Sep 2021 10:31:27 +1000
Subject: [R] adding results to plot
In-Reply-To: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
References: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
Message-ID: <CA+8X3fX38T3HQLwmQd7quvhfSKraHcLucV68Sc11jjVPPnQrRg@mail.gmail.com>

Hi Petr,
The hard part is the names for the data frame that addtable2plot requires:

set.seed(753)
res <- shapiro.test(rnorm(100))
library(plotrix)
plot(0,0,type="n",axes=FALSE)
addtable2plot(0,0,data.frame(element=names(res)[1:2],
  value=round(as.numeric(res[1:2]),3)),xjust=0.5,
  title=res$method)

There is probably a way to get blank names with data.frame(), but I gave up.

Jim

On Fri, Sep 17, 2021 at 12:22 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Dear all
>
> I know I have seen the answer somewhere but I am not able to find it. Please
> help
>
> > plot(1,1)
> > res <- shapiro.test(rnorm(100))
> > res
>
>         Shapiro-Wilk normality test
>
> data:  rnorm(100)
> W = 0.98861, p-value = 0.5544
>
> I would like to add whole res object to the plot.
>
> I can do it one by one
> > text(locator(1), res$method)
> > text(locator(1), as.character(res$p.value))
> ...
> But it is quite inconvenient
>
> I could find some way in ggplot world but not in plain plot world.
>
> Best regards
> Petr
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @gent@ @end|ng |rom medd@t@|nc@com  Fri Sep 17 02:50:20 2021
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Thu, 16 Sep 2021 20:50:20 -0400
Subject: [R] Problem with plotmat package
In-Reply-To: <CA+8X3fW4brPdznLbM+MFBju2znSFJ-4Ag1uzAkUsVsRiv7Ov+A@mail.gmail.com>
References: <ca81fc55-3dc0-0f91-75f5-315c74cb2bf4@meddatainc.com>
 <CA+8X3fUXk4XseYENCEnEKx=yFmNyTGJnafbO0fZ=qsNkrUEwTA@mail.gmail.com>
 <CA+8X3fW4brPdznLbM+MFBju2znSFJ-4Ag1uzAkUsVsRiv7Ov+A@mail.gmail.com>
Message-ID: <d6445d52-a660-39ff-cdb9-8b41a87d027c@meddatainc.com>

On 09/15/2021 09:40 PM, Jim Lemon wrote:
> Oops, your plot
>
> On Thu, Sep 16, 2021 at 11:39 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>> Hi H,
>> Looking at your example and the help page, it looks to me as though
>> the plot is consistent with the "A" matrix:
>>
>>  Oz
>>     Rain Nice
>> Rain 0.25 0.75
>> Nice 0.60 0.40
>>
>> # help page
>> A  - square coefficient matrix, specifying the links (rows=to, cols=from).
>>
>> In your plot (attached):
>> Rain (col) goes to Rain (row) 0.25
>> Rain (col) goes to Nice (row) 0.6
>> Nice (col) goes to Nice (row) 0.4
>> Nice (col) goes to Rain (row) 0.75
>>
>> This is a bit confusing, but it seems to do what it says it does.
>>
>> Jim
>>
>> On Thu, Sep 16, 2021 at 10:40 AM H <agents at meddatainc.com> wrote:
>>> I am using plotmat 1.6.5 (part of the diagram package) in R 3.6 to plot Markov transition charts but have run into an issue that I was hoping someone could shed light on here. I did e-mail the maintainer over a month ago but have not received a reply.
>>>
>>> The issue is that the directional arrows point in the wrong direction. A brief example:
>>>
>>> stateNames <- c("Rain", "Nice")
>>> Oz <- matrix(c(0.25, 0.75, 0.6, 0.4), nrow = 2, byrow = TRUE)
>>> rownames(Oz) <- stateNames; colnames(Oz) <- stateNames
>>> plotmat(Oz, pos = c(1, 1), lwd = 1, box.lwd = 2, cex.txt = 0.8, box.size = 0.1, box.type = "circle", box.prop = 0.5, box.col = "light yellow", arr.length = 0.2, arr.width = 0.2, self.cex = 0.4, self.shifty = 0.01, self.shiftx = 0.13, main = "")
>>>
>>> In the above example both arrows seem to point in the direction opposite to what I expect. Has anyone encountered this and know how to fix it?
>>>
>>> Thanks.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

I am sorry but I think you have it wrong. A transition probability matrix for the rain/nice scenario would be written:

Rain, Nice

Rain |0.25, 0.75|

Nice |0.60, 0.40|

If you sum the transition probabilities for rain or nice, they should each add to 1. Logic dictates if the only two states are rain and nice, and rain continues the next day with a probability of 0.25, nice must have a probability of 0.75. Likewise, the sum of probabilities for nice weather to change to rain, 0.6, and remain the same, 0.4 must add up to 1.

I find that the arrow directions are the opposite of what I expect.


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep 17 03:00:03 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 17 Sep 2021 11:00:03 +1000
Subject: [R] Problem with plotmat package
In-Reply-To: <d6445d52-a660-39ff-cdb9-8b41a87d027c@meddatainc.com>
References: <ca81fc55-3dc0-0f91-75f5-315c74cb2bf4@meddatainc.com>
 <CA+8X3fUXk4XseYENCEnEKx=yFmNyTGJnafbO0fZ=qsNkrUEwTA@mail.gmail.com>
 <CA+8X3fW4brPdznLbM+MFBju2znSFJ-4Ag1uzAkUsVsRiv7Ov+A@mail.gmail.com>
 <d6445d52-a660-39ff-cdb9-8b41a87d027c@meddatainc.com>
Message-ID: <CA+8X3fXi1pdyBR9T7yFWGdNSeuYpkS0mWGAisr7rvK4uaVKFOA@mail.gmail.com>

Okay, that was just my reading of the help page. I hope that I haven't
added to the confusion.

Jim

On Fri, Sep 17, 2021 at 10:50 AM H <agents at meddatainc.com> wrote:
>
> On 09/15/2021 09:40 PM, Jim Lemon wrote:
> > Oops, your plot
> >
> > On Thu, Sep 16, 2021 at 11:39 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >> Hi H,
> >> Looking at your example and the help page, it looks to me as though
> >> the plot is consistent with the "A" matrix:
> >>
> >>  Oz
> >>     Rain Nice
> >> Rain 0.25 0.75
> >> Nice 0.60 0.40
> >>
> >> # help page
> >> A  - square coefficient matrix, specifying the links (rows=to, cols=from).
> >>
> >> In your plot (attached):
> >> Rain (col) goes to Rain (row) 0.25
> >> Rain (col) goes to Nice (row) 0.6
> >> Nice (col) goes to Nice (row) 0.4
> >> Nice (col) goes to Rain (row) 0.75
> >>
> >> This is a bit confusing, but it seems to do what it says it does.
> >>
> >> Jim
> >>
> >> On Thu, Sep 16, 2021 at 10:40 AM H <agents at meddatainc.com> wrote:
> >>> I am using plotmat 1.6.5 (part of the diagram package) in R 3.6 to plot Markov transition charts but have run into an issue that I was hoping someone could shed light on here. I did e-mail the maintainer over a month ago but have not received a reply.
> >>>
> >>> The issue is that the directional arrows point in the wrong direction. A brief example:
> >>>
> >>> stateNames <- c("Rain", "Nice")
> >>> Oz <- matrix(c(0.25, 0.75, 0.6, 0.4), nrow = 2, byrow = TRUE)
> >>> rownames(Oz) <- stateNames; colnames(Oz) <- stateNames
> >>> plotmat(Oz, pos = c(1, 1), lwd = 1, box.lwd = 2, cex.txt = 0.8, box.size = 0.1, box.type = "circle", box.prop = 0.5, box.col = "light yellow", arr.length = 0.2, arr.width = 0.2, self.cex = 0.4, self.shifty = 0.01, self.shiftx = 0.13, main = "")
> >>>
> >>> In the above example both arrows seem to point in the direction opposite to what I expect. Has anyone encountered this and know how to fix it?
> >>>
> >>> Thanks.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
>
> I am sorry but I think you have it wrong. A transition probability matrix for the rain/nice scenario would be written:
>
> Rain, Nice
>
> Rain |0.25, 0.75|
>
> Nice |0.60, 0.40|
>
> If you sum the transition probabilities for rain or nice, they should each add to 1. Logic dictates if the only two states are rain and nice, and rain continues the next day with a probability of 0.25, nice must have a probability of 0.75. Likewise, the sum of probabilities for nice weather to change to rain, 0.6, and remain the same, 0.4 must add up to 1.
>
> I find that the arrow directions are the opposite of what I expect.
>


From @gent@ @end|ng |rom medd@t@|nc@com  Fri Sep 17 03:26:51 2021
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Thu, 16 Sep 2021 21:26:51 -0400
Subject: [R] Problem with plotmat package
In-Reply-To: <CA+8X3fXi1pdyBR9T7yFWGdNSeuYpkS0mWGAisr7rvK4uaVKFOA@mail.gmail.com>
References: <ca81fc55-3dc0-0f91-75f5-315c74cb2bf4@meddatainc.com>
 <CA+8X3fUXk4XseYENCEnEKx=yFmNyTGJnafbO0fZ=qsNkrUEwTA@mail.gmail.com>
 <CA+8X3fW4brPdznLbM+MFBju2znSFJ-4Ag1uzAkUsVsRiv7Ov+A@mail.gmail.com>
 <d6445d52-a660-39ff-cdb9-8b41a87d027c@meddatainc.com>
 <CA+8X3fXi1pdyBR9T7yFWGdNSeuYpkS0mWGAisr7rvK4uaVKFOA@mail.gmail.com>
Message-ID: <ddd88f73-9ee7-0863-77ff-1c0e9e4b6e13@meddatainc.com>

On 09/16/2021 09:00 PM, Jim Lemon wrote:
> Okay, that was just my reading of the help page. I hope that I haven't
> added to the confusion.
>
> Jim
>
> On Fri, Sep 17, 2021 at 10:50 AM H <agents at meddatainc.com> wrote:
>> On 09/15/2021 09:40 PM, Jim Lemon wrote:
>>> Oops, your plot
>>>
>>> On Thu, Sep 16, 2021 at 11:39 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>>> Hi H,
>>>> Looking at your example and the help page, it looks to me as though
>>>> the plot is consistent with the "A" matrix:
>>>>
>>>>  Oz
>>>>     Rain Nice
>>>> Rain 0.25 0.75
>>>> Nice 0.60 0.40
>>>>
>>>> # help page
>>>> A  - square coefficient matrix, specifying the links (rows=to, cols=from).
>>>>
>>>> In your plot (attached):
>>>> Rain (col) goes to Rain (row) 0.25
>>>> Rain (col) goes to Nice (row) 0.6
>>>> Nice (col) goes to Nice (row) 0.4
>>>> Nice (col) goes to Rain (row) 0.75
>>>>
>>>> This is a bit confusing, but it seems to do what it says it does.
>>>>
>>>> Jim
>>>>
>>>> On Thu, Sep 16, 2021 at 10:40 AM H <agents at meddatainc.com> wrote:
>>>>> I am using plotmat 1.6.5 (part of the diagram package) in R 3.6 to plot Markov transition charts but have run into an issue that I was hoping someone could shed light on here. I did e-mail the maintainer over a month ago but have not received a reply.
>>>>>
>>>>> The issue is that the directional arrows point in the wrong direction. A brief example:
>>>>>
>>>>> stateNames <- c("Rain", "Nice")
>>>>> Oz <- matrix(c(0.25, 0.75, 0.6, 0.4), nrow = 2, byrow = TRUE)
>>>>> rownames(Oz) <- stateNames; colnames(Oz) <- stateNames
>>>>> plotmat(Oz, pos = c(1, 1), lwd = 1, box.lwd = 2, cex.txt = 0.8, box.size = 0.1, box.type = "circle", box.prop = 0.5, box.col = "light yellow", arr.length = 0.2, arr.width = 0.2, self.cex = 0.4, self.shifty = 0.01, self.shiftx = 0.13, main = "")
>>>>>
>>>>> In the above example both arrows seem to point in the direction opposite to what I expect. Has anyone encountered this and know how to fix it?
>>>>>
>>>>> Thanks.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>> I am sorry but I think you have it wrong. A transition probability matrix for the rain/nice scenario would be written:
>>
>> Rain, Nice
>>
>> Rain |0.25, 0.75|
>>
>> Nice |0.60, 0.40|
>>
>> If you sum the transition probabilities for rain or nice, they should each add to 1. Logic dictates if the only two states are rain and nice, and rain continues the next day with a probability of 0.25, nice must have a probability of 0.75. Likewise, the sum of probabilities for nice weather to change to rain, 0.6, and remain the same, 0.4 must add up to 1.
>>
>> I find that the arrow directions are the opposite of what I expect.
>>
I just realized you did identify what the problem was, it was not the arrow direction but that the matrix needed to be transposed before used in plotmat. I am used to transition probability matrices read row-wise where each row adds up to 1. Plotmat expects the transition matrix to be read column-wise where each column adds up to 1.

Transposing the original matrix using t() before using it in plotmat() also resolved my own example which is considerably more complex.

Thank you for your help!


From @gent@ @end|ng |rom medd@t@|nc@com  Fri Sep 17 03:31:43 2021
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Thu, 16 Sep 2021 21:31:43 -0400
Subject: [R] Problem with plotmat package
In-Reply-To: <ddd88f73-9ee7-0863-77ff-1c0e9e4b6e13@meddatainc.com>
References: <ca81fc55-3dc0-0f91-75f5-315c74cb2bf4@meddatainc.com>
 <CA+8X3fUXk4XseYENCEnEKx=yFmNyTGJnafbO0fZ=qsNkrUEwTA@mail.gmail.com>
 <CA+8X3fW4brPdznLbM+MFBju2znSFJ-4Ag1uzAkUsVsRiv7Ov+A@mail.gmail.com>
 <d6445d52-a660-39ff-cdb9-8b41a87d027c@meddatainc.com>
 <CA+8X3fXi1pdyBR9T7yFWGdNSeuYpkS0mWGAisr7rvK4uaVKFOA@mail.gmail.com>
 <ddd88f73-9ee7-0863-77ff-1c0e9e4b6e13@meddatainc.com>
Message-ID: <ab754b79-e49b-d444-5ebe-f640401c191c@meddatainc.com>

On 09/16/2021 09:26 PM, H wrote:
> On 09/16/2021 09:00 PM, Jim Lemon wrote:
>> Okay, that was just my reading of the help page. I hope that I haven't
>> added to the confusion.
>>
>> Jim
>>
>> On Fri, Sep 17, 2021 at 10:50 AM H <agents at meddatainc.com> wrote:
>>> On 09/15/2021 09:40 PM, Jim Lemon wrote:
>>>> Oops, your plot
>>>>
>>>> On Thu, Sep 16, 2021 at 11:39 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>>>> Hi H,
>>>>> Looking at your example and the help page, it looks to me as though
>>>>> the plot is consistent with the "A" matrix:
>>>>>
>>>>>  Oz
>>>>>     Rain Nice
>>>>> Rain 0.25 0.75
>>>>> Nice 0.60 0.40
>>>>>
>>>>> # help page
>>>>> A  - square coefficient matrix, specifying the links (rows=to, cols=from).
>>>>>
>>>>> In your plot (attached):
>>>>> Rain (col) goes to Rain (row) 0.25
>>>>> Rain (col) goes to Nice (row) 0.6
>>>>> Nice (col) goes to Nice (row) 0.4
>>>>> Nice (col) goes to Rain (row) 0.75
>>>>>
>>>>> This is a bit confusing, but it seems to do what it says it does.
>>>>>
>>>>> Jim
>>>>>
>>>>> On Thu, Sep 16, 2021 at 10:40 AM H <agents at meddatainc.com> wrote:
>>>>>> I am using plotmat 1.6.5 (part of the diagram package) in R 3.6 to plot Markov transition charts but have run into an issue that I was hoping someone could shed light on here. I did e-mail the maintainer over a month ago but have not received a reply.
>>>>>>
>>>>>> The issue is that the directional arrows point in the wrong direction. A brief example:
>>>>>>
>>>>>> stateNames <- c("Rain", "Nice")
>>>>>> Oz <- matrix(c(0.25, 0.75, 0.6, 0.4), nrow = 2, byrow = TRUE)
>>>>>> rownames(Oz) <- stateNames; colnames(Oz) <- stateNames
>>>>>> plotmat(Oz, pos = c(1, 1), lwd = 1, box.lwd = 2, cex.txt = 0.8, box.size = 0.1, box.type = "circle", box.prop = 0.5, box.col = "light yellow", arr.length = 0.2, arr.width = 0.2, self.cex = 0.4, self.shifty = 0.01, self.shiftx = 0.13, main = "")
>>>>>>
>>>>>> In the above example both arrows seem to point in the direction opposite to what I expect. Has anyone encountered this and know how to fix it?
>>>>>>
>>>>>> Thanks.
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> I am sorry but I think you have it wrong. A transition probability matrix for the rain/nice scenario would be written:
>>>
>>> Rain, Nice
>>>
>>> Rain |0.25, 0.75|
>>>
>>> Nice |0.60, 0.40|
>>>
>>> If you sum the transition probabilities for rain or nice, they should each add to 1. Logic dictates if the only two states are rain and nice, and rain continues the next day with a probability of 0.25, nice must have a probability of 0.75. Likewise, the sum of probabilities for nice weather to change to rain, 0.6, and remain the same, 0.4 must add up to 1.
>>>
>>> I find that the arrow directions are the opposite of what I expect.
>>>
> I just realized you did identify what the problem was, it was not the arrow direction but that the matrix needed to be transposed before used in plotmat. I am used to transition probability matrices read row-wise where each row adds up to 1. Plotmat expects the transition matrix to be read column-wise where each column adds up to 1.
>
> Transposing the original matrix using t() before using it in plotmat() also resolved my own example which is considerably more complex.
>
> Thank you for your help!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Perhaps someone knows if it is possible to position the state boxes more flexibly in plotmat()?

I have eight states I plot in four rows of 1-3-3-1 because it makes logical sense to group them this way row-wise. There are transitions between some of the states and the default positioning of the states, the transition arrows and associated transition probabilities makes for not-so-clear figure...


From @kw@|mmo @end|ng |rom gm@||@com  Fri Sep 17 04:09:12 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 16 Sep 2021 22:09:12 -0400
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <b406b3e1-28ff-d974-3a26-3c4f8003b672@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
 <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
 <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
 <250d355b-072e-67cb-8bd5-bb012aed20a2@syonic.eu>
 <CAPcHnpSR=ZtCk=bX=NkFWO8wNc4hks07x+eGJU+Z4QA0+cJcjg@mail.gmail.com>
 <12584b25-8150-4002-4eee-b4bc21525996@syonic.eu>
 <CAPcHnpRMj=mDqhZ7C-+VvYCj9r0trS=3iOuu4NsouCG8xB2Dtw@mail.gmail.com>
 <b406b3e1-28ff-d974-3a26-3c4f8003b672@syonic.eu>
Message-ID: <CAPcHnpRTDxHLXMGAM-aKKypckypcs-LOGCvQ5Q4CcRZP_tKH5A@mail.gmail.com>

In your case, yes, there is a negative impact to formatting the code like:

x <- `padding<-`(right(x), ...)

and it comes from using 'substitute' without specifying an environment / /
list. It's my biggest problem with the tidyverse packages, the use of
non-standard evaluation. 'substitute' was originally created for simple
things like getting informative labels for data sets and plots, as well as
for 'delayedAssign'. For example, you could write your function to use the
above standard syntax, something like:

`padding<-` <- function (x, ..., value)
{
    sx <- substitute(x)
    choices <- c("bottom", "left", "top", "right")
    if (!is.call(sx) || !is.symbol(sx[[1L]]) ||
        !(k <- match(as.character(sx[[1L]]), choices, nomatch = 0L)))
        stop(gettextf("invalid 'x', must be a call to %s",
            paste(sQuote(choices), collapse = ", ")))
    choice <- choices[[k]]
    if (length(sx) != 2L)
        stop(gettextf("invalid 'x', %d arguments passed to '%s' which
requires 1",
            length(sx) - 1L, choice))
    x <- eval(sx[[2L]], parent.frame())
    # do whatever else with x, choice, ..., value
}

but given that you cannot use it like

padding(right(x)) <- 5

I can't say that I recommend it. Additionally, even if you define
`padding<-` like this, because of the non-standard evaluation from
'substitute', it means you CAN'T make a wrapper function for `padding<-`:

wrapper <- function (x, ..., value)
{
    # not sure exactly what this wrapper should do,
    # we'll add another element to 'value'
    `padding<-`(x = x, ..., value = c(list(value), "test"))
}

this won't work for a case like:

wrapper(right(letters))

because now, when you do 'substitute', it will give you the literal symbol
'x', not really what you wanted, because of the non-standard evaluation. Of
course, do whatever you want to make the syntax look the way you want, but
I think you're going about this the wrong way. I think the 'which' argument
I previously suggested will serve you far better. I hope this helps.

On Wed, Sep 15, 2021 at 2:26 AM Leonard Mada <leo.mada at syonic.eu> wrote:

> Hello Andrew,
>
>
> On 9/15/2021 6:53 AM, Andrew Simmons wrote:
>
> names(x) <- c("some names")
>
> if different from
>
> `names<-`(x, value = c("some names"))
>
> because the second piece of code does not ever call `<-`. The first piece
> of code is (approximately) equivalent to
>
> `*tmp*` <- x
> `*tmp*` <- `names<-`(`*tmp*`, value = c("some names"))
> x <- `*tmp*`
>
>
> This is my question:
>
> Would there be any negative impact if the code is changed to:
>
> x <- 'names<-'(x, value=...);
>
> The "x" will be evaluated inside 'names<-' and this function outputs &
> assigns "x". The "creation" of "x" in the current environment is done only
> after the call to 'names<-' (if it did not exist before).
>
>
> Leonard
>
>
>
> Another example,
>
> y <- `names<-`(x, value = c("some names"))
>
> now y will be equivalent to x if we did
>
> names(x) <- c("some names")
>
> except that the first will not update x, it will still have its old names.
>
> On Mon, Sep 13, 2021 at 4:33 PM Leonard Mada <leo.mada at syonic.eu> wrote:
>
>>
>> On 9/13/2021 11:28 PM, Andrew Simmons wrote:
>>
>> In the example you gave : r(x) <- 1
>> r(x) is never evaluated, the above calls `r<-`,
>> in fact r does not even have to be an existing function.
>>
>>
>> I meant:
>>
>> '*tmp*' <- x; # "x" is evaluated here;
>>
>> 'r<-' is called after this step, which makes sense in the case of
>> subsetting;
>>
>>
>> But I am wondering if changing this behaviour, when NO subsetting is
>> performed, would have any impact.
>>
>> e.g. names(x) = c("some names");
>>
>> # would it have any impact to skip the evaluation of "x" and call
>> directly:
>>
>> 'names<-'(x, value);
>>
>>
>> Leonard
>>
>>
>>
>> On Mon, Sep 13, 2021, 16:18 Leonard Mada <leo.mada at syonic.eu> wrote:
>>
>>> Hello,
>>>
>>>
>>> I have found the evaluation: it is described in the section on
>>> subsetting. The forced evaluation makes sense for subsetting.
>>>
>>>
>>> On 9/13/2021 9:42 PM, Leonard Mada wrote:
>>>
>>> Hello Andrew,
>>>
>>>
>>> I try now to understand the evaluation of the expression:
>>>
>>> e = expression(r(x) <- 1)
>>>
>>> # parameter named "value" seems to be required;
>>> 'r<-' = function(x, value) {print("R");}
>>> eval(e, list(x=2))
>>> # [1] "R"
>>>
>>> # both versions work
>>> 'r<-' = function(value, x) {print("R");}
>>> eval(e, list(x=2))
>>> # [1] "R"
>>>
>>>
>>> ### the Expression
>>> e[[1]][[1]] # "<-", not "r<-"
>>> e[[1]][[2]] # "r(x)"
>>>
>>>
>>> The evaluation of "e" somehow calls "r<-", but evaluates also the
>>> argument of r(...). I am still investigating what is actually happening.
>>>
>>>
>>> The forced evaluation is relevant for subsetting, e.g.:
>>> expression(r(x)[3] <- 1)
>>> expression(r(x)[3] <- 1)[[1]][[2]]
>>> # r(x)[3] # the evaluation details are NOT visible in the expression per
>>> se;
>>> # Note: indeed, it makes sens to first evaluate r(x) and then to perform
>>> the subsetting;
>>>
>>>
>>> However, in the case of a non-subsetted expression:
>>> r(x) <- 1;
>>> It would make sense to evaluate lazily r(x) if no subsetting is involved
>>> (more precisely "r<-"(x, value) ).
>>>
>>> Would this have any impact on the current code?
>>>
>>>
>>> Sincerely,
>>>
>>>
>>> Leonard
>>>
>>>
>>>
>>> Sincerely,
>>>
>>>
>>> Leonard
>>>
>>>
>>> On 9/13/2021 9:15 PM, Andrew Simmons wrote:
>>>
>>> R's parser doesn't work the way you're expecting it to. When doing an
>>> assignment like:
>>>
>>>
>>> padding(right(df)) <- 1
>>>
>>>
>>> it is broken into small stages. The guide "R Language Definition" claims
>>> that the above would be equivalent to:
>>>
>>>
>>> `<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))
>>>
>>>
>>> but that is not correct, and you can tell by using `substitute` as you
>>> were above. There isn't a way to do what you want with the syntax you
>>> provided, you'll have to do something different. You could add a `which`
>>> argument to each style function, and maybe put the code for `match.arg` in
>>> a separate function:
>>>
>>>
>>> match.which <- function (which)
>>> match.arg(which, c("bottom", "left", "top", "right"), several.ok = TRUE)
>>>
>>>
>>> padding <- function (x, which)
>>> {
>>>     which <- match.which(which)
>>>     # more code
>>> }
>>>
>>>
>>> border <- function (x, which)
>>> {
>>>     which <- match.which(which)
>>>     # more code
>>> }
>>>
>>>
>>> some_other_style <- function (x, which)
>>> {
>>>     which <- match.which(which)
>>>     # more code
>>> }
>>>
>>>
>>> I hope this helps.
>>>
>>> On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada <leo.mada at syonic.eu>
>>> wrote:
>>>
>>>> Hello Andrew,
>>>>
>>>>
>>>> this could work. I will think about it.
>>>>
>>>> But I was thinking more generically. Suppose we have a series of
>>>> functions:
>>>> padding(), border(), some_other_style();
>>>> Each of these functions has the parameter "right" (or the group of
>>>> parameters c("right", ...)).
>>>>
>>>>
>>>> Then I could design a function right(FUN) that assigns the value to
>>>> this parameter and evaluates the function FUN().
>>>>
>>>>
>>>> There are a few ways to do this:
>>>> 1.) Other parameters as ...
>>>> right(FUN, value, ...) = value; and then pass "..." to FUN.
>>>> right(value, FUN, ...) = value; # or is this the syntax? (TODO: explore)
>>>>
>>>> 2.) Another way:
>>>> right(FUN(...other parameters already specified...)) = value;
>>>> I wanted to explore this 2nd option: but avoid evaluating FUN, unless
>>>> the parameter "right" is injected into the call.
>>>>
>>>> 3.) Option 3:
>>>> The option you mentioned.
>>>>
>>>>
>>>> Independent of the method: there are still weird/unexplained behaviours
>>>> when I try the initial code (see the latest mail with the improved code).
>>>>
>>>>
>>>> Sincerely,
>>>>
>>>>
>>>> Leonard
>>>>
>>>>
>>>> On 9/13/2021 6:45 PM, Andrew Simmons wrote:
>>>>
>>>> I think you're trying to do something like:
>>>>
>>>> `padding<-` <- function (x, which, value)
>>>> {
>>>>     which <- match.arg(which, c("bottom", "left", "top", "right"),
>>>> several.ok = TRUE)
>>>>     # code to pad to each side here
>>>> }
>>>>
>>>> Then you could use it like
>>>>
>>>> df <- data.frame(x=1:5, y = sample(1:5, 5))
>>>> padding(df, "right") <- 1
>>>>
>>>> Does that work as expected for you?
>>>>
>>>> On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help <
>>>> r-help at r-project.org> wrote:
>>>>
>>>>> I try to clarify the code:
>>>>>
>>>>>
>>>>> ###
>>>>> right = function(x, val) {print("Right");};
>>>>> padding = function(x, right, left, top, bottom) {print("Padding");};
>>>>> 'padding<-' = function(x, ...) {print("Padding = ");};
>>>>> df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>>>>>
>>>>> ### Does NOT work as expected
>>>>> 'right<-' = function(x, value) {
>>>>>      print("This line should be the first printed!")
>>>>>      print("But ERROR: x was already evaluated, which printed
>>>>> \"Padding\"");
>>>>>      x = substitute(x); # x was already evaluated before substitute();
>>>>>      return("Nothing"); # do not now what the behaviour should be?
>>>>> }
>>>>>
>>>>> right(padding(df)) = 1;
>>>>>
>>>>> ### Output:
>>>>>
>>>>> [1] "Padding"
>>>>> [1] "This line should be the first printed!"
>>>>> [1] "But ERROR: x was already evaluated, which printed \"Padding\""
>>>>> [1] "Padding = " # How did this happen ???
>>>>>
>>>>>
>>>>> ### Problems:
>>>>>
>>>>> 1.) substitute(x): did not capture the expression;
>>>>> - the first parameter of 'right<-' was already evaluated, which is not
>>>>> the case with '%f%';
>>>>> Can I avoid evaluating this parameter?
>>>>> How can I avoid to evaluate it and capture the expression:
>>>>> "right(...)"?
>>>>>
>>>>>
>>>>> 2.) Unexpected
>>>>> 'padding<-' was also called!
>>>>> I did not know this. Is it feature or bug?
>>>>> R 4.0.4
>>>>>
>>>>>
>>>>> Sincerely,
>>>>>
>>>>>
>>>>> Leonard
>>>>>
>>>>>
>>>>> On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>>>>> > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>>>>> >> Hello,
>>>>> >>
>>>>> >>
>>>>> >> I can include code for "padding<-"as well, but the error is before
>>>>> that,
>>>>> >> namely in 'right<-':
>>>>> >>
>>>>> >> right = function(x, val) {print("Right");};
>>>>> >> # more options:
>>>>> >> padding = function(x, right, left, top, bottom) {print("Padding");};
>>>>> >> 'padding<-' = function(x, ...) {print("Padding = ");};
>>>>> >> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>>> >>
>>>>> >>
>>>>> >> ### Does NOT work
>>>>> >> 'right<-' = function(x, val) {
>>>>> >>         print("Already evaluated and also does not use 'val'");
>>>>> >>         x = substitute(x); # x was evaluated before
>>>>> >> }
>>>>> >>
>>>>> >> right(padding(df)) = 1;
>>>>> >
>>>>> > It "works" (i.e. doesn't generate an error) for me, when I correct
>>>>> > your typo:  the second argument to `right<-` should be `value`, not
>>>>> > `val`.
>>>>> >
>>>>> > I'm still not clear whether it does what you want with that fix,
>>>>> > because I don't really understand what you want.
>>>>> >
>>>>> > Duncan Murdoch
>>>>> >
>>>>> >>
>>>>> >>
>>>>> >> I want to capture the assignment event inside "right<-" and then
>>>>> call
>>>>> >> the function padding() properly.
>>>>> >>
>>>>> >> I haven't thought yet if I should use:
>>>>> >>
>>>>> >> padding(x, right, left, ... other parameters);
>>>>> >>
>>>>> >> or
>>>>> >>
>>>>> >> padding(x, parameter) <- value;
>>>>> >>
>>>>> >>
>>>>> >> It also depends if I can properly capture the unevaluated expression
>>>>> >> inside "right<-":
>>>>> >>
>>>>> >> 'right<-' = function(x, val) {
>>>>> >>
>>>>> >> # x is automatically evaluated when using 'f<-'!
>>>>> >>
>>>>> >> # but not when implementing as '%f%' = function(x, y);
>>>>> >>
>>>>> >> }
>>>>> >>
>>>>> >>
>>>>> >> Many thanks,
>>>>> >>
>>>>> >>
>>>>> >> Leonard
>>>>> >>
>>>>> >>
>>>>> >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>>>>> >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>>>>> >>>> How can I avoid evaluation?
>>>>> >>>>
>>>>> >>>> right = function(x, val) {print("Right");};
>>>>> >>>> padding = function(x) {print("Padding");};
>>>>> >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>>> >>>>
>>>>> >>>> ### OK
>>>>> >>>> '%=%' = function(x, val) {
>>>>> >>>>        x = substitute(x);
>>>>> >>>> }
>>>>> >>>> right(padding(df)) %=% 1; # but ugly
>>>>> >>>>
>>>>> >>>> ### Does NOT work
>>>>> >>>> 'right<-' = function(x, val) {
>>>>> >>>>        print("Already evaluated and also does not use 'val'");
>>>>> >>>>        x = substitute(x); # is evaluated before
>>>>> >>>> }
>>>>> >>>>
>>>>> >>>> right(padding(df)) = 1
>>>>> >>>
>>>>> >>> That doesn't make sense.  You don't have a `padding<-` function,
>>>>> and
>>>>> >>> yet you are trying to call right<- to assign something to
>>>>> padding(df).
>>>>> >>>
>>>>> >>> I'm not sure about your real intention, but assignment functions by
>>>>> >>> their nature need to evaluate the thing they are assigning to,
>>>>> since
>>>>> >>> they are designed to modify objects, not create new ones.
>>>>> >>>
>>>>> >>> To create a new object, just use regular assignment.
>>>>> >>>
>>>>> >>> Duncan Murdoch
>>>>> >
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Sep 17 08:15:10 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 17 Sep 2021 06:15:10 +0000
Subject: [R] adding results to plot
In-Reply-To: <CA+8X3fX38T3HQLwmQd7quvhfSKraHcLucV68Sc11jjVPPnQrRg@mail.gmail.com>
References: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fX38T3HQLwmQd7quvhfSKraHcLucV68Sc11jjVPPnQrRg@mail.gmail.com>
Message-ID: <81d3305adcd24f918b7ce900d6b190b8@SRVEXCHCM1302.precheza.cz>

Thanks Jim

This seems to be strightforward and quite simple. I considered addtable2plot 
but was not sure how to make propper data frame from the result.

Regards
Petr

> -----Original Message-----
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Friday, September 17, 2021 2:31 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help mailing list <r-help at r-
> project.org>
> Subject: Re: [R] adding results to plot
>
> Hi Petr,
> The hard part is the names for the data frame that addtable2plot requires:
>
> set.seed(753)
> res <- shapiro.test(rnorm(100))
> library(plotrix)
> plot(0,0,type="n",axes=FALSE)
> addtable2plot(0,0,data.frame(element=names(res)[1:2],
>   value=round(as.numeric(res[1:2]),3)),xjust=0.5,
>   title=res$method)
>
> There is probably a way to get blank names with data.frame(), but I gave up.
>
> Jim
>
> On Fri, Sep 17, 2021 at 12:22 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> > Dear all
> >
> > I know I have seen the answer somewhere but I am not able to find it.
> > Please help
> >
> > > plot(1,1)
> > > res <- shapiro.test(rnorm(100))
> > > res
> >
> >         Shapiro-Wilk normality test
> >
> > data:  rnorm(100)
> > W = 0.98861, p-value = 0.5544
> >
> > I would like to add whole res object to the plot.
> >
> > I can do it one by one
> > > text(locator(1), res$method)
> > > text(locator(1), as.character(res$p.value))
> > ...
> > But it is quite inconvenient
> >
> > I could find some way in ggplot world but not in plain plot world.
> >
> > Best regards
> > Petr
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Sep 17 21:22:06 2021
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 17 Sep 2021 14:22:06 -0500
Subject: [R] calculate power-linear mixed effect model
Message-ID: <CAF9-5jPPLT6FSnAB8EYbpAKpmGcsYdajLw+T19iBBgrO4oVcUA@mail.gmail.com>

Hi All,

I plan to identify metabolite levels that differ between individuals
with various retinopathy outcomes (DR or noDR). I plan to model
metabolite levels using linear mixed models ref as implemented in
lmm2met software. The model covariates will include: age, sex, SV1,
SV, and disease_condition.

The random effect is subject variation (ID)

Disease condition is the fixed effect because I am interested in
metabolite differences between those disease conditions.

This command  will build a model for each metabolite:
fitMet = fitLmm(fix=c('Sex','Age','SV1,'SV2','disease_condition'),
random='(1|ID)', data=df, start=10)

SV1 and SV2 are surrogate variables (numerical values)

Next I need to calculate the power of my study. Let's say that I have
1,172 individuals total in the study, from which 431 are DR. Let's say
that I would like to determine the power of this study given the
effect size of 0.337.

I know about SIMR software in R but I am not sure how to apply it to
my study design.

I looked at this paper:
https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12504

But I am not sure how to adapt the code given in the tutorial so that
it is matching to mine design.

Can you please help,

Thanks
Ana


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Sep 17 21:56:17 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 17 Sep 2021 20:56:17 +0100
Subject: [R] adding results to plot
In-Reply-To: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
References: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
Message-ID: <b354f020-4f18-d696-74d5-43a787996edf@sapo.pt>

Hello,

*.test functions in base R return a list of class "htest", with its own 
print method.
The method text.htest for objects of class "htest" below is a hack. I 
adapted the formating part of the code of print.htest to plot text().
I find it maybe too complicated but it seems to work.

Warning: Not debugged at all.



text.htest <- function (ht, x, y = NULL, digits = getOption("digits"),
                         prefix = "", adj = NULL, ...) {
   out <- list()
   i_out <- 1L
   out[[i_out]] <- paste(strwrap(ht$method, prefix = prefix), sep = "\n")
   i_out <- i_out + 1L
   out[[i_out]] <- paste0("data:  ", ht$data.name)

   stat_line <- NULL
   i_stat_line <- 0L
   if (!is.null(ht$statistic)) {
     i_stat_line <- i_stat_line + 1L
     stat_line[[i_stat_line]] <- paste(names(ht$statistic), "=",
                                       format(ht$statistic, digits = 
max(1L, digits - 2L)))
   }
   if (!is.null(ht$parameter)) {
     i_stat_line <- i_stat_line + 1L
     stat_line[[i_stat_line]] <- paste(names(ht$parameter), "=",
                                       format(ht$parameter, digits = 
max(1L, digits - 2L)))
   }
   if (!is.null(ht$p.value)) {
     fp <- format.pval(ht$p.value, digits = max(1L, digits - 3L))
     i_stat_line <- i_stat_line + 1L
     stat_line[[i_stat_line]] <- paste("p-value",
                                       if (startsWith(fp, "<")) fp else 
paste("=", fp))
   }
   if(!is.null(stat_line)){
     i_out <- i_out + 1L
     #out[[i_out]] <- strwrap(paste(stat_line, collapse = ", "))
     out[[i_out]] <- paste(stat_line, collapse = ", ")
   }
   if (!is.null(ht$alternative)) {
     alt <- NULL
     i_alt <- 1L
     alt[[i_alt]] <- "alternative hypothesis: "
     if (!is.null(ht$null.value)) {
       if (length(ht$null.value) == 1L) {
         alt.char <- switch(ht$alternative, two.sided = "not equal to",
                            less = "less than", greater = "greater than")
         i_alt <- i_alt + 1L
         alt[[i_alt]] <- paste0("true ", names(ht$null.value), " is ", 
alt.char,
                                " ", ht$null.value)
       }
       else {
         i_alt <- i_alt + 1L
         alt[[i_alt]] <- paste0(ht$alternative, "\nnull values:\n")
       }
     }
     else {
       i_alt <- i_alt + 1L
       alt[[i_alt]] <- ht$alternative
     }
     i_out <- i_out + 1L
     out[[i_out]] <- paste(alt, collapse = " ")
   }
   if (!is.null(ht$conf.int)) {
     i_out <- i_out + 1L
     out[[i_out]] <- paste0(format(100 * attr(ht$conf.int, "conf.level")),
                            " percent confidence interval:\n", " ",
                            paste(format(ht$conf.int[1:2], digits = 
digits), collapse = " "))
   }
   if (!is.null(ht$estimate)) {
     i_out <- i_out + 1L
     out[[i_out]] <- paste("sample estimates:", round(ht$estimate, 
digits = digits), sep = "\n")
   }
   i_out <- i_out + 1L
   out[[i_out]] <- "\n"
   names(out)[i_out] <- "sep"
   out <- do.call(paste, out)
   if(is.null(adj)) adj <- 0L
   text(x, y, labels = out, adj = adj, ...)
   invisible(out)
}


res <- shapiro.test(rnorm(100))
plot(1,1, ylim = c(0, length(res) + 1L))
text(res, 0.6, length(res) - 1)
res

res2 <- t.test(rnorm(100))
plot(1,1, ylim = c(0, length(res2) + 1L))
text(res2, 0.6, length(res2) - 1L)
res2


Hope this helps,

Rui Barradas



?s 15:12 de 16/09/21, PIKAL Petr escreveu:
> Dear all
> 
> I know I have seen the answer somewhere but I am not able to find it. Please
> help
> 
>> plot(1,1)
>> res <- shapiro.test(rnorm(100))
>> res
> 
>          Shapiro-Wilk normality test
> 
> data:  rnorm(100)
> W = 0.98861, p-value = 0.5544
> 
> I would like to add whole res object to the plot.
> 
> I can do it one by one
>> text(locator(1), res$method)
>> text(locator(1), as.character(res$p.value))
> ...
> But it is quite inconvenient
> 
> I could find some way in ggplot world but not in plain plot world.
> 
> Best regards
> Petr
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 17 22:05:52 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 17 Sep 2021 13:05:52 -0700
Subject: [R] calculate power-linear mixed effect model
In-Reply-To: <CAF9-5jPPLT6FSnAB8EYbpAKpmGcsYdajLw+T19iBBgrO4oVcUA@mail.gmail.com>
References: <CAF9-5jPPLT6FSnAB8EYbpAKpmGcsYdajLw+T19iBBgrO4oVcUA@mail.gmail.com>
Message-ID: <CAGxFJbQKU_BNtNN4_S7JrkwZFbSYG3nPUFLpQnvKLXihQ9wNjg@mail.gmail.com>

Wrong list! Post on r-sig-mixed-models, not here.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 17, 2021 at 12:22 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi All,
>
> I plan to identify metabolite levels that differ between individuals
> with various retinopathy outcomes (DR or noDR). I plan to model
> metabolite levels using linear mixed models ref as implemented in
> lmm2met software. The model covariates will include: age, sex, SV1,
> SV, and disease_condition.
>
> The random effect is subject variation (ID)
>
> Disease condition is the fixed effect because I am interested in
> metabolite differences between those disease conditions.
>
> This command  will build a model for each metabolite:
> fitMet = fitLmm(fix=c('Sex','Age','SV1,'SV2','disease_condition'),
> random='(1|ID)', data=df, start=10)
>
> SV1 and SV2 are surrogate variables (numerical values)
>
> Next I need to calculate the power of my study. Let's say that I have
> 1,172 individuals total in the study, from which 431 are DR. Let's say
> that I would like to determine the power of this study given the
> effect size of 0.337.
>
> I know about SIMR software in R but I am not sure how to apply it to
> my study design.
>
> I looked at this paper:
> https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12504
>
> But I am not sure how to adapt the code given in the tutorial so that
> it is matching to mine design.
>
> Can you please help,
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Sep 17 22:10:05 2021
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 17 Sep 2021 15:10:05 -0500
Subject: [R] calculate power-linear mixed effect model
In-Reply-To: <CAGxFJbQKU_BNtNN4_S7JrkwZFbSYG3nPUFLpQnvKLXihQ9wNjg@mail.gmail.com>
References: <CAF9-5jPPLT6FSnAB8EYbpAKpmGcsYdajLw+T19iBBgrO4oVcUA@mail.gmail.com>
 <CAGxFJbQKU_BNtNN4_S7JrkwZFbSYG3nPUFLpQnvKLXihQ9wNjg@mail.gmail.com>
Message-ID: <CAF9-5jM5VrKdMd0BDP2=5J0a1zKpMpQr2528WsAx3BOEmPCATw@mail.gmail.com>

Thank you so much for that info!

On Fri, Sep 17, 2021 at 3:06 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Wrong list! Post on r-sig-mixed-models, not here.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Fri, Sep 17, 2021 at 12:22 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hi All,
> >
> > I plan to identify metabolite levels that differ between individuals
> > with various retinopathy outcomes (DR or noDR). I plan to model
> > metabolite levels using linear mixed models ref as implemented in
> > lmm2met software. The model covariates will include: age, sex, SV1,
> > SV, and disease_condition.
> >
> > The random effect is subject variation (ID)
> >
> > Disease condition is the fixed effect because I am interested in
> > metabolite differences between those disease conditions.
> >
> > This command  will build a model for each metabolite:
> > fitMet = fitLmm(fix=c('Sex','Age','SV1,'SV2','disease_condition'),
> > random='(1|ID)', data=df, start=10)
> >
> > SV1 and SV2 are surrogate variables (numerical values)
> >
> > Next I need to calculate the power of my study. Let's say that I have
> > 1,172 individuals total in the study, from which 431 are DR. Let's say
> > that I would like to determine the power of this study given the
> > effect size of 0.337.
> >
> > I know about SIMR software in R but I am not sure how to apply it to
> > my study design.
> >
> > I looked at this paper:
> > https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12504
> >
> > But I am not sure how to adapt the code given in the tutorial so that
> > it is matching to mine design.
> >
> > Can you please help,
> >
> > Thanks
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 17 22:20:02 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 17 Sep 2021 13:20:02 -0700
Subject: [R] calculate power-linear mixed effect model
In-Reply-To: <CAF9-5jM5VrKdMd0BDP2=5J0a1zKpMpQr2528WsAx3BOEmPCATw@mail.gmail.com>
References: <CAF9-5jPPLT6FSnAB8EYbpAKpmGcsYdajLw+T19iBBgrO4oVcUA@mail.gmail.com>
 <CAGxFJbQKU_BNtNN4_S7JrkwZFbSYG3nPUFLpQnvKLXihQ9wNjg@mail.gmail.com>
 <CAF9-5jM5VrKdMd0BDP2=5J0a1zKpMpQr2528WsAx3BOEmPCATw@mail.gmail.com>
Message-ID: <CAGxFJbSvDJ85K7Ny+Sf7yF_0n_JbfzMMFKXar=-oHHkn4bT6dA@mail.gmail.com>

Note that such info is available at
https://www.r-project.org/mail.html  (under "Special Interest
Groups").
IMHO the posting guide ought to prominently say something about this.

Cheers,
Bert


On Fri, Sep 17, 2021 at 1:10 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Thank you so much for that info!
>
> On Fri, Sep 17, 2021 at 3:06 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > Wrong list! Post on r-sig-mixed-models, not here.
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Fri, Sep 17, 2021 at 12:22 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > >
> > > Hi All,
> > >
> > > I plan to identify metabolite levels that differ between individuals
> > > with various retinopathy outcomes (DR or noDR). I plan to model
> > > metabolite levels using linear mixed models ref as implemented in
> > > lmm2met software. The model covariates will include: age, sex, SV1,
> > > SV, and disease_condition.
> > >
> > > The random effect is subject variation (ID)
> > >
> > > Disease condition is the fixed effect because I am interested in
> > > metabolite differences between those disease conditions.
> > >
> > > This command  will build a model for each metabolite:
> > > fitMet = fitLmm(fix=c('Sex','Age','SV1,'SV2','disease_condition'),
> > > random='(1|ID)', data=df, start=10)
> > >
> > > SV1 and SV2 are surrogate variables (numerical values)
> > >
> > > Next I need to calculate the power of my study. Let's say that I have
> > > 1,172 individuals total in the study, from which 431 are DR. Let's say
> > > that I would like to determine the power of this study given the
> > > effect size of 0.337.
> > >
> > > I know about SIMR software in R but I am not sure how to apply it to
> > > my study design.
> > >
> > > I looked at this paper:
> > > https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12504
> > >
> > > But I am not sure how to adapt the code given in the tutorial so that
> > > it is matching to mine design.
> > >
> > > Can you please help,
> > >
> > > Thanks
> > > Ana
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Fri Sep 17 22:53:12 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Fri, 17 Sep 2021 23:53:12 +0300
Subject: [R] [R Code] Split long names in format.ftable
In-Reply-To: <1b3a8922-0557-256f-d707-4726e746b0d7@syonic.eu>
References: <7876cd2d-2855-fee4-2839-2821361fa85d@syonic.eu>
 <1b3a8922-0557-256f-d707-4726e746b0d7@syonic.eu>
Message-ID: <60e59082-e725-31ac-7ca4-ca4c898f9125@syonic.eu>

Dear List members,


I have uploaded an improved version on Github. The function is now fully 
functional:
- justify: left, right, cent...: TODO centre vs center;
- sep: separator when printing;
- pos: Top, Bottom; TODO: Middle;

see:
https://github.com/discoleo/R/blob/master/Stat/Tools.Data.

I will address some open questions in a separate post.


### Test
# Required:
# - all functions from Github / section "Formatting":
#?? from space.builder() to ftable2();


### Data
mtcars$carbCtg = cut(mtcars$carb, c(1, 2, 4, 8), right=FALSE)
tbl = with(mtcars, table(cyl, hp, carbCtg, gear))
id = c(1,3,4);
xnm = c("Long\nname: ", "", "Extremely\nlong\nname: ")
xnm = paste0(xnm, names(dimnames(tbl))[id]);
names(dimnames(tbl))[id] = xnm;
ftbl = ftable(tbl, row.vars = id);

### FTABLE
ftable2(ftbl, sep="|"); # works nicely
ftable2(ftbl, sep=" ")
ftable2(ftbl, sep=" | ")
ftable2(ftbl, sep=" | ", justify="left")
ftable2(ftbl, sep=" | ", justify="cent") # TODO: center vs centre
ftable2(ftbl, sep=" | ", justify="left", justify.lvl="c")


Sincerely,


Leonard


On 9/15/2021 11:14 PM, Leonard Mada wrote:
> Dear List members,
>
>
> I have uploaded an improved version on Github:
> - new option: align top vs bottom;
>
> Functions:
> split.names: splits and aligns the names;
> merge.align: aligns 2 string matrices;
> ftable2: enhanced version of format.ftable (proof of concept);
> see:
> https://github.com/discoleo/R/blob/master/Stat/Tools.Data.R
>
>
> It makes sense to have such functionality in base R as well: it may be 
> useful in various locations to format character output.
>
>
> Sincerely,
>
>
> Leonard
>
>
> On 9/14/2021 8:18 PM, Leonard Mada wrote:
>> Dear List members,
>>
>>
>> I wrote some code to split long names in format.ftable. I hope it 
>> will be useful to others as well.
>>
>>
>> Ideally, this code should be implemented natively in R. I will 
>> provide in the 2nd part of the mail a concept how to actually 
>> implement the code in R. This may be interesting to R-devel as well.
>>
>> [...]
>>
>>
>> C.) split.names Function
>>
>> This function may be useful in other locations as well, particularly 
>> to split names/labels used in axes and legends in various plots. But 
>> I do not have much knowledge of the graphics engine in R.
>>
>>
>> Sincerely,
>>
>>
>> Leonard
>>
>>


From |eo@m@d@ @end|ng |rom @yon|c@eu  Fri Sep 17 23:44:58 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sat, 18 Sep 2021 00:44:58 +0300
Subject: [R] Improvement: function cut
Message-ID: <e6f0ce18-7272-b934-51b0-839779996d41@syonic.eu>

Hello List members,


the following improvements would be useful for function cut (and .bincode):


1.) Argument: Include extremes
extremes = TRUE
if(right == FALSE) {
 ?? # include also right for last interval;
} else {
 ?? # include also left for first interval;
}


2.) Argument: warn = TRUE

Warn if any values are not included in the intervals.


Motivation:
- reduce risk of errors when using function cut();


Sincerely,


Leonard


From @kw@|mmo @end|ng |rom gm@||@com  Fri Sep 17 23:53:42 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Fri, 17 Sep 2021 17:53:42 -0400
Subject: [R] Improvement: function cut
In-Reply-To: <e6f0ce18-7272-b934-51b0-839779996d41@syonic.eu>
References: <e6f0ce18-7272-b934-51b0-839779996d41@syonic.eu>
Message-ID: <CAPcHnpSvPs8kfbOtLYD83QPcaUitXD=FOJ5PF=J3hiczusDdRw@mail.gmail.com>

Regarding your first point, argument 'include.lowest' already handles this
specific case, see ?.bincode

Your second point, maybe it could be helpful, but since both 'cut.default'
and '.bincode' return NA if a value isn't within a bin, you could make
something like this on your own.
Might be worth pitching to R-bugs on the wishlist.



On Fri, Sep 17, 2021, 17:45 Leonard Mada via R-help <r-help at r-project.org>
wrote:

> Hello List members,
>
>
> the following improvements would be useful for function cut (and .bincode):
>
>
> 1.) Argument: Include extremes
> extremes = TRUE
> if(right == FALSE) {
>     # include also right for last interval;
> } else {
>     # include also left for first interval;
> }
>
>
> 2.) Argument: warn = TRUE
>
> Warn if any values are not included in the intervals.
>
>
> Motivation:
> - reduce risk of errors when using function cut();
>
>
> Sincerely,
>
>
> Leonard
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sat Sep 18 00:01:35 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sat, 18 Sep 2021 01:01:35 +0300
Subject: [R] Improvement: function cut
In-Reply-To: <CAPcHnpSvPs8kfbOtLYD83QPcaUitXD=FOJ5PF=J3hiczusDdRw@mail.gmail.com>
References: <e6f0ce18-7272-b934-51b0-839779996d41@syonic.eu>
 <CAPcHnpSvPs8kfbOtLYD83QPcaUitXD=FOJ5PF=J3hiczusDdRw@mail.gmail.com>
Message-ID: <2f0c9a1a-35ab-fa49-f27c-20f42a926088@syonic.eu>

Thank you Andrew.


Is there any reason not to make: include.lowest = TRUE the default?


Regarding the NA:

The user still has to suspect that some values were not included and run 
that test.


Leonard


On 9/18/2021 12:53 AM, Andrew Simmons wrote:
> Regarding your first point, argument 'include.lowest' already handles 
> this specific case, see ?.bincode
>
> Your second point, maybe it could be helpful, but since both 
> 'cut.default' and '.bincode' return NA if a value isn't within a bin, 
> you could make something like this on your own.
> Might be worth pitching to R-bugs on the wishlist.
>
>
>
> On Fri, Sep 17, 2021, 17:45 Leonard Mada via R-help 
> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>
>     Hello List members,
>
>
>     the following improvements would be useful for function cut (and
>     .bincode):
>
>
>     1.) Argument: Include extremes
>     extremes = TRUE
>     if(right == FALSE) {
>     ??? # include also right for last interval;
>     } else {
>     ??? # include also left for first interval;
>     }
>
>
>     2.) Argument: warn = TRUE
>
>     Warn if any values are not included in the intervals.
>
>
>     Motivation:
>     - reduce risk of errors when using function cut();
>
>
>     Sincerely,
>
>
>     Leonard
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Sat Sep 18 00:14:02 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Fri, 17 Sep 2021 18:14:02 -0400
Subject: [R] Improvement: function cut
In-Reply-To: <2f0c9a1a-35ab-fa49-f27c-20f42a926088@syonic.eu>
References: <e6f0ce18-7272-b934-51b0-839779996d41@syonic.eu>
 <CAPcHnpSvPs8kfbOtLYD83QPcaUitXD=FOJ5PF=J3hiczusDdRw@mail.gmail.com>
 <2f0c9a1a-35ab-fa49-f27c-20f42a926088@syonic.eu>
Message-ID: <CAPcHnpR+1aPsX3woYsisoUORsxAOcJ2FkGVoQSFC=J2cUrCQTg@mail.gmail.com>

While it is not explicitly mentioned anywhere in the documentation for
.bincode, I suspect 'include.lowest = FALSE' is the default to keep the
definitions of the bins consistent. For example:


x <- 0:20
breaks1 <- seq.int(0, 16, 4)
breaks2 <- seq.int(0, 20, 4)
cbind(
    .bincode(x, breaks1, right = FALSE, include.lowest = TRUE),
    .bincode(x, breaks2, right = FALSE, include.lowest = TRUE)
)


by having 'include.lowest = TRUE' with different ends, you can get
inconsistent behaviour. While this probably wouldn't be an issue with
'real' data, this would seem like something you'd want to avoid by default.
The definitions of the bins are


[0, 4)
[4, 8)
[8, 12)
[12, 16]


and


[0, 4)
[4, 8)
[8, 12)
[12, 16)
[16, 20]


so you can see where the inconsistent behaviour comes from. You might be
able to get R-core to add argument 'warn', but probably not to change the
default of 'include.lowest'. I hope this helps


On Fri, Sep 17, 2021 at 6:01 PM Leonard Mada <leo.mada at syonic.eu> wrote:

> Thank you Andrew.
>
>
> Is there any reason not to make: include.lowest = TRUE the default?
>
>
> Regarding the NA:
>
> The user still has to suspect that some values were not included and run
> that test.
>
>
> Leonard
>
>
> On 9/18/2021 12:53 AM, Andrew Simmons wrote:
>
> Regarding your first point, argument 'include.lowest' already handles this
> specific case, see ?.bincode
>
> Your second point, maybe it could be helpful, but since both 'cut.default'
> and '.bincode' return NA if a value isn't within a bin, you could make
> something like this on your own.
> Might be worth pitching to R-bugs on the wishlist.
>
>
>
> On Fri, Sep 17, 2021, 17:45 Leonard Mada via R-help <r-help at r-project.org>
> wrote:
>
>> Hello List members,
>>
>>
>> the following improvements would be useful for function cut (and
>> .bincode):
>>
>>
>> 1.) Argument: Include extremes
>> extremes = TRUE
>> if(right == FALSE) {
>>     # include also right for last interval;
>> } else {
>>     # include also left for first interval;
>> }
>>
>>
>> 2.) Argument: warn = TRUE
>>
>> Warn if any values are not included in the intervals.
>>
>>
>> Motivation:
>> - reduce risk of errors when using function cut();
>>
>>
>> Sincerely,
>>
>>
>> Leonard
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Sat Sep 18 00:29:32 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Fri, 17 Sep 2021 18:29:32 -0400
Subject: [R] Improvement: function cut
In-Reply-To: <d540eb6a-02a6-88c1-2137-a1162273ad16@syonic.eu>
References: <e6f0ce18-7272-b934-51b0-839779996d41@syonic.eu>
 <CAPcHnpSvPs8kfbOtLYD83QPcaUitXD=FOJ5PF=J3hiczusDdRw@mail.gmail.com>
 <2f0c9a1a-35ab-fa49-f27c-20f42a926088@syonic.eu>
 <CAPcHnpR+1aPsX3woYsisoUORsxAOcJ2FkGVoQSFC=J2cUrCQTg@mail.gmail.com>
 <d540eb6a-02a6-88c1-2137-a1162273ad16@syonic.eu>
Message-ID: <CAPcHnpS+FaD3LGvSJcPfe_QjjjVwKkXKLvC1ktz1sx0T-ePbrg@mail.gmail.com>

I disagree, I don't really think it's too long or ugly, but if you think it
is, you could abbreviate it as 'i'.


x <- 0:20
breaks1 <- seq.int(0, 16, 4)
breaks2 <- seq.int(0, 20, 4)
data.frame(
    cut(x, breaks1, right = FALSE, i = TRUE),
    cut(x, breaks2, right = FALSE, i = TRUE),
    check.names = FALSE
)


I hope this helps.

On Fri, Sep 17, 2021 at 6:26 PM Leonard Mada <leo.mada at syonic.eu> wrote:

> Hello Andrew,
>
>
> But "cut" generates factors. In most cases with real data one expects to
> have also the ends of the interval: the argument "include.lowest" is both
> ugly and too long.
>
> [The test-code on the ftable thread contains this error! I have run
> through this error a couple of times.]
>
>
> The only real situation that I can imagine to be problematic:
>
> - if the interval goes to +Inf (or -Inf): I do not know if there would be
> any effects when including +Inf (or -Inf).
>
>
> Leonard
>
>
> On 9/18/2021 1:14 AM, Andrew Simmons wrote:
>
> While it is not explicitly mentioned anywhere in the documentation for
> .bincode, I suspect 'include.lowest = FALSE' is the default to keep the
> definitions of the bins consistent. For example:
>
>
> x <- 0:20
> breaks1 <- seq.int(0, 16, 4)
> breaks2 <- seq.int(0, 20, 4)
> cbind(
>     .bincode(x, breaks1, right = FALSE, include.lowest = TRUE),
>     .bincode(x, breaks2, right = FALSE, include.lowest = TRUE)
> )
>
>
> by having 'include.lowest = TRUE' with different ends, you can get
> inconsistent behaviour. While this probably wouldn't be an issue with
> 'real' data, this would seem like something you'd want to avoid by default.
> The definitions of the bins are
>
>
> [0, 4)
> [4, 8)
> [8, 12)
> [12, 16]
>
>
> and
>
>
> [0, 4)
> [4, 8)
> [8, 12)
> [12, 16)
> [16, 20]
>
>
> so you can see where the inconsistent behaviour comes from. You might be
> able to get R-core to add argument 'warn', but probably not to change the
> default of 'include.lowest'. I hope this helps
>
>
> On Fri, Sep 17, 2021 at 6:01 PM Leonard Mada <leo.mada at syonic.eu> wrote:
>
>> Thank you Andrew.
>>
>>
>> Is there any reason not to make: include.lowest = TRUE the default?
>>
>>
>> Regarding the NA:
>>
>> The user still has to suspect that some values were not included and run
>> that test.
>>
>>
>> Leonard
>>
>>
>> On 9/18/2021 12:53 AM, Andrew Simmons wrote:
>>
>> Regarding your first point, argument 'include.lowest' already handles
>> this specific case, see ?.bincode
>>
>> Your second point, maybe it could be helpful, but since both
>> 'cut.default' and '.bincode' return NA if a value isn't within a bin, you
>> could make something like this on your own.
>> Might be worth pitching to R-bugs on the wishlist.
>>
>>
>>
>> On Fri, Sep 17, 2021, 17:45 Leonard Mada via R-help <r-help at r-project.org>
>> wrote:
>>
>>> Hello List members,
>>>
>>>
>>> the following improvements would be useful for function cut (and
>>> .bincode):
>>>
>>>
>>> 1.) Argument: Include extremes
>>> extremes = TRUE
>>> if(right == FALSE) {
>>>     # include also right for last interval;
>>> } else {
>>>     # include also left for first interval;
>>> }
>>>
>>>
>>> 2.) Argument: warn = TRUE
>>>
>>> Warn if any values are not included in the intervals.
>>>
>>>
>>> Motivation:
>>> - reduce risk of errors when using function cut();
>>>
>>>
>>> Sincerely,
>>>
>>>
>>> Leonard
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sat Sep 18 00:26:08 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sat, 18 Sep 2021 01:26:08 +0300
Subject: [R] Improvement: function cut
In-Reply-To: <CAPcHnpR+1aPsX3woYsisoUORsxAOcJ2FkGVoQSFC=J2cUrCQTg@mail.gmail.com>
References: <e6f0ce18-7272-b934-51b0-839779996d41@syonic.eu>
 <CAPcHnpSvPs8kfbOtLYD83QPcaUitXD=FOJ5PF=J3hiczusDdRw@mail.gmail.com>
 <2f0c9a1a-35ab-fa49-f27c-20f42a926088@syonic.eu>
 <CAPcHnpR+1aPsX3woYsisoUORsxAOcJ2FkGVoQSFC=J2cUrCQTg@mail.gmail.com>
Message-ID: <d540eb6a-02a6-88c1-2137-a1162273ad16@syonic.eu>

Hello Andrew,


But "cut" generates factors. In most cases with real data one expects to 
have also the ends of the interval: the argument "include.lowest" is 
both ugly and too long.

[The test-code on the ftable thread contains this error! I have run 
through this error a couple of times.]


The only real situation that I can imagine to be problematic:

- if the interval goes to +Inf (or -Inf): I do not know if there would 
be any effects when including +Inf (or -Inf).


Leonard


On 9/18/2021 1:14 AM, Andrew Simmons wrote:
> While it is not explicitly mentioned anywhere in the documentation for 
> .bincode, I suspect 'include.lowest = FALSE' is the default to keep 
> the definitions of the bins consistent. For example:
>
>
> x <- 0:20
> breaks1 <- seq.int <http://seq.int>(0, 16, 4)
> breaks2 <- seq.int <http://seq.int>(0, 20, 4)
> cbind(
> ? ? .bincode(x, breaks1, right = FALSE, include.lowest = TRUE),
> ? ? .bincode(x, breaks2, right = FALSE, include.lowest = TRUE)
> )
>
>
> by having 'include.lowest = TRUE' with different ends, you can get 
> inconsistent behaviour. While this probably wouldn't be an issue with 
> 'real' data, this would seem like something you'd want to avoid by 
> default. The definitions of the bins are
>
>
> [0, 4)
> [4, 8)
> [8, 12)
> [12, 16]
>
>
> and
>
>
> [0, 4)
> [4, 8)
> [8, 12)
> [12, 16)
> [16, 20]
>
>
> so you can see where the inconsistent behaviour comes from. You might 
> be able to get R-core to add argument 'warn', but probably not to 
> change the default of 'include.lowest'. I hope this helps
>
>
> On Fri, Sep 17, 2021 at 6:01 PM Leonard Mada <leo.mada at syonic.eu 
> <mailto:leo.mada at syonic.eu>> wrote:
>
>     Thank you Andrew.
>
>
>     Is there any reason not to make: include.lowest = TRUE the default?
>
>
>     Regarding the NA:
>
>     The user still has to suspect that some values were not included
>     and run that test.
>
>
>     Leonard
>
>
>     On 9/18/2021 12:53 AM, Andrew Simmons wrote:
>>     Regarding your first point, argument 'include.lowest' already
>>     handles this specific case, see ?.bincode
>>
>>     Your second point, maybe it could be helpful, but since both
>>     'cut.default' and '.bincode' return NA if a value isn't within a
>>     bin, you could make something like this on your own.
>>     Might be worth pitching to R-bugs on the wishlist.
>>
>>
>>
>>     On Fri, Sep 17, 2021, 17:45 Leonard Mada via R-help
>>     <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>
>>         Hello List members,
>>
>>
>>         the following improvements would be useful for function cut
>>         (and .bincode):
>>
>>
>>         1.) Argument: Include extremes
>>         extremes = TRUE
>>         if(right == FALSE) {
>>         ??? # include also right for last interval;
>>         } else {
>>         ??? # include also left for first interval;
>>         }
>>
>>
>>         2.) Argument: warn = TRUE
>>
>>         Warn if any values are not included in the intervals.
>>
>>
>>         Motivation:
>>         - reduce risk of errors when using function cut();
>>
>>
>>         Sincerely,
>>
>>
>>         Leonard
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>         list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         and provide commented, minimal, self-contained, reproducible
>>         code.
>>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Sep 18 00:28:54 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 17 Sep 2021 15:28:54 -0700
Subject: [R] Improvement: function cut
In-Reply-To: <2f0c9a1a-35ab-fa49-f27c-20f42a926088@syonic.eu>
References: <e6f0ce18-7272-b934-51b0-839779996d41@syonic.eu>
 <CAPcHnpSvPs8kfbOtLYD83QPcaUitXD=FOJ5PF=J3hiczusDdRw@mail.gmail.com>
 <2f0c9a1a-35ab-fa49-f27c-20f42a926088@syonic.eu>
Message-ID: <D9A8018B-9015-4941-9CA8-CABAA9CD6B18@dcn.davis.ca.us>

Re your objection that "the user has to suspect that some values were not included" applies equally to your proposed warn option. There are a lot of ways to introduce NAs... in real projects all analysts should be suspecting this problem.

On September 17, 2021 3:01:35 PM PDT, Leonard Mada via R-help <r-help at r-project.org> wrote:
>Thank you Andrew.
>
>
>Is there any reason not to make: include.lowest = TRUE the default?
>
>
>Regarding the NA:
>
>The user still has to suspect that some values were not included and run 
>that test.
>
>
>Leonard
>
>
>On 9/18/2021 12:53 AM, Andrew Simmons wrote:
>> Regarding your first point, argument 'include.lowest' already handles 
>> this specific case, see ?.bincode
>>
>> Your second point, maybe it could be helpful, but since both 
>> 'cut.default' and '.bincode' return NA if a value isn't within a bin, 
>> you could make something like this on your own.
>> Might be worth pitching to R-bugs on the wishlist.
>>
>>
>>
>> On Fri, Sep 17, 2021, 17:45 Leonard Mada via R-help 
>> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>
>>     Hello List members,
>>
>>
>>     the following improvements would be useful for function cut (and
>>     .bincode):
>>
>>
>>     1.) Argument: Include extremes
>>     extremes = TRUE
>>     if(right == FALSE) {
>>     ??? # include also right for last interval;
>>     } else {
>>     ??? # include also left for first interval;
>>     }
>>
>>
>>     2.) Argument: warn = TRUE
>>
>>     Warn if any values are not included in the intervals.
>>
>>
>>     Motivation:
>>     - reduce risk of errors when using function cut();
>>
>>
>>     Sincerely,
>>
>>
>>     Leonard
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     <http://www.R-project.org/posting-guide.html>
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sat Sep 18 00:39:14 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sat, 18 Sep 2021 01:39:14 +0300
Subject: [R] Improvement: function cut
In-Reply-To: <CAPcHnpS+FaD3LGvSJcPfe_QjjjVwKkXKLvC1ktz1sx0T-ePbrg@mail.gmail.com>
References: <e6f0ce18-7272-b934-51b0-839779996d41@syonic.eu>
 <CAPcHnpSvPs8kfbOtLYD83QPcaUitXD=FOJ5PF=J3hiczusDdRw@mail.gmail.com>
 <2f0c9a1a-35ab-fa49-f27c-20f42a926088@syonic.eu>
 <CAPcHnpR+1aPsX3woYsisoUORsxAOcJ2FkGVoQSFC=J2cUrCQTg@mail.gmail.com>
 <d540eb6a-02a6-88c1-2137-a1162273ad16@syonic.eu>
 <CAPcHnpS+FaD3LGvSJcPfe_QjjjVwKkXKLvC1ktz1sx0T-ePbrg@mail.gmail.com>
Message-ID: <db61fc46-dbe3-90fb-de07-3f9825a3daf3@syonic.eu>

Why would you want to merge different factors?

It makes no sense on real data. Even if some names are the same, the 
factors are not the same!


The only real-data application that springs to mind is censoring (right 
or left, depending on the choice): but here we have both open and closed 
intervals, e.g. to the right (in the same data-set).


Leonard


On 9/18/2021 1:29 AM, Andrew Simmons wrote:
> I disagree, I don't really think it's too long or ugly, but if you 
> think it is, you could abbreviate it as 'i'.
>
>
> x <- 0:20
> breaks1 <- seq.int <http://seq.int>(0, 16, 4)
> breaks2 <- seq.int <http://seq.int>(0, 20, 4)
> data.frame(
> ? ? cut(x, breaks1, right = FALSE, i = TRUE),
> ? ? cut(x, breaks2, right = FALSE, i = TRUE),
> ? ? check.names = FALSE
> )
>
>
> I hope this helps.
>
> On Fri, Sep 17, 2021 at 6:26 PM Leonard Mada <leo.mada at syonic.eu 
> <mailto:leo.mada at syonic.eu>> wrote:
>
>     Hello Andrew,
>
>
>     But "cut" generates factors. In most cases with real data one
>     expects to have also the ends of the interval: the argument
>     "include.lowest" is both ugly and too long.
>
>     [The test-code on the ftable thread contains this error! I have
>     run through this error a couple of times.]
>
>
>     The only real situation that I can imagine to be problematic:
>
>     - if the interval goes to +Inf (or -Inf): I do not know if there
>     would be any effects when including +Inf (or -Inf).
>
>
>     Leonard
>
>
>     On 9/18/2021 1:14 AM, Andrew Simmons wrote:
>>     While it is not explicitly mentioned anywhere in the
>>     documentation for .bincode, I suspect 'include.lowest = FALSE' is
>>     the default to keep the definitions of the bins consistent. For
>>     example:
>>
>>
>>     x <- 0:20
>>     breaks1 <- seq.int <http://seq.int>(0, 16, 4)
>>     breaks2 <- seq.int <http://seq.int>(0, 20, 4)
>>     cbind(
>>     ? ? .bincode(x, breaks1, right = FALSE, include.lowest = TRUE),
>>     ? ? .bincode(x, breaks2, right = FALSE, include.lowest = TRUE)
>>     )
>>
>>
>>     by having 'include.lowest = TRUE' with different ends, you can
>>     get inconsistent behaviour. While this probably wouldn't be an
>>     issue with 'real' data, this would seem like something you'd want
>>     to avoid by default. The definitions of the bins are
>>
>>
>>     [0, 4)
>>     [4, 8)
>>     [8, 12)
>>     [12, 16]
>>
>>
>>     and
>>
>>
>>     [0, 4)
>>     [4, 8)
>>     [8, 12)
>>     [12, 16)
>>     [16, 20]
>>
>>
>>     so you can see where the inconsistent behaviour comes from. You
>>     might be able to get R-core to add argument 'warn', but probably
>>     not to change the default of 'include.lowest'. I hope this helps
>>
>>
>>     On Fri, Sep 17, 2021 at 6:01 PM Leonard Mada <leo.mada at syonic.eu
>>     <mailto:leo.mada at syonic.eu>> wrote:
>>
>>         Thank you Andrew.
>>
>>
>>         Is there any reason not to make: include.lowest = TRUE the
>>         default?
>>
>>
>>         Regarding the NA:
>>
>>         The user still has to suspect that some values were not
>>         included and run that test.
>>
>>
>>         Leonard
>>
>>
>>         On 9/18/2021 12:53 AM, Andrew Simmons wrote:
>>>         Regarding your first point, argument 'include.lowest'
>>>         already handles this specific case, see ?.bincode
>>>
>>>         Your second point, maybe it could be helpful, but since both
>>>         'cut.default' and '.bincode' return NA if a value isn't
>>>         within a bin, you could make something like this on your own.
>>>         Might be worth pitching to R-bugs on the wishlist.
>>>
>>>
>>>
>>>         On Fri, Sep 17, 2021, 17:45 Leonard Mada via R-help
>>>         <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>>
>>>             Hello List members,
>>>
>>>
>>>             the following improvements would be useful for function
>>>             cut (and .bincode):
>>>
>>>
>>>             1.) Argument: Include extremes
>>>             extremes = TRUE
>>>             if(right == FALSE) {
>>>             ??? # include also right for last interval;
>>>             } else {
>>>             ??? # include also left for first interval;
>>>             }
>>>
>>>
>>>             2.) Argument: warn = TRUE
>>>
>>>             Warn if any values are not included in the intervals.
>>>
>>>
>>>             Motivation:
>>>             - reduce risk of errors when using function cut();
>>>
>>>
>>>             Sincerely,
>>>
>>>
>>>             Leonard
>>>
>>>             ______________________________________________
>>>             R-help at r-project.org <mailto:R-help at r-project.org>
>>>             mailing list -- To UNSUBSCRIBE and more, see
>>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>             PLEASE do read the posting guide
>>>             http://www.R-project.org/posting-guide.html
>>>             <http://www.R-project.org/posting-guide.html>
>>>             and provide commented, minimal, self-contained,
>>>             reproducible code.
>>>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sat Sep 18 00:44:12 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sat, 18 Sep 2021 01:44:12 +0300
Subject: [R] Improvement: function cut
In-Reply-To: <D9A8018B-9015-4941-9CA8-CABAA9CD6B18@dcn.davis.ca.us>
References: <e6f0ce18-7272-b934-51b0-839779996d41@syonic.eu>
 <CAPcHnpSvPs8kfbOtLYD83QPcaUitXD=FOJ5PF=J3hiczusDdRw@mail.gmail.com>
 <2f0c9a1a-35ab-fa49-f27c-20f42a926088@syonic.eu>
 <D9A8018B-9015-4941-9CA8-CABAA9CD6B18@dcn.davis.ca.us>
Message-ID: <ff472121-f53e-07ad-c482-fdb081aeb70c@syonic.eu>

The warn should be in cut() => .bincode().

It should be generated whenever a real value (excludes NA or NAN or +/- 
Inf) is not included in any of the bins.


If the user writes a script and doesn't want any warnings: he can select 
warn = FALSE. But otherwise it would be very helpful to catch 
immediately the error (and not after a number of steps or miss the error 
altogether).


Leonard


On 9/18/2021 1:28 AM, Jeff Newmiller wrote:
> Re your objection that "the user has to suspect that some values were not included" applies equally to your proposed warn option. There are a lot of ways to introduce NAs... in real projects all analysts should be suspecting this problem.
>
> On September 17, 2021 3:01:35 PM PDT, Leonard Mada via R-help <r-help at r-project.org> wrote:
>> Thank you Andrew.
>>
>>
>> Is there any reason not to make: include.lowest = TRUE the default?
>>
>>
>> Regarding the NA:
>>
>> The user still has to suspect that some values were not included and run
>> that test.
>>
>>
>> Leonard
>>
>>
>> On 9/18/2021 12:53 AM, Andrew Simmons wrote:
>>> Regarding your first point, argument 'include.lowest' already handles
>>> this specific case, see ?.bincode
>>>
>>> Your second point, maybe it could be helpful, but since both
>>> 'cut.default' and '.bincode' return NA if a value isn't within a bin,
>>> you could make something like this on your own.
>>> Might be worth pitching to R-bugs on the wishlist.
>>>
>>>
>>>
>>> On Fri, Sep 17, 2021, 17:45 Leonard Mada via R-help
>>> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>>
>>>      Hello List members,
>>>
>>>
>>>      the following improvements would be useful for function cut (and
>>>      .bincode):
>>>
>>>
>>>      1.) Argument: Include extremes
>>>      extremes = TRUE
>>>      if(right == FALSE) {
>>>      ??? # include also right for last interval;
>>>      } else {
>>>      ??? # include also left for first interval;
>>>      }
>>>
>>>
>>>      2.) Argument: warn = TRUE
>>>
>>>      Warn if any values are not included in the intervals.
>>>
>>>
>>>      Motivation:
>>>      - reduce risk of errors when using function cut();
>>>
>>>
>>>      Sincerely,
>>>
>>>
>>>      Leonard
>>>
>>>      ______________________________________________
>>>      R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>>      To UNSUBSCRIBE and more, see
>>>      https://stat.ethz.ch/mailman/listinfo/r-help
>>>      <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>      PLEASE do read the posting guide
>>>      http://www.R-project.org/posting-guide.html
>>>      <http://www.R-project.org/posting-guide.html>
>>>      and provide commented, minimal, self-contained, reproducible code.
>>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep 18 00:57:27 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 17 Sep 2021 15:57:27 -0700
Subject: [R] Improvement: function cut
In-Reply-To: <db61fc46-dbe3-90fb-de07-3f9825a3daf3@syonic.eu>
References: <e6f0ce18-7272-b934-51b0-839779996d41@syonic.eu>
 <CAPcHnpSvPs8kfbOtLYD83QPcaUitXD=FOJ5PF=J3hiczusDdRw@mail.gmail.com>
 <2f0c9a1a-35ab-fa49-f27c-20f42a926088@syonic.eu>
 <CAPcHnpR+1aPsX3woYsisoUORsxAOcJ2FkGVoQSFC=J2cUrCQTg@mail.gmail.com>
 <d540eb6a-02a6-88c1-2137-a1162273ad16@syonic.eu>
 <CAPcHnpS+FaD3LGvSJcPfe_QjjjVwKkXKLvC1ktz1sx0T-ePbrg@mail.gmail.com>
 <db61fc46-dbe3-90fb-de07-3f9825a3daf3@syonic.eu>
Message-ID: <CAGxFJbSSy414y1zVNvrRNZZJ=6RLn1-uOt9=emE6KcL3vMkWuw@mail.gmail.com>

Perhaps you and Andrew should take this discussion off list...

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 17, 2021 at 3:45 PM Leonard Mada via R-help
<r-help at r-project.org> wrote:
>
> Why would you want to merge different factors?
>
> It makes no sense on real data. Even if some names are the same, the
> factors are not the same!
>
>
> The only real-data application that springs to mind is censoring (right
> or left, depending on the choice): but here we have both open and closed
> intervals, e.g. to the right (in the same data-set).
>
>
> Leonard
>
>
> On 9/18/2021 1:29 AM, Andrew Simmons wrote:
> > I disagree, I don't really think it's too long or ugly, but if you
> > think it is, you could abbreviate it as 'i'.
> >
> >
> > x <- 0:20
> > breaks1 <- seq.int <http://seq.int>(0, 16, 4)
> > breaks2 <- seq.int <http://seq.int>(0, 20, 4)
> > data.frame(
> >     cut(x, breaks1, right = FALSE, i = TRUE),
> >     cut(x, breaks2, right = FALSE, i = TRUE),
> >     check.names = FALSE
> > )
> >
> >
> > I hope this helps.
> >
> > On Fri, Sep 17, 2021 at 6:26 PM Leonard Mada <leo.mada at syonic.eu
> > <mailto:leo.mada at syonic.eu>> wrote:
> >
> >     Hello Andrew,
> >
> >
> >     But "cut" generates factors. In most cases with real data one
> >     expects to have also the ends of the interval: the argument
> >     "include.lowest" is both ugly and too long.
> >
> >     [The test-code on the ftable thread contains this error! I have
> >     run through this error a couple of times.]
> >
> >
> >     The only real situation that I can imagine to be problematic:
> >
> >     - if the interval goes to +Inf (or -Inf): I do not know if there
> >     would be any effects when including +Inf (or -Inf).
> >
> >
> >     Leonard
> >
> >
> >     On 9/18/2021 1:14 AM, Andrew Simmons wrote:
> >>     While it is not explicitly mentioned anywhere in the
> >>     documentation for .bincode, I suspect 'include.lowest = FALSE' is
> >>     the default to keep the definitions of the bins consistent. For
> >>     example:
> >>
> >>
> >>     x <- 0:20
> >>     breaks1 <- seq.int <http://seq.int>(0, 16, 4)
> >>     breaks2 <- seq.int <http://seq.int>(0, 20, 4)
> >>     cbind(
> >>         .bincode(x, breaks1, right = FALSE, include.lowest = TRUE),
> >>         .bincode(x, breaks2, right = FALSE, include.lowest = TRUE)
> >>     )
> >>
> >>
> >>     by having 'include.lowest = TRUE' with different ends, you can
> >>     get inconsistent behaviour. While this probably wouldn't be an
> >>     issue with 'real' data, this would seem like something you'd want
> >>     to avoid by default. The definitions of the bins are
> >>
> >>
> >>     [0, 4)
> >>     [4, 8)
> >>     [8, 12)
> >>     [12, 16]
> >>
> >>
> >>     and
> >>
> >>
> >>     [0, 4)
> >>     [4, 8)
> >>     [8, 12)
> >>     [12, 16)
> >>     [16, 20]
> >>
> >>
> >>     so you can see where the inconsistent behaviour comes from. You
> >>     might be able to get R-core to add argument 'warn', but probably
> >>     not to change the default of 'include.lowest'. I hope this helps
> >>
> >>
> >>     On Fri, Sep 17, 2021 at 6:01 PM Leonard Mada <leo.mada at syonic.eu
> >>     <mailto:leo.mada at syonic.eu>> wrote:
> >>
> >>         Thank you Andrew.
> >>
> >>
> >>         Is there any reason not to make: include.lowest = TRUE the
> >>         default?
> >>
> >>
> >>         Regarding the NA:
> >>
> >>         The user still has to suspect that some values were not
> >>         included and run that test.
> >>
> >>
> >>         Leonard
> >>
> >>
> >>         On 9/18/2021 12:53 AM, Andrew Simmons wrote:
> >>>         Regarding your first point, argument 'include.lowest'
> >>>         already handles this specific case, see ?.bincode
> >>>
> >>>         Your second point, maybe it could be helpful, but since both
> >>>         'cut.default' and '.bincode' return NA if a value isn't
> >>>         within a bin, you could make something like this on your own.
> >>>         Might be worth pitching to R-bugs on the wishlist.
> >>>
> >>>
> >>>
> >>>         On Fri, Sep 17, 2021, 17:45 Leonard Mada via R-help
> >>>         <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
> >>>
> >>>             Hello List members,
> >>>
> >>>
> >>>             the following improvements would be useful for function
> >>>             cut (and .bincode):
> >>>
> >>>
> >>>             1.) Argument: Include extremes
> >>>             extremes = TRUE
> >>>             if(right == FALSE) {
> >>>                 # include also right for last interval;
> >>>             } else {
> >>>                 # include also left for first interval;
> >>>             }
> >>>
> >>>
> >>>             2.) Argument: warn = TRUE
> >>>
> >>>             Warn if any values are not included in the intervals.
> >>>
> >>>
> >>>             Motivation:
> >>>             - reduce risk of errors when using function cut();
> >>>
> >>>
> >>>             Sincerely,
> >>>
> >>>
> >>>             Leonard
> >>>
> >>>             ______________________________________________
> >>>             R-help at r-project.org <mailto:R-help at r-project.org>
> >>>             mailing list -- To UNSUBSCRIBE and more, see
> >>>             https://stat.ethz.ch/mailman/listinfo/r-help
> >>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
> >>>             PLEASE do read the posting guide
> >>>             http://www.R-project.org/posting-guide.html
> >>>             <http://www.R-project.org/posting-guide.html>
> >>>             and provide commented, minimal, self-contained,
> >>>             reproducible code.
> >>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sat Sep 18 14:28:51 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sat, 18 Sep 2021 15:28:51 +0300
Subject: [R] Improvement: function cut
In-Reply-To: <CAPcHnpS+FaD3LGvSJcPfe_QjjjVwKkXKLvC1ktz1sx0T-ePbrg@mail.gmail.com>
References: <e6f0ce18-7272-b934-51b0-839779996d41@syonic.eu>
 <CAPcHnpSvPs8kfbOtLYD83QPcaUitXD=FOJ5PF=J3hiczusDdRw@mail.gmail.com>
 <2f0c9a1a-35ab-fa49-f27c-20f42a926088@syonic.eu>
 <CAPcHnpR+1aPsX3woYsisoUORsxAOcJ2FkGVoQSFC=J2cUrCQTg@mail.gmail.com>
 <d540eb6a-02a6-88c1-2137-a1162273ad16@syonic.eu>
 <CAPcHnpS+FaD3LGvSJcPfe_QjjjVwKkXKLvC1ktz1sx0T-ePbrg@mail.gmail.com>
Message-ID: <a4757145-2c7f-2ad8-dc94-4ec89e896c1d@syonic.eu>

Hello Andrew,


I add this info as a completion (so other users can get a better 
understanding):

If we want to perform a survival analysis, than the interval should be 
closed to the right, but we should include also the first time point (as 
per Intention-to-Treat):

[0, 4](4, 8](8, 12](12, 16]

[0, 4](4, 8](8, 12](12, 16](16, 20]


So the series is extendible to the right without any errors!

But the 1st interval (which is the same in both series) is different 
from the other intervals: [0, 4].


I feel that this should have been the default behaviour for cut().

Note:

I was induced to think about a different situation in my previous 
message, as you constructed open intervals on the right, and also 
extended to the right. But survival analysis should be as described in 
this mail and should probably be the default.


Sincerely,


Leonard


On 9/18/2021 1:29 AM, Andrew Simmons wrote:
> I disagree, I don't really think it's too long or ugly, but if you 
> think it is, you could abbreviate it as 'i'.
>
>
> x <- 0:20
> breaks1 <- seq.int <http://seq.int>(0, 16, 4)
> breaks2 <- seq.int <http://seq.int>(0, 20, 4)
> data.frame(
> ? ? cut(x, breaks1, right = FALSE, i = TRUE),
> ? ? cut(x, breaks2, right = FALSE, i = TRUE),
> ? ? check.names = FALSE
> )
>
>
> I hope this helps.
>
> On Fri, Sep 17, 2021 at 6:26 PM Leonard Mada <leo.mada at syonic.eu 
> <mailto:leo.mada at syonic.eu>> wrote:
>
>     Hello Andrew,
>
>
>     But "cut" generates factors. In most cases with real data one
>     expects to have also the ends of the interval: the argument
>     "include.lowest" is both ugly and too long.
>
>     [The test-code on the ftable thread contains this error! I have
>     run through this error a couple of times.]
>
>
>     The only real situation that I can imagine to be problematic:
>
>     - if the interval goes to +Inf (or -Inf): I do not know if there
>     would be any effects when including +Inf (or -Inf).
>
>
>     Leonard
>
>
>     On 9/18/2021 1:14 AM, Andrew Simmons wrote:
>>     While it is not explicitly mentioned anywhere in the
>>     documentation for .bincode, I suspect 'include.lowest = FALSE' is
>>     the default to keep the definitions of the bins consistent. For
>>     example:
>>
>>
>>     x <- 0:20
>>     breaks1 <- seq.int <http://seq.int>(0, 16, 4)
>>     breaks2 <- seq.int <http://seq.int>(0, 20, 4)
>>     cbind(
>>     ? ? .bincode(x, breaks1, right = FALSE, include.lowest = TRUE),
>>     ? ? .bincode(x, breaks2, right = FALSE, include.lowest = TRUE)
>>     )
>>
>>
>>     by having 'include.lowest = TRUE' with different ends, you can
>>     get inconsistent behaviour. While this probably wouldn't be an
>>     issue with 'real' data, this would seem like something you'd want
>>     to avoid by default. The definitions of the bins are
>>
>>
>>     [0, 4)
>>     [4, 8)
>>     [8, 12)
>>     [12, 16]
>>
>>
>>     and
>>
>>
>>     [0, 4)
>>     [4, 8)
>>     [8, 12)
>>     [12, 16)
>>     [16, 20]
>>
>>
>>     so you can see where the inconsistent behaviour comes from. You
>>     might be able to get R-core to add argument 'warn', but probably
>>     not to change the default of 'include.lowest'. I hope this helps
>>
>>
>>     On Fri, Sep 17, 2021 at 6:01 PM Leonard Mada <leo.mada at syonic.eu
>>     <mailto:leo.mada at syonic.eu>> wrote:
>>
>>         Thank you Andrew.
>>
>>
>>         Is there any reason not to make: include.lowest = TRUE the
>>         default?
>>
>>
>>         Regarding the NA:
>>
>>         The user still has to suspect that some values were not
>>         included and run that test.
>>
>>
>>         Leonard
>>
>>
>>         On 9/18/2021 12:53 AM, Andrew Simmons wrote:
>>>         Regarding your first point, argument 'include.lowest'
>>>         already handles this specific case, see ?.bincode
>>>
>>>         Your second point, maybe it could be helpful, but since both
>>>         'cut.default' and '.bincode' return NA if a value isn't
>>>         within a bin, you could make something like this on your own.
>>>         Might be worth pitching to R-bugs on the wishlist.
>>>
>>>
>>>
>>>         On Fri, Sep 17, 2021, 17:45 Leonard Mada via R-help
>>>         <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>>
>>>             Hello List members,
>>>
>>>
>>>             the following improvements would be useful for function
>>>             cut (and .bincode):
>>>
>>>
>>>             1.) Argument: Include extremes
>>>             extremes = TRUE
>>>             if(right == FALSE) {
>>>             ??? # include also right for last interval;
>>>             } else {
>>>             ??? # include also left for first interval;
>>>             }
>>>
>>>
>>>             2.) Argument: warn = TRUE
>>>
>>>             Warn if any values are not included in the intervals.
>>>
>>>
>>>             Motivation:
>>>             - reduce risk of errors when using function cut();
>>>
>>>
>>>             Sincerely,
>>>
>>>
>>>             Leonard
>>>
>>>             ______________________________________________
>>>             R-help at r-project.org <mailto:R-help at r-project.org>
>>>             mailing list -- To UNSUBSCRIBE and more, see
>>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>             PLEASE do read the posting guide
>>>             http://www.R-project.org/posting-guide.html
>>>             <http://www.R-project.org/posting-guide.html>
>>>             and provide commented, minimal, self-contained,
>>>             reproducible code.
>>>

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Sat Sep 18 16:19:39 2021
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Sat, 18 Sep 2021 09:19:39 -0500
Subject: [R] ReadItem:  Error
References: <009b01d7ac98$383e6a60$a8bb3f20$.ref@sbcglobal.net>
Message-ID: <009b01d7ac98$383e6a60$a8bb3f20$@sbcglobal.net>

Anyone see what I might be doing wrong? Corrupted rds file maybe. The error
would suggest I'm using an older version of R except I'm running both the
latest RStudio and R versions.

# Load in the tidyverse, raster, and sf packages
library(tidyverse)
library(raster)
library(sf)

# Read the climate data from an rds file
climate <- readRDS("Datasets/climate_raster.rds")

# Have a look at the variables in the climate data
colnames(climate)

# Convert to SpatialPixelDataFrame for plotting
climate_df <- mutate(
  .data = climate, 
  rasters = map(
    .x = rasters, 
    ~ as_tibble(as(.x, "SpatialPixelsDataFrame")))) %>%
  unnest(cols = c(rasters))

> climate <- readRDS("Datasets/climate_raster.rds")
Error in readRDS("Datasets/climate_raster.rds") : 
  ReadItem: unknown type 0, perhaps written by later version of R


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep 18 18:40:08 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 18 Sep 2021 09:40:08 -0700
Subject: [R] ReadItem: Error
In-Reply-To: <009b01d7ac98$383e6a60$a8bb3f20$@sbcglobal.net>
References: <009b01d7ac98$383e6a60$a8bb3f20$.ref@sbcglobal.net>
 <009b01d7ac98$383e6a60$a8bb3f20$@sbcglobal.net>
Message-ID: <CAGxFJbT6Pd4wiQQ-10MfEtZnhwFpLeMRzJHR0RYWhCkjfPvpTQ@mail.gmail.com>

Did you try infoRDS() ?  It **may** tell you something useful, though
it cannot tell you whether the file is corrupted or not. If you post
its results here, someone **may** be able to tell you something
informative.

That's all I got.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Sep 18, 2021 at 9:00 AM Jeff Reichman <reichmanj at sbcglobal.net> wrote:
>
> Anyone see what I might be doing wrong? Corrupted rds file maybe. The error
> would suggest I'm using an older version of R except I'm running both the
> latest RStudio and R versions.
>
> # Load in the tidyverse, raster, and sf packages
> library(tidyverse)
> library(raster)
> library(sf)
>
> # Read the climate data from an rds file
> climate <- readRDS("Datasets/climate_raster.rds")
>
> # Have a look at the variables in the climate data
> colnames(climate)
>
> # Convert to SpatialPixelDataFrame for plotting
> climate_df <- mutate(
>   .data = climate,
>   rasters = map(
>     .x = rasters,
>     ~ as_tibble(as(.x, "SpatialPixelsDataFrame")))) %>%
>   unnest(cols = c(rasters))
>
> > climate <- readRDS("Datasets/climate_raster.rds")
> Error in readRDS("Datasets/climate_raster.rds") :
>   ReadItem: unknown type 0, perhaps written by later version of R
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chr|@ho|d @end|ng |rom p@yctc@org  Sat Sep 18 21:26:08 2021
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Sat, 18 Sep 2021 19:26:08 +0000 (UTC)
Subject: [R] Cacheing of functions from libraries other than the base in
 Rmarkdown
Message-ID: <150932547.5211869.1631993168825.JavaMail.zimbra@psyctc.org>

This question may belong somewhere else, if so, please signpost me and accept apologies.

What is happening is that I have a large (for me, > 3k lines) Rmarkdown file with many R code blocks (no other code or 
engine is used) working on some large datasets.  I have some inline r like 

   There are `r n_distinct(tibDat$ID)` participants and `r nrow(tibDat)` rows of data.

What I am finding is that even if one knit has worked fine and I change something somewhere and knit again, the second
knit is often failing with an error like

   n_distinct(tibDat$ID) : could not find function "n_distinct"

This is not happening for functions like nrow() from base R and it mostly seems to happen to functions from the tidyverse.

I think what is happening is some sort of cache corruption presumably caused by the memory demands.  I am pretty sure I've
seen this before but a long time ago and dealt with it by deleting the files and cache folders created by the knit.  That
works now too but as knitting the whole file now takes over 20 minutes, I really don't want to have to do that.

I have found that replacing things with base functions fixes the problem every time, e.g. replacing `r n_distinct(tibDat$ID)`
with `r length(unique(tibDat$ID))` works fine.  The other workaround is to compute what you need for the inline 
computation at the end of the preceding code block, trivial e.g. at the end of the preceding code block:

n_distinct(tibDat$ID) -> tmpN
```

and then

  `r tmpN` 

that works fine so I have my workarounds but I guess I have three questions:

1) do others see this?
2) is there some setting that might, assuming my guess about the cause is correct, increase some storage somewhere and avert this?
3) if it is a bug, where should I report it (as I'm not sure what is causing it!)?

Thanks in advance,

Chris



> sessionInfo()
R version 4.1.1 (2021-08-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.3 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3

locale:
 [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C               LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8     LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8    LC_PAPER=en_GB.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] boot_1.3-28         CECPfuns_0.0.0.9041 janitor_2.1.0       lubridate_1.7.10    forcats_0.5.1       stringr_1.4.0       dplyr_1.0.7         purrr_0.3.4         readr_2.0.1         tidyr_1.1.3         tibble_3.1.4       
[12] ggplot2_3.3.5       tidyverse_1.3.1     english_1.2-6       pander_0.6.4       

loaded via a namespace (and not attached):
 [1] fs_1.5.0            bit64_4.0.5         RColorBrewer_1.1-2  httr_1.4.2          tools_4.1.1         backports_1.2.1     utf8_1.2.2          R6_2.5.1            rpart_4.1-15        Hmisc_4.5-0         DBI_1.1.1          
[12] colorspace_2.0-2    nnet_7.3-16         withr_2.4.2         tidyselect_1.1.1    gridExtra_2.3       bit_4.0.4           compiler_4.1.1      cli_3.0.1           rvest_1.0.1         htmlTable_2.2.1     xml2_1.3.2         
[23] labeling_0.4.2      scales_1.1.1        checkmate_2.0.0     corrr_0.4.3         odbc_1.3.2          digest_0.6.27       readODS_1.7.0       foreign_0.8-81      rmarkdown_2.11      base64enc_0.1-3     jpeg_0.1-9         
[34] pkgconfig_2.0.3     htmltools_0.5.2     dbplyr_2.1.1        fastmap_1.1.0       RJDBC_0.2-8         htmlwidgets_1.5.4   rlang_0.4.11        readxl_1.3.1        rstudioapi_0.13     farver_2.1.0        generics_0.1.0     
[45] jsonlite_1.7.2      magrittr_2.0.1      Formula_1.2-4       Matrix_1.3-4        Rcpp_1.0.7          munsell_0.5.0       fansi_0.5.0         lifecycle_1.0.0     stringi_1.7.4       yaml_2.2.1          snakecase_0.11.0   
[56] grid_4.1.1          blob_1.2.2          crayon_1.4.1        lattice_0.20-44     haven_2.4.3         splines_4.1.1       hms_1.1.0           knitr_1.34          pillar_1.6.2        reprex_2.0.1        glue_1.4.2         
[67] evaluate_0.14       latticeExtra_0.6-29 data.table_1.14.0   modelr_0.1.8        png_0.1-7           vctrs_0.3.8         tzdb_0.1.2          psy_1.1             cellranger_1.1.0    gtable_0.3.0        assertthat_0.2.1   
[78] xfun_0.26           broom_0.7.9         rsconnect_0.8.24    viridisLite_0.4.0   survival_3.2-13     rJava_1.0-4         cluster_2.1.2       ellipsis_0.3.2    


-- 
Chris Evans (he/him) <chris at psyctc.org> Visiting Professor, University of Sheffield and UDLA, Quito, Ecuador
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
   https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep 18 22:01:25 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 18 Sep 2021 13:01:25 -0700
Subject: [R] Cacheing of functions from libraries other than the base in
 Rmarkdown
In-Reply-To: <150932547.5211869.1631993168825.JavaMail.zimbra@psyctc.org>
References: <150932547.5211869.1631993168825.JavaMail.zimbra@psyctc.org>
Message-ID: <CAGxFJbQB80rU8FyhdYdfJ8w64ToxDaeanRNfpOEvaEeCxeT7ig@mail.gmail.com>

I think you should post on the RStudio help forums. They have specific
areas to ask for help on their stuff, at least for some of it. You may wish
to wait a bit before doing so, though, just to see if someone here responds.

Bert


On Sat, Sep 18, 2021, 12:26 PM Chris Evans <chrishold at psyctc.org> wrote:

> This question may belong somewhere else, if so, please signpost me and
> accept apologies.
>
> What is happening is that I have a large (for me, > 3k lines) Rmarkdown
> file with many R code blocks (no other code or
> engine is used) working on some large datasets.  I have some inline r like
>
>    There are `r n_distinct(tibDat$ID)` participants and `r nrow(tibDat)`
> rows of data.
>
> What I am finding is that even if one knit has worked fine and I change
> something somewhere and knit again, the second
> knit is often failing with an error like
>
>    n_distinct(tibDat$ID) : could not find function "n_distinct"
>
> This is not happening for functions like nrow() from base R and it mostly
> seems to happen to functions from the tidyverse.
>
> I think what is happening is some sort of cache corruption presumably
> caused by the memory demands.  I am pretty sure I've
> seen this before but a long time ago and dealt with it by deleting the
> files and cache folders created by the knit.  That
> works now too but as knitting the whole file now takes over 20 minutes, I
> really don't want to have to do that.
>
> I have found that replacing things with base functions fixes the problem
> every time, e.g. replacing `r n_distinct(tibDat$ID)`
> with `r length(unique(tibDat$ID))` works fine.  The other workaround is to
> compute what you need for the inline
> computation at the end of the preceding code block, trivial e.g. at the
> end of the preceding code block:
>
> n_distinct(tibDat$ID) -> tmpN
> ```
>
> and then
>
>   `r tmpN`
>
> that works fine so I have my workarounds but I guess I have three
> questions:
>
> 1) do others see this?
> 2) is there some setting that might, assuming my guess about the cause is
> correct, increase some storage somewhere and avert this?
> 3) if it is a bug, where should I report it (as I'm not sure what is
> causing it!)?
>
> Thanks in advance,
>
> Chris
>
>
>
> > sessionInfo()
> R version 4.1.1 (2021-08-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 20.04.3 LTS
>
> Matrix products: default
> BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3
>
> locale:
>  [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
>  LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
>  LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8
> LC_PAPER=en_GB.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>  LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>  [1] boot_1.3-28         CECPfuns_0.0.0.9041 janitor_2.1.0
>  lubridate_1.7.10    forcats_0.5.1       stringr_1.4.0       dplyr_1.0.7
>      purrr_0.3.4         readr_2.0.1         tidyr_1.1.3
>  tibble_3.1.4
> [12] ggplot2_3.3.5       tidyverse_1.3.1     english_1.2-6
>  pander_0.6.4
>
> loaded via a namespace (and not attached):
>  [1] fs_1.5.0            bit64_4.0.5         RColorBrewer_1.1-2
> httr_1.4.2          tools_4.1.1         backports_1.2.1     utf8_1.2.2
>     R6_2.5.1            rpart_4.1-15        Hmisc_4.5-0         DBI_1.1.1
>
> [12] colorspace_2.0-2    nnet_7.3-16         withr_2.4.2
>  tidyselect_1.1.1    gridExtra_2.3       bit_4.0.4
>  compiler_4.1.1      cli_3.0.1           rvest_1.0.1
>  htmlTable_2.2.1     xml2_1.3.2
> [23] labeling_0.4.2      scales_1.1.1        checkmate_2.0.0
>  corrr_0.4.3         odbc_1.3.2          digest_0.6.27       readODS_1.7.0
>      foreign_0.8-81      rmarkdown_2.11      base64enc_0.1-3
>  jpeg_0.1-9
> [34] pkgconfig_2.0.3     htmltools_0.5.2     dbplyr_2.1.1
> fastmap_1.1.0       RJDBC_0.2-8         htmlwidgets_1.5.4   rlang_0.4.11
>     readxl_1.3.1        rstudioapi_0.13     farver_2.1.0
> generics_0.1.0
> [45] jsonlite_1.7.2      magrittr_2.0.1      Formula_1.2-4
>  Matrix_1.3-4        Rcpp_1.0.7          munsell_0.5.0       fansi_0.5.0
>      lifecycle_1.0.0     stringi_1.7.4       yaml_2.2.1
> snakecase_0.11.0
> [56] grid_4.1.1          blob_1.2.2          crayon_1.4.1
> lattice_0.20-44     haven_2.4.3         splines_4.1.1       hms_1.1.0
>      knitr_1.34          pillar_1.6.2        reprex_2.0.1
> glue_1.4.2
> [67] evaluate_0.14       latticeExtra_0.6-29 data.table_1.14.0
>  modelr_0.1.8        png_0.1-7           vctrs_0.3.8         tzdb_0.1.2
>       psy_1.1             cellranger_1.1.0    gtable_0.3.0
> assertthat_0.2.1
> [78] xfun_0.26           broom_0.7.9         rsconnect_0.8.24
> viridisLite_0.4.0   survival_3.2-13     rJava_1.0-4         cluster_2.1.2
>      ellipsis_0.3.2
>
>
> --
> Chris Evans (he/him) <chris at psyctc.org> Visiting Professor, University of
> Sheffield and UDLA, Quito, Ecuador
> I do some consultation work for the University of Roehampton <
> chris.evans at roehampton.ac.uk> and other places
> but <chris at psyctc.org> remains my main Email address.  I have a work web
> site at:
>    https://www.psyctc.org/psyctc/
> and a site I manage for CORE and CORE system trust at:
>    http://www.coresystemtrust.org.uk/
> I have "semigrated" to France, see:
>    https://www.psyctc.org/pelerinage2016/semigrating-to-france/
>
> https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/
>
> If you want an Emeeting, I am trying to keep them to Thursdays and my
> diary is at:
>    https://www.psyctc.org/pelerinage2016/ceworkdiary/
> Beware: French time, generally an hour ahead of UK.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat Sep 18 22:43:31 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 18 Sep 2021 13:43:31 -0700
Subject: [R] Improvement: function cut
In-Reply-To: <a4757145-2c7f-2ad8-dc94-4ec89e896c1d@syonic.eu>
References: <e6f0ce18-7272-b934-51b0-839779996d41@syonic.eu>
 <CAPcHnpSvPs8kfbOtLYD83QPcaUitXD=FOJ5PF=J3hiczusDdRw@mail.gmail.com>
 <2f0c9a1a-35ab-fa49-f27c-20f42a926088@syonic.eu>
 <CAPcHnpR+1aPsX3woYsisoUORsxAOcJ2FkGVoQSFC=J2cUrCQTg@mail.gmail.com>
 <d540eb6a-02a6-88c1-2137-a1162273ad16@syonic.eu>
 <CAPcHnpS+FaD3LGvSJcPfe_QjjjVwKkXKLvC1ktz1sx0T-ePbrg@mail.gmail.com>
 <a4757145-2c7f-2ad8-dc94-4ec89e896c1d@syonic.eu>
Message-ID: <5fef8f53-e208-69fe-0119-b37522fd6069@comcast.net>


On 9/18/21 5:28 AM, Leonard Mada via R-help wrote:
> Hello Andrew,
>
>
> I add this info as a completion (so other users can get a better
> understanding):
>
> If we want to perform a survival analysis, than the interval should be
> closed to the right, but we should include also the first time point (as
> per Intention-to-Treat):
>
> [0, 4](4, 8](8, 12](12, 16]
>
> [0, 4](4, 8](8, 12](12, 16](16, 20]
>
>
> So the series is extendible to the right without any errors!
>
> But the 1st interval (which is the same in both series) is different
> from the other intervals: [0, 4].
>
>
> I feel that this should have been the default behaviour for cut().

To Leonard;

If you do not like the behavior of `cut`, then you should "roll your 
own". It's very unlikely that R Core will modify a base cunction like 
cut. You might want to look at Hmisc::cut2. Frank Harrell didn't like 
that default behavior and thought he could make a better cut, so he just 
put it in his package. I did like his version better and often used it 
when I was actively programming. I suspect there is also a tidyverse 
cut-like function, but I'm not terribly familiar with that fork of R. 
(It's really not the same language IMHO.)

But it's a waste of time and energy to try propose modifications of core 
R functions unless *you* can show that it is stable across 20,000 
packages and will not offend long-time users. The likelihood? of that 
happening for your proposal is vanishing small in my estimation. You 
shouldn't ask R Core to do that for you. They are busy fixing real bugs.


If you want to persist despite my negativity, then you should make a 
complete proposal by submitting a proper diff file that incorporates 
your tested efforts to the Rdevel mailing list.


-- 

David

>
> Note:
>
> I was induced to think about a different situation in my previous
> message, as you constructed open intervals on the right, and also
> extended to the right. But survival analysis should be as described in
> this mail and should probably be the default.
>
>
> Sincerely,
>
>
> Leonard
>
>
> On 9/18/2021 1:29 AM, Andrew Simmons wrote:
>> I disagree, I don't really think it's too long or ugly, but if you
>> think it is, you could abbreviate it as 'i'.
>>
>>
>> x <- 0:20
>> breaks1 <- seq.int <http://seq.int>(0, 16, 4)
>> breaks2 <- seq.int <http://seq.int>(0, 20, 4)
>> data.frame(
>>  ? ? cut(x, breaks1, right = FALSE, i = TRUE),
>>  ? ? cut(x, breaks2, right = FALSE, i = TRUE),
>>  ? ? check.names = FALSE
>> )
>>
>>
>> I hope this helps.
>>
>> On Fri, Sep 17, 2021 at 6:26 PM Leonard Mada <leo.mada at syonic.eu
>> <mailto:leo.mada at syonic.eu>> wrote:
>>
>>      Hello Andrew,
>>
>>
>>      But "cut" generates factors. In most cases with real data one
>>      expects to have also the ends of the interval: the argument
>>      "include.lowest" is both ugly and too long.
>>
>>      [The test-code on the ftable thread contains this error! I have
>>      run through this error a couple of times.]
>>
>>
>>      The only real situation that I can imagine to be problematic:
>>
>>      - if the interval goes to +Inf (or -Inf): I do not know if there
>>      would be any effects when including +Inf (or -Inf).
>>
>>
>>      Leonard
>>
>>
>>      On 9/18/2021 1:14 AM, Andrew Simmons wrote:
>>>      While it is not explicitly mentioned anywhere in the
>>>      documentation for .bincode, I suspect 'include.lowest = FALSE' is
>>>      the default to keep the definitions of the bins consistent. For
>>>      example:
>>>
>>>
>>>      x <- 0:20
>>>      breaks1 <- seq.int <http://seq.int>(0, 16, 4)
>>>      breaks2 <- seq.int <http://seq.int>(0, 20, 4)
>>>      cbind(
>>>      ? ? .bincode(x, breaks1, right = FALSE, include.lowest = TRUE),
>>>      ? ? .bincode(x, breaks2, right = FALSE, include.lowest = TRUE)
>>>      )
>>>
>>>
>>>      by having 'include.lowest = TRUE' with different ends, you can
>>>      get inconsistent behaviour. While this probably wouldn't be an
>>>      issue with 'real' data, this would seem like something you'd want
>>>      to avoid by default. The definitions of the bins are
>>>
>>>
>>>      [0, 4)
>>>      [4, 8)
>>>      [8, 12)
>>>      [12, 16]
>>>
>>>
>>>      and
>>>
>>>
>>>      [0, 4)
>>>      [4, 8)
>>>      [8, 12)
>>>      [12, 16)
>>>      [16, 20]
>>>
>>>
>>>      so you can see where the inconsistent behaviour comes from. You
>>>      might be able to get R-core to add argument 'warn', but probably
>>>      not to change the default of 'include.lowest'. I hope this helps
>>>
>>>
>>>      On Fri, Sep 17, 2021 at 6:01 PM Leonard Mada <leo.mada at syonic.eu
>>>      <mailto:leo.mada at syonic.eu>> wrote:
>>>
>>>          Thank you Andrew.
>>>
>>>
>>>          Is there any reason not to make: include.lowest = TRUE the
>>>          default?
>>>
>>>
>>>          Regarding the NA:
>>>
>>>          The user still has to suspect that some values were not
>>>          included and run that test.
>>>
>>>
>>>          Leonard
>>>
>>>
>>>          On 9/18/2021 12:53 AM, Andrew Simmons wrote:
>>>>          Regarding your first point, argument 'include.lowest'
>>>>          already handles this specific case, see ?.bincode
>>>>
>>>>          Your second point, maybe it could be helpful, but since both
>>>>          'cut.default' and '.bincode' return NA if a value isn't
>>>>          within a bin, you could make something like this on your own.
>>>>          Might be worth pitching to R-bugs on the wishlist.
>>>>
>>>>
>>>>
>>>>          On Fri, Sep 17, 2021, 17:45 Leonard Mada via R-help
>>>>          <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>>>
>>>>              Hello List members,
>>>>
>>>>
>>>>              the following improvements would be useful for function
>>>>              cut (and .bincode):
>>>>
>>>>
>>>>              1.) Argument: Include extremes
>>>>              extremes = TRUE
>>>>              if(right == FALSE) {
>>>>              ??? # include also right for last interval;
>>>>              } else {
>>>>              ??? # include also left for first interval;
>>>>              }
>>>>
>>>>
>>>>              2.) Argument: warn = TRUE
>>>>
>>>>              Warn if any values are not included in the intervals.
>>>>
>>>>
>>>>              Motivation:
>>>>              - reduce risk of errors when using function cut();
>>>>
>>>>
>>>>              Sincerely,
>>>>
>>>>
>>>>              Leonard
>>>>
>>>>              ______________________________________________
>>>>              R-help at r-project.org <mailto:R-help at r-project.org>
>>>>              mailing list -- To UNSUBSCRIBE and more, see
>>>>              https://stat.ethz.ch/mailman/listinfo/r-help
>>>>              <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>              PLEASE do read the posting guide
>>>>              http://www.R-project.org/posting-guide.html
>>>>              <http://www.R-project.org/posting-guide.html>
>>>>              and provide commented, minimal, self-contained,
>>>>              reproducible code.
>>>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Sat Sep 18 23:30:53 2021
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Sat, 18 Sep 2021 16:30:53 -0500
Subject: [R] ReadItem: Error
In-Reply-To: <CAGxFJbT6Pd4wiQQ-10MfEtZnhwFpLeMRzJHR0RYWhCkjfPvpTQ@mail.gmail.com>
References: <009b01d7ac98$383e6a60$a8bb3f20$.ref@sbcglobal.net>
 <009b01d7ac98$383e6a60$a8bb3f20$@sbcglobal.net>
 <CAGxFJbT6Pd4wiQQ-10MfEtZnhwFpLeMRzJHR0RYWhCkjfPvpTQ@mail.gmail.com>
Message-ID: <002401d7acd4$767b3830$6371a890$@sbcglobal.net>

> infoRDS("climate_raster.rds")
$version
[1] 2

$writer_version
[1] "3.5.0"

$min_reader_version
[1] "2.3.0"

$format
[1] "xdr"

-----Original Message-----
From: Bert Gunter <bgunter.4567 at gmail.com> 
Sent: Saturday, September 18, 2021 11:40 AM
To: reichmanj at sbcglobal.net
Cc: R-help <R-help at r-project.org>
Subject: Re: [R] ReadItem: Error

Did you try infoRDS() ?  It **may** tell you something useful, though it cannot tell you whether the file is corrupted or not. If you post its results here, someone **may** be able to tell you something informative.

That's all I got.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Sep 18, 2021 at 9:00 AM Jeff Reichman <reichmanj at sbcglobal.net> wrote:
>
> Anyone see what I might be doing wrong? Corrupted rds file maybe. The 
> error would suggest I'm using an older version of R except I'm running 
> both the latest RStudio and R versions.
>
> # Load in the tidyverse, raster, and sf packages
> library(tidyverse)
> library(raster)
> library(sf)
>
> # Read the climate data from an rds file climate <- 
> readRDS("Datasets/climate_raster.rds")
>
> # Have a look at the variables in the climate data
> colnames(climate)
>
> # Convert to SpatialPixelDataFrame for plotting climate_df <- mutate(
>   .data = climate,
>   rasters = map(
>     .x = rasters,
>     ~ as_tibble(as(.x, "SpatialPixelsDataFrame")))) %>%
>   unnest(cols = c(rasters))
>
> > climate <- readRDS("Datasets/climate_raster.rds")
> Error in readRDS("Datasets/climate_raster.rds") :
>   ReadItem: unknown type 0, perhaps written by later version of R
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chr|@ho|d @end|ng |rom p@yctc@org  Sun Sep 19 09:17:09 2021
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Sun, 19 Sep 2021 07:17:09 +0000 (UTC)
Subject: [R] Cacheing of functions from libraries other than the base in
 Rmarkdown
In-Reply-To: <CAGxFJbQB80rU8FyhdYdfJ8w64ToxDaeanRNfpOEvaEeCxeT7ig@mail.gmail.com>
References: <150932547.5211869.1631993168825.JavaMail.zimbra@psyctc.org>
 <CAGxFJbQB80rU8FyhdYdfJ8w64ToxDaeanRNfpOEvaEeCxeT7ig@mail.gmail.com>
Message-ID: <296470557.5610447.1632035829719.JavaMail.zimbra@psyctc.org>

Ah, I completely agree, I should have said! Definitely interested to hear from others here though.

I cannot say how much I have learned here over a now rather frightening length of time: hm, at least 16 
years to judge from the oldest Email I've kept!  Ouch, getting old.

I've put a plea about polymode and Rmd to the ESS help list as equipping my Emacs/ESS to knit whole Rmd
files may give me an alternative and a bit more information.

Thanks Bert (and all for > 16 years of knowledge and occasional high drama here!)

Chris

----- Original Message -----
> From: "Bert Gunter" <bgunter.4567 at gmail.com>
> To: "Chris Evans" <chrishold at psyctc.org>
> Cc: "R-help" <R-help at r-project.org>
> Sent: Saturday, 18 September, 2021 22:01:25
> Subject: Re: [R] Cacheing of functions from libraries other than the base in Rmarkdown

> I think you should post on the RStudio help forums. They have specific areas to
> ask for help on their stuff, at least for some of it. You may wish to wait a
> bit before doing so, though, just to see if someone here responds.

> Bert

> On Sat, Sep 18, 2021, 12:26 PM Chris Evans < [ mailto:chrishold at psyctc.org |
> chrishold at psyctc.org ] > wrote:

>> This question may belong somewhere else, if so, please signpost me and accept
>> apologies.

>> What is happening is that I have a large (for me, > 3k lines) Rmarkdown file
>> with many R code blocks (no other code or
>> engine is used) working on some large datasets. I have some inline r like

>> There are `r n_distinct(tibDat$ID)` participants and `r nrow(tibDat)` rows of
>> data.

>> What I am finding is that even if one knit has worked fine and I change
>> something somewhere and knit again, the second
>> knit is often failing with an error like

>> n_distinct(tibDat$ID) : could not find function "n_distinct"

>> This is not happening for functions like nrow() from base R and it mostly seems
>> to happen to functions from the tidyverse.

>> I think what is happening is some sort of cache corruption presumably caused by
>> the memory demands. I am pretty sure I've
>> seen this before but a long time ago and dealt with it by deleting the files and
>> cache folders created by the knit. That
>> works now too but as knitting the whole file now takes over 20 minutes, I really
>> don't want to have to do that.

>> I have found that replacing things with base functions fixes the problem every
>> time, e.g. replacing `r n_distinct(tibDat$ID)`
>> with `r length(unique(tibDat$ID))` works fine. The other workaround is to
>> compute what you need for the inline
>> computation at the end of the preceding code block, trivial e.g. at the end of
>> the preceding code block:

>> n_distinct(tibDat$ID) -> tmpN
>> ```

>> and then

>> `r tmpN`

>> that works fine so I have my workarounds but I guess I have three questions:

>> 1) do others see this?
>> 2) is there some setting that might, assuming my guess about the cause is
>> correct, increase some storage somewhere and avert this?
>> 3) if it is a bug, where should I report it (as I'm not sure what is causing
>> it!)?

>> Thanks in advance,

>> Chris

>> > sessionInfo()
>> R version 4.1.1 (2021-08-10)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 20.04.3 LTS

>> Matrix products: default
>> BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
>> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3

>> locale:
>> [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8
>> LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 LC_PAPER=en_GB.UTF-8 LC_NAME=C
>> [9] LC_ADDRESS=C LC_TELEPHONE=C LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C

>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base

>> other attached packages:
>> [1] boot_1.3-28 CECPfuns_0.0.0.9041 janitor_2.1.0 lubridate_1.7.10 forcats_0.5.1
>> stringr_1.4.0 dplyr_1.0.7 purrr_0.3.4 readr_2.0.1 tidyr_1.1.3 tibble_3.1.4
>> [12] ggplot2_3.3.5 tidyverse_1.3.1 english_1.2-6 pander_0.6.4

>> loaded via a namespace (and not attached):
>> [1] fs_1.5.0 bit64_4.0.5 RColorBrewer_1.1-2 httr_1.4.2 tools_4.1.1
>> backports_1.2.1 utf8_1.2.2 R6_2.5.1 rpart_4.1-15 Hmisc_4.5-0 DBI_1.1.1
>> [12] colorspace_2.0-2 nnet_7.3-16 withr_2.4.2 tidyselect_1.1.1 gridExtra_2.3
>> bit_4.0.4 compiler_4.1.1 cli_3.0.1 rvest_1.0.1 htmlTable_2.2.1 xml2_1.3.2
>> [23] labeling_0.4.2 scales_1.1.1 checkmate_2.0.0 corrr_0.4.3 odbc_1.3.2
>> digest_0.6.27 readODS_1.7.0 foreign_0.8-81 rmarkdown_2.11 base64enc_0.1-3
>> jpeg_0.1-9
>> [34] pkgconfig_2.0.3 htmltools_0.5.2 dbplyr_2.1.1 fastmap_1.1.0 RJDBC_0.2-8
>> htmlwidgets_1.5.4 rlang_0.4.11 readxl_1.3.1 rstudioapi_0.13 farver_2.1.0
>> generics_0.1.0
>> [45] jsonlite_1.7.2 magrittr_2.0.1 Formula_1.2-4 Matrix_1.3-4 Rcpp_1.0.7
>> munsell_0.5.0 fansi_0.5.0 lifecycle_1.0.0 stringi_1.7.4 yaml_2.2.1
>> snakecase_0.11.0
>> [56] grid_4.1.1 blob_1.2.2 crayon_1.4.1 lattice_0.20-44 haven_2.4.3
>> splines_4.1.1 hms_1.1.0 knitr_1.34 pillar_1.6.2 reprex_2.0.1 glue_1.4.2
>> [67] evaluate_0.14 latticeExtra_0.6-29 data.table_1.14.0 modelr_0.1.8 png_0.1-7
>> vctrs_0.3.8 tzdb_0.1.2 psy_1.1 cellranger_1.1.0 gtable_0.3.0 assertthat_0.2.1
>> [78] xfun_0.26 broom_0.7.9 rsconnect_0.8.24 viridisLite_0.4.0 survival_3.2-13
>> rJava_1.0-4 cluster_2.1.2 ellipsis_0.3.2

>> --
>> Chris Evans (he/him) < [ mailto:chris at psyctc.org | chris at psyctc.org ] > Visiting
>> Professor, University of Sheffield and UDLA, Quito, Ecuador
>> I do some consultation work for the University of Roehampton < [
>> mailto:chris.evans at roehampton.ac.uk | chris.evans at roehampton.ac.uk ] > and
>> other places
>> but < [ mailto:chris at psyctc.org | chris at psyctc.org ] > remains my main Email
>> address. I have a work web site at:
>> [ https://www.psyctc.org/psyctc/ | https://www.psyctc.org/psyctc/ ]
>> and a site I manage for CORE and CORE system trust at:
>> [ http://www.coresystemtrust.org.uk/ | http://www.coresystemtrust.org.uk/ ]
>> I have "semigrated" to France, see:
>> [ https://www.psyctc.org/pelerinage2016/semigrating-to-france/ |
>> https://www.psyctc.org/pelerinage2016/semigrating-to-france/ ]
>> [
>> https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/
>> |
>> https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/
>> ]

>> If you want an Emeeting, I am trying to keep them to Thursdays and my diary is
>> at:
>> [ https://www.psyctc.org/pelerinage2016/ceworkdiary/ |
>> https://www.psyctc.org/pelerinage2016/ceworkdiary/ ]
>> Beware: French time, generally an hour ahead of UK.

>> ______________________________________________
>> [ mailto:R-help at r-project.org | R-help at r-project.org ] mailing list -- To
>> UNSUBSCRIBE and more, see
>> [ https://stat.ethz.ch/mailman/listinfo/r-help |
>> https://stat.ethz.ch/mailman/listinfo/r-help ]
>> PLEASE do read the posting guide [ http://www.r-project.org/posting-guide.html |
>> http://www.R-project.org/posting-guide.html ]
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Chris Evans (he/him) <chris at psyctc.org> Visiting Professor, University of Sheffield and UDLA, Quito, Ecuador
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
   https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sun Sep 19 10:17:51 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sun, 19 Sep 2021 10:17:51 +0200
Subject: [R] how to remove factors from whole dataframe?
Message-ID: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>

Hello,
I woul dlike to remove factors from all the columns of a dataframe.
I can do it n a column at the time with
```

df <- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')),
                 sales = c(13, 16, 22, 27, 34), country=factor(c('a',
'b', 'c', 'd', 'e')))

new_df$region <- droplevels(new_df$region)
```

What is the syntax to remove all factors at once (from all columns)?
For this does not work:
```
> str(df)
'data.frame': 5 obs. of  3 variables:
 $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
 $ sales  : num  13 16 22 27 34
 $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> df = droplevels(df)
> str(df)
'data.frame': 5 obs. of  3 variables:
 $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
 $ sales  : num  13 16 22 27 34
 $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
```
Thank you


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Sep 19 11:32:34 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 19 Sep 2021 21:32:34 +1200
Subject: [R] how to remove factors from whole dataframe?
In-Reply-To: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
References: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
Message-ID: <20210919213234.71053505@rolf-Latitude-E7470>

On Sun, 19 Sep 2021 10:17:51 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> Hello,
> I woul dlike to remove factors from all the columns of a dataframe.

What on earth do you mean by that?  After struggling with your
(inadequate) example for a while, I conjecture that what you want to do
is to drop unused levels from all factor columns in a data frame.

I is that correct?

> I can do it n a column at the time with
> ```
> 
> df <- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')),
>                  sales = c(13, 16, 22, 27, 34), country=factor(c('a',
> 'b', 'c', 'd', 'e')))
> 
> new_df$region <- droplevels(new_df$region)
> ```

Before executing the foregoing command, you would have to create
new_df.  *Perhaps* you intended to do "new_df <- df" initially.

If this is the case, then new_df will be exactly the same as df
after you've applied droplevels() to new_df$region.

Note that droplevels() removes unused levels from the levels of a
factor.  The factor df$region in your confusing example has no unused
levels, so droplevels() has no effect upon it.

> 
> What is the syntax to remove all factors at once (from all columns)?
> For this does not work:
> ```
> > str(df)
> 'data.frame': 5 obs. of  3 variables:
>  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
>  $ sales  : num  13 16 22 27 34
>  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > df = droplevels(df)
> > str(df)
> 'data.frame': 5 obs. of  3 variables:
>  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
>  $ sales  : num  13 16 22 27 34
>  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> ```
> Thank you

I believe the reason you think "this does not work" is that your
example is inadequate.  If the factors in "df" actually had any unused
levels, then droplevels(df) would indeed remove them.

(a) In future please present your questions in a comprehensible manner.

(b) Also please construct your examples so that they are actually
capable of illustrating what you a trying to accomplish.

You are asking others for help.  Have a little consideration for the
helpers, who are giving of their time and effort free of charge!

(c) Note that "df" is a lousy name for a data frame, since it is the
name of a base R function (the density function for the F distribution).
No harm is done in the current context, but such nomenclature can at
times lead to errors "object of type 'closure' is not subsettable"
which mystifies most users.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From drj|m|emon @end|ng |rom gm@||@com  Sun Sep 19 11:36:54 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 19 Sep 2021 19:36:54 +1000
Subject: [R] how to remove factors from whole dataframe?
In-Reply-To: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
References: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
Message-ID: <CA+8X3fUaORRLO7r=42jKNpGDTYbTjxxSLEx1drEHNCuecDsX8w@mail.gmail.com>

Hi Luigi,
It's easy:

df1<-df[,!unlist(lapply(df,is.factor))]

_except_ when there is only one column left, as in your example. In
that case, you will have to coerce the resulting vector back into a
one column data frame.

Jim

On Sun, Sep 19, 2021 at 6:18 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I woul dlike to remove factors from all the columns of a dataframe.
> I can do it n a column at the time with
> ```
>
> df <- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')),
>                  sales = c(13, 16, 22, 27, 34), country=factor(c('a',
> 'b', 'c', 'd', 'e')))
>
> new_df$region <- droplevels(new_df$region)
> ```
>
> What is the syntax to remove all factors at once (from all columns)?
> For this does not work:
> ```
> > str(df)
> 'data.frame': 5 obs. of  3 variables:
>  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
>  $ sales  : num  13 16 22 27 34
>  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > df = droplevels(df)
> > str(df)
> 'data.frame': 5 obs. of  3 variables:
>  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
>  $ sales  : num  13 16 22 27 34
>  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> ```
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sun Sep 19 12:03:27 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sun, 19 Sep 2021 12:03:27 +0200
Subject: [R] how to remove factors from whole dataframe?
In-Reply-To: <CA+8X3fUaORRLO7r=42jKNpGDTYbTjxxSLEx1drEHNCuecDsX8w@mail.gmail.com>
References: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
 <CA+8X3fUaORRLO7r=42jKNpGDTYbTjxxSLEx1drEHNCuecDsX8w@mail.gmail.com>
Message-ID: <CAMk+s2RxaEdgeBPLdvEqi5XgQr_xMgFjLXuT6Hd=Z_RKfeO2uw@mail.gmail.com>

Thank you Jim, but I obtain:
```
> str(df)
'data.frame': 5 obs. of  3 variables:
 $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
 $ sales  : num  13 16 22 27 34
 $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> df1<-df[,!unlist(lapply(df,is.factor))]
> str(df1)
 num [1:5] 13 16 22 27 34
> df1
[1] 13 16 22 27 34
```
I was expecting
```
str(df)
'data.frame': 5 obs. of  3 variables:
 $ region : char "A","B","C","D",..: 1 2 3 4 5
 $ sales  : num  13 16 22 27 34
 $ country: char "a","b","c","d",..: 1 2 3 4 5
```

On Sun, Sep 19, 2021 at 11:37 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> It's easy:
>
> df1<-df[,!unlist(lapply(df,is.factor))]
>
> _except_ when there is only one column left, as in your example. In
> that case, you will have to coerce the resulting vector back into a
> one column data frame.
>
> Jim
>
> On Sun, Sep 19, 2021 at 6:18 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I woul dlike to remove factors from all the columns of a dataframe.
> > I can do it n a column at the time with
> > ```
> >
> > df <- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')),
> >                  sales = c(13, 16, 22, 27, 34), country=factor(c('a',
> > 'b', 'c', 'd', 'e')))
> >
> > new_df$region <- droplevels(new_df$region)
> > ```
> >
> > What is the syntax to remove all factors at once (from all columns)?
> > For this does not work:
> > ```
> > > str(df)
> > 'data.frame': 5 obs. of  3 variables:
> >  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> >  $ sales  : num  13 16 22 27 34
> >  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > > df = droplevels(df)
> > > str(df)
> > 'data.frame': 5 obs. of  3 variables:
> >  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> >  $ sales  : num  13 16 22 27 34
> >  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > ```
> > Thank you
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From drj|m|emon @end|ng |rom gm@||@com  Sun Sep 19 13:12:03 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 19 Sep 2021 21:12:03 +1000
Subject: [R] how to remove factors from whole dataframe?
In-Reply-To: <CAMk+s2RxaEdgeBPLdvEqi5XgQr_xMgFjLXuT6Hd=Z_RKfeO2uw@mail.gmail.com>
References: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
 <CA+8X3fUaORRLO7r=42jKNpGDTYbTjxxSLEx1drEHNCuecDsX8w@mail.gmail.com>
 <CAMk+s2RxaEdgeBPLdvEqi5XgQr_xMgFjLXuT6Hd=Z_RKfeO2uw@mail.gmail.com>
Message-ID: <CA+8X3fVU0558Dw5KWUu=knWiLEBe9NWC0fE_Oeey0O9fSR2JPw@mail.gmail.com>

Hi Luigi,
Okay, so you mean:
I want to change all factors in a dataframe to character class, _not_
remove them.

factor2character<-function(x) if(is.factor(x)) return(as.character(x))
else return(x)
df1<-lapply(df,factor2character)

Jim

On Sun, Sep 19, 2021 at 8:03 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Thank you Jim, but I obtain:
> ```
> > str(df)
> 'data.frame': 5 obs. of  3 variables:
>  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
>  $ sales  : num  13 16 22 27 34
>  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > df1<-df[,!unlist(lapply(df,is.factor))]
> > str(df1)
>  num [1:5] 13 16 22 27 34
> > df1
> [1] 13 16 22 27 34
> ```
> I was expecting
> ```
> str(df)
> 'data.frame': 5 obs. of  3 variables:
>  $ region : char "A","B","C","D",..: 1 2 3 4 5
>  $ sales  : num  13 16 22 27 34
>  $ country: char "a","b","c","d",..: 1 2 3 4 5
> ```
>
> On Sun, Sep 19, 2021 at 11:37 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Luigi,
> > It's easy:
> >
> > df1<-df[,!unlist(lapply(df,is.factor))]
> >
> > _except_ when there is only one column left, as in your example. In
> > that case, you will have to coerce the resulting vector back into a
> > one column data frame.
> >
> > Jim
> >
> > On Sun, Sep 19, 2021 at 6:18 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Hello,
> > > I woul dlike to remove factors from all the columns of a dataframe.
> > > I can do it n a column at the time with
> > > ```
> > >
> > > df <- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')),
> > >                  sales = c(13, 16, 22, 27, 34), country=factor(c('a',
> > > 'b', 'c', 'd', 'e')))
> > >
> > > new_df$region <- droplevels(new_df$region)
> > > ```
> > >
> > > What is the syntax to remove all factors at once (from all columns)?
> > > For this does not work:
> > > ```
> > > > str(df)
> > > 'data.frame': 5 obs. of  3 variables:
> > >  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > >  $ sales  : num  13 16 22 27 34
> > >  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > > > df = droplevels(df)
> > > > str(df)
> > > 'data.frame': 5 obs. of  3 variables:
> > >  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > >  $ sales  : num  13 16 22 27 34
> > >  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > > ```
> > > Thank you
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sun Sep 19 13:27:37 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sun, 19 Sep 2021 13:27:37 +0200
Subject: [R] how to remove factors from whole dataframe?
In-Reply-To: <CA+8X3fVU0558Dw5KWUu=knWiLEBe9NWC0fE_Oeey0O9fSR2JPw@mail.gmail.com>
References: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
 <CA+8X3fUaORRLO7r=42jKNpGDTYbTjxxSLEx1drEHNCuecDsX8w@mail.gmail.com>
 <CAMk+s2RxaEdgeBPLdvEqi5XgQr_xMgFjLXuT6Hd=Z_RKfeO2uw@mail.gmail.com>
 <CA+8X3fVU0558Dw5KWUu=knWiLEBe9NWC0fE_Oeey0O9fSR2JPw@mail.gmail.com>
Message-ID: <CAMk+s2Qo=m=G8mP4Jg2F3zky6ws7mLgQ0ajHyMmarZ_qU6W6wg@mail.gmail.com>

thank you, they both work!

On Sun, Sep 19, 2021 at 1:12 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> Okay, so you mean:
> I want to change all factors in a dataframe to character class, _not_
> remove them.
>
> factor2character<-function(x) if(is.factor(x)) return(as.character(x))
> else return(x)
> df1<-lapply(df,factor2character)
>
> Jim
>
> On Sun, Sep 19, 2021 at 8:03 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Thank you Jim, but I obtain:
> > ```
> > > str(df)
> > 'data.frame': 5 obs. of  3 variables:
> >  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> >  $ sales  : num  13 16 22 27 34
> >  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > > df1<-df[,!unlist(lapply(df,is.factor))]
> > > str(df1)
> >  num [1:5] 13 16 22 27 34
> > > df1
> > [1] 13 16 22 27 34
> > ```
> > I was expecting
> > ```
> > str(df)
> > 'data.frame': 5 obs. of  3 variables:
> >  $ region : char "A","B","C","D",..: 1 2 3 4 5
> >  $ sales  : num  13 16 22 27 34
> >  $ country: char "a","b","c","d",..: 1 2 3 4 5
> > ```
> >
> > On Sun, Sep 19, 2021 at 11:37 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Hi Luigi,
> > > It's easy:
> > >
> > > df1<-df[,!unlist(lapply(df,is.factor))]
> > >
> > > _except_ when there is only one column left, as in your example. In
> > > that case, you will have to coerce the resulting vector back into a
> > > one column data frame.
> > >
> > > Jim
> > >
> > > On Sun, Sep 19, 2021 at 6:18 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Hello,
> > > > I woul dlike to remove factors from all the columns of a dataframe.
> > > > I can do it n a column at the time with
> > > > ```
> > > >
> > > > df <- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')),
> > > >                  sales = c(13, 16, 22, 27, 34), country=factor(c('a',
> > > > 'b', 'c', 'd', 'e')))
> > > >
> > > > new_df$region <- droplevels(new_df$region)
> > > > ```
> > > >
> > > > What is the syntax to remove all factors at once (from all columns)?
> > > > For this does not work:
> > > > ```
> > > > > str(df)
> > > > 'data.frame': 5 obs. of  3 variables:
> > > >  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > > >  $ sales  : num  13 16 22 27 34
> > > >  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > > > > df = droplevels(df)
> > > > > str(df)
> > > > 'data.frame': 5 obs. of  3 variables:
> > > >  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > > >  $ sales  : num  13 16 22 27 34
> > > >  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > > > ```
> > > > Thank you
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi



-- 
Best regards,
Luigi


From d@go@t|no|@b| @end|ng |rom gm@||@com  Sun Sep 19 12:42:26 2021
From: d@go@t|no|@b| @end|ng |rom gm@||@com (Fabio D'Agostino)
Date: Sun, 19 Sep 2021 12:42:26 +0200
Subject: [R] how to remove factors from whole dataframe?
In-Reply-To: <CAMk+s2RxaEdgeBPLdvEqi5XgQr_xMgFjLXuT6Hd=Z_RKfeO2uw@mail.gmail.com>
References: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
 <CA+8X3fUaORRLO7r=42jKNpGDTYbTjxxSLEx1drEHNCuecDsX8w@mail.gmail.com>
 <CAMk+s2RxaEdgeBPLdvEqi5XgQr_xMgFjLXuT6Hd=Z_RKfeO2uw@mail.gmail.com>
Message-ID: <CADUGNTzuc9Dn+rJUuLn7v0KeoYK=u5=BeY4zQH+GTawmsQRocg@mail.gmail.com>

Hi Luigi,
try this
library(taRifx)
df_noFact <- remove.factors(df)
str(df_noFact)
'data.frame': 5 obs. of  3 variables:
 $ region : chr  "A" "B" "C" "D" ...
 $ sales  : num  13 16 22 27 34
 $ country: chr  "a" "b" "c" "d" ...
I hope this helps
Fabio

Il giorno dom 19 set 2021 alle ore 12:04 Luigi Marongiu <
marongiu.luigi at gmail.com> ha scritto:

> Thank you Jim, but I obtain:
> ```
> > str(df)
> 'data.frame': 5 obs. of  3 variables:
>  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
>  $ sales  : num  13 16 22 27 34
>  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > df1<-df[,!unlist(lapply(df,is.factor))]
> > str(df1)
>  num [1:5] 13 16 22 27 34
> > df1
> [1] 13 16 22 27 34
> ```
> I was expecting
> ```
> str(df)
> 'data.frame': 5 obs. of  3 variables:
>  $ region : char "A","B","C","D",..: 1 2 3 4 5
>  $ sales  : num  13 16 22 27 34
>  $ country: char "a","b","c","d",..: 1 2 3 4 5
> ```
>
> On Sun, Sep 19, 2021 at 11:37 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Luigi,
> > It's easy:
> >
> > df1<-df[,!unlist(lapply(df,is.factor))]
> >
> > _except_ when there is only one column left, as in your example. In
> > that case, you will have to coerce the resulting vector back into a
> > one column data frame.
> >
> > Jim
> >
> > On Sun, Sep 19, 2021 at 6:18 PM Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> > >
> > > Hello,
> > > I woul dlike to remove factors from all the columns of a dataframe.
> > > I can do it n a column at the time with
> > > ```
> > >
> > > df <- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')),
> > >                  sales = c(13, 16, 22, 27, 34), country=factor(c('a',
> > > 'b', 'c', 'd', 'e')))
> > >
> > > new_df$region <- droplevels(new_df$region)
> > > ```
> > >
> > > What is the syntax to remove all factors at once (from all columns)?
> > > For this does not work:
> > > ```
> > > > str(df)
> > > 'data.frame': 5 obs. of  3 variables:
> > >  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > >  $ sales  : num  13 16 22 27 34
> > >  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > > > df = droplevels(df)
> > > > str(df)
> > > 'data.frame': 5 obs. of  3 variables:
> > >  $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > >  $ sales  : num  13 16 22 27 34
> > >  $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > > ```
> > > Thank you
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Sep 19 16:22:48 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 19 Sep 2021 15:22:48 +0100
Subject: [R] how to remove factors from whole dataframe?
In-Reply-To: <CAMk+s2RxaEdgeBPLdvEqi5XgQr_xMgFjLXuT6Hd=Z_RKfeO2uw@mail.gmail.com>
References: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
 <CA+8X3fUaORRLO7r=42jKNpGDTYbTjxxSLEx1drEHNCuecDsX8w@mail.gmail.com>
 <CAMk+s2RxaEdgeBPLdvEqi5XgQr_xMgFjLXuT6Hd=Z_RKfeO2uw@mail.gmail.com>
Message-ID: <a9763900-5958-c063-4002-ffa824852a5b@sapo.pt>

Hello,

Using Jim's lapply(., is.factor) but simplified, you could do


df1 <- df
i <- sapply(df1, is.factor)
df1[i] <- lapply(df1[i], as.character)


a one-liner modifying df, not df1 is


df[sapply(df, is.factor)] <- lapply(df[sapply(df, is.factor)], as.character)


Hope this helps,

Rui Barradas

?s 11:03 de 19/09/21, Luigi Marongiu escreveu:
> Thank you Jim, but I obtain:
> ```
>> str(df)
> 'data.frame': 5 obs. of  3 variables:
>   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
>   $ sales  : num  13 16 22 27 34
>   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
>> df1<-df[,!unlist(lapply(df,is.factor))]
>> str(df1)
>   num [1:5] 13 16 22 27 34
>> df1
> [1] 13 16 22 27 34
> ```
> I was expecting
> ```
> str(df)
> 'data.frame': 5 obs. of  3 variables:
>   $ region : char "A","B","C","D",..: 1 2 3 4 5
>   $ sales  : num  13 16 22 27 34
>   $ country: char "a","b","c","d",..: 1 2 3 4 5
> ```
> 
> On Sun, Sep 19, 2021 at 11:37 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Luigi,
>> It's easy:
>>
>> df1<-df[,!unlist(lapply(df,is.factor))]
>>
>> _except_ when there is only one column left, as in your example. In
>> that case, you will have to coerce the resulting vector back into a
>> one column data frame.
>>
>> Jim
>>
>> On Sun, Sep 19, 2021 at 6:18 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>>
>>> Hello,
>>> I woul dlike to remove factors from all the columns of a dataframe.
>>> I can do it n a column at the time with
>>> ```
>>>
>>> df <- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')),
>>>                   sales = c(13, 16, 22, 27, 34), country=factor(c('a',
>>> 'b', 'c', 'd', 'e')))
>>>
>>> new_df$region <- droplevels(new_df$region)
>>> ```
>>>
>>> What is the syntax to remove all factors at once (from all columns)?
>>> For this does not work:
>>> ```
>>>> str(df)
>>> 'data.frame': 5 obs. of  3 variables:
>>>   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
>>>   $ sales  : num  13 16 22 27 34
>>>   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
>>>> df = droplevels(df)
>>>> str(df)
>>> 'data.frame': 5 obs. of  3 variables:
>>>   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
>>>   $ sales  : num  13 16 22 27 34
>>>   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
>>> ```
>>> Thank you
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sun Sep 19 16:42:52 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sun, 19 Sep 2021 17:42:52 +0300
Subject: [R] [Questionnaire] Standardized Options: Justify/Alignment
Message-ID: <a90d81a7-e945-eca8-5dc7-30297a881b32@syonic.eu>

Dear R users,


I have started to work on an improved version of the format.ftable 
function. The code and ideas should be reused to improve other R 
functions (enabling more advanced format of the character output).

However, there are a number of open questions. These are focused on 
standardizing the names and the options of the various arguments used to 
format the output. A separate post will address questions related to 
technical and design decisions.


Note:

The arguments are passed to various helper functions. It may be tedious 
to modify once implemented. Furthermore, package developers should be 
encouraged to use the standardized names and options as well (and may 
use the helper functions as well).


The users are also encouraged to test the various options. Some code to 
enable testing is available at the end of this post.


Structure of "Questionnaire":

a.) Answers should follow a Likert-type scale:
# Strongly disagree (on option ...);
# Disagree (on option ...);
# Agree (on option ...);
# Strongly agree (on option ...);

b.) Motivation: ...

c.) Other comments: ...


### The "Questionnaire"


1.) "MiddleTop", "MiddleBottom" vs "Middle"

Example problem: positioning 3 lines of text on 4 rows;

Workaround: user can easily prepend or append a newline to the relevant 
names, forcing the desired behaviour. However, there is a helper 
function to merge (cbind) 2 string matrices and it may be tedious for a 
user to modify all names. [but this is less used in ftable]

Disadvantages: the 2 variants "break" pmatch()!


2.) Lower case vs Upper case

Motivation: the options for most named algorithms are uppercase and are 
likely to remain uppercase;

Example: option = c("MyName1", "MyName2", "Fields1", "Fields2", ...);

Existing options in format.ftable: are lowercase, "left", "right", 
*"centre"*;


3.) Standardized Names

3.a.) Arguments:
justify = ... or align = ...?
pos = ... or position = ... or valign = ... ?

3.b.) Options:
- "left", "right", "centre" vs "center"?
- using both "centre" and "center" break pmatch();
- "top", "bottom", "middle";

Native-English speakers should review this question as well.

Note:
The new function enables to justify differently both the row-names and 
the factor levels:
- there are actually 2 arguments: justify="left", justify.lvl="c"; # 
with centre vs center issue!


I do not now if there is any facility to run such questionnaires through 
R. My resources are also rather limited - if anyone is willing to 
provide help - I would be very happy.


Sincerely,


Leonard


===========

### Test Code

The latest version of the ftable2 function (contains a fix) and the 
needed helper functions are available on Github:
https://github.com/discoleo/R/blob/master/Stat/Tools.Data.R


### Some Data
mtcars$carbCtg = cut(mtcars$carb, c(1, 2, 4, +Inf), right=FALSE)
# Alternative:
# mtcars$carbCtg = cut(mtcars$carb, c(1, 2, 4, 8), include.lowest=TRUE)
tbl = with(mtcars, table(cyl, hp, carbCtg, gear))
id = c(1,3,4);

# Note: the names can be modified to test various scenarios
xnm = c("Long\nname: ", "", "Extremely\nlong\nname: ")
xnm = paste0(xnm, names(dimnames(tbl))[id])
names(dimnames(tbl))[id] = xnm;
ftbl = ftable(tbl, row.vars = id)

### Test: FTABLE
ftable2(ftbl, sep=" | ", justify="left", justify.lvl="c", pos="Top", 
split="\n")


From ccberry @end|ng |rom he@|th@uc@d@edu  Sun Sep 19 19:28:49 2021
From: ccberry @end|ng |rom he@|th@uc@d@edu (Berry, Charles)
Date: Sun, 19 Sep 2021 17:28:49 +0000
Subject: [R] Cacheing of functions from libraries other than the base in
 Rmarkdown
In-Reply-To: <150932547.5211869.1631993168825.JavaMail.zimbra@psyctc.org>
References: <150932547.5211869.1631993168825.JavaMail.zimbra@psyctc.org>
Message-ID: <7D79378D-5C5D-47B1-80F6-9EBC8D63DDA1@health.ucsd.edu>

Chris,


> On Sep 18, 2021, at 12:26 PM, Chris Evans <chrishold at psyctc.org> wrote:
> 
> This question may belong somewhere else, if so, please signpost me and accept apologies.
> 
> What is happening is that I have a large (for me, > 3k lines) Rmarkdown file with many R code blocks (no other code or 
> engine is used) working on some large datasets.  I have some inline r like 
> 
>   There are `r n_distinct(tibDat$ID)` participants and `r nrow(tibDat)` rows of data.
> 
> What I am finding is that even if one knit has worked fine and I change something somewhere and knit again, the second
> knit is often failing with an error like
> 
>   n_distinct(tibDat$ID) : could not find function "n_distinct"
> 
> This is not happening for functions like nrow() from base R and it mostly seems to happen to functions from the tidyverse.
> 
> I think what is happening is some sort of cache corruption presumably caused by the memory demands.  I am pretty sure I've
> seen this before but a long time ago and dealt with it by deleting the files and cache folders created by the knit. 

Caching things that depend on libraries is known to be tricky.

Specifically, it is advised that "loading packages via library() in a cached chunk and these packages will be used by uncached chunks" is something you should not do.  I suspect that this is the problem with your inline chunk.

I have to reread things like:

	https://yihui.org/knitr/demo/cache/

and relevant parts of the manual to be sure I didn't mess something up and maybe you should look at that and the manual yet another time. 

HTH,

Chuck


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep 19 19:45:03 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 19 Sep 2021 10:45:03 -0700
Subject: [R] Cacheing of functions from libraries other than the base in
 Rmarkdown
In-Reply-To: <7D79378D-5C5D-47B1-80F6-9EBC8D63DDA1@health.ucsd.edu>
References: <150932547.5211869.1631993168825.JavaMail.zimbra@psyctc.org>
 <7D79378D-5C5D-47B1-80F6-9EBC8D63DDA1@health.ucsd.edu>
Message-ID: <C2C10B80-C85D-4E46-AE5A-04FD66CFF256@dcn.davis.ca.us>

I avoid knitr (Rmarkdown uses knitr) caching like the plague. If I want caching, I do it myself (with or without the aid of one of a data caching package).

On September 19, 2021 10:28:49 AM PDT, "Berry, Charles" <ccberry at health.ucsd.edu> wrote:
>Chris,
>
>
>> On Sep 18, 2021, at 12:26 PM, Chris Evans <chrishold at psyctc.org> wrote:
>> 
>> This question may belong somewhere else, if so, please signpost me and accept apologies.
>> 
>> What is happening is that I have a large (for me, > 3k lines) Rmarkdown file with many R code blocks (no other code or 
>> engine is used) working on some large datasets.  I have some inline r like 
>> 
>>   There are `r n_distinct(tibDat$ID)` participants and `r nrow(tibDat)` rows of data.
>> 
>> What I am finding is that even if one knit has worked fine and I change something somewhere and knit again, the second
>> knit is often failing with an error like
>> 
>>   n_distinct(tibDat$ID) : could not find function "n_distinct"
>> 
>> This is not happening for functions like nrow() from base R and it mostly seems to happen to functions from the tidyverse.
>> 
>> I think what is happening is some sort of cache corruption presumably caused by the memory demands.  I am pretty sure I've
>> seen this before but a long time ago and dealt with it by deleting the files and cache folders created by the knit. 
>
>Caching things that depend on libraries is known to be tricky.
>
>Specifically, it is advised that "loading packages via library() in a cached chunk and these packages will be used by uncached chunks" is something you should not do.  I suspect that this is the problem with your inline chunk.
>
>I have to reread things like:
>
>	https://yihui.org/knitr/demo/cache/
>
>and relevant parts of the manual to be sure I didn't mess something up and maybe you should look at that and the manual yet another time. 
>
>HTH,
>
>Chuck
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From chr|@ho|d @end|ng |rom p@yctc@org  Sun Sep 19 19:49:50 2021
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Sun, 19 Sep 2021 17:49:50 +0000 (UTC)
Subject: [R] Cacheing of functions from libraries other than the base in
 Rmarkdown
In-Reply-To: <C2C10B80-C85D-4E46-AE5A-04FD66CFF256@dcn.davis.ca.us>
References: <150932547.5211869.1631993168825.JavaMail.zimbra@psyctc.org>
 <7D79378D-5C5D-47B1-80F6-9EBC8D63DDA1@health.ucsd.edu>
 <C2C10B80-C85D-4E46-AE5A-04FD66CFF256@dcn.davis.ca.us>
Message-ID: <1269131926.6047461.1632073790230.JavaMail.zimbra@psyctc.org>

Can you point me to an example of this?  I definitely need cacheing for this work but I don't know
about data cacheing packages.  Might be one of those things where my learning time might outweigh
time saved but I lost a fair bit of time by being stupid with this so perhaps not.

----- Original Message -----
> From: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
> To: r-help at r-project.org, "Charles Berry" <ccberry at health.ucsd.edu>, "Chris Evans" <chrishold at psyctc.org>
> Cc: "R-help" <R-help at r-project.org>
> Sent: Sunday, 19 September, 2021 19:45:03
> Subject: Re: [R] Cacheing of functions from libraries other than the base in Rmarkdown

> I avoid knitr (Rmarkdown uses knitr) caching like the plague. If I want caching,
> I do it myself (with or without the aid of one of a data caching package).
> 
> On September 19, 2021 10:28:49 AM PDT, "Berry, Charles"
> <ccberry at health.ucsd.edu> wrote:
>>Chris,
>>
>>
>>> On Sep 18, 2021, at 12:26 PM, Chris Evans <chrishold at psyctc.org> wrote:
>>> 
>>> This question may belong somewhere else, if so, please signpost me and accept
>>> apologies.
>>> 
>>> What is happening is that I have a large (for me, > 3k lines) Rmarkdown file
>>> with many R code blocks (no other code or
>>> engine is used) working on some large datasets.  I have some inline r like
>>> 
>>>   There are `r n_distinct(tibDat$ID)` participants and `r nrow(tibDat)` rows of
>>>   data.
>>> 
>>> What I am finding is that even if one knit has worked fine and I change
>>> something somewhere and knit again, the second
>>> knit is often failing with an error like
>>> 
>>>   n_distinct(tibDat$ID) : could not find function "n_distinct"
>>> 
>>> This is not happening for functions like nrow() from base R and it mostly seems
>>> to happen to functions from the tidyverse.
>>> 
>>> I think what is happening is some sort of cache corruption presumably caused by
>>> the memory demands.  I am pretty sure I've
>>> seen this before but a long time ago and dealt with it by deleting the files and
>>> cache folders created by the knit.
>>
>>Caching things that depend on libraries is known to be tricky.
>>
>>Specifically, it is advised that "loading packages via library() in a cached
>>chunk and these packages will be used by uncached chunks" is something you
>>should not do.  I suspect that this is the problem with your inline chunk.
>>
>>I have to reread things like:
>>
>>	https://yihui.org/knitr/demo/cache/
>>
>>and relevant parts of the manual to be sure I didn't mess something up and maybe
>>you should look at that and the manual yet another time.
>>
>>HTH,
>>
>>Chuck
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Sent from my phone. Please excuse my brevity.

-- 
Chris Evans (he/him) <chris at psyctc.org> Visiting Professor, University of Sheffield and UDLA, Quito, Ecuador
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
   https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep 19 20:38:21 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 19 Sep 2021 11:38:21 -0700
Subject: [R] Cacheing of functions from libraries other than the base in
 Rmarkdown
In-Reply-To: <1269131926.6047461.1632073790230.JavaMail.zimbra@psyctc.org>
References: <150932547.5211869.1631993168825.JavaMail.zimbra@psyctc.org>
 <7D79378D-5C5D-47B1-80F6-9EBC8D63DDA1@health.ucsd.edu>
 <C2C10B80-C85D-4E46-AE5A-04FD66CFF256@dcn.davis.ca.us>
 <1269131926.6047461.1632073790230.JavaMail.zimbra@psyctc.org>
Message-ID: <53F5E27E-4E7F-4CC7-8B71-B059395F36A6@dcn.davis.ca.us>

You should Google "r cache" yourself, but I have used memoise, R.cache, drake, and targets, and I rate targets as #1 and R.cache as #2.

If you try to retrieve old cache objects (more than a few weeks, say) you are likely to run into package/class changes that could cause the kind of issues you are having to crop up. Try to archive results in an interchange format like csv, parquet, or feather to future-proof your work as a separate task from caching.

On September 19, 2021 10:49:50 AM PDT, Chris Evans <chrishold at psyctc.org> wrote:
>Can you point me to an example of this?  I definitely need cacheing for this work but I don't know
>about data cacheing packages.  Might be one of those things where my learning time might outweigh
>time saved but I lost a fair bit of time by being stupid with this so perhaps not.
>
>----- Original Message -----
>> From: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
>> To: r-help at r-project.org, "Charles Berry" <ccberry at health.ucsd.edu>, "Chris Evans" <chrishold at psyctc.org>
>> Cc: "R-help" <R-help at r-project.org>
>> Sent: Sunday, 19 September, 2021 19:45:03
>> Subject: Re: [R] Cacheing of functions from libraries other than the base in Rmarkdown
>
>> I avoid knitr (Rmarkdown uses knitr) caching like the plague. If I want caching,
>> I do it myself (with or without the aid of one of a data caching package).
>> 
>> On September 19, 2021 10:28:49 AM PDT, "Berry, Charles"
>> <ccberry at health.ucsd.edu> wrote:
>>>Chris,
>>>
>>>
>>>> On Sep 18, 2021, at 12:26 PM, Chris Evans <chrishold at psyctc.org> wrote:
>>>> 
>>>> This question may belong somewhere else, if so, please signpost me and accept
>>>> apologies.
>>>> 
>>>> What is happening is that I have a large (for me, > 3k lines) Rmarkdown file
>>>> with many R code blocks (no other code or
>>>> engine is used) working on some large datasets.  I have some inline r like
>>>> 
>>>>   There are `r n_distinct(tibDat$ID)` participants and `r nrow(tibDat)` rows of
>>>>   data.
>>>> 
>>>> What I am finding is that even if one knit has worked fine and I change
>>>> something somewhere and knit again, the second
>>>> knit is often failing with an error like
>>>> 
>>>>   n_distinct(tibDat$ID) : could not find function "n_distinct"
>>>> 
>>>> This is not happening for functions like nrow() from base R and it mostly seems
>>>> to happen to functions from the tidyverse.
>>>> 
>>>> I think what is happening is some sort of cache corruption presumably caused by
>>>> the memory demands.  I am pretty sure I've
>>>> seen this before but a long time ago and dealt with it by deleting the files and
>>>> cache folders created by the knit.
>>>
>>>Caching things that depend on libraries is known to be tricky.
>>>
>>>Specifically, it is advised that "loading packages via library() in a cached
>>>chunk and these packages will be used by uncached chunks" is something you
>>>should not do.  I suspect that this is the problem with your inline chunk.
>>>
>>>I have to reread things like:
>>>
>>>	https://yihui.org/knitr/demo/cache/
>>>
>>>and relevant parts of the manual to be sure I didn't mess something up and maybe
>>>you should look at that and the manual yet another time.
>>>
>>>HTH,
>>>
>>>Chuck
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Sent from my phone. Please excuse my brevity.
>

-- 
Sent from my phone. Please excuse my brevity.


From chr|@ @end|ng |rom p@yctc@org  Sun Sep 19 19:49:26 2021
From: chr|@ @end|ng |rom p@yctc@org (Chris Evans)
Date: Sun, 19 Sep 2021 17:49:26 +0000 (UTC)
Subject: [R] Cacheing of functions from libraries other than the base in
 Rmarkdown
Message-ID: <1773438907.6047396.1632073766383.JavaMail.zimbra@psyctc.org>

[Damn: now I'm forgetting that r-help has reply-to the individual respondent, 
sorry for duplicate Email Charles but I'm sure this should be in the archives.] 

Excellent: I'm sure that's it. I hadn't noticed that I'd loaded libraries in a 
cached code block. I thought I'd learned not to do that: can't believe I didn't 
check that. 

Thanks, another hole in a foot: (re)-read the pertinent manual before assuming 
something is broken Christopher! 

Very best all, 

C 

----- Original Message ----- 
> From: "Berry, Charles" <ccberry at health.ucsd.edu> 
> To: "Chris Evans" <chrishold at psyctc.org> 
> Cc: "R-help" <R-help at r-project.org> 
> Sent: Sunday, 19 September, 2021 19:28:49 
> Subject: Re: Cacheing of functions from libraries other than the base in Rmarkdown 

> Chris, 
> 
> 
>> On Sep 18, 2021, at 12:26 PM, Chris Evans <chrishold at psyctc.org> wrote: 
>> 
>> This question may belong somewhere else, if so, please signpost me and accept 
>> apologies. 
>> 
>> What is happening is that I have a large (for me, > 3k lines) Rmarkdown file 
>> with many R code blocks (no other code or 
>> engine is used) working on some large datasets. I have some inline r like 
>> 
>> There are `r n_distinct(tibDat$ID)` participants and `r nrow(tibDat)` rows of 
>> data. 
>> 
>> What I am finding is that even if one knit has worked fine and I change 
>> something somewhere and knit again, the second 
>> knit is often failing with an error like 
>> 
>> n_distinct(tibDat$ID) : could not find function "n_distinct" 
>> 
>> This is not happening for functions like nrow() from base R and it mostly seems 
>> to happen to functions from the tidyverse. 
>> 
>> I think what is happening is some sort of cache corruption presumably caused by 
>> the memory demands. I am pretty sure I've 
>> seen this before but a long time ago and dealt with it by deleting the files and 
>> cache folders created by the knit. 
> 
> Caching things that depend on libraries is known to be tricky. 
> 
> Specifically, it is advised that "loading packages via library() in a cached 
> chunk and these packages will be used by uncached chunks" is something you 
> should not do. I suspect that this is the problem with your inline chunk. 
> 
> I have to reread things like: 
> 
> https://yihui.org/knitr/demo/cache/ 
> 
> and relevant parts of the manual to be sure I didn't mess something up and maybe 
> you should look at that and the manual yet another time. 
> 
> HTH, 
> 
> Chuck 

-- 
Chris Evans (he/him) <chris at psyctc.org> Visiting Professor, University of Sheffield and UDLA, Quito, Ecuador 
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places 
but <chris at psyctc.org> remains my main Email address. I have a work web site at: 
https://www.psyctc.org/psyctc/ 
and a site I manage for CORE and CORE system trust at: 
http://www.coresystemtrust.org.uk/ 
I have "semigrated" to France, see: 
https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/ 

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at: 
https://www.psyctc.org/pelerinage2016/ceworkdiary/ 
Beware: French time, generally an hour ahead of UK. 

	[[alternative HTML version deleted]]


From h@k|n@mz4774 @end|ng |rom y@hoo@com  Sun Sep 19 21:53:22 2021
From: h@k|n@mz4774 @end|ng |rom y@hoo@com (haki namz)
Date: Sun, 19 Sep 2021 19:53:22 +0000 (UTC)
Subject: [R] problem solution
References: <1594393074.1327176.1632081202136.ref@mail.yahoo.com>
Message-ID: <1594393074.1327176.1632081202136@mail.yahoo.com>

Hello,please guide me where I can find the solution file of the R built-in datasets.regards
	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sun Sep 19 22:42:38 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sun, 19 Sep 2021 22:42:38 +0200
Subject: [R] how to remove factors from whole dataframe?
In-Reply-To: <a9763900-5958-c063-4002-ffa824852a5b@sapo.pt>
References: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
 <CA+8X3fUaORRLO7r=42jKNpGDTYbTjxxSLEx1drEHNCuecDsX8w@mail.gmail.com>
 <CAMk+s2RxaEdgeBPLdvEqi5XgQr_xMgFjLXuT6Hd=Z_RKfeO2uw@mail.gmail.com>
 <a9763900-5958-c063-4002-ffa824852a5b@sapo.pt>
Message-ID: <CAMk+s2RSwv8aO-1Wb8AGLM8Qw8AL1KLm3NN2V0V2ju48WkseVQ@mail.gmail.com>

Awesome, thanks!

On Sun, Sep 19, 2021 at 4:22 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Using Jim's lapply(., is.factor) but simplified, you could do
>
>
> df1 <- df
> i <- sapply(df1, is.factor)
> df1[i] <- lapply(df1[i], as.character)
>
>
> a one-liner modifying df, not df1 is
>
>
> df[sapply(df, is.factor)] <- lapply(df[sapply(df, is.factor)], as.character)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 11:03 de 19/09/21, Luigi Marongiu escreveu:
> > Thank you Jim, but I obtain:
> > ```
> >> str(df)
> > 'data.frame': 5 obs. of  3 variables:
> >   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> >   $ sales  : num  13 16 22 27 34
> >   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> >> df1<-df[,!unlist(lapply(df,is.factor))]
> >> str(df1)
> >   num [1:5] 13 16 22 27 34
> >> df1
> > [1] 13 16 22 27 34
> > ```
> > I was expecting
> > ```
> > str(df)
> > 'data.frame': 5 obs. of  3 variables:
> >   $ region : char "A","B","C","D",..: 1 2 3 4 5
> >   $ sales  : num  13 16 22 27 34
> >   $ country: char "a","b","c","d",..: 1 2 3 4 5
> > ```
> >
> > On Sun, Sep 19, 2021 at 11:37 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> Hi Luigi,
> >> It's easy:
> >>
> >> df1<-df[,!unlist(lapply(df,is.factor))]
> >>
> >> _except_ when there is only one column left, as in your example. In
> >> that case, you will have to coerce the resulting vector back into a
> >> one column data frame.
> >>
> >> Jim
> >>
> >> On Sun, Sep 19, 2021 at 6:18 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >>>
> >>> Hello,
> >>> I woul dlike to remove factors from all the columns of a dataframe.
> >>> I can do it n a column at the time with
> >>> ```
> >>>
> >>> df <- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')),
> >>>                   sales = c(13, 16, 22, 27, 34), country=factor(c('a',
> >>> 'b', 'c', 'd', 'e')))
> >>>
> >>> new_df$region <- droplevels(new_df$region)
> >>> ```
> >>>
> >>> What is the syntax to remove all factors at once (from all columns)?
> >>> For this does not work:
> >>> ```
> >>>> str(df)
> >>> 'data.frame': 5 obs. of  3 variables:
> >>>   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> >>>   $ sales  : num  13 16 22 27 34
> >>>   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> >>>> df = droplevels(df)
> >>>> str(df)
> >>> 'data.frame': 5 obs. of  3 variables:
> >>>   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> >>>   $ sales  : num  13 16 22 27 34
> >>>   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> >>> ```
> >>> Thank you
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >



-- 
Best regards,
Luigi


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Sep 19 23:04:51 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 19 Sep 2021 22:04:51 +0100
Subject: [R] problem solution
In-Reply-To: <1594393074.1327176.1632081202136@mail.yahoo.com>
References: <1594393074.1327176.1632081202136.ref@mail.yahoo.com>
 <1594393074.1327176.1632081202136@mail.yahoo.com>
Message-ID: <675d61d3-ffc6-69ed-4d06-4661c34c746b@sapo.pt>

Hello,

datasets is a base R package of built-in data sets (sorry), not a list 
of problems.
There is no solution file.

If you have course problems that use base R datasets package, please 
note that according to the posting guide R-Help doesn't do homework. You 
should ask your instructor/teacher or your colleagues or find other 
places to get on-line help.

Hope this helps,

Rui Barradas


?s 20:53 de 19/09/21, haki namz via R-help escreveu:
> Hello,please guide me where I can find the solution file of the R built-in datasets.regards
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @v|gro@@ @end|ng |rom ver|zon@net  Sun Sep 19 23:13:38 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sun, 19 Sep 2021 17:13:38 -0400
Subject: [R] how to remove factors from whole dataframe?
In-Reply-To: <CAMk+s2RSwv8aO-1Wb8AGLM8Qw8AL1KLm3NN2V0V2ju48WkseVQ@mail.gmail.com>
References: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
 <CA+8X3fUaORRLO7r=42jKNpGDTYbTjxxSLEx1drEHNCuecDsX8w@mail.gmail.com>
 <CAMk+s2RxaEdgeBPLdvEqi5XgQr_xMgFjLXuT6Hd=Z_RKfeO2uw@mail.gmail.com>
 <a9763900-5958-c063-4002-ffa824852a5b@sapo.pt>
 <CAMk+s2RSwv8aO-1Wb8AGLM8Qw8AL1KLm3NN2V0V2ju48WkseVQ@mail.gmail.com>
Message-ID: <01a801d7ad9b$373ade60$a5b09b20$@verizon.net>

Glad we have solutions BUT I note that the more abstract question is how to convert any columns that are factors to their base type and that may well NOT be character. They can be integers or doubles or complex or Boolean and maybe even raw. 

So undoing factorization may require using something like typeof() to get the base type and then depending on what final type you have, you may have to do things like as.integer(as.character(the_factor)) to get it as an integer and for a logical, as.logical(factor(c(TRUE, TRUE, FALSE, TRUE, FALSE))) and so on.

This seems like a fairly basic need so I wonder if anyone has already done it. I can see a fairly straightforward way to build a string and use eval and I suspect others might use something else like do.call() and yet others use multiple if statements or a case_when or something




-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
Sent: Sunday, September 19, 2021 4:43 PM
To: Rui Barradas <ruipbarradas at sapo.pt>
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] how to remove factors from whole dataframe?

Awesome, thanks!

On Sun, Sep 19, 2021 at 4:22 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Using Jim's lapply(., is.factor) but simplified, you could do
>
>
> df1 <- df
> i <- sapply(df1, is.factor)
> df1[i] <- lapply(df1[i], as.character)
>
>
> a one-liner modifying df, not df1 is
>
>
> df[sapply(df, is.factor)] <- lapply(df[sapply(df, is.factor)], 
> as.character)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 11:03 de 19/09/21, Luigi Marongiu escreveu:
> > Thank you Jim, but I obtain:
> > ```
> >> str(df)
> > 'data.frame': 5 obs. of  3 variables:
> >   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> >   $ sales  : num  13 16 22 27 34
> >   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> >> df1<-df[,!unlist(lapply(df,is.factor))]
> >> str(df1)
> >   num [1:5] 13 16 22 27 34
> >> df1
> > [1] 13 16 22 27 34
> > ```
> > I was expecting
> > ```
> > str(df)
> > 'data.frame': 5 obs. of  3 variables:
> >   $ region : char "A","B","C","D",..: 1 2 3 4 5
> >   $ sales  : num  13 16 22 27 34
> >   $ country: char "a","b","c","d",..: 1 2 3 4 5 ```
> >
> > On Sun, Sep 19, 2021 at 11:37 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> Hi Luigi,
> >> It's easy:
> >>
> >> df1<-df[,!unlist(lapply(df,is.factor))]
> >>
> >> _except_ when there is only one column left, as in your example. In 
> >> that case, you will have to coerce the resulting vector back into a 
> >> one column data frame.
> >>
> >> Jim
> >>
> >> On Sun, Sep 19, 2021 at 6:18 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >>>
> >>> Hello,
> >>> I woul dlike to remove factors from all the columns of a dataframe.
> >>> I can do it n a column at the time with ```
> >>>
> >>> df <- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')),
> >>>                   sales = c(13, 16, 22, 27, 34), 
> >>> country=factor(c('a', 'b', 'c', 'd', 'e')))
> >>>
> >>> new_df$region <- droplevels(new_df$region) ```
> >>>
> >>> What is the syntax to remove all factors at once (from all columns)?
> >>> For this does not work:
> >>> ```
> >>>> str(df)
> >>> 'data.frame': 5 obs. of  3 variables:
> >>>   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> >>>   $ sales  : num  13 16 22 27 34
> >>>   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> >>>> df = droplevels(df)
> >>>> str(df)
> >>> 'data.frame': 5 obs. of  3 variables:
> >>>   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> >>>   $ sales  : num  13 16 22 27 34
> >>>   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5 ``` 
> >>> Thank you
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide 
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >



--
Best regards,
Luigi

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep 19 23:19:27 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 19 Sep 2021 14:19:27 -0700
Subject: [R] problem solution
In-Reply-To: <1594393074.1327176.1632081202136@mail.yahoo.com>
References: <1594393074.1327176.1632081202136.ref@mail.yahoo.com>
 <1594393074.1327176.1632081202136@mail.yahoo.com>
Message-ID: <FFBD0E2B-32F6-4072-8654-B8FD45BD62DF@dcn.davis.ca.us>

This question is not clear. What do you mean by solution file? You can find documentation for individual datasets by typing a question mark (?) followed by the the name of the dataset.

Sample datasets are included in packages. There are several packages included with R that have some datasets. The source for those is in the source code for R [1].

There are also more than 16000 contributed packages, many of which have sample datasets, which would be in their source code [2].

Do also read the Posting Guide mentioned at the end of every message on this mailing list. Sending your email in plain text format as indicated there will help minimize scrambling if your messages on the mailing list.

[1] https://cran.r-project.org/sources.html
[2] https://cran.r-project.org/web/packages/

On September 19, 2021 12:53:22 PM PDT, haki namz via R-help <r-help at r-project.org> wrote:
>Hello,please guide me where I can find the solution file of the R built-in datasets.regards
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 20 01:18:40 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 19 Sep 2021 16:18:40 -0700
Subject: [R] how to remove factors from whole dataframe?
In-Reply-To: <01a801d7ad9b$373ade60$a5b09b20$@verizon.net>
References: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
 <CA+8X3fUaORRLO7r=42jKNpGDTYbTjxxSLEx1drEHNCuecDsX8w@mail.gmail.com>
 <CAMk+s2RxaEdgeBPLdvEqi5XgQr_xMgFjLXuT6Hd=Z_RKfeO2uw@mail.gmail.com>
 <a9763900-5958-c063-4002-ffa824852a5b@sapo.pt>
 <CAMk+s2RSwv8aO-1Wb8AGLM8Qw8AL1KLm3NN2V0V2ju48WkseVQ@mail.gmail.com>
 <01a801d7ad9b$373ade60$a5b09b20$@verizon.net>
Message-ID: <CAGxFJbTrtkL-SQ5Gc+EiBYs+xuiyobuxDzVQzbJjr=YdmAzyTg@mail.gmail.com>

You do not understand factors. There is no "base type" that can be recovered.

> f <- factor(c(5.1, 6.2), labels = c("whoa","baby"))
> f
[1] whoa baby
Levels: whoa baby

> unclass(f)
[1] 1 2
attr(,"levels")
[1] "whoa" "baby"

> typeof(f)
[1] "integer"


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Sep 19, 2021 at 2:15 PM Avi Gross via R-help
<r-help at r-project.org> wrote:
>
> Glad we have solutions BUT I note that the more abstract question is how to convert any columns that are factors to their base type and that may well NOT be character. They can be integers or doubles or complex or Boolean and maybe even raw.
>
> So undoing factorization may require using something like typeof() to get the base type and then depending on what final type you have, you may have to do things like as.integer(as.character(the_factor)) to get it as an integer and for a logical, as.logical(factor(c(TRUE, TRUE, FALSE, TRUE, FALSE))) and so on.
>
> This seems like a fairly basic need so I wonder if anyone has already done it. I can see a fairly straightforward way to build a string and use eval and I suspect others might use something else like do.call() and yet others use multiple if statements or a case_when or something
>
>
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> Sent: Sunday, September 19, 2021 4:43 PM
> To: Rui Barradas <ruipbarradas at sapo.pt>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] how to remove factors from whole dataframe?
>
> Awesome, thanks!
>
> On Sun, Sep 19, 2021 at 4:22 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > Using Jim's lapply(., is.factor) but simplified, you could do
> >
> >
> > df1 <- df
> > i <- sapply(df1, is.factor)
> > df1[i] <- lapply(df1[i], as.character)
> >
> >
> > a one-liner modifying df, not df1 is
> >
> >
> > df[sapply(df, is.factor)] <- lapply(df[sapply(df, is.factor)],
> > as.character)
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 11:03 de 19/09/21, Luigi Marongiu escreveu:
> > > Thank you Jim, but I obtain:
> > > ```
> > >> str(df)
> > > 'data.frame': 5 obs. of  3 variables:
> > >   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > >   $ sales  : num  13 16 22 27 34
> > >   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > >> df1<-df[,!unlist(lapply(df,is.factor))]
> > >> str(df1)
> > >   num [1:5] 13 16 22 27 34
> > >> df1
> > > [1] 13 16 22 27 34
> > > ```
> > > I was expecting
> > > ```
> > > str(df)
> > > 'data.frame': 5 obs. of  3 variables:
> > >   $ region : char "A","B","C","D",..: 1 2 3 4 5
> > >   $ sales  : num  13 16 22 27 34
> > >   $ country: char "a","b","c","d",..: 1 2 3 4 5 ```
> > >
> > > On Sun, Sep 19, 2021 at 11:37 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >>
> > >> Hi Luigi,
> > >> It's easy:
> > >>
> > >> df1<-df[,!unlist(lapply(df,is.factor))]
> > >>
> > >> _except_ when there is only one column left, as in your example. In
> > >> that case, you will have to coerce the resulting vector back into a
> > >> one column data frame.
> > >>
> > >> Jim
> > >>
> > >> On Sun, Sep 19, 2021 at 6:18 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >>>
> > >>> Hello,
> > >>> I woul dlike to remove factors from all the columns of a dataframe.
> > >>> I can do it n a column at the time with ```
> > >>>
> > >>> df <- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')),
> > >>>                   sales = c(13, 16, 22, 27, 34),
> > >>> country=factor(c('a', 'b', 'c', 'd', 'e')))
> > >>>
> > >>> new_df$region <- droplevels(new_df$region) ```
> > >>>
> > >>> What is the syntax to remove all factors at once (from all columns)?
> > >>> For this does not work:
> > >>> ```
> > >>>> str(df)
> > >>> 'data.frame': 5 obs. of  3 variables:
> > >>>   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > >>>   $ sales  : num  13 16 22 27 34
> > >>>   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > >>>> df = droplevels(df)
> > >>>> str(df)
> > >>> 'data.frame': 5 obs. of  3 variables:
> > >>>   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > >>>   $ sales  : num  13 16 22 27 34
> > >>>   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5 ```
> > >>> Thank you
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> > >>> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Mon Sep 20 02:47:36 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sun, 19 Sep 2021 20:47:36 -0400
Subject: [R] how to remove factors from whole dataframe?
In-Reply-To: <CAGxFJbTrtkL-SQ5Gc+EiBYs+xuiyobuxDzVQzbJjr=YdmAzyTg@mail.gmail.com>
References: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
 <CA+8X3fUaORRLO7r=42jKNpGDTYbTjxxSLEx1drEHNCuecDsX8w@mail.gmail.com>
 <CAMk+s2RxaEdgeBPLdvEqi5XgQr_xMgFjLXuT6Hd=Z_RKfeO2uw@mail.gmail.com>
 <a9763900-5958-c063-4002-ffa824852a5b@sapo.pt>
 <CAMk+s2RSwv8aO-1Wb8AGLM8Qw8AL1KLm3NN2V0V2ju48WkseVQ@mail.gmail.com>
 <01a801d7ad9b$373ade60$a5b09b20$@verizon.net>
 <CAGxFJbTrtkL-SQ5Gc+EiBYs+xuiyobuxDzVQzbJjr=YdmAzyTg@mail.gmail.com>
Message-ID: <02bd01d7adb9$1b4ee7f0$51ecb7d0$@verizon.net>

Bert, you got me. Factors seem to be implemented as a sort of one-way street. Mea maxima culpa!

I did some experiments and clearly I misunderstood the way factors in R are set up. I made a series of factors of various kinds such as integer and logical and character and they all are simply a class of "factor" as they have an attribute of 'class' and a typeof() "integer"  as the payload is now a series of small integers.  A dictionary of sorts is kept in the attribute of 'levels' but that seems to always be of type character as in:

levels(somelogsfac)
[1] "FALSE" "TRUE" 
> typeof(levels(somelogsfac)[1])
[1] "character"


So it sounds like if I read in or create something like a data.frame and I convert some columns to factors to get the results I want like more compressed storage or maybe get ggplot to use my data in some specified order, I also lose any idea of what it was once. That is fine for some purposes such as where the info is wanted in text form, perhaps less so if it has to constantly be converted back into some other form.

But it seems to be a destructive operation in the sense that once done, there is no info preserved as to what was there before. Mind you, that is not really a problem as doing many transformations like as.integer() also replaces what was with what now is.

But in a sense it can be made reversible if you choose to extend it a bit. Below is some code I threw together that if called instead of "factor()" will hide away the original type so it can be used later as an argument to as() to bring back the original type. This is not a change to the original factor() function but I wonder if it would cause any incompatibility if this was made standard. Yes, it costs a little extra in storage.


> ####
  > # PURPOSE: Given a factor that has embedded knowlege of what
  > # the underlying type once was, carefully reconstruct a vector
  > # to put it back where it should have been. If this is a normal R
  > # vector or factor, just return it as of type character.
  > # If an attribute shows the information of what kind it is
  > # was saved, convert it to that.
  > 
  > unfactormem <- function(unorig) {
    +   what_kind <- attr(unorig, "OnceWas")
    +   unorigchar <- as.character(unorig)
    +   if (is.null(what_kind)) return(unorigchar)
    +   as(unorigchar, what_kind)
    + }
>   
  > # Make a logical vector
  > somelogs <- c(TRUE, FALSE, FALSE, TRUE, FALSE)
> 
  > # convert it to factor the new way that saves that it was logical.
  > somelogsfac <- factormem(orig)
Error in factormem(orig) : object 'orig' not found
> 
  > # display what it looks like
  > somelogsfac
[1] TRUE  FALSE FALSE TRUE  FALSE
attr(,"OnceWas")
[1] logical
Levels: FALSE TRUE
> 
  > attributes(somelogsfac)
$levels
[1] "FALSE" "TRUE" 

$class
[1] "factor"

$OnceWas
[1] "logical"

> 
  > attr(somelogsfac, "OnceWas")
[1] "logical"
> 
  > # Revivify it by hand, not the function I made.
  > revived <- as(as.character(somelogsfac), attr(somelogsfac, "OnceWas"))
> 
  > # show what it looks like:
  > revived
[1]  TRUE FALSE FALSE  TRUE FALSE
> 
  > typeof(revived)
[1] "logical"
> 
  > # Alternately, use the function I created to bring it back.
  > 
  > unfactormem(somelogsfac)
[1]  TRUE FALSE FALSE  TRUE FALSE
> 
  > typeof(unfactormem(somelogsfac))
[1] "logical"
> 
  > # A complex example:
  > 
  > somecomplex <- c( 3+5i, 4+6i, 13, 4+6i, 7i, 13)
> typeof(somecomplex)
[1] "complex"
> somecomplexfac <- factormem(somecomplex)
> attributes(somecomplexfac)
$levels
[1] "0+7i"  "3+5i"  "4+6i"  "13+0i"

$class
[1] "factor"

$OnceWas
[1] "complex"

> revivified <- unfactormem(somecomplexfac)
> revivified
[1]  3+5i  4+6i 13+0i  4+6i  0+7i 13+0i
> typeof(revivified)
[1] "complex"


AGAIN, I am not asking this be done as a change in R, just that I think it is an idea of how to be able to say undo factorization properly when needed, such as before saving it to disk in some data structure, or when passing it for some other analysis where a non-factor form would work better.

NOTE: I threw this together quickly and may well have made errors or not made it bulletproof. Feel free to point out where I am wrong or how to improve it.

I also note my approach is partially based on  interactions I once had with Adrian Dusa when he shared his package "declared" and he needed to maintain additional info on some data brought into R that had multiple distinct categories of missing data. It had to carefully use attributes but also did much more to integrate the functionality more fully. So, yes, that might be something that could be done but this is just an academic exercise for me.

-----Original Message-----
From: Bert Gunter <bgunter.4567 at gmail.com> 
Sent: Sunday, September 19, 2021 7:19 PM
To: Avi Gross <avigross at verizon.net>
Cc: Luigi Marongiu <marongiu.luigi at gmail.com>; Rui Barradas <ruipbarradas at sapo.pt>; r-help <r-help at r-project.org>
Subject: Re: [R] how to remove factors from whole dataframe?

You do not understand factors. There is no "base type" that can be recovered.

> f <- factor(c(5.1, 6.2), labels = c("whoa","baby")) f
[1] whoa baby
Levels: whoa baby

> unclass(f)
[1] 1 2
attr(,"levels")
[1] "whoa" "baby"

> typeof(f)
[1] "integer"


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Sep 19, 2021 at 2:15 PM Avi Gross via R-help <r-help at r-project.org> wrote:
>
> Glad we have solutions BUT I note that the more abstract question is how to convert any columns that are factors to their base type and that may well NOT be character. They can be integers or doubles or complex or Boolean and maybe even raw.
>
> So undoing factorization may require using something like typeof() to get the base type and then depending on what final type you have, you may have to do things like as.integer(as.character(the_factor)) to get it as an integer and for a logical, as.logical(factor(c(TRUE, TRUE, FALSE, TRUE, FALSE))) and so on.
>
> This seems like a fairly basic need so I wonder if anyone has already 
> done it. I can see a fairly straightforward way to build a string and 
> use eval and I suspect others might use something else like do.call() 
> and yet others use multiple if statements or a case_when or something
>
>
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi 
> Marongiu
> Sent: Sunday, September 19, 2021 4:43 PM
> To: Rui Barradas <ruipbarradas at sapo.pt>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] how to remove factors from whole dataframe?
>
> Awesome, thanks!
>
> On Sun, Sep 19, 2021 at 4:22 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > Using Jim's lapply(., is.factor) but simplified, you could do
> >
> >
> > df1 <- df
> > i <- sapply(df1, is.factor)
> > df1[i] <- lapply(df1[i], as.character)
> >
> >
> > a one-liner modifying df, not df1 is
> >
> >
> > df[sapply(df, is.factor)] <- lapply(df[sapply(df, is.factor)],
> > as.character)
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 11:03 de 19/09/21, Luigi Marongiu escreveu:
> > > Thank you Jim, but I obtain:
> > > ```
> > >> str(df)
> > > 'data.frame': 5 obs. of  3 variables:
> > >   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > >   $ sales  : num  13 16 22 27 34
> > >   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > >> df1<-df[,!unlist(lapply(df,is.factor))]
> > >> str(df1)
> > >   num [1:5] 13 16 22 27 34
> > >> df1
> > > [1] 13 16 22 27 34
> > > ```
> > > I was expecting
> > > ```
> > > str(df)
> > > 'data.frame': 5 obs. of  3 variables:
> > >   $ region : char "A","B","C","D",..: 1 2 3 4 5
> > >   $ sales  : num  13 16 22 27 34
> > >   $ country: char "a","b","c","d",..: 1 2 3 4 5 ```
> > >
> > > On Sun, Sep 19, 2021 at 11:37 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >>
> > >> Hi Luigi,
> > >> It's easy:
> > >>
> > >> df1<-df[,!unlist(lapply(df,is.factor))]
> > >>
> > >> _except_ when there is only one column left, as in your example. 
> > >> In that case, you will have to coerce the resulting vector back 
> > >> into a one column data frame.
> > >>
> > >> Jim
> > >>
> > >> On Sun, Sep 19, 2021 at 6:18 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >>>
> > >>> Hello,
> > >>> I woul dlike to remove factors from all the columns of a dataframe.
> > >>> I can do it n a column at the time with ```
> > >>>
> > >>> df <- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')),
> > >>>                   sales = c(13, 16, 22, 27, 34), 
> > >>> country=factor(c('a', 'b', 'c', 'd', 'e')))
> > >>>
> > >>> new_df$region <- droplevels(new_df$region) ```
> > >>>
> > >>> What is the syntax to remove all factors at once (from all columns)?
> > >>> For this does not work:
> > >>> ```
> > >>>> str(df)
> > >>> 'data.frame': 5 obs. of  3 variables:
> > >>>   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > >>>   $ sales  : num  13 16 22 27 34
> > >>>   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > >>>> df = droplevels(df)
> > >>>> str(df)
> > >>> 'data.frame': 5 obs. of  3 variables:
> > >>>   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > >>>   $ sales  : num  13 16 22 27 34
> > >>>   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5 
> > >>> ``` Thank you
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, 
> > >>> see https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide 
> > >>> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 20 03:31:23 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 19 Sep 2021 18:31:23 -0700
Subject: [R] how to remove factors from whole dataframe?
In-Reply-To: <02bd01d7adb9$1b4ee7f0$51ecb7d0$@verizon.net>
References: <CAMk+s2Q8Ue4pCiFk9yEhW9D+CPedvas0ZPjmdsB=Hu1R3U=58w@mail.gmail.com>
 <CA+8X3fUaORRLO7r=42jKNpGDTYbTjxxSLEx1drEHNCuecDsX8w@mail.gmail.com>
 <CAMk+s2RxaEdgeBPLdvEqi5XgQr_xMgFjLXuT6Hd=Z_RKfeO2uw@mail.gmail.com>
 <a9763900-5958-c063-4002-ffa824852a5b@sapo.pt>
 <CAMk+s2RSwv8aO-1Wb8AGLM8Qw8AL1KLm3NN2V0V2ju48WkseVQ@mail.gmail.com>
 <01a801d7ad9b$373ade60$a5b09b20$@verizon.net>
 <CAGxFJbTrtkL-SQ5Gc+EiBYs+xuiyobuxDzVQzbJjr=YdmAzyTg@mail.gmail.com>
 <02bd01d7adb9$1b4ee7f0$51ecb7d0$@verizon.net>
Message-ID: <CAGxFJbQj4MOOxbaoUo1NZLeLeZmXjoE2P5=kZV3rXSaoZ2POoQ@mail.gmail.com>

I am not trying to "get you"; but you need to do your homework before
posting. Factor implementation is fully explained in Section 2.3.1 of
the "R Language Definition." You can also search on "enumerated
types"(mentioned in the Help page),  a long established C construct,
for a fuller explanation. Which makes all of your following remarks
just a bit pointless, no?

"I made a series of factors of various kinds such as integer and
logical and character and they all are simply a class of "factor" as
they have an attribute of 'class' and a typeof() "integer"  as the
payload is now a series of small integers.  A dictionary of sorts is
kept in the attribute of 'levels' but that seems to always be of type
character as in: ... etc."

Cheers,
Bert

On Sun, Sep 19, 2021 at 5:48 PM Avi Gross via R-help
<r-help at r-project.org> wrote:
>
> Bert, you got me. Factors seem to be implemented as a sort of one-way street. Mea maxima culpa!
>
> I did some experiments and clearly I misunderstood the way factors in R are set up. I made a series of factors of various kinds such as integer and logical and character and they all are simply a class of "factor" as they have an attribute of 'class' and a typeof() "integer"  as the payload is now a series of small integers.  A dictionary of sorts is kept in the attribute of 'levels' but that seems to always be of type character as in:
>
> levels(somelogsfac)
> [1] "FALSE" "TRUE"
> > typeof(levels(somelogsfac)[1])
> [1] "character"
>
>
> So it sounds like if I read in or create something like a data.frame and I convert some columns to factors to get the results I want like more compressed storage or maybe get ggplot to use my data in some specified order, I also lose any idea of what it was once. That is fine for some purposes such as where the info is wanted in text form, perhaps less so if it has to constantly be converted back into some other form.
>
> But it seems to be a destructive operation in the sense that once done, there is no info preserved as to what was there before. Mind you, that is not really a problem as doing many transformations like as.integer() also replaces what was with what now is.
>
> But in a sense it can be made reversible if you choose to extend it a bit. Below is some code I threw together that if called instead of "factor()" will hide away the original type so it can be used later as an argument to as() to bring back the original type. This is not a change to the original factor() function but I wonder if it would cause any incompatibility if this was made standard. Yes, it costs a little extra in storage.
>
>
> > ####
>   > # PURPOSE: Given a factor that has embedded knowlege of what
>   > # the underlying type once was, carefully reconstruct a vector
>   > # to put it back where it should have been. If this is a normal R
>   > # vector or factor, just return it as of type character.
>   > # If an attribute shows the information of what kind it is
>   > # was saved, convert it to that.
>   >
>   > unfactormem <- function(unorig) {
>     +   what_kind <- attr(unorig, "OnceWas")
>     +   unorigchar <- as.character(unorig)
>     +   if (is.null(what_kind)) return(unorigchar)
>     +   as(unorigchar, what_kind)
>     + }
> >
>   > # Make a logical vector
>   > somelogs <- c(TRUE, FALSE, FALSE, TRUE, FALSE)
> >
>   > # convert it to factor the new way that saves that it was logical.
>   > somelogsfac <- factormem(orig)
> Error in factormem(orig) : object 'orig' not found
> >
>   > # display what it looks like
>   > somelogsfac
> [1] TRUE  FALSE FALSE TRUE  FALSE
> attr(,"OnceWas")
> [1] logical
> Levels: FALSE TRUE
> >
>   > attributes(somelogsfac)
> $levels
> [1] "FALSE" "TRUE"
>
> $class
> [1] "factor"
>
> $OnceWas
> [1] "logical"
>
> >
>   > attr(somelogsfac, "OnceWas")
> [1] "logical"
> >
>   > # Revivify it by hand, not the function I made.
>   > revived <- as(as.character(somelogsfac), attr(somelogsfac, "OnceWas"))
> >
>   > # show what it looks like:
>   > revived
> [1]  TRUE FALSE FALSE  TRUE FALSE
> >
>   > typeof(revived)
> [1] "logical"
> >
>   > # Alternately, use the function I created to bring it back.
>   >
>   > unfactormem(somelogsfac)
> [1]  TRUE FALSE FALSE  TRUE FALSE
> >
>   > typeof(unfactormem(somelogsfac))
> [1] "logical"
> >
>   > # A complex example:
>   >
>   > somecomplex <- c( 3+5i, 4+6i, 13, 4+6i, 7i, 13)
> > typeof(somecomplex)
> [1] "complex"
> > somecomplexfac <- factormem(somecomplex)
> > attributes(somecomplexfac)
> $levels
> [1] "0+7i"  "3+5i"  "4+6i"  "13+0i"
>
> $class
> [1] "factor"
>
> $OnceWas
> [1] "complex"
>
> > revivified <- unfactormem(somecomplexfac)
> > revivified
> [1]  3+5i  4+6i 13+0i  4+6i  0+7i 13+0i
> > typeof(revivified)
> [1] "complex"
>
>
> AGAIN, I am not asking this be done as a change in R, just that I think it is an idea of how to be able to say undo factorization properly when needed, such as before saving it to disk in some data structure, or when passing it for some other analysis where a non-factor form would work better.
>
> NOTE: I threw this together quickly and may well have made errors or not made it bulletproof. Feel free to point out where I am wrong or how to improve it.
>
> I also note my approach is partially based on  interactions I once had with Adrian Dusa when he shared his package "declared" and he needed to maintain additional info on some data brought into R that had multiple distinct categories of missing data. It had to carefully use attributes but also did much more to integrate the functionality more fully. So, yes, that might be something that could be done but this is just an academic exercise for me.
>
> -----Original Message-----
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: Sunday, September 19, 2021 7:19 PM
> To: Avi Gross <avigross at verizon.net>
> Cc: Luigi Marongiu <marongiu.luigi at gmail.com>; Rui Barradas <ruipbarradas at sapo.pt>; r-help <r-help at r-project.org>
> Subject: Re: [R] how to remove factors from whole dataframe?
>
> You do not understand factors. There is no "base type" that can be recovered.
>
> > f <- factor(c(5.1, 6.2), labels = c("whoa","baby")) f
> [1] whoa baby
> Levels: whoa baby
>
> > unclass(f)
> [1] 1 2
> attr(,"levels")
> [1] "whoa" "baby"
>
> > typeof(f)
> [1] "integer"
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sun, Sep 19, 2021 at 2:15 PM Avi Gross via R-help <r-help at r-project.org> wrote:
> >
> > Glad we have solutions BUT I note that the more abstract question is how to convert any columns that are factors to their base type and that may well NOT be character. They can be integers or doubles or complex or Boolean and maybe even raw.
> >
> > So undoing factorization may require using something like typeof() to get the base type and then depending on what final type you have, you may have to do things like as.integer(as.character(the_factor)) to get it as an integer and for a logical, as.logical(factor(c(TRUE, TRUE, FALSE, TRUE, FALSE))) and so on.
> >
> > This seems like a fairly basic need so I wonder if anyone has already
> > done it. I can see a fairly straightforward way to build a string and
> > use eval and I suspect others might use something else like do.call()
> > and yet others use multiple if statements or a case_when or something
> >
> >
> >
> >
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi
> > Marongiu
> > Sent: Sunday, September 19, 2021 4:43 PM
> > To: Rui Barradas <ruipbarradas at sapo.pt>
> > Cc: r-help <r-help at r-project.org>
> > Subject: Re: [R] how to remove factors from whole dataframe?
> >
> > Awesome, thanks!
> >
> > On Sun, Sep 19, 2021 at 4:22 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> > >
> > > Hello,
> > >
> > > Using Jim's lapply(., is.factor) but simplified, you could do
> > >
> > >
> > > df1 <- df
> > > i <- sapply(df1, is.factor)
> > > df1[i] <- lapply(df1[i], as.character)
> > >
> > >
> > > a one-liner modifying df, not df1 is
> > >
> > >
> > > df[sapply(df, is.factor)] <- lapply(df[sapply(df, is.factor)],
> > > as.character)
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > > ?s 11:03 de 19/09/21, Luigi Marongiu escreveu:
> > > > Thank you Jim, but I obtain:
> > > > ```
> > > >> str(df)
> > > > 'data.frame': 5 obs. of  3 variables:
> > > >   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > > >   $ sales  : num  13 16 22 27 34
> > > >   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > > >> df1<-df[,!unlist(lapply(df,is.factor))]
> > > >> str(df1)
> > > >   num [1:5] 13 16 22 27 34
> > > >> df1
> > > > [1] 13 16 22 27 34
> > > > ```
> > > > I was expecting
> > > > ```
> > > > str(df)
> > > > 'data.frame': 5 obs. of  3 variables:
> > > >   $ region : char "A","B","C","D",..: 1 2 3 4 5
> > > >   $ sales  : num  13 16 22 27 34
> > > >   $ country: char "a","b","c","d",..: 1 2 3 4 5 ```
> > > >
> > > > On Sun, Sep 19, 2021 at 11:37 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > > >>
> > > >> Hi Luigi,
> > > >> It's easy:
> > > >>
> > > >> df1<-df[,!unlist(lapply(df,is.factor))]
> > > >>
> > > >> _except_ when there is only one column left, as in your example.
> > > >> In that case, you will have to coerce the resulting vector back
> > > >> into a one column data frame.
> > > >>
> > > >> Jim
> > > >>
> > > >> On Sun, Sep 19, 2021 at 6:18 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > > >>>
> > > >>> Hello,
> > > >>> I woul dlike to remove factors from all the columns of a dataframe.
> > > >>> I can do it n a column at the time with ```
> > > >>>
> > > >>> df <- data.frame(region=factor(c('A', 'B', 'C', 'D', 'E')),
> > > >>>                   sales = c(13, 16, 22, 27, 34),
> > > >>> country=factor(c('a', 'b', 'c', 'd', 'e')))
> > > >>>
> > > >>> new_df$region <- droplevels(new_df$region) ```
> > > >>>
> > > >>> What is the syntax to remove all factors at once (from all columns)?
> > > >>> For this does not work:
> > > >>> ```
> > > >>>> str(df)
> > > >>> 'data.frame': 5 obs. of  3 variables:
> > > >>>   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > > >>>   $ sales  : num  13 16 22 27 34
> > > >>>   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > > >>>> df = droplevels(df)
> > > >>>> str(df)
> > > >>> 'data.frame': 5 obs. of  3 variables:
> > > >>>   $ region : Factor w/ 5 levels "A","B","C","D",..: 1 2 3 4 5
> > > >>>   $ sales  : num  13 16 22 27 34
> > > >>>   $ country: Factor w/ 5 levels "a","b","c","d",..: 1 2 3 4 5
> > > >>> ``` Thank you
> > > >>>
> > > >>> ______________________________________________
> > > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > >>> see https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>> PLEASE do read the posting guide
> > > >>> http://www.R-project.org/posting-guide.html
> > > >>> and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > >
> > > >
> >
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From c@|@ndr@ @end|ng |rom rgzm@de  Mon Sep 20 16:09:00 2021
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 20 Sep 2021 16:09:00 +0200
Subject: [R] ggsave() with width only
In-Reply-To: <9e4dcd06-68b7-5bf5-b4d0-85f2b549abd4@rgzm.de>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
 <a6477734-fefa-9cba-b7c1-b214858edd83@e.email>
 <9e4dcd06-68b7-5bf5-b4d0-85f2b549abd4@rgzm.de>
Message-ID: <ecadbe34-a2cb-86da-d90f-1b172909421c@rgzm.de>

Dear Adam,

The function cowplot::save_plot() actually doesn't help in my case 
because I need to know the aspect ratio (which I don't in advance). If I 
knew the aspect ratio, I could calculate the height from the width or 
vice-versa, and then I could use ggplot2::ggsave().

I have found a workaround using the package patchwork: I put the plots 
together into one plot, that I save on an A4 page.

Best,
Ivan

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 14/09/2021 9:17, Ivan Calandra wrote:
> Thank you Adam!
>
> I'm a bit surprised that an extra package is needed for this, but why 
> not!
>
> Best,
> Ivan
>
> -- 
> Dr. Ivan Calandra
> Imaging lab
> RGZM - MONREPOS Archaeological Research Centre
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> On 13/09/2021 15:40, Adam Wysoki?ski wrote:
>> Hi,
>> Instead of ggsave(), use save_plot() from the "cowplot" package:
>>
>> library(ggplot2)
>> library(cowplot)
>> x <- 1:10
>> y <- x^2
>> df <- data.frame(x, y)
>> p <- ggplot(df, aes(x, y)) + geom_point()
>> save_plot("/tmp/plot.png", p, base_aspect_ratio = 1, base_width = 5, 
>> base_height = NULL)
>>


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Mon Sep 20 21:24:04 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Mon, 20 Sep 2021 19:24:04 +0000 (UTC)
Subject: [R] Improve my plot
References: <356566108.2700529.1632165844251.ref@mail.yahoo.com>
Message-ID: <356566108.2700529.1632165844251@mail.yahoo.com>

Dear R-experts,

Here below my R code. I would need your help to improve my graph/plot.

- The x-axis to be longer not to stop at 500 value
- All the name on the y-axis to appear not only a few of them and the name (Fribourg(f), Appenzell Rhodes Int?rieures,...) to appear entire, not to be cut

Many thanks.

##############
barplot(height=c(574,557,544,535,534,532,531,527,526,525,524,520,518,512,507,504,504,489,488,488,487,484,484,474,472,455,444,420),names.arg=c("Fribourg(f)","Valais(d)","Appenzell Rhodes Int?rieures","Fribourg(d)","Jura","Schwyz","Schaffhouse","Berne(f)","Thurgovie","Valais(f)","Argovie","Appenzell Rhodes Ext?rieures","Gen?ve","Zoug","Tessin","Neuch?tel","Vaud","Uri","Nidwald","Berne(d)","Zurich","Obwald","Saint-Gall","Soleure","Lucerne","Glaris","B?le-Campagne","B?le-Ville"),font.axis=4, horiz=T,col="deepskyblue2",las=2)
##############
?

?


From @d@m@wy@ok|n@k| @end|ng |rom e@em@||  Mon Sep 20 21:29:01 2021
From: @d@m@wy@ok|n@k| @end|ng |rom e@em@|| (=?UTF-8?Q?Adam_Wysoki=c5=84ski?=)
Date: Mon, 20 Sep 2021 21:29:01 +0200
Subject: [R] ggsave() with width only
In-Reply-To: <ecadbe34-a2cb-86da-d90f-1b172909421c@rgzm.de>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
 <a6477734-fefa-9cba-b7c1-b214858edd83@e.email>
 <9e4dcd06-68b7-5bf5-b4d0-85f2b549abd4@rgzm.de>
 <ecadbe34-a2cb-86da-d90f-1b172909421c@rgzm.de>
Message-ID: <4f7c4167-67f9-7710-4dfd-4f4d2fd70c44@e.email>

Dear Ivan,
I think you don't need to provide the aspect ratio, as this should work 
as well:

save_plot("/tmp/plot.png", p, base_width = 5, base_height = NULL)

-- 
Regards,
Adam Wysoki?ski

On 9/20/21 16:09, Ivan Calandra wrote:
> Dear Adam,
> 
> The function cowplot::save_plot() actually doesn't help in my case 
> because I need to know the aspect ratio (which I don't in advance). If I 
> knew the aspect ratio, I could calculate the height from the width or 
> vice-versa, and then I could use ggplot2::ggsave().
> 
> I have found a workaround using the package patchwork: I put the plots 
> together into one plot, that I save on an A4 page.
> 
> Best,
> Ivan
> 
> -- 
> Dr. Ivan Calandra
> Imaging lab
> RGZM - MONREPOS Archaeological Research Centre
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
> 
> On 14/09/2021 9:17, Ivan Calandra wrote:
>> Thank you Adam!
>>
>> I'm a bit surprised that an extra package is needed for this, but why 
>> not!
>>
>> Best,
>> Ivan
>>
>> -- 
>> Dr. Ivan Calandra
>> Imaging lab
>> RGZM - MONREPOS Archaeological Research Centre
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> On 13/09/2021 15:40, Adam Wysoki?ski wrote:
>>> Hi,
>>> Instead of ggsave(), use save_plot() from the "cowplot" package:
>>>
>>> library(ggplot2)
>>> library(cowplot)
>>> x <- 1:10
>>> y <- x^2
>>> df <- data.frame(x, y)
>>> p <- ggplot(df, aes(x, y)) + geom_point()
>>> save_plot("/tmp/plot.png", p, base_aspect_ratio = 1, base_width = 5, 
>>> base_height = NULL)
>>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Sep 20 21:54:28 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 20 Sep 2021 20:54:28 +0100
Subject: [R] Improve my plot
In-Reply-To: <356566108.2700529.1632165844251@mail.yahoo.com>
References: <356566108.2700529.1632165844251.ref@mail.yahoo.com>
 <356566108.2700529.1632165844251@mail.yahoo.com>
Message-ID: <32676359-4966-351d-14a0-4491e8238c8b@sapo.pt>

Hello,

With package ggplot2 this is easy.
ggplot2 is meant to work with data in lists or data.frames, so I use the 
new pipe operator to pass the data on to ggplot().


h <- c(574,557,544,535,534,532,531,527,526,525,
        524,520,518,512,507,504,504,489,488,488,
        487,484,484,474,472,455,444,420)

nms <- c("Fribourg(f)","Valais(d)","Appenzell Rhodes Int?rieures",
          "Fribourg(d)","Jura","Schwyz","Schaffhouse","Berne(f)",
          "Thurgovie","Valais(f)","Argovie","Appenzell Rhodes Ext?rieures",
          "Gen?ve","Zoug","Tessin","Neuch?tel","Vaud","Uri","Nidwald",
          "Berne(d)","Zurich","Obwald","Saint-Gall","Soleure","Lucerne",
          "Glaris","B?le-Campagne","B?le-Ville")
nms <- factor(nms, levels = nms)

library(ggplot2)

data.frame(height = h, names = nms) |>
   ggplot(aes(names, height)) +
   geom_col(fill = "deepskyblue2") +
   coord_flip() +
   theme_classic() +
   theme(axis.text.y = element_text(face = "italic"))


Hope this helps,

Rui Barradas


?s 20:24 de 20/09/21, varin sacha via R-help escreveu:
> Dear R-experts,
> 
> Here below my R code. I would need your help to improve my graph/plot.
> 
> - The x-axis to be longer not to stop at 500 value
> - All the name on the y-axis to appear not only a few of them and the name (Fribourg(f), Appenzell Rhodes Int?rieures,...) to appear entire, not to be cut
> 
> Many thanks.
> 
> ##############
> barplot(height=c(574,557,544,535,534,532,531,527,526,525,524,520,518,512,507,504,504,489,488,488,487,484,484,474,472,455,444,420),names.arg=c("Fribourg(f)","Valais(d)","Appenzell Rhodes Int?rieures","Fribourg(d)","Jura","Schwyz","Schaffhouse","Berne(f)","Thurgovie","Valais(f)","Argovie","Appenzell Rhodes Ext?rieures","Gen?ve","Zoug","Tessin","Neuch?tel","Vaud","Uri","Nidwald","Berne(d)","Zurich","Obwald","Saint-Gall","Soleure","Lucerne","Glaris","B?le-Campagne","B?le-Ville"),font.axis=4, horiz=T,col="deepskyblue2",las=2)
> ##############
>   
> 
>   
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Mon Sep 20 22:04:01 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Mon, 20 Sep 2021 20:04:01 +0000 (UTC)
Subject: [R] Improve my plot
In-Reply-To: <32676359-4966-351d-14a0-4491e8238c8b@sapo.pt>
References: <356566108.2700529.1632165844251.ref@mail.yahoo.com>
 <356566108.2700529.1632165844251@mail.yahoo.com>
 <32676359-4966-351d-14a0-4491e8238c8b@sapo.pt>
Message-ID: <257339679.2739883.1632168241040@mail.yahoo.com>

Hi Rui,

Many thanks but when I copy and paste your R code here below I get 2 error mesages :

##############
h <- c(574,557,544,535,534,532,531,527,526,525,
? ? ? ? 524,520,518,512,507,504,504,489,488,488,
? ? ? ? 487,484,484,474,472,455,444,420)

nms <- c("Fribourg(f)","Valais(d)","Appenzell Rhodes Int?rieures",
? ? ? ? ? "Fribourg(d)","Jura","Schwyz","Schaffhouse","Berne(f)",
? ? ? ? ? "Thurgovie","Valais(f)","Argovie","Appenzell Rhodes Ext?rieures",
? ? ? ? ? "Gen?ve","Zoug","Tessin","Neuch?tel","Vaud","Uri","Nidwald",
? ? ? ? ? "Berne(d)","Zurich","Obwald","Saint-Gall","Soleure","Lucerne",
? ? ? ? ? "Glaris","B?le-Campagne","B?le-Ville")
nms <- factor(nms, levels = nms)

library(ggplot2)

data.frame(height = h, names = nms) |>
? ggplot(aes(names, height)) +
? geom_col(fill = "deepskyblue2") +
? coord_flip() +
? theme_classic() +
? theme(axis.text.y = element_text(face = "italic"))
##############






Le lundi 20 septembre 2021, 21:54:31 UTC+2, Rui Barradas <ruipbarradas at sapo.pt> a ?crit : 





Hello,

With package ggplot2 this is easy.
ggplot2 is meant to work with data in lists or data.frames, so I use the 
new pipe operator to pass the data on to ggplot().


h <- c(574,557,544,535,534,532,531,527,526,525,
? ? ? ? 524,520,518,512,507,504,504,489,488,488,
? ? ? ? 487,484,484,474,472,455,444,420)

nms <- c("Fribourg(f)","Valais(d)","Appenzell Rhodes Int?rieures",
? ? ? ? ? "Fribourg(d)","Jura","Schwyz","Schaffhouse","Berne(f)",
? ? ? ? ? "Thurgovie","Valais(f)","Argovie","Appenzell Rhodes Ext?rieures",
? ? ? ? ? "Gen?ve","Zoug","Tessin","Neuch?tel","Vaud","Uri","Nidwald",
? ? ? ? ? "Berne(d)","Zurich","Obwald","Saint-Gall","Soleure","Lucerne",
? ? ? ? ? "Glaris","B?le-Campagne","B?le-Ville")
nms <- factor(nms, levels = nms)

library(ggplot2)

data.frame(height = h, names = nms) |>
? ggplot(aes(names, height)) +
? geom_col(fill = "deepskyblue2") +
? coord_flip() +
? theme_classic() +
? theme(axis.text.y = element_text(face = "italic"))


Hope this helps,

Rui Barradas


?s 20:24 de 20/09/21, varin sacha via R-help escreveu:
> Dear R-experts,
> 
> Here below my R code. I would need your help to improve my graph/plot.
> 
> - The x-axis to be longer not to stop at 500 value
> - All the name on the y-axis to appear not only a few of them and the name (Fribourg(f), Appenzell Rhodes Int?rieures,...) to appear entire, not to be cut
> 
> Many thanks.
> 
> ##############
> barplot(height=c(574,557,544,535,534,532,531,527,526,525,524,520,518,512,507,504,504,489,488,488,487,484,484,474,472,455,444,420),names.arg=c("Fribourg(f)","Valais(d)","Appenzell Rhodes Int?rieures","Fribourg(d)","Jura","Schwyz","Schaffhouse","Berne(f)","Thurgovie","Valais(f)","Argovie","Appenzell Rhodes Ext?rieures","Gen?ve","Zoug","Tessin","Neuch?tel","Vaud","Uri","Nidwald","Berne(d)","Zurich","Obwald","Saint-Gall","Soleure","Lucerne","Glaris","B?le-Campagne","B?le-Ville"),font.axis=4, horiz=T,col="deepskyblue2",las=2)
> ##############
>? 
> 
>? 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 20 22:20:23 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 20 Sep 2021 13:20:23 -0700
Subject: [R] Improve my plot
In-Reply-To: <356566108.2700529.1632165844251@mail.yahoo.com>
References: <356566108.2700529.1632165844251.ref@mail.yahoo.com>
 <356566108.2700529.1632165844251@mail.yahoo.com>
Message-ID: <CAGxFJbR3x366gBvR1st2q0Z2koQ0NgpWdWe3OK0jpUABJooaRw@mail.gmail.com>

Don't do this! Use a dotchart instead. See the Wikipedia article on
dotplots or search.

height=c(574,557,544,535,534,532,531,527,526,525,524,520,518,512,507,504,504,489,488,488,487,484,484,474,472,455,444,420)
## kudos for plotting the sorted results rather than alphabetically.

 nm <- c("Fribourg(f)","Valais(d)","Appenzell Rhodes
Int?rieures","Fribourg(d)","Jura","Schwyz","Schaffhouse","Berne(f)","Thurgovie","Valais(f)","Argovie","Appenzell
Rhodes Ext?rieures","Gen?ve","Zoug","Tessin","Neuch?tel","Vaud","Uri","Nidwald","Berne(d)","Zurich","Obwald","Saint-Gall","Soleure","Lucerne","Glaris","B?le-Campagne","B?le-Ville")


 dotchart(height, nm, col = "blue", main = "Dotcharts Rock")

?dotchart gives you the details and options.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 20, 2021 at 12:24 PM varin sacha via R-help
<r-help at r-project.org> wrote:
>
> Dear R-experts,
>
> Here below my R code. I would need your help to improve my graph/plot.
>
> - The x-axis to be longer not to stop at 500 value
> - All the name on the y-axis to appear not only a few of them and the name (Fribourg(f), Appenzell Rhodes Int?rieures,...) to appear entire, not to be cut
>
> Many thanks.
>
> ##############
> barplot(height=c(574,557,544,535,534,532,531,527,526,525,524,520,518,512,507,504,504,489,488,488,487,484,484,474,472,455,444,420),names.arg=c("Fribourg(f)","Valais(d)","Appenzell Rhodes Int?rieures","Fribourg(d)","Jura","Schwyz","Schaffhouse","Berne(f)","Thurgovie","Valais(f)","Argovie","Appenzell Rhodes Ext?rieures","Gen?ve","Zoug","Tessin","Neuch?tel","Vaud","Uri","Nidwald","Berne(d)","Zurich","Obwald","Saint-Gall","Soleure","Lucerne","Glaris","B?le-Campagne","B?le-Ville"),font.axis=4, horiz=T,col="deepskyblue2",las=2)
> ##############
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From y@ngk@|9999 @end|ng |rom y@hoo@com  Mon Sep 20 23:21:51 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Mon, 20 Sep 2021 21:21:51 +0000 (UTC)
Subject: [R] ggplot2 bar chart: order display for each group
References: <968880303.1115941.1632172911736.ref@mail.yahoo.com>
Message-ID: <968880303.1115941.1632172911736@mail.yahoo.com>

Hello List,

I submitted the code below, it will show two groups of avg_time bar chart for each gc_label.

ggplot(s8_GCtime, aes(fill=GTresult, y=avg_time, x=gc_label, label = avg_time)) +?
? geom_bar(position=position_dodge(), stat="identity") +
? geom_text(aes(label=avg_time), vjust=1.6, position = position_dodge(0.9), size=3.5)+
? theme(axis.text.x = element_text(angle = 45))


I found the ggplot put all of small value of avg_time on left side, bigger value of avg_time on right side for each gc_label. But I hope to control the order by GTresult. Could you tell me how to do this?

Thanks,
Kai

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Sep 21 00:10:48 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 21 Sep 2021 08:10:48 +1000
Subject: [R] Improve my plot
In-Reply-To: <356566108.2700529.1632165844251@mail.yahoo.com>
References: <356566108.2700529.1632165844251.ref@mail.yahoo.com>
 <356566108.2700529.1632165844251@mail.yahoo.com>
Message-ID: <CA+8X3fWgvd8bV-QkGN7oQFCt7+mYsBrUpVLVA4_tPiUosUBcEg@mail.gmail.com>

Hi varin,
Not too difficult:

par(mar=c(5,13,4,1))
barplot(height=c(574,557,544,535,534,532,531,527,526,525,524,520,518,
512,507,504,504,489,488,488,487,484,484,474,472,455,444,420),
names.arg=c("Fribourg(f)","Valais(d)",
 "Appenzell Rhodes Int?rieures","Fribourg(d)","Jura","Schwyz",
 "Schaffhouse","Berne(f)","Thurgovie","Valais(f)","Argovie",
 "Appenzell Rhodes Ext?rieures","Gen?ve","Zoug","Tessin",
 "Neuch?tel","Vaud","Uri","Nidwald","Berne(d)","Zurich","Obwald",
 "Saint-Gall","Soleure","Lucerne","Glaris","B?le-Campagne","B?le-Ville"),
 horiz=TRUE,col="deepskyblue2",las=2,xlim=c(0,650),font.axis=4)

With regard to Bert's objection to barplots, you can do the same thing there.

Jim

On Tue, Sep 21, 2021 at 5:24 AM varin sacha via R-help
<r-help at r-project.org> wrote:
>
> Dear R-experts,
>
> Here below my R code. I would need your help to improve my graph/plot.
>
> - The x-axis to be longer not to stop at 500 value
> - All the name on the y-axis to appear not only a few of them and the name (Fribourg(f), Appenzell Rhodes Int?rieures,...) to appear entire, not to be cut
>
> Many thanks.
>
> ##############
> barplot(height=c(574,557,544,535,534,532,531,527,526,525,524,520,518,512,507,504,504,489,488,488,487,484,484,474,472,455,444,420),names.arg=c("Fribourg(f)","Valais(d)","Appenzell Rhodes Int?rieures","Fribourg(d)","Jura","Schwyz","Schaffhouse","Berne(f)","Thurgovie","Valais(f)","Argovie","Appenzell Rhodes Ext?rieures","Gen?ve","Zoug","Tessin","Neuch?tel","Vaud","Uri","Nidwald","Berne(d)","Zurich","Obwald","Saint-Gall","Soleure","Lucerne","Glaris","B?le-Campagne","B?le-Ville"),font.axis=4, horiz=T,col="deepskyblue2",las=2)
> ##############
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Sep 21 01:43:00 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 20 Sep 2021 16:43:00 -0700
Subject: [R] ggplot2 bar chart: order display for each group
In-Reply-To: <968880303.1115941.1632172911736@mail.yahoo.com>
References: <968880303.1115941.1632172911736.ref@mail.yahoo.com>
 <968880303.1115941.1632172911736@mail.yahoo.com>
Message-ID: <6CBA7574-8892-414D-8005-312F29989E42@dcn.davis.ca.us>

I could, but this question is off topic on this mailing list. Read the Posting Guide before you post again. Help for ggplot2 can be found in many places... start your search here https://cran.r-project.org/web/packages/ggplot2/index.html.

(Hint: your data should be a factor.)

On September 20, 2021 2:21:51 PM PDT, Kai Yang via R-help <r-help at r-project.org> wrote:
>Hello List,
>
>I submitted the code below, it will show two groups of avg_time bar chart for each gc_label.
>
>ggplot(s8_GCtime, aes(fill=GTresult, y=avg_time, x=gc_label, label = avg_time)) +?
>? geom_bar(position=position_dodge(), stat="identity") +
>? geom_text(aes(label=avg_time), vjust=1.6, position = position_dodge(0.9), size=3.5)+
>? theme(axis.text.x = element_text(angle = 45))
>
>
>I found the ggplot put all of small value of avg_time on left side, bigger value of avg_time on right side for each gc_label. But I hope to control the order by GTresult. Could you tell me how to do this?
>
>Thanks,
>Kai
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From y@ngk@|9999 @end|ng |rom y@hoo@com  Mon Sep 20 23:07:33 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Mon, 20 Sep 2021 21:07:33 +0000 (UTC)
Subject: [R] ggplot2 bar chart: order display for each group
References: <2092718562.1111743.1632172053447.ref@mail.yahoo.com>
Message-ID: <2092718562.1111743.1632172053447@mail.yahoo.com>

Hello List,
I submitted the code below, it will show two groups of avg_time bar chart for each?gc_label and got the plot.

ggplot(s8_GCtime, aes(fill=GTresult, y=avg_time, x=gc_label, label = avg_time)) +?
? geom_bar(position=position_dodge(), stat="identity") +
? geom_text(aes(label=avg_time), vjust=1.6, position = position_dodge(0.9), size=3.5)+
? theme(axis.text.x = element_text(angle = 45))



I found the ggplot put all of small number of avg_time on left side, bigger number of avg_time on right side for each gc_label. But I hope to use order by GTresult?(see the plot I attached, I want to put all of blue in right and orange in left side, but Amber and Nadyah are not in that order). Could you tell me how to do this?

Thanks,
Kai


-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1632171629110blob.jpg
Type: image/png
Size: 304695 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210920/44941351/attachment.png>

From c@|@ndr@ @end|ng |rom rgzm@de  Tue Sep 21 08:46:27 2021
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Tue, 21 Sep 2021 08:46:27 +0200
Subject: [R] ggsave() with width only
In-Reply-To: <4f7c4167-67f9-7710-4dfd-4f4d2fd70c44@e.email>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
 <a6477734-fefa-9cba-b7c1-b214858edd83@e.email>
 <9e4dcd06-68b7-5bf5-b4d0-85f2b549abd4@rgzm.de>
 <ecadbe34-a2cb-86da-d90f-1b172909421c@rgzm.de>
 <4f7c4167-67f9-7710-4dfd-4f4d2fd70c44@e.email>
Message-ID: <ad91f393-2b29-376e-e908-4500940ed34c@rgzm.de>

Dear Adam,

This would work indeed, but then the default aspect ratio (1.618) would 
be used. I could as well calculate the height from the width and aspect 
ratio. Unfortunately, this doesn't help me in my case (but as I said, I 
have found a workaround).

Thank you again.

Ivan

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

Le 20/09/2021 ? 21:29, Adam Wysoki?ski via R-help a ?crit?:
> Dear Ivan,
> I think you don't need to provide the aspect ratio, as this should 
> work as well:
>
> save_plot("/tmp/plot.png", p, base_width = 5, base_height = NULL)
>


From c@buhtz m@iii@g oii posteo@jp  Tue Sep 21 09:12:14 2021
From: c@buhtz m@iii@g oii posteo@jp (c@buhtz m@iii@g oii posteo@jp)
Date: Tue, 21 Sep 2021 07:12:14 +0000
Subject: [R] Windows: start script but keep being in R-shell after finish
Message-ID: <c9bf6a264166d3184026b4dece4210a4@posteo.de>

Hello together,

I was using R some years ago and I am sorry for asking such a dumb 
question. I found some help instructions about commandline interface but 
I still miss the piece of information I need. I assume it depends on my 
non-nativ English that I am not able to ask the correct (worded) 
question to the search engines.

I use R-for-windows on the shell. No GUI, IDE or anything else.
When I am in windows shell ("command prompt"?) I wan't to run an 
R-script (filename *.R). But when the script is finished or interrupted 
the R-prompt should do not close.

In python I would do

python3 -i -m myscript

Kind
Christian


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Sep 21 15:09:40 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 21 Sep 2021 09:09:40 -0400
Subject: [R] 
 Windows: start script but keep being in R-shell after finish
In-Reply-To: <c9bf6a264166d3184026b4dece4210a4@posteo.de>
References: <c9bf6a264166d3184026b4dece4210a4@posteo.de>
Message-ID: <011e9847-c4a8-c064-4944-49d9fe8f8201@gmail.com>

On 21/09/2021 3:12 a.m., c.buhtz at posteo.jp wrote:
> Hello together,
> 
> I was using R some years ago and I am sorry for asking such a dumb
> question. I found some help instructions about commandline interface but
> I still miss the piece of information I need. I assume it depends on my
> non-nativ English that I am not able to ask the correct (worded)
> question to the search engines.
> 
> I use R-for-windows on the shell. No GUI, IDE or anything else.
> When I am in windows shell ("command prompt"?) I wan't to run an
> R-script (filename *.R). But when the script is finished or interrupted
> the R-prompt should do not close.
> 
> In python I would do
> 
> python3 -i -m myscript

I don't think R supports this, but the following almost works:

   cat myscript.R - | Rterm --ess

This copies your file followed by stdin into the stdin of R.  The --ess 
option tells R to act as if input is interactive, despite what it sees.

This comes kind of close, but there are a couple of problems.

  - If I type really fast, the characters appear in the wrong order in R.
  - At the end when I quit, it sits there for a while until I hit enter, 
then gives the error message "cat: write error: no more space on device".

Perhaps these problems can be fixed.

Another approach would be to set an environment variable specifying that 
myscript.R is a user profile file, set via environment variable

  R_PROFILE_USER=myscript.R

This has the disadvantage of overriding a pre-existing user profile 
file, but if this is just for you, I guess you know if you have one.

Duncan Murdoch


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Sep 22 11:44:17 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 22 Sep 2021 11:44:17 +0200
Subject: [R] 
 Windows: start script but keep being in R-shell after finish
In-Reply-To: <011e9847-c4a8-c064-4944-49d9fe8f8201@gmail.com>
References: <c9bf6a264166d3184026b4dece4210a4@posteo.de>
 <011e9847-c4a8-c064-4944-49d9fe8f8201@gmail.com>
Message-ID: <24906.64241.572888.67079@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Tue, 21 Sep 2021 09:09:40 -0400 writes:

    > On 21/09/2021 3:12 a.m., c.buhtz at posteo.jp wrote:
    >> Hello together,
    >> 
    >> I was using R some years ago and I am sorry for asking such a dumb
    >> question. I found some help instructions about commandline interface but
    >> I still miss the piece of information I need. I assume it depends on my
    >> non-nativ English that I am not able to ask the correct (worded)
    >> question to the search engines.
    >> 
    >> I use R-for-windows on the shell. No GUI, IDE or anything else.
    >> When I am in windows shell ("command prompt"?) I wan't to run an
    >> R-script (filename *.R). But when the script is finished or interrupted
    >> the R-prompt should do not close.
    >> 
    >> In python I would do
    >> 
    >> python3 -i -m myscript

    > I don't think R supports this, but the following almost works:

    > cat myscript.R - | Rterm --ess

Inside R, we use

  source("mycript.R")

where source() has several optional arguments in addition,
such as 'echo=TRUE' 

Probably Duncan did not mention it here, because indeed, it's
not quite equivalent to running the above semi-"batch mode"...

Martin


    > This copies your file followed by stdin into the stdin of R.  The --ess 
    > option tells R to act as if input is interactive, despite what it sees.

    > This comes kind of close, but there are a couple of problems.

    > - If I type really fast, the characters appear in the wrong order in R.
    > - At the end when I quit, it sits there for a while until I hit enter, 
    > then gives the error message "cat: write error: no more space on device".

    > Perhaps these problems can be fixed.

    > Another approach would be to set an environment variable specifying that 
    > myscript.R is a user profile file, set via environment variable

    > R_PROFILE_USER=myscript.R

    > This has the disadvantage of overriding a pre-existing user profile 
    > file, but if this is just for you, I guess you know if you have one.

    > Duncan Murdoch

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From biii m@iii@g oii de@@ey@ws  Wed Sep 22 16:21:45 2021
From: biii m@iii@g oii de@@ey@ws (biii m@iii@g oii de@@ey@ws)
Date: Wed, 22 Sep 2021 10:21:45 -0400
Subject: [R] Trying to Learn Details of Grid Graphics, Help Page Errors
Message-ID: <01e301d7afbd$2c8173c0$85845b40$@denney.ws>

Hello,

 

I'm trying to learn the details of grid graphics.  Specifically, I'm trying
to create a check that will give a warning or error if text goes outside of
the visible plot area.  (See
https://github.com/tidyverse/ggplot2/issues/3282 for an example of what I
mean.)

 

In my digging, I think that the right way to do this will be to add either a
drawDetails, preDrawDetails, or postDrawDetails method for the "text" class.
My questions are:  Is that the right way to do it or should I be looking
elsewhere?  Or, is there already a way to do this?

 

As I was digging in and trying to learn how to do it, I tried to follow some
of the examples from the help page for drawDetails (?drawDetails).  But, the
suggested functions to review do not exist.  Specifically, I wanted to look
at grid:::preDrawDetails.frame mentioned in the second paragraph of the
Details section of the help page, and it doesn't exist.
grid:::drawDetails.xaxis and grid:::postDrawDetails.frame also do not exist
(mentioned in the next two paragraphs).

 

I would try to make patch, but there is no preDrawDetails or postDrawDetails
method in grid that has any content.  For drawDetails, there are many
choices, and since I'm learning, I'm not sure which would be the best to use
as an example.

 

Thanks,

 

Bill


	[[alternative HTML version deleted]]


From @|nghk@hwet@ @end|ng |rom gm@||@com  Tue Sep 21 23:20:14 2021
From: @|nghk@hwet@ @end|ng |rom gm@||@com (Shweta Singh)
Date: Wed, 22 Sep 2021 02:50:14 +0530
Subject: [R] Codes of Fourier Transformation
Message-ID: <CAFCqL5ThCMg7ngZdZTwhTKyKC5nLVBHjXhWVeTPCt0E6eozVZA@mail.gmail.com>

Dear Sir/Madam
                  I wanted to know the codes of Fourier Transformation of
time series data.

	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Wed Sep 22 20:42:11 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Wed, 22 Sep 2021 18:42:11 +0000 (UTC)
Subject: [R] Improve my plot
In-Reply-To: <CA+8X3fWgvd8bV-QkGN7oQFCt7+mYsBrUpVLVA4_tPiUosUBcEg@mail.gmail.com>
References: <356566108.2700529.1632165844251.ref@mail.yahoo.com>
 <356566108.2700529.1632165844251@mail.yahoo.com>
 <CA+8X3fWgvd8bV-QkGN7oQFCt7+mYsBrUpVLVA4_tPiUosUBcEg@mail.gmail.com>
Message-ID: <1523820432.519651.1632336131358@mail.yahoo.com>

Hi,

Many thanks to all of you for your precious help.

Best,



Le mardi 21 septembre 2021, 00:12:02 UTC+2, Jim Lemon <drjimlemon at gmail.com> a ?crit : 





Hi varin,
Not too difficult:

par(mar=c(5,13,4,1))
barplot(height=c(574,557,544,535,534,532,531,527,526,525,524,520,518,
512,507,504,504,489,488,488,487,484,484,474,472,455,444,420),
names.arg=c("Fribourg(f)","Valais(d)",
"Appenzell Rhodes Int?rieures","Fribourg(d)","Jura","Schwyz",
"Schaffhouse","Berne(f)","Thurgovie","Valais(f)","Argovie",
"Appenzell Rhodes Ext?rieures","Gen?ve","Zoug","Tessin",
"Neuch?tel","Vaud","Uri","Nidwald","Berne(d)","Zurich","Obwald",
"Saint-Gall","Soleure","Lucerne","Glaris","B?le-Campagne","B?le-Ville"),
horiz=TRUE,col="deepskyblue2",las=2,xlim=c(0,650),font.axis=4)

With regard to Bert's objection to barplots, you can do the same thing there.

Jim

On Tue, Sep 21, 2021 at 5:24 AM varin sacha via R-help
<r-help at r-project.org> wrote:
>
> Dear R-experts,
>
> Here below my R code. I would need your help to improve my graph/plot.
>
> - The x-axis to be longer not to stop at 500 value
> - All the name on the y-axis to appear not only a few of them and the name (Fribourg(f), Appenzell Rhodes Int?rieures,...) to appear entire, not to be cut
>
> Many thanks.
>
> ##############
> barplot(height=c(574,557,544,535,534,532,531,527,526,525,524,520,518,512,507,504,504,489,488,488,487,484,484,474,472,455,444,420),names.arg=c("Fribourg(f)","Valais(d)","Appenzell Rhodes Int?rieures","Fribourg(d)","Jura","Schwyz","Schaffhouse","Berne(f)","Thurgovie","Valais(f)","Argovie","Appenzell Rhodes Ext?rieures","Gen?ve","Zoug","Tessin","Neuch?tel","Vaud","Uri","Nidwald","Berne(d)","Zurich","Obwald","Saint-Gall","Soleure","Lucerne","Glaris","B?le-Campagne","B?le-Ville"),font.axis=4, horiz=T,col="deepskyblue2",las=2)

> ##############
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S@E|||@on @end|ng |rom LGCGroup@com  Wed Sep 22 22:38:46 2021
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Wed, 22 Sep 2021 20:38:46 +0000
Subject: [R] 
 POTENTIAL PHISHING E-MAIL:   Codes of Fourier Transformation
In-Reply-To: <CAFCqL5ThCMg7ngZdZTwhTKyKC5nLVBHjXhWVeTPCt0E6eozVZA@mail.gmail.com>
References: <CAFCqL5ThCMg7ngZdZTwhTKyKC5nLVBHjXhWVeTPCt0E6eozVZA@mail.gmail.com>
Message-ID: <LOYP265MB18375097546163EE129CA0B081A29@LOYP265MB1837.GBRP265.PROD.OUTLOOK.COM>

> I wanted to know the codes of Fourier Transformation of time series
> data.
The location of complete source code for all versions of R is given at 
https://cran.r-project.org/sources.html

fft is in the stats package and is implemented as a call to C code, so you'll need to look in the C source code after unpacking the tar.gz archive; you can find the called function name by typing 'fft' at the R command line.

For code specific to time series you'll have to identify the R package you're using and find the source code repository for that. R is open source so the code for packages should be publicly available.



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Wed Sep 22 22:49:43 2021
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Thu, 23 Sep 2021 08:49:43 +1200
Subject: [R] Trying to Learn Details of Grid Graphics, Help Page Errors
In-Reply-To: <01e301d7afbd$2c8173c0$85845b40$@denney.ws>
References: <01e301d7afbd$2c8173c0$85845b40$@denney.ws>
Message-ID: <1da75c30-6cd9-2e74-c518-c6228df2428d@stat.auckland.ac.nz>

Hi

The first place you should probably start (given where you are right 
now) is this R Journal article ...

https://journal.r-project.org/archive/2013/RJ-2013-035/RJ-2013-035.pdf

In brief, the drawDetails() function has been (almost entirely) 
superceded by the makeContent() function.

The best overall reference is probably the "R Graphics" book (3rd 
edition, chapts 6, 7, & 8).  Unfortunately, because the first edition 
came out in 2005, that is an Olde Worlde pay-for-a-print-version book 
(and probably will be until something stupid like 50 years after I have 
gone).  Or maybe you are lucky and work for a first-world university 
that has purchased access to an electronic version.

Thanks for pointing out the problems with the drawDetails() help page; I 
will need to fix that.

Paul

On 9/23/2021 2:21 AM, bill at denney.ws wrote:
> Hello,
> 
> 
> 
> I'm trying to learn the details of grid graphics. Specifically, I'm trying
> to create a check that will give a warning or error if text goes outside of
> the visible plot area. (See
> https://github.com/tidyverse/ggplot2/issues/3282 
> <https://github.com/tidyverse/ggplot2/issues/3282> 
> for an example of what I
> mean.)
> 
> 
> 
> In my digging, I think that the right way to do this will be to add either a
> drawDetails, preDrawDetails, or postDrawDetails method for the "text" class.
> My questions are: Is that the right way to do it or should I be looking
> elsewhere? Or, is there already a way to do this?
> 
> 
> 
> As I was digging in and trying to learn how to do it, I tried to follow some
> of the examples from the help page for drawDetails (?drawDetails). But, the
> suggested functions to review do not exist. Specifically, I wanted to look
> at grid:::preDrawDetails.frame mentioned in the second paragraph of the
> Details section of the help page, and it doesn't exist.
> grid:::drawDetails.xaxis and grid:::postDrawDetails.frame also do not exist
> (mentioned in the next two paragraphs).
> 
> 
> 
> I would try to make patch, but there is no preDrawDetails or postDrawDetails
> method in grid that has any content. For drawDetails, there are many
> choices, and since I'm learning, I'm not sure which would be the best to use
> as an example.
> 
> 
> 
> Thanks,
> 
> 
> 
> Bill
> 
> 
> [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From biii m@iii@g oii de@@ey@ws  Fri Sep 24 05:15:22 2021
From: biii m@iii@g oii de@@ey@ws (biii m@iii@g oii de@@ey@ws)
Date: Thu, 23 Sep 2021 23:15:22 -0400
Subject: [R] Trying to Learn Details of Grid Graphics, Help Page Errors
In-Reply-To: <1da75c30-6cd9-2e74-c518-c6228df2428d@stat.auckland.ac.nz>
References: <01e301d7afbd$2c8173c0$85845b40$@denney.ws>
 <1da75c30-6cd9-2e74-c518-c6228df2428d@stat.auckland.ac.nz>
Message-ID: <03ba01d7b0f2$69792440$3c6b6cc0$@denney.ws>

Hi Paul,

Thanks very much for the pointer!

With that and a bit more investigation, I was able to make the following
functions that seem to work in initial testing.

Thanks,

Bill

library(grid)

# The no_clipping function indicates if a shape is clipped in any dimension
# relative to the entire device.  It should work for any rectangular shaped
# grob.
no_clipping <- function(x) {
  # Check the cardinal directions and corners to allow for any rotation
  angles <- seq(0, 3.5, by=0.5)*90
  if ("rot" %in% names(x)) {
    # At least text grobs have a "rot" attribute
    angles <- angles + (x$rot*pi/180)
  }
  edges_raw <-
    grid::deviceLoc(
      x=grid::grobX(x, theta=angles),
      y=grid::grobY(x, theta=angles)
    )
  edges <-
    list(
      x=grid::convertX(edges_raw$x, unitTo="cm", valueOnly=TRUE),
      y=grid::convertY(edges_raw$y, unitTo="cm", valueOnly=TRUE)
    )
  d_size <- dev.size(units="cm")
  c(
    bottom=0 <= min(edges$y),
    top=max(edges$y) <= d_size[2],
    left=0 <= min(edges$x),
    right=max(edges$x) <= d_size[1]
  )
}

makeContent.text <- function(x) {
  if (!all(no_clipping(x))) {
    warning(
      "Graphics text is outside of the device: ",
      paste0("'", x$label, "'", collapse=", ")
    )
  }
  x
}

Code I used for testing:

graphics.off()
foo <- grid.text(label="foo bar", x=0.95, y=0.9)
no_clipping(foo)
graphics.off()
foo <- grid.text(label="foo bar", x=0.9, y=0.9)
no_clipping(foo)
graphics.off()
foo <- grid.text(label="foo bar", x=0.95, y=0.9, rot=45)
no_clipping(foo)
foo <- grid.text(label="foo bar", x=0.96, y=0.9, rot=45)
no_clipping(foo)
graphics.off()
foo <- grid.text(label="foo bar", x=0.96, y=0.9, rot=80)
no_clipping(foo)
graphics.off()
foo <- grid.rect(x=0.8, y=0.8, width=0.15, height=0.15, default.units="npc",
just=c(0, 0))
no_clipping(foo)
graphics.off()
vp <- viewport(angle=45)
foo <- grid.rect(x=0.8, y=0.8, width=0.15, height=0.15, default.units="npc",
just=c(0, 0), vp=vp)
no_clipping(foo)

# It also works with ggplot2
library(ggplot2)
data_with_long_names <-
  data.frame(
    A=c(paste0(rep(LETTERS, 3), collapse=""), "ab", paste0(rep(letters, 3),
collapse="")),
    B=1
  )

# Feature request: This gives a warning
ggplot(data_with_long_names, aes(x=A, y=B)) +
  geom_point()

ggplot(data_with_long_names, aes(x=A, y=B)) +
  geom_point() +
  theme(
    axis.text.x=element_text(angle=45, hjust=1, vjust=1, size=rel(0.5))
  )

-----Original Message-----
From: Paul Murrell <paul at stat.auckland.ac.nz> 
Sent: Wednesday, September 22, 2021 4:50 PM
To: bill at denney.ws; r-help at r-project.org
Subject: Re: [R] Trying to Learn Details of Grid Graphics, Help Page Errors

Hi

The first place you should probably start (given where you are right
now) is this R Journal article ...

https://journal.r-project.org/archive/2013/RJ-2013-035/RJ-2013-035.pdf

In brief, the drawDetails() function has been (almost entirely) superceded
by the makeContent() function.

The best overall reference is probably the "R Graphics" book (3rd edition,
chapts 6, 7, & 8).  Unfortunately, because the first edition came out in
2005, that is an Olde Worlde pay-for-a-print-version book (and probably will
be until something stupid like 50 years after I have gone).  Or maybe you
are lucky and work for a first-world university that has purchased access to
an electronic version.

Thanks for pointing out the problems with the drawDetails() help page; I
will need to fix that.

Paul

On 9/23/2021 2:21 AM, bill at denney.ws wrote:
> Hello,
> 
> 
> 
> I'm trying to learn the details of grid graphics. Specifically, I'm 
> trying to create a check that will give a warning or error if text 
> goes outside of the visible plot area. (See
> https://github.com/tidyverse/ggplot2/issues/3282
> <https://github.com/tidyverse/ggplot2/issues/3282>
> for an example of what I
> mean.)
> 
> 
> 
> In my digging, I think that the right way to do this will be to add 
> either a drawDetails, preDrawDetails, or postDrawDetails method for the
"text" class.
> My questions are: Is that the right way to do it or should I be 
> looking elsewhere? Or, is there already a way to do this?
> 
> 
> 
> As I was digging in and trying to learn how to do it, I tried to 
> follow some of the examples from the help page for drawDetails 
> (?drawDetails). But, the suggested functions to review do not exist. 
> Specifically, I wanted to look at grid:::preDrawDetails.frame 
> mentioned in the second paragraph of the Details section of the help page,
and it doesn't exist.
> grid:::drawDetails.xaxis and grid:::postDrawDetails.frame also do not 
> exist (mentioned in the next two paragraphs).
> 
> 
> 
> I would try to make patch, but there is no preDrawDetails or 
> postDrawDetails method in grid that has any content. For drawDetails, 
> there are many choices, and since I'm learning, I'm not sure which 
> would be the best to use as an example.
> 
> 
> 
> Thanks,
> 
> 
> 
> Bill
> 
> 
> [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

--
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Sep 24 16:09:54 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 24 Sep 2021 16:09:54 +0200
Subject: [R] alternative to subset(dataframe, select = - column) in R
Message-ID: <CAMk+s2QCgRgUa+fzoQ1c749T8kjThstcBgDW0NbMsLxHONPZDQ@mail.gmail.com>

Hello,
this is a very simple question but...
what is the vector alternative to `subset(dataframe, select = - column)`?
I tried with:
```
> x = new[-ID]
Error in `[.data.frame`(new, -ID) : object 'ID' not found
> x = new[-"ID"]
Error in -"ID" : invalid argument to unary operator
> x = new[[-"ID"]]
Error in -"ID" : invalid argument to unary operator
> x = new[-["ID"]]
Error: unexpected '[' in "x = new[-["
```
Thank you


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 24 16:31:15 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 24 Sep 2021 07:31:15 -0700
Subject: [R] alternative to subset(dataframe, select = - column) in R
In-Reply-To: <CAMk+s2QCgRgUa+fzoQ1c749T8kjThstcBgDW0NbMsLxHONPZDQ@mail.gmail.com>
References: <CAMk+s2QCgRgUa+fzoQ1c749T8kjThstcBgDW0NbMsLxHONPZDQ@mail.gmail.com>
Message-ID: <CAGxFJbR4Yb+QsV_Dd9+_=m8yvLb8LzQw9p9hhN6bbUXX6M1MnQ@mail.gmail.com>

x <- new[-match("ID"), names(new))]

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 24, 2021 at 7:10 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> this is a very simple question but...
> what is the vector alternative to `subset(dataframe, select = - column)`?
> I tried with:
> ```
> > x = new[-ID]
> Error in `[.data.frame`(new, -ID) : object 'ID' not found
> > x = new[-"ID"]
> Error in -"ID" : invalid argument to unary operator
> > x = new[[-"ID"]]
> Error in -"ID" : invalid argument to unary operator
> > x = new[-["ID"]]
> Error: unexpected '[' in "x = new[-["
> ```
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep 24 16:43:27 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 24 Sep 2021 07:43:27 -0700
Subject: [R] alternative to subset(dataframe, select = - column) in R
In-Reply-To: <CAMk+s2QCgRgUa+fzoQ1c749T8kjThstcBgDW0NbMsLxHONPZDQ@mail.gmail.com>
References: <CAMk+s2QCgRgUa+fzoQ1c749T8kjThstcBgDW0NbMsLxHONPZDQ@mail.gmail.com>
Message-ID: <5001BF0D-7216-4A97-B590-93A6A9CB43FD@dcn.davis.ca.us>

The subset function

subset( new, select = -ID )

uses non-standard evaluation... it "knows" that when you write the language symbol ID it may match to one of the column names in new, and the `-` in the select argument will be noticed before R tries to change the sign of a variable ID in your calling environment and cause subset to remove the "ID" column from the returned version of new.

The vector indexing operator does none of that, so whatever indexing arguments you specify need to be valid expressions on their own without the indexing operator.

-ID
   You don't have a variable called ID, so its sign vanity be changed

-"ID"
   Changing the sign of a character literal is not a defined operation

-["ID"]
   Standalone brackets have no meaning in R... only can be used directly adjacent to a vector to the right.

What you do have is the data frame `new`... and it has names, and among those names is "ID", so...

"ID" != names( new )
   should be a logical vector with FALSE in the position corresponding to "ID", so

new[ , "ID" != names( new ) ]

will select all of the columns other than the "ID" column.

If you want to deselect more than one column, then the %in% operator can help:

! names( new ) %in% c( "ID", "Other" )

will be a logical vector with FALSE in the corresponding positions.


On September 24, 2021 7:09:54 AM PDT, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>Hello,
>this is a very simple question but...
>what is the vector alternative to `subset(dataframe, select = - column)`?
>I tried with:
>```
>> x = new[-ID]
>Error in `[.data.frame`(new, -ID) : object 'ID' not found
>> x = new[-"ID"]
>Error in -"ID" : invalid argument to unary operator
>> x = new[[-"ID"]]
>Error in -"ID" : invalid argument to unary operator
>> x = new[-["ID"]]
>Error: unexpected '[' in "x = new[-["
>```
>Thank you
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 24 17:07:43 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 24 Sep 2021 08:07:43 -0700
Subject: [R] alternative to subset(dataframe, select = - column) in R
In-Reply-To: <CAGxFJbR4Yb+QsV_Dd9+_=m8yvLb8LzQw9p9hhN6bbUXX6M1MnQ@mail.gmail.com>
References: <CAMk+s2QCgRgUa+fzoQ1c749T8kjThstcBgDW0NbMsLxHONPZDQ@mail.gmail.com>
 <CAGxFJbR4Yb+QsV_Dd9+_=m8yvLb8LzQw9p9hhN6bbUXX6M1MnQ@mail.gmail.com>
Message-ID: <CAGxFJbT9LZy_Y8Z4LkUYu+OFSmpFguZ5EiBeGGVq6BtVHZE_7A@mail.gmail.com>

typo. Correction:

x <- new[-match("ID", names(new))]

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 24, 2021 at 7:31 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> x <- new[-match("ID"), names(new))]
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Fri, Sep 24, 2021 at 7:10 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > this is a very simple question but...
> > what is the vector alternative to `subset(dataframe, select = - column)`?
> > I tried with:
> > ```
> > > x = new[-ID]
> > Error in `[.data.frame`(new, -ID) : object 'ID' not found
> > > x = new[-"ID"]
> > Error in -"ID" : invalid argument to unary operator
> > > x = new[[-"ID"]]
> > Error in -"ID" : invalid argument to unary operator
> > > x = new[-["ID"]]
> > Error: unexpected '[' in "x = new[-["
> > ```
> > Thank you
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Sep 24 19:33:21 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 24 Sep 2021 18:33:21 +0100
Subject: [R] alternative to subset(dataframe, select = - column) in R
In-Reply-To: <CAMk+s2QCgRgUa+fzoQ1c749T8kjThstcBgDW0NbMsLxHONPZDQ@mail.gmail.com>
References: <CAMk+s2QCgRgUa+fzoQ1c749T8kjThstcBgDW0NbMsLxHONPZDQ@mail.gmail.com>
Message-ID: <fd59cf83-5194-59a9-fe6d-deb9d72d61da@sapo.pt>

Hello,

Like this?


mtcars[names(mtcars) != "mpg"]


Hope this helps,

Rui Barradas

?s 15:09 de 24/09/21, Luigi Marongiu escreveu:
> Hello,
> this is a very simple question but...
> what is the vector alternative to `subset(dataframe, select = - column)`?
> I tried with:
> ```
>> x = new[-ID]
> Error in `[.data.frame`(new, -ID) : object 'ID' not found
>> x = new[-"ID"]
> Error in -"ID" : invalid argument to unary operator
>> x = new[[-"ID"]]
> Error in -"ID" : invalid argument to unary operator
>> x = new[-["ID"]]
> Error: unexpected '[' in "x = new[-["
> ```
> Thank you
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kev|n@thorpe @end|ng |rom utoronto@c@  Fri Sep 24 19:40:41 2021
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Fri, 24 Sep 2021 17:40:41 +0000
Subject: [R] Unusual Error Loading tidyverse
Message-ID: <1BF57FD6-084F-417A-B427-CA605963FD5D@utoronto.ca>

Below is some output from one of my students. I have never seen this error and tried a few things (updating packages for one) but am at a loss to help further. Would appreciate suggestions that I can pass along.

Here is the error. I tried an install.packages(?xml2?) which appeared to complete but the error persists.

> library("tidyverse")
Error: package or namespace load failed for ?tidyverse? in library.dynam(lib, package, package.lib):
DLL ?xml2? not found: maybe not installed for this architecture?

Here is the sessionInfo()

> sessionInfo()
R version 4.1.1 (2021-08-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19042)

Matrix products: default

locale:
[1] LC_COLLATE=English_Canada.1252 LC_CTYPE=English_Canada.1252 LC_MONETARY=English_Canada.1252 LC_NUMERIC=C  
[5] LC_TIME=English_Canada.1252  

attached base packages:
[1] stats graphics grDevices utils datasets methods base  

loaded via a namespace (and not attached):
[1] Rcpp_1.0.7 cellranger_1.1.0 pillar_1.6.2 compiler_4.1.1 dbplyr_2.1.1 forcats_0.5.1 tools_4.1.1  
[8] jsonlite_1.7.2 lubridate_1.7.10 lifecycle_1.0.0 tibble_3.1.4 gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.11  
[15] reprex_2.0.1 DBI_1.1.1 haven_2.4.3 withr_2.4.2 dplyr_1.0.7 httr_1.4.2 fs_1.5.0  
[22] generics_0.1.0 vctrs_0.3.8 hms_1.1.0 grid_4.1.1 tidyselect_1.1.1 glue_1.4.2 R6_2.5.1  
[29] fansi_0.5.0 readxl_1.3.1 tzdb_0.1.2 tidyr_1.1.3 ggplot2_3.3.5 purrr_0.3.4 readr_2.0.1  
[36] modelr_0.1.8 magrittr_2.0.1 backports_1.2.1 scales_1.1.1 ellipsis_0.3.2 assertthat_0.2.1 colorspace_2.0-2
[43] utf8_1.2.2 munsell_0.5.0 broom_0.7.9 crayon_1.4.1 

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep 24 19:58:30 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 24 Sep 2021 10:58:30 -0700
Subject: [R] Unusual Error Loading tidyverse
In-Reply-To: <1BF57FD6-084F-417A-B427-CA605963FD5D@utoronto.ca>
References: <1BF57FD6-084F-417A-B427-CA605963FD5D@utoronto.ca>
Message-ID: <8B47DEAA-AE9E-44C5-9F8D-3D73DAD6ADE9@dcn.davis.ca.us>

Seems like they should install the xml2 package before proceeding to load whatever (tidyverse).

This kind of "dependency missing" problem tends to be a recurring problem particularly on Windows but in general when some deeply-embedded dependency fails to load or is removed in preparation for upgrading.

On September 24, 2021 10:40:41 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>Below is some output from one of my students. I have never seen this error and tried a few things (updating packages for one) but am at a loss to help further. Would appreciate suggestions that I can pass along.
>
>Here is the error. I tried an install.packages(?xml2?) which appeared to complete but the error persists.
>
>> library("tidyverse")
>Error: package or namespace load failed for ?tidyverse? in library.dynam(lib, package, package.lib):
>DLL ?xml2? not found: maybe not installed for this architecture?
>
>Here is the sessionInfo()
>
>> sessionInfo()
>R version 4.1.1 (2021-08-10)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows 10 x64 (build 19042)
>
>Matrix products: default
>
>locale:
>[1] LC_COLLATE=English_Canada.1252 LC_CTYPE=English_Canada.1252 LC_MONETARY=English_Canada.1252 LC_NUMERIC=C  
>[5] LC_TIME=English_Canada.1252  
>
>attached base packages:
>[1] stats graphics grDevices utils datasets methods base  
>
>loaded via a namespace (and not attached):
>[1] Rcpp_1.0.7 cellranger_1.1.0 pillar_1.6.2 compiler_4.1.1 dbplyr_2.1.1 forcats_0.5.1 tools_4.1.1  
>[8] jsonlite_1.7.2 lubridate_1.7.10 lifecycle_1.0.0 tibble_3.1.4 gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.11  
>[15] reprex_2.0.1 DBI_1.1.1 haven_2.4.3 withr_2.4.2 dplyr_1.0.7 httr_1.4.2 fs_1.5.0  
>[22] generics_0.1.0 vctrs_0.3.8 hms_1.1.0 grid_4.1.1 tidyselect_1.1.1 glue_1.4.2 R6_2.5.1  
>[29] fansi_0.5.0 readxl_1.3.1 tzdb_0.1.2 tidyr_1.1.3 ggplot2_3.3.5 purrr_0.3.4 readr_2.0.1  
>[36] modelr_0.1.8 magrittr_2.0.1 backports_1.2.1 scales_1.1.1 ellipsis_0.3.2 assertthat_0.2.1 colorspace_2.0-2
>[43] utf8_1.2.2 munsell_0.5.0 broom_0.7.9 crayon_1.4.1 
>

-- 
Sent from my phone. Please excuse my brevity.


From kev|n@thorpe @end|ng |rom utoronto@c@  Fri Sep 24 20:04:43 2021
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Fri, 24 Sep 2021 18:04:43 +0000
Subject: [R] Unusual Error Loading tidyverse
In-Reply-To: <8B47DEAA-AE9E-44C5-9F8D-3D73DAD6ADE9@dcn.davis.ca.us>
References: <1BF57FD6-084F-417A-B427-CA605963FD5D@utoronto.ca>
 <8B47DEAA-AE9E-44C5-9F8D-3D73DAD6ADE9@dcn.davis.ca.us>
Message-ID: <1AE05F6A-672B-4A8C-8F12-90128F95F6DD@utoronto.ca>

I did try installing xml2 and it appeared to complete. I will ask him to try again and send me the output.


> On Sep 24, 2021, at 1:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Seems like they should install the xml2 package before proceeding to load whatever (tidyverse).
> 
> This kind of "dependency missing" problem tends to be a recurring problem particularly on Windows but in general when some deeply-embedded dependency fails to load or is removed in preparation for upgrading.
> 
> On September 24, 2021 10:40:41 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>> Below is some output from one of my students. I have never seen this error and tried a few things (updating packages for one) but am at a loss to help further. Would appreciate suggestions that I can pass along.
>> 
>> Here is the error. I tried an install.packages(?xml2?) which appeared to complete but the error persists.
>> 
>>> library("tidyverse")
>> Error: package or namespace load failed for ?tidyverse? in library.dynam(lib, package, package.lib):
>> DLL ?xml2? not found: maybe not installed for this architecture?
>> 
>> Here is the sessionInfo()
>> 
>>> sessionInfo()
>> R version 4.1.1 (2021-08-10)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 19042)
>> 
>> Matrix products: default
>> 
>> locale:
>> [1] LC_COLLATE=English_Canada.1252 LC_CTYPE=English_Canada.1252 LC_MONETARY=English_Canada.1252 LC_NUMERIC=C  
>> [5] LC_TIME=English_Canada.1252  
>> 
>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base  
>> 
>> loaded via a namespace (and not attached):
>> [1] Rcpp_1.0.7 cellranger_1.1.0 pillar_1.6.2 compiler_4.1.1 dbplyr_2.1.1 forcats_0.5.1 tools_4.1.1  
>> [8] jsonlite_1.7.2 lubridate_1.7.10 lifecycle_1.0.0 tibble_3.1.4 gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.11  
>> [15] reprex_2.0.1 DBI_1.1.1 haven_2.4.3 withr_2.4.2 dplyr_1.0.7 httr_1.4.2 fs_1.5.0  
>> [22] generics_0.1.0 vctrs_0.3.8 hms_1.1.0 grid_4.1.1 tidyselect_1.1.1 glue_1.4.2 R6_2.5.1  
>> [29] fansi_0.5.0 readxl_1.3.1 tzdb_0.1.2 tidyr_1.1.3 ggplot2_3.3.5 purrr_0.3.4 readr_2.0.1  
>> [36] modelr_0.1.8 magrittr_2.0.1 backports_1.2.1 scales_1.1.1 ellipsis_0.3.2 assertthat_0.2.1 colorspace_2.0-2
>> [43] utf8_1.2.2 munsell_0.5.0 broom_0.7.9 crayon_1.4.1 
>> 
> 
> -- 
> Sent from my phone. Please excuse my brevity.

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Sep 24 21:26:41 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 24 Sep 2021 15:26:41 -0400
Subject: [R] Unusual Error Loading tidyverse
In-Reply-To: <1AE05F6A-672B-4A8C-8F12-90128F95F6DD@utoronto.ca>
References: <1BF57FD6-084F-417A-B427-CA605963FD5D@utoronto.ca>
 <8B47DEAA-AE9E-44C5-9F8D-3D73DAD6ADE9@dcn.davis.ca.us>
 <1AE05F6A-672B-4A8C-8F12-90128F95F6DD@utoronto.ca>
Message-ID: <94303eba-9239-3d62-bf23-d1c19721a6b2@gmail.com>

It is worth checking that the library where things were most recently 
installed is the first place R looks, i.e. the first entry in 
.libPaths().  Often R is installed by an administrator, and users can't 
write to the main library, so when they install packages they go 
somewhere else.  If "somewhere else" isn't first in .libPaths(), R won't 
see the new installs.

Duncan Murdoch

On 24/09/2021 2:04 p.m., Kevin Thorpe wrote:
> I did try installing xml2 and it appeared to complete. I will ask him to try again and send me the output.
> 
> 
>> On Sep 24, 2021, at 1:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> Seems like they should install the xml2 package before proceeding to load whatever (tidyverse).
>>
>> This kind of "dependency missing" problem tends to be a recurring problem particularly on Windows but in general when some deeply-embedded dependency fails to load or is removed in preparation for upgrading.
>>
>> On September 24, 2021 10:40:41 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>>> Below is some output from one of my students. I have never seen this error and tried a few things (updating packages for one) but am at a loss to help further. Would appreciate suggestions that I can pass along.
>>>
>>> Here is the error. I tried an install.packages(?xml2?) which appeared to complete but the error persists.
>>>
>>>> library("tidyverse")
>>> Error: package or namespace load failed for ?tidyverse? in library.dynam(lib, package, package.lib):
>>> DLL ?xml2? not found: maybe not installed for this architecture?
>>>
>>> Here is the sessionInfo()
>>>
>>>> sessionInfo()
>>> R version 4.1.1 (2021-08-10)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 10 x64 (build 19042)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_Canada.1252 LC_CTYPE=English_Canada.1252 LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
>>> [5] LC_TIME=English_Canada.1252
>>>
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] Rcpp_1.0.7 cellranger_1.1.0 pillar_1.6.2 compiler_4.1.1 dbplyr_2.1.1 forcats_0.5.1 tools_4.1.1
>>> [8] jsonlite_1.7.2 lubridate_1.7.10 lifecycle_1.0.0 tibble_3.1.4 gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.11
>>> [15] reprex_2.0.1 DBI_1.1.1 haven_2.4.3 withr_2.4.2 dplyr_1.0.7 httr_1.4.2 fs_1.5.0
>>> [22] generics_0.1.0 vctrs_0.3.8 hms_1.1.0 grid_4.1.1 tidyselect_1.1.1 glue_1.4.2 R6_2.5.1
>>> [29] fansi_0.5.0 readxl_1.3.1 tzdb_0.1.2 tidyr_1.1.3 ggplot2_3.3.5 purrr_0.3.4 readr_2.0.1
>>> [36] modelr_0.1.8 magrittr_2.0.1 backports_1.2.1 scales_1.1.1 ellipsis_0.3.2 assertthat_0.2.1 colorspace_2.0-2
>>> [43] utf8_1.2.2 munsell_0.5.0 broom_0.7.9 crayon_1.4.1
>>>
>>
>> -- 
>> Sent from my phone. Please excuse my brevity.
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Sep 24 21:39:05 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 24 Sep 2021 21:39:05 +0200
Subject: [R] alternative to subset(dataframe, select = - column) in R
In-Reply-To: <fd59cf83-5194-59a9-fe6d-deb9d72d61da@sapo.pt>
References: <CAMk+s2QCgRgUa+fzoQ1c749T8kjThstcBgDW0NbMsLxHONPZDQ@mail.gmail.com>
 <fd59cf83-5194-59a9-fe6d-deb9d72d61da@sapo.pt>
Message-ID: <CAMk+s2QR6Gz5FLVcMK2L6Xce_dowxiVfYNDp7z7RtR20nGuNSg@mail.gmail.com>

Thank you!
```
new_out <- new[ , "ID" != names( new ) ]
new[names(new) != "ID"]
```
worked as wanted, `new[-match("ID"), names(new)]` gave the error:
`Error in match("ID") : argument "table" is missing, with no default`.
Cheers

On Fri, Sep 24, 2021 at 7:33 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Like this?
>
>
> mtcars[names(mtcars) != "mpg"]
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 15:09 de 24/09/21, Luigi Marongiu escreveu:
> > Hello,
> > this is a very simple question but...
> > what is the vector alternative to `subset(dataframe, select = - column)`?
> > I tried with:
> > ```
> >> x = new[-ID]
> > Error in `[.data.frame`(new, -ID) : object 'ID' not found
> >> x = new[-"ID"]
> > Error in -"ID" : invalid argument to unary operator
> >> x = new[[-"ID"]]
> > Error in -"ID" : invalid argument to unary operator
> >> x = new[-["ID"]]
> > Error: unexpected '[' in "x = new[-["
> > ```
> > Thank you
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >



-- 
Best regards,
Luigi


From kev|n@thorpe @end|ng |rom utoronto@c@  Fri Sep 24 22:07:15 2021
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Fri, 24 Sep 2021 20:07:15 +0000
Subject: [R] Unusual Error Loading tidyverse
In-Reply-To: <94303eba-9239-3d62-bf23-d1c19721a6b2@gmail.com>
References: <1BF57FD6-084F-417A-B427-CA605963FD5D@utoronto.ca>
 <8B47DEAA-AE9E-44C5-9F8D-3D73DAD6ADE9@dcn.davis.ca.us>
 <1AE05F6A-672B-4A8C-8F12-90128F95F6DD@utoronto.ca>
 <94303eba-9239-3d62-bf23-d1c19721a6b2@gmail.com>
Message-ID: <BC1C8486-A212-4CE2-8510-F0807E3E1C1F@utoronto.ca>

Ah. Thanks Duncan. That makes sense based on some other messages I caught a glimpse of as we tried some things. I will investigate down this line.


> On Sep 24, 2021, at 3:26 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> It is worth checking that the library where things were most recently installed is the first place R looks, i.e. the first entry in .libPaths().  Often R is installed by an administrator, and users can't write to the main library, so when they install packages they go somewhere else.  If "somewhere else" isn't first in .libPaths(), R won't see the new installs.
> 
> Duncan Murdoch
> 
> On 24/09/2021 2:04 p.m., Kevin Thorpe wrote:
>> I did try installing xml2 and it appeared to complete. I will ask him to try again and send me the output.
>>> On Sep 24, 2021, at 1:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>> 
>>> Seems like they should install the xml2 package before proceeding to load whatever (tidyverse).
>>> 
>>> This kind of "dependency missing" problem tends to be a recurring problem particularly on Windows but in general when some deeply-embedded dependency fails to load or is removed in preparation for upgrading.
>>> 
>>> On September 24, 2021 10:40:41 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>>>> Below is some output from one of my students. I have never seen this error and tried a few things (updating packages for one) but am at a loss to help further. Would appreciate suggestions that I can pass along.
>>>> 
>>>> Here is the error. I tried an install.packages(?xml2?) which appeared to complete but the error persists.
>>>> 
>>>>> library("tidyverse")
>>>> Error: package or namespace load failed for ?tidyverse? in library.dynam(lib, package, package.lib):
>>>> DLL ?xml2? not found: maybe not installed for this architecture?
>>>> 
>>>> Here is the sessionInfo()
>>>> 
>>>>> sessionInfo()
>>>> R version 4.1.1 (2021-08-10)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>> Running under: Windows 10 x64 (build 19042)
>>>> 
>>>> Matrix products: default
>>>> 
>>>> locale:
>>>> [1] LC_COLLATE=English_Canada.1252 LC_CTYPE=English_Canada.1252 LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
>>>> [5] LC_TIME=English_Canada.1252
>>>> 
>>>> attached base packages:
>>>> [1] stats graphics grDevices utils datasets methods base
>>>> 
>>>> loaded via a namespace (and not attached):
>>>> [1] Rcpp_1.0.7 cellranger_1.1.0 pillar_1.6.2 compiler_4.1.1 dbplyr_2.1.1 forcats_0.5.1 tools_4.1.1
>>>> [8] jsonlite_1.7.2 lubridate_1.7.10 lifecycle_1.0.0 tibble_3.1.4 gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.11
>>>> [15] reprex_2.0.1 DBI_1.1.1 haven_2.4.3 withr_2.4.2 dplyr_1.0.7 httr_1.4.2 fs_1.5.0
>>>> [22] generics_0.1.0 vctrs_0.3.8 hms_1.1.0 grid_4.1.1 tidyselect_1.1.1 glue_1.4.2 R6_2.5.1
>>>> [29] fansi_0.5.0 readxl_1.3.1 tzdb_0.1.2 tidyr_1.1.3 ggplot2_3.3.5 purrr_0.3.4 readr_2.0.1
>>>> [36] modelr_0.1.8 magrittr_2.0.1 backports_1.2.1 scales_1.1.1 ellipsis_0.3.2 assertthat_0.2.1 colorspace_2.0-2
>>>> [43] utf8_1.2.2 munsell_0.5.0 broom_0.7.9 crayon_1.4.1
>>>> 
>>> 
>>> -- 
>>> Sent from my phone. Please excuse my brevity.
> 

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 24 23:13:55 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 24 Sep 2021 14:13:55 -0700
Subject: [R] alternative to subset(dataframe, select = - column) in R
In-Reply-To: <CAMk+s2QR6Gz5FLVcMK2L6Xce_dowxiVfYNDp7z7RtR20nGuNSg@mail.gmail.com>
References: <CAMk+s2QCgRgUa+fzoQ1c749T8kjThstcBgDW0NbMsLxHONPZDQ@mail.gmail.com>
 <fd59cf83-5194-59a9-fe6d-deb9d72d61da@sapo.pt>
 <CAMk+s2QR6Gz5FLVcMK2L6Xce_dowxiVfYNDp7z7RtR20nGuNSg@mail.gmail.com>
Message-ID: <CAGxFJbS3Zj2rW6L3ezDViXjOhA=1rTvq7UmyPi3bPAxkAsFJyw@mail.gmail.com>

If you correct my typo as my followup message indicated, match() works
fine. As does logical indexing with %in%. The != version will work for
your query, but does not generalize to deleting several columns. The
point is to heed Jeff N's advice.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Fri, Sep 24, 2021 at 12:43 PM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
>
> Thank you!
> ```
> new_out <- new[ , "ID" != names( new ) ]
> new[names(new) != "ID"]
> ```
> worked as wanted, `new[-match("ID"), names(new)]` gave the error:
> `Error in match("ID") : argument "table" is missing, with no default`.
> Cheers
>
> On Fri, Sep 24, 2021 at 7:33 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > Like this?
> >
> >
> > mtcars[names(mtcars) != "mpg"]
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 15:09 de 24/09/21, Luigi Marongiu escreveu:
> > > Hello,
> > > this is a very simple question but...
> > > what is the vector alternative to `subset(dataframe, select = - column)`?
> > > I tried with:
> > > ```
> > >> x = new[-ID]
> > > Error in `[.data.frame`(new, -ID) : object 'ID' not found
> > >> x = new[-"ID"]
> > > Error in -"ID" : invalid argument to unary operator
> > >> x = new[[-"ID"]]
> > > Error in -"ID" : invalid argument to unary operator
> > >> x = new[-["ID"]]
> > > Error: unexpected '[' in "x = new[-["
> > > ```
> > > Thank you
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sat Sep 25 01:55:59 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sat, 25 Sep 2021 02:55:59 +0300
Subject: [R] Installed packages: Bioconductor vs CRAN?
Message-ID: <ffb01865-549e-d061-14ec-03d60b749a78@syonic.eu>

Dear List Members,


Is there a way to extract if an installed package is from Bioconductor 
or if it is a regular Cran package?


The information seems to be *not* available in:

installed.packages()


Sincerely,


Leonard

=======

I started to write some utility functions to analyse installed packages. 
The latest version is on Github:
https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R


# Basic Info:
info.pkg = function(pkg=NULL) {
 ??? if(is.null(pkg)) { pkg = installed.packages(); }
 ??? else {
 ??? ??? all.pkg = installed.packages();
 ??? ??? pkg = all.pkg[all.pkg[,1] %in% pkg, ];
 ??? }
 ??? p = pkg;
 ??? p = as.data.frame(p);
 ??? p = p[ , c("Package", "Version", "Built", "Imports")];
 ??? return(p);
}
# Imported packages:
imports.pkg = function(pkg=NULL, sort=TRUE) {
 ??? p = info.pkg(pkg);
 ??? ### Imported packages
 ??? imp = lapply(p$Imports, function(s) strsplit(s, "[,][ ]*"))
 ??? imp = unlist(imp)
 ??? imp = imp[ ! is.na(imp)]
 ??? # Cleanup:
 ??? imp = sub("[ \n\r\t]*+\\([-,. >=0-9\n\t\r]++\\) *+$", "", imp, 
perl=TRUE)
 ??? imp = sub("^[ \n\r\t]++", "", imp, perl=TRUE);
 ??? # Tabulate:
 ??? tbl = as.data.frame(table(imp), stringsAsFactors=FALSE);
 ??? names(tbl)[1] = "Name";
 ??? if(sort) {
 ??? ??? id = order(tbl$Freq, decreasing=TRUE);
 ??? ??? tbl = tbl[id,];
 ??? }
 ??? return(tbl);
}

match.imports = function(pkg, x=NULL, quote=FALSE) {
 ??? if(is.null(x)) x = info.pkg();
 ??? if(quote) {
 ??? ??? pkg = paste0("\\Q", pkg, "\\E");
 ??? }
 ??? # TODO: Use word delimiters?
 ??? # "(<?=^|[ \n\r\t],)"
 ??? if(length(pkg) == 1) {
 ??? ??? isImport = grepl(pkg, x$Imports);
 ??? ??? return(x[isImport, ]);
 ??? } else {
 ??? ??? # TODO: concept?
 ??? ??? rez = lapply(pkg, function(p) x[grepl(p, x$Imports), ]);
 ??? ??? return(rez);
 ??? }
}

Examples:

p = info.pkg();
f = imports.pkg();

### Analyze data

# imported only once: (only in the locally installed packages)
f$Name[f$Freq == 1]

match.imports("hunspell", p)
match.imports("labeling", p)
match.imports("rpart.plot", p)

match.imports(c("pROC", "ROCR"), p)


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep 25 02:06:28 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 24 Sep 2021 17:06:28 -0700
Subject: [R] Installed packages: Bioconductor vs CRAN?
In-Reply-To: <ffb01865-549e-d061-14ec-03d60b749a78@syonic.eu>
References: <ffb01865-549e-d061-14ec-03d60b749a78@syonic.eu>
Message-ID: <CAGxFJbTa2eSWRKcGpxe+RBjEbH9A3p4GEoXUZYLitXH-h_g2FQ@mail.gmail.com>

The help file tells you that installed.packages() looks at the
DESCRIPTION files of packages.
Section 1.1.1 of "Writing R Extensions" tells you what information is
in such files.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 24, 2021 at 4:56 PM Leonard Mada via R-help
<r-help at r-project.org> wrote:
>
> Dear List Members,
>
>
> Is there a way to extract if an installed package is from Bioconductor
> or if it is a regular Cran package?
>
>
> The information seems to be *not* available in:
>
> installed.packages()
>
>
> Sincerely,
>
>
> Leonard
>
> =======
>
> I started to write some utility functions to analyse installed packages.
> The latest version is on Github:
> https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
>
>
> # Basic Info:
> info.pkg = function(pkg=NULL) {
>      if(is.null(pkg)) { pkg = installed.packages(); }
>      else {
>          all.pkg = installed.packages();
>          pkg = all.pkg[all.pkg[,1] %in% pkg, ];
>      }
>      p = pkg;
>      p = as.data.frame(p);
>      p = p[ , c("Package", "Version", "Built", "Imports")];
>      return(p);
> }
> # Imported packages:
> imports.pkg = function(pkg=NULL, sort=TRUE) {
>      p = info.pkg(pkg);
>      ### Imported packages
>      imp = lapply(p$Imports, function(s) strsplit(s, "[,][ ]*"))
>      imp = unlist(imp)
>      imp = imp[ ! is.na(imp)]
>      # Cleanup:
>      imp = sub("[ \n\r\t]*+\\([-,. >=0-9\n\t\r]++\\) *+$", "", imp,
> perl=TRUE)
>      imp = sub("^[ \n\r\t]++", "", imp, perl=TRUE);
>      # Tabulate:
>      tbl = as.data.frame(table(imp), stringsAsFactors=FALSE);
>      names(tbl)[1] = "Name";
>      if(sort) {
>          id = order(tbl$Freq, decreasing=TRUE);
>          tbl = tbl[id,];
>      }
>      return(tbl);
> }
>
> match.imports = function(pkg, x=NULL, quote=FALSE) {
>      if(is.null(x)) x = info.pkg();
>      if(quote) {
>          pkg = paste0("\\Q", pkg, "\\E");
>      }
>      # TODO: Use word delimiters?
>      # "(<?=^|[ \n\r\t],)"
>      if(length(pkg) == 1) {
>          isImport = grepl(pkg, x$Imports);
>          return(x[isImport, ]);
>      } else {
>          # TODO: concept?
>          rez = lapply(pkg, function(p) x[grepl(p, x$Imports), ]);
>          return(rez);
>      }
> }
>
> Examples:
>
> p = info.pkg();
> f = imports.pkg();
>
> ### Analyze data
>
> # imported only once: (only in the locally installed packages)
> f$Name[f$Freq == 1]
>
> match.imports("hunspell", p)
> match.imports("labeling", p)
> match.imports("rpart.plot", p)
>
> match.imports(c("pROC", "ROCR"), p)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep 25 02:09:48 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 24 Sep 2021 17:09:48 -0700
Subject: [R] Installed packages: Bioconductor vs CRAN?
In-Reply-To: <CAGxFJbTa2eSWRKcGpxe+RBjEbH9A3p4GEoXUZYLitXH-h_g2FQ@mail.gmail.com>
References: <ffb01865-549e-d061-14ec-03d60b749a78@syonic.eu>
 <CAGxFJbTa2eSWRKcGpxe+RBjEbH9A3p4GEoXUZYLitXH-h_g2FQ@mail.gmail.com>
Message-ID: <CAGxFJbTqH46WZMW8ZCEaXuXfeuuOw1RPioXNMSLtEbHcYyz=KA@mail.gmail.com>

Oh, I should have added that packages can be on other repositories
(local, github,...) and I think can be both in CRAN and BIOC . So your
query would not seem to have a clear answer. AFAICS anyway.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 24, 2021 at 5:06 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> The help file tells you that installed.packages() looks at the
> DESCRIPTION files of packages.
> Section 1.1.1 of "Writing R Extensions" tells you what information is
> in such files.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Fri, Sep 24, 2021 at 4:56 PM Leonard Mada via R-help
> <r-help at r-project.org> wrote:
> >
> > Dear List Members,
> >
> >
> > Is there a way to extract if an installed package is from Bioconductor
> > or if it is a regular Cran package?
> >
> >
> > The information seems to be *not* available in:
> >
> > installed.packages()
> >
> >
> > Sincerely,
> >
> >
> > Leonard
> >
> > =======
> >
> > I started to write some utility functions to analyse installed packages.
> > The latest version is on Github:
> > https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
> >
> >
> > # Basic Info:
> > info.pkg = function(pkg=NULL) {
> >      if(is.null(pkg)) { pkg = installed.packages(); }
> >      else {
> >          all.pkg = installed.packages();
> >          pkg = all.pkg[all.pkg[,1] %in% pkg, ];
> >      }
> >      p = pkg;
> >      p = as.data.frame(p);
> >      p = p[ , c("Package", "Version", "Built", "Imports")];
> >      return(p);
> > }
> > # Imported packages:
> > imports.pkg = function(pkg=NULL, sort=TRUE) {
> >      p = info.pkg(pkg);
> >      ### Imported packages
> >      imp = lapply(p$Imports, function(s) strsplit(s, "[,][ ]*"))
> >      imp = unlist(imp)
> >      imp = imp[ ! is.na(imp)]
> >      # Cleanup:
> >      imp = sub("[ \n\r\t]*+\\([-,. >=0-9\n\t\r]++\\) *+$", "", imp,
> > perl=TRUE)
> >      imp = sub("^[ \n\r\t]++", "", imp, perl=TRUE);
> >      # Tabulate:
> >      tbl = as.data.frame(table(imp), stringsAsFactors=FALSE);
> >      names(tbl)[1] = "Name";
> >      if(sort) {
> >          id = order(tbl$Freq, decreasing=TRUE);
> >          tbl = tbl[id,];
> >      }
> >      return(tbl);
> > }
> >
> > match.imports = function(pkg, x=NULL, quote=FALSE) {
> >      if(is.null(x)) x = info.pkg();
> >      if(quote) {
> >          pkg = paste0("\\Q", pkg, "\\E");
> >      }
> >      # TODO: Use word delimiters?
> >      # "(<?=^|[ \n\r\t],)"
> >      if(length(pkg) == 1) {
> >          isImport = grepl(pkg, x$Imports);
> >          return(x[isImport, ]);
> >      } else {
> >          # TODO: concept?
> >          rez = lapply(pkg, function(p) x[grepl(p, x$Imports), ]);
> >          return(rez);
> >      }
> > }
> >
> > Examples:
> >
> > p = info.pkg();
> > f = imports.pkg();
> >
> > ### Analyze data
> >
> > # imported only once: (only in the locally installed packages)
> > f$Name[f$Freq == 1]
> >
> > match.imports("hunspell", p)
> > match.imports("labeling", p)
> > match.imports("rpart.plot", p)
> >
> > match.imports(c("pROC", "ROCR"), p)
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sat Sep 25 02:31:06 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sat, 25 Sep 2021 03:31:06 +0300
Subject: [R] Installed packages: Bioconductor vs CRAN?
In-Reply-To: <CAGxFJbTa2eSWRKcGpxe+RBjEbH9A3p4GEoXUZYLitXH-h_g2FQ@mail.gmail.com>
References: <ffb01865-549e-d061-14ec-03d60b749a78@syonic.eu>
 <CAGxFJbTa2eSWRKcGpxe+RBjEbH9A3p4GEoXUZYLitXH-h_g2FQ@mail.gmail.com>
Message-ID: <dd060dd1-4b98-9a90-a7c6-3a10e83bf785@syonic.eu>

Dear Bert,


The DESCRIPTION file contains additional useful information, e.g.:

1.) Package EBImage:
biocViews: Visualization
Packaged: 2021-05-19 23:53:29 UTC; biocbuild


2.) deSolve
Repository: CRAN


I have verified a few of the CRAN packages, and they seem to include the 
tag:

Repository: CRAN


The Bioconductor packages are different (see e.g. EBImage).

I am wondering if there is already a method to extract this info?


Sincerely,


Leonard


On 9/25/2021 3:06 AM, Bert Gunter wrote:

> The help file tells you that installed.packages() looks at the
> DESCRIPTION files of packages.
> Section 1.1.1 of "Writing R Extensions" tells you what information is
> in such files.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Fri, Sep 24, 2021 at 4:56 PM Leonard Mada via R-help
> <r-help at r-project.org> wrote:
>> Dear List Members,
>>
>>
>> Is there a way to extract if an installed package is from Bioconductor
>> or if it is a regular Cran package?
>>
>>
>> The information seems to be *not* available in:
>>
>> installed.packages()
>>
>>
>> Sincerely,
>>
>>
>> Leonard
>>
>> =======
>>
>> I started to write some utility functions to analyse installed packages.
>> The latest version is on Github:
>> https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
>>
>>
>> # Basic Info:
>> info.pkg = function(pkg=NULL) {
>>       if(is.null(pkg)) { pkg = installed.packages(); }
>>       else {
>>           all.pkg = installed.packages();
>>           pkg = all.pkg[all.pkg[,1] %in% pkg, ];
>>       }
>>       p = pkg;
>>       p = as.data.frame(p);
>>       p = p[ , c("Package", "Version", "Built", "Imports")];
>>       return(p);
>> }
>> # Imported packages:
>> imports.pkg = function(pkg=NULL, sort=TRUE) {
>>       p = info.pkg(pkg);
>>       ### Imported packages
>>       imp = lapply(p$Imports, function(s) strsplit(s, "[,][ ]*"))
>>       imp = unlist(imp)
>>       imp = imp[ ! is.na(imp)]
>>       # Cleanup:
>>       imp = sub("[ \n\r\t]*+\\([-,. >=0-9\n\t\r]++\\) *+$", "", imp,
>> perl=TRUE)
>>       imp = sub("^[ \n\r\t]++", "", imp, perl=TRUE);
>>       # Tabulate:
>>       tbl = as.data.frame(table(imp), stringsAsFactors=FALSE);
>>       names(tbl)[1] = "Name";
>>       if(sort) {
>>           id = order(tbl$Freq, decreasing=TRUE);
>>           tbl = tbl[id,];
>>       }
>>       return(tbl);
>> }
>>
>> match.imports = function(pkg, x=NULL, quote=FALSE) {
>>       if(is.null(x)) x = info.pkg();
>>       if(quote) {
>>           pkg = paste0("\\Q", pkg, "\\E");
>>       }
>>       # TODO: Use word delimiters?
>>       # "(<?=^|[ \n\r\t],)"
>>       if(length(pkg) == 1) {
>>           isImport = grepl(pkg, x$Imports);
>>           return(x[isImport, ]);
>>       } else {
>>           # TODO: concept?
>>           rez = lapply(pkg, function(p) x[grepl(p, x$Imports), ]);
>>           return(rez);
>>       }
>> }
>>
>> Examples:
>>
>> p = info.pkg();
>> f = imports.pkg();
>>
>> ### Analyze data
>>
>> # imported only once: (only in the locally installed packages)
>> f$Name[f$Freq == 1]
>>
>> match.imports("hunspell", p)
>> match.imports("labeling", p)
>> match.imports("rpart.plot", p)
>>
>> match.imports(c("pROC", "ROCR"), p)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sat Sep 25 02:37:05 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sat, 25 Sep 2021 03:37:05 +0300
Subject: [R] Installed packages: Bioconductor vs CRAN?
In-Reply-To: <dd060dd1-4b98-9a90-a7c6-3a10e83bf785@syonic.eu>
References: <ffb01865-549e-d061-14ec-03d60b749a78@syonic.eu>
 <CAGxFJbTa2eSWRKcGpxe+RBjEbH9A3p4GEoXUZYLitXH-h_g2FQ@mail.gmail.com>
 <dd060dd1-4b98-9a90-a7c6-3a10e83bf785@syonic.eu>
Message-ID: <786aa490-ffd4-20f4-a85a-1d5cba665b13@syonic.eu>

Dear Bert,


Indeed, this seems to work:

installed.packages(fields="Repository")


I still need to figure out what variants to expect.


Sincerely,


Leonard


On 9/25/2021 3:31 AM, Leonard Mada wrote:
> Dear Bert,
>
>
> The DESCRIPTION file contains additional useful information, e.g.:
>
> 1.) Package EBImage:
> biocViews: Visualization
> Packaged: 2021-05-19 23:53:29 UTC; biocbuild
>
>
> 2.) deSolve
> Repository: CRAN
>
>
> I have verified a few of the CRAN packages, and they seem to include 
> the tag:
>
> Repository: CRAN
>
>
> The Bioconductor packages are different (see e.g. EBImage).
>
> I am wondering if there is already a method to extract this info?
>
>
> Sincerely,
>
>
> Leonard
>
>
> On 9/25/2021 3:06 AM, Bert Gunter wrote:
>
>> The help file tells you that installed.packages() looks at the
>> DESCRIPTION files of packages.
>> Section 1.1.1 of "Writing R Extensions" tells you what information is
>> in such files.
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Fri, Sep 24, 2021 at 4:56 PM Leonard Mada via R-help
>> <r-help at r-project.org> wrote:
>>> Dear List Members,
>>>
>>>
>>> Is there a way to extract if an installed package is from Bioconductor
>>> or if it is a regular Cran package?
>>>
>>>
>>> The information seems to be *not* available in:
>>>
>>> installed.packages()
>>>
>>>
>>> Sincerely,
>>>
>>>
>>> Leonard
>>>
>>> =======
>>>
>>> I started to write some utility functions to analyse installed 
>>> packages.
>>> The latest version is on Github:
>>> https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
>>>
>>>
>>> # Basic Info:
>>> info.pkg = function(pkg=NULL) {
>>> ????? if(is.null(pkg)) { pkg = installed.packages(); }
>>> ????? else {
>>> ????????? all.pkg = installed.packages();
>>> ????????? pkg = all.pkg[all.pkg[,1] %in% pkg, ];
>>> ????? }
>>> ????? p = pkg;
>>> ????? p = as.data.frame(p);
>>> ????? p = p[ , c("Package", "Version", "Built", "Imports")];
>>> ????? return(p);
>>> }
>>> # Imported packages:
>>> imports.pkg = function(pkg=NULL, sort=TRUE) {
>>> ????? p = info.pkg(pkg);
>>> ????? ### Imported packages
>>> ????? imp = lapply(p$Imports, function(s) strsplit(s, "[,][ ]*"))
>>> ????? imp = unlist(imp)
>>> ????? imp = imp[ ! is.na(imp)]
>>> ????? # Cleanup:
>>> ????? imp = sub("[ \n\r\t]*+\\([-,. >=0-9\n\t\r]++\\) *+$", "", imp,
>>> perl=TRUE)
>>> ????? imp = sub("^[ \n\r\t]++", "", imp, perl=TRUE);
>>> ????? # Tabulate:
>>> ????? tbl = as.data.frame(table(imp), stringsAsFactors=FALSE);
>>> ????? names(tbl)[1] = "Name";
>>> ????? if(sort) {
>>> ????????? id = order(tbl$Freq, decreasing=TRUE);
>>> ????????? tbl = tbl[id,];
>>> ????? }
>>> ????? return(tbl);
>>> }
>>>
>>> match.imports = function(pkg, x=NULL, quote=FALSE) {
>>> ????? if(is.null(x)) x = info.pkg();
>>> ????? if(quote) {
>>> ????????? pkg = paste0("\\Q", pkg, "\\E");
>>> ????? }
>>> ????? # TODO: Use word delimiters?
>>> ????? # "(<?=^|[ \n\r\t],)"
>>> ????? if(length(pkg) == 1) {
>>> ????????? isImport = grepl(pkg, x$Imports);
>>> ????????? return(x[isImport, ]);
>>> ????? } else {
>>> ????????? # TODO: concept?
>>> ????????? rez = lapply(pkg, function(p) x[grepl(p, x$Imports), ]);
>>> ????????? return(rez);
>>> ????? }
>>> }
>>>
>>> Examples:
>>>
>>> p = info.pkg();
>>> f = imports.pkg();
>>>
>>> ### Analyze data
>>>
>>> # imported only once: (only in the locally installed packages)
>>> f$Name[f$Freq == 1]
>>>
>>> match.imports("hunspell", p)
>>> match.imports("labeling", p)
>>> match.imports("rpart.plot", p)
>>>
>>> match.imports(c("pROC", "ROCR"), p)
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sat Sep 25 02:50:19 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sat, 25 Sep 2021 03:50:19 +0300
Subject: [R] Installed packages: Bioconductor vs CRAN?
In-Reply-To: <ffb01865-549e-d061-14ec-03d60b749a78@syonic.eu>
References: <ffb01865-549e-d061-14ec-03d60b749a78@syonic.eu>
Message-ID: <b25276ec-fa34-fe0b-dac0-e4d991b4587a@syonic.eu>

[working version]

On 9/25/2021 2:55 AM, Leonard Mada wrote:
> Dear List Members,
>
>
> Is there a way to extract if an installed package is from Bioconductor 
> or if it is a regular Cran package?
>
>
> The information seems to be *not* available in:
>
> installed.packages()

### [updated]

# Basic Info:
info.pkg = function(pkg=NULL, fields="Repository") {
 ??? if(is.null(pkg)) { pkg = installed.packages(fields=fields); }
 ??? else {
 ??? ??? all.pkg = installed.packages();
 ??? ??? pkg = all.pkg[all.pkg[,1] %in% pkg, ];
 ??? }
 ??? p = pkg;
 ??? p = as.data.frame(p);
 ??? p = p[ , c("Package", "Version", "Built", fields, "Imports")];
 ??? return(p);
}


I will think later how to improve the filtering of Bioconductor 
packages. Probably based on biocViews.


Many thanks,


Leonard


>
>
> Sincerely,
>
>
> Leonard
>
> =======
>
> I started to write some utility functions to analyse installed 
> packages. The latest version is on Github:
> https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
>
>
> # Basic Info:
> info.pkg = function(pkg=NULL) {
> ??? if(is.null(pkg)) { pkg = installed.packages(); }
> ??? else {
> ??? ??? all.pkg = installed.packages();
> ??? ??? pkg = all.pkg[all.pkg[,1] %in% pkg, ];
> ??? }
> ??? p = pkg;
> ??? p = as.data.frame(p);
> ??? p = p[ , c("Package", "Version", "Built", "Imports")];
> ??? return(p);
> }
> # Imported packages:
> imports.pkg = function(pkg=NULL, sort=TRUE) {
> ??? p = info.pkg(pkg);
> ??? ### Imported packages
> ??? imp = lapply(p$Imports, function(s) strsplit(s, "[,][ ]*"))
> ??? imp = unlist(imp)
> ??? imp = imp[ ! is.na(imp)]
> ??? # Cleanup:
> ??? imp = sub("[ \n\r\t]*+\\([-,. >=0-9\n\t\r]++\\) *+$", "", imp, 
> perl=TRUE)
> ??? imp = sub("^[ \n\r\t]++", "", imp, perl=TRUE);
> ??? # Tabulate:
> ??? tbl = as.data.frame(table(imp), stringsAsFactors=FALSE);
> ??? names(tbl)[1] = "Name";
> ??? if(sort) {
> ??? ??? id = order(tbl$Freq, decreasing=TRUE);
> ??? ??? tbl = tbl[id,];
> ??? }
> ??? return(tbl);
> }
>
> match.imports = function(pkg, x=NULL, quote=FALSE) {
> ??? if(is.null(x)) x = info.pkg();
> ??? if(quote) {
> ??? ??? pkg = paste0("\\Q", pkg, "\\E");
> ??? }
> ??? # TODO: Use word delimiters?
> ??? # "(<?=^|[ \n\r\t],)"
> ??? if(length(pkg) == 1) {
> ??? ??? isImport = grepl(pkg, x$Imports);
> ??? ??? return(x[isImport, ]);
> ??? } else {
> ??? ??? # TODO: concept?
> ??? ??? rez = lapply(pkg, function(p) x[grepl(p, x$Imports), ]);
> ??? ??? return(rez);
> ??? }
> }
>
> Examples:
>
> p = info.pkg();
> f = imports.pkg();
>
> ### Analyze data
>
> # imported only once: (only in the locally installed packages)
> f$Name[f$Freq == 1]
>
> match.imports("hunspell", p)
> match.imports("labeling", p)
> match.imports("rpart.plot", p)
>
> match.imports(c("pROC", "ROCR"), p)
>


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sat Sep 25 17:11:59 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sat, 25 Sep 2021 18:11:59 +0300
Subject: [R] Reading File Sizes: very slow!
Message-ID: <a710e02f-a86d-82d5-8e40-bb9642992dad@syonic.eu>

Dear List Members,


I tried to compute the file sizes of each installed package and the 
process is terribly slow.

It took ~ 10 minutes for 512 packages / 1.6 GB total size of files.


1.) Package Sizes


system.time({
 ??? ??? x = size.pkg(file=NULL);
})
# elapsed time: 509 s !!!
# 512 Packages; 1.64 GB;
# R 4.1.1 on MS Windows 10


The code for the size.pkg() function is below and the latest version is 
on Github:

https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R


Questions:
Is there a way to get the file size faster?
It takes long on Windows as well, but of the order of 10-20 s, not 10 
minutes.
Do I miss something?


1.b.) Alternative

It came to my mind to read first all file sizes and then use tapply or 
aggregate - but I do not see why it should be faster.

Would it be meaningful to benchmark each individual package?

Although I am not very inclined to wait 10 minutes for each new try out.


2.) Big Packages

Just as a note: there are a few very large packages (in my list of 512 
packages):

1? 123,566,287?????????????? BH
2? 113,578,391?????????????? sf
3? 112,252,652??????????? rgdal
4?? 81,144,868?????????? magick
5?? 77,791,374 openNLPmodels.en

I suspect that sf & rgdal have a lot of duplicated data structures 
and/or duplicate code and/or duplicated libraries - although I am not an 
expert in the field and did not check the sources.


Sincerely,


Leonard

=======


# Package Size:
size.f.pkg = function(path=NULL) {
 ??? if(is.null(path)) path = R.home("library");
 ??? xd = list.dirs(path = path, full.names = FALSE, recursive = FALSE);
 ??? size.f = function(p) {
 ??? ??? p = paste0(path, "/", p);
 ??? ??? sum(file.info(list.files(path=p, pattern=".",
 ??? ??? ??? full.names = TRUE, all.files = TRUE, recursive = TRUE))$size);
 ??? }
 ??? sapply(xd, size.f);
}

size.pkg = function(path=NULL, sort=TRUE, file="Packages.Size.csv") {
 ??? x = size.f.pkg(path=path);
 ??? x = as.data.frame(x);
 ??? names(x) = "Size"
 ??? x$Name = rownames(x);
 ??? # Order
 ??? if(sort) {
 ??? ??? id = order(x$Size, decreasing=TRUE)
 ??? ??? x = x[id,];
 ??? }
 ??? if( ! is.null(file)) {
 ??? ??? if( ! is.character(file)) {
 ??? ??? ??? print("Error: Size NOT written to file!");
 ??? ??? } else write.csv(x, file=file, row.names=FALSE);
 ??? }
 ??? return(x);
}


From w||||@mwdun|@p @end|ng |rom gm@||@com  Sat Sep 25 19:13:33 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Sat, 25 Sep 2021 10:13:33 -0700
Subject: [R] Reading File Sizes: very slow!
In-Reply-To: <a710e02f-a86d-82d5-8e40-bb9642992dad@syonic.eu>
References: <a710e02f-a86d-82d5-8e40-bb9642992dad@syonic.eu>
Message-ID: <CAHqSRuRRYM+T_yGSR6LAxwWwD-Rb5XHr8arGLU=sAWZiQ3dk2A@mail.gmail.com>

On my Windows 10 laptop I see evidence of the operating system caching
information about recently accessed files.  This makes it hard to say how
the speed might be improved.  Is there a way to clear this cache?

> system.time(L1 <- size.f.pkg(R.home("library")))
   user  system elapsed
   0.48    2.81   30.42
> system.time(L2 <- size.f.pkg(R.home("library")))
   user  system elapsed
   0.35    1.10    1.43
> identical(L1,L2)
[1] TRUE
> length(L1)
[1] 30
> length(dir(R.home("library"),recursive=TRUE))
[1] 12949

On Sat, Sep 25, 2021 at 8:12 AM Leonard Mada via R-help <
r-help at r-project.org> wrote:

> Dear List Members,
>
>
> I tried to compute the file sizes of each installed package and the
> process is terribly slow.
>
> It took ~ 10 minutes for 512 packages / 1.6 GB total size of files.
>
>
> 1.) Package Sizes
>
>
> system.time({
>          x = size.pkg(file=NULL);
> })
> # elapsed time: 509 s !!!
> # 512 Packages; 1.64 GB;
> # R 4.1.1 on MS Windows 10
>
>
> The code for the size.pkg() function is below and the latest version is
> on Github:
>
> https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
>
>
> Questions:
> Is there a way to get the file size faster?
> It takes long on Windows as well, but of the order of 10-20 s, not 10
> minutes.
> Do I miss something?
>
>
> 1.b.) Alternative
>
> It came to my mind to read first all file sizes and then use tapply or
> aggregate - but I do not see why it should be faster.
>
> Would it be meaningful to benchmark each individual package?
>
> Although I am not very inclined to wait 10 minutes for each new try out.
>
>
> 2.) Big Packages
>
> Just as a note: there are a few very large packages (in my list of 512
> packages):
>
> 1  123,566,287               BH
> 2  113,578,391               sf
> 3  112,252,652            rgdal
> 4   81,144,868           magick
> 5   77,791,374 openNLPmodels.en
>
> I suspect that sf & rgdal have a lot of duplicated data structures
> and/or duplicate code and/or duplicated libraries - although I am not an
> expert in the field and did not check the sources.
>
>
> Sincerely,
>
>
> Leonard
>
> =======
>
>
> # Package Size:
> size.f.pkg = function(path=NULL) {
>      if(is.null(path)) path = R.home("library");
>      xd = list.dirs(path = path, full.names = FALSE, recursive = FALSE);
>      size.f = function(p) {
>          p = paste0(path, "/", p);
>          sum(file.info(list.files(path=p, pattern=".",
>              full.names = TRUE, all.files = TRUE, recursive = TRUE))$size);
>      }
>      sapply(xd, size.f);
> }
>
> size.pkg = function(path=NULL, sort=TRUE, file="Packages.Size.csv") {
>      x = size.f.pkg(path=path);
>      x = as.data.frame(x);
>      names(x) = "Size"
>      x$Name = rownames(x);
>      # Order
>      if(sort) {
>          id = order(x$Size, decreasing=TRUE)
>          x = x[id,];
>      }
>      if( ! is.null(file)) {
>          if( ! is.character(file)) {
>              print("Error: Size NOT written to file!");
>          } else write.csv(x, file=file, row.names=FALSE);
>      }
>      return(x);
> }
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Sun Sep 26 04:49:09 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sun, 26 Sep 2021 15:49:09 +1300
Subject: [R] Reading File Sizes: very slow!
In-Reply-To: <CAHqSRuRRYM+T_yGSR6LAxwWwD-Rb5XHr8arGLU=sAWZiQ3dk2A@mail.gmail.com>
References: <a710e02f-a86d-82d5-8e40-bb9642992dad@syonic.eu>
 <CAHqSRuRRYM+T_yGSR6LAxwWwD-Rb5XHr8arGLU=sAWZiQ3dk2A@mail.gmail.com>
Message-ID: <CABcYAdK3zuftuswm5GZd7w66i-wRHoiMDcAdBmefiSyC8gdZRw@mail.gmail.com>

On a $150 second-hand laptop with 0.9GB of library,
and a single-user installation of R so only one place to look
LIBRARY=$HOME/R/x86_64-pc-linux-gnu-library/4.0
cd $LIBRARY
echo "kbytes package"
du -sk * | sort -k1n

took 150 msec to report the disc space needed for every package.

That'

On Sun, 26 Sept 2021 at 06:14, Bill Dunlap <williamwdunlap at gmail.com> wrote:
>
> On my Windows 10 laptop I see evidence of the operating system caching
> information about recently accessed files.  This makes it hard to say how
> the speed might be improved.  Is there a way to clear this cache?
>
> > system.time(L1 <- size.f.pkg(R.home("library")))
>    user  system elapsed
>    0.48    2.81   30.42
> > system.time(L2 <- size.f.pkg(R.home("library")))
>    user  system elapsed
>    0.35    1.10    1.43
> > identical(L1,L2)
> [1] TRUE
> > length(L1)
> [1] 30
> > length(dir(R.home("library"),recursive=TRUE))
> [1] 12949
>
> On Sat, Sep 25, 2021 at 8:12 AM Leonard Mada via R-help <
> r-help at r-project.org> wrote:
>
> > Dear List Members,
> >
> >
> > I tried to compute the file sizes of each installed package and the
> > process is terribly slow.
> >
> > It took ~ 10 minutes for 512 packages / 1.6 GB total size of files.
> >
> >
> > 1.) Package Sizes
> >
> >
> > system.time({
> >          x = size.pkg(file=NULL);
> > })
> > # elapsed time: 509 s !!!
> > # 512 Packages; 1.64 GB;
> > # R 4.1.1 on MS Windows 10
> >
> >
> > The code for the size.pkg() function is below and the latest version is
> > on Github:
> >
> > https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
> >
> >
> > Questions:
> > Is there a way to get the file size faster?
> > It takes long on Windows as well, but of the order of 10-20 s, not 10
> > minutes.
> > Do I miss something?
> >
> >
> > 1.b.) Alternative
> >
> > It came to my mind to read first all file sizes and then use tapply or
> > aggregate - but I do not see why it should be faster.
> >
> > Would it be meaningful to benchmark each individual package?
> >
> > Although I am not very inclined to wait 10 minutes for each new try out.
> >
> >
> > 2.) Big Packages
> >
> > Just as a note: there are a few very large packages (in my list of 512
> > packages):
> >
> > 1  123,566,287               BH
> > 2  113,578,391               sf
> > 3  112,252,652            rgdal
> > 4   81,144,868           magick
> > 5   77,791,374 openNLPmodels.en
> >
> > I suspect that sf & rgdal have a lot of duplicated data structures
> > and/or duplicate code and/or duplicated libraries - although I am not an
> > expert in the field and did not check the sources.
> >
> >
> > Sincerely,
> >
> >
> > Leonard
> >
> > =======
> >
> >
> > # Package Size:
> > size.f.pkg = function(path=NULL) {
> >      if(is.null(path)) path = R.home("library");
> >      xd = list.dirs(path = path, full.names = FALSE, recursive = FALSE);
> >      size.f = function(p) {
> >          p = paste0(path, "/", p);
> >          sum(file.info(list.files(path=p, pattern=".",
> >              full.names = TRUE, all.files = TRUE, recursive = TRUE))$size);
> >      }
> >      sapply(xd, size.f);
> > }
> >
> > size.pkg = function(path=NULL, sort=TRUE, file="Packages.Size.csv") {
> >      x = size.f.pkg(path=path);
> >      x = as.data.frame(x);
> >      names(x) = "Size"
> >      x$Name = rownames(x);
> >      # Order
> >      if(sort) {
> >          id = order(x$Size, decreasing=TRUE)
> >          x = x[id,];
> >      }
> >      if( ! is.null(file)) {
> >          if( ! is.character(file)) {
> >              print("Error: Size NOT written to file!");
> >          } else write.csv(x, file=file, row.names=FALSE);
> >      }
> >      return(x);
> > }
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sun Sep 26 15:03:06 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sun, 26 Sep 2021 16:03:06 +0300
Subject: [R] Reading File Sizes: very slow!
In-Reply-To: <CABcYAdK3zuftuswm5GZd7w66i-wRHoiMDcAdBmefiSyC8gdZRw@mail.gmail.com>
References: <a710e02f-a86d-82d5-8e40-bb9642992dad@syonic.eu>
 <CAHqSRuRRYM+T_yGSR6LAxwWwD-Rb5XHr8arGLU=sAWZiQ3dk2A@mail.gmail.com>
 <CABcYAdK3zuftuswm5GZd7w66i-wRHoiMDcAdBmefiSyC8gdZRw@mail.gmail.com>
Message-ID: <e0af476c-433a-4e8e-8767-1bc65f72ee87@syonic.eu>

Dear Bill,


- using the Ms Windows Properties: ~ 15 s;

[Windows new start, 1st operation, bulk size]

- using R / file.info() (2nd operation): still 523.6 s

[and R seems mostly unresponsive during this time]


Unfortunately, I do not know how to clear any cache.

[The cache may play a role only for smaller sizes? But I am rather not 
inclined to run the ~ 10 minutes procedure multiple times.]


Sincerely,


Leonard


On 9/26/2021 5:49 AM, Richard O'Keefe wrote:
> On a $150 second-hand laptop with 0.9GB of library,
> and a single-user installation of R so only one place to look
> LIBRARY=$HOME/R/x86_64-pc-linux-gnu-library/4.0
> cd $LIBRARY
> echo "kbytes package"
> du -sk * | sort -k1n
>
> took 150 msec to report the disc space needed for every package.
>
> That'
>
> On Sun, 26 Sept 2021 at 06:14, Bill Dunlap <williamwdunlap at gmail.com> wrote:
>> On my Windows 10 laptop I see evidence of the operating system caching
>> information about recently accessed files.  This makes it hard to say how
>> the speed might be improved.  Is there a way to clear this cache?
>>
>>> system.time(L1 <- size.f.pkg(R.home("library")))
>>     user  system elapsed
>>     0.48    2.81   30.42
>>> system.time(L2 <- size.f.pkg(R.home("library")))
>>     user  system elapsed
>>     0.35    1.10    1.43
>>> identical(L1,L2)
>> [1] TRUE
>>> length(L1)
>> [1] 30
>>> length(dir(R.home("library"),recursive=TRUE))
>> [1] 12949
>>
>> On Sat, Sep 25, 2021 at 8:12 AM Leonard Mada via R-help <
>> r-help at r-project.org> wrote:
>>
>>> Dear List Members,
>>>
>>>
>>> I tried to compute the file sizes of each installed package and the
>>> process is terribly slow.
>>>
>>> It took ~ 10 minutes for 512 packages / 1.6 GB total size of files.
>>>
>>>
>>> 1.) Package Sizes
>>>
>>>
>>> system.time({
>>>           x = size.pkg(file=NULL);
>>> })
>>> # elapsed time: 509 s !!!
>>> # 512 Packages; 1.64 GB;
>>> # R 4.1.1 on MS Windows 10
>>>
>>>
>>> The code for the size.pkg() function is below and the latest version is
>>> on Github:
>>>
>>> https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
>>>
>>>
>>> Questions:
>>> Is there a way to get the file size faster?
>>> It takes long on Windows as well, but of the order of 10-20 s, not 10
>>> minutes.
>>> Do I miss something?
>>>
>>>
>>> 1.b.) Alternative
>>>
>>> It came to my mind to read first all file sizes and then use tapply or
>>> aggregate - but I do not see why it should be faster.
>>>
>>> Would it be meaningful to benchmark each individual package?
>>>
>>> Although I am not very inclined to wait 10 minutes for each new try out.
>>>
>>>
>>> 2.) Big Packages
>>>
>>> Just as a note: there are a few very large packages (in my list of 512
>>> packages):
>>>
>>> 1  123,566,287               BH
>>> 2  113,578,391               sf
>>> 3  112,252,652            rgdal
>>> 4   81,144,868           magick
>>> 5   77,791,374 openNLPmodels.en
>>>
>>> I suspect that sf & rgdal have a lot of duplicated data structures
>>> and/or duplicate code and/or duplicated libraries - although I am not an
>>> expert in the field and did not check the sources.
>>>
>>>
>>> Sincerely,
>>>
>>>
>>> Leonard
>>>
>>> =======
>>>
>>>
>>> # Package Size:
>>> size.f.pkg = function(path=NULL) {
>>>       if(is.null(path)) path = R.home("library");
>>>       xd = list.dirs(path = path, full.names = FALSE, recursive = FALSE);
>>>       size.f = function(p) {
>>>           p = paste0(path, "/", p);
>>>           sum(file.info(list.files(path=p, pattern=".",
>>>               full.names = TRUE, all.files = TRUE, recursive = TRUE))$size);
>>>       }
>>>       sapply(xd, size.f);
>>> }
>>>
>>> size.pkg = function(path=NULL, sort=TRUE, file="Packages.Size.csv") {
>>>       x = size.f.pkg(path=path);
>>>       x = as.data.frame(x);
>>>       names(x) = "Size"
>>>       x$Name = rownames(x);
>>>       # Order
>>>       if(sort) {
>>>           id = order(x$Size, decreasing=TRUE)
>>>           x = x[id,];
>>>       }
>>>       if( ! is.null(file)) {
>>>           if( ! is.character(file)) {
>>>               print("Error: Size NOT written to file!");
>>>           } else write.csv(x, file=file, row.names=FALSE);
>>>       }
>>>       return(x);
>>> }
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From rcoppock @end|ng |rom cox@net  Sun Sep 26 15:05:05 2021
From: rcoppock @end|ng |rom cox@net (Roger Coppock)
Date: Sun, 26 Sep 2021 06:05:05 -0700
Subject: [R] USB devices?
Message-ID: <33268691-D53E-4422-A610-F7BDBDF41F0B@cox.net>

How do I communicate directly with USB devices in R?

Specifically, I want to read data from this device.
http://www.zyaura.com/products/ZGm05.asp
I have the USB message formats it uses, and they are quite simple.

- -  Roger Coppock, rcoppock at cox.net


From @zwj|08 @end|ng |rom gm@||@com  Sun Sep 26 15:49:52 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Sun, 26 Sep 2021 21:49:52 +0800
Subject: [R] Reading File Sizes: very slow!
In-Reply-To: <e0af476c-433a-4e8e-8767-1bc65f72ee87@syonic.eu>
References: <a710e02f-a86d-82d5-8e40-bb9642992dad@syonic.eu>
 <CAHqSRuRRYM+T_yGSR6LAxwWwD-Rb5XHr8arGLU=sAWZiQ3dk2A@mail.gmail.com>
 <CABcYAdK3zuftuswm5GZd7w66i-wRHoiMDcAdBmefiSyC8gdZRw@mail.gmail.com>
 <e0af476c-433a-4e8e-8767-1bc65f72ee87@syonic.eu>
Message-ID: <CAGiFhPM4fSZUUgU172Q+49weGogRCE5VxgdW1KwByvcg26ofTw@mail.gmail.com>

What kind of disk do you use? The hardware differences might be important
to this issue.

Best,
Jiefei

Leonard Mada via R-help <r-help at r-project.org> ? 2021?9?26??? ??9:04???

> Dear Bill,
>
>
> - using the Ms Windows Properties: ~ 15 s;
>
> [Windows new start, 1st operation, bulk size]
>
> - using R / file.info() (2nd operation): still 523.6 s
>
> [and R seems mostly unresponsive during this time]
>
>
> Unfortunately, I do not know how to clear any cache.
>
> [The cache may play a role only for smaller sizes? But I am rather not
> inclined to run the ~ 10 minutes procedure multiple times.]
>
>
> Sincerely,
>
>
> Leonard
>
>
> On 9/26/2021 5:49 AM, Richard O'Keefe wrote:
> > On a $150 second-hand laptop with 0.9GB of library,
> > and a single-user installation of R so only one place to look
> > LIBRARY=$HOME/R/x86_64-pc-linux-gnu-library/4.0
> > cd $LIBRARY
> > echo "kbytes package"
> > du -sk * | sort -k1n
> >
> > took 150 msec to report the disc space needed for every package.
> >
> > That'
> >
> > On Sun, 26 Sept 2021 at 06:14, Bill Dunlap <williamwdunlap at gmail.com>
> wrote:
> >> On my Windows 10 laptop I see evidence of the operating system caching
> >> information about recently accessed files.  This makes it hard to say
> how
> >> the speed might be improved.  Is there a way to clear this cache?
> >>
> >>> system.time(L1 <- size.f.pkg(R.home("library")))
> >>     user  system elapsed
> >>     0.48    2.81   30.42
> >>> system.time(L2 <- size.f.pkg(R.home("library")))
> >>     user  system elapsed
> >>     0.35    1.10    1.43
> >>> identical(L1,L2)
> >> [1] TRUE
> >>> length(L1)
> >> [1] 30
> >>> length(dir(R.home("library"),recursive=TRUE))
> >> [1] 12949
> >>
> >> On Sat, Sep 25, 2021 at 8:12 AM Leonard Mada via R-help <
> >> r-help at r-project.org> wrote:
> >>
> >>> Dear List Members,
> >>>
> >>>
> >>> I tried to compute the file sizes of each installed package and the
> >>> process is terribly slow.
> >>>
> >>> It took ~ 10 minutes for 512 packages / 1.6 GB total size of files.
> >>>
> >>>
> >>> 1.) Package Sizes
> >>>
> >>>
> >>> system.time({
> >>>           x = size.pkg(file=NULL);
> >>> })
> >>> # elapsed time: 509 s !!!
> >>> # 512 Packages; 1.64 GB;
> >>> # R 4.1.1 on MS Windows 10
> >>>
> >>>
> >>> The code for the size.pkg() function is below and the latest version is
> >>> on Github:
> >>>
> >>> https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
> >>>
> >>>
> >>> Questions:
> >>> Is there a way to get the file size faster?
> >>> It takes long on Windows as well, but of the order of 10-20 s, not 10
> >>> minutes.
> >>> Do I miss something?
> >>>
> >>>
> >>> 1.b.) Alternative
> >>>
> >>> It came to my mind to read first all file sizes and then use tapply or
> >>> aggregate - but I do not see why it should be faster.
> >>>
> >>> Would it be meaningful to benchmark each individual package?
> >>>
> >>> Although I am not very inclined to wait 10 minutes for each new try
> out.
> >>>
> >>>
> >>> 2.) Big Packages
> >>>
> >>> Just as a note: there are a few very large packages (in my list of 512
> >>> packages):
> >>>
> >>> 1  123,566,287               BH
> >>> 2  113,578,391               sf
> >>> 3  112,252,652            rgdal
> >>> 4   81,144,868           magick
> >>> 5   77,791,374 openNLPmodels.en
> >>>
> >>> I suspect that sf & rgdal have a lot of duplicated data structures
> >>> and/or duplicate code and/or duplicated libraries - although I am not
> an
> >>> expert in the field and did not check the sources.
> >>>
> >>>
> >>> Sincerely,
> >>>
> >>>
> >>> Leonard
> >>>
> >>> =======
> >>>
> >>>
> >>> # Package Size:
> >>> size.f.pkg = function(path=NULL) {
> >>>       if(is.null(path)) path = R.home("library");
> >>>       xd = list.dirs(path = path, full.names = FALSE, recursive =
> FALSE);
> >>>       size.f = function(p) {
> >>>           p = paste0(path, "/", p);
> >>>           sum(file.info(list.files(path=p, pattern=".",
> >>>               full.names = TRUE, all.files = TRUE, recursive =
> TRUE))$size);
> >>>       }
> >>>       sapply(xd, size.f);
> >>> }
> >>>
> >>> size.pkg = function(path=NULL, sort=TRUE, file="Packages.Size.csv") {
> >>>       x = size.f.pkg(path=path);
> >>>       x = as.data.frame(x);
> >>>       names(x) = "Size"
> >>>       x$Name = rownames(x);
> >>>       # Order
> >>>       if(sort) {
> >>>           id = order(x$Size, decreasing=TRUE)
> >>>           x = x[id,];
> >>>       }
> >>>       if( ! is.null(file)) {
> >>>           if( ! is.character(file)) {
> >>>               print("Error: Size NOT written to file!");
> >>>           } else write.csv(x, file=file, row.names=FALSE);
> >>>       }
> >>>       return(x);
> >>> }
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Sun Sep 26 17:00:48 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Sun, 26 Sep 2021 23:00:48 +0800
Subject: [R] USB devices?
In-Reply-To: <33268691-D53E-4422-A610-F7BDBDF41F0B@cox.net>
References: <33268691-D53E-4422-A610-F7BDBDF41F0B@cox.net>
Message-ID: <CAGiFhPPKJAX2MDjBv87C70wLO0N+17vJGLEpVGgRtL6n6MAoyg@mail.gmail.com>

Hi,

If you can talk with your device through the terminal. One option is
using 'system2' in R to send the command to your OS.

Best,
Jiefei

On Sun, Sep 26, 2021 at 9:14 PM Roger Coppock <rcoppock at cox.net> wrote:
>
> How do I communicate directly with USB devices in R?
>
> Specifically, I want to read data from this device.
> http://www.zyaura.com/products/ZGm05.asp
> I have the USB message formats it uses, and they are quite simple.
>
> - -  Roger Coppock, rcoppock at cox.net
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 27 00:06:06 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 27 Sep 2021 01:06:06 +0300
Subject: [R] Reading File Sizes: very slow!
In-Reply-To: <CAHqSRuRRYM+T_yGSR6LAxwWwD-Rb5XHr8arGLU=sAWZiQ3dk2A@mail.gmail.com>
References: <a710e02f-a86d-82d5-8e40-bb9642992dad@syonic.eu>
 <CAHqSRuRRYM+T_yGSR6LAxwWwD-Rb5XHr8arGLU=sAWZiQ3dk2A@mail.gmail.com>
Message-ID: <36b8027f-d057-8395-7cc3-bcac7a1206ff@syonic.eu>

Dear Bill,


Does list.files() always sort the results?

It seems so. The option: full.names = FALSE does not have any effect: 
the results seem always sorted.


Maybe it is better to process the files in an unsorted order: as stored 
on the disk?


Sincerely,


Leonard


On 9/25/2021 8:13 PM, Bill Dunlap wrote:
> On my Windows 10 laptop I see evidence of the operating system caching 
> information about recently accessed files.? This makes it hard to say 
> how the speed might be improved.? Is there a way to clear this cache?
>
> > system.time(L1 <- size.f.pkg(R.home("library")))
> ? ?user ?system elapsed
> ? ?0.48 ? ?2.81 ? 30.42
> > system.time(L2 <- size.f.pkg(R.home("library")))
> ? ?user ?system elapsed
> ? ?0.35 ? ?1.10 ? ?1.43
> > identical(L1,L2)
> [1] TRUE
> > length(L1)
> [1] 30
> > length(dir(R.home("library"),recursive=TRUE))
> [1] 12949
>
> On Sat, Sep 25, 2021 at 8:12 AM Leonard Mada via R-help 
> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>
>     Dear List Members,
>
>
>     I tried to compute the file sizes of each installed package and the
>     process is terribly slow.
>
>     It took ~ 10 minutes for 512 packages / 1.6 GB total size of files.
>
>
>     1.) Package Sizes
>
>
>     system.time({
>     ???? ??? x = size.pkg(file=NULL);
>     })
>     # elapsed time: 509 s !!!
>     # 512 Packages; 1.64 GB;
>     # R 4.1.1 on MS Windows 10
>
>
>     The code for the size.pkg() function is below and the latest
>     version is
>     on Github:
>
>     https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
>     <https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R>
>
>
>     Questions:
>     Is there a way to get the file size faster?
>     It takes long on Windows as well, but of the order of 10-20 s, not 10
>     minutes.
>     Do I miss something?
>
>
>     1.b.) Alternative
>
>     It came to my mind to read first all file sizes and then use
>     tapply or
>     aggregate - but I do not see why it should be faster.
>
>     Would it be meaningful to benchmark each individual package?
>
>     Although I am not very inclined to wait 10 minutes for each new
>     try out.
>
>
>     2.) Big Packages
>
>     Just as a note: there are a few very large packages (in my list of
>     512
>     packages):
>
>     1? 123,566,287?????????????? BH
>     2? 113,578,391?????????????? sf
>     3? 112,252,652??????????? rgdal
>     4?? 81,144,868?????????? magick
>     5?? 77,791,374 openNLPmodels.en
>
>     I suspect that sf & rgdal have a lot of duplicated data structures
>     and/or duplicate code and/or duplicated libraries - although I am
>     not an
>     expert in the field and did not check the sources.
>
>
>     Sincerely,
>
>
>     Leonard
>
>     =======
>
>
>     # Package Size:
>     size.f.pkg = function(path=NULL) {
>     ???? if(is.null(path)) path = R.home("library");
>     ???? xd = list.dirs(path = path, full.names = FALSE, recursive =
>     FALSE);
>     ???? size.f = function(p) {
>     ???? ??? p = paste0(path, "/", p);
>     ???? ??? sum(file.info <http://file.info>(list.files(path=p,
>     pattern=".",
>     ???? ??? ??? full.names = TRUE, all.files = TRUE, recursive =
>     TRUE))$size);
>     ???? }
>     ???? sapply(xd, size.f);
>     }
>
>     size.pkg = function(path=NULL, sort=TRUE, file="Packages.Size.csv") {
>     ???? x = size.f.pkg(path=path);
>     ???? x = as.data.frame(x);
>     ???? names(x) = "Size"
>     ???? x$Name = rownames(x);
>     ???? # Order
>     ???? if(sort) {
>     ???? ??? id = order(x$Size, decreasing=TRUE)
>     ???? ??? x = x[id,];
>     ???? }
>     ???? if( ! is.null(file)) {
>     ???? ??? if( ! is.character(file)) {
>     ???? ??? ??? print("Error: Size NOT written to file!");
>     ???? ??? } else write.csv(x, file=file, row.names=FALSE);
>     ???? }
>     ???? return(x);
>     }
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 27 00:31:12 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 27 Sep 2021 01:31:12 +0300
Subject: [R] Reading File Sizes: very slow!
In-Reply-To: <36b8027f-d057-8395-7cc3-bcac7a1206ff@syonic.eu>
References: <a710e02f-a86d-82d5-8e40-bb9642992dad@syonic.eu>
 <CAHqSRuRRYM+T_yGSR6LAxwWwD-Rb5XHr8arGLU=sAWZiQ3dk2A@mail.gmail.com>
 <36b8027f-d057-8395-7cc3-bcac7a1206ff@syonic.eu>
Message-ID: <28a7ab51-98d4-f745-c290-ac41031ab325@syonic.eu>


On 9/27/2021 1:06 AM, Leonard Mada wrote:
>
> Dear Bill,
>
>
> Does list.files() always sort the results?
>
> It seems so. The option: full.names = FALSE does not have any effect: 
> the results seem always sorted.
>
>
> Maybe it is better to process the files in an unsorted order: as 
> stored on the disk?
>

After some more investigations:

This took only a few seconds:

sapply(list.dirs(path=path, full.name=F, recursive=F),
 ??? function(f) length(list.files(path = paste0(path, "/", f), 
full.names = FALSE, recursive = TRUE)))

# maybe with caching, but the difference is enormous


Seems BH contains *by far* the most files: 11701 files.

But excluding it from processing did have only a liniar effect: still 377 s.


I had a look at src/main/platform.c, but do not fully understand it.


Sincerely,


Leonard


>
> Sincerely,
>
>
> Leonard
>
>
> On 9/25/2021 8:13 PM, Bill Dunlap wrote:
>> On my Windows 10 laptop I see evidence of the operating system 
>> caching information about recently accessed files.? This makes it 
>> hard to say how the speed might be improved.? Is there a way to clear 
>> this cache?
>>
>> > system.time(L1 <- size.f.pkg(R.home("library")))
>> ? ?user ?system elapsed
>> ? ?0.48 ? ?2.81 ? 30.42
>> > system.time(L2 <- size.f.pkg(R.home("library")))
>> ? ?user ?system elapsed
>> ? ?0.35 ? ?1.10 ? ?1.43
>> > identical(L1,L2)
>> [1] TRUE
>> > length(L1)
>> [1] 30
>> > length(dir(R.home("library"),recursive=TRUE))
>> [1] 12949
>>
>> On Sat, Sep 25, 2021 at 8:12 AM Leonard Mada via R-help 
>> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>
>>     Dear List Members,
>>
>>
>>     I tried to compute the file sizes of each installed package and the
>>     process is terribly slow.
>>
>>     It took ~ 10 minutes for 512 packages / 1.6 GB total size of files.
>>
>>
>>     1.) Package Sizes
>>
>>
>>     system.time({
>>     ???? ??? x = size.pkg(file=NULL);
>>     })
>>     # elapsed time: 509 s !!!
>>     # 512 Packages; 1.64 GB;
>>     # R 4.1.1 on MS Windows 10
>>
>>
>>     The code for the size.pkg() function is below and the latest
>>     version is
>>     on Github:
>>
>>     https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
>>     <https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R>
>>
>>
>>     Questions:
>>     Is there a way to get the file size faster?
>>     It takes long on Windows as well, but of the order of 10-20 s,
>>     not 10
>>     minutes.
>>     Do I miss something?
>>
>>
>>     1.b.) Alternative
>>
>>     It came to my mind to read first all file sizes and then use
>>     tapply or
>>     aggregate - but I do not see why it should be faster.
>>
>>     Would it be meaningful to benchmark each individual package?
>>
>>     Although I am not very inclined to wait 10 minutes for each new
>>     try out.
>>
>>
>>     2.) Big Packages
>>
>>     Just as a note: there are a few very large packages (in my list
>>     of 512
>>     packages):
>>
>>     1? 123,566,287?????????????? BH
>>     2? 113,578,391?????????????? sf
>>     3? 112,252,652??????????? rgdal
>>     4?? 81,144,868?????????? magick
>>     5?? 77,791,374 openNLPmodels.en
>>
>>     I suspect that sf & rgdal have a lot of duplicated data structures
>>     and/or duplicate code and/or duplicated libraries - although I am
>>     not an
>>     expert in the field and did not check the sources.
>>
>>
>>     Sincerely,
>>
>>
>>     Leonard
>>
>>     =======
>>
>>
>>     # Package Size:
>>     size.f.pkg = function(path=NULL) {
>>     ???? if(is.null(path)) path = R.home("library");
>>     ???? xd = list.dirs(path = path, full.names = FALSE, recursive =
>>     FALSE);
>>     ???? size.f = function(p) {
>>     ???? ??? p = paste0(path, "/", p);
>>     ???? ??? sum(file.info <http://file.info>(list.files(path=p,
>>     pattern=".",
>>     ???? ??? ??? full.names = TRUE, all.files = TRUE, recursive =
>>     TRUE))$size);
>>     ???? }
>>     ???? sapply(xd, size.f);
>>     }
>>
>>     size.pkg = function(path=NULL, sort=TRUE, file="Packages.Size.csv") {
>>     ???? x = size.f.pkg(path=path);
>>     ???? x = as.data.frame(x);
>>     ???? names(x) = "Size"
>>     ???? x$Name = rownames(x);
>>     ???? # Order
>>     ???? if(sort) {
>>     ???? ??? id = order(x$Size, decreasing=TRUE)
>>     ???? ??? x = x[id,];
>>     ???? }
>>     ???? if( ! is.null(file)) {
>>     ???? ??? if( ! is.character(file)) {
>>     ???? ??? ??? print("Error: Size NOT written to file!");
>>     ???? ??? } else write.csv(x, file=file, row.names=FALSE);
>>     ???? }
>>     ???? return(x);
>>     }
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>     -- To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     <http://www.R-project.org/posting-guide.html>
>>     and provide commented, minimal, self-contained, reproducible code.
>>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Sep 27 09:32:45 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 27 Sep 2021 08:32:45 +0100
Subject: [R] Reading File Sizes: very slow!
In-Reply-To: <28a7ab51-98d4-f745-c290-ac41031ab325@syonic.eu>
References: <a710e02f-a86d-82d5-8e40-bb9642992dad@syonic.eu>
 <CAHqSRuRRYM+T_yGSR6LAxwWwD-Rb5XHr8arGLU=sAWZiQ3dk2A@mail.gmail.com>
 <36b8027f-d057-8395-7cc3-bcac7a1206ff@syonic.eu>
 <28a7ab51-98d4-f745-c290-ac41031ab325@syonic.eu>
Message-ID: <941ecaca-e338-775e-724c-be5324866825@sapo.pt>

Hello,

R 4.1.0 on Ubuntu 20.04, sessionInfo at the end.

I'm arriving a bit late to this thread but here are the timings I'm 
getting on an 10+ years old PC.

1. I am not getting anything even close to 5 or 10 mins running times.
2. Like Bill said, there seems to be a caching effect, the first runs 
are consistently slower. And this is Ubuntu, not Windows, so different 
OS's present the same behavior. It's not unexpected, disk accesses are 
slow operations and have been cached for a while now.
3. I am not at all sure if this is relevant but as for how to clean the 
Windows File Explorer cache, open a File Explorer window and click

View > Options > (Privacy section) Clear

4. Now for my timings. The cache effect is large, from 23s down to 2.5s.
But even with an old PC nowhere near 300s or 500s.

rui at rui:~$ R -q -f rhelp.R
#
# functions size.pkg and size.f.pkg omitted
#
 > R_LIBS_USER <- Sys.getenv("R_LIBS_USER")
 >
 > cat("\nLeonard Mada's code:\n\n")

Leonard Mada's code:

 > system.time({
+         x = size.pkg(path=R_LIBS_USER, file=NULL)
+ })
    user  system elapsed
   1.700   0.988  23.339
 > system.time({
+         x = size.pkg(path=R_LIBS_USER, file=NULL)
+ })
    user  system elapsed
   1.578   0.921   2.540
 > system.time({
+         x = size.pkg(path=R_LIBS_USER, file=NULL)
+ })
    user  system elapsed
   1.542   0.949   2.523
 >
 > cat("\nBill Dunlap's code:\n\n")

Bill Dunlap's code:

 > system.time(L1 <- size.f.pkg(R_LIBS_USER))
    user  system elapsed
   1.608   0.887   2.538
 > system.time(L2 <- size.f.pkg(R_LIBS_USER))
    user  system elapsed
   1.515   0.982   2.510
 > identical(L1,L2)
[1] TRUE
 > length(L1)
[1] 1773
 > length(dir(R_LIBS_USER,recursive=TRUE))
[1] 85204
 >
 > cat("\n\nsessionInfo return value:\n\n")


sessionInfo return value:

 > sessionInfo()
R version 4.1.1 (2021-08-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.3 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0

locale:
  [1] LC_CTYPE=pt_PT.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=pt_PT.UTF-8        LC_COLLATE=pt_PT.UTF-8
  [5] LC_MONETARY=pt_PT.UTF-8    LC_MESSAGES=pt_PT.UTF-8
  [7] LC_PAPER=pt_PT.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=pt_PT.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.1.1


And the sapply code.


rui at rui:~$ R -q -f rhelp2.R
 > R_LIBS_USER <- Sys.getenv("R_LIBS_USER")
 > path <- R_LIBS_USER
 > system.time({
+ sapply(list.dirs(path=path, full.name=F, recursive=F),
+      function(f) length(list.files(path = file.path(path, f),
+ full.names = FALSE, recursive = TRUE)))
+ })
    user  system elapsed
   0.802   0.901  15.964
 >
 >
rui at rui:~$ R -q -f rhelp2.R
 > R_LIBS_USER <- Sys.getenv("R_LIBS_USER")
 > path <- R_LIBS_USER
 > system.time({
+ sapply(list.dirs(path=path, full.name=F, recursive=F),
+      function(f) length(list.files(path = file.path(path, f),
+ full.names = FALSE, recursive = TRUE)))
+ })
    user  system elapsed
   0.730   0.528   1.264


Once again the 2nd run took a fraction of the 1st run.

Leonard, if you are getting those timings, is there another process 
running or that has previously run and eat up the cache?

Hope this helps,

Rui Barradas

?s 23:31 de 26/09/21, Leonard Mada via R-help escreveu:
> 
> On 9/27/2021 1:06 AM, Leonard Mada wrote:
>>
>> Dear Bill,
>>
>>
>> Does list.files() always sort the results?
>>
>> It seems so. The option: full.names = FALSE does not have any effect:
>> the results seem always sorted.
>>
>>
>> Maybe it is better to process the files in an unsorted order: as
>> stored on the disk?
>>
> 
> After some more investigations:
> 
> This took only a few seconds:
> 
> sapply(list.dirs(path=path, full.name=F, recursive=F),
>   ??? function(f) length(list.files(path = paste0(path, "/", f),
> full.names = FALSE, recursive = TRUE)))
> 
> # maybe with caching, but the difference is enormous
> 
> 
> Seems BH contains *by far* the most files: 11701 files.
> 
> But excluding it from processing did have only a liniar effect: still 377 s.
> 
> 
> I had a look at src/main/platform.c, but do not fully understand it.
> 
> 
> Sincerely,
> 
> 
> Leonard
> 
> 
>>
>> Sincerely,
>>
>>
>> Leonard
>>
>>
>> On 9/25/2021 8:13 PM, Bill Dunlap wrote:
>>> On my Windows 10 laptop I see evidence of the operating system
>>> caching information about recently accessed files.? This makes it
>>> hard to say how the speed might be improved.? Is there a way to clear
>>> this cache?
>>>
>>>> system.time(L1 <- size.f.pkg(R.home("library")))
>>>  ? ?user ?system elapsed
>>>  ? ?0.48 ? ?2.81 ? 30.42
>>>> system.time(L2 <- size.f.pkg(R.home("library")))
>>>  ? ?user ?system elapsed
>>>  ? ?0.35 ? ?1.10 ? ?1.43
>>>> identical(L1,L2)
>>> [1] TRUE
>>>> length(L1)
>>> [1] 30
>>>> length(dir(R.home("library"),recursive=TRUE))
>>> [1] 12949
>>>
>>> On Sat, Sep 25, 2021 at 8:12 AM Leonard Mada via R-help
>>> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>>
>>>      Dear List Members,
>>>
>>>
>>>      I tried to compute the file sizes of each installed package and the
>>>      process is terribly slow.
>>>
>>>      It took ~ 10 minutes for 512 packages / 1.6 GB total size of files.
>>>
>>>
>>>      1.) Package Sizes
>>>
>>>
>>>      system.time({
>>>      ???? ??? x = size.pkg(file=NULL);
>>>      })
>>>      # elapsed time: 509 s !!!
>>>      # 512 Packages; 1.64 GB;
>>>      # R 4.1.1 on MS Windows 10
>>>
>>>
>>>      The code for the size.pkg() function is below and the latest
>>>      version is
>>>      on Github:
>>>
>>>      https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
>>>      <https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R>
>>>
>>>
>>>      Questions:
>>>      Is there a way to get the file size faster?
>>>      It takes long on Windows as well, but of the order of 10-20 s,
>>>      not 10
>>>      minutes.
>>>      Do I miss something?
>>>
>>>
>>>      1.b.) Alternative
>>>
>>>      It came to my mind to read first all file sizes and then use
>>>      tapply or
>>>      aggregate - but I do not see why it should be faster.
>>>
>>>      Would it be meaningful to benchmark each individual package?
>>>
>>>      Although I am not very inclined to wait 10 minutes for each new
>>>      try out.
>>>
>>>
>>>      2.) Big Packages
>>>
>>>      Just as a note: there are a few very large packages (in my list
>>>      of 512
>>>      packages):
>>>
>>>      1? 123,566,287?????????????? BH
>>>      2? 113,578,391?????????????? sf
>>>      3? 112,252,652??????????? rgdal
>>>      4?? 81,144,868?????????? magick
>>>      5?? 77,791,374 openNLPmodels.en
>>>
>>>      I suspect that sf & rgdal have a lot of duplicated data structures
>>>      and/or duplicate code and/or duplicated libraries - although I am
>>>      not an
>>>      expert in the field and did not check the sources.
>>>
>>>
>>>      Sincerely,
>>>
>>>
>>>      Leonard
>>>
>>>      =======
>>>
>>>
>>>      # Package Size:
>>>      size.f.pkg = function(path=NULL) {
>>>      ???? if(is.null(path)) path = R.home("library");
>>>      ???? xd = list.dirs(path = path, full.names = FALSE, recursive =
>>>      FALSE);
>>>      ???? size.f = function(p) {
>>>      ???? ??? p = paste0(path, "/", p);
>>>      ???? ??? sum(file.info <http://file.info>(list.files(path=p,
>>>      pattern=".",
>>>      ???? ??? ??? full.names = TRUE, all.files = TRUE, recursive =
>>>      TRUE))$size);
>>>      ???? }
>>>      ???? sapply(xd, size.f);
>>>      }
>>>
>>>      size.pkg = function(path=NULL, sort=TRUE, file="Packages.Size.csv") {
>>>      ???? x = size.f.pkg(path=path);
>>>      ???? x = as.data.frame(x);
>>>      ???? names(x) = "Size"
>>>      ???? x$Name = rownames(x);
>>>      ???? # Order
>>>      ???? if(sort) {
>>>      ???? ??? id = order(x$Size, decreasing=TRUE)
>>>      ???? ??? x = x[id,];
>>>      ???? }
>>>      ???? if( ! is.null(file)) {
>>>      ???? ??? if( ! is.character(file)) {
>>>      ???? ??? ??? print("Error: Size NOT written to file!");
>>>      ???? ??? } else write.csv(x, file=file, row.names=FALSE);
>>>      ???? }
>>>      ???? return(x);
>>>      }
>>>
>>>      ______________________________________________
>>>      R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>      -- To UNSUBSCRIBE and more, see
>>>      https://stat.ethz.ch/mailman/listinfo/r-help
>>>      <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>      PLEASE do read the posting guide
>>>      http://www.R-project.org/posting-guide.html
>>>      <http://www.R-project.org/posting-guide.html>
>>>      and provide commented, minimal, self-contained, reproducible code.
>>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Sep 27 23:12:30 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 28 Sep 2021 10:12:30 +1300
Subject: [R] NA values for "col"
Message-ID: <20210928101230.30aded7f@rolf-Latitude-E7470>


I've just noticed what seems to me to be somewhat peculiar behaviour in
respect of how different plotting functions treat a specification
"col=NA".

Consider:

plot(1:10)
text(4,6,labels="o",col=NA)
points(6,4,col=NA)

The symbol produced by the call to text() shows up (is black).
The symbol produced by the call to points() does not appear.

Of course if one simply does

points(6,4)

then the symbol appears.

This seems to me to be a mild inconsistency.

It is No Big Deal, and in fact doesn't matter at all (who in their
right mind would specify col=NA?).  I only noticed this phenomenon
because of an error I had made in some code.  I'm just curious as to
what is going on.  Is there a reason for the difference in behaviour
between text() and points()?  (And plot(); plot(1:10,col=NA) produces
no points in the plot.)

Note that the help for par() says:

> Some functions such as lines and text accept a vector of values which
> are recycled and may be interpreted slightly differently.

So I guess differences in behaviour are hinted at.

I'm still curious!

Any thoughts from anyone?

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jun@y@n @end|ng |rom uconn@edu  Mon Sep 27 23:18:19 2021
From: jun@y@n @end|ng |rom uconn@edu (Yan, Jun)
Date: Mon, 27 Sep 2021 21:18:19 +0000
Subject: [R] vignette for package splines2 in Journal of Data Science
Message-ID: <DM6PR05MB4282D3437C448C46B79F0F5BF0A79@DM6PR05MB4282.namprd05.prod.outlook.com>

Dear R-help-listers,

Users of splines2 may find the following paper in the Journal of Data Science (https://jds-online.org) interesting:

Wang, W. and Yan, J. (2021): Shape-restricted regression splines with R package splines2. Journal of Data Science. 19(3):498?517.
https://doi.org/10.6339/21-JDS1020

As Editor of the Journal of Data Science, I hope that the paper sets an example of such papers in the Computing for Data Science Section of the Journal. This could be an outlet for your software package companions.

Jun Yan, Professor
Department of Statistics, University of Connecticut
215 Glenbrook Rd. Unit 4120  Storrs, CT 06269
Voice: 860-486-3416  Fax: 860-486-4113
Web: http://www.stat.uconn.edu/~jyan/
http://scholar.google.com/citations?user=4jVhnnEAAAAJ&hl=en
http://www.ams.org/mathscinet/search/publications.html?pg1=IID&s1=743600


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 27 23:43:38 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 27 Sep 2021 14:43:38 -0700
Subject: [R] NA values for "col"
In-Reply-To: <20210928101230.30aded7f@rolf-Latitude-E7470>
References: <20210928101230.30aded7f@rolf-Latitude-E7470>
Message-ID: <CAGxFJbRU=g4TRP22i8cK_26AB0GB5vk-FYx8JsK=rEwpsZFDGA@mail.gmail.com>

?text says

"...  NA values of font are replaced by par("font"), and similarly for col."


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 27, 2021 at 2:12 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> I've just noticed what seems to me to be somewhat peculiar behaviour in
> respect of how different plotting functions treat a specification
> "col=NA".
>
> Consider:
>
> plot(1:10)
> text(4,6,labels="o",col=NA)
> points(6,4,col=NA)
>
> The symbol produced by the call to text() shows up (is black).
> The symbol produced by the call to points() does not appear.
>
> Of course if one simply does
>
> points(6,4)
>
> then the symbol appears.
>
> This seems to me to be a mild inconsistency.
>
> It is No Big Deal, and in fact doesn't matter at all (who in their
> right mind would specify col=NA?).  I only noticed this phenomenon
> because of an error I had made in some code.  I'm just curious as to
> what is going on.  Is there a reason for the difference in behaviour
> between text() and points()?  (And plot(); plot(1:10,col=NA) produces
> no points in the plot.)
>
> Note that the help for par() says:
>
> > Some functions such as lines and text accept a vector of values which
> > are recycled and may be interpreted slightly differently.
>
> So I guess differences in behaviour are hinted at.
>
> I'm still curious!
>
> Any thoughts from anyone?
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 27 23:54:53 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 27 Sep 2021 14:54:53 -0700
Subject: [R] NA values for "col"
In-Reply-To: <CAGxFJbRU=g4TRP22i8cK_26AB0GB5vk-FYx8JsK=rEwpsZFDGA@mail.gmail.com>
References: <20210928101230.30aded7f@rolf-Latitude-E7470>
 <CAGxFJbRU=g4TRP22i8cK_26AB0GB5vk-FYx8JsK=rEwpsZFDGA@mail.gmail.com>
Message-ID: <CAGxFJbRRtS67+mJp_1Hycty3jLePE4sOBLM_TKJ1PDoHhxaC+g@mail.gmail.com>

... and also note in the *Color Specification* section of ?par, to
which ?points points,

"Additionally, "transparent" is transparent, useful for filled areas
(such as the background!), and just invisible for things like lines or
text. In most circumstances (integer) NA is equivalent to
"transparent" (but not for text and mtext)."

So an NA specification for col (or part of col, if a vector) plots the
point in "transparent" rather than omitting it.

Now if your question is *why* the specifications for a color of NA are
different in points() and text(), I don't have a clue. But the
difference is documented.

Bert

On Mon, Sep 27, 2021 at 2:43 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> ?text says
>
> "...  NA values of font are replaced by par("font"), and similarly for col."
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Sep 27, 2021 at 2:12 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
> >
> >
> > I've just noticed what seems to me to be somewhat peculiar behaviour in
> > respect of how different plotting functions treat a specification
> > "col=NA".
> >
> > Consider:
> >
> > plot(1:10)
> > text(4,6,labels="o",col=NA)
> > points(6,4,col=NA)
> >
> > The symbol produced by the call to text() shows up (is black).
> > The symbol produced by the call to points() does not appear.
> >
> > Of course if one simply does
> >
> > points(6,4)
> >
> > then the symbol appears.
> >
> > This seems to me to be a mild inconsistency.
> >
> > It is No Big Deal, and in fact doesn't matter at all (who in their
> > right mind would specify col=NA?).  I only noticed this phenomenon
> > because of an error I had made in some code.  I'm just curious as to
> > what is going on.  Is there a reason for the difference in behaviour
> > between text() and points()?  (And plot(); plot(1:10,col=NA) produces
> > no points in the plot.)
> >
> > Note that the help for par() says:
> >
> > > Some functions such as lines and text accept a vector of values which
> > > are recycled and may be interpreted slightly differently.
> >
> > So I guess differences in behaviour are hinted at.
> >
> > I'm still curious!
> >
> > Any thoughts from anyone?
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Sep 28 00:12:21 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 28 Sep 2021 11:12:21 +1300
Subject: [R] NA values for "col"
In-Reply-To: <CAGxFJbRRtS67+mJp_1Hycty3jLePE4sOBLM_TKJ1PDoHhxaC+g@mail.gmail.com>
References: <20210928101230.30aded7f@rolf-Latitude-E7470>
 <CAGxFJbRU=g4TRP22i8cK_26AB0GB5vk-FYx8JsK=rEwpsZFDGA@mail.gmail.com>
 <CAGxFJbRRtS67+mJp_1Hycty3jLePE4sOBLM_TKJ1PDoHhxaC+g@mail.gmail.com>
Message-ID: <20210928111221.64b7c186@rolf-Latitude-E7470>

On Mon, 27 Sep 2021 14:54:53 -0700
Bert Gunter <bgunter.4567 at gmail.com> wrote:

> ... and also note in the *Color Specification* section of ?par, to
> which ?points points,
> 
> "Additionally, "transparent" is transparent, useful for filled areas
> (such as the background!), and just invisible for things like lines or
> text. In most circumstances (integer) NA is equivalent to
> "transparent" (but not for text and mtext)."
> 
> So an NA specification for col (or part of col, if a vector) plots the
> point in "transparent" rather than omitting it.
> 
> Now if your question is *why* the specifications for a color of NA are
> different in points() and text(), I don't have a clue. But the
> difference is documented.

Thanks Bert.  Clear enuff!

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From q||@@ong @end|ng |rom 126@com  Tue Sep 28 11:37:09 2021
From: q||@@ong @end|ng |rom 126@com (=?GBK?B?y87G9Lei?=)
Date: Tue, 28 Sep 2021 17:37:09 +0800 (CST)
Subject: [R] Issue about eRM package
Message-ID: <26a204d.4209.17c2bc3de6b.Coremail.qifasong@126.com>

 I am using your excellent R package eRM to solve a questionaire survey data. I meet a strange issue when using RSM function. This RSM runs well using sample data.

There is a test data like this:

'data.frame':   1669 obs. of  7 variables:

 $ X1: num  2 2 3 3 2 3 4 4 3 2 ...

 $ X2: num  4 3 3 2 3 4 4 4 3 3 ...

 $ X3: num  4 3 3 4 3 3 4 4 3 0 ...

 $ X4: num  2 3 2 4 1 2 3 3 3 1 ...

 $ X5: num  4 4 3 3 3 4 4 4 3 3 ...

 $ X6: num  4 4 4 3 3 4 4 4 3 3 ...

 $ X7: num  4 2 3 4 3 3 4 4 3 3 ...

 

###

RSM(test)

Warning in sqrt(diag(solve(parest$hessian))) : NaNs produced

Warning in sqrt(diag(lres$W %*% solve(parest$hessian) %*% t(lres$W))) :

  NaNs produced

 

Results of RSM estimation:

 

Call:  RSM(X = test)

 

Conditional log-likelihood: 13768080

Number of iterations: 5

Number of parameters: 9

 

Item (Category) Difficulty Parameters (eta):

                X2        X3       X4        X5        X6        X7     Cat 2     Cat 3       Cat 4

Estimate -700.9534 -456.4338 901.4649 -1322.033 -1256.828 -673.2412 -231.5791 -3979.953 1911.748203

Std.Err        NaN       NaN      NaN       NaN       NaN       NaN       NaN       NaN    1.036215

 

###

So, I use a shortened data, run like this:

RSM(test[1:283,])

Results of RSM estimation:

 

Call:  RSM(X = test[1:283, ])

 

Conditional log-likelihood: -1015.388

Number of iterations: 29

Number of parameters: 9

 

Item (Category) Difficulty Parameters (eta):

                 X2         X3        X4         X5         X6         X7     Cat 2     Cat 3    Cat 4

Estimate -0.0739008 0.05655997 1.2203061 -1.1212188 -0.7547957 -0.0378593 1.2020940 3.2657449 8.501760

Std.Err   0.1018267 0.10026033 0.1003035  0.1195827  0.1125677  0.1013739 0.4387487 0.8161754 1.226057

 

###

However, when I add one record, from 283 to 284,

RSM(test[1:284,])

Warning in sqrt(diag(solve(parest$hessian))) : NaNs produced

Warning in sqrt(diag(lres$W %*% solve(parest$hessian) %*% t(lres$W))) :

  NaNs produced

 

Results of RSM estimation:

 

Call:  RSM(X = test[1:284, ])

 

Conditional log-likelihood: 3369344

Number of iterations: 6

Number of parameters: 9

 

Item (Category) Difficulty Parameters (eta):

                X2        X3         X4        X5        X6        X7     Cat 2     Cat 3       Cat 4

Estimate -670.9137 -554.6215 527.789997 -1359.721 -1127.137 -626.1859 -126.7199 -4753.367 2134.408482

Std.Err  2152.9823 1679.2875   2.377241       NaN       NaN 3394.5180  562.6800 11045.935    3.526018

 

I can?t find any special values in the data list

   X1 X2 X3 X4 X5 X6 X7

270  4  4  4  3  4  4  4
271  3  3  3  1  3  3  3
272  4  3  4  1  4  4  4

273  3  3  3  3  3  3  3

274  3  3  4  4  3  3  4

275  3  3  3  3  3  3  3

276  1  3  3  3  3  3  3

277  3  3  3  2  4  4  4

278  2  3  2  1  3  3  3

279  3  3  3  2  3  3  3

280  3  3  2  2  3  3  3

281  3  4  4  3  4  3  3

282  2  2  2  2  2  2  2

283  3  4  3  1  4  3  3

284  2  4  2  1  4  3  2

285  3  3  3  3  3  3  3

286  4  4  3  4  4  4  4

287  4  3  4  0  3  4  4

288  0  3  4  0  4  4  1

289  4  4  4  4  4  4  4

290  3  3  3  3  3  3  2

 

If I input many different numbers of data, the results often become strange.

The data is appended at the letter. No na values in all data.

 

Great thanks



#### all data  is in the appended file








From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue Sep 28 15:54:14 2021
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 28 Sep 2021 14:54:14 +0100
Subject: [R] Issue about eRM package
In-Reply-To: <26a204d.4209.17c2bc3de6b.Coremail.qifasong@126.com>
References: <26a204d.4209.17c2bc3de6b.Coremail.qifasong@126.com>
Message-ID: <78d213f4-22c1-99d1-f3e6-9335175c6d31@dewey.myzen.co.uk>

I do not know that package so cannot help with that but the dataset did 
not come through. This mailing list is quite restrictive in what sorts 
of attachment it allows so I suggest trying something like a .csv file 
or a .txt file.

Michael

On 28/09/2021 10:37, ??? wrote:
>   I am using your excellent R package eRM to solve a questionaire survey data. I meet a strange issue when using RSM function. This RSM runs well using sample data.
> 
> There is a test data like this:
> 
> 'data.frame':   1669 obs. of  7 variables:
> 
>   $ X1: num  2 2 3 3 2 3 4 4 3 2 ...
> 
>   $ X2: num  4 3 3 2 3 4 4 4 3 3 ...
> 
>   $ X3: num  4 3 3 4 3 3 4 4 3 0 ...
> 
>   $ X4: num  2 3 2 4 1 2 3 3 3 1 ...
> 
>   $ X5: num  4 4 3 3 3 4 4 4 3 3 ...
> 
>   $ X6: num  4 4 4 3 3 4 4 4 3 3 ...
> 
>   $ X7: num  4 2 3 4 3 3 4 4 3 3 ...
> 
>   
> 
> ###
> 
> RSM(test)
> 
> Warning in sqrt(diag(solve(parest$hessian))) : NaNs produced
> 
> Warning in sqrt(diag(lres$W %*% solve(parest$hessian) %*% t(lres$W))) :
> 
>    NaNs produced
> 
>   
> 
> Results of RSM estimation:
> 
>   
> 
> Call:  RSM(X = test)
> 
>   
> 
> Conditional log-likelihood: 13768080
> 
> Number of iterations: 5
> 
> Number of parameters: 9
> 
>   
> 
> Item (Category) Difficulty Parameters (eta):
> 
>                  X2        X3       X4        X5        X6        X7     Cat 2     Cat 3       Cat 4
> 
> Estimate -700.9534 -456.4338 901.4649 -1322.033 -1256.828 -673.2412 -231.5791 -3979.953 1911.748203
> 
> Std.Err        NaN       NaN      NaN       NaN       NaN       NaN       NaN       NaN    1.036215
> 
>   
> 
> ###
> 
> So, I use a shortened data, run like this:
> 
> RSM(test[1:283,])
> 
> Results of RSM estimation:
> 
>   
> 
> Call:  RSM(X = test[1:283, ])
> 
>   
> 
> Conditional log-likelihood: -1015.388
> 
> Number of iterations: 29
> 
> Number of parameters: 9
> 
>   
> 
> Item (Category) Difficulty Parameters (eta):
> 
>                   X2         X3        X4         X5         X6         X7     Cat 2     Cat 3    Cat 4
> 
> Estimate -0.0739008 0.05655997 1.2203061 -1.1212188 -0.7547957 -0.0378593 1.2020940 3.2657449 8.501760
> 
> Std.Err   0.1018267 0.10026033 0.1003035  0.1195827  0.1125677  0.1013739 0.4387487 0.8161754 1.226057
> 
>   
> 
> ###
> 
> However, when I add one record, from 283 to 284,
> 
> RSM(test[1:284,])
> 
> Warning in sqrt(diag(solve(parest$hessian))) : NaNs produced
> 
> Warning in sqrt(diag(lres$W %*% solve(parest$hessian) %*% t(lres$W))) :
> 
>    NaNs produced
> 
>   
> 
> Results of RSM estimation:
> 
>   
> 
> Call:  RSM(X = test[1:284, ])
> 
>   
> 
> Conditional log-likelihood: 3369344
> 
> Number of iterations: 6
> 
> Number of parameters: 9
> 
>   
> 
> Item (Category) Difficulty Parameters (eta):
> 
>                  X2        X3         X4        X5        X6        X7     Cat 2     Cat 3       Cat 4
> 
> Estimate -670.9137 -554.6215 527.789997 -1359.721 -1127.137 -626.1859 -126.7199 -4753.367 2134.408482
> 
> Std.Err  2152.9823 1679.2875   2.377241       NaN       NaN 3394.5180  562.6800 11045.935    3.526018
> 
>   
> 
> I can?t find any special values in the data list
> 
>     X1 X2 X3 X4 X5 X6 X7
> 
> 270  4  4  4  3  4  4  4
> 271  3  3  3  1  3  3  3
> 272  4  3  4  1  4  4  4
> 
> 273  3  3  3  3  3  3  3
> 
> 274  3  3  4  4  3  3  4
> 
> 275  3  3  3  3  3  3  3
> 
> 276  1  3  3  3  3  3  3
> 
> 277  3  3  3  2  4  4  4
> 
> 278  2  3  2  1  3  3  3
> 
> 279  3  3  3  2  3  3  3
> 
> 280  3  3  2  2  3  3  3
> 
> 281  3  4  4  3  4  3  3
> 
> 282  2  2  2  2  2  2  2
> 
> 283  3  4  3  1  4  3  3
> 
> 284  2  4  2  1  4  3  2
> 
> 285  3  3  3  3  3  3  3
> 
> 286  4  4  3  4  4  4  4
> 
> 287  4  3  4  0  3  4  4
> 
> 288  0  3  4  0  4  4  1
> 
> 289  4  4  4  4  4  4  4
> 
> 290  3  3  3  3  3  3  2
> 
>   
> 
> If I input many different numbers of data, the results often become strange.
> 
> The data is appended at the letter. No na values in all data.
> 
>   
> 
> Great thanks
> 
> 
> 
> #### all data  is in the appended file
> 
> 
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Sep 28 23:56:32 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 29 Sep 2021 10:56:32 +1300
Subject: [R] Rdversion ???
Message-ID: <20210929105632.24f85046@rolf-Latitude-E7470>


I just noticed that a help file in one of my packages contains,
as the second line (just after the \name{ }  macro), the line

> \Rdversion{1.1}

I have no idea how it got there.  I can find no reference to this
macro in WRE, but by doing some groping, err, grepping around I have
discovered its presence in a number of help files for other packages.

Can anyone explain to me what it's for, and what its provenance is?

Is it important?

Thanks for any enlightenment.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From w||||@mwdun|@p @end|ng |rom gm@||@com  Wed Sep 29 01:02:55 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Tue, 28 Sep 2021 16:02:55 -0700
Subject: [R] Rdversion ???
In-Reply-To: <20210929105632.24f85046@rolf-Latitude-E7470>
References: <20210929105632.24f85046@rolf-Latitude-E7470>
Message-ID: <CAHqSRuQuwNbKghCZcNbRnrvEsh-UJH5Jqh2_JPqoAoEm4ag9iA@mail.gmail.com>

tools:::prepare2_Rd contains the lines
    ## FIXME: we no longer make any use of \Rdversion
    version <- which(sections == "\\Rdversion")
    if (length(version) > 1L)
        stopRd(Rd[[version[2L]]], Rdfile,
               "Only one \\Rdversion declaration is allowed")
so I am guessing you can ignore any \Rdversion declarations.

-Bill


On Tue, Sep 28, 2021 at 2:57 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> I just noticed that a help file in one of my packages contains,
> as the second line (just after the \name{ }  macro), the line
>
> > \Rdversion{1.1}
>
> I have no idea how it got there.  I can find no reference to this
> macro in WRE, but by doing some groping, err, grepping around I have
> discovered its presence in a number of help files for other packages.
>
> Can anyone explain to me what it's for, and what its provenance is?
>
> Is it important?
>
> Thanks for any enlightenment.
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Wed Sep 29 04:25:43 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Wed, 29 Sep 2021 05:25:43 +0300
Subject: [R] Word-Wrapper Library/Package?
Message-ID: <34b53d95-1002-ab9f-b87c-95165e1d09b8@syonic.eu>

Dear R-Users,


Does anyone know any package or library that implements functions for 
word wrapping?


I did implement a very rudimentary one (Github link below), but would 
like to avoid to reinvent the wheel. Considering that word-wrapping is a 
very common task, it should be available even in base R (e.g. in a 
"format" module/package).


Sincerely,


Leonard

=======

The latest versions of the functions are on Github:

https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
# Note:
# - the function implementing word wrapping: split.N.line(...);
# - for the example below: the functions defined in Tools.CRAN.R are 
required;


Examples:
### Search CRAN
library(pkgsearch)

searchCran = function(s, from=1, len=60, len.print=20, extend="*",
 ??? ??? sep=" ", sep.h="-") {
 ??? if( ! is.null(extend)) s = paste0(s, extend);
 ??? x = advanced_search(s, size=len, from=from);
 ??? if(length(x$package_data) == 0) {
 ??? ??? cat("No packages found!", sep="\n");
 ??? } else {
 ??? ??? scroll.pkg(x, len=len.print, sep=sep, sep.h=sep.h);
 ??? }
 ??? invisible(x)
}

# with nice formatting & printing:
x = searchCran("text", from=60, sep.h="-")

scroll.pkg(x, start=20, len=21, sep.h = "-*")
# test of sep.h=NULL vs ...


Notes:

1.) split.N.line:

- was implemented to output a pre-specified number of lines (kind of 
"maxLines"), but this is not required from an actual word-wrapper;

- it was an initial design decision when implementing the format.lines() 
function; but I plan to implement a 1-pass exact algorithm during the 
next few days anyway;

2.) Refactoring

- I will also move the formatting code to a new file: probably 
Tools.Formatting.R;

- the same applies for the formatting code for ftable (currently in file 
Tools.Data.R);

3.) Package gridtext

- seems to have some word-wrapping functionality, but does not seem to 
expose it;

- I am also currently focused on character-based word wrapping (e.g. for 
RConsole);



	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Wed Sep 29 05:30:50 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Tue, 28 Sep 2021 23:30:50 -0400
Subject: [R] Word-Wrapper Library/Package?
In-Reply-To: <34b53d95-1002-ab9f-b87c-95165e1d09b8@syonic.eu>
References: <34b53d95-1002-ab9f-b87c-95165e1d09b8@syonic.eu>
Message-ID: <CAPcHnpTiBnusDrBOvXN5BJO7i5y3_jC4g7JKdyP+DAxcV=mhUQ@mail.gmail.com>

I think what you're looking for is 'strwrap', it's in package base.

On Tue, Sep 28, 2021, 22:26 Leonard Mada via R-help <r-help at r-project.org>
wrote:

> Dear R-Users,
>
>
> Does anyone know any package or library that implements functions for
> word wrapping?
>
>
> I did implement a very rudimentary one (Github link below), but would
> like to avoid to reinvent the wheel. Considering that word-wrapping is a
> very common task, it should be available even in base R (e.g. in a
> "format" module/package).
>
>
> Sincerely,
>
>
> Leonard
>
> =======
>
> The latest versions of the functions are on Github:
>
> https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
> # Note:
> # - the function implementing word wrapping: split.N.line(...);
> # - for the example below: the functions defined in Tools.CRAN.R are
> required;
>
>
> Examples:
> ### Search CRAN
> library(pkgsearch)
>
> searchCran = function(s, from=1, len=60, len.print=20, extend="*",
>          sep=" ", sep.h="-") {
>      if( ! is.null(extend)) s = paste0(s, extend);
>      x = advanced_search(s, size=len, from=from);
>      if(length(x$package_data) == 0) {
>          cat("No packages found!", sep="\n");
>      } else {
>          scroll.pkg(x, len=len.print, sep=sep, sep.h=sep.h);
>      }
>      invisible(x)
> }
>
> # with nice formatting & printing:
> x = searchCran("text", from=60, sep.h="-")
>
> scroll.pkg(x, start=20, len=21, sep.h = "-*")
> # test of sep.h=NULL vs ...
>
>
> Notes:
>
> 1.) split.N.line:
>
> - was implemented to output a pre-specified number of lines (kind of
> "maxLines"), but this is not required from an actual word-wrapper;
>
> - it was an initial design decision when implementing the format.lines()
> function; but I plan to implement a 1-pass exact algorithm during the
> next few days anyway;
>
> 2.) Refactoring
>
> - I will also move the formatting code to a new file: probably
> Tools.Formatting.R;
>
> - the same applies for the formatting code for ftable (currently in file
> Tools.Data.R);
>
> 3.) Package gridtext
>
> - seems to have some word-wrapping functionality, but does not seem to
> expose it;
>
> - I am also currently focused on character-based word wrapping (e.g. for
> RConsole);
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Wed Sep 29 05:51:11 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Wed, 29 Sep 2021 06:51:11 +0300
Subject: [R] Word-Wrapper Library/Package?
In-Reply-To: <CAPcHnpTiBnusDrBOvXN5BJO7i5y3_jC4g7JKdyP+DAxcV=mhUQ@mail.gmail.com>
References: <34b53d95-1002-ab9f-b87c-95165e1d09b8@syonic.eu>
 <CAPcHnpTiBnusDrBOvXN5BJO7i5y3_jC4g7JKdyP+DAxcV=mhUQ@mail.gmail.com>
Message-ID: <f63f5043-bfba-ddb3-8bc3-1e8384b8f5c1@syonic.eu>

Thank you Andrew.


I will explore this function more, although I am struggling to get it to 
work properly:

strwrap("Abc. B. Defg", 7)
# [1] "Abc." "B."?? "Defg"

# both "Abc. B." and "B. Defg" are 7 characters long.

strwrap(paste0(rep("ab", 7), collapse=""), 7)
# [1] "ababababababab"


Can I set an absolute maximum width?

It would be nice to have an algorithm that computes a penalty for the 
split and selects the split with the smallest penalty (when no obvious 
split is possible).


Sincerely,


Leonard



On 9/29/2021 6:30 AM, Andrew Simmons wrote:
> I think what you're looking for is 'strwrap', it's in package base.
>
> On Tue, Sep 28, 2021, 22:26 Leonard Mada via R-help 
> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>
>     Dear R-Users,
>
>
>     Does anyone know any package or library that implements functions for
>     word wrapping?
>
>
>     I did implement a very rudimentary one (Github link below), but would
>     like to avoid to reinvent the wheel. Considering that
>     word-wrapping is a
>     very common task, it should be available even in base R (e.g. in a
>     "format" module/package).
>
>
>     Sincerely,
>
>
>     Leonard
>
>     =======
>
>     The latest versions of the functions are on Github:
>
>     https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
>     <https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R>
>     # Note:
>     # - the function implementing word wrapping: split.N.line(...);
>     # - for the example below: the functions defined in Tools.CRAN.R are
>     required;
>
>
>     Examples:
>     ### Search CRAN
>     library(pkgsearch)
>
>     searchCran = function(s, from=1, len=60, len.print=20, extend="*",
>     ???? ??? sep=" ", sep.h="-") {
>     ???? if( ! is.null(extend)) s = paste0(s, extend);
>     ???? x = advanced_search(s, size=len, from=from);
>     ???? if(length(x$package_data) == 0) {
>     ???? ??? cat("No packages found!", sep="\n");
>     ???? } else {
>     ???? ??? scroll.pkg(x, len=len.print, sep=sep, sep.h=sep.h);
>     ???? }
>     ???? invisible(x)
>     }
>
>     # with nice formatting & printing:
>     x = searchCran("text", from=60, sep.h="-")
>
>     scroll.pkg(x, start=20, len=21, sep.h = "-*")
>     # test of sep.h=NULL vs ...
>
>
>     Notes:
>
>     1.) split.N.line:
>
>     - was implemented to output a pre-specified number of lines (kind of
>     "maxLines"), but this is not required from an actual word-wrapper;
>
>     - it was an initial design decision when implementing the
>     format.lines()
>     function; but I plan to implement a 1-pass exact algorithm during the
>     next few days anyway;
>
>     2.) Refactoring
>
>     - I will also move the formatting code to a new file: probably
>     Tools.Formatting.R;
>
>     - the same applies for the formatting code for ftable (currently
>     in file
>     Tools.Data.R);
>
>     3.) Package gridtext
>
>     - seems to have some word-wrapping functionality, but does not
>     seem to
>     expose it;
>
>     - I am also currently focused on character-based word wrapping
>     (e.g. for
>     RConsole);
>
>
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Wed Sep 29 05:57:43 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Tue, 28 Sep 2021 23:57:43 -0400
Subject: [R] Word-Wrapper Library/Package?
In-Reply-To: <f63f5043-bfba-ddb3-8bc3-1e8384b8f5c1@syonic.eu>
References: <34b53d95-1002-ab9f-b87c-95165e1d09b8@syonic.eu>
 <CAPcHnpTiBnusDrBOvXN5BJO7i5y3_jC4g7JKdyP+DAxcV=mhUQ@mail.gmail.com>
 <f63f5043-bfba-ddb3-8bc3-1e8384b8f5c1@syonic.eu>
Message-ID: <CAPcHnpRDAZMPW4wTcp-_sgjbaqPdTgknb37HKKA=Cg-2cuyo+w@mail.gmail.com>

'strwrap' should wrap at the target column, so I think it's behaving
correctly. You could do + 1 if you're expecting it to wrap immediately
after the target column.

As far as splitting while trying to minimize a penalty, I don't think
strwrap can do that, and I don't know of any packages that do such a thing.
If such a thing exists in another language, there's probably an R package
with a similar name containing ports of such functions, that might be your
best bet. I hope this helps.

On Tue, Sep 28, 2021, 23:51 Leonard Mada <leo.mada at syonic.eu> wrote:

> Thank you Andrew.
>
>
> I will explore this function more, although I am struggling to get it to
> work properly:
>
> strwrap("Abc. B. Defg", 7)
> # [1] "Abc." "B."   "Defg"
>
> # both "Abc. B." and "B. Defg" are 7 characters long.
>
> strwrap(paste0(rep("ab", 7), collapse=""), 7)
> # [1] "ababababababab"
>
>
> Can I set an absolute maximum width?
>
> It would be nice to have an algorithm that computes a penalty for the
> split and selects the split with the smallest penalty (when no obvious
> split is possible).
>
>
> Sincerely,
>
>
> Leonard
>
>
>
> On 9/29/2021 6:30 AM, Andrew Simmons wrote:
>
> I think what you're looking for is 'strwrap', it's in package base.
>
> On Tue, Sep 28, 2021, 22:26 Leonard Mada via R-help <r-help at r-project.org>
> wrote:
>
>> Dear R-Users,
>>
>>
>> Does anyone know any package or library that implements functions for
>> word wrapping?
>>
>>
>> I did implement a very rudimentary one (Github link below), but would
>> like to avoid to reinvent the wheel. Considering that word-wrapping is a
>> very common task, it should be available even in base R (e.g. in a
>> "format" module/package).
>>
>>
>> Sincerely,
>>
>>
>> Leonard
>>
>> =======
>>
>> The latest versions of the functions are on Github:
>>
>> https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
>> # Note:
>> # - the function implementing word wrapping: split.N.line(...);
>> # - for the example below: the functions defined in Tools.CRAN.R are
>> required;
>>
>>
>> Examples:
>> ### Search CRAN
>> library(pkgsearch)
>>
>> searchCran = function(s, from=1, len=60, len.print=20, extend="*",
>>          sep=" ", sep.h="-") {
>>      if( ! is.null(extend)) s = paste0(s, extend);
>>      x = advanced_search(s, size=len, from=from);
>>      if(length(x$package_data) == 0) {
>>          cat("No packages found!", sep="\n");
>>      } else {
>>          scroll.pkg(x, len=len.print, sep=sep, sep.h=sep.h);
>>      }
>>      invisible(x)
>> }
>>
>> # with nice formatting & printing:
>> x = searchCran("text", from=60, sep.h="-")
>>
>> scroll.pkg(x, start=20, len=21, sep.h = "-*")
>> # test of sep.h=NULL vs ...
>>
>>
>> Notes:
>>
>> 1.) split.N.line:
>>
>> - was implemented to output a pre-specified number of lines (kind of
>> "maxLines"), but this is not required from an actual word-wrapper;
>>
>> - it was an initial design decision when implementing the format.lines()
>> function; but I plan to implement a 1-pass exact algorithm during the
>> next few days anyway;
>>
>> 2.) Refactoring
>>
>> - I will also move the formatting code to a new file: probably
>> Tools.Formatting.R;
>>
>> - the same applies for the formatting code for ftable (currently in file
>> Tools.Data.R);
>>
>> 3.) Package gridtext
>>
>> - seems to have some word-wrapping functionality, but does not seem to
>> expose it;
>>
>> - I am also currently focused on character-based word wrapping (e.g. for
>> RConsole);
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Sep 29 11:23:17 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 29 Sep 2021 22:23:17 +1300
Subject: [R] Rdversion ???
In-Reply-To: <CAHqSRuQuwNbKghCZcNbRnrvEsh-UJH5Jqh2_JPqoAoEm4ag9iA@mail.gmail.com>
References: <20210929105632.24f85046@rolf-Latitude-E7470>
 <CAHqSRuQuwNbKghCZcNbRnrvEsh-UJH5Jqh2_JPqoAoEm4ag9iA@mail.gmail.com>
Message-ID: <20210929222317.66c51f28@rolf-Latitude-E7470>


On Tue, 28 Sep 2021 16:02:55 -0700
Bill Dunlap <williamwdunlap at gmail.com> wrote:

> tools:::prepare2_Rd contains the lines
>     ## FIXME: we no longer make any use of \Rdversion
>     version <- which(sections == "\\Rdversion")
>     if (length(version) > 1L)
>         stopRd(Rd[[version[2L]]], Rdfile,
>                "Only one \\Rdversion declaration is allowed")
> so I am guessing you can ignore any \Rdversion declarations.

Music to my, uh, eyes!  Thanks Bill.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Sep 29 15:46:52 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 29 Sep 2021 15:46:52 +0200
Subject: [R] How to install package meta on Linux Ubuntu 21?
Message-ID: <CAMk+s2SDjp8awgXRYsMh+iTEyRsy56f8=sneJwTEEX0dgCx+Rw@mail.gmail.com>

Hello
I have R version 4.1.1 (2021-08-10) -- "Kick Things", on an Ubuntu 21
machine. I am trying to install the package meta but I get the
following error:
```
...
ERROR: dependency ?RcppEigen? is not available for package ?lme4?
* removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/lme4?
Warning in install.packages :
  installation of package ?lme4? had non-zero exit status
ERROR: dependency ?lme4? is not available for package ?meta?
```
I tried to install RcppEigen but:
```
...
/usr/bin/ld: cannot find -llapack
/usr/bin/ld: cannot find -lblas
/usr/bin/ld: cannot find -lgfortran
collect2: error: ld returned 1 exit status
make: *** [/usr/share/R/share/make/shlib.mk:10: RcppEigen.so] Error 1
ERROR: compilation failed for package ?RcppEigen?
* removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/RcppEigen?
Warning in install.packages :
  installation of package ?RcppEigen? had non-zero exit status
```
and lme4 requires RcppEigen.
I launched
`$ sudo apt-get install r-cran-rcppeigen`
installation successful but I got the same error in installing RcppEigen.
What could be the error?
-- 
Best regards,
Luigi


From n|ckmwr@y @end|ng |rom gm@||@com  Wed Sep 29 18:29:21 2021
From: n|ckmwr@y @end|ng |rom gm@||@com (Nick Wray)
Date: Wed, 29 Sep 2021 17:29:21 +0100
Subject: [R] Rcpp package problems
Message-ID: <CABxY9BNyYaHE8HYvPNnYfFu+VZ_5UMOsUkJTF=980TokS8TQiw@mail.gmail.com>

Hi I am having having problems with the package Rcpp.  Although I have
installed and loaded it, in two different situations it seems to send R
into an endless loop



The first one was trying to run code from a site showing how to use the
stl() function

*http://www.gardner.fyi/blog/STL-Part-I/
<http://www.gardner.fyi/blog/STL-Part-I/>*



The code and data is at

https://github.com/dillongardner/NYTraffic



The first few lines are as follows:



library(feather)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stlplus)
library(dygraphs)
library(lubridate)
library(Rcpp)
##########################################################################
# Read and format
##########################################################################

myData <- read_feather("NYTrafficData.feather")

At this point I get the error message: ?Error in openFeather(path) :

  function 'Rcpp_precious_remove' not provided by package 'Rcpp'?



BUT ? if now I rerun the line

library(Rcpp)

I don?t get the error message but R goes into an endless loop with the red
button thing



Similarly, if I try to run the example code from the R documentation site



https://www.rdocumentation.org/packages/stlplus/versions/0.5.1/topics/stlplus



library(stlplus)
library(Rcpp)
######
co2_stl <- stlplus(co2, t = as.vector(time(co2)), n.p = 12,
                   l.window = 13, t.window = 19, s.window = 35, s.degree = 1,
                   sub.labels = substr(month.name, 1, 3))

Again I get the error message ?Error in c_loess(x[y_idx], y[y_idx],
degree, span, weights[y_idx], m,  :

  function 'Rcpp_precious_remove' not provided by package 'Rcpp'?



BUT again if I rerun the line

library(Rcpp)

I don?t get the error message but R goes into an endless loop with the red
button thing



Can anyone help me to sort this?  Thanks Nick Wray

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep 29 18:48:36 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 29 Sep 2021 09:48:36 -0700
Subject: [R] Rcpp package problems
In-Reply-To: <CABxY9BNyYaHE8HYvPNnYfFu+VZ_5UMOsUkJTF=980TokS8TQiw@mail.gmail.com>
References: <CABxY9BNyYaHE8HYvPNnYfFu+VZ_5UMOsUkJTF=980TokS8TQiw@mail.gmail.com>
Message-ID: <3E193C18-8694-4BBB-9E21-95B58F0F82E9@dcn.davis.ca.us>

Do read the Posting Guide ... this is the wrong venue for detailed discussions of contributed packages.

For this topic I suggest [1], though you may want to make sure you have updated all of your packages with no errors and that this behavior still occurs before going there. You should also prove your status by providing the output of sessionInfo() in your report.

[1] https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel

On September 29, 2021 9:29:21 AM PDT, Nick Wray <nickmwray at gmail.com> wrote:
>Hi I am having having problems with the package Rcpp.  Although I have
>installed and loaded it, in two different situations it seems to send R
>into an endless loop
>
>
>
>The first one was trying to run code from a site showing how to use the
>stl() function
>
>*http://www.gardner.fyi/blog/STL-Part-I/
><http://www.gardner.fyi/blog/STL-Part-I/>*
>
>
>
>The code and data is at
>
>https://github.com/dillongardner/NYTraffic
>
>
>
>The first few lines are as follows:
>
>
>
>library(feather)
>library(dplyr)
>library(tidyr)
>library(ggplot2)
>library(stlplus)
>library(dygraphs)
>library(lubridate)
>library(Rcpp)
>##########################################################################
># Read and format
>##########################################################################
>
>myData <- read_feather("NYTrafficData.feather")
>
>At this point I get the error message: ?Error in openFeather(path) :
>
>  function 'Rcpp_precious_remove' not provided by package 'Rcpp'?
>
>
>
>BUT ? if now I rerun the line
>
>library(Rcpp)
>
>I don?t get the error message but R goes into an endless loop with the red
>button thing
>
>
>
>Similarly, if I try to run the example code from the R documentation site
>
>
>
>https://www.rdocumentation.org/packages/stlplus/versions/0.5.1/topics/stlplus
>
>
>
>library(stlplus)
>library(Rcpp)
>######
>co2_stl <- stlplus(co2, t = as.vector(time(co2)), n.p = 12,
>                   l.window = 13, t.window = 19, s.window = 35, s.degree = 1,
>                   sub.labels = substr(month.name, 1, 3))
>
>Again I get the error message ?Error in c_loess(x[y_idx], y[y_idx],
>degree, span, weights[y_idx], m,  :
>
>  function 'Rcpp_precious_remove' not provided by package 'Rcpp'?
>
>
>
>BUT again if I rerun the line
>
>library(Rcpp)
>
>I don?t get the error message but R goes into an endless loop with the red
>button thing
>
>
>
>Can anyone help me to sort this?  Thanks Nick Wray
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From kev|n@thorpe @end|ng |rom utoronto@c@  Wed Sep 29 18:53:14 2021
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Wed, 29 Sep 2021 16:53:14 +0000
Subject: [R] How to install package meta on Linux Ubuntu 21?
In-Reply-To: <CAMk+s2SDjp8awgXRYsMh+iTEyRsy56f8=sneJwTEEX0dgCx+Rw@mail.gmail.com>
References: <CAMk+s2SDjp8awgXRYsMh+iTEyRsy56f8=sneJwTEEX0dgCx+Rw@mail.gmail.com>
Message-ID: <C59A4897-DA8A-450F-9515-CDC247129E2F@utoronto.ca>

It looks to me like you do not have the development packages installed in Ubuntu. These should be easy to obtain with a suitable apt-get command, but since I am not a primary Ubuntu user, I do not know the package names.


> On Sep 29, 2021, at 9:46 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> Hello
> I have R version 4.1.1 (2021-08-10) -- "Kick Things", on an Ubuntu 21
> machine. I am trying to install the package meta but I get the
> following error:
> ```
> ...
> ERROR: dependency ?RcppEigen? is not available for package ?lme4?
> * removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/lme4?
> Warning in install.packages :
>  installation of package ?lme4? had non-zero exit status
> ERROR: dependency ?lme4? is not available for package ?meta?
> ```
> I tried to install RcppEigen but:
> ```
> ...
> /usr/bin/ld: cannot find -llapack
> /usr/bin/ld: cannot find -lblas
> /usr/bin/ld: cannot find -lgfortran
> collect2: error: ld returned 1 exit status
> make: *** [/usr/share/R/share/make/shlib.mk:10: RcppEigen.so] Error 1
> ERROR: compilation failed for package ?RcppEigen?
> * removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/RcppEigen?
> Warning in install.packages :
>  installation of package ?RcppEigen? had non-zero exit status
> ```
> and lme4 requires RcppEigen.
> I launched
> `$ sudo apt-get install r-cran-rcppeigen`
> installation successful but I got the same error in installing RcppEigen.
> What could be the error?
> -- 
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep 29 21:08:09 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 29 Sep 2021 20:08:09 +0100
Subject: [R] Rcpp package problems
In-Reply-To: <CABxY9BNyYaHE8HYvPNnYfFu+VZ_5UMOsUkJTF=980TokS8TQiw@mail.gmail.com>
References: <CABxY9BNyYaHE8HYvPNnYfFu+VZ_5UMOsUkJTF=980TokS8TQiw@mail.gmail.com>
Message-ID: <822b84cc-ba48-778e-937b-64f733e1f1ce@sapo.pt>

Hello,

This problem is pratically a StackOverflow FAQ [1], with link to the 
Rcpp-devel mailing list [2].

[1] 
https://stackoverflow.com/questions/68416435/rcpp-package-doesnt-include-rcpp-precious-remove
[2] 
https://www.mail-archive.com/rcpp-devel at lists.r-forge.r-project.org/msg10226.html

Hope this helps,

Rui Barradas

?s 17:29 de 29/09/21, Nick Wray escreveu:
> Hi I am having having problems with the package Rcpp.  Although I have
> installed and loaded it, in two different situations it seems to send R
> into an endless loop
> 
> 
> 
> The first one was trying to run code from a site showing how to use the
> stl() function
> 
> *http://www.gardner.fyi/blog/STL-Part-I/
> <http://www.gardner.fyi/blog/STL-Part-I/>*
> 
> 
> 
> The code and data is at
> 
> https://github.com/dillongardner/NYTraffic
> 
> 
> 
> The first few lines are as follows:
> 
> 
> 
> library(feather)
> library(dplyr)
> library(tidyr)
> library(ggplot2)
> library(stlplus)
> library(dygraphs)
> library(lubridate)
> library(Rcpp)
> ##########################################################################
> # Read and format
> ##########################################################################
> 
> myData <- read_feather("NYTrafficData.feather")
> 
> At this point I get the error message: ?Error in openFeather(path) :
> 
>    function 'Rcpp_precious_remove' not provided by package 'Rcpp'?
> 
> 
> 
> BUT ? if now I rerun the line
> 
> library(Rcpp)
> 
> I don?t get the error message but R goes into an endless loop with the red
> button thing
> 
> 
> 
> Similarly, if I try to run the example code from the R documentation site
> 
> 
> 
> https://www.rdocumentation.org/packages/stlplus/versions/0.5.1/topics/stlplus
> 
> 
> 
> library(stlplus)
> library(Rcpp)
> ######
> co2_stl <- stlplus(co2, t = as.vector(time(co2)), n.p = 12,
>                     l.window = 13, t.window = 19, s.window = 35, s.degree = 1,
>                     sub.labels = substr(month.name, 1, 3))
> 
> Again I get the error message ?Error in c_loess(x[y_idx], y[y_idx],
> degree, span, weights[y_idx], m,  :
> 
>    function 'Rcpp_precious_remove' not provided by package 'Rcpp'?
> 
> 
> 
> BUT again if I rerun the line
> 
> library(Rcpp)
> 
> I don?t get the error message but R goes into an endless loop with the red
> button thing
> 
> 
> 
> Can anyone help me to sort this?  Thanks Nick Wray
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep 29 21:13:13 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 29 Sep 2021 20:13:13 +0100
Subject: [R] How to install package meta on Linux Ubuntu 21?
In-Reply-To: <C59A4897-DA8A-450F-9515-CDC247129E2F@utoronto.ca>
References: <CAMk+s2SDjp8awgXRYsMh+iTEyRsy56f8=sneJwTEEX0dgCx+Rw@mail.gmail.com>
 <C59A4897-DA8A-450F-9515-CDC247129E2F@utoronto.ca>
Message-ID: <f8f5b5e8-8634-71d1-18eb-6d03d30ca49e@sapo.pt>

Hello,

The recommended way is to install r-base-dev, you probably only have r-base.

sudo apt-get update
sudo apt-get install r-base-dev


Hope this helps,

Rui Barradas

?s 17:53 de 29/09/21, Kevin Thorpe escreveu:
> It looks to me like you do not have the development packages installed in Ubuntu. These should be easy to obtain with a suitable apt-get command, but since I am not a primary Ubuntu user, I do not know the package names.
> 
> 
>> On Sep 29, 2021, at 9:46 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Hello
>> I have R version 4.1.1 (2021-08-10) -- "Kick Things", on an Ubuntu 21
>> machine. I am trying to install the package meta but I get the
>> following error:
>> ```
>> ...
>> ERROR: dependency ?RcppEigen? is not available for package ?lme4?
>> * removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/lme4?
>> Warning in install.packages :
>>   installation of package ?lme4? had non-zero exit status
>> ERROR: dependency ?lme4? is not available for package ?meta?
>> ```
>> I tried to install RcppEigen but:
>> ```
>> ...
>> /usr/bin/ld: cannot find -llapack
>> /usr/bin/ld: cannot find -lblas
>> /usr/bin/ld: cannot find -lgfortran
>> collect2: error: ld returned 1 exit status
>> make: *** [/usr/share/R/share/make/shlib.mk:10: RcppEigen.so] Error 1
>> ERROR: compilation failed for package ?RcppEigen?
>> * removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/RcppEigen?
>> Warning in install.packages :
>>   installation of package ?RcppEigen? had non-zero exit status
>> ```
>> and lme4 requires RcppEigen.
>> I launched
>> `$ sudo apt-get install r-cran-rcppeigen`
>> installation successful but I got the same error in installing RcppEigen.
>> What could be the error?
>> -- 
>> Best regards,
>> Luigi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Sep 29 21:48:50 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 29 Sep 2021 21:48:50 +0200
Subject: [R] How to install package meta on Linux Ubuntu 21?
In-Reply-To: <f8f5b5e8-8634-71d1-18eb-6d03d30ca49e@sapo.pt>
References: <CAMk+s2SDjp8awgXRYsMh+iTEyRsy56f8=sneJwTEEX0dgCx+Rw@mail.gmail.com>
 <C59A4897-DA8A-450F-9515-CDC247129E2F@utoronto.ca>
 <f8f5b5e8-8634-71d1-18eb-6d03d30ca49e@sapo.pt>
Message-ID: <CAMk+s2Rr+i6tYMySs=HbfEGA_gAkYn5yNZVK9JJMBEomhKDW7g@mail.gmail.com>

Yep, that was it! Now it worked. Thanks

On Wed, Sep 29, 2021 at 9:13 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> The recommended way is to install r-base-dev, you probably only have r-base.
>
> sudo apt-get update
> sudo apt-get install r-base-dev
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 17:53 de 29/09/21, Kevin Thorpe escreveu:
> > It looks to me like you do not have the development packages installed in Ubuntu. These should be easy to obtain with a suitable apt-get command, but since I am not a primary Ubuntu user, I do not know the package names.
> >
> >
> >> On Sep 29, 2021, at 9:46 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >>
> >> Hello
> >> I have R version 4.1.1 (2021-08-10) -- "Kick Things", on an Ubuntu 21
> >> machine. I am trying to install the package meta but I get the
> >> following error:
> >> ```
> >> ...
> >> ERROR: dependency ?RcppEigen? is not available for package ?lme4?
> >> * removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/lme4?
> >> Warning in install.packages :
> >>   installation of package ?lme4? had non-zero exit status
> >> ERROR: dependency ?lme4? is not available for package ?meta?
> >> ```
> >> I tried to install RcppEigen but:
> >> ```
> >> ...
> >> /usr/bin/ld: cannot find -llapack
> >> /usr/bin/ld: cannot find -lblas
> >> /usr/bin/ld: cannot find -lgfortran
> >> collect2: error: ld returned 1 exit status
> >> make: *** [/usr/share/R/share/make/shlib.mk:10: RcppEigen.so] Error 1
> >> ERROR: compilation failed for package ?RcppEigen?
> >> * removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/RcppEigen?
> >> Warning in install.packages :
> >>   installation of package ?RcppEigen? had non-zero exit status
> >> ```
> >> and lme4 requires RcppEigen.
> >> I launched
> >> `$ sudo apt-get install r-cran-rcppeigen`
> >> installation successful but I got the same error in installing RcppEigen.
> >> What could be the error?
> >> --
> >> Best regards,
> >> Luigi
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >



-- 
Best regards,
Luigi


From brod|e @end|ng |rom mcw@edu  Wed Sep 29 23:11:14 2021
From: brod|e @end|ng |rom mcw@edu (Brodie, Kent)
Date: Wed, 29 Sep 2021 21:11:14 +0000
Subject: [R] Package installation help: Stuck at "** byte-compile and
 prepare package for lazy loading"
Message-ID: <BL3PR01MB68506C30DB1731B2E39975DCCEA99@BL3PR01MB6850.prod.exchangelabs.com>

Hey everyone!  So, I've been asked by one of our researchers to install "all" cran packages on one of our servers.    Yeah, it's a bit much (and clearly, not everything will install correctly due to various missing tidbits), but it will go a long way to having to constantly respond to install requests of various packages.  OK, fine.

Anyway, I have tried this, and things proceed nicely for several hours until the process gets completely and absolutely stuck.   I have tried several things, for example trying newer versions of R, and even repeating the process on a CentOS 8 server instead of where my stuff is now (CentOS 7).

While re-trying one of my newer attempts at this, I decided to focus on the very first place where it hangs.   It dies on package "forensim".    It's a slightly older package, and I don't see anything particularly special about it.    The text below is where it hangs.    The install "R" process doing this is whizzing at 100%,  but no progress, no output, no errors.  Nothing in the system logs.

On new "R" installs, with either operating system (CentOS 7, CentOS 8) and even different versions of "R" (up to including 4.1.1), I get the same result when just attempting to install this ONE package.    (and my guess, there's more packages out there that may bite me the same way).

I am seeking any recommendations on how I can get past this?   A debug option?  A timeout of sorts so things will  move along to the next package when attempting to install a ton, or...?   I'm of course willing to try anything.   It's stupidly frustrating.    I'd be OK if it errored out and moved on.   But it...  hangs.

Here's the latter part of the install attempt of this one package.     This latest attempt has been stuck on that last line now for 5 hours and counting.

* DONE (tkrplot)
Making 'packages.html' ... done
* installing *source* package 'forensim' ...
** package 'forensim' successfully unpacked and MD5 sums checked
** using staged installation
** libs
gcc -m64 -I"/usr/include/R" -DNDEBUG   -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection  -c auxilary.c -o auxilary.o
gcc -m64 -I"/usr/include/R" -DNDEBUG   -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection  -c recursFinal.c -o recursFinal.o
gcc -m64 -shared -L/usr/lib64/R/lib -Wl,-z,relro -Wl,-z,now -specs=/usr/lib/rpm/redhat/redhat-hardened-ld -o forensim.so auxilary.o recursFinal.o -L/usr/lib64/R/lib -lR
installing to /usr/lib64/R/library/00LOCK-forensim/00new/forensim/libs
** R
** data
** inst
** byte-compile and prepare package for lazy loading


	[[alternative HTML version deleted]]


From giusepp@cei@iu m@iii@g oii gm@ii@com  Thu Sep 30 04:24:41 2021
From: giusepp@cei@iu m@iii@g oii gm@ii@com (giusepp@cei@iu m@iii@g oii gm@ii@com)
Date: Wed, 29 Sep 2021 22:24:41 -0400
Subject: [R] How to install package meta on Linux Ubuntu 21?,
Message-ID: <008401d7b5a2$53594e10$fa0bea30$@gmail.com>

Hello,

I wonder if you can help me with this.  I am trying to eliminate unnecessary characters from the columns of a data frame.  For example this one, "df <- mutate_all(df,
                 funs(str_replace_all(., "\\[|\\]", "")))" eliminates the [ and ] that sometimes surround a number. Ex; [24.5] [54.6]

When I use the same command to eliminate the string "<NA>" it does not work. The only difference I have noticed is that the cell in the column containing the [ ] characters contains all the numbers in one row, but the cell in the column containing the "<NA>" characters contains several rows.

For example: variable_name
                        1 <NA>
                        2 <NA>
                        3 <NA> ...
I wonder if I have to collapse all the rows in a single row and eliminate one row.

Thank you,

Giuseppa Cefalu

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
Sent: Wednesday, September 29, 2021 3:13 PM
To: Kevin Thorpe <kevin.thorpe at utoronto.ca>; Luigi Marongiu <marongiu.luigi at gmail.com>
Cc: R Help Mailing List <r-help at r-project.org>
Subject: Re: [R] How to install package meta on Linux Ubuntu 21?

Hello,

The recommended way is to install r-base-dev, you probably only have r-base.

sudo apt-get update
sudo apt-get install r-base-dev


Hope this helps,

Rui Barradas

?s 17:53 de 29/09/21, Kevin Thorpe escreveu:
> It looks to me like you do not have the development packages installed in Ubuntu. These should be easy to obtain with a suitable apt-get command, but since I am not a primary Ubuntu user, I do not know the package names.
> 
> 
>> On Sep 29, 2021, at 9:46 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Hello
>> I have R version 4.1.1 (2021-08-10) -- "Kick Things", on an Ubuntu 21 
>> machine. I am trying to install the package meta but I get the 
>> following error:
>> ```
>> ...
>> ERROR: dependency ?RcppEigen? is not available for package ?lme4?
>> * removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/lme4?
>> Warning in install.packages :
>>   installation of package ?lme4? had non-zero exit status
>> ERROR: dependency ?lme4? is not available for package ?meta?
>> ```
>> I tried to install RcppEigen but:
>> ```
>> ...
>> /usr/bin/ld: cannot find -llapack
>> /usr/bin/ld: cannot find -lblas
>> /usr/bin/ld: cannot find -lgfortran
>> collect2: error: ld returned 1 exit status
>> make: *** [/usr/share/R/share/make/shlib.mk:10: RcppEigen.so] Error 1
>> ERROR: compilation failed for package ?RcppEigen?
>> * removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/RcppEigen?
>> Warning in install.packages :
>>   installation of package ?RcppEigen? had non-zero exit status ``` 
>> and lme4 requires RcppEigen.
>> I launched
>> `$ sudo apt-get install r-cran-rcppeigen` installation successful but 
>> I got the same error in installing RcppEigen.
>> What could be the error?
>> --
>> Best regards,
>> Luigi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Thu Sep 30 04:37:42 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Thu, 30 Sep 2021 05:37:42 +0300
Subject: [R] Word-Wrapper Library/Package?
In-Reply-To: <ee514a84-5d1a-421b-9bb8-4bea7e5574c0@email.android.com>
References: <ee514a84-5d1a-421b-9bb8-4bea7e5574c0@email.android.com>
Message-ID: <265cf491-9905-f8a4-d300-52aada67a323@syonic.eu>

Many thanks for the hint.


The function is actually a wrapper for:

stringi:::stri_wrap

I will need to have a closer look to this one (documentation and maybe 
also peek into the code):

ret <- .Call(C_stri_wrap, str, width, cost_exponent, indent,
 ??????? exdent, prefix, initial, whitespace_only, use_length,
 ??????? locale)


I thought at some point about the stringi package, but somehow 
overlooked it.


Sincerely,


Leonard


On 9/30/2021 1:09 AM, CALUM POLWART wrote:
> Have you looked at stringr::str_wrap or its parent function 
> stringi::stri_wrap ?
>
> It applies an algorithm for the wrap. But it doesn't vectorise the 
> lines they are returned with \n for new lines, but you could apply a 
> string split to that result...
>
>
> On 29 Sep 2021 04:57, Andrew Simmons <akwsimmo at gmail.com> wrote:
>
>     'strwrap' should wrap at the target column, so I think it's behaving
>     correctly. You could do + 1 if you're expecting it to wrap
>     immediately
>     after the target column.
>
>     As far as splitting while trying to minimize a penalty, I don't think
>     strwrap can do that, and I don't know of any packages that do such
>     a thing.
>     If such a thing exists in another language, there's probably an R
>     package
>     with a similar name containing ports of such functions, that might
>     be your
>     best bet. I hope this helps.
>
>     On Tue, Sep 28, 2021, 23:51 Leonard Mada <leo.mada at syonic.eu> wrote:
>
>     > Thank you Andrew.
>     >
>     >
>     > I will explore this function more, although I am struggling to
>     get it to
>     > work properly:
>     >
>     > strwrap("Abc. B. Defg", 7)
>     > # [1] "Abc." "B."?? "Defg"
>     >
>     > # both "Abc. B." and "B. Defg" are 7 characters long.
>     >
>     > strwrap(paste0(rep("ab", 7), collapse=""), 7)
>     > # [1] "ababababababab"
>     >
>     >
>     > Can I set an absolute maximum width?
>     >
>     > It would be nice to have an algorithm that computes a penalty
>     for the
>     > split and selects the split with the smallest penalty (when no
>     obvious
>     > split is possible).
>     >
>     >
>     > Sincerely,
>     >
>     >
>     > Leonard
>     >
>     >
>     >
>     > On 9/29/2021 6:30 AM, Andrew Simmons wrote:
>     >
>     > I think what you're looking for is 'strwrap', it's in package base.
>     >
>     > On Tue, Sep 28, 2021, 22:26 Leonard Mada via R-help
>     <r-help at r-project.org>
>     > wrote:
>     >
>     >> Dear R-Users,
>     >>
>     >>
>     >> Does anyone know any package or library that implements
>     functions for
>     >> word wrapping?
>     >>
>     >>
>     >> I did implement a very rudimentary one (Github link below), but
>     would
>     >> like to avoid to reinvent the wheel. Considering that
>     word-wrapping is a
>     >> very common task, it should be available even in base R (e.g. in a
>     >> "format" module/package).
>     >>
>     >>
>     >> Sincerely,
>     >>
>     >>
>     >> Leonard
>     >>
>     >> =======
>     >>
>     >> The latest versions of the functions are on Github:
>     >>
>     >> https://github.com/discoleo/R/blob/master/Stat/Tools.CRAN.R
>     >> # Note:
>     >> # - the function implementing word wrapping: split.N.line(...);
>     >> # - for the example below: the functions defined in
>     Tools.CRAN.R are
>     >> required;
>     >>
>     >>
>     >> Examples:
>     >> ### Search CRAN
>     >> library(pkgsearch)
>     >>
>     >> searchCran = function(s, from=1, len=60, len.print=20, extend="*",
>     >>????????? sep=" ", sep.h="-") {
>     >>????? if( ! is.null(extend)) s = paste0(s, extend);
>     >>????? x = advanced_search(s, size=len, from=from);
>     >>????? if(length(x$package_data) == 0) {
>     >>????????? cat("No packages found!", sep="\n");
>     >>????? } else {
>     >>????????? scroll.pkg(x, len=len.print, sep=sep, sep.h=sep.h);
>     >>????? }
>     >>????? invisible(x)
>     >> }
>     >>
>     >> # with nice formatting & printing:
>     >> x = searchCran("text", from=60, sep.h="-")
>     >>
>     >> scroll.pkg(x, start=20, len=21, sep.h = "-*")
>     >> # test of sep.h=NULL vs ...
>     >>
>     >>
>     >> Notes:
>     >>
>     >> 1.) split.N.line:
>     >>
>     >> - was implemented to output a pre-specified number of lines
>     (kind of
>     >> "maxLines"), but this is not required from an actual word-wrapper;
>     >>
>     >> - it was an initial design decision when implementing the
>     format.lines()
>     >> function; but I plan to implement a 1-pass exact algorithm
>     during the
>     >> next few days anyway;
>     >>
>     >> 2.) Refactoring
>     >>
>     >> - I will also move the formatting code to a new file: probably
>     >> Tools.Formatting.R;
>     >>
>     >> - the same applies for the formatting code for ftable
>     (currently in file
>     >> Tools.Data.R);
>     >>
>     >> 3.) Package gridtext
>     >>
>     >> - seems to have some word-wrapping functionality, but does not
>     seem to
>     >> expose it;
>     >>
>     >> - I am also currently focused on character-based word wrapping
>     (e.g. for
>     >> RConsole);
>     >>
>     >>
>     >>
>     >>???????? [[alternative HTML version deleted]]
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide
>     >> http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>     >>
>     >
>
>     [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Sep 30 04:42:57 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Wed, 29 Sep 2021 19:42:57 -0700
Subject: [R] Package installation help: Stuck at "** byte-compile and
 prepare package for lazy loading"
In-Reply-To: <BL3PR01MB68506C30DB1731B2E39975DCCEA99@BL3PR01MB6850.prod.exchangelabs.com>
References: <BL3PR01MB68506C30DB1731B2E39975DCCEA99@BL3PR01MB6850.prod.exchangelabs.com>
Message-ID: <CAFDcVCTd_mhZLEQpqgS0ErHUeSMmOoKt0zLLLm97MnaL0RkhGg@mail.gmail.com>

I just tried on an up-to-date CentOS 7 with R 4.1.1 built from source
using gcc 8.3.1 (from SCL devtoolset-8; so not the default gcc 4.8.5),
and it works there.  If of any help, here's the output when installing
to user's personal package library:

> chooseCRANmirror(ind = 1)
> install.packages("forensim")
Installing package into
?/c4/home/henrik/R/x86_64-pc-linux-gnu-library/4.1-CBI-gcc8?
(as ?lib? is unspecified)
trying URL 'https://cloud.r-project.org/src/contrib/forensim_4.3.tar.gz'
Content type 'application/x-gzip' length 84232 bytes (82 KB)
==================================================
downloaded 82 KB

* installing *source* package ?forensim? ...
** package ?forensim? successfully unpacked and MD5 sums checked
** using staged installation
** libs
gcc -I"/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/include"
-DNDEBUG   -I/usr/local/include   -fpic  -g -O2  -c auxilary.c -o
auxilary.o
gcc -I"/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/include"
-DNDEBUG   -I/usr/local/include   -fpic  -g -O2  -c recursFinal.c -o
recursFinal.o
gcc -shared -L/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/lib
-L/usr/local/lib64 -o forensim.so auxilary.o recursFinal.o
-L/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/lib -lR
installing to /c4/home/henrik/R/x86_64-pc-linux-gnu-library/4.1-CBI-gcc8/00LOCK-forensim/00new/forensim/libs
** R
** data
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** checking absolute paths in shared objects and dynamic libraries
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation path
* DONE (forensim)

The downloaded source packages are in
    ?/scratch/henrik/RtmpYFlQyS/downloaded_packages?

You could also try to install it via 'R CMD INSTALL' and try with
different options disabled to maybe narrow in on what's going on.

My $.02

/Henrik

On Wed, Sep 29, 2021 at 6:37 PM Brodie, Kent via R-help
<r-help at r-project.org> wrote:
>
> Hey everyone!  So, I've been asked by one of our researchers to install "all" cran packages on one of our servers.    Yeah, it's a bit much (and clearly, not everything will install correctly due to various missing tidbits), but it will go a long way to having to constantly respond to install requests of various packages.  OK, fine.
>
> Anyway, I have tried this, and things proceed nicely for several hours until the process gets completely and absolutely stuck.   I have tried several things, for example trying newer versions of R, and even repeating the process on a CentOS 8 server instead of where my stuff is now (CentOS 7).
>
> While re-trying one of my newer attempts at this, I decided to focus on the very first place where it hangs.   It dies on package "forensim".    It's a slightly older package, and I don't see anything particularly special about it.    The text below is where it hangs.    The install "R" process doing this is whizzing at 100%,  but no progress, no output, no errors.  Nothing in the system logs.
>
> On new "R" installs, with either operating system (CentOS 7, CentOS 8) and even different versions of "R" (up to including 4.1.1), I get the same result when just attempting to install this ONE package.    (and my guess, there's more packages out there that may bite me the same way).
>
> I am seeking any recommendations on how I can get past this?   A debug option?  A timeout of sorts so things will  move along to the next package when attempting to install a ton, or...?   I'm of course willing to try anything.   It's stupidly frustrating.    I'd be OK if it errored out and moved on.   But it...  hangs.
>
> Here's the latter part of the install attempt of this one package.     This latest attempt has been stuck on that last line now for 5 hours and counting.
>
> * DONE (tkrplot)
> Making 'packages.html' ... done
> * installing *source* package 'forensim' ...
> ** package 'forensim' successfully unpacked and MD5 sums checked
> ** using staged installation
> ** libs
> gcc -m64 -I"/usr/include/R" -DNDEBUG   -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection  -c auxilary.c -o auxilary.o
> gcc -m64 -I"/usr/include/R" -DNDEBUG   -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection  -c recursFinal.c -o recursFinal.o
> gcc -m64 -shared -L/usr/lib64/R/lib -Wl,-z,relro -Wl,-z,now -specs=/usr/lib/rpm/redhat/redhat-hardened-ld -o forensim.so auxilary.o recursFinal.o -L/usr/lib64/R/lib -lR
> installing to /usr/lib64/R/library/00LOCK-forensim/00new/forensim/libs
> ** R
> ** data
> ** inst
> ** byte-compile and prepare package for lazy loading
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep 30 05:04:32 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 29 Sep 2021 20:04:32 -0700
Subject: [R] How to install package meta on Linux Ubuntu 21?,
In-Reply-To: <008401d7b5a2$53594e10$fa0bea30$@gmail.com>
References: <008401d7b5a2$53594e10$fa0bea30$@gmail.com>
Message-ID: <C2552A2E-C56A-4DCE-9D97-56153366BC48@dcn.davis.ca.us>

This is called hijacking a thread. Bad etiquette.

You need to pay attention to column types and NA values. Only do regular expression manipulations on character data, and NA is never something you can do string operations on.

On September 29, 2021 7:24:41 PM PDT, giuseppacefalu at gmail.com wrote:
>Hello,
>
>I wonder if you can help me with this.  I am trying to eliminate unnecessary characters from the columns of a data frame.  For example this one, "df <- mutate_all(df,
>                 funs(str_replace_all(., "\\[|\\]", "")))" eliminates the [ and ] that sometimes surround a number. Ex; [24.5] [54.6]
>
>When I use the same command to eliminate the string "<NA>" it does not work. The only difference I have noticed is that the cell in the column containing the [ ] characters contains all the numbers in one row, but the cell in the column containing the "<NA>" characters contains several rows.
>
>For example: variable_name
>                        1 <NA>
>                        2 <NA>
>                        3 <NA> ...
>I wonder if I have to collapse all the rows in a single row and eliminate one row.
>
>Thank you,
>
>Giuseppa Cefalu
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
>Sent: Wednesday, September 29, 2021 3:13 PM
>To: Kevin Thorpe <kevin.thorpe at utoronto.ca>; Luigi Marongiu <marongiu.luigi at gmail.com>
>Cc: R Help Mailing List <r-help at r-project.org>
>Subject: Re: [R] How to install package meta on Linux Ubuntu 21?
>
>Hello,
>
>The recommended way is to install r-base-dev, you probably only have r-base.
>
>sudo apt-get update
>sudo apt-get install r-base-dev
>
>
>Hope this helps,
>
>Rui Barradas
>
>?s 17:53 de 29/09/21, Kevin Thorpe escreveu:
>> It looks to me like you do not have the development packages installed in Ubuntu. These should be easy to obtain with a suitable apt-get command, but since I am not a primary Ubuntu user, I do not know the package names.
>> 
>> 
>>> On Sep 29, 2021, at 9:46 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>>
>>> Hello
>>> I have R version 4.1.1 (2021-08-10) -- "Kick Things", on an Ubuntu 21 
>>> machine. I am trying to install the package meta but I get the 
>>> following error:
>>> ```
>>> ...
>>> ERROR: dependency ?RcppEigen? is not available for package ?lme4?
>>> * removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/lme4?
>>> Warning in install.packages :
>>>   installation of package ?lme4? had non-zero exit status
>>> ERROR: dependency ?lme4? is not available for package ?meta?
>>> ```
>>> I tried to install RcppEigen but:
>>> ```
>>> ...
>>> /usr/bin/ld: cannot find -llapack
>>> /usr/bin/ld: cannot find -lblas
>>> /usr/bin/ld: cannot find -lgfortran
>>> collect2: error: ld returned 1 exit status
>>> make: *** [/usr/share/R/share/make/shlib.mk:10: RcppEigen.so] Error 1
>>> ERROR: compilation failed for package ?RcppEigen?
>>> * removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/RcppEigen?
>>> Warning in install.packages :
>>>   installation of package ?RcppEigen? had non-zero exit status ``` 
>>> and lme4 requires RcppEigen.
>>> I launched
>>> `$ sudo apt-get install r-cran-rcppeigen` installation successful but 
>>> I got the same error in installing RcppEigen.
>>> What could be the error?
>>> --
>>> Best regards,
>>> Luigi
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Sep 30 06:12:04 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 29 Sep 2021 21:12:04 -0700
Subject: [R] How to install package meta on Linux Ubuntu 21?,
In-Reply-To: <C2552A2E-C56A-4DCE-9D97-56153366BC48@dcn.davis.ca.us>
References: <008401d7b5a2$53594e10$fa0bea30$@gmail.com>
 <C2552A2E-C56A-4DCE-9D97-56153366BC48@dcn.davis.ca.us>
Message-ID: <31fb174c-bb68-ec00-42f4-dc7c452cba70@comcast.net>


On 9/29/21 8:04 PM, Jeff Newmiller wrote:
> This is called hijacking a thread. Bad etiquette.
>
> You need to pay attention to column types and NA values. Only do regular expression manipulations on character data, and NA is never something you can do string operations on.

To Giuseppa;

When you see the characters <NA> without any surrounding quotes they are 
not really character values, but rather how the print function displays 
a missing value for a factor column. You cannot "eliminate it". In a 
very real sense it has already been "eliminated".

Read up on missing value handling at:


?NA... although that aspect is not mentioned at the help page (although 
it should be. Look at this console session fragment:


 > factor(NA)
[1] <NA>????????? # factor missing values get the extra angle brackets.
Levels:
 > NA
[1] NA
 > char <- c("a", "NA", NA)
 > char
[1] "a"? "NA" NA??? # note that a character value of "NA" has quotes but 
a real missing value has none.

-- 

David.

>
> On September 29, 2021 7:24:41 PM PDT, giuseppacefalu at gmail.com wrote:
>> Hello,
>>
>> I wonder if you can help me with this.  I am trying to eliminate unnecessary characters from the columns of a data frame.  For example this one, "df <- mutate_all(df,
>>                  funs(str_replace_all(., "\\[|\\]", "")))" eliminates the [ and ] that sometimes surround a number. Ex; [24.5] [54.6]
>>
>> When I use the same command to eliminate the string "<NA>" it does not work. The only difference I have noticed is that the cell in the column containing the [ ] characters contains all the numbers in one row, but the cell in the column containing the "<NA>" characters contains several rows.
>>
>> For example: variable_name
>>                         1 <NA>
>>                         2 <NA>
>>                         3 <NA> ...
>> I wonder if I have to collapse all the rows in a single row and eliminate one row.
>>
>> Thank you,
>>
>> Giuseppa Cefalu
>>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
>> Sent: Wednesday, September 29, 2021 3:13 PM
>> To: Kevin Thorpe <kevin.thorpe at utoronto.ca>; Luigi Marongiu <marongiu.luigi at gmail.com>
>> Cc: R Help Mailing List <r-help at r-project.org>
>> Subject: Re: [R] How to install package meta on Linux Ubuntu 21?
>>
>> Hello,
>>
>> The recommended way is to install r-base-dev, you probably only have r-base.
>>
>> sudo apt-get update
>> sudo apt-get install r-base-dev
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 17:53 de 29/09/21, Kevin Thorpe escreveu:
>>> It looks to me like you do not have the development packages installed in Ubuntu. These should be easy to obtain with a suitable apt-get command, but since I am not a primary Ubuntu user, I do not know the package names.
>>>
>>>
>>>> On Sep 29, 2021, at 9:46 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>>>
>>>> Hello
>>>> I have R version 4.1.1 (2021-08-10) -- "Kick Things", on an Ubuntu 21
>>>> machine. I am trying to install the package meta but I get the
>>>> following error:
>>>> ```
>>>> ...
>>>> ERROR: dependency ?RcppEigen? is not available for package ?lme4?
>>>> * removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/lme4?
>>>> Warning in install.packages :
>>>>    installation of package ?lme4? had non-zero exit status
>>>> ERROR: dependency ?lme4? is not available for package ?meta?
>>>> ```
>>>> I tried to install RcppEigen but:
>>>> ```
>>>> ...
>>>> /usr/bin/ld: cannot find -llapack
>>>> /usr/bin/ld: cannot find -lblas
>>>> /usr/bin/ld: cannot find -lgfortran
>>>> collect2: error: ld returned 1 exit status
>>>> make: *** [/usr/share/R/share/make/shlib.mk:10: RcppEigen.so] Error 1
>>>> ERROR: compilation failed for package ?RcppEigen?
>>>> * removing ?/home/gigiux/R/x86_64-pc-linux-gnu-library/4.1/RcppEigen?
>>>> Warning in install.packages :
>>>>    installation of package ?RcppEigen? had non-zero exit status ```
>>>> and lme4 requires RcppEigen.
>>>> I launched
>>>> `$ sudo apt-get install r-cran-rcppeigen` installation successful but
>>>> I got the same error in installing RcppEigen.
>>>> What could be the error?
>>>> --
>>>> Best regards,
>>>> Luigi
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From m|n@h@|| @end|ng |rom um|ch@edu  Thu Sep 30 06:15:47 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Thu, 30 Sep 2021 07:15:47 +0300
Subject: [R] on thread hijacking
Message-ID: <1463908.1632975347@apollo2.minshall.org>

Giuseppe,

Jeff mentioned "thread hijacking".  in case you're not familiar with the
term, you could look here
----
http://www.mutt.org/doc/manual/
----
and search for "hijacking" or "in-reply-to".

basically, afaik, when you want to send e-mail to the *same* list, but
on a *different* topic, you should

- change the subject line (to something appropriate to your new
  subject), and
- remove the "In-reply-to" header from your reply.

for example, in replying to you, i changed the subject line (as you
see), and removed this following in-reply-to header from the e-mail
headers in my reply (my e-mail reader generated this header when i hit
"reply" on your e-mail):

> In-reply-to: Your message of "Wed, 29 Sep 2021 22:24:41 -0400."
>             <008401d7b5a2$53594e10$fa0bea30$@gmail.com>

(probably more than you wanted to know; but ... :)

cheers, Greg


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep 30 15:06:37 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 30 Sep 2021 15:06:37 +0200
Subject: [R] how to combine logic test on vectors in R?
Message-ID: <CAMk+s2TiRXCr1dP1xf6F9fKj7DvGpuMSjrqfpQRBp=N8AAR-xA@mail.gmail.com>

Hello,
I have two data frames, each with three rows:
```
df_a <- data.frame(a = letters[1:3], b = LETTERS[1:3], q = c("", "", ""),
stringsAsFactors = FALSE)
df_b <- data.frame(a = letters[4:6], b = LETTERS[4:6], q = c("", "", "1.5"),
stringsAsFactors = FALSE)
```
I need to test whether the dataframe has been selected and if there is
a value in the q column. I combined in the following test:
```
if (nrow(df_a) == 0 || unique(df_a$q) == "") {
print("empty")
}
if (nrow(df_b) == 0 || unique(df_b$q) == "") {
print("empty")
}
```
The test for df_a worked as expected:
```
> nrow(df_a) == 0
[1] FALSE
> unique(df_a$q) == ""
[1] TRUE
> (nrow(df_a) == 0 || unique(df_a$q) == "")
[1] TRUE
> if (nrow(df_a) == 0 || unique(df_a$q) == "") {
+ print("empty")
+ }
[1] "empty"
```
but the one for df_b did not:
```
> nrow(df_b) == 0
[1] FALSE
> unique(df_b$q) == ""
[1]  TRUE FALSE
> (nrow(df_b) == 0 || unique(df_b$q) == "")
[1] TRUE
> unique(df_b$q)
[1] ""    "1.5"
```
I say that it did not work because unique(df_b$q) IS NOT "", hence
`(nrow(df_b) == 0 || unique(df_b$q) == "")` should be FALSE, instead R
evaluated the first element of unique(df_b$q) == "", which is TRUE.
How can I properly implement a logic test on vectors?
 Thank you


From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Sep 30 16:28:24 2021
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Thu, 30 Sep 2021 10:28:24 -0400
Subject: [R] how to combine logic test on vectors in R?
In-Reply-To: <CAMk+s2TiRXCr1dP1xf6F9fKj7DvGpuMSjrqfpQRBp=N8AAR-xA@mail.gmail.com>
References: <CAMk+s2TiRXCr1dP1xf6F9fKj7DvGpuMSjrqfpQRBp=N8AAR-xA@mail.gmail.com>
Message-ID: <CAM_vjunfBsW94i8N3-b+c5WZ19+XZi-tLMACixyTzmpj006Zyw@mail.gmail.com>

Hi,

The OR operator you used is working as expected: || starts from the
left and evaluates only enough of the options to determine the
results. The first test is TRUE,  so the result is TRUE. It sounds
like you might actually want an AND operator, & or &&, which will only
return TRUE if all elements are TRUE,

More on logical operators:
https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html

Sarah

On Thu, Sep 30, 2021 at 9:07 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have two data frames, each with three rows:
> ```
> df_a <- data.frame(a = letters[1:3], b = LETTERS[1:3], q = c("", "", ""),
> stringsAsFactors = FALSE)
> df_b <- data.frame(a = letters[4:6], b = LETTERS[4:6], q = c("", "", "1.5"),
> stringsAsFactors = FALSE)
> ```
> I need to test whether the dataframe has been selected and if there is
> a value in the q column. I combined in the following test:
> ```
> if (nrow(df_a) == 0 || unique(df_a$q) == "") {
> print("empty")
> }
> if (nrow(df_b) == 0 || unique(df_b$q) == "") {
> print("empty")
> }
> ```
> The test for df_a worked as expected:
> ```
> > nrow(df_a) == 0
> [1] FALSE
> > unique(df_a$q) == ""
> [1] TRUE
> > (nrow(df_a) == 0 || unique(df_a$q) == "")
> [1] TRUE
> > if (nrow(df_a) == 0 || unique(df_a$q) == "") {
> + print("empty")
> + }
> [1] "empty"
> ```
> but the one for df_b did not:
> ```
> > nrow(df_b) == 0
> [1] FALSE
> > unique(df_b$q) == ""
> [1]  TRUE FALSE
> > (nrow(df_b) == 0 || unique(df_b$q) == "")
> [1] TRUE
> > unique(df_b$q)
> [1] ""    "1.5"
> ```
> I say that it did not work because unique(df_b$q) IS NOT "", hence
> `(nrow(df_b) == 0 || unique(df_b$q) == "")` should be FALSE, instead R
> evaluated the first element of unique(df_b$q) == "", which is TRUE.
> How can I properly implement a logic test on vectors?
>  Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep 30 17:51:02 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 30 Sep 2021 17:51:02 +0200
Subject: [R] how to combine logic test on vectors in R?
In-Reply-To: <CAM_vjunfBsW94i8N3-b+c5WZ19+XZi-tLMACixyTzmpj006Zyw@mail.gmail.com>
References: <CAMk+s2TiRXCr1dP1xf6F9fKj7DvGpuMSjrqfpQRBp=N8AAR-xA@mail.gmail.com>
 <CAM_vjunfBsW94i8N3-b+c5WZ19+XZi-tLMACixyTzmpj006Zyw@mail.gmail.com>
Message-ID: <CAMk+s2R-eLK-b1bcHzSmrJCs7H1N9ynA3n6ckZC9mZYd+DgVOw@mail.gmail.com>

Yes, but the && should work within `unique(df_b$q) == ""` because the
test should be: (IF THE DATAFRAME HAS ZERO ROW) OR (ALL THE ELEMENTS
OF $q ARE EMPTY) THEN (PRINT empty).
Can I collapse the TRUE FALSE of `unique(df_b$q) == ""`into a single FALSE?

On Thu, Sep 30, 2021 at 4:28 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:
>
> Hi,
>
> The OR operator you used is working as expected: || starts from the
> left and evaluates only enough of the options to determine the
> results. The first test is TRUE,  so the result is TRUE. It sounds
> like you might actually want an AND operator, & or &&, which will only
> return TRUE if all elements are TRUE,
>
> More on logical operators:
> https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html
>
> Sarah
>
> On Thu, Sep 30, 2021 at 9:07 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I have two data frames, each with three rows:
> > ```
> > df_a <- data.frame(a = letters[1:3], b = LETTERS[1:3], q = c("", "", ""),
> > stringsAsFactors = FALSE)
> > df_b <- data.frame(a = letters[4:6], b = LETTERS[4:6], q = c("", "", "1.5"),
> > stringsAsFactors = FALSE)
> > ```
> > I need to test whether the dataframe has been selected and if there is
> > a value in the q column. I combined in the following test:
> > ```
> > if (nrow(df_a) == 0 || unique(df_a$q) == "") {
> > print("empty")
> > }
> > if (nrow(df_b) == 0 || unique(df_b$q) == "") {
> > print("empty")
> > }
> > ```
> > The test for df_a worked as expected:
> > ```
> > > nrow(df_a) == 0
> > [1] FALSE
> > > unique(df_a$q) == ""
> > [1] TRUE
> > > (nrow(df_a) == 0 || unique(df_a$q) == "")
> > [1] TRUE
> > > if (nrow(df_a) == 0 || unique(df_a$q) == "") {
> > + print("empty")
> > + }
> > [1] "empty"
> > ```
> > but the one for df_b did not:
> > ```
> > > nrow(df_b) == 0
> > [1] FALSE
> > > unique(df_b$q) == ""
> > [1]  TRUE FALSE
> > > (nrow(df_b) == 0 || unique(df_b$q) == "")
> > [1] TRUE
> > > unique(df_b$q)
> > [1] ""    "1.5"
> > ```
> > I say that it did not work because unique(df_b$q) IS NOT "", hence
> > `(nrow(df_b) == 0 || unique(df_b$q) == "")` should be FALSE, instead R
> > evaluated the first element of unique(df_b$q) == "", which is TRUE.
> > How can I properly implement a logic test on vectors?
> >  Thank you
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee (she/her)
> http://www.sarahgoslee.com



-- 
Best regards,
Luigi


From brod|e @end|ng |rom mcw@edu  Thu Sep 30 17:51:01 2021
From: brod|e @end|ng |rom mcw@edu (Brodie, Kent)
Date: Thu, 30 Sep 2021 15:51:01 +0000
Subject: [R] Package installation help: Stuck at "** byte-compile and
 prepare package for lazy loading"
In-Reply-To: <CAFDcVCTd_mhZLEQpqgS0ErHUeSMmOoKt0zLLLm97MnaL0RkhGg@mail.gmail.com>
References: <BL3PR01MB68506C30DB1731B2E39975DCCEA99@BL3PR01MB6850.prod.exchangelabs.com>
 <CAFDcVCTd_mhZLEQpqgS0ErHUeSMmOoKt0zLLLm97MnaL0RkhGg@mail.gmail.com>
Message-ID: <BL3PR01MB6850F588BF86CBD51D40797CCEAA9@BL3PR01MB6850.prod.exchangelabs.com>

(As I said, I'll try anything!)

OK, so I went ahead to get the scl devtoolset, and rebuilt R 4.1.1 with the same exact gcc you used.

But- same result for me.   Hung at the byte-compile step when installing that one package, no error, no messages, no logs.  



> -----Original Message-----
> From: Henrik Bengtsson <henrik.bengtsson at gmail.com>
> Sent: Wednesday, September 29, 2021 9:43 PM
> To: Brodie, Kent <brodie at mcw.edu>
> Cc: r-help at r-project.org
> Subject: Re: [R] Package installation help: Stuck at "** byte-compile and
> prepare package for lazy loading"
> 
> ATTENTION: This email originated from a sender outside of MCW. Use caution
> when clicking on links or opening attachments.
> ________________________________
> 
> I just tried on an up-to-date CentOS 7 with R 4.1.1 built from source using gcc
> 8.3.1 (from SCL devtoolset-8; so not the default gcc 4.8.5), and it works there.
> If of any help, here's the output when installing to user's personal package
> library:
> 

From w||||@mwdun|@p @end|ng |rom gm@||@com  Thu Sep 30 18:00:35 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Thu, 30 Sep 2021 09:00:35 -0700
Subject: [R] Package installation help: Stuck at "** byte-compile and
 prepare package for lazy loading"
In-Reply-To: <CAFDcVCTd_mhZLEQpqgS0ErHUeSMmOoKt0zLLLm97MnaL0RkhGg@mail.gmail.com>
References: <BL3PR01MB68506C30DB1731B2E39975DCCEA99@BL3PR01MB6850.prod.exchangelabs.com>
 <CAFDcVCTd_mhZLEQpqgS0ErHUeSMmOoKt0zLLLm97MnaL0RkhGg@mail.gmail.com>
Message-ID: <CAHqSRuQSBOc9eKA8vXawPM5VFCMqbBQwDrgch0xZ9MGC=M7LVA@mail.gmail.com>

I just tried installing forensim on R-devel/Ubuntu 20.04/WSL-2.0 without an
X server (hence DISPLAY was not set).  Loading tktcl gives a warning that
Tk is not available because DISPLAY is not set.  The installation hung
after the byte-compile message:
installing to
/home/bill/R-devel/R-build/site-library/00LOCK-tkrplot/00new/tkrplot/libs
** R
** byte-compile and prepare package for lazy loading
Warning message:
no DISPLAY variable so Tk is not available
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
Warning: no DISPLAY variable so Tk is not available
Warning: loading Rplot failed
** checking absolute paths in shared objects and dynamic libraries
** testing if installed package can be loaded from final location
Warning: no DISPLAY variable so Tk is not available
Warning: loading Rplot failed
** testing if installed package keeps a record of temporary installation
path
* DONE (tkrplot)
* installing *source* package ?forensim? ...
** package ?forensim? successfully unpacked and MD5 sums checked
** using staged installation
** libs
gcc -I"/home/bill/R-devel/R-build/include" -DNDEBUG   -I/usr/local/include
  -fpic  -g  -c auxilary.c -o auxilary.o
gcc -I"/home/bill/R-devel/R-build/include" -DNDEBUG   -I/usr/local/include
  -fpic  -g  -c recursFinal.c -o recursFinal.o
gcc -shared -L/usr/local/lib -o forensim.so auxilary.o recursFinal.o
installing to
/home/bill/R-devel/R-build/site-library/00LOCK-forensim/00new/forensim/libs
** R
** data
** inst
** byte-compile and prepare package for lazy loading
[hang]

gdb gives a traceback that I think indicates that the package is trying to
plot something via tcltk at this point:

Attaching to process 9310
[New LWP 9315]
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
0x00007fe20a50f560 in ?? () from /usr/lib/x86_64-linux-gnu/libtcl8.6.so
(gdb) where
#0  0x00007fe20a50f560 in ?? () from /usr/lib/x86_64-linux-gnu/libtcl8.6.so
#1  0x00007fe20a50f5f2 in TclNRRunCallbacks () from
/usr/lib/x86_64-linux-gnu/libtcl8.6.so
#2  0x00007fe20a5e4cd9 in Tcl_PkgRequireProc () from
/usr/lib/x86_64-linux-gnu/libtcl8.6.so
#3  0x00007fe20a5e4b06 in Tcl_PkgRequireEx () from
/usr/lib/x86_64-linux-gnu/libtcl8.6.so
#4  0x00007fe20a976be8 in Rplot_Init (interp=0x55ae6437a6c0) at
tcltkimg.c:465
#5  0x00007fe20a5d1ee3 in ?? () from /usr/lib/x86_64-linux-gnu/libtcl8.6.so
#6  0x00007fe20a50f5f2 in TclNRRunCallbacks () from
/usr/lib/x86_64-linux-gnu/libtcl8.6.so
#7  0x00007fe20b04d7f0 in dotTclObjv (args=0x55ae6489d210) at
/mnt/c/R/R-svn/trunk/src/library/tcltk/src/tcltk.c:250
#8  0x000055ae611cd5a8 in do_External (call=0x55ae6440a270,
op=0x55ae61fe1338, args=0x55ae6489d210, env=0x55ae6489d3d0)
    at /mnt/c/R/R-svn/trunk/src/main/dotcode.c:576
#9  0x000055ae6122a0b3 in bcEval (body=0x55ae6440a190, rho=0x55ae6489d3d0,
useCache=TRUE)
    at /mnt/c/R/R-svn/trunk/src/main/eval.c:7128
#10 0x000055ae6121644a in Rf_eval (e=0x55ae6440a190, rho=0x55ae6489d3d0) at
/mnt/c/R/R-svn/trunk/src/main/eval.c:740
#11 0x000055ae61215fda in forcePromise (e=0x55ae6489d398) at
/mnt/c/R/R-svn/trunk/src/main/eval.c:568
#12 0x000055ae61220b80 in FORCE_PROMISE (value=0x55ae6489d398,
symbol=0x55ae62282a08, rho=0x55ae6489d248,
    keepmiss=FALSE) at /mnt/c/R/R-svn/trunk/src/main/eval.c:5149
#13 0x000055ae61220d2f in getvar (symbol=0x55ae62282a08,
rho=0x55ae6489d248, dd=FALSE, keepmiss=FALSE,
    vcache=0x7fe20b2ec1f0, sidx=1) at
/mnt/c/R/R-svn/trunk/src/main/eval.c:5190

Henrik, can you reproduce this if you undefine DISPLAY?

-Bill




On Wed, Sep 29, 2021 at 7:48 PM Henrik Bengtsson <henrik.bengtsson at gmail.com>
wrote:

> I just tried on an up-to-date CentOS 7 with R 4.1.1 built from source
> using gcc 8.3.1 (from SCL devtoolset-8; so not the default gcc 4.8.5),
> and it works there.  If of any help, here's the output when installing
> to user's personal package library:
>
> > chooseCRANmirror(ind = 1)
> > install.packages("forensim")
> Installing package into
> ?/c4/home/henrik/R/x86_64-pc-linux-gnu-library/4.1-CBI-gcc8?
> (as ?lib? is unspecified)
> trying URL 'https://cloud.r-project.org/src/contrib/forensim_4.3.tar.gz'
> Content type 'application/x-gzip' length 84232 bytes (82 KB)
> ==================================================
> downloaded 82 KB
>
> * installing *source* package ?forensim? ...
> ** package ?forensim? successfully unpacked and MD5 sums checked
> ** using staged installation
> ** libs
> gcc -I"/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/include"
> -DNDEBUG   -I/usr/local/include   -fpic  -g -O2  -c auxilary.c -o
> auxilary.o
> gcc -I"/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/include"
> -DNDEBUG   -I/usr/local/include   -fpic  -g -O2  -c recursFinal.c -o
> recursFinal.o
> gcc -shared -L/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/lib
> -L/usr/local/lib64 -o forensim.so auxilary.o recursFinal.o
> -L/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/lib -lR
> installing to
> /c4/home/henrik/R/x86_64-pc-linux-gnu-library/4.1-CBI-gcc8/00LOCK-forensim/00new/forensim/libs
> ** R
> ** data
> ** inst
> ** byte-compile and prepare package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded from temporary location
> ** checking absolute paths in shared objects and dynamic libraries
> ** testing if installed package can be loaded from final location
> ** testing if installed package keeps a record of temporary installation
> path
> * DONE (forensim)
>
> The downloaded source packages are in
>     ?/scratch/henrik/RtmpYFlQyS/downloaded_packages?
>
> You could also try to install it via 'R CMD INSTALL' and try with
> different options disabled to maybe narrow in on what's going on.
>
> My $.02
>
> /Henrik
>
> On Wed, Sep 29, 2021 at 6:37 PM Brodie, Kent via R-help
> <r-help at r-project.org> wrote:
> >
> > Hey everyone!  So, I've been asked by one of our researchers to install
> "all" cran packages on one of our servers.    Yeah, it's a bit much (and
> clearly, not everything will install correctly due to various missing
> tidbits), but it will go a long way to having to constantly respond to
> install requests of various packages.  OK, fine.
> >
> > Anyway, I have tried this, and things proceed nicely for several hours
> until the process gets completely and absolutely stuck.   I have tried
> several things, for example trying newer versions of R, and even repeating
> the process on a CentOS 8 server instead of where my stuff is now (CentOS
> 7).
> >
> > While re-trying one of my newer attempts at this, I decided to focus on
> the very first place where it hangs.   It dies on package "forensim".
> It's a slightly older package, and I don't see anything particularly
> special about it.    The text below is where it hangs.    The install "R"
> process doing this is whizzing at 100%,  but no progress, no output, no
> errors.  Nothing in the system logs.
> >
> > On new "R" installs, with either operating system (CentOS 7, CentOS 8)
> and even different versions of "R" (up to including 4.1.1), I get the same
> result when just attempting to install this ONE package.    (and my guess,
> there's more packages out there that may bite me the same way).
> >
> > I am seeking any recommendations on how I can get past this?   A debug
> option?  A timeout of sorts so things will  move along to the next package
> when attempting to install a ton, or...?   I'm of course willing to try
> anything.   It's stupidly frustrating.    I'd be OK if it errored out and
> moved on.   But it...  hangs.
> >
> > Here's the latter part of the install attempt of this one package.
>  This latest attempt has been stuck on that last line now for 5 hours and
> counting.
> >
> > * DONE (tkrplot)
> > Making 'packages.html' ... done
> > * installing *source* package 'forensim' ...
> > ** package 'forensim' successfully unpacked and MD5 sums checked
> > ** using staged installation
> > ** libs
> > gcc -m64 -I"/usr/include/R" -DNDEBUG   -I/usr/local/include   -fpic  -O2
> -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2
> -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong
> -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
> -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
> -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection  -c
> auxilary.c -o auxilary.o
> > gcc -m64 -I"/usr/include/R" -DNDEBUG   -I/usr/local/include   -fpic  -O2
> -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2
> -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong
> -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
> -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
> -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection  -c
> recursFinal.c -o recursFinal.o
> > gcc -m64 -shared -L/usr/lib64/R/lib -Wl,-z,relro -Wl,-z,now
> -specs=/usr/lib/rpm/redhat/redhat-hardened-ld -o forensim.so auxilary.o
> recursFinal.o -L/usr/lib64/R/lib -lR
> > installing to /usr/lib64/R/library/00LOCK-forensim/00new/forensim/libs
> > ** R
> > ** data
> > ** inst
> > ** byte-compile and prepare package for lazy loading
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep 30 18:14:08 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 30 Sep 2021 09:14:08 -0700
Subject: [R] how to combine logic test on vectors in R?
In-Reply-To: <CAMk+s2R-eLK-b1bcHzSmrJCs7H1N9ynA3n6ckZC9mZYd+DgVOw@mail.gmail.com>
References: <CAMk+s2TiRXCr1dP1xf6F9fKj7DvGpuMSjrqfpQRBp=N8AAR-xA@mail.gmail.com>
 <CAM_vjunfBsW94i8N3-b+c5WZ19+XZi-tLMACixyTzmpj006Zyw@mail.gmail.com>
 <CAMk+s2R-eLK-b1bcHzSmrJCs7H1N9ynA3n6ckZC9mZYd+DgVOw@mail.gmail.com>
Message-ID: <C85D1CF9-A49D-40D5-A3BB-2E0734043B14@dcn.davis.ca.us>

No it shouldn't work. unique returns zero or more results so == with a constant will be a logical vector zero or more elements long, which is inappropriate for &&. Use the any function perhaps.

On September 30, 2021 8:51:02 AM PDT, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>Yes, but the && should work within `unique(df_b$q) == ""` because the
>test should be: (IF THE DATAFRAME HAS ZERO ROW) OR (ALL THE ELEMENTS
>OF $q ARE EMPTY) THEN (PRINT empty).
>Can I collapse the TRUE FALSE of `unique(df_b$q) == ""`into a single FALSE?
>
>On Thu, Sep 30, 2021 at 4:28 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> Hi,
>>
>> The OR operator you used is working as expected: || starts from the
>> left and evaluates only enough of the options to determine the
>> results. The first test is TRUE,  so the result is TRUE. It sounds
>> like you might actually want an AND operator, & or &&, which will only
>> return TRUE if all elements are TRUE,
>>
>> More on logical operators:
>> https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html
>>
>> Sarah
>>
>> On Thu, Sep 30, 2021 at 9:07 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> >
>> > Hello,
>> > I have two data frames, each with three rows:
>> > ```
>> > df_a <- data.frame(a = letters[1:3], b = LETTERS[1:3], q = c("", "", ""),
>> > stringsAsFactors = FALSE)
>> > df_b <- data.frame(a = letters[4:6], b = LETTERS[4:6], q = c("", "", "1.5"),
>> > stringsAsFactors = FALSE)
>> > ```
>> > I need to test whether the dataframe has been selected and if there is
>> > a value in the q column. I combined in the following test:
>> > ```
>> > if (nrow(df_a) == 0 || unique(df_a$q) == "") {
>> > print("empty")
>> > }
>> > if (nrow(df_b) == 0 || unique(df_b$q) == "") {
>> > print("empty")
>> > }
>> > ```
>> > The test for df_a worked as expected:
>> > ```
>> > > nrow(df_a) == 0
>> > [1] FALSE
>> > > unique(df_a$q) == ""
>> > [1] TRUE
>> > > (nrow(df_a) == 0 || unique(df_a$q) == "")
>> > [1] TRUE
>> > > if (nrow(df_a) == 0 || unique(df_a$q) == "") {
>> > + print("empty")
>> > + }
>> > [1] "empty"
>> > ```
>> > but the one for df_b did not:
>> > ```
>> > > nrow(df_b) == 0
>> > [1] FALSE
>> > > unique(df_b$q) == ""
>> > [1]  TRUE FALSE
>> > > (nrow(df_b) == 0 || unique(df_b$q) == "")
>> > [1] TRUE
>> > > unique(df_b$q)
>> > [1] ""    "1.5"
>> > ```
>> > I say that it did not work because unique(df_b$q) IS NOT "", hence
>> > `(nrow(df_b) == 0 || unique(df_b$q) == "")` should be FALSE, instead R
>> > evaluated the first element of unique(df_b$q) == "", which is TRUE.
>> > How can I properly implement a logic test on vectors?
>> >  Thank you
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Sarah Goslee (she/her)
>> http://www.sarahgoslee.com
>
>
>

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep 30 18:19:12 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 30 Sep 2021 09:19:12 -0700
Subject: [R] how to combine logic test on vectors in R?
In-Reply-To: <CAMk+s2R-eLK-b1bcHzSmrJCs7H1N9ynA3n6ckZC9mZYd+DgVOw@mail.gmail.com>
References: <CAMk+s2TiRXCr1dP1xf6F9fKj7DvGpuMSjrqfpQRBp=N8AAR-xA@mail.gmail.com>
 <CAM_vjunfBsW94i8N3-b+c5WZ19+XZi-tLMACixyTzmpj006Zyw@mail.gmail.com>
 <CAMk+s2R-eLK-b1bcHzSmrJCs7H1N9ynA3n6ckZC9mZYd+DgVOw@mail.gmail.com>
Message-ID: <CAGxFJbSY2gjSGfmMYVxR5qn8dAyLnH57hDUdKjW_wa++Gj5CtA@mail.gmail.com>

I haven't followed this thread closely, but to your question I think
maybe this is what you want"

> z <- c("","")
> all(z == "")
[1] TRUE
> z <- c("a","")
> all(z == "")
[1] FALSE

If this isn't it, just ignore without reply.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 30, 2021 at 8:51 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Yes, but the && should work within `unique(df_b$q) == ""` because the
> test should be: (IF THE DATAFRAME HAS ZERO ROW) OR (ALL THE ELEMENTS
> OF $q ARE EMPTY) THEN (PRINT empty).
> Can I collapse the TRUE FALSE of `unique(df_b$q) == ""`into a single FALSE?
>
> On Thu, Sep 30, 2021 at 4:28 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:
> >
> > Hi,
> >
> > The OR operator you used is working as expected: || starts from the
> > left and evaluates only enough of the options to determine the
> > results. The first test is TRUE,  so the result is TRUE. It sounds
> > like you might actually want an AND operator, & or &&, which will only
> > return TRUE if all elements are TRUE,
> >
> > More on logical operators:
> > https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html
> >
> > Sarah
> >
> > On Thu, Sep 30, 2021 at 9:07 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Hello,
> > > I have two data frames, each with three rows:
> > > ```
> > > df_a <- data.frame(a = letters[1:3], b = LETTERS[1:3], q = c("", "", ""),
> > > stringsAsFactors = FALSE)
> > > df_b <- data.frame(a = letters[4:6], b = LETTERS[4:6], q = c("", "", "1.5"),
> > > stringsAsFactors = FALSE)
> > > ```
> > > I need to test whether the dataframe has been selected and if there is
> > > a value in the q column. I combined in the following test:
> > > ```
> > > if (nrow(df_a) == 0 || unique(df_a$q) == "") {
> > > print("empty")
> > > }
> > > if (nrow(df_b) == 0 || unique(df_b$q) == "") {
> > > print("empty")
> > > }
> > > ```
> > > The test for df_a worked as expected:
> > > ```
> > > > nrow(df_a) == 0
> > > [1] FALSE
> > > > unique(df_a$q) == ""
> > > [1] TRUE
> > > > (nrow(df_a) == 0 || unique(df_a$q) == "")
> > > [1] TRUE
> > > > if (nrow(df_a) == 0 || unique(df_a$q) == "") {
> > > + print("empty")
> > > + }
> > > [1] "empty"
> > > ```
> > > but the one for df_b did not:
> > > ```
> > > > nrow(df_b) == 0
> > > [1] FALSE
> > > > unique(df_b$q) == ""
> > > [1]  TRUE FALSE
> > > > (nrow(df_b) == 0 || unique(df_b$q) == "")
> > > [1] TRUE
> > > > unique(df_b$q)
> > > [1] ""    "1.5"
> > > ```
> > > I say that it did not work because unique(df_b$q) IS NOT "", hence
> > > `(nrow(df_b) == 0 || unique(df_b$q) == "")` should be FALSE, instead R
> > > evaluated the first element of unique(df_b$q) == "", which is TRUE.
> > > How can I properly implement a logic test on vectors?
> > >  Thank you
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Sarah Goslee (she/her)
> > http://www.sarahgoslee.com
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Thu Sep 30 18:23:45 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 30 Sep 2021 19:23:45 +0300
Subject: [R] how to combine logic test on vectors in R?
In-Reply-To: <CAGxFJbSY2gjSGfmMYVxR5qn8dAyLnH57hDUdKjW_wa++Gj5CtA@mail.gmail.com>
References: <CAMk+s2TiRXCr1dP1xf6F9fKj7DvGpuMSjrqfpQRBp=N8AAR-xA@mail.gmail.com>
 <CAM_vjunfBsW94i8N3-b+c5WZ19+XZi-tLMACixyTzmpj006Zyw@mail.gmail.com>
 <CAMk+s2R-eLK-b1bcHzSmrJCs7H1N9ynA3n6ckZC9mZYd+DgVOw@mail.gmail.com>
 <CAGxFJbSY2gjSGfmMYVxR5qn8dAyLnH57hDUdKjW_wa++Gj5CtA@mail.gmail.com>
Message-ID: <CAGgJW77WETWGALN_t3N8NoXFxMrKo5tsCDXPNWWHEROMw=8yAw@mail.gmail.com>

Alternatively you can modify the test as follows:

length(unique(df_b$q)) == 1



On Thu, Sep 30, 2021 at 7:22 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I haven't followed this thread closely, but to your question I think
> maybe this is what you want"
>
> > z <- c("","")
> > all(z == "")
> [1] TRUE
> > z <- c("a","")
> > all(z == "")
> [1] FALSE
>
> If this isn't it, just ignore without reply.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Sep 30, 2021 at 8:51 AM Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> >
> > Yes, but the && should work within `unique(df_b$q) == ""` because the
> > test should be: (IF THE DATAFRAME HAS ZERO ROW) OR (ALL THE ELEMENTS
> > OF $q ARE EMPTY) THEN (PRINT empty).
> > Can I collapse the TRUE FALSE of `unique(df_b$q) == ""`into a single
> FALSE?
> >
> > On Thu, Sep 30, 2021 at 4:28 PM Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
> > >
> > > Hi,
> > >
> > > The OR operator you used is working as expected: || starts from the
> > > left and evaluates only enough of the options to determine the
> > > results. The first test is TRUE,  so the result is TRUE. It sounds
> > > like you might actually want an AND operator, & or &&, which will only
> > > return TRUE if all elements are TRUE,
> > >
> > > More on logical operators:
> > > https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html
> > >
> > > Sarah
> > >
> > > On Thu, Sep 30, 2021 at 9:07 AM Luigi Marongiu <
> marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Hello,
> > > > I have two data frames, each with three rows:
> > > > ```
> > > > df_a <- data.frame(a = letters[1:3], b = LETTERS[1:3], q = c("", "",
> ""),
> > > > stringsAsFactors = FALSE)
> > > > df_b <- data.frame(a = letters[4:6], b = LETTERS[4:6], q = c("", "",
> "1.5"),
> > > > stringsAsFactors = FALSE)
> > > > ```
> > > > I need to test whether the dataframe has been selected and if there
> is
> > > > a value in the q column. I combined in the following test:
> > > > ```
> > > > if (nrow(df_a) == 0 || unique(df_a$q) == "") {
> > > > print("empty")
> > > > }
> > > > if (nrow(df_b) == 0 || unique(df_b$q) == "") {
> > > > print("empty")
> > > > }
> > > > ```
> > > > The test for df_a worked as expected:
> > > > ```
> > > > > nrow(df_a) == 0
> > > > [1] FALSE
> > > > > unique(df_a$q) == ""
> > > > [1] TRUE
> > > > > (nrow(df_a) == 0 || unique(df_a$q) == "")
> > > > [1] TRUE
> > > > > if (nrow(df_a) == 0 || unique(df_a$q) == "") {
> > > > + print("empty")
> > > > + }
> > > > [1] "empty"
> > > > ```
> > > > but the one for df_b did not:
> > > > ```
> > > > > nrow(df_b) == 0
> > > > [1] FALSE
> > > > > unique(df_b$q) == ""
> > > > [1]  TRUE FALSE
> > > > > (nrow(df_b) == 0 || unique(df_b$q) == "")
> > > > [1] TRUE
> > > > > unique(df_b$q)
> > > > [1] ""    "1.5"
> > > > ```
> > > > I say that it did not work because unique(df_b$q) IS NOT "", hence
> > > > `(nrow(df_b) == 0 || unique(df_b$q) == "")` should be FALSE, instead
> R
> > > > evaluated the first element of unique(df_b$q) == "", which is TRUE.
> > > > How can I properly implement a logic test on vectors?
> > > >  Thank you
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Sarah Goslee (she/her)
> > > http://www.sarahgoslee.com
> >
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep 30 18:29:20 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 30 Sep 2021 09:29:20 -0700
Subject: [R] Package installation help: Stuck at "** byte-compile and
 prepare package for lazy loading"
In-Reply-To: <CAHqSRuQSBOc9eKA8vXawPM5VFCMqbBQwDrgch0xZ9MGC=M7LVA@mail.gmail.com>
References: <BL3PR01MB68506C30DB1731B2E39975DCCEA99@BL3PR01MB6850.prod.exchangelabs.com>
 <CAFDcVCTd_mhZLEQpqgS0ErHUeSMmOoKt0zLLLm97MnaL0RkhGg@mail.gmail.com>
 <CAHqSRuQSBOc9eKA8vXawPM5VFCMqbBQwDrgch0xZ9MGC=M7LVA@mail.gmail.com>
Message-ID: <FCF4375E-1692-4FC4-97EA-D044A44C8C29@dcn.davis.ca.us>

This is a microcosm of why installing "all CRAN" packages is a bad idea. Now extend this to the other 5% of 16000+ packages that will have unclear requirements, and when you have all those installed try to update just one of the packages because one of your users has learned of a bug in that package and the cascade starts again. Then listen as another user complains that one of the dependencies updated in the first update broke something they were working on.

User libraries. Project libraries (with renv). Do anything to go as fast as possible in the opposite direction from the concept presumed by this task... "universal usability". Or go help with CRAN because you are just the kind of selfless masochist that they need to keep it going and you will need a team to keep up with it. (Obligatory thanks extended here to the CRAN team.)

On September 30, 2021 9:00:35 AM PDT, Bill Dunlap <williamwdunlap at gmail.com> wrote:
>I just tried installing forensim on R-devel/Ubuntu 20.04/WSL-2.0 without an
>X server (hence DISPLAY was not set).  Loading tktcl gives a warning that
>Tk is not available because DISPLAY is not set.  The installation hung
>after the byte-compile message:
>installing to
>/home/bill/R-devel/R-build/site-library/00LOCK-tkrplot/00new/tkrplot/libs
>** R
>** byte-compile and prepare package for lazy loading
>Warning message:
>no DISPLAY variable so Tk is not available
>** help
>*** installing help indices
>** building package indices
>** testing if installed package can be loaded from temporary location
>Warning: no DISPLAY variable so Tk is not available
>Warning: loading Rplot failed
>** checking absolute paths in shared objects and dynamic libraries
>** testing if installed package can be loaded from final location
>Warning: no DISPLAY variable so Tk is not available
>Warning: loading Rplot failed
>** testing if installed package keeps a record of temporary installation
>path
>* DONE (tkrplot)
>* installing *source* package ?forensim? ...
>** package ?forensim? successfully unpacked and MD5 sums checked
>** using staged installation
>** libs
>gcc -I"/home/bill/R-devel/R-build/include" -DNDEBUG   -I/usr/local/include
>  -fpic  -g  -c auxilary.c -o auxilary.o
>gcc -I"/home/bill/R-devel/R-build/include" -DNDEBUG   -I/usr/local/include
>  -fpic  -g  -c recursFinal.c -o recursFinal.o
>gcc -shared -L/usr/local/lib -o forensim.so auxilary.o recursFinal.o
>installing to
>/home/bill/R-devel/R-build/site-library/00LOCK-forensim/00new/forensim/libs
>** R
>** data
>** inst
>** byte-compile and prepare package for lazy loading
>[hang]
>
>gdb gives a traceback that I think indicates that the package is trying to
>plot something via tcltk at this point:
>
>Attaching to process 9310
>[New LWP 9315]
>[Thread debugging using libthread_db enabled]
>Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
>0x00007fe20a50f560 in ?? () from /usr/lib/x86_64-linux-gnu/libtcl8.6.so
>(gdb) where
>#0  0x00007fe20a50f560 in ?? () from /usr/lib/x86_64-linux-gnu/libtcl8.6.so
>#1  0x00007fe20a50f5f2 in TclNRRunCallbacks () from
>/usr/lib/x86_64-linux-gnu/libtcl8.6.so
>#2  0x00007fe20a5e4cd9 in Tcl_PkgRequireProc () from
>/usr/lib/x86_64-linux-gnu/libtcl8.6.so
>#3  0x00007fe20a5e4b06 in Tcl_PkgRequireEx () from
>/usr/lib/x86_64-linux-gnu/libtcl8.6.so
>#4  0x00007fe20a976be8 in Rplot_Init (interp=0x55ae6437a6c0) at
>tcltkimg.c:465
>#5  0x00007fe20a5d1ee3 in ?? () from /usr/lib/x86_64-linux-gnu/libtcl8.6.so
>#6  0x00007fe20a50f5f2 in TclNRRunCallbacks () from
>/usr/lib/x86_64-linux-gnu/libtcl8.6.so
>#7  0x00007fe20b04d7f0 in dotTclObjv (args=0x55ae6489d210) at
>/mnt/c/R/R-svn/trunk/src/library/tcltk/src/tcltk.c:250
>#8  0x000055ae611cd5a8 in do_External (call=0x55ae6440a270,
>op=0x55ae61fe1338, args=0x55ae6489d210, env=0x55ae6489d3d0)
>    at /mnt/c/R/R-svn/trunk/src/main/dotcode.c:576
>#9  0x000055ae6122a0b3 in bcEval (body=0x55ae6440a190, rho=0x55ae6489d3d0,
>useCache=TRUE)
>    at /mnt/c/R/R-svn/trunk/src/main/eval.c:7128
>#10 0x000055ae6121644a in Rf_eval (e=0x55ae6440a190, rho=0x55ae6489d3d0) at
>/mnt/c/R/R-svn/trunk/src/main/eval.c:740
>#11 0x000055ae61215fda in forcePromise (e=0x55ae6489d398) at
>/mnt/c/R/R-svn/trunk/src/main/eval.c:568
>#12 0x000055ae61220b80 in FORCE_PROMISE (value=0x55ae6489d398,
>symbol=0x55ae62282a08, rho=0x55ae6489d248,
>    keepmiss=FALSE) at /mnt/c/R/R-svn/trunk/src/main/eval.c:5149
>#13 0x000055ae61220d2f in getvar (symbol=0x55ae62282a08,
>rho=0x55ae6489d248, dd=FALSE, keepmiss=FALSE,
>    vcache=0x7fe20b2ec1f0, sidx=1) at
>/mnt/c/R/R-svn/trunk/src/main/eval.c:5190
>
>Henrik, can you reproduce this if you undefine DISPLAY?
>
>-Bill
>
>
>
>
>On Wed, Sep 29, 2021 at 7:48 PM Henrik Bengtsson <henrik.bengtsson at gmail.com>
>wrote:
>
>> I just tried on an up-to-date CentOS 7 with R 4.1.1 built from source
>> using gcc 8.3.1 (from SCL devtoolset-8; so not the default gcc 4.8.5),
>> and it works there.  If of any help, here's the output when installing
>> to user's personal package library:
>>
>> > chooseCRANmirror(ind = 1)
>> > install.packages("forensim")
>> Installing package into
>> ?/c4/home/henrik/R/x86_64-pc-linux-gnu-library/4.1-CBI-gcc8?
>> (as ?lib? is unspecified)
>> trying URL 'https://cloud.r-project.org/src/contrib/forensim_4.3.tar.gz'
>> Content type 'application/x-gzip' length 84232 bytes (82 KB)
>> ==================================================
>> downloaded 82 KB
>>
>> * installing *source* package ?forensim? ...
>> ** package ?forensim? successfully unpacked and MD5 sums checked
>> ** using staged installation
>> ** libs
>> gcc -I"/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/include"
>> -DNDEBUG   -I/usr/local/include   -fpic  -g -O2  -c auxilary.c -o
>> auxilary.o
>> gcc -I"/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/include"
>> -DNDEBUG   -I/usr/local/include   -fpic  -g -O2  -c recursFinal.c -o
>> recursFinal.o
>> gcc -shared -L/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/lib
>> -L/usr/local/lib64 -o forensim.so auxilary.o recursFinal.o
>> -L/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/lib -lR
>> installing to
>> /c4/home/henrik/R/x86_64-pc-linux-gnu-library/4.1-CBI-gcc8/00LOCK-forensim/00new/forensim/libs
>> ** R
>> ** data
>> ** inst
>> ** byte-compile and prepare package for lazy loading
>> ** help
>> *** installing help indices
>> ** building package indices
>> ** testing if installed package can be loaded from temporary location
>> ** checking absolute paths in shared objects and dynamic libraries
>> ** testing if installed package can be loaded from final location
>> ** testing if installed package keeps a record of temporary installation
>> path
>> * DONE (forensim)
>>
>> The downloaded source packages are in
>>     ?/scratch/henrik/RtmpYFlQyS/downloaded_packages?
>>
>> You could also try to install it via 'R CMD INSTALL' and try with
>> different options disabled to maybe narrow in on what's going on.
>>
>> My $.02
>>
>> /Henrik
>>
>> On Wed, Sep 29, 2021 at 6:37 PM Brodie, Kent via R-help
>> <r-help at r-project.org> wrote:
>> >
>> > Hey everyone!  So, I've been asked by one of our researchers to install
>> "all" cran packages on one of our servers.    Yeah, it's a bit much (and
>> clearly, not everything will install correctly due to various missing
>> tidbits), but it will go a long way to having to constantly respond to
>> install requests of various packages.  OK, fine.
>> >
>> > Anyway, I have tried this, and things proceed nicely for several hours
>> until the process gets completely and absolutely stuck.   I have tried
>> several things, for example trying newer versions of R, and even repeating
>> the process on a CentOS 8 server instead of where my stuff is now (CentOS
>> 7).
>> >
>> > While re-trying one of my newer attempts at this, I decided to focus on
>> the very first place where it hangs.   It dies on package "forensim".
>> It's a slightly older package, and I don't see anything particularly
>> special about it.    The text below is where it hangs.    The install "R"
>> process doing this is whizzing at 100%,  but no progress, no output, no
>> errors.  Nothing in the system logs.
>> >
>> > On new "R" installs, with either operating system (CentOS 7, CentOS 8)
>> and even different versions of "R" (up to including 4.1.1), I get the same
>> result when just attempting to install this ONE package.    (and my guess,
>> there's more packages out there that may bite me the same way).
>> >
>> > I am seeking any recommendations on how I can get past this?   A debug
>> option?  A timeout of sorts so things will  move along to the next package
>> when attempting to install a ton, or...?   I'm of course willing to try
>> anything.   It's stupidly frustrating.    I'd be OK if it errored out and
>> moved on.   But it...  hangs.
>> >
>> > Here's the latter part of the install attempt of this one package.
>>  This latest attempt has been stuck on that last line now for 5 hours and
>> counting.
>> >
>> > * DONE (tkrplot)
>> > Making 'packages.html' ... done
>> > * installing *source* package 'forensim' ...
>> > ** package 'forensim' successfully unpacked and MD5 sums checked
>> > ** using staged installation
>> > ** libs
>> > gcc -m64 -I"/usr/include/R" -DNDEBUG   -I/usr/local/include   -fpic  -O2
>> -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2
>> -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong
>> -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
>> -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
>> -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection  -c
>> auxilary.c -o auxilary.o
>> > gcc -m64 -I"/usr/include/R" -DNDEBUG   -I/usr/local/include   -fpic  -O2
>> -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2
>> -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong
>> -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
>> -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
>> -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection  -c
>> recursFinal.c -o recursFinal.o
>> > gcc -m64 -shared -L/usr/lib64/R/lib -Wl,-z,relro -Wl,-z,now
>> -specs=/usr/lib/rpm/redhat/redhat-hardened-ld -o forensim.so auxilary.o
>> recursFinal.o -L/usr/lib64/R/lib -lR
>> > installing to /usr/lib64/R/library/00LOCK-forensim/00new/forensim/libs
>> > ** R
>> > ** data
>> > ** inst
>> > ** byte-compile and prepare package for lazy loading
>> >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From brod|e @end|ng |rom mcw@edu  Thu Sep 30 18:35:51 2021
From: brod|e @end|ng |rom mcw@edu (Brodie, Kent)
Date: Thu, 30 Sep 2021 16:35:51 +0000
Subject: [R] Package installation help: Stuck at "** byte-compile and
 prepare package for lazy loading"
In-Reply-To: <CAHqSRuQSBOc9eKA8vXawPM5VFCMqbBQwDrgch0xZ9MGC=M7LVA@mail.gmail.com>
References: <BL3PR01MB68506C30DB1731B2E39975DCCEA99@BL3PR01MB6850.prod.exchangelabs.com>
 <CAFDcVCTd_mhZLEQpqgS0ErHUeSMmOoKt0zLLLm97MnaL0RkhGg@mail.gmail.com>
 <CAHqSRuQSBOc9eKA8vXawPM5VFCMqbBQwDrgch0xZ9MGC=M7LVA@mail.gmail.com>
Message-ID: <BL3PR01MB6850E91579F3B438EC83367DCEAA9@BL3PR01MB6850.prod.exchangelabs.com>

Bill--   BINGO.    You have found the answer.     After some testing on one of my environments where it was always hanging, connecting to the same server with an X-Sever running on my workstation did indeed allow the package to be installed.

**GOOD LORD THAT?S RIDICULOUS**   But---- at least I know.    And why it doesn?t error out without X running, who knows.

After a ton more research, I ALSO discovered that there IS a timeout thing I can make use of, should I decide to continue just building things and ignoring the X-Server requirement for this (and probably some other?) packages.

Before executing R and installing things, set this:

export _R_INSTALL_PACKAGES_ELAPSED_TIMEOUT_=500

(value is seconds).   So, the previously-hanging R CMD INSTALL inside of the install.packages call will eventually die, and then move on to the next package.
This is buried in the documentation but- it?s there and I confirmed it works.    My example above times out a package install  at 5 minutes.

While knowing the X requirement is a huge win (thanks again!), I will probably stick with just using the timeout thing for what I?m trying to accomplish.    Installing EVERYTHING from cran will take forever, and more than likely my VPN connection to my data center will be disconnected (thank you internal IT department) before it finishes.    They have some sort of internal ?you?ve been connected too long? timer that disconnects things overnight.   Grr.


	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Thu Sep 30 18:36:37 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Thu, 30 Sep 2021 09:36:37 -0700
Subject: [R] Package installation help: Stuck at "** byte-compile and
 prepare package for lazy loading"
In-Reply-To: <CAHqSRuQSBOc9eKA8vXawPM5VFCMqbBQwDrgch0xZ9MGC=M7LVA@mail.gmail.com>
References: <BL3PR01MB68506C30DB1731B2E39975DCCEA99@BL3PR01MB6850.prod.exchangelabs.com>
 <CAFDcVCTd_mhZLEQpqgS0ErHUeSMmOoKt0zLLLm97MnaL0RkhGg@mail.gmail.com>
 <CAHqSRuQSBOc9eKA8vXawPM5VFCMqbBQwDrgch0xZ9MGC=M7LVA@mail.gmail.com>
Message-ID: <CAHqSRuRH=a=c3QZor9syJhAL_aT=fbHVebS_G5=vbCULPBDogA@mail.gmail.com>

I tried this a second time, but with --no-byte-compile, and it hung with a
slightly different traceback

(gdb) where
#0  0x00007f95bc4c6689 in __fxstat64 () from
/usr/lib/x86_64-linux-gnu/libc.so.6
#1  0x00007f95bc497050 in opendir () from
/usr/lib/x86_64-linux-gnu/libc.so.6
#2  0x00007f95b935f1e0 in ?? () from /usr/lib/x86_64-linux-gnu/libtcl8.6.so
#3  0x00007f95b9311242 in Tcl_FSMatchInDirectory () from
/usr/lib/x86_64-linux-gnu/libtcl8.6.so
#4  0x00007f95b92f3e2b in ?? () from /usr/lib/x86_64-linux-gnu/libtcl8.6.so
#5  0x00007f95b92f34c5 in ?? () from /usr/lib/x86_64-linux-gnu/libtcl8.6.so
#6  0x00007f95b92f29d8 in ?? () from /usr/lib/x86_64-linux-gnu/libtcl8.6.so
#7  0x00007f95b92565f2 in TclNRRunCallbacks () from
/usr/lib/x86_64-linux-gnu/libtcl8.6.so
#8  0x00007f95b932bcd9 in Tcl_PkgRequireProc () from
/usr/lib/x86_64-linux-gnu/libtcl8.6.so
#9  0x00007f95b932bb06 in Tcl_PkgRequireEx () from
/usr/lib/x86_64-linux-gnu/libtcl8.6.so
#10 0x00007f95b96bdbe8 in Rplot_Init (interp=0x5625117460d0) at
tcltkimg.c:465

and when I killed the R subprocess doing the lazyload prep I got a
quasi-infinite stream of error messages:

...
error reading package index file
/home/bill/R-devel/R-build/site-library/tcltk2/tklibs/ttktheme_aquablue/pkgIndex.tcl:
too many nested evaluations (infinite loop?)
error reading package index file
/home/bill/R-devel/R-build/site-library/tcltk2/tklibs/ttktheme_radiance/pkgIndex.tcl:
too many nested evaluations (infinite loop?)
error reading package index file
/home/bill/R-devel/R-build/site-library/tcltk2/tklibs/ttktheme_clearlooks/pkgIndex.tcl:
too many nested evaluations (infinite loop?)
error reading package index file
/home/bill/R-devel/R-build/site-library/tcltk2/tklibs/ttktheme_radiance/pkgIndex.tcl:
can't find package tile
error reading package index file
/home/bill/R-devel/R-build/site-library/tcltk2/tklibs/ttktheme_aquablue/pkgIndex.tcl:
too many nested evaluations (infinite loop?)
error reading package index file
/home/bill/R-devel/R-build/site-library/tcltk2/tklibs/ttktheme_radiance/pkgIndex.tcl:
too many nested evaluations (infinite loop?)
error reading package index file
/home/bill/R-devel/R-build/site-library/tcltk2/tklibs/ttktheme_clearlooks/pkgIndex.tcl:
too many nested evaluations (infinite loop?)
error reading package index file
/home/bill/R-devel/R-build/site-library/tcltk2/tklibs/ttktheme_clearlooks/pkgIndex.tcl:
can't find package tile
error reading package index file
/home/bill/R-devel/R-build/site-library/tcltk2/tklibs/ttktheme_clearlooks/pkgIndex.tcl:
can't find package tile
error reading package index file
/home/bill/R-devel/R-build/site-library/tcltk2/tklibs/ttktheme_clearlooks/pkgIndex.tcl:
can't find package tile
error reading package index file
/home/bill/R-devel/R-build/site-library/tcltk2/tklibs/ttktheme_radiance/pkgIndex.tcl:
can't find package tile
...

-Bill


On Thu, Sep 30, 2021 at 9:00 AM Bill Dunlap <williamwdunlap at gmail.com>
wrote:

> I just tried installing forensim on R-devel/Ubuntu 20.04/WSL-2.0 without
> an X server (hence DISPLAY was not set).  Loading tktcl gives a warning
> that Tk is not available because DISPLAY is not set.  The installation hung
> after the byte-compile message:
> installing to
> /home/bill/R-devel/R-build/site-library/00LOCK-tkrplot/00new/tkrplot/libs
> ** R
> ** byte-compile and prepare package for lazy loading
> Warning message:
> no DISPLAY variable so Tk is not available
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded from temporary location
> Warning: no DISPLAY variable so Tk is not available
> Warning: loading Rplot failed
> ** checking absolute paths in shared objects and dynamic libraries
> ** testing if installed package can be loaded from final location
> Warning: no DISPLAY variable so Tk is not available
> Warning: loading Rplot failed
> ** testing if installed package keeps a record of temporary installation
> path
> * DONE (tkrplot)
> * installing *source* package ?forensim? ...
> ** package ?forensim? successfully unpacked and MD5 sums checked
> ** using staged installation
> ** libs
> gcc -I"/home/bill/R-devel/R-build/include" -DNDEBUG   -I/usr/local/include
>   -fpic  -g  -c auxilary.c -o auxilary.o
> gcc -I"/home/bill/R-devel/R-build/include" -DNDEBUG   -I/usr/local/include
>   -fpic  -g  -c recursFinal.c -o recursFinal.o
> gcc -shared -L/usr/local/lib -o forensim.so auxilary.o recursFinal.o
> installing to
> /home/bill/R-devel/R-build/site-library/00LOCK-forensim/00new/forensim/libs
> ** R
> ** data
> ** inst
> ** byte-compile and prepare package for lazy loading
> [hang]
>
> gdb gives a traceback that I think indicates that the package is trying to
> plot something via tcltk at this point:
>
> Attaching to process 9310
> [New LWP 9315]
> [Thread debugging using libthread_db enabled]
> Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
> 0x00007fe20a50f560 in ?? () from /usr/lib/x86_64-linux-gnu/libtcl8.6.so
> (gdb) where
> #0  0x00007fe20a50f560 in ?? () from /usr/lib/x86_64-linux-gnu/
> libtcl8.6.so
> #1  0x00007fe20a50f5f2 in TclNRRunCallbacks () from
> /usr/lib/x86_64-linux-gnu/libtcl8.6.so
> #2  0x00007fe20a5e4cd9 in Tcl_PkgRequireProc () from
> /usr/lib/x86_64-linux-gnu/libtcl8.6.so
> #3  0x00007fe20a5e4b06 in Tcl_PkgRequireEx () from
> /usr/lib/x86_64-linux-gnu/libtcl8.6.so
> #4  0x00007fe20a976be8 in Rplot_Init (interp=0x55ae6437a6c0) at
> tcltkimg.c:465
> #5  0x00007fe20a5d1ee3 in ?? () from /usr/lib/x86_64-linux-gnu/
> libtcl8.6.so
> #6  0x00007fe20a50f5f2 in TclNRRunCallbacks () from
> /usr/lib/x86_64-linux-gnu/libtcl8.6.so
> #7  0x00007fe20b04d7f0 in dotTclObjv (args=0x55ae6489d210) at
> /mnt/c/R/R-svn/trunk/src/library/tcltk/src/tcltk.c:250
> #8  0x000055ae611cd5a8 in do_External (call=0x55ae6440a270,
> op=0x55ae61fe1338, args=0x55ae6489d210, env=0x55ae6489d3d0)
>     at /mnt/c/R/R-svn/trunk/src/main/dotcode.c:576
> #9  0x000055ae6122a0b3 in bcEval (body=0x55ae6440a190, rho=0x55ae6489d3d0,
> useCache=TRUE)
>     at /mnt/c/R/R-svn/trunk/src/main/eval.c:7128
> #10 0x000055ae6121644a in Rf_eval (e=0x55ae6440a190, rho=0x55ae6489d3d0)
> at /mnt/c/R/R-svn/trunk/src/main/eval.c:740
> #11 0x000055ae61215fda in forcePromise (e=0x55ae6489d398) at
> /mnt/c/R/R-svn/trunk/src/main/eval.c:568
> #12 0x000055ae61220b80 in FORCE_PROMISE (value=0x55ae6489d398,
> symbol=0x55ae62282a08, rho=0x55ae6489d248,
>     keepmiss=FALSE) at /mnt/c/R/R-svn/trunk/src/main/eval.c:5149
> #13 0x000055ae61220d2f in getvar (symbol=0x55ae62282a08,
> rho=0x55ae6489d248, dd=FALSE, keepmiss=FALSE,
>     vcache=0x7fe20b2ec1f0, sidx=1) at
> /mnt/c/R/R-svn/trunk/src/main/eval.c:5190
>
> Henrik, can you reproduce this if you undefine DISPLAY?
>
> -Bill
>
>
>
>
> On Wed, Sep 29, 2021 at 7:48 PM Henrik Bengtsson <
> henrik.bengtsson at gmail.com> wrote:
>
>> I just tried on an up-to-date CentOS 7 with R 4.1.1 built from source
>> using gcc 8.3.1 (from SCL devtoolset-8; so not the default gcc 4.8.5),
>> and it works there.  If of any help, here's the output when installing
>> to user's personal package library:
>>
>> > chooseCRANmirror(ind = 1)
>> > install.packages("forensim")
>> Installing package into
>> ?/c4/home/henrik/R/x86_64-pc-linux-gnu-library/4.1-CBI-gcc8?
>> (as ?lib? is unspecified)
>> trying URL 'https://cloud.r-project.org/src/contrib/forensim_4.3.tar.gz'
>> Content type 'application/x-gzip' length 84232 bytes (82 KB)
>> ==================================================
>> downloaded 82 KB
>>
>> * installing *source* package ?forensim? ...
>> ** package ?forensim? successfully unpacked and MD5 sums checked
>> ** using staged installation
>> ** libs
>> gcc -I"/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/include"
>> -DNDEBUG   -I/usr/local/include   -fpic  -g -O2  -c auxilary.c -o
>> auxilary.o
>> gcc -I"/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/include"
>> -DNDEBUG   -I/usr/local/include   -fpic  -g -O2  -c recursFinal.c -o
>> recursFinal.o
>> gcc -shared -L/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/lib
>> -L/usr/local/lib64 -o forensim.so auxilary.o recursFinal.o
>> -L/software/c4/cbi/software/R-4.1.1-gcc8/lib64/R/lib -lR
>> installing to
>> /c4/home/henrik/R/x86_64-pc-linux-gnu-library/4.1-CBI-gcc8/00LOCK-forensim/00new/forensim/libs
>> ** R
>> ** data
>> ** inst
>> ** byte-compile and prepare package for lazy loading
>> ** help
>> *** installing help indices
>> ** building package indices
>> ** testing if installed package can be loaded from temporary location
>> ** checking absolute paths in shared objects and dynamic libraries
>> ** testing if installed package can be loaded from final location
>> ** testing if installed package keeps a record of temporary installation
>> path
>> * DONE (forensim)
>>
>> The downloaded source packages are in
>>     ?/scratch/henrik/RtmpYFlQyS/downloaded_packages?
>>
>> You could also try to install it via 'R CMD INSTALL' and try with
>> different options disabled to maybe narrow in on what's going on.
>>
>> My $.02
>>
>> /Henrik
>>
>> On Wed, Sep 29, 2021 at 6:37 PM Brodie, Kent via R-help
>> <r-help at r-project.org> wrote:
>> >
>> > Hey everyone!  So, I've been asked by one of our researchers to install
>> "all" cran packages on one of our servers.    Yeah, it's a bit much (and
>> clearly, not everything will install correctly due to various missing
>> tidbits), but it will go a long way to having to constantly respond to
>> install requests of various packages.  OK, fine.
>> >
>> > Anyway, I have tried this, and things proceed nicely for several hours
>> until the process gets completely and absolutely stuck.   I have tried
>> several things, for example trying newer versions of R, and even repeating
>> the process on a CentOS 8 server instead of where my stuff is now (CentOS
>> 7).
>> >
>> > While re-trying one of my newer attempts at this, I decided to focus on
>> the very first place where it hangs.   It dies on package "forensim".
>> It's a slightly older package, and I don't see anything particularly
>> special about it.    The text below is where it hangs.    The install "R"
>> process doing this is whizzing at 100%,  but no progress, no output, no
>> errors.  Nothing in the system logs.
>> >
>> > On new "R" installs, with either operating system (CentOS 7, CentOS 8)
>> and even different versions of "R" (up to including 4.1.1), I get the same
>> result when just attempting to install this ONE package.    (and my guess,
>> there's more packages out there that may bite me the same way).
>> >
>> > I am seeking any recommendations on how I can get past this?   A debug
>> option?  A timeout of sorts so things will  move along to the next package
>> when attempting to install a ton, or...?   I'm of course willing to try
>> anything.   It's stupidly frustrating.    I'd be OK if it errored out and
>> moved on.   But it...  hangs.
>> >
>> > Here's the latter part of the install attempt of this one package.
>>  This latest attempt has been stuck on that last line now for 5 hours and
>> counting.
>> >
>> > * DONE (tkrplot)
>> > Making 'packages.html' ... done
>> > * installing *source* package 'forensim' ...
>> > ** package 'forensim' successfully unpacked and MD5 sums checked
>> > ** using staged installation
>> > ** libs
>> > gcc -m64 -I"/usr/include/R" -DNDEBUG   -I/usr/local/include   -fpic
>> -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2
>> -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong
>> -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
>> -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
>> -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection  -c
>> auxilary.c -o auxilary.o
>> > gcc -m64 -I"/usr/include/R" -DNDEBUG   -I/usr/local/include   -fpic
>> -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2
>> -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong
>> -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
>> -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
>> -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection  -c
>> recursFinal.c -o recursFinal.o
>> > gcc -m64 -shared -L/usr/lib64/R/lib -Wl,-z,relro -Wl,-z,now
>> -specs=/usr/lib/rpm/redhat/redhat-hardened-ld -o forensim.so auxilary.o
>> recursFinal.o -L/usr/lib64/R/lib -lR
>> > installing to /usr/lib64/R/library/00LOCK-forensim/00new/forensim/libs
>> > ** R
>> > ** data
>> > ** inst
>> > ** byte-compile and prepare package for lazy loading
>> >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Thu Sep 30 19:33:34 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Thu, 30 Sep 2021 10:33:34 -0700
Subject: [R] Package installation help: Stuck at "** byte-compile and
 prepare package for lazy loading"
In-Reply-To: <BL3PR01MB6850E91579F3B438EC83367DCEAA9@BL3PR01MB6850.prod.exchangelabs.com>
References: <BL3PR01MB68506C30DB1731B2E39975DCCEA99@BL3PR01MB6850.prod.exchangelabs.com>
 <CAFDcVCTd_mhZLEQpqgS0ErHUeSMmOoKt0zLLLm97MnaL0RkhGg@mail.gmail.com>
 <CAHqSRuQSBOc9eKA8vXawPM5VFCMqbBQwDrgch0xZ9MGC=M7LVA@mail.gmail.com>
 <BL3PR01MB6850E91579F3B438EC83367DCEAA9@BL3PR01MB6850.prod.exchangelabs.com>
Message-ID: <CAHqSRuRKuOgGCWNbJ3rU1_S+38LQ6XH1oAO4o=yctVWr6j8xCw@mail.gmail.com>

You can define the environment variable R_DONT_USE_TK (to any value) to
avoid this hang caused by code in the tkrplot package.  You do not have to
have an X server running if R_DONT_USE_TK is set.  This will avoid
potential hangs while installing the 23 packages that depend on tkrplot.

tools::package_dependencies("tkrplot", reverse=TRUE, recursive=TRUE)
$tkrplot
 [1] "adoption"               "baggingbwsel"           "biplotbootGUI"
 [4] "cncaGUI"                "ConvergenceConcepts"    "fisheyeR"
 [7] "forensim"               "GGEBiplotGUI"           "GUIDE"
[10] "idendr0"                "InterfaceqPCR"          "multibiplotGUI"
[13] "RclusTool"              "RcmdrPlugin.FuzzyClust"
"RcmdrPlugin.PcaRobust"
[16] "rriskDistributions"     "RVideoPoker"            "SyNet"
[19] "tsgui"                  "uHMM"                   "GGEBiplots"
[22] "decisionSupport"        "geneticae"

E.g.,

> install.packages("forensim", type="source",
INSTALL_opts="--no-byte-compile")
Installing package into ?/home/bill/R-devel/R-build/site-library?
(as ?lib? is unspecified)
trying URL 'https://cloud.r-project.org/src/contrib/forensim_4.3.tar.gz'
Content type 'application/x-gzip' length 84232 bytes (82 KB)
==================================================
downloaded 82 KB

* installing *source* package ?forensim? ...
** package ?forensim? successfully unpacked and MD5 sums checked
** using staged installation
** libs
gcc -I"/home/bill/R-devel/R-build/include" -DNDEBUG   -I/usr/local/include
  -fpic  -g  -c auxilary.c -o auxilary.o
gcc -I"/home/bill/R-devel/R-build/include" -DNDEBUG   -I/usr/local/include
  -fpic  -g  -c recursFinal.c -o recursFinal.o
gcc -shared -L/usr/local/lib -o forensim.so auxilary.o recursFinal.o
installing to
/home/bill/R-devel/R-build/site-library/00LOCK-forensim/00new/forensim/libs
** R
** data
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded from temporary location
** checking absolute paths in shared objects and dynamic libraries
** testing if installed package can be loaded from final location
** testing if installed package keeps a record of temporary installation
path
* DONE (forensim)

The downloaded source packages are in
        ?/tmp/Rtmp0jqhj9/downloaded_packages?

The relevant code is in tkrplot/src/tcltkimg.c:

EXPORT(int,Rplot_Init)(interp)
    Tcl_Interp *interp;
{
    /* Added to allow CRAN to disable Tk initialization */
#if !defined(Win32) && !defined(HAVE_AQUA)
    if (getenv("R_DONT_USE_TK") != NULL)
        return 0;
#endif

-Bill


On Thu, Sep 30, 2021 at 9:35 AM Brodie, Kent <brodie at mcw.edu> wrote:

> Bill--   BINGO.    You have found the answer.     After some testing on
> one of my environments where it was always hanging, connecting to the same
> server with an X-Sever running on my workstation did indeed allow the
> package to be installed.
>
>
>
> **GOOD LORD THAT?S RIDICULOUS**   But---- at least I know.    And why it
> doesn?t error out without X running, who knows.
>
>
>
> After a ton more research, I ALSO discovered that there IS a timeout thing
> I can make use of, should I decide to continue just building things and
> ignoring the X-Server requirement for this (and probably some other?)
> packages.
>
>
>
> Before executing R and installing things, set this:
>
>
>
> export _R_INSTALL_PACKAGES_ELAPSED_TIMEOUT_=500
>
>
>
> (value is seconds).   So, the previously-hanging R CMD INSTALL inside of
> the install.packages call will eventually die, and then move on to the next
> package.
>
> This is buried in the documentation but- it?s there and I confirmed it
> works.    My example above times out a package install  at 5 minutes.
>
>
>
> While knowing the X requirement is a huge win (thanks again!), I will
> probably stick with just using the timeout thing for what I?m trying to
> accomplish.    Installing EVERYTHING from cran will take forever, and more
> than likely my VPN connection to my data center will be disconnected (thank
> you internal IT department) before it finishes.    They have some sort of
> internal ?you?ve been connected too long? timer that disconnects things
> overnight.   Grr.
>
>
>

	[[alternative HTML version deleted]]


From iuke-tier@ey m@iii@g oii uiow@@edu  Thu Sep 30 19:37:13 2021
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Thu, 30 Sep 2021 12:37:13 -0500 (CDT)
Subject: [R] [External] Re: Package installation help: Stuck at "**
 byte-compile and prepare package for lazy loading"
In-Reply-To: <BL3PR01MB6850E91579F3B438EC83367DCEAA9@BL3PR01MB6850.prod.exchangelabs.com>
References: <BL3PR01MB68506C30DB1731B2E39975DCCEA99@BL3PR01MB6850.prod.exchangelabs.com>
 <CAFDcVCTd_mhZLEQpqgS0ErHUeSMmOoKt0zLLLm97MnaL0RkhGg@mail.gmail.com>
 <CAHqSRuQSBOc9eKA8vXawPM5VFCMqbBQwDrgch0xZ9MGC=M7LVA@mail.gmail.com>
 <BL3PR01MB6850E91579F3B438EC83367DCEAA9@BL3PR01MB6850.prod.exchangelabs.com>
Message-ID: <alpine.DEB.2.22.394.2109301236460.2872@luke-Latitude-7480>

When I do full CRAN/BIOC installs I use Xvfb via something like

Xvfb :5 -screen 0 1280x1024x24 &
setenv DISPLAY :5

Best,

luke

On Thu, 30 Sep 2021, Brodie, Kent via R-help wrote:

> Bill--   BINGO.    You have found the answer.     After some testing on one of my environments where it was always hanging, connecting to the same server with an X-Sever running on my workstation did indeed allow the package to be installed.
>
> **GOOD LORD THAT?S RIDICULOUS**   But---- at least I know.    And why it doesn?t error out without X running, who knows.
>
> After a ton more research, I ALSO discovered that there IS a timeout thing I can make use of, should I decide to continue just building things and ignoring the X-Server requirement for this (and probably some other?) packages.
>
> Before executing R and installing things, set this:
>
> export _R_INSTALL_PACKAGES_ELAPSED_TIMEOUT_=500
>
> (value is seconds).   So, the previously-hanging R CMD INSTALL inside of the install.packages call will eventually die, and then move on to the next package.
> This is buried in the documentation but- it?s there and I confirmed it works.    My example above times out a package install  at 5 minutes.
>
> While knowing the X requirement is a huge win (thanks again!), I will probably stick with just using the timeout thing for what I?m trying to accomplish.    Installing EVERYTHING from cran will take forever, and more than likely my VPN connection to my data center will be disconnected (thank you internal IT department) before it finishes.    They have some sort of internal ?you?ve been connected too long? timer that disconnects things overnight.   Grr.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

